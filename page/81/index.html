
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/81/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-eess.AS_2023_07_26" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/26/eess.AS_2023_07_26/" class="article-date">
  <time datetime="2023-07-26T14:00:00.000Z" itemprop="datePublished">2023-07-26</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/26/eess.AS_2023_07_26/">eess.AS - 2023-07-26</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Sound-Field-Estimation-around-a-Rigid-Sphere-with-Physics-informed-Neural-Network"><a href="#Sound-Field-Estimation-around-a-Rigid-Sphere-with-Physics-informed-Neural-Network" class="headerlink" title="Sound Field Estimation around a Rigid Sphere with Physics-informed Neural Network"></a>Sound Field Estimation around a Rigid Sphere with Physics-informed Neural Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14013">http://arxiv.org/abs/2307.14013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xingyu Chen, Fei Ma, Amy Bastine, Prasanga Samarasinghe, Huiyuan Sun</li>
<li>for: 实时测量圆体周围的声场需要足够的样本，但这不一定可行。这篇论文提出了基于物理学习网络的声场估计方法，将物理知识 integrate into 网络架构和训练过程。与其他学习基于方法不同，提议的方法具有更好的适应能力和较少的样本需求。</li>
<li>methods: physics-informed neural network</li>
<li>results: 比起圆函数方法和平面波分解方法，提议的方法可以实现更加精确的声场估计，并且不需要大量的样本。在实验中，这篇论文的方法可以从有限的测量数据中获得更加精确的声场估计，超过圆函数方法和平面波分解方法的表现。<details>
<summary>Abstract</summary>
Accurate estimation of the sound field around a rigid sphere necessitates adequate sampling on the sphere, which may not always be possible. To overcome this challenge, this paper proposes a method for sound field estimation based on a physics-informed neural network. This approach integrates physical knowledge into the architecture and training process of the network. In contrast to other learning-based methods, the proposed method incorporates additional constraints derived from the Helmholtz equation and the zero radial velocity condition on the rigid sphere. Consequently, it can generate physically feasible estimations without requiring a large dataset. In contrast to the spherical harmonic-based method, the proposed approach has better fitting abilities and circumvents the ill condition caused by truncation. Simulation results demonstrate the effectiveness of the proposed method in achieving accurate sound field estimations from limited measurements, outperforming the spherical harmonic method and plane-wave decomposition method.
</details>
<details>
<summary>摘要</summary>
固定圆球的声场估算需要充足的样本点，但这不总是可能的。为解决这个挑战，本文提出了基于物理学习网络的声场估算方法。这种方法将物理知识 integrate into网络的架构和训练过程中。与其他学习基本方法不同，该方法添加了基于海尔曼方程和径向速度条件在固定圆球上的额外约束。因此，它可以生成符合物理规则的估算结果，不需要大量数据。与圆球幂函数基本方法相比，本方法有更好的适应性和规则化特征，并且不受截断的缺陷。通过实验结果，本文证明了该方法在基于有限测量数据的情况下可以实现高精度的声场估算，超过圆球幂函数基本方法和平面波分解方法。
</details></li>
</ul>
<hr>
<h2 id="Speech-representation-learning-Learning-bidirectional-encoders-with-single-view-multi-view-and-multi-task-methods"><a href="#Speech-representation-learning-Learning-bidirectional-encoders-with-single-view-multi-view-and-multi-task-methods" class="headerlink" title="Speech representation learning: Learning bidirectional encoders with single-view, multi-view, and multi-task methods"></a>Speech representation learning: Learning bidirectional encoders with single-view, multi-view, and multi-task methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00129">http://arxiv.org/abs/2308.00129</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingming Tang</li>
<li>for: 本论文主要针对sequence数据上的时间或空间学习 representation learning，以提高下游序列预测任务的性能。</li>
<li>methods: 本论文使用supervised learning和多种不同的学习方法，包括auxiliary loss学习、无监督学习、半监督学习和多视图学习。</li>
<li>results: 本论文通过多种学习设置和方法，对speech数据进行了广泛的研究，并获得了一些有价值的结果。这些结果可以应用于其他领域中。<details>
<summary>Abstract</summary>
This thesis focuses on representation learning for sequence data over time or space, aiming to improve downstream sequence prediction tasks by using the learned representations. Supervised learning has been the most dominant approach for training deep neural networks for learning good sequential representations. However, one limiting factor to scale supervised learning is the lack of enough annotated data. Motivated by this challenge, it is natural to explore representation learning methods that can utilize large amounts of unlabeled and weakly labeled data, as well as an additional data modality. I describe my broad study of representation learning for speech data. Unlike most other works that focus on a single learning setting, this thesis studies multiple settings: supervised learning with auxiliary losses, unsupervised learning, semi-supervised learning, and multi-view learning. Besides different learning problems, I also explore multiple approaches for representation learning. Though I focus on speech data, the methods described in this thesis can also be applied to other domains. Overall, the field of representation learning is developing rapidly. State-of-the-art results on speech related tasks are typically based on Transformers pre-trained with large-scale self-supervised learning, which aims to learn generic representations that can benefit multiple downstream tasks. Since 2020, large-scale pre-training has been the de facto choice to achieve good performance. This delayed thesis does not attempt to summarize and compare with the latest results on speech representation learning; instead, it presents a unique study on speech representation learning before the Transformer era, that covers multiple learning settings. Some of the findings in this thesis can still be useful today.
</details>
<details>
<summary>摘要</summary>
这个论文关注在时间或空间序列数据上进行表示学习，以提高下游序列预测任务的性能。supervised learning是深度神经网络训练好序列表示的最主要方法。然而，缺乏充足的注释数据是规模supervised learning的限制因素。为了解决这个挑战，这个论文 explore representation learning方法，可以利用大量无注释和弱注释数据，以及多个数据模式。我描述了对speech数据的广泛研究，不同于大多数其他作品，这个论文研究了多种学习Setting：supervised learning with auxiliary losses、Unsupervised learning、semi-supervised learning和多视图学习。此外，我还探索了多种表示学习方法。尽管我专注于speech数据，但这些方法可以应用到其他领域。总的来说，表示学习领域在快速发展。目前最佳的speech相关任务的结果通常基于Transformers预先训练大规模自我超vised learning，该学习目标是学习通用的表示，可以改善多个下游任务。自2020年以来，大规模预训练成为了downstream任务的启用之选择。这个论文不尝试总结和与最新的speech表示学习结果进行比较，而是提供了在Transformer时代之前的speech表示学习研究，覆盖多种学习Setting。一些这个论文中的发现仍然有用。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/26/eess.AS_2023_07_26/" data-id="clpxp046k013yfm885w82e04j" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_07_26" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/26/cs.CV_2023_07_26/" class="article-date">
  <time datetime="2023-07-26T13:00:00.000Z" itemprop="datePublished">2023-07-26</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/26/cs.CV_2023_07_26/">cs.CV - 2023-07-26</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Artifact-Restoration-in-Histology-Images-with-Diffusion-Probabilistic-Models"><a href="#Artifact-Restoration-in-Histology-Images-with-Diffusion-Probabilistic-Models" class="headerlink" title="Artifact Restoration in Histology Images with Diffusion Probabilistic Models"></a>Artifact Restoration in Histology Images with Diffusion Probabilistic Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14262">http://arxiv.org/abs/2307.14262</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhenqi-he/artifusion">https://github.com/zhenqi-he/artifusion</a></li>
<li>paper_authors: Zhenqi He, Junjun He, Jin Ye, Yiqing Shen</li>
<li>for:  histological whole slide images (WSIs) restoration</li>
<li>methods:  denoising diffusion probabilistic model (ArtiFusion) with a novel Swin-Transformer denoising architecture and time token scheme</li>
<li>results:  effective restoration of artifact-free regions with preserved tissue structures and stain style, as demonstrated through extensive evaluations.<details>
<summary>Abstract</summary>
Histological whole slide images (WSIs) can be usually compromised by artifacts, such as tissue folding and bubbles, which will increase the examination difficulty for both pathologists and Computer-Aided Diagnosis (CAD) systems. Existing approaches to restoring artifact images are confined to Generative Adversarial Networks (GANs), where the restoration process is formulated as an image-to-image transfer. Those methods are prone to suffer from mode collapse and unexpected mistransfer in the stain style, leading to unsatisfied and unrealistic restored images. Innovatively, we make the first attempt at a denoising diffusion probabilistic model for histological artifact restoration, namely ArtiFusion.Specifically, ArtiFusion formulates the artifact region restoration as a gradual denoising process, and its training relies solely on artifact-free images to simplify the training complexity.Furthermore, to capture local-global correlations in the regional artifact restoration, a novel Swin-Transformer denoising architecture is designed, along with a time token scheme. Our extensive evaluations demonstrate the effectiveness of ArtiFusion as a pre-processing method for histology analysis, which can successfully preserve the tissue structures and stain style in artifact-free regions during the restoration. Code is available at https://github.com/zhenqi-he/ArtiFusion.
</details>
<details>
<summary>摘要</summary>
histological whole slide images (WSIs) 可能会受到artefacts的影响，如组织卷积和气泡，这会提高Pathologist和Computer-Aided Diagnosis (CAD)系统的检查难度。现有的恢复artefact图像方法被限定于生成对抗网络 (GANs)，其恢复过程是表示为图像-to-图像传输。这些方法容易受到模式落寞和意外传输的问题，导致不满意的和不实际的恢复图像。我们在这里做出了一个新的恢复气泡概率模型，即ArtiFusion。具体来说，ArtiFusion将artefact区域恢复视为一种慢涨推敲过程，其训练仅基于无artefact图像，以简化训练复杂性。此外，为了捕捉区域artefact恢复中的本地-全局相关性，我们设计了一种Swin-Transformer推净架构，并采用时间token方案。我们的广泛评估表明ArtiFusion作为 histology分析前置处理方法，可以成功保留组织结构和染色 Style在恢复后的artefact-free区域中。代码可以在https://github.com/zhenqi-he/ArtiFusion上获取。
</details></li>
</ul>
<hr>
<h2 id="Sparse-Double-Descent-in-Vision-Transformers-real-or-phantom-threat"><a href="#Sparse-Double-Descent-in-Vision-Transformers-real-or-phantom-threat" class="headerlink" title="Sparse Double Descent in Vision Transformers: real or phantom threat?"></a>Sparse Double Descent in Vision Transformers: real or phantom threat?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14253">http://arxiv.org/abs/2307.14253</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vgcq/sdd_vit">https://github.com/vgcq/sdd_vit</a></li>
<li>paper_authors: Victor Quétu, Marta Milovanovic, Enzo Tartaglione</li>
<li>for: 这 paper 的目的是研究 Vision Transformers (ViT) 是否受到 “sparse double descent” 现象的影响，并找到避免该现象的方法。</li>
<li>methods: 该 paper 使用了一种 attention-based 方法，并对 ViT 进行了优化调整，以避免 inductive bias 的影响。</li>
<li>results: 研究发现，对于 ViT，可以通过优化 lambda 值来避免 sparse double descent 现象，但是这会导致模型的压缩。<details>
<summary>Abstract</summary>
Vision transformers (ViT) have been of broad interest in recent theoretical and empirical works. They are state-of-the-art thanks to their attention-based approach, which boosts the identification of key features and patterns within images thanks to the capability of avoiding inductive bias, resulting in highly accurate image analysis. Meanwhile, neoteric studies have reported a ``sparse double descent'' phenomenon that can occur in modern deep-learning models, where extremely over-parametrized models can generalize well. This raises practical questions about the optimal size of the model and the quest over finding the best trade-off between sparsity and performance is launched: are Vision Transformers also prone to sparse double descent? Can we find a way to avoid such a phenomenon? Our work tackles the occurrence of sparse double descent on ViTs. Despite some works that have shown that traditional architectures, like Resnet, are condemned to the sparse double descent phenomenon, for ViTs we observe that an optimally-tuned $\ell_2$ regularization relieves such a phenomenon. However, everything comes at a cost: optimal lambda will sacrifice the potential compression of the ViT.
</details>
<details>
<summary>摘要</summary>
幻transformer（ViT）在最近的理论和实验研究中受到广泛关注。它们因其基于注意力的方法而成为现代图像分析的州��ensional标准，可以快速和准确地找到图像中的关键特征和模式。然而，新的研究还发现了一种“稀疏双峰”现象，这种现象在现代深度学习模型中出现，其中非常过参数的模型可以总是具有高度的泛化能力。这引发了实用问题：幻transformer也是否受到稀疏双峰现象的影响？我们的工作是研究幻transformer中稀疏双峰现象的发生。虽然一些研究表明，传统的architecture，如Resnet，是不可避免稀疏双峰现象的，但是对于幻transformer，我们发现了一种优化的 $\ell_2$ 正则化可以缓解这种现象。然而，这来的代价是优化lambda会导致幻transformer的潜在压缩被抑制。
</details></li>
</ul>
<hr>
<h2 id="Fluorescent-Neuronal-Cells-v2-Multi-Task-Multi-Format-Annotations-for-Deep-Learning-in-Microscopy"><a href="#Fluorescent-Neuronal-Cells-v2-Multi-Task-Multi-Format-Annotations-for-Deep-Learning-in-Microscopy" class="headerlink" title="Fluorescent Neuronal Cells v2: Multi-Task, Multi-Format Annotations for Deep Learning in Microscopy"></a>Fluorescent Neuronal Cells v2: Multi-Task, Multi-Format Annotations for Deep Learning in Microscopy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14243">http://arxiv.org/abs/2307.14243</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luca Clissa, Antonio Macaluso, Roberto Morelli, Alessandra Occhinegro, Emiliana Piscitiello, Ludovico Taddei, Marco Luppi, Roberto Amici, Matteo Cerri, Timna Hitrec, Lorenzo Rinaldi, Antonio Zoccoli</li>
<li>for: 本研究用于推动生物科学领域的computer视觉技术发展，提供多种标注数据集，包括semantic segmentation、物体检测和计数等学习任务。</li>
<li>methods: 本研究使用多种染色物标注 rodent neuronal cells的核心和细胞膜，包括多种生物marker和生物chemical marker，以便研究computer视觉技术的发展。</li>
<li>results: 本研究提供了一个多样化的数据集，包括rodent neuronal cells的核心和细胞膜的多种染色物标注，可以推动computer视觉技术的发展，并且可以用于多种生物科学研究。<details>
<summary>Abstract</summary>
Fluorescent Neuronal Cells v2 is a collection of fluorescence microscopy images and the corresponding ground-truth annotations, designed to foster innovative research in the domains of Life Sciences and Deep Learning. This dataset encompasses three image collections in which rodent neuronal cells' nuclei and cytoplasm are stained with diverse markers to highlight their anatomical or functional characteristics. Alongside the images, we provide ground-truth annotations for several learning tasks, including semantic segmentation, object detection, and counting. The contribution is two-fold. First, given the variety of annotations and their accessible formats, we envision our work facilitating methodological advancements in computer vision approaches for segmentation, detection, feature learning, unsupervised and self-supervised learning, transfer learning, and related areas. Second, by enabling extensive exploration and benchmarking, we hope Fluorescent Neuronal Cells v2 will catalyze breakthroughs in fluorescence microscopy analysis and promote cutting-edge discoveries in life sciences. The data are available at: https://amsacta.unibo.it/id/eprint/7347
</details>
<details>
<summary>摘要</summary>
fluorescent neuronal cells v2是一个包含 fluorescence microscopy 图像和相应的ground truth注释的集合，旨在推动生命科学和深度学习领域的创新研究。这个数据集包括三个图像集，其中 rodent neuronal cells的核和质物被使用不同的标记物来标出其形态或功能特征。同时，我们提供了ground truth注释，用于多种学习任务，包括semantic segmentation、object detection和 counting。我们的贡献是twofold。首先，由于数据集中的多样性和可访问的格式，我们期望我们的工作会促进计算机视觉方法的进步，包括 segmentation、 detection、feature learning、unsupervised和self-supervised learning、转移学习等领域。其次，通过允许广泛探索和比较，我们希望fluorescent neuronal cells v2会促进 fluorescence microscopy 分析的进步，并推动生命科学的前沿研究。数据可以在以下链接中下载：https://amsacta.unibo.it/id/eprint/7347。
</details></li>
</ul>
<hr>
<h2 id="Defending-Adversarial-Patches-via-Joint-Region-Localizing-and-Inpainting"><a href="#Defending-Adversarial-Patches-via-Joint-Region-Localizing-and-Inpainting" class="headerlink" title="Defending Adversarial Patches via Joint Region Localizing and Inpainting"></a>Defending Adversarial Patches via Joint Region Localizing and Inpainting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14242">http://arxiv.org/abs/2307.14242</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junwen Chen, Xingxing Wei</li>
<li>for: 防御对象是遭受攻击的图像识别和检测任务，应对于各种攻击方法，包括对象视觉上的变化和内容上的遗传。</li>
<li>methods: 提出了一种基于“本地化和填充”机制的防御方法，包括一个两棵分支结构的“本地化”子网络和一个使用周围上下文信息填充原始内容的“填充”子网络，两者通过迭代优化方式相互关联学习。</li>
<li>results: 通过对多个交通标识和检测任务进行测试，证明了该防御方法能够有效地防御各种攻击检测和识别任务，并且可以保持图像的可读性和检测性。<details>
<summary>Abstract</summary>
Deep neural networks are successfully used in various applications, but show their vulnerability to adversarial examples. With the development of adversarial patches, the feasibility of attacks in physical scenes increases, and the defenses against patch attacks are urgently needed. However, defending such adversarial patch attacks is still an unsolved problem. In this paper, we analyse the properties of adversarial patches, and find that: on the one hand, adversarial patches will lead to the appearance or contextual inconsistency in the target objects; on the other hand, the patch region will show abnormal changes on the high-level feature maps of the objects extracted by a backbone network. Considering the above two points, we propose a novel defense method based on a ``localizing and inpainting" mechanism to pre-process the input examples. Specifically, we design an unified framework, where the ``localizing" sub-network utilizes a two-branch structure to represent the above two aspects to accurately detect the adversarial patch region in the image. For the ``inpainting" sub-network, it utilizes the surrounding contextual cues to recover the original content covered by the adversarial patch. The quality of inpainted images is also evaluated by measuring the appearance consistency and the effects of adversarial attacks. These two sub-networks are then jointly trained via an iterative optimization manner. In this way, the ``localizing" and ``inpainting" modules can interact closely with each other, and thus learn a better solution. A series of experiments versus traffic sign classification and detection tasks are conducted to defend against various adversarial patch attacks.
</details>
<details>
<summary>摘要</summary>
深度神经网络在不同应用中得到了成功，但它们受到了针对性攻击的漏洞。随着物理场景中的攻击可能性的提高，防御针对贴图攻击的需求也日益增加。然而，防御针对贴图攻击仍然是一个未解决的问题。在这篇论文中，我们分析了针对贴图攻击的特性，并发现：一方面，贴图会导致目标对象的外观或上下文不一致；另一方面，贴图区域在对象提取后的高级特征图中会出现异常变化。基于以上两点，我们提出了一种基于“局部化和填充”机制的防御方法。具体来说，我们设计了一个统一框架，其中“局部化”子网络采用两棵树结构来准确检测贴图区域在图像中。为“填充”子网络，它利用周围的上下文征化来恢复贴图覆盖的原始内容。我们对填充图像的质量也进行了评估，包括外观一致性和针对攻击的影响。这两个子网络然后通过迭代优化方式进行联合培训，以便“局部化”和“填充”模块可以更好地互动。通过这种方式，我们可以更好地防御针对贴图攻击。我们在交通标识和检测任务上进行了多个实验，以防御不同类型的贴图攻击。
</details></li>
</ul>
<hr>
<h2 id="DisguisOR-Holistic-Face-Anonymization-for-the-Operating-Room"><a href="#DisguisOR-Holistic-Face-Anonymization-for-the-Operating-Room" class="headerlink" title="DisguisOR: Holistic Face Anonymization for the Operating Room"></a>DisguisOR: Holistic Face Anonymization for the Operating Room</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14241">http://arxiv.org/abs/2307.14241</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wngtn/disguisor">https://github.com/wngtn/disguisor</a></li>
<li>paper_authors: Lennart Bastian, Tony Danjun Wang, Tobias Czempiel, Benjamin Busam, Nassir Navab<br>for: 这篇研究旨在提高医疗数据科学（SDS）中的隐私保护，特别是在运行室（OR）中的录影视频中。methods: 本研究使用多条camera流的RGB和深度图像进行整合，从而获得了3D点云表示。然后，通过对检测到的3D人体关键点进行对应，将人脸模型覆盖在每个摄取到的相机视野中。results: 本方法能够更高效地找到人脸，并且实现了更加自然的隐私保护。DisguisOR可以实现Scene Level的隐私保护，并且具有推进SDS更多研究的潜力。<details>
<summary>Abstract</summary>
Purpose: Recent advances in Surgical Data Science (SDS) have contributed to an increase in video recordings from hospital environments. While methods such as surgical workflow recognition show potential in increasing the quality of patient care, the quantity of video data has surpassed the scale at which images can be manually anonymized. Existing automated 2D anonymization methods under-perform in Operating Rooms (OR), due to occlusions and obstructions. We propose to anonymize multi-view OR recordings using 3D data from multiple camera streams. Methods: RGB and depth images from multiple cameras are fused into a 3D point cloud representation of the scene. We then detect each individual's face in 3D by regressing a parametric human mesh model onto detected 3D human keypoints and aligning the face mesh with the fused 3D point cloud. The mesh model is rendered into every acquired camera view, replacing each individual's face. Results: Our method shows promise in locating faces at a higher rate than existing approaches. DisguisOR produces geometrically consistent anonymizations for each camera view, enabling more realistic anonymization that is less detrimental to downstream tasks. Conclusion: Frequent obstructions and crowding in operating rooms leaves significant room for improvement for off-the-shelf anonymization methods. DisguisOR addresses privacy on a scene level and has the potential to facilitate further research in SDS.
</details>
<details>
<summary>摘要</summary>
Methods:  RGB and depth images from multiple cameras are fused into a 3D point cloud representation of the scene. We then detect each individual's face in 3D by regressing a parametric human mesh model onto detected 3D human keypoints and aligning the face mesh with the fused 3D point cloud. The mesh model is rendered into every acquired camera view, replacing each individual's face.Results:  Our method shows promise in locating faces at a higher rate than existing approaches. DisguisOR produces geometrically consistent anonymizations for each camera view, enabling more realistic anonymization that is less detrimental to downstream tasks.Conclusion:  Frequent obstructions and crowding in operating rooms leaves significant room for improvement for off-the-shelf anonymization methods. DisguisOR addresses privacy on a scene level and has the potential to facilitate further research in SDS.
</details></li>
</ul>
<hr>
<h2 id="Computational-Approaches-for-Traditional-Chinese-Painting-From-the-“Six-Principles-of-Painting”-Perspective"><a href="#Computational-Approaches-for-Traditional-Chinese-Painting-From-the-“Six-Principles-of-Painting”-Perspective" class="headerlink" title="Computational Approaches for Traditional Chinese Painting: From the “Six Principles of Painting” Perspective"></a>Computational Approaches for Traditional Chinese Painting: From the “Six Principles of Painting” Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14227">http://arxiv.org/abs/2307.14227</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Zhang, Jian-Wei Zhang, Kam Kwai Wong, Yifang Wang, Yingchaojie Feng, Luwei Wang, Wei Chen<br>for: 本研究旨在探讨计算机技术在传统中国画中的应用，以保护和普及这种独特的艺术风格。methods: 本研究采用了三个视角来分析计算机技术在传统中国画中的应用，包括以“六 principios of Painting”理论为基础的艺术元素分类、四个阶段框架来描述传统中国画应用的目的、以及常用的计算机技术在传统中国画中的应用。results: 本研究通过分析92篇文献和专家访谈，提出了一个四个阶段框架来描述传统中国画应用的目的，并概括了常用的计算机技术在传统中国画中的应用。这些成果可以帮助人们更好地理解计算机技术在传统中国画中的应用，并为未来的研究提供指导。<details>
<summary>Abstract</summary>
Traditional Chinese Painting (TCP) is an invaluable cultural heritage resource and a unique visual art style. In recent years, increasing interest has been placed on digitalizing TCPs to preserve and revive the culture. The resulting digital copies have enabled the advancement of computational methods for structured and systematic understanding of TCPs. To explore this topic, we conducted an in-depth analysis of 92 pieces of literature. We examined the current use of computer technologies on TCPs from three perspectives, based on numerous conversations with specialists. First, in light of the "Six Principles of Painting" theory, we categorized the articles according to their research focus on artistic elements. Second, we created a four-stage framework to illustrate the purposes of TCP applications. Third, we summarized the popular computational techniques applied to TCPs. The framework also provides insights into potential applications and future prospects, with professional opinion. The list of surveyed publications and related information is available online at https://ca4tcp.com.
</details>
<details>
<summary>摘要</summary>
传统中国画（TCP）是一种无价的文化遗产资源和独特的视觉艺术风格。在最近几年，对于数字化TCP的兴趣日益增长，以保存和复兴文化。这些数字化 kopi 已经帮助计算机科学方面的研究人员对TCP进行结构化和系统化的研究。为了探讨这个主题，我们进行了深入的文献分析，检视了92篇论文。我们根据“六则绘画理论”分类了文章，按照许多专家的讲话，对TCP的计算机技术的应用进行了三个视角。首先，根据“六则绘画理议”分类文章，按照艺术元素的研究方向进行了分类。其次，我们创建了四个阶段框架，以 Illustrate TCP 的应用目的。最后，我们总结了应用于TCP的流行计算机技术。这个框架还提供了可能的应用和未来前景，以及专业意见。悉数据和相关信息可以在https://ca4tcp.com 上查看。
</details></li>
</ul>
<hr>
<h2 id="ADAPT-Efficient-Multi-Agent-Trajectory-Prediction-with-Adaptation"><a href="#ADAPT-Efficient-Multi-Agent-Trajectory-Prediction-with-Adaptation" class="headerlink" title="ADAPT: Efficient Multi-Agent Trajectory Prediction with Adaptation"></a>ADAPT: Efficient Multi-Agent Trajectory Prediction with Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14187">http://arxiv.org/abs/2307.14187</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/KUIS-AI/adapt">https://github.com/KUIS-AI/adapt</a></li>
<li>paper_authors: Görkay Aydemir, Adil Kaan Akan, Fatma Güney</li>
<li>for: 预测复杂交通场景中机器人的未来轨迹，需要可靠和高效的预测方法。现有的预测方法都有缺点，或者效率低下，或者精度不高。</li>
<li>methods: 我们提出了ADAPT方法，它可以同时预测整个场景中所有机器人的轨迹，并且可以在运行时动态调整模型的权重。我们的方法在单机器人和多机器人设置下，在Argoverse和Interaction数据集上都超越了状态静态方法，而且具有相对较低的计算开销。</li>
<li>results: 我们的分析表明，ADAPT方法可以准确地预测每个机器人的轨迹，并且可以快速地完成预测任务。这是因为ADAPT方法可以根据每个机器人的特点，动态地调整预测模型的权重，以确保每个机器人的预测准确性。<details>
<summary>Abstract</summary>
Forecasting future trajectories of agents in complex traffic scenes requires reliable and efficient predictions for all agents in the scene. However, existing methods for trajectory prediction are either inefficient or sacrifice accuracy. To address this challenge, we propose ADAPT, a novel approach for jointly predicting the trajectories of all agents in the scene with dynamic weight learning. Our approach outperforms state-of-the-art methods in both single-agent and multi-agent settings on the Argoverse and Interaction datasets, with a fraction of their computational overhead. We attribute the improvement in our performance: first, to the adaptive head augmenting the model capacity without increasing the model size; second, to our design choices in the endpoint-conditioned prediction, reinforced by gradient stopping. Our analyses show that ADAPT can focus on each agent with adaptive prediction, allowing for accurate predictions efficiently. https://KUIS-AI.github.io/adapt
</details>
<details>
<summary>摘要</summary>
预测未来行车路径需要可靠和高效的预测，以确保所有在场景中的代理人的行车路径都能够预测 accurately。然而，现有的行车路径预测方法 Either inefficient or sacrifice accuracy. To address this challenge, we propose ADAPT, a novel approach for jointly predicting the trajectories of all agents in the scene with dynamic weight learning. Our approach outperforms state-of-the-art methods in both single-agent and multi-agent settings on the Argoverse and Interaction datasets, with a fraction of their computational overhead. We attribute the improvement in our performance to two aspects: first, the adaptive head augmenting the model capacity without increasing the model size; second, our design choices in the endpoint-conditioned prediction, reinforced by gradient stopping. Our analyses show that ADAPT can focus on each agent with adaptive prediction, allowing for accurate predictions efficiently.Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other countries. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Resolution-Aware-Design-of-Atrous-Rates-for-Semantic-Segmentation-Networks"><a href="#Resolution-Aware-Design-of-Atrous-Rates-for-Semantic-Segmentation-Networks" class="headerlink" title="Resolution-Aware Design of Atrous Rates for Semantic Segmentation Networks"></a>Resolution-Aware Design of Atrous Rates for Semantic Segmentation Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14179">http://arxiv.org/abs/2307.14179</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bum Jun Kim, Hyeyeon Choi, Hyeonah Jang, Sang Woo Kim</li>
<li>for: 本研究旨在提供深度学习网络 semantic segmentation 的优化方法，以提高 segmentation 结果的准确性。</li>
<li>methods: 本研究使用了 DeepLab 深度学习网络，并提出了一种基于 atrous spatial pyramid pooling (ASPP) 模块的 практиче guideline，以优化 ASPP 模块中的 atrous rate。</li>
<li>results:  comparing with other values, 使用优化的 atrous rate  consistently 提高了 segmentation 结果 across multiple datasets，包括 STARE、CHASE_DB1、HRF、Cityscapes 和 iSAID 数据集。<details>
<summary>Abstract</summary>
DeepLab is a widely used deep neural network for semantic segmentation, whose success is attributed to its parallel architecture called atrous spatial pyramid pooling (ASPP). ASPP uses multiple atrous convolutions with different atrous rates to extract both local and global information. However, fixed values of atrous rates are used for the ASPP module, which restricts the size of its field of view. In principle, atrous rate should be a hyperparameter to change the field of view size according to the target task or dataset. However, the manipulation of atrous rate is not governed by any guidelines. This study proposes practical guidelines for obtaining an optimal atrous rate. First, an effective receptive field for semantic segmentation is introduced to analyze the inner behavior of segmentation networks. We observed that the use of ASPP module yielded a specific pattern in the effective receptive field, which was traced to reveal the module's underlying mechanism. Accordingly, we derive practical guidelines for obtaining the optimal atrous rate, which should be controlled based on the size of input image. Compared to other values, using the optimal atrous rate consistently improved the segmentation results across multiple datasets, including the STARE, CHASE_DB1, HRF, Cityscapes, and iSAID datasets.
</details>
<details>
<summary>摘要</summary>
深度学习是一种广泛使用的深度神经网络，用于 semantic segmentation，其成功归功于其平行架构 called atrous spatial pyramid pooling (ASPP)。ASPP使用多个不同的atrous convolutions来提取本地和全局信息。然而，ASPP模块中使用的atrous rate是固定的，这限制了其观察领域的大小。在理论上，atrous rate应该是一个可变的超参数，根据目标任务或数据集来变化观察领域的大小。然而，atrous rate的调整没有任何指导。这个研究提出了实用的指南，以获取最佳的atrous rate。首先，我们引入了 semantic segmentation 的有效覆盖区域，以分析 segmentation 网络的内部行为。我们发现，使用 ASPP 模块后会产生特定的模式在有效覆盖区域中，这被跟踪到了模块的内部机制。根据这些结果，我们 derive 了实用的指南，以控制 atrous rate 的选择，即基于输入图像的大小。与其他值相比，使用最佳的 atrous rate  consistently 改善了 segmentation 结果，在多个数据集上，包括 STARE、CHASE_DB1、HRF、Cityscapes 和 iSAID 数据集。
</details></li>
</ul>
<hr>
<h2 id="High-definition-event-frame-generation-using-SoC-FPGA-devices"><a href="#High-definition-event-frame-generation-using-SoC-FPGA-devices" class="headerlink" title="High-definition event frame generation using SoC FPGA devices"></a>High-definition event frame generation using SoC FPGA devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14177">http://arxiv.org/abs/2307.14177</a></li>
<li>repo_url: None</li>
<li>paper_authors: Krzysztof Blachut, Tomasz Kryjak</li>
<li>for: 这个论文目的是实现FPGA设备上高分辨率事件数据流（HD -1280 x 720像素）的归一化和投影。</li>
<li>methods: 这个论文使用了FPGA设备来实现高分辨率事件数据流的归一化和投影。</li>
<li>results: 研究结果表明该方法是可行的，但需要考虑一些挑战、限制和让步。选择的数据表示方式的硬件资源与AMD Xilinx等流行平台进行比较。得到的事件帧可以用于典型的视觉算法，如物体分类和检测，使用传统和深度神经网络方法。<details>
<summary>Abstract</summary>
In this paper we have addressed the implementation of the accumulation and projection of high-resolution event data stream (HD -1280 x 720 pixels) onto the image plane in FPGA devices. The results confirm the feasibility of this approach, but there are a number of challenges, limitations and trade-offs to be considered. The required hardware resources of selected data representations, such as binary frame, event frame, exponentially decaying time surface and event frequency, were compared with those available on several popular platforms from AMD Xilinx. The resulting event frames can be used for typical vision algorithms, such as object classification and detection, using both classical and deep neural network methods.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们对FPGA设备上高分辨率事件数据流（HD-1280x720像素）的归一化和投影进行了实现。结果表明该方法可行，但需要考虑一些挑战、限制和让步。我们对选择的数据表示方式的硬件资源进行了比较，包括二进制帧、事件帧、加速度度时间表面和事件频率。得到的事件帧可以用于典型的视觉算法，如物体分类和检测，使用 both classical 和深度神经网络方法。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Generative-Modeling-with-Limited-Data-Few-Shots-and-Zero-Shot"><a href="#A-Survey-on-Generative-Modeling-with-Limited-Data-Few-Shots-and-Zero-Shot" class="headerlink" title="A Survey on Generative Modeling with Limited Data, Few Shots, and Zero Shot"></a>A Survey on Generative Modeling with Limited Data, Few Shots, and Zero Shot</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14397">http://arxiv.org/abs/2307.14397</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sutd-visual-computing-group/awesome-generative-modeling-under-data-constraints">https://github.com/sutd-visual-computing-group/awesome-generative-modeling-under-data-constraints</a></li>
<li>paper_authors: Milad Abdollahzadeh, Touba Malekzadeh, Christopher T. H. Teo, Keshigeyan Chandrasegaran, Guimeng Liu, Ngai-Man Cheung</li>
<li>for: 本研究旨在探讨在数据约束下学习生成模型，包括受限数据、几架数据和零架数据等情况。</li>
<li>methods: 本研究提出了两种分类法：一种是基于任务的分类，另一种是基于方法的分类。同时，研究者还分析了不同任务和方法之间的互动。</li>
<li>results: 研究者发现了一些未来研究的潜在方向，包括如何在数据约束下提高生成模型的性能，如何将生成模型应用于健康医疗领域，以及如何将生成模型与其他技术结合使用。<details>
<summary>Abstract</summary>
In machine learning, generative modeling aims to learn to generate new data statistically similar to the training data distribution. In this paper, we survey learning generative models under limited data, few shots and zero shot, referred to as Generative Modeling under Data Constraint (GM-DC). This is an important topic when data acquisition is challenging, e.g. healthcare applications. We discuss background, challenges, and propose two taxonomies: one on GM-DC tasks and another on GM-DC approaches. Importantly, we study interactions between different GM-DC tasks and approaches. Furthermore, we highlight research gaps, research trends, and potential avenues for future exploration. Project website: https://gmdc-survey.github.io.
</details>
<details>
<summary>摘要</summary>
在机器学习中，生成模型目标是学习生成新数据，与训练数据分布相似。在这篇论文中，我们对受限数据的生成模型学习进行报告，包括几个难点和挑战。我们还提出了两种分类：一种是生成模型下数据约束任务（GM-DC）任务，另一种是生成模型下数据约束方法（GM-DC）方法。此外，我们还研究了不同GM-DC任务和方法之间的交互关系。此外，我们还提出了未来探索的研究漏斗和趋势。您可以查看更多信息在我们的项目网站：<https://gmdc-survey.github.io>。
</details></li>
</ul>
<hr>
<h2 id="Creative-Birds-Self-Supervised-Single-View-3D-Style-Transfer"><a href="#Creative-Birds-Self-Supervised-Single-View-3D-Style-Transfer" class="headerlink" title="Creative Birds: Self-Supervised Single-View 3D Style Transfer"></a>Creative Birds: Self-Supervised Single-View 3D Style Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14127">http://arxiv.org/abs/2307.14127</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wrk226/creative_birds">https://github.com/wrk226/creative_birds</a></li>
<li>paper_authors: Renke Wang, Guimin Que, Shuo Chen, Xiang Li, Jun Li, Jian Yang</li>
<li>for: 本研究主要针对鸟类三维重建中的单一视角3D题目，提出了一个新的方法，能够将两个单一视角图像中的形状和文本URE转换到3D mesh上。</li>
<li>methods: 本方法使用了一个新的形式转换生成器（DRGNet）和一个多层感知核（MLP），将源图像和目标图像的特征提取出来，并生成3D mesh的空间坐标。此外，本方法还引入了一个semantic UV文本转换模组，实现了文本类型的Style Transfer，并可以与许多现有的方法相结合。</li>
<li>results: 实验结果显示，本方法在单一视角3D Style Transfer任务上实现了州前的性能，并且可以实现高品质的3D鸟类重建。<details>
<summary>Abstract</summary>
In this paper, we propose a novel method for single-view 3D style transfer that generates a unique 3D object with both shape and texture transfer. Our focus lies primarily on birds, a popular subject in 3D reconstruction, for which no existing single-view 3D transfer methods have been developed.The method we propose seeks to generate a 3D mesh shape and texture of a bird from two single-view images. To achieve this, we introduce a novel shape transfer generator that comprises a dual residual gated network (DRGNet), and a multi-layer perceptron (MLP). DRGNet extracts the features of source and target images using a shared coordinate gate unit, while the MLP generates spatial coordinates for building a 3D mesh. We also introduce a semantic UV texture transfer module that implements textural style transfer using semantic UV segmentation, which ensures consistency in the semantic meaning of the transferred regions. This module can be widely adapted to many existing approaches. Finally, our method constructs a novel 3D bird using a differentiable renderer. Experimental results on the CUB dataset verify that our method achieves state-of-the-art performance on the single-view 3D style transfer task. Code is available in https://github.com/wrk226/creative_birds.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的单视图3D样式传输方法，该方法可以生成一个独特的3D对象，包括形状和Texture传输。我们主要关注鸟类，这是3D重建中非常流行的主题，现有的单视图3D传输方法尚未得到开发。我们的方法可以从两个单视图图像中生成一个鸟类3D网格形状和Texture。为达到这个目标，我们提出了一种新的形状传输生成器，它包括一个双重径脱敏网络（DRGNet）和一个多层权重网络（MLP）。DRGNet使用共享坐标门户单元提取源和目标图像的特征，而MLP生成3D网格的空间坐标。我们还提出了一种semantic UV文本传输模块，它通过semantic UV分割实现文本风格传输，以保证传输的区域具有相同的semantic意义。这个模块可以与许多现有方法结合使用。最后，我们的方法使用一个可导渠 Renderer构建一个新的3D鸟类。实验结果表明，我们的方法在单视图3D样式传输任务中达到了国际级的性能。代码可以在https://github.com/wrk226/creative_birds中找到。
</details></li>
</ul>
<hr>
<h2 id="Multi-modal-Learning-with-Missing-Modality-via-Shared-Specific-Feature-Modelling"><a href="#Multi-modal-Learning-with-Missing-Modality-via-Shared-Specific-Feature-Modelling" class="headerlink" title="Multi-modal Learning with Missing Modality via Shared-Specific Feature Modelling"></a>Multi-modal Learning with Missing Modality via Shared-Specific Feature Modelling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14126">http://arxiv.org/abs/2307.14126</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hu Wang, Yuanhong Chen, Congbo Ma, Jodie Avery, Louise Hull, Gustavo Carneiro</li>
<li>For: The paper is written to address the issue of missing modality in multi-modal tasks, and to propose a simpler and more effective method for handling this problem.* Methods: The proposed method, called Shared-Specific Feature Modelling (ShaSpec), uses auxiliary tasks based on distribution alignment and domain classification, as well as a residual feature fusion procedure, to learn shared and specific features from all available input modalities.* Results: The paper reports that ShaSpec outperforms competing methods by a large margin on both medical image segmentation and computer vision classification tasks, with improvements of more than 3% on BraTS2018 for enhancing tumour, 5% for tumour core, and 3% for whole tumour.Here is the same information in Simplified Chinese:* For: 这篇论文是为了解决多Modal任务中缺失Modal的问题而写的。* Methods: 提议的方法是Shared-Specific Feature Modelling（ShaSpec），它使用分布对齐和领域分类的auxiliary任务，以及剩余特征混合过程，来学习所有输入Modalities中的共享和特定特征。* Results: 论文报告说，ShaSpec比竞争方法更高效，在医学像分割和计算机视觉分类任务上都有显著提高（BraTS2018上的提升肿瘤3%，核心肿瘤5%，整个肿瘤3%）。<details>
<summary>Abstract</summary>
The missing modality issue is critical but non-trivial to be solved by multi-modal models. Current methods aiming to handle the missing modality problem in multi-modal tasks, either deal with missing modalities only during evaluation or train separate models to handle specific missing modality settings. In addition, these models are designed for specific tasks, so for example, classification models are not easily adapted to segmentation tasks and vice versa. In this paper, we propose the Shared-Specific Feature Modelling (ShaSpec) method that is considerably simpler and more effective than competing approaches that address the issues above. ShaSpec is designed to take advantage of all available input modalities during training and evaluation by learning shared and specific features to better represent the input data. This is achieved from a strategy that relies on auxiliary tasks based on distribution alignment and domain classification, in addition to a residual feature fusion procedure. Also, the design simplicity of ShaSpec enables its easy adaptation to multiple tasks, such as classification and segmentation. Experiments are conducted on both medical image segmentation and computer vision classification, with results indicating that ShaSpec outperforms competing methods by a large margin. For instance, on BraTS2018, ShaSpec improves the SOTA by more than 3% for enhancing tumour, 5% for tumour core and 3% for whole tumour.
</details>
<details>
<summary>摘要</summary>
《缺失Modalitate问题是多模态模型解决的核心问题，但它不是易于解决的。目前的方法在评估时或在训练时都只处理缺失的模态，或者通过训练不同的模型来处理特定的缺失模态情况。此外，这些模型是为特定任务设计的，因此例如分类模型不易于适应分割任务，而且反之亦然。本文提出了共享特定特征模型（ShaSpec）方法，它比竞争方法更简单而效果更好。ShaSpec在训练和评估过程中利用所有可用的输入模态，通过学习共享特征和特定特征来更好地表示输入数据。这是通过auxiliary任务基于分布对齐和领域分类，以及剩余特征 fusión过程来实现的。此外，ShaSpec的设计简单，可以方便地适应多个任务，如分类和分割。实验结果表明，ShaSpec在BraTS2018上比前一个SOTA提高了超过3%的恢复肿瘤、5%的肿瘤核心和3%的整体肿瘤。》
</details></li>
</ul>
<hr>
<h2 id="Memory-Efficient-Graph-Convolutional-Networks-for-Object-Classification-and-Detection-with-Event-Cameras"><a href="#Memory-Efficient-Graph-Convolutional-Networks-for-Object-Classification-and-Detection-with-Event-Cameras" class="headerlink" title="Memory-Efficient Graph Convolutional Networks for Object Classification and Detection with Event Cameras"></a>Memory-Efficient Graph Convolutional Networks for Object Classification and Detection with Event Cameras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14124">http://arxiv.org/abs/2307.14124</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kamil Jeziorek, Andrea Pinna, Tomasz Kryjak</li>
<li>for: 本研究旨在提高事件摄像头数据处理的效率和准确率，并且考虑了数据存储和计算成本。</li>
<li>methods: 本研究使用图 convolutional neural networks (GCNs) 进行事件数据分析，并对不同的图 convolution 操作进行比较分析，以选择最佳的操作。</li>
<li>results: 研究结果显示，使用提出的方法可以实现52.3%的分类精度，同时减少了特征提取模块中的参数数量450倍，并将数据表示形式的大小减少4.5倍。此外，对 N-Caltech101 数据集进行 object detection 预测，实现了53.7%的 <a href="mailto:&#109;&#65;&#x50;&#x40;&#x30;&#x2e;&#x35;">&#109;&#65;&#x50;&#x40;&#x30;&#x2e;&#x35;</a> 精度和82个图像每秒的执行速率。<details>
<summary>Abstract</summary>
Recent advances in event camera research emphasize processing data in its original sparse form, which allows the use of its unique features such as high temporal resolution, high dynamic range, low latency, and resistance to image blur. One promising approach for analyzing event data is through graph convolutional networks (GCNs). However, current research in this domain primarily focuses on optimizing computational costs, neglecting the associated memory costs. In this paper, we consider both factors together in order to achieve satisfying results and relatively low model complexity. For this purpose, we performed a comparative analysis of different graph convolution operations, considering factors such as execution time, the number of trainable model parameters, data format requirements, and training outcomes. Our results show a 450-fold reduction in the number of parameters for the feature extraction module and a 4.5-fold reduction in the size of the data representation while maintaining a classification accuracy of 52.3%, which is 6.3% higher compared to the operation used in state-of-the-art approaches. To further evaluate performance, we implemented the object detection architecture and evaluated its performance on the N-Caltech101 dataset. The results showed an accuracy of 53.7 % mAP@0.5 and reached an execution rate of 82 graphs per second.
</details>
<details>
<summary>摘要</summary>
最近的事件摄像头研究发展强调处理原始稀疏数据，这使得可以利用高时间分辨率、高动态范围、低延迟和图像模糊鲁棒性的独特特点。一种有前途的方法是使用图像会议网络（GCN）来分析事件数据。然而，当前研究主要关注计算成本优化，忽略了相关的内存成本。在这篇论文中，我们同时考虑这两个因素，以达到满意的结果和相对较低的模型复杂度。为此，我们进行了不同图像会议操作的比较分析，考虑因素包括执行时间、可训练模型参数数量、数据格式要求和训练结果。我们的结果显示了特征提取模块中参数数量的450倍减少和数据表示形式的4.5倍减小，同时保持52.3%的分类精度，与现有方法相比增加6.3%。为了进一步评估性能，我们实现了对象检测架构并在N-Caltech101数据集上评估其性能。结果显示了53.7%的mAP@0.5精度和82个图像每秒执行速度。
</details></li>
</ul>
<hr>
<h2 id="Periocular-biometrics-databases-algorithms-and-directions"><a href="#Periocular-biometrics-databases-algorithms-and-directions" class="headerlink" title="Periocular biometrics: databases, algorithms and directions"></a>Periocular biometrics: databases, algorithms and directions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14111">http://arxiv.org/abs/2307.14111</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fernando Alonso-Fernandez, Josef Bigun</li>
<li>for: 本文是一篇对 périocular 生物认证研究进行的综述，提供了现有Literature的概述和主要问题的探讨，以及未来研究趋势的简要介绍。</li>
<li>methods: 本文使用的方法包括 periocular 特征提取和gender和ethnicity分类等，以及对不同 gender 和ethnicity的认证性能的研究。</li>
<li>results: 本文 Summarizes the state of the art in periocular biometric research, including the most relevant issues and a thorough coverage of the existing literature.<details>
<summary>Abstract</summary>
Periocular biometrics has been established as an independent modality due to concerns on the performance of iris or face systems in uncontrolled conditions. Periocular refers to the facial region in the eye vicinity, including eyelids, lashes and eyebrows. It is available over a wide range of acquisition distances, representing a trade-off between the whole face (which can be occluded at close distances) and the iris texture (which do not have enough resolution at long distances). Since the periocular region appears in face or iris images, it can be used also in conjunction with these modalities. Features extracted from the periocular region have been also used successfully for gender classification and ethnicity classification, and to study the impact of gender transformation or plastic surgery in the recognition performance. This paper presents a review of the state of the art in periocular biometric research, providing an insight of the most relevant issues and giving a thorough coverage of the existing literature. Future research trends are also briefly discussed.
</details>
<details>
<summary>摘要</summary>
périocular 生物ometrics 已经被确立为一种独立的modalità，因为关注肉眼或面系统在无控制的环境下表现不佳。periocular 指的是眼睛附近的脸部区域，包括眼皮、毛发和眉毛。它可以在各种距离范围内获得，表示一种质量和距离之间的交易，而整个脸部（可能会被 occluded 在近距离）和眼球 тексту（没有 enough resolution 在远距离）。由于 periocular 区域出现在脸部或眼球图像中，因此也可以与这些modalities 结合使用。从 periocular 区域提取的特征已经成功地用于性别类型和种族类型的分类，以及研究 gender transformation 或整形手术对认知性能的影响。这篇文章介绍了 periocular 生物metric 研究的现状，提供了有关最重要的问题和现有文献的全面概述，以及未来研究趋势的简要讨论。
</details></li>
</ul>
<hr>
<h2 id="VideoControlNet-A-Motion-Guided-Video-to-Video-Translation-Framework-by-Using-Diffusion-Model-with-ControlNet"><a href="#VideoControlNet-A-Motion-Guided-Video-to-Video-Translation-Framework-by-Using-Diffusion-Model-with-ControlNet" class="headerlink" title="VideoControlNet: A Motion-Guided Video-to-Video Translation Framework by Using Diffusion Model with ControlNet"></a>VideoControlNet: A Motion-Guided Video-to-Video Translation Framework by Using Diffusion Model with ControlNet</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14073">http://arxiv.org/abs/2307.14073</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ZhihaoHu/VideoControlNet">https://github.com/ZhihaoHu/VideoControlNet</a></li>
<li>paper_authors: Zhihao Hu, Dong Xu</li>
<li>for: 本研究 propose a new motion-guided video-to-video translation framework called VideoControlNet, which can generate various videos based on given prompts and condition from the input video.</li>
<li>methods: 我们使用 diffusion model with ControlNet 和 motion-guided P-frame generation (MgPG) method, 以及 motion-guided B-frame interpolation (MgBI) module to generate videos.</li>
<li>results: 我们的 эксперименты表明，VideoControlNet 继承了预训练的大型扩散模型的生成能力，并将图像扩散模型扩展到视频扩散模型。更多结果请参考我们项目页面。<details>
<summary>Abstract</summary>
Recently, diffusion models like StableDiffusion have achieved impressive image generation results. However, the generation process of such diffusion models is uncontrollable, which makes it hard to generate videos with continuous and consistent content. In this work, by using the diffusion model with ControlNet, we proposed a new motion-guided video-to-video translation framework called VideoControlNet to generate various videos based on the given prompts and the condition from the input video. Inspired by the video codecs that use motion information for reducing temporal redundancy, our framework uses motion information to prevent the regeneration of the redundant areas for content consistency. Specifically, we generate the first frame (i.e., the I-frame) by using the diffusion model with ControlNet. Then we generate other key frames (i.e., the P-frame) based on the previous I/P-frame by using our newly proposed motion-guided P-frame generation (MgPG) method, in which the P-frames are generated based on the motion information and the occlusion areas are inpainted by using the diffusion model. Finally, the rest frames (i.e., the B-frame) are generated by using our motion-guided B-frame interpolation (MgBI) module. Our experiments demonstrate that our proposed VideoControlNet inherits the generation capability of the pre-trained large diffusion model and extends the image diffusion model to the video diffusion model by using motion information. More results are provided at our project page.
</details>
<details>
<summary>摘要</summary>
近些年，扩散模型如StableDiffusion在图像生成方面取得了卓越的成绩。然而，扩散模型的生成过程不可控，这使得生成视频时难以保持内容连续和一致。在这项工作中，我们通过将扩散模型与ControlNet结合使用，提出了一种基于提示和输入视频的动作指导的视频到视频翻译框架——VideoControlNet。我们受到视频编码器使用运动信息减少 temporal 重复的启发，我们的框架使用运动信息来避免重新生成冗余区域以保持内容一致。具体来说，我们使用扩散模型与ControlNet生成首帧（i.e., I-frame），然后使用我们新提出的运动指导 P-frame 生成方法（MgPG）生成后续的其他关键帧（i.e., P-frame），并使用扩散模型填充 occlusion 区域。最后，我们使用我们的运动指导 B-frame  interpolate 模块（MgBI）生成剩余帧（i.e., B-frame）。我们的实验表明，我们提posed VideoControlNet 继承了预训练的大扩散模型的生成能力，并将图像扩散模型扩展到视频扩散模型，并且使用运动信息。更多结果请参考我们项目页面。
</details></li>
</ul>
<hr>
<h2 id="PNT-Edge-Towards-Robust-Edge-Detection-with-Noisy-Labels-by-Learning-Pixel-level-Noise-Transitions"><a href="#PNT-Edge-Towards-Robust-Edge-Detection-with-Noisy-Labels-by-Learning-Pixel-level-Noise-Transitions" class="headerlink" title="PNT-Edge: Towards Robust Edge Detection with Noisy Labels by Learning Pixel-level Noise Transitions"></a>PNT-Edge: Towards Robust Edge Detection with Noisy Labels by Learning Pixel-level Noise Transitions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14070">http://arxiv.org/abs/2307.14070</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenjie Xuan, Shanshan Zhao, Yu Yao, Juhua Liu, Tongliang Liu, Yixin Chen, Bo Du, Dacheng Tao</li>
<li>for: 这篇论文是为了解决标签损害问题，尤其是在大规模训练数据中，以提高边测出的性能。</li>
<li>methods: 这篇论文提出了一种Pixel-level NoiseTransitions（PNT）模型，通过估计标签损害的过程来解决标签损害问题。PNT模型包括Pixel-wise Shift Learning（PSL）模块，可以估计标签损害的转换场。</li>
<li>results: 实验结果显示，PNT模型能够有效地减轻标签损害的影响，并且可以保持边测出的高性能。<details>
<summary>Abstract</summary>
Relying on large-scale training data with pixel-level labels, previous edge detection methods have achieved high performance. However, it is hard to manually label edges accurately, especially for large datasets, and thus the datasets inevitably contain noisy labels. This label-noise issue has been studied extensively for classification, while still remaining under-explored for edge detection. To address the label-noise issue for edge detection, this paper proposes to learn Pixel-level NoiseTransitions to model the label-corruption process. To achieve it, we develop a novel Pixel-wise Shift Learning (PSL) module to estimate the transition from clean to noisy labels as a displacement field. Exploiting the estimated noise transitions, our model, named PNT-Edge, is able to fit the prediction to clean labels. In addition, a local edge density regularization term is devised to exploit local structure information for better transition learning. This term encourages learning large shifts for the edges with complex local structures. Experiments on SBD and Cityscapes demonstrate the effectiveness of our method in relieving the impact of label noise. Codes will be available at github.
</details>
<details>
<summary>摘要</summary>
以前的边检测方法通过大规模的训练数据和像素级标注来实现高性能。然而，手动标注边界尚很困难，特别是 для大量数据集，因此标注中存在噪声。这个噪声问题在分类领域已经得到了广泛的研究，而在边检测领域仍然尚未得到充分的研究。为了解决边检测中的噪声问题，本文提出了学习像素级噪声转移（Pixel-level NoiseTransitions，PNT）来模型标签损害过程。为此，我们开发了一种名为像素级Shift学习（Pixel-wise Shift Learning，PSL）模块，以便估计从清晰标签到噪声标签的转移为一个拟合场景。通过利用估计的噪声转移，我们的模型可以适应清晰标签。此外，我们还提出了一种基于地方检测结构信息的本地检测密度规则，以便更好地学习转移。这个规则鼓励学习大尺度的转移，以便处理复杂的地方结构。实验表明，我们的方法可以减轻标签噪声的影响。代码将提供在GitHub上。
</details></li>
</ul>
<hr>
<h2 id="Pre-Training-with-Diffusion-models-for-Dental-Radiography-segmentation"><a href="#Pre-Training-with-Diffusion-models-for-Dental-Radiography-segmentation" class="headerlink" title="Pre-Training with Diffusion models for Dental Radiography segmentation"></a>Pre-Training with Diffusion models for Dental Radiography segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14066">http://arxiv.org/abs/2307.14066</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jérémy Rousseau, Christian Alaka, Emma Covili, Hippolyte Mayard, Laura Misrachi, Willy Au</li>
<li>for: 针对医疗放射学像 segmentation task, specifically dental radiography, which is limited by the high cost of labeling.</li>
<li>methods: 提出了一种简单的预训练方法，使用 Denoising Diffusion Probabilistic Models (DDPM) 进行 semantic segmentation.</li>
<li>results: 实验结果表明，该方法可以 achieve remarkable performance in terms of label efficiency, without requiring architectural modifications between pre-training and downstream tasks.<details>
<summary>Abstract</summary>
Medical radiography segmentation, and specifically dental radiography, is highly limited by the cost of labeling which requires specific expertise and labor-intensive annotations. In this work, we propose a straightforward pre-training method for semantic segmentation leveraging Denoising Diffusion Probabilistic Models (DDPM), which have shown impressive results for generative modeling. Our straightforward approach achieves remarkable performance in terms of label efficiency and does not require architectural modifications between pre-training and downstream tasks. We propose to first pre-train a Unet by exploiting the DDPM training objective, and then fine-tune the resulting model on a segmentation task. Our experimental results on the segmentation of dental radiographs demonstrate that the proposed method is competitive with state-of-the-art pre-training methods.
</details>
<details>
<summary>摘要</summary>
医疗放射segmentation，特别是牙科放射segmentation，受到标注成本的限制，需要专业知识和劳动密集的标注。在这个工作中，我们提议一种简单的预训练方法 для语义分割，利用Diffusion Probabilistic Models（DDPM），这种模型已经在生成模型中表现出色。我们的简单方法可以达到remarkable的标签效率，不需要预训练和下游任务之间的建筑修改。我们首先预训练了Unet使用DDPM训练目标，然后细化该模型以进行分割任务。我们的实验结果表明，我们提议的方法可以与现有的预训练方法竞争。
</details></li>
</ul>
<hr>
<h2 id="ECO-Ensembling-Context-Optimization-for-Vision-Language-Models"><a href="#ECO-Ensembling-Context-Optimization-for-Vision-Language-Models" class="headerlink" title="ECO: Ensembling Context Optimization for Vision-Language Models"></a>ECO: Ensembling Context Optimization for Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14063">http://arxiv.org/abs/2307.14063</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lorenzo Agnolucci, Alberto Baldrati, Francesco Todino, Federico Becattini, Marco Bertini, Alberto Del Bimbo</li>
<li>for: 这篇论文主要是为了研究如何使用文本提示来进行图像分类，并使用 CLIP 模型实现零 shot 转换。</li>
<li>methods: 该论文使用了一种 ensemble 方法，通过学习多个文本提示来提高图像分类的性能。</li>
<li>results: 研究发现，使用多个文本提示可以提高图像分类的性能，而且不需要在执行时添加额外成本。 并且在 11 个 benchmark 上进行了证明。<details>
<summary>Abstract</summary>
Image recognition has recently witnessed a paradigm shift, where vision-language models are now used to perform few-shot classification based on textual prompts. Among these, the CLIP model has shown remarkable capabilities for zero-shot transfer by matching an image and a custom textual prompt in its latent space. This has paved the way for several works that focus on engineering or learning textual contexts for maximizing CLIP's classification capabilities. In this paper, we follow this trend by learning an ensemble of prompts for image classification. We show that learning diverse and possibly shorter contexts improves considerably and consistently the results rather than relying on a single trainable prompt. In particular, we report better few-shot capabilities with no additional cost at inference time. We demonstrate the capabilities of our approach on 11 different benchmarks.
</details>
<details>
<summary>摘要</summary>
Image recognition 近期经历了一种新的思维方式，使用视力语言模型来实现几个步骤分类基于文本提示。其中，CLIP 模型表现出了很好的零shot 转移能力，可以通过匹配图像和自定义文本提示在其 latent space 进行匹配。这有助于许多工作，旨在改进或学习图像提示的文本上。在这篇论文中，我们遵循这种趋势，学习一个图像分类的 ensemble 提示。我们发现，学习多样的和可能更短的文本上下文可以大幅提高结果，而不需要在执行时添加额外成本。我们在 11 个标准测试集上进行了证明。
</details></li>
</ul>
<hr>
<h2 id="Set-level-Guidance-Attack-Boosting-Adversarial-Transferability-of-Vision-Language-Pre-training-Models"><a href="#Set-level-Guidance-Attack-Boosting-Adversarial-Transferability-of-Vision-Language-Pre-training-Models" class="headerlink" title="Set-level Guidance Attack: Boosting Adversarial Transferability of Vision-Language Pre-training Models"></a>Set-level Guidance Attack: Boosting Adversarial Transferability of Vision-Language Pre-training Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14061">http://arxiv.org/abs/2307.14061</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Zoky-2020/Set-level_Guidance_Attack">https://github.com/Zoky-2020/Set-level_Guidance_Attack</a></li>
<li>paper_authors: Dong Lu, Zhiqiang Wang, Teng Wang, Weili Guan, Hongchang Gao, Feng Zheng</li>
<li>for: 本研究是 investigate the adversarial transferability of recent VLP models.</li>
<li>methods: 我们提出了一种高度可转移的 Set-level Guidance Attack (SGA)，它充分利用了modal interactions和cross-modal guidance，并包括了alignment-preserving augmentation.</li>
<li>results: SGA可以生成高度可转移的 adversarial examples，可以强制 transferred across different VLP models on multiple downstream vision-language tasks. 例如，在图像文本检索 task 上，SGA可以significantly enhance the attack success rate for transfer attacks from ALBEF to TCL，比对 estado-of-the-art 高得多 (at least 9.78% and up to 30.21%).<details>
<summary>Abstract</summary>
Vision-language pre-training (VLP) models have shown vulnerability to adversarial examples in multimodal tasks. Furthermore, malicious adversaries can be deliberately transferred to attack other black-box models. However, existing work has mainly focused on investigating white-box attacks. In this paper, we present the first study to investigate the adversarial transferability of recent VLP models. We observe that existing methods exhibit much lower transferability, compared to the strong attack performance in white-box settings. The transferability degradation is partly caused by the under-utilization of cross-modal interactions. Particularly, unlike unimodal learning, VLP models rely heavily on cross-modal interactions and the multimodal alignments are many-to-many, e.g., an image can be described in various natural languages. To this end, we propose a highly transferable Set-level Guidance Attack (SGA) that thoroughly leverages modality interactions and incorporates alignment-preserving augmentation with cross-modal guidance. Experimental results demonstrate that SGA could generate adversarial examples that can strongly transfer across different VLP models on multiple downstream vision-language tasks. On image-text retrieval, SGA significantly enhances the attack success rate for transfer attacks from ALBEF to TCL by a large margin (at least 9.78% and up to 30.21%), compared to the state-of-the-art.
</details>
<details>
<summary>摘要</summary>
“视觉语言预训（VLP）模型在多modal任务中显示易受到恶意攻击。此外，恶意攻击者可以故意传播到攻击其他黑盒模型。然而，现有的工作主要集中在白盒攻击。在这篇论文中，我们提出了第一个研究视觉语言预训模型的攻击传播性的研究。我们发现，现有的方法在白盒 Setting下的攻击性表现强，而在黑盒 Setting下的传播性较弱。这种传播性减退部分由于视觉语言模型在模式之间的交互不充分利用。特别是，不同于单模型学习，VLP模型依赖于模式之间的交互，并且多模式对应关系是多对多的，例如一个图像可以被多种自然语言描述。为此，我们提出了高度传播的集成指导攻击（SGA），它仔细利用了模式交互和具有对应增强的扩展。实验结果表明，SGA可以在多个下游视觉语言任务上生成强制转移的攻击例子，并且在图像文本检索任务上明显提高了传播攻击的成功率（至少9.78%和30.21%），相比之下前 estado-of-the-art。”
</details></li>
</ul>
<hr>
<h2 id="Towards-Establishing-Systematic-Classification-Requirements-for-Automated-Driving"><a href="#Towards-Establishing-Systematic-Classification-Requirements-for-Automated-Driving" class="headerlink" title="Towards Establishing Systematic Classification Requirements for Automated Driving"></a>Towards Establishing Systematic Classification Requirements for Automated Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14058">http://arxiv.org/abs/2307.14058</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ken T. Mori, Trent Brown, Steven Peters</li>
<li>for: 这篇论文是为了定义一种适用于自动驾驶领域的一致的分类要求的方法。</li>
<li>methods: 该方法首先从行为需求角度标识了法律类别，然后考虑了对象和感知类别的两个方面，从而获得了一个分类层次结构。</li>
<li>results: 应用该方法于一个示例法律文本后，与标准数据集类别相比，两者之间存在有限的一致，这表明需要显式考虑法律需求关于感知。<details>
<summary>Abstract</summary>
Despite the presence of the classification task in many different benchmark datasets for perception in the automotive domain, few efforts have been undertaken to define consistent classification requirements. This work addresses the topic by proposing a structured method to generate a classification structure. First, legal categories are identified based on behavioral requirements for the vehicle. This structure is further substantiated by considering the two aspects of collision safety for objects as well as perceptual categories. A classification hierarchy is obtained by applying the method to an exemplary legal text. A comparison of the results with benchmark dataset categories shows limited agreement. This indicates the necessity for explicit consideration of legal requirements regarding perception.
</details>
<details>
<summary>摘要</summary>
即使在自动驾驶领域的识别任务中存在多种benchmark数据集，但很少有努力来定义一致的分类要求。这项工作强调这一点，并提出了一种结构化的方法来生成分类结构。首先，我们根据车辆的行为要求来确定法律类别。然后，我们根据对象避免碰撞安全和感知类别来进一步补充这种结构。通过应用这种方法，我们得到了一个分类层次结构。对比 benchmark数据集类别，我们发现了有限的一致。这表明了法律要求的明确考虑是必要的。
</details></li>
</ul>
<hr>
<h2 id="Unite-Divide-Unite-Joint-Boosting-Trunk-and-Structure-for-High-accuracy-Dichotomous-Image-Segmentation"><a href="#Unite-Divide-Unite-Joint-Boosting-Trunk-and-Structure-for-High-accuracy-Dichotomous-Image-Segmentation" class="headerlink" title="Unite-Divide-Unite: Joint Boosting Trunk and Structure for High-accuracy Dichotomous Image Segmentation"></a>Unite-Divide-Unite: Joint Boosting Trunk and Structure for High-accuracy Dichotomous Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14052">http://arxiv.org/abs/2307.14052</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pjlallen/udun">https://github.com/pjlallen/udun</a></li>
<li>paper_authors: Jialun Pei, Zhangjun Zhou, Yueming Jin, He Tang, Pheng-Ann Heng</li>
<li>for: 高精度二分图像分割（DIS）目标是从自然场景中找到类型不同的前景对象。</li>
<li>methods: 我们提出了一种新的 Unit-Divide-Unite 网络（UDUN），它通过重新安排和分割补做特征来同时提高轮廓和结构的识别效果。</li>
<li>results: UDUN 在六个评估指标中所有取得了比领先者更高的成绩，并在 1024*1024 输入下实现了实时推理，并且可以在 65.3 fps 上进行推理。<details>
<summary>Abstract</summary>
High-accuracy Dichotomous Image Segmentation (DIS) aims to pinpoint category-agnostic foreground objects from natural scenes. The main challenge for DIS involves identifying the highly accurate dominant area while rendering detailed object structure. However, directly using a general encoder-decoder architecture may result in an oversupply of high-level features and neglect the shallow spatial information necessary for partitioning meticulous structures. To fill this gap, we introduce a novel Unite-Divide-Unite Network (UDUN} that restructures and bipartitely arranges complementary features to simultaneously boost the effectiveness of trunk and structure identification. The proposed UDUN proceeds from several strengths. First, a dual-size input feeds into the shared backbone to produce more holistic and detailed features while keeping the model lightweight. Second, a simple Divide-and-Conquer Module (DCM) is proposed to decouple multiscale low- and high-level features into our structure decoder and trunk decoder to obtain structure and trunk information respectively. Moreover, we design a Trunk-Structure Aggregation module (TSA) in our union decoder that performs cascade integration for uniform high-accuracy segmentation. As a result, UDUN performs favorably against state-of-the-art competitors in all six evaluation metrics on overall DIS-TE, i.e., achieving 0.772 weighted F-measure and 977 HCE. Using 1024*1024 input, our model enables real-time inference at 65.3 fps with ResNet-18.
</details>
<details>
<summary>摘要</summary>
高精度二分图像分割（DIS）目标是从自然场景中找到不受类别限制的前景对象。主要挑战在DIS中是准确地确定高级特征区域，而不是仅仅是提供高级特征。直接使用通用的编码器-解码器架构可能会导致过度产生高级特征，而忽略细致的空间信息，这会导致精细结构的识别受到威胁。为了填补这一漏洞，我们提出了一种新的团结分解网络（UDUN）。UDUN通过重新排序和分割相 complementary 的特征，以同时提高核心区域和细致结构的识别效果。UDUN的主要优势包括：一、使用双Size输入，通过共享背bone生成更加整体和细致的特征，同时保持模型轻量级。二、提出了简单的分割和聚合模块（DCM），将多尺度低级和高级特征分割到我们的结构解码器和核心解码器中，以获得结构信息和核心信息。此外，我们还设计了团结聚合模块（TSA），通过顺序集成来实现高精度分割。因此，UDUN在所有六个评价指标中表现出色，在DIS-TE上 achieved 0.772 weighted F-measure和977 HCE。使用1024*1024输入，我们的模型在65.3 fps上实现了实时推理，并且使用ResNet-18。
</details></li>
</ul>
<hr>
<h2 id="3D-Semantic-Subspace-Traverser-Empowering-3D-Generative-Model-with-Shape-Editing-Capability"><a href="#3D-Semantic-Subspace-Traverser-Empowering-3D-Generative-Model-with-Shape-Editing-Capability" class="headerlink" title="3D Semantic Subspace Traverser: Empowering 3D Generative Model with Shape Editing Capability"></a>3D Semantic Subspace Traverser: Empowering 3D Generative Model with Shape Editing Capability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14051">http://arxiv.org/abs/2307.14051</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/TrepangCat/3D_Semantic_Subspace_Traverser">https://github.com/TrepangCat/3D_Semantic_Subspace_Traverser</a></li>
<li>paper_authors: Ruowei Wang, Yu Liu, Pei Su, Jianwei Zhang, Qijun Zhao</li>
<li>for: 本研究旨在提供一种基于semantic attribute的3D形状生成模型，以便在3D内容创建中保持形状结构的semantic consistency和提供形状结构的semantic特性编辑功能。</li>
<li>methods: 该模型使用implicit函数来表示3D形状，并结合一种novel的latent-space GAN和一个线性子空间模型，以探索3D形状的本地latent空间中的semantic维度。每个维度对应一个特定的semantic特性，可以通过 traverse这些维度的系数来编辑生成的形状的semantic特性。</li>
<li>results: 实验结果表明，该方法可以生成具有复杂结构的plausible形状，并提供形状结构的semantic特性编辑功能。代码和训练模型可以在<a target="_blank" rel="noopener" href="https://github.com/TrepangCat/3D_Semantic_Subspace_Traverser%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/TrepangCat/3D_Semantic_Subspace_Traverser上获取。</a><details>
<summary>Abstract</summary>
Shape generation is the practice of producing 3D shapes as various representations for 3D content creation. Previous studies on 3D shape generation have focused on shape quality and structure, without or less considering the importance of semantic information. Consequently, such generative models often fail to preserve the semantic consistency of shape structure or enable manipulation of the semantic attributes of shapes during generation. In this paper, we proposed a novel semantic generative model named 3D Semantic Subspace Traverser that utilizes semantic attributes for category-specific 3D shape generation and editing. Our method utilizes implicit functions as the 3D shape representation and combines a novel latent-space GAN with a linear subspace model to discover semantic dimensions in the local latent space of 3D shapes. Each dimension of the subspace corresponds to a particular semantic attribute, and we can edit the attributes of generated shapes by traversing the coefficients of those dimensions. Experimental results demonstrate that our method can produce plausible shapes with complex structures and enable the editing of semantic attributes. The code and trained models are available at https://github.com/TrepangCat/3D_Semantic_Subspace_Traverser
</details>
<details>
<summary>摘要</summary>
三维形状生成是三维内容创建中的一种实践，旨在生成具有不同表示形式的三维形状。在先前的研究中，大多数研究者对三维形状生成的焦点是形状质量和结构，而忽略或少考虑semantic信息的重要性。这导致生成的模型往往无法保持形状结构的semantic一致性，也无法在生成过程中修改形状的semantic特征。在本文中，我们提出了一种新的semantic生成模型，名为3Dsemantic Subspace Traverser（3DSS）。该模型利用形状的semantic特征来为不同类别的三维形状进行生成和编辑。我们使用隐函数作为三维形状的表示方式，并结合了一种novel的latent-space GAN和一个线性子空间模型来发现三维形状的semantic维度。每个维度对应一个特定的semantic特征，可以在生成过程中编辑形状的semantic特征。实验结果表明，我们的方法可以生成具有复杂结构的plausible形状，并允许在生成过程中修改形状的semantic特征。代码和训练模型可以在https://github.com/TrepangCat/3D_Semantic_Subspace_Traverser上下载。
</details></li>
</ul>
<hr>
<h2 id="Controllable-Guide-Space-for-Generalizable-Face-Forgery-Detection"><a href="#Controllable-Guide-Space-for-Generalizable-Face-Forgery-Detection" class="headerlink" title="Controllable Guide-Space for Generalizable Face Forgery Detection"></a>Controllable Guide-Space for Generalizable Face Forgery Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14039">http://arxiv.org/abs/2307.14039</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ying Guo, Cheng Zhen, Pengfei Yan</li>
<li>for: 提高面伪检测的普遍化能力</li>
<li>methods: 提出控制可能空间（GS）方法，以增强伪造领域特征的分类，并使真伪造领域之间的距离变得更加明显。另外，使用解联模组削弱伪造 irrelevant 跟踪的影响，并根据邻近领域特征的聚类度进行决策面的调整。</li>
<li>results: 经过广泛的实验显示，我们的方法可以在多个内部和交叉领域的设定下实现顶尖的普遍化性。<details>
<summary>Abstract</summary>
Recent studies on face forgery detection have shown satisfactory performance for methods involved in training datasets, but are not ideal enough for unknown domains. This motivates many works to improve the generalization, but forgery-irrelevant information, such as image background and identity, still exists in different domain features and causes unexpected clustering, limiting the generalization. In this paper, we propose a controllable guide-space (GS) method to enhance the discrimination of different forgery domains, so as to increase the forgery relevance of features and thereby improve the generalization. The well-designed guide-space can simultaneously achieve both the proper separation of forgery domains and the large distance between real-forgery domains in an explicit and controllable manner. Moreover, for better discrimination, we use a decoupling module to weaken the interference of forgery-irrelevant correlations between domains. Furthermore, we make adjustments to the decision boundary manifold according to the clustering degree of the same domain features within the neighborhood. Extensive experiments in multiple in-domain and cross-domain settings confirm that our method can achieve state-of-the-art generalization.
</details>
<details>
<summary>摘要</summary>
最近的面孔伪造检测研究表现良好在培训集上，但在未知领域中表现不够 Ideal。这种情况 Motivates 许多研究者增强泛化性，但伪造 irrelevant information，如图像背景和身份，仍然存在不同领域特征中，导致意外的凝集，限制了泛化。在这篇论文中，我们提出一种可控制的引导空间（GS）方法，以提高伪造领域特征的分化程度，从而提高伪造相关性。well-designed引导空间可同时实现各伪造领域的正确分离和真伪造领域之间的大距离。此外，为了提高分化度，我们使用一个解除相关性模块，以减少不同领域特征之间的干扰。此外，我们根据邻域中同一个领域特征的凝集度进行决策边缘 manifold 的调整。广泛的实验表明，我们的方法可以 achieve state-of-the-art 泛化性。
</details></li>
</ul>
<hr>
<h2 id="Human-centric-Scene-Understanding-for-3D-Large-scale-Scenarios"><a href="#Human-centric-Scene-Understanding-for-3D-Large-scale-Scenarios" class="headerlink" title="Human-centric Scene Understanding for 3D Large-scale Scenarios"></a>Human-centric Scene Understanding for 3D Large-scale Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14392">http://arxiv.org/abs/2307.14392</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/4dvlab/hucenlife">https://github.com/4dvlab/hucenlife</a></li>
<li>paper_authors: Yiteng Xu, Peishan Cong, Yichen Yao, Runnan Chen, Yuenan Hou, Xinge Zhu, Xuming He, Jingyi Yu, Yuexin Ma</li>
<li>for: 本研究旨在提供一个大规模多Modal的人Centric场景理解 dataset，以便提高3D感知技术的性能。</li>
<li>methods: 本研究使用了多种方法，包括 LiDAR 技术和多Modal 捕获。</li>
<li>results: 本研究实现了state-of-the-art性能在人Centric场景理解任务中，并提供了多种 benchmark  для相关研究。Here’s a breakdown of each point:</li>
<li>for: The paper is aimed at providing a large-scale multi-modal dataset for human-centric scene understanding, in order to improve the performance of 3D perception technologies.</li>
<li>methods: The paper uses various methods, including LiDAR technology and multi-modal capturing.</li>
<li>results: The paper achieves state-of-the-art performance in human-centric scene understanding tasks, and provides multiple benchmarks for related research.<details>
<summary>Abstract</summary>
Human-centric scene understanding is significant for real-world applications, but it is extremely challenging due to the existence of diverse human poses and actions, complex human-environment interactions, severe occlusions in crowds, etc. In this paper, we present a large-scale multi-modal dataset for human-centric scene understanding, dubbed HuCenLife, which is collected in diverse daily-life scenarios with rich and fine-grained annotations. Our HuCenLife can benefit many 3D perception tasks, such as segmentation, detection, action recognition, etc., and we also provide benchmarks for these tasks to facilitate related research. In addition, we design novel modules for LiDAR-based segmentation and action recognition, which are more applicable for large-scale human-centric scenarios and achieve state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
人Centric场景理解对实际应用有着重要意义，但是它受到人姿态和行为多样化、人环境交互复杂、群体干扰等因素的影响很大。在这篇论文中，我们提供了一个大规模多模态场景理解数据集，名为HuCenLife，该数据集在日常生活场景中收集了丰富细化的注释。我们的HuCenLife可以帮助多种3D感知任务，如分割、检测、动作识别等，并为这些任务提供了参考。此外，我们还设计了基于LiDAR的分割和动作识别模块，这些模块更适合大规模人Centric场景，并实现了当前最佳性能。
</details></li>
</ul>
<hr>
<h2 id="Consensus-Adaptive-RANSAC"><a href="#Consensus-Adaptive-RANSAC" class="headerlink" title="Consensus-Adaptive RANSAC"></a>Consensus-Adaptive RANSAC</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14030">http://arxiv.org/abs/2307.14030</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cavalli1234/ca-ransac">https://github.com/cavalli1234/ca-ransac</a></li>
<li>paper_authors: Luca Cavalli, Daniel Barath, Marc Pollefeys, Viktor Larsson</li>
<li>for: 提高 robust estimation 精度，使 RANSAC 能够更好地适应不同 dataset 和任务。</li>
<li>methods: 基于 attention 层和一步 transformer，使 RANSAC 可以更好地探索参数空间，并且可以适应不同的 residuals 情况。</li>
<li>results: 对比 state-of-the-art 估计器，提出的方法具有较高的精度和更好的一致性，并且增加了只有小致用时间 overhead。<details>
<summary>Abstract</summary>
RANSAC and its variants are widely used for robust estimation, however, they commonly follow a greedy approach to finding the highest scoring model while ignoring other model hypotheses. In contrast, Iteratively Reweighted Least Squares (IRLS) techniques gradually approach the model by iteratively updating the weight of each correspondence based on the residuals from previous iterations. Inspired by these methods, we propose a new RANSAC framework that learns to explore the parameter space by considering the residuals seen so far via a novel attention layer. The attention mechanism operates on a batch of point-to-model residuals, and updates a per-point estimation state to take into account the consensus found through a lightweight one-step transformer. This rich state then guides the minimal sampling between iterations as well as the model refinement. We evaluate the proposed approach on essential and fundamental matrix estimation on a number of indoor and outdoor datasets. It outperforms state-of-the-art estimators by a significant margin adding only a small runtime overhead. Moreover, we demonstrate good generalization properties of our trained model, indicating its effectiveness across different datasets and tasks. The proposed attention mechanism and one-step transformer provide an adaptive behavior that enhances the performance of RANSAC, making it a more effective tool for robust estimation. Code is available at https://github.com/cavalli1234/CA-RANSAC.
</details>
<details>
<summary>摘要</summary>
RANSAC和其 variants 广泛用于robust estimation，然而它们通常采用一种滥货的方法来找到最高分数模型，而忽略其他模型假设。相反，Iteratively Reweighted Least Squares (IRLS) 技术逐渐接近模型，通过在前一轮的 residuals 基础上更新每个匹配的权重。受到这些方法的启发，我们提出了一个新的 RANSAC 框架，通过一个新的注意层来探索参数空间。这个注意层在一批点到模型的 residuals 上运行，并将每个点的估计状态更新，以考虑前一轮的consensus。这个 ricstate 然后导引最小抽样和模型精度的改进。我们对几个indoor和outdoor数据集进行评估，并证明了我们的方法超过了当前的状态艺术家，并且具有良好的泛化性。这些注意层和一步transformer 提供了一种适应性，使RANSAC成为更有效的robust estimation工具。代码可以在 <https://github.com/cavalli1234/CA-RANSAC> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Topologically-Regularized-Multiple-Instance-Learning-for-Red-Blood-Cell-Disease-Classification"><a href="#Topologically-Regularized-Multiple-Instance-Learning-for-Red-Blood-Cell-Disease-Classification" class="headerlink" title="Topologically-Regularized Multiple Instance Learning for Red Blood Cell Disease Classification"></a>Topologically-Regularized Multiple Instance Learning for Red Blood Cell Disease Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14025">http://arxiv.org/abs/2307.14025</a></li>
<li>repo_url: None</li>
<li>paper_authors: Salome Kazeminia, Ario Sadafi, Asya Makhro, Anna Bogdanova, Carsten Marr, Bastian Rieck</li>
<li>for: 该研究用于自动识别罕见血液疾病的单细胞图像。</li>
<li>methods: 该研究使用了一种基于 topology 的方法，从单细胞图像中提取多尺度 topological 特征，以规范模型，保持数据的特有 topological 特性。</li>
<li>results: 实验表明，使用 topological 规范可以提高自动识别罕见血液疾病的性能，相比传统的多例学习方法，该方法可以提高性能超过 3%。这是首个使用 topological 性质来规范 MIL 过程的方法。<details>
<summary>Abstract</summary>
Diagnosing rare anemia disorders using microscopic images is challenging for skilled specialists and machine-learning methods alike. Due to thousands of disease-relevant cells in a single blood sample, this constitutes a complex multiple-instance learning (MIL) problem. While the spatial neighborhood of red blood cells is not meaningful per se, the topology, i.e., the geometry of blood samples as a whole, contains informative features to remedy typical MIL issues, such as vanishing gradients and overfitting when training on limited data. We thus develop a topology-based approach that extracts multi-scale topological features from bags of single red blood cell images. The topological features are used to regularize the model, enforcing the preservation of characteristic topological properties of the data. Applied to a dataset of 71 patients suffering from rare anemia disorders with 521 microscopic images of red blood cells, our experiments show that topological regularization is an effective method that leads to more than 3% performance improvements for the automated classification of rare anemia disorders based on single-cell images. This is the first approach that uses topological properties for regularizing the MIL process.
</details>
<details>
<summary>摘要</summary>
诊断罕见血红细胞疾病使用微型图像是复杂的，专家和机器学习方法都面临挑战。由于每个血液样本中有数千个疾病相关的细胞，这构成了复杂的多例学习（MIL）问题。血红细胞的空间邻居不是直接意义的，但血液样本的整体几何结构含有有用的特征，以解决典型的MIL问题，如衰减梯度和预测过拟合。我们因此开发了基于topology的方法，EXTRACTING多尺度的topological特征 FROM single red blood cell images。这些特征用于规范模型，使模型保留特征数据的特有topological属性。应用于71名患有罕见血红细胞疾病的患者，521个微型血红细胞图像的实验显示， topological regularization 是一种有效的方法，可以提高基于单细胞图像的罕见血红细胞自动分类的性能，高于3%。这是首次使用topological属性来规范MIL过程的方法。
</details></li>
</ul>
<hr>
<h2 id="Retinotopy-Inspired-Brain-Encoding-Model-and-the-All-for-One-Training-Recipe"><a href="#Retinotopy-Inspired-Brain-Encoding-Model-and-the-All-for-One-Training-Recipe" class="headerlink" title="Retinotopy Inspired Brain Encoding Model and the All-for-One Training Recipe"></a>Retinotopy Inspired Brain Encoding Model and the All-for-One Training Recipe</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14021">http://arxiv.org/abs/2307.14021</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huzheng Yang, Jianbo Shi, James Gee</li>
<li>for: 预测脑细胞响应图像刺激，实现脑信号捕捉技术的复制。</li>
<li>methods: 引入多种多样性优势，包括个体脑功能多样性、个体差异和成像模式差异，并通过分解大型模型问题而解决困难。</li>
<li>results: 采用多种多样性，具有3D脑图像映射的学习，并在五个公共数据集上预训练一个全面的脑编码模型，以及证明该模型可以作为视觉后处理模型的替换。进一步应用脑解码。<details>
<summary>Abstract</summary>
Brain encoding models aim to predict brain voxel-wise responses to stimuli images, replicating brain signals captured by neuroimaging techniques. There is a large volume of publicly available data, but training a comprehensive brain encoding model is challenging. The main difficulties stem from a) diversity within individual brain, with functional heterogeneous brain regions; b) diversity of brains from different subjects, due to genetic and developmental differences; c) diversity of imaging modalities and processing pipelines. We use this diversity to our advantage by introducing the All-for-One training recipe, which divides the challenging one-big-model problem into multiple small models, with the small models aggregating the knowledge while preserving the distinction between the different functional regions. Agnostic of the training recipe, we use biological knowledge of the brain, specifically retinotopy, to introduce inductive bias to learn a 3D brain-to-image mapping that ensures a) each neuron knows which image regions and semantic levels to gather information, and b) no neurons are left behind in the model.   We pre-trained a brain encoding model using over one million data points from five public datasets spanning three imaging modalities. To the best of our knowledge, this is the most comprehensive brain encoding model to the date. We demonstrate the effectiveness of the pre-trained model as a drop-in replacement for commonly used vision backbone models. Furthermore, we demonstrate the application of the model to brain decoding. Code and the model checkpoint will be made available.
</details>
<details>
<summary>摘要</summary>
brain编码模型目的是预测脑细胞层次响应外部刺激图像，模拟脑信号 captured by 神经成像技术。有大量公共数据可用，但 trains comprehensive brain编码模型是挑战。主要困难来自于：a) 个体脑中功能多样性，各个功能区域的多样性;b) 不同个体的脑发育差异，基因和发育差异;c) 成像模式和处理流水线的多样性。我们利用这些多样性，提出了 All-for-One 训练方法，将复杂的一个大模型问题分解成多个小模型，小模型互相协同，汇集知识，同时保持不同功能区域的分别。无论训练方法，我们利用脑科学中的知识，具体是视网膜，引入假设导向，学习 3D 脑-图像映射，以确保：a) 每个神经细胞知道哪些图像区域和semantic层次收集信息;b) 无神经细胞被模型忽略。我们预训练了脑编码模型，使用公共数据集总计一百万多个数据点，来自五个公共数据集，覆盖三种成像模式。到目前为止，这是最全面的脑编码模型。我们证明了预训练模型可以作为常用视觉底层模型的替换。此外，我们还应用了模型到脑解oding。代码和模型检查点将被公布。
</details></li>
</ul>
<hr>
<h2 id="RPG-Palm-Realistic-Pseudo-data-Generation-for-Palmprint-Recognition"><a href="#RPG-Palm-Realistic-Pseudo-data-Generation-for-Palmprint-Recognition" class="headerlink" title="RPG-Palm: Realistic Pseudo-data Generation for Palmprint Recognition"></a>RPG-Palm: Realistic Pseudo-data Generation for Palmprint Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14016">http://arxiv.org/abs/2307.14016</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Shen, Jianlong Jin, Ruixin Zhang, Huaen Li, Kai Zhao, Yingyi Zhang, Jingyun Zhang, Shouhong Ding, Yang Zhao, Wei Jia</li>
<li>for: 提高palmprint认证模型性能，addressing the lack of large-scale public palmprint datasets.</li>
<li>methods: 提出了一种新的 Pseudo-Palmprint Generation (RPG) 模型，使用 conditional modulation generator 和 identity-aware loss 来提高内类多样性和人脸独特性。</li>
<li>results: 实验结果表明，使用 synthetic pretraining 可以显著提高palmprint认证模型的性能，例如，在 $1:1$ 和 $1:3$ Open-set 协议下，我们的模型比 state-of-the-art B&#39;ezierPalm 提高了 более чем $5%$ 和 $14%$。而且，只使用 $10%$ 的实际训练数据，我们的方法仍然可以超越 ArcFace 使用 $100%$ 实际训练数据。<details>
<summary>Abstract</summary>
Palmprint recently shows great potential in recognition applications as it is a privacy-friendly and stable biometric. However, the lack of large-scale public palmprint datasets limits further research and development of palmprint recognition. In this paper, we propose a novel realistic pseudo-palmprint generation (RPG) model to synthesize palmprints with massive identities. We first introduce a conditional modulation generator to improve the intra-class diversity. Then an identity-aware loss is proposed to ensure identity consistency against unpaired training. We further improve the B\'ezier palm creases generation strategy to guarantee identity independence. Extensive experimental results demonstrate that synthetic pretraining significantly boosts the recognition model performance. For example, our model improves the state-of-the-art B\'ezierPalm by more than $5\%$ and $14\%$ in terms of TAR@FAR=1e-6 under the $1:1$ and $1:3$ Open-set protocol. When accessing only $10\%$ of the real training data, our method still outperforms ArcFace with $100\%$ real training data, indicating that we are closer to real-data-free palmprint recognition.
</details>
<details>
<summary>摘要</summary>
最近，手印识别技术已经显示出了很大的潜力，因为它是一种隐私友好的和稳定的生物指纹。然而，由于缺乏大规模的公共手印数据集，进一步的研究和开发受到了限制。在这篇论文中，我们提出了一种新的现实 pseudo-手印生成（RPG）模型，可以Synthesize手印 prints with massive identities。我们首先引入了条件修饰生成器，以提高内类多样性。然后，我们提出了一种身份相关损失，以保证身份一致性。最后，我们进一步改进了Bézier手印皱纹生成策略，以保证身份独立。我们的实验结果表明，在Synthetic预训练下，识别模型的性能得到了显著提高。例如，我们的模型比State-of-the-art BézierPalm提高了 более чем5%和14%在1:1和1:3开放集成协议下的TAR@FAR=1e-6。当只使用实际训练数据的10%时，我们的方法仍然超越了使用100%实际训练数据的ArcFace，这表明我们更接近实际数据免训练的手印识别。
</details></li>
</ul>
<hr>
<h2 id="Car-Studio-Learning-Car-Radiance-Fields-from-Single-View-and-Endless-In-the-wild-Images"><a href="#Car-Studio-Learning-Car-Radiance-Fields-from-Single-View-and-Endless-In-the-wild-Images" class="headerlink" title="Car-Studio: Learning Car Radiance Fields from Single-View and Endless In-the-wild Images"></a>Car-Studio: Learning Car Radiance Fields from Single-View and Endless In-the-wild Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14009">http://arxiv.org/abs/2307.14009</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lty2226262/Car_studio">https://github.com/lty2226262/Car_studio</a></li>
<li>paper_authors: Tianyu Liu, Hao Zhao, Yang Yu, Guyue Zhou, Ming Liu</li>
<li>for: 研究人员希望通过自适应驾驶模拟器中的编辑功能来提高自适应驾驶系统的性能。</li>
<li>methods: 作者提出了一种搭建自由图像学习和建立dataset的管道，并针对自驾汽车中的车身射线场进行设计，以满足模拟器的需求。</li>
<li>results: 通过实验，作者证明了他们的模型与基eline相比具有竞争性能，并逐渐实现了控制性图像编辑功能。<details>
<summary>Abstract</summary>
Compositional neural scene graph studies have shown that radiance fields can be an efficient tool in an editable autonomous driving simulator. However, previous studies learned within a sequence of autonomous driving datasets, resulting in unsatisfactory blurring when rotating the car in the simulator. In this letter, we propose a pipeline for learning unconstrained images and building a dataset from processed images. To meet the requirements of the simulator, which demands that the vehicle maintain clarity when the perspective changes and that the contour remains sharp from the background to avoid artifacts when editing, we design a radiation field of the vehicle, a crucial part of the urban scene foreground. Through experiments, we demonstrate that our model achieves competitive performance compared to baselines. Using the datasets built from in-the-wild images, our method gradually presents a controllable appearance editing function. We will release the dataset and code on https://lty2226262.github.io/car-studio/ to facilitate further research in the field.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换给定文本到简化中文。</SYS>> compositional neural scene graph 研究表明，辐射场可以是编辑自驾护 simulate 中的效果 Tools。然而，前一 studies 在一系列自动驾护数据集中学习，导致在 simulate 中旋转车辆时出现不满人的模糊。在这封信中，我们提出一个管道来学习无约束的图像和建立数据集。为满足 simulate 的需求，我们设计了车辆的辐射场，城市前景中的重要部分。通过实验，我们示出了我们的模型与基eline相比具有竞争性。使用从野外的图像构建的数据集，我们逐渐实现了可控的外观编辑功能。我们将发布数据集和代码到 https://lty2226262.github.io/car-studio/，以便进一步研究在这个领域。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Frequency-Filters-As-Efficient-Global-Token-Mixers"><a href="#Adaptive-Frequency-Filters-As-Efficient-Global-Token-Mixers" class="headerlink" title="Adaptive Frequency Filters As Efficient Global Token Mixers"></a>Adaptive Frequency Filters As Efficient Global Token Mixers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14008">http://arxiv.org/abs/2307.14008</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/TokenMixers">https://github.com/microsoft/TokenMixers</a></li>
<li>paper_authors: Zhipeng Huang, Zhizheng Zhang, Cuiling Lan, Zheng-Jun Zha, Yan Lu, Baining Guo</li>
<li>for: 本文 targets 广泛视觉任务中的效率和准确性问题，旨在提出一种有效的减少计算成本的方法，以便在移动设备上部署深度学习模型。</li>
<li>methods: 本文使用了传统的卷积定理来deep learning中，并发现了适应频率筛选器可以作为全球化征素。</li>
<li>results: 实验表明，提出的AFF征素混合器可以减少计算成本，同时保持或提高准确性。AFFNet也在广泛视觉任务中达到了较好的平衡点。<details>
<summary>Abstract</summary>
Recent vision transformers, large-kernel CNNs and MLPs have attained remarkable successes in broad vision tasks thanks to their effective information fusion in the global scope. However, their efficient deployments, especially on mobile devices, still suffer from noteworthy challenges due to the heavy computational costs of self-attention mechanisms, large kernels, or fully connected layers. In this work, we apply conventional convolution theorem to deep learning for addressing this and reveal that adaptive frequency filters can serve as efficient global token mixers. With this insight, we propose Adaptive Frequency Filtering (AFF) token mixer. This neural operator transfers a latent representation to the frequency domain via a Fourier transform and performs semantic-adaptive frequency filtering via an elementwise multiplication, which mathematically equals to a token mixing operation in the original latent space with a dynamic convolution kernel as large as the spatial resolution of this latent representation. We take AFF token mixers as primary neural operators to build a lightweight neural network, dubbed AFFNet. Extensive experiments demonstrate the effectiveness of our proposed AFF token mixer and show that AFFNet achieve superior accuracy and efficiency trade-offs compared to other lightweight network designs on broad visual tasks, including visual recognition and dense prediction tasks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Learning-Snippet-to-Motion-Progression-for-Skeleton-based-Human-Motion-Prediction"><a href="#Learning-Snippet-to-Motion-Progression-for-Skeleton-based-Human-Motion-Prediction" class="headerlink" title="Learning Snippet-to-Motion Progression for Skeleton-based Human Motion Prediction"></a>Learning Snippet-to-Motion Progression for Skeleton-based Human Motion Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14006">http://arxiv.org/abs/2307.14006</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinshun Wang, Qiongjie Cui, Chen Chen, Shen Zhao, Mengyuan Liu</li>
<li>for: 这篇论文的目的是提出一个多阶段框架，以便更好地预测人类动作。</li>
<li>methods: 该方法使用了一个单一的几何模型，实现了对特征传播的直接和有效的实现。</li>
<li>results: 实验结果显示，该方法可以在Human 3.6M、CMU Mocap和3DPW datasets上取得最佳性能，并且比之前的方法有更好的预测性。<details>
<summary>Abstract</summary>
Existing Graph Convolutional Networks to achieve human motion prediction largely adopt a one-step scheme, which output the prediction straight from history input, failing to exploit human motion patterns. We observe that human motions have transitional patterns and can be split into snippets representative of each transition. Each snippet can be reconstructed from its starting and ending poses referred to as the transitional poses. We propose a snippet-to-motion multi-stage framework that breaks motion prediction into sub-tasks easier to accomplish. Each sub-task integrates three modules: transitional pose prediction, snippet reconstruction, and snippet-to-motion prediction. Specifically, we propose to first predict only the transitional poses. Then we use them to reconstruct the corresponding snippets, obtaining a close approximation to the true motion sequence. Finally we refine them to produce the final prediction output. To implement the network, we propose a novel unified graph modeling, which allows for direct and effective feature propagation compared to existing approaches which rely on separate space-time modeling. Extensive experiments on Human 3.6M, CMU Mocap and 3DPW datasets verify the effectiveness of our method which achieves state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
现有的图像 convolutional neural networks  для人体动作预测主要采用一步方案，直接从历史输入输出预测结果，而不利用人体动作的模式。我们发现人体动作有过渡模式，可以将动作分解成表示每个过渡的小剪辑。每个小剪辑可以从其起始和结束姿势（称为过渡姿势）中重建。我们提议一个小剪辑-动作多stage框架，将动作预测分解成更容易实现的子任务。每个子任务包括三个模块：过渡姿势预测、小剪辑重建和小剪辑-动作预测。具体来说，我们首先预测过渡姿势，然后使用它们重建相应的小剪辑，获得一个近似真实动作序列。最后，我们进行细化修正，以生成最终预测输出。为实现网络，我们提议一种新的统一图像模型，允许直接和有效地传播特征，而不是现有的分离空间-时间模型。广泛的实验在人类3.6M、CMU Mocap 和 3DPW 数据集上证明了我们的方法的有效性，达到了状态 искусственный智能的性能。
</details></li>
</ul>
<hr>
<h2 id="Causal-reasoning-in-typical-computer-vision-tasks"><a href="#Causal-reasoning-in-typical-computer-vision-tasks" class="headerlink" title="Causal reasoning in typical computer vision tasks"></a>Causal reasoning in typical computer vision tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13992">http://arxiv.org/abs/2307.13992</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kexuan Zhang, Qiyu Sun, Chaoqiang Zhao, Yang Tang</li>
<li>for: This paper aims to comprehensively review existing causal methods in typical vision and vision-language tasks, and provide future roadmaps for the development and application of causal theory in computer vision.</li>
<li>methods: The paper uses a causal paradigm to model the intrinsic causal structure of vision and vision-language tasks, and reviews existing causal methods in semantic segmentation, object detection, and image captioning.</li>
<li>results: The paper discusses the advantages of using causality in deep learning-based computer vision tasks and proposes future roadmaps for the development and application of causal theory in other complex scenes and systems.<details>
<summary>Abstract</summary>
Deep learning has revolutionized the field of artificial intelligence. Based on the statistical correlations uncovered by deep learning-based methods, computer vision has contributed to tremendous growth in areas like autonomous driving and robotics. Despite being the basis of deep learning, such correlation is not stable and is susceptible to uncontrolled factors. In the absence of the guidance of prior knowledge, statistical correlations can easily turn into spurious correlations and cause confounders. As a result, researchers are now trying to enhance deep learning methods with causal theory. Causal theory models the intrinsic causal structure unaffected by data bias and is effective in avoiding spurious correlations. This paper aims to comprehensively review the existing causal methods in typical vision and vision-language tasks such as semantic segmentation, object detection, and image captioning. The advantages of causality and the approaches for building causal paradigms will be summarized. Future roadmaps are also proposed, including facilitating the development of causal theory and its application in other complex scenes and systems.
</details>
<details>
<summary>摘要</summary>
深度学习已经革命化人工智能领域。基于深度学习方法发现的统计相关性，计算机视觉在自动驾驶和机器人等领域带来了巨大的成长。然而，这种相关性并不稳定，容易受到外部因素的影响。在知识导向的指导下 absence，统计相关性可以轻易变成假 correlate 和干扰因素。因此，研究人员现在尝试通过 causal theory 增强深度学习方法。causal theory 模型了不受数据偏见影响的内在 causal 结构，可以减少假 correlate 的出现。本文将对常见视觉和语言视觉任务，如 semantic segmentation、object detection 和 image captioning 等进行全面的review。causality 的优势和建立 causal 模型的方法将被总结。未来的路线图还将包括在其他复杂的场景和系统中应用 causal theory 的发展，以及促进 causal theory 的应用。
</details></li>
</ul>
<hr>
<h2 id="METAVerse-Meta-Learning-Traversability-Cost-Map-for-Off-Road-Navigation"><a href="#METAVerse-Meta-Learning-Traversability-Cost-Map-for-Off-Road-Navigation" class="headerlink" title="METAVerse: Meta-Learning Traversability Cost Map for Off-Road Navigation"></a>METAVerse: Meta-Learning Traversability Cost Map for Off-Road Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13991">http://arxiv.org/abs/2307.13991</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junwon Seo, Taekyung Kim, Seongyong Ahn, Kiho Kwak</li>
<li>for: 这篇论文的目的是为了实现自主导航在非道路环境中，准确地估算地形通行性。</li>
<li>methods: 这篇论文使用了元学习框架，通过自动驾驶数据收集自多种环境，训练了一个全球模型，以估算地形通行性。</li>
<li>results: 研究人员通过在多种地形上收集驾驶数据，训练了一个全球模型，可以准确地估算地形通行性，并且通过与控制器集成，实现了安全和稳定的自主导航。<details>
<summary>Abstract</summary>
Autonomous navigation in off-road conditions requires an accurate estimation of terrain traversability. However, traversability estimation in unstructured environments is subject to high uncertainty due to the variability of numerous factors that influence vehicle-terrain interaction. Consequently, it is challenging to obtain a generalizable model that can accurately predict traversability in a variety of environments. This paper presents METAVerse, a meta-learning framework for learning a global model that accurately and reliably predicts terrain traversability across diverse environments. We train the traversability prediction network to generate a dense and continuous-valued cost map from a sparse LiDAR point cloud, leveraging vehicle-terrain interaction feedback in a self-supervised manner. Meta-learning is utilized to train a global model with driving data collected from multiple environments, effectively minimizing estimation uncertainty. During deployment, online adaptation is performed to rapidly adapt the network to the local environment by exploiting recent interaction experiences. To conduct a comprehensive evaluation, we collect driving data from various terrains and demonstrate that our method can obtain a global model that minimizes uncertainty. Moreover, by integrating our model with a model predictive controller, we demonstrate that the reduced uncertainty results in safe and stable navigation in unstructured and unknown terrains.
</details>
<details>
<summary>摘要</summary>
自主导航在未知预期环境中需要准确地估计地形可行性。然而，在无结构环境中 traversability 估计受到多种因素的变化所带来的不确定性的影响，因此很难取得一个通用的模型，可以准确地预测不同环境中的地形可行性。这篇论文提出了 METAVerse，一个基于 meta-学 的框架，用于学习一个准确且可靠地预测地形可行性的全球模型。我们在自然supervised 的方式下，使用汽车-地面交互反馈来训练一个 dense 和连续值的 cost 图，从 LiDAR 点云中生成一个粗略的地形可行性预测结果。通过 meta-学 的使用，我们可以在多个环境中收集的驾驶数据上训练一个全球模型，以实现最小化估计uncertainty。在部署时，我们通过在线适应来迅速地适应当地环境，并且通过利用最近的交互经验来进行更新。我们通过收集不同 terrains 的驾驶数据，并进行了全面的评估，得到了一个准确且可靠的全球模型，并且通过与预测控制器集成，实现了安全和稳定的自主导航。
</details></li>
</ul>
<hr>
<h2 id="Hybrid-Representation-Enhanced-Sampling-for-Bayesian-Active-Learning-in-Musculoskeletal-Segmentation-of-Lower-Extremities"><a href="#Hybrid-Representation-Enhanced-Sampling-for-Bayesian-Active-Learning-in-Musculoskeletal-Segmentation-of-Lower-Extremities" class="headerlink" title="Hybrid Representation-Enhanced Sampling for Bayesian Active Learning in Musculoskeletal Segmentation of Lower Extremities"></a>Hybrid Representation-Enhanced Sampling for Bayesian Active Learning in Musculoskeletal Segmentation of Lower Extremities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13986">http://arxiv.org/abs/2307.13986</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ganping Li, Yoshito Otake, Mazen Soufi, Masashi Taniguchi, Masahide Yagi, Noriaki Ichihashi, Keisuke Uemura, Masaki Takao, Nobuhiko Sugano, Yoshinobu Sato<br>for: 这个研究的目的是提高医疗影像标注的效率，使用 Bayesian active learning (BAL) 方法选择最有用的标注样本，以减少人工标注的时间和努力。methods: 这个研究使用了一个混合表现式增强抽样法，将高密度和多样性的标注样本选择进行人工修改，以便最大化与未标注样本的相似性，最小化与现有训练样本的相似性。results: 研究结果显示，提案的抽样法在两个lower extremity (LE) dataset上表现出色，在两种抽样规则下都达到了superiority或非凡性。量值结果显示，混合表现式增强抽样法在骨附致度标注中表现出色，并且在不同的抽样规则下进行了评估和比较。<details>
<summary>Abstract</summary>
Purpose: Obtaining manual annotations to train deep learning (DL) models for auto-segmentation is often time-consuming. Uncertainty-based Bayesian active learning (BAL) is a widely-adopted method to reduce annotation efforts. Based on BAL, this study introduces a hybrid representation-enhanced sampling strategy that integrates density and diversity criteria to save manual annotation costs by efficiently selecting the most informative samples.   Methods: The experiments are performed on two lower extremity (LE) datasets of MRI and CT images by a BAL framework based on Bayesian U-net. Our method selects uncertain samples with high density and diversity for manual revision, optimizing for maximal similarity to unlabeled instances and minimal similarity to existing training data. We assess the accuracy and efficiency using Dice and a proposed metric called reduced annotation cost (RAC), respectively. We further evaluate the impact of various acquisition rules on BAL performance and design an ablation study for effectiveness estimation.   Results: The proposed method showed superiority or non-inferiority to other methods on both datasets across two acquisition rules, and quantitative results reveal the pros and cons of the acquisition rules. Our ablation study in volume-wise acquisition shows that the combination of density and diversity criteria outperforms solely using either of them in musculoskeletal segmentation.   Conclusion: Our sampling method is proven efficient in reducing annotation costs in image segmentation tasks. The combination of the proposed method and our BAL framework provides a semi-automatic way for efficient annotation of medical image datasets.
</details>
<details>
<summary>摘要</summary>
目的：获取手动标注以训练深度学习（DL）模型的自动分割是时间consuming的。uncertainty-based Bayesian活动学习（BAL）是一种广泛采用的方法，可以减少手动标注的努力。基于BAL，本研究提出了一种混合表示函数增强选择策略，可以高效地选择最有用的样本进行手动修改，以便更好地适应不同的样本。方法：我们在两个lower extremity（LE）数据集上进行了MRI和CT图像的实验，使用基于Bayesian U-net的BAL框架。我们的方法选择了uncertainty高的样本，同时满足高density和多样性要求，以便手动修改后，与未标注数据的最大相似性和已有训练数据的最小相似性。我们使用Dice和一个提出的 metric called reduced annotation cost（RAC）进行评估精度和效率。我们进一步 evaluate了不同的获取规则对BAL性能的影响，并设计了一个ablation study来评估效果。结果：我们的方法在两个数据集上都显示了superiority或非 инфериорity compared to其他方法，并且quantitative results reveal了不同获取规则的优缺点。我们的ablation study表明，混合density和多样性 criterion outperforms使用任一 criterion alone in musculoskeletal segmentation。结论：我们的采样方法可以减少图像分割任务中的手动标注成本。将我们的采样方法与我们的BAL框架结合使用，可以提供一种 semi-automatic的方式，以便快速和高效地注解医疗图像数据集。
</details></li>
</ul>
<hr>
<h2 id="Enhanced-Security-against-Adversarial-Examples-Using-a-Random-Ensemble-of-Encrypted-Vision-Transformer-Models"><a href="#Enhanced-Security-against-Adversarial-Examples-Using-a-Random-Ensemble-of-Encrypted-Vision-Transformer-Models" class="headerlink" title="Enhanced Security against Adversarial Examples Using a Random Ensemble of Encrypted Vision Transformer Models"></a>Enhanced Security against Adversarial Examples Using a Random Ensemble of Encrypted Vision Transformer Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13985">http://arxiv.org/abs/2307.13985</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ryota Iijima, Miki Tanaka, Sayaka Shiota, Hitoshi Kiya</li>
<li>for: 防御深度神经网络（DNNs）受到敌意攻击（Adversarial Examples，AE）的袭击。</li>
<li>methods: 提出了一种随机ensemble的加密ViT模型来实现更加可靠的防御。</li>
<li>results: 在实验中，提议的方案比 conventional方法更加鲁棒 против不仅黑盒攻击，还有白盒攻击。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) are well known to be vulnerable to adversarial examples (AEs). In addition, AEs have adversarial transferability, which means AEs generated for a source model can fool another black-box model (target model) with a non-trivial probability. In previous studies, it was confirmed that the vision transformer (ViT) is more robust against the property of adversarial transferability than convolutional neural network (CNN) models such as ConvMixer, and moreover encrypted ViT is more robust than ViT without any encryption. In this article, we propose a random ensemble of encrypted ViT models to achieve much more robust models. In experiments, the proposed scheme is verified to be more robust against not only black-box attacks but also white-box ones than convention methods.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNNs）已经广泛地知道它们容易受到敌意例子（AEs）的攻击。此外，AEs还具有敌意传递性，意味着生成 для源模型的AEs可以诱导另一个黑盒模型（目标模型）的非常小的概率。在先前的研究中，确认了视transformer（ViT）比 convolutional neural network（CNN）模型such as ConvMixer更加抵抗性能 adversarial transferability的性能。此外，加密ViT比不加密ViT更加抗性能。在这篇文章中，我们提议一种随机ensemble of encrypted ViT模型来实现更加可靠的模型。在实验中，我们的方案被证明更加抗性能于不只是黑盒攻击，还有白盒攻击。
</details></li>
</ul>
<hr>
<h2 id="Analysis-of-Video-Quality-Datasets-via-Design-of-Minimalistic-Video-Quality-Models"><a href="#Analysis-of-Video-Quality-Datasets-via-Design-of-Minimalistic-Video-Quality-Models" class="headerlink" title="Analysis of Video Quality Datasets via Design of Minimalistic Video Quality Models"></a>Analysis of Video Quality Datasets via Design of Minimalistic Video Quality Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13981">http://arxiv.org/abs/2307.13981</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Sun, Wen Wen, Xiongkuo Min, Long Lan, Guangtao Zhai, Kede Ma<br>for:这篇论文的目的是为了评估视频质量评估（BVQA）模型的进步，以及现有的视频质量评估数据集的评估。methods:这篇论文使用了一种简单的BVQA模型，包括视频预处理器、空间质量分析器、可选的时间质量分析器和质量回归器，并对八个视频质量评估数据集进行了比较。results:研究发现，大多数数据集受到容易的数据集问题的影响，一些数据集甚至可以使用盲图质量评估（BIQA）解决方案。研究还发现，不同的BVQA设计选择对于不同的数据集有着不同的影响。这些结果表明，当前的BVQA领域需要进一步的改进，同时也提供了构建下一代视频质量评估数据集和模型的好做法。<details>
<summary>Abstract</summary>
Blind video quality assessment (BVQA) plays an indispensable role in monitoring and improving the end-users' viewing experience in various real-world video-enabled media applications. As an experimental field, the improvements of BVQA models have been measured primarily on a few human-rated VQA datasets. Thus, it is crucial to gain a better understanding of existing VQA datasets in order to properly evaluate the current progress in BVQA. Towards this goal, we conduct a first-of-its-kind computational analysis of VQA datasets via designing minimalistic BVQA models. By minimalistic, we restrict our family of BVQA models to build only upon basic blocks: a video preprocessor (for aggressive spatiotemporal downsampling), a spatial quality analyzer, an optional temporal quality analyzer, and a quality regressor, all with the simplest possible instantiations. By comparing the quality prediction performance of different model variants on eight VQA datasets with realistic distortions, we find that nearly all datasets suffer from the easy dataset problem of varying severity, some of which even admit blind image quality assessment (BIQA) solutions. We additionally justify our claims by contrasting our model generalizability on these VQA datasets, and by ablating a dizzying set of BVQA design choices related to the basic building blocks. Our results cast doubt on the current progress in BVQA, and meanwhile shed light on good practices of constructing next-generation VQA datasets and models.
</details>
<details>
<summary>摘要</summary>
视频质量评估（BVQA）在各种视频媒体应用中扮演着不可或缺的角色，评估用户在实际场景中的观看体验。作为实验领域，BVQA模型的改进主要基于一些人工评估的VQA数据集。因此，更深刻地理解现有VQA数据集是关键的。为了实现这个目标，我们通过设计最简单的BVQA模型进行计算分析。我们限制我们的BVQA模型只能使用基本块：视频预处理器（用于激进的时空下采样）、空间质量分析器、可选的时间质量分析器和质量回归器，其中所有的实现都是最简单的。通过对不同模型变体在八个VQA数据集上的质量预测性能进行比较，我们发现大多数数据集受到不同程度的易于评估问题的影响，一些甚至接受盲图质量评估（BIQA）解决方案。此外，我们还通过对这些VQA数据集的模型普适性进行比较，以及对BVQA设计决策的绝对多样化进行排除，来证明我们的结论。结果表明，目前BVQA领域的进步存在很大的问题，同时也提供了构建下一代VQA数据集和模型的好做法。
</details></li>
</ul>
<hr>
<h2 id="Tracking-Anything-in-High-Quality"><a href="#Tracking-Anything-in-High-Quality" class="headerlink" title="Tracking Anything in High Quality"></a>Tracking Anything in High Quality</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13974">http://arxiv.org/abs/2307.13974</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiawen-zhu/hqtrack">https://github.com/jiawen-zhu/hqtrack</a></li>
<li>paper_authors: Jiawen Zhu, Zhenyu Chen, Zeqi Hao, Shijie Chang, Lu Zhang, Dong Wang, Huchuan Lu, Bin Luo, Jun-Yan He, Jin-Peng Lan, Hanyuan Chen, Chenyang Li</li>
<li>for: 本文提出了一种高质量视频对象跟踪框架（HQTrack），用于高精度地跟踪视频中的任意对象。</li>
<li>methods: 该框架包括视频多对象分割器（VMOS）和掩码精度提升器（MR）两部分。VMOS通过卷积神经网络进行对象分割，而MR使用预训练的模型来精度地改善跟踪结果。</li>
<li>results: 对比其他参赛方法，HQTrack在Visual Object Tracking and Segmentation（VOTS2023）挑战中得到了第二名的成绩，而不使用任何套路如测试时数据增强和模型ensemble。<details>
<summary>Abstract</summary>
Visual object tracking is a fundamental video task in computer vision. Recently, the notably increasing power of perception algorithms allows the unification of single/multiobject and box/mask-based tracking. Among them, the Segment Anything Model (SAM) attracts much attention. In this report, we propose HQTrack, a framework for High Quality Tracking anything in videos. HQTrack mainly consists of a video multi-object segmenter (VMOS) and a mask refiner (MR). Given the object to be tracked in the initial frame of a video, VMOS propagates the object masks to the current frame. The mask results at this stage are not accurate enough since VMOS is trained on several closeset video object segmentation (VOS) datasets, which has limited ability to generalize to complex and corner scenes. To further improve the quality of tracking masks, a pretrained MR model is employed to refine the tracking results. As a compelling testament to the effectiveness of our paradigm, without employing any tricks such as test-time data augmentations and model ensemble, HQTrack ranks the 2nd place in the Visual Object Tracking and Segmentation (VOTS2023) challenge. Code and models are available at https://github.com/jiawen-zhu/HQTrack.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>>视觉对象跟踪是计算机视觉中的基本任务。近些年，人工智能的识别算法的能力不断提高，使得单/多对象和框/面签基本跟踪可以协调。其中，Segment Anything Model（SAM）吸引了很多关注。在这份报告中，我们提出了高质量跟踪任何对象的框架（HQTrack）。HQTrack主要由视频多对象分割器（VMOS）和面签修正器（MR）两部分组成。给定视频中的对象在初始帧，VMOS将对象面签推广到当前帧。但由于VMOS被训练于一些相似的视频对象分割（VOS）数据集，其泛化能力有限，因此对跟踪面签的结果进行修正。为了进一步提高跟踪面签的质量，我们采用了预训练的MR模型进行修正。作为我们模型的吸引力，在Visual Object Tracking and Segmentation（VOTS2023）挑战中，无需使用任何套路技术和模型集成，HQTrack在评测中排名第二。代码和模型可以在https://github.com/jiawen-zhu/HQTrack上获取。
</details></li>
</ul>
<hr>
<h2 id="Visual-Prompt-Flexible-Modal-Face-Anti-Spoofing"><a href="#Visual-Prompt-Flexible-Modal-Face-Anti-Spoofing" class="headerlink" title="Visual Prompt Flexible-Modal Face Anti-Spoofing"></a>Visual Prompt Flexible-Modal Face Anti-Spoofing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13958">http://arxiv.org/abs/2307.13958</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zitong Yu, Rizhao Cai, Yawen Cui, Ajian Liu, Changsheng Chen</li>
<li>for: 提高face anti-spoofing（FAS）系统的 robustness，使用视觉转换器基于多模态学习方法。</li>
<li>methods: 提出了一种名为Vision Prompt flexible-modal FAS（VP-FAS）的方法，通过在固定预训练基模型上学习模式相关的提示来适应流处理时缺失的模态。</li>
<li>results: 在两个多模态FAS benchmark数据集上进行了广泛的实验，证明了VP-FAS框架在不同缺失模态情况下的高效性，同时减少了模型重新训练的需求。<details>
<summary>Abstract</summary>
Recently, vision transformer based multimodal learning methods have been proposed to improve the robustness of face anti-spoofing (FAS) systems. However, multimodal face data collected from the real world is often imperfect due to missing modalities from various imaging sensors. Recently, flexible-modal FAS~\cite{yu2023flexible} has attracted more attention, which aims to develop a unified multimodal FAS model using complete multimodal face data but is insensitive to test-time missing modalities. In this paper, we tackle one main challenge in flexible-modal FAS, i.e., when missing modality occurs either during training or testing in real-world situations. Inspired by the recent success of the prompt learning in language models, we propose \textbf{V}isual \textbf{P}rompt flexible-modal \textbf{FAS} (VP-FAS), which learns the modal-relevant prompts to adapt the frozen pre-trained foundation model to downstream flexible-modal FAS task. Specifically, both vanilla visual prompts and residual contextual prompts are plugged into multimodal transformers to handle general missing-modality cases, while only requiring less than 4\% learnable parameters compared to training the entire model. Furthermore, missing-modality regularization is proposed to force models to learn consistent multimodal feature embeddings when missing partial modalities. Extensive experiments conducted on two multimodal FAS benchmark datasets demonstrate the effectiveness of our VP-FAS framework that improves the performance under various missing-modality cases while alleviating the requirement of heavy model re-training.
</details>
<details>
<summary>摘要</summary>
最近，基于视觉变换器的多Modal学习方法被提议以提高face anti-spoofing（FAS）系统的 Robustness。然而，从实际世界中收集的多Modal face数据经常受到不同感知器的数据损失。近期，flexible-modal FAS 在这些损失中吸引了更多的关注，它的目标是开发一个可以使用完整的多Modal face数据进行融合的 FAS模型，但是不敏感于测试时缺失的模态。在这篇论文中，我们解决了flexible-modal FAS中的一个主要挑战，即在训练或测试过程中缺失模态。我们灵感自近期的语言模型的Prompt学习的成功，我们提出了Visual Prompt flexible-modal FAS（VP-FAS），它通过学习模态相关的Prompt来适应冻结预训练基础模型到下游多Modal FAS任务。特别是，我们在多Modal transformer中插入了vanilla visual prompt和 residual contextual prompt，以处理一般缺失模态的情况，而无需更新整个模型。此外，我们还提出了缺失模态的Regularization，以强制模型学习一致的多Modal特征嵌入，即使缺失部分模态。我们在两个多Modal FAS benchmark数据集上进行了广泛的实验， demonstarted VP-FAS框架可以在不同的缺失模态情况下提高性能，而且降低模型重新训练的需求。
</details></li>
</ul>
<hr>
<h2 id="Heterogeneous-Embodied-Multi-Agent-Collaboration"><a href="#Heterogeneous-Embodied-Multi-Agent-Collaboration" class="headerlink" title="Heterogeneous Embodied Multi-Agent Collaboration"></a>Heterogeneous Embodied Multi-Agent Collaboration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13957">http://arxiv.org/abs/2307.13957</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinzhu Liu, Di Guo, Huaping Liu</li>
<li>for: 这个论文研究了多智能体在复杂的室内视觉环境中完成多智能体任务的协作方法。</li>
<li>methods: 该论文提出了一种基于多智能体探测异常物品并预测合理容器的层次决策模型，以及一种基于手势交换的群体通信机制。</li>
<li>results: 经过广泛的实验，论文证明了提出的模型的效果。项目官方网站和实验视频可以在<a target="_blank" rel="noopener" href="https://hetercol.github.io/%E6%9F%A5%E7%9C%8B%E3%80%82">https://hetercol.github.io/查看。</a><details>
<summary>Abstract</summary>
Multi-agent embodied tasks have recently been studied in complex indoor visual environments. Collaboration among multiple agents can improve work efficiency and has significant practical value. However, most of the existing research focuses on homogeneous multi-agent tasks. Compared with homogeneous agents, heterogeneous agents can leverage their different capabilities to allocate corresponding sub-tasks and cooperate to complete complex tasks. Heterogeneous multi-agent tasks are common in real-world scenarios, and the collaboration strategy among heterogeneous agents is a challenging and important problem to be solved. To study collaboration among heterogeneous agents, we propose the heterogeneous multi-agent tidying-up task, in which multiple heterogeneous agents with different capabilities collaborate with each other to detect misplaced objects and place them in reasonable locations. This is a demanding task since it requires agents to make the best use of their different capabilities to conduct reasonable task planning and complete the whole task. To solve this task, we build a heterogeneous multi-agent tidying-up benchmark dataset in a large number of houses with multiple rooms based on ProcTHOR-10K. We propose the hierarchical decision model based on misplaced object detection, reasonable receptacle prediction, as well as the handshake-based group communication mechanism. Extensive experiments are conducted to demonstrate the effectiveness of the proposed model. The project's website and videos of experiments can be found at https://hetercol.github.io/.
</details>
<details>
<summary>摘要</summary>
多智能体任务在复杂的室内视觉环境中最近得到了研究。多个代理机器人可以增加工作效率，具有重要的实用价值。然而，大多数现有研究都集中在同类代理机器人任务上。相比同类代理机器人，多种代理机器人可以利用不同的能力来分配相应的子任务并合作完成复杂任务。多种代理机器人任务在实际场景中很常见，合作策略中的多种代理机器人是一个挑战性和重要的问题。为了研究多种代理机器人之间的合作，我们提出了多种代理机器人整理任务，在多个房间的多个室内进行探测落入的物品并将其置于合理的位置。这是一项需要代理机器人利用不同的能力进行合理的任务规划，以完成整个任务的任务。为解决这个任务，我们建立了多种代理机器人整理任务的基准数据集，基于ProcTHOR-10K。我们提出了层次决策模型，包括落入物品探测、合理容器预测以及手势交换机制。我们对这些实验进行了广泛的实验，以证明提案的模型的有效性。项目的官方网站和实验视频可以在https://hetercol.github.io/查看。
</details></li>
</ul>
<hr>
<h2 id="The-Hidden-Dance-of-Phonemes-and-Visage-Unveiling-the-Enigmatic-Link-between-Phonemes-and-Facial-Features"><a href="#The-Hidden-Dance-of-Phonemes-and-Visage-Unveiling-the-Enigmatic-Link-between-Phonemes-and-Facial-Features" class="headerlink" title="The Hidden Dance of Phonemes and Visage: Unveiling the Enigmatic Link between Phonemes and Facial Features"></a>The Hidden Dance of Phonemes and Visage: Unveiling the Enigmatic Link between Phonemes and Facial Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13953">http://arxiv.org/abs/2307.13953</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liao Qu, Xianwei Zou, Xiang Li, Yandong Wen, Rita Singh, Bhiksha Raj</li>
<li>for: 这篇论文探讨了声音和面部特征之间的关系。传统的声音-面部相关性研究通常需要使用长时间的声音输入，包括从声音生成面像和从声音重建3D面膜。但在voice-based犯罪调查中，可能只有有限的声音证据。此外，从 физиологи学角度来看，每个 segment of speech （phoneme）对应不同的空气流和面部运动。因此，发现声音和面部特征之间的隐藏关系是有利的。</li>
<li>methods: 我们提出了一个分析管道，用于在细致的方式探讨声音和面部特征之间的关系。我们建立了每个声音-特征对的估计器，并通过假设检测来评估相关性。我们发现，在元音上更容易预测面部特征，特别是填凿音。此外，我们发现，在某些特征在声音发音时的更大运动，可以更好地预测。</li>
<li>results: 我们的结果支持 physiology 中关于声音和面部特征之间的相关性的发现。我们的研究为未来的声音-面部多模态学习奠基。<details>
<summary>Abstract</summary>
This work unveils the enigmatic link between phonemes and facial features. Traditional studies on voice-face correlations typically involve using a long period of voice input, including generating face images from voices and reconstructing 3D face meshes from voices. However, in situations like voice-based crimes, the available voice evidence may be short and limited. Additionally, from a physiological perspective, each segment of speech -- phoneme -- corresponds to different types of airflow and movements in the face. Therefore, it is advantageous to discover the hidden link between phonemes and face attributes. In this paper, we propose an analysis pipeline to help us explore the voice-face relationship in a fine-grained manner, i.e., phonemes v.s. facial anthropometric measurements (AM). We build an estimator for each phoneme-AM pair and evaluate the correlation through hypothesis testing. Our results indicate that AMs are more predictable from vowels compared to consonants, particularly with plosives. Additionally, we observe that if a specific AM exhibits more movement during phoneme pronunciation, it is more predictable. Our findings support those in physiology regarding correlation and lay the groundwork for future research on speech-face multimodal learning.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Rethinking-Voice-Face-Correlation-A-Geometry-View"><a href="#Rethinking-Voice-Face-Correlation-A-Geometry-View" class="headerlink" title="Rethinking Voice-Face Correlation: A Geometry View"></a>Rethinking Voice-Face Correlation: A Geometry View</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13948">http://arxiv.org/abs/2307.13948</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lxa9867/VAF">https://github.com/lxa9867/VAF</a></li>
<li>paper_authors: Xiang Li, Yandong Wen, Muqiao Yang, Jinglu Wang, Rita Singh, Bhiksha Raj</li>
<li>for: 这种研究旨在探索voice和face之间的含义，从geometry角度来恢复3D面征。</li>
<li>methods: 该研究提出了一种voice-anthropometric measurement（AM）-face模式，通过利用AM作为voice和face之间的拟合器，消除不可预测的AM的影响，使face geometry变得可追踪。</li>
<li>results: 研究发现，voice和specific parts of the face geometry（如鼻腔和头骨）之间存在显著的相关性，这些结果可能为人骨学科提供新的视角。<details>
<summary>Abstract</summary>
Previous works on voice-face matching and voice-guided face synthesis demonstrate strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emotion. In this paper, we aim to investigate the capability of reconstructing the 3D facial shape from voice from a geometry perspective without any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face correlation and can serve as a good empirical study for anthropometry science.
</details>
<details>
<summary>摘要</summary>
previous works on voice-face matching and voice-guided face synthesis have shown strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emotion. In this paper, we aim to investigate the capability of reconstructing the 3D facial shape from voice from a geometry perspective without any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face correlation and can serve as a good empirical study for anthropometry science.Here's the translation in Traditional Chinese:previous works on voice-face matching and voice-guided face synthesis have shown strong correlations between voice and face, but mainly rely on coarse semantic cues such as gender, age, and emotion. In this paper, we aim to investigate the capability of reconstructing the 3D facial shape from voice from a geometry perspective without any semantic information. We propose a voice-anthropometric measurement (AM)-face paradigm, which identifies predictable facial AMs from the voice and uses them to guide 3D face reconstruction. By leveraging AMs as a proxy to link the voice and face geometry, we can eliminate the influence of unpredictable AMs and make the face geometry tractable. Our approach is evaluated on our proposed dataset with ground-truth 3D face scans and corresponding voice recordings, and we find significant correlations between voice and specific parts of the face geometry, such as the nasal cavity and cranium. Our work offers a new perspective on voice-face correlation and can serve as a good empirical study for anthropometry science.
</details></li>
</ul>
<hr>
<h2 id="Centroid-aware-feature-recalibration-for-cancer-grading-in-pathology-images"><a href="#Centroid-aware-feature-recalibration-for-cancer-grading-in-pathology-images" class="headerlink" title="Centroid-aware feature recalibration for cancer grading in pathology images"></a>Centroid-aware feature recalibration for cancer grading in pathology images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13947">http://arxiv.org/abs/2307.13947</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/colin19950703/cafenet">https://github.com/colin19950703/cafenet</a></li>
<li>paper_authors: Jaeung Lee, Keunho Byeon, Jin Tae Kwak</li>
<li>for: 静观细胞质量评估是生物医学影像分析中的一项关键任务，Recent developments in artificial neural networks have shown great potential for improving the accuracy and quality of cancer diagnosis.</li>
<li>methods: 提议使用一种具有中心点感知的特征重新调整网络，该网络可以将输入病理图像映射到一个嵌入空间中，并通过注意机制将其调整为不同类型的肿瘤等级中心点嵌入向量。</li>
<li>results: 通过对COLON dataset进行实验，确认提议网络可以准确地进行病理图像评估，并且能够鲁棒地适应不同环境下的数据集。<details>
<summary>Abstract</summary>
Cancer grading is an essential task in pathology. The recent developments of artificial neural networks in computational pathology have shown that these methods hold great potential for improving the accuracy and quality of cancer diagnosis. However, the issues with the robustness and reliability of such methods have not been fully resolved yet. Herein, we propose a centroid-aware feature recalibration network that can conduct cancer grading in an accurate and robust manner. The proposed network maps an input pathology image into an embedding space and adjusts it by using centroids embedding vectors of different cancer grades via attention mechanism. Equipped with the recalibrated embedding vector, the proposed network classifiers the input pathology image into a pertinent class label, i.e., cancer grade. We evaluate the proposed network using colorectal cancer datasets that were collected under different environments. The experimental results confirm that the proposed network is able to conduct cancer grading in pathology images with high accuracy regardless of the environmental changes in the datasets.
</details>
<details>
<summary>摘要</summary>
乳腺癌等级是病理学中的一项重要任务。现代人工神经网络在计算病理学中的应用表明，这些方法在改善肿瘤诊断的准确性和质量方面具有很大潜力。然而，这些方法的可靠性和可重复性问题仍未得到完全解决。在这里，我们提出了一种注意力机制基于中心点的特征重新调整网络，可以准确地进行肿瘤等级诊断。该网络将输入病理图像映射到嵌入空间中，并通过中心点嵌入向量的注意力机制进行调整。根据重新调整后的嵌入vector，该网络将输入病理图像分类为相应的肿瘤等级。我们使用了不同环境下收集的直肠癌数据集进行评估，实验结果表明，我们的方法能够在不同环境下准确地进行肿瘤等级诊断。
</details></li>
</ul>
<hr>
<h2 id="Improving-Semi-Supervised-Semantic-Segmentation-with-Dual-Level-Siamese-Structure-Network"><a href="#Improving-Semi-Supervised-Semantic-Segmentation-with-Dual-Level-Siamese-Structure-Network" class="headerlink" title="Improving Semi-Supervised Semantic Segmentation with Dual-Level Siamese Structure Network"></a>Improving Semi-Supervised Semantic Segmentation with Dual-Level Siamese Structure Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13938">http://arxiv.org/abs/2307.13938</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kunzhan/DSSN">https://github.com/kunzhan/DSSN</a></li>
<li>paper_authors: Zhibo Tain, Xiaolin Zhang, Peng Zhang, Kun Zhan</li>
<li>for: 提高semantic segmentation任务中使用无标例数据的效果，减少标注训练示例的成本。</li>
<li>methods: 提posed dual-level Siamese structure network (DSSN) for pixel-wise contrastive learning，通过对各类强弱视图进行匹配，使用强大的扩展视图在低级图像空间和高级特征空间进行对齐，以 maximize 使用可用的无标例数据。 Additionally, 引入一种新的类意识 Pseudo-label 选择策略，解决大多数现有方法不进行选择或应用预先定义的阈值 для 所有类。 Specifically, 我们的策略选择每个类的高 confidence 预测值作为 pseudo labels，以便使用强 augmented views 进行supervision。 This strategy 可以考虑类偏移和提高长尾类的性能。</li>
<li>results: 对 PASCAL VOC 2012 和 Cityscapes 两个 dataset 进行实验，实现了semantic segmentation任务中使用无标例数据的最佳效果，比其他 SSS 算法出色。<details>
<summary>Abstract</summary>
Semi-supervised semantic segmentation (SSS) is an important task that utilizes both labeled and unlabeled data to reduce expenses on labeling training examples. However, the effectiveness of SSS algorithms is limited by the difficulty of fully exploiting the potential of unlabeled data. To address this, we propose a dual-level Siamese structure network (DSSN) for pixel-wise contrastive learning. By aligning positive pairs with a pixel-wise contrastive loss using strong augmented views in both low-level image space and high-level feature space, the proposed DSSN is designed to maximize the utilization of available unlabeled data. Additionally, we introduce a novel class-aware pseudo-label selection strategy for weak-to-strong supervision, which addresses the limitations of most existing methods that do not perform selection or apply a predefined threshold for all classes. Specifically, our strategy selects the top high-confidence prediction of the weak view for each class to generate pseudo labels that supervise the strong augmented views. This strategy is capable of taking into account the class imbalance and improving the performance of long-tailed classes. Our proposed method achieves state-of-the-art results on two datasets, PASCAL VOC 2012 and Cityscapes, outperforming other SSS algorithms by a significant margin.
</details>
<details>
<summary>摘要</summary>
semi-supervised semantic segmentation (SSS) 是一项重要的任务，它利用标注和无标注数据来降低标注训练示例的成本。然而，SSS 算法的效果受到无标注数据的利用的限制。为解决这个问题，我们提出了 dual-level Siamese structure network (DSSN)  для像素级对比学习。DSSN 通过在低级图像空间和高级特征空间使用强大的扩展视图进行像素级对比损失，以 maximize 利用可用的无标注数据。此外，我们还引入了一种新的类感知 pseudo-label 选择策略，用于弱到强超vision。这种策略选择每个类的高信度预测值作为 pseudo label，以便在强augmented views中进行supervision。这种策略能够考虑类别不均衡和改进长尾类的性能。我们的提议方法在 PASCAL VOC 2012 和 Cityscapes 两个数据集上实现了state-of-the-art 的结果，比其他 SSS 算法有明显的优势。
</details></li>
</ul>
<hr>
<h2 id="AIDE-A-Vision-Driven-Multi-View-Multi-Modal-Multi-Tasking-Dataset-for-Assistive-Driving-Perception"><a href="#AIDE-A-Vision-Driven-Multi-View-Multi-Modal-Multi-Tasking-Dataset-for-Assistive-Driving-Perception" class="headerlink" title="AIDE: A Vision-Driven Multi-View, Multi-Modal, Multi-Tasking Dataset for Assistive Driving Perception"></a>AIDE: A Vision-Driven Multi-View, Multi-Modal, Multi-Tasking Dataset for Assistive Driving Perception</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13933">http://arxiv.org/abs/2307.13933</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ydk122024/aide">https://github.com/ydk122024/aide</a></li>
<li>paper_authors: Dingkang Yang, Shuai Huang, Zhi Xu, Zhenpeng Li, Shunli Wang, Mingcheng Li, Yuzheng Wang, Yang Liu, Kun Yang, Zhaoyu Chen, Yan Wang, Jing Liu, Peixuan Zhang, Peng Zhai, Lihua Zhang</li>
<li>for: 这篇论文主要旨在提供一个包含上下文信息的driver monitoring系统测试数据集，以提高交通安全和安全驾驶。</li>
<li>methods: 本论文使用多个视角设置、多Modal注释和四种实践任务来提供全面的Driver monitoring。同时， authors也提供了三种基线框架的实验比较，以及两种 fusions 策略来学习有效的多流&#x2F;多Modal表示。</li>
<li>results: 研究人员通过对AIDE数据集进行了extensive 测试和分析，发现了数据集中的关键组成部分和基线框架的重要性和合理性。<details>
<summary>Abstract</summary>
Driver distraction has become a significant cause of severe traffic accidents over the past decade. Despite the growing development of vision-driven driver monitoring systems, the lack of comprehensive perception datasets restricts road safety and traffic security. In this paper, we present an AssIstive Driving pErception dataset (AIDE) that considers context information both inside and outside the vehicle in naturalistic scenarios. AIDE facilitates holistic driver monitoring through three distinctive characteristics, including multi-view settings of driver and scene, multi-modal annotations of face, body, posture, and gesture, and four pragmatic task designs for driving understanding. To thoroughly explore AIDE, we provide experimental benchmarks on three kinds of baseline frameworks via extensive methods. Moreover, two fusion strategies are introduced to give new insights into learning effective multi-stream/modal representations. We also systematically investigate the importance and rationality of the key components in AIDE and benchmarks. The project link is https://github.com/ydk122024/AIDE.
</details>
<details>
<summary>摘要</summary>
驾驶员分心已成为过去十年内最重要的严重交通事故原因之一。尽管激发驾驶员视觉系统的发展，但由于缺乏全面的感知数据集，道路安全和交通安全仍然受到限制。本文提出了一个帮助驾驶员观察 dataset（AIDE），该dataset考虑了车内和车外情况的上下文信息，并包括驾驶员和场景的多视图设置、面部、身体、姿势和手势的多模式注解、以及适用于驾驶理解的四种实用任务设计。为了全面探索AIDE，我们提供了三种基eline框架的实验均衡，以及两种 fusión策略，以获得有效的多流/多模式表示。此外，我们系统地调查了AIDE和基eline的关键组件的重要性和合理性。项目链接：https://github.com/ydk122024/AIDE。
</details></li>
</ul>
<hr>
<h2 id="Spatio-Temporal-Domain-Awareness-for-Multi-Agent-Collaborative-Perception"><a href="#Spatio-Temporal-Domain-Awareness-for-Multi-Agent-Collaborative-Perception" class="headerlink" title="Spatio-Temporal Domain Awareness for Multi-Agent Collaborative Perception"></a>Spatio-Temporal Domain Awareness for Multi-Agent Collaborative Perception</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13929">http://arxiv.org/abs/2307.13929</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ydk122024/SCOPE">https://github.com/ydk122024/SCOPE</a></li>
<li>paper_authors: Kun Yang, Dingkang Yang, Jingyu Zhang, Mingcheng Li, Yang Liu, Jing Liu, Hanqi Wang, Peng Sun, Liang Song</li>
<li>for: 提高自动驾驶车辆的感知性能</li>
<li>methods: 提出了一种新的协同感知框架（SCOPE），通过综合考虑多个agent的空间和时间特征来提高目标agent的感知</li>
<li>results: 对实际和模拟的协同3D物体检测任务进行了广泛的实验，证明了我们的方法的优越性和必要性<details>
<summary>Abstract</summary>
Multi-agent collaborative perception as a potential application for vehicle-to-everything communication could significantly improve the perception performance of autonomous vehicles over single-agent perception. However, several challenges remain in achieving pragmatic information sharing in this emerging research. In this paper, we propose SCOPE, a novel collaborative perception framework that aggregates the spatio-temporal awareness characteristics across on-road agents in an end-to-end manner. Specifically, SCOPE has three distinct strengths: i) it considers effective semantic cues of the temporal context to enhance current representations of the target agent; ii) it aggregates perceptually critical spatial information from heterogeneous agents and overcomes localization errors via multi-scale feature interactions; iii) it integrates multi-source representations of the target agent based on their complementary contributions by an adaptive fusion paradigm. To thoroughly evaluate SCOPE, we consider both real-world and simulated scenarios of collaborative 3D object detection tasks on three datasets. Extensive experiments demonstrate the superiority of our approach and the necessity of the proposed components.
</details>
<details>
<summary>摘要</summary>
多智能合作感知作为自动驾驶车辆与所有东西通信的潜在应用，可以 significatively 提高自动驾驶车辆的感知性能。然而，在实现这项新研究领域中，仍有许多挑战。在这篇论文中，我们提出了 SCOPE，一种新的合作感知框架，可以在综合方式上聚合路上智能机器人的空间时间意识特征。具体来说，SCOPE具有以下三大优势：1. 它考虑有效的时间上下文semantic见解，以提高目标机器人的当前表示;2. 它聚合异ogeneous智能机器人的感知核心空间信息，并通过多尺度特征互动来超越地理化错误;3. 它通过适应融合方式，将多个来源的目标机器人表示融合，以便充分利用它们的补做贡献。为了全面评估 SCOPE，我们在三个数据集上进行了合作3D物体检测任务的实际和 simulated 实验。广泛的实验结果表明我们的方法的优越性，以及提案的组件的必要性。
</details></li>
</ul>
<hr>
<h2 id="DFR-Net-Density-Feature-Refinement-Network-for-Image-Dehazing-Utilizing-Haze-Density-Difference"><a href="#DFR-Net-Density-Feature-Refinement-Network-for-Image-Dehazing-Utilizing-Haze-Density-Difference" class="headerlink" title="DFR-Net: Density Feature Refinement Network for Image Dehazing Utilizing Haze Density Difference"></a>DFR-Net: Density Feature Refinement Network for Image Dehazing Utilizing Haze Density Difference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13927">http://arxiv.org/abs/2307.13927</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhongze Wang, Haitao Zhao, Lujian Yao, Jingchao Peng, Kaijie Zhao<br>for: 这个论文主要用于提高雾度缓解方法的性能，特别是利用雾度差异来提高雾度特征的精度。methods: 该方法使用了一种名为全球分支（GB）和本地分支（LB）的树 структуры，其中GB使用了同构网络进行特征提取，并提出了全球雾度特征纠正模块（GDFR）来更新全球特征。LB则是利用本地雾度差异来更新本地特征，并引入了中间雾度差异feedforward（IDRF）模块。results: 该方法在多个数据集上达到了现有方法的最佳性能，并且能够更好地处理具有不同雾度差异的图像。<details>
<summary>Abstract</summary>
In image dehazing task, haze density is a key feature and affects the performance of dehazing methods. However, some of the existing methods lack a comparative image to measure densities, and others create intermediate results but lack the exploitation of their density differences, which can facilitate perception of density. To address these deficiencies, we propose a density-aware dehazing method named Density Feature Refinement Network (DFR-Net) that extracts haze density features from density differences and leverages density differences to refine density features. In DFR-Net, we first generate a proposal image that has lower overall density than the hazy input, bringing in global density differences. Additionally, the dehazing residual of the proposal image reflects the level of dehazing performance and provides local density differences that indicate localized hard dehazing or high density areas. Subsequently, we introduce a Global Branch (GB) and a Local Branch (LB) to achieve density-awareness. In GB, we use Siamese networks for feature extraction of hazy inputs and proposal images, and we propose a Global Density Feature Refinement (GDFR) module that can refine features by pushing features with different global densities further away. In LB, we explore local density features from the dehazing residuals between hazy inputs and proposal images and introduce an Intermediate Dehazing Residual Feedforward (IDRF) module to update local features and pull them closer to clear image features. Sufficient experiments demonstrate that the proposed method achieves results beyond the state-of-the-art methods on various datasets.
</details>
<details>
<summary>摘要</summary>
在图像霾除任务中，霾 densities 是关键特征，影响霾除方法的性能。然而，一些现有方法缺乏对比图像，而其他方法创造了中间结果，但缺乏利用它们的density differences 来促进霾除性能。为解决这些不足，我们提出了一种名为 density feature refinement network (DFR-Net) 的霾除方法，它从 density differences 中提取霾 densities 特征，并利用 density differences 来精细化霾 densities 特征。在 DFR-Net 中，我们首先生成一个 proposal 图像，其全体density 较低于霾输入图像，从而带来全局 density differences。此外，提取霾除 residual 的 proposal 图像反映了霾除性能的水平，并提供了本地 density differences，表示本地强霾或高density 区域。接着，我们引入了全球分支 (GB) 和本地分支 (LB)，以实现density-awareness。在 GB 中，我们使用 Siamese 网络 для霾输入图像和提案图像的特征提取，并提出了全球density feature refinement (GDFR) 模块，可以通过推动不同全局density 的特征更远的方式来精细化特征。在 LB 中，我们探索本地霾 densities 特征从霾除 residual 中的霾输入图像和提案图像之间的差异，并引入了中间霾除 residual feedforward (IDRF) 模块来更新本地特征并吸引它们更近于清晰图像特征。充分的实验结果表明，我们的方法可以在不同的 dataset 上达到现有方法的 state-of-the-art 性能。
</details></li>
</ul>
<hr>
<h2 id="EasyNet-An-Easy-Network-for-3D-Industrial-Anomaly-Detection"><a href="#EasyNet-An-Easy-Network-for-3D-Industrial-Anomaly-Detection" class="headerlink" title="EasyNet: An Easy Network for 3D Industrial Anomaly Detection"></a>EasyNet: An Easy Network for 3D Industrial Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13925">http://arxiv.org/abs/2307.13925</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruitao Chen, Guoyang Xie, Jiaqi Liu, Jinbao Wang, Ziqi Luo, Jinfan Wang, Feng Zheng</li>
<li>for: 这个研究旨在提高工业制程中的3D异常检测，以应对现有的缺陷。</li>
<li>methods: 我们提出了一个简单易用的网络（称为EasyNet），不使用预训模型和内存库。我们设计了一个多维多模式特征编码解oder，以精准地重建异常区域的分类图像，并透过多模式异常分类网络获得精确的异常地图。最后，我们提出了一个注意力基于信息熵融合模组，用于Feature融合，使其适合实时部署。</li>
<li>results: 实验结果显示，EasyNet可以在不使用预训模型和内存库的情况下，达到92.6%的异常检测AUROC。此外，EasyNet比现有的方法更快，在Tesla V100 GPU上 achieve 94.55 FPS的高帧率。<details>
<summary>Abstract</summary>
3D anomaly detection is an emerging and vital computer vision task in industrial manufacturing (IM). Recently many advanced algorithms have been published, but most of them cannot meet the needs of IM. There are several disadvantages: i) difficult to deploy on production lines since their algorithms heavily rely on large pre-trained models; ii) hugely increase storage overhead due to overuse of memory banks; iii) the inference speed cannot be achieved in real-time. To overcome these issues, we propose an easy and deployment-friendly network (called EasyNet) without using pre-trained models and memory banks: firstly, we design a multi-scale multi-modality feature encoder-decoder to accurately reconstruct the segmentation maps of anomalous regions and encourage the interaction between RGB images and depth images; secondly, we adopt a multi-modality anomaly segmentation network to achieve a precise anomaly map; thirdly, we propose an attention-based information entropy fusion module for feature fusion during inference, making it suitable for real-time deployment. Extensive experiments show that EasyNet achieves an anomaly detection AUROC of 92.6% without using pre-trained models and memory banks. In addition, EasyNet is faster than existing methods, with a high frame rate of 94.55 FPS on a Tesla V100 GPU.
</details>
<details>
<summary>摘要</summary>
三维异常检测是现代计算机视觉任务中的一个突出和生命关键任务，在工业生产中扮演着重要的角色。Recently many advanced algorithms have been published, but most of them cannot meet the needs of IM. There are several disadvantages: i) difficult to deploy on production lines since their algorithms heavily rely on large pre-trained models; ii) hugely increase storage overhead due to overuse of memory banks; iii) the inference speed cannot be achieved in real-time. To overcome these issues, we propose an easy and deployment-friendly network (called EasyNet) without using pre-trained models and memory banks: firstly, we design a multi-scale multi-modality feature encoder-decoder to accurately reconstruct the segmentation maps of anomalous regions and encourage the interaction between RGB images and depth images; secondly, we adopt a multi-modality anomaly segmentation network to achieve a precise anomaly map; thirdly, we propose an attention-based information entropy fusion module for feature fusion during inference, making it suitable for real-time deployment. Extensive experiments show that EasyNet achieves an anomaly detection AUROC of 92.6% without using pre-trained models and memory banks. In addition, EasyNet is faster than existing methods, with a high frame rate of 94.55 FPS on a Tesla V100 GPU.
</details></li>
</ul>
<hr>
<h2 id="trajdata-A-Unified-Interface-to-Multiple-Human-Trajectory-Datasets"><a href="#trajdata-A-Unified-Interface-to-Multiple-Human-Trajectory-Datasets" class="headerlink" title="trajdata: A Unified Interface to Multiple Human Trajectory Datasets"></a>trajdata: A Unified Interface to Multiple Human Trajectory Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13924">http://arxiv.org/abs/2307.13924</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nvlabs/trajdata">https://github.com/nvlabs/trajdata</a></li>
<li>paper_authors: Boris Ivanovic, Guanyu Song, Igor Gilitschenski, Marco Pavone</li>
<li>for: 本研究旨在提供一个统一的人行轨迹数据接口，以便研究人行轨迹预测和自动驾驶车辆的动作识别。</li>
<li>methods: 本研究使用了多个大规模的实际世界人行轨迹数据集，并提供了一个简单、统一的轨迹和地图数据表示方式和API。</li>
<li>results: 本研究通过对现有轨迹数据集进行广泛的实验性评估，为研究人行轨迹预测和自动驾驶车辆的动作识别提供了深入的数据理解，并提出了未来数据集的建议。<details>
<summary>Abstract</summary>
The field of trajectory forecasting has grown significantly in recent years, partially owing to the release of numerous large-scale, real-world human trajectory datasets for autonomous vehicles (AVs) and pedestrian motion tracking. While such datasets have been a boon for the community, they each use custom and unique data formats and APIs, making it cumbersome for researchers to train and evaluate methods across multiple datasets. To remedy this, we present trajdata: a unified interface to multiple human trajectory datasets. At its core, trajdata provides a simple, uniform, and efficient representation and API for trajectory and map data. As a demonstration of its capabilities, in this work we conduct a comprehensive empirical evaluation of existing trajectory datasets, providing users with a rich understanding of the data underpinning much of current pedestrian and AV motion forecasting research, and proposing suggestions for future datasets from these insights. trajdata is permissively licensed (Apache 2.0) and can be accessed online at https://github.com/NVlabs/trajdata
</details>
<details>
<summary>摘要</summary>
领域趋势预测在最近几年内得到了大量的研究和应用，部分归功于许多大规模的实际世界人 trajectory 数据集（AV 和行人运动跟踪）的发布。而这些数据集各自使用自定义的数据格式和 API，使研究人员在多个数据集之间训练和评估方法变得繁琐。为了解决这个问题，我们提出了 trajdata：一个统一的界面，用于多个人 trajectory 数据集。trajdata 的核心思想是提供简单、统一、高效的数据表示和 API，用于 trajectory 和地图数据。在这个工作中，我们进行了大量的实验性评估，为用户提供了许多现有的 pedestrian 和 AV 运动预测研究的数据基础知识，并提出了未来数据集的建议。trajdata 采用 Apache 2.0 许可证，可在 GitHub 上获取，详细信息请参考 <https://github.com/NVlabs/trajdata>。
</details></li>
</ul>
<hr>
<h2 id="Points-to-3D-Bridging-the-Gap-between-Sparse-Points-and-Shape-Controllable-Text-to-3D-Generation"><a href="#Points-to-3D-Bridging-the-Gap-between-Sparse-Points-and-Shape-Controllable-Text-to-3D-Generation" class="headerlink" title="Points-to-3D: Bridging the Gap between Sparse Points and Shape-Controllable Text-to-3D Generation"></a>Points-to-3D: Bridging the Gap between Sparse Points and Shape-Controllable Text-to-3D Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13908">http://arxiv.org/abs/2307.13908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chaohui Yu, Qiang Zhou, Jingliang Li, Zhe Zhang, Zhibin Wang, Fan Wang</li>
<li>for: 提供一种基于稀疏3D点 cloud的文本到3D生成框架，以填补现有方法的束缚和不可控性问题。</li>
<li>methods: 使用Point-E生成的稀疏3D点云作为几何假设，并通过维护点云导向损失来适应NeRF的几何。同时，通过控制NeRF的外观分布来提高视角一致性。</li>
<li>results: 比较和分析表明，Points-to-3D可以提高视角一致性并实现良好的形状控制，从而为文本到3D生成提供一个新的控制方法。<details>
<summary>Abstract</summary>
Text-to-3D generation has recently garnered significant attention, fueled by 2D diffusion models trained on billions of image-text pairs. Existing methods primarily rely on score distillation to leverage the 2D diffusion priors to supervise the generation of 3D models, e.g., NeRF. However, score distillation is prone to suffer the view inconsistency problem, and implicit NeRF modeling can also lead to an arbitrary shape, thus leading to less realistic and uncontrollable 3D generation. In this work, we propose a flexible framework of Points-to-3D to bridge the gap between sparse yet freely available 3D points and realistic shape-controllable 3D generation by distilling the knowledge from both 2D and 3D diffusion models. The core idea of Points-to-3D is to introduce controllable sparse 3D points to guide the text-to-3D generation. Specifically, we use the sparse point cloud generated from the 3D diffusion model, Point-E, as the geometric prior, conditioned on a single reference image. To better utilize the sparse 3D points, we propose an efficient point cloud guidance loss to adaptively drive the NeRF's geometry to align with the shape of the sparse 3D points. In addition to controlling the geometry, we propose to optimize the NeRF for a more view-consistent appearance. To be specific, we perform score distillation to the publicly available 2D image diffusion model ControlNet, conditioned on text as well as depth map of the learned compact geometry. Qualitative and quantitative comparisons demonstrate that Points-to-3D improves view consistency and achieves good shape controllability for text-to-3D generation. Points-to-3D provides users with a new way to improve and control text-to-3D generation.
</details>
<details>
<summary>摘要</summary>
文本到3D生成最近受到了广泛关注，受到了2D扩散模型在数百万张图像和文本对的训练。现有方法主要通过分数散熔炼来利用2D扩散先验来监督3D模型的生成，例如NeRF。然而，分数散熔炼容易受到视角不一致问题的影响，而半 implicit NeRF模型也可能导致不可预测的3D形态，因此导致文本到3D生成的真实性和可控性受到限制。在这种情况下，我们提出了一种灵活的点 clouds到3D框架，用于跨越稀疏可得到的3D点 cloud和真实形态可控的3D生成知识。核心思想是通过控制可控稀疏3D点来指导文本到3D生成。我们使用由3D扩散模型Point-E生成的稀疏点云作为几何优先，根据单个参考图像进行条件。为了更好地利用稀疏3D点，我们提出了一种高效的点云引导损失，以适应NeRF的几何进行适应。此外，我们还提出了优化NeRF以实现更加视角一致的外观。具体来说，我们通过分数散熔炼来ControlNet的2D图像扩散模型进行学习，并在文本和深度图中获得学习的紧凑geometry。经过质量和量度比较，我们发现Point-to-3D可以提高视角一致和实现好的形态可控性，提供了一种新的方法来改进和控制文本到3D生成。
</details></li>
</ul>
<hr>
<h2 id="YOLOBench-Benchmarking-Efficient-Object-Detectors-on-Embedded-Systems"><a href="#YOLOBench-Benchmarking-Efficient-Object-Detectors-on-Embedded-Systems" class="headerlink" title="YOLOBench: Benchmarking Efficient Object Detectors on Embedded Systems"></a>YOLOBench: Benchmarking Efficient Object Detectors on Embedded Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13901">http://arxiv.org/abs/2307.13901</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/deeplite/deeplite-torch-zoo">https://github.com/deeplite/deeplite-torch-zoo</a></li>
<li>paper_authors: Ivan Lazarevich, Matteo Grimaldi, Ravish Kumar, Saptarshi Mitra, Shahrukh Khan, Sudhakar Sah</li>
<li>for: 本研究为了提供一个包含550多个YOLO基于物体检测模型的benchmark，以及4种不同的嵌入式硬件平台（x86 CPU、ARM CPU、Nvidia GPU、NPU）上的4个数据集。</li>
<li>methods: 本研究使用了一种控制性的比较方法来评估不同的YOLO基于一stage检测器，并在一个固定的训练环境下收集了准确率和延迟数据。</li>
<li>results: 研究发现，如果将现代检测头和训练技术integrated into the learning process，包括older模型如YOLOv3和YOLOv4在内的多个YOLO系列模型可以实现良好的准确率-延迟质量平衡。此外，研究还评估了在YOLOBench上使用的训练成本为零的准确率估计器，并发现其中一些可以有效地预测Pareto优化的检测模型。<details>
<summary>Abstract</summary>
We present YOLOBench, a benchmark comprised of 550+ YOLO-based object detection models on 4 different datasets and 4 different embedded hardware platforms (x86 CPU, ARM CPU, Nvidia GPU, NPU). We collect accuracy and latency numbers for a variety of YOLO-based one-stage detectors at different model scales by performing a fair, controlled comparison of these detectors with a fixed training environment (code and training hyperparameters). Pareto-optimality analysis of the collected data reveals that, if modern detection heads and training techniques are incorporated into the learning process, multiple architectures of the YOLO series achieve a good accuracy-latency trade-off, including older models like YOLOv3 and YOLOv4. We also evaluate training-free accuracy estimators used in neural architecture search on YOLOBench and demonstrate that, while most state-of-the-art zero-cost accuracy estimators are outperformed by a simple baseline like MAC count, some of them can be effectively used to predict Pareto-optimal detection models. We showcase that by using a zero-cost proxy to identify a YOLO architecture competitive against a state-of-the-art YOLOv8 model on a Raspberry Pi 4 CPU. The code and data are available at https://github.com/Deeplite/deeplite-torch-zoo
</details>
<details>
<summary>摘要</summary>
我们介绍YOLOBench，一个包含550多个YOLO基于物件探测模型的benchmark，采用4个不同的 datasets和4个不同的嵌入式硬件平台（x86 CPU、ARM CPU、Nvidia GPU、NPU）。我们收集了一些YOLO基于一阶探测器的精度和延迟数据，并通过一个公平的比较方式，以确定这些探测器在不同的模型 scales 中的精度-延迟贸易。我们通过 pareto-optimality 分析所收集的数据，发现如果应用现代探测头和训练技术，多个YOLO系列的架构都可以取得良好的精度-延迟贸易，包括旧的模型YOLOv3和YOLOv4。我们还评估了用于神经建构搜寻的训练-自由精度估计器，并发现大多数现有的零成本精度估计器被简单的基准值MAC Count所出perform。我们还示出了使用零成本代理来识别YOLO架构，与现代YOLOv8模型在Raspberry Pi 4 CPU上竞争。我们的代码和数据可以在https://github.com/Deeplite/deeplite-torch-zoo上取得。
</details></li>
</ul>
<hr>
<h2 id="AViT-Adapting-Vision-Transformers-for-Small-Skin-Lesion-Segmentation-Datasets"><a href="#AViT-Adapting-Vision-Transformers-for-Small-Skin-Lesion-Segmentation-Datasets" class="headerlink" title="AViT: Adapting Vision Transformers for Small Skin Lesion Segmentation Datasets"></a>AViT: Adapting Vision Transformers for Small Skin Lesion Segmentation Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13897">http://arxiv.org/abs/2307.13897</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/siyi-wind/avit">https://github.com/siyi-wind/avit</a></li>
<li>paper_authors: Siyi Du, Nourhan Bayasi, Ghassan Harmarneh, Rafeef Garbi</li>
<li>for: 这个论文主要针对皮肤损伤分割（SLS）问题，旨在提高皮肤损伤分割的精度和效率。</li>
<li>methods: 这个论文提出了一种新的策略，即将预训练的视transformer（ViT）转移到SLS任务上，并通过附加轻量级模块（adapters）来修改特征表示。此外，论文还使用了一个浅层Convolutional Neural Network（CNN）作为提示生成器，从输入图像中生成提示embedding，以便指导分割任务。</li>
<li>results: 根据论文的实验结果，AViT可以在4个皮肤损伤Dataset上达到与当前最佳性能相当或更高的性能，而且具有许多 fewer Trainable parameters。<details>
<summary>Abstract</summary>
Skin lesion segmentation (SLS) plays an important role in skin lesion analysis. Vision transformers (ViTs) are considered an auspicious solution for SLS, but they require more training data compared to convolutional neural networks (CNNs) due to their inherent parameter-heavy structure and lack of some inductive biases. To alleviate this issue, current approaches fine-tune pre-trained ViT backbones on SLS datasets, aiming to leverage the knowledge learned from a larger set of natural images to lower the amount of skin training data needed. However, fully fine-tuning all parameters of large backbones is computationally expensive and memory intensive. In this paper, we propose AViT, a novel efficient strategy to mitigate ViTs' data-hunger by transferring any pre-trained ViTs to the SLS task. Specifically, we integrate lightweight modules (adapters) within the transformer layers, which modulate the feature representation of a ViT without updating its pre-trained weights. In addition, we employ a shallow CNN as a prompt generator to create a prompt embedding from the input image, which grasps fine-grained information and CNN's inductive biases to guide the segmentation task on small datasets. Our quantitative experiments on 4 skin lesion datasets demonstrate that AViT achieves competitive, and at times superior, performance to SOTA but with significantly fewer trainable parameters. Our code is available at https://github.com/siyi-wind/AViT.
</details>
<details>
<summary>摘要</summary>
皮肤损伤分割（SLS）在皮肤损伤分析中扮演着重要的角色。视transformer（ViTs）被视为有利的解决方案，但它们需要更多的训练数据 Compared to convolutional neural networks (CNNs) due to their inherent parameter-heavy structure and lack of some inductive biases. To alleviate this issue, current approaches fine-tune pre-trained ViT backbones on SLS datasets, aiming to leverage the knowledge learned from a larger set of natural images to lower the amount of skin training data needed. However, fully fine-tuning all parameters of large backbones is computationally expensive and memory intensive.在这篇论文中，我们提出了一种新的有效策略，以降低ViTs的数据喂食量。具体来说，我们在转换层中添加轻量级模块（适配器），以 modify the feature representation of a ViT without updating its pre-trained weights. 此外，我们使用一个浅深的CNN作为提示生成器，以从输入图像中生成提示embedding，这个embedding捕捉了细节信息和CNN的适应性来导航分割任务。我们的量化实验表明，AViT在4个皮肤损伤数据集上具有竞争力和时刻优于SOTA的性能，但具有显著更少的可训练参数。我们的代码可以在https://github.com/siyi-wind/AViT中找到。
</details></li>
</ul>
<hr>
<h2 id="Pretrained-Deep-2-5D-Models-for-Efficient-Predictive-Modeling-from-Retinal-OCT"><a href="#Pretrained-Deep-2-5D-Models-for-Efficient-Predictive-Modeling-from-Retinal-OCT" class="headerlink" title="Pretrained Deep 2.5D Models for Efficient Predictive Modeling from Retinal OCT"></a>Pretrained Deep 2.5D Models for Efficient Predictive Modeling from Retinal OCT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13865">http://arxiv.org/abs/2307.13865</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taha Emre, Marzieh Oghbaie, Arunava Chakravarty, Antoine Rivail, Sophie Riedl, Julia Mai, Hendrik P. N. Scholl, Sobha Sivaprasad, Daniel Rueckert, Andrew Lotery, Ursula Schmidt-Erfurth, Hrvoje Bogunović</li>
<li>for: 这篇论文旨在探讨如何使用2.5D架构来优化医疗影像处理中的深度学习模型，以提高模型的性能和数据效率。</li>
<li>methods: 本论文使用了2.5D架构， combining 2D和3D技术，以及Convolutional Neural Networks (CNNs)、Long Short-Term Memory (LSTM)和Transformers等方法，并且将2D非对称预训练方法应用到2.5D架构中，以提高模型的性能和数据效率。</li>
<li>results: 本论文透过实验表明，2.5D架构可以优化医疗影像处理中的深度学习模型，并且可以预测在6个月内进展到泼血性macular degeneration (AMD)的风险，在两个大量 longitudinal OCT数据集上。<details>
<summary>Abstract</summary>
In the field of medical imaging, 3D deep learning models play a crucial role in building powerful predictive models of disease progression. However, the size of these models presents significant challenges, both in terms of computational resources and data requirements. Moreover, achieving high-quality pretraining of 3D models proves to be even more challenging. To address these issues, hybrid 2.5D approaches provide an effective solution for utilizing 3D volumetric data efficiently using 2D models. Combining 2D and 3D techniques offers a promising avenue for optimizing performance while minimizing memory requirements. In this paper, we explore 2.5D architectures based on a combination of convolutional neural networks (CNNs), long short-term memory (LSTM), and Transformers. In addition, leveraging the benefits of recent non-contrastive pretraining approaches in 2D, we enhanced the performance and data efficiency of 2.5D techniques even further. We demonstrate the effectiveness of architectures and associated pretraining on a task of predicting progression to wet age-related macular degeneration (AMD) within a six-month period on two large longitudinal OCT datasets.
</details>
<details>
<summary>摘要</summary>
医疗影像领域中，3D深度学习模型在建立疾病进程预测的力度环境中扮演着关键的角色。然而，这些模型的大小带来了计算资源和数据需求的挑战。此外，获得高质量预训练3D模型也是非常困难的。为解决这些问题，混合2.5D方法提供了有效的解决方案，能够有效地利用3DVolume数据，同时减少内存需求。在这篇论文中，我们探索了基于Convolutional Neural Networks（CNN）、Long Short-Term Memory（LSTM）和Transformers的2.5D架构，并利用了2D非对抗预训练方法的优点，进一步提高了2.5D技术的性能和数据效率。我们在两个大 longitudinal OCT数据集上进行了预测湿性年龄相关macular degeneration（AMD）在6个月期内的进程预测任务，以证明我们的架构和预训练方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="On-the-unreasonable-vulnerability-of-transformers-for-image-restoration-–-and-an-easy-fix"><a href="#On-the-unreasonable-vulnerability-of-transformers-for-image-restoration-–-and-an-easy-fix" class="headerlink" title="On the unreasonable vulnerability of transformers for image restoration – and an easy fix"></a>On the unreasonable vulnerability of transformers for image restoration – and an easy fix</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13856">http://arxiv.org/abs/2307.13856</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shashank Agnihotri, Kanchana Vaishnavi Gandikota, Julia Grabinski, Paramanand Chandramouli, Margret Keuper</li>
<li>for: 这个论文 investigate the adversarial robustness of Vision Transformers (ViTs) in image restoration tasks.</li>
<li>methods: 他们使用 Projected Gradient Descent (PGD) 和 CosPGD 等 adversarial attack 来评估 ViTs 的 Robustness.</li>
<li>results: 他们发现 ViTs 在实际图像Deblurring task 中高度易受到 adversarial attack 的影响，而且 adversarial training 可以提高 Restormer 的 Robustness, but other networks 的 result  less promising.<details>
<summary>Abstract</summary>
Following their success in visual recognition tasks, Vision Transformers(ViTs) are being increasingly employed for image restoration. As a few recent works claim that ViTs for image classification also have better robustness properties, we investigate whether the improved adversarial robustness of ViTs extends to image restoration. We consider the recently proposed Restormer model, as well as NAFNet and the "Baseline network" which are both simplified versions of a Restormer. We use Projected Gradient Descent (PGD) and CosPGD, a recently proposed adversarial attack tailored to pixel-wise prediction tasks for our robustness evaluation. Our experiments are performed on real-world images from the GoPro dataset for image deblurring. Our analysis indicates that contrary to as advocated by ViTs in image classification works, these models are highly susceptible to adversarial attacks. We attempt to improve their robustness through adversarial training. While this yields a significant increase in robustness for Restormer, results on other networks are less promising. Interestingly, the design choices in NAFNet and Baselines, which were based on iid performance, and not on robust generalization, seem to be at odds with the model robustness. Thus, we investigate this further and find a fix.
</details>
<details>
<summary>摘要</summary>
根据视觉Recognition任务的成功，视觉Transformers（ViTs）现在在图像恢复领域得到了越来越多的应用。一些最近的研究表明，ViTs也有更好的鲁棒性质量，因此我们想 investigate这点是否扩展到图像恢复领域。我们考虑了Recently proposed Restormer模型，以及NAFNet和基eline网络，它们都是Restormer的简化版本。我们使用Projected Gradient Descent（PGD）和CosPGD，一种专门为像素精度预测任务设计的攻击方法来评估这些模型的鲁棒性。我们的实验使用了GoPro dataset上的实际图像锐化任务。我们的分析表明，与图像分类任务中所advocated的ViTs不同，这些模型对攻击很容易受到影响。我们通过对这些模型进行鲁棒训练来提高其鲁棒性。虽然这对Restormer模型具有显著的效果，但对NAFNet和基eline网络来说，结果较为吃亏。我们进一步调查这个问题，并发现一些design choice在NAFNet和基eline网络中，它们是基于独立性能而不是鲁棒泛化的设计，与模型的鲁棒性相冲突。因此，我们进一步调查这个问题，并发现一些解决方案。
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Sharpened-Cosine-Similarity"><a href="#Exploring-the-Sharpened-Cosine-Similarity" class="headerlink" title="Exploring the Sharpened Cosine Similarity"></a>Exploring the Sharpened Cosine Similarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13855">http://arxiv.org/abs/2307.13855</a></li>
<li>repo_url: None</li>
<li>paper_authors: Skyler Wu, Fred Lu, Edward Raff, James Holt</li>
<li>for: 检查SCS可以取代卷积层来提高图像识别器的性能。</li>
<li>methods: 研究SCS参数的行为和可以作为卷积层的替代方案，并 benchmarked on CIFAR-10 多个CNN架构。</li>
<li>results: SCS可能不会带来明显的增加精度，但可能将特征更加易于理解；在某些情况下，SCS可能会增加防火墙性。<details>
<summary>Abstract</summary>
Convolutional layers have long served as the primary workhorse for image classification. Recently, an alternative to convolution was proposed using the Sharpened Cosine Similarity (SCS), which in theory may serve as a better feature detector. While multiple sources report promising results, there has not been to date a full-scale empirical analysis of neural network performance using these new layers. In our work, we explore SCS's parameter behavior and potential as a drop-in replacement for convolutions in multiple CNN architectures benchmarked on CIFAR-10. We find that while SCS may not yield significant increases in accuracy, it may learn more interpretable representations. We also find that, in some circumstances, SCS may confer a slight increase in adversarial robustness.
</details>
<details>
<summary>摘要</summary>
convolutional layers 长期作为图像分类的主要工具。最近，一种使用简化 cosine similarity（SCS）的替代方案被提出，这 theoretically 可能是一个更好的特征检测器。虽然多个来源报告了 promising results，但到目前为止没有一个全面的 empirical analysis of neural network performance 使用这些新层。在我们的工作中，我们探索 SCS 的参数行为和作为替换 convolutions 的多个 CNN 架构在 CIFAR-10 上的性能。我们发现，虽然 SCS 可能不会导致显著的准确率提高，但它可能学习更易于理解的表示。我们还发现，在某些情况下，SCS 可能会提供一个 slight 的 adversarial robustness 提高。
</details></li>
</ul>
<hr>
<h2 id="SplitFed-resilience-to-packet-loss-Where-to-split-that-is-the-question"><a href="#SplitFed-resilience-to-packet-loss-Where-to-split-that-is-the-question" class="headerlink" title="SplitFed resilience to packet loss: Where to split, that is the question"></a>SplitFed resilience to packet loss: Where to split, that is the question</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13851">http://arxiv.org/abs/2307.13851</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chamani Shiranthika, Zahra Hafezi Kafshgari, Parvaneh Saeedi, Ivan V. Bajić</li>
<li>for: 本文研究了Split Federated Learning（SplitFed或SFL）的可靠性问题，具体来说是在通信链路上 packet loss 的影响下对 SFL 的性能的研究。</li>
<li>methods: 本文使用了多种 SFL 聚合策略，并在不同的拆分点（ shallow split 和 deep split）进行了测试，以判断拆分点是否对最终模型的准确率产生 statistically significant 的影响。</li>
<li>results: 实验结果表明，使用 deeper split point 可以获得更高的准确率。<details>
<summary>Abstract</summary>
Decentralized machine learning has broadened its scope recently with the invention of Federated Learning (FL), Split Learning (SL), and their hybrids like Split Federated Learning (SplitFed or SFL). The goal of SFL is to reduce the computational power required by each client in FL and parallelize SL while maintaining privacy. This paper investigates the robustness of SFL against packet loss on communication links. The performance of various SFL aggregation strategies is examined by splitting the model at two points -- shallow split and deep split -- and testing whether the split point makes a statistically significant difference to the accuracy of the final model. Experiments are carried out on a segmentation model for human embryo images and indicate the statistically significant advantage of a deeper split point.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用分布式机器学习的许多应用程序在最近几年内得到扩展，包括联邦学习（FL）、分解学习（SL）以及其它混合技术，如分解联邦学习（SplitFed或SFL）。SFL的目标是降低每个客户端在FL中所需的计算能力，并平行化SL，同时保持隐私。这篇论文研究了SFL在通信链路上 packet loss 的影响，并对不同的SFL聚合策略进行了测试，以确定它们在最终模型的准确性方面是否存在 statistically significant 的差异。实验使用了人类胚胎图像分割模型，并显示了深度分割点能够获得 statistically significant 的优势。Note: " statistically significant" in Chinese is "统计学上有意义" (tòng jí yǐng xìng)
</details></li>
</ul>
<hr>
<h2 id="CosSIF-Cosine-similarity-based-image-filtering-to-overcome-low-inter-class-variation-in-synthetic-medical-image-datasets"><a href="#CosSIF-Cosine-similarity-based-image-filtering-to-overcome-low-inter-class-variation-in-synthetic-medical-image-datasets" class="headerlink" title="CosSIF: Cosine similarity-based image filtering to overcome low inter-class variation in synthetic medical image datasets"></a>CosSIF: Cosine similarity-based image filtering to overcome low inter-class variation in synthetic medical image datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13842">http://arxiv.org/abs/2307.13842</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mominul-ssv/cossif">https://github.com/mominul-ssv/cossif</a></li>
<li>paper_authors: Mominul Islam, Hasib Zunair, Nabeel Mohammed<br>for: 这个研究旨在提高医疗图像分析中的深度学习模型效能，特别是在没有明显间类差异的医疗图像资料集上。methods: 本研究提出了一种新的筛选算法 called Cosine Similarity-based Image Filtering (CosSIF)，并在其基础上开发了两种筛选方法：Filtering Before GAN Training (FBGT) 和 Filtering After GAN Training (FAGT)。results: 实验结果显示，使用modern transformer和 convolutional-based networks并与 CosSIF 筛选方法可以实现substantial performance gain in various evaluation metrics。尤其是在 ISIC-2016 资料集上，FAGT 方法可以比基eline方法提高 sensitivity 1.59% 和 AUC 1.88%。在 HAM10000 资料集上，将 FABT 方法应用于过滤 synthetic images 可以提高 recall 13.75%，并且仅使用 FAGT 方法可以 дости得最大的准确率 94.44%。<details>
<summary>Abstract</summary>
Crafting effective deep learning models for medical image analysis is a complex task, particularly in cases where the medical image dataset lacks significant inter-class variation. This challenge is further aggravated when employing such datasets to generate synthetic images using generative adversarial networks (GANs), as the output of GANs heavily relies on the input data. In this research, we propose a novel filtering algorithm called Cosine Similarity-based Image Filtering (CosSIF). We leverage CosSIF to develop two distinct filtering methods: Filtering Before GAN Training (FBGT) and Filtering After GAN Training (FAGT). FBGT involves the removal of real images that exhibit similarities to images of other classes before utilizing them as the training dataset for a GAN. On the other hand, FAGT focuses on eliminating synthetic images with less discriminative features compared to real images used for training the GAN. Experimental results reveal that employing either the FAGT or FBGT method with modern transformer and convolutional-based networks leads to substantial performance gains in various evaluation metrics. FAGT implementation on the ISIC-2016 dataset surpasses the baseline method in terms of sensitivity by 1.59\% and AUC by 1.88\%. Furthermore, for the HAM10000 dataset, applying FABT outperforms the baseline approach in terms of recall by 13.75\%, and with the sole implementation of FAGT, achieves a maximum accuracy of 94.44\%.
</details>
<details>
<summary>摘要</summary>
制作深度学习模型用于医学影像分析是一个复杂的任务，特别在医学影像集lacks significant inter-class variation的情况下。这个挑战进一步加剧了在使用这些数据集来生成synthetic images using generative adversarial networks (GANs)时，GANs的输出 heavily relies on the input data。在这项研究中，我们提出了一种新的筛选算法called Cosine Similarity-based Image Filtering (CosSIF)。我们利用CosSIF开发了两种不同的筛选方法：Filtering Before GAN Training (FBGT)和Filtering After GAN Training (FAGT)。FBGT involves the removal of real images that exhibit similarities to images of other classes before using them as the training dataset for a GAN。 On the other hand, FAGT focuses on eliminating synthetic images with less discriminative features compared to real images used for training the GAN。实验结果表明，使用FABT或FBGT方法并与现代转换和卷积网络结合使用，可以实现明显的性能提升在多个评价指标中。FAGT实现在ISIC-2016数据集上超越基准方法，敏感性提升1.59%，AUC提升1.88%。此外，对HAM10000数据集应用FAGT，可以提高记忆率by 13.75%，并且只通过FAGT实现最高的准确率为94.44%。
</details></li>
</ul>
<hr>
<h2 id="A-real-time-material-breakage-detection-for-offshore-wind-turbines-based-on-improved-neural-network-algorithm"><a href="#A-real-time-material-breakage-detection-for-offshore-wind-turbines-based-on-improved-neural-network-algorithm" class="headerlink" title="A real-time material breakage detection for offshore wind turbines based on improved neural network algorithm"></a>A real-time material breakage detection for offshore wind turbines based on improved neural network algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13765">http://arxiv.org/abs/2307.13765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yantong Liu</li>
<li>for: 提高陆上风电机稳定性，为可持续能源产生做出了重要贡献。</li>
<li>methods: 使用高级版YOLOv8物体检测模型，配备卷积块注意模块（CBAM），进一步提高特征识别能力。</li>
<li>results: 通过使用5432张风电园和公共数据集进行严谨测试，实现了精度稳定性的显著提高，为陆上风电机维护做出了重要贡献。<details>
<summary>Abstract</summary>
The integrity of offshore wind turbines, pivotal for sustainable energy generation, is often compromised by surface material defects. Despite the availability of various detection techniques, limitations persist regarding cost-effectiveness, efficiency, and applicability. Addressing these shortcomings, this study introduces a novel approach leveraging an advanced version of the YOLOv8 object detection model, supplemented with a Convolutional Block Attention Module (CBAM) for improved feature recognition. The optimized loss function further refines the learning process. Employing a dataset of 5,432 images from the Saemangeum offshore wind farm and a publicly available dataset, our method underwent rigorous testing. The findings reveal a substantial enhancement in defect detection stability, marking a significant stride towards efficient turbine maintenance. This study's contributions illuminate the path for future research, potentially revolutionizing sustainable energy practices.
</details>
<details>
<summary>摘要</summary>
“陆上风电机的完整性，是可持续能源生产的重要因素，但常受到表面材料欠整问题的影响。尽管有许多检测技术可用，但还有许多限制，包括成本高、效率低和应用范围仅对某些类型的材料有效。本研究提出了一种新的方法，利用进步版的YOLOv8物体检测模型，并补助了一个卷积层注意模块（CBAM），以提高特征识别能力。另外，我们还对检测过程进行了优化损失函数。使用了5,432幅陆上风电机Saemangeum数据集和公开 disponibile数据集，我们对方法进行了严格的测试。发现的结果显示，我们的方法能够实现更高稳定性的欠整检测，创造了一个重要的进步，将来可能对可持续能源实践产生革命性的影响。本研究的贡献照明了未来研究的道路，并且将为可持续能源领域的发展带来新的希望。”Note that Simplified Chinese is used in mainland China, while Traditional Chinese is used in Taiwan and Hong Kong.
</details></li>
</ul>
<hr>
<h2 id="Implementing-and-Benchmarking-the-Locally-Competitive-Algorithm-on-the-Loihi-2-Neuromorphic-Processor"><a href="#Implementing-and-Benchmarking-the-Locally-Competitive-Algorithm-on-the-Loihi-2-Neuromorphic-Processor" class="headerlink" title="Implementing and Benchmarking the Locally Competitive Algorithm on the Loihi 2 Neuromorphic Processor"></a>Implementing and Benchmarking the Locally Competitive Algorithm on the Loihi 2 Neuromorphic Processor</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13762">http://arxiv.org/abs/2307.13762</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gavin Parpart, Sumedh R. Risbud, Garrett T. Kenyon, Yijing Watkins</li>
<li>for: 这研究旨在证明 neuromorphic processor 可以实现高效、低功耗的数据处理，尤其是在小型 робот、卫星等具有 strict SWaP 要求的应用中。</li>
<li>methods: 这研究使用了 Locally Competitive Algorithm (LCA) 在 neuromorphic processor 上进行了实现，并对 Loihi 2 processor 进行了 optimize。</li>
<li>results: 研究发现，使用 Loihi 2 processor 实现 LCA 的效率和速度比 CPU 和 GPU 设备更高，特别是在大 sparse penalty 下。此外，调整 LCA 参数可以提高性能。这些结果表明 neuromorphic processor 可以在资源受限的设备上进行高效、高精度的数据处理。<details>
<summary>Abstract</summary>
Neuromorphic processors have garnered considerable interest in recent years for their potential in energy-efficient and high-speed computing. The Locally Competitive Algorithm (LCA) has been utilized for power efficient sparse coding on neuromorphic processors, including the first Loihi processor. With the Loihi 2 processor enabling custom neuron models and graded spike communication, more complex implementations of LCA are possible. We present a new implementation of LCA designed for the Loihi 2 processor and perform an initial set of benchmarks comparing it to LCA on CPU and GPU devices. In these experiments LCA on Loihi 2 is orders of magnitude more efficient and faster for large sparsity penalties, while maintaining similar reconstruction quality. We find this performance improvement increases as the LCA parameters are tuned towards greater representation sparsity.   Our study highlights the potential of neuromorphic processors, particularly Loihi 2, in enabling intelligent, autonomous, real-time processing on small robots, satellites where there are strict SWaP (small, lightweight, and low power) requirements. By demonstrating the superior performance of LCA on Loihi 2 compared to conventional computing device, our study suggests that Loihi 2 could be a valuable tool in advancing these types of applications. Overall, our study highlights the potential of neuromorphic processors for efficient and accurate data processing on resource-constrained devices.
</details>
<details>
<summary>摘要</summary>
We present a new LCA implementation designed for the Loihi 2 processor and perform initial benchmarks comparing it to LCA on CPU and GPU devices. Our results show that LCA on Loihi 2 is several orders of magnitude more efficient and faster for large sparsity penalties, while maintaining similar reconstruction quality. We find that the performance improvement increases as the LCA parameters are tuned towards greater representation sparsity.Our study highlights the potential of neuromorphic processors, particularly Loihi 2, for enabling intelligent, autonomous, and real-time processing on small robots and satellites with strict SWaP (small, lightweight, and low power) requirements. By demonstrating the superior performance of LCA on Loihi 2 compared to conventional computing devices, our study suggests that Loihi 2 could be a valuable tool in advancing these types of applications.Overall, our study highlights the potential of neuromorphic processors for efficient and accurate data processing on resource-constrained devices.
</details></li>
</ul>
<hr>
<h2 id="PlaneRecTR-Unified-Query-Learning-for-3D-Plane-Recovery-from-a-Single-View"><a href="#PlaneRecTR-Unified-Query-Learning-for-3D-Plane-Recovery-from-a-Single-View" class="headerlink" title="PlaneRecTR: Unified Query Learning for 3D Plane Recovery from a Single View"></a>PlaneRecTR: Unified Query Learning for 3D Plane Recovery from a Single View</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13756">http://arxiv.org/abs/2307.13756</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sjingjia/planerectr">https://github.com/sjingjia/planerectr</a></li>
<li>paper_authors: Jingjia Shi, Shuaifeng Zhi, Kai Xu</li>
<li>for: 本研究旨在提出一种能够独立从单张图像中恢复3D平面的全新框架，即PlaneRecTR，该框架可以同时处理多个相关的子任务，包括平面检测、分割、参数估计和深度估计。</li>
<li>methods: PlaneRecTR 使用 Transformer 架构，并通过一种新的嵌入式嵌入法将所有相关的子任务集成到一个紧凑的模型中。</li>
<li>results: 经过广泛的量化和质量实验，我们的提议的统一学习方法在公共的 ScanNet 和 NYUv2-Plane 数据集上达到了新的状态场下的最佳性能。<details>
<summary>Abstract</summary>
3D plane recovery from a single image can usually be divided into several subtasks of plane detection, segmentation, parameter estimation and possibly depth estimation. Previous works tend to solve this task by either extending the RCNN-based segmentation network or the dense pixel embedding-based clustering framework. However, none of them tried to integrate above related subtasks into a unified framework but treat them separately and sequentially, which we suspect is potentially a main source of performance limitation for existing approaches. Motivated by this finding and the success of query-based learning in enriching reasoning among semantic entities, in this paper, we propose PlaneRecTR, a Transformer-based architecture, which for the first time unifies all subtasks related to single-view plane recovery with a single compact model. Extensive quantitative and qualitative experiments demonstrate that our proposed unified learning achieves mutual benefits across subtasks, obtaining a new state-of-the-art performance on public ScanNet and NYUv2-Plane datasets. Codes are available at https://github.com/SJingjia/PlaneRecTR.
</details>
<details>
<summary>摘要</summary>
三元平面恢复从单张图像通常可以分解为多个子任务，包括平面检测、分割、参数估算和可能的深度估算。现有的工作通常是通过扩展RCNN基于分割网络或密集像素嵌入基于聚类框架来解决这个任务。然而，现有的方法都没有尝试将上述相关的子任务集成到一个简单的框架中，而是将它们分别处理并处理，我们认为这可能是现有方法性能下限的主要原因。受这一发现和semantic Entities之间的聚合学习的成功启发，在这篇论文中，我们提出PlaneRecTR，一种基于Transformer架构的architecture，可以同时解决单视图平面恢复的所有相关子任务。我们的提议的统一学习方法在各个子任务之间带来互助效果，并在公共的ScanNet和NYUv2-Plane数据集上实现了新的state-of-the-art性能。代码可以在https://github.com/SJingjia/PlaneRecTR中获取。
</details></li>
</ul>
<hr>
<h2 id="ChildGAN-Large-Scale-Synthetic-Child-Facial-Data-Using-Domain-Adaptation-in-StyleGAN"><a href="#ChildGAN-Large-Scale-Synthetic-Child-Facial-Data-Using-Domain-Adaptation-in-StyleGAN" class="headerlink" title="ChildGAN: Large Scale Synthetic Child Facial Data Using Domain Adaptation in StyleGAN"></a>ChildGAN: Large Scale Synthetic Child Facial Data Using Domain Adaptation in StyleGAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13746">http://arxiv.org/abs/2307.13746</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Ali Farooq, Wang Yao, Gabriel Costache, Peter Corcoran</li>
<li>for: 这个论文是为了生成Synthetic boys and girls facial data，使用StyleGAN2建立了一个新的ChildGAN网络。</li>
<li>methods: 这个论文使用了含 Transfer Learning的smooth domain transfer方法，并生成了大规模的数据集，包括多种智能的 facial 变换，如表情、年龄增长、眼睛打开效果、头部 pose、皮肤和头发颜色变化、不同的照明条件等。</li>
<li>results: 这个论文通过多种计算机视觉应用测试，如CNN基于的儿童性别分类器、面部定位和表情特征检测测试、人脸认知度评估使用ArcFace，以及眼睛检测和眼球比例测试， validate了生成的儿童脸部数据的真实性和特点。<details>
<summary>Abstract</summary>
In this research work, we proposed a novel ChildGAN, a pair of GAN networks for generating synthetic boys and girls facial data derived from StyleGAN2. ChildGAN is built by performing smooth domain transfer using transfer learning. It provides photo-realistic, high-quality data samples. A large-scale dataset is rendered with a variety of smart facial transformations: facial expressions, age progression, eye blink effects, head pose, skin and hair color variations, and variable lighting conditions. The dataset comprises more than 300k distinct data samples. Further, the uniqueness and characteristics of the rendered facial features are validated by running different computer vision application tests which include CNN-based child gender classifier, face localization and facial landmarks detection test, identity similarity evaluation using ArcFace, and lastly running eye detection and eye aspect ratio tests. The results demonstrate that synthetic child facial data of high quality offers an alternative to the cost and complexity of collecting a large-scale dataset from real children.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们提出了一种新的ChildGAN，即基于StyleGAN2的两个GAN网络，用于生成Synthetic的男孩和女孩脸部数据。ChildGAN通过平滑领域传输学习来建立，可以提供高质量、photo-realistic的数据样本。我们使用了多种智能的脸部变换，包括表情、年龄增长、眼睛跳动效果、头部姿态、皮肤和头发颜色变化以及不同的照明条件。数据集包含超过300k个不同的数据样本。此外，我们验证了生成的脸部特征的独特性和特点，通过运行不同的计算机视觉应用测试，包括CNN基于儿童性别分类器、脸部定位和面部特征检测测试、ArcFace进行identity similarity评估以及最后运行眼睛检测和眼睛方向测试。结果表明，高质量的Synthetic儿童脸部数据提供了一种可行的代替实际收集大规模数据的方式，减少了成本和复杂度。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Analysis-on-the-Leakage-of-Fuzzy-Matchers"><a href="#A-Comprehensive-Analysis-on-the-Leakage-of-Fuzzy-Matchers" class="headerlink" title="A Comprehensive Analysis on the Leakage of Fuzzy Matchers"></a>A Comprehensive Analysis on the Leakage of Fuzzy Matchers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13717">http://arxiv.org/abs/2307.13717</a></li>
<li>repo_url: None</li>
<li>paper_authors: Axel Durbet, Paul-Marie Grollemund, Kevin Thiry-Atighehchi</li>
<li>for: 本文对评估距离时的信息泄露进行了全面的分析，特别是对于基于权限误差的误差距离（i.e., 杂化误差）。</li>
<li>methods: 本文提出了一个枚举式的信息泄露场景catalog，以及这些场景对数据隐私安全性的影响。每个场景都导致了通用攻击，攻击的计算成本用于确定安全性水平的Upper bound。</li>
<li>results: 本文的分析结果显示，在使用弱隐私保护matcher时， informations leakage可能导致攻击者通过side channel attack或部分杂化设计获取敏感数据。<details>
<summary>Abstract</summary>
This paper provides a comprehensive analysis of information leakage during distance evaluation, with an emphasis on threshold-based obfuscated distance (i.e., Fuzzy Matcher). Leakage can occur due to a malware infection or the use of a weakly privacy-preserving matcher, exemplified by side channel attacks or partially obfuscated designs. We provide an exhaustive catalog of information leakage scenarios as well as their impacts on the security concerning data privacy. Each of the scenarios leads to generic attacks whose impacts are expressed in terms of computational costs, hence allowing the establishment of upper bounds on the security level.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文提供了评估距离时信息泄露的全面分析，强调阈值基于杂化距离（即杂化匹配器）的情况。泄露可能由恶意软件感染或弱privacy保护匹配器引起，例如侧通攻击或部分杂化设计。我们提供了丰富的信息泄露场景目录以及它们对数据隐私安全的影响。每个场景都导致了通用攻击，攻击的影响表现为计算成本，因此可以确定安全水平的Upper bound。
</details></li>
</ul>
<hr>
<h2 id="Personal-Protective-Equipment-Detection-in-Extreme-Construction-Conditions"><a href="#Personal-Protective-Equipment-Detection-in-Extreme-Construction-Conditions" class="headerlink" title="Personal Protective Equipment Detection in Extreme Construction Conditions"></a>Personal Protective Equipment Detection in Extreme Construction Conditions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13654">http://arxiv.org/abs/2307.13654</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuexiong Ding, Xiaowei Luo</li>
<li>for: 这个研究旨在开发一个可靠的人员侦测模型，以应对在建筑工程中的极端环境。</li>
<li>methods: 这个研究使用了神经风格转移（NST）和YOLOv5技术，组合了这两种技术来建立一个抗衰变的侦测模型。</li>
<li>results: 实验结果显示，NST模组可以对极端环境进行更好的模拟，并帮助NST-YOLOv5模型在真实世界极端环境中获得0.141和0.083 mAP_(05:95)的改善。<details>
<summary>Abstract</summary>
Object detection has been widely applied for construction safety management, especially personal protective equipment (PPE) detection. Though the existing PPE detection models trained on conventional datasets have achieved excellent results, their performance dramatically declines in extreme construction conditions. A robust detection model NST-YOLOv5 is developed by combining the neural style transfer (NST) and YOLOv5 technologies. Five extreme conditions are considered and simulated via the NST module to endow the detection model with excellent robustness, including low light, intense light, sand dust, fog, and rain. Experiments show that the NST has great potential as a tool for extreme data synthesis since it is better at simulating extreme conditions than other traditional image processing algorithms and helps the NST-YOLOv5 achieve 0.141 and 0.083 mAP_(05:95) improvements in synthesized and real-world extreme data. This study provides a new feasible way to obtain a more robust detection model for extreme construction conditions.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传统的人工智能技术已经广泛应用于建筑安全管理中，特别是个人防护设备（PPE）检测。现有的PPE检测模型通过传统数据集训练已经达到了出色的结果，但是其在极端建筑条件下的性能却显著下降。为了解决这个问题，本研究开发了一种Robust检测模型NST-YOLOv5，通过结合神经风格传输（NST）和YOLOv5技术。研究认为，在极端条件下，NST模块可以更好地模拟极端情况，包括低光照、强光照、尘埃、雾和雨。实验结果表明，NST具有优秀的可模拟极端条件的能力，可以帮助NST-YOLOv5在人工生成的极端数据中达到0.141和0.083 mAP_(05:95)的改进。本研究为建筑安全管理中的极端条件下的检测模型提供了一个新的可靠的方法。
</details></li>
</ul>
<hr>
<h2 id="Learning-Transferable-Object-Centric-Diffeomorphic-Transformations-for-Data-Augmentation-in-Medical-Image-Segmentation"><a href="#Learning-Transferable-Object-Centric-Diffeomorphic-Transformations-for-Data-Augmentation-in-Medical-Image-Segmentation" class="headerlink" title="Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation"></a>Learning Transferable Object-Centric Diffeomorphic Transformations for Data Augmentation in Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13645">http://arxiv.org/abs/2307.13645</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nilesh Kumar, Prashnna K. Gyawali, Sandesh Ghimire, Linwei Wang<br>for:* 这种论文主要是为了解决医疗图像分割中获取标注数据的挑战，特别是需要专家 manually annotate每个像素点。methods:* 这种方法使用了对象的可变变换来减少这个挑战，但这些变换通常是全像的，因此无法在不同的数据集或问题中进行传输。results:* 我们提出了一种新的对象中心数据增强模型，可以学习对象的形态变化并在图像中增强对象，而不需要修改图像的其他部分。* 我们证明了该模型在儿科肿瘤分割中的效果，并且可以从同一个数据集中学习形态变化，以及从外部数据集中传输形态变化。<details>
<summary>Abstract</summary>
Obtaining labelled data in medical image segmentation is challenging due to the need for pixel-level annotations by experts. Recent works have shown that augmenting the object of interest with deformable transformations can help mitigate this challenge. However, these transformations have been learned globally for the image, limiting their transferability across datasets or applicability in problems where image alignment is difficult. While object-centric augmentations provide a great opportunity to overcome these issues, existing works are only focused on position and random transformations without considering shape variations of the objects. To this end, we propose a novel object-centric data augmentation model that is able to learn the shape variations for the objects of interest and augment the object in place without modifying the rest of the image. We demonstrated its effectiveness in improving kidney tumour segmentation when leveraging shape variations learned both from within the same dataset and transferred from external datasets.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:医学图像分割中获取标注数据具有挑战性，因为需要专家进行像素级别的标注。最近的研究表明，将对象兴趣添加到扩展变换可以减轻这些挑战。然而，这些变换通常是基于整个图像而学习的，导致其在不同数据集或图像对齐问题中的传输性不佳。而对象中心的扩展变换提供了一个大好的机会来超越这些问题，但现有的工作仅关注位置和随机变换而忽略对象形状的变化。为此，我们提议一种新的对象中心数据增强模型，能够学习对象兴趣的形状变化并在图像中增强对象而不改变其他部分。我们在使用同一个数据集中的形状变化和外部数据集中的形状变化来优化肾癌分 segmentation时进行了证明。
</details></li>
</ul>
<hr>
<h2 id="Optical-Flow-boosts-Unsupervised-Localization-and-Segmentation"><a href="#Optical-Flow-boosts-Unsupervised-Localization-and-Segmentation" class="headerlink" title="Optical Flow boosts Unsupervised Localization and Segmentation"></a>Optical Flow boosts Unsupervised Localization and Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13640">http://arxiv.org/abs/2307.13640</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlzxy/flowdino">https://github.com/mlzxy/flowdino</a></li>
<li>paper_authors: Xinyu Zhang, Abdeslam Boularias</li>
<li>for: 本研究旨在提出一种基于运动指示的无监督本地化和分割方法，以解决自主 робоット视觉任务中的长期挑战。</li>
<li>methods: 我们提出了一种新的损失函数形式ulation，使用无监督视频中的摄像机流来鼓励自我监督视transformer（ViT）特征来 closer to each other。</li>
<li>results: 我们的finetuning过程超过了无监督 semantic segmentation的状态前方法，并且在无监督物体localization和semantic segmentation benchmark上也达到了更高的性能。<details>
<summary>Abstract</summary>
Unsupervised localization and segmentation are long-standing robot vision challenges that describe the critical ability for an autonomous robot to learn to decompose images into individual objects without labeled data. These tasks are important because of the limited availability of dense image manual annotation and the promising vision of adapting to an evolving set of object categories in lifelong learning. Most recent methods focus on using visual appearance continuity as object cues by spatially clustering features obtained from self-supervised vision transformers (ViT). In this work, we leverage motion cues, inspired by the common fate principle that pixels that share similar movements tend to belong to the same object. We propose a new loss term formulation that uses optical flow in unlabeled videos to encourage self-supervised ViT features to become closer to each other if their corresponding spatial locations share similar movements, and vice versa. We use the proposed loss function to finetune vision transformers that were originally trained on static images. Our fine-tuning procedure outperforms state-of-the-art techniques for unsupervised semantic segmentation through linear probing, without the use of any labeled data. This procedure also demonstrates increased performance over original ViT networks across unsupervised object localization and semantic segmentation benchmarks.
</details>
<details>
<summary>摘要</summary>
自主化机器人视觉挑战包括无监督的本地化和分割，这两个任务都是关键的，因为有限的杂化图像手动标注数据。这些任务是重要的，因为它们可以适应不断变化的物品类别，并且拥有长期学习的承袭。现有的方法主要基于视觉外观继续性作为物体征料，通过自动将自然语言中的词语分配到相应的位置。在这项工作中，我们启用运动征料，基于共同命运原则，即像素之间的运动相似性可以用于推断这些像素属于同一个物体。我们提出了一种新的损失函数表述，使用无标注视频中的光流来鼓励自我超vised Vision Transformer（ViT）特征自适应更近。我们使用该损失函数来练化原始基于静止图像的ViT网络，并通过线性探测超越当前最佳无监督Semantic Segmentation技术。此外，我们还证明了我们的练化方法可以在无监督物体本地化和Semantic Segmentation benchmark中表现出更高的性能。
</details></li>
</ul>
<hr>
<h2 id="Fake-It-Without-Making-It-Conditioned-Face-Generation-for-Accurate-3D-Face-Shape-Estimation"><a href="#Fake-It-Without-Making-It-Conditioned-Face-Generation-for-Accurate-3D-Face-Shape-Estimation" class="headerlink" title="Fake It Without Making It: Conditioned Face Generation for Accurate 3D Face Shape Estimation"></a>Fake It Without Making It: Conditioned Face Generation for Accurate 3D Face Shape Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13639">http://arxiv.org/abs/2307.13639</a></li>
<li>repo_url: None</li>
<li>paper_authors: Will Rowan, Patrik Huber, Nick Pears, Andrew Keeling</li>
<li>for:  bridging the gap between 2D and 3D face shape estimation</li>
<li>methods:  conditioned stable diffusion model for face image generation, leveraging abundant 2D facial information to inform 3D space</li>
<li>results:  large-scale synthesized dataset of 250K photorealistic images and corresponding 3DMM parameters, and a deep neural network (ControlFace) that achieves competitive performance on the NoW benchmark without requiring 3D supervision or manual 3D asset creation.Here’s the full Chinese text:</li>
<li>for:  bridging the gap between 2D 和 3D 人脸形状估计</li>
<li>methods:  conditioned stable diffusion model for face image generation, 利用丰富的 2D 脸部信息来指导 3D 空间</li>
<li>results:  large-scale synthesized dataset of 250K photorealistic images and corresponding 3DMM parameters, 以及一个深度神经网络 (ControlFace) ，在 NoW  benchmark 上 achieve 竞争性性能，无需 3D 监督或手动 3D 资产创建。<details>
<summary>Abstract</summary>
Accurate 3D face shape estimation is an enabling technology with applications in healthcare, security, and creative industries, yet current state-of-the-art methods either rely on self-supervised training with 2D image data or supervised training with very limited 3D data. To bridge this gap, we present a novel approach which uses a conditioned stable diffusion model for face image generation, leveraging the abundance of 2D facial information to inform 3D space. By conditioning stable diffusion on depth maps sampled from a 3D Morphable Model (3DMM) of the human face, we generate diverse and shape-consistent images, forming the basis of SynthFace. We introduce this large-scale synthesised dataset of 250K photorealistic images and corresponding 3DMM parameters. We further propose ControlFace, a deep neural network, trained on SynthFace, which achieves competitive performance on the NoW benchmark, without requiring 3D supervision or manual 3D asset creation.
</details>
<details>
<summary>摘要</summary>
当前最先进的3D面部形态估算技术都是基于自动超参的2D图像数据或有限的3D数据进行超参数学习的。为了bridging这个差距，我们提出了一种新的方法，该方法使用conditioned stable diffusion模型来生成面图像，通过利用丰富的2D facial信息来导航3D空间。我们通过将稳定扩散模型conditioned on 3DMM中的深度图像，生成了多样化和形态一致的图像，这些图像组成了SynthFace大规模合成数据集。我们还提出了ControlFace，一种基于SynthFace的深度神经网络，在NoW标准测试集上达到了竞争性表现，不需要3D指导或手动创建3D资产。
</details></li>
</ul>
<hr>
<h2 id="RecursiveDet-End-to-End-Region-based-Recursive-Object-Detection"><a href="#RecursiveDet-End-to-End-Region-based-Recursive-Object-Detection" class="headerlink" title="RecursiveDet: End-to-End Region-based Recursive Object Detection"></a>RecursiveDet: End-to-End Region-based Recursive Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13619">http://arxiv.org/abs/2307.13619</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bravezzzzzz/recursivedet">https://github.com/bravezzzzzz/recursivedet</a></li>
<li>paper_authors: Jing Zhao, Li Sun, Qingli Li</li>
<li>for: 提高 End-to-end 区域基于对象检测器的性能和参数数量，使其更加高效。</li>
<li>methods: 提出一种基于重复解码的方法，通过共享参数并使用可 recursive 的解码器，提高检测器的性能。并在解码器中使用位置编码（PE），使其根据输入 bounding box 的具体位置和大小进行适应。</li>
<li>results: 通过对多个主流区域基于对象检测器进行减少，并在不同的 stage 进行 recursive 解码，实现了明显的性能提升，并且需要 fewer 参数和轻微增加计算成本。<details>
<summary>Abstract</summary>
End-to-end region-based object detectors like Sparse R-CNN usually have multiple cascade bounding box decoding stages, which refine the current predictions according to their previous results. Model parameters within each stage are independent, evolving a huge cost. In this paper, we find the general setting of decoding stages is actually redundant. By simply sharing parameters and making a recursive decoder, the detector already obtains a significant improvement. The recursive decoder can be further enhanced by positional encoding (PE) of the proposal box, which makes it aware of the exact locations and sizes of input bounding boxes, thus becoming adaptive to proposals from different stages during the recursion. Moreover, we also design centerness-based PE to distinguish the RoI feature element and dynamic convolution kernels at different positions within the bounding box. To validate the effectiveness of the proposed method, we conduct intensive ablations and build the full model on three recent mainstream region-based detectors. The RecusiveDet is able to achieve obvious performance boosts with even fewer model parameters and slightly increased computation cost. Codes are available at https://github.com/bravezzzzzz/RecursiveDet.
</details>
<details>
<summary>摘要</summary>
通常的端到端区域基于对象检测器如Sparse R-CNN都有多个阶段性 bounding box 解码机制，这些阶段性机制会根据之前的结果进行重复的精度调整。在这篇论文中，我们发现了这些阶段性机制的通用设置实际上是重复的。通过将参数共享并实现一个循环解码器，检测器就可以获得显著的提升。此外，我们还设计了基于中心点编码（PE）的方法，使循环解码器变得能够根据不同的阶段提供不同的提档。此外，我们还设计了基于中心点编码的方法，使循环解码器能够根据不同的位置和大小在矩形框内分辨不同的 RoI 特征元素和动态核心。为验证提档的效果，我们进行了广泛的ablation和在三个最新的主流区域基于检测器上建立了全模型。RecusiveDet 能够在更少的模型参数和微量的计算成本下实现明显的性能提升。代码可以在 <https://github.com/bravezzzzzz/RecursiveDet> 上下载。
</details></li>
</ul>
<hr>
<h2 id="Object-based-Probabilistic-Similarity-Evidence-of-Sparse-Latent-Features-from-Fully-Convolutional-Networks"><a href="#Object-based-Probabilistic-Similarity-Evidence-of-Sparse-Latent-Features-from-Fully-Convolutional-Networks" class="headerlink" title="Object-based Probabilistic Similarity Evidence of Sparse Latent Features from Fully Convolutional Networks"></a>Object-based Probabilistic Similarity Evidence of Sparse Latent Features from Fully Convolutional Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13606">http://arxiv.org/abs/2307.13606</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cjuliani/probabilistic-similarity-evidence-FCN">https://github.com/cjuliani/probabilistic-similarity-evidence-FCN</a></li>
<li>paper_authors: Cyril Juliani</li>
<li>for: 本研究旨在探讨使用神经网络学习的相似性分析方法，以便更好地理解和分类复杂pattern。</li>
<li>methods: 该研究使用了全连接卷积网络（FCN）生成的含义表示，并通过软件推理来确定对象在2D图像中的视觉相似性。</li>
<li>results: 研究发现，通过增加卷积网络中的特征变量权重，可以更好地识别对象的视觉特征，并提高相似性分析的准确性。<details>
<summary>Abstract</summary>
Similarity analysis using neural networks has emerged as a powerful technique for understanding and categorizing complex patterns in various domains. By leveraging the latent representations learned by neural networks, data objects such as images can be compared effectively. This research explores the utilization of latent information generated by fully convolutional networks (FCNs) in similarity analysis, notably to estimate the visual resemblance of objects segmented in 2D pictures. To do this, the analytical scheme comprises two steps: (1) extracting and transforming feature patterns per 2D object from a trained FCN, and (2) identifying the most similar patterns through fuzzy inference. The step (2) can be further enhanced by incorporating a weighting scheme that considers the significance of latent variables in the analysis. The results provide valuable insights into the benefits and challenges of employing neural network-based similarity analysis for discerning data patterns effectively.
</details>
<details>
<summary>摘要</summary>
neural network  Similarity analysis 已经成为了复杂模式理解和分类的有力的技术。通过利用 neural network 学习的含义表示，数据对象如图像可以比较有效地比较。这个研究探讨了使用 fully convolutional network (FCN) 生成的含义信息在 similarity analysis 中的应用，特别是用于估计在 2D 图像中分割的物体的视觉相似性。这个方法包括两步：（1）从 trained FCN 中提取和转换每个 2D 对象的特征模式，并（2）通过权重补做来确定最相似的模式。在第二步中，可以进一步增强使用 weighting scheme，考虑 latent variables 在分析中的重要性。研究结果为我们提供了有价值的理解，以及使用 neural network 基于的 similarity analysis 在分析复杂数据模式时的挑战和机会。
</details></li>
</ul>
<hr>
<h2 id="Decisive-Data-using-Multi-Modality-Optical-Sensors-for-Advanced-Vehicular-Systems"><a href="#Decisive-Data-using-Multi-Modality-Optical-Sensors-for-Advanced-Vehicular-Systems" class="headerlink" title="Decisive Data using Multi-Modality Optical Sensors for Advanced Vehicular Systems"></a>Decisive Data using Multi-Modality Optical Sensors for Advanced Vehicular Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13600">http://arxiv.org/abs/2307.13600</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Ali Farooq, Waseem Shariff, Mehdi Sefidgar Dilmaghani, Wang Yao, Moazam Soomro, Peter Corcoran</li>
<li>for: 这篇论文主要针对各种光学技术的设计和开发，以实现现代车辆前视系统和驾驶员监测系统。</li>
<li>methods: 论文使用了各种光学探测技术，包括长波热成像（LWIR）摄像头、近红外（NIR）摄像头、神经科学摄像头、可见CMOS摄像头和深度摄像头。</li>
<li>results: 论文描述了这些光学技术在真实环境中的应用，以及它们在不同应用中的独特优势。<details>
<summary>Abstract</summary>
Optical sensors have played a pivotal role in acquiring real world data for critical applications. This data, when integrated with advanced machine learning algorithms provides meaningful information thus enhancing human vision. This paper focuses on various optical technologies for design and development of state-of-the-art out-cabin forward vision systems and in-cabin driver monitoring systems. The focused optical sensors include Longwave Thermal Imaging (LWIR) cameras, Near Infrared (NIR), Neuromorphic/ event cameras, Visible CMOS cameras and Depth cameras. Further the paper discusses different potential applications which can be employed using the unique strengths of each these optical modalities in real time environment.
</details>
<details>
<summary>摘要</summary>
光学感知技术在实际应用中发挥了关键作用，提供了有用的信息，从而增强人类视觉。这篇论文探讨了各种光学技术在开发前瞻系统和司机监测系统中的设计和开发。主要涉及的光学感知器包括长波紫外线摄像机（LWIR）、近红外（NIR）、神经科学摄像机、可见CMOS摄像机和深度摄像机。论文还讨论了每种光学特性在实时环境中的不同应用可能性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/26/cs.CV_2023_07_26/" data-id="clpxp03yi00hdfm885j5a5v80" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_07_26" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/26/cs.AI_2023_07_26/" class="article-date">
  <time datetime="2023-07-26T12:00:00.000Z" itemprop="datePublished">2023-07-26</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/26/cs.AI_2023_07_26/">cs.AI - 2023-07-26</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Improving-International-Climate-Policy-via-Mutually-Conditional-Binding-Commitments"><a href="#Improving-International-Climate-Policy-via-Mutually-Conditional-Binding-Commitments" class="headerlink" title="Improving International Climate Policy via Mutually Conditional Binding Commitments"></a>Improving International Climate Policy via Mutually Conditional Binding Commitments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14267">http://arxiv.org/abs/2307.14267</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jobst Heitzig, Jörg Oechssler, Christoph Pröschel, Niranjana Ragavan, Yat Long Lo</li>
<li>for: 这篇论文是为了解决气候变化国际协议（Paris协议）面临的挑战，即大多数国家决定的国家决定（NDCs）的无条件性，导致主要排放者之间的免费骗取行为和NDCs中的具体性缺乏。</li>
<li>methods: 该论文提出了一种分布式、底层的决策机制——条件承诺机制， draws inspiration from国家人投票伙伴关系，并提供了适应性和激励早期采用者的优势。</li>
<li>results: 该论文介绍了机制的概述、在AI4ClimateCooperation挑战中的表现，以及实际应用方面的可能性。<details>
<summary>Abstract</summary>
The Paris Agreement, considered a significant milestone in climate negotiations, has faced challenges in effectively addressing climate change due to the unconditional nature of most Nationally Determined Contributions (NDCs). This has resulted in a prevalence of free-riding behavior among major polluters and a lack of concrete conditionality in NDCs. To address this issue, we propose the implementation of a decentralized, bottom-up approach called the Conditional Commitment Mechanism. This mechanism, inspired by the National Popular Vote Interstate Compact, offers flexibility and incentives for early adopters, aiming to formalize conditional cooperation in international climate policy. In this paper, we provide an overview of the mechanism, its performance in the AI4ClimateCooperation challenge, and discuss potential real-world implementation aspects. Prior knowledge of the climate mitigation collective action problem, basic economic principles, and game theory concepts are assumed.
</details>
<details>
<summary>摘要</summary>
《巴黎协议》被视为气候谈判中的重要里程碑，但它在有效地解决气候变化问题上遇到了挑战。这是因为大多数国家确定的气候承诺（NDCs）的条件性较弱，导致主要污染者存在“免费乘客”的现象，NDCs中缺乏具体的条件性。为解决这个问题，我们提议实施一种分散式、底层式的承诺机制，称为条件承诺机制。这种机制灵感自国家人投票协议，提供了灵活性和激励早期采取行动的优势，以帮助正式化国际气候政策中的条件合作。在这篇论文中，我们提供机制的概述、在AI4气候合作挑战中的表现，以及实际应用方面的思考。假设读者有气候 Mitigation的集体行动问题、基本经济原则和游戏理论的知识。
</details></li>
</ul>
<hr>
<h2 id="Improving-International-Climate-Policy-via-Mutually-Conditional-Binding-Commitments-1"><a href="#Improving-International-Climate-Policy-via-Mutually-Conditional-Binding-Commitments-1" class="headerlink" title="Improving International Climate Policy via Mutually Conditional Binding Commitments"></a>Improving International Climate Policy via Mutually Conditional Binding Commitments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14266">http://arxiv.org/abs/2307.14266</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jobst Heitzig, Jörg Oechssler, Christoph Pröschel, Niranjana Ragavan, Richie YatLong Lo</li>
<li>for: 提高国际气候政策决策的现实性</li>
<li>methods: 使用优化的RICE-N模拟和多代理人强化学习框架，以及 Conditional Commitments Mechanism（CCF机制）等方法</li>
<li>results: 提出了减少实验与现实之间差距，增强协调和考虑社会因素的方法，以及改进强化学习算法等建议，以提高国际气候政策决策的效果和可行性。<details>
<summary>Abstract</summary>
This paper proposes enhancements to the RICE-N simulation and multi-agent reinforcement learning framework to improve the realism of international climate policy negotiations. Acknowledging the framework's value, we highlight the necessity of significant enhancements to address the diverse array of factors in modeling climate negotiations. Building upon our previous work on the "Conditional Commitments Mechanism" (CCF mechanism) we discuss ways to bridge the gap between simulation and reality. We suggest the inclusion of a recommender or planner agent to enhance coordination, address the Real2Sim gap by incorporating social factors and non-party stakeholder sub-agents, and propose enhancements to the underlying Reinforcement Learning solution algorithm. These proposed improvements aim to advance the evaluation and formulation of negotiation protocols for more effective international climate policy decision-making in Rice-N. However, further experimentation and testing are required to determine the implications and effectiveness of these suggestions.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="The-flow-of-ideas-in-word-embeddings"><a href="#The-flow-of-ideas-in-word-embeddings" class="headerlink" title="The flow of ideas in word embeddings"></a>The flow of ideas in word embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16819">http://arxiv.org/abs/2307.16819</a></li>
<li>repo_url: None</li>
<li>paper_authors: Debayan Dasgupta</li>
<li>for:  investigate the similarity-based flow of ideas in language models</li>
<li>methods:  adopts microrheology tools and random walker in word embeddings</li>
<li>results:  shows signatures of anomalous diffusion and potential association with creativity<details>
<summary>Abstract</summary>
The flow of ideas has been extensively studied by physicists, psychologists, and machine learning engineers. This paper adopts specific tools from microrheology to investigate the similarity-based flow of ideas. We introduce a random walker in word embeddings and study its behavior. Such similarity-mediated random walks through the embedding space show signatures of anomalous diffusion commonly observed in complex structured systems such as biological cells and complex fluids. The paper concludes by proposing the application of popular tools employed in the study of random walks and diffusion of particles under Brownian motion to assess quantitatively the incorporation of diverse ideas in a document. Overall, this paper presents a self-referenced method combining microrheology and machine learning concepts to explore the meandering tendencies of language models and their potential association with creativity.
</details>
<details>
<summary>摘要</summary>
研究想法的流动已经广泛研究了物理学家、心理学家和机器学习工程师。这篇论文采用特定的工具从微流动学来研究相似性基于的想法流动。我们引入了单词嵌入中的随机游走者，并研究其行为。这种相似性媒介的随机游走在嵌入空间中显示了复杂结构系统中常见的异常扩散特征。论文结束时提出了使用广泛用于随机游走和分子扩散下 Брау恩运动的计算方法来评估文档中多元想法的 incorporation。总的来说，这篇论文提出了结合微流动学和机器学习概念的自referenced方法，用以探索语言模型的漫游倾向和创造力的可能关系。
</details></li>
</ul>
<hr>
<h2 id="Visual-Saliency-Detection-in-Advanced-Driver-Assistance-Systems"><a href="#Visual-Saliency-Detection-in-Advanced-Driver-Assistance-Systems" class="headerlink" title="Visual Saliency Detection in Advanced Driver Assistance Systems"></a>Visual Saliency Detection in Advanced Driver Assistance Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03770">http://arxiv.org/abs/2308.03770</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francesco Rundo, Michael Sebastian Rundo, Concetto Spampinato</li>
<li>for: 这 paper 的目的是提出一种智能系统，用于评估司机的注意力水平和驾驶场景的重要性。</li>
<li>methods: 该系统使用了semantic segmentation 3D deep network、dedicated 1D temporal deep convolutional network、hardware accelerator等技术。</li>
<li>results: 实验结果表明，该系统可以准确地评估司机的注意力水平和驾驶场景的重要性，提高了驾驶安全性。<details>
<summary>Abstract</summary>
Visual Saliency refers to the innate human mechanism of focusing on and extracting important features from the observed environment. Recently, there has been a notable surge of interest in the field of automotive research regarding the estimation of visual saliency. While operating a vehicle, drivers naturally direct their attention towards specific objects, employing brain-driven saliency mechanisms that prioritize certain elements over others. In this investigation, we present an intelligent system that combines a drowsiness detection system for drivers with a scene comprehension pipeline based on saliency. To achieve this, we have implemented a specialized 3D deep network for semantic segmentation, which has been pretrained and tailored for processing the frames captured by an automotive-grade external camera. The proposed pipeline was hosted on an embedded platform utilizing the STA1295 core, featuring ARM A7 dual-cores, and embeds an hardware accelerator. Additionally, we employ an innovative biosensor embedded on the car steering wheel to monitor the driver drowsiness, gathering the PhotoPlethysmoGraphy (PPG) signal of the driver. A dedicated 1D temporal deep convolutional network has been devised to classify the collected PPG time-series, enabling us to assess the driver level of attentiveness. Ultimately, we compare the determined attention level of the driver with the corresponding saliency-based scene classification to evaluate the overall safety level. The efficacy of the proposed pipeline has been validated through extensive experimental results.
</details>
<details>
<summary>摘要</summary>
“视觉吸引”指代人类在观察环境时自然地吸引注意力和提取重要特征的机制。在汽车研究领域，近期对视觉吸引的估计表现出了明显的兴趣增长。在运行汽车时， drivers 自然地将注意力集中在特定对象上，使用大脑驱动的吸引机制，将某些元素优先于别的元素。在这次研究中，我们提出了一个智能系统，该系统结合了驾驶员睡眠检测系统和基于吸引的场景理解管道。为达到这一目标，我们实施了一个特殊的3D深度网络 дляsemantic segmentation，该网络在 automotive-grade 外部摄像头捕捉的帧中进行了预训练和定制。我们的提案的管道在 ARM A7 双核 STA1295 核心上的嵌入式平台上运行，并利用硬件加速器。此外，我们还使用了车辆方向盘上的生物传感器来监测驾驶员睡眠，收集了 driver 的 PhotoPlethysmoGraphy (PPG) 信号。我们设计了一个1D时间深度卷积网络，以分类收集的 PPG 时间序列，从而评估驾驶员的注意度水平。最后，我们将驾驶员的注意度水平与相应的吸引基于场景分类相比评估整体安全水平。我们的提案的管道的效果得到了广泛的实验 validate。
</details></li>
</ul>
<hr>
<h2 id="A-New-Perspective-on-Evaluation-Methods-for-Explainable-Artificial-Intelligence-XAI"><a href="#A-New-Perspective-on-Evaluation-Methods-for-Explainable-Artificial-Intelligence-XAI" class="headerlink" title="A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)"></a>A New Perspective on Evaluation Methods for Explainable Artificial Intelligence (XAI)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14246">http://arxiv.org/abs/2307.14246</a></li>
<li>repo_url: None</li>
<li>paper_authors: Timo Speith, Markus Langer</li>
<li>for: 这个论文主要是为了探讨Explainable Artificial Intelligence（XAI）在Requirements Engineering（RE）领域中的重要性，以及XAI在系统质量中的影响。</li>
<li>methods: 该论文使用了一种critical examination的方法，检查了XAI的可解性和性能之间的Supposed trade-off，并提出了一种nuanced approach来缓解这个负面关系。</li>
<li>results: 该论文的研究结果表明，在不同的资源和领域特点的情况下，可解性和性能之间存在一定的 equilibrio，而不是简单的trade-off关系。这些结果提供了一个基础 для未来的研究和实践，以推进RE领域中的AI发展。<details>
<summary>Abstract</summary>
Within the field of Requirements Engineering (RE), the increasing significance of Explainable Artificial Intelligence (XAI) in aligning AI-supported systems with user needs, societal expectations, and regulatory standards has garnered recognition. In general, explainability has emerged as an important non-functional requirement that impacts system quality. However, the supposed trade-off between explainability and performance challenges the presumed positive influence of explainability. If meeting the requirement of explainability entails a reduction in system performance, then careful consideration must be given to which of these quality aspects takes precedence and how to compromise between them. In this paper, we critically examine the alleged trade-off. We argue that it is best approached in a nuanced way that incorporates resource availability, domain characteristics, and considerations of risk. By providing a foundation for future research and best practices, this work aims to advance the field of RE for AI.
</details>
<details>
<summary>摘要</summary>
在人工智能支持系统中的需求工程（RE）领域，增加了可解释人工智能（XAI）的重要性，以实现人工智能支持系统与用户需求、社会期望和法规标准的一致。通常，可解释性被视为系统质量的重要非功能要求。然而，它与性能之间的优先级权衡带来挑战。如果满足可解释性需求导致系统性能下降，那么需要考虑哪个质量方面优先，以及如何妥协这两个方面。在这篇论文中，我们 críticamente评估了这种负面冲击。我们认为，应该以细化的方式进行评估，考虑资源可用性、领域特点以及风险考虑。通过提供未来研究和最佳实践的基础，这篇论文旨在推动RE领域的发展。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-the-Performance-Explainability-Trade-Off-in-Explainable-Artificial-Intelligence-XAI"><a href="#Revisiting-the-Performance-Explainability-Trade-Off-in-Explainable-Artificial-Intelligence-XAI" class="headerlink" title="Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)"></a>Revisiting the Performance-Explainability Trade-Off in Explainable Artificial Intelligence (XAI)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14239">http://arxiv.org/abs/2307.14239</a></li>
<li>repo_url: None</li>
<li>paper_authors: Barnaby Crook, Maximilian Schlüter, Timo Speith</li>
<li>for: This paper aims to advance the field of Requirements Engineering (RE) for Artificial Intelligence (AI) by critically examining the supposed trade-off between explainability and performance.</li>
<li>methods: The paper argues that the trade-off between explainability and performance should be approached in a nuanced way that incorporates resource availability, domain characteristics, and considerations of risk.</li>
<li>results: The paper provides a foundation for future research and best practices in RE for AI, with the goal of advancing the field.<details>
<summary>Abstract</summary>
Within the field of Requirements Engineering (RE), the increasing significance of Explainable Artificial Intelligence (XAI) in aligning AI-supported systems with user needs, societal expectations, and regulatory standards has garnered recognition. In general, explainability has emerged as an important non-functional requirement that impacts system quality. However, the supposed trade-off between explainability and performance challenges the presumed positive influence of explainability. If meeting the requirement of explainability entails a reduction in system performance, then careful consideration must be given to which of these quality aspects takes precedence and how to compromise between them. In this paper, we critically examine the alleged trade-off. We argue that it is best approached in a nuanced way that incorporates resource availability, domain characteristics, and considerations of risk. By providing a foundation for future research and best practices, this work aims to advance the field of RE for AI.
</details>
<details>
<summary>摘要</summary>
在人工智能支持系统中的需求工程（RE）领域，随着可解释人工智能（XAI）的增加重要性，用户需求、社会期望和法规标准的Alignment已经吸引了关注。通常，可解释性被视为系统质量的重要非函数需求。然而，supposed trade-off between explainability和性能挑战了 présumé的积极影响。如果满足可解释性需求意味着系统性能下降，那么需要仔细考虑哪个质量特征优先级顺序和如何妥协 между them。在这篇论文中，我们critically examine the alleged trade-off。我们认为应该 approached in a nuanced way that incorporates resource availability, domain characteristics, and considerations of risk。通过提供未来研究和最佳实践的基础，这项工作想要进一步发展RE领域的AI。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="UnScientify-Detecting-Scientific-Uncertainty-in-Scholarly-Full-Text"><a href="#UnScientify-Detecting-Scientific-Uncertainty-in-Scholarly-Full-Text" class="headerlink" title="UnScientify: Detecting Scientific Uncertainty in Scholarly Full Text"></a>UnScientify: Detecting Scientific Uncertainty in Scholarly Full Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14236">http://arxiv.org/abs/2307.14236</a></li>
<li>repo_url: None</li>
<li>paper_authors: Panggih Kusuma Ningrum, Philipp Mayr, Iana Atanassova</li>
<li>for: 本研究的目的是开发一个可交互式的系统，用于探测科学文献中的不确定性。</li>
<li>methods: 该系统使用了一种弱监督的技术，利用细致的注释方案来在科学文献中标识句子级上的语言表达的不确定性。其执行管道包括模式匹配、复杂句子检查和作者参考检查。</li>
<li>results: 该系统可自动标记和注释科学文献中的不确定性标识，并考虑不同类型的科学不确定性，以便应用于信息检索、文本挖掘和学术文献处理等领域。此外，该系统提供了可解释的结果，帮助理解文本中标识的不确定性实例。<details>
<summary>Abstract</summary>
This demo paper presents UnScientify, an interactive system designed to detect scientific uncertainty in scholarly full text. The system utilizes a weakly supervised technique that employs a fine-grained annotation scheme to identify verbally formulated uncertainty at the sentence level in scientific texts. The pipeline for the system includes a combination of pattern matching, complex sentence checking, and authorial reference checking. Our approach automates labeling and annotation tasks for scientific uncertainty identification, taking into account different types of scientific uncertainty, that can serve various applications such as information retrieval, text mining, and scholarly document processing. Additionally, UnScientify provides interpretable results, aiding in the comprehension of identified instances of scientific uncertainty in text.
</details>
<details>
<summary>摘要</summary>
这个 demo 文章介绍了一个名为 UnScientify 的交互式系统，用于探测科学不确定性在学术全文中。该系统采用一种弱监督技术，使用细致的注释方案来在科学文本中识别句子级上的语言化不确定性。该管道包括组合pattern匹配、复杂句检查和作者参考检查。我们的方法自动标注和注释科学不确定性标识 task，考虑不同类型的科学不确定性，可以满足信息检索、文本挖掘和学术文档处理等应用。此外，UnScientify 提供可解释结果，帮助理解文本中标识的科学不确定性实例。
</details></li>
</ul>
<hr>
<h2 id="Non-Linear-Self-Augmentation-Deep-Pipeline-for-Cancer-Treatment-outcome-Prediction"><a href="#Non-Linear-Self-Augmentation-Deep-Pipeline-for-Cancer-Treatment-outcome-Prediction" class="headerlink" title="Non-Linear Self Augmentation Deep Pipeline for Cancer Treatment outcome Prediction"></a>Non-Linear Self Augmentation Deep Pipeline for Cancer Treatment outcome Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14398">http://arxiv.org/abs/2307.14398</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francesco Rundo, Concetto Spampinato, Michael Rundo</li>
<li>for: 这个研究的目的是提高化疗治结果的预测，以便更好地选择适合受到化疗治疗的病人。</li>
<li>methods: 这个研究使用了一种新的非线性细胞架构，以及一个深度下渠排序器，从抑肝 CT 图像中提取和增强 2D 特征，以提高化疗治结果的预测。</li>
<li>results: 这个研究的结果显示，这种新的方法可以实现约 93% 的全局准确率，即使在肾脏癌症 (mUC) 等特殊的疾病中也有出色的预测效果。<details>
<summary>Abstract</summary>
Immunotherapy emerges as promising approach for treating cancer. Encouraging findings have validated the efficacy of immunotherapy medications in addressing tumors, resulting in prolonged survival rates and notable reductions in toxicity compared to conventional chemotherapy methods. However, the pool of eligible patients for immunotherapy remains relatively small, indicating a lack of comprehensive understanding regarding the physiological mechanisms responsible for favorable treatment response in certain individuals while others experience limited benefits. To tackle this issue, the authors present an innovative strategy that harnesses a non-linear cellular architecture in conjunction with a deep downstream classifier. This approach aims to carefully select and enhance 2D features extracted from chest-abdomen CT images, thereby improving the prediction of treatment outcomes. The proposed pipeline has been meticulously designed to seamlessly integrate with an advanced embedded Point of Care system. In this context, the authors present a compelling case study focused on Metastatic Urothelial Carcinoma (mUC), a particularly aggressive form of cancer. Performance evaluation of the proposed approach underscores its effectiveness, with an impressive overall accuracy of approximately 93%
</details>
<details>
<summary>摘要</summary>
免疫疗法在治疗癌症方面与兴趣增加。有关免疫疗法药物在治疗肿瘤方面的显著结果，使得生存时间增加和化学治疗方法相比，较少副作用。然而，适合免疫疗法的病人群较小，这表明我们对治疗成功的生理机制所知甚少。为解决这个问题，作者们提出了一个创新的策略，利用不对称细胞架构和深度下游分类器。这个方法的目的是将来自胸腹部 Computed Tomography 影像的2D特征 precisely 选择和增强，以提高治疗结果预测的精度。提案的管道已经严格地设计，以便与高级嵌入式点检系统集成。在这个上下文中，作者们提出了一个吸引人的案例研究， concentrate 在具有攻击性的膀胱癌（mUC）上。研究表明，提案的方法在这个案例中具有很高的总精度，约93%。
</details></li>
</ul>
<hr>
<h2 id="Sources-of-Opacity-in-Computer-Systems-Towards-a-Comprehensive-Taxonomy"><a href="#Sources-of-Opacity-in-Computer-Systems-Towards-a-Comprehensive-Taxonomy" class="headerlink" title="Sources of Opacity in Computer Systems: Towards a Comprehensive Taxonomy"></a>Sources of Opacity in Computer Systems: Towards a Comprehensive Taxonomy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14232">http://arxiv.org/abs/2307.14232</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sara Mann, Barnaby Crook, Lena Kästner, Astrid Schomäcker, Timo Speith</li>
<li>for: 本研究旨在提高现代计算机系统的透明性，以便在需要公正或负责任的领域中应用。</li>
<li>methods: 本研究提出了一种基于八种透明性源的分类法，这八种源分为三大类：建筑性、分析性和社会技术性。对每种源，提供了实践中透明性处理的初步建议。</li>
<li>results: 本研究提供了一个 Context-dependent 透明性分类法，可以帮助需求工程师和其他实践者更好地理解特定context中透明性的主要来源，并选择或开发合适的透明性处理策略。<details>
<summary>Abstract</summary>
Modern computer systems are ubiquitous in contemporary life yet many of them remain opaque. This poses significant challenges in domains where desiderata such as fairness or accountability are crucial. We suggest that the best strategy for achieving system transparency varies depending on the specific source of opacity prevalent in a given context. Synthesizing and extending existing discussions, we propose a taxonomy consisting of eight sources of opacity that fall into three main categories: architectural, analytical, and socio-technical. For each source, we provide initial suggestions as to how to address the resulting opacity in practice. The taxonomy provides a starting point for requirements engineers and other practitioners to understand contextually prevalent sources of opacity, and to select or develop appropriate strategies for overcoming them.
</details>
<details>
<summary>摘要</summary>
现代计算机系统在现代生活中 ubique，但是许多它们仍然呈 opacity。这种情况会在需要 fairness 或 accountability 的领域 pose significant challenges。我们认为，在不同的 context 中 opaque 的 sources 的最佳策略是针对性的，即根据具体情况下的 opaque 的来源。通过synthesizing 和 extending 现有的讨论，我们提出了一个包含 eight sources of opacity 的税onomy，分为三大类：architectural、analytical 和 socio-technical。对于每个来源，我们提供了初步的实践方法，以便 requirements engineers 和其他专业人员在具体情况下理解contextually prevalent 的 opaque 来源，并选择或开发合适的策略来解决它们。
</details></li>
</ul>
<hr>
<h2 id="Explore-the-possibility-of-advancing-climate-negotiations-on-the-basis-of-regional-trade-organizations-A-study-based-on-RICE-N"><a href="#Explore-the-possibility-of-advancing-climate-negotiations-on-the-basis-of-regional-trade-organizations-A-study-based-on-RICE-N" class="headerlink" title="Explore the possibility of advancing climate negotiations on the basis of regional trade organizations: A study based on RICE-N"></a>Explore the possibility of advancing climate negotiations on the basis of regional trade organizations: A study based on RICE-N</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14226">http://arxiv.org/abs/2307.14226</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wubo Dai</li>
<li>for: 这篇论文是为了提供新的理论支持气候谈判，帮助解决现在国际合作的不清楚前景。</li>
<li>methods: 这篇论文使用了深度学习建立了一个基于代理模型（ABM），并基于现有的贸易团体，对气候谈判进行了模拟。</li>
<li>results: 模拟结果显示，该方案具有良好的前景。<details>
<summary>Abstract</summary>
Climate issues have become more and more important now. Although global governments have made some progress, we are still facing the truth that the prospect of international cooperation is not clear at present. Due to the limitations of the Integrated assessment models (IAMs) model, it is difficult to simulate the dynamic negotiation process. Therefore, using deep learning to build a new agents based model (ABM) might can provide new theoretical support for climate negotiations. Building on the RICE-N model, this work proposed an approach to climate negotiations based on existing trade groups. Simulation results show that the scheme has a good prospect.
</details>
<details>
<summary>摘要</summary>
现在，气候问题已经变得非常重要。虽然全球政府已经做出了一些进展，但现在我们还面临着国际合作的未定性。由于 инте格рирован的评估模型（IAMs）的局限性，模拟动态谈判过程很难。因此，使用深度学习建立新的代理人基本模型（ABM）可能会提供新的理论支持 для气候谈判。基于RICE-N模型，本研究提出了基于现有贸易组织的方法。计算结果显示，该方案具有良好的前景。Note: "RICE-N" stands for "Regional Integrated model of Climate and the Economy with Non-cooperative Negociations".
</details></li>
</ul>
<hr>
<h2 id="AI-and-Education-An-Investigation-into-the-Use-of-ChatGPT-for-Systems-Thinking"><a href="#AI-and-Education-An-Investigation-into-the-Use-of-ChatGPT-for-Systems-Thinking" class="headerlink" title="AI and Education: An Investigation into the Use of ChatGPT for Systems Thinking"></a>AI and Education: An Investigation into the Use of ChatGPT for Systems Thinking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14206">http://arxiv.org/abs/2307.14206</a></li>
<li>repo_url: None</li>
<li>paper_authors: Holger Arndt</li>
<li>for: 这个探索性研究检查了虚拟智能工具ChatGPT是否可以支持不同科目的系统思维（ST）能力。</li>
<li>methods: 研究使用了通用和专业Prompt来评估ChatGPT的准确率、帮助度和可靠性在不同版本的工具中。</li>
<li>results: 研究发现ChatGPT可以在不同科目提供大量正确和很有帮助的答案，表明它可以增强ST技能。但有时会出现错误，需要用户保持批判性。 DESPITE SOME LIMITATIONS, THIS STUDY SUGGESTS THAT WITH CAREFUL USE AND ATTENTION TO ITS IDIOSYNCRASIES, ChatGPT CAN BE A VALUABLE TOOL FOR TEACHING AND LEARNING ST.<details>
<summary>Abstract</summary>
This exploratory study investigates the potential of the artificial intelligence tool, ChatGPT, to support systems thinking (ST) in various subjects. Using both general and subject specific prompts, the study assesses the accuracy, helpfulness, and reliability of ChatGPT's responses across different versions of the tool. The results indicate that ChatGPT can provide largely correct and very helpful responses in various subjects, demonstrating its potential as a tool for enhancing ST skills. However, occasional inaccuracies highlight the need for users to remain critical of ChatGPT's responses. Despite some limitations, this study suggests that with careful use and attention to its idiosyncrasies, ChatGPT can be a valuable tool for teaching and learning ST.
</details>
<details>
<summary>摘要</summary>
这项探索性研究检查了人工智能工具ChatGPT在不同学科中支持系统思维（ST）的潜力。通过通用和专业specific prompts，研究评估了ChatGPT的答案准确性、帮助性和可靠性，并发现ChatGPT在不同版本中的答案准确性较高，能够提供帮助学习ST技能的工具。然而， occasional inaccuracies 表明用户需要保持批判性，不能完全依赖ChatGPT的答案。不withstanding some limitations，这项研究表明，通过仔细使用和注意其特点，ChatGPT可以成为教学和学习ST的有价值工具。
</details></li>
</ul>
<hr>
<h2 id="Unveiling-Security-Privacy-and-Ethical-Concerns-of-ChatGPT"><a href="#Unveiling-Security-Privacy-and-Ethical-Concerns-of-ChatGPT" class="headerlink" title="Unveiling Security, Privacy, and Ethical Concerns of ChatGPT"></a>Unveiling Security, Privacy, and Ethical Concerns of ChatGPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14192">http://arxiv.org/abs/2307.14192</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaodong Wu, Ran Duan, Jianbing Ni</li>
<li>for: 本研究探讨 chatGPT 如何应用于不同领域，以及 chatGPT 的安全、隐私和伦理问题。</li>
<li>methods: 本研究使用 topic modeling 和 reinforcement learning 技术，从 GPT-1 到 GPT-4 的升级路径，探讨模型的特点、局限性和应用前景。</li>
<li>results: 本研究指出 chatGPT 的潜在风险和问题，包括安全、隐私和伦理问题，并且提出了解决这些问题的开放问题。<details>
<summary>Abstract</summary>
This paper delves into the realm of ChatGPT, an AI-powered chatbot that utilizes topic modeling and reinforcement learning to generate natural responses. Although ChatGPT holds immense promise across various industries, such as customer service, education, mental health treatment, personal productivity, and content creation, it is essential to address its security, privacy, and ethical implications. By exploring the upgrade path from GPT-1 to GPT-4, discussing the model's features, limitations, and potential applications, this study aims to shed light on the potential risks of integrating ChatGPT into our daily lives. Focusing on security, privacy, and ethics issues, we highlight the challenges these concerns pose for widespread adoption. Finally, we analyze the open problems in these areas, calling for concerted efforts to ensure the development of secure and ethically sound large language models.
</details>
<details>
<summary>摘要</summary>
这篇论文探讨了chatGPT，一种基于人工智能的聊天机器人，它利用话题模型和强化学习生成自然的回应。虽然chatGPT在各个领域，如客户服务、教育、心理健康治疗、个人产生力和内容创作等领域都具有极大的承诺，但是需要考虑其安全、隐私和伦理问题。通过探讨GPT-1到GPT-4的升级路径，讨论模型的特点、局限性和应用潜力，这篇研究目的是为了照明chatGPT在我们日常生活中的潜在风险。Focus on安全、隐私和伦理问题，我们高亮了这些问题对普及的挑战。最后，我们分析了在这些领域的开放问题，呼吁一共努力确保开发出安全和伦理正确的大语言模型。
</details></li>
</ul>
<hr>
<h2 id="LOIS-Looking-Out-of-Instance-Semantics-for-Visual-Question-Answering"><a href="#LOIS-Looking-Out-of-Instance-Semantics-for-Visual-Question-Answering" class="headerlink" title="LOIS: Looking Out of Instance Semantics for Visual Question Answering"></a>LOIS: Looking Out of Instance Semantics for Visual Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14142">http://arxiv.org/abs/2307.14142</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siyu Zhang, Yeming Chen, Yaoru Sun, Fang Wang, Haibo Shi, Haoran Wang<br>for: 这个论文的目的是提高视觉问答模型的理解能力，尤其是在理解图像中的对象semantics的关系。methods: 该论文提出了一种不使用 bounding boxes 的模型框架，称为 Looking Out of Instance Semantics (LOIS)，以便更好地描述图像中的Visual fact。此外，该论文还提出了两种关系注意力模块：1）内模态注意力和2）间模态注意力，以解决多视Modality特征之间的关系。results: 该论文的实验结果表明，与四个标准 VQA 数据集进行比较，该提出的方法在改进视觉理解能力方面表现出优秀的成绩。<details>
<summary>Abstract</summary>
Visual question answering (VQA) has been intensively studied as a multimodal task that requires effort in bridging vision and language to infer answers correctly. Recent attempts have developed various attention-based modules for solving VQA tasks. However, the performance of model inference is largely bottlenecked by visual processing for semantics understanding. Most existing detection methods rely on bounding boxes, remaining a serious challenge for VQA models to understand the causal nexus of object semantics in images and correctly infer contextual information. To this end, we propose a finer model framework without bounding boxes in this work, termed Looking Out of Instance Semantics (LOIS) to tackle this important issue. LOIS enables more fine-grained feature descriptions to produce visual facts. Furthermore, to overcome the label ambiguity caused by instance masks, two types of relation attention modules: 1) intra-modality and 2) inter-modality, are devised to infer the correct answers from the different multi-view features. Specifically, we implement a mutual relation attention module to model sophisticated and deeper visual semantic relations between instance objects and background information. In addition, our proposed attention model can further analyze salient image regions by focusing on important word-related questions. Experimental results on four benchmark VQA datasets prove that our proposed method has favorable performance in improving visual reasoning capability.
</details>
<details>
<summary>摘要</summary>
Visual问答（VQA）已经广泛研究过，它需要跨视觉和语言之间的桥接来得出正确的答案。现有的尝试都开发了多种注意力模块来解决VQA任务。然而，模型推理性能受到视觉处理的限制，尤其是对象 semantics的理解。大多数现有的检测方法都依赖于 bounding boxes，这是VQA模型理解图像中对象 semantics的 causal nexus 的重要挑战。为此，我们在这里提出一种不使用 bounding boxes 的finer模型框架，称为 Looking Out of Instance Semantics（LOIS）。LOIS允许更细化的特征描述，以生成更加精准的视觉事实。此外，为了解决因instance masks引起的标签模糊，我们提出了两种类型的关系注意力模块：1）内模态关系注意力模块和2）间模态关系注意力模块。这些模块可以帮助模型正确地从不同的多视图特征中推理答案。具体来说，我们实现了相互关系注意力模块，以模型复杂的和深入的视觉semantics关系 между实例对象和背景信息。此外，我们的提议的注意力模型还可以进一步分析重要的单词相关问题，以增强图像区域的注意力。实验结果表明，我们的提议方法在四个 benchmark VQA 数据集上表现出色，提高了图像逻辑能力。
</details></li>
</ul>
<hr>
<h2 id="Piecewise-Stationary-Combinatorial-Semi-Bandit-with-Causally-Related-Rewards"><a href="#Piecewise-Stationary-Combinatorial-Semi-Bandit-with-Causally-Related-Rewards" class="headerlink" title="Piecewise-Stationary Combinatorial Semi-Bandit with Causally Related Rewards"></a>Piecewise-Stationary Combinatorial Semi-Bandit with Causally Related Rewards</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14138">http://arxiv.org/abs/2307.14138</a></li>
<li>repo_url: None</li>
<li>paper_authors: Behzad Nourani-Koliji, Steven Bilaj, Amir Rezaei Balef, Setareh Maghsudi</li>
<li>for: 解决 piecewise stationary combinatorial semi-bandit问题，处理非站台环境下的变化和 causal 关系。</li>
<li>methods: 使用 Upper Confidence Bound (UCB) 算法，并采用适应性的 GLR 测试来检测变化。 新引入 group restart 策略以适应结构化环境。</li>
<li>results:  theoretically 确定了变化数量对性能的影响，并且在实际场景中比 benchmark 表现更好。<details>
<summary>Abstract</summary>
We study the piecewise stationary combinatorial semi-bandit problem with causally related rewards. In our nonstationary environment, variations in the base arms' distributions, causal relationships between rewards, or both, change the reward generation process. In such an environment, an optimal decision-maker must follow both sources of change and adapt accordingly. The problem becomes aggravated in the combinatorial semi-bandit setting, where the decision-maker only observes the outcome of the selected bundle of arms. The core of our proposed policy is the Upper Confidence Bound (UCB) algorithm. We assume the agent relies on an adaptive approach to overcome the challenge. More specifically, it employs a change-point detector based on the Generalized Likelihood Ratio (GLR) test. Besides, we introduce the notion of group restart as a new alternative restarting strategy in the decision making process in structured environments. Finally, our algorithm integrates a mechanism to trace the variations of the underlying graph structure, which captures the causal relationships between the rewards in the bandit setting. Theoretically, we establish a regret upper bound that reflects the effects of the number of structural- and distribution changes on the performance. The outcome of our numerical experiments in real-world scenarios exhibits applicability and superior performance of our proposal compared to the state-of-the-art benchmarks.
</details>
<details>
<summary>摘要</summary>
我们研究分割站位的 combinatorial 半带兽问题，其中奖励的生成过程受到基础武器的分布变化、奖励之间的 causal 关系变化或者两者同时变化。在这种非站ARY环境下，一个优化的决策者需要同时考虑这些变化并适应应对。在 combinatorial 半带兽设置下，决策者只能观察选择的武器集的结果。我们的提议的策略是使用 Upper Confidence Bound（UCB）算法。我们假设Agent使用适应的方法来解决这个挑战。具体来说，它使用基于 Generalized Likelihood Ratio（GLR）测试的变化检测器。此外，我们引入了一种新的结构化环境中的 restart 策略——组合重启。最后，我们的算法包含一个跟踪下面结构变化的机制，该结构变化捕捉了奖励之间的 causal 关系。理论上，我们确定了一个 regret Upper bound，该 bound 反映了结构变化和分布变化对性能的影响。实际上，我们的数值实验在真实世界情况下展现了我们的提议的可应用性和优越性，相比之下现状标准 benchmark。
</details></li>
</ul>
<hr>
<h2 id="Developing-and-Evaluating-Tiny-to-Medium-Sized-Turkish-BERT-Models"><a href="#Developing-and-Evaluating-Tiny-to-Medium-Sized-Turkish-BERT-Models" class="headerlink" title="Developing and Evaluating Tiny to Medium-Sized Turkish BERT Models"></a>Developing and Evaluating Tiny to Medium-Sized Turkish BERT Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14134">http://arxiv.org/abs/2307.14134</a></li>
<li>repo_url: None</li>
<li>paper_authors: Himmet Toprak Kesgin, Muzaffer Kaan Yuce, Mehmet Fatih Amasyali</li>
<li>for: This paper aims to bridge the research gap in less-resourced languages by introducing and evaluating tiny, mini, small, and medium-sized uncased Turkish BERT models.</li>
<li>methods: The authors trained these models on a diverse dataset encompassing over 75GB of text from multiple sources and tested them on several tasks, including mask prediction, sentiment analysis, news classification, and zero-shot classification.</li>
<li>results: Despite their smaller size, the models exhibited robust performance, including zero-shot task, while ensuring computational efficiency and faster execution times.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文目标是bridging the research gap in less-resourced languages,通过引入和评估不同大小的uncased Turkish BERT模型。</li>
<li>methods: 作者使用了多种任务和数据集来训练这些模型，包括偏好预测、情感分析、新闻分类和零批预测。</li>
<li>results:  despite their smaller size, these models showed robust performance, including zero-shot task, while ensuring computational efficiency and faster execution times.<details>
<summary>Abstract</summary>
This study introduces and evaluates tiny, mini, small, and medium-sized uncased Turkish BERT models, aiming to bridge the research gap in less-resourced languages. We trained these models on a diverse dataset encompassing over 75GB of text from multiple sources and tested them on several tasks, including mask prediction, sentiment analysis, news classification, and, zero-shot classification. Despite their smaller size, our models exhibited robust performance, including zero-shot task, while ensuring computational efficiency and faster execution times. Our findings provide valuable insights into the development and application of smaller language models, especially in the context of the Turkish language.
</details>
<details>
<summary>摘要</summary>
Note:* "tiny" refers to models with fewer parameters, typically less than 100M;* "mini" refers to models with parameters between 100M and 500M;* "small" refers to models with parameters between 500M and 1B;* "medium-sized" refers to models with parameters between 1B and 2B.Also, "uncased" means that the models were trained without the use of capitalization, which is a common practice in natural language processing tasks.
</details></li>
</ul>
<hr>
<h2 id="A-semantics-driven-methodology-for-high-quality-image-annotation"><a href="#A-semantics-driven-methodology-for-high-quality-image-annotation" class="headerlink" title="A semantics-driven methodology for high-quality image annotation"></a>A semantics-driven methodology for high-quality image annotation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14119">http://arxiv.org/abs/2307.14119</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fausto Giunchiglia, Mayukh Bagchi, Xiaolei Diao</li>
<li>for: 本研究的目的是提出一种基于自然语言处理、知识表示和计算机视觉的方法，以降低对图像标注的主观决策。</li>
<li>methods: 该方法利用WordNet语义层次结构来提供图像标注的意义，并通过基于物品和视觉属性的对应来驱动图像的标注。</li>
<li>results: 该方法在ImageNet层次中的图像上进行了验证，并显示了降低主观决策的效果。<details>
<summary>Abstract</summary>
Recent work in Machine Learning and Computer Vision has highlighted the presence of various types of systematic flaws inside ground truth object recognition benchmark datasets. Our basic tenet is that these flaws are rooted in the many-to-many mappings which exist between the visual information encoded in images and the intended semantics of the labels annotating them. The net consequence is that the current annotation process is largely under-specified, thus leaving too much freedom to the subjective judgment of annotators. In this paper, we propose vTelos, an integrated Natural Language Processing, Knowledge Representation, and Computer Vision methodology whose main goal is to make explicit the (otherwise implicit) intended annotation semantics, thus minimizing the number and role of subjective choices. A key element of vTelos is the exploitation of the WordNet lexico-semantic hierarchy as the main means for providing the meaning of natural language labels and, as a consequence, for driving the annotation of images based on the objects and the visual properties they depict. The methodology is validated on images populating a subset of the ImageNet hierarchy.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose vTelos, an integrated methodology that combines Natural Language Processing, Knowledge Representation, and Computer Vision to explicitly define the intended annotation semantics. This approach leverages the WordNet lexico-semantic hierarchy to provide meaning to natural language labels and drive the annotation of images based on the objects and visual properties they depict. We validate the methodology on a subset of the ImageNet hierarchy.
</details></li>
</ul>
<hr>
<h2 id="GraphRNN-Revisited-An-Ablation-Study-and-Extensions-for-Directed-Acyclic-Graphs"><a href="#GraphRNN-Revisited-An-Ablation-Study-and-Extensions-for-Directed-Acyclic-Graphs" class="headerlink" title="GraphRNN Revisited: An Ablation Study and Extensions for Directed Acyclic Graphs"></a>GraphRNN Revisited: An Ablation Study and Extensions for Directed Acyclic Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14109">http://arxiv.org/abs/2307.14109</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taniya Das, Mark Koch, Maya Ravichandran, Nikhil Khatri</li>
<li>for: 学习图形生成模型</li>
<li>methods: 使用深度学习架构GraphRNN，并对基线模型进行评估和简要改进</li>
<li>results: 1) 对You等人提出的GraphRNN架构进行重现并评估，并发现BFSTraversal对模型性能有重要贡献；2) 对GraphRNN进行扩展，使其可以生成直接的有向无环图，并在实际数据集上达到显著提高。<details>
<summary>Abstract</summary>
GraphRNN is a deep learning-based architecture proposed by You et al. for learning generative models for graphs. We replicate the results of You et al. using a reproduced implementation of the GraphRNN architecture and evaluate this against baseline models using new metrics. Through an ablation study, we find that the BFS traversal suggested by You et al. to collapse representations of isomorphic graphs contributes significantly to model performance. Additionally, we extend GraphRNN to generate directed acyclic graphs by replacing the BFS traversal with a topological sort. We demonstrate that this method improves significantly over a directed-multiclass variant of GraphRNN on a real-world dataset.
</details>
<details>
<summary>摘要</summary>
GRaphRNN 是一种深度学习建议的架构，由 You 等人提出用于学习图形生成模型。我们使用重现 GRaphRNN 架构的实现来重现 You 等人的结果，并对基线模型进行评估。通过一个剥削研究，我们发现 You 等人建议的 BFS 搜索方法可以帮助 collapse 同构图的表示，对模型性能产生重要贡献。此外，我们将 GRaphRNN 扩展到生成指定的有向无环图，通过将 BFS 搜索替换为拓扑排序。我们示出了这种方法在一个真实的数据集上表现明显更好。
</details></li>
</ul>
<hr>
<h2 id="Actions-Speak-What-You-Want-Provably-Sample-Efficient-Reinforcement-Learning-of-the-Quantal-Stackelberg-Equilibrium-from-Strategic-Feedbacks"><a href="#Actions-Speak-What-You-Want-Provably-Sample-Efficient-Reinforcement-Learning-of-the-Quantal-Stackelberg-Equilibrium-from-Strategic-Feedbacks" class="headerlink" title="Actions Speak What You Want: Provably Sample-Efficient Reinforcement Learning of the Quantal Stackelberg Equilibrium from Strategic Feedbacks"></a>Actions Speak What You Want: Provably Sample-Efficient Reinforcement Learning of the Quantal Stackelberg Equilibrium from Strategic Feedbacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14085">http://arxiv.org/abs/2307.14085</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siyu Chen, Mengdi Wang, Zhuoran Yang</li>
<li>for: The paper is written for learning a Quantal Stackelberg Equilibrium (QSE) in an episodic Markov game with a leader-follower structure.</li>
<li>methods: The paper uses reinforcement learning (RL) and entropy-regularized policy optimization to solve the leader’s decision-making problem. The authors propose sample-efficient algorithms for both the online and offline settings, based on maximum likelihood estimation and model-free or model-based RL.</li>
<li>results: The paper achieves sublinear regret upper bounds for the leader’s decision-making problem, and also quantifies the uncertainty of the estimators. The authors propose optimistic and pessimistic algorithms for online and offline settings, and show that their algorithms are computationally efficient when specialized to the linear and myopic setting.<details>
<summary>Abstract</summary>
We study reinforcement learning (RL) for learning a Quantal Stackelberg Equilibrium (QSE) in an episodic Markov game with a leader-follower structure. In specific, at the outset of the game, the leader announces her policy to the follower and commits to it. The follower observes the leader's policy and, in turn, adopts a quantal response policy by solving an entropy-regularized policy optimization problem induced by leader's policy. The goal of the leader is to find her optimal policy, which yields the optimal expected total return, by interacting with the follower and learning from data. A key challenge of this problem is that the leader cannot observe the follower's reward, and needs to infer the follower's quantal response model from his actions against leader's policies. We propose sample-efficient algorithms for both the online and offline settings, in the context of function approximation. Our algorithms are based on (i) learning the quantal response model via maximum likelihood estimation and (ii) model-free or model-based RL for solving the leader's decision making problem, and we show that they achieve sublinear regret upper bounds. Moreover, we quantify the uncertainty of these estimators and leverage the uncertainty to implement optimistic and pessimistic algorithms for online and offline settings. Besides, when specialized to the linear and myopic setting, our algorithms are also computationally efficient. Our theoretical analysis features a novel performance-difference lemma which incorporates the error of quantal response model, which might be of independent interest.
</details>
<details>
<summary>摘要</summary>
我们研究利用强化学习（RL）学习一个量化Stackelberg平衡（QSE）在一个 episodic Markov 游戏中，具有领袖-追随者结构。具体来说，在游戏开始时，领袖公布她的策略给追随者，并将其固定下来。追随者根据领袖的策略采取一个量化响应策略，这是通过解决由领袖策略引起的 entropy-regularized 策略优化问题来实现的。领袖的目标是找到她的优化策略，使得她在与追随者交互时获得最优预期总回报。一个关键挑战是，领袖无法见到追随者的奖励，她需要从追随者的行为中推断出追随者的量化响应模型。我们提出了 sample-efficient 算法，这些算法基于（i）通过最大可信度估计学习量化响应模型，以及（ii）模型自由或模型基于 RL 解决领袖决策问题。我们证明了这些算法可以达到负线性 regret Upper bound。此外，我们还评估了这些估计器的uncertainty，并利用这些uncertainty来实现在线和离线设置中的优胜算法。此外，当特化到线性和偏向设置时，我们的算法也是计算效率高的。我们的理论分析包括一个新的性能差异 lemma，它可能是独立的兴趣。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-simulate-partially-known-spatio-temporal-dynamics-with-trainable-difference-operators"><a href="#Learning-to-simulate-partially-known-spatio-temporal-dynamics-with-trainable-difference-operators" class="headerlink" title="Learning to simulate partially known spatio-temporal dynamics with trainable difference operators"></a>Learning to simulate partially known spatio-temporal dynamics with trainable difference operators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14395">http://arxiv.org/abs/2307.14395</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiang Huang, Zhuoyuan Li, Hongsheng Liu, Zidong Wang, Hongye Zhou, Bin Dong, Bei Hua</li>
<li>for: 用神经网络模拟空间时间动态的研究在最近几年得到了广泛关注。然而，大多数现有方法采用纯数据驱动黑盒模型，具有限制精度和可读性。</li>
<li>methods: 我们提出一种新的混合架构，名为PDE-Net++，它将可训练的差分算子与黑盒模型结合在一起，并嵌入部分先验知识。我们还提出了两种不同的差分层：可训练的flipping差分层（TFDL）和可训练的动态差分层（TDDL）。</li>
<li>results: 数值实验表明，PDE-Net++的预测精度较高，并且在推断过程中表现出色。相比之下，黑盒模型的预测精度较差。<details>
<summary>Abstract</summary>
Recently, using neural networks to simulate spatio-temporal dynamics has received a lot of attention. However, most existing methods adopt pure data-driven black-box models, which have limited accuracy and interpretability. By combining trainable difference operators with black-box models, we propose a new hybrid architecture explicitly embedded with partial prior knowledge of the underlying PDEs named PDE-Net++. Furthermore, we introduce two distinct options called the trainable flipping difference layer (TFDL) and the trainable dynamic difference layer (TDDL) for the difference operators. Numerous numerical experiments have demonstrated that PDE-Net++ has superior prediction accuracy and better extrapolation performance than black-box models.
</details>
<details>
<summary>摘要</summary>
最近，使用神经网络模拟空间时间动态得到了很多关注。然而，大多数现有方法采用纯数据驱动黑盒模型，准确性和可解释性受限。我们提出一种新的混合架构，名为PDE-Net++，其包含可训练的差分算子和黑盒模型。此外，我们还提出了两种不同的选项，即可训练的折衔差层（TFDL）和可训练的动态差层（TDDL）。数字实验证明，PDE-Net++在预测精度和推断性方面都有较高的性能，比黑盒模型更好。
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-Guided-Adaptive-Warping-for-Robust-and-Efficient-Stereo-Matching"><a href="#Uncertainty-Guided-Adaptive-Warping-for-Robust-and-Efficient-Stereo-Matching" class="headerlink" title="Uncertainty Guided Adaptive Warping for Robust and Efficient Stereo Matching"></a>Uncertainty Guided Adaptive Warping for Robust and Efficient Stereo Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14071">http://arxiv.org/abs/2307.14071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junpeng Jing, Jiankun Li, Pengfei Xiong, Jiangyu Liu, Shuaicheng Liu, Yichen Guo, Xin Deng, Mai Xu, Lai Jiang, Leonid Sigal</li>
<li>for: 提高掌控双眼匹配的稳定性和可靠性，以便应用于实际世界中。</li>
<li>methods: 提出了一个新的不确定指标驱动的匹配方法，通过在截图运算中灵活地调整对应点的样本数量，以及将传统非 Parametric 截图改进为可学习的截图。</li>
<li>results: 实验结果显示，这个方法可以在不需要重新训练的情况下，在 ETH3D、KITTI 和 Middlebury 数据集上取得最佳性能。此外，这个方法还可以在实时应用中实现高性能和轻量级化。<details>
<summary>Abstract</summary>
Correlation based stereo matching has achieved outstanding performance, which pursues cost volume between two feature maps. Unfortunately, current methods with a fixed model do not work uniformly well across various datasets, greatly limiting their real-world applicability. To tackle this issue, this paper proposes a new perspective to dynamically calculate correlation for robust stereo matching. A novel Uncertainty Guided Adaptive Correlation (UGAC) module is introduced to robustly adapt the same model for different scenarios. Specifically, a variance-based uncertainty estimation is employed to adaptively adjust the sampling area during warping operation. Additionally, we improve the traditional non-parametric warping with learnable parameters, such that the position-specific weights can be learned. We show that by empowering the recurrent network with the UGAC module, stereo matching can be exploited more robustly and effectively. Extensive experiments demonstrate that our method achieves state-of-the-art performance over the ETH3D, KITTI, and Middlebury datasets when employing the same fixed model over these datasets without any retraining procedure. To target real-time applications, we further design a lightweight model based on UGAC, which also outperforms other methods over KITTI benchmarks with only 0.6 M parameters.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:相关基于的三维匹配已经实现了出色的性能，它追求了两个特征图的成本量。然而，当前使用固定模型时，不同数据集上的性能并不uniform，这限制了它们在实际应用中的可行性。为了解决这个问题，这篇文章提出了一新的视角，即动态计算相关性的方法。一种名为Uncertainty Guided Adaptive Correlation（UGAC）模块被引入，以适应不同的enario。在扭曲操作中，基于偏差值的不确定性估计来动态调整抽样区域。此外，我们改进了传统的非参数化扭曲，使得learnable参数可以被学习。我们表明，通过将Recurrent Network激活UGAC模块，可以更加稳定地和有效地进行三维匹配。广泛的实验表明，我们的方法在ETH3D、KITTI和Middlebury数据集上达到了 Fix 模型不需要 retrained 的最佳性能。为了实现实时应用，我们进一步设计了一种具有UGAC模块的轻量级模型，它也在KITTI benchmark上超越了其他方法，只有0.6M参数。
</details></li>
</ul>
<hr>
<h2 id="Hypergraph-Isomorphism-Computation"><a href="#Hypergraph-Isomorphism-Computation" class="headerlink" title="Hypergraph Isomorphism Computation"></a>Hypergraph Isomorphism Computation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14394">http://arxiv.org/abs/2307.14394</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifan Feng, Jiashu Han, Shihui Ying, Yue Gao<br>for: 这篇论文的目的是解决高阶结构信息的问题，并且提出了一个基于Weisfiler-Lehman test算法的高阶图变换测试方法，以及两种基于这个算法的专案架构。methods: 这篇论文使用了Weisfiler-Lehman test算法来解决高阶图变换测试问题，并且提出了一个基于这个算法的专案架构，包括Hypergraph Weisfeiler-Lehamn Subtree Kernel和Hypergraph Weisfeiler-Lehamn Hyperedge Kernel。results: 这篇论文的结果显示，使用了提出的方法可以在处理复杂高阶图结构时实现高效的运行速度，比起其他常用的核心基于方法更快，甚至可以在80倍以上的时间内运行。<details>
<summary>Abstract</summary>
The isomorphism problem is a fundamental problem in network analysis, which involves capturing both low-order and high-order structural information. In terms of extracting low-order structural information, graph isomorphism algorithms analyze the structural equivalence to reduce the solver space dimension, which demonstrates its power in many applications, such as protein design, chemical pathways, and community detection. For the more commonly occurring high-order relationships in real-life scenarios, the problem of hypergraph isomorphism, which effectively captures these high-order structural relationships, cannot be straightforwardly addressed using graph isomorphism methods. Besides, the existing hypergraph kernel methods may suffer from high memory consumption or inaccurate sub-structure identification, thus yielding sub-optimal performance. In this paper, to address the abovementioned problems, we first propose the hypergraph Weisfiler-Lehman test algorithm for the hypergraph isomorphism test problem by generalizing the Weisfiler-Lehman test algorithm from graphs to hypergraphs. Secondly, based on the presented algorithm, we propose a general hypergraph Weisfieler-Lehman kernel framework and implement two instances, which are Hypergraph Weisfeiler-Lehamn Subtree Kernel and Hypergraph Weisfeiler-Lehamn Hyperedge Kernel. In order to fulfill our research objectives, a comprehensive set of experiments was meticulously designed, including seven graph classification datasets and 12 hypergraph classification datasets. Results on hypergraph classification datasets show significant improvements compared to other typical kernel-based methods, which demonstrates the effectiveness of the proposed methods. In our evaluation, we found that our proposed methods outperform the second-best method in terms of runtime, running over 80 times faster when handling complex hypergraph structures.
</details>
<details>
<summary>摘要</summary>
“iso”问题是网络分析中的基本问题，它涉及到捕捉低阶和高阶结构信息。在提取低阶结构信息方面，图 isomorphism 算法可以将结构等价性缩小到解决空间维度，这种能力在蛋白质设计、化学路径和社区检测等多个应用中得到了证明。然而，在实际生活中更常出现的高阶关系，高阶图 isomorphism 问题不能直接使用图 isomorphism 方法处理。此外，现有的高阶kernel方法可能会具有高内存消耗或不准确的结构特征标识，从而导致低效性。在本文中，我们提出了高阶 Weisfiler-Lehman 测试算法来解决上述问题，并基于该算法提出了一种总体的高阶 Weisfiler-Lehman kernel框架。此外，我们还实现了两个实例：高阶 Weisfeiler-Lehamn 子树kernel和高阶 Weisfeiler-Lehamn 边kernel。为了实现我们的研究目标，我们细心设计了一系列实验，包括7个图分类 dataset 和12个高阶图分类 dataset。结果表明，我们的提出的方法在高阶图分类 dataset 上具有显著的改善，这表明了我们的方法的有效性。在我们的评估中，我们发现了我们的提出的方法在处理复杂的高阶结构时的运行时间比其他常见的 kernel-based 方法快得多，达到80倍以上。
</details></li>
</ul>
<hr>
<h2 id="Acceptable-risks-in-Europe’s-proposed-AI-Act-Reasonableness-and-other-principles-for-deciding-how-much-risk-management-is-enough"><a href="#Acceptable-risks-in-Europe’s-proposed-AI-Act-Reasonableness-and-other-principles-for-deciding-how-much-risk-management-is-enough" class="headerlink" title="Acceptable risks in Europe’s proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough"></a>Acceptable risks in Europe’s proposed AI Act: Reasonableness and other principles for deciding how much risk management is enough</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02047">http://arxiv.org/abs/2308.02047</a></li>
<li>repo_url: None</li>
<li>paper_authors: Henry Fraser, Jose-Miguel Bello y Villarino<br>for:The paper evaluates the European Commission’s proposed AI Act’s approach to risk management and risk acceptability for high-risk AI systems.methods:The paper critiques the Act’s provisions on risk acceptability, arguing that they are unworkable and do not promote a proportionate regulatory burden or trustworthiness.results:The paper suggests that the European Parliament’s recent draft amendments to the risk management provisions, which include “reasonableness” and cost-benefit analysis, are more workable and better balance the goals of proportionality and trustworthiness. The paper also emphasizes the importance of civic legitimacy in risk acceptability judgments, including detailed guidance or involvement from regulators and meaningful input from affected stakeholders.Here is the same information in Simplified Chinese text:for:这篇论文评估欧盟委员会的提议的人工智能法案中的风险管理和风险可接受性方面的高风险人工智能系统。methods:论文批判法案中的风险接受性条款，认为它们不实施可持续的规制负担，也不促进信任worthy的人工智能。results:论文认为欧洲 parlament最新的修订草案中的风险管理条款，包括“合理”的原则，可以更好地实现可持续的规制负担和信任worthy的人工智能。论文还强调了风险接受性评估的公民合法性的重要性，包括 regulators提供详细指南或参与，以及affected stakeholders的意见参与。<details>
<summary>Abstract</summary>
This paper critically evaluates the European Commission's proposed AI Act's approach to risk management and risk acceptability for high-risk AI systems that pose risks to fundamental rights and safety. The Act aims to promote "trustworthy" AI with a proportionate regulatory burden. Its provisions on risk acceptability require residual risks from high-risk systems to be reduced or eliminated "as far as possible", having regard to the "state of the art". This criterion, especially if interpreted narrowly, is unworkable and promotes neither proportionate regulatory burden, nor trustworthiness. By contrast the Parliament's most recent draft amendments to the risk management provisions introduce "reasonableness", cost-benefit analysis, and are more transparent about the value-laden and contextual nature of risk acceptability judgements. This paper argues that the Parliament's approach is more workable, and better balances the goals of proportionality and trustworthiness. It explains what reasonableness in risk acceptability judgments would entail, drawing on principles from negligence law and European medical devices regulation. And it contends that the approach to risk acceptability judgments need a firm foundation of civic legitimacy: including detailed guidance or involvement from regulators, and meaningful input from affected stakeholders.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Open-Image-Content-Disarm-And-Reconstruction"><a href="#Open-Image-Content-Disarm-And-Reconstruction" class="headerlink" title="Open Image Content Disarm And Reconstruction"></a>Open Image Content Disarm And Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14057">http://arxiv.org/abs/2307.14057</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eli Belkind, Ran Dubin, Amit Dvir</li>
<li>for: 本研究旨在提出一种图像内容级落实和重建（ICDR）系统，以防止恶意软件使用图像隐藏恶意脚本或敏感数据。</li>
<li>methods: 该系统采用零信任方式，对图像文件进行分析和清理，以除除恶意软件和敏感数据。</li>
<li>results: 实验结果表明，ICDR系统能够准确地检测和移除图像文件中的恶意软件和敏感数据，同时保持图像质量和文件可用性。<details>
<summary>Abstract</summary>
With the advance in malware technology, attackers create new ways to hide their malicious code from antivirus services. One way to obfuscate an attack is to use common files as cover to hide the malicious scripts, so the malware will look like a legitimate file. Although cutting-edge Artificial Intelligence and content signature exist, evasive malware successfully bypasses next-generation malware detection using advanced methods like steganography. Some of the files commonly used to hide malware are image files (e.g., JPEG). In addition, some malware use steganography to hide malicious scripts or sensitive data in images. Steganography in images is difficult to detect even with specialized tools. Image-based attacks try to attack the user's device using malicious payloads or utilize image steganography to hide sensitive data inside legitimate images and leak it outside the user's device. Therefore in this paper, we present a novel Image Content Disarm and Reconstruction (ICDR). Our ICDR system removes potential malware, with a zero trust approach, while maintaining high image quality and file usability. By extracting the image data, removing it from the rest of the file, and manipulating the image pixels, it is possible to disable or remove the hidden malware inside the file.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="One-Nearest-Neighborhood-Guides-Inlier-Estimation-for-Unsupervised-Point-Cloud-Registration"><a href="#One-Nearest-Neighborhood-Guides-Inlier-Estimation-for-Unsupervised-Point-Cloud-Registration" class="headerlink" title="One-Nearest Neighborhood Guides Inlier Estimation for Unsupervised Point Cloud Registration"></a>One-Nearest Neighborhood Guides Inlier Estimation for Unsupervised Point Cloud Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14019">http://arxiv.org/abs/2307.14019</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongzhe Yuan, Yue Wu, Maoguo Gong, Qiguang Miao, A. K. Qin</li>
<li>for: 这篇论文是为了提高无监督点云注册方法的精度，尤其是在部分重叠的场景下，而设计的。</li>
<li>methods: 该论文提出了一种有效的无监督点云注册方法，通过捕捉源点云和其相对参照点云的几何结构一致性来提高准确率。</li>
<li>results: 该论文通过实验证明了该方法的效iveness，并且在Synthetic和实际数据集上都达到了优秀的结果。<details>
<summary>Abstract</summary>
The precision of unsupervised point cloud registration methods is typically limited by the lack of reliable inlier estimation and self-supervised signal, especially in partially overlapping scenarios. In this paper, we propose an effective inlier estimation method for unsupervised point cloud registration by capturing geometric structure consistency between the source point cloud and its corresponding reference point cloud copy. Specifically, to obtain a high quality reference point cloud copy, an One-Nearest Neighborhood (1-NN) point cloud is generated by input point cloud. This facilitates matching map construction and allows for integrating dual neighborhood matching scores of 1-NN point cloud and input point cloud to improve matching confidence. Benefiting from the high quality reference copy, we argue that the neighborhood graph formed by inlier and its neighborhood should have consistency between source point cloud and its corresponding reference copy. Based on this observation, we construct transformation-invariant geometric structure representations and capture geometric structure consistency to score the inlier confidence for estimated correspondences between source point cloud and its reference copy. This strategy can simultaneously provide the reliable self-supervised signal for model optimization. Finally, we further calculate transformation estimation by the weighted SVD algorithm with the estimated correspondences and corresponding inlier confidence. We train the proposed model in an unsupervised manner, and extensive experiments on synthetic and real-world datasets illustrate the effectiveness of the proposed method.
</details>
<details>
<summary>摘要</summary>
Typically, the precision of unsupervised point cloud registration methods is limited by the lack of reliable inlier estimation and self-supervised signal, especially in partially overlapping scenarios. In this paper, we propose an effective inlier estimation method for unsupervised point cloud registration by capturing geometric structure consistency between the source point cloud and its corresponding reference point cloud copy. Specifically, we generate an One-Nearest Neighborhood (1-NN) point cloud by input point cloud to facilitate matching map construction and improve matching confidence. Benefiting from the high-quality reference copy, we argue that the neighborhood graph formed by inlier and its neighborhood should have consistency between the source point cloud and its corresponding reference copy. Based on this observation, we construct transformation-invariant geometric structure representations and capture geometric structure consistency to score the inlier confidence for estimated correspondences between the source point cloud and its reference copy. This strategy can simultaneously provide a reliable self-supervised signal for model optimization. Finally, we calculate transformation estimation by the weighted SVD algorithm with the estimated correspondences and corresponding inlier confidence. We train the proposed model in an unsupervised manner, and extensive experiments on synthetic and real-world datasets illustrate the effectiveness of the proposed method.
</details></li>
</ul>
<hr>
<h2 id="ESSAformer-Efficient-Transformer-for-Hyperspectral-Image-Super-resolution"><a href="#ESSAformer-Efficient-Transformer-for-Hyperspectral-Image-Super-resolution" class="headerlink" title="ESSAformer: Efficient Transformer for Hyperspectral Image Super-resolution"></a>ESSAformer: Efficient Transformer for Hyperspectral Image Super-resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14010">http://arxiv.org/abs/2307.14010</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingjin Zhang, Chi Zhang, Qiming Zhang, Jie Guo, Xinbo Gao, Jing Zhang</li>
<li>for:  restaura un alta resolução imagem hiperspectral a partir de uma observação de baixa resolução</li>
<li>methods: utiliza uma rede de transformador com estrutura de refinamento iterativo e uma nova métrica de similaridade espectral para incorporar informações de espectro na formação da imagem</li>
<li>results: gerou imagens de alta resolução mais naturais e obteve resultados visuais e quantitativos excelentes sem precisar de pretreinamento em grandes conjuntos de dados<details>
<summary>Abstract</summary>
Single hyperspectral image super-resolution (single-HSI-SR) aims to restore a high-resolution hyperspectral image from a low-resolution observation. However, the prevailing CNN-based approaches have shown limitations in building long-range dependencies and capturing interaction information between spectral features. This results in inadequate utilization of spectral information and artifacts after upsampling. To address this issue, we propose ESSAformer, an ESSA attention-embedded Transformer network for single-HSI-SR with an iterative refining structure. Specifically, we first introduce a robust and spectral-friendly similarity metric, \ie, the spectral correlation coefficient of the spectrum (SCC), to replace the original attention matrix and incorporates inductive biases into the model to facilitate training. Built upon it, we further utilize the kernelizable attention technique with theoretical support to form a novel efficient SCC-kernel-based self-attention (ESSA) and reduce attention computation to linear complexity. ESSA enlarges the receptive field for features after upsampling without bringing much computation and allows the model to effectively utilize spatial-spectral information from different scales, resulting in the generation of more natural high-resolution images. Without the need for pretraining on large-scale datasets, our experiments demonstrate ESSA's effectiveness in both visual quality and quantitative results.
</details>
<details>
<summary>摘要</summary>
单个多spectral像超分辨（单个HSI-SR）目标是从低分辨度观测获取高分辨度多spectral像。然而，现有的CNN基于方法具有限制性，不能建立长距离依赖关系和 spectral特征之间的交互信息。这会导致使用spectral信息的不足和 после upsampling  artifacts。为解决这个问题，我们提出了ESSAformer，一种基于 transformer 网络的 ESSA 注意力嵌入结构，其中包括迭代性修复结构。具体来说，我们首先引入一种可靠的 spectral-friendly 相似度指标，即spectrum 相似度系数（SCC），以 replacing 原始注意力矩阵，并通过这个指标来带入 inductive biases 到模型中，以便训练。然后，我们利用 kernelizable 注意力技术，并有理论支持，将SCC 转化为一种高效的 ESSA 注意力，从而降低注意力计算的复杂性。ESSA 可以在 upsampling 后扩大特征的接受场，无需增加计算量，并且可以有效地利用不同的scale中的 spatial-spectral 信息，从而生成更自然的高分辨度图像。在无需大规模数据预训练的情况下，我们的实验表明ESSA 在视觉质量和量化结果方面都有显著的效果。
</details></li>
</ul>
<hr>
<h2 id="DPBERT-Efficient-Inference-for-BERT-based-on-Dynamic-Planning"><a href="#DPBERT-Efficient-Inference-for-BERT-based-on-Dynamic-Planning" class="headerlink" title="DPBERT: Efficient Inference for BERT based on Dynamic Planning"></a>DPBERT: Efficient Inference for BERT based on Dynamic Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00108">http://arxiv.org/abs/2308.00108</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weixin Wu, Hankz Hankui Zhuo</li>
<li>for: 这个研究旨在提高BERT模型在移动设备上的应用，因为现有的输入适应参数推理方法无法充分利用BERT模型的结构。</li>
<li>methods: 我们提出了一个名为“动态观念规划”的精致化策略，它可以通过选择一个序列转换层的子集来加速BERT模型的推理过程。我们将这个方法添加到原始BERT模型中，以便在推理过程中决定哪些层应该被包含或被忽略。</li>
<li>results: 我们在GLUE评量标准上进行实验，结果显示我们的方法可以降低推理时间至75%，同时保持98%的准确度，对比于现有的输入适应方法而言，它具有更好的几何-速度贡献。<details>
<summary>Abstract</summary>
Large-scale pre-trained language models such as BERT have contributed significantly to the development of NLP. However, those models require large computational resources, making it difficult to be applied to mobile devices where computing power is limited. In this paper we aim to address the weakness of existing input-adaptive inference methods which fail to take full advantage of the structure of BERT. We propose Dynamic Planning in BERT, a novel fine-tuning strategy that can accelerate the inference process of BERT through selecting a subsequence of transformer layers list of backbone as a computational path for an input sample. To do this, our approach adds a planning module to the original BERT model to determine whether a layer is included or bypassed during inference. Experimental results on the GLUE benchmark exhibit that our method reduces latency to 75\% while maintaining 98\% accuracy, yielding a better accuracy-speed trade-off compared to state-of-the-art input-adaptive methods.
</details>
<details>
<summary>摘要</summary>
大规模预训练语言模型如BERT对自然语言处理（NLP）发展做出了重要贡献。然而，这些模型需要大量计算资源，使其在移动设备上应用具有有限的计算能力具有困难。在这篇论文中，我们目标是解决现有输入适应推理方法的弱点，这些方法无法完全利用BERT结构的优势。我们提议使用BERT动态规划策略，这是一种新的微调策略，可以通过选择一个序列中的transformer层列表来加速BERT的推理过程。为了实现这一点，我们的方法在原始BERT模型中添加了规划模块，以确定在推理过程中是否包含或绕过某层。实验结果表明，我们的方法可以将延迟时间降低至75%，同时保持98%的准确率，与现有输入适应方法相比，实现了更好的准确率-速度质量比。
</details></li>
</ul>
<hr>
<h2 id="How-User-Language-Affects-Conflict-Fatality-Estimates-in-ChatGPT"><a href="#How-User-Language-Affects-Conflict-Fatality-Estimates-in-ChatGPT" class="headerlink" title="How User Language Affects Conflict Fatality Estimates in ChatGPT"></a>How User Language Affects Conflict Fatality Estimates in ChatGPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00072">http://arxiv.org/abs/2308.00072</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Kazenwadel, Christoph V. Steinert</li>
<li>for: 这份研究旨在探讨OpenAI的ChatGPT语言模型是否受到语言特定的训练数据中的偏观影响。</li>
<li>methods: 研究使用GPT-3.5自动化查询程序，在希伯来和阿拉伯语言中查询了 especific airstrikes，在土耳其语言和кур德语言中查询了另一场战争。</li>
<li>results: 研究发现，当使用攻击者的语言进行查询时，GPT-3.5提供了27±11%比较低的伤亡估计，而且当查询结果存在推卸责任的答案时，这个差异会更大。这种语言偏观可能会增强现有的媒体偏观和信息径，最终增强冲突。<details>
<summary>Abstract</summary>
OpenAI's ChatGPT language model has gained popularity as a powerful tool for complex problem-solving and information retrieval. However, concerns arise about the reproduction of biases present in the language-specific training data. In this study, we address this issue in the context of the Israeli-Palestinian and Turkish-Kurdish conflicts. Using GPT-3.5, we employed an automated query procedure to inquire about casualties in specific airstrikes, in both Hebrew and Arabic for the former conflict and Turkish and Kurdish for the latter. Our analysis reveals that GPT-3.5 provides 27$\pm$11 percent lower fatality estimates when queried in the language of the attacker than in the language of the targeted group. Evasive answers denying the existence of such attacks further increase the discrepancy, creating a novel bias mechanism not present in regular search engines. This language bias has the potential to amplify existing media biases and contribute to information bubbles, ultimately reinforcing conflicts.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Dual-Space-Attacks-against-Random-Walk-based-Anomaly-Detection"><a href="#Dual-Space-Attacks-against-Random-Walk-based-Anomaly-Detection" class="headerlink" title="Dual-Space Attacks against Random-Walk-based Anomaly Detection"></a>Dual-Space Attacks against Random-Walk-based Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14387">http://arxiv.org/abs/2307.14387</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuni-lai/dualattackrw">https://github.com/yuni-lai/dualattackrw</a></li>
<li>paper_authors: Yuni Lai, Marcin Waniek, Yulin Zhu, Liying Li, Jingwen Wu, Tomasz P. Michalak, Talal Rahwan, Kai Zhou</li>
<li>for: 这 paper 旨在探讨 Random Walks-based Anomaly Detection (RWAD) 中的两个攻击表面，即图空间攻击和特征空间攻击。</li>
<li>methods: 作者采用了实际的双空间攻击，包括图空间攻击和特征空间攻击。图空间攻击是一个 би-级优化问题，而特征空间攻击可以通过使用随机游走模型的关闭式解来解决。</li>
<li>results: 实验表明，作者的提出的攻击方法有效地启用了 RWAD 中的目标节点，并且在黑盒设置下进行了跨度攻击。此外，特征空间攻击也有效地降低了目标节点的异常分数。<details>
<summary>Abstract</summary>
Random Walks-based Anomaly Detection (RWAD) is commonly used to identify anomalous patterns in various applications. An intriguing characteristic of RWAD is that the input graph can either be pre-existing or constructed from raw features. Consequently, there are two potential attack surfaces against RWAD: graph-space attacks and feature-space attacks. In this paper, we explore this vulnerability by designing practical dual-space attacks, investigating the interplay between graph-space and feature-space attacks. To this end, we conduct a thorough complexity analysis, proving that attacking RWAD is NP-hard. Then, we proceed to formulate the graph-space attack as a bi-level optimization problem and propose two strategies to solve it: alternative iteration (alterI-attack) or utilizing the closed-form solution of the random walk model (cf-attack). Finally, we utilize the results from the graph-space attacks as guidance to design more powerful feature-space attacks (i.e., graph-guided attacks). Comprehensive experiments demonstrate that our proposed attacks are effective in enabling the target nodes from RWAD with a limited attack budget. In addition, we conduct transfer attack experiments in a black-box setting, which show that our feature attack significantly decreases the anomaly scores of target nodes. Our study opens the door to studying the dual-space attack against graph anomaly detection in which the graph space relies on the feature space.
</details>
<details>
<summary>摘要</summary>
Random Walks-based Anomaly Detection（RWAD）通常用于识别各种应用中的异常模式。RWAD中的一个有趣特点是输入图可以是先前存在的或者从原始特征中构建的。因此，RWAD有两个可能的攻击面：图形空间攻击和特征空间攻击。在这篇论文中，我们探索这一漏洞，并设计了实用的双空间攻击。我们首先进行了全面的复杂度分析，证明攻击RWAD是NP困难的。然后，我们将图形空间攻击形式为二级优化问题，并提出了两种解决方案：alternative iteration（alterI-attack）或者利用随机游走模型的关闭式解（cf-attack）。最后，我们利用图形空间攻击的结果作为指导，设计了更有力的特征空间攻击（i.e., graph-guided attacks）。我们的实验表明，我们提posed的攻击方法可以在有限的攻击预算下启用目标节点。此外，我们进行了黑盒设置下的传输攻击实验，显示我们的特征攻击可以减少目标节点的异常分数。我们的研究开启了图 anomaly detection中的双空间攻击，其中图形空间依赖于特征空间。
</details></li>
</ul>
<hr>
<h2 id="Controlling-the-Latent-Space-of-GANs-through-Reinforcement-Learning-A-Case-Study-on-Task-based-Image-to-Image-Translation"><a href="#Controlling-the-Latent-Space-of-GANs-through-Reinforcement-Learning-A-Case-Study-on-Task-based-Image-to-Image-Translation" class="headerlink" title="Controlling the Latent Space of GANs through Reinforcement Learning: A Case Study on Task-based Image-to-Image Translation"></a>Controlling the Latent Space of GANs through Reinforcement Learning: A Case Study on Task-based Image-to-Image Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13978">http://arxiv.org/abs/2307.13978</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahyar Abbasian, Taha Rajabzadeh, Ahmadreza Moradipari, Seyed Amir Hossein Aqajari, Hongsheng Lu, Amir Rahmani</li>
<li>for:  This paper aims to address the challenge of exerting control over the generation process of Generative Adversarial Networks (GANs) by integrating a reinforcement learning (RL) agent with a latent-space GAN (l-GAN).</li>
<li>methods: The proposed methodology utilizes an actor-critic RL agent with a meticulously designed reward policy to acquire proficiency in navigating the latent space of the l-GAN and generating outputs based on specified tasks.</li>
<li>results: The authors conducted a series of experiments employing the MNIST dataset, including arithmetic addition as an illustrative task, and the outcomes serve to validate their methodology.<details>
<summary>Abstract</summary>
Generative Adversarial Networks (GAN) have emerged as a formidable AI tool to generate realistic outputs based on training datasets. However, the challenge of exerting control over the generation process of GANs remains a significant hurdle. In this paper, we propose a novel methodology to address this issue by integrating a reinforcement learning (RL) agent with a latent-space GAN (l-GAN), thereby facilitating the generation of desired outputs. More specifically, we have developed an actor-critic RL agent with a meticulously designed reward policy, enabling it to acquire proficiency in navigating the latent space of the l-GAN and generating outputs based on specified tasks. To substantiate the efficacy of our approach, we have conducted a series of experiments employing the MNIST dataset, including arithmetic addition as an illustrative task. The outcomes of these experiments serve to validate our methodology. Our pioneering integration of an RL agent with a GAN model represents a novel advancement, holding great potential for enhancing generative networks in the future.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Understanding-Deep-Neural-Networks-via-Linear-Separability-of-Hidden-Layers"><a href="#Understanding-Deep-Neural-Networks-via-Linear-Separability-of-Hidden-Layers" class="headerlink" title="Understanding Deep Neural Networks via Linear Separability of Hidden Layers"></a>Understanding Deep Neural Networks via Linear Separability of Hidden Layers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13962">http://arxiv.org/abs/2307.13962</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chao Zhang, Xinyu Chen, Wensheng Li, Lixue Liu, Wei Wu, Dacheng Tao</li>
<li>For: 本研究用线性可分性来研究深度神经网络的特点。* Methods: 我们首先提出了基于MINKOWSKI差的线性可分性度量（MD-LSM）来评估两个点集的线性可分性度。然后，我们证明了投入更新的网络权重可以提高隐藏层输出的线性可分性度，并且更新后的网络会获得更好的训练性能。此外，我们还研究了活动函数和网络大小（包括宽度和深度）对隐藏层的线性可分性的影响。* Results: 我们通过实验 validate our findings on some popular deep networks, including MLP, CNN, DBN, ResNet, VGGNet, AlexNet, ViT, and GoogLeNet.<details>
<summary>Abstract</summary>
In this paper, we measure the linear separability of hidden layer outputs to study the characteristics of deep neural networks. In particular, we first propose Minkowski difference based linear separability measures (MD-LSMs) to evaluate the linear separability degree of two points sets. Then, we demonstrate that there is a synchronicity between the linear separability degree of hidden layer outputs and the network training performance, i.e., if the updated weights can enhance the linear separability degree of hidden layer outputs, the updated network will achieve a better training performance, and vice versa. Moreover, we study the effect of activation function and network size (including width and depth) on the linear separability of hidden layers. Finally, we conduct the numerical experiments to validate our findings on some popular deep networks including multilayer perceptron (MLP), convolutional neural network (CNN), deep belief network (DBN), ResNet, VGGNet, AlexNet, vision transformer (ViT) and GoogLeNet.
</details>
<details>
<summary>摘要</summary>
在本文中，我们测量了深度神经网络的线性可分性，以研究深度神经网络的特点。特别是，我们首先提出了Minkowski差分基于的线性可分性度量（MD-LSM），用于评估两个点集的线性可分性度。然后，我们示出了潜在的同步现象：如果卷积重量更新可以提高隐藏层输出的线性可分性度，那么更新后的网络将在训练性能上得到提高，并且相反。此外，我们还研究了活化函数和网络大小（包括宽和深度）对隐藏层的线性可分性的影响。最后，我们进行了一些实验，以验证我们的发现在一些流行的深度网络上，包括多层感知网络（MLP）、卷积神经网络（CNN）、深度信念网络（DBN）、ResNet、VGGNet、AlexNet、视transformer（ViT）和GoogLeNet。
</details></li>
</ul>
<hr>
<h2 id="Flexible-Differentially-Private-Vertical-Federated-Learning-with-Adaptive-Feature-Embeddings"><a href="#Flexible-Differentially-Private-Vertical-Federated-Learning-with-Adaptive-Feature-Embeddings" class="headerlink" title="Flexible Differentially Private Vertical Federated Learning with Adaptive Feature Embeddings"></a>Flexible Differentially Private Vertical Federated Learning with Adaptive Feature Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02362">http://arxiv.org/abs/2308.02362</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxi Mi, Hongquan Liu, Yewei Xia, Yiheng Sun, Jihong Guan, Shuigeng Zhou</li>
<li>for: 本研究旨在探讨Vertically Federated Learning（VFL）中隐私保护的缺陷，因为共享特征嵌入可能泄露敏感信息。</li>
<li>methods: 本文提出了一种flexible和通用的方法，即在 differential privacy（DP）下分解隐私保护和任务用途两个目标，并在两个目标之间寻找 equilibria。</li>
<li>results: 经过广泛的实验 validate，提议的 VFL-AFE 框架能够具有防御隐私攻击和保持任务用途的能力，而不需要牺牲 Established DP 机制。<details>
<summary>Abstract</summary>
The emergence of vertical federated learning (VFL) has stimulated concerns about the imperfection in privacy protection, as shared feature embeddings may reveal sensitive information under privacy attacks. This paper studies the delicate equilibrium between data privacy and task utility goals of VFL under differential privacy (DP). To address the generality issue of prior arts, this paper advocates a flexible and generic approach that decouples the two goals and addresses them successively. Specifically, we initially derive a rigorous privacy guarantee by applying norm clipping on shared feature embeddings, which is applicable across various datasets and models. Subsequently, we demonstrate that task utility can be optimized via adaptive adjustments on the scale and distribution of feature embeddings in an accuracy-appreciative way, without compromising established DP mechanisms. We concretize our observation into the proposed VFL-AFE framework, which exhibits effectiveness against privacy attacks and the capacity to retain favorable task utility, as substantiated by extensive experiments.
</details>
<details>
<summary>摘要</summary>
vertical Federated learning (VFL) 的出现引发了隐私保护不足的担忧，因为共享特征表示可能暴露敏感信息面临隐私攻击。这篇论文研究了 VFL 中数据隐私和任务利用目标之间的紧耦合关系，并提出了一种flexible和通用的方法来解决这个问题。Specifically, we initially derive a rigorous privacy guarantee by applying norm clipping on shared feature embeddings, which is applicable across various datasets and models. Subsequently, we demonstrate that task utility can be optimized via adaptive adjustments on the scale and distribution of feature embeddings in an accuracy-appreciative way, without compromising established DP mechanisms. We concretize our observation into the proposed VFL-AFE framework, which exhibits effectiveness against privacy attacks and the capacity to retain favorable task utility, as substantiated by extensive experiments.Here's the word-for-word translation of the text into Simplified Chinese: vertical Federated learning (VFL) 的出现引发了隐私保护不足的担忧，因为共享特征表示可能暴露敏感信息面临隐私攻击。这篇论文研究了 VFL 中数据隐私和任务利用目标之间的紧耦合关系，并提出了一种flexible和通用的方法来解决这个问题。Specifically, we initially derive a rigorous privacy guarantee by applying norm clipping on shared feature embeddings, which is applicable across various datasets and models. Subsequently, we demonstrate that task utility can be optimized via adaptive adjustments on the scale and distribution of feature embeddings in an accuracy-appreciative way, without compromising established DP mechanisms. We concretize our observation into the proposed VFL-AFE framework, which exhibits effectiveness against privacy attacks and the capacity to retain favorable task utility, as substantiated by extensive experiments.
</details></li>
</ul>
<hr>
<h2 id="How-Does-Diffusion-Influence-Pretrained-Language-Models-on-Out-of-Distribution-Data"><a href="#How-Does-Diffusion-Influence-Pretrained-Language-Models-on-Out-of-Distribution-Data" class="headerlink" title="How Does Diffusion Influence Pretrained Language Models on Out-of-Distribution Data?"></a>How Does Diffusion Influence Pretrained Language Models on Out-of-Distribution Data?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13949">http://arxiv.org/abs/2307.13949</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/maybelizzy/diffusion_ood_robustness">https://github.com/maybelizzy/diffusion_ood_robustness</a></li>
<li>paper_authors: Huazheng Wang, Daixuan Cheng, Haifeng Sun, Jingyu Wang, Qi Qi, Jianxin Liao, Jing Wang, Cong Liu</li>
<li>for: 这种研究旨在探讨 diffusion models 如何影响 modern NLP 中的预训语言模型（PLMs）在异常数据（OOD）上的性能。</li>
<li>methods: 该研究使用了 diffusion 模型，包括 forward diffusion 过程和 reverse denoising 过程，以及测试不同训练参数和数据统计特征的实验。</li>
<li>results: 研究发现，在 OOD 数据上，训练 PLMs  WITH diffusion 会下降重建能力；而 diffusion 模型可以有效地检测 OOD 样本，在大多数数据集上达到了领先的性能，具体是absolute accuracy 提高达18%。这些结果表明，diffusion 减少了 PLMs 在 OOD 数据上的Robustness。<details>
<summary>Abstract</summary>
Transformer-based pretrained language models (PLMs) have achieved great success in modern NLP. An important advantage of PLMs is good out-of-distribution (OOD) robustness. Recently, diffusion models have attracted a lot of work to apply diffusion to PLMs. It remains under-explored how diffusion influences PLMs on OOD data. The core of diffusion models is a forward diffusion process which gradually applies Gaussian noise to inputs, and a reverse denoising process which removes noise. The noised input reconstruction is a fundamental ability of diffusion models. We directly analyze OOD robustness by measuring the reconstruction loss, including testing the abilities to reconstruct OOD data, and to detect OOD samples. Experiments are conducted by analyzing different training parameters and data statistical features on eight datasets. It shows that finetuning PLMs with diffusion degrades the reconstruction ability on OOD data. The comparison also shows that diffusion models can effectively detect OOD samples, achieving state-of-the-art performance in most of the datasets with an absolute accuracy improvement up to 18%. These results indicate that diffusion reduces OOD robustness of PLMs.
</details>
<details>
<summary>摘要</summary>
transformer-based pre-trained语言模型（PLM）在现代NLP中取得了很大成功。PLM的一个重要优势是对于不同类型的输入数据（out-of-distribution，OOD）的Robustness。近期，扩散模型在应用扩散到PLM方面吸引了很多研究。然而， diffusion对PLM在OOD数据上的影响还很少研究。扩散模型的核心是一个前向扩散过程，逐渐将输入数据加载到Gaussian噪声中，以及一个反推噪声过程，去除噪声。重要的是，扩散模型可以很好地重建噪声输入。我们直接分析OOD robustness，测试PLM是否能够正确重建OOD数据，以及是否能够检测OOD样本。我们通过对不同的训练参数和数据统计特征进行分析，在八个数据集上进行了实验。结果表明，练化PLMs with diffusion会降低OOD数据的重建能力。 comparison也显示，扩散模型可以有效地检测OOD样本，在大多数数据集中达到了状态的精度提升最多18%。这些结果表明， diffusion减少了PLMs的OOD Robustness。
</details></li>
</ul>
<hr>
<h2 id="Learning-based-Control-for-PMSM-Using-Distributed-Gaussian-Processes-with-Optimal-Aggregation-Strategy"><a href="#Learning-based-Control-for-PMSM-Using-Distributed-Gaussian-Processes-with-Optimal-Aggregation-Strategy" class="headerlink" title="Learning-based Control for PMSM Using Distributed Gaussian Processes with Optimal Aggregation Strategy"></a>Learning-based Control for PMSM Using Distributed Gaussian Processes with Optimal Aggregation Strategy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13945">http://arxiv.org/abs/2307.13945</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenxiao Yin, Xiaobing Dai, Zewen Yang, Yang Shen, Georges Hattab, Hang Zhao</li>
<li>for: 这篇论文的目的是提出一种基于Lyapunov稳定理论的分布式GPR控制策略，用于提高PM synchronous motor的精度控制。</li>
<li>methods: 该策略使用分布式GPR来描述系统，并采用 posterior mean来避免计算复杂的 posterior variance。</li>
<li>results: 在模拟中，该策略得到了证明，并且在高频PM synchronous motor控制中实现了简单、高效的实现。<details>
<summary>Abstract</summary>
The growing demand for accurate control in varying and unknown environments has sparked a corresponding increase in the requirements for power supply components, including permanent magnet synchronous motors (PMSMs). To infer the unknown part of the system, machine learning techniques are widely employed, especially Gaussian process regression (GPR) due to its flexibility of continuous system modeling and its guaranteed performance. For practical implementation, distributed GPR is adopted to alleviate the high computational complexity. However, the study of distributed GPR from a control perspective remains an open problem. In this paper, a control-aware optimal aggregation strategy of distributed GPR for PMSMs is proposed based on the Lyapunov stability theory. This strategy exclusively leverages the posterior mean, thereby obviating the need for computationally intensive calculations associated with posterior variance in alternative approaches. Moreover, the straightforward calculation process of our proposed strategy lends itself to seamless implementation in high-frequency PMSM control. The effectiveness of the proposed strategy is demonstrated in the simulations.
</details>
<details>
<summary>摘要</summary>
随着不确定环境中精准控制的需求增长，电动机组件，包括永磁同步机（PMSM）的要求也在增长。为了推断未知系统部分，机器学习技术广泛应用，特别是 Gaussian process regression（GPR），因为它可以 kontinuous系统模型的灵活性和 garantizado性。但是，从控制角度来看，分布式GPR的研究仍然是一个开放的问题。在这篇论文中，一种基于Lyapunov稳定理论的控制意识优化策略 для分布式GPR在PMSM控制中被提出。这种策略仅仅利用 posterior mean，因此不需要计算量大的 posterior variance在其他方法中所需的计算量。此外，我们提出的计算过程易于实现高频PMSM控制。在 simulations中，我们证明了该策略的有效性。
</details></li>
</ul>
<hr>
<h2 id="Entropy-Neural-Estimation-for-Graph-Contrastive-Learning"><a href="#Entropy-Neural-Estimation-for-Graph-Contrastive-Learning" class="headerlink" title="Entropy Neural Estimation for Graph Contrastive Learning"></a>Entropy Neural Estimation for Graph Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13944">http://arxiv.org/abs/2307.13944</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kunzhan/M-ILBO">https://github.com/kunzhan/M-ILBO</a></li>
<li>paper_authors: Yixuan Ma, Xiaolin Zhang, Peng Zhang, Kun Zhan</li>
<li>for: 本文提出了一种基于对比学习的图гра夫特表示学习方法，目的是提取图гра夫特上的独特高级表示。</li>
<li>methods: 本文使用了一种基于对比学习的方法，即通过最大化对比信息的下界来估算数据集的熵。同时，本文还提出了一种简单 yet effective的子集采样策略，以提高对比表示的精度。</li>
<li>results: 本文通过实验表明，提出的方法可以在七个图гра夫特benchmark上达到当前状态的较好表现。同时，本文还介绍了一种跨视图一致性约束，以保证学习的表示是视图的整体图гра夫特表示的一致。<details>
<summary>Abstract</summary>
Contrastive learning on graphs aims at extracting distinguishable high-level representations of nodes. In this paper, we theoretically illustrate that the entropy of a dataset can be approximated by maximizing the lower bound of the mutual information across different views of a graph, \ie, entropy is estimated by a neural network. Based on this finding, we propose a simple yet effective subset sampling strategy to contrast pairwise representations between views of a dataset. In particular, we randomly sample nodes and edges from a given graph to build the input subset for a view. Two views are fed into a parameter-shared Siamese network to extract the high-dimensional embeddings and estimate the information entropy of the entire graph. For the learning process, we propose to optimize the network using two objectives, simultaneously. Concretely, the input of the contrastive loss function consists of positive and negative pairs. Our selection strategy of pairs is different from previous works and we present a novel strategy to enhance the representation ability of the graph encoder by selecting nodes based on cross-view similarities. We enrich the diversity of the positive and negative pairs by selecting highly similar samples and totally different data with the guidance of cross-view similarity scores, respectively. We also introduce a cross-view consistency constraint on the representations generated from the different views. This objective guarantees the learned representations are consistent across views from the perspective of the entire graph. We conduct extensive experiments on seven graph benchmarks, and the proposed approach achieves competitive performance compared to the current state-of-the-art methods. The source code will be publicly released once this paper is accepted.
</details>
<details>
<summary>摘要</summary>
contrastive learning on graphs aims to extract distinguishable high-level representations of nodes. In this paper, we theoretically prove that the entropy of a dataset can be approximated by maximizing the lower bound of the mutual information across different views of a graph, \ie, entropy is estimated by a neural network. Based on this finding, we propose a simple yet effective subset sampling strategy to contrast pairwise representations between views of a dataset. Specifically, we randomly sample nodes and edges from a given graph to build the input subset for a view. Two views are fed into a parameter-shared Siamese network to extract the high-dimensional embeddings and estimate the information entropy of the entire graph. For the learning process, we propose to optimize the network using two objectives, simultaneously. Concretely, the input of the contrastive loss function consists of positive and negative pairs. Our selection strategy of pairs is different from previous works and we present a novel strategy to enhance the representation ability of the graph encoder by selecting nodes based on cross-view similarities. We enrich the diversity of the positive and negative pairs by selecting highly similar samples and totally different data with the guidance of cross-view similarity scores, respectively. We also introduce a cross-view consistency constraint on the representations generated from the different views. This objective guarantees the learned representations are consistent across views from the perspective of the entire graph. We conduct extensive experiments on seven graph benchmarks, and the proposed approach achieves competitive performance compared to the current state-of-the-art methods. The source code will be publicly released once this paper is accepted.
</details></li>
</ul>
<hr>
<h2 id="Stability-of-Multi-Agent-Learning-Convergence-in-Network-Games-with-Many-Players"><a href="#Stability-of-Multi-Agent-Learning-Convergence-in-Network-Games-with-Many-Players" class="headerlink" title="Stability of Multi-Agent Learning: Convergence in Network Games with Many Players"></a>Stability of Multi-Agent Learning: Convergence in Network Games with Many Players</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13922">http://arxiv.org/abs/2307.13922</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aamal Hussain, Dan Leonte, Francesco Belardinelli, Georgios Piliouras</li>
<li>for: 研究多智能学习在多名玩家游戏中的复杂动态行为。</li>
<li>methods: 使用Q学习方法研究多名玩家游戏的各对各交互和网络结构的影响。</li>
<li>results: 发现在适当的网络条件下，可以实现多名玩家游戏中稳定的学习动态，无论玩家的数量如何。<details>
<summary>Abstract</summary>
The behaviour of multi-agent learning in many player games has been shown to display complex dynamics outside of restrictive examples such as network zero-sum games. In addition, it has been shown that convergent behaviour is less likely to occur as the number of players increase. To make progress in resolving this problem, we study Q-Learning dynamics and determine a sufficient condition for the dynamics to converge to a unique equilibrium in any network game. We find that this condition depends on the nature of pairwise interactions and on the network structure, but is explicitly independent of the total number of agents in the game. We evaluate this result on a number of representative network games and show that, under suitable network conditions, stable learning dynamics can be achieved with an arbitrary number of agents.
</details>
<details>
<summary>摘要</summary>
多体学习在多名玩家游戏中展现出复杂的动力学行为，不受限于严格的网络零游戏例子。此外，我们发现，随着玩家数量增加，协调性行为越来越少有可能出现。为解决这个问题，我们研究了Q学习动力学和确定了一个充分条件，使得动力学在任何网络游戏中 converges to a unique equilibrium。我们发现这个条件取决于对抗对和网络结构，但是不виси于总的agent数量。我们在一些代表性的网络游戏中评估了这些结果，并显示，在适当的网络条件下，可以通过任意数量的代理人实现稳定的学习动力学。
</details></li>
</ul>
<hr>
<h2 id="HyperFed-Hyperbolic-Prototypes-Exploration-with-Consistent-Aggregation-for-Non-IID-Data-in-Federated-Learning"><a href="#HyperFed-Hyperbolic-Prototypes-Exploration-with-Consistent-Aggregation-for-Non-IID-Data-in-Federated-Learning" class="headerlink" title="HyperFed: Hyperbolic Prototypes Exploration with Consistent Aggregation for Non-IID Data in Federated Learning"></a>HyperFed: Hyperbolic Prototypes Exploration with Consistent Aggregation for Non-IID Data in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14384">http://arxiv.org/abs/2307.14384</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinting Liao, Weiming Liu, Chaochao Chen, Pengyang Zhou, Huabin Zhu, Yanchao Tan, Jun Wang, Yue Qi</li>
<li>for: 提高 Federated Learning 下非Identical Independent Distribution（non-IID）Client数据的性能</li>
<li>methods:  Hyperbolic Prototype Tammes Initialization（HPTI）、Hyperbolic Prototype Learning（HPL）和Consistent Aggregation（CA）</li>
<li>results: 在四个数据集上进行了广泛的研究，证明 HyperFed 可以有效地提高 Federated Learning 下 non-IID  Client数据的性能<details>
<summary>Abstract</summary>
Federated learning (FL) collaboratively models user data in a decentralized way. However, in the real world, non-identical and independent data distributions (non-IID) among clients hinder the performance of FL due to three issues, i.e., (1) the class statistics shifting, (2) the insufficient hierarchical information utilization, and (3) the inconsistency in aggregating clients. To address the above issues, we propose HyperFed which contains three main modules, i.e., hyperbolic prototype Tammes initialization (HPTI), hyperbolic prototype learning (HPL), and consistent aggregation (CA). Firstly, HPTI in the server constructs uniformly distributed and fixed class prototypes, and shares them with clients to match class statistics, further guiding consistent feature representation for local clients. Secondly, HPL in each client captures the hierarchical information in local data with the supervision of shared class prototypes in the hyperbolic model space. Additionally, CA in the server mitigates the impact of the inconsistent deviations from clients to server. Extensive studies of four datasets prove that HyperFed is effective in enhancing the performance of FL under the non-IID set.
</details>
<details>
<summary>摘要</summary>
Federated learning (FL) 共同模型用户数据在分布式方式下进行协同学习。然而，在实际世界中，客户端数据分布不匹配（non-IID）会阻碍 FL 的性能，主要问题包括：1）类别统计 Parametric shift，2）不足的层次信息利用，3）客户端聚合不一致。为解决以上问题，我们提出了 HyperFed，它包括以下三个主要模块：1）hyperbolic prototype Tammes initialization（HPTI），2）hyperbolic prototype learning（HPL），3）consistent aggregation（CA）。首先，HPTI 在服务器端构建固定类型和 uniformly distributed 的类prototype，并将其分享给客户端以匹配类统计，导向客户端的准确特征表示。其次，HPL 在每个客户端上在 hyperbolic 模型空间中捕捉地方数据中的层次信息，并在服务器端的 supervision 下进行学习。最后，CA 在服务器端mitigates the impact of inconsistent deviations from clients to server。经验studies of four datasets 表明，HyperFed 可以有效提高 FL 在 non-IID 环境下的性能。
</details></li>
</ul>
<hr>
<h2 id="Embedding-Democratic-Values-into-Social-Media-AIs-via-Societal-Objective-Functions"><a href="#Embedding-Democratic-Values-into-Social-Media-AIs-via-Societal-Objective-Functions" class="headerlink" title="Embedding Democratic Values into Social Media AIs via Societal Objective Functions"></a>Embedding Democratic Values into Social Media AIs via Societal Objective Functions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13912">http://arxiv.org/abs/2307.13912</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenyan Jia, Michelle S. Lam, Minh Chau Mai, Jeff Hancock, Michael S. Bernstein</li>
<li>for: 本研究旨在开发一种基于社会科学理论和方法的人工智能系统，以mitigate partisan animosity在社交媒体上的影响。</li>
<li>methods: 本研究使用了一种方法，将社会科学中已经评估和验证的社会科学构造翻译成人工智能系统中的目标函数，称为社会目标函数。然后，通过使用社会科学中已经开发的问卷Instruments和质量代码本来翻译这些构造，并将其转化为详细的大语言模型提示。</li>
<li>results: 研究发现，使用这种方法可以创建一个评估社交媒体帖子中anti-democratic attitudes的模型，并在三个研究中证明了该模型的有效性。在第一个研究中，通过手动标注（alpha&#x3D;.895）社交媒体帖子中anti-democratic attitudes的分数，并试出多种基于这些分数的 feed ranking 条件，发现可以减少参与者的偏见情感（d&#x3D;.20）和下排帖子（d&#x3D;.25）无需妨碍参与者的体验和参与度。在第二个研究中，通过创建一个民主态度模型，发现与手动标注（rho&#x3D;.75）具有强相关性。最后，在第三个研究中，重复第一个研究，使用民主态度模型代替手动标注，并发现 feed downranking 使用社会目标函数可以减少参与者的偏见情感（d&#x3D;.25）。这种方法提供了一种新的策略，可以基于社会科学理论和方法来减少社交媒体中的社会危害。<details>
<summary>Abstract</summary>
Can we design artificial intelligence (AI) systems that rank our social media feeds to consider democratic values such as mitigating partisan animosity as part of their objective functions? We introduce a method for translating established, vetted social scientific constructs into AI objective functions, which we term societal objective functions, and demonstrate the method with application to the political science construct of anti-democratic attitudes. Traditionally, we have lacked observable outcomes to use to train such models, however, the social sciences have developed survey instruments and qualitative codebooks for these constructs, and their precision facilitates translation into detailed prompts for large language models. We apply this method to create a democratic attitude model that estimates the extent to which a social media post promotes anti-democratic attitudes, and test this democratic attitude model across three studies. In Study 1, we first test the attitudinal and behavioral effectiveness of the intervention among US partisans (N=1,380) by manually annotating (alpha=.895) social media posts with anti-democratic attitude scores and testing several feed ranking conditions based on these scores. Removal (d=.20) and downranking feeds (d=.25) reduced participants' partisan animosity without compromising their experience and engagement. In Study 2, we scale up the manual labels by creating the democratic attitude model, finding strong agreement with manual labels (rho=.75). Finally, in Study 3, we replicate Study 1 using the democratic attitude model instead of manual labels to test its attitudinal and behavioral impact (N=558), and again find that the feed downranking using the societal objective function reduced partisan animosity (d=.25). This method presents a novel strategy to draw on social science theory and methods to mitigate societal harms in social media AIs.
</details>
<details>
<summary>摘要</summary>
可以我们设计人工智能（AI）系统，以考虑民主价值观为其目标函数中的一部分？我们介绍了一种将社会科学建构翻译成AI目标函数的方法，我们称之为社会目标函数，并示例了这种方法应用于政治科学构建中的反民主态度。在过去，我们缺乏可观察的结果来训练这些模型，但社会科学已经开发出了调查工具和质量代码库 для这些构建，其精度使其可以翻译成详细的提示 для大语言模型。我们应用这种方法创建了一个民主态度模型，可以估计社交媒体文章是否推动反民主态度，并在三项研究中测试了这种民主态度模型。在第一项研究中，我们首先测试了对美国党派者（N=1,380）的情感和行为效果，并 manually annotate（α=.895）社交媒体文章的反民主态度得分。去掉（d=.20）和下推文章（d=.25）可以降低参与者的党派仇恨，而不是削弱他们的体验和参与度。在第二项研究中，我们扩大了手动标签，创建了民主态度模型，并发现与手动标签强相关（ρ=.75）。在第三项研究中，我们重复了第一项研究，使用民主态度模型而不是手动标签，并发现feed下推使用社会目标函数减少了党派仇恨（d=.25）。这种方法提供了一种新的策略，可以基于社会科学理论和方法来减少社会媒体AIs中的社会危害。
</details></li>
</ul>
<hr>
<h2 id="Robustness-Verification-of-Deep-Neural-Networks-using-Star-Based-Reachability-Analysis-with-Variable-Length-Time-Series-Input"><a href="#Robustness-Verification-of-Deep-Neural-Networks-using-Star-Based-Reachability-Analysis-with-Variable-Length-Time-Series-Input" class="headerlink" title="Robustness Verification of Deep Neural Networks using Star-Based Reachability Analysis with Variable-Length Time Series Input"></a>Robustness Verification of Deep Neural Networks using Star-Based Reachability Analysis with Variable-Length Time Series Input</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13907">http://arxiv.org/abs/2307.13907</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neelanjana Pal, Diego Manzanas Lopez, Taylor T Johnson</li>
<li>for: 这个论文是为了验证和验议基于神经网络的时序数据分析和预测维护的可靠性和可靠性。</li>
<li>methods: 该论文使用了基于时序数据的神经网络分析，并使用了变量长度输入数据来简化输入处理和提高网络架构的通用性。</li>
<li>results: 该论文通过使用星形可达性分析和一些性能指标来检查神经网络的可靠性，并证明了神经网络的输出受输入噪声影响的影响。<details>
<summary>Abstract</summary>
Data-driven, neural network (NN) based anomaly detection and predictive maintenance are emerging research areas. NN-based analytics of time-series data offer valuable insights into past behaviors and estimates of critical parameters like remaining useful life (RUL) of equipment and state-of-charge (SOC) of batteries. However, input time series data can be exposed to intentional or unintentional noise when passing through sensors, necessitating robust validation and verification of these NNs. This paper presents a case study of the robustness verification approach for time series regression NNs (TSRegNN) using set-based formal methods. It focuses on utilizing variable-length input data to streamline input manipulation and enhance network architecture generalizability. The method is applied to two data sets in the Prognostics and Health Management (PHM) application areas: (1) SOC estimation of a Lithium-ion battery and (2) RUL estimation of a turbine engine. The NNs' robustness is checked using star-based reachability analysis, and several performance measures evaluate the effect of bounded perturbations in the input on network outputs, i.e., future outcomes. Overall, the paper offers a comprehensive case study for validating and verifying NN-based analytics of time-series data in real-world applications, emphasizing the importance of robustness testing for accurate and reliable predictions, especially considering the impact of noise on future outcomes.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>>数据驱动、基于神经网络（NN）的异常检测和预测维护是当前研究领域之一。NN分析时间序列数据可以提供价值的信息，如设备的剩余有用生命（RUL）和电池的状态充电（SOC）。但是，输入时间序列数据可能会受到意外或无意义的噪声影响，因此需要robust验证和验证这些NN。这篇论文介绍了一种基于集合形式方法的NN验证方法，它通过使用可变长输入数据来简化输入处理和提高网络架构的通用性。该方法在两个PHM应用领域的数据集上进行了实践：（1）Li-ion电池SOC估计和（2）涡轮机RUL估计。通过星形可达性分析来检查NN的Robustness，并使用一些性能指标来评估输入噪声对网络输出的影响，即未来的结果。总之，这篇论文提供了一个全面的NP-based analytics验证和验证方法，强调验证NN-based时间序列数据分析的重要性，特别是考虑噪声对未来结果的影响。
</details></li>
</ul>
<hr>
<h2 id="Data-Augmentation-for-Neural-Machine-Translation-using-Generative-Language-Model"><a href="#Data-Augmentation-for-Neural-Machine-Translation-using-Generative-Language-Model" class="headerlink" title="Data Augmentation for Neural Machine Translation using Generative Language Model"></a>Data Augmentation for Neural Machine Translation using Generative Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16833">http://arxiv.org/abs/2307.16833</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seokjin Oh, Su ah Lee, Woohwan Jung</li>
<li>for: 提高机器翻译模型的性能，Addressing the scarcity of large parallel corpora in Neural Machine Translation.</li>
<li>methods: 使用提示基于的数据增强技术，利用大规模语言模型如ChatGPT生成Synthetic parallel corpus，不需要新的模型训练成本。</li>
<li>results: 与未增强基eline相比，提高0.68 Bleu分数。<details>
<summary>Abstract</summary>
Despite the rapid growth in model architecture, the scarcity of large parallel corpora remains the main bottleneck in Neural Machine Translation. Data augmentation is a technique that enhances the performance of data-hungry models by generating synthetic data instead of collecting new ones. We explore prompt-based data augmentation approaches that leverage large-scale language models such as ChatGPT. To create a synthetic parallel corpus, we compare 3 methods using different prompts. We employ two assessment metrics to measure the diversity of the generated synthetic data. This approach requires no further model training cost, which is mandatory in other augmentation methods like back-translation. The proposed method improves the unaugmented baseline by 0.68 BLEU score.
</details>
<details>
<summary>摘要</summary>
尽管模型架构在快速发展，但数据缺乏大量并行 Corpora 仍然是机器翻译神经网络中的主要瓶颈。数据扩充是一种技术，可以提高数据吞吐量模型的性能，而不需要收集新的数据。我们探索了基于 prompt 的数据扩充方法，利用大规模语言模型如 ChatGPT。为创建一个合成并行 Corpora，我们比较了三种不同的 prompt 方法。我们采用了两个评估指标来度量生成的合成数据的多样性。这种方法不需要额外的模型训练成本，与其他扩充方法如 back-translation 不同。我们的方法可以提高无扩充基准值的 BLEU 得分0.68分。
</details></li>
</ul>
<hr>
<h2 id="FinTree-Financial-Dataset-Pretrain-Transformer-Encoder-for-Relation-Extraction"><a href="#FinTree-Financial-Dataset-Pretrain-Transformer-Encoder-for-Relation-Extraction" class="headerlink" title="FinTree: Financial Dataset Pretrain Transformer Encoder for Relation Extraction"></a>FinTree: Financial Dataset Pretrain Transformer Encoder for Relation Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13900">http://arxiv.org/abs/2307.13900</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyunjong Ok</li>
<li>for:  FinTree is written for financial relation extraction tasks, specifically to improve the accuracy of relation predictions between two given entities.</li>
<li>methods: FinTree uses a pre-trained encoder language model, with a novel structure that predicts a masked token instead of the conventional [CLS] token, inspired by the Pattern Exploiting Training methodology. The model is trained with a unique input pattern to provide contextual and positional information about the entities of interest, and a post-processing step ensures accurate predictions in line with the entity types.</li>
<li>results: FinTree outperforms on the REFinD, a large-scale financial relation extraction dataset.<details>
<summary>Abstract</summary>
We present FinTree, Financial Dataset Pretrain Transformer Encoder for Relation Extraction. Utilizing an encoder language model, we further pretrain FinTree on the financial dataset, adapting the model in financial domain tasks. FinTree stands out with its novel structure that predicts a masked token instead of the conventional [CLS] token, inspired by the Pattern Exploiting Training methodology. This structure allows for more accurate relation predictions between two given entities. The model is trained with a unique input pattern to provide contextual and positional information about the entities of interest, and a post-processing step ensures accurate predictions in line with the entity types. Our experiments demonstrate that FinTree outperforms on the REFinD, a large-scale financial relation extraction dataset. The code and pretrained models are available at https://github.com/HJ-Ok/FinTree.
</details>
<details>
<summary>摘要</summary>
我们介绍FinTree，一个基于语言模型的金融 dataset 预训读取器。我们透过使用语言模型，进一步预训 FinTree 在金融领域任务中。FinTree 的独特结构是预测填写的 tokens，而不是 convention 的 [CLS]  tokens，这种结构允许更精确地预测两个 Entities 之间的关系。模型在特定的输入模式下训练，以提供 Contextual 和位置信息，并且进行后处理步骤，以确保预测和 Entities 类型相符。我们的实验表明，FinTree 在 REFinD 大规模金融关系提取 dataset 上表现出色。代码和预训模型可以在 <https://github.com/HJ-Ok/FinTree> 获取。
</details></li>
</ul>
<hr>
<h2 id="Regularizing-Neural-Networks-with-Meta-Learning-Generative-Models"><a href="#Regularizing-Neural-Networks-with-Meta-Learning-Generative-Models" class="headerlink" title="Regularizing Neural Networks with Meta-Learning Generative Models"></a>Regularizing Neural Networks with Meta-Learning Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13899">http://arxiv.org/abs/2307.13899</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shin’ya Yamaguchi, Daiki Chijiwa, Sekitoshi Kanai, Atsutoshi Kumagai, Hisashi Kashima</li>
<li>for: 提高深度学习中的生成数据增强</li>
<li>methods: 利用生成模型生成的 sintetic 样本作为增强数据，并通过 meta 学习来动态确定 sintetic 样本以最小化验证损失</li>
<li>results: 对 six 个数据集进行实验，发现 MGR 可以避免生成数据增强导致性能下降，并稳定超越基elines。<details>
<summary>Abstract</summary>
This paper investigates methods for improving generative data augmentation for deep learning. Generative data augmentation leverages the synthetic samples produced by generative models as an additional dataset for classification with small dataset settings. A key challenge of generative data augmentation is that the synthetic data contain uninformative samples that degrade accuracy. This is because the synthetic samples do not perfectly represent class categories in real data and uniform sampling does not necessarily provide useful samples for tasks. In this paper, we present a novel strategy for generative data augmentation called meta generative regularization (MGR). To avoid the degradation of generative data augmentation, MGR utilizes synthetic samples in the regularization term for feature extractors instead of in the loss function, e.g., cross-entropy. These synthetic samples are dynamically determined to minimize the validation losses through meta-learning. We observed that MGR can avoid the performance degradation of na\"ive generative data augmentation and boost the baselines. Experiments on six datasets showed that MGR is effective particularly when datasets are smaller and stably outperforms baselines.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="AI4GCC-Team-Below-Sea-Level-Critiques-and-Improvements"><a href="#AI4GCC-Team-Below-Sea-Level-Critiques-and-Improvements" class="headerlink" title="AI4GCC - Team: Below Sea Level: Critiques and Improvements"></a>AI4GCC - Team: Below Sea Level: Critiques and Improvements</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13894">http://arxiv.org/abs/2307.13894</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bram Renting, Phillip Wozny, Robert Loftin, Claudia Wieners, Erman Acar</li>
<li>for: 评估气候变化对经济的影响</li>
<li>methods: 使用 интегра assessment 模型(IAM) RICE-N 进行评估</li>
<li>results: 提出了改进 rice-N 模型的建议，包括使用关税收入和奖励过production，并批判IAMs 中偏正的损害函数和不切实际的抑制成本函数。<details>
<summary>Abstract</summary>
We present a critical analysis of the simulation framework RICE-N, an integrated assessment model (IAM) for evaluating the impacts of climate change on the economy. We identify key issues with RICE-N, including action masking and irrelevant actions, and suggest improvements such as utilizing tariff revenue and penalizing overproduction. We also critically engage with features of IAMs in general, namely overly optimistic damage functions and unrealistic abatement cost functions. Our findings contribute to the ongoing efforts to further develop the RICE-N framework in an effort to improve the simulation, making it more useful as an inspiration for policymakers.
</details>
<details>
<summary>摘要</summary>
我们提出了关于模拟框架RICE-N的批判分析，这是一种气候变化影响经济的集成评估模型（IAM）。我们发现了RICE-N中的关键问题，包括行动遮盖和无关行动，并建议使用关税收入和强制产量罚款来改进。我们还与IAM中的一些特征进行批判，包括过估损害函数和不实际的降低成本函数。我们的发现可以帮助进一步发展RICE-N框架，使其更有用作政策制定者的参考。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Grouping-for-Climate-Change-Negotiation-Facilitating-Cooperation-and-Balancing-Interests-through-Effective-Strategies"><a href="#Dynamic-Grouping-for-Climate-Change-Negotiation-Facilitating-Cooperation-and-Balancing-Interests-through-Effective-Strategies" class="headerlink" title="Dynamic Grouping for Climate Change Negotiation: Facilitating Cooperation and Balancing Interests through Effective Strategies"></a>Dynamic Grouping for Climate Change Negotiation: Facilitating Cooperation and Balancing Interests through Effective Strategies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13893">http://arxiv.org/abs/2307.13893</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Qin, Duo Zhang, Yuren Pang</li>
<li>for: 这篇论文旨在提出一种基于现实世界商业和政治谈判协议的气候变化缓解动态分组模型，以促进不同参与者之间的有效合作，实现全球气候变化目标。</li>
<li>methods: 该模型包括三个阶段：分组和更新、内部谈判和间部谈判。它利用分组方法和更新策略解决多地区气候谈判中的复杂性和不均衡。</li>
<li>results: 通过在RICE-N框架中应用谈判模型，表明了国际合作气候变化缓解的可能性。<details>
<summary>Abstract</summary>
In this paper, we propose a dynamic grouping negotiation model for climate mitigation based on real-world business and political negotiation protocols. Within the AI4GCC competition framework, we develop a three-stage process: group formation and updates, intra-group negotiation, and inter-group negotiation. Our model promotes efficient and effective cooperation between various stakeholders to achieve global climate change objectives. By implementing a group-forming method and group updating strategy, we address the complexities and imbalances in multi-region climate negotiations. Intra-group negotiations ensure that all members contribute to mitigation efforts, while inter-group negotiations use the proposal-evaluation framework to set mitigation and savings rates. We demonstrate our negotiation model within the RICE-N framework, illustrating a promising approach for facilitating international cooperation on climate change mitigation.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种动态分组谈判模型，用于气候 Mitigation 的实际商业和政治谈判协议。在 AI4GCC 竞赛框架下，我们开发了三个阶段过程：分组形成和更新、内部谈判和间部谈判。我们的模型推动了不同参与者之间的有效和有效的合作，以实现全球气候变化目标。通过实施分组形成方法和分组更新策略，我们解决了多地区气候谈判中的复杂性和不平衡。内部谈判确保所有成员做出了减少措施的贡献，而间部谈判使用提案评估框架来设置减少和节约率。我们在 RICE-N 框架中示出了我们的谈判模型，预示了对国际气候变化减少努力的有效方法。
</details></li>
</ul>
<hr>
<h2 id="AI4GCC-Team-–-Below-Sea-Level-Score-and-Real-World-Relevance"><a href="#AI4GCC-Team-–-Below-Sea-Level-Score-and-Real-World-Relevance" class="headerlink" title="AI4GCC-Team – Below Sea Level: Score and Real World Relevance"></a>AI4GCC-Team – Below Sea Level: Score and Real World Relevance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13892">http://arxiv.org/abs/2307.13892</a></li>
<li>repo_url: None</li>
<li>paper_authors: Phillip Wozny, Bram Renting, Robert Loftin, Claudia Wieners, Erman Acar</li>
<li>for: The paper is written to address the challenges of carbon leakage in the context of the RICE-N climate-economic simulation, with the goal of achieving a comparable temperature rise to RCP 3.4&#x2F;4.5 and SSP 2.</li>
<li>methods: The paper proposes a negotiation protocol inspired by the Carbon Border Adjustment Mechanism (CBAM) and Climate Clubs (CC), and demonstrates the effectiveness of this approach through simulations.</li>
<li>results: The paper’s proposed protocol results in a temperature rise comparable to RCP 3.4&#x2F;4.5 and SSP 2, and provides an analysis of its World Trade Organization compliance, administrative and political feasibility, and ethical concerns. However, the paper also acknowledges the risk of hurting the least developing countries and suggests specific corrective measures to avoid exacerbating existing inequalities.In Simplified Chinese text, the three key points would be:</li>
<li>for: 该文章是为了解决RICE-N气候经济模拟中的碳泄漏问题，目的是实现RCP 3.4&#x2F;4.5和SSP 2的温室气体升高。</li>
<li>methods: 文章提出了一种启发自碳泄漏机制和气候俱乐部的谈判协议，并通过模拟证明其效果。</li>
<li>results: 文章的提出的协议实现了RCP 3.4&#x2F;4.5和SSP 2的温室气体升高，并进行了世界贸易组织合法性、行政和政治可行性以及伦理问题的分析。但文章也承认可能对最弱国家造成影响，并建议特定的修正措施来避免加剧现有不平等。<details>
<summary>Abstract</summary>
As our submission for track three of the AI for Global Climate Cooperation (AI4GCC) competition, we propose a negotiation protocol for use in the RICE-N climate-economic simulation. Our proposal seeks to address the challenges of carbon leakage through methods inspired by the Carbon Border Adjustment Mechanism (CBAM) and Climate Clubs (CC). We demonstrate the effectiveness of our approach by comparing simulated outcomes to representative concentration pathways (RCP) and shared socioeconomic pathways (SSP). Our protocol results in a temperature rise comparable to RCP 3.4/4.5 and SSP 2. Furthermore, we provide an analysis of our protocol's World Trade Organization compliance, administrative and political feasibility, and ethical concerns. We recognize that our proposal risks hurting the least developing countries, and we suggest specific corrective measures to avoid exacerbating existing inequalities, such as technology sharing and wealth redistribution. Future research should improve the RICE-N tariff mechanism and implement actions allowing for the aforementioned corrective measures.
</details>
<details>
<summary>摘要</summary>
为AIfor Global Climate Cooperation（AI4GCC）比赛的第三轨道提交，我们提议一种谈判协议，用于在RICE-N气候经济模拟中 address carbon leakage 问题。我们的提议启发自Carbon Border Adjustment Mechanism（CBAM）和Climate Clubs（CC）的方法。我们通过对比 simulate 结果和代表气候道具（RCP）和共产经济道具（SSP）来证明我们的方法的有效性。我们的协议会导致温度升高相当于RCP 3.4/4.5和SSP 2。此外，我们还提供了对我们协议的世界贸易组织合法性、行政和政治可行性以及道德问题的分析。我们认为我们的建议可能会对最少发展国家产生负面影响，我们建议特定的修正措施，以避免增加现有的不平等，如技术分享和财富重新分配。未来的研究应该完善RICE-N关税机制，并实施相应的行动，以实现上述修正措施。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Grouping-for-Climate-Change-Negotiation-Facilitating-Cooperation-and-Balancing-Interests-through-Effective-Strategies-1"><a href="#Dynamic-Grouping-for-Climate-Change-Negotiation-Facilitating-Cooperation-and-Balancing-Interests-through-Effective-Strategies-1" class="headerlink" title="Dynamic Grouping for Climate Change Negotiation: Facilitating Cooperation and Balancing Interests through Effective Strategies"></a>Dynamic Grouping for Climate Change Negotiation: Facilitating Cooperation and Balancing Interests through Effective Strategies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13886">http://arxiv.org/abs/2307.13886</a></li>
<li>repo_url: None</li>
<li>paper_authors: Duo Zhang, Yuren Pang, Yu Qin</li>
<li>for: This paper aims to improve the accuracy and effectiveness of climate change negotiation models by addressing limitations in the current framework.</li>
<li>methods: The paper explores five critical aspects of geographical impacts and refines the utility and rewards framework to better account for heterogeneity and historical&#x2F;cultural factors.</li>
<li>results: By addressing these limitations, the paper hopes to enhance the accuracy and effectiveness of climate change negotiation models, enabling policymakers and stakeholders to devise targeted and appropriate strategies to tackle climate change at both regional and global levels.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文目的是改进当前气候变化谈判模型的准确性和效果，消除当前框架中的限制。</li>
<li>methods: 论文探讨了五个关键地区的影响，并对奖励和折损函数进行了修改，以更好地考虑地域差异和历史文化因素。</li>
<li>results: 通过修改限制，论文希望提高气候变化谈判模型的准确性和效果，帮助政策制定者和各方决策者制定适当的地域和全球级气候变化策略。<details>
<summary>Abstract</summary>
The current framework for climate change negotiation models presents several limitations that warrant further research and development. In this track, we discuss mainly two key areas for improvement, focusing on the geographical impacts and utility framework. In the aspects of geographical impacts, We explore five critical aspects: (1) the shift from local to global impact, (2) variability in climate change effects across regions, (3) heterogeneity in geographical location and political structures, and (4) collaborations between adjacent nations, (5) the importance of including historical and cultural factors influencing climate negotiations. Furthermore, we emphasize the need to refine the utility and rewards framework to reduce the homogeneity and the level of overestimating the climate mitigation by integrating the positive effects of saving rates into the reward function and heterogeneity among all regions. By addressing these limitations, we hope to enhance the accuracy and effectiveness of climate change negotiation models, enabling policymakers and stakeholders to devise targeted and appropriate strategies to tackle climate change at both regional and global levels.
</details>
<details>
<summary>摘要</summary>
当前气候变化谈判模型存在多个限制，需要进一步的研究和发展。在这一轨道上，我们主要讨论两个关键领域的改进，即地域影响和用途框架。在地域影响方面，我们探讨五个关键方面：（1）从本地到全球影响的转变，（2）气候变化影响不同地区的变化性，（3）地理位置和政治结构之间的多样性，（4）邻国合作，（5）包括历史和文化因素 influencing气候谈判。此外，我们强调要更新用途和奖励框架，以减少同化和气候遏制的误差，并将保存率integrated到奖励函数中，以增强气候谈判模型的准确性和效果。通过解决这些限制，我们希望能够提高气候变化谈判模型的准确性和效果，帮助政策制定者和各方利益者制定适应的气候变化策略，并在全球和地域水平上应对气候变化。
</details></li>
</ul>
<hr>
<h2 id="WebArena-A-Realistic-Web-Environment-for-Building-Autonomous-Agents"><a href="#WebArena-A-Realistic-Web-Environment-for-Building-Autonomous-Agents" class="headerlink" title="WebArena: A Realistic Web Environment for Building Autonomous Agents"></a>WebArena: A Realistic Web Environment for Building Autonomous Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13854">http://arxiv.org/abs/2307.13854</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/web-arena-x/webarena">https://github.com/web-arena-x/webarena</a></li>
<li>paper_authors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig</li>
<li>for: 本研究旨在开发一个真实和可重现的自动化代理环境，以便用于日常任务管理。</li>
<li>methods: 本研究使用了现代自然语言处理技术，包括理解和行动之前的推理，以及网页上进行任务完成。</li>
<li>results: 研究发现，解决复杂任务是具有挑战性，并且现今的语言模型仍未能完全成功地完成这些实际生活中的任务。<details>
<summary>Abstract</summary>
With generative AI advances, the exciting potential for autonomous agents to manage daily tasks via natural language commands has emerged. However, cur rent agents are primarily created and tested in simplified synthetic environments, substantially limiting real-world scenario representation. In this paper, we build an environment for agent command and control that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on websites, and we create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and are designed to emulate tasks that humans routinely perform on the internet. We design and implement several autonomous agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 10.59%. These results highlight the need for further development of robust agents, that current state-of-the-art LMs are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress. Our code, data, environment reproduction resources, and video demonstrations are publicly available at https://webarena.dev/.
</details>
<details>
<summary>摘要</summary>
“受到生成AI的进步启发，现在可以使用自然语言指令来让自动代理人执行日常任务。然而，目前的代理人主要在简单的合成环境中被设计和测试，这限制了实际世界情况的表现。在这篇论文中，我们建立了一个高度现实和可重现的环境，用于代理人的指令和控制。我们特别关注代理人在网站上进行任务的情况，并创建了四种常见的领域中的完整网站：电子商务、社交讨论区、协同软件开发和内容管理。我们的环境包括工具（如地图）和外部知识库（如用户手册），以促进人类化的任务解决。基于我们的环境，我们发布了一组对任务完成的评估标准。我们的任务集包括多元、长期和人类在网络上常进行的任务。我们设计和实现了一些自动代理人，应用latest技术，如理解才行。我们的最佳GPT-4基于代理人仅在终端任务成功率为10.59%。这些结果显示解决复杂任务是具有挑战性，目前的state-of-the-art LMs在这些实际任务中表现未能完美，WebArena可以用来衡量这种进步。我们的代码、数据、环境重现资源和视频示例都公开available at <https://webarena.dev/>。”
</details></li>
</ul>
<hr>
<h2 id="MAEA-Multimodal-Attribution-for-Embodied-AI"><a href="#MAEA-Multimodal-Attribution-for-Embodied-AI" class="headerlink" title="MAEA: Multimodal Attribution for Embodied AI"></a>MAEA: Multimodal Attribution for Embodied AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13850">http://arxiv.org/abs/2307.13850</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vidhi Jain, Jayant Sravan Tamarapalli, Sahiti Yerramilli, Yonatan Bisk</li>
<li>for: 这篇论文是关于Multimodal Perception for Embodied AI的研究，旨在解决多modal输入可能包含高度相互补充的信息问题。</li>
<li>methods: 论文使用了Attribution分析来理解不同策略在ALFRED数据集上的全球趋势，并 investigate模型和数据集偏见。</li>
<li>results: 论文提出了MAEA框架，可以计算任意分Diffable策略的全球Attribution，并通过Attribution分析下降级语言和视觉Attribution。<details>
<summary>Abstract</summary>
Understanding multimodal perception for embodied AI is an open question because such inputs may contain highly complementary as well as redundant information for the task. A relevant direction for multimodal policies is understanding the global trends of each modality at the fusion layer. To this end, we disentangle the attributions for visual, language, and previous action inputs across different policies trained on the ALFRED dataset. Attribution analysis can be utilized to rank and group the failure scenarios, investigate modeling and dataset biases, and critically analyze multimodal EAI policies for robustness and user trust before deployment. We present MAEA, a framework to compute global attributions per modality of any differentiable policy. In addition, we show how attributions enable lower-level behavior analysis in EAI policies for language and visual attributions.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)理解多模态识别对嵌入式AI是一个开放的问题，因为这些输入可能包含高度相互补充的信息。一个有用的方向是理解每个模态在拟合层的全球趋势。为此，我们分离不同策略在ALFRED dataset上训练的视觉、语言和前一个动作输入的归因分析。归因分析可以用来排序和分组失败场景，探索模型和数据集偏见，并且在部署之前对多模态EAI策略进行critical分析。我们提出了MAEA框架，用于计算任何可微分策略的全球归因。此外，我们还示出了归因如何帮助分析EAI策略的低级行为。
</details></li>
</ul>
<hr>
<h2 id="Scaling-Integer-Arithmetic-in-Probabilistic-Programs"><a href="#Scaling-Integer-Arithmetic-in-Probabilistic-Programs" class="headerlink" title="Scaling Integer Arithmetic in Probabilistic Programs"></a>Scaling Integer Arithmetic in Probabilistic Programs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13837">http://arxiv.org/abs/2307.13837</a></li>
<li>repo_url: None</li>
<li>paper_authors: William X. Cao, Poorva Garg, Ryan Tjoa, Steven Holtzen, Todd Millstein, Guy Van den Broeck</li>
<li>for: 这篇论文是关于probabilistic programming languages (PPLs)中的分布问题的研究。</li>
<li>methods: 这篇论文使用了一种名为“binary encoding strategy”的方法，这种方法利用了整数运算中的逻辑结构来实现精确的 probabilistic inference。</li>
<li>results: 该研究表明，使用这种binary encoding strategy可以在高维复杂的整数分布中实现精确的 probabilistic inference，并且可以扩展到更大的整数分布。<details>
<summary>Abstract</summary>
Distributions on integers are ubiquitous in probabilistic modeling but remain challenging for many of today's probabilistic programming languages (PPLs). The core challenge comes from discrete structure: many of today's PPL inference strategies rely on enumeration, sampling, or differentiation in order to scale, which fail for high-dimensional complex discrete distributions involving integers. Our insight is that there is structure in arithmetic that these approaches are not using. We present a binary encoding strategy for discrete distributions that exploits the rich logical structure of integer operations like summation and comparison. We leverage this structured encoding with knowledge compilation to perform exact probabilistic inference, and show that this approach scales to much larger integer distributions with arithmetic.
</details>
<details>
<summary>摘要</summary>
随机分布在整数上是现代随机模型中非常普遍的，但它们对许多现代随机编程语言（PPL）来说仍然是挑战。核心问题在于整数的离散结构：许多今天的PPL推理策略都是基于枚举、采样或导数来扩展，这些方法在高维复杂的整数分布中失效。我们的创新是利用整数的数学结构，这些方法没有使用。我们提出了一种二进制编码策略，利用整数操作的逻辑结构来捕捉整数分布的结构。我们利用这种结构化编码，与知识编译来实现精确的随机推理，并示出这种方法可以扩展到更大的整数分布。
</details></li>
</ul>
<hr>
<h2 id="Offline-Reinforcement-Learning-with-On-Policy-Q-Function-Regularization"><a href="#Offline-Reinforcement-Learning-with-On-Policy-Q-Function-Regularization" class="headerlink" title="Offline Reinforcement Learning with On-Policy Q-Function Regularization"></a>Offline Reinforcement Learning with On-Policy Q-Function Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13824">http://arxiv.org/abs/2307.13824</a></li>
<li>repo_url: None</li>
<li>paper_authors: Laixi Shi, Robert Dadashi, Yuejie Chi, Pablo Samuel Castro, Matthieu Geist</li>
<li>for: 本研究旨在解决离线强化学习（RL）中的推理扩展错误问题，通过对政策进行正则化，以避免由历史数据集和期望政策之间的分布转换引起的扩展错误。</li>
<li>methods: 本研究提议使用Q函数正则化，通过对Q函数进行估计，以优化政策。两种基于Q函数正则化的算法被提出，并在D4RL标准套件中进行了实验。</li>
<li>results: 实验结果表明，使用Q函数正则化可以减轻推理扩展错误，并在D4RL标准套件中展现出强大的表现。<details>
<summary>Abstract</summary>
The core challenge of offline reinforcement learning (RL) is dealing with the (potentially catastrophic) extrapolation error induced by the distribution shift between the history dataset and the desired policy. A large portion of prior work tackles this challenge by implicitly/explicitly regularizing the learning policy towards the behavior policy, which is hard to estimate reliably in practice. In this work, we propose to regularize towards the Q-function of the behavior policy instead of the behavior policy itself, under the premise that the Q-function can be estimated more reliably and easily by a SARSA-style estimate and handles the extrapolation error more straightforwardly. We propose two algorithms taking advantage of the estimated Q-function through regularizations, and demonstrate they exhibit strong performance on the D4RL benchmarks.
</details>
<details>
<summary>摘要</summary>
核心挑战是线上强化学习（RL）是处理 History 集和期望策略之间分布变化导致的（可能 catastrophic）推理错误。大量先前工作是通过显式/隐式正则化学习策略向行为策略的方向进行正则化，这在实践中很难估量。在这个工作中，我们提议将正则化向行为策略的 Q-函数而不是行为策略本身，因为 Q-函数可以更容易地和更可靠地通过 SARSA 样式的估计。我们提出了两种利用估计 Q-函数的正则化算法，并在 D4RL 标准启动中展示它们的强大表现。
</details></li>
</ul>
<hr>
<h2 id="Fitting-Auditory-Filterbanks-with-Multiresolution-Neural-Networks"><a href="#Fitting-Auditory-Filterbanks-with-Multiresolution-Neural-Networks" class="headerlink" title="Fitting Auditory Filterbanks with Multiresolution Neural Networks"></a>Fitting Auditory Filterbanks with Multiresolution Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13821">http://arxiv.org/abs/2307.13821</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lostanlen/lostanlen2023waspaa">https://github.com/lostanlen/lostanlen2023waspaa</a></li>
<li>paper_authors: Vincent Lostanlen, Daniel Haider, Han Han, Mathieu Lagrange, Peter Balazs, Martin Ehler</li>
<li>for: 这 paper 是为了解决深度学习音频模型中的非parametric vs. parametric问题。</li>
<li>methods: 这 paper 使用了多resolution neural network (MuReNN)，其中包括分割 discrete wavelet transform (DWT) 的 octave subbands，并在每个 octave 中训练独立的 convolutional 操作。</li>
<li>results:  compared to convnets 和 Gabor convolutions, MuReNN 在 three optimization problems 中达到了 state-of-the-art 性能。<details>
<summary>Abstract</summary>
Waveform-based deep learning faces a dilemma between nonparametric and parametric approaches. On one hand, convolutional neural networks (convnets) may approximate any linear time-invariant system; yet, in practice, their frequency responses become more irregular as their receptive fields grow. On the other hand, a parametric model such as LEAF is guaranteed to yield Gabor filters, hence an optimal time-frequency localization; yet, this strong inductive bias comes at the detriment of representational capacity. In this paper, we aim to overcome this dilemma by introducing a neural audio model, named multiresolution neural network (MuReNN). The key idea behind MuReNN is to train separate convolutional operators over the octave subbands of a discrete wavelet transform (DWT). Since the scale of DWT atoms grows exponentially between octaves, the receptive fields of the subsequent learnable convolutions in MuReNN are dilated accordingly. For a given real-world dataset, we fit the magnitude response of MuReNN to that of a well-established auditory filterbank: Gammatone for speech, CQT for music, and third-octave for urban sounds, respectively. This is a form of knowledge distillation (KD), in which the filterbank ''teacher'' is engineered by domain knowledge while the neural network ''student'' is optimized from data. We compare MuReNN to the state of the art in terms of goodness of fit after KD on a hold-out set and in terms of Heisenberg time-frequency localization. Compared to convnets and Gabor convolutions, we find that MuReNN reaches state-of-the-art performance on all three optimization problems.
</details>
<details>
<summary>摘要</summary>
waveform-based深度学习面临一个选择between非 Parametric和 Parametricapproaches。一个方面，卷积神经网络(convnets)可以近似任何线性时变系统;然而，在实践中，它们的频谱响应变得更加异常的随着它们的感知场的增大。另一方面，一个参数化模型如LEAF可以确保生成Gabor滤波器，因此获得最佳时间频域定位;然而，这种强大的推导牵扯来了表达能力的代价。在这篇论文中，我们希望超越这个困境，通过引入多尺度神经网络(MuReNN)来实现。MuReNN的关键思想是在分割 octave 子域中训练分离的卷积操作。由于 DWT  atoms 的规模在 octave 中 exponential 增长，MuReNN 中的后续可学习卷积的感知场随着 octave 的增大而增大。对于一个实际数据集，我们将 MuReNN 的幅响应与一个已知的听力滤波器链：Gammatone for speech, CQT for music, and third-octave for urban sounds, respectively。这是一种知识储存（KD），在哪里听力滤波器''教师''是通过领域知识工程而设计的，而神经网络''学生''是通过数据优化的。我们将 MuReNN 与现状的最佳性进行比较，包括在 KD 后的好处评价和 Heisenberg 时间频域本地化。与 convnets 和 Gabor 卷积相比，我们发现 MuReNN 在三个优化问题中达到了状态机器人的表现。
</details></li>
</ul>
<hr>
<h2 id="ForestMonkey-Toolkit-for-Reasoning-with-AI-based-Defect-Detection-and-Classification-Models"><a href="#ForestMonkey-Toolkit-for-Reasoning-with-AI-based-Defect-Detection-and-Classification-Models" class="headerlink" title="ForestMonkey: Toolkit for Reasoning with AI-based Defect Detection and Classification Models"></a>ForestMonkey: Toolkit for Reasoning with AI-based Defect Detection and Classification Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13815">http://arxiv.org/abs/2307.13815</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiajun Zhang, Georgina Cosma, Sarah Bugby, Jason Watkins</li>
<li>for: 本文提出了一个名为“Forest Monkey”（FM）的工具集，用于解释任何基于人工智能的缺陷检测和分类模型的预测结果，并提供了一些可读的图表和文本来描述这些结果。</li>
<li>methods: 本文使用了一些方法，包括从预测结果提取特征，将图像转换为缺陷特征，以及使用决策树基本的人工智能推理器。</li>
<li>results: 本文透过对四个不同的数据集和四个不同的模型进行时间性能评估，以评估FM工具集的效果。此外，文章还提供了一个教学 tutorials，以帮助用户在使用FM工具集进行解释任务。<details>
<summary>Abstract</summary>
Artificial intelligence (AI) reasoning and explainable AI (XAI) tasks have gained popularity recently, enabling users to explain the predictions or decision processes of AI models. This paper introduces Forest Monkey (FM), a toolkit designed to reason the outputs of any AI-based defect detection and/or classification model with data explainability. Implemented as a Python package, FM takes input in the form of dataset folder paths (including original images, ground truth labels, and predicted labels) and provides a set of charts and a text file to illustrate the reasoning results and suggest possible improvements. The FM toolkit consists of processes such as feature extraction from predictions to reasoning targets, feature extraction from images to defect characteristics, and a decision tree-based AI-Reasoner. Additionally, this paper investigates the time performance of the FM toolkit when applied to four AI models with different datasets. Lastly, a tutorial is provided to guide users in performing reasoning tasks using the FM toolkit.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）逻辑和可解释AI（XAI）任务在最近几年内受欢迎，使用户可以解释AI模型的预测或决策过程。这篇论文介绍了森林猴（FM）工具集，用于对任何基于AI的检测和分类模型的输出进行逻辑推理。实现为Python包，FM接受输入为数据集文件夹路径（包括原始图像、真实标签和预测标签），并提供一组图表和文本文件来说明逻辑结果以及可能的改进建议。FM工具集包括从预测中提取特征到逻辑目标的特征提取、从图像中提取到缺陷特征的特征提取，以及基于决策树的AI-Reasoner。此外，本篇论文还 investigate FM工具集在不同数据集上四个AI模型的时间性能。最后，本文提供了用户执行逻辑任务的教程。
</details></li>
</ul>
<hr>
<h2 id="Speech-representation-learning-Learning-bidirectional-encoders-with-single-view-multi-view-and-multi-task-methods"><a href="#Speech-representation-learning-Learning-bidirectional-encoders-with-single-view-multi-view-and-multi-task-methods" class="headerlink" title="Speech representation learning: Learning bidirectional encoders with single-view, multi-view, and multi-task methods"></a>Speech representation learning: Learning bidirectional encoders with single-view, multi-view, and multi-task methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00129">http://arxiv.org/abs/2308.00129</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingming Tang</li>
<li>for: 本论文旨在提高时间或空间序列数据上的预测任务，通过使用学习的表示。</li>
<li>methods: 本论文使用超级vised学习来训练深度神经网络，以学习好的序列表示。</li>
<li>results: 本论文在多种学习Setting中进行了广泛的研究，包括有监督学习、无监督学习、半监督学习以及多视图学习。<details>
<summary>Abstract</summary>
This thesis focuses on representation learning for sequence data over time or space, aiming to improve downstream sequence prediction tasks by using the learned representations. Supervised learning has been the most dominant approach for training deep neural networks for learning good sequential representations. However, one limiting factor to scale supervised learning is the lack of enough annotated data. Motivated by this challenge, it is natural to explore representation learning methods that can utilize large amounts of unlabeled and weakly labeled data, as well as an additional data modality. I describe my broad study of representation learning for speech data. Unlike most other works that focus on a single learning setting, this thesis studies multiple settings: supervised learning with auxiliary losses, unsupervised learning, semi-supervised learning, and multi-view learning. Besides different learning problems, I also explore multiple approaches for representation learning. Though I focus on speech data, the methods described in this thesis can also be applied to other domains. Overall, the field of representation learning is developing rapidly. State-of-the-art results on speech related tasks are typically based on Transformers pre-trained with large-scale self-supervised learning, which aims to learn generic representations that can benefit multiple downstream tasks. Since 2020, large-scale pre-training has been the de facto choice to achieve good performance. This delayed thesis does not attempt to summarize and compare with the latest results on speech representation learning; instead, it presents a unique study on speech representation learning before the Transformer era, that covers multiple learning settings. Some of the findings in this thesis can still be useful today.
</details>
<details>
<summary>摘要</summary>
这个论文关注在时间或空间序列数据上进行表示学习，以提高 subsequenct 预测任务中的表示质量。supervised learning 是深度神经网络训练深入表示的最主要方法。然而，缺乏足够的标注数据是规模化 supervised learning 的限制因素。为了解决这个挑战，我们可以 explore representation learning 方法，可以利用大量未标注和弱标注数据，以及额外的数据模式。我描述了我对 speech 数据的广泛研究。与大多数其他作品一样，这个论文不仅关注单一的学习设定，而是研究多种设定：supervised learning with auxiliary losses，unsupervised learning，semi-supervised learning，和多视图学习。此外，我们还探索了多种表示学习方法。虽然我们关注 speech 数据，但这些方法可以应用到其他领域。总的来说，表示学习领域在发展 rapidly。现代 speech 相关任务的 state-of-the-art 结果通常基于 Transformers 预训练大规模自我学习，该目的是学习通用的表示，可以促进多个下游任务。自 2020 年以来，大规模预训练成为了downstream任务的标准选择，以实现好的性能。这个论文不尝试综述和与最新 results on speech representation learning 进行比较，而是提供了在 Transformer 时代之前的唯一研究，涵盖多种学习设定。一些这个论文中的发现仍然可以在今天上有用。
</details></li>
</ul>
<hr>
<h2 id="How-to-Scale-Your-EMA"><a href="#How-to-Scale-Your-EMA" class="headerlink" title="How to Scale Your EMA"></a>How to Scale Your EMA</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13813">http://arxiv.org/abs/2307.13813</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ZulqarnainZilli/-9-Email-Marketing-Tips-For-Content-Marketers">https://github.com/ZulqarnainZilli/-9-Email-Marketing-Tips-For-Content-Marketers</a></li>
<li>paper_authors: Dan Busbridge, Jason Ramapuram, Pierre Ablin, Tatiana Likhomanenko, Eeshan Gunesh Dhekane, Xavier Suau, Russ Webb</li>
<li>for: 这 paper 的目的是解决实际机器学习中保持批处理大小的训练动态性的问题，以便实现批处理大小和墙 clock 时间的负荷。</li>
<li>methods: 这 paper 使用了一种 scaling rule，即在批处理大小变化时，对学习率进行线性Scaling，以实现批处理大小和墙 clock 时间的负荷。此外，paper 还使用了模型Exponential Moving Average (EMA)，以提高超vised learning 的稳定性和通用性。</li>
<li>results: 这 paper 的结果表明，通过使用 scaling rule 和模型 EMA，可以在不同的架构、优化器和数据模式下实现训练动态性，并且可以在小批处理大小和大批处理大小下训练 BYOL 方法，从而实现 wall-clock 时间的6倍减少。<details>
<summary>Abstract</summary>
Preserving training dynamics across batch sizes is an important tool for practical machine learning as it enables the trade-off between batch size and wall-clock time. This trade-off is typically enabled by a scaling rule, for example, in stochastic gradient descent, one should scale the learning rate linearly with the batch size. Another important tool for practical machine learning is the model Exponential Moving Average (EMA), which is a model copy that does not receive gradient information, but instead follows its target model with some momentum. This model EMA can improve the robustness and generalization properties of supervised learning, stabilize pseudo-labeling, and provide a learning signal for Self-Supervised Learning (SSL). Prior works have treated the model EMA separately from optimization, leading to different training dynamics across batch sizes and lower model performance. In this work, we provide a scaling rule for optimization in the presence of model EMAs and demonstrate its validity across a range of architectures, optimizers, and data modalities. We also show the rule's validity where the model EMA contributes to the optimization of the target model, enabling us to train EMA-based pseudo-labeling and SSL methods at small and large batch sizes. For SSL, we enable training of BYOL up to batch size 24,576 without sacrificing performance, optimally a 6$\times$ wall-clock time reduction.
</details>
<details>
<summary>摘要</summary>
保持批处理大小下的训练动态是实用机器学习中重要的工具，它允许批处理大小和墙 clock 时间之间的变数协调。这种协调通常通过一个扩大规则实现，例如在杂散梯度下降中，需要将学习率线性地与批处理大小相乘。另外，模型 exponentially moving average（EMA）也是一种重要的实用机器学习工具，它可以提高supervised learning的稳定性和泛化性，并为自动标注和自主学习提供学习信号。先前的工作通常将模型 EMA 与优化分开处理，导致不同的批处理大小下的训练动态，从而降低模型性能。在这项工作中，我们提供了在模型 EMA 存在下的优化 scaling rule，并证明其在不同的架构、优化器和数据模式下的有效性。我们还显示了这种规则在模型 EMA 对目标模型优化的情况下的有效性，允许我们在小批处理大小和大批处理大小下进行 Pseudo-labeling 和 SSL 训练。对 SSL，我们可以在批处理大小为 24,576 的情况下训练 BYOL，无需牺牲性能，实现了墙 clock 时间的6倍减少。
</details></li>
</ul>
<hr>
<h2 id="When-Multi-Task-Learning-Meets-Partial-Supervision-A-Computer-Vision-Review"><a href="#When-Multi-Task-Learning-Meets-Partial-Supervision-A-Computer-Vision-Review" class="headerlink" title="When Multi-Task Learning Meets Partial Supervision: A Computer Vision Review"></a>When Multi-Task Learning Meets Partial Supervision: A Computer Vision Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14382">http://arxiv.org/abs/2307.14382</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maxime Fontana, Michael Spratling, Miaojing Shi</li>
<li>for: 这篇论文主要研究的是多任务学习（MTL），即同时学习多个任务，并利用这些任务之间的关系来减少内存需求和计算时间。</li>
<li>methods: 该论文主要介绍了传统的MTL方法，包括不同的参数共享技术来传递知识 между任务。同时，它还讨论了由多个目标函数组成的多目标优化问题，以及这种多目标优化问题所带来的挑战。</li>
<li>results: 该论文提出了一些基于partial supervision的MTL方法，以解决多目标优化问题中的挑战。它还介绍了一些可用的数据集、工具和benchmarking结果，以评估这些方法的性能。<details>
<summary>Abstract</summary>
Multi-Task Learning (MTL) aims to learn multiple tasks simultaneously while exploiting their mutual relationships. By using shared resources to simultaneously calculate multiple outputs, this learning paradigm has the potential to have lower memory requirements and inference times compared to the traditional approach of using separate methods for each task. Previous work in MTL has mainly focused on fully-supervised methods, as task relationships can not only be leveraged to lower the level of data-dependency of those methods but they can also improve performance. However, MTL introduces a set of challenges due to a complex optimisation scheme and a higher labeling requirement. This review focuses on how MTL could be utilised under different partial supervision settings to address these challenges. First, this review analyses how MTL traditionally uses different parameter sharing techniques to transfer knowledge in between tasks. Second, it presents the different challenges arising from such a multi-objective optimisation scheme. Third, it introduces how task groupings can be achieved by analysing task relationships. Fourth, it focuses on how partially supervised methods applied to MTL can tackle the aforementioned challenges. Lastly, this review presents the available datasets, tools and benchmarking results of such methods.
</details>
<details>
<summary>摘要</summary>
First, the review examines how MTL traditionally uses parameter sharing techniques to transfer knowledge between tasks. Second, it discusses the challenges that arise from the multi-objective optimization scheme. Third, it introduces task groupings based on task relationships. Fourth, it focuses on how partially supervised methods can be applied to MTL to tackle these challenges. Finally, the review presents available datasets, tools, and benchmarking results for such methods.
</details></li>
</ul>
<hr>
<h2 id="EdgeConvEns-Convolutional-Ensemble-Learning-for-Edge-Intelligence"><a href="#EdgeConvEns-Convolutional-Ensemble-Learning-for-Edge-Intelligence" class="headerlink" title="EdgeConvEns: Convolutional Ensemble Learning for Edge Intelligence"></a>EdgeConvEns: Convolutional Ensemble Learning for Edge Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14381">http://arxiv.org/abs/2307.14381</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ilkay Sikdokur, İnci M. Baytaş, Arda Yurdakul</li>
<li>for: 本研究旨在实现在边缘网络中部署深度学习模型，以提高边缘设备的学习能力和预测性能。</li>
<li>methods: 本研究提出了一种 convolutional ensemble learning 方法，称为 EdgeConvEns，可以在边缘设备上训练不同计算能力的弱模型，并将这些模型 ensemble 在中央服务器上进行更好的预测性能。</li>
<li>results: 实验结果表明，EdgeConvEns 可以在不同训练场景下超过当前最佳性能，并且需要 fewer 次网络通信和 menos 数据传输。<details>
<summary>Abstract</summary>
Deep edge intelligence aims to deploy deep learning models that demand computationally expensive training in the edge network with limited computational power. Moreover, many deep edge intelligence applications require handling distributed data that cannot be transferred to a central server due to privacy concerns. Decentralized learning methods, such as federated learning, offer solutions where models are learned collectively by exchanging learned weights. However, they often require complex models that edge devices may not handle and multiple rounds of network communication to achieve state-of-the-art performances. This study proposes a convolutional ensemble learning approach, coined EdgeConvEns, that facilitates training heterogeneous weak models on edge and learning to ensemble them where data on edge are heterogeneously distributed. Edge models are implemented and trained independently on Field-Programmable Gate Array (FPGA) devices with various computational capacities. Learned data representations are transferred to a central server where the ensemble model is trained with the learned features received from the edge devices to boost the overall prediction performance. Extensive experiments demonstrate that the EdgeConvEns can outperform the state-of-the-art performance with fewer communications and less data in various training scenarios.
</details>
<details>
<summary>摘要</summary>
深入智能旨在部署需要计算费时训练的深度学习模型在边缘网络中，该网络具有有限的计算能力。此外，许多深入智能应用需要处理分散的数据，这些数据不能被传输到中央服务器 Due to privacy concerns. 联邦学习方法，如联邦学习，可以解决这些问题，但它们经常需要复杂的模型，边缘设备可能无法处理，并且需要多次网络通信以 достиieving state-of-the-art表现。本研究提出了一种 convolutional ensemble learning 方法，称为 EdgeConvEns，它可以在边缘上训练不同计算 capacities的 Edge 模型，并将学习到的数据表示 transferred to a central server，并在该服务器上训练 ensemble 模型，以提高总预测性能。 Edge 模型在 Field-Programmable Gate Array (FPGA) 设备上独立实现和训练，学习到的数据表示在中央服务器上进行 ensemble 训练，以提高预测性能。广泛的实验表明，EdgeConvEns 可以在不同训练场景下超越现有的性能，并且需要 fewer communications 和 less data。
</details></li>
</ul>
<hr>
<h2 id="A-large-language-model-assisted-education-tool-to-provide-feedback-on-open-ended-responses"><a href="#A-large-language-model-assisted-education-tool-to-provide-feedback-on-open-ended-responses" class="headerlink" title="A large language model-assisted education tool to provide feedback on open-ended responses"></a>A large language model-assisted education tool to provide feedback on open-ended responses</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02439">http://arxiv.org/abs/2308.02439</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/KordingLab/llm4teach-freetext-server">https://github.com/KordingLab/llm4teach-freetext-server</a></li>
<li>paper_authors: Jordan K. Matelsky, Felipe Parodi, Tony Liu, Richard D. Lange, Konrad P. Kording</li>
<li>for: 这篇论文是为了提供一种自动回答开结问题的工具，以帮助教师提供快速个性化反馈，从而提高学生的知识水平和教学方法。</li>
<li>methods: 这个工具使用大型自然语言模型（LLMs），由教师定义的标准来指导其回答开结问题。</li>
<li>results: 这个工具可以快速提供个性化反馈，帮助学生快速测试知识和identify改进的领域。<details>
<summary>Abstract</summary>
Open-ended questions are a favored tool among instructors for assessing student understanding and encouraging critical exploration of course material. Providing feedback for such responses is a time-consuming task that can lead to overwhelmed instructors and decreased feedback quality. Many instructors resort to simpler question formats, like multiple-choice questions, which provide immediate feedback but at the expense of personalized and insightful comments. Here, we present a tool that uses large language models (LLMs), guided by instructor-defined criteria, to automate responses to open-ended questions. Our tool delivers rapid personalized feedback, enabling students to quickly test their knowledge and identify areas for improvement. We provide open-source reference implementations both as a web application and as a Jupyter Notebook widget that can be used with instructional coding or math notebooks. With instructor guidance, LLMs hold promise to enhance student learning outcomes and elevate instructional methodologies.
</details>
<details>
<summary>摘要</summary>
открытые вопросы是教师们喜欢使用的工具，用于评估学生理解度和促进课程材料的探究性评估。提供反馈 для这些答案是一项时间消耗大的任务，可能会让教师感受到压力，导致反馈质量下降。许多教师会转而使用更简单的问题格式，如多选题，以获得快速的反馈，但是这将导致个性化的反馈和深入的评估被 sacrificed。在这里，我们介绍了一种工具，使用大型自然语言模型（LLMs），以 instruktor-defined 的标准来自动回答开放式问题。我们的工具可以快速提供个性化反馈，让学生快速测试自己的知识水平，并快速发现需要改进的方面。我们提供了开源的参考实现，一个网应用和一个 Jupyter Notebook  widget，可以与教学编程或数学笔记一起使用。With instructor guidance，LLMs 表示可以提高学生学习成果和提高教学方法。
</details></li>
</ul>
<hr>
<h2 id="Is-GPT-a-Computational-Model-of-Emotion-Detailed-Analysis"><a href="#Is-GPT-a-Computational-Model-of-Emotion-Detailed-Analysis" class="headerlink" title="Is GPT a Computational Model of Emotion? Detailed Analysis"></a>Is GPT a Computational Model of Emotion? Detailed Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13779">http://arxiv.org/abs/2307.13779</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ala N. Tak, Jonathan Gratch</li>
<li>for: 这篇论文探讨 GPT 家族大语言模型的情感理解能力。</li>
<li>methods: 论文首先研究 GPT 如何理解自己的生活记忆，然后通过系统地变化情况来影响情绪强度和应急响应。</li>
<li>results: 研究发现，不使用提问工程ering的情况下，GPT 的预测与人类提供的评估和情感标签高度相符。然而，GPT 在预测情绪强度和应急响应方面存在困难。GPT-4 在初期研究中表现最佳，但在第二次研究中表现不佳，尽管通过小量提问工程ering提供了更好的结果。这些研究表明了如何有效地使用这些模型的优点，以及如何解决它们的弱点，特别是 Response 的变化。<details>
<summary>Abstract</summary>
This paper investigates the emotional reasoning abilities of the GPT family of large language models via a component perspective. The paper first examines how the model reasons about autobiographical memories. Second, it systematically varies aspects of situations to impact emotion intensity and coping tendencies. Even without the use of prompt engineering, it is shown that GPT's predictions align significantly with human-provided appraisals and emotional labels. However, GPT faces difficulties predicting emotion intensity and coping responses. GPT-4 showed the highest performance in the initial study but fell short in the second, despite providing superior results after minor prompt engineering. This assessment brings up questions on how to effectively employ the strong points and address the weak areas of these models, particularly concerning response variability. These studies underscore the merits of evaluating models from a componential perspective.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="An-Empirical-Study-on-Bugs-Inside-PyTorch-A-Replication-Study"><a href="#An-Empirical-Study-on-Bugs-Inside-PyTorch-A-Replication-Study" class="headerlink" title="An Empirical Study on Bugs Inside PyTorch: A Replication Study"></a>An Empirical Study on Bugs Inside PyTorch: A Replication Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13777">http://arxiv.org/abs/2307.13777</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sharon Chee Yin Ho, Vahid Majdinasab, Mohayeminul Islam, Diego Elias Costa, Emad Shihab, Foutse Khomh, Sarah Nadi, Muhammad Raza</li>
<li>for: 本研究旨在探讨PyTorch库中的bug标识和修复过程，以便更好地理解深度学习库中bug的特点和影响。</li>
<li>methods: 本研究采用了对PyTorch库的开发过程中发现的bug进行分析，并对bug的原因和表现特征进行描述，以及分析bug修复的方法。</li>
<li>results: 研究发现，PyTorch库中的bug更像传统软件项目中的bug，而不是深度学习特有的问题。此外，本研究还对TensorFlow库的bug标识和修复过程进行了比较，探讨了两个库之间的相似性和差异。<details>
<summary>Abstract</summary>
Software systems are increasingly relying on deep learning components, due to their remarkable capability of identifying complex data patterns and powering intelligent behaviour. A core enabler of this change in software development is the availability of easy-to-use deep learning libraries. Libraries like PyTorch and TensorFlow empower a large variety of intelligent systems, offering a multitude of algorithms and configuration options, applicable to numerous domains of systems. However, bugs in those popular deep learning libraries also may have dire consequences for the quality of systems they enable; thus, it is important to understand how bugs are identified and fixed in those libraries.   Inspired by a study of Jia et al., which investigates the bug identification and fixing process at TensorFlow, we characterize bugs in the PyTorch library, a very popular deep learning framework. We investigate the causes and symptoms of bugs identified during PyTorch's development, and assess their locality within the project, and extract patterns of bug fixes. Our results highlight that PyTorch bugs are more like traditional software projects bugs, than related to deep learning characteristics. Finally, we also compare our results with the study on TensorFlow, highlighting similarities and differences across the bug identification and fixing process.
</details>
<details>
<summary>摘要</summary>
Inspired by a study on TensorFlow, we investigated the bug identification and fixing process in PyTorch, a very popular deep learning framework. We found that the causes and symptoms of bugs in PyTorch are more like traditional software project bugs, rather than being specific to deep learning. We also extracted patterns of bug fixes and compared our results with the study on TensorFlow, highlighting similarities and differences in the bug identification and fixing process.
</details></li>
</ul>
<hr>
<h2 id="Combating-the-Curse-of-Multilinguality-in-Cross-Lingual-WSD-by-Aligning-Sparse-Contextualized-Word-Representations"><a href="#Combating-the-Curse-of-Multilinguality-in-Cross-Lingual-WSD-by-Aligning-Sparse-Contextualized-Word-Representations" class="headerlink" title="Combating the Curse of Multilinguality in Cross-Lingual WSD by Aligning Sparse Contextualized Word Representations"></a>Combating the Curse of Multilinguality in Cross-Lingual WSD by Aligning Sparse Contextualized Word Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13776">http://arxiv.org/abs/2307.13776</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/begab/sparsity_makes_sense">https://github.com/begab/sparsity_makes_sense</a></li>
<li>paper_authors: Gábor Berend</li>
<li>for: 本研究旨在使用大型预训练的单语言自然语言处理模型进行Zero-shot单词意思分类（WSD），并采用上下文化映射机制。</li>
<li>methods: 本研究使用了词典学习程序来获取笔记缩短的上下文化词表示，并使用大型预训练的单语言自然语言处理模型进行Zero-shot单词意思分类。</li>
<li>results: 实验结果表明，通过上述修改，可以对17种语言进行详细的实验，并获得了62.0到68.5的平均F1分数的显著提升（升幅约6.5）。<details>
<summary>Abstract</summary>
In this paper, we advocate for using large pre-trained monolingual language models in cross lingual zero-shot word sense disambiguation (WSD) coupled with a contextualized mapping mechanism. We also report rigorous experiments that illustrate the effectiveness of employing sparse contextualized word representations obtained via a dictionary learning procedure. Our experimental results demonstrate that the above modifications yield a significant improvement of nearly 6.5 points of increase in the average F-score (from 62.0 to 68.5) over a collection of 17 typologically diverse set of target languages. We release our source code for replicating our experiments at https://github.com/begab/sparsity_makes_sense.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们支持使用大型预训练单语言自然语言模型在跨语言零shot单词含义决定（WSD）中与contextualized mapping机制相结合。我们还对实验结果进行了严格的报告，表明使用稀疏contextualized词表示 obtener得到的改进方法可以带来较大的改进，具体是从62.0提高到68.5的平均F分数，在17种语言集中。我们将代码发布在https://github.com/begab/sparsity_makes_sense上，以便其他人复现我们的实验。
</details></li>
</ul>
<hr>
<h2 id="E-2VPT-An-Effective-and-Efficient-Approach-for-Visual-Prompt-Tuning"><a href="#E-2VPT-An-Effective-and-Efficient-Approach-for-Visual-Prompt-Tuning" class="headerlink" title="E^2VPT: An Effective and Efficient Approach for Visual Prompt Tuning"></a>E^2VPT: An Effective and Efficient Approach for Visual Prompt Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13770">http://arxiv.org/abs/2307.13770</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chenghan111/e2vpt">https://github.com/chenghan111/e2vpt</a></li>
<li>paper_authors: Cheng Han, Qifan Wang, Yiming Cui, Zhiwen Cao, Wenguan Wang, Siyuan Qi, Dongfang Liu</li>
<li>for: 这篇论文的目的是提出一种有效且有效的大规模 transformer 模型适应方法，以减少 fine-tuning 中的参数数量。</li>
<li>methods: 这篇论文使用了一些 parameter-efficient learning 技术，包括引入 learnable key-value prompts 和 visual prompts，以提高模型的适应能力。此外，它还提出了一个 prompt pruning 程序，可以系统地删除低重要性的 prompt，以提高模型的效率。</li>
<li>results: 这篇论文的实验结果显示，它的方法可以与一些现有的基eline相比，在两个 benchmark 上表现出色，并且仅使用了模型的 0.32% 的参数数量。<details>
<summary>Abstract</summary>
As the size of transformer-based models continues to grow, fine-tuning these large-scale pretrained vision models for new tasks has become increasingly parameter-intensive. Parameter-efficient learning has been developed to reduce the number of tunable parameters during fine-tuning. Although these methods show promising results, there is still a significant performance gap compared to full fine-tuning. To address this challenge, we propose an Effective and Efficient Visual Prompt Tuning (E^2VPT) approach for large-scale transformer-based model adaptation. Specifically, we introduce a set of learnable key-value prompts and visual prompts into self-attention and input layers, respectively, to improve the effectiveness of model fine-tuning. Moreover, we design a prompt pruning procedure to systematically prune low importance prompts while preserving model performance, which largely enhances the model's efficiency. Empirical results demonstrate that our approach outperforms several state-of-the-art baselines on two benchmarks, with considerably low parameter usage (e.g., 0.32% of model parameters on VTAB-1k). Our code is available at https://github.com/ChengHan111/E2VPT.
</details>
<details>
<summary>摘要</summary>
随着 transformer-based 模型的大小继续增长， fine-tuning these large-scale pretrained vision models for new tasks 已成为 parameter-intensive 的挑战。parameter-efficient learning 已经开发出来以减少 fine-tuning 过程中的可调参数数量。虽然这些方法显示了扎实的结果，但是还有一定的性能差距 compared to full fine-tuning。为了解决这个挑战，我们提出了一种 Effective and Efficient Visual Prompt Tuning (E^2VPT) 方法，用于大规模 transformer-based 模型的适应。specifically，我们在 self-attention 层和输入层中引入了一些可学习的 key-value prompts 和 visual prompts，以提高模型的 fine-tuning 效果。此外，我们还设计了一种 prompt pruning 过程，可以系统地剔除低重要性的 prompts，并保持模型的性能，这有效地提高了模型的效率。实验结果表明，我们的方法可以与一些 state-of-the-art 基eline 相比，在 two benchmarks 上表现出色，并且具有较低的参数使用率（例如，0.32% 的模型参数在 VTAB-1k 上）。我们的代码可以在 https://github.com/ChengHan111/E2VPT 上找到。
</details></li>
</ul>
<hr>
<h2 id="ClusterSeq-Enhancing-Sequential-Recommender-Systems-with-Clustering-based-Meta-Learning"><a href="#ClusterSeq-Enhancing-Sequential-Recommender-Systems-with-Clustering-based-Meta-Learning" class="headerlink" title="ClusterSeq: Enhancing Sequential Recommender Systems with Clustering based Meta-Learning"></a>ClusterSeq: Enhancing Sequential Recommender Systems with Clustering based Meta-Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13766">http://arxiv.org/abs/2307.13766</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammmadmahdi Maheri, Reza Abdollahzadeh, Bardia Mohammadi, Mina Rafiei, Jafar Habibi, Hamid R. Rabiee</li>
<li>For: 解决用户冷启始问题，提高续传推荐系统的效果。* Methods: meta-learning clustering-based sequential recommender system，利用用户序列中的动态信息提高物品预测精度。* Results: 比对几种现状的meta-学推荐器，ClusterSeq显示出较高的预测精度，特别是对”小用户”的预测。<details>
<summary>Abstract</summary>
In practical scenarios, the effectiveness of sequential recommendation systems is hindered by the user cold-start problem, which arises due to limited interactions for accurately determining user preferences. Previous studies have attempted to address this issue by combining meta-learning with user and item-side information. However, these approaches face inherent challenges in modeling user preference dynamics, particularly for "minor users" who exhibit distinct preferences compared to more common or "major users." To overcome these limitations, we present a novel approach called ClusterSeq, a Meta-Learning Clustering-Based Sequential Recommender System. ClusterSeq leverages dynamic information in the user sequence to enhance item prediction accuracy, even in the absence of side information. This model preserves the preferences of minor users without being overshadowed by major users, and it capitalizes on the collective knowledge of users within the same cluster. Extensive experiments conducted on various benchmark datasets validate the effectiveness of ClusterSeq. Empirical results consistently demonstrate that ClusterSeq outperforms several state-of-the-art meta-learning recommenders. Notably, compared to existing meta-learning methods, our proposed approach achieves a substantial improvement of 16-39% in Mean Reciprocal Rank (MRR).
</details>
<details>
<summary>摘要</summary>
在实际应用场景中，顺序推荐系统的效果受用户冷启 пробле 的限制，这种问题由用户与ITEM之间的交互有限，难以准确地确定用户的喜好。先前的研究已经尝试通过meta-学习与用户和ITEM的信息结合来解决这个问题，但这些方法面临用户喜好动态模型化的内在挑战，特别是对"小用户"（minor users）的喜好表现出明显的差异。为了解决这些限制，我们提出了一种新的方法：ClusterSeq，这是一种基于 clustering 的 Meta-Learning Sequential Recommender System。ClusterSeq 利用用户序列中的动态信息来提高ITEM预测精度，即使在没有副信息的情况下。这种模型保持了小用户的喜好，不被大用户（major users）所掩蔽，同时利用用户序列中的共同知识来提高推荐的准确率。经验 validate 了 ClusterSeq 的效果，与先前的 estado-of-the-art  meta-学习推荐器相比，ClusterSeq 在 Mean Reciprocal Rank（MRR）上表现出了明显的提高，具体数据表明，ClusterSeq 与先前的 meta-学习方法相比，在 MRR 上提高了16-39%。
</details></li>
</ul>
<hr>
<h2 id="Implicitly-Normalized-Explicitly-Regularized-Density-Estimation"><a href="#Implicitly-Normalized-Explicitly-Regularized-Density-Estimation" class="headerlink" title="Implicitly Normalized Explicitly Regularized Density Estimation"></a>Implicitly Normalized Explicitly Regularized Density Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13763">http://arxiv.org/abs/2307.13763</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mark Kozdoba, Binyamin Perets, Shie Mannor</li>
<li>for: 本文提出了一种新的非 Parametric density estimation方法，该方法基于 Sobolev  нор的 regularization。</li>
<li>methods: 本方法不同于 Kernel Density Estimation，可以使模型的偏好明确和可读性。虽然不存在关闭式analytic形式的kernel，但可以使用采样来approximate它。但问题是非CONvex，标准的梯度方法不好。但是，我们表明可以使用适当的初始化和自然梯度，以获得良好的解。</li>
<li>results: 本方法可以获得不正规化的概率分布，这使得不能使用log-likelihood дляcross validation。但我们表明可以使用 Fisher Divergence based Score Matching方法来解决这个问题。我们在 ADBench 最新的异常检测 benchmark 上评估了本方法，并发现它在more than 15Algorithms中排名第二。<details>
<summary>Abstract</summary>
We propose a new approach to non-parametric density estimation, that is based on regularizing a Sobolev norm of the density. This method is provably different from Kernel Density Estimation, and makes the bias of the model clear and interpretable. While there is no closed analytic form for the associated kernel, we show that one can approximate it using sampling. The optimization problem needed to determine the density is non-convex, and standard gradient methods do not perform well. However, we show that with an appropriate initialization and using natural gradients, one can obtain well performing solutions. Finally, while the approach provides unnormalized densities, which prevents the use of log-likelihood for cross validation, we show that one can instead adapt Fisher Divergence based Score Matching methods for this task. We evaluate the resulting method on the comprehensive recent Anomaly Detection benchmark suite, ADBench, and find that it ranks second best, among more than 15 algorithms.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的非参数性密度估计方法，基于 Sobolev  нор的规范化。这种方法与核密度估计方法不同，可以清晰地显示模型的偏见。虽然该密度函数没有固定的关联核函数，但我们表明可以使用采样来approximate它。优化问题需要解决的非 conjugate 问题，标准的梯度法不太好。然而，我们表明，通过适当的初始化和使用自然梯度，可以获得良好的解。虽然该方法提供的密度函数没有标准化，因此无法使用对数似然函数进行cross validation，但我们示出了使用 Fisher 分布 Based Score Matching 方法来解决这个问题。我们对最新的 Anomaly Detection benchmark suite ADBench 进行了评估，并发现其在more than 15 算法中排名第二。
</details></li>
</ul>
<hr>
<h2 id="Training-based-Model-Refinement-and-Representation-Disagreement-for-Semi-Supervised-Object-Detection"><a href="#Training-based-Model-Refinement-and-Representation-Disagreement-for-Semi-Supervised-Object-Detection" class="headerlink" title="Training-based Model Refinement and Representation Disagreement for Semi-Supervised Object Detection"></a>Training-based Model Refinement and Representation Disagreement for Semi-Supervised Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13755">http://arxiv.org/abs/2307.13755</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seyed Mojtaba Marvasti-Zadeh, Nilanjan Ray, Nadir Erbilgin</li>
<li>for: 提高现有 объек检测器的性能和泛化能力，通过使用有限的标注数据和广泛的无标注数据进行 semi-supervised object detection。</li>
<li>methods: 提出了一种新的训练阶段基于模型级别的准确强化（TMR）和一种简单 yet effective的表示不一致（RD）策略，用于解决经典EMA策略和教师-学生模型在训练后期的一致问题。</li>
<li>results: 对比于现有SSOD方法，提出的方法在COCO标准、COCO附加和Pascal VOC数据集上得到了更高的性能，具体来说是与基线Unbiased-Teacher-v2（&amp; Unbiased-Teacher-v1）方法相比，平均mAP差距为2.23、2.1、3.36（&amp; 2.07、1.9、3.27）。<details>
<summary>Abstract</summary>
Semi-supervised object detection (SSOD) aims to improve the performance and generalization of existing object detectors by utilizing limited labeled data and extensive unlabeled data. Despite many advances, recent SSOD methods are still challenged by inadequate model refinement using the classical exponential moving average (EMA) strategy, the consensus of Teacher-Student models in the latter stages of training (i.e., losing their distinctiveness), and noisy/misleading pseudo-labels. This paper proposes a novel training-based model refinement (TMR) stage and a simple yet effective representation disagreement (RD) strategy to address the limitations of classical EMA and the consensus problem. The TMR stage of Teacher-Student models optimizes the lightweight scaling operation to refine the model's weights and prevent overfitting or forgetting learned patterns from unlabeled data. Meanwhile, the RD strategy helps keep these models diverged to encourage the student model to explore complementary representations. Our approach can be integrated into established SSOD methods and is empirically validated using two baseline methods, with and without cascade regression, to generate more reliable pseudo-labels. Extensive experiments demonstrate the superior performance of our approach over state-of-the-art SSOD methods. Specifically, the proposed approach outperforms the baseline Unbiased-Teacher-v2 (& Unbiased-Teacher-v1) method by an average mAP margin of 2.23, 2.1, and 3.36 (& 2.07, 1.9, and 3.27) on COCO-standard, COCO-additional, and Pascal VOC datasets, respectively.
</details>
<details>
<summary>摘要</summary>
semi-supervised对象检测（SSOD）目标是提高现有对象检测器的性能和泛化能力，通过利用有限的标注数据和广泛的无标注数据。 despite many advances, recent SSOD methods are still challenged by inadequate model refinement using the classical exponential moving average (EMA) strategy, the consensus of Teacher-Student models in the latter stages of training (i.e., losing their distinctiveness), and noisy/misleading pseudo-labels. This paper proposes a novel training-based model refinement (TMR) stage and a simple yet effective representation disagreement (RD) strategy to address the limitations of classical EMA and the consensus problem. The TMR stage of Teacher-Student models optimizes the lightweight scaling operation to refine the model's weights and prevent overfitting or forgetting learned patterns from unlabeled data. Meanwhile, the RD strategy helps keep these models diverged to encourage the student model to explore complementary representations. Our approach can be integrated into established SSOD methods and is empirically validated using two baseline methods, with and without cascade regression, to generate more reliable pseudo-labels. Extensive experiments demonstrate the superior performance of our approach over state-of-the-art SSOD methods. Specifically, the proposed approach outperforms the baseline Unbiased-Teacher-v2 (& Unbiased-Teacher-v1) method by an average mAP margin of 2.23, 2.1, and 3.36 (& 2.07, 1.9, and 3.27) on COCO-standard, COCO-additional, and Pascal VOC datasets, respectively.
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-and-Analyzing-Generative-Data-for-Visual-Recognition"><a href="#Benchmarking-and-Analyzing-Generative-Data-for-Visual-Recognition" class="headerlink" title="Benchmarking and Analyzing Generative Data for Visual Recognition"></a>Benchmarking and Analyzing Generative Data for Visual Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13697">http://arxiv.org/abs/2307.13697</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Luodian/GenBench">https://github.com/Luodian/GenBench</a></li>
<li>paper_authors: Bo Li, Haotian Liu, Liangyu Chen, Yong Jae Lee, Chunyuan Li, Ziwei Liu</li>
<li>for: 本研究探讨了大型预训 génative 模型在视觉识别中的潜在作用，主要比较了三种不同的数据来源（生成、检索和原始）。</li>
<li>methods: 我们提出了一个广泛的标准套件（\textbf{GenBench），包括22个数据集和2548个类别，用于评估不同的视觉识别任务中的生成数据。我们还提出了一个无需训练的 metric（\textbf{CLER），用于评估生成数据在识别任务中的效果。</li>
<li>results: 我们的研究发现，生成数据在许多视觉识别任务中表现出优异的特点，并且可以通过文本推理来注入外部知识来提高性能。<details>
<summary>Abstract</summary>
Advancements in large pre-trained generative models have expanded their potential as effective data generators in visual recognition. This work delves into the impact of generative images, primarily comparing paradigms that harness external data (\ie generative \vs retrieval \vs original).   Our key contributions are: \textbf{1) GenBench Construction:} We devise \textbf{GenBench}, a broad benchmark comprising 22 datasets with 2548 categories, to appraise generative data across various visual recognition tasks. \textbf{2) CLER Score:} To address the insufficient correlation of existing metrics (\eg, FID, CLIP score) with downstream recognition performance, we propose \textbf{CLER}, a training-free metric indicating generative data's efficiency for recognition tasks prior to training. \textbf{3) New Baselines:} Comparisons of generative data with retrieved data from the same external pool help to elucidate the unique traits of generative data. \textbf{4) External Knowledge Injection:} By fine-tuning special token embeddings for each category via Textual Inversion, performance improves across 17 datasets, except when dealing with low-resolution reference images.   Our exhaustive benchmark and analysis spotlight generative data's promise in visual recognition, while identifying key challenges for future investigation.
</details>
<details>
<summary>摘要</summary>
“大型预训生成模型的进步已经扩展了它们在视觉识别中的应用前景。这个工作探讨了生成图像的影响，主要是比较使用外部数据（即生成 VS 重新 VS 原始）。我们的主要贡献包括：1. 生成测验工具（GenBench）的设计：我们开发了一个包含22个dataset、2548个类别的广泛benchmark，以评估不同的视觉识别任务中的生成数据。2. CLER分数的提案：为了解决现有的度量器（如FID、CLIP分数）与下游识别性能之间的不足相关性，我们提出了CLER，一个无需训练的度量器，可以在生成数据前以评估该数据的识别能力。3. 新的基准值：通过与相同的外部数据库中的重新数据进行比较，我们可以更好地显示生成数据的独特特征。4. 外部知识注入：通过在每个类别的特殊token嵌入中进行文本反转，我们在17个dataset中提高了表现，除了对低分辨率的参考图像。我们的充分的benchmark和分析灯示了生成数据在视觉识别中的应用潜力，同时点出了未来的挑战。”
</details></li>
</ul>
<hr>
<h2 id="Foundational-Models-Defining-a-New-Era-in-Vision-A-Survey-and-Outlook"><a href="#Foundational-Models-Defining-a-New-Era-in-Vision-A-Survey-and-Outlook" class="headerlink" title="Foundational Models Defining a New Era in Vision: A Survey and Outlook"></a>Foundational Models Defining a New Era in Vision: A Survey and Outlook</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13721">http://arxiv.org/abs/2307.13721</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/awaisrauf/awesome-cv-foundational-models">https://github.com/awaisrauf/awesome-cv-foundational-models</a></li>
<li>paper_authors: Muhammad Awais, Muzammal Naseer, Salman Khan, Rao Muhammad Anwer, Hisham Cholakkal, Mubarak Shah, Ming-Hsuan Yang, Fahad Shahbaz Khan<br>for:foundational models for computer vision tasks, such as segmentation, object detection, and image&#x2F;video captioning, are reviewed in this paper.methods:the paper discusses various architecture designs, training objectives, pre-training datasets, fine-tuning mechanisms, and prompting patterns used in foundational models.results:the paper reviews recent developments in foundational models and their applications in computer vision tasks, including their ability to generalize to new scenes and tasks, their contextual understanding, and their limitations in real-world environments.<details>
<summary>Abstract</summary>
Vision systems to see and reason about the compositional nature of visual scenes are fundamental to understanding our world. The complex relations between objects and their locations, ambiguities, and variations in the real-world environment can be better described in human language, naturally governed by grammatical rules and other modalities such as audio and depth. The models learned to bridge the gap between such modalities coupled with large-scale training data facilitate contextual reasoning, generalization, and prompt capabilities at test time. These models are referred to as foundational models. The output of such models can be modified through human-provided prompts without retraining, e.g., segmenting a particular object by providing a bounding box, having interactive dialogues by asking questions about an image or video scene or manipulating the robot's behavior through language instructions. In this survey, we provide a comprehensive review of such emerging foundational models, including typical architecture designs to combine different modalities (vision, text, audio, etc), training objectives (contrastive, generative), pre-training datasets, fine-tuning mechanisms, and the common prompting patterns; textual, visual, and heterogeneous. We discuss the open challenges and research directions for foundational models in computer vision, including difficulties in their evaluations and benchmarking, gaps in their real-world understanding, limitations of their contextual understanding, biases, vulnerability to adversarial attacks, and interpretability issues. We review recent developments in this field, covering a wide range of applications of foundation models systematically and comprehensively. A comprehensive list of foundational models studied in this work is available at \url{https://github.com/awaisrauf/Awesome-CV-Foundational-Models}.
</details>
<details>
<summary>摘要</summary>
视觉系统能够理解和描述视觉场景的compositional性是理解我们世界的基本要求。实际环境中 объектов和他们的位置之间的复杂关系、歧义和变化可以更好地用人类语言来描述，这些语言自然受到语法规则和其他模态的限制。通过大规模的训练数据和模型学习，可以bridge这些模式之间的差异，实现上下文理解、泛化和提示能力。这些模型被称为基础模型。基础模型的输出可以通过人提供的提示进行修改，例如提供 bounding box 来 segment particular object，或者通过问题提问来进行互动对话，或者通过语言指令来控制机器人的行为。在这篇评论中，我们提供了基础模型的广泛和系统性的 Review，包括不同模式结合（视觉、文本、音频等）、训练目标（对比、生成）、预训练数据集、练习机制和常见的提示模式（文本、视觉、混合）。我们还讨论了基础模型在计算机视觉领域的开放挑战和研究方向，包括评价和测试 benchmarking 困难、实际世界理解的差距、上下文理解的局限性、偏见、攻击性和可读性问题。我们还综述了该领域最新的发展，涵盖了基础模型的各种应用，从系统性和完整性来评价。基础模型的完整列表可以在 \url{https://github.com/awaisrauf/Awesome-CV-Foundational-Models} 上查看。
</details></li>
</ul>
<hr>
<h2 id="Composite-Diffusion-whole-Σparts"><a href="#Composite-Diffusion-whole-Σparts" class="headerlink" title="Composite Diffusion | whole &gt;&#x3D; Σparts"></a>Composite Diffusion | whole &gt;&#x3D; Σparts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13720">http://arxiv.org/abs/2307.13720</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vikram Jamwal, Ramaneswaran S</li>
<li>for: 这篇论文旨在提供一种基于文本扩散的高质量图像生成方法，帮助艺术家和 графический设计师更好地控制图像的配置和分布。</li>
<li>methods: 该方法使用 Composite Diffusion 技术，让艺术家通过自由形式的分割场景，将多个场景组合成一个完整的图像。在这个过程中，艺术家可以使用自然语言描述每个场景的内容，并可以通过引用图像或控制输入来调整图像的组合和融合。</li>
<li>results: 该方法可以提供高质量的图像生成，并且可以帮助艺术家更好地控制图像的配置和分布。通过对比现有图像质量指标和艺术家的愿望，我们提出了新的质量标准，以更好地评估图像生成的效果。<details>
<summary>Abstract</summary>
For an artist or a graphic designer, the spatial layout of a scene is a critical design choice. However, existing text-to-image diffusion models provide limited support for incorporating spatial information. This paper introduces Composite Diffusion as a means for artists to generate high-quality images by composing from the sub-scenes. The artists can specify the arrangement of these sub-scenes through a flexible free-form segment layout. They can describe the content of each sub-scene primarily using natural text and additionally by utilizing reference images or control inputs such as line art, scribbles, human pose, canny edges, and more.   We provide a comprehensive and modular method for Composite Diffusion that enables alternative ways of generating, composing, and harmonizing sub-scenes. Further, we wish to evaluate the composite image for effectiveness in both image quality and achieving the artist's intent. We argue that existing image quality metrics lack a holistic evaluation of image composites. To address this, we propose novel quality criteria especially relevant to composite generation.   We believe that our approach provides an intuitive method of art creation. Through extensive user surveys, quantitative and qualitative analysis, we show how it achieves greater spatial, semantic, and creative control over image generation. In addition, our methods do not need to retrain or modify the architecture of the base diffusion models and can work in a plug-and-play manner with the fine-tuned models.
</details>
<details>
<summary>摘要</summary>
For an artist or graphic designer, the spatial layout of a scene is a critical design choice. However, existing text-to-image diffusion models provide limited support for incorporating spatial information. This paper introduces Composite Diffusion as a means for artists to generate high-quality images by composing from sub-scenes. The artists can specify the arrangement of these sub-scenes through a flexible free-form segment layout. They can describe the content of each sub-scene primarily using natural text and additionally by utilizing reference images or control inputs such as line art, scribbles, human pose, canny edges, and more.  We provide a comprehensive and modular method for Composite Diffusion that enables alternative ways of generating, composing, and harmonizing sub-scenes. Further, we wish to evaluate the composite image for effectiveness in both image quality and achieving the artist's intent. We argue that existing image quality metrics lack a holistic evaluation of image composites. To address this, we propose novel quality criteria especially relevant to composite generation.   We believe that our approach provides an intuitive method of art creation. Through extensive user surveys, quantitative and qualitative analysis, we show how it achieves greater spatial, semantic, and creative control over image generation. In addition, our methods do not need to retrain or modify the architecture of the base diffusion models and can work in a plug-and-play manner with the fine-tuned models.
</details></li>
</ul>
<hr>
<h2 id="The-Visual-Language-of-Fabrics"><a href="#The-Visual-Language-of-Fabrics" class="headerlink" title="The Visual Language of Fabrics"></a>The Visual Language of Fabrics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13681">http://arxiv.org/abs/2307.13681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Valentin Deschaintre, Julia Guerrero-Viu, Diego Gutierrez, Tamy Boubekeur, Belen Masia</li>
<li>for: 本研究准备了一个名为text2fabric的新数据集，该数据集将自然语言描述与不同的织物材质图像联系起来。</li>
<li>methods: 研究人员使用自然语言描述来描述织物的外观，并分析了数据集，从中提取了一个紧凑的词汇、属性和结构，以便更好地理解人们如何描述织物。</li>
<li>results: 研究人员通过使用text2fabric数据集，可以准确地理解织物的描述，并且可以使用这些描述来特化大型视觉语言模型，例如CLIP，以创建一个有意义的潜在空间，并提高物料检索和自动标注等应用。<details>
<summary>Abstract</summary>
We introduce text2fabric, a novel dataset that links free-text descriptions to various fabric materials. The dataset comprises 15,000 natural language descriptions associated to 3,000 corresponding images of fabric materials. Traditionally, material descriptions come in the form of tags/keywords, which limits their expressivity, induces pre-existing knowledge of the appropriate vocabulary, and ultimately leads to a chopped description system. Therefore, we study the use of free-text as a more appropriate way to describe material appearance, taking the use case of fabrics as a common item that non-experts may often deal with. Based on the analysis of the dataset, we identify a compact lexicon, set of attributes and key structure that emerge from the descriptions. This allows us to accurately understand how people describe fabrics and draw directions for generalization to other types of materials. We also show that our dataset enables specializing large vision-language models such as CLIP, creating a meaningful latent space for fabric appearance, and significantly improving applications such as fine-grained material retrieval and automatic captioning.
</details>
<details>
<summary>摘要</summary>
我们介绍text2fabric数据集，这是一个新的数据集，将自然语言描述与各种织物材质相关联。该数据集包含15,000个自然语言描述和3,000个相应的织物图像。传统上，材质描述通常以标签/关键词的形式出现，这限制了其表达能力，需要先采用适当的词汇库，并最终导致描述系统被剪辑。因此，我们研究使用自然语言来更好地描述材质外观，以织物作为非专家通常处理的常见物品为例。基于数据集的分析，我们标识出了一个紧凑的词汇集、属性集和关键结构，这些元素允许我们准确地理解人们如何描述织物，并提供了泛化到其他材质的方向。此外，我们还示出了使用text2fabric数据集可以特化大型视觉语言模型，创造出meaningful的织物外观空间，并显著提高了材质 Retrieval和自动标题等应用。
</details></li>
</ul>
<hr>
<h2 id="How-Can-Large-Language-Models-Help-Humans-in-Design-and-Manufacturing"><a href="#How-Can-Large-Language-Models-Help-Humans-in-Design-and-Manufacturing" class="headerlink" title="How Can Large Language Models Help Humans in Design and Manufacturing?"></a>How Can Large Language Models Help Humans in Design and Manufacturing?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14377">http://arxiv.org/abs/2307.14377</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liane Makatura, Michael Foshey, Bohan Wang, Felix HähnLein, Pingchuan Ma, Bolei Deng, Megan Tjandrasuwita, Andrew Spielberg, Crystal Elaine Owens, Peter Yichen Chen, Allan Zhao, Amy Zhu, Wil J Norton, Edward Gu, Joshua Jacob, Yifei Li, Adriana Schulz, Wojciech Matusik</li>
<li>for:  investigate the application of Large Language Models (LLMs) in generative design across the entire design and manufacturing workflow.</li>
<li>methods:  convert text-based prompts into design specifications, transform designs into manufacturing instructions, produce design spaces and variations, compute design performance, and search for designs based on performance.</li>
<li>results:  highlight both the benefits and limitations of current LLMs through a series of examples, with the goal of catalyzing continued improvement and progression of these models.<details>
<summary>Abstract</summary>
The advancement of Large Language Models (LLMs), including GPT-4, provides exciting new opportunities for generative design. We investigate the application of this tool across the entire design and manufacturing workflow. Specifically, we scrutinize the utility of LLMs in tasks such as: converting a text-based prompt into a design specification, transforming a design into manufacturing instructions, producing a design space and design variations, computing the performance of a design, and searching for designs predicated on performance. Through a series of examples, we highlight both the benefits and the limitations of the current LLMs. By exposing these limitations, we aspire to catalyze the continued improvement and progression of these models.
</details>
<details>
<summary>摘要</summary>
大语言模型（LLM）的发展，包括GPT-4，为生成设计带来了新的机遇。我们对整个设计和生产工作流程中的应用进行调查。具体来说，我们分析LLM在以下任务中的用途：将文本提示转换成设计规范，将设计转换成生产指令，生成设计空间和设计变化，计算设计的性能，以及基于性能搜索设计。通过一些例子，我们显示了当前LLM的优势和局限性。通过暴露这些局限性，我们希望能够促进这些模型的持续改进和进步。
</details></li>
</ul>
<hr>
<h2 id="FedDRL-A-Trustworthy-Federated-Learning-Model-Fusion-Method-Based-on-Staged-Reinforcement-Learning"><a href="#FedDRL-A-Trustworthy-Federated-Learning-Model-Fusion-Method-Based-on-Staged-Reinforcement-Learning" class="headerlink" title="FedDRL: A Trustworthy Federated Learning Model Fusion Method Based on Staged Reinforcement Learning"></a>FedDRL: A Trustworthy Federated Learning Model Fusion Method Based on Staged Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13716">http://arxiv.org/abs/2307.13716</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leiming Chen, Cihao Dong, Sibo Qiao, Ziling Huang, Kai Wang, Yuming Nie, Zhaoxiang Hou, Cheewei Tan</li>
<li>for: 解决 federated learning 中 client 模型质量不均匀和恶意上传模型导致全局模型精度下降的问题。</li>
<li>methods: 提出了一种基于 reinforcement learning 的模型融合方法，包括两个阶段：第一阶段是过滤恶意模型并选择可信客户端模型参与融合，第二阶段是自适应调整可信客户端模型的权重并进行最佳全局模型融合。</li>
<li>results: 对五种模型融合场景进行了比较，研究结果表明，我们的算法比基eline algorithms 高于可靠性而保持精度。<details>
<summary>Abstract</summary>
Traditional federated learning uses the number of samples to calculate the weights of each client model and uses this fixed weight value to fusion the global model. However, in practical scenarios, each client's device and data heterogeneity leads to differences in the quality of each client's model. Thus the contribution to the global model is not wholly determined by the sample size. In addition, if clients intentionally upload low-quality or malicious models, using these models for aggregation will lead to a severe decrease in global model accuracy. Traditional federated learning algorithms do not address these issues. To solve this probelm, we propose FedDRL, a model fusion approach using reinforcement learning based on a two staged approach. In the first stage, Our method could filter out malicious models and selects trusted client models to participate in the model fusion. In the second stage, the FedDRL algorithm adaptively adjusts the weights of the trusted client models and aggregates the optimal global model. We also define five model fusion scenarios and compare our method with two baseline algorithms in those scenarios. The experimental results show that our algorithm has higher reliability than other algorithms while maintaining accuracy.
</details>
<details>
<summary>摘要</summary>
传统的联合学习方法使用客户端模型的样本数来计算每个客户端模型的权重值，然后使用这些固定权重值进行模型融合。然而，在实际应用中，每个客户端的设备和数据多样性会导致每个客户端模型的质量差异，因此折衔到全局模型的质量不仅取决于样本数。此外，如果客户端故意上传低质量或黑客模型，使用这些模型进行融合会导致全局模型的准确率受到严重的影响。传统的联合学习算法不能解决这些问题。为解决这个问题，我们提出了FedDRL，一种基于强化学习的模型融合方法。在第一个阶段，我们的方法可以过滤出黑客模型，并选择可信worth客户端模型参与模型融合。在第二个阶段，FedDRL算法可以自适应地调整可信worth客户端模型的权重值，并将最佳的全局模型进行融合。我们还定义了五种模型融合场景，并与两个基eline算法进行比较。实验结果显示，我们的算法在可靠性和准确率之间取得了良好的平衡。
</details></li>
</ul>
<hr>
<h2 id="Towards-an-AI-Accountability-Policy"><a href="#Towards-an-AI-Accountability-Policy" class="headerlink" title="Towards an AI Accountability Policy"></a>Towards an AI Accountability Policy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13658">http://arxiv.org/abs/2307.13658</a></li>
<li>repo_url: None</li>
<li>paper_authors: Przemyslaw Grabowicz, Nicholas Perello, Yair Zick</li>
<li>for: 这份白皮书是回应美国国家电信管理局（NATIONAL TELECOMMUNICATIONS AND INFORMATION ADMINISTRATION，NTIA）发布的“AI责任政策请求意见”。</li>
<li>methods: 本白皮书提供了一系列相互连接的建议，用于制定AI责任政策。</li>
<li>results: 本白皮书的建议可以帮助建立一个可靠、可信、可追溯的AI责任政策制度。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
This white paper is a response to the "AI Accountability Policy Request for Comments" by the National Telecommunications and Information Administration of the United States. The question numbers for which comments were requested are provided in superscripts at the end of key sentences answering the respective questions. The white paper offers a set of interconnected recommendations for an AI accountability policy.
</details>
<details>
<summary>摘要</summary>
这份白皮书是回应美国国家电信和信息管理局（NATIONAL TELECOMMUNICATIONS AND INFORMATION ADMINISTRATION，NTIA）发布的“人工智能负责任政策请求意见”（AI Accountability Policy Request for Comments）。在关键句中的问号（superscripts）后面提供了对应的答案。本白皮书提出了一系列相互关联的人工智能负责任政策建议。
</details></li>
</ul>
<hr>
<h2 id="QuickQual-Lightweight-convenient-retinal-image-quality-scoring-with-off-the-shelf-pretrained-models"><a href="#QuickQual-Lightweight-convenient-retinal-image-quality-scoring-with-off-the-shelf-pretrained-models" class="headerlink" title="QuickQual: Lightweight, convenient retinal image quality scoring with off-the-shelf pretrained models"></a>QuickQual: Lightweight, convenient retinal image quality scoring with off-the-shelf pretrained models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13646">http://arxiv.org/abs/2307.13646</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/justinengelmann/quickqual">https://github.com/justinengelmann/quickqual</a></li>
<li>paper_authors: Justin Engelmann, Amos Storkey, Miguel O. Bernabeu</li>
<li>for: 这个论文的目的是提出一种新的Retinal Image Quality Scoring（RIQS）方法，以解决目前主流的深度学习（DL）方法对眼eground图像质量评分的问题。</li>
<li>methods: 这个方法使用了一个简单的ImageNet预训练的Densenet121背景，并使用Support Vector Machine（SVM）进行分类。</li>
<li>results: 这个方法可以达到新的州对眼eground图像质量评分的最佳状态（Accuracy：88.50%，AUC：0.9687），表明RIQS可以通过普通的感知特征学习来解决，而不需要大量的fundus图像数据进行深度学习模型训练。<details>
<summary>Abstract</summary>
Image quality remains a key problem for both traditional and deep learning (DL)-based approaches to retinal image analysis, but identifying poor quality images can be time consuming and subjective. Thus, automated methods for retinal image quality scoring (RIQS) are needed. The current state-of-the-art is MCFNet, composed of three Densenet121 backbones each operating in a different colour space. MCFNet, and the EyeQ dataset released by the same authors, was a huge step forward for RIQS. We present QuickQual, a simple approach to RIQS, consisting of a single off-the-shelf ImageNet-pretrained Densenet121 backbone plus a Support Vector Machine (SVM). QuickQual performs very well, setting a new state-of-the-art for EyeQ (Accuracy: 88.50% vs 88.00% for MCFNet; AUC: 0.9687 vs 0.9588). This suggests that RIQS can be solved with generic perceptual features learned on natural images, as opposed to requiring DL models trained on large amounts of fundus images. Additionally, we propose a Fixed Prior linearisation scheme, that converts EyeQ from a 3-way classification to a continuous logistic regression task. For this task, we present a second model, QuickQual MEga Minified Estimator (QuickQual-MEME), that consists of only 10 parameters on top of an off-the-shelf Densenet121 and can distinguish between gradable and ungradable images with an accuracy of 89.18% (AUC: 0.9537). Code and model are available on GitHub: https://github.com/justinengelmann/QuickQual . QuickQual is so lightweight, that the entire inference code (and even the parameters for QuickQual-MEME) is already contained in this paper.
</details>
<details>
<summary>摘要</summary>
Image quality remains a key problem for both traditional and deep learning (DL)-based approaches to retinal image analysis, but identifying poor quality images can be time-consuming and subjective. Thus, automated methods for retinal image quality scoring (RIQS) are needed. The current state-of-the-art is MCFNet, composed of three Densenet121 backbones each operating in a different color space. MCFNet, and the EyeQ dataset released by the same authors, was a huge step forward for RIQS. We present QuickQual, a simple approach to RIQS, consisting of a single off-the-shelf ImageNet-pretrained Densenet121 backbone plus a Support Vector Machine (SVM). QuickQual performs very well, setting a new state-of-the-art for EyeQ (Accuracy: 88.50% vs 88.00% for MCFNet; AUC: 0.9687 vs 0.9588). This suggests that RIQS can be solved with generic perceptual features learned on natural images, as opposed to requiring DL models trained on large amounts of fundus images. Additionally, we propose a Fixed Prior linearization scheme, that converts EyeQ from a 3-way classification to a continuous logistic regression task. For this task, we present a second model, QuickQual MEga Minified Estimator (QuickQual-MEME), that consists of only 10 parameters on top of an off-the-shelf Densenet121 and can distinguish between gradable and ungradable images with an accuracy of 89.18% (AUC: 0.9537). Code and model are available on GitHub: <https://github.com/justinengelmann/QuickQual>. QuickQual is so lightweight, that the entire inference code (and even the parameters for QuickQual-MEME) is already contained in this paper.
</details></li>
</ul>
<hr>
<h2 id="Safety-Margins-for-Reinforcement-Learning"><a href="#Safety-Margins-for-Reinforcement-Learning" class="headerlink" title="Safety Margins for Reinforcement Learning"></a>Safety Margins for Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13642">http://arxiv.org/abs/2307.13642</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexander Grushin, Walt Woods, Alvaro Velasquez, Simon Khan</li>
<li>for: 本研究旨在提供一种能够量化评估自主控制器在某些情况下的危险性，以便在例如货物运输应用中引入人工监督。</li>
<li>methods: 本研究使用了一种基于概率动作的方法来定义自主控制器的真实扰乱性，并可以在实时中计算出代理扰乱度量。</li>
<li>results: 研究人员通过评估APE-X和A3C在Atari环境中学习的策略，发现安全间隔可以直接反映自主控制器的危险程度，并且当自主控制器接近失败状态时，安全间隔会逐渐减少。<details>
<summary>Abstract</summary>
Any autonomous controller will be unsafe in some situations. The ability to quantitatively identify when these unsafe situations are about to occur is crucial for drawing timely human oversight in, e.g., freight transportation applications. In this work, we demonstrate that the true criticality of an agent's situation can be robustly defined as the mean reduction in reward given some number of random actions. Proxy criticality metrics that are computable in real-time (i.e., without actually simulating the effects of random actions) can be compared to the true criticality, and we show how to leverage these proxy metrics to generate safety margins, which directly tie the consequences of potentially incorrect actions to an anticipated loss in overall performance. We evaluate our approach on learned policies from APE-X and A3C within an Atari environment, and demonstrate how safety margins decrease as agents approach failure states. The integration of safety margins into programs for monitoring deployed agents allows for the real-time identification of potentially catastrophic situations.
</details>
<details>
<summary>摘要</summary>
任何自主控制器都会在某些情况下不安全。可以量化地识别这些不安全情况的出现是控制器运行中的关键，例如在货物运输应用中。在这种工作中，我们表明了真正的危机性可以通过计算一些随机动作后的奖励减少平均值来定义。可计时计算的代理危机指标可以与真实危机指标进行比较，我们示出如何利用这些代理指标生成安全优势，这些优势直接与可能错误的行为相关联，并且与预计的性能损失相对比较。我们在APE-X和A3Clearned policies中的Atari环境中评估了我们的方法，并示出了安全优势随着控制器接近失败状态而减少。将安全优势 integrating into deployed agents的监控程序中可以实时识别潜在的灾难性情况。
</details></li>
</ul>
<hr>
<h2 id="GPT-3-Models-are-Few-Shot-Financial-Reasoners"><a href="#GPT-3-Models-are-Few-Shot-Financial-Reasoners" class="headerlink" title="GPT-3 Models are Few-Shot Financial Reasoners"></a>GPT-3 Models are Few-Shot Financial Reasoners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13617">http://arxiv.org/abs/2307.13617</a></li>
<li>repo_url: None</li>
<li>paper_authors: Raul Salles de Padua, Imran Qureshi, Mustafa U. Karakaplan</li>
<li>For: The paper is written to evaluate the performance of pre-trained language models, specifically GPT-3, in answering financial questions.* Methods: The paper uses a combination of a retriever and a logic engine to answer financial questions, and the authors experiment with different approaches to fine-tune the model.* Results: The authors find that a separate retrieval model and logic engine are essential components to achieving state-of-the-art performance in the financial question answering task, and their refined prompt-engineering approach on GPT-3 achieves near state-of-the-art accuracy without any fine-tuning.Here are the three points in Simplified Chinese text:* For: 本文是用来评估预训练语言模型，尤其是 GPT-3，在回答金融问题上的性能。* Methods: 本文使用了一种组合Retriever和逻辑引擎来回答金融问题，并对不同方法进行了 эксперимент来细化模型。* Results: 作者发现，分离的Retrieval模型和逻辑引擎是回答金融问题的State-of-the-art性能的关键组成部分，并且他们的改进的提问工程学approach在 GPT-3 上 achiev near State-of-the-art accuracy without any fine-tuning.<details>
<summary>Abstract</summary>
Financial analysis is an important tool for evaluating company performance. Practitioners work to answer financial questions to make profitable investment decisions, and use advanced quantitative analyses to do so. As a result, Financial Question Answering (QA) is a question answering task that requires deep reasoning about numbers. Furthermore, it is unknown how well pre-trained language models can reason in the financial domain. The current state-of-the-art requires a retriever to collect relevant facts about the financial question from the text and a generator to produce a valid financial program and a final answer. However, recently large language models like GPT-3 have achieved state-of-the-art performance on wide variety of tasks with just a few shot examples. We run several experiments with GPT-3 and find that a separate retrieval model and logic engine continue to be essential components to achieving SOTA performance in this task, particularly due to the precise nature of financial questions and the complex information stored in financial documents. With this understanding, our refined prompt-engineering approach on GPT-3 achieves near SOTA accuracy without any fine-tuning.
</details>
<details>
<summary>摘要</summary>
金融分析是评估公司性能的重要工具。实践者们努力回答金融问题，以达到可持续的投资决策。为此，金融问答（QA）是一个需要深入理解数字的问答任务。然而，目前不确定前置语言模型在金融领域的推理能力。现状顶峰需要一个检索器收集金融问题相关的信息，以及一个生成器生成有效的金融计划和最终答案。然而，最近大型语言模型如GPT-3已经在各种任务上达到了顶峰性能，只需要几个示例。我们进行了多个实验，发现在这个任务中，独立的检索器和逻辑引擎仍然是必要的组成部分，特别是因为金融问题的具体性和金融文档中的复杂信息。通过这种理解，我们对GPT-3进行了改进的提示工程，达到了近顶峰准确率，无需任何微调。
</details></li>
</ul>
<hr>
<h2 id="Team-Intro-to-AI-team8-at-CoachAI-Badminton-Challenge-2023-Advanced-ShuttleNet-for-Shot-Predictions"><a href="#Team-Intro-to-AI-team8-at-CoachAI-Badminton-Challenge-2023-Advanced-ShuttleNet-for-Shot-Predictions" class="headerlink" title="Team Intro to AI team8 at CoachAI Badminton Challenge 2023: Advanced ShuttleNet for Shot Predictions"></a>Team Intro to AI team8 at CoachAI Badminton Challenge 2023: Advanced ShuttleNet for Shot Predictions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13715">http://arxiv.org/abs/2307.13715</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shih-Hong Chen, Pin-Hsuan Chou, Yong-Fu Liu, Chien-An Han</li>
<li>for: 提高现有框架ShuttleNet在预测羽毛球击球类型和位置的性能，通过利用过去的拍打。</li>
<li>methods: 利用过去的拍打来提高ShuttleNet的预测性能。</li>
<li>results: 在CoachAI Badminton Challenge中达到了比基准更好的结果，并最终蝉联赛事的冠军。<details>
<summary>Abstract</summary>
In this paper, our objective is to improve the performance of the existing framework ShuttleNet in predicting badminton shot types and locations by leveraging past strokes. We participated in the CoachAI Badminton Challenge at IJCAI 2023 and achieved significantly better results compared to the baseline. Ultimately, our team achieved the first position in the competition and we made our code available.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们的目标是通过利用过去的拍打来提高现有框架ShuttleNet在预测羽毛球shot类型和位置的性能。我们参加了IJCAI 2023年的CoachAI Badminton Challenge并取得了对基线的显著改进。最终，我们的团队取得了比赛的第一名，并将代码公开。Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/26/cs.AI_2023_07_26/" data-id="clpxp03ts001efm882h295su1" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_07_26" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/26/cs.CL_2023_07_26/" class="article-date">
  <time datetime="2023-07-26T11:00:00.000Z" itemprop="datePublished">2023-07-26</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/26/cs.CL_2023_07_26/">cs.CL - 2023-07-26</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Say-Goodbye-to-RNN-T-Loss-A-Novel-CIF-based-Transducer-Architecture-for-Automatic-Speech-Recognition"><a href="#Say-Goodbye-to-RNN-T-Loss-A-Novel-CIF-based-Transducer-Architecture-for-Automatic-Speech-Recognition" class="headerlink" title="Say Goodbye to RNN-T Loss: A Novel CIF-based Transducer Architecture for Automatic Speech Recognition"></a>Say Goodbye to RNN-T Loss: A Novel CIF-based Transducer Architecture for Automatic Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14132">http://arxiv.org/abs/2307.14132</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tian-Hao Zhang, Dinghao Zhou, Guiping Zhong, Baoxiang Li</li>
<li>for: 提高 ASR 模型的效率和性能</li>
<li>methods: 提出一种新的 CIF-Transducer 模型，具有 Continuous Integrate-and-Fire 机制，避免 RNN-T 损失，并具有更多的预测网络作用</li>
<li>results: 在 AISHELL-1 和 WenetSpeech 数据集上实现了 state-of-the-art 的效果，并且比 RNN-T 模型具有更低的计算开销<details>
<summary>Abstract</summary>
RNN-T models are widely used in ASR, which rely on the RNN-T loss to achieve length alignment between input audio and target sequence. However, the implementation complexity and the alignment-based optimization target of RNN-T loss lead to computational redundancy and a reduced role for predictor network, respectively. In this paper, we propose a novel model named CIF-Transducer (CIF-T) which incorporates the Continuous Integrate-and-Fire (CIF) mechanism with the RNN-T model to achieve efficient alignment. In this way, the RNN-T loss is abandoned, thus bringing a computational reduction and allowing the predictor network a more significant role. We also introduce Funnel-CIF, Context Blocks, Unified Gating and Bilinear Pooling joint network, and auxiliary training strategy to further improve performance. Experiments on the 178-hour AISHELL-1 and 10000-hour WenetSpeech datasets show that CIF-T achieves state-of-the-art results with lower computational overhead compared to RNN-T models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Leveraging-Implicit-Feedback-from-Deployment-Data-in-Dialogue"><a href="#Leveraging-Implicit-Feedback-from-Deployment-Data-in-Dialogue" class="headerlink" title="Leveraging Implicit Feedback from Deployment Data in Dialogue"></a>Leveraging Implicit Feedback from Deployment Data in Dialogue</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14117">http://arxiv.org/abs/2307.14117</a></li>
<li>repo_url: None</li>
<li>paper_authors: Richard Yuanzhe Pang, Stephen Roller, Kyunghyun Cho, He He, Jason Weston</li>
<li>for: 本研究旨在提高社交对话机器人，通过学习自然对话中的用户和模型之间的交互。</li>
<li>methods: 本研究使用自然对话中的用户响应长度、情感和未来的人类响应作为机器生成句子质量的隐式指标，来训练新模型。</li>
<li>results: 人工评估表明新模型的回答比基础模型更高质量，但是某些代理指标可能会导致更多的不良特性，如争议性或不友好的回答。<details>
<summary>Abstract</summary>
We study improving social conversational agents by learning from natural dialogue between users and a deployed model, without extra annotations. To implicitly measure the quality of a machine-generated utterance, we leverage signals like user response length, sentiment and reaction of the future human utterances in the collected dialogue episodes. Our experiments use the publicly released deployment data from BlenderBot (Xu et al., 2023). Human evaluation indicates improvements in our new models over baseline responses; however, we find that some proxy signals can lead to more generations with undesirable properties as well. For example, optimizing for conversation length can lead to more controversial or unfriendly generations compared to the baseline, whereas optimizing for positive sentiment or reaction can decrease these behaviors.
</details>
<details>
<summary>摘要</summary>
我们研究改进社交对话代理人，学习自然的用户对话和部署模型之间的自然对话，不需要额外的标注。为了隐式地衡量机器生成的句子质量，我们利用用户回应长度、情感和未来人类对话的反映信号。我们的实验使用公共发布的部署数据集from BlenderBot（Xu et al., 2023）。人类评估显示我们的新模型比基线响应提高，但我们发现一些代理信号可能会导致更多的不良特性。例如，优化对话长度可能会导致更多的争议性或不友好的生成，而优化正面情感或反应可能会降低这些行为。
</details></li>
</ul>
<hr>
<h2 id="Decoding-ChatGPT-A-Taxonomy-of-Existing-Research-Current-Challenges-and-Possible-Future-Directions"><a href="#Decoding-ChatGPT-A-Taxonomy-of-Existing-Research-Current-Challenges-and-Possible-Future-Directions" class="headerlink" title="Decoding ChatGPT: A Taxonomy of Existing Research, Current Challenges, and Possible Future Directions"></a>Decoding ChatGPT: A Taxonomy of Existing Research, Current Challenges, and Possible Future Directions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14107">http://arxiv.org/abs/2307.14107</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shahab Saquib Sohail, Faiza Farhat, Yassine Himeur, Mohammad Nadeem, Dag Øivind Madsen, Yashbir Singh, Shadi Atalla, Wathiq Mansoor</li>
<li>for: 本研究的目的是为了提供一份关于ChatGPT研究的综述，探讨ChatGPT在不同领域的应用和潜在问题。</li>
<li>methods: 本研究使用了Scopus检索的 более чем100篇论文，进行了分类和 crítical分析，描述了不同领域的应用和挑战。</li>
<li>results: 研究发现了ChatGPT在医疗、市场营销、金融服务、软件工程、学术科研写作、环境科学和自然语言处理等领域的潜在应用，并提出了解决存在的问题和未来研究方向。<details>
<summary>Abstract</summary>
Chat Generative Pre-trained Transformer (ChatGPT) has gained significant interest and attention since its launch in November 2022. It has shown impressive performance in various domains, including passing exams and creative writing. However, challenges and concerns related to biases and trust persist. In this work, we present a comprehensive review of over 100 Scopus-indexed publications on ChatGPT, aiming to provide a taxonomy of ChatGPT research and explore its applications. We critically analyze the existing literature, identifying common approaches employed in the studies. Additionally, we investigate diverse application areas where ChatGPT has found utility, such as healthcare, marketing and financial services, software engineering, academic and scientific writing, research and education, environmental science, and natural language processing. Through examining these applications, we gain valuable insights into the potential of ChatGPT in addressing real-world challenges. We also discuss crucial issues related to ChatGPT, including biases and trustworthiness, emphasizing the need for further research and development in these areas. Furthermore, we identify potential future directions for ChatGPT research, proposing solutions to current challenges and speculating on expected advancements. By fully leveraging the capabilities of ChatGPT, we can unlock its potential across various domains, leading to advancements in conversational AI and transformative impacts in society.
</details>
<details>
<summary>摘要</summary>
chat生成预训练变换器（chatGPT）已经在2022年11月发布以来引起了广泛的关注和注意。它在不同领域展现出了卓越的表现，包括考试和创作写作。然而，关于偏见和信任的问题和担忧仍然存在。在这项工作中，我们对Scopus检索的 более than 100篇论文进行了全面的回顾，以提供 chatGPT 研究的分类和探讨其应用。我们critically analyze existing literature, identifying common approaches employed in the studies. In addition, we investigate diverse application areas where chatGPT has found utility, such as healthcare, marketing and financial services, software engineering, academic and scientific writing, research and education, environmental science, and natural language processing. Through examining these applications, we gain valuable insights into the potential of chatGPT in addressing real-world challenges. We also discuss crucial issues related to chatGPT, including biases and trustworthiness, emphasizing the need for further research and development in these areas. Furthermore, we identify potential future directions for chatGPT research, proposing solutions to current challenges and speculating on expected advancements. By fully leveraging the capabilities of chatGPT, we can unlock its potential across various domains, leading to advancements in conversational AI and transformative impacts in society.
</details></li>
</ul>
<hr>
<h2 id="Multi3WOZ-A-Multilingual-Multi-Domain-Multi-Parallel-Dataset-for-Training-and-Evaluating-Culturally-Adapted-Task-Oriented-Dialog-Systems"><a href="#Multi3WOZ-A-Multilingual-Multi-Domain-Multi-Parallel-Dataset-for-Training-and-Evaluating-Culturally-Adapted-Task-Oriented-Dialog-Systems" class="headerlink" title="Multi3WOZ: A Multilingual, Multi-Domain, Multi-Parallel Dataset for Training and Evaluating Culturally Adapted Task-Oriented Dialog Systems"></a>Multi3WOZ: A Multilingual, Multi-Domain, Multi-Parallel Dataset for Training and Evaluating Culturally Adapted Task-Oriented Dialog Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14031">http://arxiv.org/abs/2307.14031</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cambridgeltl/multi3woz">https://github.com/cambridgeltl/multi3woz</a></li>
<li>paper_authors: Songbo Hu, Han Zhou, Mete Hergul, Milan Gritta, Guchun Zhang, Ignacio Iacobacci, Ivan Vulić, Anna Korhonen</li>
<li>For: The paper aims to create a large-scale, culturally adapted, and multi-domain task-oriented dialog (ToD) dataset for multiple languages.* Methods: The paper introduces a novel dataset called Multi3WOZ, which is collected through a complex bottom-up process that includes human evaluation and cultural adaptation.* Results: The paper presents the first sets of baseline scores across different ToD-related tasks for future reference, highlighting the challenging nature of the dataset.Here’s the information in Simplified Chinese text:* For: 这篇论文的目的是创建多种语言的多频道任务对话（ToD）数据集，以便训练和评估多语言和跨语言的ToD系统。* Methods: 这篇论文引入了一个新的数据集called Multi3WOZ，它是通过复杂的底层数据收集过程，包括人工评估和文化适应，而收集的。* Results: 这篇论文提供了首次的基线分数，用于未来参考，同时强调数据集的挑战性。<details>
<summary>Abstract</summary>
Creating high-quality annotated data for task-oriented dialog (ToD) is known to be notoriously difficult, and the challenges are amplified when the goal is to create equitable, culturally adapted, and large-scale ToD datasets for multiple languages. Therefore, the current datasets are still very scarce and suffer from limitations such as translation-based non-native dialogs with translation artefacts, small scale, or lack of cultural adaptation, among others. In this work, we first take stock of the current landscape of multilingual ToD datasets, offering a systematic overview of their properties and limitations. Aiming to reduce all the detected limitations, we then introduce Multi3WOZ, a novel multilingual, multi-domain, multi-parallel ToD dataset. It is large-scale and offers culturally adapted dialogs in 4 languages to enable training and evaluation of multilingual and cross-lingual ToD systems. We describe a complex bottom-up data collection process that yielded the final dataset, and offer the first sets of baseline scores across different ToD-related tasks for future reference, also highlighting its challenging nature.
</details>
<details>
<summary>摘要</summary>
In this work, we first provide a systematic overview of the current landscape of multilingual ToD datasets, highlighting their properties and limitations. To address these limitations, we introduce Multi3WOZ, a novel multilingual, multi-domain, multi-parallel ToD dataset. It is large-scale and offers culturally adapted dialogs in 4 languages to enable training and evaluation of multilingual and cross-lingual ToD systems.We describe a complex bottom-up data collection process that yielded the final dataset, and offer the first sets of baseline scores across different ToD-related tasks for future reference. The dataset is challenging, and we highlight the difficulties in collecting and annotating the data.
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-extraction-of-local-and-global-keywords-from-a-single-text"><a href="#Unsupervised-extraction-of-local-and-global-keywords-from-a-single-text" class="headerlink" title="Unsupervised extraction of local and global keywords from a single text"></a>Unsupervised extraction of local and global keywords from a single text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14005">http://arxiv.org/abs/2307.14005</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lida Aleksanyan, Armen E. Allahverdyan</li>
<li>for: 本研究旨在提出一种无监督、文库独立的方法，用于从单个文本中提取关键词。</li>
<li>methods: 该方法基于文本中词语的空间分布，以及这种分布对Random Permutation of Words的响应。与现有方法（如YAKE）相比，该方法具有三个优势：首先，它在长文本中更有效地提取关键词。第二，它可以推导出两种类型的关键词：本地关键词和全局关键词。第三，它揭示了文本中的基本主题。此外，该方法语言独立，适用于短文本。结果由人工笔评员（具有文库作品数据库中的先驱知识）进行验证，并通过人工独立的论证，基于EXTRACTED CONTENT WORDS的平均长度和EXTRACTED WORDS中的平均数量词。</li>
<li>results: 研究发现，关键词与更高阶文本特征之间存在关系，同时还发现关键词与章节分区之间的连接。<details>
<summary>Abstract</summary>
We propose an unsupervised, corpus-independent method to extract keywords from a single text. It is based on the spatial distribution of words and the response of this distribution to a random permutation of words. As compared to existing methods (such as e.g. YAKE) our method has three advantages. First, it is significantly more effective at extracting keywords from long texts. Second, it allows inference of two types of keywords: local and global. Third, it uncovers basic themes in texts. Additionally, our method is language-independent and applies to short texts. The results are obtained via human annotators with previous knowledge of texts from our database of classical literary works (the agreement between annotators is from moderate to substantial). Our results are supported via human-independent arguments based on the average length of extracted content words and on the average number of nouns in extracted words. We discuss relations of keywords with higher-order textual features and reveal a connection between keywords and chapter divisions.
</details>
<details>
<summary>摘要</summary>
我们提出了一种无监督、文献自主的方法，用于从单个文本中提取关键词。该方法基于文本中词语的空间分布和词语随机Permutation的响应。与现有方法（如YAKE）相比，我们的方法有三个优势：首先，它更有效地从长文本中提取关键词。第二，它可以推断两种类型的关键词：本地和全局。第三，它揭示了文本中基本主题。此外，我们的方法语言独立，适用于短文本。结果由人工标注者通过文本数据库中的古典文学作品的先验知识获得，并且人工标注者之间的一致度从中到substantial。我们的结果得到了人工独立的证明，基于提取的内容词的平均长度和提取词中的平均名称数。我们讨论关键词与高阶文本特征之间的关系，并发现关键词和章节分区之间的连接。
</details></li>
</ul>
<hr>
<h2 id="Affective-Natural-Language-Generation-of-Event-Descriptions-through-Fine-grained-Appraisal-Conditions"><a href="#Affective-Natural-Language-Generation-of-Event-Descriptions-through-Fine-grained-Appraisal-Conditions" class="headerlink" title="Affective Natural Language Generation of Event Descriptions through Fine-grained Appraisal Conditions"></a>Affective Natural Language Generation of Event Descriptions through Fine-grained Appraisal Conditions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14004">http://arxiv.org/abs/2307.14004</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yarik Menchaca Resendiz, Roman Klinger</li>
<li>for: 这 paper 的目的是提高文本生成模型中的情感表达，并且使用评估理论来更加细化控制文本的内容和情感表达。</li>
<li>methods: 这 paper 使用了 Bart 和 T5 两种基本的文本生成模型，并在training过程中添加了评估变量来控制文本的内容和情感表达。</li>
<li>results: 这 paper 的实验结果表明，在添加评估变量时，文本生成模型的准确率提高了10个百分点，并且文本中含有更多的细节和情感表达。这表明用户可以通过评估变量来更加细化控制文本的内容和情感表达。<details>
<summary>Abstract</summary>
Models for affective text generation have shown a remarkable progress, but they commonly rely only on basic emotion theories or valance/arousal values as conditions. This is appropriate when the goal is to create explicit emotion statements ("The kid is happy."). Emotions are, however, commonly communicated implicitly. For instance, the emotional interpretation of an event ("Their dog died.") does often not require an explicit emotion statement. In psychology, appraisal theories explain the link between a cognitive evaluation of an event and the potentially developed emotion. They put the assessment of the situation on the spot, for instance regarding the own control or the responsibility for what happens. We hypothesize and subsequently show that including appraisal variables as conditions in a generation framework comes with two advantages. (1) The generation model is informed in greater detail about what makes a specific emotion and what properties it has. This leads to text generation that better fulfills the condition. (2) The variables of appraisal allow a user to perform a more fine-grained control of the generated text, by stating properties of a situation instead of only providing the emotion category. Our Bart and T5-based experiments with 7 emotions (Anger, Disgust, Fear, Guilt, Joy, Sadness, Shame), and 7 appraisals (Attention, Responsibility, Control, Circumstance, Pleasantness, Effort, Certainty) show that (1) adding appraisals during training improves the accurateness of the generated texts by 10 pp in F1. Further, (2) the texts with appraisal variables are longer and contain more details. This exemplifies the greater control for users.
</details>
<details>
<summary>摘要</summary>
模型 для生成情感文本已经取得了非常出色的进步，但它们通常只是基于基本情感理论或振荡/兴奋值作为条件。这是当目标是创建明确的情感声明("这个孩子很高兴。")时非常适用。然而，情感通常会通过各种不同的方式表达。在心理学中，评估理论解释了情感与情感表达之间的联系。它们将情感评估纳入了框架中，例如负责任、控制等。我们提出并证明了，在生成框架中包含评估变量来自动生成文本会带来两点优势。（1）生成模型在更加细化的情况下了解情感的特点和性质，这会导致生成的文本更加符合条件。（2）评估变量使得用户可以通过指定情感表达的属性来进行更加细化的控制，而不是仅提供情感类别。我们使用Bart和T5搭配7种情感（愤怒、厌恶、恐慌、负罪感、喜乐、悲伤、耻辱）和7种评估（注意力、负责任、控制、情况、愉悦、努力、确定）进行实验，结果显示：（1）在训练中添加评估可以提高生成文本准确率10个百分点。此外，（2）包含评估变量的文本比较详细，更容易控制。这是用户的优势。
</details></li>
</ul>
<hr>
<h2 id="Diff-E-Diffusion-based-Learning-for-Decoding-Imagined-Speech-EEG"><a href="#Diff-E-Diffusion-based-Learning-for-Decoding-Imagined-Speech-EEG" class="headerlink" title="Diff-E: Diffusion-based Learning for Decoding Imagined Speech EEG"></a>Diff-E: Diffusion-based Learning for Decoding Imagined Speech EEG</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14389">http://arxiv.org/abs/2307.14389</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yorgoon/diffe">https://github.com/yorgoon/diffe</a></li>
<li>paper_authors: Soowon Kim, Young-Eun Lee, Seo-Hyun Lee, Seong-Whan Lee</li>
<li>for: 用于干预神经网络中的意义语言传输</li>
<li>methods: 使用泛化抽象模型（DDPM）和条件自适应网络（Diff-E）来解决EEG信号的干扰问题</li>
<li>results: 比传统机器学习技术和基线模型有更高的准确率，表明DDPM可以有效地处理EEG信号，有potential应用于through imagined speech的脑机器交互。I hope that helps! Let me know if you have any further questions or if there’s anything else I can help with.<details>
<summary>Abstract</summary>
Decoding EEG signals for imagined speech is a challenging task due to the high-dimensional nature of the data and low signal-to-noise ratio. In recent years, denoising diffusion probabilistic models (DDPMs) have emerged as promising approaches for representation learning in various domains. Our study proposes a novel method for decoding EEG signals for imagined speech using DDPMs and a conditional autoencoder named Diff-E. Results indicate that Diff-E significantly improves the accuracy of decoding EEG signals for imagined speech compared to traditional machine learning techniques and baseline models. Our findings suggest that DDPMs can be an effective tool for EEG signal decoding, with potential implications for the development of brain-computer interfaces that enable communication through imagined speech.
</details>
<details>
<summary>摘要</summary>
“对于想像语音的EEG信号解oding是一个具有高维度和低信号对频率的挑战。近年来，散射扩散概率模型（DDPMs）在不同领域的表示学习中兴起了重要的位置。我们的研究提出了一种使用DDPMs和 conditional autoencoder（Diff-E）来解码EEG信号的新方法。结果显示，Diff-E可以与传统机器学习技术和基准模型相比，对于想像语音的EEG信号解oding具有明显的改善。我们的发现表明，DDPMs可以是EEG信号解oding的有效工具，具有潜在的应用于通过想像语音的脑computer接口的开发。”Note: Please keep in mind that the translation is done by a machine and may not be perfect. If you have any specific requirements or preferences, please let me know and I'll be happy to help.
</details></li>
</ul>
<hr>
<h2 id="This-is-not-correct-Negation-aware-Evaluation-of-Language-Generation-Systems"><a href="#This-is-not-correct-Negation-aware-Evaluation-of-Language-Generation-Systems" class="headerlink" title="This is not correct! Negation-aware Evaluation of Language Generation Systems"></a>This is not correct! Negation-aware Evaluation of Language Generation Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13989">http://arxiv.org/abs/2307.13989</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dmlls/cannot-dataset">https://github.com/dmlls/cannot-dataset</a></li>
<li>paper_authors: Miriam Anschütz, Diego Miguel Lozano, Georg Groh</li>
<li>for: 这篇论文的目的是提出一种能够识别谓语否定的评价指标 NegBLEURT，以解决现有的语言模型在识别谓语否定时的下降性问题。</li>
<li>methods: 该论文使用了一种基于规则的句子否定工具，并使用该工具生成了CANNOT negation evaluation dataset。然后，该论文使用了一种句子转换器和评价指标的微调版本，以提高其对谓语否定的敏感性。</li>
<li>results: 对现有的评价指标进行评测，该论文的微调版本在对谓语否定句子的评测中表现出色，而不会影响其对其他句子的评测。<details>
<summary>Abstract</summary>
Large language models underestimate the impact of negations on how much they change the meaning of a sentence. Therefore, learned evaluation metrics based on these models are insensitive to negations. In this paper, we propose NegBLEURT, a negation-aware version of the BLEURT evaluation metric. For that, we designed a rule-based sentence negation tool and used it to create the CANNOT negation evaluation dataset. Based on this dataset, we fine-tuned a sentence transformer and an evaluation metric to improve their negation sensitivity. Evaluating these models on existing benchmarks shows that our fine-tuned models outperform existing metrics on the negated sentences by far while preserving their base models' performances on other perturbations.
</details>
<details>
<summary>摘要</summary>
大型语言模型会对句子意思的改变低估，因此学习的评估指标基于这些模型可能不敏感于否定。这篇论文提出了NegBLEURT，一个对否定意识的BLEURT评估指标。我们设计了一个基于规则的句子否定工具，并使用这个工具创建了CANNOT否定评估集。基于这个集合，我们精心调整了句子转换器和评估指标，以提高它们对否定句子的敏感性。在现有的评估准确表上评估这些模型，我们发现我们的精心调整模型在否定句子上大幅提高了表现，而且保持了基本模型在其他损害上的表现。
</details></li>
</ul>
<hr>
<h2 id="Mental-LLM-Leveraging-Large-Language-Models-for-Mental-Health-Prediction-via-Online-Text-Data"><a href="#Mental-LLM-Leveraging-Large-Language-Models-for-Mental-Health-Prediction-via-Online-Text-Data" class="headerlink" title="Mental-LLM: Leveraging Large Language Models for Mental Health Prediction via Online Text Data"></a>Mental-LLM: Leveraging Large Language Models for Mental Health Prediction via Online Text Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14385">http://arxiv.org/abs/2307.14385</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/neuhai/mental-llm">https://github.com/neuhai/mental-llm</a></li>
<li>paper_authors: Xuhai Xu, Bingshen Yao, Yuanzhe Dong, Saadia Gabriel, Hong Yu, James Hendler, Marzyeh Ghassemi, Anind K. Dey, Dakuo Wang<br>for:This paper aims to evaluate the performance of multiple large language models (LLMs) on various mental health prediction tasks using online text data.methods:The authors use zero-shot prompting, few-shot prompting, and instruction fine-tuning to evaluate the performance of LLMs on mental health tasks.results:The results show that instruction fine-tuning can significantly boost the performance of LLMs for all tasks simultaneously, with the best-finetuned models outperforming the best prompt design of GPT-3.5 and GPT-4 by a significant margin. The authors also conduct an exploratory case study on LLMs’ capability on mental health reasoning tasks and highlight the important ethical risks accompanying this line of research.Here’s the summary in Simplified Chinese text:for: 这 paper 的目的是评估多种大语言模型（LLMs）在在线文本数据上进行心理健康预测任务的性能。methods: 作者使用零shot prompting、几shot prompting和指令 fine-tuning 来评估 LLMs 在心理健康任务上的性能。results: 结果显示，指令 fine-tuning 可以在所有任务上同时提高 LLMs 的性能，最好的 fine-tuned 模型可以与 GPT-3.5 和 GPT-4 的最佳提示设计相比，提高10.9%的平衡准确率。作者还进行了一个探索性的案例研究，探讨 LLMs 在心理健康逻辑任务上的可能性。<details>
<summary>Abstract</summary>
Advances in large language models (LLMs) have empowered a variety of applications. However, there is still a significant gap in research when it comes to understanding and enhancing the capabilities of LLMs in the field of mental health. In this work, we present the first comprehensive evaluation of multiple LLMs, including Alpaca, Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4, on various mental health prediction tasks via online text data. We conduct a broad range of experiments, covering zero-shot prompting, few-shot prompting, and instruction fine-tuning. The results indicate a promising yet limited performance of LLMs with zero-shot and few-shot prompt designs for the mental health tasks. More importantly, our experiments show that instruction finetuning can significantly boost the performance of LLMs for all tasks simultaneously. Our best-finetuned models, Mental-Alpaca and Mental-FLAN-T5, outperform the best prompt design of GPT-3.5 (25 and 15 times bigger) by 10.9% on balanced accuracy and the best of GPT-4 (250 and 150 times bigger) by 4.8%. They further perform on par with the state-of-the-art task-specific language model. We also conduct an exploratory case study on LLMs' capability on the mental health reasoning tasks, illustrating the promising capability of certain models such as GPT-4. We summarize our findings into a set of action guidelines for potential methods to enhance LLMs' capability for mental health tasks. Meanwhile, we also emphasize the important limitations before achieving deployability in real-world mental health settings, such as known racial and gender bias. We highlight the important ethical risks accompanying this line of research.
</details>
<details>
<summary>摘要</summary>
大语言模型（LLM）的进步已经授权了许多应用程序。然而，在理解和提高 LLM 在心理健康领域的能力方面仍存在一定的研究差距。在这项工作中，我们首次对多种 LLM 进行了全面的评估，包括 Alpaca、Alpaca-LoRA、FLAN-T5、GPT-3.5 和 GPT-4，在在线文本数据上进行了多种心理健康预测任务的测试。我们进行了广泛的实验，涵盖零容量提示、几容量提示和指令精细调整。结果表明 LLM 在零容量和几容量提示设计下的性能有前提，而且指令精细调整可以显著提高 LLM 的性能。我们的最佳调整模型（Mental-Alpaca和Mental-FLAN-T5）在balanced accuracy方面比 GPT-3.5 的最佳提示设计（25和15倍大）高出10.9%，并比 GPT-4 的最佳提示设计（250和150倍大）高出4.8%。此外，我们的模型还与状态当前的任务特定语言模型在同等水平。我们还进行了一项探索性的案例研究，探讨 LLM 在心理健康逻辑任务上的能力，并证明了某些模型，如 GPT-4，具有潜在的可能性。我们将我们的发现总结为了各种可能的方法来提高 LLM 在心理健康任务中的能力，同时也注意到了现有的种族和性别偏见，以及这种研究的重要道德风险。
</details></li>
</ul>
<hr>
<h2 id="GrammarGPT-Exploring-Open-Source-LLMs-for-Native-Chinese-Grammatical-Error-Correction-with-Supervised-Fine-Tuning"><a href="#GrammarGPT-Exploring-Open-Source-LLMs-for-Native-Chinese-Grammatical-Error-Correction-with-Supervised-Fine-Tuning" class="headerlink" title="GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning"></a>GrammarGPT: Exploring Open-Source LLMs for Native Chinese Grammatical Error Correction with Supervised Fine-Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13923">http://arxiv.org/abs/2307.13923</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/freedomintelligence/grammargpt">https://github.com/freedomintelligence/grammargpt</a></li>
<li>paper_authors: Yaxin Fan, Feng Jiang, Peifeng Li, Haizhou Li</li>
<li>for: 本研究旨在探索开源大语言模型（LLMs）在Native Chinese Grammatical Error Correction（CGEC）中的潜力。</li>
<li>methods: 我们提出了一种使用开源LMMs（如Phoenix）进行 instrucion tuning，并使用 hybrid 数据集（包括 ChatGPT 生成和人工标注）来驱动模型的改进。 我们还提出了一种error-invariant augmentation方法，以增强模型对native Chinese grammatical errors的抗讯息能力。</li>
<li>results: 我们的实验结果显示，GrammarGPT 可以与当前最佳系统相比，显著超越其。尽管模型参数的大小为20倍，但需要的数据量 для instrucion tuning 只需1200倍，这说明开源LMMs在native CGEC 中的潜力。我们的 GrammarGPT 在 NLPCC2023 SharedTask1 中排名第三，证明我们的方法的效果。<details>
<summary>Abstract</summary>
Grammatical error correction aims to correct ungrammatical sentences automatically. Recently, some work has demonstrated the excellent capabilities of closed-source Large Language Models (LLMs, e.g., ChatGPT) in grammatical error correction. However, the potential of open-source LLMs remains unexplored. In this paper, we introduced GrammarGPT, an open-source LLM, to preliminary explore its potential for native Chinese grammatical error correction. The core recipe of GrammarGPT is to leverage the hybrid dataset of ChatGPT-generated and human-annotated. For grammatical errors with clues, we proposed a heuristic method to guide ChatGPT to generate ungrammatical sentences by providing those clues. For grammatical errors without clues, we collected ungrammatical sentences from publicly available websites and manually corrected them. In addition, we employed an error-invariant augmentation method to enhance the ability of the model to correct native Chinese grammatical errors. We ultimately constructed about 1k parallel data and utilized these data to fine-tune open-source LLMs (e.g., Phoenix, released by The Chinese University of Hong Kong, Shenzhen) with instruction tuning. The experimental results show that GrammarGPT outperforms the existing SOTA system significantly. Although model parameters are 20x larger than the SOTA baseline, the required amount of data for instruction tuning is 1200x smaller, illustrating the potential of open-source LLMs on native CGEC. Our GrammarGPT ranks $3^{rd}$ on NLPCC2023 SharedTask1, demonstrating our approach's effectiveness. The code and data are available at \url{https://github.com/FreedomIntelligence/GrammarGPT}.
</details>
<details>
<summary>摘要</summary>
grammatical error correction旨在自动 corrections grammatical errors。最近的一些工作表明了关闭源的大语言模型（LLMs，例如ChatGPT）在grammatical error correction方面的出色表现。然而，开源的LLMs的潜力尚未得到探索。在这篇论文中，我们引入了 GrammarGPT，一个开源的LLM，以预liminary explore its potential for native Chinese grammatical error correction。GrammarGPT的核心方法是利用ChatGPT生成的和人类标注的混合数据集。对于带有提示的 grammatical errors，我们提出了一种规则方法，使ChatGPT生成不 grammatical sentences。对于无提示的 grammatical errors，我们收集了来自公共可用网站的不 grammatical sentences，并手动 corrections。此外，我们采用了一种不变 augmentation方法，以增强模型对native Chinese grammatical errors的 corrected。最后，我们构建了约1k的并行数据，并使用这些数据来精度调整开源LLMs（例如Phoenix，由香港中文大学深圳分校发布）。实验结果表明，GrammarGPT在native CGEC方面significantly outperforms现有的SOTA系统。虽然模型参数的数量为SOTA基线的20倍，但需要的数据量 дляinstruction tuning是1200倍 smaller，强调了开源LLMs的潜力。我们的GrammarGPT在NLPCC2023 SharedTask1中排名第三，证明了我们的方法的有效性。代码和数据可以在https://github.com/FreedomIntelligence/GrammarGPT中获取。
</details></li>
</ul>
<hr>
<h2 id="Trustworthiness-of-Children-Stories-Generated-by-Large-Language-Models"><a href="#Trustworthiness-of-Children-Stories-Generated-by-Large-Language-Models" class="headerlink" title="Trustworthiness of Children Stories Generated by Large Language Models"></a>Trustworthiness of Children Stories Generated by Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00073">http://arxiv.org/abs/2308.00073</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prabin Bhandari, Hannah Marie Brennan</li>
<li>for: 这个研究是为了评估大语言模型（LLMs）在生成儿童故事方面的可靠性，并对其与实际儿童故事进行比较和对比。</li>
<li>methods: 这个研究使用了多种指标评估LLMs生成的儿童故事的可靠性，并与经典和新儿童故事进行比较和对比。</li>
<li>results: 研究发现，LLMs仍然很难生成与实际儿童故事一样高质量和细腻的故事。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have shown a tremendous capacity for generating literary text. However, their effectiveness in generating children's stories has yet to be thoroughly examined. In this study, we evaluate the trustworthiness of children's stories generated by LLMs using various measures, and we compare and contrast our results with both old and new children's stories to better assess their significance. Our findings suggest that LLMs still struggle to generate children's stories at the level of quality and nuance found in actual stories
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经表现出很大的可能性来生成文学作品。然而，它们在生成儿童故事方面的效果还未得到了全面的评估。在这项研究中，我们使用不同的指标来评估 LLM 生成的儿童故事的可靠性，并与旧和新的儿童故事进行比较和对比，以更好地评估它们的意义。我们发现 LLM 仍然在生成儿童故事方面存在质量和细节上的困难。
</details></li>
</ul>
<hr>
<h2 id="ARC-NLP-at-Multimodal-Hate-Speech-Event-Detection-2023-Multimodal-Methods-Boosted-by-Ensemble-Learning-Syntactical-and-Entity-Features"><a href="#ARC-NLP-at-Multimodal-Hate-Speech-Event-Detection-2023-Multimodal-Methods-Boosted-by-Ensemble-Learning-Syntactical-and-Entity-Features" class="headerlink" title="ARC-NLP at Multimodal Hate Speech Event Detection 2023: Multimodal Methods Boosted by Ensemble Learning, Syntactical and Entity Features"></a>ARC-NLP at Multimodal Hate Speech Event Detection 2023: Multimodal Methods Boosted by Ensemble Learning, Syntactical and Entity Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13829">http://arxiv.org/abs/2307.13829</a></li>
<li>repo_url: None</li>
<li>paper_authors: Umitcan Sahin, Izzet Emre Kucukkaya, Oguzhan Ozcelik, Cagri Toraman</li>
<li>for: 本研究旨在提出一种基于多模态深度学习和语法文本特征的 hate speech 检测方法，以及基于命名实体特征的目标检测方法，以满足 Multimodal Hate Speech Event Detection 2023 的两个子任务。</li>
<li>methods: 本研究使用了多模态深度学习模型，并通过ensemble学习和语法文本特征进行增强。在第一个子任务中，我们使用了这些模型来检测 hate speech。在第二个子任务中，我们使用了命名实体特征来进行目标检测。</li>
<li>results: 我们的模型在两个子任务中表现出色，比基于全文本、视觉和文本视觉的基线模型都有更高的性能。此外，我们的模型在两个子任务的最终排名中名列第一。<details>
<summary>Abstract</summary>
Text-embedded images can serve as a means of spreading hate speech, propaganda, and extremist beliefs. Throughout the Russia-Ukraine war, both opposing factions heavily relied on text-embedded images as a vehicle for spreading propaganda and hate speech. Ensuring the effective detection of hate speech and propaganda is of utmost importance to mitigate the negative effect of hate speech dissemination. In this paper, we outline our methodologies for two subtasks of Multimodal Hate Speech Event Detection 2023. For the first subtask, hate speech detection, we utilize multimodal deep learning models boosted by ensemble learning and syntactical text attributes. For the second subtask, target detection, we employ multimodal deep learning models boosted by named entity features. Through experimentation, we demonstrate the superior performance of our models compared to all textual, visual, and text-visual baselines employed in multimodal hate speech detection. Furthermore, our models achieve the first place in both subtasks on the final leaderboard of the shared task.
</details>
<details>
<summary>摘要</summary>
文本嵌入图像可以作为散布仇恨言论、宣传和极端思想的途径。在俄乌战争期间，两方都重视使用文本嵌入图像来散布宣传和仇恨言论。确保恐怖言论检测的有效性非常重要，以避免恐怖言论的散布。在这篇论文中，我们介绍了我们的方法ologies，用于两个子任务：仇恨言论检测和目标检测。在首个子任务中，我们使用多Modal深度学习模型，并通过ensemble学习和 syntax文本特征来提高检测性能。在第二个子任务中，我们使用多Modal深度学习模型，并通过名称实体特征来提高检测性能。通过实验，我们证明了我们的模型在文本-视觉恐怖言论检测中的超越性。此外，我们的模型在最终领导板的两个子任务中获得了第一名。
</details></li>
</ul>
<hr>
<h2 id="Watermarking-Conditional-Text-Generation-for-AI-Detection-Unveiling-Challenges-and-a-Semantic-Aware-Watermark-Remedy"><a href="#Watermarking-Conditional-Text-Generation-for-AI-Detection-Unveiling-Challenges-and-a-Semantic-Aware-Watermark-Remedy" class="headerlink" title="Watermarking Conditional Text Generation for AI Detection: Unveiling Challenges and a Semantic-Aware Watermark Remedy"></a>Watermarking Conditional Text Generation for AI Detection: Unveiling Challenges and a Semantic-Aware Watermark Remedy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13808">http://arxiv.org/abs/2307.13808</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Fu, Deyi Xiong, Yue Dong</li>
<li>for: 降低人工智能检测中的风险，研究人员提出了在机器生成文本中添加水印的方法，通过随机词汇限制来实现。</li>
<li>methods: 该方法通过随机限制词汇，对机器生成文本中的水印进行植入，以便在检测中使用。</li>
<li>results: 我们的实验结果表明，我们提议的Semantic-aware watermarking算法可以在文本生成任务中提供显著改进，包括摘要和数据转文本生成，而且保持检测能力。<details>
<summary>Abstract</summary>
To mitigate potential risks associated with language models, recent AI detection research proposes incorporating watermarks into machine-generated text through random vocabulary restrictions and utilizing this information for detection. While these watermarks only induce a slight deterioration in perplexity, our empirical investigation reveals a significant detriment to the performance of conditional text generation. To address this issue, we introduce a simple yet effective semantic-aware watermarking algorithm that considers the characteristics of conditional text generation and the input context. Experimental results demonstrate that our proposed method yields substantial improvements across various text generation models, including BART and Flan-T5, in tasks such as summarization and data-to-text generation while maintaining detection ability.
</details>
<details>
<summary>摘要</summary>
为了减轻语言模型中存在的风险，当前的AI探测研究提议将水印 incorporated into machine-generated text through random vocabulary restrictions,并利用这些信息进行探测。although these watermarks only cause a slight decrease in perplexity,our empirical investigation reveals a significant negative impact on the performance of conditional text generation.to address this issue,we propose a simple yet effective semantic-aware watermarking algorithm that takes into account the characteristics of conditional text generation and the input context.our experimental results show that our proposed method achieves significant improvements across various text generation models,including BART and Flan-T5,in tasks such as summarization and data-to-text generation while maintaining detection ability.
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Large-Language-Models-for-Radiology-Natural-Language-Processing"><a href="#Evaluating-Large-Language-Models-for-Radiology-Natural-Language-Processing" class="headerlink" title="Evaluating Large Language Models for Radiology Natural Language Processing"></a>Evaluating Large Language Models for Radiology Natural Language Processing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13693">http://arxiv.org/abs/2307.13693</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhaozh10/LLM_CMP">https://github.com/zhaozh10/LLM_CMP</a></li>
<li>paper_authors: Zhengliang Liu, Tianyang Zhong, Yiwei Li, Yutong Zhang, Yi Pan, Zihao Zhao, Peixin Dong, Chao Cao, Yuxiao Liu, Peng Shu, Yaonai Wei, Zihao Wu, Chong Ma, Jiaqi Wang, Sheng Wang, Mengyue Zhou, Zuowei Jiang, Chunlin Li, Jason Holmes, Shaochen Xu, Lu Zhang, Haixing Dai, Kai Zhang, Lin Zhao, Yuanhao Chen, Xu Liu, Peilong Wang, Pingkun Yan, Jun Liu, Bao Ge, Lichao Sun, Dajiang Zhu, Xiang Li, Wei Liu, Xiaoyan Cai, Xintao Hu, Xi Jiang, Shu Zhang, Xin Zhang, Tuo Zhang, Shijie Zhao, Quanzheng Li, Hongtu Zhu, Dinggang Shen, Tianming Liu</li>
<li>for: This study aims to evaluate the performance of 32 large language models (LLMs) in interpreting radiology reports and deriving impressions from radiologic findings.</li>
<li>methods: The study uses a dataset of radiology reports and assesses the LLMs’ ability to extract relevant information and provide accurate impressions.</li>
<li>results: The study provides insights into the strengths and weaknesses of the LLMs in this task, informing their practical applications within the medical domain.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这个研究旨在评估32个大语言模型（LLMs）在阅读医学报告时的表现，特别是从医学成像中提取有用信息并提供准确的印象。</li>
<li>methods: 研究使用医学报告 dataset，评估 LLMs 在这个任务中的能力。</li>
<li>results: 研究提供了 LLMS 在这个任务中的优劣点，为医疗领域的实际应用提供指导。<details>
<summary>Abstract</summary>
The rise of large language models (LLMs) has marked a pivotal shift in the field of natural language processing (NLP). LLMs have revolutionized a multitude of domains, and they have made a significant impact in the medical field. Large language models are now more abundant than ever, and many of these models exhibit bilingual capabilities, proficient in both English and Chinese. However, a comprehensive evaluation of these models remains to be conducted. This lack of assessment is especially apparent within the context of radiology NLP. This study seeks to bridge this gap by critically evaluating thirty two LLMs in interpreting radiology reports, a crucial component of radiology NLP. Specifically, the ability to derive impressions from radiologic findings is assessed. The outcomes of this evaluation provide key insights into the performance, strengths, and weaknesses of these LLMs, informing their practical applications within the medical domain.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLMs）的出现标志着自然语言处理（NLP）领域的重要转折。LLMs在多个领域中取得了巨大的成就，并在医疗领域中发挥了重要作用。现在有很多大型语言模型，许多这些模型在英语和中文之间具有双语能力。然而，这些模型的全面评估仍然缺失。特别是在验图学NP中，这种缺失更为突出。本研究的目的是评估三二个LLMs在解读验图报告方面的能力，这是验图学NP中关键的一环。specifically，这些LLMs在解读验图结果中提取印象的能力被评估。研究结果提供关键的洞察和指导，用于评估这些LLMs在医疗领域的实际应用。
</details></li>
</ul>
<hr>
<h2 id="ARB-Advanced-Reasoning-Benchmark-for-Large-Language-Models"><a href="#ARB-Advanced-Reasoning-Benchmark-for-Large-Language-Models" class="headerlink" title="ARB: Advanced Reasoning Benchmark for Large Language Models"></a>ARB: Advanced Reasoning Benchmark for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13692">http://arxiv.org/abs/2307.13692</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tomohiro Sawada, Daniel Paleka, Alexander Havrilla, Pranav Tadepalli, Paula Vidas, Alexander Kranias, John J. Nay, Kshitij Gupta, Aran Komatsuzaki</li>
<li>for: 本研究旨在提供一个更加挑战性的语言模型评估 benchmark，以测试当今的语言模型在多个领域的高级推理能力。</li>
<li>methods: 本研究使用了一个新的 benchmark，名为 ARB，该 benchmark 包括了多个领域的高级推理问题，如数学、物理、生物、化学和法律。</li>
<li>results: 研究发现，当前的语言模型在更加挑战性的任务上的表现仍然落后于人类专家，而且只有在数学和物理领域的符号推理和领域知识方面表现较好。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have demonstrated remarkable performance on various quantitative reasoning and knowledge benchmarks. However, many of these benchmarks are losing utility as LLMs get increasingly high scores, despite not yet reaching expert performance in these domains. We introduce ARB, a novel benchmark composed of advanced reasoning problems in multiple fields. ARB presents a more challenging test than prior benchmarks, featuring problems in mathematics, physics, biology, chemistry, and law. As a subset of ARB, we introduce a challenging set of math and physics problems which require advanced symbolic reasoning and domain knowledge. We evaluate recent models such as GPT-4 and Claude on ARB and demonstrate that current models score well below 50% on more demanding tasks. In order to improve both automatic and assisted evaluation capabilities, we introduce a rubric-based evaluation approach, allowing GPT-4 to score its own intermediate reasoning steps. Further, we conduct a human evaluation of the symbolic subset of ARB, finding promising agreement between annotators and GPT-4 rubric evaluation scores.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在多种量化逻辑和知识准则上表现出了很好的表现。然而，许多这些准则已经失去了用于测试LLM的价值，即使LLM的分数还没有达到专业水平。我们介绍了ARB，一个新的准则，包括多个领域的高级逻辑问题。ARB比之前的准则更加具有挑战性，包括数学、物理、生物、化学和法律等领域的问题。我们从ARB中选择了一个挑战性较高的数学和物理问题集，需要高级 симвоlic 逻辑和领域知识。我们使用GPT-4和Claude等现代模型进行评估，并证明了这些模型在更加具有挑战性的任务上的分数尚未达到50%。为了改善自动和协助评估能力，我们引入了一种基于笔记的评估方法，允许GPT-4评估自己的中间逻辑步骤。此外，我们进行了人类评估符号 subset of ARB，发现与GPT-4笔记评估分数有良好的一致性。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Evaluation-and-Analysis-Study-for-Chinese-Spelling-Check"><a href="#A-Comprehensive-Evaluation-and-Analysis-Study-for-Chinese-Spelling-Check" class="headerlink" title="A Comprehensive Evaluation and Analysis Study for Chinese Spelling Check"></a>A Comprehensive Evaluation and Analysis Study for Chinese Spelling Check</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13655">http://arxiv.org/abs/2307.13655</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xunjian Yin, Xiaojun Wan</li>
<li>for: 本研究旨在探讨基于预训练模型和音频GRU的中文拼写检查（CSC）模型在不同目的下的表现。</li>
<li>methods: 本研究使用九种不同结构的模型，并在自定义的测试集上进行了详细的实验和分析。</li>
<li>results: 本研究发现：1）合理地 fusion 音频GRU和文本信息可以提高CSC模型的性能。2）模型对测试集的错误分布有敏感性，表明模型存在缺陷，并且透露我们需要努力改进。3）模型对错误和上下文的影响很大，这也是我们需要关注的方向。4）常用的标准准则SIGHAN无法可靠地评估模型的表现。<details>
<summary>Abstract</summary>
With the development of pre-trained models and the incorporation of phonetic and graphic information, neural models have achieved high scores in Chinese Spelling Check (CSC). However, it does not provide a comprehensive reflection of the models' capability due to the limited test sets. In this study, we abstract the representative model paradigm, implement it with nine structures and experiment them on comprehensive test sets we constructed with different purposes. We perform a detailed analysis of the results and find that: 1) Fusing phonetic and graphic information reasonably is effective for CSC. 2) Models are sensitive to the error distribution of the test set, which reflects the shortcomings of models and reveals the direction we should work on. 3) Whether or not the errors and contexts have been seen has a significant impact on models. 4) The commonly used benchmark, SIGHAN, can not reliably evaluate models' performance.
</details>
<details>
<summary>摘要</summary>
随着预训模型的发展和音频和字形信息的包含，神经网络模型在中文拼写检查（CSC）中获得了高分。但是，这并不提供全面的模型能力反映，因为测试集的数量有限。在这种研究中，我们抽象了代表性模型思想，将其实现为九种结构，并在我们自己制作的全面测试集上进行了实验。我们进行了详细的分析结果，发现：1. 合理地汇合音频和字形信息是有效的 для CSC。2. 模型对测试集的错误分布具有敏感性，这反映了模型的缺点和我们应该努力改进的方向。3. 模型是否已经看到过错误和上下文有重要的影响。4. 常用的标准准则SIGHAN无法可靠地评估模型的性能。
</details></li>
</ul>
<hr>
<h2 id="Contributions-to-the-Improvement-of-Question-Answering-Systems-in-the-Biomedical-Domain"><a href="#Contributions-to-the-Improvement-of-Question-Answering-Systems-in-the-Biomedical-Domain" class="headerlink" title="Contributions to the Improvement of Question Answering Systems in the Biomedical Domain"></a>Contributions to the Improvement of Question Answering Systems in the Biomedical Domain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13631">http://arxiv.org/abs/2307.13631</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mourad Sarrouti</li>
<li>for: 这份论文主要目标是提高生物医学领域内的问答系统（Question Answering，简称QA）的性能。</li>
<li>methods: 本论文提出了四个贡献，包括一种基于机器学习的问题类划分方法，一种用于各种生物医学问题的问题分类方法，一种用于从MEDLINE数据库中检索相关文献的方法，以及一种用于生成准确和理想答案的方法。</li>
<li>results: 本论文的实验结果表明，使用提出的方法可以提高生物医学QA系统的性能，并且可以生成准确和理想的答案。<details>
<summary>Abstract</summary>
This thesis work falls within the framework of question answering (QA) in the biomedical domain where several specific challenges are addressed, such as specialized lexicons and terminologies, the types of treated questions, and the characteristics of targeted documents. We are particularly interested in studying and improving methods that aim at finding accurate and short answers to biomedical natural language questions from a large scale of biomedical textual documents in English. QA aims at providing inquirers with direct, short and precise answers to their natural language questions. In this Ph.D. thesis, we propose four contributions to improve the performance of QA in the biomedical domain. In our first contribution, we propose a machine learning-based method for question type classification to determine the types of given questions which enable to a biomedical QA system to use the appropriate answer extraction method. We also propose an another machine learning-based method to assign one or more topics (e.g., pharmacological, test, treatment, etc.) to given questions in order to determine the semantic types of the expected answers which are very useful in generating specific answer retrieval strategies. In the second contribution, we first propose a document retrieval method to retrieve a set of relevant documents that are likely to contain the answers to biomedical questions from the MEDLINE database. We then present a passage retrieval method to retrieve a set of relevant passages to questions. In the third contribution, we propose specific answer extraction methods to generate both exact and ideal answers. Finally, in the fourth contribution, we develop a fully automated semantic biomedical QA system called SemBioNLQA which is able to deal with a variety of natural language questions and to generate appropriate answers by providing both exact and ideal answers.
</details>
<details>
<summary>摘要</summary>
Our four contributions to improving QA performance in the biomedical domain are:1. A machine learning-based method for question type classification to determine the types of given questions and enable the use of appropriate answer extraction methods.2. A machine learning-based method to assign one or more topics (e.g., pharmacological, test, treatment, etc.) to given questions to determine the semantic types of expected answers.3. A document retrieval method to retrieve relevant documents from the MEDLINE database, followed by a passage retrieval method to retrieve relevant passages to questions.4. Specific answer extraction methods to generate both exact and ideal answers.Our proposed system, SemBioNLQA, is designed to deal with a variety of natural language questions and generate appropriate answers by providing both exact and ideal answers.
</details></li>
</ul>
<hr>
<h2 id="Diversity-and-Language-Technology-How-Techno-Linguistic-Bias-Can-Cause-Epistemic-Injustice"><a href="#Diversity-and-Language-Technology-How-Techno-Linguistic-Bias-Can-Cause-Epistemic-Injustice" class="headerlink" title="Diversity and Language Technology: How Techno-Linguistic Bias Can Cause Epistemic Injustice"></a>Diversity and Language Technology: How Techno-Linguistic Bias Can Cause Epistemic Injustice</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13714">http://arxiv.org/abs/2307.13714</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paula Helm, Gábor Bella, Gertraud Koch, Fausto Giunchiglia</li>
<li>for: This paper aims to address the issue of techno-linguistic bias in AI-based language technology, which can result in systems that only express concepts from dominant languages and cultures, rather than accurately representing concepts from marginalized language communities.</li>
<li>methods: The paper uses the concept of epistemic injustice to explore the systematic tendency of technology developer communities to apply a simplistic understanding of diversity, leading to a disregard for valuable aspects of diversity and an under-representation of the needs and diverse worldviews of marginalized language communities.</li>
<li>results: The paper shows that many attempts to extend the reach of AI technology to “underserved languages” produce flawed solutions that adhere to a hard-wired representational preference for certain languages, resulting in techno-linguistic bias and a lack of accurate representation of concepts from marginalized language communities.<details>
<summary>Abstract</summary>
It is well known that AI-based language technology -- large language models, machine translation systems, multilingual dictionaries, and corpora -- is currently limited to 2 to 3 percent of the world's most widely spoken and/or financially and politically best supported languages. In response, recent research efforts have sought to extend the reach of AI technology to ``underserved languages.'' In this paper, we show that many of these attempts produce flawed solutions that adhere to a hard-wired representational preference for certain languages, which we call techno-linguistic bias. Techno-linguistic bias is distinct from the well-established phenomenon of linguistic bias as it does not concern the languages represented but rather the design of the technologies. As we show through the paper, techno-linguistic bias can result in systems that can only express concepts that are part of the language and culture of dominant powers, unable to correctly represent concepts from other communities. We argue that at the root of this problem lies a systematic tendency of technology developer communities to apply a simplistic understanding of diversity which does not do justice to the more profound differences that languages, and ultimately the communities that speak them, embody. Drawing on the concept of epistemic injustice, we point to the broader sociopolitical consequences of the bias we identify and show how it can lead not only to a disregard for valuable aspects of diversity but also to an under-representation of the needs and diverse worldviews of marginalized language communities.
</details>
<details>
<summary>摘要</summary>
现在的人工智能语言技术 -- 大语模型、机器翻译系统、多语言词典和语料库 -- 只能涵盖2-3%的世界上最广泛使用和/或经济和政治上最具影响力的语言。因此，latest research efforts have sought to extend the reach of AI technology to "underserved languages." However, we show that many of these attempts produce flawed solutions that adhere to a hard-wired representational preference for certain languages, which we call "techno-linguistic bias." This bias is distinct from the well-established phenomenon of linguistic bias, as it does not concern the languages represented but rather the design of the technologies. We argue that the root of this problem lies in a systematic tendency of technology developer communities to apply a simplistic understanding of diversity, which does not do justice to the more profound differences that languages and ultimately the communities that speak them, embody. Drawing on the concept of epistemic injustice, we point to the broader sociopolitical consequences of the bias we identify and show how it can lead not only to a disregard for valuable aspects of diversity but also to an under-representation of the needs and diverse worldviews of marginalized language communities.Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China and Singapore. Traditional Chinese is also widely used, particularly in Taiwan, Hong Kong, and Macau.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/26/cs.CL_2023_07_26/" data-id="clpxp03w30098fm88hxj48nhb" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_07_26" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/26/cs.LG_2023_07_26/" class="article-date">
  <time datetime="2023-07-26T10:00:00.000Z" itemprop="datePublished">2023-07-26</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/26/cs.LG_2023_07_26/">cs.LG - 2023-07-26</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Fluorescent-Neuronal-Cells-v2-Multi-Task-Multi-Format-Annotations-for-Deep-Learning-in-Microscopy"><a href="#Fluorescent-Neuronal-Cells-v2-Multi-Task-Multi-Format-Annotations-for-Deep-Learning-in-Microscopy" class="headerlink" title="Fluorescent Neuronal Cells v2: Multi-Task, Multi-Format Annotations for Deep Learning in Microscopy"></a>Fluorescent Neuronal Cells v2: Multi-Task, Multi-Format Annotations for Deep Learning in Microscopy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14243">http://arxiv.org/abs/2307.14243</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luca Clissa, Antonio Macaluso, Roberto Morelli, Alessandra Occhinegro, Emiliana Piscitiello, Ludovico Taddei, Marco Luppi, Roberto Amici, Matteo Cerri, Timna Hitrec, Lorenzo Rinaldi, Antonio Zoccoli</li>
<li>for:  fluorescence microscopy image analysis and deep learning research in life sciences</li>
<li>methods: diverse markers for rodent neuronal cells’ nuclei and cytoplasm, ground-truth annotations for semantic segmentation, object detection, and counting</li>
<li>results: facilitating methodological advancements in computer vision approaches and catalyzing breakthroughs in fluorescence microscopy analysis for life sciences research.Here’s the Chinese version:</li>
<li>for: 生物科学中的染色体微scopic image分析和深度学习研究</li>
<li>methods: 使用多种标记突出rodent neuronal cells的核和细胞体特征</li>
<li>results: 促进计算机视觉方法的进步和推动生物科学研究中的突破性发现<details>
<summary>Abstract</summary>
Fluorescent Neuronal Cells v2 is a collection of fluorescence microscopy images and the corresponding ground-truth annotations, designed to foster innovative research in the domains of Life Sciences and Deep Learning. This dataset encompasses three image collections in which rodent neuronal cells' nuclei and cytoplasm are stained with diverse markers to highlight their anatomical or functional characteristics. Alongside the images, we provide ground-truth annotations for several learning tasks, including semantic segmentation, object detection, and counting. The contribution is two-fold. First, given the variety of annotations and their accessible formats, we envision our work facilitating methodological advancements in computer vision approaches for segmentation, detection, feature learning, unsupervised and self-supervised learning, transfer learning, and related areas. Second, by enabling extensive exploration and benchmarking, we hope Fluorescent Neuronal Cells v2 will catalyze breakthroughs in fluorescence microscopy analysis and promote cutting-edge discoveries in life sciences. The data are available at: https://amsacta.unibo.it/id/eprint/7347
</details>
<details>
<summary>摘要</summary>
fluorescent neuronal cells v2是一个包含 fluorescence microscopy 图像和相应的真实标注的集合，旨在推动生命科学和深度学习领域的创新研究。这个数据集包括三个图像集，其中 rodent neuronal cells的核和质物被用 diverse markers 染料来标示其 анатомиче或功能特征。同时，我们提供了真实标注数据 для多种学习任务，包括semantic segmentation，对象检测和计数。我们的贡献是twofold。首先，由于数据集的多样性和可访问的格式，我们期望我们的工作可以推动计算机视觉领域中的方法创新，包括 segmentation，检测，特征学习，无监督和自监督学习，转移学习，等等。其次，通过允许广泛探索和比较，我们希望 fluorescent neuronal cells v2 可以促进 fluorescence microscopy 分析的进步，并促进生命科学的前沿研究。数据可以在：https://amsacta.unibo.it/id/eprint/7347 获取。
</details></li>
</ul>
<hr>
<h2 id="Evolving-Multi-Objective-Neural-Network-Controllers-for-Robot-Swarms"><a href="#Evolving-Multi-Objective-Neural-Network-Controllers-for-Robot-Swarms" class="headerlink" title="Evolving Multi-Objective Neural Network Controllers for Robot Swarms"></a>Evolving Multi-Objective Neural Network Controllers for Robot Swarms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14237">http://arxiv.org/abs/2307.14237</a></li>
<li>repo_url: None</li>
<li>paper_authors: Karl Mason, Sabine Hauert</li>
<li>for: 这个研究是为了开发多目标控制器 для 群体机器人。</li>
<li>methods: 这个研究使用进化神经网络方法来训练群体机器人控制器，并在低精度Python实现和高精度Webots实现中进行训练和测试。</li>
<li>results: 研究结果显示，提案的方法可以有效地控制每个机器人，并且可以随着目标权重的调整，让机器人群展示不同的行为。同时，研究还证实了训练在低精度实现中的多目标神经网络控制器可以转移到高精度实现中，并且不需要进一步 retrained。<details>
<summary>Abstract</summary>
Many swarm robotics tasks consist of multiple conflicting objectives. This research proposes a multi-objective evolutionary neural network approach to developing controllers for swarms of robots. The swarm robot controllers are trained in a low-fidelity Python simulator and then tested in a high-fidelity simulated environment using Webots. Simulations are then conducted to test the scalability of the evolved multi-objective robot controllers to environments with a larger number of robots. The results presented demonstrate that the proposed approach can effectively control each of the robots. The robot swarm exhibits different behaviours as the weighting for each objective is adjusted. The results also confirm that multi-objective neural network controllers evolved in a low-fidelity simulator can be transferred to high-fidelity simulated environments and that the controllers can scale to environments with a larger number of robots without further retraining needed.
</details>
<details>
<summary>摘要</summary>
许多群体机器人任务具有多个冲突目标。本研究提出了一种多目标演化神经网络方法来开发群体机器人控制器。群体机器人控制器在低精度Python模拟器中进行训练，然后在使用Webots的高精度模拟环境进行测试。在 simulate the scalability of the evolved multi-objective robot controllers to environments with a larger number of robots。结果显示，提出的方法可以有效地控制每个机器人。机器人群体展示不同的行为，按照目标权重的调整。结果还证明了在低精度模拟器中进行多目标神经网络控制器的演化可以在高精度模拟环境中转移，而且控制器可以在更多的机器人环境中进行扩展，无需进行进一步的 retrained。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-are-Competitive-Near-Cold-start-Recommenders-for-Language-and-Item-based-Preferences"><a href="#Large-Language-Models-are-Competitive-Near-Cold-start-Recommenders-for-Language-and-Item-based-Preferences" class="headerlink" title="Large Language Models are Competitive Near Cold-start Recommenders for Language- and Item-based Preferences"></a>Large Language Models are Competitive Near Cold-start Recommenders for Language- and Item-based Preferences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14225">http://arxiv.org/abs/2307.14225</a></li>
<li>repo_url: None</li>
<li>paper_authors: Scott Sanner, Krisztian Balog, Filip Radlinski, Ben Wedin, Lucas Dixon</li>
<li>for: 这个论文主要针对的是如何使用语言基于的偏好表达来进行推荐。</li>
<li>methods: 这篇论文使用了大型自然语言模型（LLM）的提示方法来进行推荐。</li>
<li>results: 研究发现，使用LLM的提示方法可以在没有特定任务的情况下（即冷启动）提供竞争力强的推荐性能，并且这种方法的偏好表达比Item-based CF方法更加可解释和透明。<details>
<summary>Abstract</summary>
Traditional recommender systems leverage users' item preference history to recommend novel content that users may like. However, modern dialog interfaces that allow users to express language-based preferences offer a fundamentally different modality for preference input. Inspired by recent successes of prompting paradigms for large language models (LLMs), we study their use for making recommendations from both item-based and language-based preferences in comparison to state-of-the-art item-based collaborative filtering (CF) methods. To support this investigation, we collect a new dataset consisting of both item-based and language-based preferences elicited from users along with their ratings on a variety of (biased) recommended items and (unbiased) random items. Among numerous experimental results, we find that LLMs provide competitive recommendation performance for pure language-based preferences (no item preferences) in the near cold-start case in comparison to item-based CF methods, despite having no supervised training for this specific task (zero-shot) or only a few labels (few-shot). This is particularly promising as language-based preference representations are more explainable and scrutable than item-based or vector-based representations.
</details>
<details>
<summary>摘要</summary>
传统推荐系统利用用户ITEM的喜好历史来推荐新的内容，但现代对话界面允许用户通过语言基于的喜好输入来提供一种全然不同的可能性。受最近大语言模型（LLM）的成功启发，我们研究其在基于ITEM和语言基于的喜好input中进行推荐的可能性，并与当前状态艺术CF方法进行比较。为支持这些研究，我们收集了一个新的数据集，该数据集包含了基于ITEM和语言基于的喜好输入，以及用户对各种（偏见）推荐ITEM和（无偏见）随机ITEM的评分。在许多实验结果中，我们发现了LLM在冷启动情况下，对于纯language基于的喜好（没有ITEM喜好）的推荐性能和ITEM基CF方法相当，即使没有特定任务的直接supervised训练（零shot）或只有几个标签（几shot）。这对于语言基于的喜好表示是更加可解释和易于理解，因为ITEM基CF方法的表示是基于VECTOR的。注意：这里使用的 Simplified Chinese 是指简化字符串的 Simplified Chinese，而不是指特定的字符串。
</details></li>
</ul>
<hr>
<h2 id="Online-Modeling-and-Monitoring-of-Dependent-Processes-under-Resource-Constraints"><a href="#Online-Modeling-and-Monitoring-of-Dependent-Processes-under-Resource-Constraints" class="headerlink" title="Online Modeling and Monitoring of Dependent Processes under Resource Constraints"></a>Online Modeling and Monitoring of Dependent Processes under Resource Constraints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14208">http://arxiv.org/abs/2307.14208</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tanapol Kosolwattana, Huazheng Wang, Ying Lin</li>
<li>for: 监测受限资源的依赖过程集中有 kritical importance for abnormal event detection.</li>
<li>methods: 提出了一种online collaborative learning方法，可以动态分配资源以优先级进行高风险进程的利用和依赖动力学的探索。</li>
<li>results: 理论分析和实验证明了方法的效率。<details>
<summary>Abstract</summary>
Monitoring a population of dependent processes under limited resources is critical for abnormal events detection. A novel online collaborative learning method is proposed to adaptively allocate the resources for exploitation of high-risk processes and exploration of dependent dynamics. Efficiency of the proposed method is proved through theoretical analysis and experiments.
</details>
<details>
<summary>摘要</summary>
监测依赖过程的人口在有限资源下是检测异常事件的关键。提出了一种新的在线合作学习方法，以适应尽可能地分配资源，以便利用高风险过程的探索和依赖动态的探索。我们通过理论分析和实验证明了该方法的效率。
</details></li>
</ul>
<hr>
<h2 id="Application-of-Random-Forest-and-Support-Vector-Machine-for-Investigation-of-Pressure-Filtration-Performance-a-Zinc-Plant-Filter-Cake-Modeling"><a href="#Application-of-Random-Forest-and-Support-Vector-Machine-for-Investigation-of-Pressure-Filtration-Performance-a-Zinc-Plant-Filter-Cake-Modeling" class="headerlink" title="Application of Random Forest and Support Vector Machine for Investigation of Pressure Filtration Performance, a Zinc Plant Filter Cake Modeling"></a>Application of Random Forest and Support Vector Machine for Investigation of Pressure Filtration Performance, a Zinc Plant Filter Cake Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14199">http://arxiv.org/abs/2307.14199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Masoume Kazemi, Davood Moradkhani, Alireza Abbas Alipour</li>
<li>for: 这项研究目的是研究压滤过程中硫铁残留物的影响，并通过Random Forest和Support Vector Machine模型来预测硫铁残留物的含水率。</li>
<li>methods: 本研究使用了Random Forest Regression和Support Vector Regression模型，这些模型以实验室样本中的连续变量（提取特征）为输入。</li>
<li>results: 研究发现，Random Forest Regression模型在预测硫铁残留物含水率方面比Support Vector Regression模型更为精确。<details>
<summary>Abstract</summary>
The hydrometallurgical method of zinc production involves leaching zinc from ore and then separating the solid residue from the liquid solution by pressure filtration. This separation process is very important since the solid residue contains some moisture that can reduce the amount of zinc recovered. This study modeled the pressure filtration process through Random Forest (RF) and Support Vector Machine (SVM). The models take continuous variables (extracted features) from the lab samples as inputs. Thus, regression models namely Random Forest Regression (RFR) and Support Vector Regression (SVR) were chosen. A total dataset was obtained during the pressure filtration process in two conditions: 1) Polypropylene (S1) and 2) Polyester fabrics (S2). To predict the cake moisture, solids concentration (0.2 and 0.38), temperature (35 and 65 centigrade), pH (2, 3.5, and 5), pressure, cake thickness (14, 20, 26, and 34 mm), air-blow time (2, 10 and 15 min) and filtration time were applied as input variables. The models' predictive accuracy was evaluated by the coefficient of determination (R2) parameter. The results revealed that the RFR model is superior to the SVR model for cake moisture prediction.
</details>
<details>
<summary>摘要</summary>
《锌生产水化металлурги法》中的压 филь特过程是非常重要的，因为压 filtering process中的固体剩下物含有一定的湿度，这可能会降低锌的回收率。本研究通过Random Forest（RF）和Support Vector Machine（SVM）模型来模拟压 filtering process。这两种模型都是回归模型，它们使用实验室样本中的连续变量（提取特征）作为输入。因此，我们选择了Random Forest Regression（RFR）和Support Vector Regression（SVR）模型来预测压 filtering process中固体剩下物的湿度。我们获得了压 filtering process在两种条件下的总数据集：1）Polypropylene（S1）和2）Polyester fabrics（S2）。为了预测固体剩下物的湿度，我们选择了以下输入变量：压 filtering time（2, 10和15 min），温度（35和65 centigrade），pH（2, 3.5和5），压力，压 filtering cake thickness（14, 20, 26和34 mm），空气吹气时间（2, 10和15 min）。我们使用R2参数来评估模型预测的准确性。结果表明，RFR模型在预测固体剩下物的湿度方面比SVR模型更为有力。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Learning-of-Discrete-Continuous-Computation-Graphs"><a href="#Efficient-Learning-of-Discrete-Continuous-Computation-Graphs" class="headerlink" title="Efficient Learning of Discrete-Continuous Computation Graphs"></a>Efficient Learning of Discrete-Continuous Computation Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14193">http://arxiv.org/abs/2307.14193</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nec-research/dccg">https://github.com/nec-research/dccg</a></li>
<li>paper_authors: David Friede, Mathias Niepert</li>
<li>for: 本研究旨在提出新的方法来训练混合抽象和连续模型，以便更好地处理复杂的机器学习任务。</li>
<li>methods: 研究人员使用了混合抽象和连续模型，并使用了Stochastic softmax tricks来搅合抽象和连续模型。</li>
<li>results: 研究人员发现，使用新的方法可以训练复杂的混合抽象和连续模型，并且这些模型在一些benchmark datasets上表现更好。<details>
<summary>Abstract</summary>
Numerous models for supervised and reinforcement learning benefit from combinations of discrete and continuous model components. End-to-end learnable discrete-continuous models are compositional, tend to generalize better, and are more interpretable. A popular approach to building discrete-continuous computation graphs is that of integrating discrete probability distributions into neural networks using stochastic softmax tricks. Prior work has mainly focused on computation graphs with a single discrete component on each of the graph's execution paths. We analyze the behavior of more complex stochastic computations graphs with multiple sequential discrete components. We show that it is challenging to optimize the parameters of these models, mainly due to small gradients and local minima. We then propose two new strategies to overcome these challenges. First, we show that increasing the scale parameter of the Gumbel noise perturbations during training improves the learning behavior. Second, we propose dropout residual connections specifically tailored to stochastic, discrete-continuous computation graphs. With an extensive set of experiments, we show that we can train complex discrete-continuous models which one cannot train with standard stochastic softmax tricks. We also show that complex discrete-stochastic models generalize better than their continuous counterparts on several benchmark datasets.
</details>
<details>
<summary>摘要</summary>
很多超级vised和强化学习模型都可以借鉴混合精度和连续模型组件。端到端学习可靠的精度-连续模型是可组合的，通常更容易泛化，而且更易于解释。在建立精度-连续计算图时，一种常见的方法是通过将精度概率分布 integrate到神经网络中使用随机杂化技术。先前的工作主要集中在计算图上有单个精度组件的每个执行路径。我们分析了更复杂的随机计算图中多个顺序精度组件的行为。我们发现这些模型的参数优化很困难，主要是因为小的梯度和地方最小值。我们然后提出了两种新策略来解决这些挑战。首先，我们显示在训练时增加抽象噪声拟合的扩大参数可以改善学习行为。其次，我们提出特殊设计 для某些随机、精度-连续计算图的dropout降阶连接。通过广泛的实验，我们证明可以训练复杂的精度-连续模型，而标准随机杂化技术无法训练这些模型。此外，我们还证明复杂的精度模型在多个benchmark数据集上比其连续counterpart更好地适应和泛化。
</details></li>
</ul>
<hr>
<h2 id="A-comparison-of-machine-learning-surrogate-models-of-street-scale-flooding-in-Norfolk-Virginia"><a href="#A-comparison-of-machine-learning-surrogate-models-of-street-scale-flooding-in-Norfolk-Virginia" class="headerlink" title="A comparison of machine learning surrogate models of street-scale flooding in Norfolk, Virginia"></a>A comparison of machine learning surrogate models of street-scale flooding in Norfolk, Virginia</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14185">http://arxiv.org/abs/2307.14185</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diana McSpadden, Steven Goldenberg, Binata Roy, Malachi Schram, Jonathan L. Goodall, Heather Richter</li>
<li>for: 评估低洼海岸城市（如诺福克，弗吉尼亚）面临的街道洪水问题，这会压力交通和废水系统，并可能导致财产损害。</li>
<li>methods: 使用诺福克降雨事件数据（2016-2018年），比较之前的抽象模型（基于随机森林算法）和两种深度学习模型：长短期记忆（LSTM）和闭合循环单元（GRU）的性能。</li>
<li>results: 研究表明，使用支持预测不确定性的模型架构和有效地结合相关多样特征是关键，以提高预测准确性和稳定性。<details>
<summary>Abstract</summary>
Low-lying coastal cities, exemplified by Norfolk, Virginia, face the challenge of street flooding caused by rainfall and tides, which strain transportation and sewer systems and can lead to property damage. While high-fidelity, physics-based simulations provide accurate predictions of urban pluvial flooding, their computational complexity renders them unsuitable for real-time applications. Using data from Norfolk rainfall events between 2016 and 2018, this study compares the performance of a previous surrogate model based on a random forest algorithm with two deep learning models: Long Short-Term Memory (LSTM) and Gated Recurrent Unit (GRU). This investigation underscores the importance of using a model architecture that supports the communication of prediction uncertainty and the effective integration of relevant, multi-modal features.
</details>
<details>
<summary>摘要</summary>
低洼海岸城市，如尼科尔斯，面临洪水泛滥和潮汐的挑战，这会压力交通和废水系统，并可能导致财产损害。虽然高精度的物理学基模型可以准确预测城市洪水，但它们的计算复杂度使其不适用于实时应用。根据2016-2018年尼科尔斯雨事件的数据，本研究比较了之前的随机森林算法基于模型和两种深度学习模型：长短期记忆（LSTM）和闭包逻辑单元（GRU）的表现。这一研究强调了使用一种支持预测不确定性的模型架构，并有效地 integrate 多种多样的特征。
</details></li>
</ul>
<hr>
<h2 id="Learning-Disentangled-Discrete-Representations"><a href="#Learning-Disentangled-Discrete-Representations" class="headerlink" title="Learning Disentangled Discrete Representations"></a>Learning Disentangled Discrete Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14151">http://arxiv.org/abs/2307.14151</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/david-friede/lddr">https://github.com/david-friede/lddr</a></li>
<li>paper_authors: David Friede, Christian Reimers, Heiner Stuckenschmidt, Mathias Niepert</li>
<li>for: 该论文探讨了精制的离散特征空间如何提高分离表示的质量。</li>
<li>methods: 该论文使用了特定的 categorical variational autoencoder (VAE)，并通过分析和实验证明了离散分布的格子结构可以减轻多变量 Gaussian 分布中的旋转不变性问题，从而为分离表示提供了有效的induction prior。</li>
<li>results: 该论文通过分析和实验表明，离散 VAE 可以更好地学习分离表示，并提出了首个不经过标注的模型选择策略，以便寻找更好的分离表示模型。<details>
<summary>Abstract</summary>
Recent successes in image generation, model-based reinforcement learning, and text-to-image generation have demonstrated the empirical advantages of discrete latent representations, although the reasons behind their benefits remain unclear. We explore the relationship between discrete latent spaces and disentangled representations by replacing the standard Gaussian variational autoencoder (VAE) with a tailored categorical variational autoencoder. We show that the underlying grid structure of categorical distributions mitigates the problem of rotational invariance associated with multivariate Gaussian distributions, acting as an efficient inductive prior for disentangled representations. We provide both analytical and empirical findings that demonstrate the advantages of discrete VAEs for learning disentangled representations. Furthermore, we introduce the first unsupervised model selection strategy that favors disentangled representations.
</details>
<details>
<summary>摘要</summary>
近期的图像生成、模型基 Reinforcement Learning 和文本到图像生成 achievements have shown the empirical advantages of discrete latent representations, but the reasons behind these benefits are not clear. We explore the relationship between discrete latent spaces and disentangled representations by replacing the standard Gaussian variational autoencoder (VAE) with a tailored categorical variational autoencoder. We show that the underlying grid structure of categorical distributions solves the problem of rotational invariance associated with multivariate Gaussian distributions, serving as an efficient inductive prior for disentangled representations. We provide both analytical and empirical findings that demonstrate the advantages of discrete VAEs for learning disentangled representations. Furthermore, we introduce the first unsupervised model selection strategy that favors disentangled representations.
</details></li>
</ul>
<hr>
<h2 id="Toward-Design-of-Synthetic-Active-Inference-Agents-by-Mere-Mortals"><a href="#Toward-Design-of-Synthetic-Active-Inference-Agents-by-Mere-Mortals" class="headerlink" title="Toward Design of Synthetic Active Inference Agents by Mere Mortals"></a>Toward Design of Synthetic Active Inference Agents by Mere Mortals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14145">http://arxiv.org/abs/2307.14145</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bert de Vries</li>
<li>for: 总结有效的活动推理代理在边缘设备上实现</li>
<li>methods: 软件工具箱支持不熟悉的工程师开发工作的活动推理代理</li>
<li>results: 实现了加速活动推理代理在边缘设备上的民主化Here’s the English version for reference:</li>
<li>for: Realizing effective active inference agents on edge devices</li>
<li>methods: A software toolbox supporting non-expert engineers to develop working active inference agents</li>
<li>results: Accelerating the democratization of active inference agents on edge devices<details>
<summary>Abstract</summary>
The theoretical properties of active inference agents are impressive, but how do we realize effective agents in working hardware and software on edge devices? This is an interesting problem because the computational load for policy exploration explodes exponentially, while the computational resources are very limited for edge devices. In this paper, we discuss the necessary features for a software toolbox that supports a competent non-expert engineer to develop working active inference agents. We introduce a toolbox-in-progress that aims to accelerate the democratization of active inference agents in a similar way as TensorFlow propelled applications of deep learning technology.
</details>
<details>
<summary>摘要</summary>
理论上，活动推理代理的性能很吸引人，但实现工作硬件和软件上的有效代理却是一个挑战。这是因为策略探索计算负担会 exponentiates，而边缘设备的计算资源非常有限。在这篇文章中，我们讨论了实现有效的活动推理代理所需的必要特性，以及一个在进行中的工具箱，用于加速活动推理代理的普及。
</details></li>
</ul>
<hr>
<h2 id="Piecewise-Stationary-Combinatorial-Semi-Bandit-with-Causally-Related-Rewards"><a href="#Piecewise-Stationary-Combinatorial-Semi-Bandit-with-Causally-Related-Rewards" class="headerlink" title="Piecewise-Stationary Combinatorial Semi-Bandit with Causally Related Rewards"></a>Piecewise-Stationary Combinatorial Semi-Bandit with Causally Related Rewards</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14138">http://arxiv.org/abs/2307.14138</a></li>
<li>repo_url: None</li>
<li>paper_authors: Behzad Nourani-Koliji, Steven Bilaj, Amir Rezaei Balef, Setareh Maghsudi</li>
<li>for: 解决piecewise站点稳定 combinatorial半带准问题，即在非站点环境下，base arms的分布变化、奖励之间的 causal 关系变化或 Both，导致奖励生成过程发生变化。</li>
<li>methods: 提出了一种基于 Upper Confidence Bound（UCB）算法的优化策略，即采用改变点探测器基于 Generalized Likelihood Ratio（GLR）测试，并引入了一种新的结构化环境中的 group restart 策略。</li>
<li>results:  theoretically, Establish a regret upper bound that reflects the effects of the number of structural- and distribution changes on the performance, and the numerical experiments in real-world scenarios exhibit the applicability and superior performance of the proposed method compared to the state-of-the-art benchmarks.<details>
<summary>Abstract</summary>
We study the piecewise stationary combinatorial semi-bandit problem with causally related rewards. In our nonstationary environment, variations in the base arms' distributions, causal relationships between rewards, or both, change the reward generation process. In such an environment, an optimal decision-maker must follow both sources of change and adapt accordingly. The problem becomes aggravated in the combinatorial semi-bandit setting, where the decision-maker only observes the outcome of the selected bundle of arms. The core of our proposed policy is the Upper Confidence Bound (UCB) algorithm. We assume the agent relies on an adaptive approach to overcome the challenge. More specifically, it employs a change-point detector based on the Generalized Likelihood Ratio (GLR) test. Besides, we introduce the notion of group restart as a new alternative restarting strategy in the decision making process in structured environments. Finally, our algorithm integrates a mechanism to trace the variations of the underlying graph structure, which captures the causal relationships between the rewards in the bandit setting. Theoretically, we establish a regret upper bound that reflects the effects of the number of structural- and distribution changes on the performance. The outcome of our numerical experiments in real-world scenarios exhibits applicability and superior performance of our proposal compared to the state-of-the-art benchmarks.
</details>
<details>
<summary>摘要</summary>
我们研究了分割式站立 combinatorial semi-bandit问题，其中奖励关系存在 causal 关系。在我们的非站点环境中，奖励生成过程中存在变化，包括基础武器的分布变化、奖励之间的 causal 关系变化或者两者都存在变化。在这种环境中，一个优化的决策者需要跟踪这些变化并适应应对。在 combinatorial semi-bandit 设定下，决策者只能观察选择的武器集的结果。我们的提议的策略是使用 Upper Confidence Bound（UCB）算法。我们假设agent使用可适应的方法来解决这个挑战。更具体地说，它使用基于 Generalized Likelihood Ratio（GLR）测试的变化检测器。此外，我们引入了一种新的分组重启策略，即 group restart，以便在结构化环境中决策过程中使用。最后，我们的算法包括一个跟踪变化的基本图结构，这个结构捕捉了奖励之间的 causal 关系。理论上，我们Establish了变量数量和分布变化对性能的 regret Upper bound。实际实验结果表明我们的提议在实际 scenarios 中表现出优于状态艺术的 benchmarcks。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Generative-Modeling-with-Limited-Data-Few-Shots-and-Zero-Shot"><a href="#A-Survey-on-Generative-Modeling-with-Limited-Data-Few-Shots-and-Zero-Shot" class="headerlink" title="A Survey on Generative Modeling with Limited Data, Few Shots, and Zero Shot"></a>A Survey on Generative Modeling with Limited Data, Few Shots, and Zero Shot</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14397">http://arxiv.org/abs/2307.14397</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sutd-visual-computing-group/awesome-generative-modeling-under-data-constraints">https://github.com/sutd-visual-computing-group/awesome-generative-modeling-under-data-constraints</a></li>
<li>paper_authors: Milad Abdollahzadeh, Touba Malekzadeh, Christopher T. H. Teo, Keshigeyan Chandrasegaran, Guimeng Liu, Ngai-Man Cheung</li>
<li>for: 本研究探讨在数据约束下学习生成模型，即Generative Modeling under Data Constraint（GM-DC）。GM-DC在医疗应用中数据采集困难时非常重要。</li>
<li>methods: 本研究提出了两种分类法：一种是GM-DC任务分类法，另一种是GM-DC方法分类法。此外，本研究还研究了不同GM-DC任务和方法之间的交互关系。</li>
<li>results: 本研究提出了一个GM-DC任务和方法分类框架，并进行了对GM-DC任务和方法的研究 gap、研究趋势和未来探索的探讨。<details>
<summary>Abstract</summary>
In machine learning, generative modeling aims to learn to generate new data statistically similar to the training data distribution. In this paper, we survey learning generative models under limited data, few shots and zero shot, referred to as Generative Modeling under Data Constraint (GM-DC). This is an important topic when data acquisition is challenging, e.g. healthcare applications. We discuss background, challenges, and propose two taxonomies: one on GM-DC tasks and another on GM-DC approaches. Importantly, we study interactions between different GM-DC tasks and approaches. Furthermore, we highlight research gaps, research trends, and potential avenues for future exploration. Project website: https://gmdc-survey.github.io.
</details>
<details>
<summary>摘要</summary>
在机器学习中，生成模型学习的目标是学习生成新数据，与训练数据分布相似。在这篇论文中，我们对有限数据、少量shot和零shot生成模型学习（GM-DC）进行了报告。这是在数据收集困难时，如医疗应用场景中非常重要的话题。我们讨论了背景、挑战和两种分类：一种是GM-DC任务分类，另一种是GM-DC方法分类。此外，我们还研究了不同GM-DC任务和方法之间的交互。此外，我们还提出了未来探索的研究漏洞、趋势和潜在的研究方向。项目网站：https://gmdc-survey.github.io。Here's the breakdown of the translation:* 机器学习 (machine learning) becomes 机器学习 (machine learning)* 生成模型 (generative model) becomes 生成模型 (generative model)* 学习 (learn) becomes 学习 (learn)* 新数据 (new data) becomes 新数据 (new data)* 训练数据 (training data) becomes 训练数据 (training data)* GM-DC (Generative Modeling under Data Constraint) becomes GM-DC (生成模型学习下数据约束)* 有限数据 (limited data) becomes 有限数据 (limited data)* 少量shot (few shots) becomes 少量shot (few shots)* 零shot (zero shot) becomes 零shot (zero shot)* 讨论 (discuss) becomes 讨论 (discuss)* 背景 (background) becomes 背景 (background)* 挑战 (challenges) becomes 挑战 (challenges)* 两种分类 (two taxonomies) becomes 两种分类 (two taxonomies)* 任务 (task) becomes 任务 (task)* 方法 (method) becomes 方法 (method)* 交互 (interaction) becomes 交互 (interaction)* 未来探索 (future exploration) becomes 未来探索 (future exploration)* 研究漏洞 (research gaps) becomes 研究漏洞 (research gaps)* 趋势 (trends) becomes 趋势 (trends)* 潜在的研究方向 (potential research directions) becomes 潜在的研究方向 (potential research directions)
</details></li>
</ul>
<hr>
<h2 id="Developing-and-Evaluating-Tiny-to-Medium-Sized-Turkish-BERT-Models"><a href="#Developing-and-Evaluating-Tiny-to-Medium-Sized-Turkish-BERT-Models" class="headerlink" title="Developing and Evaluating Tiny to Medium-Sized Turkish BERT Models"></a>Developing and Evaluating Tiny to Medium-Sized Turkish BERT Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14134">http://arxiv.org/abs/2307.14134</a></li>
<li>repo_url: None</li>
<li>paper_authors: Himmet Toprak Kesgin, Muzaffer Kaan Yuce, Mehmet Fatih Amasyali</li>
<li>for: 这个研究旨在 bridge the research gap in less-resourced languages, 通过开发和评估不同大小的 Turkish BERT 模型。</li>
<li>methods: 研究者使用了多种数据源，包括多种文本类型，并在不同任务上进行了测试，包括偏好预测、情感分类、新闻分类和零shot分类。</li>
<li>results: 研究者发现，即使使用了更小的模型，模型仍然可以达到可靠的性能，包括零shot任务，同时保证计算效率和快速执行时间。<details>
<summary>Abstract</summary>
This study introduces and evaluates tiny, mini, small, and medium-sized uncased Turkish BERT models, aiming to bridge the research gap in less-resourced languages. We trained these models on a diverse dataset encompassing over 75GB of text from multiple sources and tested them on several tasks, including mask prediction, sentiment analysis, news classification, and, zero-shot classification. Despite their smaller size, our models exhibited robust performance, including zero-shot task, while ensuring computational efficiency and faster execution times. Our findings provide valuable insights into the development and application of smaller language models, especially in the context of the Turkish language.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这项研究介绍和评估了不同大小的无框 Turkish BERT 模型，以填补资源更少的语言研究隔阂。我们使用多种数据源，训练这些模型，并在多个任务上进行测试，包括掩码预测、情感分析、新闻分类和零shot分类。尽管这些模型较小，但它们在零shot任务中 still exhibited robust performance，同时保证计算效率和快速执行时间。我们的发现对小语言模型的开发和应用提供了有价值的 Insights，特别是在土耳其语言上。
</details></li>
</ul>
<hr>
<h2 id="GraphRNN-Revisited-An-Ablation-Study-and-Extensions-for-Directed-Acyclic-Graphs"><a href="#GraphRNN-Revisited-An-Ablation-Study-and-Extensions-for-Directed-Acyclic-Graphs" class="headerlink" title="GraphRNN Revisited: An Ablation Study and Extensions for Directed Acyclic Graphs"></a>GraphRNN Revisited: An Ablation Study and Extensions for Directed Acyclic Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14109">http://arxiv.org/abs/2307.14109</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taniya Das, Mark Koch, Maya Ravichandran, Nikhil Khatri</li>
<li>for: 学习图形生成模型</li>
<li>methods: 使用深度学习架构GraphRNN，并对基eline模型进行评估和ablation study</li>
<li>results: 发现BFS traverse对模型性能有重要贡献，并将GraphRNN扩展到生成导向图。Here’s the same information in English:</li>
<li>for: Learning graph generative models</li>
<li>methods: Using the deep learning-based GraphRNN architecture and evaluating against baseline models with an ablation study</li>
<li>results: Find that the BFS traversal suggested by You et al. to collapse representations of isomorphic graphs significantly contributes to model performance, and extend GraphRNN to generate directed acyclic graphs by replacing the BFS traversal with a topological sort, demonstrating improved performance on a real-world dataset.<details>
<summary>Abstract</summary>
GraphRNN is a deep learning-based architecture proposed by You et al. for learning generative models for graphs. We replicate the results of You et al. using a reproduced implementation of the GraphRNN architecture and evaluate this against baseline models using new metrics. Through an ablation study, we find that the BFS traversal suggested by You et al. to collapse representations of isomorphic graphs contributes significantly to model performance. Additionally, we extend GraphRNN to generate directed acyclic graphs by replacing the BFS traversal with a topological sort. We demonstrate that this method improves significantly over a directed-multiclass variant of GraphRNN on a real-world dataset.
</details>
<details>
<summary>摘要</summary>
GRAPHRNN是一种深度学习基于架构，由You等人提出用于学习图生成模型。我们复制了You等人的结果，使用自己实现的GRAPHRNN架构，并对基准模型进行评估。通过一项剥夺研究，我们发现，You等人提出的BFS traverse方法可以很好地减少同构图的表示。此外，我们扩展GRAPHRNN来生成直接的цикли graphs，通过将BFS traverse替换为拓扑排序。我们示出，这种方法在实际数据上明显超过了一种 direkt-多类变体的GRAPHRNN。
</details></li>
</ul>
<hr>
<h2 id="Actions-Speak-What-You-Want-Provably-Sample-Efficient-Reinforcement-Learning-of-the-Quantal-Stackelberg-Equilibrium-from-Strategic-Feedbacks"><a href="#Actions-Speak-What-You-Want-Provably-Sample-Efficient-Reinforcement-Learning-of-the-Quantal-Stackelberg-Equilibrium-from-Strategic-Feedbacks" class="headerlink" title="Actions Speak What You Want: Provably Sample-Efficient Reinforcement Learning of the Quantal Stackelberg Equilibrium from Strategic Feedbacks"></a>Actions Speak What You Want: Provably Sample-Efficient Reinforcement Learning of the Quantal Stackelberg Equilibrium from Strategic Feedbacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14085">http://arxiv.org/abs/2307.14085</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siyu Chen, Mengdi Wang, Zhuoran Yang</li>
<li>for: 学习一种名为量化斯坦堡峰点的 equilibrio（QSE）在一个 episodic Markov 游戏中，其中有一位领袖和一位跟随者。</li>
<li>methods: 使用 reinforcement learning（RL）和 maximum likelihood estimation（MLE）来学习领袖的决策问题，并且使用 entropy-regularized policy optimization problem（EPOP）来解决跟随者的决策问题。</li>
<li>results: 提出了一些可靠的算法来解决领袖的决策问题，并且可以在线和离线两种设置下实现。这些算法可以在不见跟随者的奖励情况下做出优化的决策，并且可以在特定的线性和偏好设置下实现高效的计算。<details>
<summary>Abstract</summary>
We study reinforcement learning (RL) for learning a Quantal Stackelberg Equilibrium (QSE) in an episodic Markov game with a leader-follower structure. In specific, at the outset of the game, the leader announces her policy to the follower and commits to it. The follower observes the leader's policy and, in turn, adopts a quantal response policy by solving an entropy-regularized policy optimization problem induced by leader's policy. The goal of the leader is to find her optimal policy, which yields the optimal expected total return, by interacting with the follower and learning from data. A key challenge of this problem is that the leader cannot observe the follower's reward, and needs to infer the follower's quantal response model from his actions against leader's policies. We propose sample-efficient algorithms for both the online and offline settings, in the context of function approximation. Our algorithms are based on (i) learning the quantal response model via maximum likelihood estimation and (ii) model-free or model-based RL for solving the leader's decision making problem, and we show that they achieve sublinear regret upper bounds. Moreover, we quantify the uncertainty of these estimators and leverage the uncertainty to implement optimistic and pessimistic algorithms for online and offline settings. Besides, when specialized to the linear and myopic setting, our algorithms are also computationally efficient. Our theoretical analysis features a novel performance-difference lemma which incorporates the error of quantal response model, which might be of independent interest.
</details>
<details>
<summary>摘要</summary>
我们研究强化学习（RL）以学习一个量化Stackelberg均衡（QSE）在一个 episodic Markov 游戏中，具有领袖-追随者结构。具体来说，在游戏开始时，领袖宣布她的策略给追随者，并将其固定下来。追随者根据领袖的策略采取一个量化回应策略，解决由领袖的策略引起的Entropy 正则化的策略优化问题。领袖的目标是找到她的优化策略，以实现与追随者的互动和学习数据的最优预期总回报。一个关键挑战是，领袖无法观察追随者的奖励，需要从追随者的行动中推断出追随者的量化回应模型。我们提出了样本效率高的算法，包括在线和离线设置中的Maximum Likelihood估计和模型自由或模型基于的RL，并证明它们可以实现下界 regret upper bound。此外，我们还评估了这些估计的uncertainty，并利用这些uncertainty来实现在线和离线设置中的 оптимистик和悲观算法。此外，当特化到线性和偏置设置时，我们的算法也是计算效率高的。我们的理论分析包括一个新的性能差异公式，可能是独立的兴趣。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-simulate-partially-known-spatio-temporal-dynamics-with-trainable-difference-operators"><a href="#Learning-to-simulate-partially-known-spatio-temporal-dynamics-with-trainable-difference-operators" class="headerlink" title="Learning to simulate partially known spatio-temporal dynamics with trainable difference operators"></a>Learning to simulate partially known spatio-temporal dynamics with trainable difference operators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14395">http://arxiv.org/abs/2307.14395</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiang Huang, Zhuoyuan Li, Hongsheng Liu, Zidong Wang, Hongye Zhou, Bin Dong, Bei Hua</li>
<li>for: 用神经网络模拟空间时间动态的研究在最近几年得到了很多关注。然而，大多数现有方法采用纯数据驱动的黑盒模型，准确性和可解释性受限。本文提出了一种新的混合体系，名为PDE-Net++，它通过结合可训练的差异算子和黑盒模型来Explicitly embedding partial prior knowledge of the underlying PDEs。</li>
<li>methods: 本文提出了两种不同的差异算子选项：trainable flipping difference layer (TFDL)和trainable dynamic difference layer (TDDL)。</li>
<li>results: numerical experiments show that PDE-Net++ has better prediction accuracy and extrapolation performance than black-box models.<details>
<summary>Abstract</summary>
Recently, using neural networks to simulate spatio-temporal dynamics has received a lot of attention. However, most existing methods adopt pure data-driven black-box models, which have limited accuracy and interpretability. By combining trainable difference operators with black-box models, we propose a new hybrid architecture explicitly embedded with partial prior knowledge of the underlying PDEs named PDE-Net++. Furthermore, we introduce two distinct options called the trainable flipping difference layer (TFDL) and the trainable dynamic difference layer (TDDL) for the difference operators. Numerous numerical experiments have demonstrated that PDE-Net++ has superior prediction accuracy and better extrapolation performance than black-box models.
</details>
<details>
<summary>摘要</summary>
Note:* "Recently" is translated as "近些时候" (jìn xiē shí hou)* "using neural networks" is translated as "使用神经网络" (shǐ yòng jīng xīn wǎng luò)* "simulate spatio-temporal dynamics" is translated as "模拟空间时间动态" (mó xiàng kōng jiān shí huan dòng)* "black-box models" is translated as "黑盒模型" (hēi bāo mó xiàng)* "trainable difference operators" is translated as "可训练差异算子" (kě xù xíng yì yán sè)* "PDE-Net++" is translated as "PDE-Net++" (PDE-Net++), no change* "numerical experiments" is translated as "数值实验" (shù xiàng shí yàn)* "superior prediction accuracy" is translated as "更高的预测精度" (gèng gāo de yù jí dào)* "better extrapolation performance" is translated as "更好的推论性能" (gèng hǎo de tuī yì yù)
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Domain-Discrepancy-Adjustment-for-Active-Multi-Domain-Adaptation"><a href="#Dynamic-Domain-Discrepancy-Adjustment-for-Active-Multi-Domain-Adaptation" class="headerlink" title="Dynamic Domain Discrepancy Adjustment for Active Multi-Domain Adaptation"></a>Dynamic Domain Discrepancy Adjustment for Active Multi-Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14068">http://arxiv.org/abs/2307.14068</a></li>
<li>repo_url: None</li>
<li>paper_authors: Long Liu, Bo Zhou, Zhipeng Zhao, Zening Liu</li>
<li>for: 本研究旨在解决多源零监督领域适应（MUDA）中的困难，包括适应性下降和功能缺失。</li>
<li>methods: 我们提出了一种名为动态领域差异调整的活动多源领域适应（D3AAMDA）方法。该方法基于源频率的多源动态调整机制，控制每个源频率与目标频率之间的匹配程度，以便有效地利用每个源频率的本地有利特征信息。此外，我们还提出了一种多源活动边界选择策略（MABS），使用引导动态边界损失来设计高效的查询函数，以选择重要的样本。</li>
<li>results: 我们对常用的领域适应数据集进行了广泛的比较研究，并证明了我们的方法的超越性。<details>
<summary>Abstract</summary>
Multi-source unsupervised domain adaptation (MUDA) aims to transfer knowledge from related source domains to an unlabeled target domain. While recent MUDA methods have shown promising results, most focus on aligning the overall feature distributions across source domains, which can lead to negative effects due to redundant features within each domain. Moreover, there is a significant performance gap between MUDA and supervised methods. To address these challenges, we propose a novel approach called Dynamic Domain Discrepancy Adjustment for Active Multi-Domain Adaptation (D3AAMDA). Firstly, we establish a multi-source dynamic modulation mechanism during the training process based on the degree of distribution differences between source and target domains. This mechanism controls the alignment level of features between each source domain and the target domain, effectively leveraging the local advantageous feature information within the source domains. Additionally, we propose a Multi-source Active Boundary Sample Selection (MABS) strategy, which utilizes a guided dynamic boundary loss to design an efficient query function for selecting important samples. This strategy achieves improved generalization to the target domain with minimal sampling costs. We extensively evaluate our proposed method on commonly used domain adaptation datasets, comparing it against existing UDA and ADA methods. The experimental results unequivocally demonstrate the superiority of our approach.
</details>
<details>
<summary>摘要</summary>
多源无监督领域适应（MUDA）目标是将相关的源频率域知识传递到无标注目标频率域。although recent MUDA methods have shown promising results, most of them focus on aligning the overall feature distributions across source domains, which can lead to negative effects due to redundant features within each domain. Moreover, there is a significant performance gap between MUDA and supervised methods. To address these challenges, we propose a novel approach called Dynamic Domain Discrepancy Adjustment for Active Multi-Domain Adaptation (D3AAMDA). Firstly, we establish a multi-source dynamic modulation mechanism during the training process based on the degree of distribution differences between source and target domains. This mechanism controls the alignment level of features between each source domain and the target domain, effectively leveraging the local advantageous feature information within the source domains. Additionally, we propose a Multi-source Active Boundary Sample Selection (MABS) strategy, which utilizes a guided dynamic boundary loss to design an efficient query function for selecting important samples. This strategy achieves improved generalization to the target domain with minimal sampling costs. We extensively evaluate our proposed method on commonly used domain adaptation datasets, comparing it against existing UDA and ADA methods. The experimental results unequivocally demonstrate the superiority of our approach.
</details></li>
</ul>
<hr>
<h2 id="Hypergraph-Isomorphism-Computation"><a href="#Hypergraph-Isomorphism-Computation" class="headerlink" title="Hypergraph Isomorphism Computation"></a>Hypergraph Isomorphism Computation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14394">http://arxiv.org/abs/2307.14394</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifan Feng, Jiashu Han, Shihui Ying, Yue Gao</li>
<li>for:  solve the problem of hypergraph isomorphism and improve the performance of hypergraph kernel methods.</li>
<li>methods:  propose a hypergraph Weisfiler-Lehman test algorithm and a general hypergraph Weisfeiler-Lehamn kernel framework, and implement two instances.</li>
<li>results:  significant improvements in hypergraph classification and outperform other typical kernel-based methods in terms of runtime.<details>
<summary>Abstract</summary>
The isomorphism problem is a fundamental problem in network analysis, which involves capturing both low-order and high-order structural information. In terms of extracting low-order structural information, graph isomorphism algorithms analyze the structural equivalence to reduce the solver space dimension, which demonstrates its power in many applications, such as protein design, chemical pathways, and community detection. For the more commonly occurring high-order relationships in real-life scenarios, the problem of hypergraph isomorphism, which effectively captures these high-order structural relationships, cannot be straightforwardly addressed using graph isomorphism methods. Besides, the existing hypergraph kernel methods may suffer from high memory consumption or inaccurate sub-structure identification, thus yielding sub-optimal performance. In this paper, to address the abovementioned problems, we first propose the hypergraph Weisfiler-Lehman test algorithm for the hypergraph isomorphism test problem by generalizing the Weisfiler-Lehman test algorithm from graphs to hypergraphs. Secondly, based on the presented algorithm, we propose a general hypergraph Weisfieler-Lehman kernel framework and implement two instances, which are Hypergraph Weisfeiler-Lehamn Subtree Kernel and Hypergraph Weisfeiler-Lehamn Hyperedge Kernel. In order to fulfill our research objectives, a comprehensive set of experiments was meticulously designed, including seven graph classification datasets and 12 hypergraph classification datasets. Results on hypergraph classification datasets show significant improvements compared to other typical kernel-based methods, which demonstrates the effectiveness of the proposed methods. In our evaluation, we found that our proposed methods outperform the second-best method in terms of runtime, running over 80 times faster when handling complex hypergraph structures.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXTThe isomorphism problem is a fundamental problem in network analysis, which involves capturing both low-order and high-order structural information. In terms of extracting low-order structural information, graph isomorphism algorithms analyze the structural equivalence to reduce the solver space dimension, which demonstrates its power in many applications, such as protein design, chemical pathways, and community detection. For the more commonly occurring high-order relationships in real-life scenarios, the problem of hypergraph isomorphism, which effectively captures these high-order structural relationships, cannot be straightforwardly addressed using graph isomorphism methods. Besides, the existing hypergraph kernel methods may suffer from high memory consumption or inaccurate sub-structure identification, thus yielding sub-optimal performance. In this paper, to address the abovementioned problems, we first propose the hypergraph Weisfiler-Lehman test algorithm for the hypergraph isomorphism test problem by generalizing the Weisfiler-Lehman test algorithm from graphs to hypergraphs. Secondly, based on the presented algorithm, we propose a general hypergraph Weisfieler-Lehamn kernel framework and implement two instances, which are Hypergraph Weisfeiler-Lehamn Subtree Kernel and Hypergraph Weisfeiler-Lehamn Hyperedge Kernel. In order to fulfill our research objectives, a comprehensive set of experiments was meticulously designed, including seven graph classification datasets and 12 hypergraph classification datasets. Results on hypergraph classification datasets show significant improvements compared to other typical kernel-based methods, which demonstrates the effectiveness of the proposed methods. In our evaluation, we found that our proposed methods outperform the second-best method in terms of runtime, running over 80 times faster when handling complex hypergraph structures.TRANSLATE_TEXT
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-Applications-In-Healthcare-The-State-Of-Knowledge-and-Future-Directions"><a href="#Machine-Learning-Applications-In-Healthcare-The-State-Of-Knowledge-and-Future-Directions" class="headerlink" title="Machine Learning Applications In Healthcare: The State Of Knowledge and Future Directions"></a>Machine Learning Applications In Healthcare: The State Of Knowledge and Future Directions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14067">http://arxiv.org/abs/2307.14067</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mrinmoy Roy, Sarwar J. Minar, Porarthi Dhar, A T M Omor Faruq</li>
<li>For: The paper aims to gather and present Machine Learning (ML) applications in different areas of healthcare, such as community level work, risk management&#x2F;preventive care, healthcare operation management, remote care, and early detection, to provide quick access to necessary information and reduce the knowledge gap of clinicians about ML applications in healthcare.* Methods: The paper uses a comprehensive review of existing literature to identify and categorize ML applications in healthcare, and provides relevant references with descriptions in tabular form for quick access.* Results: The paper provides a comprehensive overview of ML applications in healthcare, including their potential benefits and limitations, and aims to motivate healthcare professionals towards more ML-based healthcare systems.Here’s the same information in Simplified Chinese text:* For: 这篇论文目的是为健康培训系统中的不同领域提供机器学习（ML）应用，以便快速获取必要信息，并减少医生关于ML应用的知识差距。* Methods: 这篇论文通过对现有文献进行全面审查，identify和分类健康培训系统中的ML应用，并提供相关参考文献的描述在表格形式以便快速访问。* Results: 这篇论文提供了健康培训系统中ML应用的全面概述，包括其潜在优势和局限性，并希望能够激励医疗专业人员更加关注ML基于健康培训系统。<details>
<summary>Abstract</summary>
Detection of easily missed hidden patterns with fast processing power makes machine learning (ML) indispensable to today's healthcare system. Though many ML applications have already been discovered and many are still under investigation, only a few have been adopted by current healthcare systems. As a result, there exists an enormous opportunity in healthcare system for ML but distributed information, scarcity of properly arranged and easily explainable documentation in related sector are major impede which are making ML applications difficult to healthcare professionals. This study aimed to gather ML applications in different areas of healthcare concisely and more effectively so that necessary information can be accessed immediately with relevant references. We divided our study into five major groups: community level work, risk management/ preventive care, healthcare operation management, remote care, and early detection. Dividing these groups into subgroups, we provided relevant references with description in tabular form for quick access. Our objective is to inform people about ML applicability in healthcare industry, reduce the knowledge gap of clinicians about the ML applications and motivate healthcare professionals towards more machine learning based healthcare system.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate(Detection of easily missed hidden patterns with fast processing power makes machine learning (ML) indispensable to today's healthcare system. Though many ML applications have already been discovered and many are still under investigation, only a few have been adopted by current healthcare systems. As a result, there exists an enormous opportunity in healthcare system for ML but distributed information, scarcity of properly arranged and easily explainable documentation in related sector are major impede which are making ML applications difficult to healthcare professionals. This study aimed to gather ML applications in different areas of healthcare concisely and more effectively so that necessary information can be accessed immediately with relevant references. We divided our study into five major groups: community level work, risk management/ preventive care, healthcare operation management, remote care, and early detection. Dividing these groups into subgroups, we provided relevant references with description in tabular form for quick access. Our objective is to inform people about ML applicability in healthcare industry, reduce the knowledge gap of clinicians about the ML applications and motivate healthcare professionals towards more machine learning based healthcare system.)中文(简化)机器学习（ML）因其快速处理和检测隐藏 Patterns 的能力，成为今天医疗系统中不可或缺的一部分。虽然许多 ML 应用已经被发现，但只有一些被当前医疗系统采纳。因此，医疗系统中对 ML 的潜在机会巨大，但是分散的信息和医疗相关领域的文献不够整洁和容易解释，使 ML 应用困难于医疗专业人员。本研究的目标是收集不同领域的 ML 应用，并按照五大类划分：社区层次的工作、风险管理/预防护理、医疗运营管理、远程护理和早期检测。将这些类划分为子类，并提供相关参考文献的描述在表格形式，以便快速获取相关信息。我们的目标是通过了解医疗工业中 ML 的可能性，减少医生关于 ML 应用的知识差距，并激励医疗专业人员更多地采用机器学习基于医疗系统。）
</details></li>
</ul>
<hr>
<h2 id="Pre-Training-with-Diffusion-models-for-Dental-Radiography-segmentation"><a href="#Pre-Training-with-Diffusion-models-for-Dental-Radiography-segmentation" class="headerlink" title="Pre-Training with Diffusion models for Dental Radiography segmentation"></a>Pre-Training with Diffusion models for Dental Radiography segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14066">http://arxiv.org/abs/2307.14066</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jérémy Rousseau, Christian Alaka, Emma Covili, Hippolyte Mayard, Laura Misrachi, Willy Au</li>
<li>for: 这篇论文旨在提高医疗X射影像分类的效率，尤其是 dental radiography 的分类。</li>
<li>methods: 本文提出了一种使用 Denoising Diffusion Probabilistic Models (DDPM) 的单簇预训练方法，并在这种预训练方法下预训 U-Net 模型。</li>
<li>results: 实验结果显示，提出的方法可以与现有的预训练方法相比，在 dental radiographs 的分类任务中达到高效的结果。<details>
<summary>Abstract</summary>
Medical radiography segmentation, and specifically dental radiography, is highly limited by the cost of labeling which requires specific expertise and labor-intensive annotations. In this work, we propose a straightforward pre-training method for semantic segmentation leveraging Denoising Diffusion Probabilistic Models (DDPM), which have shown impressive results for generative modeling. Our straightforward approach achieves remarkable performance in terms of label efficiency and does not require architectural modifications between pre-training and downstream tasks. We propose to first pre-train a Unet by exploiting the DDPM training objective, and then fine-tune the resulting model on a segmentation task. Our experimental results on the segmentation of dental radiographs demonstrate that the proposed method is competitive with state-of-the-art pre-training methods.
</details>
<details>
<summary>摘要</summary>
医疗成像分割，特别是牙科成像，受到标注成本的限制，需要专业知识和劳动密集的标注。在这项工作中，我们提出了一种简单的预训练方法 для semantic segmentation，利用Denosing Diffusion Probabilistic Models（DDPM），这种模型在生成模型中表现出色。我们的简单approach可以 достичьRemarkable的标签效率，不需要下游任务中的建筑修改。我们提议首先预训一个Unet，利用DDPM训练目标，然后精度调整得到的模型以进行分割任务。我们的实验结果表明，提议的方法与现有的预训方法竞争。
</details></li>
</ul>
<hr>
<h2 id="Topologically-Regularized-Multiple-Instance-Learning-for-Red-Blood-Cell-Disease-Classification"><a href="#Topologically-Regularized-Multiple-Instance-Learning-for-Red-Blood-Cell-Disease-Classification" class="headerlink" title="Topologically-Regularized Multiple Instance Learning for Red Blood Cell Disease Classification"></a>Topologically-Regularized Multiple Instance Learning for Red Blood Cell Disease Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14025">http://arxiv.org/abs/2307.14025</a></li>
<li>repo_url: None</li>
<li>paper_authors: Salome Kazeminia, Ario Sadafi, Asya Makhro, Anna Bogdanova, Carsten Marr, Bastian Rieck</li>
<li>for: 鉴别罕见贫血病用微scopic图像</li>
<li>methods: 使用topology基本特征来正则化多例学习</li>
<li>results: 在71名患有罕见贫血病的患者和521张红血球微scopic图像上，使用topology正则化方法可以提高自动识别罕见贫血病的性能超过3%。<details>
<summary>Abstract</summary>
Diagnosing rare anemia disorders using microscopic images is challenging for skilled specialists and machine-learning methods alike. Due to thousands of disease-relevant cells in a single blood sample, this constitutes a complex multiple-instance learning (MIL) problem. While the spatial neighborhood of red blood cells is not meaningful per se, the topology, i.e., the geometry of blood samples as a whole, contains informative features to remedy typical MIL issues, such as vanishing gradients and overfitting when training on limited data. We thus develop a topology-based approach that extracts multi-scale topological features from bags of single red blood cell images. The topological features are used to regularize the model, enforcing the preservation of characteristic topological properties of the data. Applied to a dataset of 71 patients suffering from rare anemia disorders with 521 microscopic images of red blood cells, our experiments show that topological regularization is an effective method that leads to more than 3% performance improvements for the automated classification of rare anemia disorders based on single-cell images. This is the first approach that uses topological properties for regularizing the MIL process.
</details>
<details>
<summary>摘要</summary>
诊断罕见血红细胞疾病使用微scopic图像具有挑战性， tanto для专家和机器学习方法。由于每个血液样本中有数以千计疾病相关的细胞，这构成了复杂的多例学习（MIL）问题。虽然红血球的空间邻居无法直接提供有用信息，但血液样本的整体几何结构却含有有用的特征，以解决典型的MIL问题，如消失梯度和过拟合。我们因此开发了基于几何特征的方法，从单个红血球图像中提取多尺度几何特征。这些几何特征用于规范模型，使模型保持疾病特征的几何特性。我们对71名患有罕见血红细胞疾病的病人，共521个微scopic红血球图像进行实验，结果表明，基于几何特征的规范是一种有效的方法，可以提高单细胞图像自动诊断罕见血红细胞疾病的性能，高于3%。这是首次使用几何特征进行MIL规范的方法。
</details></li>
</ul>
<hr>
<h2 id="Are-Transformers-with-One-Layer-Self-Attention-Using-Low-Rank-Weight-Matrices-Universal-Approximators"><a href="#Are-Transformers-with-One-Layer-Self-Attention-Using-Low-Rank-Weight-Matrices-Universal-Approximators" class="headerlink" title="Are Transformers with One Layer Self-Attention Using Low-Rank Weight Matrices Universal Approximators?"></a>Are Transformers with One Layer Self-Attention Using Low-Rank Weight Matrices Universal Approximators?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14023">http://arxiv.org/abs/2307.14023</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tokio Kajitsuka, Issei Sato</li>
<li>for: 这个论文是为了探讨Transformer模型的表达能力而写的。</li>
<li>methods: 该论文使用了 clarify the connection between the softmax function and the Boltzmann operator来解释Transformer模型的表达能力。</li>
<li>results: 研究发现，单层自注意力层可以完全捕捉输入序列的上下文，因此单层Transformer模型具有内存化能力，而且由一层自注意力层和两个隐藏层组成的Transformer模型是对 kontinuous function的universal approximator。<details>
<summary>Abstract</summary>
Existing analyses of the expressive capacity of Transformer models have required excessively deep layers for data memorization, leading to a discrepancy with the Transformers actually used in practice. This is primarily due to the interpretation of the softmax function as an approximation of the hardmax function. By clarifying the connection between the softmax function and the Boltzmann operator, we prove that a single layer of self-attention with low-rank weight matrices possesses the capability to perfectly capture the context of an entire input sequence. As a consequence, we show that single-layer Transformer has a memorization capacity for finite samples, and that Transformers consisting of one self-attention layer with two feed-forward neural networks are universal approximators for continuous functions on a compact domain.
</details>
<details>
<summary>摘要</summary>
现有的分析表明，Transformer模型的表达能力需要过度深度层来进行数据记忆，导致与实际使用中的Transformer模型存在差异。这主要是因为对softmax函数的解释为硬max函数的近似，从而导致了层次结构的增加。我们通过证明了softmax函数和Boltzmann运算符之间的连接，表明了一层自注意力层可以完全捕捉整个输入序列的上下文。因此，我们显示了单层Transformer具有 finite samples的记忆能力，并证明了由一层自注意力层和两个输入神经网络组成的Transformer模型是对紧窄领域上的连续函数的universalapproximator。
</details></li>
</ul>
<hr>
<h2 id="MCMC-Correction-of-Score-Based-Diffusion-Models-for-Model-Composition"><a href="#MCMC-Correction-of-Score-Based-Diffusion-Models-for-Model-Composition" class="headerlink" title="MCMC-Correction of Score-Based Diffusion Models for Model Composition"></a>MCMC-Correction of Score-Based Diffusion Models for Model Composition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14012">http://arxiv.org/abs/2307.14012</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jackonelli/mcmc_corr_score_diffusion">https://github.com/jackonelli/mcmc_corr_score_diffusion</a></li>
<li>paper_authors: Anders Sjöberg, Jakob Lindqvist, Magnus Önnheim, Mats Jirstrand, Lennart Svensson</li>
<li>for: 这篇论文的目的是提出一种基于得分函数的扩展样本过程，以便组合不同的Markov链 Monte Carlo（MCMC）方法。</li>
<li>methods: 这篇论文使用了得分函数来Parameterize diffusion models，并通过线tegration of the score function来计算能量基于的接受概率。</li>
<li>results: 实验表明，这种方法可以 дости得与使用能量函数参数化的性能，且可以 reuse existing diffusion models。<details>
<summary>Abstract</summary>
Diffusion models can be parameterised in terms of either a score or an energy function. The energy parameterisation has better theoretical properties, mainly that it enables an extended sampling procedure with a Metropolis--Hastings correction step, based on the change in total energy in the proposed samples. However, it seems to yield slightly worse performance, and more importantly, due to the widespread popularity of score-based diffusion, there are limited availability of off-the-shelf pre-trained energy-based ones. This limitation undermines the purpose of model composition, which aims to combine pre-trained models to sample from new distributions. Our proposal, however, suggests retaining the score parameterization and instead computing the energy-based acceptance probability through line integration of the score function. This allows us to re-use existing diffusion models and still combine the reverse process with various Markov-Chain Monte Carlo (MCMC) methods. We evaluate our method on a 2D experiment and find that it achieve similar or arguably better performance than the energy parameterisation.
</details>
<details>
<summary>摘要</summary>
Diffusion models 可以被参数化为得分或能量函数。能量参数化有更好的理论性质，主要是它允许扩展采样过程，并且基于变化总能量的 Metropolis--Hastings 修正步骤。然而，它似乎表现稍微下降，而且由于得分基 diffusion 的广泛普及，有限的可用性。这限制了模型组合的目的，即将预训练模型组合以采样新的分布。我们的提议是保留得分参数化，并计算基于得分函数的能量基于接受probability。这允许我们重用现有的 diffusion 模型，并且与多种Markov-Chain Monte Carlo（MCMC）方法结合。我们对2D实验进行评估，发现其表现相当或者更好于能量参数化。
</details></li>
</ul>
<hr>
<h2 id="Diff-E-Diffusion-based-Learning-for-Decoding-Imagined-Speech-EEG"><a href="#Diff-E-Diffusion-based-Learning-for-Decoding-Imagined-Speech-EEG" class="headerlink" title="Diff-E: Diffusion-based Learning for Decoding Imagined Speech EEG"></a>Diff-E: Diffusion-based Learning for Decoding Imagined Speech EEG</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14389">http://arxiv.org/abs/2307.14389</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yorgoon/diffe">https://github.com/yorgoon/diffe</a></li>
<li>paper_authors: Soowon Kim, Young-Eun Lee, Seo-Hyun Lee, Seong-Whan Lee</li>
<li>for: 用于实现脑机器人通信的想像语音数据解析</li>
<li>methods: 使用抽象数据模型（DDPMs）和增强型自适应神经网络（Diff-E）进行EEG信号处理</li>
<li>results: 比传统机器学习技术和基准模型更高的实现EEG信号实现想像语音的精度<details>
<summary>Abstract</summary>
Decoding EEG signals for imagined speech is a challenging task due to the high-dimensional nature of the data and low signal-to-noise ratio. In recent years, denoising diffusion probabilistic models (DDPMs) have emerged as promising approaches for representation learning in various domains. Our study proposes a novel method for decoding EEG signals for imagined speech using DDPMs and a conditional autoencoder named Diff-E. Results indicate that Diff-E significantly improves the accuracy of decoding EEG signals for imagined speech compared to traditional machine learning techniques and baseline models. Our findings suggest that DDPMs can be an effective tool for EEG signal decoding, with potential implications for the development of brain-computer interfaces that enable communication through imagined speech.
</details>
<details>
<summary>摘要</summary>
decode EEG 信号为想像的语音是一项复杂的任务，因为数据的维度高，信号噪声比低。在过去几年，杂Diffusion probabilistic models（DDPMs）已经出现为不同领域的表示学习提供了promising的方法。我们的研究提出了一种使用 DDPMs 和名为 Diff-E 的条件 autoencoder 来解码 EEG 信号的新方法。结果显示，Diff-E 可以 significatively 提高对想像语音的 EEG 信号解码精度，比传统机器学习技术和基线模型更高。我们的发现表明，DDPMs 可以是 EEG 信号解码的有效工具，具有可能应用于通过想像语音的 brain-computer interfaces 的发展的潜在意义。
</details></li>
</ul>
<hr>
<h2 id="Fast-algorithms-for-k-submodular-maximization-subject-to-a-matroid-constraint"><a href="#Fast-algorithms-for-k-submodular-maximization-subject-to-a-matroid-constraint" class="headerlink" title="Fast algorithms for k-submodular maximization subject to a matroid constraint"></a>Fast algorithms for k-submodular maximization subject to a matroid constraint</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13996">http://arxiv.org/abs/2307.13996</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuxian Niu, Qian Liu, Yang Zhou, Min Li</li>
<li>for: 本文使用阈值递减算法来最大化$k$-submodular函数 beneath 环境约束，从而降低算法的查询复杂度，与排序算法相比，只有小量的损失。</li>
<li>methods: 本文提出了$(1&#x2F;2-\epsilon)$-近似算法 для monotone $k$-submodular函数最大化，以及$(1&#x2F;3-\epsilon)$-近似算法 для非 monotone  случа例，其复杂度为 $O(\frac{n(k\cdot EO + IO)}{\epsilon} \log \frac{r}{\epsilon})$.</li>
<li>results: 本文提出了一种快速的算法来最大化$k$-submodular函数 beneath 总大小约束，其复杂度为 $O(\frac{n(k\cdot EO + IO)}{\epsilon} \log \frac{r}{\epsilon})$. 这些结果可以看作是对特殊的Uniform matroid环境的一种快速算法。<details>
<summary>Abstract</summary>
In this paper, we apply a Threshold-Decreasing Algorithm to maximize $k$-submodular functions under a matroid constraint, which reduces the query complexity of the algorithm compared to the greedy algorithm with little loss in approximation ratio. We give a $(\frac{1}{2} - \epsilon)$-approximation algorithm for monotone $k$-submodular function maximization, and a $(\frac{1}{3} - \epsilon)$-approximation algorithm for non-monotone case, with complexity $O(\frac{n(k\cdot EO + IO)}{\epsilon} \log \frac{r}{\epsilon})$, where $r$ denotes the rank of the matroid, and $IO, EO$ denote the number of oracles to evaluate whether a subset is an independent set and to compute the function value of $f$, respectively. Since the constraint of total size can be looked as a special matroid, called uniform matroid, then we present the fast algorithm for maximizing $k$-submodular functions subject to a total size constraint as corollaries. corollaries.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们采用了阈值降低算法来最大化$k$-超模ular函数 beneath a matroid constraint，这将相比于格雷德算法减少查询复杂度，即使有些损失相对精度。我们提供了$(1/2-\epsilon)$-近似算法 для升华$k$-超模ular函数最大化，以及$(1/3-\epsilon)$-近似算法 для非升华 случа子，其复杂度为$O(\frac{n(k\cdot EO+IO)}{\epsilon}\log\frac{r}{\epsilon})$，其中$r$表示矩阵的排名，$IO, EO$表示评估 subset 是独立集的或acles数和计算函数值的次数。由于总大小的约束可以看作特殊的矩阵，即uniform矩阵，因此我们将在corollaries中提供快速算法 для最大化$k$-超模ular函数 subject to 总大小约束。
</details></li>
</ul>
<hr>
<h2 id="Take-Your-Pick-Enabling-Effective-Personalized-Federated-Learning-within-Low-dimensional-Feature-Space"><a href="#Take-Your-Pick-Enabling-Effective-Personalized-Federated-Learning-within-Low-dimensional-Feature-Space" class="headerlink" title="Take Your Pick: Enabling Effective Personalized Federated Learning within Low-dimensional Feature Space"></a>Take Your Pick: Enabling Effective Personalized Federated Learning within Low-dimensional Feature Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13995">http://arxiv.org/abs/2307.13995</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guogang Zhu, Xuefeng Liu, Shaojie Tang, Jianwei Niu, Xinghao Wu, Jiaxing Shen</li>
<li>for: 这篇论文是针对个性化联合学习（PFL）框架的研究，具体来说是如何在不同客户端的数据分布下实现个性化的模型。</li>
<li>methods: 这篇论文提出了一种新的PFL框架，即FedPick，它在全局编码器生成的特征空间中采取了适应式选择客户端任务相关的特征，以提高模型在跨域FL中的性能。</li>
<li>results: 实验结果表明，FedPick可以有效地选择客户端任务相关的特征，并提高模型在跨域FL中的性能。<details>
<summary>Abstract</summary>
Personalized federated learning (PFL) is a popular framework that allows clients to have different models to address application scenarios where clients' data are in different domains. The typical model of a client in PFL features a global encoder trained by all clients to extract universal features from the raw data and personalized layers (e.g., a classifier) trained using the client's local data. Nonetheless, due to the differences between the data distributions of different clients (aka, domain gaps), the universal features produced by the global encoder largely encompass numerous components irrelevant to a certain client's local task. Some recent PFL methods address the above problem by personalizing specific parameters within the encoder. However, these methods encounter substantial challenges attributed to the high dimensionality and non-linearity of neural network parameter space. In contrast, the feature space exhibits a lower dimensionality, providing greater intuitiveness and interpretability as compared to the parameter space. To this end, we propose a novel PFL framework named FedPick. FedPick achieves PFL in the low-dimensional feature space by selecting task-relevant features adaptively for each client from the features generated by the global encoder based on its local data distribution. It presents a more accessible and interpretable implementation of PFL compared to those methods working in the parameter space. Extensive experimental results show that FedPick could effectively select task-relevant features for each client and improve model performance in cross-domain FL.
</details>
<details>
<summary>摘要</summary>
personalized federated learning (PFL) 是一种 популяр的框架，允许客户端有不同的模型来应对应用场景中客户端数据在不同域中。典型的客户端模型在 PFL 中包括全球编码器通过所有客户端训练的通用特征Extract和客户端本地数据使用的个性化层（例如分类器）。然而，由于客户端数据分布的不同（也就是域漏），全球编码器生成的通用特征主要包括客户端本地任务无关的多个组件。一些最近的 PFL 方法 Addressing the above problem by personalizing specific parameters within the encoder. However, these methods encounter substantial challenges attributed to the high dimensionality and non-linearity of neural network parameter space.在 contrast，特征空间具有较低的维度，提供更加直观和可解释的特征，相比于参数空间。为此，我们提议一种新的 PFL 框架，名为 FedPick。FedPick 实现了 PFL 在低维特征空间中，通过对每个客户端的本地数据分布进行适应性地选择任务相关的特征。它提供了 PFL 的更加可访问和可解释的实现，相比于在参数空间工作的方法。我们进行了广泛的实验研究，表明 FedPick 可以有效地选择每个客户端的任务相关特征，并提高 cross-domain FL 的模型性能。
</details></li>
</ul>
<hr>
<h2 id="BovineTalk-Machine-Learning-for-Vocalization-Analysis-of-Dairy-Cattle-under-Negative-Affective-States"><a href="#BovineTalk-Machine-Learning-for-Vocalization-Analysis-of-Dairy-Cattle-under-Negative-Affective-States" class="headerlink" title="BovineTalk: Machine Learning for Vocalization Analysis of Dairy Cattle under Negative Affective States"></a>BovineTalk: Machine Learning for Vocalization Analysis of Dairy Cattle under Negative Affective States</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13994">http://arxiv.org/abs/2307.13994</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dinu Gavojdian, Teddy Lazebnik, Madalina Mincu, Ariel Oren, Ioana Nicolae, Anna Zamansky</li>
<li>for: 这个研究的目的是开发和验证对livestock动物情感状态的非侵入式指标，以便将其 integrate到场地评估协议中。</li>
<li>methods: 这个研究使用了牛的 vocal indicators，并使用了深度学习和可解释机器学习两种计算框架来分类低频和高频牛叫，以及牛叫voice recognition。</li>
<li>results: 研究结果表明，使用深度学习和可解释机器学习两种计算框架可以达到87.2%和89.4%的叫声分类精度，并达到68.9%和72.5%的牛叫voice recognition精度。<details>
<summary>Abstract</summary>
There is a critical need to develop and validate non-invasive animal-based indicators of affective states in livestock species, in order to integrate them into on-farm assessment protocols, potentially via the use of precision livestock farming (PLF) tools. One such promising approach is the use of vocal indicators. The acoustic structure of vocalizations and their functions were extensively studied in important livestock species, such as pigs, horses, poultry and goats, yet cattle remain understudied in this context to date. Cows were shown to produce two types vocalizations: low-frequency calls (LF), produced with the mouth closed, or partially closed, for close distance contacts and open mouth emitted high-frequency calls (HF), produced for long distance communication, with the latter considered to be largely associated with negative affective states. Moreover, cattle vocalizations were shown to contain information on individuality across a wide range of contexts, both negative and positive. Nowadays, dairy cows are facing a series of negative challenges and stressors in a typical production cycle, making vocalizations during negative affective states of special interest for research. One contribution of this study is providing the largest to date pre-processed (clean from noises) dataset of lactating adult multiparous dairy cows during negative affective states induced by visual isolation challenges. Here we present two computational frameworks - deep learning based and explainable machine learning based, to classify high and low-frequency cattle calls, and individual cow voice recognition. Our models in these two frameworks reached 87.2% and 89.4% accuracy for LF and HF classification, with 68.9% and 72.5% accuracy rates for the cow individual identification, respectively.
</details>
<details>
<summary>摘要</summary>
“有一个急需要发展和验证不侵入性动物表征情感状态的需求，以便在农场评估程序中 integrate 其。一种有前途的方法是使用 vocals。livestock 种类中，如猪、马、鸡和山羊的 vocalizations 和其功能已经广泛研究，但是牛尚未在这个设定中受到研究。牛产生了两种 vocals：低频声（LF），通过关闭或部分关闭口部生成，用于近距离接触，以及开口输出高频声（HF），用于长距离通信，后者被认为与负面情感状态有关。此外，牛 vocalizations 包含个体特征信息，在各种情况下都有广泛的应用。现在，生产周期中的牛面临许多负面挑战和压力，使得在负面情感状态下的牛 vocalizations 特别有研究价值。本研究将提供过去最大的（清洁掉噪） dataset，包括排程哺乳的成年多孢牛在负面情感状态下的 vocalizations。我们提出了两个 computation framework - deep learning 基于的和可解释机器学习基于的，用于分类高频和低频牛声，以及个体牛声识别。我们的模型在这两个框架中分别达到了 87.2% 和 89.4% 的准确率 для LF 和 HF 分类，以及 68.9% 和 72.5% 的准确率 для牛个体识别。”
</details></li>
</ul>
<hr>
<h2 id="Differentiable-short-time-Fourier-transform-with-respect-to-the-hop-length"><a href="#Differentiable-short-time-Fourier-transform-with-respect-to-the-hop-length" class="headerlink" title="Differentiable short-time Fourier transform with respect to the hop length"></a>Differentiable short-time Fourier transform with respect to the hop length</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02421">http://arxiv.org/abs/2308.02421</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/maxime-leiber/dstft">https://github.com/maxime-leiber/dstft</a></li>
<li>paper_authors: Maxime Leiber, Yosra Marnissi, Axel Barrau, Mohammed El Badaoui</li>
<li>for: 提出一种可微分的短时傅立叙 transform (STFT)，允许通过 kontinuous 的 hop 长或帧时间位置进行梯度下降优化。</li>
<li>methods: 使用 kontinuous 的 hop 长和帧时间位置进行梯度下降优化，提供更精细的时间位置控制。</li>
<li>results: 在 simulated 示例中，提出的方法可以更好地控制时间位置，并且可以轻松地与现有的算法和神经网络集成。<details>
<summary>Abstract</summary>
In this paper, we propose a differentiable version of the short-time Fourier transform (STFT) that allows for gradient-based optimization of the hop length or the frame temporal position by making these parameters continuous. Our approach provides improved control over the temporal positioning of frames, as the continuous nature of the hop length allows for a more finely-tuned optimization. Furthermore, our contribution enables the use of optimization methods such as gradient descent, which are more computationally efficient than conventional discrete optimization methods. Our differentiable STFT can also be easily integrated into existing algorithms and neural networks. We present a simulated illustration to demonstrate the efficacy of our approach and to garner interest from the research community.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种可微分的短时傅立叙变换（STFT），允许通过使这些参数变为连续的，进行梯度下降优化。我们的方法可以提供更好的控制时间位置，因为连续的跳跃长度允许更细化优化。此外，我们的贡献允许使用优化方法，如梯度下降，这些方法更有效率于传统的离散优化方法。我们的可微分STFT也可以轻松地与现有的算法和神经网络结合使用。我们在示例中提供了一个示例，以证明我们的方法的有效性，并且吸引研究人员的关注。
</details></li>
</ul>
<hr>
<h2 id="METAVerse-Meta-Learning-Traversability-Cost-Map-for-Off-Road-Navigation"><a href="#METAVerse-Meta-Learning-Traversability-Cost-Map-for-Off-Road-Navigation" class="headerlink" title="METAVerse: Meta-Learning Traversability Cost Map for Off-Road Navigation"></a>METAVerse: Meta-Learning Traversability Cost Map for Off-Road Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13991">http://arxiv.org/abs/2307.13991</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junwon Seo, Taekyung Kim, Seongyong Ahn, Kiho Kwak</li>
<li>for: 本研究旨在开发一种能够准确预测不同环境中的地形通行可能性的自适应导航系统。</li>
<li>methods: 该研究使用meta-学习框架，通过自我指导式方式，使用汽车-地面交互反馈来训练一个全球模型，从稀疏的LiDAR点云中生成一个连续值的成本图，以预测地形通行可能性。</li>
<li>results: 研究人员通过收集不同地形的驾驶数据，训练了一个全球模型，并在部署过程中进行了在线适应，以快速适应当地环境。这种方法能够减少预测uncertainty，并且可以安全地和稳定地导航在未知和未适应的地形中。<details>
<summary>Abstract</summary>
Autonomous navigation in off-road conditions requires an accurate estimation of terrain traversability. However, traversability estimation in unstructured environments is subject to high uncertainty due to the variability of numerous factors that influence vehicle-terrain interaction. Consequently, it is challenging to obtain a generalizable model that can accurately predict traversability in a variety of environments. This paper presents METAVerse, a meta-learning framework for learning a global model that accurately and reliably predicts terrain traversability across diverse environments. We train the traversability prediction network to generate a dense and continuous-valued cost map from a sparse LiDAR point cloud, leveraging vehicle-terrain interaction feedback in a self-supervised manner. Meta-learning is utilized to train a global model with driving data collected from multiple environments, effectively minimizing estimation uncertainty. During deployment, online adaptation is performed to rapidly adapt the network to the local environment by exploiting recent interaction experiences. To conduct a comprehensive evaluation, we collect driving data from various terrains and demonstrate that our method can obtain a global model that minimizes uncertainty. Moreover, by integrating our model with a model predictive controller, we demonstrate that the reduced uncertainty results in safe and stable navigation in unstructured and unknown terrains.
</details>
<details>
<summary>摘要</summary>
自主导航在不结构化环境中需要准确地估计地形通行能力。然而，在无结构环境中的通行能力估计受到许多因素的变化所致的高度不确定性的影响。因此，constructing a generalizable model that can accurately predict terrain traversability in a variety of environments is challenging. This paper presents METAVerse, a meta-learning framework for learning a global model that accurately and reliably predicts terrain traversability across diverse environments. We train the traversability prediction network to generate a dense and continuous-valued cost map from a sparse LiDAR point cloud, leveraging vehicle-terrain interaction feedback in a self-supervised manner. Meta-learning is utilized to train a global model with driving data collected from multiple environments, effectively minimizing estimation uncertainty. During deployment, online adaptation is performed to rapidly adapt the network to the local environment by exploiting recent interaction experiences. To conduct a comprehensive evaluation, we collect driving data from various terrains and demonstrate that our method can obtain a global model that minimizes uncertainty. Moreover, by integrating our model with a model predictive controller, we demonstrate that the reduced uncertainty results in safe and stable navigation in unstructured and unknown terrains.Note that Simplified Chinese is a written language that is used in mainland China, and it is different from Traditional Chinese, which is used in Taiwan and other parts of the world.
</details></li>
</ul>
<hr>
<h2 id="Differentiable-adaptive-short-time-Fourier-transform-with-respect-to-the-window-length"><a href="#Differentiable-adaptive-short-time-Fourier-transform-with-respect-to-the-window-length" class="headerlink" title="Differentiable adaptive short-time Fourier transform with respect to the window length"></a>Differentiable adaptive short-time Fourier transform with respect to the window length</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02418">http://arxiv.org/abs/2308.02418</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/maxime-leiber/dstft">https://github.com/maxime-leiber/dstft</a></li>
<li>paper_authors: Maxime Leiber, Yosra Marnissi, Axel Barrau, Mohammed El Badaoui</li>
<li>for: 这篇论文是为了提出一种基于梯度的方法，用于在实时进行 STFT 的优化，包括每帧和每频域窗口长的优化。</li>
<li>methods: 这篇论文使用了 differentiable STFT，并通过将窗口长变量化，使其成为可微分的。这使得可以使用梯度下降来优化 STFT。</li>
<li>results: 研究人员透过实验验证了他们的方法，并发现其可以很好地适应具有变动和站立 ком component的时间频率图表。<details>
<summary>Abstract</summary>
This paper presents a gradient-based method for on-the-fly optimization for both per-frame and per-frequency window length of the short-time Fourier transform (STFT), related to previous work in which we developed a differentiable version of STFT by making the window length a continuous parameter. The resulting differentiable adaptive STFT possesses commendable properties, such as the ability to adapt in the same time-frequency representation to both transient and stationary components, while being easily optimized by gradient descent. We validate the performance of our method in vibration analysis.
</details>
<details>
<summary>摘要</summary>
Here's the text in Simplified Chinese:这篇论文提出了一种基于梯度的方法，用于在实时中对STFT的每帧和每频窗长进行优化，与之前的工作相关，我们将STFT中的窗长作为连续参数来实现可导的STFT。这种可导的STFT具有许多优点，如适应同时频域中的激变和站ARY组件，同时也可以通过梯度下降方便地优化。我们在振荡分析中验证了这种方法的性能。
</details></li>
</ul>
<hr>
<h2 id="This-is-not-correct-Negation-aware-Evaluation-of-Language-Generation-Systems"><a href="#This-is-not-correct-Negation-aware-Evaluation-of-Language-Generation-Systems" class="headerlink" title="This is not correct! Negation-aware Evaluation of Language Generation Systems"></a>This is not correct! Negation-aware Evaluation of Language Generation Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13989">http://arxiv.org/abs/2307.13989</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dmlls/cannot-dataset">https://github.com/dmlls/cannot-dataset</a></li>
<li>paper_authors: Miriam Anschütz, Diego Miguel Lozano, Georg Groh</li>
<li>for: 本文为了解决大语言模型对否定语句的影响不充分评估，提出了一种基于否定语句的评估指标——NegBLEURT。</li>
<li>methods: 本文使用了一种基于规则的句子否定工具，并使用这个工具创建了CANNOT negation评估数据集。然后，通过这个数据集进行了一些模型的微调和评估指标的修改，以提高对否定语句的敏感性。</li>
<li>results: 对于现有的benchmark测试，我们的微调模型和评估指标在否定句子上表现出了很大的改善，而不会影响其他类型的折衣。<details>
<summary>Abstract</summary>
Large language models underestimate the impact of negations on how much they change the meaning of a sentence. Therefore, learned evaluation metrics based on these models are insensitive to negations. In this paper, we propose NegBLEURT, a negation-aware version of the BLEURT evaluation metric. For that, we designed a rule-based sentence negation tool and used it to create the CANNOT negation evaluation dataset. Based on this dataset, we fine-tuned a sentence transformer and an evaluation metric to improve their negation sensitivity. Evaluating these models on existing benchmarks shows that our fine-tuned models outperform existing metrics on the negated sentences by far while preserving their base models' performances on other perturbations.
</details>
<details>
<summary>摘要</summary>
大型语言模型会 під估算负语气对句子意思的影响。因此，基于这些模型的评估指标会忽略负语气。在这篇论文中，我们提出了NegBLEURT，一个负语气意识的版本的BLEURT评估指标。为此，我们设计了一个基于规则的句子负语气工具，并使用这个工具创建了CANNOT负语气评估集。基于这个集合，我们精微调整了句子转换器和评估指标，以改善它们对负语气的敏感性。在现有的测试基础上评估这些模型，我们发现我们的精微调整模型在负语气句子上大幅超越了现有的指标，而且保持了基本模型在其他折冲上的表现。
</details></li>
</ul>
<hr>
<h2 id="Controlling-the-Latent-Space-of-GANs-through-Reinforcement-Learning-A-Case-Study-on-Task-based-Image-to-Image-Translation"><a href="#Controlling-the-Latent-Space-of-GANs-through-Reinforcement-Learning-A-Case-Study-on-Task-based-Image-to-Image-Translation" class="headerlink" title="Controlling the Latent Space of GANs through Reinforcement Learning: A Case Study on Task-based Image-to-Image Translation"></a>Controlling the Latent Space of GANs through Reinforcement Learning: A Case Study on Task-based Image-to-Image Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13978">http://arxiv.org/abs/2307.13978</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahyar Abbasian, Taha Rajabzadeh, Ahmadreza Moradipari, Seyed Amir Hossein Aqajari, Hongsheng Lu, Amir Rahmani</li>
<li>for: 本研究旨在解决生成器网络中控制生成过程的挑战，通过结合激励学习（RL）Agent和幂变空间生成器（l-GAN）来实现恰当的输出生成。</li>
<li>methods: 我们提出了一种 integrate RL agent with l-GAN 的方法，包括设计了一个actor-critic RL agent和一个仔细设计的奖励策略，使得 agent 在 latent space 中穿梭并生成基于指定任务的输出。</li>
<li>results: 我们通过使用 MNIST  dataset 进行了一系列实验，包括数学运算的 illustrate task，实验结果证明了我们的方法的有效性。<details>
<summary>Abstract</summary>
Generative Adversarial Networks (GAN) have emerged as a formidable AI tool to generate realistic outputs based on training datasets. However, the challenge of exerting control over the generation process of GANs remains a significant hurdle. In this paper, we propose a novel methodology to address this issue by integrating a reinforcement learning (RL) agent with a latent-space GAN (l-GAN), thereby facilitating the generation of desired outputs. More specifically, we have developed an actor-critic RL agent with a meticulously designed reward policy, enabling it to acquire proficiency in navigating the latent space of the l-GAN and generating outputs based on specified tasks. To substantiate the efficacy of our approach, we have conducted a series of experiments employing the MNIST dataset, including arithmetic addition as an illustrative task. The outcomes of these experiments serve to validate our methodology. Our pioneering integration of an RL agent with a GAN model represents a novel advancement, holding great potential for enhancing generative networks in the future.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Mathematical-Modeling-of-BCG-based-Bladder-Cancer-Treatment-Using-Socio-Demographics"><a href="#Mathematical-Modeling-of-BCG-based-Bladder-Cancer-Treatment-Using-Socio-Demographics" class="headerlink" title="Mathematical Modeling of BCG-based Bladder Cancer Treatment Using Socio-Demographics"></a>Mathematical Modeling of BCG-based Bladder Cancer Treatment Using Socio-Demographics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15084">http://arxiv.org/abs/2307.15084</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elizaveta Savchenko, Ariel Rosenfeld, Svetlana Bunimovich-Mendrazitsky</li>
<li>for: 这个研究旨在提供一个基于患者的社会民主ographic信息的个性化BCG治疗模型，以提高BCG治疗的效果。</li>
<li>methods: 研究人员采用了一个已知的BCG治疗模型，并将machine learning成分integrated到模型中，以时间地调整和重配置关键参数，以便个性化治疗。</li>
<li>results: 使用实际临床数据，研究人员发现，个性化模型比原始模型在预测治疗结束时的癌细胞数量方面，有14.8%的改善，平均而言。<details>
<summary>Abstract</summary>
Cancer is one of the most widespread diseases around the world with millions of new patients each year. Bladder cancer is one of the most prevalent types of cancer affecting all individuals alike with no obvious prototypical patient. The current standard treatment for BC follows a routine weekly Bacillus Calmette-Guerin (BCG) immunotherapy-based therapy protocol which is applied to all patients alike. The clinical outcomes associated with BCG treatment vary significantly among patients due to the biological and clinical complexity of the interaction between the immune system, treatments, and cancer cells. In this study, we take advantage of the patient's socio-demographics to offer a personalized mathematical model that describes the clinical dynamics associated with BCG-based treatment. To this end, we adopt a well-established BCG treatment model and integrate a machine learning component to temporally adjust and reconfigure key parameters within the model thus promoting its personalization. Using real clinical data, we show that our personalized model favorably compares with the original one in predicting the number of cancer cells at the end of the treatment, with 14.8% improvement, on average.
</details>
<details>
<summary>摘要</summary>
癌症是全球最常见的疾病之一，每年新生癌病例数量达数百万。膀胱癌是最常见的癌病种之一，它对所有患者来说都是无型的。现行的BCG免疫疗法从业余周调度，这个调度是给所有患者都一样的。但是，BCG治疗的临床结果差强人之间，这是因为免疫系统、治疗和癌细胞之间的生物和临床复杂性。在这个研究中，我们利用患者的社会demographics来提供一个个性化的数学模型，描述BCG治疗的临床动力学。为此，我们采用了一个已知的BCG治疗模型，并将其整合了机器学习 ком成分，以时间地调整和重新配置关键参数，以便个性化。使用实际的临床数据，我们显示了我们的个性化模型与原始模型之间的比较，显示了14.8%的改善，平均而言。
</details></li>
</ul>
<hr>
<h2 id="Understanding-Deep-Neural-Networks-via-Linear-Separability-of-Hidden-Layers"><a href="#Understanding-Deep-Neural-Networks-via-Linear-Separability-of-Hidden-Layers" class="headerlink" title="Understanding Deep Neural Networks via Linear Separability of Hidden Layers"></a>Understanding Deep Neural Networks via Linear Separability of Hidden Layers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13962">http://arxiv.org/abs/2307.13962</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chao Zhang, Xinyu Chen, Wensheng Li, Lixue Liu, Wei Wu, Dacheng Tao</li>
<li>for: 研究深度神经网络的特点，尤其是隐藏层输出的线性可分性度。</li>
<li>methods: 提出了基于美丽度差（MD）的线性可分性度度量（LSM）来评估隐藏层输出的线性可分性度。</li>
<li>results: 发现隐藏层输出的线性可分性度和网络训练性能之间存在同步关系，即如果更新参数可以提高隐藏层输出的线性可分性度，则更新后的网络将在训练过程中表现更好，并且相反。此外，研究了活化函数和网络大小（包括宽度和深度）对隐藏层输出的线性可分性度的影响。<details>
<summary>Abstract</summary>
In this paper, we measure the linear separability of hidden layer outputs to study the characteristics of deep neural networks. In particular, we first propose Minkowski difference based linear separability measures (MD-LSMs) to evaluate the linear separability degree of two points sets. Then, we demonstrate that there is a synchronicity between the linear separability degree of hidden layer outputs and the network training performance, i.e., if the updated weights can enhance the linear separability degree of hidden layer outputs, the updated network will achieve a better training performance, and vice versa. Moreover, we study the effect of activation function and network size (including width and depth) on the linear separability of hidden layers. Finally, we conduct the numerical experiments to validate our findings on some popular deep networks including multilayer perceptron (MLP), convolutional neural network (CNN), deep belief network (DBN), ResNet, VGGNet, AlexNet, vision transformer (ViT) and GoogLeNet.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们测量了深度神经网络的线性可分性来研究它们的特点。特别是，我们首先提出了米诺夫差分基于的线性可分性度量（MD-LSM）来评估两个点集的线性可分性度。然后，我们证明了深度神经网络训练性能和隐层输出的线性可分性度之间存在同步关系，即如果更新的权重可以提高隐层输出的线性可分性度，那么更新后的网络将获得更好的训练性能，并且vice versa。此外，我们研究了活动函数和网络大小（包括宽和深）对隐层输出的线性可分性的影响。最后，我们进行了一些实验来验证我们的发现，并在多层感知网络（MLP）、卷积神经网络（CNN）、深度信念网络（DBN）、ResNet、VGGNet、AlexNet、视transformer（ViT）和GoogLeNet等 популяр的深度神经网络上进行了实验。
</details></li>
</ul>
<hr>
<h2 id="Flexible-Differentially-Private-Vertical-Federated-Learning-with-Adaptive-Feature-Embeddings"><a href="#Flexible-Differentially-Private-Vertical-Federated-Learning-with-Adaptive-Feature-Embeddings" class="headerlink" title="Flexible Differentially Private Vertical Federated Learning with Adaptive Feature Embeddings"></a>Flexible Differentially Private Vertical Federated Learning with Adaptive Feature Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02362">http://arxiv.org/abs/2308.02362</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxi Mi, Hongquan Liu, Yewei Xia, Yiheng Sun, Jihong Guan, Shuigeng Zhou</li>
<li>for: 保护数据隐私和实现任务目标之间的平衡，针对垂直联合学习中的敏感信息泄露问题。</li>
<li>methods: 提出一种灵活和通用的方法，通过分解两个目标来解决这两个目标之间的矛盾，首先通过norm clipping来确保隐私保护，然后通过adaptive调整特征编码的扩展和分布来提高任务性能，保持先前的隐私机制。</li>
<li>results: 经验表明，提出的VFL-AFE框架能够有效地防止隐私泄露和保持任务性能，并且可以适应不同的数据集和模型。<details>
<summary>Abstract</summary>
The emergence of vertical federated learning (VFL) has stimulated concerns about the imperfection in privacy protection, as shared feature embeddings may reveal sensitive information under privacy attacks. This paper studies the delicate equilibrium between data privacy and task utility goals of VFL under differential privacy (DP). To address the generality issue of prior arts, this paper advocates a flexible and generic approach that decouples the two goals and addresses them successively. Specifically, we initially derive a rigorous privacy guarantee by applying norm clipping on shared feature embeddings, which is applicable across various datasets and models. Subsequently, we demonstrate that task utility can be optimized via adaptive adjustments on the scale and distribution of feature embeddings in an accuracy-appreciative way, without compromising established DP mechanisms. We concretize our observation into the proposed VFL-AFE framework, which exhibits effectiveness against privacy attacks and the capacity to retain favorable task utility, as substantiated by extensive experiments.
</details>
<details>
<summary>摘要</summary>
《垂直联邦学习（VFL）的出现引发了隐私保护的担忧，因为共享特征嵌入可能会泄露敏感信息在隐私攻击下。这篇论文研究了VFL中数据隐私和任务使用目标之间的敏感平衡，通过减少隐私攻击的方法来保护隐私。为了普适性，这篇论文提出了一种灵活和通用的方法，将数据隐私和任务使用目标分开，然后一一地处理它们。具体来说，我们首先通过在共享特征嵌入中应用范围clip来确保隐私保障，这种方法适用于不同的数据集和模型。然后，我们表明了可以通过对特征嵌入的扩缩和分布进行适应调整，以提高任务使用度，而不会违反已有的隐私机制。我们将这种观察结合到VFL-AFE框架中，该框架能够具有防止隐私攻击和保持任务使用度的能力，经过广泛的实验证明。》Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Entropy-Neural-Estimation-for-Graph-Contrastive-Learning"><a href="#Entropy-Neural-Estimation-for-Graph-Contrastive-Learning" class="headerlink" title="Entropy Neural Estimation for Graph Contrastive Learning"></a>Entropy Neural Estimation for Graph Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13944">http://arxiv.org/abs/2307.13944</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kunzhan/M-ILBO">https://github.com/kunzhan/M-ILBO</a></li>
<li>paper_authors: Yixuan Ma, Xiaolin Zhang, Peng Zhang, Kun Zhan</li>
<li>for: 本 paper 目的是提取图像中节点的可区分高级表示。</li>
<li>methods: 作者提出了一种使用 neural network 来估计数据集的熵，并使用这个熵来提取图像中节点的高级表示。他们还提出了一种subset sampling strategy来对图像进行对比，并使用两个目标函数同时优化网络。</li>
<li>results: 作者在七个图像 benchmark 上进行了广泛的实验，并取得了与当前状态艺术法相当的性能。<details>
<summary>Abstract</summary>
Contrastive learning on graphs aims at extracting distinguishable high-level representations of nodes. In this paper, we theoretically illustrate that the entropy of a dataset can be approximated by maximizing the lower bound of the mutual information across different views of a graph, \ie, entropy is estimated by a neural network. Based on this finding, we propose a simple yet effective subset sampling strategy to contrast pairwise representations between views of a dataset. In particular, we randomly sample nodes and edges from a given graph to build the input subset for a view. Two views are fed into a parameter-shared Siamese network to extract the high-dimensional embeddings and estimate the information entropy of the entire graph. For the learning process, we propose to optimize the network using two objectives, simultaneously. Concretely, the input of the contrastive loss function consists of positive and negative pairs. Our selection strategy of pairs is different from previous works and we present a novel strategy to enhance the representation ability of the graph encoder by selecting nodes based on cross-view similarities. We enrich the diversity of the positive and negative pairs by selecting highly similar samples and totally different data with the guidance of cross-view similarity scores, respectively. We also introduce a cross-view consistency constraint on the representations generated from the different views. This objective guarantees the learned representations are consistent across views from the perspective of the entire graph. We conduct extensive experiments on seven graph benchmarks, and the proposed approach achieves competitive performance compared to the current state-of-the-art methods. The source code will be publicly released once this paper is accepted.
</details>
<details>
<summary>摘要</summary>
“对图进行对比学习的目标是提取图像中节点的明确高级表示。在这篇论文中，我们理论上验证了对于不同视图的图集， Entropy 的估计可以通过最大化不同视图之间的互信息lower bound来进行approximation。基于这个发现，我们提出了一种简单 yet effective的subset sampling策略，即在给定图集中随机选择节点和边，并将其作为视图的输入子集来建立。两个视图被feed into a shared参数的siamesenetwork中，以EXTRACT高维表示和估算整个图集的Entropy。在学习过程中，我们提出了两个目标函数，同时进行优化。具体来说，输入对比损失函数的输入包括正例和负例。我们的选择策略与之前的作品不同，我们提出了一种新的选择策略，根据不同视图的相似性来选择节点。我们通过选择高度相似的样本和完全不同的数据来增强图像编码器的表示能力。此外，我们还引入了跨视图一致性约束，这个约束保证了学习到的表示是视图的整个图集的一致的表示。我们在七个图基本 benchmark 上进行了广泛的实验，并发现我们的方法与当前状态的艺术方法相当竞争。我们将代码公开发布一旦这篇论文被接受。”
</details></li>
</ul>
<hr>
<h2 id="Topology-aware-Robust-Optimization-for-Out-of-distribution-Generalization"><a href="#Topology-aware-Robust-Optimization-for-Out-of-distribution-Generalization" class="headerlink" title="Topology-aware Robust Optimization for Out-of-distribution Generalization"></a>Topology-aware Robust Optimization for Out-of-distribution Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13943">http://arxiv.org/abs/2307.13943</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/joffery/tro">https://github.com/joffery/tro</a></li>
<li>paper_authors: Fengchun Qiao, Xi Peng</li>
<li>for: 该研究旨在提高机器学习模型对非典型数据的鲁棒性，以适应高风险应用场景。</li>
<li>methods: 该研究提出了一种基于分布 topological structure的 robust optimization 方法，即 Topology-aware Robust Optimization (TRO)，其包括两个优化目标：(1) Topology Learning 探索数据抽象表示的分布 topological structure; (2) Learning on Topology 利用分布 topological structure来约束robust优化，以避免过度优化。</li>
<li>results: 研究证明了 TRO 的有效性，并在多种任务，如分类、回归和semantic segmentation 中显著超越了现有方法。此外，研究发现数据驱动的分布 topological structure与领域知识相一致，从而提高了该方法的解释性。<details>
<summary>Abstract</summary>
Out-of-distribution (OOD) generalization is a challenging machine learning problem yet highly desirable in many high-stake applications. Existing methods suffer from overly pessimistic modeling with low generalization confidence. As generalizing to arbitrary test distributions is impossible, we hypothesize that further structure on the topology of distributions is crucial in developing strong OOD resilience. To this end, we propose topology-aware robust optimization (TRO) that seamlessly integrates distributional topology in a principled optimization framework. More specifically, TRO solves two optimization objectives: (1) Topology Learning which explores data manifold to uncover the distributional topology; (2) Learning on Topology which exploits the topology to constrain robust optimization for tightly-bounded generalization risks. We theoretically demonstrate the effectiveness of our approach and empirically show that it significantly outperforms the state of the arts in a wide range of tasks including classification, regression, and semantic segmentation. Moreover, we empirically find the data-driven distributional topology is consistent with domain knowledge, enhancing the explainability of our approach.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Improving-Semi-Supervised-Semantic-Segmentation-with-Dual-Level-Siamese-Structure-Network"><a href="#Improving-Semi-Supervised-Semantic-Segmentation-with-Dual-Level-Siamese-Structure-Network" class="headerlink" title="Improving Semi-Supervised Semantic Segmentation with Dual-Level Siamese Structure Network"></a>Improving Semi-Supervised Semantic Segmentation with Dual-Level Siamese Structure Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13938">http://arxiv.org/abs/2307.13938</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kunzhan/DSSN">https://github.com/kunzhan/DSSN</a></li>
<li>paper_authors: Zhibo Tain, Xiaolin Zhang, Peng Zhang, Kun Zhan</li>
<li>for: 提高semantic segmentation任务中使用无标数据的效果，降低标注训练示例的成本。</li>
<li>methods: 提出了一种双级套件结构网络（DSSN），通过在低级图像空间和高级特征空间进行像素级强制对应，以便充分利用可用的无标数据。同时，引入了一种新的分类意识 pseudo-label 选择策略，用于 Addressing the limitations of most existing methods that do not perform selection or apply a predefined threshold for all classes。</li>
<li>results: 在 PASCAL VOC 2012 和 Cityscapes 两个预测集上达到了领先的状态态结果，与其他 SSS 算法相比，具有显著的优势。<details>
<summary>Abstract</summary>
Semi-supervised semantic segmentation (SSS) is an important task that utilizes both labeled and unlabeled data to reduce expenses on labeling training examples. However, the effectiveness of SSS algorithms is limited by the difficulty of fully exploiting the potential of unlabeled data. To address this, we propose a dual-level Siamese structure network (DSSN) for pixel-wise contrastive learning. By aligning positive pairs with a pixel-wise contrastive loss using strong augmented views in both low-level image space and high-level feature space, the proposed DSSN is designed to maximize the utilization of available unlabeled data. Additionally, we introduce a novel class-aware pseudo-label selection strategy for weak-to-strong supervision, which addresses the limitations of most existing methods that do not perform selection or apply a predefined threshold for all classes. Specifically, our strategy selects the top high-confidence prediction of the weak view for each class to generate pseudo labels that supervise the strong augmented views. This strategy is capable of taking into account the class imbalance and improving the performance of long-tailed classes. Our proposed method achieves state-of-the-art results on two datasets, PASCAL VOC 2012 and Cityscapes, outperforming other SSS algorithms by a significant margin.
</details>
<details>
<summary>摘要</summary>
semi-supervised semantic segmentation（SSS）是一项重要的任务，它利用了标注和无标注数据来降低标注训练示例的成本。然而，SSS算法的效iveness受到无标注数据的具体性的限制。为了解决这个问题，我们提议了一种双级SIAMESE结构网络（DSSN） для像素级对比学习。我们使用了强制对augmented views的像素级和高级特征空间进行对比，以使得提议的DSSN能够充分利用可用的无标注数据。此外，我们还引入了一种新的类意识 pseudo-label 选择策略，以Addressing the limitations of most existing methods that do not perform selection or apply a predefined threshold for all classes. Specifically, our strategy selects the top high-confidence prediction of the weak view for each class to generate pseudo labels that supervise the strong augmented views. This strategy is capable of taking into account the class imbalance and improving the performance of long-tailed classes. Our proposed method achieves state-of-the-art results on two datasets, PASCAL VOC 2012 and Cityscapes, outperforming other SSS algorithms by a significant margin.
</details></li>
</ul>
<hr>
<h2 id="trajdata-A-Unified-Interface-to-Multiple-Human-Trajectory-Datasets"><a href="#trajdata-A-Unified-Interface-to-Multiple-Human-Trajectory-Datasets" class="headerlink" title="trajdata: A Unified Interface to Multiple Human Trajectory Datasets"></a>trajdata: A Unified Interface to Multiple Human Trajectory Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13924">http://arxiv.org/abs/2307.13924</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nvlabs/trajdata">https://github.com/nvlabs/trajdata</a></li>
<li>paper_authors: Boris Ivanovic, Guanyu Song, Igor Gilitschenski, Marco Pavone</li>
<li>for: 本研究目的是提供一个统一的人行走轨迹数据接口，以便对多个人行走数据集进行训练和评估。</li>
<li>methods: 本研究使用了一个简单、通用、高效的数据表示和API，以探讨现有的人行走数据集。</li>
<li>results: 本研究提供了一个全面的实验分析，以帮助研究人员更好地理解现有的人行走数据集，并提出了未来数据集的建议。<details>
<summary>Abstract</summary>
The field of trajectory forecasting has grown significantly in recent years, partially owing to the release of numerous large-scale, real-world human trajectory datasets for autonomous vehicles (AVs) and pedestrian motion tracking. While such datasets have been a boon for the community, they each use custom and unique data formats and APIs, making it cumbersome for researchers to train and evaluate methods across multiple datasets. To remedy this, we present trajdata: a unified interface to multiple human trajectory datasets. At its core, trajdata provides a simple, uniform, and efficient representation and API for trajectory and map data. As a demonstration of its capabilities, in this work we conduct a comprehensive empirical evaluation of existing trajectory datasets, providing users with a rich understanding of the data underpinning much of current pedestrian and AV motion forecasting research, and proposing suggestions for future datasets from these insights. trajdata is permissively licensed (Apache 2.0) and can be accessed online at https://github.com/NVlabs/trajdata
</details>
<details>
<summary>摘要</summary>
领域轨迹预测在最近几年内得到了广泛发展，部分归功于许多大规模的实际世界人员轨迹数据集的发布，用于自动驾驶车（AV）和人行轨迹跟踪。然而，这些数据集各自使用自定义的数据格式和API，使研究人员在多个数据集之间训练和评估方法变得困难。为解决这个问题，我们提出了trajdata：一个统一的接口，用于多个人轨迹数据集。trajdata的核心思想是提供简单、统一的轨迹和地图数据表示和API。在这篇论文中，我们进行了详细的实验性评估，对现有的轨迹数据集进行了全面的检验，并提出了将来数据集的建议。trajdata是允许任意使用（Apache 2.0），可以在https://github.com/NVlabs/trajdata上线上访问。
</details></li>
</ul>
<hr>
<h2 id="HyperFed-Hyperbolic-Prototypes-Exploration-with-Consistent-Aggregation-for-Non-IID-Data-in-Federated-Learning"><a href="#HyperFed-Hyperbolic-Prototypes-Exploration-with-Consistent-Aggregation-for-Non-IID-Data-in-Federated-Learning" class="headerlink" title="HyperFed: Hyperbolic Prototypes Exploration with Consistent Aggregation for Non-IID Data in Federated Learning"></a>HyperFed: Hyperbolic Prototypes Exploration with Consistent Aggregation for Non-IID Data in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14384">http://arxiv.org/abs/2307.14384</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinting Liao, Weiming Liu, Chaochao Chen, Pengyang Zhou, Huabin Zhu, Yanchao Tan, Jun Wang, Yue Qi</li>
<li>for: 提高 Federated Learning (FL) 下非标一致数据的表现</li>
<li>methods: 使用 Hyperbolic Prototype Tammes Initialization (HPTI)、Hyperbolic Prototype Learning (HPL) 和 Consistent Aggregation (CA) 模块</li>
<li>results: 在四个数据集上进行了广泛的研究，证明 HyperFed 能够有效提高 FL 下非标一致数据的表现<details>
<summary>Abstract</summary>
Federated learning (FL) collaboratively models user data in a decentralized way. However, in the real world, non-identical and independent data distributions (non-IID) among clients hinder the performance of FL due to three issues, i.e., (1) the class statistics shifting, (2) the insufficient hierarchical information utilization, and (3) the inconsistency in aggregating clients. To address the above issues, we propose HyperFed which contains three main modules, i.e., hyperbolic prototype Tammes initialization (HPTI), hyperbolic prototype learning (HPL), and consistent aggregation (CA). Firstly, HPTI in the server constructs uniformly distributed and fixed class prototypes, and shares them with clients to match class statistics, further guiding consistent feature representation for local clients. Secondly, HPL in each client captures the hierarchical information in local data with the supervision of shared class prototypes in the hyperbolic model space. Additionally, CA in the server mitigates the impact of the inconsistent deviations from clients to server. Extensive studies of four datasets prove that HyperFed is effective in enhancing the performance of FL under the non-IID set.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>类别统计移动2. 缺乏层次信息利用3. 客户端聚合不一致为解决以上问题，我们提出了 HyperFed，它包括以下三个主要模块：1. hyperbolic prototype Tammes initialization (HPTI)：在服务器端，constructs uniformly distributed和 fixes 类别 prototype，并将其分享给客户端，以匹配类别统计，并且引导客户端的准确特征表示。2. hyperbolic prototype learning (HPL)：在每个客户端上，使用分布式hyperbolic模型，在shared class prototype的超visions下，捕捉本地数据中的层次信息。3. consistent aggregation (CA)：在服务器端，mitigates the impact of inconsistent deviations from clients to server。我们对四个数据集进行了广泛的研究，证明了 HyperFed 可以在非Identical和独立的客户端数据下提高 FL 的性能。</details></li>
</ol>
<hr>
<h2 id="Simulation-based-Inference-for-Cardiovascular-Models"><a href="#Simulation-based-Inference-for-Cardiovascular-Models" class="headerlink" title="Simulation-based Inference for Cardiovascular Models"></a>Simulation-based Inference for Cardiovascular Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13918">http://arxiv.org/abs/2307.13918</a></li>
<li>repo_url: None</li>
<li>paper_authors: Antoine Wehenkel, Jens Behrmann, Andrew C. Miller, Guillermo Sapiro, Ozan Sener, Marco Cuturi, Jörn-Henrik Jacobsen</li>
<li>for: 这 paper 是为了研究 cardiovascular systems 的实验室模拟工具，以及将 physiological parameters 映射回到可能的 waveforms 中。</li>
<li>methods: 这 paper 使用 simulation-based inference (SBI) 方法，通过 statistical inference 来解决 inverse problem，并提供了 multi-dimensional 的 uncertainty 表示。</li>
<li>results: 这 paper 的研究结果表明，SBI 可以为 five biomarkers of clinical interest 提供可靠的 estimations，并且可以捕捉到 standard sensitivity analyses 无法捕捉到的实用信息，如 parameter estimation 的不同不同 uncertainty regimes。<details>
<summary>Abstract</summary>
Over the past decades, hemodynamics simulators have steadily evolved and have become tools of choice for studying cardiovascular systems in-silico. While such tools are routinely used to simulate whole-body hemodynamics from physiological parameters, solving the corresponding inverse problem of mapping waveforms back to plausible physiological parameters remains both promising and challenging. Motivated by advances in simulation-based inference (SBI), we cast this inverse problem as statistical inference. In contrast to alternative approaches, SBI provides \textit{posterior distributions} for the parameters of interest, providing a \textit{multi-dimensional} representation of uncertainty for \textit{individual} measurements. We showcase this ability by performing an in-silico uncertainty analysis of five biomarkers of clinical interest comparing several measurement modalities. Beyond the corroboration of known facts, such as the feasibility of estimating heart rate, our study highlights the potential of estimating new biomarkers from standard-of-care measurements. SBI reveals practically relevant findings that cannot be captured by standard sensitivity analyses, such as the existence of sub-populations for which parameter estimation exhibits distinct uncertainty regimes. Finally, we study the gap between in-vivo and in-silico with the MIMIC-III waveform database and critically discuss how cardiovascular simulations can inform real-world data analysis.
</details>
<details>
<summary>摘要</summary>
Inspired by advances in simulation-based inference (SBI), we approach this inverse problem as a statistical inference problem. Unlike other methods, SBI provides a distribution of posterior probabilities for the parameters of interest, providing a multi-dimensional representation of uncertainty for individual measurements. We demonstrate the power of SBI by performing an in-silico uncertainty analysis of five biomarkers of clinical interest using different measurement modalities.Our study confirms known facts, such as the feasibility of estimating heart rate, and highlights the potential of estimating new biomarkers from standard-of-care measurements. SBI reveals practically relevant findings that cannot be captured by standard sensitivity analyses, such as the existence of sub-populations with distinct uncertainty regimes. Finally, we compare in-vivo and in-silico data using the MIMIC-III waveform database and discuss how cardiovascular simulations can inform real-world data analysis.
</details></li>
</ul>
<hr>
<h2 id="BayesDAG-Gradient-Based-Posterior-Sampling-for-Causal-Discovery"><a href="#BayesDAG-Gradient-Based-Posterior-Sampling-for-Causal-Discovery" class="headerlink" title="BayesDAG: Gradient-Based Posterior Sampling for Causal Discovery"></a>BayesDAG: Gradient-Based Posterior Sampling for Causal Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13917">http://arxiv.org/abs/2307.13917</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yashas Annadani, Nick Pawlowski, Joel Jennings, Stefan Bauer, Cheng Zhang, Wenbo Gong</li>
<li>for: 本研究旨在推断 causal 模型的 posterior 分布，Quantifying 认知不确定性并对下游任务产生积极影响。</li>
<li>methods: 我们引入了一种可扩展的 Bayesian causal discovery 框架，基于 Stochastic Gradient Markov Chain Monte Carlo (SG-MCMC)，可以缓解现有的计算挑战。我们的方法可以直接从 posterior 中抽取 DAGs，不需要任何 DAG 正则化，同时可以同时抽取函数参数样本，并适用于线性和非线性 causal 模型。</li>
<li>results: 我们的方法在 synthetic 和实际数据上进行了 empirical 评估，与 state-of-the-art 基准集比较，并达到了更高的效果。<details>
<summary>Abstract</summary>
Bayesian causal discovery aims to infer the posterior distribution over causal models from observed data, quantifying epistemic uncertainty and benefiting downstream tasks. However, computational challenges arise due to joint inference over combinatorial space of Directed Acyclic Graphs (DAGs) and nonlinear functions. Despite recent progress towards efficient posterior inference over DAGs, existing methods are either limited to variational inference on node permutation matrices for linear causal models, leading to compromised inference accuracy, or continuous relaxation of adjacency matrices constrained by a DAG regularizer, which cannot ensure resulting graphs are DAGs. In this work, we introduce a scalable Bayesian causal discovery framework based on stochastic gradient Markov Chain Monte Carlo (SG-MCMC) that overcomes these limitations. Our approach directly samples DAGs from the posterior without requiring any DAG regularization, simultaneously draws function parameter samples and is applicable to both linear and nonlinear causal models. To enable our approach, we derive a novel equivalence to the permutation-based DAG learning, which opens up possibilities of using any relaxed gradient estimator defined over permutations. To our knowledge, this is the first framework applying gradient-based MCMC sampling for causal discovery. Empirical evaluations on synthetic and real-world datasets demonstrate our approach's effectiveness compared to state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
bayesian causal discovery 目的是从观察数据中推断 posterior 分布 над causal models，量化 epistemic uncertainty 并且提高下游任务的表现。然而，因为joint inference  над combinatorial space of Directed Acyclic Graphs (DAGs) 和 nonlinear functions 而产生计算挑战。尽管最近有些进展在 posterior inference  над DAGs 上，现有的方法是 either limited to variational inference on node permutation matrices for linear causal models，导致推断精度受限，或者 continuous relaxation of adjacency matrices constrained by a DAG regularizer，无法确保得到的图是 DAGs。在这种情况下，我们提出了一个可扩展的 bayesian causal discovery 框架，基于 Stochastic Gradient Markov Chain Monte Carlo (SG-MCMC)。我们的方法可以直接从 posterior 中抽出 DAGs，无需任何 DAG regularization，同时同时 draw function parameter samples 和可以应用于 linear 和 nonlinear causal models。为了实现我们的方法，我们 derive 了一种新的 permutation-based DAG learning 的等价关系，这使得可以使用任何 relaxed gradient estimator defined over permutations。到我们所知，这是第一个 applying gradient-based MCMC sampling for causal discovery 的框架。我们的实验表明，我们的方法可以与现有的基准值相比，在 synthetic 和实际世界数据上表现更好。
</details></li>
</ul>
<hr>
<h2 id="Online-learning-in-bandits-with-predicted-context"><a href="#Online-learning-in-bandits-with-predicted-context" class="headerlink" title="Online learning in bandits with predicted context"></a>Online learning in bandits with predicted context</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13916">http://arxiv.org/abs/2307.13916</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongyi Guo, Susan Murphy</li>
<li>for:  solve the contextual bandit problem with non-diminishing context error</li>
<li>methods:  extend the measurement error model in classical statistics to the online decision-making setting</li>
<li>results:  achieve sublinear regret compared to the appropriate benchmark<details>
<summary>Abstract</summary>
We consider the contextual bandit problem where at each time, the agent only has access to a noisy version of the context and the error variance (or an estimator of this variance). This setting is motivated by a wide range of applications where the true context for decision-making is unobserved, and only a prediction of the context by a potentially complex machine learning algorithm is available. When the context error is non-diminishing, classical bandit algorithms fail to achieve sublinear regret. We propose the first online algorithm in this setting with sublinear regret compared to the appropriate benchmark. The key idea is to extend the measurement error model in classical statistics to the online decision-making setting, which is nontrivial due to the policy being dependent on the noisy context observations.
</details>
<details>
<summary>摘要</summary>
我团队考虑了 Contextual Bandit 问题，在每个时间点，机器人只有访问一个含有噪声的上下文的机会。这种设定是由各种应用场景所驱动，其中真实的决策上下文未知，仅可获取一个可能复杂的机器学习算法预测的上下文预测。当上下文噪声不逐渐减少时， classical bandit 算法无法实现 суб线性快悟。我们提出了首个在这种设定下的在线算法，与相应的 referent 相比，具有 суб线性快悟。主要想法是将 classical statistics 中的 measurement error model 扩展到在线决策设定中，这是由于决策取决于噪声上下文观测的政策依赖关系。
</details></li>
</ul>
<hr>
<h2 id="Graph-Neural-Networks-based-Hybrid-Framework-For-Predicting-Particle-Crushing-Strength"><a href="#Graph-Neural-Networks-based-Hybrid-Framework-For-Predicting-Particle-Crushing-Strength" class="headerlink" title="Graph Neural Networks-based Hybrid Framework For Predicting Particle Crushing Strength"></a>Graph Neural Networks-based Hybrid Framework For Predicting Particle Crushing Strength</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13909">http://arxiv.org/abs/2307.13909</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/doujiang-zheng/gnn-for-particle-crushing">https://github.com/doujiang-zheng/gnn-for-particle-crushing</a></li>
<li>paper_authors: Tongya Zheng, Tianli Zhang, Qingzheng Guan, Wenjie Huang, Zunlei Feng, Mingli Song, Chun Chen</li>
<li>for:  This paper aims to characterize the mechanical behaviors of particle crushing through the connectivity of particle fragments with Graph Neural Networks (GNNs) and to facilitate the research progress of machine learning for particle crushing by generating a large-scale dataset.</li>
<li>methods:  The authors use a hybrid framework based on GNNs to predict particle crushing strength in a particle fragment view, and compare their hybrid framework against traditional machine learning methods and the plain MLP to verify its effectiveness.</li>
<li>results:  The authors generate a dataset with 45,000 numerical simulations and 900 particle types, and their hybrid framework achieves better performance than traditional machine learning methods and the plain MLP. They also discuss the usefulness of different features through gradient attribution explanation w.r.t the predictions.<details>
<summary>Abstract</summary>
Graph Neural Networks have emerged as an effective machine learning tool for multi-disciplinary tasks such as pharmaceutical molecule classification and chemical reaction prediction, because they can model non-euclidean relationships between different entities. Particle crushing, as a significant field of civil engineering, describes the breakage of granular materials caused by the breakage of particle fragment bonds under the modeling of numerical simulations, which motivates us to characterize the mechanical behaviors of particle crushing through the connectivity of particle fragments with Graph Neural Networks (GNNs). However, there lacks an open-source large-scale particle crushing dataset for research due to the expensive costs of laboratory tests or numerical simulations. Therefore, we firstly generate a dataset with 45,000 numerical simulations and 900 particle types to facilitate the research progress of machine learning for particle crushing. Secondly, we devise a hybrid framework based on GNNs to predict particle crushing strength in a particle fragment view with the advances of state of the art GNNs. Finally, we compare our hybrid framework against traditional machine learning methods and the plain MLP to verify its effectiveness. The usefulness of different features is further discussed through the gradient attribution explanation w.r.t the predictions. Our data and code are released at https://github.com/doujiang-zheng/GNN-For-Particle-Crushing.
</details>
<details>
<summary>摘要</summary>
图 neural network 已成为多学科任务的有效机器学习工具，如药品分类和化学反应预测，因为它可以模型不对称关系 между不同实体。在 civil engineering 中， particulate crushing 描述了受 fragment bond 的破坏而导致的 granular material 的破坏，这使我们想使用 GNN 来描述 particulate crushing 的机械行为。然而，由于实验室测试或数值 simulate 的成本太高，因此在 particle crushing 领域中缺乏开源大规模数据集，以便进行研究。因此，我们首先生成了一个数据集，包含 45,000 个数值 simulate 和 900 种 particule type，以促进机器学习在 particle crushing 领域的研究进步。其次，我们开发了基于 GNN 的混合框架，用于预测 particulate crushing 的强度在 particule fragment 视角中。最后，我们比较了我们的混合框架与传统机器学习方法和平方多层感知网络，以验证其效果。此外，我们还通过 gradient attribution 的解释来评估不同特征的用用。我们的数据和代码在 GitHub 上发布，请参考 https://github.com/doujiang-zheng/GNN-For-Particle-Crushing。
</details></li>
</ul>
<hr>
<h2 id="Robustness-Verification-of-Deep-Neural-Networks-using-Star-Based-Reachability-Analysis-with-Variable-Length-Time-Series-Input"><a href="#Robustness-Verification-of-Deep-Neural-Networks-using-Star-Based-Reachability-Analysis-with-Variable-Length-Time-Series-Input" class="headerlink" title="Robustness Verification of Deep Neural Networks using Star-Based Reachability Analysis with Variable-Length Time Series Input"></a>Robustness Verification of Deep Neural Networks using Star-Based Reachability Analysis with Variable-Length Time Series Input</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13907">http://arxiv.org/abs/2307.13907</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neelanjana Pal, Diego Manzanas Lopez, Taylor T Johnson<br>for:这个研究探讨了如何使用神经网络（NN）进行资料驱动的异常探测和预测维护，并将注意力集中在时间序列资料的NN-基的分析方法上。methods:这篇论文使用了设计 Variable-length input 来简化输入处理并增强网络架构的可扩展性。它还使用了星形可达分析来检验NN的 Robustness，并使用了多个性能指标来衡量对输入噪声的影响。results:这篇论文发现，这些NN-based analytics 具有高度的Robustness，并且可以对时间序列资料进行高精度的预测。它还发现，这些NNs 对于不同的输入噪声情况下的预测结果稳定且可靠。<details>
<summary>Abstract</summary>
Data-driven, neural network (NN) based anomaly detection and predictive maintenance are emerging research areas. NN-based analytics of time-series data offer valuable insights into past behaviors and estimates of critical parameters like remaining useful life (RUL) of equipment and state-of-charge (SOC) of batteries. However, input time series data can be exposed to intentional or unintentional noise when passing through sensors, necessitating robust validation and verification of these NNs. This paper presents a case study of the robustness verification approach for time series regression NNs (TSRegNN) using set-based formal methods. It focuses on utilizing variable-length input data to streamline input manipulation and enhance network architecture generalizability. The method is applied to two data sets in the Prognostics and Health Management (PHM) application areas: (1) SOC estimation of a Lithium-ion battery and (2) RUL estimation of a turbine engine. The NNs' robustness is checked using star-based reachability analysis, and several performance measures evaluate the effect of bounded perturbations in the input on network outputs, i.e., future outcomes. Overall, the paper offers a comprehensive case study for validating and verifying NN-based analytics of time-series data in real-world applications, emphasizing the importance of robustness testing for accurate and reliable predictions, especially considering the impact of noise on future outcomes.
</details>
<details>
<summary>摘要</summary>
数据驱动、基于神经网络（NN）的异常检测和预测维护是当前研究领域的新兴领域。NN基于时间序列数据的分析可以为过去行为提供有价值的洞察，并估计设备的剩余有用生命（RUL）和电池的状态充电（SOC）。然而，输入时间序列数据可能会受到意外或非意外的噪声影响，因此需要Robust验证和验证这些NN。这篇论文介绍了对时间序列回归NN（TSRegNN）的Robust验证方法，使用变量长度输入数据来简化输入处理和提高网络架构的通用性。该方法在两个PHM应用领域的数据集上进行了应用：（1）离子电池SOC估计和（2）涡轮机RUL估计。NN的Robustness通过星形可达分析进行检查，并通过一些性能指标评估输入噪声对网络输出的影响，即未来的结果。总之，这篇论文提供了实际应用中验证和验证NN基于时间序列数据的分析的全面的案例研究，强调Robust验证的重要性，特别是考虑噪声对未来结果的影响。
</details></li>
</ul>
<hr>
<h2 id="Corruption-Robust-Lipschitz-Contextual-Search"><a href="#Corruption-Robust-Lipschitz-Contextual-Search" class="headerlink" title="Corruption-Robust Lipschitz Contextual Search"></a>Corruption-Robust Lipschitz Contextual Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13903">http://arxiv.org/abs/2307.13903</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiliang Zuo</li>
<li>for: 学习一个 lipschitz 函数，即 adversary 选择的函数 $f$。</li>
<li>methods: 使用 natural yet powerful technique sanity check，设计了 corruption-robust 算法。</li>
<li>results: 对于 symmetric loss， learner 的 regret 为 $O(C\log T)$ （其中 $d &#x3D; 1$），或 $O_d(C\log T + T^{(d-1)&#x2F;d})$（其中 $d &gt; 1$）；对于 pricing loss， learner 的 regret 为 $\widetilde{O} (T^{d&#x2F;(d+1)} + C\cdot T^{1&#x2F;(d+1)})$。<details>
<summary>Abstract</summary>
I study the problem of learning a Lipschitz function with corrupted binary signals. The learner tries to learn a Lipschitz function $f$ that the adversary chooses. In each round, the adversary selects a context vector $x_t$ in the input space, and the learner makes a guess to the true function value $f(x_t)$ and receives a binary signal indicating whether the guess was high or low. In a total of $C$ rounds, the signal may be corrupted, though the value of $C$ is unknown to the learner. The learner's goal is to incur a small cumulative loss. I present a natural yet powerful technique sanity check, which proves useful in designing corruption-robust algorithms. I design algorithms which (treating the Lipschitz parameter $L$ as constant): for the symmetric loss, the learner achieves regret $O(C\log T)$ with $d = 1$ and $O_d(C\log T + T^{(d-1)/d})$ with $d > 1$; for the pricing loss the learner achieves regret $\widetilde{O} (T^{d/(d+1)} + C\cdot T^{1/(d+1)})$.
</details>
<details>
<summary>摘要</summary>
我研究一个学习具有欺诈 Binary 信号的 Lipschitz 函数问题。学习者尝试学习一个由 против方选择的 Lipschitz 函数 $f$。在每个回合中，对手选择一个输入空间中的上下文向量 $x_t$，学习者对真实函数值 $f(x_t)$ 进行猜测，并接收一个指示猜测高或低的 Binary 信号。总共有 $C$ 回合，信号可能受到欺诈，尝试者不知道对手会欺诈多少回合。学习者的目标是减少总的损失。我提出了一种自然且强大的技术Check，用于设计欺诈Robust算法。我设计了算法，对于对称损失，学习者可以得到 $O(C\log T)$ 的 regret，其中 $d = 1$ 和 $O_d(C\log T + T^{(d-1)/d})$ ，其中 $d > 1$。对于价格损失，学习者可以得到 $\widetilde{O} (T^{d/(d+1)} + C\cdot T^{1/(d+1)})$。
</details></li>
</ul>
<hr>
<h2 id="Regularizing-Neural-Networks-with-Meta-Learning-Generative-Models"><a href="#Regularizing-Neural-Networks-with-Meta-Learning-Generative-Models" class="headerlink" title="Regularizing Neural Networks with Meta-Learning Generative Models"></a>Regularizing Neural Networks with Meta-Learning Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13899">http://arxiv.org/abs/2307.13899</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shin’ya Yamaguchi, Daiki Chijiwa, Sekitoshi Kanai, Atsutoshi Kumagai, Hisashi Kashima</li>
<li>for: 该论文旨在提高深度学习中的生成数据增强。</li>
<li>methods: 该论文提出了一种新的生成数据增强策略 called meta generative regularization (MGR)，通过在特征提取器中使用生成样本来避免生成数据增强的性能下降。</li>
<li>results: 实验结果表明，MGR可以避免生成数据增强的性能下降，并在小 dataset 设置下特别有效，稳定超过基eline。<details>
<summary>Abstract</summary>
This paper investigates methods for improving generative data augmentation for deep learning. Generative data augmentation leverages the synthetic samples produced by generative models as an additional dataset for classification with small dataset settings. A key challenge of generative data augmentation is that the synthetic data contain uninformative samples that degrade accuracy. This is because the synthetic samples do not perfectly represent class categories in real data and uniform sampling does not necessarily provide useful samples for tasks. In this paper, we present a novel strategy for generative data augmentation called meta generative regularization (MGR). To avoid the degradation of generative data augmentation, MGR utilizes synthetic samples in the regularization term for feature extractors instead of in the loss function, e.g., cross-entropy. These synthetic samples are dynamically determined to minimize the validation losses through meta-learning. We observed that MGR can avoid the performance degradation of na\"ive generative data augmentation and boost the baselines. Experiments on six datasets showed that MGR is effective particularly when datasets are smaller and stably outperforms baselines.
</details>
<details>
<summary>摘要</summary>
To address this challenge, we propose a novel approach called meta generative regularization (MGR). Instead of using synthetic samples in the loss function, such as cross-entropy, MGR utilizes these samples in the regularization term for feature extractors. The synthetic samples are dynamically determined to minimize validation losses through meta-learning.We observed that MGR can effectively avoid the performance degradation of naive generative data augmentation and improve baseline performance. Our experiments on six datasets showed that MGR is particularly effective in small datasets and consistently outperforms baselines.
</details></li>
</ul>
<hr>
<h2 id="Efficient-Estimation-of-the-Local-Robustness-of-Machine-Learning-Models"><a href="#Efficient-Estimation-of-the-Local-Robustness-of-Machine-Learning-Models" class="headerlink" title="Efficient Estimation of the Local Robustness of Machine Learning Models"></a>Efficient Estimation of the Local Robustness of Machine Learning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13885">http://arxiv.org/abs/2307.13885</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tessa Han, Suraj Srinivas, Himabindu Lakkaraju</li>
<li>for: 本文旨在提高机器学习模型对噪声输入数据的Robustness。</li>
<li>methods: 本文提出了首个分析性的 robustness estimator，通过地方线性函数近似和多变量正态分布函数，可以高效计算多类分类模型的地方Robustness。</li>
<li>results: 本文通过DERIVATION的过程，确认了这些 estimator 能够高度准确地计算标准深度学习模型的地方Robustness。此外，本文还证明了这些 estimator 在不同任务中的有用性，如测试模型的Robustness偏见和找到数据集中噪声扰动的易受到影响的示例。<details>
<summary>Abstract</summary>
Machine learning models often need to be robust to noisy input data. The effect of real-world noise (which is often random) on model predictions is captured by a model's local robustness, i.e., the consistency of model predictions in a local region around an input. However, the na\"ive approach to computing local robustness based on Monte-Carlo sampling is statistically inefficient, leading to prohibitive computational costs for large-scale applications. In this work, we develop the first analytical estimators to efficiently compute local robustness of multi-class discriminative models using local linear function approximation and the multivariate Normal CDF. Through the derivation of these estimators, we show how local robustness is connected to concepts such as randomized smoothing and softmax probability. We also confirm empirically that these estimators accurately and efficiently compute the local robustness of standard deep learning models. In addition, we demonstrate these estimators' usefulness for various tasks involving local robustness, such as measuring robustness bias and identifying examples that are vulnerable to noise perturbation in a dataset. By developing these analytical estimators, this work not only advances conceptual understanding of local robustness, but also makes its computation practical, enabling the use of local robustness in critical downstream applications.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ExeDec-Execution-Decomposition-for-Compositional-Generalization-in-Neural-Program-Synthesis"><a href="#ExeDec-Execution-Decomposition-for-Compositional-Generalization-in-Neural-Program-Synthesis" class="headerlink" title="ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis"></a>ExeDec: Execution Decomposition for Compositional Generalization in Neural Program Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13883">http://arxiv.org/abs/2307.13883</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kensen Shi, Joey Hong, Manzil Zaheer, Pengcheng Yin, Charles Sutton</li>
<li>for: 这个论文的目的是描述一种基于拆分的程序生成策略，以及这种策略在不同复杂性水平下的普适性。</li>
<li>methods: 这个论文使用了一种基于执行目标的分解策略，即预测每个步骤的执行目标，以解决问题步骤通过执行程序。</li>
<li>results:  compared to基elines,这种分解策略能够更好地普适化并且具有更高的程序生成性能。<details>
<summary>Abstract</summary>
When writing programs, people have the ability to tackle a new complex task by decomposing it into smaller and more familiar subtasks. While it is difficult to measure whether neural program synthesis methods have similar capabilities, we can measure whether they compositionally generalize, that is, whether a model that has been trained on the simpler subtasks is subsequently able to solve more complex tasks. In this paper, we characterize several different forms of compositional generalization that are desirable in program synthesis, forming a meta-benchmark which we use to create generalization tasks for two popular datasets, RobustFill and DeepCoder. We then propose ExeDec, a novel decomposition-based synthesis strategy that predicts execution subgoals to solve problems step-by-step informed by program execution at each step. ExeDec has better synthesis performance and greatly improved compositional generalization ability compared to baselines.
</details>
<details>
<summary>摘要</summary>
当编写程序时，人们可以将复杂任务分解成更加熟悉的子任务，以便更好地进行解决。虽然无法直接测量神经程序合成方法是否具有类似的能力，但我们可以测量它们是否具有组合普适性，即是否一个已经在简单子任务上训练的模型能够解决更复杂的任务。在这篇论文中，我们描述了几种不同的组合普适性形式，这些形式是程序合成中极其感兴趣的。我们使用这些形式组成一个元标准，并使用这个元标准来创建一些总体化任务，以便测试两个流行的数据集：RobustFill和DeepCoder。然后，我们提出了一种新的分解基于的合成策略，即ExeDec，这种策略可以预测执行目标，以解决问题步骤条件下。ExeDec的合成性能和组合普适性能比基eline要好。
</details></li>
</ul>
<hr>
<h2 id="Good-Lattice-Training-Physics-Informed-Neural-Networks-Accelerated-by-Number-Theory"><a href="#Good-Lattice-Training-Physics-Informed-Neural-Networks-Accelerated-by-Number-Theory" class="headerlink" title="Good Lattice Training: Physics-Informed Neural Networks Accelerated by Number Theory"></a>Good Lattice Training: Physics-Informed Neural Networks Accelerated by Number Theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13869">http://arxiv.org/abs/2307.13869</a></li>
<li>repo_url: None</li>
<li>paper_authors: Takashi Matsubara, Takaharu Yaguchi</li>
<li>for: 解决partial differential equations (PDEs)</li>
<li>methods: 使用physics-informed neural networks (PINNs)和good lattice training (GLT)</li>
<li>results: 需要2-20倍少的散点（相对于随机抽样或拉丁hypercube抽样），而且实现竞争性的性能<details>
<summary>Abstract</summary>
Physics-informed neural networks (PINNs) offer a novel and efficient approach to solving partial differential equations (PDEs). Their success lies in the physics-informed loss, which trains a neural network to satisfy a given PDE at specific points and to approximate the solution. However, the solutions to PDEs are inherently infinite-dimensional, and the distance between the output and the solution is defined by an integral over the domain. Therefore, the physics-informed loss only provides a finite approximation, and selecting appropriate collocation points becomes crucial to suppress the discretization errors, although this aspect has often been overlooked. In this paper, we propose a new technique called good lattice training (GLT) for PINNs, inspired by number theoretic methods for numerical analysis. GLT offers a set of collocation points that are effective even with a small number of points and for multi-dimensional spaces. Our experiments demonstrate that GLT requires 2--20 times fewer collocation points (resulting in lower computational cost) than uniformly random sampling or Latin hypercube sampling, while achieving competitive performance.
</details>
<details>
<summary>摘要</summary>
physics-informed neural networks (PINNs) 提供了一种新的和高效的方法来解决partial differential equations (PDEs)。其成功归功于物理学习损失，该损失训练一个神经网络满足给定PDE的特定点并估算解。然而，解析方程的解是无穷维度的，而误差的评价是通过域内积分来定义的。因此，物理学习损失只提供了有限的approximation，选择合适的集合点变得非常重要，尽管这一点经常被忽略。在这篇论文中，我们提出了一种新的技术called good lattice training (GLT) дляPINNs， inspirited by number theoretic methods for numerical analysis。GLT提供了一组高效的集合点，可以在小量的点数下在多维空间中达到竞争性表现。我们的实验表明，GLT比uniformly random sampling或Latin hypercube sampling要少2--20倍的集合点数（导致更低的计算成本），同时具有竞争性的表现。
</details></li>
</ul>
<hr>
<h2 id="Learning-sources-of-variability-from-high-dimensional-observational-studies"><a href="#Learning-sources-of-variability-from-high-dimensional-observational-studies" class="headerlink" title="Learning sources of variability from high-dimensional observational studies"></a>Learning sources of variability from high-dimensional observational studies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13868">http://arxiv.org/abs/2307.13868</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ebridge2/cdcorr">https://github.com/ebridge2/cdcorr</a></li>
<li>paper_authors: Eric W. Bridgeford, Jaewon Chung, Brian Gilbert, Sambit Panda, Adam Li, Cencheng Shen, Alexandra Badea, Brian Caffo, Joshua T. Vogelstein<br>for: 这个论文是关于 causal inference 的研究，即判断变量是否对观察结果产生影响的问题。methods: 这篇论文使用了一种新的方法，即将 causal estimands 扩展到包括任意维度或任意测量空间的输出，并将 Nominal 变量的 causal estimands 表示为 causal discrepancy tests。results: 该方法在数据分析中具有较好的finite sample validity和power性能，并且可以在 GitHub 上获取开源代码。<details>
<summary>Abstract</summary>
Causal inference studies whether the presence of a variable influences an observed outcome. As measured by quantities such as the "average treatment effect," this paradigm is employed across numerous biological fields, from vaccine and drug development to policy interventions. Unfortunately, the majority of these methods are often limited to univariate outcomes. Our work generalizes causal estimands to outcomes with any number of dimensions or any measurable space, and formulates traditional causal estimands for nominal variables as causal discrepancy tests. We propose a simple technique for adjusting universally consistent conditional independence tests and prove that these tests are universally consistent causal discrepancy tests. Numerical experiments illustrate that our method, Causal CDcorr, leads to improvements in both finite sample validity and power when compared to existing strategies. Our methods are all open source and available at github.com/ebridge2/cdcorr.
</details>
<details>
<summary>摘要</summary>
causal inference studies whether a variable's presence affects an observed outcome. As measured by quantities such as the "average treatment effect," this paradigm is employed across numerous biological fields, from vaccine and drug development to policy interventions. unfortunately, most methods are limited to univariate outcomes. our work generalizes causal estimands to outcomes with any number of dimensions or any measurable space, and formulates traditional causal estimands for nominal variables as causal discrepancy tests. we propose a simple technique for adjusting universally consistent conditional independence tests and prove that these tests are universally consistent causal discrepancy tests. numerical experiments illustrate that our method, causal CDcorr, leads to improvements in both finite sample validity and power compared to existing strategies. our methods are all open source and available at github.com/ebridge2/cdcorr.Here's the translation breakdown:* "causal inference" is  causal inference ( causal 推断)* "whether a variable's presence affects an observed outcome" is  whether a variable's presence affects an observed outcome ( 变量存在影响观察结果)* "as measured by quantities such as the 'average treatment effect'" is  as measured by quantities such as the 'average treatment effect' ( 根据 "average treatment effect" 类型的量进行测量)* "this paradigm is employed across numerous biological fields" is  this paradigm is employed across numerous biological fields ( 这种方法在生物学多个领域中使用)* "from vaccine and drug development to policy interventions" is  from vaccine and drug development to policy interventions ( 从疫苗和药物开发到政策干预)* "unfortunately, most methods are limited to univariate outcomes" is  unfortunately, most methods are limited to univariate outcomes (  unfortunately, most methods are limited to univariate outcomes)* "our work generalizes causal estimands to outcomes with any number of dimensions or any measurable space" is  our work generalizes causal estimands to outcomes with any number of dimensions or any measurable space ( 我们的工作泛化 causal estimands 到任意维度或任意测量空间)* "and formulates traditional causal estimands for nominal variables as causal discrepancy tests" is  and formulates traditional causal estimands for nominal variables as causal discrepancy tests ( 并将 traditional causal estimands  для nominal variables 表示为 causal discrepancy tests)* "we propose a simple technique for adjusting universally consistent conditional independence tests" is  we propose a simple technique for adjusting universally consistent conditional independence tests ( 我们提出一种简单的方法来调整 universally consistent conditional independence tests)* "and prove that these tests are universally consistent causal discrepancy tests" is  and prove that these tests are universally consistent causal discrepancy tests ( 并证明这些测试是 universally consistent causal discrepancy tests)* "numerical experiments illustrate that our method, causal CDcorr, leads to improvements in both finite sample validity and power" is  numerical experiments illustrate that our method, causal CDcorr, leads to improvements in both finite sample validity and power ( 数学实验表明，我们的方法 causal CDcorr 在finite sample validity 和 power 两个方面都有改善)* "our methods are all open source and available at github.com/ebridge2/cdcorr" is  our methods are all open source and available at github.com/ebridge2/cdcorr ( 我们的方法都是开源的，可以在 github.com/ebridge2/cdcorr 上获取)
</details></li>
</ul>
<hr>
<h2 id="Pretrained-Deep-2-5D-Models-for-Efficient-Predictive-Modeling-from-Retinal-OCT"><a href="#Pretrained-Deep-2-5D-Models-for-Efficient-Predictive-Modeling-from-Retinal-OCT" class="headerlink" title="Pretrained Deep 2.5D Models for Efficient Predictive Modeling from Retinal OCT"></a>Pretrained Deep 2.5D Models for Efficient Predictive Modeling from Retinal OCT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13865">http://arxiv.org/abs/2307.13865</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taha Emre, Marzieh Oghbaie, Arunava Chakravarty, Antoine Rivail, Sophie Riedl, Julia Mai, Hendrik P. N. Scholl, Sobha Sivaprasad, Daniel Rueckert, Andrew Lotery, Ursula Schmidt-Erfurth, Hrvoje Bogunović<br>for: 这种研究旨在提高静脉穿梭图像处理领域的肿瘤诊断和预测性能。methods: 该研究采用了2.5D结构，结合了卷积神经网络（CNN）、长短期记忆（LSTM）和变换器，并利用了非对照预训练方法。results: 研究表明，该方法可以在两个大型静脉穿梭数据集上预测肿瘤患者在六个月内到达湿性肿瘤（AMD）的患病程度，并且比传统方法提高了性能和数据使用效率。<details>
<summary>Abstract</summary>
In the field of medical imaging, 3D deep learning models play a crucial role in building powerful predictive models of disease progression. However, the size of these models presents significant challenges, both in terms of computational resources and data requirements. Moreover, achieving high-quality pretraining of 3D models proves to be even more challenging. To address these issues, hybrid 2.5D approaches provide an effective solution for utilizing 3D volumetric data efficiently using 2D models. Combining 2D and 3D techniques offers a promising avenue for optimizing performance while minimizing memory requirements. In this paper, we explore 2.5D architectures based on a combination of convolutional neural networks (CNNs), long short-term memory (LSTM), and Transformers. In addition, leveraging the benefits of recent non-contrastive pretraining approaches in 2D, we enhanced the performance and data efficiency of 2.5D techniques even further. We demonstrate the effectiveness of architectures and associated pretraining on a task of predicting progression to wet age-related macular degeneration (AMD) within a six-month period on two large longitudinal OCT datasets.
</details>
<details>
<summary>摘要</summary>
医学成像领域中，3D深度学习模型在建立疾病进程预测模型方面发挥关键作用。然而，这些模型的大小带来了计算资源和数据需求的挑战。同时，获得高质量预训练3D模型也是极其困难的。为解决这些问题，混合2.5D方法提供了高效地利用3D体积数据的解决方案。将2D和3D技术结合使用，可以备受提高性能的同时减少内存需求。在本文中，我们探讨了基于卷积神经网络（CNN）、长期吸引记忆（LSTM）和转换器的2.5D架构。此外，利用最近的非对照预训练方法在2D中，我们进一步提高了2.5D技术的性能和数据效率。我们在两个大型Longitudinal OCT数据集上证明了这些架构和预训练的效果，用于预测在6个月内进行湿性肿瘤性macular degeneration（AMD）的进程。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Design-Analog-Circuits-to-Meet-Threshold-Specifications"><a href="#Learning-to-Design-Analog-Circuits-to-Meet-Threshold-Specifications" class="headerlink" title="Learning to Design Analog Circuits to Meet Threshold Specifications"></a>Learning to Design Analog Circuits to Meet Threshold Specifications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13861">http://arxiv.org/abs/2307.13861</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/indylab/circuit-synthesis">https://github.com/indylab/circuit-synthesis</a></li>
<li>paper_authors: Dmitrii Krylov, Pooya Khajeh, Junhan Ouyang, Thomas Reeves, Tongkai Liu, Hiba Ajmal, Hamidreza Aghasi, Roy Fox</li>
<li>for: 本文是关于自动化分析和无线电电路设计的研究，使用supervised或反射学习从 simulation 数据中学习。</li>
<li>methods: 本文提出了一种方法，通过在 simulation 数据上生成一个数据集，以便通过supervised learning训练系统，以实现适用于阈值要求的电路设计。</li>
<li>results: 本文的实验结果表明，该方法可以在5%错误率下达到90%的成功率，同时提高数据效率。 Demo 系统可以在 circuits.streamlit.app 上测试。<details>
<summary>Abstract</summary>
Automated design of analog and radio-frequency circuits using supervised or reinforcement learning from simulation data has recently been studied as an alternative to manual expert design. It is straightforward for a design agent to learn an inverse function from desired performance metrics to circuit parameters. However, it is more common for a user to have threshold performance criteria rather than an exact target vector of feasible performance measures. In this work, we propose a method for generating from simulation data a dataset on which a system can be trained via supervised learning to design circuits to meet threshold specifications. We moreover perform the to-date most extensive evaluation of automated analog circuit design, including experimenting in a significantly more diverse set of circuits than in prior work, covering linear, nonlinear, and autonomous circuit configurations, and show that our method consistently reaches success rate better than 90% at 5% error margin, while also improving data efficiency by upward of an order of magnitude. A demo of this system is available at circuits.streamlit.app
</details>
<details>
<summary>摘要</summary>
自动化的分析和广播逻辑电路设计使用监督或强化学习从 simulate 数据进行研究，以代替人工专家设计。它直观的 для 设计代理人学习一个逆函数从需要性能指标到电路参数。然而，更常见的用户有阈值性能标准而不是具体的可行性表现度量Vector。在这项工作中，我们提出了一种从 simulate 数据中生成一个可以通过监督学习训练系统来满足阈值要求的数据集。我们进一步执行了之前的自动分析电路设计评估，包括在更加多样化的电路配置中进行实验，包括线性、非线性和自主电路配置，并证明了我们的方法可以在 5% 误差率下达到 Better than 90% 的成功率，同时也提高了数据效率，高达一个数量级。一个示例系统可以在 circuits.streamlit.app 上查看。
</details></li>
</ul>
<hr>
<h2 id="On-the-unreasonable-vulnerability-of-transformers-for-image-restoration-–-and-an-easy-fix"><a href="#On-the-unreasonable-vulnerability-of-transformers-for-image-restoration-–-and-an-easy-fix" class="headerlink" title="On the unreasonable vulnerability of transformers for image restoration – and an easy fix"></a>On the unreasonable vulnerability of transformers for image restoration – and an easy fix</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13856">http://arxiv.org/abs/2307.13856</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shashank Agnihotri, Kanchana Vaishnavi Gandikota, Julia Grabinski, Paramanand Chandramouli, Margret Keuper</li>
<li>for: 这个论文主要研究了使用视Transformer（ViT）进行图像修复 task 的 robustness 性能。</li>
<li>methods: 作者使用了 Projected Gradient Descent（PGD）和 Cosine PGD（CosPGD）等 adversarial attack 方法进行评估。</li>
<li>results: 研究发现，Restormer 模型在 GoPro  dataset 上的图像锐化任务中具有较高的Robustness，但 NAAFNet 和 Baseline 模型的Robustness 较差。通过对 Restormer 进行 adversarial training，可以得到显著提高的Robustness。<details>
<summary>Abstract</summary>
Following their success in visual recognition tasks, Vision Transformers(ViTs) are being increasingly employed for image restoration. As a few recent works claim that ViTs for image classification also have better robustness properties, we investigate whether the improved adversarial robustness of ViTs extends to image restoration. We consider the recently proposed Restormer model, as well as NAFNet and the "Baseline network" which are both simplified versions of a Restormer. We use Projected Gradient Descent (PGD) and CosPGD, a recently proposed adversarial attack tailored to pixel-wise prediction tasks for our robustness evaluation. Our experiments are performed on real-world images from the GoPro dataset for image deblurring. Our analysis indicates that contrary to as advocated by ViTs in image classification works, these models are highly susceptible to adversarial attacks. We attempt to improve their robustness through adversarial training. While this yields a significant increase in robustness for Restormer, results on other networks are less promising. Interestingly, the design choices in NAFNet and Baselines, which were based on iid performance, and not on robust generalization, seem to be at odds with the model robustness. Thus, we investigate this further and find a fix.
</details>
<details>
<summary>摘要</summary>
根据视觉任务的成功，视觉转换器（ViT）在图像修复领域中得到了越来越多的应用。一些最近的研究表明，ViT在图像分类任务中也有更好的鲁棒性质，我们来 investigate这些鲁棒性质是否扩展到图像修复领域。我们考虑了最近提出的Restormer模型，以及NAFNet和"基eline网络"，这两者都是Restormer的简化版本。我们使用项目化梯度下降（PGD）和CosPGD，一种最近提出的针对像精度预测任务的抗击攻击方法来评估我们的模型的鲁棒性。我们的实验是在GoPro dataset上进行了实际图像锐化任务。我们的分析表明，与在图像分类任务中所提出的鲁棒性相反，这些模型对抗击攻击非常易受伤。我们尝试通过对模型进行鲁棒训练来提高其鲁棒性。而对Restormer来说，这种方法带来了显著的鲁棒性提高，但对NAFNet和基eline网络来说，结果不那么抵触。我们进一步调查这个问题，发现iid性的设计选择在NAFNet和基eline网络中不是适合的。因此，我们进一步调查这个问题，并发现了一个解决方案。
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Sharpened-Cosine-Similarity"><a href="#Exploring-the-Sharpened-Cosine-Similarity" class="headerlink" title="Exploring the Sharpened Cosine Similarity"></a>Exploring the Sharpened Cosine Similarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13855">http://arxiv.org/abs/2307.13855</a></li>
<li>repo_url: None</li>
<li>paper_authors: Skyler Wu, Fred Lu, Edward Raff, James Holt</li>
<li>for: 对比 convolutional layers，这篇论文探讨了使用 Sharpened Cosine Similarity (SCS) 来替换图像分类模型的可能性。</li>
<li>methods: 这篇论文使用了 SCS 的参数行为和多种 CNN 架构的比较，以及对 CIFAR-10 数据集的测试。</li>
<li>results: 论文发现，使用 SCS 可能不会提高准确率，但可能学习更易于理解的特征表示。此外，在某些情况下，SCS 可能会提高对抗式攻击的Robustness。<details>
<summary>Abstract</summary>
Convolutional layers have long served as the primary workhorse for image classification. Recently, an alternative to convolution was proposed using the Sharpened Cosine Similarity (SCS), which in theory may serve as a better feature detector. While multiple sources report promising results, there has not been to date a full-scale empirical analysis of neural network performance using these new layers. In our work, we explore SCS's parameter behavior and potential as a drop-in replacement for convolutions in multiple CNN architectures benchmarked on CIFAR-10. We find that while SCS may not yield significant increases in accuracy, it may learn more interpretable representations. We also find that, in some circumstances, SCS may confer a slight increase in adversarial robustness.
</details>
<details>
<summary>摘要</summary>
卷积层长期作为图像分类的主要工具。最近，一种使用卷积的替代方案，即加剪极值相似性（SCS），被提出。虽然多种来源报道了批处性的结果，但到目前为止没有一个全面的实验分析了神经网络性能使用这些新层。在我们的工作中，我们探索SCS的参数行为和作为替换卷积层的潜在可能性。我们发现SCS可能不会导致显著提高准确率，但可能学习更易于理解的表示。我们还发现，在某些情况下，SCS可能会提供轻微的防御性提升。
</details></li>
</ul>
<hr>
<h2 id="WebArena-A-Realistic-Web-Environment-for-Building-Autonomous-Agents"><a href="#WebArena-A-Realistic-Web-Environment-for-Building-Autonomous-Agents" class="headerlink" title="WebArena: A Realistic Web Environment for Building Autonomous Agents"></a>WebArena: A Realistic Web Environment for Building Autonomous Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13854">http://arxiv.org/abs/2307.13854</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/web-arena-x/webarena">https://github.com/web-arena-x/webarena</a></li>
<li>paper_authors: Shuyan Zhou, Frank F. Xu, Hao Zhu, Xuhui Zhou, Robert Lo, Abishek Sridhar, Xianyi Cheng, Yonatan Bisk, Daniel Fried, Uri Alon, Graham Neubig</li>
<li>for: 这篇论文的目的是为了建立一个高度真实和可重现的自动控制代理环境，以便测试和评估基于自然语言命令的自动代理。</li>
<li>methods: 这篇论文使用了现有的自然语言处理技术，如GPT-4，以及一些特定的推理和决策策略，来实现自动代理的功能。</li>
<li>results: 根据这篇论文的结果，当前的状态对抗算法仍然有很大的改进空间，特别是在解决复杂的实际任务时。最好的GPT-4基本代理只有10.59%的任务完成率。这些结果表明，在实际任务中，自动代理仍然需要进一步的发展和改进。<details>
<summary>Abstract</summary>
With generative AI advances, the exciting potential for autonomous agents to manage daily tasks via natural language commands has emerged. However, cur rent agents are primarily created and tested in simplified synthetic environments, substantially limiting real-world scenario representation. In this paper, we build an environment for agent command and control that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on websites, and we create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (e.g., a map) and external knowledge bases (e.g., user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks focusing on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and are designed to emulate tasks that humans routinely perform on the internet. We design and implement several autonomous agents, integrating recent techniques such as reasoning before acting. The results demonstrate that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 10.59%. These results highlight the need for further development of robust agents, that current state-of-the-art LMs are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress. Our code, data, environment reproduction resources, and video demonstrations are publicly available at https://webarena.dev/.
</details>
<details>
<summary>摘要</summary>
With the advancement of generative AI, the possibility of autonomous agents managing daily tasks through natural language commands has emerged. However, current agents are primarily developed and tested in simplified synthetic environments, which significantly limits the representation of real-world scenarios. In this paper, we create an environment for agent command and control that is highly realistic and reproducible. Specifically, we focus on agents that perform tasks on websites, and we create an environment with fully functional websites from four common domains: e-commerce, social forum discussions, collaborative software development, and content management. Our environment is enriched with tools (such as a map) and external knowledge bases (such as user manuals) to encourage human-like task-solving. Building upon our environment, we release a set of benchmark tasks that focus on evaluating the functional correctness of task completions. The tasks in our benchmark are diverse, long-horizon, and are designed to emulate tasks that humans routinely perform on the internet. We design and implement several autonomous agents, integrating recent techniques such as reasoning before acting. The results show that solving complex tasks is challenging: our best GPT-4-based agent only achieves an end-to-end task success rate of 10.59%. These results highlight the need for further development of robust agents, that current state-of-the-art language models are far from perfect performance in these real-life tasks, and that WebArena can be used to measure such progress. Our code, data, environment reproduction resources, and video demonstrations are publicly available at <https://webarena.dev/>.
</details></li>
</ul>
<hr>
<h2 id="SplitFed-resilience-to-packet-loss-Where-to-split-that-is-the-question"><a href="#SplitFed-resilience-to-packet-loss-Where-to-split-that-is-the-question" class="headerlink" title="SplitFed resilience to packet loss: Where to split, that is the question"></a>SplitFed resilience to packet loss: Where to split, that is the question</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13851">http://arxiv.org/abs/2307.13851</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chamani Shiranthika, Zahra Hafezi Kafshgari, Parvaneh Saeedi, Ivan V. Bajić</li>
<li>for: 这篇论文是研究分布式机器学习中的 Federation Learning（FL）和 Split Learning（SL）的hybrid模型 Split Federated Learning（SplitFed或SFL）的稳定性。</li>
<li>methods: 这篇论文使用了在 коммуникаation链上的包 loss对 SFL的影响的研究，并对不同的 SFL 聚合策略进行了测试，包括在模型中分割点的深度。</li>
<li>results: 实验结果表明，在人类胚胎图像分割模型中，使用深度分割点可以获得更高的准确率。<details>
<summary>Abstract</summary>
Decentralized machine learning has broadened its scope recently with the invention of Federated Learning (FL), Split Learning (SL), and their hybrids like Split Federated Learning (SplitFed or SFL). The goal of SFL is to reduce the computational power required by each client in FL and parallelize SL while maintaining privacy. This paper investigates the robustness of SFL against packet loss on communication links. The performance of various SFL aggregation strategies is examined by splitting the model at two points -- shallow split and deep split -- and testing whether the split point makes a statistically significant difference to the accuracy of the final model. Experiments are carried out on a segmentation model for human embryo images and indicate the statistically significant advantage of a deeper split point.
</details>
<details>
<summary>摘要</summary>
分布式机器学习在最近已经扩展了其范围，包括联邦学习（FL）、分布式学习（SL）以及其混合体（SplitFed或SFL）。SFL的目标是降低每个客户端在FL中计算能力需求并并行SL，同时保持隐私。这篇论文研究了SFL在通信链路上 packet loss 的Robustness。具体来说，该论文分析了不同的SFL聚合策略在不同的分割点（浅分割和深分割）下的性能，并测试了这些分割点是否对最终模型的准确率产生了统计学上的影响。实验使用了人类胚胎图像分割模型，结果表明深分割点具有统计学上的优势。
</details></li>
</ul>
<hr>
<h2 id="MAEA-Multimodal-Attribution-for-Embodied-AI"><a href="#MAEA-Multimodal-Attribution-for-Embodied-AI" class="headerlink" title="MAEA: Multimodal Attribution for Embodied AI"></a>MAEA: Multimodal Attribution for Embodied AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13850">http://arxiv.org/abs/2307.13850</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vidhi Jain, Jayant Sravan Tamarapalli, Sahiti Yerramilli, Yonatan Bisk</li>
<li>for: 本研究旨在理解多Modal perception дляembodied AI，因为输入可能包含高度相互补充的信息。</li>
<li>methods: 本研究使用了解归报分析来理解不同策略在ALFRED数据集上的全球趋势。</li>
<li>results: 研究发现了一种名为MAEA的框架，可以计算任意分 diferenciable 策略的全球贡献。此外，研究还表明了如何使用贡献来分析低级行为在EAI策略中。<details>
<summary>Abstract</summary>
Understanding multimodal perception for embodied AI is an open question because such inputs may contain highly complementary as well as redundant information for the task. A relevant direction for multimodal policies is understanding the global trends of each modality at the fusion layer. To this end, we disentangle the attributions for visual, language, and previous action inputs across different policies trained on the ALFRED dataset. Attribution analysis can be utilized to rank and group the failure scenarios, investigate modeling and dataset biases, and critically analyze multimodal EAI policies for robustness and user trust before deployment. We present MAEA, a framework to compute global attributions per modality of any differentiable policy. In addition, we show how attributions enable lower-level behavior analysis in EAI policies for language and visual attributions.
</details>
<details>
<summary>摘要</summary>
（简体中文）理解多模态识别对带有体的AI是一个开放的问题，因为这些输入可能包含高度相互补做的信息。一个有利的方向是理解每个模态的全球趋势在融合层。为此，我们分离不同策略在ALFRED数据集上训练的视觉、语言和前一个动作输入的归因分析。归因分析可以用来排序和分组失败场景，调查模型和数据集偏见，并在部署前对多模态EAI策略进行 crítico分析。我们提出了MAEA框架，用于计算任意可导策略的全球归因。此外，我们还示出了归因如何帮助分析EAI策略的下一个行为。
</details></li>
</ul>
<hr>
<h2 id="Relationship-between-Batch-Size-and-Number-of-Steps-Needed-for-Nonconvex-Optimization-of-Stochastic-Gradient-Descent-using-Armijo-Line-Search"><a href="#Relationship-between-Batch-Size-and-Number-of-Steps-Needed-for-Nonconvex-Optimization-of-Stochastic-Gradient-Descent-using-Armijo-Line-Search" class="headerlink" title="Relationship between Batch Size and Number of Steps Needed for Nonconvex Optimization of Stochastic Gradient Descent using Armijo Line Search"></a>Relationship between Batch Size and Number of Steps Needed for Nonconvex Optimization of Stochastic Gradient Descent using Armijo Line Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13831">http://arxiv.org/abs/2307.13831</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuki Tsukada, Hideaki Iiduka</li>
<li>for: 本研究探讨了使用散射梯度下降（SGD）训练深度学习模型时的收敛分析。</li>
<li>methods: 本研究使用了Armijo线搜索学习率来实现SGD的收敛分析。</li>
<li>results: 研究结果表明，当步长和批处理大 enough时，SGD的期望平方误差的Upper bound会很小。此外，研究还发现，SGD WITH Armijo-line-search 学习率，批处理大小的增加会使得训练深度学习模型所需的步长数量减少。最后，研究还发现了一个关键的批处理大小，可以最小化Stochastic first-order oracle（SFO）复杂度。 numerics 支持了理论结果，它们表明，训练深度学习模型所需的步长数量随批处理大小的增加而减少，并且存在一个关键的批处理大小。<details>
<summary>Abstract</summary>
Stochastic gradient descent (SGD) is the simplest deep learning optimizer with which to train deep neural networks. While SGD can use various learning rates, such as constant or diminishing rates, the previous numerical results showed that SGD performs better than other deep learning optimizers using when it uses learning rates given by line search methods. In this paper, we perform a convergence analysis on SGD with a learning rate given by an Armijo line search for nonconvex optimization. The analysis indicates that the upper bound of the expectation of the squared norm of the full gradient becomes small when the number of steps and the batch size are large. Next, we show that, for SGD with the Armijo-line-search learning rate, the number of steps needed for nonconvex optimization is a monotone decreasing convex function of the batch size; that is, the number of steps needed for nonconvex optimization decreases as the batch size increases. Furthermore, we show that the stochastic first-order oracle (SFO) complexity, which is the stochastic gradient computation cost, is a convex function of the batch size; that is, there exists a critical batch size that minimizes the SFO complexity. Finally, we provide numerical results that support our theoretical results. The numerical results indicate that the number of steps needed for training deep neural networks decreases as the batch size increases and that there exist the critical batch sizes that can be estimated from the theoretical results.
</details>
<details>
<summary>摘要</summary>
Stochastic gradient descent（SGD）是深度学习优化器中最简单的一种，用于训练深度神经网络。SGD可以使用不同的学习率，如常数或减小学习率，但前面的数据分析表明SGD使用给定的线搜索方法学习率时表现比其他深度学习优化器更好。在这篇论文中，我们进行了SGD的收敛分析，其中SGD使用Armijo线搜索学习率进行非 convex 优化。分析结果表明，当数据步长和批处理大小增加时，SGD的期望平方误差的上界变小。然后，我们证明SGD使用Armijo-线搜索学习率时，非 convex 优化的数据步长是增加批处理大小的 monotone 减少函数；即，数据步长随着批处理大小增加而逐渐减少。此外，我们证明SGD的杂乱首项 Oracle（SFO）复杂度，即杂乱首项计算成本，是批处理大小的几何函数；即存在一个最佳批处理大小，可以最小化SFO复杂度。最后，我们提供了实际数据支持我们的理论结果。实际数据表明，训练深度神经网络时，数据步长随着批处理大小增加而逐渐减少，并且存在一个最佳批处理大小，可以从理论结果中估算。
</details></li>
</ul>
<hr>
<h2 id="Offline-Reinforcement-Learning-with-On-Policy-Q-Function-Regularization"><a href="#Offline-Reinforcement-Learning-with-On-Policy-Q-Function-Regularization" class="headerlink" title="Offline Reinforcement Learning with On-Policy Q-Function Regularization"></a>Offline Reinforcement Learning with On-Policy Q-Function Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13824">http://arxiv.org/abs/2307.13824</a></li>
<li>repo_url: None</li>
<li>paper_authors: Laixi Shi, Robert Dadashi, Yuejie Chi, Pablo Samuel Castro, Matthieu Geist</li>
<li>for: 本研究的目的是解决线上强化学习（RL）中的扩展错误问题，特别是在history集和期望策略之间的分布转换导致的扩展错误。</li>
<li>methods: 本研究使用Q函数估计来正则化学习策略，而不是直接正则化策略本身，以便更好地处理扩展错误。</li>
<li>results: 提出了两种基于Q函数估计的算法，并在D4RL标准吨量上表现出色。<details>
<summary>Abstract</summary>
The core challenge of offline reinforcement learning (RL) is dealing with the (potentially catastrophic) extrapolation error induced by the distribution shift between the history dataset and the desired policy. A large portion of prior work tackles this challenge by implicitly/explicitly regularizing the learning policy towards the behavior policy, which is hard to estimate reliably in practice. In this work, we propose to regularize towards the Q-function of the behavior policy instead of the behavior policy itself, under the premise that the Q-function can be estimated more reliably and easily by a SARSA-style estimate and handles the extrapolation error more straightforwardly. We propose two algorithms taking advantage of the estimated Q-function through regularizations, and demonstrate they exhibit strong performance on the D4RL benchmarks.
</details>
<details>
<summary>摘要</summary>
核心挑战是线上强化学习（RL）是处理可能导致极端的推理错误的分布shift问题。大部分先前工作是通过隐式/显式正则化学习策略向行为策略，这是在实践中难以估算的。在这种工作中，我们建议正则化学习向行为策略的Q函数，而不是行为策略本身，因为Q函数可以更好地被SARSA预测器估算，并且更直观地处理推理错误。我们提出了两种利用估算Q函数的算法，并在D4RL标准准则上展示强大的表现。
</details></li>
</ul>
<hr>
<h2 id="Fitting-Auditory-Filterbanks-with-Multiresolution-Neural-Networks"><a href="#Fitting-Auditory-Filterbanks-with-Multiresolution-Neural-Networks" class="headerlink" title="Fitting Auditory Filterbanks with Multiresolution Neural Networks"></a>Fitting Auditory Filterbanks with Multiresolution Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13821">http://arxiv.org/abs/2307.13821</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lostanlen/lostanlen2023waspaa">https://github.com/lostanlen/lostanlen2023waspaa</a></li>
<li>paper_authors: Vincent Lostanlen, Daniel Haider, Han Han, Mathieu Lagrange, Peter Balazs, Martin Ehler</li>
<li>for: 这paper的目的是超越深度学习抽象波形模型中的非Parametric和Parametric两种方法之间的矛盾。</li>
<li>methods: 这paper使用了一种名为多解析 neural network (MuReNN)，它是通过在快速傅立叶变换 (DWT) 中的 Octave 下分割，然后对每个 Octave 下的傅立叶函数进行分割学习的 convolutional neural network (CNN)。</li>
<li>results:  compare to state of the art, MuReNN 在一些优化问题上达到了最佳性能，包括 hold-out set 上的好き度Of fit 和 Heisenberg time-frequency localization。<details>
<summary>Abstract</summary>
Waveform-based deep learning faces a dilemma between nonparametric and parametric approaches. On one hand, convolutional neural networks (convnets) may approximate any linear time-invariant system; yet, in practice, their frequency responses become more irregular as their receptive fields grow. On the other hand, a parametric model such as LEAF is guaranteed to yield Gabor filters, hence an optimal time-frequency localization; yet, this strong inductive bias comes at the detriment of representational capacity. In this paper, we aim to overcome this dilemma by introducing a neural audio model, named multiresolution neural network (MuReNN). The key idea behind MuReNN is to train separate convolutional operators over the octave subbands of a discrete wavelet transform (DWT). Since the scale of DWT atoms grows exponentially between octaves, the receptive fields of the subsequent learnable convolutions in MuReNN are dilated accordingly. For a given real-world dataset, we fit the magnitude response of MuReNN to that of a well-established auditory filterbank: Gammatone for speech, CQT for music, and third-octave for urban sounds, respectively. This is a form of knowledge distillation (KD), in which the filterbank ''teacher'' is engineered by domain knowledge while the neural network ''student'' is optimized from data. We compare MuReNN to the state of the art in terms of goodness of fit after KD on a hold-out set and in terms of Heisenberg time-frequency localization. Compared to convnets and Gabor convolutions, we find that MuReNN reaches state-of-the-art performance on all three optimization problems.
</details>
<details>
<summary>摘要</summary>
文本描述一个深度学习问题，即 между非 Parametric 和 Parametric 方法之间的矛盾。一种方法是使用卷积神经网络（convnets），它们可以近似任何线性时变系统；然而，在实践中，它们的频谱响应会随着它们的观测领域而变得更加不规则。另一方面，一种 Parametric 模型如 LEAF 可以提供最佳的时间频率地址，但是这种强制性的假设来到了表达能力的代价。本文的目标是解决这个矛盾，通过引入多尺度神经网络（MuReNN）。MuReNN 的关键思想是在 discrete wavelet transform（DWT） 中的 Octave 子域上训练分离的卷积操作。由于 DWT 中的尺度很大的 Atom 在不同 Octave 中的尺度增长，因此 MuReNN 中的后续学习可以在不同 Octave 中进行扩展。对于一个真实的数据集，我们将 MuReNN 的 магниту德响应与一个已知的听力滤波器anka 进行比较：Gammatone  для语音、CQT  для音乐和第三Octave  для城市声音，分别。这是一种知识填充（KD），在听力滤波器“教师”是由领域知识工程而成，而神经网络“学生”是通过数据优化。我们将 MuReNN 与现状的最佳性比较，包括在 KD 中的准确性和 Heisenberg 时间频率地址。相比 convnets 和 Gabor 卷积，我们发现 MuReNN 在三个优化问题中达到了状态的最佳性。
</details></li>
</ul>
<hr>
<h2 id="Gradient-Based-Spectral-Embeddings-of-Random-Dot-Product-Graphs"><a href="#Gradient-Based-Spectral-Embeddings-of-Random-Dot-Product-Graphs" class="headerlink" title="Gradient-Based Spectral Embeddings of Random Dot Product Graphs"></a>Gradient-Based Spectral Embeddings of Random Dot Product Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13818">http://arxiv.org/abs/2307.13818</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/marfiori/efficient-ase">https://github.com/marfiori/efficient-ase</a></li>
<li>paper_authors: Marcelo Fiori, Bernardo Marenco, Federico Larroca, Paola Bermolen, Gonzalo Mateos</li>
<li>for: 这篇论文旨在提出一种基于非对映准则的关系数据生成模型，以及一种基于非对映准则的图像抽象算法，以解决现有的图像抽象算法存在的问题。</li>
<li>methods: 该论文使用了非对映准则优化方法来解决图像抽象问题，并且提出了一种新的 feasible 优化方法来保证对角矩阵的正则性。</li>
<li>results: 该论文通过 reproduce 性的实验表明，提出的图像抽象算法可以更好地处理实际网络数据，并且可以更好地捕捉网络数据的变化特征。<details>
<summary>Abstract</summary>
The Random Dot Product Graph (RDPG) is a generative model for relational data, where nodes are represented via latent vectors in low-dimensional Euclidean space. RDPGs crucially postulate that edge formation probabilities are given by the dot product of the corresponding latent positions. Accordingly, the embedding task of estimating these vectors from an observed graph is typically posed as a low-rank matrix factorization problem. The workhorse Adjacency Spectral Embedding (ASE) enjoys solid statistical properties, but it is formally solving a surrogate problem and can be computationally intensive. In this paper, we bring to bear recent advances in non-convex optimization and demonstrate their impact to RDPG inference. We advocate first-order gradient descent methods to better solve the embedding problem, and to organically accommodate broader network embedding applications of practical relevance. Notably, we argue that RDPG embeddings of directed graphs loose interpretability unless the factor matrices are constrained to have orthogonal columns. We thus develop a novel feasible optimization method in the resulting manifold. The effectiveness of the graph representation learning framework is demonstrated on reproducible experiments with both synthetic and real network data. Our open-source algorithm implementations are scalable, and unlike the ASE they are robust to missing edge data and can track slowly-varying latent positions from streaming graphs.
</details>
<details>
<summary>摘要</summary>
“Random Dot Product Graph（RDPG）是一种生成模型，用于关系数据，节点通过低维欧几何空间中的latent vector表示。RDPG假设边形成概率由latent vector的点积生成。因此，从观察到的图像到latent vector的嵌入问题通常是一个低级matrix factorization问题。ASE工作马力广泛应用，但是它是一个代理问题，可能会 computationally expensive。在这篇论文中，我们利用非 convex 优化的最新进展，并证明其对RDPG推理的影响。我们建议使用first-order gradient descent方法，以更好地解决嵌入问题，并且可以自然地承载更广泛的网络嵌入应用。另外，我们发现RDPG对于指向图的嵌入具有解释性的限制，因此我们开发了一种新的可行优化方法。我们的图表示学框架在 reproduceable 实验中表现出色，可扩展性和稳定性都很好。”Note: Simplified Chinese is used in this translation, which is a more casual and widely-used version of Chinese. If you prefer Traditional Chinese, I can provide that version as well.
</details></li>
</ul>
<hr>
<h2 id="How-to-Scale-Your-EMA"><a href="#How-to-Scale-Your-EMA" class="headerlink" title="How to Scale Your EMA"></a>How to Scale Your EMA</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13813">http://arxiv.org/abs/2307.13813</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ZulqarnainZilli/-9-Email-Marketing-Tips-For-Content-Marketers">https://github.com/ZulqarnainZilli/-9-Email-Marketing-Tips-For-Content-Marketers</a></li>
<li>paper_authors: Dan Busbridge, Jason Ramapuram, Pierre Ablin, Tatiana Likhomanenko, Eeshan Gunesh Dhekane, Xavier Suau, Russ Webb</li>
<li>for: This paper aims to improve the practicality of machine learning by preserving training dynamics across batch sizes, enabling the trade-off between batch size and wall-clock time.</li>
<li>methods: The paper proposes a scaling rule for optimization in the presence of model Exponential Moving Averages (EMAs), which can improve the robustness and generalization properties of supervised learning, stabilize pseudo-labeling, and provide a learning signal for Self-Supervised Learning (SSL).</li>
<li>results: The paper demonstrates the validity of the scaling rule across a range of architectures, optimizers, and data modalities, and shows that the rule enables training of EMA-based pseudo-labeling and SSL methods at small and large batch sizes. Additionally, the paper achieves a 6x wall-clock time reduction for training BYOL up to batch size 24,576 without sacrificing performance.<details>
<summary>Abstract</summary>
Preserving training dynamics across batch sizes is an important tool for practical machine learning as it enables the trade-off between batch size and wall-clock time. This trade-off is typically enabled by a scaling rule, for example, in stochastic gradient descent, one should scale the learning rate linearly with the batch size. Another important tool for practical machine learning is the model Exponential Moving Average (EMA), which is a model copy that does not receive gradient information, but instead follows its target model with some momentum. This model EMA can improve the robustness and generalization properties of supervised learning, stabilize pseudo-labeling, and provide a learning signal for Self-Supervised Learning (SSL). Prior works have treated the model EMA separately from optimization, leading to different training dynamics across batch sizes and lower model performance. In this work, we provide a scaling rule for optimization in the presence of model EMAs and demonstrate its validity across a range of architectures, optimizers, and data modalities. We also show the rule's validity where the model EMA contributes to the optimization of the target model, enabling us to train EMA-based pseudo-labeling and SSL methods at small and large batch sizes. For SSL, we enable training of BYOL up to batch size 24,576 without sacrificing performance, optimally a 6$\times$ wall-clock time reduction.
</details>
<details>
<summary>摘要</summary>
保持批处理大小中的训练动力是实用机器学习中重要的工具，因为它允许批处理大小和墙 clock 时间之间的交换。这种交换通常是通过缩放规则实现，例如在杂散Gradient Descent中，应该将学习率linearly缩放与批处理大小。另一个重要的实用机器学习工具是模型Exponential Moving Average（EMA），它是一个不接受梯度信息，而是跟随其目标模型的模型 copier ，可以提高超vised learning的稳定性和泛化性，稳定pseudo-labeling，并为Self-Supervised Learning（SSL）提供学习信号。先前的工作将模型 EMA 分离于优化，导致不同的批处理大小中的训练动力，并降低模型性能。在这项工作中，我们提供了优化过程中模型 EMA 的缩放规则，并证明其在不同的架构、优化器和数据模式下的有效性。我们还证明了这种规则在模型 EMA 对目标模型优化的情况下，可以训练 Pseudo-labeling 和 SSL 方法，包括在小批处理大小和大批处理大小下进行训练。为 SSL，我们可以在批处理大小为 24576 的情况下训练 BYOL，无需牺牲性能，实现了墙 clock 时间的6倍减少。
</details></li>
</ul>
<hr>
<h2 id="When-Multi-Task-Learning-Meets-Partial-Supervision-A-Computer-Vision-Review"><a href="#When-Multi-Task-Learning-Meets-Partial-Supervision-A-Computer-Vision-Review" class="headerlink" title="When Multi-Task Learning Meets Partial Supervision: A Computer Vision Review"></a>When Multi-Task Learning Meets Partial Supervision: A Computer Vision Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14382">http://arxiv.org/abs/2307.14382</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maxime Fontana, Michael Spratling, Miaojing Shi</li>
<li>for: 这个论文旨在探讨多任务学习（MTL）在不同部分监督设置下如何实现。</li>
<li>methods: 论文使用了不同的参数共享技术来传递知识 между任务。</li>
<li>results: 论文介绍了多任务学习引入了多个目标函数的优化问题和挑战，并提出了根据任务关系分组任务的方法来解决这些挑战。<details>
<summary>Abstract</summary>
Multi-Task Learning (MTL) aims to learn multiple tasks simultaneously while exploiting their mutual relationships. By using shared resources to simultaneously calculate multiple outputs, this learning paradigm has the potential to have lower memory requirements and inference times compared to the traditional approach of using separate methods for each task. Previous work in MTL has mainly focused on fully-supervised methods, as task relationships can not only be leveraged to lower the level of data-dependency of those methods but they can also improve performance. However, MTL introduces a set of challenges due to a complex optimisation scheme and a higher labeling requirement. This review focuses on how MTL could be utilised under different partial supervision settings to address these challenges. First, this review analyses how MTL traditionally uses different parameter sharing techniques to transfer knowledge in between tasks. Second, it presents the different challenges arising from such a multi-objective optimisation scheme. Third, it introduces how task groupings can be achieved by analysing task relationships. Fourth, it focuses on how partially supervised methods applied to MTL can tackle the aforementioned challenges. Lastly, this review presents the available datasets, tools and benchmarking results of such methods.
</details>
<details>
<summary>摘要</summary>
First, the review analyzes how MTL traditionally uses parameter sharing techniques to transfer knowledge between tasks. Second, it discusses the challenges arising from the multi-objective optimization scheme. Third, it introduces how task groupings can be achieved by analyzing task relationships. Fourth, it focuses on how partially supervised methods applied to MTL can tackle the aforementioned challenges. Lastly, the review presents available datasets, tools, and benchmarking results of such methods.Translation notes:* "Multi-Task Learning" (MTL) is translated as "多任务学习" (duō rèn shì xué yì)* "simultaneously" is translated as "同时" (tóng shí)* "exploiting their mutual relationships" is translated as "利用它们之间的关系" (lì yòng tā men zhī jiān de guān xì)* "by using shared resources" is translated as "通过共享资源" (tōng qián gòng yè zī yuán)* "lower memory requirements" is translated as "减少内存需求" (jiǎn shang nèi yì yè xū yè)* "inference times" is translated as "推理时间" (tuī lǐ shí jiān)* "traditional approach" is translated as "传统方法" (chuán tǒng fāng fǎ)* "using separate methods for each task" is translated as "使用单独的方法处理每个任务" (shǐ yòu dan zuò de fāng fǎ xíng yì jīn yè)* "lower data-dependency" is translated as "降低数据依赖" (jiàng dào xù xiàng yì yāng)* "improve performance" is translated as "提高性能" (tím gāo xìng néng)* "mainly focused" is translated as "主要强调" (zhǔ yào qiáng dào)* "fully-supervised methods" is translated as "完全监督的方法" (quán zhěn jiān dū de fāng fǎ)* "partially supervised methods" is translated as "部分监督的方法" (bùzhèng jiān dū de fāng fǎ)* "task relationships" is translated as "任务关系" (tāsk guān xì)* "multi-objective optimization scheme" is translated as "多目标优化方案" (duō mù zhì yǎo fāng yì)* "higher labeling requirement" is translated as "更高的标签要求" (gèng gāo de biāo hǎo yào qiú)* "analyzing task relationships" is translated as "分析任务关系" (fēn xiǎo tāsk guān xì)* "task groupings" is translated as "任务分组" (tāsk fēn yè)* "partially supervised methods applied to MTL" is translated as "对MTL应用部分监督的方法" (duì MTL yì yù bùzhèng jiān dū de fāng fǎ)* "available datasets, tools, and benchmarking results" is translated as "可用的数据集、工具和比较结果" (kě yòu de xiàng jì, gōng jī, bǐ jiào jié yì)
</details></li>
</ul>
<hr>
<h2 id="EdgeConvEns-Convolutional-Ensemble-Learning-for-Edge-Intelligence"><a href="#EdgeConvEns-Convolutional-Ensemble-Learning-for-Edge-Intelligence" class="headerlink" title="EdgeConvEns: Convolutional Ensemble Learning for Edge Intelligence"></a>EdgeConvEns: Convolutional Ensemble Learning for Edge Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14381">http://arxiv.org/abs/2307.14381</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ilkay Sikdokur, İnci M. Baytaş, Arda Yurdakul</li>
<li>for: 这篇论文旨在提出一种基于 Edge 的深度学习方法，以便在Edge网络中进行计算成本高的训练，同时解决了数据隐私问题。</li>
<li>methods: 该方法使用了分布式学习方法，例如联邦学习，来在Edge设备上训练多种弱型模型，并将其ensemble成一个更高级别的模型。Edge设备上实现和训练独立的FPGA设备，并将学习到的数据表示转移到中央服务器进行集成训练。</li>
<li>results: 实验结果表明，EdgeConvEns 可以在不同训练场景下超越当前最佳性能，并且需要 fewer communications 和 less data。<details>
<summary>Abstract</summary>
Deep edge intelligence aims to deploy deep learning models that demand computationally expensive training in the edge network with limited computational power. Moreover, many deep edge intelligence applications require handling distributed data that cannot be transferred to a central server due to privacy concerns. Decentralized learning methods, such as federated learning, offer solutions where models are learned collectively by exchanging learned weights. However, they often require complex models that edge devices may not handle and multiple rounds of network communication to achieve state-of-the-art performances. This study proposes a convolutional ensemble learning approach, coined EdgeConvEns, that facilitates training heterogeneous weak models on edge and learning to ensemble them where data on edge are heterogeneously distributed. Edge models are implemented and trained independently on Field-Programmable Gate Array (FPGA) devices with various computational capacities. Learned data representations are transferred to a central server where the ensemble model is trained with the learned features received from the edge devices to boost the overall prediction performance. Extensive experiments demonstrate that the EdgeConvEns can outperform the state-of-the-art performance with fewer communications and less data in various training scenarios.
</details>
<details>
<summary>摘要</summary>
深入智能目标是在边缘网络中部署需要计算资源充足的训练深度学习模型。此外，许多深入智能应用程序需要处理分布式数据，这些数据不能被传输到中央服务器 Due to privacy concerns. 联合学习方法，如联邦学习，提供了解决方案，其中模型在分布式设备上学习并交换学习到达的权重。然而，这些方法通常需要复杂的模型，边缘设备可能无法处理，并且需要多轮网络交互以达到现场表现。本研究提出了一种 convolutional ensemble learning 方法，称为 EdgeConvEns，它可以在边缘上训练不同计算能力的弱模型，并将数据在边缘处分布的学习结果转移到中央服务器进行集成。边缘设备上实现和训练独立的 Field-Programmable Gate Array (FPGA) 设备，并将学习到的特征传输到中央服务器进行集成模型训练，以提高总预测性能。广泛的实验表明，EdgeConvEns 可以在不同的训练场景下超越现有的表现，并且需要 fewer communications 和 less data。
</details></li>
</ul>
<hr>
<h2 id="Source-Condition-Double-Robust-Inference-on-Functionals-of-Inverse-Problems"><a href="#Source-Condition-Double-Robust-Inference-on-Functionals-of-Inverse-Problems" class="headerlink" title="Source Condition Double Robust Inference on Functionals of Inverse Problems"></a>Source Condition Double Robust Inference on Functionals of Inverse Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13793">http://arxiv.org/abs/2307.13793</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrew Bennett, Nathan Kallus, Xiaojie Mao, Whitney Newey, Vasilis Syrgkanis, Masatoshi Uehara</li>
<li>for: 这篇论文是关于线性逆问题的估计 parameters的研究，特别是linear functionals of solutions to linear inverse problems的估计。</li>
<li>methods: 论文使用了doubly robust representation来表示参数，这个表示法取决于解决的 dual linear inverse problem的解。</li>
<li>results: 论文提供了第一个source condition double robust inference method，可以在参数 интереBS的附近具有准确性，只要 Either the primal or the dual inverse problem是 suficiently well-posed，而不需要知道哪一个逆问题更加well-posed。这个结果得到了iterated Tikhonov regularized adversarial estimators的新的保证，这些保证适用于一般假设空间上的线性逆问题。<details>
<summary>Abstract</summary>
We consider estimation of parameters defined as linear functionals of solutions to linear inverse problems. Any such parameter admits a doubly robust representation that depends on the solution to a dual linear inverse problem, where the dual solution can be thought as a generalization of the inverse propensity function. We provide the first source condition double robust inference method that ensures asymptotic normality around the parameter of interest as long as either the primal or the dual inverse problem is sufficiently well-posed, without knowledge of which inverse problem is the more well-posed one. Our result is enabled by novel guarantees for iterated Tikhonov regularized adversarial estimators for linear inverse problems, over general hypothesis spaces, which are developments of independent interest.
</details>
<details>
<summary>摘要</summary>
我们考虑预测定义为线性函数的参数，即解决线性逆问题中的参数。任一个参数都可以得到一个双重稳定表现，这个表现取决于解决的dual逆问题的解，可以视为对问题传递函数的一种扩展。我们提供了第一个源条件双重稳定推断方法，这个方法可以在参数的数据分布预测顶点附近对参数进行推断，只要primaldual逆问题中的一个问题够单纯，就可以获得 asymptotic normality 的 guarantees，不需要知道哪一个逆问题更加单纯。我们的结果受到iterated Tikhonov regularized adversarial estimator的 novel guarantees 的支持，这些 guarantees 适用于一般假设空间中的线性逆问题，是独立的 interessing 开发。
</details></li>
</ul>
<hr>
<h2 id="Histogram-Layer-Time-Delay-Neural-Networks-for-Passive-Sonar-Classification"><a href="#Histogram-Layer-Time-Delay-Neural-Networks-for-Passive-Sonar-Classification" class="headerlink" title="Histogram Layer Time Delay Neural Networks for Passive Sonar Classification"></a>Histogram Layer Time Delay Neural Networks for Passive Sonar Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13788">http://arxiv.org/abs/2307.13788</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/peeples-lab/hltdnn">https://github.com/peeples-lab/hltdnn</a></li>
<li>paper_authors: Jarin Ritu, Ethan Barnes, Riley Martell, Alexandra Van Dine, Joshua Peeples</li>
<li>for: 提高海上探测陌生目标的精度</li>
<li>methods:  combine时间延迟神经网络和 histogram层，利用统计上下文提高特征学习和海上听频目标识别</li>
<li>results: 比基线模型高效，demonstrate了利用统计上下文的优势Here’s a more detailed explanation of each point:</li>
<li>for: The paper is written to improve the accuracy of underwater acoustic target detection in remote marine sensing operations.</li>
<li>methods: The proposed method combines a time delay neural network and histogram layer to incorporate statistical contexts for improved feature learning and underwater acoustic target classification.</li>
<li>results: The proposed method outperforms the baseline model, demonstrating the utility in incorporating statistical contexts for passive sonar target recognition.<details>
<summary>Abstract</summary>
Underwater acoustic target detection in remote marine sensing operations is challenging due to complex sound wave propagation. Despite the availability of reliable sonar systems, target recognition remains a difficult problem. Various methods address improved target recognition. However, most struggle to disentangle the high-dimensional, non-linear patterns in the observed target recordings. In this work, a novel method combines a time delay neural network and histogram layer to incorporate statistical contexts for improved feature learning and underwater acoustic target classification. The proposed method outperforms the baseline model, demonstrating the utility in incorporating statistical contexts for passive sonar target recognition. The code for this work is publicly available.
</details>
<details>
<summary>摘要</summary>
水下声学目标检测在远程海洋探测操作中是一项复杂的任务，由于声波传播的复杂性。尽管可靠的声纳系统可以提供优质的目标检测结果，但目标识别仍然是一个困难的问题。许多方法尝试解决这个问题，但大多数方法无法分解高维、非线性的目标记录特征。在这项工作中，我们提出了一种新的方法，该方法组合了时间延迟神经网络和 histogram 层，以利用统计上下文来改善声学目标识别。我们的方法在比较基准模型时表现出色，这 demonstartes 在声学目标识别中包含统计上下文的优势。代码 для这项工作公共可用。
</details></li>
</ul>
<hr>
<h2 id="The-GANfather-Controllable-generation-of-malicious-activity-to-improve-defence-systems"><a href="#The-GANfather-Controllable-generation-of-malicious-activity-to-improve-defence-systems" class="headerlink" title="The GANfather: Controllable generation of malicious activity to improve defence systems"></a>The GANfather: Controllable generation of malicious activity to improve defence systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13787">http://arxiv.org/abs/2307.13787</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ricardo Ribeiro Pereira, Jacopo Bono, João Tiago Ascensão, David Aparício, Pedro Ribeiro, Pedro Bizarro</li>
<li>for: 这篇论文的目的是提出一种基于生成 adversarial Networks (GANs) 的方法，以生成具有黑客活动特征的样本，并且不需要标签数据。</li>
<li>methods: 这篇论文使用了 GANs 来生成黑客活动的样本，并且引入了一个额外的目标函数，以优化生成的样本具有黑客活动特征。</li>
<li>results: 这篇论文在两个实际应用案例中进行了评估，分别是防止贪污和推荐系统。在第一个应用案例中，这篇论文成功地将总金额透过一个网络的账户移动到不同的账户，而不被现有的防护系统检测到。在第二个应用案例中，这篇论文成功地将目标物品推荐到广泛的用户群中，只需要30个生成的黑客攻击者。<details>
<summary>Abstract</summary>
Machine learning methods to aid defence systems in detecting malicious activity typically rely on labelled data. In some domains, such labelled data is unavailable or incomplete. In practice this can lead to low detection rates and high false positive rates, which characterise for example anti-money laundering systems. In fact, it is estimated that 1.7--4 trillion euros are laundered annually and go undetected. We propose The GANfather, a method to generate samples with properties of malicious activity, without label requirements. We propose to reward the generation of malicious samples by introducing an extra objective to the typical Generative Adversarial Networks (GANs) loss. Ultimately, our goal is to enhance the detection of illicit activity using the discriminator network as a novel and robust defence system. Optionally, we may encourage the generator to bypass pre-existing detection systems. This setup then reveals defensive weaknesses for the discriminator to correct. We evaluate our method in two real-world use cases, money laundering and recommendation systems. In the former, our method moves cumulative amounts close to 350 thousand dollars through a network of accounts without being detected by an existing system. In the latter, we recommend the target item to a broad user base with as few as 30 synthetic attackers. In both cases, we train a new defence system to capture the synthetic attacks.
</details>
<details>
<summary>摘要</summary>
机器学习方法通常需要标注数据来帮助防御系统检测恶意活动。在某些领域，这些标注数据可能不可得或者不完整。这可能导致检测率低下，假阳性率高，这些现象在例如反走私系统中经常出现。据估计，每年1.7至4万亿欧元被贩卖而不被发现。我们提出了“GANfather”方法，可以生成具有恶意活动特征的样本，无需标注数据。我们建议在传统的生成对抗网络（GANs）损失函数中引入一个额外目标，以奖励生成恶意样本的生成器。最终，我们的目标是通过使用探测器网络作为一种新的和可靠的防御系统，提高恶意活动的检测率。可选地，我们可以让生成器尝试绕过现有的检测系统，这种设置会暴露防御系统的弱点，让探测器网络进行更好的 corrections。我们在两个实际应用中评估了我们的方法：反走私和推荐系统。在前一个应用中，我们通过一个网络的账户来转移大约35万美元，而不被现有系统发现。在后一个应用中，我们通过 Synthetic 攻击者来推荐目标项目，并且只需要30名Synthetic 攻击者。在两个案例中，我们训练了一个新的防御系统，以捕捉Synthetic 攻击。
</details></li>
</ul>
<hr>
<h2 id="Robust-Assignment-of-Labels-for-Active-Learning-with-Sparse-and-Noisy-Annotations"><a href="#Robust-Assignment-of-Labels-for-Active-Learning-with-Sparse-and-Noisy-Annotations" class="headerlink" title="Robust Assignment of Labels for Active Learning with Sparse and Noisy Annotations"></a>Robust Assignment of Labels for Active Learning with Sparse and Noisy Annotations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14380">http://arxiv.org/abs/2307.14380</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Kałuża, Andrzej Janusz, Dominik Ślęzak</li>
<li>for: 提高活动学习中缺失数据标注的质量</li>
<li>methods: 提出了两种基于无标注部分的样本空间的注解统一算法，需要少量或无 intersect  между不同专家的标注</li>
<li>results: 实验结果表明提出的方法在估计专家的可靠性和实际标签分配方面具有坚定性和超越性，并且在四个公共数据集上达到了最佳效果。<details>
<summary>Abstract</summary>
Supervised classification algorithms are used to solve a growing number of real-life problems around the globe. Their performance is strictly connected with the quality of labels used in training. Unfortunately, acquiring good-quality annotations for many tasks is infeasible or too expensive to be done in practice. To tackle this challenge, active learning algorithms are commonly employed to select only the most relevant data for labeling. However, this is possible only when the quality and quantity of labels acquired from experts are sufficient. Unfortunately, in many applications, a trade-off between annotating individual samples by multiple annotators to increase label quality vs. annotating new samples to increase the total number of labeled instances is necessary. In this paper, we address the issue of faulty data annotations in the context of active learning. In particular, we propose two novel annotation unification algorithms that utilize unlabeled parts of the sample space. The proposed methods require little to no intersection between samples annotated by different experts. Our experiments on four public datasets indicate the robustness and superiority of the proposed methods in both, the estimation of the annotator's reliability, and the assignment of actual labels, against the state-of-the-art algorithms and the simple majority voting.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Accuracy-Amplification-in-Differentially-Private-Logistic-Regression-A-Pre-Training-Approach"><a href="#Accuracy-Amplification-in-Differentially-Private-Logistic-Regression-A-Pre-Training-Approach" class="headerlink" title="Accuracy Amplification in Differentially Private Logistic Regression: A Pre-Training Approach"></a>Accuracy Amplification in Differentially Private Logistic Regression: A Pre-Training Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13771">http://arxiv.org/abs/2307.13771</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Hoseinpour, Milad Hoseinpour, Ali Aghagolzadeh</li>
<li>for: 这篇论文的目的是提高具有隐私保证的机器学习（DP-ML）模型的准确性。</li>
<li>methods: 本论文使用了预训模组来提高DP-ML模型的准确性。这个预训模组首先在公开的训练 dataset 上进行预训，然后在具有隐私保证的私人训练 dataset 上进行微调。</li>
<li>results: numerical results show that adding a pre-training module significantly improves the accuracy of the DP logistic regression.<details>
<summary>Abstract</summary>
Machine learning (ML) models can memorize training datasets. As a result, training ML models over private datasets can violate the privacy of individuals. Differential privacy (DP) is a rigorous privacy notion to preserve the privacy of underlying training datasets in ML models. Yet, training ML models in a DP framework usually degrades the accuracy of ML models. This paper aims to boost the accuracy of a DP-ML model, specifically a logistic regression model, via a pre-training module. In more detail, we initially pre-train our model on a public training dataset that there is no privacy concern about it. Then, we fine-tune our model via the DP logistic regression with the private dataset. In the numerical results, we show that adding a pre-training module significantly improves the accuracy of the DP logistic regression.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ClusterSeq-Enhancing-Sequential-Recommender-Systems-with-Clustering-based-Meta-Learning"><a href="#ClusterSeq-Enhancing-Sequential-Recommender-Systems-with-Clustering-based-Meta-Learning" class="headerlink" title="ClusterSeq: Enhancing Sequential Recommender Systems with Clustering based Meta-Learning"></a>ClusterSeq: Enhancing Sequential Recommender Systems with Clustering based Meta-Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13766">http://arxiv.org/abs/2307.13766</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammmadmahdi Maheri, Reza Abdollahzadeh, Bardia Mohammadi, Mina Rafiei, Jafar Habibi, Hamid R. Rabiee</li>
<li>for: 这个研究旨在解决用户冰对问题，即用户在推荐系统中的内部状态难以准确决定。</li>
<li>methods: 这个研究使用了meta-学习和用户项目信息，以增强预测项目的准确性。</li>
<li>results: 实验结果显示， compared to existing meta-learning recommenders, 我们的提案方法可以 achieve a substantial improvement of 16-39% in Mean Reciprocal Rank (MRR)。<details>
<summary>Abstract</summary>
In practical scenarios, the effectiveness of sequential recommendation systems is hindered by the user cold-start problem, which arises due to limited interactions for accurately determining user preferences. Previous studies have attempted to address this issue by combining meta-learning with user and item-side information. However, these approaches face inherent challenges in modeling user preference dynamics, particularly for "minor users" who exhibit distinct preferences compared to more common or "major users." To overcome these limitations, we present a novel approach called ClusterSeq, a Meta-Learning Clustering-Based Sequential Recommender System. ClusterSeq leverages dynamic information in the user sequence to enhance item prediction accuracy, even in the absence of side information. This model preserves the preferences of minor users without being overshadowed by major users, and it capitalizes on the collective knowledge of users within the same cluster. Extensive experiments conducted on various benchmark datasets validate the effectiveness of ClusterSeq. Empirical results consistently demonstrate that ClusterSeq outperforms several state-of-the-art meta-learning recommenders. Notably, compared to existing meta-learning methods, our proposed approach achieves a substantial improvement of 16-39% in Mean Reciprocal Rank (MRR).
</details>
<details>
<summary>摘要</summary>
实际应用场景中，顺序推荐系统的效果受用户冷启动问题的限制，这种问题由用户的交互数量有限制，难以准确地确定用户的偏好。先前的研究尝试通过将meta学与用户和项信息结合来解决这个问题，但这些方法面临用户偏好动态模型化的内在挑战，特别是对"小用户"来说，他们的偏好比"大用户"更加独特。为了解决这些限制，我们提出了一种新的方法 called ClusterSeq，这是一种基于集群学习的顺序推荐系统。ClusterSeq利用用户序列中的动态信息来提高项预测精度，即使在没有侧 информация的情况下。这个模型保持了"小用户"的偏好，不被"大用户"所掩蔽，同时充分利用用户同一个集群内的共同知识。我们在不同的 benchmark 数据集上进行了广泛的实验，结果表明，ClusterSeq 比许多现有的meta学推荐器表现出较好的效果。empirical 结果表明，ClusterSeq 与现有meta学方法相比，在 Mean Reciprocal Rank（MRR）上实现了16-39%的显著提升。
</details></li>
</ul>
<hr>
<h2 id="Implicitly-Normalized-Explicitly-Regularized-Density-Estimation"><a href="#Implicitly-Normalized-Explicitly-Regularized-Density-Estimation" class="headerlink" title="Implicitly Normalized Explicitly Regularized Density Estimation"></a>Implicitly Normalized Explicitly Regularized Density Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13763">http://arxiv.org/abs/2307.13763</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mark Kozdoba, Binyamin Perets, Shie Mannor</li>
<li>for: 本研究提出了一种新的非参数density估计方法，基于 Sobolev 范数regularization。这种方法与kernel density estimation不同，可以提供明确可读的模型偏差。</li>
<li>methods: 本方法无法closed analytic form的kernel，可以通过采样来approximation。优化问题需要解决是非核vex的，标准的梯度方法不太好。然而，我们表明，采用适当的初始化和自然梯度，可以获得良好的解决方案。</li>
<li>results: 本研究使用了recent Anomaly Detection benchmark suite, ADBench,进行评估，并得到了第二好的成绩，在more than 15algorithms中。<details>
<summary>Abstract</summary>
We propose a new approach to non-parametric density estimation, that is based on regularizing a Sobolev norm of the density. This method is provably different from Kernel Density Estimation, and makes the bias of the model clear and interpretable. While there is no closed analytic form for the associated kernel, we show that one can approximate it using sampling. The optimization problem needed to determine the density is non-convex, and standard gradient methods do not perform well. However, we show that with an appropriate initialization and using natural gradients, one can obtain well performing solutions. Finally, while the approach provides unnormalized densities, which prevents the use of log-likelihood for cross validation, we show that one can instead adapt Fisher Divergence based Score Matching methods for this task. We evaluate the resulting method on the comprehensive recent Anomaly Detection benchmark suite, ADBench, and find that it ranks second best, among more than 15 algorithms.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的非参数化概率分布估计方法，基于 Sobolev 范数regularization。这种方法与核密度估计方法不同，可以让模型的偏见变得明确和可解释。虽然关联的核函数没有关闭的分析形式，但我们表明可以使用抽象来近似它。估计问题需要解决的非 convex 问题，标准的梯度法不太适用。然而，我们表明，通过适当的初始化和使用自然梯度，可以获得良好的解决方案。虽然方法提供的概率分布无法使用对数分布来进行验证，但我们表明可以使用基于 Fisher 分布的分数匹配方法来实现这一点。我们对最新的 Anomaly Detection 测试集 ADBench 进行了评估，并发现其在超过 15 种算法中排名第二。
</details></li>
</ul>
<hr>
<h2 id="UPREVE-An-End-to-End-Causal-Discovery-Benchmarking-System"><a href="#UPREVE-An-End-to-End-Causal-Discovery-Benchmarking-System" class="headerlink" title="UPREVE: An End-to-End Causal Discovery Benchmarking System"></a>UPREVE: An End-to-End Causal Discovery Benchmarking System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13757">http://arxiv.org/abs/2307.13757</a></li>
<li>repo_url: None</li>
<li>paper_authors: Suraj Jyothi Unni, Paras Sheth, Kaize Ding, Huan Liu, K. Selcuk Candan</li>
<li>for: 提高 complex socio-behavioral systems 中 causal relationships 的发现，以便更好地做出决策。</li>
<li>methods: 提供了一个用户友好的 web-based graphical user interface (GUI)，可以同时运行多种算法，视觉化 causal relationships，并评估学习的 causal graphs 的准确性。</li>
<li>results: 可以帮助研究者和实践者更好地探索和理解 causal relationships，从而获得更好的决策。<details>
<summary>Abstract</summary>
Discovering causal relationships in complex socio-behavioral systems is challenging but essential for informed decision-making. We present Upload, PREprocess, Visualize, and Evaluate (UPREVE), a user-friendly web-based graphical user interface (GUI) designed to simplify the process of causal discovery. UPREVE allows users to run multiple algorithms simultaneously, visualize causal relationships, and evaluate the accuracy of learned causal graphs. With its accessible interface and customizable features, UPREVE empowers researchers and practitioners in social computing and behavioral-cultural modeling (among others) to explore and understand causal relationships effectively. Our proposed solution aims to make causal discovery more accessible and user-friendly, enabling users to gain valuable insights for better decision-making.
</details>
<details>
<summary>摘要</summary>
发现复杂社会行为系统中的 causal 关系是挑战性的，但是这是 informed decision-making 的关键。我们提出了 Upload, PREprocess, Visualize, and Evaluate (UPREVE)，一个用户友好的网页式 graphical user interface (GUI)，用于简化 causal discovery 的过程。UPREVE 允许用户同时运行多个算法，可视化 causal 关系，并评估学习的 causal 图的准确性。它的可访问性和可定制功能使得社会计算和行为文化模型等研究人员能够有效地探索和理解 causal 关系，从而获得价值的情报。我们的提案的目标是使 causal discovery 更加访问ible 和用户友好，使用户能够更好地理解 causal 关系，以便更好的决策。
</details></li>
</ul>
<hr>
<h2 id="Solution-Path-of-Time-varying-Markov-Random-Fields-with-Discrete-Regularization"><a href="#Solution-Path-of-Time-varying-Markov-Random-Fields-with-Discrete-Regularization" class="headerlink" title="Solution Path of Time-varying Markov Random Fields with Discrete Regularization"></a>Solution Path of Time-varying Markov Random Fields with Discrete Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13750">http://arxiv.org/abs/2307.13750</a></li>
<li>repo_url: None</li>
<li>paper_authors: Salar Fattahi, Andres Gomez</li>
<li>for: 这个论文目的是解决推理稀疏时变Markov随机场（MRF）的问题，具有不同的抽象和时间正则化。</li>
<li>methods: 该论文使用的方法是基于新的受限制优化问题，以提高参数的稀疏性。这个方法可以 Parametrically解决，并且可以在几乎所有稀疏程度下得到解决方案。</li>
<li>results: 论文表明，该方法可以在不同类型的时变MRF中实现提高的优化性和精度，并且可以在几乎实际情况下的数据规模下进行 Parametric 解决。此外，论文还实现了在几分钟内解决3000万变量的实例问题。<details>
<summary>Abstract</summary>
We study the problem of inferring sparse time-varying Markov random fields (MRFs) with different discrete and temporal regularizations on the parameters. Due to the intractability of discrete regularization, most approaches for solving this problem rely on the so-called maximum-likelihood estimation (MLE) with relaxed regularization, which neither results in ideal statistical properties nor scale to the dimensions encountered in realistic settings. In this paper, we address these challenges by departing from the MLE paradigm and resorting to a new class of constrained optimization problems with exact, discrete regularization to promote sparsity in the estimated parameters. Despite the nonconvex and discrete nature of our formulation, we show that it can be solved efficiently and parametrically for all sparsity levels. More specifically, we show that the entire solution path of the time-varying MRF for all sparsity levels can be obtained in $\mathcal{O}(pT^3)$, where $T$ is the number of time steps and $p$ is the number of unknown parameters at any given time. The efficient and parametric characterization of the solution path renders our approach highly suitable for cross-validation, where parameter estimation is required for varying regularization values. Despite its simplicity and efficiency, we show that our proposed approach achieves provably small estimation error for different classes of time-varying MRFs, namely Gaussian and discrete MRFs, with as few as one sample per time. Utilizing our algorithm, we can recover the complete solution path for instances of time-varying MRFs featuring over 30 million variables in less than 12 minutes on a standard laptop computer. Our code is available at \url{https://sites.google.com/usc.edu/gomez/data}.
</details>
<details>
<summary>摘要</summary>
我们研究了推理缺少时间变化Markov随机场（MRF）的问题，其中参数具有不同的整数和时间规则化。由于整数规则化的不可解性，大多数解决这个问题的方法都基于最大 likelihood估计（MLE）的宽松规则化，这并不会导致理想的统计特性，nor scale to the dimensions encountered in realistic settings。在这篇论文中，我们解决这些挑战，我们 departure from the MLE paradigm and resort to a new class of constrained optimization problems with exact, discrete regularization to promote sparsity in the estimated parameters。尽管我们的形式ulation是非 convex和整数的，我们展示了可以有效地和 Parametrically解决这个问题。具体来说，我们表明了时间变化MRF的解的整个解 paths可以在 $\mathcal{O}(pT^3)$ 时间内获得，其中 $T$ 是时间步骤数量，$p$ 是任何时间点的未知参数数量。这种有效和 Parametrically 的解决方法使得我们的方法高度适合 cross-validation，其中需要在不同规则值下进行参数估计。尽管它的简单和高效性，我们证明了我们提议的方法可以在不同类型的时间变化MRFs 中实现可观测小的估计误差，只需要一个时间步骤中的一个样本。我们可以在 less than 12 分钟内在标准笔记计算机上解决了包含超过 30 万个变量的时间变化MRFs 的完整解 paths。我们的代码可以在 \url{https://sites.google.com/usc.edu/gomez/data} 上获取。
</details></li>
</ul>
<hr>
<h2 id="mL-BFGS-A-Momentum-based-L-BFGS-for-Distributed-Large-Scale-Neural-Network-Optimization"><a href="#mL-BFGS-A-Momentum-based-L-BFGS-for-Distributed-Large-Scale-Neural-Network-Optimization" class="headerlink" title="mL-BFGS: A Momentum-based L-BFGS for Distributed Large-Scale Neural Network Optimization"></a>mL-BFGS: A Momentum-based L-BFGS for Distributed Large-Scale Neural Network Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13744">http://arxiv.org/abs/2307.13744</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yue Niu, Zalan Fabian, Sunwoo Lee, Mahdi Soltanolkotabi, Salman Avestimehr</li>
<li>for: 这个论文目的是提出一种基于准新顿法的轻量级深度神经网络优化算法，以便在大规模分布式深度神经网络优化中使用。</li>
<li>methods: 该论文使用了一种叫做mL-BFGS的新算法，它是一种基于准新顿法的满足约束的批量优化算法，具有较低的计算成本和稳定的收敛性。</li>
<li>results: 在对一些标准神经网络模型的训练中，mL-BFGS算法比基于SGD、Adam和其他准新顿法的算法得到了更好的性能，同时也比基于准新顿法的算法更快。<details>
<summary>Abstract</summary>
Quasi-Newton methods still face significant challenges in training large-scale neural networks due to additional compute costs in the Hessian related computations and instability issues in stochastic training. A well-known method, L-BFGS that efficiently approximates the Hessian using history parameter and gradient changes, suffers convergence instability in stochastic training. So far, attempts that adapt L-BFGS to large-scale stochastic training incur considerable extra overhead, which offsets its convergence benefits in wall-clock time. In this paper, we propose mL-BFGS, a lightweight momentum-based L-BFGS algorithm that paves the way for quasi-Newton (QN) methods in large-scale distributed deep neural network (DNN) optimization. mL-BFGS introduces a nearly cost-free momentum scheme into L-BFGS update and greatly reduces stochastic noise in the Hessian, therefore stabilizing convergence during stochastic optimization. For model training at a large scale, mL-BFGS approximates a block-wise Hessian, thus enabling distributing compute and memory costs across all computing nodes. We provide a supporting convergence analysis for mL-BFGS in stochastic settings. To investigate mL-BFGS potential in large-scale DNN training, we train benchmark neural models using mL-BFGS and compare performance with baselines (SGD, Adam, and other quasi-Newton methods). Results show that mL-BFGS achieves both noticeable iteration-wise and wall-clock speedup.
</details>
<details>
<summary>摘要</summary>
对于大规模神经网络训练而言，类新顿方法仍然面临着 significiant 的挑战，主要是在条件 Compute 成本和统计训练中发生的不稳定性问题。一种广泛使用的方法是 L-BFGS，它可以有效地预测 Hessian 的值，但在随机训练中却会出现问题，导致训练不稳定。在这篇论文中，我们提出了 mL-BFGS，一种轻量级的态势-基本方法，它可以在大规模分布式深度神经网络优化中实现类新顿方法的可行性。mL-BFGS 通过将态势给动的思想引入 L-BFGS 更新，很大地减少了随机训练中的条件统计误差，因此稳定了训练的条件。为了在大规模的模型训练中实现分布式计算和内存成本的分摊，mL-BFGS 采用了对称的封页 Hessian 估计。我们提供了支持 mL-BFGS 在随机设定下的均衡分析。为了评估 mL-BFGS 在大规模 DNN 训练中的可能性，我们使用 mL-BFGS 训练了一些benchmark神经网络模型，并与基eline (SGD, Adam, 其他类新顿方法) 进行比较。结果显示，mL-BFGS 可以在随机训练中获得明显的迭代次数和实际时间优化。
</details></li>
</ul>
<hr>
<h2 id="ARB-Advanced-Reasoning-Benchmark-for-Large-Language-Models"><a href="#ARB-Advanced-Reasoning-Benchmark-for-Large-Language-Models" class="headerlink" title="ARB: Advanced Reasoning Benchmark for Large Language Models"></a>ARB: Advanced Reasoning Benchmark for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13692">http://arxiv.org/abs/2307.13692</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tomohiro Sawada, Daniel Paleka, Alexander Havrilla, Pranav Tadepalli, Paula Vidas, Alexander Kranias, John J. Nay, Kshitij Gupta, Aran Komatsuzaki</li>
<li>for: 本研究旨在提供一个新的评价标准 benchmark，以测试大型自然语言模型（LLM）在多个领域的高级推理能力。</li>
<li>methods: 本研究使用了一个新的评价标准，即 ARB，该标准包括了多个领域的高级推理问题。此外，研究还使用了一种新的评价方法，即 rubric-based evaluation approach，以提高自动和协助评价能力。</li>
<li>results: 研究发现，当前的LLM模型在ARB中的得分较低，只有在一些较为简单的问题上达到了50%的得分。此外，人工评价结果与GPT-4的自动评价结果之间存在了良好的一致性。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have demonstrated remarkable performance on various quantitative reasoning and knowledge benchmarks. However, many of these benchmarks are losing utility as LLMs get increasingly high scores, despite not yet reaching expert performance in these domains. We introduce ARB, a novel benchmark composed of advanced reasoning problems in multiple fields. ARB presents a more challenging test than prior benchmarks, featuring problems in mathematics, physics, biology, chemistry, and law. As a subset of ARB, we introduce a challenging set of math and physics problems which require advanced symbolic reasoning and domain knowledge. We evaluate recent models such as GPT-4 and Claude on ARB and demonstrate that current models score well below 50% on more demanding tasks. In order to improve both automatic and assisted evaluation capabilities, we introduce a rubric-based evaluation approach, allowing GPT-4 to score its own intermediate reasoning steps. Further, we conduct a human evaluation of the symbolic subset of ARB, finding promising agreement between annotators and GPT-4 rubric evaluation scores.
</details>
<details>
<summary>摘要</summary>
大语言模型（LLM）已经表现出了非常出色的表现力在不同的量化逻辑和知识测试中。然而，许多这些测试在LLM获得高分后就失去了用途，即使它们还没有在这些领域达到专家水平。我们介绍了ARB，一个新的测试套件，它包含了多个领域的高级逻辑问题。ARB比之前的测试更加具有挑战性，包括数学、物理、生物、化学和法律等领域的问题。为ARB的一个子集，我们引入了一个有chedding的数学和物理问题集，它们需要高级符号逻辑和领域知识。我们使用GPT-4和Claude等最新的模型测试ARB，并发现现在的模型在更加具有挑战性的任务上的表现仍然落后于50%。为了提高自动和协助评估能力，我们引入了一种基于笔记的评估方法，允许GPT-4自己评估其中间的符号逻辑步骤。此外，我们进行了人类评估ARB的符号子集，发现和GPT-4笔记评估得分具有惊人的一致性。
</details></li>
</ul>
<hr>
<h2 id="High-Probability-Analysis-for-Non-Convex-Stochastic-Optimization-with-Clipping"><a href="#High-Probability-Analysis-for-Non-Convex-Stochastic-Optimization-with-Clipping" class="headerlink" title="High Probability Analysis for Non-Convex Stochastic Optimization with Clipping"></a>High Probability Analysis for Non-Convex Stochastic Optimization with Clipping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13680">http://arxiv.org/abs/2307.13680</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shaojie Li, Yong Liu</li>
<li>for: 这个论文主要针对 Stochastic Optimization 中的 Gradient Clipping 技术，并提供了对这种技术的高机会分析和优化性能 bound。</li>
<li>methods: 论文使用了 Stochastic Gradient Descent 和其变种（包括带有权重和步长调整的 SGD），以及 Gradient Clipping 技术。</li>
<li>results: 论文提供了对 Stochastic Optimization 算法和 Gradient Clipping 技术的高机会分析和优化性能 bound，并研究了一种强度 bounded 的 $\alpha$-th moment 假设，以推导出更强的 теорем guarantees。<details>
<summary>Abstract</summary>
Gradient clipping is a commonly used technique to stabilize the training process of neural networks. A growing body of studies has shown that gradient clipping is a promising technique for dealing with the heavy-tailed behavior that emerged in stochastic optimization as well. While gradient clipping is significant, its theoretical guarantees are scarce. Most theoretical guarantees only provide an in-expectation analysis and only focus on optimization performance. In this paper, we provide high probability analysis in the non-convex setting and derive the optimization bound and the generalization bound simultaneously for popular stochastic optimization algorithms with gradient clipping, including stochastic gradient descent and its variants of momentum and adaptive stepsizes. With the gradient clipping, we study a heavy-tailed assumption that the gradients only have bounded $\alpha$-th moments for some $\alpha \in (1, 2]$, which is much weaker than the standard bounded second-moment assumption. Overall, our study provides a relatively complete picture for the theoretical guarantee of stochastic optimization algorithms with clipping.
</details>
<details>
<summary>摘要</summary>
Gradient clipping 是一种常用的技术来稳定神经网络的训练过程。一组不断增长的研究表明，Gradient clipping 是一种有前途的技术，用于处理随机优化中的重 tailed 行为。虽然 Gradient clipping 具有重要性，但其理论保证却 scarce。大多数理论保证都仅提供了预期分析，只关注优化性能。在这篇论文中，我们提供了高概率分析在非对称设定下，并同时 deriv 出优化 bound 和泛化 bound  для流行的随机优化算法与 Gradient clipping，包括随机梯度下降和其 variants of momentum 和 adaptive stepsizes。在使用 Gradient clipping 时，我们研究了一种偏值 $\alpha $-th moment 只有bounded 的假设，其中 $\alpha \in (1, 2] $，这是标准二次 moments 假设的很弱条件。总的来说，我们的研究提供了针对随机优化算法与 clipping 的理论保证的相对完整的图像。
</details></li>
</ul>
<hr>
<h2 id="RED-CoMETS-An-ensemble-classifier-for-symbolically-represented-multivariate-time-series"><a href="#RED-CoMETS-An-ensemble-classifier-for-symbolically-represented-multivariate-time-series" class="headerlink" title="RED CoMETS: An ensemble classifier for symbolically represented multivariate time series"></a>RED CoMETS: An ensemble classifier for symbolically represented multivariate time series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13679">http://arxiv.org/abs/2307.13679</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zy18811/red-comets">https://github.com/zy18811/red-comets</a></li>
<li>paper_authors: Luca A. Bennett, Zahraa S. Abdallah</li>
<li>For: The paper is written for researchers and practitioners working in the field of multivariate time series classification, particularly in finance, healthcare, engineering, and other related fields.* Methods: The paper proposes a novel ensemble classifier called RED CoMETS, which builds upon the success of Co-eye and extends its capabilities to handle multivariate time series data. The proposed method uses a combination of random enhanced co-eye and symbolic representation to improve the accuracy and efficiency of multivariate time series classification.* Results: The paper demonstrates the performance of RED CoMETS on benchmark datasets from the UCR archive, achieving competitive accuracy compared to state-of-the-art techniques in multivariate settings. Specifically, it achieves the highest reported accuracy in the literature for the ‘HandMovementDirection’ dataset. Additionally, the proposed method significantly reduces computation time compared to Co-eye, making it an efficient and effective choice for multivariate time series classification.Here is the simplified Chinese text for the three key points:* For: 这篇论文是为了推广多变量时间序列分类领域的研究人员和实践者而写的。* Methods: 这篇论文提出了一种新的ensemble分类器 called RED CoMETS，它基于Co-eye的成功并将其扩展到多变量时间序列数据上。提出的方法使用Random Enhanced Co-eye和符号表示来提高多变量时间序列分类的准确性和效率。* Results: 论文通过对UCR数据集的测试，展示了RED CoMETS的性能，与多变量时间序列分类领域的状态 искусственный技术相比，它达到了最高的报告精度。此外，提出的方法还能够显著减少计算时间，使其成为效率和可靠的多变量时间序列分类选择。<details>
<summary>Abstract</summary>
Multivariate time series classification is a rapidly growing research field with practical applications in finance, healthcare, engineering, and more. The complexity of classifying multivariate time series data arises from its high dimensionality, temporal dependencies, and varying lengths. This paper introduces a novel ensemble classifier called RED CoMETS (Random Enhanced Co-eye for Multivariate Time Series), which addresses these challenges. RED CoMETS builds upon the success of Co-eye, an ensemble classifier specifically designed for symbolically represented univariate time series, and extends its capabilities to handle multivariate data. The performance of RED CoMETS is evaluated on benchmark datasets from the UCR archive, where it demonstrates competitive accuracy when compared to state-of-the-art techniques in multivariate settings. Notably, it achieves the highest reported accuracy in the literature for the 'HandMovementDirection' dataset. Moreover, the proposed method significantly reduces computation time compared to Co-eye, making it an efficient and effective choice for multivariate time series classification.
</details>
<details>
<summary>摘要</summary>
多变量时间序列分类是一个快速发展的研究领域，有实际应用于金融、医疗、工程等领域。multivariate时间序列数据的复杂性来自其高维度、时间相关性和不同长度。这篇论文介绍了一种新的团队分类器called RED CoMETS（随机增强共视 для多变量时间序列），该方法解决了这些挑战。RED CoMETS基于Co-eye Ensemble分类器，该分类器专门为symbolically represented单变量时间序列设计，并扩展其能力以处理多变量数据。本文评估了RED CoMETS的性能，并与state-of-the-art多变量设置比较。结果表明，RED CoMETS在UCAR archive的 benchmark数据集上达到了Literature中最高的报告精度，特别是在'HandMovementDirection'数据集上。此外，提议的方法可以significantly reduce computation time compared to Co-eye，使其成为efficient和effective的多变量时间序列分类方法。
</details></li>
</ul>
<hr>
<h2 id="FedDRL-A-Trustworthy-Federated-Learning-Model-Fusion-Method-Based-on-Staged-Reinforcement-Learning"><a href="#FedDRL-A-Trustworthy-Federated-Learning-Model-Fusion-Method-Based-on-Staged-Reinforcement-Learning" class="headerlink" title="FedDRL: A Trustworthy Federated Learning Model Fusion Method Based on Staged Reinforcement Learning"></a>FedDRL: A Trustworthy Federated Learning Model Fusion Method Based on Staged Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13716">http://arxiv.org/abs/2307.13716</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leiming Chen, Cihao Dong, Sibo Qiao, Ziling Huang, Kai Wang, Yuming Nie, Zhaoxiang Hou, Cheewei Tan</li>
<li>for: 解决传统 federated learning 中客户端模型质量不均匀和恶意上传模型的问题</li>
<li>methods: 使用 reinforcement learning 进行模型融合，包括两个阶段：第一阶段过滤恶意模型并选择可信客户端模型参与融合，第二阶段adaptively 调整可信客户端模型的权重并融合最佳全球模型</li>
<li>results: 在五种模型融合场景中，我们的算法比基eline algorithms 高于可靠性而保持准确性<details>
<summary>Abstract</summary>
Traditional federated learning uses the number of samples to calculate the weights of each client model and uses this fixed weight value to fusion the global model. However, in practical scenarios, each client's device and data heterogeneity leads to differences in the quality of each client's model. Thus the contribution to the global model is not wholly determined by the sample size. In addition, if clients intentionally upload low-quality or malicious models, using these models for aggregation will lead to a severe decrease in global model accuracy. Traditional federated learning algorithms do not address these issues. To solve this probelm, we propose FedDRL, a model fusion approach using reinforcement learning based on a two staged approach. In the first stage, Our method could filter out malicious models and selects trusted client models to participate in the model fusion. In the second stage, the FedDRL algorithm adaptively adjusts the weights of the trusted client models and aggregates the optimal global model. We also define five model fusion scenarios and compare our method with two baseline algorithms in those scenarios. The experimental results show that our algorithm has higher reliability than other algorithms while maintaining accuracy.
</details>
<details>
<summary>摘要</summary>
传统的联合学习方法使用客户端模型的样本数来计算每个客户端模型的权重，并使用这些固定权重值进行模型融合。然而，在实际场景中，每个客户端的设备和数据多样性会导致每个客户端模型的质量差异。因此，使用传统的联合学习算法来融合所有客户端模型可能会导致全局模型的准确率下降。此外，如果客户端故意上传低质量或黑客模型，使用这些模型进行融合会导致全局模型的准确率受到严重的影响。传统的联合学习算法不能解决这些问题。为解决这些问题，我们提出了 FedDRL，一种基于强化学习的模型融合方法。在第一阶段，我们的方法可以过滤掉黑客模型，并选择可信worth的客户端模型参与模型融合。在第二阶段，FedDRL算法可以自适应地调整可信worth的客户端模型的权重，并将这些权重加权的全局模型进行融合。我们还定义了五种模型融合场景，并与两种基准算法进行比较。实验结果表明，我们的算法在可靠性和准确率之间做出了折衔。
</details></li>
</ul>
<hr>
<h2 id="Towards-an-AI-Accountability-Policy"><a href="#Towards-an-AI-Accountability-Policy" class="headerlink" title="Towards an AI Accountability Policy"></a>Towards an AI Accountability Policy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13658">http://arxiv.org/abs/2307.13658</a></li>
<li>repo_url: None</li>
<li>paper_authors: Przemyslaw Grabowicz, Nicholas Perello, Yair Zick</li>
<li>for: 这份白皮书是回应美国国家电信和信息管理局（NTIA）发布的“人工智能责任政策请求意见”（AI Accountability Policy Request for Comments）。</li>
<li>methods: 该白皮书提供了一套相互连接的建议，用于制定人工智能责任政策。</li>
<li>results: 该白皮书的建议旨在确保人工智能技术的应用符合道德和法律要求，保障公民的权益和隐私，并促进人工智能技术的负责任和可靠性。<details>
<summary>Abstract</summary>
This white paper is a response to the "AI Accountability Policy Request for Comments" by the National Telecommunications and Information Administration of the United States. The question numbers for which comments were requested are provided in superscripts at the end of key sentences answering the respective questions. The white paper offers a set of interconnected recommendations for an AI accountability policy.
</details>
<details>
<summary>摘要</summary>
这份白皮是回应美国国家电信管理局（NTIA）发布的“人工智能责任政策公开征求意见”（AI责任政策公开征求意见）的回应。文中提到的问题号用超文字标注在关键句中回答相应的问题。本白皮提供了一组相互关联的人工智能责任政策建议。
</details></li>
</ul>
<hr>
<h2 id="GNN4FR-A-Lossless-GNN-based-Federated-Recommendation-Framework"><a href="#GNN4FR-A-Lossless-GNN-based-Federated-Recommendation-Framework" class="headerlink" title="GNN4FR: A Lossless GNN-based Federated Recommendation Framework"></a>GNN4FR: A Lossless GNN-based Federated Recommendation Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01197">http://arxiv.org/abs/2308.01197</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guowei Wu, Weike Pan, Zhong Ming</li>
<li>for: 提供一种 Privacy-preserving federated recommendation framework based on Graph Neural Networks (GNNs), which can train a global graph without leaking each user’s private interaction data.</li>
<li>methods: 使用 LightGCN 实例化该框架，并证明其与非联合版本等价。</li>
<li>results: 实现了全图训练，保持完整的高阶结构信息，使训练过程与非联合版本等价。<details>
<summary>Abstract</summary>
Graph neural networks (GNNs) have gained wide popularity in recommender systems due to their capability to capture higher-order structure information among the nodes of users and items. However, these methods need to collect personal interaction data between a user and the corresponding items and then model them in a central server, which would break the privacy laws such as GDPR. So far, no existing work can construct a global graph without leaking each user's private interaction data (i.e., his or her subgraph). In this paper, we are the first to design a novel lossless federated recommendation framework based on GNN, which achieves full-graph training with complete high-order structure information, enabling the training process to be equivalent to the corresponding un-federated counterpart. In addition, we use LightGCN to instantiate an example of our framework and show its equivalence.
</details>
<details>
<summary>摘要</summary>
graph neural networks (GNNs) 在推荐系统中得到了广泛的应用，因为它们可以捕捉用户和物品之间的高阶结构信息。然而，这些方法需要收集用户与对应物品之间的个人互动数据，并将其模型在中央服务器上，这会违反隐私法规，如GDPR。到目前为止，没有任何现有的工作可以构建一个全球图 Without leaking each user's private interaction data (i.e., his or her subgraph).在这篇论文中，我们是首次设计了一种新的无损联邦推荐框架基于GNN，可以实现全图训练，并保持高阶结构信息完整性，使训练过程与相应的非联邦 counterpart等价。此外，我们使用 LightGCN 实例化我们的框架，并证明其等价性。
</details></li>
</ul>
<hr>
<h2 id="Safety-Margins-for-Reinforcement-Learning"><a href="#Safety-Margins-for-Reinforcement-Learning" class="headerlink" title="Safety Margins for Reinforcement Learning"></a>Safety Margins for Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13642">http://arxiv.org/abs/2307.13642</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexander Grushin, Walt Woods, Alvaro Velasquez, Simon Khan</li>
<li>for: This paper is written for autonomous controllers in freight transportation applications, to help identify when unsafe situations are about to occur and draw timely human oversight.</li>
<li>methods: The paper uses a definition of true criticality as the mean reduction in reward given some number of random actions, and computes proxy criticality metrics that can be compared to the true criticality in real-time.</li>
<li>results: The paper demonstrates how to leverage these proxy metrics to generate safety margins, which directly tie the consequences of potentially incorrect actions to an anticipated loss in overall performance. The approach is evaluated on learned policies from APE-X and A3C within an Atari environment, and shows how safety margins decrease as agents approach failure states.<details>
<summary>Abstract</summary>
Any autonomous controller will be unsafe in some situations. The ability to quantitatively identify when these unsafe situations are about to occur is crucial for drawing timely human oversight in, e.g., freight transportation applications. In this work, we demonstrate that the true criticality of an agent's situation can be robustly defined as the mean reduction in reward given some number of random actions. Proxy criticality metrics that are computable in real-time (i.e., without actually simulating the effects of random actions) can be compared to the true criticality, and we show how to leverage these proxy metrics to generate safety margins, which directly tie the consequences of potentially incorrect actions to an anticipated loss in overall performance. We evaluate our approach on learned policies from APE-X and A3C within an Atari environment, and demonstrate how safety margins decrease as agents approach failure states. The integration of safety margins into programs for monitoring deployed agents allows for the real-time identification of potentially catastrophic situations.
</details>
<details>
<summary>摘要</summary>
任何自主控制器都会在某些情况下不安全。可以量化地确定这些不安全情况的发生是关键，以便在例如货物运输应用中引入有效的人工监督。在这种工作中，我们示出了一种可靠地定义自动控制器的真正极点的方法，即通过一些随机动作的平均减少奖励来定义。我们还介绍了一种可实时计算的代理极点指标，可以与真实极点相比较，并且可以利用这些代理指标生成安全优势，直接将可能错误的行为与预计的损失性相关联。我们在APE-X和A3C学习政策中的Atari环境中评估了我们的方法，并证明了安全优势在失败状态附近减少。将安全优势集成到监控部署的程序中，可以实时识别可能catastrophic的情况。
</details></li>
</ul>
<hr>
<h2 id="DBGSA-A-Novel-Data-Adaptive-Bregman-Clustering-Algorithm"><a href="#DBGSA-A-Novel-Data-Adaptive-Bregman-Clustering-Algorithm" class="headerlink" title="DBGSA: A Novel Data Adaptive Bregman Clustering Algorithm"></a>DBGSA: A Novel Data Adaptive Bregman Clustering Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14375">http://arxiv.org/abs/2307.14375</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ying Xiao, Hou-biao Li, Yu-pu Zhang<br>for: 提高非对稳定数据集中的各种减redundancy算法的精度methods: 使用数据驱动的Bregman异常参数优化减redundancy算法（DBGSA），结合Universal Gravitational Algorithm（UGA）将相似点靠拢近于数据集中。构建了重力系数方程，逐渐减少影响因子，并引入Bregman异常分子总能平均信息损失最小化来识别群中心。results: 对四个模拟数据集和六个实际数据集进行了广泛的实验，结果显示DBGSA比其他类似方法和改进的数据集平均提高精度达63.8%。此外，建立了三维网格搜索来比较不同参数值的影响，发现我们的模型提供的参数集是优化的。这些发现证明了DBGSA的高精度和稳定性。<details>
<summary>Abstract</summary>
With the development of Big data technology, data analysis has become increasingly important. Traditional clustering algorithms such as K-means are highly sensitive to the initial centroid selection and perform poorly on non-convex datasets. In this paper, we address these problems by proposing a data-driven Bregman divergence parameter optimization clustering algorithm (DBGSA), which combines the Universal Gravitational Algorithm to bring similar points closer in the dataset. We construct a gravitational coefficient equation with a special property that gradually reduces the influence factor as the iteration progresses. Furthermore, we introduce the Bregman divergence generalized power mean information loss minimization to identify cluster centers and build a hyperparameter identification optimization model, which effectively solves the problems of manual adjustment and uncertainty in the improved dataset. Extensive experiments are conducted on four simulated datasets and six real datasets. The results demonstrate that DBGSA significantly improves the accuracy of various clustering algorithms by an average of 63.8\% compared to other similar approaches like enhanced clustering algorithms and improved datasets. Additionally, a three-dimensional grid search was established to compare the effects of different parameter values within threshold conditions, and it was discovered the parameter set provided by our model is optimal. This finding provides strong evidence of the high accuracy and robustness of the algorithm.
</details>
<details>
<summary>摘要</summary>
随着大数据技术的发展，数据分析已成为非常重要。传统的聚类算法如K-means受初始中心选择的影响很大，在非对称数据集上表现不佳。在这篇论文中，我们解决这些问题，提出一种基于数据驱动的布格曼异分距度优化聚类算法（DBGSA）。我们将Universal Gravitational Algorithm用于将相似点在数据集中帮助更近。我们构建了重力系数方程，其特点是逐步减少影响因子。此外，我们引入布格曼异分广泛含义力平均信息损失来识别聚类中心，并建立一个距离阈值范围内的超参数标准化模型，以有效解决手动调整和不确定性问题。我们在四个 simulate数据集和六个实际数据集上进行了广泛的实验。结果表明，DBGSA可以在不同的聚类算法上提高准确率的平均提升率为63.8%，比其他类似方法如增强聚类算法和改进的数据集更高。此外，我们建立了一个三维网格搜索，以比较不同参数值在阈值条件下的效果，发现我们的模型提供的参数集是最佳的。这一发现证明了我们的算法的高精度和可靠性。
</details></li>
</ul>
<hr>
<h2 id="Turning-hazardous-volatile-matter-compounds-into-fuel-by-catalytic-steam-reforming-An-evolutionary-machine-learning-approach"><a href="#Turning-hazardous-volatile-matter-compounds-into-fuel-by-catalytic-steam-reforming-An-evolutionary-machine-learning-approach" class="headerlink" title="Turning hazardous volatile matter compounds into fuel by catalytic steam reforming: An evolutionary machine learning approach"></a>Turning hazardous volatile matter compounds into fuel by catalytic steam reforming: An evolutionary machine learning approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05750">http://arxiv.org/abs/2308.05750</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alireza Shafizadeh, Hossein Shahbeik, Mohammad Hossein Nadian, Vijai Kumar Gupta, Abdul-Sattar Nizami, Su Shiung Lam, Wanxi Peng, Junting Pan, Meisam Tabatabaei, Mortaza Aghbashlo<br>for: 这个研究旨在开发一个基于机器学习的研究框架，用于模拟、理解和优化 catalytic steam reforming 过程中的材料和反应条件。methods: 这个研究使用了 X-ray diffraction 分析和文献库来获取输入特征，并使用了六种机器学习模型和粒子群搜索算法来优化反应条件。results: 研究发现， ensemble machine learning 模型可以提供最高的预测性能（R2 &gt; 0.976），并且在737.44-725.62 ℃ 的温度范围内，可以实现高达77.2% 的 tar 转化率和产物分布。<details>
<summary>Abstract</summary>
Chemical and biomass processing systems release volatile matter compounds into the environment daily. Catalytic reforming can convert these compounds into valuable fuels, but developing stable and efficient catalysts is challenging. Machine learning can handle complex relationships in big data and optimize reaction conditions, making it an effective solution for addressing the mentioned issues. This study is the first to develop a machine-learning-based research framework for modeling, understanding, and optimizing the catalytic steam reforming of volatile matter compounds. Toluene catalytic steam reforming is used as a case study to show how chemical/textural analyses (e.g., X-ray diffraction analysis) can be used to obtain input features for machine learning models. Literature is used to compile a database covering a variety of catalyst characteristics and reaction conditions. The process is thoroughly analyzed, mechanistically discussed, modeled by six machine learning models, and optimized using the particle swarm optimization algorithm. Ensemble machine learning provides the best prediction performance (R2 > 0.976) for toluene conversion and product distribution. The optimal tar conversion (higher than 77.2%) is obtained at temperatures between 637.44 and 725.62 {\deg}C, with a steam-to-carbon molar ratio of 5.81-7.15 and a catalyst BET surface area 476.03-638.55 m2/g. The feature importance analysis satisfactorily reveals the effects of input descriptors on model prediction. Operating conditions (50.9%) and catalyst properties (49.1%) are equally important in modeling. The developed framework can expedite the search for optimal catalyst characteristics and reaction conditions, not only for catalytic chemical processing but also for related research areas.
</details>
<details>
<summary>摘要</summary>
化学和生物质处理系统每天都会释放有害物质into the environment。 catalytic reforming可以将这些物质转化为有价值的燃料，但是开发稳定和高效的催化剂是挑战。机器学习可以处理复杂的关系在大数据中，并且可以优化反应条件，因此它是解决这些问题的有效解决方案。本研究是首次开发了基于机器学习的研究框架，用于模型、理解和优化催化气相 reforming的有害物质。toluenecatalytic steam reforming作为一个例子，通过X射线晶体分析等方法获取输入特征，并使用文献库评估催化剂特性和反应条件。机器学习模型由六种模型组成，并使用粒子群优化算法进行优化。 ensemble machine learning提供了最佳预测性能（R2> 0.976） для toluene转化和产物分布。最佳的 tar转化（高于 77.2%）在637.44-725.62 ℃的温度范围内，与气-碳分子比为5.81-7.15和催化剂BET表面积为476.03-638.55 m2/g。特征重要性分析得到了输入描述对模型预测的影响。操作条件（50.9%）和催化剂特性（49.1%）在模型中具有相等的重要性。开发的框架可以加速寻找优化催化剂特性和反应条件，不仅限于催化化学处理，还可以扩展到相关的研究领域。
</details></li>
</ul>
<hr>
<h2 id="Scaling-machine-learning-based-chemical-plant-simulation-A-method-for-fine-tuning-a-model-to-induce-stable-fixed-points"><a href="#Scaling-machine-learning-based-chemical-plant-simulation-A-method-for-fine-tuning-a-model-to-induce-stable-fixed-points" class="headerlink" title="Scaling machine learning-based chemical plant simulation: A method for fine-tuning a model to induce stable fixed points"></a>Scaling machine learning-based chemical plant simulation: A method for fine-tuning a model to induce stable fixed points</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13621">http://arxiv.org/abs/2307.13621</a></li>
<li>repo_url: None</li>
<li>paper_authors: Malte Esders, Gimmy Alex Fernandez Ramirez, Michael Gastegger, Satya Swarup Samal</li>
<li>for: 这个论文是为了使用机器学习模型直接适应化化学厂数据而写的。</li>
<li>methods: 这篇论文使用了一种结构化方法，每个厂区都被一个机器学习模型代表。模型们被连接成一个流程图像，并且在数据上适应模型。</li>
<li>results: 对小型化学厂来说，这种方法工作良好，但对大型化学厂来说，由于大量和嵌入循环的循环导致循环解决器不稳定。作者分析了这个问题，并提出了一种方法来精细调整机器学习模型，使得解决循环变得稳定。<details>
<summary>Abstract</summary>
Idealized first-principles models of chemical plants can be inaccurate. An alternative is to fit a Machine Learning (ML) model directly to plant sensor data. We use a structured approach: Each unit within the plant gets represented by one ML model. After fitting the models to the data, the models are connected into a flowsheet-like directed graph. We find that for smaller plants, this approach works well, but for larger plants, the complex dynamics arising from large and nested cycles in the flowsheet lead to instabilities in the cycle solver. We analyze this problem in depth and show that it is not merely a specialized concern but rather a more pervasive challenge that will likely occur whenever ML is applied to larger plants. To address this problem, we present a way to fine-tune ML models such that solving cycles with the usual methods becomes robust again.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)理想化的初始原理模型可能不准确。一种alternative是直接将机器学习（ML）模型适应到厂区传感器数据。我们采用一种结构化方法：每个厂区内的单元都被表示为一个ML模型。在给数据适应模型后，模型被连接成一个流程图像的导向图。我们发现，对于小型厂区，这种方法效果很好，但对于更大的厂区，由于大量和嵌套的循环在流程图中，导致循环解决器中的不稳定。我们对这个问题进行了深入分析，并证明这不仅是特殊情况，而是更普遍的挑战，当机器学习应用于更大的厂区时，这种问题将会出现。为解决这个问题，我们提出了一种精细调整ML模型的方法，使得通过常规方法解决循环变得稳定。
</details></li>
</ul>
<hr>
<h2 id="AI-and-ethics-in-insurance-a-new-solution-to-mitigate-proxy-discrimination-in-risk-modeling"><a href="#AI-and-ethics-in-insurance-a-new-solution-to-mitigate-proxy-discrimination-in-risk-modeling" class="headerlink" title="AI and ethics in insurance: a new solution to mitigate proxy discrimination in risk modeling"></a>AI and ethics in insurance: a new solution to mitigate proxy discrimination in risk modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13616">http://arxiv.org/abs/2307.13616</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marguerite Sauce, Antoine Chancel, Antoine Ly</li>
<li>For: The paper aims to address the issue of indirect discrimination in insurance pricing and risk selection practices, using a mathematical approach based on linear algebra to reduce the risks of discrimination.* Methods: The paper proposes an innovative method that has not been previously discussed in the literature, which uses mathematical concepts of linear algebra to reduce the risks of indirect discrimination in insurance.* Results: The paper demonstrates the effectiveness of the proposed method in a concrete case of risk selection in life insurance, showing its simplicity of use and promising performance.Here is the same information in Simplified Chinese text:* For: 本研究旨在Addressing indirect discrimination in insurance pricing and risk selection practices, using mathematical approach based on linear algebra to reduce the risks of discrimination.* Methods: 本研究提出了一种innovative method, which uses mathematical concepts of linear algebra to reduce the risks of indirect discrimination in insurance.* Results: 研究demonstrates the effectiveness of the proposed method in a concrete case of risk selection in life insurance, showing its simplicity of use and promising performance.<details>
<summary>Abstract</summary>
The development of Machine Learning is experiencing growing interest from the general public, and in recent years there have been numerous press articles questioning its objectivity: racism, sexism, \dots Driven by the growing attention of regulators on the ethical use of data in insurance, the actuarial community must rethink pricing and risk selection practices for fairer insurance. Equity is a philosophy concept that has many different definitions in every jurisdiction that influence each other without currently reaching consensus. In Europe, the Charter of Fundamental Rights defines guidelines on discrimination, and the use of sensitive personal data in algorithms is regulated. If the simple removal of the protected variables prevents any so-called `direct' discrimination, models are still able to `indirectly' discriminate between individuals thanks to latent interactions between variables, which bring better performance (and therefore a better quantification of risk, segmentation of prices, and so on). After introducing the key concepts related to discrimination, we illustrate the complexity of quantifying them. We then propose an innovative method, not yet met in the literature, to reduce the risks of indirect discrimination thanks to mathematical concepts of linear algebra. This technique is illustrated in a concrete case of risk selection in life insurance, demonstrating its simplicity of use and its promising performance.
</details>
<details>
<summary>摘要</summary>
机器学习的发展正在受到一般大众的越来越高度关注，最近几年媒体也有许多报导质疑其公正性： racism、性别歧视、等等。由于资料使用的 regulators 在保险业中日益增加注意力，保险业界必须重新思考定价和风险选择实践，以确保更公正的保险。“Equity”是一个哲学概念，在每个司法管辖区都有不同的定义，这些定义彼此影响而无现在达成共识。在欧洲，《欧洲基本权利宣言》提供了歧视指南，而使用敏感个人资料在算法中的使用则是规管的。即使简单地删除保护变数，模型仍然能够间接歧视个人，因为变数之间的隐藏互动可以提高模型的性能（并因此提高风险的量化、价格分 segmentation 等）。我们首先介绍了歧视的主要概念，然后详细介绍了量化歧视的复杂性。接着，我们提出了一种新的方法，尚未在文献中出现过，以减少间接歧视的风险，这种方法基于数学概念的线性代数。这种技术在生命保险中的风险选择中被证明了其简单使用和推荐性的表现。
</details></li>
</ul>
<hr>
<h2 id="Team-Intro-to-AI-team8-at-CoachAI-Badminton-Challenge-2023-Advanced-ShuttleNet-for-Shot-Predictions"><a href="#Team-Intro-to-AI-team8-at-CoachAI-Badminton-Challenge-2023-Advanced-ShuttleNet-for-Shot-Predictions" class="headerlink" title="Team Intro to AI team8 at CoachAI Badminton Challenge 2023: Advanced ShuttleNet for Shot Predictions"></a>Team Intro to AI team8 at CoachAI Badminton Challenge 2023: Advanced ShuttleNet for Shot Predictions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13715">http://arxiv.org/abs/2307.13715</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shih-Hong Chen, Pin-Hsuan Chou, Yong-Fu Liu, Chien-An Han</li>
<li>for: 提高现有框架ShuttleNet在预测羽毛球球类型和位置的性能，通过利用过去的拍打。</li>
<li>methods: 使用过去拍打来改进ShuttleNet框架的预测性能。</li>
<li>results: 在IJCAI 2023 CoachAI Badminton Challenge中获得了较好的成绩，比基线要好得多，最终获得了比赛的第一名，并公布了代码。<details>
<summary>Abstract</summary>
In this paper, our objective is to improve the performance of the existing framework ShuttleNet in predicting badminton shot types and locations by leveraging past strokes. We participated in the CoachAI Badminton Challenge at IJCAI 2023 and achieved significantly better results compared to the baseline. Ultimately, our team achieved the first position in the competition and we made our code available.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们的目标是通过利用过去的击球来提高现有框架ShuttleNet在预测羽毛球shot类型和位置的性能。我们参加了IJCAI 2023年CoachAI羽毛球比赛，与基准线比较，得到了显著更好的结果。最终，我们的团队获得了比赛的第一名，并且我们的代码公开了。
</details></li>
</ul>
<hr>
<h2 id="Forecasting-capturing-and-activation-of-carbon-dioxide-CO-2-Integration-of-Time-Series-Analysis-Machine-Learning-and-Material-Design"><a href="#Forecasting-capturing-and-activation-of-carbon-dioxide-CO-2-Integration-of-Time-Series-Analysis-Machine-Learning-and-Material-Design" class="headerlink" title="Forecasting, capturing and activation of carbon-dioxide (CO$_2$): Integration of Time Series Analysis, Machine Learning, and Material Design"></a>Forecasting, capturing and activation of carbon-dioxide (CO$_2$): Integration of Time Series Analysis, Machine Learning, and Material Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14374">http://arxiv.org/abs/2307.14374</a></li>
<li>repo_url: None</li>
<li>paper_authors: Suchetana Sadhukhan, Vivek Kumar Yadav</li>
<li>for: 这项研究旨在进行欧盟27国+英国、意大利、德国和西班牙等国家以及印度日常产业碳排放时序分析，从2019年1月至2023年2月的15个月时间段内获取数据。</li>
<li>methods: 该研究使用了卡本监测研究计划提供的近实时活动数据，并对2020年的数据进行排除，以避免 COVID-19 大流行对数据的干扰。然后，研究人员使用主成分分析（PCA）确定排放的主要贡献者。为了提高预测质量，研究人员使用了7天移动平均数据进行进一步分析。</li>
<li>results: 研究发现，电力、工业和公路交通三个领域占据了总变量的显著部分。使用长期短期记忆（LSTM）模型对7天移动平均数据进行预测，可以有效地预测排放和提供政策决策、缓减策略和气候变化努力的指导。模型在训练阶段保证稳定性和协调性，并在测试阶段表现出高效率，$R^2$ 值分别为0.8242-0.995。此外，研究人员还提出了使用锆和氮气&#x2F;铝合金薄膜作为捕捉CO2的非常有效材料，这些材料在此方面超过了 grafene 和氮氧化物薄膜的绑定能量范围。<details>
<summary>Abstract</summary>
This study provides a comprehensive time series analysis of daily industry-specific, country-wise CO$_2$ emissions from January 2019 to February 2023. The research focuses on the Power, Industry, Ground Transport, Domestic Aviation, and International Aviation sectors in European countries (EU27 & UK, Italy, Germany, Spain) and India, utilizing near-real-time activity data from the Carbon Monitor research initiative. To identify regular emission patterns, the data from the year 2020 is excluded due to the disruptive effects caused by the COVID-19 pandemic. The study then performs a principal component analysis (PCA) to determine the key contributors to CO$_2$ emissions. The analysis reveals that the Power, Industry, and Ground Transport sectors account for a significant portion of the variance in the dataset. A 7-day moving averaged dataset is employed for further analysis to facilitate robust predictions. This dataset captures both short-term and long-term trends and enhances the quality of the data for prediction purposes. The study utilizes Long Short-Term Memory (LSTM) models on the 7-day moving averaged dataset to effectively predict emissions and provide insights for policy decisions, mitigation strategies, and climate change efforts. During the training phase, the stability and convergence of the LSTM models are ensured, which guarantees their reliability in the testing phase. The evaluation of the loss function indicates this reliability. The model achieves high efficiency, as demonstrated by $R^2$ values ranging from 0.8242 to 0.995 for various countries and sectors. Furthermore, there is a proposal for utilizing scandium and boron/aluminium-based thin films as exceptionally efficient materials for capturing CO$_2$ (with a binding energy range from -3.0 to -3.5 eV). These materials are shown to surpass the affinity of graphene and boron nitride sheets in this regard.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/26/cs.LG_2023_07_26/" data-id="clpxp041500p8fm88e7069bce" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_07_26" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/26/eess.IV_2023_07_26/" class="article-date">
  <time datetime="2023-07-26T09:00:00.000Z" itemprop="datePublished">2023-07-26</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/26/eess.IV_2023_07_26/">eess.IV - 2023-07-26</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Artifact-Restoration-in-Histology-Images-with-Diffusion-Probabilistic-Models"><a href="#Artifact-Restoration-in-Histology-Images-with-Diffusion-Probabilistic-Models" class="headerlink" title="Artifact Restoration in Histology Images with Diffusion Probabilistic Models"></a>Artifact Restoration in Histology Images with Diffusion Probabilistic Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14262">http://arxiv.org/abs/2307.14262</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhenqi-he/artifusion">https://github.com/zhenqi-he/artifusion</a></li>
<li>paper_authors: Zhenqi He, Junjun He, Jin Ye, Yiqing Shen</li>
<li>for:  histological whole slide images (WSIs) restoration, to improve the examination difficulty for pathologists and Computer-Aided Diagnosis (CAD) systems.</li>
<li>methods:  innovative denoising diffusion probabilistic model called ArtiFusion, which formulates the artifact region restoration as a gradual denoising process and uses a novel Swin-Transformer denoising architecture and time token scheme to capture local-global correlations.</li>
<li>results:  effective restoration of artifact-corrupted histological WSIs, preserving tissue structures and stain style in artifact-free regions, demonstrated through extensive evaluations.<details>
<summary>Abstract</summary>
Histological whole slide images (WSIs) can be usually compromised by artifacts, such as tissue folding and bubbles, which will increase the examination difficulty for both pathologists and Computer-Aided Diagnosis (CAD) systems. Existing approaches to restoring artifact images are confined to Generative Adversarial Networks (GANs), where the restoration process is formulated as an image-to-image transfer. Those methods are prone to suffer from mode collapse and unexpected mistransfer in the stain style, leading to unsatisfied and unrealistic restored images. Innovatively, we make the first attempt at a denoising diffusion probabilistic model for histological artifact restoration, namely ArtiFusion.Specifically, ArtiFusion formulates the artifact region restoration as a gradual denoising process, and its training relies solely on artifact-free images to simplify the training complexity.Furthermore, to capture local-global correlations in the regional artifact restoration, a novel Swin-Transformer denoising architecture is designed, along with a time token scheme. Our extensive evaluations demonstrate the effectiveness of ArtiFusion as a pre-processing method for histology analysis, which can successfully preserve the tissue structures and stain style in artifact-free regions during the restoration. Code is available at https://github.com/zhenqi-he/ArtiFusion.
</details>
<details>
<summary>摘要</summary>
histological whole slide images (WSIs) 可以受到artefacts的影响，如组织卷积和气泡，这会提高Pathologist和计算机支持诊断系统（CAD）的评估难度。现有的恢复artefact图像方法包括生成对抗网络（GANs），其中恢复过程 формули为图像-图像传输。这些方法容易受到模式落入和意外传输的困难，导致 restored图像不满意和不真实。在创新的思路下，我们提出了一种denoising扩散概率模型，即ArtiFusion，用于 histological artefact 恢复。具体来说，ArtiFusion将artefact区域恢复视为一种渐进的denoising过程，其训练仅仅基于无artefact的图像，以简化训练复杂性。此外，为了捕捉local-global相关性在区域artefact恢复中，我们设计了一种Swin-Transformer恢复架构，以及一种时间标识符方案。我们的广泛评估表明ArtiFusion作为 histology 分析前置处理方法，能够成功保留组织结构和染色样式在无artefact区域中，并且不会导致图像损害。代码可以在https://github.com/zhenqi-he/ArtiFusion 上获取。
</details></li>
</ul>
<hr>
<h2 id="Visual-Saliency-Detection-in-Advanced-Driver-Assistance-Systems"><a href="#Visual-Saliency-Detection-in-Advanced-Driver-Assistance-Systems" class="headerlink" title="Visual Saliency Detection in Advanced Driver Assistance Systems"></a>Visual Saliency Detection in Advanced Driver Assistance Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03770">http://arxiv.org/abs/2308.03770</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francesco Rundo, Michael Sebastian Rundo, Concetto Spampinato</li>
<li>for: 本研究旨在开发一种智能驾驶系统，其能够检测司机的睡眠状况并根据场景的重要性进行分类。</li>
<li>methods: 该系统使用了特殊的3D深度学习网络进行semantic segmentation，并在驾驶器上使用STA1295核心和硬件加速器进行实时处理。此外，还使用了车辆轮胎上的生物传感器来监测司机的睡眠状况，并使用1D时间深度卷积网络来分类司机的PPG信号。</li>
<li>results: 实验结果表明，该系统能够有效地检测司机的睡眠状况和场景重要性，并且可以准确地评估司机的注意力水平。<details>
<summary>Abstract</summary>
Visual Saliency refers to the innate human mechanism of focusing on and extracting important features from the observed environment. Recently, there has been a notable surge of interest in the field of automotive research regarding the estimation of visual saliency. While operating a vehicle, drivers naturally direct their attention towards specific objects, employing brain-driven saliency mechanisms that prioritize certain elements over others. In this investigation, we present an intelligent system that combines a drowsiness detection system for drivers with a scene comprehension pipeline based on saliency. To achieve this, we have implemented a specialized 3D deep network for semantic segmentation, which has been pretrained and tailored for processing the frames captured by an automotive-grade external camera. The proposed pipeline was hosted on an embedded platform utilizing the STA1295 core, featuring ARM A7 dual-cores, and embeds an hardware accelerator. Additionally, we employ an innovative biosensor embedded on the car steering wheel to monitor the driver drowsiness, gathering the PhotoPlethysmoGraphy (PPG) signal of the driver. A dedicated 1D temporal deep convolutional network has been devised to classify the collected PPG time-series, enabling us to assess the driver level of attentiveness. Ultimately, we compare the determined attention level of the driver with the corresponding saliency-based scene classification to evaluate the overall safety level. The efficacy of the proposed pipeline has been validated through extensive experimental results.
</details>
<details>
<summary>摘要</summary>
视觉吸引力（Visual Saliency）是人类自然的注意力机制，它使人们在观察环境中强调和提取重要的特征。在汽车研究领域，计算视觉吸引力的技术受到了最近的关注。驾驶时， drivers 会自然地将注意力集中在特定的对象上，使用大脑驱动的注意力机制，它会优先级化某些元素。在本研究中，我们提出了一种智能系统，其combines 驾驶者睡眠检测系统和基于视觉吸引力的场景理解管道。为实现这一目标，我们实现了一种专门的3D深度网络 дляsemantic segmentation，该网络在 automotive-grade 外部摄像头捕捉的帧中进行了预训练和定制。我们的提案的管道在 ARM A7 双核心的 Embedded 平台上运行，并使用了硬件加速器。此外，我们还使用了一种创新的车辙把握 sensor，以监测驾驶者的睡眠状况，并收集了PhotoPlethysmoGraphy（PPG）信号。一个专门的1D时间深度卷积网络被设计用于分类收集的 PPG 时间序列，以评估驾驶者的注意力水平。最后，我们将驾驶者的注意力水平与相应的视觉吸引力基于场景分类进行比较，以评估整体安全水平。我们的实验结果表明，提案的管道具有良好的效果。
</details></li>
</ul>
<hr>
<h2 id="Non-Linear-Self-Augmentation-Deep-Pipeline-for-Cancer-Treatment-outcome-Prediction"><a href="#Non-Linear-Self-Augmentation-Deep-Pipeline-for-Cancer-Treatment-outcome-Prediction" class="headerlink" title="Non-Linear Self Augmentation Deep Pipeline for Cancer Treatment outcome Prediction"></a>Non-Linear Self Augmentation Deep Pipeline for Cancer Treatment outcome Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14398">http://arxiv.org/abs/2307.14398</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francesco Rundo, Concetto Spampinato, Michael Rundo</li>
<li>for: 这篇论文旨在探讨如何通过免疫疗法治疗肿瘤，以提高患者的存活率和减少化学疗法对身体的负面影响。</li>
<li>methods: 该论文提出了一种新的策略，即利用非线性细胞建筑和深度下游分类器，从肿瘤CT影像中提取和增强2D特征，以提高治疗结果预测的精度。</li>
<li>results: 作者们在实验中表明，该策略可以达到约93%的总准确率，表明其效果概括比较出色。<details>
<summary>Abstract</summary>
Immunotherapy emerges as promising approach for treating cancer. Encouraging findings have validated the efficacy of immunotherapy medications in addressing tumors, resulting in prolonged survival rates and notable reductions in toxicity compared to conventional chemotherapy methods. However, the pool of eligible patients for immunotherapy remains relatively small, indicating a lack of comprehensive understanding regarding the physiological mechanisms responsible for favorable treatment response in certain individuals while others experience limited benefits. To tackle this issue, the authors present an innovative strategy that harnesses a non-linear cellular architecture in conjunction with a deep downstream classifier. This approach aims to carefully select and enhance 2D features extracted from chest-abdomen CT images, thereby improving the prediction of treatment outcomes. The proposed pipeline has been meticulously designed to seamlessly integrate with an advanced embedded Point of Care system. In this context, the authors present a compelling case study focused on Metastatic Urothelial Carcinoma (mUC), a particularly aggressive form of cancer. Performance evaluation of the proposed approach underscores its effectiveness, with an impressive overall accuracy of approximately 93%
</details>
<details>
<summary>摘要</summary>
免疫疗法在治疗癌症方面emerges as a promising approach. 有鼓舞的结果验证了免疫疗药的有效性，对抗肿瘤，导致生存时间增长和化学治疗方法相比，对于患有癌症的患者而言，有着更好的体验和较少的副作用。然而，有效治疗的病人群较小，这表明我们对于特定个体征所需的体化机制仍然缺乏了一致性的理解。为了解决这个问题，作者们提出了一个创新的策略，利用非线性细胞架构，联合深入的下游分类器。这种方法的目的是精确地选择和增强来自胸腹部Computed Tomography（CT）图像的2D特征，以提高治疗结果预测的精度。提案的管线被精心设计，与进步的嵌入式点数检查系统完美融合。在这个上下文中，作者们透过了一个吸引人的案例研究，专注于肉瘤癌（mUC），这是一种特别的攻击性癌症。研究表现了提案的有效性，其总准确率约为93%。
</details></li>
</ul>
<hr>
<h2 id="Tackling-Scattering-and-Reflective-Flare-in-Mobile-Camera-Systems-A-Raw-Image-Dataset-for-Enhanced-Flare-Removal"><a href="#Tackling-Scattering-and-Reflective-Flare-in-Mobile-Camera-Systems-A-Raw-Image-Dataset-for-Enhanced-Flare-Removal" class="headerlink" title="Tackling Scattering and Reflective Flare in Mobile Camera Systems: A Raw Image Dataset for Enhanced Flare Removal"></a>Tackling Scattering and Reflective Flare in Mobile Camera Systems: A Raw Image Dataset for Enhanced Flare Removal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14180">http://arxiv.org/abs/2307.14180</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fengbo Lan, Chang Wen Chen</li>
<li>for: 提高手持式摄像头系统的图像质量，特别是解决散射和反射炬的问题。</li>
<li>methods: 使用Raw图像 Dataset，该Dataset包括多种不同的手持式摄像头和摄像头设置，并且可以分解成多个patches，以适应不同的捕捉环境。</li>
<li>results: 实验结果表明，使用真实图像Dataset可以更好地适应复杂的照明环境，而使用Synthesized数据会降低图像质量。 Raw图像数据也有显著优势在解决散射和反射炬问题。<details>
<summary>Abstract</summary>
The increasing prevalence of mobile devices has led to significant advancements in mobile camera systems and improved image quality. Nonetheless, mobile photography still grapples with challenging issues such as scattering and reflective flare. The absence of a comprehensive real image dataset tailored for mobile phones hinders the development of effective flare mitigation techniques. To address this issue, we present a novel raw image dataset specifically designed for mobile camera systems, focusing on flare removal. Capitalizing on the distinct properties of raw images, this dataset serves as a solid foundation for developing advanced flare removal algorithms. It encompasses a wide variety of real-world scenarios captured with diverse mobile devices and camera settings. The dataset comprises over 2,000 high-quality full-resolution raw image pairs for scattering flare and 1,100 for reflective flare, which can be further segmented into up to 30,000 and 2,200 paired patches, respectively, ensuring broad adaptability across various imaging conditions. Experimental results demonstrate that networks trained with synthesized data struggle to cope with complex lighting settings present in this real image dataset. We also show that processing data through a mobile phone's internal ISP compromises image quality while using raw image data presents significant advantages for addressing the flare removal problem. Our dataset is expected to enable an array of new research in flare removal and contribute to substantial improvements in mobile image quality, benefiting mobile photographers and end-users alike.
</details>
<details>
<summary>摘要</summary>
“由于移动设备的普及，移动摄像系统已经取得了重要进步，并且提高了图像质量。然而，移动摄影仍然面临着困难的问题，如散射和反射镜光。由于现有的移动设备实验数据集仍然不够完整，因此对于这些问题的发展有限制。为解决这个问题，我们提出了一个新的原始数据集，特别是设计用于移动摄像系统，专注于灯光减除。利用原始图像的特有性，这个数据集成为了发展高级灯光减除算法的坚实基础。它包括了各种真实世界的拍摄情况，运用多种移动设备和相机设定。数据集包含了2,000多个高品质的全分辨率原始图像，用于散射灯光和反射灯光，可以进一步被切割为30,000个和2,200个相应的对称 patch。这使得这个数据集在不同的摄影情况下具有广泛的适用性。我们的实验结果显示，使用现成数据集进行训练的网络对于实际摄影情况下表现不佳。此外，将图像处理通过移动设备的内部ISP也会导致图像质量下降，而使用原始图像数据集则具有明显的优势，用于解决灯光减除问题。我们预期这个数据集将启动新的研究，并对移动图像质量做出重要改善，帮助移动摄影师和最终用户。”
</details></li>
</ul>
<hr>
<h2 id="Memory-Efficient-Graph-Convolutional-Networks-for-Object-Classification-and-Detection-with-Event-Cameras"><a href="#Memory-Efficient-Graph-Convolutional-Networks-for-Object-Classification-and-Detection-with-Event-Cameras" class="headerlink" title="Memory-Efficient Graph Convolutional Networks for Object Classification and Detection with Event Cameras"></a>Memory-Efficient Graph Convolutional Networks for Object Classification and Detection with Event Cameras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14124">http://arxiv.org/abs/2307.14124</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kamil Jeziorek, Andrea Pinna, Tomasz Kryjak</li>
<li>for: This paper focuses on developing an efficient graph convolutional network (GCN) for processing event data in its original sparse form, with the goal of achieving high accuracy while minimizing computational and memory costs.</li>
<li>methods: The authors compare different graph convolution operations and evaluate their performance in terms of execution time, number of trainable model parameters, data format requirements, and training outcomes. They also implement an object detection architecture and evaluate its performance on the N-Caltech101 dataset.</li>
<li>results: The authors achieve a 450-fold reduction in the number of parameters for the feature extraction module and a 4.5-fold reduction in the size of the data representation while maintaining a classification accuracy of 52.3%, which is 6.3% higher compared to the operation used in state-of-the-art approaches. They also achieve an object detection accuracy of 53.7% <a href="mailto:&#109;&#65;&#80;&#x40;&#48;&#x2e;&#x35;">&#109;&#65;&#80;&#x40;&#48;&#x2e;&#x35;</a> and an execution rate of 82 graphs per second.Here’s the Chinese translation of the three key information points:</li>
<li>for: 这篇论文关注开发高效的图结构神经网络（GCN），用于处理事件数据的原始稀畴形式，以实现高精度while减少计算和内存成本。</li>
<li>methods: 作者比较了不同的图 convolution 操作，并评估其性能在执行时间、训练参数数量、数据格式要求和训练结果等方面。他们还实现了一个物体检测架构，并评估其性能在 N-Caltech101 数据集上。</li>
<li>results: 作者实现了一个 450 倍减少的特征提取模块参数数量，并将数据表示的大小减少到 4.5 倍，同时保持了 52.3% 的分类精度，相比之下和现有方法相比，提高了 6.3%。他们还实现了一个物体检测精度为 53.7% <a href="mailto:&#109;&#65;&#x50;&#64;&#48;&#x2e;&#x35;">&#109;&#65;&#x50;&#64;&#48;&#x2e;&#x35;</a> 和执行速度为 82 个图&#x2F;秒。<details>
<summary>Abstract</summary>
Recent advances in event camera research emphasize processing data in its original sparse form, which allows the use of its unique features such as high temporal resolution, high dynamic range, low latency, and resistance to image blur. One promising approach for analyzing event data is through graph convolutional networks (GCNs). However, current research in this domain primarily focuses on optimizing computational costs, neglecting the associated memory costs. In this paper, we consider both factors together in order to achieve satisfying results and relatively low model complexity. For this purpose, we performed a comparative analysis of different graph convolution operations, considering factors such as execution time, the number of trainable model parameters, data format requirements, and training outcomes. Our results show a 450-fold reduction in the number of parameters for the feature extraction module and a 4.5-fold reduction in the size of the data representation while maintaining a classification accuracy of 52.3%, which is 6.3% higher compared to the operation used in state-of-the-art approaches. To further evaluate performance, we implemented the object detection architecture and evaluated its performance on the N-Caltech101 dataset. The results showed an accuracy of 53.7 % mAP@0.5 and reached an execution rate of 82 graphs per second.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Periocular-biometrics-databases-algorithms-and-directions"><a href="#Periocular-biometrics-databases-algorithms-and-directions" class="headerlink" title="Periocular biometrics: databases, algorithms and directions"></a>Periocular biometrics: databases, algorithms and directions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14111">http://arxiv.org/abs/2307.14111</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fernando Alonso-Fernandez, Josef Bigun</li>
<li>for: 这篇论文主要是为了探讨 périocular 生物认证技术的现状和未来发展趋势。</li>
<li>methods: 论文使用了多种方法，包括Feature extraction from the periocular region, gender classification, ethnicity classification, and the impact of gender transformation or plastic surgery on recognition performance.</li>
<li>results: 论文提出了一些关键问题和未来发展趋势，包括使用 périocular 特征提高生物认证精度，以及gender transformation or plastic surgery的影响在认证性能中。<details>
<summary>Abstract</summary>
Periocular biometrics has been established as an independent modality due to concerns on the performance of iris or face systems in uncontrolled conditions. Periocular refers to the facial region in the eye vicinity, including eyelids, lashes and eyebrows. It is available over a wide range of acquisition distances, representing a trade-off between the whole face (which can be occluded at close distances) and the iris texture (which do not have enough resolution at long distances). Since the periocular region appears in face or iris images, it can be used also in conjunction with these modalities. Features extracted from the periocular region have been also used successfully for gender classification and ethnicity classification, and to study the impact of gender transformation or plastic surgery in the recognition performance. This paper presents a review of the state of the art in periocular biometric research, providing an insight of the most relevant issues and giving a thorough coverage of the existing literature. Future research trends are also briefly discussed.
</details>
<details>
<summary>摘要</summary>
périocular biometrics 已经成为一种独立的模式，由于人们对眼球或面部系统在无控制的环境中的性能有所担忧。 périocular 指的是眼睛附近的脸部区域，包括眼睛、毛发和眉毛。它可以在各种距离范围内获取，表示一种折衔 между整个脸部（可能被近距离 occluded）和眼球xture（没有足够的分辨率）。由于 périocular 区域会出现在face或iris图像中，因此它可以与这些模式一起使用。从 périocular 区域提取的特征已经成功地用于性别分类和民族分类，以及研究性别转换或整形手术对认知性能的影响。这篇论文提供了 periocular biometric 研究的现状报告，并给出了现有文献的全面概述。文章还 briefly discusses 未来的研究趋势。
</details></li>
</ul>
<hr>
<h2 id="Video-Decoding-Energy-Estimation-Using-Processor-Events"><a href="#Video-Decoding-Energy-Estimation-Using-Processor-Events" class="headerlink" title="Video Decoding Energy Estimation Using Processor Events"></a>Video Decoding Energy Estimation Using Processor Events</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14000">http://arxiv.org/abs/2307.14000</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christian Herglotz, André Kaup</li>
<li>for: 这个论文是用于研究软件视频解码器的处理能力的。</li>
<li>methods: 这个论文使用了处理器事件如 instrucion counts 或缓存misses来准确估计软件视频解码器的处理能力。</li>
<li>results: 这个论文的研究表明，使用该估计方法可以准确地估计最新的视频编码标准HEVC和VP9中的解码能力，mean estimation error小于6%。<details>
<summary>Abstract</summary>
In this paper, we show that processor events like instruction counts or cache misses can be used to accurately estimate the processing energy of software video decoders. Therefore, we perform energy measurements on an ARM-based evaluation platform and count processor level events using a dedicated profiling software. Measurements are performed for various codecs and decoder implementations to prove the general viability of our observations. Using the estimation method proposed in this paper, the true decoding energy for various recent video coding standards including HEVC and VP9 can be estimated with a mean estimation error that is smaller than 6%.
</details>
<details>
<summary>摘要</summary>
在本文中，我们证明处理器事件如 instrucion 数或缓存失败可以准确地估计软件视频解码器的处理能量。因此，我们使用专门的 profiling 软件来计数处理器级别事件，并在 ARM 基础设施上进行能量测量。测量结果表明，对于不同的编码器和解码器实现，我们可以使用我们所提出的估计方法来估计最新的视频编码标准HEVC和VP9的真正解码能量，其误差在6%以下。
</details></li>
</ul>
<hr>
<h2 id="Hybrid-Representation-Enhanced-Sampling-for-Bayesian-Active-Learning-in-Musculoskeletal-Segmentation-of-Lower-Extremities"><a href="#Hybrid-Representation-Enhanced-Sampling-for-Bayesian-Active-Learning-in-Musculoskeletal-Segmentation-of-Lower-Extremities" class="headerlink" title="Hybrid Representation-Enhanced Sampling for Bayesian Active Learning in Musculoskeletal Segmentation of Lower Extremities"></a>Hybrid Representation-Enhanced Sampling for Bayesian Active Learning in Musculoskeletal Segmentation of Lower Extremities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13986">http://arxiv.org/abs/2307.13986</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ganping Li, Yoshito Otake, Mazen Soufi, Masashi Taniguchi, Masahide Yagi, Noriaki Ichihashi, Keisuke Uemura, Masaki Takao, Nobuhiko Sugano, Yoshinobu Sato</li>
<li>for: 降低医学影像分割任务中手动标注的时间和成本</li>
<li>methods:  bayesian active learning框架基于 bayesian u-net，采用混合表示式增强采样策略，选择高密度和多样性的不确定样本进行人工修正</li>
<li>results: 对两个lower extremity（LE）数据集的MRI和CT图像进行实验，比较不同的采样规则和方法，结果表明提出的方法在两个数据集上具有超越或相等的优势，并且量化结果表明采用混合riteria的方法在musculoskeletal segmentation中表现出优势。<details>
<summary>Abstract</summary>
Purpose: Obtaining manual annotations to train deep learning (DL) models for auto-segmentation is often time-consuming. Uncertainty-based Bayesian active learning (BAL) is a widely-adopted method to reduce annotation efforts. Based on BAL, this study introduces a hybrid representation-enhanced sampling strategy that integrates density and diversity criteria to save manual annotation costs by efficiently selecting the most informative samples.   Methods: The experiments are performed on two lower extremity (LE) datasets of MRI and CT images by a BAL framework based on Bayesian U-net. Our method selects uncertain samples with high density and diversity for manual revision, optimizing for maximal similarity to unlabeled instances and minimal similarity to existing training data. We assess the accuracy and efficiency using Dice and a proposed metric called reduced annotation cost (RAC), respectively. We further evaluate the impact of various acquisition rules on BAL performance and design an ablation study for effectiveness estimation.   Results: The proposed method showed superiority or non-inferiority to other methods on both datasets across two acquisition rules, and quantitative results reveal the pros and cons of the acquisition rules. Our ablation study in volume-wise acquisition shows that the combination of density and diversity criteria outperforms solely using either of them in musculoskeletal segmentation.   Conclusion: Our sampling method is proven efficient in reducing annotation costs in image segmentation tasks. The combination of the proposed method and our BAL framework provides a semi-automatic way for efficient annotation of medical image datasets.
</details>
<details>
<summary>摘要</summary>
目的：获取手动标注以训练深度学习（DL）模型的自动分割时间consuming。uncertainty-based Bayesian活动学习（BAL）是一种广泛采用的方法，可以降低手动标注成本。本研究基于BAL，提出了一种混合表示符强化抽样策略，通过高密度和多样性标准来高效地选择最有用的样本进行手动修改。方法：我们在两个下肢（LE）数据集上进行了MRI和CT图像的实验，使用基于Bayesian U-net的BAL框架。我们的方法选择了uncertainty高和多样性高的样本进行手动修改，以便最大化与未标注实例的相似性，最小化与现有训练数据的相似性。我们使用Dice和我们所提出的metric called reduced annotation cost（RAC）进行评估精度和效率。我们进一步evaluate了不同的抽样规则对BAL性能的影响，并实现了效果的鉴定。结果：我们的方法在两个数据集上都与其他方法具有superiority或non-inferiority，并且在两个抽样规则下表现出优异。我们的ablation study表明，混合表示符强化抽样策略在musculoskeletal segmentation中表现出优异。结论：我们的抽样方法可以有效地减少图像分割任务中的手动标注成本。我们的BAL框架和混合表示符强化抽样策略的结合，提供了一种 semi-automatic的方法，可以快速和高效地注解医学图像数据集。
</details></li>
</ul>
<hr>
<h2 id="Analysis-of-Video-Quality-Datasets-via-Design-of-Minimalistic-Video-Quality-Models"><a href="#Analysis-of-Video-Quality-Datasets-via-Design-of-Minimalistic-Video-Quality-Models" class="headerlink" title="Analysis of Video Quality Datasets via Design of Minimalistic Video Quality Models"></a>Analysis of Video Quality Datasets via Design of Minimalistic Video Quality Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13981">http://arxiv.org/abs/2307.13981</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Sun, Wen Wen, Xiongkuo Min, Long Lan, Guangtao Zhai, Kede Ma</li>
<li>for: 这篇论文旨在探讨视频质量评估（BVQA）在实际应用中的监测和改进视频观看体验的角色。</li>
<li>methods: 作者采用了基于基本块的最简单的BVQA模型，包括视频预处理（对空间时间下采样进行压缩）、空间质量分析器和可选的时间质量分析器，以及质量回归器。</li>
<li>results: 作者通过对八个VQA数据集进行计算分析发现，大多数数据集具有不同程度的易 datasets问题，一些甚至可以使用盲目图像质量评估（BIQA）解决方案。作者还通过比较不同模型变体在这些数据集上的质量预测性能，以及对不同基本建构元素的影响进行ablation分析，证明了他们的结论。这些结果表明BVQA领域的进步不足，同时也提供了constructing next-generation VQA datasets和模型的好做法。<details>
<summary>Abstract</summary>
Blind video quality assessment (BVQA) plays an indispensable role in monitoring and improving the end-users' viewing experience in various real-world video-enabled media applications. As an experimental field, the improvements of BVQA models have been measured primarily on a few human-rated VQA datasets. Thus, it is crucial to gain a better understanding of existing VQA datasets in order to properly evaluate the current progress in BVQA. Towards this goal, we conduct a first-of-its-kind computational analysis of VQA datasets via designing minimalistic BVQA models. By minimalistic, we restrict our family of BVQA models to build only upon basic blocks: a video preprocessor (for aggressive spatiotemporal downsampling), a spatial quality analyzer, an optional temporal quality analyzer, and a quality regressor, all with the simplest possible instantiations. By comparing the quality prediction performance of different model variants on eight VQA datasets with realistic distortions, we find that nearly all datasets suffer from the easy dataset problem of varying severity, some of which even admit blind image quality assessment (BIQA) solutions. We additionally justify our claims by contrasting our model generalizability on these VQA datasets, and by ablating a dizzying set of BVQA design choices related to the basic building blocks. Our results cast doubt on the current progress in BVQA, and meanwhile shed light on good practices of constructing next-generation VQA datasets and models.
</details>
<details>
<summary>摘要</summary>
《盲视视频质量评估（BVQA）在各种实际视频媒体应用中扮演着不可或缺的角色，负责监测和改进用户的观看体验。作为实验室的一个领域，BVQA模型的改进都是根据一些人类评估的VQA数据进行评估的。因此，我们需要更好地了解现有的VQA数据集，以便正确评估当前的进步。为达到这个目标，我们通过设计简单的BVQA模型进行计算分析。我们的家族中的BVQA模型只能使用基本块：视频预处理器（对于激进的空间时间采样）、空间质量分析器、可选的时间质量分析器以及质量回归器，其中所有的实现都是最简单的。通过对不同模型变体在八个VQA数据集上的质量预测性能进行比较，我们发现大多数数据集具有不同程度的易于评估（Easy Dataset Problem），一些甚至接受盲图质量评估（BIQA）解决方案。我们还通过对这些VQA数据集的模型普适性进行比较，以及对BVQA设计选择的繁殖评估来证明我们的结论。我们的结果表明当前BVQA领域的进步不充分，同时也照明了constructing next-generation VQA datasets和models的好做法。》
</details></li>
</ul>
<hr>
<h2 id="A-real-time-material-breakage-detection-for-offshore-wind-turbines-based-on-improved-neural-network-algorithm"><a href="#A-real-time-material-breakage-detection-for-offshore-wind-turbines-based-on-improved-neural-network-algorithm" class="headerlink" title="A real-time material breakage detection for offshore wind turbines based on improved neural network algorithm"></a>A real-time material breakage detection for offshore wind turbines based on improved neural network algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13765">http://arxiv.org/abs/2307.13765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yantong Liu</li>
<li>for: 这种研究是为了提高陆上风电机的稳定性，以便更好地实现可持续能源生产。</li>
<li>methods: 这种方法使用了一种改进版的YOLOv8对象检测模型，并添加了一个卷积块注意模块（CBAM）来提高特征识别。研究使用了5,432张风电园的图像和一个公共可用的数据集进行了严格的测试。</li>
<li>results: 研究发现了一个显著提高的缺陷检测稳定性，这标志着可持续能源实践中的一个重要进步。<details>
<summary>Abstract</summary>
The integrity of offshore wind turbines, pivotal for sustainable energy generation, is often compromised by surface material defects. Despite the availability of various detection techniques, limitations persist regarding cost-effectiveness, efficiency, and applicability. Addressing these shortcomings, this study introduces a novel approach leveraging an advanced version of the YOLOv8 object detection model, supplemented with a Convolutional Block Attention Module (CBAM) for improved feature recognition. The optimized loss function further refines the learning process. Employing a dataset of 5,432 images from the Saemangeum offshore wind farm and a publicly available dataset, our method underwent rigorous testing. The findings reveal a substantial enhancement in defect detection stability, marking a significant stride towards efficient turbine maintenance. This study's contributions illuminate the path for future research, potentially revolutionizing sustainable energy practices.
</details>
<details>
<summary>摘要</summary>
风力机 Platform 上的缺陷问题，对可持续能源生产是关键。尽管有各种检测技术，但有限制，包括成本、效率和应用范围。本研究提出一种新的方法，利用高级版YOLOv8对象检测模型，配备Convolutional Block Attention Module (CBAM)，以提高特征识别。优化的损失函数进一步优化学习过程。使用来自韩川风电园和公共数据集的5432张图像，我们的方法经过严格测试。发现缺陷检测稳定性得到了显著提高，这标志着可持续能源实践中的重要进步。本研究的贡献，推照未来研究的道路，可能会革命化可持续能源实践。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/26/eess.IV_2023_07_26/" data-id="clpxp04870185fm88fz7ybcj8" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_07_25" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/25/cs.SD_2023_07_25/" class="article-date">
  <time datetime="2023-07-25T15:00:00.000Z" itemprop="datePublished">2023-07-25</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/25/cs.SD_2023_07_25/">cs.SD - 2023-07-25</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="A-Snoring-Sound-Dataset-for-Body-Position-Recognition-Collection-Annotation-and-Analysis"><a href="#A-Snoring-Sound-Dataset-for-Body-Position-Recognition-Collection-Annotation-and-Analysis" class="headerlink" title="A Snoring Sound Dataset for Body Position Recognition: Collection, Annotation, and Analysis"></a>A Snoring Sound Dataset for Body Position Recognition: Collection, Annotation, and Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13346">http://arxiv.org/abs/2307.13346</a></li>
<li>repo_url: None</li>
<li>paper_authors: Li Xiao, Xiuping Yang, Xinhong Li, Weiping Tu, Xiong Chen, Weiyan Yi, Jie Lin, Yuhong Yang, Yanzhen Ren</li>
<li>for: This paper aims to identify the obstruction site of the upper airways in patients with Obstructive Sleep Apnea-Hypopnea Syndrome (OSAHS) by analyzing snoring sounds.</li>
<li>methods: The paper proposes a snore-based sleep body position recognition dataset (SSBPR) consisting of 7570 snoring recordings, which includes six distinct labels for sleep body position. The authors use machine learning algorithms to analyze the acoustic features of snoring sounds and identify the sleep body position.</li>
<li>results: The experimental results show that snoring sounds exhibit certain acoustic features that can be used effectively to identify body posture during sleep in real-world scenarios.Here’s the information in Simplified Chinese text:</li>
<li>for: 这篇论文目标是通过分析呼吸声来识别抑制性睡眠呼吸综合症（OSAHS）患者的顶部空气道堵塞位置。</li>
<li>methods: 该论文提出了一个基于呼吸声的睡眠姿态识别数据集（SSBPR），包括7570个呼吸声记录，其中包括6种睡眠姿态标签：躺着、左右两侧躺着、左右两侧头躺着和躺着。作者们使用机器学习算法分析呼吸声的音频特征，以识别睡眠姿态。</li>
<li>results: 实验结果表明，呼吸声具有一定的音频特征，可以在实际应用场景中有效地利用呼吸声来识别睡眠姿态。<details>
<summary>Abstract</summary>
Obstructive Sleep Apnea-Hypopnea Syndrome (OSAHS) is a chronic breathing disorder caused by a blockage in the upper airways. Snoring is a prominent symptom of OSAHS, and previous studies have attempted to identify the obstruction site of the upper airways by snoring sounds. Despite some progress, the classification of the obstruction site remains challenging in real-world clinical settings due to the influence of sleep body position on upper airways. To address this challenge, this paper proposes a snore-based sleep body position recognition dataset (SSBPR) consisting of 7570 snoring recordings, which comprises six distinct labels for sleep body position: supine, supine but left lateral head, supine but right lateral head, left-side lying, right-side lying and prone. Experimental results show that snoring sounds exhibit certain acoustic features that enable their effective utilization for identifying body posture during sleep in real-world scenarios.
</details>
<details>
<summary>摘要</summary>
《干扰性呼吸睡眠综合征（OSAHS）》是一种常见的呼吸滥血症，由上呼吸道堵塞引起。吸吮是OSAHS的一个明显的表现，以前的研究已经尝试过通过吸吮声音来确定上呼吸道堵塞的位置。然而，在真实的临床场景下，由于睡眠姿态的影响，这种分类仍然具有挑战性。为解决这个问题，本文提出了一个基于吸吮声音的睡眠姿态识别数据集（SSBPR），包括7570个吸吮记录，其中包括6种不同的睡眠姿态标签：躺平、躺平左半身、躺平右半身、左边躺、右边躺和躺股。实验结果表明，吸吮声音具有一些听频特征，可以有效地在真实的临床场景下用于识别睡眠姿态。
</details></li>
</ul>
<hr>
<h2 id="On-Device-Speaker-Anonymization-of-Acoustic-Embeddings-for-ASR-based-onFlexible-Location-Gradient-Reversal-Layer"><a href="#On-Device-Speaker-Anonymization-of-Acoustic-Embeddings-for-ASR-based-onFlexible-Location-Gradient-Reversal-Layer" class="headerlink" title="On-Device Speaker Anonymization of Acoustic Embeddings for ASR based onFlexible Location Gradient Reversal Layer"></a>On-Device Speaker Anonymization of Acoustic Embeddings for ASR based onFlexible Location Gradient Reversal Layer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13343">http://arxiv.org/abs/2307.13343</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Asif Jalal, Pablo Peso Parada, Jisi Zhang, Karthikeyan Saravanan, Mete Ozay, Myoungji Han, Jung In Lee, Seokyeong Jung</li>
<li>for: 提高语音识别私隐和语音识别精度</li>
<li>methods: 使用隐藏声学特征的抗风险层，并在云端执行剩下的模型</li>
<li>results: 提高语音识别精度6.2%，降低语音识别人员精度33%<details>
<summary>Abstract</summary>
Smart devices serviced by large-scale AI models necessitates user data transfer to the cloud for inference. For speech applications, this means transferring private user information, e.g., speaker identity. Our paper proposes a privacy-enhancing framework that targets speaker identity anonymization while preserving speech recognition accuracy for our downstream task~-~Automatic Speech Recognition (ASR). The proposed framework attaches flexible gradient reversal based speaker adversarial layers to target layers within an ASR model, where speaker adversarial training anonymizes acoustic embeddings generated by the targeted layers to remove speaker identity. We propose on-device deployment by execution of initial layers of the ASR model, and transmitting anonymized embeddings to the cloud, where the rest of the model is executed while preserving privacy. Experimental results show that our method efficiently reduces speaker recognition relative accuracy by 33%, and improves ASR performance by achieving 6.2% relative Word Error Rate (WER) reduction.
</details>
<details>
<summary>摘要</summary>
智能设备通常需要将用户数据传输到云端进行推理，这包括将私人用户信息（如说话人的身份）传输到云端。我们的论文提出了一个隐私增强框架，以保护说话人的隐私while preserving speech recognition accuracy。该框架通过在ASR模型中附加可变梯度逆转基于说话人对抗层来实现说话人匿名化，并在云端执行 оста卷ASR模型，以保持隐私。我们的方法可以减少说话人认可率Relative accuracy by 33%，并提高ASR性能by achieving 6.2% relative Word Error Rate (WER) reduction。
</details></li>
</ul>
<hr>
<h2 id="CQNV-A-combination-of-coarsely-quantized-bitstream-and-neural-vocoder-for-low-rate-speech-coding"><a href="#CQNV-A-combination-of-coarsely-quantized-bitstream-and-neural-vocoder-for-low-rate-speech-coding" class="headerlink" title="CQNV: A combination of coarsely quantized bitstream and neural vocoder for low rate speech coding"></a>CQNV: A combination of coarsely quantized bitstream and neural vocoder for low rate speech coding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13295">http://arxiv.org/abs/2307.13295</a></li>
<li>repo_url: None</li>
<li>paper_authors: Youqiang Zheng, Li Xiao, Weiping Tu, Yuhong Yang, Xinmeng Xu</li>
<li>for: 提高低比特率 speech 编码器的质量</li>
<li>methods: 结合传统参数编码器和神经 vocoder 的新框架 CQNV，以减少比特率而不损失质量</li>
<li>results: 对比 Lyra 和 Encodec，我们的提议方法可以在 1.1 kbps 比特率下获得更高的重建语音质量<details>
<summary>Abstract</summary>
Recently, speech codecs based on neural networks have proven to perform better than traditional methods. However, redundancy in traditional parameter quantization is visible within the codec architecture of combining the traditional codec with the neural vocoder. In this paper, we propose a novel framework named CQNV, which combines the coarsely quantized parameters of a traditional parametric codec to reduce the bitrate with a neural vocoder to improve the quality of the decoded speech. Furthermore, we introduce a parameters processing module into the neural vocoder to enhance the application of the bitstream of traditional speech coding parameters to the neural vocoder, further improving the reconstructed speech's quality. In the experiments, both subjective and objective evaluations demonstrate the effectiveness of the proposed CQNV framework. Specifically, our proposed method can achieve higher quality reconstructed speech at 1.1 kbps than Lyra and Encodec at 3 kbps.
</details>
<details>
<summary>摘要</summary>
Note:* " parametric codec"  transformed into "参数化编码器" (parameterized encoder)* "traditional speech coding parameters"  transformed into "传统语音编码参数" (traditional speech coding parameters)* "neural vocoder"  transformed into "神经 vocoder" (neural vocoder)* "bitstream"  transformed into "比特流" (bitstream)* "reconstructed speech"  transformed into "重建语音" (reconstructed speech)
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/25/cs.SD_2023_07_25/" data-id="clpxp043y00x1fm88azb15qjb" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_07_25" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/25/cs.CV_2023_07_25/" class="article-date">
  <time datetime="2023-07-25T13:00:00.000Z" itemprop="datePublished">2023-07-25</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/25/cs.CV_2023_07_25/">cs.CV - 2023-07-25</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Mystique-Deconstructing-SVG-Charts-for-Layout-Reuse"><a href="#Mystique-Deconstructing-SVG-Charts-for-Layout-Reuse" class="headerlink" title="Mystique: Deconstructing SVG Charts for Layout Reuse"></a>Mystique: Deconstructing SVG Charts for Layout Reuse</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13567">http://arxiv.org/abs/2307.13567</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Chen, Bongshin Lee, Yunhai Wang, Yunjeong Chang, Zhicheng Liu</li>
<li>for: 这篇论文的目的是提出一种能够解剖 rectangle-based 图表的方法，以便在新的数据上重用现有的图表。</li>
<li>methods: 这篇论文使用了一种混合式 iniciative approach，通过提取坐标轴和标签，将图表的布局 decomposing into four semantic component： mark groups、 spatial relationships、数据编码和图形约束。</li>
<li>results: 在 150 个 rectangle-based SVG 图表上，这种方法可以达到 above 85% 的准确率 для坐标和标签提取，以及 96% 的布局 decomposing 精度。在一个图表重用研究中，参与者可以轻松地将现有的图表应用到新的数据上。<details>
<summary>Abstract</summary>
To facilitate the reuse of existing charts, previous research has examined how to obtain a semantic understanding of a chart by deconstructing its visual representation into reusable components, such as encodings. However, existing deconstruction approaches primarily focus on chart styles, handling only basic layouts. In this paper, we investigate how to deconstruct chart layouts, focusing on rectangle-based ones, as they cover not only 17 chart types but also advanced layouts (e.g., small multiples, nested layouts). We develop an interactive tool, called Mystique, adopting a mixed-initiative approach to extract the axes and legend, and deconstruct a chart's layout into four semantic components: mark groups, spatial relationships, data encodings, and graphical constraints. Mystique employs a wizard interface that guides chart authors through a series of steps to specify how the deconstructed components map to their own data. On 150 rectangle-based SVG charts, Mystique achieves above 85% accuracy for axis and legend extraction and 96% accuracy for layout deconstruction. In a chart reproduction study, participants could easily reuse existing charts on new datasets. We discuss the current limitations of Mystique and future research directions.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传送给我的文本翻译成简化中文。</SYS>>以便重用现有的图表，前期研究已经研究了如何从图表的视觉表示中提取SemanticComponents，例如编码。然而，现有的分解方法主要集中在图表风格上，只处理基本布局。在这篇论文中，我们调查了如何从图表布局中提取SemanticComponents，特点Rectangle-based布局，因为它们不仅覆盖了17种图表类型，还包括高级布局（例如小多个、嵌套布局）。我们开发了一个交互工具，名为Mystique，采用杂合主义方法来提取轴和标签，并将图表布局分解成四个SemanticComponents：标记组、空间关系、数据编码和图形约束。Mystique使用了一个帮助chart作者通过一系列步骤指定分解后的组件与他们的数据之间的映射。在150个Rectangle-based SVG图表上，Mystique实现了轴和标签提取的准确率高于85%，布局分解的准确率达96%。在一次图表重制实验中，参与者可以轻松地将现有图表应用到新的数据集上。我们讨论了Mystique的当前限制和未来研究方向。
</details></li>
</ul>
<hr>
<h2 id="Model-Calibration-in-Dense-Classification-with-Adaptive-Label-Perturbation"><a href="#Model-Calibration-in-Dense-Classification-with-Adaptive-Label-Perturbation" class="headerlink" title="Model Calibration in Dense Classification with Adaptive Label Perturbation"></a>Model Calibration in Dense Classification with Adaptive Label Perturbation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13539">http://arxiv.org/abs/2307.13539</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/carlisle-liu/aslp">https://github.com/carlisle-liu/aslp</a></li>
<li>paper_authors: Jiawei Liu, Changkun Ye, Shan Wang, Ruikai Cui, Jing Zhang, Kaihao Zhang, Nick Barnes</li>
<li>for: 这个研究旨在提高深度神经网络的准确性和信任度，以便在安全相关应用中使用。</li>
<li>methods: 本研究提出了一种名为 Adaptive Stochastic Label Perturbation (ASLP) 的方法，它可以学习每个训练图像的唯一标签变化水平。ASLP 使用的是我们所提出的 Self-Calibrating Binary Cross Entropy (SC-BCE) 损失函数，它可以统一标签变化程序，包括随机方法（如 DisturbLabel）和标签平滑，以更正均化。</li>
<li>results: 实验结果显示，ASLP 可以对封闭的 binary 分类模型进行重大的均化，并且可以保持知道的标签准确率。在 both in-distribution 和 out-of-distribution 数据上，ASLP 可以提高模型的准确性和信任度。<details>
<summary>Abstract</summary>
For safety-related applications, it is crucial to produce trustworthy deep neural networks whose prediction is associated with confidence that can represent the likelihood of correctness for subsequent decision-making. Existing dense binary classification models are prone to being over-confident. To improve model calibration, we propose Adaptive Stochastic Label Perturbation (ASLP) which learns a unique label perturbation level for each training image. ASLP employs our proposed Self-Calibrating Binary Cross Entropy (SC-BCE) loss, which unifies label perturbation processes including stochastic approaches (like DisturbLabel), and label smoothing, to correct calibration while maintaining classification rates. ASLP follows Maximum Entropy Inference of classic statistical mechanics to maximise prediction entropy with respect to missing information. It performs this while: (1) preserving classification accuracy on known data as a conservative solution, or (2) specifically improves model calibration degree by minimising the gap between the prediction accuracy and expected confidence of the target training label. Extensive results demonstrate that ASLP can significantly improve calibration degrees of dense binary classification models on both in-distribution and out-of-distribution data. The code is available on https://github.com/Carlisle-Liu/ASLP.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:为安全相关应用，生成可靠的深度神经网络的预测结果需要与正确性的可信度相关，以便进行后续决策。现有的密集二分类模型容易过于自信。为了改善模型准确性，我们提议使用 Adaptive Stochastic Label Perturbation (ASLP)，它学习每个训练图像的特有标签扰动水平。ASLP使用我们提议的 Self-Calibrating Binary Cross Entropy (SC-BCE) 损失函数，它将标签扰动过程、标签平滑和随机扰动等进行统一处理，以更正准确性。ASLP采用经典统计力学中的最大 entropy 推理来最大化预测结果的不确定性，同时： (1) 保持知道数据上的分类精度作为保守解决方案，或 (2) 特定地改善模型准确性度。广泛的结果表明，ASLP可以大幅提高密集二分类模型的准确性和可靠性。代码可以在 https://github.com/Carlisle-Liu/ASLP 上获取。
</details></li>
</ul>
<hr>
<h2 id="Not-with-my-name-Inferring-artists’-names-of-input-strings-employed-by-Diffusion-Models"><a href="#Not-with-my-name-Inferring-artists’-names-of-input-strings-employed-by-Diffusion-Models" class="headerlink" title="Not with my name! Inferring artists’ names of input strings employed by Diffusion Models"></a>Not with my name! Inferring artists’ names of input strings employed by Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13527">http://arxiv.org/abs/2307.13527</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ictlab-unict/not-with-my-name">https://github.com/ictlab-unict/not-with-my-name</a></li>
<li>paper_authors: Roberto Leotta, Oliver Giudice, Luca Guarnera, Sebastiano Battiato</li>
<li>for: 本研究的目的是探讨Diffusion Models（DM）是否可以生成艺术作品，以及如果可以的话，那么DM是如何学习和复制艺术家的风格和技巧的。</li>
<li>methods: 本研究使用了一种叫做Siamese Neural Network的特殊神经网络，以便对生成的图像进行预测和分析。</li>
<li>results: 实验结果表明，我们的方法可以准确地预测图像的一部分，并且可以作为图像的输入串进行预测。这些结果表明了我们的方法是一个有用的开始，可以用于预测某个图像的完整输入串。<details>
<summary>Abstract</summary>
Diffusion Models (DM) are highly effective at generating realistic, high-quality images. However, these models lack creativity and merely compose outputs based on their training data, guided by a textual input provided at creation time. Is it acceptable to generate images reminiscent of an artist, employing his name as input? This imply that if the DM is able to replicate an artist's work then it was trained on some or all of his artworks thus violating copyright. In this paper, a preliminary study to infer the probability of use of an artist's name in the input string of a generated image is presented. To this aim we focused only on images generated by the famous DALL-E 2 and collected images (both original and generated) of five renowned artists. Finally, a dedicated Siamese Neural Network was employed to have a first kind of probability. Experimental results demonstrate that our approach is an optimal starting point and can be employed as a prior for predicting a complete input string of an investigated image. Dataset and code are available at: https://github.com/ictlab-unict/not-with-my-name .
</details>
<details>
<summary>摘要</summary>
Diffusion Models (DM) 是非常有效的生成高质量、真实的图像。然而，这些模型缺乏创造力，只是根据它们的训练数据，遵循文本输入提供于创建时，生成输出。是否可以使用艺术家的名字来生成图像？这意味着如果 DM 能够复制艺术家的作品，那么它们可能已经训练过一些或所有的艺术作品，从而违反版权。在这篇论文中，我们提出了一项初步研究，以确定使用艺术家名字在生成图像的输入串中的概率。为此，我们仅focus在 DALL-E 2 生成的图像和五位著名艺术家的原始和生成图像上。最后，我们使用专门的 Siamese Neural Network 来获得一种首个概率。实验结果表明，我们的方法是一个优秀的起点，可以作为预测完整的输入串的先天预测。数据集和代码可以在：https://github.com/ictlab-unict/not-with-my-name 中找到。
</details></li>
</ul>
<hr>
<h2 id="HeightFormer-Explicit-Height-Modeling-without-Extra-Data-for-Camera-only-3D-Object-Detection-in-Bird’s-Eye-View"><a href="#HeightFormer-Explicit-Height-Modeling-without-Extra-Data-for-Camera-only-3D-Object-Detection-in-Bird’s-Eye-View" class="headerlink" title="HeightFormer: Explicit Height Modeling without Extra Data for Camera-only 3D Object Detection in Bird’s Eye View"></a>HeightFormer: Explicit Height Modeling without Extra Data for Camera-only 3D Object Detection in Bird’s Eye View</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13510">http://arxiv.org/abs/2307.13510</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiming Wu, Ruixiang Li, Zequn Qin, Xinhai Zhao, Xi Li<br>for:height-based bird’s eye view (BEV) representation for autonomous drivingmethods:explicitly modeling heights in the BEV space using a self-recursive approachresults:achieves state-of-the-art (SOTA) performance compared to camera-only methods without using extra data like LiDAR<details>
<summary>Abstract</summary>
Vision-based Bird's Eye View (BEV) representation is an emerging perception formulation for autonomous driving. The core challenge is to construct BEV space with multi-camera features, which is a one-to-many ill-posed problem. Diving into all previous BEV representation generation methods, we found that most of them fall into two types: modeling depths in image views or modeling heights in the BEV space, mostly in an implicit way. In this work, we propose to explicitly model heights in the BEV space, which needs no extra data like LiDAR and can fit arbitrary camera rigs and types compared to modeling depths. Theoretically, we give proof of the equivalence between height-based methods and depth-based methods. Considering the equivalence and some advantages of modeling heights, we propose HeightFormer, which models heights and uncertainties in a self-recursive way. Without any extra data, the proposed HeightFormer could estimate heights in BEV accurately. Benchmark results show that the performance of HeightFormer achieves SOTA compared with those camera-only methods.
</details>
<details>
<summary>摘要</summary>
《bird's eye view（BEV）表示方式是自动驾驶视觉形态的一种emerging概念。核心挑战是在多camera视图中构建BEV空间，这是一个一对多的ILL-posed问题。我们对所有的BEV表示生成方法进行了检查，发现大多数都 fall into两类：在图像视图中模型深度或在BEV空间中模型高度，大多数是通过隐式方式来实现。在这种工作中，我们提议在BEV空间中直接模型高度，无需额外数据如LiDAR，并且可以适应任何相机装置和类型。从理论角度来看，我们证明了高度基于方法和深度基于方法之间的等价性。考虑到等价性和高度模型的一些优点，我们提议HeightFormer，它在自我循环方式中模型高度和不确定性。无需额外数据，提议的HeightFormer可以在BEV空间中估计高度的准确性。 benchmark结果表明，HeightFormer的性能与camera-only方法相比，达到了最高的SOTA水平。》Note: "SOTA" stands for "State of the Art", which means the highest level of performance currently achieved.
</details></li>
</ul>
<hr>
<h2 id="NormAUG-Normalization-guided-Augmentation-for-Domain-Generalization"><a href="#NormAUG-Normalization-guided-Augmentation-for-Domain-Generalization" class="headerlink" title="NormAUG: Normalization-guided Augmentation for Domain Generalization"></a>NormAUG: Normalization-guided Augmentation for Domain Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13492">http://arxiv.org/abs/2307.13492</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Qi, Hongpeng Yang, Yinghuan Shi, Xin Geng</li>
<li>for: 提高深度学习模型在指导学习中的性能， Addressing the challenge of domain shift between training and test sets.</li>
<li>methods: 提出了一种名为 NormAUG（Normalization-guided Augmentation）的简单 yet effective方法，通过在不同领域的批处理中进行扩充，提高模型的泛化能力。</li>
<li>results: 在多个 benchmark datasets 上进行了广泛的实验， validate the effectiveness of our proposed method, and show that it can effectively improve the performance of deep learning models in supervised learning tasks.<details>
<summary>Abstract</summary>
Deep learning has made significant advancements in supervised learning. However, models trained in this setting often face challenges due to domain shift between training and test sets, resulting in a significant drop in performance during testing. To address this issue, several domain generalization methods have been developed to learn robust and domain-invariant features from multiple training domains that can generalize well to unseen test domains. Data augmentation plays a crucial role in achieving this goal by enhancing the diversity of the training data. In this paper, inspired by the observation that normalizing an image with different statistics generated by different batches with various domains can perturb its feature, we propose a simple yet effective method called NormAUG (Normalization-guided Augmentation). Our method includes two paths: the main path and the auxiliary (augmented) path. During training, the auxiliary path includes multiple sub-paths, each corresponding to batch normalization for a single domain or a random combination of multiple domains. This introduces diverse information at the feature level and improves the generalization of the main path. Moreover, our NormAUG method effectively reduces the existing upper boundary for generalization based on theoretical perspectives. During the test stage, we leverage an ensemble strategy to combine the predictions from the auxiliary path of our model, further boosting performance. Extensive experiments are conducted on multiple benchmark datasets to validate the effectiveness of our proposed method.
</details>
<details>
<summary>摘要</summary>
根据图像不同域生成的不同统计数据的观察，我们提出了一种简单 yet 有效的方法，即 NormAUG（normalization-guided Augmentation）。我们的方法包括两个路径：主路径和辅助（扩展）路径。在训练阶段，辅助路径包括多个子路径，每个子路径对应一个域或一个随机组合多个域的批normalization。这引入了多样化的信息水平，从而提高主路径的泛化性。此外，我们的 NormAUG 方法有效地降低了基于理论上的最大界限，以提高泛化性。在测试阶段，我们利用了一种协同策略，将辅助路径的预测结果 ensemble，进一步提高表现。我们在多个标准 benchmark 数据集上进行了广泛的实验，以验证我们的提议的效果。
</details></li>
</ul>
<hr>
<h2 id="Cos-R-CNN-for-Online-Few-shot-Object-Detection"><a href="#Cos-R-CNN-for-Online-Few-shot-Object-Detection" class="headerlink" title="Cos R-CNN for Online Few-shot Object Detection"></a>Cos R-CNN for Online Few-shot Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13485">http://arxiv.org/abs/2307.13485</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gratianus Wesley Putra Data, Henry Howard-Jenkins, David Murray, Victor Prisacariu</li>
<li>for: 这篇论文旨在提出一个简单的例子基本的几何�CNN模型，用于在网络几何中进行几何物类检测。</li>
<li>methods: 这个模型使用了学习比较任务，将未见类别表示为对象的例子图像，并通过它们的相似性进行检测。</li>
<li>results: 这个模型在5-way ImageNet几何检测测试 benchmark 上取得了最佳结果，在线上1&#x2F;5&#x2F;10-shot情况下高于8&#x2F;3&#x2F;1%，并在线上20-way几何VOC中运行所有类别，在新类别上表现最好。<details>
<summary>Abstract</summary>
We propose Cos R-CNN, a simple exemplar-based R-CNN formulation that is designed for online few-shot object detection. That is, it is able to localise and classify novel object categories in images with few examples without fine-tuning. Cos R-CNN frames detection as a learning-to-compare task: unseen classes are represented as exemplar images, and objects are detected based on their similarity to these exemplars. The cosine-based classification head allows for dynamic adaptation of classification parameters to the exemplar embedding, and encourages the clustering of similar classes in embedding space without the need for manual tuning of distance-metric hyperparameters. This simple formulation achieves best results on the recently proposed 5-way ImageNet few-shot detection benchmark, beating the online 1/5/10-shot scenarios by more than 8/3/1%, as well as performing up to 20% better in online 20-way few-shot VOC across all shots on novel classes.
</details>
<details>
<summary>摘要</summary>
我们提出了Cos R-CNN，一种简单的示例基于的R-CNN形式，用于在线少量示例Object检测。即可以在图像中检测到未经调整的新类别 объек。Cos R-CNN将检测视为学习比较任务，未seen类是用示例图像表示，并基于这些示例图像来检测对象。cosine类型的分类头允许在示例嵌入空间进行动态适应分类参数，并促进类别的嵌入空间减少，不需要手动调整距离度量参数。这种简单的形式在最新的5种ImageNet几shot检测benchmark上达到了最佳结果，在在线1/5/10-shot场景中超过8/3/1%，并在在线20-way几shotVOC中所有陌生类上达到了20%的提升。
</details></li>
</ul>
<hr>
<h2 id="Weakly-supervised-3D-Pose-Transfer-with-Keypoints"><a href="#Weakly-supervised-3D-Pose-Transfer-with-Keypoints" class="headerlink" title="Weakly-supervised 3D Pose Transfer with Keypoints"></a>Weakly-supervised 3D Pose Transfer with Keypoints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13459">http://arxiv.org/abs/2307.13459</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jinnan-chen/3d-pose-transfer">https://github.com/jinnan-chen/3d-pose-transfer</a></li>
<li>paper_authors: Jinnan Chen, Chen Li, Gim Hee Lee</li>
<li>for: 本研究旨在解决3D姿态质量转移中的三大挑战：缺乏不同人物表演同一个姿态的对应数据集，分离姿态信息和形状信息，将姿态转移应用到不同骨架上。</li>
<li>methods: 我们提出了一种新的弱监督键点基于框架，使用不同骨架的逆 kinematics 计算源和目标骨架之间的变换。我们的方法仅需要键点监督，可以应用到不同骨架上，并且具有形状不变的特点，允许提取目标骨架中的姿态信息而不是形状信息。我们还设计了一种自我超频重建来实现自监督的姿态转移，不需要与target和source骨架具有同样的姿态和形状。</li>
<li>results: 我们在人体和动物数据集上进行了评估，与状态静的无监督方法相比，我们的方法具有更高的性能，甚至与完全监督方法相当。在更复杂的 Mixamo 数据集上进行测试，我们的方法能够正确地处理具有不同骨架和衣物的骨架。跨数据集评估表明了我们的方法具有强大的总体化能力。<details>
<summary>Abstract</summary>
The main challenges of 3D pose transfer are: 1) Lack of paired training data with different characters performing the same pose; 2) Disentangling pose and shape information from the target mesh; 3) Difficulty in applying to meshes with different topologies. We thus propose a novel weakly-supervised keypoint-based framework to overcome these difficulties. Specifically, we use a topology-agnostic keypoint detector with inverse kinematics to compute transformations between the source and target meshes. Our method only requires supervision on the keypoints, can be applied to meshes with different topologies and is shape-invariant for the target which allows extraction of pose-only information from the target meshes without transferring shape information. We further design a cycle reconstruction to perform self-supervised pose transfer without the need for ground truth deformed mesh with the same pose and shape as the target and source, respectively. We evaluate our approach on benchmark human and animal datasets, where we achieve superior performance compared to the state-of-the-art unsupervised approaches and even comparable performance with the fully supervised approaches. We test on the more challenging Mixamo dataset to verify our approach's ability in handling meshes with different topologies and complex clothes. Cross-dataset evaluation further shows the strong generalization ability of our approach.
</details>
<details>
<summary>摘要</summary>
主要3D姿态传输挑战包括：1）缺乏不同人物表演同一姿态的对称训练数据；2）分离姿态信息和形状信息于目标网格；3）应用于不同顶点数的网格上。我们因此提出了一种新的弱型监督基点方法来解决这些挑战。我们使用不同顶点数的网格上的 topology-agnostic 基点检测器，并使用 inverse kinematics 计算源和目标网格之间的变换。我们的方法只需要监督基点，可以应用于不同顶点数的网格上，并且具有形状不变的特性，允许从目标网格中提取姿态信息而不是形状信息。我们进一步设计了一种自我监督的循环重建来实现无监督 pose transfer，不需要与target和source网格具有同样的姿态和形状的ground truth扭曲网格。我们在人类和动物数据集上评估了我们的方法，与无监督方法相比，我们达到了更高的性能，甚至与完全监督方法相比具有相似的性能。我们在更加具有挑战性的 Mixamo 数据集上进行了测试，以验证我们的方法可以处理不同顶点数的网格和复杂的衣服。cross-dataset评估还表明了我们的方法具有强大的泛化能力。
</details></li>
</ul>
<hr>
<h2 id="An-Explainable-Model-Agnostic-Algorithm-for-CNN-based-Biometrics-Verification"><a href="#An-Explainable-Model-Agnostic-Algorithm-for-CNN-based-Biometrics-Verification" class="headerlink" title="An Explainable Model-Agnostic Algorithm for CNN-based Biometrics Verification"></a>An Explainable Model-Agnostic Algorithm for CNN-based Biometrics Verification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13428">http://arxiv.org/abs/2307.13428</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fernando Alonso-Fernandez, Kevin Hernandez-Diaz, Jose M. Buades, Prayag Tiwari, Josef Bigun</li>
<li>for: 这 paper 描述了对生物ometric验证设定下进行 Local Interpretable Model-Agnostic Explanations (LIME) AI 方法的适应。</li>
<li>methods: 这 paper 使用了对生物ometric验证设定下的两个 CNN 模型（基于 MobileNetv2 和 ResNet50），通过对输入图像的干扰版本的特征向量之间的高 Cosine 相似性来实现解释性。</li>
<li>results: 这 paper 实现了对 face biometrics 中的两个 CNN 模型（基于 MobileNetv2 和 ResNet50）的解释性。<details>
<summary>Abstract</summary>
This paper describes an adaptation of the Local Interpretable Model-Agnostic Explanations (LIME) AI method to operate under a biometric verification setting. LIME was initially proposed for networks with the same output classes used for training, and it employs the softmax probability to determine which regions of the image contribute the most to classification. However, in a verification setting, the classes to be recognized have not been seen during training. In addition, instead of using the softmax output, face descriptors are usually obtained from a layer before the classification layer. The model is adapted to achieve explainability via cosine similarity between feature vectors of perturbated versions of the input image. The method is showcased for face biometrics with two CNN models based on MobileNetv2 and ResNet50.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-signal-processing-interpretation-of-noise-reduction-convolutional-neural-networks"><a href="#A-signal-processing-interpretation-of-noise-reduction-convolutional-neural-networks" class="headerlink" title="A signal processing interpretation of noise-reduction convolutional neural networks"></a>A signal processing interpretation of noise-reduction convolutional neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13425">http://arxiv.org/abs/2307.13425</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luis A. Zavala-Mondragón, Peter H. N. de With, Fons van der Sommen</li>
<li>for: 这篇论文旨在提供一种统一的理论框架，用于解释深度卷积神经网络（Encoding-Decoding CNNs）的内部工作机制，并且可以帮助设计更加有效率的新型神经网络架构。</li>
<li>methods: 这篇论文使用了深度卷积神经网络的基本原理，以及信号处理领域的基本概念，将其与深度学习领域的研究相结合，以建立一个自 contenido的理论框架。</li>
<li>results: 这篇论文通过这种新的理论框架，可以帮助理解深度卷积神经网络的内部工作机制，并且可以用于设计更加有效率的新型神经网络架构。<details>
<summary>Abstract</summary>
Encoding-decoding CNNs play a central role in data-driven noise reduction and can be found within numerous deep-learning algorithms. However, the development of these CNN architectures is often done in ad-hoc fashion and theoretical underpinnings for important design choices is generally lacking. Up to this moment there are different existing relevant works that strive to explain the internal operation of these CNNs. Still, these ideas are either scattered and/or may require significant expertise to be accessible for a bigger audience. In order to open up this exciting field, this article builds intuition on the theory of deep convolutional framelets and explains diverse ED CNN architectures in a unified theoretical framework. By connecting basic principles from signal processing to the field of deep learning, this self-contained material offers significant guidance for designing robust and efficient novel CNN architectures.
</details>
<details>
<summary>摘要</summary>
encoding-decoding CNNs 在数据驱动噪声reduction中扮演中心角色，可以在多种深度学习算法中找到。然而， develop these CNN architectures 通常是done in ad-hoc fashion，lacking theoretical underpinnings for important design choices。 Until now, there are different existing relevant works that strive to explain the internal operation of these CNNs，but these ideas are either scattered and/or may require significant expertise to be accessible for a bigger audience。 In order to open up this exciting field, this article builds intuition on the theory of deep convolutional framelets and explains diverse ED CNN architectures in a unified theoretical framework。By connecting basic principles from signal processing to the field of deep learning，this self-contained material offers significant guidance for designing robust and efficient novel CNN architectures。Here's the text with the traditional Chinese characters:Encoding-Decoding CNNs 在数据驱动噪音reduction中扮演中心角色，可以在多种深度学习算法中找到。然而，开发这些CNN架构通常是done in ad-hoc fashion，lacking theoretical underpinnings for important design choices。 Until now, there are different existing relevant works that strive to explain the internal operation of these CNNs，but these ideas are either scattered and/or may require significant expertise to be accessible for a bigger audience。 In order to open up this exciting field, this article builds intuition on the theory of deep convolutional framelets and explains diverse ED CNN architectures in a unified theoretical framework。By connecting basic principles from signal processing to the field of deep learning，this self-contained material offers significant guidance for designing robust and efficient novel CNN architectures。
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Memory-Wall-Effects-in-CNN-Engines-with-On-the-Fly-Weights-Generation"><a href="#Mitigating-Memory-Wall-Effects-in-CNN-Engines-with-On-the-Fly-Weights-Generation" class="headerlink" title="Mitigating Memory Wall Effects in CNN Engines with On-the-Fly Weights Generation"></a>Mitigating Memory Wall Effects in CNN Engines with On-the-Fly Weights Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13412">http://arxiv.org/abs/2307.13412</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stylianos I. Venieris, Javier Fernandez-Marques, Nicholas D. Lane</li>
<li>for: 这个研究是为了提高FPGA上的深度学习运算效率和能效性。</li>
<li>methods: 本研究使用了一种叫做”on-the-fly”的方法，通过在 runtime 中预先将矩阵扩展为较大的矩阵，以提高内存系结的效率。此外，研究者还提出了一个自动对应硬件-软件架构的方法，以提高精度和效率的平衡。</li>
<li>results: 研究结果显示，提案的框架可以实现2.57倍的效率提升比高性能的GPU设计，并且可以实现3.94倍的高效率数据频谱比较一般的FPGA-based CNN加速器。<details>
<summary>Abstract</summary>
The unprecedented accuracy of convolutional neural networks (CNNs) across a broad range of AI tasks has led to their widespread deployment in mobile and embedded settings. In a pursuit for high-performance and energy-efficient inference, significant research effort has been invested in the design of FPGA-based CNN accelerators. In this context, single computation engines constitute a popular approach to support diverse CNN modes without the overhead of fabric reconfiguration. Nevertheless, this flexibility often comes with significantly degraded performance on memory-bound layers and resource underutilisation due to the suboptimal mapping of certain layers on the engine's fixed configuration. In this work, we investigate the implications in terms of CNN engine design for a class of models that introduce a pre-convolution stage to decompress the weights at run time. We refer to these approaches as on-the-fly. This paper presents unzipFPGA, a novel CNN inference system that counteracts the limitations of existing CNN engines. The proposed framework comprises a novel CNN hardware architecture that introduces a weights generator module that enables the on-chip on-the-fly generation of weights, alleviating the negative impact of limited bandwidth on memory-bound layers. We further enhance unzipFPGA with an automated hardware-aware methodology that tailors the weights generation mechanism to the target CNN-device pair, leading to an improved accuracy-performance balance. Finally, we introduce an input selective processing element (PE) design that balances the load between PEs in suboptimally mapped layers. The proposed framework yields hardware designs that achieve an average of 2.57x performance efficiency gain over highly optimised GPU designs for the same power constraints and up to 3.94x higher performance density over a diverse range of state-of-the-art FPGA-based CNN accelerators.
</details>
<details>
<summary>摘要</summary>
“ convolutional neural networks (CNNs) 在各种人工智能任务中的无前例精度，使得它们在 mobil 和嵌入式设定中广泛应用。为了实现高性能和能效的推察，研究人员对 FPGA 基于 CNN 加速器的设计进行了很大的投入。在这个上下文中，单一 computation engine 成为了广泛使用的方法，以支持多种 CNN 模式，而不需要组织预设的组件重新配置。然而，这种灵活性通常会带来内存维护层的性能下降和资源处理不当用，从而导致某些层的对应不佳。在这个研究中，我们调查了这种问题的影响，并提出了一个 novel CNN 推察系统，称为 unzipFPGA。这个架构包括一个新的 CNN 硬件架构，其中包括一个可以在 run time 中实现 weights 的生成 module，以解决由限制的带宽所导致的负面影响。我们还将 unzipFPGA 扩展到一个自动化的硬件感知方法，以适应目标 CNN-device 组合，从而获得更好的精度-性能平衡。最后，我们引入了一个输入选择处理元素 (PE) 设计，以对不同的 PE 进行负载均衡。提案的架构可以实现与高度优化的 GPU 设计相同的性能效率，同时具有更高的性能密度。”
</details></li>
</ul>
<hr>
<h2 id="Scoring-Cycling-Environments-Perceived-Safety-using-Pairwise-Image-Comparisons"><a href="#Scoring-Cycling-Environments-Perceived-Safety-using-Pairwise-Image-Comparisons" class="headerlink" title="Scoring Cycling Environments Perceived Safety using Pairwise Image Comparisons"></a>Scoring Cycling Environments Perceived Safety using Pairwise Image Comparisons</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13397">http://arxiv.org/abs/2307.13397</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mncosta/scoring_pairwise">https://github.com/mncosta/scoring_pairwise</a></li>
<li>paper_authors: Miguel Costa, Manuel Marques, Felix Wilhelm Siebert, Carlos Lima Azevedo, Filipe Moura</li>
<li>for: 这个研究旨在探讨如何分析和理解人们对自行车安全性的感受，以及城市环境和自行车情况对这种感受的影响。</li>
<li>methods: 这个研究使用了对实际图像的评估，让受试者选择他们认为更安全的自行车环境。研究还使用了多种对比方法来评估自行车环境的安全性。</li>
<li>results: 研究发现，城市环境和自行车情况对人们对自行车安全性的感受产生了重要影响。这种方法可以帮助城市规划师设计更有效的措施，以促进自行车模式的普及。此外，这种方法可以continuously评估自行车环境的改进，并快速评估措施的效果。<details>
<summary>Abstract</summary>
Today, many cities seek to transition to more sustainable transportation systems. Cycling is critical in this transition for shorter trips, including first-and-last-mile links to transit. Yet, if individuals perceive cycling as unsafe, they will not cycle and choose other transportation modes. This study presents a novel approach to identifying how the perception of cycling safety can be analyzed and understood and the impact of the built environment and cycling contexts on such perceptions. We base our work on other perception studies and pairwise comparisons, using real-world images to survey respondents. We repeatedly show respondents two road environments and ask them to select the one they perceive as safer for cycling. We compare several methods capable of rating cycling environments from pairwise comparisons and classify cycling environments perceived as safe or unsafe. Urban planning can use this score to improve interventions' effectiveness and improve cycling promotion campaigns. Furthermore, this approach facilitates the continuous assessment of changing cycling environments, allows for a short-term evaluation of measures, and is efficiently deployed in different locations or contexts.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Towards-Unifying-Anatomy-Segmentation-Automated-Generation-of-a-Full-body-CT-Dataset-via-Knowledge-Aggregation-and-Anatomical-Guidelines"><a href="#Towards-Unifying-Anatomy-Segmentation-Automated-Generation-of-a-Full-body-CT-Dataset-via-Knowledge-Aggregation-and-Anatomical-Guidelines" class="headerlink" title="Towards Unifying Anatomy Segmentation: Automated Generation of a Full-body CT Dataset via Knowledge Aggregation and Anatomical Guidelines"></a>Towards Unifying Anatomy Segmentation: Automated Generation of a Full-body CT Dataset via Knowledge Aggregation and Anatomical Guidelines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13375">http://arxiv.org/abs/2307.13375</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alexanderjaus/atlasdataset">https://github.com/alexanderjaus/atlasdataset</a></li>
<li>paper_authors: Alexander Jaus, Constantin Seibold, Kelsey Hermann, Alexandra Walter, Kristina Giske, Johannes Haubold, Jens Kleesiek, Rainer Stiefelhagen</li>
<li>for: 本研究开发了一种自动生成医学影像分割数据集的方法，使用nnU-Net基于pseudo标签和医学指导pseudo标签纠正。</li>
<li>methods: 本方法首先使用nnU-Net进行pseudo标签生成，然后通过结合多个碎片化知识库，生成了一个涵盖整个人体CT扫描图的142个小块级标签数据集，并得到了专家认可。</li>
<li>results: 我们的方法不需要手动标注数据，并在BTCV数据集上达到85%的dice分数。此外，我们还对数据集进行了可扩展的自动检查和高质量专家检查，以确保数据集的可靠性和医学有效性。<details>
<summary>Abstract</summary>
In this study, we present a method for generating automated anatomy segmentation datasets using a sequential process that involves nnU-Net-based pseudo-labeling and anatomy-guided pseudo-label refinement. By combining various fragmented knowledge bases, we generate a dataset of whole-body CT scans with $142$ voxel-level labels for 533 volumes providing comprehensive anatomical coverage which experts have approved. Our proposed procedure does not rely on manual annotation during the label aggregation stage. We examine its plausibility and usefulness using three complementary checks: Human expert evaluation which approved the dataset, a Deep Learning usefulness benchmark on the BTCV dataset in which we achieve 85% dice score without using its training dataset, and medical validity checks. This evaluation procedure combines scalable automated checks with labor-intensive high-quality expert checks. Besides the dataset, we release our trained unified anatomical segmentation model capable of predicting $142$ anatomical structures on CT data.
</details>
<details>
<summary>摘要</summary>
在这个研究中，我们提出了一种方法用于自动生成医学影像分割数据集，该方法包括基于nnU-Net的假标注和骨化假标注纠正。通过将各种碎片化知识库集成起来，我们生成了一个整体CT扫描图像的数据集，包含142个块级标签，对533个卷积提供了全面的解剖学覆盖。我们的提posed方法不需要手动标注 durante el etiquetado de etiquetas stage。我们使用三种 complementary checks to evaluate the plausibility and usefulness of our method: expert evaluation by human, deep learning usefulness benchmark on the BTCV dataset, and medical validity checks. This evaluation procedure combines scalable automated checks with labor-intensive high-quality expert checks. In addition to the dataset, we release our trained unified anatomical segmentation model, capable of predicting 142 anatomical structures on CT data.
</details></li>
</ul>
<hr>
<h2 id="Kefa-A-Knowledge-Enhanced-and-Fine-grained-Aligned-Speaker-for-Navigation-Instruction-Generation"><a href="#Kefa-A-Knowledge-Enhanced-and-Fine-grained-Aligned-Speaker-for-Navigation-Instruction-Generation" class="headerlink" title="Kefa: A Knowledge Enhanced and Fine-grained Aligned Speaker for Navigation Instruction Generation"></a>Kefa: A Knowledge Enhanced and Fine-grained Aligned Speaker for Navigation Instruction Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13368">http://arxiv.org/abs/2307.13368</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/haitianzeng/KEFA">https://github.com/haitianzeng/KEFA</a></li>
<li>paper_authors: Haitian Zeng, Xiaohan Wang, Wenguan Wang, Yi Yang</li>
<li>for: 提高视力语言导航中的导航指令生成性能</li>
<li>methods: 提出了知识更新模块和适应时间Alignment方法，以强化特征表示和精细对齐生成的指令和观察序列</li>
<li>results: 在R2R和UrbanWalk数据集上实现了视力语言导航中的导航指令生成性能的状态作者<details>
<summary>Abstract</summary>
We introduce a novel speaker model \textsc{Kefa} for navigation instruction generation. The existing speaker models in Vision-and-Language Navigation suffer from the large domain gap of vision features between different environments and insufficient temporal grounding capability. To address the challenges, we propose a Knowledge Refinement Module to enhance the feature representation with external knowledge facts, and an Adaptive Temporal Alignment method to enforce fine-grained alignment between the generated instructions and the observation sequences. Moreover, we propose a new metric SPICE-D for navigation instruction evaluation, which is aware of the correctness of direction phrases. The experimental results on R2R and UrbanWalk datasets show that the proposed KEFA speaker achieves state-of-the-art instruction generation performance for both indoor and outdoor scenes.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种新的说话模型，即KEFA模型，用于生成导航指令。现有的视语导航中的说话模型受到不同环境中视觉特征的域外差和时间固定不足的挑战。为解决这些挑战，我们提出了知识精化模块，用于增强特征表示，以及适应时间对齐方法，用于确保生成的指令和观察序列之间的细腻对齐。此外，我们提出了一个新的评价指标SPICE-D，用于评价导航指令的正确性。实验结果表明，我们提出的KEFA说话模型在R2R和UrbanWalk数据集上实现了导航指令生成性能的州际之最。
</details></li>
</ul>
<hr>
<h2 id="3DRP-Net-3D-Relative-Position-aware-Network-for-3D-Visual-Grounding"><a href="#3DRP-Net-3D-Relative-Position-aware-Network-for-3D-Visual-Grounding" class="headerlink" title="3DRP-Net: 3D Relative Position-aware Network for 3D Visual Grounding"></a>3DRP-Net: 3D Relative Position-aware Network for 3D Visual Grounding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13363">http://arxiv.org/abs/2307.13363</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zehan Wang, Haifeng Huang, Yang Zhao, Linjun Li, Xize Cheng, Yichen Zhu, Aoxiong Yin, Zhou Zhao</li>
<li>for: 本研究旨在使用自由语言描述将3D点云中的目标对象Localize。</li>
<li>methods: 我们提出了一种关注关系的一stage框架，名为3D相对位置感知网络（3DRP-Net），可以有效地捕捉对象之间的相对空间关系并增强对象特征。</li>
<li>results: 我们的方法在三个 benchmark（ScanRefer和Nr3D&#x2F;Sr3D）中的总体性能比所有现状最佳方法高。<details>
<summary>Abstract</summary>
3D visual grounding aims to localize the target object in a 3D point cloud by a free-form language description. Typically, the sentences describing the target object tend to provide information about its relative relation between other objects and its position within the whole scene. In this work, we propose a relation-aware one-stage framework, named 3D Relative Position-aware Network (3DRP-Net), which can effectively capture the relative spatial relationships between objects and enhance object attributes. Specifically, 1) we propose a 3D Relative Position Multi-head Attention (3DRP-MA) module to analyze relative relations from different directions in the context of object pairs, which helps the model to focus on the specific object relations mentioned in the sentence. 2) We designed a soft-labeling strategy to alleviate the spatial ambiguity caused by redundant points, which further stabilizes and enhances the learning process through a constant and discriminative distribution. Extensive experiments conducted on three benchmarks (i.e., ScanRefer and Nr3D/Sr3D) demonstrate that our method outperforms all the state-of-the-art methods in general. The source code will be released on GitHub.
</details>
<details>
<summary>摘要</summary>
三维视觉定位是目标对象在三维点云中的地址定位，通常通过自由形式的语言描述。这些句子通常提供对目标对象的相对关系和场景中的位置信息。在这种工作中，我们提议一种关注相对关系的一stage框架，名为三维相对位置感知网络（3DRP-Net），可以有效地捕捉对象之间的相对空间关系并增强对象特征。Specifically，我们提出了一个三维相对位置多头注意模块（3DRP-MA）来分析对象之间的相对关系，从不同方向上在对象对中分析这些关系，以帮助模型专注于文本中提到的特定对象关系。另外，我们设计了一种软标注策略，以解决由重复点所引起的空间歧义，从而使模型更加稳定和精准。我们在三个 benchmark（即ScanRefer和Nr3D/Sr3D）进行了广泛的实验，结果显示，我们的方法在总体上超过了所有现有的方法。我们将代码发布到 GitHub。
</details></li>
</ul>
<hr>
<h2 id="Of-Mice-and-Pose-2D-Mouse-Pose-Estimation-from-Unlabelled-Data-and-Synthetic-Prior"><a href="#Of-Mice-and-Pose-2D-Mouse-Pose-Estimation-from-Unlabelled-Data-and-Synthetic-Prior" class="headerlink" title="Of Mice and Pose: 2D Mouse Pose Estimation from Unlabelled Data and Synthetic Prior"></a>Of Mice and Pose: 2D Mouse Pose Estimation from Unlabelled Data and Synthetic Prior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13361">http://arxiv.org/abs/2307.13361</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jose Sosa, Sharn Perry, Jane Alty, David Hogg</li>
<li>for: 这paper是为了解决动物Behavior tracking和量度的问题，尤其是在ecology, biology和neuroscience等领域，因为大量的动物记录数据已经被生成，但是一些计算机视觉技术无法利用这些数据，因为缺乏标注。</li>
<li>methods: 我们提出了一种使用无标注图像来估算鼠体姿 pose的方法，基于最近的自动学习人体 pose估算方法，使用单张图像和一组无对应的2Dpose图像，通过GAN框架来生成empirical prior of 2Dpose。我们适应了这种方法到鼠的肢体结构，并生成了synthetic 3D鼠模型来生成empirical prior。</li>
<li>results: 我们在一个新的鼠视频数据集上进行了实验，并与手动获取的ground truth进行比较。我们还与一种已有的supervised state-of-the-art方法进行比较，并显示了Promising results，即使没有paired training data。此外，我们还使用了一个马图像集来展示这种设置的潜在应用性。<details>
<summary>Abstract</summary>
Numerous fields, such as ecology, biology, and neuroscience, use animal recordings to track and measure animal behaviour. Over time, a significant volume of such data has been produced, but some computer vision techniques cannot explore it due to the lack of annotations. To address this, we propose an approach for estimating 2D mouse body pose from unlabelled images using a synthetically generated empirical pose prior. Our proposal is based on a recent self-supervised method for estimating 2D human pose that uses single images and a set of unpaired typical 2D poses within a GAN framework. We adapt this method to the limb structure of the mouse and generate the empirical prior of 2D poses from a synthetic 3D mouse model, thereby avoiding manual annotation. In experiments on a new mouse video dataset, we evaluate the performance of the approach by comparing pose predictions to a manually obtained ground truth. We also compare predictions with those from a supervised state-of-the-art method for animal pose estimation. The latter evaluation indicates promising results despite the lack of paired training data. Finally, qualitative results using a dataset of horse images show the potential of the setting to adapt to other animal species.
</details>
<details>
<summary>摘要</summary>
许多领域，如生态学、生物学和神经科学，通过动物记录跟踪和测量动物行为。随着时间的推移，这些数据的量已经很大，但一些计算机视觉技术无法探索它们，因为缺乏注释。为解决这个问题，我们提出了一种方法，通过使用生成的经验性姿势先验来估算无注释图像中的2D鼠体姿势。我们的提议基于最近的自动适应人体 pose 估算方法，该方法使用单张图像和一组无对应的2D姿势集来生成一个GAN框架中的经验性姿势先验。我们适应了鼠的四肢结构，并生成了一个synthetic 3D鼠模型中的经验性姿势先验，从而避免手动注释。在一个新的鼠视频数据集上进行了实验，我们评估了方法的性能，并与一种已有的supervised状态的动物pose估算方法进行比较。后者的评估结果表明，我们的方法在缺乏对应数据的情况下可以获得承诺的结果。此外，使用一个马图像集来表征其他动物种类的可能性的质性结果也提供了。
</details></li>
</ul>
<hr>
<h2 id="Prior-Based-Online-Lane-Graph-Extraction-from-Single-Onboard-Camera-Image"><a href="#Prior-Based-Online-Lane-Graph-Extraction-from-Single-Onboard-Camera-Image" class="headerlink" title="Prior Based Online Lane Graph Extraction from Single Onboard Camera Image"></a>Prior Based Online Lane Graph Extraction from Single Onboard Camera Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13344">http://arxiv.org/abs/2307.13344</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ybarancan/lanewae">https://github.com/ybarancan/lanewae</a></li>
<li>paper_authors: Yigit Baran Can, Alexander Liniger, Danda Pani Paudel, Luc Van Gool</li>
<li>for: 本研究旨在提供一种在线 Bird’s-Eye-View 车道图生成方法，以便普遍和可靠地自动驾驶。</li>
<li>methods: 该方法使用优先信息提高估计质量。优先信息通过一种基于 transformer 的 Wasserstein 自编码器从数据集提取。然后，自编码器用于提高初始车道图估计。这是通过 latent 空间向量优化来实现的，该优化劝说车道图估计与优先信息保持一致。</li>
<li>results: 对 NuScenes 和 Argoverse 两个标准数据集进行测试，结果显示提议方法与现有方法相比有显著改善。<details>
<summary>Abstract</summary>
The local road network information is essential for autonomous navigation. This information is commonly obtained from offline HD-Maps in terms of lane graphs. However, the local road network at a given moment can be drastically different than the one given in the offline maps; due to construction works, accidents etc. Moreover, the autonomous vehicle might be at a location not covered in the offline HD-Map. Thus, online estimation of the lane graph is crucial for widespread and reliable autonomous navigation. In this work, we tackle online Bird's-Eye-View lane graph extraction from a single onboard camera image. We propose to use prior information to increase quality of the estimations. The prior is extracted from the dataset through a transformer based Wasserstein Autoencoder. The autoencoder is then used to enhance the initial lane graph estimates. This is done through optimization of the latent space vector. The optimization encourages the lane graph estimation to be logical by discouraging it to diverge from the prior distribution. We test the method on two benchmark datasets, NuScenes and Argoverse. The results show that the proposed method significantly improves the performance compared to state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
地方路网信息是自动导航的关键。这些信息通常来自于离线高级地图，表示为几何图。然而，当地方路网在给定时刻发生重大变化，比如建筑工程或意外等，那么离线地图中提供的信息可能不准确。此外，自动汽车可能位于离线地图中没有覆盖的位置。因此，在线计算路网图是自动导航的关键。在这种情况下，我们解决了在单个摄像头图像上进行在线鸟瞰视图lane图Estimation。我们提议使用先前信息来提高估计质量。这些先前信息通过一种基于trasnformer的 Wasserstein Autoencoder提取于dataset中。然后，这种autoencoder用于提高初始lane图估计。这是通过对潜在空间向量进行优化来实现的，这种优化抑制了lane图估计与先前分布的偏离。我们对NuScenes和Argoverse两个标准数据集进行测试，结果表明，我们提posed方法与当前最佳方法相比，有 significan improvement。
</details></li>
</ul>
<hr>
<h2 id="Overcoming-Distribution-Mismatch-in-Quantizing-Image-Super-Resolution-Networks"><a href="#Overcoming-Distribution-Mismatch-in-Quantizing-Image-Super-Resolution-Networks" class="headerlink" title="Overcoming Distribution Mismatch in Quantizing Image Super-Resolution Networks"></a>Overcoming Distribution Mismatch in Quantizing Image Super-Resolution Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13337">http://arxiv.org/abs/2307.13337</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheeun Hong, Kyoung Mu Lee<br>for:* This paper aims to address the distribution mismatch problem in image super-resolution (SR) networks, which can lead to severe accuracy loss when using low-bit quantization.methods:* The proposed method, called ODM, uses a new quantization-aware training framework that regularizes the variance in features during training to reduce the distribution mismatch problem.* ODM also introduces distribution offsets to layers with a significant mismatch, which either scales or shifts channel-wise features.results:* ODM effectively outperforms existing SR quantization approaches with similar or fewer computations, demonstrating the importance of reducing the distribution mismatch problem.<details>
<summary>Abstract</summary>
Quantization is a promising approach to reduce the high computational complexity of image super-resolution (SR) networks. However, compared to high-level tasks like image classification, low-bit quantization leads to severe accuracy loss in SR networks. This is because feature distributions of SR networks are significantly divergent for each channel or input image, and is thus difficult to determine a quantization range. Existing SR quantization works approach this distribution mismatch problem by dynamically adapting quantization ranges to the variant distributions during test time. However, such dynamic adaptation incurs additional computational costs that limit the benefits of quantization. Instead, we propose a new quantization-aware training framework that effectively Overcomes the Distribution Mismatch problem in SR networks without the need for dynamic adaptation. Intuitively, the mismatch can be reduced by directly regularizing the variance in features during training. However, we observe that variance regularization can collide with the reconstruction loss during training and adversely impact SR accuracy. Thus, we avoid the conflict between two losses by regularizing the variance only when the gradients of variance regularization are cooperative with that of reconstruction. Additionally, to further reduce the distribution mismatch, we introduce distribution offsets to layers with a significant mismatch, which either scales or shifts channel-wise features. Our proposed algorithm, called ODM, effectively reduces the mismatch in distributions with minimal computational overhead. Experimental results show that ODM effectively outperforms existing SR quantization approaches with similar or fewer computations, demonstrating the importance of reducing the distribution mismatch problem. Our code is available at https://github.com/Cheeun/ODM.
</details>
<details>
<summary>摘要</summary>
量化是一种有前途的方法，可以降低图像超分辨率网络的计算复杂性。然而，相比高级任务如图像分类，低位数量化会导致SR网络的准确性丢失。这是因为SR网络的特征分布非常分散，难以确定量化范围。现有的SR量化方法会在测试时动态适应量化范围，以适应变化的特征分布。然而，这种动态适应带来额外的计算成本，限制了量化的优点。相反，我们提出了一个新的量化意识训练框架，可以有效地超越分布匹配问题。我们发现，可以在训练时直接规范特征变量，以减少分布匹配问题。然而，我们发现，变量规范可能会与重建损失冲突，影响SR准确性。因此，我们避免了这两个损失之间的冲突，通过在重建损失的梯度下规范变量。此外，为了进一步减少分布匹配问题，我们引入了分布偏移，以调整不同特征的分布。我们提出的ODM算法，可以有效地减少分布匹配问题，而且计算成本很低。实验结果表明，ODM可以有效地超越现有的SR量化方法，并且需要相同或更少的计算资源，这说明了分布匹配问题的重要性。我们的代码可以在https://github.com/Cheeun/ODM上获取。
</details></li>
</ul>
<hr>
<h2 id="Unmasking-Anomalies-in-Road-Scene-Segmentation"><a href="#Unmasking-Anomalies-in-Road-Scene-Segmentation" class="headerlink" title="Unmasking Anomalies in Road-Scene Segmentation"></a>Unmasking Anomalies in Road-Scene Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13316">http://arxiv.org/abs/2307.13316</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shyam671/Mask2Anomaly-Unmasking-Anomalies-in-Road-Scene-Segmentation">https://github.com/shyam671/Mask2Anomaly-Unmasking-Anomalies-in-Road-Scene-Segmentation</a></li>
<li>paper_authors: Shyam Nandan Rai, Fabio Cermelli, Dario Fontanel, Carlo Masone, Barbara Caputo</li>
<li>for: 这篇论文主要目标是提高道路Scene anomaly detection的精度。</li>
<li>methods: 该方法基于mask classification的思想，并包括全球封装注意力模块、mask contrastive learning和面精度提高等技术新特性。</li>
<li>results: 该方法在多个benchmark上达到了新的状态方法，特别是在每个像素和组件级别评估中减少了false positives率60%。<details>
<summary>Abstract</summary>
Anomaly segmentation is a critical task for driving applications, and it is approached traditionally as a per-pixel classification problem. However, reasoning individually about each pixel without considering their contextual semantics results in high uncertainty around the objects' boundaries and numerous false positives. We propose a paradigm change by shifting from a per-pixel classification to a mask classification. Our mask-based method, Mask2Anomaly, demonstrates the feasibility of integrating an anomaly detection method in a mask-classification architecture. Mask2Anomaly includes several technical novelties that are designed to improve the detection of anomalies in masks: i) a global masked attention module to focus individually on the foreground and background regions; ii) a mask contrastive learning that maximizes the margin between an anomaly and known classes; and iii) a mask refinement solution to reduce false positives. Mask2Anomaly achieves new state-of-the-art results across a range of benchmarks, both in the per-pixel and component-level evaluations. In particular, Mask2Anomaly reduces the average false positives rate by 60% wrt the previous state-of-the-art. Github page: https://github.com/shyam671/Mask2Anomaly-Unmasking-Anomalies-in-Road-Scene-Segmentation.
</details>
<details>
<summary>摘要</summary>
traditional driving application中的异常分割问题是一个关键任务，通常是以每个像素为单位进行分类的。然而，不考虑每个像素的语义上下文会导致对象边界的高度不确定性和多个假阳性。我们提议一种思路转变，即从每个像素分类转变为Mask分类。我们的Mask2异常方法在Mask分类架构中实现了异常检测方法的集成。Mask2异常包括了一些技术创新，用于改进异常检测在Mask中的精度：1. 全局掩码注意力模块，用于对前景和背景区域进行各自焦点处理。2. 掩码对比学习，以提高异常和已知类之间的边界差距。3. 掩码修正解决方案，以减少假阳性。Mask2异常实现了新的状态anner-of-the-art结果，并在像素级和组件级评估中都达到了新的高度。具体来说，Mask2异常相比前一个状态anner-of-the-art，减少了平均假阳性率60%。GitHub页面：https://github.com/shyam671/Mask2Anomaly-Unmasking-Anomalies-in-Road-Scene-Segmentation。
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Cross-client-GANs-based-Attack-in-Federated-Learning"><a href="#Mitigating-Cross-client-GANs-based-Attack-in-Federated-Learning" class="headerlink" title="Mitigating Cross-client GANs-based Attack in Federated Learning"></a>Mitigating Cross-client GANs-based Attack in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13314">http://arxiv.org/abs/2307.13314</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hong Huang, Xinyu Lei, Tao Xiang</li>
<li>For: The paper aims to improve the security of federated learning (FL) schemes by mitigating the cross-client generative adversarial networks (GANs) attack, which can reconstruct samples from other clients.* Methods: The paper proposes a technique called Federated Ensemble Data-free Knowledge Distillation (Fed-EDKD) to resist the C-GANs attack. Fed-EDKD involves each client submitting a local model to the server for obtaining an ensemble global model, and then using data-free knowledge distillation techniques to transfer knowledge from the ensemble global model to a compressed model.* Results: The experimental results demonstrate that Fed-EDKD significantly mitigates the C-GANs attack while only incurring a slight accuracy degradation of FL.Here are the three key points in Simplified Chinese text:* For: 该论文目标是提高联合学习（FL）方案的安全性，防止跨客户端生成对抗网络（GANs）攻击，该攻击可以从其他客户端中重建样本。* Methods: 该论文提出了联合集成数据自由知识传播技术（Fed-EDKD）来防止GANs攻击。Fed-EDKD方法是每个客户端将本地模型提交到服务器，从服务器获取ensemble全球模型，然后使用数据自由知识传播技术将ensemble全球模型中的知识传播到压缩模型。* Results: 实验结果表明，Fed-EDKD有效防止GANs攻击，同时仅带来FL的精度下降。<details>
<summary>Abstract</summary>
Machine learning makes multimedia data (e.g., images) more attractive, however, multimedia data is usually distributed and privacy sensitive. Multiple distributed multimedia clients can resort to federated learning (FL) to jointly learn a global shared model without requiring to share their private samples with any third-party entities. In this paper, we show that FL suffers from the cross-client generative adversarial networks (GANs)-based (C-GANs) attack, in which a malicious client (i.e., adversary) can reconstruct samples with the same distribution as the training samples from other clients (i.e., victims). Since a benign client's data can be leaked to the adversary, this attack brings the risk of local data leakage for clients in many security-critical FL applications. Thus, we propose Fed-EDKD (i.e., Federated Ensemble Data-free Knowledge Distillation) technique to improve the current popular FL schemes to resist C-GANs attack. In Fed-EDKD, each client submits a local model to the server for obtaining an ensemble global model. Then, to avoid model expansion, Fed-EDKD adopts data-free knowledge distillation techniques to transfer knowledge from the ensemble global model to a compressed model. By this way, Fed-EDKD reduces the adversary's control capability over the global model, so Fed-EDKD can effectively mitigate C-GANs attack. Finally, the experimental results demonstrate that Fed-EDKD significantly mitigates C-GANs attack while only incurring a slight accuracy degradation of FL.
</details>
<details>
<summary>摘要</summary>
机器学习使 multimedia 数据更加吸引人，然而 multimedia 数据通常是分布式并且敏感。多个分布式 multimedia 客户可以使用联邦学习（FL）来共同学习全局共享模型，而不需要将私人样本分享给任何第三方机构。在这篇论文中，我们表明了 FL 受到跨客户生成 adversarial networks（GANs） Attack，在这种攻击中，一个邪恶客户（即敌对者）可以从其他客户（即受害者）中重建样本的分布。由于benign客户的数据可以被敌对者泄露，这种攻击可能导致客户端的本地数据泄露。因此，我们提出了 Fed-EDKD（即联邦ensemble数据free知识distillation）技术，以提高当前流行的 FL 方案，抵御 C-GANs 攻击。在 Fed-EDKD 中，每个客户提交本地模型到服务器，以获取ensemble全局模型。然后，为了避免模型扩展，Fed-EDKD 采用数据free知识distillation技术，将知识从ensemble全局模型传递到压缩模型。通过这种方式，Fed-EDKD 降低了敌对者对全局模型的控制能力，因此可以有效抵御 C-GANs 攻击。最后，实验结果表明，Fed-EDKD 可以有效抵御 C-GANs 攻击，仅受到轻度的 FL 减少。
</details></li>
</ul>
<hr>
<h2 id="CT-Net-Arbitrary-Shaped-Text-Detection-via-Contour-Transformer"><a href="#CT-Net-Arbitrary-Shaped-Text-Detection-via-Contour-Transformer" class="headerlink" title="CT-Net: Arbitrary-Shaped Text Detection via Contour Transformer"></a>CT-Net: Arbitrary-Shaped Text Detection via Contour Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13310">http://arxiv.org/abs/2307.13310</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiwen Shao, Yuchen Su, Yong Zhou, Fanrong Meng, Hancheng Zhu, Bing Liu, Rui Yao</li>
<li>for: 提出一种基于Contour Transformer的自然语言场景文本检测方法，以提高文本检测精度和效率。</li>
<li>methods: 使用Contour Initialization Module生成初始文本轮廓，并采用Contour Refinement Module进行反复调整文本轮廓，以 capture contextual information和进行进度性轮廓变换。还采用Adaptive Training Strategy和Re-score Mechanism等技术来提高模型的性能。</li>
<li>results: 经过EXTensive experiments on four challenging datasets，CT-Net表现出了较高的准确率和效率，比如CT-Net在CTW1500和Total-Text datasets上的F-measure分别达到了86.1和87.8。<details>
<summary>Abstract</summary>
Contour based scene text detection methods have rapidly developed recently, but still suffer from inaccurate frontend contour initialization, multi-stage error accumulation, or deficient local information aggregation. To tackle these limitations, we propose a novel arbitrary-shaped scene text detection framework named CT-Net by progressive contour regression with contour transformers. Specifically, we first employ a contour initialization module that generates coarse text contours without any post-processing. Then, we adopt contour refinement modules to adaptively refine text contours in an iterative manner, which are beneficial for context information capturing and progressive global contour deformation. Besides, we propose an adaptive training strategy to enable the contour transformers to learn more potential deformation paths, and introduce a re-score mechanism that can effectively suppress false positives. Extensive experiments are conducted on four challenging datasets, which demonstrate the accuracy and efficiency of our CT-Net over state-of-the-art methods. Particularly, CT-Net achieves F-measure of 86.1 at 11.2 frames per second (FPS) and F-measure of 87.8 at 10.1 FPS for CTW1500 and Total-Text datasets, respectively.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>>近期，基于 kontour 的Scene文本检测方法有很大的发展，但仍然受到初始 kontour 的不准确、多Stage 的错误积累以及地方信息的不足等限制。为了解决这些局限性，我们提出了一种新的arbitrary-shaped Scene文本检测框架，即CT-Net，通过进行进度ive contour regression with contour transformers。具体来说，我们首先采用一种contour initialization module，该模块可以生成不需要任何后处理的粗糙文本 kontour。然后，我们采用 contour refinement module，该模块可以在循环方式下进行文本 kontour 的细化，以捕捉更多的上下文信息并进行进度ive global kontour 的变换。此外，我们还提出了一种适应性训练策略，使得 kontour transformers 可以学习更多的可能的变换路径，并引入了一种重新分配机制，可以有效地降低假阳性。我们在四个挑战性 datasets 上进行了广泛的实验，结果表明 CT-Net 的准确率和效率比现有方法高。特别是，CT-Net 在 CTW1500 和 Total-Text  datasets 上 achieved F-measure of 86.1 at 11.2 frames per second (FPS) and F-measure of 87.8 at 10.1 FPS, respectively.
</details></li>
</ul>
<hr>
<h2 id="Mini-PointNetPlus-a-local-feature-descriptor-in-deep-learning-model-for-3d-environment-perception"><a href="#Mini-PointNetPlus-a-local-feature-descriptor-in-deep-learning-model-for-3d-environment-perception" class="headerlink" title="Mini-PointNetPlus: a local feature descriptor in deep learning model for 3d environment perception"></a>Mini-PointNetPlus: a local feature descriptor in deep learning model for 3d environment perception</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13300">http://arxiv.org/abs/2307.13300</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chuanyu Luo, Nuo Cheng, Sikun Ma, Jun Xiang, Xiaohan Li, Shengguang Lei, Pu Li</li>
<li>for: The paper is written for improving the performance of deep learning models for 3D environment perception, specifically by proposing a novel local feature descriptor called mini-PointNetPlus.</li>
<li>methods: The paper uses pillarization&#x2F;voxelization methods to convert point cloud data into pillars&#x2F;voxels, and then applies a 2D&#x2F;3D convolutional neural network (CNN) to process the data. The proposed descriptor, mini-PointNetPlus, separately projects the data points to individual features, leading to a permutation invariant and fully utilizing the features.</li>
<li>results: The proposed descriptor demonstrates a considerable performance improvement for 3D perception compared to the pioneer work PointNet, as proven in experiments.<details>
<summary>Abstract</summary>
Common deep learning models for 3D environment perception often use pillarization/voxelization methods to convert point cloud data into pillars/voxels and then process it with a 2D/3D convolutional neural network (CNN). The pioneer work PointNet has been widely applied as a local feature descriptor, a fundamental component in deep learning models for 3D perception, to extract features of a point cloud. This is achieved by using a symmetric max-pooling operator which provides unique pillar/voxel features. However, by ignoring most of the points, the max-pooling operator causes an information loss, which reduces the model performance. To address this issue, we propose a novel local feature descriptor, mini-PointNetPlus, as an alternative for plug-and-play to PointNet. Our basic idea is to separately project the data points to the individual features considered, each leading to a permutation invariant. Thus, the proposed descriptor transforms an unordered point cloud to a stable order. The vanilla PointNet is proved to be a special case of our mini-PointNetPlus. Due to fully utilizing the features by the proposed descriptor, we demonstrate in experiment a considerable performance improvement for 3D perception.
</details>
<details>
<summary>摘要</summary>
常用的深度学习模型 для 3D 环境识别常使用柱化/体积化方法将点云数据转换为柱/体积，然后使用 2D/3D 卷积神经网络（CNN）进行处理。点云网络（PointNet）是深度学习模型中的一个开创性的工作，广泛应用于当地特征描述器，用于提取点云特征。这是通过使用对称的最大汇聚操作来实现的，该操作提供了唯一的柱/体积特征。然而，由于忽略大多数点，最大汇聚操作会导致信息损失，从而降低模型性能。为解决这个问题，我们提出了一种新的本地特征描述器，mini-PointNetPlus，作为PointNet的替换。我们的基本想法是分别将数据点 proyect 到各自的特征上，每个特征带来一种排序不变的变换。因此，我们的描述器将无序点云转换为稳定的排序。vanilla PointNet 被证明是 mini-PointNetPlus 的特殊情况。由于完全利用特征，我们在实验中证明了使用我们的描述器可以获得3D 识别的显著性能提升。
</details></li>
</ul>
<hr>
<h2 id="High-Resolution-Volumetric-Reconstruction-for-Clothed-Humans"><a href="#High-Resolution-Volumetric-Reconstruction-for-Clothed-Humans" class="headerlink" title="High-Resolution Volumetric Reconstruction for Clothed Humans"></a>High-Resolution Volumetric Reconstruction for Clothed Humans</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13282">http://arxiv.org/abs/2307.13282</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sicong Tang, Guangyuan Wang, Qing Ran, Lingzhi Li, Li Shen, Ping Tan</li>
<li>for: 重建人体形象 from 少量RGB图像</li>
<li>methods: 使用volume representation，3D convolution，coarse-to-fine strategy，voxel culling，subspace sparse convolution</li>
<li>results: 比state-of-the-art方法减少mean point-to-surface（P2S）精度 more than 50%，实现约2mm的准确性，并且图像从我们的文本模型中得到更高的PSNR值<details>
<summary>Abstract</summary>
We present a novel method for reconstructing clothed humans from a sparse set of, e.g., 1 to 6 RGB images. Despite impressive results from recent works employing deep implicit representation, we revisit the volumetric approach and demonstrate that better performance can be achieved with proper system design. The volumetric representation offers significant advantages in leveraging 3D spatial context through 3D convolutions, and the notorious quantization error is largely negligible with a reasonably large yet affordable volume resolution, e.g., 512. To handle memory and computation costs, we propose a sophisticated coarse-to-fine strategy with voxel culling and subspace sparse convolution. Our method starts with a discretized visual hull to compute a coarse shape and then focuses on a narrow band nearby the coarse shape for refinement. Once the shape is reconstructed, we adopt an image-based rendering approach, which computes the colors of surface points by blending input images with learned weights. Extensive experimental results show that our method significantly reduces the mean point-to-surface (P2S) precision of state-of-the-art methods by more than 50% to achieve approximately 2mm accuracy with a 512 volume resolution. Additionally, images rendered from our textured model achieve a higher peak signal-to-noise ratio (PSNR) compared to state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法，用于从稀疏的RGB图像集（例如1-6张）中重建披露人体。尽管最近的研究已经取得了很好的成果，我们还是返回到了Volume representation的方法，并证明了更好的性能可以通过合适的系统设计实现。Volume representation具有利用3D空间上下文的3D卷积的优势，而且量化误差在合理的卷积分辨率（例如512）下是极其忽略不起的。为了处理内存和计算成本，我们提议了一种复杂的粗化-细化策略，包括voxel culling和子空间稀疏卷积。我们的方法首先使用离散的视觉封顶来计算粗略的形状，然后将注意力集中在粗略形状附近进行细化。一旦形状重建完成，我们采用了基于图像的渲染方法，该方法通过权重混合输入图像来计算表面点的颜色。我们的实验结果表明，我们的方法可以在512卷积分辨率下将平均点到表面精度（P2S）降低至少于50%，并且图像从我们的纹理模型中获得的PSNR值高于状态艺术方法。
</details></li>
</ul>
<hr>
<h2 id="GaitFormer-Revisiting-Intrinsic-Periodicity-for-Gait-Recognition"><a href="#GaitFormer-Revisiting-Intrinsic-Periodicity-for-Gait-Recognition" class="headerlink" title="GaitFormer: Revisiting Intrinsic Periodicity for Gait Recognition"></a>GaitFormer: Revisiting Intrinsic Periodicity for Gait Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13259">http://arxiv.org/abs/2307.13259</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qian Wu, Ruixuan Xiao, Kaixin Xu, Jingcheng Ni, Boxun Li, Ziyao Xu</li>
<li>for: 本研究旨在提高人体步态识别精度，通过分析视频水平人体阴影，而不是仅仅依靠外观信息。</li>
<li>methods: 本研究提出了一种插件化策略，名为时间周期对齐策略（TPA），该策略利用人体步态序列中的周期性和细致的时间相关性，以提高识别性能。TPA策略包括两个关键组件：一是适应 Fourier-transform位编码（AFPE），该组件可适应地将特征和整数时钟信号转换为敏感于周期步态的嵌入。二是时间聚合模块（TAM），该组件可分解嵌入为趋势和季节性组分，并提取有用的时间相关性，以识别主要组分，而排除杂音噪声。</li>
<li>results: 我们基于TPA策略提出了一种简单有效的基eline方法，并在三个常用的公共数据集（CASIA-B、OU-MVLP、GREW）上进行了广泛的实验。结果表明，我们的提议方法在多个benchmark测试中达到了当前最佳性能。<details>
<summary>Abstract</summary>
Gait recognition aims to distinguish different walking patterns by analyzing video-level human silhouettes, rather than relying on appearance information. Previous research on gait recognition has primarily focused on extracting local or global spatial-temporal representations, while overlooking the intrinsic periodic features of gait sequences, which, when fully utilized, can significantly enhance performance. In this work, we propose a plug-and-play strategy, called Temporal Periodic Alignment (TPA), which leverages the periodic nature and fine-grained temporal dependencies of gait patterns. The TPA strategy comprises two key components. The first component is Adaptive Fourier-transform Position Encoding (AFPE), which adaptively converts features and discrete-time signals into embeddings that are sensitive to periodic walking patterns. The second component is the Temporal Aggregation Module (TAM), which separates embeddings into trend and seasonal components, and extracts meaningful temporal correlations to identify primary components, while filtering out random noise. We present a simple and effective baseline method for gait recognition, based on the TPA strategy. Extensive experiments conducted on three popular public datasets (CASIA-B, OU-MVLP, and GREW) demonstrate that our proposed method achieves state-of-the-art performance on multiple benchmark tests.
</details>
<details>
<summary>摘要</summary>
走姿识别目标是通过分析视频级别的人体擦抹图来分辨不同的步态模式，而不是仅仅依靠外观信息。过去的研究中，大多数关于走姿识别的研究都是提取局部或全局的时空特征，而忽略了走姿序列中的自然 périodic 特征，这些特征可以在完全利用时，可以帮助提高性能。在这种工作中，我们提出了一种插件式策略，即时间周期对齐策略（TPA），该策略利用走姿序列中的自然时间周期特征，以及步态模式中的细致时间相关性，从而增强识别性。TPA策略包括两个关键组件。首先是适应 Fourier 变换位置编码（AFPE），该组件可以将特征和离散时间信号转换成敏感于走姿序列时间周期特征的嵌入。其次是时间聚合模块（TAM），该模块可以将嵌入分解成趋势和季节性组件，并提取有用的时间相关性，以识别主要组件，同时滤除随机噪声。我们提出了一种简单而有效的基线方法，基于 TPA 策略，并在三个流行的公共数据集（CASIA-B、OU-MVLP 和 GREW）上进行了广泛的实验，结果表明，我们的提出的方法在多个benchmark测试中达到了当前领域的状态的最佳性能。
</details></li>
</ul>
<hr>
<h2 id="Conditional-Cross-Attention-Network-for-Multi-Space-Embedding-without-Entanglement-in-Only-a-SINGLE-Network"><a href="#Conditional-Cross-Attention-Network-for-Multi-Space-Embedding-without-Entanglement-in-Only-a-SINGLE-Network" class="headerlink" title="Conditional Cross Attention Network for Multi-Space Embedding without Entanglement in Only a SINGLE Network"></a>Conditional Cross Attention Network for Multi-Space Embedding without Entanglement in Only a SINGLE Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13254">http://arxiv.org/abs/2307.13254</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chull Hwan Song, Taebaek Hwang, Jooyoung Yoon, Shunghyun Choi, Yeong Hyeon Gu</li>
<li>for: 这个研究的目的是创建一个高效的单一标签物预测模型，以应对实际情况中的多个具体特征（如形状、颜色、长度等）。</li>
<li>methods: 我们提出了一个名为 Conditional Cross-Attention Network 的方法，它可以将多个具体特征转换为分开的多个空间表示，只需一个基础模型。我们使用了交叉注意机制来融合和转换条件（具体特征）的信息。</li>
<li>results: 我们的方法在多个标准 benchmark dataset上取得了稳定的state-of-the-art表现，包括 FashionAI、DARN、DeepFashion 和 Zappos50K。与之前的方法不同，我们的方法不受 benchmark dataset 的影响，表现一直优良。<details>
<summary>Abstract</summary>
Many studies in vision tasks have aimed to create effective embedding spaces for single-label object prediction within an image. However, in reality, most objects possess multiple specific attributes, such as shape, color, and length, with each attribute composed of various classes. To apply models in real-world scenarios, it is essential to be able to distinguish between the granular components of an object. Conventional approaches to embedding multiple specific attributes into a single network often result in entanglement, where fine-grained features of each attribute cannot be identified separately. To address this problem, we propose a Conditional Cross-Attention Network that induces disentangled multi-space embeddings for various specific attributes with only a single backbone. Firstly, we employ a cross-attention mechanism to fuse and switch the information of conditions (specific attributes), and we demonstrate its effectiveness through a diverse visualization example. Secondly, we leverage the vision transformer for the first time to a fine-grained image retrieval task and present a simple yet effective framework compared to existing methods. Unlike previous studies where performance varied depending on the benchmark dataset, our proposed method achieved consistent state-of-the-art performance on the FashionAI, DARN, DeepFashion, and Zappos50K benchmark datasets.
</details>
<details>
<summary>摘要</summary>
很多研究在视觉任务中尝试创建有效的嵌入空间，以便在图像中预测单个对象。然而，在实际情况下，大多数对象具有多个特定属性，如形状、颜色和长度，每个属性包含多个类。要将模型应用到实际场景中，需要能够分别识别对象的细腻特征。传统的嵌入多个特定属性到单个网络中的方法经常导致杂化，无法分别识别每个属性的细腻特征。为解决这个问题，我们提议一个名为Conditional Cross-Attention Network的方法，它可以生成独立的多个空间嵌入，用于不同的特定属性。首先，我们使用交叉注意机制将条件（特定属性）的信息融合和转换。我们通过多种视觉化示例展示了其效果。其次，我们是第一次应用视Transformer于细化图像检索任务，并提出了一个简单而有效的框架，与现有方法相比。与过去的研究不同，我们的提议方法在FashionAI、DARN、DeepFashion和Zappos50K benchmark dataset上实现了一致的状态空间性表现。
</details></li>
</ul>
<hr>
<h2 id="Keyword-Aware-Relative-Spatio-Temporal-Graph-Networks-for-Video-Question-Answering"><a href="#Keyword-Aware-Relative-Spatio-Temporal-Graph-Networks-for-Video-Question-Answering" class="headerlink" title="Keyword-Aware Relative Spatio-Temporal Graph Networks for Video Question Answering"></a>Keyword-Aware Relative Spatio-Temporal Graph Networks for Video Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13250">http://arxiv.org/abs/2307.13250</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Cheng, Hehe Fan, Dongyun Lin, Ying Sun, Mohan Kankanhalli, Joo-Hwee Lim</li>
<li>for: 提高视频问答（VideoQA）中的复杂空间和时间关系捕捉和理解，以及使用关键词更好地捕捉问题特点。</li>
<li>methods: 提出了一种关键词意识Relative Spatio-Temporal（KRST）图网络，包括使用注意力机制将关键词纳入问题编码，以及将关键词意识导入视频图构建。同时，通过 integrating relative relation modeling来更好地捕捉视频中对象之间的空间和时间关系。</li>
<li>results: 在TGIF-QA、MSVD-QA和MSRVTT-QA等多个数据集上进行了广泛的实验，证明了KRST的超过多种状态艺术方法的优越性。<details>
<summary>Abstract</summary>
The main challenge in video question answering (VideoQA) is to capture and understand the complex spatial and temporal relations between objects based on given questions. Existing graph-based methods for VideoQA usually ignore keywords in questions and employ a simple graph to aggregate features without considering relative relations between objects, which may lead to inferior performance. In this paper, we propose a Keyword-aware Relative Spatio-Temporal (KRST) graph network for VideoQA. First, to make question features aware of keywords, we employ an attention mechanism to assign high weights to keywords during question encoding. The keyword-aware question features are then used to guide video graph construction. Second, because relations are relative, we integrate the relative relation modeling to better capture the spatio-temporal dynamics among object nodes. Moreover, we disentangle the spatio-temporal reasoning into an object-level spatial graph and a frame-level temporal graph, which reduces the impact of spatial and temporal relation reasoning on each other. Extensive experiments on the TGIF-QA, MSVD-QA and MSRVTT-QA datasets demonstrate the superiority of our KRST over multiple state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
主要挑战在视频问答（VideoQA）是捕捉和理解问题中的复杂空间和时间关系。现有的图学方法通常忽略问题中的关键词并使用简单的图来汇聚特征，这可能会导致性能下降。在这篇论文中，我们提出了关键词意识的相对空间时间（KRST）图网络来解决这个问题。首先，为了让问题特征意识到关键词，我们使用注意力机制来在问题编码中分配高权重到关键词。关键词意识的问题特征然后用来导引视频图建构。其次，因为关系是相对的，我们将相对关系模型纳入更好地捕捉视频中对象节点之间的空间时间动态。此外，我们将空间时间理解分解成对象级别的空间图和帧级别的时间图，这会减少空间和时间关系的相互影响。我们在TGIF-QA、MSVD-QA和MSRVTT-QA datasets上进行了广泛的实验，并证明了我们的KRST方法在多个现状顶峰方法之上。
</details></li>
</ul>
<hr>
<h2 id="Multi-Granularity-Prediction-with-Learnable-Fusion-for-Scene-Text-Recognition"><a href="#Multi-Granularity-Prediction-with-Learnable-Fusion-for-Scene-Text-Recognition" class="headerlink" title="Multi-Granularity Prediction with Learnable Fusion for Scene Text Recognition"></a>Multi-Granularity Prediction with Learnable Fusion for Scene Text Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13244">http://arxiv.org/abs/2307.13244</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alibabaresearch/advancedliteratemachinery">https://github.com/alibabaresearch/advancedliteratemachinery</a></li>
<li>paper_authors: Cheng Da, Peng Wang, Cong Yao</li>
<li>For: The paper is written for scene text recognition (STR), which is an active research topic in computer vision. The authors aim to tackle the challenging problem of STR by incorporating linguistic knowledge into the model.* Methods: The authors use a vision STR model built upon the Vision Transformer (ViT) and a tailored Adaptive Addressing and Aggregation (A$^3$) module. They also propose a Multi-Granularity Prediction strategy to inject information from the language modality into the model, using subword representations (BPE and WordPiece) in addition to the conventional character level representation.* Results: The proposed MGP-STR algorithm achieves an average recognition accuracy of 94% on standard benchmarks for scene text recognition, and also achieves state-of-the-art results on widely-used handwritten benchmarks and more challenging scene text datasets.Here are the three key points in Simplified Chinese text:* For: 这篇论文是为了Scene Text Recognition（STR）做出一种新的方法。* Methods: 作者使用了基于Vision Transformer（ViT）的视觉STR模型，并提出了一种适应性地址和聚合（A$^3$)模块。另外，他们还提出了一种多级预测策略，以在模型中注入语言特征。* Results: 提案的MGP-STR算法可以在标准的STR测试集上达到94%的识别率，同时在手写测试集和更加具有挑战性的Scene Text测试集上也达到了状态之最的结果。<details>
<summary>Abstract</summary>
Due to the enormous technical challenges and wide range of applications, scene text recognition (STR) has been an active research topic in computer vision for years. To tackle this tough problem, numerous innovative methods have been successively proposed, and incorporating linguistic knowledge into STR models has recently become a prominent trend. In this work, we first draw inspiration from the recent progress in Vision Transformer (ViT) to construct a conceptually simple yet functionally powerful vision STR model, which is built upon ViT and a tailored Adaptive Addressing and Aggregation (A$^3$) module. It already outperforms most previous state-of-the-art models for scene text recognition, including both pure vision models and language-augmented methods. To integrate linguistic knowledge, we further propose a Multi-Granularity Prediction strategy to inject information from the language modality into the model in an implicit way, \ie, subword representations (BPE and WordPiece) widely used in NLP are introduced into the output space, in addition to the conventional character level representation, while no independent language model (LM) is adopted. To produce the final recognition results, two strategies for effectively fusing the multi-granularity predictions are devised. The resultant algorithm (termed MGP-STR) is able to push the performance envelope of STR to an even higher level. Specifically, MGP-STR achieves an average recognition accuracy of $94\%$ on standard benchmarks for scene text recognition. Moreover, it also achieves state-of-the-art results on widely-used handwritten benchmarks as well as more challenging scene text datasets, demonstrating the generality of the proposed MGP-STR algorithm. The source code and models will be available at: \url{https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/MGP-STR}.
</details>
<details>
<summary>摘要</summary>
due to the enormous technical challenges and wide range of applications, scene text recognition (STR) has been an active research topic in computer vision for years. to tackle this tough problem, numerous innovative methods have been successively proposed, and incorporating linguistic knowledge into STR models has recently become a prominent trend. in this work, we first draw inspiration from the recent progress in Vision Transformer (ViT) to construct a conceptually simple yet functionally powerful vision STR model, which is built upon ViT and a tailored Adaptive Addressing and Aggregation (A$^3$) module. it already outperforms most previous state-of-the-art models for scene text recognition, including both pure vision models and language-augmented methods. to integrate linguistic knowledge, we further propose a Multi-Granularity Prediction strategy to inject information from the language modality into the model in an implicit way, 例如，使用字符级别表示和wordpiece的subword表示，while no independent language model (LM) is adopted. to produce the final recognition results, two strategies for effectively fusing the multi-granularity predictions are devised. the resultant algorithm (termed MGP-STR) is able to push the performance envelope of STR to an even higher level. specifically, MGP-STR achieves an average recognition accuracy of 94% on standard benchmarks for scene text recognition. moreover, it also achieves state-of-the-art results on widely-used handwritten benchmarks as well as more challenging scene text datasets, demonstrating the generality of the proposed MGP-STR algorithm. the source code and models will be available at: https://github.com/AlibabaResearch/AdvancedLiterateMachinery/tree/main/OCR/MGP-STR。
</details></li>
</ul>
<hr>
<h2 id="Fashion-Matrix-Editing-Photos-by-Just-Talking"><a href="#Fashion-Matrix-Editing-Photos-by-Just-Talking" class="headerlink" title="Fashion Matrix: Editing Photos by Just Talking"></a>Fashion Matrix: Editing Photos by Just Talking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13240">http://arxiv.org/abs/2307.13240</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zheng-chong/fashionmatric">https://github.com/zheng-chong/fashionmatric</a></li>
<li>paper_authors: Zheng Chong, Xujie Zhang, Fuwei Zhao, Zhenyu Xie, Xiaodan Liang</li>
<li>for: 这个论文旨在探讨如何使用大型自然语言模型（LLM）来构建智能系统，以便在时尚领域内进行图像编辑。</li>
<li>methods: 该论文提出了一种层次结构的AI系统，名为时尚矩阵（Fashion Matrix），可以通过语音指令来编辑图像。这个系统使用LLM作为基础支持，并在用户的指令下进行迭代交互。具体来说，该系统使用了多种Semantic Segmentation Models（如Grounded-SAM、MattingAnything等）来定义特定的编辑面罩，然后使用Visual Foundation Models（如Stable Diffusion、ControlNet等）来从文本提示和面罩中生成编辑后的图像。</li>
<li>results: 实验表明，Fashion Matrix可以充分发挥大型自然语言模型在时尚编辑领域的合作潜力。<details>
<summary>Abstract</summary>
The utilization of Large Language Models (LLMs) for the construction of AI systems has garnered significant attention across diverse fields. The extension of LLMs to the domain of fashion holds substantial commercial potential but also inherent challenges due to the intricate semantic interactions in fashion-related generation. To address this issue, we developed a hierarchical AI system called Fashion Matrix dedicated to editing photos by just talking. This system facilitates diverse prompt-driven tasks, encompassing garment or accessory replacement, recoloring, addition, and removal. Specifically, Fashion Matrix employs LLM as its foundational support and engages in iterative interactions with users. It employs a range of Semantic Segmentation Models (e.g., Grounded-SAM, MattingAnything, etc.) to delineate the specific editing masks based on user instructions. Subsequently, Visual Foundation Models (e.g., Stable Diffusion, ControlNet, etc.) are leveraged to generate edited images from text prompts and masks, thereby facilitating the automation of fashion editing processes. Experiments demonstrate the outstanding ability of Fashion Matrix to explores the collaborative potential of functionally diverse pre-trained models in the domain of fashion editing.
</details>
<details>
<summary>摘要</summary>
utilization of Large Language Models (LLMs) for the construction of AI systems has garnered significant attention across diverse fields. The extension of LLMs to the domain of fashion holds substantial commercial potential but also inherent challenges due to the intricate semantic interactions in fashion-related generation. To address this issue, we developed a hierarchical AI system called Fashion Matrix dedicated to editing photos by just talking. This system facilitates diverse prompt-driven tasks, encompassing garment or accessory replacement, recoloring, addition, and removal. Specifically, Fashion Matrix employs LLM as its foundational support and engages in iterative interactions with users. It employs a range of Semantic Segmentation Models (e.g., Grounded-SAM, MattingAnything, etc.) to delineate the specific editing masks based on user instructions. Subsequently, Visual Foundation Models (e.g., Stable Diffusion, ControlNet, etc.) are leveraged to generate edited images from text prompts and masks, thereby facilitating the automation of fashion editing processes. Experiments demonstrate the outstanding ability of Fashion Matrix to explore the collaborative potential of functionally diverse pre-trained models in the domain of fashion editing.
</details></li>
</ul>
<hr>
<h2 id="Audio-aware-Query-enhanced-Transformer-for-Audio-Visual-Segmentation"><a href="#Audio-aware-Query-enhanced-Transformer-for-Audio-Visual-Segmentation" class="headerlink" title="Audio-aware Query-enhanced Transformer for Audio-Visual Segmentation"></a>Audio-aware Query-enhanced Transformer for Audio-Visual Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13236">http://arxiv.org/abs/2307.13236</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinxiang Liu, Chen Ju, Chaofan Ma, Yanfeng Wang, Yu Wang, Ya Zhang</li>
<li>for: Audio-visual segmentation (AVS) task, specifically to segment sounding objects in video frames using audio cues.</li>
<li>methods: Introduces a multimodal transformer architecture that enables deep fusion and aggregation of audio-visual features, as well as an audio-aware query-enhanced transformer decoder that explicitly focuses on the segmentation of pinpointed sounding objects based on audio signals.</li>
<li>results: Outperforms previous methods and demonstrates better generalization ability in multi-sound and open-set scenarios.<details>
<summary>Abstract</summary>
The goal of the audio-visual segmentation (AVS) task is to segment the sounding objects in the video frames using audio cues. However, current fusion-based methods have the performance limitations due to the small receptive field of convolution and inadequate fusion of audio-visual features. To overcome these issues, we propose a novel \textbf{Au}dio-aware query-enhanced \textbf{TR}ansformer (AuTR) to tackle the task. Unlike existing methods, our approach introduces a multimodal transformer architecture that enables deep fusion and aggregation of audio-visual features. Furthermore, we devise an audio-aware query-enhanced transformer decoder that explicitly helps the model focus on the segmentation of the pinpointed sounding objects based on audio signals, while disregarding silent yet salient objects. Experimental results show that our method outperforms previous methods and demonstrates better generalization ability in multi-sound and open-set scenarios.
</details>
<details>
<summary>摘要</summary>
目的是对视频帧中的听起来对象进行分割，使用听音信号作为cue。然而，现有的融合方法受到小感知区域和不足的听视特征融合的限制。为了解决这些问题，我们提出了一种新的听音意识 Query-强化 transformer（AuTR）方法。与现有方法不同，我们的方法引入了多Modal transformer架构，允许深度融合和听视特征的积累。此外，我们开发了一种听音意识Query-强化 transformer解码器，具体地帮助模型根据听音信号进行对象分割，而忽略无声却突出的对象。实验结果表明，我们的方法在多音和开放集成enario中表现出色，并且在多音和开放集成enario中具有更好的泛化能力。
</details></li>
</ul>
<hr>
<h2 id="Strivec-Sparse-Tri-Vector-Radiance-Fields"><a href="#Strivec-Sparse-Tri-Vector-Radiance-Fields" class="headerlink" title="Strivec: Sparse Tri-Vector Radiance Fields"></a>Strivec: Sparse Tri-Vector Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13226">http://arxiv.org/abs/2307.13226</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zerg-overmind/strivec">https://github.com/zerg-overmind/strivec</a></li>
<li>paper_authors: Quankai Gao, Qiangeng Xu, Hao Su, Ulrich Neumann, Zexiang Xu</li>
<li>for: 该文章旨在提出一种新的神经表示方法，用于模型3D场景为辐射场的local tensor feature网格。</li>
<li>methods: 该方法利用tensor decomposition， builds upon recent work TensoRF，并使用cloud of local tensors和classic CANDECOMP&#x2F;PARAFAC（CP）归一化来分解每个tensor成三个向量，表示本地特征分布 along spatial axes，并压缩表示本地神经场的compact neural field。</li>
<li>results: 该方法可以实现更好的渲染质量，使用相对较少的参数，比如TensoRF和Instant-NGP。<details>
<summary>Abstract</summary>
We propose Strivec, a novel neural representation that models a 3D scene as a radiance field with sparsely distributed and compactly factorized local tensor feature grids. Our approach leverages tensor decomposition, following the recent work TensoRF, to model the tensor grids. In contrast to TensoRF which uses a global tensor and focuses on their vector-matrix decomposition, we propose to utilize a cloud of local tensors and apply the classic CANDECOMP/PARAFAC (CP) decomposition to factorize each tensor into triple vectors that express local feature distributions along spatial axes and compactly encode a local neural field. We also apply multi-scale tensor grids to discover the geometry and appearance commonalities and exploit spatial coherence with the tri-vector factorization at multiple local scales. The final radiance field properties are regressed by aggregating neural features from multiple local tensors across all scales. Our tri-vector tensors are sparsely distributed around the actual scene surface, discovered by a fast coarse reconstruction, leveraging the sparsity of a 3D scene. We demonstrate that our model can achieve better rendering quality while using significantly fewer parameters than previous methods, including TensoRF and Instant-NGP.
</details>
<details>
<summary>摘要</summary>
我们提出了Strivec，一种新的神经表示方法，它将三维场景视为一个辐射场，并使用稀疏分布的本地维度特征网格来模型。我们的方法利用了矩阵分解，建立在最近的TensoRF工作之上，通过对每个矩阵进行类似于CP分解（CANDECOMP/PARAFAC），将每个矩阵分解成三个向量，表示地方特征分布在空间轴上，并压缩地表示当地神经场。我们还使用多尺度矩阵网格来探索场景的几何和外观共同点，并利用多个本地尺度的空间同步来提高渲染质量。最终，我们通过将多个本地矩阵的神经特征进行汇聚来预测场景的辐射场性质。我们的三向量矩阵在实际场景表面上稀疏分布，通过快速粗略重建来发现。我们示示了我们的模型可以在使用更少参数的情况下达到更好的渲染质量，比之前的方法，包括TensoRF和Instant-NGP。
</details></li>
</ul>
<hr>
<h2 id="Image-Segmentation-Keras-Implementation-of-Segnet-FCN-UNet-PSPNet-and-other-models-in-Keras"><a href="#Image-Segmentation-Keras-Implementation-of-Segnet-FCN-UNet-PSPNet-and-other-models-in-Keras" class="headerlink" title="Image Segmentation Keras : Implementation of Segnet, FCN, UNet, PSPNet and other models in Keras"></a>Image Segmentation Keras : Implementation of Segnet, FCN, UNet, PSPNet and other models in Keras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13215">http://arxiv.org/abs/2307.13215</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/divamgupta/image-segmentation-keras">https://github.com/divamgupta/image-segmentation-keras</a></li>
<li>paper_authors: Divam Gupta</li>
<li>for: 本文提供了一个全面的 semantic segmentation 库，包含多种流行的 segmentation 模型，如 SegNet、FCN、UNet 和 PSPNet。</li>
<li>methods: 本文提供了多种 segmentation 模型的实现，并对其进行了评估和比较，为研究人员和实践者提供了一套强大的工具集，用于解决多种分类挑战。</li>
<li>results: 本文对多个数据集进行了评估和比较，以便为研究人员和实践者提供参考结果，帮助他们更好地选择合适的 segmentation 模型。<details>
<summary>Abstract</summary>
Semantic segmentation plays a vital role in computer vision tasks, enabling precise pixel-level understanding of images. In this paper, we present a comprehensive library for semantic segmentation, which contains implementations of popular segmentation models like SegNet, FCN, UNet, and PSPNet. We also evaluate and compare these models on several datasets, offering researchers and practitioners a powerful toolset for tackling diverse segmentation challenges.
</details>
<details>
<summary>摘要</summary>
semantic segmentation 在计算机视觉任务中扮演着重要的角色，允许精确地理解图像的每个像素。在这篇论文中，我们提供了一个全面的Semantic Segmentation库，包括流行的 segmentation 模型如 SegNet、FCN、UNet 和 PSPNet。我们还对这些模型在多个数据集上进行了评估和比较，为研究人员和实践者提供了一套强大的工具集，用于解决多样化的 segmentation 挑战。
</details></li>
</ul>
<hr>
<h2 id="GeoTransformer-Fast-and-Robust-Point-Cloud-Registration-with-Geometric-Transformer"><a href="#GeoTransformer-Fast-and-Robust-Point-Cloud-Registration-with-Geometric-Transformer" class="headerlink" title="GeoTransformer: Fast and Robust Point Cloud Registration with Geometric Transformer"></a>GeoTransformer: Fast and Robust Point Cloud Registration with Geometric Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03768">http://arxiv.org/abs/2308.03768</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qinzheng93/geotransformer">https://github.com/qinzheng93/geotransformer</a></li>
<li>paper_authors: Zheng Qin, Hao Yu, Changjian Wang, Yulan Guo, Yuxing Peng, Slobodan Ilic, Dewen Hu, Kai Xu</li>
<li>for: 本文targets the problem of point cloud registration, specifically focusing on accurate correspondence extraction without relying on keypoints.</li>
<li>methods: 方法基于Geometric Transformer（GeoTransformer），利用对超点的匹配来学习 геометрических特征，使匹配方法具有对静止变换的抗干扰和低 overlap场景中的稳定性。</li>
<li>results: 实验结果表明，GeoTransformer可以达到高精度匹配，无需进行RANSAC，从而提高了匹配精度和注册精度。特别是在3DLoMatch benchmark上，我们的方法提高了匹配率18%到31%和注册精度7点以上。<details>
<summary>Abstract</summary>
We study the problem of extracting accurate correspondences for point cloud registration. Recent keypoint-free methods have shown great potential through bypassing the detection of repeatable keypoints which is difficult to do especially in low-overlap scenarios. They seek correspondences over downsampled superpoints, which are then propagated to dense points. Superpoints are matched based on whether their neighboring patches overlap. Such sparse and loose matching requires contextual features capturing the geometric structure of the point clouds. We propose Geometric Transformer, or GeoTransformer for short, to learn geometric feature for robust superpoint matching. It encodes pair-wise distances and triplet-wise angles, making it invariant to rigid transformation and robust in low-overlap cases. The simplistic design attains surprisingly high matching accuracy such that no RANSAC is required in the estimation of alignment transformation, leading to $100$ times acceleration. Extensive experiments on rich benchmarks encompassing indoor, outdoor, synthetic, multiway and non-rigid demonstrate the efficacy of GeoTransformer. Notably, our method improves the inlier ratio by $18{\sim}31$ percentage points and the registration recall by over $7$ points on the challenging 3DLoMatch benchmark. Our code and models are available at \url{https://github.com/qinzheng93/GeoTransformer}.
</details>
<details>
<summary>摘要</summary>
我们研究点云注册问题中的准确匹配问题。最近的关键点无法方法已经表现出了很大的潜力，它们通过绕过复现关键点的检测而实现了更加简单的匹配方式。它们在下采样后的超点上寻找匹配，然后将匹配推广到密集点云。超点的匹配基于他们邻近的补丁 overlap。这种稀疏和松散的匹配需要捕捉点云的几何结构。我们提出了Geometric Transformer，简称为GeoTransformer，用于学习几何特征以实现Robust superpoint匹配。它编码了对称的距离和三角形的角度，使其对于平移变换不变和低 overlap情况下具有抗锁定性。我们的简单设计听起来 surprisingly high匹配精度，无需RANSAC，从而实现了100倍的加速。我们的实验结果表明，GeoTransformer在含有室内、外部、 sintetic、多方和非RIGID的丰富benchmark上都具有remarkable的效果。其中，我们的方法提高了3DLoMatchbenchmark上的准确比例by 18-31个百分点和注册记忆by more than 7个点。我们的代码和模型可以在以下链接中找到：https://github.com/qinzheng93/GeoTransformer。
</details></li>
</ul>
<hr>
<h2 id="An-Investigation-into-Glomeruli-Detection-in-Kidney-H-E-and-PAS-Images-using-YOLO"><a href="#An-Investigation-into-Glomeruli-Detection-in-Kidney-H-E-and-PAS-Images-using-YOLO" class="headerlink" title="An Investigation into Glomeruli Detection in Kidney H&amp;E and PAS Images using YOLO"></a>An Investigation into Glomeruli Detection in Kidney H&amp;E and PAS Images using YOLO</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13199">http://arxiv.org/abs/2307.13199</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/AlexeyAB/darknet">https://github.com/AlexeyAB/darknet</a></li>
<li>paper_authors: Kimia Hemmatirad, Morteza Babaie, Jeffrey Hodgin, Liron Pantanowitz, H. R. Tizhoosh<br>for:This paper aims to assist pathologists in detecting glomeruli in human kidney images using computerized solutions, specifically using the YOLO-v4 object detector.methods:The YOLO-v4 model was used to detect glomeruli in human kidney images, and the model was trained on whole slide images. The model was fine-tuned using a private dataset from the University of Michigan, and tested on the same dataset using two different stains (H&amp;E and PAS).results:The results show that the YOLO-v4 model can achieve high specificity and sensitivity in detecting glomeruli in human kidney images, with an average specificity and sensitivity for all experiments. The model’s performance was also compared to existing segmentation methods on the same datasets, and the results show that the YOLO-v4 model outperforms these methods.<details>
<summary>Abstract</summary>
Context: Analyzing digital pathology images is necessary to draw diagnostic conclusions by investigating tissue patterns and cellular morphology. However, manual evaluation can be time-consuming, expensive, and prone to inter- and intra-observer variability. Objective: To assist pathologists using computerized solutions, automated tissue structure detection and segmentation must be proposed. Furthermore, generating pixel-level object annotations for histopathology images is expensive and time-consuming. As a result, detection models with bounding box labels may be a feasible solution. Design: This paper studies. YOLO-v4 (You-Only-Look-Once), a real-time object detector for microscopic images. YOLO uses a single neural network to predict several bounding boxes and class probabilities for objects of interest. YOLO can enhance detection performance by training on whole slide images. YOLO-v4 has been used in this paper. for glomeruli detection in human kidney images. Multiple experiments have been designed and conducted based on different training data of two public datasets and a private dataset from the University of Michigan for fine-tuning the model. The model was tested on the private dataset from the University of Michigan, serving as an external validation of two different stains, namely hematoxylin and eosin (H&E) and periodic acid-Schiff (PAS). Results: Average specificity and sensitivity for all experiments, and comparison of existing segmentation methods on the same datasets are discussed. Conclusions: Automated glomeruli detection in human kidney images is possible using modern AI models. The design and validation for different stains still depends on variability of public multi-stain datasets.
</details>
<details>
<summary>摘要</summary>
Context: 分析数字 PATHOLOGY 图像是必要的，以便从 Investigate 组织趋势和细胞形态中得出诊断结论。然而，手动评估可能会占用大量时间和成本，并且可能会存在Inter-和 intra-观察者的差异。目的：通过计算机化解决方案，自动检测和分类组织结构。此外，生成 Histopathology 图像的像素级对象标注是昂贵的和时间consuming。因此，使用 bounding box 标签的检测模型可能是一个可行的解决方案。设计：本文研究了 YOLO-v4（You-Only-Look-Once），一种实时物体检测器，用于微scopic 图像。YOLO 使用单个神经网络预测多个 bounding box 和对象类概率。YOLO 可以通过训练整个扫描图像来提高检测性能。本文使用 YOLO-v4 进行人肾图像中glomeruli 检测。多个实验基于不同的训练数据，包括两个公共数据集和大学Michigan 私有数据集进行了微调。模型在大学Michigan 私有数据集上进行了测试，并作为对 H&E 和 PAS 两种染料的外部验证。结果：本文提出了一些均衡性和敏感性的平均值，并与其他分 segmentation 方法在同一个数据集上进行了比较。结论：使用现代 AI 模型，自动检测人肾图像中的glomeruli 是可能的。不同的染料设计仍然取决于多个公共多种染料数据集的变化。
</details></li>
</ul>
<hr>
<h2 id="Does-Progress-On-Object-Recognition-Benchmarks-Improve-Real-World-Generalization"><a href="#Does-Progress-On-Object-Recognition-Benchmarks-Improve-Real-World-Generalization" class="headerlink" title="Does Progress On Object Recognition Benchmarks Improve Real-World Generalization?"></a>Does Progress On Object Recognition Benchmarks Improve Real-World Generalization?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13136">http://arxiv.org/abs/2307.13136</a></li>
<li>repo_url: None</li>
<li>paper_authors: Megan Richards, Polina Kirichenko, Diane Bouchacourt, Mark Ibrahim</li>
<li>for: 这个论文是为了评估对图像网络上的基本模型进行大规模数据训练是否能够提高对真实世界的泛化能力。</li>
<li>methods: 这个论文使用了两个 datasets of objects from households across the globe，并进行了广泛的实验研究，包括对nearly 100种视觉模型进行了评估。</li>
<li>results: 研究发现，通过标准的基本模型训练方法，模型在不同地区的性能差距较大，Foundation CLIP 模型也存在大量地区性能差距。此外，论文还发现，通过简单地在最后一层添加更 represervative 的数据进行再训练，可以减少地区性能差距。<details>
<summary>Abstract</summary>
For more than a decade, researchers have measured progress in object recognition on ImageNet-based generalization benchmarks such as ImageNet-A, -C, and -R. Recent advances in foundation models, trained on orders of magnitude more data, have begun to saturate these standard benchmarks, but remain brittle in practice. This suggests standard benchmarks, which tend to focus on predefined or synthetic changes, may not be sufficient for measuring real world generalization. Consequently, we propose studying generalization across geography as a more realistic measure of progress using two datasets of objects from households across the globe. We conduct an extensive empirical evaluation of progress across nearly 100 vision models up to most recent foundation models. We first identify a progress gap between standard benchmarks and real-world, geographical shifts: progress on ImageNet results in up to 2.5x more progress on standard generalization benchmarks than real-world distribution shifts. Second, we study model generalization across geographies by measuring the disparities in performance across regions, a more fine-grained measure of real world generalization. We observe all models have large geographic disparities, even foundation CLIP models, with differences of 7-20% in accuracy between regions. Counter to modern intuition, we discover progress on standard benchmarks fails to improve geographic disparities and often exacerbates them: geographic disparities between the least performant models and today's best models have more than tripled. Our results suggest scaling alone is insufficient for consistent robustness to real-world distribution shifts. Finally, we highlight in early experiments how simple last layer retraining on more representative, curated data can complement scaling as a promising direction of future work, reducing geographic disparity on both benchmarks by over two-thirds.
</details>
<details>
<summary>摘要</summary>
To address this, we propose studying generalization across geography as a more realistic measure of progress. We evaluate nearly 100 vision models, including the most recent foundation models, on two datasets of objects from households around the world. Our results show that there is a significant gap between progress on ImageNet and real-world geographical shifts. While progress on ImageNet results in up to 2.5 times more progress on standard generalization benchmarks, it does not improve geographic disparities and often exacerbates them. In fact, the geographic disparities between the least performant models and today's best models have more than tripled.Our findings suggest that scaling alone is not sufficient for consistent robustness to real-world distribution shifts. However, we do find that simple last layer retraining on more representative, curated data can complement scaling and reduce geographic disparity on both benchmarks by over two-thirds. These results highlight the importance of considering real-world geographical variations when evaluating progress in object recognition.
</details></li>
</ul>
<hr>
<h2 id="simPLE-a-visuotactile-method-learned-in-simulation-to-precisely-pick-localize-regrasp-and-place-objects"><a href="#simPLE-a-visuotactile-method-learned-in-simulation-to-precisely-pick-localize-regrasp-and-place-objects" class="headerlink" title="simPLE: a visuotactile method learned in simulation to precisely pick, localize, regrasp, and place objects"></a>simPLE: a visuotactile method learned in simulation to precisely pick, localize, regrasp, and place objects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13133">http://arxiv.org/abs/2307.13133</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maria Bauza, Antonia Bronars, Yifan Hou, Ian Taylor, Nikhil Chavan-Dafle, Alberto Rodriguez<br>for: 这篇论文旨在解决机器人抓取和安放精度问题。methods: 本论文提出了一种基于模拟和感知的方法，称为simPLE，可以帮助机器人在不知道任务的情况下，准确地抓取和安放多种不同形状的物体。results: 在使用 dual-arm 机器人和视听感知系统的实验中，simPLE 能够成功地将 15 种不同形状的物体安放到有序排列中，成功率高达 90% 以上，并且在 6 种物体上达到 1mm 的准确性。<details>
<summary>Abstract</summary>
Existing robotic systems have a clear tension between generality and precision. Deployed solutions for robotic manipulation tend to fall into the paradigm of one robot solving a single task, lacking precise generalization, i.e., the ability to solve many tasks without compromising on precision. This paper explores solutions for precise and general pick-and-place. In precise pick-and-place, i.e. kitting, the robot transforms an unstructured arrangement of objects into an organized arrangement, which can facilitate further manipulation. We propose simPLE (simulation to Pick Localize and PLacE) as a solution to precise pick-and-place. simPLE learns to pick, regrasp and place objects precisely, given only the object CAD model and no prior experience. We develop three main components: task-aware grasping, visuotactile perception, and regrasp planning. Task-aware grasping computes affordances of grasps that are stable, observable, and favorable to placing. The visuotactile perception model relies on matching real observations against a set of simulated ones through supervised learning. Finally, we compute the desired robot motion by solving a shortest path problem on a graph of hand-to-hand regrasps. On a dual-arm robot equipped with visuotactile sensing, we demonstrate pick-and-place of 15 diverse objects with simPLE. The objects span a wide range of shapes and simPLE achieves successful placements into structured arrangements with 1mm clearance over 90% of the time for 6 objects, and over 80% of the time for 11 objects. Videos are available at http://mcube.mit.edu/research/simPLE.html .
</details>
<details>
<summary>摘要</summary>
现有的机器人系统存在明确的一致性和精度之间的矛盾。已部署的机器人 manipulate 解决方案通常处于单一任务的解决方案，缺乏精度，即能够解决多个任务而不失去精度。本文探讨精度和通用性的pick-and-place解决方案。在精度的pick-and-place中，机器人将无结构的物品变换为结构化的安排，可以促进进一步的操作。我们提出了simPLE（从 simulate 到 Pick Localize 和 PLacE）作为精度和通用性的pick-and-place解决方案。simPLE通过学习，可以准确地找到、重新抓取并将物品放置在正确的位置，只需要物品 CAD 模型，没有先前经验。我们开发了三个主要 ком成分：任务意识 grasping、视听感知和重新抓 планиuning。任务意识 grasping 计算物品的可行性，包括稳定、可见和放置的优势。视听感知模型通过对实际观察与 simulations 进行比较，通过超参数学习来学习。最后，我们解决了一个最短路径问题，以计算手动重新抓取的desired robot 动作。在配备视听感知的双手机器人上，我们通过 simPLE 成功地完成了15种不同的物品的pick-and-place。物品的形状范围广泛，simPLE 在90% 的时间内成功地将物品放置到结构化的安排中，距离1毫米。视频可以在http://mcube.mit.edu/research/simPLE.html 上查看。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Approaches-for-Data-Augmentation-in-Medical-Imaging-A-Review"><a href="#Deep-Learning-Approaches-for-Data-Augmentation-in-Medical-Imaging-A-Review" class="headerlink" title="Deep Learning Approaches for Data Augmentation in Medical Imaging: A Review"></a>Deep Learning Approaches for Data Augmentation in Medical Imaging: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13125">http://arxiv.org/abs/2307.13125</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Arminsbss/tumor-classification">https://github.com/Arminsbss/tumor-classification</a></li>
<li>paper_authors: Aghiles Kebaili, Jérôme Lapuyade-Lahorgue, Su Ruan</li>
<li>for: 这篇论文主要关注的是如何使用深度生成模型来增强医疗影像分析，特别是对于医疗领域的训练数据有限制，并且训练数据的获得可能是成本高且受到隐私法规限制。</li>
<li>methods: 这篇论文评论了三种深度生成模型，包括Variational Autoencoders、Generative Adversarial Networks和Diffusion Models，这些模型可以生成更加真实和多样的数据，并且可以帮助提高医疗影像分析中的深度学习算法性能。</li>
<li>results: 这篇论文评论了这些模型在不同的下游任务中的表现，包括分类、分 segmentation 和 Cross-modal Translation，并且评估了这些模型的优点和缺点，并提出了未来研究的方向。<details>
<summary>Abstract</summary>
Deep learning has become a popular tool for medical image analysis, but the limited availability of training data remains a major challenge, particularly in the medical field where data acquisition can be costly and subject to privacy regulations. Data augmentation techniques offer a solution by artificially increasing the number of training samples, but these techniques often produce limited and unconvincing results. To address this issue, a growing number of studies have proposed the use of deep generative models to generate more realistic and diverse data that conform to the true distribution of the data. In this review, we focus on three types of deep generative models for medical image augmentation: variational autoencoders, generative adversarial networks, and diffusion models. We provide an overview of the current state of the art in each of these models and discuss their potential for use in different downstream tasks in medical imaging, including classification, segmentation, and cross-modal translation. We also evaluate the strengths and limitations of each model and suggest directions for future research in this field. Our goal is to provide a comprehensive review about the use of deep generative models for medical image augmentation and to highlight the potential of these models for improving the performance of deep learning algorithms in medical image analysis.
</details>
<details>
<summary>摘要</summary>
深度学习已经成为医疗图像分析中广泛使用的工具，但是培训数据的有限性仍然是一个主要挑战，特别是在医疗领域，数据收集可能是成本高昂的并且受到隐私法规限制。数据扩充技术可以人工地增加培训样本数量，但这些技术通常会生成有限和不真实的结果。为解决这个问题，一些研究在医疗图像增强中使用深度生成模型，以生成更加真实和多样的数据，这些数据遵循实际数据的分布。在本文中，我们关注了三种深度生成模型，即变量自动编码器、生成对抗网络和扩散模型，并对它们在不同的下游任务中的当前状态进行了概述。我们还评估了每种模型的优缺点，并提出了未来研究的方向。我们的目标是提供一篇全面的深度生成模型在医疗图像增强中的评review，并高亮这些模型在医疗图像分析中的潜在优势。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Infant-Respiration-Estimation-from-Video-A-Deep-Flow-based-Algorithm-and-a-Novel-Public-Benchmark"><a href="#Automatic-Infant-Respiration-Estimation-from-Video-A-Deep-Flow-based-Algorithm-and-a-Novel-Public-Benchmark" class="headerlink" title="Automatic Infant Respiration Estimation from Video: A Deep Flow-based Algorithm and a Novel Public Benchmark"></a>Automatic Infant Respiration Estimation from Video: A Deep Flow-based Algorithm and a Novel Public Benchmark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13110">http://arxiv.org/abs/2307.13110</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ostadabbas/infant-respiration-estimation">https://github.com/ostadabbas/infant-respiration-estimation</a></li>
<li>paper_authors: Sai Kumar Reddy Manne, Shaotong Zhu, Sarah Ostadabbas, Michael Wan<br>for:This paper aims to develop a deep-learning method for estimating respiratory rate and waveform from plain video footage in natural settings, with the goal of providing fully automatic, continuous, and contactless respiratory monitoring for infants.methods:The proposed method, called AIRFlowNet, combines video-extracted optical flow input and spatiotemporal convolutional processing tuned to the infant domain. The model is trained using a novel spectral bandpass loss function and a public annotated infant respiration dataset (AIR-125) with 125 videos drawn from eight infant subjects.results:Compared to other state-of-the-art methods, AIRFlowNet significantly outperforms other state-of-the-art methods in respiratory rate estimation, achieving a mean absolute error of $\sim$2.9 breaths per minute.<details>
<summary>Abstract</summary>
Respiration is a critical vital sign for infants, and continuous respiratory monitoring is particularly important for newborns. However, neonates are sensitive and contact-based sensors present challenges in comfort, hygiene, and skin health, especially for preterm babies. As a step toward fully automatic, continuous, and contactless respiratory monitoring, we develop a deep-learning method for estimating respiratory rate and waveform from plain video footage in natural settings. Our automated infant respiration flow-based network (AIRFlowNet) combines video-extracted optical flow input and spatiotemporal convolutional processing tuned to the infant domain. We support our model with the first public annotated infant respiration dataset with 125 videos (AIR-125), drawn from eight infant subjects, set varied pose, lighting, and camera conditions. We include manual respiration annotations and optimize AIRFlowNet training on them using a novel spectral bandpass loss function. When trained and tested on the AIR-125 infant data, our method significantly outperforms other state-of-the-art methods in respiratory rate estimation, achieving a mean absolute error of $\sim$2.9 breaths per minute, compared to $\sim$4.7--6.2 for other public models designed for adult subjects and more uniform environments.
</details>
<details>
<summary>摘要</summary>
呼吸是新生儿的生命指标之一，不间断的呼吸监测对新生儿 particurlary 重要。然而，新生儿强健和触感型感测器存在舒适性、卫生性和皮肤健康等问题，特别是对幼儿。为了实现完全自动、无接触、不间断的呼吸监测，我们开发了一种深度学习方法，可以从普通的视频流中提取呼吸速率和呼吸波形。我们称之为婴儿呼吸流基网络（AIRFlowNet），它将视频提取的光流输入和空间时间卷积处理结合，特制 для婴儿领域。我们为这种模型提供了首个公共标注 infant 呼吸数据集（AIR-125），包括8名婴儿的125个视频，具有多种姿势、照明和摄像头条件。我们还包括手动呼吸注释和使用新的spectral bandpass损失函数来优化AIRFlowNet 的训练。当我们在AIR-125 infant数据集上训练和测试AIRFlowNet时，它与其他公共模型相比，在呼吸速率估计方面显著超越，具有$\sim$2.9 breaths per minute的平均绝对误差，与$\sim$4.7--6.2的其他公共模型设计 для成人主题和更加均匀的环境相比。
</details></li>
</ul>
<hr>
<h2 id="General-Purpose-Multi-Modal-OOD-Detection-Framework"><a href="#General-Purpose-Multi-Modal-OOD-Detection-Framework" class="headerlink" title="General-Purpose Multi-Modal OOD Detection Framework"></a>General-Purpose Multi-Modal OOD Detection Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13069">http://arxiv.org/abs/2307.13069</a></li>
<li>repo_url: None</li>
<li>paper_authors: Viet Duong, Qiong Wu, Zhengyi Zhou, Eric Zavesky, Jiahe Chen, Xiangzhou Liu, Wen-Ling Hsu, Huajie Shao</li>
<li>for: 本研究的目的是 simultaneously detect 多个不同的 OOD 场景，以提高 ML 系统的安全性和可靠性。</li>
<li>methods: 我们提出了一种通用的 weakly-supervised OOD detection 框架，called WOOD，它结合了一个二分类器和一个对比学习组件，以便充分利用两者的优点。我们采用了 Hinge loss 来约束 ID 和 OOD 样本的准确性。</li>
<li>results: 我们在多个实际世界数据集上测试了提出的 WOOD 模型，并得到了比现状态方法更高的 OOD 检测精度。特别是，我们的方法可以同时在三个不同的 OOD 场景中具有高准确性。<details>
<summary>Abstract</summary>
Out-of-distribution (OOD) detection identifies test samples that differ from the training data, which is critical to ensuring the safety and reliability of machine learning (ML) systems. While a plethora of methods have been developed to detect uni-modal OOD samples, only a few have focused on multi-modal OOD detection. Current contrastive learning-based methods primarily study multi-modal OOD detection in a scenario where both a given image and its corresponding textual description come from a new domain. However, real-world deployments of ML systems may face more anomaly scenarios caused by multiple factors like sensor faults, bad weather, and environmental changes. Hence, the goal of this work is to simultaneously detect from multiple different OOD scenarios in a fine-grained manner. To reach this goal, we propose a general-purpose weakly-supervised OOD detection framework, called WOOD, that combines a binary classifier and a contrastive learning component to reap the benefits of both. In order to better distinguish the latent representations of in-distribution (ID) and OOD samples, we adopt the Hinge loss to constrain their similarity. Furthermore, we develop a new scoring metric to integrate the prediction results from both the binary classifier and contrastive learning for identifying OOD samples. We evaluate the proposed WOOD model on multiple real-world datasets, and the experimental results demonstrate that the WOOD model outperforms the state-of-the-art methods for multi-modal OOD detection. Importantly, our approach is able to achieve high accuracy in OOD detection in three different OOD scenarios simultaneously. The source code will be made publicly available upon publication.
</details>
<details>
<summary>摘要</summary>
外部数据（OOD）检测可以识别测试样本与训练数据之间的差异，这是机器学习（ML）系统的安全性和可靠性的关键。虽然许多方法已经开发了用于检测单modal OOD样本，但只有一些关注了多modal OOD检测。现有的对比学习基于方法主要研究了一个给定的图像和其相应的文本描述来自新领域的多modal OOD检测场景。但实际世界中部署的ML系统可能会面临更多的异常场景，如感知器故障、坏天气和环境变化。因此，我们的目标是同时从多个不同的OOD场景中同精细地检测OOD样本。为达到这个目标，我们提出了一个通用强制监督OOD检测框架，called WOOD，它将对比学习和二分类器的优点相互融合。为了更好地分解ID和OOD样本的准确表示，我们采用了缩限损失来约束它们之间的相似性。此外，我们开发了一个新的分数指标，以集成binary分类器和对比学习的预测结果，以便更好地识别OOD样本。我们在多个实际世界数据集上测试了提议的WOOD模型，实验结果表明，WOOD模型在多modal OOD检测中超过了现有方法的性能。重要的是，我们的方法能够同时在三个不同的OOD场景中同精细地检测OOD样本。代码将在出版时公开。
</details></li>
</ul>
<hr>
<h2 id="On-the-characteristics-of-natural-hydraulic-dampers-An-image-based-approach-to-study-the-fluid-flow-behaviour-inside-the-human-meniscal-tissue"><a href="#On-the-characteristics-of-natural-hydraulic-dampers-An-image-based-approach-to-study-the-fluid-flow-behaviour-inside-the-human-meniscal-tissue" class="headerlink" title="On the characteristics of natural hydraulic dampers: An image-based approach to study the fluid flow behaviour inside the human meniscal tissue"></a>On the characteristics of natural hydraulic dampers: An image-based approach to study the fluid flow behaviour inside the human meniscal tissue</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13060">http://arxiv.org/abs/2307.13060</a></li>
<li>repo_url: None</li>
<li>paper_authors: J. Waghorne, F. P. Bonomo, A. Rabbani, D. Bell, O. Barrera</li>
<li>for: 这个研究旨在了解股骨细胞层中流体流动的行为以及其与结构的关系，以便更好地理解股骨疾病的发展、治疗方法的设计和生物材料的设计。</li>
<li>methods: 这个研究使用了计算流体动力学（CFD）和图像分析（CFD-IA）的新方法，通过高分辨率3D微计算tomography扫描来分析人类股骨内部的流体流动。</li>
<li>results: 研究发现，股骨内部的流体流动与结构参数（扭曲度、连接度、孔隙率、孔径size）存在 statistically significant 相关性。一些通道的Re值可达1400，并且在输入速度为1.6m&#x2F;s时出现了非达尔cy的 regime。location-dependent permeability ranges from 20-32 Darcy。在高输入速度下，流体速度和扭曲度之间存在强相关性，以及与通道径 diameter 的相关性。<details>
<summary>Abstract</summary>
The meniscal tissue is a layered material with varying properties influenced by collagen content and arrangement. Understanding the relationship between structure and properties is crucial for disease management, treatment development, and biomaterial design. The internal layer of the meniscus is softer and more deformable than the outer layers, thanks to interconnected collagen channels that guide fluid flow. To investigate these relationships, we propose a novel approach that combines Computational Fluid Dynamics (CFD) with Image Analysis (CFD-IA). We analyze fluid flow in the internal architecture of the human meniscus across a range of inlet velocities (0.1mm/s to 1.6m/s) using high-resolution 3D micro-computed tomography scans. Statistical correlations are observed between architectural parameters (tortuosity, connectivity, porosity, pore size) and fluid flow parameters (Re number distribution, permeability). Some channels exhibit Re values of 1400 at an inlet velocity of 1.6m/s, and a transition from Darcy's regime to a non-Darcian regime occurs around an inlet velocity of 0.02m/s. Location-dependent permeability ranges from 20-32 Darcy. Regression modelling reveals a strong correlation between fluid velocity and tortuosity at high inlet velocities, as well as with channel diameter at low inlet velocities. At higher inlet velocities, flow paths deviate more from the preferential direction, resulting in a decrease in the concentration parameter by an average of 0.4. This research provides valuable insights into the fluid flow behaviour within the meniscus and its structural influences.
</details>
<details>
<summary>摘要</summary>
人门韧带组织是一种层次结构，其特性受到含氧残基的含量和排列方式的影响。理解这些结构和性能之间的关系是疾病管理、治疗开发和生物材料设计的关键。人门韧带内部层次结构比外层更软和可变形，这是因为充满气流的彩虹涂层通道导致的。为了研究这些关系，我们提出了一种结合计算流动力学（CFD）和图像分析（CFD-IA）的新方法。我们使用高分辨率3D微型计算机断层扫描器来分析人门韧带内部的液体流动情况，并对输入速度（0.1mm/s至1.6m/s）进行了 Statistical correlations were observed between architectural parameters (tortuosity, connectivity, porosity, pore size) and fluid flow parameters (Re number distribution, permeability). Some channels exhibited Re values of 1400 at an inlet velocity of 1.6m/s, and a transition from Darcy's regime to a non-Darcian regime occurred around an inlet velocity of 0.02m/s. Location-dependent permeability ranged from 20-32 Darcy. Regression modeling revealed a strong correlation between fluid velocity and tortuosity at high inlet velocities, as well as with channel diameter at low inlet velocities. At higher inlet velocities, flow paths deviated more from the preferential direction, resulting in a decrease in the concentration parameter by an average of 0.4. This research provides valuable insights into the fluid flow behavior within the meniscus and its structural influences.  investigation of fluid flow behavior within the meniscus across a range of inlet velocities. We found that the internal architecture of the meniscus has a significant impact on fluid flow, and that there is a strong correlation between architectural parameters and fluid flow parameters. Our findings provide valuable insights into the relationship between structure and properties in the meniscus, and have important implications for disease management, treatment development, and biomaterial design.
</details></li>
</ul>
<hr>
<h2 id="A-Systematic-Survey-of-Prompt-Engineering-on-Vision-Language-Foundation-Models"><a href="#A-Systematic-Survey-of-Prompt-Engineering-on-Vision-Language-Foundation-Models" class="headerlink" title="A Systematic Survey of Prompt Engineering on Vision-Language Foundation Models"></a>A Systematic Survey of Prompt Engineering on Vision-Language Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12980">http://arxiv.org/abs/2307.12980</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/JindongGu/Awesome-Prompting-on-Vision-Language-Model">https://github.com/JindongGu/Awesome-Prompting-on-Vision-Language-Model</a></li>
<li>paper_authors: Jindong Gu, Zhen Han, Shuo Chen, Ahmad Beirami, Bailan He, Gengyuan Zhang, Ruotong Liao, Yao Qin, Volker Tresp, Philip Torr<br>for: This paper provides a comprehensive survey of cutting-edge research in prompt engineering on three types of vision-language models, including multimodal-to-text generation models, image-text matching models, and text-to-image generation models.methods: The paper discusses various prompting methods for vision-language models, including manually created natural language instructions and automatically generated prompts as natural language instructions or vector representations.results: The paper summarizes and discusses the results of prompt engineering on vision-language models, including the ability to perform predictions based solely on prompts without updating model parameters, and the easier application of large pre-trained models in real-world tasks. The paper also discusses the commonalities and differences between prompting on vision-language models, language models, and vision models, as well as the challenges, future directions, and research opportunities in this field.Here is the information in Simplified Chinese text:for: 这篇论文提供了三种视觉语言模型的前沿研究报告，包括多模态文本生成模型、图像文本匹配模型以及文本图像生成模型。methods: 论文讨论了不同类型的提示方法，包括手动创建的自然语言指令以及自动生成的提示。results: 论文总结并讨论了视觉语言模型上的提示工程结果，包括基于提示进行预测而无需更新模型参数，以及使用大型预训练模型在实际任务中更加容易应用。论文还讨论了视觉语言模型、语言模型和视模型之间的相似性和不同点，以及这一领域的挑战、未来发展和研究机遇。<details>
<summary>Abstract</summary>
Prompt engineering is a technique that involves augmenting a large pre-trained model with task-specific hints, known as prompts, to adapt the model to new tasks. Prompts can be created manually as natural language instructions or generated automatically as either natural language instructions or vector representations. Prompt engineering enables the ability to perform predictions based solely on prompts without updating model parameters, and the easier application of large pre-trained models in real-world tasks. In past years, Prompt engineering has been well-studied in natural language processing. Recently, it has also been intensively studied in vision-language modeling. However, there is currently a lack of a systematic overview of prompt engineering on pre-trained vision-language models. This paper aims to provide a comprehensive survey of cutting-edge research in prompt engineering on three types of vision-language models: multimodal-to-text generation models (e.g. Flamingo), image-text matching models (e.g. CLIP), and text-to-image generation models (e.g. Stable Diffusion). For each type of model, a brief model summary, prompting methods, prompting-based applications, and the corresponding responsibility and integrity issues are summarized and discussed. Furthermore, the commonalities and differences between prompting on vision-language models, language models, and vision models are also discussed. The challenges, future directions, and research opportunities are summarized to foster future research on this topic.
</details>
<details>
<summary>摘要</summary>
广泛应用工程技术是一种方法，它利用大型预训练模型，通过添加任务特定的提示（即提示），以适应新任务。提示可以手动创建为自然语言指令，或者生成自然语言指令或者向量表示。广泛应用工程技术允许基于提示进行预测，而不需要更新模型参数，并且可以轻松地应用大型预训练模型在实际任务中。在过去几年中，广泛应用工程技术在自然语言处理领域得到了广泛的研究。在最近几年中，它也在视觉语言模型中得到了广泛的研究。然而，目前没有一篇系统的概述了广泛应用工程技术在预训练视觉语言模型上的研究。这篇论文旨在提供了广泛应用工程技术在三种类型的预训练视觉语言模型上的全面概述：多模态到文本生成模型（例如FLAMINGO）、图像文本匹配模型（例如CLIP）和文本到图像生成模型（例如稳定扩散）。对于每种模型，我们将 briefly描述模型的概述、提示方法、基于提示的应用和相应的责任和道德问题。此外，我们还将讨论广泛应用工程技术在视觉语言模型、语言模型和视觉模型之间的相似和不同。 finally,我们将 SUMMARIZE 未来的挑战、未来方向和研究机会，以促进未来在这个领域的研究。
</details></li>
</ul>
<hr>
<h2 id="DFA3D-3D-Deformable-Attention-For-2D-to-3D-Feature-Lifting"><a href="#DFA3D-3D-Deformable-Attention-For-2D-to-3D-Feature-Lifting" class="headerlink" title="DFA3D: 3D Deformable Attention For 2D-to-3D Feature Lifting"></a>DFA3D: 3D Deformable Attention For 2D-to-3D Feature Lifting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12972">http://arxiv.org/abs/2307.12972</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/IDEA-Research/3D-deformable-attention">https://github.com/IDEA-Research/3D-deformable-attention</a></li>
<li>paper_authors: Hongyang Li, Hao Zhang, Zhaoyang Zeng, Shilong Liu, Feng Li, Tianhe Ren, Lei Zhang</li>
<li>for: 提高2D图像特征的3D检测精度，通过将多视图2D图像特征映射到一个统一的3D空间中。</li>
<li>methods: 提出了一种新的操作符，即3D DeFormable Attention (DFA3D)，用于2D-to-3D特征提升，该操作符可以帮助解决depth ambiguity问题，并且可以逐层进行特征细化。</li>
<li>results: 实验结果表明，DFA3D可以提高nuScenes数据集上的平均精度+1.41%，并且在高质量深度信息可用时可以达到+15.1%的提高。<details>
<summary>Abstract</summary>
In this paper, we propose a new operator, called 3D DeFormable Attention (DFA3D), for 2D-to-3D feature lifting, which transforms multi-view 2D image features into a unified 3D space for 3D object detection. Existing feature lifting approaches, such as Lift-Splat-based and 2D attention-based, either use estimated depth to get pseudo LiDAR features and then splat them to a 3D space, which is a one-pass operation without feature refinement, or ignore depth and lift features by 2D attention mechanisms, which achieve finer semantics while suffering from a depth ambiguity problem. In contrast, our DFA3D-based method first leverages the estimated depth to expand each view's 2D feature map to 3D and then utilizes DFA3D to aggregate features from the expanded 3D feature maps. With the help of DFA3D, the depth ambiguity problem can be effectively alleviated from the root, and the lifted features can be progressively refined layer by layer, thanks to the Transformer-like architecture. In addition, we propose a mathematically equivalent implementation of DFA3D which can significantly improve its memory efficiency and computational speed. We integrate DFA3D into several methods that use 2D attention-based feature lifting with only a few modifications in code and evaluate on the nuScenes dataset. The experiment results show a consistent improvement of +1.41\% mAP on average, and up to +15.1\% mAP improvement when high-quality depth information is available, demonstrating the superiority, applicability, and huge potential of DFA3D. The code is available at https://github.com/IDEA-Research/3D-deformable-attention.git.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一新的操作符，即3D DeFormable Attention（DFA3D），用于2D-to-3D特征提升，该操作将多视图2D图像特征转换到一个统一的3D空间中，用于3D对象检测。现有的特征提升方法，如Lift-Splat-based和2D attention-based，可以通过利用估计的深度来获得pseudo LiDAR特征，然后将其扩展到3D空间，这是一个一旦性操作而不包含特征细化，或者忽略深度并通过2D attention机制提升特征，这可以达到更细的 semantics，但是受到深度抽象问题困扰。相比之下，我们的DFA3D-based方法首先利用估计的深度来扩展每个视图的2D特征图到3D，然后通过DFA3D机制来聚合来自扩展的3D特征图中的特征。通过DFA3D的帮助，可以有效解决深度抽象问题，并且可以逐层进行特征细化， благо于Transformer-like架构。此外，我们还提出了DFA3D的数学等效实现方式，可以显著提高内存利用率和计算速度。我们将DFA3D integrate到了使用2D attention-based特征提升的一些方法中，只需要在代码中做一些微调，并对nuScenes数据集进行评估。实验结果表明，DFA3D可以提供+1.41\% mAP的平均提升，并且在高质量深度信息可用时可以达到+15.1\% mAP的最大提升，这说明DFA3D的超越、可应用性和巨大的潜力。代码可以在https://github.com/IDEA-Research/3D-deformable-attention.git中找到。
</details></li>
</ul>
<hr>
<h2 id="Volcanic-ash-delimitation-using-Artificial-Intelligence-based-on-Pix2Pix"><a href="#Volcanic-ash-delimitation-using-Artificial-Intelligence-based-on-Pix2Pix" class="headerlink" title="Volcanic ash delimitation using Artificial Intelligence based on Pix2Pix"></a>Volcanic ash delimitation using Artificial Intelligence based on Pix2Pix</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12970">http://arxiv.org/abs/2307.12970</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christian Carrillo, Gissela Torres, Christian Mejia-Escobar</li>
<li>for: 这项研究的目的是提出一种基于深度学习的 ash 云定义方法，以帮助预测和 mitigate 火山喷发的影响。</li>
<li>methods: 该方法使用 Pix2Pix 模型，一种基于生成对抗网络的技术，将多spectral 卫星图像转换为黑白 ash 云图像。</li>
<li>results: 试验结果表明，该方法可以准确地定义 ash 云，并且可以在任何地区应用。这种方法可以帮助预测和 mitigate 火山喷发的影响，成为一种有用的工具。<details>
<summary>Abstract</summary>
Volcanic eruptions emit ash that can be harmful to human health and cause damage to infrastructure, economic activities and the environment. The delimitation of ash clouds allows to know their behavior and dispersion, which helps in the prevention and mitigation of this phenomenon. Traditional methods take advantage of specialized software programs to process the bands or channels that compose the satellite images. However, their use is limited to experts and demands a lot of time and significant computational resources. In recent years, Artificial Intelligence has been a milestone in the computational treatment of complex problems in different areas. In particular, Deep Learning techniques allow automatic, fast and accurate processing of digital images. The present work proposes the use of the Pix2Pix model, a type of generative adversarial network that, once trained, learns the mapping of input images to output images. The architecture of such a network consisting of a generator and a discriminator provides the versatility needed to produce black and white ash cloud images from multispectral satellite images. The evaluation of the model, based on loss and accuracy plots, a confusion matrix, and visual inspection, indicates a satisfactory solution for accurate ash cloud delineation, applicable in any area of the world and becomes a useful tool in risk management.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Learning-Dense-Correspondences-between-Photos-and-Sketches"><a href="#Learning-Dense-Correspondences-between-Photos-and-Sketches" class="headerlink" title="Learning Dense Correspondences between Photos and Sketches"></a>Learning Dense Correspondences between Photos and Sketches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12967">http://arxiv.org/abs/2307.12967</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cogtoolslab/photo-sketch-correspondence">https://github.com/cogtoolslab/photo-sketch-correspondence</a></li>
<li>paper_authors: Xuanchen Lu, Xiaolong Wang, Judith E Fan</li>
<li>For: The paper aims to support the ability of artificial systems to understand visual images at different levels of abstraction, with a focus on sketch-photo correspondence.* Methods: The paper introduces a new sketch-photo correspondence benchmark called $\textit{PSC6k}$, which contains 150K annotations of 6250 sketch-photo pairs across 125 object categories. The authors also propose a self-supervised method for learning dense correspondences between sketch-photo pairs, using a spatial transformer network to estimate the warp flow between latent representations of a sketch and photo.* Results: The authors found that their approach outperformed several strong baselines and produced predictions that were quantitatively consistent with other warp-based methods. However, their benchmark also revealed systematic differences between predictions of the suite of models they tested and those of humans.<details>
<summary>Abstract</summary>
Humans effortlessly grasp the connection between sketches and real-world objects, even when these sketches are far from realistic. Moreover, human sketch understanding goes beyond categorization -- critically, it also entails understanding how individual elements within a sketch correspond to parts of the physical world it represents. What are the computational ingredients needed to support this ability? Towards answering this question, we make two contributions: first, we introduce a new sketch-photo correspondence benchmark, $\textit{PSC6k}$, containing 150K annotations of 6250 sketch-photo pairs across 125 object categories, augmenting the existing Sketchy dataset with fine-grained correspondence metadata. Second, we propose a self-supervised method for learning dense correspondences between sketch-photo pairs, building upon recent advances in correspondence learning for pairs of photos. Our model uses a spatial transformer network to estimate the warp flow between latent representations of a sketch and photo extracted by a contrastive learning-based ConvNet backbone. We found that this approach outperformed several strong baselines and produced predictions that were quantitatively consistent with other warp-based methods. However, our benchmark also revealed systematic differences between predictions of the suite of models we tested and those of humans. Taken together, our work suggests a promising path towards developing artificial systems that achieve more human-like understanding of visual images at different levels of abstraction. Project page: https://photo-sketch-correspondence.github.io
</details>
<details>
<summary>摘要</summary>
人类可以轻松地理解绘图和实际世界之间的连接，即使绘图不够真实。此外，人类绘图理解不仅是分类，而且还包括理解绘图中的个体元素与物理世界中的部件之间的对应关系。为解答这个问题，我们提出了两个贡献：首先，我们 introduce a new sketch-photo correspondence benchmark， $\textit{PSC6k}$，包含150,000个绘图-照片对的125个物品类别中的6,250个对。我们将现有的Sketchy数据集补充了细化的对应 metadata。其次，我们提出了一种自动学习的方法，用于学习绘图-照片对的密集对应关系。我们基于现有的对应学习方法，使用一个空间变换网络来估计绘图和照片中latent表示的截面流。我们发现这种方法在多个强基elines上表现出色，并且生成的预测与其他截面基eline相比具有较高的准确性。然而，我们的benchmark还发现系统性的差异 между模型的预测和人类的预测。总之，我们的工作表明了在不同层次的视觉图像理解方面可以开发出更人类化的人工系统。我们的研究可能会为视觉计算机科学和机器学习领域的发展提供新的思路和方法。项目页面：https://photo-sketch-correspondence.github.io
</details></li>
</ul>
<hr>
<h2 id="Audio-Enhanced-Text-to-Video-Retrieval-using-Text-Conditioned-Feature-Alignment"><a href="#Audio-Enhanced-Text-to-Video-Retrieval-using-Text-Conditioned-Feature-Alignment" class="headerlink" title="Audio-Enhanced Text-to-Video Retrieval using Text-Conditioned Feature Alignment"></a>Audio-Enhanced Text-to-Video Retrieval using Text-Conditioned Feature Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12964">http://arxiv.org/abs/2307.12964</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sarah Ibrahimi, Xiaohang Sun, Pichao Wang, Amanmeet Garg, Ashutosh Sanan, Mohamed Omar</li>
<li>for: This paper focuses on the task of text-to-video retrieval, specifically addressing the issue of neglecting audio information in previous methods.</li>
<li>methods: The proposed method, TEFAL, uses two independent cross-modal attention blocks to enable the text to attend to the audio and video representations separately, producing both audio and video representations conditioned on the text query.</li>
<li>results: The proposed method achieves better than state-of-the-art performance consistently across four benchmark datasets, including MSR-VTT, LSMDC, VATEX, and Charades, demonstrating its efficacy in capturing complementary audio and video information pertinent to the text query.Here’s the simplified Chinese version of the three key points:</li>
<li>for: 这篇论文关注了文本到视频回归任务，特别是之前的方法忽略了音频信息的问题。</li>
<li>methods: 提议的方法TEFAL使用了两个独立的跨模态注意力块，使文本能够独立地对音频和视频表示进行注意力调整，生成了基于文本查询的音频和视频表示。</li>
<li>results: 提议的方法在四个标准测试集MSR-VTT、LSMDC、VATEX和Charades上取得了比前STATE-OF-THE-ART性能更好的结果， demonstarting its efficacy in capturing相关的音频和视频信息。<details>
<summary>Abstract</summary>
Text-to-video retrieval systems have recently made significant progress by utilizing pre-trained models trained on large-scale image-text pairs. However, most of the latest methods primarily focus on the video modality while disregarding the audio signal for this task. Nevertheless, a recent advancement by ECLIPSE has improved long-range text-to-video retrieval by developing an audiovisual video representation. Nonetheless, the objective of the text-to-video retrieval task is to capture the complementary audio and video information that is pertinent to the text query rather than simply achieving better audio and video alignment. To address this issue, we introduce TEFAL, a TExt-conditioned Feature ALignment method that produces both audio and video representations conditioned on the text query. Instead of using only an audiovisual attention block, which could suppress the audio information relevant to the text query, our approach employs two independent cross-modal attention blocks that enable the text to attend to the audio and video representations separately. Our proposed method's efficacy is demonstrated on four benchmark datasets that include audio: MSR-VTT, LSMDC, VATEX, and Charades, and achieves better than state-of-the-art performance consistently across the four datasets. This is attributed to the additional text-query-conditioned audio representation and the complementary information it adds to the text-query-conditioned video representation.
</details>
<details>
<summary>摘要</summary>
Text-to-video遥感系统在最近几年内已经取得了重要进步，通过使用预训练模型，这些模型在大规模的图像-文本对中训练。然而，大多数最新的方法主要关注视频模式，而忽略了声音信号。然而，ECLIPSE的最新进展已经改进了长距离文本-视频遥感。不过，文本-视频遥感任务的目标是捕捉文本查询中相关的声音和视频信息，而不仅仅是实现更好的声音和视频对齐。为解决这个问题，我们提出了TEFAL方法，它是一种基于文本查询的特征对齐方法，它生成了基于文本查询的声音和视频表示。相比使用仅仅的 audiovisual注意块，我们的方法使用两个独立的跨模态注意块，这些注意块使得文本能够独立地对声音和视频表示进行注意。我们的提议方法在四个标准数据集上进行了评估，这些数据集包括声音：MSR-VTT、LSMDC、VATEX和Charades，并在这些数据集上达到了比前方的性能。这是因为我们的方法添加了基于文本查询的声音表示，这个表示提供了与文本查询conditioned的视频表示相 complementary的信息。
</details></li>
</ul>
<hr>
<h2 id="HOOD-Real-Time-Robust-Human-Presence-and-Out-of-Distribution-Detection-with-Low-Cost-FMCW-Radar"><a href="#HOOD-Real-Time-Robust-Human-Presence-and-Out-of-Distribution-Detection-with-Low-Cost-FMCW-Radar" class="headerlink" title="HOOD: Real-Time Robust Human Presence and Out-of-Distribution Detection with Low-Cost FMCW Radar"></a>HOOD: Real-Time Robust Human Presence and Out-of-Distribution Detection with Low-Cost FMCW Radar</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02396">http://arxiv.org/abs/2308.02396</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sabri Mustafa Kahya, Muhammet Sami Yavuz, Eckehard Steinbach</li>
<li>for: 这个论文的目的是提出一种实时稳定的人员存在检测方法，以解决在室内环境中 millimeter-wave频率调制连续扫描（FMCW）雷达中人员存在检测的挑战。</li>
<li>methods: 该方法基于60GHz短距离FMCW雷达，并利用干扰图像（RDI）来实现实时人员存在和异常检测。方法根据存在或缺失人员的情况，将检测问题转化为异常检测问题，并通过一种重建性架构来实现。</li>
<li>results: 在使用60GHz短距离FMCW雷达进行数据收集后，该方法在HOOD测试数据集上 achieve an average AUROC of 94.36%。此外，对比之前的State-of-the-art（SOTA）异常检测方法，HOOD方法在常见的异常检测指标上表现更高。实时实验结果可以在<a target="_blank" rel="noopener" href="https://muskahya.github.io/HOOD%E4%B8%AD%E6%9F%A5%E7%9C%8B%E3%80%82">https://muskahya.github.io/HOOD中查看。</a><details>
<summary>Abstract</summary>
Human presence detection in indoor environments using millimeter-wave frequency-modulated continuous-wave (FMCW) radar is challenging due to the presence of moving and stationary clutters in indoor places. This work proposes "HOOD" as a real-time robust human presence and out-of-distribution (OOD) detection method by exploiting 60 GHz short-range FMCW radar. We approach the presence detection application as an OOD detection problem and solve the two problems simultaneously using a single pipeline. Our solution relies on a reconstruction-based architecture and works with radar macro and micro range-Doppler images (RDIs). HOOD aims to accurately detect the "presence" of humans in the presence or absence of moving and stationary disturbers. Since it is also an OOD detector, it aims to detect moving or stationary clutters as OOD in humans' absence and predicts the current scene's output as "no presence." HOOD is an activity-free approach that performs well in different human scenarios. On our dataset collected with a 60 GHz short-range FMCW Radar, we achieve an average AUROC of 94.36%. Additionally, our extensive evaluations and experiments demonstrate that HOOD outperforms state-of-the-art (SOTA) OOD detection methods in terms of common OOD detection metrics. Our real-time experiments are available at: https://muskahya.github.io/HOOD
</details>
<details>
<summary>摘要</summary>
人体存在检测在室内环境中使用毫米波频率调制连续波（FMCW）雷达是具有挑战性，因为室内存在移动和静止干扰物。这项工作提出了“HOOD”实时可靠人体存在和异常检测方法，通过利用60GHz短距离FMCW雷达。我们将存在检测应用作为异常检测问题，并将两个问题同时解决在单一管道中。我们的解决方案基于重建 architecture，并与雷达宽 macro和微范围Doppler图像（RDI）结合。HOOD hopes to accurately detect the "presence" of humans in the presence or absence of moving and stationary disturbers。此外，它还 hopes to检测移动或静止干扰物作为异常，并预测当前场景的输出为“无存”。HOOD是一种活动无关的方法，在不同的人类场景中表现良好。根据我们收集的60GHz短距离FMCW雷达数据集，我们实现了平均AUROC为94.36%。此外，我们的广泛评估和实验表明，HOOD在常见异常检测指标上表现出色，超过了现状顶峰（SOTA）异常检测方法。实时实验可以在：https://muskahya.github.io/HOOD
</details></li>
</ul>
<hr>
<h2 id="Dyn-E-Local-Appearance-Editing-of-Dynamic-Neural-Radiance-Fields"><a href="#Dyn-E-Local-Appearance-Editing-of-Dynamic-Neural-Radiance-Fields" class="headerlink" title="Dyn-E: Local Appearance Editing of Dynamic Neural Radiance Fields"></a>Dyn-E: Local Appearance Editing of Dynamic Neural Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12909">http://arxiv.org/abs/2307.12909</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shangzhan Zhang, Sida Peng, Yinji ShenTu, Qing Shuai, Tianrun Chen, Kaicheng Yu, Hujun Bao, Xiaowei Zhou</li>
<li>for: 本文提出了一种新的方法，用于编辑动态场景中的NeRF的本地外观。</li>
<li>methods: 本方法使用了一种新的表示方法，将编辑区域的表示插入到原始NeRF和旋转学习网络中，以便在不同的帧数据上进行渲染和插值。</li>
<li>results: 经过广泛的评估，本方法可以准确地编辑动态场景中的NeRF外观，并且可以保持空间和时间上的一致性。<details>
<summary>Abstract</summary>
Recently, the editing of neural radiance fields (NeRFs) has gained considerable attention, but most prior works focus on static scenes while research on the appearance editing of dynamic scenes is relatively lacking. In this paper, we propose a novel framework to edit the local appearance of dynamic NeRFs by manipulating pixels in a single frame of training video. Specifically, to locally edit the appearance of dynamic NeRFs while preserving unedited regions, we introduce a local surface representation of the edited region, which can be inserted into and rendered along with the original NeRF and warped to arbitrary other frames through a learned invertible motion representation network. By employing our method, users without professional expertise can easily add desired content to the appearance of a dynamic scene. We extensively evaluate our approach on various scenes and show that our approach achieves spatially and temporally consistent editing results. Notably, our approach is versatile and applicable to different variants of dynamic NeRF representations.
</details>
<details>
<summary>摘要</summary>
近些时候，神经辐射场（NeRF）的编辑技术已经吸引了广泛的关注，但大多数前一些作品都是静止场景的，关于动态场景的外观编辑研究相对较少。在这篇论文中，我们提出了一种新的框架，用于编辑动态NeRF的本地外观。具体来说，我们引入了一种修改区域的本地表面表示，可以在训练视频帧中插入并与原始NeRF和扭曲学习的运动表示网络一起渲染。通过我们的方法，用户无需专业技能就可以轻松地添加愿望的内容到动态场景的外观中。我们对多个场景进行了广泛的评估，并证明了我们的方法可以在空间和时间上实现一致的编辑结果。值得一提的是，我们的方法可以应用于不同的动态NeRF表示方式。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/25/cs.CV_2023_07_25/" data-id="clpxp03yf00h1fm883cm5ay6f" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_07_25" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/25/cs.AI_2023_07_25/" class="article-date">
  <time datetime="2023-07-25T12:00:00.000Z" itemprop="datePublished">2023-07-25</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/25/cs.AI_2023_07_25/">cs.AI - 2023-07-25</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Argument-Attribution-Explanations-in-Quantitative-Bipolar-Argumentation-Frameworks-Technical-Report"><a href="#Argument-Attribution-Explanations-in-Quantitative-Bipolar-Argumentation-Frameworks-Technical-Report" class="headerlink" title="Argument Attribution Explanations in Quantitative Bipolar Argumentation Frameworks (Technical Report)"></a>Argument Attribution Explanations in Quantitative Bipolar Argumentation Frameworks (Technical Report)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13582">http://arxiv.org/abs/2307.13582</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiang Yin, Nico Potyka, Francesca Toni</li>
<li>for: 这篇论文旨在解释Argumentation Frameworks（AFs）的量化结果，具体来说是解释Quantitative Bipolar Argumentation Frameworks（QBAFs）中的话题论点。</li>
<li>methods: 该论文提出了一种新的Argument Attribution Explanations（AAEs）理论，兼用机器学习中的特征归因来解释AFs中的论点。</li>
<li>results: 论文通过两个实践案例（即假新闻检测和电影推荐系统）来示例AAEs的应用性。<details>
<summary>Abstract</summary>
Argumentative explainable AI has been advocated by several in recent years, with an increasing interest on explaining the reasoning outcomes of Argumentation Frameworks (AFs). While there is a considerable body of research on qualitatively explaining the reasoning outcomes of AFs with debates/disputes/dialogues in the spirit of extension-based semantics, explaining the quantitative reasoning outcomes of AFs under gradual semantics has not received much attention, despite widespread use in applications. In this paper, we contribute to filling this gap by proposing a novel theory of Argument Attribution Explanations (AAEs) by incorporating the spirit of feature attribution from machine learning in the context of Quantitative Bipolar Argumentation Frameworks (QBAFs): whereas feature attribution is used to determine the influence of features towards outputs of machine learning models, AAEs are used to determine the influence of arguments towards topic arguments of interest. We study desirable properties of AAEs, including some new ones and some partially adapted from the literature to our setting. To demonstrate the applicability of our AAEs in practice, we conclude by carrying out two case studies in the scenarios of fake news detection and movie recommender systems.
</details>
<details>
<summary>摘要</summary>
争议解释AI在最近几年来得到了许多人的支持，感兴趣的是解释Argumentation Frameworks（AFs）的结果的逻辑过程。虽然有许多关于使用辩论/争议/对话来解释AFs的质量的研究，但是对于使用加权 semantics来解释AFs的量化逻辑结果没有很多关注，尽管这在应用中广泛使用。在这篇论文中，我们减轻这一点的空白，我们提出了一种新的Argument Attribution Explanations（AAEs）理论，该理论基于机器学习中的特征归因，用于解释QBAFs中的话题Arguments。而特征归因用于确定机器学习模型输出的特征对输出产生的影响，AAEs则用于确定话题Arguments对QBAFs中的话题Arguments的影响。我们研究了AAEs的愉悦性质，包括一些新的和一些从文献中部分适应我们的设置。为了证明AAEs在实践中的可行性，我们在假新闻检测和电影推荐系统两个场景中进行了两个案例研究。
</details></li>
</ul>
<hr>
<h2 id="Reinterpreting-survival-analysis-in-the-universal-approximator-age"><a href="#Reinterpreting-survival-analysis-in-the-universal-approximator-age" class="headerlink" title="Reinterpreting survival analysis in the universal approximator age"></a>Reinterpreting survival analysis in the universal approximator age</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13579">http://arxiv.org/abs/2307.13579</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sdittmer/survival_analysis_sumo_plus_plus">https://github.com/sdittmer/survival_analysis_sumo_plus_plus</a></li>
<li>paper_authors: Sören Dittmer, Michael Roberts, Jacobus Preller, AIX COVNET, James H. F. Rudd, John A. D. Aston, Carola-Bibiane Schönlieb</li>
<li>for: 本研究旨在提供用于深度学习中survival分析的工具，以便充分发挥survival分析的潜在力量。</li>
<li>methods: 本研究使用的方法包括新的损失函数、评价指标和首个universal approximating网络，这些工具可以无需数值integation生成survival曲线。</li>
<li>results: 研究表明，新的损失函数和模型在大规模的数据研究中表现出色，超过其他方法的表现。<details>
<summary>Abstract</summary>
Survival analysis is an integral part of the statistical toolbox. However, while most domains of classical statistics have embraced deep learning, survival analysis only recently gained some minor attention from the deep learning community. This recent development is likely in part motivated by the COVID-19 pandemic. We aim to provide the tools needed to fully harness the potential of survival analysis in deep learning. On the one hand, we discuss how survival analysis connects to classification and regression. On the other hand, we provide technical tools. We provide a new loss function, evaluation metrics, and the first universal approximating network that provably produces survival curves without numeric integration. We show that the loss function and model outperform other approaches using a large numerical study.
</details>
<details>
<summary>摘要</summary>
生存分析是统计工具箱中的一个重要组成部分。然而，在经典统计领域中，深度学习已经广泛应用，而生存分析则只是在深度学习社区中最近才得到了一些微的注意。这种最近的发展可能与COVID-19大流行有关。我们的目标是为生存分析在深度学习中充分发挥作用提供工具。一方面，我们讨论了生存分析与分类和回归之间的联系。另一方面，我们提供了技术工具。我们提出了一个新的损失函数、评估指标和首个可靠地生成Survival Curve的网络。我们通过大规模的数值研究表明，我们的损失函数和模型在其他方法的比较中表现出色。
</details></li>
</ul>
<hr>
<h2 id="A-Dual-mode-Local-Search-Algorithm-for-Solving-the-Minimum-Dominating-Set-Problem"><a href="#A-Dual-mode-Local-Search-Algorithm-for-Solving-the-Minimum-Dominating-Set-Problem" class="headerlink" title="A Dual-mode Local Search Algorithm for Solving the Minimum Dominating Set Problem"></a>A Dual-mode Local Search Algorithm for Solving the Minimum Dominating Set Problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16815">http://arxiv.org/abs/2307.16815</a></li>
<li>repo_url: None</li>
<li>paper_authors: Enqiang Zhu, Yu Zhang, Shengzhi Wang, Darren Strash, Chanjuan Liu</li>
<li>for: 解决图形中最小控制集（MinDS）问题，即找到一个最小的集合 $D$，使得每个不在 $D$ 中的顶点都与至少一个 $D$ 中的顶点相邻。</li>
<li>methods: 我们提出了一种有效的本地搜索算法（DmDS），它采用了两种不同的顶点交换方案来解决MinDS问题。此外，我们还提出了一种基于频率的顶点选择 criterion，以解决其他算法中的各种绑定情况，以及一种新的Initial Solution质量提高策略，基于批处理和扰动。</li>
<li>results: 我们对 seven 个数据集进行了比较，包括 346 个实例（或家族），最多有十亿个顶点。实验结果表明，DmDS 在大多数实例中具有最高的准确率，并在广泛的实际图形上发现了许多更好的解决方案。<details>
<summary>Abstract</summary>
Given a graph, the minimum dominating set (MinDS) problem is to identify a smallest set $D$ of vertices such that every vertex not in $D$ is adjacent to at least one vertex in $D$. The MinDS problem is a classic $\mathcal{NP}$-hard problem and has been extensively studied because of its many disparate applications in network analysis. To solve this problem efficiently, many heuristic approaches have been proposed to obtain a good solution within an acceptable time limit. However, existing MinDS heuristic algorithms are always limited by various tie-breaking cases when selecting vertices, which slows down the effectiveness of the algorithms. In this paper, we design an efficient local search algorithm for the MinDS problem, named DmDS -- a dual-mode local search framework that probabilistically chooses between two distinct vertex-swapping schemes. We further address limitations of other algorithms by introducing vertex selection criterion based on the frequency of vertices added to solutions to address tie-breaking cases, and a new strategy to improve the quality of the initial solution via a greedy-based strategy integrated with perturbation. We evaluate DmDS against the state-of-the-art algorithms on seven datasets, consisting of 346 instances (or families) with up to tens of millions of vertices. Experimental results show that DmDS obtains the best performance in accuracy for almost all instances and finds much better solutions than state-of-the-art MinDS algorithms on a broad range of large real-world graphs.
</details>
<details>
<summary>摘要</summary>
Existing MinDS heuristic algorithms are limited by various tie-breaking cases when selecting vertices, which slows down their effectiveness. In this paper, we propose an efficient local search algorithm for the MinDS problem, called DmDS, which uses a dual-mode local search framework that probabilistically chooses between two distinct vertex-swapping schemes.To address limitations of other algorithms, we introduce a vertex selection criterion based on the frequency of vertices added to solutions to address tie-breaking cases, and a new strategy to improve the quality of the initial solution via a greedy-based strategy integrated with perturbation.We evaluate DmDS against state-of-the-art algorithms on seven datasets, consisting of 346 instances (or families) with up to tens of millions of vertices. Experimental results show that DmDS obtains the best performance in accuracy for almost all instances and finds much better solutions than state-of-the-art MinDS algorithms on a broad range of large real-world graphs.Here is the text in Simplified Chinese:给定一个图，最小控制集（MinDS）问题是找到最小的集合 $D$ 的 vertices，使得每个不在 $D$ 中的 vertex 都与至少一个在 $D$ 中的 vertex 相邻。这是一个 класси的 $\mathcal{NP}$-hard 问题，广泛的研究了因为它在网络分析中的许多实际应用。现有的 MinDS 规则算法都受到不同的选择情况的限制，这会使得它们的效iveness降低。在这篇论文中，我们提出一种高效的本地搜索算法 для MinDS 问题，名为 DmDS，它使用了一种 dual-mode 本地搜索框架， probabilistically 选择两种不同的 vertex-swapping 策略。为了解决其他算法的限制，我们引入一个基于频率的 vertex 选择标准，以 Address 选择情况中的僵尸性，并 introducing a new strategy to improve the quality of the initial solution via a greedy-based strategy integrated with perturbation。我们对 seven 个 datasets 进行了对比，这些 datasets 包括 346 个实例（或家族），最多达到了 tens of millions 的 vertices。实验结果显示，DmDS 在大多数实例中具有最高的准确性，并在许多实际世界图上发现了 much better 的解决方案，远超现有的 MinDS 算法。
</details></li>
</ul>
<hr>
<h2 id="The-Impact-of-Imperfect-XAI-on-Human-AI-Decision-Making"><a href="#The-Impact-of-Imperfect-XAI-on-Human-AI-Decision-Making" class="headerlink" title="The Impact of Imperfect XAI on Human-AI Decision-Making"></a>The Impact of Imperfect XAI on Human-AI Decision-Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13566">http://arxiv.org/abs/2307.13566</a></li>
<li>repo_url: None</li>
<li>paper_authors: Katelyn Morrison, Philipp Spitzer, Violet Turri, Michelle Feng, Niklas Kühl, Adam Perer</li>
<li>for: 这研究旨在探讨人类和AI协作中如何处理不准确的解释，以提高人类和AI协作的效果。</li>
<li>methods: 本研究采用了混合方法，包括人类参与者136人的混合研究，以评估人类在鸟种识别任务中对不准确解释的影响。</li>
<li>results: 研究发现，不准确解释会影响人类对AI的依赖度和人类-AI团队性能。此外，解释的强度也影响人类的决策行为。这些发现有助于理解人类和AI协作中的不准确解释的影响，并提供设计人类-AI协作系统的指南。<details>
<summary>Abstract</summary>
Explainability techniques are rapidly being developed to improve human-AI decision-making across various cooperative work settings. Consequently, previous research has evaluated how decision-makers collaborate with imperfect AI by investigating appropriate reliance and task performance with the aim of designing more human-centered computer-supported collaborative tools. Several human-centered explainable AI (XAI) techniques have been proposed in hopes of improving decision-makers' collaboration with AI; however, these techniques are grounded in findings from previous studies that primarily focus on the impact of incorrect AI advice. Few studies acknowledge the possibility for the explanations to be incorrect even if the AI advice is correct. Thus, it is crucial to understand how imperfect XAI affects human-AI decision-making. In this work, we contribute a robust, mixed-methods user study with 136 participants to evaluate how incorrect explanations influence humans' decision-making behavior in a bird species identification task taking into account their level of expertise and an explanation's level of assertiveness. Our findings reveal the influence of imperfect XAI and humans' level of expertise on their reliance on AI and human-AI team performance. We also discuss how explanations can deceive decision-makers during human-AI collaboration. Hence, we shed light on the impacts of imperfect XAI in the field of computer-supported cooperative work and provide guidelines for designers of human-AI collaboration systems.
</details>
<details>
<summary>摘要</summary>
<<SYS>>人工智能技术在协作工作场景中快速发展，以提高人机协作决策。先前的研究已经评估了人与不完美AI的协作方式，并设计了更人类中心的计算机支持协作工具。然而，这些技术多数基于先前研究中关注 incorrect AI 建议的影响。很少的研究承认可能存在 incorrect 的解释，即使 AI 建议正确。因此，理解 incorrect XAI 如何影响人机协作决策是关键。在这种情况下，我们通过一项强大的混合方法用户研究，卷入 136 名参与者，评估 incorrect 解释如何影响人们决策行为，包括他们的专业水平和解释的强硬程度。我们的发现表明 incorrect XAI 和参与者的专业水平对人机协作的可靠性和性能产生了影响。我们还讨论了解释如何在人机协作中欺骗决策者。因此，我们为计算机支持协作系统的设计提供了指导，并着重于人机协作中 incorrect XAI 的影响。
</details></li>
</ul>
<hr>
<h2 id="Decision-Focused-Learning-Foundations-State-of-the-Art-Benchmark-and-Future-Opportunities"><a href="#Decision-Focused-Learning-Foundations-State-of-the-Art-Benchmark-and-Future-Opportunities" class="headerlink" title="Decision-Focused Learning: Foundations, State of the Art, Benchmark and Future Opportunities"></a>Decision-Focused Learning: Foundations, State of the Art, Benchmark and Future Opportunities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13565">http://arxiv.org/abs/2307.13565</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/predopt/predopt-benchmarks">https://github.com/predopt/predopt-benchmarks</a></li>
<li>paper_authors: Jayanta Mandi, James Kotary, Senne Berden, Maxime Mulamba, Victor Bucarey, Tias Guns, Ferdinando Fioretto</li>
<li>for: 这篇论文主要是为了介绍决策关注学习（DFL）这一新兴机器学习 paradigma，它将预测和优化结合在一个端到端系统中，以便在不确定环境下做出优化决策。</li>
<li>methods: 论文介绍了各种将机器学习和优化模型集成的技术，并提出了一种分类DFL方法的 Taxonomy，以及一些适用于DFL的测试数据集和任务。</li>
<li>results: 论文进行了广泛的实验评估，对DFL方法进行了valuable的探索和评估，并提供了有价值的Future research direction。<details>
<summary>Abstract</summary>
Decision-focused learning (DFL) is an emerging paradigm in machine learning which trains a model to optimize decisions, integrating prediction and optimization in an end-to-end system. This paradigm holds the promise to revolutionize decision-making in many real-world applications which operate under uncertainty, where the estimation of unknown parameters within these decision models often becomes a substantial roadblock. This paper presents a comprehensive review of DFL. It provides an in-depth analysis of the various techniques devised to integrate machine learning and optimization models, introduces a taxonomy of DFL methods distinguished by their unique characteristics, and conducts an extensive empirical evaluation of these methods proposing suitable benchmark dataset and tasks for DFL. Finally, the study provides valuable insights into current and potential future avenues in DFL research.
</details>
<details>
<summary>摘要</summary>
决策关注学习（DFL）是一种emerging paradigm在机器学习领域，它允许模型通过端到端系统来优化决策，并将预测和优化结合在一起。这种方法在不确定环境下进行决策，对决策模型中未知参数的估计成为了一个重要的障碍。本文提供了DFL的全面回顾，包括不同方法的集成、机器学习和优化模型的分类、以及对这些方法的广泛实验评估。最后，研究还提供了DFL研究的当前和未来可能的方向。Here's the translation of the text in Traditional Chinese:决策关注学习（DFL）是一种emerging paradigm在机器学习领域，它允许模型透过端到端系统来优化决策，并将预测和优化结合在一起。这种方法在不确定环境下进行决策，对决策模型中未知参数的估计成为了一个重要的障碍。本文提供了DFL的全面回顾，包括不同方法的集成、机器学习和优化模型的分类、以及对这些方法的广泛实验评估。最后，研究还提供了DFL研究的现在和未来可能的方向。
</details></li>
</ul>
<hr>
<h2 id="On-Solving-the-Rubik’s-Cube-with-Domain-Independent-Planners-Using-Standard-Representations"><a href="#On-Solving-the-Rubik’s-Cube-with-Domain-Independent-Planners-Using-Standard-Representations" class="headerlink" title="On Solving the Rubik’s Cube with Domain-Independent Planners Using Standard Representations"></a>On Solving the Rubik’s Cube with Domain-Independent Planners Using Standard Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13552">http://arxiv.org/abs/2307.13552</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bharath Muppasani, Vishal Pallagani, Biplav Srivastava, Forest Agostinelli<br>for:这篇论文的目的是将 Rubik’s Cube  puzzle 表示为 PDDL 语言，以便更好地访问 PDDL  планировщики、竞赛和知识工程工具，并使其更易于人类阅读。methods:该论文使用了 PDDL 语言表示 Rubik’s Cube  puzzle，并与现有的方法进行比较。其中包括使用 DeepCubeA 搜索算法和 Scorpion  планировщиker 的 State-Action-Space+ 表示方法，以及 FastDownward 搜索算法和 FF 规则的组合。results:该论文的实验结果显示，使用 PDDL 语言表示 Rubik’s Cube  puzzle可以提高 solve 率，但是不同的表示方法和搜索算法之间存在负荷和优化的贸易offs。Specifically, DeepCubeA 搜索算法可以解决所有问题，但只有78.5%是优化的计划；Scorpion  планировщиker 可以解决61.50%的问题，其中79.64%是优化的计划。<details>
<summary>Abstract</summary>
Rubik's Cube (RC) is a well-known and computationally challenging puzzle that has motivated AI researchers to explore efficient alternative representations and problem-solving methods. The ideal situation for planning here is that a problem be solved optimally and efficiently represented in a standard notation using a general-purpose solver and heuristics. The fastest solver today for RC is DeepCubeA with a custom representation, and another approach is with Scorpion planner with State-Action-Space+ (SAS+) representation. In this paper, we present the first RC representation in the popular PDDL language so that the domain becomes more accessible to PDDL planners, competitions, and knowledge engineering tools, and is more human-readable. We then bridge across existing approaches and compare performance. We find that in one comparable experiment, DeepCubeA (trained with 12 RC actions) solves all problems with varying complexities, albeit only 78.5% are optimal plans. For the same problem set, Scorpion with SAS+ representation and pattern database heuristics solves 61.50% problems optimally, while FastDownward with PDDL representation and FF heuristic solves 56.50% problems, out of which 79.64% of the plans generated were optimal. Our study provides valuable insights into the trade-offs between representational choice and plan optimality that can help researchers design future strategies for challenging domains combining general-purpose solving methods (planning, reinforcement learning), heuristics, and representations (standard or custom).
</details>
<details>
<summary>摘要</summary>
瑞比克立方体（RC）是一个知名且 computationally challenging 的游戏，它激发了人工智能研究者们开发高效的代表法和解决方法。理想情况是将问题解决得最优化地，使用标准notation representation 和通用的解决器和规则。目前最快的解决器是 DeepCubeA  WITH custom representation，另一种方法是使用 Scorpion  плаanner WITH State-Action-Space+（SAS+) representation。在这篇论文中，我们将 RC 的第一个 representation 在流行的 PDDL 语言中提供，使得Domain 变得更加可达性和可读性更高，并且可以用于 PDDL  плаanner、竞赛和知识工程工具。然后，我们将现有的方法相互连接，并比较性能。我们发现在一个相同的实验中，DeepCubeA（已经训练有 12 RC 动作）可以解决具有不同复杂性的所有问题，但只有 78.5% 是优化的方案。对于同一个问题集，Scorpion  WITH SAS+ representation 和模式数据库规则可以解决 61.50% 问题，而 FastDownward  WITH PDDL representation 和 FF 规则可以解决 56.50% 问题，其中 79.64% 的方案是优化的。我们的研究提供了有价值的对于表示选择和方案优化的交易所，可以帮助研究人员设计未来在复杂的 Domain 中结合通用解决方法（规划、强化学习）、规则和表示（标准或自定义）的策略。
</details></li>
</ul>
<hr>
<h2 id="A-Planning-Ontology-to-Represent-and-Exploit-Planning-Knowledge-for-Performance-Efficiency"><a href="#A-Planning-Ontology-to-Represent-and-Exploit-Planning-Knowledge-for-Performance-Efficiency" class="headerlink" title="A Planning Ontology to Represent and Exploit Planning Knowledge for Performance Efficiency"></a>A Planning Ontology to Represent and Exploit Planning Knowledge for Performance Efficiency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13549">http://arxiv.org/abs/2307.13549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bharath Muppasani, Vishal Pallagani, Biplav Srivastava, Raghava Mutharaju, Michael N. Huhns, Vignesh Narayanan</li>
<li>for: 本研究旨在解决自动规划问题，即找到将智能机器人从初始状态转移到目标状态的有效动作序列。</li>
<li>methods: 本研究使用国际规划竞赛（IPC）数据 construct了规划ontology，并通过实验在两个用例中示出ontology可以选择有potential的规划器并提高其性能using macros。</li>
<li>results: 实验结果表明，使用规划ontology可以选择适合域的规划器并提高其性能。同时，研究者还为社区提供了规划ontology和相关资源，以便进一步研究。<details>
<summary>Abstract</summary>
Ontologies are known for their ability to organize rich metadata, support the identification of novel insights via semantic queries, and promote reuse. In this paper, we consider the problem of automated planning, where the objective is to find a sequence of actions that will move an agent from an initial state of the world to a desired goal state. We hypothesize that given a large number of available planners and diverse planning domains; they carry essential information that can be leveraged to identify suitable planners and improve their performance for a domain. We use data on planning domains and planners from the International Planning Competition (IPC) to construct a planning ontology and demonstrate via experiments in two use cases that the ontology can lead to the selection of promising planners and improving their performance using macros - a form of action ordering constraints extracted from planning ontology. We also make the planning ontology and associated resources available to the community to promote further research.
</details>
<details>
<summary>摘要</summary>
Ontologies 知道如何组织富有 metadata，支持通过semantic queries提取新的发现，并促进重用。在这篇论文中，我们考虑自动规划问题， objective 是找到一个将智能机器从初始状态转移到目标状态的 sequences of actions。我们假设， given 大量可用的 плаanner 和多样化的规划领域; 它们携带着重要信息，可以用来选择适合的 плаanner 并提高其性能。我们使用国际规划竞赛（IPC）的数据construct 规划ontology，并通过实验示例二进行了证明，规划ontology 可以选择promising planners 并使其性能提高。我们还将规划ontology 和相关资源公开发布，以便进一步的研究。
</details></li>
</ul>
<hr>
<h2 id="Group-Activity-Recognition-in-Computer-Vision-A-Comprehensive-Review-Challenges-and-Future-Perspectives"><a href="#Group-Activity-Recognition-in-Computer-Vision-A-Comprehensive-Review-Challenges-and-Future-Perspectives" class="headerlink" title="Group Activity Recognition in Computer Vision: A Comprehensive Review, Challenges, and Future Perspectives"></a>Group Activity Recognition in Computer Vision: A Comprehensive Review, Challenges, and Future Perspectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13541">http://arxiv.org/abs/2307.13541</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chuanchuan Wang, Ahmad Sufril Azlan Mohamed</li>
<li>For: 这篇论文主要研究目标是为了提高群体活动识别技术，具体来说是通过Global interactivity和活动的方式进行识别。* Methods: 这篇论文使用了多种方法，包括传统方法、基于空间结构的方法、描述符、非深度学习方法、层次回归神经网络（HRNN）、关系模型和注意机制等。* Results: 这篇论文对群体活动识别方法进行了全面的审视和比较，并提出了一种基于关系网络的模块化方法，并进行了实验验证。<details>
<summary>Abstract</summary>
Group activity recognition is a hot topic in computer vision. Recognizing activities through group relationships plays a vital role in group activity recognition. It holds practical implications in various scenarios, such as video analysis, surveillance, automatic driving, and understanding social activities. The model's key capabilities encompass efficiently modeling hierarchical relationships within a scene and accurately extracting distinctive spatiotemporal features from groups. Given this technology's extensive applicability, identifying group activities has garnered significant research attention. This work examines the current progress in technology for recognizing group activities, with a specific focus on global interactivity and activities. Firstly, we comprehensively review the pertinent literature and various group activity recognition approaches, from traditional methodologies to the latest methods based on spatial structure, descriptors, non-deep learning, hierarchical recurrent neural networks (HRNN), relationship models, and attention mechanisms. Subsequently, we present the relational network and relational architectures for each module. Thirdly, we investigate methods for recognizing group activity and compare their performance with state-of-the-art technologies. We summarize the existing challenges and provide comprehensive guidance for newcomers to understand group activity recognition. Furthermore, we review emerging perspectives in group activity recognition to explore new directions and possibilities.
</details>
<details>
<summary>摘要</summary>
There has been significant research attention on identifying group activities, and this work aims to provide a comprehensive review of the current progress in this field. We will focus on global interactivity and activities, and our approach will include the following steps:1. Literature review: We will review the relevant literature and various group activity recognition approaches, from traditional methodologies to the latest methods based on spatial structure, descriptors, non-deep learning, hierarchical recurrent neural networks (HRNN), relationship models, and attention mechanisms.2. Relational network and architectures: We will present the relational network and relational architectures for each module.3. Methods for recognizing group activity: We will investigate methods for recognizing group activity and compare their performance with state-of-the-art technologies.4. Challenges and future directions: We will summarize the existing challenges and provide comprehensive guidance for newcomers to understand group activity recognition. Additionally, we will review emerging perspectives in group activity recognition to explore new directions and possibilities.Overall, this work aims to provide a comprehensive overview of the current state of group activity recognition technology and its applications, as well as to explore new directions and possibilities for future research.
</details></li>
</ul>
<hr>
<h2 id="Spectrum-guided-Multi-granularity-Referring-Video-Object-Segmentation"><a href="#Spectrum-guided-Multi-granularity-Referring-Video-Object-Segmentation" class="headerlink" title="Spectrum-guided Multi-granularity Referring Video Object Segmentation"></a>Spectrum-guided Multi-granularity Referring Video Object Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13537">http://arxiv.org/abs/2307.13537</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bo-miao/sgmg">https://github.com/bo-miao/sgmg</a></li>
<li>paper_authors: Bo Miao, Mohammed Bennamoun, Yongsheng Gao, Ajmal Mian</li>
<li>for: 这个论文是为了解决现有的视频对象 segmentation (R-VOS) 技术中的 feature drift 问题，以提高 segmentation 效果。</li>
<li>methods: 该论文提出了一种 Spectrum-guided Multi-granularity (SgMg) 方法， Direct segmentation 在编码特征上进行，并使用视觉细节进行优化mask。同时，提出了 Spectrum-guided Cross-modal Fusion (SCF) 方法，在 spectral 频谱上进行了跨模态拟合。</li>
<li>results: 实验表明，SgMg 方法在四个视频测试集上达到了当前最佳性能，与 nearest competitor 相比，提高了2.8% 点的 Ref-YouTube-VOS 性能。同时，通过扩展 SgMg，实现了多对象 R-VOS，不仅快速响应，还可以保持满意的性能。<details>
<summary>Abstract</summary>
Current referring video object segmentation (R-VOS) techniques extract conditional kernels from encoded (low-resolution) vision-language features to segment the decoded high-resolution features. We discovered that this causes significant feature drift, which the segmentation kernels struggle to perceive during the forward computation. This negatively affects the ability of segmentation kernels. To address the drift problem, we propose a Spectrum-guided Multi-granularity (SgMg) approach, which performs direct segmentation on the encoded features and employs visual details to further optimize the masks. In addition, we propose Spectrum-guided Cross-modal Fusion (SCF) to perform intra-frame global interactions in the spectral domain for effective multimodal representation. Finally, we extend SgMg to perform multi-object R-VOS, a new paradigm that enables simultaneous segmentation of multiple referred objects in a video. This not only makes R-VOS faster, but also more practical. Extensive experiments show that SgMg achieves state-of-the-art performance on four video benchmark datasets, outperforming the nearest competitor by 2.8% points on Ref-YouTube-VOS. Our extended SgMg enables multi-object R-VOS, runs about 3 times faster while maintaining satisfactory performance. Code is available at https://github.com/bo-miao/SgMg.
</details>
<details>
<summary>摘要</summary>
当前的视频对象 segmentation (R-VOS) 技术从编码的低分辨率视Language特征中提取条件kernels来 segment decode高分辨率特征。我们发现这会导致重要的特征漂移，使segmentation kernels在前向计算中困难以感知。这 negatively affects the ability of segmentation kernels。为解决这个问题，我们提出了spectrum-guided Multi-granularity (SgMg)方法，它直接在编码特征上进行分 segmentation和使用视觉细节进一步优化Mask。此外，我们提出了spectrum-guided Cross-modal Fusion (SCF)，它在spectral domain中进行了intra-frame global interactions，以实现有效的 Multimodal Representation。 finally，我们扩展了SgMg，以实现多对象R-VOS，一种新的 paradigm，可以同时 segment multiple referred objects in a video。这不仅使R-VOS更快，而且更实用。我们的扩展SgMg在四个视频 benchmark dataset上进行了广泛的实验，并达到了状态的art Performance，比 nearest competitor高2.8%点。我们的扩展SgMg可以在3倍的速度下维持满意的性能。代码可以在https://github.com/bo-miao/SgMg 中找到。
</details></li>
</ul>
<hr>
<h2 id="Re-mine-Learn-and-Reason-Exploring-the-Cross-modal-Semantic-Correlations-for-Language-guided-HOI-detection"><a href="#Re-mine-Learn-and-Reason-Exploring-the-Cross-modal-Semantic-Correlations-for-Language-guided-HOI-detection" class="headerlink" title="Re-mine, Learn and Reason: Exploring the Cross-modal Semantic Correlations for Language-guided HOI detection"></a>Re-mine, Learn and Reason: Exploring the Cross-modal Semantic Correlations for Language-guided HOI detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13529">http://arxiv.org/abs/2307.13529</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yichao Cao, Xiu Su, Qingfei Tang, Feng Yang, Shan You, Xiaobo Lu, Chang Xu</li>
<li>for: 提高人员对象互动（HOI）检测的精度，使用视觉模型解决人员对象互动的复杂关系。</li>
<li>methods: 提出了一个系统atic和统一的框架（RmLR），通过结构化文本知识来增强HOI检测。首先，分析了两阶段HOI检测器中的交互信息损失，并提出了重新挖掘策略来生成更全面的视觉表示。其次，设计了更细化的句子和单词级别对齐和知识传递策略，以有效地解决多个交互和多个文本之间的多对多匹配问题。这些策略可以减轻在多个交互同时发生时出现的匹配混乱问题，从而提高对齐过程的有效性。</li>
<li>results: 实验结果表明，我们的方法可以减轻HOI检测的困难，并在公共测试集上达到状态 искусственный智能性能的最高水平。我们进一步分析了不同组成部分的影响，以便更好地理解我们的方法的作用。<details>
<summary>Abstract</summary>
Human-Object Interaction (HOI) detection is a challenging computer vision task that requires visual models to address the complex interactive relationship between humans and objects and predict HOI triplets. Despite the challenges posed by the numerous interaction combinations, they also offer opportunities for multimodal learning of visual texts. In this paper, we present a systematic and unified framework (RmLR) that enhances HOI detection by incorporating structured text knowledge. Firstly, we qualitatively and quantitatively analyze the loss of interaction information in the two-stage HOI detector and propose a re-mining strategy to generate more comprehensive visual representation.Secondly, we design more fine-grained sentence- and word-level alignment and knowledge transfer strategies to effectively address the many-to-many matching problem between multiple interactions and multiple texts.These strategies alleviate the matching confusion problem that arises when multiple interactions occur simultaneously, thereby improving the effectiveness of the alignment process. Finally, HOI reasoning by visual features augmented with textual knowledge substantially improves the understanding of interactions. Experimental results illustrate the effectiveness of our approach, where state-of-the-art performance is achieved on public benchmarks. We further analyze the effects of different components of our approach to provide insights into its efficacy.
</details>
<details>
<summary>摘要</summary>
人机物交互（HOI）检测是一个复杂的计算机视觉任务，需要视觉模型处理人与物之间的复杂交互关系，并预测HOI triplets。尽管交互组合多样化，但它们也提供了多模式学习视觉文本的机会。在这篇论文中，我们提出了一个系统性和统一的框架（RmLR），增强HOI检测的能力，并包括结构化文本知识。首先，我们质量和量上分析了两stage HOI检测器中的交互信息损失，并提出了重新挖掘策略，以生成更全面的视觉表示。其次，我们设计了更细grained的句子和单词级别对齐和知识传递策略，以有效地Address多对多匹配问题。这些策略可以减少同时发生多个交互时的匹配混乱问题，从而改善对齐过程的效果。最后，通过视觉特征加上文本知识来进行HOI理解，可以大幅提高交互的理解能力。实验结果表明，我们的方法可以在公共 benchMark上达到领先的性能。我们进一步分析了不同组成部分的效果，以提供对其效果的深入分析。
</details></li>
</ul>
<hr>
<h2 id="FacTool-Factuality-Detection-in-Generative-AI-–-A-Tool-Augmented-Framework-for-Multi-Task-and-Multi-Domain-Scenarios"><a href="#FacTool-Factuality-Detection-in-Generative-AI-–-A-Tool-Augmented-Framework-for-Multi-Task-and-Multi-Domain-Scenarios" class="headerlink" title="FacTool: Factuality Detection in Generative AI – A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios"></a>FacTool: Factuality Detection in Generative AI – A Tool Augmented Framework for Multi-Task and Multi-Domain Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13528">http://arxiv.org/abs/2307.13528</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gair-nlp/factool">https://github.com/gair-nlp/factool</a></li>
<li>paper_authors: I-Chun Chern, Steffi Chern, Shiqi Chen, Weizhe Yuan, Kehua Feng, Chunting Zhou, Junxian He, Graham Neubig, Pengfei Liu</li>
<li>for: 检测生成模型中的错误信息</li>
<li>methods: 提出了一个任务和领域无关的框架，用于检测由大语言模型生成的文本中的错误信息</li>
<li>results: 在四个不同的任务（知识基础问答、代码生成、数学逻辑和科学文献评论）中，实验结果表明提出的方法有效。<details>
<summary>Abstract</summary>
The emergence of generative pre-trained models has facilitated the synthesis of high-quality text, but it has also posed challenges in identifying factual errors in the generated text. In particular: (1) A wider range of tasks now face an increasing risk of containing factual errors when handled by generative models. (2) Generated texts tend to be lengthy and lack a clearly defined granularity for individual facts. (3) There is a scarcity of explicit evidence available during the process of fact checking. With the above challenges in mind, in this paper, we propose FacTool, a task and domain agnostic framework for detecting factual errors of texts generated by large language models (e.g., ChatGPT). Experiments on four different tasks (knowledge-based QA, code generation, mathematical reasoning, and scientific literature review) show the efficacy of the proposed method. We release the code of FacTool associated with ChatGPT plugin interface at https://github.com/GAIR-NLP/factool .
</details>
<details>
<summary>摘要</summary>
<<SYS>>请将以下文本翻译成简化中文。<</SYS>>生成模型的出现使得高质量文本的合成变得更加容易，但也使得检测生成文本中的事实错误变得更加困难。特别是：（1）更多的任务现在面临着增加的事实错误风险。（2）生成的文本往往很长，缺乏明确的粒度来分割个别的事实。（3）在 фактиче检查过程中没有明确的证据。为了解决这些挑战，在这篇论文中，我们提出了 FacTool，一种任务和领域无关的检测文本生成模型中的事实错误框架。实验在四个不同的任务（知识基础问答、代码生成、数学推理和科学文献综述）中展示了提案的效果。我们将 FacTool 相关的 ChatGPT 插件接口的代码发布在 GitHub 上，请参考 <https://github.com/GAIR-NLP/factool>。
</details></li>
</ul>
<hr>
<h2 id="An-Empirical-Study-on-Fairness-Improvement-with-Multiple-Protected-Attributes"><a href="#An-Empirical-Study-on-Fairness-Improvement-with-Multiple-Protected-Attributes" class="headerlink" title="An Empirical Study on Fairness Improvement with Multiple Protected Attributes"></a>An Empirical Study on Fairness Improvement with Multiple Protected Attributes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01923">http://arxiv.org/abs/2308.01923</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenpeng Chen, Jie M. Zhang, Federica Sarro, Mark Harman</li>
<li>for: 该论文主要针对多个保护特征的公平性提升，而现有研究多数只是针对单个保护特征进行公平性提升。</li>
<li>methods: 该论文对11种现状顶尖公平性提升方法进行了广泛的研究，并分析了不同的数据集、度量和机器学习模型在考虑多个保护特征时的效果。</li>
<li>results: 研究发现，只考虑单一保护特征进行公平性提升可能会导致其他保护特征的不公平性增加，这种增加的比例可达88.3%（57.5%的平均值）。此外，对多个保护特征进行公平性提升不会带来减少准确性的代价，但是处理多个保护特征时的精度和回归率增加约5倍和8倍。这些结果有重要的意义，将只报告准确性作为机器学习性能指标是不充分的。<details>
<summary>Abstract</summary>
Existing research mostly improves the fairness of Machine Learning (ML) software regarding a single protected attribute at a time, but this is unrealistic given that many users have multiple protected attributes. This paper conducts an extensive study of fairness improvement regarding multiple protected attributes, covering 11 state-of-the-art fairness improvement methods. We analyze the effectiveness of these methods with different datasets, metrics, and ML models when considering multiple protected attributes. The results reveal that improving fairness for a single protected attribute can largely decrease fairness regarding unconsidered protected attributes. This decrease is observed in up to 88.3% of scenarios (57.5% on average). More surprisingly, we find little difference in accuracy loss when considering single and multiple protected attributes, indicating that accuracy can be maintained in the multiple-attribute paradigm. However, the effect on precision and recall when handling multiple protected attributes is about 5 times and 8 times that of a single attribute. This has important implications for future fairness research: reporting only accuracy as the ML performance metric, which is currently common in the literature, is inadequate.
</details>
<details>
<summary>摘要</summary>
现有研究主要是在受保护特征单个方面提高机器学习软件的公平性，但这并不是现实中的情况，用户通常有多个受保护特征。这篇论文进行了多个受保护特征公平性改进的广泛研究，涵盖了11种现状最佳实践方法。我们对不同的数据集、度量和机器学习模型进行了这些方法的分析，并发现了以下结论：在考虑多个受保护特征时，改进公平性对单个受保护特征的改进可以导致其他受保护特征的公平性下降，这种下降的比例在88.3%的情况下（57.5%的平均值）。而且，我们发现在考虑单个和多个受保护特征时，精度的影响几乎没有变化，这意味着在多个受保护特征的情况下，精度可以保持在相同的水平。然而，处理多个受保护特征时，精度和准确率的影响是单个受保护特征的8倍和5倍。这有重要的实践意义：现在流行的 literatura 中报道精度作为机器学习性能指标是不充分的。
</details></li>
</ul>
<hr>
<h2 id="Zshot-An-Open-source-Framework-for-Zero-Shot-Named-Entity-Recognition-and-Relation-Extraction"><a href="#Zshot-An-Open-source-Framework-for-Zero-Shot-Named-Entity-Recognition-and-Relation-Extraction" class="headerlink" title="Zshot: An Open-source Framework for Zero-Shot Named Entity Recognition and Relation Extraction"></a>Zshot: An Open-source Framework for Zero-Shot Named Entity Recognition and Relation Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13497">http://arxiv.org/abs/2307.13497</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gabriele Picco, Marcos Martínez Galindo, Alberto Purpura, Leopold Fuchs, Vanessa López, Hoang Thanh Lam</li>
<li>for: 这项研究的目的是提供一个可比较多种现代Zero-Shot Learning（ZSL）方法的框架，以便研究人员可以通过对标准benchmark数据集进行比较。</li>
<li>methods: 该框架使用了大量预训练语言模型，并提出了许多新的方法，从而导致了ZSL性能的明显提高。</li>
<li>results: 该研究提出了一个名为Zshot的新的ZSL框架，该框架包含了可extendible和可评估的API，以及多种优化技术，如管道 ensemble和可视化工具，以提高ZSL性能。<details>
<summary>Abstract</summary>
The Zero-Shot Learning (ZSL) task pertains to the identification of entities or relations in texts that were not seen during training. ZSL has emerged as a critical research area due to the scarcity of labeled data in specific domains, and its applications have grown significantly in recent years. With the advent of large pretrained language models, several novel methods have been proposed, resulting in substantial improvements in ZSL performance. There is a growing demand, both in the research community and industry, for a comprehensive ZSL framework that facilitates the development and accessibility of the latest methods and pretrained models.In this study, we propose a novel ZSL framework called Zshot that aims to address the aforementioned challenges. Our primary objective is to provide a platform that allows researchers to compare different state-of-the-art ZSL methods with standard benchmark datasets. Additionally, we have designed our framework to support the industry with readily available APIs for production under the standard SpaCy NLP pipeline. Our API is extendible and evaluable, moreover, we include numerous enhancements such as boosting the accuracy with pipeline ensembling and visualization utilities available as a SpaCy extension.
</details>
<details>
<summary>摘要</summary>
zero-shot learning (ZSL) 任务是指在训练中没有看到的文本中预测实体或关系。 ZSL 已成为一个重要的研究领域，因为特定领域的标注数据稀缺，其应用也在过去几年内不断增长。随着大型预训言语模型的出现，一些新的方法被提出，从而导致了 ZSL 性能的明显提升。现在，研究社区和业界均有强烈的需求，一个涵盖最新的 ZSL 方法和预训言语模型的全面框架。在这个研究中，我们提出了一个名为 Zshot 的新的 ZSL 框架，旨在解决以下问题。我们的主要目标是提供一个平台， allowing researchers 可以比较不同的状态对 ZSL 方法的标准 benchmark 数据集。此外，我们设计了我们的框架可以支持产业，通过在 SpaCy NLP 管道中提供可靠的 API。我们的 API 可扩展和评估，其中包括将 pipeline 结合使用以提高准确性，以及可用的 SpaCy 扩展包中的可视化工具。
</details></li>
</ul>
<hr>
<h2 id="Duet-efficient-and-scalable-hybriD-neUral-rElation-undersTanding"><a href="#Duet-efficient-and-scalable-hybriD-neUral-rElation-undersTanding" class="headerlink" title="Duet: efficient and scalable hybriD neUral rElation undersTanding"></a>Duet: efficient and scalable hybriD neUral rElation undersTanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13494">http://arxiv.org/abs/2307.13494</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/GIS-PuppetMaster/Duet">https://github.com/GIS-PuppetMaster/Duet</a></li>
<li>paper_authors: Kaixin Zhang, Hongzhi Wang, Yabin Lu, Ziqi Li, Chang Shu, Yu Yan, Donghua Yang</li>
<li>for: 估算卡尔达ности（cardinality estimation）问题，尤其是在高卡尔达ности和高维度表上，以提高learned cardinality estimator的实际应用。</li>
<li>methods: 引入 predicate information into autoregressive model，并提出了一种稳定、高效、可扩展的混合方法（Duet），可以直接估算卡尔达ности而不需要采样或非 differentiable process，从而降低推理复杂度从 O(n) 降至 O(1)，并在高卡尔达ности和高维度表上达到更高的准确性。</li>
<li>results: 实验结果表明，Duet 可以实现所有设计目标，并在 CPU 上实现更低的推理成本，而且在 GPU 上的大多数学习方法上实现更高的准确性。<details>
<summary>Abstract</summary>
Learned cardinality estimation methods have achieved high precision compared to traditional methods. Among learned methods, query-driven approaches face the data and workload drift problem for a long time. Although both query-driven and hybrid methods are proposed to avoid this problem, even the state-of-the-art of them suffer from high training and estimation costs, limited scalability, instability, and long-tailed distribution problem on high cardinality and high-dimensional tables, which seriously affects the practical application of learned cardinality estimators. In this paper, we prove that most of these problems are directly caused by the widely used progressive sampling. We solve this problem by introducing predicates information into the autoregressive model and propose Duet, a stable, efficient, and scalable hybrid method to estimate cardinality directly without sampling or any non-differentiable process, which can not only reduces the inference complexity from O(n) to O(1) compared to Naru and UAE but also achieve higher accuracy on high cardinality and high-dimensional tables. Experimental results show that Duet can achieve all the design goals above and be much more practical and even has a lower inference cost on CPU than that of most learned methods on GPU.
</details>
<details>
<summary>摘要</summary>
现代学习 cardinality 估计方法已经达到了高精度，比传统方法更高。 among 学习方法中， Query-driven 方法面临着数据和工作负载漂移问题，持续时间很长。 although  Query-driven 和混合方法都是为了避免这个问题，即使是当前最佳的它们也受到高训练和估计成本、有限扩展性、不稳定性和高维度高 cardinality 表的长板块分布问题的影响，这些问题对实际应用 cardinality 估计器产生了严重的影响。在本文中，我们证明了大多数这些问题是由广泛使用进度 sampling 所引起的。我们解决这个问题，通过将 predicate 信息添加到权重 autoregressive 模型，并提出了 Duet，一种稳定、高效和可扩展的混合方法，可以直接无需采样或任何不可微分过程，对高 cardinality 和高维度表进行 cardinality 估计，可以将推理复杂度从 O(n) 降低至 O(1)，比 Naru 和 UAE 更高。实验结果表明，Duet 可以实现所有设计目标，并且在 CPU 上比大多数学习方法在 GPU 上更具实际性，甚至在推理成本方面也更低。
</details></li>
</ul>
<hr>
<h2 id="Integrating-processed-based-models-and-machine-learning-for-crop-yield-prediction"><a href="#Integrating-processed-based-models-and-machine-learning-for-crop-yield-prediction" class="headerlink" title="Integrating processed-based models and machine learning for crop yield prediction"></a>Integrating processed-based models and machine learning for crop yield prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13466">http://arxiv.org/abs/2307.13466</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michiel G. J. Kallenberg, Bernardo Maestrini, Ron van Bree, Paul Ravensbergen, Christos Pylianidis, Frits van Evert, Ioannis N. Athanasiadis</li>
<li>for: 预测哈密瓜产量</li>
<li>methods: 使用混合元模型方法</li>
<li>results: 比基eline方法更好，但需更多实际数据 validate its practical effectiveness。Here’s the full translation of the abstract in Simplified Chinese:预测哈密瓜产量通常 involve theory-driven process-based 植物生长模型，它们在地方条件下困难准确化，或者数据驱动机器学习方法，它们需要大量数据。在这项工作中，我们调查了使用混合元模型方法进行哈密瓜产量预测。我们使用植物生长模型生成了一个数据集，并对其进行(预)训练一个卷积神经网络，然后使用观察数据进行精度调整。在Silico中，我们的元模型方法比基eline方法更好。在实际试验中，我们的方法与植物生长模型相比，在77个商业场景中表现相当，但是在303个试验场景中，两者都比一个简单的直线回归方法和专门设计的预处理方法差一些。我们的发现表明元模型方法在准确预测哈密瓜产量方面有潜力，但是需要更多的实际数据 validate its practical effectiveness。<details>
<summary>Abstract</summary>
Crop yield prediction typically involves the utilization of either theory-driven process-based crop growth models, which have proven to be difficult to calibrate for local conditions, or data-driven machine learning methods, which are known to require large datasets. In this work we investigate potato yield prediction using a hybrid meta-modeling approach. A crop growth model is employed to generate synthetic data for (pre)training a convolutional neural net, which is then fine-tuned with observational data. When applied in silico, our meta-modeling approach yields better predictions than a baseline comprising a purely data-driven approach. When tested on real-world data from field trials (n=303) and commercial fields (n=77), the meta-modeling approach yields competitive results with respect to the crop growth model. In the latter set, however, both models perform worse than a simple linear regression with a hand-picked feature set and dedicated preprocessing designed by domain experts. Our findings indicate the potential of meta-modeling for accurate crop yield prediction; however, further advancements and validation using extensive real-world datasets is recommended to solidify its practical effectiveness.
</details>
<details>
<summary>摘要</summary>
卷积预测通常使用理论驱动的生物物理型或数据驱动机器学方法。前者具有难以调整本地条件的缺点，而后者需要大量数据。在这种工作中，我们调查了混合元模型方法用于预测食用产量。我们使用生长模型生成人工数据，并将其用于（预）训练卷积神经网络，然后精度地调整 Observational data。在虚拟环境中，我们的元模型方法比基准组的数据驱动方法更好。在实际数据集（n=303）和商业场景（n=77）中，元模型方法与生长模型具有相似的性能，但是在这两个场景中，所有模型都比一个简单的直线回归和专门为域专家设计的特定预处理方法更差。我们的发现表明元模型方法在准确预测卷积产量方面有潜力，但是进一步的进展和验证使用广泛的实际数据集是建议的，以固定其实际效果。
</details></li>
</ul>
<hr>
<h2 id="Unlocking-the-Emotional-World-of-Visual-Media-An-Overview-of-the-Science-Research-and-Impact-of-Understanding-Emotion"><a href="#Unlocking-the-Emotional-World-of-Visual-Media-An-Overview-of-the-Science-Research-and-Impact-of-Understanding-Emotion" class="headerlink" title="Unlocking the Emotional World of Visual Media: An Overview of the Science, Research, and Impact of Understanding Emotion"></a>Unlocking the Emotional World of Visual Media: An Overview of the Science, Research, and Impact of Understanding Emotion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13463">http://arxiv.org/abs/2307.13463</a></li>
<li>repo_url: None</li>
<li>paper_authors: James Z. Wang, Sicheng Zhao, Chenyan Wu, Reginald B. Adams, Michelle G. Newman, Tal Shafir, Rachelle Tsachor</li>
<li>for: 这篇论文旨在探讨计算机和机器人领域中人工情感智能技术的发展，以及这种技术如何改变计算机视觉领域的研究。</li>
<li>methods: 这篇论文使用了多种方法，包括心理学、工程学和艺术等多个领域的研究成果，以提供一个全面的、多元的视听媒体情感分析领域的概述。</li>
<li>results: 这篇论文提出了计算机视觉领域中自动理解表达或诱发情感的技术存在一些挑战和限制，并提出了未来研究的重要方向和途径。<details>
<summary>Abstract</summary>
The emergence of artificial emotional intelligence technology is revolutionizing the fields of computers and robotics, allowing for a new level of communication and understanding of human behavior that was once thought impossible. While recent advancements in deep learning have transformed the field of computer vision, automated understanding of evoked or expressed emotions in visual media remains in its infancy. This foundering stems from the absence of a universally accepted definition of "emotion", coupled with the inherently subjective nature of emotions and their intricate nuances. In this article, we provide a comprehensive, multidisciplinary overview of the field of emotion analysis in visual media, drawing on insights from psychology, engineering, and the arts. We begin by exploring the psychological foundations of emotion and the computational principles that underpin the understanding of emotions from images and videos. We then review the latest research and systems within the field, accentuating the most promising approaches. We also discuss the current technological challenges and limitations of emotion analysis, underscoring the necessity for continued investigation and innovation. We contend that this represents a "Holy Grail" research problem in computing and delineate pivotal directions for future inquiry. Finally, we examine the ethical ramifications of emotion-understanding technologies and contemplate their potential societal impacts. Overall, this article endeavors to equip readers with a deeper understanding of the domain of emotion analysis in visual media and to inspire further research and development in this captivating and rapidly evolving field.
</details>
<details>
<summary>摘要</summary>
人工情感智能技术的出现正在改变计算机和机器人领域，allowing for a new level of communication and understanding of human behavior that was once thought impossible.  However, recent advancements in deep learning have transformed the field of computer vision, automated understanding of evoked or expressed emotions in visual media remains in its infancy. This foundering stems from the absence of a universally accepted definition of "emotion", coupled with the inherently subjective nature of emotions and their intricate nuances.In this article, we provide a comprehensive, multidisciplinary overview of the field of emotion analysis in visual media, drawing on insights from psychology, engineering, and the arts. We begin by exploring the psychological foundations of emotion and the computational principles that underpin the understanding of emotions from images and videos. We then review the latest research and systems within the field, accentuating the most promising approaches. We also discuss the current technological challenges and limitations of emotion analysis, underscoring the necessity for continued investigation and innovation. We contend that this represents a "Holy Grail" research problem in computing and delineate pivotal directions for future inquiry.Finally, we examine the ethical ramifications of emotion-understanding technologies and contemplate their potential societal impacts. Overall, this article endeavors to equip readers with a deeper understanding of the domain of emotion analysis in visual media and to inspire further research and development in this captivating and rapidly evolving field.
</details></li>
</ul>
<hr>
<h2 id="Fundamental-causal-bounds-of-quantum-random-access-memories"><a href="#Fundamental-causal-bounds-of-quantum-random-access-memories" class="headerlink" title="Fundamental causal bounds of quantum random access memories"></a>Fundamental causal bounds of quantum random access memories</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13460">http://arxiv.org/abs/2307.13460</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunfei Wang, Yuri Alexeev, Liang Jiang, Frederic T. Chong, Junyu Liu</li>
<li>for: 本研究旨在探讨量子Random Access Memory（QRAM）在量子物理原理下的限制，以确定量子计算应用程序在数据科学领域的长期表现。</li>
<li>methods: 本研究使用相对论和量子多体系统的 Lieb-Robinson  bounds来探讨量子快速记忆器的内在约束。</li>
<li>results: 研究发现，使用量子声学系统的硬件设计，QRAM 可以处理 $\mathcal{O}(10^7)$ 逻辑量子 bits 在一维结构中，而在二维和三维结构中可以处理 $\mathcal{O}(10^{15})$ 到 $\mathcal{O}(10^{20})$ 和 $\mathcal{O}(10^{24})$ 量子 bits  соответpectively。这些约束适用于其他量子硬件系统。研究结果表明，量子物理原理的限制对量子计算应用程序的长期表现有重要的影响，并且提出了可能提高性能的量子记忆器设计。<details>
<summary>Abstract</summary>
Quantum devices should operate in adherence to quantum physics principles. Quantum random access memory (QRAM), a fundamental component of many essential quantum algorithms for tasks such as linear algebra, data search, and machine learning, is often proposed to offer $\mathcal{O}(\log N)$ circuit depth for $\mathcal{O}(N)$ data size, given $N$ qubits. However, this claim appears to breach the principle of relativity when dealing with a large number of qubits in quantum materials interacting locally. In our study we critically explore the intrinsic bounds of rapid quantum memories based on causality, employing the relativistic quantum field theory and Lieb-Robinson bounds in quantum many-body systems. In this paper, we consider a hardware-efficient QRAM design in hybrid quantum acoustic systems. Assuming clock cycle times of approximately $10^{-3}$ seconds and a lattice spacing of about 1 micrometer, we show that QRAM can accommodate up to $\mathcal{O}(10^7)$ logical qubits in 1 dimension, $\mathcal{O}(10^{15})$ to $\mathcal{O}(10^{20})$ in various 2D architectures, and $\mathcal{O}(10^{24})$ in 3 dimensions. We contend that this causality bound broadly applies to other quantum hardware systems. Our findings highlight the impact of fundamental quantum physics constraints on the long-term performance of quantum computing applications in data science and suggest potential quantum memory designs for performance enhancement.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Monte-Carlo-Tree-Search-for-Multi-Agent-Pathfinding-Preliminary-Results"><a href="#Monte-Carlo-Tree-Search-for-Multi-Agent-Pathfinding-Preliminary-Results" class="headerlink" title="Monte-Carlo Tree Search for Multi-Agent Pathfinding: Preliminary Results"></a>Monte-Carlo Tree Search for Multi-Agent Pathfinding: Preliminary Results</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13453">http://arxiv.org/abs/2307.13453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yelisey Pitanov, Alexey Skrynnik, Anton Andreychuk, Konstantin Yakovlev, Aleksandr Panov</li>
<li>for: 这个论文研究了多 Agent Pathfinding 问题，即在图形结构下，每个代理都有唯一的起点和目标点，需要找到一个不受碰撞的多个路径，使每个代理都能够达到其目标点。</li>
<li>methods: 我们使用 Monte-Carlo Tree Search (MCTS) 来解决这个问题。MCTS 在各种问题中表现出色，如游戏等，但在多 Agent Pathfinding 中并未得到广泛研究。我们提出了一种专门为多 Agent Pathfinding 设计的 MCTS 变体。我们在 Compute 奖励的方法中使用了特定的路径来帮助代理人员达到目标点，同时保留了代理人员可以离开路径以避免碰撞的能力。</li>
<li>results: 我们对基eline  планинг算法，例如 A*，进行比较，并证明了我们的方法在多 Agent Pathfinding 中表现出色，超过了基eline 方法。<details>
<summary>Abstract</summary>
In this work we study a well-known and challenging problem of Multi-agent Pathfinding, when a set of agents is confined to a graph, each agent is assigned a unique start and goal vertices and the task is to find a set of collision-free paths (one for each agent) such that each agent reaches its respective goal. We investigate how to utilize Monte-Carlo Tree Search (MCTS) to solve the problem. Although MCTS was shown to demonstrate superior performance in a wide range of problems like playing antagonistic games (e.g. Go, Chess etc.), discovering faster matrix multiplication algorithms etc., its application to the problem at hand was not well studied before. To this end we introduce an original variant of MCTS, tailored to multi-agent pathfinding. The crux of our approach is how the reward, that guides MCTS, is computed. Specifically, we use individual paths to assist the agents with the the goal-reaching behavior, while leaving them freedom to get off the track if it is needed to avoid collisions. We also use a dedicated decomposition technique to reduce the branching factor of the tree search procedure. Empirically we show that the suggested method outperforms the baseline planning algorithm that invokes heuristic search, e.g. A*, at each re-planning step.
</details>
<details>
<summary>摘要</summary>
To address this, we introduce an original variant of MCTS tailored to multi-agent pathfinding. The key aspect of our approach is how the reward, which guides the MCTS, is computed. Specifically, we use individual paths to assist the agents in reaching their goals while allowing them to deviate from the planned path if necessary to avoid collisions. We also employ a dedicated decomposition technique to reduce the branching factor of the tree search procedure.Empirically, we show that our suggested method outperforms a baseline planning algorithm that invokes heuristic search, such as A\*, at each re-planning step.
</details></li>
</ul>
<hr>
<h2 id="A-behavioural-transformer-for-effective-collaboration-between-a-robot-and-a-non-stationary-human"><a href="#A-behavioural-transformer-for-effective-collaboration-between-a-robot-and-a-non-stationary-human" class="headerlink" title="A behavioural transformer for effective collaboration between a robot and a non-stationary human"></a>A behavioural transformer for effective collaboration between a robot and a non-stationary human</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13447">http://arxiv.org/abs/2307.13447</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruaridh Mon-Williams, Theodoros Stouraitis, Sethu Vijayakumar</li>
<li>for:  This paper aims to address the challenges of human-robot collaboration in non-stationary environments, where human behavior changes over time.</li>
<li>methods:  The authors propose a principled meta-learning framework and develop a conditional transformer called Behaviour-Transform (BeTrans) to adapt to new human agents with non-stationary behaviors.</li>
<li>results:  BeTrans effectively collaborates with simulated human agents and adapts faster to non-stationary simulated human agents than state-of-the-art techniques.Here’s the full text in Simplified Chinese:</li>
<li>for: 本研究旨在解决人机合作中的非站点环境问题，其中人类行为随着时间的变化。</li>
<li>methods: 作者提出了一种原理化的元学习框架，并开发了一种名为行为变换（BeTrans）的条件变换器，以适应新的人类代理者具有非站点行为的情况。</li>
<li>results: BeTrans在模拟人类代理者中的原创自定义环境中显示了与非站点模拟人类代理者的更好的协作和更快的适应速度，比STATE-OF-THE-ART技术更高。<details>
<summary>Abstract</summary>
A key challenge in human-robot collaboration is the non-stationarity created by humans due to changes in their behaviour. This alters environmental transitions and hinders human-robot collaboration. We propose a principled meta-learning framework to explore how robots could better predict human behaviour, and thereby deal with issues of non-stationarity. On the basis of this framework, we developed Behaviour-Transform (BeTrans). BeTrans is a conditional transformer that enables a robot agent to adapt quickly to new human agents with non-stationary behaviours, due to its notable performance with sequential data. We trained BeTrans on simulated human agents with different systematic biases in collaborative settings. We used an original customisable environment to show that BeTrans effectively collaborates with simulated human agents and adapts faster to non-stationary simulated human agents than SOTA techniques.
</details>
<details>
<summary>摘要</summary>
人机合作中的一大挑战是由人类行为引起的非站点性，这会导致环境转移和人机合作困难。我们提出了一种原则性的元学习框架，以便让机器人更好地预测人类行为，从而解决非站点性问题。基于这个框架，我们开发了行为变换（BeTrans）。BeTrans 是一种 Conditional Transformer，它允许机器人代理人类快速适应新的非站点人类行为，因为它在序列数据上表现出了显著的性能。我们在模拟人类代理人中进行了训练，并在合作 Setting 中验证了 BeTrans 的效果。我们使用了一个自定义的环境，以示 BeTrans 可以快速适应非站点人类行为，并且比标准技术更快。
</details></li>
</ul>
<hr>
<h2 id="On-the-Learning-Dynamics-of-Attention-Networks"><a href="#On-the-Learning-Dynamics-of-Attention-Networks" class="headerlink" title="On the Learning Dynamics of Attention Networks"></a>On the Learning Dynamics of Attention Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13421">http://arxiv.org/abs/2307.13421</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vashisht-rahul/on-the-learning-dynamics-of-attention-networks">https://github.com/vashisht-rahul/on-the-learning-dynamics-of-attention-networks</a></li>
<li>paper_authors: Rahul Vashisht, Harish G. Ramaswamy</li>
<li>for: 本研究的目的是探讨Attention模型的不同损失函数（soft attention、hard attention和latent variable marginal likelihood（LVML））在模型学习中的影响。</li>
<li>methods: 本研究使用了三种不同的损失函数来训练Attention模型，包括soft attention、hard attention和LVML。</li>
<li>results: 研究发现不同的损失函数会导致Attention模型的不同行为和结果。在训练过程中，使用soft attention损失函数可以让注意力模型在初始化阶段快速改进，但后续会降低。相反，使用hard attention损失函数可以使注意力模型在训练过程中保持稳定。此外，研究还提出了一种简单的混合方法，该方法结合了不同损失函数的优点，并在一些半人工和实际数据集上进行了测试。<details>
<summary>Abstract</summary>
Attention models are typically learned by optimizing one of three standard loss functions that are variously called -- soft attention, hard attention, and latent variable marginal likelihood (LVML) attention. All three paradigms are motivated by the same goal of finding two models -- a `focus' model that `selects' the right \textit{segment} of the input and a `classification' model that processes the selected segment into the target label. However, they differ significantly in the way the selected segments are aggregated, resulting in distinct dynamics and final results. We observe a unique signature of models learned using these paradigms and explain this as a consequence of the evolution of the classification model under gradient descent when the focus model is fixed. We also analyze these paradigms in a simple setting and derive closed-form expressions for the parameter trajectory under gradient flow. With the soft attention loss, the focus model improves quickly at initialization and splutters later on. On the other hand, hard attention loss behaves in the opposite fashion. Based on our observations, we propose a simple hybrid approach that combines the advantages of the different loss functions and demonstrates it on a collection of semi-synthetic and real-world datasets
</details>
<details>
<summary>摘要</summary>
注意模型通常通过优化三种标准损失函数来学习，它们分别被称为软注意力、硬注意力和隐变量概率 marginal likelihood（LVML）注意力。这三种方法都是为了找到两个模型---一个`焦点'模型可以选择正确的输入段落，以及一个`分类'模型可以处理选择的段落并生成目标标签。然而，它们在选取段落的方式不同，从而导致了不同的动力学和最终结果。我们观察到每种模型学习的独特签名，并解释这是因为分类模型在梯度下降过程中的演化。我们还对这些方法进行了简单的分析，并 deriv了关于参数轨迹的关闭式表达式。在软注意力损失函数下，焦点模型在初始化时快速提升，然后后来受阻。相反，硬注意力损失函数 behave in the opposite fashion。基于我们的观察，我们提出了一种简单的混合方法，将不同的损失函数的优点相互融合，并在一些半Synthetic和实际世界数据集上进行了证明。
</details></li>
</ul>
<hr>
<h2 id="Synthesis-of-Procedural-Models-for-Deterministic-Transition-Systems"><a href="#Synthesis-of-Procedural-Models-for-Deterministic-Transition-Systems" class="headerlink" title="Synthesis of Procedural Models for Deterministic Transition Systems"></a>Synthesis of Procedural Models for Deterministic Transition Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14368">http://arxiv.org/abs/2307.14368</a></li>
<li>repo_url: None</li>
<li>paper_authors: Javier Segovia-Aguas, Jonathan Ferrer-Mestres, Sergio Jiménez</li>
<li>for: 这篇论文旨在提出一种总体方法，用于生成某种逻辑系统的状态转移模型。</li>
<li>methods: 该方法采用抽象搜索，在Random-Access Machine（RAM）上使用有限Memory和简单的指令集来生成结构化程序。</li>
<li>results: 该方法可以生成符合给定输入集的状态转移模型，并且可以针对不同的目标语言进行模型化。<details>
<summary>Abstract</summary>
This paper introduces a general approach for synthesizing procedural models of the state-transitions of a given discrete system. The approach is general in that it accepts different target languages for modeling the state-transitions of a discrete system; different model acquisition tasks with different target languages, such as the synthesis of STRIPS action models, or the update rule of a cellular automaton, fit as particular instances of our general approach. We follow an inductive approach to synthesis meaning that a set of examples of state-transitions, represented as (pre-state, action, post-state) tuples, are given as input. The goal is to synthesize a structured program that, when executed on a given pre-state, outputs its associated post-state. Our synthesis method implements a combinatorial search in the space of well-structured terminating programs that can be built using a Random-Access Machine (RAM), with a minimalist instruction set, and a finite amount of memory. The combinatorial search is guided with functions that asses the complexity of the candidate programs, as well as their fitness to the given input set of examples.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-short-review-of-the-main-concerns-in-A-I-development-and-application-within-the-public-sector-supported-by-NLP-and-TM"><a href="#A-short-review-of-the-main-concerns-in-A-I-development-and-application-within-the-public-sector-supported-by-NLP-and-TM" class="headerlink" title="A short review of the main concerns in A.I. development and application within the public sector supported by NLP and TM"></a>A short review of the main concerns in A.I. development and application within the public sector supported by NLP and TM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02042">http://arxiv.org/abs/2308.02042</a></li>
<li>repo_url: None</li>
<li>paper_authors: Carlos Ferreira</li>
<li>for: 这个研究旨在捕捉公共领域中AI应用的数据隐私、伦理、可解释性、信任性和公平性问题的研究趋势。</li>
<li>methods: 该研究使用了NLP和TM基础概念，对ACMDigital Library和IEEE Xplore会议论文进行了两年内的查询和分析，以捕捉相关信息。</li>
<li>results: 研究结果显示，公平性是最常见的关注点，而数据隐私则是最少的关注点（即使它在大多数文章中都是embedded），而信任性则是最为显著的关注点。<details>
<summary>Abstract</summary>
Artificial Intelligence is not a new subject, and business, industry and public sectors have used it in different ways and contexts and considering multiple concerns. This work reviewed research papers published in ACM Digital Library and IEEE Xplore conference proceedings in the last two years supported by fundamental concepts of Natural Language Processing (NLP) and Text Mining (TM). The objective was to capture insights regarding data privacy, ethics, interpretability, explainability, trustworthiness, and fairness in the public sector. The methodology has saved analysis time and could retrieve papers containing relevant information. The results showed that fairness was the most frequent concern. The least prominent topic was data privacy (although embedded in most articles), while the most prominent was trustworthiness. Finally, gathering helpful insights about those concerns regarding A.I. applications in the public sector was also possible.
</details>
<details>
<summary>摘要</summary>
人工智能不是新的话题，商业、工业和公共部门在不同的方式和上下文中使用它，并考虑多种关注。这项工作查询了过去两年ACM数字图书馆和IEEE Xplore会议论文，基于自然语言处理（NLP）和文本挖掘（TM）的基本概念。目标是捕捉公共部门中关于数据隐私、伦理、可解性、可信度和公平性的视角。方法包括文献分析，减少分析时间，检索包含相关信息的论文。结果表明，公平性是最常见的关注点，而数据隐私即使在大多数文章中隐藏，也是最少提到的话题。最后，对于人工智能在公共部门中的应用中有所获得有用的洞察。
</details></li>
</ul>
<hr>
<h2 id="Towards-Bridging-the-Digital-Language-Divide"><a href="#Towards-Bridging-the-Digital-Language-Divide" class="headerlink" title="Towards Bridging the Digital Language Divide"></a>Towards Bridging the Digital Language Divide</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13405">http://arxiv.org/abs/2307.13405</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gábor Bella, Paula Helm, Gertraud Koch, Fausto Giunchiglia</li>
<li>for: 帮助各种语言技术扩展到受欠发达语言领域</li>
<li>methods: 通过对语言技术的研发方法进行修改，以减少语言偏见</li>
<li>results: 通过与本地社区的合作，提高语言技术的多样性和准确性<details>
<summary>Abstract</summary>
It is a well-known fact that current AI-based language technology -- language models, machine translation systems, multilingual dictionaries and corpora -- focuses on the world's 2-3% most widely spoken languages. Recent research efforts have attempted to expand the coverage of AI technology to `under-resourced languages.' The goal of our paper is to bring attention to a phenomenon that we call linguistic bias: multilingual language processing systems often exhibit a hardwired, yet usually involuntary and hidden representational preference towards certain languages. Linguistic bias is manifested in uneven per-language performance even in the case of similar test conditions. We show that biased technology is often the result of research and development methodologies that do not do justice to the complexity of the languages being represented, and that can even become ethically problematic as they disregard valuable aspects of diversity as well as the needs of the language communities themselves. As our attempt at building diversity-aware language resources, we present a new initiative that aims at reducing linguistic bias through both technological design and methodology, based on an eye-level collaboration with local communities.
</details>
<details>
<summary>摘要</summary>
现在的人工智能语言技术，包括语言模型、机器翻译系统、多语言词典和语料库，它们主要集中在世界上2-3%最广泛使用的语言上。 latest research efforts have attempted to expand the coverage of AI technology to "under-resourced languages." However, we have noticed a phenomenon that we call "linguistic bias" in multilingual language processing systems, which exhibits a hardwired yet involuntary and hidden representational preference towards certain languages. This bias is manifested in uneven per-language performance, even under similar test conditions. We argue that biased technology is often the result of research and development methodologies that do not fully consider the complexity of the languages being represented, and can even become ethically problematic as they disregard valuable aspects of diversity and the needs of language communities themselves. To address this issue, we present a new initiative that aims to reduce linguistic bias through both technological design and methodology, based on eye-level collaboration with local communities.
</details></li>
</ul>
<hr>
<h2 id="Predicting-Code-Coverage-without-Execution"><a href="#Predicting-Code-Coverage-without-Execution" class="headerlink" title="Predicting Code Coverage without Execution"></a>Predicting Code Coverage without Execution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13383">http://arxiv.org/abs/2307.13383</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/coverage-eval">https://github.com/microsoft/coverage-eval</a></li>
<li>paper_authors: Michele Tufano, Shubham Chandel, Anisha Agarwal, Neel Sundaresan, Colin Clement</li>
<li>for: 这篇论文的目的是为了评估大语言模型（LLM）对代码执行的理解程度，并提出了一个新的任务——代码覆盖率预测任务。</li>
<li>methods: 该论文使用了机器学习算法来减少计算代码覆盖率的成本，并且使用了人工生成的代码和测试用例来评估模型的性能。</li>
<li>results: 研究发现，OpenAI的GPT-4和GPT-3.5-Turbo、Google的BARD和Anthropic的Claude等四种state-of-the-art LLM在代码覆盖率预测任务中表现出色，并且 argue that code coverage as a metric and pre-training data source are valuable for overall LLM performance on software engineering tasks。<details>
<summary>Abstract</summary>
Code coverage is a widely used metric for quantifying the extent to which program elements, such as statements or branches, are executed during testing. Calculating code coverage is resource-intensive, requiring code building and execution with additional overhead for the instrumentation. Furthermore, computing coverage of any snippet of code requires the whole program context. Using Machine Learning to amortize this expensive process could lower the cost of code coverage by requiring only the source code context, and the task of code coverage prediction can be a novel benchmark for judging the ability of models to understand code. We propose a novel benchmark task called Code Coverage Prediction for Large Language Models (LLMs). We formalize this task to evaluate the capability of LLMs in understanding code execution by determining which lines of a method are executed by a given test case and inputs. We curate and release a dataset we call COVERAGEEVAL by executing tests and code from the HumanEval dataset and collecting code coverage information. We report the performance of four state-of-the-art LLMs used for code-related tasks, including OpenAI's GPT-4 and GPT-3.5-Turbo, Google's BARD, and Anthropic's Claude, on the Code Coverage Prediction task. Finally, we argue that code coverage as a metric and pre-training data source are valuable for overall LLM performance on software engineering tasks.
</details>
<details>
<summary>摘要</summary>
“代码覆盖率”是一个广泛使用的度量来量化程式码中不同元素的执行情况。计算代码覆盖率需要费时consumption，需要将代码建立和执行，并且需要额外的实现工具。此外，计算任何一段代码的覆盖率都需要整个程式码上下文。使用机器学习来优化这个费时的过程可以降低代码覆盖率的成本，只需要提供代码上下文，而不需要整个程式码。我们提出一个新的benchmark任务，名为代码覆盖预测（Code Coverage Prediction），用于评估大型自然语言模型（LLMs）的能力。我们正式定义这个任务，以评估LLMs对代码执行的理解度。我们组织了一个名为COVERAGEEVAL的数据集，通过执行HumanEval测试数据并收集代码覆盖信息。我们报告了四个现代LLMs的表现，包括OpenAI的GPT-4和GPT-3.5-Turbo、Google的BARD、以及Anthropic的Claude，在代码覆盖预测任务上的表现。最后，我们认为代码覆盖率作为度量和预训数据来源是LLM在软件工程任务上的重要因素。”
</details></li>
</ul>
<hr>
<h2 id="Empower-Your-Model-with-Longer-and-Better-Context-Comprehension"><a href="#Empower-Your-Model-with-Longer-and-Better-Context-Comprehension" class="headerlink" title="Empower Your Model with Longer and Better Context Comprehension"></a>Empower Your Model with Longer and Better Context Comprehension</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13365">http://arxiv.org/abs/2307.13365</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yileijin/attention-transition">https://github.com/yileijin/attention-transition</a></li>
<li>paper_authors: Yifei Gao, Lei Wang, Jun Fang, Longhua Hu, Jun Cheng</li>
<li>for: 提高 LL 模型在较长和复杂的上下文中的理解能力，以便更好地应用在实际场景中。</li>
<li>methods: 提出了一种新的技术 called Attention Transition，通过增强模型内部信息传递的能力，使模型能够更好地理解较长的上下文，无需额外训练或影响生成流畅性。</li>
<li>results: 在 XSum 数据集上进行了实验，与 GPT4 进行比较，得到了显著的改善，证明了 Attention Transition 的有效性。<details>
<summary>Abstract</summary>
Recently, with the emergence of numerous Large Language Models (LLMs), the implementation of AI has entered a new era. Irrespective of these models' own capacity and structure, there is a growing demand for LLMs to possess enhanced comprehension of longer and more complex contexts with relatively smaller sizes. Models often encounter an upper limit when processing sequences of sentences that extend beyond their comprehension capacity and result in off-topic or even chaotic responses. While several recent works attempt to address this issue in various ways, they rarely focus on "why models are unable to compensate or strengthen their capabilities on their own". In this paper, we thoroughly investigate the nature of information transfer within LLMs and propose a novel technique called Attention Transition. This technique empowers models to achieve longer and better context comprehension with minimal additional training or impact on generation fluency. Our experiments are conducted on the challenging XSum dataset using LLaMa-7b model with context token length ranging from 800 to 1900. Results demonstrate that we achieve substantial improvements compared with the original generation results evaluated by GPT4.
</details>
<details>
<summary>摘要</summary>
现在，许多大语言模型（LLM）的出现，AI的实现进入了新的时代。无论这些模型的本身能力和结构，有越来越多的需求要LLM具备更好的长文本理解能力，即使文本长度较短。 modeloften encounter an upper limit when processing sequences of sentences that extend beyond their comprehension capacity and result in off-topic or even chaotic responses。 although several recent works attempt to address this issue in various ways, they rarely focus on "why models are unable to compensate or strengthen their capabilities on their own".在这篇论文中，我们全面调查LLM中信息传递的本质，并提出一种新的技术 called Attention Transition。这种技术使得模型可以在不需要额外训练或影响生成流畅性的情况下，实现更长更好的文本理解。我们对XSum数据集使用LLaMa-7b模型，Context Token length在800到1900之间进行了实验。结果显示，我们在评估于GPT4的原始生成结果的基础上获得了显著提高。
</details></li>
</ul>
<hr>
<h2 id="Do-humans-and-Convolutional-Neural-Networks-attend-to-similar-areas-during-scene-classification-Effects-of-task-and-image-type"><a href="#Do-humans-and-Convolutional-Neural-Networks-attend-to-similar-areas-during-scene-classification-Effects-of-task-and-image-type" class="headerlink" title="Do humans and Convolutional Neural Networks attend to similar areas during scene classification: Effects of task and image type"></a>Do humans and Convolutional Neural Networks attend to similar areas during scene classification: Effects of task and image type</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13345">http://arxiv.org/abs/2307.13345</a></li>
<li>repo_url: None</li>
<li>paper_authors: Romy Müller, Marcel Duerschmidt, Julian Ullrich, Carsten Knoll, Sascha Weber, Steffen Seitz</li>
<li>for: 本研究旨在探讨深度学习模型如 convolutional neural networks (CNN) 是如何决定是否与人类注意力相似的因素？而前一代研究主要关注技术因素，很少关注人类注意力的因素。</li>
<li>methods: 我们在 presente 研究中采用了多种任务来诱导人类注意力地图，包括自发的视线探索、意图的视线指向以及手动选择区域。此外，我们还使用了不同类型的图像，包括单一的醒目对象、室内场景和无明确对象定义的类别。</li>
<li>results: 我们发现，人类任务对于图像类型有很大的影响。对于对象，人类手动选择生成的地图和 CNN 的注意力地图最为相似，而自发视线任务干得影响相对较小。对于室内场景，自发视线任务生成的地图和 CNN 的注意力地图最为不同，而手动选择任务生成的地图和 CNN 的注意力地图相似度较高。这些结果表明，在比较人类和 CNN 的注意力时，需要考虑人类因素。<details>
<summary>Abstract</summary>
Deep Learning models like Convolutional Neural Networks (CNN) are powerful image classifiers, but what factors determine whether they attend to similar image areas as humans do? While previous studies have focused on technological factors, little is known about the role of factors that affect human attention. In the present study, we investigated how the tasks used to elicit human attention maps interact with image characteristics in modulating the similarity between humans and CNN. We varied the intentionality of human tasks, ranging from spontaneous gaze during categorization over intentional gaze-pointing up to manual area selection. Moreover, we varied the type of image to be categorized, using either singular, salient objects, indoor scenes consisting of object arrangements, or landscapes without distinct objects defining the category. The human attention maps generated in this way were compared to the CNN attention maps revealed by explainable artificial intelligence (Grad-CAM). The influence of human tasks strongly depended on image type: For objects, human manual selection produced maps that were most similar to CNN, while the specific eye movement task has little impact. For indoor scenes, spontaneous gaze produced the least similarity, while for landscapes, similarity was equally low across all human tasks. To better understand these results, we also compared the different human attention maps to each other. Our results highlight the importance of taking human factors into account when comparing the attention of humans and CNN.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "Deep Learning models" is translated as "深度学习模型" (shēn dào xué xí mó del)* "Convolutional Neural Networks" is translated as "卷积神经网络" (jué shū shēn xīn wǎng luò)* "human attention maps" is translated as "人类注意地图" (rén xìng zhù yì dì tu)* "CNN attention maps" is translated as "CNN注意地图" (CNN zhù yì dì tu)* "explainable artificial intelligence" is translated as "可解释人工智能" (kě jiě jiě rén xīn zhī neng)* "Grad-CAM" is translated as "Grad-CAM" (Grad-CAM)* "human tasks" is translated as "人类任务" (rén xìng zhī yè)* "image characteristics" is translated as "图像特点" (tú xiàng tè qǐ)* "singular objects" is translated as "单一物体" (dan yī wù tǐ)* "indoor scenes" is translated as "室内场景" (shì nérie jīng jì)* "landscapes" is translated as "风景" (fēng jǐng)* "intentionality of human tasks" is translated as "人类任务的意图性" (rén xìng zhī yè de yì tú xìng)* "specific eye movement task" is translated as "特定眼动任务" (tè dìng jǐng yù zhí zhì yè)* "manual area selection" is translated as "手动区域选择" (shǒu dòng qū yù zhì yè)Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="Analyzing-Chain-of-Thought-Prompting-in-Large-Language-Models-via-Gradient-based-Feature-Attributions"><a href="#Analyzing-Chain-of-Thought-Prompting-in-Large-Language-Models-via-Gradient-based-Feature-Attributions" class="headerlink" title="Analyzing Chain-of-Thought Prompting in Large Language Models via Gradient-based Feature Attributions"></a>Analyzing Chain-of-Thought Prompting in Large Language Models via Gradient-based Feature Attributions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13339">http://arxiv.org/abs/2307.13339</a></li>
<li>repo_url: None</li>
<li>paper_authors: Skyler Wu, Eric Meng Shen, Charumathi Badrinath, Jiaqi Ma, Himabindu Lakkaraju</li>
<li>for: 这个论文的目的是解释为何 chain-of-thought (CoT) 提示能使大型自然语言模型（LLM）在各种问答任务上具有更高的准确率。</li>
<li>methods: 这篇论文使用了 gradient-based feature attribution 方法，以生成输入字符串对模型输出的影响度量。</li>
<li>results: 研究发现，CoT 提示不会使输入字符串中相关的 Token 的重要性增加，但可以增加提问和模型输出变化时 Token 的稳定性。<details>
<summary>Abstract</summary>
Chain-of-thought (CoT) prompting has been shown to empirically improve the accuracy of large language models (LLMs) on various question answering tasks. While understanding why CoT prompting is effective is crucial to ensuring that this phenomenon is a consequence of desired model behavior, little work has addressed this; nonetheless, such an understanding is a critical prerequisite for responsible model deployment. We address this question by leveraging gradient-based feature attribution methods which produce saliency scores that capture the influence of input tokens on model output. Specifically, we probe several open-source LLMs to investigate whether CoT prompting affects the relative importances they assign to particular input tokens. Our results indicate that while CoT prompting does not increase the magnitude of saliency scores attributed to semantically relevant tokens in the prompt compared to standard few-shot prompting, it increases the robustness of saliency scores to question perturbations and variations in model output.
</details>
<details>
<summary>摘要</summary>
<<SYS>>chain-of-thought（CoT）提示有效地提高了大型语言模型（LLM）在各种问题回答任务上的准确率。 although understanding why CoT prompting is effective is crucial to ensuring that this phenomenon is a consequence of desired model behavior, little work has addressed this; nonetheless, such an understanding is a critical prerequisite for responsible model deployment. we address this question by leveraging gradient-based feature attribution methods, which produce saliency scores that capture the influence of input tokens on model output. specifically, we probe several open-source LLMs to investigate whether CoT prompting affects the relative importances they assign to particular input tokens. our results indicate that while CoT prompting does not increase the magnitude of saliency scores attributed to semantically relevant tokens in the prompt compared to standard few-shot prompting, it increases the robustness of saliency scores to question perturbations and variations in model output.Note: Please note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="The-Optimal-Approximation-Factors-in-Misspecified-Off-Policy-Value-Function-Estimation"><a href="#The-Optimal-Approximation-Factors-in-Misspecified-Off-Policy-Value-Function-Estimation" class="headerlink" title="The Optimal Approximation Factors in Misspecified Off-Policy Value Function Estimation"></a>The Optimal Approximation Factors in Misspecified Off-Policy Value Function Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13332">http://arxiv.org/abs/2307.13332</a></li>
<li>repo_url: None</li>
<li>paper_authors: Philip Amortila, Nan Jiang, Csaba Szepesvári</li>
<li>for: 这篇论文是关于 reinforcement learning（RL）中的函数估计精度的研究。特别是研究函数估计精度如何受到函数错误的影响。</li>
<li>methods: 这篇论文使用了 linear off-policy value function estimation 方法，并在不同的设定下（如 weighted $L_2$-norm、$L_\infty$ norm、状态别名和状态空间覆盖率）研究了函数估计精度的优化因子。</li>
<li>results: 研究发现，在不同的设定下，函数估计精度受到多个因素的影响，其中包括函数错误和状态别名等。这些因素的优化因子可以用来评估函数估计精度的困难程度。<details>
<summary>Abstract</summary>
Theoretical guarantees in reinforcement learning (RL) are known to suffer multiplicative blow-up factors with respect to the misspecification error of function approximation. Yet, the nature of such \emph{approximation factors} -- especially their optimal form in a given learning problem -- is poorly understood. In this paper we study this question in linear off-policy value function estimation, where many open questions remain. We study the approximation factor in a broad spectrum of settings, such as with the weighted $L_2$-norm (where the weighting is the offline state distribution), the $L_\infty$ norm, the presence vs. absence of state aliasing, and full vs. partial coverage of the state space. We establish the optimal asymptotic approximation factors (up to constants) for all of these settings. In particular, our bounds identify two instance-dependent factors for the $L_2(\mu)$ norm and only one for the $L_\infty$ norm, which are shown to dictate the hardness of off-policy evaluation under misspecification.
</details>
<details>
<summary>摘要</summary>
theoretical guarantees in reinforcement learning (RL) 知道 suffer 多个 multiplication blow-up factors with respect to the misspecification error of function approximation. yet, the nature of such approximation factors -- especially their optimal form in a given learning problem -- is poorly understood. In this paper, we study this question in linear off-policy value function estimation, where many open questions remain. We study the approximation factor in a broad spectrum of settings, such as with the weighted $L_2$-norm (where the weighting is the offline state distribution), the $L_\infty$ norm, the presence vs. absence of state aliasing, and full vs. partial coverage of the state space. We establish the optimal asymptotic approximation factors (up to constants) for all of these settings. In particular, our bounds identify two instance-dependent factors for the $L_2(\mu)$ norm and only one for the $L_\infty$ norm, which are shown to dictate the hardness of off-policy evaluation under misspecification.Here's the Chinese translation of the text:理论保证在强化学习（RL）中知道会受到函数近似错误的多个多项式增长因素的影响。然而，这些近似因素的最佳形式在给定的学习问题中仍然不够了解。在这篇论文中，我们研究了这个问题在线性偏离策略估值函数估计中，这里有许多未解之处。我们在各种设置下研究了近似因素，包括使用权重$L_2$-norm（其权重是在线状态分布上）、$L_\infty$ norm、状态别名和状态空间的完整性 vs. 部分覆盖。我们确定了所有设置的优化的极限增长因素（即常数），并且发现了这些因素在不正确的函数近似下的评估难度。 Specifically, our bounds identify two instance-dependent factors for the $L_2(\mu)$ norm and only one for the $L_\infty$ norm, which are shown to dictate the hardness of off-policy evaluation under misspecification.这里的 bounds 发现了 $L_2(\mu)$ norm 下的两个实例依赖的因素，以及 $L_\infty$ norm 下的一个因素，这些因素在函数近似错误下的评估难度。
</details></li>
</ul>
<hr>
<h2 id="2-Level-Reinforcement-Learning-for-Ships-on-Inland-Waterways"><a href="#2-Level-Reinforcement-Learning-for-Ships-on-Inland-Waterways" class="headerlink" title="2-Level Reinforcement Learning for Ships on Inland Waterways"></a>2-Level Reinforcement Learning for Ships on Inland Waterways</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16769">http://arxiv.org/abs/2307.16769</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/marwaltz/tud_rl">https://github.com/marwaltz/tud_rl</a></li>
<li>paper_authors: Martin Waltz, Niklas Paulig, Ostap Okhrin</li>
<li>for: 这个论文目的是控制自主水面车（ASV）在内陆水道（IW）上，基于深度强化学习（DRL）。</li>
<li>methods: 该框架包括两级：一级是高级本地路径规划（LPP）单元，另一级是低级路径跟踪（PF）单元，每个单元都包含一个DRL代理。LPP代理负责考虑附近船只、交通规则和水道的几何，而PF代理负责低级杆控制，并考虑水下船只的杆控制、环境力量（风、浪、涨潮）的影响。</li>
<li>results: 在模拟环境中，两个代理都进行了广泛验证，使用德国北部的下落河为例子，并使用实际的AIS轨迹来模拟其他船只的行为。<details>
<summary>Abstract</summary>
This paper proposes a realistic modularized framework for controlling autonomous surface vehicles (ASVs) on inland waterways (IWs) based on deep reinforcement learning (DRL). The framework comprises two levels: a high-level local path planning (LPP) unit and a low-level path following (PF) unit, each consisting of a DRL agent. The LPP agent is responsible for planning a path under consideration of nearby vessels, traffic rules, and the geometry of the waterway. We thereby leverage a recently proposed spatial-temporal recurrent neural network architecture, which is transferred to continuous action spaces. The PF agent is responsible for low-level actuator control while accounting for shallow water influences on the marine craft and the environmental forces winds, waves, and currents. Both agents are thoroughly validated in simulation, employing the lower Elbe in northern Germany as an example case and using real AIS trajectories to model the behavior of other ships.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Learning-Autonomous-Ultrasound-via-Latent-Task-Representation-and-Robotic-Skills-Adaptation"><a href="#Learning-Autonomous-Ultrasound-via-Latent-Task-Representation-and-Robotic-Skills-Adaptation" class="headerlink" title="Learning Autonomous Ultrasound via Latent Task Representation and Robotic Skills Adaptation"></a>Learning Autonomous Ultrasound via Latent Task Representation and Robotic Skills Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13323">http://arxiv.org/abs/2307.13323</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xutian Deng, Junnan Jiang, Wen Cheng, Miao Li</li>
<li>for: 提高机器人超声扫描的自动化精度和效率</li>
<li>methods: 使用多Modal ultrasound技术和自动适应学习方法</li>
<li>results: 实验结果显示，提议方法可以生成适应不同人群的复杂超声策略，并实现了对比较好的量化结果<details>
<summary>Abstract</summary>
As medical ultrasound is becoming a prevailing examination approach nowadays, robotic ultrasound systems can facilitate the scanning process and prevent professional sonographers from repetitive and tedious work. Despite the recent progress, it is still a challenge to enable robots to autonomously accomplish the ultrasound examination, which is largely due to the lack of a proper task representation method, and also an adaptation approach to generalize learned skills across different patients. To solve these problems, we propose the latent task representation and the robotic skills adaptation for autonomous ultrasound in this paper. During the offline stage, the multimodal ultrasound skills are merged and encapsulated into a low-dimensional probability model through a fully self-supervised framework, which takes clinically demonstrated ultrasound images, probe orientations, and contact forces into account. During the online stage, the probability model will select and evaluate the optimal prediction. For unstable singularities, the adaptive optimizer fine-tunes them to near and stable predictions in high-confidence regions. Experimental results show that the proposed approach can generate complex ultrasound strategies for diverse populations and achieve significantly better quantitative results than our previous method.
</details>
<details>
<summary>摘要</summary>
现在医疗超声成为主流检查方法，Robotic超声系统可以帮助扫描过程，避免专业医疗人员的重复和厌烦工作。尽管最近做出了一些进步，但是还是面临着自动完成超声检查的挑战，主要原因是缺乏适当的任务表示方法，以及将学习到的技能通用化到不同的病人身上。为解决这些问题，我们在这篇论文中提出了缺失任务表示和机器人技能适应。在线阶段，我们使用了完全自我超vised框架，将多modal超声技能集成到低维度概率模型中，考虑了临床证明的超声图像、探针 orientations和触摸力。在线阶段，概率模型会选择和评估最佳预测。对于不稳定的孤点，适应优化器进行了微调，使其在高信任区域靠近和稳定预测。实验结果表明，我们的方法可以生成适应不同人口的复杂超声策略，并取得了significantly更好的量化结果，比我们之前的方法更好。
</details></li>
</ul>
<hr>
<h2 id="Towards-Integrated-Traffic-Control-with-Operating-Decentralized-Autonomous-Organization"><a href="#Towards-Integrated-Traffic-Control-with-Operating-Decentralized-Autonomous-Organization" class="headerlink" title="Towards Integrated Traffic Control with Operating Decentralized Autonomous Organization"></a>Towards Integrated Traffic Control with Operating Decentralized Autonomous Organization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03769">http://arxiv.org/abs/2308.03769</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shengyue Yao, Jingru Yu, Yi Yu, Jia Xu, Xingyuan Dai, Honghai Li, Fei-Yue Wang, Yilun Lin</li>
<li>for: 提高智能交通系统（ITS）的集成控制能力，考虑多种多样智能代理的优化和扩展。</li>
<li>methods: 基于分布式自治组织（DAO）框架，实现全局能源消耗效率（ECE）的全球协商，并通过奖励机制优化本地目标。另外，对DAO结构硬直性问题进行了解决方案。</li>
<li>results: 通过 numerics 实验，提出的方法可以在各种情况下更快达成全局目标，并且可以提高本地目标。这表明该方法在智能交通系统集成控制中具有潜在的应用前景。<details>
<summary>Abstract</summary>
With a growing complexity of the intelligent traffic system (ITS), an integrated control of ITS that is capable of considering plentiful heterogeneous intelligent agents is desired. However, existing control methods based on the centralized or the decentralized scheme have not presented their competencies in considering the optimality and the scalability simultaneously. To address this issue, we propose an integrated control method based on the framework of Decentralized Autonomous Organization (DAO). The proposed method achieves a global consensus on energy consumption efficiency (ECE), meanwhile to optimize the local objectives of all involved intelligent agents, through a consensus and incentive mechanism. Furthermore, an operation algorithm is proposed regarding the issue of structural rigidity in DAO. Specifically, the proposed operation approach identifies critical agents to execute the smart contract in DAO, which ultimately extends the capability of DAO-based control. In addition, a numerical experiment is designed to examine the performance of the proposed method. The experiment results indicate that the controlled agents can achieve a consensus faster on the global objective with improved local objectives by the proposed method, compare to existing decentralized control methods. In general, the proposed method shows a great potential in developing an integrated control system in the ITS
</details>
<details>
<summary>摘要</summary>
随着智能交通系统（ITS）的复杂度的增加，一种能够考虑丰富多种智能代理人的集中化控制方法是感到需要。然而，现有的中央化或分布式控制方法未能同时考虑优化和可扩展性。为解决这个问题，我们提议一种基于分布式自治组织（DAO）的集中化控制方法。该方法可以在全球范围内达成能源消耗效率（ECE）的全球协议，同时通过协议和激励机制来优化所有参与的智能代理人的本地目标。此外，我们还提出了一种对 DAO 的结构硬直性问题的操作算法。具体来说，该算法可以在 DAO 中标识关键代理人执行智能合同，从而扩展 DAO 基础的能力。此外，我们还设计了一个数值实验，以评估提议方法的性能。实验结果表明，由于提议方法，控制代理人可以更快达成全球目标，并且提高本地目标。总之，我们的方法在智能交通系统中集中化控制方法具有很大的潜力。
</details></li>
</ul>
<hr>
<h2 id="Word-Sense-Disambiguation-as-a-Game-of-Neurosymbolic-Darts"><a href="#Word-Sense-Disambiguation-as-a-Game-of-Neurosymbolic-Darts" class="headerlink" title="Word Sense Disambiguation as a Game of Neurosymbolic Darts"></a>Word Sense Disambiguation as a Game of Neurosymbolic Darts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16663">http://arxiv.org/abs/2307.16663</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tiansi Dong, Rafet Sifa</li>
<li>for: 本研究旨在提出一种新的神经符号方法来解决自然语言理解和知识工程中的词意划分问题。</li>
<li>methods: 该方法基于一种嵌入式的 Configuration of Nested Balls (CNB) 模型，其中每个词 embedding 的中心点具有一定的稳定性，并且可以准确地表示词义的含义。而 inclusion 关系 между球体可以准确地表示符号 гиперonym 关系 между词义，从而实现了简单的逻辑推理。</li>
<li>results: 在使用预训练 n-ball 嵌入后，我们在 WSD 数据集上进行了一系列实验，并取得了 F1 分数在 90.1% 到 100.0% 之间的结果。这表明了我们的方法可以超越深度学习方法的楼层效果。<details>
<summary>Abstract</summary>
Word Sense Disambiguation (WSD) is one of the hardest tasks in natural language understanding and knowledge engineering. The glass ceiling of 80% F1 score is recently achieved through supervised deep-learning, enriched by a variety of knowledge graphs. Here, we propose a novel neurosymbolic methodology that is able to push the F1 score above 90%. The core of our methodology is a neurosymbolic sense embedding, in terms of a configuration of nested balls in n-dimensional space. The centre point of a ball well-preserves word embedding, which partially fix the locations of balls. Inclusion relations among balls precisely encode symbolic hypernym relations among senses, and enable simple logic deduction among sense embeddings, which cannot be realised before. We trained a Transformer to learn the mapping from a contextualized word embedding to its sense ball embedding, just like playing the game of darts (a game of shooting darts into a dartboard). A series of experiments are conducted by utilizing pre-training n-ball embeddings, which have the coverage of around 70% training data and 75% testing data in the benchmark WSD corpus. The F1 scores in experiments range from 90.1% to 100.0% in all six groups of test data-sets (each group has 4 testing data with different sizes of n-ball embeddings). Our novel neurosymbolic methodology has the potential to break the ceiling of deep-learning approaches for WSD. Limitations and extensions of our current works are listed.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Imperceptible-Physical-Attack-against-Face-Recognition-Systems-via-LED-Illumination-Modulation"><a href="#Imperceptible-Physical-Attack-against-Face-Recognition-Systems-via-LED-Illumination-Modulation" class="headerlink" title="Imperceptible Physical Attack against Face Recognition Systems via LED Illumination Modulation"></a>Imperceptible Physical Attack against Face Recognition Systems via LED Illumination Modulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13294">http://arxiv.org/abs/2307.13294</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junbin Fang, Canjian Jiang, You Jiang, Puxi Lin, Zhaojie Chen, Yujing Sun, Siu-Ming Yiu, Zoe L. Jiang</li>
<li>for: 本研究旨在提出一种实用、执行、不显而又低计算量的LED照明模拓ersion adversarial攻击，以攻击数据驱动的面Recognition视系统。</li>
<li>methods: 该攻击方法基于LED照明模拓ersion，通过快速幅度调整场景LED照明的强度来生成不可见的明暗变化，并利用CMOS图像感知器的滚动闸效果，将明暗信息加入到捕捉到的脸像中。</li>
<li>results: 对于Well-known的面检测模型Dlib、MTCNN和RetinaFace，DoS攻击达成率分别为97.67%、100%和100%，而对于面验证模型Dlib、FaceNet和ArcFace，掩饰攻击达成率均为100%。<details>
<summary>Abstract</summary>
Although face recognition starts to play an important role in our daily life, we need to pay attention that data-driven face recognition vision systems are vulnerable to adversarial attacks. However, the current two categories of adversarial attacks, namely digital attacks and physical attacks both have drawbacks, with the former ones impractical and the latter one conspicuous, high-computational and inexecutable. To address the issues, we propose a practical, executable, inconspicuous and low computational adversarial attack based on LED illumination modulation. To fool the systems, the proposed attack generates imperceptible luminance changes to human eyes through fast intensity modulation of scene LED illumination and uses the rolling shutter effect of CMOS image sensors in face recognition systems to implant luminance information perturbation to the captured face images. In summary,we present a denial-of-service (DoS) attack for face detection and a dodging attack for face verification. We also evaluate their effectiveness against well-known face detection models, Dlib, MTCNN and RetinaFace , and face verification models, Dlib, FaceNet,and ArcFace.The extensive experiments show that the success rates of DoS attacks against face detection models reach 97.67%, 100%, and 100%, respectively, and the success rates of dodging attacks against all face verification models reach 100%.
</details>
<details>
<summary>摘要</summary>
尽管人脸识别开始在我们日常生活中扮演重要角色，但是我们需要注意到数据驱动的人脸识别视觉系统容易受到反对攻击。然而，当前两种反对攻击方法，即数字攻击和物理攻击都有缺点，前者不实用，后者突出、计算高、不执行。为了解决这些问题，我们提议一种实用、执行、不露出来、计算低的反对攻击方法，基于LED照明模拟。通过快速强度模拟场景LED照明的快速强度变化，并使用CMOS图像感知器中的滚动闸效果，我们生成不可见的明暗变化，让人类眼睛无法感受到。总之，我们提出了一种人脸检测系统的拒绝服务（DoS）攻击和躲避攻击，并对知名的人脸检测模型Dlib、MTCNN和RetinaFace，以及人脸验证模型Dlib、FaceNet和ArcFace进行了广泛的测试，结果显示，对人脸检测模型的DoS攻击成功率为97.67%、100%和100%，对所有人脸验证模型的躲避攻击成功率均为100%。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Learning-based-Adaptation-and-Scheduling-Methods-for-Multi-source-DASH"><a href="#Reinforcement-Learning-based-Adaptation-and-Scheduling-Methods-for-Multi-source-DASH" class="headerlink" title="Reinforcement Learning -based Adaptation and Scheduling Methods for Multi-source DASH"></a>Reinforcement Learning -based Adaptation and Scheduling Methods for Multi-source DASH</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11621">http://arxiv.org/abs/2308.11621</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ntnghia1908/Master_Thesis">https://github.com/ntnghia1908/Master_Thesis</a></li>
<li>paper_authors: Nghia T. Nguyen, Long Luu, Phuong L. Vo, Thi Thanh Sang Nguyen, Cuong T. Do, Ngoc-thanh Nguyen</li>
<li>for: 这个论文主要研究多源视频流ING的高质量体验（QoE）优化。</li>
<li>methods: 该论文提出了两种RL算法来优化多源视频流的QoE：RL-based adaptation with greedy scheduling（RLAGS）和RL-based adaptation and scheduling（RLAS）。</li>
<li>results: 经过广泛的 simulations  validate 了提出的算法的效率。<details>
<summary>Abstract</summary>
Dynamic adaptive streaming over HTTP (DASH) has been widely used in video streaming recently. In DASH, the client downloads video chunks in order from a server. The rate adaptation function at the video client enhances the user's quality-of-experience (QoE) by choosing a suitable quality level for each video chunk to download based on the network condition. Today networks such as content delivery networks, edge caching networks, content-centric networks,... usually replicate video contents on multiple cache nodes. We study video streaming from multiple sources in this work. In multi-source streaming, video chunks may arrive out of order due to different conditions of the network paths. Hence, to guarantee a high QoE, the video client needs not only rate adaptation but also chunk scheduling. Reinforcement learning (RL) has emerged as the state-of-the-art control method in various fields in recent years. This paper proposes two algorithms for streaming from multiple sources: RL-based adaptation with greedy scheduling (RLAGS) and RL-based adaptation and scheduling (RLAS). We also build a simulation environment for training and evaluating. The efficiency of the proposed algorithms is proved via extensive simulations with real-trace data.
</details>
<details>
<summary>摘要</summary>
“对于多源串流，由于不同的网络路径，可能会有弹性的播放顺序。因此，确保高质量体验（QoE）需要不仅进行率适应，还需要进行块调度。对于多源串流，本文提出了两个算法：基于强化学习（RL）的适应调度（RLAGS）和基于RL的适应调度和调度（RLAS）。我们还建立了一个实验环境，用于训练和评估。经过广泛的实验，我们证明了提案的算法的效率。”Note: Simplified Chinese is used here, as it is more commonly used in mainland China and is the standard for most online content. Traditional Chinese is used in Taiwan and Hong Kong, and is a more complex and nuanced version of the language.
</details></li>
</ul>
<hr>
<h2 id="Curvature-based-Transformer-for-Molecular-Property-Prediction"><a href="#Curvature-based-Transformer-for-Molecular-Property-Prediction" class="headerlink" title="Curvature-based Transformer for Molecular Property Prediction"></a>Curvature-based Transformer for Molecular Property Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13275">http://arxiv.org/abs/2307.13275</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yili Chen, Zhengyu Li, Zheng Wan, Hui Yu, Xian Wei</li>
<li>for: 提高基于人工智能的药物设计中分子属性预测的能力</li>
<li>methods: 引入Discretization of Ricci Curvature来提高图像神经网络模型对分子图数据的结构信息抽取能力</li>
<li>results: 在PCQM4M-LST、MoleculeNet等化学分子数据集上进行了实验，与Uni-Mol、Graphormer等模型进行比较，结果表明该方法可以达到状态艺术的结果，并且证明了Discretized Ricci curvature可以反映分子结构和功能关系。<details>
<summary>Abstract</summary>
The prediction of molecular properties is one of the most important and challenging tasks in the field of artificial intelligence-based drug design. Among the current mainstream methods, the most commonly used feature representation for training DNN models is based on SMILES and molecular graphs, although these methods are concise and effective, they also limit the ability to capture spatial information. In this work, we propose Curvature-based Transformer to improve the ability of Graph Transformer neural network models to extract structural information on molecular graph data by introducing Discretization of Ricci Curvature. To embed the curvature in the model, we add the curvature information of the graph as positional Encoding to the node features during the attention-score calculation. This method can introduce curvature information from graph data without changing the original network architecture, and it has the potential to be extended to other models. We performed experiments on chemical molecular datasets including PCQM4M-LST, MoleculeNet and compared with models such as Uni-Mol, Graphormer, and the results show that this method can achieve the state-of-the-art results. It is proved that the discretized Ricci curvature also reflects the structural and functional relationship while describing the local geometry of the graph molecular data.
</details>
<details>
<summary>摘要</summary>
预测分子性质是人工智能基于药物设计的一个最重要和挑战性任务。现有主流方法中，最常用的特征表示方法是基于SMILES和分子图，尽管这些方法简洁有效，但它们也限制了捕捉空间信息的能力。在这种工作中，我们提出了几何基于变换器的Curvature-based Transformer，以提高分子图数据中的结构信息提取能力。为了嵌入曲率信息，我们在节点特征计算时将拟合分数加入节点特征中，从而将曲率信息作为位置编码。这种方法可以在原始网络结构不变的情况下，将曲率信息引入模型，并且具有扩展性。我们在PCQM4M-LST、MoleculeNet等化学分子数据集上进行了实验，并与Uni-Mol、Graphormer等模型进行比较，结果表明，这种方法可以实现领先的结果。此外，我们还发现，积分 Ricci 曲率也可以反映分子结构和功能关系，并描述分子图数据的地方几何结构。
</details></li>
</ul>
<hr>
<h2 id="Unbiased-Weight-Maximization"><a href="#Unbiased-Weight-Maximization" class="headerlink" title="Unbiased Weight Maximization"></a>Unbiased Weight Maximization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13270">http://arxiv.org/abs/2307.13270</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stephen Chung</li>
<li>for: 本研究旨在提出一种生物学可能性的人工神经网络（ANN）训练方法，即将每个单元视为一个随机强化学习（RL）代理，从而将网络视为一群代理。这种方法可以更好地模仿生物系统中观察到的 synaptic plasticity 的形式。</li>
<li>methods: 本研究使用的方法包括 REINFORCE 本地学习规则，以及一种名为 Weight Maximization 的新方法。Weight Maximization 将每个隐藏单元的奖励信号替换为其发射量的 нор，从而让每个隐藏单元可以最大化其发射量的 norm 而不是全局奖励信号。</li>
<li>results: 研究人员通过分析Weight Maximization的理论性质和提出一种变体 Unbiased Weight Maximization，发现这种新的学习规则可以提高学习速度和最终性能。特别是，在我们所知道的情况下，这是第一种不偏不倚于网络单元数量的学习规则，可以快速地学习一个 Bernoulli-logistic 网络。<details>
<summary>Abstract</summary>
A biologically plausible method for training an Artificial Neural Network (ANN) involves treating each unit as a stochastic Reinforcement Learning (RL) agent, thereby considering the network as a team of agents. Consequently, all units can learn via REINFORCE, a local learning rule modulated by a global reward signal, which aligns more closely with biologically observed forms of synaptic plasticity. Nevertheless, this learning method is often slow and scales poorly with network size due to inefficient structural credit assignment, since a single reward signal is broadcast to all units without considering individual contributions. Weight Maximization, a proposed solution, replaces a unit's reward signal with the norm of its outgoing weight, thereby allowing each hidden unit to maximize the norm of the outgoing weight instead of the global reward signal. In this research report, we analyze the theoretical properties of Weight Maximization and propose a variant, Unbiased Weight Maximization. This new approach provides an unbiased learning rule that increases learning speed and improves asymptotic performance. Notably, to our knowledge, this is the first learning rule for a network of Bernoulli-logistic units that is unbiased and scales well with the number of network's units in terms of learning speed.
</details>
<details>
<summary>摘要</summary>
一种生物学可能性的方法 для训练人工神经网络（ANN）是将每个单元视为一个随机强化学习（RL）代理，从而考虑网络为一群代理。因此，所有单元都可以通过REINFORCE本地学习规则，该规则由全局奖励信号修饰，更加接近生物观察到的 synaptic plasticity 形式。然而，这种学习方法通常慢速并且与网络大小成比例差化学分，因为不充分考虑单元各自的贡献。Weight Maximization 是一种提议的解决方案，它将每个隐藏单元的奖励信号替换为单元的出口权重的 нор，从而让每个隐藏单元可以最大化出口权重的 norm 而不是全局奖励信号。在这份研究报告中，我们分析了Weight Maximization 的理论性质和一种变体，即偏函数Weight Maximization。这种新的学习规则提供了一种不偏学习规则，可以提高学习速度和最终性能。值得注意的是，到我们所知，这是一种可以快速学习和与网络单元数量成比例增长的学习规则，对于一个由 Bernoulli-logistic 单元组成的网络来说。
</details></li>
</ul>
<hr>
<h2 id="LoraHub-Efficient-Cross-Task-Generalization-via-Dynamic-LoRA-Composition"><a href="#LoraHub-Efficient-Cross-Task-Generalization-via-Dynamic-LoRA-Composition" class="headerlink" title="LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition"></a>LoraHub: Efficient Cross-Task Generalization via Dynamic LoRA Composition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13269">http://arxiv.org/abs/2307.13269</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sail-sg/lorahub">https://github.com/sail-sg/lorahub</a></li>
<li>paper_authors: Chengsong Huang, Qian Liu, Bill Yuchen Lin, Tianyu Pang, Chao Du, Min Lin</li>
<li>for: 这篇论文旨在研究LoRA（低级别适应）的可组合性，以实现新任务的适应性。</li>
<li>methods: 该论文提出了LoraHub框架，可以策略性地组合多个LoRA模块，从多个任务中学习各种不同的技能。</li>
<li>results: 实验结果表明，LoraHub可以在几个shot数据量的情况下，模拟内在学习的表现，而不需要具体的例子。此外，LoraHub的组合不需要新的参数或梯度。<details>
<summary>Abstract</summary>
Low-rank adaptations (LoRA) are often employed to fine-tune large language models (LLMs) for new tasks. This paper investigates LoRA composability for cross-task generalization and introduces LoraHub, a strategic framework devised for the purposive assembly of LoRA modules trained on diverse given tasks, with the objective of achieving adaptable performance on unseen tasks. With just a few examples from a novel task, LoraHub enables the fluid combination of multiple LoRA modules, eradicating the need for human expertise. Notably, the composition requires neither additional model parameters nor gradients. Our empirical results, derived from the Big-Bench Hard (BBH) benchmark, suggest that LoraHub can effectively mimic the performance of in-context learning in few-shot scenarios, excluding the necessity of in-context examples alongside each inference input. A significant contribution of our research is the fostering of a community for LoRA, where users can share their trained LoRA modules, thereby facilitating their application to new tasks. We anticipate this resource will widen access to and spur advancements in general intelligence as well as LLMs in production. Code will be available at https://github.com/sail-sg/lorahub.
</details>
<details>
<summary>摘要</summary>
低阶 adaptations（LoRA）常用于细化大语言模型（LLM）以适应新任务。这篇论文研究LoRA的可组合性，并提出了LoraHub，一个战略性框架，用于策略性将LoRA模块训练在多种任务上，以实现对未看过任务的适应性。只需几个例子，LoraHub可以快速组合多个LoRA模块，不需要人工专业知识。更重要的是，组合不需要额外参数或梯度。我们的实验结果，基于Big-Bench Hard（BBH）benchmark，表明LoraHub可以有效模拟少数例大学习的表现，排除需要在每个推理输入 alongside的具体例子。我们的研究的一个重要贡献是推动LoRA社区，用户可以共享自己训练好的LoRA模块，从而使其应用于新任务。我们预计这种资源将扩大LLM的应用范围和推动生产环境中的普通智能。代码将在https://github.com/sail-sg/lorahub上提供。
</details></li>
</ul>
<hr>
<h2 id="Federated-Split-Learning-with-Only-Positive-Labels-for-resource-constrained-IoT-environment"><a href="#Federated-Split-Learning-with-Only-Positive-Labels-for-resource-constrained-IoT-environment" class="headerlink" title="Federated Split Learning with Only Positive Labels for resource-constrained IoT environment"></a>Federated Split Learning with Only Positive Labels for resource-constrained IoT environment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13266">http://arxiv.org/abs/2307.13266</a></li>
<li>repo_url: None</li>
<li>paper_authors: Praveen Joshi, Chandra Thapa, Mohammed Hasanuzzaman, Ted Scully, Haithem Afli</li>
<li>for: 提高 IoT 设备数据隐私和提高模型训练效率</li>
<li>methods: 使用 federated split learning (SFPL) 技术，包括随机洗涤数据和本地批量正则化</li>
<li>results: SFPL 比 SFL 提高了模型训练效率和精度，具体比例为：	+ CIFAR-100 数据集上 ResNet-56 和 ResNet-32 模型的比例分别为 51.54 和 32.57	+ CIFAR-10 数据集上 ResNet-32 和 ResNet-8 模型的比例分别为 9.23 和 8.52<details>
<summary>Abstract</summary>
Distributed collaborative machine learning (DCML) is a promising method in the Internet of Things (IoT) domain for training deep learning models, as data is distributed across multiple devices. A key advantage of this approach is that it improves data privacy by removing the necessity for the centralized aggregation of raw data but also empowers IoT devices with low computational power. Among various techniques in a DCML framework, federated split learning, known as splitfed learning (SFL), is the most suitable for efficient training and testing when devices have limited computational capabilities. Nevertheless, when resource-constrained IoT devices have only positive labeled data, multiclass classification deep learning models in SFL fail to converge or provide suboptimal results. To overcome these challenges, we propose splitfed learning with positive labels (SFPL). SFPL applies a random shuffling function to the smashed data received from clients before supplying it to the server for model training. Additionally, SFPL incorporates the local batch normalization for the client-side model portion during the inference phase. Our results demonstrate that SFPL outperforms SFL: (i) by factors of 51.54 and 32.57 for ResNet-56 and ResNet-32, respectively, with the CIFAR-100 dataset, and (ii) by factors of 9.23 and 8.52 for ResNet-32 and ResNet-8, respectively, with CIFAR-10 dataset. Overall, this investigation underscores the efficacy of the proposed SFPL framework in DCML.
</details>
<details>
<summary>摘要</summary>
“分布式合作机器学习（DCML）是互联网东西（IoT）领域的一种有前途的方法，用于训练深度学习模型，因为数据分布在多个设备上。这种方法的优点在于，它提高了数据隐私，因为不需要将原始数据集中化，同时也使得 IoT 设备 WITH 较低的计算能力得到启发。在 DCML 框架中， federated split learning（SFL）是最适合高效地训练和测试，因为设备具有有限的计算能力。然而，当 IoT 设备具有只有正例数据时，SFL 中的多类分类深度学习模型无法实现或提供低效果。为了解决这些挑战，我们提出了 splitfed learning with positive labels（SFPL）。SFPL 使用随机排序函数将客户端上收到的数据进行销毁，然后将其提供给服务器进行模型训练。此外，SFPL 还在推理阶段添加了本地批处理正则化。我们的结果表明，SFPL 在 CIFAR-100 和 CIFAR-10  datasets 上分别比 SFL 提高了51.54 和 32.57 倍，并且在 CIFAR-10  datasets 上比 SFL 提高了9.23 和 8.52 倍。总的来说，这种研究证明了我们提出的 SFPL 框架在 DCML 中的效果。”Note: Please note that the translation is in Simplified Chinese, and the words and phrases in bold are the ones that are translated.
</details></li>
</ul>
<hr>
<h2 id="Structural-Credit-Assignment-with-Coordinated-Exploration"><a href="#Structural-Credit-Assignment-with-Coordinated-Exploration" class="headerlink" title="Structural Credit Assignment with Coordinated Exploration"></a>Structural Credit Assignment with Coordinated Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13256">http://arxiv.org/abs/2307.13256</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stephen Chung</li>
<li>for: 训练人工神经网络（ANN），使用生物学可能性的方法。</li>
<li>methods: 每个单元 treated as 随机强化学习（RL）代理，使用REINFORCE本地学习规则，且受到全局奖励信号的调整，更加符合生物观察到的 synaptic plasticity 形式。</li>
<li>results: 协调探索可以大幅提高训练速度，并且可以超过 straight-through estimator（STE）反propagation。<details>
<summary>Abstract</summary>
A biologically plausible method for training an Artificial Neural Network (ANN) involves treating each unit as a stochastic Reinforcement Learning (RL) agent, thereby considering the network as a team of agents. Consequently, all units can learn via REINFORCE, a local learning rule modulated by a global reward signal, which aligns more closely with biologically observed forms of synaptic plasticity. However, this learning method tends to be slow and does not scale well with the size of the network. This inefficiency arises from two factors impeding effective structural credit assignment: (i) all units independently explore the network, and (ii) a single reward is used to evaluate the actions of all units. Accordingly, methods aimed at improving structural credit assignment can generally be classified into two categories. The first category includes algorithms that enable coordinated exploration among units, such as MAP propagation. The second category encompasses algorithms that compute a more specific reward signal for each unit within the network, like Weight Maximization and its variants. In this research report, our focus is on the first category. We propose the use of Boltzmann machines or a recurrent network for coordinated exploration. We show that the negative phase, which is typically necessary to train Boltzmann machines, can be removed. The resulting learning rules are similar to the reward-modulated Hebbian learning rule. Experimental results demonstrate that coordinated exploration significantly exceeds independent exploration in training speed for multiple stochastic and discrete units based on REINFORCE, even surpassing straight-through estimator (STE) backpropagation.
</details>
<details>
<summary>摘要</summary>
一种生物学可能性的人工神经网络（ANN）训练方法是将每个单元视为一个随机奖励学习（RL）代理，从而考虑网络为一个团队。因此，所有单元都可以通过REINFORCE本地学习规则，该规则由全局奖励信号调整，更加接近生物观察到的 synaptic plasticity 形式。然而，这种学习方法通常慢并不能Scalable 到网络的大小。这种缺效果来自两个因素：（i）所有单元独立探索网络，（ii）全网络使用单一奖励评价所有单元的行为。因此，可以将方法分为两类：第一类包括使用MAP卷积算法进行协调探索的算法，第二类包括计算网络内每个单元的具体奖励信号的算法，如Weight Maximization 和其变种。在这份研究报告中，我们注重第一类。我们提议使用 Boltzmann 机或回归网络进行协调探索。我们发现，通常需要训练 Boltzmann 机的负阶可以被除去，其结果的学习规则与奖励调整的 Hebbian 学习规则类似。实验结果表明，协调探索在多个随机和离散单元基于 REINFORCE 训练速度上明显超过独立探索，甚至超过 straight-through estimator（STE）反propagation。
</details></li>
</ul>
<hr>
<h2 id="GaPro-Box-Supervised-3D-Point-Cloud-Instance-Segmentation-Using-Gaussian-Processes-as-Pseudo-Labelers"><a href="#GaPro-Box-Supervised-3D-Point-Cloud-Instance-Segmentation-Using-Gaussian-Processes-as-Pseudo-Labelers" class="headerlink" title="GaPro: Box-Supervised 3D Point Cloud Instance Segmentation Using Gaussian Processes as Pseudo Labelers"></a>GaPro: Box-Supervised 3D Point Cloud Instance Segmentation Using Gaussian Processes as Pseudo Labelers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13251">http://arxiv.org/abs/2307.13251</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vinairesearch/gapro">https://github.com/vinairesearch/gapro</a></li>
<li>paper_authors: Tuan Duc Ngo, Binh-Son Hua, Khoi Nguyen</li>
<li>for: 这篇论文主要针对的是3D点云实例分割的问题，即使使用软指导下进行解决。</li>
<li>methods: 我们提出了一种新的实例分割方法，即使使用软指导下进行解决。我们的方法包括从矩形框签到实例分割网络的训练。此外，我们还使用了自适应策略来进一步提高方法的性能。</li>
<li>results: 我们的实验表明，我们的方法可以比前一代软指导下的实例分割方法表现更好，并且与现有的全指导方法具有相似的性能。此外，我们还证明了我们的方法可以适应不同的全指导方法，只需使用我们生成的 Pseudo 标签进行训练即可。<details>
<summary>Abstract</summary>
Instance segmentation on 3D point clouds (3DIS) is a longstanding challenge in computer vision, where state-of-the-art methods are mainly based on full supervision. As annotating ground truth dense instance masks is tedious and expensive, solving 3DIS with weak supervision has become more practical. In this paper, we propose GaPro, a new instance segmentation for 3D point clouds using axis-aligned 3D bounding box supervision. Our two-step approach involves generating pseudo labels from box annotations and training a 3DIS network with the resulting labels. Additionally, we employ the self-training strategy to improve the performance of our method further. We devise an effective Gaussian Process to generate pseudo instance masks from the bounding boxes and resolve ambiguities when they overlap, resulting in pseudo instance masks with their uncertainty values. Our experiments show that GaPro outperforms previous weakly supervised 3D instance segmentation methods and has competitive performance compared to state-of-the-art fully supervised ones. Furthermore, we demonstrate the robustness of our approach, where we can adapt various state-of-the-art fully supervised methods to the weak supervision task by using our pseudo labels for training. The source code and trained models are available at https://github.com/VinAIResearch/GaPro.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="RoSAS-Deep-Semi-Supervised-Anomaly-Detection-with-Contamination-Resilient-Continuous-Supervision"><a href="#RoSAS-Deep-Semi-Supervised-Anomaly-Detection-with-Contamination-Resilient-Continuous-Supervision" class="headerlink" title="RoSAS: Deep Semi-Supervised Anomaly Detection with Contamination-Resilient Continuous Supervision"></a>RoSAS: Deep Semi-Supervised Anomaly Detection with Contamination-Resilient Continuous Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13239">http://arxiv.org/abs/2307.13239</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xuhongzuo/rosas">https://github.com/xuhongzuo/rosas</a></li>
<li>paper_authors: Hongzuo Xu, Yijie Wang, Guansong Pang, Songlei Jian, Ning Liu, Yongjun Wang<br>for: 这篇论文是为了解决半有向式异常检测方法中的两个限制而撰写的。这两个限制分别是：1）无法处理没有标签的异常（即异常污染），这可能导致学习过程中的混乱；2）仅使用类别型标签（例如二进制或排序标签），这会导致异常分析 scores 的学习得到极其连续的分布。methods: 这篇论文提出了一种新的半有向式异常检测方法，其中提案了一种称为“污染抑制连续超级指导”的新方法。这种方法利用标签的混合来创建新的标签数据，以减少异常污染的影响。同时，这种方法还加入了一个对应于特征学习的目标，以增强网络的弹性和适应力。results: 根据11个真实世界数据集的实验结果，这篇论文的方法与现有的竞争者相比，能够提高20%-30%的AUC-PR表现，并且在不同的异常污染水平和标签数量中具有更好的适应能力和更高的稳定性。<details>
<summary>Abstract</summary>
Semi-supervised anomaly detection methods leverage a few anomaly examples to yield drastically improved performance compared to unsupervised models. However, they still suffer from two limitations: 1) unlabeled anomalies (i.e., anomaly contamination) may mislead the learning process when all the unlabeled data are employed as inliers for model training; 2) only discrete supervision information (such as binary or ordinal data labels) is exploited, which leads to suboptimal learning of anomaly scores that essentially take on a continuous distribution. Therefore, this paper proposes a novel semi-supervised anomaly detection method, which devises \textit{contamination-resilient continuous supervisory signals}. Specifically, we propose a mass interpolation method to diffuse the abnormality of labeled anomalies, thereby creating new data samples labeled with continuous abnormal degrees. Meanwhile, the contaminated area can be covered by new data samples generated via combinations of data with correct labels. A feature learning-based objective is added to serve as an optimization constraint to regularize the network and further enhance the robustness w.r.t. anomaly contamination. Extensive experiments on 11 real-world datasets show that our approach significantly outperforms state-of-the-art competitors by 20%-30% in AUC-PR and obtains more robust and superior performance in settings with different anomaly contamination levels and varying numbers of labeled anomalies. The source code is available at https://github.com/xuhongzuo/rosas/.
</details>
<details>
<summary>摘要</summary>
semi-supervised异常检测方法可以利用一些异常示例来提高性能，但它们仍然受到两种限制：1）无标签异常（即异常污染）可能会导致学习过程中的干扰，当所有无标签数据被用作模型训练时；2）只利用精确的数据标签（如二进制或排序数据标签），这会导致异常分数的学习被强制为精确的连续分布。因此，本文提出了一种新的 semi-supervised异常检测方法，即使用“污染 resistant 连续指导信号”。具体来说，我们提出了一种质量 interpolating 方法，以填充标记为异常的数据中的异常性，并创建新的数据样本，其标签为连续的异常度。同时，污染区域可以被新生成的数据样本覆盖，这些样本由正确标签的数据组合生成。此外，我们还添加了一个基于特征学习的目标函数，以便为抗污染regular化网络，进一步提高对异常污染的Robustness。我们在11个实际世界数据集上进行了广泛的实验，结果表明，我们的方法在AUC-PR方面比状态艺术竞争者提高20%-30%，并在不同的异常污染水平和变量数量的情况下具有更加稳定和优秀的性能。代码可以在https://github.com/xuhongzuo/rosas/获取。
</details></li>
</ul>
<hr>
<h2 id="Multilevel-Large-Language-Models-for-Everyone"><a href="#Multilevel-Large-Language-Models-for-Everyone" class="headerlink" title="Multilevel Large Language Models for Everyone"></a>Multilevel Large Language Models for Everyone</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13221">http://arxiv.org/abs/2307.13221</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanhao Gong</li>
<li>for: 将大语言模型连接到一起，实现更高级别的功能，基于用户个人输入和互联网信息。</li>
<li>methods: 利用人脑蓝图的多层次结构，连接通用和专业型大语言模型，以实现更高效的自然语言处理、计算机视觉任务、专业助手、商业和医疗应用。</li>
<li>results: 提出了一种基于用户个人输入和互联网信息的多层次大语言模型，可以减少冗余并提高性能，适用于多种应用场景。<details>
<summary>Abstract</summary>
Large language models have made significant progress in the past few years. However, they are either generic {\it or} field specific, splitting the community into different groups. In this paper, we unify these large language models into a larger map, where the generic {\it and} specific models are linked together and can improve each other, based on the user personal input and information from the internet. The idea of linking several large language models together is inspired by the functionality of human brain. The specific regions on the brain cortex are specific for certain low level functionality. And these regions can jointly work together to achieve more complex high level functionality. Such behavior on human brain cortex sheds the light to design the multilevel large language models that contain global level, field level and user level models. The user level models run on local machines to achieve efficient response and protect the user's privacy. Such multilevel models reduce some redundancy and perform better than the single level models. The proposed multilevel idea can be applied in various applications, such as natural language processing, computer vision tasks, professional assistant, business and healthcare.
</details>
<details>
<summary>摘要</summary>
Our multilevel approach includes global, field, and user levels, with user-level models running on local machines to ensure efficient response and protect user privacy. This approach reduces redundancy and performs better than single-level models, and it can be applied to various applications such as natural language processing, computer vision tasks, professional assistance, business, and healthcare.
</details></li>
</ul>
<hr>
<h2 id="One-for-Multiple-Physics-informed-Synthetic-Data-Boosts-Generalizable-Deep-Learning-for-Fast-MRI-Reconstruction"><a href="#One-for-Multiple-Physics-informed-Synthetic-Data-Boosts-Generalizable-Deep-Learning-for-Fast-MRI-Reconstruction" class="headerlink" title="One for Multiple: Physics-informed Synthetic Data Boosts Generalizable Deep Learning for Fast MRI Reconstruction"></a>One for Multiple: Physics-informed Synthetic Data Boosts Generalizable Deep Learning for Fast MRI Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13220">http://arxiv.org/abs/2307.13220</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangziblake/pisf">https://github.com/wangziblake/pisf</a></li>
<li>paper_authors: Zi Wang, Xiaotong Yu, Chengyan Wang, Weibo Chen, Jiazheng Wang, Ying-Hua Chu, Hongwei Sun, Rushuai Li, Peiyong Li, Fan Yang, Haiwei Han, Taishan Kang, Jianzhong Lin, Chen Yang, Shufu Chang, Zhang Shi, Sha Hua, Yan Li, Juan Hu, Liuhong Zhu, Jianjun Zhou, Meijing Lin, Jiefeng Guo, Congbo Cai, Zhong Chen, Di Guo, Xiaobo Qu<br>for:这个研究旨在提高快速磁共振成像（MRI）的扫描时间，并使用深度学习（DL）来进行图像重建。methods:本研究使用了一个名为Physics-Informed Synthetic data learning framework（PISF），这是一个可以在多个实验设计下进行测试和训练的框架。PISF使用了一个单一的训练模型，可以在多个实验设计下进行图像重建。results:研究发现，使用PISF可以实现对多种实验设计的图像重建，并且可以在实验设计之间进行一致性的重建。此外，PISF还可以在不同的显示器和中心之间进行一致性的重建。对10名医生进行评价后，PISF的优秀适应性得到了证明。<details>
<summary>Abstract</summary>
Magnetic resonance imaging (MRI) is a principal radiological modality that provides radiation-free, abundant, and diverse information about the whole human body for medical diagnosis, but suffers from prolonged scan time. The scan time can be significantly reduced through k-space undersampling but the introduced artifacts need to be removed in image reconstruction. Although deep learning (DL) has emerged as a powerful tool for image reconstruction in fast MRI, its potential in multiple imaging scenarios remains largely untapped. This is because not only collecting large-scale and diverse realistic training data is generally costly and privacy-restricted, but also existing DL methods are hard to handle the practically inevitable mismatch between training and target data. Here, we present a Physics-Informed Synthetic data learning framework for Fast MRI, called PISF, which is the first to enable generalizable DL for multi-scenario MRI reconstruction using solely one trained model. For a 2D image, the reconstruction is separated into many 1D basic problems and starts with the 1D data synthesis, to facilitate generalization. We demonstrate that training DL models on synthetic data, integrated with enhanced learning techniques, can achieve comparable or even better in vivo MRI reconstruction compared to models trained on a matched realistic dataset, reducing the demand for real-world MRI data by up to 96%. Moreover, our PISF shows impressive generalizability in multi-vendor multi-center imaging. Its excellent adaptability to patients has been verified through 10 experienced doctors' evaluations. PISF provides a feasible and cost-effective way to markedly boost the widespread usage of DL in various fast MRI applications, while freeing from the intractable ethical and practical considerations of in vivo human data acquisitions.
</details>
<details>
<summary>摘要</summary>
To address these challenges, we present a Physics-Informed Synthetic data learning framework for Fast MRI, called PISF. This framework enables generalizable DL for multi-scenario MRI reconstruction using solely one trained model. For a 2D image, the reconstruction is separated into many 1D basic problems, starting with 1D data synthesis to facilitate generalization. We demonstrate that training DL models on synthetic data, integrated with enhanced learning techniques, can achieve comparable or even better in vivo MRI reconstruction compared to models trained on a matched realistic dataset, reducing the demand for real-world MRI data by up to 96%. Moreover, our PISF shows impressive generalizability in multi-vendor multi-center imaging, and its excellent adaptability to patients has been verified through 10 experienced doctors' evaluations.PISF provides a feasible and cost-effective way to markedly boost the widespread usage of DL in various fast MRI applications, while freeing from the intractable ethical and practical considerations of in vivo human data acquisitions.
</details></li>
</ul>
<hr>
<h2 id="Adversarial-Deep-Hedging-Learning-to-Hedge-without-Price-Process-Modeling"><a href="#Adversarial-Deep-Hedging-Learning-to-Hedge-without-Price-Process-Modeling" class="headerlink" title="Adversarial Deep Hedging: Learning to Hedge without Price Process Modeling"></a>Adversarial Deep Hedging: Learning to Hedge without Price Process Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13217">http://arxiv.org/abs/2307.13217</a></li>
<li>repo_url: None</li>
<li>paper_authors: Masanori Hirano, Kentaro Minami, Kentaro Imajo</li>
<li>for: 这个论文是为了探讨deep hedging框架在不完全市场中的应用，以及如何使用机器学习来 Addressing Market frictions和其他实际市场条件。</li>
<li>methods: 这个论文提出了一种新的框架，即对抗深度减值（Adversarial Deep Hedging），它是基于对抗学习的。在这个框架中，一个农家和一个生成器，分别模拟了基础资产过程和基础资产过程，在对抗的情况下被训练。这种方法可以不Explicitly model the underlying asset process，并且可以学习一个Robust hedger。</li>
<li>results: 通过numerical experiments，我们示示了我们的提议方法在实际市场数据上的竞争性表现。<details>
<summary>Abstract</summary>
Deep hedging is a deep-learning-based framework for derivative hedging in incomplete markets. The advantage of deep hedging lies in its ability to handle various realistic market conditions, such as market frictions, which are challenging to address within the traditional mathematical finance framework. Since deep hedging relies on market simulation, the underlying asset price process model is crucial. However, existing literature on deep hedging often relies on traditional mathematical finance models, e.g., Brownian motion and stochastic volatility models, and discovering effective underlying asset models for deep hedging learning has been a challenge. In this study, we propose a new framework called adversarial deep hedging, inspired by adversarial learning. In this framework, a hedger and a generator, which respectively model the underlying asset process and the underlying asset process, are trained in an adversarial manner. The proposed method enables to learn a robust hedger without explicitly modeling the underlying asset process. Through numerical experiments, we demonstrate that our proposed method achieves competitive performance to models that assume explicit underlying asset processes across various real market data.
</details>
<details>
<summary>摘要</summary>
深度投资是一种基于深度学习的derivative投资框架，可以在不完全市场中实现效果性的补偿。深度投资的优点在于它可以处理不同的实际市场条件，如市场阻力，这些条件在传统的数学金融框架中很难处理。深度投资基于市场模拟，因此下面资产价值过程模型是关键。然而，现有的文献中的深度投资经常采用传统的数学金融模型，如 Браунов运动和随机振荡模型，找到有效的下面资产模型 для深度投资学习是一个挑战。在这项研究中，我们提出了一种新的框架，即反对抗深度投资， inspirited by adversarial learning。在这个框架中，一个投资者和一个生成器，分别模拟下面资产过程和下面资产过程，在对抗的方式下进行训练。我们的提议的方法可以不Explicitly模型下面资产过程，却可以学习一个有效的投资者。通过数值实验，我们示出了我们的提议方法可以与假设下面资产过程的模型相比，在各种实际市场数据上达到竞争性的性能。
</details></li>
</ul>
<hr>
<h2 id="FedMEKT-Distillation-based-Embedding-Knowledge-Transfer-for-Multimodal-Federated-Learning"><a href="#FedMEKT-Distillation-based-Embedding-Knowledge-Transfer-for-Multimodal-Federated-Learning" class="headerlink" title="FedMEKT: Distillation-based Embedding Knowledge Transfer for Multimodal Federated Learning"></a>FedMEKT: Distillation-based Embedding Knowledge Transfer for Multimodal Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13214">http://arxiv.org/abs/2307.13214</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huy Q. Le, Minh N. H. Nguyen, Chu Myaet Thwal, Yu Qiao, Chaoning Zhang, Choong Seon Hong</li>
<li>for: 提出了一种基于多模态学习的联合学习框架，以便在多个客户端协同训练一个通用全球模型，而不需要分享私人数据。</li>
<li>methods: 提出了一种 semi-supervised learning 方法，使得客户端可以从不同的模式中提取表示，并将其交换到服务器和客户端中。同时，我们还提出了一种基于液化的多模态嵌入知识传输机制，以便在客户端和服务器之间共享知识。</li>
<li>results: 经过广泛的实验，我们发现 FedMEKT 可以在多modal human activity recognition 任务中提高全球编码器性能，同时保护用户隐私和个人数据，并且需要更少的通信成本。<details>
<summary>Abstract</summary>
Federated learning (FL) enables a decentralized machine learning paradigm for multiple clients to collaboratively train a generalized global model without sharing their private data. Most existing works simply propose typical FL systems for single-modal data, thus limiting its potential on exploiting valuable multimodal data for future personalized applications. Furthermore, the majority of FL approaches still rely on the labeled data at the client side, which is limited in real-world applications due to the inability of self-annotation from users. In light of these limitations, we propose a novel multimodal FL framework that employs a semi-supervised learning approach to leverage the representations from different modalities. Bringing this concept into a system, we develop a distillation-based multimodal embedding knowledge transfer mechanism, namely FedMEKT, which allows the server and clients to exchange the joint knowledge of their learning models extracted from a small multimodal proxy dataset. Our FedMEKT iteratively updates the generalized global encoders with the joint embedding knowledge from the participating clients. Thereby, to address the modality discrepancy and labeled data constraint in existing FL systems, our proposed FedMEKT comprises local multimodal autoencoder learning, generalized multimodal autoencoder construction, and generalized classifier learning. Through extensive experiments on three multimodal human activity recognition datasets, we demonstrate that FedMEKT achieves superior global encoder performance on linear evaluation and guarantees user privacy for personal data and model parameters while demanding less communication cost than other baselines.
</details>
<details>
<summary>摘要</summary>
联合学习（FL）提供了一个分散式机器学习模式，让多个客户端合作训练一个通用的全球模型，无需分享私人数据。现有大部分研究仅提出传统的FL系统，仅适用于单一模式的数据，因此限制了其在未来个性化应用中的潜力。另外，大多数FL方法仍然依赖客户端上的标签数据，实际上在实际应用中因为用户无法自动标注数据而受限。为了解决这些限制，我们提出了一个新的多modal FL框架，它使用了 semi-supervised 学习方法，以利用不同模式之间的表示。我们发展了一个炼制基于的多modal嵌入知识传递机制，即 FedMEKT，让服务器和客户端可以将它们的学习模型中的通用知识交换。我们的 FedMEKT 逐步更新通用全球嵌入器，使用参与客户端的共同知识。这样可以解决现有 FL 系统中的模式差异和标签数据限制，我们的提案包括本地多modal自适应器学习、通用多modal自适应器建构和通用分类学习。经过广泛的实验，我们在三个多modal人类活动识别数据集上证明了 FedMEKT 可以实现更好的全球嵌入器性能，并保证用户隐私和个人数据，同时需要更少的通信成本。
</details></li>
</ul>
<hr>
<h2 id="Gait-Cycle-Inspired-Learning-Strategy-for-Continuous-Prediction-of-Knee-Joint-Trajectory-from-sEMG"><a href="#Gait-Cycle-Inspired-Learning-Strategy-for-Continuous-Prediction-of-Knee-Joint-Trajectory-from-sEMG" class="headerlink" title="Gait Cycle-Inspired Learning Strategy for Continuous Prediction of Knee Joint Trajectory from sEMG"></a>Gait Cycle-Inspired Learning Strategy for Continuous Prediction of Knee Joint Trajectory from sEMG</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13209">http://arxiv.org/abs/2307.13209</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xueming Fu, Hao Zheng, Luyan Liu, Wenjuan Zhong, Haowen Liu, Wenxuan Xiong, Yuyang Zhang, Yifeng Chen, Dong Wei, Mingjie Dong, Yefeng Zheng, Mingming Zhang</li>
<li>for: 预测下肢运动意图是控制机器人外科手臂和 prosthetic 臂的关键。</li>
<li>methods: 本文提出了一种结合两种步征学习策略来减少人类股关节轨迹预测性能的问题。</li>
<li>results: 实验结果显示，我们的模型可以预测股关节角度的平均Root Mean Square Error（RMSE）为3.03（0.49）度和50ms之前。这是相关文献中已知的最佳性能，与其他文献相比，减少RMSE至少9.5%。<details>
<summary>Abstract</summary>
Predicting lower limb motion intent is vital for controlling exoskeleton robots and prosthetic limbs. Surface electromyography (sEMG) attracts increasing attention in recent years as it enables ahead-of-time prediction of motion intentions before actual movement. However, the estimation performance of human joint trajectory remains a challenging problem due to the inter- and intra-subject variations. The former is related to physiological differences (such as height and weight) and preferred walking patterns of individuals, while the latter is mainly caused by irregular and gait-irrelevant muscle activity. This paper proposes a model integrating two gait cycle-inspired learning strategies to mitigate the challenge for predicting human knee joint trajectory. The first strategy is to decouple knee joint angles into motion patterns and amplitudes former exhibit low variability while latter show high variability among individuals. By learning through separate network entities, the model manages to capture both the common and personalized gait features. In the second, muscle principal activation masks are extracted from gait cycles in a prolonged walk. These masks are used to filter out components unrelated to walking from raw sEMG and provide auxiliary guidance to capture more gait-related features. Experimental results indicate that our model could predict knee angles with the average root mean square error (RMSE) of 3.03(0.49) degrees and 50ms ahead of time. To our knowledge this is the best performance in relevant literatures that has been reported, with reduced RMSE by at least 9.5%.
</details>
<details>
<summary>摘要</summary>
预测下肢运动意图是控制外骨骼机器人和人工肢的关键。表面电 MYography (sEMG) 在最近几年来引起了越来越多的关注，因为它可以在实际运动之前预测人体运动意图。然而，人体 JOINT 轨迹的预测性能仍然是一个挑战，这是因为人体之间和个体之间存在差异。前者是由生物学特征（如身高和体重）和个人偏好的步态所致，而后者是由不规则的肌肉活动所引起的。本文提出了一种将两种步征学习策略 integrate 到模型中，以减少预测人体 knee Joint 轨迹的挑战。首先，我们决定将 knee Joint 角度分解成运动模式和振荡强度两个部分。前者在各个个体中表现出低变异性，而后者则表现出高变异性。通过分解这两个部分，我们可以通过不同的网络实体学习两者。这种方法可以捕捉到各个个体的共同和个性化步态特征。其次，我们从步征征ycle中提取了肌肉主动活动面。这些面用于过滤 raw sEMG 中不相关于步行的组分，并提供辅助指导以捕捉更多的步行特征。实验结果表明，我们的模型可以预测 knee Joint 角度的平均根据 Mean Square Error (RMSE) 为 3.03（0.49）度，并在50毫秒前预测。根据我们所知，这是相关文献中最佳的性能，相比前一个最佳性能减少了至少9.5%。
</details></li>
</ul>
<hr>
<h2 id="Federated-Distributionally-Robust-Optimization-with-Non-Convex-Objectives-Algorithm-and-Analysis"><a href="#Federated-Distributionally-Robust-Optimization-with-Non-Convex-Objectives-Algorithm-and-Analysis" class="headerlink" title="Federated Distributionally Robust Optimization with Non-Convex Objectives: Algorithm and Analysis"></a>Federated Distributionally Robust Optimization with Non-Convex Objectives: Algorithm and Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14364">http://arxiv.org/abs/2307.14364</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Jiao, Kai Yang, Dongjin Song</li>
<li>for: 解决分布式环境中 asynchronous updating 问题，以及如何有效地利用 prior distribution 和适度地调整 robustness 水平。</li>
<li>methods: 提出了 asynchronous distributed algorithm ASPIRE algorithm with EASE method，并开发了新的 uncertainty set - constrained D-norm uncertainty set，以便有效地利用 prior distribution 和控制 robustness 水平。</li>
<li>results: 理论分析表明提出的算法可靠地 converge，并且 iteration complexity 也得到了分析。 empirical studies 表明该方法可以快速 converge，对数据不同性和 malicious attacks 具有抗锋性，并且可以控制 robustness 水平和性能之间的负荷。<details>
<summary>Abstract</summary>
Distributionally Robust Optimization (DRO), which aims to find an optimal decision that minimizes the worst case cost over the ambiguity set of probability distribution, has been widely applied in diverse applications, e.g., network behavior analysis, risk management, etc. However, existing DRO techniques face three key challenges: 1) how to deal with the asynchronous updating in a distributed environment; 2) how to leverage the prior distribution effectively; 3) how to properly adjust the degree of robustness according to different scenarios. To this end, we propose an asynchronous distributed algorithm, named Asynchronous Single-looP alternatIve gRadient projEction (ASPIRE) algorithm with the itErative Active SEt method (EASE) to tackle the federated distributionally robust optimization (FDRO) problem. Furthermore, a new uncertainty set, i.e., constrained D-norm uncertainty set, is developed to effectively leverage the prior distribution and flexibly control the degree of robustness. Finally, our theoretical analysis elucidates that the proposed algorithm is guaranteed to converge and the iteration complexity is also analyzed. Extensive empirical studies on real-world datasets demonstrate that the proposed method can not only achieve fast convergence, and remain robust against data heterogeneity as well as malicious attacks, but also tradeoff robustness with performance.
</details>
<details>
<summary>摘要</summary>
Distributionally Robust Optimization (DRO)，targeting at finding an optimal decision that minimizes the worst-case cost over the ambiguity set of probability distribution, has been widely applied in various fields, such as network behavior analysis and risk management. However, existing DRO techniques face three key challenges:1. How to deal with asynchronous updating in a distributed environment;2. How to effectively leverage the prior distribution;3. How to properly adjust the degree of robustness according to different scenarios.To address these challenges, we propose an asynchronous distributed algorithm, named Asynchronous Single-loop Alternating Gradient Projection (ASPIRE) algorithm with the Iterative Active Set method (EASE) to solve the Federated Distributionally Robust Optimization (FDRO) problem. Furthermore, a new uncertainty set, i.e., constrained D-norm uncertainty set, is developed to effectively leverage the prior distribution and flexibly control the degree of robustness.Our theoretical analysis shows that the proposed algorithm is guaranteed to converge, and the iteration complexity is also analyzed. Extensive empirical studies on real-world datasets demonstrate that the proposed method can not only achieve fast convergence, remain robust against data heterogeneity as well as malicious attacks, but also trade off robustness with performance.
</details></li>
</ul>
<hr>
<h2 id="Blockchain-based-Optimized-Client-Selection-and-Privacy-Preserved-Framework-for-Federated-Learning"><a href="#Blockchain-based-Optimized-Client-Selection-and-Privacy-Preserved-Framework-for-Federated-Learning" class="headerlink" title="Blockchain-based Optimized Client Selection and Privacy Preserved Framework for Federated Learning"></a>Blockchain-based Optimized Client Selection and Privacy Preserved Framework for Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04442">http://arxiv.org/abs/2308.04442</a></li>
<li>repo_url: None</li>
<li>paper_authors: Attia Qammar, Abdenacer Naouri, Jianguo Ding, Huansheng Ning</li>
<li>for: 这个研究旨在提出一个基于区块链的优化客户端选择和隐私保证的联边学习框架，以解决传统联边学习结构中的单点失灵攻击和随机选择客户端对模型训练的影响。</li>
<li>methods: 我们提出了三种智能合约：1）客户端注册合约、2）前向拍卖合约来选择优化客户端进行联边学习模型训练、3）支付和赔偿合约。另外，我们还实现了完全几何加密（CKKS）方法，以保证在传输本地模型更新时，资料的隐私不会被泄露。</li>
<li>results: 我们在 benchmark 数据集上评估了我们的提案，并与现有的研究进行比较。结果显示，我们的方法可以实现高精度率和隐私保证的联边学习框架，并且具有分散的自然 caracteristics。<details>
<summary>Abstract</summary>
Federated learning is a distributed mechanism that trained large-scale neural network models with the participation of multiple clients and data remains on their devices, only sharing the local model updates. With this feature, federated learning is considered a secure solution for data privacy issues. However, the typical FL structure relies on the client-server, which leads to the single-point-of-failure (SPoF) attack, and the random selection of clients for model training compromised the model accuracy. Furthermore, adversaries try for inference attacks i.e., attack on privacy leads to gradient leakage attacks. We proposed the blockchain-based optimized client selection and privacy-preserved framework in this context. We designed the three kinds of smart contracts such as 1) registration of clients 2) forward bidding to select optimized clients for FL model training 3) payment settlement and reward smart contracts. Moreover, fully homomorphic encryption with Cheon, Kim, Kim, and Song (CKKS) method is implemented before transmitting the local model updates to the server. Finally, we evaluated our proposed method on the benchmark dataset and compared it with state-of-the-art studies. Consequently, we achieved a higher accuracy rate and privacy-preserved FL framework with decentralized nature.
</details>
<details>
<summary>摘要</summary>
federated learning 是一种分布式机制，通过多个客户端参与训练大规模神经网络模型，保留数据在客户端上，只将本地模型更新共享。由于这种特点， federated learning 被视为一种保障数据隐私的解决方案。然而， Typical FL 结构依赖于客户端-服务器模型，导致单点失败攻击（SPoF）和随机选择客户端进行模型训练，从而影响模型精度。此外，敌方会尝试进行推理攻击，即袭击隐私导致梯度泄露攻击。我们在这种情况下提出了基于区块链的优化客户端选择和隐私保护框架。我们设计了三种种智能合约，包括1）客户端注册 2）向服务器进行前置拍卖选择优化客户端进行 FL 模型训练 3）支付和奖励智能合约。此外，我们实现了使用 Cheon、Kim、Kim 和 Song（CKKS）方法的完全同质加密，以便在向服务器传输本地模型更新之前对其进行加密。最后，我们对标准数据集进行评估，并与现有研究进行比较。因此，我们实现了高精度率和隐私保护的 FL 框架，并具有分布式的自然Characteristics。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-enhanced-Neuro-Symbolic-AI-for-Cybersecurity-and-Privacy"><a href="#Knowledge-enhanced-Neuro-Symbolic-AI-for-Cybersecurity-and-Privacy" class="headerlink" title="Knowledge-enhanced Neuro-Symbolic AI for Cybersecurity and Privacy"></a>Knowledge-enhanced Neuro-Symbolic AI for Cybersecurity and Privacy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02031">http://arxiv.org/abs/2308.02031</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aritran Piplai, Anantaa Kotal, Seyedreza Mohseni, Manas Gaur, Sudip Mittal, Anupam Joshi</li>
<li>for: 该论文旨在探讨如何使用神经网络和符号知识图来提高人类可理解性和安全性在人工智能系统中。</li>
<li>methods: 该论文使用了神经网络和符号知识图的组合方法，以提高对复杂数据空间的探索和学习，同时保持可理解性和安全性。</li>
<li>results: 该论文表明，通过神经网络和符号知识图的组合，可以在Cybersecurity和隐私等高度需要人工智能可解释性的领域中提高AI系统的准确性和安全性。<details>
<summary>Abstract</summary>
Neuro-Symbolic Artificial Intelligence (AI) is an emerging and quickly advancing field that combines the subsymbolic strengths of (deep) neural networks and explicit, symbolic knowledge contained in knowledge graphs to enhance explainability and safety in AI systems. This approach addresses a key criticism of current generation systems, namely their inability to generate human-understandable explanations for their outcomes and ensure safe behaviors, especially in scenarios with \textit{unknown unknowns} (e.g. cybersecurity, privacy). The integration of neural networks, which excel at exploring complex data spaces, and symbolic knowledge graphs, which represent domain knowledge, allows AI systems to reason, learn, and generalize in a manner understandable to experts. This article describes how applications in cybersecurity and privacy, two most demanding domains in terms of the need for AI to be explainable while being highly accurate in complex environments, can benefit from Neuro-Symbolic AI.
</details>
<details>
<summary>摘要</summary>
neural network 和 symbolic knowledge graph 的结合，即 Neuro-Symbolic AI，是一个快速发展的领域，它可以提高 AI 系统的解释性和安全性。这种方法可以解决现有系统的一个批评，即无法生成人类理解的解释，特别是在“未知未知”（如隐私、安全）的场景下。 neural network 可以很好地探索复杂数据空间，而 symbolic knowledge graph 可以表示领域知识，这使得 AI 系统可以由专家理解的方式进行推理、学习和泛化。本文介绍了如何通过 Neuro-Symbolic AI 应用于隐私和安全领域，这两个领域对 AI 系统的解释性和高精度性有特别高的需求。
</details></li>
</ul>
<hr>
<h2 id="Counterfactual-Explanation-Policies-in-RL"><a href="#Counterfactual-Explanation-Policies-in-RL" class="headerlink" title="Counterfactual Explanation Policies in RL"></a>Counterfactual Explanation Policies in RL</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13192">http://arxiv.org/abs/2307.13192</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shripad V. Deshmukh, Srivatsan R, Supriti Vijay, Jayakumar Subramanian, Chirag Agarwal</li>
<li>for: 这个论文的目的是解释RL策略的可解释性，并提供一种基于对比的策略分析方法。</li>
<li>methods: 该论文使用了对比方法，将策略视为一种可变的对比，并通过对比来分析策略的改进。</li>
<li>results: 实验结果表明，COUNTERPOL可以生成有用的对比解释，帮助分析RL策略的性能改进。 论文在五个不同的RL环境中进行了广泛的实验，并证明了对比解释的实用性。<details>
<summary>Abstract</summary>
As Reinforcement Learning (RL) agents are increasingly employed in diverse decision-making problems using reward preferences, it becomes important to ensure that policies learned by these frameworks in mapping observations to a probability distribution of the possible actions are explainable. However, there is little to no work in the systematic understanding of these complex policies in a contrastive manner, i.e., what minimal changes to the policy would improve/worsen its performance to a desired level. In this work, we present COUNTERPOL, the first framework to analyze RL policies using counterfactual explanations in the form of minimal changes to the policy that lead to the desired outcome. We do so by incorporating counterfactuals in supervised learning in RL with the target outcome regulated using desired return. We establish a theoretical connection between Counterpol and widely used trust region-based policy optimization methods in RL. Extensive empirical analysis shows the efficacy of COUNTERPOL in generating explanations for (un)learning skills while keeping close to the original policy. Our results on five different RL environments with diverse state and action spaces demonstrate the utility of counterfactual explanations, paving the way for new frontiers in designing and developing counterfactual policies.
</details>
<details>
<summary>摘要</summary>
为了使机器学习（RL）代理人在各种决策问题中使用奖励偏好，正在使得RL政策的可追踪性变得越来越重要。然而，现有的工作几乎没有系统地理解这些复杂的政策，尤其是在对比方式下进行分析。在这项工作中，我们提出了Counterpol，第一个使用对比解释来分析RL政策的框架。我们通过在RL中 incorporating counterfactuals into supervised learning，使得政策更容易理解。我们还证明了Counterpol与常用的信任区间基本策略优化方法在RL中的理论联系。我们的实验结果表明，Counterpol可以快速生成对应于不同奖励目标的解释，同时保持着原始政策的相似性。我们在五种不同的RL环境中进行了extensive empirical analysis，并证明了对于不同的状态和动作空间，Counterpol可以提供有用的对比解释，开启了新的前ier征学习和开发对比政策的可能性。
</details></li>
</ul>
<hr>
<h2 id="Digital-Emotion-Regulation-on-Social-Media"><a href="#Digital-Emotion-Regulation-on-Social-Media" class="headerlink" title="Digital Emotion Regulation on Social Media"></a>Digital Emotion Regulation on Social Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13187">http://arxiv.org/abs/2307.13187</a></li>
<li>repo_url: None</li>
<li>paper_authors: Akriti Verma, Shama Islam, Valeh Moghaddam, Adnan Anwar</li>
<li>for: 这篇论文主要是关于如何利用数字技术来调节情绪 state，以支持伦理的技术设计、开发和部署。</li>
<li>methods: 论文使用了社交媒体应用程序的不同特性和功能来描述不同阶段的情绪调节过程。</li>
<li>results: 研究发现了不同社交媒体应用程序在不同阶段的情绪调节过程中的应用，以及最近的研究对社交媒体应用程序的情绪调节 intervenciones。<details>
<summary>Abstract</summary>
Emotion regulation is the process of consciously altering one's affective state, that is the underlying emotional state such as happiness, confidence, guilt, anger etc. The ability to effectively regulate emotions is necessary for functioning efficiently in everyday life. Today, the pervasiveness of digital technology is being purposefully employed to modify our affective states, a process known as digital emotion regulation. Understanding digital emotion regulation can help support the rise of ethical technology design, development, and deployment. This article presents an overview of digital emotion regulation in social media applications, as well as a synthesis of recent research on emotion regulation interventions for social media. We share our findings from analysing state-of-the-art literature on how different social media applications are utilised at different stages in the process of emotion regulation.
</details>
<details>
<summary>摘要</summary>
情绪调节是指意识地改变自己的情绪状态，包括内在的情绪状态如快乐、自信、罪愧、愤怒等。有效地调节情绪是日常生活中必要的。随着数字技术的普及，人们正在意识地利用这些技术来修改自己的情绪状态，这被称为数字情绪调节。了解数字情绪调节可以帮助促进伦理技术的设计、开发和投入。本文提供了社交媒体应用程序中数字情绪调节的概述，以及最新的研究成果表明在社交媒体上进行情绪调节的干预措施。我们分析了最新的文献，描述了不同的社交媒体应用程序在不同阶段的情绪调节过程中的使用。
</details></li>
</ul>
<hr>
<h2 id="Opinion-Mining-Using-Population-tuned-Generative-Language-Models"><a href="#Opinion-Mining-Using-Population-tuned-Generative-Language-Models" class="headerlink" title="Opinion Mining Using Population-tuned Generative Language Models"></a>Opinion Mining Using Population-tuned Generative Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13173">http://arxiv.org/abs/2307.13173</a></li>
<li>repo_url: None</li>
<li>paper_authors: Allmin Susaiyah, Abhinay Pandya, Aki Härmä</li>
<li>for: 用于挖掘文本收集中的意见</li>
<li>methods: 使用生成语言模型，通过特定的方法和数据集进行训练</li>
<li>results: 可以学习和传递意见到semantic类，保持极性分布<details>
<summary>Abstract</summary>
We present a novel method for mining opinions from text collections using generative language models trained on data collected from different populations. We describe the basic definitions, methodology and a generic algorithm for opinion insight mining. We demonstrate the performance of our method in an experiment where a pre-trained generative model is fine-tuned using specifically tailored content with unnatural and fully annotated opinions. We show that our approach can learn and transfer the opinions to the semantic classes while maintaining the proportion of polarisation. Finally, we demonstrate the usage of an insight mining system to scale up the discovery of opinion insights from a real text corpus.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法，用于从文本集中挖掘意见使用生成语言模型，这些模型在不同的人口数据上进行训练。我们描述了基本定义、方法和一个通用的算法 для意见洞察挖掘。我们在实验中使用预训练的生成模型进行微调，使用特定的内容和假备注意意见。我们显示了我们的方法可以学习并传递意见到Semantic类中，同时保持极性分布。最后，我们示出了一个洞察挖掘系统可以扩大从真实文本集中发现意见洞察的能力。Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Investigating-the-Robustness-of-Sequential-Recommender-Systems-Against-Training-Data-Perturbations-an-Empirical-Study"><a href="#Investigating-the-Robustness-of-Sequential-Recommender-Systems-Against-Training-Data-Perturbations-an-Empirical-Study" class="headerlink" title="Investigating the Robustness of Sequential Recommender Systems Against Training Data Perturbations: an Empirical Study"></a>Investigating the Robustness of Sequential Recommender Systems Against Training Data Perturbations: an Empirical Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13165">http://arxiv.org/abs/2307.13165</a></li>
<li>repo_url: None</li>
<li>paper_authors: Filippo Betello, Federico Siciliano, Pushkar Mishra, Fabrizio Silvestri</li>
<li>for: 这个论文旨在研究Sequential Recommender Systems（SRSs）在训练数据中的稳定性，具体来说是研究在 temporally ordered sequence 中移除items的影响。</li>
<li>methods: 这个论文使用了两种不同的SRS模型，在多个数据集上进行了评估，使用了Normalized Discounted Cumulative Gain（NDCG）和Rank Sensitivity List metric来衡量性能。</li>
<li>results: 研究发现，在序列中移除items的末端位置会导致性能下降，NDCG下降可达60%，而从开头或中间位置移除items没有显著影响。这些发现表明考虑训练数据中items的位置是重要的，这将有助于设计更加稳定的SRSs。<details>
<summary>Abstract</summary>
Sequential Recommender Systems (SRSs) have been widely used to model user behavior over time, but their robustness in the face of perturbations to training data is a critical issue. In this paper, we conduct an empirical study to investigate the effects of removing items at different positions within a temporally ordered sequence. We evaluate two different SRS models on multiple datasets, measuring their performance using Normalized Discounted Cumulative Gain (NDCG) and Rank Sensitivity List metrics. Our results demonstrate that removing items at the end of the sequence significantly impacts performance, with NDCG decreasing up to 60\%, while removing items from the beginning or middle has no significant effect. These findings highlight the importance of considering the position of the perturbed items in the training data and shall inform the design of more robust SRSs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Improving-Primary-Healthcare-Workflow-Using-Extreme-Summarization-of-Scientific-Literature-Based-on-Generative-AI"><a href="#Improving-Primary-Healthcare-Workflow-Using-Extreme-Summarization-of-Scientific-Literature-Based-on-Generative-AI" class="headerlink" title="Improving Primary Healthcare Workflow Using Extreme Summarization of Scientific Literature Based on Generative AI"></a>Improving Primary Healthcare Workflow Using Extreme Summarization of Scientific Literature Based on Generative AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15715">http://arxiv.org/abs/2307.15715</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gregor Stiglic, Leon Kopitar, Lucija Gosak, Primoz Kocbek, Zhe He, Prithwish Chakraborty, Pablo Meyer, Jiang Bian<br>for: 这个研究的目的是探究生成人工智能在减轻医疗专业人员的认知压力方面的潜力，以便更好地帮助他们保持最新的科学文献知识。methods: 这个研究使用了生成型人工智能技术，基于大规模语言模型，对科学报告摘要进行概括。results: 研究结果表明，使用生成型人工智能 для文献综述是高效的，可以减少医疗专业人员查找科学文献所需的时间。然而，研究还发现，当全文摘要不可用时，EXTRACTED知识的准确性会下降。这种破坏性技术有potential可以大幅减少医疗专业人员保持最新科学文献知识的时间，但是进一步的发展可能需要帮助他们更好地理解摘要中的知识。<details>
<summary>Abstract</summary>
Primary care professionals struggle to keep up to date with the latest scientific literature critical in guiding evidence-based practice related to their daily work. To help solve the above-mentioned problem, we employed generative artificial intelligence techniques based on large-scale language models to summarize abstracts of scientific papers. Our objective is to investigate the potential of generative artificial intelligence in diminishing the cognitive load experienced by practitioners, thus exploring its ability to alleviate mental effort and burden. The study participants were provided with two use cases related to preventive care and behavior change, simulating a search for new scientific literature. The study included 113 university students from Slovenia and the United States randomized into three distinct study groups. The first group was assigned to the full abstracts. The second group was assigned to the short abstracts generated by AI. The third group had the option to select a full abstract in addition to the AI-generated short summary. Each use case study included ten retrieved abstracts. Our research demonstrates that the use of generative AI for literature review is efficient and effective. The time needed to answer questions related to the content of abstracts was significantly lower in groups two and three compared to the first group using full abstracts. The results, however, also show significantly lower accuracy in extracted knowledge in cases where full abstract was not available. Such a disruptive technology could significantly reduce the time required for healthcare professionals to keep up with the most recent scientific literature; nevertheless, further developments are needed to help them comprehend the knowledge accurately.
</details>
<details>
<summary>摘要</summary>
We conducted a study with 113 university students from Slovenia and the United States, randomly assigned to three groups. The first group was given full abstracts, the second group was given AI-generated short summaries, and the third group had the option to choose a full abstract or the AI-generated summary. Each use case study included ten retrieved abstracts.Our findings show that using generative AI for literature review is efficient and effective. The time needed to answer questions related to the content of abstracts was significantly lower in groups two and three compared to the first group using full abstracts. However, the results also showed that accuracy in extracted knowledge was significantly lower when full abstracts were not available.This disruptive technology has the potential to significantly reduce the time required for healthcare professionals to keep up with the most recent scientific literature. However, further developments are needed to help them comprehend the knowledge accurately.
</details></li>
</ul>
<hr>
<h2 id="Why-Don’t-You-Clean-Your-Glasses-Perception-Attacks-with-Dynamic-Optical-Perturbations"><a href="#Why-Don’t-You-Clean-Your-Glasses-Perception-Attacks-with-Dynamic-Optical-Perturbations" class="headerlink" title="Why Don’t You Clean Your Glasses? Perception Attacks with Dynamic Optical Perturbations"></a>Why Don’t You Clean Your Glasses? Perception Attacks with Dynamic Optical Perturbations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13131">http://arxiv.org/abs/2307.13131</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Han, Matthew Chan, Eric Wengrowski, Zhuohuan Li, Nils Ole Tippenhauer, Mani Srivastava, Saman Zonouz, Luis Garcia</li>
<li>for: 这篇论文的目的是研究攻击自适应系统中的机器学习模型，以及这些模型在物理世界中的攻击。</li>
<li>methods: 这篇论文使用了一种名为“EvilEye”的人在中渠攻击，利用透明屏幕生成动态物理攻击示例。这种攻击利用了相机的光学特性，在不同的照明条件下引起识别错误。</li>
<li>results: 实验表明，EvilEye生成的攻击示例在环境噪声和自适应系统的动态变化下表现得非常稳定，可以高效绕过当前物理世界攻击检测框架。此外，EvilEye可以针对不同的物体实现高度的攻击成功率。<details>
<summary>Abstract</summary>
Camera-based autonomous systems that emulate human perception are increasingly being integrated into safety-critical platforms. Consequently, an established body of literature has emerged that explores adversarial attacks targeting the underlying machine learning models. Adapting adversarial attacks to the physical world is desirable for the attacker, as this removes the need to compromise digital systems. However, the real world poses challenges related to the "survivability" of adversarial manipulations given environmental noise in perception pipelines and the dynamicity of autonomous systems. In this paper, we take a sensor-first approach. We present EvilEye, a man-in-the-middle perception attack that leverages transparent displays to generate dynamic physical adversarial examples. EvilEye exploits the camera's optics to induce misclassifications under a variety of illumination conditions. To generate dynamic perturbations, we formalize the projection of a digital attack into the physical domain by modeling the transformation function of the captured image through the optical pipeline. Our extensive experiments show that EvilEye's generated adversarial perturbations are much more robust across varying environmental light conditions relative to existing physical perturbation frameworks, achieving a high attack success rate (ASR) while bypassing state-of-the-art physical adversarial detection frameworks. We demonstrate that the dynamic nature of EvilEye enables attackers to adapt adversarial examples across a variety of objects with a significantly higher ASR compared to state-of-the-art physical world attack frameworks. Finally, we discuss mitigation strategies against the EvilEye attack.
</details>
<details>
<summary>摘要</summary>
摄像头基于自动化系统，模拟人类感知，在安全关键平台中得到普遍应用。因此，一个已经形成的文献出现，探讨机器学习模型的攻击。对于攻击者来说，在物理世界中进行攻击是有利的，因为这 eliminates the need to compromise digital systems。然而，物理世界具有对攻击修改的"生存性"问题，即环境噪声和自动化系统的动态性。在这篇论文中，我们采用了感知先采集的方法。我们介绍了一种基于透明显示器的人在中间攻击，称为EvilEye。EvilEye利用摄像头的光学来导致分类错误，并在不同的照明条件下实现高度的攻击成功率（ASR），并 circumvent state-of-the-art physical adversarial detection frameworks。我们的广泛实验表明，EvilEye生成的physical perturbations是对环境光度条件的变化具有更高的Robustness，相比之下，现有的物理扰动框架。我们还证明了EvilEye的动态性可以在不同的物体上实现更高的ASR，比之前的物理世界攻击框架。最后，我们讨论了对EvilEye攻击的防御策略。
</details></li>
</ul>
<hr>
<h2 id="A-Hybrid-Machine-Learning-Model-for-Classifying-Gene-Mutations-in-Cancer-using-LSTM-BiLSTM-CNN-GRU-and-GloVe"><a href="#A-Hybrid-Machine-Learning-Model-for-Classifying-Gene-Mutations-in-Cancer-using-LSTM-BiLSTM-CNN-GRU-and-GloVe" class="headerlink" title="A Hybrid Machine Learning Model for Classifying Gene Mutations in Cancer using LSTM, BiLSTM, CNN, GRU, and GloVe"></a>A Hybrid Machine Learning Model for Classifying Gene Mutations in Cancer using LSTM, BiLSTM, CNN, GRU, and GloVe</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14361">http://arxiv.org/abs/2307.14361</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanad Aburass, Osama Dorgham, Jamil Al Shaqsi</li>
<li>for: 这种研究是为了使用Kaggle的个性化医疗：再定义癌症治疗数据集来分类基因突变。</li>
<li>methods: 这个模型使用了LSTM、BiLSTM、CNN、GRU和GloVe ensemble模型来实现这一目标。</li>
<li>results: 这个模型的准确率、精度、准确率、F1分数和平均平方误差都高于所有其他模型，并且需要更少的训练时间，因此是性能和效率的完美结合。<details>
<summary>Abstract</summary>
This study presents an ensemble model combining LSTM, BiLSTM, CNN, GRU, and GloVe to classify gene mutations using Kaggle's Personalized Medicine: Redefining Cancer Treatment dataset. The results were compared against well-known transformers like as BERT, Electra, Roberta, XLNet, Distilbert, and their LSTM ensembles. Our model outperformed all other models in terms of accuracy, precision, recall, F1 score, and Mean Squared Error. Surprisingly, it also needed less training time, resulting in a perfect combination of performance and efficiency. This study demonstrates the utility of ensemble models for difficult tasks such as gene mutation classification.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "LSTM" and "BiLSTM" were translated as "长ShortTermMemory" (CHángshòu Dàimengyī) and "双向LongShortTermMemory" (Shuāngxiàng CHángshòu Dàimengyī) respectively.* "CNN" was translated as "卷积神经网络" (Jiànpán Jīngxīn Wǎngwǎng)* "GRU" was translated as "幂等循环神经网络" (Jìdé Xiàngxīng Jīngxīn Wǎngwǎng)* "GloVe" was translated as "全球最佳 embeddings" (Quánqīu Zuìjiā Embeddings)* "BERT" was translated as "Bidirectional Encoder Representations from Transformers" (Bìxiàngdìng Jīngxīn Fāngyìng)* "Electra" was translated as "Electra: A Method for Estimating the Representation of a Set of Words" (Électra: A Method for Estimating the Representation of a Set of Words)* "Roberta" was translated as "Roberta: A Simple and Efficient Transformer for Language Understanding" (Roberta: A Simple and Efficient Transformer for Language Understanding)* "XLNet" was translated as "XLNet: Generalized Autoencoders for Language Understanding" (XLNet: Generalized Autoencoders for Language Understanding)* "Distilbert" was translated as "DistilBERT: Distilled BERT for Efficient and Compact Language Models" (DistilBERT: Distilled BERT for Efficient and Compact Language Models)* "ensemble" was translated as "组合" (Zǔzhōng)Please note that the translation is in Simplified Chinese, and the translation may vary depending on the context and the specific dialect.
</details></li>
</ul>
<hr>
<h2 id="Deep-Bradley-Terry-Rating-Quantifying-Properties-from-Comparisons"><a href="#Deep-Bradley-Terry-Rating-Quantifying-Properties-from-Comparisons" class="headerlink" title="Deep Bradley-Terry Rating: Quantifying Properties from Comparisons"></a>Deep Bradley-Terry Rating: Quantifying Properties from Comparisons</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13709">http://arxiv.org/abs/2307.13709</a></li>
<li>repo_url: None</li>
<li>paper_authors: Satoru Fujii</li>
<li>for: 该论文旨在解决实际世界中不直接可观察的许多属性的难题，通过使用grade human scores作为目标标签进行训练。</li>
<li>methods: 该论文提出了一种名为深度布莱德利-泰勒评分（DBTR）的新机器学习框架，该框架将布莱德利-泰勒模型 integrates into neural network structure，并在不平等环境下进行扩展。</li>
<li>results: 经过实验分析，DBTR成功地学习和估计所需的属性。<details>
<summary>Abstract</summary>
Many properties in the real world can't be directly observed, making them difficult to learn. To deal with this challenging problem, prior works have primarily focused on estimating those properties by using graded human scores as the target label in the training. Meanwhile, rating algorithms based on the Bradley-Terry model are extensively studied to evaluate the competitiveness of players based on their match history. In this paper, we introduce the Deep Bradley-Terry Rating (DBTR), a novel machine learning framework designed to quantify and evaluate properties of unknown items. Our method seamlessly integrates the Bradley-Terry model into the neural network structure. Moreover, we generalize this architecture further to asymmetric environments with unfairness, a condition more commonly encountered in real-world settings. Through experimental analysis, we demonstrate that DBTR successfully learns to quantify and estimate desired properties.
</details>
<details>
<summary>摘要</summary>
很多现实世界中的属性是直接观察不到的，使得学习变得困难。以前的工作主要是通过使用排名为目标标签进行训练来估算这些属性。而BRADLEY-TERRY模型的评分算法在评估玩家的竞技水平上广泛研究。在这篇论文中，我们介绍了深度BRADLEY-TERRY评分（DBTR），一种新的机器学习框架，用于评估和评价未知的物品属性。我们将BRADLEY-TERRY模型集成到神经网络结构中，并将其扩展到不平等环境下，更加符合实际世界中的情况。我们通过实验分析，证明DBTR可以成功地评估和估算所需的属性。
</details></li>
</ul>
<hr>
<h2 id="Getting-pwn’d-by-AI-Penetration-Testing-with-Large-Language-Models"><a href="#Getting-pwn’d-by-AI-Penetration-Testing-with-Large-Language-Models" class="headerlink" title="Getting pwn’d by AI: Penetration Testing with Large Language Models"></a>Getting pwn’d by AI: Penetration Testing with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.00121">http://arxiv.org/abs/2308.00121</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ipa-lab/hackingBuddyGPT">https://github.com/ipa-lab/hackingBuddyGPT</a></li>
<li>paper_authors: Andreas Happe, Jürgen Cito</li>
<li>for: 该论文探讨了使用大语言模型（如GPT3.5）来补充安全测试人员，以增强安全测试的效率和质量。</li>
<li>methods: 论文采用了高级语言模型进行具体的任务规划和低级漏洞搜索两种使用场景，并实现了在虚拟机上实现了封闭反馈循环，让LLM分析机器状态并提供攻击方式。</li>
<li>results: 论文初步结果显示，使用大语言模型可以帮助提高安全测试的效率和质量，并且可以帮助找到一些潜在的漏洞。但是，论文还需要进一步的改进和优化。<details>
<summary>Abstract</summary>
The field of software security testing, more specifically penetration testing, is an activity that requires high levels of expertise and involves many manual testing and analysis steps. This paper explores the potential usage of large-language models, such as GPT3.5, to augment penetration testers with AI sparring partners. We explore the feasibility of supplementing penetration testers with AI models for two distinct use cases: high-level task planning for security testing assignments and low-level vulnerability hunting within a vulnerable virtual machine. For the latter, we implemented a closed-feedback loop between LLM-generated low-level actions with a vulnerable virtual machine (connected through SSH) and allowed the LLM to analyze the machine state for vulnerabilities and suggest concrete attack vectors which were automatically executed within the virtual machine. We discuss promising initial results, detail avenues for improvement, and close deliberating on the ethics of providing AI-based sparring partners.
</details>
<details>
<summary>摘要</summary>
field 软件安全测试，具体来说是渗透测试，需要高水平的专业知识和多种手动测试和分析步骤。这篇论文探讨使用大型自然语言模型，如GPT3.5，来补充渗透测试员的人工智能对手。我们探讨在两个不同的用例中使用AI模型：一是高级任务规划 для安全测试任务，二是低级漏洞搜寻在易于攻击的虚拟机中。对于后一个，我们实现了关闭反馈循环，使用SSH连接到易于攻击的虚拟机，让LLM分析机器状态以找到漏洞并建议具体的攻击方式，然后自动在虚拟机中执行。我们讨论了初步的结果，详细描述改进的方向，并关于提供AI基本对手的伦理问题。
</details></li>
</ul>
<hr>
<h2 id="An-Explainable-Geometric-Weighted-Graph-Attention-Network-for-Identifying-Functional-Networks-Associated-with-Gait-Impairment"><a href="#An-Explainable-Geometric-Weighted-Graph-Attention-Network-for-Identifying-Functional-Networks-Associated-with-Gait-Impairment" class="headerlink" title="An Explainable Geometric-Weighted Graph Attention Network for Identifying Functional Networks Associated with Gait Impairment"></a>An Explainable Geometric-Weighted Graph Attention Network for Identifying Functional Networks Associated with Gait Impairment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13108">http://arxiv.org/abs/2307.13108</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/favour-nerrise/xgw-gat">https://github.com/favour-nerrise/xgw-gat</a></li>
<li>paper_authors: Favour Nerrise, Qingyu Zhao, Kathleen L. Poston, Kilian M. Pohl, Ehsan Adeli</li>
<li>for: 这个研究的目的是为了更好地理解parkinson病的motor进程，以开发更有效和个性化的治疗方法。</li>
<li>methods: 这个研究使用了一种可解释的、几何的、weighted-graph注意力神经网络（xGW-GAT），用于预测parkinson病患者的跑步困难程度。</li>
<li>results: xGW-GAT模型可以从resting-state功能MRI数据中提取出跑步困难相关的功能连接图，并且可以提供可解释的功能子网络，对于parkinson病患者的motor困难提供了解释。<details>
<summary>Abstract</summary>
One of the hallmark symptoms of Parkinson's Disease (PD) is the progressive loss of postural reflexes, which eventually leads to gait difficulties and balance problems. Identifying disruptions in brain function associated with gait impairment could be crucial in better understanding PD motor progression, thus advancing the development of more effective and personalized therapeutics. In this work, we present an explainable, geometric, weighted-graph attention neural network (xGW-GAT) to identify functional networks predictive of the progression of gait difficulties in individuals with PD. xGW-GAT predicts the multi-class gait impairment on the MDS Unified PD Rating Scale (MDS-UPDRS). Our computational- and data-efficient model represents functional connectomes as symmetric positive definite (SPD) matrices on a Riemannian manifold to explicitly encode pairwise interactions of entire connectomes, based on which we learn an attention mask yielding individual- and group-level explainability. Applied to our resting-state functional MRI (rs-fMRI) dataset of individuals with PD, xGW-GAT identifies functional connectivity patterns associated with gait impairment in PD and offers interpretable explanations of functional subnetworks associated with motor impairment. Our model successfully outperforms several existing methods while simultaneously revealing clinically-relevant connectivity patterns. The source code is available at https://github.com/favour-nerrise/xGW-GAT .
</details>
<details>
<summary>摘要</summary>
Our model represents functional connectomes as symmetric positive definite (SPD) matrices on a Riemannian manifold to explicitly encode pairwise interactions of entire connectomes. Based on this, we learn an attention mask that yields individual- and group-level explainability. Applied to our resting-state functional MRI (rs-fMRI) dataset of individuals with PD, xGW-GAT identifies functional connectivity patterns associated with gait impairment in PD and provides interpretable explanations of functional subnetworks associated with motor impairment. Our model outperforms several existing methods while providing clinically relevant connectivity patterns. The source code is available at https://github.com/favour-nerrise/xGW-GAT.
</details></li>
</ul>
<hr>
<h2 id="How-to-use-LLMs-for-Text-Analysis"><a href="#How-to-use-LLMs-for-Text-Analysis" class="headerlink" title="How to use LLMs for Text Analysis"></a>How to use LLMs for Text Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13106">http://arxiv.org/abs/2307.13106</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cssmodels/howtousellms">https://github.com/cssmodels/howtousellms</a></li>
<li>paper_authors: Petter Törnberg</li>
<li>for: 这篇论文是用于介绍大语言模型（LLM）在社会科学中的应用。</li>
<li>methods: 论文使用Python语言和API进行文本分析，包括文本标注和分类、情感分析和批判话语分析等多种任务。</li>
<li>results: 论文通过使用LLM来分析政治文本，并成功地超越了现有的状态。<details>
<summary>Abstract</summary>
This guide introduces Large Language Models (LLM) as a highly versatile text analysis method within the social sciences. As LLMs are easy-to-use, cheap, fast, and applicable on a broad range of text analysis tasks, ranging from text annotation and classification to sentiment analysis and critical discourse analysis, many scholars believe that LLMs will transform how we do text analysis. This how-to guide is aimed at students and researchers with limited programming experience, and offers a simple introduction to how LLMs can be used for text analysis in your own research project, as well as advice on best practices. We will go through each of the steps of analyzing textual data with LLMs using Python: installing the software, setting up the API, loading the data, developing an analysis prompt, analyzing the text, and validating the results. As an illustrative example, we will use the challenging task of identifying populism in political texts, and show how LLMs move beyond the existing state-of-the-art.
</details>
<details>
<summary>摘要</summary>
这个指南介绍大语言模型（LLM）作为社会科学中高度灵活的文本分析方法。由于LLM是容易使用、便宜、快速并可应用于广泛的文本分析任务，从文本标注和分类到情感分析和批判性文本分析，许多学者认为LLM会改变我们如何进行文本分析。这本引导是向没有programming经验的学生和研究人员的，提供了使用Python来进行文本分析的简单入门，以及最佳实践的建议。我们将通过每个步骤来分析文本数据使用LLM，包括安装软件、设置API、加载数据、开发分析提示、分析文本和验证结果。作为一个示例，我们使用政治文本中的 populism 识别任务，并示出如何使用LLM超越现有的状态。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Example-Based-Control"><a href="#Contrastive-Example-Based-Control" class="headerlink" title="Contrastive Example-Based Control"></a>Contrastive Example-Based Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13101">http://arxiv.org/abs/2307.13101</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/khatch31/laeo">https://github.com/khatch31/laeo</a></li>
<li>paper_authors: Kyle Hatch, Benjamin Eysenbach, Rafael Rafailov, Tianhe Yu, Ruslan Salakhutdinov, Sergey Levine, Chelsea Finn</li>
<li>for: 这篇论文的目的是提出一种基于实例的控制方法，可以在无线务动态环境中学习Q值函数。</li>
<li>methods: 这种方法使用数据驱动的方法，从转移动力和高返回状态中学习一个隐式模型，而不是直接学习奖励函数。</li>
<li>results: 对比基线方法，这种方法在多种状态基于和图像基于的离线控制任务中表现出色，并且在数据集大小增加时显示了更好的稳定性和扩展性。<details>
<summary>Abstract</summary>
While many real-world problems that might benefit from reinforcement learning, these problems rarely fit into the MDP mold: interacting with the environment is often expensive and specifying reward functions is challenging. Motivated by these challenges, prior work has developed data-driven approaches that learn entirely from samples from the transition dynamics and examples of high-return states. These methods typically learn a reward function from high-return states, use that reward function to label the transitions, and then apply an offline RL algorithm to these transitions. While these methods can achieve good results on many tasks, they can be complex, often requiring regularization and temporal difference updates. In this paper, we propose a method for offline, example-based control that learns an implicit model of multi-step transitions, rather than a reward function. We show that this implicit model can represent the Q-values for the example-based control problem. Across a range of state-based and image-based offline control tasks, our method outperforms baselines that use learned reward functions; additional experiments demonstrate improved robustness and scaling with dataset size.
</details>
<details>
<summary>摘要</summary>
虽然许多实际问题可以借助强化学习解决，但这些问题很少遵循MDP模型：与环境交互往往是昂贵的，并且指定奖励函数是困难的。受这些挑战的推动，先前的工作已经开发出了基于数据的方法，这些方法通过从转移动力学中采样而学习，并使用高奖状态的示例来标记转移。这些方法可以在许多任务上达到良好的结果，但它们可能复杂，需要减少和时间差更新。在这篇论文中，我们提出了一种没有奖励函数的离线控制方法，这种方法学习了多步转移的隐藏模型，而不是奖励函数。我们证明这种隐藏模型可以表示离线控制问题中的Q值。在一系列基于状态和图像的离线控制任务上，我们的方法超过了基准值，并且进行了附加的robustness和数据集大小的扩展试验。
</details></li>
</ul>
<hr>
<h2 id="Comparative-Analysis-of-Drug-GPT-and-ChatGPT-LLMs-for-Healthcare-Insights-Evaluating-Accuracy-and-Relevance-in-Patient-and-HCP-Contexts"><a href="#Comparative-Analysis-of-Drug-GPT-and-ChatGPT-LLMs-for-Healthcare-Insights-Evaluating-Accuracy-and-Relevance-in-Patient-and-HCP-Contexts" class="headerlink" title="Comparative Analysis of Drug-GPT and ChatGPT LLMs for Healthcare Insights: Evaluating Accuracy and Relevance in Patient and HCP Contexts"></a>Comparative Analysis of Drug-GPT and ChatGPT LLMs for Healthcare Insights: Evaluating Accuracy and Relevance in Patient and HCP Contexts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.16850">http://arxiv.org/abs/2307.16850</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giorgos Lysandrou, Roma English Owen, Kirsty Mursec, Grant Le Brun, Elizabeth A. L. Fairley</li>
<li>for: 这个研究旨在比较三个生成预训练变换器（GPT）解决方案在问答（Q&amp;A） Setting中的表现：Drug-GPT 3、Drug-GPT 4 和 ChatGPT，以医疗应用场景为背景。研究的目的是确定哪一个模型可以在涉及到患有过敏性皮肤炎（AD）患者经验和医疗专业人员（HCP）关于糖尿病讨论中提供最准确和有 relevance 的答案。</li>
<li>methods: 这个研究使用了三个GPT模型：Drug-GPT 3、Drug-GPT 4 和 ChatGPT，通过精心编辑的患者和医疗专业人员社交媒体和讨论区域的数据来支持这三个模型。</li>
<li>results: 研究结果表明，三个模型都能生成有 relevance 和准确的答案，但Drug-GPT 3 和 Drug-GPT 4 通过使用专门编辑的患者和医疗专业人员社交媒体和讨论区域数据，为患者和医疗专业人员提供了更加有target 和深入的报告。ChatGPT 是一个更通用的模型，可以为读者提供高度概括的了解这些主题，但可能缺乏Drug-GPT模型所具备的深度和个人经验。<details>
<summary>Abstract</summary>
This study presents a comparative analysis of three Generative Pre-trained Transformer (GPT) solutions in a question and answer (Q&A) setting: Drug-GPT 3, Drug-GPT 4, and ChatGPT, in the context of healthcare applications. The objective is to determine which model delivers the most accurate and relevant information in response to prompts related to patient experiences with atopic dermatitis (AD) and healthcare professional (HCP) discussions about diabetes. The results demonstrate that while all three models are capable of generating relevant and accurate responses, Drug-GPT 3 and Drug-GPT 4, which are supported by curated datasets of patient and HCP social media and message board posts, provide more targeted and in-depth insights. ChatGPT, a more general-purpose model, generates broader and more general responses, which may be valuable for readers seeking a high-level understanding of the topics but may lack the depth and personal insights found in the answers generated by the specialized Drug-GPT models. This comparative analysis highlights the importance of considering the language model's perspective, depth of knowledge, and currency when evaluating the usefulness of generated information in healthcare applications.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "Atopic dermatitis" (AD) is translated as "恶性皮肤炎" (éviation skin rash)* "Healthcare professional" (HCP) is translated as "医疗专业人员" (yījīu zhōngyè rényuè)* "Curated datasets" is translated as "精选数据集" (jīngxuǎn numérique)* "Social media and message board posts" is translated as "社交媒体和讨论版块" (shèjiāo tiēdī yǔ tǎo luó bǎ)* "General-purpose model" is translated as "通用模型" (tōngyòng módeli)* "Specialized models" is translated as "专业模型" (zhuāngyè módeli)
</details></li>
</ul>
<hr>
<h2 id="Making-Metadata-More-FAIR-Using-Large-Language-Models"><a href="#Making-Metadata-More-FAIR-Using-Large-Language-Models" class="headerlink" title="Making Metadata More FAIR Using Large Language Models"></a>Making Metadata More FAIR Using Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13085">http://arxiv.org/abs/2307.13085</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sowmya S. Sundaram, Mark A. Musen</li>
<li>for: 这篇论文是为了解决实验数据中的metadata问题，尤其是对于不同的metadata数据进行比较和分组。</li>
<li>methods: 这篇论文使用自然语言处理（NLP）技术，开发了一个名为FAIRMetaText的应用程序，可以比较metadata中的自然语言描述，并提供一个数学性相似度的衡量方法，以便对metadata进行分组或找到相似的替代词。</li>
<li>results: 这篇论文透过对公开 available的研究artifacts进行详细的研究，证明了FAIRMetaText的算法可以大幅提高metadata相关的任务，包括搜寻、分组和替代词等。<details>
<summary>Abstract</summary>
With the global increase in experimental data artifacts, harnessing them in a unified fashion leads to a major stumbling block - bad metadata. To bridge this gap, this work presents a Natural Language Processing (NLP) informed application, called FAIRMetaText, that compares metadata. Specifically, FAIRMetaText analyzes the natural language descriptions of metadata and provides a mathematical similarity measure between two terms. This measure can then be utilized for analyzing varied metadata, by suggesting terms for compliance or grouping similar terms for identification of replaceable terms. The efficacy of the algorithm is presented qualitatively and quantitatively on publicly available research artifacts and demonstrates large gains across metadata related tasks through an in-depth study of a wide variety of Large Language Models (LLMs). This software can drastically reduce the human effort in sifting through various natural language metadata while employing several experimental datasets on the same topic.
</details>
<details>
<summary>摘要</summary>
global 实验数据的增加，将它们集成一起是一个主要障碍 - 坏的metadata。为了bridging这个差距，这个工作提出了一个基于自然语言处理（NLP）的应用程序，called FAIRMetaText，它比较metadata的自然语言描述。具体来说，FAIRMetaText使用自然语言描述来提供两个条件之间的数学相似度测量。这个测量可以用来分析不同的metadata，提供符合性检查或组织相似的条件。这个软件可以帮助大幅提高人工过滤不同主题的自然语言metadata的时间和努力。Here's a breakdown of the translation:* global 实验数据 (global experimental data) becomes 实验数据的增加 (increase in experimental data)* 将它们集成一起 (harnessing them in a unified fashion) becomes 将它们集成一起 (collecting them together)* 坏的metadata (bad metadata) becomes 坏的metadata (incorrect or incomplete metadata)*  bridging 这个差距 (bridging the gap) becomes 帮助大幅提高 (helping to greatly improve)* 这个工作 (this work) becomes 这个软件 (this software)* called FAIRMetaText (called FAIRMetaText) becomes 叫做 FAIRMetaText (called FAIRMetaText)* 比较metadata (compare metadata) becomes 比较metadata (compare metadata)* 自然语言描述 (natural language description) becomes 自然语言描述 (natural language description)* 提供两个条件之间的数学相似度测量 (provide a mathematical similarity measure between two terms) becomes 提供两个条件之间的数学相似度测量 (provide a mathematical similarity measure between two terms)* 这个测量可以用来 (this measurement can be used to) becomes 这个测量可以用来 (this measurement can be used to)* 分析不同的metadata (analyze varied metadata) becomes 分析不同的metadata (analyze different metadata)* 提供符合性检查 (provide compliance checks) becomes 提供符合性检查 (provide compliance checks)* 组织相似的条件 (group similar terms) becomes 组织相似的条件 (group similar terms)I hope this helps! Let me know if you have any further questions or if you'd like me to translate anything else.
</details></li>
</ul>
<hr>
<h2 id="Fairness-Under-Demographic-Scarce-Regime"><a href="#Fairness-Under-Demographic-Scarce-Regime" class="headerlink" title="Fairness Under Demographic Scarce Regime"></a>Fairness Under Demographic Scarce Regime</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13081">http://arxiv.org/abs/2307.13081</a></li>
<li>repo_url: None</li>
<li>paper_authors: Patrik Joslin Kenfack, Samira Ebrahimi Kahou, Ulrich Aïvodji</li>
<li>for: 提高模型的公平性和准确性之间的贸易offs</li>
<li>methods: 引入不确定性认识，并在具有最低不确定性的样本上遵循公平性约束</li>
<li>results: 比 класси型的属性分类器更好地平衡公平性和准确性，并且在一些实际场景下超过使用真实敏感属性的模型。<details>
<summary>Abstract</summary>
Most existing works on fairness assume the model has full access to demographic information. However, there exist scenarios where demographic information is partially available because a record was not maintained throughout data collection or due to privacy reasons. This setting is known as demographic scarce regime. Prior research have shown that training an attribute classifier to replace the missing sensitive attributes (proxy) can still improve fairness. However, the use of proxy-sensitive attributes worsens fairness-accuracy trade-offs compared to true sensitive attributes. To address this limitation, we propose a framework to build attribute classifiers that achieve better fairness-accuracy trade-offs. Our method introduces uncertainty awareness in the attribute classifier and enforces fairness on samples with demographic information inferred with the lowest uncertainty. We show empirically that enforcing fairness constraints on samples with uncertain sensitive attributes is detrimental to fairness and accuracy. Our experiments on two datasets showed that the proposed framework yields models with significantly better fairness-accuracy trade-offs compared to classic attribute classifiers. Surprisingly, our framework outperforms models trained with constraints on the true sensitive attributes.
</details>
<details>
<summary>摘要</summary>
Our method introduces uncertainty awareness in the attribute classifier and enforces fairness on samples with demographic information inferred with the lowest uncertainty. We show empirically that enforcing fairness constraints on samples with uncertain sensitive attributes is detrimental to fairness and accuracy. Our experiments on two datasets showed that the proposed framework yields models with significantly better fairness-accuracy trade-offs compared to classic attribute classifiers. Surprisingly, our framework outperforms models trained with constraints on the true sensitive attributes.In simplified Chinese:大多数现有的公平研究假设模型拥有完整的人口信息。然而，有些场景中人口信息只有部分可用，如数据采集或隐私问题，这种情况被称为人口缺乏 режим。先前的研究表明，使用代理敏感特征来取代缺失的人口信息可以提高公平性。然而，使用代理敏感特征会对公平精度负面影响。为解决这些限制，我们提出了一个框架，用于建立具有更好的公平精度负面的属性分类器。我们的方法会在属性分类器中引入不确定性意识，并在拥有最低不确定性的人口信息上遵循公平约束。我们的实验表明，对不确定的敏感特征进行公平约束是对公平和准确性的负面影响。我们的方案在两个 datasets 上进行了实验，结果表明，我们的框架可以在公平精度负面上取得显著更好的性能，并且超过使用真实敏感特征进行约束的模型。这种情况下，我们的框架可以更好地处理人口缺失的问题。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Certified-Training-Towards-Better-Accuracy-Robustness-Tradeoffs"><a href="#Adaptive-Certified-Training-Towards-Better-Accuracy-Robustness-Tradeoffs" class="headerlink" title="Adaptive Certified Training: Towards Better Accuracy-Robustness Tradeoffs"></a>Adaptive Certified Training: Towards Better Accuracy-Robustness Tradeoffs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13078">http://arxiv.org/abs/2307.13078</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhakshylyk Nurlanov, Frank R. Schmidt, Florian Bernard</li>
<li>for: 本研究旨在提高深度学习模型的可靠性，尤其是在实际应用中。</li>
<li>methods: 我们提出了一种基于适应证明半径的新训练方法，以提高模型的标准准确率和鲁棒性。</li>
<li>results: 我们在MNIST、CIFAR-10和TinyImageNet datasets上进行了实验，并证明了我们的方法可以提高模型的鲁棒性，并且在标准准确率保持不变的情况下提高模型的鲁棒性。特别是在CIFAR-10和TinyImageNet上，我们的方法可以提高模型的鲁棒性至多两倍，并且在同等标准准确率水平下。<details>
<summary>Abstract</summary>
As deep learning models continue to advance and are increasingly utilized in real-world systems, the issue of robustness remains a major challenge. Existing certified training methods produce models that achieve high provable robustness guarantees at certain perturbation levels. However, the main problem of such models is a dramatically low standard accuracy, i.e. accuracy on clean unperturbed data, that makes them impractical. In this work, we consider a more realistic perspective of maximizing the robustness of a model at certain levels of (high) standard accuracy. To this end, we propose a novel certified training method based on a key insight that training with adaptive certified radii helps to improve both the accuracy and robustness of the model, advancing state-of-the-art accuracy-robustness tradeoffs. We demonstrate the effectiveness of the proposed method on MNIST, CIFAR-10, and TinyImageNet datasets. Particularly, on CIFAR-10 and TinyImageNet, our method yields models with up to two times higher robustness, measured as an average certified radius of a test set, at the same levels of standard accuracy compared to baseline approaches.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="LLM-Rec-Personalized-Recommendation-via-Prompting-Large-Language-Models"><a href="#LLM-Rec-Personalized-Recommendation-via-Prompting-Large-Language-Models" class="headerlink" title="LLM-Rec: Personalized Recommendation via Prompting Large Language Models"></a>LLM-Rec: Personalized Recommendation via Prompting Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15780">http://arxiv.org/abs/2307.15780</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanjia Lyu, Song Jiang, Hanqing Zeng, Qifan Wang, Si Zhang, Ren Chen, Chris Leung, Jiajie Tang, Yinglong Xia, Jiebo Luo</li>
<li>for: 提高个性化推荐性能</li>
<li>methods: 使用大语言模型（LLM）输入增强strategies，包括基本提示、推荐驱动提示、参与度引导提示和推荐驱动+参与度引导提示</li>
<li>results: 结合LLM生成的增强输入文本后，个性化推荐性能得到提高，推荐驱动和参与度引导提示策略可以启动LLM理解全球和本地项目特点。<details>
<summary>Abstract</summary>
We investigate various prompting strategies for enhancing personalized recommendation performance with large language models (LLMs) through input augmentation. Our proposed approach, termed LLM-Rec, encompasses four distinct prompting strategies: (1) basic prompting, (2) recommendation-driven prompting, (3) engagement-guided prompting, and (4) recommendation-driven + engagement-guided prompting. Our empirical experiments show that incorporating the augmented input text generated by LLM leads to improved recommendation performance. Recommendation-driven and engagement-guided prompting strategies are found to elicit LLM's understanding of global and local item characteristics. This finding highlights the importance of leveraging diverse prompts and input augmentation techniques to enhance the recommendation capabilities with LLMs.
</details>
<details>
<summary>摘要</summary>
我们研究了多种提示策略，以提高大语言模型（LLM）个性化推荐性能。我们提出的方法，称之为LLM-Rec，包括四种不同的提示策略：（1）基础提示，（2）推荐驱动提示，（3）参与指导提示，和（4）推荐驱动+参与指导提示。我们的实验表明，通过将LLM生成的增强输入文本 integrating 到推荐系统中，可以提高推荐性能。推荐驱动和参与指导提示策略可以引导LLM理解全球和本地项目特征。这一发现强调了利用多种提示和输入增强技术，以提高LLM推荐能力。
</details></li>
</ul>
<hr>
<h2 id="Personalized-Category-Frequency-prediction-for-Buy-It-Again-recommendations"><a href="#Personalized-Category-Frequency-prediction-for-Buy-It-Again-recommendations" class="headerlink" title="Personalized Category Frequency prediction for Buy It Again recommendations"></a>Personalized Category Frequency prediction for Buy It Again recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01195">http://arxiv.org/abs/2308.01195</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amit Pande, Kunal Ghosh, Rankyung Park</li>
<li>for: 这个论文的目的是提出一种基于个性化类别的推荐系统，以帮助零售商提高用户体验和网站参与度。</li>
<li>methods: 该论文提出了一种叫做层次PCIC模型，它包括个性化类别模型（PC模型）和个性化类别下的项模型（IC模型）。PC模型生成了个性化的类别列表，IC模型排名类别下的项目。这个模型使用生存分布模型和时间序列模型来捕捉产品的通用消耗率和趋势。</li>
<li>results: 相比十二个基准模型，PCIC提高了NDCG达16%，同时提高了回归率约2%。PCIC可以在大规模数据集上进行批量训练（耗时8个小时），并在一家大型零售商的官方网站上进行AB测试，导致用户参与度得到了显著提高。<details>
<summary>Abstract</summary>
Buy It Again (BIA) recommendations are crucial to retailers to help improve user experience and site engagement by suggesting items that customers are likely to buy again based on their own repeat purchasing patterns. Most existing BIA studies analyze guests personalized behavior at item granularity. A category-based model may be more appropriate in such scenarios. We propose a recommendation system called a hierarchical PCIC model that consists of a personalized category model (PC model) and a personalized item model within categories (IC model). PC model generates a personalized list of categories that customers are likely to purchase again. IC model ranks items within categories that guests are likely to consume within a category. The hierarchical PCIC model captures the general consumption rate of products using survival models. Trends in consumption are captured using time series models. Features derived from these models are used in training a category-grained neural network. We compare PCIC to twelve existing baselines on four standard open datasets. PCIC improves NDCG up to 16 percent while improving recall by around 2 percent. We were able to scale and train (over 8 hours) PCIC on a large dataset of 100M guests and 3M items where repeat categories of a guest out number repeat items. PCIC was deployed and AB tested on the site of a major retailer, leading to significant gains in guest engagement.
</details>
<details>
<summary>摘要</summary>
Buy It Again（BIA）建议对零售商非常重要，可以帮助提高用户体验和网站参与度，通过建议客户可能会再次购买的商品，基于客户的重复购买模式。大多数现有的BIA研究分析客人个性化行为的项目粒度。我们提出了一种推荐系统，即层次PCIC模型，它包括个性化类别模型（PC模型）和个性化类别内项模型（IC模型）。PC模型生成了客户可能会购买的个性化类别列表。IC模型在类别内排名客户可能会消耗的项目。层次PCIC模型捕捉了产品的总消耗率，使用生存模型记录时间序列模型。这些模型中的特征被用于训练类别粒度的神经网络。我们与12个基准模型进行比较，PCIC提高了NDCG达16%，同时提高了回归率约2%。我们可以在8小时内扩展和训练PCIC模型（100万客户和300万项目），并在一家大型零售商的官方网站上部署PCIC模型，导致用户参与度显著增长。
</details></li>
</ul>
<hr>
<h2 id="Parallel-Q-Learning-Scaling-Off-policy-Reinforcement-Learning-under-Massively-Parallel-Simulation"><a href="#Parallel-Q-Learning-Scaling-Off-policy-Reinforcement-Learning-under-Massively-Parallel-Simulation" class="headerlink" title="Parallel $Q$-Learning: Scaling Off-policy Reinforcement Learning under Massively Parallel Simulation"></a>Parallel $Q$-Learning: Scaling Off-policy Reinforcement Learning under Massively Parallel Simulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12983">http://arxiv.org/abs/2307.12983</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Improbable-AI/pql">https://github.com/Improbable-AI/pql</a></li>
<li>paper_authors: Zechu Li, Tao Chen, Zhang-Wei Hong, Anurag Ajay, Pulkit Agrawal</li>
<li>for: 这个论文是为了提高复杂任务的强化学习效率，特别是利用高性能的GPU加速器进行数据采集和训练。</li>
<li>methods: 这个论文使用了并行$Q$-学习（PQL）算法，该算法可以并行采集数据、学习策略和价值函数，从而提高强化学习的效率。</li>
<li>results: 该论文通过实验表明，使用PQL算法可以在短短的wall-clock时间内完成复杂任务的强化学习训练，并且能够保持偏离策略的数据效率。此外，论文还 investigate了强化学习学习速度的关键因素。<details>
<summary>Abstract</summary>
Reinforcement learning is time-consuming for complex tasks due to the need for large amounts of training data. Recent advances in GPU-based simulation, such as Isaac Gym, have sped up data collection thousands of times on a commodity GPU. Most prior works used on-policy methods like PPO due to their simplicity and ease of scaling. Off-policy methods are more data efficient but challenging to scale, resulting in a longer wall-clock training time. This paper presents a Parallel $Q$-Learning (PQL) scheme that outperforms PPO in wall-clock time while maintaining superior sample efficiency of off-policy learning. PQL achieves this by parallelizing data collection, policy learning, and value learning. Different from prior works on distributed off-policy learning, such as Apex, our scheme is designed specifically for massively parallel GPU-based simulation and optimized to work on a single workstation. In experiments, we demonstrate that $Q$-learning can be scaled to \textit{tens of thousands of parallel environments} and investigate important factors affecting learning speed. The code is available at https://github.com/Improbable-AI/pql.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>因为复杂任务需要大量训练数据，因此强化学习需要较长的时间。 latest advances in GPU-based simulation, such as Isaac Gym, have sped up data collection by thousands of times on a commodity GPU. Most prior works used on-policy methods like PPO due to their simplicity and ease of scaling. Off-policy methods are more data efficient but challenging to scale, resulting in longer wall-clock training time. This paper presents a Parallel $Q$-Learning (PQL) scheme that outperforms PPO in wall-clock time while maintaining the superior sample efficiency of off-policy learning. PQL achieves this by parallelizing data collection, policy learning, and value learning. Unlike prior works on distributed off-policy learning, such as Apex, our scheme is designed specifically for massively parallel GPU-based simulation and optimized to work on a single workstation. In experiments, we demonstrate that $Q$-learning can be scaled to tens of thousands of parallel environments and investigate important factors affecting learning speed. The code is available at https://github.com/Improbable-AI/pql.
</details></li>
</ul>
<hr>
<h2 id="3D-LLM-Injecting-the-3D-World-into-Large-Language-Models"><a href="#3D-LLM-Injecting-the-3D-World-into-Large-Language-Models" class="headerlink" title="3D-LLM: Injecting the 3D World into Large Language Models"></a>3D-LLM: Injecting the 3D World into Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12981">http://arxiv.org/abs/2307.12981</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/UMass-Foundation-Model/3D-LLM">https://github.com/UMass-Foundation-Model/3D-LLM</a></li>
<li>paper_authors: Yining Hong, Haoyu Zhen, Peihao Chen, Shuhong Zheng, Yilun Du, Zhenfang Chen, Chuang Gan</li>
<li>for: This paper is written for proposing a new family of 3D language models (3D-LLMs) that can take 3D point clouds and their features as input and perform a diverse set of 3D-related tasks.</li>
<li>methods: The paper uses three types of prompting mechanisms to collect over 300k 3D-language data covering tasks such as captioning, dense captioning, 3D question answering, task decomposition, 3D grounding, 3D-assisted dialog, navigation, and more. The paper also utilizes a 3D feature extractor to obtain 3D features from rendered multi-view images, and uses 2D VLMs as the backbone to train the 3D-LLMs. Additionally, the paper introduces a 3D localization mechanism to better capture 3D spatial information.</li>
<li>results: The paper shows that the proposed 3D-LLMs outperform state-of-the-art baselines on the ScanQA dataset, with a BLEU-1 score that surpasses the state-of-the-art score by 9%. Additionally, the paper shows that the 3D-LLMs outperform 2D VLMs on held-in datasets for 3D captioning, task composition, and 3D-assisted dialogue, and provides qualitative examples of the model’s ability to perform tasks beyond the scope of existing LLMs and VLMs.Here’s the format you requested:</li>
<li>for: 这篇论文是为了提出一种新的3D语言模型（3D-LLMs），可以将3D点云和其特征作为输入，并执行多种3D相关任务。</li>
<li>methods: 论文使用三种提问机制来收集超过300k个3D语言数据，覆盖包括captioning、dense captioning、3D问答、任务分解、3D静止、3D-assisted dialog、导航等任务。论文还利用了一种3D特征提取器来从渲染多视图图像中提取3D特征。在训练3D-LLMs时，论文使用2D VLMs作为基础。此外，论文还引入了3D地址机制，使3D-LLMs更好地捕捉3D空间信息。</li>
<li>results: 论文显示，提出的3D-LLMs在ScanQA数据集上超过了状态艺术基线，BLEU-1分数高于状态艺术分数 by 9%。此外，论文还显示，3D-LLMs在固定数据集上超过了2D VLMs，并提供了质量例子，表明模型可以完成超出现有LLMs和VLMs的任务。<details>
<summary>Abstract</summary>
Large language models (LLMs) and Vision-Language Models (VLMs) have been proven to excel at multiple tasks, such as commonsense reasoning. Powerful as these models can be, they are not grounded in the 3D physical world, which involves richer concepts such as spatial relationships, affordances, physics, layout, and so on. In this work, we propose to inject the 3D world into large language models and introduce a whole new family of 3D-LLMs. Specifically, 3D-LLMs can take 3D point clouds and their features as input and perform a diverse set of 3D-related tasks, including captioning, dense captioning, 3D question answering, task decomposition, 3D grounding, 3D-assisted dialog, navigation, and so on. Using three types of prompting mechanisms that we design, we are able to collect over 300k 3D-language data covering these tasks. To efficiently train 3D-LLMs, we first utilize a 3D feature extractor that obtains 3D features from rendered multi- view images. Then, we use 2D VLMs as our backbones to train our 3D-LLMs. By introducing a 3D localization mechanism, 3D-LLMs can better capture 3D spatial information. Experiments on ScanQA show that our model outperforms state-of-the-art baselines by a large margin (e.g., the BLEU-1 score surpasses state-of-the-art score by 9%). Furthermore, experiments on our held-in datasets for 3D captioning, task composition, and 3D-assisted dialogue show that our model outperforms 2D VLMs. Qualitative examples also show that our model could perform more tasks beyond the scope of existing LLMs and VLMs. Project Page: : https://vis-www.cs.umass.edu/3dllm/.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）和视力语言模型（VLM）已经证明可以在多个任务上表现出色，如常识理解。尽管这些模型强大，但它们不是基于3D物理世界的，这个世界包括更加复杂的概念，如空间关系、可用性、物理、布局等。在这项工作中，我们提议将3D世界注入到大型语言模型中，并 introduce a whole new family of 3D-LLMs。Specifically, 3D-LLMs can take 3D点云和其特征作为输入，并执行一系列3D相关任务，包括captioning、dense captioning、3D问答、任务分解、3D定位、3D辅助对话、导航等。通过我们设计的三种提示机制，我们能够收集超过300k的3D语言数据覆盖这些任务。为有效地训练3D-LLMs，我们首先利用3D特征EXTRACTOR提取3D特征从渲染多视图图像中。然后，我们使用2D VLMs作为我们的背部来训练我们的3D-LLMs。通过引入3D本地化机制，3D-LLMs可以更好地捕捉3D空间信息。ScanQA实验结果显示，我们的模型超过了状态机的基准值（例如BLEU-1分数超过了状态机的分数 by 9%）。此外，我们在我们保留的数据集上进行3D captioning、任务组合和3D辅助对话的实验，我们的模型超过了2D VLMs。质量例子也表明我们的模型可以完成更多的任务，超出现有LLMs和VLMs的范围。项目页面：https://vis-www.cs.umass.edu/3dllm/。
</details></li>
</ul>
<hr>
<h2 id="A-Connection-between-One-Step-Regularization-and-Critic-Regularization-in-Reinforcement-Learning"><a href="#A-Connection-between-One-Step-Regularization-and-Critic-Regularization-in-Reinforcement-Learning" class="headerlink" title="A Connection between One-Step Regularization and Critic Regularization in Reinforcement Learning"></a>A Connection between One-Step Regularization and Critic Regularization in Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12968">http://arxiv.org/abs/2307.12968</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ben-eysenbach/ac-connection">https://github.com/ben-eysenbach/ac-connection</a></li>
<li>paper_authors: Benjamin Eysenbach, Matthieu Geist, Sergey Levine, Ruslan Salakhutdinov</li>
<li>for: 这个论文的目的是解释一些离线RL算法的正则化方法，以提高其性能。</li>
<li>methods: 这个论文使用了一些常用的离线RL算法，如CQL和一步RL，并对它们进行了正则化。</li>
<li>results: 研究发现，使用一步RL可以得到类似于critic正则化的性能，但是需要更多的计算资源。而在实际应用中，使用一步RL可以实现稳定和简单的RL方法，但是其性能可能不及critic正则化。<details>
<summary>Abstract</summary>
As with any machine learning problem with limited data, effective offline RL algorithms require careful regularization to avoid overfitting. One-step methods perform regularization by doing just a single step of policy improvement, while critic regularization methods do many steps of policy improvement with a regularized objective. These methods appear distinct. One-step methods, such as advantage-weighted regression and conditional behavioral cloning, truncate policy iteration after just one step. This ``early stopping'' makes one-step RL simple and stable, but can limit its asymptotic performance. Critic regularization typically requires more compute but has appealing lower-bound guarantees. In this paper, we draw a close connection between these methods: applying a multi-step critic regularization method with a regularization coefficient of 1 yields the same policy as one-step RL. While practical implementations violate our assumptions and critic regularization is typically applied with smaller regularization coefficients, our experiments nevertheless show that our analysis makes accurate, testable predictions about practical offline RL methods (CQL and one-step RL) with commonly-used hyperparameters. Our results that every problem can be solved with a single step of policy improvement, but rather that one-step RL might be competitive with critic regularization on RL problems that demand strong regularization.
</details>
<details>
<summary>摘要</summary>
“与有限数据的机器学习问题相似，有效的离线RL算法需要仔细的规则化以避免过拟合。一步方法在做出一步策略改进后就结束，而批处规则化方法则在多个步骤策略改进中使用规则化目标。这些方法看起来很不同。一步方法，如偏好权重回归和 conditional behavioral cloning，在做出一步策略改进后就结束。这种``早期停止''使得一步RL简单和稳定，但可能限制其极限性能。批处规则化通常需要更多的计算资源，但它具有吸引人的下界保证。在这篇论文中，我们将一步和批处规则化方法之间 Draw a close connection：在应用多步批处规则化方法时，使用规则化系数为1就等于一步RL。虽然实践中的假设不符合我们的假设，但我们的实验表明，我们的分析对实际的离线RL方法（CQL和一步RL）的实现进行了准确和可靠的预测。我们的结果表明，每个问题都可以通过一步策略改进来解决，但是一步RL可能与批处规则化在RL问题上具有强规则化的情况下竞争。”
</details></li>
</ul>
<hr>
<h2 id="Enhancing-image-captioning-with-depth-information-using-a-Transformer-based-framework"><a href="#Enhancing-image-captioning-with-depth-information-using-a-Transformer-based-framework" class="headerlink" title="Enhancing image captioning with depth information using a Transformer-based framework"></a>Enhancing image captioning with depth information using a Transformer-based framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03767">http://arxiv.org/abs/2308.03767</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aya Mahmoud Ahmed, Mohamed Yousef, Khaled F. Hussain, Yousef Bassyouni Mahdy</li>
<li>for: 提高图像描述性能</li>
<li>methods: 使用 transformer 架构，RGB 图像和其对应的深度图像进行共同描述</li>
<li>results: 在 NYU-v2 和 Stanford 图像段落描述数据集上实现了提高描述性能，并提出了一个更正版的 NYU-v2 数据集。Here’s the full Chinese text:</li>
<li>for: 本文 investigate  Whether integrating depth information with RGB images can enhance the captioning task and generate better descriptions.</li>
<li>methods: 我们提出了一个基于 transformer 架构的 RGB 图像和其对应的深度图像共同描述框架。</li>
<li>results: 我们在 NYU-v2 和 Stanford 图像段落描述数据集上实现了提高描述性能，并提出了一个更正版的 NYU-v2 数据集。<details>
<summary>Abstract</summary>
Captioning images is a challenging scene-understanding task that connects computer vision and natural language processing. While image captioning models have been successful in producing excellent descriptions, the field has primarily focused on generating a single sentence for 2D images. This paper investigates whether integrating depth information with RGB images can enhance the captioning task and generate better descriptions. For this purpose, we propose a Transformer-based encoder-decoder framework for generating a multi-sentence description of a 3D scene. The RGB image and its corresponding depth map are provided as inputs to our framework, which combines them to produce a better understanding of the input scene. Depth maps could be ground truth or estimated, which makes our framework widely applicable to any RGB captioning dataset. We explored different fusion approaches to fuse RGB and depth images. The experiments are performed on the NYU-v2 dataset and the Stanford image paragraph captioning dataset. During our work with the NYU-v2 dataset, we found inconsistent labeling that prevents the benefit of using depth information to enhance the captioning task. The results were even worse than using RGB images only. As a result, we propose a cleaned version of the NYU-v2 dataset that is more consistent and informative. Our results on both datasets demonstrate that the proposed framework effectively benefits from depth information, whether it is ground truth or estimated, and generates better captions. Code, pre-trained models, and the cleaned version of the NYU-v2 dataset will be made publically available.
</details>
<details>
<summary>摘要</summary>
captioning图像是一个复杂的Scene理解任务，搭配计算机视觉和自然语言处理。虽然图像描述模型已经在生成出excelente描述，但这个领域主要集中在生成2D图像的单个句子。这篇论文 investigates whether integrating depth信息withRGB图像可以提高描述任务并生成更好的描述。为此，我们提出了一个基于Transformer架构的encoder-decoder框架，用于生成3D场景的多句子描述。RGB图像和其相应的深度图被提供为我们框架的输入，我们将它们结合以生成更好的对输入场景的理解。深度图可以是真实的或估计的，使我们的框架适用于任何RGB描述数据集。我们实现了不同的融合方法来融合RGB和深度图像。实验在NYU-v2数据集和Stanford图像段落描述数据集进行。在我们的NYU-v2数据集工作中，我们发现了不一致的标签，这阻碍了使用深度信息提高描述任务的好处。结果甚至比使用RGB图像alone更差。因此，我们提出了一个更正版的NYU-v2数据集，其标签更加一致和有用。我们的结果在两个数据集上表明，我们的提案的框架可以受益于深度信息，无论是真实的或估计的，并生成更好的描述。代码、预训练模型和更正版的NYU-v2数据集将公开发布。
</details></li>
</ul>
<hr>
<h2 id="RLCD-Reinforcement-Learning-from-Contrast-Distillation-for-Language-Model-Alignment"><a href="#RLCD-Reinforcement-Learning-from-Contrast-Distillation-for-Language-Model-Alignment" class="headerlink" title="RLCD: Reinforcement Learning from Contrast Distillation for Language Model Alignment"></a>RLCD: Reinforcement Learning from Contrast Distillation for Language Model Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12950">http://arxiv.org/abs/2307.12950</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/rlcd">https://github.com/facebookresearch/rlcd</a></li>
<li>paper_authors: Kevin Yang, Dan Klein, Asli Celikyilmaz, Nanyun Peng, Yuandong Tian</li>
<li>for: 本研究旨在开发一种不使用人类反馈的自然语言原则Alignment方法，以提高语言模型的表现。</li>
<li>methods: 本方法使用模拟的偏好对，包括高质量和低质量示例，通过对比正向和负向提示来训练偏好模型。然后，使用奖励学习来改进基础不aligned语言模型。</li>
<li>results: 实验表明，RLCD方法在三种多样化的对齐任务中（无害性、有益性、故事简 outline生成）均表现出色，并在7B和30B模型缩放下表现出超过RLAIF（Bai et al., 2022b）和上下文混合（Huang et al., 2022）基eline的result。<details>
<summary>Abstract</summary>
We propose Reinforcement Learning from Contrast Distillation (RLCD), a method for aligning language models to follow natural language principles without using human feedback. RLCD trains a preference model using simulated preference pairs that contain both a high-quality and low-quality example, generated using contrasting positive and negative prompts. The preference model is then used to improve a base unaligned language model via reinforcement learning. Empirically, RLCD outperforms RLAIF (Bai et al., 2022b) and context distillation (Huang et al., 2022) baselines across three diverse alignment tasks--harmlessness, helpfulness, and story outline generation--and on both 7B and 30B model scales for preference data simulation.
</details>
<details>
<summary>摘要</summary>
我们提议一种基于强化学习的自然语言原则对齐方法，称为强化学习自然语言原则（RLCD）。RLCD使用模拟的偏好对使用了对比正反例的高质量和低质量示例，通过偏好模型进行改进。我们在三种多样化的对齐任务中（无害、有用和故事笔记生成） empirically 证明RLCD超过RLAIF（Bai et al., 2022b）和语音维度（Huang et al., 2022）基elines，并在7B和30B模型缩放下进行偏好数据模拟。
</details></li>
</ul>
<hr>
<h2 id="On-Privileged-and-Convergent-Bases-in-Neural-Network-Representations"><a href="#On-Privileged-and-Convergent-Bases-in-Neural-Network-Representations" class="headerlink" title="On Privileged and Convergent Bases in Neural Network Representations"></a>On Privileged and Convergent Bases in Neural Network Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12941">http://arxiv.org/abs/2307.12941</a></li>
<li>repo_url: None</li>
<li>paper_authors: Davis Brown, Nikhil Vyas, Yamini Bansal</li>
<li>for: 本研究探究 neural network 学习的表示方式是否具有特权和共同基准。</li>
<li>methods: 研究使用各个神经元表示的特征方向的重要性。</li>
<li>results: 发现 neural network 表示不具有完全旋转不变性，并且在不同初始化的情况下，多个基准可以实现相同的性能。<details>
<summary>Abstract</summary>
In this study, we investigate whether the representations learned by neural networks possess a privileged and convergent basis. Specifically, we examine the significance of feature directions represented by individual neurons. First, we establish that arbitrary rotations of neural representations cannot be inverted (unlike linear networks), indicating that they do not exhibit complete rotational invariance. Subsequently, we explore the possibility of multiple bases achieving identical performance. To do this, we compare the bases of networks trained with the same parameters but with varying random initializations. Our study reveals two findings: (1) Even in wide networks such as WideResNets, neural networks do not converge to a unique basis; (2) Basis correlation increases significantly when a few early layers of the network are frozen identically.   Furthermore, we analyze Linear Mode Connectivity, which has been studied as a measure of basis correlation. Our findings give evidence that while Linear Mode Connectivity improves with increased network width, this improvement is not due to an increase in basis correlation.
</details>
<details>
<summary>摘要</summary>
在这个研究中，我们研究神经网络学习的表示方式是否具有特权和共同基准。 Specifically，我们研究神经元每个个体的特征方向的重要性。首先，我们证明神经网络中的表示不能逆转（不同于线性网络），这表明它们不具备完全旋转不变性。接着，我们探索多个基准是否可以实现相同的性能。为此，我们比较由同样的参数训练而成的不同随机初始化的网络的基准。我们的研究发现了两点：1.  même dans les réseaux larges tels que les WideResNets, les réseaux neuronaux ne convergent pas vers une base unique;2. La corrélation de la base augmente significativement lorsque les premières couches du réseau sont gelées de manière identique. En outre, nous analysons la connectivité linéaire des modes, qui a été étudiée comme une mesure de la corrélation de la base. Nos résultats montrent que si la largeur du réseau augmente, la connectivité linéaire des modes s'améliore, mais cet amélioration n'est pas due à une augmentation de la corrélation de la base.
</details></li>
</ul>
<hr>
<h2 id="Rule-By-Example-Harnessing-Logical-Rules-for-Explainable-Hate-Speech-Detection"><a href="#Rule-By-Example-Harnessing-Logical-Rules-for-Explainable-Hate-Speech-Detection" class="headerlink" title="Rule By Example: Harnessing Logical Rules for Explainable Hate Speech Detection"></a>Rule By Example: Harnessing Logical Rules for Explainable Hate Speech Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12935">http://arxiv.org/abs/2307.12935</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chrisisking/rule-by-example">https://github.com/chrisisking/rule-by-example</a></li>
<li>paper_authors: Christopher Clarke, Matthew Hall, Gaurav Mittal, Ye Yu, Sandra Sajeev, Jason Mars, Mei Chen</li>
<li>for: 这个论文旨在解决现代在线内容审核中的挑战，即使用深度学习模型来取代规则驱动的方法，以提高内容审核的可靠性和可 explainer。</li>
<li>methods: 这个论文提出了一种新的示例基于对比学习方法，称为规则示例学习（Rule By Example，RBE），可以从逻辑规则中学习rich embedding表示。</li>
<li>results: 实验结果表明，RBE可以在3个popular hate speech classification dataset上超越现状的深度学习分类器，以及使用规则和无监督学习方法，同时提供可 explainer的模型预测结果via规则基准。<details>
<summary>Abstract</summary>
Classic approaches to content moderation typically apply a rule-based heuristic approach to flag content. While rules are easily customizable and intuitive for humans to interpret, they are inherently fragile and lack the flexibility or robustness needed to moderate the vast amount of undesirable content found online today. Recent advances in deep learning have demonstrated the promise of using highly effective deep neural models to overcome these challenges. However, despite the improved performance, these data-driven models lack transparency and explainability, often leading to mistrust from everyday users and a lack of adoption by many platforms. In this paper, we present Rule By Example (RBE): a novel exemplar-based contrastive learning approach for learning from logical rules for the task of textual content moderation. RBE is capable of providing rule-grounded predictions, allowing for more explainable and customizable predictions compared to typical deep learning-based approaches. We demonstrate that our approach is capable of learning rich rule embedding representations using only a few data examples. Experimental results on 3 popular hate speech classification datasets show that RBE is able to outperform state-of-the-art deep learning classifiers as well as the use of rules in both supervised and unsupervised settings while providing explainable model predictions via rule-grounding.
</details>
<details>
<summary>摘要</summary>
传统的内容审核方法通常采用规则基于的冒泡法来标识内容。虽然规则容易自定义和人类易于理解，但它们具有脆弱性和缺乏在当今互联网上巨量undesirable content的适应性。近年来，深度学习的进步有力地解决了这些挑战。然而，尽管表现得到改善，这些数据驱动模型仍然缺乏透明性和可解释性，导致用户和多个平台的不信任。在这篇论文中，我们提出了 Rule By Example (RBE)：一种基于例子的对比学习方法，用于从逻辑规则中学习文本内容审核任务。RBE可以提供规则基于的预测，使得模型预测更加可解释和自定义。我们示示了我们的方法可以使用只有几个数据示例来学习丰富的规则嵌入表示。实验结果表明，RBE在3个流行的仇恨言语分类数据集上能够超越当前的深度学习分类器和规则在指导下的情况下，同时提供可解释的模型预测 via 规则嵌入。
</details></li>
</ul>
<hr>
<h2 id="Theoretically-Guaranteed-Policy-Improvement-Distilled-from-Model-Based-Planning"><a href="#Theoretically-Guaranteed-Policy-Improvement-Distilled-from-Model-Based-Planning" class="headerlink" title="Theoretically Guaranteed Policy Improvement Distilled from Model-Based Planning"></a>Theoretically Guaranteed Policy Improvement Distilled from Model-Based Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12933">http://arxiv.org/abs/2307.12933</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chuming Li, Ruonan Jia, Jie Liu, Yinmin Zhang, Yazhe Niu, Yaodong Yang, Yu Liu, Wanli Ouyang</li>
<li>for: 这篇论文是为了提出一种基于模型的 reinforcement learning 算法，以提高控制任务的效率。</li>
<li>methods: 该论文使用了模型改进阶段来储存优化的动作序列，并通过Policy ImprovementStep进行了优化。</li>
<li>results: 实验表明，MPDP算法在六个 MuJoCo 连续控制任务上实现了更高的样本效率和极限性性能，比较model-free和基于模型的 плани法。<details>
<summary>Abstract</summary>
Model-based reinforcement learning (RL) has demonstrated remarkable successes on a range of continuous control tasks due to its high sample efficiency. To save the computation cost of conducting planning online, recent practices tend to distill optimized action sequences into an RL policy during the training phase. Although the distillation can incorporate both the foresight of planning and the exploration ability of RL policies, the theoretical understanding of these methods is yet unclear. In this paper, we extend the policy improvement step of Soft Actor-Critic (SAC) by developing an approach to distill from model-based planning to the policy. We then demonstrate that such an approach of policy improvement has a theoretical guarantee of monotonic improvement and convergence to the maximum value defined in SAC. We discuss effective design choices and implement our theory as a practical algorithm -- Model-based Planning Distilled to Policy (MPDP) -- that updates the policy jointly over multiple future time steps. Extensive experiments show that MPDP achieves better sample efficiency and asymptotic performance than both model-free and model-based planning algorithms on six continuous control benchmark tasks in MuJoCo.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Contextual-Bandits-and-Imitation-Learning-via-Preference-Based-Active-Queries"><a href="#Contextual-Bandits-and-Imitation-Learning-via-Preference-Based-Active-Queries" class="headerlink" title="Contextual Bandits and Imitation Learning via Preference-Based Active Queries"></a>Contextual Bandits and Imitation Learning via Preference-Based Active Queries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12926">http://arxiv.org/abs/2307.12926</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ayush Sekhari, Karthik Sridharan, Wen Sun, Runzhe Wu</li>
<li>for: 本研究考虑了上下文搬狮和模仿学习问题，learner 缺乏直接行动的奖励信息，而是可以在每个回合中aktive查询专家以获取不准确的偏好反馈。learner 的目标是同时减少执行行动的 regret 和对专家进行比较查询的次数。</li>
<li>methods: 本研究提出了一种算法，该算法利用在函数类型上的在线回归 oracle，以选择行动和决定何时进行查询。对于上下文搬狮 Setting，我们的算法实现了一个 regret  bound，其中 regret 的极限为 $O(\min{\sqrt{T}, d&#x2F;\Delta})$，其中 $T$ 表示互动次数，$d$ 表示函数类型的拓扑维度，$\Delta$ 表示最佳行动对所有上下文下的最小偏好。我们的算法不需要知道 $\Delta$，并且与标准上下文搬狮 Setting 中获得的 regret bound相当。此外，我们的算法只需要对专家进行 $O(\min{T, d^2&#x2F;\Delta^2})$ 次查询。</li>
<li>results: 我们的算法可以在上下文搬狮和模仿学习 Setting 中实现 regret  bound，同时减少对专家的查询次数。在模仿学习 Setting 中，我们的算法甚至可以超过专家的性能，这 highlights 一个实际的应用优点，即在不熟悉环境中，可以通过偏好反馈来学习并超越专家。<details>
<summary>Abstract</summary>
We consider the problem of contextual bandits and imitation learning, where the learner lacks direct knowledge of the executed action's reward. Instead, the learner can actively query an expert at each round to compare two actions and receive noisy preference feedback. The learner's objective is two-fold: to minimize the regret associated with the executed actions, while simultaneously, minimizing the number of comparison queries made to the expert. In this paper, we assume that the learner has access to a function class that can represent the expert's preference model under appropriate link functions, and provide an algorithm that leverages an online regression oracle with respect to this function class for choosing its actions and deciding when to query. For the contextual bandit setting, our algorithm achieves a regret bound that combines the best of both worlds, scaling as $O(\min\{\sqrt{T}, d/\Delta\})$, where $T$ represents the number of interactions, $d$ represents the eluder dimension of the function class, and $\Delta$ represents the minimum preference of the optimal action over any suboptimal action under all contexts. Our algorithm does not require the knowledge of $\Delta$, and the obtained regret bound is comparable to what can be achieved in the standard contextual bandits setting where the learner observes reward signals at each round. Additionally, our algorithm makes only $O(\min\{T, d^2/\Delta^2\})$ queries to the expert. We then extend our algorithm to the imitation learning setting, where the learning agent engages with an unknown environment in episodes of length $H$ each, and provide similar guarantees for regret and query complexity. Interestingly, our algorithm for imitation learning can even learn to outperform the underlying expert, when it is suboptimal, highlighting a practical benefit of preference-based feedback in imitation learning.
</details>
<details>
<summary>摘要</summary>
我们考虑了上下文带强盗捕鱼和模仿学习问题，learner缺乏直接行动的奖励知识。而是可以在每个回合中活动地询问专家， comparison two actions，并 receive noisy preference feedback。学习者的目标是两fold：一是最小化执行的行动奖励相关的 regret，二是最小化向专家提问的数量。在这篇文章中，我们假设学习者可以访问一个函数类，该函数类可以表示专家的偏好模型，并提供一个在线回归 oracle，以便选择行动和决定何时向专家提问。对于上下文带强盗捕鱼设置，我们的算法可以达到 $O(\min\{\sqrt{T}, d/\Delta\})$ 的 regret bound，其中 $T$ 表示互动次数， $d$ 表示函数类的吸引力维度， $\Delta$ 表示最佳行动在所有上下文中的最小偏好。我们的算法不需要了解 $\Delta$，并且与标准上下文带强盗捕鱼设置的 regret bound相比，我们的 regret bound相对较高。此外，我们的算法只需要 $O(\min\{T, d^2/\Delta^2\})$ 次向专家提问。然后，我们将我们的算法扩展到模仿学习设置，learner在每个 episodes 中与未知环境互动，并提供了类似的 regret 和查询复杂度保证。有趣的是，我们的算法可以在专家下不佳的情况下，learn to outperform 专家，这 highlights 实用上的 benefit 。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Skeleton-Meta-Prototype-Contrastive-Learning-with-Hard-Skeleton-Mining-for-Unsupervised-Person-Re-Identification"><a href="#Hierarchical-Skeleton-Meta-Prototype-Contrastive-Learning-with-Hard-Skeleton-Mining-for-Unsupervised-Person-Re-Identification" class="headerlink" title="Hierarchical Skeleton Meta-Prototype Contrastive Learning with Hard Skeleton Mining for Unsupervised Person Re-Identification"></a>Hierarchical Skeleton Meta-Prototype Contrastive Learning with Hard Skeleton Mining for Unsupervised Person Re-Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12917">http://arxiv.org/abs/2307.12917</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kali-hac/hi-mpc">https://github.com/kali-hac/hi-mpc</a></li>
<li>paper_authors: Haocong Rao, Cyril Leung, Chunyan Miao</li>
<li>for: 本研究旨在提出一种基于深度感知器和深度学习的人重识别方法，使用无监督的 Hierarchical skeleton Meta-Prototype Contrastive learning (Hi-MPC) 方法，以提高人重识别的精度。</li>
<li>methods: 本方法首先构建了 hierarchical 表示，以模型人体的坐标系和运动特征，从 JOINTS 、component 和 limb 等多个水平。然后，提出了一种 hierarchical meta-prototype contrastive learning 模型，通过对不同水平的skeleton features进行 clustering和对比，以学习更有效的人体特征。此外，还提出了一种硬件骨挖掘机制，以适应ively 挖掘出更有用的骨骼特征。</li>
<li>results: 在五个数据集上进行了广泛的评估，显示了我们的方法可以与现有的state-of-the-art方法进行比较，并且在cross-view人重识别和 RGB 环境下也表现出色。<details>
<summary>Abstract</summary>
With rapid advancements in depth sensors and deep learning, skeleton-based person re-identification (re-ID) models have recently achieved remarkable progress with many advantages. Most existing solutions learn single-level skeleton features from body joints with the assumption of equal skeleton importance, while they typically lack the ability to exploit more informative skeleton features from various levels such as limb level with more global body patterns. The label dependency of these methods also limits their flexibility in learning more general skeleton representations. This paper proposes a generic unsupervised Hierarchical skeleton Meta-Prototype Contrastive learning (Hi-MPC) approach with Hard Skeleton Mining (HSM) for person re-ID with unlabeled 3D skeletons. Firstly, we construct hierarchical representations of skeletons to model coarse-to-fine body and motion features from the levels of body joints, components, and limbs. Then a hierarchical meta-prototype contrastive learning model is proposed to cluster and contrast the most typical skeleton features ("prototypes") from different-level skeletons. By converting original prototypes into meta-prototypes with multiple homogeneous transformations, we induce the model to learn the inherent consistency of prototypes to capture more effective skeleton features for person re-ID. Furthermore, we devise a hard skeleton mining mechanism to adaptively infer the informative importance of each skeleton, so as to focus on harder skeletons to learn more discriminative skeleton representations. Extensive evaluations on five datasets demonstrate that our approach outperforms a wide variety of state-of-the-art skeleton-based methods. We further show the general applicability of our method to cross-view person re-ID and RGB-based scenarios with estimated skeletons.
</details>
<details>
<summary>摘要</summary>
With the rapid advancements in depth sensors and deep learning, skeleton-based person re-identification (re-ID) models have recently made significant progress with many advantages. Most existing solutions learn single-level skeleton features from body joints, assuming equal skeleton importance, while they typically lack the ability to exploit more informative skeleton features from various levels such as limb level with more global body patterns. The label dependency of these methods also limits their flexibility in learning more general skeleton representations. This paper proposes a generic unsupervised Hierarchical skeleton Meta-Prototype Contrastive learning (Hi-MPC) approach with Hard Skeleton Mining (HSM) for person re-ID with unlabeled 3D skeletons. Firstly, we construct hierarchical representations of skeletons to model coarse-to-fine body and motion features from the levels of body joints, components, and limbs. Then, we propose a hierarchical meta-prototype contrastive learning model to cluster and contrast the most typical skeleton features ("prototypes") from different-level skeletons. By converting original prototypes into meta-prototypes with multiple homogeneous transformations, we induce the model to learn the inherent consistency of prototypes to capture more effective skeleton features for person re-ID. Furthermore, we devise a hard skeleton mining mechanism to adaptively infer the informative importance of each skeleton, so as to focus on harder skeletons to learn more discriminative skeleton representations. Extensive evaluations on five datasets demonstrate that our approach outperforms a wide variety of state-of-the-art skeleton-based methods. We further show the general applicability of our method to cross-view person re-ID and RGB-based scenarios with estimated skeletons.
</details></li>
</ul>
<hr>
<h2 id="Consensus-based-Participatory-Budgeting-for-Legitimacy-Decision-Support-via-Multi-agent-Reinforcement-Learning"><a href="#Consensus-based-Participatory-Budgeting-for-Legitimacy-Decision-Support-via-Multi-agent-Reinforcement-Learning" class="headerlink" title="Consensus-based Participatory Budgeting for Legitimacy: Decision Support via Multi-agent Reinforcement Learning"></a>Consensus-based Participatory Budgeting for Legitimacy: Decision Support via Multi-agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12915">http://arxiv.org/abs/2307.12915</a></li>
<li>repo_url: None</li>
<li>paper_authors: Srijoni Majumdar, Evangelos Pournaras</li>
<li>for: 这篇论文是关于如何使用协商来改善参与预算的法定程序的，以提高公共基金的分配的公正性和包容性。</li>
<li>methods: 这篇论文提出了一种新的协商方法，使用多代理人强化学习技术来支持决策，并帮助选民互动以达成可持续的妥协。</li>
<li>results: 实验结果表明，这种协商方法可以达成妥协，效率高并稳定，而且与现有的投票聚合方法相比，它可以提高公平性和包容性。<details>
<summary>Abstract</summary>
The legitimacy of bottom-up democratic processes for the distribution of public funds by policy-makers is challenging and complex. Participatory budgeting is such a process, where voting outcomes may not always be fair or inclusive. Deliberation for which project ideas to put for voting and choose for implementation lack systematization and do not scale. This paper addresses these grand challenges by introducing a novel and legitimate iterative consensus-based participatory budgeting process. Consensus is designed to be a result of decision support via an innovative multi-agent reinforcement learning approach. Voters are assisted to interact with each other to make viable compromises. Extensive experimental evaluation with real-world participatory budgeting data from Poland reveal striking findings: Consensus is reachable, efficient and robust. Compromise is required, which is though comparable to the one of existing voting aggregation methods that promote fairness and inclusion without though attaining consensus.
</details>
<details>
<summary>摘要</summary>
政策制定者的底层民主过程对公共资金的分配存在挑战和复杂性。参与预算是这种过程之一，其投票结果可能不一定公平和包容。协商选择要投票的项目意见和实施的方法缺乏系统化和扩展性。这篇论文解决这些总统困难，提出了一种新的合法的迭代共识参与预算过程。这种共识是通过创新的多代理增强学习方法支持决策的结果。选民被助け到互动相互，制定可行的妥协。实际在波兰的实验证明了 striking 的发现：共识是可以达成的，高效和稳定。妥协是必要的，与现有的投票集成方法相比，它不一定实现共识，但能够保证公平和包容。
</details></li>
</ul>
<hr>
<h2 id="Graph-Neural-Networks-For-Mapping-Variables-Between-Programs-–-Extended-Version"><a href="#Graph-Neural-Networks-For-Mapping-Variables-Between-Programs-–-Extended-Version" class="headerlink" title="Graph Neural Networks For Mapping Variables Between Programs – Extended Version"></a>Graph Neural Networks For Mapping Variables Between Programs – Extended Version</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13014">http://arxiv.org/abs/2307.13014</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pmorvalho/ecai23-gnns-for-mapping-variables-between-programs">https://github.com/pmorvalho/ecai23-gnns-for-mapping-variables-between-programs</a></li>
<li>paper_authors: Pedro Orvalho, Jelle Piepenbrock, Mikoláš Janota, Vasco Manquinho</li>
<li>for: 本研究旨在提高程序相似性比较的精度和效率，通过使用图神经网络（GNN）将两个程序中变量的集合映射到一起。</li>
<li>methods: 本研究使用了图神经网络（GNN）来映射两个程序的抽象树（AST）中的变量集合。</li>
<li>results: 实验结果显示，我们的方法可以正确地映射83%的评估数据集，而当前状态的程序修复方法（主要基于程序结构）只能修复约72%的错误程序。而我们的方法， solely based on variable mappings，可以修复约88.5%的错误程序。<details>
<summary>Abstract</summary>
Automated program analysis is a pivotal research domain in many areas of Computer Science -- Formal Methods and Artificial Intelligence, in particular. Due to the undecidability of the problem of program equivalence, comparing two programs is highly challenging. Typically, in order to compare two programs, a relation between both programs' sets of variables is required. Thus, mapping variables between two programs is useful for a panoply of tasks such as program equivalence, program analysis, program repair, and clone detection. In this work, we propose using graph neural networks (GNNs) to map the set of variables between two programs based on both programs' abstract syntax trees (ASTs). To demonstrate the strength of variable mappings, we present three use-cases of these mappings on the task of program repair to fix well-studied and recurrent bugs among novice programmers in introductory programming assignments (IPAs). Experimental results on a dataset of 4166 pairs of incorrect/correct programs show that our approach correctly maps 83% of the evaluation dataset. Moreover, our experiments show that the current state-of-the-art on program repair, greatly dependent on the programs' structure, can only repair about 72% of the incorrect programs. In contrast, our approach, which is solely based on variable mappings, can repair around 88.5%.
</details>
<details>
<summary>摘要</summary>
自动化程序分析是计算机科学多个领域的重要研究领域，特别是正式方法和人工智能。由于程序相等性问题是不可解决的，因此比较两个程序是非常困难的。通常，以便比较两个程序，需要两个程序变量集的关系。因此，将变量 между两个程序映射到相同的空间是非常有用的，这有助于许多任务，如程序相等性、程序分析、程序修复和假象检测。在这个工作中，我们提议使用图神经网络（GNNs）将两个程序的变量集映射到相同的空间，基于这两个程序的抽象语法树（ASTs）。为了证明变量映射的强大性，我们在程序修复任务上提供了三个使用情况，用于修复 novice 程序员在入门编程作业（IPAs）中经常出现的常见bug。实验结果表明，我们的方法可以在4166对错误/正确程序的评估集中正确地映射83%的评估集。此外，我们的实验还表明，现有的程序修复方法，强调程序结构，只能修复约72%的错误程序。相比之下，我们的方法，solely基于变量映射，可以修复约88.5%的错误程序。
</details></li>
</ul>
<hr>
<h2 id="Towards-a-Visual-Language-Foundation-Model-for-Computational-Pathology"><a href="#Towards-a-Visual-Language-Foundation-Model-for-Computational-Pathology" class="headerlink" title="Towards a Visual-Language Foundation Model for Computational Pathology"></a>Towards a Visual-Language Foundation Model for Computational Pathology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12914">http://arxiv.org/abs/2307.12914</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ming Y. Lu, Bowen Chen, Drew F. K. Williamson, Richard J. Chen, Ivy Liang, Tong Ding, Guillaume Jaume, Igor Odintsov, Andrew Zhang, Long Phi Le, Georg Gerber, Anil V Parwani, Faisal Mahmood</li>
<li>for: 这篇研究旨在提出一个基于对比学习的类别学习模型，以推广 Histopathology 领域中的诊断和鉴别 tasks。</li>
<li>methods: 这篇研究使用了多种来源的 Histopathology 图像和生医文本，并运用了1,170万个图像-描述对的 pairs 进行task-agnostic pretraining。</li>
<li>results: 研究发现，这个 CONCH 模型可以在13个不同的benchmark上进行 transferred learning，并在 histology 图像分类、分类、描述、文本-图像和图像-文本撷取等下测试得到了顶尖性能。<details>
<summary>Abstract</summary>
The accelerated adoption of digital pathology and advances in deep learning have enabled the development of powerful models for various pathology tasks across a diverse array of diseases and patient cohorts. However, model training is often difficult due to label scarcity in the medical domain and the model's usage is limited by the specific task and disease for which it is trained. Additionally, most models in histopathology leverage only image data, a stark contrast to how humans teach each other and reason about histopathologic entities. We introduce CONtrastive learning from Captions for Histopathology (CONCH), a visual-language foundation model developed using diverse sources of histopathology images, biomedical text, and notably over 1.17 million image-caption pairs via task-agnostic pretraining. Evaluated on a suite of 13 diverse benchmarks, CONCH can be transferred to a wide range of downstream tasks involving either or both histopathology images and text, achieving state-of-the-art performance on histology image classification, segmentation, captioning, text-to-image and image-to-text retrieval. CONCH represents a substantial leap over concurrent visual-language pretrained systems for histopathology, with the potential to directly facilitate a wide array of machine learning-based workflows requiring minimal or no further supervised fine-tuning.
</details>
<details>
<summary>摘要</summary>
随着数字 PATHOLOGY 的加速采用和深度学习的进步，已经开发出了许多强大的模型用于各种疾病和患者群体中的 PATHOLOGY 任务。然而，模型训练往往困难，因为医疗领域中标签的缺乏和模型的使用受到特定任务和疾病的限制。此外，大多数 histopathology 模型仅利用图像数据，与人类教育和理解 histopathologic 实体不符。我们介绍了 CONtrastive learning from Captions for Histopathology (CONCH)，一种基于多种 histopathology 图像、生物医学文本和着重于 1.17 万个图像-caption 对的视觉语言基础模型。在 13 种多样化的标准测试集上评估，CONCH 可以转移到覆盖图像和文本下游任务，实现 histology 图像分类、 segmentation、captioning、text-to-image 和 image-to-text 检索的状态计算机科学中的最佳性能。CONCH 代表了对于 histopathology 的较大的进步，具有直接促进许多机器学习基于工作流程，需要 minimal 或无需进一步的监督微调的潜在。
</details></li>
</ul>
<hr>
<h2 id="GridMM-Grid-Memory-Map-for-Vision-and-Language-Navigation"><a href="#GridMM-Grid-Memory-Map-for-Vision-and-Language-Navigation" class="headerlink" title="GridMM: Grid Memory Map for Vision-and-Language Navigation"></a>GridMM: Grid Memory Map for Vision-and-Language Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12907">http://arxiv.org/abs/2307.12907</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mrzihan/gridmm">https://github.com/mrzihan/gridmm</a></li>
<li>paper_authors: Zihan Wang, Xiangyang Li, Jiahao Yang, Yeqi Liu, Shuqiang Jiang</li>
<li>for: 本研究旨在提出一种新的视觉语言导航（VLN）方法，以便在3D环境中根据自然语言指令进行导航。</li>
<li>methods: 我们提出了一种名为Grid Memory Map（GridMM）的新方法，它使用了顺序状态、 topological maps 或 top-down semantic maps来表示已经游览过的环境。我们还提出了一种 instruction relevance aggregation 方法，用于在每个格子区域中捕捉细腻的视觉提示。</li>
<li>results: 我们在REVERIE、R2R、SOON数据集上进行了广泛的实验，并在R2R-CE数据集上进行了连续环境的实验，结果显示了我们的提posed方法的优越性。<details>
<summary>Abstract</summary>
Vision-and-language navigation (VLN) enables the agent to navigate to a remote location following the natural language instruction in 3D environments. To represent the previously visited environment, most approaches for VLN implement memory using recurrent states, topological maps, or top-down semantic maps. In contrast to these approaches, we build the top-down egocentric and dynamically growing Grid Memory Map (i.e., GridMM) to structure the visited environment. From a global perspective, historical observations are projected into a unified grid map in a top-down view, which can better represent the spatial relations of the environment. From a local perspective, we further propose an instruction relevance aggregation method to capture fine-grained visual clues in each grid region. Extensive experiments are conducted on both the REVERIE, R2R, SOON datasets in the discrete environments, and the R2R-CE dataset in the continuous environments, showing the superiority of our proposed method.
</details>
<details>
<summary>摘要</summary>
视觉语言导航（VLN）允许代理人在三维环境中根据自然语言指令进行导航。以前的环境表示方法中，大多数方法使用循环状态、 topological map 或 top-down semantic map 来实现记忆。在这些方法中，我们构建了从上而下的 egocentric 和动态增长的 Grid Memory Map（i.e., GridMM），以 структуриze 已经探索的环境。从全球视角来看，历史观察被投影到一个统一的格子地图上，可以更好地表示环境的空间关系。从本地视角来看，我们还提出了一种指令相关积累方法，以捕捉每个格子区域中的细腻视觉准确。我们在 discrete 环境中的 REVERIE、R2R 和 SOON 数据集上，以及 continuous 环境中的 R2R-CE 数据集上进行了广泛的实验，显示了我们提出的方法的优越性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/25/cs.AI_2023_07_25/" data-id="clpxp03ts001cfm886nzcfa7k" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_07_25" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/25/cs.CL_2023_07_25/" class="article-date">
  <time datetime="2023-07-25T11:00:00.000Z" itemprop="datePublished">2023-07-25</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/25/cs.CL_2023_07_25/">cs.CL - 2023-07-25</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="XDLM-Cross-lingual-Diffusion-Language-Model-for-Machine-Translation"><a href="#XDLM-Cross-lingual-Diffusion-Language-Model-for-Machine-Translation" class="headerlink" title="XDLM: Cross-lingual Diffusion Language Model for Machine Translation"></a>XDLM: Cross-lingual Diffusion Language Model for Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13560">http://arxiv.org/abs/2307.13560</a></li>
<li>repo_url: None</li>
<li>paper_authors: Linyao Chen, Aosong Feng, Boming Yang, Zihui Li</li>
<li>for: 这个研究是为了探讨 cross-lingual 的 diffusion model，以提高机器翻译的效果。</li>
<li>methods: 本研究使用了一种新的训练目标—TLDM，并在 fine-tuning 阶段使用了一个基于这个模型的翻译系统。</li>
<li>results: 研究发现，使用 XDLM 可以在机器翻译 benchmark 上超越 diffusion 和 Transformer 基于模型的基eline。<details>
<summary>Abstract</summary>
Recently, diffusion models have excelled in image generation tasks and have also been applied to neural language processing (NLP) for controllable text generation. However, the application of diffusion models in a cross-lingual setting is less unexplored. Additionally, while pretraining with diffusion models has been studied within a single language, the potential of cross-lingual pretraining remains understudied. To address these gaps, we propose XDLM, a novel Cross-lingual diffusion model for machine translation, consisting of pretraining and fine-tuning stages. In the pretraining stage, we propose TLDM, a new training objective for mastering the mapping between different languages; in the fine-tuning stage, we build up the translation system based on the pretrained model. We evaluate the result on several machine translation benchmarks and outperformed both diffusion and Transformer baselines.
</details>
<details>
<summary>摘要</summary>
近些时间，扩散模型在图像生成任务中表现出色，同时也应用于神经语言处理（NLP）中控制文本生成。然而，扩散模型在跨语言设置下的应用仍然未得到充分研究。此外，在单一语言预训练下的扩散模型预训练还未得到充分研究。为了解决这些漏洞，我们提出了 XDLM，一种新的跨语言扩散模型 для机器翻译，包括预训练和精度调整两个阶段。在预训练阶段，我们提出了 TLDM，一个新的训练目标，用于掌握不同语言之间的映射关系；在精度调整阶段，我们建立了基于预训练模型的翻译系统。我们对多个机器翻译标准 benchmark 进行评估，并在 diffusion 和 Transformer 基elines 上出perform。
</details></li>
</ul>
<hr>
<h2 id="Holistic-Exploration-on-Universal-Decompositional-Semantic-Parsing-Architecture-Data-Augmentation-and-LLM-Paradigm"><a href="#Holistic-Exploration-on-Universal-Decompositional-Semantic-Parsing-Architecture-Data-Augmentation-and-LLM-Paradigm" class="headerlink" title="Holistic Exploration on Universal Decompositional Semantic Parsing: Architecture, Data Augmentation, and LLM Paradigm"></a>Holistic Exploration on Universal Decompositional Semantic Parsing: Architecture, Data Augmentation, and LLM Paradigm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13424">http://arxiv.org/abs/2307.13424</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hexuandeng/hexp4uds">https://github.com/hexuandeng/hexp4uds</a></li>
<li>paper_authors: Hexuan Deng, Xin Zhang, Meishan Zhang, Xuebo Liu, Min Zhang</li>
<li>for: 这个论文主要是为了探讨Universal Decompositional Semantic（UDS）分析的全面性。</li>
<li>methods: 这个论文提出了一种卷积模型来实现UDS分析，将复杂的分析任务分解成semantically appropriate的子任务。此外，论文还 incorporates了 syntax information和进一步优化了architecture。</li>
<li>results: 论文的实验结果显示， compared to prior models, our approach significantly reduces inference time while maintaining performance. 在不同的数据增强方法下，我们还进行了实验调查，发现ChatGPT在Attribute parsing方面表现出色，但在Relation parsing方面表现不佳，而使用ChatGPT进行数据增强则得不到优秀的结果。<details>
<summary>Abstract</summary>
In this paper, we conduct a holistic exploration of the Universal Decompositional Semantic (UDS) Parsing. We first introduce a cascade model for UDS parsing that decomposes the complex parsing task into semantically appropriate subtasks. Our approach outperforms the prior models, while significantly reducing inference time. We also incorporate syntactic information and further optimized the architecture. Besides, different ways for data augmentation are explored, which further improve the UDS Parsing. Lastly, we conduct experiments to investigate the efficacy of ChatGPT in handling the UDS task, revealing that it excels in attribute parsing but struggles in relation parsing, and using ChatGPT for data augmentation yields suboptimal results. Our code is available at https://github.com/hexuandeng/HExp4UDS.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们进行了整体的 Universal Decompositional Semantic（UDS）解析探索。我们首先介绍了一种卷积模型为UDS解析任务进行分解，将复杂的解析任务分解成Semantically相应的子任务。我们的方法在优化后比之前的模型表现更优，同时减少了推理时间。我们还将 sintactic information  incorporated 到架构中，进一步优化了 architecture。此外，我们还 explore 了不同的数据增强方法，进一步提高了 UDS解析。最后，我们对 ChatGPT 在 UDS 任务中的处理进行了实验，发现它在 attribute 解析方面表现出色，而在 relation 解析方面却遇到了困难，并且使用 ChatGPT 进行数据增强后的结果不佳。我们的代码可以在 GitHub 上找到：https://github.com/hexuandeng/HExp4UDS。
</details></li>
</ul>
<hr>
<h2 id="Towards-Resolving-Word-Ambiguity-with-Word-Embeddings"><a href="#Towards-Resolving-Word-Ambiguity-with-Word-Embeddings" class="headerlink" title="Towards Resolving Word Ambiguity with Word Embeddings"></a>Towards Resolving Word Ambiguity with Word Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13417">http://arxiv.org/abs/2307.13417</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthias Thurnbauer, Johannes Reisinger, Christoph Goller, Andreas Fischer</li>
<li>for: This paper aims to address the problem of ambiguity in natural language processing, specifically in the context of word embeddings and information retrieval tasks.</li>
<li>methods: The authors propose using DBSCAN clustering to identify ambiguous words and evaluate their level of ambiguity in the latent space. They also propose an automatic parameter selection method for DBSCAN to ensure high-quality clusters.</li>
<li>results: The authors show that their approach can identify ambiguous words and evaluate their level of ambiguity, and that the resulting clusters are semantically coherent and correspond well to the perceived meanings of the words.<details>
<summary>Abstract</summary>
Ambiguity is ubiquitous in natural language. Resolving ambiguous meanings is especially important in information retrieval tasks. While word embeddings carry semantic information, they fail to handle ambiguity well. Transformer models have been shown to handle word ambiguity for complex queries, but they cannot be used to identify ambiguous words, e.g. for a 1-word query. Furthermore, training these models is costly in terms of time, hardware resources, and training data, prohibiting their use in specialized environments with sensitive data. Word embeddings can be trained using moderate hardware resources. This paper shows that applying DBSCAN clustering to the latent space can identify ambiguous words and evaluate their level of ambiguity. An automatic DBSCAN parameter selection leads to high-quality clusters, which are semantically coherent and correspond well to the perceived meanings of a given word.
</details>
<details>
<summary>摘要</summary>
<<SYS>>自然语言中的歧义是 ubique 存在的。在信息检索任务中，解决歧义的含义特别重要。虽然词嵌入带有含义信息，但它们不能好地处理歧义。 transformer 模型可以处理复杂的查询中的词歧义，但它们无法识别歧义的单个词，例如一个单词查询。此外，使用这些模型进行训练需要大量的时间、硬件资源和训练数据，这限制了它们在特殊环境中使用。 word embedding 可以通过中等级别的硬件资源进行训练。这篇论文显示，将 DBSCAN 归一化算法应用到封闭空间可以识别歧义的单个词，并评估它们的歧义水平。自动选择 DBSCAN 参数可以获得高质量的归一化结果，这些结果是semantically coherent 的，与给定词的感知含义相吻合。
</details></li>
</ul>
<hr>
<h2 id="Embedding-Models-for-Supervised-Automatic-Extraction-and-Classification-of-Named-Entities-in-Scientific-Acknowledgements"><a href="#Embedding-Models-for-Supervised-Automatic-Extraction-and-Classification-of-Named-Entities-in-Scientific-Acknowledgements" class="headerlink" title="Embedding Models for Supervised Automatic Extraction and Classification of Named Entities in Scientific Acknowledgements"></a>Embedding Models for Supervised Automatic Extraction and Classification of Named Entities in Scientific Acknowledgements</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13377">http://arxiv.org/abs/2307.13377</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kalawinka/season">https://github.com/kalawinka/season</a></li>
<li>paper_authors: Nina Smirnova, Philipp Mayr</li>
<li>for: 本研究旨在评估不同嵌入模型在科学论文感谢部分自动提取和分类承认实体的性能。</li>
<li>methods: 我们使用Flair NLP框架进行命名实体识别（NER）任务，训练 employed three default Flair NER模型，使用四个不同的训练集和不同版本的Flair NLP框架。</li>
<li>results: 我们发现，使用Flair Embeddings模型在中等训练集和最新版本Flair NLP框架下，性能最高，准确率为0.79。训练集的大小从非常小到中等大幅提高了所有训练算法的准确率，但是进一步扩大训练集不再提高性能。模型可以识别六种实体类型：资金机构、奖励编号、个人、大学、公司和其他。模型在一些实体类型上具有较高的F1分数，如个人和奖励编号，它们的F1分数都高于0.9。<details>
<summary>Abstract</summary>
Acknowledgments in scientific papers may give an insight into aspects of the scientific community, such as reward systems, collaboration patterns, and hidden research trends. The aim of the paper is to evaluate the performance of different embedding models for the task of automatic extraction and classification of acknowledged entities from the acknowledgment text in scientific papers. We trained and implemented a named entity recognition (NER) task using the Flair NLP framework. The training was conducted using three default Flair NER models with four differently-sized corpora and different versions of the Flair NLP framework. The Flair Embeddings model trained on the medium corpus with the latest FLAIR version showed the best accuracy of 0.79. Expanding the size of a training corpus from very small to medium size massively increased the accuracy of all training algorithms, but further expansion of the training corpus did not bring further improvement. Moreover, the performance of the model slightly deteriorated. Our model is able to recognize six entity types: funding agency, grant number, individuals, university, corporation, and miscellaneous. The model works more precisely for some entity types than for others; thus, individuals and grant numbers showed a very good F1-Score over 0.9. Most of the previous works on acknowledgment analysis were limited by the manual evaluation of data and therefore by the amount of processed data. This model can be applied for the comprehensive analysis of acknowledgment texts and may potentially make a great contribution to the field of automated acknowledgment analysis.
</details>
<details>
<summary>摘要</summary>
科学论文的感谢部分可以提供科学社区的一些方面的信息，如奖励系统、合作模式和隐藏的研究趋势。本文的目标是评估不同的嵌入模型在自动抽取和分类感谢 Entity 的任务中的表现。我们使用 Flair NLP 框架进行命名实体识别（NER）任务，并对三个默认的 Flair NER 模型进行训练。训练使用了不同的四个 corpus 和不同的 Flair NLP 框架版本。Flair Embeddings 模型使用 medium corpus 和最新的 FLAIR 版本显示最好的准确率为 0.79。将训练 corpus 的大小从非常小到中型大小会大幅提高所有训练算法的准确率，但是进一步扩大训练 corpus 不会再得到更好的改善。此外，模型的性能略有下降。我们的模型能够识别六种实体类型：资金机构、奖学金号、个人、大学、公司和其他。模型在一些实体类型上更加精准，例如个人和奖学金号的 F1 分数都高于 0.9。大多数前一些 acknowledgment 分析的研究都是通过手动评估数据来限制的，因此只能处理有限量的数据。这种模型可以应用于全面的 acknowledgment 文本分析，并可能对自动 acknowledgment 分析领域产生很大的贡献。
</details></li>
</ul>
<hr>
<h2 id="Prot2Text-Multimodal-Protein’s-Function-Generation-with-GNNs-and-Transformers"><a href="#Prot2Text-Multimodal-Protein’s-Function-Generation-with-GNNs-and-Transformers" class="headerlink" title="Prot2Text: Multimodal Protein’s Function Generation with GNNs and Transformers"></a>Prot2Text: Multimodal Protein’s Function Generation with GNNs and Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.14367">http://arxiv.org/abs/2307.14367</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hadi Abdine, Michail Chatzianastasis, Costas Bouyioukos, Michalis Vazirgiannis</li>
<li>for: 这 paper 的目的是提出一种新的蛋白质功能预测方法，即 Prot2Text，可以在文本化的方式下预测蛋白质的功能。</li>
<li>methods: 这 paper 使用了 Graph Neural Networks(GNNs) 和 Large Language Models(LLMs) 组合在一起，在encoder-decoder框架下实现蛋白质功能的文本化预测。</li>
<li>results: 该 paper 的实验结果表明，Prot2Text 可以准确地预测蛋白质的功能，并且可以生成详细的文本描述。这些结果表明了 multimodal 模型的转变性，特别是 GNNs 和 LLMs 的融合，为蛋白质功能预测提供了 poderful 工具。<details>
<summary>Abstract</summary>
The complex nature of big biological systems pushed some scientists to classify its understanding under the inconceivable missions. Different leveled challenges complicated this task, one of is the prediction of a protein's function. In recent years, significant progress has been made in this field through the development of various machine learning approaches. However, most existing methods formulate the task as a multi-classification problem, i.e assigning predefined labels to proteins. In this work, we propose a novel approach, \textbf{Prot2Text}, which predicts a protein function's in a free text style, moving beyond the conventional binary or categorical classifications. By combining Graph Neural Networks(GNNs) and Large Language Models(LLMs), in an encoder-decoder framework, our model effectively integrates diverse data types including proteins' sequences, structures, and textual annotations. This multimodal approach allows for a holistic representation of proteins' functions, enabling the generation of detailed and accurate descriptions. To evaluate our model, we extracted a multimodal protein dataset from SwissProt, and demonstrate empirically the effectiveness of Prot2Text. These results highlight the transformative impact of multimodal models, specifically the fusion of GNNs and LLMs, empowering researchers with powerful tools for more accurate prediction of proteins' functions. The code, the models and a demo will be publicly released.
</details>
<details>
<summary>摘要</summary>
大型生物系统的复杂性让一些科学家将其理解归类为不可思议任务。不同的层次挑战使得这项任务更加复杂，其中之一是蛋白质功能预测。在最近几年，通过开发不同的机器学习方法，有 significante进步在这一领域。然而，大多数现有方法将任务 формули化为多类别问题，即将蛋白质分配预定的标签。在这项工作中，我们提出了一种新的方法——Prot2Text，它预测蛋白质功能的方式与传统的多类别分类法不同，而是通过组合图 neural network和大型自然语言模型，在Encoder-Decoder框架中进行融合。这种多Modal的方法允许对蛋白质功能进行全面表示，从而生成详细和准确的描述。为评估我们的模型，我们从SwissProt中提取了一个多Modal蛋白质数据集，并通过实验证明了Prot2Text的效果。这些结果显示了多Modal模型的转变性，尤其是GNNs和LLMs的融合，为研究人员提供了更准确的蛋白质功能预测工具。代码、模型和 demo 将公开发布。
</details></li>
</ul>
<hr>
<h2 id="Improving-the-Generalization-Ability-in-Essay-Coherence-Evaluation-through-Monotonic-Constraints"><a href="#Improving-the-Generalization-Ability-in-Essay-Coherence-Evaluation-through-Monotonic-Constraints" class="headerlink" title="Improving the Generalization Ability in Essay Coherence Evaluation through Monotonic Constraints"></a>Improving the Generalization Ability in Essay Coherence Evaluation through Monotonic Constraints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02506">http://arxiv.org/abs/2308.02506</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Zheng, Huan Zhang, Yan Zhao, Yuxuan Lai</li>
<li>for: 评估文本可读性的一个重要方面是 coherence，可以通过两个主要因素评估一篇文章的 coherence：第一个因素是逻辑连接的正确使用，第二个因素是句子结构的适用性。</li>
<li>methods: 为了解决这些问题，我们提出了一种 coherence 评估模型，包括一个回归模型和两个特征提取器：地方逻辑连接推论模型和句子结构修正模型。我们使用Gradient Boosting 回归树作为回归模型，并对输入特征做出假设约束。</li>
<li>results: 我们的提出的模型能够更好地泛化未经见过的数据。模型在 NLPCC 2023 年度共同任务7的第三名上进行了比赛，并 briefly 介绍了我们的解决方案的剩下的 tracks，其中在第二名上进行了第二名，并在第三名和第四名上进行了第一名。<details>
<summary>Abstract</summary>
Coherence is a crucial aspect of evaluating text readability and can be assessed through two primary factors when evaluating an essay in a scoring scenario. The first factor is logical coherence, characterized by the appropriate use of discourse connectives and the establishment of logical relationships between sentences. The second factor is the appropriateness of punctuation, as inappropriate punctuation can lead to confused sentence structure. To address these concerns, we propose a coherence scoring model consisting of a regression model with two feature extractors: a local coherence discriminative model and a punctuation correction model. We employ gradient-boosting regression trees as the regression model and impose monotonicity constraints on the input features. The results show that our proposed model better generalizes unseen data. The model achieved third place in track 1 of NLPCC 2023 shared task 7. Additionally, we briefly introduce our solution for the remaining tracks, which achieves second place for track 2 and first place for both track 3 and track 4.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Coherence is a crucial aspect of evaluating text readability and can be assessed through two primary factors when evaluating an essay in a scoring scenario. The first factor is logical coherence, characterized by the appropriate use of discourse connectives and the establishment of logical relationships between sentences. The second factor is the appropriateness of punctuation, as inappropriate punctuation can lead to confused sentence structure. To address these concerns, we propose a coherence scoring model consisting of a regression model with two feature extractors: a local coherence discriminative model and a punctuation correction model. We employ gradient-boosting regression trees as the regression model and impose monotonicity constraints on the input features. The results show that our proposed model better generalizes unseen data. The model achieved third place in track 1 of NLPCC 2023 shared task 7. Additionally, we briefly introduce our solution for the remaining tracks, which achieves second place for track 2 and first place for both track 3 and track 4." into Simplified Chinese. coherence 是文本可读性评估中的一个关键因素，可以通过两个主要因素进行评估：一是逻辑连贯性，即使用演示连接词和建立句子之间的逻辑关系；二是句子结构的括号正确性，因为不当的括号可能导致句子结构混乱。为解决这些问题，我们提出了一种减量模型，包括两个特征提取器：本地连贯性推论模型和括号修正模型。我们使用梯度提升回归树作为回归模型，并对输入特征受到约束。结果表明，我们的提出的模型在未seen数据上更好地泛化。这个模型在 NLPCC 2023 共享任务 7 的第三名。此外，我们简要介绍我们对其余轨迹的解决方案，其中在第二轨迹上获得第二名，并在第三轨迹和第四轨迹上均获得第一名。Note: "NLPCC" stands for "Natural Language Processing and Chinese Computing" conference.
</details></li>
</ul>
<hr>
<h2 id="QuIP-2-Bit-Quantization-of-Large-Language-Models-With-Guarantees"><a href="#QuIP-2-Bit-Quantization-of-Large-Language-Models-With-Guarantees" class="headerlink" title="QuIP: 2-Bit Quantization of Large Language Models With Guarantees"></a>QuIP: 2-Bit Quantization of Large Language Models With Guarantees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13304">http://arxiv.org/abs/2307.13304</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jerry-chee/quip">https://github.com/jerry-chee/quip</a></li>
<li>paper_authors: Jerry Chee, Yaohui Cai, Volodymyr Kuleshov, Christopher De Sa</li>
<li>for: 本文研究大语言模型（LLM）后期参数量化。</li>
<li>methods: 我们提出了一种基于 weights和Hessian矩阵偏移的新方法，称为量化偏移处理（QuIP）。QuIP包括两个步骤：（1）一种适应减法程序，使得量化后的模型仍然能够保持准确性；（2）高效的预处理和后处理，使得模型的权重和Hessian矩阵偏移。</li>
<li>results: 我们通过实验发现，我们的偏移预处理可以提高一些现有的量化算法，并且使用只有两个位数的量化方法实现了LLM模型的可行结果。我们的代码可以在<a target="_blank" rel="noopener" href="https://github.com/jerry-chee/QuIP%E4%B8%8A%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/jerry-chee/QuIP上找到。</a><details>
<summary>Abstract</summary>
This work studies post-training parameter quantization in large language models (LLMs). We introduce quantization with incoherence processing (QuIP), a new method based on the insight that quantization benefits from incoherent weight and Hessian matrices, i.e., from the weights and the directions in which it is important to round them accurately being unaligned with the coordinate axes. QuIP consists of two steps: (1) an adaptive rounding procedure minimizing a quadratic proxy objective; (2) efficient pre- and post-processing that ensures weight and Hessian incoherence via multiplication by random orthogonal matrices. We complement QuIP with the first theoretical analysis for an LLM-scale quantization algorithm, and show that our theory also applies to an existing method, OPTQ. Empirically, we find that our incoherence preprocessing improves several existing quantization algorithms and yields the first LLM quantization methods that produce viable results using only two bits per weight. Our code can be found at https://github.com/jerry-chee/QuIP .
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>An adaptive rounding procedure that minimizes a quadratic proxy objective.2. Efficient pre- and post-processing that ensures weight and Hessian incoherence through multiplication by random orthogonal matrices.We also provide the first theoretical analysis for an LLM-scale quantization algorithm and show that our theory applies to an existing method, OPTQ. Empirically, we find that our incoherence preprocessing improves several existing quantization algorithms and yields the first LLM quantization methods that produce viable results using only two bits per weight. Our code can be found at <a target="_blank" rel="noopener" href="https://github.com/jerry-chee/QuIP">https://github.com/jerry-chee/QuIP</a>.</details></li>
</ol>
<hr>
<h2 id="An-Intent-Taxonomy-of-Legal-Case-Retrieval"><a href="#An-Intent-Taxonomy-of-Legal-Case-Retrieval" class="headerlink" title="An Intent Taxonomy of Legal Case Retrieval"></a>An Intent Taxonomy of Legal Case Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13298">http://arxiv.org/abs/2307.13298</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunqiu Shao, Haitao Li, Yueyue Wu, Yiqun Liu, Qingyao Ai, Jiaxin Mao, Yixiao Ma, Shaoping Ma</li>
<li>for: 本研究旨在理解法律案例检索用户的搜寻意图，并开发一个新的法律案例检索Intent taxonomy。</li>
<li>methods: 本研究使用了面试、编辑用户研究和查询日志分析等方法构建了一个法律案例检索Intent taxonomy。</li>
<li>results: 研究发现在不同的搜寻意图下，用户的搜寻行为和满意度有显著差异。此外，该taxonomy可以应用于多个下游法律检索任务，如结果排名和满意度预测。<details>
<summary>Abstract</summary>
Legal case retrieval is a special Information Retrieval~(IR) task focusing on legal case documents. Depending on the downstream tasks of the retrieved case documents, users' information needs in legal case retrieval could be significantly different from those in Web search and traditional ad-hoc retrieval tasks. While there are several studies that retrieve legal cases based on text similarity, the underlying search intents of legal retrieval users, as shown in this paper, are more complicated than that yet mostly unexplored. To this end, we present a novel hierarchical intent taxonomy of legal case retrieval. It consists of five intent types categorized by three criteria, i.e., search for Particular Case(s), Characterization, Penalty, Procedure, and Interest. The taxonomy was constructed transparently and evaluated extensively through interviews, editorial user studies, and query log analysis. Through a laboratory user study, we reveal significant differences in user behavior and satisfaction under different search intents in legal case retrieval. Furthermore, we apply the proposed taxonomy to various downstream legal retrieval tasks, e.g., result ranking and satisfaction prediction, and demonstrate its effectiveness. Our work provides important insights into the understanding of user intents in legal case retrieval and potentially leads to better retrieval techniques in the legal domain, such as intent-aware ranking strategies and evaluation methodologies.
</details>
<details>
<summary>摘要</summary>
法律案例检索是一种特殊的信息检索任务，专注于法律案例文档。根据下游任务中返回的案例文档的用户信息需求，用户在法律检索任务中的搜索意图可能与传统的Web搜索和特殊检索任务存在很大差异。虽然有几篇研究文章通过文本相似性来检索法律案例，但用户在法律检索中的搜索意图还未得到了充分的研究。为此，我们提出了一个新的层次意图分类法，它包括五种意图类别，分为三个标准：寻找特定案例（Search for Particular Case）、特征化（Characterization）、裁罚（Penalty）、程序（Procedure）和利益（Interest）。这个分类体系由 transparent construction 和广泛的用户研究进行验证，并通过实验研究表明了用户在不同搜索意图下的行为和满意度之间存在显著差异。此外，我们还应用该分类法到不同的下游法律检索任务中，如结果排名和满意度预测，并证明其效果。我们的工作为法律检索领域的理解用户意图提供了重要的洞察，并可能导致更好的检索技术的发展，如意向检索策略和评价方法。
</details></li>
</ul>
<hr>
<h2 id="Schema-Driven-Actionable-Insight-Generation-and-Smart-Recommendation"><a href="#Schema-Driven-Actionable-Insight-Generation-and-Smart-Recommendation" class="headerlink" title="Schema-Driven Actionable Insight Generation and Smart Recommendation"></a>Schema-Driven Actionable Insight Generation and Smart Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13176">http://arxiv.org/abs/2307.13176</a></li>
<li>repo_url: None</li>
<li>paper_authors: Allmin Susaiyah, Aki Härmä, Milan Petković</li>
<li>for: 这篇论文是用于生成可行的洞察结论，以促进增长和变革。</li>
<li>methods: 该方法使用了Schema-driven的方法，通过挖掘数据中有趣的模式，生成可读的洞察结论。</li>
<li>results: 该方法可以根据用户反馈进行排序，以适应用户的兴趣。我们已经展示了这种方法可以生成的先验结果。<details>
<summary>Abstract</summary>
In natural language generation (NLG), insight mining is seen as a data-to-text task, where data is mined for interesting patterns and verbalised into 'insight' statements. An 'over-generate and rank' paradigm is intuitively used to generate such insights. The multidimensionality and subjectivity of this process make it challenging. This paper introduces a schema-driven method to generate actionable insights from data to drive growth and change. It also introduces a technique to rank the insights to align with user interests based on their feedback. We show preliminary qualitative results of the insights generated using our technique and demonstrate its ability to adapt to feedback.
</details>
<details>
<summary>摘要</summary>
natural language generation (NLG) 中，启示挖掘被看作是一个数据到文本任务，通过挖掘数据中有趣的模式，并将其转化为“启示”声明。一种“过度生成并排序”的思路是INTUITIVELY用于生成这些启示。由于这个过程的多维度和主观性，使其具有挑战性。这篇论文介绍了一种基于Schema驱动的方法，用于从数据中生成可行的启示，以驱动增长和变革。它还介绍了一种基于用户反馈的技术，用于对启示进行排序，以符合用户的兴趣。我们展示了先期的Qualitative结果，证明了我们的方法能够适应反馈。
</details></li>
</ul>
<hr>
<h2 id="Explaining-Math-Word-Problem-Solvers"><a href="#Explaining-Math-Word-Problem-Solvers" class="headerlink" title="Explaining Math Word Problem Solvers"></a>Explaining Math Word Problem Solvers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13128">http://arxiv.org/abs/2307.13128</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abby Newcomb, Jugal Kalita</li>
<li>for: 本研究旨在探讨自动解 math word problem 的方法是否遵循语言表达的 semantic logic。</li>
<li>methods: 本研究使用了 removing parts of the input 来测试模型的性能，以确定模型是否仅仅匹配语言表达的特征。</li>
<li>results: 结果表明，模型对输入中的多个字词的删除不会影响其解题能力，而且可以从 nonsense 问题中提取正确的解答。这表明自动解 math word problem 的模型可能会匹配语言表达的表现，而不是遵循语言表达的 semantic logic。<details>
<summary>Abstract</summary>
Automated math word problem solvers based on neural networks have successfully managed to obtain 70-80\% accuracy in solving arithmetic word problems. However, it has been shown that these solvers may rely on superficial patterns to obtain their equations. In order to determine what information math word problem solvers use to generate solutions, we remove parts of the input and measure the model's performance on the perturbed dataset. Our results show that the model is not sensitive to the removal of many words from the input and can still manage to find a correct answer when given a nonsense question. This indicates that automatic solvers do not follow the semantic logic of math word problems, and may be overfitting to the presence of specific words.
</details>
<details>
<summary>摘要</summary>
自动化的数学问题解决程式基于神经网络已经成功地在解决算数问题上获得70-80%的准确率。然而，研究人员发现这些解决方案可能会从 superficier 的特征中获得其方程。为了决定这些解决方案所使用的信息，我们将输入中的部分 removed 并评估模型在这些干扰dataset上的性能。我们的结果显示，模型对输入中的许多字都不敏感，仍然可以从非现实问题中获得正确的解答。这表明自动解决方案不会跟着数学问题的semantic逻辑，可能是过拟合特定的字汇。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-the-Ripple-Effects-of-Knowledge-Editing-in-Language-Models"><a href="#Evaluating-the-Ripple-Effects-of-Knowledge-Editing-in-Language-Models" class="headerlink" title="Evaluating the Ripple Effects of Knowledge Editing in Language Models"></a>Evaluating the Ripple Effects of Knowledge Editing in Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12976">http://arxiv.org/abs/2307.12976</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/edenbiran/rippleedits">https://github.com/edenbiran/rippleedits</a></li>
<li>paper_authors: Roi Cohen, Eden Biran, Ori Yoran, Amir Globerson, Mor Geva</li>
<li>for: 这篇论文主要针对现代语言模型中的知识更新问题。</li>
<li>methods: 论文提出了一种新的评估标准，用于评估编辑方法对模型知识的影响。</li>
<li>results: 研究发现，目前的编辑方法通常无法在模型知识中引入一致的变化，而一种简单的上下文编辑基线得到了最佳成绩。<details>
<summary>Abstract</summary>
Modern language models capture a large body of factual knowledge. However, some facts can be incorrectly induced or become obsolete over time, resulting in factually incorrect generations. This has led to the development of various editing methods that allow updating facts encoded by the model. Evaluation of these methods has primarily focused on testing whether an individual fact has been successfully injected, and if similar predictions for other subjects have not changed. Here we argue that such evaluation is limited, since injecting one fact (e.g. ``Jack Depp is the son of Johnny Depp'') introduces a ``ripple effect'' in the form of additional facts that the model needs to update (e.g.``Jack Depp is the sibling of Lily-Rose Depp''). To address this issue, we propose a novel set of evaluation criteria that consider the implications of an edit on related facts. Using these criteria, we then construct \ripple{}, a diagnostic benchmark of 5K factual edits, capturing a variety of types of ripple effects. We evaluate prominent editing methods on \ripple{}, showing that current methods fail to introduce consistent changes in the model's knowledge. In addition, we find that a simple in-context editing baseline obtains the best scores on our benchmark, suggesting a promising research direction for model editing.
</details>
<details>
<summary>摘要</summary>
现代语言模型可以捕捉大量的事实知识。然而，一些事实可能会在时间的推移中变得过时或者错误地被推导出来，导致模型生成的结果不准确。为了解决这个问题，人们开发了多种修改方法，以更新模型中的事实。然而，评估这些方法的主要方法是测试模型中的一个特定事实是否已经成功地更新，并且其他主题的预测没有变化。在这篇文章中，我们 argue这种评估方法是有限的，因为更新一个事实（例如，“杰克·德普是Johnny Depp的儿子”）会导致模型需要更新其他相关的事实（例如，“杰克·德普是LILY-ROSE DEPP的姐妹”）。为解决这个问题，我们提出了一组新的评估标准，考虑修改的影响于相关的事实。使用这些标准，我们然后构建了一个名为\ripple{}的诊断 benchmark，包含5000个事实修改。我们对这些修改进行评估，发现当前的修改方法无法在模型中引入一致的改变。此外，我们发现一个简单的 Context-sensitive editing baseline 在我们的benchmark上获得了最好的分数， suggesting a promising research direction for model editing。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Label-Variation-in-Large-Language-Models-for-Zero-Shot-Text-Classification"><a href="#Leveraging-Label-Variation-in-Large-Language-Models-for-Zero-Shot-Text-Classification" class="headerlink" title="Leveraging Label Variation in Large Language Models for Zero-Shot Text Classification"></a>Leveraging Label Variation in Large Language Models for Zero-Shot Text Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12973">http://arxiv.org/abs/2307.12973</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zeniSoida/pl1">https://github.com/zeniSoida/pl1</a></li>
<li>paper_authors: Flor Miriam Plaza-del-Arco, Debora Nozza, Dirk Hovy</li>
<li>for: 这个论文旨在探讨大语言模型（LLM）在无监督学习下的文本分类能力，以及这些模型在不同任务、数据和语言下的表现。</li>
<li>methods: 这个论文使用了5种当今最佳的LLM作为”注解器”，在5个不同的任务（年龄、性别、主题、情感预测和仇恨言语检测）中进行了4种不同的语言（英语、法语、德语和西班牙语）的测试。</li>
<li>results: 论文发现，虽然不同的任务、数据和语言下的模型表现不同，但使用人工注解者的汇集技术可以substantially better than任何一个个体模型。然而，LLMs仍然不能与人工注解者相比，因此它们并不可以完全取代人工注解。<details>
<summary>Abstract</summary>
The zero-shot learning capabilities of large language models (LLMs) make them ideal for text classification without annotation or supervised training. Many studies have shown impressive results across multiple tasks. While tasks, data, and results differ widely, their similarities to human annotation can aid us in tackling new tasks with minimal expenses. We evaluate using 5 state-of-the-art LLMs as "annotators" on 5 different tasks (age, gender, topic, sentiment prediction, and hate speech detection), across 4 languages: English, French, German, and Spanish. No single model excels at all tasks, across languages, or across all labels within a task. However, aggregation techniques designed for human annotators perform substantially better than any one individual model. Overall, though, LLMs do not rival even simple supervised models, so they do not (yet) replace the need for human annotation. We also discuss the tradeoffs between speed, accuracy, cost, and bias when it comes to aggregated model labeling versus human annotation.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）的零shot学习能力使其成为文本分类无需注释或指导式训练的理想选择。许多研究表明在多个任务上获得了吸引人的结果。虽然任务、数据和结果之间存在差异，但它们在人类注释上的相似性可以帮助我们解决新的任务，降低成本。我们使用5种 state-of-the-art LLM作为“注释员”进行5个任务（年龄、性别、主题、情感预测和词语攻击检测），在英语、法语、德语和西班牙语四种语言上进行评估。没有任何模型在所有任务和语言上表现出色，但是为human annotator的汇集技术表现出了明显的改善。总的来说，LLMs现在没有超过简单的指导式模型，因此它们还没有取代人类注释。我们还讨论了在汇集模型标签与人类注释之间的速度、准确率、成本和偏见的贸易。
</details></li>
</ul>
<hr>
<h2 id="Aligning-Large-Language-Models-with-Human-A-Survey"><a href="#Aligning-Large-Language-Models-with-Human-A-Survey" class="headerlink" title="Aligning Large Language Models with Human: A Survey"></a>Aligning Large Language Models with Human: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12966">http://arxiv.org/abs/2307.12966</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/garyyufei/alignllmhumansurvey">https://github.com/garyyufei/alignllmhumansurvey</a></li>
<li>paper_authors: Yufei Wang, Wanjun Zhong, Liangyou Li, Fei Mi, Xingshan Zeng, Wenyong Huang, Lifeng Shang, Xin Jiang, Qun Liu</li>
<li>For: This paper provides a comprehensive overview of alignment technologies for large language models (LLMs) to better suit human-oriented tasks and expectations.* Methods: The paper reviews various training methodologies for LLM alignment, including supervised fine-tuning, online and offline human preference training, and parameter-efficient training mechanisms.* Results: The paper evaluates the effectiveness of human-aligned LLMs using a multifaceted approach and highlights several promising future research avenues in the field.Here is the same information in Simplified Chinese text:* For: 这篇论文提供了大语言模型（LLM）的启用技术的全面回顾，以便更好地适应人类需求。* Methods: 论文回顾了各种用于LLM启用的训练方法，包括监督精度调整、在线和离线人类偏好训练以及参数高效训练机制。* Results: 论文使用多方面的评估方法评估了人类启用LLM的效果，并提出了许多可能的未来研究方向。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) trained on extensive textual corpora have emerged as leading solutions for a broad array of Natural Language Processing (NLP) tasks. Despite their notable performance, these models are prone to certain limitations such as misunderstanding human instructions, generating potentially biased content, or factually incorrect (hallucinated) information. Hence, aligning LLMs with human expectations has become an active area of interest within the research community. This survey presents a comprehensive overview of these alignment technologies, including the following aspects. (1) Data collection: the methods for effectively collecting high-quality instructions for LLM alignment, including the use of NLP benchmarks, human annotations, and leveraging strong LLMs. (2) Training methodologies: a detailed review of the prevailing training methods employed for LLM alignment. Our exploration encompasses Supervised Fine-tuning, both Online and Offline human preference training, along with parameter-efficient training mechanisms. (3) Model Evaluation: the methods for evaluating the effectiveness of these human-aligned LLMs, presenting a multifaceted approach towards their assessment. In conclusion, we collate and distill our findings, shedding light on several promising future research avenues in the field. This survey, therefore, serves as a valuable resource for anyone invested in understanding and advancing the alignment of LLMs to better suit human-oriented tasks and expectations. An associated GitHub link collecting the latest papers is available at https://github.com/GaryYufei/AlignLLMHumanSurvey.
</details>
<details>
<summary>摘要</summary>
庞大语言模型（LLM）在各种自然语言处理（NLP）任务中表现出色，但它们也存在一些局限性，如不理解人类指令、生成可能偏见的内容或者 factually incorrect（hallucinated）信息。因此，与人类期望的 aligning LLM 已成为研究领域的热点。这篇评论文章提供了一个全面的对这些对齐技术的评论，包括以下方面：1. 数据采集：如何有效地采集高质量的人类指令，包括使用 NLP 标准准则、人工标注和利用强大的 LLM。2. 训练方法：详细介绍了在 LLM 对齐中广泛使用的训练方法，包括监督精细调整、在线人类喜好训练和效率的参数训练机制。3. 模型评价：如何评价这些人类对齐的 LLM，提出了多方面的评价方法，以提供全面的评价方式。总之，这篇评论文章为各种投入 NLP 领域的人提供了一个有价值的资源，帮助他们更好地理解和提高 LLM 的对齐性，以更好地适应人类中心的任务和期望。关于这些研究的最新论文，可以通过以下 GitHub 链接获取：https://github.com/GaryYufei/AlignLLMHumanSurvey.
</details></li>
</ul>
<hr>
<h2 id="Boosting-Punctuation-Restoration-with-Data-Generation-and-Reinforcement-Learning"><a href="#Boosting-Punctuation-Restoration-with-Data-Generation-and-Reinforcement-Learning" class="headerlink" title="Boosting Punctuation Restoration with Data Generation and Reinforcement Learning"></a>Boosting Punctuation Restoration with Data Generation and Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.12949">http://arxiv.org/abs/2307.12949</a></li>
<li>repo_url: None</li>
<li>paper_authors: Viet Dac Lai, Abel Salinas, Hao Tan, Trung Bui, Quan Tran, Seunghyun Yoon, Hanieh Deilamsalehy, Franck Dernoncourt, Thien Huu Nguyen</li>
<li>for: 提高自动语音识别（ASR）系统的可读性，通过使用生成语言模型和强化学习来修复ASR文本中的 sintactic structure。</li>
<li>methods: 使用强化学习方法，利用topic中的文本和大型预训练的生成语言模型，将written文本和ASR文本之间的差异 bridge。</li>
<li>results: 实验表明，我们的方法在ASR测试集上的两个标准 datasets上达到了状态的最佳性能。<details>
<summary>Abstract</summary>
Punctuation restoration is an important task in automatic speech recognition (ASR) which aim to restore the syntactic structure of generated ASR texts to improve readability. While punctuated texts are abundant from written documents, the discrepancy between written punctuated texts and ASR texts limits the usability of written texts in training punctuation restoration systems for ASR texts. This paper proposes a reinforcement learning method to exploit in-topic written texts and recent advances in large pre-trained generative language models to bridge this gap. The experiments show that our method achieves state-of-the-art performance on the ASR test set on two benchmark datasets for punctuation restoration.
</details>
<details>
<summary>摘要</summary>
“短语结构修复是自动语音识别（ASR）中的一项重要任务，旨在提高ASR文本的可读性。written文本充沛，但是ASR文本与written文本之间存在差异，这限制了使用written文本来训练ASR文本的短语结构修复系统。本文提出了一种利用topic内文本和大型预训练生成语言模型的强化学习方法，bridge这个差异。实验结果显示，我们的方法在ASR测试集上两个benchmark dataset上达到了状态对抗性的性能。”Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know and I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="The-potential-of-LLMs-for-coding-with-low-resource-and-domain-specific-programming-languages"><a href="#The-potential-of-LLMs-for-coding-with-low-resource-and-domain-specific-programming-languages" class="headerlink" title="The potential of LLMs for coding with low-resource and domain-specific programming languages"></a>The potential of LLMs for coding with low-resource and domain-specific programming languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13018">http://arxiv.org/abs/2307.13018</a></li>
<li>repo_url: None</li>
<li>paper_authors: Artur Tarassow</li>
<li>for: 这项研究旨在探讨使用大语言模型（LLM）进行低资源和域语言编程语言的编程，以便更好地利用LLM处理技术。</li>
<li>methods: 本研究使用了一种基于GPT-3.5的专有LLM，并采用了经济cripting语言名为hansl的开源软件gretl进行实践。</li>
<li>results: 研究发现，LLM可以用于写作、理解、改进和文档gretl代码，包括生成函数的描述文档和提供 econometric代码的准确解释。但是，LLM还有一些局限性，如无法改进某些代码部分和写入正确的单元测试代码。<details>
<summary>Abstract</summary>
This paper presents a study on the feasibility of using large language models (LLM) for coding with low-resource and domain-specific programming languages that typically lack the amount of data required for effective LLM processing techniques. This study focuses on the econometric scripting language named hansl of the open-source software gretl and employs a proprietary LLM based on GPT-3.5. Our findings suggest that LLMs can be a useful tool for writing, understanding, improving, and documenting gretl code, which includes generating descriptive docstrings for functions and providing precise explanations for abstract and poorly documented econometric code. While the LLM showcased promoting docstring-to-code translation capability, we also identify some limitations, such as its inability to improve certain sections of code and to write accurate unit tests. This study is a step towards leveraging the power of LLMs to facilitate software development in low-resource programming languages and ultimately to lower barriers to entry for their adoption.
</details>
<details>
<summary>摘要</summary>
Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and widely used in other countries as well.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/25/cs.CL_2023_07_25/" data-id="clpxp03w20096fm8833404hn2" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/80/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/79/">79</a><a class="page-number" href="/page/80/">80</a><span class="page-number current">81</span><a class="page-number" href="/page/82/">82</a><a class="page-number" href="/page/83/">83</a><span class="space">&hellip;</span><a class="page-number" href="/page/98/">98</a><a class="extend next" rel="next" href="/page/82/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">142</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">67</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">82</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">147</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
