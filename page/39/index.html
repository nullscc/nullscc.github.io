
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/39/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.SD_2023_09_10" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/10/cs.SD_2023_09_10/" class="article-date">
  <time datetime="2023-09-10T15:00:00.000Z" itemprop="datePublished">2023-09-10</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/10/cs.SD_2023_09_10/">cs.SD - 2023-09-10</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Multimodal-Fish-Feeding-Intensity-Assessment-in-Aquaculture"><a href="#Multimodal-Fish-Feeding-Intensity-Assessment-in-Aquaculture" class="headerlink" title="Multimodal Fish Feeding Intensity Assessment in Aquaculture"></a>Multimodal Fish Feeding Intensity Assessment in Aquaculture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05058">http://arxiv.org/abs/2309.05058</a></li>
<li>repo_url: None</li>
<li>paper_authors: Meng Cui, Xubo Liu, Haohe Liu, Zhuangzhuang Du, Tao Chen, Guoping Lian, Daoliang Li, Wenwu Wang</li>
<li>for: 这项研究的目的是评估鱼类食欲强度变化的评估方法，具体来说是用于工业鱼类养殖应用。</li>
<li>methods: 这项研究使用了多modal方法，包括单模态预训练模型和模式融合方法，并在大规模的 audio-visual数据集 AV-FFIA 上进行了比较研究。</li>
<li>results: 研究结果表明，多模态方法在噪音环境中表现明显更好，而单模态方法在静音环境中表现更好。此外，提出了一种单一模型 U-FFIA，可以处理不同的感知模式，并且可以在较低的计算成本下实现更高的性能。<details>
<summary>Abstract</summary>
Fish feeding intensity assessment (FFIA) aims to evaluate the intensity change of fish appetite during the feeding process, which is vital in industrial aquaculture applications. The main challenges surrounding FFIA are two-fold. 1) robustness: existing work has mainly leveraged single-modality (e.g., vision, audio) methods, which have a high sensitivity to input noise. 2) efficiency: FFIA models are generally expected to be employed on devices. This presents a challenge in terms of computational efficiency. In this work, we first introduce an audio-visual dataset, called AV-FFIA. AV-FFIA consists of 27,000 labeled audio and video clips that capture different levels of fish feeding intensity. To our knowledge, AV-FFIA is the first large-scale multimodal dataset for FFIA research. Then, we introduce a multi-modal approach for FFIA by leveraging single-modality pre-trained models and modality-fusion methods, with benchmark studies on AV-FFIA. Our experimental results indicate that the multi-modal approach substantially outperforms the single-modality based approach, especially in noisy environments. While multimodal approaches provide a performance gain for FFIA, it inherently increase the computational cost. To overcome this issue, we further present a novel unified model, termed as U-FFIA. U-FFIA is a single model capable of processing audio, visual, or audio-visual modalities, by leveraging modality dropout during training and knowledge distillation from single-modality pre-trained models. We demonstrate that U-FFIA can achieve performance better than or on par with the state-of-the-art modality-specific FFIA models, with significantly lower computational overhead. Our proposed U-FFIA approach enables a more robust and efficient method for FFIA, with the potential to contribute to improved management practices and sustainability in aquaculture.
</details>
<details>
<summary>摘要</summary>
鱼食吞吐评估（FFIA）目的是评估鱼的吞吐程度在食物过程中的变化，这对于工业鱼养殖非常重要。主要挑战包括：1）稳定性：现有工作主要基于单模态（如视觉、音频）方法，具有高敏感度输入噪声。2）效率：FFIA模型通常预期在设备上使用，这将带来计算效率的挑战。在这种情况下，我们首先介绍了一个音频视频数据集（AV-FFIA），AV-FFIA包括27,000个标注音频和视频剪辑，各个剪辑捕捉不同水平的鱼食吞吐程度。我们知道，AV-FFIA是首个大规模的多模态FFIA数据集。然后，我们介绍了一种多模态方法，通过单模态预训练模型和多模态融合方法，对AV-FFIA进行了 benchmark研究。我们的实验结果表明，多模态方法在噪声环境中substantially outperforms单模态基于方法，特别是在噪声环境下。虽然多模态方法提供了FFIA中性能提升，但它会自然增加计算成本。为了解决这个问题，我们进一步发表了一种单一模型，称为U-FFIA。U-FFIA是一个能够处理音频、视觉或音频视频模式的单一模型，通过训练时模式排除和知识储存单模态预训练模型来实现。我们示示了U-FFIA可以达到与状态空间的性能，同时具有明显更低的计算开销。我们的提出的U-FFIA方法可以提供更加稳定和高效的FFIA方法，具有改善鱼养殖管理实践和可持续发展的潜在潜力。
</details></li>
</ul>
<hr>
<h2 id="Gray-Jedi-MVDR-Post-filtering"><a href="#Gray-Jedi-MVDR-Post-filtering" class="headerlink" title="Gray Jedi MVDR Post-filtering"></a>Gray Jedi MVDR Post-filtering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05057">http://arxiv.org/abs/2309.05057</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/FrancoisGrondin/mvdrpf">https://github.com/FrancoisGrondin/mvdrpf</a></li>
<li>paper_authors: François Grondin, Caleb Rascón</li>
<li>for: 提高多个语音源场景中的语音质量</li>
<li>methods: 使用深度学习基于的语音提高模型，并使用最小差分误差Response（MVDR）进行干扰估计</li>
<li>results: 比单输入基线具有更高的提升性能，并且需要更少的计算资源进行后处理<details>
<summary>Abstract</summary>
Spatial filters can exploit deep-learning-based speech enhancement models to increase their reliability in scenarios with multiple speech sources scenarios. To further improve speech quality, it is common to perform postfiltering on the estimated target speech obtained with spatial filtering. In this work, Minimum Variance Distortionless Response (MVDR) is employed to provide the interference estimation, along with the estimation of the target speech, to be later used for postfiltering. This improves the enhancement performance over a single-input baseline in a far more significant way than by increasing the model's complexity. Results suggest that less computing resources are required for postfiltering when provided with both target and interference signals, which is a step forward in developing an online speech enhancement system for multi-speech scenarios.
</details>
<details>
<summary>摘要</summary>
空间滤波可以利用深度学习基于的Speech增强模型来提高其在多个语音源场景中的可靠性。为进一步提高语音质量，通常会在估计目标语音后进行后 filtering。在这种工作中，使用最小差异无损响应（MVDR）来提供干扰估计，同时提供目标语音估计，以便后续使用。这会提高增强性能，相比增加模型复杂度。结果表明，提供target和干扰信号后 filtering需要更少的计算资源，这是在开发在线语音增强系统的重要进展。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/10/cs.SD_2023_09_10/" data-id="cloimipe200uss48839ol4kxi" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_10" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/10/cs.CV_2023_09_10/" class="article-date">
  <time datetime="2023-09-10T13:00:00.000Z" itemprop="datePublished">2023-09-10</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/10/cs.CV_2023_09_10/">cs.CV - 2023-09-10</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Beyond-Skin-Tone-A-Multidimensional-Measure-of-Apparent-Skin-Color"><a href="#Beyond-Skin-Tone-A-Multidimensional-Measure-of-Apparent-Skin-Color" class="headerlink" title="Beyond Skin Tone: A Multidimensional Measure of Apparent Skin Color"></a>Beyond Skin Tone: A Multidimensional Measure of Apparent Skin Color</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05148">http://arxiv.org/abs/2309.05148</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Thong, Przemyslaw Joniak, Alice Xiang</li>
<li>for: 这篇论文目的是在计算机视觉中测量表面颜色，超越单一的皮肤颜色标准。</li>
<li>methods: 该论文使用了 Fitzpatrick 皮肤类型分类法，以及颜色探测技术来评估计算机视觉系统中的皮肤偏见。</li>
<li>results: 该论文发现，使用单一的皮肤颜色标准（Fitzpatrick 分类法）不能充分捕捉计算机视觉系统中的皮肤偏见，而使用多维度皮肤颜色标准（包括皮肤颜色和颜色角度）可以更好地评估计算机视觉系统中的皮肤偏见。<details>
<summary>Abstract</summary>
This paper strives to measure apparent skin color in computer vision, beyond a unidimensional scale on skin tone. In their seminal paper Gender Shades, Buolamwini and Gebru have shown how gender classification systems can be biased against women with darker skin tones. Subsequently, fairness researchers and practitioners have adopted the Fitzpatrick skin type classification as a common measure to assess skin color bias in computer vision systems. While effective, the Fitzpatrick scale only focuses on the skin tone ranging from light to dark. Towards a more comprehensive measure of skin color, we introduce the hue angle ranging from red to yellow. When applied to images, the hue dimension reveals additional biases related to skin color in both computer vision datasets and models. We then recommend multidimensional skin color scales, relying on both skin tone and hue, for fairness assessments.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Skeleton-based-Approach-For-Rock-Crack-Detection-Towards-A-Climbing-Robot-Application"><a href="#A-Skeleton-based-Approach-For-Rock-Crack-Detection-Towards-A-Climbing-Robot-Application" class="headerlink" title="A Skeleton-based Approach For Rock Crack Detection Towards A Climbing Robot Application"></a>A Skeleton-based Approach For Rock Crack Detection Towards A Climbing Robot Application</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05139">http://arxiv.org/abs/2309.05139</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/josselinsomervilleroberts/reachbot-predictor">https://github.com/josselinsomervilleroberts/reachbot-predictor</a></li>
<li>paper_authors: Josselin Somerville Roberts, Paul-Emile Giacomelli, Yoni Gozlan, Julia Di</li>
<li>for: 这个论文是为了提高吊 Bridge 爬行机器人在科学上有趣但危险的洞穴环境中的运动能力而写的。</li>
<li>methods: 这篇论文使用了一种新的分割方法，即 SKeleton Intersection Loss (SKIL)，以便在硬石表面上检测岩石裂隙和边缘。此外，论文还提出了一组新的评价指标，即 LineAcc，以便评估细长物体分割的质量。</li>
<li>results: 根据论文的描述，使用 SKIL 方法和 LineAcc 指标可以在类似的细长物体分割任务中获得更高的性能，例如血管分割。这表示这些方法可以用于吊 Bridge 爬行机器人上的 grasp 位置识别。<details>
<summary>Abstract</summary>
Conventional wheeled robots are unable to traverse scientifically interesting, but dangerous, cave environments. Multi-limbed climbing robot designs, such as ReachBot, are able to grasp irregular surface features and execute climbing motions to overcome obstacles, given suitable grasp locations. To support grasp site identification, we present a method for detecting rock cracks and edges, the SKeleton Intersection Loss (SKIL). SKIL is a loss designed for thin object segmentation that leverages the skeleton of the label. A dataset of rock face images was collected, manually annotated, and augmented with generated data. A new group of metrics, LineAcc, has been proposed for thin object segmentation such that the impact of the object width on the score is minimized. In addition, the metric is less sensitive to translation which can often lead to a score of zero when computing classical metrics such as Dice on thin objects. Our fine-tuned models outperform previous methods on similar thin object segmentation tasks such as blood vessel segmentation and show promise for integration onto a robotic system.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="DAD-Improved-Data-free-Test-Time-Adversarial-Defense"><a href="#DAD-Improved-Data-free-Test-Time-Adversarial-Defense" class="headerlink" title="DAD++: Improved Data-free Test Time Adversarial Defense"></a>DAD++: Improved Data-free Test Time Adversarial Defense</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05132">http://arxiv.org/abs/2309.05132</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vcl-iisc/data-free-defense-at-test-time">https://github.com/vcl-iisc/data-free-defense-at-test-time</a></li>
<li>paper_authors: Gaurav Kumar Nayak, Inder Khatri, Shubham Randive, Ruchit Rawal, Anirban Chakraborty</li>
<li>for: 这个研究旨在提高深度神经网络在实际应用中的防御性，以应对攻击者可能会运用攻击技术来破坏神经网络的问题。</li>
<li>methods: 本研究使用了训练时间不需要数据的攻击防御技术，包括检测和修正框架。此外，为了进一步提高修正框架在检测器不足自信的情况下的表现，提出了一种软检测方案（称为“DAD++”）。</li>
<li>results: 在多个数据集和网络架构上进行了广泛的实验和检测，证明了我们的提案的有效性。此外，我们还证明了我们的方法可以在没有训练数据的情况下实现攻击防御，例如在数据自由知识传播和无监督无标注领域数据预测等方面。我们发现在所有实验和应用中，我们的DAD++方法具有优秀的防御性，即使面对多种攻击方法，clean准确率也几乎不受影响。<details>
<summary>Abstract</summary>
With the increasing deployment of deep neural networks in safety-critical applications such as self-driving cars, medical imaging, anomaly detection, etc., adversarial robustness has become a crucial concern in the reliability of these networks in real-world scenarios. A plethora of works based on adversarial training and regularization-based techniques have been proposed to make these deep networks robust against adversarial attacks. However, these methods require either retraining models or training them from scratch, making them infeasible to defend pre-trained models when access to training data is restricted. To address this problem, we propose a test time Data-free Adversarial Defense (DAD) containing detection and correction frameworks. Moreover, to further improve the efficacy of the correction framework in cases when the detector is under-confident, we propose a soft-detection scheme (dubbed as "DAD++"). We conduct a wide range of experiments and ablations on several datasets and network architectures to show the efficacy of our proposed approach. Furthermore, we demonstrate the applicability of our approach in imparting adversarial defense at test time under data-free (or data-efficient) applications/setups, such as Data-free Knowledge Distillation and Source-free Unsupervised Domain Adaptation, as well as Semi-supervised classification frameworks. We observe that in all the experiments and applications, our DAD++ gives an impressive performance against various adversarial attacks with a minimal drop in clean accuracy. The source code is available at: https://github.com/vcl-iisc/Improved-Data-free-Test-Time-Adversarial-Defense
</details>
<details>
<summary>摘要</summary>
随着深度神经网络在安全关键应用领域的普及，如自动驾驶车、医学影像分析、异常检测等，对深度神经网络的抗 adversarial 性能成为了这些网络在实际场景中的可靠性问题。众多基于对抗训练和规范化技术的方法已经被提议以使得这些深度网络对 adversarial 攻击具有抗性。然而，这些方法需要 Either retrain models 或从scratch 训练，使得在数据限制情况下不可防御 pre-trained 模型。为解决这个问题，我们提出了一种测试时 Data-free Adversarial Defense (DAD) 包含检测和修正框架。此外，为了进一步提高修正框架在检测器具有低自信的情况下的效果，我们提议了一种软检测方案（称为 "DAD++"）。我们在多种数据集和网络架构上进行了广泛的实验和剖除，以示我们的提议方法的有效性。此外，我们还证明了我们的方法可以在数据缺乏（或数据高效）应用/设置下进行免数据抗 adversarial 防御，如数据缺乏知识传承和源缺乏无监督领域适应，以及半监督分类框架。我们在所有实验和应用中观察到，我们的 DAD++ 在对多种 adversarial 攻击的检测和修正方面表现出色，而且clean accuracy 的损失很小。源代码可以在：https://github.com/vcl-iisc/Improved-Data-free-Test-Time-Adversarial-Defense 中下载。
</details></li>
</ul>
<hr>
<h2 id="3D-Implicit-Transporter-for-Temporally-Consistent-Keypoint-Discovery"><a href="#3D-Implicit-Transporter-for-Temporally-Consistent-Keypoint-Discovery" class="headerlink" title="3D Implicit Transporter for Temporally Consistent Keypoint Discovery"></a>3D Implicit Transporter for Temporally Consistent Keypoint Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05098">http://arxiv.org/abs/2309.05098</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhongcl-thu/3d-implicit-transporter">https://github.com/zhongcl-thu/3d-implicit-transporter</a></li>
<li>paper_authors: Chengliang Zhong, Yuhang Zheng, Yupeng Zheng, Hao Zhao, Li Yi, Xiaodong Mu, Ling Wang, Pengfei Li, Guyue Zhou, Chao Yang, Xinliang Zhang, Jian Zhao</li>
<li>for: 本研究旨在提高3D点云数据中的键点检测精度，通过 integrate 空间和时间信息。</li>
<li>methods: 该研究提出了首个3D版本的Transporter方法，基于混合3D表示、交叉注意力和隐藏重建。</li>
<li>results: 对3D柔性物体和非定形动物（人类和小鼠）进行了验证，显示学习的键点具有空间-时间一致性。此外，还提出了一种封闭控制策略，利用学习的键点进行3D物体抓取，并证明其性能优于传统方法。<details>
<summary>Abstract</summary>
Keypoint-based representation has proven advantageous in various visual and robotic tasks. However, the existing 2D and 3D methods for detecting keypoints mainly rely on geometric consistency to achieve spatial alignment, neglecting temporal consistency. To address this issue, the Transporter method was introduced for 2D data, which reconstructs the target frame from the source frame to incorporate both spatial and temporal information. However, the direct application of the Transporter to 3D point clouds is infeasible due to their structural differences from 2D images. Thus, we propose the first 3D version of the Transporter, which leverages hybrid 3D representation, cross attention, and implicit reconstruction. We apply this new learning system on 3D articulated objects and nonrigid animals (humans and rodents) and show that learned keypoints are spatio-temporally consistent. Additionally, we propose a closed-loop control strategy that utilizes the learned keypoints for 3D object manipulation and demonstrate its superior performance. Codes are available at https://github.com/zhongcl-thu/3D-Implicit-Transporter.
</details>
<details>
<summary>摘要</summary>
《键点基本表示法在视觉和机器人任务中表现出了优势。然而，现有的2D和3D关键点检测方法主要基于几何一致性来实现空间对齐，忽略了时间一致性。为解决这个问题，Transporter方法在2D数据上被引入，可以重建目标帧从源帧中，并同时包含空间和时间信息。然而，直接将Transporter应用于3D点云是不可能的，因为它们与2D图像的结构不同。因此，我们提出了第一个3D版本的Transporter，它利用混合3D表示、对比注意力和隐式重建。我们在3D可变物体和非均质动物（人类和小鼠）上应用这种新学习系统，并证明学习的关键点是空间-时间一致的。此外，我们提出了一种封闭控制策略，使用学习的关键点进行3D物体操作，并证明其性能更高。代码可以在https://github.com/zhongcl-thu/3D-Implicit-Transporter上下载。》Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know and I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="MaskRenderer-3D-Infused-Multi-Mask-Realistic-Face-Reenactment"><a href="#MaskRenderer-3D-Infused-Multi-Mask-Realistic-Face-Reenactment" class="headerlink" title="MaskRenderer: 3D-Infused Multi-Mask Realistic Face Reenactment"></a>MaskRenderer: 3D-Infused Multi-Mask Realistic Face Reenactment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05095">http://arxiv.org/abs/2309.05095</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tina Behrouzi, Atefeh Shahroudnejad, Payam Mousavi</li>
<li>for: 本研究旨在提出一种新的端到端身份无关面塑渲染系统，MaskRenderer，可以在实时下生成真实、高精度的面塑渲染图像。</li>
<li>methods: MaskRenderer使用以下三种方法来解决现有面塑渲染问题：（i）使用3DMM模型来更好地处理pose变化、遮挡和嘴部运动;（ii）使用 triplet loss函数来在训练中进行cross-reenactment，以保持人脸认知;（iii）使用多尺度遮挡来提高填充和恢复失去的区域。</li>
<li>results: 根据在VoxCeleb1测试集上进行的全面量化和质量测试，MaskRenderer比现有的模型在未看到面前，尤其是当源和驱动身份很不同时，表现出优异的效果。<details>
<summary>Abstract</summary>
We present a novel end-to-end identity-agnostic face reenactment system, MaskRenderer, that can generate realistic, high fidelity frames in real-time. Although recent face reenactment works have shown promising results, there are still significant challenges such as identity leakage and imitating mouth movements, especially for large pose changes and occluded faces. MaskRenderer tackles these problems by using (i) a 3DMM to model 3D face structure to better handle pose changes, occlusion, and mouth movements compared to 2D representations; (ii) a triplet loss function to embed the cross-reenactment during training for better identity preservation; and (iii) multi-scale occlusion, improving inpainting and restoring missing areas. Comprehensive quantitative and qualitative experiments conducted on the VoxCeleb1 test set, demonstrate that MaskRenderer outperforms state-of-the-art models on unseen faces, especially when the Source and Driving identities are very different.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的端到端无关identitface reenactment系统，MaskRenderer，可以在实时下生成真实、高质量的帧。尽管最近的face reenactment工作已经显示出了有前途的结果，但还存在许多挑战，如人脸泄露和模仿嘴部运动，尤其是大 pose 变化和 occluded 人脸。MaskRenderer 通过以下几个方法解决这些问题：(i) 使用 3DMM 模型人脸结构来更好地处理 pose 变化、遮挡和嘴部运动，相比于2D 表示。(ii) 使用 triplet 损失函数在训练期间进行 cross-reenactment 的嵌入，以保持人脸identit。(iii) 使用多尺度遮挡，提高填充和恢复缺失区域。我们在 VoxCeleb1 测试集上进行了全面的量化和质量实验，结果表明，MaskRenderer 在未看过的人脸上比 state-of-the-art 模型更高效，特别是当 Source 和 Driving 身份很不同时。
</details></li>
</ul>
<hr>
<h2 id="Sculpting-Efficiency-Pruning-Medical-Imaging-Models-for-On-Device-Inference"><a href="#Sculpting-Efficiency-Pruning-Medical-Imaging-Models-for-On-Device-Inference" class="headerlink" title="Sculpting Efficiency: Pruning Medical Imaging Models for On-Device Inference"></a>Sculpting Efficiency: Pruning Medical Imaging Models for On-Device Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05090">http://arxiv.org/abs/2309.05090</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sudarshan Sreeram, Bernhard Kainz</li>
<li>for: 这个论文旨在应用机器学习技术于医疗领域，以提高患者结果。</li>
<li>methods: 这个论文使用了筛选排序技术，测试了心血管疾病和眼科领域的分割模型。</li>
<li>results: 研究发现，使用筛选排序技术可以实现图像压缩率达1148倍，而无需 sacrifiSing图像质量。此外， filter-pruned模型在高压缩率下的执行速度比GPU基eline更快。此外，这些模型还表现出了比基eline和Weight-pruned模型更好的 Robustness和泛化特点。<details>
<summary>Abstract</summary>
Applying ML advancements to healthcare can improve patient outcomes. However, the sheer operational complexity of ML models, combined with legacy hardware and multi-modal gigapixel images, poses a severe deployment limitation for real-time, on-device inference. We consider filter pruning as a solution, exploring segmentation models in cardiology and ophthalmology. Our preliminary results show a compression rate of up to 1148x with minimal loss in quality, stressing the need to consider task complexity and architectural details when using off-the-shelf models. At high compression rates, filter-pruned models exhibit faster inference on a CPU than the GPU baseline. We also demonstrate that such models' robustness and generalisability characteristics exceed that of the baseline and weight-pruned counterparts. We uncover intriguing questions and take a step towards realising cost-effective disease diagnosis, monitoring, and preventive solutions.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)使用机器学习（ML）技术应用于医疗领域可以提高病人结果，但是ML模型的运算复杂性，加上传统硬件和多模式 gigapixel 图像，导致实时、设备上的推理存在严重的部署限制。我们考虑使用筛子剪辑作为解决方案，探索卡диологи和眼科领域中的 segmentation 模型。我们的初步结果显示，可以达到 1148x 的压缩率，而且影响质量 minimal。这说明在使用卖外模型时需要考虑任务复杂性和建筑特点。在高压缩率下，筛子剪辑的模型在 CPU 上的推理速度比 GPU 基线 faster。我们还发现这些模型的可靠性和泛化特点超过基线和重量剪辑模型。我们探索了一些有趣的问题，并在实现成本效果的道路上进行了一步前进。
</details></li>
</ul>
<hr>
<h2 id="FreeMan-Towards-Benchmarking-3D-Human-Pose-Estimation-in-the-Wild"><a href="#FreeMan-Towards-Benchmarking-3D-Human-Pose-Estimation-in-the-Wild" class="headerlink" title="FreeMan: Towards Benchmarking 3D Human Pose Estimation in the Wild"></a>FreeMan: Towards Benchmarking 3D Human Pose Estimation in the Wild</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05073">http://arxiv.org/abs/2309.05073</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangjiongw/freeman_api">https://github.com/wangjiongw/freeman_api</a></li>
<li>paper_authors: Jiong Wang, Fengyu Yang, Wenbo Gou, Bingliang Li, Danqi Yan, Ailing Zeng, Yijun Gao, Junle Wang, Ruimao Zhang</li>
<li>for: 这个论文的目的是为了提供一个大规模、实际场景中的人体3D姿态估计数据集，以促进人体 pose estimation 领域的研究。</li>
<li>methods: 这个论文使用了多视图摄像头捕捉的方法，将数据集收集到了8000个序列、1100万帧中，并设计了一个自动化、精确的标注管道，以便大规模处理。</li>
<li>results: 这个论文提供了一个大规模、实际场景中的人体3D姿态估计数据集，并提供了评估基准，以便评估不同任务的性能。这个数据集还能够在实际场景中提供Robust的人体姿态估计。<details>
<summary>Abstract</summary>
Estimating the 3D structure of the human body from natural scenes is a fundamental aspect of visual perception. This task carries great importance for fields like AIGC and human-robot interaction. In practice, 3D human pose estimation in real-world settings is a critical initial step in solving this problem. However, the current datasets, often collected under controlled laboratory conditions using complex motion capture equipment and unvarying backgrounds, are insufficient. The absence of real-world datasets is stalling the progress of this crucial task. To facilitate the development of 3D pose estimation, we present FreeMan, the first large-scale, real-world multi-view dataset. FreeMan was captured by synchronizing 8 smartphones across diverse scenarios. It comprises 11M frames from 8000 sequences, viewed from different perspectives. These sequences cover 40 subjects across 10 different scenarios, each with varying lighting conditions. We have also established an automated, precise labeling pipeline that allows for large-scale processing efficiently. We provide comprehensive evaluation baselines for a range of tasks, underlining the significant challenges posed by FreeMan. Further evaluations of standard indoor/outdoor human sensing datasets reveal that FreeMan offers robust representation transferability in real and complex scenes. FreeMan is now publicly available at https://wangjiongw.github.io/freeman.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate the following text into Simplified Chinese<</SYS>>人体三维结构估算从自然场景中获得是视觉认知的基本问题。这项任务对于AIGC和人机交互等领域具有极大的重要性。然而，现有的数据集，通常在控制的实验室条件下使用复杂的运动跟踪设备和不变的背景 captured，具有限制性。absence of real-world data is hindering the progress of this critical task. To facilitate the development of 3D pose estimation, we present FreeMan, the first large-scale, real-world multi-view dataset. FreeMan was captured by synchronizing 8 smartphones across diverse scenarios. It comprises 11 million frames from 8000 sequences, viewed from different perspectives. These sequences cover 40 subjects across 10 different scenarios, each with varying lighting conditions. We have also established an automated, precise labeling pipeline that allows for large-scale processing efficiently. We provide comprehensive evaluation baselines for a range of tasks, underlining the significant challenges posed by FreeMan. Further evaluations of standard indoor/outdoor human sensing datasets reveal that FreeMan offers robust representation transferability in real and complex scenes. FreeMan is now publicly available at <https://wangjiongw.github.io/freeman>.Translation:人体三维结构估算从自然场景中获得是视觉认知的基本问题。这项任务对于AIGC和人机交互等领域具有极大的重要性。然而，现有的数据集，通常在控制的实验室条件下使用复杂的运动跟踪设备和不变的背景 captured，具有限制性。absence of real-world data is hindering the progress of this critical task. To facilitate the development of 3D pose estimation, we present FreeMan, the first large-scale, real-world multi-view dataset. FreeMan was captured by synchronizing 8 smartphones across diverse scenarios. It comprises 11 million frames from 8000 sequences, viewed from different perspectives. These sequences cover 40 subjects across 10 different scenarios, each with varying lighting conditions. We have also established an automated, precise labeling pipeline that allows for large-scale processing efficiently. We provide comprehensive evaluation baselines for a range of tasks, underlining the significant challenges posed by FreeMan. Further evaluations of standard indoor/outdoor human sensing datasets reveal that FreeMan offers robust representation transferability in real and complex scenes. FreeMan is now publicly available at <https://wangjiongw.github.io/freeman>.
</details></li>
</ul>
<hr>
<h2 id="Lung-Diseases-Image-Segmentation-using-Faster-R-CNNs"><a href="#Lung-Diseases-Image-Segmentation-using-Faster-R-CNNs" class="headerlink" title="Lung Diseases Image Segmentation using Faster R-CNNs"></a>Lung Diseases Image Segmentation using Faster R-CNNs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06386">http://arxiv.org/abs/2309.06386</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mihir Jain</li>
<li>for: 这个论文主要是为了提高儿童肺病诊断的准确率，以减少发展国家儿童死亡率。</li>
<li>methods: 这个论文提出了一种基于低级别神经网络结构的方法，以解决深度网络中的拓扑挑战。该方法包括在特征峰中嵌入参数，以提高数据提取和避免信息损失。它还使用软非最大抑制来优化地方提案网络生成的地方提案。</li>
<li>results: 该论文在肺X射线图像上进行了测试，并计算了冲撤率、准确率、敏感度和特征率来评估模型的性能。研究还分析了损失函数的趋势，包括训练阶段和分类阶段的loss函数。<details>
<summary>Abstract</summary>
Lung diseases are a leading cause of child mortality in the developing world, with India accounting for approximately half of global pneumonia deaths (370,000) in 2016. Timely diagnosis is crucial for reducing mortality rates. This paper introduces a low-density neural network structure to mitigate topological challenges in deep networks. The network incorporates parameters into a feature pyramid, enhancing data extraction and minimizing information loss. Soft Non-Maximal Suppression optimizes regional proposals generated by the Region Proposal Network. The study evaluates the model on chest X-ray images, computing a confusion matrix to determine accuracy, precision, sensitivity, and specificity. We analyze loss functions, highlighting their trends during training. The regional proposal loss and classification loss assess model performance during training and classification phases. This paper analysis lung disease detection and neural network structures.
</details>
<details>
<summary>摘要</summary>
乳腺疾病是发展中国家儿童死亡率的主要原因，印度负责全球肺炎死亡人数的大约一半（370,000）在2016年。 时间早报诊断非常重要，以减少死亡率。这篇论文介绍了一种低密度神经网络结构，以减少深度网络的拓扑挑战。该网络嵌入参数到特征pyramid中，提高数据提取和减少信息损失。软非最大抑制优化地区提议生成的地区提议网络。本研究对胸部X射线图像进行评估，计算冲混矩阵来确定准确率、精度、敏感度和特征率。我们分析损失函数，描述它们在训练和分类阶段的趋势。地域提议损失和分类损失评估模型在训练和分类阶段的性能。本文分析肺疾病检测和神经网络结构。
</details></li>
</ul>
<hr>
<h2 id="Super-Resolution-Surface-Reconstruction-from-Few-Low-Resolution-Slices"><a href="#Super-Resolution-Surface-Reconstruction-from-Few-Low-Resolution-Slices" class="headerlink" title="Super-Resolution Surface Reconstruction from Few Low-Resolution Slices"></a>Super-Resolution Surface Reconstruction from Few Low-Resolution Slices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05071">http://arxiv.org/abs/2309.05071</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cyiyoo/SurfaceReconstructionFromFewSlices">https://github.com/cyiyoo/SurfaceReconstructionFromFewSlices</a></li>
<li>paper_authors: Yiyao Zhang, Ke Chen, Shang-Hua Yang</li>
<li>for: 提高几何特征表面的分辨率，以便进行其他数学模拟（如费米素分析）。</li>
<li>methods: 提出了一种基于循环几何的变量模型，并实现了两种数值算法（投影梯度下降法和多个参数的替换方法）来解决该模型。</li>
<li>results: 通过实际例子（包括另一种变量模型的输出）的数值实验，显示了新模型的优点，并通过几何学的标准差比较来证明其精度的提高。<details>
<summary>Abstract</summary>
In many imaging applications where segmented features (e.g. blood vessels) are further used for other numerical simulations (e.g. finite element analysis), the obtained surfaces do not have fine resolutions suitable for the task. Increasing the resolution of such surfaces becomes crucial. This paper proposes a new variational model for solving this problem, based on an Euler-Elastica-based regulariser. Further, we propose and implement two numerical algorithms for solving the model, a projected gradient descent method and the alternating direction method of multipliers. Numerical experiments using real-life examples (including two from outputs of another variational model) have been illustrated for effectiveness. The advantages of the new model are shown through quantitative comparisons by the standard deviation of Gaussian curvatures and mean curvatures from the viewpoint of discrete geometry.
</details>
<details>
<summary>摘要</summary>
Many 图像应用程序中，已经分割特征（例如血液动脉）进行其他数学模拟（例如finite element分析）时，获得的表面没有高精度适用于任务。 提高表面精度成为重要问题。这篇论文提出了一种新的可变模型，基于Euler-Elastica基础函数。此外，我们提出并实现了两种数值算法来解决该模型，即投影梯度下降法和分解方向多项式法。实际实验使用真实的例子（包括另一种可变模型的输出），以示效果。新模型的优势通过精度评估（基于离散几何的标准差）与其他模型进行比较。
</details></li>
</ul>
<hr>
<h2 id="Exploiting-CLIP-for-Zero-shot-HOI-Detection-Requires-Knowledge-Distillation-at-Multiple-Levels"><a href="#Exploiting-CLIP-for-Zero-shot-HOI-Detection-Requires-Knowledge-Distillation-at-Multiple-Levels" class="headerlink" title="Exploiting CLIP for Zero-shot HOI Detection Requires Knowledge Distillation at Multiple Levels"></a>Exploiting CLIP for Zero-shot HOI Detection Requires Knowledge Distillation at Multiple Levels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05069">http://arxiv.org/abs/2309.05069</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bobwan1995/zeroshot-hoi-with-clip">https://github.com/bobwan1995/zeroshot-hoi-with-clip</a></li>
<li>paper_authors: Bo Wan, Tinne Tuytelaars</li>
<li>for: 本研究探讨了零例人物对象互动（HOI）检测任务，这是一种不需要特定任务标注的新 paradigm。</li>
<li>methods: 我们采用了CLIP，一个大规模预训练的视觉语言模型（VLM），进行知识储存和多级卷积 neural network，以学习HOI表示。</li>
<li>results: 我们的实验证明，我们的新的多级CLIP知识集成策略能够实现强大的表现，与一些完全监督和弱监督方法相比，其表现甚至能达到公共HICO-DET标准 benchmark 的水平。<details>
<summary>Abstract</summary>
In this paper, we investigate the task of zero-shot human-object interaction (HOI) detection, a novel paradigm for identifying HOIs without the need for task-specific annotations. To address this challenging task, we employ CLIP, a large-scale pre-trained vision-language model (VLM), for knowledge distillation on multiple levels. Specifically, we design a multi-branch neural network that leverages CLIP for learning HOI representations at various levels, including global images, local union regions encompassing human-object pairs, and individual instances of humans or objects. To train our model, CLIP is utilized to generate HOI scores for both global images and local union regions that serve as supervision signals. The extensive experiments demonstrate the effectiveness of our novel multi-level CLIP knowledge integration strategy. Notably, the model achieves strong performance, which is even comparable with some fully-supervised and weakly-supervised methods on the public HICO-DET benchmark.
</details>
<details>
<summary>摘要</summary>
在本文中，我们研究了零例人物对象互动（HOI）检测任务，这是一种新的概念，可以无需特定任务的注释来认定HOIs。为解决这个复杂的任务，我们使用了CLIP，一个大规模预训练的视觉语言模型（VLM），进行知识储存在多级。具体来说，我们设计了一个多支 neuron 网络，利用CLIP来学习 HOI 表示形式在不同级别，包括全图、人物对象对的本地联合区域以及人类或物体的个体实例。为训练我们的模型，CLIP 生成了 HOI  scores  для全图和本地联合区域，这些权重函数作为超参数。我们的实验证明，我们的新的多级 CLIP 知识集成策略有效。特别是，模型在公共 HICO-DET benchmark 上表现出色，与一些完全监督和弱监督方法相比，其性能甚至达到了一些相似水平。
</details></li>
</ul>
<hr>
<h2 id="Multi-view-Self-supervised-Disentanglement-for-General-Image-Denoising"><a href="#Multi-view-Self-supervised-Disentanglement-for-General-Image-Denoising" class="headerlink" title="Multi-view Self-supervised Disentanglement for General Image Denoising"></a>Multi-view Self-supervised Disentanglement for General Image Denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05049">http://arxiv.org/abs/2309.05049</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chqwer2/multi-view-self-supervised-disentanglement-denoising">https://github.com/chqwer2/multi-view-self-supervised-disentanglement-denoising</a></li>
<li>paper_authors: Hao Chen, Chenyuan Qu, Yu Zhang, Chen Chen, Jianbo Jiao</li>
<li>for: 提高现代图像噪声去除器的性能，采用深度学习方法。</li>
<li>methods: 提出了一种自我超vised学习框架，不需要seen clean图像，通过两个不同的噪声版本输入，学习分离干净图像的特征和噪声。</li>
<li>results: 在 synthetic 和实际噪声下，与先前自我超vised方法相比，提出的方法表现更加优秀，特别是在未看到的新噪声类型上。在实际噪声下，even outperform its supervised counterparts by over 3 dB.<details>
<summary>Abstract</summary>
With its significant performance improvements, the deep learning paradigm has become a standard tool for modern image denoisers. While promising performance has been shown on seen noise distributions, existing approaches often suffer from generalisation to unseen noise types or general and real noise. It is understandable as the model is designed to learn paired mapping (e.g. from a noisy image to its clean version). In this paper, we instead propose to learn to disentangle the noisy image, under the intuitive assumption that different corrupted versions of the same clean image share a common latent space. A self-supervised learning framework is proposed to achieve the goal, without looking at the latent clean image. By taking two different corrupted versions of the same image as input, the proposed Multi-view Self-supervised Disentanglement (MeD) approach learns to disentangle the latent clean features from the corruptions and recover the clean image consequently. Extensive experimental analysis on both synthetic and real noise shows the superiority of the proposed method over prior self-supervised approaches, especially on unseen novel noise types. On real noise, the proposed method even outperforms its supervised counterparts by over 3 dB.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:利用深度学习 paradigm 的性能提升，现代图像去噪器已成为标准工具。然而，现有方法常受到未经测试的噪音类型或通用噪音的影响。这是因为模型是用来学习对应关系（例如，从噪图到其干净版本）。在这篇文章中，我们反而提议学习噪图，基于干净图像的假设，即不同的噪图版本都共享同一个封闭空间。我们提出了一种自我超级vised学习框架，以实现目标。无需考虑干净图像，我们的Multi-view Self-supervised Disentanglement（MeD）方法可以从两个不同的噪图版本中提取干净特征，并 eventually 恢复干净图像。我们对具有 synthetic 和实际噪音的实验分析表明，我们的方法在先前的自我超级vised方法中表现出优异性，特别是在未经测试的新类型噪音上。在实际噪音上，我们的方法甚至超过了其supervised对手的性能，高于3 dB。
</details></li>
</ul>
<hr>
<h2 id="What-Is-Near-Room-Locality-Learning-for-Enhanced-Robot-Vision-Language-Navigation-in-Indoor-Living-Environments"><a href="#What-Is-Near-Room-Locality-Learning-for-Enhanced-Robot-Vision-Language-Navigation-in-Indoor-Living-Environments" class="headerlink" title="What Is Near?: Room Locality Learning for Enhanced Robot Vision-Language-Navigation in Indoor Living Environments"></a>What Is Near?: Room Locality Learning for Enhanced Robot Vision-Language-Navigation in Indoor Living Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05036">http://arxiv.org/abs/2309.05036</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muraleekrishna Gopinathan, Jumana Abu-Khalaf, David Suter, Sidike Paheding, Nathir A. Rawashdeh</li>
<li>for: 本研究旨在提供基于常见家居空间知识的可理解语言导航（VLN）模型，帮助导航器在新环境中快速寻找目标房间。</li>
<li>methods: 我们提出了一种名为WIN（What Is Near）的共通elian学习模型，该模型根据当前观察和导航历史，使用生活空间的常见知识来预测当前环境的局部地图。</li>
<li>results: 我们的实验结果显示，基于WIN模型的本地-全球规划和预测室内布局可以帮助导航器更好地选择合适的行动，并在未看过的环境中表现出比 классиical VLN代理更好的普适性。我们的模型在标准VLN指标中获得了68%的成功率和63%的成功指标。<details>
<summary>Abstract</summary>
Humans use their knowledge of common house layouts obtained from previous experiences to predict nearby rooms while navigating in new environments. This greatly helps them navigate previously unseen environments and locate their target room. To provide layout prior knowledge to navigational agents based on common human living spaces, we propose WIN (\textit{W}hat \textit{I}s \textit{N}ear), a commonsense learning model for Vision Language Navigation (VLN) tasks. VLN requires an agent to traverse indoor environments based on descriptive navigational instructions. Unlike existing layout learning works, WIN predicts the local neighborhood map based on prior knowledge of living spaces and current observation, operating on an imagined global map of the entire environment. The model infers neighborhood regions based on visual cues of current observations, navigational history, and layout common sense. We show that local-global planning based on locality knowledge and predicting the indoor layout allows the agent to efficiently select the appropriate action. Specifically, we devised a cross-modal transformer that utilizes this locality prior for decision-making in addition to visual inputs and instructions. Experimental results show that locality learning using WIN provides better generalizability compared to classical VLN agents in unseen environments. Our model performs favorably on standard VLN metrics, with Success Rate 68\% and Success weighted by Path Length 63\% in unseen environments.
</details>
<details>
<summary>摘要</summary>
人类利用前期经验获得的常见家庭布局知识，在新环境中预测附近的房间，以便更好地导航和寻找目标房间。为了为导航代理人提供基于常见生活空间的布局先验知识，我们提议了WIN（何处near）模型，这是一种基于视觉语言导航（VLN）任务的 Commonsense 学习模型。VLN需要一个代理人通过描述性导航指令 traverse indoor环境。不同于现有的布局学习工作，WIN 预测当前环境的本地区域地图，基于先前的生活空间知识和当前观察，并在想象的全局环境地图上进行操作。模型根据当前观察的视觉指示和导航历史，以及布局常识来做地图推断。我们发现，基于本地知识和预测室内布局，使用WIN 模型进行本地-全局规划，可以有效地选择适当的行动。特别是，我们开发了一种跨模态变换器，使用这种本地知识进行决策，并与视觉输入和指令一起使用。实验结果表明，利用WIN 模型学习本地知识可以在未seen 环境中提供更好的普适性，我们的模型在标准 VLN 指标上表现良好，Success Rate 为 68%，Success weighted by Path Length 为 63%。
</details></li>
</ul>
<hr>
<h2 id="Unified-Contrastive-Fusion-Transformer-for-Multimodal-Human-Action-Recognition"><a href="#Unified-Contrastive-Fusion-Transformer-for-Multimodal-Human-Action-Recognition" class="headerlink" title="Unified Contrastive Fusion Transformer for Multimodal Human Action Recognition"></a>Unified Contrastive Fusion Transformer for Multimodal Human Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05032">http://arxiv.org/abs/2309.05032</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kyoung Ok Yang, Junho Koh, Jun Won Choi<br>for:本研究旨在提高人体动作识别（HAR）模型的性能，通过融合不同感知器获取的数据。methods:本文提出了一种新的多模式融合架构， referred to as Unified Contrastive Fusion Transformer (UCFFormer)，用于融合不同分布的数据，以提高HAR性能。UCFFormer使用了Unified Transformer来捕捉多模式嵌入特征之间的相互关系，并使用Factorized Time-Modality Attention进行有效的自我注意力计算。此外，UCFFormer还包括对比学习，以减少不同模式特征分布之间的差异，从而生成协调的特征 для信息融合。results:实验结果表明，UCFFormer在UTD-MHAD和NTU RGB+D等两个 популяр的数据集上表现出状元的性能，与竞争方法相比，具有显著的优势。<details>
<summary>Abstract</summary>
Various types of sensors have been considered to develop human action recognition (HAR) models. Robust HAR performance can be achieved by fusing multimodal data acquired by different sensors. In this paper, we introduce a new multimodal fusion architecture, referred to as Unified Contrastive Fusion Transformer (UCFFormer) designed to integrate data with diverse distributions to enhance HAR performance. Based on the embedding features extracted from each modality, UCFFormer employs the Unified Transformer to capture the inter-dependency among embeddings in both time and modality domains. We present the Factorized Time-Modality Attention to perform self-attention efficiently for the Unified Transformer. UCFFormer also incorporates contrastive learning to reduce the discrepancy in feature distributions across various modalities, thus generating semantically aligned features for information fusion. Performance evaluation conducted on two popular datasets, UTD-MHAD and NTU RGB+D, demonstrates that UCFFormer achieves state-of-the-art performance, outperforming competing methods by considerable margins.
</details>
<details>
<summary>摘要</summary>
不同类型的感知器被考虑用于开发人体行为识别（HAR）模型。在这篇论文中，我们介绍了一种新的多模态融合架构，称为统一对比融合变换器（UCFFormer），用于融合具有多样化分布的数据以提高HAR性能。基于每种模式中提取的嵌入特征，UCFFormer使用统一变换器来捕捉时间和模式域中嵌入的相互关系。我们还提出了分解时间-模式注意力 Mechanism，以实现效率的自我注意力计算。UCFFormer还 integrate了对比学习，以降低不同模式特征分布的差异，从而生成具有相同含义的特征进行信息融合。在UTD-MHAD和NTU RGB+D等两个流行的数据集上进行了性能评估，结果表明，UCFFormer在与竞争方法相比具有明显的优势，以至于达到状态之 искусственный智能。
</details></li>
</ul>
<hr>
<h2 id="SC-NeRF-Self-Correcting-Neural-Radiance-Field-with-Sparse-Views"><a href="#SC-NeRF-Self-Correcting-Neural-Radiance-Field-with-Sparse-Views" class="headerlink" title="SC-NeRF: Self-Correcting Neural Radiance Field with Sparse Views"></a>SC-NeRF: Self-Correcting Neural Radiance Field with Sparse Views</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05028">http://arxiv.org/abs/2309.05028</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liang Song, Guangming Wang, Jiuming Liu, Zhenyang Fu, Yanzi Miao, Hesheng</li>
<li>for: 本研究扩展了神经辐射场的总结任务到户外场景，并且只使用对象级 datasets 进行训练。</li>
<li>methods: 我们提出了一种基于多头注意力机制的几何修正模块和出现修正模块来解决室外场景中的分布隔离和视角变化导致的渲染问题。</li>
<li>results: 我们的方法在四个 dataset （Blender, DTU, LLFF, Spaces）上进行评估，与之前的方法相比，我们的网络在户外场景中表现出色，PSNR 平均值由 19.369 提高到 25.989，SSIM 平均值由 0.838 提高到 0.889，LPIPS 值由 0.265 降低到 0.224。<details>
<summary>Abstract</summary>
In recent studies, the generalization of neural radiance fields for novel view synthesis task has been widely explored. However, existing methods are limited to objects and indoor scenes. In this work, we extend the generalization task to outdoor scenes, trained only on object-level datasets. This approach presents two challenges. Firstly, the significant distributional shift between training and testing scenes leads to black artifacts in rendering results. Secondly, viewpoint changes in outdoor scenes cause ghosting or missing regions in rendered images. To address these challenges, we propose a geometric correction module and an appearance correction module based on multi-head attention mechanisms. We normalize rendered depth and combine it with light direction as query in the attention mechanism. Our network effectively corrects varying scene structures and geometric features in outdoor scenes, generalizing well from object-level to unseen outdoor scenes. Additionally, we use appearance correction module to correct appearance features, preventing rendering artifacts like blank borders and ghosting due to viewpoint changes. By combining these modules, our approach successfully tackles the challenges of outdoor scene generalization, producing high-quality rendering results. When evaluated on four datasets (Blender, DTU, LLFF, Spaces), our network outperforms previous methods. Notably, compared to MVSNeRF, our network improves average PSNR from 19.369 to 25.989, SSIM from 0.838 to 0.889, and reduces LPIPS from 0.265 to 0.224 on Spaces outdoor scenes.
</details>
<details>
<summary>摘要</summary>
在 latest studies, 神经网络频谱场景推广到新视图合成任务中得到了广泛探索。然而，现有方法仅限于对象和室内场景。在这种工作中，我们将推广任务扩展到户外场景，只使用对象级数据进行训练。这种方法存在两个挑战。首先，训练和测试场景之间的分布差异导致黑色artefacts在渲染结果中出现。其次，户外场景中的视角变化会导致 Ghosting 或者 absent 区域在渲染图像中出现。为了解决这些挑战，我们提议一种几何修正模块和一种外观修正模块，这两个模块都基于多头注意机制。我们将渲染深度Normalize 并与光direction作为查询在注意机制中。我们的网络有效地 correction 户外场景中的变化Scene structure 和几何特征，通过对象级数据进行推广，在未看到的户外场景中 generalized 良好。此外，我们使用外观修正模块来修正外观特征，避免由视角变化引起的渲染缺陷，如空白边缘和 Ghosting。通过这两个模块的组合，我们的方法成功地解决了户外场景推广的挑战，生成高质量的渲染结果。当我们的网络在四个数据集（Blender, DTU, LLFF, Spaces）进行评估时，与之前的方法相比，我们的网络在PSNR, SSIM 和 LPIPS 等指标上表现出色，特别是在 Spaces 户外场景上，我们的网络从19.369 提高到25.989，从0.838 提高到0.889，并且降低了0.265 到0.224。
</details></li>
</ul>
<hr>
<h2 id="Boosting-Unsupervised-Contrastive-Learning-Using-Diffusion-Based-Data-Augmentation-From-Scratch"><a href="#Boosting-Unsupervised-Contrastive-Learning-Using-Diffusion-Based-Data-Augmentation-From-Scratch" class="headerlink" title="Boosting Unsupervised Contrastive Learning Using Diffusion-Based Data Augmentation From Scratch"></a>Boosting Unsupervised Contrastive Learning Using Diffusion-Based Data Augmentation From Scratch</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07909">http://arxiv.org/abs/2309.07909</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zelin Zang, Hao Luo, Kai Wang, Panpan Zhang, Fan Wang, Stan. Z Li, Yang You</li>
<li>for: 提高不监督对比学习的效果，特别是针对科学数据领域的数据增强。</li>
<li>methods: 提出了一种基于扩散的数据增强技术DiffAug，通过扩散步骤确保增强后和原始数据的略matrizspace相似。DiffAug不需要标签、外部数据&#x2F;模型或先前知识，因为它首先在邻域中挖掘足够的语义知识。</li>
<li>results: DiffAug在图像分类和聚类任务上提高了1.6%~4.5%的精度，对生物数据进行应用后提高了10.1%的性能，平均提高5.8%。DiffAug在视觉和生物领域都表现良好。<details>
<summary>Abstract</summary>
Unsupervised contrastive learning methods have recently seen significant improvements, particularly through data augmentation strategies that aim to produce robust and generalizable representations. However, prevailing data augmentation methods, whether hand designed or based on foundation models, tend to rely heavily on prior knowledge or external data. This dependence often compromises their effectiveness and efficiency. Furthermore, the applicability of most existing data augmentation strategies is limited when transitioning to other research domains, especially science-related data. This limitation stems from the paucity of prior knowledge and labeled data available in these domains. To address these challenges, we introduce DiffAug-a novel and efficient Diffusion-based data Augmentation technique. DiffAug aims to ensure that the augmented and original data share a smoothed latent space, which is achieved through diffusion steps. Uniquely, unlike traditional methods, DiffAug first mines sufficient prior semantic knowledge about the neighborhood. This provides a constraint to guide the diffusion steps, eliminating the need for labels, external data/models, or prior knowledge. Designed as an architecture-agnostic framework, DiffAug provides consistent improvements. Specifically, it improves image classification and clustering accuracy by 1.6%~4.5%. When applied to biological data, DiffAug improves performance by up to 10.1%, with an average improvement of 5.8%. DiffAug shows good performance in both vision and biological domains.
</details>
<details>
<summary>摘要</summary>
Recently, unsupervised contrastive learning methods have made significant progress, particularly through data augmentation strategies that aim to produce robust and generalizable representations. However, current data augmentation methods, whether designed by hand or based on pre-existing models, often rely heavily on prior knowledge or external data, which can limit their effectiveness and efficiency. Moreover, most existing data augmentation strategies are not applicable to other research domains, especially science-related data, due to the lack of prior knowledge and labeled data available in these domains. To address these challenges, we propose DiffAug, a novel and efficient Diffusion-based data Augmentation technique. DiffAug aims to ensure that the augmented and original data share a smoothed latent space, which is achieved through a series of diffusion steps. Unlike traditional methods, DiffAug first mines sufficient prior semantic knowledge about the neighborhood, providing a constraint to guide the diffusion steps, eliminating the need for labels, external data/models, or prior knowledge. As an architecture-agnostic framework, DiffAug provides consistent improvements, with image classification and clustering accuracy improved by 1.6%~4.5% and biological data improved by up to 10.1%, with an average improvement of 5.8%. DiffAug demonstrates good performance in both vision and biological domains.
</details></li>
</ul>
<hr>
<h2 id="DeViT-Decomposing-Vision-Transformers-for-Collaborative-Inference-in-Edge-Devices"><a href="#DeViT-Decomposing-Vision-Transformers-for-Collaborative-Inference-in-Edge-Devices" class="headerlink" title="DeViT: Decomposing Vision Transformers for Collaborative Inference in Edge Devices"></a>DeViT: Decomposing Vision Transformers for Collaborative Inference in Edge Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05015">http://arxiv.org/abs/2309.05015</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guanyu Xu, Zhiwei Hao, Yong Luo, Han Hu, Jianping An, Shiwen Mao<br>for:* The paper aims to achieve fast and energy-efficient collaborative inference for vision transformer (ViT) models on resource-constrained edge devices, while maintaining comparable accuracy with large ViTs.methods:* The authors propose a collaborative inference framework called DeViT, which decomposes large ViTs into multiple small models for efficient inference on edge devices.* They also design a decomposition-and-ensemble algorithm based on knowledge distillation, called DEKD, to fuse multiple small decomposed models and reduce communication overheads.results:* The authors achieve efficient collaborative inference for ViTs and outperform existing lightweight ViTs, striking a good trade-off between efficiency and accuracy.* Their DeViTs improve end-to-end latency by 2.89 times with only 1.65% accuracy sacrifice compared to the large ViT, ViT-L&#x2F;16, on the GPU server.* Their DeDeiTs surpass the recent efficient ViT, MobileViT-S, by 3.54% in accuracy on ImageNet-1K, while running 1.72 times faster and requiring 55.28% lower energy consumption on the edge device.<details>
<summary>Abstract</summary>
Recent years have witnessed the great success of vision transformer (ViT), which has achieved state-of-the-art performance on multiple computer vision benchmarks. However, ViT models suffer from vast amounts of parameters and high computation cost, leading to difficult deployment on resource-constrained edge devices. Existing solutions mostly compress ViT models to a compact model but still cannot achieve real-time inference. To tackle this issue, we propose to explore the divisibility of transformer structure, and decompose the large ViT into multiple small models for collaborative inference at edge devices. Our objective is to achieve fast and energy-efficient collaborative inference while maintaining comparable accuracy compared with large ViTs. To this end, we first propose a collaborative inference framework termed DeViT to facilitate edge deployment by decomposing large ViTs. Subsequently, we design a decomposition-and-ensemble algorithm based on knowledge distillation, termed DEKD, to fuse multiple small decomposed models while dramatically reducing communication overheads, and handle heterogeneous models by developing a feature matching module to promote the imitations of decomposed models from the large ViT. Extensive experiments for three representative ViT backbones on four widely-used datasets demonstrate our method achieves efficient collaborative inference for ViTs and outperforms existing lightweight ViTs, striking a good trade-off between efficiency and accuracy. For example, our DeViTs improves end-to-end latency by 2.89$\times$ with only 1.65% accuracy sacrifice using CIFAR-100 compared to the large ViT, ViT-L/16, on the GPU server. DeDeiTs surpasses the recent efficient ViT, MobileViT-S, by 3.54% in accuracy on ImageNet-1K, while running 1.72$\times$ faster and requiring 55.28% lower energy consumption on the edge device.
</details>
<details>
<summary>摘要</summary>
近年来，大量参数和高计算成本的视觉变换器（ViT）在计算机视觉领域取得了伟大成就，但是ViT模型在有限的边缘设备上进行部署是困难的。现有的解决方案主要是压缩ViT模型到一个尺寸化的模型，但是这些模型仍然无法实现实时推理。为了解决这个问题，我们提出了在变换结构中进行分解的方法，将大型ViT decomposed into multiple small models，以实现在边缘设备上快速和能efficient的合作推理。我们的目标是实现高度可配置的推理，同时保持与大型ViT相同的准确性。为此，我们首先提出了一种协同推理框架，称为DeViT，以便在边缘设备上部署。然后，我们设计了一种基于知识传授的分解和聚合算法，称为DEKD，以减少通信开销，并处理不同模型的兼容性。我们还开发了一种匹配特征模块，以促进分解模型从大型ViT中的模仿。我们对三种常见的ViT脊梁进行了四个常用的数据集进行了广泛的实验。结果表明，我们的方法可以实现高效的协同推理，同时保持与大型ViT相同的准确性。例如，我们的DeViT在CIFAR-100上提高了端到端延迟时间，同时仅减少了1.65%的准确性。DeDeiTs在ImageNet-1K上超越了最近的高效ViT，MobileViT-S，而且在边缘设备上运行1.72倍快，需要55.28%的能源投入下降。
</details></li>
</ul>
<hr>
<h2 id="Geometrically-Consistent-Partial-Shape-Matching"><a href="#Geometrically-Consistent-Partial-Shape-Matching" class="headerlink" title="Geometrically Consistent Partial Shape Matching"></a>Geometrically Consistent Partial Shape Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05013">http://arxiv.org/abs/2309.05013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Viktoria Ehm, Paul Roetzer, Marvin Eisenberger, Maolin Gao, Florian Bernard, Daniel Cremers</li>
<li>for: 这 paper 的目的是解决计算机视觉和图形领域中缺失部分形状匹配的问题，例如形状插值、pose transfer 和 texture transfer。</li>
<li>methods: 这 paper 使用了国际线性程序程序方法，并将国际状态艺术特征集成到匹配中。</li>
<li>results: 这 paper 的结果表明，使用这种方法可以在部分观察到的形状上提供更可靠和更平滑的匹配结果，并且可以比较学习基于的现有匹配方法。<details>
<summary>Abstract</summary>
Finding correspondences between 3D shapes is a crucial problem in computer vision and graphics, which is for example relevant for tasks like shape interpolation, pose transfer, or texture transfer. An often neglected but essential property of matchings is geometric consistency, which means that neighboring triangles in one shape are consistently matched to neighboring triangles in the other shape. Moreover, while in practice one often has only access to partial observations of a 3D shape (e.g. due to occlusion, or scanning artifacts), there do not exist any methods that directly address geometrically consistent partial shape matching. In this work we fill this gap by proposing to integrate state-of-the-art deep shape features into a novel integer linear programming partial shape matching formulation. Our optimization yields a globally optimal solution on low resolution shapes, which we then refine using a coarse-to-fine scheme. We show that our method can find more reliable results on partial shapes in comparison to existing geometrically consistent algorithms (for which one first has to fill missing parts with a dummy geometry). Moreover, our matchings are substantially smoother than learning-based state-of-the-art shape matching methods.
</details>
<details>
<summary>摘要</summary>
寻找3D形状之间的对应关系是计算机视觉和图形处理中的一项重要问题，这种问题在例如形状 interpolate、pose transfer 和 texture transfer 等任务中具有重要意义。一种常被忽略但重要的属性是 geometric consistency，即邻近的三角形在一个形状中是一致地匹配邻近的三角形在另一个形状中。而在实践中，一般只有对形状的部分观察数据（例如因 occlusion 或扫描 artifacts）的访问，而没有任何方法可以直接处理准确的 partial shape matching。在这个工作中，我们填充了这个空白，我们提议将 state-of-the-art 的深度 shape feature 集成到一个新的整数线性 программирова部分形状匹配方法中。我们的优化得到了低分辨率形状上的全球优化解决方案，然后使用一种 course-to-fine 方案进行细化。我们表明，我们的方法可以在 partial shape 上获得更可靠的结果，并且与现有的准确 geometric consistency 算法相比，我们的匹配结果更平滑。
</details></li>
</ul>
<hr>
<h2 id="Towards-Fully-Decoupled-End-to-End-Person-Search"><a href="#Towards-Fully-Decoupled-End-to-End-Person-Search" class="headerlink" title="Towards Fully Decoupled End-to-End Person Search"></a>Towards Fully Decoupled End-to-End Person Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04967">http://arxiv.org/abs/2309.04967</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pengcheng Zhang, Xiao Bai, Jin Zheng, Xin Ning</li>
<li>for: 本文旨在提出一种全分解人体搜索方法，即将搜索任务分解为两个子任务：检测和身份识别，并通过一个统一的模型来实现这两个任务。</li>
<li>methods: 该方法使用一种任务协调学习策略，即在检测和身份识别任务之间进行协调学习，以解决这两个任务之间的冲突。</li>
<li>results: 实验结果表明，该方法可以减轻人体搜索任务中的冲突，并提高搜索性能。<details>
<summary>Abstract</summary>
End-to-end person search aims to jointly detect and re-identify a target person in raw scene images with a unified model. The detection task unifies all persons while the re-id task discriminates different identities, resulting in conflict optimal objectives. Existing works proposed to decouple end-to-end person search to alleviate such conflict. Yet these methods are still sub-optimal on one or two of the sub-tasks due to their partially decoupled models, which limits the overall person search performance. In this paper, we propose to fully decouple person search towards optimal person search. A task-incremental person search network is proposed to incrementally construct an end-to-end model for the detection and re-id sub-task, which decouples the model architecture for the two sub-tasks. The proposed task-incremental network allows task-incremental training for the two conflicting tasks. This enables independent learning for different objectives thus fully decoupled the model for persons earch. Comprehensive experimental evaluations demonstrate the effectiveness of the proposed fully decoupled models for end-to-end person search.
</details>
<details>
<summary>摘要</summary>
Traditional end-to-end person search aims to jointly detect and re-identify a target person in raw scene images with a unified model. The detection task unifies all persons while the re-id task discriminates different identities, resulting in conflict optimal objectives. Existing works proposed to decouple end-to-end person search to alleviate such conflict. Yet these methods are still sub-optimal on one or two of the sub-tasks due to their partially decoupled models, which limits the overall person search performance. In this paper, we propose to fully decouple person search towards optimal person search. A task-incremental person search network is proposed to incrementally construct an end-to-end model for the detection and re-id sub-task, which decouples the model architecture for the two sub-tasks. The proposed task-incremental network allows task-incremental training for the two conflicting tasks. This enables independent learning for different objectives thus fully decoupled the model for persons search. Comprehensive experimental evaluations demonstrate the effectiveness of the proposed fully decoupled models for end-to-end person search.Here's the word-for-word translation:既然传统的端到端人体搜索是通过一个统一的模型来探测和重新标识目标人体在原始场景图像中的，但是探测和重新标识的任务之间存在冲突的优化目标。现有的方法是将端到端人体搜索解除，以降低这种冲突。然而，这些方法仍然在一或两个子任务上不优化，这限制了整体人体搜索性能。在本文中，我们提出了完全解除人体搜索的方法。我们提出了一种任务增量人体搜索网络，可以逐步建立端到端模型，以解除探测和重新标识两个子任务的模型体系。这种任务增量网络允许任务增量训练，从而实现独立学习不同目标，即完全解除人体搜索模型。我们的实验证明了我们的完全解除模型的效果。
</details></li>
</ul>
<hr>
<h2 id="Multi-modal-Extreme-Classification"><a href="#Multi-modal-Extreme-Classification" class="headerlink" title="Multi-modal Extreme Classification"></a>Multi-modal Extreme Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04961">http://arxiv.org/abs/2309.04961</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/extreme-classification/mufin">https://github.com/extreme-classification/mufin</a></li>
<li>paper_authors: Anshul Mittal, Kunal Dahiya, Shreya Malani, Janani Ramaswamy, Seba Kuruvilla, Jitendra Ajmera, Keng-hao Chang, Sumeet Agarwal, Purushottam Kar, Manik Varma</li>
<li>for: 这个论文是为了解决极端分类（XC）任务中 millions of labels 的问题，其中数据点和标签具有视觉和文本描述器。</li>
<li>methods: 这篇论文提出了 MUFIN 技术，它是一种基于 cross-modal 注意力的多模态方法，可以在 millions of labels 的情况下提供高精度的分类。</li>
<li>results: 在 MM-AmazonTitles-300K 数据集上，MUFIN 对比主流的文本基于、图像基于和多模态方法，能够提供至少 3% 高的精度。<details>
<summary>Abstract</summary>
This paper develops the MUFIN technique for extreme classification (XC) tasks with millions of labels where datapoints and labels are endowed with visual and textual descriptors. Applications of MUFIN to product-to-product recommendation and bid query prediction over several millions of products are presented. Contemporary multi-modal methods frequently rely on purely embedding-based methods. On the other hand, XC methods utilize classifier architectures to offer superior accuracies than embedding only methods but mostly focus on text-based categorization tasks. MUFIN bridges this gap by reformulating multi-modal categorization as an XC problem with several millions of labels. This presents the twin challenges of developing multi-modal architectures that can offer embeddings sufficiently expressive to allow accurate categorization over millions of labels; and training and inference routines that scale logarithmically in the number of labels. MUFIN develops an architecture based on cross-modal attention and trains it in a modular fashion using pre-training and positive and negative mining. A novel product-to-product recommendation dataset MM-AmazonTitles-300K containing over 300K products was curated from publicly available amazon.com listings with each product endowed with a title and multiple images. On the all datasets MUFIN offered at least 3% higher accuracy than leading text-based, image-based and multi-modal techniques. Code for MUFIN is available at https://github.com/Extreme-classification/MUFIN
</details>
<details>
<summary>摘要</summary>
Traditional multi-modal methods rely solely on embedding-based approaches, while XC methods use classifier architectures for higher accuracy but are limited to text-based categorization tasks. MUFIN addresses this gap by treating multi-modal categorization as an XC problem with millions of labels. This presents two challenges: developing multi-modal architectures that can provide expressive embeddings for accurate categorization, and training and inference routines that scale logarithmically with the number of labels.MUFIN's architecture is based on cross-modal attention and is trained in a modular fashion using pre-training and positive and negative mining. The authors curated a new dataset, MM-AmazonTitles-300K, containing over 300K products with titles and multiple images from publicly available Amazon listings. MUFIN achieved at least 3% higher accuracy than leading text-based, image-based, and multi-modal techniques on all datasets.The code for MUFIN is available on GitHub at <https://github.com/Extreme-classification/MUFIN>.
</details></li>
</ul>
<hr>
<h2 id="SdCT-GAN-Reconstructing-CT-from-Biplanar-X-Rays-with-Self-driven-Generative-Adversarial-Networks"><a href="#SdCT-GAN-Reconstructing-CT-from-Biplanar-X-Rays-with-Self-driven-Generative-Adversarial-Networks" class="headerlink" title="SdCT-GAN: Reconstructing CT from Biplanar X-Rays with Self-driven Generative Adversarial Networks"></a>SdCT-GAN: Reconstructing CT from Biplanar X-Rays with Self-driven Generative Adversarial Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04960">http://arxiv.org/abs/2309.04960</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/csqvictory/sdct-gan">https://github.com/csqvictory/sdct-gan</a></li>
<li>paper_authors: Shuangqin Cheng, Qingliang Chen, Qiyi Zhang, Ming Li, Yamuhanmode Alike, Kaile Su, Pengcheng Wen</li>
<li>For: The paper aims to address the limitations of existing methods in reconstructing 3D CT images from a limited number of 2D X-rays, by proposing a new self-driven generative adversarial network model (SdCT-GAN) that prioritizes the preservation of image details.* Methods: The proposed SdCT-GAN model incorporates a novel auto-encoder structure in the discriminator and utilizes a Sobel Gradient Guider (SGG) idea to integrate edge information from the 2D X-ray image at the input. Additionally, the LPIPS evaluation metric is adopted to quantitatively evaluate the fine contours and textures of reconstructed images.* Results: The proposed SdCT-GAN model outperforms mainstream state-of-the-art baselines in terms of both qualitative and quantitative results, as demonstrated through empirical studies. The reconstructed images exhibit better preservation of textural details and fine contours, as evaluated using the LPIPS metric.<details>
<summary>Abstract</summary>
Computed Tomography (CT) is a medical imaging modality that can generate more informative 3D images than 2D X-rays. However, this advantage comes at the expense of more radiation exposure, higher costs, and longer acquisition time. Hence, the reconstruction of 3D CT images using a limited number of 2D X-rays has gained significant importance as an economical alternative. Nevertheless, existing methods primarily prioritize minimizing pixel/voxel-level intensity discrepancies, often neglecting the preservation of textural details in the synthesized images. This oversight directly impacts the quality of the reconstructed images and thus affects the clinical diagnosis. To address the deficits, this paper presents a new self-driven generative adversarial network model (SdCT-GAN), which is motivated to pay more attention to image details by introducing a novel auto-encoder structure in the discriminator. In addition, a Sobel Gradient Guider (SGG) idea is applied throughout the model, where the edge information from the 2D X-ray image at the input can be integrated. Moreover, LPIPS (Learned Perceptual Image Patch Similarity) evaluation metric is adopted that can quantitatively evaluate the fine contours and textures of reconstructed images better than the existing ones. Finally, the qualitative and quantitative results of the empirical studies justify the power of the proposed model compared to mainstream state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
computed tomography (CT) 是医疗影像Modalities中能生成更加有用的三维图像，比二维X射线更高的Radiation exposure, cost and acquisition time. 因此，通过有限数量的二维X射线重建三维CT图像的重建技术已经得到了重要的重视。然而，现有的方法主要强调Minimize pixel/voxel-level intensity discrepancies，经常忽略保留图像细节的Synthesized images。这种缺点直接影响了重建图像的质量，从而affects the clinical diagnosis.为了解决这些缺点，本文提出了一种新的自适应生成对抗网络模型（SdCT-GAN），该模型具有一种新的自适应网络结构，以增强图像细节的保留。此外，本文还应用了 Sobel Gradient Guider（SGG）的想法，将输入2D X射线图像的边信息集成到模型中。此外，本文采用了LPIPS（学习Perceptual Image Patch Similarity）评价度量，可以更好地评估重建图像的细节和Texture。最后，对比主流状态的参考基eline，质量和量测试结果证明了提案模型的力量。
</details></li>
</ul>
<hr>
<h2 id="Semi-Supervised-learning-for-Face-Anti-Spoofing-using-Apex-frame"><a href="#Semi-Supervised-learning-for-Face-Anti-Spoofing-using-Apex-frame" class="headerlink" title="Semi-Supervised learning for Face Anti-Spoofing using Apex frame"></a>Semi-Supervised learning for Face Anti-Spoofing using Apex frame</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04958">http://arxiv.org/abs/2309.04958</a></li>
<li>repo_url: None</li>
<li>paper_authors: Usman Muhammad, Mourad Oussalah, Jorma Laaksonen</li>
<li>for: 提高面部防诈技术的表现</li>
<li>methods: 使用 Gaussian 分布计算apex帧，不需要卷积</li>
<li>results: 在四个面部防诈数据库（CASIA、REPLAY-ATTACK、OULU-NPU、MSU-MFSD）中，使用apex帧提高了面部防诈技术的表现<details>
<summary>Abstract</summary>
Conventional feature extraction techniques in the face anti-spoofing domain either analyze the entire video sequence or focus on a specific segment to improve model performance. However, identifying the optimal frames that provide the most valuable input for the face anti-spoofing remains a challenging task. In this paper, we address this challenge by employing Gaussian weighting to create apex frames for videos. Specifically, an apex frame is derived from a video by computing a weighted sum of its frames, where the weights are determined using a Gaussian distribution centered around the video's central frame. Furthermore, we explore various temporal lengths to produce multiple unlabeled apex frames using a Gaussian function, without the need for convolution. By doing so, we leverage the benefits of semi-supervised learning, which considers both labeled and unlabeled apex frames to effectively discriminate between live and spoof classes. Our key contribution emphasizes the apex frame's capacity to represent the most significant moments in the video, while unlabeled apex frames facilitate efficient semi-supervised learning, as they enable the model to learn from videos of varying temporal lengths. Experimental results using four face anti-spoofing databases: CASIA, REPLAY-ATTACK, OULU-NPU, and MSU-MFSD demonstrate the apex frame's efficacy in advancing face anti-spoofing techniques.
</details>
<details>
<summary>摘要</summary>
传统的特征提取技术在面对抗假驱动领域 either 分析整个视频序列或专注于特定的段来提高模型性能。然而，确定最佳的帧，以提供模型最有价值的输入， remains 一个挑战。在这篇论文中，我们解决这个挑战 by employing  Gaussian weighting to create apex frames for videos. Specifically, an apex frame is derived from a video by computing a weighted sum of its frames, where the weights are determined using a Gaussian distribution centered around the video's central frame. Furthermore, we explore various temporal lengths to produce multiple unlabeled apex frames using a Gaussian function, without the need for convolution. By doing so, we leverage the benefits of semi-supervised learning, which considers both labeled and unlabeled apex frames to effectively discriminate between live and spoof classes. Our key contribution emphasizes the apex frame's capacity to represent the most significant moments in the video, while unlabeled apex frames facilitate efficient semi-supervised learning, as they enable the model to learn from videos of varying temporal lengths. Experimental results using four face anti-spoofing databases: CASIA, REPLAY-ATTACK, OULU-NPU, and MSU-MFSD demonstrate the apex frame's efficacy in advancing face anti-spoofing techniques.
</details></li>
</ul>
<hr>
<h2 id="Anatomy-Completor-A-Multi-class-Completion-Framework-for-3D-Anatomy-Reconstruction"><a href="#Anatomy-Completor-A-Multi-class-Completion-Framework-for-3D-Anatomy-Reconstruction" class="headerlink" title="Anatomy Completor: A Multi-class Completion Framework for 3D Anatomy Reconstruction"></a>Anatomy Completor: A Multi-class Completion Framework for 3D Anatomy Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04956">http://arxiv.org/abs/2309.04956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianning Li, Antonio Pepe, Gijs Luijten, Christina Schwarz-Gsaxner, Jens Kleesiek, Jan Egger</li>
<li>for: 这 paper  targets 一种 scenario where one or multiple anatomies are missing in the imaging data due to surgical, pathological or traumatic factors, or simply because these anatomies are not covered by image acquisition.</li>
<li>methods: 该 paper 提出了 two paradigms based on a 3D denoising auto-encoder (DAE) to solve the anatomy reconstruction problem: (i) the DAE learns a many-to-one mapping between incomplete and complete instances; (ii) the DAE learns directly a one-to-one residual mapping between the incomplete instances and the target anatomies.</li>
<li>results: Results show that the method produces reasonable anatomy reconstructions given instances with different levels of incompleteness (i.e., one or multiple random anatomies are missing).<details>
<summary>Abstract</summary>
In this paper, we introduce a completion framework to reconstruct the geometric shapes of various anatomies, including organs, vessels and muscles. Our work targets a scenario where one or multiple anatomies are missing in the imaging data due to surgical, pathological or traumatic factors, or simply because these anatomies are not covered by image acquisition. Automatic reconstruction of the missing anatomies benefits many applications, such as organ 3D bio-printing, whole-body segmentation, animation realism, paleoradiology and forensic imaging. We propose two paradigms based on a 3D denoising auto-encoder (DAE) to solve the anatomy reconstruction problem: (i) the DAE learns a many-to-one mapping between incomplete and complete instances; (ii) the DAE learns directly a one-to-one residual mapping between the incomplete instances and the target anatomies. We apply a loss aggregation scheme that enables the DAE to learn the many-to-one mapping more effectively and further enhances the learning of the residual mapping. On top of this, we extend the DAE to a multiclass completor by assigning a unique label to each anatomy involved. We evaluate our method using a CT dataset with whole-body segmentations. Results show that our method produces reasonable anatomy reconstructions given instances with different levels of incompleteness (i.e., one or multiple random anatomies are missing). Codes and pretrained models are publicly available at https://github.com/Jianningli/medshapenet-feedback/ tree/main/anatomy-completor
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了一个完成框架，用于重建各种生物体的几何形状，包括器官、血管和肌肉。我们的工作针对于医学影像数据中缺失一或多个生物体，可能因为手术、病理或受伤等因素，或者只是因为这些生物体没有被影像捕获。自动重建缺失的生物体具有许多应用，如器官3D生物印刷、全身份割、动画实实地、古生物Radiology和审判影像。我们提出了两种方案，基于3D杂噪自动编码器（DAE）解决生物体重建问题：（i）DAE学习多个尝试的多对一映射，使得 incomplete instances 可以转化为完整的实例。（ii）DAE直接学习一对一差分映射，使得 incomplete instances 可以减少为目标生物体。我们采用损失聚合方案，使得 DAE 更好地学习多对一映射，并进一步提高了差分映射的学习。此外，我们将 DAE 扩展到多类完成器，通过为每个生物体分配唯一的标签。我们使用 CT 数据集进行评估，结果表明，我们的方法可以在不同水平的不完整性（即一或多个随机生物体缺失）下生成合理的生物体重建。代码和预训练模型可以在 <https://github.com/Jianningli/medshapenet-feedback/tree/main/anatomy-completor> 中下载。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Emotional-Adaptation-for-Audio-Driven-Talking-Head-Generation"><a href="#Efficient-Emotional-Adaptation-for-Audio-Driven-Talking-Head-Generation" class="headerlink" title="Efficient Emotional Adaptation for Audio-Driven Talking-Head Generation"></a>Efficient Emotional Adaptation for Audio-Driven Talking-Head Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04946">http://arxiv.org/abs/2309.04946</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuangan/eat_code">https://github.com/yuangan/eat_code</a></li>
<li>paper_authors: Yuan Gan, Zongxin Yang, Xihang Yue, Lingyun Sun, Yi Yang</li>
<li>for: 这项研究旨在提高audio-driven talking-head sintheis的灵活性和效率，并提供一种可靠地控制表情的方法。</li>
<li>methods: 该方法使用一个预训练的无情 talking-head transformer，并提出三种轻量级的改进（深度情感提示、情感变形网络和情感适应模块），以实现精准和真实的情感控制。</li>
<li>results: 该方法在广泛使用的benchmark上达到了状态之前的性能，包括LRW和MEAD。此外，我们的参数有效地适应能力在情感训练视频罕见或缺失时表现出色。<details>
<summary>Abstract</summary>
Audio-driven talking-head synthesis is a popular research topic for virtual human-related applications. However, the inflexibility and inefficiency of existing methods, which necessitate expensive end-to-end training to transfer emotions from guidance videos to talking-head predictions, are significant limitations. In this work, we propose the Emotional Adaptation for Audio-driven Talking-head (EAT) method, which transforms emotion-agnostic talking-head models into emotion-controllable ones in a cost-effective and efficient manner through parameter-efficient adaptations. Our approach utilizes a pretrained emotion-agnostic talking-head transformer and introduces three lightweight adaptations (the Deep Emotional Prompts, Emotional Deformation Network, and Emotional Adaptation Module) from different perspectives to enable precise and realistic emotion controls. Our experiments demonstrate that our approach achieves state-of-the-art performance on widely-used benchmarks, including LRW and MEAD. Additionally, our parameter-efficient adaptations exhibit remarkable generalization ability, even in scenarios where emotional training videos are scarce or nonexistent. Project website: https://yuangan.github.io/eat/
</details>
<details>
<summary>摘要</summary>
文本：Audio-driven talking-head synthesis是虚拟人类应用领域的受欢迎研究主题。然而，现有方法的不灵活和不效率是重要的限制，这些方法需要昂贵的端到端训练来传递视频指导中的情感到说话人预测中。在这项工作中，我们提出了情感适应 для Audio-driven Talking-head（EAT）方法，它将情感无关的说话人模型转化为可控情感的模型，在成本效率的方式下进行。我们的方法使用预训练的情感无关说话人转换器，并引入三种轻量级的适应（深度情感提示、情感变形网络和情感适应模块）从不同的角度来实现精准和真实的情感控制。我们的实验显示，我们的方法在广泛使用的标准准则上达到了状态 искусственный智能的性能，包括LRW和MEAD。此外，我们的参数效率的适应表现了Remarkable的总体化能力，即使情感训练视频罕见或缺失。项目网站：https://yuangan.github.io/eat/Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Text-driven-Editing-of-3D-Scenes-without-Retraining"><a href="#Text-driven-Editing-of-3D-Scenes-without-Retraining" class="headerlink" title="Text-driven Editing of 3D Scenes without Retraining"></a>Text-driven Editing of 3D Scenes without Retraining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04917">http://arxiv.org/abs/2309.04917</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuangkang Fang, Yufeng Wang, Yi Yang, Yi-Hsuan Tsai, Wenrui Ding, Ming-Hsuan Yang, Shuchang Zhou</li>
<li>for: 该文章目的是提出一种基于文本的3D场景编辑方法，允许用户通过文本描述编辑3D场景图像。</li>
<li>methods: 该方法使用现成的文本基于编辑模型来修改2D图像，然后对修改后的图像进行筛选，以消除质量不佳的图像。最后，该方法使用生成特征相似的训练数据来减少干扰干扰。</li>
<li>results: 该方法可以实现多种编辑类型，包括外观编辑、天气转换、材质变换和风格传递。具有用户可以通过文本描述编辑3D场景图像的便捷、直观和实用性。<details>
<summary>Abstract</summary>
Numerous diffusion models have recently been applied to image synthesis and editing. However, editing 3D scenes is still in its early stages. It poses various challenges, such as the requirement to design specific methods for different editing types, retraining new models for various 3D scenes, and the absence of convenient human interaction during editing. To tackle these issues, we introduce a text-driven editing method, termed DN2N, which allows for the direct acquisition of a NeRF model with universal editing capabilities, eliminating the requirement for retraining. Our method employs off-the-shelf text-based editing models of 2D images to modify the 3D scene images, followed by a filtering process to discard poorly edited images that disrupt 3D consistency. We then consider the remaining inconsistency as a problem of removing noise perturbation, which can be solved by generating training data with similar perturbation characteristics for training. We further propose cross-view regularization terms to help the generalized NeRF model mitigate these perturbations. Our text-driven method allows users to edit a 3D scene with their desired description, which is more friendly, intuitive, and practical than prior works. Empirical results show that our method achieves multiple editing types, including but not limited to appearance editing, weather transition, material changing, and style transfer. Most importantly, our method generalizes well with editing abilities shared among a set of model parameters without requiring a customized editing model for some specific scenes, thus inferring novel views with editing effects directly from user input. The project website is available at http://sk-fun.fun/DN2N
</details>
<details>
<summary>摘要</summary>
“很多扩散模型在图像生成和修改中被应用，但是修改3D场景仍处于早期阶段。这具有多种挑战，例如需要设计特定的修改类型，重新训练新模型以适应不同的3D场景，以及在修改过程中缺乏便利的人类交互。为解决这些问题，我们介绍了一种基于文本的修改方法，称为DN2N，它允许直接从文本描述中获得一个通用的修改能力。我们的方法使用商业可用的文本基于修改模型来修改2D图像，然后对修改后的图像进行筛选，以排除破坏3D一致性的图像。我们认为剩下的不一致性可以视为去除噪声干扰的问题，可以通过生成类似噪声特征的训练数据来解决。我们还提出了跨视图常见化项来帮助通用NeRF模型解决这些干扰。我们的文本驱动方法允许用户通过文本描述修改3D场景，这是较为友好、直观和实用的than之前的方法。我们的实验结果表明，我们的方法可以实现多种修改类型，包括但不限于外观修改、天气转换、材质变化和风格传递。最重要的是，我们的方法可以将修改能力共享到一组模型参数中，无需特定的修改模型，从而直接从用户输入中推断出修改后的视图。项目网站地址为http://sk-fun.fun/DN2N。”
</details></li>
</ul>
<hr>
<h2 id="Transformers-in-Small-Object-Detection-A-Benchmark-and-Survey-of-State-of-the-Art"><a href="#Transformers-in-Small-Object-Detection-A-Benchmark-and-Survey-of-State-of-the-Art" class="headerlink" title="Transformers in Small Object Detection: A Benchmark and Survey of State-of-the-Art"></a>Transformers in Small Object Detection: A Benchmark and Survey of State-of-the-Art</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04902">http://arxiv.org/abs/2309.04902</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/arekavandi/transformer-sod">https://github.com/arekavandi/transformer-sod</a></li>
<li>paper_authors: Aref Miri Rekavandi, Shima Rashidi, Farid Boussaid, Stephen Hoefs, Emre Akbas, Mohammed bennamoun</li>
<li>for: 这个研究的目的是探索对小物类别检测（SOD）的表现优化，以及可能的原因。</li>
<li>methods: 这个研究使用了训练中的广泛网络，包括当前最优秀的对应物检测器。</li>
<li>results: 这个研究发现，广泛网络在SOD tasks中的表现优化，并且提供了一个统计分析和评估方法来评估广泛网络在SOD tasks中的表现。<details>
<summary>Abstract</summary>
Transformers have rapidly gained popularity in computer vision, especially in the field of object recognition and detection. Upon examining the outcomes of state-of-the-art object detection methods, we noticed that transformers consistently outperformed well-established CNN-based detectors in almost every video or image dataset. While transformer-based approaches remain at the forefront of small object detection (SOD) techniques, this paper aims to explore the performance benefits offered by such extensive networks and identify potential reasons for their SOD superiority. Small objects have been identified as one of the most challenging object types in detection frameworks due to their low visibility. We aim to investigate potential strategies that could enhance transformers' performance in SOD. This survey presents a taxonomy of over 60 research studies on developed transformers for the task of SOD, spanning the years 2020 to 2023. These studies encompass a variety of detection applications, including small object detection in generic images, aerial images, medical images, active millimeter images, underwater images, and videos. We also compile and present a list of 12 large-scale datasets suitable for SOD that were overlooked in previous studies and compare the performance of the reviewed studies using popular metrics such as mean Average Precision (mAP), Frames Per Second (FPS), number of parameters, and more. Researchers can keep track of newer studies on our web page, which is available at \url{https://github.com/arekavandi/Transformer-SOD}.
</details>
<details>
<summary>摘要</summary>
孔雀Transformers在计算机视觉领域快速崛起，尤其是对象识别和检测领域。我们对现代对象检测方法的结果进行分析发现，transformers在大多数视频或图像数据集上 consistently outperform了基于CNN的检测器。虽然transformer-basedapproaches在小对象检测（SOD）技术中保持领先地位，但这篇论文旨在探讨transformers在SOD中的性能优势，以及可能的潜在原因。小对象被识别为计算机检测框架中最为困难的对象之一，因为它们的可见性较低。我们想 investigate potential strategies可以提高transformers在SOD中的表现。这篇评论文件了60多个关于发展transformers的研究成果，涵盖了2020-2023年间的多种检测应用，包括通用图像中的小对象检测、航空图像、医疗图像、活动毫米图像、水下图像和视频。我们还编译了12个大规模的SOD适用的数据集，并与之前的研究相比较了这些研究的性能，使用popular metrics such as mean Average Precision（mAP）、Frames Per Second（FPS）、参数数量和更多。研究人员可以通过我们的网页（https://github.com/arekavandi/Transformer-SOD） Track newer studies.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/10/cs.CV_2023_09_10/" data-id="cloimip9200h8s4889a1u4zqh" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_10" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/10/cs.AI_2023_09_10/" class="article-date">
  <time datetime="2023-09-10T12:00:00.000Z" itemprop="datePublished">2023-09-10</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/10/cs.AI_2023_09_10/">cs.AI - 2023-09-10</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Collecting-Visually-Grounded-Dialogue-with-A-Game-Of-Sorts"><a href="#Collecting-Visually-Grounded-Dialogue-with-A-Game-Of-Sorts" class="headerlink" title="Collecting Visually-Grounded Dialogue with A Game Of Sorts"></a>Collecting Visually-Grounded Dialogue with A Game Of Sorts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05162">http://arxiv.org/abs/2309.05162</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/willemsenbram/a-game-of-sorts">https://github.com/willemsenbram/a-game-of-sorts</a></li>
<li>paper_authors: Bram Willemsen, Dmytro Kalpakchi, Gabriel Skantze</li>
<li>for: 本研究旨在检验对话中referring表达的生成和固定过程是如何进行的。</li>
<li>methods: 本研究使用了一个合作图片排序任务，称为“ Sorting Game”，以检验对话中referring表达的困难性和复杂性。</li>
<li>results: 研究发现，在这种合作交流中，参与者需要通过讨论和协商来达成一致，而不是只是交换简单的referring表达。这些讨论和协商过程中，参与者需要共同理解和协商referent的含义和特征。<details>
<summary>Abstract</summary>
An idealized, though simplistic, view of the referring expression production and grounding process in (situated) dialogue assumes that a speaker must merely appropriately specify their expression so that the target referent may be successfully identified by the addressee. However, referring in conversation is a collaborative process that cannot be aptly characterized as an exchange of minimally-specified referring expressions. Concerns have been raised regarding assumptions made by prior work on visually-grounded dialogue that reveal an oversimplified view of conversation and the referential process. We address these concerns by introducing a collaborative image ranking task, a grounded agreement game we call "A Game Of Sorts". In our game, players are tasked with reaching agreement on how to rank a set of images given some sorting criterion through a largely unrestricted, role-symmetric dialogue. By putting emphasis on the argumentation in this mixed-initiative interaction, we collect discussions that involve the collaborative referential process. We describe results of a small-scale data collection experiment with the proposed task. All discussed materials, which includes the collected data, the codebase, and a containerized version of the application, are publicly available.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Faster-Lighter-More-Accurate-A-Deep-Learning-Ensemble-for-Content-Moderation"><a href="#Faster-Lighter-More-Accurate-A-Deep-Learning-Ensemble-for-Content-Moderation" class="headerlink" title="Faster, Lighter, More Accurate: A Deep Learning Ensemble for Content Moderation"></a>Faster, Lighter, More Accurate: A Deep Learning Ensemble for Content Moderation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05150">http://arxiv.org/abs/2309.05150</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Hosseini, Mahmudul Hasan</li>
<li>for:  addresses the increasing need for efficient and accurate content moderation</li>
<li>methods:  combines simple visual features with a lightweight ensemble of models</li>
<li>results:  achieves significant improvements in prediction accuracy with 7.64x faster inference and lower computation cost compared to popular deep learning models such as ResNet-50.<details>
<summary>Abstract</summary>
To address the increasing need for efficient and accurate content moderation, we propose an efficient and lightweight deep classification ensemble structure. Our approach is based on a combination of simple visual features, designed for high-accuracy classification of violent content with low false positives. Our ensemble architecture utilizes a set of lightweight models with narrowed-down color features, and we apply it to both images and videos.   We evaluated our approach using a large dataset of explosion and blast contents and compared its performance to popular deep learning models such as ResNet-50. Our evaluation results demonstrate significant improvements in prediction accuracy, while benefiting from 7.64x faster inference and lower computation cost.   While our approach is tailored to explosion detection, it can be applied to other similar content moderation and violence detection use cases as well. Based on our experiments, we propose a "think small, think many" philosophy in classification scenarios. We argue that transforming a single, large, monolithic deep model into a verification-based step model ensemble of multiple small, simple, and lightweight models with narrowed-down visual features can possibly lead to predictions with higher accuracy.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:为了解决内容筛选的增加需求，我们提出了一种高效、轻量级的深度分类ensemble结构。我们的方法基于一组简单的视觉特征，设计用于高精度的暴力内容分类，false positive低。我们的ensemble架构使用一组轻量级的模型，并将其应用于图像和视频。  我们使用一个大量的爆炸和爆炸内容Dataset进行评估，并与popular的深度学习模型 such as ResNet-50进行比较。我们的评估结果表明，我们的方法可以 achieve higher prediction accuracy, while enjoying 7.64x faster inference and lower computation cost。  虽然我们的方法是针对爆炸检测的，但它可以应用于其他类似的内容筛选和暴力检测场景。基于我们的实验，我们提出了一种"思小、思多"的哲学，即将单一的大型、复杂的深度模型转换为验证基于步骤模型ensemble，并使用简单的视觉特征进行筛选。我们认为这可能会导致更高的预测精度。
</details></li>
</ul>
<hr>
<h2 id="Representation-Learning-in-Low-rank-Slate-based-Recommender-Systems"><a href="#Representation-Learning-in-Low-rank-Slate-based-Recommender-Systems" class="headerlink" title="Representation Learning in Low-rank Slate-based Recommender Systems"></a>Representation Learning in Low-rank Slate-based Recommender Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08622">http://arxiv.org/abs/2309.08622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yijia Dai, Wen Sun</li>
<li>for: 提高用户长期活跃度，通过强化学习推荐系统。</li>
<li>methods: 使用标准推荐setup和低维度Markov决策过程（MDPs）进行 represntation学习算法，以处理在线RL问题。</li>
<li>results: 通过构建推荐 simulate环境和提出的采样方法，实现样本效率的学习和探索。<details>
<summary>Abstract</summary>
Reinforcement learning (RL) in recommendation systems offers the potential to optimize recommendations for long-term user engagement. However, the environment often involves large state and action spaces, which makes it hard to efficiently learn and explore. In this work, we propose a sample-efficient representation learning algorithm, using the standard slate recommendation setup, to treat this as an online RL problem with low-rank Markov decision processes (MDPs). We also construct the recommender simulation environment with the proposed setup and sampling method.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate Reinforcement Learning (RL) in recommendation systems into 推荐学习 (RL)<</SYS>>推荐学习（RL）在推荐系统中提供了长期用户参与度优化的潜在可能性。然而，环境通常具有大状态和动作空间，这使得效率地学习和探索变得困难。在这种工作中，我们提议一种效率的表示学习算法，使用标准推荐SlaterSetup，将这视为在线RL问题，使用低级Markov决策过程（MDP）。我们还构建了推荐 simulate环境，使用我们的设置和抽样方法。
</details></li>
</ul>
<hr>
<h2 id="Outlier-Robust-Adversarial-Training"><a href="#Outlier-Robust-Adversarial-Training" class="headerlink" title="Outlier Robust Adversarial Training"></a>Outlier Robust Adversarial Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05145">http://arxiv.org/abs/2309.05145</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/discovershu/orat">https://github.com/discovershu/orat</a></li>
<li>paper_authors: Shu Hu, Zhenhuan Yang, Xin Wang, Yiming Ying, Siwei Lyu</li>
<li>for: 这篇论文目的是提出一种能够同时处理含有异常值和敌意攻击的supervised学习模型，以提高模型的可靠性和robustness。</li>
<li>methods: 该论文提出了一种基于两级优化的BI-level adversarial Training（ORAT）方法，该方法使用一种鲁棒度-based loss函数来增强模型的鲁棒性。</li>
<li>results: 实验结果表明，ORAT可以有效地处理含有异常值和敌意攻击的训练数据，并且在高probability中保证了模型的一致性和一致性。<details>
<summary>Abstract</summary>
Supervised learning models are challenged by the intrinsic complexities of training data such as outliers and minority subpopulations and intentional attacks at inference time with adversarial samples. While traditional robust learning methods and the recent adversarial training approaches are designed to handle each of the two challenges, to date, no work has been done to develop models that are robust with regard to the low-quality training data and the potential adversarial attack at inference time simultaneously. It is for this reason that we introduce Outlier Robust Adversarial Training (ORAT) in this work. ORAT is based on a bi-level optimization formulation of adversarial training with a robust rank-based loss function. Theoretically, we show that the learning objective of ORAT satisfies the $\mathcal{H}$-consistency in binary classification, which establishes it as a proper surrogate to adversarial 0/1 loss. Furthermore, we analyze its generalization ability and provide uniform convergence rates in high probability. ORAT can be optimized with a simple algorithm. Experimental evaluations on three benchmark datasets demonstrate the effectiveness and robustness of ORAT in handling outliers and adversarial attacks. Our code is available at https://github.com/discovershu/ORAT.
</details>
<details>
<summary>摘要</summary>
超级vised学习模型面临训练数据中的自然复杂性，如异常数据和少数批处理，以及推理时间的意外攻击。传统的Robust学习方法和最近的对抗学习方法可以处理每一个挑战，但到目前为止，没有任何工作在同时处理低质量训练数据和推理时间的对抗攻击。这是我们在这篇文章中引入Outlier Robust Adversarial Training（ORAT）的原因。ORAT基于对抗训练的双级优化形式和Robust排名基于损失函数。我们理论上显示，ORAT的学习目标满足了$\mathcal{H}$-一致性在二分类问题中，这使其成为对抗0/1损失函数的合法代理。此外，我们分析了它的泛化能力，并提供了高probability中的均匀收敛率。ORAT可以使用简单的算法进行优化。实验评估在三个标准数据集上表明ORAT有效地处理异常数据和对抗攻击。我们的代码可以在https://github.com/discovershu/ORAT中找到。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-for-Difficulty-Estimation-of-Foreign-Language-Content-with-Application-to-Language-Learning"><a href="#Large-Language-Models-for-Difficulty-Estimation-of-Foreign-Language-Content-with-Application-to-Language-Learning" class="headerlink" title="Large Language Models for Difficulty Estimation of Foreign Language Content with Application to Language Learning"></a>Large Language Models for Difficulty Estimation of Foreign Language Content with Application to Language Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05142">http://arxiv.org/abs/2309.05142</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michalis Vlachos, Mircea Lungu, Yash Raj Shrestha, Johannes-Rudolf David</li>
<li>for: 帮助外语学习者提高外语水平，通过identifying感兴趣的话题和learner的外语水平相似的内容。</li>
<li>methods: 使用大语言模型提高外语学习者的掌握能力，包括发现learner关注的话题上的内容、更准确地估计内容的语言难度，以及提供文本和视频内容。</li>
<li>results: 提供一种可以适应学习者的兴趣和学习目标的语言学习解决方案，可以帮助学习者持续激发对外语学习的兴趣和motivation。<details>
<summary>Abstract</summary>
We use large language models to aid learners enhance proficiency in a foreign language. This is accomplished by identifying content on topics that the user is interested in, and that closely align with the learner's proficiency level in that foreign language. Our work centers on French content, but our approach is readily transferable to other languages. Our solution offers several distinctive characteristics that differentiate it from existing language-learning solutions, such as, a) the discovery of content across topics that the learner cares about, thus increasing motivation, b) a more precise estimation of the linguistic difficulty of the content than traditional readability measures, and c) the availability of both textual and video-based content. The linguistic complexity of video content is derived from the video captions. It is our aspiration that such technology will enable learners to remain engaged in the language-learning process by continuously adapting the topics and the difficulty of the content to align with the learners' evolving interests and learning objectives.
</details>
<details>
<summary>摘要</summary>
我们使用大型语言模型帮助学生提高Foreign language proficiency。我们通过识别用户感兴趣的话题，并与学生的Foreign language水平相似的话题进行匹配，以提高学生的motivation。我们的工作主要关注法语内容，但我们的方法可以适用于其他语言。我们的解决方案具有以下三个特点：一、通过找到用户关心的话题来增加motivation；二、通过语言难度测试来更准确地评估内容的语言难度；三、提供文本和视频内容。视频内容的语言难度来自于视频字幕。我们的目标是通过不断地适应用户的兴趣和学习目标，使学生保持在Foreign language学习过程中的兴趣和积极性。
</details></li>
</ul>
<hr>
<h2 id="Signal-Temporal-Logic-Neural-Predictive-Control"><a href="#Signal-Temporal-Logic-Neural-Predictive-Control" class="headerlink" title="Signal Temporal Logic Neural Predictive Control"></a>Signal Temporal Logic Neural Predictive Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05131">http://arxiv.org/abs/2309.05131</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yue Meng, Chuchu Fan</li>
<li>for: 本研究旨在提供一种能够系统地和可靠地满足长期机器人任务的安全性和时间约束要求的方法。</li>
<li>methods: 我们提出了一种直接使用强化学习学习一个神经网络控制器，以满足由Signal Temporal Logic（STL）所规定的要求。我们的控制器在训练中 Maximize STL 鲁棒性分数，在投入中类似于预测控制（MPC），预测一个在规划 horizons 内的 trajectory，以确保任务满足 STL 要求。</li>
<li>results: 我们在六个任务上进行了实验，其中我们的方法与备用策略在 STL 满足率方面表现出色，特别是在任务中存在复杂 STL 要求时，与传统方法（MPC、STL 解决方案）、模型自由和模型基于RL方法相比，速度比较快，10X-100X faster than classical methods。<details>
<summary>Abstract</summary>
Ensuring safety and meeting temporal specifications are critical challenges for long-term robotic tasks. Signal temporal logic (STL) has been widely used to systematically and rigorously specify these requirements. However, traditional methods of finding the control policy under those STL requirements are computationally complex and not scalable to high-dimensional or systems with complex nonlinear dynamics. Reinforcement learning (RL) methods can learn the policy to satisfy the STL specifications via hand-crafted or STL-inspired rewards, but might encounter unexpected behaviors due to ambiguity and sparsity in the reward. In this paper, we propose a method to directly learn a neural network controller to satisfy the requirements specified in STL. Our controller learns to roll out trajectories to maximize the STL robustness score in training. In testing, similar to Model Predictive Control (MPC), the learned controller predicts a trajectory within a planning horizon to ensure the satisfaction of the STL requirement in deployment. A backup policy is designed to ensure safety when our controller fails. Our approach can adapt to various initial conditions and environmental parameters. We conduct experiments on six tasks, where our method with the backup policy outperforms the classical methods (MPC, STL-solver), model-free and model-based RL methods in STL satisfaction rate, especially on tasks with complex STL specifications while being 10X-100X faster than the classical methods.
</details>
<details>
<summary>摘要</summary>
Ensuring safety and meeting temporal specifications are critical challenges for long-term robotic tasks. 信号时间逻辑（STL）已广泛应用于系统地和准确地要求这些需求。然而，传统的控制策略找到方法是计算复杂和不可扩展高维或非线性动力学系统。 reinforcement learning（RL）方法可以通过手工或STL- inspirited reward学习策略满足STL要求，但可能会遇到意外行为 due to ambiguity and sparsity in the reward.在这篇论文中，我们提出了一种方法，可以直接学习神经网络控制器，满足STL要求。我们的控制器在训练中学习满足STLRobustness分数的扩展曲线。在测试中，类似于Model Predictive Control（MPC），我们学习的控制器预测一个在规划时间Horizon内的轨迹，以确保STL要求的满足。我们还设计了一个备份策略，以确保安全性，当我们的控制器失败时。我们的方法可以适应不同的初始条件和环境参数。我们在六个任务上进行了实验，我们的方法，备份策略相比于经典方法（MPC、STL-solver）、模型自由和模型基于RL方法，在STL满足率方面表现出色，特别是在复杂的STL要求下，并且在10X-100X快于经典方法。
</details></li>
</ul>
<hr>
<h2 id="The-online-learning-architecture-with-edge-computing-for-high-level-control-for-assisting-patients"><a href="#The-online-learning-architecture-with-edge-computing-for-high-level-control-for-assisting-patients" class="headerlink" title="The online learning architecture with edge computing for high-level control for assisting patients"></a>The online learning architecture with edge computing for high-level control for assisting patients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05130">http://arxiv.org/abs/2309.05130</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yue Shi, Yihui Zhao</li>
<li>for: 这篇研究旨在提高因病患或创伤等因素而导致下肢功能障碍的人士 mobility 和 Rehabilitation 的可能性。</li>
<li>methods: 本研究使用了在紧复时间内处理感应数据的边缘 Computing 和在线 adversarial learning 架构，实现高级的下肢 exoskeleton 控制。</li>
<li>results: 实验结果显示，该架构可以提高控制精度和适应性，同时提高 Quality-of-Service (QoS) 指标。这些成果显示，将在线 adversarial learning 与边缘 Computing 结合可以提供下一代下肢 exoskeleton 控制系统的可靠和高效方法。<details>
<summary>Abstract</summary>
The prevalence of mobility impairments due to conditions such as spinal cord injuries, strokes, and degenerative diseases is on the rise globally. Lower-limb exoskeletons have been increasingly recognized as a viable solution for enhancing mobility and rehabilitation for individuals with such impairments. However, existing exoskeleton control systems often suffer from limitations such as latency, lack of adaptability, and computational inefficiency. To address these challenges, this paper introduces a novel online adversarial learning architecture integrated with edge computing for high-level lower-limb exoskeleton control. In the proposed architecture, sensor data from the user is processed in real-time through edge computing nodes, which then interact with an online adversarial learning model. This model adapts to the user's specific needs and controls the exoskeleton with minimal latency. Experimental evaluations demonstrate significant improvements in control accuracy and adaptability, as well as enhanced quality-of-service (QoS) metrics. These findings indicate that the integration of online adversarial learning with edge computing offers a robust and efficient approach for the next generation of lower-limb exoskeleton control systems.
</details>
<details>
<summary>摘要</summary>
全球的 mobililty 障碍（如脊梁创伤、中风和逐渐恶化的疾病）的发展趋势是增加的。Lower-limb exoskeletons 被越来越多地认为是提高 mobililty 和rehabilitation 的有效解决方案。然而，现有的 exoskeleton 控制系统经常受到 limitation 的影响，如延迟、缺乏适应性和计算不足。为了解决这些挑战，本文提出了一种基于 online adversarial learning 架构的高级 lower-limb exoskeleton 控制系统。在该架构中，用户的感知数据在实时通过边缘计算节点处理，然后与在线 adversarial learning 模型交互。这个模型适应用户的特定需求，控制 exoskeleton  WITH 最小延迟。实验评估表明，该架构可以提高控制精度和适应性，同时提高质量服务（QoS）指标。这些发现表明，将 online adversarial learning 与边缘计算相结合可以提供下一代 lower-limb exoskeleton 控制系统的可靠和高效的解决方案。
</details></li>
</ul>
<hr>
<h2 id="WIP-Development-of-a-Student-Centered-Personalized-Learning-Framework-to-Advance-Undergraduate-Robotics-Education"><a href="#WIP-Development-of-a-Student-Centered-Personalized-Learning-Framework-to-Advance-Undergraduate-Robotics-Education" class="headerlink" title="WIP: Development of a Student-Centered Personalized Learning Framework to Advance Undergraduate Robotics Education"></a>WIP: Development of a Student-Centered Personalized Learning Framework to Advance Undergraduate Robotics Education</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05124">http://arxiv.org/abs/2309.05124</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ponkoj Chandra Shill, Rui Wu, Hossein Jamali, Bryan Hutchins, Sergiu Dascalu, Frederick C. Harris, David Feil-Seifer</li>
<li>for: 提供个性化学习环境 для机器人学生，解决了学院级机器人教学资源紧缺和高昂的训练成本问题。</li>
<li>methods: 开发一个基于网页界面的机器人教学系统，可以与较便宜的硬件配合使用，以便免费分布教学材料，推动更多的机器人课程在两年和四年大学 Offered。</li>
<li>results: 针对五个Module mini-course进行了评估，发现学生对在线内容表示 позитив的体验，同时在相关性、熟悉性和自主性等三个方面得分很高，表明这种方法具有强大的动机潜力。<details>
<summary>Abstract</summary>
This paper presents a work-in-progress on a learn-ing system that will provide robotics students with a personalized learning environment. This addresses both the scarcity of skilled robotics instructors, particularly in community colleges and the expensive demand for training equipment. The study of robotics at the college level represents a wide range of interests, experiences, and aims. This project works to provide students the flexibility to adapt their learning to their own goals and prior experience. We are developing a system to enable robotics instruction through a web-based interface that is compatible with less expensive hardware. Therefore, the free distribution of teaching materials will empower educators. This project has the potential to increase the number of robotics courses offered at both two- and four-year schools and universities. The course materials are being designed with small units and a hierarchical dependency tree in mind; students will be able to customize their course of study based on the robotics skills they have already mastered. We present an evaluation of a five module mini-course in robotics. Students indicated that they had a positive experience with the online content. They also scored the experience highly on relatedness, mastery, and autonomy perspectives, demonstrating strong motivation potential for this approach.
</details>
<details>
<summary>摘要</summary>
这份论文介绍了一个学习系统，旨在为机器人学生提供个性化学习环境。这种系统将解决机器人教育人员短缺和训练设备成本高的问题，特别是在社区学院。学生在学习机器人时有各种兴趣、经验和目标，这个项目的目的是让学生可以根据自己的目标和先前学习来自定义学习路径。我们正在开发一个通过网络界面进行机器人教学，可以与较便宜的硬件相结合。因此，我们将免费发布教学材料，以便教育者们可以更加自由地使用。这个项目有望增加两年和四年学院和大学机器人课程的数量。我们正在设计课程材料，以小单元和层次结构为基础，学生可以根据已经掌握的机器人技能自定义课程。我们对五个模块小课程进行了评估，学生表示对在线内容有积极的体验，并在相关性、掌握和自主性方面得分高，表明这种方法具有强的动机潜力。
</details></li>
</ul>
<hr>
<h2 id="High-Fidelity-Fast-Simulation-of-Human-in-the-Loop-Human-in-the-Plant-HIL-HIP-Systems"><a href="#High-Fidelity-Fast-Simulation-of-Human-in-the-Loop-Human-in-the-Plant-HIL-HIP-Systems" class="headerlink" title="High Fidelity Fast Simulation of Human in the Loop Human in the Plant (HIL-HIP) Systems"></a>High Fidelity Fast Simulation of Human in the Loop Human in the Plant (HIL-HIP) Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06558">http://arxiv.org/abs/2309.06558</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ayan Banerjee, Payal Kamboj, Aranyak Maity, Riya Sudhakar Salian, Sandeep K. S. Gupta<br>for: 这个论文是为了研究在 integrate  wireless mobile networks 和人在loop （HIL）和人在plant （HIP）physical systems 下的非线性simulation 问题。methods: 该论文使用了分割时间变化Component的方法（PLIS），将其分解成多个Interval中的固定时间点，然后将这些Interval concatenated 在时间域中。results: 研究发现PLIS方法可以带来大于2.1倍的速度提升，并且保证了 simulations 的准确性。<details>
<summary>Abstract</summary>
Non-linearities in simulation arise from the time variance in wireless mobile networks when integrated with human in the loop, human in the plant (HIL-HIP) physical systems under dynamic contexts, leading to simulation slowdown. Time variance is handled by deriving a series of piece wise linear time invariant simulations (PLIS) in intervals, which are then concatenated in time domain. In this paper, we conduct a formal analysis of the impact of discretizing time-varying components in wireless network-controlled HIL-HIP systems on simulation accuracy and speedup, and evaluate trade-offs with reliable guarantees. We develop an accurate simulation framework for an artificial pancreas wireless network system that controls blood glucose in Type 1 Diabetes patients with time varying properties such as physiological changes associated with psychological stress and meal patterns. PLIS approach achieves accurate simulation with greater than 2.1 times speedup than a non-linear system simulation for the given dataset.
</details>
<details>
<summary>摘要</summary>
非线性在模拟中来自无线移动网络与人loop（HIL-HIP）物理系统的时间变化下出现，导致模拟慢速。我们采取了分割时间变化的方法， derive a series of piece wise linear time invariant simulations（PLIS），然后将它们 concatenated 在时域中。在这篇论文中，我们进行了正式的时间变化精度和速度的分析，并评估了可靠保证的交易。我们开发了一个准确的模拟框架，用于控制Type 1  диабеت斯 patients的血糖水平，该系统具有时变性特征，如生物physiological 变化和心理压力和饭 Patterns。PLIS 方法实现了更高于 2.1 倍的速度提升，而不 sacrifi 精度。
</details></li>
</ul>
<hr>
<h2 id="A-compendium-of-data-sources-for-data-science-machine-learning-and-artificial-intelligence"><a href="#A-compendium-of-data-sources-for-data-science-machine-learning-and-artificial-intelligence" class="headerlink" title="A compendium of data sources for data science, machine learning, and artificial intelligence"></a>A compendium of data sources for data science, machine learning, and artificial intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05682">http://arxiv.org/abs/2309.05682</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paul Bilokon, Oleksandr Bilokon, Saeed Amen</li>
<li>for: 提供数据科学、机器学习和人工智能领域的数据源列表，帮助数据科学家和机器学习专家在各个应用领域进行数据处理和分析。</li>
<li>methods: 列举了多个应用领域的数据源，包括金融和经济、法律（法律和规章）、生命科学（医学和药物发现）、新闻情感和社交媒体、零售和电商、卫星影像和运输和供应链，并提供了这些数据源的简要描述。</li>
<li>results: 提供了一个不完全的，但广泛的数据源列表，可以帮助数据科学家和机器学习专家在各个应用领域进行数据处理和分析。<details>
<summary>Abstract</summary>
Recent advances in data science, machine learning, and artificial intelligence, such as the emergence of large language models, are leading to an increasing demand for data that can be processed by such models. While data sources are application-specific, and it is impossible to produce an exhaustive list of such data sources, it seems that a comprehensive, rather than complete, list would still benefit data scientists and machine learning experts of all levels of seniority. The goal of this publication is to provide just such an (inevitably incomplete) list -- or compendium -- of data sources across multiple areas of applications, including finance and economics, legal (laws and regulations), life sciences (medicine and drug discovery), news sentiment and social media, retail and ecommerce, satellite imagery, and shipping and logistics, and sports.
</details>
<details>
<summary>摘要</summary>
Recent advances in数据科学、机器学习和人工智能，如大语言模型的出现，导致了对这些模型处理数据的需求的增加。虽然数据来源是应用程序特定的，但是无法制作完整的列表，但一份具体的列表仍然会对数据科学家和机器学习专家们有帮助。本文的目标是提供一个（必然不完整的）列表，涵盖多个领域的应用，包括金融和经济、法律（法律和规章）、生命科学（医学和药物发现）、新闻情感和社交媒体、零售和电商、卫星图像和运输和供应链，以及体育。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Aided-Subspace-Based-DOA-Recovery-for-Sparse-Arrays"><a href="#Deep-Learning-Aided-Subspace-Based-DOA-Recovery-for-Sparse-Arrays" class="headerlink" title="Deep Learning-Aided Subspace-Based DOA Recovery for Sparse Arrays"></a>Deep Learning-Aided Subspace-Based DOA Recovery for Sparse Arrays</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05109">http://arxiv.org/abs/2309.05109</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yoav Amiel, Dor H. Shmuel, Nir Shlezinger, Wasim Huleihel</li>
<li>for: 这项研究旨在开发一种基于深度学习的异常探测方法，以解决稀疏降噪数组中的方向探测问题。</li>
<li>methods: 该方法使用深度学习来学习一个专门的深度网络，以将数组中的异常信号分解成可分辨的子空间。</li>
<li>results: 该方法可以在稀疏降噪数组中处理听到的干扰信号，并且可以保持模型基于子空间方向探测器的解释性和适用性。<details>
<summary>Abstract</summary>
Sparse arrays enable resolving more direction of arrivals (DoAs) than antenna elements using non-uniform arrays. This is typically achieved by reconstructing the covariance of a virtual large uniform linear array (ULA), which is then processed by subspace DoA estimators. However, these method assume that the signals are non-coherent and the array is calibrated; the latter often challenging to achieve in sparse arrays, where one cannot access the virtual array elements. In this work, we propose Sparse-SubspaceNet, which leverages deep learning to enable subspace-based DoA recovery from sparse miscallibrated arrays with coherent sources. Sparse- SubspaceNet utilizes a dedicated deep network to learn from data how to compute a surrogate virtual array covariance that is divisible into distinguishable subspaces. By doing so, we learn to cope with coherent sources and miscalibrated sparse arrays, while preserving the interpretability and the suitability of model-based subspace DoA estimators.
</details>
<details>
<summary>摘要</summary>
稀疏数组可以解决更多的方向来源（DoAs）than antenna element using non-uniform arrays. 通常通过重建虚拟大 uniform linear array（ULA）的协方差来实现这一点，然后使用子空间DoA估计器进行处理。然而，这些方法假设信号是非几何的和数组是calibrated; 后者经常是稀疏数组中的挑战。在这种情况下，我们提出了Sparse-SubspaceNet，这是一种使用深度学习来实现基于subspace的DoA恢复从稀疏不calibrated数组中的几何源。Sparse-SubspaceNet使用专门的深度网络来学习从数据中如何计算一个可分解的虚拟数组协方差，这使得我们可以处理几何源和不calibrated稀疏数组，同时保持模型基于subspace DoA估计器的可读性和适用性。
</details></li>
</ul>
<hr>
<h2 id="AGent-A-Novel-Pipeline-for-Automatically-Creating-Unanswerable-Questions"><a href="#AGent-A-Novel-Pipeline-for-Automatically-Creating-Unanswerable-Questions" class="headerlink" title="AGent: A Novel Pipeline for Automatically Creating Unanswerable Questions"></a>AGent: A Novel Pipeline for Automatically Creating Unanswerable Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05103">http://arxiv.org/abs/2309.05103</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sonqt/agent-unanswerable">https://github.com/sonqt/agent-unanswerable</a></li>
<li>paper_authors: Son Quoc Tran, Gia-Huy Do, Phong Nguyen-Thuan Do, Matt Kretchmar, Xinya Du</li>
<li>for: 提高Extractive Question Answering（EQA）领域中模型的性能，通过自动生成无法回答的问题来训练EQA模型，以避免模型提取错误或不正确的答案。</li>
<li>methods: 提出AGent管道，通过重新匹配问题与缺乏必要信息的上下文来自动生成无法回答的问题。</li>
<li>results: 通过使用AGent管道生成的无法回答问题，训练EQA模型可以达到与使用SQuAD 2.0 dataset的性能相似的水平。<details>
<summary>Abstract</summary>
The development of large high-quality datasets and high-performing models have led to significant advancements in the domain of Extractive Question Answering (EQA). This progress has sparked considerable interest in exploring unanswerable questions within the EQA domain. Training EQA models with unanswerable questions helps them avoid extracting misleading or incorrect answers for queries that lack valid responses. However, manually annotating unanswerable questions is labor-intensive. To address this, we propose AGent, a novel pipeline that automatically creates new unanswerable questions by re-matching a question with a context that lacks the necessary information for a correct answer. In this paper, we demonstrate the usefulness of this AGent pipeline by creating two sets of unanswerable questions from answerable questions in SQuAD and HotpotQA. These created question sets exhibit low error rates. Additionally, models fine-tuned on these questions show comparable performance with those fine-tuned on the SQuAD 2.0 dataset on multiple EQA benchmarks.
</details>
<details>
<summary>摘要</summary>
<<SYS>>大量高质量数据和高性能模型的发展对提取问题回答领域（EQA）带来了重要进步，这些进步引起了对不可回答问题的探索的广泛关注。通过训练EQA模型使用不可回答问题，可以帮助这些模型避免提取错误或 incomplete 答案。然而，手动标注不可回答问题是劳动密集的。为解决这个问题，我们提出了AGent管道，一种新的管道，可以自动生成新的不可回答问题，通过重新匹配一个问题与缺乏必要信息的上下文。在这篇论文中，我们示出了AGent管道的有用性，通过将answerable questions转换成不可回答问题，并创造了两个不可回答问题集，其错误率较低。此外，基于这些问题进行了 fine-tuning，模型在多个 EQA 测试上表现相当。[/INST  Sure, here's the translation of the text into Simplified Chinese:大量高质量数据和高性能模型的发展对提取问题回答领域（EQA）带来了重要进步，这些进步引起了对不可回答问题的探索的广泛关注。通过训练EQA模型使用不可回答问题，可以帮助这些模型避免提取错误或 incomplete 答案。然而，手动标注不可回答问题是劳动密集的。为解决这个问题，我们提出了AGent管道，一种新的管道，可以自动生成新的不可回答问题，通过重新匹配一个问题与缺乏必要信息的上下文。在这篇论文中，我们示出了AGent管道的有用性，通过将answerable questions转换成不可回答问题，并创造了两个不可回答问题集，其错误率较低。此外，基于这些问题进行了 fine-tuning，模型在多个 EQA 测试上表现相当。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Social-Choice-Mechanisms-for-Recommendation-Fairness-in-SCRUF"><a href="#Exploring-Social-Choice-Mechanisms-for-Recommendation-Fairness-in-SCRUF" class="headerlink" title="Exploring Social Choice Mechanisms for Recommendation Fairness in SCRUF"></a>Exploring Social Choice Mechanisms for Recommendation Fairness in SCRUF</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08621">http://arxiv.org/abs/2309.08621</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/that-recsys-lab/scruf_facctrec_2023">https://github.com/that-recsys-lab/scruf_facctrec_2023</a></li>
<li>paper_authors: Amanda Aird, Cassidy All, Paresha Farastu, Elena Stefancova, Joshua Sun, Nicholas Mattei, Robin Burke</li>
<li>for: 这篇论文主要针对的是推荐系统中的公平问题，具体来说是多个公平关注者之间的矛盾和讨论。</li>
<li>methods: 该论文使用社会选择理论来形式化和解决公平问题，并考虑了多种选择机制和分配方式来处理多个公平关注者之间的矛盾。</li>
<li>results: 该论文通过使用实际和synthetic数据进行实验，发现不同的选择机制和分配方式会导致不同的公平精度和准确率之间的权衡。此外，该论文还表明了多个代理人形式ulation的灵活性，可以适应用户人口动态变化。<details>
<summary>Abstract</summary>
Fairness problems in recommender systems often have a complexity in practice that is not adequately captured in simplified research formulations. A social choice formulation of the fairness problem, operating within a multi-agent architecture of fairness concerns, offers a flexible and multi-aspect alternative to fairness-aware recommendation approaches. Leveraging social choice allows for increased generality and the possibility of tapping into well-studied social choice algorithms for resolving the tension between multiple, competing fairness concerns. This paper explores a range of options for choice mechanisms in multi-aspect fairness applications using both real and synthetic data and shows that different classes of choice and allocation mechanisms yield different but consistent fairness / accuracy tradeoffs. We also show that a multi-agent formulation offers flexibility in adapting to user population dynamics.
</details>
<details>
<summary>摘要</summary>
“具有多元 fairness 需求的推荐系统问题通常在实际应用中具有复杂性，不充分被研究形式化的研究所能够捕捉。使用社会选择形式ulation的 fairness 问题，在多代理oki的公平关注架构中运作，提供了一个洒脱的多方面替代方案。利用社会选择可以提高通用性和可以将多元公平 Concerns 转化为已经学习的社会选择算法来解决多元公平 Concerns 之间的紧张关系。本文将评估不同的选择和分配机制在多元公平应用中的效果，包括使用实际和 sintetic 数据，并显示出不同类型的选择和分配机制在公平率 / 准确度贸易中产生不同的但是一致的变化。我们还示出了多代理oki 形式的洒脱性，可以适应用户人口动态。”Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Variance-Reduction-of-Resampling-for-Sequential-Monte-Carlo"><a href="#Variance-Reduction-of-Resampling-for-Sequential-Monte-Carlo" class="headerlink" title="Variance Reduction of Resampling for Sequential Monte Carlo"></a>Variance Reduction of Resampling for Sequential Monte Carlo</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.08620">http://arxiv.org/abs/2309.08620</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/986876245/variance-reduction-for-smc">https://github.com/986876245/variance-reduction-for-smc</a></li>
<li>paper_authors: Xiongming Dai, Gerald Baumgartner</li>
<li>for: 这篇论文是为了提出一种统计重点抽样方法，来替代低重量粒子的MCMC方法，以更快速地和更精确地描述隐藏Markov过程。</li>
<li>methods: 本论文使用了一种重复决定域法，并且使用中值ergodicity来进行抽样。</li>
<li>results: 研究发现，这种方法可以在非线性情况下更快速地和更精确地描述隐藏Markov过程，并且可以降低样本变化的方差。<details>
<summary>Abstract</summary>
A resampling scheme provides a way to switch low-weight particles for sequential Monte Carlo with higher-weight particles representing the objective distribution. The less the variance of the weight distribution is, the more concentrated the effective particles are, and the quicker and more accurate it is to approximate the hidden Markov model, especially for the nonlinear case. We propose a repetitive deterministic domain with median ergodicity for resampling and have achieved the lowest variances compared to the other resampling methods. As the size of the deterministic domain $M\ll N$ (the size of population), given a feasible size of particles, our algorithm is faster than the state of the art, which is verified by theoretical deduction and experiments of a hidden Markov model in both the linear and non-linear cases.
</details>
<details>
<summary>摘要</summary>
一种重采样方案可以将低权重粒子换为顺序 Monte Carlo 中的高权重粒子，表示目标分布。当 variance 的低时，粒子的效果更集中，更快速地 aproximate 隐藏 Markov 模型，特别是非线性情况。我们提议一种循环决定的 deterministic Domain  WITH median 征求，并实现了最低的方差。当 $M\ll N$ (人口大小)，给定可行的粒子大小，我们的算法比现状慢，经过了逻辑推导和隐藏 Markov 模型在线性和非线性情况下的实验验证。
</details></li>
</ul>
<hr>
<h2 id="Neural-Hidden-CRF-A-Robust-Weakly-Supervised-Sequence-Labeler"><a href="#Neural-Hidden-CRF-A-Robust-Weakly-Supervised-Sequence-Labeler" class="headerlink" title="Neural-Hidden-CRF: A Robust Weakly-Supervised Sequence Labeler"></a>Neural-Hidden-CRF: A Robust Weakly-Supervised Sequence Labeler</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05086">http://arxiv.org/abs/2309.05086</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/junchenzhi/neural-hidden-crf">https://github.com/junchenzhi/neural-hidden-crf</a></li>
<li>paper_authors: Zhijun Chen, Hailong Sun, Wanhao Zhang, Chunyi Xu, Qianren Mao, Pengpeng Chen</li>
<li>for: 解决弱监督序列标签问题</li>
<li>methods: 使用神经网络隐藏CRF层模型word序列、隐藏真实标签序列和弱标签序列的变量，并利用全球视角来模型这些变量</li>
<li>results: 在一个人工智能 benchmark 和三个弱监督 benchmark 上达到新的状态对应记录，包括在一般化和推理性能中超过最近的进步模型CHMM的2.80 F1点和2.23 F1点。<details>
<summary>Abstract</summary>
We propose a neuralized undirected graphical model called Neural-Hidden-CRF to solve the weakly-supervised sequence labeling problem. Under the umbrella of probabilistic undirected graph theory, the proposed Neural-Hidden-CRF embedded with a hidden CRF layer models the variables of word sequence, latent ground truth sequence, and weak label sequence with the global perspective that undirected graphical models particularly enjoy. In Neural-Hidden-CRF, we can capitalize on the powerful language model BERT or other deep models to provide rich contextual semantic knowledge to the latent ground truth sequence, and use the hidden CRF layer to capture the internal label dependencies. Neural-Hidden-CRF is conceptually simple and empirically powerful. It obtains new state-of-the-art results on one crowdsourcing benchmark and three weak-supervision benchmarks, including outperforming the recent advanced model CHMM by 2.80 F1 points and 2.23 F1 points in average generalization and inference performance, respectively.
</details>
<details>
<summary>摘要</summary>
我们提出了一种含有隐藏CRF层的神经网络模型，称为神经隐藏CRF，用于解决弱监督序列标签问题。在概率无向图论下，神经隐藏CRF模型了 palabras序列、隐藏真实序列和弱标签序列的变量，并且具有全局视角，特别是无向图论中的优势。在神经隐藏CRF中，我们可以利用深度语言模型BERT或其他深度模型提供丰富的语义知识来隐藏真实序列，并使用隐藏CRF层捕捉内部标签依赖关系。神经隐藏CRF的概念简单，实际强大。它在一个人工智能投票 benchmark和三个弱监督 benchmark 上取得了新的状态理论最佳结果，包括在平均总体化和推理性能方面比最近的高级模型CHMM高2.80个F1分和2.23个F1分。
</details></li>
</ul>
<hr>
<h2 id="An-Appraisal-Based-Chain-Of-Emotion-Architecture-for-Affective-Language-Model-Game-Agents"><a href="#An-Appraisal-Based-Chain-Of-Emotion-Architecture-for-Affective-Language-Model-Game-Agents" class="headerlink" title="An Appraisal-Based Chain-Of-Emotion Architecture for Affective Language Model Game Agents"></a>An Appraisal-Based Chain-Of-Emotion Architecture for Affective Language Model Game Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05076">http://arxiv.org/abs/2309.05076</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maximilian Croissant, Madeleine Frister, Guy Schofield, Cade McCall</li>
<li>for: 这项研究旨在解决人工智能代理人的可信度、自然性和互动性等领域中的一些挑战，具体来说是开发一种能够模拟人类情感的人工智能代理人。</li>
<li>methods: 这项研究采用了大型自然语言模型（LLM），通过挖掘情境评估中的共同模式来解决情感智能任务，并在视频游戏中测试了一种新的情感链架架构。</li>
<li>results: 研究结果表明，新的情感链架架构在用户体验和内容分析等方面的多个指标上表现出色，比标准LLM架构更高效。这项研究因此提供了在基于语言模型的认知过程中构建和测试情感代理人的初始证据。<details>
<summary>Abstract</summary>
The development of believable, natural, and interactive digital artificial agents is a field of growing interest. Theoretical uncertainties and technical barriers present considerable challenges to the field, particularly with regards to developing agents that effectively simulate human emotions. Large language models (LLMs) might address these issues by tapping common patterns in situational appraisal. In three empirical experiments, this study tests the capabilities of LLMs to solve emotional intelligence tasks and to simulate emotions. It presents and evaluates a new chain-of-emotion architecture for emotion simulation within video games, based on psychological appraisal research. Results show that it outperforms standard LLM architectures on a range of user experience and content analysis metrics. This study therefore provides early evidence of how to construct and test affective agents based on cognitive processes represented in language models.
</details>
<details>
<summary>摘要</summary>
随着人工智能技术的不断发展，开发可信、自然、互动的数字人工智能代理人也成为了一项快速增长的领域。然而，许多理论上的不确定性和技术难题使得该领域面临着很大的挑战，尤其是在模拟人类情感方面。大语言模型（LLM）可能可以解决这些问题，通过捕捉情境评估中的共同模式。本研究通过三个实验测试了LLM在情感智能任务中的能力，以及它们在视频游戏中的情感模拟能力。结果表明，我们的新的情感链架系统在用户体验和内容分析指标上表现出色，比标准LLM架构更高效。这项研究因此为构建和测试基于语言模型的情感代理人提供了早期的证据。
</details></li>
</ul>
<hr>
<h2 id="Chebyshev-Particles"><a href="#Chebyshev-Particles" class="headerlink" title="Chebyshev Particles"></a>Chebyshev Particles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06373">http://arxiv.org/abs/2309.06373</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/986876245/chebyshevparticles">https://github.com/986876245/chebyshevparticles</a></li>
<li>paper_authors: Xiongming Dai, Gerald Baumgartner</li>
<li>for: 这个论文主要用于推断隐藏马尔可夫模型（Hidden Markov Model，HMM）的参数，尤其是在维度约束的情况下，where the Monte Carlo sampler struggles with the curse of dimensionality.</li>
<li>methods: 该论文提出了一种新的 критерий，即最大化权重的里茨卷积量（weighted Riesz polarization quantity），来精确地拟合 rectifiable submanifolds，并通过对互相互动的pairwise interaction来离散化。</li>
<li>results: 该论文通过实验表明，在一个线性加 Gaussian state-space模型（Linear Gaussian state-space model，LGSSM）中的参数推断和一个非线性随机抖动模型（Non-linear stochastic volatility model，NLSM）中的参数推断都能够达到高性能。<details>
<summary>Abstract</summary>
Markov chain Monte Carlo (MCMC) provides a feasible method for inferring Hidden Markov models, however, it is often computationally prohibitive, especially constrained by the curse of dimensionality, as the Monte Carlo sampler traverses randomly taking small steps within uncertain regions in the parameter space. We are the first to consider the posterior distribution of the objective as a mapping of samples in an infinite-dimensional Euclidean space where deterministic submanifolds are embedded and propose a new criterion by maximizing the weighted Riesz polarization quantity, to discretize rectifiable submanifolds via pairwise interaction. We study the characteristics of Chebyshev particles and embed them into sequential MCMC, a novel sampler with a high acceptance ratio that proposes only a few evaluations. We have achieved high performance from the experiments for parameter inference in a linear Gaussian state-space model with synthetic data and a non-linear stochastic volatility model with real-world data.
</details>
<details>
<summary>摘要</summary>
Markerov链 Монте Carlo（MCMC）提供了一种可行的方法来推断隐藏Markov模型，但是它常常由尺度约束所困，尤其是在维度约束的咒语下，MCMC抽样器在参数空间中随机漫步，难以在不确定的区域中进行准确的步长。我们是第一个考虑 posterior Distribution 作为抽象空间中的样本映射，并提出了一新的 критерий，通过最大化均值拓扑量的weighted Riesz polarization量来离散可导的子拓扑。我们研究了Chebychev particles的特点并将其集成到顺序MCMC中，一种新的抽样器，它的接受率很高，只需要少量的评估。我们通过实验表明，这种方法在Linear Gaussian state-space model中进行参数推断时可以 дости得高性能，并在非线性抽象噪声模型中进行参数推断时也能够达到高性能。
</details></li>
</ul>
<hr>
<h2 id="Spatiotemporal-Graph-Neural-Networks-with-Uncertainty-Quantification-for-Traffic-Incident-Risk-Prediction"><a href="#Spatiotemporal-Graph-Neural-Networks-with-Uncertainty-Quantification-for-Traffic-Incident-Risk-Prediction" class="headerlink" title="Spatiotemporal Graph Neural Networks with Uncertainty Quantification for Traffic Incident Risk Prediction"></a>Spatiotemporal Graph Neural Networks with Uncertainty Quantification for Traffic Incident Risk Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05072">http://arxiv.org/abs/2309.05072</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sttdanonymous/sttd">https://github.com/sttdanonymous/sttd</a></li>
<li>paper_authors: Xiaowei Gao, Xinke Jiang, Dingyi Zhuang, Huanfa Chen, Shenhao Wang, James Haworth</li>
<li>for: 预测交通事故风险在细致时空层面是一项挑战。现有数据主要具有零值，表示没有事故，而 occasional high-risk values 表示严重事故。现有大多数模型， especial deep learning methods, 强调估计风险值，忽视因事故本身具有不可预测性而产生的uncertainty。</li>
<li>methods: 我们引入了Spatiotemporal Zero-Inflated Tweedie Graph Neural Networks (STZITD-GNNs) 模型，这种模型结合了传统统计模型的可靠性和图神经网络的灵活性，以准确量化交通事故风险的不确定性。该模型采用了Tweedie家族中的复合模型，其中Poisson分布模型了风险频率，而Gamma分布做了事故严重程度的衡量。此外，zero-inflated组成部分帮助确定非事故风险enario。</li>
<li>results: 实验结果表明，STZITD-GNNs 模型在使用英国伦敦实际交通数据时，不仅在精度方面超越了目前的标准准则，而且在短（7天）和长（14天）时间尺度上都能够提供稳定和可靠的预测结果。STZITD-GNNs 模型的优势不仅在于准确性，还在于能够减少不确定性，从而提供更加可靠的预测结果。<details>
<summary>Abstract</summary>
Predicting traffic incident risks at granular spatiotemporal levels is challenging. The datasets predominantly feature zero values, indicating no incidents, with sporadic high-risk values for severe incidents. Notably, a majority of current models, especially deep learning methods, focus solely on estimating risk values, overlooking the uncertainties arising from the inherently unpredictable nature of incidents. To tackle this challenge, we introduce the Spatiotemporal Zero-Inflated Tweedie Graph Neural Networks (STZITD-GNNs). Our model merges the reliability of traditional statistical models with the flexibility of graph neural networks, aiming to precisely quantify uncertainties associated with road-level traffic incident risks. This model strategically employs a compound model from the Tweedie family, as a Poisson distribution to model risk frequency and a Gamma distribution to account for incident severity. Furthermore, a zero-inflated component helps to identify the non-incident risk scenarios. As a result, the STZITD-GNNs effectively capture the dataset's skewed distribution, placing emphasis on infrequent but impactful severe incidents. Empirical tests using real-world traffic data from London, UK, demonstrate that our model excels beyond current benchmarks. The forte of STZITD-GNN resides not only in its accuracy but also in its adeptness at curtailing uncertainties, delivering robust predictions over short (7 days) and extended (14 days) timeframes.
</details>
<details>
<summary>摘要</summary>
预测路网冲击风险在精度空间时间层面是一项挑战。数据主要具有零值，表示没有事故，其中间间有极高风险值的严重事故。现有大多数模型，特别是深度学习方法，偏向仅仅估计风险值，忽视了事故的不可预测性。为了解决这个挑战，我们介绍了空间时间零值 Tweedie 图 neural network（STZITD-GNN）。我们的模型结合了传统统计模型的可靠性和图神经网络的灵活性，以准确量化道路层次交通事故的不确定性。我们的模型采用 Tweedie 家族中的复合模型，其中 Poisson 分布模型风险频率，而 Gamma 分布模型考虑事故严重程度。此外，零值填充部分帮助分辨非事故风险场景。因此，STZITD-GNN 能够准确地捕捉数据的极向分布，强调罕见但具有深远影响的严重事故。我们对实际的伦敦交通数据进行了 empirical 测试，发现我们的模型在短（7天）和长（14天）时间层面上都能够超越当前标准。STZITD-GNN 的 forte 不仅在准确性方面，还在减少不确定性方面，在短时间和长时间层面上都能够提供可靠的预测。
</details></li>
</ul>
<hr>
<h2 id="Chasing-the-Intruder-A-Reinforcement-Learning-Approach-for-Tracking-Intruder-Drones"><a href="#Chasing-the-Intruder-A-Reinforcement-Learning-Approach-for-Tracking-Intruder-Drones" class="headerlink" title="Chasing the Intruder: A Reinforcement Learning Approach for Tracking Intruder Drones"></a>Chasing the Intruder: A Reinforcement Learning Approach for Tracking Intruder Drones</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05070">http://arxiv.org/abs/2309.05070</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shivam Kainth, Subham Sahoo, Rajtilak Pal, Shashi Shekhar Jha</li>
<li>for: 这篇论文是用来解决非法用探空机采用探空机跟踪攻击者探空机的问题的。</li>
<li>methods: 该论文提出了一种基于Policy学习的探空机跟踪方法，利用计算机视觉技术和Policy学习框架来学习控制策略，实现探空机跟踪攻击者探空机。</li>
<li>results: 实验结果表明，提出的方法可以快速和精准地识别和跟踪攻击者探空机，并且对攻击者探空机的速度或方向变化具有弹性性。<details>
<summary>Abstract</summary>
Drones are becoming versatile in a myriad of applications. This has led to the use of drones for spying and intruding into the restricted or private air spaces. Such foul use of drone technology is dangerous for the safety and security of many critical infrastructures. In addition, due to the varied low-cost design and agility of the drones, it is a challenging task to identify and track them using the conventional radar systems. In this paper, we propose a reinforcement learning based approach for identifying and tracking any intruder drone using a chaser drone. Our proposed solution uses computer vision techniques interleaved with the policy learning framework of reinforcement learning to learn a control policy for chasing the intruder drone. The whole system has been implemented using ROS and Gazebo along with the Ardupilot based flight controller. The results show that the reinforcement learning based policy converges to identify and track the intruder drone. Further, the learnt policy is robust with respect to the change in speed or orientation of the intruder drone.
</details>
<details>
<summary>摘要</summary>
随着无人机在各种应用中的普及，无人机也开始用于间谍和非法进入受限或私人空域。这种不良使用无人机技术会对多个关键基础设施的安全和安全造成威胁。此外，由于无人机的多样化低成本设计和机敏性，使用传统雷达系统识别和跟踪它们是一项困难的任务。在这篇论文中，我们提出了基于Policy学习框架的强化学习方法，用于识别和跟踪任何非法无人机。我们的提议的解决方案使用计算机视觉技术与Policy学习框架结合，以学习控制策略，追踪非法无人机。整个系统使用ROS和Gazebo以及Ardupilot基于飞行控制器。实验结果表明，强化学习基于策略 converges to识别和跟踪非法无人机。此外，学习的策略还具有对速度或方向变化的robust性。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-Incentive-Mechanism-under-Buyers’-Auction-Market"><a href="#Federated-Learning-Incentive-Mechanism-under-Buyers’-Auction-Market" class="headerlink" title="Federated Learning Incentive Mechanism under Buyers’ Auction Market"></a>Federated Learning Incentive Mechanism under Buyers’ Auction Market</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05063">http://arxiv.org/abs/2309.05063</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxi Yang, Zihao Guo, Sheng Cao, Cuifang Zhao, Li-Chuan Tsai</li>
<li>For: 本文探讨了基于拍卖的联合学习（AFL）如何在开放合作环境下实现数据拥有者和数据消费者之间的协作。* Methods: 本文采用了基于拍卖的订单框架，以解释在买家市场下的价格行为。文中还使用了一种基于区块链的声誉机制，以选择具有高可靠性和数据质量的客户端。* Results: 实验结果证明了我们的方法的有效性。<details>
<summary>Abstract</summary>
Auction-based Federated Learning (AFL) enables open collaboration among self-interested data consumers and data owners. Existing AFL approaches are commonly under the assumption of sellers' market in that the service clients as sellers are treated as scarce resources so that the aggregation servers as buyers need to compete the bids. Yet, as the technology progresses, an increasing number of qualified clients are now capable of performing federated learning tasks, leading to shift from sellers' market to a buyers' market. In this paper, we shift the angle by adapting the procurement auction framework, aiming to explain the pricing behavior under buyers' market. Our modeling starts with basic setting under complete information, then move further to the scenario where sellers' information are not fully observable. In order to select clients with high reliability and data quality, and to prevent from external attacks, we utilize a blockchain-based reputation mechanism. The experimental results validate the effectiveness of our approach.
</details>
<details>
<summary>摘要</summary>
价格赢 Auction-based Federated Learning (AFL) 可以实现开放合作 among self-interested data consumers 和数据所有者。现有的 AFL 方法通常假设出售方为稀缺资源，因此整合服务器需要竞标。然而，技术的进步使得更多的资格客户可以执行联邦学习任务，导致市场的转变。在这篇论文中，我们将Angleshift towards buyers' market。我们采用了基于 blockchain 的声誉机制来选择可靠的客户和数据质量。实验结果证明了我们的方法的有效性。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-for-maximizing-the-memristivity-of-single-and-coupled-quantum-memristors"><a href="#Machine-Learning-for-maximizing-the-memristivity-of-single-and-coupled-quantum-memristors" class="headerlink" title="Machine Learning for maximizing the memristivity of single and coupled quantum memristors"></a>Machine Learning for maximizing the memristivity of single and coupled quantum memristors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05062">http://arxiv.org/abs/2309.05062</a></li>
<li>repo_url: None</li>
<li>paper_authors: Carlos Hernani-Morales, Gabriel Alvarado, Francisco Albarrán-Arriagada, Yolanda Vives-Gilabert, Enrique Solano, José D. Martín-Guerrero</li>
<li>for: 用机器学习方法描述单个和连接的量子幂istor的幂istor性质。</li>
<li>methods: 使用机器学习方法来描述单个和连接的量子幂istor的幂istor性质。</li>
<li>results: 结果表明，通过增加幂istor性，可以获得两个量子幂istor的高度相关性，从而证明了量子幂istor与记忆之间的密切关系。这些结果为量子幂istorneuromorphic量子计算提供了更多的可能性。<details>
<summary>Abstract</summary>
We propose machine learning (ML) methods to characterize the memristive properties of single and coupled quantum memristors. We show that maximizing the memristivity leads to large values in the degree of entanglement of two quantum memristors, unveiling the close relationship between quantum correlations and memory. Our results strengthen the possibility of using quantum memristors as key components of neuromorphic quantum computing.
</details>
<details>
<summary>摘要</summary>
我们提出机器学习（ML）方法来描述单个和连接的量子幂istor的幂istor性质。我们发现通过提高幂istor性来获得两个量子幂istor的共聚能量，暴露出量子相关性和记忆之间的密切关系。我们的结果加强了使用量子幂istor作为神经omorphic量子计算的可能性。Note: The translation is done using Google Translate, and may not be perfect or entirely accurate.
</details></li>
</ul>
<hr>
<h2 id="Decolonial-AI-Alignment-Visesadharma-Argument-and-Artistic-Expression"><a href="#Decolonial-AI-Alignment-Visesadharma-Argument-and-Artistic-Expression" class="headerlink" title="Decolonial AI Alignment: Viśesadharma, Argument, and Artistic Expression"></a>Decolonial AI Alignment: Viśesadharma, Argument, and Artistic Expression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05030">http://arxiv.org/abs/2309.05030</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kush R. Varshney</li>
<li>for: 本研究旨在寻找一种去殖民化人工智能（AI）的方法，以适应不同文化和价值观的需求。</li>
<li>methods: 本研究提出了三个建议来减少AIAlignment中的殖民化影响：（1）改变基础道德哲学从西方哲学改为道德，（2）允许不同传统的论证和多元主义在Alignment技术中，（3）扩展价值观的 épistémologie beyond自然语言中的 instrucciones or commandments。</li>
<li>results: 本研究的提议可以帮助去殖民化AIAlignment，使其更适应不同文化和价值观的需求，并且可以增强AI的多样性和包容性。<details>
<summary>Abstract</summary>
Prior work has explicated the coloniality of artificial intelligence (AI) development and deployment. One process that that work has not engaged with much is alignment: the tuning of large language model (LLM) behavior to be in line with desired values based on fine-grained human feedback. In addition to other practices, colonialism has a history of altering the beliefs and values of colonized peoples; this history is recapitulated in current LLM alignment practices. We suggest that AI alignment be decolonialized using three proposals: (a) changing the base moral philosophy from Western philosophy to dharma, (b) permitting traditions of argument and pluralism in alignment technologies, and (c) expanding the epistemology of values beyond instructions or commandments given in natural language.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Shift the base moral philosophy from Western philosophy to dharma.2. Embrace diverse traditions of argument and pluralism in alignment technologies.3. Expand the epistemology of values beyond instructions or commandments given in natural language.By implementing these proposals, we can work towards decolonializing AI alignment and promoting more inclusive and culturally sensitive values in AI development.</details></li>
</ol>
<hr>
<h2 id="VoiceFlow-Efficient-Text-to-Speech-with-Rectified-Flow-Matching"><a href="#VoiceFlow-Efficient-Text-to-Speech-with-Rectified-Flow-Matching" class="headerlink" title="VoiceFlow: Efficient Text-to-Speech with Rectified Flow Matching"></a>VoiceFlow: Efficient Text-to-Speech with Rectified Flow Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05027">http://arxiv.org/abs/2309.05027</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiwei Guo, Chenpeng Du, Ziyang Ma, Xie Chen, Kai Yu</li>
<li>for: 提高 текст到语音synthesis的效率，替代传统的扩散模型。</li>
<li>methods: 提出了一种基于流匹配算法的语音模型，通过限制抽样步数，实现高质量的语音生成。</li>
<li>results: 对单和多话者 corpora进行主观和objective评估，显示了 VoiceFlow 的synthesis质量明显超过扩散模型。<details>
<summary>Abstract</summary>
Although diffusion models in text-to-speech have become a popular choice due to their strong generative ability, the intrinsic complexity of sampling from diffusion models harms their efficiency. Alternatively, we propose VoiceFlow, an acoustic model that utilizes a rectified flow matching algorithm to achieve high synthesis quality with a limited number of sampling steps. VoiceFlow formulates the process of generating mel-spectrograms into an ordinary differential equation conditional on text inputs, whose vector field is then estimated. The rectified flow technique then effectively straightens its sampling trajectory for efficient synthesis. Subjective and objective evaluations on both single and multi-speaker corpora showed the superior synthesis quality of VoiceFlow compared to the diffusion counterpart. Ablation studies further verified the validity of the rectified flow technique in VoiceFlow.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:尽管扩散模型在文本到语音转换中成为了流行的选择，但它们的内在复杂性使其效率受限。相反，我们提出了 VoiceFlow，一种使用矫正流匹配算法来实现高质量的合成。VoiceFlow将文本输入转换为mel-spectrogram的过程形式化为一个条件的ordinary differential equation，然后估算vector field。矫正流技术然后有效地平直 sampling 的轨迹，从而提高合成效率。对单个和多个说话者 corpora进行主观和 объектив评估表明，VoiceFlow的合成质量高于扩散对应部分。另外，ablation 研究进一步证明了矫正流技术在 VoiceFlow 中的有效性。
</details></li>
</ul>
<hr>
<h2 id="FOLLOWUPQG-Towards-Information-Seeking-Follow-up-Question-Generation"><a href="#FOLLOWUPQG-Towards-Information-Seeking-Follow-up-Question-Generation" class="headerlink" title="FOLLOWUPQG: Towards Information-Seeking Follow-up Question Generation"></a>FOLLOWUPQG: Towards Information-Seeking Follow-up Question Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05007">http://arxiv.org/abs/2309.05007</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yan Meng, Liangming Pan, Yixin Cao, Min-Yen Kan</li>
<li>for: 本研究旨在提供一个真实世界信息寻求续问生成任务 (FQG), 协助模型产生更深入的理解和更多的质问。</li>
<li>methods: 研究人员使用 Reddit 论坛提供的开放式问题和回答数据集 (FOLLOWUPQG)，并使用现有的问题生成模型来评估模型的效果。</li>
<li>results: 研究结果显示，现有的问题生成模型可以生成一些有用的续问，但与人类提出的问题相比，模型生成的问题较为简单和不具有高级认知功能。<details>
<summary>Abstract</summary>
Humans ask follow-up questions driven by curiosity, which reflects a creative human cognitive process. We introduce the task of real-world information-seeking follow-up question generation (FQG), which aims to generate follow-up questions seeking a more in-depth understanding of an initial question and answer. We construct FOLLOWUPQG, a dataset of over 3K real-world (initial question, answer, follow-up question) tuples collected from a Reddit forum providing layman-friendly explanations for open-ended questions. In contrast to existing datasets, questions in FOLLOWUPQG use more diverse pragmatic strategies to seek information, and they also show higher-order cognitive skills (such as applying and relating). We evaluate current question generation models on their efficacy for generating follow-up questions, exploring how to generate specific types of follow-up questions based on step-by-step demonstrations. Our results validate FOLLOWUPQG as a challenging benchmark, as model-generated questions are adequate but far from human-raised questions in terms of informativeness and complexity.
</details>
<details>
<summary>摘要</summary>
人类会提出续问，这反映了人类的创新性思维过程。我们介绍了实际世界信息寻求续问生成任务（FQG），该任务的目标是生成更深入理解初始问题和答案的续问。我们构建了FOLLOWUPQG数据集，包含了超过3000个实际世界（初始问题、答案、续问）元组，这些元组来自一个基于Reddit社区的讨论平台，提供了对开放问题的便捷描述。与现有数据集不同，FOLLOWUPQG中的问题使用更多的 Pragmatic 策略来寻求信息，同时也表现出更高一级的认知技能（如应用和关系）。我们对当前问题生成模型进行评估，explore如何基于步骤示例来生成特定类型的续问。我们的结果证明 FOLLOWUPQG 是一个具有挑战性的标准，因为模型生成的问题具有充足的信息和复杂性，但与人类提出的问题相比，它们仍然有一定的差距。
</details></li>
</ul>
<hr>
<h2 id="RGAT-A-Deeper-Look-into-Syntactic-Dependency-Information-for-Coreference-Resolution"><a href="#RGAT-A-Deeper-Look-into-Syntactic-Dependency-Information-for-Coreference-Resolution" class="headerlink" title="RGAT: A Deeper Look into Syntactic Dependency Information for Coreference Resolution"></a>RGAT: A Deeper Look into Syntactic Dependency Information for Coreference Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04977">http://arxiv.org/abs/2309.04977</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qingtian5/rgat_with_bert">https://github.com/qingtian5/rgat_with_bert</a></li>
<li>paper_authors: Yuan Meng, Xuhao Pan, Jun Chang, Yue Wang</li>
<li>for: 这个论文主要研究了如何使用语法依赖关系图来解决核心引用解决问题。</li>
<li>methods: 该论文提出了一种结合预训练BERT和语法关系图注意力网络（RGAT）的终端解析器，以更深入地探究语法依赖关系图对核心引用解决问题的作用。RGAT模型首先被提出，然后用于理解语法依赖图并学习更好的任务特定语法嵌入。一个整合的建筑物 combining BERT嵌入和语法嵌入被构建，以生成融合表示 для下游任务。</li>
<li>results: 在一个公共的性别不确定 pronouns（GAP）数据集上的实验表明，在对语法依赖图的监督学习和不进行BERT全体调参的情况下，我们提高了之前最佳模型（RGCN-with-BERT）的F1分数从80.3%提高到82.5%，相比于单独使用BERT嵌入的F1分数从78.5%提高到82.5%。另一个公共的OntoNotes 5.0数据集上的实验结果也表明了模型的性能得到了改进。<details>
<summary>Abstract</summary>
Although syntactic information is beneficial for many NLP tasks, combining it with contextual information between words to solve the coreference resolution problem needs to be further explored. In this paper, we propose an end-to-end parser that combines pre-trained BERT with a Syntactic Relation Graph Attention Network (RGAT) to take a deeper look into the role of syntactic dependency information for the coreference resolution task. In particular, the RGAT model is first proposed, then used to understand the syntactic dependency graph and learn better task-specific syntactic embeddings. An integrated architecture incorporating BERT embeddings and syntactic embeddings is constructed to generate blending representations for the downstream task. Our experiments on a public Gendered Ambiguous Pronouns (GAP) dataset show that with the supervision learning of the syntactic dependency graph and without fine-tuning the entire BERT, we increased the F1-score of the previous best model (RGCN-with-BERT) from 80.3% to 82.5%, compared to the F1-score by single BERT embeddings from 78.5% to 82.5%. Experimental results on another public dataset - OntoNotes 5.0 demonstrate that the performance of the model is also improved by incorporating syntactic dependency information learned from RGAT.
</details>
<details>
<summary>摘要</summary>
�although syntactic information is beneficial for many NLP tasks, combining it with contextual information between words to solve the coreference resolution problem needs to be further explored. In this paper, we propose an end-to-end parser that combines pre-trained BERT with a Syntactic Relation Graph Attention Network (RGAT) to take a deeper look into the role of syntactic dependency information for the coreference resolution task. In particular, the RGAT model is first proposed, then used to understand the syntactic dependency graph and learn better task-specific syntactic embeddings. An integrated architecture incorporating BERT embeddings and syntactic embeddings is constructed to generate blending representations for the downstream task. Our experiments on a public Gendered Ambiguous Pronouns (GAP) dataset show that with the supervision learning of the syntactic dependency graph and without fine-tuning the entire BERT, we increased the F1-score of the previous best model (RGCN-with-BERT) from 80.3% to 82.5%, compared to the F1-score by single BERT embeddings from 78.5% to 82.5%. Experimental results on another public dataset - OntoNotes 5.0 demonstrate that the performance of the model is also improved by incorporating syntactic dependency information learned from RGAT.Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="AVARS-–-Alleviating-Unexpected-Urban-Road-Traffic-Congestion-using-UAVs"><a href="#AVARS-–-Alleviating-Unexpected-Urban-Road-Traffic-Congestion-using-UAVs" class="headerlink" title="AVARS – Alleviating Unexpected Urban Road Traffic Congestion using UAVs"></a>AVARS – Alleviating Unexpected Urban Road Traffic Congestion using UAVs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04976">http://arxiv.org/abs/2309.04976</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/guojyjy/avars">https://github.com/guojyjy/avars</a></li>
<li>paper_authors: Jiaying Guo, Michael R. Jones, Soufiene Djahel, Shen Wang</li>
<li>for: 实时监控交通流量并快速采取适当的交通信号控制措施，以减少城市快速几何化交通堵塞。</li>
<li>methods: 使用深度强化学习（DRL）算法控制交通信号灯，并运用无人机（UAV）实时监控交通流量提供高频高分辨率的交通数据。</li>
<li>results: 透过AVARS系统，可以实现快速对应未预期的交通堵塞，并将交通流量回复到原本的不堵塞状态，而且可以在一般无人机的电池寿命 duration 内完成。<details>
<summary>Abstract</summary>
Reducing unexpected urban traffic congestion caused by en-route events (e.g., road closures, car crashes, etc.) often requires fast and accurate reactions to choose the best-fit traffic signals. Traditional traffic light control systems, such as SCATS and SCOOT, are not efficient as their traffic data provided by induction loops has a low update frequency (i.e., longer than 1 minute). Moreover, the traffic light signal plans used by these systems are selected from a limited set of candidate plans pre-programmed prior to unexpected events' occurrence. Recent research demonstrates that camera-based traffic light systems controlled by deep reinforcement learning (DRL) algorithms are more effective in reducing traffic congestion, in which the cameras can provide high-frequency high-resolution traffic data. However, these systems are costly to deploy in big cities due to the excessive potential upgrades required to road infrastructure. In this paper, we argue that Unmanned Aerial Vehicles (UAVs) can play a crucial role in dealing with unexpected traffic congestion because UAVs with onboard cameras can be economically deployed when and where unexpected congestion occurs. Then, we propose a system called "AVARS" that explores the potential of using UAVs to reduce unexpected urban traffic congestion using DRL-based traffic light signal control. This approach is validated on a widely used open-source traffic simulator with practical UAV settings, including its traffic monitoring ranges and battery lifetime. Our simulation results show that AVARS can effectively recover the unexpected traffic congestion in Dublin, Ireland, back to its original un-congested level within the typical battery life duration of a UAV.
</details>
<details>
<summary>摘要</summary>
红色减少意外城市堵塞需要快速准确的反应选择最佳的交通信号控制。传统的交通信号控制系统，如SCATS和SCOOT，不是高效的，因为它们的交通数据由感测器提供，更新频率较低（大于1分钟）。此外，这些系统使用的交通信号信息是从先前定义的候选计划中选择的，无法适应意外事件的发生。当前的研究表明，基于深度优化学习（DRL）算法控制的摄像头交通信号系统更有效地减少交通堵塞。然而，这些系统在大城市部署时需要昂贵的基础设施升级。在这篇论文中，我们提出了使用无人机（UAV）来解决意外交通堵塞的想法。我们认为UAV可以在意外堵塞发生时经济性地部署，并使用摄像头提供高频高分辨率的交通数据。然后，我们提出了一个名为“AVARS”的系统，该系统使用DRL算法控制UAV摄像头提供的交通数据，以减少意外城市堵塞。我们使用一个广泛使用的开源交通模拟器进行了实验，并模拟了实际的UAV设置，包括交通监测范围和电池寿命。我们的实验结果表明，AVARS可以在都柏林、爱尔兰 effectively recovery意外交通堵塞，并在UAV的Typical电池寿命内恢复到原始无堵塞水平。
</details></li>
</ul>
<hr>
<h2 id="Continual-Robot-Learning-using-Self-Supervised-Task-Inference"><a href="#Continual-Robot-Learning-using-Self-Supervised-Task-Inference" class="headerlink" title="Continual Robot Learning using Self-Supervised Task Inference"></a>Continual Robot Learning using Self-Supervised Task Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04974">http://arxiv.org/abs/2309.04974</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Burhan Hafez, Stefan Wermter</li>
<li>for: 本研究旨在将机器人给予人类学习能力，即在生命途中不断学习多个技能。</li>
<li>methods: 本研究使用自我组织学习法，从观察运动和效果部分的自适应学习出动作和意图嵌入，以及从共同动作意图嵌入自适应学习出高级行为嵌入。</li>
<li>results: 本研究比较多种多任务学习基eline，在人工智能验证中表现出色，能够从不完整的示例中推理任务，并且在不断学习设定中表现更好。<details>
<summary>Abstract</summary>
Endowing robots with the human ability to learn a growing set of skills over the course of a lifetime as opposed to mastering single tasks is an open problem in robot learning. While multi-task learning approaches have been proposed to address this problem, they pay little attention to task inference. In order to continually learn new tasks, the robot first needs to infer the task at hand without requiring predefined task representations. In this paper, we propose a self-supervised task inference approach. Our approach learns action and intention embeddings from self-organization of the observed movement and effect parts of unlabeled demonstrations and a higher-level behavior embedding from self-organization of the joint action-intention embeddings. We construct a behavior-matching self-supervised learning objective to train a novel Task Inference Network (TINet) to map an unlabeled demonstration to its nearest behavior embedding, which we use as the task representation. A multi-task policy is built on top of the TINet and trained with reinforcement learning to optimize performance over tasks. We evaluate our approach in the fixed-set and continual multi-task learning settings with a humanoid robot and compare it to different multi-task learning baselines. The results show that our approach outperforms the other baselines, with the difference being more pronounced in the challenging continual learning setting, and can infer tasks from incomplete demonstrations. Our approach is also shown to generalize to unseen tasks based on a single demonstration in one-shot task generalization experiments.
</details>
<details>
<summary>摘要</summary>
<<SYS>>对于 робоット来说，授予它人类的学习能力，即在一生中不断学习多种技能，是一个打开的问题。虽然多任务学习方法有所提出，但它们对任务推理 pays little attention。为了不断学习新任务，首先需要由 robot 自动推理出当前任务，而不需要预定的任务表示。在这篇论文中，我们提出了一种自动任务推理方法。我们从无标示示例中自动学习动作和意图嵌入，以及高级行为嵌入。我们构建了一个行为匹配自我监督学习目标，用于训练一个新的任务推理网络（TINet），以将无标示示例映射到其最似的行为嵌入。基于 TINet 的多任务策略，我们使用强化学习训练，以优化任务表示的性能。我们在固定集和不断多任务学习设置中对我们的方法进行评估，并与不同的多任务学习基准进行比较。结果表明，我们的方法在不断学习设置中与其他基准之间的差异更加明显，并且可以从不完整的示例中推理任务。我们的方法还在一次任务扩展试验中被证明可以基于单个示例进行一次任务扩展。Note: The translation is done using Google Translate and may not be perfect. Please let me know if you need further assistance.
</details></li>
</ul>
<hr>
<h2 id="Prefix-diffusion-A-Lightweight-Diffusion-Model-for-Diverse-Image-Captioning"><a href="#Prefix-diffusion-A-Lightweight-Diffusion-Model-for-Diverse-Image-Captioning" class="headerlink" title="Prefix-diffusion: A Lightweight Diffusion Model for Diverse Image Captioning"></a>Prefix-diffusion: A Lightweight Diffusion Model for Diverse Image Captioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04965">http://arxiv.org/abs/2309.04965</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guisheng Liu, Yi Li, Zhengcong Fei, Haiyan Fu, Xiangyang Luo, Yanqing Guo</li>
<li>for: 提高图像描述的多样性和可靠性</li>
<li>methods: 使用轻量级图像描述网络和不间断填充方法</li>
<li>results: 实现多样化的图像描述，同时减少trainable参数数量<details>
<summary>Abstract</summary>
While impressive performance has been achieved in image captioning, the limited diversity of the generated captions and the large parameter scale remain major barriers to the real-word application of these systems. In this work, we propose a lightweight image captioning network in combination with continuous diffusion, called Prefix-diffusion. To achieve diversity, we design an efficient method that injects prefix image embeddings into the denoising process of the diffusion model. In order to reduce trainable parameters, we employ a pre-trained model to extract image features and further design an extra mapping network. Prefix-diffusion is able to generate diverse captions with relatively less parameters, while maintaining the fluency and relevance of the captions benefiting from the generative capabilities of the diffusion model. Our work paves the way for scaling up diffusion models for image captioning, and achieves promising performance compared with recent approaches.
</details>
<details>
<summary>摘要</summary>
While impressive performance has been achieved in image captioning, the limited diversity of the generated captions and the large parameter scale remain major barriers to the real-world application of these systems. In this work, we propose a lightweight image captioning network in combination with continuous diffusion, called Prefix-diffusion. To achieve diversity, we design an efficient method that injects prefix image embeddings into the denoising process of the diffusion model. In order to reduce trainable parameters, we employ a pre-trained model to extract image features and further design an extra mapping network. Prefix-diffusion is able to generate diverse captions with relatively less parameters, while maintaining the fluency and relevance of the captions benefiting from the generative capabilities of the diffusion model. Our work paves the way for scaling up diffusion models for image captioning, and achieves promising performance compared with recent approaches.Here's the translation in Traditional Chinese:虽然印象描述中已经取得了卓越的表现，但是生成的描述仍然受到限制的多样性和大量的参数数量的阻碍。在这个工作中，我们提出了一个轻量级的图像描述网络，与不断传递（Diffusion）相结合，称为Prefix-diffusion。以提高多样性，我们设计了一个高效的方法，将预设的prefix图像嵌入送入传递过程中的混浊模型。以减少可读参数数量，我们使用预训模型提取图像特征，并设计了额外的映射网络。Prefix-diffusion能够生成多样的描述，并且保持描述的流利和相关性，充分利用传递模型的创造能力。我们的工作开启了扩展传递模型的可能性，并取得了最近的方法的优秀表现。
</details></li>
</ul>
<hr>
<h2 id="Multi-document-Summarization-A-Comparative-Evaluation"><a href="#Multi-document-Summarization-A-Comparative-Evaluation" class="headerlink" title="Multi-document Summarization: A Comparative Evaluation"></a>Multi-document Summarization: A Comparative Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04951">http://arxiv.org/abs/2309.04951</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kushan Hewapathirana, Nisansa de Silva, C. D. Athuraliya</li>
<li>for: 评估现有多文摘要模型在不同领域和数据集上的表现，并探讨现有模型的局限性，以决定未来研究方向。</li>
<li>methods: 进行了广泛的文献综述，并分析了PRIMERA和PEGASUS模型在BigSurvey-MDS和MS$^2$数据集上的表现。</li>
<li>results: 发现LED全局预训练模型在MS$^2$数据集上比PRIMERA和PEGASUS表现更好，使用ROUGE分数来评估不同数据集上模型的表现。这些发现可以帮助未来的多文摘要研究，并为涉及复杂数据的各种领域提供准确和可靠的模型。<details>
<summary>Abstract</summary>
This paper is aimed at evaluating state-of-the-art models for Multi-document Summarization (MDS) on different types of datasets in various domains and investigating the limitations of existing models to determine future research directions. To address this gap, we conducted an extensive literature review to identify state-of-the-art models and datasets. We analyzed the performance of PRIMERA and PEGASUS models on BigSurvey-MDS and MS$^2$ datasets, which posed unique challenges due to their varied domains. Our findings show that the General-Purpose Pre-trained Model LED outperforms PRIMERA and PEGASUS on the MS$^2$ dataset. We used the ROUGE score as a performance metric to evaluate the identified models on different datasets. Our study provides valuable insights into the models' strengths and weaknesses, as well as their applicability in different domains. This work serves as a reference for future MDS research and contributes to the development of accurate and robust models which can be utilized on demanding datasets with academically and/or scientifically complex data as well as generalized, relatively simple datasets.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "Multi-document Summarization" (MDS) is translated as "多文摘要" (duō wén jué yào) in Simplified Chinese.* "BigSurvey-MDS" and "MS$^2$" are translated as "大调查-MDS" (dà zhù zhàng - MDs) and "MS$^2$" (Meng Shi Er Shi) respectively.* "PRIMERA" and "PEGASUS" are translated as "PRIMERA" (Pǐ Mǐ É Ra) and "PEGASUS" (Péi Jī É Shū) respectively.* "General-Purpose Pre-trained Model" (LED) is translated as "通用预训模型" (tōng yòng yù xùn módel) in Simplified Chinese.* "ROUGE" score is translated as "ROUGE" 得分 (ROUGE dé fèng) in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Knowledge-based-Refinement-of-Scientific-Publication-Knowledge-Graphs"><a href="#Knowledge-based-Refinement-of-Scientific-Publication-Knowledge-Graphs" class="headerlink" title="Knowledge-based Refinement of Scientific Publication Knowledge Graphs"></a>Knowledge-based Refinement of Scientific Publication Knowledge Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05681">http://arxiv.org/abs/2309.05681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siwen Yan, Phillip Odom, Sriraam Natarajan</li>
<li>for: 本研究目的是解决作者归属问题，具体来说是通过构建和更新知识图来实现。</li>
<li>methods: 本研究使用了功能Gradient Boosting来学习概率逻辑模型，并在人工指导下进行知识填充。</li>
<li>results: 研究表明，在七种作者域中，人工知识可以有效地提高作者归属预测的准确率和可解性。<details>
<summary>Abstract</summary>
We consider the problem of identifying authorship by posing it as a knowledge graph construction and refinement. To this effect, we model this problem as learning a probabilistic logic model in the presence of human guidance (knowledge-based learning). Specifically, we learn relational regression trees using functional gradient boosting that outputs explainable rules. To incorporate human knowledge, advice in the form of first-order clauses is injected to refine the trees. We demonstrate the usefulness of human knowledge both quantitatively and qualitatively in seven authorship domains.
</details>
<details>
<summary>摘要</summary>
我们视作推断作者的问题为建构知识图和精焕。为此，我们以学习机会逻辑模型为基础，使用函数Gradient Boosting学习关联 regression树，从而获得可解释的规则。为了包括人类知识，我们将知识型clause注入到树中来精焕。我们在七个作者领域证明了人类知识的有用性， both quantitatively and qualitatively。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="MFPNet-Multi-scale-Feature-Propagation-Network-For-Lightweight-Semantic-Segmentation"><a href="#MFPNet-Multi-scale-Feature-Propagation-Network-For-Lightweight-Semantic-Segmentation" class="headerlink" title="MFPNet: Multi-scale Feature Propagation Network For Lightweight Semantic Segmentation"></a>MFPNet: Multi-scale Feature Propagation Network For Lightweight Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04914">http://arxiv.org/abs/2309.04914</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guoan Xu, Wenjing Jia, Tao Wu, Ligeng Chen</li>
<li>for: 提高轻量级 semantic segmentation 的进步（semantic segmentation 是指将图像分割成不同类别的过程），尤其是在 compare to large-scale models 的研究方面，研究发现该领域的进步相对较慢。</li>
<li>methods: 我们提出了一种新的轻量级 segmentation 架构，即 Multi-scale Feature Propagation Network (MFPNet)，用于解决这个问题。MFPNet 包括对称的 residual blocks，以及 flexible bottleneck residual modules (BRMs)，以探索深度和 ricoh 多尺度 semantic context。此外，我们还利用 Graph Convolutional Networks (GCNs) 来促进多尺度 feature propagation between BRM blocks。</li>
<li>results: 我们的方法在 benchmark datasets 上进行测试，显示了出色的 segmentation 结果。<details>
<summary>Abstract</summary>
In contrast to the abundant research focusing on large-scale models, the progress in lightweight semantic segmentation appears to be advancing at a comparatively slower pace. However, existing compact methods often suffer from limited feature representation capability due to the shallowness of their networks. In this paper, we propose a novel lightweight segmentation architecture, called Multi-scale Feature Propagation Network (MFPNet), to address the dilemma. Specifically, we design a robust Encoder-Decoder structure featuring symmetrical residual blocks that consist of flexible bottleneck residual modules (BRMs) to explore deep and rich muti-scale semantic context. Furthermore, taking benefit from their capacity to model latent long-range contextual relationships, we leverage Graph Convolutional Networks (GCNs) to facilitate multi-scale feature propagation between the BRM blocks. When evaluated on benchmark datasets, our proposed approach shows superior segmentation results.
</details>
<details>
<summary>摘要</summary>
contrast to the abundant research focusing on large-scale models, the progress in lightweight semantic segmentation appears to be advancing at a comparatively slower pace. However, existing compact methods often suffer from limited feature representation capability due to the shallowness of their networks. In this paper, we propose a novel lightweight segmentation architecture, called Multi-scale Feature Propagation Network (MFPNet), to address the dilemma. Specifically, we design a robust Encoder-Decoder structure featuring symmetrical residual blocks that consist of flexible bottleneck residual modules (BRMs) to explore deep and rich multi-scale semantic context. Furthermore, taking benefit from their capacity to model latent long-range contextual relationships, we leverage Graph Convolutional Networks (GCNs) to facilitate multi-scale feature propagation between the BRM blocks. When evaluated on benchmark datasets, our proposed approach shows superior segmentation results.Here's the breakdown of the translation:* 异常 (contrast) - 对 (to)* 丰富 (abundant) - 研究 (research)* 注重 (focusing) - 大型 (large-scale) 模型 (models)* 进步 (progress) - 在 (in)* 较 (comparatively)  slower pace* 然而 (however) - 现有 (existing) 紧凑 (compact) 方法 (methods)* 常 (often) suffer from - 有限 (limited) 表示 (representation) capability* due to - 由 (because of) the shallowness of their networks* In this paper, we propose - 在这篇论文中，我们提出* a novel lightweight segmentation architecture, called Multi-scale Feature Propagation Network (MFPNet)* to address the dilemma* Specifically, we design - 具体来说，我们设计* a robust Encoder-Decoder structure featuring symmetrical residual blocks* that consist of flexible bottleneck residual modules (BRMs)* to explore deep and rich multi-scale semantic context* Furthermore, taking benefit from - 另外，我们利用* their capacity to model latent long-range contextual relationships* we leverage Graph Convolutional Networks (GCNs) to facilitate multi-scale feature propagation between the BRM blocks* When evaluated on benchmark datasets, our proposed approach shows superior segmentation results.Note that Simplified Chinese is used in this translation, which is the standard written form of Chinese used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="A-Review-of-Machine-Learning-based-Security-in-Cloud-Computing"><a href="#A-Review-of-Machine-Learning-based-Security-in-Cloud-Computing" class="headerlink" title="A Review of Machine Learning-based Security in Cloud Computing"></a>A Review of Machine Learning-based Security in Cloud Computing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04911">http://arxiv.org/abs/2309.04911</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Aptin Babaei, Parham M. Kebria, Mohsen Moradi Dalvand, Saeid Nahavandi</li>
<li>for: 本研究旨在提供一个全面的Machine Learning（ML）在云计算安全领域的现状报告，探讨不同ML算法的特点和效果，以及其可能的局限性。</li>
<li>methods: 本研究使用了许多最新的ML算法，包括分类、回归、 clustering等，以及其各自的特点和应用场景。</li>
<li>results: 本研究发现了一些ML算法在云计算安全领域的应用，包括攻击检测、数据分析、威胁感知等，以及这些算法的效果和局限性。<details>
<summary>Abstract</summary>
Cloud Computing (CC) is revolutionizing the way IT resources are delivered to users, allowing them to access and manage their systems with increased cost-effectiveness and simplified infrastructure. However, with the growth of CC comes a host of security risks, including threats to availability, integrity, and confidentiality. To address these challenges, Machine Learning (ML) is increasingly being used by Cloud Service Providers (CSPs) to reduce the need for human intervention in identifying and resolving security issues. With the ability to analyze vast amounts of data, and make high-accuracy predictions, ML can transform the way CSPs approach security. In this paper, we will explore some of the most recent research in the field of ML-based security in Cloud Computing. We will examine the features and effectiveness of a range of ML algorithms, highlighting their unique strengths and potential limitations. Our goal is to provide a comprehensive overview of the current state of ML in cloud security and to shed light on the exciting possibilities that this emerging field has to offer.
</details>
<details>
<summary>摘要</summary>
云计算（CC）正在改变IT资源的提供方式，让用户通过更加成本效益和简化的基础设施访问和管理他们的系统。然而，随着CC的增长，也出现了一系列安全风险，包括可用性、完整性和机密性的威胁。为了解决这些挑战，机器学习（ML）在云服务提供商（CSP）中越来越广泛使用，以减少人类干预在安全问题上的需求。机器学习可以分析大量数据，并做出高准确率的预测，因此它可以将云安全问题的解决方式转化为自动化的过程。在这篇论文中，我们将探讨最新的云计算领域中ML基于安全性的研究。我们将评估一些常用的ML算法的特点和效果，并 highlight其独特优势和潜在的限制。我们的目标是提供云计算领域ML安全性的全面概述，并探讨这个新兴领域的激动人心的可能性。
</details></li>
</ul>
<hr>
<h2 id="Effective-Real-Image-Editing-with-Accelerated-Iterative-Diffusion-Inversion"><a href="#Effective-Real-Image-Editing-with-Accelerated-Iterative-Diffusion-Inversion" class="headerlink" title="Effective Real Image Editing with Accelerated Iterative Diffusion Inversion"></a>Effective Real Image Editing with Accelerated Iterative Diffusion Inversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04907">http://arxiv.org/abs/2309.04907</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhihong Pan, Riccardo Gherardi, Xiufeng Xie, Stephen Huang</li>
<li>for: 这 paper 的目的是提出一种高效的图像修改方法，以解决现代生成模型中的图像编辑问题。</li>
<li>methods: 该方法使用一种新的混合导航技术，将混合导航和梯度下降两种方法相互融合，以提高图像修改的准确率。</li>
<li>results: 对比其他扩散逆向方法，该方法在10和20扩散步的 режиме下显示出更高的稳定性和效率，并且不需要大量的类ifier-free导航。<details>
<summary>Abstract</summary>
Despite all recent progress, it is still challenging to edit and manipulate natural images with modern generative models. When using Generative Adversarial Network (GAN), one major hurdle is in the inversion process mapping a real image to its corresponding noise vector in the latent space, since its necessary to be able to reconstruct an image to edit its contents. Likewise for Denoising Diffusion Implicit Models (DDIM), the linearization assumption in each inversion step makes the whole deterministic inversion process unreliable. Existing approaches that have tackled the problem of inversion stability often incur in significant trade-offs in computational efficiency. In this work we propose an Accelerated Iterative Diffusion Inversion method, dubbed AIDI, that significantly improves reconstruction accuracy with minimal additional overhead in space and time complexity. By using a novel blended guidance technique, we show that effective results can be obtained on a large range of image editing tasks without large classifier-free guidance in inversion. Furthermore, when compared with other diffusion inversion based works, our proposed process is shown to be more robust for fast image editing in the 10 and 20 diffusion steps' regimes.
</details>
<details>
<summary>摘要</summary>
尽管最近的进步很大，但是使用现代生成模型编辑和 manipulate 自然图像仍然是一个挑战。使用生成对抗网络（GAN）时，一个主要的障碍是在映射实际图像到其对应的隐藏空间噪声 вектор的过程中，因为需要能够重建图像以编辑其内容。同样，对于隐藏扩散假设模型（DDIM），每个反向步骤的线性化假设使整个推导性反向过程变得不可靠。现有的方法通常会在稳定性的权衡中做出大的牺牲。在这种情况下，我们提出了一种加速iterativediffusion inverse method，名为AIDI，该方法可以在重建精度方面取得显著改进，而无需增加空间和时间复杂度。我们使用了一种新的混合引导技术，并证明在大范围的图像编辑任务中可以获得有效的结果，无需大量的类ifier-free引导。此外，我们的提posed进程比其他扩散反向过程更加稳定，在10和20扩散步骤的 режиме下进行快速图像编辑。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/10/cs.AI_2023_09_10/" data-id="cloimip4z003js4886tt3191v" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_10" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/10/cs.CL_2023_09_10/" class="article-date">
  <time datetime="2023-09-10T11:00:00.000Z" itemprop="datePublished">2023-09-10</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/10/cs.CL_2023_09_10/">cs.CL - 2023-09-10</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="The-Effect-of-Alignment-Objectives-on-Code-Switching-Translation"><a href="#The-Effect-of-Alignment-Objectives-on-Code-Switching-Translation" class="headerlink" title="The Effect of Alignment Objectives on Code-Switching Translation"></a>The Effect of Alignment Objectives on Code-Switching Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05044">http://arxiv.org/abs/2309.05044</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamed Anwar</li>
<li>for: 这个论文主要是为了提高机器翻译模型对Code-switching内容的翻译能力，特别是随着社交媒体和用户生成内容的兴起。</li>
<li>methods: 该论文提出了一种训练单个机器翻译模型，可以将一种语言中的单 sentence翻译成另一种语言，同时也可以翻译code-switched sentence。这个模型可以看作是人类的双语模型。为了更好地利用平行数据，我们生成了Synthetic Code-switched (CSW) 数据，并在编码器上添加了对齐损失，以将语言表示 align across languages。</li>
<li>results: 使用WMT14英语-法语（En-Fr）数据集，训练过程中的模型在处理code-switched翻译时强制性超过了批量基eline，同时保持了非code-switched（单语言）数据的质量。<details>
<summary>Abstract</summary>
One of the things that need to change when it comes to machine translation is the models' ability to translate code-switching content, especially with the rise of social media and user-generated content. In this paper, we are proposing a way of training a single machine translation model that is able to translate monolingual sentences from one language to another, along with translating code-switched sentences to either language. This model can be considered a bilingual model in the human sense. For better use of parallel data, we generated synthetic code-switched (CSW) data along with an alignment loss on the encoder to align representations across languages. Using the WMT14 English-French (En-Fr) dataset, the trained model strongly outperforms bidirectional baselines on code-switched translation while maintaining quality for non-code-switched (monolingual) data.
</details>
<details>
<summary>摘要</summary>
一些需要改变的事情在机器翻译方面是模型对混合语言内容的翻译能力，尤其是随着社交媒体和用户生成内容的兴起。在这篇论文中，我们提出了一种训练单个机器翻译模型，可以将一种语言中的单语句翻译成另一种语言，同时也可以翻译混合语言句子到任一种语言。这个模型可以被视为人类中的双语模型。为了更好地利用平行数据，我们生成了人工合成的混合语言数据，并在编码器中添加了对逻辑的损失，以确保语言之间的表示相互对应。使用WMT14英语-法语（En-Fr）数据集，我们训练的模型在混合语言翻译中强制超越了irectional基eline，同时保持了非混合语言数据的质量。
</details></li>
</ul>
<hr>
<h2 id="Chat2Brain-A-Method-for-Mapping-Open-Ended-Semantic-Queries-to-Brain-Activation-Maps"><a href="#Chat2Brain-A-Method-for-Mapping-Open-Ended-Semantic-Queries-to-Brain-Activation-Maps" class="headerlink" title="Chat2Brain: A Method for Mapping Open-Ended Semantic Queries to Brain Activation Maps"></a>Chat2Brain: A Method for Mapping Open-Ended Semantic Queries to Brain Activation Maps</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05021">http://arxiv.org/abs/2309.05021</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yaonai Wei, Tuo Zhang, Han Zhang, Tianyang Zhong, Lin Zhao, Zhengliang Liu, Chong Ma, Songyao Zhang, Muheng Shang, Lei Du, Xiao Li, Tianming Liu, Junwei Han</li>
<li>for: 本研究旨在提高meta-analysis中文本Query的准确性，使用大型自然语言模型(LLMs)来解决现有的问题，如semantic redundancy和ambiguity。</li>
<li>methods: 本研究使用了一种称为Chat2Brain的方法，它将基本的文本-2-图模型(Text2Brain)与LLMs相结合，以将开放式SemanticQuery映射到大脑活动图像中。</li>
<li>results: 研究表明，Chat2Brain可以将文本Query转化为具有生物学可能性的大脑活动图像，并且在数据缺乏和复杂的查询环境中表现出了优于Text2Brain模型。<details>
<summary>Abstract</summary>
Over decades, neuroscience has accumulated a wealth of research results in the text modality that can be used to explore cognitive processes. Meta-analysis is a typical method that successfully establishes a link from text queries to brain activation maps using these research results, but it still relies on an ideal query environment. In practical applications, text queries used for meta-analyses may encounter issues such as semantic redundancy and ambiguity, resulting in an inaccurate mapping to brain images. On the other hand, large language models (LLMs) like ChatGPT have shown great potential in tasks such as context understanding and reasoning, displaying a high degree of consistency with human natural language. Hence, LLMs could improve the connection between text modality and neuroscience, resolving existing challenges of meta-analyses. In this study, we propose a method called Chat2Brain that combines LLMs to basic text-2-image model, known as Text2Brain, to map open-ended semantic queries to brain activation maps in data-scarce and complex query environments. By utilizing the understanding and reasoning capabilities of LLMs, the performance of the mapping model is optimized by transferring text queries to semantic queries. We demonstrate that Chat2Brain can synthesize anatomically plausible neural activation patterns for more complex tasks of text queries.
</details>
<details>
<summary>摘要</summary>
（注：以下是简化中文版本）多年来，神经科学在文本模式中积累了大量的研究成果，可以用来探索认知过程。meta分析是一种常见的方法，可以将文本查询映射到大脑活动图表，但是它仍然依赖于理想的查询环境。在实际应用中，用于meta分析的文本查询可能会遇到 semantics redundancy和ambiguity问题，导致不准确地映射到大脑图像。然而，大型自然语言模型（LLMs）如ChatGPT显示出了在上下文理解和思维任务中的极高潜力，这与人类自然语言的一致度很高。因此，LLMs可以改善文本模式和神经科学之间的连接，解决现有的meta分析挑战。在这项研究中，我们提议一种名为Chat2Brain的方法，将LLMs与基本的文本-2-图模型（Text2Brain）结合，以将开放式semantic查询映射到大脑活动图表中。通过利用LLMs的理解和思维能力，我们可以优化映射模型的性能，将文本查询转化为semantic查询。我们示例ify that Chat2Brain可以生成符合生物学原理的大脑活动 Patterns for more complex tasks of text queries.
</details></li>
</ul>
<hr>
<h2 id="Machine-Translation-Models-Stand-Strong-in-the-Face-of-Adversarial-Attacks"><a href="#Machine-Translation-Models-Stand-Strong-in-the-Face-of-Adversarial-Attacks" class="headerlink" title="Machine Translation Models Stand Strong in the Face of Adversarial Attacks"></a>Machine Translation Models Stand Strong in the Face of Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06527">http://arxiv.org/abs/2309.06527</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pavel Burnyshev, Elizaveta Kostenok, Alexey Zaytsev</li>
<li>for: 本研究探讨了深度学习模型面临攻击时的漏洞，具体来说是对序列至序列（seq2seq）模型的机器翻译模型进行攻击。</li>
<li>methods: 我们引入了基本文本扰动规则和更高级别的策略，如梯度基于攻击，利用不可导的翻译度量的拟合来进行攻击。</li>
<li>results: 我们的研究表明，机器翻译模型对已知最佳攻击方法 Displayed robustness，输入扰动与输出扰动直接相关。但是，在弱者中，我们的攻击表现最好，与其他攻击相比，具有最高相对性。另一强 candidate是基于个体字符混合的攻击。<details>
<summary>Abstract</summary>
Adversarial attacks expose vulnerabilities of deep learning models by introducing minor perturbations to the input, which lead to substantial alterations in the output. Our research focuses on the impact of such adversarial attacks on sequence-to-sequence (seq2seq) models, specifically machine translation models. We introduce algorithms that incorporate basic text perturbation heuristics and more advanced strategies, such as the gradient-based attack, which utilizes a differentiable approximation of the inherently non-differentiable translation metric. Through our investigation, we provide evidence that machine translation models display robustness displayed robustness against best performed known adversarial attacks, as the degree of perturbation in the output is directly proportional to the perturbation in the input. However, among underdogs, our attacks outperform alternatives, providing the best relative performance. Another strong candidate is an attack based on mixing of individual characters.
</details>
<details>
<summary>摘要</summary>
深度学习模型的敌对攻击暴露了它们的漏洞，通过对输入添加微小的修改，导致输出受到重大的变化。我们的研究关注于seq2seq模型，具体来说是机器翻译模型，对于这类模型的敌对攻击。我们提出了基于文本修饰规则和更高级的策略，如基于梯度的攻击，利用可微的翻译评价函数来近似非微分的翻译评价函数。我们的调查发现，机器翻译模型对已知最佳敌对攻击表现出了强健性，输入修饰程度与输出修饰程度直接相关。然而，在弱者中，我们的攻击表现最佳，提供了最好的相对性。另一个强 канди达是基于个体字符混合的攻击。
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Word-Bias-in-Zero-shot-Prompt-based-Classifiers"><a href="#Mitigating-Word-Bias-in-Zero-shot-Prompt-based-Classifiers" class="headerlink" title="Mitigating Word Bias in Zero-shot Prompt-based Classifiers"></a>Mitigating Word Bias in Zero-shot Prompt-based Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04992">http://arxiv.org/abs/2309.04992</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adian Liusie, Potsawee Manakul, Mark J. F. Gales</li>
<li>for: 提高 prompt-based 分类器的性能，解决 word biases 问题</li>
<li>methods: 使用 unsupervised 方法，对类别的预测概率进行重新权重，并与语言模型的词权相连</li>
<li>results: 实现了大幅提高 prompt 设置的性能，与 oracle Upper bound 性能呈现强相关，并可以在 zero-resource 环境下设置阈值<details>
<summary>Abstract</summary>
Prompt-based classifiers are an attractive approach for zero-shot classification. However, the precise choice of the prompt template and label words can largely influence performance, with semantically equivalent settings often showing notable performance difference. This discrepancy can be partly attributed to word biases, where the classifier may be biased towards classes. To address this problem, it is possible to optimise classification thresholds on a labelled data set, however, this mitigates some of the advantages of prompt-based classifiers. This paper instead approaches this problem by examining the expected marginal probabilities of the classes. Here, probabilities are reweighted to have a uniform prior over classes, in an unsupervised fashion. Further, we draw a theoretical connection between the class priors and the language models' word prior, and offer the ability to set a threshold in a zero-resource fashion. We show that matching class priors correlates strongly with the oracle upper bound performance and demonstrate large consistent performance gains for prompt settings over a range of NLP tasks.
</details>
<details>
<summary>摘要</summary>
This paper proposes a different approach: reweighting probabilities to have a uniform prior over classes in an unsupervised fashion. The expected marginal probabilities of the classes are examined, and a threshold can be set in a zero-resource fashion. The class priors are found to be closely related to the language models' word prior, and matching class priors can achieve strong performance gains for prompt settings across a range of NLP tasks.
</details></li>
</ul>
<hr>
<h2 id="Retrieval-Augmented-Meta-Learning-for-Low-Resource-Text-Classification"><a href="#Retrieval-Augmented-Meta-Learning-for-Low-Resource-Text-Classification" class="headerlink" title="Retrieval-Augmented Meta Learning for Low-Resource Text Classification"></a>Retrieval-Augmented Meta Learning for Low-Resource Text Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04979">http://arxiv.org/abs/2309.04979</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Carolmelon/RAML">https://github.com/Carolmelon/RAML</a></li>
<li>paper_authors: Rongsheng Li, Yangning Li, Yinghui Li, Chaiyut Luoyiching, Hai-Tao Zheng, Nannan Zhou, Hanjing Su</li>
<li>for: 优化低资源文本分类任务的表现，通过从源类任务中传递知识来预测目标类。</li>
<li>methods: 使用参数化神经网络进行推理，并从外部词库中检索非参数化知识来增强推理表现。</li>
<li>results: 在低资源文本分类任务中显著超过当前最佳状态的表现。<details>
<summary>Abstract</summary>
Meta learning have achieved promising performance in low-resource text classification which aims to identify target classes with knowledge transferred from source classes with sets of small tasks named episodes. However, due to the limited training data in the meta-learning scenario and the inherent properties of parameterized neural networks, poor generalization performance has become a pressing problem that needs to be addressed. To deal with this issue, we propose a meta-learning based method called Retrieval-Augmented Meta Learning(RAML). It not only uses parameterization for inference but also retrieves non-parametric knowledge from an external corpus to make inferences, which greatly alleviates the problem of poor generalization performance caused by the lack of diverse training data in meta-learning. This method differs from previous models that solely rely on parameters, as it explicitly emphasizes the importance of non-parametric knowledge, aiming to strike a balance between parameterized neural networks and non-parametric knowledge. The model is required to determine which knowledge to access and utilize during inference. Additionally, our multi-view passages fusion network module can effectively and efficiently integrate the retrieved information into low-resource classification task. The extensive experiments demonstrate that RAML significantly outperforms current SOTA low-resource text classification models.
</details>
<details>
<summary>摘要</summary>
Meta 学习已经实现了低资源文本分类中的出色表现，通过从源类中 transferred 知识来标识目标类。然而，由于 meta-learning enario 中的培育数据有限和参数化神经网络的内在性质，低泛化性表现成为一个需要解决的问题。为解决这个问题，我们提出了 Retrieval-Augmented Meta Learning（RAML）方法。它不仅使用参数进行推理，而且从外部资源中检索非参数化知识，以便在推理时使用，这有效地解决了由于缺乏多样化培育数据而导致的低泛化性问题。与之前的模型不同，RAML 不仅仅仅靠参数来进行推理，而是强调非参数化知识的重要性，以达到参数化神经网络和非参数化知识之间的平衡。模型需要在推理时决定哪些知识要访问和利用。此外，我们的多视图通道融合网络模块可以高效地和有效地将检索到的信息集成到低资源分类任务中。广泛的实验表明，RAML 可以明显超过当前最佳的低资源文本分类模型。
</details></li>
</ul>
<hr>
<h2 id="Prompt-Learning-With-Knowledge-Memorizing-Prototypes-For-Generalized-Few-Shot-Intent-Detection"><a href="#Prompt-Learning-With-Knowledge-Memorizing-Prototypes-For-Generalized-Few-Shot-Intent-Detection" class="headerlink" title="Prompt Learning With Knowledge Memorizing Prototypes For Generalized Few-Shot Intent Detection"></a>Prompt Learning With Knowledge Memorizing Prototypes For Generalized Few-Shot Intent Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04971">http://arxiv.org/abs/2309.04971</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chaiyut Luoyiching, Yangning Li, Yinghui Li, Rongsheng Li, Hai-Tao Zheng, Nannan Zhou, Hanjing Su</li>
<li>for:  solves the challenging problem of generalized few-shot intent detection (GFSID) by converting the task into the class incremental learning paradigm.</li>
<li>methods:  proposes a two-stage learning framework that sequentially learns the knowledge of different intents in various periods via prompt learning, and uses prototypes to categorize both seen and novel intents.</li>
<li>results:  achieves promising performance on two widely used datasets through extensive experiments and detailed analyses.Here’s the full summary in Simplified Chinese:</li>
<li>for: 通过将GFSID任务转换为类增量学习 paradigm，解决了Generalized Few-Shot Intent Detection (GFSID) 的挑战性问题。</li>
<li>methods: 提议了一个两阶段学习框架，通过提示学习顺序地学习不同意图的知识，并使用prototype来分类seen和novel意图。</li>
<li>results: 通过广泛的实验和详细的分析，在两个广泛使用的数据集上达到了可观的表现。<details>
<summary>Abstract</summary>
Generalized Few-Shot Intent Detection (GFSID) is challenging and realistic because it needs to categorize both seen and novel intents simultaneously. Previous GFSID methods rely on the episodic learning paradigm, which makes it hard to extend to a generalized setup as they do not explicitly learn the classification of seen categories and the knowledge of seen intents. To address the dilemma, we propose to convert the GFSID task into the class incremental learning paradigm. Specifically, we propose a two-stage learning framework, which sequentially learns the knowledge of different intents in various periods via prompt learning. And then we exploit prototypes for categorizing both seen and novel intents. Furthermore, to achieve the transfer knowledge of intents in different stages, for different scenarios we design two knowledge preservation methods which close to realistic applications. Extensive experiments and detailed analyses on two widely used datasets show that our framework based on the class incremental learning paradigm achieves promising performance.
</details>
<details>
<summary>摘要</summary>
通用几招意图检测（GFSID）是一个具有挑战性和实用性的任务，因为它需要同时分类已知和新的意图。先前的GFSID方法基于 episodic learning 模式，这使得它们不能直接应用到通用化设置中。为解决这个困境，我们提议将 GFSID 任务转化为类增量学习模式。具体来说，我们提议一个两阶段学习框架，先后学习不同时期的意图知识via prompt learning。然后，我们利用示例来分类已知和新的意图。此外，为了保持意图在不同阶段的传递知识，我们设计了两种知识保持方法，它们更加适合实际应用。我们在两个广泛使用的数据集上进行了详细的实验和分析，得到了我们基于类增量学习模式的框架的优秀表现。
</details></li>
</ul>
<hr>
<h2 id="What’s-Hard-in-English-RST-Parsing-Predictive-Models-for-Error-Analysis"><a href="#What’s-Hard-in-English-RST-Parsing-Predictive-Models-for-Error-Analysis" class="headerlink" title="What’s Hard in English RST Parsing? Predictive Models for Error Analysis"></a>What’s Hard in English RST Parsing? Predictive Models for Error Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04940">http://arxiv.org/abs/2309.04940</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Janet Liu, Tatsuya Aoyama, Amir Zeldes</li>
<li>for: 本研究旨在探讨逻辑结构理论下的层次话语分析仍然存在挑战，以及这些挑战的原因是如何。</li>
<li>methods: 本文使用了一些过去研究中的难点，包括半显式关系、远程关系、缺失词汇等因素，以及两个英文测试集，其中一个包含正确的金标RST关系，另一个包含干扰关系。</li>
<li>results: 我们的结果显示，与浅度话语分析一样，显式&#x2F;隐式之分在层次话语分析中也发挥了作用，但是远程依赖关系是主要的挑战，而词汇重叠的问题较少。我们的最终模型可以在76.3%的精度上预测错误的位置，Bottom-upParser 和 Top-downParser 都是如此。<details>
<summary>Abstract</summary>
Despite recent advances in Natural Language Processing (NLP), hierarchical discourse parsing in the framework of Rhetorical Structure Theory remains challenging, and our understanding of the reasons for this are as yet limited. In this paper, we examine and model some of the factors associated with parsing difficulties in previous work: the existence of implicit discourse relations, challenges in identifying long-distance relations, out-of-vocabulary items, and more. In order to assess the relative importance of these variables, we also release two annotated English test-sets with explicit correct and distracting discourse markers associated with gold standard RST relations. Our results show that as in shallow discourse parsing, the explicit/implicit distinction plays a role, but that long-distance dependencies are the main challenge, while lack of lexical overlap is less of a problem, at least for in-domain parsing. Our final model is able to predict where errors will occur with an accuracy of 76.3% for the bottom-up parser and 76.6% for the top-down parser.
</details>
<details>
<summary>摘要</summary>
尽管最近的自然语言处理（NLP）技术已经取得了 significiant advances，但在 rhethorical structure theory（RST）框架下的层次演化分析仍然是一个挑战，我们对这些挑战的理解仍然有限。在这篇论文中，我们研究了过去的 parsing 困难的一些因素，包括隐式 discourse relations 的存在、远程关系的挑战、out-of-vocabulary items 和更多的因素。为了评估这些变量的相对重要性，我们还发布了两个英文测试集，其中包含了可见的正确和干扰 discourse markers，与黄金标准 RST 关系相关。我们的结果表明，与浅层演化 parsing 类似，显式/隐式之分发挥了作用，但长距离依赖关系是主要挑战，而词汇重叠的不足则是一个较小的问题，至少是在预测 parsing 中。我们的最终模型能够预测错误的发生位置的准确率为 76.3%（底层parser）和 76.6%（顶层parser）。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Chunking-with-Hierarchical-RNN"><a href="#Unsupervised-Chunking-with-Hierarchical-RNN" class="headerlink" title="Unsupervised Chunking with Hierarchical RNN"></a>Unsupervised Chunking with Hierarchical RNN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04919">http://arxiv.org/abs/2309.04919</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/manga-uofa/uchrnn">https://github.com/manga-uofa/uchrnn</a></li>
<li>paper_authors: Zijun Wu, Anup Anand Deshmukh, Yongkang Wu, Jimmy Lin, Lili Mou</li>
<li>for: 这篇论文主要是为了探讨一种无监督的句子分析方法，即用Recurrent Neural Network (RNN)模型来自动从语言模式中提取句子结构。</li>
<li>methods: 这篇论文使用了一种两层层次RNN模型，即 Hierarchical Recurrent Neural Network (HRNN)，来模型单词到句子和句子到句子的组合。该方法包括了两个阶段的训练过程：首先预训练一个无监督分析器，然后使用下游NLP任务进行细化训练。</li>
<li>results: 实验结果表明，这种无监督 chunking 方法可以在 CoNLL-2000 数据集上提取句子结构，并且与现有的无监督方法相比，提高了一个phrase F1 分数的值。此外，在下游 NLP 任务的训练过程中，模型的性能进一步提高。有趣的是，我们发现在神经网络模型在下游任务训练过程中，句子结构的出现是暂时的。这种研究对无监督句子结构发现的进步做出了贡献，并开创了更多的语言理论研究的可能性。<details>
<summary>Abstract</summary>
In Natural Language Processing (NLP), predicting linguistic structures, such as parsing and chunking, has mostly relied on manual annotations of syntactic structures. This paper introduces an unsupervised approach to chunking, a syntactic task that involves grouping words in a non-hierarchical manner. We present a two-layer Hierarchical Recurrent Neural Network (HRNN) designed to model word-to-chunk and chunk-to-sentence compositions. Our approach involves a two-stage training process: pretraining with an unsupervised parser and finetuning on downstream NLP tasks. Experiments on the CoNLL-2000 dataset reveal a notable improvement over existing unsupervised methods, enhancing phrase F1 score by up to 6 percentage points. Further, finetuning with downstream tasks results in an additional performance improvement. Interestingly, we observe that the emergence of the chunking structure is transient during the neural model's downstream-task training. This study contributes to the advancement of unsupervised syntactic structure discovery and opens avenues for further research in linguistic theory.
</details>
<details>
<summary>摘要</summary>
在自然语言处理（NLP）领域，预测语言结构，如分析和块分，旁通过手动标注语法结构来进行。这篇论文介绍了一种不需要监督的块分法，即将词语组合成非层次的方式。我们提出了一种两层层次逻辑神经网络（HRNN），用于模elling 词语到块和块到句子的组合。我们的方法包括两个阶段的训练过程：预训练与无监督分析器和下游 NLP 任务的训练。实验结果表明，我们的方法在 CoNLL-2000 数据集上具有明显的提升，提高了phrase F1分数 by up to 6个百分点。此外，在下游任务的训练中，再进行一次性的性能提升。另外，我们发现在神经网络模型在下游任务训练过程中，块分结构的出现是暂时的。这项研究对无监督语法结构发现的进步做出了贡献，并开启了更多的语言理论研究的可能性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/10/cs.CL_2023_09_10/" data-id="cloimip6w00abs4884c4r2mvy" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_09_10" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/10/cs.LG_2023_09_10/" class="article-date">
  <time datetime="2023-09-10T10:00:00.000Z" itemprop="datePublished">2023-09-10</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/10/cs.LG_2023_09_10/">cs.LG - 2023-09-10</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Learning-Energy-Based-Models-by-Cooperative-Diffusion-Recovery-Likelihood"><a href="#Learning-Energy-Based-Models-by-Cooperative-Diffusion-Recovery-Likelihood" class="headerlink" title="Learning Energy-Based Models by Cooperative Diffusion Recovery Likelihood"></a>Learning Energy-Based Models by Cooperative Diffusion Recovery Likelihood</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05153">http://arxiv.org/abs/2309.05153</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yaxuan Zhu, Jianwen Xie, Yingnian Wu, Ruiqi Gao</li>
<li>for: 这个论文主要是为了提高能量基本模型（EBM）的采样质量和训练效率。</li>
<li>methods: 这个论文提出了一种叫做协同涂抹恢复likelihood（CDRL）的方法，它是一种可追加的方法，可以训练和采样多个EBM，并且可以在不同的噪音水平上进行协同训练。</li>
<li>results: 在CIFAR-10和ImageNet 32x32上，这个方法可以大幅提高EBM的FID分数，同时比DRL快2倍，并且可以进行 compositional generation和图像填充任务。<details>
<summary>Abstract</summary>
Training energy-based models (EBMs) with maximum likelihood estimation on high-dimensional data can be both challenging and time-consuming. As a result, there a noticeable gap in sample quality between EBMs and other generative frameworks like GANs and diffusion models. To close this gap, inspired by the recent efforts of learning EBMs by maximimizing diffusion recovery likelihood (DRL), we propose cooperative diffusion recovery likelihood (CDRL), an effective approach to tractably learn and sample from a series of EBMs defined on increasingly noisy versons of a dataset, paired with an initializer model for each EBM. At each noise level, the initializer model learns to amortize the sampling process of the EBM, and the two models are jointly estimated within a cooperative training framework. Samples from the initializer serve as starting points that are refined by a few sampling steps from the EBM. With the refined samples, the EBM is optimized by maximizing recovery likelihood, while the initializer is optimized by learning from the difference between the refined samples and the initial samples. We develop a new noise schedule and a variance reduction technique to further improve the sample quality. Combining these advances, we significantly boost the FID scores compared to existing EBM methods on CIFAR-10 and ImageNet 32x32, with a 2x speedup over DRL. In addition, we extend our method to compositional generation and image inpainting tasks, and showcase the compatibility of CDRL with classifier-free guidance for conditional generation, achieving similar trade-offs between sample quality and sample diversity as in diffusion models.
</details>
<details>
<summary>摘要</summary>
训练能量基模型（EBM）的最大可能性估计在高维数据上可能是一项挑战和时间消耗的任务。因此，EBM和其他生成框架如GANs和扩散模型之间存在一定的样本质量差距。为了 bridging这个差距，我们提出了协同扩散恢复可能性（CDRL），一种有效的方法，可以有效地学习和采样多个EBM，每个EBM定义在不同的噪声水平上。在每个噪声水平上，初始化模型学习了EBM的采样过程，两个模型在一个协同训练框架中被联合学习。采样过程中，初始化模型生成的样本作为EBM的起始点，然后通过EBM的几个采样步骤来修正样本。通过这种方式，EBM可以通过最大化恢复可能性来优化，而初始化模型可以通过学习差异来学习。我们还提出了一种新的噪声调度和一种减少噪声的技术，以进一步提高样本质量。将这些进步组合起来，我们在CIFAR-10和ImageNet 32x32上比现有EBM方法提高了FID分数，同时具有2倍的速度提升。此外，我们还扩展了我们的方法到组合生成和图像填充任务，并示出了与类标量指导无关的条件生成的可能性。
</details></li>
</ul>
<hr>
<h2 id="Distribution-Grid-Line-Outage-Identification-with-Unknown-Pattern-and-Performance-Guarantee"><a href="#Distribution-Grid-Line-Outage-Identification-with-Unknown-Pattern-and-Performance-Guarantee" class="headerlink" title="Distribution Grid Line Outage Identification with Unknown Pattern and Performance Guarantee"></a>Distribution Grid Line Outage Identification with Unknown Pattern and Performance Guarantee</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07157">http://arxiv.org/abs/2309.07157</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenhan Xiao, Yizheng Liao, Yang Weng</li>
<li>for: 检测分布网络中的线路失效是持续运行的关键，本文提出了一种实用又可靠的检测方法，不需要costly phase angles或流量数据。</li>
<li>methods: 我们提出了一种基于变化点检测的数据驱动方法，通过梯度下降学习 poste-outage 分布的参数，但是直接使用梯度下降会存在可行性问题。我们解决这问题 by adding a Bregman divergence constraint to control the trajectory of the parameter updates。</li>
<li>results: 我们使用了多个代表性的分布网络和实际的荷载 profilestest our approach with 17 outage configurations, and the results show that we can detect and localize the outage in a timely manner with only voltage magnitudes and without assuming a prior knowledge of outage patterns.<details>
<summary>Abstract</summary>
Line outage identification in distribution grids is essential for sustainable grid operation. In this work, we propose a practical yet robust detection approach that utilizes only readily available voltage magnitudes, eliminating the need for costly phase angles or power flow data. Given the sensor data, many existing detection methods based on change-point detection require prior knowledge of outage patterns, which are unknown for real-world outage scenarios. To remove this impractical requirement, we propose a data-driven method to learn the parameters of the post-outage distribution through gradient descent. However, directly using gradient descent presents feasibility issues. To address this, we modify our approach by adding a Bregman divergence constraint to control the trajectory of the parameter updates, which eliminates the feasibility problems. As timely operation is the key nowadays, we prove that the optimal parameters can be learned with convergence guarantees via leveraging the statistical and physical properties of voltage data. We evaluate our approach using many representative distribution grids and real load profiles with 17 outage configurations. The results show that we can detect and localize the outage in a timely manner with only voltage magnitudes and without assuming a prior knowledge of outage patterns.
</details>
<details>
<summary>摘要</summary>
distribution 网格中的线路停机标识是可持续的网格运行的关键。在这种工作中，我们提出了一种实用又可靠的检测方法，只需利用 readily available 电压大小，不需要成本的相位角或电力流数据。给定感知数据，许多现有的检测方法基于变化点检测需要先知道停机模式，这些模式在实际停机场景中是未知的。为了解除这种不实际的要求，我们提出了一种数据驱动的方法，通过梯度下降来学习停机后的分布参数。然而，直接使用梯度下降存在可行性问题。为解决这个问题，我们修改了我们的方法，添加了布雷格曼分布约束来控制参数更新的轨迹，这样消除了可行性问题。由于快速操作是当今关键，我们证明可以在有 statistically 和物理性质的电压数据的基础上快速学习优化参数，并且有 convergence guarantees。我们使用了多个代表性的分布网格和真实的负荷 profiles，并对 17 个停机配置进行了评估。结果表明，我们可以在有 voltage magnitudes 和不假设停机模式的情况下，及时检测和地点化停机。
</details></li>
</ul>
<hr>
<h2 id="Nonlinear-Granger-Causality-using-Kernel-Ridge-Regression"><a href="#Nonlinear-Granger-Causality-using-Kernel-Ridge-Regression" class="headerlink" title="Nonlinear Granger Causality using Kernel Ridge Regression"></a>Nonlinear Granger Causality using Kernel Ridge Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05107">http://arxiv.org/abs/2309.05107</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/WojtekFulmyk/mlcausality-krr-paper-replication">https://github.com/WojtekFulmyk/mlcausality-krr-paper-replication</a></li>
<li>paper_authors: Wojciech “Victor” Fulmyk</li>
<li>For:  Identifying nonlinear Granger causal relationships* Methods:  Utilizes a flexible plug-in architecture with any nonlinear regressor, and kernel ridge regression with radial basis function kernel* Results:  Achieves competitive AUC scores, more finely calibrated $p$-values, and significantly reduced computation times compared to existing algorithms.<details>
<summary>Abstract</summary>
I introduce a novel algorithm and accompanying Python library, named mlcausality, designed for the identification of nonlinear Granger causal relationships. This novel algorithm uses a flexible plug-in architecture that enables researchers to employ any nonlinear regressor as the base prediction model. Subsequently, I conduct a comprehensive performance analysis of mlcausality when the prediction regressor is the kernel ridge regressor with the radial basis function kernel. The results demonstrate that mlcausality employing kernel ridge regression achieves competitive AUC scores across a diverse set of simulated data. Furthermore, mlcausality with kernel ridge regression yields more finely calibrated $p$-values in comparison to rival algorithms. This enhancement enables mlcausality to attain superior accuracy scores when using intuitive $p$-value-based thresholding criteria. Finally, mlcausality with the kernel ridge regression exhibits significantly reduced computation times compared to existing nonlinear Granger causality algorithms. In fact, in numerous instances, this innovative approach achieves superior solutions within computational timeframes that are an order of magnitude shorter than those required by competing algorithms.
</details>
<details>
<summary>摘要</summary>
我引入了一种新的算法和 accompanying Python 库，名为 mlcausality，用于非线性格兰GER causal 关系的标识。这种新算法使用一种灵活的插件架构，允许研究人员使用任何非线性预测模型作为基础预测模型。然后，我进行了对 mlcausality 使用 kernel ridge 回归时的性能分析。结果表明，mlcausality 使用 kernel ridge 回归可以在一个多样化的 simulated 数据集中实现竞争力强的 AUC 分数。此外，mlcausality 使用 kernel ridge 回归可以获得更细化的 $p$-值，比其他算法更加精准。这种改进使得 mlcausality 可以在使用直观 $p$-值 基于的阈值标准下达到更高的准确率。最后，mlcausality 使用 kernel ridge 回归可以在许多情况下实现比现有的非线性格兰GER causal 关系算法更快的计算速度，并且在一些情况下可以达到对抗算法的一个阶段的计算时间。
</details></li>
</ul>
<hr>
<h2 id="Convex-Q-Learning-in-a-Stochastic-Environment-Extended-Version"><a href="#Convex-Q-Learning-in-a-Stochastic-Environment-Extended-Version" class="headerlink" title="Convex Q Learning in a Stochastic Environment: Extended Version"></a>Convex Q Learning in a Stochastic Environment: Extended Version</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05105">http://arxiv.org/abs/2309.05105</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fan Lu, Sean Meyn</li>
<li>for: 这篇论文是关于Markov决策过程中的凸Q学习，使用函数近似。</li>
<li>methods: 论文使用了一种凸 программирова的关键性下降法，基于Manne所提出的线性程序Characterization of Optimal Control的准确矩阵。</li>
<li>results: 主要贡献包括：(1) 凸程序relaxation的性质和Q学习的关系; (2) 一种直接的模型自由方法，可以准确地approximate凸程序; (3) 新的分析技术，可以确定模型的收敛速率。<details>
<summary>Abstract</summary>
The paper introduces the first formulation of convex Q-learning for Markov decision processes with function approximation. The algorithms and theory rest on a relaxation of a dual of Manne's celebrated linear programming characterization of optimal control. The main contributions firstly concern properties of the relaxation, described as a deterministic convex program: we identify conditions for a bounded solution, and a significant relationship between the solution to the new convex program, and the solution to standard Q-learning. The second set of contributions concern algorithm design and analysis: (i) A direct model-free method for approximating the convex program for Q-learning shares properties with its ideal. In particular, a bounded solution is ensured subject to a simple property of the basis functions; (ii) The proposed algorithms are convergent and new techniques are introduced to obtain the rate of convergence in a mean-square sense; (iii) The approach can be generalized to a range of performance criteria, and it is found that variance can be reduced by considering ``relative'' dynamic programming equations; (iv) The theory is illustrated with an application to a classical inventory control problem.
</details>
<details>
<summary>摘要</summary>
文章介绍了第一种凸Q学习方法 дляMarkov决策过程中的函数近似。算法和理论基于一种缓和的 dual Manne的线性程序优化 caracterization的relaxation。文章的主要贡献包括：1. 凸程Program的属性：我们确定了一个凸程Program的解是否 bounded，以及它与标准Q学习解的关系。2. 算法设计和分析：（i）一种直接的模型自由方法，可以近似凸程Program，并且具有相似的性质， garantizing a bounded solution subject to a simple property of the basis functions。（ii）提出的算法是 converges，并且引入了新的技术来确定 Mean-square convergence rate。（iii）方法可以扩展到多种性能标准，并且发现可以降低差异的方法是考虑“相对”动态程序方程。（iv）理论通过一个 classical inventory control problem的应用得到了证明。
</details></li>
</ul>
<hr>
<h2 id="Is-Learning-in-Biological-Neural-Networks-based-on-Stochastic-Gradient-Descent-An-analysis-using-stochastic-processes"><a href="#Is-Learning-in-Biological-Neural-Networks-based-on-Stochastic-Gradient-Descent-An-analysis-using-stochastic-processes" class="headerlink" title="Is Learning in Biological Neural Networks based on Stochastic Gradient Descent? An analysis using stochastic processes"></a>Is Learning in Biological Neural Networks based on Stochastic Gradient Descent? An analysis using stochastic processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05102">http://arxiv.org/abs/2309.05102</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sören Christensen, Jan Kallsen</li>
<li>for: 本研究探讨了生物神经网络（BNN）中学习的不同方式，以及人工神经网络（ANN）中学习的不同方式之间的区别。</li>
<li>methods: 本研究使用了一种抽象的概率模型来研究BNN中的超visum学习。</li>
<li>results: 研究发现，在每次学习机会中，多个本地更新都会导致一个梯度步骤出现，这 suggetssthat stochastic gradient descent可能会在BNN中进行优化。<details>
<summary>Abstract</summary>
In recent years, there has been an intense debate about how learning in biological neural networks (BNNs) differs from learning in artificial neural networks. It is often argued that the updating of connections in the brain relies only on local information, and therefore a stochastic gradient-descent type optimization method cannot be used. In this paper, we study a stochastic model for supervised learning in BNNs. We show that a (continuous) gradient step occurs approximately when each learning opportunity is processed by many local updates. This result suggests that stochastic gradient descent may indeed play a role in optimizing BNNs.
</details>
<details>
<summary>摘要</summary>
近年来，有一些研究者提出了关于生物神经网络（BNN）学习方式与人工神经网络（ANN）之间的区别。一般认为，大脑中的连接更新受到本地信息的限制，因此无法使用渐进式梯度下降优化方法。本文研究了BNN中的抽象学习模型。我们发现，在每次学习机会处理时，多个本地更新发生 approximate gradient step。这一结果表明，渐进式梯度下降可能在BNN中发挥作用。
</details></li>
</ul>
<hr>
<h2 id="A-Deep-Dive-into-Sleep-Single-Channel-EEG-Based-Sleep-Stage-Classification-with-Model-Interpretability"><a href="#A-Deep-Dive-into-Sleep-Single-Channel-EEG-Based-Sleep-Stage-Classification-with-Model-Interpretability" class="headerlink" title="A Deep Dive into Sleep: Single-Channel EEG-Based Sleep Stage Classification with Model Interpretability"></a>A Deep Dive into Sleep: Single-Channel EEG-Based Sleep Stage Classification with Model Interpretability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07156">http://arxiv.org/abs/2309.07156</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/suvadeepmaiti/EEG_Sleep_Stage_classification">https://github.com/suvadeepmaiti/EEG_Sleep_Stage_classification</a></li>
<li>paper_authors: Shivam Sharma, Suvadeep Maiti, S. Mythirayee, Srijithesh Rajendran, Bapi Raju</li>
<li>for: 这个研究是为了开发一个基于单通道EEG的睡眠阶段分类方法。</li>
<li>methods: 本研究使用了一个SE-ResNet-Bi-LSTM架构，包括两个基本元素：一个特征提取器使用SE-ResNet，以及一个时间上下文编码器使用堆叠Bi-LSTM单元。</li>
<li>results: 本研究在三个不同的数据集上进行了严格的评估，包括SLeepEDF-20、SleepEDF-78和SHHS数据集。结果显示，我们的方法在这三个数据集上取得了高度的精度和macro-F1分数（87.5%, 83.9%, 87.8%和82.5, 78.9, 81.9）。此外，我们还引入了1D-GradCAM可视化方法，帮助理解模型在睡眠阶段分类过程中的决策过程。<details>
<summary>Abstract</summary>
Sleep, a fundamental physiological process, occupies a significant portion of our lives. Accurate classification of sleep stages serves as a crucial tool for evaluating sleep quality and identifying probable sleep disorders. This work introduces a novel methodology that utilises a SE-Resnet-Bi-LSTM architecture to classify sleep into five separate stages. The classification process is based on the analysis of single-channel electroencephalograms (EEGs). The framework that has been suggested consists of two fundamental elements: a feature extractor that utilises SE-ResNet, and a temporal context encoder that use stacks of Bi-LSTM units.The effectiveness of our approach is substantiated by thorough assessments conducted on three different datasets, namely SLeepEDF-20, SleepEDF-78, and SHHS. Significantly, our methodology attains notable levels of accuracy, specifically 87.5\%, 83.9\%, and 87.8\%, along with macro-F1 scores of 82.5, 78.9, and 81.9 for the corresponding datasets. Notably, we introduce the utilization of 1D-GradCAM visualization to shed light on the decision-making process of our model in the realm of sleep stage classification. This visualization method not only provides valuable insights into the model's classification rationale but also aligns its outcomes with the annotations made by sleep experts. One notable feature of our research is the integration of an expedited training approach, which effectively preserves the model's resilience in terms of performance. The experimental evaluations conducted provide a comprehensive evaluation of the effectiveness of our proposed model in comparison to existing approaches, highlighting its potential for practical applications.
</details>
<details>
<summary>摘要</summary>
睡眠是生物体的基本生理过程，占据了我们生活的一大部分。准确地分类睡眠阶段是评估睡眠质量的重要工具，并可以识别可能的睡眠障碍。本文提出了一种新的方法，使用SE-ResNet-Bi-LSTM架构来分类睡眠为五个不同阶段。该分类过程基于单通道电enzephalogram (EEG) 的分析。我们提出的框架包括两个基本元素：一个特征提取器，使用 SE-ResNet，以及一个时间上下文编码器，使用堆栈的 Bi-LSTM 单元。我们的方法在三个不同的数据集上进行了系统性的评估，即SLeepEDF-20、SleepEDF-78和SHHS。结果显示，我们的方法在这些数据集上达到了remarkable的准确率和macro-F1分数，具体数据如下：87.5%、83.9%和87.8%，以及macro-F1分数分别为82.5、78.9和81.9。值得一提的是，我们首次在睡眠阶段分类中引入了1D-GradCAM视觉化方法，以便了解模型在哪些情况下进行分类的决策过程。这种视觉化方法不仅提供了模型分类的价值信息，还与睡眠专家的注释相匹配。我们的研究还 интегрирова了一种加速训练方法，以保持模型在性能上的稳定性。实验评估表明，我们提出的模型在现有方法相比有更好的实际应用前景。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-conformal-classification-with-noisy-labels"><a href="#Adaptive-conformal-classification-with-noisy-labels" class="headerlink" title="Adaptive conformal classification with noisy labels"></a>Adaptive conformal classification with noisy labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05092">http://arxiv.org/abs/2309.05092</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/msesia/conformal-label-noise">https://github.com/msesia/conformal-label-noise</a></li>
<li>paper_authors: Matteo Sesia, Y. X. Rachel Wang, Xin Tong</li>
<li>for: 这 paper 是为了开发一种能够自动适应Random label contamination的 conformal prediction 方法，以提供更加信息强的预测集和更强的覆盖保证，比对state-of-the-art方法更高效。</li>
<li>methods: 这 paper 使用了一种精确的理论 caracterization 来描述标签污染的影响，并通过新的 calibration 算法来让这种影响变得可行。这种解决方案 flexible ，可以利用不同的标签污染过程的假设，而不需要关于数据分布或机器学习分类器的知识。</li>
<li>results: 这 paper 通过了广泛的 simulations 和 CIFAR-10H 图像数据集的应用，证明了其方法的优势。<details>
<summary>Abstract</summary>
This paper develops novel conformal prediction methods for classification tasks that can automatically adapt to random label contamination in the calibration sample, enabling more informative prediction sets with stronger coverage guarantees compared to state-of-the-art approaches. This is made possible by a precise theoretical characterization of the effective coverage inflation (or deflation) suffered by standard conformal inferences in the presence of label contamination, which is then made actionable through new calibration algorithms. Our solution is flexible and can leverage different modeling assumptions about the label contamination process, while requiring no knowledge about the data distribution or the inner workings of the machine-learning classifier. The advantages of the proposed methods are demonstrated through extensive simulations and an application to object classification with the CIFAR-10H image data set.
</details>
<details>
<summary>摘要</summary>
这个论文开发了一种新的准确预测方法，用于Classification任务，可以自动适应随机标签污染的校准样本，以便生成更加信息强的预测集，与现有方法相比具有更强的覆盖保证。这种方法基于标准准确推理中对标签污染的精确理论 caracterization，然后通过新的校准算法来实现。我们的解决方案 flexible，可以利用不同的标签污染过程的模型假设，而不需要关于数据分布或机器学习分类器的知识。我们的优点在 simulate 和对 CIFAR-10H 图像数据集进行应用中得到了证明。
</details></li>
</ul>
<hr>
<h2 id="A-supervised-generative-optimization-approach-for-tabular-data"><a href="#A-supervised-generative-optimization-approach-for-tabular-data" class="headerlink" title="A supervised generative optimization approach for tabular data"></a>A supervised generative optimization approach for tabular data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05079">http://arxiv.org/abs/2309.05079</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fadi Hamad, Shinpei Nakamura-Sakai, Saheed Obitayo, Vamsi K. Potluru</li>
<li>for: 本研究旨在提供一种基于supervised learning的synthetic data生成框架，以满足金融机构对具有特定任务和数据集的数据生成需求。</li>
<li>methods: 该框架 integra supervised component，专门针对特定下游任务进行tailoring，并使用meta-学习方法来学习优化现有synthetic数据集的混合分布。</li>
<li>results: 该框架可以生成高质量的synthetic数据，并且可以根据下游任务进行tailoring，从而提高数据生成的效果和可靠性。<details>
<summary>Abstract</summary>
Synthetic data generation has emerged as a crucial topic for financial institutions, driven by multiple factors, such as privacy protection and data augmentation. Many algorithms have been proposed for synthetic data generation but reaching the consensus on which method we should use for the specific data sets and use cases remains challenging. Moreover, the majority of existing approaches are ``unsupervised'' in the sense that they do not take into account the downstream task. To address these issues, this work presents a novel synthetic data generation framework. The framework integrates a supervised component tailored to the specific downstream task and employs a meta-learning approach to learn the optimal mixture distribution of existing synthetic distributions.
</details>
<details>
<summary>摘要</summary>
文本翻译为简化中文：</SYS>现代数据生成技术已成为金融机构关键话题，受多种因素驱动，如隐私保护和数据扩展。许多算法已经提出用于数据生成，但确定特定数据集和用例中使用哪种方法仍然是挑战。此外，大多数现有方法是“无监督的”，即不考虑下游任务。为解决这些问题，本文提出了一种新的数据生成框架。该框架 integrate 一种监督分布 tailored 特定下游任务，并使用 meta-学习方法学习最佳混合分布。
</details></li>
</ul>
<hr>
<h2 id="Generalization-error-bounds-for-iterative-learning-algorithms-with-bounded-updates"><a href="#Generalization-error-bounds-for-iterative-learning-algorithms-with-bounded-updates" class="headerlink" title="Generalization error bounds for iterative learning algorithms with bounded updates"></a>Generalization error bounds for iterative learning algorithms with bounded updates</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05077">http://arxiv.org/abs/2309.05077</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingwen Fu, Nanning Zheng</li>
<li>for: 本研究探讨了iterative learning算法对非凸损函数的泛化特性，利用信息学技术。我们的主要贡献是对 bounded updates 算法的泛化错误 bound，超越了先前的works只关注 Stochastic Gradient Descent (SGD) 的情况。</li>
<li>methods: 我们的方法包括两大新特点：1) 将更新的不确定性重新表述为 mutual information，提供了新的视角；2) 使用 variance decomposition technique 来分解 iteration 之间的信息，使 surrogate process 更加简单。</li>
<li>results: 我们对不同设置下的泛化 bound 进行分析，并在模型维度增加时与训练样本数量相同时显示出改进的 bound。此外，我们还检验了在大型自然语言模型中观察到的扩展行为。最终，我们的工作为实际泛化理论的发展做出了一个更一步。<details>
<summary>Abstract</summary>
This paper explores the generalization characteristics of iterative learning algorithms with bounded updates for non-convex loss functions, employing information-theoretic techniques. Our key contribution is a novel bound for the generalization error of these algorithms with bounded updates, extending beyond the scope of previous works that only focused on Stochastic Gradient Descent (SGD). Our approach introduces two main novelties: 1) we reformulate the mutual information as the uncertainty of updates, providing a new perspective, and 2) instead of using the chaining rule of mutual information, we employ a variance decomposition technique to decompose information across iterations, allowing for a simpler surrogate process. We analyze our generalization bound under various settings and demonstrate improved bounds when the model dimension increases at the same rate as the number of training data samples. To bridge the gap between theory and practice, we also examine the previously observed scaling behavior in large language models. Ultimately, our work takes a further step for developing practical generalization theories.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>We reformulate the mutual information as a measure of the uncertainty of updates, providing a new perspective on the problem.2. Instead of using the chaining rule of mutual information, we employ a variance decomposition technique to decompose information across iterations, allowing for a simpler surrogate process.We analyze our generalization bound under various settings and show that it improves as the model dimension increases at the same rate as the number of training data samples. To bridge the gap between theory and practice, we also examine the previously observed scaling behavior in large language models. Our work represents a significant step forward in developing practical generalization theories.</details></li>
</ol>
<hr>
<h2 id="Mutation-based-Fault-Localization-of-Deep-Neural-Networks"><a href="#Mutation-based-Fault-Localization-of-Deep-Neural-Networks" class="headerlink" title="Mutation-based Fault Localization of Deep Neural Networks"></a>Mutation-based Fault Localization of Deep Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05067">http://arxiv.org/abs/2309.05067</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ali-ghanbari/deepmufl-ase-2023">https://github.com/ali-ghanbari/deepmufl-ase-2023</a></li>
<li>paper_authors: Ali Ghanbari, Deepak-George Thomas, Muhammad Arbab Arshad, Hridesh Rajan</li>
<li>for: 本研究旨在提高深度神经网络（DNN）系统的可靠性，特别是在安全关键领域。</li>
<li>methods: 本文提出了一种新的技术——深度瑞夫特（DeepMUFL），用于检测DNN模型中的错误。</li>
<li>results: 对于109个Stack Overflow上的错误集，深度瑞夫特能够检测出53个错误，比州态艺术的静态和动态DNN错误检测系统高效。此外，我们发现可以通过选择突变来减少检测时间，但是产生的 bug 检测率下降了7.55%。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) are susceptible to bugs, just like other types of software systems. A significant uptick in using DNN, and its applications in wide-ranging areas, including safety-critical systems, warrant extensive research on software engineering tools for improving the reliability of DNN-based systems. One such tool that has gained significant attention in the recent years is DNN fault localization. This paper revisits mutation-based fault localization in the context of DNN models and proposes a novel technique, named deepmufl, applicable to a wide range of DNN models. We have implemented deepmufl and have evaluated its effectiveness using 109 bugs obtained from StackOverflow. Our results show that deepmufl detects 53/109 of the bugs by ranking the buggy layer in top-1 position, outperforming state-of-the-art static and dynamic DNN fault localization systems that are also designed to target the class of bugs supported by deepmufl. Moreover, we observed that we can halve the fault localization time for a pre-trained model using mutation selection, yet losing only 7.55% of the bugs localized in top-1 position.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SA-Solver-Stochastic-Adams-Solver-for-Fast-Sampling-of-Diffusion-Models"><a href="#SA-Solver-Stochastic-Adams-Solver-for-Fast-Sampling-of-Diffusion-Models" class="headerlink" title="SA-Solver: Stochastic Adams Solver for Fast Sampling of Diffusion Models"></a>SA-Solver: Stochastic Adams Solver for Fast Sampling of Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05019">http://arxiv.org/abs/2309.05019</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuchen Xue, Mingyang Yi, Weijian Luo, Shifeng Zhang, Jiacheng Sun, Zhenguo Li, Zhi-Ming Ma</li>
<li>for: 这个论文主要针对Diffusion Probabilistic Models（DPMs）的生成任务进行了广泛的分析和优化。</li>
<li>methods: 论文使用了两种方法进行随机抽样：variance-controlled diffusion SDE和线性多步SDE解决方法。</li>
<li>results: 对于几步抽样，SA-Solver可以实现改进或相当于现有state-of-the-art抽样方法的性能，并在适当的函数评估次数（NFEs）下达到了SOTA FID分数在大量的benchmark数据集上。<details>
<summary>Abstract</summary>
Diffusion Probabilistic Models (DPMs) have achieved considerable success in generation tasks. As sampling from DPMs is equivalent to solving diffusion SDE or ODE which is time-consuming, numerous fast sampling methods built upon improved differential equation solvers are proposed. The majority of such techniques consider solving the diffusion ODE due to its superior efficiency. However, stochastic sampling could offer additional advantages in generating diverse and high-quality data. In this work, we engage in a comprehensive analysis of stochastic sampling from two aspects: variance-controlled diffusion SDE and linear multi-step SDE solver. Based on our analysis, we propose SA-Solver, which is an improved efficient stochastic Adams method for solving diffusion SDE to generate data with high quality. Our experiments show that SA-Solver achieves: 1) improved or comparable performance compared with the existing state-of-the-art sampling methods for few-step sampling; 2) SOTA FID scores on substantial benchmark datasets under a suitable number of function evaluations (NFEs).
</details>
<details>
<summary>摘要</summary>
Diffusion Probabilistic Models (DPMs) 已经取得了较大的成功在生成任务中。由于从 DPMs 中采样是等价于解决 diffusion SDE 或 ODE，这些问题需要很长时间，因此有许多快速采样技术被建议。大多数这些技术是解决 diffusion ODE，因为它的效率更高。然而，随机采样可以提供额外的优势，如生成多样化和高质量的数据。在这项工作中，我们进行了Diffusion SDE 采样的两个方面的全面分析：变量控制的 diffusion SDE 和线性多步 SDE 解决器。基于我们的分析，我们提出了 SA-Solver，它是一种改进的效率随机阿达姆斯方法，用于解决 diffusion SDE，以生成高质量的数据。我们的实验表明，SA-Solver 可以：1）与现有状态的艺术方法相比，在几步采样中达到相同或更高的性能; 2）在适当的函数评估次数（NFEs）下，在大量 benchmark 数据集上达到 SOTA FID 分数。
</details></li>
</ul>
<hr>
<h2 id="Computational-Approaches-for-Predicting-Drug-Disease-Associations-A-Comprehensive-Review"><a href="#Computational-Approaches-for-Predicting-Drug-Disease-Associations-A-Comprehensive-Review" class="headerlink" title="Computational Approaches for Predicting Drug-Disease Associations: A Comprehensive Review"></a>Computational Approaches for Predicting Drug-Disease Associations: A Comprehensive Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06388">http://arxiv.org/abs/2309.06388</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chunyan Ao, Zhichao Xiao, Lixin Guan, Liang Yu</li>
<li>For: 本研究旨在探讨计算方法对药物与疾病关系的预测，以优化药物开发过程中的成本、时间和风险。* Methods: 本文分析了多种计算方法，包括神经网络算法、矩阵算法、推荐算法、链接基于的理由算法和文本挖掘和 semantics 理解算法，以预测药物与疾病关系。* Results: 本文对现有的药物与疾病关系预测算法进行比较，并探讨了现有挑战和未来发展前景。<details>
<summary>Abstract</summary>
In recent decades, traditional drug research and development have been facing challenges such as high cost, long timelines, and high risks. To address these issues, many computational approaches have been suggested for predicting the relationship between drugs and diseases through drug repositioning, aiming to reduce the cost, development cycle, and risks associated with developing new drugs. Researchers have explored different computational methods to predict drug-disease associations, including drug side effects-disease associations, drug-target associations, and miRNAdisease associations. In this comprehensive review, we focus on recent advances in predicting drug-disease association methods for drug repositioning. We first categorize these methods into several groups, including neural network-based algorithms, matrixbased algorithms, recommendation algorithms, link-based reasoning algorithms, and text mining and semantic reasoning. Then, we compare the prediction performance of existing drug-disease association prediction algorithms. Lastly, we delve into the present challenges and future prospects concerning drug-disease associations.
</details>
<details>
<summary>摘要</summary>
现代药物研发面临高成本、长时间和高风险的挑战。为解决这些问题，许多计算方法被建议用于预测药物和疾病之间的关系，以减少开发新药物的成本、开发周期和风险。研究人员已经探索了不同的计算方法来预测药物疾病关系，包括药物副作用疾病关系、药物Target关系和miRNA疾病关系。在这篇概述中，我们关注最近的药物疾病关系预测方法的进步。我们首先将这些方法分为了一些组，包括神经网络基于的算法、矩阵基于的算法、推荐算法、链接基于的理由算法和文本挖掘和 semantic reasoning。然后，我们比较了现有的药物疾病关系预测算法的预测性能。最后，我们探讨了药物疾病关系的当前挑战和未来前途。
</details></li>
</ul>
<hr>
<h2 id="Linear-Speedup-of-Incremental-Aggregated-Gradient-Methods-on-Streaming-Data"><a href="#Linear-Speedup-of-Incremental-Aggregated-Gradient-Methods-on-Streaming-Data" class="headerlink" title="Linear Speedup of Incremental Aggregated Gradient Methods on Streaming Data"></a>Linear Speedup of Incremental Aggregated Gradient Methods on Streaming Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04980">http://arxiv.org/abs/2309.04980</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaolu Wang, Cheng Jin, Hoi-To Wai, Yuantao Gu</li>
<li>for: 这种研究是为了研究大规模分布式优化中的增量累加梯度（IAG）方法。</li>
<li>methods: 这种方法适合参数服务器架构，因为它可以轻松地将工作者可能停止的梯度集成。</li>
<li>results: 对于具有流动数据的 случа子，这种方法可以实现线性的速度提升，即使工作者们在更新频繁 enough。我们证明了在每个工作者更新一个数据点后，解的平均方差衰逝为 O((1+T)&#x2F;(nt)),其中 n 是工作者数量，t 是迭代次数，T&#x2F;n 是工作者更新频率。我们的分析包括处理受到停止梯度的条件预期以及延迟和噪声项的重叠系统，这些是 IAG 类型算法的分析中的新特点。<details>
<summary>Abstract</summary>
This paper considers a type of incremental aggregated gradient (IAG) method for large-scale distributed optimization. The IAG method is well suited for the parameter server architecture as the latter can easily aggregate potentially staled gradients contributed by workers. Although the convergence of IAG in the case of deterministic gradient is well known, there are only a few results for the case of its stochastic variant based on streaming data. Considering strongly convex optimization, this paper shows that the streaming IAG method achieves linear speedup when the workers are updating frequently enough, even if the data sample distribution across workers are heterogeneous. We show that the expected squared distance to optimal solution decays at O((1+T)/(nt)), where $n$ is the number of workers, t is the iteration number, and T/n is the update frequency of workers. Our analysis involves careful treatments of the conditional expectations with staled gradients and a recursive system with both delayed and noise terms, which are new to the analysis of IAG-type algorithms. Numerical results are presented to verify our findings.
</details>
<details>
<summary>摘要</summary>
This paper focuses on strongly convex optimization and shows that the streaming IAG method achieves linear speedup when workers update frequently enough, even if the data sample distribution across workers is heterogeneous. Our analysis takes into account careful treatments of conditional expectations with stale gradients and a recursive system with both delayed and noise terms, which are new to the analysis of IAG-type algorithms.The expected squared distance to the optimal solution decays at O((1+T)/(nt)), where n is the number of workers, t is the iteration number, and T/n is the update frequency of workers. Numerical results are presented to verify our findings.
</details></li>
</ul>
<hr>
<h2 id="LMBiS-Net-A-Lightweight-Multipath-Bidirectional-Skip-Connection-based-CNN-for-Retinal-Blood-Vessel-Segmentation"><a href="#LMBiS-Net-A-Lightweight-Multipath-Bidirectional-Skip-Connection-based-CNN-for-Retinal-Blood-Vessel-Segmentation" class="headerlink" title="LMBiS-Net: A Lightweight Multipath Bidirectional Skip Connection based CNN for Retinal Blood Vessel Segmentation"></a>LMBiS-Net: A Lightweight Multipath Bidirectional Skip Connection based CNN for Retinal Blood Vessel Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04968">http://arxiv.org/abs/2309.04968</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mufassir M. Abbasi, Shahzaib Iqbal, Asim Naveed, Tariq M. Khan, Syed S. Naqvi, Wajeeha Khalid</li>
<li>for: 这个研究是为了提出一个高速和高精度的眼睛病变检测方法，以帮助诊断和治疗眼睛疾病。</li>
<li>methods: 这个方法使用了一个名为LMBiS-Net的轻量级像素级卷积神经网，并且使用了多路特征提取对象和对向 skip connections，以提高分类精度。</li>
<li>results: 根据实验结果显示，LMBiS-Net可以实现高速和高精度的眼睛影像分类，并且具有较高的一致性和可靠性。<details>
<summary>Abstract</summary>
Blinding eye diseases are often correlated with altered retinal morphology, which can be clinically identified by segmenting retinal structures in fundus images. However, current methodologies often fall short in accurately segmenting delicate vessels. Although deep learning has shown promise in medical image segmentation, its reliance on repeated convolution and pooling operations can hinder the representation of edge information, ultimately limiting overall segmentation accuracy. In this paper, we propose a lightweight pixel-level CNN named LMBiS-Net for the segmentation of retinal vessels with an exceptionally low number of learnable parameters \textbf{(only 0.172 M)}. The network used multipath feature extraction blocks and incorporates bidirectional skip connections for the information flow between the encoder and decoder. Additionally, we have optimized the efficiency of the model by carefully selecting the number of filters to avoid filter overlap. This optimization significantly reduces training time and enhances computational efficiency. To assess the robustness and generalizability of LMBiS-Net, we performed comprehensive evaluations on various aspects of retinal images. Specifically, the model was subjected to rigorous tests to accurately segment retinal vessels, which play a vital role in ophthalmological diagnosis and treatment. By focusing on the retinal blood vessels, we were able to thoroughly analyze the performance and effectiveness of the LMBiS-Net model. The results of our tests demonstrate that LMBiS-Net is not only robust and generalizable but also capable of maintaining high levels of segmentation accuracy. These characteristics highlight the potential of LMBiS-Net as an efficient tool for high-speed and accurate segmentation of retinal images in various clinical applications.
</details>
<details>
<summary>摘要</summary>
盲目疾病常与改变 RETINAL 结构相关，可以在背部图像中进行临床识别。然而，现有方法通常不够准确地分割细血管。深度学习在医疗图像分割方面表现出了承诺，但是它的依赖于重复的卷积和抽取操作可能会阻碍缝合信息的表现，从而限制总的分割精度。在这篇论文中，我们提出了一个轻量级的像素级 CNN 名为 LMBiS-Net，用于分割背部图像中的血管。该网络使用多路特征提取块和双向跳转连接，以便在编码和解码器之间进行信息流。此外，我们优化了模型的效率，通过精心选择缺省的缺省数据来避免缺省的过滤重叠。这种优化显著降低了训练时间和计算效率。为评估 LMBiS-Net 模型的稳定性和普适性，我们进行了广泛的评估，包括不同方面的 RETINAL 图像。Specifically，我们将模型测试在精确地分割背部图像中的血管方面，这些血管在眼科诊断和治疗中扮演着关键角色。通过专注于背部血管，我们可以仔细分析 LMBiS-Net 模型的性能和效果。测试结果表明，LMBiS-Net 模型不仅稳定和普适，还能够保持高度的分割精度。这些特点表明 LMBiS-Net 模型具有高速和准确地分割背部图像的能力，这些能力在各种临床应用中具有广泛的应用前景。
</details></li>
</ul>
<hr>
<h2 id="A-multiple-k-means-cluster-ensemble-framework-for-clustering-citation-trajectories"><a href="#A-multiple-k-means-cluster-ensemble-framework-for-clustering-citation-trajectories" class="headerlink" title="A multiple k-means cluster ensemble framework for clustering citation trajectories"></a>A multiple k-means cluster ensemble framework for clustering citation trajectories</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04949">http://arxiv.org/abs/2309.04949</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joyita Chakraborty, Dinesh K. Pradhan, Subrata Nandi</li>
<li>for: 这篇论文的主要目的是探讨文献强度的分布和不同时间间隔的影响。</li>
<li>methods: 这篇论文使用了多尺度整合 clustering 方法，并对不同时间间隔的文献进行分类。</li>
<li>results: 研究发现，文献的强度演变 exhibits 四种不同的趋势，包括 Early Rise Rapid Decline、Early Rise Slow Decline、Delayed Rise No Decline 和 Delayed Rise Slow Decline。这些趋势的发展和衰落时间、累积引用分布以及峰值特征都被重新定义了。<details>
<summary>Abstract</summary>
Citation maturity time varies for different articles. However, the impact of all articles is measured in a fixed window. Clustering their citation trajectories helps understand the knowledge diffusion process and reveals that not all articles gain immediate success after publication. Moreover, clustering trajectories is necessary for paper impact recommendation algorithms. It is a challenging problem because citation time series exhibit significant variability due to non linear and non stationary characteristics. Prior works propose a set of arbitrary thresholds and a fixed rule based approach. All methods are primarily parameter dependent. Consequently, it leads to inconsistencies while defining similar trajectories and ambiguities regarding their specific number. Most studies only capture extreme trajectories. Thus, a generalised clustering framework is required. This paper proposes a feature based multiple k means cluster ensemble framework. 1,95,783 and 41,732 well cited articles from the Microsoft Academic Graph data are considered for clustering short term (10 year) and long term (30 year) trajectories, respectively. It has linear run time. Four distinct trajectories are obtained Early Rise Rapid Decline (2.2%), Early Rise Slow Decline (45%), Delayed Rise No Decline (53%), and Delayed Rise Slow Decline (0.8%). Individual trajectory differences for two different spans are studied. Most papers exhibit Early Rise Slow Decline and Delayed Rise No Decline patterns. The growth and decay times, cumulative citation distribution, and peak characteristics of individual trajectories are redefined empirically. A detailed comparative study reveals our proposed methodology can detect all distinct trajectory classes.
</details>
<details>
<summary>摘要</summary>
“文献成熟时间各不相同，但所有文献的影响都是在固定窗口内测量的。对文献 trajectory 的归一化可以理解知识传播过程，并发现不所有文献在出版后即时获得成功。此外，对 trajectory 的归一化是提出纸影响建议算法的必要condition。但是，由于引用时间序列具有非线性和不稳定的特点，这是一个具有挑战性的问题。先前的研究提出了一些arbitrary 的阈值和固定规则的方法，但这些方法都是具有参数依赖性的。因此，它们会导致对类似 trajectory 的定义不一致和对其具体数量的歧义。大多数研究只 capture 极端 trajectory。因此，一个通用的归一化框架是需要的。本文提出了一种特征基于多种 k-means 集成框架。对于10年和30年的短期和长期 trajectory，分别使用 Microsoft Academic Graph 数据集中的195,783 和41,732 篇著作进行归一化。它具有线性运行时间。我们获得了4种不同的 trajectory：早期快速下降（2.2%）、早期快速下降（45%）、延迟快速下降（53%）和延迟快速下降（0.8%）。我们对不同时间跨度中文章的差异进行了详细研究。大多数文章展现出早期快速下降和延迟快速下降的模式。我们重新定义了文章成长和衰退时间、累积引用分布和峰值特征。与之前的比较研究相比，我们的提出方法可以检测所有不同的 trajectory 类别。”
</details></li>
</ul>
<hr>
<h2 id="Distance-Restricted-Folklore-Weisfeiler-Leman-GNNs-with-Provable-Cycle-Counting-Power"><a href="#Distance-Restricted-Folklore-Weisfeiler-Leman-GNNs-with-Provable-Cycle-Counting-Power" class="headerlink" title="Distance-Restricted Folklore Weisfeiler-Leman GNNs with Provable Cycle Counting Power"></a>Distance-Restricted Folklore Weisfeiler-Leman GNNs with Provable Cycle Counting Power</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04941">http://arxiv.org/abs/2309.04941</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junru Zhou, Jiarui Feng, Xiyuan Wang, Muhan Zhang</li>
<li>For: The paper aims to improve the efficiency and expressive power of graph neural networks (GNNs) for counting certain graph substructures, especially cycles, which is crucial for achieving robust and generalizable performance on molecular tasks.* Methods: The proposed method, $d$-Distance-Restricted FWL(2) GNNs, uses node pairs whose mutual distances are at most $d$ as the units for message passing to balance the expressive power and complexity. This approach avoids the expensive subgraph extraction operations in subgraph GNNs, making both the time and space complexity lower.* Results: The paper theoretically shows that the discriminative power of $d$-DRFWL(2) GNNs strictly increases as $d$ increases. Moreover, the model has provably strong cycle counting power even with $d&#x3D;2$, being able to count all 3, 4, 5, 6-cycles, which is crucial for achieving robust and generalizable performance on molecular tasks. Experiments on both synthetic datasets and molecular datasets verify the theory.<details>
<summary>Abstract</summary>
The ability of graph neural networks (GNNs) to count certain graph substructures, especially cycles, is important for the success of GNNs on a wide range of tasks. It has been recently used as a popular metric for evaluating the expressive power of GNNs. Many of the proposed GNN models with provable cycle counting power are based on subgraph GNNs, i.e., extracting a bag of subgraphs from the input graph, generating representations for each subgraph, and using them to augment the representation of the input graph. However, those methods require heavy preprocessing, and suffer from high time and memory costs. In this paper, we overcome the aforementioned limitations of subgraph GNNs by proposing a novel class of GNNs -- $d$-Distance-Restricted FWL(2) GNNs, or $d$-DRFWL(2) GNNs. $d$-DRFWL(2) GNNs use node pairs whose mutual distances are at most $d$ as the units for message passing to balance the expressive power and complexity. By performing message passing among distance-restricted node pairs in the original graph, $d$-DRFWL(2) GNNs avoid the expensive subgraph extraction operations in subgraph GNNs, making both the time and space complexity lower. We theoretically show that the discriminative power of $d$-DRFWL(2) GNNs strictly increases as $d$ increases. More importantly, $d$-DRFWL(2) GNNs have provably strong cycle counting power even with $d=2$: they can count all 3, 4, 5, 6-cycles. Since 6-cycles (e.g., benzene rings) are ubiquitous in organic molecules, being able to detect and count them is crucial for achieving robust and generalizable performance on molecular tasks. Experiments on both synthetic datasets and molecular datasets verify our theory. To the best of our knowledge, our model is the most efficient GNN model to date (both theoretically and empirically) that can count up to 6-cycles.
</details>
<details>
<summary>摘要</summary>
граф neural networks (GNNs) 的能力count certain graph substructures, especially cycles, is important for the success of GNNs on a wide range of tasks. It has been recently used as a popular metric for evaluating the expressive power of GNNs. Many of the proposed GNN models with provable cycle counting power are based on subgraph GNNs, i.e., extracting a bag of subgraphs from the input graph, generating representations for each subgraph, and using them to augment the representation of the input graph. However, those methods require heavy preprocessing, and suffer from high time and memory costs. In this paper, we overcome the aforementioned limitations of subgraph GNNs by proposing a novel class of GNNs -- $d$-Distance-Restricted FWL(2) GNNs, or $d$-DRFWL(2) GNNs. $d$-DRFWL(2) GNNs use node pairs whose mutual distances are at most $d$ as the units for message passing to balance the expressive power and complexity. By performing message passing among distance-restricted node pairs in the original graph, $d$-DRFWL(2) GNNs avoid the expensive subgraph extraction operations in subgraph GNNs, making both the time and space complexity lower. We theoretically show that the discriminative power of $d$-DRFWL(2) GNNs strictly increases as $d$ increases. More importantly, $d$-DRFWL(2) GNNs have provably strong cycle counting power even with $d=2$: they can count all 3, 4, 5, 6-cycles. Since 6-cycles (e.g., benzene rings) are ubiquitous in organic molecules, being able to detect and count them is crucial for achieving robust and generalizable performance on molecular tasks. Experiments on both synthetic datasets and molecular datasets verify our theory. To the best of our knowledge, our model is the most efficient GNN model to date (both theoretically and empirically) that can count up to 6-cycles.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/10/cs.LG_2023_09_10/" data-id="cloimipb800o5s488c4sr5h6f" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_09_10" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/10/eess.IV_2023_09_10/" class="article-date">
  <time datetime="2023-09-10T09:00:00.000Z" itemprop="datePublished">2023-09-10</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/10/eess.IV_2023_09_10/">eess.IV - 2023-09-10</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Spatial-Perceptual-Quality-Aware-Adaptive-Volumetric-Video-Streaming"><a href="#Spatial-Perceptual-Quality-Aware-Adaptive-Volumetric-Video-Streaming" class="headerlink" title="Spatial Perceptual Quality Aware Adaptive Volumetric Video Streaming"></a>Spatial Perceptual Quality Aware Adaptive Volumetric Video Streaming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05026">http://arxiv.org/abs/2309.05026</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xi Wang, Wei Liu, Huitong Liu, Peng Yang</li>
<li>for: 本研究旨在探讨6自由度空间浏览所引入的观看距离对用户感知质量的影响，以及一种基于人类视觉能力限制的视觉含量模型，以满足6DoF浏览期间的空间视觉需求。</li>
<li>methods: 本研究使用了人类视觉能力限制的视觉含量模型，以满足6DoF浏览期间的空间视觉需求。此外，还提出了一种基于用户感知质量的QoE模型，以准确地表示用户在不同观看距离下的感知质量。</li>
<li>results: 实验结果表明，提出的方案可以提高总平均QoE水平，相比现有基eline，提高了26%。<details>
<summary>Abstract</summary>
Volumetric video offers a highly immersive viewing experience, but poses challenges in ensuring quality of experience (QoE) due to its high bandwidth requirements. In this paper, we explore the effect of viewing distance introduced by six degrees of freedom (6DoF) spatial navigation on user's perceived quality. By considering human visual resolution limitations, we propose a visual acuity model that describes the relationship between the virtual viewing distance and the tolerable boundary point cloud density. The proposed model satisfies spatial visual requirements during 6DoF exploration. Additionally, it dynamically adjusts quality levels to balance perceptual quality and bandwidth consumption. Furthermore, we present a QoE model to represent user's perceived quality at different viewing distances precisely. Extensive experimental results demonstrate that, the proposed scheme can effectively improve the overall average QoE by up to 26% over real networks and user traces, compared to existing baselines.
</details>
<details>
<summary>摘要</summary>
三维视频提供了非常深刻的浸没体验，但它带来质量经验（QoE）的挑战，因为它具有高带宽需求。在这篇论文中，我们探索了通过六个自由度（6DoF）空间导航引入的观看距离对用户的感知质量的影响。通过考虑人类视觉限制，我们提出了一个视觉acuity模型，该模型描述虚拟观看距离对tolerable boundary point cloud density的关系。我们的模型满足了在6DoF探索中的空间视觉需求。此外，我们还提出了一个QoE模型，可以准确地表示用户在不同观看距离下的感知质量。我们的方案可以有效地提高总平均QoE，相比现有基elines，提高了26%。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/10/eess.IV_2023_09_10/" data-id="cloimiphk014is4884gj5b42d" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_09_10" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/10/eess.SP_2023_09_10/" class="article-date">
  <time datetime="2023-09-10T08:00:00.000Z" itemprop="datePublished">2023-09-10</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/10/eess.SP_2023_09_10/">eess.SP - 2023-09-10</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Kinematics-Based-Sensor-Fault-Detection-for-Autonomous-Vehicles-Using-Real-Time-Numerical-Differentiation"><a href="#Kinematics-Based-Sensor-Fault-Detection-for-Autonomous-Vehicles-Using-Real-Time-Numerical-Differentiation" class="headerlink" title="Kinematics-Based Sensor Fault Detection for Autonomous Vehicles Using Real-Time Numerical Differentiation"></a>Kinematics-Based Sensor Fault Detection for Autonomous Vehicles Using Real-Time Numerical Differentiation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05158">http://arxiv.org/abs/2309.05158</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shashank Verma, Yousaf Rahman, E. Dogan Sumer, Dennis S. Bernstein</li>
<li>for: 本研究旨在检测和识别汽车上的感测器故障。</li>
<li>methods: 本方法基于地面载荷的六个遥感数据，包括 компас、雷达、加速仪和gyro的测量数据及其 derivates，通过实时数值导函来计算实时错误指标。</li>
<li>results: 实验结果表明，该方法可以准确检测和识别汽车上的感测器故障。<details>
<summary>Abstract</summary>
Sensor fault detection is of extreme importance for ensuring the safe operation of vehicles. This paper introduces a novel approach to detecting and identifying faulty sensors. For ground vehicles confined to the horizontal plane, this technique is based on six kinematics-based error metrics that are computed in real time by using onboard sensor data encompassing compass, radar, rate gyro, and accelerometer measurements as well as their derivatives. Real-time numerical differentiation is performed by applying the adaptive input and state estimation (AIE/ASE) algorithm. Numerical examples are provided to assess the efficacy of the proposed methodology.
</details>
<details>
<summary>摘要</summary>
感测器故障检测对于保证交通工具安全运行至关重要。本文介绍一种新的检测和识别故障感测器的方法。对于在水平面上行驶的地面交通工具，该技术基于六种动力学基础错误指标，通过在board上的感测器数据（ magnetometer、雷达、速度gyro和加速计）以及其导数来计算在实时中。实时数值分析通过应用适应输入和状态估计（AIE/ASE）算法进行。提供数值例子，评估提案的有效性。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Multi-UAV-enabled-Distributed-Sensing-Cooperation-Orchestration-and-Detection-Protocol"><a href="#Multi-UAV-enabled-Distributed-Sensing-Cooperation-Orchestration-and-Detection-Protocol" class="headerlink" title="Multi UAV-enabled Distributed Sensing: Cooperation Orchestration and Detection Protocol"></a>Multi UAV-enabled Distributed Sensing: Cooperation Orchestration and Detection Protocol</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05114">http://arxiv.org/abs/2309.05114</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xavier Alejandro Flores Cabezas, Diana Pamela Moya Osorio, Markku Juntti</li>
<li>for: 这个论文提出了一种基于无人机（UAV）的分布感知框架，用于检测地面目标的位置，并且UAV在半播调制模式下运行。</li>
<li>methods: 该框架使用了Orthogonal Frequency-Division Multiplexing（OFDM）波形检测地面目标，并使用了空间网格方法，将特定区域分割成等大小的细节，然后将每个细节的射频跨section（RCS）联合估算由一个网络的双功能无人机（UAV）。</li>
<li>results:  Monte Carlo simulations 表明，提出的框架可以提高检测精度和分辨率，并且比单一干扰无人机（UAV）标准做法具有更好的可靠性和稳定性。同时，与通用压缩感知（CS）方法相比，该框架具有较少的过载。<details>
<summary>Abstract</summary>
This paper proposes an unmanned aerial vehicle (UAV)-based distributed sensing framework that uses orthogonal frequency-division multiplexing (OFDM) waveforms to detect the position of a ground target, and UAVs operate in half-duplex mode. A spatial grid approach is proposed, where an specific area in the ground is divided into cells of equal size, then the radar cross-section (RCS) of each cell is jointly estimated by a network of dual-function UAVs. For this purpose, three estimation algorithms are proposed employing the maximum likelihood criterion, and digital beamforming is used for the local signal acquisition at the receive UAVs. It is also considered that the coordination, fusion of sensing data, and central estimation is performed at a certain UAV acting as a fusion center (FC). Monte Carlo simulations are performed to obtain the absolute estimation error of the proposed framework. The results show an improved accuracy and resolution by the proposed framework, if compared to a single monostatic UAV benchmark, due to the distributed approach among the UAVs. It is also evidenced that a reduced overhead is obtained when compared to a general compressive sensing (CS) approach.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Strategic-Deployment-of-Swarm-of-UAVs-for-Secure-IoT-Networks"><a href="#Strategic-Deployment-of-Swarm-of-UAVs-for-Secure-IoT-Networks" class="headerlink" title="Strategic Deployment of Swarm of UAVs for Secure IoT Networks"></a>Strategic Deployment of Swarm of UAVs for Secure IoT Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05104">http://arxiv.org/abs/2309.05104</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xavier Alejandro Flores Cabezas, Diana Pamela Moya Osorio</li>
<li>for: 提高未来无线网络的安全性，特别是在互联网物联网（IoT）中的设备采用安全传输。</li>
<li>methods: 利用无人机（UAV）作为空中基站，实现 IoT 网络中节点之间的安全连接。并通过游戏理论和几何优化的工具，实现网络节点协调、UAV 的3D定位和无线电源分配，以提高系统的机密性性能。</li>
<li>results: 比起当前的欢快算法，提案的框架在 IoT 网络中实现了更好的和更高效的机密性性能。<details>
<summary>Abstract</summary>
Security provisioning for low-complex and constrained devices in the Internet of Things (IoT) is exacerbating the concerns for the design of future wireless networks. To unveil the full potential of the sixth generation (6G), it is becoming even more evident that security measurements should be considered at all layers of the network. This work aims to contribute in this direction by investigating the employment of unmanned aerial vehicles (UAVs) for providing secure transmissions in ground IoT networks. Toward this purpose, it is considered that a set of UAVs acting as aerial base stations provide secure connectivity between the network and multiple ground nodes. Then, the association of IoT nodes, the 3D positioning of the UAVs and the power allocation of the UAVs are obtained by leveraging game theoretic and convex optimization-based tools with the goal of improving the secrecy of the system. It is shown that the proposed framework obtains better and more efficient secrecy performance over an IoT network than state-of-the-art greedy algorithms for positioning and association.
</details>
<details>
<summary>摘要</summary>
安全资源分配 для低复杂和受限设备在互联网器物 (IoT) 是加剧未来无线网络设计的担忧。为探索 sixth generation (6G) 的潜力，越来越清楚地示出安全测量应该考虑到网络各层。这项工作想要贡献在这个方向，研究使用无人飞行器 (UAV) 为 IoT 网络提供安全传输。为达到这一目的，假设一组 UAV 作为空中基站，为网络和多个地面节点之间提供安全连接。然后， IoT 节点协会、UAV 的3D定位和 UAV 的能量分配通过游戏理论和几何优化工具来实现，以提高系统的秘密性。结果表明，该提案的框架比 estado-of-the-art 探索算法具有更好的和更高效的秘密性性能。
</details></li>
</ul>
<hr>
<h2 id="Maximizing-the-performance-for-microcomb-based-microwave-photonic-transversal-signal-processors"><a href="#Maximizing-the-performance-for-microcomb-based-microwave-photonic-transversal-signal-processors" class="headerlink" title="Maximizing the performance for microcomb based microwave photonic transversal signal processors"></a>Maximizing the performance for microcomb based microwave photonic transversal signal processors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07155">http://arxiv.org/abs/2309.07155</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Sun, Jiayang Wu, Yang Li, Xingyuan Xu, Guanghui Ren, Mengxi Tan, Sai Tak Chu, Brent E. Little, Roberto Morandotti, Arnan Mitchell, David J. Moss</li>
<li>for:  This paper aims to analyze and improve the accuracy of microcomb-based MWP transversal signal processors.</li>
<li>methods: The paper uses a detailed analysis of error sources, including imperfections in microcombs, chirp of electro-optic modulators, chromatic dispersion of the dispersive module, shaping errors of optical spectral shapers, and noise of the photodetector.</li>
<li>results: The paper shows that feedback control can be used to compensate for errors caused by experimental imperfections, resulting in significantly improved accuracy for microcomb-based MWP transversal signal processors.<details>
<summary>Abstract</summary>
Microwave photonic (MWP) transversal signal processors offer a compelling solution for realizing versatile high-speed information processing by combining the advantages of reconfigurable electrical digital signal processing and high-bandwidth photonic processing. With the capability of generating a number of discrete wavelengths from micro-scale resonators, optical microcombs are powerful multi-wavelength sources for implementing MWP transversal signal processors with significantly reduced size, power consumption, and complexity. By using microcomb-based MWP transversal signal processors, a diverse range of signal processing functions have been demonstrated recently. In this paper, we provide a detailed analysis for the processing inaccuracy that is induced by the imperfect response of experimental components. First, we investigate the errors arising from different sources including imperfections in the microcombs, the chirp of electro-optic modulators, chromatic dispersion of the dispersive module, shaping errors of the optical spectral shapers, and noise of the photodetector. Next, we provide a global picture quantifying the impact of different error sources on the overall system performance. Finally, we introduce feedback control to compensate the errors caused by experimental imperfections and achieve significantly improved accuracy. These results provide a guide for optimizing the accuracy of microcomb-based MWP transversal signal processors.
</details>
<details>
<summary>摘要</summary>
microwave photonic（MWP）横向信号处理器提供了一个有力的解决方案，实现多样化高速信息处理，并结合电子数字信号处理的可重配置优点和光子处理的带宽优势。通过使用微型振荡器生成多个独立激光波，光学微comb是一种具有显著减小体积、功耗和复杂性的多激光源。在这篇论文中，我们对实验性错误引起的处理不准确性进行了详细分析。首先，我们研究了不同来源的错误，包括微comb的不完美性、电极激光模ulator的倾斜、分析模块中的彩色偏振、光学spectral shaper的形状错误和光电转换器的噪声。接着，我们提供了全局的错误影响系统性能的图像。最后，我们引入反馈控制，以弥补实验性错误引起的错误，并实现了显著改善的精度。这些结果为微comb基于MWP横向信号处理器的精度优化提供了一个指南。
</details></li>
</ul>
<hr>
<h2 id="High-Precision-Channel-Estimation-for-Sub-Noise-Self-Interference-Cancellation"><a href="#High-Precision-Channel-Estimation-for-Sub-Noise-Self-Interference-Cancellation" class="headerlink" title="High-Precision Channel Estimation for Sub-Noise Self-Interference Cancellation"></a>High-Precision Channel Estimation for Sub-Noise Self-Interference Cancellation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05042">http://arxiv.org/abs/2309.05042</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongsheng Zheng, Lifeng Lin, Wenyao Li, Bingli Jiao</li>
<li>for: 实现可靠的全双工通信，自阻干扰抑制具有关键作用。</li>
<li>methods: 提议一种高精度通道估计方法，特点是利用所有发送的符号，进行自阻干扰通道估计。</li>
<li>results: 通过分析和数值仿真， validate the effectiveness of the proposed method，并显示了我们的方法在实现下阻干扰抑制的优秀性能。<details>
<summary>Abstract</summary>
Self-interference cancellation plays a crucial role in achieving reliable full-duplex communications. In general, it is essential to cancel the self-interference signal below the thermal noise level, which necessitates accurate reconstruction of the self-interference signal. In this paper, we propose a high-precision channel estimation method specifically designed for sub-noise self-interference cancellation. Exploiting the fact that all transmitted symbols are known to their respective receivers, our method utilizes all transmitted symbols for self-interference channel estimation. Through analytical derivations and numerical simulations, we validate the effectiveness of the proposed method. The results demonstrate the superior performance of our approach in achieving sub-noise self-interference cancellation.
</details>
<details>
<summary>摘要</summary>
自我干扰抵消在实现可靠全双工通信中发挥关键作用。一般来说，需要在噪声水平下取消自我干扰信号，这需要精准地重建自我干扰信号。在这篇论文中，我们提议一种高精度频率估计方法，专门用于低于噪声水平的自我干扰抵消。我们利用所有发送的符号都知道它们的接收器，我们的方法利用所有发送的符号进行自我干扰通道估计。通过分析性 derivations 和数值仿真，我们证明了我们的方法的有效性。结果表明我们的方法可以在实现低于噪声水平的自我干扰抵消。
</details></li>
</ul>
<hr>
<h2 id="Soft-connected-Rigid-Body-Localization-State-of-the-Art-and-Research-Directions-for-6G"><a href="#Soft-connected-Rigid-Body-Localization-State-of-the-Art-and-Research-Directions-for-6G" class="headerlink" title="Soft-connected Rigid Body Localization: State-of-the-Art and Research Directions for 6G"></a>Soft-connected Rigid Body Localization: State-of-the-Art and Research Directions for 6G</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05002">http://arxiv.org/abs/2309.05002</a></li>
<li>repo_url: None</li>
<li>paper_authors: Niclas Führling, Hyeon Seok Rou, Giuseppe Thadeu Freitas de Abreu, David González G., Osvaldo Gonsa</li>
<li>for: 本文将提供一项关于无线局域化（WL）演进的深入研究，从单点模型到无线刚体位置（W-RBL）。</li>
<li>methods: 本文将介绍一些机制来演进WL算法到W-RBL方案中，包括其特点、数学方法和特性。</li>
<li>results: 本文将讨论扩展W-RBL技术到软连接刚体位置（SCW-RBL）算法。<details>
<summary>Abstract</summary>
This white paper describes a proposed article that will aim to provide a thorough study of the evolution of the typical paradigm of wireless localization (WL), which is based on a single point model of each target, towards wireless rigid body localization (W-RBL). We also look beyond the concept of RBL itself, whereby each target is modeled as an independent multi-point three-dimensional (3D), with shape enforced via a set of conformation constraints, as a step towards a more general approach we refer to as soft-connected RBL, whereby an ensemble of several objects embedded in a given environment, is modeled as a set of soft-connected 3D objects, with rigid and soft conformation constraints enforced within each object and among them, respectively. A first intended contribution of the full version of this article is a compact but comprehensive survey on mechanisms to evolve WL algorithms in W-RBL schemes, considering their peculiarities in terms of the type of information, mathematical approach, and features the build on or offer. A subsequent contribution is a discussion of mechanisms to extend W-RBL techniques to soft-connected rigid body localization (SCW-RBL) algorithms.
</details>
<details>
<summary>摘要</summary>
The article's first intended contribution is a compact but comprehensive survey of mechanisms to evolve WL algorithms in W-RBL schemes, considering their peculiarities in terms of the type of information, mathematical approach, and features they build on or offer. A subsequent contribution is a discussion of mechanisms to extend W-RBL techniques to soft-connected rigid body localization (SCW-RBL) algorithms.
</details></li>
</ul>
<hr>
<h2 id="AFDM-vs-OTFS-A-Comparative-Study-of-Promising-Waveforms-for-ISAC-in-Doubly-Dispersive-Channels"><a href="#AFDM-vs-OTFS-A-Comparative-Study-of-Promising-Waveforms-for-ISAC-in-Doubly-Dispersive-Channels" class="headerlink" title="AFDM vs OTFS: A Comparative Study of Promising Waveforms for ISAC in Doubly-Dispersive Channels"></a>AFDM vs OTFS: A Comparative Study of Promising Waveforms for ISAC in Doubly-Dispersive Channels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04998">http://arxiv.org/abs/2309.04998</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyeon Seok Rou, Giuseppe Thadeu Freitas de Abreu, Junil Choi, David González G., Osvaldo Gonsa, Yong Lian Guan, Marios Kountouris</li>
<li>for: The paper is written for a comprehensive comparative study of waveforms suitable for integrated sensing and communications (ISAC) systems in beyond fifth generation (B5G) and sixth generation (6G) wireless communication systems.</li>
<li>methods: The paper compares two waveform designs: (1) delay-Doppler domain-based orthognal time frequency space (OTFS) waveforms, and (2) chirp domain-based affine frequency division multiplexing (AFDM) waveforms. Both waveforms are designed based on a full delay-Doppler representation of the time variant (TV) multipath channel.</li>
<li>results: The paper aims to provide a thorough study of the advantages, shortcomings, and implications of these waveform designs for ISAC systems in B5G&#x2F;6G systems, including their performance in terms of communication and sensing functions.<details>
<summary>Abstract</summary>
This white paper aims to briefly describe a proposed article that will provide a thorough comparative study of waveforms designed to exploit the features of doubly-dispersive channels arising in heterogeneous high-mobility scenarios as expected in the beyond fifth generation (B5G) and sixth generation (6G), in relation to their suitability to integrated sensing and communications (ISAC) systems. In particular, the full article will compare the well-established delay-Doppler domain-based orthognal time frequency space (OTFS) and the recently proposed chirp domain-based affine frequency division multiplexing (AFDM) waveforms. Both these waveforms are designed based on a full delay- Doppler representation of the time variant (TV) multipath channel, yielding not only robustness and orthogonality of information symbols in high-mobility scenarios, but also a beneficial implication for environment target detection through the inherent capability of estimating the path delay and Doppler shifts, which are standard radar parameters. These modulation schemes are distinct candidates for ISAC in B5G/6G systems, such that a thorough study of their advantages, shortcomings, implications to signal processing, and performance of communication and sensing functions are well in order. In light of the above, a sample of the intended contribution (Special Issue paper) is provided below.
</details>
<details>
<summary>摘要</summary>
这份白皮书目的是简要描述一篇提议的文章，该文章将进行同时比较 doubly-dispersive 通道在不同准备下的波形设计，以探讨其适用于 интеграted sensing and communications (ISAC) 系统。特别是，该文章将比较已经确立的 delay-Doppler 频域基于的orthogonal time frequency space (OTFS) 波形和最近提议的 chirp 频域基于的 affine frequency division multiplexing (AFDM) 波形。这两种波形都是基于全 delay-Doppler 表示的时变 multipath 通道，具有在高机动场景下Robustness和信息符号的正交性，同时具有优化环境目标探测的能力，这是标准雷达参数。这些调制方案是 B5G/6G 系统中 ISAC 的可能候选人，因此进行了这些方案的优点、缺点、处理信号的影响和通信和探测功能的性能等方面的深入研究是非常必要。以下是该文章的一个示例。
</details></li>
</ul>
<hr>
<h2 id="On-the-Impact-of-Mutual-Coupling-on-RIS-Assisted-Channel-Estimation"><a href="#On-the-Impact-of-Mutual-Coupling-on-RIS-Assisted-Channel-Estimation" class="headerlink" title="On the Impact of Mutual Coupling on RIS-Assisted Channel Estimation"></a>On the Impact of Mutual Coupling on RIS-Assisted Channel Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04990">http://arxiv.org/abs/2309.04990</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pinjun Zheng, Xiuxiu Ma, Tareq Y. Al-Naffouri</li>
<li>for: 这个论文旨在评估智能表面协助下的通道估计中的共享干扰效应的影响。</li>
<li>methods: 该论文使用了一种错误的克拉默-拉奥 bounds分析方法，以evaluate the impact of mutual coupling on RIS-assisted channel estimation。</li>
<li>results: 数据分析显示，在实际场景中，减少RIS元素间距或增加RIS大小可以强化共享干扰效应的影响。此外，即使在忽略共享干扰效应的情况下，过于紧密的RIS元素间距可能会导致通道估计性能受到重大降低。<details>
<summary>Abstract</summary>
Amid the demand for densely integrated elements in holographic reconfigurable intelligent surfaces (RISs), the mutual coupling effect has gained prominence. By performing a misspecified Cram\'er-Rao bound analysis within an electromagnetics-compliant communication model, this letter offers a quantitative evaluation of the impact of mutual coupling on RIS-assisted channel estimation. Our analysis provides insights into situations where mutual coupling can be disregarded safely. The numerical results reveal that within practical scenarios, closer integration of RIS elements or the enlargement of RIS size accentuates the impact of neglecting mutual coupling. In addition, even with mutual coupling-aware setups, excessively tight RIS element spacing can lead to substantial degradation in the channel estimation performance.
</details>
<details>
<summary>摘要</summary>
在激光卷积智能表面（RIS）中受需求的紧密集成元素下，双向干扰效应得到了更多的关注。通过在电磁学相容通信模型中进行误pecified Cramér-Rao bound分析，本书提供了RIS协助通道估计的量化评估。我们的分析为你提供了忽略双向干扰的情况下的洞察。 numerics 结果表明，在实际场景下，将RIS元素更加紧密集成或者提高RIS大小，会强调对忽略双向干扰的影响。此外，即使在忽略双向干扰的设置下，当RIS元素间距过紧时，channel estimation表现会受到显著的降低。
</details></li>
</ul>
<hr>
<h2 id="On-the-Capacity-of-Generalized-Quadrature-Spatial-Modulation"><a href="#On-the-Capacity-of-Generalized-Quadrature-Spatial-Modulation" class="headerlink" title="On the Capacity of Generalized Quadrature Spatial Modulation"></a>On the Capacity of Generalized Quadrature Spatial Modulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04986">http://arxiv.org/abs/2309.04986</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kein Yukiyoshi, Naoki Ishikawa</li>
<li>for: 这个论文主要用于研究通用四象限幂冲扩展（GQSM）的特性。</li>
<li>methods: 论文使用了蒙特卡洛方法进行数据集计算，并 derivied了GQSM的关键性能指标——平均相互信息（AMI）的闭合表达式。</li>
<li>results: 研究结果表明，对于不同的antenna activation pattern，GQSM的AMI与其他相关的SM方案相比，在符号水平上略有下降，但在总体水平上显著提高。此外，在选择antenna的过程中，使用 equiprobable antenna selection method可以进一步提高GQSM的AMI。<details>
<summary>Abstract</summary>
In this letter, the average mutual information (AMI) of generalized quadrature spatial modulation (GQSM) is first derived for continuous-input continuous-output channels. Our mathematical analysis shows that the calculation error induced by Monte Carlo integration increases exponentially with the signal-to-noise ratio. This nature of GQSM is resolved by deriving a closed-form expression. The derived AMI is compared with other related SM schemes and evaluated for different antenna activation patterns. Our results show that an equiprobable antenna selection method slightly decreases AMI of symbols, while the method significantly improves AMI in total.
</details>
<details>
<summary>摘要</summary>
本封信中，我们首先计算了通用四则幂空间模ulation（GQSM）的平均双向信息（AMI），这是一种连续输入连续输出通道的问题。我们的数学分析表明，使用Monte Carlo方法求解时的计算误差随信号响应比例呈指数增长。这种GQSM特性的解决方法是得到一个关闭式表达。我们对其他相关的SM方案进行了比较，并对不同的天线活动模式进行了评估。我们的结果表明， equiprobable antenna selection方法会对符号AMI造成轻微下降，但是对总AMI具有显著改善的作用。
</details></li>
</ul>
<hr>
<h2 id="Trade-Off-Between-Beamforming-and-Macro-Diversity-Gains-in-Distributed-mMIMO"><a href="#Trade-Off-Between-Beamforming-and-Macro-Diversity-Gains-in-Distributed-mMIMO" class="headerlink" title="Trade-Off Between Beamforming and Macro-Diversity Gains in Distributed mMIMO"></a>Trade-Off Between Beamforming and Macro-Diversity Gains in Distributed mMIMO</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04975">http://arxiv.org/abs/2309.04975</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eduardo Noboro Tominaga, Hsuan-Jung Su, Jinfeng Du, Sivarama Venkatesan, Richard Demo Souza, Hirley Alves</li>
<li>for: 研究者们是为了演进从中心化大量多输入多出口（CmMIMO）演进到分布式多输入多出口（DmMIMO）架构而工作。</li>
<li>methods: 研究者们使用了数学模型来研究在选择更多的Access Points（AP）与 fewer APs equipped with many antennas之间的牵扯关系。</li>
<li>results: 研究者们发现了一个&#96;&#96;甜点”在最佳Access Points数量和每个AP的天线元数之间，这个甜点是函散于覆盖区域的物理尺寸。<details>
<summary>Abstract</summary>
Industry and academia have been working towards the evolution from Centralized massive Multiple-Input Multiple-Output (CmMIMO) to Distributed mMIMO (DmMIMO) architectures. Instead of splitting a coverage area into many cells, each served by a single Base Station equipped with several antennas, the whole coverage area is jointly covered by several Access Points (AP) equipped with few or single antennas. Nevertheless, when choosing between deploying more APs with few or single antennas or fewer APs equipped with many antennas, one observes an inherent trade-off between the beamforming and macro-diversity gains that has not been investigated in the literature. Given a total number of antenna elements and total downlink power, under a channel model that takes into account a probability of Line-of-Sight (LoS) as a function of the distance between the User Equipments (UEs) and APs, our numerical results show that there exists a ``sweet spot" on the optimal number of APs and of antenna elements per AP which is a function of the physical dimensions of the coverage area.
</details>
<details>
<summary>摘要</summary>
产业和学术界在演化 FROM Centralized massive Multiple-Input Multiple-Output (CmMIMO) 到 Distributed mMIMO (DmMIMO) 架构方面努力奋斗。而不是将覆盖区域分成多个Cell，每个Cell都由一个单antenna Base Station 服务器而不是多个antenna，整个覆盖区域都是由多个Access Points (AP) 服务器，每个AP 只有一些或一个天线。然而，在选择更多的APs 或更少的APs 每个antenna 数量时，存在一个内在的质量和多样性收益之间的交易，这在文献中没有被调查。给定一个总天线元素数和总下行功率，根据UEs 和 APs 之间距离的概率Line-of-Sight (LoS) 函数，我们的数值结果显示，存在一个"甜点"的最佳APs 和天线元素数量，这是覆盖区域的物理尺寸函数。
</details></li>
</ul>
<hr>
<h2 id="Data-Fusion-Based-Predictive-Beamforming-for-Downlink-UAV-Assisted-Massive-MIMO-Communication"><a href="#Data-Fusion-Based-Predictive-Beamforming-for-Downlink-UAV-Assisted-Massive-MIMO-Communication" class="headerlink" title="Data Fusion-Based Predictive Beamforming for Downlink UAV-Assisted Massive MIMO Communication"></a>Data Fusion-Based Predictive Beamforming for Downlink UAV-Assisted Massive MIMO Communication</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04916">http://arxiv.org/abs/2309.04916</a></li>
<li>repo_url: None</li>
<li>paper_authors: Byunghyun Lee, Andrew Marcum, David Love, James Krogmeier</li>
<li>for: 提高无人机驱动多Input多Output通信系统的 spectral efficiency</li>
<li>methods: 使用数据融合predictive beamforming schemes, 利用飞行器动态跟踪和预测 trajectory和orientation</li>
<li>results:  simulation results demonstrate improved overall spectral efficiency, particularly when the number of antennas is large.<details>
<summary>Abstract</summary>
In this letter, we propose a data fusion-based predictive beamforming scheme for unmanned aerial vehicle (UAV)-assisted massive multiple-input multiple-output (MIMO) communication, which involves a base station and UAV, each equipped with a massive MIMO array. We consider aircraft dynamics to track and predict the trajectory and orientation of the UAV. To improve communication and tracking performance, we propose a novel fusion of the channel and motion data of the UAV using an extended Kalman filter (EKF). Simulation results demonstrate that the proposed scheme can improve overall spectral efficiency, particularly when the number of antennas is large.
</details>
<details>
<summary>摘要</summary>
在这封信中，我们提出了基于数据融合的预测扫描优化方案，用于无人机（UAV）协助大量多输入多输出（MIMO）通信，该方案包括基站和UAV，每个都装备了庞大的MIMO阵列。我们考虑了飞机动力来跟踪和预测无人机的轨迹和方向。为了提高通信和跟踪性能，我们提议一种新的扩展卡尔曼滤波器（EKF）来融合无人机的通道和运动数据。实验结果表明，提议的方案可以提高总频谱效率，特别是当antenna的数量很大时。
</details></li>
</ul>
<hr>
<h2 id="One-Bit-Aided-Modulo-Sampling-for-DOA-Estimation"><a href="#One-Bit-Aided-Modulo-Sampling-for-DOA-Estimation" class="headerlink" title="One-Bit-Aided Modulo Sampling for DOA Estimation"></a>One-Bit-Aided Modulo Sampling for DOA Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04901">http://arxiv.org/abs/2309.04901</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qi Zhang, Jiang Zhu, Zhiwei Xu, De Wen Soh</li>
<li>for: 提高DOA估计精度并解决近远问题</li>
<li>methods: 一位数量化+盲引数强制（1bit-aided BIF）方法</li>
<li>results: 比高精度ADC直接使用的方法有更好的性能<details>
<summary>Abstract</summary>
Modulo sampling or unlimited sampling has recently drawn a great deal of attention for cutting-edge applications, due to overcoming the barrier of information loss through sensor saturation and clipping. This is a significant problem, especially when the range of signal amplitudes is unknown or in the near-far case. To overcome this fundamental bottleneck, we propose a one-bit-aided (1bit-aided) modulo sampling scheme for direction-of-arrival (DOA) estimation. On the one hand, one-bit quantization involving a simple comparator offers the advantages of low-cost and low-complexity implementation. On the other hand, one-bit quantization provides an estimate of the normalized covariance matrix of the unquantized measurements via the arcsin law. The estimate of the normalized covariance matrix is used to implement blind integer-forcing (BIF) decoder to unwrap the modulo samples to construct the covariance matrix, and subspace methods can be used to perform the DOA estimation. Our approach named as 1bit-aided-BIF addresses the near-far problem well and overcomes the intrinsic low dynamic range of one-bit quantization. Numerical experiments validate the excellent performance of the proposed algorithm compared to using a high-precision ADC directly in the given set up.
</details>
<details>
<summary>摘要</summary>
“模ulo sampling或无限 sampling在最前线应用中受到了非常多的关注，因为它可以超越传感器满荷和剪辑导致的信息损失问题。这是一个非常重要的问题，特别在signal amplitude范围未知或near-far情况下。为了解决这个基本的瓶颈，我们提议一种基于一位数（1bit）的modulo sampling schemes дляdirection-of-arrival（DOA）估计。一方面，一位数量化可以通过简单的比较器实现low-cost和low-complexity的实现。另一方面，一位数量化可以通过arsin法得到normalized covariance matrix的估计。这个估计的normalized covariance matrix可以用来实现blind integer-forcing（BIF）解oder，将modulo samplesunwrap到construct covariance matrix，并使用subspace方法进行DOA估计。我们的方法名为1bit-aided-BIF，可以很好地解决near-far问题，并且超越了一位数量化的内置低动态范围。numerical experiments表明，我们的算法与使用高精度ADC直接在给定的设置中比较出色。”
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/10/eess.SP_2023_09_10/" data-id="cloimipit017ms4880umkddrx" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_09_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/09/cs.SD_2023_09_09/" class="article-date">
  <time datetime="2023-09-09T15:00:00.000Z" itemprop="datePublished">2023-09-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/09/cs.SD_2023_09_09/">cs.SD - 2023-09-09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Exploring-Music-Genre-Classification-Algorithm-Analysis-and-Deployment-Architecture"><a href="#Exploring-Music-Genre-Classification-Algorithm-Analysis-and-Deployment-Architecture" class="headerlink" title="Exploring Music Genre Classification: Algorithm Analysis and Deployment Architecture"></a>Exploring Music Genre Classification: Algorithm Analysis and Deployment Architecture</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04861">http://arxiv.org/abs/2309.04861</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ayan Biswas, Supriya Dhabal, Palaniandavar Venkateswaran</li>
<li>for: 这篇论文是为了研究音乐类别分类而写的。</li>
<li>methods: 这篇论文使用了数字信号处理（DSP）和深度学习（DL）技术，提出了一种结合DSP和DL方法的音乐类别分类算法。</li>
<li>results: 该算法在GTZAN数据集上进行测试，准确率高。此外，文章还提出了一种端到端部署架构，用于音乐相关应用的集成。<details>
<summary>Abstract</summary>
Music genre classification has become increasingly critical with the advent of various streaming applications. Nowadays, we find it impossible to imagine using the artist's name and song title to search for music in a sophisticated music app. It is always difficult to classify music correctly because the information linked to music, such as region, artist, album, or non-album, is so variable. This paper presents a study on music genre classification using a combination of Digital Signal Processing (DSP) and Deep Learning (DL) techniques. A novel algorithm is proposed that utilizes both DSP and DL methods to extract relevant features from audio signals and classify them into various genres. The algorithm was tested on the GTZAN dataset and achieved high accuracy. An end-to-end deployment architecture is also proposed for integration into music-related applications. The performance of the algorithm is analyzed and future directions for improvement are discussed. The proposed DSP and DL-based music genre classification algorithm and deployment architecture demonstrate a promising approach for music genre classification.
</details>
<details>
<summary>摘要</summary>
音乐类别分类已成为现代音乐应用程序中的关键环节。如今，我们无法想象使用艺术家名和歌曲名来在高级音乐应用程序中搜索音乐。因为音乐相关信息，如地区、艺术家、专辑和非专辑等，是非常变化的。本文提出了一种结合数字信号处理（DSP）和深度学习（DL）技术的音乐类别分类算法。该算法利用了DSP和DL方法来提取音频信号中相关的特征并将其分类为不同的类别。该算法在GTZAN数据集上进行测试并达到了高精度。本文还提出了将该算法集成到音乐相关应用程序中的综合投入体系。算法的性能分析和未来改进方向也被讨论。提出的DSP和DL基于的音乐类别分类算法和投入体系表现出了可行的应用前景。
</details></li>
</ul>
<hr>
<h2 id="Generalized-Minimum-Error-with-Fiducial-Points-Criterion-for-Robust-Learning"><a href="#Generalized-Minimum-Error-with-Fiducial-Points-Criterion-for-Robust-Learning" class="headerlink" title="Generalized Minimum Error with Fiducial Points Criterion for Robust Learning"></a>Generalized Minimum Error with Fiducial Points Criterion for Robust Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04670">http://arxiv.org/abs/2309.04670</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haiquan Zhao, Yuan Gao, Yingying Zhu</li>
<li>for: 提高 minimum error entropy criterion 的灵活性和敏感性，并应对不确定性Error probability density function locations。</li>
<li>methods: 采用 Generalized Gaussian Density 函数作为 kernel，提供更多控制 tail 行为和峰度的能力。</li>
<li>results: 在适应Filter、kernel recursive algorithm、多层感知等领域的numerical simulations中，提出的新算法表现出色，比如系统识别、声学闭合取消、时间序列预测和超vised classification。<details>
<summary>Abstract</summary>
The conventional Minimum Error Entropy criterion (MEE) has its limitations, showing reduced sensitivity to error mean values and uncertainty regarding error probability density function locations. To overcome this, a MEE with fiducial points criterion (MEEF), was presented. However, the efficacy of the MEEF is not consistent due to its reliance on a fixed Gaussian kernel. In this paper, a generalized minimum error with fiducial points criterion (GMEEF) is presented by adopting the Generalized Gaussian Density (GGD) function as kernel. The GGD extends the Gaussian distribution by introducing a shape parameter that provides more control over the tail behavior and peakedness. In addition, due to the high computational complexity of GMEEF criterion, the quantized idea is introduced to notably lower the computational load of the GMEEF-type algorithm. Finally, the proposed criterions are introduced to the domains of adaptive filter, kernel recursive algorithm, and multilayer perceptron. Several numerical simulations, which contain system identification, acoustic echo cancellation, times series prediction, and supervised classification, indicate that the novel algorithms' performance performs excellently.
</details>
<details>
<summary>摘要</summary>
传统的最小错误Entropy（MEE）具有局限性，显示了错误均值的减少敏感性和不确定性关于错误概率分布的位置。为了缓解这些局限性，一种基于 fiducial points 的 MEE（MEEF）被提出。然而，MEEF 的效果不稳定，因为它依赖于固定的 Gaussian 核。在这篇论文中，一种通用的最小错误与 fiducial points  criterion（GMEEF）被提出，通过采用通用 Gaussian Density 函数（GGD）作为核来扩展 Gaussian 分布。GGD 在尾部和峰值方面提供更多的控制，并且可以更好地捕捉非常轻量级的噪声。此外，由于 GMEEF  criterion 的计算复杂度较高，因此在这篇论文中，一种quantized 的想法被引入，以减少 GMEEF-type 算法的计算负担。最后，提出了在适应过滤器、基于 Recursive Algorithm 的 kernel 算法和多层感知机中应用 GMEEF 和 MEEF  criterion。numerical simulations 表明，提出的新算法在系统标识、音频回声抑制、时间序列预测和监督学习等领域的性能几乎卓越。
</details></li>
</ul>
<hr>
<h2 id="Mask-CTC-based-Encoder-Pre-training-for-Streaming-End-to-End-Speech-Recognition"><a href="#Mask-CTC-based-Encoder-Pre-training-for-Streaming-End-to-End-Speech-Recognition" class="headerlink" title="Mask-CTC-based Encoder Pre-training for Streaming End-to-End Speech Recognition"></a>Mask-CTC-based Encoder Pre-training for Streaming End-to-End Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04654">http://arxiv.org/abs/2309.04654</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huaibo Zhao, Yosuke Higuchi, Yusuke Kida, Tetsuji Ogawa, Tetsunori Kobayashi</li>
<li>for: 这 paper 的目的是检验Mask-CTC基于预训练的效果，以提高流式自动语音识别（ASR）系统的准确率和速度。</li>
<li>methods: 这 paper 使用的方法包括Mask-CTC基于预训练、触发注意力和不同的模型架构（如Transformer-Transducer和 contextual block streaming ASR）。</li>
<li>results: 研究发现，Mask-CTC基于预训练可以提高不同模型架构的流式ASR准确率和速度，且可以获得正确的输出脉冲时间。<details>
<summary>Abstract</summary>
Achieving high accuracy with low latency has always been a challenge in streaming end-to-end automatic speech recognition (ASR) systems. By attending to more future contexts, a streaming ASR model achieves higher accuracy but results in larger latency, which hurts the streaming performance. In the Mask-CTC framework, an encoder network is trained to learn the feature representation that anticipates long-term contexts, which is desirable for streaming ASR. Mask-CTC-based encoder pre-training has been shown beneficial in achieving low latency and high accuracy for triggered attention-based ASR. However, the effectiveness of this method has not been demonstrated for various model architectures, nor has it been verified that the encoder has the expected look-ahead capability to reduce latency. This study, therefore, examines the effectiveness of Mask-CTCbased pre-training for models with different architectures, such as Transformer-Transducer and contextual block streaming ASR. We also discuss the effect of the proposed pre-training method on obtaining accurate output spike timing.
</details>
<details>
<summary>摘要</summary>
在流动式自动语音识别（ASR）系统中，实现高精度低延迟总是一个挑战。 streaming ASR 模型通过更多未来上下文来提高准确率，但是会增加延迟，这会对流动性表现不利。在面具-CTC 框架中，一个Encoder网络被训练来学习预测长期上下文的特征表示，这是流动 ASR 中所需的。面具-CTC 基于的encoder预训练有助于实现低延迟和高精度的触发注意力基于 ASR。然而，这种方法的效果尚未在不同的模型结构上进行了证明，也没有确定Encoder是否具有预期的推迟能力来减少延迟。本研究，因此，检查了不同的模型结构，如 Transformer-Transducer 和 contextual block streaming ASR 中的 Mask-CTC 基于预训练的效果。我们还讨论了提取模型的输出脉冲时间是否准确。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/09/cs.SD_2023_09_09/" data-id="cloimipe100uos4881y080vlw" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/09/cs.CV_2023_09_09/" class="article-date">
  <time datetime="2023-09-09T13:00:00.000Z" itemprop="datePublished">2023-09-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/09/cs.CV_2023_09_09/">cs.CV - 2023-09-09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Semi-supervised-Instance-Segmentation-with-a-Learned-Shape-Prior"><a href="#Semi-supervised-Instance-Segmentation-with-a-Learned-Shape-Prior" class="headerlink" title="Semi-supervised Instance Segmentation with a Learned Shape Prior"></a>Semi-supervised Instance Segmentation with a Learned Shape Prior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04888">http://arxiv.org/abs/2309.04888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Long Chen, Weiwen Zhang, Yuli Wu, Martin Strauch, Dorit Merhof</li>
<li>for: 这个 paper 是为了解决实例分割问题，而不需要大量的标注对象边框数据。</li>
<li>methods: 这个方法使用了形状先验模型，该模型是通过变分自动编码器学习的，只需要很少量的训练数据。</li>
<li>results: 在我们的实验中，使用了几十个目标数据集中的对象形状补丁，以及完全 sintetic 的形状，可以达到与超级vised 方法相同的效果，并在三个 cell 分割数据集上都 superior 于预训练的超级vised 模型。<details>
<summary>Abstract</summary>
To date, most instance segmentation approaches are based on supervised learning that requires a considerable amount of annotated object contours as training ground truth. Here, we propose a framework that searches for the target object based on a shape prior. The shape prior model is learned with a variational autoencoder that requires only a very limited amount of training data: In our experiments, a few dozens of object shape patches from the target dataset, as well as purely synthetic shapes, were sufficient to achieve results en par with supervised methods with full access to training data on two out of three cell segmentation datasets. Our method with a synthetic shape prior was superior to pre-trained supervised models with access to limited domain-specific training data on all three datasets. Since the learning of prior models requires shape patches, whether real or synthetic data, we call this framework semi-supervised learning.
</details>
<details>
<summary>摘要</summary>
到目前为止，大多数实例分割方法基于supervised learning，需要较大量的标注对象边框作为训练真实数据。在这里，我们提出了一种框架，它基于形态先验来寻找目标对象。形态先验模型通过variational autoencoder来学习，只需要一个非常有限的训练数据：在我们的实验中，几十个目标数据集中的对象形状补充、完全 sintética的形状都能够达到与supervised方法相同的效果。我们的方法使用 sintética形状先验在所有三个数据集上都高于预训练的supervised模型。由于学习先验模型需要形状补充，是semi-supervised learning。
</details></li>
</ul>
<hr>
<h2 id="SortedAP-Rethinking-evaluation-metrics-for-instance-segmentation"><a href="#SortedAP-Rethinking-evaluation-metrics-for-instance-segmentation" class="headerlink" title="SortedAP: Rethinking evaluation metrics for instance segmentation"></a>SortedAP: Rethinking evaluation metrics for instance segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04887">http://arxiv.org/abs/2309.04887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Long Chen, Yuli Wu, Johannes Stegmaier, Dorit Merhof</li>
<li>for: 评估实例分割中的评价指标，需要全面考虑对象检测和分割精度。</li>
<li>methods: 本文提出了一种新的评价指标called sortedAP，它具有 conditional sensitivity和精度递减的特点。</li>
<li>results: sortedAP可以准确地评估实例分割的质量，并且具有不间断的惩罚尺度，可以提供更加准确的质量评估结果。<details>
<summary>Abstract</summary>
Designing metrics for evaluating instance segmentation revolves around comprehensively considering object detection and segmentation accuracy. However, other important properties, such as sensitivity, continuity, and equality, are overlooked in the current study. In this paper, we reveal that most existing metrics have a limited resolution of segmentation quality. They are only conditionally sensitive to the change of masks or false predictions. For certain metrics, the score can change drastically in a narrow range which could provide a misleading indication of the quality gap between results. Therefore, we propose a new metric called sortedAP, which strictly decreases with both object- and pixel-level imperfections and has an uninterrupted penalization scale over the entire domain. We provide the evaluation toolkit and experiment code at https://www.github.com/looooongChen/sortedAP.
</details>
<details>
<summary>摘要</summary>
设计实例 segmentation 评价指标涉及全面考虑对象检测和分割精度。然而，现有的研究几乎忽略了其他重要特性，如敏感性、连续性和平等性。在这篇论文中，我们发现现有的指标有限制的分辨率。它们只是在某些指标下有限制的敏感，而且有一定的风险提供假的质量指标。因此，我们提出了一个新的指标called sortedAP，它在对象和像素级别的不足下坚持减少，并在整个领域上具有不间断的补偿幅度。我们在 GitHub 上提供了评价工具箱和实验代码，请参考 <https://www.github.com/looooongChen/sortedAP>。
</details></li>
</ul>
<hr>
<h2 id="AnyPose-Anytime-3D-Human-Pose-Forecasting-via-Neural-Ordinary-Differential-Equations"><a href="#AnyPose-Anytime-3D-Human-Pose-Forecasting-via-Neural-Ordinary-Differential-Equations" class="headerlink" title="AnyPose: Anytime 3D Human Pose Forecasting via Neural Ordinary Differential Equations"></a>AnyPose: Anytime 3D Human Pose Forecasting via Neural Ordinary Differential Equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04840">http://arxiv.org/abs/2309.04840</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zixing Wang, Ahmed H. Qureshi</li>
<li>for: 这篇研究目的是为了提出一个可靠的三维人体姿态预测方法，以便在实时人机交互中进行预测。</li>
<li>methods: 这篇研究使用了神经ordinary differential equation（Neural ODE）来建模人类行为动力学。</li>
<li>results: 研究结果显示，AnyPose方法在Human3.6M、AMASS和3DPW数据集上显示出高精度的未来姿态预测，并且比传统方法快得多个computational time。<details>
<summary>Abstract</summary>
Anytime 3D human pose forecasting is crucial to synchronous real-world human-machine interaction, where the term ``anytime" corresponds to predicting human pose at any real-valued time step. However, to the best of our knowledge, all the existing methods in human pose forecasting perform predictions at preset, discrete time intervals. Therefore, we introduce AnyPose, a lightweight continuous-time neural architecture that models human behavior dynamics with neural ordinary differential equations. We validate our framework on the Human3.6M, AMASS, and 3DPW dataset and conduct a series of comprehensive analyses towards comparison with existing methods and the intersection of human pose and neural ordinary differential equations. Our results demonstrate that AnyPose exhibits high-performance accuracy in predicting future poses and takes significantly lower computational time than traditional methods in solving anytime prediction tasks.
</details>
<details>
<summary>摘要</summary>
任何时刻3D人姿预测是实时人机交互中关键，其中“任何时刻”指的是预测人姿的任何实数时间步。然而，我们所知道的所有现有方法都是在固定、精确时间间隔进行预测。因此，我们介绍了AnyPose，一种轻量级连续时间神经网络架构，用于模elling人类行为动力学。我们验证了我们的框架在Human3.6M、AMASS和3DPW数据集上，并进行了一系列完整的分析，包括与现有方法进行比较和人姿和神经ordinary differential equations的交叠。我们的结果表明，AnyPose在预测未来姿势方面具有高精度性和较低的计算时间，与传统方法在实时预测任务中具有优势。
</details></li>
</ul>
<hr>
<h2 id="Neural-Semantic-Surface-Maps"><a href="#Neural-Semantic-Surface-Maps" class="headerlink" title="Neural Semantic Surface Maps"></a>Neural Semantic Surface Maps</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04836">http://arxiv.org/abs/2309.04836</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luca Morreale, Noam Aigerman, Vladimir G. Kim, Niloy J. Mitra</li>
<li>for: 生成两个 genus-zero 形的 semantic surface-to-surface 映射，即将 semantically 相应的区域匹配到另一个形上。</li>
<li>methods: 使用 pre-trained 视觉模型进行 Semantic Matching，并使用 off-the-shelf 图像匹配方法生成 feature points。</li>
<li>results: 可以生成 semantic surface-to-surface 映射，不需要任何 3D 训练数据或手动标注。方法可以在高semantic complexity 和 nearly isometric 情况下效果很好。<details>
<summary>Abstract</summary>
We present an automated technique for computing a map between two genus-zero shapes, which matches semantically corresponding regions to one another. Lack of annotated data prohibits direct inference of 3D semantic priors; instead, current State-of-the-art methods predominantly optimize geometric properties or require varying amounts of manual annotation. To overcome the lack of annotated training data, we distill semantic matches from pre-trained vision models: our method renders the pair of 3D shapes from multiple viewpoints; the resulting renders are then fed into an off-the-shelf image-matching method which leverages a pretrained visual model to produce feature points. This yields semantic correspondences, which can be projected back to the 3D shapes, producing a raw matching that is inaccurate and inconsistent between different viewpoints. These correspondences are refined and distilled into an inter-surface map by a dedicated optimization scheme, which promotes bijectivity and continuity of the output map. We illustrate that our approach can generate semantic surface-to-surface maps, eliminating manual annotations or any 3D training data requirement. Furthermore, it proves effective in scenarios with high semantic complexity, where objects are non-isometrically related, as well as in situations where they are nearly isometric.
</details>
<details>
<summary>摘要</summary>
Note:* "genus-zero shapes" refers to shapes without any holes or singularities.* "semantic priors" refer to the prior knowledge of the semantic meaning of the objects or regions in the scene.* "manual annotation" refers to the process of labeling the objects or regions in the scene with semantic information.* "pre-trained vision models" refer to deep learning models that have been trained on large datasets of images to learn features and patterns.* "image-matching method" refers to a technique that compares two images and finds the corresponding points between them.* "feature points" refer to the points in the image that have been identified as being semantically meaningful.* "bijection" refers to a one-to-one correspondence between two sets, which is important for ensuring that the output map is accurate and consistent.* "continuity" refers to the property of a function that has no gaps or jumps in its output.
</details></li>
</ul>
<hr>
<h2 id="Few-Shot-Medical-Image-Segmentation-via-a-Region-enhanced-Prototypical-Transformer"><a href="#Few-Shot-Medical-Image-Segmentation-via-a-Region-enhanced-Prototypical-Transformer" class="headerlink" title="Few-Shot Medical Image Segmentation via a Region-enhanced Prototypical Transformer"></a>Few-Shot Medical Image Segmentation via a Region-enhanced Prototypical Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04825">http://arxiv.org/abs/2309.04825</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yazhouzhu19/rpt">https://github.com/yazhouzhu19/rpt</a></li>
<li>paper_authors: Yazhou Zhu, Shidong Wang, Tong Xin, Haofeng Zhang</li>
<li>for: 这篇论文是为了解决医疗图像分类 tasks 中的问题，特别是对于大量医疗图像的自动分类。</li>
<li>methods: 本篇论文使用了一种名为 Region-enhanced Prototypical Transformer (RPT) 的方法，这是一种基于几个支持像的学习方法，它可以对于不同的测试案例进行几个 shot 的学习。</li>
<li>results: 在三个公开的医疗图像数据集上进行了广泛的实验，结果显示 RPT 方法可以对于 Few-Shot Medical Image Segmentation (FSMS)  tasks 提供更好的性能，与现有的方法相比，具有更好的准确性和稳定性。<details>
<summary>Abstract</summary>
Automated segmentation of large volumes of medical images is often plagued by the limited availability of fully annotated data and the diversity of organ surface properties resulting from the use of different acquisition protocols for different patients. In this paper, we introduce a more promising few-shot learning-based method named Region-enhanced Prototypical Transformer (RPT) to mitigate the effects of large intra-class diversity/bias. First, a subdivision strategy is introduced to produce a collection of regional prototypes from the foreground of the support prototype. Second, a self-selection mechanism is proposed to incorporate into the Bias-alleviated Transformer (BaT) block to suppress or remove interferences present in the query prototype and regional support prototypes. By stacking BaT blocks, the proposed RPT can iteratively optimize the generated regional prototypes and finally produce rectified and more accurate global prototypes for Few-Shot Medical Image Segmentation (FSMS). Extensive experiments are conducted on three publicly available medical image datasets, and the obtained results show consistent improvements compared to state-of-the-art FSMS methods. The source code is available at: https://github.com/YazhouZhu19/RPT.
</details>
<details>
<summary>摘要</summary>
自动化分割大量医疗图像的问题 frequently 受到完全标注数据的有限性和不同患者的获取协议所导致的组织表面性的多样性的影响。在这篇论文中，我们介绍了一种更有前途的几拟学学习基于方法，名为区域增强的原型变换器（RPT），以降低大型内类多样性/偏见的影响。首先，我们提出了一种分区策略，以生成支持原型的分区原型集。其次，我们提出了一种自选机制，以吸收或移除在支持原型和区域支持原型中的干扰。通过堆叠 BaT 块，我们的 RPT 可以Iteratively 优化生成的区域原型，并最终生成修正和更准确的全局原型，为几拟学医疗图像分割（FSMS）提供了更好的结果。我们在三个公开的医疗图像数据集上进行了广泛的实验，并取得了与当前最佳 FSMS 方法相对的稳定性和可靠性。源代码可以在 GitHub 上找到：https://github.com/YazhouZhu19/RPT。
</details></li>
</ul>
<hr>
<h2 id="ABC-Easy-as-123-A-Blind-Counter-for-Exemplar-Free-Multi-Class-Class-agnostic-Counting"><a href="#ABC-Easy-as-123-A-Blind-Counter-for-Exemplar-Free-Multi-Class-Class-agnostic-Counting" class="headerlink" title="ABC Easy as 123: A Blind Counter for Exemplar-Free Multi-Class Class-agnostic Counting"></a>ABC Easy as 123: A Blind Counter for Exemplar-Free Multi-Class Class-agnostic Counting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04820">http://arxiv.org/abs/2309.04820</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael A. Hobley, Victor A. Prisacariu</li>
<li>for: 这篇论文的目的是提出一种多类、无类别 counting 方法，以解决现有方法在 COUNTING 任务中存在的限制。</li>
<li>methods: 该方法使用了一种新的概念，即在 COUNTING 阶段不需要使用类例进行导航，而是在计数后发现类例以帮助用户理解生成的输出。</li>
<li>results: 对于 MCAC 数据集，该方法可以与 Contemporary methods 相比，而无需人工循环注解。此外，该方法还在 FSC-147 数据集上实现了类似的性能。<details>
<summary>Abstract</summary>
Class-agnostic counting methods enumerate objects of an arbitrary class, providing tremendous utility in many fields. Prior works have limited usefulness as they require either a set of examples of the type to be counted or that the image contains only a single type of object. A significant factor in these shortcomings is the lack of a dataset to properly address counting in settings with more than one kind of object present. To address these issues, we propose the first Multi-class, Class-Agnostic Counting dataset (MCAC) and A Blind Counter (ABC123), a method that can count multiple types of objects simultaneously without using examples of type during training or inference. ABC123 introduces a new paradigm where instead of requiring exemplars to guide the enumeration, examples are found after the counting stage to help a user understand the generated outputs. We show that ABC123 outperforms contemporary methods on MCAC without the requirement of human in-the-loop annotations. We also show that this performance transfers to FSC-147, the standard class-agnostic counting dataset.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Class-agnostic counting methods enumerate objects of an arbitrary class, providing tremendous utility in many fields. Prior works have limited usefulness as they require either a set of examples of the type to be counted or that the image contains only a single type of object. A significant factor in these shortcomings is the lack of a dataset to properly address counting in settings with more than one kind of object present. To address these issues, we propose the first Multi-class, Class-Agnostic Counting dataset (MCAC) and A Blind Counter (ABC123), a method that can count multiple types of objects simultaneously without using examples of type during training or inference. ABC123 introduces a new paradigm where instead of requiring exemplars to guide the enumeration, examples are found after the counting stage to help a user understand the generated outputs. We show that ABC123 outperforms contemporary methods on MCAC without the requirement of human in-the-loop annotations. We also show that this performance transfers to FSC-147, the standard class-agnostic counting dataset."中文简体版：类型不扩知的统计方法可以对任意类型的对象进行枚举，提供了很多领域的巨大实用性。先前的方法具有有限的用途，因为它们需要 Either a set of examples of the type to be counted or that the image contains only a single type of object。这些缺点的一个重要因素是缺乏适用于多种对象存在的数据集，以正确地解决类型不扩知的统计问题。为解决这些问题，我们提出了首个多类、类型不扩知统计数据集（MCAC）和一种无需在训练或推理阶段使用类型示例的方法（ABC123）。ABC123引入了一新的思路，而不是需要 exemplars 来引导枚举，而是在统计阶段找到例子，以帮助用户理解生成的输出。我们表明，ABC123 在 MCAC 上超越了当前方法，而不需要人工循环注释。我们还表明，这种性能可以跨种类，并在标准的类型不扩知统计数据集 FSC-147 上进行验证。
</details></li>
</ul>
<hr>
<h2 id="Speech2Lip-High-fidelity-Speech-to-Lip-Generation-by-Learning-from-a-Short-Video"><a href="#Speech2Lip-High-fidelity-Speech-to-Lip-Generation-by-Learning-from-a-Short-Video" class="headerlink" title="Speech2Lip: High-fidelity Speech to Lip Generation by Learning from a Short Video"></a>Speech2Lip: High-fidelity Speech to Lip Generation by Learning from a Short Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04814">http://arxiv.org/abs/2309.04814</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiuzhe Wu, Pengfei Hu, Yang Wu, Xiaoyang Lyu, Yan-Pei Cao, Ying Shan, Wenming Yang, Zhongqian Sun, Xiaojuan Qi</li>
<li>for: 根据谈话生成自然看起来的动画，解决过去的问题包括不准确的唇形生成和底层的图像质量。</li>
<li>methods: 我们提出了一个构成-分解-重新组合框架（Speech2Lip），将谈话驱动的动作和外观分解为两个部分：谈话敏感的动作和谈话不敏感的动作。这使得我们可以从有限的训练数据中学习出自然的动画。</li>
<li>results: 我们的模型可以从几分钟的训练影片中学习出高品质的动画，并且在谈话与图像的同步性方面达到了顶尖的表现。<details>
<summary>Abstract</summary>
Synthesizing realistic videos according to a given speech is still an open challenge. Previous works have been plagued by issues such as inaccurate lip shape generation and poor image quality. The key reason is that only motions and appearances on limited facial areas (e.g., lip area) are mainly driven by the input speech. Therefore, directly learning a mapping function from speech to the entire head image is prone to ambiguity, particularly when using a short video for training. We thus propose a decomposition-synthesis-composition framework named Speech to Lip (Speech2Lip) that disentangles speech-sensitive and speech-insensitive motion/appearance to facilitate effective learning from limited training data, resulting in the generation of natural-looking videos. First, given a fixed head pose (i.e., canonical space), we present a speech-driven implicit model for lip image generation which concentrates on learning speech-sensitive motion and appearance. Next, to model the major speech-insensitive motion (i.e., head movement), we introduce a geometry-aware mutual explicit mapping (GAMEM) module that establishes geometric mappings between different head poses. This allows us to paste generated lip images at the canonical space onto head images with arbitrary poses and synthesize talking videos with natural head movements. In addition, a Blend-Net and a contrastive sync loss are introduced to enhance the overall synthesis performance. Quantitative and qualitative results on three benchmarks demonstrate that our model can be trained by a video of just a few minutes in length and achieve state-of-the-art performance in both visual quality and speech-visual synchronization. Code: https://github.com/CVMI-Lab/Speech2Lip.
</details>
<details>
<summary>摘要</summary>
Synthesizing realistic videos according to given speech is still an open challenge. Previous works have been plagued by issues such as inaccurate lip shape generation and poor image quality. The key reason is that only motions and appearances on limited facial areas (e.g., lip area) are mainly driven by the input speech. Therefore, directly learning a mapping function from speech to the entire head image is prone to ambiguity, particularly when using a short video for training. We thus propose a decomposition-synthesis-composition framework named Speech to Lip (Speech2Lip) that disentangles speech-sensitive and speech-insensitive motion/appearance to facilitate effective learning from limited training data, resulting in the generation of natural-looking videos. First, given a fixed head pose (i.e., canonical space), we present a speech-driven implicit model for lip image generation which concentrates on learning speech-sensitive motion and appearance. Next, to model the major speech-insensitive motion (i.e., head movement), we introduce a geometry-aware mutual explicit mapping (GAMEM) module that establishes geometric mappings between different head poses. This allows us to paste generated lip images at the canonical space onto head images with arbitrary poses and synthesize talking videos with natural head movements. In addition, a Blend-Net and a contrastive sync loss are introduced to enhance the overall synthesis performance. Quantitative and qualitative results on three benchmarks demonstrate that our model can be trained by a video of just a few minutes in length and achieve state-of-the-art performance in both visual quality and speech-visual synchronization. Code: <https://github.com/CVMI-Lab/Speech2Lip>.
</details></li>
</ul>
<hr>
<h2 id="VeRi3D-Generative-Vertex-based-Radiance-Fields-for-3D-Controllable-Human-Image-Synthesis"><a href="#VeRi3D-Generative-Vertex-based-Radiance-Fields-for-3D-Controllable-Human-Image-Synthesis" class="headerlink" title="VeRi3D: Generative Vertex-based Radiance Fields for 3D Controllable Human Image Synthesis"></a>VeRi3D: Generative Vertex-based Radiance Fields for 3D Controllable Human Image Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04800">http://arxiv.org/abs/2309.04800</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinya Chen, Jiaxin Huang, Yanrui Bin, Lu Yu, Yiyi Liao</li>
<li>for: 生成高质量人体图像，包括自然的姿势和形态变化。</li>
<li>methods: 使用神经网络学习 vertex-based radiance field， Parametric human template SMPL 进行 parameterization。</li>
<li>results: 可以生成高品质的人体图像，并且可以自由控制摄像机姿势、人姿势、形态变化以及部分编辑。<details>
<summary>Abstract</summary>
Unsupervised learning of 3D-aware generative adversarial networks has lately made much progress. Some recent work demonstrates promising results of learning human generative models using neural articulated radiance fields, yet their generalization ability and controllability lag behind parametric human models, i.e., they do not perform well when generalizing to novel pose/shape and are not part controllable. To solve these problems, we propose VeRi3D, a generative human vertex-based radiance field parameterized by vertices of the parametric human template, SMPL. We map each 3D point to the local coordinate system defined on its neighboring vertices, and use the corresponding vertex feature and local coordinates for mapping it to color and density values. We demonstrate that our simple approach allows for generating photorealistic human images with free control over camera pose, human pose, shape, as well as enabling part-level editing.
</details>
<details>
<summary>摘要</summary>
Recently, there has been significant progress in unsupervised learning of 3D-aware generative adversarial networks. Some recent work has shown promising results in learning human generative models using neural articulated radiance fields, but their generalization ability and controllability are still limited, such as difficulty in generalizing to novel pose/shape and lack of part controllability. To address these issues, we propose VeRi3D, a generative human vertex-based radiance field parameterized by the vertices of the parametric human template, SMPL. We map each 3D point to the local coordinate system defined on its neighboring vertices, and use the corresponding vertex feature and local coordinates to map it to color and density values. Our simple approach enables the generation of photorealistic human images with free control over camera pose, human pose, shape, as well as part-level editing.
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Transformer-with-Domain-Adaptive-Reconstruction-for-General-Face-Forgery-Video-Detection"><a href="#Self-Supervised-Transformer-with-Domain-Adaptive-Reconstruction-for-General-Face-Forgery-Video-Detection" class="headerlink" title="Self-Supervised Transformer with Domain Adaptive Reconstruction for General Face Forgery Video Detection"></a>Self-Supervised Transformer with Domain Adaptive Reconstruction for General Face Forgery Video Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04795">http://arxiv.org/abs/2309.04795</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daichi Zhang, Zihao Xiao, Jianmin Li, Shiming Ge</li>
<li>for: 本研究旨在提高违伪面影片检测效果，尤其是在不同的违伪方法或真实源影片下进行检测时。</li>
<li>methods: 本研究提出了一种基于自动编码器和对比学习的Self-supervised Transformer，并在 fine-tuning 过程中添加了两种辅助任务，即对比学习和重建学习。此外，还提出了一种适应域重建模块，用于在不同违伪频谱上进行适应。</li>
<li>results: 经验表明，提出的方法在公共数据集上进行测试时，能够与现有的超级vised竞争对手相比，并且具有很好的泛化性。<details>
<summary>Abstract</summary>
Face forgery videos have caused severe social public concern, and various detectors have been proposed recently. However, most of them are trained in a supervised manner with limited generalization when detecting videos from different forgery methods or real source videos. To tackle this issue, we explore to take full advantage of the difference between real and forgery videos by only exploring the common representation of real face videos. In this paper, a Self-supervised Transformer cooperating with Contrastive and Reconstruction learning (CoReST) is proposed, which is first pre-trained only on real face videos in a self-supervised manner, and then fine-tuned a linear head on specific face forgery video datasets. Two specific auxiliary tasks incorporated contrastive and reconstruction learning are designed to enhance the representation learning. Furthermore, a Domain Adaptive Reconstruction (DAR) module is introduced to bridge the gap between different forgery domains by reconstructing on unlabeled target videos when fine-tuning. Extensive experiments on public datasets demonstrate that our proposed method performs even better than the state-of-the-art supervised competitors with impressive generalization.
</details>
<details>
<summary>摘要</summary>
《Face forgery videos have caused severe social public concern, and various detectors have been proposed recently. However, most of them are trained in a supervised manner with limited generalization when detecting videos from different forgery methods or real source videos. To tackle this issue, we explore taking full advantage of the difference between real and forgery videos by only exploring the common representation of real face videos. In this paper, a Self-supervised Transformer cooperating with Contrastive and Reconstruction learning (CoReST) is proposed, which is first pre-trained only on real face videos in a self-supervised manner, and then fine-tuned a linear head on specific face forgery video datasets. Two specific auxiliary tasks incorporated contrastive and reconstruction learning are designed to enhance the representation learning. Furthermore, a Domain Adaptive Reconstruction (DAR) module is introduced to bridge the gap between different forgery domains by reconstructing on unlabeled target videos when fine-tuning. Extensive experiments on public datasets demonstrate that our proposed method performs even better than the state-of-the-art supervised competitors with impressive generalization.》Here's the word-for-word translation:《人脸伪造视频引起了严重的社会公众关注，而最近有许多检测器被提出。然而，大多数检测器都是在有监督的方式进行训练，其检测视频的能力受到不同的伪造方法或原始视频的限制。为了解决这个问题，我们尝试了利用真实视频中的差异，并且只探索真实视频的共同表示。在这篇论文中，我们提出了一种基于自助学习的 transformer 和对比学习（CoReST），它首先在真实视频上进行自助学习，然后在特定的伪造视频数据集上进行细致的调整。为了增强表示学习，我们采用了两种特定的辅助任务：对比学习和重构学习。此外，我们还提出了一种适应域重构（DAR）模块，用于在不同的伪造领域之间桥接。在公共数据集上进行了广泛的实验，结果表明，我们的提出的方法能够在充分扩展的情况下，与当前最佳监督者进行比较，并且表现出色。》
</details></li>
</ul>
<hr>
<h2 id="Latent-Degradation-Representation-Constraint-for-Single-Image-Deraining"><a href="#Latent-Degradation-Representation-Constraint-for-Single-Image-Deraining" class="headerlink" title="Latent Degradation Representation Constraint for Single Image Deraining"></a>Latent Degradation Representation Constraint for Single Image Deraining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04780">http://arxiv.org/abs/2309.04780</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhong He, Long Peng, Lu Wang, Jun Cheng</li>
<li>for: 本研究旨在提出一种新的单图排除雨水模型，以解决现有方法难以学习雨水干扰的问题。</li>
<li>methods: 该模型包括指向感知编码器（DAEncoder）、UNet排除网络和多尺度交互块（MSIBlock）。DAEncoder使用可变扩散捕捉雨水束的方向一致性，适应地抽取雨水干扰表示。然后，在训练中引入约束损失来显式地约束干扰表示学习。最后，我们提出了MSIBlock，用于与学习的干扰表示和排除网络的解码特征进行 adaptive 信息互动，以便使排除网络能够消除各种复杂的雨水束和重建图像细节。</li>
<li>results: 实验结果表明，我们的方法在 sintetic 和实际数据集上达到了新的州OF-the-art 性能。<details>
<summary>Abstract</summary>
Since rain streaks show a variety of shapes and directions, learning the degradation representation is extremely challenging for single image deraining. Existing methods are mainly targeted at designing complicated modules to implicitly learn latent degradation representation from coupled rainy images. This way, it is hard to decouple the content-independent degradation representation due to the lack of explicit constraint, resulting in over- or under-enhancement problems. To tackle this issue, we propose a novel Latent Degradation Representation Constraint Network (LDRCNet) that consists of Direction-Aware Encoder (DAEncoder), UNet Deraining Network, and Multi-Scale Interaction Block (MSIBlock). Specifically, the DAEncoder is proposed to adaptively extract latent degradation representation by using the deformable convolutions to exploit the direction consistency of rain streaks. Next, a constraint loss is introduced to explicitly constraint the degradation representation learning during training. Last, we propose an MSIBlock to fuse with the learned degradation representation and decoder features of the deraining network for adaptive information interaction, which enables the deraining network to remove various complicated rainy patterns and reconstruct image details. Experimental results on synthetic and real datasets demonstrate that our method achieves new state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
因为雨条状态呈多种形状和方向，单一图像净化很难学习降低表现的表现。现有方法主要是通过设计复杂的模组来隐式地学习隐藏的降低表现征象，这样很难分离内容独立的降低表现，从而导致过弹或者下弹问题。为解决这个问题，我们提出了一个新的内容独立降低表现条件网络（LDRCNet），它包括了方向感应编码器（DAEncoder）、UNet净化网络和多尺度互动对（MSIBlock）。具体来说，DAEncoder可以透过使用可整合的梯度感应来适应地抽出降低表现的内容独立表现。接着，我们引入了一个约束损失来规范降低表现学习的过程中。最后，我们提出了一个MSIBlock，用于与学习的降低表现和净化网络的解码特征进行互动运算，这使得净化网络能够根据不同的雨条状态和内容独立的降低表现来移除各种复杂的雨条状态和重建图像细节。实验结果显示，我们的方法在synthetic和real dataset上取得了新的顶峰性能。
</details></li>
</ul>
<hr>
<h2 id="Visual-Material-Characteristics-Learning-for-Circular-Healthcare"><a href="#Visual-Material-Characteristics-Learning-for-Circular-Healthcare" class="headerlink" title="Visual Material Characteristics Learning for Circular Healthcare"></a>Visual Material Characteristics Learning for Circular Healthcare</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04763">http://arxiv.org/abs/2309.04763</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fedezocco/matvisiongluinh-pytorch_tensorflow">https://github.com/fedezocco/matvisiongluinh-pytorch_tensorflow</a></li>
<li>paper_authors: Federico Zocco, Shahin Rahimifard</li>
<li>for: 增强医疗垃圾回收链，提高医疗垃圾的再利用率。</li>
<li>methods: 开发了多种视力系统，用于三个主要循环经济任务：资源映射和量化、垃圾分类、和分解。</li>
<li>results: 研究表明，使用表征学视觉技术可以提高回收链的性能，自动化系统是关键因素，因为受污染风险。两个完全注释化数据集也公开发布，用于图像分割和逻辑点跟踪在医疗器械分解过程中。<details>
<summary>Abstract</summary>
The linear take-make-dispose paradigm at the foundations of our traditional economy is proving to be unsustainable due to waste pollution and material supply uncertainties. Hence, increasing the circularity of material flows is necessary. In this paper, we make a step towards circular healthcare by developing several vision systems targeting three main circular economy tasks: resources mapping and quantification, waste sorting, and disassembly. The performance of our systems demonstrates that representation-learning vision can improve the recovery chain, where autonomous systems are key enablers due to the contamination risks. We also published two fully-annotated datasets for image segmentation and for key-point tracking in disassembly operations of inhalers and glucose meters. The datasets and source code are publicly available.
</details>
<details>
<summary>摘要</summary>
传统经济的线性“取-制造-废弃”模式已经显示无法维持可持续发展，由废弃污染和材料供应不确定性而导致。因此，提高物流循环性是必要的。在这篇论文中，我们向循环医疗领域发展了多种视系统，目标是三大循环经济任务：资源映射和评估、废弃分类和分解。我们的系统表现了使用表征学视觉技术可以提高回收链，自主系统作为污染风险的关键启用者。我们还发布了两个完全注释的数据集，一个是图像分割数据集，另一个是关键点跟踪在分解医疗器械和糖尿病测量仪器的数据集。这两个数据集和源代码都公开可用。
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-Triangulation-for-Uncalibrated-Multi-View-3D-Human-Pose-Estimation"><a href="#Probabilistic-Triangulation-for-Uncalibrated-Multi-View-3D-Human-Pose-Estimation" class="headerlink" title="Probabilistic Triangulation for Uncalibrated Multi-View 3D Human Pose Estimation"></a>Probabilistic Triangulation for Uncalibrated Multi-View 3D Human Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04756">http://arxiv.org/abs/2309.04756</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bymaths/probabilistic_triangulation">https://github.com/bymaths/probabilistic_triangulation</a></li>
<li>paper_authors: Boyuan Jiang, Lei Hu, Shihong Xia</li>
<li>for: 本研究旨在提出一种可靠的三维人体 pose 估计方法，以替代现有的固定摄像机pose 方法，提高 pose 估计的泛化能力。</li>
<li>methods: 本方法基于 probablistic triangulation 模块，通过 iteratively 更新摄像机pose 分布，从 2D 特征点计算 posterior 概率，以直接卷积 backwards 传播 gradients，实现 end-to-end 训练。</li>
<li>results: 对 Human3.6M 和 CMU Panoptic 数据集进行了广泛的实验，比较了与其他不准确方法和准确方法进行比较，显示了我们的方法可以达到更高的泛化性和更高的估计精度之间的让步。<details>
<summary>Abstract</summary>
3D human pose estimation has been a long-standing challenge in computer vision and graphics, where multi-view methods have significantly progressed but are limited by the tedious calibration processes. Existing multi-view methods are restricted to fixed camera pose and therefore lack generalization ability. This paper presents a novel Probabilistic Triangulation module that can be embedded in a calibrated 3D human pose estimation method, generalizing it to uncalibration scenes. The key idea is to use a probability distribution to model the camera pose and iteratively update the distribution from 2D features instead of using camera pose. Specifically, We maintain a camera pose distribution and then iteratively update this distribution by computing the posterior probability of the camera pose through Monte Carlo sampling. This way, the gradients can be directly back-propagated from the 3D pose estimation to the 2D heatmap, enabling end-to-end training. Extensive experiments on Human3.6M and CMU Panoptic demonstrate that our method outperforms other uncalibration methods and achieves comparable results with state-of-the-art calibration methods. Thus, our method achieves a trade-off between estimation accuracy and generalizability. Our code is in https://github.com/bymaths/probabilistic_triangulation
</details>
<details>
<summary>摘要</summary>
三维人体姿态估算已经是计算机视觉和图形领域的长期挑战，多视图方法在这一点上已经取得了 significativement progress，但它们受到了繁琐的卡利ibration过程的限制。现有的多视图方法受到固定相机pose的限制，因此缺乏总体化能力。这篇论文提出了一种新的概率三角形模块，可以在卡利ibration场景下插入到已经卡利ibration的三维人体姿态估算方法中，并且可以提高其总体化能力。我们的关键想法是使用概率分布来模型相机pose，并且在每次迭代中更新这个分布，从2D特征上计算后验概率。具体来说，我们保持一个相机pose分布，然后在每次迭代中使用蒙地卡ろ sampling算法来更新这个分布。这样，可以直接从3D姿态估算中传递梯度到2D热图中，实现端到端训练。我们在Human3.6M和CMU Panoptic等数据集上进行了广泛的实验，结果表明，我们的方法在不卡利ibration场景下表现出比其他无卡利ibration方法更好的性能，并且与卡利ibration方法相当的性能。因此，我们的方法实现了姿态估算精度和总体化之间的交换。我们的代码在https://github.com/bymaths/probabilistic_triangulation中。
</details></li>
</ul>
<hr>
<h2 id="Deep-Video-Restoration-for-Under-Display-Camera"><a href="#Deep-Video-Restoration-for-Under-Display-Camera" class="headerlink" title="Deep Video Restoration for Under-Display Camera"></a>Deep Video Restoration for Under-Display Camera</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04752">http://arxiv.org/abs/2309.04752</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuanxi Chen, Tao Wang, Ziqian Shao, Kaihao Zhang, Wenhan Luo, Tong Lu, Zikun Liu, Tae-Kyun Kim, Hongdong Li</li>
<li>For: 这个论文主要针对的是Under-Display Camera（UDC）视频修复（UDC-VR）问题，而现有的UDC修复方法仅专注于图像。* Methods: 这篇论文首先提出了基于GAN生成器的生成管线，用于模拟真实的UDC降低过程。然后，他们建立了大规模的UDC视频修复数据集named PexelsUDC，包括两个子集named PexelsUDC-T和PexelsUDC-P，这两个子集分别对应不同的显示器。* Results: 使用提出的数据集和基线方法，论文进行了广泛的比较研究，发现现有的视频修复方法在UDC-VR任务上存在局限性。然后，他们提出了一种基于 transformer 的新基eline方法，该方法可以充分利用视频的空间和时间信息来修复降低的视频。广泛的实验表明，该方法在 PexelsUDC 上达到了状态级表现。<details>
<summary>Abstract</summary>
Images or videos captured by the Under-Display Camera (UDC) suffer from severe degradation, such as saturation degeneration and color shift. While restoration for UDC has been a critical task, existing works of UDC restoration focus only on images. UDC video restoration (UDC-VR) has not been explored in the community. In this work, we first propose a GAN-based generation pipeline to simulate the realistic UDC degradation process. With the pipeline, we build the first large-scale UDC video restoration dataset called PexelsUDC, which includes two subsets named PexelsUDC-T and PexelsUDC-P corresponding to different displays for UDC. Using the proposed dataset, we conduct extensive benchmark studies on existing video restoration methods and observe their limitations on the UDC-VR task. To this end, we propose a novel transformer-based baseline method that adaptively enhances degraded videos. The key components of the method are a spatial branch with local-aware transformers, a temporal branch embedded temporal transformers, and a spatial-temporal fusion module. These components drive the model to fully exploit spatial and temporal information for UDC-VR. Extensive experiments show that our method achieves state-of-the-art performance on PexelsUDC. The benchmark and the baseline method are expected to promote the progress of UDC-VR in the community, which will be made public.
</details>
<details>
<summary>摘要</summary>
“图像或视频捕捉于下层显示摄像头（UDC）会受到严重的降解效应，如饱和衰减和颜色偏移。而现有的UDC还原方法仅专注于图像还原，UDC视频还原（UDC-VR）尚未在社区中得到探索。在这项工作中，我们首先提出了基于GAN的生成管道，用于模拟真实的UDC降解过程。通过管道，我们建立了首个大规模的UDC视频还原数据集named PexelsUDC，该数据集包括两个子集名为 PexelsUDC-T 和 PexelsUDC-P，分别对应不同的显示器 для UDC。使用我们提posed的数据集，我们进行了广泛的比较研究，发现现有的视频还原方法在UDC-VR任务上存在局限性。为此，我们提出了一种基于 transformer 的基eline方法，该方法可以在不同的显示器上进行自适应增强降解视频。该方法的关键组件包括空间分支、本地化 transformers、嵌入时间 transformers 和空间-时间融合模块。这些组件使得模型能够充分利用空间和时间信息进行UDC-VR。广泛的实验表明，我们的方法在 PexelsUDC 上达到了状态的最佳性能。数据集和基线方法将被公开，以促进社区中 UDC-VR 的进步。”
</details></li>
</ul>
<hr>
<h2 id="Mirror-Aware-Neural-Humans"><a href="#Mirror-Aware-Neural-Humans" class="headerlink" title="Mirror-Aware Neural Humans"></a>Mirror-Aware Neural Humans</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04750">http://arxiv.org/abs/2309.04750</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Ajisafe, James Tang, Shih-Yang Su, Bastian Wandt, Helge Rhodin</li>
<li>for: 实现基于单个摄像头的高质量人体动作捕捉系统，解决多视图系统和单视图系统的缺点。</li>
<li>methods: 使用镜子来记录两个视图，并利用镜子来学习人体完整的形状和精密的外观特征。</li>
<li>results: 实现了一个可靠地从Off-the-shelf 2D姿势获取3Dskeleton姿势，并且在镜子场景中处理 occlusion 问题，提高了系统的可靠性和精度。<details>
<summary>Abstract</summary>
Human motion capture either requires multi-camera systems or is unreliable using single-view input due to depth ambiguities. Meanwhile, mirrors are readily available in urban environments and form an affordable alternative by recording two views with only a single camera. However, the mirror setting poses the additional challenge of handling occlusions of real and mirror image. Going beyond existing mirror approaches for 3D human pose estimation, we utilize mirrors for learning a complete body model, including shape and dense appearance. Our main contributions are extending articulated neural radiance fields to include a notion of a mirror, making it sample-efficient over potential occlusion regions. Together, our contributions realize a consumer-level 3D motion capture system that starts from off-the-shelf 2D poses by automatically calibrating the camera, estimating mirror orientation, and subsequently lifting 2D keypoint detections to 3D skeleton pose that is used to condition the mirror-aware NeRF. We empirically demonstrate the benefit of learning a body model and accounting for occlusion in challenging mirror scenes.
</details>
<details>
<summary>摘要</summary>
人体运动捕捉 either需要多个摄像头系统或者因为深度 ambiguity 导致单视输入不可靠。然而，镜子在城市环境中ready available 并且成为一种可靠的替代方案，只需要一个单个摄像头来记录两个视图。然而，镜子设置增加了处理真实和镜像干扰的挑战。我们超越现有的镜子方法 для 3D人体 pose estimation，我们利用镜子来学习完整的身体模型，包括形状和精密的外观。我们的主要贡献是将 articulated neural radiance fields 扩展到包括镜子的概念，使其在潜在干扰区域上更加效率。在一起，我们的贡献实现了一个消费级3D运动捕捉系统，它可以从OFF-THE-SHELF 2Dpose开始，自动调整摄像头，估算镜子方向，并将2D键点检测提升到3D骨骼姿势，该姿势用于condition mirror-aware NeRF。我们实际示出了学习身体模型和考虑干扰的好处在具有挑战的镜子场景中。
</details></li>
</ul>
<hr>
<h2 id="When-to-Learn-What-Model-Adaptive-Data-Augmentation-Curriculum"><a href="#When-to-Learn-What-Model-Adaptive-Data-Augmentation-Curriculum" class="headerlink" title="When to Learn What: Model-Adaptive Data Augmentation Curriculum"></a>When to Learn What: Model-Adaptive Data Augmentation Curriculum</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04747">http://arxiv.org/abs/2309.04747</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengkai Hou, Jieyu Zhang, Tianyi Zhou</li>
<li>for: 提高神经网络的通用性，通过强制实施输入数据中的一系列固定变换来实现数据增强。</li>
<li>methods: 提出了一种名为 Model Adaptive Data Augmentation (MADAug) 的方法，该方法通过在不同训练阶段选择不同的数据增强操作符来适应每个输入图像，从而生成一个数据增强课程优化了模型的泛化性。</li>
<li>results: 对多个图像分类任务和网络架构进行了广泛的评估，与现有的数据增强方法进行了互相比较，并表明 MADAug 可以在所有类型上提供更好的性能，并且在难度更高的类型上提供更大的改进。此外，MADAug 学习的策略在细化数据上表现更好，并自然地生成了一个易于难度增加的学习课程。<details>
<summary>Abstract</summary>
Data augmentation (DA) is widely used to improve the generalization of neural networks by enforcing the invariances and symmetries to pre-defined transformations applied to input data. However, a fixed augmentation policy may have different effects on each sample in different training stages but existing approaches cannot adjust the policy to be adaptive to each sample and the training model. In this paper, we propose Model Adaptive Data Augmentation (MADAug) that jointly trains an augmentation policy network to teach the model when to learn what. Unlike previous work, MADAug selects augmentation operators for each input image by a model-adaptive policy varying between training stages, producing a data augmentation curriculum optimized for better generalization. In MADAug, we train the policy through a bi-level optimization scheme, which aims to minimize a validation-set loss of a model trained using the policy-produced data augmentations. We conduct an extensive evaluation of MADAug on multiple image classification tasks and network architectures with thorough comparisons to existing DA approaches. MADAug outperforms or is on par with other baselines and exhibits better fairness: it brings improvement to all classes and more to the difficult ones. Moreover, MADAug learned policy shows better performance when transferred to fine-grained datasets. In addition, the auto-optimized policy in MADAug gradually introduces increasing perturbations and naturally forms an easy-to-hard curriculum.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate the following text into Simplified Chinese<</SYS>>数据扩充（DA）广泛应用于神经网络中以提高模型通用性，通过强制数据中的不变性和对称性。然而，现有的方法无法适应每个样本和训练阶段的不同效果，它们的固定扩充策略可能会导致模型的不平衡。在这篇论文中，我们提出了模型适应性数据扩充（MADAug），它将在训练过程中同时训练扩充策略网络，以教导模型何时学习什么。与之前的方法不同，MADAug在每个输入图像上选择的扩充运算符会随训练阶段而变化，生成一个适应性优化的数据扩充课程，以提高模型的通用性。在MADAug中，我们通过两级优化算法，即目标函数优化和权重优化，以iminimize一个验证集损失函数，以训练扩充策略网络。我们进行了多种图像分类任务和网络架构的广泛评估，并进行了对现有DA方法的比较。MADAug在多个任务上具有优于或与其他基elines一样的性能，并且展现出更好的公平性：它对所有类别都带来改进，并对难类更多。此外，MADAug学习的策略表现更好，当 transferred to 细化数据集时。此外，MADAug自动优化的策略逐渐增加干扰量，自然地形成一个易于困难的课程。Note: "Simplified Chinese" is used to refer to the written form of Chinese that uses simpler characters and grammar compared to Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Frequency-Aware-Self-Supervised-Long-Tailed-Learning"><a href="#Frequency-Aware-Self-Supervised-Long-Tailed-Learning" class="headerlink" title="Frequency-Aware Self-Supervised Long-Tailed Learning"></a>Frequency-Aware Self-Supervised Long-Tailed Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04723">http://arxiv.org/abs/2309.04723</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ci-Siang Lin, Min-Hung Chen, Yu-Chiang Frank Wang</li>
<li>for: 本研究旨在 Addressing the challenges of long-tailed data distributions in real-world scenarios, where label annotation may not be available.</li>
<li>methods: 方法方面, the paper proposes Frequency-Aware Self-Supervised Learning (FASSL), which learns discriminative feature representations from unlabeled data with inherent long-tailed distributions. The approach involves learning frequency-aware prototypes and exploiting the relationships between image data and the derived prototypes using a self-supervised learning scheme.</li>
<li>results: 实验结果表明, FASSL 可以有效地学习从无标签数据中，并且可以提供高质量的特征表示。 experiments on long-tailed image datasets demonstrate the effectiveness of the proposed approach.<details>
<summary>Abstract</summary>
Data collected from the real world typically exhibit long-tailed distributions, where frequent classes contain abundant data while rare ones have only a limited number of samples. While existing supervised learning approaches have been proposed to tackle such data imbalance, the requirement of label supervision would limit their applicability to real-world scenarios in which label annotation might not be available. Without the access to class labels nor the associated class frequencies, we propose Frequency-Aware Self-Supervised Learning (FASSL) in this paper. Targeting at learning from unlabeled data with inherent long-tailed distributions, the goal of FASSL is to produce discriminative feature representations for downstream classification tasks. In FASSL, we first learn frequency-aware prototypes, reflecting the associated long-tailed distribution. Particularly focusing on rare-class samples, the relationships between image data and the derived prototypes are further exploited with the introduced self-supervised learning scheme. Experiments on long-tailed image datasets quantitatively and qualitatively verify the effectiveness of our learning scheme.
</details>
<details>
<summary>摘要</summary>
通常来说，实际世界中的数据都会展现长尾分布，其中常见的类别具有丰富的数据，而罕见的类别则只有有限的样本。现有的超级vised学习方法可以解决数据不均衡问题，但是它们需要 labels 的存在，这限制了它们在真实世界中的应用。在这篇文章中，我们提出了不需要 labels 的自动学习方法，即频率意识自我超级学习（FASSL）。我们的目标是从无标签数据中学习具有抑制力的特征表示，以便在下游分类任务中使用。在 FASSL 中，我们首先学习频率意识的原型，这些原型反映了相应的长尾分布。特别是关注罕见类别的样本，我们通过引入的自我超级学习方案来利用这些样本和 derivated 的原型之间的关系。实验表明，我们的学习方法在长尾图像 dataset 上具有较高的效果。
</details></li>
</ul>
<hr>
<h2 id="UnitModule-A-Lightweight-Joint-Image-Enhancement-Module-for-Underwater-Object-Detection"><a href="#UnitModule-A-Lightweight-Joint-Image-Enhancement-Module-for-Underwater-Object-Detection" class="headerlink" title="UnitModule: A Lightweight Joint Image Enhancement Module for Underwater Object Detection"></a>UnitModule: A Lightweight Joint Image Enhancement Module for Underwater Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04708">http://arxiv.org/abs/2309.04708</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuoyan Liu, Bo Wang, Ye Li, Jiaxian He, Yunfeng Li<br>for: 提高对水下物体检测模型的输入图像质量，以提高检测效果。methods: 提出了一种可插入式的水下共同图像增强模块（UnitModule），通过对 UnitModule 和检测器进行无监督学习，以提高UnitModule 和检测器之间的交互。此外，还提出了一种预测颜色偏见的方法，以及一种叫做水下随机颜色传播（UCRT）的数据增强技术。results: 对 DUO  dataset 进行了广泛的实验，并取得了最高改进率的 2.6 AP 以及新测试集（URPCtest）上的改进率为 3.3 AP。 UnitModule 可以提高所有测试模型的性能，特别是具有较少参数的模型。此外，UnitModule 的参数量只有 31K，对原始检测模型的执行速度没有明显的影响。我们的量化和视觉分析也证明了 UnitModule 可以有效地提高输入图像质量和检测器对对象特征的识别能力。<details>
<summary>Abstract</summary>
Underwater object detection faces the problem of underwater image degradation, which affects the performance of the detector. Underwater object detection methods based on noise reduction and image enhancement usually do not provide images preferred by the detector or require additional datasets. In this paper, we propose a plug-and-play Underwater joint image enhancement Module (UnitModule) that provides the input image preferred by the detector. We design an unsupervised learning loss for the joint training of UnitModule with the detector without additional datasets to improve the interaction between UnitModule and the detector. Furthermore, a color cast predictor with the assisting color cast loss and a data augmentation called Underwater Color Random Transfer (UCRT) are designed to improve the performance of UnitModule on underwater images with different color casts. Extensive experiments are conducted on DUO for different object detection models, where UnitModule achieves the highest performance improvement of 2.6 AP for YOLOv5-S and gains the improvement of 3.3 AP on the brand-new test set (URPCtest). And UnitModule significantly improves the performance of all object detection models we test, especially for models with a small number of parameters. In addition, UnitModule with a small number of parameters of 31K has little effect on the inference speed of the original object detection model. Our quantitative and visual analysis also demonstrates the effectiveness of UnitModule in enhancing the input image and improving the perception ability of the detector for object features.
</details>
<details>
<summary>摘要</summary>
水下物体检测面临着水下图像弱化问题，这会影响检测器的性能。通常的水下物体检测方法通过减少噪声和图像提高不提供检测器所需的图像，或者需要额外数据集。在这篇论文中，我们提出了一个卷积核Module（UnitModule），它提供了检测器所需的输入图像。我们设计了一个不supervised学习损失，以joint地训练UnitModule和检测器，从而改善UnitModule和检测器之间的交互。此外，我们还设计了一个帮助预测颜色折射的颜色预测器，以及一种叫做水下随机传播（UCRT）的数据增强技术，以提高UnitModule在不同颜色折射下的性能。我们在DUO上进行了广泛的实验，其中UnitModule在不同的物体检测模型上达到了最高的性能提升2.6AP，并在新的测试集（URPCtest）上提升3.3AP。此外，UnitModule对所有物体检测模型都有显著的性能提升，特别是对具有较少参数的模型。此外，UnitModule具有31K参数，对原始物体检测模型的执行速度有很小的影响。我们的量化和视觉分析也表明，UnitModule可以有效地提高输入图像的质量和检测器对物体特征的感知能力。
</details></li>
</ul>
<hr>
<h2 id="A-Spatial-Temporal-Deformable-Attention-based-Framework-for-Breast-Lesion-Detection-in-Videos"><a href="#A-Spatial-Temporal-Deformable-Attention-based-Framework-for-Breast-Lesion-Detection-in-Videos" class="headerlink" title="A Spatial-Temporal Deformable Attention based Framework for Breast Lesion Detection in Videos"></a>A Spatial-Temporal Deformable Attention based Framework for Breast Lesion Detection in Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04702">http://arxiv.org/abs/2309.04702</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alfredqin/stnet">https://github.com/alfredqin/stnet</a></li>
<li>paper_authors: Chao Qin, Jiale Cao, Huazhu Fu, Rao Muhammad Anwer, Fahad Shahbaz Khan</li>
<li>for: 检测乳腺癌视频是计算机辅助诊断中的关键任务。现有的视频基于乳腺癌检测方法通常是基于自我注意力操作进行时间特征聚合。我们认为这种策略难以有效地执行深度特征聚合，并且忽略了有用的地方信息。</li>
<li>methods: 我们提出了一种空间-时间可变注意力基础框架，名为STNet。我们的STNet引入了一个空间-时间可变注意力模块，以进行本地空间-时间特征融合。这个模块在每个阶段的encoder和decoder中都可以进行深度特征聚合。为了进一步加速检测速度，我们引入了一种encoder特征排序策略，在排序过程中，我们共享了背景和encoder特征，并将encoder特征排序给decoder生成多帧预测结果。</li>
<li>results: 我们在公共乳腺癌ultrasound视频数据集上进行了实验，结果显示，我们的STNet在检测性能方面取得了州属的纪录，同时在检测速度方面也比前者快两倍。代码和模型可以在<a target="_blank" rel="noopener" href="https://github.com/AlfredQin/STNet%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/AlfredQin/STNet上获取。</a><details>
<summary>Abstract</summary>
Detecting breast lesion in videos is crucial for computer-aided diagnosis. Existing video-based breast lesion detection approaches typically perform temporal feature aggregation of deep backbone features based on the self-attention operation. We argue that such a strategy struggles to effectively perform deep feature aggregation and ignores the useful local information. To tackle these issues, we propose a spatial-temporal deformable attention based framework, named STNet. Our STNet introduces a spatial-temporal deformable attention module to perform local spatial-temporal feature fusion. The spatial-temporal deformable attention module enables deep feature aggregation in each stage of both encoder and decoder. To further accelerate the detection speed, we introduce an encoder feature shuffle strategy for multi-frame prediction during inference. In our encoder feature shuffle strategy, we share the backbone and encoder features, and shuffle encoder features for decoder to generate the predictions of multiple frames. The experiments on the public breast lesion ultrasound video dataset show that our STNet obtains a state-of-the-art detection performance, while operating twice as fast inference speed. The code and model are available at https://github.com/AlfredQin/STNet.
</details>
<details>
<summary>摘要</summary>
检测乳腺病变视频是计算机辅助诊断中的关键任务。现有的视频基于 breast lesion 检测方法通常采用深度归一化特征的时间特征聚合方法。我们认为这种策略困难具有效地执行深度特征聚合和忽略了有用的本地信息。为解决这些问题，我们提出了一种空间时间变形注意力基本框架，名为 STNet。我们的 STNet 引入了一个空间时间变形注意力模块，以进行本地空间时间特征融合。这个模块在每个阶段的 both encoder 和 decoder 中进行深度特征聚合。为了进一步加速检测速度，我们提出了一种 encoder 特征混合策略，在推理过程中将 encoder 特征混合多帧预测。在我们的 encoder 特征混合策略中，我们共享 backbone 和 encoder 特征，并在 decoder 中混合 encoder 特征来生成多帧预测。实验结果表明，我们的 STNet 在公共乳腺病变ultrasound video 数据集上取得了状态的检测性能，同时在推理速度上两倍快。代码和模型可以在 <https://github.com/AlfredQin/STNet> 中下载。
</details></li>
</ul>
<hr>
<h2 id="DeNoising-MOT-Towards-Multiple-Object-Tracking-with-Severe-Occlusions"><a href="#DeNoising-MOT-Towards-Multiple-Object-Tracking-with-Severe-Occlusions" class="headerlink" title="DeNoising-MOT: Towards Multiple Object Tracking with Severe Occlusions"></a>DeNoising-MOT: Towards Multiple Object Tracking with Severe Occlusions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04682">http://arxiv.org/abs/2309.04682</a></li>
<li>repo_url: None</li>
<li>paper_authors: Teng Fu, Xiaocong Wang, Haiyang Yu, Ke Niu, Bin Li, Xiangyang Xue</li>
<li>for: 提高多对目标跟踪（MOT）在受阻碍的情况下的性能。</li>
<li>methods: 使用增强的隐藏状态和推理框架，以及一种新的排除噪声的策略。</li>
<li>results: 在MOT17、MOT20和DanceTrack datasets上进行了广泛的实验，并表明了与之前的状态革命性的提高。<details>
<summary>Abstract</summary>
Multiple object tracking (MOT) tends to become more challenging when severe occlusions occur. In this paper, we analyze the limitations of traditional Convolutional Neural Network-based methods and Transformer-based methods in handling occlusions and propose DNMOT, an end-to-end trainable DeNoising Transformer for MOT. To address the challenge of occlusions, we explicitly simulate the scenarios when occlusions occur. Specifically, we augment the trajectory with noises during training and make our model learn the denoising process in an encoder-decoder architecture, so that our model can exhibit strong robustness and perform well under crowded scenes. Additionally, we propose a Cascaded Mask strategy to better coordinate the interaction between different types of queries in the decoder to prevent the mutual suppression between neighboring trajectories under crowded scenes. Notably, the proposed method requires no additional modules like matching strategy and motion state estimation in inference. We conduct extensive experiments on the MOT17, MOT20, and DanceTrack datasets, and the experimental results show that our method outperforms previous state-of-the-art methods by a clear margin.
</details>
<details>
<summary>摘要</summary>
多bject 跟踪 (MOT) 在严重遮挡情况下变得更加挑战。在这篇论文中，我们分析传统的卷积神经网络基本方法和转移器基本方法在处理遮挡的局限性，并提出了DNMOT，一种可以受教育的端到端的减噪变换器 для MOT。为了解决遮挡的挑战，我们在训练时间添加了噪声到轨迹上，使我们的模型在encoder-decoder架构中学习减噪过程，从而使我们的模型在拥挤的场景下表现出强大的鲁棒性。此外，我们提出了协调器策略，以更好地协调不同类型的查询在解码器中的交互，从而避免在拥挤的场景下邻近轨迹之间的互相抑制。值得注意的是，我们提出的方法不需要在推断过程中添加额外的模块，如匹配策略和运动状态估计。我们在MOT17、MOT20和DanceTrack datasets上进行了广泛的实验，实验结果表明，我们的方法在前一代方法之上具有明显的优势。
</details></li>
</ul>
<hr>
<h2 id="BiLMa-Bidirectional-Local-Matching-for-Text-based-Person-Re-identification"><a href="#BiLMa-Bidirectional-Local-Matching-for-Text-based-Person-Re-identification" class="headerlink" title="BiLMa: Bidirectional Local-Matching for Text-based Person Re-identification"></a>BiLMa: Bidirectional Local-Matching for Text-based Person Re-identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04675">http://arxiv.org/abs/2309.04675</a></li>
<li>repo_url: None</li>
<li>paper_authors: Takuro Fujii, Shuhei Tarashima<br>for: 这个论文是针对文本描述人脸图像的重新识别问题（Text-based Person Re-identification，TBPReID）的研究。methods: 这个论文使用的方法是将图像和文本部分对齐，并通过Masked Language Modeling（MLM）和Masked Image Modeling（MIM）进行协调训练。它还提出了对向（from text to image）和反向（from image to text）的本地匹配方法，以提高TBPReID的性能。results: 根据实验结果，这个方法在三个测试 benchmark 上达到了当今最佳的 Rank@1 和 mAP 分数。<details>
<summary>Abstract</summary>
Text-based person re-identification (TBPReID) aims to retrieve person images represented by a given textual query. In this task, how to effectively align images and texts globally and locally is a crucial challenge. Recent works have obtained high performances by solving Masked Language Modeling (MLM) to align image/text parts. However, they only performed uni-directional (i.e., from image to text) local-matching, leaving room for improvement by introducing opposite-directional (i.e., from text to image) local-matching. In this work, we introduce Bidirectional Local-Matching (BiLMa) framework that jointly optimize MLM and Masked Image Modeling (MIM) in TBPReID model training. With this framework, our model is trained so as the labels of randomly masked both image and text tokens are predicted by unmasked tokens. In addition, to narrow the semantic gap between image and text in MIM, we propose Semantic MIM (SemMIM), in which the labels of masked image tokens are automatically given by a state-of-the-art human parser. Experimental results demonstrate that our BiLMa framework with SemMIM achieves state-of-the-art Rank@1 and mAP scores on three benchmarks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SSHNN-Semi-Supervised-Hybrid-NAS-Network-for-Echocardiographic-Image-Segmentation"><a href="#SSHNN-Semi-Supervised-Hybrid-NAS-Network-for-Echocardiographic-Image-Segmentation" class="headerlink" title="SSHNN: Semi-Supervised Hybrid NAS Network for Echocardiographic Image Segmentation"></a>SSHNN: Semi-Supervised Hybrid NAS Network for Echocardiographic Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04672">http://arxiv.org/abs/2309.04672</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renqi Chen, Jingjing Luo, Fan Nian, Yuhui Cen, Yiheng Peng, Zekuan Yu</li>
<li>for: 准确的医疗影像分割，特别是echocardiographic图像处理中的噪声难以忽略，需要 elaboration 的网络设计。</li>
<li>methods: 我们提出了一种新的半supervised Hybrid NAS网络（SSHNN），利用卷积操作来实现层次特征融合，并通过引入Transformers来补做全局上下文，以及U-shaped解码器来有效地连接全局上下文和本地特征。</li>
<li>results: 我们在CAMUS医学电子心肺图像集上进行了广泛的实验，发现SSHNN比 estado-of-the-art方法更高效，实现了高精度的分割。<details>
<summary>Abstract</summary>
Accurate medical image segmentation especially for echocardiographic images with unmissable noise requires elaborate network design. Compared with manual design, Neural Architecture Search (NAS) realizes better segmentation results due to larger search space and automatic optimization, but most of the existing methods are weak in layer-wise feature aggregation and adopt a ``strong encoder, weak decoder" structure, insufficient to handle global relationships and local details. To resolve these issues, we propose a novel semi-supervised hybrid NAS network for accurate medical image segmentation termed SSHNN. In SSHNN, we creatively use convolution operation in layer-wise feature fusion instead of normalized scalars to avoid losing details, making NAS a stronger encoder. Moreover, Transformers are introduced for the compensation of global context and U-shaped decoder is designed to efficiently connect global context with local features. Specifically, we implement a semi-supervised algorithm Mean-Teacher to overcome the limited volume problem of labeled medical image dataset. Extensive experiments on CAMUS echocardiography dataset demonstrate that SSHNN outperforms state-of-the-art approaches and realizes accurate segmentation. Code will be made publicly available.
</details>
<details>
<summary>摘要</summary>
准确的医疗图像分割，特别是用于echocardiographic图像，需要考虑到干扰的存在。传统的手动设计方法在层次特征聚合方面有限，而Neural Architecture Search（NAS）可以通过更大的搜索空间和自动优化来实现更好的分割结果。然而，现有的方法通常具有“强Encoder,弱Decoder”结构，无法处理全局关系和地方细节。为解决这些问题，我们提出了一种新的半supervised Hybrid NAS网络，称为 SSHNN。在 SSHNN 中，我们创新地使用卷积操作来实现层次特征融合，而不是使用normalized scalars，以避免丢失细节。此外，我们还引入了Transformers来补做全局上下文，并设计了U型决策器来有效地连接全局上下文和地方特征。具体来说，我们实现了一种半supervised算法Mean-Teacher来超越医疗图像数据集的限制。我们进行了广泛的实验，并证明了 SSHNN 可以超过现有的方法，并实现准确的分割。代码将公开发布。
</details></li>
</ul>
<hr>
<h2 id="Unified-Language-Vision-Pretraining-with-Dynamic-Discrete-Visual-Tokenization"><a href="#Unified-Language-Vision-Pretraining-with-Dynamic-Discrete-Visual-Tokenization" class="headerlink" title="Unified Language-Vision Pretraining with Dynamic Discrete Visual Tokenization"></a>Unified Language-Vision Pretraining with Dynamic Discrete Visual Tokenization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04669">http://arxiv.org/abs/2309.04669</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jy0205/LaVIT">https://github.com/jy0205/LaVIT</a></li>
<li>paper_authors: Yang Jin, Kun Xu, Kun Xu, Liwei Chen, Chao Liao, Jianchao Tan, Bin Chen, Chenyi Lei, An Liu, Chengru Song, Xiaoqiang Lei, Yadong Mu, Di Zhang, Wenwu Ou, Kun Gai</li>
<li>for: 本研究旨在突破现有语言模型只允许视觉输入的限制，将语言和视觉都 Represented为一个共同表示，以提高多模态理解能力。</li>
<li>methods: 作者提出了一种名为LaVIT（语言-视觉 transformer）的基础模型，该模型通过一种图像tokenizer将非语言图像转化为一个序列化的语言形式，从而使得模型可以同时处理图像和文本。</li>
<li>results: 对于下游任务，LaVIT比现有模型提高了大幅度的性能，并且在多模态理解任务中表现出色。<details>
<summary>Abstract</summary>
Recently, the remarkable advance of the Large Language Model (LLM) has inspired researchers to transfer its extraordinary reasoning capability to data across several modalities. The prevailing approaches primarily regard visual input as the prompt and focus exclusively on optimizing the text generation process conditioned upon vision content by a frozen LLM. Such an inequitable treatment of vision and language heavily constrains the model's potential. In this paper, we break through this limitation by representing both vision and language in a unified representation. To this end, we craft a visual tokenizer that translates the non-linguistic image into a sequence of discrete tokens like a foreign language that LLM can read. The resulting visual tokens encompass high-level semantics worthy of a word and also support dynamic sequence length varying from the image content. Coped with this visual tokenizer, the presented foundation model called LaVIT (Language-VIsion Transformer) can handle both image and text indiscriminately under a unified generative learning paradigm. Pre-trained on the web-scale image-text corpus, LaVIT is empowered with impressive multi-modal comprehension capability. The extensive experiments showcase that it outperforms existing models by a large margin on downstream tasks. Our code and models will be available at https://github.com/jy0205/LaVIT.
</details>
<details>
<summary>摘要</summary>
近期，大型语言模型（LLM）的出色发展已经激发了研究人员将其杰出的思维能力应用到多 modalities 的数据上。现有的方法主要将视觉输入视为提示，归类专门为conditioned upon vision content by a frozen LLM。这种对视觉和语言的不公平待遇，具有严重限制模型的潜力。在这篇论文中，我们突破这一限制，将视觉和语言都 Represented 为共同表示。为此，我们设计了一种视觉化 токен化器，将非语言的图像转化为一系列精确的 discrete tokens，这些 tokens 类似于外语，LLM 可以读取。得到的视觉 tokens 包含高级别 semantics 和支持动态序列长度，从图像内容而来。与这种视觉化 токен化器相配合，我们提出的基础模型 called LaVIT (Language-VIsion Transformer) 可以平等地处理图像和文本，并在一个共同生成学习 paradigm 下进行学习。预训练在网络规模的图像-文本 Corporpus 上，LaVIT 具有卓越的多模态理解能力。广泛的实验表明，它在下游任务上高度超越现有模型。我们的代码和模型将在 GitHub 上提供，请参考 https://github.com/jy0205/LaVIT。
</details></li>
</ul>
<hr>
<h2 id="ConvFormer-Plug-and-Play-CNN-Style-Transformers-for-Improving-Medical-Image-Segmentation"><a href="#ConvFormer-Plug-and-Play-CNN-Style-Transformers-for-Improving-Medical-Image-Segmentation" class="headerlink" title="ConvFormer: Plug-and-Play CNN-Style Transformers for Improving Medical Image Segmentation"></a>ConvFormer: Plug-and-Play CNN-Style Transformers for Improving Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05674">http://arxiv.org/abs/2309.05674</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xianlin7/convformer">https://github.com/xianlin7/convformer</a></li>
<li>paper_authors: Xian Lin, Zengqiang Yan, Xianbo Deng, Chuansheng Zheng, Li Yu</li>
<li>for: 提高transformer-based框架中的 segmentation性能，增强对医疗图像的分类能力。</li>
<li>methods: 提出CNN-style Transformers（ConvFormer），通过增强注意力归一化和特征提取来提高分类性能。ConvFormer包括pooling、CNN-style自注意（CSA）和卷积FeedForward Network（CFFN），可以作为vanilla Vision Transformers中的tokenization、self-attention和FeedForward Network。</li>
<li>results: 在多个 dataset上展示了ConvFormer作为plug-and-play模块，可以遥增transformer-based框架中的segmentation性能。<details>
<summary>Abstract</summary>
Transformers have been extensively studied in medical image segmentation to build pairwise long-range dependence. Yet, relatively limited well-annotated medical image data makes transformers struggle to extract diverse global features, resulting in attention collapse where attention maps become similar or even identical. Comparatively, convolutional neural networks (CNNs) have better convergence properties on small-scale training data but suffer from limited receptive fields. Existing works are dedicated to exploring the combinations of CNN and transformers while ignoring attention collapse, leaving the potential of transformers under-explored. In this paper, we propose to build CNN-style Transformers (ConvFormer) to promote better attention convergence and thus better segmentation performance. Specifically, ConvFormer consists of pooling, CNN-style self-attention (CSA), and convolutional feed-forward network (CFFN) corresponding to tokenization, self-attention, and feed-forward network in vanilla vision transformers. In contrast to positional embedding and tokenization, ConvFormer adopts 2D convolution and max-pooling for both position information preservation and feature size reduction. In this way, CSA takes 2D feature maps as inputs and establishes long-range dependency by constructing self-attention matrices as convolution kernels with adaptive sizes. Following CSA, 2D convolution is utilized for feature refinement through CFFN. Experimental results on multiple datasets demonstrate the effectiveness of ConvFormer working as a plug-and-play module for consistent performance improvement of transformer-based frameworks. Code is available at https://github.com/xianlin7/ConvFormer.
</details>
<details>
<summary>摘要</summary>
transformers 已经广泛研究在医学影像分割中建立对比较远范围的长距离相依性。然而，有限的高质量医学影像数据使 transformers 具有医学影像分割中的注意力塌缩现象，其中注意力映射变得相似或 même identical。相比之下，卷积神经网络（CNN）在小规模训练数据上具有更好的收敛性能，但它们受限于有限的接收场。现有的工作主要关注于将 CNN 和 transformers 结合使用，而忽略了注意力塌缩现象，这使得 transformers 的潜在能力尚未得到充分探索。在这篇论文中，我们提出了一种基于 CNN 的 transformers（ConvFormer），以便提高注意力的叠合和医学影像分割性能。具体来说，ConvFormer 包括池化、CNN 样式自注意（CSA）和卷积神经网络（CFFN），与标准视觉 transformers 中的征文化、自注意和Feed Forward 网络相对应。与position embedding和分割不同，ConvFormer 采用了2D卷积和最大池化来保持位坐标信息和特征大小减少。这样，CSA 可以将 2D 特征图作为输入，建立长距离相依性 by 构建自注意矩阵作为卷积核函数的 adaptive 大小。接着，2D 卷积被用于特征细化通过 CFFN。实验结果表明，ConvFormer 作为 transformer 基础架构中的插件模块，可以提高 transformer 基础架构的一致性和医学影像分割性能。代码可以在 https://github.com/xianlin7/ConvFormer 找到。
</details></li>
</ul>
<hr>
<h2 id="Progressive-Feature-Adjustment-for-Semi-supervised-Learning-from-Pretrained-Models"><a href="#Progressive-Feature-Adjustment-for-Semi-supervised-Learning-from-Pretrained-Models" class="headerlink" title="Progressive Feature Adjustment for Semi-supervised Learning from Pretrained Models"></a>Progressive Feature Adjustment for Semi-supervised Learning from Pretrained Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04659">http://arxiv.org/abs/2309.04659</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hai-Ming Xu, Lingqiao Liu, Hao Chen, Ehsan Abbasnejad, Rafael Felix</li>
<li>for: 提高 semi-supervised learning 的性能，解决数据标注束缚问题</li>
<li>methods: 使用 pseudo-labels 更新 feature extractor，保证 feature distribution 维护良好的类别分离性，并且只允许类ifier 通过 labels 进行训练</li>
<li>results: 对比现有解决方案，提出的方法实现更高的性能<details>
<summary>Abstract</summary>
As an effective way to alleviate the burden of data annotation, semi-supervised learning (SSL) provides an attractive solution due to its ability to leverage both labeled and unlabeled data to build a predictive model. While significant progress has been made recently, SSL algorithms are often evaluated and developed under the assumption that the network is randomly initialized. This is in sharp contrast to most vision recognition systems that are built from fine-tuning a pretrained network for better performance. While the marriage of SSL and a pretrained model seems to be straightforward, recent literature suggests that naively applying state-of-the-art SSL with a pretrained model fails to unleash the full potential of training data. In this paper, we postulate the underlying reason is that the pretrained feature representation could bring a bias inherited from the source data, and the bias tends to be magnified through the self-training process in a typical SSL algorithm. To overcome this issue, we propose to use pseudo-labels from the unlabelled data to update the feature extractor that is less sensitive to incorrect labels and only allow the classifier to be trained from the labeled data. More specifically, we progressively adjust the feature extractor to ensure its induced feature distribution maintains a good class separability even under strong input perturbation. Through extensive experimental studies, we show that the proposed approach achieves superior performance over existing solutions.
</details>
<details>
<summary>摘要</summary>
为了减轻数据标注的负担，半upervised learning（SSL）提供了一个有力的解决方案，因为它可以利用标注和无标注数据建立预测模型。 although significant progress has been made recently, SSL algorithms are often evaluated and developed under the assumption that the network is randomly initialized. This is in sharp contrast to most vision recognition systems that are built from fine-tuning a pretrained network for better performance. While the marriage of SSL and a pretrained model seems to be straightforward, recent literature suggests that naively applying state-of-the-art SSL with a pretrained model fails to unleash the full potential of training data. In this paper, we postulate that the underlying reason is that the pretrained feature representation could bring a bias inherited from the source data, and the bias tends to be magnified through the self-training process in a typical SSL algorithm. To overcome this issue, we propose to use pseudo-labels from the unlabelled data to update the feature extractor that is less sensitive to incorrect labels and only allow the classifier to be trained from the labeled data. More specifically, we progressively adjust the feature extractor to ensure its induced feature distribution maintains a good class separability even under strong input perturbation. Through extensive experimental studies, we show that the proposed approach achieves superior performance over existing solutions.Note: The translation is in Simplified Chinese, which is one of the two standard versions of Chinese used in mainland China and Singapore.
</details></li>
</ul>
<hr>
<h2 id="Generation-and-Recombination-for-Multifocus-Image-Fusion-with-Free-Number-of-Inputs"><a href="#Generation-and-Recombination-for-Multifocus-Image-Fusion-with-Free-Number-of-Inputs" class="headerlink" title="Generation and Recombination for Multifocus Image Fusion with Free Number of Inputs"></a>Generation and Recombination for Multifocus Image Fusion with Free Number of Inputs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04657">http://arxiv.org/abs/2309.04657</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huafeng Li, Dan Wang, Yuxin Huang, Yafei Zhang, Zhengtao Yu</li>
<li>for:  overcome the limitation of optical lenses and achieve simultaneous fusion of multiple images</li>
<li>methods:  combining generation and recombination model (GRFusion), hard-pixel-guided recombination mechanism, and multi-directional gradient embedding method</li>
<li>results:  effective and superior fusion performance, free from the number of inputs and with improved visual quality<details>
<summary>Abstract</summary>
Multifocus image fusion is an effective way to overcome the limitation of optical lenses. Many existing methods obtain fused results by generating decision maps. However, such methods often assume that the focused areas of the two source images are complementary, making it impossible to achieve simultaneous fusion of multiple images. Additionally, the existing methods ignore the impact of hard pixels on fusion performance, limiting the visual quality improvement of fusion image. To address these issues, a combining generation and recombination model, termed as GRFusion, is proposed. In GRFusion, focus property detection of each source image can be implemented independently, enabling simultaneous fusion of multiple source images and avoiding information loss caused by alternating fusion. This makes GRFusion free from the number of inputs. To distinguish the hard pixels from the source images, we achieve the determination of hard pixels by considering the inconsistency among the detection results of focus areas in source images. Furthermore, a multi-directional gradient embedding method for generating full focus images is proposed. Subsequently, a hard-pixel-guided recombination mechanism for constructing fused result is devised, effectively integrating the complementary advantages of feature reconstruction-based method and focused pixel recombination-based method. Extensive experimental results demonstrate the effectiveness and the superiority of the proposed method.The source code will be released on https://github.com/xxx/xxx.
</details>
<details>
<summary>摘要</summary>
多聚焦图像融合是一种有效的方法来超越光学镜头的限制。许多现有方法通过生成决策地图来获得融合结果，但这些方法经常假设源图像的焦点区域是补偿的，这使得同时融合多个图像变得不可能。此外，现有方法忽略了融合过程中硬Pixel的影响，从而限制融合图像的视觉质量改善。为解决这些问题，我们提出了GRFusion模型。GRFusion模型中可以独立实现每个源图像的焦点属性检测，因此可以同时融合多个源图像，避免因为交替融合而产生的信息损失。这使得GRFusion模型不受输入数量的限制。为了分辨硬Pixel与源图像之间的差异，我们提出了基于focus区域的决策结果的不一致来确定硬Pixel。此外，我们还提出了一种多向导向量嵌入方法来生成全焦图像。然后，我们设计了一种基于硬Pixel指导的融合机制，以有效地结合了特征重建方法和焦点像素重建方法的优点。经验证明了我们的方法的有效性和优越性。源代码将在GitHub上发布。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Robust-Features-for-Improving-Adversarial-Robustness"><a href="#Exploring-Robust-Features-for-Improving-Adversarial-Robustness" class="headerlink" title="Exploring Robust Features for Improving Adversarial Robustness"></a>Exploring Robust Features for Improving Adversarial Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04650">http://arxiv.org/abs/2309.04650</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hong Wang, Yuefan Deng, Shinjae Yoo, Yuewei Lin</li>
<li>for: 提高深度神经网络（DNNs）在安全敏感应用中的使用，因为它们容易受到特制攻击。</li>
<li>methods: 提出了一种特征分离模型，用于分离Robust特征和非Robust特征以及域специфи的特征。</li>
<li>results: 对四种广泛使用的数据集进行了extensive实验，并证明了我们的模型可以提高对特制攻击的抵抗力，并且可以准确地识别域特定的特征。<details>
<summary>Abstract</summary>
While deep neural networks (DNNs) have revolutionized many fields, their fragility to carefully designed adversarial attacks impedes the usage of DNNs in safety-critical applications. In this paper, we strive to explore the robust features which are not affected by the adversarial perturbations, i.e., invariant to the clean image and its adversarial examples, to improve the model's adversarial robustness. Specifically, we propose a feature disentanglement model to segregate the robust features from non-robust features and domain specific features. The extensive experiments on four widely used datasets with different attacks demonstrate that robust features obtained from our model improve the model's adversarial robustness compared to the state-of-the-art approaches. Moreover, the trained domain discriminator is able to identify the domain specific features from the clean images and adversarial examples almost perfectly. This enables adversarial example detection without incurring additional computational costs. With that, we can also specify different classifiers for clean images and adversarial examples, thereby avoiding any drop in clean image accuracy.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）在许多领域中已经引领了革命，但它们对特制的敌意攻击却有很大的敏感性，这限制了DNN在安全关键应用程序中的使用。在这篇论文中，我们尝试探索抗敌攻击的可靠特征，即对于清洁图像和敌意攻击的稳定特征，以提高模型的抗敌能力。具体来说，我们提出了特征分离模型，以分离可靠特征和非可靠特征、域特定特征。我们在四种广泛使用的数据集上进行了大量的实验，并证明了我们的模型可以在不同的攻击下提高抗敌能力，并且域特定特征分离器可以准确地从清洁图像和敌意攻击中分离域特定特征。这使得我们可以采取不同的分类器来处理清洁图像和敌意攻击，从而避免清洁图像精度下降。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/09/cs.CV_2023_09_09/" data-id="cloimip9100h6s4881p1tg5ji" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/09/cs.AI_2023_09_09/" class="article-date">
  <time datetime="2023-09-09T12:00:00.000Z" itemprop="datePublished">2023-09-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/09/cs.AI_2023_09_09/">cs.AI - 2023-09-09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="How-to-Evaluate-Semantic-Communications-for-Images-with-ViTScore-Metric"><a href="#How-to-Evaluate-Semantic-Communications-for-Images-with-ViTScore-Metric" class="headerlink" title="How to Evaluate Semantic Communications for Images with ViTScore Metric?"></a>How to Evaluate Semantic Communications for Images with ViTScore Metric?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04891">http://arxiv.org/abs/2309.04891</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tingting Zhu, Bo Peng, Jifan Liang, Tingchen Han, Hai Wan, Jingqiao Fu, Junjie Chen</li>
<li>for: 这 paper 的目的是为了提出一种新的图像Semantic Similarity评估方法，以替代传统的图像相似度评估方法，以便在Semantic Communications 中更好地交换semantic information。</li>
<li>methods: 这 paper 使用了一种基于 Transformer 模型的新 metric，名为 Vision Transformer Score (ViTScore)，来评估图像的Semantic Similarity。</li>
<li>results: 经过5类 экспериimento，结果表明，ViTScore 能够更好地评估图像的Semantic Similarity，比传统的 PSNR、MS-SSIM 和 LPIPS 三种 metric 更加有效。<details>
<summary>Abstract</summary>
Semantic communications (SC) have been expected to be a new paradigm shifting to catalyze the next generation communication, whose main concerns shift from accurate bit transmission to effective semantic information exchange in communications. However, the previous and widely-used metrics for images are not applicable to evaluate the image semantic similarity in SC. Classical metrics to measure the similarity between two images usually rely on the pixel level or the structural level, such as the PSNR and the MS-SSIM. Straightforwardly using some tailored metrics based on deep-learning methods in CV community, such as the LPIPS, is infeasible for SC. To tackle this, inspired by BERTScore in NLP community, we propose a novel metric for evaluating image semantic similarity, named Vision Transformer Score (ViTScore). We prove theoretically that ViTScore has 3 important properties, including symmetry, boundedness, and normalization, which make ViTScore convenient and intuitive for image measurement. To evaluate the performance of ViTScore, we compare ViTScore with 3 typical metrics (PSNR, MS-SSIM, and LPIPS) through 5 classes of experiments. Experimental results demonstrate that ViTScore can better evaluate the image semantic similarity than the other 3 typical metrics, which indicates that ViTScore is an effective performance metric when deployed in SC scenarios.
</details>
<details>
<summary>摘要</summary>
听说（SC）将被看作是一个新的思维方式，它将catalyze下一代通信，主要关注从精确位传输升级到有效semantic信息交换在通信中。然而，过去广泛使用的图像评估 metric不适用于图像semantic相似性的评估。经典的图像相似性评估方法通常基于像素层或结构层，如PSNR和MS-SSIM。直接使用CV社区的深度学习方法基于metric，如LPIPS，是不可能的SC中。为了解决这个问题，我们提出了一种新的图像semantic相似性评估 metric，名为视觉 трансформа器分数（ViTScore）。我们证明了ViTScore具有3个重要的性质，包括对称性、卷积性和正规化性，这些性质使得ViTScore在图像评估中方便又直观。为了评估ViTScore的性能，我们与3种典型的metric（PSNR、MS-SSIM和LPIPS）进行5种类型的实验。实验结果表明，ViTScore可以更好地评估图像semantic相似性，这表明ViTScore是SC场景中的有效性能指标。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Chatbots-to-Promote-Users’-Trust-–-Practices-and-Open-Problems"><a href="#Evaluating-Chatbots-to-Promote-Users’-Trust-–-Practices-and-Open-Problems" class="headerlink" title="Evaluating Chatbots to Promote Users’ Trust – Practices and Open Problems"></a>Evaluating Chatbots to Promote Users’ Trust – Practices and Open Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05680">http://arxiv.org/abs/2309.05680</a></li>
<li>repo_url: None</li>
<li>paper_authors: Biplav Srivastava, Kausik Lakkaraju, Tarmo Koppel, Vignesh Narayanan, Ashish Kundu, Sachindra Joshi</li>
<li>for: 评估聊天机器人（chatbot）的可靠性和用户满意度，以及长期对社会的影响。</li>
<li>methods: 现有的chatbot测试方法和开放问题，以及未来的测试方法和技术。</li>
<li>results: 评估chatbot的性能和用户满意度，以及对社会的长期影响。<details>
<summary>Abstract</summary>
Chatbots, the common moniker for collaborative assistants, are Artificial Intelligence (AI) software that enables people to naturally interact with them to get tasks done. Although chatbots have been studied since the dawn of AI, they have particularly caught the imagination of the public and businesses since the launch of easy-to-use and general-purpose Large Language Model-based chatbots like ChatGPT. As businesses look towards chatbots as a potential technology to engage users, who may be end customers, suppliers, or even their own employees, proper testing of chatbots is important to address and mitigate issues of trust related to service or product performance, user satisfaction and long-term unintended consequences for society. This paper reviews current practices for chatbot testing, identifies gaps as open problems in pursuit of user trust, and outlines a path forward.
</details>
<details>
<summary>摘要</summary>
chatbots，它们是人工智能软件，允许人们自然地与其交互，完成任务。虽然 chatbots 已经从人工智能出现以来被研究，但是它们特别在 ChatGPT 类大语言模型基础上的易于使用和通用 chatbots 出现后，引起了公众和企业的关注。在企业希望通过 chatbots 来与用户进行互动，包括客户、供应商和员工，正确测试 chatbots 是非常重要的，以解决服务或产品性能、用户满意度和社会长期未来的问题。本文将评论当前 chatbot 测试实践，描述存在的问题和挑战，并提出未来的发展道路。
</details></li>
</ul>
<hr>
<h2 id="Recall-driven-Precision-Refinement-Unveiling-Accurate-Fall-Detection-using-LSTM"><a href="#Recall-driven-Precision-Refinement-Unveiling-Accurate-Fall-Detection-using-LSTM" class="headerlink" title="Recall-driven Precision Refinement: Unveiling Accurate Fall Detection using LSTM"></a>Recall-driven Precision Refinement: Unveiling Accurate Fall Detection using LSTM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07154">http://arxiv.org/abs/2309.07154</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rishabh Mondal, Prasun Ghosal</li>
<li>for: 这篇研究旨在解决老年人堕伤的问题，通过开发一个精准的堕伤检测系统。</li>
<li>methods: 本研究使用了现代技术，包括加速计和陀螺仪数据，与深度学习模型，具体是长期快速传统机制（LSTM）网络。实时执行能力通过raspberry Pi硬件的整合。我们还提出了裁剪技术，对LSTM模型的架构和参数进行精确调整，以便提高系统的性能。</li>
<li>results: 我们的实验结果显示，本系统具有高精度和高特异性（96%），实现了堕伤检测的目标。我们的研究将fall detection技术带到了新的水平，提供了一个可靠和有效的堕伤预防和处理解决方案。<details>
<summary>Abstract</summary>
This paper presents an innovative approach to address the pressing concern of fall incidents among the elderly by developing an accurate fall detection system. Our proposed system combines state-of-the-art technologies, including accelerometer and gyroscope sensors, with deep learning models, specifically Long Short-Term Memory (LSTM) networks. Real-time execution capabilities are achieved through the integration of Raspberry Pi hardware. We introduce pruning techniques that strategically fine-tune the LSTM model's architecture and parameters to optimize the system's performance. We prioritize recall over precision, aiming to accurately identify falls and minimize false negatives for timely intervention. Extensive experimentation and meticulous evaluation demonstrate remarkable performance metrics, emphasizing a high recall rate while maintaining a specificity of 96\%. Our research culminates in a state-of-the-art fall detection system that promptly sends notifications, ensuring vulnerable individuals receive timely assistance and improve their overall well-being. Applying LSTM models and incorporating pruning techniques represent a significant advancement in fall detection technology, offering an effective and reliable fall prevention and intervention solution.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)这篇论文提出了一种创新的方法，用于解决老年人倒下的问题，即开发一个高度准确的倒下检测系统。我们的提议的系统结合了当前最佳的技术，包��加速度和自转仪器，以及深度学习模型，具体来说是Long Short-Term Memory（LSTM）网络。通过raspberry pi硬件的集成，实现了实时执行能力。我们引入了截剪技术，以优化LSTM模型的结构和参数，以提高系统的性能。我们偏好回报，即准确地识别倒下，而不是精度。通过严格的实验和评估，我们得到了惊人的性能指标，包括高回报率和96%的特异性。我们的研究最终 culminates in a state-of-the-art fall detection system that promptly sends notifications, ensuring vulnerable individuals receive timely assistance and improve their overall well-being。通过应用LSTM模型和截剪技术，我们代表了一种有效和可靠的倒下检测技术，提供了一个有效的倒下预防和 intervención解决方案。
</details></li>
</ul>
<hr>
<h2 id="Distributional-Data-Augmentation-Methods-for-Low-Resource-Language"><a href="#Distributional-Data-Augmentation-Methods-for-Low-Resource-Language" class="headerlink" title="Distributional Data Augmentation Methods for Low Resource Language"></a>Distributional Data Augmentation Methods for Low Resource Language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04862">http://arxiv.org/abs/2309.04862</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mosh98/text_aug_low_res">https://github.com/mosh98/text_aug_low_res</a></li>
<li>paper_authors: Mosleh Mahamud, Zed Lee, Isak Samsten</li>
<li>for: 提高预测性能，特别是在低资源语言中</li>
<li>methods: 使用易搅拌数据增强技术（EDA），以及基于语义词语上下文信息和分词标签的类型特定相似词替换技术（TSSR）</li>
<li>results: 在 svenska 语料中，使用提议的方法可以提高分类性能，特别是在低资源语言中<details>
<summary>Abstract</summary>
Text augmentation is a technique for constructing synthetic data from an under-resourced corpus to improve predictive performance. Synthetic data generation is common in numerous domains. However, recently text augmentation has emerged in natural language processing (NLP) to improve downstream tasks. One of the current state-of-the-art text augmentation techniques is easy data augmentation (EDA), which augments the training data by injecting and replacing synonyms and randomly permuting sentences. One major obstacle with EDA is the need for versatile and complete synonym dictionaries, which cannot be easily found in low-resource languages. To improve the utility of EDA, we propose two extensions, easy distributional data augmentation (EDDA) and type specific similar word replacement (TSSR), which uses semantic word context information and part-of-speech tags for word replacement and augmentation. In an extensive empirical evaluation, we show the utility of the proposed methods, measured by F1 score, on two representative datasets in Swedish as an example of a low-resource language. With the proposed methods, we show that augmented data improve classification performances in low-resource settings.
</details>
<details>
<summary>摘要</summary>
文本扩充是一种技术，用于从不充分的 corpus 中构建合成数据，以提高预测性能。合成数据生成在许多领域非常常见。然而，在自然语言处理（NLP）领域，文本扩充最近才得到了应用。一种当前状态的文本扩充技术是轻松数据扩充（EDA），它在训练数据中注入和替换同义词和随机排序句子。然而，EDA 需要具有广泛和完整的同义词词典，这些词典在低资源语言中很难找。为了改进 EDDA 的Utility，我们提出了两种扩展，易用分布数据扩充（EDDA）和类型特定相似词替换（TSSR），它们使用语义词语上下文信息和部首标签进行词替换和扩展。在两个代表性数据集上进行了广泛的实验评估，我们表明了提案方法的有用性， measured by F1 分数。通过扩展了的数据，我们在低资源设置中显示了预测性能的提高。
</details></li>
</ul>
<hr>
<h2 id="AmbientFlow-Invertible-generative-models-from-incomplete-noisy-measurements"><a href="#AmbientFlow-Invertible-generative-models-from-incomplete-noisy-measurements" class="headerlink" title="AmbientFlow: Invertible generative models from incomplete, noisy measurements"></a>AmbientFlow: Invertible generative models from incomplete, noisy measurements</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04856">http://arxiv.org/abs/2309.04856</a></li>
<li>repo_url: None</li>
<li>paper_authors: Varun A. Kelkar, Rucha Deshpande, Arindam Banerjee, Mark A. Anastasio</li>
<li>for: 这 paper 是为了学习基于流的生成模型，并 directly from noisy and incomplete data。</li>
<li>methods: 该 paper 使用了变量 Bayesian 方法，建立了一个新的 framework 来学习 flow-based generative models。</li>
<li>results: 数值研究表明，AmbientFlow 可以正确地学习对象分布，并在下游推理任务中进行图像重建。<details>
<summary>Abstract</summary>
Generative models have gained popularity for their potential applications in imaging science, such as image reconstruction, posterior sampling and data sharing. Flow-based generative models are particularly attractive due to their ability to tractably provide exact density estimates along with fast, inexpensive and diverse samples. Training such models, however, requires a large, high quality dataset of objects. In applications such as computed imaging, it is often difficult to acquire such data due to requirements such as long acquisition time or high radiation dose, while acquiring noisy or partially observed measurements of these objects is more feasible. In this work, we propose AmbientFlow, a framework for learning flow-based generative models directly from noisy and incomplete data. Using variational Bayesian methods, a novel framework for establishing flow-based generative models from noisy, incomplete data is proposed. Extensive numerical studies demonstrate the effectiveness of AmbientFlow in correctly learning the object distribution. The utility of AmbientFlow in a downstream inference task of image reconstruction is demonstrated.
</details>
<details>
<summary>摘要</summary>
生成模型在媒体科学中得到了广泛的应用，如图像重建、贝叶抽样和数据分享。基于流的生成模型尤其吸引人，因为它们可以追加精确的概率估计，同时提供快速、便宜和多样的样本。但是训练这些模型需要一大量、高质量的对象数据。在计算成像应用中，通常难以获得这些数据，因为需要长时间的获取或高剂量的辐射剂量，而获取噪声或部分观测的对象数据是更可行的。在这项工作中，我们提出了 AmbientFlow，一种直接从噪声和部分观测数据学习流基的生成模型的框架。使用变分 Bayesian 方法，我们提出了一种新的框架，可以从噪声和部分观测数据中直接学习对象分布。我们的数值研究表明，AmbientFlow 可以正确地学习对象分布。此外，AmbientFlow 在下游推理任务中的图像重建中的实用性也被证明。
</details></li>
</ul>
<hr>
<h2 id="Speech-Emotion-Recognition-with-Distilled-Prosodic-and-Linguistic-Affect-Representations"><a href="#Speech-Emotion-Recognition-with-Distilled-Prosodic-and-Linguistic-Affect-Representations" class="headerlink" title="Speech Emotion Recognition with Distilled Prosodic and Linguistic Affect Representations"></a>Speech Emotion Recognition with Distilled Prosodic and Linguistic Affect Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04849">http://arxiv.org/abs/2309.04849</a></li>
<li>repo_url: None</li>
<li>paper_authors: Debaditya Shome, Ali Etemad</li>
<li>for: 这个论文是为了提出一种新的语音情绪识别（SER）框架，以便在语音信号上学习强大的语言和情感表达。</li>
<li>methods: 这个方法使用了cross-modal知识填充在训练时期，以学习语音信号上的情感表达。在推断时期，我们的方法只需要一个流经语音信号来进行单模式SER，从而降低计算开销和避免在运行时转写和语音特征提取错误。</li>
<li>results: 实验表明，我们的方法在IEMOCAP benchmark上比其他单模式和多模式方法高出许多，并达到了状态机的性能（77.49%无担荷准确率和78.91%担荷准确率）。详细的ablation研究表明每个组件的影响。<details>
<summary>Abstract</summary>
We propose EmoDistill, a novel speech emotion recognition (SER) framework that leverages cross-modal knowledge distillation during training to learn strong linguistic and prosodic representations of emotion from speech. During inference, our method only uses a stream of speech signals to perform unimodal SER thus reducing computation overhead and avoiding run-time transcription and prosodic feature extraction errors. During training, our method distills information at both embedding and logit levels from a pair of pre-trained Prosodic and Linguistic teachers that are fine-tuned for SER. Experiments on the IEMOCAP benchmark demonstrate that our method outperforms other unimodal and multimodal techniques by a considerable margin, and achieves state-of-the-art performance of 77.49% unweighted accuracy and 78.91% weighted accuracy. Detailed ablation studies demonstrate the impact of each component of our method.
</details>
<details>
<summary>摘要</summary>
我们提出了 EmoDistill，一种新的语音情感识别（SER）框架，利用交叉模态知识储备 durante 训练以学习从语音中强大的语言和表征表达情感。在推断过程中，我们的方法仅使用一个流 speech 信号来进行单模态 SER，从而减少计算负担和避免运行时转写和表征特征EXTRACTING错误。在训练过程中，我们的方法在 embedding 和 logit 两个水平上储备信息从 two 个预训练的 Prosodic 和 Linguistic 教师，这些教师在 SER 上进行了精度的 fine-tuning。在 IEMOCAP benchmark 上进行的实验表明，我们的方法在其他单模态和多模态技术的比较中表现出了 considerable 的优势，并达到了 state-of-the-art 性能的 77.49% 不平衡精度和 78.91% 平衡精度。详细的抽象研究表明了我们的方法中每个组件的影响。
</details></li>
</ul>
<hr>
<h2 id="Verifiable-Reinforcement-Learning-Systems-via-Compositionality"><a href="#Verifiable-Reinforcement-Learning-Systems-via-Compositionality" class="headerlink" title="Verifiable Reinforcement Learning Systems via Compositionality"></a>Verifiable Reinforcement Learning Systems via Compositionality</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06420">http://arxiv.org/abs/2309.06420</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cyrus Neary, Aryaman Singh Samyal, Christos Verginis, Murat Cubuktepe, Ufuk Topcu</li>
<li>for: 本文提出了一个可验证和可分解的强化学习框架，用于实现多个强化学习子系统的集成，以完成一个总任务。</li>
<li>methods: 该框架包括一个高级模型，表示为 Parametric Markov Decision Process，用于规划和分析强化学习子系统的集成。强化学习子系统是通过定义子系统之间的接口，以实现自动化的任务分解和独立的训练和测试。</li>
<li>results: 实验结果表明，该框架在具有全 observability 和 partial observability 的环境中都能够实现高效的任务执行。同时，该框架可以处理离散和连续状态和动作空间，以及 deterministic 和 stochastic 动力学。<details>
<summary>Abstract</summary>
We propose a framework for verifiable and compositional reinforcement learning (RL) in which a collection of RL subsystems, each of which learns to accomplish a separate subtask, are composed to achieve an overall task. The framework consists of a high-level model, represented as a parametric Markov decision process, which is used to plan and analyze compositions of subsystems, and of the collection of low-level subsystems themselves. The subsystems are implemented as deep RL agents operating under partial observability. By defining interfaces between the subsystems, the framework enables automatic decompositions of task specifications, e.g., reach a target set of states with a probability of at least 0.95, into individual subtask specifications, i.e. achieve the subsystem's exit conditions with at least some minimum probability, given that its entry conditions are met. This in turn allows for the independent training and testing of the subsystems. We present theoretical results guaranteeing that if each subsystem learns a policy satisfying its subtask specification, then their composition is guaranteed to satisfy the overall task specification. Conversely, if the subtask specifications cannot all be satisfied by the learned policies, we present a method, formulated as the problem of finding an optimal set of parameters in the high-level model, to automatically update the subtask specifications to account for the observed shortcomings. The result is an iterative procedure for defining subtask specifications, and for training the subsystems to meet them. Experimental results demonstrate the presented framework's novel capabilities in environments with both full and partial observability, discrete and continuous state and action spaces, as well as deterministic and stochastic dynamics.
</details>
<details>
<summary>摘要</summary>
我们提出了一个扩展的强化学习（RL）框架，在这个框架中，一群RL子系统，每个子系统都学习完成一个独立的子任务，这些子系统被组合以完成总任务。该框架包括一个高级模型，表示为参数化的随机过程决策过程，用于规划和分析子系统的组合。子系统实现为深度学习RL代理，在受限性观察下运行。通过定义子系统之间的界面，该框架允许自动将任务规范分解成个别子任务规范，例如，达到目标集的状态 WITH  least 0.95 的概率，或者在达到子系统的入口条件时，达到至少一定的最小概率。这样做了可以独立地培训和测试子系统。我们提供了理论结果，证明如果每个子系统学习满足其子任务规范，那么其组合就可以满足总任务规范。相反，如果子任务规范无法由学习的策略满足，我们提供了一种方法，即在高级模型中寻找优化的参数集，以自动更新子任务规范，以便 compte ten  observe 短coming。结果是一种迭代的过程，用于定义子任务规范，并培训子系统以满足它们。实验结果表明，该框架在具有全 observable 和 partial observable 的环境中，以及具有整数和连续状态空间的环境中，都能够展示出新的能力。
</details></li>
</ul>
<hr>
<h2 id="Global-Convergence-of-Receding-Horizon-Policy-Search-in-Learning-Estimator-Designs"><a href="#Global-Convergence-of-Receding-Horizon-Policy-Search-in-Learning-Estimator-Designs" class="headerlink" title="Global Convergence of Receding-Horizon Policy Search in Learning Estimator Designs"></a>Global Convergence of Receding-Horizon Policy Search in Learning Estimator Designs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04831">http://arxiv.org/abs/2309.04831</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiangyuan-zhang/learningkf">https://github.com/xiangyuan-zhang/learningkf</a></li>
<li>paper_authors: Xiangyuan Zhang, Saviz Mowlavi, Mouhacine Benosman, Tamer Başar</li>
<li>for: 本研究开发了一种名为往返 horizon policy gradient（RHPG）算法，用于学习最佳线性估计设计（Kalman filter，KF）。</li>
<li>methods: RHPG算法 integrates vanilla policy search directions into a dynamic programming outer loop，将无限时间KF问题转换为一系列静止估计问题，并且提供了优化内部的测地图分析和数据点复杂度保证。</li>
<li>results: RHPG算法可以实现全球均衡，并且不需要任何先验知识或开 Loop稳定性。我们还提供了细化的优化景象分析和数据点复杂度保证。这个研究是控制应用中首次开发了具有性能保证的循环学习算法，并且结合了精确控制理论在算法设计和理论分析中。我们还验证了RHPG算法在一个大规模对流混合运算中的性能。代码存储库可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/xiangyuan-zhang/LearningKF%7D">https://github.com/xiangyuan-zhang/LearningKF}</a> 上找到。<details>
<summary>Abstract</summary>
We introduce the receding-horizon policy gradient (RHPG) algorithm, the first PG algorithm with provable global convergence in learning the optimal linear estimator designs, i.e., the Kalman filter (KF). Notably, the RHPG algorithm does not require any prior knowledge of the system for initialization and does not require the target system to be open-loop stable. The key of RHPG is that we integrate vanilla PG (or any other policy search directions) into a dynamic programming outer loop, which iteratively decomposes the infinite-horizon KF problem that is constrained and non-convex in the policy parameter into a sequence of static estimation problems that are unconstrained and strongly-convex, thus enabling global convergence. We further provide fine-grained analyses of the optimization landscape under RHPG and detail the convergence and sample complexity guarantees of the algorithm. This work serves as an initial attempt to develop reinforcement learning algorithms specifically for control applications with performance guarantees by utilizing classic control theory in both algorithmic design and theoretical analyses. Lastly, we validate our theories by deploying the RHPG algorithm to learn the Kalman filter design of a large-scale convection-diffusion model. We open-source the code repository at \url{https://github.com/xiangyuan-zhang/LearningKF}.
</details>
<details>
<summary>摘要</summary>
我们介绍了落后 horizen 策略导数（RHPG）算法，这是首个可证明全球准确性的学习优化 Linear Estimator 设计算法，即卡尔曼滤波器（KF）。值得注意的是，RHPG 算法不需要任何系统的先前知识 для初始化，也不需要目标系统是开 Loop 稳定。RHPG 算法的关键在于将 vanilla PG（或任何其他策略搜索方向）integrated into a dynamic programming outer loop，这将将无限远程 KF 问题，即受约束和非对称的策略参数， decomposed into a sequence of static estimation problems that are unconstrained and strongly convex, thus enabling global convergence. 我们还提供了细化的优化景观下的 RHPG 算法的分析，并详细介绍了算法的收敛和样本复杂度保证。这项工作作为控制应用中开发强化学习算法的初步尝试，并通过利用经典控制理论在算法设计和理论分析中使用。最后，我们验证了我们的理论，通过将 RHPG 算法应用于一个大规模的扩散干扰模型来学习 Kalman 滤波器设计。我们在 GitHub 上开源了代码存储库，详情请参考 \url{https://github.com/xiangyuan-zhang/LearningKF}.
</details></li>
</ul>
<hr>
<h2 id="Good-looking-but-Lacking-Faithfulness-Understanding-Local-Explanation-Methods-through-Trend-based-Testing"><a href="#Good-looking-but-Lacking-Faithfulness-Understanding-Local-Explanation-Methods-through-Trend-based-Testing" class="headerlink" title="Good-looking but Lacking Faithfulness: Understanding Local Explanation Methods through Trend-based Testing"></a>Good-looking but Lacking Faithfulness: Understanding Local Explanation Methods through Trend-based Testing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05679">http://arxiv.org/abs/2309.05679</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jenniferho97/xai-trend-test">https://github.com/jenniferho97/xai-trend-test</a></li>
<li>paper_authors: Jinwen He, Kai Chen, Guozhu Meng, Jiangshan Zhang, Congyi Li</li>
<li>for: 本研究旨在evaluating explanation methods的实用性和 faithfulness，以及解释模型做出的决策。</li>
<li>methods: 本研究使用了三种新的趋势基测试来评估 faithfulness，并对十种受测方法进行了评估。</li>
<li>results: 研究发现，使用新的趋势基测试可以更好地评估 faithfulness，并获得了在复杂数据上的首次评估成果。 Downstream tasks也受益匪浅，例如模型调试具有 faithful explanation methods可以更好地检测和修正精度和安全问题。<details>
<summary>Abstract</summary>
While enjoying the great achievements brought by deep learning (DL), people are also worried about the decision made by DL models, since the high degree of non-linearity of DL models makes the decision extremely difficult to understand. Consequently, attacks such as adversarial attacks are easy to carry out, but difficult to detect and explain, which has led to a boom in the research on local explanation methods for explaining model decisions. In this paper, we evaluate the faithfulness of explanation methods and find that traditional tests on faithfulness encounter the random dominance problem, \ie, the random selection performs the best, especially for complex data. To further solve this problem, we propose three trend-based faithfulness tests and empirically demonstrate that the new trend tests can better assess faithfulness than traditional tests on image, natural language and security tasks. We implement the assessment system and evaluate ten popular explanation methods. Benefiting from the trend tests, we successfully assess the explanation methods on complex data for the first time, bringing unprecedented discoveries and inspiring future research. Downstream tasks also greatly benefit from the tests. For example, model debugging equipped with faithful explanation methods performs much better for detecting and correcting accuracy and security problems.
</details>
<details>
<summary>摘要</summary>
While enjoying the great achievements brought by deep learning (DL), people are also worried about the decisions made by DL models, since the high degree of non-linearity of DL models makes the decisions extremely difficult to understand. Consequently, attacks such as adversarial attacks are easy to carry out, but difficult to detect and explain, which has led to a boom in the research on local explanation methods for explaining model decisions. In this paper, we evaluate the faithfulness of explanation methods and find that traditional tests on faithfulness encounter the random dominance problem, \ie, the random selection performs the best, especially for complex data. To further solve this problem, we propose three trend-based faithfulness tests and empirically demonstrate that the new trend tests can better assess faithfulness than traditional tests on image, natural language and security tasks. We implement the assessment system and evaluate ten popular explanation methods. Benefiting from the trend tests, we successfully assess the explanation methods on complex data for the first time, bringing unprecedented discoveries and inspiring future research. Downstream tasks also greatly benefit from the tests. For example, model debugging equipped with faithful explanation methods performs much better for detecting and correcting accuracy and security problems.Here is the translation in Traditional Chinese:人们在深度学习（DL）的成就下享受着，但也担心DL模型的决策，因为DL模型的高度非线性性使得决策 extremely difficult to understand。因此，如 adversarial attack 等攻击性能易于实现，但困难检测和解释，这导致了解释模型决策的本地解释方法的研究热潮。在这篇论文中，我们评估解释方法的忠实度，发现传统的忠实度测试遇到随机主导问题，即随机选择perform the best，特别是 для复杂的数据。为了解决这个问题，我们提出了三种趋势基本的忠实度测试，并证明了这些新的趋势测试可以更好地评估忠实度 than traditional tests on image, natural language and security tasks。我们实现了评估系统，并评估了十种受欢迎的解释方法。受益于趋势测试，我们成功地评估了解释方法 on complex data for the first time，带来了前所未有的发现和未来研究的鼓励。下游任务也受益于测试。例如，具有忠实的解释方法的模型 Debugging 在检测和修正精度和安全问题上表现 Much better。
</details></li>
</ul>
<hr>
<h2 id="Timely-Fusion-of-Surround-Radar-Lidar-for-Object-Detection-in-Autonomous-Driving-Systems"><a href="#Timely-Fusion-of-Surround-Radar-Lidar-for-Object-Detection-in-Autonomous-Driving-Systems" class="headerlink" title="Timely Fusion of Surround Radar&#x2F;Lidar for Object Detection in Autonomous Driving Systems"></a>Timely Fusion of Surround Radar&#x2F;Lidar for Object Detection in Autonomous Driving Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04806">http://arxiv.org/abs/2309.04806</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenjing Xie, Tao Hu, Neiwen Ling, Guoliang Xing, Shaoshan Liu, Nan Guan<br>for: This paper aims to improve the fusion of surround Radar and Lidar sensor data for autonomous driving systems by developing techniques to work with the faster Lidar data instead of the slower Radar data.methods: The proposed method uses the state-of-the-art object detection model MVDNet to fuse surround Radar&#x2F;Lidar data, but with enhanced training to tolerate the temporal unalignment of input data.results: The proposed method achieves high output frequency with little accuracy loss, making it a promising solution for real-time object detection in autonomous driving systems.<details>
<summary>Abstract</summary>
Fusing Radar and Lidar sensor data can fully utilize their complementary advantages and provide more accurate reconstruction of the surrounding for autonomous driving systems. Surround Radar/Lidar can provide 360-degree view sampling with the minimal cost, which are promising sensing hardware solutions for autonomous driving systems. However, due to the intrinsic physical constraints, the rotating speed of surround Radar, and thus the frequency to generate Radar data frames, is much lower than surround Lidar. Existing Radar/Lidar fusion methods have to work at the low frequency of surround Radar, which cannot meet the high responsiveness requirement of autonomous driving systems.This paper develops techniques to fuse surround Radar/Lidar with working frequency only limited by the faster surround Lidar instead of the slower surround Radar, based on the state-of-the-art object detection model MVDNet. The basic idea of our approach is simple: we let MVDNet work with temporally unaligned data from Radar/Lidar, so that fusion can take place at any time when a new Lidar data frame arrives, instead of waiting for the slow Radar data frame. However, directly applying MVDNet to temporally unaligned Radar/Lidar data greatly degrades its object detection accuracy. The key information revealed in this paper is that we can achieve high output frequency with little accuracy loss by enhancing the training procedure to explore the temporal redundancy in MVDNet so that it can tolerate the temporal unalignment of input data. We explore several different ways of training enhancement and compare them quantitatively with experiments.
</details>
<details>
<summary>摘要</summary>
将雷达和激光感知器融合可以完全利用它们的优势，提供更准确的周围环境重建 для自动驾驶系统。三百六十度雷达/激光可以提供360度的视野样本，是自动驾驶系统的感知硬件解决方案。然而，由于雷达的物理限制，雷达旋转速率相对较低，因此雷达数据帧的频率远低于激光。现有的雷达/激光融合方法必须在低频率的雷达数据帧上工作，无法满足自动驾驶系统的高响应性要求。本文提出了一种解决方案，使用基于state-of-the-art对象检测模型MVDNet进行雷达/激光融合。我们的思路简单：让MVDNet在雷达/激光数据不对时进行融合，以便在新的激光数据帧到达时进行融合，而不必等待慢速的雷达数据帧。然而，直接将MVDNet应用于不对时的雷达/激光数据会导致对象检测精度下降。我们发现，可以通过强化训练程序，以利用MVDNet中的时间重复性，使其能够忍受输入数据的时间不对。我们试了多种训练强化方法，并对它们进行了量化比较。
</details></li>
</ul>
<hr>
<h2 id="Finding-Influencers-in-Complex-Networks-An-Effective-Deep-Reinforcement-Learning-Approach"><a href="#Finding-Influencers-in-Complex-Networks-An-Effective-Deep-Reinforcement-Learning-Approach" class="headerlink" title="Finding Influencers in Complex Networks: An Effective Deep Reinforcement Learning Approach"></a>Finding Influencers in Complex Networks: An Effective Deep Reinforcement Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07153">http://arxiv.org/abs/2309.07153</a></li>
<li>repo_url: None</li>
<li>paper_authors: Changan Liu, Changjun Fan, Zhongzhi Zhang</li>
<li>for: 本文针对复杂网络中Influence Maximization问题提出了一种有效的深度学习模型，以提高社会网络分析中的效果。</li>
<li>methods: 本文提出了一种结合图 neural network和强化学习的综合学习框架，名为DREIM，通过广泛的小型synthetic graphs训练，在大型synthetic和实际世界网络上超越了现有的基eline方法，并且对网络大小 linear scalability 的特性做出了实际证明。</li>
<li>results: 本文的DREIM模型在解决Influence Maximization问题时，相比现有的基eline方法，具有更高的解决质量和linear scalability 特性。<details>
<summary>Abstract</summary>
Maximizing influences in complex networks is a practically important but computationally challenging task for social network analysis, due to its NP- hard nature. Most current approximation or heuristic methods either require tremendous human design efforts or achieve unsatisfying balances between effectiveness and efficiency. Recent machine learning attempts only focus on speed but lack performance enhancement. In this paper, different from previous attempts, we propose an effective deep reinforcement learning model that achieves superior performances over traditional best influence maximization algorithms. Specifically, we design an end-to-end learning framework that combines graph neural network as the encoder and reinforcement learning as the decoder, named DREIM. Trough extensive training on small synthetic graphs, DREIM outperforms the state-of-the-art baseline methods on very large synthetic and real-world networks on solution quality, and we also empirically show its linear scalability with regard to the network size, which demonstrates its superiority in solving this problem.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将复杂网络中的影响力最大化作为社交网络分析中的实际重要任务，由于其NP困难的性质，现有的现有的近似或规则方法通常需要巨大的人工设计努力或者实现不够的效率和效果平衡。现代机器学习尝试只集中于速度，但缺乏性能提升。在这篇论文中，与之前的尝试不同，我们提出了一种高效的深度强化学习模型，可以超越传统的最佳影响最大化算法。specifically，我们设计了一个端到端学习框架，将图 neural network作为编码器和强化学习作为解码器，名为DREIM。经过广泛的小 synthetic graphs 训练，DREIM 超越了状态静态基eline 方法在很大的 sintetic 和实际网络上的解决质量，并且我们还证明其线性扩展性，表明其在解决这个问题上的优势。Note:* "NP-hard" is translated as "NP困难" (NP困难性)* "influence maximization" is translated as "影响力最大化" (影响力最大化)* "deep reinforcement learning" is translated as "深度强化学习" (深度强化学习)* "graph neural network" is translated as "图 neural network" (图 neural network)* "baseline methods" is translated as "基线方法" (基线方法)* "synthetic graphs" is translated as "小 synthetic graphs" (小 synthetic graphs)
</details></li>
</ul>
<hr>
<h2 id="Towards-Real-World-Burst-Image-Super-Resolution-Benchmark-and-Method"><a href="#Towards-Real-World-Burst-Image-Super-Resolution-Benchmark-and-Method" class="headerlink" title="Towards Real-World Burst Image Super-Resolution: Benchmark and Method"></a>Towards Real-World Burst Image Super-Resolution: Benchmark and Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04803">http://arxiv.org/abs/2309.04803</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yjsunnn/fbanet">https://github.com/yjsunnn/fbanet</a></li>
<li>paper_authors: Pengxu Wei, Yujing Sun, Xingbei Guo, Chang Liu, Jie Chen, Xiangyang Ji, Liang Lin</li>
<li>for: 本研究旨在探讨如何使用多张图像来重建高质量的图像，特别是在实际场景中。</li>
<li>methods: 我们提出了一种 Federated Burst Affinity network (FBAnet)，它使用了一种简单的投影变换来对图像进行匹配，并使用了一种 Federated Affinity Fusion (FAF) 策略来聚合帧中的相关信息。</li>
<li>results: 我们的 FBAnet 在两个版本的数据集上进行了广泛的实验，并证明了它可以超过现有的状态艺术图像重建方法，并且可以生成有趣的 SR 图像预测。我们的数据集、代码和模型都公开可用于 GitHub。<details>
<summary>Abstract</summary>
Despite substantial advances, single-image super-resolution (SISR) is always in a dilemma to reconstruct high-quality images with limited information from one input image, especially in realistic scenarios. In this paper, we establish a large-scale real-world burst super-resolution dataset, i.e., RealBSR, to explore the faithful reconstruction of image details from multiple frames. Furthermore, we introduce a Federated Burst Affinity network (FBAnet) to investigate non-trivial pixel-wise displacements among images under real-world image degradation. Specifically, rather than using pixel-wise alignment, our FBAnet employs a simple homography alignment from a structural geometry aspect and a Federated Affinity Fusion (FAF) strategy to aggregate the complementary information among frames. Those fused informative representations are fed to a Transformer-based module of burst representation decoding. Besides, we have conducted extensive experiments on two versions of our datasets, i.e., RealBSR-RAW and RealBSR-RGB. Experimental results demonstrate that our FBAnet outperforms existing state-of-the-art burst SR methods and also achieves visually-pleasant SR image predictions with model details. Our dataset, codes, and models are publicly available at https://github.com/yjsunnn/FBANet.
</details>
<details>
<summary>摘要</summary>
尽管已经取得了重要进步，单一图像超分解 (SISR) 仍然面临着从一个输入图像中重建高质量图像的挑战，特别是在实际场景下。在这篇论文中，我们建立了一个大规模的实际场景中的爆发超分解数据集，即RealBSR，以探索图像细节的忠实重建。此外，我们引入了一种 Federated Burst Affinity network (FBAnet)，以探索实际场景下图像的非致命像素位移。具体来说，而不是使用像素位移对 align，我们的FBAnet使用了一种简单的投影变换的结构几何学方面的同步方法，并使用一种 Federated Affinity Fusion (FAF) 策略来聚合各帧中的补充信息。这些融合的信息表示被 fed 到一个基于 Transformer 的强制代码帧表示解码模块。此外，我们在 RealBSR-RAW 和 RealBSR-RGB 两个版本的数据集上进行了广泛的实验，结果表明，我们的 FBAnet 超过了现有的推荐爆发 SR 方法，并且实现了可见愉悦 SR 图像预测，同时保持模型细节。我们的数据集、代码和模型都可以在 GitHub 上公开获取，链接在https://github.com/yjsunnn/FBANet。
</details></li>
</ul>
<hr>
<h2 id="CPMR-Context-Aware-Incremental-Sequential-Recommendation-with-Pseudo-Multi-Task-Learning"><a href="#CPMR-Context-Aware-Incremental-Sequential-Recommendation-with-Pseudo-Multi-Task-Learning" class="headerlink" title="CPMR: Context-Aware Incremental Sequential Recommendation with Pseudo-Multi-Task Learning"></a>CPMR: Context-Aware Incremental Sequential Recommendation with Pseudo-Multi-Task Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04802">http://arxiv.org/abs/2309.04802</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dimarziobian/cpmr">https://github.com/dimarziobian/cpmr</a></li>
<li>paper_authors: Qingtian Bian, Jiaxing Xu, Hui Fang, Yiping Ke</li>
<li>for: 模型用户表征的动态兴趣环境，即用户在不同时间和上下文中的行为。</li>
<li>methods: 使用信息传播和进化来挖掘批处理的交互数据，并创建用户和物品的三个表示：静态嵌入、历史时间状态和Contextual时间状态。</li>
<li>results: 在四个标准推荐数据集上实验表明，CPMR可以持续超越当前状态艺术的基eline，并在三个数据集上 achieve 显著的提升。<details>
<summary>Abstract</summary>
The motivations of users to make interactions can be divided into static preference and dynamic interest. To accurately model user representations over time, recent studies in sequential recommendation utilize information propagation and evolution to mine from batches of arriving interactions. However, they ignore the fact that people are easily influenced by the recent actions of other users in the contextual scenario, and applying evolution across all historical interactions dilutes the importance of recent ones, thus failing to model the evolution of dynamic interest accurately. To address this issue, we propose a Context-Aware Pseudo-Multi-Task Recommender System (CPMR) to model the evolution in both historical and contextual scenarios by creating three representations for each user and item under different dynamics: static embedding, historical temporal states, and contextual temporal states. To dually improve the performance of temporal states evolution and incremental recommendation, we design a Pseudo-Multi-Task Learning (PMTL) paradigm by stacking the incremental single-target recommendations into one multi-target task for joint optimization. Within the PMTL paradigm, CPMR employs a shared-bottom network to conduct the evolution of temporal states across historical and contextual scenarios, as well as the fusion of them at the user-item level. In addition, CPMR incorporates one real tower for incremental predictions, and two pseudo towers dedicated to updating the respective temporal states based on new batches of interactions. Experimental results on four benchmark recommendation datasets show that CPMR consistently outperforms state-of-the-art baselines and achieves significant gains on three of them. The code is available at: https://github.com/DiMarzioBian/CPMR.
</details>
<details>
<summary>摘要</summary>
用户的动机可以分为静态喜好和动态兴趣。为了准确地模型用户在时间上的表现，现在的研究在串行推荐中使用信息传播和进化来 mines 从到达的交互批处理。然而，它们忽略了人们在场景下的受到他人最近行为影响的事实，并且在所有历史交互上应用进化，从而不能准确地模型动态兴趣的演化。为解决这个问题，我们提出了Context-Aware Pseudo-Multi-Task Recommender System (CPMR)，用于在历史和场景下模型用户和ITEM的演化。我们设计了三种表示方法：静态嵌入、历史时间状态和场景时间状态。为了提高时间状态演化和逐步推荐的性能，我们实现了一种Pseudo-Multi-Task Learning (PMTL) paradigm，其中CPMR使用一个共享底层网络来进行时间状态的演化和用户-ITEM级别的 fusión。此外，CPMR还包括一个真实的射频塔来进行逐步预测，以及两个 Pseudo 射频塔来更新各自的时间状态基于新批处理的交互。实验结果表明，CPMR在四个基准推荐数据集上具有显著的优势，并在三个基准上达到了显著的提升。代码可以在https://github.com/DiMarzioBian/CPMR 中获取。
</details></li>
</ul>
<hr>
<h2 id="TMComposites-Plug-and-Play-Collaboration-Between-Specialized-Tsetlin-Machines"><a href="#TMComposites-Plug-and-Play-Collaboration-Between-Specialized-Tsetlin-Machines" class="headerlink" title="TMComposites: Plug-and-Play Collaboration Between Specialized Tsetlin Machines"></a>TMComposites: Plug-and-Play Collaboration Between Specialized Tsetlin Machines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04801">http://arxiv.org/abs/2309.04801</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cair/plug-and-play-collaboration-between-specialized-tsetlin-machines">https://github.com/cair/plug-and-play-collaboration-between-specialized-tsetlin-machines</a></li>
<li>paper_authors: Ole-Christoffer Granmo</li>
<li>for: 提高TM的性能在更复杂的任务和数据集上，例如CIFAR-10和CIFAR-100。</li>
<li>methods: 特有的TM Composites的协作，通过学习和推理时的特有精度评估来实现。</li>
<li>results: 在Fashion-MNIST、CIFAR-10和CIFAR-100上提高了准确率， Specifically, the TM Composite increased accuracy on Fashion-MNIST by 2 percentage points, CIFAR-10 by 12 points, and CIFAR-100 by 9 points, achieving new state-of-the-art results for TMs.<details>
<summary>Abstract</summary>
Tsetlin Machines (TMs) provide a fundamental shift from arithmetic-based to logic-based machine learning. Supporting convolution, they deal successfully with image classification datasets like MNIST, Fashion-MNIST, and CIFAR-2. However, the TM struggles with getting state-of-the-art performance on CIFAR-10 and CIFAR-100, representing more complex tasks. This paper introduces plug-and-play collaboration between specialized TMs, referred to as TM Composites. The collaboration relies on a TM's ability to specialize during learning and to assess its competence during inference. When teaming up, the most confident TMs make the decisions, relieving the uncertain ones. In this manner, a TM Composite becomes more competent than its members, benefiting from their specializations. The collaboration is plug-and-play in that members can be combined in any way, at any time, without fine-tuning. We implement three TM specializations in our empirical evaluation: Histogram of Gradients, Adaptive Gaussian Thresholding, and Color Thermometers. The resulting TM Composite increases accuracy on Fashion-MNIST by two percentage points, CIFAR-10 by twelve points, and CIFAR-100 by nine points, yielding new state-of-the-art results for TMs. Overall, we envision that TM Composites will enable an ultra-low energy and transparent alternative to state-of-the-art deep learning on more tasks and datasets.
</details>
<details>
<summary>摘要</summary>
特具机器 (TM) 提供了一个基本的转换，从数学基础到逻辑基础的机器学习。它们可以成功地处理像 Minnist、Fashion-Minnist 和 CIFAR-2 这些图像分类 dataset，但是它们对 CIFAR-10 和 CIFAR-100 这些更加复杂的任务表现不佳。这篇论文介绍了特殊化的 TM 之间的协作，称为 TM Composites。这种协作基于 TM 的学习中的特殊化和推断中的能力评估。当它们合作时，最自信的 TM 会作出决策，减轻不确定的 TM。因此，一个 TM Composite 会比其成员更有能力，从其特殊化中受益。这种协作是可插入式的，成员可以在任何时候、任何方式混合，不需要微调。我们在实验中实现了三种 TM 特殊化： Histogram of Gradients、Adaptive Gaussian Thresholding 和 Color Thermometers。它们的结合使得 Fashion-MNIST 的准确率提高了二个百分比点，CIFAR-10 的准确率提高了十二个百分比点，CIFAR-100 的准确率提高了九个百分比点，创造了新的state-of-the-art 结果。总的来说，我们预期 TM Composites 将在更多的任务和数据集上提供低能耗和透明的替代方案。
</details></li>
</ul>
<hr>
<h2 id="A-Fast-Algorithm-for-Moderating-Critical-Nodes-via-Edge-Removal"><a href="#A-Fast-Algorithm-for-Moderating-Critical-Nodes-via-Edge-Removal" class="headerlink" title="A Fast Algorithm for Moderating Critical Nodes via Edge Removal"></a>A Fast Algorithm for Moderating Critical Nodes via Edge Removal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06392">http://arxiv.org/abs/2309.06392</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hahaabc/fasticm">https://github.com/hahaabc/fasticm</a></li>
<li>paper_authors: Changan Liu, Xiaotian Zhou, Ahad N. Zehmakan, Zhongzhi Zhang</li>
<li>for: 本研究旨在提高网络中执行有效的moderation，以避免由于恶意扩散而导致的负面响应。</li>
<li>methods: 本研究使用新的技术，如random walk-based Schur complement approximation和快速和简单的和计算方法，提出三种近似算法来解决这个问题。</li>
<li>results: 实验结果表明，我们提出的算法在不同的设定下具有高效性和可靠性，能够有效地减少网络中执行moderation的计算成本。<details>
<summary>Abstract</summary>
Critical nodes in networks are extremely vulnerable to malicious attacks to trigger negative cascading events such as the spread of misinformation and diseases. Therefore, effective moderation of critical nodes is very vital for mitigating the potential damages caused by such malicious diffusions. The current moderation methods are computationally expensive. Furthermore, they disregard the fundamental metric of information centrality, which measures the dissemination power of nodes.   We investigate the problem of removing $k$ edges from a network to minimize the information centrality of a target node $\lea$ while preserving the network's connectivity. We prove that this problem is computationally challenging: it is NP-complete and its objective function is not supermodular. However, we propose three approximation greedy algorithms using novel techniques such as random walk-based Schur complement approximation and fast sum estimation. One of our algorithms runs in nearly linear time in the number of edges.   To complement our theoretical analysis, we conduct a comprehensive set of experiments on synthetic and real networks with over one million nodes. Across various settings, the experimental results illustrate the effectiveness and efficiency of our proposed algorithms.
</details>
<details>
<summary>摘要</summary>
重要的网络中的节点非常易受到黑客攻击，导致负面传播事件的发生，如误information和疾病的传播。因此，有效地调节重要节点非常重要，以减少这些黑客攻击导致的潜在损害。现有的调节方法 computationally expensive，而且忽略了信息中心度的基本度量，它度量节点传播力。我们研究了从网络中移除 $k$ 个边，以使Target node $\lea$ 的信息中心度最小化，保持网络连接性。我们证明这个问题是 computationally challenging：它是NP-complete，并且其目标函数不具有supermodular。然而，我们提出了三种近似算法，使用了新的技术，如Random walk-based Schur complement approximation和快速总和估计。其中一个算法在 Nearly linear time 中处理了 edges。实际上，我们对实际和 sintetic 网络进行了广泛的实验，包括超过一百万个节点。不同的设定下，实验结果显示了我们的提案的有效性和高效性。
</details></li>
</ul>
<hr>
<h2 id="A-Full-fledged-Commit-Message-Quality-Checker-Based-on-Machine-Learning"><a href="#A-Full-fledged-Commit-Message-Quality-Checker-Based-on-Machine-Learning" class="headerlink" title="A Full-fledged Commit Message Quality Checker Based on Machine Learning"></a>A Full-fledged Commit Message Quality Checker Based on Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04797">http://arxiv.org/abs/2309.04797</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/commit-message-collective/beams-commit-message-checker">https://github.com/commit-message-collective/beams-commit-message-checker</a></li>
<li>paper_authors: David Faragó, Michael Färber, Christian Petrov</li>
<li>for: 这篇论文是关于提高版本控制中的提交信息质量的研究，以便更好地支持软件维护和演化。</li>
<li>methods: 该论文使用机器学习方法来评估提交信息质量，包括语义和上下文。</li>
<li>results: 该论文可以够准确地评估提交信息质量，其最低F$_1$分为82.9%，这表明机器学习方法可以很好地评估提交信息质量。<details>
<summary>Abstract</summary>
Commit messages (CMs) are an essential part of version control. By providing important context in regard to what has changed and why, they strongly support software maintenance and evolution. But writing good CMs is difficult and often neglected by developers. So far, there is no tool suitable for practice that automatically assesses how well a CM is written, including its meaning and context. Since this task is challenging, we ask the research question: how well can the CM quality, including semantics and context, be measured with machine learning methods? By considering all rules from the most popular CM quality guideline, creating datasets for those rules, and training and evaluating state-of-the-art machine learning models to check those rules, we can answer the research question with: sufficiently well for practice, with the lowest F$_1$ score of 82.9\%, for the most challenging task. We develop a full-fledged open-source framework that checks all these CM quality rules. It is useful for research, e.g., automatic CM generation, but most importantly for software practitioners to raise the quality of CMs and thus the maintainability and evolution speed of their software.
</details>
<details>
<summary>摘要</summary>
commit messages (CMs) 是版本控制中非常重要的一部分，它们提供了更改的重要上下文和原因，从而强化软件维护和演化。然而，写好CMs是很困难的，开发者们经常忽略这一点。迄今为止，没有一种适合实践的工具可以自动评估CM质量，包括它的 semantics 和context。由于这是一项具有挑战性的任务，我们提出了研究问题：可以使用机器学习方法来评估CM质量，包括 semantics 和context？我们考虑了最流行的CM质量指南中的所有规则，创建了相应的数据集，并使用当今最佳的机器学习模型来检查这些规则。我们的研究表明，使用机器学习方法可以很好地评估CM质量，最低的F1分数为82.9%，对最复杂的任务来说。我们开发了一套免费、开源的框架，可以检查所有CM质量规则。它可以用于研究，例如自动生成CM，但更重要的是，它可以帮助软件实践者提高CM质量，从而提高软件的维护和演化速度。
</details></li>
</ul>
<hr>
<h2 id="Towards-Robust-Model-Watermark-via-Reducing-Parametric-Vulnerability"><a href="#Towards-Robust-Model-Watermark-via-Reducing-Parametric-Vulnerability" class="headerlink" title="Towards Robust Model Watermark via Reducing Parametric Vulnerability"></a>Towards Robust Model Watermark via Reducing Parametric Vulnerability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04777">http://arxiv.org/abs/2309.04777</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/guanhaogan/robust-model-watermarking">https://github.com/guanhaogan/robust-model-watermarking</a></li>
<li>paper_authors: Guanhao Gan, Yiming Li, Dongxian Wu, Shu-Tao Xia</li>
<li>for: 保护深度神经网络（DNN）的版权，防止其被不当使用或盗取。</li>
<li>methods: 使用后门式拓展来嵌入特定的行为，以便在发布模型时验证其所有权。</li>
<li>results: 提出了一种基于最大化最小化的方法，可以在 parametric 变化和许多后门除法攻击下提高模型水印的稳定性。<details>
<summary>Abstract</summary>
Deep neural networks are valuable assets considering their commercial benefits and huge demands for costly annotation and computation resources. To protect the copyright of DNNs, backdoor-based ownership verification becomes popular recently, in which the model owner can watermark the model by embedding a specific backdoor behavior before releasing it. The defenders (usually the model owners) can identify whether a suspicious third-party model is ``stolen'' from them based on the presence of the behavior. Unfortunately, these watermarks are proven to be vulnerable to removal attacks even like fine-tuning. To further explore this vulnerability, we investigate the parameter space and find there exist many watermark-removed models in the vicinity of the watermarked one, which may be easily used by removal attacks. Inspired by this finding, we propose a mini-max formulation to find these watermark-removed models and recover their watermark behavior. Extensive experiments demonstrate that our method improves the robustness of the model watermarking against parametric changes and numerous watermark-removal attacks. The codes for reproducing our main experiments are available at \url{https://github.com/GuanhaoGan/robust-model-watermarking}.
</details>
<details>
<summary>摘要</summary>
深度神经网络是商业上非常有价值的资产，同时它们需要大量的昂贵的注解和计算资源。为了保护深度神经网络的版权，在最近几年，以特定的后门行为为水印的拥有者认可方式在使用。但是这些水印却被证明容易受到移除攻击，甚至是通过精细调整。为了进一步探索这一点，我们研究了参数空间，发现在水印模型附近存在许多没有水印的模型，这些模型可能被用于移除攻击。受这一发现的启发，我们提出了一种最大化-最小化的形式来找到这些没有水印的模型，并恢复它们的水印行为。我们的方法可以提高模型水印的对 Parametric 变化和许多水印移除攻击的Robustness。codes for reproducing our main experiments are available at \url{https://github.com/GuanhaoGan/robust-model-watermarking}.
</details></li>
</ul>
<hr>
<h2 id="SeaEval-for-Multilingual-Foundation-Models-From-Cross-Lingual-Alignment-to-Cultural-Reasoning"><a href="#SeaEval-for-Multilingual-Foundation-Models-From-Cross-Lingual-Alignment-to-Cultural-Reasoning" class="headerlink" title="SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning"></a>SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04766">http://arxiv.org/abs/2309.04766</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bin Wang, Zhengyuan Liu, Xin Huang, Fangkai Jiao, Yang Ding, Ai Ti Aw, Nancy F. Chen</li>
<li>for: 本文提出了一个多语言基础模型的benchmark，以探讨这些模型对自然语言理解和reasong的能力，以及它们对文化实践、细节和价值观的理解。</li>
<li>methods: 本文使用了标准的准确度指标以外的其他方法来评估基础模型的稳定性和多语言能力。</li>
<li>results: 研究发现了许多基础模型具有异常的行为，如重复提供的指令、位置偏好和主流标签偏好。此外，许多模型在根据factual、科学和常识知识提问时表现不一致。<details>
<summary>Abstract</summary>
We present SeaEval, a benchmark for multilingual foundation models. In addition to characterizing how these models understand and reason with natural language, we also investigate how well they comprehend cultural practices, nuances, and values. Alongside standard accuracy metrics, we investigate the brittleness of foundation models in the dimensions of semantics and multilinguality. Our analyses span both open-sourced and closed models, leading to empirical results across classic NLP tasks, reasoning, and cultural comprehension. Key findings indicate (1) Most models exhibit varied behavior when given paraphrased instructions. (2) Many models still suffer from exposure bias (e.g., positional bias, majority label bias). (3) For questions rooted in factual, scientific, and commonsense knowledge, consistent responses are expected across multilingual queries that are semantically equivalent. Yet, most models surprisingly demonstrate inconsistent performance on these queries. (4) Multilingually-trained models have not attained "balanced multilingual" capabilities. Our endeavors underscore the need for more generalizable semantic representations and enhanced multilingual contextualization. SeaEval can serve as a launchpad for more thorough investigations and evaluations for multilingual and multicultural scenarios.
</details>
<details>
<summary>摘要</summary>
我们介绍了 SeaEval，一个多语言基础模型的benchmark。除了描述这些模型如何理解和处理自然语言之外，我们还研究了这些模型如何理解文化做法、细节和价值观。与标准精度指标相结合，我们调查基础模型在语义和多语言方面的脆弱性。我们的分析覆盖了开源和关闭模型，从经典NLP任务、理解到文化理解方面得到了实证结果。关键发现包括：1. 大多数模型对提供重叠 instrucciones 时表现不同。2. 许多模型仍然受到露天偏见（例如位置偏见、多数标签偏见）的影响。3. 根据Factual、科学和通俗知识而问的问题，多语言查询的semantic相同性预期得到一致的回答。然而，大多数模型却在这些查询上表现不一致。4. 多语言训练的模型尚未 дости到了"平衡多语言"的能力。我们的努力强调了需要更加通用的semantic表示和多语言contextualization。 SeaEval可以作为多语言和多文化enario的评估和研究的起点。
</details></li>
</ul>
<hr>
<h2 id="AudRandAug-Random-Image-Augmentations-for-Audio-Classification"><a href="#AudRandAug-Random-Image-Augmentations-for-Audio-Classification" class="headerlink" title="AudRandAug: Random Image Augmentations for Audio Classification"></a>AudRandAug: Random Image Augmentations for Audio Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04762">http://arxiv.org/abs/2309.04762</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/turab45/audrandaug">https://github.com/turab45/audrandaug</a></li>
<li>paper_authors: Teerath Kumar, Muhammad Turab, Alessandra Mileo, Malika Bendechache, Takfarinas Saber</li>
<li>for: 这篇论文主要用于探讨对数据进行资料增强的方法，并提出了一种基于搜索空间的随机数据增强方法（AudRandAug）。</li>
<li>methods: 这篇论文使用了一种基于搜索空间的随机数据增强方法（AudRandAug）， randomly selecting data augmentation techniques from a dedicated audio search space。</li>
<li>results: 根据我们的实验结果，AudRandAug 比其他现有的数据增强方法有着更高的精度表现。<details>
<summary>Abstract</summary>
Data augmentation has proven to be effective in training neural networks. Recently, a method called RandAug was proposed, randomly selecting data augmentation techniques from a predefined search space. RandAug has demonstrated significant performance improvements for image-related tasks while imposing minimal computational overhead. However, no prior research has explored the application of RandAug specifically for audio data augmentation, which converts audio into an image-like pattern. To address this gap, we introduce AudRandAug, an adaptation of RandAug for audio data. AudRandAug selects data augmentation policies from a dedicated audio search space. To evaluate the effectiveness of AudRandAug, we conducted experiments using various models and datasets. Our findings indicate that AudRandAug outperforms other existing data augmentation methods regarding accuracy performance.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate "Data augmentation has proven to be effective in training neural networks. Recently, a method called RandAug was proposed, randomly selecting data augmentation techniques from a predefined search space. RandAug has demonstrated significant performance improvements for image-related tasks while imposing minimal computational overhead. However, no prior research has explored the application of RandAug specifically for audio data augmentation, which converts audio into an image-like pattern. To address this gap, we introduce AudRandAug, an adaptation of RandAug for audio data. AudRandAug selects data augmentation policies from a dedicated audio search space. To evaluate the effectiveness of AudRandAug, we conducted experiments using various models and datasets. Our findings indicate that AudRandAug outperforms other existing data augmentation methods regarding accuracy performance." into 简化中文。Here's the translation:数据增强已经证明对神经网络训练是有效的。最近，一种方法called RandAug被提出，随机从预定搜索空间中选择数据增强策略。RandAug在图像相关任务上表现出了显著的性能提升，而且对计算负担的要求非常低。然而，没有任何之前的研究探讨了将RandAug特地应用于音频数据增强，这将音频转换成图像类似的模式。为了填补这一漏洞，我们介绍了AudRandAug，它是RandAug的音频数据增强版本。AudRandAug从专门的音频搜索空间中选择数据增强策略。为了评估AudRandAug的效果，我们使用了不同的模型和数据集进行实验。我们的发现表明，AudRandAug在准确性表现方面超过了其他现有的数据增强方法。
</details></li>
</ul>
<hr>
<h2 id="RR-CP-Reliable-Region-Based-Conformal-Prediction-for-Trustworthy-Medical-Image-Classification"><a href="#RR-CP-Reliable-Region-Based-Conformal-Prediction-for-Trustworthy-Medical-Image-Classification" class="headerlink" title="RR-CP: Reliable-Region-Based Conformal Prediction for Trustworthy Medical Image Classification"></a>RR-CP: Reliable-Region-Based Conformal Prediction for Trustworthy Medical Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04760">http://arxiv.org/abs/2309.04760</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yizhe Zhang, Shuo Wang, Yejia Zhang, Danny Z. Chen</li>
<li>for: 提高医疗AI模型的准确率和可靠性，以便更好地与人类专家合作。</li>
<li>methods: 基于可靠区域的均衡预测（RR-CP）技术，以实现用户指定的错误率（例如0.5%），并且在这种约束下优化预测集的大小。</li>
<li>results: 在五个公共数据集上进行了实验，并显示了RR-CP在实现用户指定的错误率（例如0.5%）的情况下， prediction set 的大小相对较小，而且可靠性较高。<details>
<summary>Abstract</summary>
Conformal prediction (CP) generates a set of predictions for a given test sample such that the prediction set almost always contains the true label (e.g., 99.5\% of the time). CP provides comprehensive predictions on possible labels of a given test sample, and the size of the set indicates how certain the predictions are (e.g., a set larger than one is `uncertain'). Such distinct properties of CP enable effective collaborations between human experts and medical AI models, allowing efficient intervention and quality check in clinical decision-making. In this paper, we propose a new method called Reliable-Region-Based Conformal Prediction (RR-CP), which aims to impose a stronger statistical guarantee so that the user-specified error rate (e.g., 0.5\%) can be achieved in the test time, and under this constraint, the size of the prediction set is optimized (to be small). We consider a small prediction set size an important measure only when the user-specified error rate is achieved. Experiments on five public datasets show that our RR-CP performs well: with a reasonably small-sized prediction set, it achieves the user-specified error rate (e.g., 0.5\%) significantly more frequently than exiting CP methods.
</details>
<details>
<summary>摘要</summary>
具有预测集的具体预测（CP）生成一个测试样本的预测集，使得预测集中的真实标签几乎总是包含true label（例如，99.5%的时间）。CP提供了测试样本的可能性标签的全面预测，预测集的大小表示预测的certainty（例如，大于一的集是“uncertain”）。CP的特有性使得人类专家和医疗AI模型之间的合作更加有效， allowing for efficient intervention and quality check in clinical decision-making.在这篇论文中，我们提出了一种新的方法called Reliable-Region-Based Conformal Prediction (RR-CP)，旨在在测试时间内实现用户指定的错误率（例如，0.5%），并在这个约束下优化预测集的大小。我们认为小的预测集大小是重要的度量，只当用户指定的错误率得到实现时。在五个公共数据集上进行了实验，我们的RR-CP表现良好：与相对较小的预测集大小，它可以 achieve用户指定的错误率（例如，0.5%），与现有CP方法相比，significantly more frequently。
</details></li>
</ul>
<hr>
<h2 id="Towards-Real-time-Training-of-Physics-informed-Neural-Networks-Applications-in-Ultrafast-Ultrasound-Blood-Flow-Imaging"><a href="#Towards-Real-time-Training-of-Physics-informed-Neural-Networks-Applications-in-Ultrafast-Ultrasound-Blood-Flow-Imaging" class="headerlink" title="Towards Real-time Training of Physics-informed Neural Networks: Applications in Ultrafast Ultrasound Blood Flow Imaging"></a>Towards Real-time Training of Physics-informed Neural Networks: Applications in Ultrafast Ultrasound Blood Flow Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04755">http://arxiv.org/abs/2309.04755</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haotian Guan, Jinping Dong, Wei-Ning Lee</li>
<li>for: 解决 Navier-Stokes 方程，即血液流动方程</li>
<li>methods: 使用 Physics-informed Neural Network (PINN) 和 SeqPINN 方法</li>
<li>results: 实现了血液流动速度的Recovery，并且比原始设计快速多少Here’s the full translation of the abstract in Simplified Chinese:</li>
<li>for: 本文使用 Physics-informed Neural Network (PINN) 方法解决 Navier-Stokes 方程，即血液流动方程，但现有方法不适用于 ultrafast Doppler 超音波，这是血液流动动态图像的 estado-of-the-art 技术。</li>
<li>methods: 本文提出了一种新的训练框架，称为 SeqPINN，它通过稠密化 Navier-Stokes 方程，并采用转移学习来解决稠密化 Navier-Stokes 方程。此外，本文还提出了一种新的初始化方法，称为 SP-PINN，它通过权重抽象和随机梯度下降来初始化 PINN。</li>
<li>results: 对于单血管和 trifurcate 血管的 Finite-element 模拟和 \emph{in vitro} 血液模型，SeqPINN 和 SP-PINN 都能够快速地解决血液流动速度的问题，而且它们分别对 straight 血管和 trifurcate 血管的 RMSE 分别为 1.01 cm&#x2F;s 和 1.26 cm&#x2F;s，和 1.91 cm&#x2F;s 和 2.56 cm&#x2F;s。<details>
<summary>Abstract</summary>
Physics-informed Neural Network (PINN) is one of the most preeminent solvers of Navier-Stokes equations, which are widely used as the governing equation of blood flow. However, current approaches, relying on full Navier-Stokes equations, are impractical for ultrafast Doppler ultrasound, the state-of-the-art technique for depiction of complex blood flow dynamics \emph{in vivo} through acquired thousands of frames (or, timestamps) per second. In this article, we first propose a novel training framework of PINN for solving Navier-Stokes equations by discretizing Navier-Stokes equations into steady state and sequentially solving steady-state Navier-Stokes equations with transfer learning. The novel training framework is coined as SeqPINN. Upon the success of SeqPINN, we adopt the idea of averaged constant stochastic gradient descent (SGD) as initialization and propose a parallel training scheme for all timestamps. To ensure an initialization that generalizes well, we borrow the concept of Stochastic Weight Averaging Gaussian to perform uncertainty estimation as an indicator of generalizability of the initialization. This algorithm, named SP-PINN, further expedites training of PINN while achieving comparable accuracy with SeqPINN. Finite-element simulations and \emph{in vitro} phantoms of single-branch and trifurcate blood vessels are used to evaluate the performance of SeqPINN and SP-PINN. Results show that both SeqPINN and SP-PINN are manyfold faster than the original design of PINN, while respectively achieving Root Mean Square Errors (RMSEs) of 1.01 cm/s and 1.26 cm/s on the straight vessel and 1.91 cm/s and 2.56 cm/s on the trifurcate blood vessel when recovering blood flow velocities.
</details>
<details>
<summary>摘要</summary>
物理学信息化神经网络（PINN）是 Navier-Stokes 方程的一种最优解，广泛用于血液流动的研究。然而，现有的方法，基于全 Navier-Stokes 方程，对于高速Doppler超音波扫描（ultrafast Doppler ultrasound）来说是不实用的。在这篇文章中，我们首先提出了一种新的训练框架，称为SeqPINN，用于解决 Navier-Stokes 方程。我们将 Navier-Stokes 方程精度化为稳定态，并采用转移学习来逐渐解决稳定态 Navier-Stokes 方程。这种训练框架是SeqPINN。成功SeqPINN之后，我们采用了averaged constant stochastic gradient descent（SGD）的初始化，并提出了并行训练方案。为确保一个初始化能够通用，我们借鉴了Stochastic Weight Averaging Gaussian（SWAG）来进行uncertainty estimation，这个算法被称为SP-PINN。SP-PINN可以更快地训练 PINN，而且可以达到与SeqPINN相同的准确性。在finite-element simulations和�emph;in vitro�emph; phantoms中，我们使用了单臂和 trifurcate 血管来评估SeqPINN和SP-PINN的性能。结果显示，SeqPINN和SP-PINN都比原始 PINN 快得多，同时分别在直流血管和 trifurcate 血管中的Root Mean Square Errors（RMSE）分别为1.01 cm/s和1.26 cm/s，以及1.91 cm/s和2.56 cm/s。
</details></li>
</ul>
<hr>
<h2 id="A-Spatiotemporal-Deep-Neural-Network-for-Fine-Grained-Multi-Horizon-Wind-Prediction"><a href="#A-Spatiotemporal-Deep-Neural-Network-for-Fine-Grained-Multi-Horizon-Wind-Prediction" class="headerlink" title="A Spatiotemporal Deep Neural Network for Fine-Grained Multi-Horizon Wind Prediction"></a>A Spatiotemporal Deep Neural Network for Fine-Grained Multi-Horizon Wind Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04733">http://arxiv.org/abs/2309.04733</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hfl15/windpred">https://github.com/hfl15/windpred</a></li>
<li>paper_authors: Fanling Huang, Yangdong Deng</li>
<li>for: 预测风速和方向，即多种实际应用中的关键因素，如航空和风力发电等。</li>
<li>methods: 提出了一种新的数据驱动模型，即多个深度神经网络组合体系（MHSTN），用于准确和高效地预测细详风速和方向。</li>
<li>results: 模型的评估结果表明，与竞争对手相比，MHSTN具有显著的优势，并且已经在中国一个最繁忙的国际机场的调度平台中实现了集成。<details>
<summary>Abstract</summary>
The prediction of wind in terms of both wind speed and direction, which has a crucial impact on many real-world applications like aviation and wind power generation, is extremely challenging due to the high stochasticity and complicated correlation in the weather data. Existing methods typically focus on a sub-set of influential factors and thus lack a systematic treatment of the problem. In addition, fine-grained forecasting is essential for efficient industry operations, but has been less attended in the literature. In this work, we propose a novel data-driven model, Multi-Horizon SpatioTemporal Network (MHSTN), generally for accurate and efficient fine-grained wind prediction. MHSTN integrates multiple deep neural networks targeting different factors in a sequence-to-sequence (Seq2Seq) backbone to effectively extract features from various data sources and produce multi-horizon predictions for all sites within a given region. MHSTN is composed of four major modules. First, a temporal module fuses coarse-grained forecasts derived by Numerical Weather Prediction (NWP) and historical on-site observation data at stations so as to leverage both global and local atmospheric information. Second, a spatial module exploits spatial correlation by modeling the joint representation of all stations. Third, an ensemble module weighs the above two modules for final predictions. Furthermore, a covariate selection module automatically choose influential meteorological variables as initial input. MHSTN is already integrated into the scheduling platform of one of the busiest international airports of China. The evaluation results demonstrate that our model outperforms competitors by a significant margin.
</details>
<details>
<summary>摘要</summary>
各种因素的预测，包括风速和方向，对许多现实生活中的应用，如航空和风力发电，是极其困难的。这是因为天气数据中存在高度的随机性和复杂的相关性。现有的方法通常只关注一 subset of 影响因素，因此缺乏一个系统性的处理方法。另外，细化预测是业务操作的效率化的关键，但在文献中得到了更少的关注。在这项工作中，我们提出了一种新的数据驱动模型，即多个顺序时空网络（Multi-Horizon SpatioTemporal Network，MHSTN），用于准确和效率地进行细化风预测。MHSTN 模型包括四个主要模块。首先，一个时间模块将 numerical weather prediction（NWP） 和历史站点观测数据 fusion 以利用全球和地方大气信息。其次，一个空间模块利用空间相关性，模型所有站点的联合表示。第三，一个ensemble模块将上述两个模块进行最终预测。最后，一个 covariate 选择模块自动选择影响大气变量的关键变量作为输入。MHSTN 模型已经成功 интеGRATED 到了中国一个最繁忙的国际机场的调度平台。评估结果表明，我们的模型在竞争对手之上显著超越。
</details></li>
</ul>
<hr>
<h2 id="TCGAN-Convolutional-Generative-Adversarial-Network-for-Time-Series-Classification-and-Clustering"><a href="#TCGAN-Convolutional-Generative-Adversarial-Network-for-Time-Series-Classification-and-Clustering" class="headerlink" title="TCGAN: Convolutional Generative Adversarial Network for Time Series Classification and Clustering"></a>TCGAN: Convolutional Generative Adversarial Network for Time Series Classification and Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04732">http://arxiv.org/abs/2309.04732</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://bitbucket.org/lynn1/tcgan">https://bitbucket.org/lynn1/tcgan</a></li>
<li>paper_authors: Fanling Huang, Yangdong Deng</li>
<li>for: 本文旨在提出一种时序卷积神经网络（TCGAN），用于不监督地学习时序数据的层次表示。</li>
<li>methods: TCGAN 通过两个一维卷积神经网络（生成器和分类器）进行对抗游戏学习，不需要标注数据。</li>
<li>results: 对 synthetic 和实际世界数据进行了广泛的实验，结果表明 TCGAN 比现有的时序 GAN 更快速和更准确。学习得到的表示能够提高简单的分类和归一化方法的性能，并在具有少量标注和不均匀标注的情况下保持高效。<details>
<summary>Abstract</summary>
Recent works have demonstrated the superiority of supervised Convolutional Neural Networks (CNNs) in learning hierarchical representations from time series data for successful classification. These methods require sufficiently large labeled data for stable learning, however acquiring high-quality labeled time series data can be costly and potentially infeasible. Generative Adversarial Networks (GANs) have achieved great success in enhancing unsupervised and semi-supervised learning. Nonetheless, to our best knowledge, it remains unclear how effectively GANs can serve as a general-purpose solution to learn representations for time series recognition, i.e., classification and clustering. The above considerations inspire us to introduce a Time-series Convolutional GAN (TCGAN). TCGAN learns by playing an adversarial game between two one-dimensional CNNs (i.e., a generator and a discriminator) in the absence of label information. Parts of the trained TCGAN are then reused to construct a representation encoder to empower linear recognition methods. We conducted comprehensive experiments on synthetic and real-world datasets. The results demonstrate that TCGAN is faster and more accurate than existing time-series GANs. The learned representations enable simple classification and clustering methods to achieve superior and stable performance. Furthermore, TCGAN retains high efficacy in scenarios with few-labeled and imbalanced-labeled data. Our work provides a promising path to effectively utilize abundant unlabeled time series data.
</details>
<details>
<summary>摘要</summary>
Recent research has shown that supervised Convolutional Neural Networks (CNNs) can learn hierarchical representations from time series data for successful classification. However, acquiring high-quality labeled time series data can be costly and potentially infeasible. Generative Adversarial Networks (GANs) have achieved great success in enhancing unsupervised and semi-supervised learning. However, it remains unclear how effectively GANs can serve as a general-purpose solution to learn representations for time series recognition, i.e., classification and clustering. Inspired by these considerations, we introduce a Time-series Convolutional GAN (TCGAN). TCGAN learns by playing an adversarial game between two one-dimensional CNNs (i.e., a generator and a discriminator) in the absence of label information. Parts of the trained TCGAN are then reused to construct a representation encoder to empower linear recognition methods. We conducted comprehensive experiments on synthetic and real-world datasets. The results demonstrate that TCGAN is faster and more accurate than existing time-series GANs. The learned representations enable simple classification and clustering methods to achieve superior and stable performance. Furthermore, TCGAN retains high efficacy in scenarios with few-labeled and imbalanced-labeled data. Our work provides a promising path to effectively utilize abundant unlabeled time series data.Here is the word-for-word translation of the text into Simplified Chinese:近期研究表明，监督式 Convolutional Neural Networks (CNNs) 可以学习时序数据的层次表示，以实现成功的分类。然而，获取高质量的时序数据标注可能成本高昂，可能无法实现。生成对抗网络 (GANs) 在无标签情况下增强了无监督和半监督学习。然而，我们知道 GANs 是否可以作为时序Recognition的通用解决方案？TCGAN 是我们的答案。TCGAN 通过两个一维 CNNs（生成器和识别器）之间的对抗游戏学习，不需要标签信息。部分训练 TCGAN 后，可以重用来构建表示编码器，以便使用线性识别方法。我们在synthetic和实际 datasets上进行了广泛的实验。结果表明，TCGAN 比现有的时序 GANs 更快和更准。TCGAN 学习的表示能够使得简单的分类和聚类方法实现超越性和稳定性。此外，TCGAN 在少量标签和偏振标签数据 scenarios 中保持高效。我们的工作为充分利用庞大的无标签时序数据提供了一条可行的道路。
</details></li>
</ul>
<hr>
<h2 id="Transitions-in-echo-index-and-dependence-on-input-repetitions"><a href="#Transitions-in-echo-index-and-dependence-on-input-repetitions" class="headerlink" title="Transitions in echo index and dependence on input repetitions"></a>Transitions in echo index and dependence on input repetitions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04728">http://arxiv.org/abs/2309.04728</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Ashwin, Andrea Ceni</li>
<li>for: 研究非自动的动力系统中的响应性稳态（echo state property），并探讨响应性稳态与输入的关系。</li>
<li>methods: 使用非自动系统的切换 между一组finite maps来研究响应性稳态的依赖于输入的 Parameter。</li>
<li>results: 发现响应性稳态与输入的关系取决于输入的振荡 amplitude和输入的特性，并在输入强度 intermediate 区域内适用。<details>
<summary>Abstract</summary>
The echo index counts the number of simultaneously stable asymptotic responses of a nonautonomous (i.e. input-driven) dynamical system. It generalizes the well-known echo state property for recurrent neural networks - this corresponds to the echo index being equal to one. In this paper, we investigate how the echo index depends on parameters that govern typical responses to a finite-state ergodic external input that forces the dynamics. We consider the echo index for a nonautonomous system that switches between a finite set of maps, where we assume that each map possesses a finite set of hyperbolic equilibrium attractors. We find the minimum and maximum repetitions of each map are crucial for the resulting echo index. Casting our theoretical findings in the RNN computing framework, we obtain that for small amplitude forcing the echo index corresponds to the number of attractors for the input-free system, while for large amplitude forcing, the echo index reduces to one. The intermediate regime is the most interesting; in this region the echo index depends not just on the amplitude of forcing but also on more subtle properties of the input.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SHAPE-A-Sample-adaptive-Hierarchical-Prediction-Network-for-Medication-Recommendation"><a href="#SHAPE-A-Sample-adaptive-Hierarchical-Prediction-Network-for-Medication-Recommendation" class="headerlink" title="SHAPE: A Sample-adaptive Hierarchical Prediction Network for Medication Recommendation"></a>SHAPE: A Sample-adaptive Hierarchical Prediction Network for Medication Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05675">http://arxiv.org/abs/2309.05675</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sicen Liu, Xiaolong Wang, JIngcheng Du, Yongshuai Hou, Xianbing Zhao, Hui Xu, Hui Wang, Yang Xiang, Buzhou Tang</li>
<li>for: 这个论文的目的是提出一种基于复杂多重疾病的药物建议方法，以解决现有的医疗健康预测任务中的挑战。</li>
<li>methods: 该论文提出了一种Sample-adaptive Hierarchical medicAtion Prediction nEtwork（SHAPE）模型，用于解决上述挑战。该模型包括一个嵌入式的内访集编码器，用于编码医疗事件中的关系，以及一个间访长链编码器，用于学习患者水平的时间序列表示。此外，该模型还使用了一种软学习策略，以自动调整每个样本的难度。</li>
<li>results: 经验表明，SHAPE模型在一个标准测试集上比多种现有基线模型具有更高的准确率和更好的泛化能力。<details>
<summary>Abstract</summary>
Effectively medication recommendation with complex multimorbidity conditions is a critical task in healthcare. Most existing works predicted medications based on longitudinal records, which assumed the information transmitted patterns of learning longitudinal sequence data are stable and intra-visit medical events are serialized. However, the following conditions may have been ignored: 1) A more compact encoder for intra-relationship in the intra-visit medical event is urgent; 2) Strategies for learning accurate representations of the variable longitudinal sequences of patients are different. In this paper, we proposed a novel Sample-adaptive Hierarchical medicAtion Prediction nEtwork, termed SHAPE, to tackle the above challenges in the medication recommendation task. Specifically, we design a compact intra-visit set encoder to encode the relationship in the medical event for obtaining visit-level representation and then develop an inter-visit longitudinal encoder to learn the patient-level longitudinal representation efficiently. To endow the model with the capability of modeling the variable visit length, we introduce a soft curriculum learning method to assign the difficulty of each sample automatically by the visit length. Extensive experiments on a benchmark dataset verify the superiority of our model compared with several state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
<<SYS>>输入文本 translate into Simplified Chinese:“医疗健康预测是一项关键任务。现有的大多数工作都是基于长期纪录预测药物，假设传输信息的长期记录数据是稳定的，并且intragvisit医疗事件是串行化的。然而，以下情况可能被忽略：1）更加 компакт的内部关系编码器可以更好地编码医疗事件中的关系，以获得访问级别表示。2）为了学习精准的患者级别长期序列表示，需要不同的策略。在这篇论文中，我们提出了一种新的Sample-adaptive Hierarchical medicAtion Prediction nEtwork，简称SHAPE，以解决以上挑战。具体来说，我们设计了一个更加 компакт的内部关系编码器，以编码医疗事件中的关系，并开发了一个间访长期编码器，以有效地学习患者级别长期序列表示。为了让模型能够模型变化的访问长度，我们引入了一种软学习策略，以自动将每个样本的难度分配到访问长度。经过了一系列的实验，我们发现我们的模型在一个标准 benchmark dataset 上表现出色，与多种状态之前的基准相比。”Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Toward-Reproducing-Network-Research-Results-Using-Large-Language-Models"><a href="#Toward-Reproducing-Network-Research-Results-Using-Large-Language-Models" class="headerlink" title="Toward Reproducing Network Research Results Using Large Language Models"></a>Toward Reproducing Network Research Results Using Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04716">http://arxiv.org/abs/2309.04716</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiao Xiang, Yuling Lin, Mingjun Fang, Bang Huang, Siyong Huang, Ridi Wen, Franck Le, Linghe Kong, Jiwu Shu</li>
<li>for: 本文提出了一种新的方法来复制网络研究结果，即使用大型自然语言模型（LLM）。</li>
<li>methods: 本文使用了四名学生，每个学生分别使用ChatGPT进行一种不同的网络系统的复制，通过提示工程来实现。</li>
<li>results: 实验观察到了四名学生的复制结果和经验教训，并提出了未来的研究问题。<details>
<summary>Abstract</summary>
Reproducing research results in the networking community is important for both academia and industry. The current best practice typically resorts to three approaches: (1) looking for publicly available prototypes; (2) contacting the authors to get a private prototype; and (3) manually implementing a prototype following the description of the publication. However, most published network research does not have public prototypes and private prototypes are hard to get. As such, most reproducing efforts are spent on manual implementation based on the publications, which is both time and labor consuming and error-prone. In this paper, we boldly propose reproducing network research results using the emerging large language models (LLMs). In particular, we first prove its feasibility with a small-scale experiment, in which four students with essential networking knowledge each reproduces a different networking system published in prominent conferences and journals by prompt engineering ChatGPT. We report the experiment's observations and lessons and discuss future open research questions of this proposal. This work raises no ethical issue.
</details>
<details>
<summary>摘要</summary>
重要的网络研究结果复制是对学术界和业界都非常重要。目前最佳做法通常是：（1）搜索公开可用的原型；（2）与作者联系以获取私有原型；以及（3）根据文章描述手动实现原型。但大多数发表的网络研究没有公共原型，私有原型很难获得。因此，大多数复制努力都是基于文章的手动实现，这是时间和劳动 intensity的和容易出错的。在这篇论文中，我们勇敢地提议使用emerging的大语言模型（LLMs）来复制网络研究结果。具体来说，我们首先证明了这种方法的可行性，通过在四名学生每个复制一种不同的网络系统，这些系统分别发表在知名会议和学术期刊上，通过提示工程ChatGPT来实现。我们报告了实验的观察和教训，并讨论了未来的开放研究问题。这项工作没有伦理问题。
</details></li>
</ul>
<hr>
<h2 id="Jade-A-Differentiable-Physics-Engine-for-Articulated-Rigid-Bodies-with-Intersection-Free-Frictional-Contact"><a href="#Jade-A-Differentiable-Physics-Engine-for-Articulated-Rigid-Bodies-with-Intersection-Free-Frictional-Contact" class="headerlink" title="Jade: A Differentiable Physics Engine for Articulated Rigid Bodies with Intersection-Free Frictional Contact"></a>Jade: A Differentiable Physics Engine for Articulated Rigid Bodies with Intersection-Free Frictional Contact</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04710">http://arxiv.org/abs/2309.04710</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gang Yang, Siyuan Luo, Lin Shao</li>
<li>for: 这个论文是用来描述一个可微分的物理引擎，用于静止和动的零碎体之间的冲击和碰撞。</li>
<li>methods: 这个论文使用了Linear Complementarity Problem (LCP)来模型联系，并且使用了无穷小冲击探测和反转策略来避免体之间的交叉。它还使用了不断的碰撞探测来探测冲击时间，并且将整个模拟过程转换为可微分的形式。</li>
<li>results: 这个论文通过广泛的实验表明，它的可微分物理模拟可以在许多具有联系的任务中实现更高的效能和稳定性，比如零碎体之间的碰撞和冲击。<details>
<summary>Abstract</summary>
We present Jade, a differentiable physics engine for articulated rigid bodies. Jade models contacts as the Linear Complementarity Problem (LCP). Compared to existing differentiable simulations, Jade offers features including intersection-free collision simulation and stable LCP solutions for multiple frictional contacts. We use continuous collision detection to detect the time of impact and adopt the backtracking strategy to prevent intersection between bodies with complex geometry shapes. We derive the gradient calculation to ensure the whole simulation process is differentiable under the backtracking mechanism. We modify the popular Dantzig algorithm to get valid solutions under multiple frictional contacts. We conduct extensive experiments to demonstrate the effectiveness of our differentiable physics simulation over a variety of contact-rich tasks.
</details>
<details>
<summary>摘要</summary>
我们介绍了一个差异化物理引擎——瑰琅（Jade），它模型了接触为线性补假问题（LCP）。相比现有的差异化仿真，瑰琅具有不同的特点，包括不受接触干扰的碰撞仿真和多种摩擦接触的稳定解。我们使用连续碰撞检测来检测碰撞时间，并采用回溯策略来避免复杂形状的体之间的交叠。我们还计算了梯度，以确保整个仿真过程是不可分割的。我们修改了流行的达条算法，以获得多种摩擦接触下的有效解。我们进行了广泛的实验，以证明我们的差异化物理仿真在多种接触丰富任务中的效果。
</details></li>
</ul>
<hr>
<h2 id="Advantage-Actor-Critic-with-Reasoner-Explaining-the-Agent’s-Behavior-from-an-Exploratory-Perspective"><a href="#Advantage-Actor-Critic-with-Reasoner-Explaining-the-Agent’s-Behavior-from-an-Exploratory-Perspective" class="headerlink" title="Advantage Actor-Critic with Reasoner: Explaining the Agent’s Behavior from an Exploratory Perspective"></a>Advantage Actor-Critic with Reasoner: Explaining the Agent’s Behavior from an Exploratory Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04707">http://arxiv.org/abs/2309.04707</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muzhe Guo, Feixu Yu, Tian Lan, Fang Jin</li>
<li>for: 解决复杂决策问题的 reinforcement learning (RL) 缺乏透明度和可解释性，这在具有重要实际影响的决策领域 pose  significative 挑战。</li>
<li>methods: 我们提出了一种名为 Advantage Actor-Critic with Reasoner (A2CR) 的新方法，可以轻松应用于 Actor-Critic 基于的 RL 模型中，并使其更加可解释。A2CR 由三个相互连接的网络组成：政策网络、价值网络和理解器网络。通过预先定义和分类 actor 的行为目的，A2CR 自动生成了更加全面和可解释的决策过程模型。</li>
<li>results: 在行动含量高的 Super Mario Bros 环境中进行了评估，发现：Reasoner 预测的标签分数随 RL 算法的探索水平增加而减少，而 purpose-based 焦点更加集中和可读。<details>
<summary>Abstract</summary>
Reinforcement learning (RL) is a powerful tool for solving complex decision-making problems, but its lack of transparency and interpretability has been a major challenge in domains where decisions have significant real-world consequences. In this paper, we propose a novel Advantage Actor-Critic with Reasoner (A2CR), which can be easily applied to Actor-Critic-based RL models and make them interpretable. A2CR consists of three interconnected networks: the Policy Network, the Value Network, and the Reasoner Network. By predefining and classifying the underlying purpose of the actor's actions, A2CR automatically generates a more comprehensive and interpretable paradigm for understanding the agent's decision-making process. It offers a range of functionalities such as purpose-based saliency, early failure detection, and model supervision, thereby promoting responsible and trustworthy RL. Evaluations conducted in action-rich Super Mario Bros environments yield intriguing findings: Reasoner-predicted label proportions decrease for ``Breakout" and increase for ``Hovering" as the exploration level of the RL algorithm intensifies. Additionally, purpose-based saliencies are more focused and comprehensible.
</details>
<details>
<summary>摘要</summary>
� Reinforcement learning (RL) 是一种强大的解决复杂决策问题的工具，但它缺乏透明性和可解释性，在具有重要现实世界影响的领域是一个主要挑战。在这篇论文中，我们提出了一种新的优先级理解者-评价者（A2CR）模型，可以轻松应用于actor-critic型RL模型中，并使其更加透明。A2CR包括三个相互连接的网络：政策网络、价值网络和理解者网络。通过预先定义和分类actor的行为目的，A2CR自动生成了更加全面和可解释的agent决策过程的模型。它提供了一些功能，如目的基于的焦点度、早期失败检测和模型监管，从而推动了负责任和可信RL。在动作富 Super Mario Bros 环境中进行的评估结果表明：理解者预测的标签分布随RL算法的探索水平的强化而下降，而“Breakout”和“悬停”的目的基于的焦点度更加集中和可解释。
</details></li>
</ul>
<hr>
<h2 id="Analysis-of-Disinformation-and-Fake-News-Detection-Using-Fine-Tuned-Large-Language-Model"><a href="#Analysis-of-Disinformation-and-Fake-News-Detection-Using-Fine-Tuned-Large-Language-Model" class="headerlink" title="Analysis of Disinformation and Fake News Detection Using Fine-Tuned Large Language Model"></a>Analysis of Disinformation and Fake News Detection Using Fine-Tuned Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04704">http://arxiv.org/abs/2309.04704</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bohdan M. Pavlyshenko</li>
<li>for: 本研究探讨了使用LLM进行假新闻检测和假信息分析的可能性。</li>
<li>methods: 本研究使用PEFT&#x2F;LoRA等方法进行了模型精细调整。</li>
<li>results: 研究表明，精细调整的Llama 2模型可以深入分析文本，揭示复杂的风格和narraatives。提取的名实体情感可以作为预测特征在指导机器学习模型中。<details>
<summary>Abstract</summary>
The paper considers the possibility of fine-tuning Llama 2 large language model (LLM) for the disinformation analysis and fake news detection. For fine-tuning, the PEFT/LoRA based approach was used. In the study, the model was fine-tuned for the following tasks: analysing a text on revealing disinformation and propaganda narratives, fact checking, fake news detection, manipulation analytics, extracting named entities with their sentiments. The obtained results show that the fine-tuned Llama 2 model can perform a deep analysis of texts and reveal complex styles and narratives. Extracted sentiments for named entities can be considered as predictive features in supervised machine learning models.
</details>
<details>
<summary>摘要</summary>
文章考虑了使用LLama 2大语言模型（LLM）进行假新闻检测和假信息分析的可能性。为了进行细化，使用了PEFT/LoRA基于的方法。研究中使用了以下任务进行细化：分析文本中的假信息和宣传叙述，实现Fact Checking，假新闻检测， manipulate analytics，提取Named Entity的情感。研究结果显示，经过细化的Llama 2模型可以对文本进行深入的分析，揭示复杂的风格和叙述。提取的情感特征可以作为生成式机器学习模型的预测特征。
</details></li>
</ul>
<hr>
<h2 id="Advancements-in-Upper-Body-Exoskeleton-Implementing-Active-Gravity-Compensation-with-a-Feedforward-Controller"><a href="#Advancements-in-Upper-Body-Exoskeleton-Implementing-Active-Gravity-Compensation-with-a-Feedforward-Controller" class="headerlink" title="Advancements in Upper Body Exoskeleton: Implementing Active Gravity Compensation with a Feedforward Controller"></a>Advancements in Upper Body Exoskeleton: Implementing Active Gravity Compensation with a Feedforward Controller</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04698">http://arxiv.org/abs/2309.04698</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Ayaz Hussain, Ioannis Iossifidis</li>
<li>for: 这个论文是为了开发一种基于前向控制的活动重力补偿 upper body exoskeleton 的控制系统。</li>
<li>methods: 这个系统使用内部电动机传感器的位置数据来计算扭矩，使用分析控制方程基于新顿-尤利尔反动动力学。</li>
<li>results: 对硬件和软件实验以及模拟结果进行比较，系统在稳定性和精度方面具有优秀表现，能够维持位置在长时间内，并具有最小摩擦和不良滚动的特点。<details>
<summary>Abstract</summary>
In this study, we present a feedforward control system designed for active gravity compensation on an upper body exoskeleton. The system utilizes only positional data from internal motor sensors to calculate torque, employing analytical control equations based on Newton-Euler Inverse Dynamics. Compared to feedback control systems, the feedforward approach offers several advantages. It eliminates the need for external torque sensors, resulting in reduced hardware complexity and weight. Moreover, the feedforward control exhibits a more proactive response, leading to enhanced performance. The exoskeleton used in the experiments is lightweight and comprises 4 Degrees of Freedom, closely mimicking human upper body kinematics and three-dimensional range of motion. We conducted tests on both hardware and simulations of the exoskeleton, demonstrating stable performance. The system maintained its position over an extended period, exhibiting minimal friction and avoiding undesired slewing.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们提出了一种Feedforward控制系统，用于活动重力补偿Upper Body exoskeleton。该系统只使用内部电动机传感器的位势数据来计算扭矩，使用分析控制方程基于新顿-尤利尔反逆动力学。相比反馈控制系统，Feedforward方法具有多种优势。它消除了需要外部扭矩传感器的需求，从而减轻硬件复杂性和重量。此外，Feedforward控制具有更加积极的响应，导致性能的提高。我们使用的Exoskeleton是轻量级的，包含4个度Of Freedom，准确模拟人类Upper Body骨骼动态和三维运动范围。我们对硬件和Simulations中的Exoskeleton进行了测试，示出了稳定的性能。系统在Extended Period内保持了其位置，表现出Minimal friction和避免了不良滚动。
</details></li>
</ul>
<hr>
<h2 id="Code-Style-In-Context-Learning-for-Knowledge-Based-Question-Answering"><a href="#Code-Style-In-Context-Learning-for-Knowledge-Based-Question-Answering" class="headerlink" title="Code-Style In-Context Learning for Knowledge-Based Question Answering"></a>Code-Style In-Context Learning for Knowledge-Based Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04695">http://arxiv.org/abs/2309.04695</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/TeniaKovacs/ExploratoryDataProject1">https://github.com/TeniaKovacs/ExploratoryDataProject1</a></li>
<li>paper_authors: Zhijie Nie, Richong Zhang, Zhongyuan Wang, Xudong Liu</li>
<li>for: 本研究旨在提高知识基因问答（KBQA）的实用应用，通过简单的训练技术和模型框架来解决现有的限制。</li>
<li>methods: 本研究使用了受Context学习（ICL）技术，通过给大语言模型（LLM）提供一小数量的问题和其标注的逻辑形式作为示例，使得LLM可以理解任务意图并生成新问题的逻辑形式。</li>
<li>results: 实验结果表明，我们的代码式受Context学习方法可以减少生成逻辑形式时的格式错误问题，同时实现新的最佳性能在WebQSP、GrailQA和GraphQ下的少量设定下。<details>
<summary>Abstract</summary>
Current methods for Knowledge-Based Question Answering (KBQA) usually rely on complex training techniques and model frameworks, leading to many limitations in practical applications. Recently, the emergence of In-Context Learning (ICL) capabilities in Large Language Models (LLMs) provides a simple and training-free semantic parsing paradigm for KBQA: Given a small number of questions and their labeled logical forms as demo examples, LLMs can understand the task intent and generate the logic form for a new question. However, current powerful LLMs have little exposure to logic forms during pre-training, resulting in a high format error rate. To solve this problem, we propose a code-style in-context learning method for KBQA, which converts the generation process of unfamiliar logical form into the more familiar code generation process for LLMs. Experimental results on three mainstream datasets show that our method dramatically mitigated the formatting error problem in generating logic forms while realizing a new SOTA on WebQSP, GrailQA, and GraphQ under the few-shot setting.
</details>
<details>
<summary>摘要</summary>
现有的知识基本问答（KBQA）方法通常依赖于复杂的训练技术和模型框架，导致在实际应用中具有许多限制。近期，大量语言模型（LLMs）的具有场景学习（ICL）能力提供了一种简单而无需训练的 semantic parsing 模型 для KBQA：给定一小 número de preguntas和其标注的逻辑形式作为示例，LLMs 可以理解任务目的并生成新的问题逻辑形式。然而，当前最强大的 LLMs 在预训练时对逻辑形式没有多少接触，导致高的格式错误率。为解决这个问题，我们提议一种 code-style 在 Context Learning 方法 для KBQA，将生成不熟悉的逻辑形式转换成更加熟悉的代码生成过程。实验结果表明，我们的方法可以减少生成逻辑形式时的格式错误问题，同时实现新的 SOTA 在 WebQSP、GrailQA 和 GraphQ 上下的 few-shot 设置下。
</details></li>
</ul>
<hr>
<h2 id="Flexible-and-Robust-Counterfactual-Explanations-with-Minimal-Satisfiable-Perturbations"><a href="#Flexible-and-Robust-Counterfactual-Explanations-with-Minimal-Satisfiable-Perturbations" class="headerlink" title="Flexible and Robust Counterfactual Explanations with Minimal Satisfiable Perturbations"></a>Flexible and Robust Counterfactual Explanations with Minimal Satisfiable Perturbations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04676">http://arxiv.org/abs/2309.04676</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangyongjie-ntu/cemsp">https://github.com/wangyongjie-ntu/cemsp</a></li>
<li>paper_authors: Yongjie Wang, Hangwei Qian, Yongjie Liu, Wei Guo, Chunyan Miao</li>
<li>For: The paper aims to provide more robust and flexible counterfactual explanations (CFEs) for enhancing informational fairness and trustworthiness in machine learning models.* Methods: The proposed method, called Counterfactual Explanations with Minimal Satisfiable Perturbations (CEMSP), constrains changing values of abnormal features with their semantically meaningful normal ranges, and models the problem as a Boolean satisfiability problem to modify as few features as possible.* Results: The proposed method provides more robust explanations while preserving flexibility, and is demonstrated to be more effective than existing methods through comprehensive experiments on both synthetic and real-world datasets.Here’s the simplified Chinese text for the three key points:* For: 这篇论文目的是提供更加稳定和灵活的对假解释（CFEs），以增强机器学习模型的信息公正和可靠性。* Methods: 提议的方法是Counterfactual Explanations with Minimal Satisfiable Perturbations（CEMSP），它将异常特征值修改为 semantically meaningful normal ranges，并将问题模型为Boolean satisfiability problem，以修改最少特征。* Results: 提议的方法可以提供更加稳定的解释，同时保持灵活性，并在synthetic和实际 datasets上进行了广泛的实验，证明了它比现有方法更有效。<details>
<summary>Abstract</summary>
Counterfactual explanations (CFEs) exemplify how to minimally modify a feature vector to achieve a different prediction for an instance. CFEs can enhance informational fairness and trustworthiness, and provide suggestions for users who receive adverse predictions. However, recent research has shown that multiple CFEs can be offered for the same instance or instances with slight differences. Multiple CFEs provide flexible choices and cover diverse desiderata for user selection. However, individual fairness and model reliability will be damaged if unstable CFEs with different costs are returned. Existing methods fail to exploit flexibility and address the concerns of non-robustness simultaneously. To address these issues, we propose a conceptually simple yet effective solution named Counterfactual Explanations with Minimal Satisfiable Perturbations (CEMSP). Specifically, CEMSP constrains changing values of abnormal features with the help of their semantically meaningful normal ranges. For efficiency, we model the problem as a Boolean satisfiability problem to modify as few features as possible. Additionally, CEMSP is a general framework and can easily accommodate more practical requirements, e.g., casualty and actionability. Compared to existing methods, we conduct comprehensive experiments on both synthetic and real-world datasets to demonstrate that our method provides more robust explanations while preserving flexibility.
</details>
<details>
<summary>摘要</summary>
counterfactual explanations (CFEs) 可以最小化特征向量的修改，以实现对一个实例的不同预测。CFEs 可以提高信息公正和可靠性，并为用户提供不同预测选择的建议。然而，当不同的 CFEs 对同一个实例或 slight 不同的实例提供多个选择时，这会导致问题。多个 CFEs 可以提供多样化的选择，但是如果返回不稳定的 CFEs ，则个人公正和模型可靠性将受损。现有方法无法充分利用多样化和不稳定性问题的同时处理。为解决这些问题，我们提出了一种概念简单又有效的解决方案，名为 counterfactual explanations with minimal satisfiable perturbations (CEMSP)。具体来说，CEMSP 通过在异常特征上进行Semantically meaningful normal range的改变来限制修改。为了提高效率，我们将问题模型为Boolean satisfiability problem，以修改最少的特征。此外，CEMSP 是一个通用的框架，可以轻松地满足更多的实际需求，例如 causality 和 actionability。与现有方法相比，我们在 Both synthetic 和实际数据集上进行了 comprehensive 的实验，并证明了我们的方法可以提供更加稳定的解释，同时保持多样化。
</details></li>
</ul>
<hr>
<h2 id="FIAT-Fusing-learning-paradigms-with-Instruction-Accelerated-Tuning"><a href="#FIAT-Fusing-learning-paradigms-with-Instruction-Accelerated-Tuning" class="headerlink" title="FIAT: Fusing learning paradigms with Instruction-Accelerated Tuning"></a>FIAT: Fusing learning paradigms with Instruction-Accelerated Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04663">http://arxiv.org/abs/2309.04663</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyi Wang, John Wieting, Jonathan H. Clark</li>
<li>for: 这篇论文旨在探讨大语言模型（LLM）的学习方法，具体来说是研究如何使用受限的数据量、模型大小和计算成本来训练LLM，以及如何使用最大化的方法来提高模型的性能。</li>
<li>methods: 该论文使用了两种常见的LLM学习方法：受限学习（ICL）和全部精度调整（full fine-tuning）。它们的不同之处在于数据量、模型大小和计算成本等方面，并且它们在不同的任务上表现不同。</li>
<li>results: 研究发现，使用FIAT方法可以在100-10,000个训练示例的范围内，比ICL和精度调整更好地表现。FIAT方法可以同时利用最大化的方法和受限学习的方法，以提高模型的性能。<details>
<summary>Abstract</summary>
Learning paradigms for large language models (LLMs) currently tend to fall within either in-context learning (ICL) or full fine-tuning. Each of these comes with their own trade-offs based on available data, model size, compute cost, ease-of-use, and final quality with neither solution performing well across-the-board. In this article, we first describe ICL and fine-tuning paradigms in a way that highlights their natural connections. Based on these connections, we propose a new learning paradigm called FIAT that fuses the best of these paradigms together, enabling prompt-engineered instructions and chain-of-thought reasoning with the very largest models while also using similar methods to perform parameter updates on a modestly-sized LLM with parameter-efficient tuning. We evaluate FIAT's effectiveness on a variety of multilingual tasks and observe that FIAT performs better than both ICL and fine-tuning at scales ranging from 100-10,000 training examples. We hope that FIAT provides a practical way of harnessing the full potential of LLMs without needing to make a hard choice between learning paradigms.
</details>
<details>
<summary>摘要</summary>
现有大语言模型（LLM）学习模式主要分为两类：在Context Learning（ICL）和完整精度调整（Fine-tuning）。每种方法都有其特点，包括数据可用性、模型大小、计算成本、使用容易度和最终质量等方面。然而， neither solution performs well across-the-board。在这篇文章中，我们首先描述ICL和精度调整模式，并将其联系到它们之间的自然联系。基于这些联系，我们提议一种新的学习模式called FIAT，它结合了ICL和精度调整模式的优点，使得使用最大模型时可以实现提示工程ered instrucions和链式思维，同时使用相同的方法来进行参数更新 modestly-sized LLM中 parameter-efficient tuning。我们在多种多语言任务上评估FIAT的效果，并发现FIAT在100-10,000个训练示例范围内比ICL和精度调整更好。我们希望FIAT可以为LLM的潜在力量做出实用的方式，不需要选择学习模式。
</details></li>
</ul>
<hr>
<h2 id="Video-and-Synthetic-MRI-Pre-training-of-3D-Vision-Architectures-for-Neuroimage-Analysis"><a href="#Video-and-Synthetic-MRI-Pre-training-of-3D-Vision-Architectures-for-Neuroimage-Analysis" class="headerlink" title="Video and Synthetic MRI Pre-training of 3D Vision Architectures for Neuroimage Analysis"></a>Video and Synthetic MRI Pre-training of 3D Vision Architectures for Neuroimage Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04651">http://arxiv.org/abs/2309.04651</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikhil J. Dhinagar, Amit Singh, Saket Ozarkar, Ketaki Buwa, Sophia I. Thomopoulos, Conor Owens-Walton, Emily Laltoo, Yao-Liang Chen, Philip Cook, Corey McMillan, Chih-Chien Tsai, J-J Wang, Yih-Ru Wu, Paul M. Thompson<br>for: 这个论文主要是为了评估不同的预训练方法，以提高3D医学影像任务的模型性能。methods: 作者使用了视transformer（ViT）和卷积神经网络（CNN）作为模型，并对其进行了不同的预训练方法 initialization。results: 研究发现，预训练可以提高所有任务的性能，包括提高AD分类任务的性能7.4%和PD分类任务的性能4.6%，同时也可以减少脑龄预测错误值1.26年。此外，研究还发现，使用大规模的视频或合成MRI数据进行预训练可以提高ViT的性能，而CNN在有限数据设置下表现了良好的稳定性，并且在预训练下进行域外预测也有良好的性能。<details>
<summary>Abstract</summary>
Transfer learning represents a recent paradigm shift in the way we build artificial intelligence (AI) systems. In contrast to training task-specific models, transfer learning involves pre-training deep learning models on a large corpus of data and minimally fine-tuning them for adaptation to specific tasks. Even so, for 3D medical imaging tasks, we do not know if it is best to pre-train models on natural images, medical images, or even synthetically generated MRI scans or video data. To evaluate these alternatives, here we benchmarked vision transformers (ViTs) and convolutional neural networks (CNNs), initialized with varied upstream pre-training approaches. These methods were then adapted to three unique downstream neuroimaging tasks with a range of difficulty: Alzheimer's disease (AD) and Parkinson's disease (PD) classification, "brain age" prediction. Experimental tests led to the following key observations: 1. Pre-training improved performance across all tasks including a boost of 7.4% for AD classification and 4.6% for PD classification for the ViT and 19.1% for PD classification and reduction in brain age prediction error by 1.26 years for CNNs, 2. Pre-training on large-scale video or synthetic MRI data boosted performance of ViTs, 3. CNNs were robust in limited-data settings, and in-domain pretraining enhanced their performances, 4. Pre-training improved generalization to out-of-distribution datasets and sites. Overall, we benchmarked different vision architectures, revealing the value of pre-training them with emerging datasets for model initialization. The resulting pre-trained models can be adapted to a range of downstream neuroimaging tasks, even when training data for the target task is limited.
</details>
<details>
<summary>摘要</summary>
transferred learning 表示人工智能（AI）系统的新方法shift。相比于专门预训练任务的模型，transferred learning 涉及预训练深度学习模型在大量数据集上并将其微调以适应特定任务。然而， для 3D医学成像任务，我们不知道是否最好预训练模型在自然图像、医疗图像或Synthetically生成的MRI扫描或视频数据上。为了评估这些选择，我们在这里对 ViTs 和 convolutional neural networks (CNNs) 进行了初始化不同的上游预训练方法。这些方法然后在三个独特的下游神经成像任务中进行了适应，包括阿尔茨海默病（AD）和公主病（PD）的分类、"脑龄"预测。实验测试表明了以下关键观察：1. 预训练提高了所有任务的表现，包括ViTs中的7.4%的AD分类提升和4.6%的PD分类提升，以及CNNs中的19.1%的PD分类提升和1.26年的脑龄预测错误减少。2. 预训练在大规模的视频或生成的MRI数据上得到了ViTs的提升，而CNNs在有限数据设置中表现了 robustness。3. 在有限数据设置中，培育在域内预训练中表现出了优异，而CNNs在域外预训练中表现出了更好的泛化性。4. 预训练提高了模型对不同数据集和站点的泛化性。总之，我们对不同的视觉架构进行了 benchmarking，发现预训练它们使用emerging datasets的值。这些预训练的模型可以适应一系列的下游神经成像任务，即使训练数据集的规模有限。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Finetuning-Large-Language-Models-For-Vietnamese-Chatbot"><a href="#Efficient-Finetuning-Large-Language-Models-For-Vietnamese-Chatbot" class="headerlink" title="Efficient Finetuning Large Language Models For Vietnamese Chatbot"></a>Efficient Finetuning Large Language Models For Vietnamese Chatbot</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04646">http://arxiv.org/abs/2309.04646</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vu-Thuan Doan, Quoc-Truong Truong, Duc-Vu Nguyen, Vinh-Tiep Nguyen, Thuy-Ngan Nguyen Luu</li>
<li>for: 这个研究旨在提高大型自然语言模型（LLMs）的效能，并且可以实现用户的指令和生成人类化回应。</li>
<li>methods: 我们使用大量的指令跟踪数据库，包括Alpaca、GPT4All和Chat-Doctor等，这些数据库覆盖了通用领域和具体医疗领域。然后，我们使用LoRA的参数高效调整技术，将Bloomz（多语言）和GPTJ-6B（越南语）两个开源模型进行调整，从而产生四个模型：Bloomz-Chat、Bloomz-Doctor、GPTJ-Chat和GPTJ-Doctor。</li>
<li>results: 我们通过自动评分机制GPT-4进行评估，发现我们的方法可以在评估任务中提高20-30%。<details>
<summary>Abstract</summary>
Large language models (LLMs), such as GPT-4, PaLM, and LLaMa, have been shown to achieve remarkable performance across a variety of natural language tasks. Recent advancements in instruction tuning bring LLMs with ability in following user's instructions and producing human-like responses. However, the high costs associated with training and implementing LLMs pose challenges to academic research. Furthermore, the availability of pretrained LLMs and instruction-tune datasets for Vietnamese language is limited. To tackle these concerns, we leverage large-scale instruction-following datasets from open-source projects, namely Alpaca, GPT4All, and Chat-Doctor, which cover general domain and specific medical domain. To the best of our knowledge, these are the first instructional dataset for Vietnamese. Subsequently, we utilize parameter-efficient tuning through Low-Rank Adaptation (LoRA) on two open LLMs: Bloomz (Multilingual) and GPTJ-6B (Vietnamese), resulting four models: Bloomz-Chat, Bloomz-Doctor, GPTJ-Chat, GPTJ-Doctor.Finally, we assess the effectiveness of our methodology on a per-sample basis, taking into consideration the helpfulness, relevance, accuracy, level of detail in their responses. This evaluation process entails the utilization of GPT-4 as an automated scoring mechanism. Despite utilizing a low-cost setup, our method demonstrates about 20-30\% improvement over the original models in our evaluation tasks.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM），如GPT-4、PaLM和LLaMa，已经在各种自然语言任务上表现出色。最近的指令调整技术使得LLM可以按照用户的指令进行行动，并生成人类化的回复。然而，训练和实现LLM的成本高昂，对学术研究提出了挑战。此外，预训练的LLM和指令调整数据集 для越南语言的可用性受限。为解决这些问题，我们利用大规模的指令遵从数据集，来自开源项目，包括Alpaca、GPT4All和Chat-Doctor，这些数据集覆盖通用领域和具体医疗领域。我们知道这是越南语言第一个指令数据集。然后，我们使用LoRA parameter-efficient tuning技术，在开放的两个LLM上进行调整，生成四个模型：Bloomz-Chat、Bloomz-Doctor、GPTJ-Chat和GPTJ-Doctor。最后，我们根据每个样本的帮助程度、相关性、准确性和回答细节进行评估。这个评估过程中使用GPT-4作为自动评分机制。尽管我们使用低成本的设置，但我们的方法在我们的评估任务中表现出20-30%的提升。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/09/cs.AI_2023_09_09/" data-id="cloimip50003ls48895pk8cne" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/38/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/37/">37</a><a class="page-number" href="/page/38/">38</a><span class="page-number current">39</span><a class="page-number" href="/page/40/">40</a><a class="page-number" href="/page/41/">41</a><span class="space">&hellip;</span><a class="page-number" href="/page/84/">84</a><a class="extend next" rel="next" href="/page/40/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">116</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">56</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">112</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">62</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
