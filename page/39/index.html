
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/39/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.CV_2023_09_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/09/cs.CV_2023_09_09/" class="article-date">
  <time datetime="2023-09-09T13:00:00.000Z" itemprop="datePublished">2023-09-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/09/cs.CV_2023_09_09/">cs.CV - 2023-09-09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Semi-supervised-Instance-Segmentation-with-a-Learned-Shape-Prior"><a href="#Semi-supervised-Instance-Segmentation-with-a-Learned-Shape-Prior" class="headerlink" title="Semi-supervised Instance Segmentation with a Learned Shape Prior"></a>Semi-supervised Instance Segmentation with a Learned Shape Prior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04888">http://arxiv.org/abs/2309.04888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Long Chen, Weiwen Zhang, Yuli Wu, Martin Strauch, Dorit Merhof</li>
<li>for: 这个 paper 是为了解决实例分割问题，而不需要大量的标注对象边框数据。</li>
<li>methods: 这个方法使用了形状先验模型，该模型是通过变分自动编码器学习的，只需要很少量的训练数据。</li>
<li>results: 在我们的实验中，使用了几十个目标数据集中的对象形状补丁，以及完全 sintetic 的形状，可以达到与超级vised 方法相同的效果，并在三个 cell 分割数据集上都 superior 于预训练的超级vised 模型。<details>
<summary>Abstract</summary>
To date, most instance segmentation approaches are based on supervised learning that requires a considerable amount of annotated object contours as training ground truth. Here, we propose a framework that searches for the target object based on a shape prior. The shape prior model is learned with a variational autoencoder that requires only a very limited amount of training data: In our experiments, a few dozens of object shape patches from the target dataset, as well as purely synthetic shapes, were sufficient to achieve results en par with supervised methods with full access to training data on two out of three cell segmentation datasets. Our method with a synthetic shape prior was superior to pre-trained supervised models with access to limited domain-specific training data on all three datasets. Since the learning of prior models requires shape patches, whether real or synthetic data, we call this framework semi-supervised learning.
</details>
<details>
<summary>摘要</summary>
到目前为止，大多数实例分割方法基于supervised learning，需要较大量的标注对象边框作为训练真实数据。在这里，我们提出了一种框架，它基于形态先验来寻找目标对象。形态先验模型通过variational autoencoder来学习，只需要一个非常有限的训练数据：在我们的实验中，几十个目标数据集中的对象形状补充、完全 sintética的形状都能够达到与supervised方法相同的效果。我们的方法使用 sintética形状先验在所有三个数据集上都高于预训练的supervised模型。由于学习先验模型需要形状补充，是semi-supervised learning。
</details></li>
</ul>
<hr>
<h2 id="SortedAP-Rethinking-evaluation-metrics-for-instance-segmentation"><a href="#SortedAP-Rethinking-evaluation-metrics-for-instance-segmentation" class="headerlink" title="SortedAP: Rethinking evaluation metrics for instance segmentation"></a>SortedAP: Rethinking evaluation metrics for instance segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04887">http://arxiv.org/abs/2309.04887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Long Chen, Yuli Wu, Johannes Stegmaier, Dorit Merhof</li>
<li>for: 评估实例分割中的评价指标，需要全面考虑对象检测和分割精度。</li>
<li>methods: 本文提出了一种新的评价指标called sortedAP，它具有 conditional sensitivity和精度递减的特点。</li>
<li>results: sortedAP可以准确地评估实例分割的质量，并且具有不间断的惩罚尺度，可以提供更加准确的质量评估结果。<details>
<summary>Abstract</summary>
Designing metrics for evaluating instance segmentation revolves around comprehensively considering object detection and segmentation accuracy. However, other important properties, such as sensitivity, continuity, and equality, are overlooked in the current study. In this paper, we reveal that most existing metrics have a limited resolution of segmentation quality. They are only conditionally sensitive to the change of masks or false predictions. For certain metrics, the score can change drastically in a narrow range which could provide a misleading indication of the quality gap between results. Therefore, we propose a new metric called sortedAP, which strictly decreases with both object- and pixel-level imperfections and has an uninterrupted penalization scale over the entire domain. We provide the evaluation toolkit and experiment code at https://www.github.com/looooongChen/sortedAP.
</details>
<details>
<summary>摘要</summary>
设计实例 segmentation 评价指标涉及全面考虑对象检测和分割精度。然而，现有的研究几乎忽略了其他重要特性，如敏感性、连续性和平等性。在这篇论文中，我们发现现有的指标有限制的分辨率。它们只是在某些指标下有限制的敏感，而且有一定的风险提供假的质量指标。因此，我们提出了一个新的指标called sortedAP，它在对象和像素级别的不足下坚持减少，并在整个领域上具有不间断的补偿幅度。我们在 GitHub 上提供了评价工具箱和实验代码，请参考 <https://www.github.com/looooongChen/sortedAP>。
</details></li>
</ul>
<hr>
<h2 id="AnyPose-Anytime-3D-Human-Pose-Forecasting-via-Neural-Ordinary-Differential-Equations"><a href="#AnyPose-Anytime-3D-Human-Pose-Forecasting-via-Neural-Ordinary-Differential-Equations" class="headerlink" title="AnyPose: Anytime 3D Human Pose Forecasting via Neural Ordinary Differential Equations"></a>AnyPose: Anytime 3D Human Pose Forecasting via Neural Ordinary Differential Equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04840">http://arxiv.org/abs/2309.04840</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zixing Wang, Ahmed H. Qureshi</li>
<li>for: 这篇研究目的是为了提出一个可靠的三维人体姿态预测方法，以便在实时人机交互中进行预测。</li>
<li>methods: 这篇研究使用了神经ordinary differential equation（Neural ODE）来建模人类行为动力学。</li>
<li>results: 研究结果显示，AnyPose方法在Human3.6M、AMASS和3DPW数据集上显示出高精度的未来姿态预测，并且比传统方法快得多个computational time。<details>
<summary>Abstract</summary>
Anytime 3D human pose forecasting is crucial to synchronous real-world human-machine interaction, where the term ``anytime" corresponds to predicting human pose at any real-valued time step. However, to the best of our knowledge, all the existing methods in human pose forecasting perform predictions at preset, discrete time intervals. Therefore, we introduce AnyPose, a lightweight continuous-time neural architecture that models human behavior dynamics with neural ordinary differential equations. We validate our framework on the Human3.6M, AMASS, and 3DPW dataset and conduct a series of comprehensive analyses towards comparison with existing methods and the intersection of human pose and neural ordinary differential equations. Our results demonstrate that AnyPose exhibits high-performance accuracy in predicting future poses and takes significantly lower computational time than traditional methods in solving anytime prediction tasks.
</details>
<details>
<summary>摘要</summary>
任何时刻3D人姿预测是实时人机交互中关键，其中“任何时刻”指的是预测人姿的任何实数时间步。然而，我们所知道的所有现有方法都是在固定、精确时间间隔进行预测。因此，我们介绍了AnyPose，一种轻量级连续时间神经网络架构，用于模elling人类行为动力学。我们验证了我们的框架在Human3.6M、AMASS和3DPW数据集上，并进行了一系列完整的分析，包括与现有方法进行比较和人姿和神经ordinary differential equations的交叠。我们的结果表明，AnyPose在预测未来姿势方面具有高精度性和较低的计算时间，与传统方法在实时预测任务中具有优势。
</details></li>
</ul>
<hr>
<h2 id="Neural-Semantic-Surface-Maps"><a href="#Neural-Semantic-Surface-Maps" class="headerlink" title="Neural Semantic Surface Maps"></a>Neural Semantic Surface Maps</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04836">http://arxiv.org/abs/2309.04836</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luca Morreale, Noam Aigerman, Vladimir G. Kim, Niloy J. Mitra</li>
<li>for: 生成两个 genus-zero 形的 semantic surface-to-surface 映射，即将 semantically 相应的区域匹配到另一个形上。</li>
<li>methods: 使用 pre-trained 视觉模型进行 Semantic Matching，并使用 off-the-shelf 图像匹配方法生成 feature points。</li>
<li>results: 可以生成 semantic surface-to-surface 映射，不需要任何 3D 训练数据或手动标注。方法可以在高semantic complexity 和 nearly isometric 情况下效果很好。<details>
<summary>Abstract</summary>
We present an automated technique for computing a map between two genus-zero shapes, which matches semantically corresponding regions to one another. Lack of annotated data prohibits direct inference of 3D semantic priors; instead, current State-of-the-art methods predominantly optimize geometric properties or require varying amounts of manual annotation. To overcome the lack of annotated training data, we distill semantic matches from pre-trained vision models: our method renders the pair of 3D shapes from multiple viewpoints; the resulting renders are then fed into an off-the-shelf image-matching method which leverages a pretrained visual model to produce feature points. This yields semantic correspondences, which can be projected back to the 3D shapes, producing a raw matching that is inaccurate and inconsistent between different viewpoints. These correspondences are refined and distilled into an inter-surface map by a dedicated optimization scheme, which promotes bijectivity and continuity of the output map. We illustrate that our approach can generate semantic surface-to-surface maps, eliminating manual annotations or any 3D training data requirement. Furthermore, it proves effective in scenarios with high semantic complexity, where objects are non-isometrically related, as well as in situations where they are nearly isometric.
</details>
<details>
<summary>摘要</summary>
Note:* "genus-zero shapes" refers to shapes without any holes or singularities.* "semantic priors" refer to the prior knowledge of the semantic meaning of the objects or regions in the scene.* "manual annotation" refers to the process of labeling the objects or regions in the scene with semantic information.* "pre-trained vision models" refer to deep learning models that have been trained on large datasets of images to learn features and patterns.* "image-matching method" refers to a technique that compares two images and finds the corresponding points between them.* "feature points" refer to the points in the image that have been identified as being semantically meaningful.* "bijection" refers to a one-to-one correspondence between two sets, which is important for ensuring that the output map is accurate and consistent.* "continuity" refers to the property of a function that has no gaps or jumps in its output.
</details></li>
</ul>
<hr>
<h2 id="Few-Shot-Medical-Image-Segmentation-via-a-Region-enhanced-Prototypical-Transformer"><a href="#Few-Shot-Medical-Image-Segmentation-via-a-Region-enhanced-Prototypical-Transformer" class="headerlink" title="Few-Shot Medical Image Segmentation via a Region-enhanced Prototypical Transformer"></a>Few-Shot Medical Image Segmentation via a Region-enhanced Prototypical Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04825">http://arxiv.org/abs/2309.04825</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yazhouzhu19/rpt">https://github.com/yazhouzhu19/rpt</a></li>
<li>paper_authors: Yazhou Zhu, Shidong Wang, Tong Xin, Haofeng Zhang</li>
<li>for: 这篇论文是为了解决医疗图像分类 tasks 中的问题，特别是对于大量医疗图像的自动分类。</li>
<li>methods: 本篇论文使用了一种名为 Region-enhanced Prototypical Transformer (RPT) 的方法，这是一种基于几个支持像的学习方法，它可以对于不同的测试案例进行几个 shot 的学习。</li>
<li>results: 在三个公开的医疗图像数据集上进行了广泛的实验，结果显示 RPT 方法可以对于 Few-Shot Medical Image Segmentation (FSMS)  tasks 提供更好的性能，与现有的方法相比，具有更好的准确性和稳定性。<details>
<summary>Abstract</summary>
Automated segmentation of large volumes of medical images is often plagued by the limited availability of fully annotated data and the diversity of organ surface properties resulting from the use of different acquisition protocols for different patients. In this paper, we introduce a more promising few-shot learning-based method named Region-enhanced Prototypical Transformer (RPT) to mitigate the effects of large intra-class diversity/bias. First, a subdivision strategy is introduced to produce a collection of regional prototypes from the foreground of the support prototype. Second, a self-selection mechanism is proposed to incorporate into the Bias-alleviated Transformer (BaT) block to suppress or remove interferences present in the query prototype and regional support prototypes. By stacking BaT blocks, the proposed RPT can iteratively optimize the generated regional prototypes and finally produce rectified and more accurate global prototypes for Few-Shot Medical Image Segmentation (FSMS). Extensive experiments are conducted on three publicly available medical image datasets, and the obtained results show consistent improvements compared to state-of-the-art FSMS methods. The source code is available at: https://github.com/YazhouZhu19/RPT.
</details>
<details>
<summary>摘要</summary>
自动化分割大量医疗图像的问题 frequently 受到完全标注数据的有限性和不同患者的获取协议所导致的组织表面性的多样性的影响。在这篇论文中，我们介绍了一种更有前途的几拟学学习基于方法，名为区域增强的原型变换器（RPT），以降低大型内类多样性/偏见的影响。首先，我们提出了一种分区策略，以生成支持原型的分区原型集。其次，我们提出了一种自选机制，以吸收或移除在支持原型和区域支持原型中的干扰。通过堆叠 BaT 块，我们的 RPT 可以Iteratively 优化生成的区域原型，并最终生成修正和更准确的全局原型，为几拟学医疗图像分割（FSMS）提供了更好的结果。我们在三个公开的医疗图像数据集上进行了广泛的实验，并取得了与当前最佳 FSMS 方法相对的稳定性和可靠性。源代码可以在 GitHub 上找到：https://github.com/YazhouZhu19/RPT。
</details></li>
</ul>
<hr>
<h2 id="ABC-Easy-as-123-A-Blind-Counter-for-Exemplar-Free-Multi-Class-Class-agnostic-Counting"><a href="#ABC-Easy-as-123-A-Blind-Counter-for-Exemplar-Free-Multi-Class-Class-agnostic-Counting" class="headerlink" title="ABC Easy as 123: A Blind Counter for Exemplar-Free Multi-Class Class-agnostic Counting"></a>ABC Easy as 123: A Blind Counter for Exemplar-Free Multi-Class Class-agnostic Counting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04820">http://arxiv.org/abs/2309.04820</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael A. Hobley, Victor A. Prisacariu</li>
<li>for: 这篇论文的目的是提出一种多类、无类别 counting 方法，以解决现有方法在 COUNTING 任务中存在的限制。</li>
<li>methods: 该方法使用了一种新的概念，即在 COUNTING 阶段不需要使用类例进行导航，而是在计数后发现类例以帮助用户理解生成的输出。</li>
<li>results: 对于 MCAC 数据集，该方法可以与 Contemporary methods 相比，而无需人工循环注解。此外，该方法还在 FSC-147 数据集上实现了类似的性能。<details>
<summary>Abstract</summary>
Class-agnostic counting methods enumerate objects of an arbitrary class, providing tremendous utility in many fields. Prior works have limited usefulness as they require either a set of examples of the type to be counted or that the image contains only a single type of object. A significant factor in these shortcomings is the lack of a dataset to properly address counting in settings with more than one kind of object present. To address these issues, we propose the first Multi-class, Class-Agnostic Counting dataset (MCAC) and A Blind Counter (ABC123), a method that can count multiple types of objects simultaneously without using examples of type during training or inference. ABC123 introduces a new paradigm where instead of requiring exemplars to guide the enumeration, examples are found after the counting stage to help a user understand the generated outputs. We show that ABC123 outperforms contemporary methods on MCAC without the requirement of human in-the-loop annotations. We also show that this performance transfers to FSC-147, the standard class-agnostic counting dataset.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Class-agnostic counting methods enumerate objects of an arbitrary class, providing tremendous utility in many fields. Prior works have limited usefulness as they require either a set of examples of the type to be counted or that the image contains only a single type of object. A significant factor in these shortcomings is the lack of a dataset to properly address counting in settings with more than one kind of object present. To address these issues, we propose the first Multi-class, Class-Agnostic Counting dataset (MCAC) and A Blind Counter (ABC123), a method that can count multiple types of objects simultaneously without using examples of type during training or inference. ABC123 introduces a new paradigm where instead of requiring exemplars to guide the enumeration, examples are found after the counting stage to help a user understand the generated outputs. We show that ABC123 outperforms contemporary methods on MCAC without the requirement of human in-the-loop annotations. We also show that this performance transfers to FSC-147, the standard class-agnostic counting dataset."中文简体版：类型不扩知的统计方法可以对任意类型的对象进行枚举，提供了很多领域的巨大实用性。先前的方法具有有限的用途，因为它们需要 Either a set of examples of the type to be counted or that the image contains only a single type of object。这些缺点的一个重要因素是缺乏适用于多种对象存在的数据集，以正确地解决类型不扩知的统计问题。为解决这些问题，我们提出了首个多类、类型不扩知统计数据集（MCAC）和一种无需在训练或推理阶段使用类型示例的方法（ABC123）。ABC123引入了一新的思路，而不是需要 exemplars 来引导枚举，而是在统计阶段找到例子，以帮助用户理解生成的输出。我们表明，ABC123 在 MCAC 上超越了当前方法，而不需要人工循环注释。我们还表明，这种性能可以跨种类，并在标准的类型不扩知统计数据集 FSC-147 上进行验证。
</details></li>
</ul>
<hr>
<h2 id="Speech2Lip-High-fidelity-Speech-to-Lip-Generation-by-Learning-from-a-Short-Video"><a href="#Speech2Lip-High-fidelity-Speech-to-Lip-Generation-by-Learning-from-a-Short-Video" class="headerlink" title="Speech2Lip: High-fidelity Speech to Lip Generation by Learning from a Short Video"></a>Speech2Lip: High-fidelity Speech to Lip Generation by Learning from a Short Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04814">http://arxiv.org/abs/2309.04814</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiuzhe Wu, Pengfei Hu, Yang Wu, Xiaoyang Lyu, Yan-Pei Cao, Ying Shan, Wenming Yang, Zhongqian Sun, Xiaojuan Qi</li>
<li>for: 根据谈话生成自然看起来的动画，解决过去的问题包括不准确的唇形生成和底层的图像质量。</li>
<li>methods: 我们提出了一个构成-分解-重新组合框架（Speech2Lip），将谈话驱动的动作和外观分解为两个部分：谈话敏感的动作和谈话不敏感的动作。这使得我们可以从有限的训练数据中学习出自然的动画。</li>
<li>results: 我们的模型可以从几分钟的训练影片中学习出高品质的动画，并且在谈话与图像的同步性方面达到了顶尖的表现。<details>
<summary>Abstract</summary>
Synthesizing realistic videos according to a given speech is still an open challenge. Previous works have been plagued by issues such as inaccurate lip shape generation and poor image quality. The key reason is that only motions and appearances on limited facial areas (e.g., lip area) are mainly driven by the input speech. Therefore, directly learning a mapping function from speech to the entire head image is prone to ambiguity, particularly when using a short video for training. We thus propose a decomposition-synthesis-composition framework named Speech to Lip (Speech2Lip) that disentangles speech-sensitive and speech-insensitive motion/appearance to facilitate effective learning from limited training data, resulting in the generation of natural-looking videos. First, given a fixed head pose (i.e., canonical space), we present a speech-driven implicit model for lip image generation which concentrates on learning speech-sensitive motion and appearance. Next, to model the major speech-insensitive motion (i.e., head movement), we introduce a geometry-aware mutual explicit mapping (GAMEM) module that establishes geometric mappings between different head poses. This allows us to paste generated lip images at the canonical space onto head images with arbitrary poses and synthesize talking videos with natural head movements. In addition, a Blend-Net and a contrastive sync loss are introduced to enhance the overall synthesis performance. Quantitative and qualitative results on three benchmarks demonstrate that our model can be trained by a video of just a few minutes in length and achieve state-of-the-art performance in both visual quality and speech-visual synchronization. Code: https://github.com/CVMI-Lab/Speech2Lip.
</details>
<details>
<summary>摘要</summary>
Synthesizing realistic videos according to given speech is still an open challenge. Previous works have been plagued by issues such as inaccurate lip shape generation and poor image quality. The key reason is that only motions and appearances on limited facial areas (e.g., lip area) are mainly driven by the input speech. Therefore, directly learning a mapping function from speech to the entire head image is prone to ambiguity, particularly when using a short video for training. We thus propose a decomposition-synthesis-composition framework named Speech to Lip (Speech2Lip) that disentangles speech-sensitive and speech-insensitive motion/appearance to facilitate effective learning from limited training data, resulting in the generation of natural-looking videos. First, given a fixed head pose (i.e., canonical space), we present a speech-driven implicit model for lip image generation which concentrates on learning speech-sensitive motion and appearance. Next, to model the major speech-insensitive motion (i.e., head movement), we introduce a geometry-aware mutual explicit mapping (GAMEM) module that establishes geometric mappings between different head poses. This allows us to paste generated lip images at the canonical space onto head images with arbitrary poses and synthesize talking videos with natural head movements. In addition, a Blend-Net and a contrastive sync loss are introduced to enhance the overall synthesis performance. Quantitative and qualitative results on three benchmarks demonstrate that our model can be trained by a video of just a few minutes in length and achieve state-of-the-art performance in both visual quality and speech-visual synchronization. Code: <https://github.com/CVMI-Lab/Speech2Lip>.
</details></li>
</ul>
<hr>
<h2 id="VeRi3D-Generative-Vertex-based-Radiance-Fields-for-3D-Controllable-Human-Image-Synthesis"><a href="#VeRi3D-Generative-Vertex-based-Radiance-Fields-for-3D-Controllable-Human-Image-Synthesis" class="headerlink" title="VeRi3D: Generative Vertex-based Radiance Fields for 3D Controllable Human Image Synthesis"></a>VeRi3D: Generative Vertex-based Radiance Fields for 3D Controllable Human Image Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04800">http://arxiv.org/abs/2309.04800</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinya Chen, Jiaxin Huang, Yanrui Bin, Lu Yu, Yiyi Liao</li>
<li>for: 生成高质量人体图像，包括自然的姿势和形态变化。</li>
<li>methods: 使用神经网络学习 vertex-based radiance field， Parametric human template SMPL 进行 parameterization。</li>
<li>results: 可以生成高品质的人体图像，并且可以自由控制摄像机姿势、人姿势、形态变化以及部分编辑。<details>
<summary>Abstract</summary>
Unsupervised learning of 3D-aware generative adversarial networks has lately made much progress. Some recent work demonstrates promising results of learning human generative models using neural articulated radiance fields, yet their generalization ability and controllability lag behind parametric human models, i.e., they do not perform well when generalizing to novel pose/shape and are not part controllable. To solve these problems, we propose VeRi3D, a generative human vertex-based radiance field parameterized by vertices of the parametric human template, SMPL. We map each 3D point to the local coordinate system defined on its neighboring vertices, and use the corresponding vertex feature and local coordinates for mapping it to color and density values. We demonstrate that our simple approach allows for generating photorealistic human images with free control over camera pose, human pose, shape, as well as enabling part-level editing.
</details>
<details>
<summary>摘要</summary>
Recently, there has been significant progress in unsupervised learning of 3D-aware generative adversarial networks. Some recent work has shown promising results in learning human generative models using neural articulated radiance fields, but their generalization ability and controllability are still limited, such as difficulty in generalizing to novel pose/shape and lack of part controllability. To address these issues, we propose VeRi3D, a generative human vertex-based radiance field parameterized by the vertices of the parametric human template, SMPL. We map each 3D point to the local coordinate system defined on its neighboring vertices, and use the corresponding vertex feature and local coordinates to map it to color and density values. Our simple approach enables the generation of photorealistic human images with free control over camera pose, human pose, shape, as well as part-level editing.
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Transformer-with-Domain-Adaptive-Reconstruction-for-General-Face-Forgery-Video-Detection"><a href="#Self-Supervised-Transformer-with-Domain-Adaptive-Reconstruction-for-General-Face-Forgery-Video-Detection" class="headerlink" title="Self-Supervised Transformer with Domain Adaptive Reconstruction for General Face Forgery Video Detection"></a>Self-Supervised Transformer with Domain Adaptive Reconstruction for General Face Forgery Video Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04795">http://arxiv.org/abs/2309.04795</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daichi Zhang, Zihao Xiao, Jianmin Li, Shiming Ge</li>
<li>for: 本研究旨在提高违伪面影片检测效果，尤其是在不同的违伪方法或真实源影片下进行检测时。</li>
<li>methods: 本研究提出了一种基于自动编码器和对比学习的Self-supervised Transformer，并在 fine-tuning 过程中添加了两种辅助任务，即对比学习和重建学习。此外，还提出了一种适应域重建模块，用于在不同违伪频谱上进行适应。</li>
<li>results: 经验表明，提出的方法在公共数据集上进行测试时，能够与现有的超级vised竞争对手相比，并且具有很好的泛化性。<details>
<summary>Abstract</summary>
Face forgery videos have caused severe social public concern, and various detectors have been proposed recently. However, most of them are trained in a supervised manner with limited generalization when detecting videos from different forgery methods or real source videos. To tackle this issue, we explore to take full advantage of the difference between real and forgery videos by only exploring the common representation of real face videos. In this paper, a Self-supervised Transformer cooperating with Contrastive and Reconstruction learning (CoReST) is proposed, which is first pre-trained only on real face videos in a self-supervised manner, and then fine-tuned a linear head on specific face forgery video datasets. Two specific auxiliary tasks incorporated contrastive and reconstruction learning are designed to enhance the representation learning. Furthermore, a Domain Adaptive Reconstruction (DAR) module is introduced to bridge the gap between different forgery domains by reconstructing on unlabeled target videos when fine-tuning. Extensive experiments on public datasets demonstrate that our proposed method performs even better than the state-of-the-art supervised competitors with impressive generalization.
</details>
<details>
<summary>摘要</summary>
《Face forgery videos have caused severe social public concern, and various detectors have been proposed recently. However, most of them are trained in a supervised manner with limited generalization when detecting videos from different forgery methods or real source videos. To tackle this issue, we explore taking full advantage of the difference between real and forgery videos by only exploring the common representation of real face videos. In this paper, a Self-supervised Transformer cooperating with Contrastive and Reconstruction learning (CoReST) is proposed, which is first pre-trained only on real face videos in a self-supervised manner, and then fine-tuned a linear head on specific face forgery video datasets. Two specific auxiliary tasks incorporated contrastive and reconstruction learning are designed to enhance the representation learning. Furthermore, a Domain Adaptive Reconstruction (DAR) module is introduced to bridge the gap between different forgery domains by reconstructing on unlabeled target videos when fine-tuning. Extensive experiments on public datasets demonstrate that our proposed method performs even better than the state-of-the-art supervised competitors with impressive generalization.》Here's the word-for-word translation:《人脸伪造视频引起了严重的社会公众关注，而最近有许多检测器被提出。然而，大多数检测器都是在有监督的方式进行训练，其检测视频的能力受到不同的伪造方法或原始视频的限制。为了解决这个问题，我们尝试了利用真实视频中的差异，并且只探索真实视频的共同表示。在这篇论文中，我们提出了一种基于自助学习的 transformer 和对比学习（CoReST），它首先在真实视频上进行自助学习，然后在特定的伪造视频数据集上进行细致的调整。为了增强表示学习，我们采用了两种特定的辅助任务：对比学习和重构学习。此外，我们还提出了一种适应域重构（DAR）模块，用于在不同的伪造领域之间桥接。在公共数据集上进行了广泛的实验，结果表明，我们的提出的方法能够在充分扩展的情况下，与当前最佳监督者进行比较，并且表现出色。》
</details></li>
</ul>
<hr>
<h2 id="Latent-Degradation-Representation-Constraint-for-Single-Image-Deraining"><a href="#Latent-Degradation-Representation-Constraint-for-Single-Image-Deraining" class="headerlink" title="Latent Degradation Representation Constraint for Single Image Deraining"></a>Latent Degradation Representation Constraint for Single Image Deraining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04780">http://arxiv.org/abs/2309.04780</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhong He, Long Peng, Lu Wang, Jun Cheng</li>
<li>for: 本研究旨在提出一种新的单图排除雨水模型，以解决现有方法难以学习雨水干扰的问题。</li>
<li>methods: 该模型包括指向感知编码器（DAEncoder）、UNet排除网络和多尺度交互块（MSIBlock）。DAEncoder使用可变扩散捕捉雨水束的方向一致性，适应地抽取雨水干扰表示。然后，在训练中引入约束损失来显式地约束干扰表示学习。最后，我们提出了MSIBlock，用于与学习的干扰表示和排除网络的解码特征进行 adaptive 信息互动，以便使排除网络能够消除各种复杂的雨水束和重建图像细节。</li>
<li>results: 实验结果表明，我们的方法在 sintetic 和实际数据集上达到了新的州OF-the-art 性能。<details>
<summary>Abstract</summary>
Since rain streaks show a variety of shapes and directions, learning the degradation representation is extremely challenging for single image deraining. Existing methods are mainly targeted at designing complicated modules to implicitly learn latent degradation representation from coupled rainy images. This way, it is hard to decouple the content-independent degradation representation due to the lack of explicit constraint, resulting in over- or under-enhancement problems. To tackle this issue, we propose a novel Latent Degradation Representation Constraint Network (LDRCNet) that consists of Direction-Aware Encoder (DAEncoder), UNet Deraining Network, and Multi-Scale Interaction Block (MSIBlock). Specifically, the DAEncoder is proposed to adaptively extract latent degradation representation by using the deformable convolutions to exploit the direction consistency of rain streaks. Next, a constraint loss is introduced to explicitly constraint the degradation representation learning during training. Last, we propose an MSIBlock to fuse with the learned degradation representation and decoder features of the deraining network for adaptive information interaction, which enables the deraining network to remove various complicated rainy patterns and reconstruct image details. Experimental results on synthetic and real datasets demonstrate that our method achieves new state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
因为雨条状态呈多种形状和方向，单一图像净化很难学习降低表现的表现。现有方法主要是通过设计复杂的模组来隐式地学习隐藏的降低表现征象，这样很难分离内容独立的降低表现，从而导致过弹或者下弹问题。为解决这个问题，我们提出了一个新的内容独立降低表现条件网络（LDRCNet），它包括了方向感应编码器（DAEncoder）、UNet净化网络和多尺度互动对（MSIBlock）。具体来说，DAEncoder可以透过使用可整合的梯度感应来适应地抽出降低表现的内容独立表现。接着，我们引入了一个约束损失来规范降低表现学习的过程中。最后，我们提出了一个MSIBlock，用于与学习的降低表现和净化网络的解码特征进行互动运算，这使得净化网络能够根据不同的雨条状态和内容独立的降低表现来移除各种复杂的雨条状态和重建图像细节。实验结果显示，我们的方法在synthetic和real dataset上取得了新的顶峰性能。
</details></li>
</ul>
<hr>
<h2 id="Visual-Material-Characteristics-Learning-for-Circular-Healthcare"><a href="#Visual-Material-Characteristics-Learning-for-Circular-Healthcare" class="headerlink" title="Visual Material Characteristics Learning for Circular Healthcare"></a>Visual Material Characteristics Learning for Circular Healthcare</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04763">http://arxiv.org/abs/2309.04763</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fedezocco/matvisiongluinh-pytorch_tensorflow">https://github.com/fedezocco/matvisiongluinh-pytorch_tensorflow</a></li>
<li>paper_authors: Federico Zocco, Shahin Rahimifard</li>
<li>for: 增强医疗垃圾回收链，提高医疗垃圾的再利用率。</li>
<li>methods: 开发了多种视力系统，用于三个主要循环经济任务：资源映射和量化、垃圾分类、和分解。</li>
<li>results: 研究表明，使用表征学视觉技术可以提高回收链的性能，自动化系统是关键因素，因为受污染风险。两个完全注释化数据集也公开发布，用于图像分割和逻辑点跟踪在医疗器械分解过程中。<details>
<summary>Abstract</summary>
The linear take-make-dispose paradigm at the foundations of our traditional economy is proving to be unsustainable due to waste pollution and material supply uncertainties. Hence, increasing the circularity of material flows is necessary. In this paper, we make a step towards circular healthcare by developing several vision systems targeting three main circular economy tasks: resources mapping and quantification, waste sorting, and disassembly. The performance of our systems demonstrates that representation-learning vision can improve the recovery chain, where autonomous systems are key enablers due to the contamination risks. We also published two fully-annotated datasets for image segmentation and for key-point tracking in disassembly operations of inhalers and glucose meters. The datasets and source code are publicly available.
</details>
<details>
<summary>摘要</summary>
传统经济的线性“取-制造-废弃”模式已经显示无法维持可持续发展，由废弃污染和材料供应不确定性而导致。因此，提高物流循环性是必要的。在这篇论文中，我们向循环医疗领域发展了多种视系统，目标是三大循环经济任务：资源映射和评估、废弃分类和分解。我们的系统表现了使用表征学视觉技术可以提高回收链，自主系统作为污染风险的关键启用者。我们还发布了两个完全注释的数据集，一个是图像分割数据集，另一个是关键点跟踪在分解医疗器械和糖尿病测量仪器的数据集。这两个数据集和源代码都公开可用。
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-Triangulation-for-Uncalibrated-Multi-View-3D-Human-Pose-Estimation"><a href="#Probabilistic-Triangulation-for-Uncalibrated-Multi-View-3D-Human-Pose-Estimation" class="headerlink" title="Probabilistic Triangulation for Uncalibrated Multi-View 3D Human Pose Estimation"></a>Probabilistic Triangulation for Uncalibrated Multi-View 3D Human Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04756">http://arxiv.org/abs/2309.04756</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bymaths/probabilistic_triangulation">https://github.com/bymaths/probabilistic_triangulation</a></li>
<li>paper_authors: Boyuan Jiang, Lei Hu, Shihong Xia</li>
<li>for: 本研究旨在提出一种可靠的三维人体 pose 估计方法，以替代现有的固定摄像机pose 方法，提高 pose 估计的泛化能力。</li>
<li>methods: 本方法基于 probablistic triangulation 模块，通过 iteratively 更新摄像机pose 分布，从 2D 特征点计算 posterior 概率，以直接卷积 backwards 传播 gradients，实现 end-to-end 训练。</li>
<li>results: 对 Human3.6M 和 CMU Panoptic 数据集进行了广泛的实验，比较了与其他不准确方法和准确方法进行比较，显示了我们的方法可以达到更高的泛化性和更高的估计精度之间的让步。<details>
<summary>Abstract</summary>
3D human pose estimation has been a long-standing challenge in computer vision and graphics, where multi-view methods have significantly progressed but are limited by the tedious calibration processes. Existing multi-view methods are restricted to fixed camera pose and therefore lack generalization ability. This paper presents a novel Probabilistic Triangulation module that can be embedded in a calibrated 3D human pose estimation method, generalizing it to uncalibration scenes. The key idea is to use a probability distribution to model the camera pose and iteratively update the distribution from 2D features instead of using camera pose. Specifically, We maintain a camera pose distribution and then iteratively update this distribution by computing the posterior probability of the camera pose through Monte Carlo sampling. This way, the gradients can be directly back-propagated from the 3D pose estimation to the 2D heatmap, enabling end-to-end training. Extensive experiments on Human3.6M and CMU Panoptic demonstrate that our method outperforms other uncalibration methods and achieves comparable results with state-of-the-art calibration methods. Thus, our method achieves a trade-off between estimation accuracy and generalizability. Our code is in https://github.com/bymaths/probabilistic_triangulation
</details>
<details>
<summary>摘要</summary>
三维人体姿态估算已经是计算机视觉和图形领域的长期挑战，多视图方法在这一点上已经取得了 significativement progress，但它们受到了繁琐的卡利ibration过程的限制。现有的多视图方法受到固定相机pose的限制，因此缺乏总体化能力。这篇论文提出了一种新的概率三角形模块，可以在卡利ibration场景下插入到已经卡利ibration的三维人体姿态估算方法中，并且可以提高其总体化能力。我们的关键想法是使用概率分布来模型相机pose，并且在每次迭代中更新这个分布，从2D特征上计算后验概率。具体来说，我们保持一个相机pose分布，然后在每次迭代中使用蒙地卡ろ sampling算法来更新这个分布。这样，可以直接从3D姿态估算中传递梯度到2D热图中，实现端到端训练。我们在Human3.6M和CMU Panoptic等数据集上进行了广泛的实验，结果表明，我们的方法在不卡利ibration场景下表现出比其他无卡利ibration方法更好的性能，并且与卡利ibration方法相当的性能。因此，我们的方法实现了姿态估算精度和总体化之间的交换。我们的代码在https://github.com/bymaths/probabilistic_triangulation中。
</details></li>
</ul>
<hr>
<h2 id="Deep-Video-Restoration-for-Under-Display-Camera"><a href="#Deep-Video-Restoration-for-Under-Display-Camera" class="headerlink" title="Deep Video Restoration for Under-Display Camera"></a>Deep Video Restoration for Under-Display Camera</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04752">http://arxiv.org/abs/2309.04752</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuanxi Chen, Tao Wang, Ziqian Shao, Kaihao Zhang, Wenhan Luo, Tong Lu, Zikun Liu, Tae-Kyun Kim, Hongdong Li</li>
<li>For: 这个论文主要针对的是Under-Display Camera（UDC）视频修复（UDC-VR）问题，而现有的UDC修复方法仅专注于图像。* Methods: 这篇论文首先提出了基于GAN生成器的生成管线，用于模拟真实的UDC降低过程。然后，他们建立了大规模的UDC视频修复数据集named PexelsUDC，包括两个子集named PexelsUDC-T和PexelsUDC-P，这两个子集分别对应不同的显示器。* Results: 使用提出的数据集和基线方法，论文进行了广泛的比较研究，发现现有的视频修复方法在UDC-VR任务上存在局限性。然后，他们提出了一种基于 transformer 的新基eline方法，该方法可以充分利用视频的空间和时间信息来修复降低的视频。广泛的实验表明，该方法在 PexelsUDC 上达到了状态级表现。<details>
<summary>Abstract</summary>
Images or videos captured by the Under-Display Camera (UDC) suffer from severe degradation, such as saturation degeneration and color shift. While restoration for UDC has been a critical task, existing works of UDC restoration focus only on images. UDC video restoration (UDC-VR) has not been explored in the community. In this work, we first propose a GAN-based generation pipeline to simulate the realistic UDC degradation process. With the pipeline, we build the first large-scale UDC video restoration dataset called PexelsUDC, which includes two subsets named PexelsUDC-T and PexelsUDC-P corresponding to different displays for UDC. Using the proposed dataset, we conduct extensive benchmark studies on existing video restoration methods and observe their limitations on the UDC-VR task. To this end, we propose a novel transformer-based baseline method that adaptively enhances degraded videos. The key components of the method are a spatial branch with local-aware transformers, a temporal branch embedded temporal transformers, and a spatial-temporal fusion module. These components drive the model to fully exploit spatial and temporal information for UDC-VR. Extensive experiments show that our method achieves state-of-the-art performance on PexelsUDC. The benchmark and the baseline method are expected to promote the progress of UDC-VR in the community, which will be made public.
</details>
<details>
<summary>摘要</summary>
“图像或视频捕捉于下层显示摄像头（UDC）会受到严重的降解效应，如饱和衰减和颜色偏移。而现有的UDC还原方法仅专注于图像还原，UDC视频还原（UDC-VR）尚未在社区中得到探索。在这项工作中，我们首先提出了基于GAN的生成管道，用于模拟真实的UDC降解过程。通过管道，我们建立了首个大规模的UDC视频还原数据集named PexelsUDC，该数据集包括两个子集名为 PexelsUDC-T 和 PexelsUDC-P，分别对应不同的显示器 для UDC。使用我们提posed的数据集，我们进行了广泛的比较研究，发现现有的视频还原方法在UDC-VR任务上存在局限性。为此，我们提出了一种基于 transformer 的基eline方法，该方法可以在不同的显示器上进行自适应增强降解视频。该方法的关键组件包括空间分支、本地化 transformers、嵌入时间 transformers 和空间-时间融合模块。这些组件使得模型能够充分利用空间和时间信息进行UDC-VR。广泛的实验表明，我们的方法在 PexelsUDC 上达到了状态的最佳性能。数据集和基线方法将被公开，以促进社区中 UDC-VR 的进步。”
</details></li>
</ul>
<hr>
<h2 id="Mirror-Aware-Neural-Humans"><a href="#Mirror-Aware-Neural-Humans" class="headerlink" title="Mirror-Aware Neural Humans"></a>Mirror-Aware Neural Humans</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04750">http://arxiv.org/abs/2309.04750</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Ajisafe, James Tang, Shih-Yang Su, Bastian Wandt, Helge Rhodin</li>
<li>for: 实现基于单个摄像头的高质量人体动作捕捉系统，解决多视图系统和单视图系统的缺点。</li>
<li>methods: 使用镜子来记录两个视图，并利用镜子来学习人体完整的形状和精密的外观特征。</li>
<li>results: 实现了一个可靠地从Off-the-shelf 2D姿势获取3Dskeleton姿势，并且在镜子场景中处理 occlusion 问题，提高了系统的可靠性和精度。<details>
<summary>Abstract</summary>
Human motion capture either requires multi-camera systems or is unreliable using single-view input due to depth ambiguities. Meanwhile, mirrors are readily available in urban environments and form an affordable alternative by recording two views with only a single camera. However, the mirror setting poses the additional challenge of handling occlusions of real and mirror image. Going beyond existing mirror approaches for 3D human pose estimation, we utilize mirrors for learning a complete body model, including shape and dense appearance. Our main contributions are extending articulated neural radiance fields to include a notion of a mirror, making it sample-efficient over potential occlusion regions. Together, our contributions realize a consumer-level 3D motion capture system that starts from off-the-shelf 2D poses by automatically calibrating the camera, estimating mirror orientation, and subsequently lifting 2D keypoint detections to 3D skeleton pose that is used to condition the mirror-aware NeRF. We empirically demonstrate the benefit of learning a body model and accounting for occlusion in challenging mirror scenes.
</details>
<details>
<summary>摘要</summary>
人体运动捕捉 either需要多个摄像头系统或者因为深度 ambiguity 导致单视输入不可靠。然而，镜子在城市环境中ready available 并且成为一种可靠的替代方案，只需要一个单个摄像头来记录两个视图。然而，镜子设置增加了处理真实和镜像干扰的挑战。我们超越现有的镜子方法 для 3D人体 pose estimation，我们利用镜子来学习完整的身体模型，包括形状和精密的外观。我们的主要贡献是将 articulated neural radiance fields 扩展到包括镜子的概念，使其在潜在干扰区域上更加效率。在一起，我们的贡献实现了一个消费级3D运动捕捉系统，它可以从OFF-THE-SHELF 2Dpose开始，自动调整摄像头，估算镜子方向，并将2D键点检测提升到3D骨骼姿势，该姿势用于condition mirror-aware NeRF。我们实际示出了学习身体模型和考虑干扰的好处在具有挑战的镜子场景中。
</details></li>
</ul>
<hr>
<h2 id="When-to-Learn-What-Model-Adaptive-Data-Augmentation-Curriculum"><a href="#When-to-Learn-What-Model-Adaptive-Data-Augmentation-Curriculum" class="headerlink" title="When to Learn What: Model-Adaptive Data Augmentation Curriculum"></a>When to Learn What: Model-Adaptive Data Augmentation Curriculum</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04747">http://arxiv.org/abs/2309.04747</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengkai Hou, Jieyu Zhang, Tianyi Zhou</li>
<li>for: 提高神经网络的通用性，通过强制实施输入数据中的一系列固定变换来实现数据增强。</li>
<li>methods: 提出了一种名为 Model Adaptive Data Augmentation (MADAug) 的方法，该方法通过在不同训练阶段选择不同的数据增强操作符来适应每个输入图像，从而生成一个数据增强课程优化了模型的泛化性。</li>
<li>results: 对多个图像分类任务和网络架构进行了广泛的评估，与现有的数据增强方法进行了互相比较，并表明 MADAug 可以在所有类型上提供更好的性能，并且在难度更高的类型上提供更大的改进。此外，MADAug 学习的策略在细化数据上表现更好，并自然地生成了一个易于难度增加的学习课程。<details>
<summary>Abstract</summary>
Data augmentation (DA) is widely used to improve the generalization of neural networks by enforcing the invariances and symmetries to pre-defined transformations applied to input data. However, a fixed augmentation policy may have different effects on each sample in different training stages but existing approaches cannot adjust the policy to be adaptive to each sample and the training model. In this paper, we propose Model Adaptive Data Augmentation (MADAug) that jointly trains an augmentation policy network to teach the model when to learn what. Unlike previous work, MADAug selects augmentation operators for each input image by a model-adaptive policy varying between training stages, producing a data augmentation curriculum optimized for better generalization. In MADAug, we train the policy through a bi-level optimization scheme, which aims to minimize a validation-set loss of a model trained using the policy-produced data augmentations. We conduct an extensive evaluation of MADAug on multiple image classification tasks and network architectures with thorough comparisons to existing DA approaches. MADAug outperforms or is on par with other baselines and exhibits better fairness: it brings improvement to all classes and more to the difficult ones. Moreover, MADAug learned policy shows better performance when transferred to fine-grained datasets. In addition, the auto-optimized policy in MADAug gradually introduces increasing perturbations and naturally forms an easy-to-hard curriculum.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate the following text into Simplified Chinese<</SYS>>数据扩充（DA）广泛应用于神经网络中以提高模型通用性，通过强制数据中的不变性和对称性。然而，现有的方法无法适应每个样本和训练阶段的不同效果，它们的固定扩充策略可能会导致模型的不平衡。在这篇论文中，我们提出了模型适应性数据扩充（MADAug），它将在训练过程中同时训练扩充策略网络，以教导模型何时学习什么。与之前的方法不同，MADAug在每个输入图像上选择的扩充运算符会随训练阶段而变化，生成一个适应性优化的数据扩充课程，以提高模型的通用性。在MADAug中，我们通过两级优化算法，即目标函数优化和权重优化，以iminimize一个验证集损失函数，以训练扩充策略网络。我们进行了多种图像分类任务和网络架构的广泛评估，并进行了对现有DA方法的比较。MADAug在多个任务上具有优于或与其他基elines一样的性能，并且展现出更好的公平性：它对所有类别都带来改进，并对难类更多。此外，MADAug学习的策略表现更好，当 transferred to 细化数据集时。此外，MADAug自动优化的策略逐渐增加干扰量，自然地形成一个易于困难的课程。Note: "Simplified Chinese" is used to refer to the written form of Chinese that uses simpler characters and grammar compared to Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Frequency-Aware-Self-Supervised-Long-Tailed-Learning"><a href="#Frequency-Aware-Self-Supervised-Long-Tailed-Learning" class="headerlink" title="Frequency-Aware Self-Supervised Long-Tailed Learning"></a>Frequency-Aware Self-Supervised Long-Tailed Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04723">http://arxiv.org/abs/2309.04723</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ci-Siang Lin, Min-Hung Chen, Yu-Chiang Frank Wang</li>
<li>for: 本研究旨在 Addressing the challenges of long-tailed data distributions in real-world scenarios, where label annotation may not be available.</li>
<li>methods: 方法方面, the paper proposes Frequency-Aware Self-Supervised Learning (FASSL), which learns discriminative feature representations from unlabeled data with inherent long-tailed distributions. The approach involves learning frequency-aware prototypes and exploiting the relationships between image data and the derived prototypes using a self-supervised learning scheme.</li>
<li>results: 实验结果表明, FASSL 可以有效地学习从无标签数据中，并且可以提供高质量的特征表示。 experiments on long-tailed image datasets demonstrate the effectiveness of the proposed approach.<details>
<summary>Abstract</summary>
Data collected from the real world typically exhibit long-tailed distributions, where frequent classes contain abundant data while rare ones have only a limited number of samples. While existing supervised learning approaches have been proposed to tackle such data imbalance, the requirement of label supervision would limit their applicability to real-world scenarios in which label annotation might not be available. Without the access to class labels nor the associated class frequencies, we propose Frequency-Aware Self-Supervised Learning (FASSL) in this paper. Targeting at learning from unlabeled data with inherent long-tailed distributions, the goal of FASSL is to produce discriminative feature representations for downstream classification tasks. In FASSL, we first learn frequency-aware prototypes, reflecting the associated long-tailed distribution. Particularly focusing on rare-class samples, the relationships between image data and the derived prototypes are further exploited with the introduced self-supervised learning scheme. Experiments on long-tailed image datasets quantitatively and qualitatively verify the effectiveness of our learning scheme.
</details>
<details>
<summary>摘要</summary>
通常来说，实际世界中的数据都会展现长尾分布，其中常见的类别具有丰富的数据，而罕见的类别则只有有限的样本。现有的超级vised学习方法可以解决数据不均衡问题，但是它们需要 labels 的存在，这限制了它们在真实世界中的应用。在这篇文章中，我们提出了不需要 labels 的自动学习方法，即频率意识自我超级学习（FASSL）。我们的目标是从无标签数据中学习具有抑制力的特征表示，以便在下游分类任务中使用。在 FASSL 中，我们首先学习频率意识的原型，这些原型反映了相应的长尾分布。特别是关注罕见类别的样本，我们通过引入的自我超级学习方案来利用这些样本和 derivated 的原型之间的关系。实验表明，我们的学习方法在长尾图像 dataset 上具有较高的效果。
</details></li>
</ul>
<hr>
<h2 id="UnitModule-A-Lightweight-Joint-Image-Enhancement-Module-for-Underwater-Object-Detection"><a href="#UnitModule-A-Lightweight-Joint-Image-Enhancement-Module-for-Underwater-Object-Detection" class="headerlink" title="UnitModule: A Lightweight Joint Image Enhancement Module for Underwater Object Detection"></a>UnitModule: A Lightweight Joint Image Enhancement Module for Underwater Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04708">http://arxiv.org/abs/2309.04708</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuoyan Liu, Bo Wang, Ye Li, Jiaxian He, Yunfeng Li<br>for: 提高对水下物体检测模型的输入图像质量，以提高检测效果。methods: 提出了一种可插入式的水下共同图像增强模块（UnitModule），通过对 UnitModule 和检测器进行无监督学习，以提高UnitModule 和检测器之间的交互。此外，还提出了一种预测颜色偏见的方法，以及一种叫做水下随机颜色传播（UCRT）的数据增强技术。results: 对 DUO  dataset 进行了广泛的实验，并取得了最高改进率的 2.6 AP 以及新测试集（URPCtest）上的改进率为 3.3 AP。 UnitModule 可以提高所有测试模型的性能，特别是具有较少参数的模型。此外，UnitModule 的参数量只有 31K，对原始检测模型的执行速度没有明显的影响。我们的量化和视觉分析也证明了 UnitModule 可以有效地提高输入图像质量和检测器对对象特征的识别能力。<details>
<summary>Abstract</summary>
Underwater object detection faces the problem of underwater image degradation, which affects the performance of the detector. Underwater object detection methods based on noise reduction and image enhancement usually do not provide images preferred by the detector or require additional datasets. In this paper, we propose a plug-and-play Underwater joint image enhancement Module (UnitModule) that provides the input image preferred by the detector. We design an unsupervised learning loss for the joint training of UnitModule with the detector without additional datasets to improve the interaction between UnitModule and the detector. Furthermore, a color cast predictor with the assisting color cast loss and a data augmentation called Underwater Color Random Transfer (UCRT) are designed to improve the performance of UnitModule on underwater images with different color casts. Extensive experiments are conducted on DUO for different object detection models, where UnitModule achieves the highest performance improvement of 2.6 AP for YOLOv5-S and gains the improvement of 3.3 AP on the brand-new test set (URPCtest). And UnitModule significantly improves the performance of all object detection models we test, especially for models with a small number of parameters. In addition, UnitModule with a small number of parameters of 31K has little effect on the inference speed of the original object detection model. Our quantitative and visual analysis also demonstrates the effectiveness of UnitModule in enhancing the input image and improving the perception ability of the detector for object features.
</details>
<details>
<summary>摘要</summary>
水下物体检测面临着水下图像弱化问题，这会影响检测器的性能。通常的水下物体检测方法通过减少噪声和图像提高不提供检测器所需的图像，或者需要额外数据集。在这篇论文中，我们提出了一个卷积核Module（UnitModule），它提供了检测器所需的输入图像。我们设计了一个不supervised学习损失，以joint地训练UnitModule和检测器，从而改善UnitModule和检测器之间的交互。此外，我们还设计了一个帮助预测颜色折射的颜色预测器，以及一种叫做水下随机传播（UCRT）的数据增强技术，以提高UnitModule在不同颜色折射下的性能。我们在DUO上进行了广泛的实验，其中UnitModule在不同的物体检测模型上达到了最高的性能提升2.6AP，并在新的测试集（URPCtest）上提升3.3AP。此外，UnitModule对所有物体检测模型都有显著的性能提升，特别是对具有较少参数的模型。此外，UnitModule具有31K参数，对原始物体检测模型的执行速度有很小的影响。我们的量化和视觉分析也表明，UnitModule可以有效地提高输入图像的质量和检测器对物体特征的感知能力。
</details></li>
</ul>
<hr>
<h2 id="A-Spatial-Temporal-Deformable-Attention-based-Framework-for-Breast-Lesion-Detection-in-Videos"><a href="#A-Spatial-Temporal-Deformable-Attention-based-Framework-for-Breast-Lesion-Detection-in-Videos" class="headerlink" title="A Spatial-Temporal Deformable Attention based Framework for Breast Lesion Detection in Videos"></a>A Spatial-Temporal Deformable Attention based Framework for Breast Lesion Detection in Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04702">http://arxiv.org/abs/2309.04702</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alfredqin/stnet">https://github.com/alfredqin/stnet</a></li>
<li>paper_authors: Chao Qin, Jiale Cao, Huazhu Fu, Rao Muhammad Anwer, Fahad Shahbaz Khan</li>
<li>for: 检测乳腺癌视频是计算机辅助诊断中的关键任务。现有的视频基于乳腺癌检测方法通常是基于自我注意力操作进行时间特征聚合。我们认为这种策略难以有效地执行深度特征聚合，并且忽略了有用的地方信息。</li>
<li>methods: 我们提出了一种空间-时间可变注意力基础框架，名为STNet。我们的STNet引入了一个空间-时间可变注意力模块，以进行本地空间-时间特征融合。这个模块在每个阶段的encoder和decoder中都可以进行深度特征聚合。为了进一步加速检测速度，我们引入了一种encoder特征排序策略，在排序过程中，我们共享了背景和encoder特征，并将encoder特征排序给decoder生成多帧预测结果。</li>
<li>results: 我们在公共乳腺癌ultrasound视频数据集上进行了实验，结果显示，我们的STNet在检测性能方面取得了州属的纪录，同时在检测速度方面也比前者快两倍。代码和模型可以在<a target="_blank" rel="noopener" href="https://github.com/AlfredQin/STNet%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/AlfredQin/STNet上获取。</a><details>
<summary>Abstract</summary>
Detecting breast lesion in videos is crucial for computer-aided diagnosis. Existing video-based breast lesion detection approaches typically perform temporal feature aggregation of deep backbone features based on the self-attention operation. We argue that such a strategy struggles to effectively perform deep feature aggregation and ignores the useful local information. To tackle these issues, we propose a spatial-temporal deformable attention based framework, named STNet. Our STNet introduces a spatial-temporal deformable attention module to perform local spatial-temporal feature fusion. The spatial-temporal deformable attention module enables deep feature aggregation in each stage of both encoder and decoder. To further accelerate the detection speed, we introduce an encoder feature shuffle strategy for multi-frame prediction during inference. In our encoder feature shuffle strategy, we share the backbone and encoder features, and shuffle encoder features for decoder to generate the predictions of multiple frames. The experiments on the public breast lesion ultrasound video dataset show that our STNet obtains a state-of-the-art detection performance, while operating twice as fast inference speed. The code and model are available at https://github.com/AlfredQin/STNet.
</details>
<details>
<summary>摘要</summary>
检测乳腺病变视频是计算机辅助诊断中的关键任务。现有的视频基于 breast lesion 检测方法通常采用深度归一化特征的时间特征聚合方法。我们认为这种策略困难具有效地执行深度特征聚合和忽略了有用的本地信息。为解决这些问题，我们提出了一种空间时间变形注意力基本框架，名为 STNet。我们的 STNet 引入了一个空间时间变形注意力模块，以进行本地空间时间特征融合。这个模块在每个阶段的 both encoder 和 decoder 中进行深度特征聚合。为了进一步加速检测速度，我们提出了一种 encoder 特征混合策略，在推理过程中将 encoder 特征混合多帧预测。在我们的 encoder 特征混合策略中，我们共享 backbone 和 encoder 特征，并在 decoder 中混合 encoder 特征来生成多帧预测。实验结果表明，我们的 STNet 在公共乳腺病变ultrasound video 数据集上取得了状态的检测性能，同时在推理速度上两倍快。代码和模型可以在 <https://github.com/AlfredQin/STNet> 中下载。
</details></li>
</ul>
<hr>
<h2 id="DeNoising-MOT-Towards-Multiple-Object-Tracking-with-Severe-Occlusions"><a href="#DeNoising-MOT-Towards-Multiple-Object-Tracking-with-Severe-Occlusions" class="headerlink" title="DeNoising-MOT: Towards Multiple Object Tracking with Severe Occlusions"></a>DeNoising-MOT: Towards Multiple Object Tracking with Severe Occlusions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04682">http://arxiv.org/abs/2309.04682</a></li>
<li>repo_url: None</li>
<li>paper_authors: Teng Fu, Xiaocong Wang, Haiyang Yu, Ke Niu, Bin Li, Xiangyang Xue</li>
<li>for: 提高多对目标跟踪（MOT）在受阻碍的情况下的性能。</li>
<li>methods: 使用增强的隐藏状态和推理框架，以及一种新的排除噪声的策略。</li>
<li>results: 在MOT17、MOT20和DanceTrack datasets上进行了广泛的实验，并表明了与之前的状态革命性的提高。<details>
<summary>Abstract</summary>
Multiple object tracking (MOT) tends to become more challenging when severe occlusions occur. In this paper, we analyze the limitations of traditional Convolutional Neural Network-based methods and Transformer-based methods in handling occlusions and propose DNMOT, an end-to-end trainable DeNoising Transformer for MOT. To address the challenge of occlusions, we explicitly simulate the scenarios when occlusions occur. Specifically, we augment the trajectory with noises during training and make our model learn the denoising process in an encoder-decoder architecture, so that our model can exhibit strong robustness and perform well under crowded scenes. Additionally, we propose a Cascaded Mask strategy to better coordinate the interaction between different types of queries in the decoder to prevent the mutual suppression between neighboring trajectories under crowded scenes. Notably, the proposed method requires no additional modules like matching strategy and motion state estimation in inference. We conduct extensive experiments on the MOT17, MOT20, and DanceTrack datasets, and the experimental results show that our method outperforms previous state-of-the-art methods by a clear margin.
</details>
<details>
<summary>摘要</summary>
多bject 跟踪 (MOT) 在严重遮挡情况下变得更加挑战。在这篇论文中，我们分析传统的卷积神经网络基本方法和转移器基本方法在处理遮挡的局限性，并提出了DNMOT，一种可以受教育的端到端的减噪变换器 для MOT。为了解决遮挡的挑战，我们在训练时间添加了噪声到轨迹上，使我们的模型在encoder-decoder架构中学习减噪过程，从而使我们的模型在拥挤的场景下表现出强大的鲁棒性。此外，我们提出了协调器策略，以更好地协调不同类型的查询在解码器中的交互，从而避免在拥挤的场景下邻近轨迹之间的互相抑制。值得注意的是，我们提出的方法不需要在推断过程中添加额外的模块，如匹配策略和运动状态估计。我们在MOT17、MOT20和DanceTrack datasets上进行了广泛的实验，实验结果表明，我们的方法在前一代方法之上具有明显的优势。
</details></li>
</ul>
<hr>
<h2 id="BiLMa-Bidirectional-Local-Matching-for-Text-based-Person-Re-identification"><a href="#BiLMa-Bidirectional-Local-Matching-for-Text-based-Person-Re-identification" class="headerlink" title="BiLMa: Bidirectional Local-Matching for Text-based Person Re-identification"></a>BiLMa: Bidirectional Local-Matching for Text-based Person Re-identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04675">http://arxiv.org/abs/2309.04675</a></li>
<li>repo_url: None</li>
<li>paper_authors: Takuro Fujii, Shuhei Tarashima<br>for: 这个论文是针对文本描述人脸图像的重新识别问题（Text-based Person Re-identification，TBPReID）的研究。methods: 这个论文使用的方法是将图像和文本部分对齐，并通过Masked Language Modeling（MLM）和Masked Image Modeling（MIM）进行协调训练。它还提出了对向（from text to image）和反向（from image to text）的本地匹配方法，以提高TBPReID的性能。results: 根据实验结果，这个方法在三个测试 benchmark 上达到了当今最佳的 Rank@1 和 mAP 分数。<details>
<summary>Abstract</summary>
Text-based person re-identification (TBPReID) aims to retrieve person images represented by a given textual query. In this task, how to effectively align images and texts globally and locally is a crucial challenge. Recent works have obtained high performances by solving Masked Language Modeling (MLM) to align image/text parts. However, they only performed uni-directional (i.e., from image to text) local-matching, leaving room for improvement by introducing opposite-directional (i.e., from text to image) local-matching. In this work, we introduce Bidirectional Local-Matching (BiLMa) framework that jointly optimize MLM and Masked Image Modeling (MIM) in TBPReID model training. With this framework, our model is trained so as the labels of randomly masked both image and text tokens are predicted by unmasked tokens. In addition, to narrow the semantic gap between image and text in MIM, we propose Semantic MIM (SemMIM), in which the labels of masked image tokens are automatically given by a state-of-the-art human parser. Experimental results demonstrate that our BiLMa framework with SemMIM achieves state-of-the-art Rank@1 and mAP scores on three benchmarks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SSHNN-Semi-Supervised-Hybrid-NAS-Network-for-Echocardiographic-Image-Segmentation"><a href="#SSHNN-Semi-Supervised-Hybrid-NAS-Network-for-Echocardiographic-Image-Segmentation" class="headerlink" title="SSHNN: Semi-Supervised Hybrid NAS Network for Echocardiographic Image Segmentation"></a>SSHNN: Semi-Supervised Hybrid NAS Network for Echocardiographic Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04672">http://arxiv.org/abs/2309.04672</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renqi Chen, Jingjing Luo, Fan Nian, Yuhui Cen, Yiheng Peng, Zekuan Yu</li>
<li>for: 准确的医疗影像分割，特别是echocardiographic图像处理中的噪声难以忽略，需要 elaboration 的网络设计。</li>
<li>methods: 我们提出了一种新的半supervised Hybrid NAS网络（SSHNN），利用卷积操作来实现层次特征融合，并通过引入Transformers来补做全局上下文，以及U-shaped解码器来有效地连接全局上下文和本地特征。</li>
<li>results: 我们在CAMUS医学电子心肺图像集上进行了广泛的实验，发现SSHNN比 estado-of-the-art方法更高效，实现了高精度的分割。<details>
<summary>Abstract</summary>
Accurate medical image segmentation especially for echocardiographic images with unmissable noise requires elaborate network design. Compared with manual design, Neural Architecture Search (NAS) realizes better segmentation results due to larger search space and automatic optimization, but most of the existing methods are weak in layer-wise feature aggregation and adopt a ``strong encoder, weak decoder" structure, insufficient to handle global relationships and local details. To resolve these issues, we propose a novel semi-supervised hybrid NAS network for accurate medical image segmentation termed SSHNN. In SSHNN, we creatively use convolution operation in layer-wise feature fusion instead of normalized scalars to avoid losing details, making NAS a stronger encoder. Moreover, Transformers are introduced for the compensation of global context and U-shaped decoder is designed to efficiently connect global context with local features. Specifically, we implement a semi-supervised algorithm Mean-Teacher to overcome the limited volume problem of labeled medical image dataset. Extensive experiments on CAMUS echocardiography dataset demonstrate that SSHNN outperforms state-of-the-art approaches and realizes accurate segmentation. Code will be made publicly available.
</details>
<details>
<summary>摘要</summary>
准确的医疗图像分割，特别是用于echocardiographic图像，需要考虑到干扰的存在。传统的手动设计方法在层次特征聚合方面有限，而Neural Architecture Search（NAS）可以通过更大的搜索空间和自动优化来实现更好的分割结果。然而，现有的方法通常具有“强Encoder,弱Decoder”结构，无法处理全局关系和地方细节。为解决这些问题，我们提出了一种新的半supervised Hybrid NAS网络，称为 SSHNN。在 SSHNN 中，我们创新地使用卷积操作来实现层次特征融合，而不是使用normalized scalars，以避免丢失细节。此外，我们还引入了Transformers来补做全局上下文，并设计了U型决策器来有效地连接全局上下文和地方特征。具体来说，我们实现了一种半supervised算法Mean-Teacher来超越医疗图像数据集的限制。我们进行了广泛的实验，并证明了 SSHNN 可以超过现有的方法，并实现准确的分割。代码将公开发布。
</details></li>
</ul>
<hr>
<h2 id="Unified-Language-Vision-Pretraining-with-Dynamic-Discrete-Visual-Tokenization"><a href="#Unified-Language-Vision-Pretraining-with-Dynamic-Discrete-Visual-Tokenization" class="headerlink" title="Unified Language-Vision Pretraining with Dynamic Discrete Visual Tokenization"></a>Unified Language-Vision Pretraining with Dynamic Discrete Visual Tokenization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04669">http://arxiv.org/abs/2309.04669</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jy0205/LaVIT">https://github.com/jy0205/LaVIT</a></li>
<li>paper_authors: Yang Jin, Kun Xu, Kun Xu, Liwei Chen, Chao Liao, Jianchao Tan, Bin Chen, Chenyi Lei, An Liu, Chengru Song, Xiaoqiang Lei, Yadong Mu, Di Zhang, Wenwu Ou, Kun Gai</li>
<li>for: 本研究旨在突破现有语言模型只允许视觉输入的限制，将语言和视觉都 Represented为一个共同表示，以提高多模态理解能力。</li>
<li>methods: 作者提出了一种名为LaVIT（语言-视觉 transformer）的基础模型，该模型通过一种图像tokenizer将非语言图像转化为一个序列化的语言形式，从而使得模型可以同时处理图像和文本。</li>
<li>results: 对于下游任务，LaVIT比现有模型提高了大幅度的性能，并且在多模态理解任务中表现出色。<details>
<summary>Abstract</summary>
Recently, the remarkable advance of the Large Language Model (LLM) has inspired researchers to transfer its extraordinary reasoning capability to data across several modalities. The prevailing approaches primarily regard visual input as the prompt and focus exclusively on optimizing the text generation process conditioned upon vision content by a frozen LLM. Such an inequitable treatment of vision and language heavily constrains the model's potential. In this paper, we break through this limitation by representing both vision and language in a unified representation. To this end, we craft a visual tokenizer that translates the non-linguistic image into a sequence of discrete tokens like a foreign language that LLM can read. The resulting visual tokens encompass high-level semantics worthy of a word and also support dynamic sequence length varying from the image content. Coped with this visual tokenizer, the presented foundation model called LaVIT (Language-VIsion Transformer) can handle both image and text indiscriminately under a unified generative learning paradigm. Pre-trained on the web-scale image-text corpus, LaVIT is empowered with impressive multi-modal comprehension capability. The extensive experiments showcase that it outperforms existing models by a large margin on downstream tasks. Our code and models will be available at https://github.com/jy0205/LaVIT.
</details>
<details>
<summary>摘要</summary>
近期，大型语言模型（LLM）的出色发展已经激发了研究人员将其杰出的思维能力应用到多 modalities 的数据上。现有的方法主要将视觉输入视为提示，归类专门为conditioned upon vision content by a frozen LLM。这种对视觉和语言的不公平待遇，具有严重限制模型的潜力。在这篇论文中，我们突破这一限制，将视觉和语言都 Represented 为共同表示。为此，我们设计了一种视觉化 токен化器，将非语言的图像转化为一系列精确的 discrete tokens，这些 tokens 类似于外语，LLM 可以读取。得到的视觉 tokens 包含高级别 semantics 和支持动态序列长度，从图像内容而来。与这种视觉化 токен化器相配合，我们提出的基础模型 called LaVIT (Language-VIsion Transformer) 可以平等地处理图像和文本，并在一个共同生成学习 paradigm 下进行学习。预训练在网络规模的图像-文本 Corporpus 上，LaVIT 具有卓越的多模态理解能力。广泛的实验表明，它在下游任务上高度超越现有模型。我们的代码和模型将在 GitHub 上提供，请参考 https://github.com/jy0205/LaVIT。
</details></li>
</ul>
<hr>
<h2 id="ConvFormer-Plug-and-Play-CNN-Style-Transformers-for-Improving-Medical-Image-Segmentation"><a href="#ConvFormer-Plug-and-Play-CNN-Style-Transformers-for-Improving-Medical-Image-Segmentation" class="headerlink" title="ConvFormer: Plug-and-Play CNN-Style Transformers for Improving Medical Image Segmentation"></a>ConvFormer: Plug-and-Play CNN-Style Transformers for Improving Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05674">http://arxiv.org/abs/2309.05674</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xianlin7/convformer">https://github.com/xianlin7/convformer</a></li>
<li>paper_authors: Xian Lin, Zengqiang Yan, Xianbo Deng, Chuansheng Zheng, Li Yu</li>
<li>for: 提高transformer-based框架中的 segmentation性能，增强对医疗图像的分类能力。</li>
<li>methods: 提出CNN-style Transformers（ConvFormer），通过增强注意力归一化和特征提取来提高分类性能。ConvFormer包括pooling、CNN-style自注意（CSA）和卷积FeedForward Network（CFFN），可以作为vanilla Vision Transformers中的tokenization、self-attention和FeedForward Network。</li>
<li>results: 在多个 dataset上展示了ConvFormer作为plug-and-play模块，可以遥增transformer-based框架中的segmentation性能。<details>
<summary>Abstract</summary>
Transformers have been extensively studied in medical image segmentation to build pairwise long-range dependence. Yet, relatively limited well-annotated medical image data makes transformers struggle to extract diverse global features, resulting in attention collapse where attention maps become similar or even identical. Comparatively, convolutional neural networks (CNNs) have better convergence properties on small-scale training data but suffer from limited receptive fields. Existing works are dedicated to exploring the combinations of CNN and transformers while ignoring attention collapse, leaving the potential of transformers under-explored. In this paper, we propose to build CNN-style Transformers (ConvFormer) to promote better attention convergence and thus better segmentation performance. Specifically, ConvFormer consists of pooling, CNN-style self-attention (CSA), and convolutional feed-forward network (CFFN) corresponding to tokenization, self-attention, and feed-forward network in vanilla vision transformers. In contrast to positional embedding and tokenization, ConvFormer adopts 2D convolution and max-pooling for both position information preservation and feature size reduction. In this way, CSA takes 2D feature maps as inputs and establishes long-range dependency by constructing self-attention matrices as convolution kernels with adaptive sizes. Following CSA, 2D convolution is utilized for feature refinement through CFFN. Experimental results on multiple datasets demonstrate the effectiveness of ConvFormer working as a plug-and-play module for consistent performance improvement of transformer-based frameworks. Code is available at https://github.com/xianlin7/ConvFormer.
</details>
<details>
<summary>摘要</summary>
transformers 已经广泛研究在医学影像分割中建立对比较远范围的长距离相依性。然而，有限的高质量医学影像数据使 transformers 具有医学影像分割中的注意力塌缩现象，其中注意力映射变得相似或 même identical。相比之下，卷积神经网络（CNN）在小规模训练数据上具有更好的收敛性能，但它们受限于有限的接收场。现有的工作主要关注于将 CNN 和 transformers 结合使用，而忽略了注意力塌缩现象，这使得 transformers 的潜在能力尚未得到充分探索。在这篇论文中，我们提出了一种基于 CNN 的 transformers（ConvFormer），以便提高注意力的叠合和医学影像分割性能。具体来说，ConvFormer 包括池化、CNN 样式自注意（CSA）和卷积神经网络（CFFN），与标准视觉 transformers 中的征文化、自注意和Feed Forward 网络相对应。与position embedding和分割不同，ConvFormer 采用了2D卷积和最大池化来保持位坐标信息和特征大小减少。这样，CSA 可以将 2D 特征图作为输入，建立长距离相依性 by 构建自注意矩阵作为卷积核函数的 adaptive 大小。接着，2D 卷积被用于特征细化通过 CFFN。实验结果表明，ConvFormer 作为 transformer 基础架构中的插件模块，可以提高 transformer 基础架构的一致性和医学影像分割性能。代码可以在 https://github.com/xianlin7/ConvFormer 找到。
</details></li>
</ul>
<hr>
<h2 id="Progressive-Feature-Adjustment-for-Semi-supervised-Learning-from-Pretrained-Models"><a href="#Progressive-Feature-Adjustment-for-Semi-supervised-Learning-from-Pretrained-Models" class="headerlink" title="Progressive Feature Adjustment for Semi-supervised Learning from Pretrained Models"></a>Progressive Feature Adjustment for Semi-supervised Learning from Pretrained Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04659">http://arxiv.org/abs/2309.04659</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hai-Ming Xu, Lingqiao Liu, Hao Chen, Ehsan Abbasnejad, Rafael Felix</li>
<li>for: 提高 semi-supervised learning 的性能，解决数据标注束缚问题</li>
<li>methods: 使用 pseudo-labels 更新 feature extractor，保证 feature distribution 维护良好的类别分离性，并且只允许类ifier 通过 labels 进行训练</li>
<li>results: 对比现有解决方案，提出的方法实现更高的性能<details>
<summary>Abstract</summary>
As an effective way to alleviate the burden of data annotation, semi-supervised learning (SSL) provides an attractive solution due to its ability to leverage both labeled and unlabeled data to build a predictive model. While significant progress has been made recently, SSL algorithms are often evaluated and developed under the assumption that the network is randomly initialized. This is in sharp contrast to most vision recognition systems that are built from fine-tuning a pretrained network for better performance. While the marriage of SSL and a pretrained model seems to be straightforward, recent literature suggests that naively applying state-of-the-art SSL with a pretrained model fails to unleash the full potential of training data. In this paper, we postulate the underlying reason is that the pretrained feature representation could bring a bias inherited from the source data, and the bias tends to be magnified through the self-training process in a typical SSL algorithm. To overcome this issue, we propose to use pseudo-labels from the unlabelled data to update the feature extractor that is less sensitive to incorrect labels and only allow the classifier to be trained from the labeled data. More specifically, we progressively adjust the feature extractor to ensure its induced feature distribution maintains a good class separability even under strong input perturbation. Through extensive experimental studies, we show that the proposed approach achieves superior performance over existing solutions.
</details>
<details>
<summary>摘要</summary>
为了减轻数据标注的负担，半upervised learning（SSL）提供了一个有力的解决方案，因为它可以利用标注和无标注数据建立预测模型。 although significant progress has been made recently, SSL algorithms are often evaluated and developed under the assumption that the network is randomly initialized. This is in sharp contrast to most vision recognition systems that are built from fine-tuning a pretrained network for better performance. While the marriage of SSL and a pretrained model seems to be straightforward, recent literature suggests that naively applying state-of-the-art SSL with a pretrained model fails to unleash the full potential of training data. In this paper, we postulate that the underlying reason is that the pretrained feature representation could bring a bias inherited from the source data, and the bias tends to be magnified through the self-training process in a typical SSL algorithm. To overcome this issue, we propose to use pseudo-labels from the unlabelled data to update the feature extractor that is less sensitive to incorrect labels and only allow the classifier to be trained from the labeled data. More specifically, we progressively adjust the feature extractor to ensure its induced feature distribution maintains a good class separability even under strong input perturbation. Through extensive experimental studies, we show that the proposed approach achieves superior performance over existing solutions.Note: The translation is in Simplified Chinese, which is one of the two standard versions of Chinese used in mainland China and Singapore.
</details></li>
</ul>
<hr>
<h2 id="Generation-and-Recombination-for-Multifocus-Image-Fusion-with-Free-Number-of-Inputs"><a href="#Generation-and-Recombination-for-Multifocus-Image-Fusion-with-Free-Number-of-Inputs" class="headerlink" title="Generation and Recombination for Multifocus Image Fusion with Free Number of Inputs"></a>Generation and Recombination for Multifocus Image Fusion with Free Number of Inputs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04657">http://arxiv.org/abs/2309.04657</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huafeng Li, Dan Wang, Yuxin Huang, Yafei Zhang, Zhengtao Yu</li>
<li>for:  overcome the limitation of optical lenses and achieve simultaneous fusion of multiple images</li>
<li>methods:  combining generation and recombination model (GRFusion), hard-pixel-guided recombination mechanism, and multi-directional gradient embedding method</li>
<li>results:  effective and superior fusion performance, free from the number of inputs and with improved visual quality<details>
<summary>Abstract</summary>
Multifocus image fusion is an effective way to overcome the limitation of optical lenses. Many existing methods obtain fused results by generating decision maps. However, such methods often assume that the focused areas of the two source images are complementary, making it impossible to achieve simultaneous fusion of multiple images. Additionally, the existing methods ignore the impact of hard pixels on fusion performance, limiting the visual quality improvement of fusion image. To address these issues, a combining generation and recombination model, termed as GRFusion, is proposed. In GRFusion, focus property detection of each source image can be implemented independently, enabling simultaneous fusion of multiple source images and avoiding information loss caused by alternating fusion. This makes GRFusion free from the number of inputs. To distinguish the hard pixels from the source images, we achieve the determination of hard pixels by considering the inconsistency among the detection results of focus areas in source images. Furthermore, a multi-directional gradient embedding method for generating full focus images is proposed. Subsequently, a hard-pixel-guided recombination mechanism for constructing fused result is devised, effectively integrating the complementary advantages of feature reconstruction-based method and focused pixel recombination-based method. Extensive experimental results demonstrate the effectiveness and the superiority of the proposed method.The source code will be released on https://github.com/xxx/xxx.
</details>
<details>
<summary>摘要</summary>
多聚焦图像融合是一种有效的方法来超越光学镜头的限制。许多现有方法通过生成决策地图来获得融合结果，但这些方法经常假设源图像的焦点区域是补偿的，这使得同时融合多个图像变得不可能。此外，现有方法忽略了融合过程中硬Pixel的影响，从而限制融合图像的视觉质量改善。为解决这些问题，我们提出了GRFusion模型。GRFusion模型中可以独立实现每个源图像的焦点属性检测，因此可以同时融合多个源图像，避免因为交替融合而产生的信息损失。这使得GRFusion模型不受输入数量的限制。为了分辨硬Pixel与源图像之间的差异，我们提出了基于focus区域的决策结果的不一致来确定硬Pixel。此外，我们还提出了一种多向导向量嵌入方法来生成全焦图像。然后，我们设计了一种基于硬Pixel指导的融合机制，以有效地结合了特征重建方法和焦点像素重建方法的优点。经验证明了我们的方法的有效性和优越性。源代码将在GitHub上发布。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Robust-Features-for-Improving-Adversarial-Robustness"><a href="#Exploring-Robust-Features-for-Improving-Adversarial-Robustness" class="headerlink" title="Exploring Robust Features for Improving Adversarial Robustness"></a>Exploring Robust Features for Improving Adversarial Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04650">http://arxiv.org/abs/2309.04650</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hong Wang, Yuefan Deng, Shinjae Yoo, Yuewei Lin</li>
<li>for: 提高深度神经网络（DNNs）在安全敏感应用中的使用，因为它们容易受到特制攻击。</li>
<li>methods: 提出了一种特征分离模型，用于分离Robust特征和非Robust特征以及域специфи的特征。</li>
<li>results: 对四种广泛使用的数据集进行了extensive实验，并证明了我们的模型可以提高对特制攻击的抵抗力，并且可以准确地识别域特定的特征。<details>
<summary>Abstract</summary>
While deep neural networks (DNNs) have revolutionized many fields, their fragility to carefully designed adversarial attacks impedes the usage of DNNs in safety-critical applications. In this paper, we strive to explore the robust features which are not affected by the adversarial perturbations, i.e., invariant to the clean image and its adversarial examples, to improve the model's adversarial robustness. Specifically, we propose a feature disentanglement model to segregate the robust features from non-robust features and domain specific features. The extensive experiments on four widely used datasets with different attacks demonstrate that robust features obtained from our model improve the model's adversarial robustness compared to the state-of-the-art approaches. Moreover, the trained domain discriminator is able to identify the domain specific features from the clean images and adversarial examples almost perfectly. This enables adversarial example detection without incurring additional computational costs. With that, we can also specify different classifiers for clean images and adversarial examples, thereby avoiding any drop in clean image accuracy.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）在许多领域中已经引领了革命，但它们对特制的敌意攻击却有很大的敏感性，这限制了DNN在安全关键应用程序中的使用。在这篇论文中，我们尝试探索抗敌攻击的可靠特征，即对于清洁图像和敌意攻击的稳定特征，以提高模型的抗敌能力。具体来说，我们提出了特征分离模型，以分离可靠特征和非可靠特征、域特定特征。我们在四种广泛使用的数据集上进行了大量的实验，并证明了我们的模型可以在不同的攻击下提高抗敌能力，并且域特定特征分离器可以准确地从清洁图像和敌意攻击中分离域特定特征。这使得我们可以采取不同的分类器来处理清洁图像和敌意攻击，从而避免清洁图像精度下降。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/09/cs.CV_2023_09_09/" data-id="clogxf3n100h25xracxop3p2l" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/09/cs.AI_2023_09_09/" class="article-date">
  <time datetime="2023-09-09T12:00:00.000Z" itemprop="datePublished">2023-09-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/09/cs.AI_2023_09_09/">cs.AI - 2023-09-09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="How-to-Evaluate-Semantic-Communications-for-Images-with-ViTScore-Metric"><a href="#How-to-Evaluate-Semantic-Communications-for-Images-with-ViTScore-Metric" class="headerlink" title="How to Evaluate Semantic Communications for Images with ViTScore Metric?"></a>How to Evaluate Semantic Communications for Images with ViTScore Metric?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04891">http://arxiv.org/abs/2309.04891</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tingting Zhu, Bo Peng, Jifan Liang, Tingchen Han, Hai Wan, Jingqiao Fu, Junjie Chen</li>
<li>for: 这 paper 的目的是为了提出一种新的图像Semantic Similarity评估方法，以替代传统的图像相似度评估方法，以便在Semantic Communications 中更好地交换semantic information。</li>
<li>methods: 这 paper 使用了一种基于 Transformer 模型的新 metric，名为 Vision Transformer Score (ViTScore)，来评估图像的Semantic Similarity。</li>
<li>results: 经过5类 экспериimento，结果表明，ViTScore 能够更好地评估图像的Semantic Similarity，比传统的 PSNR、MS-SSIM 和 LPIPS 三种 metric 更加有效。<details>
<summary>Abstract</summary>
Semantic communications (SC) have been expected to be a new paradigm shifting to catalyze the next generation communication, whose main concerns shift from accurate bit transmission to effective semantic information exchange in communications. However, the previous and widely-used metrics for images are not applicable to evaluate the image semantic similarity in SC. Classical metrics to measure the similarity between two images usually rely on the pixel level or the structural level, such as the PSNR and the MS-SSIM. Straightforwardly using some tailored metrics based on deep-learning methods in CV community, such as the LPIPS, is infeasible for SC. To tackle this, inspired by BERTScore in NLP community, we propose a novel metric for evaluating image semantic similarity, named Vision Transformer Score (ViTScore). We prove theoretically that ViTScore has 3 important properties, including symmetry, boundedness, and normalization, which make ViTScore convenient and intuitive for image measurement. To evaluate the performance of ViTScore, we compare ViTScore with 3 typical metrics (PSNR, MS-SSIM, and LPIPS) through 5 classes of experiments. Experimental results demonstrate that ViTScore can better evaluate the image semantic similarity than the other 3 typical metrics, which indicates that ViTScore is an effective performance metric when deployed in SC scenarios.
</details>
<details>
<summary>摘要</summary>
听说（SC）将被看作是一个新的思维方式，它将catalyze下一代通信，主要关注从精确位传输升级到有效semantic信息交换在通信中。然而，过去广泛使用的图像评估 metric不适用于图像semantic相似性的评估。经典的图像相似性评估方法通常基于像素层或结构层，如PSNR和MS-SSIM。直接使用CV社区的深度学习方法基于metric，如LPIPS，是不可能的SC中。为了解决这个问题，我们提出了一种新的图像semantic相似性评估 metric，名为视觉 трансформа器分数（ViTScore）。我们证明了ViTScore具有3个重要的性质，包括对称性、卷积性和正规化性，这些性质使得ViTScore在图像评估中方便又直观。为了评估ViTScore的性能，我们与3种典型的metric（PSNR、MS-SSIM和LPIPS）进行5种类型的实验。实验结果表明，ViTScore可以更好地评估图像semantic相似性，这表明ViTScore是SC场景中的有效性能指标。
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Chatbots-to-Promote-Users’-Trust-–-Practices-and-Open-Problems"><a href="#Evaluating-Chatbots-to-Promote-Users’-Trust-–-Practices-and-Open-Problems" class="headerlink" title="Evaluating Chatbots to Promote Users’ Trust – Practices and Open Problems"></a>Evaluating Chatbots to Promote Users’ Trust – Practices and Open Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05680">http://arxiv.org/abs/2309.05680</a></li>
<li>repo_url: None</li>
<li>paper_authors: Biplav Srivastava, Kausik Lakkaraju, Tarmo Koppel, Vignesh Narayanan, Ashish Kundu, Sachindra Joshi</li>
<li>for: 评估聊天机器人（chatbot）的可靠性和用户满意度，以及长期对社会的影响。</li>
<li>methods: 现有的chatbot测试方法和开放问题，以及未来的测试方法和技术。</li>
<li>results: 评估chatbot的性能和用户满意度，以及对社会的长期影响。<details>
<summary>Abstract</summary>
Chatbots, the common moniker for collaborative assistants, are Artificial Intelligence (AI) software that enables people to naturally interact with them to get tasks done. Although chatbots have been studied since the dawn of AI, they have particularly caught the imagination of the public and businesses since the launch of easy-to-use and general-purpose Large Language Model-based chatbots like ChatGPT. As businesses look towards chatbots as a potential technology to engage users, who may be end customers, suppliers, or even their own employees, proper testing of chatbots is important to address and mitigate issues of trust related to service or product performance, user satisfaction and long-term unintended consequences for society. This paper reviews current practices for chatbot testing, identifies gaps as open problems in pursuit of user trust, and outlines a path forward.
</details>
<details>
<summary>摘要</summary>
chatbots，它们是人工智能软件，允许人们自然地与其交互，完成任务。虽然 chatbots 已经从人工智能出现以来被研究，但是它们特别在 ChatGPT 类大语言模型基础上的易于使用和通用 chatbots 出现后，引起了公众和企业的关注。在企业希望通过 chatbots 来与用户进行互动，包括客户、供应商和员工，正确测试 chatbots 是非常重要的，以解决服务或产品性能、用户满意度和社会长期未来的问题。本文将评论当前 chatbot 测试实践，描述存在的问题和挑战，并提出未来的发展道路。
</details></li>
</ul>
<hr>
<h2 id="Recall-driven-Precision-Refinement-Unveiling-Accurate-Fall-Detection-using-LSTM"><a href="#Recall-driven-Precision-Refinement-Unveiling-Accurate-Fall-Detection-using-LSTM" class="headerlink" title="Recall-driven Precision Refinement: Unveiling Accurate Fall Detection using LSTM"></a>Recall-driven Precision Refinement: Unveiling Accurate Fall Detection using LSTM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07154">http://arxiv.org/abs/2309.07154</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rishabh Mondal, Prasun Ghosal</li>
<li>for: 这篇研究旨在解决老年人堕伤的问题，通过开发一个精准的堕伤检测系统。</li>
<li>methods: 本研究使用了现代技术，包括加速计和陀螺仪数据，与深度学习模型，具体是长期快速传统机制（LSTM）网络。实时执行能力通过raspberry Pi硬件的整合。我们还提出了裁剪技术，对LSTM模型的架构和参数进行精确调整，以便提高系统的性能。</li>
<li>results: 我们的实验结果显示，本系统具有高精度和高特异性（96%），实现了堕伤检测的目标。我们的研究将fall detection技术带到了新的水平，提供了一个可靠和有效的堕伤预防和处理解决方案。<details>
<summary>Abstract</summary>
This paper presents an innovative approach to address the pressing concern of fall incidents among the elderly by developing an accurate fall detection system. Our proposed system combines state-of-the-art technologies, including accelerometer and gyroscope sensors, with deep learning models, specifically Long Short-Term Memory (LSTM) networks. Real-time execution capabilities are achieved through the integration of Raspberry Pi hardware. We introduce pruning techniques that strategically fine-tune the LSTM model's architecture and parameters to optimize the system's performance. We prioritize recall over precision, aiming to accurately identify falls and minimize false negatives for timely intervention. Extensive experimentation and meticulous evaluation demonstrate remarkable performance metrics, emphasizing a high recall rate while maintaining a specificity of 96\%. Our research culminates in a state-of-the-art fall detection system that promptly sends notifications, ensuring vulnerable individuals receive timely assistance and improve their overall well-being. Applying LSTM models and incorporating pruning techniques represent a significant advancement in fall detection technology, offering an effective and reliable fall prevention and intervention solution.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)这篇论文提出了一种创新的方法，用于解决老年人倒下的问题，即开发一个高度准确的倒下检测系统。我们的提议的系统结合了当前最佳的技术，包��加速度和自转仪器，以及深度学习模型，具体来说是Long Short-Term Memory（LSTM）网络。通过raspberry pi硬件的集成，实现了实时执行能力。我们引入了截剪技术，以优化LSTM模型的结构和参数，以提高系统的性能。我们偏好回报，即准确地识别倒下，而不是精度。通过严格的实验和评估，我们得到了惊人的性能指标，包括高回报率和96%的特异性。我们的研究最终 culminates in a state-of-the-art fall detection system that promptly sends notifications, ensuring vulnerable individuals receive timely assistance and improve their overall well-being。通过应用LSTM模型和截剪技术，我们代表了一种有效和可靠的倒下检测技术，提供了一个有效的倒下预防和 intervención解决方案。
</details></li>
</ul>
<hr>
<h2 id="Distributional-Data-Augmentation-Methods-for-Low-Resource-Language"><a href="#Distributional-Data-Augmentation-Methods-for-Low-Resource-Language" class="headerlink" title="Distributional Data Augmentation Methods for Low Resource Language"></a>Distributional Data Augmentation Methods for Low Resource Language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04862">http://arxiv.org/abs/2309.04862</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mosh98/text_aug_low_res">https://github.com/mosh98/text_aug_low_res</a></li>
<li>paper_authors: Mosleh Mahamud, Zed Lee, Isak Samsten</li>
<li>for: 提高预测性能，特别是在低资源语言中</li>
<li>methods: 使用易搅拌数据增强技术（EDA），以及基于语义词语上下文信息和分词标签的类型特定相似词替换技术（TSSR）</li>
<li>results: 在 svenska 语料中，使用提议的方法可以提高分类性能，特别是在低资源语言中<details>
<summary>Abstract</summary>
Text augmentation is a technique for constructing synthetic data from an under-resourced corpus to improve predictive performance. Synthetic data generation is common in numerous domains. However, recently text augmentation has emerged in natural language processing (NLP) to improve downstream tasks. One of the current state-of-the-art text augmentation techniques is easy data augmentation (EDA), which augments the training data by injecting and replacing synonyms and randomly permuting sentences. One major obstacle with EDA is the need for versatile and complete synonym dictionaries, which cannot be easily found in low-resource languages. To improve the utility of EDA, we propose two extensions, easy distributional data augmentation (EDDA) and type specific similar word replacement (TSSR), which uses semantic word context information and part-of-speech tags for word replacement and augmentation. In an extensive empirical evaluation, we show the utility of the proposed methods, measured by F1 score, on two representative datasets in Swedish as an example of a low-resource language. With the proposed methods, we show that augmented data improve classification performances in low-resource settings.
</details>
<details>
<summary>摘要</summary>
文本扩充是一种技术，用于从不充分的 corpus 中构建合成数据，以提高预测性能。合成数据生成在许多领域非常常见。然而，在自然语言处理（NLP）领域，文本扩充最近才得到了应用。一种当前状态的文本扩充技术是轻松数据扩充（EDA），它在训练数据中注入和替换同义词和随机排序句子。然而，EDA 需要具有广泛和完整的同义词词典，这些词典在低资源语言中很难找。为了改进 EDDA 的Utility，我们提出了两种扩展，易用分布数据扩充（EDDA）和类型特定相似词替换（TSSR），它们使用语义词语上下文信息和部首标签进行词替换和扩展。在两个代表性数据集上进行了广泛的实验评估，我们表明了提案方法的有用性， measured by F1 分数。通过扩展了的数据，我们在低资源设置中显示了预测性能的提高。
</details></li>
</ul>
<hr>
<h2 id="AmbientFlow-Invertible-generative-models-from-incomplete-noisy-measurements"><a href="#AmbientFlow-Invertible-generative-models-from-incomplete-noisy-measurements" class="headerlink" title="AmbientFlow: Invertible generative models from incomplete, noisy measurements"></a>AmbientFlow: Invertible generative models from incomplete, noisy measurements</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04856">http://arxiv.org/abs/2309.04856</a></li>
<li>repo_url: None</li>
<li>paper_authors: Varun A. Kelkar, Rucha Deshpande, Arindam Banerjee, Mark A. Anastasio</li>
<li>for: 这 paper 是为了学习基于流的生成模型，并 directly from noisy and incomplete data。</li>
<li>methods: 该 paper 使用了变量 Bayesian 方法，建立了一个新的 framework 来学习 flow-based generative models。</li>
<li>results: 数值研究表明，AmbientFlow 可以正确地学习对象分布，并在下游推理任务中进行图像重建。<details>
<summary>Abstract</summary>
Generative models have gained popularity for their potential applications in imaging science, such as image reconstruction, posterior sampling and data sharing. Flow-based generative models are particularly attractive due to their ability to tractably provide exact density estimates along with fast, inexpensive and diverse samples. Training such models, however, requires a large, high quality dataset of objects. In applications such as computed imaging, it is often difficult to acquire such data due to requirements such as long acquisition time or high radiation dose, while acquiring noisy or partially observed measurements of these objects is more feasible. In this work, we propose AmbientFlow, a framework for learning flow-based generative models directly from noisy and incomplete data. Using variational Bayesian methods, a novel framework for establishing flow-based generative models from noisy, incomplete data is proposed. Extensive numerical studies demonstrate the effectiveness of AmbientFlow in correctly learning the object distribution. The utility of AmbientFlow in a downstream inference task of image reconstruction is demonstrated.
</details>
<details>
<summary>摘要</summary>
生成模型在媒体科学中得到了广泛的应用，如图像重建、贝叶抽样和数据分享。基于流的生成模型尤其吸引人，因为它们可以追加精确的概率估计，同时提供快速、便宜和多样的样本。但是训练这些模型需要一大量、高质量的对象数据。在计算成像应用中，通常难以获得这些数据，因为需要长时间的获取或高剂量的辐射剂量，而获取噪声或部分观测的对象数据是更可行的。在这项工作中，我们提出了 AmbientFlow，一种直接从噪声和部分观测数据学习流基的生成模型的框架。使用变分 Bayesian 方法，我们提出了一种新的框架，可以从噪声和部分观测数据中直接学习对象分布。我们的数值研究表明，AmbientFlow 可以正确地学习对象分布。此外，AmbientFlow 在下游推理任务中的图像重建中的实用性也被证明。
</details></li>
</ul>
<hr>
<h2 id="Speech-Emotion-Recognition-with-Distilled-Prosodic-and-Linguistic-Affect-Representations"><a href="#Speech-Emotion-Recognition-with-Distilled-Prosodic-and-Linguistic-Affect-Representations" class="headerlink" title="Speech Emotion Recognition with Distilled Prosodic and Linguistic Affect Representations"></a>Speech Emotion Recognition with Distilled Prosodic and Linguistic Affect Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04849">http://arxiv.org/abs/2309.04849</a></li>
<li>repo_url: None</li>
<li>paper_authors: Debaditya Shome, Ali Etemad</li>
<li>for: 这个论文是为了提出一种新的语音情绪识别（SER）框架，以便在语音信号上学习强大的语言和情感表达。</li>
<li>methods: 这个方法使用了cross-modal知识填充在训练时期，以学习语音信号上的情感表达。在推断时期，我们的方法只需要一个流经语音信号来进行单模式SER，从而降低计算开销和避免在运行时转写和语音特征提取错误。</li>
<li>results: 实验表明，我们的方法在IEMOCAP benchmark上比其他单模式和多模式方法高出许多，并达到了状态机的性能（77.49%无担荷准确率和78.91%担荷准确率）。详细的ablation研究表明每个组件的影响。<details>
<summary>Abstract</summary>
We propose EmoDistill, a novel speech emotion recognition (SER) framework that leverages cross-modal knowledge distillation during training to learn strong linguistic and prosodic representations of emotion from speech. During inference, our method only uses a stream of speech signals to perform unimodal SER thus reducing computation overhead and avoiding run-time transcription and prosodic feature extraction errors. During training, our method distills information at both embedding and logit levels from a pair of pre-trained Prosodic and Linguistic teachers that are fine-tuned for SER. Experiments on the IEMOCAP benchmark demonstrate that our method outperforms other unimodal and multimodal techniques by a considerable margin, and achieves state-of-the-art performance of 77.49% unweighted accuracy and 78.91% weighted accuracy. Detailed ablation studies demonstrate the impact of each component of our method.
</details>
<details>
<summary>摘要</summary>
我们提出了 EmoDistill，一种新的语音情感识别（SER）框架，利用交叉模态知识储备 durante 训练以学习从语音中强大的语言和表征表达情感。在推断过程中，我们的方法仅使用一个流 speech 信号来进行单模态 SER，从而减少计算负担和避免运行时转写和表征特征EXTRACTING错误。在训练过程中，我们的方法在 embedding 和 logit 两个水平上储备信息从 two 个预训练的 Prosodic 和 Linguistic 教师，这些教师在 SER 上进行了精度的 fine-tuning。在 IEMOCAP benchmark 上进行的实验表明，我们的方法在其他单模态和多模态技术的比较中表现出了 considerable 的优势，并达到了 state-of-the-art 性能的 77.49% 不平衡精度和 78.91% 平衡精度。详细的抽象研究表明了我们的方法中每个组件的影响。
</details></li>
</ul>
<hr>
<h2 id="Verifiable-Reinforcement-Learning-Systems-via-Compositionality"><a href="#Verifiable-Reinforcement-Learning-Systems-via-Compositionality" class="headerlink" title="Verifiable Reinforcement Learning Systems via Compositionality"></a>Verifiable Reinforcement Learning Systems via Compositionality</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06420">http://arxiv.org/abs/2309.06420</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cyrus Neary, Aryaman Singh Samyal, Christos Verginis, Murat Cubuktepe, Ufuk Topcu</li>
<li>for: 本文提出了一个可验证和可分解的强化学习框架，用于实现多个强化学习子系统的集成，以完成一个总任务。</li>
<li>methods: 该框架包括一个高级模型，表示为 Parametric Markov Decision Process，用于规划和分析强化学习子系统的集成。强化学习子系统是通过定义子系统之间的接口，以实现自动化的任务分解和独立的训练和测试。</li>
<li>results: 实验结果表明，该框架在具有全 observability 和 partial observability 的环境中都能够实现高效的任务执行。同时，该框架可以处理离散和连续状态和动作空间，以及 deterministic 和 stochastic 动力学。<details>
<summary>Abstract</summary>
We propose a framework for verifiable and compositional reinforcement learning (RL) in which a collection of RL subsystems, each of which learns to accomplish a separate subtask, are composed to achieve an overall task. The framework consists of a high-level model, represented as a parametric Markov decision process, which is used to plan and analyze compositions of subsystems, and of the collection of low-level subsystems themselves. The subsystems are implemented as deep RL agents operating under partial observability. By defining interfaces between the subsystems, the framework enables automatic decompositions of task specifications, e.g., reach a target set of states with a probability of at least 0.95, into individual subtask specifications, i.e. achieve the subsystem's exit conditions with at least some minimum probability, given that its entry conditions are met. This in turn allows for the independent training and testing of the subsystems. We present theoretical results guaranteeing that if each subsystem learns a policy satisfying its subtask specification, then their composition is guaranteed to satisfy the overall task specification. Conversely, if the subtask specifications cannot all be satisfied by the learned policies, we present a method, formulated as the problem of finding an optimal set of parameters in the high-level model, to automatically update the subtask specifications to account for the observed shortcomings. The result is an iterative procedure for defining subtask specifications, and for training the subsystems to meet them. Experimental results demonstrate the presented framework's novel capabilities in environments with both full and partial observability, discrete and continuous state and action spaces, as well as deterministic and stochastic dynamics.
</details>
<details>
<summary>摘要</summary>
我们提出了一个扩展的强化学习（RL）框架，在这个框架中，一群RL子系统，每个子系统都学习完成一个独立的子任务，这些子系统被组合以完成总任务。该框架包括一个高级模型，表示为参数化的随机过程决策过程，用于规划和分析子系统的组合。子系统实现为深度学习RL代理，在受限性观察下运行。通过定义子系统之间的界面，该框架允许自动将任务规范分解成个别子任务规范，例如，达到目标集的状态 WITH  least 0.95 的概率，或者在达到子系统的入口条件时，达到至少一定的最小概率。这样做了可以独立地培训和测试子系统。我们提供了理论结果，证明如果每个子系统学习满足其子任务规范，那么其组合就可以满足总任务规范。相反，如果子任务规范无法由学习的策略满足，我们提供了一种方法，即在高级模型中寻找优化的参数集，以自动更新子任务规范，以便 compte ten  observe 短coming。结果是一种迭代的过程，用于定义子任务规范，并培训子系统以满足它们。实验结果表明，该框架在具有全 observable 和 partial observable 的环境中，以及具有整数和连续状态空间的环境中，都能够展示出新的能力。
</details></li>
</ul>
<hr>
<h2 id="Global-Convergence-of-Receding-Horizon-Policy-Search-in-Learning-Estimator-Designs"><a href="#Global-Convergence-of-Receding-Horizon-Policy-Search-in-Learning-Estimator-Designs" class="headerlink" title="Global Convergence of Receding-Horizon Policy Search in Learning Estimator Designs"></a>Global Convergence of Receding-Horizon Policy Search in Learning Estimator Designs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04831">http://arxiv.org/abs/2309.04831</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiangyuan-zhang/learningkf">https://github.com/xiangyuan-zhang/learningkf</a></li>
<li>paper_authors: Xiangyuan Zhang, Saviz Mowlavi, Mouhacine Benosman, Tamer Başar</li>
<li>for: 本研究开发了一种名为往返 horizon policy gradient（RHPG）算法，用于学习最佳线性估计设计（Kalman filter，KF）。</li>
<li>methods: RHPG算法 integrates vanilla policy search directions into a dynamic programming outer loop，将无限时间KF问题转换为一系列静止估计问题，并且提供了优化内部的测地图分析和数据点复杂度保证。</li>
<li>results: RHPG算法可以实现全球均衡，并且不需要任何先验知识或开 Loop稳定性。我们还提供了细化的优化景象分析和数据点复杂度保证。这个研究是控制应用中首次开发了具有性能保证的循环学习算法，并且结合了精确控制理论在算法设计和理论分析中。我们还验证了RHPG算法在一个大规模对流混合运算中的性能。代码存储库可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/xiangyuan-zhang/LearningKF%7D">https://github.com/xiangyuan-zhang/LearningKF}</a> 上找到。<details>
<summary>Abstract</summary>
We introduce the receding-horizon policy gradient (RHPG) algorithm, the first PG algorithm with provable global convergence in learning the optimal linear estimator designs, i.e., the Kalman filter (KF). Notably, the RHPG algorithm does not require any prior knowledge of the system for initialization and does not require the target system to be open-loop stable. The key of RHPG is that we integrate vanilla PG (or any other policy search directions) into a dynamic programming outer loop, which iteratively decomposes the infinite-horizon KF problem that is constrained and non-convex in the policy parameter into a sequence of static estimation problems that are unconstrained and strongly-convex, thus enabling global convergence. We further provide fine-grained analyses of the optimization landscape under RHPG and detail the convergence and sample complexity guarantees of the algorithm. This work serves as an initial attempt to develop reinforcement learning algorithms specifically for control applications with performance guarantees by utilizing classic control theory in both algorithmic design and theoretical analyses. Lastly, we validate our theories by deploying the RHPG algorithm to learn the Kalman filter design of a large-scale convection-diffusion model. We open-source the code repository at \url{https://github.com/xiangyuan-zhang/LearningKF}.
</details>
<details>
<summary>摘要</summary>
我们介绍了落后 horizen 策略导数（RHPG）算法，这是首个可证明全球准确性的学习优化 Linear Estimator 设计算法，即卡尔曼滤波器（KF）。值得注意的是，RHPG 算法不需要任何系统的先前知识 для初始化，也不需要目标系统是开 Loop 稳定。RHPG 算法的关键在于将 vanilla PG（或任何其他策略搜索方向）integrated into a dynamic programming outer loop，这将将无限远程 KF 问题，即受约束和非对称的策略参数， decomposed into a sequence of static estimation problems that are unconstrained and strongly convex, thus enabling global convergence. 我们还提供了细化的优化景观下的 RHPG 算法的分析，并详细介绍了算法的收敛和样本复杂度保证。这项工作作为控制应用中开发强化学习算法的初步尝试，并通过利用经典控制理论在算法设计和理论分析中使用。最后，我们验证了我们的理论，通过将 RHPG 算法应用于一个大规模的扩散干扰模型来学习 Kalman 滤波器设计。我们在 GitHub 上开源了代码存储库，详情请参考 \url{https://github.com/xiangyuan-zhang/LearningKF}.
</details></li>
</ul>
<hr>
<h2 id="Good-looking-but-Lacking-Faithfulness-Understanding-Local-Explanation-Methods-through-Trend-based-Testing"><a href="#Good-looking-but-Lacking-Faithfulness-Understanding-Local-Explanation-Methods-through-Trend-based-Testing" class="headerlink" title="Good-looking but Lacking Faithfulness: Understanding Local Explanation Methods through Trend-based Testing"></a>Good-looking but Lacking Faithfulness: Understanding Local Explanation Methods through Trend-based Testing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05679">http://arxiv.org/abs/2309.05679</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jenniferho97/xai-trend-test">https://github.com/jenniferho97/xai-trend-test</a></li>
<li>paper_authors: Jinwen He, Kai Chen, Guozhu Meng, Jiangshan Zhang, Congyi Li</li>
<li>for: 本研究旨在evaluating explanation methods的实用性和 faithfulness，以及解释模型做出的决策。</li>
<li>methods: 本研究使用了三种新的趋势基测试来评估 faithfulness，并对十种受测方法进行了评估。</li>
<li>results: 研究发现，使用新的趋势基测试可以更好地评估 faithfulness，并获得了在复杂数据上的首次评估成果。 Downstream tasks也受益匪浅，例如模型调试具有 faithful explanation methods可以更好地检测和修正精度和安全问题。<details>
<summary>Abstract</summary>
While enjoying the great achievements brought by deep learning (DL), people are also worried about the decision made by DL models, since the high degree of non-linearity of DL models makes the decision extremely difficult to understand. Consequently, attacks such as adversarial attacks are easy to carry out, but difficult to detect and explain, which has led to a boom in the research on local explanation methods for explaining model decisions. In this paper, we evaluate the faithfulness of explanation methods and find that traditional tests on faithfulness encounter the random dominance problem, \ie, the random selection performs the best, especially for complex data. To further solve this problem, we propose three trend-based faithfulness tests and empirically demonstrate that the new trend tests can better assess faithfulness than traditional tests on image, natural language and security tasks. We implement the assessment system and evaluate ten popular explanation methods. Benefiting from the trend tests, we successfully assess the explanation methods on complex data for the first time, bringing unprecedented discoveries and inspiring future research. Downstream tasks also greatly benefit from the tests. For example, model debugging equipped with faithful explanation methods performs much better for detecting and correcting accuracy and security problems.
</details>
<details>
<summary>摘要</summary>
While enjoying the great achievements brought by deep learning (DL), people are also worried about the decisions made by DL models, since the high degree of non-linearity of DL models makes the decisions extremely difficult to understand. Consequently, attacks such as adversarial attacks are easy to carry out, but difficult to detect and explain, which has led to a boom in the research on local explanation methods for explaining model decisions. In this paper, we evaluate the faithfulness of explanation methods and find that traditional tests on faithfulness encounter the random dominance problem, \ie, the random selection performs the best, especially for complex data. To further solve this problem, we propose three trend-based faithfulness tests and empirically demonstrate that the new trend tests can better assess faithfulness than traditional tests on image, natural language and security tasks. We implement the assessment system and evaluate ten popular explanation methods. Benefiting from the trend tests, we successfully assess the explanation methods on complex data for the first time, bringing unprecedented discoveries and inspiring future research. Downstream tasks also greatly benefit from the tests. For example, model debugging equipped with faithful explanation methods performs much better for detecting and correcting accuracy and security problems.Here is the translation in Traditional Chinese:人们在深度学习（DL）的成就下享受着，但也担心DL模型的决策，因为DL模型的高度非线性性使得决策 extremely difficult to understand。因此，如 adversarial attack 等攻击性能易于实现，但困难检测和解释，这导致了解释模型决策的本地解释方法的研究热潮。在这篇论文中，我们评估解释方法的忠实度，发现传统的忠实度测试遇到随机主导问题，即随机选择perform the best，特别是 для复杂的数据。为了解决这个问题，我们提出了三种趋势基本的忠实度测试，并证明了这些新的趋势测试可以更好地评估忠实度 than traditional tests on image, natural language and security tasks。我们实现了评估系统，并评估了十种受欢迎的解释方法。受益于趋势测试，我们成功地评估了解释方法 on complex data for the first time，带来了前所未有的发现和未来研究的鼓励。下游任务也受益于测试。例如，具有忠实的解释方法的模型 Debugging 在检测和修正精度和安全问题上表现 Much better。
</details></li>
</ul>
<hr>
<h2 id="Timely-Fusion-of-Surround-Radar-Lidar-for-Object-Detection-in-Autonomous-Driving-Systems"><a href="#Timely-Fusion-of-Surround-Radar-Lidar-for-Object-Detection-in-Autonomous-Driving-Systems" class="headerlink" title="Timely Fusion of Surround Radar&#x2F;Lidar for Object Detection in Autonomous Driving Systems"></a>Timely Fusion of Surround Radar&#x2F;Lidar for Object Detection in Autonomous Driving Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04806">http://arxiv.org/abs/2309.04806</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenjing Xie, Tao Hu, Neiwen Ling, Guoliang Xing, Shaoshan Liu, Nan Guan<br>for: This paper aims to improve the fusion of surround Radar and Lidar sensor data for autonomous driving systems by developing techniques to work with the faster Lidar data instead of the slower Radar data.methods: The proposed method uses the state-of-the-art object detection model MVDNet to fuse surround Radar&#x2F;Lidar data, but with enhanced training to tolerate the temporal unalignment of input data.results: The proposed method achieves high output frequency with little accuracy loss, making it a promising solution for real-time object detection in autonomous driving systems.<details>
<summary>Abstract</summary>
Fusing Radar and Lidar sensor data can fully utilize their complementary advantages and provide more accurate reconstruction of the surrounding for autonomous driving systems. Surround Radar/Lidar can provide 360-degree view sampling with the minimal cost, which are promising sensing hardware solutions for autonomous driving systems. However, due to the intrinsic physical constraints, the rotating speed of surround Radar, and thus the frequency to generate Radar data frames, is much lower than surround Lidar. Existing Radar/Lidar fusion methods have to work at the low frequency of surround Radar, which cannot meet the high responsiveness requirement of autonomous driving systems.This paper develops techniques to fuse surround Radar/Lidar with working frequency only limited by the faster surround Lidar instead of the slower surround Radar, based on the state-of-the-art object detection model MVDNet. The basic idea of our approach is simple: we let MVDNet work with temporally unaligned data from Radar/Lidar, so that fusion can take place at any time when a new Lidar data frame arrives, instead of waiting for the slow Radar data frame. However, directly applying MVDNet to temporally unaligned Radar/Lidar data greatly degrades its object detection accuracy. The key information revealed in this paper is that we can achieve high output frequency with little accuracy loss by enhancing the training procedure to explore the temporal redundancy in MVDNet so that it can tolerate the temporal unalignment of input data. We explore several different ways of training enhancement and compare them quantitatively with experiments.
</details>
<details>
<summary>摘要</summary>
将雷达和激光感知器融合可以完全利用它们的优势，提供更准确的周围环境重建 для自动驾驶系统。三百六十度雷达/激光可以提供360度的视野样本，是自动驾驶系统的感知硬件解决方案。然而，由于雷达的物理限制，雷达旋转速率相对较低，因此雷达数据帧的频率远低于激光。现有的雷达/激光融合方法必须在低频率的雷达数据帧上工作，无法满足自动驾驶系统的高响应性要求。本文提出了一种解决方案，使用基于state-of-the-art对象检测模型MVDNet进行雷达/激光融合。我们的思路简单：让MVDNet在雷达/激光数据不对时进行融合，以便在新的激光数据帧到达时进行融合，而不必等待慢速的雷达数据帧。然而，直接将MVDNet应用于不对时的雷达/激光数据会导致对象检测精度下降。我们发现，可以通过强化训练程序，以利用MVDNet中的时间重复性，使其能够忍受输入数据的时间不对。我们试了多种训练强化方法，并对它们进行了量化比较。
</details></li>
</ul>
<hr>
<h2 id="Finding-Influencers-in-Complex-Networks-An-Effective-Deep-Reinforcement-Learning-Approach"><a href="#Finding-Influencers-in-Complex-Networks-An-Effective-Deep-Reinforcement-Learning-Approach" class="headerlink" title="Finding Influencers in Complex Networks: An Effective Deep Reinforcement Learning Approach"></a>Finding Influencers in Complex Networks: An Effective Deep Reinforcement Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07153">http://arxiv.org/abs/2309.07153</a></li>
<li>repo_url: None</li>
<li>paper_authors: Changan Liu, Changjun Fan, Zhongzhi Zhang</li>
<li>for: 本文针对复杂网络中Influence Maximization问题提出了一种有效的深度学习模型，以提高社会网络分析中的效果。</li>
<li>methods: 本文提出了一种结合图 neural network和强化学习的综合学习框架，名为DREIM，通过广泛的小型synthetic graphs训练，在大型synthetic和实际世界网络上超越了现有的基eline方法，并且对网络大小 linear scalability 的特性做出了实际证明。</li>
<li>results: 本文的DREIM模型在解决Influence Maximization问题时，相比现有的基eline方法，具有更高的解决质量和linear scalability 特性。<details>
<summary>Abstract</summary>
Maximizing influences in complex networks is a practically important but computationally challenging task for social network analysis, due to its NP- hard nature. Most current approximation or heuristic methods either require tremendous human design efforts or achieve unsatisfying balances between effectiveness and efficiency. Recent machine learning attempts only focus on speed but lack performance enhancement. In this paper, different from previous attempts, we propose an effective deep reinforcement learning model that achieves superior performances over traditional best influence maximization algorithms. Specifically, we design an end-to-end learning framework that combines graph neural network as the encoder and reinforcement learning as the decoder, named DREIM. Trough extensive training on small synthetic graphs, DREIM outperforms the state-of-the-art baseline methods on very large synthetic and real-world networks on solution quality, and we also empirically show its linear scalability with regard to the network size, which demonstrates its superiority in solving this problem.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将复杂网络中的影响力最大化作为社交网络分析中的实际重要任务，由于其NP困难的性质，现有的现有的近似或规则方法通常需要巨大的人工设计努力或者实现不够的效率和效果平衡。现代机器学习尝试只集中于速度，但缺乏性能提升。在这篇论文中，与之前的尝试不同，我们提出了一种高效的深度强化学习模型，可以超越传统的最佳影响最大化算法。specifically，我们设计了一个端到端学习框架，将图 neural network作为编码器和强化学习作为解码器，名为DREIM。经过广泛的小 synthetic graphs 训练，DREIM 超越了状态静态基eline 方法在很大的 sintetic 和实际网络上的解决质量，并且我们还证明其线性扩展性，表明其在解决这个问题上的优势。Note:* "NP-hard" is translated as "NP困难" (NP困难性)* "influence maximization" is translated as "影响力最大化" (影响力最大化)* "deep reinforcement learning" is translated as "深度强化学习" (深度强化学习)* "graph neural network" is translated as "图 neural network" (图 neural network)* "baseline methods" is translated as "基线方法" (基线方法)* "synthetic graphs" is translated as "小 synthetic graphs" (小 synthetic graphs)
</details></li>
</ul>
<hr>
<h2 id="Towards-Real-World-Burst-Image-Super-Resolution-Benchmark-and-Method"><a href="#Towards-Real-World-Burst-Image-Super-Resolution-Benchmark-and-Method" class="headerlink" title="Towards Real-World Burst Image Super-Resolution: Benchmark and Method"></a>Towards Real-World Burst Image Super-Resolution: Benchmark and Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04803">http://arxiv.org/abs/2309.04803</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yjsunnn/fbanet">https://github.com/yjsunnn/fbanet</a></li>
<li>paper_authors: Pengxu Wei, Yujing Sun, Xingbei Guo, Chang Liu, Jie Chen, Xiangyang Ji, Liang Lin</li>
<li>for: 本研究旨在探讨如何使用多张图像来重建高质量的图像，特别是在实际场景中。</li>
<li>methods: 我们提出了一种 Federated Burst Affinity network (FBAnet)，它使用了一种简单的投影变换来对图像进行匹配，并使用了一种 Federated Affinity Fusion (FAF) 策略来聚合帧中的相关信息。</li>
<li>results: 我们的 FBAnet 在两个版本的数据集上进行了广泛的实验，并证明了它可以超过现有的状态艺术图像重建方法，并且可以生成有趣的 SR 图像预测。我们的数据集、代码和模型都公开可用于 GitHub。<details>
<summary>Abstract</summary>
Despite substantial advances, single-image super-resolution (SISR) is always in a dilemma to reconstruct high-quality images with limited information from one input image, especially in realistic scenarios. In this paper, we establish a large-scale real-world burst super-resolution dataset, i.e., RealBSR, to explore the faithful reconstruction of image details from multiple frames. Furthermore, we introduce a Federated Burst Affinity network (FBAnet) to investigate non-trivial pixel-wise displacements among images under real-world image degradation. Specifically, rather than using pixel-wise alignment, our FBAnet employs a simple homography alignment from a structural geometry aspect and a Federated Affinity Fusion (FAF) strategy to aggregate the complementary information among frames. Those fused informative representations are fed to a Transformer-based module of burst representation decoding. Besides, we have conducted extensive experiments on two versions of our datasets, i.e., RealBSR-RAW and RealBSR-RGB. Experimental results demonstrate that our FBAnet outperforms existing state-of-the-art burst SR methods and also achieves visually-pleasant SR image predictions with model details. Our dataset, codes, and models are publicly available at https://github.com/yjsunnn/FBANet.
</details>
<details>
<summary>摘要</summary>
尽管已经取得了重要进步，单一图像超分解 (SISR) 仍然面临着从一个输入图像中重建高质量图像的挑战，特别是在实际场景下。在这篇论文中，我们建立了一个大规模的实际场景中的爆发超分解数据集，即RealBSR，以探索图像细节的忠实重建。此外，我们引入了一种 Federated Burst Affinity network (FBAnet)，以探索实际场景下图像的非致命像素位移。具体来说，而不是使用像素位移对 align，我们的FBAnet使用了一种简单的投影变换的结构几何学方面的同步方法，并使用一种 Federated Affinity Fusion (FAF) 策略来聚合各帧中的补充信息。这些融合的信息表示被 fed 到一个基于 Transformer 的强制代码帧表示解码模块。此外，我们在 RealBSR-RAW 和 RealBSR-RGB 两个版本的数据集上进行了广泛的实验，结果表明，我们的 FBAnet 超过了现有的推荐爆发 SR 方法，并且实现了可见愉悦 SR 图像预测，同时保持模型细节。我们的数据集、代码和模型都可以在 GitHub 上公开获取，链接在https://github.com/yjsunnn/FBANet。
</details></li>
</ul>
<hr>
<h2 id="CPMR-Context-Aware-Incremental-Sequential-Recommendation-with-Pseudo-Multi-Task-Learning"><a href="#CPMR-Context-Aware-Incremental-Sequential-Recommendation-with-Pseudo-Multi-Task-Learning" class="headerlink" title="CPMR: Context-Aware Incremental Sequential Recommendation with Pseudo-Multi-Task Learning"></a>CPMR: Context-Aware Incremental Sequential Recommendation with Pseudo-Multi-Task Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04802">http://arxiv.org/abs/2309.04802</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dimarziobian/cpmr">https://github.com/dimarziobian/cpmr</a></li>
<li>paper_authors: Qingtian Bian, Jiaxing Xu, Hui Fang, Yiping Ke</li>
<li>for: 模型用户表征的动态兴趣环境，即用户在不同时间和上下文中的行为。</li>
<li>methods: 使用信息传播和进化来挖掘批处理的交互数据，并创建用户和物品的三个表示：静态嵌入、历史时间状态和Contextual时间状态。</li>
<li>results: 在四个标准推荐数据集上实验表明，CPMR可以持续超越当前状态艺术的基eline，并在三个数据集上 achieve 显著的提升。<details>
<summary>Abstract</summary>
The motivations of users to make interactions can be divided into static preference and dynamic interest. To accurately model user representations over time, recent studies in sequential recommendation utilize information propagation and evolution to mine from batches of arriving interactions. However, they ignore the fact that people are easily influenced by the recent actions of other users in the contextual scenario, and applying evolution across all historical interactions dilutes the importance of recent ones, thus failing to model the evolution of dynamic interest accurately. To address this issue, we propose a Context-Aware Pseudo-Multi-Task Recommender System (CPMR) to model the evolution in both historical and contextual scenarios by creating three representations for each user and item under different dynamics: static embedding, historical temporal states, and contextual temporal states. To dually improve the performance of temporal states evolution and incremental recommendation, we design a Pseudo-Multi-Task Learning (PMTL) paradigm by stacking the incremental single-target recommendations into one multi-target task for joint optimization. Within the PMTL paradigm, CPMR employs a shared-bottom network to conduct the evolution of temporal states across historical and contextual scenarios, as well as the fusion of them at the user-item level. In addition, CPMR incorporates one real tower for incremental predictions, and two pseudo towers dedicated to updating the respective temporal states based on new batches of interactions. Experimental results on four benchmark recommendation datasets show that CPMR consistently outperforms state-of-the-art baselines and achieves significant gains on three of them. The code is available at: https://github.com/DiMarzioBian/CPMR.
</details>
<details>
<summary>摘要</summary>
用户的动机可以分为静态喜好和动态兴趣。为了准确地模型用户在时间上的表现，现在的研究在串行推荐中使用信息传播和进化来 mines 从到达的交互批处理。然而，它们忽略了人们在场景下的受到他人最近行为影响的事实，并且在所有历史交互上应用进化，从而不能准确地模型动态兴趣的演化。为解决这个问题，我们提出了Context-Aware Pseudo-Multi-Task Recommender System (CPMR)，用于在历史和场景下模型用户和ITEM的演化。我们设计了三种表示方法：静态嵌入、历史时间状态和场景时间状态。为了提高时间状态演化和逐步推荐的性能，我们实现了一种Pseudo-Multi-Task Learning (PMTL) paradigm，其中CPMR使用一个共享底层网络来进行时间状态的演化和用户-ITEM级别的 fusión。此外，CPMR还包括一个真实的射频塔来进行逐步预测，以及两个 Pseudo 射频塔来更新各自的时间状态基于新批处理的交互。实验结果表明，CPMR在四个基准推荐数据集上具有显著的优势，并在三个基准上达到了显著的提升。代码可以在https://github.com/DiMarzioBian/CPMR 中获取。
</details></li>
</ul>
<hr>
<h2 id="TMComposites-Plug-and-Play-Collaboration-Between-Specialized-Tsetlin-Machines"><a href="#TMComposites-Plug-and-Play-Collaboration-Between-Specialized-Tsetlin-Machines" class="headerlink" title="TMComposites: Plug-and-Play Collaboration Between Specialized Tsetlin Machines"></a>TMComposites: Plug-and-Play Collaboration Between Specialized Tsetlin Machines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04801">http://arxiv.org/abs/2309.04801</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cair/plug-and-play-collaboration-between-specialized-tsetlin-machines">https://github.com/cair/plug-and-play-collaboration-between-specialized-tsetlin-machines</a></li>
<li>paper_authors: Ole-Christoffer Granmo</li>
<li>for: 提高TM的性能在更复杂的任务和数据集上，例如CIFAR-10和CIFAR-100。</li>
<li>methods: 特有的TM Composites的协作，通过学习和推理时的特有精度评估来实现。</li>
<li>results: 在Fashion-MNIST、CIFAR-10和CIFAR-100上提高了准确率， Specifically, the TM Composite increased accuracy on Fashion-MNIST by 2 percentage points, CIFAR-10 by 12 points, and CIFAR-100 by 9 points, achieving new state-of-the-art results for TMs.<details>
<summary>Abstract</summary>
Tsetlin Machines (TMs) provide a fundamental shift from arithmetic-based to logic-based machine learning. Supporting convolution, they deal successfully with image classification datasets like MNIST, Fashion-MNIST, and CIFAR-2. However, the TM struggles with getting state-of-the-art performance on CIFAR-10 and CIFAR-100, representing more complex tasks. This paper introduces plug-and-play collaboration between specialized TMs, referred to as TM Composites. The collaboration relies on a TM's ability to specialize during learning and to assess its competence during inference. When teaming up, the most confident TMs make the decisions, relieving the uncertain ones. In this manner, a TM Composite becomes more competent than its members, benefiting from their specializations. The collaboration is plug-and-play in that members can be combined in any way, at any time, without fine-tuning. We implement three TM specializations in our empirical evaluation: Histogram of Gradients, Adaptive Gaussian Thresholding, and Color Thermometers. The resulting TM Composite increases accuracy on Fashion-MNIST by two percentage points, CIFAR-10 by twelve points, and CIFAR-100 by nine points, yielding new state-of-the-art results for TMs. Overall, we envision that TM Composites will enable an ultra-low energy and transparent alternative to state-of-the-art deep learning on more tasks and datasets.
</details>
<details>
<summary>摘要</summary>
特具机器 (TM) 提供了一个基本的转换，从数学基础到逻辑基础的机器学习。它们可以成功地处理像 Minnist、Fashion-Minnist 和 CIFAR-2 这些图像分类 dataset，但是它们对 CIFAR-10 和 CIFAR-100 这些更加复杂的任务表现不佳。这篇论文介绍了特殊化的 TM 之间的协作，称为 TM Composites。这种协作基于 TM 的学习中的特殊化和推断中的能力评估。当它们合作时，最自信的 TM 会作出决策，减轻不确定的 TM。因此，一个 TM Composite 会比其成员更有能力，从其特殊化中受益。这种协作是可插入式的，成员可以在任何时候、任何方式混合，不需要微调。我们在实验中实现了三种 TM 特殊化： Histogram of Gradients、Adaptive Gaussian Thresholding 和 Color Thermometers。它们的结合使得 Fashion-MNIST 的准确率提高了二个百分比点，CIFAR-10 的准确率提高了十二个百分比点，CIFAR-100 的准确率提高了九个百分比点，创造了新的state-of-the-art 结果。总的来说，我们预期 TM Composites 将在更多的任务和数据集上提供低能耗和透明的替代方案。
</details></li>
</ul>
<hr>
<h2 id="A-Fast-Algorithm-for-Moderating-Critical-Nodes-via-Edge-Removal"><a href="#A-Fast-Algorithm-for-Moderating-Critical-Nodes-via-Edge-Removal" class="headerlink" title="A Fast Algorithm for Moderating Critical Nodes via Edge Removal"></a>A Fast Algorithm for Moderating Critical Nodes via Edge Removal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06392">http://arxiv.org/abs/2309.06392</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hahaabc/fasticm">https://github.com/hahaabc/fasticm</a></li>
<li>paper_authors: Changan Liu, Xiaotian Zhou, Ahad N. Zehmakan, Zhongzhi Zhang</li>
<li>for: 本研究旨在提高网络中执行有效的moderation，以避免由于恶意扩散而导致的负面响应。</li>
<li>methods: 本研究使用新的技术，如random walk-based Schur complement approximation和快速和简单的和计算方法，提出三种近似算法来解决这个问题。</li>
<li>results: 实验结果表明，我们提出的算法在不同的设定下具有高效性和可靠性，能够有效地减少网络中执行moderation的计算成本。<details>
<summary>Abstract</summary>
Critical nodes in networks are extremely vulnerable to malicious attacks to trigger negative cascading events such as the spread of misinformation and diseases. Therefore, effective moderation of critical nodes is very vital for mitigating the potential damages caused by such malicious diffusions. The current moderation methods are computationally expensive. Furthermore, they disregard the fundamental metric of information centrality, which measures the dissemination power of nodes.   We investigate the problem of removing $k$ edges from a network to minimize the information centrality of a target node $\lea$ while preserving the network's connectivity. We prove that this problem is computationally challenging: it is NP-complete and its objective function is not supermodular. However, we propose three approximation greedy algorithms using novel techniques such as random walk-based Schur complement approximation and fast sum estimation. One of our algorithms runs in nearly linear time in the number of edges.   To complement our theoretical analysis, we conduct a comprehensive set of experiments on synthetic and real networks with over one million nodes. Across various settings, the experimental results illustrate the effectiveness and efficiency of our proposed algorithms.
</details>
<details>
<summary>摘要</summary>
重要的网络中的节点非常易受到黑客攻击，导致负面传播事件的发生，如误information和疾病的传播。因此，有效地调节重要节点非常重要，以减少这些黑客攻击导致的潜在损害。现有的调节方法 computationally expensive，而且忽略了信息中心度的基本度量，它度量节点传播力。我们研究了从网络中移除 $k$ 个边，以使Target node $\lea$ 的信息中心度最小化，保持网络连接性。我们证明这个问题是 computationally challenging：它是NP-complete，并且其目标函数不具有supermodular。然而，我们提出了三种近似算法，使用了新的技术，如Random walk-based Schur complement approximation和快速总和估计。其中一个算法在 Nearly linear time 中处理了 edges。实际上，我们对实际和 sintetic 网络进行了广泛的实验，包括超过一百万个节点。不同的设定下，实验结果显示了我们的提案的有效性和高效性。
</details></li>
</ul>
<hr>
<h2 id="A-Full-fledged-Commit-Message-Quality-Checker-Based-on-Machine-Learning"><a href="#A-Full-fledged-Commit-Message-Quality-Checker-Based-on-Machine-Learning" class="headerlink" title="A Full-fledged Commit Message Quality Checker Based on Machine Learning"></a>A Full-fledged Commit Message Quality Checker Based on Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04797">http://arxiv.org/abs/2309.04797</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/commit-message-collective/beams-commit-message-checker">https://github.com/commit-message-collective/beams-commit-message-checker</a></li>
<li>paper_authors: David Faragó, Michael Färber, Christian Petrov</li>
<li>for: 这篇论文是关于提高版本控制中的提交信息质量的研究，以便更好地支持软件维护和演化。</li>
<li>methods: 该论文使用机器学习方法来评估提交信息质量，包括语义和上下文。</li>
<li>results: 该论文可以够准确地评估提交信息质量，其最低F$_1$分为82.9%，这表明机器学习方法可以很好地评估提交信息质量。<details>
<summary>Abstract</summary>
Commit messages (CMs) are an essential part of version control. By providing important context in regard to what has changed and why, they strongly support software maintenance and evolution. But writing good CMs is difficult and often neglected by developers. So far, there is no tool suitable for practice that automatically assesses how well a CM is written, including its meaning and context. Since this task is challenging, we ask the research question: how well can the CM quality, including semantics and context, be measured with machine learning methods? By considering all rules from the most popular CM quality guideline, creating datasets for those rules, and training and evaluating state-of-the-art machine learning models to check those rules, we can answer the research question with: sufficiently well for practice, with the lowest F$_1$ score of 82.9\%, for the most challenging task. We develop a full-fledged open-source framework that checks all these CM quality rules. It is useful for research, e.g., automatic CM generation, but most importantly for software practitioners to raise the quality of CMs and thus the maintainability and evolution speed of their software.
</details>
<details>
<summary>摘要</summary>
commit messages (CMs) 是版本控制中非常重要的一部分，它们提供了更改的重要上下文和原因，从而强化软件维护和演化。然而，写好CMs是很困难的，开发者们经常忽略这一点。迄今为止，没有一种适合实践的工具可以自动评估CM质量，包括它的 semantics 和context。由于这是一项具有挑战性的任务，我们提出了研究问题：可以使用机器学习方法来评估CM质量，包括 semantics 和context？我们考虑了最流行的CM质量指南中的所有规则，创建了相应的数据集，并使用当今最佳的机器学习模型来检查这些规则。我们的研究表明，使用机器学习方法可以很好地评估CM质量，最低的F1分数为82.9%，对最复杂的任务来说。我们开发了一套免费、开源的框架，可以检查所有CM质量规则。它可以用于研究，例如自动生成CM，但更重要的是，它可以帮助软件实践者提高CM质量，从而提高软件的维护和演化速度。
</details></li>
</ul>
<hr>
<h2 id="Towards-Robust-Model-Watermark-via-Reducing-Parametric-Vulnerability"><a href="#Towards-Robust-Model-Watermark-via-Reducing-Parametric-Vulnerability" class="headerlink" title="Towards Robust Model Watermark via Reducing Parametric Vulnerability"></a>Towards Robust Model Watermark via Reducing Parametric Vulnerability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04777">http://arxiv.org/abs/2309.04777</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/guanhaogan/robust-model-watermarking">https://github.com/guanhaogan/robust-model-watermarking</a></li>
<li>paper_authors: Guanhao Gan, Yiming Li, Dongxian Wu, Shu-Tao Xia</li>
<li>for: 保护深度神经网络（DNN）的版权，防止其被不当使用或盗取。</li>
<li>methods: 使用后门式拓展来嵌入特定的行为，以便在发布模型时验证其所有权。</li>
<li>results: 提出了一种基于最大化最小化的方法，可以在 parametric 变化和许多后门除法攻击下提高模型水印的稳定性。<details>
<summary>Abstract</summary>
Deep neural networks are valuable assets considering their commercial benefits and huge demands for costly annotation and computation resources. To protect the copyright of DNNs, backdoor-based ownership verification becomes popular recently, in which the model owner can watermark the model by embedding a specific backdoor behavior before releasing it. The defenders (usually the model owners) can identify whether a suspicious third-party model is ``stolen'' from them based on the presence of the behavior. Unfortunately, these watermarks are proven to be vulnerable to removal attacks even like fine-tuning. To further explore this vulnerability, we investigate the parameter space and find there exist many watermark-removed models in the vicinity of the watermarked one, which may be easily used by removal attacks. Inspired by this finding, we propose a mini-max formulation to find these watermark-removed models and recover their watermark behavior. Extensive experiments demonstrate that our method improves the robustness of the model watermarking against parametric changes and numerous watermark-removal attacks. The codes for reproducing our main experiments are available at \url{https://github.com/GuanhaoGan/robust-model-watermarking}.
</details>
<details>
<summary>摘要</summary>
深度神经网络是商业上非常有价值的资产，同时它们需要大量的昂贵的注解和计算资源。为了保护深度神经网络的版权，在最近几年，以特定的后门行为为水印的拥有者认可方式在使用。但是这些水印却被证明容易受到移除攻击，甚至是通过精细调整。为了进一步探索这一点，我们研究了参数空间，发现在水印模型附近存在许多没有水印的模型，这些模型可能被用于移除攻击。受这一发现的启发，我们提出了一种最大化-最小化的形式来找到这些没有水印的模型，并恢复它们的水印行为。我们的方法可以提高模型水印的对 Parametric 变化和许多水印移除攻击的Robustness。codes for reproducing our main experiments are available at \url{https://github.com/GuanhaoGan/robust-model-watermarking}.
</details></li>
</ul>
<hr>
<h2 id="SeaEval-for-Multilingual-Foundation-Models-From-Cross-Lingual-Alignment-to-Cultural-Reasoning"><a href="#SeaEval-for-Multilingual-Foundation-Models-From-Cross-Lingual-Alignment-to-Cultural-Reasoning" class="headerlink" title="SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning"></a>SeaEval for Multilingual Foundation Models: From Cross-Lingual Alignment to Cultural Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04766">http://arxiv.org/abs/2309.04766</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bin Wang, Zhengyuan Liu, Xin Huang, Fangkai Jiao, Yang Ding, Ai Ti Aw, Nancy F. Chen</li>
<li>for: 本文提出了一个多语言基础模型的benchmark，以探讨这些模型对自然语言理解和reasong的能力，以及它们对文化实践、细节和价值观的理解。</li>
<li>methods: 本文使用了标准的准确度指标以外的其他方法来评估基础模型的稳定性和多语言能力。</li>
<li>results: 研究发现了许多基础模型具有异常的行为，如重复提供的指令、位置偏好和主流标签偏好。此外，许多模型在根据factual、科学和常识知识提问时表现不一致。<details>
<summary>Abstract</summary>
We present SeaEval, a benchmark for multilingual foundation models. In addition to characterizing how these models understand and reason with natural language, we also investigate how well they comprehend cultural practices, nuances, and values. Alongside standard accuracy metrics, we investigate the brittleness of foundation models in the dimensions of semantics and multilinguality. Our analyses span both open-sourced and closed models, leading to empirical results across classic NLP tasks, reasoning, and cultural comprehension. Key findings indicate (1) Most models exhibit varied behavior when given paraphrased instructions. (2) Many models still suffer from exposure bias (e.g., positional bias, majority label bias). (3) For questions rooted in factual, scientific, and commonsense knowledge, consistent responses are expected across multilingual queries that are semantically equivalent. Yet, most models surprisingly demonstrate inconsistent performance on these queries. (4) Multilingually-trained models have not attained "balanced multilingual" capabilities. Our endeavors underscore the need for more generalizable semantic representations and enhanced multilingual contextualization. SeaEval can serve as a launchpad for more thorough investigations and evaluations for multilingual and multicultural scenarios.
</details>
<details>
<summary>摘要</summary>
我们介绍了 SeaEval，一个多语言基础模型的benchmark。除了描述这些模型如何理解和处理自然语言之外，我们还研究了这些模型如何理解文化做法、细节和价值观。与标准精度指标相结合，我们调查基础模型在语义和多语言方面的脆弱性。我们的分析覆盖了开源和关闭模型，从经典NLP任务、理解到文化理解方面得到了实证结果。关键发现包括：1. 大多数模型对提供重叠 instrucciones 时表现不同。2. 许多模型仍然受到露天偏见（例如位置偏见、多数标签偏见）的影响。3. 根据Factual、科学和通俗知识而问的问题，多语言查询的semantic相同性预期得到一致的回答。然而，大多数模型却在这些查询上表现不一致。4. 多语言训练的模型尚未 дости到了"平衡多语言"的能力。我们的努力强调了需要更加通用的semantic表示和多语言contextualization。 SeaEval可以作为多语言和多文化enario的评估和研究的起点。
</details></li>
</ul>
<hr>
<h2 id="AudRandAug-Random-Image-Augmentations-for-Audio-Classification"><a href="#AudRandAug-Random-Image-Augmentations-for-Audio-Classification" class="headerlink" title="AudRandAug: Random Image Augmentations for Audio Classification"></a>AudRandAug: Random Image Augmentations for Audio Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04762">http://arxiv.org/abs/2309.04762</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/turab45/audrandaug">https://github.com/turab45/audrandaug</a></li>
<li>paper_authors: Teerath Kumar, Muhammad Turab, Alessandra Mileo, Malika Bendechache, Takfarinas Saber</li>
<li>for: 这篇论文主要用于探讨对数据进行资料增强的方法，并提出了一种基于搜索空间的随机数据增强方法（AudRandAug）。</li>
<li>methods: 这篇论文使用了一种基于搜索空间的随机数据增强方法（AudRandAug）， randomly selecting data augmentation techniques from a dedicated audio search space。</li>
<li>results: 根据我们的实验结果，AudRandAug 比其他现有的数据增强方法有着更高的精度表现。<details>
<summary>Abstract</summary>
Data augmentation has proven to be effective in training neural networks. Recently, a method called RandAug was proposed, randomly selecting data augmentation techniques from a predefined search space. RandAug has demonstrated significant performance improvements for image-related tasks while imposing minimal computational overhead. However, no prior research has explored the application of RandAug specifically for audio data augmentation, which converts audio into an image-like pattern. To address this gap, we introduce AudRandAug, an adaptation of RandAug for audio data. AudRandAug selects data augmentation policies from a dedicated audio search space. To evaluate the effectiveness of AudRandAug, we conducted experiments using various models and datasets. Our findings indicate that AudRandAug outperforms other existing data augmentation methods regarding accuracy performance.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate "Data augmentation has proven to be effective in training neural networks. Recently, a method called RandAug was proposed, randomly selecting data augmentation techniques from a predefined search space. RandAug has demonstrated significant performance improvements for image-related tasks while imposing minimal computational overhead. However, no prior research has explored the application of RandAug specifically for audio data augmentation, which converts audio into an image-like pattern. To address this gap, we introduce AudRandAug, an adaptation of RandAug for audio data. AudRandAug selects data augmentation policies from a dedicated audio search space. To evaluate the effectiveness of AudRandAug, we conducted experiments using various models and datasets. Our findings indicate that AudRandAug outperforms other existing data augmentation methods regarding accuracy performance." into 简化中文。Here's the translation:数据增强已经证明对神经网络训练是有效的。最近，一种方法called RandAug被提出，随机从预定搜索空间中选择数据增强策略。RandAug在图像相关任务上表现出了显著的性能提升，而且对计算负担的要求非常低。然而，没有任何之前的研究探讨了将RandAug特地应用于音频数据增强，这将音频转换成图像类似的模式。为了填补这一漏洞，我们介绍了AudRandAug，它是RandAug的音频数据增强版本。AudRandAug从专门的音频搜索空间中选择数据增强策略。为了评估AudRandAug的效果，我们使用了不同的模型和数据集进行实验。我们的发现表明，AudRandAug在准确性表现方面超过了其他现有的数据增强方法。
</details></li>
</ul>
<hr>
<h2 id="RR-CP-Reliable-Region-Based-Conformal-Prediction-for-Trustworthy-Medical-Image-Classification"><a href="#RR-CP-Reliable-Region-Based-Conformal-Prediction-for-Trustworthy-Medical-Image-Classification" class="headerlink" title="RR-CP: Reliable-Region-Based Conformal Prediction for Trustworthy Medical Image Classification"></a>RR-CP: Reliable-Region-Based Conformal Prediction for Trustworthy Medical Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04760">http://arxiv.org/abs/2309.04760</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yizhe Zhang, Shuo Wang, Yejia Zhang, Danny Z. Chen</li>
<li>for: 提高医疗AI模型的准确率和可靠性，以便更好地与人类专家合作。</li>
<li>methods: 基于可靠区域的均衡预测（RR-CP）技术，以实现用户指定的错误率（例如0.5%），并且在这种约束下优化预测集的大小。</li>
<li>results: 在五个公共数据集上进行了实验，并显示了RR-CP在实现用户指定的错误率（例如0.5%）的情况下， prediction set 的大小相对较小，而且可靠性较高。<details>
<summary>Abstract</summary>
Conformal prediction (CP) generates a set of predictions for a given test sample such that the prediction set almost always contains the true label (e.g., 99.5\% of the time). CP provides comprehensive predictions on possible labels of a given test sample, and the size of the set indicates how certain the predictions are (e.g., a set larger than one is `uncertain'). Such distinct properties of CP enable effective collaborations between human experts and medical AI models, allowing efficient intervention and quality check in clinical decision-making. In this paper, we propose a new method called Reliable-Region-Based Conformal Prediction (RR-CP), which aims to impose a stronger statistical guarantee so that the user-specified error rate (e.g., 0.5\%) can be achieved in the test time, and under this constraint, the size of the prediction set is optimized (to be small). We consider a small prediction set size an important measure only when the user-specified error rate is achieved. Experiments on five public datasets show that our RR-CP performs well: with a reasonably small-sized prediction set, it achieves the user-specified error rate (e.g., 0.5\%) significantly more frequently than exiting CP methods.
</details>
<details>
<summary>摘要</summary>
具有预测集的具体预测（CP）生成一个测试样本的预测集，使得预测集中的真实标签几乎总是包含true label（例如，99.5%的时间）。CP提供了测试样本的可能性标签的全面预测，预测集的大小表示预测的certainty（例如，大于一的集是“uncertain”）。CP的特有性使得人类专家和医疗AI模型之间的合作更加有效， allowing for efficient intervention and quality check in clinical decision-making.在这篇论文中，我们提出了一种新的方法called Reliable-Region-Based Conformal Prediction (RR-CP)，旨在在测试时间内实现用户指定的错误率（例如，0.5%），并在这个约束下优化预测集的大小。我们认为小的预测集大小是重要的度量，只当用户指定的错误率得到实现时。在五个公共数据集上进行了实验，我们的RR-CP表现良好：与相对较小的预测集大小，它可以 achieve用户指定的错误率（例如，0.5%），与现有CP方法相比，significantly more frequently。
</details></li>
</ul>
<hr>
<h2 id="Towards-Real-time-Training-of-Physics-informed-Neural-Networks-Applications-in-Ultrafast-Ultrasound-Blood-Flow-Imaging"><a href="#Towards-Real-time-Training-of-Physics-informed-Neural-Networks-Applications-in-Ultrafast-Ultrasound-Blood-Flow-Imaging" class="headerlink" title="Towards Real-time Training of Physics-informed Neural Networks: Applications in Ultrafast Ultrasound Blood Flow Imaging"></a>Towards Real-time Training of Physics-informed Neural Networks: Applications in Ultrafast Ultrasound Blood Flow Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04755">http://arxiv.org/abs/2309.04755</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haotian Guan, Jinping Dong, Wei-Ning Lee</li>
<li>for: 解决 Navier-Stokes 方程，即血液流动方程</li>
<li>methods: 使用 Physics-informed Neural Network (PINN) 和 SeqPINN 方法</li>
<li>results: 实现了血液流动速度的Recovery，并且比原始设计快速多少Here’s the full translation of the abstract in Simplified Chinese:</li>
<li>for: 本文使用 Physics-informed Neural Network (PINN) 方法解决 Navier-Stokes 方程，即血液流动方程，但现有方法不适用于 ultrafast Doppler 超音波，这是血液流动动态图像的 estado-of-the-art 技术。</li>
<li>methods: 本文提出了一种新的训练框架，称为 SeqPINN，它通过稠密化 Navier-Stokes 方程，并采用转移学习来解决稠密化 Navier-Stokes 方程。此外，本文还提出了一种新的初始化方法，称为 SP-PINN，它通过权重抽象和随机梯度下降来初始化 PINN。</li>
<li>results: 对于单血管和 trifurcate 血管的 Finite-element 模拟和 \emph{in vitro} 血液模型，SeqPINN 和 SP-PINN 都能够快速地解决血液流动速度的问题，而且它们分别对 straight 血管和 trifurcate 血管的 RMSE 分别为 1.01 cm&#x2F;s 和 1.26 cm&#x2F;s，和 1.91 cm&#x2F;s 和 2.56 cm&#x2F;s。<details>
<summary>Abstract</summary>
Physics-informed Neural Network (PINN) is one of the most preeminent solvers of Navier-Stokes equations, which are widely used as the governing equation of blood flow. However, current approaches, relying on full Navier-Stokes equations, are impractical for ultrafast Doppler ultrasound, the state-of-the-art technique for depiction of complex blood flow dynamics \emph{in vivo} through acquired thousands of frames (or, timestamps) per second. In this article, we first propose a novel training framework of PINN for solving Navier-Stokes equations by discretizing Navier-Stokes equations into steady state and sequentially solving steady-state Navier-Stokes equations with transfer learning. The novel training framework is coined as SeqPINN. Upon the success of SeqPINN, we adopt the idea of averaged constant stochastic gradient descent (SGD) as initialization and propose a parallel training scheme for all timestamps. To ensure an initialization that generalizes well, we borrow the concept of Stochastic Weight Averaging Gaussian to perform uncertainty estimation as an indicator of generalizability of the initialization. This algorithm, named SP-PINN, further expedites training of PINN while achieving comparable accuracy with SeqPINN. Finite-element simulations and \emph{in vitro} phantoms of single-branch and trifurcate blood vessels are used to evaluate the performance of SeqPINN and SP-PINN. Results show that both SeqPINN and SP-PINN are manyfold faster than the original design of PINN, while respectively achieving Root Mean Square Errors (RMSEs) of 1.01 cm/s and 1.26 cm/s on the straight vessel and 1.91 cm/s and 2.56 cm/s on the trifurcate blood vessel when recovering blood flow velocities.
</details>
<details>
<summary>摘要</summary>
物理学信息化神经网络（PINN）是 Navier-Stokes 方程的一种最优解，广泛用于血液流动的研究。然而，现有的方法，基于全 Navier-Stokes 方程，对于高速Doppler超音波扫描（ultrafast Doppler ultrasound）来说是不实用的。在这篇文章中，我们首先提出了一种新的训练框架，称为SeqPINN，用于解决 Navier-Stokes 方程。我们将 Navier-Stokes 方程精度化为稳定态，并采用转移学习来逐渐解决稳定态 Navier-Stokes 方程。这种训练框架是SeqPINN。成功SeqPINN之后，我们采用了averaged constant stochastic gradient descent（SGD）的初始化，并提出了并行训练方案。为确保一个初始化能够通用，我们借鉴了Stochastic Weight Averaging Gaussian（SWAG）来进行uncertainty estimation，这个算法被称为SP-PINN。SP-PINN可以更快地训练 PINN，而且可以达到与SeqPINN相同的准确性。在finite-element simulations和�emph;in vitro�emph; phantoms中，我们使用了单臂和 trifurcate 血管来评估SeqPINN和SP-PINN的性能。结果显示，SeqPINN和SP-PINN都比原始 PINN 快得多，同时分别在直流血管和 trifurcate 血管中的Root Mean Square Errors（RMSE）分别为1.01 cm/s和1.26 cm/s，以及1.91 cm/s和2.56 cm/s。
</details></li>
</ul>
<hr>
<h2 id="A-Spatiotemporal-Deep-Neural-Network-for-Fine-Grained-Multi-Horizon-Wind-Prediction"><a href="#A-Spatiotemporal-Deep-Neural-Network-for-Fine-Grained-Multi-Horizon-Wind-Prediction" class="headerlink" title="A Spatiotemporal Deep Neural Network for Fine-Grained Multi-Horizon Wind Prediction"></a>A Spatiotemporal Deep Neural Network for Fine-Grained Multi-Horizon Wind Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04733">http://arxiv.org/abs/2309.04733</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hfl15/windpred">https://github.com/hfl15/windpred</a></li>
<li>paper_authors: Fanling Huang, Yangdong Deng</li>
<li>for: 预测风速和方向，即多种实际应用中的关键因素，如航空和风力发电等。</li>
<li>methods: 提出了一种新的数据驱动模型，即多个深度神经网络组合体系（MHSTN），用于准确和高效地预测细详风速和方向。</li>
<li>results: 模型的评估结果表明，与竞争对手相比，MHSTN具有显著的优势，并且已经在中国一个最繁忙的国际机场的调度平台中实现了集成。<details>
<summary>Abstract</summary>
The prediction of wind in terms of both wind speed and direction, which has a crucial impact on many real-world applications like aviation and wind power generation, is extremely challenging due to the high stochasticity and complicated correlation in the weather data. Existing methods typically focus on a sub-set of influential factors and thus lack a systematic treatment of the problem. In addition, fine-grained forecasting is essential for efficient industry operations, but has been less attended in the literature. In this work, we propose a novel data-driven model, Multi-Horizon SpatioTemporal Network (MHSTN), generally for accurate and efficient fine-grained wind prediction. MHSTN integrates multiple deep neural networks targeting different factors in a sequence-to-sequence (Seq2Seq) backbone to effectively extract features from various data sources and produce multi-horizon predictions for all sites within a given region. MHSTN is composed of four major modules. First, a temporal module fuses coarse-grained forecasts derived by Numerical Weather Prediction (NWP) and historical on-site observation data at stations so as to leverage both global and local atmospheric information. Second, a spatial module exploits spatial correlation by modeling the joint representation of all stations. Third, an ensemble module weighs the above two modules for final predictions. Furthermore, a covariate selection module automatically choose influential meteorological variables as initial input. MHSTN is already integrated into the scheduling platform of one of the busiest international airports of China. The evaluation results demonstrate that our model outperforms competitors by a significant margin.
</details>
<details>
<summary>摘要</summary>
各种因素的预测，包括风速和方向，对许多现实生活中的应用，如航空和风力发电，是极其困难的。这是因为天气数据中存在高度的随机性和复杂的相关性。现有的方法通常只关注一 subset of 影响因素，因此缺乏一个系统性的处理方法。另外，细化预测是业务操作的效率化的关键，但在文献中得到了更少的关注。在这项工作中，我们提出了一种新的数据驱动模型，即多个顺序时空网络（Multi-Horizon SpatioTemporal Network，MHSTN），用于准确和效率地进行细化风预测。MHSTN 模型包括四个主要模块。首先，一个时间模块将 numerical weather prediction（NWP） 和历史站点观测数据 fusion 以利用全球和地方大气信息。其次，一个空间模块利用空间相关性，模型所有站点的联合表示。第三，一个ensemble模块将上述两个模块进行最终预测。最后，一个 covariate 选择模块自动选择影响大气变量的关键变量作为输入。MHSTN 模型已经成功 интеGRATED 到了中国一个最繁忙的国际机场的调度平台。评估结果表明，我们的模型在竞争对手之上显著超越。
</details></li>
</ul>
<hr>
<h2 id="TCGAN-Convolutional-Generative-Adversarial-Network-for-Time-Series-Classification-and-Clustering"><a href="#TCGAN-Convolutional-Generative-Adversarial-Network-for-Time-Series-Classification-and-Clustering" class="headerlink" title="TCGAN: Convolutional Generative Adversarial Network for Time Series Classification and Clustering"></a>TCGAN: Convolutional Generative Adversarial Network for Time Series Classification and Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04732">http://arxiv.org/abs/2309.04732</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://bitbucket.org/lynn1/tcgan">https://bitbucket.org/lynn1/tcgan</a></li>
<li>paper_authors: Fanling Huang, Yangdong Deng</li>
<li>for: 本文旨在提出一种时序卷积神经网络（TCGAN），用于不监督地学习时序数据的层次表示。</li>
<li>methods: TCGAN 通过两个一维卷积神经网络（生成器和分类器）进行对抗游戏学习，不需要标注数据。</li>
<li>results: 对 synthetic 和实际世界数据进行了广泛的实验，结果表明 TCGAN 比现有的时序 GAN 更快速和更准确。学习得到的表示能够提高简单的分类和归一化方法的性能，并在具有少量标注和不均匀标注的情况下保持高效。<details>
<summary>Abstract</summary>
Recent works have demonstrated the superiority of supervised Convolutional Neural Networks (CNNs) in learning hierarchical representations from time series data for successful classification. These methods require sufficiently large labeled data for stable learning, however acquiring high-quality labeled time series data can be costly and potentially infeasible. Generative Adversarial Networks (GANs) have achieved great success in enhancing unsupervised and semi-supervised learning. Nonetheless, to our best knowledge, it remains unclear how effectively GANs can serve as a general-purpose solution to learn representations for time series recognition, i.e., classification and clustering. The above considerations inspire us to introduce a Time-series Convolutional GAN (TCGAN). TCGAN learns by playing an adversarial game between two one-dimensional CNNs (i.e., a generator and a discriminator) in the absence of label information. Parts of the trained TCGAN are then reused to construct a representation encoder to empower linear recognition methods. We conducted comprehensive experiments on synthetic and real-world datasets. The results demonstrate that TCGAN is faster and more accurate than existing time-series GANs. The learned representations enable simple classification and clustering methods to achieve superior and stable performance. Furthermore, TCGAN retains high efficacy in scenarios with few-labeled and imbalanced-labeled data. Our work provides a promising path to effectively utilize abundant unlabeled time series data.
</details>
<details>
<summary>摘要</summary>
Recent research has shown that supervised Convolutional Neural Networks (CNNs) can learn hierarchical representations from time series data for successful classification. However, acquiring high-quality labeled time series data can be costly and potentially infeasible. Generative Adversarial Networks (GANs) have achieved great success in enhancing unsupervised and semi-supervised learning. However, it remains unclear how effectively GANs can serve as a general-purpose solution to learn representations for time series recognition, i.e., classification and clustering. Inspired by these considerations, we introduce a Time-series Convolutional GAN (TCGAN). TCGAN learns by playing an adversarial game between two one-dimensional CNNs (i.e., a generator and a discriminator) in the absence of label information. Parts of the trained TCGAN are then reused to construct a representation encoder to empower linear recognition methods. We conducted comprehensive experiments on synthetic and real-world datasets. The results demonstrate that TCGAN is faster and more accurate than existing time-series GANs. The learned representations enable simple classification and clustering methods to achieve superior and stable performance. Furthermore, TCGAN retains high efficacy in scenarios with few-labeled and imbalanced-labeled data. Our work provides a promising path to effectively utilize abundant unlabeled time series data.Here is the word-for-word translation of the text into Simplified Chinese:近期研究表明，监督式 Convolutional Neural Networks (CNNs) 可以学习时序数据的层次表示，以实现成功的分类。然而，获取高质量的时序数据标注可能成本高昂，可能无法实现。生成对抗网络 (GANs) 在无标签情况下增强了无监督和半监督学习。然而，我们知道 GANs 是否可以作为时序Recognition的通用解决方案？TCGAN 是我们的答案。TCGAN 通过两个一维 CNNs（生成器和识别器）之间的对抗游戏学习，不需要标签信息。部分训练 TCGAN 后，可以重用来构建表示编码器，以便使用线性识别方法。我们在synthetic和实际 datasets上进行了广泛的实验。结果表明，TCGAN 比现有的时序 GANs 更快和更准。TCGAN 学习的表示能够使得简单的分类和聚类方法实现超越性和稳定性。此外，TCGAN 在少量标签和偏振标签数据 scenarios 中保持高效。我们的工作为充分利用庞大的无标签时序数据提供了一条可行的道路。
</details></li>
</ul>
<hr>
<h2 id="Transitions-in-echo-index-and-dependence-on-input-repetitions"><a href="#Transitions-in-echo-index-and-dependence-on-input-repetitions" class="headerlink" title="Transitions in echo index and dependence on input repetitions"></a>Transitions in echo index and dependence on input repetitions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04728">http://arxiv.org/abs/2309.04728</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Ashwin, Andrea Ceni</li>
<li>for: 研究非自动的动力系统中的响应性稳态（echo state property），并探讨响应性稳态与输入的关系。</li>
<li>methods: 使用非自动系统的切换 между一组finite maps来研究响应性稳态的依赖于输入的 Parameter。</li>
<li>results: 发现响应性稳态与输入的关系取决于输入的振荡 amplitude和输入的特性，并在输入强度 intermediate 区域内适用。<details>
<summary>Abstract</summary>
The echo index counts the number of simultaneously stable asymptotic responses of a nonautonomous (i.e. input-driven) dynamical system. It generalizes the well-known echo state property for recurrent neural networks - this corresponds to the echo index being equal to one. In this paper, we investigate how the echo index depends on parameters that govern typical responses to a finite-state ergodic external input that forces the dynamics. We consider the echo index for a nonautonomous system that switches between a finite set of maps, where we assume that each map possesses a finite set of hyperbolic equilibrium attractors. We find the minimum and maximum repetitions of each map are crucial for the resulting echo index. Casting our theoretical findings in the RNN computing framework, we obtain that for small amplitude forcing the echo index corresponds to the number of attractors for the input-free system, while for large amplitude forcing, the echo index reduces to one. The intermediate regime is the most interesting; in this region the echo index depends not just on the amplitude of forcing but also on more subtle properties of the input.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SHAPE-A-Sample-adaptive-Hierarchical-Prediction-Network-for-Medication-Recommendation"><a href="#SHAPE-A-Sample-adaptive-Hierarchical-Prediction-Network-for-Medication-Recommendation" class="headerlink" title="SHAPE: A Sample-adaptive Hierarchical Prediction Network for Medication Recommendation"></a>SHAPE: A Sample-adaptive Hierarchical Prediction Network for Medication Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05675">http://arxiv.org/abs/2309.05675</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sicen Liu, Xiaolong Wang, JIngcheng Du, Yongshuai Hou, Xianbing Zhao, Hui Xu, Hui Wang, Yang Xiang, Buzhou Tang</li>
<li>for: 这个论文的目的是提出一种基于复杂多重疾病的药物建议方法，以解决现有的医疗健康预测任务中的挑战。</li>
<li>methods: 该论文提出了一种Sample-adaptive Hierarchical medicAtion Prediction nEtwork（SHAPE）模型，用于解决上述挑战。该模型包括一个嵌入式的内访集编码器，用于编码医疗事件中的关系，以及一个间访长链编码器，用于学习患者水平的时间序列表示。此外，该模型还使用了一种软学习策略，以自动调整每个样本的难度。</li>
<li>results: 经验表明，SHAPE模型在一个标准测试集上比多种现有基线模型具有更高的准确率和更好的泛化能力。<details>
<summary>Abstract</summary>
Effectively medication recommendation with complex multimorbidity conditions is a critical task in healthcare. Most existing works predicted medications based on longitudinal records, which assumed the information transmitted patterns of learning longitudinal sequence data are stable and intra-visit medical events are serialized. However, the following conditions may have been ignored: 1) A more compact encoder for intra-relationship in the intra-visit medical event is urgent; 2) Strategies for learning accurate representations of the variable longitudinal sequences of patients are different. In this paper, we proposed a novel Sample-adaptive Hierarchical medicAtion Prediction nEtwork, termed SHAPE, to tackle the above challenges in the medication recommendation task. Specifically, we design a compact intra-visit set encoder to encode the relationship in the medical event for obtaining visit-level representation and then develop an inter-visit longitudinal encoder to learn the patient-level longitudinal representation efficiently. To endow the model with the capability of modeling the variable visit length, we introduce a soft curriculum learning method to assign the difficulty of each sample automatically by the visit length. Extensive experiments on a benchmark dataset verify the superiority of our model compared with several state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
<<SYS>>输入文本 translate into Simplified Chinese:“医疗健康预测是一项关键任务。现有的大多数工作都是基于长期纪录预测药物，假设传输信息的长期记录数据是稳定的，并且intragvisit医疗事件是串行化的。然而，以下情况可能被忽略：1）更加 компакт的内部关系编码器可以更好地编码医疗事件中的关系，以获得访问级别表示。2）为了学习精准的患者级别长期序列表示，需要不同的策略。在这篇论文中，我们提出了一种新的Sample-adaptive Hierarchical medicAtion Prediction nEtwork，简称SHAPE，以解决以上挑战。具体来说，我们设计了一个更加 компакт的内部关系编码器，以编码医疗事件中的关系，并开发了一个间访长期编码器，以有效地学习患者级别长期序列表示。为了让模型能够模型变化的访问长度，我们引入了一种软学习策略，以自动将每个样本的难度分配到访问长度。经过了一系列的实验，我们发现我们的模型在一个标准 benchmark dataset 上表现出色，与多种状态之前的基准相比。”Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Toward-Reproducing-Network-Research-Results-Using-Large-Language-Models"><a href="#Toward-Reproducing-Network-Research-Results-Using-Large-Language-Models" class="headerlink" title="Toward Reproducing Network Research Results Using Large Language Models"></a>Toward Reproducing Network Research Results Using Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04716">http://arxiv.org/abs/2309.04716</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiao Xiang, Yuling Lin, Mingjun Fang, Bang Huang, Siyong Huang, Ridi Wen, Franck Le, Linghe Kong, Jiwu Shu</li>
<li>for: 本文提出了一种新的方法来复制网络研究结果，即使用大型自然语言模型（LLM）。</li>
<li>methods: 本文使用了四名学生，每个学生分别使用ChatGPT进行一种不同的网络系统的复制，通过提示工程来实现。</li>
<li>results: 实验观察到了四名学生的复制结果和经验教训，并提出了未来的研究问题。<details>
<summary>Abstract</summary>
Reproducing research results in the networking community is important for both academia and industry. The current best practice typically resorts to three approaches: (1) looking for publicly available prototypes; (2) contacting the authors to get a private prototype; and (3) manually implementing a prototype following the description of the publication. However, most published network research does not have public prototypes and private prototypes are hard to get. As such, most reproducing efforts are spent on manual implementation based on the publications, which is both time and labor consuming and error-prone. In this paper, we boldly propose reproducing network research results using the emerging large language models (LLMs). In particular, we first prove its feasibility with a small-scale experiment, in which four students with essential networking knowledge each reproduces a different networking system published in prominent conferences and journals by prompt engineering ChatGPT. We report the experiment's observations and lessons and discuss future open research questions of this proposal. This work raises no ethical issue.
</details>
<details>
<summary>摘要</summary>
重要的网络研究结果复制是对学术界和业界都非常重要。目前最佳做法通常是：（1）搜索公开可用的原型；（2）与作者联系以获取私有原型；以及（3）根据文章描述手动实现原型。但大多数发表的网络研究没有公共原型，私有原型很难获得。因此，大多数复制努力都是基于文章的手动实现，这是时间和劳动 intensity的和容易出错的。在这篇论文中，我们勇敢地提议使用emerging的大语言模型（LLMs）来复制网络研究结果。具体来说，我们首先证明了这种方法的可行性，通过在四名学生每个复制一种不同的网络系统，这些系统分别发表在知名会议和学术期刊上，通过提示工程ChatGPT来实现。我们报告了实验的观察和教训，并讨论了未来的开放研究问题。这项工作没有伦理问题。
</details></li>
</ul>
<hr>
<h2 id="Jade-A-Differentiable-Physics-Engine-for-Articulated-Rigid-Bodies-with-Intersection-Free-Frictional-Contact"><a href="#Jade-A-Differentiable-Physics-Engine-for-Articulated-Rigid-Bodies-with-Intersection-Free-Frictional-Contact" class="headerlink" title="Jade: A Differentiable Physics Engine for Articulated Rigid Bodies with Intersection-Free Frictional Contact"></a>Jade: A Differentiable Physics Engine for Articulated Rigid Bodies with Intersection-Free Frictional Contact</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04710">http://arxiv.org/abs/2309.04710</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gang Yang, Siyuan Luo, Lin Shao</li>
<li>for: 这个论文是用来描述一个可微分的物理引擎，用于静止和动的零碎体之间的冲击和碰撞。</li>
<li>methods: 这个论文使用了Linear Complementarity Problem (LCP)来模型联系，并且使用了无穷小冲击探测和反转策略来避免体之间的交叉。它还使用了不断的碰撞探测来探测冲击时间，并且将整个模拟过程转换为可微分的形式。</li>
<li>results: 这个论文通过广泛的实验表明，它的可微分物理模拟可以在许多具有联系的任务中实现更高的效能和稳定性，比如零碎体之间的碰撞和冲击。<details>
<summary>Abstract</summary>
We present Jade, a differentiable physics engine for articulated rigid bodies. Jade models contacts as the Linear Complementarity Problem (LCP). Compared to existing differentiable simulations, Jade offers features including intersection-free collision simulation and stable LCP solutions for multiple frictional contacts. We use continuous collision detection to detect the time of impact and adopt the backtracking strategy to prevent intersection between bodies with complex geometry shapes. We derive the gradient calculation to ensure the whole simulation process is differentiable under the backtracking mechanism. We modify the popular Dantzig algorithm to get valid solutions under multiple frictional contacts. We conduct extensive experiments to demonstrate the effectiveness of our differentiable physics simulation over a variety of contact-rich tasks.
</details>
<details>
<summary>摘要</summary>
我们介绍了一个差异化物理引擎——瑰琅（Jade），它模型了接触为线性补假问题（LCP）。相比现有的差异化仿真，瑰琅具有不同的特点，包括不受接触干扰的碰撞仿真和多种摩擦接触的稳定解。我们使用连续碰撞检测来检测碰撞时间，并采用回溯策略来避免复杂形状的体之间的交叠。我们还计算了梯度，以确保整个仿真过程是不可分割的。我们修改了流行的达条算法，以获得多种摩擦接触下的有效解。我们进行了广泛的实验，以证明我们的差异化物理仿真在多种接触丰富任务中的效果。
</details></li>
</ul>
<hr>
<h2 id="Advantage-Actor-Critic-with-Reasoner-Explaining-the-Agent’s-Behavior-from-an-Exploratory-Perspective"><a href="#Advantage-Actor-Critic-with-Reasoner-Explaining-the-Agent’s-Behavior-from-an-Exploratory-Perspective" class="headerlink" title="Advantage Actor-Critic with Reasoner: Explaining the Agent’s Behavior from an Exploratory Perspective"></a>Advantage Actor-Critic with Reasoner: Explaining the Agent’s Behavior from an Exploratory Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04707">http://arxiv.org/abs/2309.04707</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muzhe Guo, Feixu Yu, Tian Lan, Fang Jin</li>
<li>for: 解决复杂决策问题的 reinforcement learning (RL) 缺乏透明度和可解释性，这在具有重要实际影响的决策领域 pose  significative 挑战。</li>
<li>methods: 我们提出了一种名为 Advantage Actor-Critic with Reasoner (A2CR) 的新方法，可以轻松应用于 Actor-Critic 基于的 RL 模型中，并使其更加可解释。A2CR 由三个相互连接的网络组成：政策网络、价值网络和理解器网络。通过预先定义和分类 actor 的行为目的，A2CR 自动生成了更加全面和可解释的决策过程模型。</li>
<li>results: 在行动含量高的 Super Mario Bros 环境中进行了评估，发现：Reasoner 预测的标签分数随 RL 算法的探索水平增加而减少，而 purpose-based 焦点更加集中和可读。<details>
<summary>Abstract</summary>
Reinforcement learning (RL) is a powerful tool for solving complex decision-making problems, but its lack of transparency and interpretability has been a major challenge in domains where decisions have significant real-world consequences. In this paper, we propose a novel Advantage Actor-Critic with Reasoner (A2CR), which can be easily applied to Actor-Critic-based RL models and make them interpretable. A2CR consists of three interconnected networks: the Policy Network, the Value Network, and the Reasoner Network. By predefining and classifying the underlying purpose of the actor's actions, A2CR automatically generates a more comprehensive and interpretable paradigm for understanding the agent's decision-making process. It offers a range of functionalities such as purpose-based saliency, early failure detection, and model supervision, thereby promoting responsible and trustworthy RL. Evaluations conducted in action-rich Super Mario Bros environments yield intriguing findings: Reasoner-predicted label proportions decrease for ``Breakout" and increase for ``Hovering" as the exploration level of the RL algorithm intensifies. Additionally, purpose-based saliencies are more focused and comprehensible.
</details>
<details>
<summary>摘要</summary>
� Reinforcement learning (RL) 是一种强大的解决复杂决策问题的工具，但它缺乏透明性和可解释性，在具有重要现实世界影响的领域是一个主要挑战。在这篇论文中，我们提出了一种新的优先级理解者-评价者（A2CR）模型，可以轻松应用于actor-critic型RL模型中，并使其更加透明。A2CR包括三个相互连接的网络：政策网络、价值网络和理解者网络。通过预先定义和分类actor的行为目的，A2CR自动生成了更加全面和可解释的agent决策过程的模型。它提供了一些功能，如目的基于的焦点度、早期失败检测和模型监管，从而推动了负责任和可信RL。在动作富 Super Mario Bros 环境中进行的评估结果表明：理解者预测的标签分布随RL算法的探索水平的强化而下降，而“Breakout”和“悬停”的目的基于的焦点度更加集中和可解释。
</details></li>
</ul>
<hr>
<h2 id="Analysis-of-Disinformation-and-Fake-News-Detection-Using-Fine-Tuned-Large-Language-Model"><a href="#Analysis-of-Disinformation-and-Fake-News-Detection-Using-Fine-Tuned-Large-Language-Model" class="headerlink" title="Analysis of Disinformation and Fake News Detection Using Fine-Tuned Large Language Model"></a>Analysis of Disinformation and Fake News Detection Using Fine-Tuned Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04704">http://arxiv.org/abs/2309.04704</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bohdan M. Pavlyshenko</li>
<li>for: 本研究探讨了使用LLM进行假新闻检测和假信息分析的可能性。</li>
<li>methods: 本研究使用PEFT&#x2F;LoRA等方法进行了模型精细调整。</li>
<li>results: 研究表明，精细调整的Llama 2模型可以深入分析文本，揭示复杂的风格和narraatives。提取的名实体情感可以作为预测特征在指导机器学习模型中。<details>
<summary>Abstract</summary>
The paper considers the possibility of fine-tuning Llama 2 large language model (LLM) for the disinformation analysis and fake news detection. For fine-tuning, the PEFT/LoRA based approach was used. In the study, the model was fine-tuned for the following tasks: analysing a text on revealing disinformation and propaganda narratives, fact checking, fake news detection, manipulation analytics, extracting named entities with their sentiments. The obtained results show that the fine-tuned Llama 2 model can perform a deep analysis of texts and reveal complex styles and narratives. Extracted sentiments for named entities can be considered as predictive features in supervised machine learning models.
</details>
<details>
<summary>摘要</summary>
文章考虑了使用LLama 2大语言模型（LLM）进行假新闻检测和假信息分析的可能性。为了进行细化，使用了PEFT/LoRA基于的方法。研究中使用了以下任务进行细化：分析文本中的假信息和宣传叙述，实现Fact Checking，假新闻检测， manipulate analytics，提取Named Entity的情感。研究结果显示，经过细化的Llama 2模型可以对文本进行深入的分析，揭示复杂的风格和叙述。提取的情感特征可以作为生成式机器学习模型的预测特征。
</details></li>
</ul>
<hr>
<h2 id="Advancements-in-Upper-Body-Exoskeleton-Implementing-Active-Gravity-Compensation-with-a-Feedforward-Controller"><a href="#Advancements-in-Upper-Body-Exoskeleton-Implementing-Active-Gravity-Compensation-with-a-Feedforward-Controller" class="headerlink" title="Advancements in Upper Body Exoskeleton: Implementing Active Gravity Compensation with a Feedforward Controller"></a>Advancements in Upper Body Exoskeleton: Implementing Active Gravity Compensation with a Feedforward Controller</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04698">http://arxiv.org/abs/2309.04698</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Ayaz Hussain, Ioannis Iossifidis</li>
<li>for: 这个论文是为了开发一种基于前向控制的活动重力补偿 upper body exoskeleton 的控制系统。</li>
<li>methods: 这个系统使用内部电动机传感器的位置数据来计算扭矩，使用分析控制方程基于新顿-尤利尔反动动力学。</li>
<li>results: 对硬件和软件实验以及模拟结果进行比较，系统在稳定性和精度方面具有优秀表现，能够维持位置在长时间内，并具有最小摩擦和不良滚动的特点。<details>
<summary>Abstract</summary>
In this study, we present a feedforward control system designed for active gravity compensation on an upper body exoskeleton. The system utilizes only positional data from internal motor sensors to calculate torque, employing analytical control equations based on Newton-Euler Inverse Dynamics. Compared to feedback control systems, the feedforward approach offers several advantages. It eliminates the need for external torque sensors, resulting in reduced hardware complexity and weight. Moreover, the feedforward control exhibits a more proactive response, leading to enhanced performance. The exoskeleton used in the experiments is lightweight and comprises 4 Degrees of Freedom, closely mimicking human upper body kinematics and three-dimensional range of motion. We conducted tests on both hardware and simulations of the exoskeleton, demonstrating stable performance. The system maintained its position over an extended period, exhibiting minimal friction and avoiding undesired slewing.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们提出了一种Feedforward控制系统，用于活动重力补偿Upper Body exoskeleton。该系统只使用内部电动机传感器的位势数据来计算扭矩，使用分析控制方程基于新顿-尤利尔反逆动力学。相比反馈控制系统，Feedforward方法具有多种优势。它消除了需要外部扭矩传感器的需求，从而减轻硬件复杂性和重量。此外，Feedforward控制具有更加积极的响应，导致性能的提高。我们使用的Exoskeleton是轻量级的，包含4个度Of Freedom，准确模拟人类Upper Body骨骼动态和三维运动范围。我们对硬件和Simulations中的Exoskeleton进行了测试，示出了稳定的性能。系统在Extended Period内保持了其位置，表现出Minimal friction和避免了不良滚动。
</details></li>
</ul>
<hr>
<h2 id="Code-Style-In-Context-Learning-for-Knowledge-Based-Question-Answering"><a href="#Code-Style-In-Context-Learning-for-Knowledge-Based-Question-Answering" class="headerlink" title="Code-Style In-Context Learning for Knowledge-Based Question Answering"></a>Code-Style In-Context Learning for Knowledge-Based Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04695">http://arxiv.org/abs/2309.04695</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/TeniaKovacs/ExploratoryDataProject1">https://github.com/TeniaKovacs/ExploratoryDataProject1</a></li>
<li>paper_authors: Zhijie Nie, Richong Zhang, Zhongyuan Wang, Xudong Liu</li>
<li>for: 本研究旨在提高知识基因问答（KBQA）的实用应用，通过简单的训练技术和模型框架来解决现有的限制。</li>
<li>methods: 本研究使用了受Context学习（ICL）技术，通过给大语言模型（LLM）提供一小数量的问题和其标注的逻辑形式作为示例，使得LLM可以理解任务意图并生成新问题的逻辑形式。</li>
<li>results: 实验结果表明，我们的代码式受Context学习方法可以减少生成逻辑形式时的格式错误问题，同时实现新的最佳性能在WebQSP、GrailQA和GraphQ下的少量设定下。<details>
<summary>Abstract</summary>
Current methods for Knowledge-Based Question Answering (KBQA) usually rely on complex training techniques and model frameworks, leading to many limitations in practical applications. Recently, the emergence of In-Context Learning (ICL) capabilities in Large Language Models (LLMs) provides a simple and training-free semantic parsing paradigm for KBQA: Given a small number of questions and their labeled logical forms as demo examples, LLMs can understand the task intent and generate the logic form for a new question. However, current powerful LLMs have little exposure to logic forms during pre-training, resulting in a high format error rate. To solve this problem, we propose a code-style in-context learning method for KBQA, which converts the generation process of unfamiliar logical form into the more familiar code generation process for LLMs. Experimental results on three mainstream datasets show that our method dramatically mitigated the formatting error problem in generating logic forms while realizing a new SOTA on WebQSP, GrailQA, and GraphQ under the few-shot setting.
</details>
<details>
<summary>摘要</summary>
现有的知识基本问答（KBQA）方法通常依赖于复杂的训练技术和模型框架，导致在实际应用中具有许多限制。近期，大量语言模型（LLMs）的具有场景学习（ICL）能力提供了一种简单而无需训练的 semantic parsing 模型 для KBQA：给定一小 número de preguntas和其标注的逻辑形式作为示例，LLMs 可以理解任务目的并生成新的问题逻辑形式。然而，当前最强大的 LLMs 在预训练时对逻辑形式没有多少接触，导致高的格式错误率。为解决这个问题，我们提议一种 code-style 在 Context Learning 方法 для KBQA，将生成不熟悉的逻辑形式转换成更加熟悉的代码生成过程。实验结果表明，我们的方法可以减少生成逻辑形式时的格式错误问题，同时实现新的 SOTA 在 WebQSP、GrailQA 和 GraphQ 上下的 few-shot 设置下。
</details></li>
</ul>
<hr>
<h2 id="Flexible-and-Robust-Counterfactual-Explanations-with-Minimal-Satisfiable-Perturbations"><a href="#Flexible-and-Robust-Counterfactual-Explanations-with-Minimal-Satisfiable-Perturbations" class="headerlink" title="Flexible and Robust Counterfactual Explanations with Minimal Satisfiable Perturbations"></a>Flexible and Robust Counterfactual Explanations with Minimal Satisfiable Perturbations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04676">http://arxiv.org/abs/2309.04676</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangyongjie-ntu/cemsp">https://github.com/wangyongjie-ntu/cemsp</a></li>
<li>paper_authors: Yongjie Wang, Hangwei Qian, Yongjie Liu, Wei Guo, Chunyan Miao</li>
<li>For: The paper aims to provide more robust and flexible counterfactual explanations (CFEs) for enhancing informational fairness and trustworthiness in machine learning models.* Methods: The proposed method, called Counterfactual Explanations with Minimal Satisfiable Perturbations (CEMSP), constrains changing values of abnormal features with their semantically meaningful normal ranges, and models the problem as a Boolean satisfiability problem to modify as few features as possible.* Results: The proposed method provides more robust explanations while preserving flexibility, and is demonstrated to be more effective than existing methods through comprehensive experiments on both synthetic and real-world datasets.Here’s the simplified Chinese text for the three key points:* For: 这篇论文目的是提供更加稳定和灵活的对假解释（CFEs），以增强机器学习模型的信息公正和可靠性。* Methods: 提议的方法是Counterfactual Explanations with Minimal Satisfiable Perturbations（CEMSP），它将异常特征值修改为 semantically meaningful normal ranges，并将问题模型为Boolean satisfiability problem，以修改最少特征。* Results: 提议的方法可以提供更加稳定的解释，同时保持灵活性，并在synthetic和实际 datasets上进行了广泛的实验，证明了它比现有方法更有效。<details>
<summary>Abstract</summary>
Counterfactual explanations (CFEs) exemplify how to minimally modify a feature vector to achieve a different prediction for an instance. CFEs can enhance informational fairness and trustworthiness, and provide suggestions for users who receive adverse predictions. However, recent research has shown that multiple CFEs can be offered for the same instance or instances with slight differences. Multiple CFEs provide flexible choices and cover diverse desiderata for user selection. However, individual fairness and model reliability will be damaged if unstable CFEs with different costs are returned. Existing methods fail to exploit flexibility and address the concerns of non-robustness simultaneously. To address these issues, we propose a conceptually simple yet effective solution named Counterfactual Explanations with Minimal Satisfiable Perturbations (CEMSP). Specifically, CEMSP constrains changing values of abnormal features with the help of their semantically meaningful normal ranges. For efficiency, we model the problem as a Boolean satisfiability problem to modify as few features as possible. Additionally, CEMSP is a general framework and can easily accommodate more practical requirements, e.g., casualty and actionability. Compared to existing methods, we conduct comprehensive experiments on both synthetic and real-world datasets to demonstrate that our method provides more robust explanations while preserving flexibility.
</details>
<details>
<summary>摘要</summary>
counterfactual explanations (CFEs) 可以最小化特征向量的修改，以实现对一个实例的不同预测。CFEs 可以提高信息公正和可靠性，并为用户提供不同预测选择的建议。然而，当不同的 CFEs 对同一个实例或 slight 不同的实例提供多个选择时，这会导致问题。多个 CFEs 可以提供多样化的选择，但是如果返回不稳定的 CFEs ，则个人公正和模型可靠性将受损。现有方法无法充分利用多样化和不稳定性问题的同时处理。为解决这些问题，我们提出了一种概念简单又有效的解决方案，名为 counterfactual explanations with minimal satisfiable perturbations (CEMSP)。具体来说，CEMSP 通过在异常特征上进行Semantically meaningful normal range的改变来限制修改。为了提高效率，我们将问题模型为Boolean satisfiability problem，以修改最少的特征。此外，CEMSP 是一个通用的框架，可以轻松地满足更多的实际需求，例如 causality 和 actionability。与现有方法相比，我们在 Both synthetic 和实际数据集上进行了 comprehensive 的实验，并证明了我们的方法可以提供更加稳定的解释，同时保持多样化。
</details></li>
</ul>
<hr>
<h2 id="FIAT-Fusing-learning-paradigms-with-Instruction-Accelerated-Tuning"><a href="#FIAT-Fusing-learning-paradigms-with-Instruction-Accelerated-Tuning" class="headerlink" title="FIAT: Fusing learning paradigms with Instruction-Accelerated Tuning"></a>FIAT: Fusing learning paradigms with Instruction-Accelerated Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04663">http://arxiv.org/abs/2309.04663</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyi Wang, John Wieting, Jonathan H. Clark</li>
<li>for: 这篇论文旨在探讨大语言模型（LLM）的学习方法，具体来说是研究如何使用受限的数据量、模型大小和计算成本来训练LLM，以及如何使用最大化的方法来提高模型的性能。</li>
<li>methods: 该论文使用了两种常见的LLM学习方法：受限学习（ICL）和全部精度调整（full fine-tuning）。它们的不同之处在于数据量、模型大小和计算成本等方面，并且它们在不同的任务上表现不同。</li>
<li>results: 研究发现，使用FIAT方法可以在100-10,000个训练示例的范围内，比ICL和精度调整更好地表现。FIAT方法可以同时利用最大化的方法和受限学习的方法，以提高模型的性能。<details>
<summary>Abstract</summary>
Learning paradigms for large language models (LLMs) currently tend to fall within either in-context learning (ICL) or full fine-tuning. Each of these comes with their own trade-offs based on available data, model size, compute cost, ease-of-use, and final quality with neither solution performing well across-the-board. In this article, we first describe ICL and fine-tuning paradigms in a way that highlights their natural connections. Based on these connections, we propose a new learning paradigm called FIAT that fuses the best of these paradigms together, enabling prompt-engineered instructions and chain-of-thought reasoning with the very largest models while also using similar methods to perform parameter updates on a modestly-sized LLM with parameter-efficient tuning. We evaluate FIAT's effectiveness on a variety of multilingual tasks and observe that FIAT performs better than both ICL and fine-tuning at scales ranging from 100-10,000 training examples. We hope that FIAT provides a practical way of harnessing the full potential of LLMs without needing to make a hard choice between learning paradigms.
</details>
<details>
<summary>摘要</summary>
现有大语言模型（LLM）学习模式主要分为两类：在Context Learning（ICL）和完整精度调整（Fine-tuning）。每种方法都有其特点，包括数据可用性、模型大小、计算成本、使用容易度和最终质量等方面。然而， neither solution performs well across-the-board。在这篇文章中，我们首先描述ICL和精度调整模式，并将其联系到它们之间的自然联系。基于这些联系，我们提议一种新的学习模式called FIAT，它结合了ICL和精度调整模式的优点，使得使用最大模型时可以实现提示工程ered instrucions和链式思维，同时使用相同的方法来进行参数更新 modestly-sized LLM中 parameter-efficient tuning。我们在多种多语言任务上评估FIAT的效果，并发现FIAT在100-10,000个训练示例范围内比ICL和精度调整更好。我们希望FIAT可以为LLM的潜在力量做出实用的方式，不需要选择学习模式。
</details></li>
</ul>
<hr>
<h2 id="Video-and-Synthetic-MRI-Pre-training-of-3D-Vision-Architectures-for-Neuroimage-Analysis"><a href="#Video-and-Synthetic-MRI-Pre-training-of-3D-Vision-Architectures-for-Neuroimage-Analysis" class="headerlink" title="Video and Synthetic MRI Pre-training of 3D Vision Architectures for Neuroimage Analysis"></a>Video and Synthetic MRI Pre-training of 3D Vision Architectures for Neuroimage Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04651">http://arxiv.org/abs/2309.04651</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikhil J. Dhinagar, Amit Singh, Saket Ozarkar, Ketaki Buwa, Sophia I. Thomopoulos, Conor Owens-Walton, Emily Laltoo, Yao-Liang Chen, Philip Cook, Corey McMillan, Chih-Chien Tsai, J-J Wang, Yih-Ru Wu, Paul M. Thompson<br>for: 这个论文主要是为了评估不同的预训练方法，以提高3D医学影像任务的模型性能。methods: 作者使用了视transformer（ViT）和卷积神经网络（CNN）作为模型，并对其进行了不同的预训练方法 initialization。results: 研究发现，预训练可以提高所有任务的性能，包括提高AD分类任务的性能7.4%和PD分类任务的性能4.6%，同时也可以减少脑龄预测错误值1.26年。此外，研究还发现，使用大规模的视频或合成MRI数据进行预训练可以提高ViT的性能，而CNN在有限数据设置下表现了良好的稳定性，并且在预训练下进行域外预测也有良好的性能。<details>
<summary>Abstract</summary>
Transfer learning represents a recent paradigm shift in the way we build artificial intelligence (AI) systems. In contrast to training task-specific models, transfer learning involves pre-training deep learning models on a large corpus of data and minimally fine-tuning them for adaptation to specific tasks. Even so, for 3D medical imaging tasks, we do not know if it is best to pre-train models on natural images, medical images, or even synthetically generated MRI scans or video data. To evaluate these alternatives, here we benchmarked vision transformers (ViTs) and convolutional neural networks (CNNs), initialized with varied upstream pre-training approaches. These methods were then adapted to three unique downstream neuroimaging tasks with a range of difficulty: Alzheimer's disease (AD) and Parkinson's disease (PD) classification, "brain age" prediction. Experimental tests led to the following key observations: 1. Pre-training improved performance across all tasks including a boost of 7.4% for AD classification and 4.6% for PD classification for the ViT and 19.1% for PD classification and reduction in brain age prediction error by 1.26 years for CNNs, 2. Pre-training on large-scale video or synthetic MRI data boosted performance of ViTs, 3. CNNs were robust in limited-data settings, and in-domain pretraining enhanced their performances, 4. Pre-training improved generalization to out-of-distribution datasets and sites. Overall, we benchmarked different vision architectures, revealing the value of pre-training them with emerging datasets for model initialization. The resulting pre-trained models can be adapted to a range of downstream neuroimaging tasks, even when training data for the target task is limited.
</details>
<details>
<summary>摘要</summary>
transferred learning 表示人工智能（AI）系统的新方法shift。相比于专门预训练任务的模型，transferred learning 涉及预训练深度学习模型在大量数据集上并将其微调以适应特定任务。然而， для 3D医学成像任务，我们不知道是否最好预训练模型在自然图像、医疗图像或Synthetically生成的MRI扫描或视频数据上。为了评估这些选择，我们在这里对 ViTs 和 convolutional neural networks (CNNs) 进行了初始化不同的上游预训练方法。这些方法然后在三个独特的下游神经成像任务中进行了适应，包括阿尔茨海默病（AD）和公主病（PD）的分类、"脑龄"预测。实验测试表明了以下关键观察：1. 预训练提高了所有任务的表现，包括ViTs中的7.4%的AD分类提升和4.6%的PD分类提升，以及CNNs中的19.1%的PD分类提升和1.26年的脑龄预测错误减少。2. 预训练在大规模的视频或生成的MRI数据上得到了ViTs的提升，而CNNs在有限数据设置中表现了 robustness。3. 在有限数据设置中，培育在域内预训练中表现出了优异，而CNNs在域外预训练中表现出了更好的泛化性。4. 预训练提高了模型对不同数据集和站点的泛化性。总之，我们对不同的视觉架构进行了 benchmarking，发现预训练它们使用emerging datasets的值。这些预训练的模型可以适应一系列的下游神经成像任务，即使训练数据集的规模有限。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Finetuning-Large-Language-Models-For-Vietnamese-Chatbot"><a href="#Efficient-Finetuning-Large-Language-Models-For-Vietnamese-Chatbot" class="headerlink" title="Efficient Finetuning Large Language Models For Vietnamese Chatbot"></a>Efficient Finetuning Large Language Models For Vietnamese Chatbot</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04646">http://arxiv.org/abs/2309.04646</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vu-Thuan Doan, Quoc-Truong Truong, Duc-Vu Nguyen, Vinh-Tiep Nguyen, Thuy-Ngan Nguyen Luu</li>
<li>for: 这个研究旨在提高大型自然语言模型（LLMs）的效能，并且可以实现用户的指令和生成人类化回应。</li>
<li>methods: 我们使用大量的指令跟踪数据库，包括Alpaca、GPT4All和Chat-Doctor等，这些数据库覆盖了通用领域和具体医疗领域。然后，我们使用LoRA的参数高效调整技术，将Bloomz（多语言）和GPTJ-6B（越南语）两个开源模型进行调整，从而产生四个模型：Bloomz-Chat、Bloomz-Doctor、GPTJ-Chat和GPTJ-Doctor。</li>
<li>results: 我们通过自动评分机制GPT-4进行评估，发现我们的方法可以在评估任务中提高20-30%。<details>
<summary>Abstract</summary>
Large language models (LLMs), such as GPT-4, PaLM, and LLaMa, have been shown to achieve remarkable performance across a variety of natural language tasks. Recent advancements in instruction tuning bring LLMs with ability in following user's instructions and producing human-like responses. However, the high costs associated with training and implementing LLMs pose challenges to academic research. Furthermore, the availability of pretrained LLMs and instruction-tune datasets for Vietnamese language is limited. To tackle these concerns, we leverage large-scale instruction-following datasets from open-source projects, namely Alpaca, GPT4All, and Chat-Doctor, which cover general domain and specific medical domain. To the best of our knowledge, these are the first instructional dataset for Vietnamese. Subsequently, we utilize parameter-efficient tuning through Low-Rank Adaptation (LoRA) on two open LLMs: Bloomz (Multilingual) and GPTJ-6B (Vietnamese), resulting four models: Bloomz-Chat, Bloomz-Doctor, GPTJ-Chat, GPTJ-Doctor.Finally, we assess the effectiveness of our methodology on a per-sample basis, taking into consideration the helpfulness, relevance, accuracy, level of detail in their responses. This evaluation process entails the utilization of GPT-4 as an automated scoring mechanism. Despite utilizing a low-cost setup, our method demonstrates about 20-30\% improvement over the original models in our evaluation tasks.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM），如GPT-4、PaLM和LLaMa，已经在各种自然语言任务上表现出色。最近的指令调整技术使得LLM可以按照用户的指令进行行动，并生成人类化的回复。然而，训练和实现LLM的成本高昂，对学术研究提出了挑战。此外，预训练的LLM和指令调整数据集 для越南语言的可用性受限。为解决这些问题，我们利用大规模的指令遵从数据集，来自开源项目，包括Alpaca、GPT4All和Chat-Doctor，这些数据集覆盖通用领域和具体医疗领域。我们知道这是越南语言第一个指令数据集。然后，我们使用LoRA parameter-efficient tuning技术，在开放的两个LLM上进行调整，生成四个模型：Bloomz-Chat、Bloomz-Doctor、GPTJ-Chat和GPTJ-Doctor。最后，我们根据每个样本的帮助程度、相关性、准确性和回答细节进行评估。这个评估过程中使用GPT-4作为自动评分机制。尽管我们使用低成本的设置，但我们的方法在我们的评估任务中表现出20-30%的提升。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/09/cs.AI_2023_09_09/" data-id="clogxf3kh003n5xrahy15bgai" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/09/cs.CL_2023_09_09/" class="article-date">
  <time datetime="2023-09-09T11:00:00.000Z" itemprop="datePublished">2023-09-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/09/cs.CL_2023_09_09/">cs.CL - 2023-09-09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Reverse-Engineering-Decoding-Strategies-Given-Blackbox-Access-to-a-Language-Generation-System"><a href="#Reverse-Engineering-Decoding-Strategies-Given-Blackbox-Access-to-a-Language-Generation-System" class="headerlink" title="Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System"></a>Reverse-Engineering Decoding Strategies Given Blackbox Access to a Language Generation System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04858">http://arxiv.org/abs/2309.04858</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daphne Ippolito, Nicholas Carlini, Katherine Lee, Milad Nasr, Yun William Yu</li>
<li>for: 本研究旨在逆引导语言模型生成文本的方法，以便检测生成文本和掌握模型生成过程中的偏见。</li>
<li>methods: 本研究使用逆引导技术揭示语言模型生成文本时使用的排名方法（top-$k$或核心抽样），并评估这些方法对模型生成过程中的偏见的影响。</li>
<li>results: 研究人员通过逆引导语言模型生成文本的方法，成功地探测了许多家族的开源语言模型和生产系统（如ChatGPT）中使用的排名方法，并发现这些方法可能导致模型生成过程中的偏见。<details>
<summary>Abstract</summary>
Neural language models are increasingly deployed into APIs and websites that allow a user to pass in a prompt and receive generated text. Many of these systems do not reveal generation parameters. In this paper, we present methods to reverse-engineer the decoding method used to generate text (i.e., top-$k$ or nucleus sampling). Our ability to discover which decoding strategy was used has implications for detecting generated text. Additionally, the process of discovering the decoding strategy can reveal biases caused by selecting decoding settings which severely truncate a model's predicted distributions. We perform our attack on several families of open-source language models, as well as on production systems (e.g., ChatGPT).
</details>
<details>
<summary>摘要</summary>
神经语言模型在API和网站中逐渐被部署，允许用户输入提示并接收生成的文本。许多这些系统并不披露生成参数。在这篇论文中，我们提出了一些方法来逆向工程生成文本的方法（即top-$k$或核心采样）。我们能够找到生成文本的decoding策略，这有关于检测生成文本的意义。此外，通过发现decoding设置的选择会产生模型预测分布的偏见，我们可以通过这个过程揭示生成文本的偏见。我们对一些开源语言模型家族以及生产系统（如ChatGPT）进行了攻击。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Large-Language-Models-for-Exploiting-ASR-Uncertainty"><a href="#Leveraging-Large-Language-Models-for-Exploiting-ASR-Uncertainty" class="headerlink" title="Leveraging Large Language Models for Exploiting ASR Uncertainty"></a>Leveraging Large Language Models for Exploiting ASR Uncertainty</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04842">http://arxiv.org/abs/2309.04842</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pranay Dighe, Yi Su, Shangshang Zheng, Yunshu Liu, Vineet Garg, Xiaochuan Niu, Ahmed Tewfik</li>
<li>for: 这项研究旨在提高语言模型在语音理解任务中的表现，而不需要采用复杂或特化的架构设计。</li>
<li>methods: 研究人员使用n-best列表作为语音识别器输入，并通过训练低维适应器来调整下游任务。</li>
<li>results: 使用n-best列表提高了语言模型在语音检测和关键词检测任务中的表现，而且在这些任务中，使用n-best列表的系统表现较为稳定。<details>
<summary>Abstract</summary>
While large language models excel in a variety of natural language processing (NLP) tasks, to perform well on spoken language understanding (SLU) tasks, they must either rely on off-the-shelf automatic speech recognition (ASR) systems for transcription, or be equipped with an in-built speech modality. This work focuses on the former scenario, where LLM's accuracy on SLU tasks is constrained by the accuracy of a fixed ASR system on the spoken input. Specifically, we tackle speech-intent classification task, where a high word-error-rate can limit the LLM's ability to understand the spoken intent. Instead of chasing a high accuracy by designing complex or specialized architectures regardless of deployment costs, we seek to answer how far we can go without substantially changing the underlying ASR and LLM, which can potentially be shared by multiple unrelated tasks. To this end, we propose prompting the LLM with an n-best list of ASR hypotheses instead of only the error-prone 1-best hypothesis. We explore prompt-engineering to explain the concept of n-best lists to the LLM; followed by the finetuning of Low-Rank Adapters on the downstream tasks. Our approach using n-best lists proves to be effective on a device-directed speech detection task as well as on a keyword spotting task, where systems using n-best list prompts outperform those using 1-best ASR hypothesis; thus paving the way for an efficient method to exploit ASR uncertainty via LLMs for speech-based applications.
</details>
<details>
<summary>摘要</summary>
大型自然语言处理（NLP）模型在各种任务上表现出色，但是在语音理解（SLU）任务上，它们需要依赖于可用的自动语音识别（ASR）系统进行转录，或者具备语音模式。本工作关注于前一种情况，即LLM的SLU任务表现受ASR系统对语音输入的准确率的限制。具体来说，我们解决了语音意图分类任务，其中高度的单词错误率可能限制LLM的意图理解能力。而不是通过设计复杂或特殊的架构来提高准确率，我们寻求如何不需要重大变革ASR和LLM的基础结构，以便在多个无关的任务上共享。为此，我们提出了使用n-best列表而不是唯一的错误的1-best假设来提示LLM。我们进行了提示工程来解释n-best列表的概念给LLM，然后进行了下游任务的训练。我们的方法使用n-best列表证明有效于设备指定的语音检测任务以及关键词检测任务，其中使用n-best列表提示的系统在1-best假设的系统上表现出色，因此为语音基于应用程序的有效方法。
</details></li>
</ul>
<hr>
<h2 id="Neurons-in-Large-Language-Models-Dead-N-gram-Positional"><a href="#Neurons-in-Large-Language-Models-Dead-N-gram-Positional" class="headerlink" title="Neurons in Large Language Models: Dead, N-gram, Positional"></a>Neurons in Large Language Models: Dead, N-gram, Positional</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04827">http://arxiv.org/abs/2309.04827</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elena Voita, Javier Ferrando, Christoforos Nalmpantis</li>
<li>for: 这篇论文主要研究了一种大型自然语言处理模型，并在单个GPU上进行轻量级的分析。</li>
<li>methods: 研究者使用了OPT家族模型，从125m到66b参数的范围内进行研究，并仅仅基于FFN神经元是否活跃或不活跃。</li>
<li>results: 研究者发现，早期网络部分很 sparse，表示许多特征是离散的。大约70%的神经元在66b模型中是“死亡”的，即 nunca activated 在大量多样化数据集上。同时，有些 alive 神经元 acts as token和n-gram探测器。 FFN更新不仅推荐下一个元素 канди达，而且还专门消除输入中的信息。这是研究者发现的首个特有的机制，用于从剩余流中移除（而不是添加）信息。随着规模的增加，模型变得更加 sparse，即有更多的“死亡”神经元和token探测器。最后，一些神经元被发现为位置 dependent，即它们的活跃或不活跃取决于位置，而不是文本数据。<details>
<summary>Abstract</summary>
We analyze a family of large language models in such a lightweight manner that can be done on a single GPU. Specifically, we focus on the OPT family of models ranging from 125m to 66b parameters and rely only on whether an FFN neuron is activated or not. First, we find that the early part of the network is sparse and represents many discrete features. Here, many neurons (more than 70% in some layers of the 66b model) are "dead", i.e. they never activate on a large collection of diverse data. At the same time, many of the alive neurons are reserved for discrete features and act as token and n-gram detectors. Interestingly, their corresponding FFN updates not only promote next token candidates as could be expected, but also explicitly focus on removing the information about triggering them tokens, i.e., current input. To the best of our knowledge, this is the first example of mechanisms specialized at removing (rather than adding) information from the residual stream. With scale, models become more sparse in a sense that they have more dead neurons and token detectors. Finally, some neurons are positional: them being activated or not depends largely (or solely) on position and less so (or not at all) on textual data. We find that smaller models have sets of neurons acting as position range indicators while larger models operate in a less explicit manner.
</details>
<details>
<summary>摘要</summary>
我们对一家大型语言模型进行轻量级分析，可以在单个GPU上进行。我们专注于OPT家族模型， Parameter范围从125m到66b，并且仅基于FFN neuron是否活动。我们发现，早期网络部分是稀畴的，表示许多独特的特征。在某些层中，66b模型中的超过70%的神经元是"死亡"的，即它们从未在大量多样化数据上活动。同时，大多数活跃神经元作为token和n-gram探测器，其FFN更新不仅推荐下一个Token候选者，还显著地减少输入信息，即当前输入。我们认为，这是首次特有的机制，从 residual 流中Explicitly removing 信息而不是添加信息。随着scale，模型变得更加稀畴，即它们有更多的"死亡"神经元和token探测器。最后，一些神经元是位置特征，它们的活动或不活动主要取决于位置，而不是文本数据。我们发现小型模型有一组神经元作为位置范围指示器，而更大的模型在更不那么显式的方式下运行。
</details></li>
</ul>
<hr>
<h2 id="FaNS-a-Facet-based-Narrative-Similarity-Metric"><a href="#FaNS-a-Facet-based-Narrative-Similarity-Metric" class="headerlink" title="FaNS: a Facet-based Narrative Similarity Metric"></a>FaNS: a Facet-based Narrative Similarity Metric</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04823">http://arxiv.org/abs/2309.04823</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mousumi Akter, Shubhra Kanti Karmaker Santu</li>
<li>for: 本研究的目的是提出一种新的叙事相似度度量方法，以便更好地比较叙事的细节。</li>
<li>methods: 本研究使用了现有的大语言模型（LLMs）来提取5W1H的特征（Who, What, When, Where, Why, and How），并将其作为叙事相似度度量的基础。</li>
<li>results: 实验结果表明，FaNS度量在比较叙事的细节方面表现出了37%的高 corrrelation，与传统的文本相似度度量方法相比，表明FaNS度量能够更好地捕捉叙事的细节。<details>
<summary>Abstract</summary>
Similar Narrative Retrieval is a crucial task since narratives are essential for explaining and understanding events, and multiple related narratives often help to create a holistic view of the event of interest. To accurately identify semantically similar narratives, this paper proposes a novel narrative similarity metric called Facet-based Narrative Similarity (FaNS), based on the classic 5W1H facets (Who, What, When, Where, Why, and How), which are extracted by leveraging the state-of-the-art Large Language Models (LLMs). Unlike existing similarity metrics that only focus on overall lexical/semantic match, FaNS provides a more granular matching along six different facets independently and then combines them. To evaluate FaNS, we created a comprehensive dataset by collecting narratives from AllSides, a third-party news portal. Experimental results demonstrate that the FaNS metric exhibits a higher correlation (37\% higher) than traditional text similarity metrics that directly measure the lexical/semantic match between narratives, demonstrating its effectiveness in comparing the finer details between a pair of narratives.
</details>
<details>
<summary>摘要</summary>
相似的故事检索是一项非常重要的任务，因为故事是解释和理解事件的重要工具。多个相关的故事可以帮助创建一个事件的总体视图。为了准确地标识semantically相似的故事，这篇论文提出了一种新的故事相似度度量方法，称为 Facet-based Narrative Similarity（FaNS），基于经典的5W1Hfacets（Who、What、When、Where、Why和How）。与现有的相似度度量方法不同，FaNS提供了更加细化的匹配，分别对六个不同的facet进行独立匹配，然后进行组合。为了评估FaNS，我们创建了一个完整的数据集，通过收集AllSides第三方新闻门户上的故事。实验结果表明，FaNS metric在比较两个故事的细节方面 exhibits higher correlation（37%高于传统的文本相似度度量方法），这demonstrates its effectiveness in comparing the finer details between a pair of narratives.
</details></li>
</ul>
<hr>
<h2 id="MMHQA-ICL-Multimodal-In-context-Learning-for-Hybrid-Question-Answering-over-Text-Tables-and-Images"><a href="#MMHQA-ICL-Multimodal-In-context-Learning-for-Hybrid-Question-Answering-over-Text-Tables-and-Images" class="headerlink" title="MMHQA-ICL: Multimodal In-context Learning for Hybrid Question Answering over Text, Tables and Images"></a>MMHQA-ICL: Multimodal In-context Learning for Hybrid Question Answering over Text, Tables and Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04790">http://arxiv.org/abs/2309.04790</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weihao Liu, Fangyu Lei, Tongxu Luo, Jiahe Lei, Shizhu He, Jun Zhao, Kang Liu</li>
<li>for: 解决多modal和多种类型的问答问题 (addressing multimodal and heterogeneous question answering problems)</li>
<li>methods: 提出了MMHQA-ICL框架，包括强化的多元数据检索器和图像caption模块，以及类型特定的在 контекス学习策略 (proposed MMHQA-ICL framework, including a strengthened heterogeneous data retriever and an image caption module, as well as a type-specific in-context learning strategy)</li>
<li>results: 实验结果表明，我们的框架在少量数据下的少 shot Setting下表现出state-of-the-art的result，在MultimodalQA数据集上超过所有基线和数据集全部训练的方法 (experimental results show that our framework achieves state-of-the-art results under the few-shot setting on the MultimodalQA dataset, outperforming all baselines and methods trained on the full dataset)<details>
<summary>Abstract</summary>
In the real world, knowledge often exists in a multimodal and heterogeneous form. Addressing the task of question answering with hybrid data types, including text, tables, and images, is a challenging task (MMHQA). Recently, with the rise of large language models (LLM), in-context learning (ICL) has become the most popular way to solve QA problems. We propose MMHQA-ICL framework for addressing this problems, which includes stronger heterogeneous data retriever and an image caption module. Most importantly, we propose a Type-specific In-context Learning Strategy for MMHQA, enabling LLMs to leverage their powerful performance in this task. We are the first to use end-to-end LLM prompting method for this task. Experimental results demonstrate that our framework outperforms all baselines and methods trained on the full dataset, achieving state-of-the-art results under the few-shot setting on the MultimodalQA dataset.
</details>
<details>
<summary>摘要</summary>
在现实世界中，知识经常存在多模式和多种形式。解决问答问题时使用混合数据类型，包括文本、表格和图像，是一项复杂的任务（MMHQA）。近些年来，大型自然语言模型（LLM）的出现，使得在场景学习（ICL）成为解决问答问题的最受欢迎方法。我们提出了MMHQA-ICL框架，该框架包括更强的多种数据检索器和图像描述模块。最重要的是，我们提出了特定类型的场景学习策略，使得LLM可以在这个任务中发挥出色的表现。我们是第一个使用端到端LLM推荐方法来解决这个任务。实验结果表明，我们的框架在几shotSetting下超过了所有基线和已经训练的方法，在多媒体Question Answering dataset上达到了当前最佳result。
</details></li>
</ul>
<hr>
<h2 id="Data-Augmentation-for-Conversational-AI"><a href="#Data-Augmentation-for-Conversational-AI" class="headerlink" title="Data Augmentation for Conversational AI"></a>Data Augmentation for Conversational AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04739">http://arxiv.org/abs/2309.04739</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dataug-convai/dataug-convai.github.io">https://github.com/dataug-convai/dataug-convai.github.io</a></li>
<li>paper_authors: Heydar Soudani, Evangelos Kanoulas, Faegheh Hasibi</li>
<li>for: 提高对话系统的信息访问，超越单个查询的限制</li>
<li>methods: 使用数据扩充（DA）方法，解决低资源领域和语言的数据罕见问题</li>
<li>results: 提供了对话系统中最新的扩充技术，包括对话生成、开放领域对话生成和任务域对话生成，以及评估这些模型的不同方法。<details>
<summary>Abstract</summary>
Advancements in conversational systems have revolutionized information access, surpassing the limitations of single queries. However, developing dialogue systems requires a large amount of training data, which is a challenge in low-resource domains and languages. Traditional data collection methods like crowd-sourcing are labor-intensive and time-consuming, making them ineffective in this context. Data augmentation (DA) is an affective approach to alleviate the data scarcity problem in conversational systems. This tutorial provides a comprehensive and up-to-date overview of DA approaches in the context of conversational systems. It highlights recent advances in conversation augmentation, open domain and task-oriented conversation generation, and different paradigms of evaluating these models. We also discuss current challenges and future directions in order to help researchers and practitioners to further advance the field in this area.
</details>
<details>
<summary>摘要</summary>
“对话系统的进步已经改变了信息存取的方式，超过了单一查询的限制。但是开发对话系统需要大量的训练数据，这是低资源领域和语言的挑战。传统的数据收集方法如聚思网络是劳动密集和时间负担重的，使其在这个上下文中无法有效。数据增强（DA）是一种有效的方法来解决数据缺乏问题在对话系统中。本教程提供了对话系统中 DA 方法的全面和最新的概述，包括最新的对话增强、开放领域和任务对话生成、以及不同类型的评估这些模型。我们还讨论了现在的挑战和未来的方向，以帮助研究者和实践者继续推动这个领域。”Note that Simplified Chinese is used here, as it is the more widely used standard for Chinese writing in mainland China and other countries. If you prefer Traditional Chinese, I can provide that version as well.
</details></li>
</ul>
<hr>
<h2 id="Towards-Better-Multi-modal-Keyphrase-Generation-via-Visual-Entity-Enhancement-and-Multi-granularity-Image-Noise-Filtering"><a href="#Towards-Better-Multi-modal-Keyphrase-Generation-via-Visual-Entity-Enhancement-and-Multi-granularity-Image-Noise-Filtering" class="headerlink" title="Towards Better Multi-modal Keyphrase Generation via Visual Entity Enhancement and Multi-granularity Image Noise Filtering"></a>Towards Better Multi-modal Keyphrase Generation via Visual Entity Enhancement and Multi-granularity Image Noise Filtering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04734">http://arxiv.org/abs/2309.04734</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifan Dong, Suhang Wu, Fandong Meng, Jie Zhou, Xiaoli Wang, Jianxin Lin, Jinsong Su</li>
<li>for: 本研究旨在提出一种基于多模态信息的关键短语生成模型，以便更好地捕捉输入文本和图像对的核心意思。</li>
<li>methods: 我们提出了一种新的多模态关键短语生成模型，该模型不仅通过外部知识补充模型输入，还能够有效地过滤图像噪音。我们首先引入图像外部视觉实体作为模型输入，以便进行交叉模态Semantic对齐。其次，我们同时计算图像文本匹配分数和图像区域文本相关分数，以进行多granularity图像噪音过滤。尤其是，我们引入图像区域和真实关键短语之间的相关分数，以进一步改进图像匹配分数的计算。</li>
<li>results: 我们在 benchmark 数据集上进行了多组实验，实验结果表明，我们的模型可以达到领先的性能。我们的代码可以在 <a target="_blank" rel="noopener" href="https://github.com/DeepLearnXMU/MM-MKP">https://github.com/DeepLearnXMU/MM-MKP</a> 上找到。<details>
<summary>Abstract</summary>
Multi-modal keyphrase generation aims to produce a set of keyphrases that represent the core points of the input text-image pair. In this regard, dominant methods mainly focus on multi-modal fusion for keyphrase generation. Nevertheless, there are still two main drawbacks: 1) only a limited number of sources, such as image captions, can be utilized to provide auxiliary information. However, they may not be sufficient for the subsequent keyphrase generation. 2) the input text and image are often not perfectly matched, and thus the image may introduce noise into the model. To address these limitations, in this paper, we propose a novel multi-modal keyphrase generation model, which not only enriches the model input with external knowledge, but also effectively filters image noise. First, we introduce external visual entities of the image as the supplementary input to the model, which benefits the cross-modal semantic alignment for keyphrase generation. Second, we simultaneously calculate an image-text matching score and image region-text correlation scores to perform multi-granularity image noise filtering. Particularly, we introduce the correlation scores between image regions and ground-truth keyphrases to refine the calculation of the previously-mentioned correlation scores. To demonstrate the effectiveness of our model, we conduct several groups of experiments on the benchmark dataset.   Experimental results and in-depth analyses show that our model achieves the state-of-the-art performance. Our code is available on https://github.com/DeepLearnXMU/MM-MKP.
</details>
<details>
<summary>摘要</summary>
多Modal键词生成的目标是生成对输入文本-图像对的核心点的集合。在这意义上，主宰方法主要强调多Modal融合 для键词生成。然而，还有两个主要缺点：1）只有一定的资源，如图像描述，可以提供辅助信息。然而，这些资源可能不够充分 для后续的键词生成。2）输入文本和图像可能不匹配，因此图像可能会干扰模型。为了解决这些限制，在这篇论文中，我们提出了一个新的多Modal键词生成模型，不仅丰富模型的输入，而且有效地范围干扰图像噪声。首先，我们将图像的外部视觉实体作为模型的辅助输入，从而促进跨Modal semantic alignment。其次，我们同时计算图像文本匹配分数和图像区域文本相似度分数，以进行多粒度图像噪声范围。特别是，我们引入图像区域和真实键词之间的相似度分数，以进一步调整先前述的相似度分数。为了证明我们的模型的效果，我们进行了多组实验，并进行了深入的分析。结果显示，我们的模型在 benchmark 数据集上达到了国际级的表现。我们的代码可以在 <https://github.com/DeepLearnXMU/MM-MKP> 上下载。
</details></li>
</ul>
<hr>
<h2 id="EPA-Easy-Prompt-Augmentation-on-Large-Language-Models-via-Multiple-Sources-and-Multiple-Targets"><a href="#EPA-Easy-Prompt-Augmentation-on-Large-Language-Models-via-Multiple-Sources-and-Multiple-Targets" class="headerlink" title="EPA: Easy Prompt Augmentation on Large Language Models via Multiple Sources and Multiple Targets"></a>EPA: Easy Prompt Augmentation on Large Language Models via Multiple Sources and Multiple Targets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04725">http://arxiv.org/abs/2309.04725</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongyuan Lu, Wai Lam<br>for: This paper aims to improve the performance of large language models (LLMs) on various natural language processing (NLP) tasks by developing a novel method called Easy Prompt Augmentation (EPA).methods: The proposed EPA method uses paraphrasing as an augmentation method to automatically generate multiple sources&#x2F;targets for demonstrations, which are then used to improve the performance of LLMs on NLP tasks.results: The proposed EPA method effectively improves the performance of LLMs on various NLP tasks, including natural language inference and machine translation, covering tens of languages.<details>
<summary>Abstract</summary>
Large language models (LLMs) have shown promising performance on various NLP tasks via task prompting. And their performance can be further improved by appending task demonstrations to the head of the prompt. And usually, a better performance can be achieved with more demonstrations. However, asking the users to write the demonstrations can be cumbersome. As a simple yet cost-effective workaround, this paper proposes a novel method called EPA (\textbf{E}asy \textbf{P}rompt \textbf{A}ugmentation)\footnote{While this paper considers augmenting prompts via demonstrations, we name it EPA as the name EDA is already taken by a well-known NLP method \citep{wei-zou-2019-eda}.} that effectively minimizes user efforts in writing demonstrations while improving the model performance at the same time. EPA achieves these goals by automatically augmenting the demonstrations with multiple sources/targets, where each of them paraphrases each other. This is well motivated as augmenting data via paraphrasing effectively improves neural language models. EPA thus employs paraphrasing as an augmentation method for in-context learning. Extensive experiments indicate that EPA effectively improves both NLU and NLG tasks, covering from natural language inference to machine translation in translating tens of languages.\footnote{Code and data will be released upon publication.}
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在不同的自然语言处理（NLP）任务上显示了拥有推进性的表现，并且可以通过将任务示范复制到请求的首部来进一步提高表现。然而，要求用户写示范可能是一个困难和费时的过程。为了解决这个问题，这篇论文提出了一个简单 yet cost-effective的方法，即EPA（易于提高表现的请求补充，即EDA的一个修改）。EPA透过自动将示范复制多个来源/目标，每个来源/目标都会对另一个进行重新诠释，以提高语言模型的表现。这是因为将数据进行重新诠释实际上可以提高神经语言模型的表现。EPA因此使用重新诠释作为对应的增强方法，以进行内容学习。实验结果显示，EPA可以有效地提高自然语言推理和机器翻译等多种NLP任务，涵盖了多种语言的翻译。[Code和数据将在出版时发布.]
</details></li>
</ul>
<hr>
<h2 id="Embedding-structure-matters-Comparing-methods-to-adapt-multilingual-vocabularies-to-new-languages"><a href="#Embedding-structure-matters-Comparing-methods-to-adapt-multilingual-vocabularies-to-new-languages" class="headerlink" title="Embedding structure matters: Comparing methods to adapt multilingual vocabularies to new languages"></a>Embedding structure matters: Comparing methods to adapt multilingual vocabularies to new languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04679">http://arxiv.org/abs/2309.04679</a></li>
<li>repo_url: None</li>
<li>paper_authors: C. M. Downey, Terra Blevins, Nora Goldfine, Shane Steinert-Threlkeld</li>
<li>for: 本研究旨在提高低资源语言下的模型性能，通过特点化多语言模型的词库和嵌入矩阵。</li>
<li>methods: 本研究提出了一些简单的技术来取代多语言词库，包括词库特定化和嵌入矩阵重新初始化策略。</li>
<li>results: 研究结果显示，使用词库特定化和嵌入矩阵重新初始化策略可以提高低资源语言下的模型性能，并且与ocus方法相当。<details>
<summary>Abstract</summary>
Pre-trained multilingual language models underpin a large portion of modern NLP tools outside of English. A strong baseline for specializing these models for specific languages is Language-Adaptive Pre-Training (LAPT). However, retaining a large cross-lingual vocabulary and embedding matrix comes at considerable excess computational cost during adaptation. In this study, we propose several simple techniques to replace a cross-lingual vocabulary with a compact, language-specific one. Namely, we address strategies for re-initializing the token embedding matrix after vocabulary specialization. We then provide a systematic experimental comparison of our techniques, in addition to the recently-proposed Focus method. We demonstrate that: 1) Embedding-replacement techniques in the monolingual transfer literature are inadequate for adapting multilingual models. 2) Replacing cross-lingual vocabularies with smaller specialized ones provides an efficient method to improve performance in low-resource languages. 3) Simple embedding re-initialization techniques based on script-wise sub-distributions rival techniques such as Focus, which rely on similarity scores obtained from an auxiliary model.
</details>
<details>
<summary>摘要</summary>
预训练多语言模型在现代自然语言处理（NLP）工具中占据主导地位，尤其是外语模型。为了特化这些模型，我们可以使用语言适应预训练（LAPT）。然而，保留大量的跨语言词汇和嵌入矩阵来自恰到位的计算成本增加。在本研究中，我们提出了一些简单的技巧来替代跨语言词汇。首先，我们考虑了在特циализиasi词汇后重新初始化Token嵌入矩阵的策略。然后，我们对我们的技巧进行了系统性的实验比较，以及最近提出的关注方法（Focus）。我们的结果表明：1）在单语言传输文献中使用嵌入替换技术是不充分的。2）将跨语言词汇替换为更小的特定语言词汇可以有效地提高低资源语言的性能。3）基于书写系统的子分布的简单嵌入重新初始化技术可以与关注方法（Focus）相比。
</details></li>
</ul>
<hr>
<h2 id="MADLAD-400-A-Multilingual-And-Document-Level-Large-Audited-Dataset"><a href="#MADLAD-400-A-Multilingual-And-Document-Level-Large-Audited-Dataset" class="headerlink" title="MADLAD-400: A Multilingual And Document-Level Large Audited Dataset"></a>MADLAD-400: A Multilingual And Document-Level Large Audited Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04662">http://arxiv.org/abs/2309.04662</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sneha Kudugunta, Isaac Caswell, Biao Zhang, Xavier Garcia, Christopher A. Choquette-Choo, Katherine Lee, Derrick Xin, Aditya Kusupati, Romi Stella, Ankur Bapna, Orhan Firat</li>
<li>for: 这个论文是为了介绍一个新的、通用领域的3Ttoken单语言 dataset，名为MADLAD-400，该 dataset 基于 CommonCrawl，覆盖了419种语言。</li>
<li>methods: 论文使用了自我审核的方法来检测 dataset 的局限性，并讨论了数据审核在 dataset 创建过程中的作用。</li>
<li>results: 论文在使用公共可用数据进行训练后，发现一个10.7B参数的多语言翻译模型和一个8B参数的语言模型，并对不同领域进行评估。Results 表明这些模型在翻译和ew-shot翻译方面具有竞争力，并且提供了基准模型供研究人员使用。<details>
<summary>Abstract</summary>
We introduce MADLAD-400, a manually audited, general domain 3T token monolingual dataset based on CommonCrawl, spanning 419 languages. We discuss the limitations revealed by self-auditing MADLAD-400, and the role data auditing had in the dataset creation process. We then train and release a 10.7B-parameter multilingual machine translation model on 250 billion tokens covering over 450 languages using publicly available data, and find that it is competitive with models that are significantly larger, and report the results on different domains. In addition, we train a 8B-parameter language model, and assess the results on few-shot translation. We make the baseline models available to the research community.
</details>
<details>
<summary>摘要</summary>
我们介绍MADLAD-400，一个人工审核的、通用领域3Token单语言数据集，基于CommonCrawl，覆盖419种语言。我们讨论自我审核MADLAD-400中的局限性，以及数据审核在数据集创建过程中的角色。然后我们使用公共可用数据进行训练，并发布一个10.7B参数的多语言翻译模型，覆盖超过450种语言，并发现其与更大的模型相比竞争性强。此外，我们还训练了8B参数的语言模型，并评估其在几个语言翻译中的表现。我们将基准模型公开发布给研究社区。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Large-Language-Models-for-Communication-Games-An-Empirical-Study-on-Werewolf"><a href="#Exploring-Large-Language-Models-for-Communication-Games-An-Empirical-Study-on-Werewolf" class="headerlink" title="Exploring Large Language Models for Communication Games: An Empirical Study on Werewolf"></a>Exploring Large Language Models for Communication Games: An Empirical Study on Werewolf</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04658">http://arxiv.org/abs/2309.04658</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuzhuang Xu, Shuo Wang, Peng Li, Fuwen Luo, Xiaolong Wang, Weidong Liu, Yang Liu</li>
<li>for: 这个论文探讨了如何让大语言模型（LLMs）参与交流游戏，并提出了一个不需要调整的框架。</li>
<li>methods: 该方法采用了采集和反思过去交流和经验来提高。</li>
<li>results: 实验表明，该框架可以无需调整LLMs的参数来玩“人狼”游戏，并且在实验中出现了策略性行为，表明将LLMs引入交流游戏和相关领域是一个有前途的研究方向。<details>
<summary>Abstract</summary>
Communication games, which we refer to as incomplete information games that heavily depend on natural language communication, hold significant research value in fields such as economics, social science, and artificial intelligence. In this work, we explore the problem of how to engage large language models (LLMs) in communication games, and in response, propose a tuning-free framework. Our approach keeps LLMs frozen, and relies on the retrieval and reflection on past communications and experiences for improvement. An empirical study on the representative and widely-studied communication game, ``Werewolf'', demonstrates that our framework can effectively play Werewolf game without tuning the parameters of the LLMs. More importantly, strategic behaviors begin to emerge in our experiments, suggesting that it will be a fruitful journey to engage LLMs in communication games and associated domains.
</details>
<details>
<summary>摘要</summary>
通信游戏，我们称之为受限信息游戏，在经济学、社会科学和人工智能等领域具有重要的研究价值。在这种游戏中，我们研究如何让大型自然语言模型（LLM）参与通信游戏，并提出了一个不需要调参的框架。我们的方法是冻结LLM，并基于过去的交流和经验进行改进。在一个代表性和广泛研究的通信游戏“狼人”的实验中，我们证明了我们的框架可以无需调参地在狼人游戏中进行效果性的游戏。此外，我们的实验还发现了一些策略性的行为，这表示将LLM参与到通信游戏和相关领域的研究将是一项有前途的冒险。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/09/cs.CL_2023_09_09/" data-id="clogxf3lr00a95xra5lux69qw" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_09_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/09/cs.LG_2023_09_09/" class="article-date">
  <time datetime="2023-09-09T10:00:00.000Z" itemprop="datePublished">2023-09-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/09/cs.LG_2023_09_09/">cs.LG - 2023-09-09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Symplectic-Structure-Aware-Hamiltonian-Graph-Embeddings"><a href="#Symplectic-Structure-Aware-Hamiltonian-Graph-Embeddings" class="headerlink" title="Symplectic Structure-Aware Hamiltonian (Graph) Embeddings"></a>Symplectic Structure-Aware Hamiltonian (Graph) Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04885">http://arxiv.org/abs/2309.04885</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxu Liu, Xinping Yi, Tianle Zhang, Xiaowei Huang</li>
<li>for: 这个研究旨在提高传统图形神经网络（GNN）的灵活性，以便更好地适应不同的图形几何。</li>
<li>methods: 这个研究使用了规律方程式来更新节点特征，并运用了里曼对称数学来自适性地学习底下的对称结构。</li>
<li>results: 这个研究获得了在不同类型图形资料集上的优秀表现和灵活性，并且在训练过程中实现了能量守恒性。<details>
<summary>Abstract</summary>
In traditional Graph Neural Networks (GNNs), the assumption of a fixed embedding manifold often limits their adaptability to diverse graph geometries. Recently, Hamiltonian system-inspired GNNs are proposed to address the dynamic nature of such embeddings by incorporating physical laws into node feature updates. In this work, we present SAH-GNN, a novel approach that generalizes Hamiltonian dynamics for more flexible node feature updates. Unlike existing Hamiltonian-inspired GNNs, SAH-GNN employs Riemannian optimization on the symplectic Stiefel manifold to adaptively learn the underlying symplectic structure during training, circumventing the limitations of existing Hamiltonian GNNs that rely on a pre-defined form of standard symplectic structure. This innovation allows SAH-GNN to automatically adapt to various graph datasets without extensive hyperparameter tuning. Moreover, it conserves energy during training such that the implicit Hamiltonian system is physically meaningful. To this end, we empirically validate SAH-GNN's superior performance and adaptability in node classification tasks across multiple types of graph datasets.
</details>
<details>
<summary>摘要</summary>
传统的图 neuronal networks (GNNs) 假设了固定的嵌入 manifold 经常限制它们在不同的图 геометрии上的适应性。最近，基于 Hamiltonian 系统的 GNNs 被提出来解决图嵌入的动态性，通过将物理法则 integrate 到节点特征更新中。在这项工作中，我们提出了 SAH-GNN，一种新的方法，可以扩展 Hamiltonian 动力学来更 flexible 的节点特征更新。与现有的 Hamiltonian-inspired GNNs 不同，SAH-GNN 使用 Riemannian 优化在 симплектиче Stiefel 拟合中学习Podcast 的下面结构，从而自适应地适应不同的图数据集。这种创新使得 SAH-GNN 可以自动适应不同类型的图数据集，而不需要较多的 гипер参数调整。此外，它保持了能量的 física 意义，从而使得 implicit Hamiltonian 系统 Physically meaningful。为了证明 SAH-GNN 的超过性和适应性，我们在多种类型的图数据集上进行了 empirical 验证。
</details></li>
</ul>
<hr>
<h2 id="A-Gentle-Introduction-to-Gradient-Based-Optimization-and-Variational-Inequalities-for-Machine-Learning"><a href="#A-Gentle-Introduction-to-Gradient-Based-Optimization-and-Variational-Inequalities-for-Machine-Learning" class="headerlink" title="A Gentle Introduction to Gradient-Based Optimization and Variational Inequalities for Machine Learning"></a>A Gentle Introduction to Gradient-Based Optimization and Variational Inequalities for Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04877">http://arxiv.org/abs/2309.04877</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neha S. Wadia, Yatin Dandi, Michael I. Jordan</li>
<li>for: 这篇论文主要针对的是机器学习领域的扩展和进步，具体来说是从优化角度出发，转移到决策和多代人问题上。</li>
<li>methods: 论文使用的方法包括落差点和矩阵游戏等，这些方法可以帮助解决机器学习问题中的新的数学挑战。</li>
<li>results: 论文提供了一种更加广泛的框架来理解机器学习中的梯度下降算法，包括落差点和矩阵游戏等。但是，论文的主要重点不是提供具体的计算证明，而是为了提供动机和直觉。<details>
<summary>Abstract</summary>
The rapid progress in machine learning in recent years has been based on a highly productive connection to gradient-based optimization. Further progress hinges in part on a shift in focus from pattern recognition to decision-making and multi-agent problems. In these broader settings, new mathematical challenges emerge that involve equilibria and game theory instead of optima. Gradient-based methods remain essential -- given the high dimensionality and large scale of machine-learning problems -- but simple gradient descent is no longer the point of departure for algorithm design. We provide a gentle introduction to a broader framework for gradient-based algorithms in machine learning, beginning with saddle points and monotone games, and proceeding to general variational inequalities. While we provide convergence proofs for several of the algorithms that we present, our main focus is that of providing motivation and intuition.
</details>
<details>
<summary>摘要</summary>
随着机器学习领域的快速进步，总是基于高度生产力的梯度基于优化。未来的进步受到一定程度的宽度化的影响，转移焦点从形式识别向决策和多代人问题。在这些更广泛的设置下，新的数学挑战出现，涉及到平衡和游戏理论而不是最优点。梯度基于方法仍然是机器学习问题中的基础，但简单的梯度下降不再是算法设计的起点。我们提供一个温顺的引入，开始于极点和 monotone 游戏，然后进行总variational 不等式。虽提供了一些算法的收敛证明，但我们的主要焦点是提供动机和直觉。
</details></li>
</ul>
<hr>
<h2 id="Approximating-ReLU-on-a-Reduced-Ring-for-Efficient-MPC-based-Private-Inference"><a href="#Approximating-ReLU-on-a-Reduced-Ring-for-Efficient-MPC-based-Private-Inference" class="headerlink" title="Approximating ReLU on a Reduced Ring for Efficient MPC-based Private Inference"></a>Approximating ReLU on a Reduced Ring for Efficient MPC-based Private Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04875">http://arxiv.org/abs/2309.04875</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kiwan Maeng, G. Edward Suh</li>
<li>for: 这篇论文旨在提高无信赖服务器端的机器学习运算速度，并维护用户的隐私敏感资料。</li>
<li>methods: 本文使用多方点 computation（MPC）技术，并运用一个名为 HummingBird 的框架，将 ReLU 评估过程中的通信量大幅降低。</li>
<li>results: HummingBird 可以在多服务器端实现高精度机器学习运算，并在实际应用中实现2.03-2.67倍的终端执行时间增速，最高可达8.64倍。<details>
<summary>Abstract</summary>
Secure multi-party computation (MPC) allows users to offload machine learning inference on untrusted servers without having to share their privacy-sensitive data. Despite their strong security properties, MPC-based private inference has not been widely adopted in the real world due to their high communication overhead. When evaluating ReLU layers, MPC protocols incur a significant amount of communication between the parties, making the end-to-end execution time multiple orders slower than its non-private counterpart.   This paper presents HummingBird, an MPC framework that reduces the ReLU communication overhead significantly by using only a subset of the bits to evaluate ReLU on a smaller ring. Based on theoretical analyses, HummingBird identifies bits in the secret share that are not crucial for accuracy and excludes them during ReLU evaluation to reduce communication. With its efficient search engine, HummingBird discards 87--91% of the bits during ReLU and still maintains high accuracy. On a real MPC setup involving multiple servers, HummingBird achieves on average 2.03--2.67x end-to-end speedup without introducing any errors, and up to 8.64x average speedup when some amount of accuracy degradation can be tolerated, due to its up to 8.76x communication reduction.
</details>
<details>
<summary>摘要</summary>
安全多方计算（MPC）使用户可以在不信任服务器上执行机器学习推理，而不需要将隐私敏感数据分享。尽管它们具有强安全性质，但MPC基于私人推理还没有在实际应用中广泛采用，因为它们的通信开销较高。在评估ReLU层时，MPC协议在党之间交换大量数据，使总端到端执行时间与非私人计算相比多次 slower。本文介绍了HummingBird框架，它可以减少ReLU通信开销，使用一个较小的环来评估ReLU。基于理论分析，HummingBird可以在秘密分享中标识不重要的比特，并在ReLU评估中排除它们，以减少通信。具有高效的搜索引擎，HummingBird可以在ReLU评估中抛弃87--91%的比特，并仍保持高精度。在多服务器MPC设置中，HummingBird在平均2.03--2.67倍的端到端执行时间内实现了无错误的8.76倍通信减少。
</details></li>
</ul>
<hr>
<h2 id="Approximation-Results-for-Gradient-Descent-trained-Neural-Networks"><a href="#Approximation-Results-for-Gradient-Descent-trained-Neural-Networks" class="headerlink" title="Approximation Results for Gradient Descent trained Neural Networks"></a>Approximation Results for Gradient Descent trained Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04860">http://arxiv.org/abs/2309.04860</a></li>
<li>repo_url: None</li>
<li>paper_authors: G. Welper</li>
<li>for: 这篇论文的目的是为了提供对具有 Sobolev 的函数进行预测的神经网络的近似保证。</li>
<li>methods: 这篇论文使用的方法包括 gradient flow 和 neural tangent kernel (NTK) 分析。</li>
<li>results: 论文得到的结果是，对于 Sobolev 的函数，采用 gradient flow 训练的神经网络可以在不超过参数的情况下提供高度的近似保证。<details>
<summary>Abstract</summary>
The paper contains approximation guarantees for neural networks that are trained with gradient flow, with error measured in the continuous $L_2(\mathbb{S}^{d-1})$-norm on the $d$-dimensional unit sphere and targets that are Sobolev smooth. The networks are fully connected of constant depth and increasing width. Although all layers are trained, the gradient flow convergence is based on a neural tangent kernel (NTK) argument for the non-convex second but last layer. Unlike standard NTK analysis, the continuous error norm implies an under-parametrized regime, possible by the natural smoothness assumption required for approximation. The typical over-parametrization re-enters the results in form of a loss in approximation rate relative to established approximation methods for Sobolev smooth functions.
</details>
<details>
<summary>摘要</summary>
文章提供了对神经网络的规uli guarantees，该网络通过梯度流进行训练，错误度量为绝对-$L_2(\mathbb{S}^{d-1})$ norm在$d$维单位球上，目标函数具有 Sobolev 的准确性。网络是完全连接的，深度和宽度都是常数。虽然所有层都被训练，但梯度流 converges based on neural tangent kernel（NTK）Argument for the non-convex second but last layer。与标准 NTK 分析不同，绝对错误 norm implies an under-parametrized regime, 可能由自然的 Sobolev 的假设所需的approximation。通常的过 Parametrization 重新出现在结果中，relative to established approximation methods for Sobolev smooth functions as a loss in approximation rate.
</details></li>
</ul>
<hr>
<h2 id="HAct-Out-of-Distribution-Detection-with-Neural-Net-Activation-Histograms"><a href="#HAct-Out-of-Distribution-Detection-with-Neural-Net-Activation-Histograms" class="headerlink" title="HAct: Out-of-Distribution Detection with Neural Net Activation Histograms"></a>HAct: Out-of-Distribution Detection with Neural Net Activation Histograms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04837">http://arxiv.org/abs/2309.04837</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sudeepta Mondal, Ganesh Sundaramoorthi</li>
<li>for: 检测训练后神经网络模型对于非典型数据（out-of-distribution，OOD）的探测</li>
<li>methods: 提出了一种简单、高效、准确的OOD探测方法，基于神经网络层输出值的激活分布（HAct）</li>
<li>results: 在多个OOD图像分类benchmark上达到了state-of-the-art的准确率（TPR），例如使用Resnet-50达到了95%的TPR，同时具有低的假阳性率（FP），比前一代方法提高20.66%。<details>
<summary>Abstract</summary>
We propose a simple, efficient, and accurate method for detecting out-of-distribution (OOD) data for trained neural networks, a potential first step in methods for OOD generalization. We propose a novel descriptor, HAct - activation histograms, for OOD detection, that is, probability distributions (approximated by histograms) of output values of neural network layers under the influence of incoming data. We demonstrate that HAct is significantly more accurate than state-of-the-art on multiple OOD image classification benchmarks. For instance, our approach achieves a true positive rate (TPR) of 95% with only 0.05% false-positives using Resnet-50 on standard OOD benchmarks, outperforming previous state-of-the-art by 20.66% in the false positive rate (at the same TPR of 95%). The low computational complexity and the ease of implementation make HAct suitable for online implementation in monitoring deployed neural networks in practice at scale.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Correcting-sampling-biases-via-importance-reweighting-for-spatial-modeling"><a href="#Correcting-sampling-biases-via-importance-reweighting-for-spatial-modeling" class="headerlink" title="Correcting sampling biases via importance reweighting for spatial modeling"></a>Correcting sampling biases via importance reweighting for spatial modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04824">http://arxiv.org/abs/2309.04824</a></li>
<li>repo_url: None</li>
<li>paper_authors: Boris Prokhorov, Diana Koldasbayeva, Alexey Zaytsev</li>
<li>for: 该 paper 是为了解决Machine Learning模型中错误估计中的分布偏见问题，尤其是在环境学研究中的空间数据中。</li>
<li>methods: 该方法基于重要度抽样的想法，通过考虑愿望错误和可用数据之间的差异，重新权重错误在每个样点上， нейтралиzed 分布偏见。使用重要度抽样技术和kernel density estimation进行重新权重。</li>
<li>results: 我们使用人工数据，模拟实际的空间数据集， validate 该方法的有效性。我们发现，该方法可以减少预测错误的总体错误率，从7%降低到2%，并且随着样本规模增加，预测错误率越来越小。<details>
<summary>Abstract</summary>
In machine learning models, the estimation of errors is often complex due to distribution bias, particularly in spatial data such as those found in environmental studies. We introduce an approach based on the ideas of importance sampling to obtain an unbiased estimate of the target error. By taking into account difference between desirable error and available data, our method reweights errors at each sample point and neutralizes the shift. Importance sampling technique and kernel density estimation were used for reweighteing. We validate the effectiveness of our approach using artificial data that resemble real-world spatial datasets. Our findings demonstrate advantages of the proposed approach for the estimation of the target error, offering a solution to a distribution shift problem. Overall error of predictions dropped from 7% to just 2% and it gets smaller for larger samples.
</details>
<details>
<summary>摘要</summary>
在机器学习模型中，错误估计通常受到分布偏见的影响，特别是在环境学研究中的空间数据中。我们介绍了一种基于重要性抽样的方法，以获得不偏的目标错误估计。通过考虑愿景错误和可用数据之间的差异，我们的方法在每个抽样点重新权重错误。我们使用重要性抽样技术和核密度估计来重新权重错误。我们使用人工数据，模拟实际世界的空间数据集，以验证我们的方法的效果。我们的发现表明，我们的方法可以减少预测错误的总错误率，从7%降低到2%，并且随着样本规模的增加，错误率会更加小。
</details></li>
</ul>
<hr>
<h2 id="Detecting-Violations-of-Differential-Privacy-for-Quantum-Algorithms"><a href="#Detecting-Violations-of-Differential-Privacy-for-Quantum-Algorithms" class="headerlink" title="Detecting Violations of Differential Privacy for Quantum Algorithms"></a>Detecting Violations of Differential Privacy for Quantum Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04819">http://arxiv.org/abs/2309.04819</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ji Guan, Wang Fang, Mingyu Huang, Mingsheng Ying</li>
<li>for: 本研究旨在提出一种形式化的检测方法，用于检测量子算法中的不同步私隐私泄露。</li>
<li>methods: 本文使用tensor网络数据结构和量子计算平台TensorFlow Quantum和TorchQuantum进行实现，开发了一种检测算法，可以自动生成泄露信息，以便检测量子算法中的不同步私隐私泄露。</li>
<li>results: 实验结果表明，本方法可以准确地检测大多数量子算法中的不同步私隐私泄露，包括量子优化算法、量子机器学习模型、量子约等优化算法和量子均衡算法。<details>
<summary>Abstract</summary>
Quantum algorithms for solving a wide range of practical problems have been proposed in the last ten years, such as data search and analysis, product recommendation, and credit scoring. The concern about privacy and other ethical issues in quantum computing naturally rises up. In this paper, we define a formal framework for detecting violations of differential privacy for quantum algorithms. A detection algorithm is developed to verify whether a (noisy) quantum algorithm is differentially private and automatically generate bugging information when the violation of differential privacy is reported. The information consists of a pair of quantum states that violate the privacy, to illustrate the cause of the violation. Our algorithm is equipped with Tensor Networks, a highly efficient data structure, and executed both on TensorFlow Quantum and TorchQuantum which are the quantum extensions of famous machine learning platforms -- TensorFlow and PyTorch, respectively. The effectiveness and efficiency of our algorithm are confirmed by the experimental results of almost all types of quantum algorithms already implemented on realistic quantum computers, including quantum supremacy algorithms (beyond the capability of classical algorithms), quantum machine learning models, quantum approximate optimization algorithms, and variational quantum eigensolvers with up to 21 quantum bits.
</details>
<details>
<summary>摘要</summary>
近十年内，有许多关于实际问题的量子算法被提出，如数据搜索和分析、产品推荐和借记评分。随着量子计算技术的发展，关注隐私和其他伦理问题的担忧自然而生。在这篇论文中，我们定义了一个形式化的检测框架，用于检测量子算法中的不同隐私抵触。我们开发了一个检测算法，用于验证（含噪）量子算法是否遵循不同隐私规则，并自动生成违反隐私规则的信息。这些信息包括两个量子状态，用于说明违反的原因。我们的算法使用了矩阵网络，一种高效的数据结构，并在TensorFlow Quantum和TorchQuantum上执行，这两者分别是矩阵Flow和PyTorch的量子扩展。我们的实验结果表明，我们的算法具有高效和高可靠性。
</details></li>
</ul>
<hr>
<h2 id="Neural-Latent-Geometry-Search-Product-Manifold-Inference-via-Gromov-Hausdorff-Informed-Bayesian-Optimization"><a href="#Neural-Latent-Geometry-Search-Product-Manifold-Inference-via-Gromov-Hausdorff-Informed-Bayesian-Optimization" class="headerlink" title="Neural Latent Geometry Search: Product Manifold Inference via Gromov-Hausdorff-Informed Bayesian Optimization"></a>Neural Latent Geometry Search: Product Manifold Inference via Gromov-Hausdorff-Informed Bayesian Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04810">http://arxiv.org/abs/2309.04810</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haitz Saez de Ocariz Borde, Alvaro Arroyo, Ismael Morales, Ingmar Posner, Xiaowen Dong</li>
<li>for: 提高机器学习模型的性能，通过调整幽默空间的几何结构，使其更好地模型数据结构。</li>
<li>methods: 提出了一种名为神经幽默几何搜索（NLGS）的新形式，它是一种基于度量几何的方法，可以自动地找到最佳的幽默空间，以提高模型的性能。</li>
<li>results: 通过实验证明，NLGS可以高效地找到多种机器学习模型的最佳幽默空间，提高模型的性能。<details>
<summary>Abstract</summary>
Recent research indicates that the performance of machine learning models can be improved by aligning the geometry of the latent space with the underlying data structure. Rather than relying solely on Euclidean space, researchers have proposed using hyperbolic and spherical spaces with constant curvature, or combinations thereof, to better model the latent space and enhance model performance. However, little attention has been given to the problem of automatically identifying the optimal latent geometry for the downstream task. We mathematically define this novel formulation and coin it as neural latent geometry search (NLGS). More specifically, we introduce a principled method that searches for a latent geometry composed of a product of constant curvature model spaces with minimal query evaluations. To accomplish this, we propose a novel notion of distance between candidate latent geometries based on the Gromov-Hausdorff distance from metric geometry. In order to compute the Gromov-Hausdorff distance, we introduce a mapping function that enables the comparison of different manifolds by embedding them in a common high-dimensional ambient space. Finally, we design a graph search space based on the calculated distances between candidate manifolds and use Bayesian optimization to search for the optimal latent geometry in a query-efficient manner. This is a general method which can be applied to search for the optimal latent geometry for a variety of models and downstream tasks. Extensive experiments on synthetic and real-world datasets confirm the efficacy of our method in identifying the optimal latent geometry for multiple machine learning problems.
</details>
<details>
<summary>摘要</summary>
We propose a novel approach called neural latent geometry search (NLGS) to address this problem. NLGS is a principled method that searches for a latent geometry composed of a product of constant curvature model spaces with minimal query evaluations. To accomplish this, we introduce a new notion of distance between candidate latent geometries based on the Gromov-Hausdorff distance from metric geometry. This distance measure allows us to compare different manifolds by embedding them in a common high-dimensional ambient space.We then design a graph search space based on the calculated distances between candidate manifolds and use Bayesian optimization to search for the optimal latent geometry in a query-efficient manner. This method is general and can be applied to search for the optimal latent geometry for a variety of models and downstream tasks.Extensive experiments on synthetic and real-world datasets confirm the effectiveness of our method in identifying the optimal latent geometry for multiple machine learning problems. By automatically identifying the optimal latent geometry, our method can improve the performance of machine learning models and help to unlock their full potential.
</details></li>
</ul>
<hr>
<h2 id="Stochastic-Gradient-Descent-outperforms-Gradient-Descent-in-recovering-a-high-dimensional-signal-in-a-glassy-energy-landscape"><a href="#Stochastic-Gradient-Descent-outperforms-Gradient-Descent-in-recovering-a-high-dimensional-signal-in-a-glassy-energy-landscape" class="headerlink" title="Stochastic Gradient Descent outperforms Gradient Descent in recovering a high-dimensional signal in a glassy energy landscape"></a>Stochastic Gradient Descent outperforms Gradient Descent in recovering a high-dimensional signal in a glassy energy landscape</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04788">http://arxiv.org/abs/2309.04788</a></li>
<li>repo_url: None</li>
<li>paper_authors: Persia Jana Kamali, Pierfrancesco Urbani</li>
<li>for: 这个论文主要研究了泊松梯度下降（SGD）在训练人工神经网络时的效果，以及SGD在高维非对称优化问题中的表现。</li>
<li>methods: 这篇论文使用了动态均衡理论来分析SGD在高维限制下的性能。</li>
<li>results: 研究发现，使用SGD比使用梯度下降（GD）可以更好地优化高维非对称优化问题，特别是在小批量大小下。SGD的刺激时间下降的Power Law适应比GD更好。<details>
<summary>Abstract</summary>
Stochastic Gradient Descent (SGD) is an out-of-equilibrium algorithm used extensively to train artificial neural networks. However very little is known on to what extent SGD is crucial for to the success of this technology and, in particular, how much it is effective in optimizing high-dimensional non-convex cost functions as compared to other optimization algorithms such as Gradient Descent (GD). In this work we leverage dynamical mean field theory to analyze exactly its performances in the high-dimensional limit. We consider the problem of recovering a hidden high-dimensional non-linearly encrypted signal, a prototype high-dimensional non-convex hard optimization problem. We compare the performances of SGD to GD and we show that SGD largely outperforms GD. In particular, a power law fit of the relaxation time of these algorithms shows that the recovery threshold for SGD with small batch size is smaller than the corresponding one of GD.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="RRCNN-An-Enhanced-Residual-Recursive-Convolutional-Neural-Network-for-Non-stationary-Signal-Decomposition"><a href="#RRCNN-An-Enhanced-Residual-Recursive-Convolutional-Neural-Network-for-Non-stationary-Signal-Decomposition" class="headerlink" title="RRCNN$^{+}$: An Enhanced Residual Recursive Convolutional Neural Network for Non-stationary Signal Decomposition"></a>RRCNN$^{+}$: An Enhanced Residual Recursive Convolutional Neural Network for Non-stationary Signal Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04782">http://arxiv.org/abs/2309.04782</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhoudafa08/RRCNN_plus">https://github.com/zhoudafa08/RRCNN_plus</a></li>
<li>paper_authors: Feng Zhou, Antonio Cicone, Haomin Zhou</li>
<li>for: 这个论文主要针对非线性和非站点信号时频分析中的挑战。</li>
<li>methods: 该论文提出了一种基于实验模式分解法的新方法，并利用深度学习提供了一个独特的非站点信号分解视角。</li>
<li>results: 研究表明，该新方法可以在大规模信号批处理中实现更稳定的分解，同时具有低计算成本和高效率。<details>
<summary>Abstract</summary>
Time-frequency analysis is an important and challenging task in many applications. Fourier and wavelet analysis are two classic methods that have achieved remarkable success in many fields. They also exhibit limitations when applied to nonlinear and non-stationary signals. To address this challenge, a series of nonlinear and adaptive methods, pioneered by the empirical mode decomposition method have been proposed. Their aim is to decompose a non-stationary signal into quasi-stationary components which reveal better features in the time-frequency analysis. Recently, inspired by deep learning, we proposed a novel method called residual recursive convolutional neural network (RRCNN). Not only RRCNN can achieve more stable decomposition than existing methods while batch processing large-scale signals with low computational cost, but also deep learning provides a unique perspective for non-stationary signal decomposition. In this study, we aim to further improve RRCNN with the help of several nimble techniques from deep learning and optimization to ameliorate the method and overcome some of the limitations of this technique.
</details>
<details>
<summary>摘要</summary>
时频分析是许多应用中的重要和挑战性任务。法oux和涤纹分析是两种经典的方法，在许多领域取得了很大的成功。但它们在非线性和非站点信号处理中表现有限。为了解决这个挑战，一系列的非线性和适应方法，如empirical mode decomposition方法，在提出了解决非站点信号的分解。这些方法的目标是将非站点信号分解成更好地表征的 quasi-stationary 组件。在最近，我们受到深度学习的启发，提出了一种新的方法：差异循环神经网络（RRCNN）。RRCNN不仅可以在批处理大规模信号时实现更稳定的分解，同时也可以在低计算成本下提供更高的分解精度。此外，深度学习提供了非站点信号分解中独特的视角。在本研究中，我们想要通过深度学习和优化技术来提高RRCNN方法，并解决一些这种方法的限制。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Survey-on-Deep-Learning-Techniques-in-Educational-Data-Mining"><a href="#A-Comprehensive-Survey-on-Deep-Learning-Techniques-in-Educational-Data-Mining" class="headerlink" title="A Comprehensive Survey on Deep Learning Techniques in Educational Data Mining"></a>A Comprehensive Survey on Deep Learning Techniques in Educational Data Mining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04761">http://arxiv.org/abs/2309.04761</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanguo Lin, Hong Chen, Wei Xia, Fan Lin, Pengcheng Wu, Zongyue Wang, Yong Li</li>
<li>for: 这篇论文旨在系统地回顾现代教育中使用深度学习技术的教育数据挖掘（EDM）现状。</li>
<li>methods: 本论文使用深度学习技术分析和建模教育数据，包括知识追踪、不良学生检测、性能预测和个性化推荐等四个教育场景。</li>
<li>results: 本论文对现有的公共数据集和处理工具进行了全面的概述，并指出了未来这个领域的趋势和发展方向。<details>
<summary>Abstract</summary>
Educational Data Mining (EDM) has emerged as a vital field of research, which harnesses the power of computational techniques to analyze educational data. With the increasing complexity and diversity of educational data, Deep Learning techniques have shown significant advantages in addressing the challenges associated with analyzing and modeling this data. This survey aims to systematically review the state-of-the-art in EDM with Deep Learning. We begin by providing a brief introduction to EDM and Deep Learning, highlighting their relevance in the context of modern education. Next, we present a detailed review of Deep Learning techniques applied in four typical educational scenarios, including knowledge tracing, undesirable student detecting, performance prediction, and personalized recommendation. Furthermore, a comprehensive overview of public datasets and processing tools for EDM is provided. Finally, we point out emerging trends and future directions in this research area.
</details>
<details>
<summary>摘要</summary>
现代教育数据挖掘（EDM）已成为一个重要的研究领域，利用计算机技术来分析教育数据。随着教育数据的复杂度和多样性的增加，深度学习技术在处理和模型这些数据方面表现出了显著的优势。本文系统地回顾了现代教育数据挖掘领域中使用深度学习技术的状态。我们首先提供了 EDM 和深度学习的简介，强调它们在现代教育中的重要性。然后，我们提供了四种常见的教育场景，包括知识追踪、不良学生检测、性能预测和个性化推荐。此外，我们还提供了一个全面的公共数据集和处理工具的概述。最后，我们指出了这个研究领域的出现趋势和未来方向。Note: Please note that the translation is in Simplified Chinese, which is used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Gromov-Hausdorff-Distances-for-Comparing-Product-Manifolds-of-Model-Spaces"><a href="#Gromov-Hausdorff-Distances-for-Comparing-Product-Manifolds-of-Model-Spaces" class="headerlink" title="Gromov-Hausdorff Distances for Comparing Product Manifolds of Model Spaces"></a>Gromov-Hausdorff Distances for Comparing Product Manifolds of Model Spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05678">http://arxiv.org/abs/2309.05678</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haitz Saez de Ocariz Borde, Alvaro Arroyo, Ismael Morales, Ingmar Posner, Xiaowen Dong</li>
<li>for: 提高机器学习模型的性能，通过对积累空间的几何特征与数据结构的对应进行调整。</li>
<li>methods: 使用非欧几何空间（如偏 sfere 和 hyperbolic space）或其组合（知为产品 manifold）来提高模型性能，并使用图earch space来搜索最佳积累geometry。</li>
<li>results: 提出一种新的评估积累geometry的方法，基于度量几何学中的Gromov-Hausdorff距离，并实现了计算Gromov-Hausdorff距离的算法。<details>
<summary>Abstract</summary>
Recent studies propose enhancing machine learning models by aligning the geometric characteristics of the latent space with the underlying data structure. Instead of relying solely on Euclidean space, researchers have suggested using hyperbolic and spherical spaces with constant curvature, or their combinations (known as product manifolds), to improve model performance. However, there exists no principled technique to determine the best latent product manifold signature, which refers to the choice and dimensionality of manifold components. To address this, we introduce a novel notion of distance between candidate latent geometries using the Gromov-Hausdorff distance from metric geometry. We propose using a graph search space that uses the estimated Gromov-Hausdorff distances to search for the optimal latent geometry. In this work we focus on providing a description of an algorithm to compute the Gromov-Hausdorff distance between model spaces and its computational implementation.
</details>
<details>
<summary>摘要</summary>
近期研究建议通过对 latent space 的几何特征与数据结构进行对齐，以提高机器学习模型的性能。而不是仅仅采用欧几何空间，研究人员已经提议使用扁球空间和圆柱空间（或其组合）来改进模型性能。然而，没有一种原则性的技巧来确定最佳的 latent product manifold 签名，即选择和维度 manifold 组件的决策。为此，我们介绍了一种新的 latent geometry 距离度量，基于度量几何中的 Gromov-Hausdorff 距离。我们提议使用图搜索空间，使用估计的 Gromov-Hausdorff 距离来搜索最佳 latent geometry。在这篇文章中，我们主要关注 computing Gromov-Hausdorff distance 和其计算实现。
</details></li>
</ul>
<hr>
<h2 id="Affine-Invariant-Ensemble-Transform-Methods-to-Improve-Predictive-Uncertainty-in-ReLU-Networks"><a href="#Affine-Invariant-Ensemble-Transform-Methods-to-Improve-Predictive-Uncertainty-in-ReLU-Networks" class="headerlink" title="Affine Invariant Ensemble Transform Methods to Improve Predictive Uncertainty in ReLU Networks"></a>Affine Invariant Ensemble Transform Methods to Improve Predictive Uncertainty in ReLU Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04742">http://arxiv.org/abs/2309.04742</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diksha Bhandari, Jakiw Pidstrigach, Sebastian Reich</li>
<li>for: 用 ensemble Kalman filter 进行 Bayesian inference  для logistic regression</li>
<li>methods: 使用两种互动的 particle systems 采样 approximate posterior，并证明这些 particle systems 在数量趋于无穷时 Display quantitative convergence rates</li>
<li>results: 应用这些技术，对 ReLU 网络中 predictive uncertainty 进行评估，并证明其效果<details>
<summary>Abstract</summary>
We consider the problem of performing Bayesian inference for logistic regression using appropriate extensions of the ensemble Kalman filter. Two interacting particle systems are proposed that sample from an approximate posterior and prove quantitative convergence rates of these interacting particle systems to their mean-field limit as the number of particles tends to infinity. Furthermore, we apply these techniques and examine their effectiveness as methods of Bayesian approximation for quantifying predictive uncertainty in ReLU networks.
</details>
<details>
<summary>摘要</summary>
我们考虑使用 ensemble Kalman filter 的扩展来进行 bayesian 推理 для Logistic Regression。我们提出了两种互动的 particle system，它们可以从 approximate posterior 中采样，并证明这些互动 particle system 在数量的增加时对mean-field limit的量化准确率。此外，我们运用这些技术来评估它们在 ReLU 网络中Quantifying predictive uncertainty的效果。Here's the word-for-word translation of the text:我们考虑使用ensemble Kalman filter的扩展来进行 bayesian推理 дляLogistic Regression。我们提出了两种互动的particle system，它们可以从approximate posterior中采样，并证明这些互动particle system在数量的增加时对mean-field limit的量化准确率。此外，我们运用这些技术来评估它们在ReLU网络中Quantifying predictive uncertainty的效果。
</details></li>
</ul>
<hr>
<h2 id="Training-of-Spiking-Neural-Network-joint-Curriculum-Learning-Strategy"><a href="#Training-of-Spiking-Neural-Network-joint-Curriculum-Learning-Strategy" class="headerlink" title="Training of Spiking Neural Network joint Curriculum Learning Strategy"></a>Training of Spiking Neural Network joint Curriculum Learning Strategy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04737">http://arxiv.org/abs/2309.04737</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lingling Tang, Jielei Chu, Zhiguo Gong, Tianrui Li</li>
<li>For: The paper aims to enhance the biological plausibility of Spiking Neural Networks (SNNs) by introducing Curriculum Learning (CL) into SNNs.* Methods: The proposed CL-SNN model uses a confidence-aware loss to measure and process samples with different difficulty levels, allowing the model to learn more like humans and with higher biological interpretability.* Results: The authors conducted experiments on various datasets, including static image datasets MNIST, Fashion-MNIST, CIFAR10, and neuromorphic datasets N-MNIST, CIFAR10-DVS, DVS-Gesture, and the results are promising. To the best of the authors’ knowledge, this is the first proposal to enhance the biologically plausibility of SNNs by introducing CL.Here is the information in Simplified Chinese text:* For: 这篇论文目的是增强神经网络模型的生物可能性，通过引入学习环境中的学习策略，使神经网络模型更加类似于人类学习。* Methods: 提议的 CL-SNN 模型使用一种自信感掌握损失函数来评估不同难度水平的样本，从而使模型更加类似于人类学习。* Results: 作者在不同的数据集上进行了实验，包括静止图像集 MNIST、Fashion-MNIST、CIFAR10，以及 neuromorphic 数据集 N-MNIST、CIFAR10-DVS、DVS-Gesture，结果很有前途。据作者所知，这是首次通过引入 CL 增强 SNN 的生物可能性。<details>
<summary>Abstract</summary>
Starting with small and simple concepts, and gradually introducing complex and difficult concepts is the natural process of human learning. Spiking Neural Networks (SNNs) aim to mimic the way humans process information, but current SNNs models treat all samples equally, which does not align with the principles of human learning and overlooks the biological plausibility of SNNs. To address this, we propose a CL-SNN model that introduces Curriculum Learning(CL) into SNNs, making SNNs learn more like humans and providing higher biological interpretability. CL is a training strategy that advocates presenting easier data to models before gradually introducing more challenging data, mimicking the human learning process. We use a confidence-aware loss to measure and process the samples with different difficulty levels. By learning the confidence of different samples, the model reduces the contribution of difficult samples to parameter optimization automatically. We conducted experiments on static image datasets MNIST, Fashion-MNIST, CIFAR10, and neuromorphic datasets N-MNIST, CIFAR10-DVS, DVS-Gesture. The results are promising. To our best knowledge, this is the first proposal to enhance the biologically plausibility of SNNs by introducing CL.
</details>
<details>
<summary>摘要</summary>
人类学习的自然过程是从小而简单的概念开始，然后慢慢地引入复杂和困难的概念。神经网络模型（SNN）想要模仿人类信息处理的方式，但现有的SNN模型对所有样本进行同等的处理，这并不符合人类学习的原理，而且忽略了神经网络的生物学可能性。为解决这个问题，我们提出了CL-SNN模型，它将CURRICULUM学习（CL）引入SNN，使SNN更像人类学习的方式，并提供更高的生物学可解性。CL是一种培训策略，它提出将更容易的数据给模型之前，然后逐渐增加更加困难的数据，这与人类学习过程相似。我们使用了对样本的信任度进行评估和处理的confidence-aware损失函数。通过学习不同样本的信任度，模型会自动减少困难样本对参数优化的贡献。我们在静止图像集MNIST、Fashion-MNIST、CIFAR10、神经元逻辑集N-MNIST、CIFAR10-DVS、DVS-Gesture上进行了实验。结果很有前途。到我们知道的 extend，这是第一个通过引入CL提高神经网络的生物学可能性的提议。
</details></li>
</ul>
<hr>
<h2 id="MultiCaM-Vis-Visual-Exploration-of-Multi-Classification-Model-with-High-Number-of-Classes"><a href="#MultiCaM-Vis-Visual-Exploration-of-Multi-Classification-Model-with-High-Number-of-Classes" class="headerlink" title="MultiCaM-Vis: Visual Exploration of Multi-Classification Model with High Number of Classes"></a>MultiCaM-Vis: Visual Exploration of Multi-Classification Model with High Number of Classes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05676">http://arxiv.org/abs/2309.05676</a></li>
<li>repo_url: None</li>
<li>paper_authors: Syed Ahsan Ali Dilawer, Shah Rukh Humayoun</li>
<li>for: 本文旨在帮助机器学习专家在学习阶段出现错误的问题时，通过可见化分析，快速定位问题的根本原因。</li>
<li>methods: 本文提出了一种交互式可见化分析工具，名为MultiCaM-Vis，它提供了Overview+Detail样式的并行坐标图和一个Chord диаграм来探索和检查实例级别的错误分类。</li>
<li>results: 本文还提出了一项初步的用户研究，通过12名参与者的实验，发现这种可见化分析工具可以帮助机器学习专家快速定位问题的根本原因。<details>
<summary>Abstract</summary>
Visual exploration of multi-classification models with large number of classes would help machine learning experts in identifying the root cause of a problem that occurs during learning phase such as miss-classification of instances. Most of the previous visual analytics solutions targeted only a few classes. In this paper, we present our interactive visual analytics tool, called MultiCaM-Vis, that provides \Emph{overview+detail} style parallel coordinate views and a Chord diagram for exploration and inspection of class-level miss-classification of instances. We also present results of a preliminary user study with 12 participants.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传送给定文本到简化中文。</SYS>>通过视觉探索多类分类模型的许多类型的实例会帮助机器学习专家在学习阶段出现错误的问题的根本原因。大多数前一代的视觉分析解决方案仅针对其中的一些类型。在这篇论文中，我们提出了我们的交互式视觉分析工具 MultiCaM-Vis，它提供了概览+细节并行拐视图和一个弦表来探索和检查实例的类别错误分类。我们还发布了12名参与者的初步用户研究结果。
</details></li>
</ul>
<hr>
<h2 id="Weak-PDE-LEARN-A-Weak-Form-Based-Approach-to-Discovering-PDEs-From-Noisy-Limited-Data"><a href="#Weak-PDE-LEARN-A-Weak-Form-Based-Approach-to-Discovering-PDEs-From-Noisy-Limited-Data" class="headerlink" title="Weak-PDE-LEARN: A Weak Form Based Approach to Discovering PDEs From Noisy, Limited Data"></a>Weak-PDE-LEARN: A Weak Form Based Approach to Discovering PDEs From Noisy, Limited Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04699">http://arxiv.org/abs/2309.04699</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/punkduckable/weak_pde_learn">https://github.com/punkduckable/weak_pde_learn</a></li>
<li>paper_authors: Robert Stephany, Christopher Earls</li>
<li>for: 用于从噪音有限的解析数据中直接推断非线性偏微分方程（PDE）。</li>
<li>methods: 使用适应损失函数基于弱形式来训练神经网络，approximate PDE解而同时标识主要PDE。</li>
<li>results: 可以快速精准地推断多种偏微分方程，并且具有较高的噪音抗性和可靠性。<details>
<summary>Abstract</summary>
We introduce Weak-PDE-LEARN, a Partial Differential Equation (PDE) discovery algorithm that can identify non-linear PDEs from noisy, limited measurements of their solutions. Weak-PDE-LEARN uses an adaptive loss function based on weak forms to train a neural network, $U$, to approximate the PDE solution while simultaneously identifying the governing PDE. This approach yields an algorithm that is robust to noise and can discover a range of PDEs directly from noisy, limited measurements of their solutions. We demonstrate the efficacy of Weak-PDE-LEARN by learning several benchmark PDEs.
</details>
<details>
<summary>摘要</summary>
我们介绍Weak-PDE-LEARN，一种partial differential equation（PDE）发现算法，可以从噪音、有限测量的解方面获取非线性PDE。Weak-PDE-LEARN使用适应损失函数基于弱形式来训练神经网络U，以估计PDE解释，同时也可以获取统治PDE。这种方法可以对噪音有效，并且可以直接从噪音有限测量的解方面获取PDE。我们透过训练几个benchmark PDE来证明其效果。
</details></li>
</ul>
<hr>
<h2 id="Redundancy-Free-Self-Supervised-Relational-Learning-for-Graph-Clustering"><a href="#Redundancy-Free-Self-Supervised-Relational-Learning-for-Graph-Clustering" class="headerlink" title="Redundancy-Free Self-Supervised Relational Learning for Graph Clustering"></a>Redundancy-Free Self-Supervised Relational Learning for Graph Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04694">http://arxiv.org/abs/2309.04694</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yisiyu95/r2fgc">https://github.com/yisiyu95/r2fgc</a></li>
<li>paper_authors: Si-Yu Yi, Wei Ju, Yifang Qin, Xiao Luo, Luchen Liu, Yong-Dao Zhou, Ming Zhang</li>
<li>for: 这篇论文的目的是提出一种基于自动编码器和图自动编码器的自然语言 clustering 方法，以优化图 струкured 数据中的 semantic 信息的抽象和利用。</li>
<li>methods: 该方法使用了一种名为 Relational Redundancy-Free Graph Clustering (R$^2$FGC)，它从全球和本地视图中提取了属性和结构层次的关系信息，并通过保持归一化后的节点归一化来提取归一化后的semantic信息。此外，该方法还采用了一种简单 yet 有效的策略来解决过滤问题。</li>
<li>results: 对于 widely 使用的 benchmark 数据集，R$^2$FGC 在比较基准方法的情况下显示出了优越性，并且可以更好地利用图 structured 数据中的semantic信息。<details>
<summary>Abstract</summary>
Graph clustering, which learns the node representations for effective cluster assignments, is a fundamental yet challenging task in data analysis and has received considerable attention accompanied by graph neural networks in recent years. However, most existing methods overlook the inherent relational information among the non-independent and non-identically distributed nodes in a graph. Due to the lack of exploration of relational attributes, the semantic information of the graph-structured data fails to be fully exploited which leads to poor clustering performance. In this paper, we propose a novel self-supervised deep graph clustering method named Relational Redundancy-Free Graph Clustering (R$^2$FGC) to tackle the problem. It extracts the attribute- and structure-level relational information from both global and local views based on an autoencoder and a graph autoencoder. To obtain effective representations of the semantic information, we preserve the consistent relation among augmented nodes, whereas the redundant relation is further reduced for learning discriminative embeddings. In addition, a simple yet valid strategy is utilized to alleviate the over-smoothing issue. Extensive experiments are performed on widely used benchmark datasets to validate the superiority of our R$^2$FGC over state-of-the-art baselines. Our codes are available at https://github.com/yisiyu95/R2FGC.
</details>
<details>
<summary>摘要</summary>
GRAPH CLUSTERING，即通过学习节点表示来实现有效的分群任务，是数据分析领域的基础 yet challenging task，在最近的几年中，随着图神经网络的发展，得到了广泛的关注。然而，大多数现有的方法忽略了图中 nodes 之间的自然关系信息，因此 не能充分利用图 structured data 中的semantic信息，这导致了分群性能的下降。在这篇论文中，我们提出了一种新的自动supervised deep graph clustering方法，名为 Relational Redundancy-Free Graph Clustering (R$^2$FGC)，以解决这个问题。R$^2$FGC 方法通过自动编码器和图自动编码器来提取图中 attribute-和 structure-level 的关系信息，并在 global 和 local 视图下对这些信息进行拓展。为了获得有效的semantic信息表示，我们保留了归一化后的节点之间的一致关系，而 redundant 关系则进一步减少以学习特异性的嵌入。此外，我们采用了一种简单 yet valid 的策略来解决过拟合问题。我们在 widely used 的 benchmark 数据集上进行了广泛的实验，以验证 R$^2$FGC 的超越性。codes 可以在 https://github.com/yisiyu95/R2FGC 上获取。
</details></li>
</ul>
<hr>
<h2 id="Compact-Approximating-Complex-Activation-Functions-for-Secure-Computation"><a href="#Compact-Approximating-Complex-Activation-Functions-for-Secure-Computation" class="headerlink" title="Compact: Approximating Complex Activation Functions for Secure Computation"></a>Compact: Approximating Complex Activation Functions for Secure Computation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04664">http://arxiv.org/abs/2309.04664</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mazharul Islam, Sunpreet S. Arora, Rahul Chatterjee, Peter Rindal, Maliheh Shirvanian</li>
<li>for: 提供隐私保护的深度神经网络（DNN）模型查询服务，使用公共云计算。</li>
<li>methods: 使用现状顶尖的多方 computation（MPC）技术，并使用Compact生成 piece-wise polynomialapproximation来提高MPC技术的效率。</li>
<li>results: Compact不需要任何限制model训练，并且对四种不同的机器学习任务进行了广泛的实验评估，结果表明Compact与DNN特有的方法相比，对于处理复杂非线性 activation functions（AFs）而言，具有 negligible accuracy loss，同时提供了2-5倍的计算速度提升。<details>
<summary>Abstract</summary>
Secure multi-party computation (MPC) techniques can be used to provide data privacy when users query deep neural network (DNN) models hosted on a public cloud. State-of-the-art MPC techniques can be directly leveraged for DNN models that use simple activation functions (AFs) such as ReLU. However, DNN model architectures designed for cutting-edge applications often use complex and highly non-linear AFs. Designing efficient MPC techniques for such complex AFs is an open problem.   Towards this, we propose Compact, which produces piece-wise polynomial approximations of complex AFs to enable their efficient use with state-of-the-art MPC techniques. Compact neither requires nor imposes any restriction on model training and results in near-identical model accuracy. We extensively evaluate Compact on four different machine-learning tasks with DNN architectures that use popular complex AFs SiLU, GeLU, and Mish. Our experimental results show that Compact incurs negligible accuracy loss compared to DNN-specific approaches for handling complex non-linear AFs. We also incorporate Compact in two state-of-the-art MPC libraries for privacy-preserving inference and demonstrate that Compact provides 2x-5x speedup in computation compared to the state-of-the-art approximation approach for non-linear functions -- while providing similar or better accuracy for DNN models with large number of hidden layers
</details>
<details>
<summary>摘要</summary>
使用安全多方计算（MPC）技术可以保证用户在公共云上查询深度神经网络（DNN）模型时的数据隐私。现状的MPC技术可以直接应用于使用简单 activation function（AF）的 DNN 模型，如 ReLU。然而，设计用于进行先进应用的 DNN 模型 architecture 通常使用复杂和高度非线性的 AF。为此，我们提出了 Compact，它生成了 piece-wise 多项式近似的复杂 AF，以便使用现状的MPC技术进行高效的使用。Compact 不需要或强制任何模型训练限制，并且会导致模型准确性几乎不变。我们在四种不同的机器学习任务上进行了广泛的实验，并证明了 Compact 与 DNN 特有的方法相比，对于处理复杂非线性 AF 的模型而言，减少了精度损失。此外，我们将 Compact 集成到了两个现状的MPC库中，并证明了 Compact 在计算速度方面比现状的近似方法提供了2-5倍的提升，而同时保持了模型中多个隐藏层的准确性。
</details></li>
</ul>
<hr>
<h2 id="Intelligent-upper-limb-exoskeleton-using-deep-learning-to-predict-human-intention-for-sensory-feedback-augmentation"><a href="#Intelligent-upper-limb-exoskeleton-using-deep-learning-to-predict-human-intention-for-sensory-feedback-augmentation" class="headerlink" title="Intelligent upper-limb exoskeleton using deep learning to predict human intention for sensory-feedback augmentation"></a>Intelligent upper-limb exoskeleton using deep learning to predict human intention for sensory-feedback augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04655">http://arxiv.org/abs/2309.04655</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinwoo Lee, Kangkyu Kwon, Ira Soltis, Jared Matthews, Yoonjae Lee, Hojoong Kim, Lissette Romero, Nathan Zavanelli, Youngjin Kwon, Shinjae Kwon, Jimin Lee, Yewon Na, Sung Hoon Lee, Ki Jun Yu, Minoru Shinohara, Frank L. Hammond, Woon-Hong Yeo</li>
<li>for: 这个研究旨在开发一种基于云计算和感知反馈的智能 upper-limb exoskeleton系统，以增强人类的手部运动能力。</li>
<li>methods: 该系统使用云计算的深度学习算法预测人类的意图动作，并通过软件感知器收集实时肌肉信号来提供感知反馈。</li>
<li>results: 研究表明，该系统可以在200-250毫秒响应时间内预测四个 upper-limb 关节运动，准确率达96.2%，并可以提供5.15倍的人类力量增强。<details>
<summary>Abstract</summary>
The age and stroke-associated decline in musculoskeletal strength degrades the ability to perform daily human tasks using the upper extremities. Although there are a few examples of exoskeletons, they need manual operations due to the absence of sensor feedback and no intention prediction of movements. Here, we introduce an intelligent upper-limb exoskeleton system that uses cloud-based deep learning to predict human intention for strength augmentation. The embedded soft wearable sensors provide sensory feedback by collecting real-time muscle signals, which are simultaneously computed to determine the user's intended movement. The cloud-based deep-learning predicts four upper-limb joint motions with an average accuracy of 96.2% at a 200-250 millisecond response rate, suggesting that the exoskeleton operates just by human intention. In addition, an array of soft pneumatics assists the intended movements by providing 897 newton of force and 78.7 millimeter of displacement at maximum. Collectively, the intent-driven exoskeleton can augment human strength by 5.15 times on average compared to the unassisted exoskeleton. This report demonstrates an exoskeleton robot that augments the upper-limb joint movements by human intention based on a machine-learning cloud computing and sensory feedback.
</details>
<details>
<summary>摘要</summary>
人们日常活动中使用上肢部时，年龄和roke-相关的肌肉强度下降会导致功能下降。虽然有一些外套式机器人，但它们需要人工操作，因为缺乏感知反馈和移动意图预测。在这里，我们介绍了一个智能上肢部外套系统，使用云计算深度学习预测人类意图，以增强肌肉强度。系统内置软件式感知器收集实时肌肉信号，并同时计算用户的意图移动。云计算深度学习预测四个上肢部 JOINT 运动，平均准确率为96.2%，响应时间为200-250毫秒，这表明机器人只遵循人类意图。此外，一个数组软空气填充器助力用户意图的运动，提供897牛顿的力和78.7毫米的移动距离最大。总的来说，意图驱动的机器人可以增强人类上肢部 JOINT 运动的强度，平均提高5.15倍 compared to 无助担机器人。这份报告描述了一种基于机器学习云计算和感知反馈的肌肉强度增强机器人。
</details></li>
</ul>
<hr>
<h2 id="Towards-Understanding-Neural-Collapse-The-Effects-of-Batch-Normalization-and-Weight-Decay"><a href="#Towards-Understanding-Neural-Collapse-The-Effects-of-Batch-Normalization-and-Weight-Decay" class="headerlink" title="Towards Understanding Neural Collapse: The Effects of Batch Normalization and Weight Decay"></a>Towards Understanding Neural Collapse: The Effects of Batch Normalization and Weight Decay</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04644">http://arxiv.org/abs/2309.04644</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leyan Pan, Xinyuan Cao</li>
<li>For: 这个论文研究了在神经网络分类器的最后一层使用批Normalization和权重衰退后，是否会出现神经崩溃现象。* Methods: 该论文提出了一种基于几何学的内部类和间类cosine相似度度量，可以捕捉到神经崩溃现象的多个核心方面。同时，该论文还提供了对于最佳化混合Entropy损失函数时，神经崩溃的理论保证。* Results: 实验结果表明，在神经网络模型中添加批Normalization和高权重衰退值时，神经崩溃现象更加明显，而且与批Normalization和权重衰退值之间存在正相关性。<details>
<summary>Abstract</summary>
Neural Collapse is a recently observed geometric structure that emerges in the final layer of neural network classifiers. Specifically, Neural Collapse states that at the terminal phase of neural networks training, 1) the intra-class variability of last-layer features tends to zero, 2) the class feature means form an Equiangular Tight Frame (ETF), 3) last-layer class features and weights becomes equal up the scaling, and 4) classification behavior collapses to the nearest class center (NCC) decision rule. This paper investigates the effect of batch normalization and weight decay on the emergence of Neural Collapse. We propose the geometrically intuitive intra-class and inter-class cosine similarity measure which captures multiple core aspects of Neural Collapse. With this measure, we provide theoretical guarantees of Neural Collapse emergence with last-layer batch normalization and weight decay when the regularized cross-entropy loss is near optimal. We also perform further experiments to show that the Neural Collapse is most significant in models with batch normalization and high weight-decay values. Collectively, our results imply that batch normalization and weight decay may be fundamental factors in the emergence of Neural Collapse.
</details>
<details>
<summary>摘要</summary>
neural collapse 是一种最近发现的几何结构，它在神经网络分类器的最后一层出现。具体来说，神经collapse 表示在神经网络训练的末期，1）最后一层特征变量内部减少到零，2）类特征均值形成等角紧凑框（ETF），3）最后一层类特征和权重归一化，4）分类行为归一化到最近的类中心（NCC）决策规则。本文研究了批Normalization和权重衰减对神经collapse 的影响。我们提出了几何直观的内类和间类夹角相似度度量，该度量捕捉了多个核心方面的神经collapse。通过这个度量，我们提供了理论保证神经collapse 的出现，当批Normalization和权重衰减值很大时。我们还进行了更多的实验，证明神经collapse 在模型中具有批Normalization和高权重衰减值时最为明显。总的来说，我们的结果表明，批Normalization和权重衰减可能是神经collapse 的基本因素。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/09/cs.LG_2023_09_09/" data-id="clogxf3of00nx5xra6bp2fxb6" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_09_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/09/eess.IV_2023_09_09/" class="article-date">
  <time datetime="2023-09-09T09:00:00.000Z" itemprop="datePublished">2023-09-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/09/eess.IV_2023_09_09/">eess.IV - 2023-09-09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Latent-Degradation-Representation-Constraint-for-Single-Image-Deraining"><a href="#Latent-Degradation-Representation-Constraint-for-Single-Image-Deraining" class="headerlink" title="Latent Degradation Representation Constraint for Single Image Deraining"></a>Latent Degradation Representation Constraint for Single Image Deraining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04780">http://arxiv.org/abs/2309.04780</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhong He, Long Peng, Lu Wang, Jun Cheng</li>
<li>for: 提高单图雨植物除法的精度和效果，解决现有方法存在过度或未适应现象。</li>
<li>methods: 提出了一种基于irection-aware编码器、UNet排除网络和多尺度交互块的Latent Degradation Representation Constraint Network（LDRCNet），通过带有方向一致性的扩展几何梯度来适应各种雨植物模式，并在训练时引入约束损失来显式地学习雨植物表示。</li>
<li>results: 在 sintetic 和实际数据集上实验表明，提出的方法可以达到新的状态级性能。<details>
<summary>Abstract</summary>
Since rain streaks show a variety of shapes and directions, learning the degradation representation is extremely challenging for single image deraining. Existing methods are mainly targeted at designing complicated modules to implicitly learn latent degradation representation from coupled rainy images. This way, it is hard to decouple the content-independent degradation representation due to the lack of explicit constraint, resulting in over- or under-enhancement problems. To tackle this issue, we propose a novel Latent Degradation Representation Constraint Network (LDRCNet) that consists of Direction-Aware Encoder (DAEncoder), UNet Deraining Network, and Multi-Scale Interaction Block (MSIBlock). Specifically, the DAEncoder is proposed to adaptively extract latent degradation representation by using the deformable convolutions to exploit the direction consistency of rain streaks. Next, a constraint loss is introduced to explicitly constraint the degradation representation learning during training. Last, we propose an MSIBlock to fuse with the learned degradation representation and decoder features of the deraining network for adaptive information interaction, which enables the deraining network to remove various complicated rainy patterns and reconstruct image details. Experimental results on synthetic and real datasets demonstrate that our method achieves new state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
因为雨托 Streaks 显示出多种形状和方向，学习降解表示是单图像抖掉极其困难的。现有方法主要targeted at设计复杂的模块，以异步学习潜在的降解表示从相关的雨照图像中。这种方法难以分离内容独立的降解表示，导致过度或不足进行增强问题。为了解决这个问题，我们提出了一种新的降解表示约束网络（LDRCNet），包括方向感知编码器（DAEncoder）、UNet抖掉网络和多Scale交互块（MSIBlock）。具体来说，DAEncoder是用具有可变扩散的卷积来适应ively抽取降解表示，并且通过利用雨托的方向一致性来提取有用的降解表示。然后，我们引入了一个约束损失来在训练中直接约束降解表示学习。最后，我们提出了一个MSIBlock来与学习的降解表示和抖掉网络的解码器特征进行相互交互，使得抖掉网络能够去除各种复杂的雨托模式，并重建图像细节。实验结果表明，我们的方法在 sintetic 和实际 datasets 上达到了新的状态级表现。
</details></li>
</ul>
<hr>
<h2 id="SSHNN-Semi-Supervised-Hybrid-NAS-Network-for-Echocardiographic-Image-Segmentation"><a href="#SSHNN-Semi-Supervised-Hybrid-NAS-Network-for-Echocardiographic-Image-Segmentation" class="headerlink" title="SSHNN: Semi-Supervised Hybrid NAS Network for Echocardiographic Image Segmentation"></a>SSHNN: Semi-Supervised Hybrid NAS Network for Echocardiographic Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04672">http://arxiv.org/abs/2309.04672</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renqi Chen, Jingjing Luo, Fan Nian, Yuhui Cen, Yiheng Peng, Zekuan Yu</li>
<li>for: 这个研究旨在提高医疗影像分类的精度，特别是用于echocardiographic影像，减少不必要的噪声。</li>
<li>methods: 这个研究使用Neural Architecture Search（NAS）来设计网络，并将层别特征聚合和对应的Transformers引入，以提高分类的精度和效率。</li>
<li>results: 实验结果显示，这个 SSHNN 网络可以优于现有的方法，实现更高的分类精度和效率。<details>
<summary>Abstract</summary>
Accurate medical image segmentation especially for echocardiographic images with unmissable noise requires elaborate network design. Compared with manual design, Neural Architecture Search (NAS) realizes better segmentation results due to larger search space and automatic optimization, but most of the existing methods are weak in layer-wise feature aggregation and adopt a ``strong encoder, weak decoder" structure, insufficient to handle global relationships and local details. To resolve these issues, we propose a novel semi-supervised hybrid NAS network for accurate medical image segmentation termed SSHNN. In SSHNN, we creatively use convolution operation in layer-wise feature fusion instead of normalized scalars to avoid losing details, making NAS a stronger encoder. Moreover, Transformers are introduced for the compensation of global context and U-shaped decoder is designed to efficiently connect global context with local features. Specifically, we implement a semi-supervised algorithm Mean-Teacher to overcome the limited volume problem of labeled medical image dataset. Extensive experiments on CAMUS echocardiography dataset demonstrate that SSHNN outperforms state-of-the-art approaches and realizes accurate segmentation. Code will be made publicly available.
</details>
<details>
<summary>摘要</summary>
准确的医学影像分割特别是用于echocardiographic图像的分割需要精心设计网络。与手动设计相比，使用神经网络搜索（NAS）可以实现更好的分割结果，因为它可以在更大的搜索空间中进行自动优化，但是现有的方法往往弱于层次特征聚合和采用了“强Encoder,弱Decoder”结构，无法处理全局关系和本地细节。为解决这些问题，我们提出了一种新的半supervised混合NAS网络，称为SSHNN。在SSHNN中，我们创新地使用卷积操作来实现层次特征融合，而不是使用正常化的整数，以避免丢失细节。此外，我们还引入了Transformers来补做全局上下文，并设计了U字形解码器来有效地连接全局上下文和本地特征。具体来说，我们实现了一种半supervised算法 Mean-Teacher，以解决有限量的医学影像数据集的问题。我们的实验表明，SSHNN在CAMUS echocardiography数据集上表现出了State-of-the-art的分割结果，并实现了准确的分割。我们将代码公开。
</details></li>
</ul>
<hr>
<h2 id="ConvFormer-Plug-and-Play-CNN-Style-Transformers-for-Improving-Medical-Image-Segmentation"><a href="#ConvFormer-Plug-and-Play-CNN-Style-Transformers-for-Improving-Medical-Image-Segmentation" class="headerlink" title="ConvFormer: Plug-and-Play CNN-Style Transformers for Improving Medical Image Segmentation"></a>ConvFormer: Plug-and-Play CNN-Style Transformers for Improving Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05674">http://arxiv.org/abs/2309.05674</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xian Lin, Zengqiang Yan, Xianbo Deng, Chuansheng Zheng, Li Yu</li>
<li>for: 提高 трансформа器在医学图像分割中的表现，特别是解决注意力归一化问题。</li>
<li>methods: 建立CNN风格的transformer（ConvFormer），通过pooling、CNN风格自注意（CSA）和卷积FeedForward Network（CFFN）来提高注意力归一化和feature refinement。</li>
<li>results: 在多个 dataset 上实验表明，ConvFormer 可以作为替换 transformer 框架中的插件模块，提高表现。<details>
<summary>Abstract</summary>
Transformers have been extensively studied in medical image segmentation to build pairwise long-range dependence. Yet, relatively limited well-annotated medical image data makes transformers struggle to extract diverse global features, resulting in attention collapse where attention maps become similar or even identical. Comparatively, convolutional neural networks (CNNs) have better convergence properties on small-scale training data but suffer from limited receptive fields. Existing works are dedicated to exploring the combinations of CNN and transformers while ignoring attention collapse, leaving the potential of transformers under-explored. In this paper, we propose to build CNN-style Transformers (ConvFormer) to promote better attention convergence and thus better segmentation performance. Specifically, ConvFormer consists of pooling, CNN-style self-attention (CSA), and convolutional feed-forward network (CFFN) corresponding to tokenization, self-attention, and feed-forward network in vanilla vision transformers. In contrast to positional embedding and tokenization, ConvFormer adopts 2D convolution and max-pooling for both position information preservation and feature size reduction. In this way, CSA takes 2D feature maps as inputs and establishes long-range dependency by constructing self-attention matrices as convolution kernels with adaptive sizes. Following CSA, 2D convolution is utilized for feature refinement through CFFN. Experimental results on multiple datasets demonstrate the effectiveness of ConvFormer working as a plug-and-play module for consistent performance improvement of transformer-based frameworks. Code is available at https://github.com/xianlin7/ConvFormer.
</details>
<details>
<summary>摘要</summary>
transformers 在医学影像 segmentation 领域得到了广泛的研究，以建立对应的长距离依赖关系。然而，有限的高质量医学影像数据使 transformers 在提取多样的全球特征方面困难，导致注意力坍塌，注意力映射变得相似或 même identical。相比之下，卷积神经网络（CNN）在小规模训练数据上有更好的收敛性能，但受限于宽度的接受范围。现有的工作主要是探索 CCN 和 transformers 的组合，忽略了注意力坍塌问题，因此 transformers 的潜在能力还未得到充分的探索。本文提出了一种具有 CNN 特征的 transformers（ConvFormer），以便提高注意力均匀性和 segmentation 性能。具体来说，ConvFormer 由池化、CNN 式自注意（CSA）和卷积 feed-forward 网络（CFFN）组成，与 vanilla vision transformers 中的封装、自注意和 feed-forward 网络相对应。与 pozitional embedding 和封装不同，ConvFormer 采用了2D卷积和最大池化来保持位置信息和特征大小减少。这样，CSA 可以将 2D 特征图作为输入，建立长距离依赖关系，并通过构建自注意矩阵来实现自注意。接下来，2D 卷积被用来进行特征细化，通过 CFFN 进行特征细化。实验结果表明，ConvFormer 作为 transformer 基础架构上的插件模块，可以为 transformer 基础架构提供可靠的性能提升。代码可以在 <https://github.com/xianlin7/ConvFormer> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Video-and-Synthetic-MRI-Pre-training-of-3D-Vision-Architectures-for-Neuroimage-Analysis"><a href="#Video-and-Synthetic-MRI-Pre-training-of-3D-Vision-Architectures-for-Neuroimage-Analysis" class="headerlink" title="Video and Synthetic MRI Pre-training of 3D Vision Architectures for Neuroimage Analysis"></a>Video and Synthetic MRI Pre-training of 3D Vision Architectures for Neuroimage Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04651">http://arxiv.org/abs/2309.04651</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikhil J. Dhinagar, Amit Singh, Saket Ozarkar, Ketaki Buwa, Sophia I. Thomopoulos, Conor Owens-Walton, Emily Laltoo, Yao-Liang Chen, Philip Cook, Corey McMillan, Chih-Chien Tsai, J-J Wang, Yih-Ru Wu, Paul M. Thompson<br>for:* 3D medical imaging tasks, particularly Alzheimer’s disease (AD) and Parkinson’s disease (PD) classification, and “brain age” prediction.methods:* Pre-training deep learning models on a large corpus of data, including natural images, medical images, and synthetically generated MRI scans or video data.* Adapting pre-trained models to downstream neuroimaging tasks with a range of difficulty.results:* Pre-training improved performance across all tasks, with a boost of 7.4% for AD classification and 4.6% for PD classification for ViTs, and 19.1% for PD classification and reduction in brain age prediction error by 1.26 years for CNNs.* Pre-training on large-scale video or synthetic MRI data boosted performance of ViTs.* CNNs were robust in limited-data settings, and in-domain pretraining enhanced their performances.* Pre-training improved generalization to out-of-distribution datasets and sites.<details>
<summary>Abstract</summary>
Transfer learning represents a recent paradigm shift in the way we build artificial intelligence (AI) systems. In contrast to training task-specific models, transfer learning involves pre-training deep learning models on a large corpus of data and minimally fine-tuning them for adaptation to specific tasks. Even so, for 3D medical imaging tasks, we do not know if it is best to pre-train models on natural images, medical images, or even synthetically generated MRI scans or video data. To evaluate these alternatives, here we benchmarked vision transformers (ViTs) and convolutional neural networks (CNNs), initialized with varied upstream pre-training approaches. These methods were then adapted to three unique downstream neuroimaging tasks with a range of difficulty: Alzheimer's disease (AD) and Parkinson's disease (PD) classification, "brain age" prediction. Experimental tests led to the following key observations: 1. Pre-training improved performance across all tasks including a boost of 7.4% for AD classification and 4.6% for PD classification for the ViT and 19.1% for PD classification and reduction in brain age prediction error by 1.26 years for CNNs, 2. Pre-training on large-scale video or synthetic MRI data boosted performance of ViTs, 3. CNNs were robust in limited-data settings, and in-domain pretraining enhanced their performances, 4. Pre-training improved generalization to out-of-distribution datasets and sites. Overall, we benchmarked different vision architectures, revealing the value of pre-training them with emerging datasets for model initialization. The resulting pre-trained models can be adapted to a range of downstream neuroimaging tasks, even when training data for the target task is limited.
</details>
<details>
<summary>摘要</summary>
Transfer learning 表示现代人工智能系统的一种新的思路。而不是专门为每个任务训练特定的模型， transfer learning 是在大量数据上预训练深度学习模型，并在最小化 fine-tuning 后应用于特定任务。然而，对于3D医学影像任务，我们不知道是否应该预训练模型于自然图像、医学影像或者 sintetically生成的 MRI 扫描或视频数据。为了评估这些选项，我们在这里对 vision transformers（ViTs）和卷积神经网络（CNNs）进行了比较。这些方法在三个独特的下游神经成像任务中进行了适应：阿尔茨heimer 病（AD）和 пар金森病（PD）分类、"brain age" 预测。实验证明了以下关键观察：1. 预训练可以提高所有任务的性能，包括boost 7.4% 的 AD 分类和4.6% 的 PD 分类 для ViT，以及19.1% 的 PD 分类和 reductions 的 brain age 预测错误率为 1.26 年 для CNNs。2. 预训练于大规模的视频或生成的 MRI 数据可以提高 ViTs 的性能。3. CNNs 在有限数据设置下表现稳定，并且在域内预训练下进一步提高了其性能。4. 预训练可以提高模型对outsidel distribution 数据集和站点的一致性。总的来说，我们对不同的视觉架构进行了比较，发现预训练它们以 emerging 数据集为初始化的值。这些预训练后的模型可以适应具有有限数据的下游神经成像任务，并且在训练数据中不同的站点上也能够达到良好的性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/09/eess.IV_2023_09_09/" data-id="clogxf3sn01455xra6bcqcsp0" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_09_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/09/eess.SP_2023_09_09/" class="article-date">
  <time datetime="2023-09-09T08:00:00.000Z" itemprop="datePublished">2023-09-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/09/eess.SP_2023_09_09/">eess.SP - 2023-09-09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="After-Fatigue-Condition-A-Novel-Analysis-Based-on-Surface-EMG-Signals"><a href="#After-Fatigue-Condition-A-Novel-Analysis-Based-on-Surface-EMG-Signals" class="headerlink" title="After-Fatigue Condition: A Novel Analysis Based on Surface EMG Signals"></a>After-Fatigue Condition: A Novel Analysis Based on Surface EMG Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04770">http://arxiv.org/abs/2309.04770</a></li>
<li>repo_url: None</li>
<li>paper_authors: Van Hieu Nguyen, Gia Thien Luu, Thien Van Luong, Mai Xuan Trang, Philippe Ravier, Olivier Buttelli</li>
<li>for: 本研究旨在evaluating muscle after-fatigue condition based on surface electromyography (sEMG) signals, which has been overlooked in previous studies.</li>
<li>methods: 该方法使用了amplitude-based, spectral-based, 和muscle fiber conduction velocity (CV) parameters to analyze muscle fatigue indicators at various maximal voluntary contraction (MVC) levels, 以及每个MVC水平的contractions time.</li>
<li>results: 研究结果显示在after-fatigue condition下, muscle activation undergoes significant changes, including higher CV, power spectral density shifting to the right, and longer contraction time until exhaustion compared to before-fatigue and fatigue conditions.<details>
<summary>Abstract</summary>
This study introduces a novel muscle activation analysis based on surface electromyography (sEMG) signals to assess the muscle's after-fatigue condition. Previous studies have mainly focused on the before-fatigue and fatigue conditions. However, a comprehensive analysis of the after-fatigue condition has been overlooked. The proposed method analyzes muscle fatigue indicators at various maximal voluntary contraction (MVC) levels to compare the before-fatigue, fatigue, and after-fatigue conditions using amplitude-based, spectral-based, and muscle fiber conduction velocity (CV) parameters. In addition, the contraction time of each MVC level is also analyzed with the same indicators. The results show that in the after-fatigue condition, the muscle activation changes significantly in the ways such as higher CV, power spectral density shifting to the right, and longer contraction time until exhaustion compared to the before-fatigue and fatigue conditions. The results can provide a comprehensive and objective evaluation of muscle fatigue and recovery, which can be helpful in clinical diagnosis, rehabilitation, and sports performance.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "surface electromyography" (sEMG) is translated as "表面电 MYography" (bǎo miàn diàn MYography)* "maximal voluntary contraction" (MVC) is translated as "最大自愿收缩" (zuì dà zì yù shōu)* "muscle fiber conduction velocity" (CV) is translated as "肌细胞传导速度" (jiāo xì bāng chuán dào)* "power spectral density" is translated as "能量 спектраль密度" (néngyè spèktrum míngdé)* "contractions time" is translated as "收缩时间" (shōu shū shíjiān)
</details></li>
</ul>
<hr>
<h2 id="Transformer-Based-Deep-Learning-Detector-for-Dual-Mode-Index-Modulation-3D-OFDM"><a href="#Transformer-Based-Deep-Learning-Detector-for-Dual-Mode-Index-Modulation-3D-OFDM" class="headerlink" title="Transformer-Based Deep Learning Detector for Dual-Mode Index Modulation 3D-OFDM"></a>Transformer-Based Deep Learning Detector for Dual-Mode Index Modulation 3D-OFDM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04764">http://arxiv.org/abs/2309.04764</a></li>
<li>repo_url: None</li>
<li>paper_authors: Toan Gian, Tien-Hoa Nguyen, Trung Tan Nguyen, Van-Cuong Pham, Thien Van Luong</li>
<li>for: 这个论文旨在提出一个基于深度学习的信号探测器，即TransD3D-IM，用于三维多调变调分多重频率分裂(3D-OFDM)系统中的信号探测。</li>
<li>methods: 这个方法使用Transformer框架进行信号探测，并且使用双模式3D标志和活动子频率指标来传输数据位元。</li>
<li>results: 实验结果显示，TransD3D-IM可以对DM-IM-3D-OFDM系统中的信号探测进行优化，并且比现有的IM基于模型的探测器更高的传输可靠性。此外，TransD3D-IM也可以大幅提高传输速率，并且具有更好的响应性。<details>
<summary>Abstract</summary>
In this paper, we propose a deep learning-based signal detector called TransD3D-IM, which employs the Transformer framework for signal detection in the Dual-mode index modulation-aided three-dimensional (3D) orthogonal frequency division multiplexing (DM-IM-3D-OFDM) system. In this system, the data bits are conveyed using dual-mode 3D constellation symbols and active subcarrier indices. As a result, this method exhibits significantly higher transmission reliability than current IM-based models with traditional maximum likelihood (ML) detection. Nevertheless, the ML detector suffers from high computational complexity, particularly when the parameters of the system are large. Even the complexity of the Log-Likelihood Ratio algorithm, known as a low-complexity detector for signal detection in the DM-IM-3D-OFDM system, is also not impressive enough. To overcome this limitation, our proposal applies a deep neural network at the receiver, utilizing the Transformer framework for signal detection of DM-IM-3D-OFDM system in Rayleigh fading channel. Simulation results demonstrate that our detector attains to approach performance compared to the model-based receiver. Furthermore, TransD3D-IM exhibits more robustness than the existing deep learning-based detector while considerably reducing runtime complexity in comparison with the benchmarks.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种深度学习基于的信号探测器，即TransD3D-IM，该探测器使用Transformer框架进行信号探测在三个维度（3D）相互频分复用（DM-IM-3D-OFDM）系统中。在这个系统中，数据位通过 dual-mode 3D 象限符号和活动子频点来传输。因此，这种方法在现有的IM-based模型中显示出了明显更高的传输可靠性。然而，ML 探测器在系统参数较大时会受到高计算复杂性的限制。而Log-Likelihood Ratio 算法，作为 DM-IM-3D-OFDM 系统中的低复杂度探测器，也并不够印象。为了解决这个问题，我们的提案使用了一个深度神经网络，通过Transformer框架进行 DM-IM-3D-OFDM 系统中的信号探测。实验结果表明，我们的探测器可以准确地探测 DM-IM-3D-OFDM 系统中的信号，并且比模型基于接收器更具有 approached 性。此外，TransD3D-IM 还表现了更高的鲁棒性，而且可以在对比 benchmarks 时大幅减少运行时复杂性。
</details></li>
</ul>
<hr>
<h2 id="A-Public-Information-Precoding-for-MIMO-Visible-Light-Communication-System-Based-on-Manifold-Optimization"><a href="#A-Public-Information-Precoding-for-MIMO-Visible-Light-Communication-System-Based-on-Manifold-Optimization" class="headerlink" title="A Public Information Precoding for MIMO Visible Light Communication System Based on Manifold Optimization"></a>A Public Information Precoding for MIMO Visible Light Communication System Based on Manifold Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04709">http://arxiv.org/abs/2309.04709</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hamed Alizadeh Ghazijahani, Mahmoud Atashbar, Guan Yong Liang, Zhaojie Yang</li>
<li>For: 这 paper 的目的是设计一种 omnidirectional  precoding，以便在 MIMO-VLC 网络中传输公共信息的信号。* Methods: 该 paper 使用了一种最大化可 achievable 率的方法，以提高发送信号的能量效率和bit error rate。它还考虑了所有 LED 的平均发送功率是相同的约束。* Results:  simulation 结果表明，提案的 omnidirectional precoding 可以实现更高的Received Mean Power 和 bit error rate，相比于传统的无precoding方法。<details>
<summary>Abstract</summary>
Visible light communication (VLC) is an attractive subset of optical communication that provides a high data rate in the access layer of the network. The combination of multiple inputmultiple output (MIMO) with a VLC system leads to a higher speed of data transmission named as MIMO-VLC system. In multi-user (MU) MIMO-VLC, a LED array transmits signals for users. These signals are categorized as signals of private information for each user and signals of public information for all users. The main idea of this paper is to design an omnidirectional precoding to transmit the signals of public information in the MUMIMO-VLC network. To this end, we propose to maximize the achievable rate which leads to maximizing the received mean power at the possible location of the users. Besides maximizing the achievable rate, we consider equal mean transmission power constraint in all LEDs to achieve higher power efficiency of the power amplifiers used in the LED array. Based on this we formulate an optimization problem in which the constraint is in the form of a manifold and utilize a gradient method projected on the manifold to solve the problem. Simulation results indicate that the proposed omnidirectional precoding can achieve superior received mean power and bit error rate with respect to the classical form without precoding utilization.
</details>
<details>
<summary>摘要</summary>
可见光通信（VLC）是一个吸引人的光学通信子集，它在网络访问层提供高速的数据传输率。将多输入多输出（MIMO）技术与VLC系统结合，称为MIMO-VLC系统，可以提高数据传输速率。在多用户（MU）MIMO-VLC网络中，LED数组发送用户信号。这些信号分为每个用户的专用信息信号和所有用户的公共信息信号。本文的主要想法是设计一种全方位预编码，以在MUMIMO-VLC网络中传输公共信息信号。为此，我们提出了最大化可 achievable 率的目标，以最大化用户可能位置上接收到的平均功率。此外，我们还考虑了所有LED的平均发射功率均衡限制，以提高发射器使用的电力增效。基于这些假设，我们形式化了一个优化问题，并使用梯度法在杯 manifold上解决问题。实验结果表明，我们提出的全方位预编码可以在比较高的接收平均功率和比特错误率下获得优于经典预编码无使用情况。
</details></li>
</ul>
<hr>
<h2 id="Novel-Smart-N95-Filtering-Facepiece-Respirator-with-Real-time-Adaptive-Fit-Functionality-and-Wireless-Humidity-Monitoring-for-Enhanced-Wearable-Comfort"><a href="#Novel-Smart-N95-Filtering-Facepiece-Respirator-with-Real-time-Adaptive-Fit-Functionality-and-Wireless-Humidity-Monitoring-for-Enhanced-Wearable-Comfort" class="headerlink" title="Novel Smart N95 Filtering Facepiece Respirator with Real-time Adaptive Fit Functionality and Wireless Humidity Monitoring for Enhanced Wearable Comfort"></a>Novel Smart N95 Filtering Facepiece Respirator with Real-time Adaptive Fit Functionality and Wireless Humidity Monitoring for Enhanced Wearable Comfort</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07152">http://arxiv.org/abs/2309.07152</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kangkyu Kwon, Yoon Jae Lee, Yeongju Jung, Ira Soltis, Chanyeong Choi, Yewon Na, Lissette Romero, Myung Chul Kim, Nathan Rodeheaver, Hodam Kim, Michael S. Lloyd, Ziqing Zhuang, William King, Susan Xu, Seung-Hwan Ko, Jinwoo Lee, Woon-Hong Yeo</li>
<li>For: This paper aims to address the limitations of current facial respirators by developing a novel smart N-95 filtering facepiece respirator with self-fit adjusting functionality and air quality monitoring.* Methods: The proposed respirator incorporates a humidity sensor made of laser-induced graphene and a pressure sensor array based on dielectric elastomeric sponge to monitor the respirator’s contact with the user’s face and provide closed-loop feedback for self-fit adjustment.* Results: The self-fit adjusting mode and elastomeric lining of the proposed respirator improve the fit factor by an average of 3.20 and 5 times at maximum, compared to current commercial respirators.<details>
<summary>Abstract</summary>
The widespread emergence of the COVID-19 pandemic has transformed our lifestyle, and facial respirators have become an essential part of daily life. Nevertheless, the current respirators possess several limitations such as poor respirator fit because they are incapable of covering diverse human facial sizes and shapes, potentially diminishing the effect of wearing respirators. In addition, the current facial respirators do not inform the user of the air quality within the smart facepiece respirator in case of continuous long-term use. Here, we demonstrate the novel smart N-95 filtering facepiece respirator that incorporates the humidity sensor and pressure sensory feedback-enabled self-fit adjusting functionality for the effective performance of the facial respirator to prevent the transmission of airborne pathogens. The laser-induced graphene (LIG) constitutes the humidity sensor, and the pressure sensor array based on the dielectric elastomeric sponge monitors the respirator contact on the face of the user, providing the sensory information for a closed-loop feedback mechanism. As a result of the self-fit adjusting mode along with elastomeric lining, the fit factor is increased by 3.20 and 5 times at average and maximum respectively. We expect that the experimental proof-of-concept of this work will offer viable solutions to the current commercial respirators to address the limitations.
</details>
<details>
<summary>摘要</summary>
covid-19 疫情的普及使我们的生活方式发生了深刻的改变，而 facial respirator 也成为了我们日常生活中的必备品。然而，现有的 respirator 具有许多限制，例如覆盖人类面部多样化大小和形状的能力不足，可能导致戴着 respirator 的效果受损。此外，现有的 facial respirator 也无法在长期使用时提供空气质量的信息。我们在这里展示了一种新型的智能 N-95 滤袋面罩，它具有滤袋面罩内部湿度感应器和压力感应器透过自适应调节功能，以提高面罩的适合度和效果。使用 LIG 将滤袋面罩内部湿度感应器，而基于导电塑胶泡的压力感应器则用于监控用户面罩的接触情况，提供关键的感应信息。因此，这个自适应调节模式加上塑料膜装饰，使面罩的适合度提高了 3.20 和 5 倍的平均和最大值。我们预期这个实验证明将提供现有商业 respirator 改进的可能性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/09/eess.SP_2023_09_09/" data-id="clogxf3tf01785xra9e52avte" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_09_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/08/cs.SD_2023_09_08/" class="article-date">
  <time datetime="2023-09-08T15:00:00.000Z" itemprop="datePublished">2023-09-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/08/cs.SD_2023_09_08/">cs.SD - 2023-09-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Exploring-Domain-Specific-Enhancements-for-a-Neural-Foley-Synthesizer"><a href="#Exploring-Domain-Specific-Enhancements-for-a-Neural-Foley-Synthesizer" class="headerlink" title="Exploring Domain-Specific Enhancements for a Neural Foley Synthesizer"></a>Exploring Domain-Specific Enhancements for a Neural Foley Synthesizer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04641">http://arxiv.org/abs/2309.04641</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ashwin Pillay, Sage Betko, Ari Liloia, Hao Chen, Ankit Shah</li>
<li>for: 这个研究旨在创建一个基于神经网络的FOLEY声音生成模型，可以生成多种声音效果 clip。</li>
<li>methods: 该模型利用预训练encoder保留声学和音乐特征，并通过类别conditioning进行修饰，以提高FOLEY类型之间的差异性。它还采用了一种新的 transformer 架构来优化自我注意计算，以满足大输入的需求。</li>
<li>results: 研究人员通过实施该模型后，得到了胜过基准的中间结果，并提出了实践中遇到的挑战和未来研究的可能性。<details>
<summary>Abstract</summary>
Foley sound synthesis refers to the creation of authentic, diegetic sound effects for media, such as film or radio. In this study, we construct a neural Foley synthesizer capable of generating mono-audio clips across seven predefined categories. Our approach introduces multiple enhancements to existing models in the text-to-audio domain, with the goal of enriching the diversity and acoustic characteristics of the generated foleys. Notably, we utilize a pre-trained encoder that retains acoustical and musical attributes in intermediate embeddings, implement class-conditioning to enhance differentiability among foley classes in their intermediate representations, and devise an innovative transformer-based architecture for optimizing self-attention computations on very large inputs without compromising valuable information. Subsequent to implementation, we present intermediate outcomes that surpass the baseline, discuss practical challenges encountered in achieving optimal results, and outline potential pathways for further research.
</details>
<details>
<summary>摘要</summary>
FOLEY声音合成指的是为媒体（如电影或广播）创建真实、地点声音效果。在这个研究中，我们构建了一个基于神经网络的FOLEY声音合成器，能够生成多个频道单声道音频clip。我们的方法对现有文本到声音频域的模型进行了多种改进，以增强生成的FOLEY声音的多样性和听觉特征。特别是，我们使用预训练的编码器保留了听觉和音乐特征在中间 Representation中，实施了类conditioning来增强FOLEY类在中间表示中的分 differentiability，并设计了一种新的transformer-based架构来优化自注意计算在很大输入上 без comprising valuable information。在实施后，我们展示了胜过基准的中间结果，讨论了实际遇到的挑战和 achievement 的可能性，并 outline了进一步研究的可能性。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Pretrained-Image-text-Models-for-Improving-Audio-Visual-Learning"><a href="#Leveraging-Pretrained-Image-text-Models-for-Improving-Audio-Visual-Learning" class="headerlink" title="Leveraging Pretrained Image-text Models for Improving Audio-Visual Learning"></a>Leveraging Pretrained Image-text Models for Improving Audio-Visual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04628">http://arxiv.org/abs/2309.04628</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saurabhchand Bhati, Jesús Villalba, Laureano Moro-Velazquez, Thomas Thebaud, Najim Dehak<br>for: 这 paper 的目的是提高 speech-based visually grounded models 的性能，使其能够更好地利用 pretrained image 和 text 编码器。methods: 这 paper 使用了 hierarchical segmental speech 编码器，将 speech 转化为 sequence of word-like unit 表示，然后使用 pretrained CLIP text 编码器进行编码。它还 explore 了 mapping audio 到 CLIP 词嵌入空间 via regularization 和 quantization。results:  experiments 表明，使用这种方法可以减少 Retrieval 性能下降，并且 audio-only 系统可以减少到 audio-visual 系统的性能差距。<details>
<summary>Abstract</summary>
Visually grounded speech systems learn from paired images and their spoken captions. Recently, there have been attempts to utilize the visually grounded models trained from images and their corresponding text captions, such as CLIP, to improve speech-based visually grounded models' performance. However, the majority of these models only utilize the pretrained image encoder. Cascaded SpeechCLIP attempted to generate localized word-level information and utilize both the pretrained image and text encoders. Despite using both, they noticed a substantial drop in retrieval performance. We proposed Segmental SpeechCLIP which used a hierarchical segmental speech encoder to generate sequences of word-like units. We used the pretrained CLIP text encoder on top of these word-like unit representations and showed significant improvements over the cascaded variant of SpeechCLIP. Segmental SpeechCLIP directly learns the word embeddings as input to the CLIP text encoder bypassing the vocabulary embeddings. Here, we explore mapping audio to CLIP vocabulary embeddings via regularization and quantization. As our objective is to distill semantic information into the speech encoders, we explore the usage of large unimodal pretrained language models as the text encoders. Our method enables us to bridge image and text encoders e.g. DINO and RoBERTa trained with uni-modal data. Finally, we extend our framework in audio-only settings where only pairs of semantically related audio are available. Experiments show that audio-only systems perform close to the audio-visual system.
</details>
<details>
<summary>摘要</summary>
visually grounded speech系统学习从图像和其对应的语音标签 pairs。最近，有人尝试使用已经训练过图像和语音标签的视觉grounded模型，如CLIP，来提高语音基于图像的模型性能。然而，大多数模型只使用预训练的图像编码器。卷积SpeechCLIP尝试生成本地化的单词水平信息并使用图像和语音编码器。尽管使用了两者，但它们发现了重要的搜索性能下降。我们提出了层次分割的SpeechCLIP，使用层次分割的语音编码器来生成语音序列。我们使用预训练的CLIP文本编码器进行这些语音序列表示，并显示了显著改进于卷积SpeechCLIP的变体。Segmental SpeechCLIP直接学习 word embeddings 作为 CLIP文本编码器的输入，而不需要词表 embeddings。我们的目标是将语音编码器中的semantic信息储存下来，所以我们 explore使用大型单模型预训练语言模型作为文本编码器。我们的方法可以将图像和语音编码器相互连接，例如 DINO和RoBERTa 在单模型数据上进行训练。最后，我们扩展我们的框架到具有唯一相关的音频的设置， где只有semantically相关的音频对应。实验显示，具有唯一相关的音频系统可以与具有视频的系统相互竞争。
</details></li>
</ul>
<hr>
<h2 id="A-Long-Tail-Friendly-Representation-Framework-for-Artist-and-Music-Similarity"><a href="#A-Long-Tail-Friendly-Representation-Framework-for-Artist-and-Music-Similarity" class="headerlink" title="A Long-Tail Friendly Representation Framework for Artist and Music Similarity"></a>A Long-Tail Friendly Representation Framework for Artist and Music Similarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04182">http://arxiv.org/abs/2309.04182</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoran Xiang, Junyu Dai, Xuchen Song, Furao Shen</li>
<li>for: 这 paper 的目的是提出一种适应长尾情况的 Long-Tail Friendly Representation Framework (LTFRF), 用于音乐检索和推荐。</li>
<li>methods: 该 paper 使用神经网络模型音乐、用户、元数据和关系数据， integrate 到一个统一的 métric learning 框架中，并使用多种关系为regular term来引入多元关系损失。</li>
<li>results: 对于 Similar Artist&#x2F;Music Recommendation 任务，LTFRF 比基eline 高效， Hit Ratio@10 上升9.69%&#x2F;19.42%，而在长尾情况下，LTFRF 与基eline 的差距为11.05%&#x2F;14.14%。<details>
<summary>Abstract</summary>
The investigation of the similarity between artists and music is crucial in music retrieval and recommendation, and addressing the challenge of the long-tail phenomenon is increasingly important. This paper proposes a Long-Tail Friendly Representation Framework (LTFRF) that utilizes neural networks to model the similarity relationship. Our approach integrates music, user, metadata, and relationship data into a unified metric learning framework, and employs a meta-consistency relationship as a regular term to introduce the Multi-Relationship Loss. Compared to the Graph Neural Network (GNN), our proposed framework improves the representation performance in long-tail scenarios, which are characterized by sparse relationships between artists and music. We conduct experiments and analysis on the AllMusic dataset, and the results demonstrate that our framework provides a favorable generalization of artist and music representation. Specifically, on similar artist/music recommendation tasks, the LTFRF outperforms the baseline by 9.69%/19.42% in Hit Ratio@10, and in long-tail cases, the framework achieves 11.05%/14.14% higher than the baseline in Consistent@10.
</details>
<details>
<summary>摘要</summary>
<SYS> translate("The investigation of the similarity between artists and music is crucial in music retrieval and recommendation, and addressing the challenge of the long-tail phenomenon is increasingly important.")</SYS> investigate("调查") similarity("相似性") artists("艺术家") music("音乐") retrieval("检索") recommendation("推荐") long-tail("长尾") phenomenon("现象") crucial("关键") addressing("解决") challenge("挑战")Here's the translation of the rest of the text:<SYS> translate("This paper proposes a Long-Tail Friendly Representation Framework (LTFRF) that utilizes neural networks to model the similarity relationship. Our approach integrates music, user, metadata, and relationship data into a unified metric learning framework, and employs a meta-consistency relationship as a regular term to introduce the Multi-Relationship Loss. Compared to the Graph Neural Network (GNN), our proposed framework improves the representation performance in long-tail scenarios, which are characterized by sparse relationships between artists and music.")</SYS> propose("提出") framework("框架") Long-Tail Friendly Representation Framework ("LTFRF") neural networks ("神经网络") model("模型") similarity relationship ("相似性关系") integrate("集成") music ("音乐") user ("用户") metadata ("元数据") relationship data ("关系数据") unified metric learning framework ("统一度量学习框架") meta-consistency relationship ("meta共识关系") Multi-Relationship Loss ("多关系损失") Graph Neural Network ("GNN") representation performance ("表示性能") long-tail scenarios ("长尾场景") sparse relationships ("稀疏关系") between artists and music ("艺术家和音乐之间")
</details></li>
</ul>
<hr>
<h2 id="A-Two-Stage-Training-Framework-for-Joint-Speech-Compression-and-Enhancement"><a href="#A-Two-Stage-Training-Framework-for-Joint-Speech-Compression-and-Enhancement" class="headerlink" title="A Two-Stage Training Framework for Joint Speech Compression and Enhancement"></a>A Two-Stage Training Framework for Joint Speech Compression and Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04132">http://arxiv.org/abs/2309.04132</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jscscloris/sestream">https://github.com/jscscloris/sestream</a></li>
<li>paper_authors: Jiayi Huang, Zeyu Yan, Wenbin Jiang, Fei Wen</li>
<li>for: 本研究考虑了干扰处理 speech signal 的同时压缩和提高问题。</li>
<li>methods: 该研究提出了一种理论基础的两个阶段优化过程，首先优化一个编码器-解码器对，然后使用感知损失来优化一个感知解码器。</li>
<li>results: 实验结果表明，使用该两阶段训练方法可以超越 SoundStream 和其他代表性的编码器，在对象和主观评价指标上均表现出色。<details>
<summary>Abstract</summary>
This paper considers the joint compression and enhancement problem for speech signal in the presence of noise. Recently, the SoundStream codec, which relies on end-to-end joint training of an encoder-decoder pair and a residual vector quantizer by a combination of adversarial and reconstruction losses,has shown very promising performance, especially in subjective perception quality. In this work, we provide a theoretical result to show that, to simultaneously achieve low distortion and high perception in the presence of noise, there exist an optimal two-stage optimization procedure for the joint compression and enhancement problem. This procedure firstly optimizes an encoder-decoder pair using only distortion loss and then fixes the encoder to optimize a perceptual decoder using perception loss. Based on this result, we construct a two-stage training framework for joint compression and enhancement of noisy speech signal. Unlike existing training methods which are heuristic, the proposed two-stage training method has a theoretical foundation. Finally, experimental results for various noise and bit-rate conditions are provided. The results demonstrate that a codec trained by the proposed framework can outperform SoundStream and other representative codecs in terms of both objective and subjective evaluation metrics. Code is available at \textit{https://github.com/jscscloris/SEStream}.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/08/cs.SD_2023_09_08/" data-id="clogxf3qb00uj5xra1pcp1pd4" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_09_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/08/eess.AS_2023_09_08/" class="article-date">
  <time datetime="2023-09-08T14:00:00.000Z" itemprop="datePublished">2023-09-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/08/eess.AS_2023_09_08/">eess.AS - 2023-09-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Asymmetric-Clean-Segments-Guided-Self-Supervised-Learning-for-Robust-Speaker-Verification"><a href="#Asymmetric-Clean-Segments-Guided-Self-Supervised-Learning-for-Robust-Speaker-Verification" class="headerlink" title="Asymmetric Clean Segments-Guided Self-Supervised Learning for Robust Speaker Verification"></a>Asymmetric Clean Segments-Guided Self-Supervised Learning for Robust Speaker Verification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04265">http://arxiv.org/abs/2309.04265</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chong-Xin Gan, Man-Wai Mak, Weiwei Lin, Jen-Tzung Chien</li>
<li>for: 这个论文是为了提高Speaker Verification（SV）的性能而写的。</li>
<li>methods: 这个论文使用了Contrastive Self-supervised Learning（CSL）方法，并在数据增强前进行了精心的调整，以确保保留speaker-specific信息。</li>
<li>results: 实验结果表明，提出的方法可以在Voxceleb1 dataset上达到19%的提升，并超过许多现有的状态对技术。<details>
<summary>Abstract</summary>
Contrastive self-supervised learning (CSL) for speaker verification (SV) has drawn increasing interest recently due to its ability to exploit unlabeled data. Performing data augmentation on raw waveforms, such as adding noise or reverberation, plays a pivotal role in achieving promising results in SV. Data augmentation, however, demands meticulous calibration to ensure intact speaker-specific information, which is difficult to achieve without speaker labels. To address this issue, we introduce a novel framework by incorporating clean and augmented segments into the contrastive training pipeline. The clean segments are repurposed to pair with noisy segments to form additional positive and negative pairs. Moreover, the contrastive loss is weighted to increase the difference between the clean and augmented embeddings of different speakers. Experimental results on Voxceleb1 suggest that the proposed framework can achieve a remarkable 19% improvement over the conventional methods, and it surpasses many existing state-of-the-art techniques.
</details>
<details>
<summary>摘要</summary>
“对话自我超vised学习（CSL）在 speaker verification（SV）中已引起了越来越多的关注，因为它可以利用无标签数据。在 raw waveform 上进行数据增强，如添加噪音或投射，对 SV 的表现产生了关键作用。然而，数据增强需要仔细调整，以确保保留Speaker-specific信息，这是 без speaker 标签很难实现。为解决这个问题，我们提出了一种新的框架，通过将清晰和增强段 integrate 到对比训练管道中。清晰段被重新用于与噪音段成对，以形成额外的正方向和负方向对。此外，对比损失被权重，以增加不同Speaker的增强 embeddings 之间的差异。实验结果表明，我们的方法可以在 Voxceleb1 上实现了非常出色的 19% 提高，并超越了许多现有的state-of-the-art技术。”Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/08/eess.AS_2023_09_08/" data-id="clogxf3re00z75xrahzi32juo" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/08/cs.CV_2023_09_08/" class="article-date">
  <time datetime="2023-09-08T13:00:00.000Z" itemprop="datePublished">2023-09-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/08/cs.CV_2023_09_08/">cs.CV - 2023-09-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Open-and-reusable-deep-learning-for-pathology-with-WSInfer-and-QuPath"><a href="#Open-and-reusable-deep-learning-for-pathology-with-WSInfer-and-QuPath" class="headerlink" title="Open and reusable deep learning for pathology with WSInfer and QuPath"></a>Open and reusable deep learning for pathology with WSInfer and QuPath</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04631">http://arxiv.org/abs/2309.04631</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jakub R. Kaczmarzyk, Alan O’Callaghan, Fiona Inglis, Tahsin Kurc, Rajarsi Gupta, Erich Bremer, Peter Bankhead, Joel H. Saltz</li>
<li>for: 这份论文的目的是提高肿瘤学中深度学习模型的应用，并使其更加流畅和可存取。</li>
<li>methods: 本研究使用了一个新的开源软件生态系统，名为WSInfer，以便更加方便地将深度学习模型应用到肿瘤影像中。WSInfer包括三个主要元素：1）一个Python套件和命令行工具，可以快速地将裁剪式深度学习应用到整个肿瘤影像中; 2）一个QuPath扩展，提供了一个易用且交互式的软件引擎，并3）一个模型zoo，可以让肿瘤学模型和metadata在标准化的形式下进行分享。</li>
<li>results: 本研究的结果显示，WSInfer可以让肿瘤学家和研究人员更加方便地存取和应用深度学习模型，并且不需要程式码经验。WSInfer的源代码被hosts在GitHub上，并且有相关的文档在<a target="_blank" rel="noopener" href="https://wsinfer.readthedocs.io/">https://wsinfer.readthedocs.io</a> 。<details>
<summary>Abstract</summary>
The field of digital pathology has seen a proliferation of deep learning models in recent years. Despite substantial progress, it remains rare for other researchers and pathologists to be able to access models published in the literature and apply them to their own images. This is due to difficulties in both sharing and running models. To address these concerns, we introduce WSInfer: a new, open-source software ecosystem designed to make deep learning for pathology more streamlined and accessible. WSInfer comprises three main elements: 1) a Python package and command line tool to efficiently apply patch-based deep learning inference to whole slide images; 2) a QuPath extension that provides an alternative inference engine through user-friendly and interactive software, and 3) a model zoo, which enables pathology models and metadata to be easily shared in a standardized form. Together, these contributions aim to encourage wider reuse, exploration, and interrogation of deep learning models for research purposes, by putting them into the hands of pathologists and eliminating a need for coding experience when accessed through QuPath. The WSInfer source code is hosted on GitHub and documentation is available at https://wsinfer.readthedocs.io.
</details>
<details>
<summary>摘要</summary>
随着数字 PATHOLOGY 领域的发展，深度学习模型在过去几年内得到了广泛应用。尽管已经取得了显著进步，但是对于其他研究人员和病理学家来说，访问已经发表的模型并将其应用到自己的图像仍然是非常困难的。这是由于分享和运行模型的困难所致。为解决这些问题，我们介绍了 WSInfer：一个新的开源软件生态系统，旨在使得 PATHOLOGY 中的深度学习更加流畅和可访问。WSInfer 包括三个主要元素：1. Python 包和命令行工具，用于高效地应用 patch-based 深度学习推理到整个扫描图像上。2. QuPath 扩展，提供了一个用户友好的和交互式的推理引擎，并且可以让病理学家通过 QuPath 访问和运行深度学习模型，不需要编程经验。3. 模型 zoo，可以方便地将 PATHOLOGY 模型和元数据分享在标准化的形式下。综上所述，WSInfer 的贡献是希望通过将深度学习模型带到病理学家手上，并且不需要编程经验，以便更多的研究人员和病理学家可以轻松地 reuse、探索和调查 PATHOLOGY 中的深度学习模型，以便更好地推进 PATHOLOGY 领域的研究。WSInfer 的源代码位于 GitHub 上，文档可以在 <https://wsinfer.readthedocs.io> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Style-Generation-Image-Synthesis-based-on-Coarsely-Matched-Texts"><a href="#Style-Generation-Image-Synthesis-based-on-Coarsely-Matched-Texts" class="headerlink" title="Style Generation: Image Synthesis based on Coarsely Matched Texts"></a>Style Generation: Image Synthesis based on Coarsely Matched Texts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04608">http://arxiv.org/abs/2309.04608</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengyao Cui, Zhe Zhu, Shao-Ping Lu, Yulu Yang</li>
<li>for: 文章主要目的是提出一种基于文本指导的图像风格生成方法，以便在具有粗糙匹配的文本指导下进行图像生成和修饰。</li>
<li>methods: 本文提出了一种基于文本指导的图像风格生成方法，包括两个阶段：第一阶段使用句子特征来生成图像的整体风格，第二阶段使用多模态风格合成模块来细化生成的风格。</li>
<li>results: 经过广泛的实验和简洁分析，本文提出的方法能够有效地生成基于文本指导的图像风格，并且可以应用于多个实际场景，如文本-图像对齐和故事视觉化等。<details>
<summary>Abstract</summary>
Previous text-to-image synthesis algorithms typically use explicit textual instructions to generate/manipulate images accurately, but they have difficulty adapting to guidance in the form of coarsely matched texts. In this work, we attempt to stylize an input image using such coarsely matched text as guidance. To tackle this new problem, we introduce a novel task called text-based style generation and propose a two-stage generative adversarial network: the first stage generates the overall image style with a sentence feature, and the second stage refines the generated style with a synthetic feature, which is produced by a multi-modality style synthesis module. We re-filter one existing dataset and collect a new dataset for the task. Extensive experiments and ablation studies are conducted to validate our framework. The practical potential of our work is demonstrated by various applications such as text-image alignment and story visualization. Our datasets are published at https://www.kaggle.com/datasets/mengyaocui/style-generation.
</details>
<details>
<summary>摘要</summary>
The first stage of our GAN uses a sentence feature to generate the overall image style, while the second stage refines the generated style with a synthetic feature produced by a multi-modality style synthesis module. We collect a new dataset and re-filter an existing dataset to support our framework.To validate our approach, we conduct extensive experiments and ablation studies. Our work has practical potential, as demonstrated by applications such as text-image alignment and story visualization. Our datasets are available at <https://www.kaggle.com/datasets/mengyaocui/style-generation>.
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Mesh-Aware-Radiance-Fields"><a href="#Dynamic-Mesh-Aware-Radiance-Fields" class="headerlink" title="Dynamic Mesh-Aware Radiance Fields"></a>Dynamic Mesh-Aware Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04581">http://arxiv.org/abs/2309.04581</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/YilingQiao/DMRF">https://github.com/YilingQiao/DMRF</a></li>
<li>paper_authors: Yi-Ling Qiao, Alexander Gao, Yiran Xu, Yue Feng, Jia-Bin Huang, Ming C. Lin</li>
<li>for: 这篇论文的目的是探讨在把几何体资产逻辑地嵌入到 fotorealistic Neural Radience Fields（NeRF）中，以便在物理上一致的方式渲染和模拟它们，从系统角度来看是一个未经探讨的领域。</li>
<li>methods: 这篇论文提出了一种两向相互关联的方法，即在渲染和模拟过程中，将几何体和NeRF之间进行相互 Coupling。首先，我们审视了几何体和NeRF之间的光传输方程，然后将它们转化为一种高效的算法，用于更新各个碰撞点的辐射和通过put。为了解决NeRF使用的标准颜色空间和几何体之间的差异，我们在NeRF中训练了高动态范围（HDR）图像。此外，我们还提出了一种策略来估算NeRF中的光源和投射阴影。</li>
<li>results: 我们的实验结果表明，在渲染和模拟过程中，将几何体和NeRF之间进行相互 Coupling，可以提高视觉真实性。这是因为它允许真实的光传输从NeRF媒体onto几何体，对折射&#x2F;填充表面和 diffuse surface informed by dynamic scene产生影响。<details>
<summary>Abstract</summary>
Embedding polygonal mesh assets within photorealistic Neural Radience Fields (NeRF) volumes, such that they can be rendered and their dynamics simulated in a physically consistent manner with the NeRF, is under-explored from the system perspective of integrating NeRF into the traditional graphics pipeline. This paper designs a two-way coupling between mesh and NeRF during rendering and simulation. We first review the light transport equations for both mesh and NeRF, then distill them into an efficient algorithm for updating radiance and throughput along a cast ray with an arbitrary number of bounces. To resolve the discrepancy between the linear color space that the path tracer assumes and the sRGB color space that standard NeRF uses, we train NeRF with High Dynamic Range (HDR) images. We also present a strategy to estimate light sources and cast shadows on the NeRF. Finally, we consider how the hybrid surface-volumetric formulation can be efficiently integrated with a high-performance physics simulator that supports cloth, rigid and soft bodies. The full rendering and simulation system can be run on a GPU at interactive rates. We show that a hybrid system approach outperforms alternatives in visual realism for mesh insertion, because it allows realistic light transport from volumetric NeRF media onto surfaces, which affects the appearance of reflective/refractive surfaces and illumination of diffuse surfaces informed by the dynamic scene.
</details>
<details>
<summary>摘要</summary>
<<SYS>> transtable mesh assets within photorealistic Neural Radience Fields（NeRF）volumes, such that they can be rendered and their dynamics simulated in a physically consistent manner with the NeRF, is under-explored from the system perspective of integrating NeRF into the traditional graphics pipeline. This paper designs a two-way coupling between mesh and NeRF during rendering and simulation. We first review the light transport equations for both mesh and NeRF, then distill them into an efficient algorithm for updating radiance and throughput along a cast ray with an arbitrary number of bounces. To resolve the discrepancy between the linear color space that the path tracer assumes and the sRGB color space that standard NeRF uses, we train NeRF with High Dynamic Range（HDR）images. We also present a strategy to estimate light sources and cast shadows on the NeRF. Finally, we consider how the hybrid surface-volumetric formulation can be efficiently integrated with a high-performance physics simulator that supports cloth, rigid and soft bodies. The full rendering and simulation system can be run on a GPU at interactive rates. We show that a hybrid system approach outperforms alternatives in visual realism for mesh insertion, because it allows realistic light transport from volumetric NeRF media onto surfaces, which affects the appearance of reflective/refractive surfaces and illumination of diffuse surfaces informed by the dynamic scene.Note that Simplified Chinese is a more casual and informal version of Chinese, and the word order and grammar may be different from Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Mask2Anomaly-Mask-Transformer-for-Universal-Open-set-Segmentation"><a href="#Mask2Anomaly-Mask-Transformer-for-Universal-Open-set-Segmentation" class="headerlink" title="Mask2Anomaly: Mask Transformer for Universal Open-set Segmentation"></a>Mask2Anomaly: Mask Transformer for Universal Open-set Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04573">http://arxiv.org/abs/2309.04573</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shyam Nandan Rai, Fabio Cermelli, Barbara Caputo, Carlo Masone</li>
<li>for: 本文旨在提出一种基于面Mask的异常检测方法，以解决自动驾驶应用中异常对象实例分割的问题。</li>
<li>methods: 本文提出了一种新的面Mask分类架构，包括全球面Mask注意模块、面对比学习、面修正解决方案和面架构特性采集方法等技术创新，以提高异常检测的精度。</li>
<li>results: 经过全面的质量评估，本文的Mask2异常方法在异常分割、开放集Semantic分割和开放集精度分割三个任务上达到了新的国际纪录。<details>
<summary>Abstract</summary>
Segmenting unknown or anomalous object instances is a critical task in autonomous driving applications, and it is approached traditionally as a per-pixel classification problem. However, reasoning individually about each pixel without considering their contextual semantics results in high uncertainty around the objects' boundaries and numerous false positives. We propose a paradigm change by shifting from a per-pixel classification to a mask classification. Our mask-based method, Mask2Anomaly, demonstrates the feasibility of integrating a mask-classification architecture to jointly address anomaly segmentation, open-set semantic segmentation, and open-set panoptic segmentation. Mask2Anomaly includes several technical novelties that are designed to improve the detection of anomalies/unknown objects: i) a global masked attention module to focus individually on the foreground and background regions; ii) a mask contrastive learning that maximizes the margin between an anomaly and known classes; iii) a mask refinement solution to reduce false positives; and iv) a novel approach to mine unknown instances based on the mask-architecture properties. By comprehensive qualitative and qualitative evaluation, we show Mask2Anomaly achieves new state-of-the-art results across the benchmarks of anomaly segmentation, open-set semantic segmentation, and open-set panoptic segmentation.
</details>
<details>
<summary>摘要</summary>
segmenting unknown or anomalous object instances是自动驾驶应用中的一个关键任务，它通常是以每个像素为单位进行分类的传统方法。然而，不考虑每个像素的语义上下文会导致对象边界的高度不确定性和多个假阳性。我们提议一种思路变革，即从每个像素分类转换到Mask分类。我们的Mask2Anomaly方法表明了将Mask分类建立在 JOINT 中的可能性，以同时解决异常分 segmentation、开放集Semantic segmentation和开放集Panoptic segmentation的问题。Mask2Anomaly方法包括多个技术创新，用于提高异常检测：一、全局遮盲注意力模块，以各自针对前景和背景区域进行遮盲注意力;二、遮盲对比学习，以最大化异常与已知类之间的距离;三、遮盲修正解决方案，以降低假阳性;四、基于Mask-architecture属性挖掘未知实例的新方法。通过全面的Qualitative和Quantitative评估，我们证明Mask2Anomaly方法在 benchmark 上实现了新的状态可识别结果，包括异常分 segmentation、开放集Semantic segmentation和开放集Panoptic segmentation。
</details></li>
</ul>
<hr>
<h2 id="Poster-Making-Edge-assisted-LiDAR-Perceptions-Robust-to-Lossy-Point-Cloud-Compression"><a href="#Poster-Making-Edge-assisted-LiDAR-Perceptions-Robust-to-Lossy-Point-Cloud-Compression" class="headerlink" title="Poster: Making Edge-assisted LiDAR Perceptions Robust to Lossy Point Cloud Compression"></a>Poster: Making Edge-assisted LiDAR Perceptions Robust to Lossy Point Cloud Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04549">http://arxiv.org/abs/2309.04549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jin Heo, Gregorie Phillips, Per-Erik Brodin, Ada Gavrilovska</li>
<li>for: 提高LiDAR点云的质量，以减少因压缩而导致的感知性能下降。</li>
<li>methods: 使用基于深度梯度的插值算法来提高LiDAR点云的质量。</li>
<li>results: 与现有的图像插值算法相比，该算法可以提供更好的质量结果，当点云从插值后重建时。<details>
<summary>Abstract</summary>
Real-time light detection and ranging (LiDAR) perceptions, e.g., 3D object detection and simultaneous localization and mapping are computationally intensive to mobile devices of limited resources and often offloaded on the edge. Offloading LiDAR perceptions requires compressing the raw sensor data, and lossy compression is used for efficiently reducing the data volume. Lossy compression degrades the quality of LiDAR point clouds, and the perception performance is decreased consequently. In this work, we present an interpolation algorithm improving the quality of a LiDAR point cloud to mitigate the perception performance loss due to lossy compression. The algorithm targets the range image (RI) representation of a point cloud and interpolates points at the RI based on depth gradients. Compared to existing image interpolation algorithms, our algorithm shows a better qualitative result when the point cloud is reconstructed from the interpolated RI. With the preliminary results, we also describe the next steps of the current work.
</details>
<details>
<summary>摘要</summary>
现实时光 detection和跟踪（LiDAR）感知需要大量计算能力，例如3D对象检测和同时地图定位。由于移动设备的限制资源，LiDAR感知通常会在边缘上下载。压缩 Raw sensor data 需要lossy compression，这会降低LiDAR点云的质量。在这种情况下，我们提出了一种 interpolating algorithm，用于改善LiDAR点云的质量，以避免因压缩而导致的感知性能下降。我们的算法targets the range image（RI）表示法，并在RI基于深度梯度进行点云点的 interpolating。与现有的图像 interpolating algorithm相比，我们的算法在重建点云时表现更好。在下一步工作中，我们还将描述我们的current work的进展。
</details></li>
</ul>
<hr>
<h2 id="Examining-Autoexposure-for-Challenging-Scenes"><a href="#Examining-Autoexposure-for-Challenging-Scenes" class="headerlink" title="Examining Autoexposure for Challenging Scenes"></a>Examining Autoexposure for Challenging Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04542">http://arxiv.org/abs/2309.04542</a></li>
<li>repo_url: None</li>
<li>paper_authors: SaiKiran Tedla, Beixuan Yang, Michael S. Brown</li>
<li>for: 提供一个大量的曝光数据集，以便发展适用于具有变化照明的环境中的曝光算法。</li>
<li>methods: 使用一个软件平台，让不同的曝光算法可以在一个插件的方式下使用数据集进行重复评估。</li>
<li>results: 透过评估一些现有的曝光策略，发现大多数使用者偏好使用简单的焦点方法来应对具有变化照明的情况。<details>
<summary>Abstract</summary>
Autoexposure (AE) is a critical step applied by camera systems to ensure properly exposed images. While current AE algorithms are effective in well-lit environments with constant illumination, these algorithms still struggle in environments with bright light sources or scenes with abrupt changes in lighting. A significant hurdle in developing new AE algorithms for challenging environments, especially those with time-varying lighting, is the lack of suitable image datasets. To address this issue, we have captured a new 4D exposure dataset that provides a large solution space (i.e., shutter speed range from (1/500 to 15 seconds) over a temporal sequence with moving objects, bright lights, and varying lighting. In addition, we have designed a software platform to allow AE algorithms to be used in a plug-and-play manner with the dataset. Our dataset and associate platform enable repeatable evaluation of different AE algorithms and provide a much-needed starting point to develop better AE methods. We examine several existing AE strategies using our dataset and show that most users prefer a simple saliency method for challenging lighting conditions.
</details>
<details>
<summary>摘要</summary>
自动曝光（AE）是摄像系统中一个关键的步骤，以确保得到正确曝光的图像。目前的AE算法在充足照明环境下效果良好，但是这些算法在灯光强度变化或场景中有突然变化的照明情况下仍然受到挑战。开发新的AE算法需要一个适当的图像数据集，但现有的问题在开发新算法方面带来了很大的障碍。为解决这个问题，我们已经捕捉了一个新的4D曝光数据集，该数据集提供了广泛的解决空间（即闭合速度范围从(1/500到15秒)），并且包含了在时间序列中移动的 объек、灯光和不同的照明情况。此外，我们还设计了一个软件平台，以便AE算法可以在插件化的方式使用该数据集。我们的数据集和相关平台为不同的AE算法提供了重复可评估的开始点，并且我们通过使用我们的数据集对一些现有的AE策略进行了评估，发现大多数用户在困难的照明条件下偏好使用简单的注意力方法。
</details></li>
</ul>
<hr>
<h2 id="Generalized-Cross-domain-Multi-label-Few-shot-Learning-for-Chest-X-rays"><a href="#Generalized-Cross-domain-Multi-label-Few-shot-Learning-for-Chest-X-rays" class="headerlink" title="Generalized Cross-domain Multi-label Few-shot Learning for Chest X-rays"></a>Generalized Cross-domain Multi-label Few-shot Learning for Chest X-rays</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04462">http://arxiv.org/abs/2309.04462</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aroof Aimen, Arsh Verma, Makarand Tapaswi, Narayanan C. Krishnan</li>
<li>for: 这篇论文是用于测试胸部X射镜像的异常性分类方法。</li>
<li>methods: 这篇论文使用了一个称为Generalized Cross-Domain Multi-Label Few-Shot Learning（GenCDML-FSL）的整合框架，这个框架可以处理多个挑战，包括训练和评估集来自不同Domain的资料，以及训练和评估过程中的类别 overlap。</li>
<li>results: 比较了以上Method与已知方法，如trasnfer learning、Hybrid transfer learning和Multi-label meta-learning，在多个数据集上的比较结果显示了我们的方法的超越性。<details>
<summary>Abstract</summary>
Real-world application of chest X-ray abnormality classification requires dealing with several challenges: (i) limited training data; (ii) training and evaluation sets that are derived from different domains; and (iii) classes that appear during training may have partial overlap with classes of interest during evaluation. To address these challenges, we present an integrated framework called Generalized Cross-Domain Multi-Label Few-Shot Learning (GenCDML-FSL). The framework supports overlap in classes during training and evaluation, cross-domain transfer, adopts meta-learning to learn using few training samples, and assumes each chest X-ray image is either normal or associated with one or more abnormalities. Furthermore, we propose Generalized Episodic Training (GenET), a training strategy that equips models to operate with multiple challenges observed in the GenCDML-FSL scenario. Comparisons with well-established methods such as transfer learning, hybrid transfer learning, and multi-label meta-learning on multiple datasets show the superiority of our approach.
</details>
<details>
<summary>摘要</summary>
实际应用中的胸部X射线异常分类问题需要面临多个挑战：（i）有限的训练数据；（ii）训练和评估集来自不同领域；（iii）训练中的类可能与评估中的类有部分重叠。为解决这些挑战，我们提出了一个总结性的框架，即通用跨领域多标签少量学习（GenCDML-FSL）框架。该框架支持训练和评估阶段类的重叠，进行跨领域传输，采用元学习来学习使用少量训练样本，并假设每个胸部X射线图像是正常的或与一个或多个异常相关。此外，我们提出了一种通用 episodic 训练策略（GenET），该策略可以让模型在 GenCDML-FSL 场景中处理多个挑战。与已有方法 such as 传输学习、混合传输学习和多标签元学习在多个数据集上进行比较，我们的方法表现出了superiority。
</details></li>
</ul>
<hr>
<h2 id="WiSARD-A-Labeled-Visual-and-Thermal-Image-Dataset-for-Wilderness-Search-and-Rescue"><a href="#WiSARD-A-Labeled-Visual-and-Thermal-Image-Dataset-for-Wilderness-Search-and-Rescue" class="headerlink" title="WiSARD: A Labeled Visual and Thermal Image Dataset for Wilderness Search and Rescue"></a>WiSARD: A Labeled Visual and Thermal Image Dataset for Wilderness Search and Rescue</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04453">http://arxiv.org/abs/2309.04453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Broyles, Christopher R. Hayner, Karen Leung</li>
<li>for: 这些研究是为了帮助reducesearch times和alleviate safety risks for first responders carrying out Wilderness Search and Rescue (WiSAR) operations.</li>
<li>methods: 这些研究使用了多模式感知器，specifically visual-thermal cameras，以使wiSAR UAVs可以在多种操作条件下工作。</li>
<li>results: 这些研究提供了roughly 56,000 labeled visual and thermal images，用于开发vision-based algorithms for autonomous WiSAR UAVs。这些图像来自UAV飞行中的多种地形、季节、天气和照明条件。<details>
<summary>Abstract</summary>
Sensor-equipped unoccupied aerial vehicles (UAVs) have the potential to help reduce search times and alleviate safety risks for first responders carrying out Wilderness Search and Rescue (WiSAR) operations, the process of finding and rescuing person(s) lost in wilderness areas. Unfortunately, visual sensors alone do not address the need for robustness across all the possible terrains, weather, and lighting conditions that WiSAR operations can be conducted in. The use of multi-modal sensors, specifically visual-thermal cameras, is critical in enabling WiSAR UAVs to perform in diverse operating conditions. However, due to the unique challenges posed by the wilderness context, existing dataset benchmarks are inadequate for developing vision-based algorithms for autonomous WiSAR UAVs. To this end, we present WiSARD, a dataset with roughly 56,000 labeled visual and thermal images collected from UAV flights in various terrains, seasons, weather, and lighting conditions. To the best of our knowledge, WiSARD is the first large-scale dataset collected with multi-modal sensors for autonomous WiSAR operations. We envision that our dataset will provide researchers with a diverse and challenging benchmark that can test the robustness of their algorithms when applied to real-world (life-saving) applications.
</details>
<details>
<summary>摘要</summary>
游戏式无人航空车(UAV)可以帮助紧急救援人员在遥远地区进行搜索和拯救操作，即当人失踪在郊状地区时。然而，视觉感应器alone无法涵盖所有可能的地形、天气和照明情况，因此需要使用多模式感应器，尤其是视觉热成像摄像头，以实现 WiSAR UAVs 在多元运行环境中的运作。然而，由于郊状地区的特殊挑战，现有的数据集标准是不充分的 для开发基于视觉的数据分析算法。为此，我们提出了 WiSARD 数据集，收集了来自 UAV 飞行的约 56,000 个视觉和热成像摄像头标签图像，包括不同的地形、季节、天气和照明情况。我们知道 WiSARD 是首个基于多模式感应器的大规模数据集，我们预期这个数据集将提供研究人员一个多样化和挑战性的 benchmarck，以测试对真实应用中的数据分析算法的Robustness。
</details></li>
</ul>
<hr>
<h2 id="Demographic-Disparities-in-1-to-Many-Facial-Identification"><a href="#Demographic-Disparities-in-1-to-Many-Facial-Identification" class="headerlink" title="Demographic Disparities in 1-to-Many Facial Identification"></a>Demographic Disparities in 1-to-Many Facial Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04447">http://arxiv.org/abs/2309.04447</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aman Bhatta, Gabriella Pangelinan, Micheal C. King, Kevin W. Bowyer</li>
<li>for: 这个研究旨在检验不同民族和性别对多个人识别率的影响，以及低分辨率和噪音影响识别率的变化。</li>
<li>methods: 这个研究使用了一个新的评价指标，以检验多个人识别率的差异。这些指标包括d’指标、相对分数差和多个人识别分数的分布。</li>
<li>results: 研究发现，不同民族和性别对多个人识别率的影响不同，而且在低分辨率和噪音情况下，男女之间的差异更大。此外，研究还发现，使用”surveillance camera quality”图像库对”government ID quality”图像库进行比较可能会导致识别率下降。<details>
<summary>Abstract</summary>
Most studies to date that have examined demographic variations in face recognition accuracy have analyzed 1-to-1 matching accuracy, using images that could be described as "government ID quality". This paper analyzes the accuracy of 1-to-many facial identification across demographic groups, and in the presence of blur and reduced resolution in the probe image as might occur in "surveillance camera quality" images. Cumulative match characteristic curves(CMC) are not appropriate for comparing propensity for rank-one recognition errors across demographics, and so we introduce three metrics for this: (1) d' metric between mated and non-mated score distributions, (2) absolute score difference between thresholds in the high-similarity tail of the non-mated and the low-similarity tail of the mated distribution, and (3) distribution of (mated - non-mated rank one scores) across the set of probe images. We find that demographic variation in 1-to-many accuracy does not entirely follow what has been observed in 1-to-1 matching accuracy. Also, different from 1-to-1 accuracy, demographic comparison of 1-to-many accuracy can be affected by different numbers of identities and images across demographics. Finally, we show that increased blur in the probe image, or reduced resolution of the face in the probe image, can significantly increase the false positive identification rate. And we show that the demographic variation in these high blur or low resolution conditions is much larger for male/ female than for African-American / Caucasian. The point that 1-to-many accuracy can potentially collapse in the context of processing "surveillance camera quality" probe images against a "government ID quality" gallery is an important one.
</details>
<details>
<summary>摘要</summary>
大多数研究到目前为止对人群差异对面部识别精度进行了分析，使用“政府身份证图像”的样本。这篇论文研究了面部识别的1-to-多匹配精度，以及在不同人群中的差异。我们还引入了三个指标来比较不同人群的潜在一级识别错误风险：1. between mated and non-mated score distributions的d'指标;2. 非硬件tail的非硬件分布下的硬件分布附近的硬件分布差异;3. 探索图像集中的(硬件-非硬件一级识别分布)的分布。我们发现，在1-to-多匹配精度方面，人群差异并不完全与1-to-1匹配精度相同。此外，对于不同人群来说，1-to-多匹配精度的比较可能受到不同人群中的人数和图像数的影响。最后，我们发现，在低锐化或低分辨率情况下，增加了挤压效应可以导致False Positive Identification率的增加。此外，对于男女和非裔美国人来说，在高锐化或低分辨率情况下的人群差异较大。这一点显示，在处理“surveillance camera quality”的探索图像时，1-to-多匹配精度可能会受到“government ID quality”画库的影响。
</details></li>
</ul>
<hr>
<h2 id="Comparative-Study-of-Visual-SLAM-Based-Mobile-Robot-Localization-Using-Fiducial-Markers"><a href="#Comparative-Study-of-Visual-SLAM-Based-Mobile-Robot-Localization-Using-Fiducial-Markers" class="headerlink" title="Comparative Study of Visual SLAM-Based Mobile Robot Localization Using Fiducial Markers"></a>Comparative Study of Visual SLAM-Based Mobile Robot Localization Using Fiducial Markers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04441">http://arxiv.org/abs/2309.04441</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jongwon Lee, Su Yeon Choi, David Hanley, Timothy Bretl</li>
<li>for: 本研究比较了基于视觉SLAM的移动机器人地理位置的三种方法，包括SLAM、SLAM与先前地图和地理位置与先前地图。这些方法都使用了 fiducial marker（即正方形的人工标记，具有黑白棕点纹），以提高地理位置准确性和计算效率。</li>
<li>methods: 本研究使用了视觉SLAM技术，并且在 fiducial marker 的支持下进行了地理位置估算。在这些方法中，SLAM 方法使用了所有可用的特征和标记来估算地理位置，而 SLAM 与先前地图方法则使用了先前知道的地图来帮助估算地理位置。</li>
<li>results: 实验结果表明，三种方法具有相似的绝对轨迹错误水平，但是地理位置估算过程中的运行时间中最短。在地图噪音的影响下，SLAM 与先前地图方法能够维持性能，而地理位置方法却在两个方面下降。<details>
<summary>Abstract</summary>
This paper presents a comparative study of three modes for mobile robot localization based on visual SLAM using fiducial markers (i.e., square-shaped artificial landmarks with a black-and-white grid pattern): SLAM, SLAM with a prior map, and localization with a prior map. The reason for comparing the SLAM-based approaches leveraging fiducial markers is because previous work has shown their superior performance over feature-only methods, with less computational burden compared to methods that use both feature and marker detection without compromising the localization performance. The evaluation is conducted using indoor image sequences captured with a hand-held camera containing multiple fiducial markers in the environment. The performance metrics include absolute trajectory error and runtime for the optimization process per frame. In particular, for the last two modes (SLAM and localization with a prior map), we evaluate their performances by perturbing the quality of prior map to study the extent to which each mode is tolerant to such perturbations. Hardware experiments show consistent trajectory error levels across the three modes, with the localization mode exhibiting the shortest runtime among them. Yet, with map perturbations, SLAM with a prior map maintains performance, while localization mode degrades in both aspects.
</details>
<details>
<summary>摘要</summary>
Here is the text in Simplified Chinese:这篇论文比较了三种移动机器人本地化方法，基于视觉SLAM和 fiducial marker（即方正方形人工标记，黑白扫描纹理）：SLAM、SLAM WITH prior map 和本地化 WITH prior map。这种比较是因为之前的研究表明，使用 fiducial marker 的方法在功能特征和计算成本方面都有着优势，而不需要同时检测特征和标记。这些方法的评估是通过使用indoor镜头拍摄的图像序列来进行，这些序列包含多个 fiducial marker。评估 metric 包括每帧的绝对轨迹错误和优化过程的运行时间。结果表明，三种方法在绝对轨迹错误方面具有相同的水平，但本地化模式具有最短的运行时间。然而，当 prior map 的质量受到扰动时，SLAM WITH prior map 能够维持性能，而本地化模式在两个方面都会下降。
</details></li>
</ul>
<hr>
<h2 id="Single-View-Refractive-Index-Tomography-with-Neural-Fields"><a href="#Single-View-Refractive-Index-Tomography-with-Neural-Fields" class="headerlink" title="Single View Refractive Index Tomography with Neural Fields"></a>Single View Refractive Index Tomography with Neural Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04437">http://arxiv.org/abs/2309.04437</a></li>
<li>repo_url: None</li>
<li>paper_authors: Brandon Zhao, Aviad Levis, Liam Connor, Pratul P. Srinivasan, Katherine L. Bouman</li>
<li>for: 这篇论文的目的是重建场景中的3D干涉场，从2D投射图像测量得到。</li>
<li>methods: 这篇论文使用一种坐标基于的神经网络来模型场景中的连续干涉场，并使用光束的3D空间弯曲来优化网络参数，从而重建干涉场。</li>
<li>results: 在模拟中，这种方法可以成功地重建干涉场，并分析了不同光源分布对重建的影响。在一个模拟的黑洞映射问题中，还成功地重建了真实的模拟黑洞分布。<details>
<summary>Abstract</summary>
Refractive Index Tomography is an inverse problem in which we seek to reconstruct a scene's 3D refractive field from 2D projected image measurements. The refractive field is not visible itself, but instead affects how the path of a light ray is continuously curved as it travels through space. Refractive fields appear across a wide variety of scientific applications, from translucent cell samples in microscopy to fields of dark matter bending light from faraway galaxies. This problem poses a unique challenge because the refractive field directly affects the path that light takes, making its recovery a non-linear problem. In addition, in contrast with traditional tomography, we seek to recover the refractive field using a projected image from only a single viewpoint by leveraging knowledge of light sources scattered throughout the medium. In this work, we introduce a method that uses a coordinate-based neural network to model the underlying continuous refractive field in a scene. We then use explicit modeling of rays' 3D spatial curvature to optimize the parameters of this network, reconstructing refractive fields with an analysis-by-synthesis approach. The efficacy of our approach is demonstrated by recovering refractive fields in simulation, and analyzing how recovery is affected by the light source distribution. We then test our method on a simulated dark matter mapping problem, where we recover the refractive field underlying a realistic simulated dark matter distribution.
</details>
<details>
<summary>摘要</summary>
《干涉度图像》是一种逆 проблеme 在干涉度图像中，我们希望从2D投影图像的测量中重construct 场景中的3D干涉场。干涉场不可见自身，但它会影响光束在空间中的曲线运动。干涉场在多种科学应用中出现，从微scopic 的透明细胞样本到远方 галакси的场景中的暗物质弯光。这个问题 pose 一种独特挑战，因为干涉场直接影响光束的路径，使其回归变为非线性问题。此外，在传统tomography 中，我们通过多个视点测量来重construct 干涉场，而我们在这里是通过单个视点测量来实现。在这个工作中，我们提出了一种基于坐标的神经网络来模型场景中的连续干涉场。然后，我们通过明确的3D空间曲线的计算来优化神经网络的参数，通过分析synthesis 的方法来重construct 干涉场。我们的方法的效果在仿真中进行了测试，并分析了灯源分布对回归的影响。最后，我们在一个模拟的黑 matter 映射问题中测试了我们的方法，并成功地重construct 黑 matter 的干涉场。
</details></li>
</ul>
<hr>
<h2 id="Video-Task-Decathlon-Unifying-Image-and-Video-Tasks-in-Autonomous-Driving"><a href="#Video-Task-Decathlon-Unifying-Image-and-Video-Tasks-in-Autonomous-Driving" class="headerlink" title="Video Task Decathlon: Unifying Image and Video Tasks in Autonomous Driving"></a>Video Task Decathlon: Unifying Image and Video Tasks in Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04422">http://arxiv.org/abs/2309.04422</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas E. Huang, Yifan Liu, Luc Van Gool, Fisher Yu</li>
<li>for: 本研究旨在探讨自动驾驶场景中多个多样化视觉任务的整合。</li>
<li>methods: 该研究使用了一种单一结构和单一参数的网络（VTDNet），通过任务间交互阶段来交换信息，实现多个任务的同时解决。</li>
<li>results: 与单任务网络相比，VTDNet在大多数任务上表现出色，仅使用20%的计算资源。<details>
<summary>Abstract</summary>
Performing multiple heterogeneous visual tasks in dynamic scenes is a hallmark of human perception capability. Despite remarkable progress in image and video recognition via representation learning, current research still focuses on designing specialized networks for singular, homogeneous, or simple combination of tasks. We instead explore the construction of a unified model for major image and video recognition tasks in autonomous driving with diverse input and output structures. To enable such an investigation, we design a new challenge, Video Task Decathlon (VTD), which includes ten representative image and video tasks spanning classification, segmentation, localization, and association of objects and pixels. On VTD, we develop our unified network, VTDNet, that uses a single structure and a single set of weights for all ten tasks. VTDNet groups similar tasks and employs task interaction stages to exchange information within and between task groups. Given the impracticality of labeling all tasks on all frames, and the performance degradation associated with joint training of many tasks, we design a Curriculum training, Pseudo-labeling, and Fine-tuning (CPF) scheme to successfully train VTDNet on all tasks and mitigate performance loss. Armed with CPF, VTDNet significantly outperforms its single-task counterparts on most tasks with only 20% overall computations. VTD is a promising new direction for exploring the unification of perception tasks in autonomous driving.
</details>
<details>
<summary>摘要</summary>
人类视觉能力的一个特征是同时完成多种不同类型的视觉任务在动态场景中。虽然图像和视频认知技术已经做出了很大的进步，但现在的研究仍然强调设计专门的网络来解决单一或同类型的任务。我们则是探索构建一个统一的模型来涵盖主要的图像和视频认知任务在自动驾驶中，并且输入和输出结构多样化。为了实现这种研究，我们设计了一个新的挑战——视频任务十项赛（VTD），这个挑战包括十种代表性的图像和视频任务，涵盖分类、 segmentation、 localization 和对象和像素的关系。在 VTD 中，我们开发了一个统一的网络——VTDNet，它使用单一的结构和单一的参数来实现所有十个任务。VTDNet 将相似任务分组，并在任务组之间进行交互来交换信息。由于实际上标注所有任务的所有帧是不实际的，以及多任务合并训练会导致性能下降，我们设计了一种学习环境、 Pseudo-labeling 和精度调整（CPF）的办法，以成功训练 VTDNet 在所有任务上，并将性能下降降到最低。与单任务网络相比，VTDNet 在大多数任务上表现出色，只需要20%的总计算资源。VTD 是自动驾驶视觉任务统一探索的一个有前途的新方向。
</details></li>
</ul>
<hr>
<h2 id="DeformToon3D-Deformable-3D-Toonification-from-Neural-Radiance-Fields"><a href="#DeformToon3D-Deformable-3D-Toonification-from-Neural-Radiance-Fields" class="headerlink" title="DeformToon3D: Deformable 3D Toonification from Neural Radiance Fields"></a>DeformToon3D: Deformable 3D Toonification from Neural Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04410">http://arxiv.org/abs/2309.04410</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/junzhezhang/DeformToon3D">https://github.com/junzhezhang/DeformToon3D</a></li>
<li>paper_authors: Junzhe Zhang, Yushi Lan, Shuai Yang, Fangzhou Hong, Quan Wang, Chai Kiat Yeo, Ziwei Liu, Chen Change Loy</li>
<li>for: 本研究旨在解决3D漫画化问题，即将艺术领域的样式应用到目标3D面部上，并保持原始GAN幂等空间的良好性。</li>
<li>methods: 我们提出了DeformToon3D方法，它是针对堆叠3D GAN的有效漫画化框架。我们将3D漫画化分解为geometry和texture材质化的子问题，以更好地保持原始GAN幂等空间。我们还提出了一种新的StyleField，它预测 conditional 3D变形以将真实空间NeRF调整到样式空间中。</li>
<li>results: 我们的方法可以实现高质量的3D漫画化，并且支持灵活的样式度控制和形状-文本ure-特有的样式交换。此外，我们可以高效地训练我们的模型，不需要任何实际的2D-3D训练对。<details>
<summary>Abstract</summary>
In this paper, we address the challenging problem of 3D toonification, which involves transferring the style of an artistic domain onto a target 3D face with stylized geometry and texture. Although fine-tuning a pre-trained 3D GAN on the artistic domain can produce reasonable performance, this strategy has limitations in the 3D domain. In particular, fine-tuning can deteriorate the original GAN latent space, which affects subsequent semantic editing, and requires independent optimization and storage for each new style, limiting flexibility and efficient deployment. To overcome these challenges, we propose DeformToon3D, an effective toonification framework tailored for hierarchical 3D GAN. Our approach decomposes 3D toonification into subproblems of geometry and texture stylization to better preserve the original latent space. Specifically, we devise a novel StyleField that predicts conditional 3D deformation to align a real-space NeRF to the style space for geometry stylization. Thanks to the StyleField formulation, which already handles geometry stylization well, texture stylization can be achieved conveniently via adaptive style mixing that injects information of the artistic domain into the decoder of the pre-trained 3D GAN. Due to the unique design, our method enables flexible style degree control and shape-texture-specific style swap. Furthermore, we achieve efficient training without any real-world 2D-3D training pairs but proxy samples synthesized from off-the-shelf 2D toonification models.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们讨论了三维渐化（3D toonification）问题，即将艺术领域的风格应用到目标三维face上，并保持具有渐化的geometry和Texture。虽然可以通过练化预训练的3D GAN来实现可理解的性能，但这种策略有一些限制。具体来说，练化可能会损害原始GAN latent space，影响后续的semantic editing，并需要独立的优化和存储每个新风格，限制了灵活性和高效的部署。为了解决这些挑战，我们提出了DeformToon3D，一种适合层次3D GAN的有效渐化框架。我们的方法将三维渐化分解为geometry和Texture渐化的子问题，以更好地保持原始latent space。具体来说，我们开发了一种名为StyleField的新型预测器，可以在Real-Space NeRF上预测conditional 3D deformation，以使geometry渐化适应风格空间。由于StyleField的形式，Texture渐化可以通过适应风格混合来实现，injects风格空间信息到预训练的3D GAN decoder中。由于独特的设计，我们的方法可以实现自适应风格度控制和形状特征特定的风格交换。此外，我们可以不使用任何真实世界2D-3D训练对，而是使用市面上的2D渐化模型生成的代理样本进行训练。
</details></li>
</ul>
<hr>
<h2 id="MaskDiffusion-Boosting-Text-to-Image-Consistency-with-Conditional-Mask"><a href="#MaskDiffusion-Boosting-Text-to-Image-Consistency-with-Conditional-Mask" class="headerlink" title="MaskDiffusion: Boosting Text-to-Image Consistency with Conditional Mask"></a>MaskDiffusion: Boosting Text-to-Image Consistency with Conditional Mask</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04399">http://arxiv.org/abs/2309.04399</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yupeng Zhou, Daquan Zhou, Zuo-Liang Zhu, Yaxing Wang, Qibin Hou, Jiashi Feng</li>
<li>for: 提高 diffusion 模型中文案与图像的匹配率</li>
<li>methods: 使用 adaptive mask 来改进 cross-modality 关系学习，从而更好地匹配文本 embedding 和图像特征</li>
<li>results: 与原始 diffusion 模型相比，MaskDiffusion 可以大幅提高文本-图像匹配率，而且计算负担几乎不变。<details>
<summary>Abstract</summary>
Recent advancements in diffusion models have showcased their impressive capacity to generate visually striking images. Nevertheless, ensuring a close match between the generated image and the given prompt remains a persistent challenge. In this work, we identify that a crucial factor leading to the text-image mismatch issue is the inadequate cross-modality relation learning between the prompt and the output image. To better align the prompt and image content, we advance the cross-attention with an adaptive mask, which is conditioned on the attention maps and the prompt embeddings, to dynamically adjust the contribution of each text token to the image features. This mechanism explicitly diminishes the ambiguity in semantic information embedding from the text encoder, leading to a boost of text-to-image consistency in the synthesized images. Our method, termed MaskDiffusion, is training-free and hot-pluggable for popular pre-trained diffusion models. When applied to the latent diffusion models, our MaskDiffusion can significantly improve the text-to-image consistency with negligible computation overhead compared to the original diffusion models.
</details>
<details>
<summary>摘要</summary>
最近的扩散模型进步有力地生成了视觉吸引人的图像。然而，确保生成图像与给定的提示保持close match仍然是一项棘手的挑战。在这项工作中，我们发现了一个关键因素导致文本-图像匹配问题的原因：在提取图像特征时，扩散模型缺乏文本和图像之间的跨Modal关系学习。为了更好地对准提示和图像内容，我们提出了一种基于适应面罩的跨注意力机制，该机制通过根据注意力地图和提示嵌入来动态调整每个文本符号对图像特征的贡献。这种机制明确地减少了文本编码器中嵌入的Semantic信息抖动，从而导致了文本-图像一致性的明显提高。我们称之为MaskDiffusion，它是训练 свобо和热插的，可以应用于流行的预训练扩散模型。当应用于凉 diffusion模型时，我们的MaskDiffusion可以显著提高文本-图像一致性，而且与原始扩散模型的计算负担几乎不变。
</details></li>
</ul>
<hr>
<h2 id="Language-Prompt-for-Autonomous-Driving"><a href="#Language-Prompt-for-Autonomous-Driving" class="headerlink" title="Language Prompt for Autonomous Driving"></a>Language Prompt for Autonomous Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04379">http://arxiv.org/abs/2309.04379</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wudongming97/prompt4driving">https://github.com/wudongming97/prompt4driving</a></li>
<li>paper_authors: Dongming Wu, Wencheng Han, Tiancai Wang, Yingfei Liu, Xiangyu Zhang, Jianbing Shen</li>
<li>for: 这篇论文是为了解决自动驾驶领域中使用自然语言提示驱动场景中的挑战，即缺乏配对的提示-实例数据。</li>
<li>methods: 该论文提出了第一个用于驾驶场景的对象中心语言提示集，名为NuPrompt，它扩展了Nuscenes数据集，并构建了35,367个语言描述，每个描述都对应5.3个 объек跟踪。</li>
<li>results: 该论文提出了一种基于Transformer的简单朴素模型，名为PromptTrack，并在NuPrompt上进行了实验，实验结果表明，PromptTrack在NuPrompt上表现出色。<details>
<summary>Abstract</summary>
A new trend in the computer vision community is to capture objects of interest following flexible human command represented by a natural language prompt. However, the progress of using language prompts in driving scenarios is stuck in a bottleneck due to the scarcity of paired prompt-instance data. To address this challenge, we propose the first object-centric language prompt set for driving scenes within 3D, multi-view, and multi-frame space, named NuPrompt. It expands Nuscenes dataset by constructing a total of 35,367 language descriptions, each referring to an average of 5.3 object tracks. Based on the object-text pairs from the new benchmark, we formulate a new prompt-based driving task, \ie, employing a language prompt to predict the described object trajectory across views and frames. Furthermore, we provide a simple end-to-end baseline model based on Transformer, named PromptTrack. Experiments show that our PromptTrack achieves impressive performance on NuPrompt. We hope this work can provide more new insights for the autonomous driving community. Dataset and Code will be made public at \href{https://github.com/wudongming97/Prompt4Driving}{https://github.com/wudongming97/Prompt4Driving}.
</details>
<details>
<summary>摘要</summary>
新趋势在计算机视觉社区是通过自然语言提示来捕捉对象 Interest的 flexible 人工命令。然而，使用语言提示在驾驶场景中的进展却被困在数据缺乏的瓶颈中。为解决这个挑战，我们提出了首个适用于驾驶场景的三维、多视图、多帧空间的对象-中心语言提示集，名为NuPrompt。它将Nuscenes数据集扩展到构建总共35,367个语言描述，每个描述都关联着5.3个对象跟踪。基于对象-文本对的新标准，我们提出了一个新的提示驱动任务，即使用语言提示来预测视图和帧中描述的对象轨迹。此外，我们还提供了一个简单的端到端基eline模型，基于Transformer，名为PromptTrack。实验表明，我们的PromptTrack在NuPrompt上表现出了很好的表现。我们希望这项工作能够为自动驾驶社区提供更多的新想法。数据集和代码将在\href{https://github.com/wudongming97/Prompt4Driving}{https://github.com/wudongming97/Prompt4Driving}上公开。
</details></li>
</ul>
<hr>
<h2 id="CNN-Injected-Transformer-for-Image-Exposure-Correction"><a href="#CNN-Injected-Transformer-for-Image-Exposure-Correction" class="headerlink" title="CNN Injected Transformer for Image Exposure Correction"></a>CNN Injected Transformer for Image Exposure Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04366">http://arxiv.org/abs/2309.04366</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rebeccaeexu/cit-ec">https://github.com/rebeccaeexu/cit-ec</a></li>
<li>paper_authors: Shuning Xu, Xiangyu Chen, Binbin Song, Jiantao Zhou</li>
<li>for:  corrected image exposure</li>
<li>methods:  CNN Injected Transformer (CIT) and carefully formulated loss functions</li>
<li>results:  outperforms state-of-the-art approaches in terms of both quantitative and qualitative metrics<details>
<summary>Abstract</summary>
Capturing images with incorrect exposure settings fails to deliver a satisfactory visual experience. Only when the exposure is properly set, can the color and details of the images be appropriately preserved. Previous exposure correction methods based on convolutions often produce exposure deviation in images as a consequence of the restricted receptive field of convolutional kernels. This issue arises because convolutions are not capable of capturing long-range dependencies in images accurately. To overcome this challenge, we can apply the Transformer to address the exposure correction problem, leveraging its capability in modeling long-range dependencies to capture global representation. However, solely relying on the window-based Transformer leads to visually disturbing blocking artifacts due to the application of self-attention in small patches. In this paper, we propose a CNN Injected Transformer (CIT) to harness the individual strengths of CNN and Transformer simultaneously. Specifically, we construct the CIT by utilizing a window-based Transformer to exploit the long-range interactions among different regions in the entire image. Within each CIT block, we incorporate a channel attention block (CAB) and a half-instance normalization block (HINB) to assist the window-based self-attention to acquire the global statistics and refine local features. In addition to the hybrid architecture design for exposure correction, we apply a set of carefully formulated loss functions to improve the spatial coherence and rectify potential color deviations. Extensive experiments demonstrate that our image exposure correction method outperforms state-of-the-art approaches in terms of both quantitative and qualitative metrics.
</details>
<details>
<summary>摘要</summary>
捕捉图像with incorrect exposure settings会导致视觉经验不满意。只有当曝光正确设置时，图像的颜色和细节才能正确保存。过去的曝光修正方法基于 convolution often produce exposure deviation in images as a consequence of the restricted receptive field of convolutional kernels. This issue arises because convolutions are not capable of capturing long-range dependencies in images accurately. To overcome this challenge, we can apply the Transformer to address the exposure correction problem, leveraging its capability in modeling long-range dependencies to capture global representation. However, solely relying on the window-based Transformer leads to visually disturbing blocking artifacts due to the application of self-attention in small patches. In this paper, we propose a CNN Injected Transformer (CIT) to harness the individual strengths of CNN and Transformer simultaneously. Specifically, we construct the CIT by utilizing a window-based Transformer to exploit the long-range interactions among different regions in the entire image. Within each CIT block, we incorporate a channel attention block (CAB) and a half-instance normalization block (HINB) to assist the window-based self-attention to acquire the global statistics and refine local features. In addition to the hybrid architecture design for exposure correction, we apply a set of carefully formulated loss functions to improve the spatial coherence and rectify potential color deviations. Extensive experiments demonstrate that our image exposure correction method outperforms state-of-the-art approaches in terms of both quantitative and qualitative metrics.
</details></li>
</ul>
<hr>
<h2 id="SSIG-A-Visually-Guided-Graph-Edit-Distance-for-Floor-Plan-Similarity"><a href="#SSIG-A-Visually-Guided-Graph-Edit-Distance-for-Floor-Plan-Similarity" class="headerlink" title="SSIG: A Visually-Guided Graph Edit Distance for Floor Plan Similarity"></a>SSIG: A Visually-Guided Graph Edit Distance for Floor Plan Similarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04357">http://arxiv.org/abs/2309.04357</a></li>
<li>repo_url: None</li>
<li>paper_authors: Casper van Engelenburg, Seyran Khademi, Jan van Gemert<br>for: 这 paper 是为了提出一种简单 yet effective 的 metric，用于衡量建筑底层平面图像之间的结构相似性，而不需要学习。methods: 这 paper 使用了 image 和 graph 距离来计算 structural similarity，并提出了一种基于 IoU 和 GED 的评价指标，称为 SSIG。results: 实验结果表明，使用 SSIG 可以获得类似于深度学习方法的结构相似性 Retrieval 结果，而且更加有效地比较建筑底层平面图像的结构相似性。<details>
<summary>Abstract</summary>
We propose a simple yet effective metric that measures structural similarity between visual instances of architectural floor plans, without the need for learning. Qualitatively, our experiments show that the retrieval results are similar to deeply learned methods. Effectively comparing instances of floor plan data is paramount to the success of machine understanding of floor plan data, including the assessment of floor plan generative models and floor plan recommendation systems. Comparing visual floor plan images goes beyond a sole pixel-wise visual examination and is crucially about similarities and differences in the shapes and relations between subdivisions that compose the layout. Currently, deep metric learning approaches are used to learn a pair-wise vector representation space that closely mimics the structural similarity, in which the models are trained on similarity labels that are obtained by Intersection-over-Union (IoU). To compensate for the lack of structural awareness in IoU, graph-based approaches such as Graph Matching Networks (GMNs) are used, which require pairwise inference for comparing data instances, making GMNs less practical for retrieval applications. In this paper, an effective evaluation metric for judging the structural similarity of floor plans, coined SSIG (Structural Similarity by IoU and GED), is proposed based on both image and graph distances. In addition, an efficient algorithm is developed that uses SSIG to rank a large-scale floor plan database. Code will be openly available.
</details>
<details>
<summary>摘要</summary>
我们提出一种简单 yet有效的度量，用于衡量建筑floor plan的结构相似性，无需学习。我们的实验表明，检索结果与深度学习方法相似。对于机器理解floor plan数据的成功，包括floor plan生成模型和floor plan推荐系统，都是重要的。 Comparing visual floor plan图像不仅是solely based on pixel-wise visual examination，更是关注 shapes和relations between subdivisions that compose the layout的相似性和差异。目前，深度度量学习方法是用于学习一个pair-wise vector representation space，以便closely mimic structural similarity，其中模型是通过Intersection-over-Union（IoU）获得对应的similarity labels。为了补做IoU中的结构不足，Graph-based approaches such as Graph Matching Networks (GMNs) 是使用的，但这些方法需要对数据实例进行对比，使得GMNs 在检索应用中不实用。在这篇论文中，一种有效的floor plan结构相似度度量，称为SSIG（Structural Similarity by IoU and GED），是基于图像和图distance的。此外，一种高效的算法是开发出来，用于排序大规模的floor plan数据库。代码将公开。
</details></li>
</ul>
<hr>
<h2 id="Mobile-V-MoEs-Scaling-Down-Vision-Transformers-via-Sparse-Mixture-of-Experts"><a href="#Mobile-V-MoEs-Scaling-Down-Vision-Transformers-via-Sparse-Mixture-of-Experts" class="headerlink" title="Mobile V-MoEs: Scaling Down Vision Transformers via Sparse Mixture-of-Experts"></a>Mobile V-MoEs: Scaling Down Vision Transformers via Sparse Mixture-of-Experts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04354">http://arxiv.org/abs/2309.04354</a></li>
<li>repo_url: None</li>
<li>paper_authors: Erik Daxberger, Floris Weers, Bowen Zhang, Tom Gunter, Ruoming Pang, Marcin Eichner, Michael Emmersberger, Yinfei Yang, Alexander Toshev, Xianzhi Du</li>
<li>for: 这个研究旨在使用罕发 Mixture-of-Experts 模型（MoE）来缩小 Computer Vision Transformers（ViT），以提高资源受限的视觉应用程序中的表现。</li>
<li>methods: 提议了一个简化的 Mobile Vision MoE 设计，将整个图像Routing 到专家中，以及一个稳定的 MoE 训练方法，使用超级类信息来导引路由器。</li>
<li>results: 经验表明，我们的罕发 Mobile Vision MoE 可以在 ImageNet-1k 上比 dense ViT 表现更好，例如 ViT-Tiny 模型的 Mobile V-MoE 比它的 dense 对应者高出3.39%。另外，对于仅有54M FLOPs 的视觉运算成本的 ViT Variant，我们的 MoE 可以提高4.66%。<details>
<summary>Abstract</summary>
Sparse Mixture-of-Experts models (MoEs) have recently gained popularity due to their ability to decouple model size from inference efficiency by only activating a small subset of the model parameters for any given input token. As such, sparse MoEs have enabled unprecedented scalability, resulting in tremendous successes across domains such as natural language processing and computer vision. In this work, we instead explore the use of sparse MoEs to scale-down Vision Transformers (ViTs) to make them more attractive for resource-constrained vision applications. To this end, we propose a simplified and mobile-friendly MoE design where entire images rather than individual patches are routed to the experts. We also propose a stable MoE training procedure that uses super-class information to guide the router. We empirically show that our sparse Mobile Vision MoEs (V-MoEs) can achieve a better trade-off between performance and efficiency than the corresponding dense ViTs. For example, for the ViT-Tiny model, our Mobile V-MoE outperforms its dense counterpart by 3.39% on ImageNet-1k. For an even smaller ViT variant with only 54M FLOPs inference cost, our MoE achieves an improvement of 4.66%.
</details>
<details>
<summary>摘要</summary>
低粒度混合专家模型（MoE）在最近几年内得到了广泛的关注，因为它可以将模型大小与输入Token的执行效率解耦开来，只有一小部分模型参数对于任何输入Token进行激活。这使得低粒度MoE在不同领域，如自然语言处理和计算机视觉等领域取得了无 precedent的缩放。在这种工作中，我们则是使用低粒度MoE来缩小视Transformers（ViTs），以使其更适合具有限制的视觉应用。为此，我们提出了简单化了的手持版MoE设计，其中整个图像而不是具体的补丁被 routed 到专家。我们还提出了稳定的MoE训练过程，该过程使用超类信息来引导路由。我们实验表明，我们的粒度 мобиLE Vision MoEs（V-MoEs）可以在性能和效率之间取得更好的平衡，比如对于 ViT-Tiny 模型，我们的手持 V-MoE 在 ImageNet-1k 上比其拥有相同执行成本的 dense ViT 提高3.39%。而对于具有仅 54M FLOPs 执行成本的 ViT 变体，我们的 MoE 提高4.66%。
</details></li>
</ul>
<hr>
<h2 id="Revealing-the-preference-for-correcting-separated-aberrations-in-joint-optic-image-design"><a href="#Revealing-the-preference-for-correcting-separated-aberrations-in-joint-optic-image-design" class="headerlink" title="Revealing the preference for correcting separated aberrations in joint optic-image design"></a>Revealing the preference for correcting separated aberrations in joint optic-image design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04342">http://arxiv.org/abs/2309.04342</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingwen Zhou, Shiqi Chen, Zheng Ren, Wenguan Zhang, Jiapu Yan, Huajun Feng, Qi Li, Yueting Chen</li>
<li>for: 本文旨在jointly设计光学系统和下游算法，以实现高效的复杂系统设计 such as smartphones和 дроны。</li>
<li>methods: 本文首先从光学设计的角度，描述了光学系统中的各种荷 aberrations。然后，提出了一种图像模拟系统，用于重现真实的拍摄过程。最后，提出了一种基于神经网络的 aberration correction 方法，并证明其超过了现有方法。</li>
<li>results: 实验表明，在jointly设计光学系统和下游算法时，应该优先 corrected  longitudinal chromatic aberration、lateral chromatic aberration、spherical aberration、field curvature 和 coma，而 astigmatism 则应该排在最后。基于这些 preference，可以实现10%的总轨道减少，并且具有更高的计算摄影质量。本文的优化思路为jointly设计复杂光学系统和下游算法提供了新的思路。<details>
<summary>Abstract</summary>
The joint design of the optical system and the downstream algorithm is a challenging and promising task. Due to the demand for balancing the global optimal of imaging systems and the computational cost of physical simulation, existing methods cannot achieve efficient joint design of complex systems such as smartphones and drones. In this work, starting from the perspective of the optical design, we characterize the optics with separated aberrations. Additionally, to bridge the hardware and software without gradients, an image simulation system is presented to reproduce the genuine imaging procedure of lenses with large field-of-views. As for aberration correction, we propose a network to perceive and correct the spatially varying aberrations and validate its superiority over state-of-the-art methods. Comprehensive experiments reveal that the preference for correcting separated aberrations in joint design is as follows: longitudinal chromatic aberration, lateral chromatic aberration, spherical aberration, field curvature, and coma, with astigmatism coming last. Drawing from the preference, a 10% reduction in the total track length of the consumer-level mobile phone lens module is accomplished. Moreover, this procedure spares more space for manufacturing deviations, realizing extreme-quality enhancement of computational photography. The optimization paradigm provides innovative insight into the practical joint design of sophisticated optical systems and post-processing algorithms.
</details>
<details>
<summary>摘要</summary>
合作设计光学系统和下游算法是一项挑战性较高且投资极大的任务。由于需要平衡全球优化图像系统和物理模拟计算成本，现有方法无法实现复杂系统 such as 智能手机和无人机的有效集成设计。在这种工作中，从光学设计的视角出发，我们 caracterize 光学器件为分离的荷量。此外，为了bridging 硬件和软件而无需梯度，我们提出了一种图像仿真系统，可以复制实际摄影过程中的镜头大 FOV 的真实摄影。在荷量修正方面，我们提议一种神经网络，可以感知并修正场景中的空间变化荷量，并证明其超过了当前方法的优势。经过广泛的实验，我们发现在修正分离荷量时的偏好顺序如下：Longitudinal Chromatic Aberration、Lateral Chromatic Aberration、Spherical Aberration、Field Curvature、Coma、Astigmatism，其中 Astigmatism 为最后一个。基于这种偏好，我们实现了Consumer-level 移动 phone 镜头模块的10% 总轨道减少。此外，这种过程还剩余了更多的生产偏移，实现了极高质量的计算摄影增强。我们的优化思路为实际复杂光学系统和后处理算法的集成设计带来了创新的视角。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Model-Fusion-for-Improved-License-Plate-Recognition"><a href="#Leveraging-Model-Fusion-for-Improved-License-Plate-Recognition" class="headerlink" title="Leveraging Model Fusion for Improved License Plate Recognition"></a>Leveraging Model Fusion for Improved License Plate Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04331">http://arxiv.org/abs/2309.04331</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rayson Laroca, Luiz A. Zanlorensi, Valter Estevam, Rodrigo Minetto, David Menotti</li>
<li>for: 本研究旨在填补多模型识别结果的缺失，探讨多个识别模型的结果结合可以提高识别精度。</li>
<li>methods: 本研究使用多种直观的方法进行结合，包括选择最有信心的预测和多数投票策略。</li>
<li>results: 实验结果表明，结合多个模型可以减少对特定数据集&#x2F;场景的表现下降的可能性。此外，结合基于速度的模型也是一个有效的策略，能够在满足一定的时间延迟的情况下提高识别精度。<details>
<summary>Abstract</summary>
License Plate Recognition (LPR) plays a critical role in various applications, such as toll collection, parking management, and traffic law enforcement. Although LPR has witnessed significant advancements through the development of deep learning, there has been a noticeable lack of studies exploring the potential improvements in results by fusing the outputs from multiple recognition models. This research aims to fill this gap by investigating the combination of up to 12 different models using straightforward approaches, such as selecting the most confident prediction or employing majority vote-based strategies. Our experiments encompass a wide range of datasets, revealing substantial benefits of fusion approaches in both intra- and cross-dataset setups. Essentially, fusing multiple models reduces considerably the likelihood of obtaining subpar performance on a particular dataset/scenario. We also found that combining models based on their speed is an appealing approach. Specifically, for applications where the recognition task can tolerate some additional time, though not excessively, an effective strategy is to combine 4-6 models. These models may not be the most accurate individually, but their fusion strikes an optimal balance between accuracy and speed.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="AMLP-Adaptive-Masking-Lesion-Patches-for-Self-supervised-Medical-Image-Segmentation"><a href="#AMLP-Adaptive-Masking-Lesion-Patches-for-Self-supervised-Medical-Image-Segmentation" class="headerlink" title="AMLP:Adaptive Masking Lesion Patches for Self-supervised Medical Image Segmentation"></a>AMLP:Adaptive Masking Lesion Patches for Self-supervised Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04312">http://arxiv.org/abs/2309.04312</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangtao Wang, Ruizhi Wang, Jie Zhou, Thomas Lukasiewicz, Zhenghua Xu</li>
<li>for: 这个论文是为了解决自主指定的医学图像分割问题，即使用自主掩码模型在医学图像上进行学习。</li>
<li>methods: 该论文提出了一种新的自主掩码医学图像分割框架，称为自适应掩码病变块（AMLP）。该框架包括一种掩码选择策略（MPS），用于确定和学习含病变块的块。此外，该论文还引入了一种注意力重构损失（ARL）和一种类别一致损失（CCL），以提高病变块的准确性和分类精度。</li>
<li>results: 根据两个医学图像分割数据集的实验结果，AMLP在自主掩码模型中的性能明显高于现有的自主方法。这些策略有效地解决了在医学图像上应用自主掩码模型的限制，并且能够捕捉病变块的细节，这些细节是分割任务中非常重要的。<details>
<summary>Abstract</summary>
Self-supervised masked image modeling has shown promising results on natural images. However, directly applying such methods to medical images remains challenging. This difficulty stems from the complexity and distinct characteristics of lesions compared to natural images, which impedes effective representation learning. Additionally, conventional high fixed masking ratios restrict reconstructing fine lesion details, limiting the scope of learnable information. To tackle these limitations, we propose a novel self-supervised medical image segmentation framework, Adaptive Masking Lesion Patches (AMLP). Specifically, we design a Masked Patch Selection (MPS) strategy to identify and focus learning on patches containing lesions. Lesion regions are scarce yet critical, making their precise reconstruction vital. To reduce misclassification of lesion and background patches caused by unsupervised clustering in MPS, we introduce an Attention Reconstruction Loss (ARL) to focus on hard-to-reconstruct patches likely depicting lesions. We further propose a Category Consistency Loss (CCL) to refine patch categorization based on reconstruction difficulty, strengthening distinction between lesions and background. Moreover, we develop an Adaptive Masking Ratio (AMR) strategy that gradually increases the masking ratio to expand reconstructible information and improve learning. Extensive experiments on two medical segmentation datasets demonstrate AMLP's superior performance compared to existing self-supervised approaches. The proposed strategies effectively address limitations in applying masked modeling to medical images, tailored to capturing fine lesion details vital for segmentation tasks.
</details>
<details>
<summary>摘要</summary>
自我监督遮盲图像模型在自然图像上显示了扎实的成果。然而，直接将这些方法应用到医学图像仍然是一项挑战。这种挑战的原因在于医学图像中的病变特征更加复杂和特殊，使得学习有效的表征变得困难。另外，传统的高固定遮盲率限制了修剪细小病变细节，导致学习的范围受限。为解决这些限制，我们提出了一种新的自我监督医学图像分割框架，即适应遮盲病变裂片（AMLP）。特别是，我们设计了一种遮盲裂片选择策略（MPS），以确定和专注于包含病变的裂片进行学习。病变区域scarce yet critical，需要精准重建。为了避免由自动归类所引起的病变和背景裂片的混淆，我们引入了一种注意力重建损失（ARL），以注意精准重建病变裂片。此外，我们还提出了一种类别一致损失（CCL），以根据重建难度进一步划分病变和背景裂片，强化病变和背景之间的分别。此外，我们还开发了一种适应遮盲率策略（AMR），以逐渐增加遮盲率，扩大可重建信息，提高学习。我们对医学图像分割任务中的两个数据集进行了广泛的实验，并证明AMLP在自我监督方法中表现出色，与现有的自我监督方法相比。我们的提案有效地解决了应用遮盲模型到医学图像的限制，适应捕捉病变细节，这些细节对分割任务至关重要。
</details></li>
</ul>
<hr>
<h2 id="Have-We-Ever-Encountered-This-Before-Retrieving-Out-of-Distribution-Road-Obstacles-from-Driving-Scenes"><a href="#Have-We-Ever-Encountered-This-Before-Retrieving-Out-of-Distribution-Road-Obstacles-from-Driving-Scenes" class="headerlink" title="Have We Ever Encountered This Before? Retrieving Out-of-Distribution Road Obstacles from Driving Scenes"></a>Have We Ever Encountered This Before? Retrieving Out-of-Distribution Road Obstacles from Driving Scenes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04302">http://arxiv.org/abs/2309.04302</a></li>
<li>repo_url: None</li>
<li>paper_authors: Youssef Shoeb, Robin Chan, Gesina Schwalbe, Azarm Nowzard, Fatma Güney, Hanno Gottschalk</li>
<li>for: 本研究旨在提供一种基于文本查询的外部数据采集方法，以满足自动驾驶系统中的协同Debugging需求。</li>
<li>methods: 该方法基于最新的OoD分割和多Modal基础模型，可以快速从无标注视频中提取安全关键场景，并通过文本查询来检索相似的场景。</li>
<li>results: 该方法可以快速和高效地提取与OoD道路障碍相关的场景，并提供一种基于文本查询的novel Approach来检索这些场景。<details>
<summary>Abstract</summary>
In the life cycle of highly automated systems operating in an open and dynamic environment, the ability to adjust to emerging challenges is crucial. For systems integrating data-driven AI-based components, rapid responses to deployment issues require fast access to related data for testing and reconfiguration. In the context of automated driving, this especially applies to road obstacles that were not included in the training data, commonly referred to as out-of-distribution (OoD) road obstacles. Given the availability of large uncurated recordings of driving scenes, a pragmatic approach is to query a database to retrieve similar scenarios featuring the same safety concerns due to OoD road obstacles. In this work, we extend beyond identifying OoD road obstacles in video streams and offer a comprehensive approach to extract sequences of OoD road obstacles using text queries, thereby proposing a way of curating a collection of OoD data for subsequent analysis. Our proposed method leverages the recent advances in OoD segmentation and multi-modal foundation models to identify and efficiently extract safety-relevant scenes from unlabeled videos. We present a first approach for the novel task of text-based OoD object retrieval, which addresses the question ''Have we ever encountered this before?''.
</details>
<details>
<summary>摘要</summary>
生命周期中高度自动化系统在开放动态环境中的适应能力是关键。具有数据驱动AI组件的系统在部署问题上需要快速访问相关数据进行测试和重新配置。在自动驾驶上特别是，对于没有包含在训练数据中的外部道路障碍（OoD），快速响应是非常重要。由于有大量未经整理的驾驶场景录像，我们可以通过查询数据库来检索类似的场景，并且可以使用文本查询来提取OoD道路障碍序列。在这种情况下，我们不仅可以识别OoD道路障碍在视频流中，还可以提供一种抽象CURATE OoD数据集，以便进行后续分析。我们的提议方法基于最近的OoD分割和多Modal基础模型，可以快速和有效地从未标注的视频中提取安全相关的场景。我们还提出了一种新的任务：文本基本对象重 Retrieval，可以回答问题“我们之前有否遇到过这个?”。
</details></li>
</ul>
<hr>
<h2 id="How-Can-We-Tame-the-Long-Tail-of-Chest-X-ray-Datasets"><a href="#How-Can-We-Tame-the-Long-Tail-of-Chest-X-ray-Datasets" class="headerlink" title="How Can We Tame the Long-Tail of Chest X-ray Datasets?"></a>How Can We Tame the Long-Tail of Chest X-ray Datasets?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04293">http://arxiv.org/abs/2309.04293</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arsh Verma</li>
<li>for: 用于自动推断胸部X射线图像中的各种畸形。</li>
<li>methods: 使用深度学习模型来学习独立的特征，解决多标签和少数畸形问题。</li>
<li>results: 提出一种使用初始化更加近似于目标数据集的方法，可以帮助提高模型性能，并且可以轻松扩展到新的标签。<details>
<summary>Abstract</summary>
Chest X-rays (CXRs) are a medical imaging modality that is used to infer a large number of abnormalities. While it is hard to define an exhaustive list of these abnormalities, which may co-occur on a chest X-ray, few of them are quite commonly observed and are abundantly represented in CXR datasets used to train deep learning models for automated inference. However, it is challenging for current models to learn independent discriminatory features for labels that are rare but may be of high significance. Prior works focus on the combination of multi-label and long tail problems by introducing novel loss functions or some mechanism of re-sampling or re-weighting the data. Instead, we propose that it is possible to achieve significant performance gains merely by choosing an initialization for a model that is closer to the domain of the target dataset. This method can complement the techniques proposed in existing literature, and can easily be scaled to new labels. Finally, we also examine the veracity of synthetically generated data to augment the tail labels and analyse its contribution to improving model performance.
</details>
<details>
<summary>摘要</summary>
胸部X光图（CXR）是医学影像模式，用于推断许多不正常情况。尽管难以列举完整的不正常情况列表，这些情况可能在胸部X光图上同时出现，但一些非常常见，并且在使用深度学习模型自动推断时广泛存在于CXR数据集中。然而，当前的模型很难学习独立的特征来标识罕见的标签，它们可能具有高度的重要性。先前的工作将焦点放在多标签和长尾问题的组合上，通过引入新的损失函数或数据重新排序机制来解决。而我们则提议，可以通过选择更加适应目标数据集的初始化方法来实现显著的性能提升。这种方法可以补充现有文献中的技术，并可以轻松扩展到新的标签。此外，我们还研究了增强尾标签的合成数据的真实性，并分析其对模型性能的贡献。
</details></li>
</ul>
<hr>
<h2 id="The-Power-of-Sound-TPoS-Audio-Reactive-Video-Generation-with-Stable-Diffusion"><a href="#The-Power-of-Sound-TPoS-Audio-Reactive-Video-Generation-with-Stable-Diffusion" class="headerlink" title="The Power of Sound (TPoS): Audio Reactive Video Generation with Stable Diffusion"></a>The Power of Sound (TPoS): Audio Reactive Video Generation with Stable Diffusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04509">http://arxiv.org/abs/2309.04509</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yujin Jeong, Wonjeong Ryoo, Seunghyun Lee, Dabin Seo, Wonmin Byeon, Sangpil Kim, Jinkyu Kim</li>
<li>for: 这篇论文主要针对的是音频到视频生成技术，具体来说是使用音频输入将 temporal semantics 和 magnitude 纳入视频生成中，以生成响应音频的视频内容。</li>
<li>methods: 该模型使用了稳定扩散模型，将文本语义信息与音频编码器的顺序编码器结合，以生成视频帧。</li>
<li>results: 该方法在多个任务上表现出色，与当前领域的状态Of-the-art技术进行比较，并提供了更多的示例，可以在 <a target="_blank" rel="noopener" href="https://ku-vai.github.io/TPoS/">https://ku-vai.github.io/TPoS/</a> 中找到。<details>
<summary>Abstract</summary>
In recent years, video generation has become a prominent generative tool and has drawn significant attention. However, there is little consideration in audio-to-video generation, though audio contains unique qualities like temporal semantics and magnitude. Hence, we propose The Power of Sound (TPoS) model to incorporate audio input that includes both changeable temporal semantics and magnitude. To generate video frames, TPoS utilizes a latent stable diffusion model with textual semantic information, which is then guided by the sequential audio embedding from our pretrained Audio Encoder. As a result, this method produces audio reactive video contents. We demonstrate the effectiveness of TPoS across various tasks and compare its results with current state-of-the-art techniques in the field of audio-to-video generation. More examples are available at https://ku-vai.github.io/TPoS/
</details>
<details>
<summary>摘要</summary>
Recently, video generation has become a prominent generative tool and has attracted significant attention. However, there is little consideration in audio-to-video generation, although audio contains unique qualities such as temporal semantics and magnitude. Therefore, we propose The Power of Sound (TPoS) model to incorporate audio input that includes both changeable temporal semantics and magnitude. To generate video frames, TPoS utilizes a latent stable diffusion model with textual semantic information, which is then guided by the sequential audio embedding from our pretrained Audio Encoder. As a result, this method produces audio reactive video contents. We demonstrate the effectiveness of TPoS across various tasks and compare its results with current state-of-the-art techniques in the field of audio-to-video generation. More examples are available at https://ku-vai.github.io/TPoS/.Here's the translation in Traditional Chinese:近年来，影片生成技术成为了主要的生成工具，吸引了广泛的关注。然而，对于音频至影片生成的考虑，几乎没有，尽管音频具有时间 semantics 和强度等独特特性。因此，我们提出了 The Power of Sound (TPoS) 模型，将音频输入包括了可变的时间 semantics 和强度。将 TPoS 模型应用于生成影片帧，使用了稳定的扩散模型，并将文本内容与影片帧的预先训练 Audio Encoder 进行组合。因此，这种方法可以生成对音频有应答的影片内容。我们在不同的任务中认为 TPoS 的效果，并与现有的音频至影片生成技术进行比较。更多的例子可以在 <https://ku-vai.github.io/TPoS/> 网站上找到。
</details></li>
</ul>
<hr>
<h2 id="Towards-Practical-Capture-of-High-Fidelity-Relightable-Avatars"><a href="#Towards-Practical-Capture-of-High-Fidelity-Relightable-Avatars" class="headerlink" title="Towards Practical Capture of High-Fidelity Relightable Avatars"></a>Towards Practical Capture of High-Fidelity Relightable Avatars</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04247">http://arxiv.org/abs/2309.04247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haotian Yang, Mingwu Zheng, Wanquan Feng, Haibin Huang, Yu-Kun Lai, Pengfei Wan, Zhongyuan Wang, Chongyang Ma</li>
<li>for: 高精度3D人物捕捉和重建</li>
<li>methods: 使用动态图像序列和变化灯光条件进行训练，实现真实的照明和实时动画</li>
<li>results: 提供了一种高质量的捕捉和重建方法，可以在多种场景中实现真实的照明和动画效果<details>
<summary>Abstract</summary>
In this paper, we propose a novel framework, Tracking-free Relightable Avatar (TRAvatar), for capturing and reconstructing high-fidelity 3D avatars. Compared to previous methods, TRAvatar works in a more practical and efficient setting. Specifically, TRAvatar is trained with dynamic image sequences captured in a Light Stage under varying lighting conditions, enabling realistic relighting and real-time animation for avatars in diverse scenes. Additionally, TRAvatar allows for tracking-free avatar capture and obviates the need for accurate surface tracking under varying illumination conditions. Our contributions are two-fold: First, we propose a novel network architecture that explicitly builds on and ensures the satisfaction of the linear nature of lighting. Trained on simple group light captures, TRAvatar can predict the appearance in real-time with a single forward pass, achieving high-quality relighting effects under illuminations of arbitrary environment maps. Second, we jointly optimize the facial geometry and relightable appearance from scratch based on image sequences, where the tracking is implicitly learned. This tracking-free approach brings robustness for establishing temporal correspondences between frames under different lighting conditions. Extensive qualitative and quantitative experiments demonstrate that our framework achieves superior performance for photorealistic avatar animation and relighting.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的框架，即 Tracking-free Relightable Avatar（TRAvatar），用于捕捉和重建高质量的3D人物。相比前方法，TRAvatar在更实用和高效的设置下工作。具体来说，TRAvatar通过在不同照明条件下捕捉的动态图像序列进行训练，使得人物在多样化场景中的动画和重新照明得到了真实的渲染。此外，TRAvatar允许无需准确的表面跟踪，从而消除了对不同照明条件下的表面跟踪的需求。我们的贡献有两个方面：首先，我们提出了一种新的网络架构，该架构直接基于和确保光线的线性性。通过训练简单的群组照明 Captures，TRAvatar可以在实时下一步逻辑执行，实现高质量的重新照明效果下环境图像中的不同照明条件下。其次，我们将人物的面部几何和可重新照明的外观从头开始，基于图像序列进行 JOINT 优化。这种无需跟踪的方法带来了在不同照明条件下建立 temporales 匹配的稳定性。我们的框架在实际和量化的实验中都达到了高质量的人物动画和重新照明的表现。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Gaze-aware-Contrastive-Learning-with-Subject-specific-Condition"><a href="#Unsupervised-Gaze-aware-Contrastive-Learning-with-Subject-specific-Condition" class="headerlink" title="Unsupervised Gaze-aware Contrastive Learning with Subject-specific Condition"></a>Unsupervised Gaze-aware Contrastive Learning with Subject-specific Condition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04506">http://arxiv.org/abs/2309.04506</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lingyu Du, Xucong Zhang, Guohao Lan</li>
<li>for: 提高出现在多个 gaze 数据集上的 gaze 估计性能，使用一个通用的摄像头作为输入设备。</li>
<li>methods: 提出 ConGaze 框架，利用无标注的脸部图像学习无关Subject的 gaze-aware 表示，通过对 gaze-specific 数据增强和subject-conditional projection module来保持 gaze-semantic 特征和眼神一致性。</li>
<li>results: ConGaze 在三个公共 gaze 估计数据集上比现有的无监督学习解决方案提高了6.7%到22.5%，并在跨数据集评估中提高了15.1%到24.6%。<details>
<summary>Abstract</summary>
Appearance-based gaze estimation has shown great promise in many applications by using a single general-purpose camera as the input device. However, its success is highly depending on the availability of large-scale well-annotated gaze datasets, which are sparse and expensive to collect. To alleviate this challenge we propose ConGaze, a contrastive learning-based framework that leverages unlabeled facial images to learn generic gaze-aware representations across subjects in an unsupervised way. Specifically, we introduce the gaze-specific data augmentation to preserve the gaze-semantic features and maintain the gaze consistency, which are proven to be crucial for effective contrastive gaze representation learning. Moreover, we devise a novel subject-conditional projection module that encourages a share feature extractor to learn gaze-aware and generic representations. Our experiments on three public gaze estimation datasets show that ConGaze outperforms existing unsupervised learning solutions by 6.7% to 22.5%; and achieves 15.1% to 24.6% improvement over its supervised learning-based counterpart in cross-dataset evaluations.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本到简化中文。<</SYS>>应用基于的 gaze 估计已经在许多应用程序中显示出了很大的搭配性，只使用一个通用的摄像头作为输入设备。然而，其成功受到大规模、有良好标注的 gaze 数据集的可用性的限制。为了解决这个挑战，我们提出了 ConGaze，一个基于对比学习的框架，利用无标注的脸部图像来学习不同人Subject中的通用 gaze-aware 表示。specifically，我们引入了 gaze-specific 数据增强技术来保持 gaze-semantic 特征和维护 gaze 一致性，这些特征被证明是对有效对比 gaze 表示学习的关键。此外，我们设计了一个新的 subject-conditional projection module，以便一个共享特征提取器来学习 gaze-aware 和通用表示。我们在三个公共 gaze 估计数据集上进行了实验，结果显示，ConGaze 在对比学习解决方案上出现了6.7%到22.5%的提升，并在跨数据集评估中达到15.1%到24.6%的提升。
</details></li>
</ul>
<hr>
<h2 id="FIVA-Facial-Image-and-Video-Anonymization-and-Anonymization-Defense"><a href="#FIVA-Facial-Image-and-Video-Anonymization-and-Anonymization-Defense" class="headerlink" title="FIVA: Facial Image and Video Anonymization and Anonymization Defense"></a>FIVA: Facial Image and Video Anonymization and Anonymization Defense</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04228">http://arxiv.org/abs/2309.04228</a></li>
<li>repo_url: None</li>
<li>paper_authors: Felix Rosberg, Eren Erdal Aksoy, Cristofer Englund, Fernando Alonso-Fernandez</li>
<li>for: 这个论文旨在提出一种新的面部匿名化方法，以保护个人隐私。</li>
<li>methods: 这个方法使用了建议的身份追踪和强大的匿名化技术，以确保面部匿名化能够一致性地运行在帧中，并且可以抵挡重建攻击。</li>
<li>results: 这个方法可以确保0个真阳性，false acceptance rate为0.001，并且可以实现面部匿名化和脸部替换。<details>
<summary>Abstract</summary>
In this paper, we present a new approach for facial anonymization in images and videos, abbreviated as FIVA. Our proposed method is able to maintain the same face anonymization consistently over frames with our suggested identity-tracking and guarantees a strong difference from the original face. FIVA allows for 0 true positives for a false acceptance rate of 0.001. Our work considers the important security issue of reconstruction attacks and investigates adversarial noise, uniform noise, and parameter noise to disrupt reconstruction attacks. In this regard, we apply different defense and protection methods against these privacy threats to demonstrate the scalability of FIVA. On top of this, we also show that reconstruction attack models can be used for detection of deep fakes. Last but not least, we provide experimental results showing how FIVA can even enable face swapping, which is purely trained on a single target image.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的面部匿名技术，简称为FIVA。我们的提议方法可以保持面部匿名的一致性在帧内，并且可以 garantuee a strong difference from the original face。FIVA 可以保证0个真正的正确率，false acceptance rate 为0.001。我们的工作考虑了重要的安全问题，包括重建攻击，并对不同类型的随机噪声进行了 investigate。为了恢复随机噪声的攻击，我们应用了不同的防御和保护方法。此外，我们还证明了可以使用重建攻击模型来检测深伪。最后，我们提供了实验结果，证明FIVA 可以实现面部交换，只需要单个目标图像进行培训。
</details></li>
</ul>
<hr>
<h2 id="Long-Range-Correlation-Supervision-for-Land-Cover-Classification-from-Remote-Sensing-Images"><a href="#Long-Range-Correlation-Supervision-for-Land-Cover-Classification-from-Remote-Sensing-Images" class="headerlink" title="Long-Range Correlation Supervision for Land-Cover Classification from Remote Sensing Images"></a>Long-Range Correlation Supervision for Land-Cover Classification from Remote Sensing Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04225">http://arxiv.org/abs/2309.04225</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dawen Yu, Shunping Ji<br>for:这篇论文的目的是提出一种基于深度学习的陆地覆盖分类方法，以优化大型遥感图像中的远距离相关性模型。methods:该方法使用了一种名为超级vised长距离相关网络（SLCNet），它通过在批处理中使用类别一致性信息来directly supervise the long-range dependency modeling。此外，该方法还引入了一个辅助的自适应感知场特征提取模块，以Capture finely detailed feature representations for multi-size objects in multi-scale remote sensing images。results:对于三个遥感数据集，SLCNet achieved state-of-the-art performance compared with advanced segmentation methods from computer vision, medicine, and remote sensing communities。<details>
<summary>Abstract</summary>
Long-range dependency modeling has been widely considered in modern deep learning based semantic segmentation methods, especially those designed for large-size remote sensing images, to compensate the intrinsic locality of standard convolutions. However, in previous studies, the long-range dependency, modeled with an attention mechanism or transformer model, has been based on unsupervised learning, instead of explicit supervision from the objective ground truth. In this paper, we propose a novel supervised long-range correlation method for land-cover classification, called the supervised long-range correlation network (SLCNet), which is shown to be superior to the currently used unsupervised strategies. In SLCNet, pixels sharing the same category are considered highly correlated and those having different categories are less relevant, which can be easily supervised by the category consistency information available in the ground truth semantic segmentation map. Under such supervision, the recalibrated features are more consistent for pixels of the same category and more discriminative for pixels of other categories, regardless of their proximity. To complement the detailed information lacking in the global long-range correlation, we introduce an auxiliary adaptive receptive field feature extraction module, parallel to the long-range correlation module in the encoder, to capture finely detailed feature representations for multi-size objects in multi-scale remote sensing images. In addition, we apply multi-scale side-output supervision and a hybrid loss function as local and global constraints to further boost the segmentation accuracy. Experiments were conducted on three remote sensing datasets. Compared with the advanced segmentation methods from the computer vision, medicine, and remote sensing communities, the SLCNet achieved a state-of-the-art performance on all the datasets.
</details>
<details>
<summary>摘要</summary>
现代深度学习基于语义 segmentation 方法中，远程依赖关系模型已经广泛应用，特别是针对大型远程感知图像。然而，在前一些研究中，远程依赖关系，通过注意力机制或 transformer 模型进行模型，都是基于无监督学习。在这篇论文中，我们提出了一种新的监督性远程相关方法，called SLCNet，可以在土地覆盖分类中提高准确率。在 SLCNet 中，与同一类别的像素视为高度相关，与不同类别的像素视为不相关，这可以通过地图中的类别一致信息进行监督。由于这种监督，重调的特征更加一致于同类别的像素，更加突出不同类别的像素，不管它们的距离。为了补充全局远程相关缺失的细节信息，我们引入了一个辅助适应性识别场FeatureEXTRACT模块，并行于远程相关模块在编码器中。此外，我们还应用多尺度侧输出监督和混合损失函数作为本地和全局约束，以进一步提高分类精度。在三个远程感知数据集上进行了实验。与现代分类方法（计算机视觉、医学和远程感知社区）相比，SLCNet 在所有数据集上达到了状态的表现。
</details></li>
</ul>
<hr>
<h2 id="Score-PA-Score-based-3D-Part-Assembly"><a href="#Score-PA-Score-based-3D-Part-Assembly" class="headerlink" title="Score-PA: Score-based 3D Part Assembly"></a>Score-PA: Score-based 3D Part Assembly</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04220">http://arxiv.org/abs/2309.04220</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/j-f-cheng/score-pa_score-based-3d-part-assembly">https://github.com/j-f-cheng/score-pa_score-based-3d-part-assembly</a></li>
<li>paper_authors: Junfeng Cheng, Mingdong Wu, Ruiyuan Zhang, Guanqi Zhan, Chao Wu, Hao Dong</li>
<li>for: 本研究旨在提出一种基于生成模型的3D部件组装方法，以解决自主3D部件组装问题在机器人和3D计算机视觉领域中的挑战。</li>
<li>methods: 本文提出了一种名为Score-based 3D Part Assembly（Score-PA）框架，用于3D部件组装。此外，我们还提出了一种叫做快速预测器-修正器抽象器（FPC）算法，用于加速框架中的采样过程。</li>
<li>results: 我们通过了多种评价指标来评估组装质量和多样性，并发现我们的算法在比较现有状态艺术方法时表现出色，得到了更好的结果。<details>
<summary>Abstract</summary>
Autonomous 3D part assembly is a challenging task in the areas of robotics and 3D computer vision. This task aims to assemble individual components into a complete shape without relying on predefined instructions. In this paper, we formulate this task from a novel generative perspective, introducing the Score-based 3D Part Assembly framework (Score-PA) for 3D part assembly. Knowing that score-based methods are typically time-consuming during the inference stage. To address this issue, we introduce a novel algorithm called the Fast Predictor-Corrector Sampler (FPC) that accelerates the sampling process within the framework. We employ various metrics to assess assembly quality and diversity, and our evaluation results demonstrate that our algorithm outperforms existing state-of-the-art approaches. We release our code at https://github.com/J-F-Cheng/Score-PA_Score-based-3D-Part-Assembly.
</details>
<details>
<summary>摘要</summary>
自主三维部件组装是机器人和三维计算机视觉领域中的一项挑战性任务。这个任务的目标是将个体部件组装成完整的形状，不依赖于预定的指令。在这篇论文中，我们从一种新的生成方式出发，提出了Score-based 3D Part Assembly框架（Score-PA），用于三维部件组装。因为分数基本方法通常在推理阶段相对耗时，为了解决这个问题，我们提出了一种新的算法叫做快速预测器-修正器抽象器（FPC），它加速了Score-PA框架中的采样过程。我们使用了多种指标来评估组装质量和多样性，我们的评估结果表明，我们的算法在现有状态的方法上表现出色。我们在https://github.com/J-F-Cheng/Score-PA_Score-based-3D-Part-Assembly上分享了我们的代码。
</details></li>
</ul>
<hr>
<h2 id="SegmentAnything-helps-microscopy-images-based-automatic-and-quantitative-organoid-detection-and-analysis"><a href="#SegmentAnything-helps-microscopy-images-based-automatic-and-quantitative-organoid-detection-and-analysis" class="headerlink" title="SegmentAnything helps microscopy images based automatic and quantitative organoid detection and analysis"></a>SegmentAnything helps microscopy images based automatic and quantitative organoid detection and analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04190">http://arxiv.org/abs/2309.04190</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiaodanxing/sam4organoid">https://github.com/xiaodanxing/sam4organoid</a></li>
<li>paper_authors: Xiaodan Xing, Chunling Tang, Yunzhe Guo, Nicholas Kurniawan, Guang Yang</li>
<li>for: studying organ development, drug discovery, and toxicity assessment</li>
<li>methods: leveraging SegmentAnything for precise demarcation of individual organoids, and introducing a set of morphological properties for quantitative analysis</li>
<li>results: close alignment with manual organoid detection and measurement, demonstrating the effectiveness of the proposed method in accelerating organoid morphology analysis<details>
<summary>Abstract</summary>
Organoids are self-organized 3D cell clusters that closely mimic the architecture and function of in vivo tissues and organs. Quantification of organoid morphology helps in studying organ development, drug discovery, and toxicity assessment. Recent microscopy techniques provide a potent tool to acquire organoid morphology features, but manual image analysis remains a labor and time-intensive process. Thus, this paper proposes a comprehensive pipeline for microscopy analysis that leverages the SegmentAnything to precisely demarcate individual organoids. Additionally, we introduce a set of morphological properties, including perimeter, area, radius, non-smoothness, and non-circularity, allowing researchers to analyze the organoid structures quantitatively and automatically. To validate the effectiveness of our approach, we conducted tests on bright-field images of human induced pluripotent stem cells (iPSCs) derived neural-epithelial (NE) organoids. The results obtained from our automatic pipeline closely align with manual organoid detection and measurement, showcasing the capability of our proposed method in accelerating organoids morphology analysis.
</details>
<details>
<summary>摘要</summary>
organoids 是自组织的3D细胞群，具有在 vivo 组织中的结构和功能的高度相似性。量化 organoid 形态可以帮助研究器官发展、药物探索和毒性评估。现有的微镜技术为 organoid 形态特征的获取提供了强大的工具，但是手动图像分析仍然是一项劳动和时间耗费的过程。因此，这篇论文提出了一个完整的微镜分析管线，利用 SegmentAnything 精准地界定个体 organoid。此外，我们还引入了一组形态特征，包括周长、面积、半径、不整形和不圆形，使研究人员可以对 organoid 结构进行量化和自动化的分析。为验证我们的方法的有效性，我们对人类干细胞 derived neural-epithelial（NE） organoids 的明亮场图进行了测试。结果表明，我们的自动化管线与手动图像分析结果高度相似，这表明了我们提出的方法在加速 organoid 形态分析方面的能力。
</details></li>
</ul>
<hr>
<h2 id="Stereo-Matching-in-Time-100-FPS-Video-Stereo-Matching-for-Extended-Reality"><a href="#Stereo-Matching-in-Time-100-FPS-Video-Stereo-Matching-for-Extended-Reality" class="headerlink" title="Stereo Matching in Time: 100+ FPS Video Stereo Matching for Extended Reality"></a>Stereo Matching in Time: 100+ FPS Video Stereo Matching for Extended Reality</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04183">http://arxiv.org/abs/2309.04183</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziang Cheng, Jiayu Yang, Hongdong Li</li>
<li>for: 这篇论文主要是为了解决现场掌上设备上的实时深度推断问题，以提高现场扩展实际（XR）应用的性能。</li>
<li>methods: 这篇论文使用了一种新的视频斯特瑞数据集，并提出了一种基于视频的斯特瑞匹配方法，以实现实时的深度推断。这种方法利用了视频中的相互关系和缓存机制，以提高效率而不损失准确性。</li>
<li>results: 根据论文的测试结果，这种方法在标准桌面计算机上实现了134帧每秒的实时推断速度，或在磁盘式VR&#x2F;AR头戴式设备上实现了30帧每秒的实时推断速度，都是现有技术的最佳性能。<details>
<summary>Abstract</summary>
Real-time Stereo Matching is a cornerstone algorithm for many Extended Reality (XR) applications, such as indoor 3D understanding, video pass-through, and mixed-reality games. Despite significant advancements in deep stereo methods, achieving real-time depth inference with high accuracy on a low-power device remains a major challenge. One of the major difficulties is the lack of high-quality indoor video stereo training datasets captured by head-mounted VR/AR glasses. To address this issue, we introduce a novel video stereo synthetic dataset that comprises photorealistic renderings of various indoor scenes and realistic camera motion captured by a 6-DoF moving VR/AR head-mounted display (HMD). This facilitates the evaluation of existing approaches and promotes further research on indoor augmented reality scenarios. Our newly proposed dataset enables us to develop a novel framework for continuous video-rate stereo matching.   As another contribution, our dataset enables us to proposed a new video-based stereo matching approach tailored for XR applications, which achieves real-time inference at an impressive 134fps on a standard desktop computer, or 30fps on a battery-powered HMD. Our key insight is that disparity and contextual information are highly correlated and redundant between consecutive stereo frames. By unrolling an iterative cost aggregation in time (i.e. in the temporal dimension), we are able to distribute and reuse the aggregated features over time. This approach leads to a substantial reduction in computation without sacrificing accuracy. We conducted extensive evaluations and comparisons and demonstrated that our method achieves superior performance compared to the current state-of-the-art, making it a strong contender for real-time stereo matching in VR/AR applications.
</details>
<details>
<summary>摘要</summary>
现实时斯特瑞匹配是虚拟现实（XR）应用的关键算法之一，包括室内3D理解、视频过关和混合实际游戏。尽管深度斯特瑞方法得到了重要的进步，但在低功耗设备上实现实时深度推测仍然是一个主要挑战。主要的困难之一是lack of high-quality indoor video stereo training datasets captured by head-mounted VR/AR glasses。为解决这个问题，我们介绍了一个新的视频斯特瑞 sintetic dataset，该dataset包括各种室内场景的 photorealistic 渲染和realistic camera motion captured by a 6-DoF moving VR/AR head-mounted display (HMD)。这使得我们可以评估现有方法并促进更多的室内扩展实际游戏enario研究。我们新提出的dataset允许我们开发一个新的持续视频斯特瑞匹配框架。另一个贡献是我们的dataset允许我们提出一种适合XR应用的新视频斯特瑞匹配方法，该方法在惊人的134fps（在标准桌面电脑上）或30fps（在电池电源的HMD上）实时推测。我们的关键发现是，在不同的斯特瑞帧之间，диспараITY和上下文信息之间存在很高的相关性和重复性。我们通过在时间维度（i.e.,在时间维度）折叠一种迭代成本聚合来分配和重用聚合的特征。这种方法导致了显著的计算减少，而不是牺牲准确性。我们进行了广泛的评估和比较，并证明了我们的方法在当前状态的某些应用中表现出色，使其成为实时斯特瑞匹配的强 кандидат。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Object-Localization-with-Representer-Point-Selection"><a href="#Unsupervised-Object-Localization-with-Representer-Point-Selection" class="headerlink" title="Unsupervised Object Localization with Representer Point Selection"></a>Unsupervised Object Localization with Representer Point Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04172">http://arxiv.org/abs/2309.04172</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yeonghwansong/uolwrps">https://github.com/yeonghwansong/uolwrps</a></li>
<li>paper_authors: Yeonghwan Song, Seokwoo Jang, Dina Katabi, Jeany Son</li>
<li>for: 本研究旨在提出一种新的无监督对象定位方法，可以让我们理解模型的预测结果。</li>
<li>methods: 本方法基于代表点选择，通过选择模型预测结果中最重要的示例，提供了如何理解模型预测的示例和其重要性。</li>
<li>results: 我们的方法在多个数据集上与状态当前的无监督和自监督对象定位方法相比，具有显著的优势，甚至超过了最近的弱监督和几个预处理方法。<details>
<summary>Abstract</summary>
We propose a novel unsupervised object localization method that allows us to explain the predictions of the model by utilizing self-supervised pre-trained models without additional finetuning. Existing unsupervised and self-supervised object localization methods often utilize class-agnostic activation maps or self-similarity maps of a pre-trained model. Although these maps can offer valuable information for localization, their limited ability to explain how the model makes predictions remains challenging. In this paper, we propose a simple yet effective unsupervised object localization method based on representer point selection, where the predictions of the model can be represented as a linear combination of representer values of training points. By selecting representer points, which are the most important examples for the model predictions, our model can provide insights into how the model predicts the foreground object by providing relevant examples as well as their importance. Our method outperforms the state-of-the-art unsupervised and self-supervised object localization methods on various datasets with significant margins and even outperforms recent weakly supervised and few-shot methods.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的无监督物体定位方法，可以使用无监督预训练模型来解释模型预测的结果。现有的无监督和自我监督物体定位方法经常使用类型不具有激活图或模型自身的相似图来提供有价值的信息。虽然这些图可以提供有用的信息，但它们的解释能力对模型预测的限制性尚未得到解决。在这篇论文中，我们提出了一种简单 yet 有效的无监督物体定位方法，基于表达点选择，其中模型预测可以表示为一个线性组合的表达点值。通过选择表达点，这些是模型预测中最重要的示例，我们的模型可以提供如何模型预测了前景对象的信息，并提供相关示例以及其重要性。我们的方法在多个数据集上与状态之前的无监督和自我监督物体定位方法之间具有显著的差异，甚至超过最近的弱监督和几个shot方法。
</details></li>
</ul>
<hr>
<h2 id="PRISTA-Net-Deep-Iterative-Shrinkage-Thresholding-Network-for-Coded-Diffraction-Patterns-Phase-Retrieval"><a href="#PRISTA-Net-Deep-Iterative-Shrinkage-Thresholding-Network-for-Coded-Diffraction-Patterns-Phase-Retrieval" class="headerlink" title="PRISTA-Net: Deep Iterative Shrinkage Thresholding Network for Coded Diffraction Patterns Phase Retrieval"></a>PRISTA-Net: Deep Iterative Shrinkage Thresholding Network for Coded Diffraction Patterns Phase Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04171">http://arxiv.org/abs/2309.04171</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liuaxou/prista-net">https://github.com/liuaxou/prista-net</a></li>
<li>paper_authors: Aoxu Liu, Xiaohong Fan, Yin Yang, Jianping Zhang<br>for:PRISTA-Net is designed to solve the problem of phase retrieval (PR) in computational imaging and image processing, which is a challenge nonlinear inverse problem.methods:PRISTA-Net uses a deep unfolding network (DUN) based on the first-order iterative shrinkage thresholding algorithm (ISTA) to address the proximal-point mapping sub-problem associated with sparse priors. It also utilizes an attention mechanism to focus on phase information containing image edges, textures, and structures, and the fast Fourier transform (FFT) to learn global features to enhance local information.results:Experiments on Coded Diffraction Patterns (CDPs) measurements demonstrate that PRISTA-Net outperforms the existing state-of-the-art methods in terms of qualitative and quantitative evaluations.<details>
<summary>Abstract</summary>
The problem of phase retrieval (PR) involves recovering an unknown image from limited amplitude measurement data and is a challenge nonlinear inverse problem in computational imaging and image processing. However, many of the PR methods are based on black-box network models that lack interpretability and plug-and-play (PnP) frameworks that are computationally complex and require careful parameter tuning. To address this, we have developed PRISTA-Net, a deep unfolding network (DUN) based on the first-order iterative shrinkage thresholding algorithm (ISTA). This network utilizes a learnable nonlinear transformation to address the proximal-point mapping sub-problem associated with the sparse priors, and an attention mechanism to focus on phase information containing image edges, textures, and structures. Additionally, the fast Fourier transform (FFT) is used to learn global features to enhance local information, and the designed logarithmic-based loss function leads to significant improvements when the noise level is low. All parameters in the proposed PRISTA-Net framework, including the nonlinear transformation, threshold parameters, and step size, are learned end-to-end instead of being manually set. This method combines the interpretability of traditional methods with the fast inference ability of deep learning and is able to handle noise at each iteration during the unfolding stage, thus improving recovery quality. Experiments on Coded Diffraction Patterns (CDPs) measurements demonstrate that our approach outperforms the existing state-of-the-art methods in terms of qualitative and quantitative evaluations. Our source codes are available at \emph{https://github.com/liuaxou/PRISTA-Net}.
</details>
<details>
<summary>摘要</summary>
“复位问题（PR） involves recovering an unknown image from limited amplitude measurement data，是一个非线性逆问题在计算机影像和影像处理中。然而，许多PR方法是基于黑盒网络模型，缺乏可解性和插件和平（PnP）框架，需要精确的参数调整。为了解决这个问题，我们开发了PRISTA-Net，一个深度 unfolding 网络（DUN），基于首次iterative shrinkage thresholding 算法（ISTA）。这个网络使用可学化的非线性转换来解决对簇统调整问题，并使用注意力机制来针对具有像素、文本和结构的phasic信息。此外，我们使用快速傅立叶变换（FFT）来学习全域特征，以增强本地信息，并使用设计的对数型损失函数，导致在噪音水平低时有明显的改进。所有PRISTA-Net框架内的参数，包括非线性转换、阈值参数和步长，都是通过端到端学习而不是手动设置。这种方法结合了传统方法的可解性和深度学习的快速推理能力，并可以在每个融合阶段中处理噪音，进而改善复位质量。实验结果显示，我们的方法在CDPs测量中超过了现有的州际优秀方法，以质量和量度评估为准。我们的原始代码可以在 \emph{https://github.com/liuaxou/PRISTA-Net} 获取。”
</details></li>
</ul>
<hr>
<h2 id="Grouping-Boundary-Proposals-for-Fast-Interactive-Image-Segmentation"><a href="#Grouping-Boundary-Proposals-for-Fast-Interactive-Image-Segmentation" class="headerlink" title="Grouping Boundary Proposals for Fast Interactive Image Segmentation"></a>Grouping Boundary Proposals for Fast Interactive Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04169">http://arxiv.org/abs/2309.04169</a></li>
<li>repo_url: None</li>
<li>paper_authors: Li Liu, Da Chen, Minglei Shu, Laurent D. Cohen</li>
<li>for: This paper proposes a new image segmentation model that leverages the minimal geodesic framework and adaptive cut-based circular optimal path computation scheme to improve the accuracy and efficiency of image segmentation.</li>
<li>methods: The proposed model combines the minimal geodesic framework with an adaptive cut-based circular optimal path computation scheme and a graph-based boundary proposals grouping scheme to segment images.</li>
<li>results: Experimental results show that the proposed model outperforms state-of-the-art minimal paths-based image segmentation approaches.Here’s the same information in Simplified Chinese:</li>
<li>for: 这篇论文提出了一种基于最小几何框架和自适应割分算法的新的图像分割模型，用于解决图像分割问题。</li>
<li>methods: 该模型结合了最小几何框架、自适应割分算法和图形基于边界提议的组合来分割图像。</li>
<li>results: 实验结果表明，该模型比状态艺术最小路径基于图像分割方法更高效和更准确。<details>
<summary>Abstract</summary>
Geodesic models are known as an efficient tool for solving various image segmentation problems. Most of existing approaches only exploit local pointwise image features to track geodesic paths for delineating the objective boundaries. However, such a segmentation strategy cannot take into account the connectivity of the image edge features, increasing the risk of shortcut problem, especially in the case of complicated scenario. In this work, we introduce a new image segmentation model based on the minimal geodesic framework in conjunction with an adaptive cut-based circular optimal path computation scheme and a graph-based boundary proposals grouping scheme. Specifically, the adaptive cut can disconnect the image domain such that the target contours are imposed to pass through this cut only once. The boundary proposals are comprised of precomputed image edge segments, providing the connectivity information for our segmentation model. These boundary proposals are then incorporated into the proposed image segmentation model, such that the target segmentation contours are made up of a set of selected boundary proposals and the corresponding geodesic paths linking them. Experimental results show that the proposed model indeed outperforms state-of-the-art minimal paths-based image segmentation approaches.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Context-Aware-Prompt-Tuning-for-Vision-Language-Model-with-Dual-Alignment"><a href="#Context-Aware-Prompt-Tuning-for-Vision-Language-Model-with-Dual-Alignment" class="headerlink" title="Context-Aware Prompt Tuning for Vision-Language Model with Dual-Alignment"></a>Context-Aware Prompt Tuning for Vision-Language Model with Dual-Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04158">http://arxiv.org/abs/2309.04158</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongyu Hu, Tiancheng Lin, Jie Wang, Zhenbang Sun, Yi Xu</li>
<li>for: 提高视语模型（VLM）的适应能力，使其更好地适应下游任务。</li>
<li>methods:  combining pre-trained large language models（LLMs）和learnable prompts，通过对Prompt的学习进行对接，从而提高视语模型的适应能力。</li>
<li>results: 在11个下游数据集上，DuAl-PT实现了superior的表现，并且在base-to-new泛化上也显示出了优秀的结果。<details>
<summary>Abstract</summary>
Large-scale vision-language models (VLMs), e.g., CLIP, learn broad visual concepts from tedious training data, showing superb generalization ability. Amount of prompt learning methods have been proposed to efficiently adapt the VLMs to downstream tasks with only a few training samples. We introduce a novel method to improve the prompt learning of vision-language models by incorporating pre-trained large language models (LLMs), called Dual-Aligned Prompt Tuning (DuAl-PT). Learnable prompts, like CoOp, implicitly model the context through end-to-end training, which are difficult to control and interpret. While explicit context descriptions generated by LLMs, like GPT-3, can be directly used for zero-shot classification, such prompts are overly relying on LLMs and still underexplored in few-shot domains. With DuAl-PT, we propose to learn more context-aware prompts, benefiting from both explicit and implicit context modeling. To achieve this, we introduce a pre-trained LLM to generate context descriptions, and we encourage the prompts to learn from the LLM's knowledge by alignment, as well as the alignment between prompts and local image features. Empirically, DuAl-PT achieves superior performance on 11 downstream datasets on few-shot recognition and base-to-new generalization. Hopefully, DuAl-PT can serve as a strong baseline. Code will be available.
</details>
<details>
<summary>摘要</summary>
大规模视言模型（VLM），如CLIP，通过 tedious 训练数据学习广泛的视觉概念，显示出杰出的泛化能力。Amount of 提示学习方法已经被提出，以实现通过只需几个训练样本来适应下游任务。我们介绍了一种新的方法，通过将预训练的大型语言模型（LLM）与视言模型结合，来提高提示学习的视言模型。我们称之为双对调整提示（DuAl-PT）。learnable prompts，如CoOp，通过端到端训练来模型上下文，但这些提示难以控制和解释。而由 LLM 生成的文本提示，如 GPT-3，可以直接用于零shot分类，但这些提示过于依赖 LLM 并且还未在几shot领域得到充分发挥。With DuAl-PT，我们提议学习更加上下文意识的提示，利用 both explicit 和 implicit 上下文模型。为了实现这一点，我们引入了预训练 LLM 生成上下文描述，并强制提示学习从 LLM 的知识中，以及上下文和本地图像特征之间的对应。实验结果表明，DuAl-PT 在 11 个下游数据集上的几shot认识和基础到新泛化中表现出色。希望 DuAl-PT 可以成为一个强大的基eline。代码将可以公开。
</details></li>
</ul>
<hr>
<h2 id="Mapping-EEG-Signals-to-Visual-Stimuli-A-Deep-Learning-Approach-to-Match-vs-Mismatch-Classification"><a href="#Mapping-EEG-Signals-to-Visual-Stimuli-A-Deep-Learning-Approach-to-Match-vs-Mismatch-Classification" class="headerlink" title="Mapping EEG Signals to Visual Stimuli: A Deep Learning Approach to Match vs. Mismatch Classification"></a>Mapping EEG Signals to Visual Stimuli: A Deep Learning Approach to Match vs. Mismatch Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04153">http://arxiv.org/abs/2309.04153</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiqian Yang, Zhengqiao Zhao, Qian Wang, Yan Yang, Jingdong Chen</li>
<li>for: 该研究旨在开发一种基于深度学习的“匹配vs不匹配”模型，用于类ifizying视频片段是否引起记录的EEG信号响应，以及学习视觉内容和相应的神经记录之间的关系。</li>
<li>methods: 该模型使用了一种新的“匹配vs不匹配”机制，通过对视频片段和EEG信号进行匹配和不匹配的比较，以捕捉视频内容和神经记录之间的关系。</li>
<li>results: 研究发现，使用该模型可以在不知道训练数据的情况下，达到最高的准确率，并且可以减少 между主体噪音。此外，研究还发现，模型预测中的脑区域主要与语言处理相关，然后是视觉处理相关。这些结果有助于开发基于神经录音的视频重建技术和相关应用。<details>
<summary>Abstract</summary>
Existing approaches to modeling associations between visual stimuli and brain responses are facing difficulties in handling between-subject variance and model generalization. Inspired by the recent progress in modeling speech-brain response, we propose in this work a ``match-vs-mismatch'' deep learning model to classify whether a video clip induces excitatory responses in recorded EEG signals and learn associations between the visual content and corresponding neural recordings. Using an exclusive experimental dataset, we demonstrate that the proposed model is able to achieve the highest accuracy on unseen subjects as compared to other baseline models. Furthermore, we analyze the inter-subject noise using a subject-level silhouette score in the embedding space and show that the developed model is able to mitigate inter-subject noise and significantly reduce the silhouette score. Moreover, we examine the Grad-CAM activation score and show that the brain regions associated with language processing contribute most to the model predictions, followed by regions associated with visual processing. These results have the potential to facilitate the development of neural recording-based video reconstruction and its related applications.
</details>
<details>
<summary>摘要</summary>
现有的视觉刺激和大脑响应模型面临着处理 между人差异和模型泛化的挑战。启发于最近的语音大脑响应模型的进步，我们在本工作中提出了一种“匹配vs不匹配”深度学习模型，用于判断视频片断是否产生记录的EEG信号中的刺激响应。使用专属实验数据集，我们示出了该模型能够在未见过的人群中达到最高的准确率，并且分析了在 embedding 空间中的人体遮盾分数，显示该模型能够减少人体噪音，并且通过Grad-CAM活化分数显示，大脑语言处理相关区域对模型预测做出了主要贡献，其次是视觉处理相关区域。这些结果有potential用于发展基于 neural recording 的视频重建和相关应用。
</details></li>
</ul>
<hr>
<h2 id="Representation-Synthesis-by-Probabilistic-Many-Valued-Logic-Operation-in-Self-Supervised-Learning"><a href="#Representation-Synthesis-by-Probabilistic-Many-Valued-Logic-Operation-in-Self-Supervised-Learning" class="headerlink" title="Representation Synthesis by Probabilistic Many-Valued Logic Operation in Self-Supervised Learning"></a>Representation Synthesis by Probabilistic Many-Valued Logic Operation in Self-Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04148">http://arxiv.org/abs/2309.04148</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hiroki Nakamura, Masashi Okada, Tadahiro Taniguchi</li>
<li>for: 本研究探讨了一种基于多值逻辑的自助学习（SSL）方法，用于学习混合图像表示。</li>
<li>methods: 该方法使用混合图像synthesize表示，并使用多值逻辑运算实现表示合并。该方法可以保持原始表示的remarkable特征。</li>
<li>results: 对于图像分类任务，该方法与前期表示合并方法竞争性。此外，我们还研究了图像检索应用，并发现了与图像类别数量之间的关系。<details>
<summary>Abstract</summary>
Self-supervised learning (SSL) using mixed images has been studied to learn various image representations. Existing methods using mixed images learn a representation by maximizing the similarity between the representation of the mixed image and the synthesized representation of the original images. However, few methods consider the synthesis of representations from the perspective of mathematical logic. In this study, we focused on a synthesis method of representations. We proposed a new SSL with mixed images and a new representation format based on many-valued logic. This format can indicate the feature-possession degree, that is, how much of each image feature is possessed by a representation. This representation format and representation synthesis by logic operation realize that the synthesized representation preserves the remarkable characteristics of the original representations. Our method performed competitively with previous representation synthesis methods for image classification tasks. We also examined the relationship between the feature-possession degree and the number of classes of images in the multilabel image classification dataset to verify that the intended learning was achieved. In addition, we discussed image retrieval, which is an application of our proposed representation format using many-valued logic.
</details>
<details>
<summary>摘要</summary>
（简化中文）自动学习（SSL）使用混合图像已经研究了学习不同的图像表示。现有的方法使用混合图像学习表示，通常是通过最大化混合图像表示和原始图像表示的相似性来学习表示。然而，很少考虑混合表示的合成从数学逻辑的角度。在这个研究中，我们关注了混合表示的合成方法。我们提出了一种新的SSL WITH mixed images和一种基于多值逻辑的新表示格式。这种格式可以表示每个图像特征的具有度，即表示中具有多少个图像特征。这种表示格式和基于逻辑操作的表示合成实现了保留原始表示的杰出特征。我们的方法与之前的表示合成方法相比较竞争，并在图像分类任务中达到了类似的性能。我们还检验了图像分类 dataset 中图像类别数与特征具有度之间的关系，以验证学习是否实现了所需的。此外，我们还讨论了使用我们提出的表示格式进行图像检索，这是一个图像检索的应用。
</details></li>
</ul>
<hr>
<h2 id="Robot-Localization-and-Mapping-Final-Report-–-Sequential-Adversarial-Learning-for-Self-Supervised-Deep-Visual-Odometry"><a href="#Robot-Localization-and-Mapping-Final-Report-–-Sequential-Adversarial-Learning-for-Self-Supervised-Deep-Visual-Odometry" class="headerlink" title="Robot Localization and Mapping Final Report – Sequential Adversarial Learning for Self-Supervised Deep Visual Odometry"></a>Robot Localization and Mapping Final Report – Sequential Adversarial Learning for Self-Supervised Deep Visual Odometry</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04147">http://arxiv.org/abs/2309.04147</a></li>
<li>repo_url: None</li>
<li>paper_authors: Akankshya Kar, Sajal Maheshwari, Shamit Lal, Vinay Sameer Raja Kad</li>
<li>For: The paper aims to improve the accuracy of visual odometry (VO) and Simultaneous Localization and Mapping (SLAM) in challenging scenarios by using deep neural networks to extract high-level features and generate more accurate depth and pose estimates.* Methods: The paper explores two approaches to improve the accuracy of VO and SLAM: 1) modeling using optical flow and recurrent neural networks (RNN) to exploit spatio-temporal correlations, and 2) using a generative adversarial network (GAN) to improve the depth estimation and reduce artifacts.* Results: The paper achieves better depth and pose estimates compared to previous works, and demonstrates the effectiveness of the proposed methods in challenging scenarios such as low-texture images and dynamic scenarios.<details>
<summary>Abstract</summary>
Visual odometry (VO) and SLAM have been using multi-view geometry via local structure from motion for decades. These methods have a slight disadvantage in challenging scenarios such as low-texture images, dynamic scenarios, etc. Meanwhile, use of deep neural networks to extract high level features is ubiquitous in computer vision. For VO, we can use these deep networks to extract depth and pose estimates using these high level features. The visual odometry task then can be modeled as an image generation task where the pose estimation is the by-product. This can also be achieved in a self-supervised manner, thereby eliminating the data (supervised) intensive nature of training deep neural networks. Although some works tried the similar approach [1], the depth and pose estimation in the previous works are vague sometimes resulting in accumulation of error (drift) along the trajectory. The goal of this work is to tackle these limitations of past approaches and to develop a method that can provide better depths and pose estimates. To address this, a couple of approaches are explored: 1) Modeling: Using optical flow and recurrent neural networks (RNN) in order to exploit spatio-temporal correlations which can provide more information to estimate depth. 2) Loss function: Generative adversarial network (GAN) [2] is deployed to improve the depth estimation (and thereby pose too), as shown in Figure 1. This additional loss term improves the realism in generated images and reduces artifacts.
</details>
<details>
<summary>摘要</summary>
Visual odometry (VO) 和 SLAM 已经在多个视图几何学中使用了多年。这些方法在复杂的场景下（如低Texture图像、动态场景等）存在一定的缺陷。而现在，使用深度神经网络提取高级特征是计算机视觉中 ubique 的现象。为VO，我们可以使用这些深度神经网络来提取深度和pose估计，并将视觉跟踪任务模型为图像生成任务，其中 pose 估计是产物。这可以通过自我监督的方式进行实现，从而消除深度神经网络的培训数据（supervised）Intensive 性。虽然一些工作已经尝试了类似的方法 [1]，但在这些方法中的深度和pose估计 Sometimes 存在抽象（vague），导致轨迹中的错误（drift）积累。本工作的目标是解决过去的限制，并提供更好的深度和pose估计。为此，我们探讨了一些方法：1. 模型：通过光流和循环神经网络（RNN）来利用空间时间相关性，从而提供更多的信息来估计深度。2. 损失函数：使用生成对抗网络（GAN）来改善深度估计（并因此提高pose估计），如图1所示。这个额外的损失函数提高生成图像的真实性，并减少了图像的artefacts。
</details></li>
</ul>
<hr>
<h2 id="Depth-Completion-with-Multiple-Balanced-Bases-and-Confidence-for-Dense-Monocular-SLAM"><a href="#Depth-Completion-with-Multiple-Balanced-Bases-and-Confidence-for-Dense-Monocular-SLAM" class="headerlink" title="Depth Completion with Multiple Balanced Bases and Confidence for Dense Monocular SLAM"></a>Depth Completion with Multiple Balanced Bases and Confidence for Dense Monocular SLAM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04145">http://arxiv.org/abs/2309.04145</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weijian Xie, Guanyi Chu, Quanhao Qian, Yihao Yu, Hai Li, Danpeng Chen, Shangjin Zhai, Nan Wang, Hujun Bao, Guofeng Zhang</li>
<li>For: This paper proposes a novel method for dense SLAM based on monocular cameras, which can achieve online dense mapping on a mobile device.* Methods: The proposed method integrates a light-weight depth completion network (BBC-Net) into a sparse SLAM system using a multi-basis depth representation. The method predicts multiple balanced bases and a confidence map from a monocular image with sparse points, and the final depth is a linear combination of predicted depth bases optimized by tuning the corresponding weights.* Results: The proposed method achieves better performance in monocular dense mapping than state-of-the-art methods, and provides an online demo running on a mobile phone.<details>
<summary>Abstract</summary>
Dense SLAM based on monocular cameras does indeed have immense application value in the field of AR/VR, especially when it is performed on a mobile device. In this paper, we propose a novel method that integrates a light-weight depth completion network into a sparse SLAM system using a multi-basis depth representation, so that dense mapping can be performed online even on a mobile phone. Specifically, we present a specifically optimized multi-basis depth completion network, called BBC-Net, tailored to the characteristics of traditional sparse SLAM systems. BBC-Net can predict multiple balanced bases and a confidence map from a monocular image with sparse points generated by off-the-shelf keypoint-based SLAM systems. The final depth is a linear combination of predicted depth bases that can be optimized by tuning the corresponding weights. To seamlessly incorporate the weights into traditional SLAM optimization and ensure efficiency and robustness, we design a set of depth weight factors, which makes our network a versatile plug-in module, facilitating easy integration into various existing sparse SLAM systems and significantly enhancing global depth consistency through bundle adjustment. To verify the portability of our method, we integrate BBC-Net into two representative SLAM systems. The experimental results on various datasets show that the proposed method achieves better performance in monocular dense mapping than the state-of-the-art methods. We provide an online demo running on a mobile phone, which verifies the efficiency and mapping quality of the proposed method in real-world scenarios.
</details>
<details>
<summary>摘要</summary>
“对于单目镜头的SLAM技术来说， dense SLAM 在 AR/VR 领域中有很大的应用价值，特别是在移动设备上进行。在这篇论文中，我们提出了一个新的方法，将轻量级的深度完成网络（BBC-Net）integrete到了简略SLAM 系统中，以在移动电话上进行线上 dense mapping。具体来说，我们提出了一个特别适合传统简略SLAM 系统的多基底深度完成网络，可以从单目镜头照片中预测多个均衡基底和一个信心地图。最终的深度是由多个预测的深度基底进行线性结合，可以通过调整对应的加权因子进行优化。为了让我们的网络适应各种现有的简略SLAM 系统，我们设计了一个深度加权因子集，这使得我们的网络成为了一个通用的插入模组，可以轻松地整合到各种现有的简略SLAM 系统中，并且可以提高全球深度一致性through bundle adjustment。为了证明我们的方法的可移植性，我们将 BBC-Net 整合到了两个代表性的 SLAM 系统中。实验结果显示，我们的方法在单目密集地图中表现比前景方法更好。我们提供了一个线上 demo，证明了我们的方法在实际情况下的效率和地图质量。”
</details></li>
</ul>
<hr>
<h2 id="On-the-Efficacy-of-Multi-scale-Data-Samplers-for-Vision-Applications"><a href="#On-the-Efficacy-of-Multi-scale-Data-Samplers-for-Vision-Applications" class="headerlink" title="On the Efficacy of Multi-scale Data Samplers for Vision Applications"></a>On the Efficacy of Multi-scale Data Samplers for Vision Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04502">http://arxiv.org/abs/2309.04502</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elvis Nunez, Thomas Merth, Anish Prabhu, Mehrdad Farajtabar, Mohammad Rastegari, Sachin Mehta, Maxwell Horton</li>
<li>For: 本研究探讨了多尺度解析训练的性质，以帮助提高视觉任务的性能。* Methods: 本研究使用了可变批处理多尺度数据采样器，该采样器在每个训练迭代中随机选择输入分辨率，并在批处理大小的同时进行调整。* Results: 研究发现，多尺度采样器 behave as 隐式数据正则化，可以加速训练速度，同时保持或提高模型的准确率，并且更好地适应数据分布和缩放变化。此外，研究还扩展了一个多尺度变换批处理器，通过逐渐增加分辨率来减少计算量，并在检测和实例分割任务中获得了37%的训练计算量减少和3-4%的mAP提高。<details>
<summary>Abstract</summary>
Multi-scale resolution training has seen an increased adoption across multiple vision tasks, including classification and detection. Training with smaller resolutions enables faster training at the expense of a drop in accuracy. Conversely, training with larger resolutions has been shown to improve performance, but memory constraints often make this infeasible. In this paper, we empirically study the properties of multi-scale training procedures. We focus on variable batch size multi-scale data samplers that randomly sample an input resolution at each training iteration and dynamically adjust their batch size according to the resolution. Such samplers have been shown to improve model accuracy beyond standard training with a fixed batch size and resolution, though it is not clear why this is the case. We explore the properties of these data samplers by performing extensive experiments on ResNet-101 and validate our conclusions across multiple architectures, tasks, and datasets. We show that multi-scale samplers behave as implicit data regularizers and accelerate training speed. Compared to models trained with single-scale samplers, we show that models trained with multi-scale samplers retain or improve accuracy, while being better-calibrated and more robust to scaling and data distribution shifts. We additionally extend a multi-scale variable batch sampler with a simple curriculum that progressively grows resolutions throughout training, allowing for a compute reduction of more than 30%. We show that the benefits of multi-scale training extend to detection and instance segmentation tasks, where we observe a 37% reduction in training FLOPs along with a 3-4% mAP increase on MS-COCO using a Mask R-CNN model.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="From-Text-to-Mask-Localizing-Entities-Using-the-Attention-of-Text-to-Image-Diffusion-Models"><a href="#From-Text-to-Mask-Localizing-Entities-Using-the-Attention-of-Text-to-Image-Diffusion-Models" class="headerlink" title="From Text to Mask: Localizing Entities Using the Attention of Text-to-Image Diffusion Models"></a>From Text to Mask: Localizing Entities Using the Attention of Text-to-Image Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04109">http://arxiv.org/abs/2309.04109</a></li>
<li>repo_url: None</li>
<li>paper_authors: Changming Xiao, Qi Yang, Feng Zhou, Changshui Zhang</li>
<li>for: 这研究旨在利用文本扩散模型中的注意机制进行Semantic Grounding，不需要再训练也不需要执行时间优化。</li>
<li>methods: 提议使用文本扩散模型的denoising网络中的注意机制来实现Semantic Grounding。</li>
<li>results: 在 Pascal VOC 2012 和 Microsoft COCO 2014 上进行了weakly-supervised Semantic Segmentation的评估，并得到了较高的性能。此外，我们还发现了自定义生成方法中学习的文本嵌入的word-pixel相关性可以通过一些修改来掌握。<details>
<summary>Abstract</summary>
Diffusion models have revolted the field of text-to-image generation recently. The unique way of fusing text and image information contributes to their remarkable capability of generating highly text-related images. From another perspective, these generative models imply clues about the precise correlation between words and pixels. In this work, a simple but effective method is proposed to utilize the attention mechanism in the denoising network of text-to-image diffusion models. Without re-training nor inference-time optimization, the semantic grounding of phrases can be attained directly. We evaluate our method on Pascal VOC 2012 and Microsoft COCO 2014 under weakly-supervised semantic segmentation setting and our method achieves superior performance to prior methods. In addition, the acquired word-pixel correlation is found to be generalizable for the learned text embedding of customized generation methods, requiring only a few modifications. To validate our discovery, we introduce a new practical task called "personalized referring image segmentation" with a new dataset. Experiments in various situations demonstrate the advantages of our method compared to strong baselines on this task. In summary, our work reveals a novel way to extract the rich multi-modal knowledge hidden in diffusion models for segmentation.
</details>
<details>
<summary>摘要</summary>
Diffusion models have recently revolutionized the field of text-to-image generation. These models have a unique way of fusing text and image information, which allows them to generate highly text-related images. From another perspective, these generative models provide insights into the precise correlation between words and pixels. In this work, we propose a simple but effective method that utilizes the attention mechanism in the denoising network of text-to-image diffusion models to achieve semantic grounding of phrases without re-training or inference-time optimization. We evaluate our method on Pascal VOC 2012 and Microsoft COCO 2014 under weakly-supervised semantic segmentation settings, and our method achieves superior performance compared to prior methods. Furthermore, we find that the acquired word-pixel correlation is generalizable for the learned text embedding of customized generation methods, which only require a few modifications. To validate our discovery, we introduce a new practical task called "personalized referring image segmentation" with a new dataset. Our experiments in various situations demonstrate the advantages of our method compared to strong baselines on this task. In summary, our work reveals a novel way to extract the rich multi-modal knowledge hidden in diffusion models for segmentation.Here is the word-for-word translation of the text into Simplified Chinese:Diffusion 模型最近在文本到图像生成领域引起了革命。这些模型具有独特的文本和图像信息 fusions 的方式，使得它们能够生成高度相关的文本图像。从另一个角度来看，这些生成模型表明了文本和像素之间的精确相关性。在这项工作中，我们提出了一种简单 yet effective 的方法，利用文本涂抹网络中的注意机制来实现文本短语的semantic grounding，不需要重新训练 nor inference-time optimization。我们在 Pascal VOC 2012 和 Microsoft COCO 2014 下进行了弱监督semantic segmentation 设置下的评估，并发现我们的方法在相比先前方法上表现出色。此外，我们发现了acquired 的word-pixel correlation 可以通过自定义生成方法中学习的文本嵌入来扩展。为了证明我们的发现，我们引入了一个新的实际任务“个性化引用图像分割”，并提供了一个新的数据集。我们在多种情况下进行了实验，并发现我们的方法在这个任务上比强基eline 表现出优异。总之，我们的工作揭示了 diffusion 模型中的丰富多模态知识可以用于分割。
</details></li>
</ul>
<hr>
<h2 id="Toward-Sufficient-Spatial-Frequency-Interaction-for-Gradient-aware-Underwater-Image-Enhancement"><a href="#Toward-Sufficient-Spatial-Frequency-Interaction-for-Gradient-aware-Underwater-Image-Enhancement" class="headerlink" title="Toward Sufficient Spatial-Frequency Interaction for Gradient-aware Underwater Image Enhancement"></a>Toward Sufficient Spatial-Frequency Interaction for Gradient-aware Underwater Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04089">http://arxiv.org/abs/2309.04089</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhihefang/SFGNet">https://github.com/zhihefang/SFGNet</a></li>
<li>paper_authors: Chen Zhao, Weiling Cai, Chenyu Dong, Ziqi Zeng</li>
<li>for: 提高水下图像质量</li>
<li>methods: 基于空间频率相互作用和梯度地图的SFGNet框架</li>
<li>results: 实验结果表明，我们的方法可以成功提高水下图像质量，并与其他方法匹配或超越其视觉质量改进。<details>
<summary>Abstract</summary>
Underwater images suffer from complex and diverse degradation, which inevitably affects the performance of underwater visual tasks. However, most existing learning-based Underwater image enhancement (UIE) methods mainly restore such degradations in the spatial domain, and rarely pay attention to the fourier frequency information. In this paper, we develop a novel UIE framework based on spatial-frequency interaction and gradient maps, namely SFGNet, which consists of two stages. Specifically, in the first stage, we propose a dense spatial-frequency fusion network (DSFFNet), mainly including our designed dense fourier fusion block and dense spatial fusion block, achieving sufficient spatial-frequency interaction by cross connections between these two blocks. In the second stage, we propose a gradient-aware corrector (GAC) to further enhance perceptual details and geometric structures of images by gradient map. Experimental results on two real-world underwater image datasets show that our approach can successfully enhance underwater images, and achieves competitive performance in visual quality improvement.
</details>
<details>
<summary>摘要</summary>
水下图像受到复杂和多样化的干扰，这会不可避免地影响水下视觉任务的性能。然而，大多数现有的学习基于水下图像改善（UIE）方法主要是在空间频谱领域进行修复，rarely 充分利用了干扰的频率信息。在这篇论文中，我们开发了一种新的UIE框架，即SFGNet，它包括两个阶段。具体来说，在第一阶段，我们提出了一个密集的空间频谱融合网络（DSFFNet），包括我们设计的密集傅立叶融合块和密集空间融合块，通过跨连接这两个块实现了足够的空间频谱交互。在第二阶段，我们提出了一个梯度感知corrector（GAC），用于进一步增强图像的感知细节和几何结构，通过梯度地图。实验结果表明，我们的方法可以成功地改善水下图像，并在视觉质量改进方面实现了竞争性能。
</details></li>
</ul>
<hr>
<h2 id="Towards-Efficient-SDRTV-to-HDRTV-by-Learning-from-Image-Formation"><a href="#Towards-Efficient-SDRTV-to-HDRTV-by-Learning-from-Image-Formation" class="headerlink" title="Towards Efficient SDRTV-to-HDRTV by Learning from Image Formation"></a>Towards Efficient SDRTV-to-HDRTV by Learning from Image Formation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04084">http://arxiv.org/abs/2309.04084</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiaom233/hdrtvnet-plus">https://github.com/xiaom233/hdrtvnet-plus</a></li>
<li>paper_authors: Xiangyu Chen, Zheyuan Li, Zhengwen Zhang, Jimmy S. Ren, Yihao Liu, Jingwen He, Yu Qiao, Jiantao Zhou, Chao Dong</li>
<li>for: 本研究目的是将SDRTV内容转换为HDRTV标准，以提高视觉效果。</li>
<li>methods: 本文提出了一种三步解决方案，包括自适应全色映射、本地增强和高点级别。全色映射阶段使用全图统计作为引导，进行图像适应色映射。本地增强网络用于增强本地细节。最后，我们将两个子网络组合成一个生成器，通过GAN共同训练来保证高点级别。</li>
<li>results: 我们的方法可以准确地将SDRTV内容转换为HDRTV标准，并且可以保持高品质和精细的视觉效果。我们的方法主要针对4K分辨率图像，是轻量级的和高效的。我们还构建了一个名为HDRTV1K的数据集，包含1235个和117个训练图像和测试图像，均为4K分辨率。此外，我们选择了五个度量来评估SDRTV-to-HDRTV算法的结果。最终结果表明我们的方法在量化和视觉上具有国际前沿水平。代码、模型和数据集可以在<a target="_blank" rel="noopener" href="https://github.com/xiaom233/HDRTVNet-plus%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/xiaom233/HDRTVNet-plus上获取。</a><details>
<summary>Abstract</summary>
Modern displays are capable of rendering video content with high dynamic range (HDR) and wide color gamut (WCG). However, the majority of available resources are still in standard dynamic range (SDR). As a result, there is significant value in transforming existing SDR content into the HDRTV standard. In this paper, we define and analyze the SDRTV-to-HDRTV task by modeling the formation of SDRTV/HDRTV content. Our analysis and observations indicate that a naive end-to-end supervised training pipeline suffers from severe gamut transition errors. To address this issue, we propose a novel three-step solution pipeline called HDRTVNet++, which includes adaptive global color mapping, local enhancement, and highlight refinement. The adaptive global color mapping step uses global statistics as guidance to perform image-adaptive color mapping. A local enhancement network is then deployed to enhance local details. Finally, we combine the two sub-networks above as a generator and achieve highlight consistency through GAN-based joint training. Our method is primarily designed for ultra-high-definition TV content and is therefore effective and lightweight for processing 4K resolution images. We also construct a dataset using HDR videos in the HDR10 standard, named HDRTV1K that contains 1235 and 117 training images and 117 testing images, all in 4K resolution. Besides, we select five metrics to evaluate the results of SDRTV-to-HDRTV algorithms. Our final results demonstrate state-of-the-art performance both quantitatively and visually. The code, model and dataset are available at https://github.com/xiaom233/HDRTVNet-plus.
</details>
<details>
<summary>摘要</summary>
现代显示器可以渲染视频内容高动态范围（HDR）和宽色域范围（WCG）。然而，大多数可用资源仍然是标准动态范围（SDR）。因此，将现有的SDR内容转换到HDRTV标准具有重要价值。在这篇论文中，我们定义和分析将SDRTV转换为HDRTV的任务。我们的分析和观察表明，使用简单的端到端超vised训练管道会导致严重的色域过渡错误。为解决这个问题，我们提出了一个新的三步解决方案管道called HDRTVNet++,其包括 adaptive global color mapping、local enhancement和高点级别调整。adaptive global color mapping步骤使用图像全局统计作为指导进行图像适应色mapping。然后，我们部署了本地增强网络来增强本地细节。最后，我们将两个子网络组合成一个生成器，通过GAN相关训练实现高点级别调整。我们的方法主要针对4K分辨率图像，因此效果精准和轻量级。我们还构建了一个名为HDRTV1K的HDR视频集，包含1235个和117个训练图像和测试图像，全部是4K分辨率。此外，我们选择了五个度量来评估SDRTV-to-HDRTV算法的结果。最终结果表明我们的方法在量和视觉上具有国际前进的性能。代码、模型和数据集可以在https://github.com/xiaom233/HDRTVNet-plus上获取。
</details></li>
</ul>
<hr>
<h2 id="UER-A-Heuristic-Bias-Addressing-Approach-for-Online-Continual-Learning"><a href="#UER-A-Heuristic-Bias-Addressing-Approach-for-Online-Continual-Learning" class="headerlink" title="UER: A Heuristic Bias Addressing Approach for Online Continual Learning"></a>UER: A Heuristic Bias Addressing Approach for Online Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04081">http://arxiv.org/abs/2309.04081</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/FelixHuiweiLin/UER">https://github.com/FelixHuiweiLin/UER</a></li>
<li>paper_authors: Huiwei Lin, Shanshan Feng, Baoquan Zhang, Hongliang Qiao, Xutao Li, Yunming Ye</li>
<li>for: 这篇论文主要针对在线连续学习中的偏见问题，即在继续训练神经网络时，由于数据流动性的限制，导致神经网络偏爱当前数据中的类别，从而导致忘记前期数据的问题。</li>
<li>methods: 这篇论文提出了一种简单而高效的方法，即使 angle factor 和 norm factor 的偏见问题。通过分解 dot-product logits 为两个因素，发现偏见主要出现在 angle factor 上，可以用 cosine logits 来学习新知识。同时，通过使用 norm factor 来帮助保持历史知识。</li>
<li>results: 对于三个数据集，论文提出的 UER 方法可以在不同的情况下具有最高的性能，超过了多种现有方法的性能。<details>
<summary>Abstract</summary>
Online continual learning aims to continuously train neural networks from a continuous data stream with a single pass-through data. As the most effective approach, the rehearsal-based methods replay part of previous data. Commonly used predictors in existing methods tend to generate biased dot-product logits that prefer to the classes of current data, which is known as a bias issue and a phenomenon of forgetting. Many approaches have been proposed to overcome the forgetting problem by correcting the bias; however, they still need to be improved in online fashion. In this paper, we try to address the bias issue by a more straightforward and more efficient method. By decomposing the dot-product logits into an angle factor and a norm factor, we empirically find that the bias problem mainly occurs in the angle factor, which can be used to learn novel knowledge as cosine logits. On the contrary, the norm factor abandoned by existing methods helps remember historical knowledge. Based on this observation, we intuitively propose to leverage the norm factor to balance the new and old knowledge for addressing the bias. To this end, we develop a heuristic approach called unbias experience replay (UER). UER learns current samples only by the angle factor and further replays previous samples by both the norm and angle factors. Extensive experiments on three datasets show that UER achieves superior performance over various state-of-the-art methods. The code is in https://github.com/FelixHuiweiLin/UER.
</details>
<details>
<summary>摘要</summary>
（简化中文）在线continuous学习目标是通过连续数据流进行单次 passes through 训练神经网络。现有最有效的方法是启用循环训练，但它们仍然需要进一步改进。在这篇论文中，我们尝试通过更直观和更有效的方法来解决偏见问题。我们通过分解dot product logits into angle factor和norm factor来发现，偏见问题主要出现在角度因子上，可以用作学习新知识的cosine logits。相反，待用于记忆知识的norm factor被现有方法抛弃。基于这一观察，我们提议使用norm factor来平衡新知识和历史知识，以解决偏见问题。为此，我们开发了一种启用经验回放（UER）的规则。UER只learning当前样本的角度因子，并在之前的样本中重新使用角度因子和norm因子来回放。我们在三个dataset上进行了广泛的实验，并证明UER可以超越多种现有方法的性能。代码可以在https://github.com/FelixHuiweiLin/UER中找到。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Hierarchical-Transformers-for-Whole-Brain-Segmentation-with-Intracranial-Measurements-Integration"><a href="#Enhancing-Hierarchical-Transformers-for-Whole-Brain-Segmentation-with-Intracranial-Measurements-Integration" class="headerlink" title="Enhancing Hierarchical Transformers for Whole Brain Segmentation with Intracranial Measurements Integration"></a>Enhancing Hierarchical Transformers for Whole Brain Segmentation with Intracranial Measurements Integration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04071">http://arxiv.org/abs/2309.04071</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/masilab/unest">https://github.com/masilab/unest</a></li>
<li>paper_authors: Xin Yu, Yucheng Tang, Qi Yang, Ho Hin Lee, Shunxing Bao, Yuankai Huo, Bennett A. Landman</li>
<li>for: 本研究旨在提高现有的全脑分割方法，以包含内侧量测量，并提供更全面的脑结构分析。</li>
<li>methods: 本研究使用改进的层次变换器UNesT进行全脑分割，并同时分割脑部133个区域和内侧量&#x2F;后腔量。为了解决数据短缺问题，模型首先在8个不同站点的4859个T1-weighted（T1w）3D图像上进行预训练，然后在Open Access Series Imaging Studies（OASIS）上进行微调。</li>
<li>results: 我们使用Dice相似度（DSC）评估方法，并显示我们的模型能够准确地估计内侧量&#x2F;后腔量，同时保持132个脑区的性能在相同水平。<details>
<summary>Abstract</summary>
Whole brain segmentation with magnetic resonance imaging (MRI) enables the non-invasive measurement of brain regions, including total intracranial volume (TICV) and posterior fossa volume (PFV). Enhancing the existing whole brain segmentation methodology to incorporate intracranial measurements offers a heightened level of comprehensiveness in the analysis of brain structures. Despite its potential, the task of generalizing deep learning techniques for intracranial measurements faces data availability constraints due to limited manually annotated atlases encompassing whole brain and TICV/PFV labels. In this paper, we enhancing the hierarchical transformer UNesT for whole brain segmentation to achieve segmenting whole brain with 133 classes and TICV/PFV simultaneously. To address the problem of data scarcity, the model is first pretrained on 4859 T1-weighted (T1w) 3D volumes sourced from 8 different sites. These volumes are processed through a multi-atlas segmentation pipeline for label generation, while TICV/PFV labels are unavailable. Subsequently, the model is finetuned with 45 T1w 3D volumes from Open Access Series Imaging Studies (OASIS) where both 133 whole brain classes and TICV/PFV labels are available. We evaluate our method with Dice similarity coefficients(DSC). We show that our model is able to conduct precise TICV/PFV estimation while maintaining the 132 brain regions performance at a comparable level. Code and trained model are available at: https://github.com/MASILab/UNesT/wholebrainSeg.
</details>
<details>
<summary>摘要</summary>
整个脑部分 segmentation with magnetic resonance imaging (MRI) 可以不侵入性地测量脑部分，包括总脑部分体积 (TICV) 和后底槽体积 (PFV)。提高现有的整个脑部分分 segmentation 方法，以包括脑部分测量，可以提供更全面的脑结构分析。然而，将深度学习技术推广到脑部分测量 faced 数据可用性问题，因为有限的手动标注图集覆盖整个脑部分和 TICV/PFV 标签。在这篇论文中，我们改进了层次转换器 UNesT  для整个脑部分分 segmentation，以达到同时 segmenting 整个脑部分和 TICV/PFV 的目的。为了解决数据缺乏问题，我们首先在 8 个不同的站点上获得了 4859 个 T1-weighted (T1w) 三维图像，并将其传递 через多个 Atlas 分割ipeline 生成标签。然后，我们在 Open Access Series Imaging Studies (OASIS) 上进行了 fine-tuning，使得模型可以同时测量整个脑部分和 TICV/PFV。我们使用 dice 相似度 coefficient (DSC) 进行评估。我们发现，我们的模型可以准确地估计 TICV/PFV，同时保持 132 个脑部分性能的水平。代码和已经训练的模型可以在 GitHub 上获取：<https://github.com/MASILab/UNesT/wholebrainSeg>。
</details></li>
</ul>
<hr>
<h2 id="INSURE-An-Information-Theory-Inspired-Disentanglement-and-Purification-Model-for-Domain-Generalization"><a href="#INSURE-An-Information-Theory-Inspired-Disentanglement-and-Purification-Model-for-Domain-Generalization" class="headerlink" title="INSURE: An Information Theory Inspired Disentanglement and Purification Model for Domain Generalization"></a>INSURE: An Information Theory Inspired Disentanglement and Purification Model for Domain Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04063">http://arxiv.org/abs/2309.04063</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xi Yu, Huan-Hsin Tseng, Shinjae Yoo, Haibin Ling, Yuewei Lin</li>
<li>for: 本文旨在提出一种基于信息理论的分解和纯化模型（INSURE），以便在未见目标领域中学习泛化模型。</li>
<li>methods: 本文使用了一种信息理论启发的损失函数，以确保分解的特征包含足够的类标签信息和另一个分解的卫星特征包含足够的领域信息。此外，本文还使用了一种对照纯化损失函数，使卫星特征抛弃所有类相关信息，使得类相关特征包含足够和必要的类标签信息。而不是使用多个Encoder，本文使用了一个学习的二进制masque作为分解器，以便更加有效地进行分解。</li>
<li>results: 对四个广泛使用的预测数据集（PACS、OfficeHome、TerraIncognita和DomainNet）进行了广泛的实验，并证明了提出的INSURE方法可以超越当前的状态艺。此外，本文还证明了领域特定的类相关特征对预测数据集的泛化有益。<details>
<summary>Abstract</summary>
Domain Generalization (DG) aims to learn a generalizable model on the unseen target domain by only training on the multiple observed source domains. Although a variety of DG methods have focused on extracting domain-invariant features, the domain-specific class-relevant features have attracted attention and been argued to benefit generalization to the unseen target domain. To take into account the class-relevant domain-specific information, in this paper we propose an Information theory iNspired diSentanglement and pURification modEl (INSURE) to explicitly disentangle the latent features to obtain sufficient and compact (necessary) class-relevant feature for generalization to the unseen domain. Specifically, we first propose an information theory inspired loss function to ensure the disentangled class-relevant features contain sufficient class label information and the other disentangled auxiliary feature has sufficient domain information. We further propose a paired purification loss function to let the auxiliary feature discard all the class-relevant information and thus the class-relevant feature will contain sufficient and compact (necessary) class-relevant information. Moreover, instead of using multiple encoders, we propose to use a learnable binary mask as our disentangler to make the disentanglement more efficient and make the disentangled features complementary to each other. We conduct extensive experiments on four widely used DG benchmark datasets including PACS, OfficeHome, TerraIncognita, and DomainNet. The proposed INSURE outperforms the state-of-art methods. We also empirically show that domain-specific class-relevant features are beneficial for domain generalization.
</details>
<details>
<summary>摘要</summary>
域内泛化（DG）目标是通过只在多个观察到的源领域进行训练来学习一个通用的模型，以便在未见目标领域进行泛化。虽然许多DG方法都专注于提取域无关特征，但是域相关的类特征受到了关注，并且被论证可以帮助泛化到未见目标领域。为了考虑域相关的类特征信息，在这篇论文中，我们提出了基于信息理论的INSURE模型，以Explicitly分离隐藏特征，以获得充足和 компакт（必要）的类特征，以便泛化到未见目标领域。具体来说，我们首先提出了基于信息理论的损失函数，以确保分离的类特征包含充足的类标签信息，而另一个分离的卫星特征具备充足的域信息。我们进一步提出了一个套用纯化损失函数，使卫星特征抛弃所有类相关信息，从而使类特征具备充足和 компакт（必要）的信息。此外，而不是使用多个encoder，我们提议使用学习的二进制面积作为我们的分离器，以使分离更高效，并使分离的特征相互补做。我们在四个广泛使用DG benchmark数据集（PACS、OfficeHome、TerraIncognita和DomainNet）进行了广泛的实验。提出的INSURE模型超过了当前的状态艺。我们还证明了域相关的类特征对泛化有利。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/08/cs.CV_2023_09_08/" data-id="clogxf3n000gy5xraahqgfpsm" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/08/cs.AI_2023_09_08/" class="article-date">
  <time datetime="2023-09-08T12:00:00.000Z" itemprop="datePublished">2023-09-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/08/cs.AI_2023_09_08/">cs.AI - 2023-09-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Few-Shot-Learning-of-Force-Based-Motions-From-Demonstration-Through-Pre-training-of-Haptic-Representation"><a href="#Few-Shot-Learning-of-Force-Based-Motions-From-Demonstration-Through-Pre-training-of-Haptic-Representation" class="headerlink" title="Few-Shot Learning of Force-Based Motions From Demonstration Through Pre-training of Haptic Representation"></a>Few-Shot Learning of Force-Based Motions From Demonstration Through Pre-training of Haptic Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04640">http://arxiv.org/abs/2309.04640</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marina Y. Aoyama, João Moura, Namiko Saito, Sethu Vijayakumar</li>
<li>for: 能够快速适应不同物体的物理特性，提高机器人抓取物体的能力。</li>
<li>methods: 使用半监督学习自动机制，将学习模型分解成感觉表示编码器和动作生成解码器。首先使用大量未经监督的数据进行预训练，然后使用少量监督学习来训练动作生成解码器，以便快速适应不同物体的物理特性。</li>
<li>results: 对干洗任务使用不同弹性和表面黏度的毛巾进行验证，结果表明预训练可以大幅提高下游任务中机器人对物体物理特性的认识和生成恰当的动作，超过了没有预训练的LfD方法。此外，我们还验证了在物理机器人硬件上运行的动作是否符合预期，并证明感觉表示编码器在实际物体上采集的数据上具有良好的表达能力，从而解释了它在下游任务中的贡献。<details>
<summary>Abstract</summary>
In many contact-rich tasks, force sensing plays an essential role in adapting the motion to the physical properties of the manipulated object. To enable robots to capture the underlying distribution of object properties necessary for generalising learnt manipulation tasks to unseen objects, existing Learning from Demonstration (LfD) approaches require a large number of costly human demonstrations. Our proposed semi-supervised LfD approach decouples the learnt model into an haptic representation encoder and a motion generation decoder. This enables us to pre-train the first using large amount of unsupervised data, easily accessible, while using few-shot LfD to train the second, leveraging the benefits of learning skills from humans. We validate the approach on the wiping task using sponges with different stiffness and surface friction. Our results demonstrate that pre-training significantly improves the ability of the LfD model to recognise physical properties and generate desired wiping motions for unseen sponges, outperforming the LfD method without pre-training. We validate the motion generated by our semi-supervised LfD model on the physical robot hardware using the KUKA iiwa robot arm. We also validate that the haptic representation encoder, pre-trained in simulation, captures the properties of real objects, explaining its contribution to improving the generalisation of the downstream task.
</details>
<details>
<summary>摘要</summary>
多数有物理性任务中，力感测具有重要作用，以适应 manipulate 物体的物理性。现有的学习从示例 (LfD) 方法需要大量的贵重人类示例，以便学习总结 manipulate 任务。我们提出的半supervised LfD 方法将学习模型分解为感觉表示编码器和动作生成解码器。这使得我们可以在大量的无监督数据上预训练首先，使用少量的 LfD 训练第二个，利用学习人类技能的好处。我们使用擦除任务中使用不同坚度和表面黏性的湿巾进行验证。我们的结果表明，预训练可以提高 LfD 模型认识物理特性和生成满意的擦除动作的能力，超过没有预训练的 LfD 方法。我们使用Physical robot 硬件KUKA iiwa robot arm验证下游任务中的动作。我们还验证预训练在实际物体上的感觉表示编码器能够 capture 物体的物理特性，解释其在下游任务的总结中的贡献。
</details></li>
</ul>
<hr>
<h2 id="Perceptual-adjustment-queries-and-an-inverted-measurement-paradigm-for-low-rank-metric-learning"><a href="#Perceptual-adjustment-queries-and-an-inverted-measurement-paradigm-for-low-rank-metric-learning" class="headerlink" title="Perceptual adjustment queries and an inverted measurement paradigm for low-rank metric learning"></a>Perceptual adjustment queries and an inverted measurement paradigm for low-rank metric learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04626">http://arxiv.org/abs/2309.04626</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/austinxu87/paq">https://github.com/austinxu87/paq</a></li>
<li>paper_authors: Austin Xu, Andrew D. McRae, Jingyan Wang, Mark A. Davenport, Ashwin Pananjady</li>
<li>for: 这个论文是为了提出一种新的查询机制，即感知调整查询（PAQ），用于收集人类反馈。</li>
<li>methods: 这个论文使用了一种倒计时间的测量方案，并结合了 cardinal 和 ordinal 查询的优点。</li>
<li>results: 论文在度量学习问题中使用了 PAQ 测量，并实现了一种高维度、低纬度矩阵估计问题的解决方案，并提供了样本复杂性保证。<details>
<summary>Abstract</summary>
We introduce a new type of query mechanism for collecting human feedback, called the perceptual adjustment query ( PAQ). Being both informative and cognitively lightweight, the PAQ adopts an inverted measurement scheme, and combines advantages from both cardinal and ordinal queries. We showcase the PAQ in the metric learning problem, where we collect PAQ measurements to learn an unknown Mahalanobis distance. This gives rise to a high-dimensional, low-rank matrix estimation problem to which standard matrix estimators cannot be applied. Consequently, we develop a two-stage estimator for metric learning from PAQs, and provide sample complexity guarantees for this estimator. We present numerical simulations demonstrating the performance of the estimator and its notable properties.
</details>
<details>
<summary>摘要</summary>
我们介绍一种新型的询问机制，called perceptual adjustment query (PAQ)，它具有 both informative 和 cognitively lightweight 的特点。PAQ 使用倒排量度系统，并结合 cardinal 和 ordinal 询问的优点。我们在 metric learning 问题中使用 PAQ，收集 PAQ 测量来学习未知的 Mahalanobis 距离。这导致了一个高维、低阶矩阵估计问题，标准矩阵估计器无法应用。因此，我们开发了一个 two-stage 估计器 для metric learning from PAQs，并提供了样本Complexity 保证 для 这个估计器。我们还进行了 numrical simulations 来评估这个估计器的表现和其他优点。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-World-Model-Disentanglement-in-Value-Based-Multi-Agent-Reinforcement-Learning"><a href="#Leveraging-World-Model-Disentanglement-in-Value-Based-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Leveraging World Model Disentanglement in Value-Based Multi-Agent Reinforcement Learning"></a>Leveraging World Model Disentanglement in Value-Based Multi-Agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04615">http://arxiv.org/abs/2309.04615</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhizun Wang, David Meger</li>
<li>for:  addresses the challenge of achieving a common goal of multiple agents interacting in the same environment with reduced sample complexity.</li>
<li>methods:  uses a modularized world model, composed of action-conditioned, action-free, and static branches, to unravel the environment dynamics and produce imagined outcomes based on past experience, without sampling directly from the real environment.</li>
<li>results:  achieves high sample efficiency and exhibits superior performance in defeating the enemy armies compared to other baselines in Easy, Hard, and Super-Hard StarCraft II micro-management challenges.<details>
<summary>Abstract</summary>
In this paper, we propose a novel model-based multi-agent reinforcement learning approach named Value Decomposition Framework with Disentangled World Model to address the challenge of achieving a common goal of multiple agents interacting in the same environment with reduced sample complexity. Due to scalability and non-stationarity problems posed by multi-agent systems, model-free methods rely on a considerable number of samples for training. In contrast, we use a modularized world model, composed of action-conditioned, action-free, and static branches, to unravel the environment dynamics and produce imagined outcomes based on past experience, without sampling directly from the real environment. We employ variational auto-encoders and variational graph auto-encoders to learn the latent representations for the world model, which is merged with a value-based framework to predict the joint action-value function and optimize the overall training objective. We present experimental results in Easy, Hard, and Super-Hard StarCraft II micro-management challenges to demonstrate that our method achieves high sample efficiency and exhibits superior performance in defeating the enemy armies compared to other baselines.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的模型基于多代理人强化学习方法，称为值分解框架，以解决多代理人在同一环境中实现共同目标的问题，并减少样本复杂性。由于多代理人系统的扩展性和非站点性问题，无约方法需要很多样本进行训练。相反，我们使用模块化的世界模型，包括动作决策、无动作和静态分支，来揭示环境动力学和生成基于过去经验的想像结果，不直接从实际环境中采样。我们使用变量自动编码器和变量图自动编码器来学习 latent 表示，并将其与值基于框架相结合，预测共同动作值函数并优化总训练目标。我们在易、Difficult和超级Difficult StarCraft II 微管理挑战中进行了实验，并证明了我们的方法可以 достичь高样本效率，并在击败敌军方面表现出色，相比其他基准。
</details></li>
</ul>
<hr>
<h2 id="Linking-Symptom-Inventories-using-Semantic-Textual-Similarity"><a href="#Linking-Symptom-Inventories-using-Semantic-Textual-Similarity" class="headerlink" title="Linking Symptom Inventories using Semantic Textual Similarity"></a>Linking Symptom Inventories using Semantic Textual Similarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04607">http://arxiv.org/abs/2309.04607</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shashankv98/symptom-inventories">https://github.com/shashankv98/symptom-inventories</a></li>
<li>paper_authors: Eamonn Kennedy, Shashank Vadlamani, Hannah M Lindsey, Kelly S Peterson, Kristen Dams OConnor, Kenton Murray, Ronak Agarwal, Houshang H Amiri, Raeda K Andersen, Talin Babikian, David A Baron, Erin D Bigler, Karen Caeyenberghs, Lisa Delano-Wood, Seth G Disner, Ekaterina Dobryakova, Blessen C Eapen, Rachel M Edelstein, Carrie Esopenko, Helen M Genova, Elbert Geuze, Naomi J Goodrich-Hunsaker, Jordan Grafman, Asta K Haberg, Cooper B Hodges, Kristen R Hoskinson, Elizabeth S Hovenden, Andrei Irimia, Neda Jahanshad, Ruchira M Jha, Finian Keleher, Kimbra Kenney, Inga K Koerte, Spencer W Liebel, Abigail Livny, Marianne Lovstad, Sarah L Martindale, Jeffrey E Max, Andrew R Mayer, Timothy B Meier, Deleene S Menefee, Abdalla Z Mohamed, Stefania Mondello, Martin M Monti, Rajendra A Morey, Virginia Newcombe, Mary R Newsome, Alexander Olsen, Nicholas J Pastorek, Mary Jo Pugh, Adeel Razi, Jacob E Resch, Jared A Rowland, Kelly Russell, Nicholas P Ryan, Randall S Scheibel, Adam T Schmidt, Gershon Spitz, Jaclyn A Stephens, Assaf Tal, Leah D Talbert, Maria Carmela Tartaglia, Brian A Taylor, Sophia I Thomopoulos, Maya Troyanskaya, Eve M Valera, Harm Jan van der Horn, John D Van Horn, Ragini Verma, Benjamin SC Wade, Willian SC Walker, Ashley L Ware, J Kent Werner Jr, Keith Owen Yeates, Ross D Zafonte, Michael M Zeineh, Brandon Zielinski, Paul M Thompson, Frank G Hillary, David F Tate, Elisabeth A Wilde, Emily L Dennis</li>
<li>for: 这研究旨在使用人工智能（AI）方法，通过语义文本相似性（STS）来连接不同设置和研究中的症状和分数。</li>
<li>methods: 这研究使用四种预训练的STS模型，测试这些模型能够对多达6,607名参与者和16个国际数据源中的症状描述对应的分数进行预测。</li>
<li>results: STS方法实现了74.8%的准确率，在五个任务中表现出色，超过其他测试模型。这项研究表明，将语义信息纳入专家决策过程可以提高总体和疾病特定评估的效果。<details>
<summary>Abstract</summary>
An extensive library of symptom inventories has been developed over time to measure clinical symptoms, but this variety has led to several long standing issues. Most notably, results drawn from different settings and studies are not comparable, which limits reproducibility. Here, we present an artificial intelligence (AI) approach using semantic textual similarity (STS) to link symptoms and scores across previously incongruous symptom inventories. We tested the ability of four pre-trained STS models to screen thousands of symptom description pairs for related content - a challenging task typically requiring expert panels. Models were tasked to predict symptom severity across four different inventories for 6,607 participants drawn from 16 international data sources. The STS approach achieved 74.8% accuracy across five tasks, outperforming other models tested. This work suggests that incorporating contextual, semantic information can assist expert decision-making processes, yielding gains for both general and disease-specific clinical assessment.
</details>
<details>
<summary>摘要</summary>
有很多 symptom 库已经在不同的时间和场景中开发出来，但这种多样性带来了一些长期的问题。最主要的问题是不同的设置和研究中的结果无法比较，这限制了重producibility。在这里，我们使用人工智能（AI）方法，使用semantic textual similarity（STS）将症状和分数连接起来，以解决这些不同的症状库之间的不一致性。我们测试了四种预训练的 STS 模型，将 тысячи个症状描述对比的任务进行了检测 - 这是一项传统上需要专家团队完成的复杂任务。模型在四个不同的库中预测了6,607名参与者从16个国际数据源中的症状严重程度，STS 方法实现了74.8%的准确率，超过了其他测试的模型。这种工作表明， incorporating contextual, semantic information可以帮助专家决策过程，带来疾病特定和通用的临床评估的改进。
</details></li>
</ul>
<hr>
<h2 id="EGOFALLS-A-visual-audio-dataset-and-benchmark-for-fall-detection-using-egocentric-cameras"><a href="#EGOFALLS-A-visual-audio-dataset-and-benchmark-for-fall-detection-using-egocentric-cameras" class="headerlink" title="EGOFALLS: A visual-audio dataset and benchmark for fall detection using egocentric cameras"></a>EGOFALLS: A visual-audio dataset and benchmark for fall detection using egocentric cameras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04579">http://arxiv.org/abs/2309.04579</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Xueyi-Wang/EGOFALLS">https://github.com/Xueyi-Wang/EGOFALLS</a></li>
<li>paper_authors: Xueyi Wang</li>
<li>for: 预防和mitigate falls的 Tool</li>
<li>methods: 使用多modal descriptor从 egocentric camera captured video中提取特征，并在late decision fusion层上建立。</li>
<li>results: 结果表明，通过 audio和视觉信息的混合，通过late decision fusion层，可以提高探测性能，这对于护理老年人有很好的应用。<details>
<summary>Abstract</summary>
Falls are significant and often fatal for vulnerable populations such as the elderly. Previous works have addressed the detection of falls by relying on data capture by a single sensor, images or accelerometers. In this work, we rely on multimodal descriptors extracted from videos captured by egocentric cameras. Our proposed method includes a late decision fusion layer that builds on top of the extracted descriptors. Furthermore, we collect a new dataset on which we assess our proposed approach. We believe this is the first public dataset of its kind. The dataset comprises 10,948 video samples by 14 subjects. We conducted ablation experiments to assess the performance of individual feature extractors, fusion of visual information, and fusion of both visual and audio information. Moreover, we experimented with internal and external cross-validation. Our results demonstrate that the fusion of audio and visual information through late decision fusion improves detection performance, making it a promising tool for fall prevention and mitigation.
</details>
<details>
<summary>摘要</summary>
跌倒是脆弱群体，如老年人，可致生命危险。先前的研究通过单个传感器、图像或加速计获取数据进行跌倒检测。在这种工作中，我们基于视频捕获的 egocentric 摄像头提取多模态描述符。我们的提议方法包括在描述符之间堆叠晚期决策层。此外，我们收集了一个新的数据集，用于评估我们的提议方法。这是首个公共数据集。数据集包含 10,948 个视频样本，来自 14 个主题。我们进行了减少实验来评估特定的特征提取器、视觉信息的融合和双重视觉和声音信息的融合的性能。此外，我们还进行了内部和外部验证。我们的结果表明，通过晚期决策融合视觉和声音信息可以提高跌倒检测性能，这是跌倒预防和 Mitigation 的有望工具。
</details></li>
</ul>
<hr>
<h2 id="Unleashing-the-Power-of-Graph-Learning-through-LLM-based-Autonomous-Agents"><a href="#Unleashing-the-Power-of-Graph-Learning-through-LLM-based-Autonomous-Agents" class="headerlink" title="Unleashing the Power of Graph Learning through LLM-based Autonomous Agents"></a>Unleashing the Power of Graph Learning through LLM-based Autonomous Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04565">http://arxiv.org/abs/2309.04565</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lanning Wei, Zhiqiang He, Huan Zhao, Quanming Yao<br>for:* This paper aims to simplify the learning process on diverse real-world graphs by using Large Language Models (LLMs) as autonomous agents.methods:* The proposed method, called Auto$^2$Graph, uses LLMs to decompose the complex graph learning task into three components: detecting the learning intent, configuring solutions based on AutoGraph, and generating a response.* The AutoGraph agents manage crucial procedures in automated graph learning, including data-processing, AutoML configuration, searching architectures, and hyper-parameter fine-tuning.results:* The proposed method demonstrates comparable performance on different datasets and learning tasks, and the human-like decisions made by the agents.<details>
<summary>Abstract</summary>
Graph structured data are widely existed and applied in the real-world applications, while it is a challenge to handling these diverse data and learning tasks on graph in an efficient manner. When facing the complicated graph learning tasks, experts have designed diverse Graph Neural Networks (GNNs) in recent years. They have also implemented AutoML in Graph, also known as AutoGraph, to automatically generate data-specific solutions. Despite their success, they encounter limitations in (1) managing diverse learning tasks at various levels, (2) dealing with different procedures in graph learning beyond architecture design, and (3) the huge requirements on the prior knowledge when using AutoGraph. In this paper, we propose to use Large Language Models (LLMs) as autonomous agents to simplify the learning process on diverse real-world graphs. Specifically, in response to a user request which may contain varying data and learning targets at the node, edge, or graph levels, the complex graph learning task is decomposed into three components following the agent planning, namely, detecting the learning intent, configuring solutions based on AutoGraph, and generating a response. The AutoGraph agents manage crucial procedures in automated graph learning, including data-processing, AutoML configuration, searching architectures, and hyper-parameter fine-tuning. With these agents, those components are processed by decomposing and completing step by step, thereby generating a solution for the given data automatically, regardless of the learning task on node or graph. The proposed method is dubbed Auto$^2$Graph, and the comparable performance on different datasets and learning tasks. Its effectiveness is demonstrated by its comparable performance on different datasets and learning tasks, as well as the human-like decisions made by the agents.
</details>
<details>
<summary>摘要</summary>
Graph结构数据广泛存在并应用于实际应用场景，但是处理这些多样化数据和学习任务是一个挑战。随着复杂Graph学习任务的出现，专家们在过去几年内设计了多种Graph Neural Networks（GNNs）。他们还实现了AutoML在Graph上，也称为AutoGraph，以自动生成数据特定的解决方案。尽管它们取得了成功，但它们还面临着（1）在不同级别上处理多种学习任务的管理问题，（2）在Graph学习任务之外的不同过程的处理，以及（3）使用AutoGraph时对特定知识的巨大要求。在这篇论文中，我们提议使用大语言模型（LLMs）作为自主代理人，使得Graph学习过程更加简单。具体来说，在用户请求中可能包含不同数据和学习目标的情况下，我们将复杂的Graph学习任务分解为三个组件，即检测学习意图、基于AutoGraph配置解决方案以及生成响应。AutoGraph代理人处理关键的自动Graph学习过程，包括数据处理、AutoML配置、搜索架构和超参数精度调整。通过这些代理人，这些组件可以一步步完成，从而自动生成对给定数据的解决方案，不管学习任务是节点级或图级。我们称这种方法为Auto$^2$Graph，其效果得到证明，包括在不同数据集和学习任务上实现相同或更好的性能，以及代理人做出的人类化决策。
</details></li>
</ul>
<hr>
<h2 id="Connecting-NTK-and-NNGP-A-Unified-Theoretical-Framework-for-Neural-Network-Learning-Dynamics-in-the-Kernel-Regime"><a href="#Connecting-NTK-and-NNGP-A-Unified-Theoretical-Framework-for-Neural-Network-Learning-Dynamics-in-the-Kernel-Regime" class="headerlink" title="Connecting NTK and NNGP: A Unified Theoretical Framework for Neural Network Learning Dynamics in the Kernel Regime"></a>Connecting NTK and NNGP: A Unified Theoretical Framework for Neural Network Learning Dynamics in the Kernel Regime</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04522">http://arxiv.org/abs/2309.04522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yehonatan Avidan, Qianyi Li, Haim Sompolinsky</li>
<li>for: 这 paper 旨在解释深度神经网络在无穷宽度限制下学习过程的完整理论框架。</li>
<li>methods: 这 paper 使用 Markov 距离学习模型和时间依赖神经动力学kernel（NDK）来结合NTK和NNGP两种不同的理论框架。</li>
<li>results: 这 paper 得出了两个不同的学习阶段：梯度导航阶段和扩散学习阶段，并通过synthetic和benchmark数据集的numerical evaluations来提供新的理解深度神经网络学习过程的新视角。<details>
<summary>Abstract</summary>
Artificial neural networks have revolutionized machine learning in recent years, but a complete theoretical framework for their learning process is still lacking. Substantial progress has been made for infinitely wide networks. In this regime, two disparate theoretical frameworks have been used, in which the network's output is described using kernels: one framework is based on the Neural Tangent Kernel (NTK) which assumes linearized gradient descent dynamics, while the Neural Network Gaussian Process (NNGP) kernel assumes a Bayesian framework. However, the relation between these two frameworks has remained elusive. This work unifies these two distinct theories using a Markov proximal learning model for learning dynamics in an ensemble of randomly initialized infinitely wide deep networks. We derive an exact analytical expression for the network input-output function during and after learning, and introduce a new time-dependent Neural Dynamical Kernel (NDK) from which both NTK and NNGP kernels can be derived. We identify two learning phases characterized by different time scales: gradient-driven and diffusive learning. In the initial gradient-driven learning phase, the dynamics is dominated by deterministic gradient descent, and is described by the NTK theory. This phase is followed by the diffusive learning stage, during which the network parameters sample the solution space, ultimately approaching the equilibrium distribution corresponding to NNGP. Combined with numerical evaluations on synthetic and benchmark datasets, we provide novel insights into the different roles of initialization, regularization, and network depth, as well as phenomena such as early stopping and representational drift. This work closes the gap between the NTK and NNGP theories, providing a comprehensive framework for understanding the learning process of deep neural networks in the infinite width limit.
</details>
<details>
<summary>摘要</summary>
人工神经网络在最近几年内 revolutionized机器学习，但完整的理论框架仍然缺失。在无穷宽网络 regime 中，有两种不同的理论框架用于描述网络的输出：一个基于 Neural Tangent Kernel (NTK) 的框架，它假设 linearized gradient descent 动力学，而另一个基于 Neural Network Gaussian Process (NNGP) 框架，它假设 Bayesian 框架。然而，这两个框架之间的关系仍然不明确。这项工作将这两个不同的理论联系起来，使用一种 Markov proximal learning 模型来描述学习过程中的动力学。我们得到了一个精确的分析表达，描述了网络输入-输出函数在学习和学习后的行为，并引入了一种新的时间依赖的 Neural Dynamical Kernel (NDK)，从而可以 derivate NTK 和 NNGP 两个框架。我们分 distinguished two stages of learning characterized by different time scales：deterministic gradient descent 驱动的早期学习阶段，以及在这个阶段之后的杂散学习阶段。在初期的梯度驱动学习阶段，动力学由 deterministic gradient descent 控制，可以通过 NTK 理论来描述。这个阶段被后来的杂散学习阶段所follow，在这个阶段中，网络参数在解决空间中享受漂泊，最终 approaching the equilibrium distribution corresponding to NNGP。通过对 sintetic 和 benchmark 数据进行数值评估，我们提供了新的理解，关于初始化、正则化和网络深度的不同角色，以及phenomena such as early stopping 和 representational drift。这项工作 closure 了 NTK 和 NNGP 两个理论之间的 gap，提供了深度学习过程中无穷宽网络的全面框架。
</details></li>
</ul>
<hr>
<h2 id="On-the-Actionability-of-Outcome-Prediction"><a href="#On-the-Actionability-of-Outcome-Prediction" class="headerlink" title="On the Actionability of Outcome Prediction"></a>On the Actionability of Outcome Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04470">http://arxiv.org/abs/2309.04470</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/andrewmogbolu2/blockchain-technology">https://github.com/andrewmogbolu2/blockchain-technology</a></li>
<li>paper_authors: Lydia T. Liu, Solon Barocas, Jon Kleinberg, Karen Levy</li>
<li>for: 这篇论文探讨了在社会影响领域中预测未来结果的应用，包括教育和医疗等领域。</li>
<li>methods: 论文使用了一个简单的模型，包括行动、隐藏状态和测量。</li>
<li>results: 论文发现，准确预测结果并不总是最有效的策略，即使结合其他测量。 except in cases where there is a single decisive action for improving the outcome, outcome prediction never maximizes “action value”. 在大多数情况下，测量行动可能性和隐藏状态可以大幅提高行动价值。<details>
<summary>Abstract</summary>
Predicting future outcomes is a prevalent application of machine learning in social impact domains. Examples range from predicting student success in education to predicting disease risk in healthcare. Practitioners recognize that the ultimate goal is not just to predict but to act effectively. Increasing evidence suggests that relying on outcome predictions for downstream interventions may not have desired results.   In most domains there exists a multitude of possible interventions for each individual, making the challenge of taking effective action more acute. Even when causal mechanisms connecting the individual's latent states to outcomes is well understood, in any given instance (a specific student or patient), practitioners still need to infer -- from budgeted measurements of latent states -- which of many possible interventions will be most effective for this individual. With this in mind, we ask: when are accurate predictors of outcomes helpful for identifying the most suitable intervention?   Through a simple model encompassing actions, latent states, and measurements, we demonstrate that pure outcome prediction rarely results in the most effective policy for taking actions, even when combined with other measurements. We find that except in cases where there is a single decisive action for improving the outcome, outcome prediction never maximizes "action value", the utility of taking actions. Making measurements of actionable latent states, where specific actions lead to desired outcomes, considerably enhances the action value compared to outcome prediction, and the degree of improvement depends on action costs and the outcome model. This analysis emphasizes the need to go beyond generic outcome prediction in interventional settings by incorporating knowledge of plausible actions and latent states.
</details>
<details>
<summary>摘要</summary>
预测未来结果是社会影响领域中广泛应用的机器学习技术。例如，预测教育中学生成功和医疗领域疾病风险等。专业人员认为，最终目标不仅是预测，还是实际行动。然而，有增加证据表明，仅仅基于结果预测的下游 intervención可能无法实现愿望的结果。在大多数领域中，每个个体都有多种可能的 intervención，使得选择有效行动变得更加困难。即使理解个体的 latent states 和结果之间的 causal 机制，在特定学生或病人身上，专业人员仍需从预算的 latent states 中推断哪一些 intervención 最有效。基于这点，我们问：精准的结果预测有什么帮助于确定最佳 intervención？通过一个简单的模型，包括行动、 latent states 和测量，我们表明了纯粹的结果预测在大多数情况下无法实现最有效的政策，即使与其他测量结合使用。我们发现，除非结果中存在单一的决定性行动，否则结果预测不能增加“行动价值”，即对行动的负担和结果模型。通过测量行动可触发结果的 latent states，可以显著提高行动价值，并且提高的程度取决于行动成本和结果模型。这一分析强调了在干预设定中超越普通的结果预测，通过包含可能的行动和 latent states 的知识来实现更高效的行动。
</details></li>
</ul>
<hr>
<h2 id="tSPM-a-high-performance-algorithm-for-mining-transitive-sequential-patterns-from-clinical-data"><a href="#tSPM-a-high-performance-algorithm-for-mining-transitive-sequential-patterns-from-clinical-data" class="headerlink" title="tSPM+; a high-performance algorithm for mining transitive sequential patterns from clinical data"></a>tSPM+; a high-performance algorithm for mining transitive sequential patterns from clinical data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.05671">http://arxiv.org/abs/2309.05671</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonas Hügel, Ulrich Sax, Shawn N. Murphy, Hossein Estiri</li>
<li>for: 本研究旨在开发高性能的时间序列模式挖掘算法（tSPM+），以便更好地挖掘大规模医疗数据集中的时间序列模式，并通过 Machine Learning 工作流程进行挖掘。</li>
<li>methods: 本研究使用的方法包括时间序列模式挖掘算法（tSPM）和高性能实现方法（tSPM+），以及 Docker 容器和 R 包套件，以便易于与现有的 Machine Learning 工作流程集成。</li>
<li>results: 本研究表明，使用 tSPM+ 算法可以提高速度到因子 980，并降低内存占用量达 48 倍。此外，研究还使用了 WHO 定义的 Post COVID-19 病人和其症状，并通过时间序列模式挖掘来识别这些病人。<details>
<summary>Abstract</summary>
The increasing availability of large clinical datasets collected from patients can enable new avenues for computational characterization of complex diseases using different analytic algorithms. One of the promising new methods for extracting knowledge from large clinical datasets involves temporal pattern mining integrated with machine learning workflows. However, mining these temporal patterns is a computational intensive task and has memory repercussions. Current algorithms, such as the temporal sequence pattern mining (tSPM) algorithm, are already providing promising outcomes, but still leave room for optimization. In this paper, we present the tSPM+ algorithm, a high-performance implementation of the tSPM algorithm, which adds a new dimension by adding the duration to the temporal patterns. We show that the tSPM+ algorithm provides a speed up to factor 980 and a up to 48 fold improvement in memory consumption. Moreover, we present a docker container with an R-package, We also provide vignettes for an easy integration into already existing machine learning workflows and use the mined temporal sequences to identify Post COVID-19 patients and their symptoms according to the WHO definition.
</details>
<details>
<summary>摘要</summary>
“随着巨量临床数据的可用性增加，可以开启新的可 Computational 描述复杂疾病的可能性。一种可能的新方法是在机器学习工作流程中进行时间模式挖掘，但是挖掘这些时间模式是一个 computationally 沉重的任务，需要大量的计算资源和内存。现有的算法，如时间序列模式挖掘（tSPM）算法，已经提供了有希望的结果，但还有很多的余地来进行优化。在本文中，我们提出了 tSPM+ 算法，它是 tSPM 算法的高性能实现，通过添加时间持续时间到时间模式，提供了速度因子 980 和内存使用量增加到 48 倍。此外，我们提供了一个 Docker 容器和 R 套件，并提供了绿色的范例，以便与现有的机器学习工作流程整合，并使用挖掘的时间序列来根据 WHO 定义识别 Post COVID-19 病人和其症状。”
</details></li>
</ul>
<hr>
<h2 id="Subwords-as-Skills-Tokenization-for-Sparse-Reward-Reinforcement-Learning"><a href="#Subwords-as-Skills-Tokenization-for-Sparse-Reward-Reinforcement-Learning" class="headerlink" title="Subwords as Skills: Tokenization for Sparse-Reward Reinforcement Learning"></a>Subwords as Skills: Tokenization for Sparse-Reward Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04459">http://arxiv.org/abs/2309.04459</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Yunis, Justin Jung, Falcon Dai, Matthew Walter</li>
<li>for: 实现短时间内获得奖励的环境探索是困难的，特别是在连续动作空间中，因为需要进行长时间的协调动作序列以获得任何奖励。</li>
<li>methods: 我们提出了一种新的方法，它包括将互动资料集中的交互资料转换为短时间内的动作集，然后使用这个新的动作空间来优化策略。这个方法比基eline要好，因为它不需要从动作空间中挑选整个范围。</li>
<li>results: 我们的方法在一些困难的短时间内获得奖励的环境中比基eline更好，并且需要很少的计算量进行技能生成和在线探索。<details>
<summary>Abstract</summary>
Exploration in sparse-reward reinforcement learning is difficult due to the requirement of long, coordinated sequences of actions in order to achieve any reward. Moreover, in continuous action spaces there are an infinite number of possible actions, which only increases the difficulty of exploration. One class of methods designed to address these issues forms temporally extended actions, often called skills, from interaction data collected in the same domain, and optimizes a policy on top of this new action space. Typically such methods require a lengthy pretraining phase, especially in continuous action spaces, in order to form the skills before reinforcement learning can begin. Given prior evidence that the full range of the continuous action space is not required in such tasks, we propose a novel approach to skill-generation with two components. First we discretize the action space through clustering, and second we leverage a tokenization technique borrowed from natural language processing to generate temporally extended actions. Such a method outperforms baselines for skill-generation in several challenging sparse-reward domains, and requires orders-of-magnitude less computation in skill-generation and online rollouts.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Discretize the action space through clustering.2. Leverage a tokenization technique from natural language processing to generate temporally extended actions.Our approach outperforms baselines for skill-generation in several challenging sparse-reward domains and requires significantly less computation in skill-generation and online rollouts.Simplified Chinese:探索 sparse-reward  reinforcement learning 是困难的，因为需要长时间协调的动作序列来获得任何奖励。此外，连续动作空间中有无限多个可能的动作，这只会使探索变得更加困难。一些方法使用时间扩展的动作，通常称为技能，从互动数据中的同一个领域中收集，然后优化一个策略。然而，这些方法通常需要很长的预训练阶段，特别是在连续动作空间中。基于证据表明，完整的连续动作空间不是必需的，我们提出了一种新的方法 для技能生成，具有两个组成部分：1. 使用 clustering 将动作空间细分。2. 从自然语言处理中借鉴的tokenization技术来生成时间扩展的动作。我们的方法在一些具有挑战性的 sparse-reward 领域中出perform baseline，并且需要orders-of-magnitude  less computation在技能生成和在线执行。</details></li>
</ol>
<hr>
<h2 id="Physics-Informed-Neural-Networks-for-an-optimal-counterdiabatic-quantum-computation"><a href="#Physics-Informed-Neural-Networks-for-an-optimal-counterdiabatic-quantum-computation" class="headerlink" title="Physics-Informed Neural Networks for an optimal counterdiabatic quantum computation"></a>Physics-Informed Neural Networks for an optimal counterdiabatic quantum computation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04434">http://arxiv.org/abs/2309.04434</a></li>
<li>repo_url: None</li>
<li>paper_authors: Antonio Ferrer-Sánchez, Carlos Flores-Garrigos, Carlos Hernani-Morales, José J. Orquín-Marqués, Narendra N. Hegade, Alejandro Gomez Cadavid, Iraitz Montalban, Enrique Solano, Yolanda Vives-Gilabert, José D. Martín-Guerrero</li>
<li>for: 用于解决量子电路中系统的 counterdiabatic（CD）协议，即利用物理学发现的启发式神经网络（PINNs）来准确地解决量子系统中不同物理 observable 的时间演化问题。</li>
<li>methods: 借鉴物理学的思想，将必要的物理信息嵌入到一个底层神经网络中，以有效地解决问题。在特定的情况下，我们采用 hermiticity condition 来保证获得最佳的 counterdiabatic 项，并使用了原理力动的最小化方法来实现。</li>
<li>results: 提出了一种可靠的方法来解决 CD 驱动问题，不受过去基于类型数字approximation的方法所受的限制。方法可以获得物理 observable 中的优化结果，包括时间参数函数、 gauge potential 或运算符、系统能量水平的时间演化等。在实践中，我们应用了这种方法于 $\mathrm{H_{2}$ 和 $\mathrm{LiH}$ 分子，使用 STO-3G 基准表示。结果表明可以成功地解决非adiabatic 项的归一化问题，并且这种方法在量子计算算法中具有重要的实际应用优势。<details>
<summary>Abstract</summary>
We introduce a novel methodology that leverages the strength of Physics-Informed Neural Networks (PINNs) to address the counterdiabatic (CD) protocol in the optimization of quantum circuits comprised of systems with $N_{Q}$ qubits. The primary objective is to utilize physics-inspired deep learning techniques to accurately solve the time evolution of the different physical observables within the quantum system. To accomplish this objective, we embed the necessary physical information into an underlying neural network to effectively tackle the problem. In particular, we impose the hermiticity condition on all physical observables and make use of the principle of least action, guaranteeing the acquisition of the most appropriate counterdiabatic terms based on the underlying physics. The proposed approach offers a dependable alternative to address the CD driving problem, free from the constraints typically encountered in previous methodologies relying on classical numerical approximations. Our method provides a general framework to obtain optimal results from the physical observables relevant to the problem, including the external parameterization in time known as scheduling function, the gauge potential or operator involving the non-adiabatic terms, as well as the temporal evolution of the energy levels of the system, among others. The main applications of this methodology have been the $\mathrm{H_{2}$ and $\mathrm{LiH}$ molecules, represented by a 2-qubit and 4-qubit systems employing the STO-3G basis. The presented results demonstrate the successful derivation of a desirable decomposition for the non-adiabatic terms, achieved through a linear combination utilizing Pauli operators. This attribute confers significant advantages to its practical implementation within quantum computing algorithms.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的方法，利用物理学 informed neural network（PINNs）来解决量子环境中的 counterdiabatic（CD）协议。我们的主要目标是利用物理类似深度学习技术来精确地解决量子系统中不同物理观测器的时间演化。为了完成这个目标，我们将必要的物理信息嵌入到一个基础的神经网络中，以有效地处理问题。特别是，我们将 hermiticity 条件套用到所有物理观测器上，并使用最小作用原理，以确保获得最适当的 counterdiabatic 项目，基于背景的物理。我们的方法提供了一个可靠的替代方案，用于解决 CD 驱动问题，不受前一代方法所受的传统约束。我们的方法可以实现从物理观测器中获得最佳结果，包括时间进行演化的外部化函数、 gauge 潜在或操作内含非adiabatic 项目，以及量子系统中能阶的时间演化。主要应用包括 $\rm H_2$ 和 $\rm LiH$ 分子，表示了一个 2-qubit 和 4-qubit 系统，使用 STO-3G 基底。给出的结果显示了成功地从非adiabatic 项目中获得了欲要的分解，通过一个基于 Pauli 算子的线性 комbination。这个特性具有实用实现量子 Computing 算法中的实际优势。
</details></li>
</ul>
<hr>
<h2 id="Variations-and-Relaxations-of-Normalizing-Flows"><a href="#Variations-and-Relaxations-of-Normalizing-Flows" class="headerlink" title="Variations and Relaxations of Normalizing Flows"></a>Variations and Relaxations of Normalizing Flows</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04433">http://arxiv.org/abs/2309.04433</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keegan Kelly, Lorena Piedras, Sukrit Rao, David Roth</li>
<li>for: 本研究旨在探讨 Normalizing Flows (NFs) 模型的扩展和改进，以提高其表达能力和采样效率。</li>
<li>methods: 本研究使用了一系列的改进和扩展方法，包括将 Normalizing Flows 与其他生成模型相结合，以释放其表达能力和采样速度。</li>
<li>results: 研究人员通过实验和数据分析表明，这些改进和扩展方法可以增强 Normalizing Flows 的表达能力和采样效率，同时保持其likelihood tractability和数据可靠性。<details>
<summary>Abstract</summary>
Normalizing Flows (NFs) describe a class of models that express a complex target distribution as the composition of a series of bijective transformations over a simpler base distribution. By limiting the space of candidate transformations to diffeomorphisms, NFs enjoy efficient, exact sampling and density evaluation, enabling NFs to flexibly behave as both discriminative and generative models. Their restriction to diffeomorphisms, however, enforces that input, output and all intermediary spaces share the same dimension, limiting their ability to effectively represent target distributions with complex topologies. Additionally, in cases where the prior and target distributions are not homeomorphic, Normalizing Flows can leak mass outside of the support of the target. This survey covers a selection of recent works that combine aspects of other generative model classes, such as VAEs and score-based diffusion, and in doing so loosen the strict bijectivity constraints of NFs to achieve a balance of expressivity, training speed, sample efficiency and likelihood tractability.
</details>
<details>
<summary>摘要</summary>
对象分布的描述：Normalizing Flows（NFs）是一类模型，它将复杂的目标分布表示为一系列基于简单的基分布的比例变换的组合。通过限制变换空间为抽象函数，NFs 可以实现高效、准确的采样和总体评估，使其能够作为描述性和生成模型。然而，NFs 的假设均为抽象函数限制了输入、输出和所有中间空间的维度相同，这限制了它们对复杂分布的表示能力。此外，当先验分布和目标分布不同映射时，Normalizing Flows 可能会导致流出先验分布的质量。这篇评论汇聚了一些最近的工作，它们将其他生成模型类型，如 VAEs 和 score-based diffusion 的特点与 Normalizing Flows 结合，以适应不同的应用场景。这些工作通过放宽 Normalizing Flows 的假设，以达到表达能力、训练速度、采样效率和可评估性的平衡。
</details></li>
</ul>
<hr>
<h2 id="Create-Your-World-Lifelong-Text-to-Image-Diffusion"><a href="#Create-Your-World-Lifelong-Text-to-Image-Diffusion" class="headerlink" title="Create Your World: Lifelong Text-to-Image Diffusion"></a>Create Your World: Lifelong Text-to-Image Diffusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04430">http://arxiv.org/abs/2309.04430</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gan Sun, Wenqi Liang, Jiahua Dong, Jun Li, Zhengming Ding, Yang Cong</li>
<li>for: 创造用户自己的概念世界，即通过文本提示生成用户自己的概念图像。</li>
<li>methods: 提出了一种具有知识紧急忘记和semantic紧急忽略的文本到图像扩散模型（L2DM），通过任务意识增强模块和灵活概念融合模块来解决知识紧急忘记问题，并通过概念注意艺术家模块和正交注意模块来解决semantic紧急忽略问题。</li>
<li>results: 在比较 related state-of-the-art 模型时，our model可以在不同的 continual text prompts 下生成更 faithful 的图像，both in terms of qualitative and quantitative metrics。<details>
<summary>Abstract</summary>
Text-to-image generative models can produce diverse high-quality images of concepts with a text prompt, which have demonstrated excellent ability in image generation, image translation, etc. We in this work study the problem of synthesizing instantiations of a use's own concepts in a never-ending manner, i.e., create your world, where the new concepts from user are quickly learned with a few examples. To achieve this goal, we propose a Lifelong text-to-image Diffusion Model (L2DM), which intends to overcome knowledge "catastrophic forgetting" for the past encountered concepts, and semantic "catastrophic neglecting" for one or more concepts in the text prompt. In respect of knowledge "catastrophic forgetting", our L2DM framework devises a task-aware memory enhancement module and a elastic-concept distillation module, which could respectively safeguard the knowledge of both prior concepts and each past personalized concept. When generating images with a user text prompt, the solution to semantic "catastrophic neglecting" is that a concept attention artist module can alleviate the semantic neglecting from concept aspect, and an orthogonal attention module can reduce the semantic binding from attribute aspect. To the end, our model can generate more faithful image across a range of continual text prompts in terms of both qualitative and quantitative metrics, when comparing with the related state-of-the-art models. The code will be released at https://wenqiliang.github.io/.
</details>
<details>
<summary>摘要</summary>
文本到图生成模型可以生成多种高质量图像，用文本提示来描述概念，并达到图像生成、图像翻译等领域的出色表现。在这项工作中，我们研究如何通过不断创造用户自己的概念实例，即“创造你的世界”，使用户的新概念快速学习。为了实现这个目标，我们提出了一种生命long text-to-image扩散模型（L2DM），用于解决知识“悖论”和 semantic “悖论”问题。在知识“悖论”方面，L2DM框架启用任务意识增强模块和灵活概念精炼模块，可以分别保护以前所遇到的概念知识和每个个人化的概念知识。在生成用户文本提示图像时，对 semantic “悖论”问题的解决方式是通过概念注意力艺术模块和 ortogonal注意力模块来减少概念忽视和属性绑定。因此，我们的模型可以在不同的 continual text prompts 下生成更 faithful 的图像，并且在质量和量度上都达到了相对的提升。代码将在 <https://wenqiliang.github.io/> 上发布。
</details></li>
</ul>
<hr>
<h2 id="Advanced-Computing-and-Related-Applications-Leveraging-Brain-inspired-Spiking-Neural-Networks"><a href="#Advanced-Computing-and-Related-Applications-Leveraging-Brain-inspired-Spiking-Neural-Networks" class="headerlink" title="Advanced Computing and Related Applications Leveraging Brain-inspired Spiking Neural Networks"></a>Advanced Computing and Related Applications Leveraging Brain-inspired Spiking Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04426">http://arxiv.org/abs/2309.04426</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lyuyang Sima, Joseph Bucukovski, Erwan Carlson, Nicole L. Yien</li>
<li>for: 本研究旨在为新手研究领域的同仁提供一种系统性的学习概念和研究方向，探讨了脑灵模型的优缺点和适用性，以及脑灵网络算法和无监督学习算法的概念和研究进展。</li>
<li>methods: 本研究通过对五种脑灵模型的优缺点和适用性进行梳理，分析了五种网络拓扑的特点，并概述了基于synaptic plasticity规则的无监督学习算法和四种监督学习算法的研究进展。</li>
<li>results: 本研究对脑灵网络算法的概念和研究进展进行了报告和分析，并对国内外的脑灵neuromorphic芯片的研究进行了评论和分析。<details>
<summary>Abstract</summary>
In the rapid evolution of next-generation brain-inspired artificial intelligence and increasingly sophisticated electromagnetic environment, the most bionic characteristics and anti-interference performance of spiking neural networks show great potential in terms of computational speed, real-time information processing, and spatio-temporal information processing. Data processing. Spiking neural network is one of the cores of brain-like artificial intelligence, which realizes brain-like computing by simulating the structure and information transfer mode of biological neural networks. This paper summarizes the strengths, weaknesses and applicability of five neuronal models and analyzes the characteristics of five network topologies; then reviews the spiking neural network algorithms and summarizes the unsupervised learning algorithms based on synaptic plasticity rules and four types of supervised learning algorithms from the perspectives of unsupervised learning and supervised learning; finally focuses on the review of brain-like neuromorphic chips under research at home and abroad. This paper is intended to provide learning concepts and research orientations for the peers who are new to the research field of spiking neural networks through systematic summaries.
</details>
<details>
<summary>摘要</summary>
在Next-generation brain-inspired artificial intelligence的快速演化和日益复杂的电磁环境中，具有最高生物化特征和抗干扰性能的脉冲神经网络表现出了很大的潜力，包括计算速度、实时信息处理和空间时间信息处理。数据处理。脉冲神经网络是人工智能中的核心之一，通过模拟生物神经网络的结构和信息传递方式来实现脑内样式计算。本文对五种神经元模型的优缺点和适用场景进行总结，然后分析了五种网络拓扑的特点，最后评论了国内外的脑系模块 chip 的研究进展。本文的目的是为研究领域新手提供系统性的学习概念和研究方向，以帮助他们更好地了解脉冲神经网络的研究领域。
</details></li>
</ul>
<hr>
<h2 id="SynthoGestures-A-Novel-Framework-for-Synthetic-Dynamic-Hand-Gesture-Generation-for-Driving-Scenarios"><a href="#SynthoGestures-A-Novel-Framework-for-Synthetic-Dynamic-Hand-Gesture-Generation-for-Driving-Scenarios" class="headerlink" title="SynthoGestures: A Novel Framework for Synthetic Dynamic Hand Gesture Generation for Driving Scenarios"></a>SynthoGestures: A Novel Framework for Synthetic Dynamic Hand Gesture Generation for Driving Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04421">http://arxiv.org/abs/2309.04421</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amrgomaaelhady/synthogestures">https://github.com/amrgomaaelhady/synthogestures</a></li>
<li>paper_authors: Amr Gomaa, Robin Zitt, Guillermo Reyes, Antonio Krüger</li>
<li>for: 这篇论文旨在提供一种用于生成人工智能人机界面的自动驾驶领域的手势数据集的创新性方法。</li>
<li>methods: 该方法使用虚拟3D模型生成手势数据集，并提供了自定义选项和降低欠拟合风险。它还模拟了不同的摄像头位置和类型，包括RGB、红外和深度摄像头。</li>
<li>results: 实验结果表明，该方法可以提高手势识别精度，并可以取代或补充真实手势数据集。这种方法可以节省时间和劳动力来创建数据集，因此加速了人机界面的开发。<details>
<summary>Abstract</summary>
Creating a diverse and comprehensive dataset of hand gestures for dynamic human-machine interfaces in the automotive domain can be challenging and time-consuming. To overcome this challenge, we propose using synthetic gesture datasets generated by virtual 3D models. Our framework utilizes Unreal Engine to synthesize realistic hand gestures, offering customization options and reducing the risk of overfitting. Multiple variants, including gesture speed, performance, and hand shape, are generated to improve generalizability. In addition, we simulate different camera locations and types, such as RGB, infrared, and depth cameras, without incurring additional time and cost to obtain these cameras. Experimental results demonstrate that our proposed framework, SynthoGestures\footnote{\url{https://github.com/amrgomaaelhady/SynthoGestures}, improves gesture recognition accuracy and can replace or augment real-hand datasets. By saving time and effort in the creation of the data set, our tool accelerates the development of gesture recognition systems for automotive applications.
</details>
<details>
<summary>摘要</summary>
创建一个多样化和完整的手势数据集 для动态人机界面在汽车领域可能是困难和耗时的。为了解决这个挑战，我们提议使用虚拟3D模型生成的 sintetic手势数据集。我们的框架使用Unreal Engine生成真实的手势，提供自定义选项，降低遮挡风险。多种变体，包括手势速度、性能和手形，被生成以提高泛化性。此外，我们模拟了不同的摄像头位置和类型，如RGB、红外和深度摄像头，而无需额外的时间和成本来获得这些摄像头。实验结果表明，我们提议的框架SynthoGestures\footnote{\url{https://github.com/amrgomaaelhady/SynthoGestures}，可以提高手势识别精度，并可以取代或补充真正的手势数据集。通过节省时间和努力来创建数据集，我们的工具加速了汽车应用程序的手势识别系统的开发。
</details></li>
</ul>
<hr>
<h2 id="Privacy-Preserving-Federated-Learning-with-Convolutional-Variational-Bottlenecks"><a href="#Privacy-Preserving-Federated-Learning-with-Convolutional-Variational-Bottlenecks" class="headerlink" title="Privacy Preserving Federated Learning with Convolutional Variational Bottlenecks"></a>Privacy Preserving Federated Learning with Convolutional Variational Bottlenecks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04515">http://arxiv.org/abs/2309.04515</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Scheliga, Patrick Mäder, Marco Seeland</li>
<li>for: 防止梯度泄露攻击，保护训练数据隐私。</li>
<li>methods: 使用Variational Modeling实现隐私保护，并对梯度泄露攻击进行分析。</li>
<li>results: 提出了一种新的隐私模块—卷积秘密瓶颈（CVB），可以在潜在攻击的情况下保持隐私。对三种模型和六个图像分类 datasets进行了广泛的实验研究，并证明了CVB的有效性。<details>
<summary>Abstract</summary>
Gradient inversion attacks are an ubiquitous threat in federated learning as they exploit gradient leakage to reconstruct supposedly private training data. Recent work has proposed to prevent gradient leakage without loss of model utility by incorporating a PRivacy EnhanCing mODulE (PRECODE) based on variational modeling. Without further analysis, it was shown that PRECODE successfully protects against gradient inversion attacks. In this paper, we make multiple contributions. First, we investigate the effect of PRECODE on gradient inversion attacks to reveal its underlying working principle. We show that variational modeling introduces stochasticity into the gradients of PRECODE and the subsequent layers in a neural network. The stochastic gradients of these layers prevent iterative gradient inversion attacks from converging. Second, we formulate an attack that disables the privacy preserving effect of PRECODE by purposefully omitting stochastic gradients during attack optimization. To preserve the privacy preserving effect of PRECODE, our analysis reveals that variational modeling must be placed early in the network. However, early placement of PRECODE is typically not feasible due to reduced model utility and the exploding number of additional model parameters. Therefore, as a third contribution, we propose a novel privacy module -- the Convolutional Variational Bottleneck (CVB) -- that can be placed early in a neural network without suffering from these drawbacks. We conduct an extensive empirical study on three seminal model architectures and six image classification datasets. We find that all architectures are susceptible to gradient leakage attacks, which can be prevented by our proposed CVB. Compared to PRECODE, we show that our novel privacy module requires fewer trainable parameters, and thus computational and communication costs, to effectively preserve privacy.
</details>
<details>
<summary>摘要</summary>
Gradient倒转攻击是聚合学习中普遍存在的威胁，它们利用梯度泄露来重构被认为是私有的训练数据。 recent work 提出了防止梯度泄露而不失去模型效用的方法，基于隐私提升模型（PRECODE）的variational modeling。 without further analysis, it was shown that PRECODE successfully protects against gradient inversion attacks. In this paper, we make multiple contributions. First, we investigate the effect of PRECODE on gradient inversion attacks to reveal its underlying working principle. We show that variational modeling introduces stochasticity into the gradients of PRECODE and the subsequent layers in a neural network. The stochastic gradients of these layers prevent iterative gradient inversion attacks from converging. Second, we formulate an attack that disables the privacy preserving effect of PRECODE by purposefully omitting stochastic gradients during attack optimization. To preserve the privacy preserving effect of PRECODE, our analysis reveals that variational modeling must be placed early in the network. However, early placement of PRECODE is typically not feasible due to reduced model utility and the exploding number of additional model parameters. Therefore, as a third contribution, we propose a novel privacy module -- the Convolutional Variational Bottleneck (CVB) -- that can be placed early in a neural network without suffering from these drawbacks. We conduct an extensive empirical study on three seminal model architectures and six image classification datasets. We find that all architectures are susceptible to gradient leakage attacks, which can be prevented by our proposed CVB. Compared to PRECODE, we show that our novel privacy module requires fewer trainable parameters, and thus computational and communication costs, to effectively preserve privacy.
</details></li>
</ul>
<hr>
<h2 id="Generalization-Bounds-Perspectives-from-Information-Theory-and-PAC-Bayes"><a href="#Generalization-Bounds-Perspectives-from-Information-Theory-and-PAC-Bayes" class="headerlink" title="Generalization Bounds: Perspectives from Information Theory and PAC-Bayes"></a>Generalization Bounds: Perspectives from Information Theory and PAC-Bayes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04381">http://arxiv.org/abs/2309.04381</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fredrik Hellström, Giuseppe Durisi, Benjamin Guedj, Maxim Raginsky</li>
<li>for: 本研究旨在探讨机器学习理论中的泛化问题，尤其是PAC-Bayesian方法的应用和扩展。</li>
<li>methods: 本研究使用了信息理论的视角来探讨泛化问题，并与PAC-Bayesian方法的信息论派 connexion。</li>
<li>results: 本研究提供了一个统一的对待方法，并证明了许多泛化证明和PAC-Bayesian方法之间的相似性。 特别是，本研究强调了 conditional mutual information（CMI）框架，信息复杂度的分析，以及应用于深度学习等领域。<details>
<summary>Abstract</summary>
A fundamental question in theoretical machine learning is generalization. Over the past decades, the PAC-Bayesian approach has been established as a flexible framework to address the generalization capabilities of machine learning algorithms, and design new ones. Recently, it has garnered increased interest due to its potential applicability for a variety of learning algorithms, including deep neural networks. In parallel, an information-theoretic view of generalization has developed, wherein the relation between generalization and various information measures has been established. This framework is intimately connected to the PAC-Bayesian approach, and a number of results have been independently discovered in both strands. In this monograph, we highlight this strong connection and present a unified treatment of generalization. We present techniques and results that the two perspectives have in common, and discuss the approaches and interpretations that differ. In particular, we demonstrate how many proofs in the area share a modular structure, through which the underlying ideas can be intuited. We pay special attention to the conditional mutual information (CMI) framework; analytical studies of the information complexity of learning algorithms; and the application of the proposed methods to deep learning. This monograph is intended to provide a comprehensive introduction to information-theoretic generalization bounds and their connection to PAC-Bayes, serving as a foundation from which the most recent developments are accessible. It is aimed broadly towards researchers with an interest in generalization and theoretical machine learning.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Beyond-Static-Datasets-A-Deep-Interaction-Approach-to-LLM-Evaluation"><a href="#Beyond-Static-Datasets-A-Deep-Interaction-Approach-to-LLM-Evaluation" class="headerlink" title="Beyond Static Datasets: A Deep Interaction Approach to LLM Evaluation"></a>Beyond Static Datasets: A Deep Interaction Approach to LLM Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04369">http://arxiv.org/abs/2309.04369</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiatong Li, Rui Li, Qi Liu</li>
<li>for: 评估大语言模型（LLMs）的能力在各种现实世界任务中，以提高LLMs的评估方法。</li>
<li>methods: 提出了一种基于深度交互的LLM评估框架，通过 LLMS 在 elaborately 设计的评估任务中的深度交互来评估其在现实世界中的表现。</li>
<li>results: 通过了四个 elaborately 设计的评估任务的实验，证明了该方法的效iveness。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have made progress in various real-world tasks, which stimulates requirements for the evaluation of LLMs. Existing LLM evaluation methods are mainly supervised signal-based which depends on static datasets and cannot evaluate the ability of LLMs in dynamic real-world scenarios where deep interaction widely exists. Other LLM evaluation methods are human-based which are costly and time-consuming and are incapable of large-scale evaluation of LLMs. To address the issues above, we propose a novel Deep Interaction-based LLM-evaluation framework. In our proposed framework, LLMs' performances in real-world domains can be evaluated from their deep interaction with other LLMs in elaborately designed evaluation tasks. Furthermore, our proposed framework is a general evaluation method that can be applied to a host of real-world tasks such as machine translation and code generation. We demonstrate the effectiveness of our proposed method through extensive experiments on four elaborately designed evaluation tasks.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese)大型语言模型（LLM）在不同的实际任务中进步，这些进步刺激了 LLM 的评估需求。现有的 LLM 评估方法主要是指导信号基的，它们依赖于静态数据集，无法评估 LLM 在动态实际场景中的能力。其他 LLM 评估方法是人类基的，成本和时间开销高，不能大规模评估 LLM。为解决这些问题，我们提出了一种深度互动基本 LLM 评估框架。在我们的提议中， LLM 的实际领域表现可以通过它们在其他 LLM 之间的深度互动来评估。此外，我们的提议框架是一种通用的评估方法，可以应用于多种实际任务，如机器翻译和代码生成。我们通过了四个 elaborate 的评估任务进行了广泛的实验，以证明我们的提议方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Active-Learning-for-Classifying-2D-Grid-Based-Level-Completability"><a href="#Active-Learning-for-Classifying-2D-Grid-Based-Level-Completability" class="headerlink" title="Active Learning for Classifying 2D Grid-Based Level Completability"></a>Active Learning for Classifying 2D Grid-Based Level Completability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04367">http://arxiv.org/abs/2309.04367</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mahsabazzaz/level-completabilty-x-active-learning">https://github.com/mahsabazzaz/level-completabilty-x-active-learning</a></li>
<li>paper_authors: Mahsa Bazzaz, Seth Cooper</li>
<li>for: 本研究旨在使用活动学习方法来评估生成器生成的关卡完成度。</li>
<li>methods: 本研究使用了深度学习模型来训练关卡完成度分类器，并通过活动学习方法来选择需要标注的关卡。</li>
<li>results: 研究结果显示，使用活动学习方法来标注关卡可以获得更高的分类器性能，而不需要更多的标注数据。<details>
<summary>Abstract</summary>
Determining the completability of levels generated by procedural generators such as machine learning models can be challenging, as it can involve the use of solver agents that often require a significant amount of time to analyze and solve levels. Active learning is not yet widely adopted in game evaluations, although it has been used successfully in natural language processing, image and speech recognition, and computer vision, where the availability of labeled data is limited or expensive. In this paper, we propose the use of active learning for learning level completability classification. Through an active learning approach, we train deep-learning models to classify the completability of generated levels for Super Mario Bros., Kid Icarus, and a Zelda-like game. We compare active learning for querying levels to label with completability against random queries. Our results show using an active learning approach to label levels results in better classifier performance with the same amount of labeled data.
</details>
<details>
<summary>摘要</summary>
确定生成器生成的水平的可完成性可以是一项具有挑战性的任务，因为它可能需要使用解决者代理，这些代理经常需要较长的时间来分析和解决水平。在游戏评估中，活动学习还没有广泛采用， although it has been successfully applied in自然语言处理、图像和语音识别以及计算机视觉等领域，其中数据的可用性是有限的或昂贵的。在本文中，我们提议使用活动学习来学习生成器生成的水平可完成性分类。通过活动学习的方式，我们使用深度学习模型来类ifying生成器生成的水平的可完成性，并对Super Mario Bros., Kid Icarus和一款 Zelda-like 游戏进行了实验。我们比较了使用活动学习查询水平是否可以完成的 Label 与随机查询的性能。我们的结果表明，使用活动学习方法来标注水平的可完成性可以获得更好的分类器性能，只需要与传统的随机查询相同的数据量。
</details></li>
</ul>
<hr>
<h2 id="Systematic-Review-of-Techniques-in-Brain-Image-Synthesis-using-Deep-Learning"><a href="#Systematic-Review-of-Techniques-in-Brain-Image-Synthesis-using-Deep-Learning" class="headerlink" title="Systematic Review of Techniques in Brain Image Synthesis using Deep Learning"></a>Systematic Review of Techniques in Brain Image Synthesis using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04511">http://arxiv.org/abs/2309.04511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shubham Singh, Ammar Ranapurwala, Mrunal Bewoor, Sheetal Patil, Satyam Rai</li>
<li>for: 本文探讨医学成像领域的当前状况，尤其是利用深度学习技术进行大脑成像synthesis。</li>
<li>methods: 本文详细介绍了不同的方法和技术，包括2D to 3D constructions、MRI synthesis以及使用transformers。</li>
<li>results: 本文总结了这些方法的限制和挑战，并探讨未来这个领域的发展前景和深度学习技术在医学成像领域的潜在影响。<details>
<summary>Abstract</summary>
This review paper delves into the present state of medical imaging, with a specific focus on the use of deep learning techniques for brain image synthesis. The need for medical image synthesis to improve diagnostic accuracy and decrease invasiveness in medical procedures is emphasized, along with the role of deep learning in enabling these advancements. The paper examines various methods and techniques for brain image synthesis, including 2D to 3D constructions, MRI synthesis, and the use of transformers. It also addresses limitations and challenges faced in these methods, such as obtaining well-curated training data and addressing brain ultrasound issues. The review concludes by exploring the future potential of this field and the opportunities for further advancements in medical imaging using deep learning techniques. The significance of transformers and their potential to revolutionize the medical imaging field is highlighted. Additionally, the paper discusses the potential solutions to the shortcomings and limitations faced in this field. The review provides researchers with an updated reference on the present state of the field and aims to inspire further research and bridge the gap between the present state of medical imaging and the future possibilities offered by deep learning techniques.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Zero-Shot-Robustification-of-Zero-Shot-Models-With-Foundation-Models"><a href="#Zero-Shot-Robustification-of-Zero-Shot-Models-With-Foundation-Models" class="headerlink" title="Zero-Shot Robustification of Zero-Shot Models With Foundation Models"></a>Zero-Shot Robustification of Zero-Shot Models With Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04344">http://arxiv.org/abs/2309.04344</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sprocketlab/roboshot">https://github.com/sprocketlab/roboshot</a></li>
<li>paper_authors: Dyah Adila, Changho Shin, Linrong Cai, Frederic Sala</li>
<li>for: 提高预训练模型的Robustness和Zero-shot推理能力</li>
<li>methods: 使用零shot语言模型获取任务描述中有用的信息，并使用这些信息来修正预训练模型的嵌入。</li>
<li>results: 对九个图像和自然语言处理任务进行评估，与多种零shot基线比较，平均提高15.98%。同时，RoboShotCompatible with多种预训练模型和语言模型。<details>
<summary>Abstract</summary>
Zero-shot inference is a powerful paradigm that enables the use of large pretrained models for downstream classification tasks without further training. However, these models are vulnerable to inherited biases that can impact their performance. The traditional solution is fine-tuning, but this undermines the key advantage of pretrained models, which is their ability to be used out-of-the-box. We propose RoboShot, a method that improves the robustness of pretrained model embeddings in a fully zero-shot fashion. First, we use zero-shot language models (LMs) to obtain useful insights from task descriptions. These insights are embedded and used to remove harmful and boost useful components in embeddings -- without any supervision. Theoretically, we provide a simple and tractable model for biases in zero-shot embeddings and give a result characterizing under what conditions our approach can boost performance. Empirically, we evaluate RoboShot on nine image and NLP classification tasks and show an average improvement of 15.98% over several zero-shot baselines. Additionally, we demonstrate that RoboShot is compatible with a variety of pretrained and language models.
</details>
<details>
<summary>摘要</summary>
zero-shot推理是一种强大的概念，它允许使用大规模预训练模型来进行下游分类任务，无需进一步训练。然而，这些模型受到遗传的偏见的影响，这可能会影响其性能。传统的解决方案是细化，但这会消除预训练模型的优势，即可以直接使用。我们提出了RoboShot，一种方法，可以在完全零shot的方式下提高预训练模型的坚持性。首先，我们使用零shot语言模型（LM）来获得有用的洞察 FROM task descriptions。这些洞察被嵌入并用于从预训练模型中移除害虫和提高有用的组件，无需任何监督。理论上，我们提供了零shot偏见的简单和可追踪的模型，并给出了在哪些条件下，我们的方法可以提高性能。Empirically，我们在九个图像和NLP分类任务上评估了RoboShot，并显示了15.98%的均值提升，相比于多个零shot基线。此外，我们也证明了RoboShot与多种预训练和语言模型相容。
</details></li>
</ul>
<hr>
<h2 id="Online-Submodular-Maximization-via-Online-Convex-Optimization"><a href="#Online-Submodular-Maximization-via-Online-Convex-Optimization" class="headerlink" title="Online Submodular Maximization via Online Convex Optimization"></a>Online Submodular Maximization via Online Convex Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04339">http://arxiv.org/abs/2309.04339</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tareq Si-Salem, Gözde Özcan, Iasonas Nikolaou, Evimaria Terzi, Stratis Ioannidis</li>
<li>for: 研究 monotone submodular maximization under general matroid constraints 的在线设定下的优化问题。</li>
<li>methods: 使用 online convex optimization (OCO) 来优化大量的 submodular functions，即Weighted threshold potential functions。</li>
<li>results: 可以通过 OCO 策略和合适的轮减方案来实现 sublinear regret 在 combinatorial 设定下。<details>
<summary>Abstract</summary>
We study monotone submodular maximization under general matroid constraints in the online setting. We prove that online optimization of a large class of submodular functions, namely, weighted threshold potential functions, reduces to online convex optimization (OCO). This is precisely because functions in this class admit a concave relaxation; as a result, OCO policies, coupled with an appropriate rounding scheme, can be used to achieve sublinear regret in the combinatorial setting. We show that our reduction extends to many different versions of the online learning problem, including the dynamic regret, bandit, and optimistic-learning settings.
</details>
<details>
<summary>摘要</summary>
我们研究简单幂函数最大化在通用环境中的在线Setting下。我们证明在线优化一种大类型的简单幂函数，即有重量的阈值 potential functions，可以降为在线凸优化（OCO）。这是因为这种函数允许一种凹降函数的抽象，因此OCO策略，结合适当的舒缓策略，可以实现在 combinatorial 设置下的减少 regret。我们证明我们的减少扩展到许多不同的在线学习问题，包括动态 regret、bandit 和 optimistic-learning 设置。
</details></li>
</ul>
<hr>
<h2 id="Graph-Neural-Networks-Use-Graphs-When-They-Shouldn’t"><a href="#Graph-Neural-Networks-Use-Graphs-When-They-Shouldn’t" class="headerlink" title="Graph Neural Networks Use Graphs When They Shouldn’t"></a>Graph Neural Networks Use Graphs When They Shouldn’t</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04332">http://arxiv.org/abs/2309.04332</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mayabechlerspeicher/Graph_Neural_Networks_Overfit_Graphs">https://github.com/mayabechlerspeicher/Graph_Neural_Networks_Overfit_Graphs</a></li>
<li>paper_authors: Maya Bechler-Speicher, Ido Amos, Ran Gilad-Bachrach, Amir Globerson</li>
<li>for: 本研究探讨了Graph Neural Networks（GNNs）在不同graph distribution中对graph structure的学习情况。</li>
<li>methods: 本研究使用了GNNs学习graph数据，并通过graph editing方法来 Mitigate GNNs对不必要的graph structure的过拟合。</li>
<li>results: 研究发现，GNNs在某些graph distribution中有很强的过拟合行为，而且reguler graphs更为稳定。此外，研究还提供了一种理论解释，asserting that GNNs的学习过程受到了gradient descent的偏见。最后，研究表明，通过graph editing方法可以提高GNNs的准确率。<details>
<summary>Abstract</summary>
Predictions over graphs play a crucial role in various domains, including social networks, molecular biology, medicine, and more. Graph Neural Networks (GNNs) have emerged as the dominant approach for learning on graph data. Instances of graph labeling problems consist of the graph-structure (i.e., the adjacency matrix), along with node-specific feature vectors. In some cases, this graph-structure is non-informative for the predictive task. For instance, molecular properties such as molar mass depend solely on the constituent atoms (node features), and not on the molecular structure. While GNNs have the ability to ignore the graph-structure in such cases, it is not clear that they will. In this work, we show that GNNs actually tend to overfit the graph-structure in the sense that they use it even when a better solution can be obtained by ignoring it. We examine this phenomenon with respect to different graph distributions and find that regular graphs are more robust to this overfitting. We then provide a theoretical explanation for this phenomenon, via analyzing the implicit bias of gradient-descent-based learning of GNNs in this setting. Finally, based on our empirical and theoretical findings, we propose a graph-editing method to mitigate the tendency of GNNs to overfit graph-structures that should be ignored. We show that this method indeed improves the accuracy of GNNs across multiple benchmarks.
</details>
<details>
<summary>摘要</summary>
Graph predictions play a crucial role in various domains, including social networks, molecular biology, and medicine. Graph Neural Networks (GNNs) have emerged as the dominant approach for learning on graph data. Instances of graph labeling problems consist of the graph structure (i.e., the adjacency matrix) and node-specific feature vectors. In some cases, the graph structure is non-informative for the predictive task, such as molecular properties that depend solely on the constituent atoms (node features) and not on the molecular structure. While GNNs have the ability to ignore the graph structure in such cases, it is not clear that they will. In this work, we show that GNNs tend to overfit the graph structure, using it even when a better solution can be obtained by ignoring it. We examine this phenomenon with respect to different graph distributions and find that regular graphs are more robust to this overfitting. We then provide a theoretical explanation for this phenomenon, via analyzing the implicit bias of gradient-descent-based learning of GNNs in this setting. Finally, based on our empirical and theoretical findings, we propose a graph-editing method to mitigate the tendency of GNNs to overfit graph structures that should be ignored. We show that this method improves the accuracy of GNNs across multiple benchmarks.Here is the translation in Traditional Chinese:Graph predictions play a crucial role in various domains, including social networks, molecular biology, and medicine. Graph Neural Networks (GNNs) have emerged as the dominant approach for learning on graph data. Instances of graph labeling problems consist of the graph structure (i.e., the adjacency matrix) and node-specific feature vectors. In some cases, the graph structure is non-informative for the predictive task, such as molecular properties that depend solely on the constituent atoms (node features) and not on the molecular structure. While GNNs have the ability to ignore the graph structure in such cases, it is not clear that they will. In this work, we show that GNNs tend to overfit the graph structure, using it even when a better solution can be obtained by ignoring it. We examine this phenomenon with respect to different graph distributions and find that regular graphs are more robust to this overfitting. We then provide a theoretical explanation for this phenomenon, via analyzing the implicit bias of gradient-descent-based learning of GNNs in this setting. Finally, based on our empirical and theoretical findings, we propose a graph-editing method to mitigate the tendency of GNNs to overfit graph structures that should be ignored. We show that this method improves the accuracy of GNNs across multiple benchmarks.
</details></li>
</ul>
<hr>
<h2 id="Incremental-Learning-of-Humanoid-Robot-Behavior-from-Natural-Interaction-and-Large-Language-Models"><a href="#Incremental-Learning-of-Humanoid-Robot-Behavior-from-Natural-Interaction-and-Large-Language-Models" class="headerlink" title="Incremental Learning of Humanoid Robot Behavior from Natural Interaction and Large Language Models"></a>Incremental Learning of Humanoid Robot Behavior from Natural Interaction and Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04316">http://arxiv.org/abs/2309.04316</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leonard Bärmann, Rainer Kartmann, Fabian Peller-Konrad, Alex Waibel, Tamim Asfour</li>
<li>for: 本研究旨在将人工智能给机器人，以便实现人机合作的自然语言对话。</li>
<li>methods: 本研究使用大量语言模型（LLMs）来高级掌控机器人的行为，通过在互动式终端机中透过人类指令、环境观察和执行结果来对LMM进行反馈，从而生成下一个陈述。</li>
<li>results: 本研究实现了机器人在进行互动式学习时的增量学习，并在 simulations 和实际情况中进行评估，展示了对多种任务的通用增量学习能力。<details>
<summary>Abstract</summary>
Natural-language dialog is key for intuitive human-robot interaction. It can be used not only to express humans' intents, but also to communicate instructions for improvement if a robot does not understand a command correctly. Of great importance is to endow robots with the ability to learn from such interaction experience in an incremental way to allow them to improve their behaviors or avoid mistakes in the future. In this paper, we propose a system to achieve incremental learning of complex behavior from natural interaction, and demonstrate its implementation on a humanoid robot. Building on recent advances, we present a system that deploys Large Language Models (LLMs) for high-level orchestration of the robot's behavior, based on the idea of enabling the LLM to generate Python statements in an interactive console to invoke both robot perception and action. The interaction loop is closed by feeding back human instructions, environment observations, and execution results to the LLM, thus informing the generation of the next statement. Specifically, we introduce incremental prompt learning, which enables the system to interactively learn from its mistakes. For that purpose, the LLM can call another LLM responsible for code-level improvements of the current interaction based on human feedback. The improved interaction is then saved in the robot's memory, and thus retrieved on similar requests. We integrate the system in the robot cognitive architecture of the humanoid robot ARMAR-6 and evaluate our methods both quantitatively (in simulation) and qualitatively (in simulation and real-world) by demonstrating generalized incrementally-learned knowledge.
</details>
<details>
<summary>摘要</summary>
人工智能对话是人机交互的关键，可以不仅表达人类的意图，还可以通过对缺失指令的通信来传达 instrucciones 。对于 robots 来说，授予其能够通过交互经验学习，以便在未来避免错误或改善行为。在这篇论文中，我们提出了一种实现复杂行为的逐步学习系统，并在人工智能大语言模型（LLM）的基础上实现了高级别的行为编导。我们建立了一个交互循环，其中人类指令、环境观察和执行结果被反馈给 LLM，以便生成下一句语句。特别是，我们引入了逐步提问学习，这使得系统可以通过自己的错误来学习。为此，LLM可以调用另一个 LLM，以便基于人类反馈进行代码级别的改进。改进后的交互被保存在机器人的记忆中，并在相似的请求时被重新使用。我们在人工智能杂质机器人 ARMAR-6 的认知架构中集成了系统，并在模拟和真实环境中进行了评估，并表明了通过逐步学习获得的普遍化知识。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-for-Early-Dropout-Prediction-on-Healthy-Ageing-Applications"><a href="#Federated-Learning-for-Early-Dropout-Prediction-on-Healthy-Ageing-Applications" class="headerlink" title="Federated Learning for Early Dropout Prediction on Healthy Ageing Applications"></a>Federated Learning for Early Dropout Prediction on Healthy Ageing Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04311">http://arxiv.org/abs/2309.04311</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christos Chrysanthos Nikolaidis, Vasileios Perifanis, Nikolaos Pavlidis, Pavlos S. Efraimidis</li>
<li>for: 这 paper 是关于社会护理应用的研究，旨在提高老年人的生活质量，并帮助操作人员提供早期干预。</li>
<li>methods: 这 paper 使用了机器学习（ML）算法，实现了高度准确的预测，超过传统统计方法的cope能力。</li>
<li>results: 研究表明， federated machine learning（FML）方法可以减轻隐私问题，实现分布式训练，无需传输个人数据。该方法在实际数据集上进行了评估，并提出了数据选择和类别不平衡处理技术，以提高模型在非独立Identical分布（non-iid）数据上的预测精度。<details>
<summary>Abstract</summary>
The provision of social care applications is crucial for elderly people to improve their quality of life and enables operators to provide early interventions. Accurate predictions of user dropouts in healthy ageing applications are essential since they are directly related to individual health statuses. Machine Learning (ML) algorithms have enabled highly accurate predictions, outperforming traditional statistical methods that struggle to cope with individual patterns. However, ML requires a substantial amount of data for training, which is challenging due to the presence of personal identifiable information (PII) and the fragmentation posed by regulations. In this paper, we present a federated machine learning (FML) approach that minimizes privacy concerns and enables distributed training, without transferring individual data. We employ collaborative training by considering individuals and organizations under FML, which models both cross-device and cross-silo learning scenarios. Our approach is evaluated on a real-world dataset with non-independent and identically distributed (non-iid) data among clients, class imbalance and label ambiguity. Our results show that data selection and class imbalance handling techniques significantly improve the predictive accuracy of models trained under FML, demonstrating comparable or superior predictive performance than traditional ML models.
</details>
<details>
<summary>摘要</summary>
提供社会护理应用程序对老年人的生活质量有着关键作用，可以帮助运营商提供早期干预。准确预测健康年龄应用程序用户退出是直接关系到个人健康状况。机器学习（ML）算法可以实现非常高精度预测，超出传统统计方法的cope能力。然而，ML需要训练大量数据，这在个人标识信息（PII）和法规 Fragmentation 的存在下是挑战。在这篇论文中，我们提出了一种联邦机器学习（FML）方法，减少隐私问题，实现分布式训练，不需要传输个人数据。我们采用了合作训练，考虑个人和组织在FML中的相互作用，模型cross设备和cross筒 scenarios。我们的方法在实际数据集上进行了评估，该数据集具有非独立和同样分布（non-iid）、客户端数据不均衡和标签抖抖。我们的结果表明，数据选择和客户端数据不均衡处理技术可以提高FML训练得到的预测性能，达到与传统ML模型相同或更高的预测性能。
</details></li>
</ul>
<hr>
<h2 id="Navigating-Out-of-Distribution-Electricity-Load-Forecasting-during-COVID-19-A-Continual-Learning-Approach-Leveraging-Human-Mobility"><a href="#Navigating-Out-of-Distribution-Electricity-Load-Forecasting-during-COVID-19-A-Continual-Learning-Approach-Leveraging-Human-Mobility" class="headerlink" title="Navigating Out-of-Distribution Electricity Load Forecasting during COVID-19: A Continual Learning Approach Leveraging Human Mobility"></a>Navigating Out-of-Distribution Electricity Load Forecasting during COVID-19: A Continual Learning Approach Leveraging Human Mobility</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04296">http://arxiv.org/abs/2309.04296</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arian Prabowo, Kaixuan Chen, Hao Xue, Subbu Sethuvenkatraman, Flora D. Salim</li>
<li>for: 这篇论文旨在应对 COVID-19 锁定期间中的能源负载预测问题，并使用 continual learning 技术更新模型以应对 Out-of-Distribution 情况。</li>
<li>methods: 这篇论文使用了 continual learning 算法 FSNet，与 privacy-preserving 的人偏移数据来更新模型，并评估了这些方法在实际应用中的性能。</li>
<li>results: 研究结果显示 continual learning 技术在 Out-of-Distribution 期间能够确保精确的能源负载预测，并且在锁定期间内与普通的 online learning 方法相比，能够更好地适应变化。<details>
<summary>Abstract</summary>
In traditional deep learning algorithms, one of the key assumptions is that the data distribution remains constant during both training and deployment. However, this assumption becomes problematic when faced with Out-of-Distribution periods, such as the COVID-19 lockdowns, where the data distribution significantly deviates from what the model has seen during training. This paper employs a two-fold strategy: utilizing continual learning techniques to update models with new data and harnessing human mobility data collected from privacy-preserving pedestrian counters located outside buildings. In contrast to online learning, which suffers from 'catastrophic forgetting' as newly acquired knowledge often erases prior information, continual learning offers a holistic approach by preserving past insights while integrating new data. This research applies FSNet, a powerful continual learning algorithm, to real-world data from 13 building complexes in Melbourne, Australia, a city which had the second longest total lockdown duration globally during the pandemic. Results underscore the crucial role of continual learning in accurate energy forecasting, particularly during Out-of-Distribution periods. Secondary data such as mobility and temperature provided ancillary support to the primary forecasting model. More importantly, while traditional methods struggled to adapt during lockdowns, models featuring at least online learning demonstrated resilience, with lockdown periods posing fewer challenges once armed with adaptive learning techniques. This study contributes valuable methodologies and insights to the ongoing effort to improve energy load forecasting during future Out-of-Distribution periods.
</details>
<details>
<summary>摘要</summary>
传统深度学习算法中一个关键假设是数据分布在训练和部署期间都保持不变。然而，这个假设在面临外部数据期间（如 COVID-19 封锁）时变得问题。这篇论文采用了两重策略：利用连续学习技术更新模型并利用隐私保护的人行数据，收集在外部建筑物外。与在线学习相比，其受到“致命的忘记”的影响，新获得的知识经常覆盖先前的信息，而连续学习则提供了一个整体的方法，保留过去的经验并与新数据集成。这项研究使用了 FSNet，一种强大的连续学习算法，对澳大利亚梅尔本市（全球第二长的总封锁时间）的13个建筑物进行实际应用。结果表明，连续学习在异常数据期间具有精度的能量预测作用，特别是在外部数据期间。次要数据，如流动和温度，为主要预测模型提供了辅助支持。更重要的是，传统方法在封锁期间很难适应，而在线学习方法至少在封锁期间展现了抗逆境能力，封锁期间使用可靠的学习技术后，封锁期间的挑战较少。本研究对未来的异常数据期间的能量负荷预测做出了有价值的方法和发现。
</details></li>
</ul>
<hr>
<h2 id="FIMO-A-Challenge-Formal-Dataset-for-Automated-Theorem-Proving"><a href="#FIMO-A-Challenge-Formal-Dataset-for-Automated-Theorem-Proving" class="headerlink" title="FIMO: A Challenge Formal Dataset for Automated Theorem Proving"></a>FIMO: A Challenge Formal Dataset for Automated Theorem Proving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04295">http://arxiv.org/abs/2309.04295</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengwu Liu, Jianhao Shen, Huajian Xin, Zhengying Liu, Ye Yuan, Haiming Wang, Wei Ju, Chuanyang Zheng, Yichun Yin, Lin Li, Ming Zhang, Qun Liu</li>
<li>for: 用于提高现有的自动证明方法，以达到国际数学奥林匹克（IMO）水平。</li>
<li>methods: 使用了GPT-4进行初步实验，以评估现有方法的局限性。</li>
<li>results: 发现现有方法存在很大的局限性，表明还有很长的探索之路才能达到满意的自动证明结果。<details>
<summary>Abstract</summary>
We present FIMO, an innovative dataset comprising formal mathematical problem statements sourced from the International Mathematical Olympiad (IMO) Shortlisted Problems. Designed to facilitate advanced automated theorem proving at the IMO level, FIMO is currently tailored for the Lean formal language. It comprises 149 formal problem statements, accompanied by both informal problem descriptions and their corresponding LaTeX-based informal proofs. Through initial experiments involving GPT-4, our findings underscore the existing limitations in current methodologies, indicating a substantial journey ahead before achieving satisfactory IMO-level automated theorem proving outcomes.
</details>
<details>
<summary>摘要</summary>
我们介绍FIMO，一个创新的数据集，包含国际数学奥林匹克（IMO）短列表问题的正式数学问题陈述。 FIMO是为了促进高级自动证明在IMO水平而设计，现在采用了Lean正式语言。它包含149个正式问题陈述，以及相应的LaTeX格式的不正式证明。经初步实验表明，现有的方法存在限制，需要进一步的努力才能达到满意的IMO自动证明结果。
</details></li>
</ul>
<hr>
<h2 id="Fuzzy-Fingerprinting-Transformer-Language-Models-for-Emotion-Recognition-in-Conversations"><a href="#Fuzzy-Fingerprinting-Transformer-Language-Models-for-Emotion-Recognition-in-Conversations" class="headerlink" title="Fuzzy Fingerprinting Transformer Language-Models for Emotion Recognition in Conversations"></a>Fuzzy Fingerprinting Transformer Language-Models for Emotion Recognition in Conversations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04292">http://arxiv.org/abs/2309.04292</a></li>
<li>repo_url: None</li>
<li>paper_authors: Patrícia Pereira, Rui Ribeiro, Helena Moniz, Luisa Coheur, Joao Paulo Carvalho</li>
<li>for: 这个论文是为了结合大语言模型和杂糅指纹技术来实现对话情感识别的目的。</li>
<li>methods: 该论文使用了预训练的RoBERTa模型和改进的杂糅指纹分类模块来实现对话情感识别。</li>
<li>results: 该论文在 DailyDialog ERC 数据集上实现了状态元的识别结果，使用了许多更轻量级的模型。<details>
<summary>Abstract</summary>
Fuzzy Fingerprints have been successfully used as an interpretable text classification technique, but, like most other techniques, have been largely surpassed in performance by Large Pre-trained Language Models, such as BERT or RoBERTa. These models deliver state-of-the-art results in several Natural Language Processing tasks, namely Emotion Recognition in Conversations (ERC), but suffer from the lack of interpretability and explainability. In this paper, we propose to combine the two approaches to perform ERC, as a means to obtain simpler and more interpretable Large Language Models-based classifiers. We propose to feed the utterances and their previous conversational turns to a pre-trained RoBERTa, obtaining contextual embedding utterance representations, that are then supplied to an adapted Fuzzy Fingerprint classification module. We validate our approach on the widely used DailyDialog ERC benchmark dataset, in which we obtain state-of-the-art level results using a much lighter model.
</details>
<details>
<summary>摘要</summary>
弹性指纹技术已成功应用于可读性文本分类 tasks，但，如大多数其他技术一样，它们在BERT或RoBERTa等大型预训练语言模型的出现后，已被大量超越。这些模型在识别情感 conversations（ERC）中达到了状态的表现，但它们缺乏可读性和解释性。在这篇论文中，我们提议将两种方法结合使用，以实现更加简单和可读的 Large Language Models-based classifier。我们提议将话语和其前一系列的对话提供给预训练的 RoBERTa，以获取话语上下文嵌入表示，然后将其传递给修改后的弹性指纹分类模块。我们在广泛使用的 DailyDialog ERC benchmark dataset上验证了我们的方法，并在使用轻量级模型时达到了状态的水平。
</details></li>
</ul>
<hr>
<h2 id="Sequential-Semantic-Generative-Communication-for-Progressive-Text-to-Image-Generation"><a href="#Sequential-Semantic-Generative-Communication-for-Progressive-Text-to-Image-Generation" class="headerlink" title="Sequential Semantic Generative Communication for Progressive Text-to-Image Generation"></a>Sequential Semantic Generative Communication for Progressive Text-to-Image Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04287">http://arxiv.org/abs/2309.04287</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyelin Nam, Jihong Park, Jinho Choi, Seong-Lyun Kim</li>
<li>for: 这篇论文提出了一种基于多模态生成器的新通信系统框架，以便在智能应用中实现成功的通信。</li>
<li>methods: 论文使用多模态生成器的技术将对象图像转换为文本，并使用反向过程将文本转换回图像。每个文本句子中的每个单词都有特定的语法角色，负责传递图像中的特定信息。</li>
<li>results: 论文的实验结果表明，使用文本将图像转换为文本并将文本转换回图像可以减轻通信负担，同时保持图像的含义。这种方法可以在智能应用中实现更高效的通信。<details>
<summary>Abstract</summary>
This paper proposes new framework of communication system leveraging promising generation capabilities of multi-modal generative models. Regarding nowadays smart applications, successful communication can be made by conveying the perceptual meaning, which we set as text prompt. Text serves as a suitable semantic representation of image data as it has evolved to instruct an image or generate image through multi-modal techniques, by being interpreted in a manner similar to human cognition. Utilizing text can also reduce the overload compared to transmitting the intact data itself. The transmitter converts objective image to text through multi-model generation process and the receiver reconstructs the image using reverse process. Each word in the text sentence has each syntactic role, responsible for particular piece of information the text contains. For further efficiency in communication load, the transmitter sequentially sends words in priority of carrying the most information until reaches successful communication. Therefore, our primary focus is on the promising design of a communication system based on image-to-text transformation and the proposed schemes for sequentially transmitting word tokens. Our work is expected to pave a new road of utilizing state-of-the-art generative models to real communication systems
</details>
<details>
<summary>摘要</summary>
The transmitter converts objective images into text through a multi-model generation process, and the receiver reconstructs the image using a reverse process. Each word in the text sentence has a specific syntactic role, responsible for conveying a particular piece of information the text contains. To further improve communication efficiency, the transmitter sequentially sends words in priority of carrying the most information until successful communication is achieved.Our primary focus is on the design of a communication system based on image-to-text transformation and the proposed schemes for sequentially transmitting word tokens. Our work is expected to pave a new road for utilizing state-of-the-art generative models in real communication systems.
</details></li>
</ul>
<hr>
<h2 id="Spatial-Temporal-Graph-Attention-Fuser-for-Calibration-in-IoT-Air-Pollution-Monitoring-Systems"><a href="#Spatial-Temporal-Graph-Attention-Fuser-for-Calibration-in-IoT-Air-Pollution-Monitoring-Systems" class="headerlink" title="Spatial-Temporal Graph Attention Fuser for Calibration in IoT Air Pollution Monitoring Systems"></a>Spatial-Temporal Graph Attention Fuser for Calibration in IoT Air Pollution Monitoring Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04508">http://arxiv.org/abs/2309.04508</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keivan Faghih Niresi, Mengjie Zhao, Hugo Bissig, Henri Baumann, Olga Fink</li>
<li>for: 这篇论文主要是为了提高互联网物联网（IoT）传感器的精度，特别是在无控制的环境下进行准确的减噪calibration。</li>
<li>methods: 我们提出了一种新的方法，利用图 neural network，具体来说是图注意力网络模块，将数组传感器的数据进行融合，以提高传感器的准确性。</li>
<li>results: 我们的实验结果表明，我们的方法可以在IoT空气污染监测平台中显著提高传感器的准确性。<details>
<summary>Abstract</summary>
The use of Internet of Things (IoT) sensors for air pollution monitoring has significantly increased, resulting in the deployment of low-cost sensors. Despite this advancement, accurately calibrating these sensors in uncontrolled environmental conditions remains a challenge. To address this, we propose a novel approach that leverages graph neural networks, specifically the graph attention network module, to enhance the calibration process by fusing data from sensor arrays. Through our experiments, we demonstrate the effectiveness of our approach in significantly improving the calibration accuracy of sensors in IoT air pollution monitoring platforms.
</details>
<details>
<summary>摘要</summary>
互联网物品（IoT）传感器在空气污染监测中的应用已经增加了，因此促进了低成本传感器的应用。然而，在无法控制的环境下精确地调整这些传感器仍然是一大挑战。为解决这个问题，我们提出了一种新的方法，利用图像神经网络，具体来说是图像注意力网络模组，将数据从传感器阵列融合以提高传感器的准确调整。我们的实验结果显示，我们的方法可以对IoT空气污染监测平台中的传感器进行重要的改善。
</details></li>
</ul>
<hr>
<h2 id="LLMCad-Fast-and-Scalable-On-device-Large-Language-Model-Inference"><a href="#LLMCad-Fast-and-Scalable-On-device-Large-Language-Model-Inference" class="headerlink" title="LLMCad: Fast and Scalable On-device Large Language Model Inference"></a>LLMCad: Fast and Scalable On-device Large Language Model Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04255">http://arxiv.org/abs/2309.04255</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daliang Xu, Wangsong Yin, Xin Jin, Ying Zhang, Shiyun Wei, Mengwei Xu, Xuanzhe Liu<br>for:This paper aims to improve the efficiency of generative Natural Language Processing (NLP) tasks on mobile devices.methods:The proposed method, LLMCad, uses a compact LLM to generate candidate tokens and a high-precision LLM to validate them, with three novel techniques: token tree construction, self-adjusting fallback strategy, and speculative token generation.results:LLMCad achieves impressive token generation speeds, up to 9.3x faster than existing inference engines, making it a promising solution for on-device NLP tasks.<details>
<summary>Abstract</summary>
Generative tasks, such as text generation and question answering, hold a crucial position in the realm of mobile applications. Due to their sensitivity to privacy concerns, there is a growing demand for their execution directly on mobile devices. Currently, the execution of these generative tasks heavily depends on Large Language Models (LLMs). Nevertheless, the limited memory capacity of these devices presents a formidable challenge to the scalability of such models.   In our research, we introduce LLMCad, an innovative on-device inference engine specifically designed for efficient generative Natural Language Processing (NLP) tasks. The core idea behind LLMCad revolves around model collaboration: a compact LLM, residing in memory, takes charge of generating the most straightforward tokens, while a high-precision LLM steps in to validate these tokens and rectify any identified errors. LLMCad incorporates three novel techniques: (1) Instead of generating candidate tokens in a sequential manner, LLMCad employs the smaller LLM to construct a token tree, encompassing a wider range of plausible token pathways. Subsequently, the larger LLM can efficiently validate all of these pathways simultaneously. (2) It employs a self-adjusting fallback strategy, swiftly initiating the verification process whenever the smaller LLM generates an erroneous token. (3) To ensure a continuous flow of token generation, LLMCad speculatively generates tokens during the verification process by implementing a compute-IO pipeline. Through an extensive series of experiments, LLMCad showcases an impressive token generation speed, achieving rates up to 9.3x faster than existing inference engines.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传统的自然语言处理（NLP）任务，如文本生成和问答，在移动设备上执行的需求不断增长。由于隐私问题的敏感性，需要直接在移动设备上执行这些任务。现在，这些任务的执行仍然大多依赖于大型语言模型（LLM）。然而，移动设备的内存容量却成为这些模型的扩展性的强烈挑战。  在我们的研究中，我们提出了 LLMCad，一种特有的在移动设备上进行高效生成NLP任务的推理引擎。 LLMCad的核心思想是模型合作：一个较小的LLM在内存中 residences，负责生成最直观的单词，而一个高精度的LLM则在验证这些单词并更正发现的错误。 LLMCad包含三种新技术：1. 而不是顺序生成候选单词，LLMCad使用小型LLM构建一个包含更多可能的单词路径的单词树。然后，大型LLM可以高效地验证这些路径。2. 它采用自适应的快速恢复策略，当小型LLM生成错误的单词时，快速发起验证过程。3. 为确保单词生成的不间断流动，LLMCad使用compute-IO管道来 спекулятив地生成单词，以便在验证过程中继续生成单词。经过了广泛的实验，LLMCad展示了很快的单词生成速度，达到9.3倍于现有的推理引擎。>>>
</details></li>
</ul>
<hr>
<h2 id="Towards-Reliable-and-Fluent-Large-Language-Models-Incorporating-Feedback-Learning-Loops-in-QA-Systems"><a href="#Towards-Reliable-and-Fluent-Large-Language-Models-Incorporating-Feedback-Learning-Loops-in-QA-Systems" class="headerlink" title="Towards Reliable and Fluent Large Language Models: Incorporating Feedback Learning Loops in QA Systems"></a>Towards Reliable and Fluent Large Language Models: Incorporating Feedback Learning Loops in QA Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06384">http://arxiv.org/abs/2309.06384</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongyub Lee, Taesun Whang, Chanhee Lee, Heuiseok Lim</li>
<li>For: The paper aims to improve the utility and trustworthiness of large language models (LLMs) in various daily applications by addressing issues such as erroneous references, hallucinated information, and inadequate details.* Methods: The study builds a dataset to train a critic model that evaluates the citation, correctness, and fluency of responses generated by LLMs in QA systems. It also proposes an automated feedback mechanism that leverages the critic model to offer real-time feedback on heterogeneous aspects of generated text, and introduces a feedback learning loop that uses the critic model to iteratively improve the performance of the LLM responsible for response generation.* Results: The experimental results demonstrate the efficacy of the approach, showing substantial improvements in citation and fluency metrics for ChatGPT, including a 4% precision increase in citation and an approximately 8% enhancement in the MAUVE metric for fluency, while maintaining high levels of correctness.Here’s the simplified Chinese text for the three information points:* 为：本研究旨在提高大语言模型（LLM）在日常应用中的可靠性和信任worthiness，并解决误差参考、hallucinated信息和缺乏细节等问题。* 方法：本研究建立了一个评价机器人模型可以评估LLM在问答系统中生成的引用、正确性和流畅性。它还提出了一种自动反馈机制，利用评价模型提供实时反馈对生成文本中的多种方面。最后，它引入了一个反馈学习循环，使用评价模型来持续改进LLM负责生成文本的性能。* 结果：实验结果表明，本approach的有效性，包括对ChatGPT的引用精度提高4%，以及对流畅性metric MAUVE的提高约8%，同时保持高水平的正确性。<details>
<summary>Abstract</summary>
Large language models (LLMs) have emerged as versatile tools in various daily applications. However, they are fraught with issues that undermine their utility and trustworthiness. These include the incorporation of erroneous references (citation), the generation of hallucinated information (correctness), and the inclusion of superfluous or omission of crucial details (fluency). To ameliorate these concerns, this study makes several key contributions. First, we build a dataset to train a critic model capable of evaluating the citation, correctness, and fluency of responses generated by LLMs in QA systems. Second, we propose an automated feedback mechanism that leverages the critic model to offer real-time feedback on heterogeneous aspects of generated text. Third, we introduce a feedback learning loop that uses this critic model to iteratively improve the performance of the LLM responsible for response generation. Experimental results demonstrate the efficacy of our approach, showing substantial improvements in citation and fluency metrics for ChatGPT, including a 4% precision increase in citation and an approximately 8% enhancement in the MAUVE metric for fluency, while maintaining high levels of correctness.
</details>
<details>
<summary>摘要</summary></li>
<li>Incorrect references (citation)* Made-up information (correctness)* Too much or too little information (fluency)To address these problems, this study makes three important contributions:1. We create a dataset to train a critic model that can evaluate the citation, correctness, and fluency of responses generated by LLMs in QA systems.2. We propose an automated feedback mechanism that uses the critic model to give real-time feedback on the responses.3. We introduce a feedback learning loop that uses the critic model to improve the performance of the LLM responsible for response generation.Our approach was tested and showed significant improvements in citation and fluency metrics for ChatGPT. The precision of citation improved by 4% and the MAUVE metric for fluency improved by approximately 8%, while maintaining high levels of correctness.</details></li>
</ul>
<hr>
<h2 id="Decoding-visual-brain-representations-from-electroencephalography-through-Knowledge-Distillation-and-latent-diffusion-models"><a href="#Decoding-visual-brain-representations-from-electroencephalography-through-Knowledge-Distillation-and-latent-diffusion-models" class="headerlink" title="Decoding visual brain representations from electroencephalography through Knowledge Distillation and latent diffusion models"></a>Decoding visual brain representations from electroencephalography through Knowledge Distillation and latent diffusion models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.07149">http://arxiv.org/abs/2309.07149</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matteo Ferrante, Tommaso Boccato, Stefano Bargione, Nicola Toschi</li>
<li>for: 这个研究旨在连接神经信号与视觉认知。</li>
<li>methods: 该研究使用电энцефалография（EEG）数据来分类和重建图像，并采用了一种基于Contrastive Language-Image Pre-Training（CLIP）的语音分类教师网络进行知识传承。</li>
<li>results: 该模型可以达到80%的top-5准确率，significantly出perform了标准CNN和多个RNN基本 Referenced benchmarks，并且可以生成基于EEG活动的图像估计。<details>
<summary>Abstract</summary>
Decoding visual representations from human brain activity has emerged as a thriving research domain, particularly in the context of brain-computer interfaces. Our study presents an innovative method that employs to classify and reconstruct images from the ImageNet dataset using electroencephalography (EEG) data from subjects that had viewed the images themselves (i.e. "brain decoding"). We analyzed EEG recordings from 6 participants, each exposed to 50 images spanning 40 unique semantic categories. These EEG readings were converted into spectrograms, which were then used to train a convolutional neural network (CNN), integrated with a knowledge distillation procedure based on a pre-trained Contrastive Language-Image Pre-Training (CLIP)-based image classification teacher network. This strategy allowed our model to attain a top-5 accuracy of 80%, significantly outperforming a standard CNN and various RNN-based benchmarks. Additionally, we incorporated an image reconstruction mechanism based on pre-trained latent diffusion models, which allowed us to generate an estimate of the images which had elicited EEG activity. Therefore, our architecture not only decodes images from neural activity but also offers a credible image reconstruction from EEG only, paving the way for e.g. swift, individualized feedback experiments. Our research represents a significant step forward in connecting neural signals with visual cognition.
</details>
<details>
<summary>摘要</summary>
研究人员们已经开发了一种新的方法，可以从人脑电听信号中解码和重建图像。我们的研究使用了6名参与者，每名参与者看过50个图像，这些图像包括40个semantic类别。我们将EEG记录转换成spectrogram，然后使用这些spectrogram来训练一个卷积神经网络（CNN），并结合一种基于预训练的Contrastive Language-Image Pre-Training（CLIP）图像分类教师网络的知识继承程序。这种策略使我们的模型达到了80%的top-5准确率，明显超过了标准CNN和多种RNN基本指标。此外，我们还添加了一种基于预训练的液态噪声模型的图像重建机制，使我们能够从EEG只有generated一个图像的估计。因此，我们的architecture不仅可以从 neural activity中解码图像，还可以提供一种可靠的图像重建方式，从EEG只有。这些成果 Represent a significant step forward in connecting neural signals with visual cognition.
</details></li>
</ul>
<hr>
<h2 id="UQ-at-SMM4H-2023-ALEX-for-Public-Health-Analysis-with-Social-Media"><a href="#UQ-at-SMM4H-2023-ALEX-for-Public-Health-Analysis-with-Social-Media" class="headerlink" title="UQ at #SMM4H 2023: ALEX for Public Health Analysis with Social Media"></a>UQ at #SMM4H 2023: ALEX for Public Health Analysis with Social Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04213">http://arxiv.org/abs/2309.04213</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yanjiangjerry/alex">https://github.com/yanjiangjerry/alex</a></li>
<li>paper_authors: Yan Jiang, Ruihong Qiu, Yi Zhang, Zi Huang</li>
<li>for: This paper aims to improve the performance of public health analysis on social media by addressing the data imbalance issue and utilizing the ability of large language models (LLMs) effectively.</li>
<li>methods: The proposed ALEX framework uses a combination of data augmentation, balanced training, and proper prompting to improve the performance of LLMs in public health analysis on social media.</li>
<li>results: The ALEX model achieved the best performance among all submissions in three tasks (Task 2, Task 4, and Task 1) in the Social Media Mining for Health 2023 (SMM4H) challenge, with high scores in all tasks.Here’s the simplified Chinese text for the three key points:</li>
<li>for: 这篇论文目的是通过解决数据不均衡问题和有效地利用大语言模型（LLMs）的能力来提高社交媒体上公共健康分析的性能。</li>
<li>methods: 提出的ALEX框架使用数据扩充、平衡训练和合适的提示来提高LLMs在社交媒体上公共健康分析中的性能。</li>
<li>results: ALEX模型在2023年社交媒体健康挖掘大会（SMM4H）中的三个任务（任务2、任务4和任务1）中得分最高，在所有任务中得分也很高。<details>
<summary>Abstract</summary>
As social media becomes increasingly popular, more and more activities related to public health emerge. Current techniques for public health analysis involve popular models such as BERT and large language models (LLMs). However, the costs of training in-domain LLMs for public health are especially expensive. Furthermore, such kinds of in-domain datasets from social media are generally imbalanced. To tackle these challenges, the data imbalance issue can be overcome by data augmentation and balanced training. Moreover, the ability of the LLMs can be effectively utilized by prompting the model properly. In this paper, a novel ALEX framework is proposed to improve the performance of public health analysis on social media by adopting an LLMs explanation mechanism. Results show that our ALEX model got the best performance among all submissions in both Task 2 and Task 4 with a high score in Task 1 in Social Media Mining for Health 2023 (SMM4H)[1]. Our code has been released at https:// github.com/YanJiangJerry/ALEX.
</details>
<details>
<summary>摘要</summary>
随着社交媒体的普及，公共卫生领域的活动越来越多。现有的公共卫生分析技术主要基于BERT和大型自然语言模型（LLM）。然而，培训域 específico LLMs 的成本特别高。此外，这些社交媒体数据集通常受到偏见的问题。为了解决这些挑战，可以通过数据扩展和平衡训练来缓解数据不均衡问题。此外，可以通过对模型提供正确的提示来有效地利用LLMs的能力。本文提出了一种基于 LLMs 解释机制的ALEX框架，用于提高社交媒体上的公共卫生分析表现。实验结果表明，我们的ALEX模型在 Social Media Mining for Health 2023（SMM4H）中的任务2和任务4中得到了最高分，并在任务1中获得了高分。我们的代码已经在 GitHub 上发布，请参考 https://github.com/YanJiangJerry/ALEX。
</details></li>
</ul>
<hr>
<h2 id="Towards-Mitigating-Architecture-Overfitting-in-Dataset-Distillation"><a href="#Towards-Mitigating-Architecture-Overfitting-in-Dataset-Distillation" class="headerlink" title="Towards Mitigating Architecture Overfitting in Dataset Distillation"></a>Towards Mitigating Architecture Overfitting in Dataset Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04195">http://arxiv.org/abs/2309.04195</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuyang Zhong, Chen Liu</li>
<li>for: 提高 neural network 在具有限制的训练数据情况下的性能</li>
<li>methods: 提出了一系列的建筑设计和训练方法，能够提高不同网络架构在热针训练数据上的泛化性能</li>
<li>results: 通过广泛的实验，证明了我们的方法的有效性和通用性，特别是在不同的尺度情况下，我们的方法可以在使用更大容量网络时达到相对或超过现有方法的性能<details>
<summary>Abstract</summary>
Dataset distillation methods have demonstrated remarkable performance for neural networks trained with very limited training data. However, a significant challenge arises in the form of architecture overfitting: the distilled training data synthesized by a specific network architecture (i.e., training network) generates poor performance when trained by other network architectures (i.e., test networks). This paper addresses this issue and proposes a series of approaches in both architecture designs and training schemes which can be adopted together to boost the generalization performance across different network architectures on the distilled training data. We conduct extensive experiments to demonstrate the effectiveness and generality of our methods. Particularly, across various scenarios involving different sizes of distilled data, our approaches achieve comparable or superior performance to existing methods when training on the distilled data using networks with larger capacities.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Knowledge-tuning-Large-Language-Models-with-Structured-Medical-Knowledge-Bases-for-Reliable-Response-Generation-in-Chinese"><a href="#Knowledge-tuning-Large-Language-Models-with-Structured-Medical-Knowledge-Bases-for-Reliable-Response-Generation-in-Chinese" class="headerlink" title="Knowledge-tuning Large Language Models with Structured Medical Knowledge Bases for Reliable Response Generation in Chinese"></a>Knowledge-tuning Large Language Models with Structured Medical Knowledge Bases for Reliable Response Generation in Chinese</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04175">http://arxiv.org/abs/2309.04175</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haochun Wang, Sendong Zhao, Zewen Qiang, Zijian Li, Nuwa Xi, Yanrui Du, MuZhen Cai, Haoqiang Guo, Yuhan Chen, Haoming Xu, Bing Qin, Ting Liu</li>
<li>for: 提高大语言模型在医疗领域中的可靠性和效果，即使模型没有医疗领域的专业知识。</li>
<li>methods: 利用结构化的医疗知识库来提高大语言模型的领域知识，从而提高响应生成的准确率。</li>
<li>results: 经过知识训练后，大语言模型可以在医疗知识区域中表现出更高的准确率，并且可以提供可靠的响应。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have demonstrated remarkable success in diverse natural language processing (NLP) tasks in general domains. However, LLMs sometimes generate responses with the hallucination about medical facts due to limited domain knowledge. Such shortcomings pose potential risks in the utilization of LLMs within medical contexts. To address this challenge, we propose knowledge-tuning, which leverages structured medical knowledge bases for the LLMs to grasp domain knowledge efficiently and facilitate reliable response generation. We also release cMedKnowQA, a Chinese medical knowledge question-answering dataset constructed from medical knowledge bases to assess the medical knowledge proficiency of LLMs. Experimental results show that the LLMs which are knowledge-tuned with cMedKnowQA, can exhibit higher levels of accuracy in response generation compared with vanilla instruction-tuning and offer a new reliable way for the domain adaptation of LLMs.
</details>
<details>
<summary>摘要</summary>
Note:* "Large Language Models" (LLMs) is translated as "大型语言模型" (dàxìng yǔyán módelǐ)* "natural language processing" (NLP) is translated as "自然语言处理" (zìrán yǔyán xùcè)* "medical knowledge" is translated as "医学知识" (yīxué zhīshī)* "knowledge-tuning" is translated as "知识调教" (zhīshī tiàoxüe)* "vanilla instruction-tuning" is translated as "简单的指导调教" (jiǎndān de zhǐguī tiàoxüe)* "domain adaptation" is translated as "领域适应" (lǐngyì shìbiàn)
</details></li>
</ul>
<hr>
<h2 id="Manifold-based-Verbalizer-Space-Re-embedding-for-Tuning-free-Prompt-based-Classification"><a href="#Manifold-based-Verbalizer-Space-Re-embedding-for-Tuning-free-Prompt-based-Classification" class="headerlink" title="Manifold-based Verbalizer Space Re-embedding for Tuning-free Prompt-based Classification"></a>Manifold-based Verbalizer Space Re-embedding for Tuning-free Prompt-based Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04174">http://arxiv.org/abs/2309.04174</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haochun Wang, Sendong Zhao, Chi Liu, Nuwa Xi, Muzhen Cai, Bing Qin, Ting Liu</li>
<li>for: 这个研究的目的是提出一种免 Parametric 的概率类别方法，可以与高维度的关键词嵌入进行类别。</li>
<li>methods: 这个方法使用了 Locally Linear Embedding with Intra-class Neighborhood Constraint (LLE-INC) 技术，将关键词嵌入转换为高维度的数据点，并将这些点分为不同的类别。</li>
<li>results: 实验结果显示，这个方法可以与受条件的类别方法相比，具有相似的类别精度，并且不需要任何参数调整。另外，在将类别方法与高维度关键词嵌入结合使用时，这个方法可以进一步提高类别精度。<details>
<summary>Abstract</summary>
Prompt-based classification adapts tasks to a cloze question format utilizing the [MASK] token and the filled tokens are then mapped to labels through pre-defined verbalizers. Recent studies have explored the use of verbalizer embeddings to reduce labor in this process. However, all existing studies require a tuning process for either the pre-trained models or additional trainable embeddings. Meanwhile, the distance between high-dimensional verbalizer embeddings should not be measured by Euclidean distance due to the potential for non-linear manifolds in the representation space. In this study, we propose a tuning-free manifold-based space re-embedding method called Locally Linear Embedding with Intra-class Neighborhood Constraint (LLE-INC) for verbalizer embeddings, which preserves local properties within the same class as guidance for classification. Experimental results indicate that even without tuning any parameters, our LLE-INC is on par with automated verbalizers with parameter tuning. And with the parameter updating, our approach further enhances prompt-based tuning by up to 3.2%. Furthermore, experiments with the LLaMA-7B&13B indicate that LLE-INC is an efficient tuning-free classification approach for the hyper-scale language models.
</details>
<details>
<summary>摘要</summary>
In this study, we propose a tuning-free manifold-based space re-embedding method called Locally Linear Embedding with Intra-class Neighborhood Constraint (LLE-INC) for verbalizer embeddings, which preserves local properties within the same class as guidance for classification. Experimental results indicate that even without tuning any parameters, our LLE-INC is on par with automated verbalizers with parameter tuning. And with the parameter updating, our approach further enhances prompt-based tuning by up to 3.2%. Furthermore, experiments with the LLaMA-7B&13B indicate that LLE-INC is an efficient tuning-free classification approach for the hyper-scale language models.(Note: The text has been translated into Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. The traditional Chinese form is also commonly used in Taiwan and Hong Kong.)
</details></li>
</ul>
<hr>
<h2 id="Compositional-Learning-of-Visually-Grounded-Concepts-Using-Reinforcement"><a href="#Compositional-Learning-of-Visually-Grounded-Concepts-Using-Reinforcement" class="headerlink" title="Compositional Learning of Visually-Grounded Concepts Using Reinforcement"></a>Compositional Learning of Visually-Grounded Concepts Using Reinforcement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04504">http://arxiv.org/abs/2309.04504</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/haidiazaman/rl-concept-learning-project">https://github.com/haidiazaman/rl-concept-learning-project</a></li>
<li>paper_authors: Zijun Lin, Haidi Azaman, M Ganesh Kumar, Cheston Tan</li>
<li>for:  investigating how deep reinforcement learning agents learn and compose color-shape based combinatorial instructions to solve novel combinations in a spatial navigation task.</li>
<li>methods: using 3D environments and exploring compositional learning, frozen text encoders (e.g. CLIP, BERT), and pretraining on shape or color concepts separately.</li>
<li>results: agents pretrained on concept and compositional learning achieve significantly higher reward when evaluated zero-shot on novel color-shape1-shape2 visual object combinations, and a 20 times decrease in training episodes needed to solve unseen combinations of instructions.<details>
<summary>Abstract</summary>
Deep reinforcement learning agents need to be trained over millions of episodes to decently solve navigation tasks grounded to instructions. Furthermore, their ability to generalize to novel combinations of instructions is unclear. Interestingly however, children can decompose language-based instructions and navigate to the referred object, even if they have not seen the combination of queries prior. Hence, we created three 3D environments to investigate how deep RL agents learn and compose color-shape based combinatorial instructions to solve novel combinations in a spatial navigation task. First, we explore if agents can perform compositional learning, and whether they can leverage on frozen text encoders (e.g. CLIP, BERT) to learn word combinations in fewer episodes. Next, we demonstrate that when agents are pretrained on the shape or color concepts separately, they show a 20 times decrease in training episodes needed to solve unseen combinations of instructions. Lastly, we show that agents pretrained on concept and compositional learning achieve significantly higher reward when evaluated zero-shot on novel color-shape1-shape2 visual object combinations. Overall, our results highlight the foundations needed to increase an agent's proficiency in composing word groups through reinforcement learning and its ability for zero-shot generalization to new combinations.
</details>
<details>
<summary>摘要</summary>
深度强化学习机器人需要通过百万集 Episodes 来有效地解决基于指令的导航任务。此外，它们对新的组合指令的泛化能力也不清楚。然而，孩子们可以将语言基于的指令分解成不同的部分，并寻找 Referred 对象，即使它们没有看到这些组合指令之前。因此，我们创建了三个3D环境，以 investigate 如何深度RL机器人学习和组合色彩基本指令来解决新的组合任务。首先，我们研究了机器人是否可以进行组合学习，以及是否可以使用冻结文本编码器（例如 CLIP、BERT）来学习单词组合。接着，我们示出了当机器人在Shape或Color概念上进行预训练后，它们可以减少解决未看过的组合指令的训练集数量。最后，我们显示了在概念学习和组合学习下，机器人在零次学习情况下对新的Color-Shape1-Shape2视觉对象组合表现出了显著更高的奖励。总的来说，我们的结果表明了如何通过强化学习来提高机器人对单词组合的能力，以及这种能力的零次泛化能力。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Prototype-Patient-Representations-with-Feature-Missing-Aware-Calibration-to-Mitigate-EHR-Data-Sparsity"><a href="#Leveraging-Prototype-Patient-Representations-with-Feature-Missing-Aware-Calibration-to-Mitigate-EHR-Data-Sparsity" class="headerlink" title="Leveraging Prototype Patient Representations with Feature-Missing-Aware Calibration to Mitigate EHR Data Sparsity"></a>Leveraging Prototype Patient Representations with Feature-Missing-Aware Calibration to Mitigate EHR Data Sparsity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04160">http://arxiv.org/abs/2309.04160</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yinghao Zhu, Zixiang Wang, Long He, Shiyun Xie, Zixi Chen, Jingkun An, Liantao Ma, Chengwei Pan</li>
<li>for: 这份研究是为了解决电子健康记录（EHR）数据的稀畴性问题，以提高预测模型的效能。</li>
<li>methods: 本研究使用间接替代填写方法，利用相似 пацієнтах的原型表示来获得更为紧密的嵌入。它还包括一个专门设计的特征信任学习模组，以评估每个特征的可靠性。</li>
<li>results: 研究结果显示，设计的模型在MIMIC-III和MIMIC-IV数据集上的医院死亡结果预测任务中实现了 statistically significant 的提升，比较之前的EHR-Related模型。代码可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/yhzhu99/SparseEHR%7D">https://github.com/yhzhu99/SparseEHR}</a> 上获取，以保证可重现性。<details>
<summary>Abstract</summary>
Electronic Health Record (EHR) data frequently exhibits sparse characteristics, posing challenges for predictive modeling. Current direct imputation such as matrix imputation approaches hinge on referencing analogous rows or columns to complete raw missing data and do not differentiate between imputed and actual values. As a result, models may inadvertently incorporate irrelevant or deceptive information with respect to the prediction objective, thereby compromising the efficacy of downstream performance. While some methods strive to recalibrate or augment EHR embeddings after direct imputation, they often mistakenly prioritize imputed features. This misprioritization can introduce biases or inaccuracies into the model. To tackle these issues, our work resorts to indirect imputation, where we leverage prototype representations from similar patients to obtain a denser embedding. Recognizing the limitation that missing features are typically treated the same as present ones when measuring similar patients, our approach designs a feature confidence learner module. This module is sensitive to the missing feature status, enabling the model to better judge the reliability of each feature. Moreover, we propose a novel patient similarity metric that takes feature confidence into account, ensuring that evaluations are not based merely on potentially inaccurate imputed values. Consequently, our work captures dense prototype patient representations with feature-missing-aware calibration process. Comprehensive experiments demonstrate that designed model surpasses established EHR-focused models with a statistically significant improvement on MIMIC-III and MIMIC-IV datasets in-hospital mortality outcome prediction task. The code is publicly available at \url{https://github.com/yhzhu99/SparseEHR} to assure the reproducibility.
</details>
<details>
<summary>摘要</summary>
电子健康记录（EHR）数据经常具有稀畴特征，这会对预测模型造成挑战。目前的直接填充方法，如矩阵填充方法，基于相似的行或列来完善未完整的数据，并不能区分填充的和实际值。这会让模型把无关或误导性的信息纳入预测目标中，从而降低下游性能。一些方法尝试通过重新填充或扩展EHR嵌入来解决这些问题，但它们通常会偏好填充的特征。这会引入偏见或错误到模型中。为了解决这些问题，我们的工作采用间接填充方法，利用相似患者的原型表示来获得更密集的嵌入。我们认识到缺失的特征通常会被视为已知的特征，因此我们的方法设计了特征信任学习模块。这个模块能够感知缺失特征的状态，使模型更好地评估每个特征的可靠性。此外，我们提出了一种新的患者相似度度量，该度量考虑特征信任度，以确保评估不仅基于可能不准确的填充值。因此，我们的工作可以获得 dense prototype 患者表示，同时具有缺失特征整合过程中的可靠性评估。我们的实验表明，我们的模型在MIMIC-III和MIMIC-IV数据集上的医院死亡结果预测任务中 statistically significant 提高了表现，至于代码，可以在 <https://github.com/yhzhu99/SparseEHR> 中找到。以确保可重现性。
</details></li>
</ul>
<hr>
<h2 id="NESTLE-a-No-Code-Tool-for-Statistical-Analysis-of-Legal-Corpus"><a href="#NESTLE-a-No-Code-Tool-for-Statistical-Analysis-of-Legal-Corpus" class="headerlink" title="NESTLE: a No-Code Tool for Statistical Analysis of Legal Corpus"></a>NESTLE: a No-Code Tool for Statistical Analysis of Legal Corpus</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04146">http://arxiv.org/abs/2309.04146</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kyoungyeon Cho, Seungkum Han, Wonseok Hwang</li>
<li>for: 法律文本分析的大规模统计分析可以提供有价值的法律洞察。</li>
<li>methods:  NESTLE 提供了一个无代码工具 для大规模法律文本统计分析，包括搜索引擎、终端信息抽取系统和大语言模型。</li>
<li>results: NESTLE 可以在大规模法律文本中实现 GPT-4 相当的性能，并且可以在不需要编写代码的情况下进行自定义统计分析。<details>
<summary>Abstract</summary>
The statistical analysis of large scale legal corpus can provide valuable legal insights. For such analysis one needs to (1) select a subset of the corpus using document retrieval tools, (2) structuralize text using information extraction (IE) systems, and (3) visualize the data for the statistical analysis. Each process demands either specialized tools or programming skills whereas no comprehensive unified "no-code" tools have been available. Especially for IE, if the target information is not predefined in the ontology of the IE system, one needs to build their own system. Here we provide NESTLE, a no code tool for large-scale statistical analysis of legal corpus. With NESTLE, users can search target documents, extract information, and visualize the structured data all via the chat interface with accompanying auxiliary GUI for the fine-level control. NESTLE consists of three main components: a search engine, an end-to-end IE system, and a Large Language Model (LLM) that glues the whole components together and provides the chat interface. Powered by LLM and the end-to-end IE system, NESTLE can extract any type of information that has not been predefined in the IE system opening up the possibility of unlimited customizable statistical analysis of the corpus without writing a single line of code. The use of the custom end-to-end IE system also enables faster and low-cost IE on large scale corpus. We validate our system on 15 Korean precedent IE tasks and 3 legal text classification tasks from LEXGLUE. The comprehensive experiments reveal NESTLE can achieve GPT-4 comparable performance by training the internal IE module with 4 human-labeled, and 192 LLM-labeled examples. The detailed analysis provides the insight on the trade-off between accuracy, time, and cost in building such system.
</details>
<details>
<summary>摘要</summary>
大规模法律文本分析可以提供有价值的法律洞察。为实现这一目标，需要（1）使用文档检索工具选择规模大的文本子集，（2）使用信息抽取（IE）系统结构化文本，以及（3）使用数据视图工具进行统计分析。每个过程都需要特殊的工具或编程技能，而现在没有一款综合的“无代码”工具可用。尤其是IE，如果目标信息没有在IE系统中 Ontology 中定义，那么需要自己建立系统。我们提供了 NESTLE，一款“无代码”工具，可以在对大规模文本进行统计分析时，使用 conversational  интерфейス和相应的辅助GUI进行搜索、信息抽取和数据视图。NESTLE 由三个主要组件组成：搜索引擎、端到端IE系统和一个基于大语言模型（LLM）的核心组件。通过LLM和端到端IE系统，NESTLE 可以自动抽取文本中的任何信息，无需在IE系统中先定义目标信息，这样开放了无限可定制的统计分析方法，无需写一行代码。使用自定义端到端IE系统，NESTLE 还可以在大规模文本中进行更快和低成本的IE。我们在15个韩国前例IE任务和3个法律文本分类任务上进行了详细的实验，并证明NESTLE 可以在培育内部IE模块时与 GPT-4 相当的性能。etailed 分析还提供了对准则、时间和成本之间的费 trade-off 的深入分析。
</details></li>
</ul>
<hr>
<h2 id="Trustworthy-and-Synergistic-Artificial-Intelligence-for-Software-Engineering-Vision-and-Roadmaps"><a href="#Trustworthy-and-Synergistic-Artificial-Intelligence-for-Software-Engineering-Vision-and-Roadmaps" class="headerlink" title="Trustworthy and Synergistic Artificial Intelligence for Software Engineering: Vision and Roadmaps"></a>Trustworthy and Synergistic Artificial Intelligence for Software Engineering: Vision and Roadmaps</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04142">http://arxiv.org/abs/2309.04142</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Lo</li>
<li>for: This paper aims to provide a comprehensive overview of the current state and future directions of Artificial Intelligence for Software Engineering (AI4SE), with a focus on realizing trustworthy and synergistic AI4SE.</li>
<li>methods: The paper uses a combination of literature review, analysis, and visioning to explore the current challenges and potential solutions for AI4SE, and to paint a vision for the future of software engineering.</li>
<li>results: The paper highlights the potential leaps that can be achieved if the key challenges of AI4SE are surmounted, including the transition towards Software Engineering 2.0, and provides two strategic roadmaps for realizing trustworthy and synergistic AI4SE.<details>
<summary>Abstract</summary>
For decades, much software engineering research has been dedicated to devising automated solutions aimed at enhancing developer productivity and elevating software quality. The past two decades have witnessed an unparalleled surge in the development of intelligent solutions tailored for software engineering tasks. This momentum established the Artificial Intelligence for Software Engineering (AI4SE) area, which has swiftly become one of the most active and popular areas within the software engineering field.   This Future of Software Engineering (FoSE) paper navigates through several focal points. It commences with a succinct introduction and history of AI4SE. Thereafter, it underscores the core challenges inherent to AI4SE, particularly highlighting the need to realize trustworthy and synergistic AI4SE. Progressing, the paper paints a vision for the potential leaps achievable if AI4SE's key challenges are surmounted, suggesting a transition towards Software Engineering 2.0. Two strategic roadmaps are then laid out: one centered on realizing trustworthy AI4SE, and the other on fostering synergistic AI4SE. While this paper may not serve as a conclusive guide, its intent is to catalyze further progress. The ultimate aspiration is to position AI4SE as a linchpin in redefining the horizons of software engineering, propelling us toward Software Engineering 2.0.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)For decades, much software engineering research has been dedicated to devising automated solutions aimed at enhancing developer productivity and elevating software quality. The past two decades have witnessed an unparalleled surge in the development of intelligent solutions tailored for software engineering tasks. This momentum established the Artificial Intelligence for Software Engineering (AI4SE) area, which has swiftly become one of the most active and popular areas within the software engineering field.   This Future of Software Engineering (FoSE) paper navigates through several focal points. It commences with a succinct introduction and history of AI4SE. Thereafter, it underscores the core challenges inherent to AI4SE, particularly highlighting the need to realize trustworthy and synergistic AI4SE. Progressing, the paper paints a vision for the potential leaps achievable if AI4SE's key challenges are surmounted, suggesting a transition towards Software Engineering 2.0. Two strategic roadmaps are then laid out: one centered on realizing trustworthy AI4SE, and the other on fostering synergistic AI4SE. While this paper may not serve as a conclusive guide, its intent is to catalyze further progress. The ultimate aspiration is to position AI4SE as a linchpin in redefining the horizons of software engineering, propelling us toward Software Engineering 2.0.
</details></li>
</ul>
<hr>
<h2 id="Proprioceptive-External-Torque-Learning-for-Floating-Base-Robot-and-its-Applications-to-Humanoid-Locomotion"><a href="#Proprioceptive-External-Torque-Learning-for-Floating-Base-Robot-and-its-Applications-to-Humanoid-Locomotion" class="headerlink" title="Proprioceptive External Torque Learning for Floating Base Robot and its Applications to Humanoid Locomotion"></a>Proprioceptive External Torque Learning for Floating Base Robot and its Applications to Humanoid Locomotion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04138">http://arxiv.org/abs/2309.04138</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daegyu Lim, Myeong-Ju Kim, Junhyeok Cha, Donghyeon Kim, Jaeheung Park</li>
<li>for: 本研究旨在实现人型机器人的稳定行走和安全执行，并且减少对系统的成本、阻尼、复杂度和故障可能性。</li>
<li>methods: 本研究使用 proprioceptive 哔视感器（Encoder 和 IMU）来学习外部关节扭矩，不需要增加价格、阻尼、复杂度和可能性故障的 Force-Torque 仪。</li>
<li>results: 实验结果显示，训练 GRU 网络可以实现更好的外部关节扭矩和触地力估算，与模型基本方法（MOB）和摩擦模型相比，具有更小的误差。此外，训练网络还可以在不同脚和上层体重的情况下保持稳定的行走，并且显示了可以实现零矩点传递控制。<details>
<summary>Abstract</summary>
The estimation of external joint torque and contact wrench is essential for achieving stable locomotion of humanoids and safety-oriented robots. Although the contact wrench on the foot of humanoids can be measured using a force-torque sensor (FTS), FTS increases the cost, inertia, complexity, and failure possibility of the system. This paper introduces a method for learning external joint torque solely using proprioceptive sensors (encoders and IMUs) for a floating base robot. For learning, the GRU network is used and random walking data is collected. Real robot experiments demonstrate that the network can estimate the external torque and contact wrench with significantly smaller errors compared to the model-based method, momentum observer (MOB) with friction modeling. The study also validates that the estimated contact wrench can be utilized for zero moment point (ZMP) feedback control, enabling stable walking. Moreover, even when the robot's feet and the inertia of the upper body are changed, the trained network shows consistent performance with a model-based calibration. This result demonstrates the possibility of removing FTS on the robot, which reduces the disadvantages of hardware sensors. The summary video is available at https://youtu.be/gT1D4tOiKpo.
</details>
<details>
<summary>摘要</summary>
estimate 外部联 torque 和 接触扭矩 的估算是人类机器人稳定行走和安全机器人的关键。 although 机器人的足部可以使用力矩传感器（FTS）测量 contacts 扭矩，FTS 会增加系统的成本、抗力、复杂性和失败可能性。 this paper introduces a method for learning external joint torque solely using proprioceptive sensors (encoders and IMUs) for a floating base robot. for learning, the GRU network is used and random walking data is collected. real robot experiments demonstrate that the network can estimate the external torque and contact wrench with significantly smaller errors compared to the model-based method, momentum observer (MOB) with friction modeling. the study also validates that the estimated contact wrench can be utilized for zero moment point (ZMP) feedback control, enabling stable walking. moreover, even when the robot's feet and the inertia of the upper body are changed, the trained network shows consistent performance with a model-based calibration. this result demonstrates the possibility of removing FTS on the robot, which reduces the disadvantages of hardware sensors. the summary video is available at <https://youtu.be/gT1D4tOiKpo>.Note: The translation is in Simplified Chinese, which is the standard written form of Chinese used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Weakly-Supervised-Point-Clouds-Transformer-for-3D-Object-Detection"><a href="#Weakly-Supervised-Point-Clouds-Transformer-for-3D-Object-Detection" class="headerlink" title="Weakly Supervised Point Clouds Transformer for 3D Object Detection"></a>Weakly Supervised Point Clouds Transformer for 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04105">http://arxiv.org/abs/2309.04105</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zuojin Tang, Bo Sun, Tongwei Ma, Daosheng Li, Zhenhui Xu</li>
<li>for: 本文提出了一种基于点云transformer的弱类别学习框架，用于3D对象检测。目的是降低3D数据集的标注成本，以提高训练效率。</li>
<li>methods: 我们提出了一种无监督投票提议模块，通过随机设置anchor点和使用投票网络选择高质量的anchor点。然后，它将信息详细总结成教师和学生网络。学生网络采用ResNet网络高效地提取本地特征，但也可能丢失全局信息。为了提供全局和本地信息的输入，我们采用了transformer自注意机制和ResNet层。</li>
<li>results: 在KITTI datasets上进行了实验， achieved the highest level of average precision compared with the most recent weakly supervised 3D object detectors。<details>
<summary>Abstract</summary>
The annotation of 3D datasets is required for semantic-segmentation and object detection in scene understanding. In this paper we present a framework for the weakly supervision of a point clouds transformer that is used for 3D object detection. The aim is to decrease the required amount of supervision needed for training, as a result of the high cost of annotating a 3D datasets. We propose an Unsupervised Voting Proposal Module, which learns randomly preset anchor points and uses voting network to select prepared anchor points of high quality. Then it distills information into student and teacher network. In terms of student network, we apply ResNet network to efficiently extract local characteristics. However, it also can lose much global information. To provide the input which incorporates the global and local information as the input of student networks, we adopt the self-attention mechanism of transformer to extract global features, and the ResNet layers to extract region proposals. The teacher network supervises the classification and regression of the student network using the pre-trained model on ImageNet. On the challenging KITTI datasets, the experimental results have achieved the highest level of average precision compared with the most recent weakly supervised 3D object detectors.
</details>
<details>
<summary>摘要</summary>
三维数据集的注释是Scene理解中Semantic-segmentation和对象检测的必要条件。在这篇论文中，我们提出了一个用于弱样本监督的点云变换器框架，以降低训练所需的监督量，因为 annotating a 3D dataset 的成本很高。我们提出了一个无监督投票建议模块，它学习随机设置的锚点，并使用投票网络选择高质量的锚点。然后，它将信息精炼到教师和学生网络。在学生网络中，我们使用ResNet网络来高效地提取本地特征，但它也可能产生大量的全局信息丢失。为了提供包含全局和本地信息的输入，我们采用了 transformer 自注意机制来提取全局特征，并使用 ResNet 层来提取地区提案。教师网络监督学生网络在 ImageNet 预训练模型的基础上进行分类和回归。在 KITTI 数据集上进行的实验结果达到了最近弱样本监督三维对象检测器的最高水平，相比之下，其他最近的弱样本监督三维对象检测器。
</details></li>
</ul>
<hr>
<h2 id="Modeling-Recommender-Ecosystems-Research-Challenges-at-the-Intersection-of-Mechanism-Design-Reinforcement-Learning-and-Generative-Models"><a href="#Modeling-Recommender-Ecosystems-Research-Challenges-at-the-Intersection-of-Mechanism-Design-Reinforcement-Learning-and-Generative-Models" class="headerlink" title="Modeling Recommender Ecosystems: Research Challenges at the Intersection of Mechanism Design, Reinforcement Learning and Generative Models"></a>Modeling Recommender Ecosystems: Research Challenges at the Intersection of Mechanism Design, Reinforcement Learning and Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.06375">http://arxiv.org/abs/2309.06375</a></li>
<li>repo_url: None</li>
<li>paper_authors: Craig Boutilier, Martin Mladenov, Guy Tennenholtz</li>
<li>for: 本文提出了一种概念框架，用于提高现代推荐系统的价值，以及提高推荐系统中各个actor的利益。</li>
<li>methods: 本文提出了一些新的方法，包括使用强化学习优化长期目标，使用社会选择理论考虑不同actor的利益，以及使用行为经济学和心理学来更好地模型用户和Item提供者的行为。</li>
<li>results: 本文的研究结果表明，通过使用这些新的方法，可以提高推荐系统的总体健康度和用户利益，同时也可以提高Item提供者的利益。<details>
<summary>Abstract</summary>
Modern recommender systems lie at the heart of complex ecosystems that couple the behavior of users, content providers, advertisers, and other actors. Despite this, the focus of the majority of recommender research -- and most practical recommenders of any import -- is on the local, myopic optimization of the recommendations made to individual users. This comes at a significant cost to the long-term utility that recommenders could generate for its users. We argue that explicitly modeling the incentives and behaviors of all actors in the system -- and the interactions among them induced by the recommender's policy -- is strictly necessary if one is to maximize the value the system brings to these actors and improve overall ecosystem "health". Doing so requires: optimization over long horizons using techniques such as reinforcement learning; making inevitable tradeoffs in the utility that can be generated for different actors using the methods of social choice; reducing information asymmetry, while accounting for incentives and strategic behavior, using the tools of mechanism design; better modeling of both user and item-provider behaviors by incorporating notions from behavioral economics and psychology; and exploiting recent advances in generative and foundation models to make these mechanisms interpretable and actionable. We propose a conceptual framework that encompasses these elements, and articulate a number of research challenges that emerge at the intersection of these different disciplines.
</details>
<details>
<summary>摘要</summary>
现代推荐系统处于复杂的生态系统中，与用户、内容提供者、广告主和其他actor的行为相互关联。然而，大多数推荐研究和实践中心于本地、短期优化推荐给单个用户。我们认为，如果推荐系统想要在长期增值给用户，那么需要考虑所有actor的利益和行为，以及这些actor之间由推荐策略引起的互动。这需要：使用增强学习来优化推荐策略在长期 horizons上; 通过社会选择方法来让拥有不同利益的actor之间进行让担做出妥协; 减少信息不对称性，同时考虑激励和战略行为，使用机制设计的工具; 更好地模型用户和物品提供者的行为，通过包括行为经济学和心理学的思想; 并利用最新的生成和基础模型来使这些机制可读性和可行性。我们提出了一个涵盖这些元素的概念框架，并详细描述了这些不同领域之间的研究挑战。
</details></li>
</ul>
<hr>
<h2 id="Data-driven-classification-of-low-power-communication-signals-by-an-unauthenticated-user-using-a-software-defined-radio"><a href="#Data-driven-classification-of-low-power-communication-signals-by-an-unauthenticated-user-using-a-software-defined-radio" class="headerlink" title="Data-driven classification of low-power communication signals by an unauthenticated user using a software-defined radio"></a>Data-driven classification of low-power communication signals by an unauthenticated user using a software-defined radio</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04088">http://arxiv.org/abs/2309.04088</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/minds-code/jammingsdr">https://github.com/minds-code/jammingsdr</a></li>
<li>paper_authors: Tarun Rao Keshabhoina, Marcos M. Vasconcelos</li>
<li>for: 本文针对大规模分布式多智能体系统，尤其是在 робо控制网络应用中，通过低功率通信网络进行信息交换，具有限制的功率和无法识别的频率带宽和扩散因子。</li>
<li>methods: 本文使用了一种 Structural Pattern 在 LoRa 信号的快速频率表示中找到一个简单的解决方案，将问题转化为一个分类问题，可以使用神经网络实现。</li>
<li>results: 本文表明，如果攻击者可以成功地确定目标信号的带宽和扩散因子，那么 LoRa 协议就会受到拒绝服务攻击。<details>
<summary>Abstract</summary>
Many large-scale distributed multi-agent systems exchange information over low-power communication networks. In particular, agents intermittently communicate state and control signals in robotic network applications, often with limited power over an unlicensed spectrum, prone to eavesdropping and denial-of-service attacks. In this paper, we argue that a widely popular low-power communication protocol known as LoRa is vulnerable to denial-of-service attacks by an unauthenticated attacker if it can successfully identify a target signal's bandwidth and spreading factor. Leveraging a structural pattern in the LoRa signal's instantaneous frequency representation, we relate the problem of jointly inferring the two unknown parameters to a classification problem, which can be efficiently implemented using neural networks.
</details>
<details>
<summary>摘要</summary>
很多大规模分布式多代理系统通过低功率通信网络进行信息交换。特别是在机器人网络应用中，代理器间断断续地交换状态和控制信号，经常具有有限的功率和无license频段，容易受到侦测和拒绝服务攻击。在这篇论文中，我们 argue That a widely popular low-power communication protocol known as LoRa is vulnerable to denial-of-service attacks by an unauthenticated attacker if it can successfully identify a target signal's bandwidth and spreading factor。通过利用LoRa信号的快速频率表示结构特征，我们将相应的问题相似于一个分类问题，可以使用神经网络高效地解决。
</details></li>
</ul>
<hr>
<h2 id="Curve-Your-Attention-Mixed-Curvature-Transformers-for-Graph-Representation-Learning"><a href="#Curve-Your-Attention-Mixed-Curvature-Transformers-for-Graph-Representation-Learning" class="headerlink" title="Curve Your Attention: Mixed-Curvature Transformers for Graph Representation Learning"></a>Curve Your Attention: Mixed-Curvature Transformers for Graph Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04082">http://arxiv.org/abs/2309.04082</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sungjun Cho, Seunghyuk Cho, Sungwoo Park, Hankook Lee, Honglak Lee, Moontae Lee</li>
<li>for: 学习实际图像中的层次或循环结构，而传统的欧几何空间不能够准确地表示这些结构。</li>
<li>methods: 提出全产品托卡斯特谐变换器，一种可以在常数曲率空间上操作的全通过积分的变换器，可以在endorse-to-end的方式中学习不同曲率的图像。</li>
<li>results: 对图像重建和节点分类进行了实验，并证明了通过托卡斯特谐变换器可以更好地学习非欧几何图像。<details>
<summary>Abstract</summary>
Real-world graphs naturally exhibit hierarchical or cyclical structures that are unfit for the typical Euclidean space. While there exist graph neural networks that leverage hyperbolic or spherical spaces to learn representations that embed such structures more accurately, these methods are confined under the message-passing paradigm, making the models vulnerable against side-effects such as oversmoothing and oversquashing. More recent work have proposed global attention-based graph Transformers that can easily model long-range interactions, but their extensions towards non-Euclidean geometry are yet unexplored. To bridge this gap, we propose Fully Product-Stereographic Transformer, a generalization of Transformers towards operating entirely on the product of constant curvature spaces. When combined with tokenized graph Transformers, our model can learn the curvature appropriate for the input graph in an end-to-end fashion, without the need of additional tuning on different curvature initializations. We also provide a kernelized approach to non-Euclidean attention, which enables our model to run in time and memory cost linear to the number of nodes and edges while respecting the underlying geometry. Experiments on graph reconstruction and node classification demonstrate the benefits of generalizing Transformers to the non-Euclidean domain.
</details>
<details>
<summary>摘要</summary>
real-world 图表自然地具有层次或循环结构，这些结构不适合传统的欧几何空间。有些图注意力网络可以利用折射或圆形空间来学习更准确的表示，但这些方法受到消息传递模式的限制，容易导致过滤和压缩的问题。更新的工作已经提出了全球注意力基于图Transformers，可以轻松模型长距离交互，但这些方法在非欧几何几何上的扩展仍然未知。为了bridging这个鸿沟，我们提出了全产品投影特征变换器，一种基于Transformers的非欧几何特征变换器。当与 токен化的图Transformers结合使用时，我们的模型可以在终端方式上学习输入图的曲率，无需额外调整不同曲率的初始化。我们还提供了非欧几何注意力的kernel方法，使得我们的模型在时间和内存成本 linear 于图的节点和边数量的情况下运行，同时尊重下面的几何结构。实验表示，通过将Transformers扩展到非欧几何领域，可以获得更好的图重建和节点分类性能。
</details></li>
</ul>
<hr>
<h2 id="SayNav-Grounding-Large-Language-Models-for-Dynamic-Planning-to-Navigation-in-New-Environments"><a href="#SayNav-Grounding-Large-Language-Models-for-Dynamic-Planning-to-Navigation-in-New-Environments" class="headerlink" title="SayNav: Grounding Large Language Models for Dynamic Planning to Navigation in New Environments"></a>SayNav: Grounding Large Language Models for Dynamic Planning to Navigation in New Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04077">http://arxiv.org/abs/2309.04077</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhinav Rajvanshi, Karan Sikka, Xiao Lin, Bhoram Lee, Han-Pang Chiu, Alvaro Velasquez</li>
<li>for: 这篇论文是用于提出一种新的方法，即 SayNav，以便 autonomous agent 在未知环境中完成复杂的导航任务。</li>
<li>methods: SayNav 使用了一种新的固定机制，即增量建立 3D 场景图，以便将人类知识从大型自然语言模型 (LLMs) 中生成适合情况的高级计划。</li>
<li>results: SayNav 在一个新的多物体导航任务上取得了95.35% 的成功率（与基线相比，只有56.06%），这highlights SayNav 的能力在大规模新环境中生成动态计划并成功地找到物体。 In addition, SayNav 还能够效率地泛化到实际环境中。<details>
<summary>Abstract</summary>
Semantic reasoning and dynamic planning capabilities are crucial for an autonomous agent to perform complex navigation tasks in unknown environments. It requires a large amount of common-sense knowledge, that humans possess, to succeed in these tasks. We present SayNav, a new approach that leverages human knowledge from Large Language Models (LLMs) for efficient generalization to complex navigation tasks in unknown large-scale environments. SayNav uses a novel grounding mechanism, that incrementally builds a 3D scene graph of the explored environment as inputs to LLMs, for generating feasible and contextually appropriate high-level plans for navigation. The LLM-generated plan is then executed by a pre-trained low-level planner, that treats each planned step as a short-distance point-goal navigation sub-task. SayNav dynamically generates step-by-step instructions during navigation and continuously refines future steps based on newly perceived information. We evaluate SayNav on a new multi-object navigation task, that requires the agent to utilize a massive amount of human knowledge to efficiently search multiple different objects in an unknown environment. SayNav outperforms an oracle based Point-nav baseline, achieving a success rate of 95.35% (vs 56.06% for the baseline), under the ideal settings on this task, highlighting its ability to generate dynamic plans for successfully locating objects in large-scale new environments. In addition, SayNav also enables efficient generalization from simulation to real environments.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Semantic reasoning和动态规划能力是自主代理人完成复杂的导航任务所必需的。这需要人类具备的通用常识知识，以确保成功完成这些任务。我们介绍了SayNav，一种新的方法，利用大型自然语言模型（LLM）来提高导航任务的效率。SayNav使用一种新的固定机制，逐步建立未知环境中探索的3D场景图，并将这些图用于LLM生成高级计划。生成的计划将被一个已经训练的低级 плаanner执行，该 плаanner将每个规划步骤视为短距离点 Navigation sub-任务。SayNav在导航过程中动态生成步骤指示，并在新获得的信息基础上不断改进未来步骤。我们对SayNav进行了一种新的多对象导航任务的评估，该任务需要代理人能够效率地搜索未知环境中多种不同的对象。SayNav在理想的设置下，与基线点导航比较，成功率为95.35%（vs 56.06%）， highlighting its ability to generate dynamic plans for successfully locating objects in large-scale new environments。此外，SayNav还能够效率地从 simulate 到实际环境的总结。>>>
</details></li>
</ul>
<hr>
<h2 id="Computationally-Efficient-Data-Driven-Discovery-and-Linear-Representation-of-Nonlinear-Systems-For-Control"><a href="#Computationally-Efficient-Data-Driven-Discovery-and-Linear-Representation-of-Nonlinear-Systems-For-Control" class="headerlink" title="Computationally Efficient Data-Driven Discovery and Linear Representation of Nonlinear Systems For Control"></a>Computationally Efficient Data-Driven Discovery and Linear Representation of Nonlinear Systems For Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04074">http://arxiv.org/abs/2309.04074</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tiwari-research-group/koopman-control-no-decoder">https://github.com/tiwari-research-group/koopman-control-no-decoder</a></li>
<li>paper_authors: Madhur Tiwari, George Nehma, Bethany Lusch</li>
<li>for: 这个研究旨在开发一种基于库曼算法的数据驱动框架，用于系统识别和非线性系统的线性化。</li>
<li>methods: 我们提出的方法基于深度学习框架，包括回归学习。我们使用一个线性quadratic控制来控制得到的线性系统。</li>
<li>results: 我们通过一个拖钩系统的示例来展示我们的方法，并在噪音数据上进行了仿真。我们发现，与Autoencoder为基础的方法相比，我们的方法更高效地训练，并且更准确地预测。<details>
<summary>Abstract</summary>
This work focuses on developing a data-driven framework using Koopman operator theory for system identification and linearization of nonlinear systems for control. Our proposed method presents a deep learning framework with recursive learning. The resulting linear system is controlled using a linear quadratic control. An illustrative example using a pendulum system is presented with simulations on noisy data. We show that our proposed method is trained more efficiently and is more accurate than an autoencoder baseline.
</details>
<details>
<summary>摘要</summary>
这个研究将关注使用库曼算法来建立数据驱动的框架，用于系统识别和线性化非线性系统，以便控制。我们提出的方法使用循环学习，并使用线性quadratic控制来控制得到的线性系统。我们通过用一个悬钩系统为例，并在噪声数据上进行了仿真，显示了我们的提议方法可以更高效地训练和更准确地识别。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Inferring-physical-laws-by-artificial-intelligence-based-causal-models"><a href="#Inferring-physical-laws-by-artificial-intelligence-based-causal-models" class="headerlink" title="Inferring physical laws by artificial intelligence based causal models"></a>Inferring physical laws by artificial intelligence based causal models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04069">http://arxiv.org/abs/2309.04069</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jorawar Singh, Kishor Bharti, Arvind</li>
<li>for: 这个论文旨在探讨人工智能和机器学习在科学研究中的应用，以及如何通过 causal learning 模型捕捉物理现象的 causal 关系。</li>
<li>methods: 这篇论文使用了 causal inference 和 intervención 的原则来研究物理现象的 causal 关系，并通过对一些常见物理现象的研究来证明模型的可靠性。</li>
<li>results: 研究发现，这种 causal learning 模型不仅可以捕捉数据之间的相关性，还可以正确地确定变量之间的 causal 关系，从而增强（或减弱）对模型的信任度。<details>
<summary>Abstract</summary>
The advances in Artificial Intelligence (AI) and Machine Learning (ML) have opened up many avenues for scientific research, and are adding new dimensions to the process of knowledge creation. However, even the most powerful and versatile of ML applications till date are primarily in the domain of analysis of associations and boil down to complex data fitting. Judea Pearl has pointed out that Artificial General Intelligence must involve interventions involving the acts of doing and imagining. Any machine assisted scientific discovery thus must include casual analysis and interventions. In this context, we propose a causal learning model of physical principles, which not only recognizes correlations but also brings out casual relationships. We use the principles of causal inference and interventions to study the cause-and-effect relationships in the context of some well-known physical phenomena. We show that this technique can not only figure out associations among data, but is also able to correctly ascertain the cause-and-effect relations amongst the variables, thereby strengthening (or weakening) our confidence in the proposed model of the underlying physical process.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）和机器学习（ML）的进步开创了许多科研领域的可能性，增加了知识创造的新维度。然而，至今最强大和多样化的ML应用都是对关系分析的，即使是复杂数据适应。 Judah Pearl指出，人工通用智能必须包括干预和想象的行为。因此，任何机器帮助科研发现都必须包括 causal 分析和干预。在这个上下文中，我们提议一种 causal 学习模型，不仅认可关系，还能够揭示 causal 关系。我们使用 causal 推理和干预来研究物理现象中的因果关系。我们示例了这种技术不仅可以找出数据中的相关性，还能够正确地确定变量之间的因果关系，从而增强（或削弱）我们对下面物理过程的模型的信任程度。
</details></li>
</ul>
<hr>
<h2 id="3D-Denoisers-are-Good-2D-Teachers-Molecular-Pretraining-via-Denoising-and-Cross-Modal-Distillation"><a href="#3D-Denoisers-are-Good-2D-Teachers-Molecular-Pretraining-via-Denoising-and-Cross-Modal-Distillation" class="headerlink" title="3D Denoisers are Good 2D Teachers: Molecular Pretraining via Denoising and Cross-Modal Distillation"></a>3D Denoisers are Good 2D Teachers: Molecular Pretraining via Denoising and Cross-Modal Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.04062">http://arxiv.org/abs/2309.04062</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sungjun Cho, Dae-Woong Jeong, Sung Moon Ko, Jinwoo Kim, Sehui Han, Seunghoon Hong, Honglak Lee, Moontae Lee</li>
<li>for: 本研究旨在开发一种自然语言处理技术，用于提高分子性质预测的准确率和效率。</li>
<li>methods: 本研究使用了一种名为D&amp;D的自适应分子表示学习框架，通过对3D杂交的知识进行填充和跨模态知识传递来学习分子表示。</li>
<li>results: 实验表明，使用D&amp;D框架学习的图表示能够基于2D图像推断3D信息，并在实际分子性质预测任务中表现出优于其他基eline。<details>
<summary>Abstract</summary>
Pretraining molecular representations from large unlabeled data is essential for molecular property prediction due to the high cost of obtaining ground-truth labels. While there exist various 2D graph-based molecular pretraining approaches, these methods struggle to show statistically significant gains in predictive performance. Recent work have thus instead proposed 3D conformer-based pretraining under the task of denoising, which led to promising results. During downstream finetuning, however, models trained with 3D conformers require accurate atom-coordinates of previously unseen molecules, which are computationally expensive to acquire at scale. In light of this limitation, we propose D&D, a self-supervised molecular representation learning framework that pretrains a 2D graph encoder by distilling representations from a 3D denoiser. With denoising followed by cross-modal knowledge distillation, our approach enjoys use of knowledge obtained from denoising as well as painless application to downstream tasks with no access to accurate conformers. Experiments on real-world molecular property prediction datasets show that the graph encoder trained via D&D can infer 3D information based on the 2D graph and shows superior performance and label-efficiency against other baselines.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传统的分类任务中使用大量标注数据进行预训练是不可避免的，因为获取标注数据的成本很高。然而，现有的2D图形基于的分子预训练方法很难实现 statistically significant的提升。最近的研究则提出了基于3D杂化的分子预训练，这些方法在预测性能方面具有了良好的结果。然而，在下游训练中，使用3D杂化的模型需要在未看过的分子上获取高精度的原子坐标，这是 computationally expensive的。为了解决这个限制，我们提出了 D&D，一种自助学习的分子表示学习框架，通过减噪和跨模态知识传递来预训练2D图形编码器。我们的方法可以充分利用减噪中获得的知识，同时在下游任务中不需要高精度的原子坐标。实验表明，通过 D&D 预训练的图形编码器可以基于2D图形中推断出3D信息，并与其他基准方法相比具有更好的性能和标签效率。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format instead.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/08/cs.AI_2023_09_08/" data-id="clogxf3ki003r5xrahza23nwb" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/38/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/37/">37</a><a class="page-number" href="/page/38/">38</a><span class="page-number current">39</span><a class="page-number" href="/page/40/">40</a><a class="page-number" href="/page/41/">41</a><span class="space">&hellip;</span><a class="page-number" href="/page/83/">83</a><a class="extend next" rel="next" href="/page/40/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">115</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">55</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">111</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">61</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
