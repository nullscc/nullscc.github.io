
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/35/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.CL_2023_09_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/22/cs.CL_2023_09_22/" class="article-date">
  <time datetime="2023-09-22T11:00:00.000Z" itemprop="datePublished">2023-09-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/22/cs.CL_2023_09_22/">cs.CL - 2023-09-22</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Document-Understanding-for-Healthcare-Referrals"><a href="#Document-Understanding-for-Healthcare-Referrals" class="headerlink" title="Document Understanding for Healthcare Referrals"></a>Document Understanding for Healthcare Referrals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13184">http://arxiv.org/abs/2309.13184</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Jimit Mistry, Natalia M. Arzeno</li>
<li>for: 提高医疗referral管理效率，减少管理成本和错误</li>
<li>methods: 提出了一种гибрид模型，结合LayoutLMv3和域pecific规则，用于在传输referral文档中自动识别关键病人、医生和检查相关信息</li>
<li>results: 结果表明，通过添加域pecific规则，使用变换器模型的精度和F1分数得到了大幅提高，表明混合模型在实际应用中可以提高referral管理效率。<details>
<summary>Abstract</summary>
Reliance on scanned documents and fax communication for healthcare referrals leads to high administrative costs and errors that may affect patient care. In this work we propose a hybrid model leveraging LayoutLMv3 along with domain-specific rules to identify key patient, physician, and exam-related entities in faxed referral documents. We explore some of the challenges in applying a document understanding model to referrals, which have formats varying by medical practice, and evaluate model performance using MUC-5 metrics to obtain appropriate metrics for the practical use case. Our analysis shows the addition of domain-specific rules to the transformer model yields greatly increased precision and F1 scores, suggesting a hybrid model trained on a curated dataset can increase efficiency in referral management.
</details>
<details>
<summary>摘要</summary>
靠扫描文档和传真communication для医疗referral导致高行政成本和错误，这些错误可能影响病人护理。在这个工作中，我们提出了一种hybrid模型，利用LayoutLMv3 alongside domain-specific规则来标识患者、医生和检查相关实体在传真referral文档中。我们探讨了应用文档理解模型到referral的挑战，因为referral的格式可能因医疗实践而异常，并评估模型性能使用MUC-5指标，以获得实用的指标。我们的分析显示，将域专门规则添加到变换器模型可以提高准确率和F1分数，表明一种基于 cura dataset的hybrid模型可以提高referral管理的效率。
</details></li>
</ul>
<hr>
<h2 id="Effective-Distillation-of-Table-based-Reasoning-Ability-from-LLMs"><a href="#Effective-Distillation-of-Table-based-Reasoning-Ability-from-LLMs" class="headerlink" title="Effective Distillation of Table-based Reasoning Ability from LLMs"></a>Effective Distillation of Table-based Reasoning Ability from LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13182">http://arxiv.org/abs/2309.13182</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bohao Yang, Chen Tang, Kun Zhao, Chenghao Xiao, Chenghua Lin<br>for:This paper aims to specialize table reasoning skills in smaller models for table-to-text generation tasks.methods:The proposed method uses distillation to transfer specific capabilities of large language models (LLMs) to smaller models, specifically tailored for table-based reasoning.results:The fine-tuned model (Flan-T5-base) achieved significant improvement compared to traditional baselines and outperformed specific LLMs like gpt-3.5-turbo on the scientific table-to-text generation dataset (SciGen).<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have demonstrated remarkable performance across a wide range of natural language processing tasks. However, their remarkable parameter size and their impressive high requirement of computing resources pose challenges for their practical deployment. Recent research has revealed that specific capabilities of LLMs, such as numerical reasoning, can be transferred to smaller models through distillation. Some studies explore the potential of leveraging LLMs to perform table-based reasoning. Nevertheless, prior to our work, there has been no investigation into the prospect of specialising table reasoning skills in smaller models specifically tailored for table-to-text generation tasks. In this paper, we propose a novel table-based reasoning distillation, with the aim of distilling distilling LLMs into tailored, smaller models specifically designed for table-based reasoning task. Experimental results have shown that a 0.22 billion parameter model (Flan-T5-base) fine-tuned using distilled data, not only achieves a significant improvement compared to traditionally fine-tuned baselines but also surpasses specific LLMs like gpt-3.5-turbo on the scientific table-to-text generation dataset (SciGen). The code and data are released in https://github.com/Bernard-Yang/TableDistill.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="BenLLMEval-A-Comprehensive-Evaluation-into-the-Potentials-and-Pitfalls-of-Large-Language-Models-on-Bengali-NLP"><a href="#BenLLMEval-A-Comprehensive-Evaluation-into-the-Potentials-and-Pitfalls-of-Large-Language-Models-on-Bengali-NLP" class="headerlink" title="BenLLMEval: A Comprehensive Evaluation into the Potentials and Pitfalls of Large Language Models on Bengali NLP"></a>BenLLMEval: A Comprehensive Evaluation into the Potentials and Pitfalls of Large Language Models on Bengali NLP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13173">http://arxiv.org/abs/2309.13173</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohsinul Kabir, Mohammed Saidul Islam, Md Tahmid Rahman Laskar, Mir Tafseer Nayeem, M Saiful Bari, Enamul Hoque</li>
<li>for: 本研究评估了大型自然语言处理（NLP）模型（LLMs）在低资源语言如孟加拉语（Bangla）中的表现。</li>
<li>methods: 本研究使用了多种重要和多样化的孟加拉语NLP任务，如抽象摘要、问答、重叠、自然语言推理、文本分类和情感分析，对ChatGPT、LLaMA-2和Claude-2等LLMs进行零搅evaluation，并比较其表现与现有的精度调整模型。</li>
<li>results: 实验结果显示了不同孟加拉语NLP任务中LLMs的表现较差，这表明需要进一步的研究以提高LLMs在低资源语言如孟加拉语的理解。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have emerged as one of the most important breakthroughs in natural language processing (NLP) for their impressive skills in language generation and other language-specific tasks. Though LLMs have been evaluated in various tasks, mostly in English, they have not yet undergone thorough evaluation in under-resourced languages such as Bengali (Bangla). In this paper, we evaluate the performance of LLMs for the low-resourced Bangla language. We select various important and diverse Bangla NLP tasks, such as abstractive summarization, question answering, paraphrasing, natural language inference, text classification, and sentiment analysis for zero-shot evaluation with ChatGPT, LLaMA-2, and Claude-2 and compare the performance with state-of-the-art fine-tuned models. Our experimental results demonstrate an inferior performance of LLMs for different Bangla NLP tasks, calling for further effort to develop better understanding of LLMs in low-resource languages like Bangla.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）已经被认为是自然语言处理（NLP）领域的一个重要突破，它们在语言生成和其他语言特定任务中表现出了卓越的能力。虽然 LLM 已经在英语等语言上进行了评估，但它们尚未在低资源语言 such as 孟加拉语（Bangla）进行了系统性的评估。在这篇论文中，我们对低资源 Bangla 语言进行了 LLM 的评估。我们选择了一些重要和多样的 Bangla NLP 任务，如抽象摘要、问答、重叠、自然语言推理、文本分类和情感分析，并对 ChatGPT、LLaMA-2 和 Claude-2 进行零 shot 评估，并与当前的精度模型进行比较。我们的实验结果表明 LLMs 在不同的 Bangla NLP 任务中表现出了较差的性能，这表明需要进一步的研究，以更好地理解 LLMs 在低资源语言如 Bangla 的性能。
</details></li>
</ul>
<hr>
<h2 id="Cardiovascular-Disease-Risk-Prediction-via-Social-Media"><a href="#Cardiovascular-Disease-Risk-Prediction-via-Social-Media" class="headerlink" title="Cardiovascular Disease Risk Prediction via Social Media"></a>Cardiovascular Disease Risk Prediction via Social Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13147">http://arxiv.org/abs/2309.13147</a></li>
<li>repo_url: None</li>
<li>paper_authors: Al Zadid Sultan Bin Habib, Md Asif Bin Syed, Md Tanvirul Islam, Donald A. Adjeroh</li>
<li>for: 预测心血管疾病（CVD）风险</li>
<li>methods: 使用推特和情感分析预测CVD风险，开发了新的CVD相关关键词词典，并使用VADER模型进行情感分析，将用户分类为可能存在CVD风险</li>
<li>results: 结果表明通过分析推特中的情感，可以超过基于人口数据alone的预测力，并能够识别可能发展CVD的个体，这些结果表明了自然语言处理和机器学习技术在使用推特来识别CVD风险的潜力。<details>
<summary>Abstract</summary>
Researchers use Twitter and sentiment analysis to predict Cardiovascular Disease (CVD) risk. We developed a new dictionary of CVD-related keywords by analyzing emotions expressed in tweets. Tweets from eighteen US states, including the Appalachian region, were collected. Using the VADER model for sentiment analysis, users were classified as potentially at CVD risk. Machine Learning (ML) models were employed to classify individuals' CVD risk and applied to a CDC dataset with demographic information to make the comparison. Performance evaluation metrics such as Test Accuracy, Precision, Recall, F1 score, Mathew's Correlation Coefficient (MCC), and Cohen's Kappa (CK) score were considered. Results demonstrated that analyzing tweets' emotions surpassed the predictive power of demographic data alone, enabling the identification of individuals at potential risk of developing CVD. This research highlights the potential of Natural Language Processing (NLP) and ML techniques in using tweets to identify individuals with CVD risks, providing an alternative approach to traditional demographic information for public health monitoring.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Dynamic-ASR-Pathways-An-Adaptive-Masking-Approach-Towards-Efficient-Pruning-of-A-Multilingual-ASR-Model"><a href="#Dynamic-ASR-Pathways-An-Adaptive-Masking-Approach-Towards-Efficient-Pruning-of-A-Multilingual-ASR-Model" class="headerlink" title="Dynamic ASR Pathways: An Adaptive Masking Approach Towards Efficient Pruning of A Multilingual ASR Model"></a>Dynamic ASR Pathways: An Adaptive Masking Approach Towards Efficient Pruning of A Multilingual ASR Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13018">http://arxiv.org/abs/2309.13018</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiamin Xie, Ke Li, Jinxi Guo, Andros Tjandra, Yuan Shangguan, Leda Sari, Chunyang Wu, Junteng Jia, Jay Mahadeokar, Ozlem Kalinli</li>
<li>for: 这个研究的目的是实现对多语言自动话语识别（ASR）模型的压缩，并且将其转换为单语言模型或多语言模型。</li>
<li>methods: 这个研究使用了适应性遮盾方法，包括两个情况：一是生成简单的单语言模型，二是将多语言模型转换为简单的多语言模型。这个方法可以避免固定的子网络结构，并且在不同的初始化情况下进行适应。</li>
<li>results: 这个研究发现，使用适应性遮盾方法可以在对多语言模型进行压缩时，比较有效率，并且可以实现更好的表现。此外，这个方法可以将多语言模型转换为简单的多语言模型，并且可以实现更好的表现。<details>
<summary>Abstract</summary>
Neural network pruning offers an effective method for compressing a multilingual automatic speech recognition (ASR) model with minimal performance loss. However, it entails several rounds of pruning and re-training needed to be run for each language. In this work, we propose the use of an adaptive masking approach in two scenarios for pruning a multilingual ASR model efficiently, each resulting in sparse monolingual models or a sparse multilingual model (named as Dynamic ASR Pathways). Our approach dynamically adapts the sub-network, avoiding premature decisions about a fixed sub-network structure. We show that our approach outperforms existing pruning methods when targeting sparse monolingual models. Further, we illustrate that Dynamic ASR Pathways jointly discovers and trains better sub-networks (pathways) of a single multilingual model by adapting from different sub-network initializations, thereby reducing the need for language-specific pruning.
</details>
<details>
<summary>摘要</summary>
中文简体版：神经网络剪枝提供了一种有效的压缩方法，以最小化多语言自动语音识别（ASR）模型的性能损失。然而，它需要每种语言进行多轮剪枝和重新训练。在这个工作中，我们提议使用适应maskingapproach来有效地剪枝多语言ASR模型，分别得到简洁的单语言模型或简洁的多语言模型（名为动态ASR PATHways）。我们的方法可以动态适应子网络，避免提前决定固定子网络结构。我们显示，我们的方法在targeting简洁的单语言模型时比既有的剪枝方法高效。此外，我们还示出了Dynamic ASR PATHways可以将多语言模型中的不同子网络初始化相互转换，从而降低语言特定的剪枝需求。
</details></li>
</ul>
<hr>
<h2 id="Nested-Event-Extraction-upon-Pivot-Element-Recogniton"><a href="#Nested-Event-Extraction-upon-Pivot-Element-Recogniton" class="headerlink" title="Nested Event Extraction upon Pivot Element Recogniton"></a>Nested Event Extraction upon Pivot Element Recogniton</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12960">http://arxiv.org/abs/2309.12960</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weicheng Ren, Zixuan Li, Xiaolong Jin, Long Bai, Miao Su, Yantao Liu, Saiping Guan, Jiafeng Guo, Xueqi Cheng</li>
<li>for: 提高复杂事件结构抽取精度，解决现有方法不能很好地处理嵌入式事件结构中的 pivot element 问题。</li>
<li>methods: 基于识别触发器对 triggers 和 arguments 的类型和关系进行分类，并通过提示学习获得更好的触发器和 argue 的表示，以提高 NEE 性能。</li>
<li>results: PerNee 在 ACE2005-Nest、Genia11 和 Genia13 上实现了状态之冠性表现，提高了 NEE 精度。<details>
<summary>Abstract</summary>
Nested Event Extraction (NEE) aims to extract complex event structures where an event contains other events as its arguments recursively. Nested events involve a kind of Pivot Elements (PEs) that simultaneously act as arguments of outer events and as triggers of inner events, and thus connect them into nested structures. This special characteristic of PEs brings challenges to existing NEE methods, as they cannot well cope with the dual identities of PEs. Therefore, this paper proposes a new model, called PerNee, which extracts nested events mainly based on recognizing PEs. Specifically, PerNee first recognizes the triggers of both inner and outer events and further recognizes the PEs via classifying the relation type between trigger pairs. In order to obtain better representations of triggers and arguments to further improve NEE performance, it incorporates the information of both event types and argument roles into PerNee through prompt learning. Since existing NEE datasets (e.g., Genia11) are limited to specific domains and contain a narrow range of event types with nested structures, we systematically categorize nested events in generic domain and construct a new NEE dataset, namely ACE2005-Nest. Experimental results demonstrate that PerNee consistently achieves state-of-the-art performance on ACE2005-Nest, Genia11 and Genia13.
</details>
<details>
<summary>摘要</summary>
嵌入式事件提取（NEE）目标是提取嵌入式事件结构，其中事件包含其他事件作为自身参数的嵌入式结构。嵌入事件中的 pivot 元素（PE）同时作为外部事件的参数和内部事件的触发器，因此将其连接到嵌入结构中。这种特殊的 PE 特点带来了现有 NEE 方法的挑战，因为它们无法好地处理 PE 的双重身份。因此，本文提出了一种新模型，即 PerNee，它基于认可 PE 来提取嵌入事件。具体来说，PerNee 先认可外部和内部事件的触发器，然后通过类型化 trigger 对的关系来认定 PE。为了从trigger和参数角度获得更好的表示，PerNee 通过推训来 incorporate 事件类型和参数角色信息。由于现有 NEE 数据集（如 Genia11）限制在特定领域，并且只包含一些嵌入式事件结构，我们系统地分类嵌入事件在通用领域，并构建了一个新的 NEE 数据集，即 ACE2005-Nest。实验结果表明，PerNee 在 ACE2005-Nest、Genia11 和 Genia13 上具有状态的表现。
</details></li>
</ul>
<hr>
<h2 id="TopRoBERTa-Topology-Aware-Authorship-Attribution-of-Deepfake-Texts"><a href="#TopRoBERTa-Topology-Aware-Authorship-Attribution-of-Deepfake-Texts" class="headerlink" title="TopRoBERTa: Topology-Aware Authorship Attribution of Deepfake Texts"></a>TopRoBERTa: Topology-Aware Authorship Attribution of Deepfake Texts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12934">http://arxiv.org/abs/2309.12934</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adaku Uchendu, Thai Le, Dongwon Lee</li>
<li>for: 本研究旨在开发一种可以判断文本是否为深度伪造文本（deepfake text）的计算方法，以mitigate大量深度伪造文本的散布。</li>
<li>methods: 本研究使用了Topological Data Analysis（TDA）层和RoBERTa模型，以capture更多的语言特征和结构特征，提高作者识别率。</li>
<li>results: 对于3个 datasets，TopRoBERTa模型比vanilla RoBERTa模型提高了2&#x2F;3的Macro F1分数，最高提高7%。<details>
<summary>Abstract</summary>
Recent advances in Large Language Models (LLMs) have enabled the generation of open-ended high-quality texts, that are non-trivial to distinguish from human-written texts. We refer to such LLM-generated texts as \emph{deepfake texts}. There are currently over 11K text generation models in the huggingface model repo. As such, users with malicious intent can easily use these open-sourced LLMs to generate harmful texts and misinformation at scale. To mitigate this problem, a computational method to determine if a given text is a deepfake text or not is desired--i.e., Turing Test (TT). In particular, in this work, we investigate the more general version of the problem, known as \emph{Authorship Attribution (AA)}, in a multi-class setting--i.e., not only determining if a given text is a deepfake text or not but also being able to pinpoint which LLM is the author. We propose \textbf{TopRoBERTa} to improve existing AA solutions by capturing more linguistic patterns in deepfake texts by including a Topological Data Analysis (TDA) layer in the RoBERTa model. We show the benefits of having a TDA layer when dealing with noisy, imbalanced, and heterogeneous datasets, by extracting TDA features from the reshaped $pooled\_output$ of RoBERTa as input. We use RoBERTa to capture contextual representations (i.e., semantic and syntactic linguistic features), while using TDA to capture the shape and structure of data (i.e., linguistic structures). Finally, \textbf{TopRoBERTa}, outperforms the vanilla RoBERTa in 2/3 datasets, achieving up to 7\% increase in Macro F1 score.
</details>
<details>
<summary>摘要</summary>
最近的大语言模型（LLM）技术的进步，使得可以生成高质量、不易于 distinguishing 的文本，我们称之为“深伪文本”。目前已经有超过 11K 的文本生成模型在 huggingface 模型库中。因此，有恶意用户可以使用这些开源的 LLM 生成大量的危险文本和谣言。为了解决这问题，一种计算方法是需要的——namely，Turing Test（TT）。在这种情况下，我们研究了一个更一般的问题——作者归属问题（AA），在多类别Setting下进行研究——即不仅是判断给定文本是否是深伪文本，还可以确定这个文本的作者是哪个 LLM。我们提出了 TopRoBERTa，用于改进现有 AA 解决方案，通过包含 Topological Data Analysis（TDA）层在 RoBERTa 模型中，从而更好地捕捉深伪文本中的语言特征。我们通过对不规则、不均衡和不一致的数据进行处理，提取 TDA 特征从 RoBERTa 模型中的 pooling 输出中。我们使用 RoBERTa 模型来捕捉语义和语法特征，而使用 TDA 来捕捉数据的形态和结构特征。最后，TopRoBERTa 在 2/3 个数据集上表现出色，与原始 RoBERTa 相比，提高了 macro F1 得分的最高7%。
</details></li>
</ul>
<hr>
<h2 id="PopBERT-Detecting-populism-and-its-host-ideologies-in-the-German-Bundestag"><a href="#PopBERT-Detecting-populism-and-its-host-ideologies-in-the-German-Bundestag" class="headerlink" title="PopBERT. Detecting populism and its host ideologies in the German Bundestag"></a>PopBERT. Detecting populism and its host ideologies in the German Bundestag</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14355">http://arxiv.org/abs/2309.14355</a></li>
<li>repo_url: None</li>
<li>paper_authors: L. Erhard, S. Hanke, U. Remer, A. Falenska, R. Heiberger</li>
<li>for: 本研究旨在提供一种可靠、有效、可扩展的方法来评估民粹主义的语言表达。</li>
<li>methods: 我们创建了基于德国bundestag（2013-2021年）的 parliamentary speeches 的标注 dataset，并采用 transformer-based 模型（PopBERT）作为多类分类器来检测和评估民粹主义语言的多个维度。</li>
<li>results: 验证检查表明，PopBERT 具有强的预测准确率、高质量的面效VALIDITY、与专家调查中党派排名相符、并能正确地检测新的文本片断。PopBERT 可以为德语政治家和党派的语言使用提供动态分析，以及可以在跨领域应用或开发相关的分类器。<details>
<summary>Abstract</summary>
The rise of populism concerns many political scientists and practitioners, yet the detection of its underlying language remains fragmentary. This paper aims to provide a reliable, valid, and scalable approach to measure populist stances. For that purpose, we created an annotated dataset based on parliamentary speeches of the German Bundestag (2013 to 2021). Following the ideational definition of populism, we label moralizing references to the virtuous people or the corrupt elite as core dimensions of populist language. To identify, in addition, how the thin ideology of populism is thickened, we annotate how populist statements are attached to left-wing or right-wing host ideologies. We then train a transformer-based model (PopBERT) as a multilabel classifier to detect and quantify each dimension. A battery of validation checks reveals that the model has a strong predictive accuracy, provides high qualitative face validity, matches party rankings of expert surveys, and detects out-of-sample text snippets correctly. PopBERT enables dynamic analyses of how German-speaking politicians and parties use populist language as a strategic device. Furthermore, the annotator-level data may also be applied in cross-domain applications or to develop related classifiers.
</details>
<details>
<summary>摘要</summary>
populism 的崛起引起了许多政治科学家和实践者的关注，但检测其下面的语言 ainda是 fragmentary。这篇论文目的是提供一种可靠、有效、可扩展的方法来评估 populist 的立场。为此，我们创建了基于德国bundestag parliamentary speeches（2013-2021）的注释数据集。根据意识形态的定义，我们将 moralizing 引用为贤良人或腐败的エリー特定为 populist 语言的核心维度。此外，为了了解 populist 语言如何被膨胀，我们还注释了 populist 声明与左翼或右翼的主义相关的hosts。然后，我们使用 transformer 基本模型（PopBERT）作为多类归一类ifier来检测和评估每一维度。一系列的验证检查表明，模型具有强大预测精度，提供高质量的面 validate，匹配党派评估专家调查的排名，并正确地检测出 sample 文本片段。PopBERT 允许我们动态地分析德语政治人物和党派如何使用 populist 语言作为策略工具。此外，注释数据还可以在跨领域应用或开发相关的分类器。
</details></li>
</ul>
<hr>
<h2 id="Affect-Recognition-in-Conversations-Using-Large-Language-Models"><a href="#Affect-Recognition-in-Conversations-Using-Large-Language-Models" class="headerlink" title="Affect Recognition in Conversations Using Large Language Models"></a>Affect Recognition in Conversations Using Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12881">http://arxiv.org/abs/2309.12881</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shutong Feng, Guangzhi Sun, Nurul Lubis, Chao Zhang, Milica Gašić</li>
<li>for: 本研究旨在探讨大语言模型（LLMs）在对话中识别人类情感的能力，包括开放领域对话和任务导向对话。</li>
<li>methods: 研究使用了三个不同的数据集：IEMOCAP、EmoWOZ和DAIC-WOZ，这些数据集涵盖了从伙伴对话到医疗采访的对话。研究使用了零shot和几shot学习，以及任务特定的精度调整，来评估和比较LLMs的表现。</li>
<li>results: 研究发现LLMs在情感识别方面具有一定的能力，但是其表现受到自动语音识别（ASR）错误的影响。通过这项研究，我们希望探讨LLMs在对话中是否可以模拟人类的情感识别能力。<details>
<summary>Abstract</summary>
Affect recognition, encompassing emotions, moods, and feelings, plays a pivotal role in human communication. In the realm of conversational artificial intelligence (AI), the ability to discern and respond to human affective cues is a critical factor for creating engaging and empathetic interactions. This study delves into the capacity of large language models (LLMs) to recognise human affect in conversations, with a focus on both open-domain chit-chat dialogues and task-oriented dialogues. Leveraging three diverse datasets, namely IEMOCAP, EmoWOZ, and DAIC-WOZ, covering a spectrum of dialogues from casual conversations to clinical interviews, we evaluated and compared LLMs' performance in affect recognition. Our investigation explores the zero-shot and few-shot capabilities of LLMs through in-context learning (ICL) as well as their model capacities through task-specific fine-tuning. Additionally, this study takes into account the potential impact of automatic speech recognition (ASR) errors on LLM predictions. With this work, we aim to shed light on the extent to which LLMs can replicate human-like affect recognition capabilities in conversations.
</details>
<details>
<summary>摘要</summary>
人类communication中，情感认知（affect recognition）发挥关键作用。在人工智能对话中，能够识别和回应人类情感cue的能力是创造有趣和同情的交互的关键因素。本研究探讨了大型自然语言模型（LLMs）在对话中识别人类情感的能力，包括开放领域对话和任务导向对话。通过使用三个多样化的数据集，namely IEMOCAP、EmoWOZ和DAIC-WOZ，覆盖了对话的广泛spectrum，从互斥对话到临床采访，我们评估和比较了LLMs的表现。我们的调查探讨了LLMs在零shot和几shot情况下的能力，以及通过任务特定的精度调整来提高模型 capacities。此外，本研究还考虑了自动语音识别（ASR）错误对LLM预测的影响。通过这项工作，我们希望探讨LLMs在对话中是否能够模拟人类情感认知能力。
</details></li>
</ul>
<hr>
<h2 id="StyloMetrix-An-Open-Source-Multilingual-Tool-for-Representing-Stylometric-Vectors"><a href="#StyloMetrix-An-Open-Source-Multilingual-Tool-for-Representing-Stylometric-Vectors" class="headerlink" title="StyloMetrix: An Open-Source Multilingual Tool for Representing Stylometric Vectors"></a>StyloMetrix: An Open-Source Multilingual Tool for Representing Stylometric Vectors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12810">http://arxiv.org/abs/2309.12810</a></li>
<li>repo_url: None</li>
<li>paper_authors: Inez Okulska, Daria Stetsenko, Anna Kołos, Agnieszka Karlińska, Kinga Głąbińska, Adam Nowakowski</li>
<li>for: 这个论文的目的是为开源多语言工具StyloMetrix提供一个概述。这个工具提供了不同语言的语法、 синтакси和词汇方面的语料，覆盖了波兰语、英语、乌克兰语和俄语四种语言。</li>
<li>methods: 这个论文使用了StyloMetrix工具来生成各种语言的语料，并对这些语料进行了normalization处理。然后，使用了不同的机器学习算法进行超参数的评估。</li>
<li>results: 实验结果表明，StyloMetrix vectors可以在不同的语言上进行有效的内容分类，并且可以帮助提高深度学习算法的表现。在Random Forest Classifier、Voting Classifier、Logistic Regression等简单机器学习算法上进行了超参数的评估，并且在Transformer架构上进行了深度学习的评估。<details>
<summary>Abstract</summary>
This work aims to provide an overview on the open-source multilanguage tool called StyloMetrix. It offers stylometric text representations that cover various aspects of grammar, syntax and lexicon. StyloMetrix covers four languages: Polish as the primary language, English, Ukrainian and Russian. The normalized output of each feature can become a fruitful course for machine learning models and a valuable addition to the embeddings layer for any deep learning algorithm. We strive to provide a concise, but exhaustive overview on the application of the StyloMetrix vectors as well as explain the sets of the developed linguistic features. The experiments have shown promising results in supervised content classification with simple algorithms as Random Forest Classifier, Voting Classifier, Logistic Regression and others. The deep learning assessments have unveiled the usefulness of the StyloMetrix vectors at enhancing an embedding layer extracted from Transformer architectures. The StyloMetrix has proven itself to be a formidable source for the machine learning and deep learning algorithms to execute different classification tasks.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "stylometric" is translated as "式文学的" (shìwén xué de), which is a compound word consisting of "式" (shì) meaning "style" and "文学" (wénxué) meaning "literature" or "linguistics".* "multilanguage" is translated as "多语言" (duō yǔyán), which is a compound word consisting of "多" (duō) meaning "many" and "语言" (yǔyán) meaning "language".* "tool" is translated as "工具" (gōngjù), which is a generic term for any device or software used to perform a specific task.* "cover" is translated as "覆盖" (fùkài), which means "to cover" or "to encompass".* "aspects" is translated as "方面" (fāngmiàn), which means "aspects" or "facets".* "grammar" is translated as "语法" (yǔfǎ), which is the study of the rules and structures of a language.* "syntax" is translated as "语法结构" (yǔfǎ jiégòu), which is the study of the arrangement of words and phrases to form sentences.* "lexicon" is translated as "词汇" (cíhuì), which is a collection of words and their meanings.* "normalized" is translated as "标准化" (biǎozhǔn huà), which means "to make something conform to a standard or norm".* "output" is translated as "输出" (shūchū), which means "output" or "result".* "feature" is translated as "特征" (tèzhèng), which means "feature" or "characteristic".* "developed" is translated as "开发" (kāifā), which means "to develop" or "to create".* "linguistic" is translated as "语言学的" (yǔyán xué de), which is a compound word consisting of "语言" (yǔyán) meaning "language" and "学的" (xué de) meaning "academic" or "scholarly".* "fruitful" is translated as "有益" (yǒu yì), which means "beneficial" or "useful".* "course" is translated as "课程" (kèchéng), which means "course" or "program".* "machine learning" is translated as "机器学习" (jīqì xuéxí), which is a compound word consisting of "机器" (jīqì) meaning "machine" and "学习" (xuéxí) meaning "learning" or "study".* "deep learning" is translated as "深度学习" (shēngrù xuéxí), which is a compound word consisting of "深度" (shēngrù) meaning "depth" and "学习" (xuéxí) meaning "learning" or "study".* "supervised" is translated as "监督学习" (jiāndū xuéxí), which is a compound word consisting of "监督" (jiāndū) meaning "supervise" and "学习" (xuéxí) meaning "learning" or "study".* "content classification" is translated as "内容分类" (nèiróng fēnlèi), which is a compound word consisting of "内容" (nèiróng) meaning "content" and "分类" (fēnlèi) meaning "classification" or "categorization".* "simple algorithms" is translated as "简单的算法" (jiǎnduō de suānfǎ), which is a compound word consisting of "简单" (jiǎnduō) meaning "simple" and "算法" (suānfǎ) meaning "algorithm".* "random forest classifier" is translated as "随机森林分类器" (suījì sēnjīn fēnlèi zhīngjī), which is a compound word consisting of "随机" (suījì) meaning "random" and "森林" (sēnjīn) meaning "forest" and "分类器" (fēnlèi zhīngjī) meaning "classifier".* "voting classifier" is translated as "投票分类器" (tóuchòu fēnlèi zhīngjī), which is a compound word consisting of "投票" (tóuchòu) meaning "vote" and "分类器" (fēnlèi zhīngjī) meaning "classifier".* "logistic regression" is translated as "逻辑回归" (suǒyì huíqiù), which is a compound word consisting of "逻辑" (suǒyì) meaning "logic" and "回归" (huíqiù) meaning "regression".* "deep learning assessments" is translated as "深度学习评估" (shēngrù xuéxí píngjì), which is a compound word consisting of "深度" (shēngrù) meaning "depth" and "学习" (xuéxí) meaning "learning" or "study" and "评估" (píngjì) meaning "assessment" or "evaluation".* "Transformer architectures" is translated as "变换器架构" (biànhuà zhìgòu), which is a compound word consisting of "变换" (biànhuà) meaning "transformation" and "器架构" (zhìgòu) meaning "architecture".
</details></li>
</ul>
<hr>
<h2 id="ChatPRCS-A-Personalized-Support-System-for-English-Reading-Comprehension-based-on-ChatGPT"><a href="#ChatPRCS-A-Personalized-Support-System-for-English-Reading-Comprehension-based-on-ChatGPT" class="headerlink" title="ChatPRCS: A Personalized Support System for English Reading Comprehension based on ChatGPT"></a>ChatPRCS: A Personalized Support System for English Reading Comprehension based on ChatGPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12808">http://arxiv.org/abs/2309.12808</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xizhe Wang, Yihua Zhong, Changqin Huang, Xiaodi Huang</li>
<li>for: 提高学生的阅读理解能力</li>
<li>methods: 使用大语言模型技术，包括预测学生阅读理解水平、生成问题和自动评估等方法</li>
<li>results: 实验结果显示，ChatPRCS可以为学生提供高质量的阅读理解问题，与专家制定的问题相似程度有统计显著的相似性<details>
<summary>Abstract</summary>
As a common approach to learning English, reading comprehension primarily entails reading articles and answering related questions. However, the complexity of designing effective exercises results in students encountering standardized questions, making it challenging to align with individualized learners' reading comprehension ability. By leveraging the advanced capabilities offered by large language models, exemplified by ChatGPT, this paper presents a novel personalized support system for reading comprehension, referred to as ChatPRCS, based on the Zone of Proximal Development theory. ChatPRCS employs methods including reading comprehension proficiency prediction, question generation, and automatic evaluation, among others, to enhance reading comprehension instruction. First, we develop a new algorithm that can predict learners' reading comprehension abilities using their historical data as the foundation for generating questions at an appropriate level of difficulty. Second, a series of new ChatGPT prompt patterns is proposed to address two key aspects of reading comprehension objectives: question generation, and automated evaluation. These patterns further improve the quality of generated questions. Finally, by integrating personalized ability and reading comprehension prompt patterns, ChatPRCS is systematically validated through experiments. Empirical results demonstrate that it provides learners with high-quality reading comprehension questions that are broadly aligned with expert-crafted questions at a statistical level.
</details>
<details>
<summary>摘要</summary>
通常来说，学习英语的读写涉及到阅读文章并回答相关问题。然而，设计有效的训练活动具有复杂性，导致学生遇到标准化的问题，困难与个性化学生的读写理解水平进行对应。本文基于大语言模型的高级功能，例如ChatGPT，提出了一种新的个性化支持系统，称为ChatPRCS，基于读写理解能力的发展Zone of Proximal Development理论。ChatPRCS使用包括读写理解能力预测、问题生成和自动评估等方法，以提高读写理解教学。首先，我们开发了一种新的算法，可以根据学生的历史数据预测他们的读写理解能力，并使用这些数据来生成适合的题目。其次，我们提出了一系列新的ChatGPT提示模式，用于解决读写理解目标的两个关键方面：问题生成和自动评估。这些模式进一步提高生成的题目质量。最后，通过结合个性化能力和读写理解提示模式，我们系统化验证了ChatPRCS。实验结果表明，它可以为学生提供高质量的读写理解题目，与专家制作的问题在统计上保持一致。
</details></li>
</ul>
<hr>
<h2 id="Furthest-Reasoning-with-Plan-Assessment-Stable-Reasoning-Path-with-Retrieval-Augmented-Large-Language-Models"><a href="#Furthest-Reasoning-with-Plan-Assessment-Stable-Reasoning-Path-with-Retrieval-Augmented-Large-Language-Models" class="headerlink" title="Furthest Reasoning with Plan Assessment: Stable Reasoning Path with Retrieval-Augmented Large Language Models"></a>Furthest Reasoning with Plan Assessment: Stable Reasoning Path with Retrieval-Augmented Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12767">http://arxiv.org/abs/2309.12767</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yin Zhu, Zhiling Luo, Gong Cheng</li>
<li>for: 本研究旨在解决现有多步问答（MHQA）方法中的两个主要缺陷：一是信息检索器（IR）因为生成过程中的低质量问题而受到限制，二是语言模型（LLM）因为与 irrelevant knowledge 的交互而导致偏差。</li>
<li>methods: 本研究提出了一种新的管道方法，即 Furthest-Reasoning-with-Plan-Assessment（FuRePA），其包括一种改进的框架（Furthest Reasoning）和一个附加的模块（Plan Assessor）。 Furthest Reasoning operates by masking previous reasoning path and generated queries for LLM, encouraging LLM generating chain of thought from scratch in each iteration。 Plan Assessor 是一个训练过的评价器，可以选择 LLM 提出的合适的计划。</li>
<li>results: 本研究在三个公开的多步问答数据集上进行了评估，并与现有最佳方法进行比较。结果显示， FuRePA 在大多数指标上表现出色，相比之下， achieved a 10%-12% 的答案准确率。<details>
<summary>Abstract</summary>
Large Language Models (LLMs), acting as a powerful reasoner and generator, exhibit extraordinary performance across various natural language tasks, such as question answering (QA). Among these tasks, Multi-Hop Question Answering (MHQA) stands as a widely discussed category, necessitating seamless integration between LLMs and the retrieval of external knowledge. Existing methods employ LLM to generate reasoning paths and plans, and utilize IR to iteratively retrieve related knowledge, but these approaches have inherent flaws. On one hand, Information Retriever (IR) is hindered by the low quality of generated queries by LLM. On the other hand, LLM is easily misguided by the irrelevant knowledge by IR. These inaccuracies, accumulated by the iterative interaction between IR and LLM, lead to a disaster in effectiveness at the end. To overcome above barriers, in this paper, we propose a novel pipeline for MHQA called Furthest-Reasoning-with-Plan-Assessment (FuRePA), including an improved framework (Furthest Reasoning) and an attached module (Plan Assessor). 1) Furthest reasoning operates by masking previous reasoning path and generated queries for LLM, encouraging LLM generating chain of thought from scratch in each iteration. This approach enables LLM to break the shackle built by previous misleading thoughts and queries (if any). 2) The Plan Assessor is a trained evaluator that selects an appropriate plan from a group of candidate plans proposed by LLM. Our methods are evaluated on three highly recognized public multi-hop question answering datasets and outperform state-of-the-art on most metrics (achieving a 10%-12% in answer accuracy).
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）作为强大的理解和生成工具，在不同的自然语言任务中表现出色，其中包括多步 вопро答（MHQA）类型。在这些任务中，我们需要让 LLM 和外部知识的搜寻紧密相连。现有的方法使用 LLM 生成推理路径和计划，并使用 IR 逐步获取相关知识，但这些方法存在问题。一方面，资讯搜寻器（IR）受到 LLM 产生的问题质量低下的限制。另一方面， LLM 受到 IR 提供的无关知识的影响，导致错误的推理。这些错误，在 LLM 和 IR 之间的回归交互中累累积累，最终导致效率下降。为解决以上问题，在这篇论文中，我们提出了一个新的多步 вопро答（MHQA）管道，称为 Furthest-Reasoning-with-Plan-Assessment（FuRePA），包括改进的架构（ Furthest Reasoning）和附加的模组（ Plan Assessor）。1. Furthest Reasoning 运作方式是将前一次的推理路径和生成的问题遮盖，让 LLM 在每次回归中从头开始生成推理链。这种方法允许 LLM 破坏前一次的错误思维和问题（如果有），并将注意力集中在更加重要的问题上。2. Plan Assessor 是一个训练好的评估器，可以从 LLM 提供的候选计划中选择最佳的计划。我们的方法在三个公开的多步 вопро答 datasets 上进行评估，并在大多数指标上超越了现有的state-of-the-art（实现了10%-12%的答案精度提升）。
</details></li>
</ul>
<hr>
<h2 id="Reduce-Reuse-Recycle-Is-Perturbed-Data-better-than-Other-Language-augmentation-for-Low-Resource-Self-Supervised-Speech-Models"><a href="#Reduce-Reuse-Recycle-Is-Perturbed-Data-better-than-Other-Language-augmentation-for-Low-Resource-Self-Supervised-Speech-Models" class="headerlink" title="Reduce, Reuse, Recycle: Is Perturbed Data better than Other Language augmentation for Low Resource Self-Supervised Speech Models"></a>Reduce, Reuse, Recycle: Is Perturbed Data better than Other Language augmentation for Low Resource Self-Supervised Speech Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12763">http://arxiv.org/abs/2309.12763</a></li>
<li>repo_url: None</li>
<li>paper_authors: Asad Ullah, Alessandro Ragano, Andrew Hines</li>
<li>for: 本研究旨在提高low resource语言下的自主学习表示学习（SSRL）模型的表现，并评估其在下游phoneme认识任务中的性能。</li>
<li>methods: 本研究使用了音频扩展来预训SSRL模型，并评估其在phoneme认识任务中的表现。我们系统地比较了不同的扩展技术，包括拟音变化、噪音添加、重音目标语言speech和其他语言speech。我们发现，将扩展技术与拟音变化相结合（噪音&#x2F;拟音）是最佳扩展策略，超过了重音和语言知识传递。</li>
<li>results: 我们发现，使用具有不同量和类型的预训数据，SSRL模型在phoneme认识任务中的表现都有所提高。此外，我们还评估了扩展数据的缩放因子，以达到与target domain speech预训数据相等的性能。我们的发现表明，在resource受限的语言下，使用本地生成的扩展数据可以超过语言知识传递和其他语言speech的表现。<details>
<summary>Abstract</summary>
Self-supervised representation learning (SSRL) has improved the performance on downstream phoneme recognition versus supervised models. Training SSRL models requires a large amount of pre-training data and this poses a challenge for low resource languages. A common approach is transferring knowledge from other languages. Instead, we propose to use audio augmentation to pre-train SSRL models in a low resource condition and evaluate phoneme recognition as downstream task. We performed a systematic comparison of augmentation techniques, namely: pitch variation, noise addition, accented target-language speech and other language speech. We found combined augmentations (noise/pitch) was the best augmentation strategy outperforming accent and language knowledge transfer. We compared the performance with various quantities and types of pre-training data. We examined the scaling factor of augmented data to achieve equivalent performance to models pre-trained with target domain speech. Our findings suggest that for resource constrained languages, in-domain synthetic augmentation can outperform knowledge transfer from accented or other language speech.
</details>
<details>
<summary>摘要</summary>
自我指导学习（SSRL）已经提高了下游音频识别的性能，而不需要大量的标注数据。然而，对于低资源语言，具有大量预训练数据的困难。而不是通过语言知识传输，我们提议使用音频加工来预训练SSRL模型，并评估音频识别作为下游任务。我们进行了系统性的比较，包括噪音添加、抖音变化、外语言材料和对应语言材料。我们发现将噪音和抖音相结合是最佳的加工策略，超过了对应语言和外语言知识传输。我们对不同量和类型的预训练数据进行了比较，并评估了增强数据的扩展因子以实现与目标频谱 speech 的相同性。我们的发现表明，在资源受限的语言中，可以通过本地生成的增强数据来超越对应语言和外语言的知识传输。
</details></li>
</ul>
<hr>
<h2 id="Semantic-similarity-prediction-is-better-than-other-semantic-similarity-measures"><a href="#Semantic-similarity-prediction-is-better-than-other-semantic-similarity-measures" class="headerlink" title="Semantic similarity prediction is better than other semantic similarity measures"></a>Semantic similarity prediction is better than other semantic similarity measures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12697">http://arxiv.org/abs/2309.12697</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aieng-lab/stsscore">https://github.com/aieng-lab/stsscore</a></li>
<li>paper_authors: Steffen Herbold</li>
<li>for:  mesure la similarité sémantique entre des textes naturels</li>
<li>methods: utilise une modèle fine-tuné pour prédire la similarité</li>
<li>results: obtenu une mesure de similarité plus robuste et alignée avec les attentes que les autres approches<details>
<summary>Abstract</summary>
Semantic similarity between natural language texts is typically measured either by looking at the overlap between subsequences (e.g., BLEU) or by using embeddings (e.g., BERTScore, S-BERT). Within this paper, we argue that when we are only interested in measuring the semantic similarity, it is better to directly predict the similarity using a fine-tuned model for such a task. Using a fine-tuned model for the STS-B from the GLUE benchmark, we define the STSScore approach and show that the resulting similarity is better aligned with our expectations on a robust semantic similarity measure than other approaches.
</details>
<details>
<summary>摘要</summary>
<<SYS>>按照以下文本翻译成简化中文：<</SYS>>自然语言文本之间的 semantics 相似性通常通过子序列重叠（例如 BLEU）或使用嵌入（例如 BERTScore、S-BERT）来衡量。在这篇论文中，我们认为只需要量化 semantics 相似性时，直接使用特定任务的 fine-tuned 模型来预测相似性是更好的方法。使用 GLUE benchmark 中的 STS-B 任务中的 fine-tuned 模型，我们定义了 STSScore 方法，并证明其生成的相似性更加符合我们对坚实 semantics 相似性的预期，与其他方法相比。
</details></li>
</ul>
<hr>
<h2 id="AMPLIFY-Attention-based-Mixup-for-Performance-Improvement-and-Label-Smoothing-in-Transformer"><a href="#AMPLIFY-Attention-based-Mixup-for-Performance-Improvement-and-Label-Smoothing-in-Transformer" class="headerlink" title="AMPLIFY:Attention-based Mixup for Performance Improvement and Label Smoothing in Transformer"></a>AMPLIFY:Attention-based Mixup for Performance Improvement and Label Smoothing in Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12689">http://arxiv.org/abs/2309.12689</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kiwi-lilo/amplify">https://github.com/kiwi-lilo/amplify</a></li>
<li>paper_authors: Leixin Yang, Yaping Zhang, Haoyu Xiong, Yu Xiang</li>
<li>for: 提高文本分类 task 的性能，降低模型对噪音和异常值的敏感性。</li>
<li>methods: 提出了一种新的 Mixup 方法 called AMPLIFY，通过 Transformer 自带的注意力机制来减少原始样本中噪音和异常值的影响，不增加额外可训练参数，计算成本很低。</li>
<li>results: 在 7 个 benchmark dataset 上，AMPLIFY 在文本分类任务中比其他 Mixup 方法具有更高的性能，而且在较小的计算成本下。<details>
<summary>Abstract</summary>
Mixup is an effective data augmentation method that generates new augmented samples by aggregating linear combinations of different original samples. However, if there are noises or aberrant features in the original samples, Mixup may propagate them to the augmented samples, leading to over-sensitivity of the model to these outliers . To solve this problem, this paper proposes a new Mixup method called AMPLIFY. This method uses the Attention mechanism of Transformer itself to reduce the influence of noises and aberrant values in the original samples on the prediction results, without increasing additional trainable parameters, and the computational cost is very low, thereby avoiding the problem of high resource consumption in common Mixup methods such as Sentence Mixup . The experimental results show that, under a smaller computational resource cost, AMPLIFY outperforms other Mixup methods in text classification tasks on 7 benchmark datasets, providing new ideas and new ways to further improve the performance of pre-trained models based on the Attention mechanism, such as BERT, ALBERT, RoBERTa, and GPT. Our code can be obtained at https://github.com/kiwi-lilo/AMPLIFY.
</details>
<details>
<summary>摘要</summary>
混合是一种有效的数据增强方法，可以生成新的增强样本通过原始样本的线性组合。但是，如果原始样本中存在噪声或异常特征，那么混合可能会传递这些噪声或异常特征到增强样本中，导致模型对这些噪声或异常特征过敏。为解决这个问题，本文提出了一种新的混合方法called AMPLIFY。这种方法使用Transformer自带的注意力机制来减少原始样本中噪声或异常值对预测结果的影响，无需增加额外可训练参数，计算成本非常低，因此可以避免常见的混合方法如 Sentence Mixup 中的高资源消耗问题。实验结果表明，在相对较小的计算资源成本下，AMPLIFY在文本分类任务中比其他混合方法表现更好，提供了新的想法和新的方法来进一步提高基于注意力机制的预测模型，如BERT、ALBERT、RoBERTa和GPT。我们的代码可以在https://github.com/kiwi-lilo/AMPLIFY获取。
</details></li>
</ul>
<hr>
<h2 id="JCoLA-Japanese-Corpus-of-Linguistic-Acceptability"><a href="#JCoLA-Japanese-Corpus-of-Linguistic-Acceptability" class="headerlink" title="JCoLA: Japanese Corpus of Linguistic Acceptability"></a>JCoLA: Japanese Corpus of Linguistic Acceptability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12676">http://arxiv.org/abs/2309.12676</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/osekilab/jcola">https://github.com/osekilab/jcola</a></li>
<li>paper_authors: Taiga Someya, Yushi Sugimoto, Yohei Oseki<br>for:这个论文的目的是为了评估不同类型的日语语言模型在语法可接受性领域的性能。methods:这篇论文使用了10,020个句子的手动标注的双值可接受性判断，其中86%是来自语言学教科书和手册的简单可接受性判断，剩下的14%是根据语言学期刊文章中的12种语言现象分类的。然后， authors使用这些数据来评估9种日语语言模型的语法知识。results:论文的结果表明，一些模型在域内数据上可以超越人类性能，而在域外数据上则无法超越人类性能。此外，对具体的语言现象进行分析也表明，虽然神经语言模型在地方语法依赖关系上很强，但在长距离语法依赖关系上表现不佳，如宾格结构和词汇协调等。<details>
<summary>Abstract</summary>
Neural language models have exhibited outstanding performance in a range of downstream tasks. However, there is limited understanding regarding the extent to which these models internalize syntactic knowledge, so that various datasets have recently been constructed to facilitate syntactic evaluation of language models across languages. In this paper, we introduce JCoLA (Japanese Corpus of Linguistic Acceptability), which consists of 10,020 sentences annotated with binary acceptability judgments. Specifically, those sentences are manually extracted from linguistics textbooks, handbooks and journal articles, and split into in-domain data (86 %; relatively simple acceptability judgments extracted from textbooks and handbooks) and out-of-domain data (14 %; theoretically significant acceptability judgments extracted from journal articles), the latter of which is categorized by 12 linguistic phenomena. We then evaluate the syntactic knowledge of 9 different types of Japanese language models on JCoLA. The results demonstrated that several models could surpass human performance for the in-domain data, while no models were able to exceed human performance for the out-of-domain data. Error analyses by linguistic phenomena further revealed that although neural language models are adept at handling local syntactic dependencies like argument structure, their performance wanes when confronted with long-distance syntactic dependencies like verbal agreement and NPI licensing.
</details>
<details>
<summary>摘要</summary>
neural language models 在多种下游任务中表现出色，但是对这些模型内化语法知识的理解还很有限，因此在不同语言之间建立了一些数据集，以便对语言模型的语法评估。本文介绍了日语Corpus of Linguistic Acceptability（JCoLA），包含10,020个句子，每个句子都有 binary acceptability 判断。具体来说，这些句子来自语言学书籍、手册和学术期刊，并分为预测数据（86%；相对简单的acceptability judgments从书籍和手册中提取）和 OUT-OF-DOMAIN 数据（14%；从期刊中提取，并分为12种语言现象）。然后，我们对9种日语语言模型在 JCoLA 上进行了语法知识的评估。结果显示，一些模型在预测数据上能够超越人类性能，而在 OUT-OF-DOMAIN 数据上则没有任何模型能够达到人类性能。进一步的错误分析按语言现象分类，表明了 neural language models 在处理本地语法依赖关系（如语素结构）方面表现出色，但是在面对远程语法依赖关系（如 Nominalization 和 NPI 许可）时，其性能却衰退。
</details></li>
</ul>
<hr>
<h2 id="HRoT-Hybrid-prompt-strategy-and-Retrieval-of-Thought-for-Table-Text-Hybrid-Question-Answering"><a href="#HRoT-Hybrid-prompt-strategy-and-Retrieval-of-Thought-for-Table-Text-Hybrid-Question-Answering" class="headerlink" title="HRoT: Hybrid prompt strategy and Retrieval of Thought for Table-Text Hybrid Question Answering"></a>HRoT: Hybrid prompt strategy and Retrieval of Thought for Table-Text Hybrid Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12669">http://arxiv.org/abs/2309.12669</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tongxu Luo, Fangyu Lei, Jiahe Lei, Weihao Liu, Shihu He, Jun Zhao, Kang Liu</li>
<li>for: 这篇论文是为了解决Answering numerical questions over hybrid contents from the given tables and text(TextTableQA)问题。</li>
<li>methods: 这篇论文使用了Large Language Models (LLMs)和In-Context Learning技术，以及Chain-of-Thought prompting。</li>
<li>results: 这篇论文的方法在 MultiHiertt 数据集中的少量学习情况下达到了State-of-the-Art (SOTA) 性能。<details>
<summary>Abstract</summary>
Answering numerical questions over hybrid contents from the given tables and text(TextTableQA) is a challenging task. Recently, Large Language Models (LLMs) have gained significant attention in the NLP community. With the emergence of large language models, In-Context Learning and Chain-of-Thought prompting have become two particularly popular research topics in this field. In this paper, we introduce a new prompting strategy called Hybrid prompt strategy and Retrieval of Thought for TextTableQA. Through In-Context Learning, we prompt the model to develop the ability of retrieval thinking when dealing with hybrid data. Our method achieves superior performance compared to the fully-supervised SOTA on the MultiHiertt dataset in the few-shot setting.
</details>
<details>
<summary>摘要</summary>
Answering numerical questions over hybrid contents from the given tables and text(文本表格问答) is a challenging task. Recently, Large Language Models (LLMs) have gained significant attention in the NLP community. With the emergence of large language models, In-Context Learning and Chain-of-Thought prompting have become two particularly popular research topics in this field. In this paper, we introduce a new prompting strategy called Hybrid prompt strategy and Retrieval of Thought for TextTableQA. Through In-Context Learning, we prompt the model to develop the ability of retrieval thinking when dealing with hybrid data. Our method achieves superior performance compared to the fully-supervised SOTA on the MultiHiertt dataset in the few-shot setting.Here's the translation breakdown:* Answering numerical questions over hybrid contents (文本表格问答)	+ Answering (答案)	+ Numerical questions (数字问题)	+ Hybrid contents (混合内容)	+ Text and tables (文本和表格)* Recently, Large Language Models (LLMs) have gained significant attention (最近，大型语言模型已经吸引了重要的注意)	+ Recently (最近)	+ Large Language Models (大型语言模型)	+ Gained significant attention (吸引了重要的注意)* With the emergence of large language models (LLMs), In-Context Learning and Chain-of-Thought prompting have become two particularly popular research topics (LLMs的出现使得受到了关注的研究话题)	+ With the emergence of (出现)	+ Large language models (LLMs)	+ In-Context Learning (在Context学习)	+ Chain-of-Thought prompting (Chain-of-Thought提问)	+ Two particularly popular research topics (两个非常流行的研究话题)* In this paper, we introduce a new prompting strategy called Hybrid prompt strategy and Retrieval of Thought (在这篇论文中，我们介绍了一种新的提问策略)	+ In this paper (在这篇论文中)	+ We introduce (介绍)	+ A new prompting strategy (一种新的提问策略)	+ Called Hybrid prompt strategy (被称为Hybrid提问策略)	+ And Retrieval of Thought (以及 Retrieval of Thought)* Through In-Context Learning, we prompt the model to develop the ability of retrieval thinking (通过In-Context学习，我们透过提问模型发展 Retrieval thinking的能力)	+ Through (通过)	+ In-Context Learning (在Context学习)	+ We prompt (我们透过提问)	+ The model (模型)	+ To develop (发展)	+ The ability of retrieval thinking ( Retrieval thinking的能力)* Our method achieves superior performance compared to the fully-supervised SOTA on the MultiHiertt dataset in the few-shot setting (我们的方法在 MultiHiertt 数据集上在少量学习设置下表现出了superior的性能)	+ Our method (我们的方法)	+ Achieves (表现出)	+ Superior performance (superior的性能)	+ Compared to (与)	+ The fully-supervised SOTA (完全指导的SOTA)	+ On the MultiHiertt dataset (在 MultiHiertt 数据集上)	+ In the few-shot setting (在少量学习设置下)
</details></li>
</ul>
<hr>
<h2 id="Decoding-Affect-in-Dyadic-Conversations-Leveraging-Semantic-Similarity-through-Sentence-Embedding"><a href="#Decoding-Affect-in-Dyadic-Conversations-Leveraging-Semantic-Similarity-through-Sentence-Embedding" class="headerlink" title="Decoding Affect in Dyadic Conversations: Leveraging Semantic Similarity through Sentence Embedding"></a>Decoding Affect in Dyadic Conversations: Leveraging Semantic Similarity through Sentence Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12646">http://arxiv.org/abs/2309.12646</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen-Wei Yu, Yun-Shiuan Chuang, Alexandros N. Lotsos, Claudia M. Haase</li>
<li>For: The paper aims to explore the use of sentence embeddings in analyzing real-world dyadic interactions and predicting the affect of conversational participants.* Methods: The study employs a Transformer-based model to obtain the embeddings of utterances from each speaker in 50 married couples’ conversations about conflicts and pleasant activities.* Results: The study finds that semantic similarity has a positive association with wives’ affect during conflict conversations, but not with husbands’ affect or during pleasant conversations.Here’s the information in Simplified Chinese text:</li>
<li>for: 这研究旨在利用句子嵌入来分析现实生活中的对话和预测对话参与者的情感。</li>
<li>methods: 这些研究使用Transformer模型来获取每个说话者的句子嵌入。</li>
<li>results: 研究发现，在对话中的 semantic similarity 与妻子在对抗对话中的情感有正相关关系，但不与丈夫在对抗对话中的情感或在愉悦对话中的情感有关系。<details>
<summary>Abstract</summary>
Recent advancements in Natural Language Processing (NLP) have highlighted the potential of sentence embeddings in measuring semantic similarity. Yet, its application in analyzing real-world dyadic interactions and predicting the affect of conversational participants remains largely uncharted. To bridge this gap, the present study utilizes verbal conversations within 50 married couples talking about conflicts and pleasant activities. Transformer-based model all-MiniLM-L6-v2 was employed to obtain the embeddings of the utterances from each speaker. The overall similarity of the conversation was then quantified by the average cosine similarity between the embeddings of adjacent utterances. Results showed that semantic similarity had a positive association with wives' affect during conflict (but not pleasant) conversations. Moreover, this association was not observed with husbands' affect regardless of conversation types. Two validation checks further provided support for the validity of the similarity measure and showed that the observed patterns were not mere artifacts of data. The present study underscores the potency of sentence embeddings in understanding the association between interpersonal dynamics and individual affect, paving the way for innovative applications in affective and relationship sciences.
</details>
<details>
<summary>摘要</summary>
现代自然语言处理（NLP）技术的发展，推祟了句子嵌入的潜在意义。然而，它在实际对话中分析双方对话和预测对话参与者的情感影响仍然是未知之地。为了bridging这一 gab，本研究使用了50对夫妻互动的对话，其中一方为冲突对话，另一方为愉悦对话。使用Transformer模型all-MiniLM-L6-v2，从每个发言人的utterance中获得了嵌入。然后，通过计算 adjacentutterance的cosine相似性的平均值来衡量对话的总相似性。结果表明，在冲突对话中，夫人的情感相关性与句子嵌入的semantic相似性呈正相关关系。此外，这种相关性不存在于愉悦对话中。两项验证检查还为研究的有效性提供了支持，并证明了所见到的模式不是数据的假象。本研究表明，句子嵌入可以帮助我们理解对话中的人际动力和个体情感之间的关系，并为情感科学和关系科学开辟了新的应用领域。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Diversify-Neural-Text-Generation-via-Degenerative-Model"><a href="#Learning-to-Diversify-Neural-Text-Generation-via-Degenerative-Model" class="headerlink" title="Learning to Diversify Neural Text Generation via Degenerative Model"></a>Learning to Diversify Neural Text Generation via Degenerative Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12619">http://arxiv.org/abs/2309.12619</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jimin Hong, ChaeHun Park, Jaegul Choo</li>
<li>for: 提高Neural语言模型的多样性和有用性，以扩展其应用范围。</li>
<li>methods: 提出一种新的方法，基于模型学习属性的观察：模型主要学习引起堕落问题的特征。该方法包括两个模型的训练：首先训练一个用于增强不良模式的模型，然后通过关注这个模型无法学习的模式来提高第二个模型的多样性。</li>
<li>results: 通过两个任务， namely语言模型和对话生成，进行了广泛的实验，证明了该方法的有效性。<details>
<summary>Abstract</summary>
Neural language models often fail to generate diverse and informative texts, limiting their applicability in real-world problems. While previous approaches have proposed to address these issues by identifying and penalizing undesirable behaviors (e.g., repetition, overuse of frequent words) from language models, we propose an alternative approach based on an observation: models primarily learn attributes within examples that are likely to cause degeneration problems. Based on this observation, we propose a new approach to prevent degeneration problems by training two models. Specifically, we first train a model that is designed to amplify undesirable patterns. We then enhance the diversity of the second model by focusing on patterns that the first model fails to learn. Extensive experiments on two tasks, namely language modeling and dialogue generation, demonstrate the effectiveness of our approach.
</details>
<details>
<summary>摘要</summary>
neural network语言模型经常无法生成多样化和有用的文本，限制它们在实际问题中的应用。而以前的方法已经提议通过识别和处罚不良行为（例如重复、频繁使用常见词）来解决这些问题。我们则基于一个观察：模型主要学习文本中可能导致异常问题的特征。基于这个观察，我们提出了一种新的方法，通过训练两个模型来预防异常问题。具体来说，我们首先训练一个用于强化不良模式的模型。然后，我们通过关注这个模型无法学习的模式来提高第二个模型的多样性。我们在语言模型和对话生成两个任务上进行了广泛的实验，并证明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Unlocking-Model-Insights-A-Dataset-for-Automated-Model-Card-Generation"><a href="#Unlocking-Model-Insights-A-Dataset-for-Automated-Model-Card-Generation" class="headerlink" title="Unlocking Model Insights: A Dataset for Automated Model Card Generation"></a>Unlocking Model Insights: A Dataset for Automated Model Card Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12616">http://arxiv.org/abs/2309.12616</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shruti Singh, Hitesh Lodwal, Husain Malwat, Rakesh Thakur, Mayank Singh</li>
<li>for: 这paper是为了提高机器学习模型的训练和应用而写的。</li>
<li>methods: 这paper使用了500个问题对25种机器学习模型进行了询问，以描述这些模型的训练配置、数据集、偏见、结构细节和训练资源。</li>
<li>results: 这paper发现现有的语言模型（如ChatGPT-3.5、LLaMa和Galactica）在理解研讨纸和生成文字回答中存在差距，并且可以使用这些模型来自动生成模型卡。<details>
<summary>Abstract</summary>
Language models (LMs) are no longer restricted to ML community, and instruction-tuned LMs have led to a rise in autonomous AI agents. As the accessibility of LMs grows, it is imperative that an understanding of their capabilities, intended usage, and development cycle also improves. Model cards are a popular practice for documenting detailed information about an ML model. To automate model card generation, we introduce a dataset of 500 question-answer pairs for 25 ML models that cover crucial aspects of the model, such as its training configurations, datasets, biases, architecture details, and training resources. We employ annotators to extract the answers from the original paper. Further, we explore the capabilities of LMs in generating model cards by answering questions. Our initial experiments with ChatGPT-3.5, LLaMa, and Galactica showcase a significant gap in the understanding of research papers by these aforementioned LMs as well as generating factual textual responses. We posit that our dataset can be used to train models to automate the generation of model cards from paper text and reduce human effort in the model card curation process. The complete dataset is available on https://osf.io/hqt7p/?view_only=3b9114e3904c4443bcd9f5c270158d37
</details>
<details>
<summary>摘要</summary>
机器学习模型（LM）不再受限于机器学习社区， instrucion-tuned LM 的出现导致自主AI代理人数量的增加。随着LM的访问权增加，理解其能力、适用范围和开发周期也变得非常重要。模型卡是一种很流行的实践，用于记录ML模型的详细信息。为了自动生成模型卡，我们提出了一个包含25种ML模型的500个问题答案对集。我们采用了人工批注人员，从原始论文中提取答案。此外，我们还explore了LM的可能性，以及它们在生成模型卡时的表现。我们的初步实验表明，ChatGPT-3.5、LLaMa和Galactica等LM在理解研讨文献和生成事实性文本响应方面存在较大的差距。我们认为，我们的数据集可以用于训练模型，以自动生成模型卡从文献中，并减少人类努力在模型卡筹编过程中。完整的数据集可以在https://osf.io/hqt7p/?view_only=3b9114e3904c4443bcd9f5c270158d37中找到。
</details></li>
</ul>
<hr>
<h2 id="Is-it-Possible-to-Modify-Text-to-a-Target-Readability-Level-An-Initial-Investigation-Using-Zero-Shot-Large-Language-Models"><a href="#Is-it-Possible-to-Modify-Text-to-a-Target-Readability-Level-An-Initial-Investigation-Using-Zero-Shot-Large-Language-Models" class="headerlink" title="Is it Possible to Modify Text to a Target Readability Level? An Initial Investigation Using Zero-Shot Large Language Models"></a>Is it Possible to Modify Text to a Target Readability Level? An Initial Investigation Using Zero-Shot Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12551">http://arxiv.org/abs/2309.12551</a></li>
<li>repo_url: None</li>
<li>paper_authors: Asma Farajidizaji, Vatsal Raina, Mark Gales</li>
<li>for: 本研究旨在提出一种新的文本修改任务，即可以独立地控制文本的阅读difficulty水平。</li>
<li>methods: 本研究使用了ChatGPT和Llama-2两种基础模型，以及一种扩展方法，即通过语言模型两次生成 парафраз。</li>
<li>results: 研究发现，零配置方法可以将文本的阅读difficulty水平Push in the desired direction，但最终阅读difficulty仍然与原始文本的阅读difficulty相关。此外，研究还发现，阅读difficulty的变化会导致文本 semantic和 lexical similarity降低。<details>
<summary>Abstract</summary>
Text simplification is a common task where the text is adapted to make it easier to understand. Similarly, text elaboration can make a passage more sophisticated, offering a method to control the complexity of reading comprehension tests. However, text simplification and elaboration tasks are limited to only relatively alter the readability of texts. It is useful to directly modify the readability of any text to an absolute target readability level to cater to a diverse audience. Ideally, the readability of readability-controlled generated text should be independent of the source text. Therefore, we propose a novel readability-controlled text modification task. The task requires the generation of 8 versions at various target readability levels for each input text. We introduce novel readability-controlled text modification metrics. The baselines for this task use ChatGPT and Llama-2, with an extension approach introducing a two-step process (generating paraphrases by passing through the language model twice). The zero-shot approaches are able to push the readability of the paraphrases in the desired direction but the final readability remains correlated with the original text's readability. We also find greater drops in semantic and lexical similarity between the source and target texts with greater shifts in the readability.
</details>
<details>
<summary>摘要</summary>
文本简化和文本膨化是常见的任务，它们可以使文本更易于理解。然而，文本简化和膨化任务只能有限地改变文本的可读性。为了直接修改文本的可读性水平，我们提出了一个新的可读性控制文本修改任务。这个任务需要对每个输入文本生成8个版本，每个版本都达到不同的目标可读性水平。我们介绍了一些新的可读性控制文本修改指标。基elines для这个任务使用ChatGPT和Llama-2，我们还提出了一种扩展方法，即通过语言模型两次进行两步过程（生成重叠的重叠）来生成重叠。我们发现零配置方法可以推动文本的可读性水平，但最终的可读性仍然与原始文本的可读性相关。此外，我们还发现，随着可读性的增加，文本之间的semantic和lexical相似度会降低。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Answerability-Evaluation-for-Question-Generation"><a href="#Automatic-Answerability-Evaluation-for-Question-Generation" class="headerlink" title="Automatic Answerability Evaluation for Question Generation"></a>Automatic Answerability Evaluation for Question Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12546">http://arxiv.org/abs/2309.12546</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zifan Wang, Kotaro Funakoshi, Manabu Okumura</li>
<li>for: 这 paper 的目的是提出一种新的自动评价指标，以评估生成的问题是否能够由参考答案回答。</li>
<li>methods: 这 paper 使用了一种基于提示的评价指标， named PMAN，通过对生成的问题和参考答案进行对比，来评估问题的可answerability。</li>
<li>results: 经过广泛的实验，这 paper 的评价结果被证明可靠，与人工评价结果相align。此外，这 paper 还应用了其metric来评估生成问题模型的性能，发现其metric 与传统的评价指标 complementary。最后， authors 使用 ChatGPT 实现了一个 SOTA 的问题生成模型。<details>
<summary>Abstract</summary>
Conventional automatic evaluation metrics, such as BLEU and ROUGE, developed for natural language generation (NLG) tasks, are based on measuring the n-gram overlap between the generated and reference text. These simple metrics may be insufficient for more complex tasks, such as question generation (QG), which requires generating questions that are answerable by the reference answers. Developing a more sophisticated automatic evaluation metric, thus, remains as an urgent problem in QG research. This work proposes a Prompting-based Metric on ANswerability (PMAN), a novel automatic evaluation metric to assess whether the generated questions are answerable by the reference answers for the QG tasks. Extensive experiments demonstrate that its evaluation results are reliable and align with human evaluations. We further apply our metric to evaluate the performance of QG models, which shows our metric complements conventional metrics. Our implementation of a ChatGPT-based QG model achieves state-of-the-art (SOTA) performance in generating answerable questions.
</details>
<details>
<summary>摘要</summary>
传统的自动评价指标，如BLEU和ROUGE，是基于生成和参考文本中的n-gram重叠而定义的。这些简单的指标可能不够用于更复杂的任务，如问题生成（QG），因为QG需要生成可回答的问题。开发一种更加复杂的自动评价指标，因此是QG研究中的紧迫问题。本工作提出了Answerability-based Metric on ANswerability（PMAN），一种新的自动评价指标，用于评估生成的问题是否可以由参考答案回答。我们进行了广泛的实验，并证明了其评价结果的可靠性和与人工评价结果的一致性。此外，我们还应用了我们的指标来评估QG模型的性能，并发现了它与传统指标的协同作用。我们实现了基于ChatGPT的QG模型，实现了状态的杰出表现（SOTA）在生成可回答的问题。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/22/cs.CL_2023_09_22/" data-id="cloqtaeow00bkgh88eler4m6h" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_09_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/22/cs.LG_2023_09_22/" class="article-date">
  <time datetime="2023-09-22T10:00:00.000Z" itemprop="datePublished">2023-09-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/22/cs.LG_2023_09_22/">cs.LG - 2023-09-22</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="The-LHCb-ultra-fast-simulation-option-Lamarr-design-and-validation"><a href="#The-LHCb-ultra-fast-simulation-option-Lamarr-design-and-validation" class="headerlink" title="The LHCb ultra-fast simulation option, Lamarr: design and validation"></a>The LHCb ultra-fast simulation option, Lamarr: design and validation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13213">http://arxiv.org/abs/2309.13213</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lucio Anderlini, Matteo Barbetti, Simone Capelli, Gloria Corti, Adam Davis, Denis Derkach, Nikita Kazeev, Artem Maevskiy, Maurizio Martinelli, Sergei Mokonenko, Benedetto Gianluca Siddi, Zehua Xu</li>
<li>for: 用于提高LHCb实验中的详细探测器模拟，以满足Run 3中的数据收集需求。</li>
<li>methods: 使用Gaudi框架，并利用深度生成模型和梯度提升决策树来 parameterize探测器响应和重建算法。</li>
<li>results: 比较详细模拟和Lamarr模拟的结果，发现Lamarr可以提供两个数量级的速度提升，同时保持与详细模拟的一致性。<details>
<summary>Abstract</summary>
Detailed detector simulation is the major consumer of CPU resources at LHCb, having used more than 90% of the total computing budget during Run 2 of the Large Hadron Collider at CERN. As data is collected by the upgraded LHCb detector during Run 3 of the LHC, larger requests for simulated data samples are necessary, and will far exceed the pledged resources of the experiment, even with existing fast simulation options. An evolution of technologies and techniques to produce simulated samples is mandatory to meet the upcoming needs of analysis to interpret signal versus background and measure efficiencies. In this context, we propose Lamarr, a Gaudi-based framework designed to offer the fastest solution for the simulation of the LHCb detector. Lamarr consists of a pipeline of modules parameterizing both the detector response and the reconstruction algorithms of the LHCb experiment. Most of the parameterizations are made of Deep Generative Models and Gradient Boosted Decision Trees trained on simulated samples or alternatively, where possible, on real data. Embedding Lamarr in the general LHCb Gauss Simulation framework allows combining its execution with any of the available generators in a seamless way. Lamarr has been validated by comparing key reconstructed quantities with Detailed Simulation. Good agreement of the simulated distributions is obtained with two-order-of-magnitude speed-up of the simulation phase.
</details>
<details>
<summary>摘要</summary>
具有详细探测器模拟功能的 Lamarr 框架，基于 Gaudi 框架，可以提供最快的 LHCb 探测器模拟解决方案。Lamarr 包含一系列模块，用于 parameterizing LHCb 实验中的探测器响应和重建算法。大多数参数化都是使用深度生成模型和梯度提升决策树，并在训练过程中使用 simulate 样本或实际数据。嵌入 Lamarr 到 LHCb Gauss Simulation 框架中，可以将其与任何可用的生成器结合使用，实现无缝的执行。Lamarr 已经得到了对 Key 重建量的验证，并与详细模拟相比，实现了两个级别的速度提升。
</details></li>
</ul>
<hr>
<h2 id="Evidential-Deep-Learning-Enhancing-Predictive-Uncertainty-Estimation-for-Earth-System-Science-Applications"><a href="#Evidential-Deep-Learning-Enhancing-Predictive-Uncertainty-Estimation-for-Earth-System-Science-Applications" class="headerlink" title="Evidential Deep Learning: Enhancing Predictive Uncertainty Estimation for Earth System Science Applications"></a>Evidential Deep Learning: Enhancing Predictive Uncertainty Estimation for Earth System Science Applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13207">http://arxiv.org/abs/2309.13207</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/AI2ES/miles-guess">https://github.com/AI2ES/miles-guess</a></li>
<li>paper_authors: John S. Schreck, David John Gagne II, Charlie Becker, William E. Chapman, Kim Elmore, Gabrielle Gantos, Eliot Kim, Dhamma Kimpara, Thomas Martin, Maria J. Molina, Vanessa M. Pryzbylo, Jacob Radford, Belen Saavedra, Justin Willson, Christopher Wirz</li>
<li>for: 这个研究旨在提供一个可靠且实用的深度学习方法来量化气候和天气预测结果的不确定性。</li>
<li>methods: 这个研究使用的方法是 Parametric deep learning 和 Evidential deep learning，这两种方法可以 estimate 预测结果的不确定性，并且可以account for  both aleatoric 和 epistemic uncertainty。</li>
<li>results: 这个研究发现，使用 evidential neural networks 可以实现预测精度与 ensemble 方法相当，同时可以严谨地量化预测结果的不确定性。<details>
<summary>Abstract</summary>
Robust quantification of predictive uncertainty is critical for understanding factors that drive weather and climate outcomes. Ensembles provide predictive uncertainty estimates and can be decomposed physically, but both physics and machine learning ensembles are computationally expensive. Parametric deep learning can estimate uncertainty with one model by predicting the parameters of a probability distribution but do not account for epistemic uncertainty.. Evidential deep learning, a technique that extends parametric deep learning to higher-order distributions, can account for both aleatoric and epistemic uncertainty with one model. This study compares the uncertainty derived from evidential neural networks to those obtained from ensembles. Through applications of classification of winter precipitation type and regression of surface layer fluxes, we show evidential deep learning models attaining predictive accuracy rivaling standard methods, while robustly quantifying both sources of uncertainty. We evaluate the uncertainty in terms of how well the predictions are calibrated and how well the uncertainty correlates with prediction error. Analyses of uncertainty in the context of the inputs reveal sensitivities to underlying meteorological processes, facilitating interpretation of the models. The conceptual simplicity, interpretability, and computational efficiency of evidential neural networks make them highly extensible, offering a promising approach for reliable and practical uncertainty quantification in Earth system science modeling. In order to encourage broader adoption of evidential deep learning in Earth System Science, we have developed a new Python package, MILES-GUESS (https://github.com/ai2es/miles-guess), that enables users to train and evaluate both evidential and ensemble deep learning.
</details>
<details>
<summary>摘要</summary>
Robust量化预测uncertainty是气候和天气结果的关键因素。集合可以提供预测uncertainty估计，但物理和机器学习集合都是计算成本高的。 parametric deep learning可以通过预测概率分布的参数来估计uncertainty，但不能考虑到epistemic uncertainty。 evidential deep learning，一种扩展 parametric deep learning 到更高阶分布的技术，可以同时考虑到aleatoric和epistemic uncertainty。本研究比较了来自集合和 evidential neural network 的uncertainty。通过对冬季降水类型分类和表面层流量预测的应用，我们显示 evidential deep learning 模型可以与标准方法匹配的预测精度，同时坚定地量化两种uncertainty。我们评估预测的uncertainty，包括预测是否准确折叠和预测错误与uncertainty之间的相关性。对输入uncertainty进行分析，可以了解模型对下游气象过程的敏感性，从而更好地理解模型。 evidential neural network 的概念简单、可解释性和计算效率，使其成为可靠和实用的uncertainty量化方法。为促进 Earth System Science 中 evidential deep learning 的广泛应用，我们已经开发了一个新的 Python 包，MILES-GUESS（https://github.com/ai2es/miles-guess），它允许用户训练和评估 evidential 和集合 deep learning。
</details></li>
</ul>
<hr>
<h2 id="Federated-Short-Term-Load-Forecasting-with-Personalization-Layers-for-Heterogeneous-Clients"><a href="#Federated-Short-Term-Load-Forecasting-with-Personalization-Layers-for-Heterogeneous-Clients" class="headerlink" title="Federated Short-Term Load Forecasting with Personalization Layers for Heterogeneous Clients"></a>Federated Short-Term Load Forecasting with Personalization Layers for Heterogeneous Clients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13194">http://arxiv.org/abs/2309.13194</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shourya Bose, Kibaek Kim</li>
<li>for: 这篇论文是为了提高 Federated Learning（FL）的精度和减少资料隐私问题。</li>
<li>methods: 本论文使用了Argonne Privacy-Preserving Federated Learning套件，并提出了一个专门 для处理对私页面层的Personalized Federated Learning（PL-FL）算法，以提高模型的精度。</li>
<li>results: 根据NREL ComStock资料集的实验结果显示，PL-FL算法可以提高模型的预测性能，并且可以处理各个客户的对私页面层。<details>
<summary>Abstract</summary>
The advent of smart meters has enabled pervasive collection of energy consumption data for training short-term load forecasting (STLF) models. In response to privacy concerns, federated learning (FL) has been proposed as a privacy-preserving approach for training, but the quality of trained models degrades as client data becomes heterogeneous. In this paper we alleviate this drawback using personalization layers, wherein certain layers of an STLF model in an FL framework are trained exclusively on the clients' own data. To that end, we propose a personalized FL algorithm (PL-FL) enabling FL to handle personalization layers. The PL-FL algorithm is implemented by using the Argonne Privacy-Preserving Federated Learning package. We test the forecast performance of models trained on the NREL ComStock dataset, which contains heterogeneous energy consumption data of multiple commercial buildings. Superior performance of models trained with PL-FL demonstrates that personalization layers enable classical FL algorithms to handle clients with heterogeneous data.
</details>
<details>
<summary>摘要</summary>
智能仪器的出现使得能源消耗数据进行普遍收集，用于训练短期负荷预测（STLF）模型。为了保护隐私，联邦学习（FL）被提议作为隐私保护的方法，但训练模型的质量受到客户数据的不同性的影响。在本文中，我们通过个性化层来缓解这个缺点，其中某些层在联邦学习框架中仅使用客户自己的数据进行训练。为此，我们提出了个性化联邦学习算法（PL-FL），允许联邦学习算法处理个性化层。PL-FL算法使用Argonne隐私保护联邦学习包进行实现。我们在NREL ComStock数据集上测试了由PL-FL训练的预测模型的forecast性能，该数据集包含多个商业建筑物的各种能源消耗数据。我们发现模型通过PL-FL训练显示出了superior的预测性能，这说明个性化层使得传统的联邦学习算法能够处理客户具有不同数据的情况。
</details></li>
</ul>
<hr>
<h2 id="Visualizing-Topological-Importance-A-Class-Driven-Approach"><a href="#Visualizing-Topological-Importance-A-Class-Driven-Approach" class="headerlink" title="Visualizing Topological Importance: A Class-Driven Approach"></a>Visualizing Topological Importance: A Class-Driven Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13185">http://arxiv.org/abs/2309.13185</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Qin, Brittany Terese Fasy, Carola Wenk, Brian Summa</li>
<li>for: 本研究首次用图像化方法来显示数据中重要的拓扑特征，以便更好地分析和理解数据的结构。</li>
<li>methods: 本研究使用了已经证明的可解释深度学习方法，并将其应用于拓扑分类任务。这种方法可以在每个数据集中找出重要的拓扑结构，并为每个类别分配不同的权重。</li>
<li>results: 本研究通过创建 persistente point density 的重要性场来显示数据中重要的拓扑特征。这种方法可以在图像、3D 形状和医疗图像等数据上进行实际应用，并提供了真实世界中这种方法的应用示例。<details>
<summary>Abstract</summary>
This paper presents the first approach to visualize the importance of topological features that define classes of data. Topological features, with their ability to abstract the fundamental structure of complex data, are an integral component of visualization and analysis pipelines. Although not all topological features present in data are of equal importance. To date, the default definition of feature importance is often assumed and fixed. This work shows how proven explainable deep learning approaches can be adapted for use in topological classification. In doing so, it provides the first technique that illuminates what topological structures are important in each dataset in regards to their class label. In particular, the approach uses a learned metric classifier with a density estimator of the points of a persistence diagram as input. This metric learns how to reweigh this density such that classification accuracy is high. By extracting this weight, an importance field on persistent point density can be created. This provides an intuitive representation of persistence point importance that can be used to drive new visualizations. This work provides two examples: Visualization on each diagram directly and, in the case of sublevel set filtrations on images, directly on the images themselves. This work highlights real-world examples of this approach visualizing the important topological features in graph, 3D shape, and medical image data.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文介绍了首先使用 topological features 来定义数据类别的方法。 topological features 拥有抽象复杂数据的基本结构的能力，因此是数据可视化和分析管道中的一个重要组成部分。although not all topological features in data are of equal importance. Until now, the default definition of feature importance has been often assumed and fixed. This work shows how proven explainable deep learning approaches can be adapted for use in topological classification. In doing so, it provides the first technique that illuminates what topological structures are important in each dataset in regards to their class label. In particular, the approach uses a learned metric classifier with a density estimator of the points of a persistence diagram as input. This metric learns how to reweigh this density such that classification accuracy is high. By extracting this weight, an importance field on persistent point density can be created. This provides an intuitive representation of persistence point importance that can be used to drive new visualizations. This work provides two examples: Visualization on each diagram directly and, in the case of sublevel set filtrations on images, directly on the images themselves. This work highlights real-world examples of this approach visualizing the important topological features in graph, 3D shape, and medical image data.
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Multi-Objective-Optimization-through-Machine-Learning-Supported-Multiphysics-Simulation"><a href="#Enhancing-Multi-Objective-Optimization-through-Machine-Learning-Supported-Multiphysics-Simulation" class="headerlink" title="Enhancing Multi-Objective Optimization through Machine Learning-Supported Multiphysics Simulation"></a>Enhancing Multi-Objective Optimization through Machine Learning-Supported Multiphysics Simulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13179">http://arxiv.org/abs/2309.13179</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diego Botache, Jens Decke, Winfried Ripken, Abhinay Dornipati, Franz Götz-Hahn, Mohamed Ayeb, Bernhard Sick</li>
<li>for: 这篇论文旨在提出一个方法ological framework для快速化多物理 simulations，以满足多个目标的优化。</li>
<li>methods: 这篇论文使用了两种机器学习和深度学习算法，以及两种优化算法，并将其组合成一个完整的训练和优化管线。</li>
<li>results: 经过实验和评估，这篇论文发现可以使用相对少量的数据来训练高精度的代理模型，并且可以快速地获得多个目标的Pareto优化结果。<details>
<summary>Abstract</summary>
Multiphysics simulations that involve multiple coupled physical phenomena quickly become computationally expensive. This imposes challenges for practitioners aiming to find optimal configurations for these problems satisfying multiple objectives, as optimization algorithms often require querying the simulation many times. This paper presents a methodological framework for training, self-optimizing, and self-organizing surrogate models to approximate and speed up Multiphysics simulations. We generate two real-world tabular datasets, which we make publicly available, and show that surrogate models can be trained on relatively small amounts of data to approximate the underlying simulations accurately. We conduct extensive experiments combining four machine learning and deep learning algorithms with two optimization algorithms and a comprehensive evaluation strategy. Finally, we evaluate the performance of our combined training and optimization pipeline by verifying the generated Pareto-optimal results using the ground truth simulations. We also employ explainable AI techniques to analyse our surrogates and conduct a preselection strategy to determine the most relevant features in our real-world examples. This approach lets us understand the underlying problem and identify critical partial dependencies.
</details>
<details>
<summary>摘要</summary>
多物理 simulate 快速增加计算成本，这会对实践者们的优化问题提出挑战，因为优化算法通常需要对 simulate 进行多次查询。这篇论文提出了一种方法ológical framework для训练、自动优化和自动组织替身模型，以加速多物理 simulate。我们生成了两个实际世界的表格数据集，并证明了替身模型可以通过相对小量数据来准确地表示下面 simulate。我们在多种机器学习和深度学习算法和两种优化算法的基础上进行了广泛的实验。最后，我们使用了可解释 AI 技术来分析我们的替身和采用预选策略来确定实际世界中最重要的特征。这种方法让我们理解下面的问题，并识别 kritical partial dependencies。
</details></li>
</ul>
<hr>
<h2 id="Invisible-Watermarking-for-Audio-Generation-Diffusion-Models"><a href="#Invisible-Watermarking-for-Audio-Generation-Diffusion-Models" class="headerlink" title="Invisible Watermarking for Audio Generation Diffusion Models"></a>Invisible Watermarking for Audio Generation Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13166">http://arxiv.org/abs/2309.13166</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mikiyaxi/watermark-audio-diffusion">https://github.com/mikiyaxi/watermark-audio-diffusion</a></li>
<li>paper_authors: Xirong Cao, Xiang Li, Divyesh Jadav, Yanzhao Wu, Zhehui Chen, Chen Zeng, Wenqi Wei</li>
<li>for: 保护音频扩散模型的 интеграITY和数据权益</li>
<li>methods: 基于mel-spectrogram的音频扩散模型 watermarking技术</li>
<li>results: 实现了不可见水印触发机制，保护模型的有Integrity和数据权益，同时仍能够保持高效的净音频生成能力。<details>
<summary>Abstract</summary>
Diffusion models have gained prominence in the image domain for their capabilities in data generation and transformation, achieving state-of-the-art performance in various tasks in both image and audio domains. In the rapidly evolving field of audio-based machine learning, safeguarding model integrity and establishing data copyright are of paramount importance. This paper presents the first watermarking technique applied to audio diffusion models trained on mel-spectrograms. This offers a novel approach to the aforementioned challenges. Our model excels not only in benign audio generation, but also incorporates an invisible watermarking trigger mechanism for model verification. This watermark trigger serves as a protective layer, enabling the identification of model ownership and ensuring its integrity. Through extensive experiments, we demonstrate that invisible watermark triggers can effectively protect against unauthorized modifications while maintaining high utility in benign audio generation tasks.
</details>
<details>
<summary>摘要</summary>
各种扩散模型在图像领域中得到了广泛应用，以其数据生成和转换能力为特点，在图像和音频领域中实现了状态 искусственный机器学习的最佳性能。在快速发展的音频基于机器学习领域中，保护模型完整性和确立数据版权是核心问题。本文提出了首个应用于音频扩散模型训练的mel-spectrogram watermarking技术。这提供了一种新的方法来解决以上问题。我们的模型不仅在正常的音频生成任务中表现出色，还包含了隐藏的 watermarking 触发器机制，以确保模型的完整性和版权。通过广泛的实验，我们证明了隐藏的 watermark 触发器可以有效地保护 against 未授权修改，同时保持高的用于正常音频生成任务的实用性。
</details></li>
</ul>
<hr>
<h2 id="Forecasting-Response-to-Treatment-with-Global-Deep-Learning-and-Patient-Specific-Pharmacokinetic-Priors"><a href="#Forecasting-Response-to-Treatment-with-Global-Deep-Learning-and-Patient-Specific-Pharmacokinetic-Priors" class="headerlink" title="Forecasting Response to Treatment with Global Deep Learning and Patient-Specific Pharmacokinetic Priors"></a>Forecasting Response to Treatment with Global Deep Learning and Patient-Specific Pharmacokinetic Priors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13135">http://arxiv.org/abs/2309.13135</a></li>
<li>repo_url: None</li>
<li>paper_authors: Willa Potosnak, Cristian Challu, Kin G. Olivares, Artur Dubrawski</li>
<li>for: 预测医疗时序数据，以早发现不良结果和监测病人状况。</li>
<li>methods: 提议一种新的混合全局-本地架构和药理学编码器，用于深入了解患者特定的治疗效应。</li>
<li>results: 对比patient-specific模型，全局-本地架构提高了9.2-14.6%的准确率；对比alternative编码技术，药理学编码器在模拟数据上提高了4.4%，在实际数据上提高了2.1%。<details>
<summary>Abstract</summary>
Forecasting healthcare time series is crucial for early detection of adverse outcomes and for patient monitoring. Forecasting, however, can be difficult in practice due to noisy and intermittent data. The challenges are often exacerbated by change points induced via extrinsic factors, such as the administration of medication. To address these challenges, we propose a novel hybrid global-local architecture and a pharmacokinetic encoder that informs deep learning models of patient-specific treatment effects. We showcase the efficacy of our approach in achieving significant accuracy gains for a blood glucose forecasting task using both realistically simulated and real-world data. Our global-local architecture improves over patient-specific models by 9.2-14.6%. Additionally, our pharmacokinetic encoder improves over alternative encoding techniques by 4.4% on simulated data and 2.1% on real-world data. The proposed approach can have multiple beneficial applications in clinical practice, such as issuing early warnings about unexpected treatment responses, or helping to characterize patient-specific treatment effects in terms of drug absorption and elimination characteristics.
</details>
<details>
<summary>摘要</summary>
预测医疗时序数据是重要的，可以早期检测不良结果并跟踪病人。然而，在实践中预测可能会困难，因为数据充满噪音和中断。这些挑战通常由外部因素引起的变换点加剧，如药物的给药。为了解决这些挑战，我们提议一种新的全球-本地架构和一种用于深度学习模型的药物生物学编码器。我们在血糖预测任务中使用这种方法，并使用真实的 simulated 数据和实际数据进行比较。我们的全球-本地架构在patient-specific模型的基础上提高了9.2-14.6%的准确率。此外，我们的药物生物学编码器在 simulated 数据上比替代编码技术提高4.4%，并在实际数据上提高2.1%。我们的方法可以在临床实践中有多个有利应用，如发现不ждан的治疗反应，或者帮助characterize patient-specific treatment effects in terms of drug absorption and elimination characteristics。
</details></li>
</ul>
<hr>
<h2 id="AntiBARTy-Diffusion-for-Property-Guided-Antibody-Design"><a href="#AntiBARTy-Diffusion-for-Property-Guided-Antibody-Design" class="headerlink" title="AntiBARTy Diffusion for Property Guided Antibody Design"></a>AntiBARTy Diffusion for Property Guided Antibody Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13129">http://arxiv.org/abs/2309.13129</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jordan Venderley</li>
<li>for: 这 paper 是为了探讨用 machine learning 技术来设计和工程抗体的可能性。</li>
<li>methods: 这 paper 使用了一种基于 BART 的语言模型，以及一种基于这种语言模型的扩散模型来导向 IgG 抗体的 de novo 设计。</li>
<li>results: 这 paper 的实验结果表明，可以使用这种方法来生成具有改进的在silico 稳定性的新抗体，同时保持抗体的有效性和序列多样性。<details>
<summary>Abstract</summary>
Over the past decade, antibodies have steadily grown in therapeutic importance thanks to their high specificity and low risk of adverse effects compared to other drug modalities. While traditional antibody discovery is primarily wet lab driven, the rapid improvement of ML-based generative modeling has made in-silico approaches an increasingly viable route for discovery and engineering. To this end, we train an antibody-specific language model, AntiBARTy, based on BART (Bidirectional and Auto-Regressive Transformer) and use its latent space to train a property-conditional diffusion model for guided IgG de novo design. As a test case, we show that we can effectively generate novel antibodies with improved in-silico solubility while maintaining antibody validity and controlling sequence diversity.
</details>
<details>
<summary>摘要</summary>
过去十年，抗体在治疗方面的重要性逐渐增长，主要归功于它们的高特异性和其他药物modalities相比的低风险。而传统抗体发现主要是在湿lab中进行，但随着机器学习（ML）基于生成模型的快速进步，在硬件上进行的方法在抗体发现和工程方面变得越来越有前途。为此，我们训练了一个抗体特有的语言模型 AntiBARTy，基于BART（双向自适应变换器），并使用其潜在空间来训练一个基于属性的扩散模型，用于导引IgG de novo设计。作为一个测试案例，我们显示了我们可以效果地生成改进了室内溶解性的新抗体，同时保持抗体有效性和控制序列多样性。
</details></li>
</ul>
<hr>
<h2 id="Data-is-often-loadable-in-short-depth-Quantum-circuits-from-tensor-networks-for-finance-images-fluids-and-proteins"><a href="#Data-is-often-loadable-in-short-depth-Quantum-circuits-from-tensor-networks-for-finance-images-fluids-and-proteins" class="headerlink" title="Data is often loadable in short depth: Quantum circuits from tensor networks for finance, images, fluids, and proteins"></a>Data is often loadable in short depth: Quantum circuits from tensor networks for finance, images, fluids, and proteins</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13108">http://arxiv.org/abs/2309.13108</a></li>
<li>repo_url: None</li>
<li>paper_authors: Raghav Jumade, Nicolas PD Sawaya</li>
<li>For: This paper addresses the “input problem” of loading classical data into a quantum computer, which has been an obstacle to achieving quantum advantage.* Methods: The paper introduces a circuit compilation method based on tensor network (TN) theory, called AMLET (Automatic Multi-layer Loader Exploiting TNs), which can be tailored to arbitrary circuit depths.* Results: The paper performs numerical experiments on real-world classical data from four distinct areas and shows that the required circuit depths are often several orders of magnitude lower than the exponentially-scaling general loading algorithm would require. This demonstrates that many classical datasets can be loaded into a quantum computer in much shorter depth than previously expected, which has positive implications for speeding up classical workloads on quantum computers.<details>
<summary>Abstract</summary>
Though there has been substantial progress in developing quantum algorithms to study classical datasets, the cost of simply loading classical data is an obstacle to quantum advantage. When the amplitude encoding is used, loading an arbitrary classical vector requires up to exponential circuit depths with respect to the number of qubits. Here, we address this ``input problem'' with two contributions. First, we introduce a circuit compilation method based on tensor network (TN) theory. Our method -- AMLET (Automatic Multi-layer Loader Exploiting TNs) -- proceeds via careful construction of a specific TN topology and can be tailored to arbitrary circuit depths. Second, we perform numerical experiments on real-world classical data from four distinct areas: finance, images, fluid mechanics, and proteins. To the best of our knowledge, this is the broadest numerical analysis to date of loading classical data into a quantum computer. Consistent with other recent work in this area, the required circuit depths are often several orders of magnitude lower than the exponentially-scaling general loading algorithm would require. Besides introducing a more efficient loading algorithm, this work demonstrates that many classical datasets are loadable in depths that are much shorter than previously expected, which has positive implications for speeding up classical workloads on quantum computers.
</details>
<details>
<summary>摘要</summary>
尽管在开发量子算法研究类别数据上已经取得了重要进展，但是将类别数据加载到量子计算机上的成本仍然是一个障碍物，以致于实现量子优势。当使用振荡编码时，将任意类别数据加载到多个量子比特（qubit）上可能需要对数量积累的循环深度。在这里，我们提出了两项贡献以解决这个“输入问题”。首先，我们基于张量网络（TN）理论开发了一种简单的练习方法，称之为自动多层加载器（AMLET）。我们的方法通过精心构建特定的TN结构，可以适应任意循环深度。其次，我们在实际的类别数据上进行了数值实验，来评估加载类别数据到量子计算机上的可能性。我们的实验结果表明，可以在循环深度上下文中加载类别数据，而不需要遵循普通的循环深度级数。此外，这项工作还证明了许多类别数据可以在循环深度上下文中加载，这意味着可以通过加速类别工作来减轻量子计算机上的工作负担。
</details></li>
</ul>
<hr>
<h2 id="Graph-Neural-Network-for-Stress-Predictions-in-Stiffened-Panels-Under-Uniform-Loading"><a href="#Graph-Neural-Network-for-Stress-Predictions-in-Stiffened-Panels-Under-Uniform-Loading" class="headerlink" title="Graph Neural Network for Stress Predictions in Stiffened Panels Under Uniform Loading"></a>Graph Neural Network for Stress Predictions in Stiffened Panels Under Uniform Loading</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13022">http://arxiv.org/abs/2309.13022</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuecheng Cai, Jasmin Jelovica</li>
<li>for: 本研究旨在提出一种novel的图形嵌入技术，用于高效地表示3D厚度板的强度分布。</li>
<li>methods: 本研究使用了Graph Sampling and Aggregation（GraphSAGE）技术，并 comparing withfinite-element-vertex图表示方法。</li>
<li>results: 研究结果表明，使用提议的图形嵌入方法可以更加准确地预测3D厚度板的强度分布，并且可以快速地对不同结构 Parametric study。<details>
<summary>Abstract</summary>
Machine learning (ML) and deep learning (DL) techniques have gained significant attention as reduced order models (ROMs) to computationally expensive structural analysis methods, such as finite element analysis (FEA). Graph neural network (GNN) is a particular type of neural network which processes data that can be represented as graphs. This allows for efficient representation of complex geometries that can change during conceptual design of a structure or a product. In this study, we propose a novel graph embedding technique for efficient representation of 3D stiffened panels by considering separate plate domains as vertices. This approach is considered using Graph Sampling and Aggregation (GraphSAGE) to predict stress distributions in stiffened panels with varying geometries. A comparison between a finite-element-vertex graph representation is conducted to demonstrate the effectiveness of the proposed approach. A comprehensive parametric study is performed to examine the effect of structural geometry on the prediction performance. Our results demonstrate the immense potential of graph neural networks with the proposed graph embedding method as robust reduced-order models for 3D structures.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Brain-Age-Revisited-Investigating-the-State-vs-Trait-Hypotheses-of-EEG-derived-Brain-Age-Dynamics-with-Deep-Learning"><a href="#Brain-Age-Revisited-Investigating-the-State-vs-Trait-Hypotheses-of-EEG-derived-Brain-Age-Dynamics-with-Deep-Learning" class="headerlink" title="Brain Age Revisited: Investigating the State vs. Trait Hypotheses of EEG-derived Brain-Age Dynamics with Deep Learning"></a>Brain Age Revisited: Investigating the State vs. Trait Hypotheses of EEG-derived Brain-Age Dynamics with Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.07029">http://arxiv.org/abs/2310.07029</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gemeinl/eeg-brain-age">https://github.com/gemeinl/eeg-brain-age</a></li>
<li>paper_authors: Lukas AW Gemein, Robin T Schirrmeister, Joschka Boedecker, Tonio Ball<br>for:* The paper aims to investigate the relationship between brain age and brain pathology using clinical EEG recordings.methods:* The authors use a state-of-the-art Temporal Convolutional Network (TCN) for age regression, and train the model on recordings from the Temple University Hospital EEG Corpus (TUEG) with explicit labels for non-pathological and pathological recordings.results:* The TCN achieves state-of-the-art performance in age decoding with a mean absolute error of 6.6 years.* The authors find that the brain age gap biomarker is not indicative of pathological EEG, and that the model significantly underestimates the age of non-pathological and pathological subjects.<details>
<summary>Abstract</summary>
The brain's biological age has been considered as a promising candidate for a neurologically significant biomarker. However, recent results based on longitudinal magnetic resonance imaging data have raised questions on its interpretation. A central question is whether an increased biological age of the brain is indicative of brain pathology and if changes in brain age correlate with diagnosed pathology (state hypothesis). Alternatively, could the discrepancy in brain age be a stable characteristic unique to each individual (trait hypothesis)? To address this question, we present a comprehensive study on brain aging based on clinical EEG, which is complementary to previous MRI-based investigations. We apply a state-of-the-art Temporal Convolutional Network (TCN) to the task of age regression. We train on recordings of the Temple University Hospital EEG Corpus (TUEG) explicitly labeled as non-pathological and evaluate on recordings of subjects with non-pathological as well as pathological recordings, both with examinations at a single point in time and repeated examinations over time. Therefore, we created four novel subsets of TUEG that include subjects with multiple recordings: I) all labeled non-pathological; II) all labeled pathological; III) at least one recording labeled non-pathological followed by at least one recording labeled pathological; IV) similar to III) but with opposing transition (first pathological then non-pathological). The results show that our TCN reaches state-of-the-art performance in age decoding with a mean absolute error of 6.6 years. Our extensive analyses demonstrate that the model significantly underestimates the age of non-pathological and pathological subjects (-1 and -5 years, paired t-test, p <= 0.18 and p <= 0.0066). Furthermore, the brain age gap biomarker is not indicative of pathological EEG.
</details>
<details>
<summary>摘要</summary>
研究人员认为大脑的生物龄可能是脑科学中的一个有价值的生物标志物。然而，最近的长期磁共振成像数据显示了解释问题。我们的中心问题是大脑生物龄是脑病学的指标吗，而且改变大脑生物龄与诊断病理相关吗（状态假设）？或者这些差异是每个人的稳定特征吗（性 trait假设）？为了回答这个问题，我们提供了一项全面的大脑老化研究，基于临床EEG。我们使用了当今最佳的时间卷积神经网络（TCN）进行年龄预测任务。我们在记录了普通大学医院EEG资料库（TUEG）的非病理记录上进行训练，并对记录了非病理和病理记录的评估。因此，我们创建了四个新的TUEG子集：I) 所有非病理记录; II) 所有病理记录; III) 至少有一个非病理记录，后跟至少一个病理记录; IV) 与III相似，但具有反向转变（先病理然后非病理）。结果显示，我们的TCN达到了当今最佳性能水平，年龄预测的绝对误差为6.6年。我们进行了广泛的分析，发现TCN对非病理和病理subject下都有显著下降（-1和-5年，paired t-test，p<=0.18和p<=0.0066）。此外，大脑生物龄差异标志物并不是诊断EEG的病理指标。
</details></li>
</ul>
<hr>
<h2 id="Understanding-Deep-Gradient-Leakage-via-Inversion-Influence-Functions"><a href="#Understanding-Deep-Gradient-Leakage-via-Inversion-Influence-Functions" class="headerlink" title="Understanding Deep Gradient Leakage via Inversion Influence Functions"></a>Understanding Deep Gradient Leakage via Inversion Influence Functions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13016">http://arxiv.org/abs/2309.13016</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/illidanlab/inversion-influence-function">https://github.com/illidanlab/inversion-influence-function</a></li>
<li>paper_authors: Haobo Zhang, Junyuan Hong, Yuyang Deng, Mehrdad Mahdavi, Jiayu Zhou</li>
<li>for: 防止分布式学习中的隐私泄露，尤其是在客户端存储敏感数据时。</li>
<li>methods: 提出了一种新的倒影影响函数(I$^2$F)，通过减少隐私泄露，为分布式学习提供了一种可扩展的解决方案。</li>
<li>results: 在不同的网络架构、数据集、攻击实现和干扰防御方法下，I$^2$F有效地预测了潜在的隐私泄露。 codes are provided in <a target="_blank" rel="noopener" href="https://github.com/illidanlab/inversion-influence-function">https://github.com/illidanlab/inversion-influence-function</a>.<details>
<summary>Abstract</summary>
Deep Gradient Leakage (DGL) is a highly effective attack that recovers private training images from gradient vectors. This attack casts significant privacy challenges on distributed learning from clients with sensitive data, where clients are required to share gradients. Defending against such attacks requires but lacks an understanding of when and how privacy leakage happens, mostly because of the black-box nature of deep networks. In this paper, we propose a novel Inversion Influence Function (I$^2$F) that establishes a closed-form connection between the recovered images and the private gradients by implicitly solving the DGL problem. Compared to directly solving DGL, I$^2$F is scalable for analyzing deep networks, requiring only oracle access to gradients and Jacobian-vector products. We empirically demonstrate that I$^2$F effectively approximated the DGL generally on different model architectures, datasets, attack implementations, and noise-based defenses. With this novel tool, we provide insights into effective gradient perturbation directions, the unfairness of privacy protection, and privacy-preferred model initialization. Our codes are provided in https://github.com/illidanlab/inversion-influence-function.
</details>
<details>
<summary>摘要</summary>
深度梯度泄露（DGL）是一种非常有效的攻击，可以从梯度向量中提取私人训练图像。这种攻击对于分布式学习从客户端进行训练的数据进行了重大隐私挑战，因为客户端需要共享梯度。防止这种攻击需要一个深入了解梯度泄露发生的时间和方式，但是由于深度网络的黑盒特性，这种理解很困难。在这篇论文中，我们提出了一种新的反向影响函数（I$^2$F），它可以通过解决DGL问题来建立私人梯度和 recovered图像之间的关系。与直接解决DGL相比，I$^2$F是可扩展的，只需要对梯度和Jacobian-vector产品进行 oracle 访问即可。我们通过实验表明，I$^2$F可以有效地适应不同的网络架构、数据集、攻击实现和噪声防御。通过这个新工具，我们提供了关于有效梯度扰动方向、隐私保护不公平性和隐私首选模型初始化的新视角。我们的代码可以在https://github.com/illidanlab/inversion-influence-function中找到。
</details></li>
</ul>
<hr>
<h2 id="Importance-of-Smoothness-Induced-by-Optimizers-in-FL4ASR-Towards-Understanding-Federated-Learning-for-End-to-End-ASR"><a href="#Importance-of-Smoothness-Induced-by-Optimizers-in-FL4ASR-Towards-Understanding-Federated-Learning-for-End-to-End-ASR" class="headerlink" title="Importance of Smoothness Induced by Optimizers in FL4ASR: Towards Understanding Federated Learning for End-to-End ASR"></a>Importance of Smoothness Induced by Optimizers in FL4ASR: Towards Understanding Federated Learning for End-to-End ASR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13102">http://arxiv.org/abs/2309.13102</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sheikh Shams Azam, Tatiana Likhomanenko, Martin Pelikan, Jan “Honza” Silovsky</li>
<li>For: 本研究使用 Federated Learning (FL) 技术来训练 End-to-End 语音识别 (ASR) 模型，并研究如何减少 word error rate  между FL 模型和中央化训练模型之间的性能差距。* Methods: 本研究考虑了多个因素，包括适应优化器、 Connectionist Temporal Classification (CTC) 权重的变化、模型初始化方法、将中央化训练经验应用到 FL 中、FL 特有的hyperparameter 等，以探讨如何在 ASR 下面 heterogeneous data distribution 中实现更好的性能。* Results: 研究发现一些优化器可以更好地适应 FL 环境，并且在不同的Client sample size 和学习率调度器下进行了详细的分析。此外，本研究还总结了以前的相关研究中的算法、趋势和最佳实践，以便在 FL 中实现更好的 ASR 性能。<details>
<summary>Abstract</summary>
In this paper, we start by training End-to-End Automatic Speech Recognition (ASR) models using Federated Learning (FL) and examining the fundamental considerations that can be pivotal in minimizing the performance gap in terms of word error rate between models trained using FL versus their centralized counterpart. Specifically, we study the effect of (i) adaptive optimizers, (ii) loss characteristics via altering Connectionist Temporal Classification (CTC) weight, (iii) model initialization through seed start, (iv) carrying over modeling setup from experiences in centralized training to FL, e.g., pre-layer or post-layer normalization, and (v) FL-specific hyperparameters, such as number of local epochs, client sampling size, and learning rate scheduler, specifically for ASR under heterogeneous data distribution. We shed light on how some optimizers work better than others via inducing smoothness. We also summarize the applicability of algorithms, trends, and propose best practices from prior works in FL (in general) toward End-to-End ASR models.
</details>
<details>
<summary>摘要</summary>
在本文中，我们开始由使用联合学习（Federated Learning，FL）训练端到端自动语音识别（ASR）模型，并探讨在减少中心化训练模型和FL模型之间性能差距方面的基本考虑因素。我们专注于以下五个方面：（i）适应性优化器，（ii）修改连接主义时间分类（CTC）重量，（iii）模型初始化通过种子开始，（iv）从中心化训练经验中提取模型设置，例如前层或后层正则化，（v）FL特有的超参数，如本地环节数、客户端抽样大小和学习率调度器。我们解释了一些优化器如何通过减少缓动性来工作更好。我们还总结了先前的FL研究中对端到端ASR模型的算法、趋势和最佳实践。
</details></li>
</ul>
<hr>
<h2 id="Expressive-variational-quantum-circuits-provide-inherent-privacy-in-federated-learning"><a href="#Expressive-variational-quantum-circuits-provide-inherent-privacy-in-federated-learning" class="headerlink" title="Expressive variational quantum circuits provide inherent privacy in federated learning"></a>Expressive variational quantum circuits provide inherent privacy in federated learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13002">http://arxiv.org/abs/2309.13002</a></li>
<li>repo_url: None</li>
<li>paper_authors: Niraj Kumar, Jamie Heredge, Changhao Li, Shaltiel Eloul, Shree Hari Sureshbabu, Marco Pistoia</li>
<li>for: 这个论文目的是提出一种基于量子机器学习模型的联合学习方法，以保护数据隐私。</li>
<li>methods: 这个论文使用了变量量子环境模型，并利用表达性编码映射和过参数化 Ansatz 来保护数据隐私。</li>
<li>results: 论文表明，使用变量量子环境模型可以避免数据泄露，并且在各种攻击模型下保持模型训练可能性。<details>
<summary>Abstract</summary>
Federated learning has emerged as a viable distributed solution to train machine learning models without the actual need to share data with the central aggregator. However, standard neural network-based federated learning models have been shown to be susceptible to data leakage from the gradients shared with the server. In this work, we introduce federated learning with variational quantum circuit model built using expressive encoding maps coupled with overparameterized ans\"atze. We show that expressive maps lead to inherent privacy against gradient inversion attacks, while overparameterization ensures model trainability. Our privacy framework centers on the complexity of solving the system of high-degree multivariate Chebyshev polynomials generated by the gradients of quantum circuit. We present compelling arguments highlighting the inherent difficulty in solving these equations, both in exact and approximate scenarios. Additionally, we delve into machine learning-based attack strategies and establish a direct connection between overparameterization in the original federated learning model and underparameterization in the attack model. Furthermore, we provide numerical scaling arguments showcasing that underparameterization of the expressive map in the attack model leads to the loss landscape being swamped with exponentially many spurious local minima points, thus making it extremely hard to realize a successful attack. This provides a strong claim, for the first time, that the nature of quantum machine learning models inherently helps prevent data leakage in federated learning.
</details>
<details>
<summary>摘要</summary>
Federated learning 已经出现为一种可行的分布式解决方案，用于在没有实际分享数据的情况下训练机器学习模型。然而，标准的神经网络基本的 federated learning 模型已经被证明容易受到数据泄露的威胁，即通过分享梯度来泄露数据。在这种情况下，我们介绍了使用表达式编码映射和过参数 Ansatz 构建的 federated learning 模型。我们表明了表达式编码映射会带来自然的隐私保护，而过参数 Ansatz 可以保证模型可训练。我们的隐私框架基于解决由梯度生成的高阶多变量Chebychev多项式系统的复杂性。我们提供了吸引人的论述，证明在正确和近似情况下解决这些方程是非常困难的。此外，我们还探讨了机器学习基于攻击策略，并证明了过参数化在原始 federated learning 模型中的下降会导致攻击模型下降。最后，我们提供了数学Scaling 理论，表明在攻击模型中下降过参数化会导致搜索空间拥有infiniti多个假的本地最优点，因此非常难实现成功攻击。这提供了一个强有力的证明，即 quantum machine learning 模型的本质带来了防止数据泄露的隐私保护。
</details></li>
</ul>
<hr>
<h2 id="Deep-learning-probability-flows-and-entropy-production-rates-in-active-matter"><a href="#Deep-learning-probability-flows-and-entropy-production-rates-in-active-matter" class="headerlink" title="Deep learning probability flows and entropy production rates in active matter"></a>Deep learning probability flows and entropy production rates in active matter</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12991">http://arxiv.org/abs/2309.12991</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicholas M. Boffi, Eric Vanden-Eijnden</li>
<li>for: 这 paper 是为了理解 nonequilibrium 状态下 active matter 系统的性质。</li>
<li>methods: 这 paper 使用了 deep learning 方法来计算 entropy production rate 和 probability current。</li>
<li>results: 这 paper 得到了一种可以 direct access 到 entropy production rate 和 probability current 的方法，并且可以分解成各个个体、空间区域和自由度的地方贡献。<details>
<summary>Abstract</summary>
Active matter systems, from self-propelled colloids to motile bacteria, are characterized by the conversion of free energy into useful work at the microscopic scale. These systems generically involve physics beyond the reach of equilibrium statistical mechanics, and a persistent challenge has been to understand the nature of their nonequilibrium states. The entropy production rate and the magnitude of the steady-state probability current provide quantitative ways to do so by measuring the breakdown of time-reversal symmetry and the strength of nonequilibrium transport of measure. Yet, their efficient computation has remained elusive, as they depend on the system's unknown and high-dimensional probability density. Here, building upon recent advances in generative modeling, we develop a deep learning framework that estimates the score of this density. We show that the score, together with the microscopic equations of motion, gives direct access to the entropy production rate, the probability current, and their decomposition into local contributions from individual particles, spatial regions, and degrees of freedom. To represent the score, we introduce a novel, spatially-local transformer-based network architecture that learns high-order interactions between particles while respecting their underlying permutation symmetry. We demonstrate the broad utility and scalability of the method by applying it to several high-dimensional systems of interacting active particles undergoing motility-induced phase separation (MIPS). We show that a single instance of our network trained on a system of 4096 particles at one packing fraction can generalize to other regions of the phase diagram, including systems with as many as 32768 particles. We use this observation to quantify the spatial structure of the departure from equilibrium in MIPS as a function of the number of particles and the packing fraction.
</details>
<details>
<summary>摘要</summary>
活的物质系统，从自驱动溶液到运动细菌，通常表现为在微观尺度上将自由能转化为有用的劳动。这些系统通常包括物理现象超出平衡统计力学的范畴，因此理解其非平衡状态的性质是一个挑战。生成热量率和稳态概率流的大小都是量化Nonequilibrium状态的指标，它们取决于系统的未知和高维度概率密度。在这里，我们基于最近的生成模型技术，开发了一种深度学习框架，可以估算概率密度的分数。我们证明，这个分数，与微观运动方程相结合，可以直接访问生成热量率、稳态概率流和它们的分解为个体粒子、空间区域和自由度的本地贡献。为表示分数，我们引入了一种新的、空间地本符论基于网络架构，可以学习高阶相互作用 между粒子，同时尊重它们的基本卷积共轭性。我们在应用这种方法于多种高维度相互作用的活跃粒子系统时，发现这种方法可以泛化到其他频谱 диаграм中，包括系统中的4096个粒子。我们用这个观察来量化离散于MIPS中的空间结构，并与粒子数和压力 fraction有关。
</details></li>
</ul>
<hr>
<h2 id="BayesDLL-Bayesian-Deep-Learning-Library"><a href="#BayesDLL-Bayesian-Deep-Learning-Library" class="headerlink" title="BayesDLL: Bayesian Deep Learning Library"></a>BayesDLL: Bayesian Deep Learning Library</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12928">http://arxiv.org/abs/2309.12928</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/samsunglabs/bayesdll">https://github.com/samsunglabs/bayesdll</a></li>
<li>paper_authors: Minyoung Kim, Timothy Hospedales</li>
<li>for: 这份论文是为了描述一个基于PyTorch的泛型概率神经网络库，用于处理大规模深度网络。</li>
<li>methods: 这个库实现了主流的approximate Bayesian推理算法，包括变分推理、MC-dropout、渐进MCMC和拉пла斯方法。</li>
<li>results: 与其他现有的Bayesian神经网络库相比，这个库可以处理非常大的深度网络，包括视transformer（ViTs）。此外，用户无需编写任何代码修改，可以直接使用现有的backbone网络定义代码。最后，这个库还允许使用预训练模型的权重作为先验均值，这非常有用于使用大规模基础模型如ViTs进行Bayesian推理，这些模型难以从scratch使用下游数据进行优化。<details>
<summary>Abstract</summary>
We release a new Bayesian neural network library for PyTorch for large-scale deep networks. Our library implements mainstream approximate Bayesian inference algorithms: variational inference, MC-dropout, stochastic-gradient MCMC, and Laplace approximation. The main differences from other existing Bayesian neural network libraries are as follows: 1) Our library can deal with very large-scale deep networks including Vision Transformers (ViTs). 2) We need virtually zero code modifications for users (e.g., the backbone network definition codes do not neet to be modified at all). 3) Our library also allows the pre-trained model weights to serve as a prior mean, which is very useful for performing Bayesian inference with the large-scale foundation models like ViTs that are hard to optimise from scratch with the downstream data alone. Our code is publicly available at: \url{https://github.com/SamsungLabs/BayesDLL}\footnote{A mirror repository is also available at: \url{https://github.com/minyoungkim21/BayesDLL}.}.
</details>
<details>
<summary>摘要</summary>
我们发布了一个基于PyTorch的抽象概率神经网络库，用于大规模深度网络。我们的库实现了主流的抽象概率推理算法：变量推理、MC-dropout、随机梯度MCMC和拉пла斯投影。与其他现有的概率神经网络库相比，我们的库具有以下主要优势：1. 我们的库可以处理非常大的深度网络，包括视Transformer（ViTs）。2. 用户没需要修改代码（例如，后ION网络定义代码不需要修改）。3. 我们的库还允许预训练模型的权重服为先验均值，这对于使用大规模基础模型如ViTs进行概率推理非常有用，这些模型难以从头开始使用下游数据进行优化。我们的代码公共可用于：<https://github.com/SamsungLabs/BayesDLL>（备用存储库：<https://github.com/minyoungkim21/BayesDLL>）。
</details></li>
</ul>
<hr>
<h2 id="Topological-Data-Mapping-of-Online-Hate-Speech-Misinformation-and-General-Mental-Health-A-Large-Language-Model-Based-Study"><a href="#Topological-Data-Mapping-of-Online-Hate-Speech-Misinformation-and-General-Mental-Health-A-Large-Language-Model-Based-Study" class="headerlink" title="Topological Data Mapping of Online Hate Speech, Misinformation, and General Mental Health: A Large Language Model Based Study"></a>Topological Data Mapping of Online Hate Speech, Misinformation, and General Mental Health: A Large Language Model Based Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13098">http://arxiv.org/abs/2309.13098</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrew Alexander, Hongbin Wang</li>
<li>for: 这项研究旨在了解社交媒体上的仇恨言论和谣言对poster的心理健康造成的影响。</li>
<li>methods: 研究使用OpenAI的GPT3 derivateposts的嵌入，并通过机器学习分类来理解仇恨言论&#x2F;谣言在不同社区中的角色。</li>
<li>results: 研究发现仇恨言论&#x2F;谣言与心理疾病之间存在紧密的关系，并通过图形分析获得了在线仇恨言论&#x2F;谣言与心理健康之间的视觉地图。<details>
<summary>Abstract</summary>
The advent of social media has led to an increased concern over its potential to propagate hate speech and misinformation, which, in addition to contributing to prejudice and discrimination, has been suspected of playing a role in increasing social violence and crimes in the United States. While literature has shown the existence of an association between posting hate speech and misinformation online and certain personality traits of posters, the general relationship and relevance of online hate speech/misinformation in the context of overall psychological wellbeing of posters remain elusive. One difficulty lies in the lack of adequate data analytics tools capable of adequately analyzing the massive amount of social media posts to uncover the underlying hidden links. Recent progresses in machine learning and large language models such as ChatGPT have made such an analysis possible. In this study, we collected thousands of posts from carefully selected communities on the social media site Reddit. We then utilized OpenAI's GPT3 to derive embeddings of these posts, which are high-dimensional real-numbered vectors that presumably represent the hidden semantics of posts. We then performed various machine-learning classifications based on these embeddings in order to understand the role of hate speech/misinformation in various communities. Finally, a topological data analysis (TDA) was applied to the embeddings to obtain a visual map connecting online hate speech, misinformation, various psychiatric disorders, and general mental health.
</details>
<details>
<summary>摘要</summary>
“社交媒体的出现引发了对其可能传播仇恨言论和谎言的担忧，这些言论可能导致人们偏见和歧视，并被怀疑与社会暴力和犯罪之间存在关系。虽然文献表明在线仇恨言论和谎言与发帖者的个人特征有关，但全面的心理健康和发帖者的关系还未得到了解。一个问题在于分析大量社交媒体帖子的数据分析工具不够完善。Recent progresses in machine learning and large language models such as ChatGPT have made such an analysis possible。在这项研究中，我们收集了Reddit社交媒体平台上的 тысячи篇帖子，然后使用OpenAI的GPT3来 derive embeddings的这些帖子，这些帖子的坐标是高维实数Vecctors，它们可能表示帖子的隐藏 semantics。然后我们通过这些坐标进行了不同的机器学习分类，以了解在不同社区中仇恨言论和谎言的角色。最后，我们对坐标进行了拓扑数据分析（TDA），以获得在线仇恨言论、谎言、心理疾病和总的心理健康之间的视觉地图。”
</details></li>
</ul>
<hr>
<h2 id="FairComp-Workshop-on-Fairness-and-Robustness-in-Machine-Learning-for-Ubiquitous-Computing"><a href="#FairComp-Workshop-on-Fairness-and-Robustness-in-Machine-Learning-for-Ubiquitous-Computing" class="headerlink" title="FairComp: Workshop on Fairness and Robustness in Machine Learning for Ubiquitous Computing"></a>FairComp: Workshop on Fairness and Robustness in Machine Learning for Ubiquitous Computing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12877">http://arxiv.org/abs/2309.12877</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sofia Yfantidou, Dimitris Spathis, Marios Constantinides, Tong Xia, Niels van Berkel</li>
<li>for: 本研讨会旨在讨论 ubicomp 研究中的公平性，以及其社会、技术和法律含义。</li>
<li>methods: 本研讨会将从社会角度探讨公平性和 ubicomp 研究之间的关系，并确定了不会 causing harm 或违反个人权利的技术实践。</li>
<li>results: 本研讨会希望能够培养一个关注公平性的 ubicomp 研究社区，同时也为未来的研究提供明确的指导方针。<details>
<summary>Abstract</summary>
How can we ensure that Ubiquitous Computing (UbiComp) research outcomes are both ethical and fair? While fairness in machine learning (ML) has gained traction in recent years, fairness in UbiComp remains unexplored. This workshop aims to discuss fairness in UbiComp research and its social, technical, and legal implications. From a social perspective, we will examine the relationship between fairness and UbiComp research and identify pathways to ensure that ubiquitous technologies do not cause harm or infringe on individual rights. From a technical perspective, we will initiate a discussion on data practices to develop bias mitigation approaches tailored to UbiComp research. From a legal perspective, we will examine how new policies shape our community's work and future research. We aim to foster a vibrant community centered around the topic of responsible UbiComp, while also charting a clear path for future research endeavours in this field.
</details>
<details>
<summary>摘要</summary>
如何确保宇宙计算（UbiComp）研究成果是公正和公平的？尽管机器学习（ML）中的公正在最近几年得到了更多的关注，但UbiComp中的公正仍然未得到探讨。这个研讨会旨在讨论UbiComp研究中的公正性和其社会、技术和法律因素的影响。从社会角度来看，我们将探讨UBicomp技术不会对个人 права或者造成伤害的关系。从技术角度来看，我们将开始讨论针对UbiComp研究的数据实践，以开发减少偏见的技术策略。从法律角度来看，我们将检查新的政策如何影响我们的社区和未来的研究。我们想建立一个热烈的社区，以讨论负责任的UbiComp研究，同时也映射出未来这一领域的研究方向。
</details></li>
</ul>
<hr>
<h2 id="Robotic-Handling-of-Compliant-Food-Objects-by-Robust-Learning-from-Demonstration"><a href="#Robotic-Handling-of-Compliant-Food-Objects-by-Robust-Learning-from-Demonstration" class="headerlink" title="Robotic Handling of Compliant Food Objects by Robust Learning from Demonstration"></a>Robotic Handling of Compliant Food Objects by Robust Learning from Demonstration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12856">http://arxiv.org/abs/2309.12856</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ekrem Misimi, Alexander Olofsson, Aleksander Eilertsen, Elling Ruud Øye, John Reidar Mathiassen</li>
<li>for:  robotic grasping of food compliant objects, to improve the consistency of robot learning and reduce the variability of human operators.</li>
<li>methods:  Learning from Demonstration (LfD) approach that combines RGB-D images and tactile data to estimate the necessary gripper pose, finger configuration, and forces for effective robot handling.</li>
<li>results:  the proposed approach can automatically remove inconsistent demonstrations and estimate the teacher’s intended policy, with validated performance for fragile and compliant food objects with complex 3D shapes.<details>
<summary>Abstract</summary>
The robotic handling of compliant and deformable food raw materials, characterized by high biological variation, complex geometrical 3D shapes, and mechanical structures and texture, is currently in huge demand in the ocean space, agricultural, and food industries. Many tasks in these industries are performed manually by human operators who, due to the laborious and tedious nature of their tasks, exhibit high variability in execution, with variable outcomes. The introduction of robotic automation for most complex processing tasks has been challenging due to current robot learning policies. A more consistent learning policy involving skilled operators is desired. In this paper, we address the problem of robot learning when presented with inconsistent demonstrations. To this end, we propose a robust learning policy based on Learning from Demonstration (LfD) for robotic grasping of food compliant objects. The approach uses a merging of RGB-D images and tactile data in order to estimate the necessary pose of the gripper, gripper finger configuration and forces exerted on the object in order to achieve effective robot handling. During LfD training, the gripper pose, finger configurations and tactile values for the fingers, as well as RGB-D images are saved. We present an LfD learning policy that automatically removes inconsistent demonstrations, and estimates the teacher's intended policy. The performance of our approach is validated and demonstrated for fragile and compliant food objects with complex 3D shapes. The proposed approach has a vast range of potential applications in the aforementioned industry sectors.
</details>
<details>
<summary>摘要</summary>
“ robotic food raw material 的自适应和弹性处理，具有高度生物变化、复杂的三维几何形状、机械结构和 текстусту，目前在海洋、农业和食品行业中受到巨大的需求。这些行业中的许多任务现在由人类操作员执行，由于任务的劳动 INTENSIVE 和 monotony，操作员的执行效果存在很大的变化， resulting in variable outcomes。 introducing robotic automation for most complex processing tasks has been challenging due to current robot learning policies. therefore, a more consistent learning policy involving skilled operators is desired. in this paper, we address the problem of robot learning when presented with inconsistent demonstrations. to this end, we propose a robust learning policy based on Learning from Demonstration (LfD) for robotic grasping of food compliant objects. the approach uses a merging of RGB-D images and tactile data in order to estimate the necessary pose of the gripper, gripper finger configuration and forces exerted on the object in order to achieve effective robot handling. during LfD training, the gripper pose, finger configurations and tactile values for the fingers, as well as RGB-D images are saved. we present an LfD learning policy that automatically removes inconsistent demonstrations, and estimates the teacher's intended policy. the performance of our approach is validated and demonstrated for fragile and compliant food objects with complex 3D shapes. the proposed approach has a vast range of potential applications in the aforementioned industry sectors.”Note: The translation is in Simplified Chinese, which is the standard version of Chinese used in mainland China and Singapore. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="DeepOPF-U-A-Unified-Deep-Neural-Network-to-Solve-AC-Optimal-Power-Flow-in-Multiple-Networks"><a href="#DeepOPF-U-A-Unified-Deep-Neural-Network-to-Solve-AC-Optimal-Power-Flow-in-Multiple-Networks" class="headerlink" title="DeepOPF-U: A Unified Deep Neural Network to Solve AC Optimal Power Flow in Multiple Networks"></a>DeepOPF-U: A Unified Deep Neural Network to Solve AC Optimal Power Flow in Multiple Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12849">http://arxiv.org/abs/2309.12849</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hieu9955/ggggg">https://github.com/hieu9955/ggggg</a></li>
<li>paper_authors: Heng Liang, Changhong Zhao</li>
<li>for: 解决不同电力网络中的最优电力流问题</li>
<li>methods: 使用单一深度神经网络（DNN）解决交流电力流问题，并采用滑动输入和输出层对各种电力网络中的负荷和OPT问题进行适应</li>
<li>results: 对IEEE 57&#x2F;118&#x2F;300-bus测试系统和一个逐渐增长的网络进行了优化的性能表现，并且可以处理不同数量的节点、线径和可再生能源资源。<details>
<summary>Abstract</summary>
The traditional machine learning models to solve optimal power flow (OPF) are mostly trained for a given power network and lack generalizability to today's power networks with varying topologies and growing plug-and-play distributed energy resources (DERs). In this paper, we propose DeepOPF-U, which uses one unified deep neural network (DNN) to solve alternating-current (AC) OPF problems in different power networks, including a set of power networks that is successively expanding. Specifically, we design elastic input and output layers for the vectors of given loads and OPF solutions with varying lengths in different networks. The proposed method, using a single unified DNN, can deal with different and growing numbers of buses, lines, loads, and DERs. Simulations of IEEE 57/118/300-bus test systems and a network growing from 73 to 118 buses verify the improved performance of DeepOPF-U compared to existing DNN-based solution methods.
</details>
<details>
<summary>摘要</summary>
传统的机器学习模型用于优化电力流（OPF）大多是为某个特定的电力网络训练，而缺乏对今天的电力网络结构和增加插入式分布式能源资源（DERs）的普适性。在这篇论文中，我们提议了DeepOPF-U，它使用一个通用的深度神经网络（DNN）来解决不同电力网络中的交流电力流优化问题。Specifically，我们设计了弹性输入和输出层，以处理具有不同长度的输入和解决方案Vector在不同的网络中。我们的方法使用单个通用DNN来解决不同的和增加的电力网络中的问题，包括不同数量的总站、线径和负荷。我们的实验结果表明，相比之前的DNN基本方法，DeepOPF-U可以更好地处理不同的电力网络和增加的负荷。Here's a word-for-word translation of the text into Simplified Chinese:传统的机器学习模型用于优化电力流（OPF）大多是为某个特定的电力网络训练，而缺乏对今天的电力网络结构和增加插入式分布式能源资源（DERs）的普适性。在这篇论文中，我们提议了DeepOPF-U，它使用一个通用的深度神经网络（DNN）来解决不同电力网络中的交流电力流优化问题。Specifically，我们设计了弹性输入和输出层，以处理具有不同长度的输入和解决方案Vector在不同的网络中。我们的方法使用单个通用DNN来解决不同的和增加的电力网络中的问题，包括不同数量的总站、线径和负荷。我们的实验结果表明，相比之前的DNN基本方法，DeepOPF-U可以更好地处理不同的电力网络和增加的负荷。
</details></li>
</ul>
<hr>
<h2 id="Multiple-Independent-DE-Optimizations-to-Tackle-Uncertainty-and-Variability-in-Demand-in-Inventory-Management"><a href="#Multiple-Independent-DE-Optimizations-to-Tackle-Uncertainty-and-Variability-in-Demand-in-Inventory-Management" class="headerlink" title="Multiple Independent DE Optimizations to Tackle Uncertainty and Variability in Demand in Inventory Management"></a>Multiple Independent DE Optimizations to Tackle Uncertainty and Variability in Demand in Inventory Management</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13095">http://arxiv.org/abs/2309.13095</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sarit Maitra, Sukanya Kundu, Vivek Mishra</li>
<li>for: 本研究旨在找出适用于不确定需求 patrerns 的 Metaheuristic Differeential Evolution 优化策略，以最小化存储成本。</li>
<li>methods: 本研究结合综合 IM 策略的 continuous review 和 Monte Carlo Simulation (MCS)，并对多种算法进行比较，以找到最佳解决方案。</li>
<li>results: 研究发现，Differeential Evolution (DE) 算法在优化 IM 中表现最佳，并通过 Latin Hypercube Sampling (LHS) 统计方法进行参数调整。本研究还提出了一种 combining 多个独立 DE 优化实例的方法，以提高性能和成本效益，特别是在不确定需求 patrerns 下。<details>
<summary>Abstract</summary>
To determine the effectiveness of metaheuristic Differential Evolution optimization strategy for inventory management (IM) in the context of stochastic demand, this empirical study undertakes a thorough investigation. The primary objective is to discern the most effective strategy for minimizing inventory costs within the context of uncertain demand patterns. Inventory costs refer to the expenses associated with holding and managing inventory within a business. The approach combines a continuous review of IM policies with a Monte Carlo Simulation (MCS). To find the optimal solution, the study focuses on meta-heuristic approaches and compares multiple algorithms. The outcomes reveal that the Differential Evolution (DE) algorithm outperforms its counterparts in optimizing IM. To fine-tune the parameters, the study employs the Latin Hypercube Sampling (LHS) statistical method. To determine the final solution, a method is employed in this study which combines the outcomes of multiple independent DE optimizations, each initiated with different random initial conditions. This approach introduces a novel and promising dimension to the field of inventory management, offering potential enhancements in performance and cost efficiency, especially in the presence of stochastic demand patterns.
</details>
<details>
<summary>摘要</summary>
为了判断metaheuristic diferencial evolution优化策略对供应链管理（IM）在不确定的需求 Patterns 上的效果，这个实验室进行了一项严格的调查。主要目标是找到最有效的策略来最小化存储成本在企业中。存储成本包括保持和管理存储的成本。该方法结合了连续性 IM 策略的审查和Monte Carlo Simulation（MCS）。为了找到优化策略，这个研究对meta-heuristic Approaches进行了比较多个算法。研究发现，diferencial Evolution（DE）算法在优化IM方面表现出色。为了调整参数，这个研究使用了Latin Hypercube Sampling（LHS）统计方法。为了确定最终解决方案，这个研究employs a方法，将多个独立的DE优化结果组合起来，每个初始条件都是random。这种方法在供应链管理领域引入了一个新的维度，提供了可能的性能和成本效益，特别是在不确定的需求Patterns 上。
</details></li>
</ul>
<hr>
<h2 id="Reward-Function-Design-for-Crowd-Simulation-via-Reinforcement-Learning"><a href="#Reward-Function-Design-for-Crowd-Simulation-via-Reinforcement-Learning" class="headerlink" title="Reward Function Design for Crowd Simulation via Reinforcement Learning"></a>Reward Function Design for Crowd Simulation via Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12841">http://arxiv.org/abs/2309.12841</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ariel Kwiatkowski, Vicky Kalogeiton, Julien Pettré, Marie-Paule Cani</li>
<li>for: 这个论文的目的是探讨基于奖励学习的人群 simulate 的方法，以及设计奖励函数的正确方法。</li>
<li>methods: 这个论文使用了奖励学习方法，并通过 theoretically 和 empirically 分析奖励函数的效果。</li>
<li>results: 该论文的实验结果表明，直接减少能量消耗是一种有效的策略， provided that it is paired with an appropriately scaled guiding potential。这些结果可以帮助开发新的人群 simulate 技术，并对人类 Navigation 的研究产生影响。<details>
<summary>Abstract</summary>
Crowd simulation is important for video-games design, since it enables to populate virtual worlds with autonomous avatars that navigate in a human-like manner. Reinforcement learning has shown great potential in simulating virtual crowds, but the design of the reward function is critical to achieving effective and efficient results. In this work, we explore the design of reward functions for reinforcement learning-based crowd simulation. We provide theoretical insights on the validity of certain reward functions according to their analytical properties, and evaluate them empirically using a range of scenarios, using the energy efficiency as the metric. Our experiments show that directly minimizing the energy usage is a viable strategy as long as it is paired with an appropriately scaled guiding potential, and enable us to study the impact of the different reward components on the behavior of the simulated crowd. Our findings can inform the development of new crowd simulation techniques, and contribute to the wider study of human-like navigation.
</details>
<details>
<summary>摘要</summary>
伪人群模拟在游戏设计中具有重要意义，因为它使得虚拟世界中的自主人物能够在人类化的方式下自主 Navigation。基于奖励学习的人群模拟显示了巨大的潜力，但是奖励函数的设计是获得有效和高效的结果的关键。在这项工作中，我们探讨了基于奖励学习的人群模拟中奖励函数的设计。我们提供了理论上的思路，并通过一系列场景的实验来评估奖励函数的有效性。我们发现，直接减少能量使用是一个有效的策略，只要与适当的拟合潜在能量相关的奖励函数相结合。这些实验结果可以导向新的人群模拟技术的开发，并对人类化导航的更广泛研究产生贡献。
</details></li>
</ul>
<hr>
<h2 id="Doubly-Robust-Proximal-Causal-Learning-for-Continuous-Treatments"><a href="#Doubly-Robust-Proximal-Causal-Learning-for-Continuous-Treatments" class="headerlink" title="Doubly Robust Proximal Causal Learning for Continuous Treatments"></a>Doubly Robust Proximal Causal Learning for Continuous Treatments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12819">http://arxiv.org/abs/2309.12819</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yong Wu, Yanwei Fu, Shouyan Wang, Xinwei Sun</li>
<li>for: 本研究旨在提出一种可以处理连续干扰因素的 proximal causal learning 框架，以便在实际应用中更好地估计 causal effect。</li>
<li>methods: 我们提出了一种基于 kernel 函数的 DR 估计器，可以有效地处理连续干扰因素。我们还提出了一种新的方法来效率地解决干扰函数的问题。</li>
<li>results: 我们对 synthetic 数据和实际应用进行了评估，并证明了我们的估计器具有良好的准确性和稳定性。<details>
<summary>Abstract</summary>
Proximal causal learning is a promising framework for identifying the causal effect under the existence of unmeasured confounders. Within this framework, the doubly robust (DR) estimator was derived and has shown its effectiveness in estimation, especially when the model assumption is violated. However, the current form of the DR estimator is restricted to binary treatments, while the treatment can be continuous in many real-world applications. The primary obstacle to continuous treatments resides in the delta function present in the original DR estimator, making it infeasible in causal effect estimation and introducing a heavy computational burden in nuisance function estimation. To address these challenges, we propose a kernel-based DR estimator that can well handle continuous treatments. Equipped with its smoothness, we show that its oracle form is a consistent approximation of the influence function. Further, we propose a new approach to efficiently solve the nuisance functions. We then provide a comprehensive convergence analysis in terms of the mean square error. We demonstrate the utility of our estimator on synthetic datasets and real-world applications.
</details>
<details>
<summary>摘要</summary>
近似 causal learning 是一个有前途的框架，用于在存在未测量的干扰因素时确定 causal effect。在这个框架下， doubly robust（DR）估计器被 derivation 出来，并在不符合模型假设的情况下表现出优异的效果。然而，现有的 DR 估计器只适用于 binary 治疗，而在实际应用中，治疗可能是连续的。主要的障碍是 delta 函数存在在原始 DR 估计器中，使其无法在 causal effect 估计中使用，并且在 auxiliary function 估计中增加了巨大的计算负担。为了解决这些挑战，我们提出了基于 kernel 的 DR 估计器，可以好好地处理连续治疗。利用其平滑性，我们表明其oracle形式是一个可靠的 influence function 的近似。此外，我们提出了一种新的方法来有效地解决 auxiliary function。然后，我们进行了完整的mean square error（MSE）的收敛分析。我们在 sintetic 数据和实际应用中展示了我们的估计器的实用性。
</details></li>
</ul>
<hr>
<h2 id="Improving-Generalization-in-Game-Agents-with-Data-Augmentation-in-Imitation-Learning"><a href="#Improving-Generalization-in-Game-Agents-with-Data-Augmentation-in-Imitation-Learning" class="headerlink" title="Improving Generalization in Game Agents with Data Augmentation in Imitation Learning"></a>Improving Generalization in Game Agents with Data Augmentation in Imitation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12815">http://arxiv.org/abs/2309.12815</a></li>
<li>repo_url: None</li>
<li>paper_authors: Derek Yadgaroff, Alessandro Sestini, Konrad Tollmar, Linus Gisslén</li>
<li>for: 提高游戏AI的通用能力</li>
<li>methods: 使用数据扩展法提高imitative learning agents的通用能力</li>
<li>results: 数据扩展法可以有效提高imitative learning agents的通用能力，并提供了多种3D环境中的性能指标。<details>
<summary>Abstract</summary>
Imitation learning is an effective approach for training game-playing agents and, consequently, for efficient game production. However, generalization - the ability to perform well in related but unseen scenarios - is an essential requirement that remains an unsolved challenge for game AI. Generalization is difficult for imitation learning agents because it requires the algorithm to take meaningful actions outside of the training distribution. In this paper we propose a solution to this challenge. Inspired by the success of data augmentation in supervised learning, we augment the training data so the distribution of states and actions in the dataset better represents the real state-action distribution. This study evaluates methods for combining and applying data augmentations to observations, to improve generalization of imitation learning agents. It also provides a performance benchmark of these augmentations across several 3D environments. These results demonstrate that data augmentation is a promising framework for improving generalization in imitation learning agents.
</details>
<details>
<summary>摘要</summary>
仿制学习是一种有效的方法用于训练游戏AI代理人，并且可以提高游戏生产效率。然而，通用化（能够在相关 yet unseen 的情况下表现良好）是一个必备的要求，它是一个未解决的挑战。通用化对仿制学习代理人来说是一个困难的任务，因为它需要算法在训练分布之外行为。在这篇论文中，我们提出了一种解决这个挑战的方法。受到超参数学习中的数据扩展成功的启发，我们将训练数据进行扩展，以使得状态和动作的分布更好地表示真实的状态-动作分布。本研究评估了对观察数据的合并和应用的方法，以提高仿制学习代理人的通用化。此外，本研究还提供了不同3D环境下这些扩展的性能比较。这些结果表明，数据扩展是一种有前途的框架，可以提高仿制学习代理人的通用化。
</details></li>
</ul>
<hr>
<h2 id="Deepfake-audio-as-a-data-augmentation-technique-for-training-automatic-speech-to-text-transcription-models"><a href="#Deepfake-audio-as-a-data-augmentation-technique-for-training-automatic-speech-to-text-transcription-models" class="headerlink" title="Deepfake audio as a data augmentation technique for training automatic speech to text transcription models"></a>Deepfake audio as a data augmentation technique for training automatic speech to text transcription models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12802">http://arxiv.org/abs/2309.12802</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexandre R. Ferreira, Cláudio E. C. Campelo</li>
<li>for: 本研究旨在提高语音识别模型的Robustness，需要一个大型多样化的标注数据集。</li>
<li>methods: 本文提出了一种基于深度假音的数据增强策略，使用了voice cloner和英文语音 Dataset produced by Indians。</li>
<li>results: 经过实验 validate，使用增强数据可以提高语音识别模型的性能，并且在不同的场景下都有良好的效果。<details>
<summary>Abstract</summary>
To train transcriptor models that produce robust results, a large and diverse labeled dataset is required. Finding such data with the necessary characteristics is a challenging task, especially for languages less popular than English. Moreover, producing such data requires significant effort and often money. Therefore, a strategy to mitigate this problem is the use of data augmentation techniques. In this work, we propose a framework that approaches data augmentation based on deepfake audio. To validate the produced framework, experiments were conducted using existing deepfake and transcription models. A voice cloner and a dataset produced by Indians (in English) were selected, ensuring the presence of a single accent in the dataset. Subsequently, the augmented data was used to train speech to text models in various scenarios.
</details>
<details>
<summary>摘要</summary>
In this work, we conducted experiments using existing deepfake and transcription models. We selected a voice cloner and a dataset produced by Indians (in English) to ensure the presence of a single accent in the dataset. We then augmented the data and used it to train speech-to-text models in various scenarios.
</details></li>
</ul>
<hr>
<h2 id="An-Intelligent-Approach-to-Detecting-Novel-Fault-Classes-for-Centrifugal-Pumps-Based-on-Deep-CNNs-and-Unsupervised-Methods"><a href="#An-Intelligent-Approach-to-Detecting-Novel-Fault-Classes-for-Centrifugal-Pumps-Based-on-Deep-CNNs-and-Unsupervised-Methods" class="headerlink" title="An Intelligent Approach to Detecting Novel Fault Classes for Centrifugal Pumps Based on Deep CNNs and Unsupervised Methods"></a>An Intelligent Approach to Detecting Novel Fault Classes for Centrifugal Pumps Based on Deep CNNs and Unsupervised Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12765">http://arxiv.org/abs/2309.12765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahdi Abdollah Chalaki, Daniyal Maroufi, Mahdi Robati, Mohammad Javad Karimi, Ali Sadighi</li>
<li>for: 本研究旨在Addressing the challenges of data-driven fault diagnosis of rotating machines, particularly the lack of information about various faults in the field.</li>
<li>methods: 本 paper 使用了 convolutional neural network (CNN) 和 t-SNE 方法，以检测 novel faults. 首先，使用受限的系统故障信息进行训练，然后使用 clustering 技术进行检测。 如果检测到新的故障，则使用新数据进行网络的扩展。</li>
<li>results: 实验结果表明，这种 two-stage 方法在一台 centrifugal pump 上得到了高精度的 novel fault 检测结果。<details>
<summary>Abstract</summary>
Despite the recent success in data-driven fault diagnosis of rotating machines, there are still remaining challenges in this field. Among the issues to be addressed, is the lack of information about variety of faults the system may encounter in the field. In this paper, we assume a partial knowledge of the system faults and use the corresponding data to train a convolutional neural network. A combination of t-SNE method and clustering techniques is then employed to detect novel faults. Upon detection, the network is augmented using the new data. Finally, a test setup is used to validate this two-stage methodology on a centrifugal pump and experimental results show high accuracy in detecting novel faults.
</details>
<details>
<summary>摘要</summary>
尽管在数据驱动机器故障诊断方面已经取得了一定的成功，但这个领域仍然存在一些挑战。其中一个问题是系统可能在场景中遇到多种故障的信息不够。在这篇论文中，我们假设系统具有部分故障知识，并使用相应的数据来训练卷积神经网络。然后，我们使用t-SNE方法和聚类技术检测新的故障。检测到故障后，网络被扩展使用新的数据。最后，我们使用测试setup验证这种两个阶段方法在中心泵上的效果，实验结果显示高精度地检测到新的故障。Note: "t-SNE" stands for "t-distributed Stochastic Neighbor Embedding", which is a technique used to reduce the dimensionality of data.
</details></li>
</ul>
<hr>
<h2 id="Prototype-Enhanced-Hypergraph-Learning-for-Heterogeneous-Information-Networks"><a href="#Prototype-Enhanced-Hypergraph-Learning-for-Heterogeneous-Information-Networks" class="headerlink" title="Prototype-Enhanced Hypergraph Learning for Heterogeneous Information Networks"></a>Prototype-Enhanced Hypergraph Learning for Heterogeneous Information Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13092">http://arxiv.org/abs/2309.13092</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuai Wang, Jiayi Shen, Athanasios Efthymiou, Stevan Rudinac, Monika Kackovic, Nachoem Wijnberg, Marcel Worring</li>
<li>for: 本研究旨在提出一种基于超граpher学习的节点分类方法，用于处理具有多样化和复杂关系的 multimedia数据中的异构信息网络（HINs）。</li>
<li>methods: 本方法使用超граpher instead of graph，以捕捉高阶关系 между节点，而无需靠谱定过程。它还利用示例来改善超граpher学习过程的稳定性，从而提供可读性的人类可读性。</li>
<li>results: 对于三个真实的 HINs 实验，本方法显示了效果。<details>
<summary>Abstract</summary>
The variety and complexity of relations in multimedia data lead to Heterogeneous Information Networks (HINs). Capturing the semantics from such networks requires approaches capable of utilizing the full richness of the HINs. Existing methods for modeling HINs employ techniques originally designed for graph neural networks, and HINs decomposition analysis, like using manually predefined metapaths. In this paper, we introduce a novel prototype-enhanced hypergraph learning approach for node classification in HINs. Using hypergraphs instead of graphs, our method captures higher-order relationships among nodes and extracts semantic information without relying on metapaths. Our method leverages the power of prototypes to improve the robustness of the hypergraph learning process and creates the potential to provide human-interpretable insights into the underlying network structure. Extensive experiments on three real-world HINs demonstrate the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
multimedia数据中的多样性和复杂性导致非同様网络（HINs）的出现。捕捉HINs中的semantics需要能够利用非同様网络的全部 ricinus。现有的HINs模型使用原本设计 для图神经网络的技术，以及手动划定的ме타路径进行分析。本文提出了一种基于prototype强化的超граraph学习方法 дляHINs节点分类。使用超граraph instead of graphs，我们的方法可以捕捉节点之间的高阶关系，并提取无需依赖于ме타路径的semantic信息。我们的方法利用 prototype的力量来提高超гра�学习过程的稳定性，并创造了可以提供人类可读的网络结构下的内部层次结构的可能性。我们在三个真实的HINs上进行了广泛的实验，并证明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Make-the-U-in-UDA-Matter-Invariant-Consistency-Learning-for-Unsupervised-Domain-Adaptation"><a href="#Make-the-U-in-UDA-Matter-Invariant-Consistency-Learning-for-Unsupervised-Domain-Adaptation" class="headerlink" title="Make the U in UDA Matter: Invariant Consistency Learning for Unsupervised Domain Adaptation"></a>Make the U in UDA Matter: Invariant Consistency Learning for Unsupervised Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12742">http://arxiv.org/abs/2309.12742</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yue-zhongqi/icon">https://github.com/yue-zhongqi/icon</a></li>
<li>paper_authors: Zhongqi Yue, Hanwang Zhang, Qianru Sun</li>
<li>for: 本研究旨在解决Unsupervised Domain Adaptation (UDA)中存在的假 correlate问题，即源领域中的特征与目标领域的特征之间的假 correlate，这导致了目标领域的模型难以泛化。</li>
<li>methods: 我们提出了一种名为“做 Consistency learning”（ICON）的方法，它通过同时使源领域和目标领域的分类器预测结果相一致，从而消除了目标领域中的假 correlate。</li>
<li>results: 我们在经验证上表明，ICON可以在经典的UDA benchmark上达到最佳性能，并在挑战性的WILDS 2.0 benchmark上超越所有传统方法。<details>
<summary>Abstract</summary>
Domain Adaptation (DA) is always challenged by the spurious correlation between domain-invariant features (e.g., class identity) and domain-specific features (e.g., environment) that does not generalize to the target domain. Unfortunately, even enriched with additional unsupervised target domains, existing Unsupervised DA (UDA) methods still suffer from it. This is because the source domain supervision only considers the target domain samples as auxiliary data (e.g., by pseudo-labeling), yet the inherent distribution in the target domain -- where the valuable de-correlation clues hide -- is disregarded. We propose to make the U in UDA matter by giving equal status to the two domains. Specifically, we learn an invariant classifier whose prediction is simultaneously consistent with the labels in the source domain and clusters in the target domain, hence the spurious correlation inconsistent in the target domain is removed. We dub our approach "Invariant CONsistency learning" (ICON). Extensive experiments show that ICON achieves the state-of-the-art performance on the classic UDA benchmarks: Office-Home and VisDA-2017, and outperforms all the conventional methods on the challenging WILDS 2.0 benchmark. Codes are in https://github.com/yue-zhongqi/ICON.
</details>
<details>
<summary>摘要</summary>
域 adaptation (DA) 总是面临着域特异特征（例如类标识）和域特定特征（例如环境）之间的假设相关性，这种相关性不能泛化到目标域。尽管使用额外的无监督目标域数据，现有的无监督DA（UDA）方法仍然受到这种挑战。这是因为源域监督只考虑目标域样本为辅助数据（例如 pseudo-labeling），忽略了目标域的自然分布，其中包含了价值的分解准则。我们提议使得U在UDA中变得重要，即在源域和目标域之间学习一个不变的分类器，其预测结果同时与源域中的标签和目标域中的团集一致，因此在目标域中排除了假设相关性。我们称之为“不变CONsistency学习”（ICON）。我们进行了广泛的实验，ICON在经典的UDABenchmark上取得了state-of-the-art性能，并在挑战性的WILDS 2.0 Benchmark上超过了所有传统方法。代码在https://github.com/yue-zhongqi/ICON。
</details></li>
</ul>
<hr>
<h2 id="Optimal-Dynamic-Fees-for-Blockchain-Resources"><a href="#Optimal-Dynamic-Fees-for-Blockchain-Resources" class="headerlink" title="Optimal Dynamic Fees for Blockchain Resources"></a>Optimal Dynamic Fees for Blockchain Resources</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12735">http://arxiv.org/abs/2309.12735</a></li>
<li>repo_url: None</li>
<li>paper_authors: Davide Crapis, Ciamac C. Moallemi, Shouqiao Wang</li>
<li>For: 本研究は多个区块链资源的优化奖励机制的设计问题进行通用和实用的框架开发。* Methods: 我们的框架可以计算优化奖励策略，以让奖励策略与持续的需求变化进行融合，同时保证奖励策略对当地噪声的Robustness。在多个资源的总情况下，我们的优化策略能正确处理资源需求之间的交叉效应（补做和替代）。* Results: 我们的框架可以用来修订或指导使用各种各样的奖励更新规则，如EIP-1559或EIP-4844。我们通过两个案例研究证明了这一点。我们还使用实际市场数据来对一个一维版本的我们模型进行估算，并对EIP-1559的性能与我们的优化策略进行比较。<details>
<summary>Abstract</summary>
We develop a general and practical framework to address the problem of the optimal design of dynamic fee mechanisms for multiple blockchain resources. Our framework allows to compute policies that optimally trade-off between adjusting resource prices to handle persistent demand shifts versus being robust to local noise in the observed block demand. In the general case with more than one resource, our optimal policies correctly handle cross-effects (complementarity and substitutability) in resource demands. We also show how these cross-effects can be used to inform resource design, i.e. combining resources into bundles that have low demand-side cross-effects can yield simpler and more efficient price-update rules. Our framework is also practical, we demonstrate how it can be used to refine or inform the design of heuristic fee update rules such as EIP-1559 or EIP-4844 with two case studies. We then estimate a uni-dimensional version of our model using real market data from the Ethereum blockchain and empirically compare the performance of our optimal policies to EIP-1559.
</details>
<details>
<summary>摘要</summary>
我们开发了一个通用且实用的框架，以解决多个区块链资源的优化设计动态费用机制问题。我们的框架可以计算优化费用更新策略，以优考虑到适应持续强制变化的需求轨迹，同时保持对地方噪声观测到的区块需求的稳定性。在多than one resource的普通情况下，我们的优化策略可以正确处理资源需求之间的交叉效应（补做和替代）。我们还示出了如何使用这些交叉效应来指导资源设计，例如将资源合并成具有低需求层次交叉效应的套件可以得到简单而高效的价格更新规则。我们的框架也是实用的，我们示出了如何使用它来优化或指导基于EIP-1559或EIP-4844的费用更新规则的设计。然后，我们使用实际市场数据从Ethereum区块链进行了一个一维版本的模型估算，并对EIP-1559的性能与我们的优化策略进行了实际比较。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Representations-Improve-Supervised-Learning-in-Speech-Emotion-Recognition"><a href="#Unsupervised-Representations-Improve-Supervised-Learning-in-Speech-Emotion-Recognition" class="headerlink" title="Unsupervised Representations Improve Supervised Learning in Speech Emotion Recognition"></a>Unsupervised Representations Improve Supervised Learning in Speech Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12714">http://arxiv.org/abs/2309.12714</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amirali Soltani Tehrani, Niloufar Faridani, Ramin Toosi</li>
<li>for: 这个研究旨在提高人机交互的深度理解，通过感知人类情感状态，提高人机交互的效果和同情性。</li>
<li>methods: 该研究提出了一种新的方法，即结合自我指导特征提取和指导分类来实现情绪识别。在预处理步骤中，我们使用基于Wav2Vec模型的自我指导特征提取器，从audio数据中捕捉音频特征。然后，输出特征图的前一步结果被传递给自定义的卷积神经网络模型进行情绪分类。</li>
<li>results: 在使用ShEMO数据集进行测试时，该方法超过了两个基准方法，即支持向量机分类器和转移学习预训练的CNN模型。与状态的艺术方法相比，该方法表现更出色，提供了更高的情感认知水平，为人机交互领域带来更多的同情性和效果。<details>
<summary>Abstract</summary>
Speech Emotion Recognition (SER) plays a pivotal role in enhancing human-computer interaction by enabling a deeper understanding of emotional states across a wide range of applications, contributing to more empathetic and effective communication. This study proposes an innovative approach that integrates self-supervised feature extraction with supervised classification for emotion recognition from small audio segments. In the preprocessing step, to eliminate the need of crafting audio features, we employed a self-supervised feature extractor, based on the Wav2Vec model, to capture acoustic features from audio data. Then, the output featuremaps of the preprocessing step are fed to a custom designed Convolutional Neural Network (CNN)-based model to perform emotion classification. Utilizing the ShEMO dataset as our testing ground, the proposed method surpasses two baseline methods, i.e. support vector machine classifier and transfer learning of a pretrained CNN. comparing the propose method to the state-of-the-art methods in SER task indicates the superiority of the proposed method. Our findings underscore the pivotal role of deep unsupervised feature learning in elevating the landscape of SER, offering enhanced emotional comprehension in the realm of human-computer interactions.
</details>
<details>
<summary>摘要</summary>
人机交互中情感认识（SER）发挥关键作用，帮助更深入理解情感状态，涵盖广泛应用领域，从而提供更 Empathetic 和有效的沟通。本研究提出了一种创新的方法，将自主学习特征提取与经过监督分类结合用于情感识别。在预处理步骤中，我们采用基于 Wav2Vec 模型的自主学习特征提取器，从音频数据中提取了音频特征。然后，预处理步骤的输出特征地图被传递给自定义设计的卷积神经网络（CNN）模型进行情感分类。使用 ShEMO 数据集进行测试，我们的提议方法超过了两个基准方法，即支持向量机学习分类器和转移学习已经训练的 CNN。与状态 искусственный地进行SER任务的方法进行比较，我们的发现表明了深入的无监督特征学习对 SER 任务的提升具有重要作用。我们的发现强调了深入的特征学习在人机交互中的情感理解方面的重要性。
</details></li>
</ul>
<hr>
<h2 id="Big-model-only-for-hard-audios-Sample-dependent-Whisper-model-selection-for-efficient-inferences"><a href="#Big-model-only-for-hard-audios-Sample-dependent-Whisper-model-selection-for-efficient-inferences" class="headerlink" title="Big model only for hard audios: Sample dependent Whisper model selection for efficient inferences"></a>Big model only for hard audios: Sample dependent Whisper model selection for efficient inferences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12712">http://arxiv.org/abs/2309.12712</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hugomalard/big-model-only-for-hard-audios">https://github.com/hugomalard/big-model-only-for-hard-audios</a></li>
<li>paper_authors: Hugo Malard, Salah Zaiem, Robin Algayres</li>
<li>for: 这个研究的目的是提出一个可以在不同的模型大小下选择最佳的决策模组，以便在不同的内存和硬件环境下进行自动语音识别（ASR）。</li>
<li>methods: 作者使用了两个不同大小的 Whisper 模型，并将它们联合使用以构建一个决策模组。他们还使用了一些计算效率的技巧来降低决策模组的计算成本。</li>
<li>results: 作者的实验结果显示，使用这个决策模组可以实现substantial的计算成本减少，同时保持transcription的性能水平。具体来说，在两个 Whisper 模型中，使用决策模组可以降低了模型的计算成本，并且对于大多数的测试数据进行了好的调整。<details>
<summary>Abstract</summary>
Recent progress in Automatic Speech Recognition (ASR) has been coupled with a substantial increase in the model sizes, which may now contain billions of parameters, leading to slow inferences even with adapted hardware. In this context, several ASR models exist in various sizes, with different inference costs leading to different performance levels. Based on the observation that smaller models perform optimally on large parts of testing corpora, we propose to train a decision module, that would allow, given an audio sample, to use the smallest sufficient model leading to a good transcription. We apply our approach to two Whisper models with different sizes. By keeping the decision process computationally efficient, we build a decision module that allows substantial computational savings with reduced performance drops.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Discovering-the-Interpretability-Performance-Pareto-Front-of-Decision-Trees-with-Dynamic-Programming"><a href="#Discovering-the-Interpretability-Performance-Pareto-Front-of-Decision-Trees-with-Dynamic-Programming" class="headerlink" title="Discovering the Interpretability-Performance Pareto Front of Decision Trees with Dynamic Programming"></a>Discovering the Interpretability-Performance Pareto Front of Decision Trees with Dynamic Programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12701">http://arxiv.org/abs/2309.12701</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hector Kohler, Riad Akrour, Philippe Preux</li>
<li>for: 本文提出了一种新的Markov Decision Problem（MDP）形式，用于找到最佳决策树。</li>
<li>methods: 该方法使用了一个单一的动态计划来计算多种解释性-性能质量Front的优化决策树。</li>
<li>results: 实验表明，该方法与当前状态的算法相当于的精度和运行时间，同时返回了一组决策树，用于用户选择最适合其需求的解释性-性能质量Front。<details>
<summary>Abstract</summary>
Decision trees are known to be intrinsically interpretable as they can be inspected and interpreted by humans. Furthermore, recent hardware advances have rekindled an interest for optimal decision tree algorithms, that produce more accurate trees than the usual greedy approaches. However, these optimal algorithms return a single tree optimizing a hand defined interpretability-performance trade-off, obtained by specifying a maximum number of decision nodes, giving no further insights about the quality of this trade-off. In this paper, we propose a new Markov Decision Problem (MDP) formulation for finding optimal decision trees. The main interest of this formulation is that we can compute the optimal decision trees for several interpretability-performance trade-offs by solving a single dynamic program, letting the user choose a posteriori the tree that best suits their needs. Empirically, we show that our method is competitive with state-of-the-art algorithms in terms of accuracy and runtime while returning a whole set of trees on the interpretability-performance Pareto front.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose a new Markov Decision Problem (MDP) formulation for finding optimal decision trees. Our approach allows us to compute the optimal decision trees for multiple interpretability-performance trade-offs by solving a single dynamic program. This enables the user to choose the tree that best suits their needs after the fact. Empirical results show that our method is competitive with state-of-the-art algorithms in terms of accuracy and runtime, while providing a set of trees on the interpretability-performance Pareto front.
</details></li>
</ul>
<hr>
<h2 id="Recurrent-Temporal-Revision-Graph-Networks"><a href="#Recurrent-Temporal-Revision-Graph-Networks" class="headerlink" title="Recurrent Temporal Revision Graph Networks"></a>Recurrent Temporal Revision Graph Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12694">http://arxiv.org/abs/2309.12694</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yizhou Chen, Anxiang Zeng, Guangda Huzhang, Qingtao Yu, Kerui Zhang, Cao Yuanpeng, Kangle Wu, Han Yu, Zhiming Zhou</li>
<li>for: 本研究旨在提供一种更准确地模型 temporal graph 的方法，具体来说是一种基于 recurrent neural network (RNN) 的 temporal neighbor aggregation 方法，以便更好地捕捉 temporal graph 中 node 之间的关系。</li>
<li>methods: 本研究使用 RNN  WITH node-wise hidden states 来集成所有历史邻居信息，从而提供更完整的邻居信息。这种方法可以在实际应用中提高 averaged precision 约 9.6%  compared to existing methods。</li>
<li>results: 本研究的实际应用result 显示，使用本研究提出的方法可以在 Ecommerce  dataset 中提高 averaged precision 约 9.6%  compared to existing methods。这表明本研究的方法可以更好地捕捉 temporal graph 中 node 之间的关系，从而提高模型的准确性。<details>
<summary>Abstract</summary>
Temporal graphs offer more accurate modeling of many real-world scenarios than static graphs. However, neighbor aggregation, a critical building block of graph networks, for temporal graphs, is currently straightforwardly extended from that of static graphs. It can be computationally expensive when involving all historical neighbors during such aggregation. In practice, typically only a subset of the most recent neighbors are involved. However, such subsampling leads to incomplete and biased neighbor information. To address this limitation, we propose a novel framework for temporal neighbor aggregation that uses the recurrent neural network with node-wise hidden states to integrate information from all historical neighbors for each node to acquire the complete neighbor information. We demonstrate the superior theoretical expressiveness of the proposed framework as well as its state-of-the-art performance in real-world applications. Notably, it achieves a significant +9.6% improvement on averaged precision in a real-world Ecommerce dataset over existing methods on 2-layer models.
</details>
<details>
<summary>摘要</summary>
时间图表提供更加准确地模型多种实际场景 than static graphs. However, temporal graph neighbor aggregation, a critical component of graph networks, is currently extended straightforwardly from static graphs. This can be computationally expensive when considering all historical neighbors during aggregation. In practice, only a subset of the most recent neighbors are typically involved, but such subsampling leads to incomplete and biased neighbor information. To address this limitation, we propose a novel framework for temporal neighbor aggregation that uses recurrent neural networks with node-wise hidden states to integrate information from all historical neighbors for each node to obtain complete neighbor information. We demonstrate the superior theoretical expressiveness of the proposed framework as well as its state-of-the-art performance in real-world applications. Notably, it achieves a significant +9.6% improvement in averaged precision over existing methods on 2-layer models in a real-world Ecommerce dataset.
</details></li>
</ul>
<hr>
<h2 id="OneNet-Enhancing-Time-Series-Forecasting-Models-under-Concept-Drift-by-Online-Ensembling"><a href="#OneNet-Enhancing-Time-Series-Forecasting-Models-under-Concept-Drift-by-Online-Ensembling" class="headerlink" title="OneNet: Enhancing Time Series Forecasting Models under Concept Drift by Online Ensembling"></a>OneNet: Enhancing Time Series Forecasting Models under Concept Drift by Online Ensembling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12659">http://arxiv.org/abs/2309.12659</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yfzhang114/onenet">https://github.com/yfzhang114/onenet</a></li>
<li>paper_authors: Yi-Fan Zhang, Qingsong Wen, Xue Wang, Weiqi Chen, Liang Sun, Zhang Zhang, Liang Wang, Rong Jin, Tieniu Tan</li>
<li>For: 本研究旨在提出一种能够高效地更新时间序列预测模型，以Addressing the concept drifting problem。* Methods: 本文提出了一种基于online convex programming框架的强化学习方法，可以动态地更新和组合两个模型，其中一个模型专注于时间维度上的关系，另一个模型则是跨变量关系。* Results: 实验结果显示，OneNet可以在线预测错误下降超过50%，至比State-Of-The-Art方法更高。<details>
<summary>Abstract</summary>
Online updating of time series forecasting models aims to address the concept drifting problem by efficiently updating forecasting models based on streaming data. Many algorithms are designed for online time series forecasting, with some exploiting cross-variable dependency while others assume independence among variables. Given every data assumption has its own pros and cons in online time series modeling, we propose \textbf{On}line \textbf{e}nsembling \textbf{Net}work (OneNet). It dynamically updates and combines two models, with one focusing on modeling the dependency across the time dimension and the other on cross-variate dependency. Our method incorporates a reinforcement learning-based approach into the traditional online convex programming framework, allowing for the linear combination of the two models with dynamically adjusted weights. OneNet addresses the main shortcoming of classical online learning methods that tend to be slow in adapting to the concept drift. Empirical results show that OneNet reduces online forecasting error by more than $\mathbf{50\%}$ compared to the State-Of-The-Art (SOTA) method. The code is available at \url{https://github.com/yfzhang114/OneNet}.
</details>
<details>
<summary>摘要</summary>
在线更新时间序列预测模型目的是解决概念漂移问题，通过基于流入数据的高效更新预测模型。许多算法已经为在线时间序列预测设计，其中一些利用时间维度之间的依赖关系，而其他们假设变量之间是独立的。每个数据假设都有其自己的优缺点，在在线时间序列预测中。我们提出了《Online Ensembling Network（OneNet）》，它在实时更新和组合两个模型，其中一个专门关注时间维度之间的依赖关系，另一个则关注变量之间的交叉依赖关系。我们的方法将经验学学习基于的逻辑添加到传统的在线凸programming框架中，允许在线动态调整模型之间的线性组合。OneNet可以快速适应概念漂移，并且实际结果表明，与现状技术（SOTA）方法相比，OneNet可以降低在线预测错误率高于50%。代码可以在 \url{https://github.com/yfzhang114/OneNet} 中找到。
</details></li>
</ul>
<hr>
<h2 id="Neural-Operator-Variational-Inference-based-on-Regularized-Stein-Discrepancy-for-Deep-Gaussian-Processes"><a href="#Neural-Operator-Variational-Inference-based-on-Regularized-Stein-Discrepancy-for-Deep-Gaussian-Processes" class="headerlink" title="Neural Operator Variational Inference based on Regularized Stein Discrepancy for Deep Gaussian Processes"></a>Neural Operator Variational Inference based on Regularized Stein Discrepancy for Deep Gaussian Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12658">http://arxiv.org/abs/2309.12658</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jian Xu, Shian Du, Junmei Yang, Qianli Ma, Delu Zeng</li>
<li>for: 这个研究旨在提出一种基于神经网络的 Variational Inference 方法，用于深度 Gaussian Process (DGP) 模型中的 Bayesian 推断。</li>
<li>methods: 方法使用神经网络生成器，实现了对真 posterior 的过程独立推断，并使用 Monte Carlo 估计和抽样数据点估计技术来解决问题。</li>
<li>results: 实验结果显示，提出的方法可以实现高精度和高速度的推断，并在许多数据集上实现了比 SOTA Gaussian process 方法更高的分类精度。此外，方法可以 theoretically 控制预测误差，并在各种数据集上展示了优异的表现。<details>
<summary>Abstract</summary>
Deep Gaussian Process (DGP) models offer a powerful nonparametric approach for Bayesian inference, but exact inference is typically intractable, motivating the use of various approximations. However, existing approaches, such as mean-field Gaussian assumptions, limit the expressiveness and efficacy of DGP models, while stochastic approximation can be computationally expensive. To tackle these challenges, we introduce Neural Operator Variational Inference (NOVI) for Deep Gaussian Processes. NOVI uses a neural generator to obtain a sampler and minimizes the Regularized Stein Discrepancy in L2 space between the generated distribution and true posterior. We solve the minimax problem using Monte Carlo estimation and subsampling stochastic optimization techniques. We demonstrate that the bias introduced by our method can be controlled by multiplying the Fisher divergence with a constant, which leads to robust error control and ensures the stability and precision of the algorithm. Our experiments on datasets ranging from hundreds to tens of thousands demonstrate the effectiveness and the faster convergence rate of the proposed method. We achieve a classification accuracy of 93.56 on the CIFAR10 dataset, outperforming SOTA Gaussian process methods. Furthermore, our method guarantees theoretically controlled prediction error for DGP models and demonstrates remarkable performance on various datasets. We are optimistic that NOVI has the potential to enhance the performance of deep Bayesian nonparametric models and could have significant implications for various practical applications
</details>
<details>
<summary>摘要</summary>
深度泊松过程（DGP）模型提供了一种强大的非参数方法 для bayesian推理，但确切的推理通常是不可能的，这导致了不同的 aproximation 被使用。然而，现有的方法，如 Gaussian 假设，限制了 DGP 模型的表达能力和有效性，而随机approximation 可能会是 computationally  expensive。为了解决这些挑战，我们引入了 Neural Operator Variational Inference（NOVI） для Deep Gaussian Processes。NOVI 使用神经网络生成器来获取一个采样器，并将 Regularized Stein Discrepancy 在 L2 空间中减少到真 posterior 和生成的分布之间的差异。我们使用 Monte Carlo 估计和抽样化优化技术来解决最小最大问题。我们发现，我们的方法中引入的偏差可以通过多余的 Fisher 异同平方控制，从而保证算法的稳定性和精度。我们的实验结果表明，我们的方法可以在数据集规模从百万到万个数据点之间进行效果地训练，并且在 CIFAR10 数据集上达到了 93.56% 的分类精度，超过了现有的 Gaussian process 方法。此外，我们的方法可以 theoretically 控制 DGP 模型的预测错误，并在不同的数据集上显示出惊人的性能。我们认为 NOVI 有可能提高深度 Bayesian 非 Parametric 模型的性能，并可能在各种实际应用中具有重要意义。
</details></li>
</ul>
<hr>
<h2 id="Sequential-Action-Induced-Invariant-Representation-for-Reinforcement-Learning"><a href="#Sequential-Action-Induced-Invariant-Representation-for-Reinforcement-Learning" class="headerlink" title="Sequential Action-Induced Invariant Representation for Reinforcement Learning"></a>Sequential Action-Induced Invariant Representation for Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12628">http://arxiv.org/abs/2309.12628</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dmu-xmu/sar">https://github.com/dmu-xmu/sar</a></li>
<li>paper_authors: Dayang Liang, Qihang Chen, Yunlong Liu</li>
<li>for: 提高visual reinforcement learning中 task-relevant state representation的学习精度，并在受到视觉干扰的环境中实现更好的性能。</li>
<li>methods: 基于bisimulation metric、prediction、contrast和重建等方法，提出Sequential Action–induced invariant Representation（SAR）方法，通过控制信号驱动encoder的优化，使代理人能够学习对干扰免疫的表示。</li>
<li>results: 在DeepMind Control suite任务上实现了最佳baseline的性能，并在实际的CARLA自动驾驶中证明了方法的有效性。 Code和示例视频可以在<a target="_blank" rel="noopener" href="https://github.com/DMU-XMU/SAR.git%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/DMU-XMU/SAR.git中找到。</a><details>
<summary>Abstract</summary>
How to accurately learn task-relevant state representations from high-dimensional observations with visual distractions is a realistic and challenging problem in visual reinforcement learning. Recently, unsupervised representation learning methods based on bisimulation metrics, contrast, prediction, and reconstruction have shown the ability for task-relevant information extraction. However, due to the lack of appropriate mechanisms for the extraction of task information in the prediction, contrast, and reconstruction-related approaches and the limitations of bisimulation-related methods in domains with sparse rewards, it is still difficult for these methods to be effectively extended to environments with distractions. To alleviate these problems, in the paper, the action sequences, which contain task-intensive signals, are incorporated into representation learning. Specifically, we propose a Sequential Action--induced invariant Representation (SAR) method, in which the encoder is optimized by an auxiliary learner to only preserve the components that follow the control signals of sequential actions, so the agent can be induced to learn the robust representation against distractions. We conduct extensive experiments on the DeepMind Control suite tasks with distractions while achieving the best performance over strong baselines. We also demonstrate the effectiveness of our method at disregarding task-irrelevant information by deploying SAR to real-world CARLA-based autonomous driving with natural distractions. Finally, we provide the analysis results of generalization drawn from the generalization decay and t-SNE visualization. Code and demo videos are available at https://github.com/DMU-XMU/SAR.git.
</details>
<details>
<summary>摘要</summary>
如何准确地从高维观察数据中提取任务相关的状态表示是现实和挑战性的问题在视觉回归学中。在最近的无监督表示学方法基于 bisimulation 度量、对比、预测和重构方面，已经显示出提取任务相关信息的能力。但由于预测、对比和重构相关的方法中缺乏任务信息抽取的适当机制，以及 bisimulation 度量相关的方法在射频奖励下的局限性，使得这些方法在环境噪音中仍然具有困难。为解决这些问题，在本文中，我们提出了一种Sequential Action--induced invariant Representation（SAR）方法，其中扩展器是通过辅助学习器优化，以便只保留遵循控制信号的序列动作中的组件，以使代理人能够学习免斥噪音的Robust表示。我们在 DeepMind Control suite任务上进行了广泛的实验，并实现了强基eline的最高表现。我们还证明了我们的方法可以忽略任务无关的信息，通过将 SAR 应用于实际的 CARLA 基于自动驾驶中的自然噪音。最后，我们提供了一些总结和分析结果，包括通过总结衰减和 t-SNE 视觉化来证明代理人学习的一致性。代码和示例视频可以在 <https://github.com/DMU-XMU/SAR.git> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Data-driven-Preference-Learning-Methods-for-Multiple-Criteria-Sorting-with-Temporal-Criteria"><a href="#Data-driven-Preference-Learning-Methods-for-Multiple-Criteria-Sorting-with-Temporal-Criteria" class="headerlink" title="Data-driven Preference Learning Methods for Multiple Criteria Sorting with Temporal Criteria"></a>Data-driven Preference Learning Methods for Multiple Criteria Sorting with Temporal Criteria</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12620">http://arxiv.org/abs/2309.12620</a></li>
<li>repo_url: None</li>
<li>paper_authors: Li Yijun, Guo Mengzhuo, Zhang Qingpeng</li>
<li>for: 本研究旨在提出新的偏好学习方法，用于多 criterion 排序问题中的时间序列数据处理。</li>
<li>methods: 本研究使用了一种固定时间折扣因子的几何 quadratic programming 模型，以及一种 ensemble learning 算法，可以将多个可能较弱的优化器的输出集成起来，并通过并行计算进行高效地执行。此外，本研究还提出了一种新的幂等 Recurrent Neural Network (mRNN)，可以捕捉时间序列中的偏好动态，并保持多重排序问题中的关键性质，如偏好幂等性、偏好独立性和自然排序。</li>
<li>results: 对于 synthetic 数据和一个实际案例（关于分类用户在 mobil 游戏中的历史行为序列），实验结果表明，提出的模型在与基准方法（包括机器学习、深度学习和传统多 criterion 排序方法）进行比较时，表现出了显著的性能改进。<details>
<summary>Abstract</summary>
The advent of predictive methodologies has catalyzed the emergence of data-driven decision support across various domains. However, developing models capable of effectively handling input time series data presents an enduring challenge. This study presents novel preference learning approaches to multiple criteria sorting problems in the presence of temporal criteria. We first formulate a convex quadratic programming model characterized by fixed time discount factors, operating within a regularization framework. Additionally, we propose an ensemble learning algorithm designed to consolidate the outputs of multiple, potentially weaker, optimizers, a process executed efficiently through parallel computation. To enhance scalability and accommodate learnable time discount factors, we introduce a novel monotonic Recurrent Neural Network (mRNN). It is designed to capture the evolving dynamics of preferences over time while upholding critical properties inherent to MCS problems, including criteria monotonicity, preference independence, and the natural ordering of classes. The proposed mRNN can describe the preference dynamics by depicting marginal value functions and personalized time discount factors along with time, effectively amalgamating the interpretability of traditional MCS methods with the predictive potential offered by deep preference learning models. Comprehensive assessments of the proposed models are conducted, encompassing synthetic data scenarios and a real-case study centered on classifying valuable users within a mobile gaming app based on their historical in-app behavioral sequences. Empirical findings underscore the notable performance improvements achieved by the proposed models when compared to a spectrum of baseline methods, spanning machine learning, deep learning, and conventional multiple criteria sorting approaches.
</details>
<details>
<summary>摘要</summary>
“预测方法的出现刺激了不同领域的数据驱动决策。然而，处理时间序列资料的模型建立仍然是一个持续的挑战。本研究提出了一些新的偏好学习方法，用于多个条件中的排序问题，包括时间条件。我们首先建立了一个固定时间折冲因子的对称quadratic programming模型，并在一个调整框架下进行运算。此外，我们提出了一个ensemble学习算法，用于结合多个、可能的弱来调整器的output，这个过程通过平行计算进行高效执行。为了增强可扩展性和可学习时间折冲因子，我们引入了一个新的对称复环神经网络（mRNN）。这个mRNN可以捕捉时间的演进 Dynamics 的偏好，同时维持多个条件问题的核心性质，包括条件单调性、偏好独立性和时间条件下的自然顺序。提出的mRNN可以描述偏好动态，包括时间条件下的贡献值函数和对个人时间折冲因子的描述，实现了传统多个条件排序方法的解释性和深度偏好学习模型的预测能力。实验结果显示，提出的模型在 synthetic 数据enario 和一个实际的移动游戏APP用户评分案例中均表现出色，与一系列基准方法相比，包括机器学习、深度学习和传统多个条件排序方法。”
</details></li>
</ul>
<hr>
<h2 id="Zero-Regret-Performative-Prediction-Under-Inequality-Constraints"><a href="#Zero-Regret-Performative-Prediction-Under-Inequality-Constraints" class="headerlink" title="Zero-Regret Performative Prediction Under Inequality Constraints"></a>Zero-Regret Performative Prediction Under Inequality Constraints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12618">http://arxiv.org/abs/2309.12618</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenjing Yan, Xuanyu Cao</li>
<li>for: 本文研究了受约束的performative预测问题，即预测结果会影响未来数据分布的问题。</li>
<li>methods: 本文提出了一种robust预测框架，可以在约束条件下实现高效的预测。此外，本文还提出了一种适应预测算法，可以在各种场景下实现优化的预测。</li>
<li>results: 本文的分析表明，提出的适应预测算法可以在约束条件下实现$\ca{O}(\sqrt{T})$的违规和约束违宪，使用只有$\sqrt{T} + 2T$个样本。这是首次对performative预测问题的优化问题进行分析和研究。<details>
<summary>Abstract</summary>
Performative prediction is a recently proposed framework where predictions guide decision-making and hence influence future data distributions. Such performative phenomena are ubiquitous in various areas, such as transportation, finance, public policy, and recommendation systems. To date, work on performative prediction has only focused on unconstrained scenarios, neglecting the fact that many real-world learning problems are subject to constraints. This paper bridges this gap by studying performative prediction under inequality constraints. Unlike most existing work that provides only performative stable points, we aim to find the optimal solutions. Anticipating performative gradients is a challenging task, due to the agnostic performative effect on data distributions. To address this issue, we first develop a robust primal-dual framework that requires only approximate gradients up to a certain accuracy, yet delivers the same order of performance as the stochastic primal-dual algorithm without performativity. Based on this framework, we then propose an adaptive primal-dual algorithm for location families. Our analysis demonstrates that the proposed adaptive primal-dual algorithm attains $\ca{O}(\sqrt{T})$ regret and constraint violations, using only $\sqrt{T} + 2T$ samples, where $T$ is the time horizon. To our best knowledge, this is the first study and analysis on the optimality of the performative prediction problem under inequality constraints. Finally, we validate the effectiveness of our algorithm and theoretical results through numerical simulations.
</details>
<details>
<summary>摘要</summary>
Performative 预测是一种最近提出的框架，在预测导向决策的过程中，预测结果会影响未来数据分布。这种 performative 现象在交通、金融、公共政策和推荐系统等领域都是非常普遍的。然而，现有的工作都是在不受限制的情况下进行预测，忽略了现实世界学习问题往往受到限制。这篇论文尝试填补这个空白，通过研究 performative 预测下 inequality 约束来解决这个问题。不同于大多数现有的工作，我们不仅提供 performative 稳定点，而是寻找最佳解决方案。预测 performative Gradient 是一项非常困难的任务，因为 performative 对数据分布的影响是agnostic的。为 Addressing this issue, we first develop a robust primal-dual framework that requires only approximate gradients up to a certain accuracy, yet delivers the same order of performance as the stochastic primal-dual algorithm without performativity. Based on this framework, we then propose an adaptive primal-dual algorithm for location families. Our analysis demonstrates that the proposed adaptive primal-dual algorithm attains $\ca{O}(\sqrt{T})$ regret and constraint violations, using only $\sqrt{T} + 2T$ samples, where $T$ is the time horizon. To our best knowledge, this is the first study and analysis on the optimality of the performative prediction problem under inequality constraints. Finally, we validate the effectiveness of our algorithm and theoretical results through numerical simulations.
</details></li>
</ul>
<hr>
<h2 id="ARRQP-Anomaly-Resilient-Real-time-QoS-Prediction-Framework-with-Graph-Convolution"><a href="#ARRQP-Anomaly-Resilient-Real-time-QoS-Prediction-Framework-with-Graph-Convolution" class="headerlink" title="ARRQP: Anomaly Resilient Real-time QoS Prediction Framework with Graph Convolution"></a>ARRQP: Anomaly Resilient Real-time QoS Prediction Framework with Graph Convolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.02269">http://arxiv.org/abs/2310.02269</a></li>
<li>repo_url: None</li>
<li>paper_authors: Suraj Kumar, Soumi Chattopadhyay<br>for: 这种研究旨在提高现代服务套件架构中的质量服务（QoS）预测精度，以便用户可以根据预测结果做出了 Informed 决策。methods: 这种预测框架（名为 ARRQP）利用图 convolution 技术捕捉用户和服务之间的复杂关系和依赖关系，即使数据是有限或缺失的。 ARRQP 集成了上下文信息和协同信息，以获得用户-服务交互的全面理解。 results: 对 WS-DREAM 测试集的实验表明，这种预测框架可以准确地预测 QoS，并且在各种异常情况下保持高度的稳定性。<details>
<summary>Abstract</summary>
In the realm of modern service-oriented architecture, ensuring Quality of Service (QoS) is of paramount importance. The ability to predict QoS values in advance empowers users to make informed decisions. However, achieving accurate QoS predictions in the presence of various issues and anomalies, including outliers, data sparsity, grey-sheep instances, and cold-start scenarios, remains a challenge. Current state-of-the-art methods often fall short when addressing these issues simultaneously, resulting in performance degradation. In this paper, we introduce a real-time QoS prediction framework (called ARRQP) with a specific emphasis on improving resilience to anomalies in the data. ARRQP utilizes the power of graph convolution techniques to capture intricate relationships and dependencies among users and services, even when the data is limited or sparse. ARRQP integrates both contextual information and collaborative insights, enabling a comprehensive understanding of user-service interactions. By utilizing robust loss functions, ARRQP effectively reduces the impact of outliers during the model training. Additionally, we introduce a sparsity-resilient grey-sheep detection method, which is subsequently treated separately for QoS prediction. Furthermore, we address the cold-start problem by emphasizing contextual features over collaborative features. Experimental results on the benchmark WS-DREAM dataset demonstrate the framework's effectiveness in achieving accurate and timely QoS predictions.
</details>
<details>
<summary>摘要</summary>
在现代服务套件架构中，保证服务质量（QoS）的重要性不言而喻。预测QoS值的能力使用户做出了 Informed 决策。然而，在面临各种问题和异常情况，包括异常值、数据稀缺、灰羊实例和冷启动场景时，实现准确的QoS预测仍然是一大挑战。当前的状态艺术方法经常在同时处理这些问题时表现不佳，导致性能下降。在这篇论文中，我们提出了一个实时QoS预测框架（叫做ARRQP），强调改进数据中异常现象的抗逆性。ARRQP利用图 convolution 技术捕捉用户和服务之间的复杂关系和依赖关系，即使数据稀缺或异常。ARRQP结合了上下文信息和协同知识，使得用户-服务交互的全面理解。通过使用robust 损失函数，ARRQP减少了模型训练中异常值的影响。此外，我们还提出了稀缺灰羊检测方法，并将其与QoS预测分开处理。此外，我们解决冷启动问题，强调上下文特征而不是协同特征。实验结果表明，ARRQP在WS-DREAM 数据集上实现了准确和时间性的QoS预测。
</details></li>
</ul>
<hr>
<h2 id="Multiply-Robust-Federated-Estimation-of-Targeted-Average-Treatment-Effects"><a href="#Multiply-Robust-Federated-Estimation-of-Targeted-Average-Treatment-Effects" class="headerlink" title="Multiply Robust Federated Estimation of Targeted Average Treatment Effects"></a>Multiply Robust Federated Estimation of Targeted Average Treatment Effects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12600">http://arxiv.org/abs/2309.12600</a></li>
<li>repo_url: None</li>
<li>paper_authors: Larry Han, Zhu Shen, Jose Zubizarreta</li>
<li>for: 这 paper 是为了 Derive valid causal inferences for a target population using multi-site data.</li>
<li>methods: 这 paper 使用了一种 novel federated approach, 包括 covariate shift and covariate mismatch between sites 的 adjustment, 以及 transfer learning 来 estimate ensemble weights to combine information from source sites.</li>
<li>results: 这 paper 的研究结果表明，这种方法在不同的 scenario 下具有高效和可靠的特点，并且在 finite sample 上有效性和稳定性比 existed approach 更高.<details>
<summary>Abstract</summary>
Federated or multi-site studies have distinct advantages over single-site studies, including increased generalizability, the ability to study underrepresented populations, and the opportunity to study rare exposures and outcomes. However, these studies are challenging due to the need to preserve the privacy of each individual's data and the heterogeneity in their covariate distributions. We propose a novel federated approach to derive valid causal inferences for a target population using multi-site data. We adjust for covariate shift and covariate mismatch between sites by developing multiply-robust and privacy-preserving nuisance function estimation. Our methodology incorporates transfer learning to estimate ensemble weights to combine information from source sites. We show that these learned weights are efficient and optimal under different scenarios. We showcase the finite sample advantages of our approach in terms of efficiency and robustness compared to existing approaches.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese translation:多站或联合研究有许多优点，包括增加了一般化性、研究少数群体和罕见的暴露和结果。然而，这些研究具有保护每个个体数据隐私和不同站点的 covariate 分布异常性的挑战。我们提出了一种新的联邦方法，以 derivation 适用于目标人口的有效 causal inference。我们对 covariate shift 和 covariate mismatch 进行了修正，并通过开发多重可靠和隐私保护的干扰函数估计。我们的方法包括使用转移学习来估计ensemble weights，将多个源站的信息组合。我们显示了这些学习到的权重是有效的和优化的在不同的场景下。我们还展示了我们的方法在规模和稳定性方面的较好的 finite sample 优势，与现有方法相比。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. The Traditional Chinese version is also available upon request.
</details></li>
</ul>
<hr>
<h2 id="Learning-algorithms-for-identification-of-whisky-using-portable-Raman-spectroscopy"><a href="#Learning-algorithms-for-identification-of-whisky-using-portable-Raman-spectroscopy" class="headerlink" title="Learning algorithms for identification of whisky using portable Raman spectroscopy"></a>Learning algorithms for identification of whisky using portable Raman spectroscopy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13087">http://arxiv.org/abs/2309.13087</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kwang Jun Lee, Alexander C. Trowbridge, Graham D. Bruce, George O. Dwapanyin, Kylie R. Dunning, Kishan Dholakia, Erik P. Schartner</li>
<li>for: 鉴定高值饮料的可靠性是一个日益重要的领域，因为问题如品牌替换（即虚假产品）和质量控制对行业是关键的。</li>
<li>methods: 我们检查了一系列机器学习算法，并将其直接与可携带式拉曼谱仪device进行了交互，以 both identify和 characterize commercial whisky samples的 ethanol&#x2F;methanol浓度。</li>
<li>results: 我们示出了机器学习模型可以在二十八个商业样本中实现超过99%的品牌认定率。此外，我们还使用了同样的样本和算法来量化 ethanol浓度，以及在杂入 whisky 样本中测量 methanol 水平。我们的机器学习技术然后与通过瓶装置进行spectral analysis和标识，不需要样本从原始容器中抽取，这表明了这种方法在检测假冒或杂入饮料和其他高值液体样本中的实际潜力。<details>
<summary>Abstract</summary>
Reliable identification of high-value products such as whisky is an increasingly important area, as issues such as brand substitution (i.e. fraudulent products) and quality control are critical to the industry. We have examined a range of machine learning algorithms and interfaced them directly with a portable Raman spectroscopy device to both identify and characterize the ethanol/methanol concentrations of commercial whisky samples. We demonstrate that machine learning models can achieve over 99% accuracy in brand identification across twenty-eight commercial samples. To demonstrate the flexibility of this approach we utilised the same samples and algorithms to quantify ethanol concentrations, as well as measuring methanol levels in spiked whisky samples. Our machine learning techniques are then combined with a through-the-bottle method to perform spectral analysis and identification without requiring the sample to be decanted from the original container, showing the practical potential of this approach to the detection of counterfeit or adulterated spirits and other high value liquid samples.
</details>
<details>
<summary>摘要</summary>
stable 识别高值产品，如威士忌，在当今越来越重要，因为问题如品牌替换（即假冒产品）和质量控制是行业关键。我们已经审查了一系列机器学习算法，并直接与可携带式拉曼谱仪器集成以识别和Characterize商业威士忌样本中的丙醇/甲醇浓度。我们示出了机器学习模型可以在28个商业样本中达到99%以上的品牌识别率。为了 demonstarte 这种方法的灵活性，我们使用了相同的样本和算法来量化丙醇浓度，以及测量杂入威士忌样本中的甲醇含量。我们的机器学习技术然后与通过瓶子方法进行spectral analysis和识别，无需将样本从原始容器中抽取，显示了这种方法在检测假冒或杂入饮料和其他高值液体样本中的实际潜力。
</details></li>
</ul>
<hr>
<h2 id="Sampling-Frequency-Independent-Universal-Sound-Separation"><a href="#Sampling-Frequency-Independent-Universal-Sound-Separation" class="headerlink" title="Sampling-Frequency-Independent Universal Sound Separation"></a>Sampling-Frequency-Independent Universal Sound Separation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12581">http://arxiv.org/abs/2309.12581</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tomohiko Nakamura, Kohei Yatabe</li>
<li>for: 这个论文提出了一种能够处理未经训练的采样频率（SF）的通用声音分离（USS）方法，用于分离不同类型的源 signal。</li>
<li>methods: 该方法使用了我们之前提出的SF独立（SFI）扩展，使用SFI convolutional layers来处理不同SF。</li>
<li>results: 实验表明，信号重采样可能会降低USS性能，而我们提出的方法在不同SF下表现更一致。<details>
<summary>Abstract</summary>
This paper proposes a universal sound separation (USS) method capable of handling untrained sampling frequencies (SFs). The USS aims at separating arbitrary sources of different types and can be the key technique to realize a source separator that can be universally used as a preprocessor for any downstream tasks. To realize a universal source separator, there are two essential properties: universalities with respect to source types and recording conditions. The former property has been studied in the USS literature, which has greatly increased the number of source types that can be handled by a single neural network. However, the latter property (e.g., SF) has received less attention despite its necessity. Since the SF varies widely depending on the downstream tasks, the universal source separator must handle a wide variety of SFs. In this paper, to encompass the two properties, we propose an SF-independent (SFI) extension of a computationally efficient USS network, SuDoRM-RF. The proposed network uses our previously proposed SFI convolutional layers, which can handle various SFs by generating convolutional kernels in accordance with an input SF. Experiments show that signal resampling can degrade the USS performance and the proposed method works more consistently than signal-resampling-based methods for various SFs.
</details>
<details>
<summary>摘要</summary>
To address this challenge, the proposed method extends a computationally efficient USS network, SuDoRM-RF, with an SF-independent (SFI) extension. The proposed network uses SFI convolutional layers that can handle various SFs by generating convolutional kernels in accordance with the input SF. This allows the network to maintain its performance across different SFs. Experimental results show that signal resampling can degrade the USS performance, and the proposed method outperforms signal-resampling-based methods for various SFs.In simplified Chinese, the text would be:这篇论文提出了一种能处理不受训练 sampling frequency (SF) 的通用声音分离 (USS) 方法。USS 目标是分离不同类型的原始源，并且可以是下游任务的键技术。为实现这一目标，需要两个关键属性：对于源类型和记录条件的通用性。前者已经在 USS 文献中得到了大量的研究，但是后者（即 SF）尚未得到了 suficient 的关注，尽管它的重要性。由于 SF 在下游任务中变化广泛，通用的源分离器必须能处理多种 SF。为此，我们提议一种 SF-独立 (SFI) 的扩展，使用我们之前提出的 SFI 卷积层，可以根据输入 SF 生成卷积 kernel。实验显示，signal resampling 可能会降低 USS 性能，而我们提议的方法在不同 SF 下表现更稳定。
</details></li>
</ul>
<hr>
<h2 id="SPION-Layer-Wise-Sparse-Training-of-Transformer-via-Convolutional-Flood-Filling"><a href="#SPION-Layer-Wise-Sparse-Training-of-Transformer-via-Convolutional-Flood-Filling" class="headerlink" title="SPION: Layer-Wise Sparse Training of Transformer via Convolutional Flood Filling"></a>SPION: Layer-Wise Sparse Training of Transformer via Convolutional Flood Filling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12578">http://arxiv.org/abs/2309.12578</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bokyeong Yoon, Yoonsang Han, Gordon Euhyun Moon</li>
<li>for: 这篇论文旨在提高Transformer模型的训练效率和内存压缩，以提高模型的运算效率和评估质量。</li>
<li>methods: 本论文提出了一种新的对Transformer模型进行实体化的方法，使用了对于层次的滤波器和淹水填充方法，以提高对于注意力操作的实体化效率。</li>
<li>results: 本论文的实验结果显示，使用了本方法可以实现Transformer模型的训练时间和内存压缩，并且可以维持评估质量。具体来说，本论文可以在GPU上实现快速的实体化执行，并且可以比起现有的紧缩Transformer模型实现3.08倍的速度提升，同时保持评估质量。<details>
<summary>Abstract</summary>
Sparsifying the Transformer has garnered considerable interest, as training the Transformer is very computationally demanding. Prior efforts to sparsify the Transformer have either used a fixed pattern or data-driven approach to reduce the number of operations involving the computation of multi-head attention, which is the main bottleneck of the Transformer. However, existing methods suffer from inevitable problems, such as the potential loss of essential sequence features due to the uniform fixed pattern applied across all layers, and an increase in the model size resulting from the use of additional parameters to learn sparsity patterns in attention operations. In this paper, we propose a novel sparsification scheme for the Transformer that integrates convolution filters and the flood filling method to efficiently capture the layer-wise sparse pattern in attention operations. Our sparsification approach reduces the computational complexity and memory footprint of the Transformer during training. Efficient implementations of the layer-wise sparsified attention algorithm on GPUs are developed, demonstrating a new SPION that achieves up to 3.08X speedup over existing state-of-the-art sparse Transformer models, with better evaluation quality.
</details>
<details>
<summary>摘要</summary>
减少Transformer的计算复杂性得到了广泛关注，因为训练Transformer很计算昂贵。先前的减少方法包括使用固定模式或数据驱动方法来减少多头注意力计算的数量，但现有方法受到不可避免的问题，如所有层都应用 uniform 固定模式，导致可能丢失重要的序列特征，并且使用更多参数来学习注意力操作的缺省模式。在这篇论文中，我们提出了一种新的减少方案，将 convolution 筛选器和淹水填充方法结合使用，以高效地捕捉层 wise  sparse 模式在注意力操作中。我们的减少方法可以在训练过程中降低Transformer的计算复杂性和内存占用。我们实现了层 wise 减少的注意力算法在GPU上，并达到了3.08倍的速度提升，与评价质量相对较好的现有 sparse Transformer 模型相比。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Network-Resilience-through-Machine-Learning-powered-Graph-Combinatorial-Optimization-Applications-in-Cyber-Defense-and-Information-Diffusion"><a href="#Enhancing-Network-Resilience-through-Machine-Learning-powered-Graph-Combinatorial-Optimization-Applications-in-Cyber-Defense-and-Information-Diffusion" class="headerlink" title="Enhancing Network Resilience through Machine Learning-powered Graph Combinatorial Optimization: Applications in Cyber Defense and Information Diffusion"></a>Enhancing Network Resilience through Machine Learning-powered Graph Combinatorial Optimization: Applications in Cyber Defense and Information Diffusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10667">http://arxiv.org/abs/2310.10667</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diksha Goel</li>
<li>For: This paper focuses on developing effective approaches for enhancing network resilience in cyber defense and information diffusion application domains.* Methods: The paper transforms the problems of discovering bottleneck edges and structural hole spanner nodes into graph-combinatorial optimization problems and designs machine learning-based approaches to discover bottleneck points vital for network resilience.* Results: The paper aims to provide effective, efficient, and scalable techniques for enhancing network resilience in specific application domains.Here is the simplified Chinese version of the three key information points:</li>
<li>for: 这篇论文关注于在网络防御和信息传播应用领域中提高网络可恢复性。</li>
<li>methods: 论文将瓶颈边缘和结构孔挫节点的问题转化为图谱-组合优化问题，并采用机器学习方法来找出网络中瓶颈点。</li>
<li>results: 论文目标是为特定应用领域提供有效、高效和可扩展的网络可恢复性提高方法。<details>
<summary>Abstract</summary>
With the burgeoning advancements of computing and network communication technologies, network infrastructures and their application environments have become increasingly complex. Due to the increased complexity, networks are more prone to hardware faults and highly susceptible to cyber-attacks. Therefore, for rapidly growing network-centric applications, network resilience is essential to minimize the impact of attacks and to ensure that the network provides an acceptable level of services during attacks, faults or disruptions. In this regard, this thesis focuses on developing effective approaches for enhancing network resilience. Existing approaches for enhancing network resilience emphasize on determining bottleneck nodes and edges in the network and designing proactive responses to safeguard the network against attacks. However, existing solutions generally consider broader application domains and possess limited applicability when applied to specific application areas such as cyber defense and information diffusion, which are highly popular application domains among cyber attackers.   This thesis aims to design effective, efficient and scalable techniques for discovering bottleneck nodes and edges in the network to enhance network resilience in cyber defense and information diffusion application domains. We first investigate a cyber defense graph optimization problem, i.e., hardening active directory systems by discovering bottleneck edges in the network. We then study the problem of identifying bottleneck structural hole spanner nodes, which are crucial for information diffusion in the network. We transform both problems into graph-combinatorial optimization problems and design machine learning based approaches for discovering bottleneck points vital for enhancing network resilience.
</details>
<details>
<summary>摘要</summary>
随着计算和网络通信技术的不断发展，网络基础设施和其应用环境变得越来越复杂，因此网络更容易受到硬件故障和攻击。为了应对这些攻击和故障，网络可靠性变得非常重要，以确保网络在攻击或故障时仍能提供可接受的服务。在这个视角下，这个论文将关注开发有效的网络可靠性提升方法。现有的网络可靠性提升方法通常是通过确定网络中瓶须节点和边来预防攻击。然而，现有的解决方案通常只适用于更广泛的应用领域，而不是特定的应用领域，如网络防御和信息传播，这些应用领域在网络攻击者中非常受欢迎。这个论文的目标是为网络防御和信息传播应用领域提供有效、高效和可扩展的瓶须节点和边发现方法，以提升网络可靠性。我们首先研究了网络防御图优化问题，即通过发现网络中瓶须边来强化网络防御。然后，我们研究了网络中瓶须结构孔隙节点的问题，这些节点对于信息传播非常重要。我们将这两个问题转化为图-数学优化问题，并使用机器学习方法来发现瓶须点，以提升网络可靠性。
</details></li>
</ul>
<hr>
<h2 id="A-Simple-Illustration-of-Interleaved-Learning-using-Kalman-Filter-for-Linear-Least-Squares"><a href="#A-Simple-Illustration-of-Interleaved-Learning-using-Kalman-Filter-for-Linear-Least-Squares" class="headerlink" title="A Simple Illustration of Interleaved Learning using Kalman Filter for Linear Least Squares"></a>A Simple Illustration of Interleaved Learning using Kalman Filter for Linear Least Squares</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03751">http://arxiv.org/abs/2310.03751</a></li>
<li>repo_url: None</li>
<li>paper_authors: Majnu John, Yihren Wu</li>
<li>for: 提出了一种基于Kalman Filter的线性最小二乘算法的机器学习算法协调学习机制。</li>
<li>methods: 使用了Kalman Filter来实现线性最小二乘算法中的协调学习机制。</li>
<li>results: 通过实验证明了该算法的效果。<details>
<summary>Abstract</summary>
Interleaved learning in machine learning algorithms is a biologically inspired training method with promising results. In this short note, we illustrate the interleaving mechanism via a simple statistical and optimization framework based on Kalman Filter for Linear Least Squares.
</details>
<details>
<summary>摘要</summary>
生物学中的混合学习（Interleaved learning）是一种机器学习算法中的训练方法，具有承诺的成果。本短记将通过简单的统计和优化框架，基于加尔曼缓冲器进行线性最小二乘问题的示例阐释interleaving机制。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/22/cs.LG_2023_09_22/" data-id="cloqtaets00pxgh883qh1gyya" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_09_22" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/22/eess.SP_2023_09_22/" class="article-date">
  <time datetime="2023-09-22T08:00:00.000Z" itemprop="datePublished">2023-09-22</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/22/eess.SP_2023_09_22/">eess.SP - 2023-09-22</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="A-Survey-of-Brain-Computer-Interface-Using-Non-Invasive-Methods"><a href="#A-Survey-of-Brain-Computer-Interface-Using-Non-Invasive-Methods" class="headerlink" title="A Survey of Brain Computer Interface Using Non-Invasive Methods"></a>A Survey of Brain Computer Interface Using Non-Invasive Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13151">http://arxiv.org/abs/2309.13151</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ritam Ghosh</li>
<li>for: 这篇论文主要用于探讨脑机器接口（BCI）技术的优缺点，以及一些非侵入式技术的应用场景。</li>
<li>methods: 本文使用了脑电图（EEG）、功能磁共振成像（fMRI）、近红外 спектроскопия（NIRs）和混合系统等非侵入式技术。</li>
<li>results: 本文总结了这些非侵入式技术的优点和缺点，并展示了它们在各种应用场景中的应用。<details>
<summary>Abstract</summary>
Research on Brain-Computer Interface (BCI) began in the 1970s and has increased in volume and diversified significantly since then. Today BCI is widely used for applications like assistive devices for physically challenged users, mental state monitoring, input devices for hands-free applications, marketing, education, security, games and entertainment. This article explores the advantages and disadvantages of invasive and non-invasive BCI technologies and focuses on use cases of several non-invasive technologies, namely electroencephalogram (EEG), functional Magnetic Resonance Imaging (fMRI), Near Infrared Spectroscopy (NIRs) and hybrid systems.
</details>
<details>
<summary>摘要</summary>
研究Brain-Computer Interface（BCI）始于1970年代，自 then onwards 已经增加了量和多样化了很多。今天，BCI 广泛应用于帮助 físically challenged 用户、监测 mental state、手sfree 应用程序的输入设备、marketing、教育、安全、游戏和娱乐等领域。本文介绍了 BCIs 的优势和缺点，并关注了多种非侵入式技术的应用情况，namely 电энцефаogram（EEG）、功能磁共振成像（fMRI）、近红外 спектроскопи（NIRs）和混合系统。
</details></li>
</ul>
<hr>
<h2 id="Performance-Evaluation-for-Subarray-based-Reconfigurable-Intelligent-Surface-Aided-Wireless-Communication-Systems"><a href="#Performance-Evaluation-for-Subarray-based-Reconfigurable-Intelligent-Surface-Aided-Wireless-Communication-Systems" class="headerlink" title="Performance Evaluation for Subarray-based Reconfigurable Intelligent Surface-Aided Wireless Communication Systems"></a>Performance Evaluation for Subarray-based Reconfigurable Intelligent Surface-Aided Wireless Communication Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12977">http://arxiv.org/abs/2309.12977</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyi Yang, Weicong Chen, Xiao Li, Shi Jin</li>
<li>for: 提高无线通信系统性能，研究基于减数阵的智能表面协助系统</li>
<li>methods: 使用基于减数阵的协助技术，分析和优化协助系统中的反射率和谱系数</li>
<li>results: 提出基于减数阵的协助系统可以提高系统的均衡 spectral efficiency 和能效率，并且可以同时降低功率消耗和反射率Note: The above results are in Simplified Chinese text.<details>
<summary>Abstract</summary>
Reconfigurable intelligent surfaces (RISs) have received extensive concern to improve the performance of wireless communication systems. In this paper, a subarray-based scheme is investigated in terms of its effects on ergodic spectral efficiency (SE) and energy efficiency (EE) in RIS-assisted systems. In this scheme, the adjacent elements divided into a subarray are controlled by one signal and share the same reflection coefficient. An upper bound of ergodic SE is derived and an optimal phase shift design is proposed for the subarray-based RIS. Based on the upper bound and optimal design, we obtain the maximum of the upper bound. In particular, we analytically evaluate the effect of the subarray-based RIS on EE since it reduces SE and power consumption simultaneously. Numerical results verify the tightness of the upper bound, demonstrate the effectiveness of the optimal phase shift design for the subarray-based RIS, and reveal the effects of the subarray-based scheme on SE and EE.
</details>
<details>
<summary>摘要</summary>
改进无线通信系统性能的重 Configurable intelligent surfaces (RISs) 已经引起了广泛关注。本文 investigate 一种基于subarray的方案，包括其对ergodic spectral efficiency (SE) 和能效率 (EE) 的影响。在这种方案中，邻近元素被分成一个subarray，并由一个信号控制，共享相同的反射系数。我们 derive 一个上限 bound 的ergodic SE，并提出了一种优化的相位偏移设计。基于上限 bound 和优化设计，我们获得了最大的上限。具体来说，我们分析了subarray-based RIS 对EE的影响，因为它同时降低了SE和功率消耗。 numerically 结果证明了上限 bound 的紧张性，证明了优化相位偏移设计的效果，并揭示了subarray-based scheme 对SE和EE的影响。
</details></li>
</ul>
<hr>
<h2 id="Guaranteed-Private-Communication-with-Secret-Block-Structure"><a href="#Guaranteed-Private-Communication-with-Secret-Block-Structure" class="headerlink" title="Guaranteed Private Communication with Secret Block Structure"></a>Guaranteed Private Communication with Secret Block Structure</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12949">http://arxiv.org/abs/2309.12949</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maxime Ferreira Da Costa, Jianxiu Li, Urbashi Mitra</li>
<li>for: 这篇论文提出了一种新的私人通信框架，通过在通道实例上传输线性逆问题，使得隐私被引入。这个框架的安全性基于发送方和合法接收方之间的秘密知识。</li>
<li>methods: 这篇论文使用了一种基于秘密块结构的协议，使得接收方可以从不充足的线性测量中解码块稀热消息。这种协议可以应用于实际的多Access无线通信系统中。</li>
<li>results: 研究表明，在某些特定的频率和传输参数下，伪装者可以尝试从通道输出的四次趋势中提取秘密块结构。然而，计算一个统计下界，表明该提出的四次趋势秘密块估计策略几乎是优化的。此外，研究表明，通过spectral clustering算法，可以定义扩大秘密键的时间长度，以确保通信的安全性。<details>
<summary>Abstract</summary>
A novel private communication framework is proposed where privacy is induced by transmitting over channel instances of linear inverse problems that are identifiable to the legitimate receiver, but unidentifiable to an eavesdropper. The gap in identifiability is created in the framework by leveraging secret knowledge between the transmitter and the legitimate receiver. Specifically, the case where the legitimate receiver harnesses a secret block structure to decode a transmitted block-sparse message from underdetermined linear measurements in conditions where classical compressed sensing would provably fail is examined. The applicability of the proposed scheme to practical multiple access wireless communication systems is discussed. The protocol's privacy is studied under a single transmission, and under multiple transmissions without refreshing the secret block structure. It is shown that, under a specific scaling of the channel dimensions and transmission parameters, the eavesdropper can attempt to overhear the block structure from the fourth-order moments of the channel output. Computation of a statistical lower bound, suggests that the proposed fourth-order moment secret block estimation strategy is near optimal. The performance of a spectral clustering algorithm is studied to that end, defining scaling laws on the lifespan of the secret key before the communication is compromised. Finally, numerical experiments corroborating the theoretical findings are conducted.
</details>
<details>
<summary>摘要</summary>
一种新的私人通信框架被提议，其中隐私是通过在通道上传输线性逆问题的实例，这些问题只能被合法接收者识别出来，但不能被侦测者识别出来。在这个框架中，通过 transmitter 和合法接收者之间的秘密知识来创造不可识别的差异。例如，在 transmitter 将块稀疏消息从不充分的线性测量中解码的情况下，合法接收者可以利用秘密块结构来解码消息。本文探讨了这种方案在实际多接入无线通信系统中的可行性，并研究了协议的隐私性。在单次传输和多次传输无需刷新秘密块结构的情况下，分析表明，在某些频率缩放和传输参数的情况下，侦测者可以尝试从通道输出的四次 moments 中找到秘密块结构。计算统计下界，表明该提议的四次 moment 秘密块估计策略是近似优美的。此外，对spectral clustering算法的研究表明，在某些频率缩放和传输参数的情况下，秘密钥的寿命会随着通信的增加而减少。最后，通过实验证明了理论发现的结论。
</details></li>
</ul>
<hr>
<h2 id="A-Proof-of-Concept-for-OTFS-Resilience-in-Doubly-Selective-Channels-by-GPU-Enabled-Real-Time-SDR"><a href="#A-Proof-of-Concept-for-OTFS-Resilience-in-Doubly-Selective-Channels-by-GPU-Enabled-Real-Time-SDR" class="headerlink" title="A Proof of Concept for OTFS Resilience in Doubly-Selective Channels by GPU-Enabled Real-Time SDR"></a>A Proof of Concept for OTFS Resilience in Doubly-Selective Channels by GPU-Enabled Real-Time SDR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12861">http://arxiv.org/abs/2309.12861</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Xien Yap, Neil Bhushan, Onur Dizdar, Ata Sattarzadeh, David Redgate, Venkateswara Battula, Stephen Wang</li>
<li>for: 该论文旨在研究Orthogonal Time Frequency Space (OTFS) 模ulation技术，并在实际的实时Software Defined Radio (SDR) 设置中进行实验研究。</li>
<li>methods: 该论文使用了一个基于 Graphical Processing Unit (GPU) 的信号处理程序，以及 Universal Software Radio Peripheral (USRP) 设备来实现一个低延迟的接收结构，并在不同的Doppler值下调查其性能。</li>
<li>results: 研究结果表明，OTFS 比 OFDM 更高度具有对双选择通道的鲁棒性，并在实际实验中表现出色。<details>
<summary>Abstract</summary>
Orthogonal time frequency space (OTFS) is a modulation technique which is robust against the disruptive effects of doubly-selective channels. In this paper, we perform an experimental study of OTFS by a real-time software defined radio (SDR) setup. Our SDR consists of a Graphical Processing Unit (GPU) for signal processing programmed using Sionna and TensorFlow, and Universal Software Radio Peripheral (USRP) devices for air interface. We implement a low-latency transceiver structure for OTFS and investigate its performance under various Doppler values. By comparing the performance of OTFS with Orthogonal Frequency Division Multiplexing (OFDM), we demonstrate that OTFS is highly robust against the disruptive effects of doubly-selective channels in a real-time experimental setup.
</details>
<details>
<summary>摘要</summary>
水平时频空间（OTFS）是一种干扰强度较弱的模调技术，可以在双 selektiv通道中具有高Robustness。在这篇论文中，我们通过实验研究了OTFS，使用了一个真实时间定制的Software Defined Radio（SDR）设置。我们的SDR包括一个图形处理器（GPU）用于信号处理，并使用Sionna和TensorFlow编程，以及Universal Software Radio Peripheral（USRP）设备用于空中接口。我们实现了一种低延迟的接收结构，并在不同的Doppler值下调查其性能。通过对OTFS和Orthogonal Frequency Division Multiplexing（OFDM）的比较，我们表明了OTFS在真实时间实验设置中对双 selektiv通道的破坏性影响具有高Robustness。
</details></li>
</ul>
<hr>
<h2 id="Multiple-Satellites-Collaboration-for-Joint-Code-aided-CFOs-and-CPOs-Estimation"><a href="#Multiple-Satellites-Collaboration-for-Joint-Code-aided-CFOs-and-CPOs-Estimation" class="headerlink" title="Multiple Satellites Collaboration for Joint Code-aided CFOs and CPOs Estimation"></a>Multiple Satellites Collaboration for Joint Code-aided CFOs and CPOs Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12828">http://arxiv.org/abs/2309.12828</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pingyue Yue, Yixuan Li, Yue Li, Rui Zhang, Shuai Wang, Jianping An</li>
<li>For: 提高低Earth轨道卫星网络的安全性和可靠性* Methods: 使用合作卫星技术，并提出了一种基于编码的迭代参数估计算法来解决低信号噪比下的参数估计挑战* Results:  simulation results show that the proposed algorithm can approach Bit Error Rate (BER) performance bound within 0.4 dB with regards to four-satellite collaboration.<details>
<summary>Abstract</summary>
Low Earth Orbit (LEO) satellites are being extensively researched in the development of secure Internet of Remote Things (IoRT). In scenarios with miniaturized terminals, the limited transmission power and long transmission distance often lead to low Signal-to-Noise Ratio (SNR) at the satellite receiver, which degrades communication performance. A solution to address this issue is the utilization of cooperative satellites, which can combine signals received from multiple satellites, thereby significantly improve SNR. However, in order to maximize the combination gain, the signal coherent combining is necessary, which requires the carrier frequency and phase of each receiving signal to be aligned.   Under low SNR circumstances, carrier parameter estimation can be a significant challenge, especially for short burst transmission with no training sequence. In order to tackle it, we propose an iterative code-aided estimation algorithm for joint Carrier Frequency Offset (CFO) and Carrier Phase Offset (CPO). The Cram\'er-Rao Lower Bound (CRLB) is suggested as the limit on the parameter estimation performance. Simulation results demonstrate that the proposed algorithm can approach Bit Error Rate (BER) performance bound within 0.4 dB with regards to four-satellite collaboration.
</details>
<details>
<summary>摘要</summary>
低地球轨道（LEO）卫星在网络 remote Things（IoRT）的开发中被广泛研究。在具有小型终端的场景下，由于传输功率和传输距离都很小，因此在卫星接收器上常常出现低信噪比（SNR），这会降低通信性能。为解决这个问题，可以利用合作卫星，即将多个卫星接收器的信号合并，从而显著提高SNR。然而，为了最大化合并增益，需要进行信号干涉合并，这需要每个接收信号的干涉频率和相位相同。在低SNR情况下，干涉参数估计可能是一个 significiant挑战，特别是在短暂的传输中没有训练序列。为解决这个问题，我们提出了一种迭代码帮助估计算法，用于同时估计干涉频率偏移（CFO）和干涉相位偏移（CPO）。对于四个卫星的合作，我们提出的算法可以在0.4dB之内 approaching Bit Error Rate（BER）性能 bound。
</details></li>
</ul>
<hr>
<h2 id="Alteration-of-skeletal-muscle-energy-metabolism-assessed-by-31P-MRS-in-clinical-routine-part-1-Advanced-Quality-Control-pipeline"><a href="#Alteration-of-skeletal-muscle-energy-metabolism-assessed-by-31P-MRS-in-clinical-routine-part-1-Advanced-Quality-Control-pipeline" class="headerlink" title="Alteration of skeletal muscle energy metabolism assessed by 31P MRS in clinical routine, part 1: Advanced Quality Control pipeline"></a>Alteration of skeletal muscle energy metabolism assessed by 31P MRS in clinical routine, part 1: Advanced Quality Control pipeline</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12796">http://arxiv.org/abs/2309.12796</a></li>
<li>repo_url: None</li>
<li>paper_authors: Antoine Naëgel, Hélène Ratiney, Jabrane Karkouri, Djahid Kennouche, Nicolas Royer, Jill M Slade, Jérôme Morel, Pierre Croisille, Magalie Viallon</li>
<li>for: 本研究目的是提供一种基于Literature current recommendations和临床经验所提出的数据质量控制方法，以帮助在 dynamic 31P-MRS 数据处理中获得可靠的结果。</li>
<li>methods: 本研究使用了一种三元组合的数据质量控制方法，包括对数据进行自适应标准化、对数据进行质量控制分数（QCS）的计算、并对数据进行手动审核。</li>
<li>results: 使用QCS可以快速标识具有数据异常的 subjects，并提供对数据进行修正的指导。总的来说，QCS使得可以自动分类45%的 subjects，其中58名参与者的数据没有规则违反，21名参与者的数据需要拒绝。此外，手动审核还可以Acceptance of full datasets from an additional 80 participants and recovery phase data from an additional 16 subjects。总之，patient数据中出现了更多的异常（35%的dataset），比healthy controls（15%的dataset）更高。<details>
<summary>Abstract</summary>
Background: Implementing a standardized 31P-MRS dynamic acquisition protocol to evaluate skeletal muscle energy metabolism and monitor muscle fatigability1,2, while being compatible with various longitudinal clinical studies on diversified patient cohorts, requires a high level of technicality and expertise. Furthermore, processing data to obtain reliable results also demands a great degree of expertise from the operator. In this two-part article, we present an advanced quality control approach for data acquired using a dynamic 31P-MRS protocol. The aim is to provide decision support to the operator in order to assist in data processing and obtain reliable results based on objective criteria. We present first in part one, an advanced data quality control (QC) approach of a dynamic 31P-MRS protocol. Part two is an impact study demonstrating the added value of the QC approach to explore clinical results derived from two patient populations with significant fatigue: COVID19 and multiple sclerosis (MS). Experimental: 31P-MRS was performed on a 3T clinical MRI in 175 subjects from clinical and healthy control populations conducted in a University Hospital. An advanced data QC Score (QCS) was developed using multiple objective criteria. The criteria were based on current recommendations from the literature enriched by new proposals based on clinical experience. The QCS was designed to indicate valid and corrupt data and guide necessary objective data editing to extract as much valid physiological data as possible. Dynamic acquisitions using an MR-compatible ergometer ran over a rest(40s), exercise(2min), and a recovery phase(6min). Results: Using QCS enabled rapid identification of subjects with data anomalies allowing the user to correct the data series or reject them partially or entirely as well as identify fully valid datasets. Overall, the use of the QCS resulted in the automatic classification of 45% of the subjects including 58 participants that had data with no criterion violation and 21 participants with violations that resulted in the rejection of all dynamic data. The remaining datasets were inspected manually with guidance allowing acceptance of full datasets from an additional 80 participants and recovery phase data from an additional 16 subjects. Overall, more anomalies occurred with patient data (35% of datasets) compared to healthy controls (15% of datasets). Conclusion: This paper describes typical difficulties encountered during the dynamic acquisition of 31P-MRS. Based on these observations, a standardized data quality control pipeline was created and implemented in both healthy and patient populations. The QC scoring ensures a standardized data rejection procedure and rigorous objective analysis of dynamic 31P-MRS data obtained from patients. The contribution of this methodology contributes to efforts made to standardize the practices of the 31P-MRS that has been underway for a decade, with the ultimate goal of making it an empowered tool for clinical research.
</details>
<details>
<summary>摘要</summary>
Background: 实施标准化31P-MRS动态获取协议，以评估骨骼肌能量代谢和监测肌肉疲劳性，需要高水平的技术性和专业知识。此外，从操作员处理数据以获得可靠结果也需要很高的专业度。在这两篇文章中，我们提出了一种高级数据质控方法，以帮助操作员在数据处理中做出客观的决策。在第一篇文章中，我们介绍了一种高级数据质控方法，以帮助操作员在数据处理中做出客观的决策。第二篇文章是一项影响研究，探讨了这种质控方法在 COVID-19 和多发性骨骼炎（MS）两种疲劳性疾病中的价值。Experimental: 31P-MRS在3T临床MRI上进行了175名临床和健康控制群体的测试。我们开发了一种多重目的 criterion 基于当前文献的建议，以及我们的临床经验所提出的新建议。这种 QCS 是用来指示有效和假数据，并帮助操作员对数据进行客观编辑，以提取最多可靠生物学数据。动态获取使用 MR 兼容的自行车在休息（40s）、运动（2分）和恢复阶段（6分）。结果：通过 QCS，可以快速标识具有数据异常的主体，并让用户对数据系列进行修正或者部分或全部拒绝。总的来说，使用 QCS 导致了自动将45%的主体分类为有效数据，其中有58名参与者没有任何 criterion 违反，而有21名参与者因违反 criterion 而拒绝了所有动态数据。剩下的数据被手动检查，以确定是否acceptable。总的来说， patient 数据中出现了更多的异常（35%的数据），compared to healthy controls（15%的数据）。结论：这篇文章描述了在动态获取31P-MRS数据时常见的困难。基于这些观察，我们创建了一个标准化的数据质控管道，并在健康和疾病人群中实施。 QCS  scoring 确保了一个标准化的数据拒绝程序，并且对动态31P-MRS数据从病人中得到的结果进行了严格的客观分析。本质控方法的贡献是为标准化31P-MRS实践做出了贡献，这一实践已经在过去十年中进行了不断的标准化努力，以使其成为严格的研究工具。
</details></li>
</ul>
<hr>
<h2 id="Multi-objective-Optimization-of-Space-Air-Ground-Integrated-Network-Slicing-Relying-on-a-Pair-of-Central-and-Distributed-Learning-Algorithms"><a href="#Multi-objective-Optimization-of-Space-Air-Ground-Integrated-Network-Slicing-Relying-on-a-Pair-of-Central-and-Distributed-Learning-Algorithms" class="headerlink" title="Multi-objective Optimization of Space-Air-Ground Integrated Network Slicing Relying on a Pair of Central and Distributed Learning Algorithms"></a>Multi-objective Optimization of Space-Air-Ground Integrated Network Slicing Relying on a Pair of Central and Distributed Learning Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12783">http://arxiv.org/abs/2309.12783</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guorong Zhou, Liqiang Zhao, Gan Zheng, Shenghui Song, Jiankang Zhang, Lajos Hanzo</li>
<li>for: 本文旨在研究如何在全球空天地网络（SAGIN）中 dynamically 考虑三种常见的Radio Access Network（RAN）slice，以提高多种定制化服务的可用性和效率。</li>
<li>methods: 本文提出了一种基于多智能agent的 deep deterministic policy gradient（CDMADDPG）算法，用于同时优化三种类型的RAN slice的吞吐量、延迟和覆盖面积。</li>
<li>results:  simulation 结果表明，提出的方法可以尝试到Pareto优化多个RAN slice，并超越参考模型。<details>
<summary>Abstract</summary>
As an attractive enabling technology for next-generation wireless communications, network slicing supports diverse customized services in the global space-air-ground integrated network (SAGIN) with diverse resource constraints. In this paper, we dynamically consider three typical classes of radio access network (RAN) slices, namely high-throughput slices, low-delay slices and wide-coverage slices, under the same underlying physical SAGIN. The throughput, the service delay and the coverage area of these three classes of RAN slices are jointly optimized in a non-scalar form by considering the distinct channel features and service advantages of the terrestrial, aerial and satellite components of SAGINs. A joint central and distributed multi-agent deep deterministic policy gradient (CDMADDPG) algorithm is proposed for solving the above problem to obtain the Pareto optimal solutions. The algorithm first determines the optimal virtual unmanned aerial vehicle (vUAV) positions and the inter-slice sub-channel and power sharing by relying on a centralized unit. Then it optimizes the intra-slice sub-channel and power allocation, and the virtual base station (vBS)/vUAV/virtual low earth orbit (vLEO) satellite deployment in support of three classes of slices by three separate distributed units. Simulation results verify that the proposed method approaches the Pareto-optimal exploitation of multiple RAN slices, and outperforms the benchmarkers.
</details>
<details>
<summary>摘要</summary>
作为下一代无线通信技术的吸引人之一，网络剖析支持多种个性化服务在全球空天地 Integrated Network (SAGIN) 中，拥有多种资源限制。在这篇论文中，我们动态考虑了三种常见的无线接入网络 (RAN) slice，namely 高速吞吐 slice, 低延迟 slice 和广泛覆盖 slice，在同一层次的物理 SAGIN 中。这三种 RAN slice 的吞吐率、服务延迟和覆盖区域都是jointly 优化的，而且考虑了不同的通信频率和服务优势，以实现 Pareto 优化解决方案。我们提出了一种基于多代理 deep deterministic policy gradient (CDMADDPG) 算法的 JOINT 中央和分布式算法来解决这个问题。该算法首先确定了最佳虚拟无人机 (vUAV) 位置和间 slice Sub-channel 和功率分配，然后对每种 slice 进行内 slice Sub-channel 和功率分配，以及虚拟基站 (vBS)/vUAV/虚拟低地球 (vLEO) 卫星部署。测试结果表明，提议的方法可以实现 Pareto 优化多个 RAN slice，并超过参考值。
</details></li>
</ul>
<hr>
<h2 id="Green-Holographic-MIMO-Communications-With-A-Few-Transmit-Radio-Frequency-Chains"><a href="#Green-Holographic-MIMO-Communications-With-A-Few-Transmit-Radio-Frequency-Chains" class="headerlink" title="Green Holographic MIMO Communications With A Few Transmit Radio Frequency Chains"></a>Green Holographic MIMO Communications With A Few Transmit Radio Frequency Chains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12688">http://arxiv.org/abs/2309.12688</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuaishuai Guo, Jia Ye, Kaiqian Qu, Shuping Dang</li>
<li>for: 本文旨在探讨绿色束缚多输入多输出通信技术，以减少电磁谱上的束缚数量，同时保持高速度信息传输。</li>
<li>methods: 本文提出了一种名为非均匀束缚模式变换（NUHPM）的有效传输方式，通过利用额外的空间度量来实现高SNR范围内的容量限制。</li>
<li>results: 分析结果表明，通过增大天线覆盖面积而不增加发射RF束缚数量，可以实现绿色评估多input多output通信系统的高性能。数值结果也验证了我们的分析结论。<details>
<summary>Abstract</summary>
Holographic multiple-input multiple-output (MIMO) communications are widely recognized as a promising candidate for the next-generation air interface. With holographic MIMO surface, the number of the spatial degrees-of-freedom (DoFs) considerably increases and also significantly varies as the user moves. To fully employ the large and varying number of spatial DoFs, the number of equipped RF chains has to be larger than or equal to the largest number of spatial DoFs. However, this causes much waste as radio frequency (RF) chains (especially the transmit RF chains) are costly and power-hungry. To avoid the heavy burden, this paper investigates green holographic MIMO communications with a few transmit RF chains under an electromagnetic-based communication model. We not only look at the fundamental capacity limits but also propose an effective transmission, namely non-uniform holographic pattern modulation (NUHPM), to achieve the capacity limit in the high signal-to-noise (SNR) regime. The analytical result sheds light on the green evaluation of MIMO communications, which can be realized by increasing the size of the antenna aperture without increasing the number of transmit RF chains. Numerical results are provided to verify our analysis and to show the great performance gain by employing the additional spatial DoFs as modulation resources.
</details>
<details>
<summary>摘要</summary>
干扰多输入多输出（MIMO）通信被广泛认为是下一代无线接口的优选候选人。干扰MIMO表面上，空间度量自由（DoF）的数量增加很多，同时也因用户移动而异常变化。要完全利用这些很多和变化很大的空间DoF，需要更多的RF扩展（ especial transmit RF），但这会带来很大的浪费。为了避免这种重荷，本文研究了绿色干扰MIMO通信，使用只有一些发射RF扩展。我们不仅研究基本容量的限制，还提议非均匀干扰模式变换（NUHPM），以实现高信号噪响比（SNR）下的容量限制。分析结果抛光绿色评估MIMO通信，可以通过增加天线覆盖面积而不增加发射RF扩展。数值结果证明我们的分析结果，并显示了采用additional spatial DoF作为模ulation资源时的很大性能提升。
</details></li>
</ul>
<hr>
<h2 id="ViT-MDHGR-Cross-day-Reliability-and-Agility-in-Dynamic-Hand-Gesture-Prediction-via-HD-sEMG-Signal-Decoding"><a href="#ViT-MDHGR-Cross-day-Reliability-and-Agility-in-Dynamic-Hand-Gesture-Prediction-via-HD-sEMG-Signal-Decoding" class="headerlink" title="ViT-MDHGR: Cross-day Reliability and Agility in Dynamic Hand Gesture Prediction via HD-sEMG Signal Decoding"></a>ViT-MDHGR: Cross-day Reliability and Agility in Dynamic Hand Gesture Prediction via HD-sEMG Signal Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12602">http://arxiv.org/abs/2309.12602</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qin Hu, Golara Ahmadi Azar, Alyson Fletcher, Sundeep Rangan, S. Farokh Atashzar</li>
<li>for: 这个研究是为了提高多天手势识别的精度和可靠性，并且解决现有的问题，例如对于训练和测试日的数据分配不均匀，导致模型的一致性受损。</li>
<li>methods: 本研究使用了一个封闭的ViT-based网络，并且运用了非常短的HD-sEMG信号窗口（仅50ms），从而提高了模型的迅速性和反应性。</li>
<li>results: 研究发现，使用了提案的模型，可以预测11种动作，并且在20名对象中平均精度高于71%，并且在重新训练少于10%的parameters下，可以达到92%的精度。<details>
<summary>Abstract</summary>
Surface electromyography (sEMG) and high-density sEMG (HD-sEMG) biosignals have been extensively investigated for myoelectric control of prosthetic devices, neurorobotics, and more recently human-computer interfaces because of their capability for hand gesture recognition/prediction in a wearable and non-invasive manner. High intraday (same-day) performance has been reported. However, the interday performance (separating training and testing days) is substantially degraded due to the poor generalizability of conventional approaches over time, hindering the application of such techniques in real-life practices. There are limited recent studies on the feasibility of multi-day hand gesture recognition. The existing studies face a major challenge: the need for long sEMG epochs makes the corresponding neural interfaces impractical due to the induced delay in myoelectric control. This paper proposes a compact ViT-based network for multi-day dynamic hand gesture prediction. We tackle the main challenge as the proposed model only relies on very short HD-sEMG signal windows (i.e., 50 ms, accounting for only one-sixth of the convention for real-time myoelectric implementation), boosting agility and responsiveness. Our proposed model can predict 11 dynamic gestures for 20 subjects with an average accuracy of over 71% on the testing day, 3-25 days after training. Moreover, when calibrated on just a small portion of data from the testing day, the proposed model can achieve over 92% accuracy by retraining less than 10% of the parameters for computational efficiency.
</details>
<details>
<summary>摘要</summary>
superficiale electromiografia (sEMG) 和高密度 sEMG (HD-sEMG) 生物信号已经广泛研究用于 prosthetic device 控制、neurorobotics 和最近的人机交互，因为它们可以在穿着和非侵入性的方式下识别/预测手势。 高于同一天的性能已经被报道。然而， между天性能（分开训练和测试日）却很差，这限制了这些技术的应用在实际场景中。有限的最近研究表明了多天手势识别的可能性。现有的研究面临主要挑战：需要长时间的 sEMG 时间窗口，使得相关的神经接口不实用，因为引入的myoelectric控制延迟。本文提议了一个快速的 ViT 基于网络，用于多天动手势预测。我们解决了主要的挑战，因为我们的提议模型只需要非常短的 HD-sEMG 信号窗口（即 50 ms，相当于一半的实时 myoelectric 实现），提高了机敏性和响应性。我们的提议模型可以预测 11 种动手势，对 20 名参与者的测试日有效率超过 71%，并且在只使用测试日少量数据进行升级时，可以达到超过 92% 的精度。
</details></li>
</ul>
<hr>
<h2 id="Movable-Antenna-Empowered-AirComp"><a href="#Movable-Antenna-Empowered-AirComp" class="headerlink" title="Movable Antenna-Empowered AirComp"></a>Movable Antenna-Empowered AirComp</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12596">http://arxiv.org/abs/2309.12596</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenqiao Cheng, Nanxi Li, Jianchi Zhu, Xiaoming She, Chongjun Ouyang, Peng Chen</li>
<li>for: 提高计算准确性</li>
<li>methods: joint优化传输功率控制、天线位置调整和接收组合</li>
<li>results: 提供了一种有效的方法来最小化计算均方差误差，并且数据显示了该方法的明显优势 compared to 基于固定天线的参考系统。<details>
<summary>Abstract</summary>
A novel over-the-air computation (AirComp) framework, empowered by the incorporation of movable antennas (MAs), is proposed to significantly enhance computation accuracy. Within this framework, the joint optimization of transmit power control, antenna positioning, and receive combining is investigated. An efficient method is proposed to tackle the problem of computation mean-squared error (MSE) minimization, capitalizing on the approach of alternating optimization. Numerical results are provided to substantiate the superior MSE performance of the proposed framework, which establish its clear advantage over benchmark systems employing conventional fixed-position antennas (FPAs).
</details>
<details>
<summary>摘要</summary>
“一个基于无线电处理（AirComp）框架的新方案，利用可动天线（MA）的增强，以提高计算精度。在这个框架中，联合服务器传输电力控制、天线位置调整和接收结合优化。一种高效的方法是提出来解决计算平均方差误差（MSE）的最小化问题，基于交替优化的方法。实验结果显示了提案的框架具有明显的MSE表现优势，与传统固定天线（FPAs）的系统相比。”Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Passive-Reflection-Codebook-Design-for-IRS-Integrated-Access-Point"><a href="#Passive-Reflection-Codebook-Design-for-IRS-Integrated-Access-Point" class="headerlink" title="Passive Reflection Codebook Design for IRS-Integrated Access Point"></a>Passive Reflection Codebook Design for IRS-Integrated Access Point</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12563">http://arxiv.org/abs/2309.12563</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuwei Huang, Lipeng Zhu, Rui Zhang</li>
<li>for: 该研究旨在提高无线信号覆盖范围和通信性能，采用智能反射表面技术（IRS）和接收机天线阵列。</li>
<li>methods: 该研究提出了一种新的codebook-based IRS反射设计，通过在同一个天线覆盖中集成IRS和接收机天线阵列，减少了信道损失。</li>
<li>results: 实验结果表明，该设计可以提高总频谱能量平均值，并在单用户和多用户传输中实现显著的性能提升。<details>
<summary>Abstract</summary>
Intelligent reflecting surface (IRS) has emerged as a promising technique to extend the wireless signal coverage of access point (AP) and improve the communication performance cost-effectively. In order to reduce the path-loss of the cascaded user-IRS-AP channels, the IRS-integrated AP architecture has been proposed to deploy the IRSs and the antenna array of the AP within the same antenna radome. To reduce the pilot overhead for estimating all IRS-involved channels, in this paper, we propose a novel codebook-based IRS reflection design for the IRS-integrated AP to enhance the coverage performance in a given area. In particular, the codebook consisting of a small number of codewords is designed offline by employing an efficient sector division strategy based on the azimuth angle. To ensure the performance of each sector, we optimize its corresponding codeword for IRS reflection pattern to maximize the sector-min-average-effective-channel-power (SMAECP) by applying the alternating optimization (AO) and semidefinite relaxation (SDR) methods. With the designed codebook, the AP performs the IRS reflection training by sequentially applying all codewords and selects the one achieving the best communication performance for data transmission. Numerical results show that our proposed codebook design can enhance the average channel power of the whole coverage area, as compared to the system without IRS. Moreover, our proposed codebook-based IRS reflection design is shown to achieve significant performance gain over other benchmark schemes in both single-user and multi-user transmissions.
</details>
<details>
<summary>摘要</summary>
智能反射表面（IRS）已经成为一种有前途的技术，以提高无线信号覆盖范围和通信性能，而不需要大量的成本投入。为了减少用户-IRS-AP通道的偏移损耗，我们提议在同一个天线覆盖中部署IRS和AP天线阵列。为了减少估算所需的射频资源，在本文中，我们提出了一种新的codebook-based IRS反射设计，以提高在给定区域的覆盖性能。具体来说，我们采用了一个小型的codeword集合来设计codebook，通过使用高效的扇区策略来基于Azimuth角来设计。为了保证每个扇区的性能，我们对每个扇区的相应codeword进行了最优化，以最大化扇区最小平均有效通道功率（SMAECP）。通过将codebook传递给AP，AP可以通过顺序应用所有codeword来进行IRS反射训练，并选择最佳的通信性能来进行数据传输。numerical results表明，我们的提议的codebook设计可以提高整个覆盖区域的平均通道功率，相比于没有IRS的系统。此外，我们的codebook-based IRS反射设计还被证明可以在单用户和多用户传输中具有显著的性能提升。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/22/eess.SP_2023_09_22/" data-id="cloqtaf2c01aggh88dlx6cv3g" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_09_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/21/cs.SD_2023_09_21/" class="article-date">
  <time datetime="2023-09-21T15:00:00.000Z" itemprop="datePublished">2023-09-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/21/cs.SD_2023_09_21/">cs.SD - 2023-09-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Profile-Error-Tolerant-Target-Speaker-Voice-Activity-Detection"><a href="#Profile-Error-Tolerant-Target-Speaker-Voice-Activity-Detection" class="headerlink" title="Profile-Error-Tolerant Target-Speaker Voice Activity Detection"></a>Profile-Error-Tolerant Target-Speaker Voice Activity Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12521">http://arxiv.org/abs/2309.12521</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongmei Wang, Xiong Xiao, Naoyuki Kanda, Midia Yousefi, Takuya Yoshioka, Jian Wu</li>
<li>for: 这篇论文旨在提高TS-VAD方法的稳定性和可靠性，使其能够抗击发音人识别错误。</li>
<li>methods: 这篇论文提出了一种基于变换器的TS-VAD方法，该方法可以处理不同数量的发音人，并且引入了一组附加的伪发音人识别器来处理在第一次分配不正确的发音人。在训练时，我们使用多种不同的聚类算法来估计发音人识别器，以减少训练和测试条件之间的差异。</li>
<li>results: 实验结果表明，PET-TSVAD方法在VoxConverse和DIHARD-I datasets上具有更高的稳定性和可靠性，与现有的TS-VAD方法相比，可以更好地抗击发音人识别错误。<details>
<summary>Abstract</summary>
Target-Speaker Voice Activity Detection (TS-VAD) utilizes a set of speaker profiles alongside an input audio signal to perform speaker diarization. While its superiority over conventional methods has been demonstrated, the method can suffer from errors in speaker profiles, as those profiles are typically obtained by running a traditional clustering-based diarization method over the input signal. This paper proposes an extension to TS-VAD, called Profile-Error-Tolerant TS-VAD (PET-TSVAD), which is robust to such speaker profile errors. This is achieved by employing transformer-based TS-VAD that can handle a variable number of speakers and further introducing a set of additional pseudo-speaker profiles to handle speakers undetected during the first pass diarization. During training, we use speaker profiles estimated by multiple different clustering algorithms to reduce the mismatch between the training and testing conditions regarding speaker profiles. Experimental results show that PET-TSVAD consistently outperforms the existing TS-VAD method on both the VoxConverse and DIHARD-I datasets.
</details>
<details>
<summary>摘要</summary>
target-speaker voice activity detection (TS-VAD) 使用一组说话者配置文件和输入音频信号进行说话者分类。尽管它在传统方法上表现出优势，但该方法可能会因为说话者配置文件中的错误而受到影响。这篇论文提出了一种对 TS-VAD 进行扩展，称为 Profile-Error-Tolerant TS-VAD (PET-TSVAD)，可以抗 resist 说话者配置文件中的错误。这是通过使用 transformer-based TS-VAD 来实现，该方法可以处理变数量的说话者和额外引入一组 Pseudo-speaker 配置文件来处理在首个扫描中未探测到的说话者。在训练中，我们使用不同 clustering 算法来估计说话者配置文件，以降低在训练和测试条件下的配置文件匹配度。实验结果表明，PET-TSVAD 在 VoxConverse 和 DIHARD-I 数据集上一直表现出优势，与传统 TS-VAD 方法相比。
</details></li>
</ul>
<hr>
<h2 id="Variational-Quantum-Harmonizer-Generating-Chord-Progressions-and-Other-Sonification-Methods-with-the-VQE-Algorithm"><a href="#Variational-Quantum-Harmonizer-Generating-Chord-Progressions-and-Other-Sonification-Methods-with-the-VQE-Algorithm" class="headerlink" title="Variational Quantum Harmonizer: Generating Chord Progressions and Other Sonification Methods with the VQE Algorithm"></a>Variational Quantum Harmonizer: Generating Chord Progressions and Other Sonification Methods with the VQE Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12254">http://arxiv.org/abs/2309.12254</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paulo Vitor Itaboraí, Tim Schwägerl, María Aguado Yáñez, Arianna Crippa, Karl Jansen, Eduardo Reck Miranda, Peter Thomas</li>
<li>for: 这项研究探讨了使用物理基于的声明方法来解决Quadratic Unconstrained Binary Optimization (QUBO)问题，使用Variational Quantum Eigensolver (VQE)算法进行优化。</li>
<li>methods: 这项研究使用了VQE算法的迭代循环来 aproximate QUBO问题的解决方案，并将每次迭代的中间状态 vectors 用于声明方法。</li>
<li>results: 这项研究实现了一个名为Variational Quantum Harmonizer (VQH)的音乐 интер法案例，可以用来增强数据可见性或创作艺术作品。VQH还可以用于让艺术家更好地理解QUBO问题的解决方案，并且可以提供一个广泛的声音库 дляQUBO和量子激发的音乐作品。<details>
<summary>Abstract</summary>
This work investigates a case study of using physical-based sonification of Quadratic Unconstrained Binary Optimization (QUBO) problems, optimized by the Variational Quantum Eigensolver (VQE) algorithm. The VQE approximates the solution of the problem by using an iterative loop between the quantum computer and a classical optimization routine. This work explores the intermediary statevectors found in each VQE iteration as the means of sonifying the optimization process itself. The implementation was realised in the form of a musical interface prototype named Variational Quantum Harmonizer (VQH), providing potential design strategies for musical applications, focusing on chords, chord progressions, and arpeggios. The VQH can be used both to enhance data visualization or to create artistic pieces. The methodology is also relevant in terms of how an artist would gain intuition towards achieving a desired musical sound by carefully designing QUBO cost functions. Flexible mapping strategies could supply a broad portfolio of sounds for QUBO and quantum-inspired musical compositions, as demonstrated in a case study composition, "Dependent Origination" by Peter Thomas and Paulo Itaborai.
</details>
<details>
<summary>摘要</summary>
The researchers developed a musical interface prototype named Variational Quantum Harmonizer (VQH), which provides potential design strategies for musical applications, such as chords, chord progressions, and arpeggios. The VQH can be used to enhance data visualization or create artistic pieces. The methodology is also relevant for artists who want to achieve a desired musical sound by carefully designing QUBO cost functions.The study demonstrates flexible mapping strategies that can supply a broad portfolio of sounds for QUBO and quantum-inspired musical compositions. A case study composition, "Dependent Origination" by Peter Thomas and Paulo Itaborai, is used to illustrate the potential of the VQH. The research provides a new approach to sonification and has the potential to inspire new forms of artistic expression.In simplified Chinese, the text can be translated as:这项研究investigates the use ofphysical-based sonification ofQuadratic Unconstrained Binary Optimization (QUBO) problems, which are optimized by theVariational Quantum Eigensolver (VQE) algorithm. The VQE algorithm uses an iterative loop between a quantum computer and a classical optimization routine to approximate the solution of the problem. The study focuses on the intermediary statevectors found in each VQE iteration as a means of sonifying the optimization process itself.The researchers developed a musical interface prototype namedVariational Quantum Harmonizer (VQH), which provides potential design strategies for musical applications, such as chords, chord progressions, and arpeggios. The VQH can be used to enhance data visualization or create artistic pieces. The methodology is also relevant for artists who want to achieve a desired musical sound by carefully designing QUBO cost functions.The study demonstrates flexible mapping strategies that can supply a broad portfolio of sounds for QUBO and quantum-inspired musical compositions. A case study composition, "Dependent Origination" by Peter Thomas and Paulo Itaborai, is used to illustrate the potential of the VQH. The research provides a new approach to sonification and has the potential to inspire new forms of artistic expression.
</details></li>
</ul>
<hr>
<h2 id="A-Multiscale-Autoencoder-MSAE-Framework-for-End-to-End-Neural-Network-Speech-Enhancement"><a href="#A-Multiscale-Autoencoder-MSAE-Framework-for-End-to-End-Neural-Network-Speech-Enhancement" class="headerlink" title="A Multiscale Autoencoder (MSAE) Framework for End-to-End Neural Network Speech Enhancement"></a>A Multiscale Autoencoder (MSAE) Framework for End-to-End Neural Network Speech Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12121">http://arxiv.org/abs/2309.12121</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bengt J. Borgstrom, Michael S. Brandstein</li>
<li>for: 提高单频道语音干扰的性能</li>
<li>methods: 使用多Scale自编码器（MSAE），利用不同的速率和尺度进行spectral decomposition，提取多个尺度嵌入</li>
<li>results: 相比传统方法，MSAE提供了明显的性能提升，并在对话质量指标和自动语音识别精度上表现出色。<details>
<summary>Abstract</summary>
Neural network approaches to single-channel speech enhancement have received much recent attention. In particular, mask-based architectures have achieved significant performance improvements over conventional methods. This paper proposes a multiscale autoencoder (MSAE) for mask-based end-to-end neural network speech enhancement. The MSAE performs spectral decomposition of an input waveform within separate band-limited branches, each operating with a different rate and scale, to extract a sequence of multiscale embeddings. The proposed framework features intuitive parameterization of the autoencoder, including a flexible spectral band design based on the Constant-Q transform. Additionally, the MSAE is constructed entirely of differentiable operators, allowing it to be implemented within an end-to-end neural network, and be discriminatively trained. The MSAE draws motivation both from recent multiscale network topologies and from traditional multiresolution transforms in speech processing. Experimental results show the MSAE to provide clear performance benefits relative to conventional single-branch autoencoders. Additionally, the proposed framework is shown to outperform a variety of state-of-the-art enhancement systems, both in terms of objective speech quality metrics and automatic speech recognition accuracy.
</details>
<details>
<summary>摘要</summary>
Recent attention has been given to neural network approaches for single-channel speech enhancement. In particular, mask-based architectures have achieved significant performance improvements over conventional methods. This paper proposes a multiscale autoencoder (MSAE) for mask-based end-to-end neural network speech enhancement. The MSAE performs spectral decomposition of an input waveform within separate band-limited branches, each operating with a different rate and scale, to extract a sequence of multiscale embeddings. The proposed framework features intuitive parameterization of the autoencoder, including a flexible spectral band design based on the Constant-Q transform. Additionally, the MSAE is constructed entirely of differentiable operators, allowing it to be implemented within an end-to-end neural network, and be discriminatively trained. The MSAE draws motivation both from recent multiscale network topologies and from traditional multiresolution transforms in speech processing. Experimental results show the MSAE to provide clear performance benefits relative to conventional single-branch autoencoders. Additionally, the proposed framework is shown to outperform a variety of state-of-the-art enhancement systems, both in terms of objective speech quality metrics and automatic speech recognition accuracy.Here's the translation in Traditional Chinese:近期对单道声音提升的神经网络方法Received much attention. In particular, mask-based architectures have achieved significant performance improvements over conventional methods. This paper proposes a multiscale autoencoder (MSAE) for mask-based end-to-end neural network speech enhancement. The MSAE performs spectral decomposition of an input waveform within separate band-limited branches, each operating with a different rate and scale, to extract a sequence of multiscale embeddings. The proposed framework features intuitive parameterization of the autoencoder, including a flexible spectral band design based on the Constant-Q transform. Additionally, the MSAE is constructed entirely of differentiable operators, allowing it to be implemented within an end-to-end neural network, and be discriminatively trained. The MSAE draws motivation both from recent multiscale network topologies and from traditional multiresolution transforms in speech processing. Experimental results show the MSAE to provide clear performance benefits relative to conventional single-branch autoencoders. Additionally, the proposed framework is shown to outperform a variety of state-of-the-art enhancement systems, both in terms of objective speech quality metrics and automatic speech recognition accuracy.
</details></li>
</ul>
<hr>
<h2 id="Is-the-Ideal-Ratio-Mask-Really-the-Best-–-Exploring-the-Best-Extraction-Performance-and-Optimal-Mask-of-Mask-based-Beamformers"><a href="#Is-the-Ideal-Ratio-Mask-Really-the-Best-–-Exploring-the-Best-Extraction-Performance-and-Optimal-Mask-of-Mask-based-Beamformers" class="headerlink" title="Is the Ideal Ratio Mask Really the Best? – Exploring the Best Extraction Performance and Optimal Mask of Mask-based Beamformers"></a>Is the Ideal Ratio Mask Really the Best? – Exploring the Best Extraction Performance and Optimal Mask of Mask-based Beamformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12065">http://arxiv.org/abs/2309.12065</a></li>
<li>repo_url: None</li>
<li>paper_authors: Atsuo Hiroe, Katsutoshi Itoyama, Kazuhiro Nakadai</li>
<li>for: 这个研究探讨了面具基于的扩音器（BF），它们使用时间频率面具来提取目标语音。虽然已经有很多BF方法被提出，但以下几个方面还没有得到全面的探讨：1）哪种BF可以提供最好的提取性能？2）最佳面具是固定的？3）面具是否与理想的干扰面具（IRM）一样？</li>
<li>methods: 我们 investigate这些问题，考虑四种面具基于的BF：最大信号噪声比BF、其两种变体、以及多通道维因纳Filter（MWF）BF。为了获得每种BF的优化面具，我们使用一种通过每个语音样本的方差平方误差来最小化BF输出与目标语音之间的差异的方法。</li>
<li>results: 通过CHiME-3数据集的实验，我们发现四种BF都可以达到理想MWFBF的上限性能，但是每种BF的优化面具与IRM不同。这与传统的想法不同，即最佳面具是共同的，并且每种BF的最高性能都不同。因此，这个研究对面具基于BF的设计提供了贡献。<details>
<summary>Abstract</summary>
This study investigates mask-based beamformers (BFs), which estimate filters to extract target speech using time-frequency masks. Although several BF methods have been proposed, the following aspects are yet to be comprehensively investigated. 1) Which BF can provide the best extraction performance in terms of the closeness of the BF output to the target speech? 2) Is the optimal mask for the best performance common for all BFs? 3) Is the ideal ratio mask (IRM) identical to the optimal mask? Accordingly, we investigate these issues considering four mask-based BFs: the maximum signal-to-noise ratio BF, two variants of this, and the multichannel Wiener filter (MWF) BF. To obtain the optimal mask corresponding to the peak performance for each BF, we employ an approach that minimizes the mean square error between the BF output and target speech for each utterance. Via the experiments with the CHiME-3 dataset, we verify that the four BFs have the same peak performance as the upper bound provided by the ideal MWF BF, whereas the optimal mask depends on the adopted BF and differs from the IRM. These observations differ from the conventional idea that the optimal mask is common for all BFs and that peak performance differs for each BF. Hence, this study contributes to the design of mask-based BFs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Which BF can provide the best extraction performance in terms of the closeness of the BF output to the target speech?2. Is the optimal mask for the best performance common for all BFs?3. Is the ideal ratio mask (IRM) identical to the optimal mask?To investigate these issues, we considered four mask-based BFs: the maximum signal-to-noise ratio BF, two variants of this, and the multichannel Wiener filter (MWF) BF. We employed an approach that minimizes the mean square error between the BF output and target speech for each utterance to obtain the optimal mask corresponding to the peak performance for each BF.Through experiments with the CHiME-3 dataset, we found that the four BFs have the same peak performance as the upper bound provided by the ideal MWF BF, but the optimal mask depends on the adopted BF and differs from the IRM. These observations differ from the conventional idea that the optimal mask is common for all BFs and that peak performance differs for each BF. Therefore, this study contributes to the design of mask-based BFs.</details></li>
</ol>
<hr>
<h2 id="Improving-Language-Model-Based-Zero-Shot-Text-to-Speech-Synthesis-with-Multi-Scale-Acoustic-Prompts"><a href="#Improving-Language-Model-Based-Zero-Shot-Text-to-Speech-Synthesis-with-Multi-Scale-Acoustic-Prompts" class="headerlink" title="Improving Language Model-Based Zero-Shot Text-to-Speech Synthesis with Multi-Scale Acoustic Prompts"></a>Improving Language Model-Based Zero-Shot Text-to-Speech Synthesis with Multi-Scale Acoustic Prompts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11977">http://arxiv.org/abs/2309.11977</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shun Lei, Yixuan Zhou, Liyang Chen, Dan Luo, Zhiyong Wu, Xixin Wu, Shiyin Kang, Tao Jiang, Yahui Zhou, Yuxing Han, Helen Meng</li>
<li>for: 本研究旨在提出一种基于语言模型的零示Text-to-Speech（TTS）生成器，可以跨语言和 speaker 进行适应。</li>
<li>methods: 该模型使用了一种基于 neural codec 的语言模型 VALL-E，并提出了一种 speaker-aware 文本编码器和一种基于 frame-level 的音响解码器。</li>
<li>results: 实验结果显示，该模型在自然性和 speaker 相似性方面比基eline 高，并可以通过提高 style prompt 的长度来提高性能。<details>
<summary>Abstract</summary>
Zero-shot text-to-speech (TTS) synthesis aims to clone any unseen speaker's voice without adaptation parameters. By quantizing speech waveform into discrete acoustic tokens and modeling these tokens with the language model, recent language model-based TTS models show zero-shot speaker adaptation capabilities with only a 3-second acoustic prompt of an unseen speaker. However, they are limited by the length of the acoustic prompt, which makes it difficult to clone personal speaking style. In this paper, we propose a novel zero-shot TTS model with the multi-scale acoustic prompts based on a neural codec language model VALL-E. A speaker-aware text encoder is proposed to learn the personal speaking style at the phoneme-level from the style prompt consisting of multiple sentences. Following that, a VALL-E based acoustic decoder is utilized to model the timbre from the timbre prompt at the frame-level and generate speech. The experimental results show that our proposed method outperforms baselines in terms of naturalness and speaker similarity, and can achieve better performance by scaling out to a longer style prompt.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate("Zero-shot text-to-speech（TTS）Synthesis aims to clone any unseen speaker's voice without adaptation parameters. By quantizing speech waveform into discrete acoustic tokens and modeling these tokens with the language model, recent language model-based TTS models show zero-shot speaker adaptation capabilities with only a 3-second acoustic prompt of an unseen speaker. However, they are limited by the length of the acoustic prompt, which makes it difficult to clone personal speaking style. In this paper, we propose a novel zero-shot TTS model with the multi-scale acoustic prompts based on a neural codec language model VALL-E. A speaker-aware text encoder is proposed to learn the personal speaking style at the phoneme-level from the style prompt consisting of multiple sentences. Following that, a VALL-E based acoustic decoder is utilized to model the timbre from the timbre prompt at the frame-level and generate speech. The experimental results show that our proposed method outperforms baselines in terms of naturalness and speaker similarity, and can achieve better performance by scaling out to a longer style prompt.")中文简体版：Zero-shot文本到语音（TTS）synthesis目标是将未看过的说话者的声音复制到新的语音系统中，无需适应参数。通过将语音波形转换为精确的语音符号，并使用语言模型来模型这些符号，现有的语言模型基于TTS模型已经实现了零shot说话者适应能力，只需要3秒钟的未看过说话者的声音提示。然而，它们受到声音提示的长度限制，making it difficult to clone personal speaking style。在这篇论文中，我们提出了一种基于neural codec语言模型VALL-E的新的零shotTTS模型。我们提出了一种 speaker-aware文本编码器，用于从多句式样本中学习个人说话风格的phoneme级别。然后，我们使用VALL-E基于的语音解码器来模型timbre在frame级别，并生成语音。实验结果表明，我们的提出方法可以超越基eline，在自然性和说话者相似性方面表现更好，并可以通过扩展style提示来提高性能。
</details></li>
</ul>
<hr>
<h2 id="Multi-Channel-MOSRA-Mean-Opinion-Score-and-Room-Acoustics-Estimation-Using-Simulated-Data-and-a-Teacher-Model"><a href="#Multi-Channel-MOSRA-Mean-Opinion-Score-and-Room-Acoustics-Estimation-Using-Simulated-Data-and-a-Teacher-Model" class="headerlink" title="Multi-Channel MOSRA: Mean Opinion Score and Room Acoustics Estimation Using Simulated Data and a Teacher Model"></a>Multi-Channel MOSRA: Mean Opinion Score and Room Acoustics Estimation Using Simulated Data and a Teacher Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11976">http://arxiv.org/abs/2309.11976</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jozef Coldenhoff, Andrew Harper, Paul Kendrick, Tijana Stojkovic, Milos Cernak</li>
<li>for: 预测房间声学参数和沟通质量指标</li>
<li>methods: 使用多通道模型进行同时预测多个 recordingdevice 的 MOS 和房间声学参数</li>
<li>results: 提高了直接响应率、清晰度和语音传输指标的预测，相比单通道模型，需要约5倍 menos计算资源，但是减少了其他指标的性能表现的loss。<details>
<summary>Abstract</summary>
Previous methods for predicting room acoustic parameters and speech quality metrics have focused on the single-channel case, where room acoustics and Mean Opinion Score (MOS) are predicted for a single recording device. However, quality-based device selection for rooms with multiple recording devices may benefit from a multi-channel approach where the descriptive metrics are predicted for multiple devices in parallel. Following our hypothesis that a model may benefit from multi-channel training, we develop a multi-channel model for joint MOS and room acoustics prediction (MOSRA) for five channels in parallel. The lack of multi-channel audio data with ground truth labels necessitated the creation of simulated data using an acoustic simulator with room acoustic labels extracted from the generated impulse responses and labels for MOS generated in a student-teacher setup using a wav2vec2-based MOS prediction model. Our experiments show that the multi-channel model improves the prediction of the direct-to-reverberation ratio, clarity, and speech transmission index over the single-channel model with roughly 5$\times$ less computation while suffering minimal losses in the performance of the other metrics.
</details>
<details>
<summary>摘要</summary>
因为前面的方法都是单通道的，所以我们假设多通道训练可能会提高模型的性能。我们开发了一个同时预测多个通道的MOS和房间听音参数的模型（MOSRA），并在五个通道上进行了并行预测。由于没有多通道音频数据的标签，我们使用了一个听音器模拟器生成的房间听音标签，并使用了基于wav2vec2的MOS预测模型生成的教师-学生组合中的标签。我们的实验表明，多通道模型在直接响应比、清晰度和语音传输指数方面的预测性能有5倍以下的计算量，而且对其他指标的性能几乎不受影响。
</details></li>
</ul>
<hr>
<h2 id="Cluster-based-pruning-techniques-for-audio-data"><a href="#Cluster-based-pruning-techniques-for-audio-data" class="headerlink" title="Cluster-based pruning techniques for audio data"></a>Cluster-based pruning techniques for audio data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11922">http://arxiv.org/abs/2309.11922</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/boris-bergsma/audio_pruning">https://github.com/boris-bergsma/audio_pruning</a></li>
<li>paper_authors: Boris Bergsma, Marta Brzezinska, Oleg V. Yazyev, Milos Cernak</li>
<li>for: 提高深度学习模型在各个领域的性能，减少数据量以提高计算效率。</li>
<li>methods: 使用k-means clustering方法对数据进行有效的 selección，将相似样本 grouped  вместе，减少数据量而保持分类表达能力。</li>
<li>results: 在关键词检测（KWS）数据集上进行 clustering分析，显示k-means clustering可以减少音频数据集的大小，保持不同架构NNs的分类性能。<details>
<summary>Abstract</summary>
Deep learning models have become widely adopted in various domains, but their performance heavily relies on a vast amount of data. Datasets often contain a large number of irrelevant or redundant samples, which can lead to computational inefficiencies during the training. In this work, we introduce, for the first time in the context of the audio domain, the k-means clustering as a method for efficient data pruning. K-means clustering provides a way to group similar samples together, allowing the reduction of the size of the dataset while preserving its representative characteristics. As an example, we perform clustering analysis on the keyword spotting (KWS) dataset. We discuss how k-means clustering can significantly reduce the size of audio datasets while maintaining the classification performance across neural networks (NNs) with different architectures. We further comment on the role of scaling analysis in identifying the optimal pruning strategies for a large number of samples. Our studies serve as a proof-of-principle, demonstrating the potential of data selection with distance-based clustering algorithms for the audio domain and highlighting promising research avenues.
</details>
<details>
<summary>摘要</summary>
Note:* "Deep learning models" is translated as "深度学习模型" (shēn dào xué xí mó del)* "datasets" is translated as "数据集" (data set)* "k-means clustering" is translated as "k-means 聚合" (k-means zù hé)* "keywords spotting" is translated as "关键词检测" (guān jí xiē jiàn dòu)* "neural networks" is translated as "神经网络" (shén xiāo wǎng luò)
</details></li>
</ul>
<hr>
<h2 id="The-Impact-of-Silence-on-Speech-Anti-Spoofing"><a href="#The-Impact-of-Silence-on-Speech-Anti-Spoofing" class="headerlink" title="The Impact of Silence on Speech Anti-Spoofing"></a>The Impact of Silence on Speech Anti-Spoofing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11827">http://arxiv.org/abs/2309.11827</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxiang Zhang, Zhuo Li, Jingze Lu, Hua Hua, Wenchao Wang, Pengyuan Zhang</li>
<li>for: 这个论文旨在分析防 spoofing Countermeasures 对干扰声音的影响。</li>
<li>methods: 该论文使用了 Voice Activity Detection (VAD) 技术和 class activation mapping (CAM) 来分析干扰声音对防 spoofing CMs 的影响。</li>
<li>results: 研究发现，对 spoof speech 进行干扰声音 removing 可能会导致 CMs 的性能下降。此外，研究还发现了干扰声音的内容和长度的影响，以及如何通过masking silence或non-silence来提高 CMs 的Robustness。<details>
<summary>Abstract</summary>
The current speech anti-spoofing countermeasures (CMs) show excellent performance on specific datasets. However, removing the silence of test speech through Voice Activity Detection (VAD) can severely degrade performance. In this paper, the impact of silence on speech anti-spoofing is analyzed. First, the reasons for the impact are explored, including the proportion of silence duration and the content of silence. The proportion of silence duration in spoof speech generated by text-to-speech (TTS) algorithms is lower than that in bonafide speech. And the content of silence generated by different waveform generators varies compared to bonafide speech. Then the impact of silence on model prediction is explored. Even after retraining, the spoof speech generated by neural network based end-to-end TTS algorithms suffers a significant rise in error rates when the silence is removed. To demonstrate the reasons for the impact of silence on CMs, the attention distribution of a CM is visualized through class activation mapping (CAM). Furthermore, the implementation and analysis of the experiments masking silence or non-silence demonstrates the significance of the proportion of silence duration for detecting TTS and the importance of silence content for detecting voice conversion (VC). Based on the experimental results, improving the robustness of CMs against unknown spoofing attacks by masking silence is also proposed. Finally, the attacks on anti-spoofing CMs through concatenating silence, and the mitigation of VAD and silence attack through low-pass filtering are introduced.
</details>
<details>
<summary>摘要</summary>
当前的语音反伪措施（CMs）在特定的数据集上表现出色。然而，通过语音活动检测（VAD）来除去测试语音的沉默部分可能会严重降低性能。在这篇论文中，我们分析了语音反伪措施中的沉默的影响。首先，我们研究了沉默的影响原因，包括沉默部分的持续时间比例和沉默部分的内容。TTS算法生成的假语音中的沉默部分持续时间比例较低，而bonafide语音中的沉默部分持续时间比例较高。此外，不同的波形生成器生成的沉默部分与bonafide语音中的沉默部分存在差异。然后，我们研究了沉默对模型预测的影响。即使重新训练，使用基于神经网络的端到端TTS算法生成的假语音在去除沉默后 Error rates 显著增加。为了证明沉默对CMs的影响的原因，我们通过类Activation mapping（CAM） visualize CM的注意力分布。此外，我们还实现了在掩码沉默或非沉默时对实验的分析，这些实验结果表明了沉默持续时间的重要性以及沉默内容的重要性。最后，我们提出了通过掩码沉默来提高CMs对未知假语音攻击的Robustness。此外，我们还介绍了 concatenating silence 攻击和 VAD 和沉默攻击的低通过滤波来 Mitigation。
</details></li>
</ul>
<hr>
<h2 id="Frame-Pairwise-Distance-Loss-for-Weakly-supervised-Sound-Event-Detection"><a href="#Frame-Pairwise-Distance-Loss-for-Weakly-supervised-Sound-Event-Detection" class="headerlink" title="Frame Pairwise Distance Loss for Weakly-supervised Sound Event Detection"></a>Frame Pairwise Distance Loss for Weakly-supervised Sound Event Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11783">http://arxiv.org/abs/2309.11783</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui Tao, Yuxing Huang, Xiangdong Wang, Long Yan, Lufeng Zhai, Kazushige Ouchi, Taihao Li</li>
<li>for:  bridging the gap between fully supervised methods and unsupervised techniques in various domains, specifically for detecting sound events with limited labeled data.</li>
<li>methods: introducing a Frame Pairwise Distance (FPD) loss branch, along with a minimal amount of synthesized data and corresponding sampling and label processing strategies.</li>
<li>results: validated on the standard DCASE dataset, the proposed approach showed efficacy and improved the recognition rate of weakly-supervised sound event detection.<details>
<summary>Abstract</summary>
Weakly-supervised learning has emerged as a promising approach to leverage limited labeled data in various domains by bridging the gap between fully supervised methods and unsupervised techniques. Acquisition of strong annotations for detecting sound events is prohibitively expensive, making weakly supervised learning a more cost-effective and broadly applicable alternative. In order to enhance the recognition rate of the learning of detection of weakly-supervised sound events, we introduce a Frame Pairwise Distance (FPD) loss branch, complemented with a minimal amount of synthesized data. The corresponding sampling and label processing strategies are also proposed. Two distinct distance metrics are employed to evaluate the proposed approach. Finally, the method is validated on the standard DCASE dataset. The obtained experimental results corroborated the efficacy of this approach.
</details>
<details>
<summary>摘要</summary>
弱监督学习已成为各领域中利用有限标注数据的有力的方法之一，它将完全监督方法和无监督技术相连接起来，从而bridge难以估计的差距。为了提高弱监督声音事件的识别率，我们引入了帧对Distance（FPD）损失支线，并补充了一小量的合成数据。对应的采样和标签处理策略也被提出。两种不同的距离度量被使用来评估该方法。最后，方法在标准的DCASE数据集上进行验证，实验结果证明了该方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="CoMFLP-Correlation-Measure-based-Fast-Search-on-ASR-Layer-Pruning"><a href="#CoMFLP-Correlation-Measure-based-Fast-Search-on-ASR-Layer-Pruning" class="headerlink" title="CoMFLP: Correlation Measure based Fast Search on ASR Layer Pruning"></a>CoMFLP: Correlation Measure based Fast Search on ASR Layer Pruning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11768">http://arxiv.org/abs/2309.11768</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/louislau1129/comflp">https://github.com/louislau1129/comflp</a></li>
<li>paper_authors: Wei Liu, Zhiyuan Peng, Tan Lee</li>
<li>for: 提高资源受限设备上Transformer-based语音识别（ASR）模型的性能。</li>
<li>methods: 使用层架减少（LP）方法来减少模型中的层数，并使用相关度度量来评估层之间的重复性。</li>
<li>results: 比较 existed LP 方法，CoMFLP 可以更好地选择减少的层数，同时只需要常量时间复杂度。实验结果表明，由 CoMFLP 确定的减少提议超过了现有 LP 方法的性能。代码可以在 <a target="_blank" rel="noopener" href="https://github.com/louislau1129/CoMFLP">https://github.com/louislau1129/CoMFLP</a> 上获取。<details>
<summary>Abstract</summary>
Transformer-based speech recognition (ASR) model with deep layers exhibited significant performance improvement. However, the model is inefficient for deployment on resource-constrained devices. Layer pruning (LP) is a commonly used compression method to remove redundant layers. Previous studies on LP usually identify the redundant layers according to a task-specific evaluation metric. They are time-consuming for models with a large number of layers, even in a greedy search manner. To address this problem, we propose CoMFLP, a fast search LP algorithm based on correlation measure. The correlation between layers is computed to generate a correlation matrix, which identifies the redundancy among layers. The search process is carried out in two steps: (1) coarse search: to determine top $K$ candidates by pruning the most redundant layers based on the correlation matrix; (2) fine search: to select the best pruning proposal among $K$ candidates using a task-specific evaluation metric. Experiments on an ASR task show that the pruning proposal determined by CoMFLP outperforms existing LP methods while only requiring constant time complexity. The code is publicly available at https://github.com/louislau1129/CoMFLP.
</details>
<details>
<summary>摘要</summary>
“trasformer基于的语音识别（ASR）模型中深层显示了性能提升。然而，这种模型在资源受限的设备上部署不是非常高效。层束（LP）是一种常用压缩方法，可以从模型中除掉 redundant 层。先前的研究通常根据任务特定的评价指标来确定级别的重复性。这些方法在大量层的情况下，甚至在批处理方式下，都需要较长的时间。为解决这个问题，我们提出了 CoMFLP，一种快速搜索 LP 算法，基于相关度计算。在这种算法中， Compute 层之间的相关度，生成一个相关矩阵，并且在这个矩阵中找到最 redundant 层。搜索过程分为两步：（1）粗略搜索：根据相关矩阵，先找到 top K 个候选项，其中 K 是一个固定的整数；（2）细致搜索：使用任务特定的评价指标，从 K 个候选项中选择最佳剪除提议。实验结果表明，由 CoMFLP 确定的剪除提议，在 ASR 任务中能够超越现有的 LP 方法，而且只需要常量时间复杂度。代码可以在 https://github.com/louislau1129/CoMFLP 上找到。”
</details></li>
</ul>
<hr>
<h2 id="Sparsely-Shared-LoRA-on-Whisper-for-Child-Speech-Recognition"><a href="#Sparsely-Shared-LoRA-on-Whisper-for-Child-Speech-Recognition" class="headerlink" title="Sparsely Shared LoRA on Whisper for Child Speech Recognition"></a>Sparsely Shared LoRA on Whisper for Child Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11756">http://arxiv.org/abs/2309.11756</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Liu, Ying Qin, Zhiyuan Peng, Tan Lee</li>
<li>for: 这 paper 的目的是提高 Whisper 自动话语识别（ASR）模型的零基础性性能。</li>
<li>methods: 这 paper 使用的方法包括 parameter-efficient fine-tuning (PEFT) 和 LoRA 等方法，以及一种新的 Sparsely Shared LoRA (S2-LoRA) 方法。</li>
<li>results: 实验结果表明，S2-LoRA 方法可以在低资源的中文儿童语音上达到与 AdaLoRA 相当的适应性，并且在对应数据上表现更好的泛化性。此外，S2-LoRA 方法自动学习的核心矩阵分布与 AdaLoRA 的分布有类似的特征。<details>
<summary>Abstract</summary>
Whisper is a powerful automatic speech recognition (ASR) model. Nevertheless, its zero-shot performance on low-resource speech requires further improvement. Child speech, as a representative type of low-resource speech, is leveraged for adaptation. Recently, parameter-efficient fine-tuning (PEFT) in NLP was shown to be comparable and even better than full fine-tuning, while only needing to tune a small set of trainable parameters. However, current PEFT methods have not been well examined for their effectiveness on Whisper. In this paper, only parameter composition types of PEFT approaches such as LoRA and Bitfit are investigated as they do not bring extra inference costs. Different popular PEFT methods are examined. Particularly, we compare LoRA and AdaLoRA and figure out the learnable rank coefficient is a good design. Inspired by the sparse rank distribution allocated by AdaLoRA, a novel PEFT approach Sparsely Shared LoRA (S2-LoRA) is proposed. The two low-rank decomposed matrices are globally shared. Each weight matrix only has to maintain its specific rank coefficients that are constrained to be sparse. Experiments on low-resource Chinese child speech show that with much fewer trainable parameters, S2-LoRA can achieve comparable in-domain adaptation performance to AdaLoRA and exhibit better generalization ability on out-of-domain data. In addition, the rank distribution automatically learned by S2-LoRA is found to have similar patterns to AdaLoRA's allocation.
</details>
<details>
<summary>摘要</summary>
喊voice是一款强大的自动语音识别（ASR）模型。然而，它在低资源语音的零shot性表现仍需要进一步改进。儿童语音作为低资源语音的代表类型，被用于适应。近期， parameter-efficient fine-tuning（PEFT）在NLP中被证明可以与全量精度相当，而只需要调整一小部分的可变参数。然而，当前PEFT方法尚未对喊voice进行了深入研究。本文仅 investigate parameter composition type的PEFT方法，如LoRA和Bitfit，因为它们不会增加额外的推理成本。不同的Popular PEFT方法被比较。特别是，我们比较LoRA和AdaLoRA，并发现了可学习排名系数是一个好设计。受AdaLoRA的稀疑rank分布启发，我们提出了一种新的PEFT方法，即Sparsely Shared LoRA（S2-LoRA）。两个低级别分解的矩阵都是全局分享的。每个weight矩阵只需要保持它的特定排名系数，这些系数被限制为稀疑分布。实验表明，S2-LoRA可以在低资源中文儿童语音上 достичь与AdaLoRA相同的适应性，并且在非适应数据上表现更好。此外，S2-LoRA自动学习的排名分布与AdaLoRA的分布相似。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-In-the-Wild-Data-for-Effective-Self-Supervised-Pretraining-in-Speaker-Recognition"><a href="#Leveraging-In-the-Wild-Data-for-Effective-Self-Supervised-Pretraining-in-Speaker-Recognition" class="headerlink" title="Leveraging In-the-Wild Data for Effective Self-Supervised Pretraining in Speaker Recognition"></a>Leveraging In-the-Wild Data for Effective Self-Supervised Pretraining in Speaker Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11730">http://arxiv.org/abs/2309.11730</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wenet-e2e/wespeaker">https://github.com/wenet-e2e/wespeaker</a></li>
<li>paper_authors: Shuai Wang, Qibing Bai, Qi Liu, Jianwei Yu, Zhengyang Chen, Bing Han, Yanmin Qian, Haizhou Li</li>
<li>for: 本研究目的是提高current speaker recognition系统的性能，通过将大规模预训练模型（如WavLM）传递到下游任务中，以及直接应用自我超vised方法（如DINO）进行 speaker embedding 学习。</li>
<li>methods: 本研究使用了DINO自我超vised方法进行 speaker embedding 学习，并在大规模的WenetSpeech dataset上进行了预训练。在这个过程中，我们还提出了一种基于信任度的数据过滤算法，以提高预训练数据的可靠性。</li>
<li>results: 研究结果表明，通过使用DINO自我超vised方法和 confidence-based 数据过滤算法，可以提高speaker recognition系统的性能，并且在大规模的in-the-wild datasets上保持良好的表现。此外，我们还发现了这种方法的可迁移性，可以在不同的 dataset 上提高系统性能。<details>
<summary>Abstract</summary>
Current speaker recognition systems primarily rely on supervised approaches, constrained by the scale of labeled datasets. To boost the system performance, researchers leverage large pretrained models such as WavLM to transfer learned high-level features to the downstream speaker recognition task. However, this approach introduces extra parameters as the pretrained model remains in the inference stage. Another group of researchers directly apply self-supervised methods such as DINO to speaker embedding learning, yet they have not explored its potential on large-scale in-the-wild datasets. In this paper, we present the effectiveness of DINO training on the large-scale WenetSpeech dataset and its transferability in enhancing the supervised system performance on the CNCeleb dataset. Additionally, we introduce a confidence-based data filtering algorithm to remove unreliable data from the pretraining dataset, leading to better performance with less training data. The associated pretrained models, confidence files, pretraining and finetuning scripts will be made available in the Wespeaker toolkit.
</details>
<details>
<summary>摘要</summary>
当前的说话识别系统主要依靠supervised方法，受到标注数据的尺度限制。为了提高系统性能，研究人员利用大型预训练模型，如WavLM，将高级特征传递到下游说话识别任务。然而，这种方法添加了额外的参数，因为预训练模型在推理阶段仍然存在。另一组研究人员直接应用自监学方法，如DINO，来学习说话嵌入，但他们没有探索其在大规模在野数据集上的潜力。在这篇论文中，我们介绍了DINO训练在大规模WenetSpeech数据集上的效果，以及其在CNCeleb数据集上的传输性。此外，我们还提出了一种基于信任度的数据过滤算法，以 removal of unreliable data from the pretraining dataset，从而提高supervised系统的性能。相关的预训练模型、信任文件、预训练和Finetuning脚本将在Wespeaker工具箱中提供。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/21/cs.SD_2023_09_21/" data-id="cloqtaewe00wxgh887ctgh3wl" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_09_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/21/cs.CV_2023_09_21/" class="article-date">
  <time datetime="2023-09-21T13:00:00.000Z" itemprop="datePublished">2023-09-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/21/cs.CV_2023_09_21/">cs.CV - 2023-09-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="A-Sentence-Speaks-a-Thousand-Images-Domain-Generalization-through-Distilling-CLIP-with-Language-Guidance"><a href="#A-Sentence-Speaks-a-Thousand-Images-Domain-Generalization-through-Distilling-CLIP-with-Language-Guidance" class="headerlink" title="A Sentence Speaks a Thousand Images: Domain Generalization through Distilling CLIP with Language Guidance"></a>A Sentence Speaks a Thousand Images: Domain Generalization through Distilling CLIP with Language Guidance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12530">http://arxiv.org/abs/2309.12530</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oodbag/rise">https://github.com/oodbag/rise</a></li>
<li>paper_authors: Zeyi Huang, Andy Zhou, Zijian Lin, Mu Cai, Haohan Wang, Yong Jae Lee</li>
<li>for: 这篇论文旨在应用大型感知语言模型（CLIP教师模型）来培训一个更小的模型，使其在未见过的领域中具有普遍性。</li>
<li>methods: 这篇论文提出了一种新的方法，名为RISE（固定不变性与semantic embedding），它使用CLIP教师模型的学习图像表现来对学习过程进行调整。</li>
<li>results: 研究发现，RISE方法可以在多个benchmark数据集上实现更好的领域普遍性，并且比之前的领域普遍性方法更好。<details>
<summary>Abstract</summary>
Domain generalization studies the problem of training a model with samples from several domains (or distributions) and then testing the model with samples from a new, unseen domain. In this paper, we propose a novel approach for domain generalization that leverages recent advances in large vision-language models, specifically a CLIP teacher model, to train a smaller model that generalizes to unseen domains. The key technical contribution is a new type of regularization that requires the student's learned image representations to be close to the teacher's learned text representations obtained from encoding the corresponding text descriptions of images. We introduce two designs of the loss function, absolute and relative distance, which provide specific guidance on how the training process of the student model should be regularized. We evaluate our proposed method, dubbed RISE (Regularized Invariance with Semantic Embeddings), on various benchmark datasets and show that it outperforms several state-of-the-art domain generalization methods. To our knowledge, our work is the first to leverage knowledge distillation using a large vision-language model for domain generalization. By incorporating text-based information, RISE improves the generalization capability of machine learning models.
</details>
<details>
<summary>摘要</summary>
域 generale 研究训练一个模型使用多个域（或分布）的样本，然后测试模型使用新、未经见过的域的样本。在这篇论文中，我们提出了一种新的方法 для域 generale，利用最近的大视语模型，具体来说是 CLIP 教师模型，来训练一个更小的模型，以便在未经见过的域上进行泛化。我们的关键技术贡献是一种新的规范，即要求学生模型学习的图像表示必须与教师模型对图像的文本描述进行编码后获得的文本表示之间很近。我们提出了两种损失函数的设计：绝对距离和相对距离，它们为训练学生模型的规范过程提供了特定的指导。我们称之为 RISE（固有协调 with 语义嵌入）。我们对多个标准测试集进行评估，并证明我们的提出方法可以超越一些状态实际的域泛化方法。我们知道，我们的工作是首次利用知识填充大视语模型来实现域泛化。通过包含文本信息，RISE 可以提高机器学习模型的泛化能力。
</details></li>
</ul>
<hr>
<h2 id="License-Plate-Super-Resolution-Using-Diffusion-Models"><a href="#License-Plate-Super-Resolution-Using-Diffusion-Models" class="headerlink" title="License Plate Super-Resolution Using Diffusion Models"></a>License Plate Super-Resolution Using Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12506">http://arxiv.org/abs/2309.12506</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sawsan AlHalawani, Bilel Benjdira, Adel Ammar, Anis Koubaa, Anas M. Ali<br>for: 这个研究旨在提高识别车牌的精度，并且对于surveillance系统中的车牌识别有实际的应用。methods: 本研究使用了cutting-edge diffusion model，并通过对沙乌地车牌 dataset的训练，以提高车牌图像的Restoration。results: 研究发现，diffusion model在车牌图像Restoration中表现出色，与SwinIR和ESRGAN相比，它在PSNR和SSIM上分别提高了12.55%和37.32%，并且92%的人类评审者对于我们的图像有所喜欢。<details>
<summary>Abstract</summary>
In surveillance, accurately recognizing license plates is hindered by their often low quality and small dimensions, compromising recognition precision. Despite advancements in AI-based image super-resolution, methods like Convolutional Neural Networks (CNNs) and Generative Adversarial Networks (GANs) still fall short in enhancing license plate images. This study leverages the cutting-edge diffusion model, which has consistently outperformed other deep learning techniques in image restoration. By training this model using a curated dataset of Saudi license plates, both in low and high resolutions, we discovered the diffusion model's superior efficacy. The method achieves a 12.55\% and 37.32% improvement in Peak Signal-to-Noise Ratio (PSNR) over SwinIR and ESRGAN, respectively. Moreover, our method surpasses these techniques in terms of Structural Similarity Index (SSIM), registering a 4.89% and 17.66% improvement over SwinIR and ESRGAN, respectively. Furthermore, 92% of human evaluators preferred our images over those from other algorithms. In essence, this research presents a pioneering solution for license plate super-resolution, with tangible potential for surveillance systems.
</details>
<details>
<summary>摘要</summary>
surveillance中，因license plate的低质量和小尺寸，识别精度受到阻碍。尽管人工智能基于图像超分辨技术如Convolutional Neural Networks (CNNs)和Generative Adversarial Networks (GANs)已经取得了进步，但这些方法仍然无法提高license plate图像的识别精度。这项研究利用了当今最佳的扩散模型，通过使用精心制作的Saudi license plates数据集，并在低和高分辨率下训练这个模型，我们发现了这个模型在图像恢复方面的超越。这种方法在PSNR指标上提高12.55%和37.32%，并在SSIM指标上提高4.89%和17.66%，相比SwirIR和ESRGAN。此外，92%的人类评估者偏好了我们的图像。简而言之，这项研究提供了一种领先的license plate超分辨技术，具有实际应用的潜在价值。
</details></li>
</ul>
<hr>
<h2 id="Impact-of-architecture-on-robustness-and-interpretability-of-multispectral-deep-neural-networks"><a href="#Impact-of-architecture-on-robustness-and-interpretability-of-multispectral-deep-neural-networks" class="headerlink" title="Impact of architecture on robustness and interpretability of multispectral deep neural networks"></a>Impact of architecture on robustness and interpretability of multispectral deep neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12463">http://arxiv.org/abs/2309.12463</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hendrycks/robustness">https://github.com/hendrycks/robustness</a></li>
<li>paper_authors: Charles Godfrey, Elise Bishoff, Myles McKay, Eleanor Byler</li>
<li>for: 这种研究是为了探讨不同的融合策略如何改善多光谱深度学习模型在视觉任务中表现。</li>
<li>methods: 这些模型使用了不同的融合方法，包括早期融合和晚期融合。早期融合将额外频谱通道与RGB频谱通道一起堆叠成一个高达多个频谱通道的输入图像。晚期融合则是将RGB和非RGB频谱通道通过不同的深度学习模型分支，并在最终分类或分割层前进行融合。</li>
<li>results: 这些模型的表现被评估，并分析了它们对自然主义图像损害的 robustness。研究发现，早期融合和晚期融合的表现差异较大，而且不同的输入频谱通道之间的融合方式对模型的性能有着不同的影响。<details>
<summary>Abstract</summary>
Including information from additional spectral bands (e.g., near-infrared) can improve deep learning model performance for many vision-oriented tasks. There are many possible ways to incorporate this additional information into a deep learning model, but the optimal fusion strategy has not yet been determined and can vary between applications. At one extreme, known as "early fusion," additional bands are stacked as extra channels to obtain an input image with more than three channels. At the other extreme, known as "late fusion," RGB and non-RGB bands are passed through separate branches of a deep learning model and merged immediately before a final classification or segmentation layer. In this work, we characterize the performance of a suite of multispectral deep learning models with different fusion approaches, quantify their relative reliance on different input bands and evaluate their robustness to naturalistic image corruptions affecting one or more input channels.
</details>
<details>
<summary>摘要</summary>
可以包含更多 спектраль频谱信息（例如近红外）可以提高深度学习模型对视觉任务的性能。有多种方式可以将这些额外信息integrated到深度学习模型中，但最佳的融合策略尚未确定，可能因应用场景不同而异。一种方法是“早期融合”，其中附加的频谱通道与RGB频谱合并为多通道输入图像。另一种方法是“晚期融合”，RGB和非RGB频谱通道通过不同的深度学习模型分支进行处理，并在最后的分类或分割层进行融合。本工作将characterize不同融合方法的多spectral深度学习模型的性能，量化它们对不同输入频谱通道的依赖度，以及它们对自然场景中图像损害的Robustness。
</details></li>
</ul>
<hr>
<h2 id="DIOR-Dataset-for-Indoor-Outdoor-Reidentification-–-Long-Range-3D-2D-Skeleton-Gait-Collection-Pipeline-Semi-Automated-Gait-Keypoint-Labeling-and-Baseline-Evaluation-Methods"><a href="#DIOR-Dataset-for-Indoor-Outdoor-Reidentification-–-Long-Range-3D-2D-Skeleton-Gait-Collection-Pipeline-Semi-Automated-Gait-Keypoint-Labeling-and-Baseline-Evaluation-Methods" class="headerlink" title="DIOR: Dataset for Indoor-Outdoor Reidentification – Long Range 3D&#x2F;2D Skeleton Gait Collection Pipeline, Semi-Automated Gait Keypoint Labeling and Baseline Evaluation Methods"></a>DIOR: Dataset for Indoor-Outdoor Reidentification – Long Range 3D&#x2F;2D Skeleton Gait Collection Pipeline, Semi-Automated Gait Keypoint Labeling and Baseline Evaluation Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12429">http://arxiv.org/abs/2309.12429</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuyang Chen, Praveen Raj Masilamani, Bhavin Jawade, Srirangaraj Setlur, Karthik Dantu</li>
<li>for: 本研究旨在提供一个数据收集框架和半自动标注方法，以及一个包含14名受试者和1649万帧RGB帧的数据集，以便进行人体识别和重新识别。</li>
<li>methods: 本研究使用了进阶的3D计算机视觉技术来实现像素精度的人体识别，并且在室内设置中使用动作捕捉系统来进行标注。在外部长距离设置中，我们使用了一个低成本的Hybrid3D计算机视觉和学习架构，只需4个低成本的RGB摄像头，成功地实现了精确的骨架标注，甚至在距离较远的对象中，其高度仅限于20-25像素。</li>
<li>results: 本研究获得了精确的骨架标注结果，包括200,000帧的长距离摄像头标注。<details>
<summary>Abstract</summary>
In recent times, there is an increased interest in the identification and re-identification of people at long distances, such as from rooftop cameras, UAV cameras, street cams, and others. Such recognition needs to go beyond face and use whole-body markers such as gait. However, datasets to train and test such recognition algorithms are not widely prevalent, and fewer are labeled. This paper introduces DIOR -- a framework for data collection, semi-automated annotation, and also provides a dataset with 14 subjects and 1.649 million RGB frames with 3D/2D skeleton gait labels, including 200 thousands frames from a long range camera. Our approach leverages advanced 3D computer vision techniques to attain pixel-level accuracy in indoor settings with motion capture systems. Additionally, for outdoor long-range settings, we remove the dependency on motion capture systems and adopt a low-cost, hybrid 3D computer vision and learning pipeline with only 4 low-cost RGB cameras, successfully achieving precise skeleton labeling on far-away subjects, even when their height is limited to a mere 20-25 pixels within an RGB frame. On publication, we will make our pipeline open for others to use.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Synthetic-Image-Detection-Highlights-from-the-IEEE-Video-and-Image-Processing-Cup-2022-Student-Competition"><a href="#Synthetic-Image-Detection-Highlights-from-the-IEEE-Video-and-Image-Processing-Cup-2022-Student-Competition" class="headerlink" title="Synthetic Image Detection: Highlights from the IEEE Video and Image Processing Cup 2022 Student Competition"></a>Synthetic Image Detection: Highlights from the IEEE Video and Image Processing Cup 2022 Student Competition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12428">http://arxiv.org/abs/2309.12428</a></li>
<li>repo_url: None</li>
<li>paper_authors: Davide Cozzolino, Koki Nagano, Lucas Thomaz, Angshul Majumdar, Luisa Verdoliva</li>
<li>for: 本研究旨在开发一种能够分辨真实图像和生成图像的系统，以满足现在AI生成图像技术的快速发展和媒体内容的可靠性问题。</li>
<li>methods: 本研究使用了一种基于Diffusion Models的生成图像检测方法，通过分析图像的扩散特征来 отличи出真实图像和生成图像。</li>
<li>results: 研究结果表明，该方法可以准确地分辨真实图像和生成图像，并且可以承受大量的生成图像。这种方法有广泛的应用前景，可以用于媒体内容的可靠性检测和识别生成图像。<details>
<summary>Abstract</summary>
The Video and Image Processing (VIP) Cup is a student competition that takes place each year at the IEEE International Conference on Image Processing. The 2022 IEEE VIP Cup asked undergraduate students to develop a system capable of distinguishing pristine images from generated ones. The interest in this topic stems from the incredible advances in the AI-based generation of visual data, with tools that allows the synthesis of highly realistic images and videos. While this opens up a large number of new opportunities, it also undermines the trustworthiness of media content and fosters the spread of disinformation on the internet. Recently there was strong concern about the generation of extremely realistic images by means of editing software that includes the recent technology on diffusion models. In this context, there is a need to develop robust and automatic tools for synthetic image detection.
</details>
<details>
<summary>摘要</summary>
《视频和图像处理（VIP）杯赛》是每年在IEEE国际图像处理会议上举行的学生比赛。2022年IEEE VIP杯赛要求了本科生开发一个能够分辨真实图像和生成图像的系统。这个主题的兴趣源于人工智能在生成视频数据方面的异常进步，具有生成高度真实的图像和视频的工具。然而，这也导致媒体内容的可信度受到了损害，促使虚假信息在互联网上广泛传播。最近，对于使用扩散模型生成高度真实图像的技术表示了强烈的关注。在这种情况下，需要开发一些自动和可靠的生成图像检测工具。
</details></li>
</ul>
<hr>
<h2 id="DualToken-ViT-Position-aware-Efficient-Vision-Transformer-with-Dual-Token-Fusion"><a href="#DualToken-ViT-Position-aware-Efficient-Vision-Transformer-with-Dual-Token-Fusion" class="headerlink" title="DualToken-ViT: Position-aware Efficient Vision Transformer with Dual Token Fusion"></a>DualToken-ViT: Position-aware Efficient Vision Transformer with Dual Token Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12424">http://arxiv.org/abs/2309.12424</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenzhen Chu, Jiayu Chen, Cen Chen, Chengyu Wang, Ziheng Wu, Jun Huang, Weining Qian</li>
<li>for: 这个研究的目的是提出一个轻量级和高效的Computer Vision Transformer（ViT）模型，以获得更好的Computer Vision任务效果。</li>
<li>methods: 这个模型使用了一种称为DualToken-ViT的新型自注意力架构，具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有具有�<details>
<summary>Abstract</summary>
Self-attention-based vision transformers (ViTs) have emerged as a highly competitive architecture in computer vision. Unlike convolutional neural networks (CNNs), ViTs are capable of global information sharing. With the development of various structures of ViTs, ViTs are increasingly advantageous for many vision tasks. However, the quadratic complexity of self-attention renders ViTs computationally intensive, and their lack of inductive biases of locality and translation equivariance demands larger model sizes compared to CNNs to effectively learn visual features. In this paper, we propose a light-weight and efficient vision transformer model called DualToken-ViT that leverages the advantages of CNNs and ViTs. DualToken-ViT effectively fuses the token with local information obtained by convolution-based structure and the token with global information obtained by self-attention-based structure to achieve an efficient attention structure. In addition, we use position-aware global tokens throughout all stages to enrich the global information, which further strengthening the effect of DualToken-ViT. Position-aware global tokens also contain the position information of the image, which makes our model better for vision tasks. We conducted extensive experiments on image classification, object detection and semantic segmentation tasks to demonstrate the effectiveness of DualToken-ViT. On the ImageNet-1K dataset, our models of different scales achieve accuracies of 75.4% and 79.4% with only 0.5G and 1.0G FLOPs, respectively, and our model with 1.0G FLOPs outperforms LightViT-T using global tokens by 0.7%.
</details>
<details>
<summary>摘要</summary>
自注意力基于视transformer（ViT）在计算机视觉领域已经出现为非常竞争力的建筑。不同于卷积神经网络（CNN），ViT可以共享全局信息。随着不同类型的ViT的开发，ViT在许多视觉任务上变得越来越有利。然而，自注意力的 quadratic complexity使得ViT computationally intensive，而且它们没有对于局部性和平移对称性的偏好，因此需要 larger model size compared to CNNs 以有效地学习视觉特征。在这篇文章中，我们提出了一种轻量级和高效的视transformer模型called DualToken-ViT，该模型利用了CNN和ViT的优点。DualToken-ViT通过将token与局部信息通过卷积结构获得的local information和token与全局信息通过自注意力结构获得的global information进行有效的融合，以实现高效的注意结构。此外，我们在所有阶段使用position-aware global tokens，以增强全局信息的效果，这些position-aware global tokens还包含图像的位置信息，使我们的模型更适合视觉任务。我们在ImageNet-1K dataset上进行了广泛的实验，我们的不同规模的模型在分类、物体检测和 semantic segmentation 任务上达到了75.4%和79.4%的准确率，并且我们的1.0G FLOPs模型超过了LightViT-T使用全球token的模型。
</details></li>
</ul>
<hr>
<h2 id="Speeding-up-Resnet-Architecture-with-Layers-Targeted-Low-Rank-Decomposition"><a href="#Speeding-up-Resnet-Architecture-with-Layers-Targeted-Low-Rank-Decomposition" class="headerlink" title="Speeding up Resnet Architecture with Layers Targeted Low Rank Decomposition"></a>Speeding up Resnet Architecture with Layers Targeted Low Rank Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12412">http://arxiv.org/abs/2309.12412</a></li>
<li>repo_url: None</li>
<li>paper_authors: Walid Ahmed, Habib Hajimolahoseini, Austin Wen, Yang Liu</li>
<li>for: 降低神经网络训练和推理的速度</li>
<li>methods: 使用低级别分解来压缩网络层</li>
<li>results: 在Nvidia V100和Huawei Ascend910两种不同硬件系统上实现5.36%的训练速度提升和15.79%的推理速度提升，只有1%的精度下降相比原始不压缩模型<details>
<summary>Abstract</summary>
Compression of a neural network can help in speeding up both the training and the inference of the network. In this research, we study applying compression using low rank decomposition on network layers. Our research demonstrates that to acquire a speed up, the compression methodology should be aware of the underlying hardware as analysis should be done to choose which layers to compress. The advantage of our approach is demonstrated via a case study of compressing ResNet50 and training on full ImageNet-ILSVRC2012. We tested on two different hardware systems Nvidia V100 and Huawei Ascend910. With hardware targeted compression, results on Ascend910 showed 5.36% training speedup and 15.79% inference speed on Ascend310 with only 1% drop in accuracy compared to the original uncompressed model
</details>
<details>
<summary>摘要</summary>
压缩神经网络可以帮助提高神经网络的训练和推断速度。在这项研究中，我们研究了使用低级别分解来压缩神经网络层。我们的研究表明，为了提高速度，压缩方法应该了解下面硬件，并进行分析选择哪些层进行压缩。我们的方法的优点被示例通过压缩ResNet50并在全 ImageNet-ILSVRC2012 上训练。我们在两个不同的硬件系统Nvidia V100和Huawei Ascend910上进行测试。与目标硬件压缩，我们在Ascend910上获得了5.36%的训练速度提升和15.79%的推断速度提升在Ascend310上，只有1%的精度下降相比于原始未压缩模型。
</details></li>
</ul>
<hr>
<h2 id="POLAR3D-Augmenting-NASA’s-POLAR-Dataset-for-Data-Driven-Lunar-Perception-and-Rover-Simulation"><a href="#POLAR3D-Augmenting-NASA’s-POLAR-Dataset-for-Data-Driven-Lunar-Perception-and-Rover-Simulation" class="headerlink" title="POLAR3D: Augmenting NASA’s POLAR Dataset for Data-Driven Lunar Perception and Rover Simulation"></a>POLAR3D: Augmenting NASA’s POLAR Dataset for Data-Driven Lunar Perception and Rover Simulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12397">http://arxiv.org/abs/2309.12397</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/uwsbel/polar-digital">https://github.com/uwsbel/polar-digital</a></li>
<li>paper_authors: Bo-Hsun Chen, Peter Negrut, Thomas Liang, Nevindu Batagoda, Harry Zhang, Dan Negrut</li>
<li>for: 这个论文的目的是提供一个基于NASA的POLAR数据集的三维数据集，用于 lunar 探测和synthesize 高品质的图像。</li>
<li>methods: 这个论文使用了两种方法：首先，对POLAR数据集中的每个照片进行了标注，提供了约23000个岩石和其阴影的标签。其次，利用POLAR的LiDAR点云数据，对月表地形场景进行了数字化。 specifically, the authors constructed detailed obj files for all identifiable assets by utilizing both the lunar photos and the POLAR’s LiDAR point clouds.</li>
<li>results: 这个论文的结果是POLAR3D，一个包含岩石&#x2F;阴影标签和月表地形场景的数字化资产集。这个数据集可以用于训练探测算法、synthesize 高品质图像以及模拟月球环境。<details>
<summary>Abstract</summary>
We report on an effort that led to POLAR3D, a set of digital assets that enhance the POLAR dataset of stereo images generated by NASA to mimic lunar lighting conditions. Our contributions are twofold. First, we have annotated each photo in the POLAR dataset, providing approximately 23 000 labels for rocks and their shadows. Second, we digitized several lunar terrain scenarios available in the POLAR dataset. Specifically, by utilizing both the lunar photos and the POLAR's LiDAR point clouds, we constructed detailed obj files for all identifiable assets. POLAR3D is the set of digital assets comprising of rock/shadow labels and obj files associated with the digital twins of lunar terrain scenarios. This new dataset can be used for training perception algorithms for lunar exploration and synthesizing photorealistic images beyond the original POLAR collection. Likewise, the obj assets can be integrated into simulation environments to facilitate realistic rover operations in a digital twin of a POLAR scenario. POLAR3D is publicly available to aid perception algorithm development, camera simulation efforts, and lunar simulation exercises.POLAR3D is publicly available at https://github.com/uwsbel/POLAR-digital.
</details>
<details>
<summary>摘要</summary>
我们报道了一项工作，它导致了POLAR3D，一组数字资产，用于增强由美国国家航空航天局生成的POLAR数据集中的月球照明条件。我们的贡献是两重。首先，我们为POLAR数据集中每张照片 annotated，提供了约23000个岩石和其阴影的标签。其次，我们利用了月球地表场景的数字图像和POLAR的 LiDAR点云，对可识别的资产进行了详细的数字化。POLAR3D是这些数字资产的集合，包括岩石/阴影标签和与数字双胞虫相关的obj文件。这个新的数据集可以用于训练月球探测的观察算法，并生成超出原始POLAR收集的 fotorealistic 图像。同时，obj资产可以与 simulation 环境集成，以便在数字双胞虫中进行真实的月球车辆操作。POLAR3D公开可用，以便帮助观察算法开发、摄像头模拟和月球 simulations 演练。POLAR3D可以在 GitHub 上找到：https://github.com/uwsbel/POLAR-digital。
</details></li>
</ul>
<hr>
<h2 id="Active-Stereo-Without-Pattern-Projector"><a href="#Active-Stereo-Without-Pattern-Projector" class="headerlink" title="Active Stereo Without Pattern Projector"></a>Active Stereo Without Pattern Projector</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12315">http://arxiv.org/abs/2309.12315</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bartn8/vppstereo">https://github.com/bartn8/vppstereo</a></li>
<li>paper_authors: Luca Bartolomei, Matteo Poggi, Fabio Tosi, Andrea Conti, Stefano Mattoccia</li>
<li>for: 提高标准透镜系统中的活动三维视觉效果，无需物理 patrern projector。</li>
<li>methods: 通过虚拟投影pattern onto left and right images，根据深度感知器的稀缺度量获取。任何设备可以无缝插入我们的框架中，在任何环境下实现虚拟活动三维设置，超越物理 patrern projector的限制，如工作范围或环境条件。</li>
<li>results: 在室内&#x2F;室外 dataset上，包括长距离和近距离的实验，证明了我们的方法的无缝有效性，提高了 both stereo算法和深度网络的准确性。<details>
<summary>Abstract</summary>
This paper proposes a novel framework integrating the principles of active stereo in standard passive camera systems without a physical pattern projector. We virtually project a pattern over the left and right images according to the sparse measurements obtained from a depth sensor. Any such devices can be seamlessly plugged into our framework, allowing for the deployment of a virtual active stereo setup in any possible environment, overcoming the limitation of pattern projectors, such as limited working range or environmental conditions. Experiments on indoor/outdoor datasets, featuring both long and close-range, support the seamless effectiveness of our approach, boosting the accuracy of both stereo algorithms and deep networks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="TinyCLIP-CLIP-Distillation-via-Affinity-Mimicking-and-Weight-Inheritance"><a href="#TinyCLIP-CLIP-Distillation-via-Affinity-Mimicking-and-Weight-Inheritance" class="headerlink" title="TinyCLIP: CLIP Distillation via Affinity Mimicking and Weight Inheritance"></a>TinyCLIP: CLIP Distillation via Affinity Mimicking and Weight Inheritance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12314">http://arxiv.org/abs/2309.12314</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/Cream/tree/main/TinyCLIP">https://github.com/microsoft/Cream/tree/main/TinyCLIP</a></li>
<li>paper_authors: Kan Wu, Houwen Peng, Zhenghong Zhou, Bin Xiao, Mengchen Liu, Lu Yuan, Hong Xuan, Michael Valenzuela, Xi, Chen, Xinggang Wang, Hongyang Chao, Han Hu</li>
<li>for: 这个研究提出了一个新的跨模AL（cross-modal distillation）方法，名为TinyCLIP，用于大规模的语言-图像预训模型。</li>
<li>methods: TinyCLIP方法 introduce two core techniques：互动模式（affinity mimicking）和重量继承（weight inheritance）。互动模式探索了多 modalities during distillation中的互动，使学生模型能够模仿老师模型在视力语言匹配空间中学习跨modal feature alignment。重量继承传递老师模型的预训重量到学生模型，以提高填充效率。</li>
<li>results: 实验结果显示TinyCLIP可以将预训CLIP ViT-B&#x2F;32的大小增加50%，保持相似的零基eline性能。而且，将TinyCLIP与重量继承结合，可以将训练时间速度提高1.4-7.8倍，比较训练从零的效率。此外，我们的TinyCLIP ViT-8M&#x2F;16，在YFCC-15M上训练，在ImageNet上 achieves zero-shot top-1准确率41.1%，比原CLIP ViT-B&#x2F;16高3.5%，同时只使用8.9%的参数。最后，我们显示了TinyCLIP在不同的下游任务中的好转移性。代码和模型将在<a target="_blank" rel="noopener" href="https://aka.ms/tinyclip%E4%B8%8A%E5%85%AC%E5%BC%80%E3%80%82">https://aka.ms/tinyclip上公开。</a><details>
<summary>Abstract</summary>
In this paper, we propose a novel cross-modal distillation method, called TinyCLIP, for large-scale language-image pre-trained models. The method introduces two core techniques: affinity mimicking and weight inheritance. Affinity mimicking explores the interaction between modalities during distillation, enabling student models to mimic teachers' behavior of learning cross-modal feature alignment in a visual-linguistic affinity space. Weight inheritance transmits the pre-trained weights from the teacher models to their student counterparts to improve distillation efficiency. Moreover, we extend the method into a multi-stage progressive distillation to mitigate the loss of informative weights during extreme compression. Comprehensive experiments demonstrate the efficacy of TinyCLIP, showing that it can reduce the size of the pre-trained CLIP ViT-B/32 by 50%, while maintaining comparable zero-shot performance. While aiming for comparable performance, distillation with weight inheritance can speed up the training by 1.4 - 7.8 $\times$ compared to training from scratch. Moreover, our TinyCLIP ViT-8M/16, trained on YFCC-15M, achieves an impressive zero-shot top-1 accuracy of 41.1% on ImageNet, surpassing the original CLIP ViT-B/16 by 3.5% while utilizing only 8.9% parameters. Finally, we demonstrate the good transferability of TinyCLIP in various downstream tasks. Code and models will be open-sourced at https://aka.ms/tinyclip.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种新的跨模态填充方法，叫做TinyCLIP，用于大规模语言图像预训练模型。该方法 introduce two core techniques：对媒体之间的互动进行填充，以及继承权重。对媒体之间的互动可以让学生模型模仿教师的行为，即在视觉语言相互作用空间中学习跨模态特征对齐。继承权重可以将教师模型预训练的权重传递给学生模型，以提高填充效率。此外，我们将方法拓展到多个阶段进行进程式填充，以避免极端压缩中的有用权重的产生。实验表明，TinyCLIP可以将预训练CLIP ViT-B/32的大小减少50%，保持与零shot性能相似。而在尝试保持相似性的情况下，填充与权重继承可以提高训练速度1.4-7.8倍。此外，我们的TinyCLIP ViT-8M/16，在YFCC-15M上训练，在ImageNet上 achieve Zero-shot top-1准确率41.1%，比原CLIP ViT-B/16提高3.5%，同时只使用8.9%的参数。最后，我们展示了TinyCLIP在多个下游任务中的好传输性。代码和模型将在https://aka.ms/tinyclip上开源。
</details></li>
</ul>
<hr>
<h2 id="TalkNCE-Improving-Active-Speaker-Detection-with-Talk-Aware-Contrastive-Learning"><a href="#TalkNCE-Improving-Active-Speaker-Detection-with-Talk-Aware-Contrastive-Learning" class="headerlink" title="TalkNCE: Improving Active Speaker Detection with Talk-Aware Contrastive Learning"></a>TalkNCE: Improving Active Speaker Detection with Talk-Aware Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12306">http://arxiv.org/abs/2309.12306</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chaeyoung Jung, Suyeon Lee, Kihyun Nam, Kyeongha Rho, You Jin Kim, Youngjoon Jang, Joon Son Chung</li>
<li>for: 本研究的目的是提出一种 Active Speaker Detection (ASD) 任务，即在视频帧序中判断一个人是否在说话。先前的工作主要关注网络架构，而学习有效表示的研究得到了更少的关注。</li>
<li>methods: 我们提出了一种新的对话有用的抽象损失函数，即 TalkNCE。该损失函数只在屏幕上的人正在说话的部分应用，这使得模型学习有效的表示，通过自然的语音和脸部运动的相干关系。我们的损失函数可以与现有的 ASD 训练目标一起优化，不需要额外的监督或训练数据。</li>
<li>results: 我们的方法在 AVA-ActiveSpeaker 和 ASW 数据集上达到了状态之Art的性能。<details>
<summary>Abstract</summary>
The goal of this work is Active Speaker Detection (ASD), a task to determine whether a person is speaking or not in a series of video frames. Previous works have dealt with the task by exploring network architectures while learning effective representations has been less explored. In this work, we propose TalkNCE, a novel talk-aware contrastive loss. The loss is only applied to part of the full segments where a person on the screen is actually speaking. This encourages the model to learn effective representations through the natural correspondence of speech and facial movements. Our loss can be jointly optimized with the existing objectives for training ASD models without the need for additional supervision or training data. The experiments demonstrate that our loss can be easily integrated into the existing ASD frameworks, improving their performance. Our method achieves state-of-the-art performances on AVA-ActiveSpeaker and ASW datasets.
</details>
<details>
<summary>摘要</summary>
目标是活动说话人检测（ASD），即在视频帧序中确定人是否正在说话。先前的工作主要关注网络架构，学习有效表示得到了更少的关注。在这个工作中，我们提出了一种新的对话意识强制损失（TalkNCE）。这种损失仅应用于屏幕上人是说话的部分段落，从而鼓励模型通过自然的语音和面部运动的相干学习有效的表示。我们的损失可以与现有的ASD模型训练目标一起优化，无需额外的监督或训练数据。实验表明，我们的损失可以轻松地与现有的ASD框架集成，提高其性能。我们的方法在AVA-ActiveSpeaker和ASW数据集上达到了状态计算的表现。
</details></li>
</ul>
<hr>
<h2 id="SlowFast-Network-for-Continuous-Sign-Language-Recognition"><a href="#SlowFast-Network-for-Continuous-Sign-Language-Recognition" class="headerlink" title="SlowFast Network for Continuous Sign Language Recognition"></a>SlowFast Network for Continuous Sign Language Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12304">http://arxiv.org/abs/2309.12304</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junseok Ahn, Youngjoon Jang, Joon Son Chung</li>
<li>for: 本文目的是提高连续手语识别（CSLR）中的空间和动态特征EXTRACTION。</li>
<li>methods: 作者使用了两路快慢网络，其中每个路径在不同的时间分辨率下运行，分别捕捉手势（手势、表情）和动态信息（运动）。此外，作者还提出了两种特点适应CSLR的特点的特征融合方法：一是双向特征融合（BFF），可以将动态 semantics transfer into spatial semantics和vice versa; 二是路径特征增强（PFE），可以通过辅助子网络增强动态和空间表示，而不需要额外的推理时间。</li>
<li>results: 作者的模型在流行的CSLR数据集上（包括PHOENIX14、PHOENIX14-T和CSL-Daily）达到了当前状态的艺术。<details>
<summary>Abstract</summary>
The objective of this work is the effective extraction of spatial and dynamic features for Continuous Sign Language Recognition (CSLR). To accomplish this, we utilise a two-pathway SlowFast network, where each pathway operates at distinct temporal resolutions to separately capture spatial (hand shapes, facial expressions) and dynamic (movements) information. In addition, we introduce two distinct feature fusion methods, carefully designed for the characteristics of CSLR: (1) Bi-directional Feature Fusion (BFF), which facilitates the transfer of dynamic semantics into spatial semantics and vice versa; and (2) Pathway Feature Enhancement (PFE), which enriches dynamic and spatial representations through auxiliary subnetworks, while avoiding the need for extra inference time. As a result, our model further strengthens spatial and dynamic representations in parallel. We demonstrate that the proposed framework outperforms the current state-of-the-art performance on popular CSLR datasets, including PHOENIX14, PHOENIX14-T, and CSL-Daily.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Bi-directional Feature Fusion (BFF), which facilitates the transfer of dynamic semantics into spatial semantics and vice versa.2. Pathway Feature Enhancement (PFE), which enriches dynamic and spatial representations through auxiliary subnetworks, while avoiding the need for extra inference time.As a result, our model further strengthens spatial and dynamic representations in parallel. We demonstrate that the proposed framework outperforms the current state-of-the-art performance on popular CSLR datasets, including PHOENIX14, PHOENIX14-T, and CSL-Daily.</details></li>
</ol>
<hr>
<h2 id="PanoVOS-Bridging-Non-panoramic-and-Panoramic-Views-with-Transformer-for-Video-Segmentation"><a href="#PanoVOS-Bridging-Non-panoramic-and-Panoramic-Views-with-Transformer-for-Video-Segmentation" class="headerlink" title="PanoVOS: Bridging Non-panoramic and Panoramic Views with Transformer for Video Segmentation"></a>PanoVOS: Bridging Non-panoramic and Panoramic Views with Transformer for Video Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12303">http://arxiv.org/abs/2309.12303</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shilinyan99/panovos">https://github.com/shilinyan99/panovos</a></li>
<li>paper_authors: Shilin Yan, Xiaohao Xu, Lingyi Hong, Wenchao Chen, Wenqiang Zhang, Wei Zhang</li>
<li>for: 该论文主要用于提出一个全新的пано拉миче视频分割数据集，以及一种基于这个数据集的新的视频对象分割方法。</li>
<li>methods: 该论文使用了15种市场上的视频对象分割模型进行评估，并通过错误分析发现这些模型无法处理panoramic视频中的像素级别内容继续性。为了解决这个问题，该论文提出了一种基于semantic boundary信息的Pixel-level匹配方法。</li>
<li>results: 对比于之前的最佳模型，该论文的PSCFormer网络在panoramic设定下表现出了出色的优势，segmenation结果较为出色。<details>
<summary>Abstract</summary>
Panoramic videos contain richer spatial information and have attracted tremendous amounts of attention due to their exceptional experience in some fields such as autonomous driving and virtual reality. However, existing datasets for video segmentation only focus on conventional planar images. To address the challenge, in this paper, we present a panoramic video dataset, PanoVOS. The dataset provides 150 videos with high video resolutions and diverse motions. To quantify the domain gap between 2D planar videos and panoramic videos, we evaluate 15 off-the-shelf video object segmentation (VOS) models on PanoVOS. Through error analysis, we found that all of them fail to tackle pixel-level content discontinues of panoramic videos. Thus, we present a Panoramic Space Consistency Transformer (PSCFormer), which can effectively utilize the semantic boundary information of the previous frame for pixel-level matching with the current frame. Extensive experiments demonstrate that compared with the previous SOTA models, our PSCFormer network exhibits a great advantage in terms of segmentation results under the panoramic setting. Our dataset poses new challenges in panoramic VOS and we hope that our PanoVOS can advance the development of panoramic segmentation/tracking.
</details>
<details>
<summary>摘要</summary>
паннорамные видео содержат богатую информацию о пространстве и привлекли огромное внимание из-за своей выдающейся экспедиции в некоторых областях, таких как автономное управление и виртуальная реальность. Однако существующие данные для видеосегментации сосредоточены только на конвенциональных плоских изображениях. Чтобы решить эту проблему, в этой статье мы представляем панорамный видеоданные, PanoVOS. Данные предоставляют 150 видео с высокой разрешающей способностью и разнообразными движениями. Чтобы оценить разрыв доменных областей между плоскими видео и панорамными видео, мы оцениваем 15 готовых видеообъектной сегментации (VOS) моделей на PanoVOS. After error analysis, we found that all of them fail to handle pixel-level content discontinuities of panoramic videos. Therefore, we propose a Panoramic Space Consistency Transformer (PSCFormer), which can effectively utilize the semantic boundary information of the previous frame for pixel-level matching with the current frame. Extensive experiments show that compared with previous SOTA models, our PSCFormer network exhibits a great advantage in terms of segmentation results under the panoramic setting. Our dataset poses new challenges in panoramic VOS, and we hope that our PanoVOS can advance the development of panoramic segmentation/tracking.
</details></li>
</ul>
<hr>
<h2 id="Text-Guided-Vector-Graphics-Customization"><a href="#Text-Guided-Vector-Graphics-Customization" class="headerlink" title="Text-Guided Vector Graphics Customization"></a>Text-Guided Vector Graphics Customization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12302">http://arxiv.org/abs/2309.12302</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peiying Zhang, Nanxuan Zhao, Jing Liao</li>
<li>for: 生成高质量自定义 вектор图形，基于文本提示。</li>
<li>methods: 利用大规模预训练文本到图像模型，进行精度的文本提示导向图像生成，并使用 semantic-based path alignment 方法初始化 SVG。</li>
<li>results: 生成了多种高质量自定义 вектор图形，并通过多种纬度的评估方法得到了极高的评估结果。<details>
<summary>Abstract</summary>
Vector graphics are widely used in digital art and valued by designers for their scalability and layer-wise topological properties. However, the creation and editing of vector graphics necessitate creativity and design expertise, leading to a time-consuming process. In this paper, we propose a novel pipeline that generates high-quality customized vector graphics based on textual prompts while preserving the properties and layer-wise information of a given exemplar SVG. Our method harnesses the capabilities of large pre-trained text-to-image models. By fine-tuning the cross-attention layers of the model, we generate customized raster images guided by textual prompts. To initialize the SVG, we introduce a semantic-based path alignment method that preserves and transforms crucial paths from the exemplar SVG. Additionally, we optimize path parameters using both image-level and vector-level losses, ensuring smooth shape deformation while aligning with the customized raster image. We extensively evaluate our method using multiple metrics from vector-level, image-level, and text-level perspectives. The evaluation results demonstrate the effectiveness of our pipeline in generating diverse customizations of vector graphics with exceptional quality. The project page is https://intchous.github.io/SVGCustomization.
</details>
<details>
<summary>摘要</summary>
vector graphics 广泛应用于数字艺术中，因其可扩展性和层次结构而受到设计师的喜爱。然而，创建和修改 vector graphics 需要创作力和设计技巧，这会导致时间消耗。在这篇论文中，我们提出了一个新的管道，可以基于文本提示生成高质量自定义 vector graphics，保留原始 SVG 的属性和层次信息。我们利用大型预训练的文本到图像模型的能力，通过微调模型的跨层注意力层，生成基于文本提示的静态图像。为初始化 SVG，我们提出了基于 semantics 的路径对齐方法，保留和转换原始 SVG 中重要的路径。此外，我们使用图像级和向量级损失进行路径参数优化，确保形状变换平滑，同时与自定义静态图像对齐。我们进行了多metric 的全面评估，证明我们的管道可以生成高质量自定义 vector graphics，并且具有多样性。项目页面是 <https://intchous.github.io/SVGCustomization>。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Input-image-Normalization-for-Solving-the-Mode-Collapse-Problem-in-GAN-based-X-ray-Images"><a href="#Adaptive-Input-image-Normalization-for-Solving-the-Mode-Collapse-Problem-in-GAN-based-X-ray-Images" class="headerlink" title="Adaptive Input-image Normalization for Solving the Mode Collapse Problem in GAN-based X-ray Images"></a>Adaptive Input-image Normalization for Solving the Mode Collapse Problem in GAN-based X-ray Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12245">http://arxiv.org/abs/2309.12245</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Muneeb Saad, Mubashir Husain Rehmani, Ruairi O’Reilly</li>
<li>for: 增强生成的骨科影像数据集中的数据异质性，以提高机器学习分类器的性能。</li>
<li>methods: 使用生成对抗网络（DCGAN和ACGAN）生成增强的骨科影像数据集，并采用输入图像normalization来缓解模式塌井问题。</li>
<li>results: 对比使用不具有normalization的DCGAN和ACGAN，使用具有normalization的DCGAN和ACGAN能够提高分类器的性能和多样性指标。<details>
<summary>Abstract</summary>
Biomedical image datasets can be imbalanced due to the rarity of targeted diseases. Generative Adversarial Networks play a key role in addressing this imbalance by enabling the generation of synthetic images to augment datasets. It is important to generate synthetic images that incorporate a diverse range of features to accurately represent the distribution of features present in the training imagery. Furthermore, the absence of diverse features in synthetic images can degrade the performance of machine learning classifiers. The mode collapse problem impacts Generative Adversarial Networks' capacity to generate diversified images. Mode collapse comes in two varieties: intra-class and inter-class. In this paper, both varieties of the mode collapse problem are investigated, and their subsequent impact on the diversity of synthetic X-ray images is evaluated. This work contributes an empirical demonstration of the benefits of integrating the adaptive input-image normalization with the Deep Convolutional GAN and Auxiliary Classifier GAN to alleviate the mode collapse problems. Synthetically generated images are utilized for data augmentation and training a Vision Transformer model. The classification performance of the model is evaluated using accuracy, recall, and precision scores. Results demonstrate that the DCGAN and the ACGAN with adaptive input-image normalization outperform the DCGAN and ACGAN with un-normalized X-ray images as evidenced by the superior diversity scores and classification scores.
</details>
<details>
<summary>摘要</summary>
There are two types of mode collapse: intra-class and inter-class. In this paper, both types of mode collapse are investigated, and their impact on the diversity of synthetic X-ray images is evaluated. The authors propose integrating adaptive input-image normalization with GANs to alleviate the mode collapse problems.The proposed method is evaluated using a Vision Transformer model, and the classification performance is measured using accuracy, recall, and precision scores. The results show that the DCGAN and ACGAN with adaptive input-image normalization outperform the DCGAN and ACGAN with un-normalized X-ray images, as evidenced by superior diversity scores and classification scores.In summary, the authors propose a method to address the mode collapse problem in GANs for generating diverse synthetic biomedical images, and demonstrate its effectiveness using a Vision Transformer model. The proposed method can potentially improve the accuracy and robustness of biomedical image classification tasks.
</details></li>
</ul>
<hr>
<h2 id="Can-We-Reliably-Improve-the-Robustness-to-Image-Acquisition-of-Remote-Sensing-of-PV-Systems"><a href="#Can-We-Reliably-Improve-the-Robustness-to-Image-Acquisition-of-Remote-Sensing-of-PV-Systems" class="headerlink" title="Can We Reliably Improve the Robustness to Image Acquisition of Remote Sensing of PV Systems?"></a>Can We Reliably Improve the Robustness to Image Acquisition of Remote Sensing of PV Systems?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12214">http://arxiv.org/abs/2309.12214</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gabriel Kasmi, Laurent Dubus, Yves-Marie Saint-Drenan, Philippe Blanc</li>
<li>for: 监测区域规模的热顶solar电力安装 fleet的发展</li>
<li>methods: 利用wavelet scale attribution method (WCAM)来评估深度学习模型的鲁棒性和可靠性</li>
<li>results: 提高深度学习系统的可靠性和鲁棒性，以便安全地集成清洁能源到电力系统中<details>
<summary>Abstract</summary>
Photovoltaic (PV) energy is crucial for the decarbonization of energy systems. Due to the lack of centralized data, remote sensing of rooftop PV installations is the best option to monitor the evolution of the rooftop PV installed fleet at a regional scale. However, current techniques lack reliability and are notably sensitive to shifts in the acquisition conditions. To overcome this, we leverage the wavelet scale attribution method (WCAM), which decomposes a model's prediction in the space-scale domain. The WCAM enables us to assess on which scales the representation of a PV model rests and provides insights to derive methods that improve the robustness to acquisition conditions, thus increasing trust in deep learning systems to encourage their use for the safe integration of clean energy in electric systems.
</details>
<details>
<summary>摘要</summary>
彩绘太阳能（PV）是加速化清洁能源系统的关键。由于缺乏中央数据，远程探测楼顶PV设备是监测区域规模上批量PV设备的最佳选择。然而，现有技术缺乏可靠性，特别是对获取条件的变化非常敏感。为解决这问题，我们利用波лет级别归属方法（WCAM），它在空间频谱域中分解模型预测。WCAM允许我们评估模型预测中哪些级别的表示很重要，并提供了改进鲁棒性的方法，以便在不同的获取条件下提高深度学习系统的可靠性，从而激发使用清洁能源系统，并降低环境污染。
</details></li>
</ul>
<hr>
<h2 id="Brain-Tumor-Detection-Using-Deep-Learning-Approaches"><a href="#Brain-Tumor-Detection-Using-Deep-Learning-Approaches" class="headerlink" title="Brain Tumor Detection Using Deep Learning Approaches"></a>Brain Tumor Detection Using Deep Learning Approaches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12193">http://arxiv.org/abs/2309.12193</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Arminsbss/tumor-classification">https://github.com/Arminsbss/tumor-classification</a></li>
<li>paper_authors: Razia Sultana Misu</li>
<li>for: 本研究旨在使用深度学习技术自动检测脑肿。</li>
<li>methods: 本研究使用了五种转移学习模型，包括VGG16、VGG19、DenseNet121、ResNet50和YOLO V4，其中ResNet50得到了最高精度99.54%。</li>
<li>results: 本研究表明，使用深度学习技术可以准确地检测脑肿，并且ResNet50模型得到了最高精度。<details>
<summary>Abstract</summary>
Brain tumors are collections of abnormal cells that can develop into masses or clusters. Because they have the potential to infiltrate other tissues, they pose a risk to the patient. The main imaging technique used, MRI, may be able to identify a brain tumor with accuracy. The fast development of Deep Learning methods for use in computer vision applications has been facilitated by a vast amount of training data and improvements in model construction that offer better approximations in a supervised setting. The need for these approaches has been the main driver of this expansion. Deep learning methods have shown promise in improving the precision of brain tumor detection and classification using magnetic resonance imaging (MRI). The study on the use of deep learning techniques, especially ResNet50, for brain tumor identification is presented in this abstract. As a result, this study investigates the possibility of automating the detection procedure using deep learning techniques. In this study, I utilized five transfer learning models which are VGG16, VGG19, DenseNet121, ResNet50 and YOLO V4 where ResNet50 provide the best or highest accuracy 99.54%. The goal of the study is to guide researchers and medical professionals toward powerful brain tumor detecting systems by employing deep learning approaches by way of this evaluation and analysis.
</details>
<details>
<summary>摘要</summary>
脑肿是一种集合异常细胞的疾病，可能发展成为肿体或集群。由于它们可能会扩散到其他组织，因此对病人存在风险。主要用于识别脑肿的成像技术是MRI，可能能够准确地识别脑肿。深度学习方法在计算机视觉应用中的快速发展，主要受到了大量的训练数据和改进的模型构建的推动。这些方法在辅助脑肿检测和分类方面表现出了承诺。本研究使用了五种传输学习模型，即VGG16、VGG19、DenseNet121、ResNet50和YOLO V4，其中ResNet50提供了最高或最高精度99.54%。本研究的目标是通过深度学习方法来自动化脑肿检测过程，以帮助研究人员和医疗专业人员建立高效的脑肿检测系统。
</details></li>
</ul>
<hr>
<h2 id="SG-Bot-Object-Rearrangement-via-Coarse-to-Fine-Robotic-Imagination-on-Scene-Graphs"><a href="#SG-Bot-Object-Rearrangement-via-Coarse-to-Fine-Robotic-Imagination-on-Scene-Graphs" class="headerlink" title="SG-Bot: Object Rearrangement via Coarse-to-Fine Robotic Imagination on Scene Graphs"></a>SG-Bot: Object Rearrangement via Coarse-to-Fine Robotic Imagination on Scene Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12188">http://arxiv.org/abs/2309.12188</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guangyao Zhai, Xiaoni Cai, Dianye Huang, Yan Di, Fabian Manhardt, Federico Tombari, Nassir Navab, Benjamin Busam</li>
<li>for: 本研究旨在提供一个轻量级、即时、用户可控的物品重新排序框架，以便在人工智能肉体中实现环境互动。</li>
<li>methods: 本研究使用了一个粗细排序方案，其中包括使用场景图来表示场景，并且运用了三种程序—观察、想像和实施—以实现任务。</li>
<li>results: 实验结果显示，SG-Bot 在与竞争对手比较之下，有着很大的进步。<details>
<summary>Abstract</summary>
Object rearrangement is pivotal in robotic-environment interactions, representing a significant capability in embodied AI. In this paper, we present SG-Bot, a novel rearrangement framework that utilizes a coarse-to-fine scheme with a scene graph as the scene representation. Unlike previous methods that rely on either known goal priors or zero-shot large models, SG-Bot exemplifies lightweight, real-time, and user-controllable characteristics, seamlessly blending the consideration of commonsense knowledge with automatic generation capabilities. SG-Bot employs a three-fold procedure--observation, imagination, and execution--to adeptly address the task. Initially, objects are discerned and extracted from a cluttered scene during the observation. These objects are first coarsely organized and depicted within a scene graph, guided by either commonsense or user-defined criteria. Then, this scene graph subsequently informs a generative model, which forms a fine-grained goal scene considering the shape information from the initial scene and object semantics. Finally, for execution, the initial and envisioned goal scenes are matched to formulate robotic action policies. Experimental results demonstrate that SG-Bot outperforms competitors by a large margin.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate("Object rearrangement is pivotal in robotic-environment interactions, representing a significant capability in embodied AI. In this paper, we present SG-Bot, a novel rearrangement framework that utilizes a coarse-to-fine scheme with a scene graph as the scene representation. Unlike previous methods that rely on either known goal priors or zero-shot large models, SG-Bot exemplifies lightweight, real-time, and user-controllable characteristics, seamlessly blending the consideration of commonsense knowledge with automatic generation capabilities. SG-Bot employs a three-fold procedure--observation, imagination, and execution--to adeptly address the task. Initially, objects are discerned and extracted from a cluttered scene during the observation. These objects are first coarsely organized and depicted within a scene graph, guided by either commonsense or user-defined criteria. Then, this scene graph subsequently informs a generative model, which forms a fine-grained goal scene considering the shape information from the initial scene and object semantics. Finally, for execution, the initial and envisioned goal scenes are matched to formulate robotic action policies. Experimental results demonstrate that SG-Bot outperforms competitors by a large margin.")Here's the translation: объект перераспределение является ключевым в взаимодействиях робота с окружающей средой, представляя значительную возможность в инкорпорированном ИИ. В этой статье мы представляем SG-Бот, новый фреймворк перераспределения, который использует схему "коarse-to-fine" с графиком сцены как представление сцены. В отличие от предыдущих методов, которые основаны на известных принципах целей или моделях zeroshot, SG-Бот демонстрирует лёгкость, реальное времени и управляемые характеристики, гармонично сочетая рассмотрение общих смыслов с автоматическими возможностями. SG-Бот использует трёхступенчатую процедуру - наблюдение, воображение и выполнение - для эффективного решения задачи. Сначала объекты определяются и извлекаются из переплетенной сцены во время наблюдения. Эти объекты первоначально грубо организуются и описываются в графике сцены, руководствуясь Either common sense или критериями, определенными пользователем. Затем эта сцена графика влияет на модель генерации, которая формирует фине-задачу сцены, учитывая информацию о форме из исходной сцены и семантике объектов. Наконец, для выполнения, инициализированная и задуманная сцена графика соответствуют, чтобы сформулировать политики действий робота. Экспериментальные результаты подтверждают, что SG-Бот превышает конкурентов на значительном масштабе.
</details></li>
</ul>
<hr>
<h2 id="ORTexME-Occlusion-Robust-Human-Shape-and-Pose-via-Temporal-Average-Texture-and-Mesh-Encoding"><a href="#ORTexME-Occlusion-Robust-Human-Shape-and-Pose-via-Temporal-Average-Texture-and-Mesh-Encoding" class="headerlink" title="ORTexME: Occlusion-Robust Human Shape and Pose via Temporal Average Texture and Mesh Encoding"></a>ORTexME: Occlusion-Robust Human Shape and Pose via Temporal Average Texture and Mesh Encoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12183">http://arxiv.org/abs/2309.12183</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Cheng, Bo Wang, Robby T. Tan</li>
<li>for:  addressed the problem of occlusion in 3D human shape and pose estimation from monocular videos, which is common in real-world scenarios.</li>
<li>methods:  proposed an occlusion-robust temporal method called ORTexME, which utilizes temporal information from the input video to better regularize occluded body parts. The method is based on NeRF, and uses a novel average texture learning approach and human body mesh to guide the opacity-field updates and suppress blur and noise.</li>
<li>results:  achieved significant improvement on the challenging multi-person 3DPW dataset, with 1.8 P-MPJPE error reduction compared to the state-of-the-art rendering-based methods, which enlarged the error up to 5.6 on the same dataset.<details>
<summary>Abstract</summary>
In 3D human shape and pose estimation from a monocular video, models trained with limited labeled data cannot generalize well to videos with occlusion, which is common in the wild videos. The recent human neural rendering approaches focusing on novel view synthesis initialized by the off-the-shelf human shape and pose methods have the potential to correct the initial human shape. However, the existing methods have some drawbacks such as, erroneous in handling occlusion, sensitive to inaccurate human segmentation, and ineffective loss computation due to the non-regularized opacity field. To address these problems, we introduce ORTexME, an occlusion-robust temporal method that utilizes temporal information from the input video to better regularize the occluded body parts. While our ORTexME is based on NeRF, to determine the reliable regions for the NeRF ray sampling, we utilize our novel average texture learning approach to learn the average appearance of a person, and to infer a mask based on the average texture. In addition, to guide the opacity-field updates in NeRF to suppress blur and noise, we propose the use of human body mesh. The quantitative evaluation demonstrates that our method achieves significant improvement on the challenging multi-person 3DPW dataset, where our method achieves 1.8 P-MPJPE error reduction. The SOTA rendering-based methods fail and enlarge the error up to 5.6 on the same dataset.
</details>
<details>
<summary>摘要</summary>
在单目视频中的人体形态和姿态估计中，使用有限的标注数据训练的模型不能generalize well于受遮挡影响的视频，这是野外视频中的常见情况。 recent human neural rendering approaches focusing on novel view synthesis initialized by off-the-shelf human shape and pose methods have the potential to correct the initial human shape. However, the existing methods have some drawbacks such as, erroneous in handling occlusion, sensitive to inaccurate human segmentation, and ineffective loss computation due to the non-regularized opacity field. To address these problems, we introduce ORTexME, an occlusion-robust temporal method that utilizes temporal information from the input video to better regularize the occluded body parts. While our ORTexME is based on NeRF, to determine the reliable regions for the NeRF ray sampling, we utilize our novel average texture learning approach to learn the average appearance of a person, and to infer a mask based on the average texture. In addition, to guide the opacity-field updates in NeRF to suppress blur and noise, we propose the use of human body mesh. The quantitative evaluation demonstrates that our method achieves significant improvement on the challenging multi-person 3DPW dataset, where our method achieves 1.8 P-MPJPE error reduction. The SOTA rendering-based methods fail and enlarge the error up to 5.6 on the same dataset.
</details></li>
</ul>
<hr>
<h2 id="Autoregressive-Sign-Language-Production-A-Gloss-Free-Approach-with-Discrete-Representations"><a href="#Autoregressive-Sign-Language-Production-A-Gloss-Free-Approach-with-Discrete-Representations" class="headerlink" title="Autoregressive Sign Language Production: A Gloss-Free Approach with Discrete Representations"></a>Autoregressive Sign Language Production: A Gloss-Free Approach with Discrete Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12179">http://arxiv.org/abs/2309.12179</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eui Jun Hwang, Huije Lee, Jong C. Park</li>
<li>for: 这篇论文是为了提供一种直接将口语句子翻译成手语的方法，而不需要 intermediate gloss。</li>
<li>methods: 这篇论文提出了一种新的手语vector量化网络方法，该方法利用vector量化来 derivate discrete representation from sign pose sequences。</li>
<li>results: 该方法在 comprehensive evaluations 中表现出了较好的性能，并且比 Priors SLP 方法更加可靠，同时还提出了使用 Back-Translation 和 Fréchet Gesture Distance 作为评价指标的可靠性。<details>
<summary>Abstract</summary>
Gloss-free Sign Language Production (SLP) offers a direct translation of spoken language sentences into sign language, bypassing the need for gloss intermediaries. This paper presents the Sign language Vector Quantization Network, a novel approach to SLP that leverages Vector Quantization to derive discrete representations from sign pose sequences. Our method, rooted in both manual and non-manual elements of signing, supports advanced decoding methods and integrates latent-level alignment for enhanced linguistic coherence. Through comprehensive evaluations, we demonstrate superior performance of our method over prior SLP methods and highlight the reliability of Back-Translation and Fr\'echet Gesture Distance as evaluation metrics.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换给定文本到简化中文。<</SYS>>流利手语生产（SLP）提供了直接将口语句子转换为手语，无需间接采用概念介质。本文介绍了手语向量量化网络，一种新的SLP方法，利用向量量化 derive discrete representation from sign pose sequences。我们的方法受到手语的手势和非手势元素支持高级解码方法，并实现了层次匹配以提高语言一致性。通过全面评估，我们证明了我们的方法在先前SLP方法之上具有更高的性能，并高亮了回传和Fréchet手势距离的评估指标。
</details></li>
</ul>
<hr>
<h2 id="SANPO-A-Scene-Understanding-Accessibility-Navigation-Pathfinding-Obstacle-Avoidance-Dataset"><a href="#SANPO-A-Scene-Understanding-Accessibility-Navigation-Pathfinding-Obstacle-Avoidance-Dataset" class="headerlink" title="SANPO: A Scene Understanding, Accessibility, Navigation, Pathfinding, Obstacle Avoidance Dataset"></a>SANPO: A Scene Understanding, Accessibility, Navigation, Pathfinding, Obstacle Avoidance Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12172">http://arxiv.org/abs/2309.12172</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sagar M. Waghmare, Kimberly Wilber, Dave Hawkey, Xuan Yang, Matthew Wilson, Stephanie Debats, Cattalyya Nuengsigkapian, Astuti Sharma, Lars Pandikow, Huisheng Wang, Hartwig Adam, Mikhail Sirotenko</li>
<li>For: The paper is written for researchers and developers working on video segmentation, depth estimation, multi-task visual modeling, and synthetic-to-real domain adaptation.* Methods: The paper uses a large-scale egocentric video dataset called SANPO, which contains stereo video sessions collected in diverse outdoor environments, as well as rendered synthetic video sessions. The dataset includes dense depth and odometry labels, as well as temporally consistent dense panoptic segmentation labels for some sessions.* Results: The paper provides zero-shot baselines and SANPO benchmarks for future research, with the goal of advancing the state-of-the-art in the above-mentioned areas while enabling human navigation systems.Here’s the information in Simplified Chinese text format:* For: 这篇论文是为研究者和开发者们而写的，他们工作在视频分割、深度估计、多任务视觉模型和真实到 sintetic 领域的域 adaptation 等领域。* Methods: 这篇论文使用了一个大规模的 egocentric 视频数据集 called SANPO，该数据集包括多种不同的户外环境中的双视频会话，以及由 Parallel Domain 提供的 Rendered 的 synthetic 视频会话。数据集包括深度和运动标签，以及一些会话中的时间协调的 dense panoptic segmentation 标签。* Results: 这篇论文提供了 zero-shot baselines 和 SANPO benchmarks，以便未来的研究者可以通过这些 benchmaks 进行研究，以达到提高视频分割、深度估计、多任务视觉模型和真实到 sintetic 领域的状态前瞻。同时，这些 benchmaks 也可以帮助人类导航系统的开发。<details>
<summary>Abstract</summary>
We introduce SANPO, a large-scale egocentric video dataset focused on dense prediction in outdoor environments. It contains stereo video sessions collected across diverse outdoor environments, as well as rendered synthetic video sessions. (Synthetic data was provided by Parallel Domain.) All sessions have (dense) depth and odometry labels. All synthetic sessions and a subset of real sessions have temporally consistent dense panoptic segmentation labels. To our knowledge, this is the first human egocentric video dataset with both large scale dense panoptic segmentation and depth annotations. In addition to the dataset we also provide zero-shot baselines and SANPO benchmarks for future research. We hope that the challenging nature of SANPO will help advance the state-of-the-art in video segmentation, depth estimation, multi-task visual modeling, and synthetic-to-real domain adaptation, while enabling human navigation systems.   SANPO is available here: https://google-research-datasets.github.io/sanpo_dataset/
</details>
<details>
<summary>摘要</summary>
我们介绍SANPO，一个大规模自我视频数据集， focus on dense prediction in outdoor environments。它包含了不同的outdoor环境中的stereo视频会议，以及由Parallel Domain提供的Synthetic视频会议。所有会议都有dense的深度和odometry标签。Synthetic会议和一些真实会议都有时间相同的dense panoptic segmentation标签。根据我们所知，这是人类自我视频数据集中首次同时拥有大规模的dense panoptic segmentation和深度标签。此外，我们还提供了零基eline和SANPObenchmark，以便未来的研究。我们希望SANPO能帮助进步类比类比预测、深度估计、多任务视觉模型和Synthetic-to-real域转换，并帮助人类NAVIGATION系统。SANPO可以在以下网站上获取：https://google-research-datasets.github.io/sanpo_dataset/
</details></li>
</ul>
<hr>
<h2 id="Information-Forensics-and-Security-A-quarter-century-long-journey"><a href="#Information-Forensics-and-Security-A-quarter-century-long-journey" class="headerlink" title="Information Forensics and Security: A quarter-century-long journey"></a>Information Forensics and Security: A quarter-century-long journey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12159">http://arxiv.org/abs/2309.12159</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mauro Barni, Patrizio Campisi, Edward J. Delp, Gwenael Doërr, Jessica Fridrich, Nasir Memon, Fernando Pérez-González, Anderson Rocha, Luisa Verdoliva, Min Wu</li>
<li>for:  Ensuring that people use devices, data, and intellectual properties for authorized purposes, and facilitating the gathering of solid evidence to hold perpetrators accountable.</li>
<li>methods:  Technological advances in various focus areas, including but not limited to signal processing, data analysis, and machine learning, to address the societal needs of the digital information era.</li>
<li>results:  Landmark technical contributions and future trends in the field of Information Forensics and Security (IFS) over the last 25 years, as celebrated by the IEEE Signal Processing Society (SPS).<details>
<summary>Abstract</summary>
Information Forensics and Security (IFS) is an active R&D area whose goal is to ensure that people use devices, data, and intellectual properties for authorized purposes and to facilitate the gathering of solid evidence to hold perpetrators accountable. For over a quarter century since the 1990s, the IFS research area has grown tremendously to address the societal needs of the digital information era. The IEEE Signal Processing Society (SPS) has emerged as an important hub and leader in this area, and the article below celebrates some landmark technical contributions. In particular, we highlight the major technological advances on some selected focus areas in the field developed in the last 25 years from the research community and present future trends.
</details>
<details>
<summary>摘要</summary>
信息 FORENSICS 和安全 (IFS) 是一个活跃的研发领域，旨在确保人们在授权的情况下使用设备、数据和知识产权，并且为追究过失者负责任而收集坚实的证据。自1990年代以来的半个世纪以来，IFS研究领域已经快速增长，以应对数字信息时代的社会需求。IEEE信号处理学会（SPS）在这个领域中已经成为重要的枢纽和领导者，本文将highlight一些在过去25年中由研究社区提出的重要技术进步，并提出未来趋势。
</details></li>
</ul>
<hr>
<h2 id="Vulnerability-of-3D-Face-Recognition-Systems-to-Morphing-Attacks"><a href="#Vulnerability-of-3D-Face-Recognition-Systems-to-Morphing-Attacks" class="headerlink" title="Vulnerability of 3D Face Recognition Systems to Morphing Attacks"></a>Vulnerability of 3D Face Recognition Systems to Morphing Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12118">http://arxiv.org/abs/2309.12118</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanjeet Vardam, Luuk Spreeuwers</li>
<li>For: 本研究探讨了3DFR系统对3D面部变换攻击的Robustness。* Methods: 本文提出了一些方法来生成高质量的3D面部变换，并对这些变换进行检测。* Results: 实验结果显示，当3DFR系统遇到相似 morphs 攻击时，其最大同比差度（MMPMR）约为40%，相对差度（RMMR）约为41.76%。<details>
<summary>Abstract</summary>
In recent years face recognition systems have been brought to the mainstream due to development in hardware and software. Consistent efforts are being made to make them better and more secure. This has also brought developments in 3D face recognition systems at a rapid pace. These 3DFR systems are expected to overcome certain vulnerabilities of 2DFR systems. One such problem that the domain of 2DFR systems face is face image morphing. A substantial amount of research is being done for generation of high quality face morphs along with detection of attacks from these morphs. Comparatively the understanding of vulnerability of 3DFR systems against 3D face morphs is less. But at the same time an expectation is set from 3DFR systems to be more robust against such attacks. This paper attempts to research and gain more information on this matter. The paper describes a couple of methods that can be used to generate 3D face morphs. The face morphs that are generated using this method are then compared to the contributing faces to obtain similarity scores. The highest MMPMR is obtained around 40% with RMMR of 41.76% when 3DFRS are attacked with look-a-like morphs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="AutoPET-Challenge-2023-Sliding-Window-based-Optimization-of-U-Net"><a href="#AutoPET-Challenge-2023-Sliding-Window-based-Optimization-of-U-Net" class="headerlink" title="AutoPET Challenge 2023: Sliding Window-based Optimization of U-Net"></a>AutoPET Challenge 2023: Sliding Window-based Optimization of U-Net</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12114">http://arxiv.org/abs/2309.12114</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/matt3o/autopet2-submission">https://github.com/matt3o/autopet2-submission</a></li>
<li>paper_authors: Matthias Hadlich, Zdravko Marinov, Rainer Stiefelhagen</li>
<li>for: 这个研究是为了提高医疗影像中肿瘤分类的精确性，并且利用PET和CT两种图像技术来结合metros� and anatomical information。</li>
<li>methods: 这个研究使用了FDG-PET&#x2F;CT扫描，并且提出了一个挑战task来验证肿瘤特有的FDG取摄，并且使用了一个自动化的分类方法来分类肿瘤和正常组织。</li>
<li>results: 这个研究获得了1014个FDG-PET&#x2F;CT研究数据，并且显示了一个高度精确的肿瘤分类方法，并且可以对肿瘤进行严格的分类和分析。<details>
<summary>Abstract</summary>
Tumor segmentation in medical imaging is crucial and relies on precise delineation. Fluorodeoxyglucose Positron-Emission Tomography (FDG-PET) is widely used in clinical practice to detect metabolically active tumors. However, FDG-PET scans may misinterpret irregular glucose consumption in healthy or benign tissues as cancer. Combining PET with Computed Tomography (CT) can enhance tumor segmentation by integrating metabolic and anatomic information. FDG-PET/CT scans are pivotal for cancer staging and reassessment, utilizing radiolabeled fluorodeoxyglucose to highlight metabolically active regions. Accurately distinguishing tumor-specific uptake from physiological uptake in normal tissues is a challenging aspect of precise tumor segmentation. The AutoPET challenge addresses this by providing a dataset of 1014 FDG-PET/CT studies, encouraging advancements in accurate tumor segmentation and analysis within the FDG-PET/CT domain. Code: https://github.com/matt3o/AutoPET2-Submission/
</details>
<details>
<summary>摘要</summary>
肿体分割在医学影像中是关键和需要精准定义。 fluorodeoxyglucose positron emission tomography（FDG-PET）广泛应用于临床实践中检测活跃的肿体。然而，FDG-PET扫描可能会错误地认为正常或无害组织中的不规则糖分摄取为癌。将PET与计算机扫描成像（CT）结合可以提高肿体分割，将元素学和解剖信息结合起来。FDG-PET/CT扫描是癌病 stagings和重新评估中的关键工具，使用标记的fluorodeoxyglucose来高亮活跃的区域。准确地分辨肿体特有的摄取和正常组织中的 physiological uptake 是精准肿体分割的挑战。AutoPET挑战提供了一个包含1014个FDG-PET/CT研究的数据集，激励创新在FDG-PET/CT领域中的准确肿体分割和分析。代码：https://github.com/matt3o/AutoPET2-Submission/
</details></li>
</ul>
<hr>
<h2 id="Exploiting-CLIP-based-Multi-modal-Approach-for-Artwork-Classification-and-Retrieval"><a href="#Exploiting-CLIP-based-Multi-modal-Approach-for-Artwork-Classification-and-Retrieval" class="headerlink" title="Exploiting CLIP-based Multi-modal Approach for Artwork Classification and Retrieval"></a>Exploiting CLIP-based Multi-modal Approach for Artwork Classification and Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12110">http://arxiv.org/abs/2309.12110</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alberto Baldrati, Marco Bertini, Tiberio Uricchio, Alberto Del Bimbo</li>
<li>for: 这个论文主要是为了研究如何应用最近的多Modal图像预训练模型在艺术领域中。</li>
<li>methods: 这个论文使用的方法是使用semantic density的文本超级视觉模型，以提高模型的泛化能力。</li>
<li>results: 在NoisyArt dataset上进行了广泛的实验，CLIP模型在零批分类和描述到图像和艺术作品之间的转换中表现出色，并在描述到图像和艺术作品之间的转换中达到了有前例的结果。<details>
<summary>Abstract</summary>
Given the recent advances in multimodal image pretraining where visual models trained with semantically dense textual supervision tend to have better generalization capabilities than those trained using categorical attributes or through unsupervised techniques, in this work we investigate how recent CLIP model can be applied in several tasks in artwork domain. We perform exhaustive experiments on the NoisyArt dataset which is a dataset of artwork images crawled from public resources on the web. On such dataset CLIP achieves impressive results on (zero-shot) classification and promising results in both artwork-to-artwork and description-to-artwork domain.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="FourierLoss-Shape-Aware-Loss-Function-with-Fourier-Descriptors"><a href="#FourierLoss-Shape-Aware-Loss-Function-with-Fourier-Descriptors" class="headerlink" title="FourierLoss: Shape-Aware Loss Function with Fourier Descriptors"></a>FourierLoss: Shape-Aware Loss Function with Fourier Descriptors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12106">http://arxiv.org/abs/2309.12106</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mehmet Bahadir Erden, Selahattin Cansiz, Onur Caki, Haya Khattak, Durmus Etiz, Melek Cosar Yakar, Kerem Duruer, Berke Barut, Cigdem Gunduz-Demir</li>
<li>for: 这个研究是为了提高医学影像分类 tasks 中的综合性和准确性。</li>
<li>methods: 这个研究使用了 encoder-decoder 网络，并引入了一个新的 shape-aware loss function，named FourierLoss，来视�{数学描述者} 计算的物体形状差异，并对这个差异进行处理。</li>
<li>results: 这个研究显示，使用 proposed adaptive loss update mechanism 和 FourierLoss loss function，可以将网络的注意力从学习物体的大致形状转移到学习物体的细微形状，或是vice versa，以提高医学影像分类的准确性。在2879个 Computed Tomography 影像中，这个方法比其他方法 statistically significantly better 的结果。<details>
<summary>Abstract</summary>
Encoder-decoder networks become a popular choice for various medical image segmentation tasks. When they are trained with a standard loss function, these networks are not explicitly enforced to preserve the shape integrity of an object in an image. However, this ability of the network is important to obtain more accurate results, especially when there is a low-contrast difference between the object and its surroundings. In response to this issue, this work introduces a new shape-aware loss function, which we name FourierLoss. This loss function relies on quantifying the shape dissimilarity between the ground truth and the predicted segmentation maps through the Fourier descriptors calculated on their objects, and penalizing this dissimilarity in network training. Different than the previous studies, FourierLoss offers an adaptive loss function with trainable hyperparameters that control the importance of the level of the shape details that the network is enforced to learn in the training process. This control is achieved by the proposed adaptive loss update mechanism, which end-to-end learns the hyperparameters simultaneously with the network weights by backpropagation. As a result of using this mechanism, the network can dynamically change its attention from learning the general outline of an object to learning the details of its contour points, or vice versa, in different training epochs. Working on 2879 computed tomography images of 93 subjects, our experiments revealed that the proposed adaptive shape-aware loss function led to statistically significantly better results for liver segmentation, compared to its counterparts.
</details>
<details>
<summary>摘要</summary>
现代编码器-解码器网络在医疗图像分割任务中变得非常流行。当它们被训练于标准损失函数时，这些网络没有Explicitly保持图像中对象的形状完整性。然而，这种网络的能力是获得更高准确的结果的关键，特别是在对象和周围环境之间存在低对比的情况下。为解决这个问题，本研究提出了一种新的形态意识损失函数，我们称之为FourierLoss。这个损失函数基于计算图像中对象的Fourier描述符，并将其用于训练网络。与前一 Studies不同，FourierLoss提供了一个可调参数的损失函数，可以在训练过程中控制网络学习的形态细节水平。这种控制由我们提出的适应式损失更新机制实现，该机制通过反向传播来同时学习网络参数和损失函数参数。因此，网络可以在不同的训练纪元中动态地改变它的注意力，从学习对象的总轮廓到学习对象的轮廓点，或者vice versa。在我们对2879个计算Tomography图像的93个Subject进行实验后，我们发现，提出的适应式形态意识损失函数在肝 segmentation任务中具有统计学上significantly Better的结果，相比其他Counterparts。
</details></li>
</ul>
<hr>
<h2 id="Bayesian-sparsification-for-deep-neural-networks-with-Bayesian-model-reduction"><a href="#Bayesian-sparsification-for-deep-neural-networks-with-Bayesian-model-reduction" class="headerlink" title="Bayesian sparsification for deep neural networks with Bayesian model reduction"></a>Bayesian sparsification for deep neural networks with Bayesian model reduction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12095">http://arxiv.org/abs/2309.12095</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dimarkov/bmr4pml">https://github.com/dimarkov/bmr4pml</a></li>
<li>paper_authors: Dimitrije Marković, Karl J. Friston, Stefan J. Kiebel</li>
<li>for: 这篇论文旨在探讨 bayesian 简化技术的应用在深度学习中，以提高深度学习模型的计算效率和表现。</li>
<li>methods: 本研究使用 bayesian 简化技术，结合结构缩小假设和数学随机构造推断，实现了对深度学习模型的简化。</li>
<li>results: 研究比较了不同的简化方法，结果显示 bayesian 模型简化（BMR）方法在不同的深度学习架构上具有优越的表现，并且比较简单和有效。<details>
<summary>Abstract</summary>
Deep learning's immense capabilities are often constrained by the complexity of its models, leading to an increasing demand for effective sparsification techniques. Bayesian sparsification for deep learning emerges as a crucial approach, facilitating the design of models that are both computationally efficient and competitive in terms of performance across various deep learning applications. The state-of-the-art -- in Bayesian sparsification of deep neural networks -- combines structural shrinkage priors on model weights with an approximate inference scheme based on stochastic variational inference. However, model inversion of the full generative model is exceptionally computationally demanding, especially when compared to standard deep learning of point estimates. In this context, we advocate for the use of Bayesian model reduction (BMR) as a more efficient alternative for pruning of model weights. As a generalization of the Savage-Dickey ratio, BMR allows a post-hoc elimination of redundant model weights based on the posterior estimates under a straightforward (non-hierarchical) generative model. Our comparative study highlights the advantages of the BMR method relative to established approaches based on hierarchical horseshoe priors over model weights. We illustrate the potential of BMR across various deep learning architectures, from classical networks like LeNet to modern frameworks such as Vision Transformers and MLP-Mixers.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multi-Task-Cooperative-Learning-via-Searching-for-Flat-Minima"><a href="#Multi-Task-Cooperative-Learning-via-Searching-for-Flat-Minima" class="headerlink" title="Multi-Task Cooperative Learning via Searching for Flat Minima"></a>Multi-Task Cooperative Learning via Searching for Flat Minima</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12090">http://arxiv.org/abs/2309.12090</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fuping Wu, Le Zhang, Yang Sun, Yuanhan Mo, Thomas Nichols, Bartlomiej W. Papiez</li>
<li>for:  This paper is written for medical image analysis, specifically to improve the generalizability of learned features and performance in individual tasks using multi-task learning (MTL).</li>
<li>methods:  The paper proposes a multi&#x2F;bi-level optimization approach to MTL, where features are learned in a cooperative manner by updating the sub-model for each task alternatively, taking advantage of the learned sub-models of the other tasks. To alleviate negative transfer, the paper searches for flat minima with regard to features from other tasks.</li>
<li>results:  The proposed method is validated on three publicly available datasets and shows promising results compared to state-of-the-art MTL approaches, demonstrating the effectiveness of cooperative learning in medical image analysis.<details>
<summary>Abstract</summary>
Multi-task learning (MTL) has shown great potential in medical image analysis, improving the generalizability of the learned features and the performance in individual tasks. However, most of the work on MTL focuses on either architecture design or gradient manipulation, while in both scenarios, features are learned in a competitive manner. In this work, we propose to formulate MTL as a multi/bi-level optimization problem, and therefore force features to learn from each task in a cooperative approach. Specifically, we update the sub-model for each task alternatively taking advantage of the learned sub-models of the other tasks. To alleviate the negative transfer problem during the optimization, we search for flat minima for the current objective function with regard to features from other tasks. To demonstrate the effectiveness of the proposed approach, we validate our method on three publicly available datasets. The proposed method shows the advantage of cooperative learning, and yields promising results when compared with the state-of-the-art MTL approaches. The code will be available online.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Self-Calibrating-Fully-Differentiable-NLOS-Inverse-Rendering"><a href="#Self-Calibrating-Fully-Differentiable-NLOS-Inverse-Rendering" class="headerlink" title="Self-Calibrating, Fully Differentiable NLOS Inverse Rendering"></a>Self-Calibrating, Fully Differentiable NLOS Inverse Rendering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12047">http://arxiv.org/abs/2309.12047</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kiseok Choi, Inchul Kim, Dongyoung Choi, Julio Marco, Diego Gutierrez, Min H. Kim</li>
<li>for:  This paper aims to improve the accuracy and robustness of non-line-of-sight (NLOS) imaging methods for reconstructing hidden scenes.</li>
<li>methods:  The proposed method uses a fully-differentiable end-to-end NLOS inverse rendering pipeline that self-calibrates imaging parameters during the reconstruction process, using measured illumination in both the time and frequency domains.</li>
<li>results:  The method is able to consistently reconstruct detailed geometry and albedo of hidden scenes, even under significant noise levels, by using a combination of diffraction-based volumetric NLOS reconstruction, path-space light transport, and a simple ray marching technique.<details>
<summary>Abstract</summary>
Existing time-resolved non-line-of-sight (NLOS) imaging methods reconstruct hidden scenes by inverting the optical paths of indirect illumination measured at visible relay surfaces. These methods are prone to reconstruction artifacts due to inversion ambiguities and capture noise, which are typically mitigated through the manual selection of filtering functions and parameters. We introduce a fully-differentiable end-to-end NLOS inverse rendering pipeline that self-calibrates the imaging parameters during the reconstruction of hidden scenes, using as input only the measured illumination while working both in the time and frequency domains. Our pipeline extracts a geometric representation of the hidden scene from NLOS volumetric intensities and estimates the time-resolved illumination at the relay wall produced by such geometric information using differentiable transient rendering. We then use gradient descent to optimize imaging parameters by minimizing the error between our simulated time-resolved illumination and the measured illumination. Our end-to-end differentiable pipeline couples diffraction-based volumetric NLOS reconstruction with path-space light transport and a simple ray marching technique to extract detailed, dense sets of surface points and normals of hidden scenes. We demonstrate the robustness of our method to consistently reconstruct geometry and albedo, even under significant noise levels.
</details>
<details>
<summary>摘要</summary>
现有的时间分解非直视（NLOS）成像方法利用测量的 indirect 照明的光学路径进行场景重建。这些方法容易出现重建 artifacts，因为它们通常需要手动选择筛选函数和参数来 Mitigate 这些artefacts。我们介绍了一个完全可导的端到端 NLOS 反推管线，该管线在重建隐藏场景时自动调整成像参数，使用只有测量的照明作为输入，同时在时间和频率两个频率域中工作。我们的管线从 NLOS 体积强度中提取隐藏场景的几何表示，并估算在静止墙上生成的时间分解照明，使用可导的漫游技术来提取详细的表面点和法向量。然后，我们使用梯度下降优化成像参数，使得模拟的时间分解照明与测量的照明之间的错误最小化。我们的端到端可导管线结合了干涉基本的体积NLOS 重建、路径空间光传输和简单的漫游技术，以提取细腻的表面点和法向量。我们 demonstarte 了我们的方法可以在各种噪音水平下一致地重建场景的几何和反射率。
</details></li>
</ul>
<hr>
<h2 id="Beyond-Image-Borders-Learning-Feature-Extrapolation-for-Unbounded-Image-Composition"><a href="#Beyond-Image-Borders-Learning-Feature-Extrapolation-for-Unbounded-Image-Composition" class="headerlink" title="Beyond Image Borders: Learning Feature Extrapolation for Unbounded Image Composition"></a>Beyond Image Borders: Learning Feature Extrapolation for Unbounded Image Composition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12042">http://arxiv.org/abs/2309.12042</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liuxiaoyu1104/unic">https://github.com/liuxiaoyu1104/unic</a></li>
<li>paper_authors: Xiaoyu Liu, Ming Liu, Junyi Li, Shuai Liu, Xiaotao Wang, Lei Lei, Wangmeng Zuo</li>
<li>for: 提高图像组合和美观品质，大多数现有方法会修剪捕捉到的图像，但这些方法的修剪范围有限。</li>
<li>methods: 我们提出了一个联合框架，可以同时进行无限的摄像头视图建议和图像组合（i.e., UNIC），以确保生成的修剪图像是真实的和图像质量高。</li>
<li>results: 我们的方法可以在基于现有图像剪辑 datasets 的 dataset 上进行广泛的实验，并显示了我们的 UNIC 在无限的摄像头视图建议和图像组合方面的效果。<details>
<summary>Abstract</summary>
For improving image composition and aesthetic quality, most existing methods modulate the captured images by striking out redundant content near the image borders. However, such image cropping methods are limited in the range of image views. Some methods have been suggested to extrapolate the images and predict cropping boxes from the extrapolated image. Nonetheless, the synthesized extrapolated regions may be included in the cropped image, making the image composition result not real and potentially with degraded image quality. In this paper, we circumvent this issue by presenting a joint framework for both unbounded recommendation of camera view and image composition (i.e., UNIC). In this way, the cropped image is a sub-image of the image acquired by the predicted camera view, and thus can be guaranteed to be real and consistent in image quality. Specifically, our framework takes the current camera preview frame as input and provides a recommendation for view adjustment, which contains operations unlimited by the image borders, such as zooming in or out and camera movement. To improve the prediction accuracy of view adjustment prediction, we further extend the field of view by feature extrapolation. After one or several times of view adjustments, our method converges and results in both a camera view and a bounding box showing the image composition recommendation. Extensive experiments are conducted on the datasets constructed upon existing image cropping datasets, showing the effectiveness of our UNIC in unbounded recommendation of camera view and image composition. The source code, dataset, and pretrained models is available at https://github.com/liuxiaoyu1104/UNIC.
</details>
<details>
<summary>摘要</summary>
为提高图像组合和艺术质量，现有方法通常对捕捉到的图像进行剪辑，但这些图像剪辑方法有限制的视野范围。一些方法已经建议了从拟合图像中预测剪辑框。然而，生成的拟合区域可能包含在剪辑后的图像中，导致图像组合结果不真实并且可能受到质量下降的影响。在这篇论文中，我们解决了这个问题，提出了一个共同框架，即UNIC，以实现无限制的摄像头视野和图像组合。具体来说，我们的框架接受当前摄像头预览帧作为输入，并提供无限制的视野调整建议，包括图像边缘不受限制的缩放、摄像头移动等操作。为了提高视野调整预测精度，我们还进一步扩展了视野范围，通过特征拟合。经过一次或多次视野调整，我们的方法会 converges，并产生一个摄像头视野和图像组合建议。我们在基于现有图像剪辑数据集构建的数据集上进行了广泛的实验，证明了我们的UNIC在无限制的摄像头视野和图像组合方面的效果。源代码、数据集和预训练模型可以在https://github.com/liuxiaoyu1104/UNIC上下载。
</details></li>
</ul>
<hr>
<h2 id="BASE-Probably-a-Better-Approach-to-Multi-Object-Tracking"><a href="#BASE-Probably-a-Better-Approach-to-Multi-Object-Tracking" class="headerlink" title="BASE: Probably a Better Approach to Multi-Object Tracking"></a>BASE: Probably a Better Approach to Multi-Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12035">http://arxiv.org/abs/2309.12035</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martin Vonheim Larsen, Sigmund Rolfsjord, Daniel Gusland, Jörgen Ahlberg, Kim Mathiassen</li>
<li>for: 这篇论文是为了探讨可靠的视觉对象跟踪方法，以帮助解决现有的跟踪问题。</li>
<li>methods: 这篇论文使用了 bayesian 方法，并提出了一种简单、高效的视觉跟踪模型，称为 BASE（ bayesian approximation single-hypothesis estimator），可以在 MOT17 和 MOT20 上达到 state-of-the-art 水平。</li>
<li>results: 该模型在 MOT17 和 MOT20 上实现了 state-of-the-art 的跟踪效果，而无需使用 Re-Id。<details>
<summary>Abstract</summary>
The field of visual object tracking is dominated by methods that combine simple tracking algorithms and ad hoc schemes. Probabilistic tracking algorithms, which are leading in other fields, are surprisingly absent from the leaderboards. We found that accounting for distance in target kinematics, exploiting detector confidence and modelling non-uniform clutter characteristics is critical for a probabilistic tracker to work in visual tracking. Previous probabilistic methods fail to address most or all these aspects, which we believe is why they fall so far behind current state-of-the-art (SOTA) methods (there are no probabilistic trackers in the MOT17 top 100). To rekindle progress among probabilistic approaches, we propose a set of pragmatic models addressing these challenges, and demonstrate how they can be incorporated into a probabilistic framework. We present BASE (Bayesian Approximation Single-hypothesis Estimator), a simple, performant and easily extendible visual tracker, achieving state-of-the-art (SOTA) on MOT17 and MOT20, without using Re-Id. Code will be made available at https://github.com/ffi-no
</details>
<details>
<summary>摘要</summary>
visual 目标跟踪领域受到简单跟踪算法和尝试性方案的控制。 probabilistic 跟踪算法，在其他领域的领导地位，在视觉跟踪领域却缺失。我们发现，考虑目标动力学中的距离，利用探测器信任度和非对称雷达特征是 kritical 的。 previous probabilistic methods 缺乏这些方面的处理，我们认为这是为什么它们落后于当前状态的方法（MOT17 top 100 中没有probabilistic tracker）。为了恢复 probablistic 方法的进步，我们提出了一组做实的模型，并示出如何将它们 incorporated 到 probablistic 框架中。我们介绍了 BASE（Bayesian Approximation Single-hypothesis Estimator），一种简单、高性能和易扩展的视觉跟踪器，在 MOT17 和 MOT20 中 achieved state-of-the-art 成绩，不使用 Re-Id。代码将在 https://github.com/ffi-no 上提供。
</details></li>
</ul>
<hr>
<h2 id="Face-Identity-Aware-Disentanglement-in-StyleGAN"><a href="#Face-Identity-Aware-Disentanglement-in-StyleGAN" class="headerlink" title="Face Identity-Aware Disentanglement in StyleGAN"></a>Face Identity-Aware Disentanglement in StyleGAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12033">http://arxiv.org/abs/2309.12033</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adrian Suwała, Bartosz Wójcik, Magdalena Proszewska, Jacek Tabor, Przemysław Spurek, Marek Śmieja</li>
<li>for: 本研究旨在解决 Conditional GANs  manipulate 人脸图像的特征（如表情、发型、姿势、年龄）时同时改变人脸图像的身份特征的问题。</li>
<li>methods: 我们提出了 PluGeN4Faces，一个 StyleGAN 插件，可以显著分离人脸图像的特征和人脸图像的身份特征。我们的关键想法是在 Movie Frames 中检索到人物出现在不同的姿势和特征下的图像，然后通过一种对比损失来鼓励模型将同一个人的图像分配到相似的 latent space 中。</li>
<li>results: 我们的实验结果表明，PluGeN4Faces 对人脸图像的特征进行修改时，对图像的其他特征的改变相对较少，与现有状态的模型相比。<details>
<summary>Abstract</summary>
Conditional GANs are frequently used for manipulating the attributes of face images, such as expression, hairstyle, pose, or age. Even though the state-of-the-art models successfully modify the requested attributes, they simultaneously modify other important characteristics of the image, such as a person's identity. In this paper, we focus on solving this problem by introducing PluGeN4Faces, a plugin to StyleGAN, which explicitly disentangles face attributes from a person's identity. Our key idea is to perform training on images retrieved from movie frames, where a given person appears in various poses and with different attributes. By applying a type of contrastive loss, we encourage the model to group images of the same person in similar regions of latent space. Our experiments demonstrate that the modifications of face attributes performed by PluGeN4Faces are significantly less invasive on the remaining characteristics of the image than in the existing state-of-the-art models.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用可能性GAN进行面像图像的属性修饰，如表情、发型、姿势和年龄等。尽管现有模型成功修改请求的属性，但同时也会修改图像中其他重要特征，如人脸的身份。在这篇论文中，我们关注解决这个问题，我们引入了PluGeN4Faces， StyleGAN 的插件，它将明确分离人脸属性和人脸身份。我们的关键想法是在电影帧中检索到的图像进行训练，图像中一个人出现在不同的姿势和属性下。通过应用一种对比损失，我们鼓励模型将同一个人的图像分组到类似的潜在空间中。我们的实验表明，PluGeN4Faces 对面像图像的修饰是现有状态OF-THE-ART模型相比较不侵略的。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know and I can provide that version as well.
</details></li>
</ul>
<hr>
<h2 id="Unveiling-the-Hidden-Realm-Self-supervised-Skeleton-based-Action-Recognition-in-Occluded-Environments"><a href="#Unveiling-the-Hidden-Realm-Self-supervised-Skeleton-based-Action-Recognition-in-Occluded-Environments" class="headerlink" title="Unveiling the Hidden Realm: Self-supervised Skeleton-based Action Recognition in Occluded Environments"></a>Unveiling the Hidden Realm: Self-supervised Skeleton-based Action Recognition in Occluded Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12029">http://arxiv.org/abs/2309.12029</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cyfml/opstl">https://github.com/cyfml/opstl</a></li>
<li>paper_authors: Yifei Chen, Kunyu Peng, Alina Roitberg, David Schneider, Jiaming Zhang, Junwei Zheng, Ruiping Liu, Yufan Chen, Kailun Yang, Rainer Stiefelhagen</li>
<li>for: 这篇论文的目的是将人工智能应用到自主机器人系统中，以便处理目标遮蔽的情况。</li>
<li>methods: 这篇论文使用了阶层学习（Hierarchical Learning）和填写遮蔽（Imputation）方法来解决目标遮蔽的问题。</li>
<li>results: 这篇论文的结果显示，使用这些方法可以将自主机器人系统升级为能够处理目标遮蔽的情况，并且可以实现更高的识别率。<details>
<summary>Abstract</summary>
To integrate action recognition methods into autonomous robotic systems, it is crucial to consider adverse situations involving target occlusions. Such a scenario, despite its practical relevance, is rarely addressed in existing self-supervised skeleton-based action recognition methods. To empower robots with the capacity to address occlusion, we propose a simple and effective method. We first pre-train using occluded skeleton sequences, then use k-means clustering (KMeans) on sequence embeddings to group semantically similar samples. Next, we employ K-nearest-neighbor (KNN) to fill in missing skeleton data based on the closest sample neighbors. Imputing incomplete skeleton sequences to create relatively complete sequences as input provides significant benefits to existing skeleton-based self-supervised models. Meanwhile, building on the state-of-the-art Partial Spatio-Temporal Learning (PSTL), we introduce an Occluded Partial Spatio-Temporal Learning (OPSTL) framework. This enhancement utilizes Adaptive Spatial Masking (ASM) for better use of high-quality, intact skeletons. The effectiveness of our imputation methods is verified on the challenging occluded versions of the NTURGB+D 60 and NTURGB+D 120. The source code will be made publicly available at https://github.com/cyfml/OPSTL.
</details>
<details>
<summary>摘要</summary>
为了将动作识别方法integrated into autonomous robotic systems，需要考虑目标 occlusion 的情况。这种情况，虽然在现有的自适应skeleton-based action recognition方法中 rarely addressed，但它在实际应用中非常重要。为了赋能机器人处理 occlusion，我们提出了一种简单而有效的方法。我们首先使用 occluded skeleton sequences 进行预训练，然后使用 k-means clustering (KMeans) 对序列嵌入进行分组。接着，我们使用 K-nearest-neighbor (KNN) 填充 incomplete skeleton 数据，基于最近的样本 neighborgood 的 nearest 邻居。填充 incomplete skeleton sequences，以创建比较完整的输入序列，对现有skeleton-based self-supervised模型带来了显著的改进。此外，我们在 Partial Spatio-Temporal Learning (PSTL) 框架之上进行了更新，并增加了 Adaptive Spatial Masking (ASM)，以更好地利用高质量、完整的skeleton。我们证明了我们的填充方法的效果，在 NTURGB+D 60 和 NTURGB+D 120 的 occluded 版本上进行了测试。源代码将在 https://github.com/cyfml/OPSTL 上公开。
</details></li>
</ul>
<hr>
<h2 id="Precision-in-Building-Extraction-Comparing-Shallow-and-Deep-Models-using-LiDAR-Data"><a href="#Precision-in-Building-Extraction-Comparing-Shallow-and-Deep-Models-using-LiDAR-Data" class="headerlink" title="Precision in Building Extraction: Comparing Shallow and Deep Models using LiDAR Data"></a>Precision in Building Extraction: Comparing Shallow and Deep Models using LiDAR Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12027">http://arxiv.org/abs/2309.12027</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Sulaiman, Mina Farmanbar, Ahmed Nabil Belbachir, Chunming Rong</li>
<li>for: 本文使用 LiDAR 数据进行检测建筑物的深度学习模型，以提高建筑物的分割精度。</li>
<li>methods: 本文使用了 shallow 模型，并使用了 boundary masks 来提高建筑物的边界精度。</li>
<li>results:  compared with deep learning models, shallow models 在 IoU 分数上表现出优异，但是在 BIoU 分数上，deep learning models 表现更好。 boundary masks 可以提高 BIoU 分数 by 4%。 LightGBM 也比 RF 和 XGBoost 表现更好。<details>
<summary>Abstract</summary>
Building segmentation is essential in infrastructure development, population management, and geological observations. This article targets shallow models due to their interpretable nature to assess the presence of LiDAR data for supervised segmentation. The benchmark data used in this article are published in NORA MapAI competition for deep learning model. Shallow models are compared with deep learning models based on Intersection over Union (IoU) and Boundary Intersection over Union (BIoU). In the proposed work, boundary masks from the original mask are generated to improve the BIoU score, which relates to building shapes' borderline. The influence of LiDAR data is tested by training the model with only aerial images in task 1 and a combination of aerial and LiDAR data in task 2 and then compared. shallow models outperform deep learning models in IoU by 8% using aerial images (task 1) only and 2% in combined aerial images and LiDAR data (task 2). In contrast, deep learning models show better performance on BIoU scores. Boundary masks improve BIoU scores by 4% in both tasks. Light Gradient-Boosting Machine (LightGBM) performs better than RF and Extreme Gradient Boosting (XGBoost).
</details>
<details>
<summary>摘要</summary>
监测建筑物分割是基础设施开发、人口管理和地质观测中的关键。这篇文章主要针对使用 shallow model，因为它们的解释能力可以评估 LiDAR 数据是否对 supervised segmentation 有影响。这篇文章使用的标准数据来自 NORA MapAI 比赛，这是深度学习模型的 benchmark。在这篇文章中， shallow model 与深度学习模型进行比较，使用 Intersection over Union (IoU) 和 Boundary Intersection over Union (BIoU) 两个指标。在提议的工作中，从原始Mask中生成了Boundary Mask，以提高 BIoU 分数，这与建筑物的边界相关。在任务1中，使用只有飞行图像的情况下，shallow model 在 IoU 上比深度学习模型高出8%，而在任务2中，使用飞行图像和 LiDAR 数据的组合时，shallow model 和深度学习模型的分数相似。然而，深度学习模型在 BIoU 分数上表现更好。Boundary Mask 在两个任务中提高 BIoU 分数4%。Light Gradient-Boosting Machine (LightGBM) 在 RF 和 Extreme Gradient Boosting (XGBoost) 之上表现更好。
</details></li>
</ul>
<hr>
<h2 id="Convolution-and-Attention-Mixer-for-Synthetic-Aperture-Radar-Image-Change-Detection"><a href="#Convolution-and-Attention-Mixer-for-Synthetic-Aperture-Radar-Image-Change-Detection" class="headerlink" title="Convolution and Attention Mixer for Synthetic Aperture Radar Image Change Detection"></a>Convolution and Attention Mixer for Synthetic Aperture Radar Image Change Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12010">http://arxiv.org/abs/2309.12010</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/summitgao/camixer">https://github.com/summitgao/camixer</a></li>
<li>paper_authors: Haopeng Zhang, Zijing Lin, Feng Gao, Junyu Dong, Qian Du, Heng-Chao Li</li>
<li>for: 本文旨在提出一种基于Transformer-like架构的SAR变化检测方法，以提高SAR图像变化检测的精度和效率。</li>
<li>methods: 本文提出了一种叫做Convolution and Attention Mixer（CAMixer）的新方法，它通过并行的自注意力和平移核函数来提取全球 semantic信息，并通过阻塞机制来增强非线性特征变换。</li>
<li>results: 对于三个SAR数据集，实验结果表明，CAMixer方法可以具有更高的精度和效率，并且可以更好地鲁棒化SAR图像变化检测 task。<details>
<summary>Abstract</summary>
Synthetic aperture radar (SAR) image change detection is a critical task and has received increasing attentions in the remote sensing community. However, existing SAR change detection methods are mainly based on convolutional neural networks (CNNs), with limited consideration of global attention mechanism. In this letter, we explore Transformer-like architecture for SAR change detection to incorporate global attention. To this end, we propose a convolution and attention mixer (CAMixer). First, to compensate the inductive bias for Transformer, we combine self-attention with shift convolution in a parallel way. The parallel design effectively captures the global semantic information via the self-attention and performs local feature extraction through shift convolution simultaneously. Second, we adopt a gating mechanism in the feed-forward network to enhance the non-linear feature transformation. The gating mechanism is formulated as the element-wise multiplication of two parallel linear layers. Important features can be highlighted, leading to high-quality representations against speckle noise. Extensive experiments conducted on three SAR datasets verify the superior performance of the proposed CAMixer. The source codes will be publicly available at https://github.com/summitgao/CAMixer .
</details>
<details>
<summary>摘要</summary>
这是一个实验室内的文章，标题是“Synthetic Aperture Radar（SAR）图像变化检测方法”。这个领域在远程感知领域中具有重要性，但是现有的SAR变化检测方法主要基于卷积神经网络（CNN），对于全球注意机制的考虑却有限。在这封信中，我们尝试使用Transformer-like架构来检测SAR图像变化，以包含全球注意机制。为了补偿对Transformer的推导性，我们结合了自我注意和移位卷积，并在平行的方式下实现了全球 semantic信息的捕捉和本地特征提取。其次，我们采用了阻塞机制，以增强非线性特征转换。阻塞机制是将两个平行的直线层进行元素对元素乘法。这使得重要的特征能够获得突出，从而实现高质量的特征表现，抗衡杂音噪声。我们进行了广泛的实验，证明了我们提出的CAMixer方法的超越性。我们将代码公开在GitHub上，请参考https://github.com/summitgao/CAMixer。
</details></li>
</ul>
<hr>
<h2 id="Elevating-Skeleton-Based-Action-Recognition-with-Efficient-Multi-Modality-Self-Supervision"><a href="#Elevating-Skeleton-Based-Action-Recognition-with-Efficient-Multi-Modality-Self-Supervision" class="headerlink" title="Elevating Skeleton-Based Action Recognition with Efficient Multi-Modality Self-Supervision"></a>Elevating Skeleton-Based Action Recognition with Efficient Multi-Modality Self-Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12009">http://arxiv.org/abs/2309.12009</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/desehuileng0o0/ikem">https://github.com/desehuileng0o0/ikem</a></li>
<li>paper_authors: Yiping Wei, Kunyu Peng, Alina Roitberg, Jiaming Zhang, Junwei Zheng, Ruiping Liu, Yufan Chen, Kailun Yang, Rainer Stiefelhagen</li>
<li>for: 本研究旨在提高人体动作识别的自动学习性能，特别是使用多modalities setup时的表现。</li>
<li>methods: 我们首先提出了一种Implicit Knowledge Exchange Module (IKEM)，以消除低性能Modalities之间的知识协同传递。然后，我们提出了三种新的Modalities，以增强不同Modalities之间的补充信息。最后，我们提出了一种新的教师学生框架，以在引入新Modalities时保持效率，并在anchors, positives和negatives的约束下，将secondaryModalities中的知识透传到primaryModalities中。</li>
<li>results: 实验结果表明，我们的方法有效地提高了skeleton-based多modalities数据的表现，这标志着我们的approach可以有效地使用多modalities setup进行人体动作识别。<details>
<summary>Abstract</summary>
Self-supervised representation learning for human action recognition has developed rapidly in recent years. Most of the existing works are based on skeleton data while using a multi-modality setup. These works overlooked the differences in performance among modalities, which led to the propagation of erroneous knowledge between modalities while only three fundamental modalities, i.e., joints, bones, and motions are used, hence no additional modalities are explored.   In this work, we first propose an Implicit Knowledge Exchange Module (IKEM) which alleviates the propagation of erroneous knowledge between low-performance modalities. Then, we further propose three new modalities to enrich the complementary information between modalities. Finally, to maintain efficiency when introducing new modalities, we propose a novel teacher-student framework to distill the knowledge from the secondary modalities into the mandatory modalities considering the relationship constrained by anchors, positives, and negatives, named relational cross-modality knowledge distillation. The experimental results demonstrate the effectiveness of our approach, unlocking the efficient use of skeleton-based multi-modality data. Source code will be made publicly available at https://github.com/desehuileng0o0/IKEM.
</details>
<details>
<summary>摘要</summary>
实际承认人类动作的自我监督学习在近年来有很快的发展。大多数现有的工作都是基于骨架数据，并使用多 modalities 设置。这些工作忽略了不同modalities的表现差异，这导致了错误知识的传播 между modalities，仅有三种基本modalities，即肢体、骨骼和动作，没有进一步 explore 其他modalities。  在这个工作中，我们首先提出了隐式知识交换模组（IKEM），以解决错误知识传播 between low-performance modalities。然后，我们进一步提出了三种新的modalities，以增加多modalities 之间的补充信息。最后，为确保效率，我们提出了一个 novel teacher-student 框架，以将次要modalities 中的知识转换到必要modalities 中，考虑到紧缩链、正例和负例的关系，称为关联跨modalities 知识传播。实验结果显示了我们的方法的有效性，从而解锁了骨架基于多modalities 数据的效率使用。源代码将在https://github.com/desehuileng0o0/IKEM 上公开。
</details></li>
</ul>
<hr>
<h2 id="Identification-of-pneumonia-on-chest-x-ray-images-through-machine-learning"><a href="#Identification-of-pneumonia-on-chest-x-ray-images-through-machine-learning" class="headerlink" title="Identification of pneumonia on chest x-ray images through machine learning"></a>Identification of pneumonia on chest x-ray images through machine learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11995">http://arxiv.org/abs/2309.11995</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Nabeel-105/Covid-19-and-Pneumonia-Detection-Using-Chest-Xray-Images-Full-Desktop-Application-">https://github.com/Nabeel-105/Covid-19-and-Pneumonia-Detection-Using-Chest-Xray-Images-Full-Desktop-Application-</a></li>
<li>paper_authors: Eduardo Augusto Roeder</li>
<li>for: 该研究旨在开发一种用于识别儿童肺部X光图像中的抑菌病毒病的软件。</li>
<li>methods: 该软件是基于机器学习技术的计算模型，使用了传输学习技术进行训练。</li>
<li>results: 经过训练后，模型在新的图像上达到了98%的敏感度和97.3%的特异性。<details>
<summary>Abstract</summary>
Pneumonia is the leading infectious cause of infant death in the world. When identified early, it is possible to alter the prognosis of the patient, one could use imaging exams to help in the diagnostic confirmation. Performing and interpreting the exams as soon as possible is vital for a good treatment, with the most common exam for this pathology being chest X-ray. The objective of this study was to develop a software that identify the presence or absence of pneumonia in chest radiographs. The software was developed as a computational model based on machine learning using transfer learning technique. For the training process, images were collected from a database available online with children's chest X-rays images taken at a hospital in China. After training, the model was then exposed to new images, achieving relevant results on identifying such pathology, reaching 98% sensitivity and 97.3% specificity for the sample used for testing. It can be concluded that it is possible to develop a software that identifies pneumonia in chest X-ray images.
</details>
<details>
<summary>摘要</summary>
全球最主要的感染性新生儿死亡原因是肺炎，早期诊断可以改变病人的预后。用于诊断确认的成像检查可以帮助医生，最常用的检查方法是胸部X射线。本研究的目的是开发一种用于识别肺炎在胸部X射线图像中的软件。该软件是基于机器学习技术的计算模型，使用了传输学习技术进行训练。训练过程中获得的图像来自中国医院的儿童胸部X射线图像库。经训练后，模型对新图像进行测试， дости得了98%的敏感性和97.3%的特异性。可以 concluye ，可以开发一种用于识别肺炎在胸部X射线图像中的软件。
</details></li>
</ul>
<hr>
<h2 id="Neural-Stochastic-Screened-Poisson-Reconstruction"><a href="#Neural-Stochastic-Screened-Poisson-Reconstruction" class="headerlink" title="Neural Stochastic Screened Poisson Reconstruction"></a>Neural Stochastic Screened Poisson Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11993">http://arxiv.org/abs/2309.11993</a></li>
<li>repo_url: None</li>
<li>paper_authors: Silvia Sellán, Alec Jacobson</li>
<li>for: 用于重建三维表面从点云数据中</li>
<li>methods: 使用神经网络研究和量化重建不确定性，基于波峰平滑先验</li>
<li>results: 解决现有工作的主要限制，可以完全 интеGRATE到3D扫描管道中，从获取初始重建到决定下一个感知器位置并更新重建数据I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Reconstructing a surface from a point cloud is an underdetermined problem. We use a neural network to study and quantify this reconstruction uncertainty under a Poisson smoothness prior. Our algorithm addresses the main limitations of existing work and can be fully integrated into the 3D scanning pipeline, from obtaining an initial reconstruction to deciding on the next best sensor position and updating the reconstruction upon capturing more data.
</details>
<details>
<summary>摘要</summary>
<<SYS>> transtable("Reconstructing a surface from a point cloud is an underdetermined problem.") transtable("We use a neural network to study and quantify this reconstruction uncertainty under a Poisson smoothness prior.") transtable("Our algorithm addresses the main limitations of existing work and can be fully integrated into the 3D scanning pipeline, from obtaining an initial reconstruction to deciding on the next best sensor position and updating the reconstruction upon capturing more data.")>>Here's the translation of the text in Traditional Chinese:<<SYS>> transtable("重建表面从点云是一个不充分确定的问题。") transtable("我们使用神经网络来研究和评估这种重建不确定性，以Pointer Sobolev smoothness prior为基础。") transtable("我们的算法解决了现有工作的主要限制，可以完全整合到3D扫描管线中，从获取初始重建到决定下一个感知器位置并将更多数据捕获后更新重建。")>>Note that the translation is based on the Google Translate API, and may not be perfect or entirely accurate.
</details></li>
</ul>
<hr>
<h2 id="Crop-Row-Switching-for-Vision-Based-Navigation-A-Comprehensive-Approach-for-Efficient-Crop-Field-Navigation"><a href="#Crop-Row-Switching-for-Vision-Based-Navigation-A-Comprehensive-Approach-for-Efficient-Crop-Field-Navigation" class="headerlink" title="Crop Row Switching for Vision-Based Navigation: A Comprehensive Approach for Efficient Crop Field Navigation"></a>Crop Row Switching for Vision-Based Navigation: A Comprehensive Approach for Efficient Crop Field Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11989">http://arxiv.org/abs/2309.11989</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rajitha de Silva, Grzegorz Cielniak, Junfeng Gao</li>
<li>for: 该论文旨在开发一种基于视觉的移动机器人Navigation系统，可以在农业用途中涵盖整个田地。</li>
<li>methods: 该论文使用了深度学习的RGB图像分割和深度数据，通过探测农作物的结束和下一排农作物的重新入口来实现视觉基于的农作物行进管理策略。</li>
<li>results: 在一个真实的糖芘场中测试了该管理策略，结果表明机器人可以成功地从一排农作物出口，并重新进入下一排农作物， median误差为19.25cm和6.77度。<details>
<summary>Abstract</summary>
Vision-based mobile robot navigation systems in arable fields are mostly limited to in-row navigation. The process of switching from one crop row to the next in such systems is often aided by GNSS sensors or multiple camera setups. This paper presents a novel vision-based crop row-switching algorithm that enables a mobile robot to navigate an entire field of arable crops using a single front-mounted camera. The proposed row-switching manoeuvre uses deep learning-based RGB image segmentation and depth data to detect the end of the crop row, and re-entry point to the next crop row which would be used in a multi-state row switching pipeline. Each state of this pipeline use visual feedback or wheel odometry of the robot to successfully navigate towards the next crop row. The proposed crop row navigation pipeline was tested in a real sugar beet field containing crop rows with discontinuities, varying light levels, shadows and irregular headland surfaces. The robot could successfully exit from one crop row and re-enter the next crop row using the proposed pipeline with absolute median errors averaging at 19.25 cm and 6.77{\deg} for linear and rotational steps of the proposed manoeuvre.
</details>
<details>
<summary>摘要</summary>
视觉基于移动机器人农业场 Navigation 系统通常只能进行行间 navigation。 switching 过程中常用 GNSS 感知器或多个摄像头设计。本文提出了一种新的视觉基于的农作物行 switching 算法，可以使移动机器人在一个全场农作物中进行整个途径。提出的行 switching 举动使用深度学习基于 RGB 图像分割和深度数据检测农作物行的结束和下一行的重新入口点，并在多个状态的管道中使用视觉反馈或机器人轮胎速度进行成功导航到下一行农作物。该管道在实际的糖葱田中进行测试，包括农作物行间缺陷、变化的照明水平、阴影和不规则的机场表面。机器人可以成功从一个农作物行出现在下一个农作物行中使用提案的管道，相对 median 误差为 19.25 cm 和 6.77°。
</details></li>
</ul>
<hr>
<h2 id="ZS6D-Zero-shot-6D-Object-Pose-Estimation-using-Vision-Transformers"><a href="#ZS6D-Zero-shot-6D-Object-Pose-Estimation-using-Vision-Transformers" class="headerlink" title="ZS6D: Zero-shot 6D Object Pose Estimation using Vision Transformers"></a>ZS6D: Zero-shot 6D Object Pose Estimation using Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11986">http://arxiv.org/abs/2309.11986</a></li>
<li>repo_url: None</li>
<li>paper_authors: Philipp Ausserlechner, David Haberger, Stefan Thalhammer, Jean-Baptiste Weibel, Markus Vincze</li>
<li>for:  zeroshot 6D对象pose estimation</li>
<li>methods: 使用pre-trained Vision Transformers（ViT）抽取视觉描述符，并使用RANSAC-based PnP算法对比query图像和模板图像进行对应。</li>
<li>results: 对比两个现有的状态态的方法，提高了所有三个数据集的平均回归率。<details>
<summary>Abstract</summary>
As robotic systems increasingly encounter complex and unconstrained real-world scenarios, there is a demand to recognize diverse objects. The state-of-the-art 6D object pose estimation methods rely on object-specific training and therefore do not generalize to unseen objects. Recent novel object pose estimation methods are solving this issue using task-specific fine-tuned CNNs for deep template matching. This adaptation for pose estimation still requires expensive data rendering and training procedures. MegaPose for example is trained on a dataset consisting of two million images showing 20,000 different objects to reach such generalization capabilities. To overcome this shortcoming we introduce ZS6D, for zero-shot novel object 6D pose estimation. Visual descriptors, extracted using pre-trained Vision Transformers (ViT), are used for matching rendered templates against query images of objects and for establishing local correspondences. These local correspondences enable deriving geometric correspondences and are used for estimating the object's 6D pose with RANSAC-based PnP. This approach showcases that the image descriptors extracted by pre-trained ViTs are well-suited to achieve a notable improvement over two state-of-the-art novel object 6D pose estimation methods, without the need for task-specific fine-tuning. Experiments are performed on LMO, YCBV, and TLESS. In comparison to one of the two methods we improve the Average Recall on all three datasets and compared to the second method we improve on two datasets.
</details>
<details>
<summary>摘要</summary>
为了应对机器人系统在复杂和无束缚的实际场景中识别多种物体的需求，现状的6D物体姿态估计方法依赖于物体特定的训练，因此无法泛化到未见过的物体。最新的novel object pose estimation方法通过使用任务特定的精度调整的 convolutional neural networks (CNNs) 进行深度模板匹配来解决这个问题。这种适应仍然需要昂贵的数据渲染和训练过程。例如，MegaPose 是在包含20,000个不同的物体图像中训练的，以达到这种泛化能力。为了解决这个缺点，我们介绍了 Zero-shot Novel Object 6D Pose Estimation（ZS6D）方法。我们使用预训练的 Vision Transformers (ViT) 提取的视觉描述符来匹配渲染的模板图像和查询图像之间的本地匹配。这些本地匹配使得我们可以 derivation  геометрические匹配，并用 RANSAC-based PnP 方法来估计物体的6D姿态。这种方法显示了预训练的 ViT 提取的图像描述符能够达到两种现状的novel object 6D pose estimation方法的显著改进，无需进行任务特定的精度调整。我们在 LMO、YCBV 和 TLESS 上进行了实验，与两种方法进行比较。相比之下，我们在所有三个数据集上的均值回归得分都有所提高，相比第二种方法，我们在两个数据集上有所提高。
</details></li>
</ul>
<hr>
<h2 id="Spatially-Guiding-Unsupervised-Semantic-Segmentation-Through-Depth-Informed-Feature-Distillation-and-Sampling"><a href="#Spatially-Guiding-Unsupervised-Semantic-Segmentation-Through-Depth-Informed-Feature-Distillation-and-Sampling" class="headerlink" title="Spatially Guiding Unsupervised Semantic Segmentation Through Depth-Informed Feature Distillation and Sampling"></a>Spatially Guiding Unsupervised Semantic Segmentation Through Depth-Informed Feature Distillation and Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12378">http://arxiv.org/abs/2309.12378</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leon Sick, Dominik Engel, Pedro Hermosilla, Timo Ropinski</li>
<li>for: 降低需要人工标注的劳动成本，通过不监督学习方法进行 semantic segmentation 训练。</li>
<li>methods: 利用图像随机样本的特征进行学习，并通过 depth 信息了解场景结构。</li>
<li>results: 对多个 benchmark 数据集进行了广泛的实验，并得到了显著的性能改进。<details>
<summary>Abstract</summary>
Traditionally, training neural networks to perform semantic segmentation required expensive human-made annotations. But more recently, advances in the field of unsupervised learning have made significant progress on this issue and towards closing the gap to supervised algorithms. To achieve this, semantic knowledge is distilled by learning to correlate randomly sampled features from images across an entire dataset. In this work, we build upon these advances by incorporating information about the structure of the scene into the training process through the use of depth information. We achieve this by (1) learning depth-feature correlation by spatially correlate the feature maps with the depth maps to induce knowledge about the structure of the scene and (2) implementing farthest-point sampling to more effectively select relevant features by utilizing 3D sampling techniques on depth information of the scene. Finally, we demonstrate the effectiveness of our technical contributions through extensive experimentation and present significant improvements in performance across multiple benchmark datasets.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>通过将特征图与深度图进行空间相关性学习，以便从图像结构中获取知识。2. 通过使用深度信息来实现更有效的特征选择，通过利用3D抽样技术来选择相关的特征。最后，我们通过广泛的实验证明了我们的技术贡献的效果，并在多个 benchmark 数据集上显示了显著的改善。</details></li>
</ol>
<hr>
<h2 id="NeuralLabeling-A-versatile-toolset-for-labeling-vision-datasets-using-Neural-Radiance-Fields"><a href="#NeuralLabeling-A-versatile-toolset-for-labeling-vision-datasets-using-Neural-Radiance-Fields" class="headerlink" title="NeuralLabeling: A versatile toolset for labeling vision datasets using Neural Radiance Fields"></a>NeuralLabeling: A versatile toolset for labeling vision datasets using Neural Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11966">http://arxiv.org/abs/2309.11966</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/FlorisE/neural-labeling">https://github.com/FlorisE/neural-labeling</a></li>
<li>paper_authors: Floris Erich, Naoya Chiba, Yusuke Yoshiyasu, Noriaki Ando, Ryo Hanai, Yukiyasu Domae</li>
<li>for: 该论文旨在提出一种基于神经辐射场（NeRF）的场景标注方法和工具集，用于生成分割图、可用性图、2D bounding box、3D bounding box、6DOF对象位姿、深度图和对象体系。</li>
<li>methods: 该方法使用NeRF作为渲染器，通过利用多视点图像输入和三角函数等几何准确信息，进行3D空间工具进行标注，不需要特定的标注工具或扫描仪。</li>
<li>results: 在应用于机器人实际问题的情况下，通过添加深度图ground truth，使用30000帧透明物体RGB和噪音深度图捕捉到的碗洗机器人中的玻璃镜扭损捕捉到的30000帧碗洗机器人中的玻璃镜扭损，并训练一个简单的深度神经网络，使用标注的深度图进行监督，可以获得较高的重建性能，比之前使用弱监督方法更高。<details>
<summary>Abstract</summary>
We present NeuralLabeling, a labeling approach and toolset for annotating a scene using either bounding boxes or meshes and generating segmentation masks, affordance maps, 2D bounding boxes, 3D bounding boxes, 6DOF object poses, depth maps and object meshes. NeuralLabeling uses Neural Radiance Fields (NeRF) as renderer, allowing labeling to be performed using 3D spatial tools while incorporating geometric clues such as occlusions, relying only on images captured from multiple viewpoints as input. To demonstrate the applicability of NeuralLabeling to a practical problem in robotics, we added ground truth depth maps to 30000 frames of transparent object RGB and noisy depth maps of glasses placed in a dishwasher captured using an RGBD sensor, yielding the Dishwasher30k dataset. We show that training a simple deep neural network with supervision using the annotated depth maps yields a higher reconstruction performance than training with the previously applied weakly supervised approach.
</details>
<details>
<summary>摘要</summary>
我们介绍NeuralLabeling，一种标注方法和工具集 для使用矩形框或多面体标注场景并生成分割图、可用性图、2D矩形框、3D矩形框、6DOF物体位势、深度图和物体多面体。NeuralLabeling使用神经辐射场（NeRF）作为渲染器，允许使用3D空间工具进行标注，同时利用图像从多个视角捕捉的光学信息，如 occlusion 等。为证明NeuralLabeling在机器人学中的实用性，我们添加了透明物体RGB和噪声深度图的30000帧拍摄到的碗洗器dataset。我们表明，通过对标注深度图进行超级vision的深度神经网络训练，可以获得更高的重建性能，比较于之前应用的弱supervision方法。
</details></li>
</ul>
<hr>
<h2 id="Ego3DPose-Capturing-3D-Cues-from-Binocular-Egocentric-Views"><a href="#Ego3DPose-Capturing-3D-Cues-from-Binocular-Egocentric-Views" class="headerlink" title="Ego3DPose: Capturing 3D Cues from Binocular Egocentric Views"></a>Ego3DPose: Capturing 3D Cues from Binocular Egocentric Views</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11962">http://arxiv.org/abs/2309.11962</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tho-kn/Ego3DPose">https://github.com/tho-kn/Ego3DPose</a></li>
<li>paper_authors: Taeho Kang, Kyungjin Lee, Jinrui Zhang, Youngki Lee<br>methods:  Two-path network architecture with binocular heatmaps and perspective-aware representation using trigonometryresults:  Outperforms state-of-the-art models by 23.1% in MPJPE reduction in UnrealEgo dataset, with superior performance in challenging occlusion cases and visible joint positions.<details>
<summary>Abstract</summary>
We present Ego3DPose, a highly accurate binocular egocentric 3D pose reconstruction system. The binocular egocentric setup offers practicality and usefulness in various applications, however, it remains largely under-explored. It has been suffering from low pose estimation accuracy due to viewing distortion, severe self-occlusion, and limited field-of-view of the joints in egocentric 2D images. Here, we notice that two important 3D cues, stereo correspondences, and perspective, contained in the egocentric binocular input are neglected. Current methods heavily rely on 2D image features, implicitly learning 3D information, which introduces biases towards commonly observed motions and leads to low overall accuracy. We observe that they not only fail in challenging occlusion cases but also in estimating visible joint positions. To address these challenges, we propose two novel approaches. First, we design a two-path network architecture with a path that estimates pose per limb independently with its binocular heatmaps. Without full-body information provided, it alleviates bias toward trained full-body distribution. Second, we leverage the egocentric view of body limbs, which exhibits strong perspective variance (e.g., a significantly large-size hand when it is close to the camera). We propose a new perspective-aware representation using trigonometry, enabling the network to estimate the 3D orientation of limbs. Finally, we develop an end-to-end pose reconstruction network that synergizes both techniques. Our comprehensive evaluations demonstrate that Ego3DPose outperforms state-of-the-art models by a pose estimation error (i.e., MPJPE) reduction of 23.1% in the UnrealEgo dataset. Our qualitative results highlight the superiority of our approach across a range of scenarios and challenges.
</details>
<details>
<summary>摘要</summary>
我们介绍EGO3DPose，一个高精度双目人体3D姿势重建系统。双目人体设置具有实用性和有用性，但它受到低姿势估计精度的影响，主要是因为视野扭曲、严重的自遮挡和 JOINTS 的限制。我们发现，双目人体输入中含有两种重要的3D征象，即σtereo对称和视角，但现有方法仅仅将重点放在2D图像特征上，这会导致对常见运动的偏好和低整体精度。我们观察到，它们不仅在难度遮挡的情况下失败，而且在可视 JOINTS 的估计也失败。为解决这些挑战，我们提出了两个新的方法。首先，我们设计了一个两条路径网络架构，其中一条路径估计每个肢体的姿势独立地使用双目热映图。不需要全身信息提供，这样可以减少对训练全身份布的偏好。其次，我们利用 egocentric 视野中的身体部分，其中展现了强大的视角变化（例如，在相机近距离时，手部将变得非常大）。我们提出了一新的视角感知表示方法，使得网络可以估计肢体的3D方向。最后，我们实现了一个统一的姿势重建网络，融合了这两种技术。我们的全面评估显示，EGO3DPose 比前方 Models 的姿势估计误差（即MPJPE） reduction 为23.1%。我们的质数结果显示我们的方法在各种情况和挑战中具有优越性。
</details></li>
</ul>
<hr>
<h2 id="A-Study-of-Forward-Forward-Algorithm-for-Self-Supervised-Learning"><a href="#A-Study-of-Forward-Forward-Algorithm-for-Self-Supervised-Learning" class="headerlink" title="A Study of Forward-Forward Algorithm for Self-Supervised Learning"></a>A Study of Forward-Forward Algorithm for Self-Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11955">http://arxiv.org/abs/2309.11955</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonas Brenig, Radu Timofte</li>
<li>for: 本研究是 investigate the performance of forward-forward algorithm vs. backpropagation for self-supervised representation learning, and provide insights into the learned representation spaces.</li>
<li>methods: 本研究使用了四个标准数据集（MNIST、F-MNIST、SVHN和CIFAR-10）和三种常用的自助学习表示学习技术（旋转、翻转和碎片）。</li>
<li>results: 研究发现，虽然forward-forward算法与backpropagation在(自-)超vised学习中表现相似，但在所有研究 setting中转移性能明显落后。这可能是由多个因素引起的，包括每层有独立损失函数和在forward-forward paradigm中实现supervised training的方式。与backpropagation相比，forward-forward算法更关注边界和抛弃一些不必要的信息，这可能妨碍了表示学习的目标。进一步的调查和研究是必要的，以稳定forward-forward策略在自助学习中，并能够在不同的数据集和配置上进行可靠的应用。<details>
<summary>Abstract</summary>
Self-supervised representation learning has seen remarkable progress in the last few years, with some of the recent methods being able to learn useful image representations without labels. These methods are trained using backpropagation, the de facto standard. Recently, Geoffrey Hinton proposed the forward-forward algorithm as an alternative training method. It utilizes two forward passes and a separate loss function for each layer to train the network without backpropagation.   In this study, for the first time, we study the performance of forward-forward vs. backpropagation for self-supervised representation learning and provide insights into the learned representation spaces. Our benchmark employs four standard datasets, namely MNIST, F-MNIST, SVHN and CIFAR-10, and three commonly used self-supervised representation learning techniques, namely rotation, flip and jigsaw.   Our main finding is that while the forward-forward algorithm performs comparably to backpropagation during (self-)supervised training, the transfer performance is significantly lagging behind in all the studied settings. This may be caused by a combination of factors, including having a loss function for each layer and the way the supervised training is realized in the forward-forward paradigm. In comparison to backpropagation, the forward-forward algorithm focuses more on the boundaries and drops part of the information unnecessary for making decisions which harms the representation learning goal. Further investigation and research are necessary to stabilize the forward-forward strategy for self-supervised learning, to work beyond the datasets and configurations demonstrated by Geoffrey Hinton.
</details>
<details>
<summary>摘要</summary>
自顾的表示学习在最近几年内取得了非常出色的进步，其中一些最新的方法可以无需标签学习有用的图像表示。这些方法通常通过反射传播来训练网络。在这项研究中，我们第一次比较了反射传播和反射传播两种训练方法的性能，并对学习的表示空间提供了深入的启示。我们的基准使用了四个标准数据集，即MNIST、F-MNIST、SVHN和CIFAR-10，以及三种常用的自顾表示学习技术，即旋转、翻折和缝隙。我们的主要发现是，虽然反射传播在（自）超vised训练中和反射传播相当，但在所有研究的设置中，转移性能明显落后。这可能是由多种因素引起的，包括每层有自己的损失函数以及在反射传播中实现自顾训练的方式。与反射传播相比，反射传播更关注边界，抛弃一些无关于做出决策的信息，这会妨碍表示学习的目标。进一步的调查和研究是必要的，以稳定反射传播的自顾学习策略，并在不同的数据集和配置下进行研究。
</details></li>
</ul>
<hr>
<h2 id="Fully-Transformer-Equipped-Architecture-for-End-to-End-Referring-Video-Object-Segmentation"><a href="#Fully-Transformer-Equipped-Architecture-for-End-to-End-Referring-Video-Object-Segmentation" class="headerlink" title="Fully Transformer-Equipped Architecture for End-to-End Referring Video Object Segmentation"></a>Fully Transformer-Equipped Architecture for End-to-End Referring Video Object Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11933">http://arxiv.org/abs/2309.11933</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ping Li, Yu Zhang, Li Yuan, Xianghua Xu</li>
<li>for: 本研究旨在提出一个 completel y built upon transformers 的 Referring Video Object Segmentation (RVOS) 框架，以解决跨modal  зада件中的 объек对象搜寻问题。</li>
<li>methods: 本研究使用 transformers 完全建立了一个 RVOS 框架，并将任务视为一个 mask sequence learning 问题，将所有在视频中的物件视为候选物件。</li>
<li>results: 验证研究表明，提案的方法在三个 benchmark 上表现出色，例如在 A2D Sentences 和 J-HMDB Sentences 上的 mAP 分别为 45.1% 和 38.7%，在 Ref-YouTube-VOS 上的 $\mathcal{J&amp;F}$ 分别为 56.6%。相比最佳候选方法，提案方法在前两个 benchmark 上的 P$@$0.5 分别提高了 2.1% 和 3.2%，在 Ref-YouTube-VOS 上的 $\mathcal{J}$ 分别提高了 2.9%。<details>
<summary>Abstract</summary>
Referring Video Object Segmentation (RVOS) requires segmenting the object in video referred by a natural language query. Existing methods mainly rely on sophisticated pipelines to tackle such cross-modal task, and do not explicitly model the object-level spatial context which plays an important role in locating the referred object. Therefore, we propose an end-to-end RVOS framework completely built upon transformers, termed \textit{Fully Transformer-Equipped Architecture} (FTEA), which treats the RVOS task as a mask sequence learning problem and regards all the objects in video as candidate objects. Given a video clip with a text query, the visual-textual features are yielded by encoder, while the corresponding pixel-level and word-level features are aligned in terms of semantic similarity. To capture the object-level spatial context, we have developed the Stacked Transformer, which individually characterizes the visual appearance of each candidate object, whose feature map is decoded to the binary mask sequence in order directly. Finally, the model finds the best matching between mask sequence and text query. In addition, to diversify the generated masks for candidate objects, we impose a diversity loss on the model for capturing more accurate mask of the referred object. Empirical studies have shown the superiority of the proposed method on three benchmarks, e.g., FETA achieves 45.1% and 38.7% in terms of mAP on A2D Sentences (3782 videos) and J-HMDB Sentences (928 videos), respectively; it achieves 56.6% in terms of $\mathcal{J\&F}$ on Ref-YouTube-VOS (3975 videos and 7451 objects). Particularly, compared to the best candidate method, it has a gain of 2.1% and 3.2% in terms of P$@$0.5 on the former two, respectively, while it has a gain of 2.9% in terms of $\mathcal{J}$ on the latter one.
</details>
<details>
<summary>摘要</summary>
referring video object segmentation (RVOS)需要将视频中的对象分割成自然语言查询中引用的对象。现有方法主要基于复杂的管道来解决这种跨模态任务，而不直接模型对象水平的空间上下文，这将对于定位引用对象具有重要作用。因此，我们提出了一个 completelystructured upon transformers的框架，称为完全转换器装置架构（FTEA），它将RVOS任务视为一个mask sequence学习问题，并将所有视频中的对象视为候选对象。给定一个视频clip和文本查询，则可以通过encoder提取视觉和文本特征，并将它们在semantic similarity上对应。为了捕捉对象水平的空间上下文，我们开发了堆叠transformer，它可以在不同的对象水平上彩色化每个候选对象的视觉特征，并将其解码成直接对应的二进制掩码序列。最后，模型将找到与文本查询最佳匹配的mask sequence。此外，为了让模型生成更加准确的掩码，我们对模型征加多样性损失，以捕捉更多的对象特征。实验表明，我们的方法在三个标准测试集上表现出色，例如，FETA在A2D Sentences（3782个视频）和J-HMDB Sentences（928个视频）上达到了45.1%和38.7%的mAP，并在Ref-YouTube-VOS（3975个视频和7451个对象）上达到了56.6%的$\mathcal{J\&F}$。特别是，与最佳候选方法相比，FETA在前两个测试集上具有2.1%和3.2%的P$@$0.5提升，而在后一个测试集上具有2.9%的提升。
</details></li>
</ul>
<hr>
<h2 id="Bridging-the-Gap-Learning-Pace-Synchronization-for-Open-World-Semi-Supervised-Learning"><a href="#Bridging-the-Gap-Learning-Pace-Synchronization-for-Open-World-Semi-Supervised-Learning" class="headerlink" title="Bridging the Gap: Learning Pace Synchronization for Open-World Semi-Supervised Learning"></a>Bridging the Gap: Learning Pace Synchronization for Open-World Semi-Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11930">http://arxiv.org/abs/2309.11930</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bo Ye, Kai Gan, Tong Wei, Min-Ling Zhang</li>
<li>for: 这篇论文的目的是解决开放世界半监督学习中的新类发现问题，即使用无标签数据来增强模型对已知类的性能。</li>
<li>methods: 这篇论文提出了两种方法来解决这个问题：1）使用适应margin损失，根据估算的类分布来强制将seen类和novel类的学习速度融合，以同步学习速度。2）使用假标签对比归一化，将可能属于同一个类的样本集中，以提高新类发现。</li>
<li>results: 对多个数据集进行了广泛的评估，发现现有模型仍然困难地学习新类，而我们的方法却能够平衡seen和novel类，在ImageNet数据集上取得了3%的平均准确率提升，至于先前的状态艺术。此外，我们发现在默认的先前文献中进行自我超参数 fine-tuning 可以显著提高性能。<details>
<summary>Abstract</summary>
In open-world semi-supervised learning, a machine learning model is tasked with uncovering novel categories from unlabeled data while maintaining performance on seen categories from labeled data. The central challenge is the substantial learning gap between seen and novel categories, as the model learns the former faster due to accurate supervisory information. To address this, we introduce 1) an adaptive margin loss based on estimated class distribution, which encourages a large negative margin for samples in seen classes, to synchronize learning paces, and 2) pseudo-label contrastive clustering, which pulls together samples which are likely from the same class in the output space, to enhance novel class discovery. Our extensive evaluations on multiple datasets demonstrate that existing models still hinder novel class learning, whereas our approach strikingly balances both seen and novel classes, achieving a remarkable 3% average accuracy increase on the ImageNet dataset compared to the prior state-of-the-art. Additionally, we find that fine-tuning the self-supervised pre-trained backbone significantly boosts performance over the default in prior literature. After our paper is accepted, we will release the code.
</details>
<details>
<summary>摘要</summary>
在开放世界半supervised学习中，一个机器学习模型被要求发现未经标注的类，并保持已经标注的类的性能。中心挑战是seen和novel类之间的学习差距，因为模型通过准确的监督信息更快地学习seen类。为此，我们提出了两点解决方案：1）适应margin损失基于估计类分布，以便同步学习速度，和2） Pseudo-label对比聚合，以便增强novel类发现。我们在多个数据集进行了广泛的评估，发现现有模型仍然受限于novel类学习，而我们的方法能够平衡seen和novel类，在ImageNet数据集上实现了3%的平均准确率提升，相比之前的状态的艺术。此外，我们发现在先前的文献中 defaults 的自然语言预训练模型进行了显著的性能提升。接下来，我们将接受论文后，将代码发布。
</details></li>
</ul>
<hr>
<h2 id="Video-Scene-Location-Recognition-with-Neural-Networks"><a href="#Video-Scene-Location-Recognition-with-Neural-Networks" class="headerlink" title="Video Scene Location Recognition with Neural Networks"></a>Video Scene Location Recognition with Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11928">http://arxiv.org/abs/2309.11928</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lukáš Korel, Petr Pulc, Jiří Tumpach, Martin Holeňa</li>
<li>for: 这个论文探讨了基于视频序列的场景识别问题，使用人工神经网络来实现场景识别。</li>
<li>methods: 该方法选择每个场景中的一组帧，使用预训练的单图预处理卷积网络进行转换，并使用后续层的神经网络进行场景位置的分类。</li>
<li>results: 研究人员在使用不同层的神经网络进行组合，发现只有一些方法适用于这种任务。<details>
<summary>Abstract</summary>
This paper provides an insight into the possibility of scene recognition from a video sequence with a small set of repeated shooting locations (such as in television series) using artificial neural networks. The basic idea of the presented approach is to select a set of frames from each scene, transform them by a pre-trained singleimage pre-processing convolutional network, and classify the scene location with subsequent layers of the neural network. The considered networks have been tested and compared on a dataset obtained from The Big Bang Theory television series. We have investigated different neural network layers to combine individual frames, particularly AveragePooling, MaxPooling, Product, Flatten, LSTM, and Bidirectional LSTM layers. We have observed that only some of the approaches are suitable for the task at hand.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "scene recognition" is translated as "场景识别" (chǎngjìng zhībèi)* "video sequence" is translated as "视频序列" (zhìpín xùxiàn)* "artificial neural networks" is translated as "人工神经网络" (réngōng shénxiào wǎngluō)* "pre-trained" is translated as "预训练" (yùxùnliào)* "single-image pre-processing" is translated as "单图预处理" (dāngràng yùxùnliào)* "classify" is translated as "分类" (fēngróng)* "scene location" is translated as "场景位置" (chǎngjìng weíqióng)* "neural network layers" is translated as "神经网络层" (shénxiào wǎngluō jié)* "AveragePooling" is translated as "平均池化" (píngyuan chíhuà)* "MaxPooling" is translated as "最大池化" (máxī chíhuà)* "Product" is translated as "乘法" (shūfǎ)* "Flatten" is translated as "平铺" (píngshì)* "LSTM" is translated as "长期记忆神经网络" (chángjì shēngyì shénxiào wǎngluō)* "Bidirectional LSTM" is translated as "双向长期记忆神经网络" (shuāngxiàng chángjì shēngyì shénxiào wǎngluō)
</details></li>
</ul>
<hr>
<h2 id="TextCLIP-Text-Guided-Face-Image-Generation-And-Manipulation-Without-Adversarial-Training"><a href="#TextCLIP-Text-Guided-Face-Image-Generation-And-Manipulation-Without-Adversarial-Training" class="headerlink" title="TextCLIP: Text-Guided Face Image Generation And Manipulation Without Adversarial Training"></a>TextCLIP: Text-Guided Face Image Generation And Manipulation Without Adversarial Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11923">http://arxiv.org/abs/2309.11923</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaozhou You, Jian Zhang</li>
<li>for: 文章目的是提出一种基于文本的图像生成和修改方法，无需对抗训练。</li>
<li>methods: 方法利用 StyleGAN 的强大生成能力和 CLIP 的文本图像表示能力，通过特制的映射网络实现图像生成和修改。</li>
<li>results: 在 Multi-modal CelebA-HQ 数据集上进行了广泛的实验，表明我们的提出方法在图像生成和修改任务上具有优于现有方法的性能。<details>
<summary>Abstract</summary>
Text-guided image generation aimed to generate desired images conditioned on given texts, while text-guided image manipulation refers to semantically edit parts of a given image based on specified texts. For these two similar tasks, the key point is to ensure image fidelity as well as semantic consistency. Many previous approaches require complex multi-stage generation and adversarial training, while struggling to provide a unified framework for both tasks. In this work, we propose TextCLIP, a unified framework for text-guided image generation and manipulation without adversarial training. The proposed method accepts input from images or random noise corresponding to these two different tasks, and under the condition of the specific texts, a carefully designed mapping network that exploits the powerful generative capabilities of StyleGAN and the text image representation capabilities of Contrastive Language-Image Pre-training (CLIP) generates images of up to $1024\times1024$ resolution that can currently be generated. Extensive experiments on the Multi-modal CelebA-HQ dataset have demonstrated that our proposed method outperforms existing state-of-the-art methods, both on text-guided generation tasks and manipulation tasks.
</details>
<details>
<summary>摘要</summary>
文本导向图像生成和修改旨在生成基于给定文本的所需图像，而文本导向图像修改则是基于指定文本进行Semantic的修改。为这两个相似任务，关键点是保持图像准确性和Semantic一致。许多前一代方法需要复杂的多阶段生成和对抗训练，而困难提供一个简单的框架 для这两个任务。在这项工作中，我们提出了TextCLIP，一个不需要对抗训练的简单框架，可以同时进行文本导向图像生成和修改。提案的方法接受图像或随机噪声作为输入，根据特定的文本来生成高分辨率图像（最大支持1024x1024）。广泛的实验表明，我们的提案方法在Multi-modal CelebA-HQ dataset上比前一代方法更高效，同时在文本导向生成和修改任务上都有优异表现。
</details></li>
</ul>
<hr>
<h2 id="Spatial-Temporal-Transformer-based-Video-Compression-Framework"><a href="#Spatial-Temporal-Transformer-based-Video-Compression-Framework" class="headerlink" title="Spatial-Temporal Transformer based Video Compression Framework"></a>Spatial-Temporal Transformer based Video Compression Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11913">http://arxiv.org/abs/2309.11913</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanbo Gao, Wenjia Huang, Shuai Li, Hui Yuan, Mao Ye, Siwei Ma</li>
<li>for: 提高learned video compression（LVC）的效率和稳定性。</li>
<li>methods: 基于卷积神经网络（NN）的拟合推理，包括弹性推理（Uformer）、多个参考帧（MGP）和空间特征分布预测（SFD-T）等模块。</li>
<li>results: 与VTM比较，实现13.5%的BD率降低。<details>
<summary>Abstract</summary>
Learned video compression (LVC) has witnessed remarkable advancements in recent years. Similar as the traditional video coding, LVC inherits motion estimation/compensation, residual coding and other modules, all of which are implemented with neural networks (NNs). However, within the framework of NNs and its training mechanism using gradient backpropagation, most existing works often struggle to consistently generate stable motion information, which is in the form of geometric features, from the input color features. Moreover, the modules such as the inter-prediction and residual coding are independent from each other, making it inefficient to fully reduce the spatial-temporal redundancy. To address the above problems, in this paper, we propose a novel Spatial-Temporal Transformer based Video Compression (STT-VC) framework. It contains a Relaxed Deformable Transformer (RDT) with Uformer based offsets estimation for motion estimation and compensation, a Multi-Granularity Prediction (MGP) module based on multi-reference frames for prediction refinement, and a Spatial Feature Distribution prior based Transformer (SFD-T) for efficient temporal-spatial joint residual compression. Specifically, RDT is developed to stably estimate the motion information between frames by thoroughly investigating the relationship between the similarity based geometric motion feature extraction and self-attention. MGP is designed to fuse the multi-reference frame information by effectively exploring the coarse-grained prediction feature generated with the coded motion information. SFD-T is to compress the residual information by jointly exploring the spatial feature distributions in both residual and temporal prediction to further reduce the spatial-temporal redundancy. Experimental results demonstrate that our method achieves the best result with 13.5% BD-Rate saving over VTM.
</details>
<details>
<summary>摘要</summary>
Traditional video coding 的发展已经做出了很大的进步，但是这些方法通常难以稳定地生成从输入色彩特征中的动态信息，即几何特征。此外，模块之间的独立性使得减少空间时间重复的效率受到限制。为解决这些问题，在这篇论文中，我们提出了一种新的空间时间变换基于视频压缩（STT-VC）框架。它包括一个宽度自适应变换（RDT），基于uformer的偏移估计来实现动态信息估计和补做，一个多级别预测（MGP）模块，基于多个参考帧来进行预测精度的提升，以及一个空间特征分布先前基于变换（SFD-T）来高效地压缩剩余信息。具体来说，RDT是通过系统地研究 similarity 基于几何动态特征提取和自我注意来稳定地估计动态信息的。MGP是通过有效地探索粗级预测特征，使用编码动态信息来融合多个参考帧信息。SFD-T是通过同时探索剩余信息中的空间特征分布来进一步减少空间时间重复。实验结果表明，我们的方法可以在 VTM 上实现13.5%的BD-Rate减少。
</details></li>
</ul>
<hr>
<h2 id="Heart-Rate-Detection-Using-an-Event-Camera"><a href="#Heart-Rate-Detection-Using-an-Event-Camera" class="headerlink" title="Heart Rate Detection Using an Event Camera"></a>Heart Rate Detection Using an Event Camera</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11891">http://arxiv.org/abs/2309.11891</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aniket Jagtap, RamaKrishna Venkatesh Saripalli, Joe Lemley, Waseem Shariff, Alan F. Smeaton</li>
<li>for: 用于非侵入式心率监测</li>
<li>methods: 使用事件摄像机技术进行血液征迹捕捉</li>
<li>results: 成功实现了非接触式心率测量，并且可以减轻误差和难以控制的人体自然抖动等问题<details>
<summary>Abstract</summary>
Event cameras, also known as neuromorphic cameras, are an emerging technology that offer advantages over traditional shutter and frame-based cameras, including high temporal resolution, low power consumption, and selective data acquisition. In this study, we propose to harnesses the capabilities of event-based cameras to capture subtle changes in the surface of the skin caused by the pulsatile flow of blood in the wrist region. We investigate whether an event camera could be used for continuous noninvasive monitoring of heart rate (HR). Event camera video data from 25 participants, comprising varying age groups and skin colours, was collected and analysed. Ground-truth HR measurements obtained using conventional methods were used to evaluate of the accuracy of automatic detection of HR from event camera data. Our experimental results and comparison to the performance of other non-contact HR measurement methods demonstrate the feasibility of using event cameras for pulse detection. We also acknowledge the challenges and limitations of our method, such as light-induced flickering and the sub-conscious but naturally-occurring tremors of an individual during data capture.
</details>
<details>
<summary>摘要</summary>
事件摄像机也称为neuromorphic摄像机，是一种出现在技术领域的新兴技术，它们比传统的闭锁和帧采集机器更具有优点，包括高时间分辨率、低功耗和选择性数据采集。在这项研究中，我们利用事件驱动的摄像机来捕捉血液循环在手部区域中的微妙变化。我们研究了使用事件摄像机进行无侵入性的血液总流率（HR）连续监测。我们收集了25名参与者的事件摄像机视频数据，这些参与者来自不同的年龄组和皮肤颜色。我们使用传统方法获取的真实HR测量来评估自动从事件摄像机数据中检测HR的准确性。我们的实验结果和与其他非接触HR测量方法的比较表明了使用事件摄像机进行脉律检测的可能性。我们也认可了我们的方法的挑战和限制，例如光线辐射引起的闪光和个体在数据采集过程中的自然发生的微小振荡。
</details></li>
</ul>
<hr>
<h2 id="On-the-Fly-SfM-What-you-capture-is-What-you-get"><a href="#On-the-Fly-SfM-What-you-capture-is-What-you-get" class="headerlink" title="On-the-Fly SfM: What you capture is What you get"></a>On-the-Fly SfM: What you capture is What you get</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11883">http://arxiv.org/abs/2309.11883</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zongqian Zhan, Rui Xia, Yifei Yu, Yibo Xu, Xin Wang</li>
<li>for: 实时Structure from motion（SfM），可以在摄像头捕捉图像的同时进行注册和三角坐标估算。</li>
<li>methods: 我们的方法包括使用自动学习的词汇树进行快速图像检索、使用最小二乘（LSM）匹配机制提高图像对齐性、以及使用层次权重本地杆对调 optimization。</li>
<li>results: 我们的实验结果表明，在线SfM可以在实时捕捉图像时具有robustness和稳定性，并且可以实现图像注册和三角坐标估算。<details>
<summary>Abstract</summary>
Over the last decades, ample achievements have been made on Structure from motion (SfM). However, the vast majority of them basically work in an offline manner, i.e., images are firstly captured and then fed together into a SfM pipeline for obtaining poses and sparse point cloud. In this work, on the contrary, we present an on-the-fly SfM: running online SfM while image capturing, the newly taken On-the-Fly image is online estimated with the corresponding pose and points, i.e., what you capture is what you get. Specifically, our approach firstly employs a vocabulary tree that is unsupervised trained using learning-based global features for fast image retrieval of newly fly-in image. Then, a robust feature matching mechanism with least squares (LSM) is presented to improve image registration performance. Finally, via investigating the influence of newly fly-in image's connected neighboring images, an efficient hierarchical weighted local bundle adjustment (BA) is used for optimization. Extensive experimental results demonstrate that on-the-fly SfM can meet the goal of robustly registering the images while capturing in an online way.
</details>
<details>
<summary>摘要</summary>
Over the past few decades, significant progress has been made in Structure from Motion (SfM). However, most of these methods work in an offline manner, where images are captured and then fed into a SfM pipeline to obtain poses and sparse point clouds. In this work, we propose an on-the-fly SfM approach that runs SfM online while capturing images. Specifically, our method first employs an unsupervised vocabulary tree trained using learning-based global features for fast image retrieval of newly captured images. Then, we present a robust feature matching mechanism with least squares (LSM) to improve image registration performance. Finally, we use an efficient hierarchical weighted local bundle adjustment (BA) to optimize the images. Experimental results show that on-the-fly SfM can robustly register images captured online.Here's the word-for-word translation of the text into Simplified Chinese:过去几十年，结构从运动（SfM）领域得到了充足的成果。然而，大多数方法都是在离线模式下工作，即首先捕捉图像，然后将其传输到SfM管道中进行获取pose和稀疏点云。在这种情况下，我们提出了在线SfM方法：在捕捉图像时，新 captured On-the-Fly图像会在线被估算pose和点云，即你捕捉的就是你得到的。specifically，我们的方法首先采用了一个不supervised的词汇树，通过学习基于全局特征的学习来快速检索新飞入的图像。然后，我们提出了一种基于小正方形（LSM）的强健特征匹配机制，以提高图像匹配性能。最后，我们通过研究新飞入图像的相邻图像的影响，使用高效的层次权重本地加载平衡（BA）来优化图像。广泛的实验结果表明，在线SfM可以robustly register captured图像。
</details></li>
</ul>
<hr>
<h2 id="Using-Saliency-and-Cropping-to-Improve-Video-Memorability"><a href="#Using-Saliency-and-Cropping-to-Improve-Video-Memorability" class="headerlink" title="Using Saliency and Cropping to Improve Video Memorability"></a>Using Saliency and Cropping to Improve Video Memorability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11881">http://arxiv.org/abs/2309.11881</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hieu9955/ggggg">https://github.com/hieu9955/ggggg</a></li>
<li>paper_authors: Vaibhav Mudgal, Qingyang Wang, Lorin Sweeney, Alan F. Smeaton</li>
<li>for: 提高视频记忆性，以便提高视频的分享、播放和讨论可能性。</li>
<li>methods: 通过基于图像引人注意力的选择性剪辑来提高视频记忆性。实验包括基本固定剪辑和动态剪辑，其中剪辑大小和位置随视频播放和引人注意力跟踪变化。</li>
<li>results: Results indicate that especially for videos of low initial memorability, the memorability score can be improved.<details>
<summary>Abstract</summary>
Video memorability is a measure of how likely a particular video is to be remembered by a viewer when that viewer has no emotional connection with the video content. It is an important characteristic as videos that are more memorable are more likely to be shared, viewed, and discussed. This paper presents results of a series of experiments where we improved the memorability of a video by selectively cropping frames based on image saliency. We present results of a basic fixed cropping as well as the results from dynamic cropping where both the size of the crop and the position of the crop within the frame, move as the video is played and saliency is tracked. Our results indicate that especially for videos of low initial memorability, the memorability score can be improved.
</details>
<details>
<summary>摘要</summary>
视频记忆度是观看者视频内容无情感连接时视频的记忆程度。这是一项重要的特性，因为更有记忆力的视频更有可能被分享、播放和讨论。这篇论文介绍了一系列实验，我们通过选择性剪辑帧来提高视频的记忆力。我们发现，特别是初始记忆力较低的视频，通过动态剪辑（即剪辑大小和位置随视频播放和注意力追踪而变化）可以提高记忆力。
</details></li>
</ul>
<hr>
<h2 id="TCOVIS-Temporally-Consistent-Online-Video-Instance-Segmentation"><a href="#TCOVIS-Temporally-Consistent-Online-Video-Instance-Segmentation" class="headerlink" title="TCOVIS: Temporally Consistent Online Video Instance Segmentation"></a>TCOVIS: Temporally Consistent Online Video Instance Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11857">http://arxiv.org/abs/2309.11857</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jun-long-li/tcovis">https://github.com/jun-long-li/tcovis</a></li>
<li>paper_authors: Junlong Li, Bingyao Yu, Yongming Rao, Jie Zhou, Jiwen Lu</li>
<li>for: 本文提出了一种新的在线视频实例分割方法（TCOVIS），用于解决视频实例分割 task 中的时间一致性问题。</li>
<li>methods: TCOVIS 方法包括全局实例匹配策略和空间时间增强模块，这两个部分都可以提高视频中的时间一致性。</li>
<li>results: 在四个广泛采用的视频实例分割benchmark上（YouTube-VIS 2019&#x2F;2021&#x2F;2022 和 OVIS），TCOVIS 方法达到了所有benchmark上的最佳性能，不需要额外的技术。例如，在 YouTube-VIS 2021 上，TCOVIS 方法使用 ResNet-50 和 Swin-L 的背部板，分别获得了 49.5 AP 和 61.3 AP。<details>
<summary>Abstract</summary>
In recent years, significant progress has been made in video instance segmentation (VIS), with many offline and online methods achieving state-of-the-art performance. While offline methods have the advantage of producing temporally consistent predictions, they are not suitable for real-time scenarios. Conversely, online methods are more practical, but maintaining temporal consistency remains a challenging task. In this paper, we propose a novel online method for video instance segmentation, called TCOVIS, which fully exploits the temporal information in a video clip. The core of our method consists of a global instance assignment strategy and a spatio-temporal enhancement module, which improve the temporal consistency of the features from two aspects. Specifically, we perform global optimal matching between the predictions and ground truth across the whole video clip, and supervise the model with the global optimal objective. We also capture the spatial feature and aggregate it with the semantic feature between frames, thus realizing the spatio-temporal enhancement. We evaluate our method on four widely adopted VIS benchmarks, namely YouTube-VIS 2019/2021/2022 and OVIS, and achieve state-of-the-art performance on all benchmarks without bells-and-whistles. For instance, on YouTube-VIS 2021, TCOVIS achieves 49.5 AP and 61.3 AP with ResNet-50 and Swin-L backbones, respectively. Code is available at https://github.com/jun-long-li/TCOVIS.
</details>
<details>
<summary>摘要</summary>
近年来，视频实例分割（VIS）领域内，有很多离线和在线方法实现了状态数据最佳性。然而，离线方法在实时场景下不够实用，而在线方法尚未保证时间一致性。在这篇论文中，我们提出了一种新的在线视频实例分割方法，即TCOVIS，该方法完全利用视频帧序中的时间信息。TCOVIS的核心包括全局实例分配策略和空间时间增强模块，这两者共同提高了特征序列中的时间一致性。具体来说，我们在整个视频帧序中进行全局最佳匹配，并将模型监督global最佳目标。此外，我们还捕捉了空间特征，将其与语义特征在帧之间归一化，实现了空间时间增强。我们在四个广泛采用的 VIS 标准测试集上进行评估，分别是 YouTube-VIS 2019/2021/2022 和 OVIS，并在所有标准测试集上取得了状态数据最佳性。例如，在 YouTube-VIS 2021 上，TCOVIS 取得了 49.5 AP 和 61.3 AP，使用 ResNet-50 和 Swin-L 框架。代码可以在 <https://github.com/jun-long-li/TCOVIS> 上获取。
</details></li>
</ul>
<hr>
<h2 id="DEYOv3-DETR-with-YOLO-for-Real-time-Object-Detection"><a href="#DEYOv3-DETR-with-YOLO-for-Real-time-Object-Detection" class="headerlink" title="DEYOv3: DETR with YOLO for Real-time Object Detection"></a>DEYOv3: DETR with YOLO for Real-time Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11851">http://arxiv.org/abs/2309.11851</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haodong Ouyang</li>
<li>for: 提出了一种新的训练方法，以提高实时物体检测器的性能和投入成本。</li>
<li>methods: 使用步骤训练方法，首先使用预训练的 YOLO 检测器来初始化结束到端检测器，然后在第二个阶段将Encoder和背景匹配到 DETR 类型模型中，但只需要重新训练检测器。</li>
<li>results: 提出了一种brand-new的实时物体检测模型called DEYOv3，可以在 COCO  validate2017 上 достичь 41.1% 的分数和 T4 GPU 上达到 270 FPS，同时 DEYOv3-L 可以在 COCO  validate2017 上达到 51.3% AP 和 102 FPS。此外，DEYOv3 不需要额外的训练数据，可以在 N、S 和 M 级模型上 Completed 在 COCO  dataset 上训练，只需要一个 24GB RTX3090 GPU。<details>
<summary>Abstract</summary>
Recently, end-to-end object detectors have gained significant attention from the research community due to their outstanding performance. However, DETR typically relies on supervised pretraining of the backbone on ImageNet, which limits the practical application of DETR and the design of the backbone, affecting the model's potential generalization ability. In this paper, we propose a new training method called step-by-step training. Specifically, in the first stage, the one-to-many pre-trained YOLO detector is used to initialize the end-to-end detector. In the second stage, the backbone and encoder are consistent with the DETR-like model, but only the detector needs to be trained from scratch. Due to this training method, the object detector does not need the additional dataset (ImageNet) to train the backbone, which makes the design of the backbone more flexible and dramatically reduces the training cost of the detector, which is helpful for the practical application of the object detector. At the same time, compared with the DETR-like model, the step-by-step training method can achieve higher accuracy than the traditional training method of the DETR-like model. With the aid of this novel training method, we propose a brand-new end-to-end real-time object detection model called DEYOv3. DEYOv3-N achieves 41.1% on COCO val2017 and 270 FPS on T4 GPU, while DEYOv3-L achieves 51.3% AP and 102 FPS. Without the use of additional training data, DEYOv3 surpasses all existing real-time object detectors in terms of both speed and accuracy. It is worth noting that for models of N, S, and M scales, the training on the COCO dataset can be completed using a single 24GB RTX3090 GPU. Code will be released at https://github.com/ouyanghaodong/DEYOv3.
</details>
<details>
<summary>摘要</summary>
最近，端到端对象检测器在研究 сообществе中获得了重要的注意力，因为它们的表现非常出色。然而，DETR通常需要supervised预训练的后IONet，这限制了DETR的实际应用和后IONet的设计，从而影响了模型的总体化能力。在这篇论文中，我们提出了一种新的训练方法called step-by-step training。具体来说，在第一个阶段，使用pre-trained YOLO检测器进行一对多的初始化，然后在第二个阶段，后IONet和编码器与DETR-like模型相同，但是检测器需要从零开始训练。由于这种训练方法，对象检测器不需要额外的数据集（ImageNet）来训练后IONet，这使得后IONet的设计更加灵活，减少了检测器的训练成本，有助于实际应用。同时，相比DETR-like模型，step-by-step training方法可以在同样的精度下提高对象检测器的速度。通过这种新的训练方法，我们提出了一种全新的端到端实时对象检测模型called DEYOv3。DEYOv3-N在COCO val2017上得到了41.1%的分数和270 FPS的速度，而DEYOv3-L在COCO val2017上得到了51.3%的AP和102 FPS。不需要额外的训练数据，DEYOv3超过了所有现有的实时对象检测器，在速度和精度两个方面。值得注意的是，对于N、S、M缩放的模型，在COCO数据集上进行训练可以使用单个24GB RTX3090 GPU。代码将在https://github.com/ouyanghaodong/DEYOv3上发布。
</details></li>
</ul>
<hr>
<h2 id="MEFLUT-Unsupervised-1D-Lookup-Tables-for-Multi-exposure-Image-Fusion"><a href="#MEFLUT-Unsupervised-1D-Lookup-Tables-for-Multi-exposure-Image-Fusion" class="headerlink" title="MEFLUT: Unsupervised 1D Lookup Tables for Multi-exposure Image Fusion"></a>MEFLUT: Unsupervised 1D Lookup Tables for Multi-exposure Image Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11847">http://arxiv.org/abs/2309.11847</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hedlen/meflut">https://github.com/hedlen/meflut</a></li>
<li>paper_authors: Ting Jiang, Chuan Wang, Xinpeng Li, Ru Li, Haoqiang Fan, Shuaicheng Liu</li>
<li>for: 高品质多曝光图像融合 (MEF)</li>
<li>methods: 提出了一种新的方法，通过编码折衔表 (LUT) 来实现高效和高质量的多曝光图像融合，并通过注意力机制在不同维度进行调整，以提高融合质量。</li>
<li>results: 对比州时的最佳方法 (SOTA)，新方法在两个 dataset 上表现出较高的质量和效率，并且运行速度快（less than 4ms）。此外，该方法已经被广泛应用在 Android 手机上，并在多个国际品牌中推广。<details>
<summary>Abstract</summary>
In this paper, we introduce a new approach for high-quality multi-exposure image fusion (MEF). We show that the fusion weights of an exposure can be encoded into a 1D lookup table (LUT), which takes pixel intensity value as input and produces fusion weight as output. We learn one 1D LUT for each exposure, then all the pixels from different exposures can query 1D LUT of that exposure independently for high-quality and efficient fusion. Specifically, to learn these 1D LUTs, we involve attention mechanism in various dimensions including frame, channel and spatial ones into the MEF task so as to bring us significant quality improvement over the state-of-the-art (SOTA). In addition, we collect a new MEF dataset consisting of 960 samples, 155 of which are manually tuned by professionals as ground-truth for evaluation. Our network is trained by this dataset in an unsupervised manner. Extensive experiments are conducted to demonstrate the effectiveness of all the newly proposed components, and results show that our approach outperforms the SOTA in our and another representative dataset SICE, both qualitatively and quantitatively. Moreover, our 1D LUT approach takes less than 4ms to run a 4K image on a PC GPU. Given its high quality, efficiency and robustness, our method has been shipped into millions of Android mobiles across multiple brands world-wide. Code is available at: https://github.com/Hedlen/MEFLUT.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了一种新的高质量多曝光图像融合（MEF）方法。我们显示了一个曝光的融合权重可以被编码成1D查找表（LUT），该表接受像素强度值作为输入，并生成融合权重作为输出。我们学习了每个曝光的1D LUT，然后所有的像素从不同的曝光照片都可以独立地查询该曝光的1D LUT，以实现高质量和高效的融合。具体来说，为了学习这些1D LUT，我们在MEF任务中涉及了注意力机制在不同的维度，包括帧、通道和空间维度，以此实现显著的质量改进。此外，我们收集了一个新的MEF数据集，包含960个样本，其中155个是由专业人员手动调整为标准参考。我们的网络在这个数据集上进行了无监督的训练。我们进行了广泛的实验，以证明所有我们提出的新组件的效果，结果显示我们的方法在我们的数据集和另一个代表性数据集SICE中，都有较高的质量和效率。此外，我们的1D LUT方法在4K图像上只需要0.4毫秒钟，在PC GPU上运行。由于其高质量、效率和稳定性，我们的方法已经被安装在全球多个Android手机品牌上。代码可以在https://github.com/Hedlen/MEFLUT中找到。
</details></li>
</ul>
<hr>
<h2 id="MoPA-Multi-Modal-Prior-Aided-Domain-Adaptation-for-3D-Semantic-Segmentation"><a href="#MoPA-Multi-Modal-Prior-Aided-Domain-Adaptation-for-3D-Semantic-Segmentation" class="headerlink" title="MoPA: Multi-Modal Prior Aided Domain Adaptation for 3D Semantic Segmentation"></a>MoPA: Multi-Modal Prior Aided Domain Adaptation for 3D Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11839">http://arxiv.org/abs/2309.11839</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haozhi Cao, Yuecong Xu, Jianfei Yang, Pengyu Yin, Shenghai Yuan, Lihua Xie</li>
<li>for: 这个研究旨在提高3D semantic segmentation中的罕见物类分类性能，并且不需要耗费价值的点据标注。</li>
<li>methods: 本研究使用Multi-modal Prior Aided（MoPA）领域对应，提出Valid Ground-based Insertion（VGI）和SAM consistency loss等方法来缓解自我训练中的分布不均势问题，并且将多modal特征知识共享到各自的领域中。</li>
<li>results: 实验结果显示，本研究在MM-UDAbenchmark上的表现凌驾了现有的方法，并且在罕见物类分类上具有更高的准确性。<details>
<summary>Abstract</summary>
Multi-modal unsupervised domain adaptation (MM-UDA) for 3D semantic segmentation is a practical solution to embed semantic understanding in autonomous systems without expensive point-wise annotations. While previous MM-UDA methods can achieve overall improvement, they suffer from significant class-imbalanced performance, restricting their adoption in real applications. This imbalanced performance is mainly caused by: 1) self-training with imbalanced data and 2) the lack of pixel-wise 2D supervision signals. In this work, we propose Multi-modal Prior Aided (MoPA) domain adaptation to improve the performance of rare objects. Specifically, we develop Valid Ground-based Insertion (VGI) to rectify the imbalance supervision signals by inserting prior rare objects collected from the wild while avoiding introducing artificial artifacts that lead to trivial solutions. Meanwhile, our SAM consistency loss leverages the 2D prior semantic masks from SAM as pixel-wise supervision signals to encourage consistent predictions for each object in the semantic mask. The knowledge learned from modal-specific prior is then shared across modalities to achieve better rare object segmentation. Extensive experiments show that our method achieves state-of-the-art performance on the challenging MM-UDA benchmark. Code will be available at https://github.com/AronCao49/MoPA.
</details>
<details>
<summary>摘要</summary>
多模态无监督领域适应（MM-UDA）为3D语义分割提供了实用的解决方案，以嵌入自主系统中的语义理解无需昂贵的点级标注。先前的MM-UDA方法可以实现总体改进，但它们受到类别不均衡性的影响，导致其在实际应用中的采用有限。这种不均衡性主要来自于：1）自我训练偏斜数据和2）缺失像素级2D超参信号。在这种工作中，我们提出了多模态依据帮助（MoPA）领域适应，以改善罕见对象的性能。特别是，我们开发了有效的地面基础插入（VGI），以修正不均衡的指导信号，并避免引入人工 artifacts，以避免导致轻微解决方案。此外，我们的SAM一致性损失利用了2D先前语义masks从SAM中的像素级超参信号，以强制每个对象在semantic mask中的一致预测。知识从多模态依据中学习的知识然后被共享到多个模式，以实现更好的罕见对象分割。广泛的实验表明，我们的方法在复杂的MM-UDAbenchmark上实现了状态的最佳性能。代码将在https://github.com/AronCao49/MoPA上公开。
</details></li>
</ul>
<hr>
<h2 id="Automatic-Endoscopic-Ultrasound-Station-Recognition-with-Limited-Data"><a href="#Automatic-Endoscopic-Ultrasound-Station-Recognition-with-Limited-Data" class="headerlink" title="Automatic Endoscopic Ultrasound Station Recognition with Limited Data"></a>Automatic Endoscopic Ultrasound Station Recognition with Limited Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11820">http://arxiv.org/abs/2309.11820</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amrita-medical-ai/eusml-labeller">https://github.com/amrita-medical-ai/eusml-labeller</a></li>
<li>paper_authors: Abhijit Ramesh, Anantha Nandanan, Nikhil Boggavarapu, Priya Nair MD, Gilad Gressel</li>
<li>For: 这个研究旨在帮助医生更有效地诊断胰脏癌，使用人工智能技术来帮助医生更快速地识别胰脏癌的“EUS站”（胰脏ultrasound的不同位置）。* Methods: 这个研究使用了深度学习技术，开发了一个可以在EUS процеду中实时识别胰脏癌的computer-assisted diagnostic（CAD）工具。这个工具可以帮助医生更快速地识别胰脏癌，并且提供可读的和解释的视觉化技术。* Results: 研究发现，只需使用43次程序， без任何参数调整，可以取得90%的平衡精度，与现有的州前测试相当。此外，这个工具还可以提供可读的和解释的视觉化技术，帮助医生更好地理解胰脏癌的特征。<details>
<summary>Abstract</summary>
Pancreatic cancer is a lethal form of cancer that significantly contributes to cancer-related deaths worldwide. Early detection is essential to improve patient prognosis and survival rates. Despite advances in medical imaging techniques, pancreatic cancer remains a challenging disease to detect. Endoscopic ultrasound (EUS) is the most effective diagnostic tool for detecting pancreatic cancer. However, it requires expert interpretation of complex ultrasound images to complete a reliable patient scan. To obtain complete imaging of the pancreas, practitioners must learn to guide the endoscope into multiple "EUS stations" (anatomical locations), which provide different views of the pancreas. This is a difficult skill to learn, involving over 225 proctored procedures with the support of an experienced doctor. We build an AI-assisted tool that utilizes deep learning techniques to identify these stations of the stomach in real time during EUS procedures. This computer-assisted diagnostic (CAD) will help train doctors more efficiently. Historically, the challenge faced in developing such a tool has been the amount of retrospective labeling required by trained clinicians. To solve this, we developed an open-source user-friendly labeling web app that streamlines the process of annotating stations during the EUS procedure with minimal effort from the clinicians. Our research shows that employing only 43 procedures with no hyperparameter fine-tuning obtained a balanced accuracy of 90%, comparable to the current state of the art. In addition, we employ Grad-CAM, a visualization technology that provides clinicians with interpretable and explainable visualizations.
</details>
<details>
<summary>摘要</summary>
肝胆癌是一种致命的癌症，对全球癌症相关死亡率做出了重要贡献。早期癌症检测是关键，可以提高病人预后和存活率。 despite advances in medical imaging techniques, pancreatic cancer remains a challenging disease to detect. Endoscopic ultrasound (EUS) is the most effective diagnostic tool for detecting pancreatic cancer, but it requires expert interpretation of complex ultrasound images to complete a reliable patient scan. To obtain complete imaging of the pancreas, practitioners must learn to guide the endoscope into multiple "EUS stations" (anatomical locations), which provide different views of the pancreas. This is a difficult skill to learn, involving over 225 proctored procedures with the support of an experienced doctor. We build an AI-assisted tool that utilizes deep learning techniques to identify these stations of the stomach in real time during EUS procedures. This computer-assisted diagnostic (CAD) will help train doctors more efficiently. Historically, the challenge faced in developing such a tool has been the amount of retrospective labeling required by trained clinicians. To solve this, we developed an open-source user-friendly labeling web app that streamlines the process of annotating stations during the EUS procedure with minimal effort from the clinicians. Our research shows that employing only 43 procedures with no hyperparameter fine-tuning obtained a balanced accuracy of 90%, comparable to the current state of the art. In addition, we employ Grad-CAM, a visualization technology that provides clinicians with interpretable and explainable visualizations.
</details></li>
</ul>
<hr>
<h2 id="FGFusion-Fine-Grained-Lidar-Camera-Fusion-for-3D-Object-Detection"><a href="#FGFusion-Fine-Grained-Lidar-Camera-Fusion-for-3D-Object-Detection" class="headerlink" title="FGFusion: Fine-Grained Lidar-Camera Fusion for 3D Object Detection"></a>FGFusion: Fine-Grained Lidar-Camera Fusion for 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11804">http://arxiv.org/abs/2309.11804</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xaviergrool/fgfusion">https://github.com/xaviergrool/fgfusion</a></li>
<li>paper_authors: Zixuan Yin, Han Sun, Ningzhong Liu, Huiyu Zhou, Jiaquan Shen</li>
<li>for: 这个研究旨在提高自动驾驶中的3D检测精度，使用照相机和激光测距仪作为重要的感知器。</li>
<li>methods: 本研究提出了细部激光-照相机融合（FGFusion）方法，具有多个描述度的特征，并将其组合在一个细部的方式下。首先，设计了双轮幕架构造，以提取高层次semantic和低层次细部特征。其次，引入了帮助点云特征更好地学习细部空间信息的帮助网络。最后，提出了多个描述度融合（MSF），以融合最后N个图像和点云特征对应的特征对。</li>
<li>results: 实验结果显示，FGFusion方法在KITTI和Waymo两个流行的自动驾驶测试 benchmark上具有高效性。<details>
<summary>Abstract</summary>
Lidars and cameras are critical sensors that provide complementary information for 3D detection in autonomous driving. While most prevalent methods progressively downscale the 3D point clouds and camera images and then fuse the high-level features, the downscaled features inevitably lose low-level detailed information. In this paper, we propose Fine-Grained Lidar-Camera Fusion (FGFusion) that make full use of multi-scale features of image and point cloud and fuse them in a fine-grained way. First, we design a dual pathway hierarchy structure to extract both high-level semantic and low-level detailed features of the image. Second, an auxiliary network is introduced to guide point cloud features to better learn the fine-grained spatial information. Finally, we propose multi-scale fusion (MSF) to fuse the last N feature maps of image and point cloud. Extensive experiments on two popular autonomous driving benchmarks, i.e. KITTI and Waymo, demonstrate the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
（本文提出了一种新的方法，即细腻激光镜头混合（FGFusion），以便更好地利用摄像头和激光镜头中的多尺度特征。我们首先设计了一个双路层次结构，以提取摄像头中的高层次semantic特征和低层次细节特征。其次，我们引入了一个auxiliary网络，以帮助激光镜头特征更好地学习细腻空间信息。最后，我们提出了多尺度混合（MSF），以混合最后N个特征图。我们在两个流行的自动驾驶 benchmark上进行了广泛的实验，并证明了我们的方法的有效性。）Here's the breakdown of the translation:* 摄像头 (camera) becomes 摄像头 (cameras) in Simplified Chinese.* 激光镜头 (lidar) becomes 激光镜头 (lidars) in Simplified Chinese.* 多尺度特征 (multi-scale features) becomes 多尺度特征 (multiscale features) in Simplified Chinese.* 细腻激光镜头混合 (FGFusion) becomes 细腻激光镜头混合 (FGFusion) in Simplified Chinese.* 高层次semantic特征 (high-level semantic features) becomes 高层次semantic特征 (high-level semantic features) in Simplified Chinese.* 低层次细节特征 (low-level detailed features) becomes 低层次细节特征 (low-level detailed features) in Simplified Chinese.* auxiliary网络 (auxiliary network) becomes auxiliary网络 (auxiliary network) in Simplified Chinese.* 多尺度混合 (MSF) becomes 多尺度混合 (MSF) in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="A-Real-Time-Multi-Task-Learning-System-for-Joint-Detection-of-Face-Facial-Landmark-and-Head-Pose"><a href="#A-Real-Time-Multi-Task-Learning-System-for-Joint-Detection-of-Face-Facial-Landmark-and-Head-Pose" class="headerlink" title="A Real-Time Multi-Task Learning System for Joint Detection of Face, Facial Landmark and Head Pose"></a>A Real-Time Multi-Task Learning System for Joint Detection of Face, Facial Landmark and Head Pose</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11773">http://arxiv.org/abs/2309.11773</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingtian Wu, Liming Zhang</li>
<li>for: 本研究旨在提出一种实时多任务检测系统，能同时检测面部、面部特征点和头部姿态。</li>
<li>methods: 该系统基于广泛采用的YOLOv8检测框架，并在原始对象检测头上添加了多个特征点准备 regression 头，以高效地定位面部特征点。此外，我们在原始 YOLOv8 框架中进行了优化和改进。</li>
<li>results: 我们在 300W-LP 和 AFLW2000-3D 数据集上进行了广泛的实验， validate 了我们提出的模型在大角度面部姿态下的能力和实时性。结果表明，我们的模型可以有效地解决大角度面部姿态的挑战，并在这些相互连接的任务中具有实时性。<details>
<summary>Abstract</summary>
Extreme head postures pose a common challenge across a spectrum of facial analysis tasks, including face detection, facial landmark detection (FLD), and head pose estimation (HPE). These tasks are interdependent, where accurate FLD relies on robust face detection, and HPE is intricately associated with these key points. This paper focuses on the integration of these tasks, particularly when addressing the complexities posed by large-angle face poses. The primary contribution of this study is the proposal of a real-time multi-task detection system capable of simultaneously performing joint detection of faces, facial landmarks, and head poses. This system builds upon the widely adopted YOLOv8 detection framework. It extends the original object detection head by incorporating additional landmark regression head, enabling efficient localization of crucial facial landmarks. Furthermore, we conduct optimizations and enhancements on various modules within the original YOLOv8 framework. To validate the effectiveness and real-time performance of our proposed model, we conduct extensive experiments on 300W-LP and AFLW2000-3D datasets. The results obtained verify the capability of our model to tackle large-angle face pose challenges while delivering real-time performance across these interconnected tasks.
</details>
<details>
<summary>摘要</summary>
extreme head postures pose a common challenge across a spectrum of facial analysis tasks, including face detection, facial landmark detection (FLD), and head pose estimation (HPE). these tasks are interdependent, where accurate FLD relies on robust face detection, and HPE is intricately associated with these key points. this paper focuses on the integration of these tasks, particularly when addressing the complexities posed by large-angle face poses. the primary contribution of this study is the proposal of a real-time multi-task detection system capable of simultaneously performing joint detection of faces, facial landmarks, and head poses. this system builds upon the widely adopted YOLOv8 detection framework. it extends the original object detection head by incorporating additional landmark regression head, enabling efficient localization of crucial facial landmarks. furthermore, we conduct optimizations and enhancements on various modules within the original YOLOv8 framework. to validate the effectiveness and real-time performance of our proposed model, we conduct extensive experiments on 300w-lp and aflw2000-3d datasets. the results obtained verify the capability of our model to tackle large-angle face pose challenges while delivering real-time performance across these interconnected tasks.
</details></li>
</ul>
<hr>
<h2 id="Fast-Satellite-Tensorial-Radiance-Field-for-Multi-date-Satellite-Imagery-of-Large-Size"><a href="#Fast-Satellite-Tensorial-Radiance-Field-for-Multi-date-Satellite-Imagery-of-Large-Size" class="headerlink" title="Fast Satellite Tensorial Radiance Field for Multi-date Satellite Imagery of Large Size"></a>Fast Satellite Tensorial Radiance Field for Multi-date Satellite Imagery of Large Size</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11767">http://arxiv.org/abs/2309.11767</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tongtong Zhang, Yuanxiang Li</li>
<li>for: 这篇论文的目的是对于卫星图像进行重建和新视角synthesis，并且解决了现有NeRF模型的速度问题、必要的太阳信息输入和实现大型卫星图像的局限性。</li>
<li>methods: 这篇论文使用了多对多核网络（Multi-scale Tensor Decomposition, MTD）来模型彩色、体积密度和辅助变数，并且将问题视为一个净化任务，以缓解多日期影像之间的不一致。</li>
<li>results: 这篇论文的结果显示，SatensoRF比过去的Sat-NeRF系列具有更好的新视角synthesis表现，并且需要训练 fewer parameters，实现了更快的训练和测试速度，以及降低了计算 overhead。<details>
<summary>Abstract</summary>
Existing NeRF models for satellite images suffer from slow speeds, mandatory solar information as input, and limitations in handling large satellite images. In response, we present SatensoRF, which significantly accelerates the entire process while employing fewer parameters for satellite imagery of large size. Besides, we observed that the prevalent assumption of Lambertian surfaces in neural radiance fields falls short for vegetative and aquatic elements. In contrast to the traditional hierarchical MLP-based scene representation, we have chosen a multiscale tensor decomposition approach for color, volume density, and auxiliary variables to model the lightfield with specular color. Additionally, to rectify inconsistencies in multi-date imagery, we incorporate total variation loss to restore the density tensor field and treat the problem as a denosing task.To validate our approach, we conducted assessments of SatensoRF using subsets from the spacenet multi-view dataset, which includes both multi-date and single-date multi-view RGB images. Our results clearly demonstrate that SatensoRF surpasses the state-of-the-art Sat-NeRF series in terms of novel view synthesis performance. Significantly, SatensoRF requires fewer parameters for training, resulting in faster training and inference speeds and reduced computational demands.
</details>
<details>
<summary>摘要</summary>
现有的卫星图像NeRF模型受到慢速、必须输入太阳信息以及处理大容量卫星图像的限制。为此，我们提出了SatensoRF，它可以快速加速整个过程，并使用 fewer parameters 来处理大容量卫星图像。此外，我们发现了传统的 Lambertian 表面假设在神经辐射场中失去效果，特别是 для植物和水生元素。与传统的层次 MLB Scene 表示方法不同，我们选择了多尺度矩阵分解方法来odel 颜色、体积密度和辅助变量的辐射场，并将问题视为一个减除任务。为验证我们的方法，我们对Spacenet多视图数据集中的子集进行了评估，该数据集包括多日期和单日期多视图RGB图像。我们的结果显示，SatensoRF 超过了状态的艺术 Sat-NeRF 系列在新视图合成性能方面。此外，SatensoRF 具有更快的训练和推理速度，以及减少的计算需求。
</details></li>
</ul>
<hr>
<h2 id="Dictionary-Attack-on-IMU-based-Gait-Authentication"><a href="#Dictionary-Attack-on-IMU-based-Gait-Authentication" class="headerlink" title="Dictionary Attack on IMU-based Gait Authentication"></a>Dictionary Attack on IMU-based Gait Authentication</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11766">http://arxiv.org/abs/2309.11766</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rajeshjnu2006/dictionaryattackonimugait">https://github.com/rajeshjnu2006/dictionaryattackonimugait</a></li>
<li>paper_authors: Rajesh Kumar, Can Isik, Chilukuri K. Mohan</li>
<li>For: The paper aims to investigate the vulnerability of gait pattern-based authentication systems using inertial measurement units (IMUs) built into smartphones, and to develop a dictionary attack on these systems.* Methods: The paper uses a dataset of 178 unique IMUGait patterns collected from nine physically and demographically diverse individuals, and tests the attack idea on various user authentication models.* Results: The paper finds that it is possible to build a dictionary of IMUGait patterns and use it to launch an attack or find an imitator who can actively reproduce IMUGait patterns that match the target’s IMUGait pattern, and that the error rates of the authentication systems before and after the attack challenge the belief that these systems are the most difficult to spoof.Here are the three points in Simplified Chinese text:* For: 这个论文目的是研究基于智能手机内置的倾斜测量单元（IMU）记录的步幅模式认证系统的攻击性，并开发一种词汇攻击模型。* Methods: 论文使用了9名物理和人口学多样化的个体，在不同的四个可控和可适应步factor（速度、步长、步宽、股提升）下，记录了178个独特的IMUGait模式。这些模式被用来攻击多种用户认证模型。* Results: 论文发现可以建立一个IMUGait模式词汇，并使用它来发动攻击或找到一个可以活动地复制目标IMUGait模式的imitator。此外，论文还发现在攻击前和攻击后的错误率下降，这会让人们对认证系统的安全性产生更多的怀疑。<details>
<summary>Abstract</summary>
We present a novel adversarial model for authentication systems that use gait patterns recorded by the inertial measurement unit (IMU) built into smartphones. The attack idea is inspired by and named after the concept of a dictionary attack on knowledge (PIN or password) based authentication systems. In particular, this work investigates whether it is possible to build a dictionary of IMUGait patterns and use it to launch an attack or find an imitator who can actively reproduce IMUGait patterns that match the target's IMUGait pattern. Nine physically and demographically diverse individuals walked at various levels of four predefined controllable and adaptable gait factors (speed, step length, step width, and thigh-lift), producing 178 unique IMUGait patterns. Each pattern attacked a wide variety of user authentication models. The deeper analysis of error rates (before and after the attack) challenges the belief that authentication systems based on IMUGait patterns are the most difficult to spoof; further research is needed on adversarial models and associated countermeasures.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的反对抗模型，用于 Authentication systems that use gait patterns recorded by the inertial measurement unit (IMU) built into smartphones. 攻击的想法源于和named after the concept of a dictionary attack on knowledge (PIN or password) based authentication systems. 特别是，这项工作研究了是否可以构建一个IMUGait模式字典，并使用其发动攻击或找到一个可以活动地重现IMUGait模式的imitator。 nine physically and demographically diverse individuals walked at various levels of four predefined controllable and adaptable gait factors (speed, step length, step width, and thigh-lift), producing 178 unique IMUGait patterns. each pattern attacked a wide variety of user authentication models. 更深入的分析错误率 (before and after the attack) 挑战了认为基于IMUGait模式的身份验证系统是最难模仿的; 需要进一步的研究反对模型和相关的防御措施。
</details></li>
</ul>
<hr>
<h2 id="SAM-OCTA-A-Fine-Tuning-Strategy-for-Applying-Foundation-Model-to-OCTA-Image-Segmentation-Tasks"><a href="#SAM-OCTA-A-Fine-Tuning-Strategy-for-Applying-Foundation-Model-to-OCTA-Image-Segmentation-Tasks" class="headerlink" title="SAM-OCTA: A Fine-Tuning Strategy for Applying Foundation Model to OCTA Image Segmentation Tasks"></a>SAM-OCTA: A Fine-Tuning Strategy for Applying Foundation Model to OCTA Image Segmentation Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11758">http://arxiv.org/abs/2309.11758</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shellredia/sam-octa">https://github.com/shellredia/sam-octa</a></li>
<li>paper_authors: Chengliang Wang, Xinrun Chen, Haojian Ning, Shiying Li</li>
<li>for: 这个论文主要是为了解决Optical coherence tomography angiography（OCTA）图像分割 зада务中的特定目标segmentation问题。</li>
<li>methods: 这个论文使用了low-rank adaptation技术和基于Foundation model的微调，并提出了相应的提示点生成策略来处理不同的分割任务。</li>
<li>results: 该方法在OCTA-500 dataset上进行了实验，并达到了当前最佳性能指标，同时也能够实现当地血管分 segmentation和有效的血管-血管分 segmentation，这些问题在之前的工作中尚未得到了好的解决。<details>
<summary>Abstract</summary>
In the analysis of optical coherence tomography angiography (OCTA) images, the operation of segmenting specific targets is necessary. Existing methods typically train on supervised datasets with limited samples (approximately a few hundred), which can lead to overfitting. To address this, the low-rank adaptation technique is adopted for foundation model fine-tuning and proposed corresponding prompt point generation strategies to process various segmentation tasks on OCTA datasets. This method is named SAM-OCTA and has been experimented on the publicly available OCTA-500 dataset. While achieving state-of-the-art performance metrics, this method accomplishes local vessel segmentation as well as effective artery-vein segmentation, which was not well-solved in previous works. The code is available at: https://github.com/ShellRedia/SAM-OCTA.
</details>
<details>
<summary>摘要</summary>
在Optical coherence tomography angiography（OCTA）图像分析中，需要进行特定目标 segmentation 操作。现有方法通常是通过指导数据集（约几百个样本）进行超参数化训练，这可能会导致过拟合。为解决这问题，我们采用了低级别适应技术，并提出了相应的提示点生成策略，以处理不同的 segmentation 任务。这种方法被称为SAM-OCTA，并在公共可用的OCTA-500数据集上进行了实验。它不仅达到了当前最佳性能指标，还能够有效地完成本地血管分 segmentation 以及血管-血管分 segmentation，这在前一些工作中尚未得到妥善解决。代码可以在：https://github.com/ShellRedia/SAM-OCTA 中找到。
</details></li>
</ul>
<hr>
<h2 id="A-Vision-Centric-Approach-for-Static-Map-Element-Annotation"><a href="#A-Vision-Centric-Approach-for-Static-Map-Element-Annotation" class="headerlink" title="A Vision-Centric Approach for Static Map Element Annotation"></a>A Vision-Centric Approach for Static Map Element Annotation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11754">http://arxiv.org/abs/2309.11754</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/manymuch/cama">https://github.com/manymuch/cama</a></li>
<li>paper_authors: Jiaxin Zhang, Shiyuan Chen, Haoran Yin, Ruohong Mei, Xuan Liu, Cong Yang, Qian Zhang, Wei Sui</li>
<li>for: 提供高质量的地图元素标注数据，帮助提高静止地图建模算法的准确率和一致性。</li>
<li>methods: 提出了一种视觉中心的方法，无需LiDAR输入可以生成高质量的3D地图元素标注。</li>
<li>results: 对于流行的nuScenes dataset，使用CAMA方法可以提供高效和准确的标注，并且与原始nuScenes静止地图元素比较，模型训练使用CAMA标注得到的 reprojection 误差较低（例如，4.73 vs. 8.03像素）。<details>
<summary>Abstract</summary>
The recent development of online static map element (a.k.a. HD Map) construction algorithms has raised a vast demand for data with ground truth annotations. However, available public datasets currently cannot provide high-quality training data regarding consistency and accuracy. To this end, we present CAMA: a vision-centric approach for Consistent and Accurate Map Annotation. Without LiDAR inputs, our proposed framework can still generate high-quality 3D annotations of static map elements. Specifically, the annotation can achieve high reprojection accuracy across all surrounding cameras and is spatial-temporal consistent across the whole sequence. We apply our proposed framework to the popular nuScenes dataset to provide efficient and highly accurate annotations. Compared with the original nuScenes static map element, models trained with annotations from CAMA achieve lower reprojection errors (e.g., 4.73 vs. 8.03 pixels).
</details>
<details>
<summary>摘要</summary>
“Recent developments in online static map element (a.k.a. HD Map) construction algorithms have led to a significant demand for high-quality training data. However, public datasets currently available do not provide consistent and accurate data. To address this issue, we propose CAMA, a vision-centric approach for Consistent and Accurate Map Annotation. Our framework can generate high-quality 3D annotations of static map elements without relying on LiDAR inputs. Specifically, the annotations can achieve high reprojection accuracy across all surrounding cameras and are spatial-temporally consistent across the entire sequence. We apply our proposed framework to the popular nuScenes dataset to provide efficient and highly accurate annotations. Compared with the original nuScenes static map element, models trained with annotations from CAMA achieve lower reprojection errors (e.g., 4.73 vs. 8.03 pixels).”Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="PIE-Simulating-Disease-Progression-via-Progressive-Image-Editing"><a href="#PIE-Simulating-Disease-Progression-via-Progressive-Image-Editing" class="headerlink" title="PIE: Simulating Disease Progression via Progressive Image Editing"></a>PIE: Simulating Disease Progression via Progressive Image Editing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11745">http://arxiv.org/abs/2309.11745</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/irohxu/pie">https://github.com/irohxu/pie</a></li>
<li>paper_authors: Kaizhao Liang, Xu Cao, Kuei-Da Liao, Tianren Gao, Wenqian Ye, Zhengyu Chen, Jianguo Cao, Tejas Nama, Jimeng Sun</li>
<li>for: 预测疾病进程和诊断支持</li>
<li>methods: 基于文本生成模型的疾病进程模拟</li>
<li>results: 比CLIP分数和疾病分类信息更高的疾病进程生成Translation:</li>
<li>for: 用于预测疾病进程和诊断支持</li>
<li>methods: 使用基于文本生成模型的疾病进程模拟方法</li>
<li>results: 比CLIP分数和疾病分类信息更高的疾病进程生成结果<details>
<summary>Abstract</summary>
Disease progression simulation is a crucial area of research that has significant implications for clinical diagnosis, prognosis, and treatment. One major challenge in this field is the lack of continuous medical imaging monitoring of individual patients over time. To address this issue, we develop a novel framework termed Progressive Image Editing (PIE) that enables controlled manipulation of disease-related image features, facilitating precise and realistic disease progression simulation. Specifically, we leverage recent advancements in text-to-image generative models to simulate disease progression accurately and personalize it for each patient. We theoretically analyze the iterative refining process in our framework as a gradient descent with an exponentially decayed learning rate. To validate our framework, we conduct experiments in three medical imaging domains. Our results demonstrate the superiority of PIE over existing methods such as Stable Diffusion Walk and Style-Based Manifold Extrapolation based on CLIP score (Realism) and Disease Classification Confidence (Alignment). Our user study collected feedback from 35 veteran physicians to assess the generated progressions. Remarkably, 76.2% of the feedback agrees with the fidelity of the generated progressions. To our best knowledge, PIE is the first of its kind to generate disease progression images meeting real-world standards. It is a promising tool for medical research and clinical practice, potentially allowing healthcare providers to model disease trajectories over time, predict future treatment responses, and improve patient outcomes.
</details>
<details>
<summary>摘要</summary>
疾病发展模拟是医学研究中一个关键领域，具有诊断、诊断和治疗等方面的重要意义。然而，在这个领域中一个主要挑战是缺乏持续医疗影像监测个体患者的能力。为了解决这个问题，我们开发了一个名为进步图像编辑（PIE）的新框架。PIE可以准确地控制疾病相关的图像特征，以便实现 precisel 和现实的疾病发展模拟。具体来说，我们利用了最新的文本生成图像技术来模拟疾病发展，并为每个患者个性化模拟。我们对PIE的迭代缩进过程进行了理论分析，并证明其等价于梯度下降算法。为了验证PIE的有效性，我们在医疗影像领域进行了三个领域的实验。我们的结果表明PIE在CLIP分数（现实）和疾病分类信心度（对齐）等方面比存在方法更高。我们的用户测试收集了35名经验丰富的医生的反馈，并证明76.2%的反馈同意生成的进步准确。到目前为止，PIE是第一个满足现实标准的疾病发展图像生成工具。它是医学研究和临床实践中的一个有前途的工具，可能允许医疗提供者在时间上模拟疾病轨迹，预测未来治疗响应，并提高患者的结果。
</details></li>
</ul>
<hr>
<h2 id="CPR-Coach-Recognizing-Composite-Error-Actions-based-on-Single-class-Training"><a href="#CPR-Coach-Recognizing-Composite-Error-Actions-based-on-Single-class-Training" class="headerlink" title="CPR-Coach: Recognizing Composite Error Actions based on Single-class Training"></a>CPR-Coach: Recognizing Composite Error Actions based on Single-class Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11718">http://arxiv.org/abs/2309.11718</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shunli Wang, Qing Yu, Shuaibing Wang, Dingkang Yang, Liuzhen Su, Xiao Zhao, Haopeng Kuang, Peixuan Zhang, Peng Zhai, Lihua Zhang</li>
<li>for: 这篇论文的目的是为了提高紧急救援中的心脏复苏技巧评估，并提出了一个基于视觉数据的系统来识别和评估心脏复苏技巧的错误动作。</li>
<li>methods: 这篇论文使用了视觉数据来定义13种单一错误动作和74种合成错误动作，并建立了一个名为CPR-Coach的视觉数据集。然后，这篇论文对现有的动作识别模型进行了比较和探讨，以解决单簇训练和多簇测试的问题。</li>
<li>results: 这篇论文的实验结果显示，使用ImagineNet框架可以帮助模型增强多错误识别能力，并且可以解决单簇训练和多簇测试的问题。<details>
<summary>Abstract</summary>
The fine-grained medical action analysis task has received considerable attention from pattern recognition communities recently, but it faces the problems of data and algorithm shortage. Cardiopulmonary Resuscitation (CPR) is an essential skill in emergency treatment. Currently, the assessment of CPR skills mainly depends on dummies and trainers, leading to high training costs and low efficiency. For the first time, this paper constructs a vision-based system to complete error action recognition and skill assessment in CPR. Specifically, we define 13 types of single-error actions and 74 types of composite error actions during external cardiac compression and then develop a video dataset named CPR-Coach. By taking the CPR-Coach as a benchmark, this paper thoroughly investigates and compares the performance of existing action recognition models based on different data modalities. To solve the unavoidable Single-class Training & Multi-class Testing problem, we propose a humancognition-inspired framework named ImagineNet to improve the model's multierror recognition performance under restricted supervision. Extensive experiments verify the effectiveness of the framework. We hope this work could advance research toward fine-grained medical action analysis and skill assessment. The CPR-Coach dataset and the code of ImagineNet are publicly available on Github.
</details>
<details>
<summary>摘要</summary>
Recently, the fine-grained medical action analysis task has received significant attention from the pattern recognition community, but it faces challenges such as data and algorithm shortages. cardiopulmonary resuscitation (CPR) is an essential skill in emergency treatment, but the current assessment of CPR skills mainly relies on dummies and trainers, leading to high training costs and low efficiency. For the first time, this paper constructs a vision-based system to complete error action recognition and skill assessment in CPR. Specifically, we define 13 types of single-error actions and 74 types of composite error actions during external cardiac compression and develop a video dataset named CPR-Coach. By using the CPR-Coach as a benchmark, this paper thoroughly investigates and compares the performance of existing action recognition models based on different data modalities. To solve the unavoidable Single-class Training & Multi-class Testing problem, we propose a human-cognition-inspired framework named ImagineNet to improve the model's multierror recognition performance under restricted supervision. Extensive experiments verify the effectiveness of the framework. We hope this work could advance research toward fine-grained medical action analysis and skill assessment. The CPR-Coach dataset and the code of ImagineNet are publicly available on Github.
</details></li>
</ul>
<hr>
<h2 id="Deshadow-Anything-When-Segment-Anything-Model-Meets-Zero-shot-shadow-removal"><a href="#Deshadow-Anything-When-Segment-Anything-Model-Meets-Zero-shot-shadow-removal" class="headerlink" title="Deshadow-Anything: When Segment Anything Model Meets Zero-shot shadow removal"></a>Deshadow-Anything: When Segment Anything Model Meets Zero-shot shadow removal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11715">http://arxiv.org/abs/2309.11715</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiao Feng Zhang, Tian Yi Song, Jia Wei Yao</li>
<li>for: Image shadow removal and image restoration.</li>
<li>methods: 	+ Deshadow-Anything: A diffusion model that diffuses along the edges and textures of an image to remove shadows while preserving image details.	+ Multi-Self-Attention Guidance (MSAG) and adaptive input perturbation (DDPM-AIP) to accelerate the iterative training speed of diffusion.</li>
<li>results: 	+ Effective improvement in image restoration performance in shadow removal tasks.<details>
<summary>Abstract</summary>
Segment Anything (SAM), an advanced universal image segmentation model trained on an expansive visual dataset, has set a new benchmark in image segmentation and computer vision. However, it faced challenges when it came to distinguishing between shadows and their backgrounds. To address this, we developed Deshadow-Anything, considering the generalization of large-scale datasets, and we performed Fine-tuning on large-scale datasets to achieve image shadow removal. The diffusion model can diffuse along the edges and textures of an image, helping to remove shadows while preserving the details of the image. Furthermore, we design Multi-Self-Attention Guidance (MSAG) and adaptive input perturbation (DDPM-AIP) to accelerate the iterative training speed of diffusion. Experiments on shadow removal tasks demonstrate that these methods can effectively improve image restoration performance.
</details>
<details>
<summary>摘要</summary>
segments anything (SAM), an advanced universal image segmentation model trained on an expansive visual dataset, has set a new benchmark in image segmentation and computer vision. However, it faced challenges when it came to distinguishing between shadows and their backgrounds. To address this, we developed Deshadow-Anything, considering the generalization of large-scale datasets, and we performed Fine-tuning on large-scale datasets to achieve image shadow removal. The diffusion model can diffuse along the edges and textures of an image, helping to remove shadows while preserving the details of the image. Furthermore, we design Multi-Self-Attention Guidance (MSAG) and adaptive input perturbation (DDPM-AIP) to accelerate the iterative training speed of diffusion. Experiments on shadow removal tasks demonstrate that these methods can effectively improve image restoration performance.
</details></li>
</ul>
<hr>
<h2 id="MoDA-Leveraging-Motion-Priors-from-Videos-for-Advancing-Unsupervised-Domain-Adaptation-in-Semantic-Segmentation"><a href="#MoDA-Leveraging-Motion-Priors-from-Videos-for-Advancing-Unsupervised-Domain-Adaptation-in-Semantic-Segmentation" class="headerlink" title="MoDA: Leveraging Motion Priors from Videos for Advancing Unsupervised Domain Adaptation in Semantic Segmentation"></a>MoDA: Leveraging Motion Priors from Videos for Advancing Unsupervised Domain Adaptation in Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11711">http://arxiv.org/abs/2309.11711</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fei Pan, Xu Yin, Seokju Lee, Sungeui Yoon, In So Kweon</li>
<li>for: 这篇论文的目的是提出一个实用的领域对预设不足的目标领域进行Semantic Segmentation任务。</li>
<li>methods: 这篇论文使用自我监督学来学习 objet motion 的自适应表现，并且将其应用到对预设不足的目标领域进行Semantic Segmentation。</li>
<li>results: 实验结果显示，这篇论文的方法可以对多个测试 benchmark 进行优化，并且可以与现有的州chart-of-the-art方法相互协同运作以进一步改善表现。<details>
<summary>Abstract</summary>
Unsupervised domain adaptation (UDA) is an effective approach to handle the lack of annotations in the target domain for the semantic segmentation task. In this work, we consider a more practical UDA setting where the target domain contains sequential frames of the unlabeled videos which are easy to collect in practice. A recent study suggests self-supervised learning of the object motion from unlabeled videos with geometric constraints. We design a motion-guided domain adaptive semantic segmentation framework (MoDA), that utilizes self-supervised object motion to learn effective representations in the target domain. MoDA differs from previous methods that use temporal consistency regularization for the target domain frames. Instead, MoDA deals separately with the domain alignment on the foreground and background categories using different strategies. Specifically, MoDA contains foreground object discovery and foreground semantic mining to align the foreground domain gaps by taking the instance-level guidance from the object motion. Additionally, MoDA includes background adversarial training which contains a background category-specific discriminator to handle the background domain gaps. Experimental results on multiple benchmarks highlight the effectiveness of MoDA against existing approaches in the domain adaptive image segmentation and domain adaptive video segmentation. Moreover, MoDA is versatile and can be used in conjunction with existing state-of-the-art approaches to further improve performance.
</details>
<details>
<summary>摘要</summary>
无监督领域适应（USDA）是一种有效的方法，用于处理目标领域无监督标注的 semantic segmentation 任务中的缺乏标注问题。在这项工作中，我们考虑了更实际的 USDA 设定，其中目标领域包含序列帧的无标注视频，这些视频易于在实践中收集。一项研究建议通过不监督视频中的对象运动学习自我监督学习。我们设计了一个带有自我监督对象运动学习的动态适应 semantic segmentation 框架（MoDA），该框架利用了自我监督对象运动来学习有效的表示。MoDA 与前期方法不同，它不使用目标领域帧的时间一致约束，而是分别对前景和背景类使用不同的策略进行领域对应。具体来说，MoDA 包括前景对象发现和前景Semantic挖掘，以启用目标领域前景异常的匹配。此外，MoDA 还包括背景反馈学习，其中包括一个特定于背景类别的反馈器，以处理背景领域异常。实验结果表明，MoDA 在多个 benchmark 上表现出色，与现有方法相比，具有更高的效果。此外，MoDA 可以与现有状态监督的方法结合使用，以进一步提高性能。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Long-Short-Temporal-Attention-Network-for-Unsupervised-Video-Object-Segmentation"><a href="#Efficient-Long-Short-Temporal-Attention-Network-for-Unsupervised-Video-Object-Segmentation" class="headerlink" title="Efficient Long-Short Temporal Attention Network for Unsupervised Video Object Segmentation"></a>Efficient Long-Short Temporal Attention Network for Unsupervised Video Object Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11707">http://arxiv.org/abs/2309.11707</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ping Li, Yu Zhang, Li Yuan, Huaxin Xiao, Binbin Lin, Xianghua Xu</li>
<li>for: Unsupervised Video Object Segmentation (VOS)</li>
<li>methods: Long-Short Temporal Attention network (LSTA)</li>
<li>results: Promising performances with high efficiency on several benchmarks.Here’s the full text in Simplified Chinese:</li>
<li>for: 本研究探讨了无监督视频对象分割（VOS）问题，旨在在视频中快速、高效地分割主要背景 объек。</li>
<li>methods: 我们提出了一种高效的 Long-Short Temporal Attention 网络（简称 LSTA），它包括两个主要模块：长期记忆和短期注意力。前者捕捉了过去帧和当前帧中长期全局像素关系，模型了不断存在的对象的出现模式。而后者揭示了当前帧和一 nearby frame 中短期局部像素关系，模型了移动对象的运动模式。为了加速推理，我们采用了高效投影和地址预测来实现近似线性时间复杂度。</li>
<li>results: 我们在多个 benchmark 上进行了广泛的实验，并证明了提出的方法在高效性和性能方面具有惊人的表现。<details>
<summary>Abstract</summary>
Unsupervised Video Object Segmentation (VOS) aims at identifying the contours of primary foreground objects in videos without any prior knowledge. However, previous methods do not fully use spatial-temporal context and fail to tackle this challenging task in real-time. This motivates us to develop an efficient Long-Short Temporal Attention network (termed LSTA) for unsupervised VOS task from a holistic view. Specifically, LSTA consists of two dominant modules, i.e., Long Temporal Memory and Short Temporal Attention. The former captures the long-term global pixel relations of the past frames and the current frame, which models constantly present objects by encoding appearance pattern. Meanwhile, the latter reveals the short-term local pixel relations of one nearby frame and the current frame, which models moving objects by encoding motion pattern. To speedup the inference, the efficient projection and the locality-based sliding window are adopted to achieve nearly linear time complexity for the two light modules, respectively. Extensive empirical studies on several benchmarks have demonstrated promising performances of the proposed method with high efficiency.
</details>
<details>
<summary>摘要</summary>
Unsupervised Video Object Segmentation (VOS) targets identifying primary foreground objects' contours in videos without prior knowledge. However, previous methods neglect spatial-temporal context and can't handle this challenging task in real-time. This motivates us to develop an efficient Long-Short Temporal Attention network (LSTA) for unsupervised VOS from a holistic view. Specifically, LSTA consists of two main modules: Long Temporal Memory and Short Temporal Attention. The former captures long-term global pixel relations of past frames and the current frame, modeling constantly present objects by encoding appearance pattern. Meanwhile, the latter reveals short-term local pixel relations of one nearby frame and the current frame, modeling moving objects by encoding motion pattern. To speed up inference, efficient projection and locality-based sliding window are adopted to achieve nearly linear time complexity for the two light modules, respectively. Extensive empirical studies on several benchmarks have demonstrated the proposed method's promising performance with high efficiency.
</details></li>
</ul>
<hr>
<h2 id="Meta-OOD-Learning-for-Continuously-Adaptive-OOD-Detection"><a href="#Meta-OOD-Learning-for-Continuously-Adaptive-OOD-Detection" class="headerlink" title="Meta OOD Learning for Continuously Adaptive OOD Detection"></a>Meta OOD Learning for Continuously Adaptive OOD Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11705">http://arxiv.org/abs/2309.11705</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinheng Wu, Jie Lu, Zhen Fang, Guangquan Zhang</li>
<li>for: 这个研究是为了提出一种可靠地检测深度学习模型中的外部遗传数据（out-of-distribution，OOD）的方法，并且可以在实际世界中的不断变化和迁移中进行适应。</li>
<li>methods: 这个研究使用了一种名为“可动数据适应”（continuously adaptive out-of-distribution，CAOOD）的设定，并且提出了一个名为“多元外部遗传学习”（meta out-of-distribution learning，MOL）的方法来解决CAOOD。MOL使用了一个学习到适应的图表，以便在训练和测试过程中快速适应新的分布。</li>
<li>results: 实验结果显示，MOL可以保持ID分类精度和OOD检测性能在不断变化的分布下，并且在实际世界中的应用中可以提供更高的可靠性和效能。<details>
<summary>Abstract</summary>
Out-of-distribution (OOD) detection is crucial to modern deep learning applications by identifying and alerting about the OOD samples that should not be tested or used for making predictions. Current OOD detection methods have made significant progress when in-distribution (ID) and OOD samples are drawn from static distributions. However, this can be unrealistic when applied to real-world systems which often undergo continuous variations and shifts in ID and OOD distributions over time. Therefore, for an effective application in real-world systems, the development of OOD detection methods that can adapt to these dynamic and evolving distributions is essential. In this paper, we propose a novel and more realistic setting called continuously adaptive out-of-distribution (CAOOD) detection which targets on developing an OOD detection model that enables dynamic and quick adaptation to a new arriving distribution, with insufficient ID samples during deployment time. To address CAOOD, we develop meta OOD learning (MOL) by designing a learning-to-adapt diagram such that a good initialized OOD detection model is learned during the training process. In the testing process, MOL ensures OOD detection performance over shifting distributions by quickly adapting to new distributions with a few adaptations. Extensive experiments on several OOD benchmarks endorse the effectiveness of our method in preserving both ID classification accuracy and OOD detection performance on continuously shifting distributions.
</details>
<details>
<summary>摘要</summary>
现代深度学习应用中，外围分布（OOD）检测是非常重要的，可以识别并警告不应该用于预测的外围样本。现有的OOD检测方法在固定分布下已经做出了 significiant progress。然而，这可能是不现实的，因为实际系统经常发生连续变化和分布的变化。因此，为了有效地应用于实际系统，需要开发能够适应动态和演化分布的OOD检测方法。在这篇论文中，我们提出了一种新的设定，即持续适应外围（CAOOD）检测，旨在开发一种能够在部署时动态适应新 arriving 分布的OOD检测模型。为了解决CAOOD，我们开发了元外围学习（MOL），它是一种学习适应图表，可以在训练过程中初始化一个好的OOD检测模型，并在测试过程中快速适应新的分布，只需要几次适应。我们在多个OOD benchmark上进行了广泛的实验，证明了我们的方法可以在连续变化的分布下保持ID分类精度和OOD检测性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/21/cs.CV_2023_09_21/" data-id="cloqtaera00itgh8846rw7834" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_09_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/21/cs.AI_2023_09_21/" class="article-date">
  <time datetime="2023-09-21T12:00:00.000Z" itemprop="datePublished">2023-09-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/21/cs.AI_2023_09_21/">cs.AI - 2023-09-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Curriculum-Reinforcement-Learning-via-Morphology-Environment-Co-Evolution"><a href="#Curriculum-Reinforcement-Learning-via-Morphology-Environment-Co-Evolution" class="headerlink" title="Curriculum Reinforcement Learning via Morphology-Environment Co-Evolution"></a>Curriculum Reinforcement Learning via Morphology-Environment Co-Evolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12529">http://arxiv.org/abs/2309.12529</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuang Ao, Tianyi Zhou, Guodong Long, Xuan Song, Jing Jiang</li>
<li>for: 本研究旨在帮助RL机器人在不同环境中学习和适应，以提高其总体性和可重复性。</li>
<li>methods: 本研究使用了“形态环境共EVOLUTION（MECE）”方法，在这种方法中，RL机器人的形态和环境会不断地更新和改进，以适应环境的变化。</li>
<li>results: 实验结果表明，通过MECE方法训练RL机器人的形态和策略，可以在未看过的测试环境中表现出显著更好的普适性和可重复性。此外，我们的剥离分析表明，MECE方法的成功与形态和环境的共EVOLUTION有直接的关系。<details>
<summary>Abstract</summary>
Throughout long history, natural species have learned to survive by evolving their physical structures adaptive to the environment changes. In contrast, current reinforcement learning (RL) studies mainly focus on training an agent with a fixed morphology (e.g., skeletal structure and joint attributes) in a fixed environment, which can hardly generalize to changing environments or new tasks. In this paper, we optimize an RL agent and its morphology through ``morphology-environment co-evolution (MECE)'', in which the morphology keeps being updated to adapt to the changing environment, while the environment is modified progressively to bring new challenges and stimulate the improvement of the morphology. This leads to a curriculum to train generalizable RL, whose morphology and policy are optimized for different environments. Instead of hand-crafting the curriculum, we train two policies to automatically change the morphology and the environment. To this end, (1) we develop two novel and effective rewards for the two policies, which are solely based on the learning dynamics of the RL agent; (2) we design a scheduler to automatically determine when to change the environment and the morphology. In experiments on two classes of tasks, the morphology and RL policies trained via MECE exhibit significantly better generalization performance in unseen test environments than SOTA morphology optimization methods. Our ablation studies on the two MECE policies further show that the co-evolution between the morphology and environment is the key to the success.
</details>
<details>
<summary>摘要</summary>
通过历史的演化，自然种类学会适应环境变化，而现代强化学习（RL）研究主要集中在训练一个固定结构（例如骨架和关节特性）在固定环境中，这难以应对变化环境或新任务。在这篇论文中，我们通过“形态环境共演化（MECE）”优化RL代理人和其形态，在形态不断更新以适应变化环境的同时，环境也不断改进以带来新的挑战和适应性提升。这导致了一个训练通用RL的课程，其中形态和策略在不同环境中得到优化。而不是手动设计课程，我们训练了两个政策来自动改变形态和环境。为此，我们：1. 开发了两种新有效的奖励，以便为两个政策提供动力学学习RL代理人的学习动态;2. 设计了一个计划器，以自动确定改变形态和环境的时间。在两类任务上进行了实验，MECE训练的形态和RL策略在未看到的测试环境中表现出了显著更好的普适性。我们的剖析研究还表明，MECE中形态和环境之间的共演化是成功的关键。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-Graph-Embedding-An-Overview"><a href="#Knowledge-Graph-Embedding-An-Overview" class="headerlink" title="Knowledge Graph Embedding: An Overview"></a>Knowledge Graph Embedding: An Overview</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12501">http://arxiv.org/abs/2309.12501</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Xiou Ge, Yun-Cheng Wang, Bin Wang, C. -C. Jay Kuo</li>
<li>for: 本文概述了目前knowledge graph completion（KGC）领域的研究进展，尤其是两种主要的knowledge graph embedding（KGE）设计方法：距离基于方法和semantic matching基于方法。</li>
<li>methods: 本文总结了 reciently proposed models的关系，并发现了这些模型之间的联系。此外，文章还介绍了一种新的approach for KGC，即通过预训练语言模型（PLM）和实体和关系的文本描述来完成KGC。</li>
<li>results: 文章介绍了一种基于2D和3D affine操作的CompoundE和CompoundE3D模型，以及一种 combining KGE embedding方法与PLMs的新方法。这些方法可以提供更高的explainability和渐进性。<details>
<summary>Abstract</summary>
Many mathematical models have been leveraged to design embeddings for representing Knowledge Graph (KG) entities and relations for link prediction and many downstream tasks. These mathematically-inspired models are not only highly scalable for inference in large KGs, but also have many explainable advantages in modeling different relation patterns that can be validated through both formal proofs and empirical results. In this paper, we make a comprehensive overview of the current state of research in KG completion. In particular, we focus on two main branches of KG embedding (KGE) design: 1) distance-based methods and 2) semantic matching-based methods. We discover the connections between recently proposed models and present an underlying trend that might help researchers invent novel and more effective models. Next, we delve into CompoundE and CompoundE3D, which draw inspiration from 2D and 3D affine operations, respectively. They encompass a broad spectrum of techniques including distance-based and semantic-based methods. We will also discuss an emerging approach for KG completion which leverages pre-trained language models (PLMs) and textual descriptions of entities and relations and offer insights into the integration of KGE embedding methods with PLMs for KG completion.
</details>
<details>
<summary>摘要</summary>
许多数学模型已经被应用于设计知识 graphs (KG) 实体和关系的 Representation 以进行链接预测和多种下游任务。这些数学静态的模型不仅可以在大型 KG 中进行可扩展的推理，而且具有许多可解释的优势，可以通过正式证明和实际结果来验证不同的关系模式。在这篇论文中，我们对当前 KG 完成研究进行了全面的概述。特别是，我们关注了两个主要的 KG 嵌入 (KGE) 设计分支：1) 距离基于方法和 2) 含义匹配基于方法。我们发现了最新提出的模型之间的连接，并提出了一个可能的趋势，可以帮助研究人员创造更有效和新的模型。接着，我们探讨了 CompoundE 和 CompoundE3D，它们继承了2D和3D afine操作的想法。它们包括距离基于和含义基于的多种技术。我们还讨论了一种emergingapproach для KG completion，它利用预训练的语言模型 (PLMs) 和实体和关系的文本描述，并提供了 KGE嵌入方法与 PLMs 的集成的思路。
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Impact-of-Training-Data-Distribution-and-Subword-Tokenization-on-Gender-Bias-in-Machine-Translation"><a href="#Exploring-the-Impact-of-Training-Data-Distribution-and-Subword-Tokenization-on-Gender-Bias-in-Machine-Translation" class="headerlink" title="Exploring the Impact of Training Data Distribution and Subword Tokenization on Gender Bias in Machine Translation"></a>Exploring the Impact of Training Data Distribution and Subword Tokenization on Gender Bias in Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12491">http://arxiv.org/abs/2309.12491</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tomlimi/MT-Tokenizer-Bias">https://github.com/tomlimi/MT-Tokenizer-Bias</a></li>
<li>paper_authors: Bar Iluz, Tomasz Limisiewicz, Gabriel Stanovsky, David Mareček</li>
<li>for: This paper focuses on the effect of tokenization on gender bias in machine translation, specifically examining the interactions between the frequency of gendered profession names in training data, their representation in the subword tokenizer’s vocabulary, and gender bias.</li>
<li>methods: The authors use a combination of data analysis and machine learning techniques to study the impact of tokenization on gender bias in machine translation. They analyze the subword splits of gendered profession names in the training data and use fine-tuning of the token embedding layer to decrease the gender bias in the model.</li>
<li>results: The authors find that the imbalance of gender forms in the model’s training corpus is a major factor contributing to gender bias, and that analyzing subword splits provides good estimates of gender-form imbalance in the training data. They also show that fine-tuning just the token embedding layer can decrease the gap in gender prediction accuracy between female and male forms without impairing the translation quality.Here are the three points in Simplified Chinese text:</li>
<li>for: 这个论文研究了机器翻译中的gender bias问题，具体来说是研究训练数据中gendered profession名称的频率、tokenizer的词库中gendered profession名称的表示方式和gender bias之间的交互关系。</li>
<li>methods: 作者们使用了数据分析和机器学习技术来研究tokenization对机器翻译中的gender bias的影响。他们分析了训练数据中gendered profession名称的subword splits，并通过token embedding层的微调来降低模型中的gender bias。</li>
<li>results: 作者们发现，模型的训练数据中gender forms的偏度是gender bias的主要原因，而且分析subword splits可以提供good estimate of训练数据中gender-form偏度。他们还显示了微调只token embedding层可以降低女性和男性形式之间的差距而不妨碍翻译质量。<details>
<summary>Abstract</summary>
We study the effect of tokenization on gender bias in machine translation, an aspect that has been largely overlooked in previous works. Specifically, we focus on the interactions between the frequency of gendered profession names in training data, their representation in the subword tokenizer's vocabulary, and gender bias. We observe that female and non-stereotypical gender inflections of profession names (e.g., Spanish "doctora" for "female doctor") tend to be split into multiple subword tokens. Our results indicate that the imbalance of gender forms in the model's training corpus is a major factor contributing to gender bias and has a greater impact than subword splitting. We show that analyzing subword splits provides good estimates of gender-form imbalance in the training data and can be used even when the corpus is not publicly available. We also demonstrate that fine-tuning just the token embedding layer can decrease the gap in gender prediction accuracy between female and male forms without impairing the translation quality.
</details>
<details>
<summary>摘要</summary>
我们研究了各种卡通化的影响于机器翻译中的性别偏见，这是前一些研究中尚未得到充分关注的方面。我们专注于训练数据中的性别定型名称的频率，它们在字节化器的词库中的表示方式，以及性别偏见的关系。我们发现，女性和非标准性别定型名称（例如西班牙语"doctora"）在训练数据中出现的频率较低，这些名称往往会被拆分成多个字节。我们的结果表明，训练数据中性别形式的偏见是机器翻译模型的训练 corpus 中最大的一个因素，并且对性别预测精度的差异产生了更大的影响，而不是字节拆分。我们示出，分析字节拆分可以提供良好的性别形式偏见的估计，即使训练数据不公开可用。此外，我们还证明了只修改字节嵌入层可以降低女性和男性形式之间的翻译质量差异。
</details></li>
</ul>
<hr>
<h2 id="Studying-and-improving-reasoning-in-humans-and-machines"><a href="#Studying-and-improving-reasoning-in-humans-and-machines" class="headerlink" title="Studying and improving reasoning in humans and machines"></a>Studying and improving reasoning in humans and machines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12485">http://arxiv.org/abs/2309.12485</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Nicolas Yax, Hernan Anlló, Stefano Palminteri</li>
<li>for:  investigate and compare reasoning in large language models (LLM) and humans</li>
<li>methods:  used cognitive psychology tools traditionally dedicated to the study of (bounded) rationality</li>
<li>results:  most of the included models presented reasoning errors akin to those frequently ascribed to error-prone, heuristic-based human reasoning, but with important differences with human-like reasoning and limitations disappearing in more recent LLMs releases.<details>
<summary>Abstract</summary>
In the present study, we investigate and compare reasoning in large language models (LLM) and humans using a selection of cognitive psychology tools traditionally dedicated to the study of (bounded) rationality. To do so, we presented to human participants and an array of pretrained LLMs new variants of classical cognitive experiments, and cross-compared their performances. Our results showed that most of the included models presented reasoning errors akin to those frequently ascribed to error-prone, heuristic-based human reasoning. Notwithstanding this superficial similarity, an in-depth comparison between humans and LLMs indicated important differences with human-like reasoning, with models limitations disappearing almost entirely in more recent LLMs releases. Moreover, we show that while it is possible to devise strategies to induce better performance, humans and machines are not equally-responsive to the same prompting schemes. We conclude by discussing the epistemological implications and challenges of comparing human and machine behavior for both artificial intelligence and cognitive psychology.
</details>
<details>
<summary>摘要</summary>
在本研究中，我们研究和比较大语言模型（LLM）和人类的理解能力使用一些传统的认知心理学工具，以 investigate bounded rationality 的研究。我们给人类参与者和一些预训练的 LLM 提供了新的变种 classical cognitive experiments，并将其比较。我们的结果表明，大多数包含在模型中的理解错误与人类的错误相似，但是在深入比较之后，发现模型的局限性在更新的 LLM 发布中几乎消失了。此外，我们还证明了可以采取措施来提高表现，但是人类和机器不同的响应方式。我们 conclude 这些比较结果对人工智能和认知心理学都具有epistemological 意义和挑战。
</details></li>
</ul>
<hr>
<h2 id="State2Explanation-Concept-Based-Explanations-to-Benefit-Agent-Learning-and-User-Understanding"><a href="#State2Explanation-Concept-Based-Explanations-to-Benefit-Agent-Learning-and-User-Understanding" class="headerlink" title="State2Explanation: Concept-Based Explanations to Benefit Agent Learning and User Understanding"></a>State2Explanation: Concept-Based Explanations to Benefit Agent Learning and User Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12482">http://arxiv.org/abs/2309.12482</a></li>
<li>repo_url: None</li>
<li>paper_authors: Devleena Das, Sonia Chernova, Been Kim</li>
<li>for: 该研究旨在开发一种可以帮助非AI专家理解AI决策过程的方法，以便在日常任务中使用AI系统。</li>
<li>methods: 该研究使用了基于概念的解释方法，其中概念是在动作选择 Setting 中定义的。另外，研究还提出了一种joint embedding模型，用于学习状态动作对应的概念解释。</li>
<li>results: 实验结果表明，使用State2Explanation（S2E）框架可以提高代理人学习率和任务性能，同时也可以为非AI专家提供有用的解释，从而提高任务完成性。<details>
<summary>Abstract</summary>
With more complex AI systems used by non-AI experts to complete daily tasks, there is an increasing effort to develop methods that produce explanations of AI decision making understandable by non-AI experts. Towards this effort, leveraging higher-level concepts and producing concept-based explanations have become a popular method. Most concept-based explanations have been developed for classification techniques, and we posit that the few existing methods for sequential decision making are limited in scope. In this work, we first contribute a desiderata for defining "concepts" in sequential decision making settings. Additionally, inspired by the Protege Effect which states explaining knowledge often reinforces one's self-learning, we explore the utility of concept-based explanations providing a dual benefit to the RL agent by improving agent learning rate, and to the end-user by improving end-user understanding of agent decision making. To this end, we contribute a unified framework, State2Explanation (S2E), that involves learning a joint embedding model between state-action pairs and concept-based explanations, and leveraging such learned model to both (1) inform reward shaping during an agent's training, and (2) provide explanations to end-users at deployment for improved task performance. Our experimental validations, in Connect 4 and Lunar Lander, demonstrate the success of S2E in providing a dual-benefit, successfully informing reward shaping and improving agent learning rate, as well as significantly improving end user task performance at deployment time.
</details>
<details>
<summary>摘要</summary>
With the increasing use of more complex AI systems by non-AI experts for daily tasks, there is a growing effort to develop methods that provide understandable explanations of AI decision-making. To address this, leveraging higher-level concepts and producing concept-based explanations have become a popular approach. However, most existing methods are limited to classification techniques, and there is a lack of methods for sequential decision-making.In this work, we first propose a desiderata for defining "concepts" in sequential decision-making settings. Additionally, inspired by the Protege Effect, which states that explaining knowledge can reinforce one's self-learning, we explore the utility of concept-based explanations providing a dual benefit to both the RL agent and the end-user. To achieve this, we contribute a unified framework called State2Explanation (S2E), which involves learning a joint embedding model between state-action pairs and concept-based explanations, and leveraging this model to both inform reward shaping during the agent's training and provide explanations to end-users at deployment time.Our experimental validations in Connect 4 and Lunar Lander demonstrate the success of S2E in providing a dual-benefit, successfully informing reward shaping and improving agent learning rate, as well as significantly improving end-user task performance at deployment time.
</details></li>
</ul>
<hr>
<h2 id="HANS-are-you-clever-Clever-Hans-Effect-Analysis-of-Neural-Systems"><a href="#HANS-are-you-clever-Clever-Hans-Effect-Analysis-of-Neural-Systems" class="headerlink" title="HANS, are you clever? Clever Hans Effect Analysis of Neural Systems"></a>HANS, are you clever? Clever Hans Effect Analysis of Neural Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12481">http://arxiv.org/abs/2309.12481</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leonardo Ranaldi, Fabio Massimo Zanzotto</li>
<li>for: 这篇论文旨在检验 Iterative Large Language Models（It-LLMs）在不同选项顺序下的抗衰假设能力。</li>
<li>methods: 作者使用了多个多选题目（MCQ）benchmarks来构建坚实的评估模型能力。他们还引入了对抗样本，以检验模型的可靠性。</li>
<li>results: 研究发现，模型在选项顺序变化时存在偏袋性，具体来说是在第一个选项的位置影响模型选择的现象。此外，作者还发现模型在几个示例下 exhibit 偏好结构性的决策过程。通过使用 Chain-of-Thought（CoT）技术，作者可以让模型更加坚定地reasoning，从而减少偏袋性。<details>
<summary>Abstract</summary>
Instruction-tuned Large Language Models (It-LLMs) have been exhibiting outstanding abilities to reason around cognitive states, intentions, and reactions of all people involved, letting humans guide and comprehend day-to-day social interactions effectively. In fact, several multiple-choice questions (MCQ) benchmarks have been proposed to construct solid assessments of the models' abilities. However, earlier works are demonstrating the presence of inherent "order bias" in It-LLMs, posing challenges to the appropriate evaluation. In this paper, we investigate It-LLMs' resilience abilities towards a series of probing tests using four MCQ benchmarks. Introducing adversarial examples, we show a significant performance gap, mainly when varying the order of the choices, which reveals a selection bias and brings into discussion reasoning abilities. Following a correlation between first positions and model choices due to positional bias, we hypothesized the presence of structural heuristics in the decision-making process of the It-LLMs, strengthened by including significant examples in few-shot scenarios. Finally, by using the Chain-of-Thought (CoT) technique, we elicit the model to reason and mitigate the bias by obtaining more robust models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SAVME-Efficient-Safety-Validation-for-Autonomous-Systems-Using-Meta-Learning"><a href="#SAVME-Efficient-Safety-Validation-for-Autonomous-Systems-Using-Meta-Learning" class="headerlink" title="SAVME: Efficient Safety Validation for Autonomous Systems Using Meta-Learning"></a>SAVME: Efficient Safety Validation for Autonomous Systems Using Meta-Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12474">http://arxiv.org/abs/2309.12474</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marc R. Schlichting, Nina V. Boord, Anthony L. Corso, Mykel J. Kochenderfer</li>
<li>for: 本研究旨在快速发现自动驾驶系统的可能性故障，以便在部署之前进行风险评估。</li>
<li>methods: 我们提出了一种 bayesian 方法，它结合了 meta-learning 策略和多重武器框架，以优化验证过程。我们学习了触发故障场景的分布，以及对 simulator 的精度设置的分布。在 meta-learning 的精神中，我们还评估了学习分布是否能够帮助更快地学习新场景。</li>
<li>results: 我们使用了一个 cutting-edge 3D 驾驶 simulator，包含了 16 个精度设置，对自动驾驶车stack 进行了测试。我们根据自动驾驶车的偏倾类型进行了不同的场景测试。结果显示，我们的方法可以快速减少验证时间，比传统方法快速多达 18 倍。<details>
<summary>Abstract</summary>
Discovering potential failures of an autonomous system is important prior to deployment. Falsification-based methods are often used to assess the safety of such systems, but the cost of running many accurate simulation can be high. The validation can be accelerated by identifying critical failure scenarios for the system under test and by reducing the simulation runtime. We propose a Bayesian approach that integrates meta-learning strategies with a multi-armed bandit framework. Our method involves learning distributions over scenario parameters that are prone to triggering failures in the system under test, as well as a distribution over fidelity settings that enable fast and accurate simulations. In the spirit of meta-learning, we also assess whether the learned fidelity settings distribution facilitates faster learning of the scenario parameter distributions for new scenarios. We showcase our methodology using a cutting-edge 3D driving simulator, incorporating 16 fidelity settings for an autonomous vehicle stack that includes camera and lidar sensors. We evaluate various scenarios based on an autonomous vehicle pre-crash typology. As a result, our approach achieves a significant speedup, up to 18 times faster compared to traditional methods that solely rely on a high-fidelity simulator.
</details>
<details>
<summary>摘要</summary>
发现自动化系统的潜在失败是在部署之前非常重要。使用模糊化方法评估自动化系统的安全性可能是costly的。我们提议使用 bayesian方法，结合多重武器框架，以加速验证过程。我们的方法是学习触发故障场景的分布，以及对于快速和准确的模拟而设置的信任度设定的分布。在meta-learning的精神中，我们还评估了学习分布中的信任度设定是否可以更快地学习新场景的分布。我们使用了一个前沿的3D驾驶模拟器，包括16个可信度设定，对于一个包含摄像头和雷达感知器的自动驾驶车Stack。我们根据自动驾驶车预crash类型进行了多种场景的评估。因此，我们的方法可以减少至18倍以上，相比传统方法仅使用高可信度模拟器。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Deep-Learning-for-Scientific-Imaging-Interpretation"><a href="#Multimodal-Deep-Learning-for-Scientific-Imaging-Interpretation" class="headerlink" title="Multimodal Deep Learning for Scientific Imaging Interpretation"></a>Multimodal Deep Learning for Scientific Imaging Interpretation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12460">http://arxiv.org/abs/2309.12460</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Abdulelah S. Alshehri, Franklin L. Lee, Shihu Wang</li>
<li>for: 本研究旨在 linguistically emulating human-like interactions with Scanning Electron Microscopy (SEM) images, specifically of glass materials, and evaluating the accuracy of such interactions.</li>
<li>methods: 该方法基于多模态深度学习框架，利用文献评审文章中的文本和图像数据，以及GPT-4的数据生成和评估能力，以提取图像中的关键特征和缺陷。</li>
<li>results: 模型（GlassLLaVA）在前所未见的SEM图像中提取了准确的解释、标识了关键特征，并检测到缺陷。此外，我们还介绍了适用于科学成像应用的多样化评价指标，可以与研究级别的答案进行比较。<details>
<summary>Abstract</summary>
In the domain of scientific imaging, interpreting visual data often demands an intricate combination of human expertise and deep comprehension of the subject materials. This study presents a novel methodology to linguistically emulate and subsequently evaluate human-like interactions with Scanning Electron Microscopy (SEM) images, specifically of glass materials. Leveraging a multimodal deep learning framework, our approach distills insights from both textual and visual data harvested from peer-reviewed articles, further augmented by the capabilities of GPT-4 for refined data synthesis and evaluation. Despite inherent challenges--such as nuanced interpretations and the limited availability of specialized datasets--our model (GlassLLaVA) excels in crafting accurate interpretations, identifying key features, and detecting defects in previously unseen SEM images. Moreover, we introduce versatile evaluation metrics, suitable for an array of scientific imaging applications, which allows for benchmarking against research-grounded answers. Benefiting from the robustness of contemporary Large Language Models, our model adeptly aligns with insights from research papers. This advancement not only underscores considerable progress in bridging the gap between human and machine interpretation in scientific imaging, but also hints at expansive avenues for future research and broader application.
</details>
<details>
<summary>摘要</summary>
在科学成像领域，解读视觉数据经常需要复杂的人工智能和深入的Subject材料的理解。这项研究提出了一种新的方法ología，用于模拟和评估SEM图像中的人类如果交互行为，特别是钢琴材料的SEM图像。我们利用了一种多模态深度学习框架，将文本和视觉数据从同行评审文章中提取出来，并通过GPT-4的数据生成和评估能力进行进一步的增强。尽管存在某些挑战，如细微的解释和特殊 dataset的有限性，但我们的模型（GlassLLaVA）在面临 previously unseen SEM 图像时仍然能够提供高度准确的解释、标识关键特征和检测缺陷。此外，我们还引入了适用于多种科学成像应用的评价指标，使得可以对研究级答案进行比较。这种进步不仅标识了人机共同解读的科学成像领域中的巨大进步，还预示了未来研究和应用的广阔前景。
</details></li>
</ul>
<hr>
<h2 id="LongDocFACTScore-Evaluating-the-Factuality-of-Long-Document-Abstractive-Summarisation"><a href="#LongDocFACTScore-Evaluating-the-Factuality-of-Long-Document-Abstractive-Summarisation" class="headerlink" title="LongDocFACTScore: Evaluating the Factuality of Long Document Abstractive Summarisation"></a>LongDocFACTScore: Evaluating the Factuality of Long Document Abstractive Summarisation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12455">http://arxiv.org/abs/2309.12455</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jbshp/longdocfactscore">https://github.com/jbshp/longdocfactscore</a></li>
<li>paper_authors: Jennifer A Bishop, Qianqian Xie, Sophia Ananiadou</li>
<li>for: 本研究旨在evaluating automatic text summarization metrics for long document data sets, and proposing a new evaluation framework called LongDocFACTScore.</li>
<li>methods: 本研究使用了pre-trained language models和human annotated data sets来evaluate automatic text summarization metrics的准确性。</li>
<li>results: LongDocFACTScore outperforms existing state-of-the-art metrics in its ability to correlate with human measures of factuality when used to evaluate long document summarization data sets, and its performance is comparable to state-of-the-art metrics when evaluated against human measures of factual consistency on short document data sets.<details>
<summary>Abstract</summary>
Maintaining factual consistency is a critical issue in abstractive text summarisation, however, it cannot be assessed by traditional automatic metrics used for evaluating text summarisation, such as ROUGE scoring. Recent efforts have been devoted to developing improved metrics for measuring factual consistency using pre-trained language models, but these metrics have restrictive token limits, and are therefore not suitable for evaluating long document text summarisation. Moreover, there is limited research evaluating whether existing automatic evaluation metrics are fit for purpose when applied to long document data sets. In this work, we evaluate the efficacy of automatic metrics at assessing factual consistency in long document text summarisation and propose a new evaluation framework LongDocFACTScore. This framework allows metrics to be extended to any length document. This framework outperforms existing state-of-the-art metrics in its ability to correlate with human measures of factuality when used to evaluate long document summarisation data sets. Furthermore, we show LongDocFACTScore has performance comparable to state-of-the-art metrics when evaluated against human measures of factual consistency on short document data sets. We make our code and annotated data publicly available: https://github.com/jbshp/LongDocFACTScore.
</details>
<details>
<summary>摘要</summary>
保持事实一致性是抽象文本概要化中的关键问题，但这无法由传统的自动评价指标来评估，如ROUGE分数。 recent efforts have been devoted to developing improved metrics for measuring factual consistency using pre-trained language models, but these metrics have restrictive token limits and are therefore not suitable for evaluating long document text summarization. In addition, there is limited research evaluating whether existing automatic evaluation metrics are fit for purpose when applied to long document data sets. In this work, we evaluate the efficacy of automatic metrics at assessing factual consistency in long document text summarization and propose a new evaluation framework LongDocFACTScore. This framework allows metrics to be extended to any length document. This framework outperforms existing state-of-the-art metrics in its ability to correlate with human measures of factuality when used to evaluate long document summarization data sets. Furthermore, we show LongDocFACTScore has performance comparable to state-of-the-art metrics when evaluated against human measures of factual consistency on short document data sets. We make our code and annotated data publicly available: <https://github.com/jbshp/LongDocFACTScore>.
</details></li>
</ul>
<hr>
<h2 id="Ensemble-Neural-Networks-for-Remaining-Useful-Life-RUL-Prediction"><a href="#Ensemble-Neural-Networks-for-Remaining-Useful-Life-RUL-Prediction" class="headerlink" title="Ensemble Neural Networks for Remaining Useful Life (RUL) Prediction"></a>Ensemble Neural Networks for Remaining Useful Life (RUL) Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12445">http://arxiv.org/abs/2309.12445</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahbishek Srinivasan, Juan Carlos Andresen, Anders Holst</li>
<li>For: The paper aims to propose an ensemble neural network approach for probabilistic remaining useful life (RUL) predictions, which considers both aleatoric and epistemic uncertainties and decouples them to provide a more accurate and interpretable prediction.* Methods: The proposed method uses ensemble neural networks to model the probabilistic nature of RUL predictions, and decouples the aleatoric and epistemic uncertainties to provide a better understanding of the confidence of the predictions.* Results: The proposed approach is tested on NASA’s turbofan jet engine CMAPSS data-set and shows how the uncertainties can be modeled and disentangled. The results also demonstrate the effectiveness of the proposed approach compared to current state-of-the-art methods.Here is the same information in Simplified Chinese text:* For: 该文章目的是提出一种 ensemble neural network 方法，用于 probabilistic 的 remaining useful life（RUL）预测，并考虑了 aleatoric 和 epistemic 不确定性，并将其分解为两个不同的不确定性。* Methods: 该方法使用 ensemble neural networks 来模型 probabilistic 的 RUL 预测，并将 aleatoric 和 epistemic 不确定性分解为两个不同的不确定性。* Results: 该方法在 NASA 的 turbofan jet engine CMAPSS 数据集上进行了测试，并显示了如何模型和分解不确定性。结果还比较了该方法与当前状态的先进方法。<details>
<summary>Abstract</summary>
A core part of maintenance planning is a monitoring system that provides a good prognosis on health and degradation, often expressed as remaining useful life (RUL). Most of the current data-driven approaches for RUL prediction focus on single-point prediction. These point prediction approaches do not include the probabilistic nature of the failure. The few probabilistic approaches to date either include the aleatoric uncertainty (which originates from the system), or the epistemic uncertainty (which originates from the model parameters), or both simultaneously as a total uncertainty. Here, we propose ensemble neural networks for probabilistic RUL predictions which considers both uncertainties and decouples these two uncertainties. These decoupled uncertainties are vital in knowing and interpreting the confidence of the predictions. This method is tested on NASA's turbofan jet engine CMAPSS data-set. Our results show how these uncertainties can be modeled and how to disentangle the contribution of aleatoric and epistemic uncertainty. Additionally, our approach is evaluated on different metrics and compared against the current state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
系综综保养规划中的核心部分是监测系统，提供器部件的健康和衰化情况的良好预测，通常表示为剩下的有用寿命（RUL）。现有的大多数数据驱动方法都是单点预测，不包括失败的 probabilistic 特征。其中一些 probabilistic 方法可以同时考虑系统内的 aleatoric 不确定性和模型参数的 epistemic 不确定性，或者将这两种不确定性作为总的不确定性。在这里，我们提出了ensemble neural networks для probabilistic RUL 预测，该方法考虑了这两种不确定性，并将它们分解开来。这些分解的不确定性非常重要，因为它们可以帮助我们理解和解释预测结果的信任程度。我们在NASA的涡轮喷气发动机CMAPSS数据集上测试了这种方法，我们的结果表明了如何模拟这些不确定性，并如何分解它们的贡献。此外，我们还对这种方法进行了不同的评价指标和与当前状态艺术方法进行了比较。
</details></li>
</ul>
<hr>
<h2 id="Can-LLMs-Augment-Low-Resource-Reading-Comprehension-Datasets-Opportunities-and-Challenges"><a href="#Can-LLMs-Augment-Low-Resource-Reading-Comprehension-Datasets-Opportunities-and-Challenges" class="headerlink" title="Can LLMs Augment Low-Resource Reading Comprehension Datasets? Opportunities and Challenges"></a>Can LLMs Augment Low-Resource Reading Comprehension Datasets? Opportunities and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12426">http://arxiv.org/abs/2309.12426</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vinay Samuel, Houda Aynaou, Arijit Ghosh Chowdhury, Karthik Venkat Ramanan, Aman Chadha</li>
<li>for: 这个论文主要是用于探讨使用大语言模型（LLMs）来增强现有的抽取式阅读理解任务数据集，以提高下游任务的性能。</li>
<li>methods: 该论文使用的方法包括使用GPT-4来自动生成数据集的描述和答案，然后对这些数据集进行微调以适应特定任务。</li>
<li>results: 研究发现，使用GPT-4进行数据生成和微调可以提高low resource阅读理解任务的性能，同时也可以大幅减少人工标注的成本。此外，研究还发现了一些特殊的机会和挑战，需要进一步的研究和优化。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have demonstrated impressive zero shot performance on a wide range of NLP tasks, demonstrating the ability to reason and apply commonsense. A relevant application is to use them for creating high quality synthetic datasets for downstream tasks. In this work, we probe whether GPT-4 can be used to augment existing extractive reading comprehension datasets. Automating data annotation processes has the potential to save large amounts of time, money and effort that goes into manually labelling datasets. In this paper, we evaluate the performance of GPT-4 as a replacement for human annotators for low resource reading comprehension tasks, by comparing performance after fine tuning, and the cost associated with annotation. This work serves to be the first analysis of LLMs as synthetic data augmenters for QA systems, highlighting the unique opportunities and challenges. Additionally, we release augmented versions of low resource datasets, that will allow the research community to create further benchmarks for evaluation of generated datasets.
</details>
<details>
<summary>摘要</summary>
We evaluate the performance of GPT-4 as a replacement for human annotators for low-resource reading comprehension tasks by comparing performance after fine-tuning and the cost associated with annotation. This work is the first analysis of LLMs as synthetic data augmenters for QA systems, highlighting the unique opportunities and challenges. Additionally, we release augmented versions of low-resource datasets, allowing the research community to create further benchmarks for evaluating generated datasets.Note: "Simplified Chinese" is a romanization of Chinese characters, it's not a native language. The correct name of the language is "中文（简体）" in Chinese.
</details></li>
</ul>
<hr>
<h2 id="Event-Prediction-using-Case-Based-Reasoning-over-Knowledge-Graphs"><a href="#Event-Prediction-using-Case-Based-Reasoning-over-Knowledge-Graphs" class="headerlink" title="Event Prediction using Case-Based Reasoning over Knowledge Graphs"></a>Event Prediction using Case-Based Reasoning over Knowledge Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12423">http://arxiv.org/abs/2309.12423</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/solashirai/www-evcbr">https://github.com/solashirai/www-evcbr</a></li>
<li>paper_authors: Sola Shirai, Debarun Bhattacharjya, Oktie Hassanzadeh</li>
<li>for: 预测新事件的 causal 关系和属性</li>
<li>methods: 使用case-based reasoning模型（EvCBR），不需要 retraining，通过统计度量identify similar事件并进行路径预测</li>
<li>results: 在使用新闻事件 dataset 进行测试时，EvCBR 表现出色，超过基eline模型（包括 translate-distance-based、GNN-based和规则based LP 模型）<details>
<summary>Abstract</summary>
Applying link prediction (LP) methods over knowledge graphs (KG) for tasks such as causal event prediction presents an exciting opportunity. However, typical LP models are ill-suited for this task as they are incapable of performing inductive link prediction for new, unseen event entities and they require retraining as knowledge is added or changed in the underlying KG. We introduce a case-based reasoning model, EvCBR, to predict properties about new consequent events based on similar cause-effect events present in the KG. EvCBR uses statistical measures to identify similar events and performs path-based predictions, requiring no training step. To generalize our methods beyond the domain of event prediction, we frame our task as a 2-hop LP task, where the first hop is a causal relation connecting a cause event to a new effect event and the second hop is a property about the new event which we wish to predict. The effectiveness of our method is demonstrated using a novel dataset of newsworthy events with causal relations curated from Wikidata, where EvCBR outperforms baselines including translational-distance-based, GNN-based, and rule-based LP models.
</details>
<details>
<summary>摘要</summary>
使用链接预测（LP）方法在知识图（KG）上进行任务，如 causal event prediction 具有吸引人的机遇。然而，典型的 LP 模型无法执行新的链接预测，因为它们无法处理新的事件实体，并且需要重新训练。我们介绍了一种 случа件理解模型（EvCBR），用于预测新的后果事件的属性，基于知识图中的相似 causa-effect 事件。EvCBR 使用统计度量来标识相似事件，并进行路径预测，不需要训练步骤。为了扩展我们的方法，我们将任务划为两个步骤 LP 任务，第一步是一个 causal 关系连接一个新的效应事件和一个原因事件，第二步是预测新事件的属性。我们的方法在使用 Wikidata 上的新闻事件 causal 关系的数据集上进行了证明，EvCBR 在基于译译距离、图 neural network 和规则 LP 模型的基础上减少。
</details></li>
</ul>
<hr>
<h2 id="Constraints-First-A-New-MDD-based-Model-to-Generate-Sentences-Under-Constraints"><a href="#Constraints-First-A-New-MDD-based-Model-to-Generate-Sentences-Under-Constraints" class="headerlink" title="Constraints First: A New MDD-based Model to Generate Sentences Under Constraints"></a>Constraints First: A New MDD-based Model to Generate Sentences Under Constraints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12415">http://arxiv.org/abs/2309.12415</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexandre Bonlarron, Aurélie Calabrèse, Pierre Kornprobst, Jean-Charles Régin</li>
<li>for: 这个论文是为了开发一种生成受约文本的新方法而写的。</li>
<li>methods: 这篇论文使用了多值决策图(MDD)来解决这个问题，并应用了一个语言模型(GPT-2)来选择最佳的句子。</li>
<li>results: 该方法可以生成大量的合法的句子，比传统的视力检测测试(MNREAD)中的句子更多，这为标准化句子生成带来了重大突破。此外，这种方法可以轻松适应其他语言，因此具有普适性和可重用性。<details>
<summary>Abstract</summary>
This paper introduces a new approach to generating strongly constrained texts. We consider standardized sentence generation for the typical application of vision screening. To solve this problem, we formalize it as a discrete combinatorial optimization problem and utilize multivalued decision diagrams (MDD), a well-known data structure to deal with constraints. In our context, one key strength of MDD is to compute an exhaustive set of solutions without performing any search. Once the sentences are obtained, we apply a language model (GPT-2) to keep the best ones. We detail this for English and also for French where the agreement and conjugation rules are known to be more complex. Finally, with the help of GPT-2, we get hundreds of bona-fide candidate sentences. When compared with the few dozen sentences usually available in the well-known vision screening test (MNREAD), this brings a major breakthrough in the field of standardized sentence generation. Also, as it can be easily adapted for other languages, it has the potential to make the MNREAD test even more valuable and usable. More generally, this paper highlights MDD as a convincing alternative for constrained text generation, especially when the constraints are hard to satisfy, but also for many other prospects.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ForceSight-Text-Guided-Mobile-Manipulation-with-Visual-Force-Goals"><a href="#ForceSight-Text-Guided-Mobile-Manipulation-with-Visual-Force-Goals" class="headerlink" title="ForceSight: Text-Guided Mobile Manipulation with Visual-Force Goals"></a>ForceSight: Text-Guided Mobile Manipulation with Visual-Force Goals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12312">http://arxiv.org/abs/2309.12312</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/force-sight/forcesight">https://github.com/force-sight/forcesight</a></li>
<li>paper_authors: Jeremy A. Collins, Cody Houff, You Liang Tan, Charles C. Kemp</li>
<li>for: 这篇论文是为了研究文本指导的移动 manipulate 系统，该系统使用深度学习神经网络预测视觉力目标。</li>
<li>methods: 该论文使用了一种深度学习模型，该模型使用单个RGBD图像和文本提示来预测视觉力目标（姿态目标）和相关的力目标（力量目标）。</li>
<li>results: 当部署在携带着RGBD相机的移动 manipulate 器上时，ForceSight系统在未seen环境中完成了精度抓取、抽屉开启和物品传递等任务，成功率达81%。在另一个实验中，仅通过视觉服务器而忽略力目标，成功率下降至45%，这说明力目标可以显著提高性能。<details>
<summary>Abstract</summary>
We present ForceSight, a system for text-guided mobile manipulation that predicts visual-force goals using a deep neural network. Given a single RGBD image combined with a text prompt, ForceSight determines a target end-effector pose in the camera frame (kinematic goal) and the associated forces (force goal). Together, these two components form a visual-force goal. Prior work has demonstrated that deep models outputting human-interpretable kinematic goals can enable dexterous manipulation by real robots. Forces are critical to manipulation, yet have typically been relegated to lower-level execution in these systems. When deployed on a mobile manipulator equipped with an eye-in-hand RGBD camera, ForceSight performed tasks such as precision grasps, drawer opening, and object handovers with an 81% success rate in unseen environments with object instances that differed significantly from the training data. In a separate experiment, relying exclusively on visual servoing and ignoring force goals dropped the success rate from 90% to 45%, demonstrating that force goals can significantly enhance performance. The appendix, videos, code, and trained models are available at https://force-sight.github.io/.
</details>
<details>
<summary>摘要</summary>
我们介绍ForceSight，一种基于文本指导的移动摩擦系统，该系统使用深度神经网络预测视觉力目标。给定一个RGBD图像和一个文本提示，ForceSight将确定相机框架中的目标终端器姿态（骨干目标）和相关的力（力目标）。这两个组成部分共同组成了视觉力目标。在前一个研究中，深度模型输出的人类可读的骨干目标可以使得真正的机器人实现灵活的摩擦。然而，力是摩擦中关键的一部分，通常被低级执行系统中排除。当部署在配备了眼头RGBD摄像头的移动摩擦机器人上时，ForceSight完成了精度抓取、抽屉打开和物品传递等任务，成功率达81%，在未看过的环境中，物品实例与训练数据有很大差异。在另一个实验中，仅通过视觉服务器和忽略力目标，成功率从90%降落到45%，这表明力目标可以显著提高性能。详细介绍、视频、代码和训练模型可以在<https://force-sight.github.io/>中找到。
</details></li>
</ul>
<hr>
<h2 id="LLM-Grounder-Open-Vocabulary-3D-Visual-Grounding-with-Large-Language-Model-as-an-Agent"><a href="#LLM-Grounder-Open-Vocabulary-3D-Visual-Grounding-with-Large-Language-Model-as-an-Agent" class="headerlink" title="LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent"></a>LLM-Grounder: Open-Vocabulary 3D Visual Grounding with Large Language Model as an Agent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12311">http://arxiv.org/abs/2309.12311</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianing Yang, Xuweiyi Chen, Shengyi Qian, Nikhil Madaan, Madhavan Iyengar, David F. Fouhey, Joyce Chai</li>
<li>for: 提高家庭机器人的3D视觉掌握能力，以便机器人可以基于环境中的物体进行导航、物体操作和回答问题。</li>
<li>methods: 使用大语言模型（LLM）将复杂的自然语言查询拆分成Semantic constituents，然后使用OpenScene或LERF等视觉定位工具来定位3D场景中的物体。LLM然后评估这些提议的物体之间的空间和通用常识关系，以便作出最终的定位决定。</li>
<li>results: 在ScanRefer benchark中评估LLM-Grounder，未使用任何标注训练数据，可以普适地处理 novel 3D场景和任意自然语言查询，并达到了零shot定位精度。研究表明，LLM可以大幅提高定位能力，特别是对于复杂的语言查询，使LLM-Grounder成为3D视觉语言任务中的有效方法。<details>
<summary>Abstract</summary>
3D visual grounding is a critical skill for household robots, enabling them to navigate, manipulate objects, and answer questions based on their environment. While existing approaches often rely on extensive labeled data or exhibit limitations in handling complex language queries, we propose LLM-Grounder, a novel zero-shot, open-vocabulary, Large Language Model (LLM)-based 3D visual grounding pipeline. LLM-Grounder utilizes an LLM to decompose complex natural language queries into semantic constituents and employs a visual grounding tool, such as OpenScene or LERF, to identify objects in a 3D scene. The LLM then evaluates the spatial and commonsense relations among the proposed objects to make a final grounding decision. Our method does not require any labeled training data and can generalize to novel 3D scenes and arbitrary text queries. We evaluate LLM-Grounder on the ScanRefer benchmark and demonstrate state-of-the-art zero-shot grounding accuracy. Our findings indicate that LLMs significantly improve the grounding capability, especially for complex language queries, making LLM-Grounder an effective approach for 3D vision-language tasks in robotics. Videos and interactive demos can be found on the project website https://chat-with-nerf.github.io/ .
</details>
<details>
<summary>摘要</summary>
三维视觉定位是家庭机器人的关键技能，它使机器人能够在环境中导航、操作物品和回答问题。现有的方法常常需要大量标注数据或者在处理复杂的语言查询时显示限制，而我们提议了LLM-Grounder，一种新的零批处理、开 vocabulary 的大语言模型（LLM）基于的三维视觉定位管道。LLM-Grounder 利用 LLM 将复杂的自然语言查询分解成Semantic 成分，然后使用 OpenScene 或 LERF 等视觉定位工具来确定3D场景中的物体。LLM 然后评估物体之间的空间和常识关系，以便做最终的定位决定。我们的方法不需要任何标注训练数据，可以泛化到新的3D场景和任意文本查询。我们在 ScanRefer benchmark 上评估了LLM-Grounder，并实现了零批处理定位精度。我们的发现表明，LLM 可以大幅提高定位能力，特别是对于复杂的语言查询，从而使LLM-Grounder 成为家庭机器人中的有效方法。视频和交互demo可以在项目网站https://chat-with-nerf.github.io/ 找到。
</details></li>
</ul>
<hr>
<h2 id="Rehearsal-Simulating-Conflict-to-Teach-Conflict-Resolution"><a href="#Rehearsal-Simulating-Conflict-to-Teach-Conflict-Resolution" class="headerlink" title="Rehearsal: Simulating Conflict to Teach Conflict Resolution"></a>Rehearsal: Simulating Conflict to Teach Conflict Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12309">http://arxiv.org/abs/2309.12309</a></li>
<li>repo_url: None</li>
<li>paper_authors: Omar Shaikh, Valentino Chai, Michele J. Gelfand, Diyi Yang, Michael S. Bernstein</li>
<li>for: This paper aims to provide a system for users to practice and learn effective conflict resolution strategies through simulated conversations with a believable interlocutor.</li>
<li>methods: The paper introduces a system called Rehearsal, which uses a large language model conditioned on the Interest-Rights-Power (IRP) theory to generate counterfactual scenarios and guide users towards de-escalating difficult conversations.</li>
<li>results: In a between-subjects evaluation, participants who received simulated training from Rehearsal significantly improved their performance in unaided conflicts, reducing their use of escalating competitive strategies by 67% and doubling their use of cooperative strategies.<details>
<summary>Abstract</summary>
Interpersonal conflict is an uncomfortable but unavoidable fact of life. Navigating conflict successfully is a skill -- one that can be learned through deliberate practice -- but few have access to effective training or feedback. To expand this access, we introduce Rehearsal, a system that allows users to rehearse conflicts with a believable simulated interlocutor, explore counterfactual "what if?" scenarios to identify alternative conversational paths, and learn through feedback on how and when to apply specific conflict strategies. Users can utilize Rehearsal to practice handling a variety of predefined conflict scenarios, from office disputes to relationship issues, or they can choose to create their own. To enable Rehearsal, we develop IRP prompting, a method of conditioning output of a large language model on the influential Interest-Rights-Power (IRP) theory from conflict resolution. Rehearsal uses IRP to generate utterances grounded in conflict resolution theory, guiding users towards counterfactual conflict resolution strategies that help de-escalate difficult conversations. In a between-subjects evaluation, 40 participants engaged in an actual conflict with a confederate after training. Compared to a control group with lecture material covering the same IRP theory, participants with simulated training from Rehearsal significantly improved their performance in the unaided conflict: they reduced their use of escalating competitive strategies by an average of 67%, while doubling their use of cooperative strategies. Overall, Rehearsal highlights the potential effectiveness of language models as tools for learning and practicing interpersonal skills.
</details>
<details>
<summary>摘要</summary>
人际冲突是生活中不可避免的一种不适，但是通过成功 Navigation 这种技能可以帮助你更好地处理这些冲突。然而，有限的人们有效地接受这种技能的训练和反馈。为解决这个问题，我们介绍了一个系统 called Rehearsal，它使得用户能够在受到虚拟对话者的反馈下练习冲突，探索不同的对话路径，并通过反馈学习如何在不同的情况下应用特定的冲突策略。用户可以使用 Rehearsal 练习各种预先定义的冲突场景，从办公室的争议到关系问题，或者他们可以创建自己的场景。为实现 Rehearsal，我们开发了 IRP 提示，一种基于冲突解决理论中的 Interest-Rights-Power（IRP）理论来控制大语言模型的输出。Rehearsal 使用 IRP 生成对话，引导用户采取与冲突解决相关的措施，以帮助他们在不易的对话中减少竞争策略的使用，同时增加合作策略的使用。在一个 between-subjects 评估中，40名参与者在与一名演员进行了实际冲突后接受了 Rehearsal 的虚拟训练。与控制组，其中接受了同样的 IRP 讲解材料，相比之下，Rehearsal 组的参与者在没有任何帮助的情况下处理冲突时表现出了显著改善：他们减少了竞争策略的使用平均67%，同时增加了合作策略的使用。总的来说，Rehearsal  highlights 语言模型的潜在效果性作为人际技能学习和练习的工具。
</details></li>
</ul>
<hr>
<h2 id="LongLoRA-Efficient-Fine-tuning-of-Long-Context-Large-Language-Models"><a href="#LongLoRA-Efficient-Fine-tuning-of-Long-Context-Large-Language-Models" class="headerlink" title="LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models"></a>LongLoRA: Efficient Fine-tuning of Long-Context Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12307">http://arxiv.org/abs/2309.12307</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dvlab-research/longlora">https://github.com/dvlab-research/longlora</a></li>
<li>paper_authors: Yukang Chen, Shengju Qian, Haotian Tang, Xin Lai, Zhijian Liu, Song Han, Jiaya Jia<br>for: 这个研究旨在提高预训语言模型（LLM）的上下文大小，以减少计算成本，并且保留原始架构。methods: 本研究使用了两种方法来实现上下文扩展：首先，使用稀疏的地方注意力进行练习，以减少计算成本；其次，重新检视了受限的参数练习环境，以确保模型在扩展上下文时仍然能够保持好的性能。results: 本研究在多个任务上实现了优秀的实验结果，包括从7B&#x2F;13B到70B的LLaMA2模型。具体来说，LongLoRA可以将7B模型的上下文延长至4k至100k，或者将70B模型的上下文延长至32k，在单一的8x A100机器上进行训练。此外，本研究还创建了一个名为LongQA的数据集，用于监督练习。这个数据集包含了超过3,000个长上下文问题答案对。<details>
<summary>Abstract</summary>
We present LongLoRA, an efficient fine-tuning approach that extends the context sizes of pre-trained large language models (LLMs), with limited computation cost. Typically, training LLMs with long context sizes is computationally expensive, requiring extensive training hours and GPU resources. For example, training on the context length of 8192 needs 16x computational costs in self-attention layers as that of 2048. In this paper, we speed up the context extension of LLMs in two aspects. On the one hand, although dense global attention is needed during inference, fine-tuning the model can be effectively and efficiently done by sparse local attention. The proposed shift short attention effectively enables context extension, leading to non-trivial computation saving with similar performance to fine-tuning with vanilla attention. Particularly, it can be implemented with only two lines of code in training, while being optional in inference. On the other hand, we revisit the parameter-efficient fine-tuning regime for context expansion. Notably, we find that LoRA for context extension works well under the premise of trainable embedding and normalization. LongLoRA demonstrates strong empirical results on various tasks on LLaMA2 models from 7B/13B to 70B. LongLoRA adopts LLaMA2 7B from 4k context to 100k, or LLaMA2 70B to 32k on a single 8x A100 machine. LongLoRA extends models' context while retaining their original architectures, and is compatible with most existing techniques, like FlashAttention-2. In addition, to make LongLoRA practical, we collect a dataset, LongQA, for supervised fine-tuning. It contains more than 3k long context question-answer pairs.
</details>
<details>
<summary>摘要</summary>
我们介绍LongLoRA，一种高效的精度调整方法，可以将预训练大语言模型（LLM）的上下文大小提高，而不需要巨大的计算成本。通常，在训练LLMs时，使用长上下文大小需要大量的计算时间和GPU资源。例如，在上下文长度为8192时，需要16倍的计算成本，相比于上下文长度为2048。在这篇论文中，我们提高了LLM的上下文扩展的速度，从两个方面进行了优化。一方面，虽然在推理时需要使用紧凑的全球注意力，但在微调时可以使用笔者的本地注意力进行有效和高效地调整。我们提出的Shift Short Attention技术可以有效地扩展上下文，并且可以在训练中实现只需两行代码，而在推理时可以选择使用。另一方面，我们再次检视了 Parametric Efficient Fine-Tuning 的 режим，发现在可 Trainable Embedding 和 Normalization 的前提下，LoRA 对上下文扩展非常有效。LongLoRA在多种任务上表现出色，包括 LLMA2 模型从 7B/13B 到 70B。LongLoRA 可以从 4k 上下文扩展到 100k，或者从 70B 下降到 32k 的单个 8x A100 机器上。LongLoRA 可以保留原始模型的结构，并且可以与大多数现有技术相容，如 FlashAttention-2。此外，为了让 LongLoRA 实用，我们收集了一个数据集，LongQA，用于supervised fine-tuning。这个数据集包含了 более3k个长上下文问答对。
</details></li>
</ul>
<hr>
<h2 id="Environment-biased-Feature-Ranking-for-Novelty-Detection-Robustness"><a href="#Environment-biased-Feature-Ranking-for-Novelty-Detection-Robustness" class="headerlink" title="Environment-biased Feature Ranking for Novelty Detection Robustness"></a>Environment-biased Feature Ranking for Novelty Detection Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12301">http://arxiv.org/abs/2309.12301</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefan Smeu, Elena Burceanu, Emanuela Haller, Andrei Liviu Nicolicioiu</li>
<li>for: robust novelty detection, aiming to detect novelties in terms of semantic content while being invariant to changes in other, irrelevant factors.</li>
<li>methods: propose a method that starts with a pretrained embedding and a multi-env setup, and ranks features based on their environment-focus, using a per-feature score based on feature distribution variance between envs.</li>
<li>results: improve the overall performance by up to 6%, both in covariance and sub-population shift cases, both for a real and a synthetic benchmark.<details>
<summary>Abstract</summary>
We tackle the problem of robust novelty detection, where we aim to detect novelties in terms of semantic content while being invariant to changes in other, irrelevant factors. Specifically, we operate in a setup with multiple environments, where we determine the set of features that are associated more with the environments, rather than to the content relevant for the task. Thus, we propose a method that starts with a pretrained embedding and a multi-env setup and manages to rank the features based on their environment-focus. First, we compute a per-feature score based on the feature distribution variance between envs. Next, we show that by dropping the highly scored ones, we manage to remove spurious correlations and improve the overall performance by up to 6%, both in covariance and sub-population shift cases, both for a real and a synthetic benchmark, that we introduce for this task.
</details>
<details>
<summary>摘要</summary>
我们面临Semantic novelty detection问题，即检测含义上的新鲜事物，而不受其他无关因素的变化影响。特别是，我们在多个环境下运行，并确定了与环境相关的特征，而不是与任务相关的内容。因此，我们提出了一种方法，它从预训练的嵌入起始，并在多个环境下进行了环境带重分类。首先，我们计算了每个特征的分布差异分布变化得分，以确定它们与环境相关程度。然后，我们证明了，通过去掉高分得分的特征，可以消除干扰关系，并提高总性能。我们在 covariance和 sub-population shift案例中实现了这一点，并在真实和 sintetic  benchmark 中实现了6%的提高。
</details></li>
</ul>
<hr>
<h2 id="See-to-Touch-Learning-Tactile-Dexterity-through-Visual-Incentives"><a href="#See-to-Touch-Learning-Tactile-Dexterity-through-Visual-Incentives" class="headerlink" title="See to Touch: Learning Tactile Dexterity through Visual Incentives"></a>See to Touch: Learning Tactile Dexterity through Visual Incentives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12300">http://arxiv.org/abs/2309.12300</a></li>
<li>repo_url: None</li>
<li>paper_authors: Irmak Guzey, Yinlong Dai, Ben Evans, Soumith Chintala, Lerrel Pinto</li>
<li>for: 提高多 finger 机器人的灵活和精准把握能力。</li>
<li>methods: 使用视觉奖励来优化把握策略。</li>
<li>results: 在六个复杂任务中，如抓取固定物体、推翻细长物体等，TAVI 得到了 73% 的成功率，相比之下，不使用视觉奖励的策略只得到了 65% 的成功率，而使用视觉和抓取奖励的策略则达到了 82% 的成功率。Here’s the full translation of the paper’s abstract in Simplified Chinese:</li>
<li>for: 这篇论文旨在提高多 finger 机器人的灵活和精准把握能力。</li>
<li>methods: 该论文使用视觉奖励来优化把握策略。</li>
<li>results: 在六个复杂任务中，TAVI 得到了 73% 的成功率，相比之下，不使用视觉奖励的策略只得到了 65% 的成功率，而使用视觉和抓取奖励的策略则达到了 82% 的成功率。I hope this helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
Equipping multi-fingered robots with tactile sensing is crucial for achieving the precise, contact-rich, and dexterous manipulation that humans excel at. However, relying solely on tactile sensing fails to provide adequate cues for reasoning about objects' spatial configurations, limiting the ability to correct errors and adapt to changing situations. In this paper, we present Tactile Adaptation from Visual Incentives (TAVI), a new framework that enhances tactile-based dexterity by optimizing dexterous policies using vision-based rewards. First, we use a contrastive-based objective to learn visual representations. Next, we construct a reward function using these visual representations through optimal-transport based matching on one human demonstration. Finally, we use online reinforcement learning on our robot to optimize tactile-based policies that maximize the visual reward. On six challenging tasks, such as peg pick-and-place, unstacking bowls, and flipping slender objects, TAVI achieves a success rate of 73% using our four-fingered Allegro robot hand. The increase in performance is 108% higher than policies using tactile and vision-based rewards and 135% higher than policies without tactile observational input. Robot videos are best viewed on our project website: https://see-to-touch.github.io/.
</details>
<details>
<summary>摘要</summary>
装备多指抓取机器人的感觉感知是实现人类精准、接触丰富、灵活抓取的关键。然而，仅仅通过感觉感知不能提供充分的启示，用于了解物体的空间配置，限制了 corrected errors and adapt to changing situations。在这篇论文中，我们提出了视觉适应的策略（TAVI），一种新的框架，可以通过视觉奖励来增强感觉基础的灵活性。首先，我们使用对比度基于的目标函数来学习视觉表示。接着，我们通过对一个人示例的最佳匹配来构建视觉奖励函数。最后，我们使用在我们四指抓取机器人上的在线反射学习来优化感觉基础的策略，以达到最大化视觉奖励的目标。在六个具有挑战性的任务中，例如吸盘卸、推倒碗和抓flipping细长物体，TAVI达到了73%的成功率。与不含感觉观察输入的策略相比，TAVI的表现提高了108%，与基于感觉和视觉奖励的策略相比，提高了135%。机器人视频最好在我们项目网站上观看：https://see-to-touch.github.io/。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Drive-Anywhere"><a href="#Learning-to-Drive-Anywhere" class="headerlink" title="Learning to Drive Anywhere"></a>Learning to Drive Anywhere</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12295">http://arxiv.org/abs/2309.12295</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Sfedfcv/redesigned-pancake">https://github.com/Sfedfcv/redesigned-pancake</a></li>
<li>paper_authors: Ruizhao Zhu, Peng Huang, Eshed Ohn-Bar, Venkatesh Saligrama</li>
<li>for: 这个研究旨在开发一个可以在不同地理位置和规律下适应驾驶决策的自动驾驶模型。</li>
<li>methods: 这个研究使用了一种名为conditional imitation learning（CIL）的方法，并将高容量的地图位置基于的频道对应 Mechanism引入，以有效地适应地方特点，同时也能够模型区域间的相似性。</li>
<li>results: 研究发现，使用AnyD模型可以在多个数据集、城市和扩展方法（如中央、半监督和分布式训练）中表现出色，比基线CIL模型高出14%以上在开 Loop评估中和30%以上在关闭 Loop测试中。<details>
<summary>Abstract</summary>
Human drivers can seamlessly adapt their driving decisions across geographical locations with diverse conditions and rules of the road, e.g., left vs. right-hand traffic. In contrast, existing models for autonomous driving have been thus far only deployed within restricted operational domains, i.e., without accounting for varying driving behaviors across locations or model scalability. In this work, we propose AnyD, a single geographically-aware conditional imitation learning (CIL) model that can efficiently learn from heterogeneous and globally distributed data with dynamic environmental, traffic, and social characteristics. Our key insight is to introduce a high-capacity geo-location-based channel attention mechanism that effectively adapts to local nuances while also flexibly modeling similarities among regions in a data-driven manner. By optimizing a contrastive imitation objective, our proposed approach can efficiently scale across inherently imbalanced data distributions and location-dependent events. We demonstrate the benefits of our AnyD agent across multiple datasets, cities, and scalable deployment paradigms, i.e., centralized, semi-supervised, and distributed agent training. Specifically, AnyD outperforms CIL baselines by over 14% in open-loop evaluation and 30% in closed-loop testing on CARLA.
</details>
<details>
<summary>摘要</summary>
人类司机可以无缝地适应不同地区的条件和道路规则，例如左右两种交通方向。然而，现有的自动驾驶模型只能在限定的运行域中进行部署，无法考虑不同地区的驾驶行为和模型可扩展性。在这项工作中，我们提出了AnyD，一个基于条件学习（CIL）模型，可以高效地从多样化的全球分布的数据中学习地区特有的驾驶行为。我们的关键发现是引入高容量的地理位置基于的通道注意力机制，可以有效地适应本地特点，同时也能够模型地区之间的相似性。通过优化一个对比式学习目标函数，我们的提出的AnyD代理可以高效地扩展到具有不同数据分布和地区事件的情况。我们在多个数据集、城市和可扩展的训练方法（中央化、半supervised和分布式代理训练）中证明了AnyD的优势，特别是在CARLA上，AnyD比基线CIL模型高于14%的开loop评估和30%的关闭loop测试。
</details></li>
</ul>
<hr>
<h2 id="The-Reversal-Curse-LLMs-trained-on-“A-is-B”-fail-to-learn-“B-is-A”"><a href="#The-Reversal-Curse-LLMs-trained-on-“A-is-B”-fail-to-learn-“B-is-A”" class="headerlink" title="The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”"></a>The Reversal Curse: LLMs trained on “A is B” fail to learn “B is A”</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12288">http://arxiv.org/abs/2309.12288</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lukasberglund/reversal_curse">https://github.com/lukasberglund/reversal_curse</a></li>
<li>paper_authors: Lukas Berglund, Meg Tong, Max Kaufmann, Mikita Balesni, Asa Cooper Stickland, Tomasz Korbak, Owain Evans<br>for:* The paper reveals a surprising failure of generalization in auto-regressive large language models (LLMs) when it comes to reversals of statements.methods:* The authors train and fine-tune GPT-3 and Llama-1 on fictitious statements and evaluate their performance on questions about real-world celebrities.results:* The models fail to correctly answer questions about real-world celebrities when the information is presented in reverse order, demonstrating a basic failure of logical deduction. GPT-4 is able to correctly answer questions about real-world celebrities 79% of the time, but only 33% of the time when the information is presented in reverse order. This failure is called the “Reversal Curse” and is robust across model sizes and model families.<details>
<summary>Abstract</summary>
We expose a surprising failure of generalization in auto-regressive large language models (LLMs). If a model is trained on a sentence of the form "A is B", it will not automatically generalize to the reverse direction "B is A". This is the Reversal Curse. For instance, if a model is trained on "Olaf Scholz was the ninth Chancellor of Germany", it will not automatically be able to answer the question, "Who was the ninth Chancellor of Germany?". Moreover, the likelihood of the correct answer ("Olaf Scholz") will not be higher than for a random name. Thus, models exhibit a basic failure of logical deduction and do not generalize a prevalent pattern in their training set (i.e. if "A is B'' occurs, "B is A" is more likely to occur). We provide evidence for the Reversal Curse by finetuning GPT-3 and Llama-1 on fictitious statements such as "Uriah Hawthorne is the composer of 'Abyssal Melodies'" and showing that they fail to correctly answer "Who composed 'Abyssal Melodies?'". The Reversal Curse is robust across model sizes and model families and is not alleviated by data augmentation. We also evaluate ChatGPT (GPT-3.5 and GPT-4) on questions about real-world celebrities, such as "Who is Tom Cruise's mother? [A: Mary Lee Pfeiffer]" and the reverse "Who is Mary Lee Pfeiffer's son?". GPT-4 correctly answers questions like the former 79% of the time, compared to 33% for the latter. This shows a failure of logical deduction that we hypothesize is caused by the Reversal Curse. Code is available at https://github.com/lukasberglund/reversal_curse.
</details>
<details>
<summary>摘要</summary>
我们揭示了自动进行推理的大语言模型（LLM）的一个意外的泛化失败。如果一个模型被训练在“A是B”的句子上，它不会自动泛化到“B是A”的方向。我们称这为“排名之咒”。例如，如果一个模型被训练在“奥拉夫·施科尔茨是德国第九任总理”上，它不会自动回答“德国第九任总理是谁？”的问题，而且对于正确答案（奥拉夫·施科尔茨）的概率不高于随机名称。因此，模型表现出了基本的逻辑推理失败，不会泛化训练集中的普遍规律（即如果“A是B”出现，“B是A”更可能出现）。我们提供了证据，通过finetuning GPT-3和Llama-1在虚假句子上，并示出它们无法正确回答“谁写了‘abyssal Melodies’？”的问题。排名之咒是模型大小和模型家族的稳定特征，不受数据增强影响。我们还评估了ChatGPT（GPT-3.5和GPT-4）在真实世界名人的问题上，如“谁是汤美·克雷的妈妈？”和其反向“谁是mary Lee Pfeiffer的儿子？”。GPT-4在前者79%的时间内正确回答问题，而后者只有33%。这表明了逻辑推理的失败，我们假设是由排名之咒引起的。代码可以在https://github.com/lukasberglund/reversal_curse上获取。
</details></li>
</ul>
<hr>
<h2 id="MetaMath-Bootstrap-Your-Own-Mathematical-Questions-for-Large-Language-Models"><a href="#MetaMath-Bootstrap-Your-Own-Mathematical-Questions-for-Large-Language-Models" class="headerlink" title="MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models"></a>MetaMath: Bootstrap Your Own Mathematical Questions for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12284">http://arxiv.org/abs/2309.12284</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/meta-math/MetaMath">https://github.com/meta-math/MetaMath</a></li>
<li>paper_authors: Longhui Yu, Weisen Jiang, Han Shi, Jincheng Yu, Zhengying Liu, Yu Zhang, James T. Kwok, Zhenguo Li, Adrian Weller, Weiyang Liu<br>for:这篇论文旨在提高大型自然语言处理器（LLMs）的数学理解能力，以提供更好的数学问题解决能力。methods:作者们使用了自然语言处理技术，包括重新写数学问题的多种角度，以生成一个名为MetaMathQA的新数据集。然后，他们使用了LLaMA-2模型进行微调，以便在数学理解方面进行更好的表现。results:实验结果表明，作者们的MetaMath模型在两个流行的数学理解benchmark（GSM8K和MATH）上表现出色，与开源LLMs相比，它们的表现有所提高。具体来说，MetaMath-7B模型在GSM8K上达到了66.4%的准确率，而MetaMath-70B模型在MATH上达到了82.3%的准确率，这 beiden都高于同等模型大小的state-of-the-art模型。<details>
<summary>Abstract</summary>
Large language models (LLMs) have pushed the limits of natural language understanding and exhibited excellent problem-solving ability. Despite the great success, most existing open-source LLMs (e.g., LLaMA-2) are still far away from satisfactory for solving mathematical problem due to the complex reasoning procedures. To bridge this gap, we propose MetaMath, a fine-tuned language model that specializes in mathematical reasoning. Specifically, we start by bootstrapping mathematical questions by rewriting the question from multiple perspectives without extra knowledge, which results in a new dataset called MetaMathQA. Then we fine-tune the LLaMA-2 models on MetaMathQA. Experimental results on two popular benchmarks (i.e., GSM8K and MATH) for mathematical reasoning demonstrate that MetaMath outperforms a suite of open-source LLMs by a significant margin. Our MetaMath-7B model achieves 66.4% on GSM8K and 19.4% on MATH, exceeding the state-of-the-art models of the same size by 11.5% and 8.7%. Particularly, MetaMath-70B achieves an accuracy of 82.3% on GSM8K, slightly better than GPT-3.5-Turbo. We release all the MetaMathQA dataset, the MetaMath models with different model sizes and the training code for public use.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLMs）已经推进了自然语言理解的limits和显示出了优秀的问题解决能力。 despite the great success, most existing open-source LLMs（例如LLaMA-2）仍然与mathematical problem solving remains far away from satisfactory due to the complex reasoning procedures. To bridge this gap, we propose MetaMath, a fine-tuned language model that specializes in mathematical reasoning. Specifically, we start by bootstrapping mathematical questions by rewriting the question from multiple perspectives without extra knowledge, which results in a new dataset called MetaMathQA. Then we fine-tune the LLaMA-2 models on MetaMathQA. Experimental results on two popular benchmarks（i.e., GSM8K和MATH）for mathematical reasoning demonstrate that MetaMath outperforms a suite of open-source LLMs by a significant margin. Our MetaMath-7B model achieves 66.4% on GSM8K and 19.4% on MATH, exceeding the state-of-the-art models of the same size by 11.5% and 8.7%. Particularly, MetaMath-70B achieves an accuracy of 82.3% on GSM8K, slightly better than GPT-3.5-Turbo. We release all the MetaMathQA dataset, the MetaMath models with different model sizes, and the training code for public use.
</details></li>
</ul>
<hr>
<h2 id="LLMR-Real-time-Prompting-of-Interactive-Worlds-using-Large-Language-Models"><a href="#LLMR-Real-time-Prompting-of-Interactive-Worlds-using-Large-Language-Models" class="headerlink" title="LLMR: Real-time Prompting of Interactive Worlds using Large Language Models"></a>LLMR: Real-time Prompting of Interactive Worlds using Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12276">http://arxiv.org/abs/2309.12276</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/asem010/legend-pice">https://github.com/asem010/legend-pice</a></li>
<li>paper_authors: Fernanda De La Torre, Cathy Mengying Fang, Han Huang, Andrzej Banburski-Fahey, Judith Amores Fernandez, Jaron Lanier</li>
<li>for: 本研究开发了一个大语言模型 для混合现实（LLMR），用于实时创建和修改混合现实经验。</li>
<li>methods: LLMR 使用了新的策略来解决对理想训练数据罕至或需要创造内部动力、敏捷分析或高级互动的问题。 它靠扩展文本互动和 Unity 游戏引擎。</li>
<li>results: LLMR 比标准 GPT-4 快四倍在均误率上。它在跨平台互操作性方面进行了多个示例世界的评估和创建&#x2F;修改任务的评估，并进行了一次用户研究（N&#x3D;11），发现用户们对系统有正面体验并会再次使用它。<details>
<summary>Abstract</summary>
We present Large Language Model for Mixed Reality (LLMR), a framework for the real-time creation and modification of interactive Mixed Reality experiences using LLMs. LLMR leverages novel strategies to tackle difficult cases where ideal training data is scarce, or where the design goal requires the synthesis of internal dynamics, intuitive analysis, or advanced interactivity. Our framework relies on text interaction and the Unity game engine. By incorporating techniques for scene understanding, task planning, self-debugging, and memory management, LLMR outperforms the standard GPT-4 by 4x in average error rate. We demonstrate LLMR's cross-platform interoperability with several example worlds, and evaluate it on a variety of creation and modification tasks to show that it can produce and edit diverse objects, tools, and scenes. Finally, we conducted a usability study (N=11) with a diverse set that revealed participants had positive experiences with the system and would use it again.
</details>
<details>
<summary>摘要</summary>
我们介绍Large Language Model for Mixed Reality（LLMR），一个用于实时创建和修改混合现实经验的框架，使用大自然语言模型（LLM）。 LLMR 利用新的策略来解决缺乏理想训练数据或设计目标需要创造内部动力、直观分析或进阶互动的问题。我们的框架基于文本互动和Unity游戏引擎。通过包括场景理解、任务观察、自我检查和记忆管理的技术，LLMR 在average error rate上比标准GPT-4高出4倍。我们显示 LLMR 的跨平台可扩展性，并评估其在创建和修改多种物品、工具和场景时的表现。最后，我们进行了一次使用者研究（N=11），发现参与者对系统有正面的经验，并会再次使用它。
</details></li>
</ul>
<hr>
<h2 id="Enabling-Quartile-based-Estimated-Mean-Gradient-Aggregation-As-Baseline-for-Federated-Image-Classifications"><a href="#Enabling-Quartile-based-Estimated-Mean-Gradient-Aggregation-As-Baseline-for-Federated-Image-Classifications" class="headerlink" title="Enabling Quartile-based Estimated-Mean Gradient Aggregation As Baseline for Federated Image Classifications"></a>Enabling Quartile-based Estimated-Mean Gradient Aggregation As Baseline for Federated Image Classifications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12267">http://arxiv.org/abs/2309.12267</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yusen Wu, Jamie Deng, Hao Chen, Phuong Nguyen, Yelena Yesha</li>
<li>for: 这 paper 的目的是提出一种解决 federated learning 中数据多样性和安全性问题的新方法，以及提供一个基本参考点 для advanced aggregation techniques。</li>
<li>methods: 该 paper 使用了 estimated mean aggregation (EMA) 方法，它通过使用 trimmed means 处理异常值和揭示数据不同性，以确保模型在各个客户端数据集上进行适应。</li>
<li>results: via 大量实验，EMA 方法能够保持高精度和 area under the curve (AUC)，相比于其他方法，EMA 方法成为 federated learning 中效果和安全性的基本参考点。<details>
<summary>Abstract</summary>
Federated Learning (FL) has revolutionized how we train deep neural networks by enabling decentralized collaboration while safeguarding sensitive data and improving model performance. However, FL faces two crucial challenges: the diverse nature of data held by individual clients and the vulnerability of the FL system to security breaches. This paper introduces an innovative solution named Estimated Mean Aggregation (EMA) that not only addresses these challenges but also provides a fundamental reference point as a $\mathsf{baseline}$ for advanced aggregation techniques in FL systems. EMA's significance lies in its dual role: enhancing model security by effectively handling malicious outliers through trimmed means and uncovering data heterogeneity to ensure that trained models are adaptable across various client datasets. Through a wealth of experiments, EMA consistently demonstrates high accuracy and area under the curve (AUC) compared to alternative methods, establishing itself as a robust baseline for evaluating the effectiveness and security of FL aggregation methods. EMA's contributions thus offer a crucial step forward in advancing the efficiency, security, and versatility of decentralized deep learning in the context of FL.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SALSA-CLRS-A-Sparse-and-Scalable-Benchmark-for-Algorithmic-Reasoning"><a href="#SALSA-CLRS-A-Sparse-and-Scalable-Benchmark-for-Algorithmic-Reasoning" class="headerlink" title="SALSA-CLRS: A Sparse and Scalable Benchmark for Algorithmic Reasoning"></a>SALSA-CLRS: A Sparse and Scalable Benchmark for Algorithmic Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12253">http://arxiv.org/abs/2309.12253</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jkminder/salsa-clrs">https://github.com/jkminder/salsa-clrs</a></li>
<li>paper_authors: Julian Minder, Florian Grötschla, Joël Mathys, Roger Wattenhofer</li>
<li>for: 本研究旨在扩展CLRS算法学习benchmark，强调可扩展性和稀疏表示的使用。</li>
<li>methods: 本研究使用了修改后CLRS算法和分布式随机算法中的一些问题，以及新增了一些问题。</li>
<li>results: 我们在empirical evaluation中发现，SALSA-CLRS比CLRS更具可扩展性和稀疏表示能力。<details>
<summary>Abstract</summary>
We introduce an extension to the CLRS algorithmic learning benchmark, prioritizing scalability and the utilization of sparse representations. Many algorithms in CLRS require global memory or information exchange, mirrored in its execution model, which constructs fully connected (not sparse) graphs based on the underlying problem. Despite CLRS's aim of assessing how effectively learned algorithms can generalize to larger instances, the existing execution model becomes a significant constraint due to its demanding memory requirements and runtime (hard to scale). However, many important algorithms do not demand a fully connected graph; these algorithms, primarily distributed in nature, align closely with the message-passing paradigm employed by Graph Neural Networks. Hence, we propose SALSA-CLRS, an extension of the current CLRS benchmark specifically with scalability and sparseness in mind. Our approach includes adapted algorithms from the original CLRS benchmark and introduces new problems from distributed and randomized algorithms. Moreover, we perform a thorough empirical evaluation of our benchmark. Code is publicly available at https://github.com/jkminder/SALSA-CLRS.
</details>
<details>
<summary>摘要</summary>
我们介绍一个CLRS算法学习标准延伸，优先愿景是数据分析和紧缩表示。许多CLRS中的算法需要全球内存或资讯交换，这反映了它们的执行模型，它们创建了不紧缩的图（不是紧缩图）基于下面问题。尽管CLRS的目标是评估学习算法在更大的实例中对稍低的数据分析和紧缩表示的能力，但现有的执行模型对于内存需求和时间（困难扩展）带来了重要的限制。然而，许多重要的算法不需要全球连接图，这些算法，主要是分布式的，与传递讯息的方法相似，这与Graph Neural Networks的传递讯息模型相符。因此，我们提出了SALSA-CLRS，CLRS标准的延伸，优先愿景是数据分析和紧缩表示的扩展。我们的方法包括CLRS中原始的算法的修改，以及新的分布式和随机算法问题。此外，我们执行了详细的实验评估。代码可以在https://github.com/jkminder/SALSA-CLRS上取得。
</details></li>
</ul>
<hr>
<h2 id="Bad-Actor-Good-Advisor-Exploring-the-Role-of-Large-Language-Models-in-Fake-News-Detection"><a href="#Bad-Actor-Good-Advisor-Exploring-the-Role-of-Large-Language-Models-in-Fake-News-Detection" class="headerlink" title="Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection"></a>Bad Actor, Good Advisor: Exploring the Role of Large Language Models in Fake News Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12247">http://arxiv.org/abs/2309.12247</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ictmcg/arg">https://github.com/ictmcg/arg</a></li>
<li>paper_authors: Beizhe Hu, Qiang Sheng, Juan Cao, Yuhui Shi, Yang Li, Danding Wang, Peng Qi</li>
<li>for: 这个论文旨在研究大型语言模型（LLMs）是否可以帮助检测假新闻。</li>
<li>methods: 作者使用了一种名为ARG的可靠性指南网络，该网络使用了精心调整的BERT来选择合适的理由，以帮助检测假新闻。</li>
<li>results: 实验结果表明，作者的ARG和ARG-D方法可以比三种基eline方法（包括SLM、LLM和这两种组合）表现更好，并且可以在Cost-sensitive的enario中提供更好的性能。<details>
<summary>Abstract</summary>
Detecting fake news requires both a delicate sense of diverse clues and a profound understanding of the real-world background, which remains challenging for detectors based on small language models (SLMs) due to their knowledge and capability limitations. Recent advances in large language models (LLMs) have shown remarkable performance in various tasks, but whether and how LLMs could help with fake news detection remains underexplored. In this paper, we investigate the potential of LLMs in fake news detection. First, we conduct an empirical study and find that a sophisticated LLM such as GPT 3.5 could generally expose fake news and provide desirable multi-perspective rationales but still underperforms the basic SLM, fine-tuned BERT. Our subsequent analysis attributes such a gap to the LLM's inability to select and integrate rationales properly to conclude. Based on these findings, we propose that current LLMs may not substitute fine-tuned SLMs in fake news detection but can be a good advisor for SLMs by providing multi-perspective instructive rationales. To instantiate this proposal, we design an adaptive rationale guidance network for fake news detection (ARG), in which SLMs selectively acquire insights on news analysis from the LLMs' rationales. We further derive a rationale-free version of ARG by distillation, namely ARG-D, which services cost-sensitive scenarios without inquiring LLMs. Experiments on two real-world datasets demonstrate that ARG and ARG-D outperform three types of baseline methods, including SLM-based, LLM-based, and combinations of small and large language models.
</details>
<details>
<summary>摘要</summary>
检测假新闻需要一种细腻的多种证据敏感和深刻的真实背景理解，这对小语言模型（SLM）来说是一项挑战。然而，大语言模型（LLM）的最新进展表现出色在多种任务上，但是LLM是否能够帮助检测假新闻仍然未得到充分探索。本文 investigate LLM在假新闻检测中的潜力。我们首先进行了实验研究，发现一个复杂的LLM如GPT 3.5可以暴露假新闻并提供愉悦多元理由，但还是落后于基本SLM、精通BERT。我们后续的分析表明这种差距是由LLM无法选择和结合理由而导致的。根据这些发现，我们认为当前LLM可能不能完全取代精通SLM，但可以作为SLM的好帮手，提供多元指导性的理由。为实现这一提议，我们设计了一种适应性理由指导网络（ARG），其中SLM可以选择性地从LLM的理由中获得分析新闻的 instrucity。此外，我们还 derivates一种不需要理由的ARG-D版本，通过萃取来实现成本敏感enario中无需问题LLM。我们在两个实际 datasets上进行了实验，发现ARG和ARG-D都高于三种基eline方法，包括SLM、LLM和小语言模型的组合。
</details></li>
</ul>
<hr>
<h2 id="ChaCha-Leveraging-Large-Language-Models-to-Prompt-Children-to-Share-Their-Emotions-about-Personal-Events"><a href="#ChaCha-Leveraging-Large-Language-Models-to-Prompt-Children-to-Share-Their-Emotions-about-Personal-Events" class="headerlink" title="ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events"></a>ChaCha: Leveraging Large Language Models to Prompt Children to Share Their Emotions about Personal Events</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12244">http://arxiv.org/abs/2309.12244</a></li>
<li>repo_url: None</li>
<li>paper_authors: Woosuk Seo, Chanmo Yang, Young-Ho Kim</li>
<li>for: 这篇研究的目的是为了探讨儿童如何通过与他人分享故事和感受来学习表达情感。</li>
<li>methods: 这篇研究使用了一个状态机和大型自然语言模型（LLMs），将对话保持在轨道上，同时让儿童进行自由的对话。</li>
<li>results: 研究发现，儿童对 ChaCha 表示出了亲密的感觉，并让他们分享了各种主题，如家庭旅行和个人成就。<details>
<summary>Abstract</summary>
Children typically learn to identify and express emotions through sharing their stories and feelings with others, particularly their family. However, it is challenging for parents or siblings to have emotional communication with children since children are still developing their communication skills. We present ChaCha, a chatbot that encourages and guides children to share personal events and associated emotions. ChaCha combines a state machine and large language models (LLMs) to keep the dialogue on track while carrying on free-form conversations. Through an exploratory study with 20 children (aged 8-12), we examine how ChaCha prompts children to share personal events and guides them to describe associated emotions. Participants perceived ChaCha as a close friend and shared their stories on various topics, such as family trips and personal achievements. Based on the quantitative and qualitative findings, we discuss opportunities for leveraging LLMs to design child-friendly chatbots to support children in sharing their emotions.
</details>
<details>
<summary>摘要</summary>
孩子通常通过与他人分享自己的故事和感受来学习识别和表达情感。然而，由于孩子的交流技巧还在发展，因此与孩子进行情感交流可以是一项挑战。我们介绍了一个名为ChaCha的虚拟助手，它鼓励和指导孩子分享个人事件和相关的情感。ChaCha结合状态机制和大型自然语言模型（LLM），以保持对话在轨而进行自由的对话。我们通过对20名8-12岁的孩子进行exploratory研究，发现ChaCha可以鼓励孩子分享个人事件并指导他们描述相关的情感。参与者认为ChaCha是一个亲密的朋友，并分享了各种话题，如家庭旅行和个人成就。根据数据和质量调查结果，我们讨论了如何利用LLM来设计适合孩子的虚拟助手，以支持孩子在表达情感方面。
</details></li>
</ul>
<hr>
<h2 id="Explainable-Artificial-Intelligence-for-Drug-Discovery-and-Development-–-A-Comprehensive-Survey"><a href="#Explainable-Artificial-Intelligence-for-Drug-Discovery-and-Development-–-A-Comprehensive-Survey" class="headerlink" title="Explainable Artificial Intelligence for Drug Discovery and Development – A Comprehensive Survey"></a>Explainable Artificial Intelligence for Drug Discovery and Development – A Comprehensive Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12177">http://arxiv.org/abs/2309.12177</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roohallah Alizadehsani, Sadiq Hussain, Rene Ripardo Calixto, Victor Hugo C. de Albuquerque, Mohamad Roshanzamir, Mohamed Rahouti, Senthil Kumar Jagatheesaperumal</li>
<li>for: 本文提供了一个全面的介绍，涵盖了使用Explainable Artificial Intelligence（XAI）技术在药物发现中的当前状况，包括不同的XAI方法、其应用在药物发现中的方法、以及XAI技术在药物发现中的挑战和限制。</li>
<li>methods: 本文详细介绍了XAI技术在药物发现中的应用，包括目标预测、化学物质设计和毒性预测等方面。</li>
<li>results: 本文summarizes the current state of XAI in drug discovery, highlighting the challenges and limitations of XAI techniques in drug discovery, and suggesting potential future research directions for the application of XAI in drug discovery.<details>
<summary>Abstract</summary>
The field of drug discovery has experienced a remarkable transformation with the advent of artificial intelligence (AI) and machine learning (ML) technologies. However, as these AI and ML models are becoming more complex, there is a growing need for transparency and interpretability of the models. Explainable Artificial Intelligence (XAI) is a novel approach that addresses this issue and provides a more interpretable understanding of the predictions made by machine learning models. In recent years, there has been an increasing interest in the application of XAI techniques to drug discovery. This review article provides a comprehensive overview of the current state-of-the-art in XAI for drug discovery, including various XAI methods, their application in drug discovery, and the challenges and limitations of XAI techniques in drug discovery. The article also covers the application of XAI in drug discovery, including target identification, compound design, and toxicity prediction. Furthermore, the article suggests potential future research directions for the application of XAI in drug discovery. The aim of this review article is to provide a comprehensive understanding of the current state of XAI in drug discovery and its potential to transform the field.
</details>
<details>
<summary>摘要</summary>
随着人工智能（AI）和机器学习（ML）技术的出现，药物发现领域已经经历了很大的变革。然而，随着AI和ML模型的复杂度的增加，对模型的透明度和解释性的需求也在增加。解释性人工智能（XAI）是一种新的方法，旨在提供更加解释的机器学习模型预测结果的理解。在过去几年中，对XAI技术的应用在药物发现领域的兴趣有所增加。本文提供了药物发现领域XAI技术的当前状态的总结，包括各种XAI方法、其应用在药物发现领域、以及XAI技术在药物发现领域的挑战和限制。文章还涵盖了XAI技术在药物发现中的应用，包括目标 indentification、化合物设计和毒性预测。此外，文章还提出了XAI技术在药物发现领域的未来研究方向。本文的目的是为读者提供药物发现领域XAI技术的全面了解，以及其在药物发现领域的潜在变革性。
</details></li>
</ul>
<hr>
<h2 id="SCOB-Universal-Text-Understanding-via-Character-wise-Supervised-Contrastive-Learning-with-Online-Text-Rendering-for-Bridging-Domain-Gap"><a href="#SCOB-Universal-Text-Understanding-via-Character-wise-Supervised-Contrastive-Learning-with-Online-Text-Rendering-for-Bridging-Domain-Gap" class="headerlink" title="SCOB: Universal Text Understanding via Character-wise Supervised Contrastive Learning with Online Text Rendering for Bridging Domain Gap"></a>SCOB: Universal Text Understanding via Character-wise Supervised Contrastive Learning with Online Text Rendering for Bridging Domain Gap</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12382">http://arxiv.org/abs/2309.12382</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daehee Kim, Yoonsik Kim, DongHyun Kim, Yumin Lim, Geewook Kim, Taeho Kil</li>
<li>for: 这个研究是为了提高语言模型（LM）基于预训练的效能，并应用于视觉文档理解中。</li>
<li>methods: 这篇研究使用了LM基于预训练方法，并提出了一个名为SCOB的新预训练方法，这个方法使用字元别超vised contrastive learning和在线文本渲染来将文档和景象文本领域融合。</li>
<li>results: 实验结果显示，SCOB比vanilla预训练方法有更好的效果，并且与现有的方法相比，它的表现相当。这些结果表明，SCOB可以应用于读取类型的预训练方法中。<details>
<summary>Abstract</summary>
Inspired by the great success of language model (LM)-based pre-training, recent studies in visual document understanding have explored LM-based pre-training methods for modeling text within document images. Among them, pre-training that reads all text from an image has shown promise, but often exhibits instability and even fails when applied to broader domains, such as those involving both visual documents and scene text images. This is a substantial limitation for real-world scenarios, where the processing of text image inputs in diverse domains is essential. In this paper, we investigate effective pre-training tasks in the broader domains and also propose a novel pre-training method called SCOB that leverages character-wise supervised contrastive learning with online text rendering to effectively pre-train document and scene text domains by bridging the domain gap. Moreover, SCOB enables weakly supervised learning, significantly reducing annotation costs. Extensive benchmarks demonstrate that SCOB generally improves vanilla pre-training methods and achieves comparable performance to state-of-the-art methods. Our findings suggest that SCOB can be served generally and effectively for read-type pre-training methods. The code will be available at https://github.com/naver-ai/scob.
</details>
<details>
<summary>摘要</summary>
受Language Model（LM）预训示的成功启发，最近的视觉文档理解研究已经 explore LM预训示方法来模型图像中的文本。其中， reads all text from an image 预训示方法已经显示了 promise, 但经常存在不稳定和失败问题，尤其是在更广泛的领域，如文档和场景文本图像中。这是一个重要的限制，因为在实际应用中，处理各种文本图像输入的多样化领域是必要的。在这篇论文中，我们investigate effective pre-training tasks in the broader domains, 并提出了一种新的预训示方法called SCOB，它通过Character-wise supervised contrastive learning with online text rendering来有效地预训示文档和场景文本领域，并bridge the domain gap。此外，SCOB支持weakly supervised learning，可以减少注解成本。我们的实验表明，SCOB通常超越原始预训示方法，并与状态之artefacts达到相似的性能。我们的发现建议SCOB可以普遍应用和有效地预训示读类预训示方法。代码将在https://github.com/naver-ai/scob中提供。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Domain-Adaptation-for-Self-Driving-from-Past-Traversal-Features"><a href="#Unsupervised-Domain-Adaptation-for-Self-Driving-from-Past-Traversal-Features" class="headerlink" title="Unsupervised Domain Adaptation for Self-Driving from Past Traversal Features"></a>Unsupervised Domain Adaptation for Self-Driving from Past Traversal Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12140">http://arxiv.org/abs/2309.12140</a></li>
<li>repo_url: None</li>
<li>paper_authors: Travis Zhang, Katie Luo, Cheng Perng Phoo, Yurong You, Wei-Lun Chao, Bharath Hariharan, Mark Campbell, Kilian Q. Weinberger</li>
<li>for: 提高自动驾驶车辆中3D对象检测系统的精度和通用性。</li>
<li>methods: 利用无标注重复旋转多个位置来适应新的驾驶环境，通过计算重复LiDAR扫描数据的统计信息来导导适应过程。</li>
<li>results: 通过含有空间量化历史特征的LiDAR检测模型和Lightweight回归头来强化检测模型，实现了20点的性能提升，特别是人员和远距离对象的检测。Here’s the breakdown of each point:</li>
<li>for: The paper aims to improve the accuracy and generalization of 3D object detection systems for self-driving cars.</li>
<li>methods: The proposed method uses unlabeled repeated traversals of multiple locations to adapt object detectors to new driving environments, and incorporates statistics computed from repeated LiDAR scans to guide the adaptation process.</li>
<li>results: The proposed method achieves significant improvements in detection performance, up to 20 points, especially in detecting pedestrians and distant objects, through the use of spatial quantized historical features and a lightweight regression head.<details>
<summary>Abstract</summary>
The rapid development of 3D object detection systems for self-driving cars has significantly improved accuracy. However, these systems struggle to generalize across diverse driving environments, which can lead to safety-critical failures in detecting traffic participants. To address this, we propose a method that utilizes unlabeled repeated traversals of multiple locations to adapt object detectors to new driving environments. By incorporating statistics computed from repeated LiDAR scans, we guide the adaptation process effectively. Our approach enhances LiDAR-based detection models using spatial quantized historical features and introduces a lightweight regression head to leverage the statistics for feature regularization. Additionally, we leverage the statistics for a novel self-training process to stabilize the training. The framework is detector model-agnostic and experiments on real-world datasets demonstrate significant improvements, achieving up to a 20-point performance gain, especially in detecting pedestrians and distant objects. Code is available at https://github.com/zhangtravis/Hist-DA.
</details>
<details>
<summary>摘要</summary>
三维物体探测系统的快速发展对自动驾驶车有了显著改善的准确性。然而，这些系统在不同的驾驶环境中很难泛化，这可能会导致检测交通参与者的安全关键失败。为解决这个问题，我们提出了一种方法，该方法利用多次重复的多个位置的无标签数据来适应新的驾驶环境。通过基于重复扫描 LiDAR 数据计算的统计信息，我们有效地引导适应过程。我们的方法可以增强基于 LiDAR 的探测模型，并引入空间量化历史特征来减少特征的抖动。此外，我们还利用统计信息进行一种新的自动训练过程，以稳定训练。这种框架是探测模型无关的，实验结果表明，在实际数据上可以获得大约 20 个表现指标的改善，特别是检测人员和远距离物体的检测。代码可以在 https://github.com/zhangtravis/Hist-DA 上获取。
</details></li>
</ul>
<hr>
<h2 id="On-the-relationship-between-Benchmarking-Standards-and-Certification-in-Robotics-and-AI"><a href="#On-the-relationship-between-Benchmarking-Standards-and-Certification-in-Robotics-and-AI" class="headerlink" title="On the relationship between Benchmarking, Standards and Certification in Robotics and AI"></a>On the relationship between Benchmarking, Standards and Certification in Robotics and AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12139">http://arxiv.org/abs/2309.12139</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alan F. T. Winfield, Matthew Studley</li>
<li>for: 这篇论文主要是用来探讨责任创新的相关过程，包括标准、认证和测试 benchmarking。</li>
<li>methods: 论文使用了标准、认证和测试 benchmarking 等方法来探讨责任创新的实践。</li>
<li>results: 论文通过 analyzing 标准、认证和测试 benchmarking 等方法， argued that these three linked processes are not only useful but vital to the broader practice of Responsible Innovation。<details>
<summary>Abstract</summary>
Benchmarking, standards and certification are closely related processes. Standards can provide normative requirements that robotics and AI systems may or may not conform to. Certification generally relies upon conformance with one or more standards as the key determinant of granting a certificate to operate. And benchmarks are sets of standardised tests against which robots and AI systems can be measured. Benchmarks therefore can be thought of as informal standards. In this paper we will develop these themes with examples from benchmarking, standards and certification, and argue that these three linked processes are not only useful but vital to the broader practice of Responsible Innovation.
</details>
<details>
<summary>摘要</summary>
《benchmarking、标准和认证》是密切相关的过程。标准可以提供一些必须遵循的规范要求，机器人和人工智能系统可能或可能不遵循。认证通常基于一个或多个标准来决定授予操作权限。而 benchmark 则是一种标准化测试集，可以用来评估机器人和人工智能系统的性能。 benchmark 因此可以被视为一种不正式的标准。在这篇文章中，我们将通过 examples from benchmarking、标准和认证， argued that这三个相关过程不仅有用，而且是责任创新的重要组成部分。
</details></li>
</ul>
<hr>
<h2 id="OSN-MDAD-Machine-Translation-Dataset-for-Arabic-Multi-Dialectal-Conversations-on-Online-Social-Media"><a href="#OSN-MDAD-Machine-Translation-Dataset-for-Arabic-Multi-Dialectal-Conversations-on-Online-Social-Media" class="headerlink" title="OSN-MDAD: Machine Translation Dataset for Arabic Multi-Dialectal Conversations on Online Social Media"></a>OSN-MDAD: Machine Translation Dataset for Arabic Multi-Dialectal Conversations on Online Social Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12137">http://arxiv.org/abs/2309.12137</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fatimah Alzamzami, Abdulmotaleb El Saddik</li>
<li>for: 本研究旨在提高阿拉伯语 dialectal 翻译模型的效果，以满足社交媒体平台上的语言需求。</li>
<li>methods: 研究人员采用了一种 Contextual Translation 策略，通过将英语推文翻译成四种阿拉伯语方言： Golfo、Yemeni、Iraqi 和 Levantine。</li>
<li>results: 研究人员通过开发神经网络翻译模型，证明了该数据集的可靠性和效果。<details>
<summary>Abstract</summary>
While resources for English language are fairly sufficient to understand content on social media, similar resources in Arabic are still immature. The main reason that the resources in Arabic are insufficient is that Arabic has many dialects in addition to the standard version (MSA). Arabs do not use MSA in their daily communications; rather, they use dialectal versions. Unfortunately, social users transfer this phenomenon into their use of social media platforms, which in turn has raised an urgent need for building suitable AI models for language-dependent applications. Existing machine translation (MT) systems designed for MSA fail to work well with Arabic dialects. In light of this, it is necessary to adapt to the informal nature of communication on social networks by developing MT systems that can effectively handle the various dialects of Arabic. Unlike for MSA that shows advanced progress in MT systems, little effort has been exerted to utilize Arabic dialects for MT systems. While few attempts have been made to build translation datasets for dialectal Arabic, they are domain dependent and are not OSN cultural-language friendly. In this work, we attempt to alleviate these limitations by proposing an online social network-based multidialect Arabic dataset that is crafted by contextually translating English tweets into four Arabic dialects: Gulf, Yemeni, Iraqi, and Levantine. To perform the translation, we followed our proposed guideline framework for content translation, which could be universally applicable for translation between foreign languages and local dialects. We validated the authenticity of our proposed dataset by developing neural MT models for four Arabic dialects. Our results have shown a superior performance of our NMT models trained using our dataset. We believe that our dataset can reliably serve as an Arabic multidialectal translation dataset for informal MT tasks.
</details>
<details>
<summary>摘要</summary>
在社交媒体上，英语资源够用以理解内容，但阿拉伯语资源仍然落后。主要原因是阿拉伯语有很多方言，而且用户不使用标准版本（MSA）在日常交流中，而是使用方言版本。这使得社交媒体平台上的用户将这种现象传播到了他们的使用方式，从而提高了建立适合语言依赖应用的人工智能模型的需求。现有的机器翻译（MT）系统设计为MSA时，对阿拉伯语方言不够有效。因此，需要适应社交媒体上的不正式交流方式，开发MT系统可以有效地处理不同的阿拉伯语方言。与MSA的翻译系统有很大进步的情况不同，对阿拉伯语方言的翻译系统几乎没有努力。尽管有些尝试了为dialectal Arabic建立翻译集合，但这些集合是域名 dependent 并不是社交网络文化语言友好。在这种情况下，我们尝试缓解这些限制，提出了一个基于社交网络的多方言阿拉伯语数据集。我们采用我们提议的内容翻译指南来进行翻译，这可以universally适用于外语到本地方言的翻译。我们验证了我们的数据集的authenticity，通过开发四种阿拉伯语方言的神经机器翻译模型。我们的结果表明，使用我们的数据集训练的NMT模型表现出色。我们认为，我们的数据集可靠地服务为阿拉伯语多方言翻译数据集。
</details></li>
</ul>
<hr>
<h2 id="A-knowledge-representation-approach-for-construction-contract-knowledge-modeling"><a href="#A-knowledge-representation-approach-for-construction-contract-knowledge-modeling" class="headerlink" title="A knowledge representation approach for construction contract knowledge modeling"></a>A knowledge representation approach for construction contract knowledge modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12132">http://arxiv.org/abs/2309.12132</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chunmo Zheng, Saika Wong, Xing Su, Yinqiu Tang</li>
<li>for: 本研究旨在使用大型自然语言模型（LLM）提高建筑合同管理的自动化程度，减少人类错误和时间成本。</li>
<li>methods: 本研究提出了一种嵌入式合同知识图（NCKG）知识表示方法，将专业人员驱动的合同知识以结构化的方式呈现，以防止LLM生成的内容不准确或欺诈性强。</li>
<li>results: 本研究实现了一个基于NCKG和LLM的合同审核管道，对建筑合同进行了可靠和可解释的审核，从而减少了合同风险。<details>
<summary>Abstract</summary>
The emergence of large language models (LLMs) presents an unprecedented opportunity to automate construction contract management, reducing human errors and saving significant time and costs. However, LLMs may produce convincing yet inaccurate and misleading content due to a lack of domain expertise. To address this issue, expert-driven contract knowledge can be represented in a structured manner to constrain the automatic contract management process. This paper introduces the Nested Contract Knowledge Graph (NCKG), a knowledge representation approach that captures the complexity of contract knowledge using a nested structure. It includes a nested knowledge representation framework, a NCKG ontology built on the framework, and an implementation method. Furthermore, we present the LLM-assisted contract review pipeline enhanced with external knowledge in NCKG. Our pipeline achieves a promising performance in contract risk reviewing, shedding light on the combination of LLM and KG towards more reliable and interpretable contract management.
</details>
<details>
<summary>摘要</summary>
LLM的出现提供了历史上无 precedent的机会，使得建筑合同管理可以自动化，从而减少人类错误和成本。然而，LLM可能生成的内容可能会有吸引力，但是不准确和欺骗性很强。为解决这个问题，我们可以通过封装专家驱动的合同知识来约束自动合同管理过程。本文介绍了嵌入式合同知识图ogram（NCKG），一种知识表示方法，它使用嵌入结构来捕捉合同知识的复杂性。它包括嵌入结构知识表示框架、基于框架的NCKG ontology，以及实现方法。此外，我们还提出了利用LLM和KG的结合来提高合同审核的管道。我们的管道实现了在合同风险审核中的优秀表现，为将LLM和KG结合在更可靠和可解释的合同管理中提供了灯光。
</details></li>
</ul>
<hr>
<h2 id="Incentivizing-Massive-Unknown-Workers-for-Budget-Limited-Crowdsensing-From-Off-Line-and-On-Line-Perspectives"><a href="#Incentivizing-Massive-Unknown-Workers-for-Budget-Limited-Crowdsensing-From-Off-Line-and-On-Line-Perspectives" class="headerlink" title="Incentivizing Massive Unknown Workers for Budget-Limited Crowdsensing: From Off-Line and On-Line Perspectives"></a>Incentivizing Massive Unknown Workers for Budget-Limited Crowdsensing: From Off-Line and On-Line Perspectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12113">http://arxiv.org/abs/2309.12113</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feng Li, Yuqi Chai, Huan Yang, Pengfei Hu, Lingjie Duan</li>
<li>For: 增强大量未知工作者的奖励机制， addresses the challenges of limited budget and dynamic worker population.* Methods: 基于Context-Aware Combinatorial Multi-Armed Bandit (CACI) mechanism, leveraging exploration-exploitation trade-off in a partitioned context space to incentivize massive unknown workers with limited budget.* Results: 提供了理论上的Upper Bounds on the regrets, 并通过实验证明了机制的有效性。<details>
<summary>Abstract</summary>
Although the uncertainties of the workers can be addressed by the standard Combinatorial Multi-Armed Bandit (CMAB) framework in existing proposals through a trade-off between exploration and exploitation, we may not have sufficient budget to enable the trade-off among the individual workers, especially when the number of the workers is huge while the budget is limited. Moreover, the standard CMAB usually assumes the workers always stay in the system, whereas the workers may join in or depart from the system over time, such that what we have learnt for an individual worker cannot be applied after the worker leaves. To address the above challenging issues, in this paper, we first propose an off-line Context-Aware CMAB-based Incentive (CACI) mechanism. We innovate in leveraging the exploration-exploitation trade-off in a elaborately partitioned context space instead of the individual workers, to effectively incentivize the massive unknown workers with very limited budget. We also extend the above basic idea to the on-line setting where unknown workers may join in or depart from the systems dynamically, and propose an on-line version of the CACI mechanism. Specifically, by the exploitation-exploration trade-off in the context space, we learn to estimate the sensing ability of any unknown worker (even it never appeared in the system before) according to its context information. We perform rigorous theoretical analysis to reveal the upper bounds on the regrets of our CACI mechanisms and to prove their truthfulness and individual rationality, respectively. Extensive experiments on both synthetic and real datasets are also conducted to verify the efficacy of our mechanisms.
</details>
<details>
<summary>摘要</summary>
尽管工作者的不确定性可以通过标准的 combinatorial Multi-Armed Bandit（CMAB）框架在现有的建议中Addressed through a trade-off between exploration and exploitation, but we may not have enough budget to enable the trade-off among individual workers, especially when the number of workers is large and the budget is limited. In addition, the standard CMAB usually assumes that workers always stay in the system, but workers may join or leave the system over time, so what we learn about an individual worker may not be applicable after they leave. To address these challenges, in this paper, we propose an offline Context-Aware CMAB-based Incentive (CACI) mechanism. We innovate by leveraging the exploration-exploitation trade-off in a carefully partitioned context space instead of individual workers to effectively incentivize massive unknown workers with a very limited budget. We also extend the basic idea to the online setting where unknown workers may join or leave the system dynamically, and propose an online version of the CACI mechanism. Specifically, by using the exploration-exploitation trade-off in the context space, we learn to estimate the sensing ability of any unknown worker (even if it has never appeared in the system before) based on its context information. We provide rigorous theoretical analysis to reveal the upper bounds on the regrets of our CACI mechanisms and to prove their truthfulness and individual rationality, respectively. Extensive experiments on both synthetic and real datasets are also conducted to verify the effectiveness of our mechanisms.
</details></li>
</ul>
<hr>
<h2 id="PEFTT-Parameter-Efficient-Fine-Tuning-for-low-resource-Tibetan-pre-trained-language-models"><a href="#PEFTT-Parameter-Efficient-Fine-Tuning-for-low-resource-Tibetan-pre-trained-language-models" class="headerlink" title="PEFTT: Parameter-Efficient Fine-Tuning for low-resource Tibetan pre-trained language models"></a>PEFTT: Parameter-Efficient Fine-Tuning for low-resource Tibetan pre-trained language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12109">http://arxiv.org/abs/2309.12109</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhou Mingjun, Daiqing Zhuoma, Qun Nuo, Nyima Tashi</li>
<li>for: 这个研究是为了探索高资源语言模型的高效微调技术，以便更多的用户和机构可以使用这些模型进行训练。</li>
<li>methods: 本研究使用了三种有效微调策略：”提示微调”、”Adapter轻量级微调”和”提示微调+Adapter微调”，并对公共可用的 TNCC-title 数据集进行实验。</li>
<li>results: 实验结果表明，使用这些微调策略可以获得显著的改善，为 Tibetan 语言应用程序在基于预训练模型的上提供了有价值的发现。<details>
<summary>Abstract</summary>
In this era of large language models (LLMs), the traditional training of models has become increasingly unimaginable for regular users and institutions. The exploration of efficient fine-tuning for high-resource languages on these models is an undeniable trend that is gradually gaining popularity. However, there has been very little exploration for various low-resource languages, such as Tibetan. Research in Tibetan NLP is inherently scarce and limited. While there is currently no existing large language model for Tibetan due to its low-resource nature, that day will undoubtedly arrive. Therefore, research on efficient fine-tuning for low-resource language models like Tibetan is highly necessary. Our research can serve as a reference to fill this crucial gap. Efficient fine-tuning strategies for pre-trained language models (PLMs) in Tibetan have seen minimal exploration. We conducted three types of efficient fine-tuning experiments on the publicly available TNCC-title dataset: "prompt-tuning," "Adapter lightweight fine-tuning," and "prompt-tuning + Adapter fine-tuning." The experimental results demonstrate significant improvements using these methods, providing valuable insights for advancing Tibetan language applications in the context of pre-trained models.
</details>
<details>
<summary>摘要</summary>
在这个大语模型（LLM）时代，传统的模型训练已成为常见的无法想象的行为，特别是 для普通用户和机构。探索高资源语言模型的有效精细调整是一种日益受欢迎的趋势，但对低资源语言，如藏语，的研究却很少。藏语自然语言处理研究受限，目前没有任何藏语大语模型，这一天将来得不可避免。因此，关于低资源语言模型的有效精细调整是非常必要的。在这个背景下，我们对藏语预训练语言模型（PLM）的有效精细调整进行了较少的探索。我们在公共可用的 TNCC-title 数据集上进行了三种有效精细调整实验："提示调整","Adapter 轻量级精细调整"和"提示调整 + Adapter 精细调整"。实验结果表明，这些方法可以获得显著改进，为 Tibetan 语言应用程序在预训练模型的上下文中提供了有价值的洞察。
</details></li>
</ul>
<hr>
<h2 id="Prompt-Tuned-Embedding-Classification-for-Multi-Label-Industry-Sector-Allocation"><a href="#Prompt-Tuned-Embedding-Classification-for-Multi-Label-Industry-Sector-Allocation" class="headerlink" title="Prompt Tuned Embedding Classification for Multi-Label Industry Sector Allocation"></a>Prompt Tuned Embedding Classification for Multi-Label Industry Sector Allocation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12075">http://arxiv.org/abs/2309.12075</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/eqtpartners/ptec">https://github.com/eqtpartners/ptec</a></li>
<li>paper_authors: Valentin Leonhard Buchner, Lele Cao, Jan-Christoph Kalo, Vilhelm von Ehrenheim</li>
<li>for: 这个研究用于评估和优化预训练语言模型（PLM）的精心调整方法，以及这种方法在多类文本分类任务中的性能和计算效率。</li>
<li>methods: 本研究使用了Prompt Tuning和基准方法来评估多类文本分类任务的性能和计算效率。它还应用了Trie Search来Address limitation (a)，并将PLM的语言头换为分类头来Address limitation (b)和(c)。</li>
<li>results: 研究发现，Prompt Tuned Embedding Classification（PTEC）可以显著改善文本分类性能，同时降低推理时间成本。此外，模型的性能在不同公司规模和知名度的情况下都具有可靠性。<details>
<summary>Abstract</summary>
Prompt Tuning is emerging as a scalable and cost-effective method to fine-tune Pretrained Language Models (PLMs), which are often referred to as Large Language Models (LLMs). This study benchmarks the performance and computational efficiency of Prompt Tuning and baselines for multi-label text classification. This is applied to the challenging task of classifying companies into an investment firm's proprietary industry taxonomy, supporting their thematic investment strategy. Text-to-text classification is frequently reported to outperform task-specific classification heads, but has several limitations when applied to a multi-label classification problem where each label consists of multiple tokens: (a) Generated labels may not match any label in the label taxonomy; (b) The fine-tuning process lacks permutation invariance and is sensitive to the order of the provided labels; (c) The model provides binary decisions rather than appropriate confidence scores. Limitation (a) is addressed by applying constrained decoding using Trie Search, which slightly improves classification performance. All limitations (a), (b), and (c) are addressed by replacing the PLM's language head with a classification head, which is referred to as Prompt Tuned Embedding Classification (PTEC). This improves performance significantly, while also reducing computational costs during inference. In our industrial application, the training data is skewed towards well-known companies. We confirm that the model's performance is consistent across both well-known and less-known companies. Our overall results indicate the continuing need to adapt state-of-the-art methods to domain-specific tasks, even in the era of PLMs with strong generalization abilities. We release our codebase and a benchmarking dataset at https://github.com/EQTPartners/PTEC.
</details>
<details>
<summary>摘要</summary>
《Prompt Tuning for Multi-Label Text Classification》Introduction:Prompt Tuning 是一种可扩展和成本效果的方法，用于细化预训练语言模型（PLM），以实现多个标签文本分类。本研究对 Prompt Tuning 和基eline进行性能和计算效率的比较，并应用于投资公司的专有行业分类任务。文本到文本分类 часто被报道可以超越任务特定的分类头，但在多个标签分类问题中存在以下限制：（a）生成的标签可能并不匹配任何标签在标签分类表中；（b） fine-tuning 过程缺乏 permutation 不变性，敏感于提供标签的顺序；（c）模型提供的 binary 决策而不是适当的信心分数。限制（a）通过使用 Trie Search 的受限 décoding，略微提高分类性能。所有限制（a）、（b）和（c）都被 Addressed 通过将 PLM 的语言头 replaced 为分类头，称为 Prompt Tuned Embedding Classification (PTEC)，这Significantly 提高性能，同时降低了推理过程中的计算成本。在我们的工业应用中，训练数据偏向知名公司。我们确认模型在知名和不知名公司之间具有一致性。总的来说，我们的结果表明在域专任务中，需要灵活适应当今 PLM 的状态艺术，以实现优化的性能。我们将代码库和分类数据集发布在 GitHub 上，链接在 <https://github.com/EQTPartners/PTEC>。
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-quantized-LLaMa-based-models-on-the-Brazilian-Secondary-School-Exam"><a href="#Benchmarking-quantized-LLaMa-based-models-on-the-Brazilian-Secondary-School-Exam" class="headerlink" title="Benchmarking quantized LLaMa-based models on the Brazilian Secondary School Exam"></a>Benchmarking quantized LLaMa-based models on the Brazilian Secondary School Exam</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12071">http://arxiv.org/abs/2309.12071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matheus L. O. Santos, Cláudio E. C. Campelo</li>
<li>for: 这个研究旨在评估基于7和13亿LLaMA模型的大语言模型（LLMs）在家用硬件上的性能。</li>
<li>methods: 我们使用了一个包含1,006个问题的数据库，来评估这些模型的效果。我们还测试了这些模型的计算效率。</li>
<li>results: 我们发现最佳performing模型在原始葡萄牙语问题上达到了约46%的准确率，而在英文翻译中达到了约49%的准确率。此外，我们发现7和13亿LLMs在这些问题上的计算时间为20和50秒，室内装备了AMD Ryzen 5 3600x处理器。<details>
<summary>Abstract</summary>
Although Large Language Models (LLMs) represent a revolution in the way we interact with computers, allowing the construction of complex questions and the ability to reason over a sequence of statements, their use is restricted due to the need for dedicated hardware for execution. In this study, we evaluate the performance of LLMs based on the 7 and 13 billion LLaMA models, subjected to a quantization process and run on home hardware. The models considered were Alpaca, Koala, and Vicuna. To evaluate the effectiveness of these models, we developed a database containing 1,006 questions from the ENEM (Brazilian National Secondary School Exam). Our analysis revealed that the best performing models achieved an accuracy of approximately 46% for the original texts of the Portuguese questions and 49% on their English translations. In addition, we evaluated the computational efficiency of the models by measuring the time required for execution. On average, the 7 and 13 billion LLMs took approximately 20 and 50 seconds, respectively, to process the queries on a machine equipped with an AMD Ryzen 5 3600x processor
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:尽管大语言模型（LLM）代表了计算机与人类之间的交互方式的革命，允许建立复杂的问题和对语言序列进行理解，但其使用受到硬件限制，因此在执行时需要专门的硬件。在这项研究中，我们评估了基于7和13亿个LLaMA模型的LMM，经过量化处理并在家用硬件上运行。我们考虑了阿LPACA、科洛哈和维瓦纳这三种模型。为了评估这些模型的效果，我们创建了包含1006个ENEM（巴西国家高中考试）问题的数据库。我们的分析发现，最佳performing模型在原始葡萄牙语问题上的准确率为 approximately 46%，而在其英文翻译中的准确率为approximately 49%。此外，我们还评估了这些模型的计算效率，并测量了在一个配备AMD Ryzen 5 3600x处理器的机器上执行查询所需的时间。结果表明，7亿和13亿LLMs在 average需要20和50秒钟才能处理查询。
</details></li>
</ul>
<hr>
<h2 id="Survey-of-Action-Recognition-Spotting-and-Spatio-Temporal-Localization-in-Soccer-–-Current-Trends-and-Research-Perspectives"><a href="#Survey-of-Action-Recognition-Spotting-and-Spatio-Temporal-Localization-in-Soccer-–-Current-Trends-and-Research-Perspectives" class="headerlink" title="Survey of Action Recognition, Spotting and Spatio-Temporal Localization in Soccer – Current Trends and Research Perspectives"></a>Survey of Action Recognition, Spotting and Spatio-Temporal Localization in Soccer – Current Trends and Research Perspectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12067">http://arxiv.org/abs/2309.12067</a></li>
<li>repo_url: None</li>
<li>paper_authors: Karolina Seweryn, Anna Wróblewska, Szymon Łukasik</li>
<li>for: 本研究旨在提供关于足球动作认知的全面概述，包括动作识别、定位和空间时间动作local化等方面，尤其是使用不同感知modalities和多modal方法。</li>
<li>methods: 本文详细介绍了用于评估模型性能的公共数据源和评价指标，并探讨了最新的状态艺术方法，包括深度学习技术和传统方法。文中强调了多modal方法，以及将一种源数据 representation在不同的方式下表示。</li>
<li>results: 本文评论了现有的状态艺术方法的优劣点和局限性，以及它们在提高模型准确性和鲁棒性方面的潜在潜力。最后，文章强调了未来在足球动作认知领域的开放研究问题和未来趋势，包括多modal方法在这个领域的潜在推动作用。<details>
<summary>Abstract</summary>
Action scene understanding in soccer is a challenging task due to the complex and dynamic nature of the game, as well as the interactions between players. This article provides a comprehensive overview of this task divided into action recognition, spotting, and spatio-temporal action localization, with a particular emphasis on the modalities used and multimodal methods. We explore the publicly available data sources and metrics used to evaluate models' performance. The article reviews recent state-of-the-art methods that leverage deep learning techniques and traditional methods. We focus on multimodal methods, which integrate information from multiple sources, such as video and audio data, and also those that represent one source in various ways. The advantages and limitations of methods are discussed, along with their potential for improving the accuracy and robustness of models. Finally, the article highlights some of the open research questions and future directions in the field of soccer action recognition, including the potential for multimodal methods to advance this field. Overall, this survey provides a valuable resource for researchers interested in the field of action scene understanding in soccer.
</details>
<details>
<summary>摘要</summary>
《足球动作场景理解》是一项复杂和动态的任务，由于游戏的复杂性和玩家之间的交互。本文提供了全面的概述，分为动作识别、定位和空间时间动作Localization，强调modalities和多模态方法。我们探讨了公共可用的数据源和评估模型性能的度量。文章回顾了最新的state-of-the-art方法，包括深度学习技术和传统方法。我们专注于多模态方法，汇集视频和音频数据，以及表示一种来源的不同方式。我们讨论了方法的优点和局限性，以及它们在准确和Robustness中的潜在提升。最后，文章强调了该领域的一些未解决问题和未来方向，包括多模态方法在足球动作识别领域的潜在推动作用。总的来说，本文对研究足球动作场景理解领域的人士提供了有价值的资源。
</details></li>
</ul>
<hr>
<h2 id="An-Efficient-Consolidation-of-Word-Embedding-and-Deep-Learning-Techniques-for-Classifying-Anticancer-Peptides-FastText-BiLSTM"><a href="#An-Efficient-Consolidation-of-Word-Embedding-and-Deep-Learning-Techniques-for-Classifying-Anticancer-Peptides-FastText-BiLSTM" class="headerlink" title="An Efficient Consolidation of Word Embedding and Deep Learning Techniques for Classifying Anticancer Peptides: FastText+BiLSTM"></a>An Efficient Consolidation of Word Embedding and Deep Learning Techniques for Classifying Anticancer Peptides: FastText+BiLSTM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12058">http://arxiv.org/abs/2309.12058</a></li>
<li>repo_url: None</li>
<li>paper_authors: Onur Karakaya, Zeynep Hilal Kilimci</li>
<li>for: 这 paper 的目的是为了开发一个高精度的预测模型，用于分类抗癌肽（ACPs）。</li>
<li>methods: 该 paper 使用 Word2Vec 和 FastText 作为词嵌入技术，然后使用 CNN、LSTM 和 BiLSTM 深度学习模型进行分类。</li>
<li>results: 实验结果表明，使用提议的模型可以提高分类精度，并在 widely-used 数据集上达到新的州态艺。 Specifically, 使用 FastText+BiLSTM 组合可以达到 ACPs250 数据集的92.50% 的准确率，以及 Independent 数据集的96.15% 的准确率，从而确定新的州态艺。<details>
<summary>Abstract</summary>
Anticancer peptides (ACPs) are a group of peptides that exhibite antineoplastic properties. The utilization of ACPs in cancer prevention can present a viable substitute for conventional cancer therapeutics, as they possess a higher degree of selectivity and safety. Recent scientific advancements generate an interest in peptide-based therapies which offer the advantage of efficiently treating intended cells without negatively impacting normal cells. However, as the number of peptide sequences continues to increase rapidly, developing a reliable and precise prediction model becomes a challenging task. In this work, our motivation is to advance an efficient model for categorizing anticancer peptides employing the consolidation of word embedding and deep learning models. First, Word2Vec and FastText are evaluated as word embedding techniques for the purpose of extracting peptide sequences. Then, the output of word embedding models are fed into deep learning approaches CNN, LSTM, BiLSTM. To demonstrate the contribution of proposed framework, extensive experiments are carried on widely-used datasets in the literature, ACPs250 and Independent. Experiment results show the usage of proposed model enhances classification accuracy when compared to the state-of-the-art studies. The proposed combination, FastText+BiLSTM, exhibits 92.50% of accuracy for ACPs250 dataset, and 96.15% of accuracy for Independent dataset, thence determining new state-of-the-art.
</details>
<details>
<summary>摘要</summary>
《抗癌肽（ACPs）是一组具有抗肿瘤性的肽。使用ACPs在抗癌治疗中可能成为一种可靠的替代方案，因为它们具有更高的选择性和安全性。最新的科学发展使得肽基本治疗在抗癌领域受到了广泛关注。在这项工作中，我们的动机是提出一种高效的ACP分类模型，使用词嵌入和深度学习模型的结合。首先，我们使用Word2Vec和FastText作为词嵌入技术，以提取肽序列。然后，Word2Vec和FastText模型的输出被 fed into深度学习方法CNN、LSTM和BiLSTM。为了证明我们的提案的价值，我们在文献中广泛使用的数据集进行了广泛的实验。实验结果表明，我们的模型可以在ACPs250和独立数据集上提高分类精度，比之前的状态 arts。特别是，我们的组合FastText+BiLSTM在ACPs250数据集上达到了92.50%的准确率，在独立数据集上达到了96.15%的准确率，从而确定了新的状态 arts。》Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China.
</details></li>
</ul>
<hr>
<h2 id="BELT-Bootstrapping-Electroencephalography-to-Language-Decoding-and-Zero-Shot-Sentiment-Classification-by-Natural-Language-Supervision"><a href="#BELT-Bootstrapping-Electroencephalography-to-Language-Decoding-and-Zero-Shot-Sentiment-Classification-by-Natural-Language-Supervision" class="headerlink" title="BELT:Bootstrapping Electroencephalography-to-Language Decoding and Zero-Shot Sentiment Classification by Natural Language Supervision"></a>BELT:Bootstrapping Electroencephalography-to-Language Decoding and Zero-Shot Sentiment Classification by Natural Language Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12056">http://arxiv.org/abs/2309.12056</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinzhao Zhou, Yiqun Duan, Yu-Cheng Chang, Yu-Kai Wang, Chin-Teng Lin</li>
<li>for: 这paper的目的是提出一种新的模型和学习框架，用于解决脑Signal到自然语言翻译的问题。</li>
<li>methods: 该paper使用了大型预训练语言模型（LM）来学习EEG表示，并通过对比学习获得semantically Meaningful的EEG表示。</li>
<li>results: 该paper在两个脑解释任务上达到了state-of-the-art的结果，分别超过了基eline模型 by 5.45%和10%，并在翻译和零批情感分类任务上取得了42.31%的BLEU-1分数和67.32%的精度。<details>
<summary>Abstract</summary>
This paper presents BELT, a novel model and learning framework for the pivotal topic of brain-to-language translation research. The translation from noninvasive brain signals into readable natural language has the potential to promote the application scenario as well as the development of brain-computer interfaces (BCI) as a whole. The critical problem in brain signal decoding or brain-to-language translation is the acquisition of semantically appropriate and discriminative EEG representation from a dataset of limited scale and quality. The proposed BELT method is a generic and efficient framework that bootstraps EEG representation learning using off-the-shelf large-scale pretrained language models (LMs). With a large LM's capacity for understanding semantic information and zero-shot generalization, BELT utilizes large LMs trained on Internet-scale datasets to bring significant improvements to the understanding of EEG signals.   In particular, the BELT model is composed of a deep conformer encoder and a vector quantization encoder. Semantical EEG representation is achieved by a contrastive learning step that provides natural language supervision. We achieve state-of-the-art results on two featuring brain decoding tasks including the brain-to-language translation and zero-shot sentiment classification. Specifically, our model surpasses the baseline model on both tasks by 5.45% and over 10% and archives a 42.31% BLEU-1 score and 67.32% precision on the main evaluation metrics for translation and zero-shot sentiment classification respectively.
</details>
<details>
<summary>摘要</summary>
The proposed BELT method addresses this problem by leveraging off-the-shelf large-scale pretrained language models (LMs) to bootstrap EEG representation learning. With the capacity of large LMs to understand semantic information and their ability to generalize to new situations, BELT achieves significant improvements in understanding EEG signals.The BELT model consists of a deep conformer encoder and a vector quantization encoder, and semantical EEG representation is achieved through a contrastive learning step that provides natural language supervision. The model is evaluated on two brain decoding tasks, brain-to-language translation and zero-shot sentiment classification, and achieves state-of-the-art results. Specifically, the model outperforms the baseline model by 5.45% and over 10% on both tasks, with a BLEU-1 score of 42.31% and precision of 67.32% for translation and zero-shot sentiment classification, respectively.
</details></li>
</ul>
<hr>
<h2 id="SCVCNet-Sliding-cross-vector-convolution-network-for-cross-task-and-inter-individual-set-EEG-based-cognitive-workload-recognition"><a href="#SCVCNet-Sliding-cross-vector-convolution-network-for-cross-task-and-inter-individual-set-EEG-based-cognitive-workload-recognition" class="headerlink" title="SCVCNet: Sliding cross-vector convolution network for cross-task and inter-individual-set EEG-based cognitive workload recognition"></a>SCVCNet: Sliding cross-vector convolution network for cross-task and inter-individual-set EEG-based cognitive workload recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03749">http://arxiv.org/abs/2310.03749</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qi Wang, Li Chen, Zhiyuan Zhan, Jianhua Zhang, Zhong Yin</li>
<li>For: 这篇论文旨在应用认知劳动量识别器，通过利用不同人机任务和个体集的共同电enzephalogram（EEG）模式，实现Generic Approach。* Methods: 该论文提出了一种名为SCVCNet的神经网络模型，通过分析EEG的细致频率结构来消除任务和个体集相关的干扰。SCVCNet使用了滑动cross-vector convolution（SCVC）操作，并将 paired input layers representing theta和alpha power 作为输入。* Results: 该论文通过使用Regularized least-square method with ridge regression和extreme learning machine theory进行训练，并在三个数据库中验证性能，其中每个数据库包含不同任务由独立的参与者组成。结果显示，SCVCNet在两个不同的验证方案中平均准确率（0.6813和0.6229）和F1分数（0.6743和0.6076）达到了部分比前作高的性能。<details>
<summary>Abstract</summary>
This paper presents a generic approach for applying the cognitive workload recognizer by exploiting common electroencephalogram (EEG) patterns across different human-machine tasks and individual sets. We propose a neural network called SCVCNet, which eliminates task- and individual-set-related interferences in EEGs by analyzing finer-grained frequency structures in the power spectral densities. The SCVCNet utilizes a sliding cross-vector convolution (SCVC) operation, where paired input layers representing the theta and alpha power are employed. By extracting the weights from a kernel matrix's central row and column, we compute the weighted sum of the two vectors around a specified scalp location. Next, we introduce an inter-frequency-point feature integration module to fuse the SCVC feature maps. Finally, we combined the two modules with the output-channel pooling and classification layers to construct the model. To train the SCVCNet, we employ the regularized least-square method with ridge regression and the extreme learning machine theory. We validate its performance using three databases, each consisting of distinct tasks performed by independent participant groups. The average accuracy (0.6813 and 0.6229) and F1 score (0.6743 and 0.6076) achieved in two different validation paradigms show partially higher performance than the previous works. All features and algorithms are available on website:https://github.com/7ohnKeats/SCVCNet.
</details>
<details>
<summary>摘要</summary>
Here is the translation in Simplified Chinese:这篇论文提出了一种新的认知工作负担识别方法，使用电enzephalogram（EEG）信号。该方法称为SCVCNet，它使用神经网络分析EEG信号的功率 спектраль密度，并提取更细化的频率结构。网络使用滑动交叉向量 convolution（SCVC）操作和间频点特征集成模块来融合特征图。模型使用正则化最小二乘法withridge regression和极限学习机理来训练。模型的性能通过三个数据库，每个数据库包含不同任务和独立参与者组的EEG信号，进行验证。结果显示，提出的方法在两个不同的验证模式中的平均准确率为0.6813和0.6229，F1分数为0.6743和0.6076。所有特征和算法可以在以下网站上获得：<https://github.com/7ohnKeats/SCVCNet>。
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-driven-Exploration-Strategies-for-Online-Grasp-Learning"><a href="#Uncertainty-driven-Exploration-Strategies-for-Online-Grasp-Learning" class="headerlink" title="Uncertainty-driven Exploration Strategies for Online Grasp Learning"></a>Uncertainty-driven Exploration Strategies for Online Grasp Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12038">http://arxiv.org/abs/2309.12038</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yitian Shi, Philipp Schillinger, Miroslav Gabriel, Alexander Kuss, Zohar Feldman, Hanna Ziesche, Ngo Anh Vien</li>
<li>For: 提高机器人箱内物品抓取率和灵活性。* Methods: 基于在线学习和 reinforcement learning 的 grasp 预测方法，以及不同的不确定性估计方法。* Results: 实验结果显示，提出的方法可以在实际箱内物品抓取场景中显著提高 grasp 预测精度和灵活性，并且比传统的在线学习方法具有更好的适应能力。<details>
<summary>Abstract</summary>
Existing grasp prediction approaches are mostly based on offline learning, while, ignored the exploratory grasp learning during online adaptation to new picking scenarios, i.e., unseen object portfolio, camera and bin settings etc. In this paper, we present a novel method for online learning of grasp predictions for robotic bin picking in a principled way. Existing grasp prediction approaches are mostly based on offline learning, while, ignored the exploratory grasp learning during online adaptation to new picking scenarios, i.e., unseen object portfolio, camera and bin settings etc. In this paper, we present a novel method for online learning of grasp predictions for robotic bin picking in a principled way. Specifically, the online learning algorithm with an effective exploration strategy can significantly improve its adaptation performance to unseen environment settings. To this end, we first propose to formulate online grasp learning as a RL problem that will allow to adapt both grasp reward prediction and grasp poses. We propose various uncertainty estimation schemes based on Bayesian Uncertainty Quantification and Distributional Ensembles. We carry out evaluations on real-world bin picking scenes of varying difficulty. The objects in the bin have various challenging physical and perceptual characteristics that can be characterized by semi- or total transparency, and irregular or curved surfaces. The results of our experiments demonstrate a notable improvement in the suggested approach compared to conventional online learning methods which incorporate only naive exploration strategies.
</details>
<details>
<summary>摘要</summary>
现有的抓取预测方法都是基于离线学习，而忽略了在线适应新抓取场景中的探索式学习，即未经见过的物品库、摄像头和容器设置等等。在这篇论文中，我们提出了一种新的在线学习抓取预测方法，以便在原则上进行在线适应。specifically，我们提出了一种有效的探索策略，可以显著提高在未经见过的环境设置下的适应性。为此，我们首先提出了在线抓取学习为RL问题的形式，以便适应抓取奖励预测和抓取姿势。我们还提出了多种不确定性估计方法，基于 bayesian uncertainty quantification和分布 ensemble。我们在实际的垃圾桶抓取场景中进行了评估，桶中的物品具有各种困难的物理和感知特征，包括半透明或完全透明、扭曲或弯曲的表面等。实验结果表明，我们的方法与传统的在线学习方法相比，具有显著的改善。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Hypergraph-Structure-Learning-for-Traffic-Flow-Forecasting"><a href="#Dynamic-Hypergraph-Structure-Learning-for-Traffic-Flow-Forecasting" class="headerlink" title="Dynamic Hypergraph Structure Learning for Traffic Flow Forecasting"></a>Dynamic Hypergraph Structure Learning for Traffic Flow Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12028">http://arxiv.org/abs/2309.12028</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yusheng Zhao, Xiao Luo, Wei Ju, Chong Chen, Xian-Sheng Hua, Ming Zhang</li>
<li>for: 预测未来交通情况，基于路网和过去交通情况。</li>
<li>methods: 使用强化图 neural network (GNN) 模型复杂的空间时间相关性，并提出一种名为动态Hipergraph结构学习 (DyHSL) 模型来解决交通流量预测问题。</li>
<li>results: 在四个流行的交通测试数据集上进行了广泛的实验，并证明了 DyHSL 模型的效果比基本方法更高。<details>
<summary>Abstract</summary>
This paper studies the problem of traffic flow forecasting, which aims to predict future traffic conditions on the basis of road networks and traffic conditions in the past. The problem is typically solved by modeling complex spatio-temporal correlations in traffic data using spatio-temporal graph neural networks (GNNs). However, the performance of these methods is still far from satisfactory since GNNs usually have limited representation capacity when it comes to complex traffic networks. Graphs, by nature, fall short in capturing non-pairwise relations. Even worse, existing methods follow the paradigm of message passing that aggregates neighborhood information linearly, which fails to capture complicated spatio-temporal high-order interactions. To tackle these issues, in this paper, we propose a novel model named Dynamic Hypergraph Structure Learning (DyHSL) for traffic flow prediction. To learn non-pairwise relationships, our DyHSL extracts hypergraph structural information to model dynamics in the traffic networks, and updates each node representation by aggregating messages from its associated hyperedges. Additionally, to capture high-order spatio-temporal relations in the road network, we introduce an interactive graph convolution block, which further models the neighborhood interaction for each node. Finally, we integrate these two views into a holistic multi-scale correlation extraction module, which conducts temporal pooling with different scales to model different temporal patterns. Extensive experiments on four popular traffic benchmark datasets demonstrate the effectiveness of our proposed DyHSL compared with a broad range of competing baselines.
</details>
<details>
<summary>摘要</summary>
DyHSL extracts hypergraph structural information to model dynamics in the traffic networks and updates each node representation by aggregating messages from its associated hyperedges. Additionally, an interactive graph convolution block is introduced to model high-order spatio-temporal relations in the road network. The two views are then integrated into a holistic multi-scale correlation extraction module, which conducts temporal pooling with different scales to model different temporal patterns.Extensive experiments on four popular traffic benchmark datasets demonstrate the effectiveness of DyHSL compared with a broad range of competing baselines. The proposed method is able to capture complex traffic patterns and improve traffic flow forecasting accuracy.
</details></li>
</ul>
<hr>
<h2 id="Demystifying-Visual-Features-of-Movie-Posters-for-Multi-Label-Genre-Identification"><a href="#Demystifying-Visual-Features-of-Movie-Posters-for-Multi-Label-Genre-Identification" class="headerlink" title="Demystifying Visual Features of Movie Posters for Multi-Label Genre Identification"></a>Demystifying Visual Features of Movie Posters for Multi-Label Genre Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12022">http://arxiv.org/abs/2309.12022</a></li>
<li>repo_url: None</li>
<li>paper_authors: Utsav Kumar Nareti, Chandranath Adak, Soumi Chattopadhyay</li>
<li>for: Automated multi-label genre identification of movies from poster images.</li>
<li>methods: Deep transformer network with a probabilistic module.</li>
<li>results: Encouraging performance and outperformed some contemporary architectures in experimental analysis using 13882 posters from IMDb.<details>
<summary>Abstract</summary>
In the film industry, movie posters have been an essential part of advertising and marketing for many decades, and continue to play a vital role even today in the form of digital posters through online, social media and OTT platforms. Typically, movie posters can effectively promote and communicate the essence of a film, such as its genre, visual style/ tone, vibe and storyline cue/ theme, which are essential to attract potential viewers. Identifying the genres of a movie often has significant practical applications in recommending the film to target audiences. Previous studies on movie genre identification are limited to subtitles, plot synopses, and movie scenes that are mostly accessible after the movie release. Posters usually contain pre-release implicit information to generate mass interest. In this paper, we work for automated multi-label genre identification only from movie poster images, without any aid of additional textual/meta-data information about movies, which is one of the earliest attempts of its kind. Here, we present a deep transformer network with a probabilistic module to identify the movie genres exclusively from the poster. For experimental analysis, we procured 13882 number of posters of 13 genres from the Internet Movie Database (IMDb), where our model performances were encouraging and even outperformed some major contemporary architectures.
</details>
<details>
<summary>摘要</summary>
在电影业中，电影海报是广告和营销的重要组成部分，已经有很多年了，并且在今天的形式中仍然扮演着重要的角色，包括数字海报通过在线、社交媒体和OTT平台。通常，电影海报可以有效地推广和传达电影的核心元素，如其类别、视觉风格/调子、氛围和故事线索/主题，这些元素都是吸引potential viewers的关键。识别电影的类别有重要实际应用，例如推荐电影给target audience。过去的研究通常限于电影的字幕、剧情简opsis和电影场景，这些信息通常都可以在电影上映后获得。然而，海报通常包含在电影发布之前的隐式信息，以便生成大量的兴趣。在这篇论文中，我们采用了自动化多标签类别预测方法，只使用电影海报图像，无需任何额外的文本/ мета-数据信息 about movies，这是当前的一个非常早期的尝试。我们采用了深度变换网络和概率模块来预测电影类别。为了实验分析，我们从互联网电影数据库（IMDb）上获取了13882张海报，并发现我们的模型性能很出色，甚至超过了一些当前的主流架构。
</details></li>
</ul>
<hr>
<h2 id="Safe-Hierarchical-Reinforcement-Learning-for-CubeSat-Task-Scheduling-Based-on-Energy-Consumption"><a href="#Safe-Hierarchical-Reinforcement-Learning-for-CubeSat-Task-Scheduling-Based-on-Energy-Consumption" class="headerlink" title="Safe Hierarchical Reinforcement Learning for CubeSat Task Scheduling Based on Energy Consumption"></a>Safe Hierarchical Reinforcement Learning for CubeSat Task Scheduling Based on Energy Consumption</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12004">http://arxiv.org/abs/2309.12004</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahya Ramezani, M. Amin Alandihallaj, Jose Luis Sanchez-Lopez, Andreas Hein</li>
<li>for: 优化CubeSat任务调度在低地球轨道（LEO）中</li>
<li>methods: 使用层次强化学习方法，包括高级策略 для全局任务分配和低级策略作为安全机制，并使用相似性注意力基本编码器（SABE）进行任务优先级化和多项式预测器（MLP）进行能量消耗预测</li>
<li>results: 在多个CubeSat配置下，通过实验证明 Hierarchical Reinforcement Learning 的超 convergency和任务成功率优于 MADDPG 模型和随机调度策略<details>
<summary>Abstract</summary>
This paper presents a Hierarchical Reinforcement Learning methodology tailored for optimizing CubeSat task scheduling in Low Earth Orbits (LEO). Incorporating a high-level policy for global task distribution and a low-level policy for real-time adaptations as a safety mechanism, our approach integrates the Similarity Attention-based Encoder (SABE) for task prioritization and an MLP estimator for energy consumption forecasting. Integrating this mechanism creates a safe and fault-tolerant system for CubeSat task scheduling. Simulation results validate the Hierarchical Reinforcement Learning superior convergence and task success rate, outperforming both the MADDPG model and traditional random scheduling across multiple CubeSat configurations.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="LMSYS-Chat-1M-A-Large-Scale-Real-World-LLM-Conversation-Dataset"><a href="#LMSYS-Chat-1M-A-Large-Scale-Real-World-LLM-Conversation-Dataset" class="headerlink" title="LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset"></a>LMSYS-Chat-1M: A Large-Scale Real-World LLM Conversation Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11998">http://arxiv.org/abs/2309.11998</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lm-sys/fastchat">https://github.com/lm-sys/fastchat</a></li>
<li>paper_authors: Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Tianle Li, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zhuohan Li, Zi Lin, Eric. P Xing, Joseph E. Gonzalez, Ion Stoica, Hao Zhang</li>
<li>for: The paper is written for researchers and developers who want to understand and advance the capabilities of large language models (LLMs) in real-world scenarios.</li>
<li>methods: The paper introduces a large-scale dataset called LMSYS-Chat-1M, which contains one million real-world conversations with 25 state-of-the-art LLMs. The dataset is collected from 210K unique IP addresses in the wild and includes a curation process, basic statistics, and topic distribution.</li>
<li>results: The paper demonstrates the versatility of the dataset through four use cases: developing content moderation models, building a safety benchmark, training instruction-following models, and creating challenging benchmark questions. The dataset is publicly available and is expected to serve as a valuable resource for understanding and advancing LLM capabilities.<details>
<summary>Abstract</summary>
Studying how people interact with large language models (LLMs) in real-world scenarios is increasingly important due to their widespread use in various applications. In this paper, we introduce LMSYS-Chat-1M, a large-scale dataset containing one million real-world conversations with 25 state-of-the-art LLMs. This dataset is collected from 210K unique IP addresses in the wild on our Vicuna demo and Chatbot Arena website. We offer an overview of the dataset's content, including its curation process, basic statistics, and topic distribution, highlighting its diversity, originality, and scale. We demonstrate its versatility through four use cases: developing content moderation models that perform similarly to GPT-4, building a safety benchmark, training instruction-following models that perform similarly to Vicuna, and creating challenging benchmark questions. We believe that this dataset will serve as a valuable resource for understanding and advancing LLM capabilities. The dataset is publicly available at https://huggingface.co/datasets/lmsys/lmsys-chat-1m.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:研究人员在实际场景中与大语言模型（LLM）交互的研究日益重要，因为它们在各种应用程序中广泛使用。在这篇论文中，我们介绍了LMSYS-Chat-1M数据集，这是一个包含100万个实际对话，并与25个现代LLM进行交互的大规模数据集。这个数据集来自于210,000个唯一的IP地址，并在我们的Vicuna demo和Chatbot Arena网站上采集。我们提供了数据集的内容概述，包括筛选过程、基本统计和主题分布，并 highlighted its diversity, originality, and scale。我们还示例了这个数据集的多样性，通过四个使用场景：开发与GPT-4类似的内容审核模型，建立安全基准，训练与Vicuna类似的 instrucion-following 模型，并创建挑战性的问题集。我们认为这个数据集将成为 LLM 能力的研究和进步的重要资源。这个数据集公开可用于https://huggingface.co/datasets/lmsys/lmsys-chat-1m。
</details></li>
</ul>
<hr>
<h2 id="Predictability-and-Comprehensibility-in-Post-Hoc-XAI-Methods-A-User-Centered-Analysis"><a href="#Predictability-and-Comprehensibility-in-Post-Hoc-XAI-Methods-A-User-Centered-Analysis" class="headerlink" title="Predictability and Comprehensibility in Post-Hoc XAI Methods: A User-Centered Analysis"></a>Predictability and Comprehensibility in Post-Hoc XAI Methods: A User-Centered Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11987">http://arxiv.org/abs/2309.11987</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anahid Jalali, Bernhard Haslhofer, Simone Kriglstein, Andreas Rauber</li>
<li>for: 本研究旨在评估用户对黑盒机器学习模型预测结果的解释是否能够增强用户对模型行为的预测能力。</li>
<li>methods: 本研究使用了两种广泛使用的工具：LIME和SHAP。我们还研究了对于用户理解和预测模型行为的影响。</li>
<li>results: 我们发现SHAP的解释在模型决策边界附近时具有显著的减少了可读性。此外，我们发现对于用户理解和预测模型行为的影响很大。基于我们的发现，我们还提出了未来采用更高度的可读性和预测性的后期解释方法的设计建议。<details>
<summary>Abstract</summary>
Post-hoc explainability methods aim to clarify predictions of black-box machine learning models. However, it is still largely unclear how well users comprehend the provided explanations and whether these increase the users ability to predict the model behavior. We approach this question by conducting a user study to evaluate comprehensibility and predictability in two widely used tools: LIME and SHAP. Moreover, we investigate the effect of counterfactual explanations and misclassifications on users ability to understand and predict the model behavior. We find that the comprehensibility of SHAP is significantly reduced when explanations are provided for samples near a model's decision boundary. Furthermore, we find that counterfactual explanations and misclassifications can significantly increase the users understanding of how a machine learning model is making decisions. Based on our findings, we also derive design recommendations for future post-hoc explainability methods with increased comprehensibility and predictability.
</details>
<details>
<summary>摘要</summary>
afterwards explainability 方法 goals to clarify predictions of black-box machine learning models. However, it is still largely unclear how well users comprehend the provided explanations and whether these increase the users ability to predict the model behavior. We approach this question by conducting a user study to evaluate comprehensibility and predictability in two widely used tools: LIME and SHAP. Moreover, we investigate the effect of counterfactual explanations and misclassifications on users ability to understand and predict the model behavior. We find that the comprehensibility of SHAP is significantly reduced when explanations are provided for samples near a model's decision boundary. Furthermore, we find that counterfactual explanations and misclassifications can significantly increase the users understanding of how a machine learning model is making decisions. Based on our findings, we also derive design recommendations for future post-hoc explainability methods with increased comprehensibility and predictability.Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other parts of the world. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Representation-Abstractions-as-Incentives-for-Reinforcement-Learning-Agents-A-Robotic-Grasping-Case-Study"><a href="#Representation-Abstractions-as-Incentives-for-Reinforcement-Learning-Agents-A-Robotic-Grasping-Case-Study" class="headerlink" title="Representation Abstractions as Incentives for Reinforcement Learning Agents: A Robotic Grasping Case Study"></a>Representation Abstractions as Incentives for Reinforcement Learning Agents: A Robotic Grasping Case Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11984">http://arxiv.org/abs/2309.11984</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/PetropoulakisPanagiotis/igae">https://github.com/PetropoulakisPanagiotis/igae</a></li>
<li>paper_authors: Panagiotis Petropoulakis, Ludwig Gräf, Josip Josifovski, Mohammadhossein Malmir, Alois Knoll</li>
<li>for: 这个研究的目的是探讨RL Agent在各种状态表示下解决 робо控制任务的效果。</li>
<li>methods: 这个研究使用了不同的状态表示方法，从模型基于的方法、数值型的表示、到图像型的表示，以评估RL Agent在不同状态表示下的性能。</li>
<li>results: 研究结果表明，RL Agent使用数值型状态表示可以与非学习基线相当，而图像型表示可以提高RL Agent的成功率和转移率。<details>
<summary>Abstract</summary>
Choosing an appropriate representation of the environment for the underlying decision-making process of the RL agent is not always straightforward. The state representation should be inclusive enough to allow the agent to informatively decide on its actions and compact enough to increase sample efficiency for policy training. Given this outlook, this work examines the effect of various state representations in incentivizing the agent to solve a specific robotic task: antipodal and planar object grasping. A continuum of state representation abstractions is defined, starting from a model-based approach with complete system knowledge, through hand-crafted numerical, to image-based representations with decreasing level of induced task-specific knowledge. We examine the effects of each representation in the ability of the agent to solve the task in simulation and the transferability of the learned policy to the real robot. The results show that RL agents using numerical states can perform on par with non-learning baselines. Furthermore, we find that agents using image-based representations from pre-trained environment embedding vectors perform better than end-to-end trained agents, and hypothesize that task-specific knowledge is necessary for achieving convergence and high success rates in robot control.
</details>
<details>
<summary>摘要</summary>
（注意：以下是简化中文翻译，不同的翻译方式可能会有所不同）选择RL机器人的决策过程下的环境表示方式不一定 straightforward。状态表示应该包含足够的信息，让机器人能够决策，同时也应该尽量减少样本效率，以便策略训练。基于这个视角，这项工作研究了不同状态表示方式对RL机器人解决特殊 робо控任务：把物捕获到极点和平面上的效果。一个维度的状态表示各种抽象维度定义，从模型基于的方法，到手工制作的数值，以至图像基于的表示，均逐渐减少所引入的任务特定知识。我们研究每种表示方式对机器人解决任务在模拟环境中的能力，以及这些学习的策略在真实机器人中的传输性。结果表明RL机器人使用数值状态可以与非学习基准相当，而使用图像基于表示，从预训练的环境嵌入向量中提取的表示，能够在策略训练中获得更高的成功率和转移率。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-the-Evaluating-Framework-for-Natural-Language-Understanding-in-AI-Systems-Language-Acquisition-as-a-Core-for-Future-Metrics"><a href="#Rethinking-the-Evaluating-Framework-for-Natural-Language-Understanding-in-AI-Systems-Language-Acquisition-as-a-Core-for-Future-Metrics" class="headerlink" title="Rethinking the Evaluating Framework for Natural Language Understanding in AI Systems: Language Acquisition as a Core for Future Metrics"></a>Rethinking the Evaluating Framework for Natural Language Understanding in AI Systems: Language Acquisition as a Core for Future Metrics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11981">http://arxiv.org/abs/2309.11981</a></li>
<li>repo_url: None</li>
<li>paper_authors: Patricio Vera, Pedro Moya, Lisa Barraza</li>
<li>for: 本研究旨在探讨人工智能（AI）领域内大语言模型（LLM）在自然语言处理（NLP）领域的不同进化，并重新评估传统机器智能的评价方法。</li>
<li>methods: 本研究提出一种新的评价框架，启发自现代语言模型的进步，旨在掌握语言理解和学习能力。</li>
<li>results: 研究表明，新的评价框架可以更好地评估机器智能的语言理解和学习能力，并且可以帮助解决传统评价方法的限制。<details>
<summary>Abstract</summary>
In the burgeoning field of artificial intelligence (AI), the unprecedented progress of large language models (LLMs) in natural language processing (NLP) offers an opportunity to revisit the entire approach of traditional metrics of machine intelligence, both in form and content. As the realm of machine cognitive evaluation has already reached Imitation, the next step is an efficient Language Acquisition and Understanding. Our paper proposes a paradigm shift from the established Turing Test towards an all-embracing framework that hinges on language acquisition, taking inspiration from the recent advancements in LLMs. The present contribution is deeply tributary of the excellent work from various disciplines, point out the need to keep interdisciplinary bridges open, and delineates a more robust and sustainable approach.
</details>
<details>
<summary>摘要</summary>
在人工智能（AI）领域的不断发展中，大语言模型（LLM）在自然语言处理（NLP）领域的无前例进步，为我们重新审视传统机器智能评价 metric 的整体方法和内容。因为机器认知领域已经达到了仿制，接下来的步骤是有效地语言学习和理解。我们的论文提出了由传统图灵测试shift towards一个涵盖语言学习的框架，以启发自最近的大语言模型的进步。本贡献受到了不同领域的出色工作的推动，要继续保持交往的桥梁，并定义了更加坚固和可持续的方法。
</details></li>
</ul>
<hr>
<h2 id="Inferring-Capabilities-from-Task-Performance-with-Bayesian-Triangulation"><a href="#Inferring-Capabilities-from-Task-Performance-with-Bayesian-Triangulation" class="headerlink" title="Inferring Capabilities from Task Performance with Bayesian Triangulation"></a>Inferring Capabilities from Task Performance with Bayesian Triangulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11975">http://arxiv.org/abs/2309.11975</a></li>
<li>repo_url: None</li>
<li>paper_authors: John Burden, Konstantinos Voudouris, Ryan Burnell, Danaja Rutar, Lucy Cheke, José Hernández-Orallo</li>
<li>for: 本研究旨在Characterizing machine learning models in richer, more meaningful ways, using diverse experimental data to infer the cognitive profile of a system.</li>
<li>methods: 该方法使用PyMC probabilistic programming library, introducing measurement layouts to model how task-instance features interact with system capabilities, triangulating features to infer capabilities from non-populational data.</li>
<li>results: 研究通过对68个实际参赛者和30个synthetic agents进行评估，成功地推断出不同的认知 профиls，展示了 capability-oriented evaluation的潜力。<details>
<summary>Abstract</summary>
As machine learning models become more general, we need to characterise them in richer, more meaningful ways. We describe a method to infer the cognitive profile of a system from diverse experimental data. To do so, we introduce measurement layouts that model how task-instance features interact with system capabilities to affect performance. These features must be triangulated in complex ways to be able to infer capabilities from non-populational data -- a challenge for traditional psychometric and inferential tools. Using the Bayesian probabilistic programming library PyMC, we infer different cognitive profiles for agents in two scenarios: 68 actual contestants in the AnimalAI Olympics and 30 synthetic agents for O-PIAAGETS, an object permanence battery. We showcase the potential for capability-oriented evaluation.
</details>
<details>
<summary>摘要</summary>
随着机器学习模型变得更通用，我们需要用更加细致、有意义的方式来描述它们。我们介绍了一种方法，用于从多种实验数据中推断系统的认知 profiling。为此，我们引入了任务实例特征和系统能力之间的测量布局，以便从非常量数据中推断系统的能力。这些特征需要在复杂的方式下进行三角测量，以便从非常量数据中推断系统的能力。我们使用 bayesian  probabilistic programming 库 PyMC，对 AnimalAI 奥运会中的68名实际参赛者和 O-PIAAGETS 对象常见性测试中的30名 sintetic agent 进行推断，并示cases the potential of capability-oriented evaluation。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Review-on-Financial-Explainable-AI"><a href="#A-Comprehensive-Review-on-Financial-Explainable-AI" class="headerlink" title="A Comprehensive Review on Financial Explainable AI"></a>A Comprehensive Review on Financial Explainable AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11960">http://arxiv.org/abs/2309.11960</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Jie Yeo, Wihan van der Heever, Rui Mao, Erik Cambria, Ranjan Satapathy, Gianmarco Mengaldo</li>
<li>for: 评估和选择深度学习模型的解释性方法，以提高深度学习模型在金融领域的透明度和可信度。</li>
<li>methods: 对深度学习模型的解释性方法进行比较分析，并根据它们的特点进行分类。</li>
<li>results: 对深度学习模型的解释性方法的透明度和可信度进行评估，并探讨采用解释性AI方法的问题和挑战，以及未来的发展方向。<details>
<summary>Abstract</summary>
The success of artificial intelligence (AI), and deep learning models in particular, has led to their widespread adoption across various industries due to their ability to process huge amounts of data and learn complex patterns. However, due to their lack of explainability, there are significant concerns regarding their use in critical sectors, such as finance and healthcare, where decision-making transparency is of paramount importance. In this paper, we provide a comparative survey of methods that aim to improve the explainability of deep learning models within the context of finance. We categorize the collection of explainable AI methods according to their corresponding characteristics, and we review the concerns and challenges of adopting explainable AI methods, together with future directions we deemed appropriate and important.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）和深度学习模型的成功导致它们在不同领域得到广泛的应用，这主要是因为它们可以处理巨量数据并学习复杂的模式。然而，由于它们的不可解性，在重要领域如金融和医疗等，它们的使用受到了 significatively 的关注，因为它们的决策过程的透明度是非常重要的。在这篇论文中，我们提供了对于改善深度学习模型可见性的比较调查。我们根据这些方法的特点进行分类，并评估了采用可见性AI方法的问题和挑战，以及未来的发展方向。
</details></li>
</ul>
<hr>
<h2 id="On-the-Definition-of-Appropriate-Trust-and-the-Tools-that-Come-with-it"><a href="#On-the-Definition-of-Appropriate-Trust-and-the-Tools-that-Come-with-it" class="headerlink" title="On the Definition of Appropriate Trust and the Tools that Come with it"></a>On the Definition of Appropriate Trust and the Tools that Come with it</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11937">http://arxiv.org/abs/2309.11937</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Helena Löfström</li>
<li>For: This paper focuses on evaluating the efficiency of human-AI interactions, specifically in terms of the human experience of explanations and the user’s appropriate trust in the model.* Methods: The paper compares the definitions of appropriate trust from the literature with model performance evaluation, and offers a novel approach to evaluating appropriate trust by taking advantage of the likenesses between definitions. The paper also provides several straightforward evaluation methods for different aspects of user performance, including measuring uncertainty and appropriate trust in regression.* Results: The paper’s main contribution is a novel approach to evaluating appropriate trust, which offers a more objective and comparative evaluation of explanation methods. The paper also provides specific evaluation methods for different aspects of user performance.<details>
<summary>Abstract</summary>
Evaluating the efficiency of human-AI interactions is challenging, including subjective and objective quality aspects. With the focus on the human experience of the explanations, evaluations of explanation methods have become mostly subjective, making comparative evaluations almost impossible and highly linked to the individual user. However, it is commonly agreed that one aspect of explanation quality is how effectively the user can detect if the predictions are trustworthy and correct, i.e., if the explanations can increase the user's appropriate trust in the model. This paper starts with the definitions of appropriate trust from the literature. It compares the definitions with model performance evaluation, showing the strong similarities between appropriate trust and model performance evaluation. The paper's main contribution is a novel approach to evaluating appropriate trust by taking advantage of the likenesses between definitions. The paper offers several straightforward evaluation methods for different aspects of user performance, including suggesting a method for measuring uncertainty and appropriate trust in regression.
</details>
<details>
<summary>摘要</summary>
评估人类-AI交互的效率具有挑战性，包括主观和客观质量方面。因为注重人类解释的经验，评估解释方法的评价倾向于主观，使对比评价变得各异不同，高度受用户个人影响。然而，通常认为一个解释质量的重要方面是否能让用户正确地判断预测结果的可靠性和正确性，即是否能够提高用户对模型的适当信任。这篇论文从文献中定义了适当信任的定义，并与模型性能评估进行比较，显示了这两者之间的强相似性。本文的主要贡献是一种新的适当信任评估方法，利用定义之间的相似性。文章还提供了不同方面的用户性能评估方法，包括用于推荐和回归中的不确定性和适当信任评估方法。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Recover-for-Safe-Reinforcement-Learning"><a href="#Learning-to-Recover-for-Safe-Reinforcement-Learning" class="headerlink" title="Learning to Recover for Safe Reinforcement Learning"></a>Learning to Recover for Safe Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11907">http://arxiv.org/abs/2309.11907</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoyu Wang, Xin Yuan, Qinqing Ren<br>for: 这种研究旨在实现安全的学习控制，以及在复杂环境中自动生成安全约束。methods: 提议了一种三个阶段架构，称为TU-Recovery架构，包括安全评估和恢复策略的学习。results: 实验表明，TU-Recovery在约束遵从和约束违反两个方面都有优于不受约束的对照组，并且 auxiliary reward 可以进一步提高TU-Recovery的奖励至比例。<details>
<summary>Abstract</summary>
Safety controllers is widely used to achieve safe reinforcement learning. Most methods that apply a safety controller are using handcrafted safety constraints to construct the safety controller. However, when the environment dynamics are sophisticated, handcrafted safety constraints become unavailable. Therefore, it worth to research on constructing safety controllers by learning algorithms. We propose a three-stage architecture for safe reinforcement learning, namely TU-Recovery Architecture. A safety critic and a recovery policy is learned before task training. They form a safety controller to ensure safety in task training. Then a phenomenon induced by disagreement between task policy and recovery policy, called adversarial phenomenon, which reduces learning efficiency and model performance, is described. Auxiliary reward is proposed to mitigate adversarial phenomenon, while help the task policy to learn to recover from high-risk states. A series of experiments are conducted in a robot navigation environment. Experiments demonstrate that TU-Recovery outperforms unconstrained counterpart in both reward gaining and constraint violations during task training, and auxiliary reward further improve TU-Recovery in reward-to-cost ratio by significantly reduce constraint violations.
</details>
<details>
<summary>摘要</summary>
安全控制器广泛应用于安全返回学习，大多数方法都使用手工安全限制构建安全控制器。然而，当环境动力较复杂时，手工安全限制变得无效。因此，研究构建基于学习算法的安全控制器是有优势的。我们提出了三阶 Architecture for Safe Reinforcement Learning，称为TU-Recovery Architecture。在任务训练之前，一个安全评价器和一个恢复策略被学习出来，它们组成一个安全控制器，确保任务训练中的安全性。然后，一种由任务策略和恢复策略的不一致引起的现象，称为对抗现象，这会降低学习效率和模型性能。为了 Mitigate this phenomenon, an auxiliary reward is proposed to help the task policy learn to recover from high-risk states.在一个机器人导航环境中，我们进行了一系列实验，结果表明，TU-Recovery在增加奖励和限制违反时比无限制版本表现更好，并且 auxiliary reward 可以再加强 TU-Recovery 的奖励比例。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Unlocking-the-Heart-Using-Adaptive-Locked-Agnostic-Networks"><a href="#Unlocking-the-Heart-Using-Adaptive-Locked-Agnostic-Networks" class="headerlink" title="Unlocking the Heart Using Adaptive Locked Agnostic Networks"></a>Unlocking the Heart Using Adaptive Locked Agnostic Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11899">http://arxiv.org/abs/2309.11899</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/AstraZeneca/UnlockingHeart">https://github.com/AstraZeneca/UnlockingHeart</a></li>
<li>paper_authors: Sylwia Majchrowska, Anders Hildeman, Philip Teare, Tom Diethe</li>
<li>For: The paper is written for medical imaging applications, specifically for echocardiography datasets.* Methods: The paper introduces the Adaptive Locked Agnostic Network (ALAN) method, which uses self-supervised visual feature extraction and a large backbone model to produce anatomically robust semantic self-segmentation.* Results: The paper demonstrates that the self-supervised backbone model robustly identifies anatomical subregions of the heart in an apical four-chamber view, and then uses these features to design two downstream models for segmenting a target anatomical region and echocardiogram view classification.Here’s the Chinese translation of the three points:* For: 这篇论文是为医疗影像应用而写的，特别是为echocardiography datasets。* Methods: 论文介绍了Adaptive Locked Agnostic Network (ALAN)方法，该方法使用自动启动的视觉特征提取和大型后处理模型来生成医学上Robust的semantic自 Segmentation。* Results: 论文表明，自动启动后处理模型可以强健地识别心脏四室视图中的 анатомичеSUBregion。然后，通过使用这些特征，设计了两个下游模型，一个用于目标 анаatomical区域分割，另一个用于echo cardiogram视图分类。<details>
<summary>Abstract</summary>
Supervised training of deep learning models for medical imaging applications requires a significant amount of labeled data. This is posing a challenge as the images are required to be annotated by medical professionals. To address this limitation, we introduce the Adaptive Locked Agnostic Network (ALAN), a concept involving self-supervised visual feature extraction using a large backbone model to produce anatomically robust semantic self-segmentation. In the ALAN methodology, this self-supervised training occurs only once on a large and diverse dataset. Due to the intuitive interpretability of the segmentation, downstream models tailored for specific tasks can be easily designed using white-box models with few parameters. This, in turn, opens up the possibility of communicating the inner workings of a model with domain experts and introducing prior knowledge into it. It also means that the downstream models become less data-hungry compared to fully supervised approaches. These characteristics make ALAN particularly well-suited for resource-scarce scenarios, such as costly clinical trials and rare diseases. In this paper, we apply the ALAN approach to three publicly available echocardiography datasets: EchoNet-Dynamic, CAMUS, and TMED-2. Our findings demonstrate that the self-supervised backbone model robustly identifies anatomical subregions of the heart in an apical four-chamber view. Building upon this, we design two downstream models, one for segmenting a target anatomical region, and a second for echocardiogram view classification.
</details>
<details>
<summary>摘要</summary>
超vised学习深度学习模型用于医学成像应用需要一定量的标注数据。然而，获取标注数据具有挑战，因为图像需要由医疗专业人员进行标注。为解决这个限制，我们介绍了自适应锁定不可知数网络（ALAN）。ALAN方法包括使用大型后向模型进行自主超vised视觉特征提取，以生成可靠的各种生物marker。在ALAN方法中，这种自主超vised训练只需在一个大型和多样化的数据集上进行一次。由于分割结果具有直观可读性，可以使用白盒模型并少量参数来设计下游模型。这种特点使得ALAN在资源匮乏的enario下具有优势，如costly临床试验和罕见疾病。在这篇论文中，我们运用ALAN方法于三个公共可用的echocardiography数据集：EchoNet-Dynamic、CAMUS和TMED-2。我们的发现表明，自适应锁定不可知数网络可以在Apical四室视图中稳定地标识心脏的各种生物marker。基于这种成果，我们设计了两个下游模型：一个用于标识目标生物区域，另一个用于echocardiogram视图分类。
</details></li>
</ul>
<hr>
<h2 id="MiChao-HuaFen-1-0-A-Specialized-Pre-trained-Corpus-Dataset-for-Domain-specific-Large-Models"><a href="#MiChao-HuaFen-1-0-A-Specialized-Pre-trained-Corpus-Dataset-for-Domain-specific-Large-Models" class="headerlink" title="MiChao-HuaFen 1.0: A Specialized Pre-trained Corpus Dataset for Domain-specific Large Models"></a>MiChao-HuaFen 1.0: A Specialized Pre-trained Corpus Dataset for Domain-specific Large Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13079">http://arxiv.org/abs/2309.13079</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yidong Liu, FuKai Shang, Fang Wang, Rui Xu, Jun Wang, Wei Li, Yao Li, Conghui He</li>
<li>for: 这篇论文旨在为特定领域（如医疗、法律、金融等）提供高质量、域specific的输出，以满足各个领域的需求。</li>
<li>methods: 该论文首先评估了现有的大型模型在专业领域的表现，并讨论了这些模型的限制。然后，该论文提出了一个名为“MiChao-HuaFen 1.0”的预训练数据集，专门为新闻和政府部门提供。这个数据集来自于2022年公开available的互联网数据，经过多轮净化和处理，以确保高质量和可靠的来源。</li>
<li>results: 该论文通过预训练大型模型在中文垂直领域中表现出色，并为深度学习研究和应用在相关领域提供了支持。<details>
<summary>Abstract</summary>
With the advancement of deep learning technologies, general-purpose large models such as GPT-4 have demonstrated exceptional capabilities across various domains. Nevertheless, there remains a demand for high-quality, domain-specific outputs in areas like healthcare, law, and finance. This paper first evaluates the existing large models for specialized domains and discusses their limitations. To cater to the specific needs of certain domains, we introduce the ``MiChao-HuaFen 1.0'' pre-trained corpus dataset, tailored for the news and governmental sectors. The dataset, sourced from publicly available internet data from 2022, underwent multiple rounds of cleansing and processing to ensure high quality and reliable origins, with provisions for consistent and stable updates. This dataset not only supports the pre-training of large models for Chinese vertical domains but also aids in propelling deep learning research and applications in related fields.
</details>
<details>
<summary>摘要</summary>
随着深度学习技术的发展，通用大型模型如GPT-4已经表现出色在各个领域。然而，仍然存在特定领域的高质量、域专输出的需求，如医疗、法律和金融等。这篇论文首先评估了现有的域专大型模型，并讨论了它们的限制。为了满足特定领域的需求，我们介绍了“微超花均1.0”预训练数据集，专门为新闻和政府部门设计。这个数据集来自于2022年公开available的互联网数据，经过多 rondas of 清洁和处理，以确保高质量和可靠的来源，并提供了一系列的常规和稳定的更新。这个数据集不仅支持中文垂直领域的大型模型的预训练，还可以推动深度学习研究和应用在相关领域。
</details></li>
</ul>
<hr>
<h2 id="Audio-Contrastive-based-Fine-tuning"><a href="#Audio-Contrastive-based-Fine-tuning" class="headerlink" title="Audio Contrastive based Fine-tuning"></a>Audio Contrastive based Fine-tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11895">http://arxiv.org/abs/2309.11895</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Wang, Qibin Liang, Chenghao Xiao, Yizhi Li, Noura Al Moubayed, Chenghua Lin</li>
<li>for: Audio classification tasks with a wide range of applications, such as speech and sound processing.</li>
<li>methods:  contrastive learning, fine-tuning.</li>
<li>results:  state-of-the-art results in various settings, robust generalisability.Here’s the full text in Simplified Chinese:for: Audio classification tasks with a wide range of applications, such as speech and sound processing.methods: contrastive learning, fine-tuning.results: state-of-the-art results in various settings, robust generalisability.<details>
<summary>Abstract</summary>
Audio classification plays a crucial role in speech and sound processing tasks with a wide range of applications. There still remains a challenge of striking the right balance between fitting the model to the training data (avoiding overfitting) and enabling it to generalise well to a new domain. Leveraging the transferability of contrastive learning, we introduce Audio Contrastive-based Fine-tuning (AudioConFit), an efficient approach characterised by robust generalisability. Empirical experiments on a variety of audio classification tasks demonstrate the effectiveness and robustness of our approach, which achieves state-of-the-art results in various settings.
</details>
<details>
<summary>摘要</summary>
Audio分类在语音和声音处理任务中扮演着重要角色，它在各种应用领域中具有广泛的应用前景。然而，模型适应训练数据的问题仍然存在，即避免过拟合。我们利用对比学习的转移性，提出了Audio Contrastive-based Fine-tuning（AudioConFit）方法，具有良好的抗抗销性。经验测试表明，我们的方法在多种Audio分类任务中具有出色的效果和稳定性，达到了不同设置下的状态体现。
</details></li>
</ul>
<hr>
<h2 id="A-Knowledge-Driven-Cross-view-Contrastive-Learning-for-EEG-Representation"><a href="#A-Knowledge-Driven-Cross-view-Contrastive-Learning-for-EEG-Representation" class="headerlink" title="A Knowledge-Driven Cross-view Contrastive Learning for EEG Representation"></a>A Knowledge-Driven Cross-view Contrastive Learning for EEG Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03747">http://arxiv.org/abs/2310.03747</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weining Weng, Yang Gu, Qihui Zhang, Yingying Huang, Chunyan Miao, Yiqiang Chen</li>
<li>for: This paper is written for researchers and practitioners working with electroencephalogram (EEG) signals and deep learning methods, particularly those interested in developing supervised learning methods for EEG signals with limited labels.</li>
<li>methods: The paper proposes a knowledge-driven cross-view contrastive learning framework (KDC2) that integrates neurological theory to extract effective representations from EEG signals with limited labels. The KDC2 method creates scalp and neural views of EEG signals, simulating the internal and external representation of brain activity, and uses inter-view and cross-view contrastive learning pipelines in combination with various augmentation methods to capture neural features from different views.</li>
<li>results: The experimental results on different downstream tasks demonstrate that the proposed method outperforms state-of-the-art methods, highlighting the superior generalization of neural knowledge-supported EEG representations across various brain tasks.<details>
<summary>Abstract</summary>
Due to the abundant neurophysiological information in the electroencephalogram (EEG) signal, EEG signals integrated with deep learning methods have gained substantial traction across numerous real-world tasks. However, the development of supervised learning methods based on EEG signals has been hindered by the high cost and significant label discrepancies to manually label large-scale EEG datasets. Self-supervised frameworks are adopted in vision and language fields to solve this issue, but the lack of EEG-specific theoretical foundations hampers their applicability across various tasks. To solve these challenges, this paper proposes a knowledge-driven cross-view contrastive learning framework (KDC2), which integrates neurological theory to extract effective representations from EEG with limited labels. The KDC2 method creates scalp and neural views of EEG signals, simulating the internal and external representation of brain activity. Sequentially, inter-view and cross-view contrastive learning pipelines in combination with various augmentation methods are applied to capture neural features from different views. By modeling prior neural knowledge based on homologous neural information consistency theory, the proposed method extracts invariant and complementary neural knowledge to generate combined representations. Experimental results on different downstream tasks demonstrate that our method outperforms state-of-the-art methods, highlighting the superior generalization of neural knowledge-supported EEG representations across various brain tasks.
</details>
<details>
<summary>摘要</summary>
因为电энце法测试（EEG）信号具有庞大的神经生物学信息，因此EEG信号与深度学习方法的结合在许多实际任务中得到了广泛的应用。然而，基于EEG信号的指导学习方法的发展受到了大量标签数据手动标注的高成本和标签差异的限制。在视觉和语言领域中采用了自动标注框架，但是由于EEG信号的特殊性，这些框架在不同任务中的应用受到了限制。为解决这些挑战，本文提出了基于知识驱动的跨视图对比学习框架（KDC2），该框架通过神经生物学理论提取EEG信号中有效的表示。KDC2方法创建了脊梁和神经视图的EEG信号，模拟内部和外部的脑动力表示。然后，在不同视图之间和跨视图之间，应用了多种扩展方法，以捕捉不同视图中的神经特征。通过基于同源神经信息一致理论模型尽可能多的先验知识，提出的方法提取了不变和补充的神经知识，生成了组合表示。实验结果表明，我们的方法在不同下游任务中的表现优于状态之前的方法，highlighting the superior generalization of neural knowledge-supported EEG representations across various brain tasks.
</details></li>
</ul>
<hr>
<h2 id="Multi-level-Asymmetric-Contrastive-Learning-for-Medical-Image-Segmentation-Pre-training"><a href="#Multi-level-Asymmetric-Contrastive-Learning-for-Medical-Image-Segmentation-Pre-training" class="headerlink" title="Multi-level Asymmetric Contrastive Learning for Medical Image Segmentation Pre-training"></a>Multi-level Asymmetric Contrastive Learning for Medical Image Segmentation Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11876">http://arxiv.org/abs/2309.11876</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuang Zeng, Lei Zhu, Xinliang Zhang, Zifeng Tian, Qian Chen, Lujia Jin, Jiayi Wang, Yanye Lu</li>
<li>for: 这个研究旨在提出一个新的对称对抗学习框架（JCL），用于医疗影像分类。</li>
<li>methods: 这个框架使用了一个新的对称对抗学习策略，同时预训 Both encoder和decoder，以提供更好的初始化 для分类模型。另外，一个多层对抗损失函数被设计来考虑对于特征层、影像层和像素层的对应，以确保encoder和decoder在预训过程中学习多层表示。</li>
<li>results: 在多个医疗影像数据集上进行了实验，结果显示了我们的JCL框架比现有的SOTA对抗学习策略更好。<details>
<summary>Abstract</summary>
Contrastive learning, which is a powerful technique for learning image-level representations from unlabeled data, leads a promising direction to dealing with the dilemma between large-scale pre-training and limited labeled data. However, most existing contrastive learning strategies are designed mainly for downstream tasks of natural images, therefore they are sub-optimal and even worse than learning from scratch when directly applied to medical images whose downstream tasks are usually segmentation. In this work, we propose a novel asymmetric contrastive learning framework named JCL for medical image segmentation with self-supervised pre-training. Specifically, (1) A novel asymmetric contrastive learning strategy is proposed to pre-train both encoder and decoder simultaneously in one-stage to provide better initialization for segmentation models. (2) A multi-level contrastive loss is designed to take the correspondence among feature-level, image-level and pixel-level projections, respectively into account to make sure multi-level representations can be learned by the encoder and decoder during pre-training. (3) Experiments on multiple medical image datasets indicate our JCL framework outperforms existing SOTA contrastive learning strategies.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXTcontrastive learning, which is a powerful technique for learning image-level representations from unlabeled data, leads a promising direction to dealing with the dilemma between large-scale pre-training and limited labeled data. However, most existing contrastive learning strategies are designed mainly for downstream tasks of natural images, therefore they are sub-optimal and even worse than learning from scratch when directly applied to medical images whose downstream tasks are usually segmentation. In this work, we propose a novel asymmetric contrastive learning framework named JCL for medical image segmentation with self-supervised pre-training. Specifically, (1) A novel asymmetric contrastive learning strategy is proposed to pre-train both encoder and decoder simultaneously in one-stage to provide better initialization for segmentation models. (2) A multi-level contrastive loss is designed to take the correspondence among feature-level, image-level and pixel-level projections, respectively into account to make sure multi-level representations can be learned by the encoder and decoder during pre-training. (3) Experiments on multiple medical image datasets indicate our JCL framework outperforms existing SOTA contrastive learning strategies.TRANSLATE_TEXT
</details></li>
</ul>
<hr>
<h2 id="Stochastic-stiffness-identification-and-response-estimation-of-Timoshenko-beams-via-physics-informed-Gaussian-processes"><a href="#Stochastic-stiffness-identification-and-response-estimation-of-Timoshenko-beams-via-physics-informed-Gaussian-processes" class="headerlink" title="Stochastic stiffness identification and response estimation of Timoshenko beams via physics-informed Gaussian processes"></a>Stochastic stiffness identification and response estimation of Timoshenko beams via physics-informed Gaussian processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11875">http://arxiv.org/abs/2309.11875</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gledsonrt/pigptimoshenkobeam">https://github.com/gledsonrt/pigptimoshenkobeam</a></li>
<li>paper_authors: Gledson Rodrigo Tondo, Sebastian Rau, Igor Kavrakov, Guido Morgenthal</li>
<li>For: 这篇论文是用来描述一种基于机器学习的结构健康监测系统，用于结构参数Identification和结构回归预测。* Methods: 该论文使用了一种基于 Gaussian Process（GP）模型的physics-informed机器学习模型，使用多输出GP模型来描述Timoshenko beam元件的运动、弯 curvature、应力、负荷等参数。使用bayesian方式进行模型优化，通过Markov chain Monte Carlo方法来最大化 posterior模型。* Results: 该论文通过实验 validate了其模型，并 demonstarted that the proposed approach is effective at identifying structural parameters and is capable of fusing data from heterogeneous and multi-fidelity sensors. probabilistic predictions of structural responses and internal forces are in closer agreement with measured data.<details>
<summary>Abstract</summary>
Machine learning models trained with structural health monitoring data have become a powerful tool for system identification. This paper presents a physics-informed Gaussian process (GP) model for Timoshenko beam elements. The model is constructed as a multi-output GP with covariance and cross-covariance kernels analytically derived based on the differential equations for deflections, rotations, strains, bending moments, shear forces and applied loads. Stiffness identification is performed in a Bayesian format by maximising a posterior model through a Markov chain Monte Carlo method, yielding a stochastic model for the structural parameters. The optimised GP model is further employed for probabilistic predictions of unobserved responses. Additionally, an entropy-based method for physics-informed sensor placement optimisation is presented, exploiting heterogeneous sensor position information and structural boundary conditions built into the GP model. Results demonstrate that the proposed approach is effective at identifying structural parameters and is capable of fusing data from heterogeneous and multi-fidelity sensors. Probabilistic predictions of structural responses and internal forces are in closer agreement with measured data. We validate our model with an experimental setup and discuss the quality and uncertainty of the obtained results. The proposed approach has potential applications in the field of structural health monitoring (SHM) for both mechanical and structural systems.
</details>
<details>
<summary>摘要</summary>
机器学习模型使用结构健康监测数据变得了一种强大的系统识别工具。这篇论文提出了一种基于Timoshenko梁元件的物理学报GP模型。该模型通过分析差分方程来DERIVE covariance和交叉covariancekernel，并在Bayesian格式下通过Markov链 Monte Carlo方法进行弹性模型化。通过最大化 posterior模型，实现了结构参数的逻辑IDENTIFICATION。furthermore, the proposed approach is capable of fusing data from heterogeneous and multi-fidelity sensors, and provides probabilistic predictions of unobserved responses. The results show that the proposed approach is effective in identifying structural parameters and provides more accurate predictions of structural responses and internal forces. We validate the model with an experimental setup and discuss the quality and uncertainty of the obtained results. The proposed approach has potential applications in the field of structural health monitoring (SHM) for both mechanical and structural systems.Note: Please note that the translation is in Simplified Chinese, and the grammar and sentence structure may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="OSNet-MNetO-Two-Types-of-General-Reconstruction-Architectures-for-Linear-Computed-Tomography-in-Multi-Scenarios"><a href="#OSNet-MNetO-Two-Types-of-General-Reconstruction-Architectures-for-Linear-Computed-Tomography-in-Multi-Scenarios" class="headerlink" title="OSNet &amp; MNetO: Two Types of General Reconstruction Architectures for Linear Computed Tomography in Multi-Scenarios"></a>OSNet &amp; MNetO: Two Types of General Reconstruction Architectures for Linear Computed Tomography in Multi-Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11858">http://arxiv.org/abs/2309.11858</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhisheng Wang, Zihan Deng, Fenglin Liu, Yixing Huang, Haijun Yu, Junning Cui</li>
<li>For:  This paper proposes two novel reconstruction architectures for linear computed tomography (LCT) systems to weaken projection truncation and image the region of interest (ROI).* Methods: The proposed methods use backprojection filtration (BPF) and two types of reconstruction architectures, Overlay-Single Network (OSNet) and Multiple Networks Overlaying (MNetO), to achieve stable interior reconstruction and avoid rotation operations of Hilbert filtering.* Results: Experimental results show that the proposed methods can both recover images, and OSNet outperforms BPF in various scenarios. Additionally, ST-pix2pixGAN is superior to pix2pixGAN and CycleGAN, and MNetO exhibits a few artifacts due to the differences among the multiple models.Here is the simplified Chinese text:* 为：这篇论文提出了两种新的重构架构来弱化投影截断和图像区域 интереса（ROI） для线性 computed tomography（LCT）系统。* 方法：提出的方法使用了投影筛选（BPF）和两种重构架构：重叠单网络（OSNet）和多网络叠加（MNetO），以实现稳定的内部重构和避免希尔贝特滤波的旋转操作。* 结果：实验结果表明，提出的方法都可以重建图像，并且OSNet在多种场景中都超过BPF表现。此外，ST-pix2pixGAN比pix2pixGAN和CycleGAN更佳，MNetO因多个模型之间的差异而具有一些瑕疵。<details>
<summary>Abstract</summary>
Recently, linear computed tomography (LCT) systems have actively attracted attention. To weaken projection truncation and image the region of interest (ROI) for LCT, the backprojection filtration (BPF) algorithm is an effective solution. However, in BPF for LCT, it is difficult to achieve stable interior reconstruction, and for differentiated backprojection (DBP) images of LCT, multiple rotation-finite inversion of Hilbert transform (Hilbert filtering)-inverse rotation operations will blur the image. To satisfy multiple reconstruction scenarios for LCT, including interior ROI, complete object, and exterior region beyond field-of-view (FOV), and avoid the rotation operations of Hilbert filtering, we propose two types of reconstruction architectures. The first overlays multiple DBP images to obtain a complete DBP image, then uses a network to learn the overlying Hilbert filtering function, referred to as the Overlay-Single Network (OSNet). The second uses multiple networks to train different directional Hilbert filtering models for DBP images of multiple linear scannings, respectively, and then overlays the reconstructed results, i.e., Multiple Networks Overlaying (MNetO). In two architectures, we introduce a Swin Transformer (ST) block to the generator of pix2pixGAN to extract both local and global features from DBP images at the same time. We investigate two architectures from different networks, FOV sizes, pixel sizes, number of projections, geometric magnification, and processing time. Experimental results show that two architectures can both recover images. OSNet outperforms BPF in various scenarios. For the different networks, ST-pix2pixGAN is superior to pix2pixGAN and CycleGAN. MNetO exhibits a few artifacts due to the differences among the multiple models, but any one of its models is suitable for imaging the exterior edge in a certain direction.
</details>
<details>
<summary>摘要</summary>
近些时候，线性计算 Tomatoesography（LCT）系统已经吸引了广泛的关注。为了减弱投影 truncation 并图像区域内 interest（ROI） для LCT，backprojection filtration（BPF）算法是一种有效的解决方案。然而，在 BPF 中，实现稳定的内部重建很难，而且对于 differentiated backprojection（DBP）图像的 LCT，多个旋转-有限倒散 transform（Hilbert filtering）- inverse rotation 操作会模糊图像。为满足 LCT 多种重建enario，包括内部 ROI、完整的物体和外部区域 beyond field-of-view（FOV），并避免 Hilbert filtering 的旋转操作，我们提出了两种重建架构。第一种是将多个 DBP 图像 overlay 成一个完整的 DBP 图像，然后使用一个网络学习 overlaying  Hilbert filtering 函数，称为 Overlay-Single Network（OSNet）。第二种是使用多个网络在不同的旋转下对 DBP 图像进行不同的方向性 Hilbert filtering 模型训练，然后 overlay 得到的重建结果，称为 Multiple Networks Overlaying（MNetO）。在两种架构中，我们在 pix2pixGAN 生成器中引入了 Swin Transformer（ST）块，以同时提取 DBP 图像的局部和全局特征。我们从不同的网络、FOV 大小、像素大小、数据量、几何倍化和处理时间等方面进行了调查。实验结果表明，两种架构都可以重建图像。OSNet 在多种enario 中表现出色，比 BPF 更高效。在不同的网络方面，ST-pix2pixGAN 高于 pix2pixGAN 和 CycleGAN。MNetO 因多个模型之间的差异而存在一些瑕疵，但任一个模型都适用于在某个方向上图像外部边缘的重建。
</details></li>
</ul>
<hr>
<h2 id="BitCoin-Bidirectional-Tagging-and-Supervised-Contrastive-Learning-based-Joint-Relational-Triple-Extraction-Framework"><a href="#BitCoin-Bidirectional-Tagging-and-Supervised-Contrastive-Learning-based-Joint-Relational-Triple-Extraction-Framework" class="headerlink" title="BitCoin: Bidirectional Tagging and Supervised Contrastive Learning based Joint Relational Triple Extraction Framework"></a>BitCoin: Bidirectional Tagging and Supervised Contrastive Learning based Joint Relational Triple Extraction Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11853">http://arxiv.org/abs/2309.11853</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luyao He, Zhongbao Zhang, Sen Su, Yuxin Chen</li>
<li>for: 提高relation triple extraction（RTE）任务的精度和效率，并解决现有方法的一些局限性。</li>
<li>methods: 提出了一种基于标签和监督contrastive学习的bidirectional triple extraction框架，并实现了标签在两个方向的执行，以便从主语到谓语和谓语到主语中提取关系 triples。</li>
<li>results: 在标准数据集上达到了state-of-the-art的result，并在不同类型的任务中显著提高了F1分数，包括Normal、SEO、EPO和多个关系提取任务。<details>
<summary>Abstract</summary>
Relation triple extraction (RTE) is an essential task in information extraction and knowledge graph construction. Despite recent advancements, existing methods still exhibit certain limitations. They just employ generalized pre-trained models and do not consider the specificity of RTE tasks. Moreover, existing tagging-based approaches typically decompose the RTE task into two subtasks, initially identifying subjects and subsequently identifying objects and relations. They solely focus on extracting relational triples from subject to object, neglecting that once the extraction of a subject fails, it fails in extracting all triples associated with that subject. To address these issues, we propose BitCoin, an innovative Bidirectional tagging and supervised Contrastive learning based joint relational triple extraction framework. Specifically, we design a supervised contrastive learning method that considers multiple positives per anchor rather than restricting it to just one positive. Furthermore, a penalty term is introduced to prevent excessive similarity between the subject and object. Our framework implements taggers in two directions, enabling triples extraction from subject to object and object to subject. Experimental results show that BitCoin achieves state-of-the-art results on the benchmark datasets and significantly improves the F1 score on Normal, SEO, EPO, and multiple relation extraction tasks.
</details>
<details>
<summary>摘要</summary>
信息提取和知识图构建中的关系 triple 提取（RTE）是一项重要任务。尽管最近有所进步，现有的方法仍然存在一些局限性。它们通常使用通用预训练模型，不考虑RTE任务的特殊性。此外，现有的标记 Based 方法通常将RTE任务分解为两个子任务，先 identific 主题，然后 identific 对象和关系。它们仅ocus on从主题到对象中提取关系 triple，忽略了如果提取主题失败，那么所有与该主题相关的 triple 都将难以提取。为了解决这些问题，我们提出了 BitCoin，一种创新的双向标记和监督对比学习基于的关系 triple 提取框架。具体来说，我们设计了一种监督对比学习方法，可以考虑多个正例而不是仅仅 restricting 到一个正例。此外，我们引入了一个罚 terme 来防止主题和对象之间的过度相似性。我们的框架实现了两个方向的标记，即从主题到对象和从对象到主题，以便提取关系 triple。实验结果表明，BitCoin在标准 benchmark 数据集上实现了当前最佳Result 和显著提高了Normal、SEO、EPO 和多个关系提取任务的 F1 分数。
</details></li>
</ul>
<hr>
<h2 id="How-Prevalent-is-Gender-Bias-in-ChatGPT-–-Exploring-German-and-English-ChatGPT-Responses"><a href="#How-Prevalent-is-Gender-Bias-in-ChatGPT-–-Exploring-German-and-English-ChatGPT-Responses" class="headerlink" title="How Prevalent is Gender Bias in ChatGPT? – Exploring German and English ChatGPT Responses"></a>How Prevalent is Gender Bias in ChatGPT? – Exploring German and English ChatGPT Responses</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03031">http://arxiv.org/abs/2310.03031</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Ognatai/bias_chatGPT">https://github.com/Ognatai/bias_chatGPT</a></li>
<li>paper_authors: Stefanie Urchs, Veronika Thurner, Matthias Aßenmacher, Christian Heumann, Stephanie Thiemichen</li>
<li>for: 这个论文旨在探讨OpenAI的ChatGPT语言模型如何帮助非技术用户创作日常工作中的文本，以及该模型的局限性和偏见问题。</li>
<li>methods: 该论文采用系统性的分析方法，对提示和生成的答案进行了深入的检查和分析，以找出可能存在的偏见问题。</li>
<li>results: 研究发现，ChatGPT可以帮助非技术用户创作文本，但是需要仔细检查系统的答案以避免偏见和语法错误。<details>
<summary>Abstract</summary>
With the introduction of ChatGPT, OpenAI made large language models (LLM) accessible to users with limited IT expertise. However, users with no background in natural language processing (NLP) might lack a proper understanding of LLMs. Thus the awareness of their inherent limitations, and therefore will take the systems' output at face value. In this paper, we systematically analyse prompts and the generated responses to identify possible problematic issues with a special focus on gender biases, which users need to be aware of when processing the system's output. We explore how ChatGPT reacts in English and German if prompted to answer from a female, male, or neutral perspective. In an in-depth investigation, we examine selected prompts and analyse to what extent responses differ if the system is prompted several times in an identical way. On this basis, we show that ChatGPT is indeed useful for helping non-IT users draft texts for their daily work. However, it is absolutely crucial to thoroughly check the system's responses for biases as well as for syntactic and grammatical mistakes.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Evaluating-Large-Language-Models-for-Document-grounded-Response-Generation-in-Information-Seeking-Dialogues"><a href="#Evaluating-Large-Language-Models-for-Document-grounded-Response-Generation-in-Information-Seeking-Dialogues" class="headerlink" title="Evaluating Large Language Models for Document-grounded Response Generation in Information-Seeking Dialogues"></a>Evaluating Large Language Models for Document-grounded Response Generation in Information-Seeking Dialogues</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11838">http://arxiv.org/abs/2309.11838</a></li>
<li>repo_url: None</li>
<li>paper_authors: Norbert Braunschweiler, Rama Doddipatla, Simon Keizer, Svetlana Stoyanchev</li>
<li>for: 这个论文 investigate了使用大型自然语言模型（LLMs）如ChatGPT来进行基于文档的回答生成在信息寻求对话中。</li>
<li>methods: 作者使用了两种方法：ChatCompletion和LlamaIndex。ChatCompletion使用了ChatGPT模型的知识，而LlamaIndex同时提取了文档中相关信息。</li>
<li>results: 观察到文档基于LLMs无法准确地评估回答生成，因为它们更加具有描述性。因此，作者进行了人工评估，评估 Shared Task 赛事获奖系统、ChatGPT两种变体的输出以及人类回答。结果显示，ChatGPT变体的输出被评估高于Shared Task 赛事获奖系统和人类回答。<details>
<summary>Abstract</summary>
In this paper, we investigate the use of large language models (LLMs) like ChatGPT for document-grounded response generation in the context of information-seeking dialogues. For evaluation, we use the MultiDoc2Dial corpus of task-oriented dialogues in four social service domains previously used in the DialDoc 2022 Shared Task. Information-seeking dialogue turns are grounded in multiple documents providing relevant information. We generate dialogue completion responses by prompting a ChatGPT model, using two methods: Chat-Completion and LlamaIndex. ChatCompletion uses knowledge from ChatGPT model pretraining while LlamaIndex also extracts relevant information from documents. Observing that document-grounded response generation via LLMs cannot be adequately assessed by automatic evaluation metrics as they are significantly more verbose, we perform a human evaluation where annotators rate the output of the shared task winning system, the two Chat-GPT variants outputs, and human responses. While both ChatGPT variants are more likely to include information not present in the relevant segments, possibly including a presence of hallucinations, they are rated higher than both the shared task winning system and human responses.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了大语言模型（LLM）如ChatGPT在信息寻求对话中的回答生成。为评估，我们使用了MultiDoc2Dial词汇对话集，这是四个社会服务领域的任务对话集，已经在DialDoc 2022共同任务中使用。信息寻求对话转帖是基于多份文档提供相关信息。我们使用两种方法生成对话完成响应：ChatCompletion和LlamaIndex。ChatCompletion利用ChatGPT模型的先验知识，而LlamaIndex同时从文档中提取有用信息。由于文档基于的回答生成无法准确地评估，我们进行了人工评估，评估共同任务赢家系统、ChatGPT两种变体的输出以及人类回答。结果显示，两种ChatGPT变体的输出被评估高于共同任务赢家系统和人类回答。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Transformers-for-Wireless-Communications-A-Case-Study-in-Beam-Prediction"><a href="#Multimodal-Transformers-for-Wireless-Communications-A-Case-Study-in-Beam-Prediction" class="headerlink" title="Multimodal Transformers for Wireless Communications: A Case Study in Beam Prediction"></a>Multimodal Transformers for Wireless Communications: A Case Study in Beam Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11811">http://arxiv.org/abs/2309.11811</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/itu-ai-ml-in-5g-challenge/deepsense6g_tii">https://github.com/itu-ai-ml-in-5g-challenge/deepsense6g_tii</a></li>
<li>paper_authors: Yu Tian, Qiyang Zhao, Zine el abidine Kherroubi, Fouzi Boukhalfa, Kebin Wu, Faouzi Bader</li>
<li>For: 这个论文目的是为了提高无线通讯中高频率带的焦点管理，使用多modal的感知信息，包括相机、LiDAR、激光和GPS。* Methods: 这个论文使用多modal的transformer深度学习框架，将影像、点云、激光原始数据作为时间序列中的数据，使用卷积神经网提取特征，然后使用transformer核心来学习不同模式之间的隐藏关系，生成下一个层的特征提取。* Results: 这个论文的实验结果显示，使用影像和GPS数据训练的解析器，可以在78.44%的精度下预测焦点，并且具有优秀的泛化能力，在未见日情况下的73%和夜情况下的84%。这比使用其他模式和随机处理技术更好，显示了transformer具有组合特征的优秀表现在无线电波预测中。<details>
<summary>Abstract</summary>
Wireless communications at high-frequency bands with large antenna arrays face challenges in beam management, which can potentially be improved by multimodality sensing information from cameras, LiDAR, radar, and GPS. In this paper, we present a multimodal transformer deep learning framework for sensing-assisted beam prediction. We employ a convolutional neural network to extract the features from a sequence of images, point clouds, and radar raw data sampled over time. At each convolutional layer, we use transformer encoders to learn the hidden relations between feature tokens from different modalities and time instances over abstraction space and produce encoded vectors for the next-level feature extraction. We train the model on a combination of different modalities with supervised learning. We try to enhance the model over imbalanced data by utilizing focal loss and exponential moving average. We also evaluate data processing and augmentation techniques such as image enhancement, segmentation, background filtering, multimodal data flipping, radar signal transformation, and GPS angle calibration. Experimental results show that our solution trained on image and GPS data produces the best distance-based accuracy of predicted beams at 78.44%, with effective generalization to unseen day scenarios near 73% and night scenarios over 84%. This outperforms using other modalities and arbitrary data processing techniques, which demonstrates the effectiveness of transformers with feature fusion in performing radio beam prediction from images and GPS. Furthermore, our solution could be pretrained from large sequences of multimodality wireless data, on fine-tuning for multiple downstream radio network tasks.
</details>
<details>
<summary>摘要</summary>
无线通信在高频带width大antenna数组面临扩扫管理挑战，可能可以通过多模态感知信息来改进。在这篇论文中，我们提出了一个多模态变换深度学习框架，用于感知协助扫束预测。我们使用卷积神经网络提取图像、点云和雷达原始数据序列中的特征，并在每层卷积层中使用变换器Encoder学习不同模态和时间实例之间的隐藏关系，生成下一层特征提取的编码向量。我们使用多种模式进行超参数学习。为了强化模型在不平衡数据上，我们利用焦点损失和加权移动平均。我们还评估了数据处理和扩展技术，如图像改进、分割、背景筛选、多模态数据翻转、雷达信号转换和GPS角度准确。实验结果表明，我们基于图像和GPS数据进行训练的解决方案在predicted扫束距离方面取得了78.44%的最佳性能，并且在未看到天气的日常场景中实现了73%的有效普适性。此外，我们的解决方案可以从大量多模态无线数据中进行预训练，然后进行多个下游无线网络任务的细化调整。
</details></li>
</ul>
<hr>
<h2 id="JobRecoGPT-–-Explainable-job-recommendations-using-LLMs"><a href="#JobRecoGPT-–-Explainable-job-recommendations-using-LLMs" class="headerlink" title="JobRecoGPT – Explainable job recommendations using LLMs"></a>JobRecoGPT – Explainable job recommendations using LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11805">http://arxiv.org/abs/2309.11805</a></li>
<li>repo_url: None</li>
<li>paper_authors: Preetam Ghosh, Vaishali Sadaphal</li>
<li>for: 本研究旨在提出一种基于自然语言理解的 Job 推荐方法，以填补传统方法所产生的数据损失。</li>
<li>methods: 本研究使用 Large Language Models (LLMs) 来捕捉原始文本数据中的信息，并评估四种不同的方法（内容基于的 deterministic、LLM 引导的、LLM 无引导的、混合）的性能。</li>
<li>results: 研究发现，LLM 引导的方法和混合方法的性能较高，而内容基于的 deterministic 方法和 LLM 无引导的方法的性能较低。同时，LLM 引导的方法和混合方法的时间需求较低。<details>
<summary>Abstract</summary>
In today's rapidly evolving job market, finding the right opportunity can be a daunting challenge. With advancements in the field of AI, computers can now recommend suitable jobs to candidates. However, the task of recommending jobs is not same as recommending movies to viewers. Apart from must-have criteria, like skills and experience, there are many subtle aspects to a job which can decide if it is a good fit or not for a given candidate. Traditional approaches can capture the quantifiable aspects of jobs and candidates, but a substantial portion of the data that is present in unstructured form in the job descriptions and resumes is lost in the process of conversion to structured format. As of late, Large Language Models (LLMs) have taken over the AI field by storm with extraordinary performance in fields where text-based data is available. Inspired by the superior performance of LLMs, we leverage their capability to understand natural language for capturing the information that was previously getting lost during the conversion of unstructured data to structured form. To this end, we compare performance of four different approaches for job recommendations namely, (i) Content based deterministic, (ii) LLM guided, (iii) LLM unguided, and (iv) Hybrid. In this study, we present advantages and limitations of each method and evaluate their performance in terms of time requirements.
</details>
<details>
<summary>摘要</summary>
Large Language Models (LLMs) have recently taken the AI field by storm with extraordinary performance in fields where text-based data is available. Inspired by their superior performance, we leverage their ability to understand natural language to capture the information that was previously lost during the conversion of unstructured data to a structured form. To this end, we compare the performance of four different approaches for job recommendations, including:1. Content-based deterministic approach2. LLM-guided approach3. LLM unguided approach4. Hybrid approachIn this study, we present the advantages and limitations of each method and evaluate their performance in terms of time requirements.
</details></li>
</ul>
<hr>
<h2 id="DimCL-Dimensional-Contrastive-Learning-For-Improving-Self-Supervised-Learning"><a href="#DimCL-Dimensional-Contrastive-Learning-For-Improving-Self-Supervised-Learning" class="headerlink" title="DimCL: Dimensional Contrastive Learning For Improving Self-Supervised Learning"></a>DimCL: Dimensional Contrastive Learning For Improving Self-Supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11782">http://arxiv.org/abs/2309.11782</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thanh Nguyen, Trung Pham, Chaoning Zhang, Tung Luu, Thang Vu, Chang D. Yoo</li>
<li>for: 提高自主学习（SSL）的性能，尤其是对于非对照学习（CL）的扩展和改进。</li>
<li>methods: 提出了一种名为维度对比学习（DimCL）的策略，即在维度方向上进行对比学习而不是批处理方向上，以增强特征多样性并作为SSL前期执行的正则化。</li>
<li>results: 对多个数据集和后端架构进行了广泛的实验，并证明了DimCL可以提高SSL性能，并且发现了硬度意识的特性为DimCL的成功的关键原因。<details>
<summary>Abstract</summary>
Self-supervised learning (SSL) has gained remarkable success, for which contrastive learning (CL) plays a key role. However, the recent development of new non-CL frameworks has achieved comparable or better performance with high improvement potential, prompting researchers to enhance these frameworks further. Assimilating CL into non-CL frameworks has been thought to be beneficial, but empirical evidence indicates no visible improvements. In view of that, this paper proposes a strategy of performing CL along the dimensional direction instead of along the batch direction as done in conventional contrastive learning, named Dimensional Contrastive Learning (DimCL). DimCL aims to enhance the feature diversity, and it can serve as a regularizer to prior SSL frameworks. DimCL has been found to be effective, and the hardness-aware property is identified as a critical reason for its success. Extensive experimental results reveal that assimilating DimCL into SSL frameworks leads to performance improvement by a non-trivial margin on various datasets and backbone architectures.
</details>
<details>
<summary>摘要</summary>
自领导学习（SSL）已经取得了很大的成功，其中对比学习（CL）扮演着关键角色。然而，最近的新非CL框架的发展已经达到了相当或更好的性能水平，并且有很大的提升潜力，因此研究人员尝试进一步加强这些框架。将CL assimilated into non-CL frameworks 已经被考虑，但实际证据表明没有可见的改善。因此，这篇论文提出了一种在维度方向上进行CL而不是在批处理方向上进行CL，称之为维度对比学习（DimCL）。DimCL aimsto enhance the feature diversity, and it can serve as a regularizer to prior SSL frameworks. DimCL has been found to be effective, and the hardness-aware property is identified as a critical reason for its success. 广泛的实验结果表明，将DimCL assimilated into SSL frameworks 会导致性能提高，具有非负的幅度。
</details></li>
</ul>
<hr>
<h2 id="2DDATA-2D-Detection-Annotations-Transmittable-Aggregation-for-Semantic-Segmentation-on-Point-Cloud"><a href="#2DDATA-2D-Detection-Annotations-Transmittable-Aggregation-for-Semantic-Segmentation-on-Point-Cloud" class="headerlink" title="2DDATA: 2D Detection Annotations Transmittable Aggregation for Semantic Segmentation on Point Cloud"></a>2DDATA: 2D Detection Annotations Transmittable Aggregation for Semantic Segmentation on Point Cloud</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11755">http://arxiv.org/abs/2309.11755</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guan-Cheng Lee</li>
<li>for: 本研究旨在解决现有多感器模型面临的精度匹配和费用高问题，以实现在实际应用中使用多感器模型。</li>
<li>methods: 本研究使用了2D检测注释传递汇集(\textbf{2DDATA})，设计了本地物体分支（\textbf{Local Object Branch），以处理固定盒体内点。这种简单的设计可以将矩形盒体约束信息传递到3D编码器模型中。</li>
<li>results: 研究证明了我们的简单设计可以将矩形盒体约束信息传递到3D编码器模型中，证明了大量多感器模型与特定数据 fusion 的可能性。<details>
<summary>Abstract</summary>
Recently, multi-modality models have been introduced because of the complementary information from different sensors such as LiDAR and cameras. It requires paired data along with precise calibrations for all modalities, the complicated calibration among modalities hugely increases the cost of collecting such high-quality datasets, and hinder it from being applied to practical scenarios. Inherit from the previous works, we not only fuse the information from multi-modality without above issues, and also exhaust the information in the RGB modality. We introduced the 2D Detection Annotations Transmittable Aggregation(\textbf{2DDATA}), designing a data-specific branch, called \textbf{Local Object Branch}, which aims to deal with points in a certain bounding box, because of its easiness of acquiring 2D bounding box annotations. We demonstrate that our simple design can transmit bounding box prior information to the 3D encoder model, proving the feasibility of large multi-modality models fused with modality-specific data.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Improve-the-efficiency-of-deep-reinforcement-learning-through-semantic-exploration-guided-by-natural-language"><a href="#Improve-the-efficiency-of-deep-reinforcement-learning-through-semantic-exploration-guided-by-natural-language" class="headerlink" title="Improve the efficiency of deep reinforcement learning through semantic exploration guided by natural language"></a>Improve the efficiency of deep reinforcement learning through semantic exploration guided by natural language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11753">http://arxiv.org/abs/2309.11753</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhourui Guo, Meng Yao, Yang Yu, Qiyue Yin</li>
<li>for: 这个论文的目的是提出一种新的RL方法，以便更高效地使用奥拉克力来提高RL的性能。</li>
<li>methods: 该方法使用一种选择性的方式来与奥拉克力进行交互，使用一个封装了当前状态和奥拉克力的神经网络来选择最相关的问题，并使用奥拉克力的答案来更新RL的策略和价值函数。</li>
<li>results: 该方法可以在一个物体抓取任务中显著提高RL的效率，比基eline方法减少了与奥拉克力的交互次数，以达到一定的性能水平。<details>
<summary>Abstract</summary>
Reinforcement learning is a powerful technique for learning from trial and error, but it often requires a large number of interactions to achieve good performance. In some domains, such as sparse-reward tasks, an oracle that can provide useful feedback or guidance to the agent during the learning process is really of great importance. However, querying the oracle too frequently may be costly or impractical, and the oracle may not always have a clear answer for every situation. Therefore, we propose a novel method for interacting with the oracle in a selective and efficient way, using a retrieval-based approach. We assume that the interaction can be modeled as a sequence of templated questions and answers, and that there is a large corpus of previous interactions available. We use a neural network to encode the current state of the agent and the oracle, and retrieve the most relevant question from the corpus to ask the oracle. We then use the oracle's answer to update the agent's policy and value function. We evaluate our method on an object manipulation task. We show that our method can significantly improve the efficiency of RL by reducing the number of interactions needed to reach a certain level of performance, compared to baselines that do not use the oracle or use it in a naive way.
</details>
<details>
<summary>摘要</summary>
强化学习是一种强大的技术，可以通过试错学习，但它经常需要许多交互来达到良好的性能。在某些领域，如稀薄奖励任务，一个智能 oracle 可以提供有用的反馈或指导，这对 agents 的学习过程是非常重要。然而，向 oracle 查询过于频繁可能是成本高或实际不可能的，而且 oracle 不一定总是可以为每个情况提供明确的答案。因此，我们提出了一种新的方法，使用选择性和有效的方式与 oracle 交互，使用一种检索基于的方法。我们假设交互可以被视为一个序列化的问题和答案，并且有一个大量的前期交互数据库。我们使用一个神经网络来编码 agent 和 oracle 的当前状态，并从数据库中检索最相关的问题来问 oracle。然后，我们使用 oracle 的答案来更新 agent 的策略和价值函数。我们在一个物品抓取任务上进行了evaluation，我们显示，我们的方法可以减少RL中交互的次数，以达到一定的性能水平，相比于不使用 oracle 或使用它的简单方法。
</details></li>
</ul>
<hr>
<h2 id="How-Robust-is-Google’s-Bard-to-Adversarial-Image-Attacks"><a href="#How-Robust-is-Google’s-Bard-to-Adversarial-Image-Attacks" class="headerlink" title="How Robust is Google’s Bard to Adversarial Image Attacks?"></a>How Robust is Google’s Bard to Adversarial Image Attacks?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11751">http://arxiv.org/abs/2309.11751</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thu-ml/attack-bard">https://github.com/thu-ml/attack-bard</a></li>
<li>paper_authors: Yinpeng Dong, Huanran Chen, Jiawei Chen, Zhengwei Fang, Xiao Yang, Yichi Zhang, Yu Tian, Hang Su, Jun Zhu</li>
<li>for: 这个论文主要研究了Google的Bard chatbot的抗 adversarial robustness问题，以更好地理解商业多模态语言模型的漏洞。</li>
<li>methods: 作者使用了白盒子代理视觉编码器或多模态语言模型进行攻击，生成了对Bard的恶意例子，并证明了这些例子可以让Bard输出错误的图像描述。</li>
<li>results: 作者发现，对Bard使用的攻击方法可以在22%的情况下成功，并且这些攻击也可以让其他多模态语言模型（如Bing Chat和ERNIE bot）被攻击。此外，作者还发现了Bard的两种防御机制，并设计了对这些防御机制的攻击方法。<details>
<summary>Abstract</summary>
Multimodal Large Language Models (MLLMs) that integrate text and other modalities (especially vision) have achieved unprecedented performance in various multimodal tasks. However, due to the unsolved adversarial robustness problem of vision models, MLLMs can have more severe safety and security risks by introducing the vision inputs. In this work, we study the adversarial robustness of Google's Bard, a competitive chatbot to ChatGPT that released its multimodal capability recently, to better understand the vulnerabilities of commercial MLLMs. By attacking white-box surrogate vision encoders or MLLMs, the generated adversarial examples can mislead Bard to output wrong image descriptions with a 22% success rate based solely on the transferability. We show that the adversarial examples can also attack other MLLMs, e.g., a 26% attack success rate against Bing Chat and a 86% attack success rate against ERNIE bot. Moreover, we identify two defense mechanisms of Bard, including face detection and toxicity detection of images. We design corresponding attacks to evade these defenses, demonstrating that the current defenses of Bard are also vulnerable. We hope this work can deepen our understanding on the robustness of MLLMs and facilitate future research on defenses. Our code is available at https://github.com/thu-ml/Attack-Bard.   Update: GPT-4V is available at October 2023. We further evaluate its robustness under the same set of adversarial examples, achieving a 45% attack success rate.
</details>
<details>
<summary>摘要</summary>
多模态大语言模型（MLLMs），包括文本和其他感知modalities（特别是视觉），在多种多modal任务中表现出了无precendent的表现。然而，由于视觉模型的不可靠性问题，MLLMs可能具有更严重的安全和安全风险。在这个工作中，我们研究Google的Bard，一个与ChatGPT竞争的聊天机器人，以更好地了解商业MLLMs的漏洞。我们通过攻击白盒子代理视觉encoder或MLLMs来生成对抗例子，可以让Bard输出错误的图像描述，成功率达22%。此外，我们发现Bard的防御机制，包括图像检测和图像攻击检测。我们设计了对这些防御机制的攻击，并证明现有的防御机制也受到攻击。我们希望这个工作可以深入了解MLLMs的稳定性，并促进未来的防御研究。我们的代码可以在https://github.com/thu-ml/Attack-Bard上获取。更新：GPT-4V将于2023年10月发布。我们进一步测试其在同样的对抗例子下的稳定性，成功率达45%。
</details></li>
</ul>
<hr>
<h2 id="LPML-LLM-Prompting-Markup-Language-for-Mathematical-Reasoning"><a href="#LPML-LLM-Prompting-Markup-Language-for-Mathematical-Reasoning" class="headerlink" title="LPML: LLM-Prompting Markup Language for Mathematical Reasoning"></a>LPML: LLM-Prompting Markup Language for Mathematical Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13078">http://arxiv.org/abs/2309.13078</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ryutaro Yamauchi, Sho Sonoda, Akiyoshi Sannai, Wataru Kumagai</li>
<li>for: 本研究旨在使用大型自然语言模型（LLMs）进行数学逻辑 reasoning，并解决由 LLMS 生成的文本中存在的错误和计算问题。</li>
<li>methods: 本研究提出了一种 novel 的框架，即将 Chain-of-Thought（CoT）方法与外部工具（Python REPL）集成，并通过占位符语言的 markup 语言来控制 LLMS 的不жела的行为。</li>
<li>results: 通过对 ChatGPT（GPT-3.5）进行应用，我们 demonstated 了将 CoT 和 Python REPL 集成可以提高 LLMS 的逻辑能力，并且可以使 LLMS 通过 zero-shot 提示来进行高级数学逻辑。<details>
<summary>Abstract</summary>
In utilizing large language models (LLMs) for mathematical reasoning, addressing the errors in the reasoning and calculation present in the generated text by LLMs is a crucial challenge. In this paper, we propose a novel framework that integrates the Chain-of-Thought (CoT) method with an external tool (Python REPL). We discovered that by prompting LLMs to generate structured text in XML-like markup language, we could seamlessly integrate CoT and the external tool and control the undesired behaviors of LLMs. With our approach, LLMs can utilize Python computation to rectify errors within CoT. We applied our method to ChatGPT (GPT-3.5) to solve challenging mathematical problems and demonstrated that combining CoT and Python REPL through the markup language enhances the reasoning capability of LLMs. Our approach enables LLMs to write the markup language and perform advanced mathematical reasoning using only zero-shot prompting.
</details>
<details>
<summary>摘要</summary>
utilizing large language models (LLMs) for mathematical reasoning, addressing the errors in the reasoning and calculation present in the generated text by LLMs is a crucial challenge. In this paper, we propose a novel framework that integrates the Chain-of-Thought (CoT) method with an external tool (Python REPL). We discovered that by prompting LLMs to generate structured text in XML-like markup language, we could seamlessly integrate CoT and the external tool and control the undesired behaviors of LLMs. With our approach, LLMs can utilize Python computation to rectify errors within CoT. We applied our method to ChatGPT (GPT-3.5) to solve challenging mathematical problems and demonstrated that combining CoT and Python REPL through the markup language enhances the reasoning capability of LLMs. Our approach enables LLMs to write the markup language and perform advanced mathematical reasoning using only zero-shot prompting.Here's the translation in Traditional Chinese:使用大型语言模型（LLMs）进行数学理解，对于 LLMS 生成的文本中的错误和计算存在的挑战是一个重要的挑战。在这篇论文中，我们提出了一个新的框架，它结合了排序链 (CoT) 方法和一个外部工具（Python REPL）。我们发现，通过将 LLMS 调侃为生成标记语言（XML-like）的 markup 语言，可以与 CoT 和外部工具完美整合，控制 LLMS 的不适当行为。我们的方法可以让 LLMS 使用 Python 计算 rectify CoT 中的错误。我们将我们的方法应用到 ChatGPT (GPT-3.5) 来解决困难的数学问题，并证明了通过 markup 语言来结合 CoT 和 Python REPL 可以提高 LLMS 的数学理解能力。我们的方法可以让 LLMS 只需零 shot 提示就能写 markup 语言并进行进阶的数学理解。
</details></li>
</ul>
<hr>
<h2 id="Choice-75-A-Dataset-on-Decision-Branching-in-Script-Learning"><a href="#Choice-75-A-Dataset-on-Decision-Branching-in-Script-Learning" class="headerlink" title="Choice-75: A Dataset on Decision Branching in Script Learning"></a>Choice-75: A Dataset on Decision Branching in Script Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11737">http://arxiv.org/abs/2309.11737</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhaoyi Joey Hou, Li Zhang, Chris Callison-Burch</li>
<li>for: 本研究旨在研究日常事件的发展。</li>
<li>methods: 本文提出了Choice-75，首个测试智能系统可Predict decisions given descriptive scenarios的benchmark。</li>
<li>results: 大语言模型在总体上表现不错，但在许多困难的场景下还有很大的进步空间。<details>
<summary>Abstract</summary>
Script learning studies how daily events unfold. Previous works tend to consider a script as a linear sequence of events while ignoring the potential branches that arise due to people's circumstantial choices. We hence propose Choice-75, the first benchmark that challenges intelligent systems to predict decisions given descriptive scenarios, containing 75 scripts and more than 600 scenarios. While large language models demonstrate overall decent performances, there is still notable room for improvement in many hard scenarios.
</details>
<details>
<summary>摘要</summary>
学习脚本研究每日事件的发展。以前的工作通常将脚本视为一个Linear sequence of events而忽略人们因特殊选择而导致的可能的分支。我们因此提出了选择75，首个挑战智能系统预测基于描述场景的决策，包括75个脚本和超过600个场景。虽然大型语言模型在总的表现不错，但还有许多困难场景需要进一步改进。
</details></li>
</ul>
<hr>
<h2 id="A-Differentiable-Framework-for-End-to-End-Learning-of-Hybrid-Structured-Compression"><a href="#A-Differentiable-Framework-for-End-to-End-Learning-of-Hybrid-Structured-Compression" class="headerlink" title="A Differentiable Framework for End-to-End Learning of Hybrid Structured Compression"></a>A Differentiable Framework for End-to-End Learning of Hybrid Structured Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13077">http://arxiv.org/abs/2309.13077</a></li>
<li>repo_url: None</li>
<li>paper_authors: Moonjung Eo, Suhyun Kang, Wonjong Rhee</li>
<li>for: 提高结构压缩技术的性能。</li>
<li>methods: 使用梯度基本优化的演化框架（DF），包括筛选器选择（DML-S）和排名选择（DTL-S）。</li>
<li>results: 实验结果表明DF比现有的结构压缩方法更高效。<details>
<summary>Abstract</summary>
Filter pruning and low-rank decomposition are two of the foundational techniques for structured compression. Although recent efforts have explored hybrid approaches aiming to integrate the advantages of both techniques, their performance gains have been modest at best. In this study, we develop a \textit{Differentiable Framework~(DF)} that can express filter selection, rank selection, and budget constraint into a single analytical formulation. Within the framework, we introduce DML-S for filter selection, integrating scheduling into existing mask learning techniques. Additionally, we present DTL-S for rank selection, utilizing a singular value thresholding operator. The framework with DML-S and DTL-S offers a hybrid structured compression methodology that facilitates end-to-end learning through gradient-base optimization. Experimental results demonstrate the efficacy of DF, surpassing state-of-the-art structured compression methods. Our work establishes a robust and versatile avenue for advancing structured compression techniques.
</details>
<details>
<summary>摘要</summary>
<<SYS>>请转换文本为简化中文。<</SYS>>基础技术 Filter pruning 和 low-rank decomposition 是结构压缩的两大基础技术。 although recent efforts have explored hybrid approaches aiming to integrate the advantages of both techniques, their performance gains have been modest at best. In this study, we develop a 可微分 Framework~(DF) that can express filter selection, rank selection, and budget constraint into a single analytical formulation. Within the framework, we introduce DML-S for filter selection, integrating scheduling into existing mask learning techniques. Additionally, we present DTL-S for rank selection, utilizing a singular value thresholding operator. The framework with DML-S and DTL-S offers a hybrid structured compression methodology that facilitates end-to-end learning through gradient-based optimization. Experimental results demonstrate the efficacy of DF, surpassing state-of-the-art structured compression methods. Our work establishes a robust and versatile avenue for advancing structured compression techniques.Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="FluentEditor-Text-based-Speech-Editing-by-Considering-Acoustic-and-Prosody-Consistency"><a href="#FluentEditor-Text-based-Speech-Editing-by-Considering-Acoustic-and-Prosody-Consistency" class="headerlink" title="FluentEditor: Text-based Speech Editing by Considering Acoustic and Prosody Consistency"></a>FluentEditor: Text-based Speech Editing by Considering Acoustic and Prosody Consistency</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11725">http://arxiv.org/abs/2309.11725</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ai-s2-lab/fluenteditor">https://github.com/ai-s2-lab/fluenteditor</a></li>
<li>paper_authors: Rui Liu, Jiatian Xi, Ziyue Jiang, Haizhou Li</li>
<li>for: 提高语音编辑技术中的流畅性，使得用户可以通过修改输入文本脚本而不是直接修改音频自身来编辑语音。</li>
<li>methods: 基于神经网络的文本语音编辑技术，包括在编辑区域和邻近音频段之间的听力过渡和原始语音风格的保持。</li>
<li>results: 对VCTK数据进行主观和 объектив的实验，表明我们的fluente Editor在自然性和流畅性方面超越了所有先进的基elines。<details>
<summary>Abstract</summary>
Text-based speech editing (TSE) techniques are designed to enable users to edit the output audio by modifying the input text transcript instead of the audio itself. Despite much progress in neural network-based TSE techniques, the current techniques have focused on reducing the difference between the generated speech segment and the reference target in the editing region, ignoring its local and global fluency in the context and original utterance. To maintain the speech fluency, we propose a fluency speech editing model, termed \textit{FluentEditor}, by considering fluency-aware training criterion in the TSE training. Specifically, the \textit{acoustic consistency constraint} aims to smooth the transition between the edited region and its neighboring acoustic segments consistent with the ground truth, while the \textit{prosody consistency constraint} seeks to ensure that the prosody attributes within the edited regions remain consistent with the overall style of the original utterance. The subjective and objective experimental results on VCTK demonstrate that our \textit{FluentEditor} outperforms all advanced baselines in terms of naturalness and fluency. The audio samples and code are available at \url{https://github.com/Ai-S2-Lab/FluentEditor}.
</details>
<details>
<summary>摘要</summary>
文本基于的语音编辑（TSE）技术是为了让用户通过修改输入文本脚本而非直接修改音频自行编辑语音。虽然 neural network-based TSE 技术已经做出了很多进展，但当前技术主要是针对编辑区域和参考目标之间的差异减小，忽略了语音流畅性的本地和全局因素。为保持语音流畅性，我们提议一种流畅语音编辑模型，称为“流畅编辑器”（FluentEditor），通过考虑语音流畅性训练 criterion 在 TSE 训练中。具体来说，“语音一致性约束”目的在编辑区域和其相邻的语音段之间实现缓冲的过渡，使得语音流畅性更高；“语调一致性约束”则是保证编辑区域中的语调特征与原始语音的整体风格保持一致。对 VCTK 进行主观和客观实验表明，我们的“流畅编辑器”在自然性和流畅性两个方面超越了所有高级基elines。听音样本和代码可以在 GitHub 上获得：https://github.com/Ai-S2-Lab/FluentEditor。
</details></li>
</ul>
<hr>
<h2 id="Emotion-Aware-Prosodic-Phrasing-for-Expressive-Text-to-Speech"><a href="#Emotion-Aware-Prosodic-Phrasing-for-Expressive-Text-to-Speech" class="headerlink" title="Emotion-Aware Prosodic Phrasing for Expressive Text-to-Speech"></a>Emotion-Aware Prosodic Phrasing for Expressive Text-to-Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11724">http://arxiv.org/abs/2309.11724</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ai-s2-lab/emopp">https://github.com/ai-s2-lab/emopp</a></li>
<li>paper_authors: Rui Liu, Bin Liu, Haizhou Li</li>
<li>for: 这个论文主要研究了用于实现语音合成中的情感表达。</li>
<li>methods: 这个论文提出了一种基于语音感知的情感表达模型，称为Emotion-Aware Prosodic Phrasing（EmoPP），以便准确地捕捉语音中的情感cue并预测合适的分割点。</li>
<li>results: 对于ESD dataset的对象评估和主观评估表明，EmoPP模型在情感表达方面表现出色，与基础模型相比有显著的提升。Audioamples和代码可以在<a target="_blank" rel="noopener" href="https://github.com/AI-S2-Lab/EmoPP">https://github.com/AI-S2-Lab/EmoPP</a>中找到。<details>
<summary>Abstract</summary>
Prosodic phrasing is crucial to the naturalness and intelligibility of end-to-end Text-to-Speech (TTS). There exist both linguistic and emotional prosody in natural speech. As the study of prosodic phrasing has been linguistically motivated, prosodic phrasing for expressive emotion rendering has not been well studied. In this paper, we propose an emotion-aware prosodic phrasing model, termed \textit{EmoPP}, to mine the emotional cues of utterance accurately and predict appropriate phrase breaks. We first conduct objective observations on the ESD dataset to validate the strong correlation between emotion and prosodic phrasing. Then the objective and subjective evaluations show that the EmoPP outperforms all baselines and achieves remarkable performance in terms of emotion expressiveness. The audio samples and the code are available at \url{https://github.com/AI-S2-Lab/EmoPP}.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传统的 Text-to-Speech (TTS) 系统通常强调语音的正确性和自然性，但是它们往往忽略了语音的情感表达。在这篇论文中，我们提出了一种基于情感的语音分割模型，称为 EmoPP，可以准确地捕捉语音中的情感cue并预测合适的分割点。我们首先通过对 ESD 数据集的 объектив观察， Validate the strong correlation between emotion and prosodic phrasing。然后，对象和主观评估表明，EmoPP 超过了所有基eline，并达到了很高的情感表达性能。听音amples和代码可以在 GitHub 上 obtian 到：https://github.com/AI-S2-Lab/EmoPP。Note: "ESD" stands for "Emotion-based Speech Dataset" in Chinese.
</details></li>
</ul>
<hr>
<h2 id="A-Dynamic-Domain-Adaptation-Deep-Learning-Network-for-EEG-based-Motor-Imagery-Classification"><a href="#A-Dynamic-Domain-Adaptation-Deep-Learning-Network-for-EEG-based-Motor-Imagery-Classification" class="headerlink" title="A Dynamic Domain Adaptation Deep Learning Network for EEG-based Motor Imagery Classification"></a>A Dynamic Domain Adaptation Deep Learning Network for EEG-based Motor Imagery Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11714">http://arxiv.org/abs/2309.11714</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Jiao, Meiyan Xu, Qingqing Chen, Hefan Zhou, Wangliang Zhou</li>
<li>for: 提高BCI系统的精度和稳定性，减少参数调整时间</li>
<li>methods: 使用Dynamic Domain Adaptation Based Deep Learning Network (DADL-Net)，将EEG数据映射到三维几何空间，并通过3D数据模组和通道注意力机制强化特征，最后通过最终数据模组更新特征</li>
<li>results: 在BCI竞赛IV 2a和OpenBMI数据集上验证了方法的表现，实现了70.42%和73.91%的准确率<details>
<summary>Abstract</summary>
There is a correlation between adjacent channels of electroencephalogram (EEG), and how to represent this correlation is an issue that is currently being explored. In addition, due to inter-individual differences in EEG signals, this discrepancy results in new subjects need spend a amount of calibration time for EEG-based motor imagery brain-computer interface. In order to solve the above problems, we propose a Dynamic Domain Adaptation Based Deep Learning Network (DADL-Net). First, the EEG data is mapped to the three-dimensional geometric space and its temporal-spatial features are learned through the 3D convolution module, and then the spatial-channel attention mechanism is used to strengthen the features, and the final convolution module can further learn the spatial-temporal information of the features. Finally, to account for inter-subject and cross-sessions differences, we employ a dynamic domain-adaptive strategy, the distance between features is reduced by introducing a Maximum Mean Discrepancy loss function, and the classification layer is fine-tuned by using part of the target domain data. We verify the performance of the proposed method on BCI competition IV 2a and OpenBMI datasets. Under the intra-subject experiment, the accuracy rates of 70.42% and 73.91% were achieved on the OpenBMI and BCIC IV 2a datasets.
</details>
<details>
<summary>摘要</summary>
有 correlation  между邻近通道的电энцефаogram (EEG), 如何表示这种 correlation 是目前正在探索的问题。此外，由于 EEG 信号的个体差异，这种差异会导致新的 subjects 需要 spent 一定的 calibration 时间 для EEG-based motor imagination 脑机器 interfaces。为解决上述问题，我们提议一种 Dynamic Domain Adaptation Based Deep Learning Network (DADL-Net)。首先，EEG 数据被映射到三维几何空间中，并通过 3D 卷积模块学习其时间-空间特征，然后通过空间通道注意力机制强化特征，最后通过最后一个卷积模块学习特征的时间-空间信息。此外，为了补偿个体和跨会话差异，我们采用动态领域适应策略，将特征之间的距离减少到最大平均差异损失函数，并使用部分目标领域数据进行细化。我们验证了提议的方法在 BCI 竞赛 IV 2a 和 OpenBMI 数据集上的性能。在内部实验中，我们在 OpenBMI 和 BCIC IV 2a 数据集上达到了准确率为 70.42% 和 73.91%。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/21/cs.AI_2023_09_21/" data-id="cloqtaemq0049gh885jd752p8" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_09_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/21/cs.CL_2023_09_21/" class="article-date">
  <time datetime="2023-09-21T11:00:00.000Z" itemprop="datePublished">2023-09-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/21/cs.CL_2023_09_21/">cs.CL - 2023-09-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Towards-Lexical-Analysis-of-Dog-Vocalizations-via-Online-Videos"><a href="#Towards-Lexical-Analysis-of-Dog-Vocalizations-via-Online-Videos" class="headerlink" title="Towards Lexical Analysis of Dog Vocalizations via Online Videos"></a>Towards Lexical Analysis of Dog Vocalizations via Online Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13086">http://arxiv.org/abs/2309.13086</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yufei Wang, Chunhao Zhang, Jieyi Huang, Mengyue Wu, Kenny Zhu</li>
<li>for: 这个研究是为了解含犬语言 semantics 的大挑战。</li>
<li>methods: 这个研究使用了数据驱动的方法，通过对犬叫声与相应的位置和活动之间的conditioned probability进行分析，探讨犬语言 semantics 的含义。</li>
<li>results: 研究发现了一些支持先前观察研究的犬叫声 semantics 的证据，如 growl 可能表示互动。此外，研究还提供了新的发现，例如 whimper 可以被细分为两种类型：寻求注意和不适。<details>
<summary>Abstract</summary>
Deciphering the semantics of animal language has been a grand challenge. This study presents a data-driven investigation into the semantics of dog vocalizations via correlating different sound types with consistent semantics. We first present a new dataset of Shiba Inu sounds, along with contextual information such as location and activity, collected from YouTube with a well-constructed pipeline. The framework is also applicable to other animal species. Based on the analysis of conditioned probability between dog vocalizations and corresponding location and activity, we discover supporting evidence for previous heuristic research on the semantic meaning of various dog sounds. For instance, growls can signify interactions. Furthermore, our study yields new insights that existing word types can be subdivided into finer-grained subtypes and minimal semantic unit for Shiba Inu is word-related. For example, whimper can be subdivided into two types, attention-seeking and discomfort.
</details>
<details>
<summary>摘要</summary>
研究动物语言 semantics 是一个大型挑战。本研究通过对狗叫声的数据驱动Investigation into the semantics of dog vocalizations has been a grand challenge. This study presents a data-driven investigation into the semantics of dog vocalizations by correlating different sound types with consistent semantics. We first present a new dataset of Shiba Inu sounds, along with contextual information such as location and activity, collected from YouTube with a well-constructed pipeline. The framework is also applicable to other animal species. Based on the analysis of conditioned probability between dog vocalizations and corresponding location and activity, we discover supporting evidence for previous heuristic research on the semantic meaning of various dog sounds. For instance, growls can signify interactions. Furthermore, our study yields new insights that existing word types can be subdivided into finer-grained subtypes and minimal semantic unit for Shiba Inu is word-related. For example, whimper can be subdivided into two types, attention-seeking and discomfort.Here's the translation in Traditional Chinese:研究动物语言 semantics 是一个大型挑战。本研究通过对狗叫声的数据驱动Investigation into the semantics of dog vocalizations has been a grand challenge. This study presents a data-driven investigation into the semantics of dog vocalizations by correlating different sound types with consistent semantics. We first present a new dataset of Shiba Inu sounds, along with contextual information such as location and activity, collected from YouTube with a well-constructed pipeline. The framework is also applicable to other animal species. Based on the analysis of conditioned probability between dog vocalizations and corresponding location and activity, we discover supporting evidence for previous heuristic research on the semantic meaning of various dog sounds. For instance, growls can signify interactions. Furthermore, our study yields new insights that existing word types can be subdivided into finer-grained subtypes and minimal semantic unit for Shiba Inu is word-related. For example, whimper can be subdivided into two types, attention-seeking and discomfort.
</details></li>
</ul>
<hr>
<h2 id="Foundation-Metrics-Quantifying-Effectiveness-of-Healthcare-Conversations-powered-by-Generative-AI"><a href="#Foundation-Metrics-Quantifying-Effectiveness-of-Healthcare-Conversations-powered-by-Generative-AI" class="headerlink" title="Foundation Metrics: Quantifying Effectiveness of Healthcare Conversations powered by Generative AI"></a>Foundation Metrics: Quantifying Effectiveness of Healthcare Conversations powered by Generative AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12444">http://arxiv.org/abs/2309.12444</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahyar Abbasian, Elahe Khatibi, Iman Azimi, David Oniani, Zahra Shakeri Hossein Abad, Alexander Thieme, Ram Sriram, Zhongqi Yang, Yanshan Wang, Bryant Lin, Olivier Gevaert, Li-Jia Li, Ramesh Jain, Amir M. Rahmani</li>
<li>for: 这项研究的目的是为了评估医疗聊天机器人的性能，以提高患者的健康结果。</li>
<li>methods: 这项研究使用了现有的大语言模型评估指标，并对其进行了修改和扩展，以适应医疗聊天机器人的特点。</li>
<li>results: 研究结果表明，现有的评估指标无法完全评估医疗聊天机器人的性能，因为它们缺乏对医疗概念和患者需求的理解。新的评估指标可以更好地评估机器人的语言处理能力、实际医疗任务的影响和用户交互对话的效果。<details>
<summary>Abstract</summary>
Generative Artificial Intelligence is set to revolutionize healthcare delivery by transforming traditional patient care into a more personalized, efficient, and proactive process. Chatbots, serving as interactive conversational models, will probably drive this patient-centered transformation in healthcare. Through the provision of various services, including diagnosis, personalized lifestyle recommendations, and mental health support, the objective is to substantially augment patient health outcomes, all the while mitigating the workload burden on healthcare providers. The life-critical nature of healthcare applications necessitates establishing a unified and comprehensive set of evaluation metrics for conversational models. Existing evaluation metrics proposed for various generic large language models (LLMs) demonstrate a lack of comprehension regarding medical and health concepts and their significance in promoting patients' well-being. Moreover, these metrics neglect pivotal user-centered aspects, including trust-building, ethics, personalization, empathy, user comprehension, and emotional support. The purpose of this paper is to explore state-of-the-art LLM-based evaluation metrics that are specifically applicable to the assessment of interactive conversational models in healthcare. Subsequently, we present an comprehensive set of evaluation metrics designed to thoroughly assess the performance of healthcare chatbots from an end-user perspective. These metrics encompass an evaluation of language processing abilities, impact on real-world clinical tasks, and effectiveness in user-interactive conversations. Finally, we engage in a discussion concerning the challenges associated with defining and implementing these metrics, with particular emphasis on confounding factors such as the target audience, evaluation methods, and prompt techniques involved in the evaluation process.
</details>
<details>
<summary>摘要</summary>
优化人工智能将革新医疗服务，从传统患者护理转化为更个性化、高效、积极的过程。 chatbot 作为互动对话模型，将主导这种患者中心的变革。通过提供诊断、个性化生活建议、心理支持等服务，目标是大幅提高患者健康结果，同时减轻医疗提供者的劳作负担。由于医疗应用的生命重要性，需要建立一个统一和完整的评估指标集，以评估对话模型的性能。现有的评估指标，针对普通的大语言模型（LLM），表明对医疗和健康概念的 comprendio 和其在患者健康状态提高中的重要性存在缺失。此外，这些指标忽视了关键的用户中心因素，如信任建立、伦理、个性化、同理、用户理解和情感支持。本文的目的是探讨采用 LLM 的现状评估指标，并提出一个完整的评估指标集，以评估医疗 chatbot 的性能从患者视角。这些指标包括语言处理能力、对实际医疗任务的影响和用户互动对话的效果。最后，我们展开讨论关于定义和实施这些指标的挑战，尤其是对象audience、评估方法和提示技术的影响。
</details></li>
</ul>
<hr>
<h2 id="Active-Learning-for-Multilingual-Fingerspelling-Corpora"><a href="#Active-Learning-for-Multilingual-Fingerspelling-Corpora" class="headerlink" title="Active Learning for Multilingual Fingerspelling Corpora"></a>Active Learning for Multilingual Fingerspelling Corpora</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12443">http://arxiv.org/abs/2309.12443</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuai Wang, Eric Nalisnick</li>
<li>for: 帮助手语数据稀缺问题</li>
<li>methods: 使用活动学习</li>
<li>results: 发现预训练可能利用手语语言之间的手势相似性，但是可能是视觉相似性而不是语言相似性引起的 benefita<details>
<summary>Abstract</summary>
We apply active learning to help with data scarcity problems in sign languages. In particular, we perform a novel analysis of the effect of pre-training. Since many sign languages are linguistic descendants of French sign language, they share hand configurations, which pre-training can hopefully exploit. We test this hypothesis on American, Chinese, German, and Irish fingerspelling corpora. We do observe a benefit from pre-training, but this may be due to visual rather than linguistic similarities
</details>
<details>
<summary>摘要</summary>
我们使用活动学习来帮助数据缺乏问题在手语中。特别是，我们进行了一种新的预训练分析。由于许多手语都是法语手语的语言后裔，因此它们可能具有相似的手势配置，预训练可能可以利用这些相似性。我们在美国、中国、德国和爱尔兰手语词汇集中测试了这个假设。我们确实发现了预训练的好处，但这可能是由视觉相似性而不是语言相似性导致的。Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. Traditional Chinese is also commonly used in Taiwan and Hong Kong.
</details></li>
</ul>
<hr>
<h2 id="Reranking-for-Natural-Language-Generation-from-Logical-Forms-A-Study-based-on-Large-Language-Models"><a href="#Reranking-for-Natural-Language-Generation-from-Logical-Forms-A-Study-based-on-Large-Language-Models" class="headerlink" title="Reranking for Natural Language Generation from Logical Forms: A Study based on Large Language Models"></a>Reranking for Natural Language Generation from Logical Forms: A Study based on Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12294">http://arxiv.org/abs/2309.12294</a></li>
<li>repo_url: None</li>
<li>paper_authors: Levon Haroutunian, Zhuang Li, Lucian Galescu, Philip Cohen, Raj Tumuluri, Gholamreza Haffari</li>
<li>for: 本文旨在提高大型自然语言模型（LLM）生成的自然语言质量。</li>
<li>methods: 本文提出了一种生成并重新排序的方法，包括首先通过提示LLM生成一组候选输出，然后使用任务特定的重新排序模型进行重新排序。</li>
<li>results: 经过广泛的实验表明，我们的方法可以提高LLM生成的输出质量，包括semantic consistency和fluency。<details>
<summary>Abstract</summary>
Large language models (LLMs) have demonstrated impressive capabilities in natural language generation. However, their output quality can be inconsistent, posing challenges for generating natural language from logical forms (LFs). This task requires the generated outputs to embody the exact semantics of LFs, without missing any LF semantics or creating any hallucinations. In this work, we tackle this issue by proposing a novel generate-and-rerank approach. Our approach involves initially generating a set of candidate outputs by prompting an LLM and subsequently reranking them using a task-specific reranker model. In addition, we curate a manually collected dataset to evaluate the alignment between different ranking metrics and human judgements. The chosen ranking metrics are utilized to enhance the training and evaluation of the reranker model. By conducting extensive experiments on three diverse datasets, we demonstrate that the candidates selected by our reranker outperform those selected by baseline methods in terms of semantic consistency and fluency, as measured by three comprehensive metrics. Our findings provide strong evidence for the effectiveness of our approach in improving the quality of generated outputs.
</details>
<details>
<summary>摘要</summary>
Our approach involves first generating a set of candidate outputs using an LLM and then reranking them using a task-specific reranker model. We also create a manually curated dataset to evaluate the alignment between different ranking metrics and human judgments. We use these ranking metrics to enhance the training and evaluation of the reranker model.We conduct extensive experiments on three diverse datasets and show that the candidates selected by our reranker outperform those selected by baseline methods in terms of semantic consistency and fluency, as measured by three comprehensive metrics. Our findings provide strong evidence for the effectiveness of our approach in improving the quality of generated outputs.
</details></li>
</ul>
<hr>
<h2 id="Inspire-the-Large-Language-Model-by-External-Knowledge-on-BioMedical-Named-Entity-Recognition"><a href="#Inspire-the-Large-Language-Model-by-External-Knowledge-on-BioMedical-Named-Entity-Recognition" class="headerlink" title="Inspire the Large Language Model by External Knowledge on BioMedical Named Entity Recognition"></a>Inspire the Large Language Model by External Knowledge on BioMedical Named Entity Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12278">http://arxiv.org/abs/2309.12278</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyi Bian, Jiaxuan Zheng, Yuyi Zhang, Shanfeng Zhu</li>
<li>for: 这 paper 的目的是解决生物医学命名实体识别（BioNER）任务，特别是利用大语言模型（LLM）来解决这个任务。</li>
<li>methods: 这 paper 使用了一种两步 Approach，首先将 NER 任务分解为 entity span EXTRACTION 和 entity type 确定两个步骤。其次，为 entity type 确定，我们将实体知识注入到 LLM 中以解决 LL 缺乏域知识的问题。</li>
<li>results: 实验结果表明，我们的 two-step BioNER 方法与之前的几 shot LLM 基eline 相比有了显著的改善。同时，将外部知识注入到 LLM 中也有效地提高了实体类别确定性。<details>
<summary>Abstract</summary>
Large language models (LLMs) have demonstrated dominating performance in many NLP tasks, especially on generative tasks. However, they often fall short in some information extraction tasks, particularly those requiring domain-specific knowledge, such as Biomedical Named Entity Recognition (NER). In this paper, inspired by Chain-of-thought, we leverage the LLM to solve the Biomedical NER step-by-step: break down the NER task into entity span extraction and entity type determination. Additionally, for entity type determination, we inject entity knowledge to address the problem that LLM's lack of domain knowledge when predicting entity category. Experimental results show a significant improvement in our two-step BioNER approach compared to previous few-shot LLM baseline. Additionally, the incorporation of external knowledge significantly enhances entity category determination performance.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Improving-VTE-Identification-through-Adaptive-NLP-Model-Selection-and-Clinical-Expert-Rule-based-Classifier-from-Radiology-Reports"><a href="#Improving-VTE-Identification-through-Adaptive-NLP-Model-Selection-and-Clinical-Expert-Rule-based-Classifier-from-Radiology-Reports" class="headerlink" title="Improving VTE Identification through Adaptive NLP Model Selection and Clinical Expert Rule-based Classifier from Radiology Reports"></a>Improving VTE Identification through Adaptive NLP Model Selection and Clinical Expert Rule-based Classifier from Radiology Reports</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12273">http://arxiv.org/abs/2309.12273</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jamie Deng, Yusen Wu, Hilary Hayssen, Brain Englum, Aman Kankaria, Minerva Mayorga-Carlin, Shalini Sahoo, John Sorkin, Brajesh Lal, Yelena Yesha, Phuong Nguyen</li>
<li>for: 这个研究旨在提高不结构化（free-text）医疗报告中的深部静脉血栓（DVT）和肺动脉血栓（PE）的识别率，以便更好地治疗Cardiovascular disease。</li>
<li>methods: 本研究使用自然语言处理（NLP）方法，结合深度学习（DL）和数据增强，以提高VTE事件的识别率。</li>
<li>results: 本研究的实验结果显示，模型具有97%的准确率和97%的F1分数在预测DVT，并具有98.3%的准确率和98.4%的F1分数在预测PE。<details>
<summary>Abstract</summary>
Rapid and accurate identification of Venous thromboembolism (VTE), a severe cardiovascular condition including deep vein thrombosis (DVT) and pulmonary embolism (PE), is important for effective treatment. Leveraging Natural Language Processing (NLP) on radiology reports, automated methods have shown promising advancements in identifying VTE events from retrospective data cohorts or aiding clinical experts in identifying VTE events from radiology reports. However, effectively training Deep Learning (DL) and the NLP models is challenging due to limited labeled medical text data, the complexity and heterogeneity of radiology reports, and data imbalance. This study proposes novel method combinations of DL methods, along with data augmentation, adaptive pre-trained NLP model selection, and a clinical expert NLP rule-based classifier, to improve the accuracy of VTE identification in unstructured (free-text) radiology reports. Our experimental results demonstrate the model's efficacy, achieving an impressive 97\% accuracy and 97\% F1 score in predicting DVT, and an outstanding 98.3\% accuracy and 98.4\% F1 score in predicting PE. These findings emphasize the model's robustness and its potential to significantly contribute to VTE research.
</details>
<details>
<summary>摘要</summary>
快速和准确地识别深静脉栓塞（VTE），包括深静脉栓塞（DVT）和肺动脉栓塞（PE），是诊断 cardiovascular 疾病的关键。通过自然语言处理（NLP）技术对医疗报告进行自动分析，已经在从退化数据库中提取VTE事件的方面展现出了扎实的进步。然而，由于医疗文本数据的有限性、报告的复杂性和多样性以及数据不均衡，训练深度学习（DL）和NLP模型的问题很大。这项研究提出了一种新的方法组合，包括DL方法、数据增强、适应预训练NLP模型选择和临床专家NLP规则基本分类器，以提高无结构（自由文本）医疗报告中VTE识别的准确率。我们的实验结果表明，该模型具有卓越的表现，在静脉栓塞（DVT）预测方面达到了97%的准确率和97%的F1分数，在肺动脉栓塞（PE）预测方面达到了98.3%的准确率和98.4%的F1分数。这些发现证明了模型的稳定性，并且它有potential为VTE研究做出重要贡献。
</details></li>
</ul>
<hr>
<h2 id="The-Cambridge-Law-Corpus-A-Corpus-for-Legal-AI-Research"><a href="#The-Cambridge-Law-Corpus-A-Corpus-for-Legal-AI-Research" class="headerlink" title="The Cambridge Law Corpus: A Corpus for Legal AI Research"></a>The Cambridge Law Corpus: A Corpus for Legal AI Research</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12269">http://arxiv.org/abs/2309.12269</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andreas Östling, Holli Sargeant, Huiyuan Xie, Ludwig Bull, Alexander Terenin, Leif Jonsson, Måns Magnusson, Felix Steffek</li>
<li>for: 这份论文是为了推动法律人工智能研究而创建的剑桥法律词汇库（CLC）的首次发布。CLC包含了超过250,000个英国法律案例，其中大多数案例发生在21世纪，但词汇库还包括16世纪的案例。</li>
<li>methods: 这篇论文提供了CLC的首次发布，包括Raw文本和元数据。同时，作者还提供了638个案例的注释，由法律专家进行标注。使用了这些注释数据，作者在GPT-3、GPT-4和RoBERTa模型上进行了案例结果抽取的训练和评估。</li>
<li>results: 作者通过使用GPT-3、GPT-4和RoBERTa模型进行了案例结果抽取的训练和评估。他们提供了这些模型的benchmark，以便用于未来的法律人工智能研究。同时，作者还进行了extensive的法律和伦理讨论，以 Addressing the potentially sensitive nature of this material。<details>
<summary>Abstract</summary>
We introduce the Cambridge Law Corpus (CLC), a corpus for legal AI research. It consists of over 250 000 court cases from the UK. Most cases are from the 21st century, but the corpus includes cases as old as the 16th century. This paper presents the first release of the corpus, containing the raw text and meta-data. Together with the corpus, we provide annotations on case outcomes for 638 cases, done by legal experts. Using our annotated data, we have trained and evaluated case outcome extraction with GPT-3, GPT-4 and RoBERTa models to provide benchmarks. We include an extensive legal and ethical discussion to address the potentially sensitive nature of this material. As a consequence, the corpus will only be released for research purposes under certain restrictions.
</details>
<details>
<summary>摘要</summary>
我们介绍了剑桥法律词库（CLC），一个为法律人工智能研究提供的词库。它包含了超过250,000个英国法院案例，大多数案例是21世纪的，但词库还包括了16世纪的案例。本文发布了词库的首个版本，其中包含了原始文本和元数据。同时，我们提供了638个案例的法律专家标注，用于训练和评估案例结果抽取模型。我们还进行了广泛的法律和伦理讨论，以Addressing the potentially sensitive nature of this material。因此，词库将仅 для研究用途发布，受限于 certain restrictions。
</details></li>
</ul>
<hr>
<h2 id="On-the-Relationship-between-Skill-Neurons-and-Robustness-in-Prompt-Tuning"><a href="#On-the-Relationship-between-Skill-Neurons-and-Robustness-in-Prompt-Tuning" class="headerlink" title="On the Relationship between Skill Neurons and Robustness in Prompt Tuning"></a>On the Relationship between Skill Neurons and Robustness in Prompt Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12263">http://arxiv.org/abs/2309.12263</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leon Ackermann, Xenia Ohmer</li>
<li>for: 这 paper 研究了 Prompt Tuning 方法在 pre-trained 大语言模型 (PLMs) 上的稳定性，以及这方法 在具体任务上如何活化特定的 neuron。</li>
<li>methods: 这 paper 使用了 RoBERTa 和 T5 进行实验，并研究了这些模型在不同任务上的表现。</li>
<li>results: 研究结果表明，Prompt Tuning 在不同任务上的表现不够稳定，而 T5 的表现比 RoBERTa 更加稳定。此外，研究还发现了 RoBERTa 和 T5 中的特定 neuron 在不同任务上的表现。<details>
<summary>Abstract</summary>
Prompt Tuning is a popular parameter-efficient finetuning method for pre-trained large language models (PLMs). Recently, based on experiments with RoBERTa, it has been suggested that Prompt Tuning activates specific neurons in the transformer's feed-forward networks, that are highly predictive and selective for the given task. In this paper, we study the robustness of Prompt Tuning in relation to these "skill neurons", using RoBERTa and T5. We show that prompts tuned for a specific task are transferable to tasks of the same type but are not very robust to adversarial data, with higher robustness for T5 than RoBERTa. At the same time, we replicate the existence of skill neurons in RoBERTa and further show that skill neurons also seem to exist in T5. Interestingly, the skill neurons of T5 determined on non-adversarial data are also among the most predictive neurons on the adversarial data, which is not the case for RoBERTa. We conclude that higher adversarial robustness may be related to a model's ability to activate the relevant skill neurons on adversarial data.
</details>
<details>
<summary>摘要</summary>
启发调整（Prompt Tuning）是一种Parameter-efficient finetuning方法，用于预训练大型自然语言模型（PLMs）。最近，通过RoBERTa的实验，表明Prompt Tuning可以活化特定的转换器网络中的高度预测和选择性 neuron，用于给定任务。在这篇论文中，我们研究Prompt Tuning的稳定性，与这些“技能neuron”（skill neurons）相关。使用RoBERTa和T5，我们发现，任务特定的启发调整可以在同类任务中进行转移，但对阴谋数据不具有很高的稳定性，T5的稳定性比RoBERTa更高。同时，我们复制了RoBERTa中的技能neurons，并证明T5中也存在技能neurons。更有趣的是，T5中非阴谋数据上定义的技能neurons还是阴谋数据上最预测性的 neurons的一部分，而RoBERTa中的技能neurons不是。我们认为，高度阴谋稳定性可能与模型活化相关的技能neurons的存在有关。
</details></li>
</ul>
<hr>
<h2 id="SQUARE-Automatic-Question-Answering-Evaluation-using-Multiple-Positive-and-Negative-References"><a href="#SQUARE-Automatic-Question-Answering-Evaluation-using-Multiple-Positive-and-Negative-References" class="headerlink" title="SQUARE: Automatic Question Answering Evaluation using Multiple Positive and Negative References"></a>SQUARE: Automatic Question Answering Evaluation using Multiple Positive and Negative References</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12250">http://arxiv.org/abs/2309.12250</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matteo Gabburo, Siddhant Garg, Rik Koncel Kedziorski, Alessandro Moschitti</li>
<li>for: 本研究旨在提出一种新的问答评估 metric，用于评估句子级问答系统的正确率。</li>
<li>methods: 本研究使用多个参考答案（包括多个正确和错误的参考答案）来评估句子级问答系统的表现，并使用 transformer LM encoder 基于相似度metric 进行评估。</li>
<li>results: 研究结果表明，SQuArE metric 在 sentence-level 提取式（Answer Selection）和生成（GenQA）问答系统上具有更高的协调度和更好的性能，并且在多个学术和工业数据集上都具有优异的表现。<details>
<summary>Abstract</summary>
Evaluation of QA systems is very challenging and expensive, with the most reliable approach being human annotations of correctness of answers for questions. Recent works (AVA, BEM) have shown that transformer LM encoder based similarity metrics transfer well for QA evaluation, but they are limited by the usage of a single correct reference answer. We propose a new evaluation metric: SQuArE (Sentence-level QUestion AnsweRing Evaluation), using multiple reference answers (combining multiple correct and incorrect references) for sentence-form QA. We evaluate SQuArE on both sentence-level extractive (Answer Selection) and generative (GenQA) QA systems, across multiple academic and industrial datasets, and show that it outperforms previous baselines and obtains the highest correlation with human annotations.
</details>
<details>
<summary>摘要</summary>
评估问答系统非常困难和昂贵，人工标注正确答案为最可靠的方法。最近的研究（AVA、BEM）表明，基于转换器LM核心 metric 可以很好地传递问答评估，但它们受到唯一正确参考答案的限制。我们提议一种新的评估指标：SQuArE（句子级问答回答评估），使用多个参考答案（包括多个正确和错误参考）评估句子级问答系统。我们在多个学术和产业数据集上评估了SQuArE，并显示它超过了先前的基线和 humans 的标注相关度最高。
</details></li>
</ul>
<hr>
<h2 id="Bridging-the-Gaps-of-Both-Modality-and-Language-Synchronous-Bilingual-CTC-for-Speech-Translation-and-Speech-Recognition"><a href="#Bridging-the-Gaps-of-Both-Modality-and-Language-Synchronous-Bilingual-CTC-for-Speech-Translation-and-Speech-Recognition" class="headerlink" title="Bridging the Gaps of Both Modality and Language: Synchronous Bilingual CTC for Speech Translation and Speech Recognition"></a>Bridging the Gaps of Both Modality and Language: Synchronous Bilingual CTC for Speech Translation and Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12234">http://arxiv.org/abs/2309.12234</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xuchennlp/s2t">https://github.com/xuchennlp/s2t</a></li>
<li>paper_authors: Chen Xu, Xiaoqian Liu, Erfeng He, Yuhao Zhang, Qianqian Dong, Tong Xiao, Jingbo Zhu, Dapeng Man, Wu Yang</li>
<li>for: 这篇论文主要针对的是语音翻译任务中的同时双语连接主义推荐（CTC）框架，用于桥接语音和文本、源语言和目标语言之间的差异。</li>
<li>methods: 该模型使用了涉及训练和评估的同时双语CTC框架，利用训练录音和翻译文本作为同时目标，从而桥接语音和文本之间的差异。</li>
<li>results: 该模型在资源受限的情况下在MuST-C ST benchmark上达到了新的州OF-the-art表现，并且在语音识别任务中也显示了显著提高，这表明了涉及多语言学习的跨语言学习效应。<details>
<summary>Abstract</summary>
In this study, we present synchronous bilingual Connectionist Temporal Classification (CTC), an innovative framework that leverages dual CTC to bridge the gaps of both modality and language in the speech translation (ST) task. Utilizing transcript and translation as concurrent objectives for CTC, our model bridges the gap between audio and text as well as between source and target languages. Building upon the recent advances in CTC application, we develop an enhanced variant, BiL-CTC+, that establishes new state-of-the-art performances on the MuST-C ST benchmarks under resource-constrained scenarios. Intriguingly, our method also yields significant improvements in speech recognition performance, revealing the effect of cross-lingual learning on transcription and demonstrating its broad applicability. The source code is available at https://github.com/xuchennlp/S2T.
</details>
<details>
<summary>摘要</summary>
在本研究中，我们提出了同步双语 Connectionist Temporal Classification（CTC）框架，这是一种创新的方法，利用了双CTC来跨越语言和Modalities在语音翻译（ST）任务中的差异。我们通过使用讲解和翻译作为同时目标 для CTC，我们的模型可以跨越音频和文本之间的差异，以及源语言和目标语言之间的差异。基于最近的CTC应用的进步，我们开发了一种改进的变体，BiL-CTC+，它在资源受限的情况下在MuST-C ST标准测试上达到了新的州Of-The-Art表现。很有趣的是，我们的方法还提高了语音识别性能，这表明了涉及跨语言学习的跨越效应，并证明了其广泛的适用性。代码可以在https://github.com/xuchennlp/S2T上获取。
</details></li>
</ul>
<hr>
<h2 id="Towards-Answering-Health-related-Questions-from-Medical-Videos-Datasets-and-Approaches"><a href="#Towards-Answering-Health-related-Questions-from-Medical-Videos-Datasets-and-Approaches" class="headerlink" title="Towards Answering Health-related Questions from Medical Videos: Datasets and Approaches"></a>Towards Answering Health-related Questions from Medical Videos: Datasets and Approaches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12224">http://arxiv.org/abs/2309.12224</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deepak Gupta, Kush Attal, Dina Demner-Fushman</li>
<li>for: 这个论文是为了回答公众的健康相关问题而提供视频回答。</li>
<li>methods: 这篇论文使用了一个批处理方法创建了两个大规模数据集：HealthVidQA-CRF和HealthVidQA-Prompt。然后，它们提出了单模态和多模态方法，可以从医疗视频中提取视觉回答。</li>
<li>results: 这篇论文的结果表明，创建了这两个数据集可以提高医疗视频回答任务的模型训练，并且视觉特征可以提高单模态和多模态方法的性能。<details>
<summary>Abstract</summary>
The increase in the availability of online videos has transformed the way we access information and knowledge. A growing number of individuals now prefer instructional videos as they offer a series of step-by-step procedures to accomplish particular tasks. The instructional videos from the medical domain may provide the best possible visual answers to first aid, medical emergency, and medical education questions. Toward this, this paper is focused on answering health-related questions asked by the public by providing visual answers from medical videos. The scarcity of large-scale datasets in the medical domain is a key challenge that hinders the development of applications that can help the public with their health-related questions. To address this issue, we first proposed a pipelined approach to create two large-scale datasets: HealthVidQA-CRF and HealthVidQA-Prompt. Later, we proposed monomodal and multimodal approaches that can effectively provide visual answers from medical videos to natural language questions. We conducted a comprehensive analysis of the results, focusing on the impact of the created datasets on model training and the significance of visual features in enhancing the performance of the monomodal and multi-modal approaches. Our findings suggest that these datasets have the potential to enhance the performance of medical visual answer localization tasks and provide a promising future direction to further enhance the performance by using pre-trained language-vision models.
</details>
<details>
<summary>摘要</summary>
“在线影片的更多可用性已经改变了我们取得信息和知识的方式。更多的人现在偏好使用指南影片，因为它们提供了一系列步骤的程序来完成特定任务。医疗领域的指南影片可能提供医疗问题上最佳的可视答案。这篇论文专注于通过提供医疗影片的可视答案来回答公众对健康问题的问题。医疗领域的大规模数据匮乏是开发应用程序的关键挑战。为解决这个问题，我们首先提出了管道方法，创建了HealthVidQA-CRF和HealthVidQA-Prompt两个大规模数据集。之后，我们提出了单模式和多模式的方法，可以从医疗影片中提取可视答案。我们进行了全面的分析结果，专注于数据集的创建影响模型训练的影响和可视特征的增强效果。我们的发现表明这些数据集具有提高医疗可视答案定位任务的潜力，并提供了未来发展的可能性，使用预训语音视觉模型。”
</details></li>
</ul>
<hr>
<h2 id="Code-Soliloquies-for-Accurate-Calculations-in-Large-Language-Models"><a href="#Code-Soliloquies-for-Accurate-Calculations-in-Large-Language-Models" class="headerlink" title="Code Soliloquies for Accurate Calculations in Large Language Models"></a>Code Soliloquies for Accurate Calculations in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12161">http://arxiv.org/abs/2309.12161</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luffycodes/tutorbot-spock-phys">https://github.com/luffycodes/tutorbot-spock-phys</a></li>
<li>paper_authors: Shashank Sonkar, MyCo Le, Xinghe Chen, Naiming Liu, Debshila Basu Mallick, Richard G. Baraniuk</li>
<li>for: 这个论文的目的是提高智能教学系统（ITS）中使用大语言模型（LLM）后端的质量，通过使用高质量的对话数据集来改进学生和ITS之间的交互。</li>
<li>methods: 这个论文使用了先进的GPT-4模型生成Synthetic学生教师对话，并采用了一种新的状态强调设计来解决GPT-4在处理简单的乘数任务时表现不佳的问题。</li>
<li>results: 这个论文的结果表明，使用这种新的状态强调设计可以增强Mock对话数据集的质量，特别是在需要计算的科学概念上。这种方法可以提高LLM后端的准确率和计算可靠性。<details>
<summary>Abstract</summary>
High-quality conversational datasets are integral to the successful development of Intelligent Tutoring Systems (ITS) that employ a Large Language Model (LLM) backend. These datasets, when used to fine-tune the LLM backend, significantly enhance the quality of interactions between students and ITS. A common strategy for developing these datasets involves generating synthetic student-teacher dialogues using advanced GPT-4 models. However, challenges arise when these dialogues demand complex calculations, common in subjects like physics. Despite its advanced capabilities, GPT-4's performance falls short in reliably handling even simple multiplication tasks, marking a significant limitation in its utility for these subjects. To address these challenges, this paper introduces an innovative stateful prompt design. Our approach generates a mock conversation between a student and a tutorbot, both roles simulated by GPT-4. Each student response triggers a soliloquy (an inner monologue) in the GPT-tutorbot, which assesses whether its response would necessitate calculations. If so, it proceeds to script the required code in Python and then uses the resulting output to construct its response to the student. Our approach notably enhances the quality of synthetic conversation datasets, especially for subjects that are calculation-intensive. Our findings show that our Higgs model -- a LLaMA finetuned with datasets generated through our novel stateful prompt design -- proficiently utilizes Python for computations. Consequently, finetuning with our datasets enriched with code soliloquies enhances not just the accuracy but also the computational reliability of Higgs' responses.
</details>
<details>
<summary>摘要</summary>
高品质对话数据集是智能教学系统（ITS）的成功发展的重要组成部分。这些数据集，当用于精度调整LLM后端，会显著提高学生和ITS之间的互动质量。一种常见的发展策略是使用高级GPT-4模型生成synthetic学生教师对话。然而，在涉及到物理等科学的复杂计算时，GPT-4的表现不具备可靠性，这成为了这些主题的限制。为了解决这些挑战，本文提出了一种创新的状态归并提示设计。我们的方法通过GPT-4 simulate学生和教师两个角色，然后通过模拟对话来生成Mock对话。每个学生回答都会触发GPT-tutorbot的内部对话（soliloquy），判断是否需要计算。如果需要，那么GPT-tutorbot会使用Python脚本编写代码，然后使用该代码生成回答给学生。我们的方法可以明显提高synthetic对话数据集的质量，特别是对于需要计算的主题。我们的研究发现，我们的Higgs模型（LLaMA finetuned with我们的新状态归并提示设计生成的数据集）可以高效地使用Python进行计算。因此，在我们的数据集中添加了代码soliloquy后，finetuning Higgs的精度和计算可靠性都会提高。
</details></li>
</ul>
<hr>
<h2 id="How-to-Guides-for-Specific-Audiences-A-Corpus-and-Initial-Findings"><a href="#How-to-Guides-for-Specific-Audiences-A-Corpus-and-Initial-Findings" class="headerlink" title="How-to Guides for Specific Audiences: A Corpus and Initial Findings"></a>How-to Guides for Specific Audiences: A Corpus and Initial Findings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12117">http://arxiv.org/abs/2309.12117</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicola Fanton, Agnieszka Falenska, Michael Roth</li>
<li>for: 这篇论文 investigate wikiHow 上的 how-to 指南是否因为目标读者而有所不同。</li>
<li>methods: 作者使用了资深研究和计算方法来检查文本中的偏见。</li>
<li>results: 研究发现，wikiHow 上的 how-to 指南受到社会 norms 和潜在的偏见的影响。<details>
<summary>Abstract</summary>
Instructional texts for specific target groups should ideally take into account the prior knowledge and needs of the readers in order to guide them efficiently to their desired goals. However, targeting specific groups also carries the risk of reflecting disparate social norms and subtle stereotypes. In this paper, we investigate the extent to which how-to guides from one particular platform, wikiHow, differ in practice depending on the intended audience. We conduct two case studies in which we examine qualitative features of texts written for specific audiences. In a generalization study, we investigate which differences can also be systematically demonstrated using computational methods. The results of our studies show that guides from wikiHow, like other text genres, are subject to subtle biases. We aim to raise awareness of these inequalities as a first step to addressing them in future work.
</details>
<details>
<summary>摘要</summary>
教程文档应该根据目标群体的先前知识和需求进行定制，以efficient地引导读者到他们的目标。然而，targeting specific groups也可能折衣不同的社会规范和微妙的刻板印象。在这篇论文中，我们研究了wikiHow的教程文档在实践中是否受到目标读者影响。我们进行了两个案例研究，检查了特定读者群体的文本特质。在一个总结研究中，我们使用计算方法示出这些差异。结果显示，wikiHow的教程文档，如其他文章类型，受到微妙的偏见。我们希望通过提醒这些不平等来addressing them in future work。Note: Please note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="A-Computational-Analysis-of-Vagueness-in-Revisions-of-Instructional-Texts"><a href="#A-Computational-Analysis-of-Vagueness-in-Revisions-of-Instructional-Texts" class="headerlink" title="A Computational Analysis of Vagueness in Revisions of Instructional Texts"></a>A Computational Analysis of Vagueness in Revisions of Instructional Texts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12107">http://arxiv.org/abs/2309.12107</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alok Debnath, Michael Roth</li>
<li>for: 本研究旨在分析WikiHow上的修订历史数据，找出涉及uncertainty的修改。</li>
<li>methods: 本研究使用神经网络模型分析修订历史数据，并采用对比性评价任务来评估模型的性能。</li>
<li>results: 研究表明，使用神经网络模型可以有效地分辨修改后的 instrucion 和原始 instrucion。<details>
<summary>Abstract</summary>
WikiHow is an open-domain repository of instructional articles for a variety of tasks, which can be revised by users. In this paper, we extract pairwise versions of an instruction before and after a revision was made. Starting from a noisy dataset of revision histories, we specifically extract and analyze edits that involve cases of vagueness in instructions. We further investigate the ability of a neural model to distinguish between two versions of an instruction in our data by adopting a pairwise ranking task from previous work and showing improvements over existing baselines.
</details>
<details>
<summary>摘要</summary>
WikiHow 是一个开放领域的指导文章存储库，可以由用户修改。在这篇论文中，我们提取了对应的版本之间的对应。从含污染的历史记录开始，我们特定地提取和分析对于 instrucional 不具体的修改。我们进一步调查一个神经网络模型是否能够在我们的数据中分辨两个版本的指导。我们采用了之前的对应任务，并超过了现有的基线。
</details></li>
</ul>
<hr>
<h2 id="SemEval-2022-Task-7-Identifying-Plausible-Clarifications-of-Implicit-and-Underspecified-Phrases-in-Instructional-Texts"><a href="#SemEval-2022-Task-7-Identifying-Plausible-Clarifications-of-Implicit-and-Underspecified-Phrases-in-Instructional-Texts" class="headerlink" title="SemEval-2022 Task 7: Identifying Plausible Clarifications of Implicit and Underspecified Phrases in Instructional Texts"></a>SemEval-2022 Task 7: Identifying Plausible Clarifications of Implicit and Underspecified Phrases in Instructional Texts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12102">http://arxiv.org/abs/2309.12102</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/acidann/claire">https://github.com/acidann/claire</a></li>
<li>paper_authors: Michael Roth, Talita Anthonio, Anna Sauer</li>
<li>for: 这个研究是为了评估帮助文档中的解释是否有效。</li>
<li>methods: 该研究使用了人工修改的 instrucitonal 文档，并生成了多个解释选项。然后，收集了人类的可能性评估。</li>
<li>results: 该研究发现了21个参与者的系统，最佳系统的准确率为68.9%。此外，研究还发现了一些参与者的系统可以在特定上下文中identify多个可能的解释，准确率为75.2%。<details>
<summary>Abstract</summary>
We describe SemEval-2022 Task 7, a shared task on rating the plausibility of clarifications in instructional texts. The dataset for this task consists of manually clarified how-to guides for which we generated alternative clarifications and collected human plausibility judgements. The task of participating systems was to automatically determine the plausibility of a clarification in the respective context. In total, 21 participants took part in this task, with the best system achieving an accuracy of 68.9%. This report summarizes the results and findings from 8 teams and their system descriptions. Finally, we show in an additional evaluation that predictions by the top participating team make it possible to identify contexts with multiple plausible clarifications with an accuracy of 75.2%.
</details>
<details>
<summary>摘要</summary>
我们描述SemEval-2022任务7，一个共同任务，评估指导文章中的解释可能性。这个任务的数据集包括手动修订的使用指南，我们生成了备用的解释，并收集了人类可能性评估。参与系统的任务是自动确定解释的可能性在特定上下文中。总共有21个参与者，最佳系统的准确率为68.9%。这份报告总结了8个团队和他们的系统描述。此外，我们在额外评估中发现，参与者顶尖系统的预测可以在多个可能性的上下文中寻找正确的解释，准确率为75.2%。
</details></li>
</ul>
<hr>
<h2 id="AceGPT-Localizing-Large-Language-Models-in-Arabic"><a href="#AceGPT-Localizing-Large-Language-Models-in-Arabic" class="headerlink" title="AceGPT, Localizing Large Language Models in Arabic"></a>AceGPT, Localizing Large Language Models in Arabic</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12053">http://arxiv.org/abs/2309.12053</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/freedomintelligence/acegpt">https://github.com/freedomintelligence/acegpt</a></li>
<li>paper_authors: Huang Huang, Fei Yu, Jianqing Zhu, Xuening Sun, Hao Cheng, Dingjie Song, Zhihong Chen, Abdulmohsen Alharthi, Bang An, Juncai He, Ziche Liu, Zhiyi Zhang, Junying Chen, Jianquan Li, Benyou Wang, Lian Zhang, Ruoyu Sun, Xiang Wan, Haizhou Li, Jinchao Xu</li>
<li>for: 本研究旨在开发一个特性化为阿拉伯语的大语言模型（LLM），以满足当前主流模型无法充分考虑的阿拉伯语文化特点。</li>
<li>methods: 该研究提出了一种全面的解决方案，包括进一步预训练阿拉伯语文本，使用本地阿拉伯语指令进行精度调整（SFT），以及使用阿拉伯语GPT-4响应和人工智能反馈学习（RLAIF）。</li>
<li>results: 研究发现，通过使用这种解决方案，可以创造出具有当地文化特点和价值观的阿拉伯语LLM，能够满足不同应用场景中的阿拉伯语使用者需求。研究表明，在不同的benchmark上，包括阿拉伯语Vicuna-80和阿拉伯语AlpacaEval等，AceGPT模型都达到了开放阿拉伯语LLM的状态标准。尤其是在使用GPT-4时，AceGPT在Vicuna-80benchmark中超过Turbo，即使这个benchmark的规模较小。代码、数据和模型可以在<a target="_blank" rel="noopener" href="https://github.com/FreedomIntelligence/AceGPT%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/FreedomIntelligence/AceGPT中找到。</a><details>
<summary>Abstract</summary>
This paper is devoted to the development of a localized Large Language Model (LLM) specifically for Arabic, a language imbued with unique cultural characteristics inadequately addressed by current mainstream models. Significant concerns emerge when addressing cultural sensitivity and local values. To address this, the paper proposes a comprehensive solution that includes further pre-training with Arabic texts, Supervised Fine-Tuning (SFT) utilizing native Arabic instructions, and GPT-4 responses in Arabic, alongside Reinforcement Learning with AI Feedback (RLAIF) employing a reward model attuned to local culture and values. The goal is to cultivate culturally cognizant and value-aligned Arabic LLMs capable of accommodating the diverse, application-specific needs of Arabic-speaking communities. Comprehensive evaluations reveal that the resulting model, dubbed 'AceGPT', sets the state-of-the-art standard for open Arabic LLMs across various benchmarks, including the instruction-following benchmark (i.e., Arabic Vicuna-80 and Arabic AlpacaEval), knowledge benchmark (i.e., Arabic MMLU and EXAMs), and the newly introduced Arabic Cultural and Value Alignment benchmark. Notably, AceGPT outperforms Turbo in the popular Vicuna-80 benchmark when evaluated with GPT-4, despite the benchmark's limited scale. Codes, data, and models are in https://github.com/FreedomIntelligence/AceGPT.
</details>
<details>
<summary>摘要</summary>
The proposed approach is evaluated on various benchmarks, including Arabic Vicuna-80 and Arabic AlpacaEval for instruction-following, Arabic MMLU and EXAMs for knowledge benchmarking, and a newly introduced Arabic Cultural and Value Alignment benchmark. The results show that the proposed model, named 'AceGPT', sets the state-of-the-art standard for open Arabic LLMs across all benchmarks. Notably, AceGPT outperforms Turbo in the popular Vicuna-80 benchmark when evaluated with GPT-4, despite the limited scale of the benchmark.The codes, data, and models used in this study are available on GitHub at <https://github.com/FreedomIntelligence/AceGPT>.
</details></li>
</ul>
<hr>
<h2 id="CAMERA-A-Multimodal-Dataset-and-Benchmark-for-Ad-Text-Generation"><a href="#CAMERA-A-Multimodal-Dataset-and-Benchmark-for-Ad-Text-Generation" class="headerlink" title="CAMERA: A Multimodal Dataset and Benchmark for Ad Text Generation"></a>CAMERA: A Multimodal Dataset and Benchmark for Ad Text Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12030">http://arxiv.org/abs/2309.12030</a></li>
<li>repo_url: None</li>
<li>paper_authors: Masato Mita, Soichiro Murakami, Akihiko Kato, Peinan Zhang<br>for: 提高自动广告文本生成（ATG）领域的研究，为它们提供一个全面的benchmark和明确的问题集，以便比较不同的方法。methods: 该研究使用了一种新的定义，即将ATG看作是跨应用领域的任务，利用多种模式的信息进行生成。具体来说，他们提出了一个首先的benchmark数据集，名为CA Multimodal Evaluation for Ad Text GeneRAtion（CAMERA），这个数据集特别地设计为ATG，以便利用多Modal信息进行评估。results: 研究人员通过多种基线模型的评估实验，证明了他们提出的benchmark和数据集的有用性。这些基线模型包括不同的预训练语言模型和多Modal信息的integration。此外，研究人员还讨论了当前任务的状态和未来的挑战。<details>
<summary>Abstract</summary>
In response to the limitations of manual online ad production, significant research has been conducted in the field of automatic ad text generation (ATG). However, comparing different methods has been challenging because of the lack of benchmarks encompassing the entire field and the absence of well-defined problem sets with clear model inputs and outputs. To address these challenges, this paper aims to advance the field of ATG by introducing a redesigned task and constructing a benchmark. Specifically, we defined ATG as a cross-application task encompassing various aspects of the Internet advertising. As part of our contribution, we propose a first benchmark dataset, CA Multimodal Evaluation for Ad Text GeneRAtion (CAMERA), carefully designed for ATG to be able to leverage multi-modal information and conduct an industry-wise evaluation. Furthermore, we demonstrate the usefulness of our proposed benchmark through evaluation experiments using multiple baseline models, which vary in terms of the type of pre-trained language model used and the incorporation of multi-modal information. We also discuss the current state of the task and the future challenges.
</details>
<details>
<summary>摘要</summary>
因为手动在线广告生产的限制，有关自动广告文本生成（ATG）的研究得到了广泛的关注。然而，不同方法的比较困难由于整个领域缺乏一个涵盖整个领域的标准准则和明确的输入输出问题集。为了解决这些挑战，本文准备了ATG领域的进步，包括将ATG定义为跨应用任务，涵盖互联网广告不同方面的多种方面。作为我们的贡献，我们提出了首个benchmark dataset，即CA Multimodal Evaluation for Ad Text GeneRAtion（CAMERA），特意设计用于ATG，以便利用多模态信息并进行产业批处。此外，我们通过多种基线模型的评估实验，表明了我们提posed benchmark的有用性。这些基线模型包括不同的预训练语言模型和多模态信息的 incorporation。我们还讨论了当前任务的状态和未来的挑战。
</details></li>
</ul>
<hr>
<h2 id="Stock-Market-Sentiment-Classification-and-Backtesting-via-Fine-tuned-BERT"><a href="#Stock-Market-Sentiment-Classification-and-Backtesting-via-Fine-tuned-BERT" class="headerlink" title="Stock Market Sentiment Classification and Backtesting via Fine-tuned BERT"></a>Stock Market Sentiment Classification and Backtesting via Fine-tuned BERT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11979">http://arxiv.org/abs/2309.11979</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiashu Lou</li>
<li>for: 这篇论文主要是为了研究基于实时信息获取的低延迟自动交易平台中的量化交易，以及如何通过情感因素提高交易效果。</li>
<li>methods: 本论文使用的方法包括BERT自然语言处理模型的建立和微调，以及基于Alpha191模型和情感标签的 regression 模型的建立。</li>
<li>results: 实验结果表明，将情感因素integrated into the Alpha191 model can significantly improve the return rate, with a return rate of 73.8% compared to the baseline and 32.41% compared to the original Alpha191 model during the trading period.<details>
<summary>Abstract</summary>
With the rapid development of big data and computing devices, low-latency automatic trading platforms based on real-time information acquisition have become the main components of the stock trading market, so the topic of quantitative trading has received widespread attention. And for non-strongly efficient trading markets, human emotions and expectations always dominate market trends and trading decisions. Therefore, this paper starts from the theory of emotion, taking East Money as an example, crawling user comment titles data from its corresponding stock bar and performing data cleaning. Subsequently, a natural language processing model BERT was constructed, and the BERT model was fine-tuned using existing annotated data sets. The experimental results show that the fine-tuned model has different degrees of performance improvement compared to the original model and the baseline model. Subsequently, based on the above model, the user comment data crawled is labeled with emotional polarity, and the obtained label information is combined with the Alpha191 model to participate in regression, and significant regression results are obtained. Subsequently, the regression model is used to predict the average price change for the next five days, and use it as a signal to guide automatic trading. The experimental results show that the incorporation of emotional factors increased the return rate by 73.8\% compared to the baseline during the trading period, and by 32.41\% compared to the original alpha191 model. Finally, we discuss the advantages and disadvantages of incorporating emotional factors into quantitative trading, and give possible directions for further research in the future.
</details>
<details>
<summary>摘要</summary>
随着大数据和计算设备的快速发展，基于实时信息获取的快速交易平台已成为股票交易市场的主要组成部分，因此量化交易的话题得到了广泛的关注。而在非强效交易市场中，人类情感和期望总是主宰市场趋势和交易决策。因此，本文从情感理论出发，使用东方财富为例，从其相应股票板块中提取用户评论标题数据，并进行数据清洁。然后，构建了一个自然语言处理模型BERT，并使用现有的标注数据集进行微调。实验结果显示，微调后的模型具有不同程度的性能改进。然后，根据上述模型，用户评论数据被标注为情感方向，并将所获取的标签信息与Alpha191模型组合使用进行回归，并获得了显著的回归结果。然后，使用回归模型预测下一个五天内的均价变化，并使其为自动交易的指导信号。实验结果表明，包含情感因素的 incorporation 提高了基线期间的回报率73.8%，并比原始 Alpha191 模型提高32.41%。最后，我们讨论了包含情感因素的量化交易的优缺点，并提出了未来研究的可能性。
</details></li>
</ul>
<hr>
<h2 id="SPICED-News-Similarity-Detection-Dataset-with-Multiple-Topics-and-Complexity-Levels"><a href="#SPICED-News-Similarity-Detection-Dataset-with-Multiple-Topics-and-Complexity-Levels" class="headerlink" title="SPICED: News Similarity Detection Dataset with Multiple Topics and Complexity Levels"></a>SPICED: News Similarity Detection Dataset with Multiple Topics and Complexity Levels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13080">http://arxiv.org/abs/2309.13080</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elena Shushkevich, Long Mai, Manuel V. Loureiro, Steven Derby, Tri Kurniawan Wijaya<br>for: 这个论文的目的是提出一个新的新闻相似性数据集，以及四种生成新闻对的方法，以便进行新闻相似性检测任务的训练。methods: 这个论文使用了七个话题来分类新闻，并使用了四种不同的方法来生成新闻对。这些方法包括文本摘要、文本分类、命名实体识别和文本对比。results: 研究人员使用了MinHash、BERT、SBERT和SimCSE模型对创建的数据集进行了测试，并获得了良好的结果。这些模型可以准确地检测新闻的相似性，并且可以在不同的话题下进行更加精准的检测。<details>
<summary>Abstract</summary>
Nowadays, the use of intelligent systems to detect redundant information in news articles has become especially prevalent with the proliferation of news media outlets in order to enhance user experience. However, the heterogeneous nature of news can lead to spurious findings in these systems: Simple heuristics such as whether a pair of news are both about politics can provide strong but deceptive downstream performance. Segmenting news similarity datasets into topics improves the training of these models by forcing them to learn how to distinguish salient characteristics under more narrow domains. However, this requires the existence of topic-specific datasets, which are currently lacking. In this article, we propose a new dataset of similar news, SPICED, which includes seven topics: Crime & Law, Culture & Entertainment, Disasters & Accidents, Economy & Business, Politics & Conflicts, Science & Technology, and Sports. Futhermore, we present four distinct approaches for generating news pairs, which are used in the creation of datasets specifically designed for news similarity detection task. We benchmarked the created datasets using MinHash, BERT, SBERT, and SimCSE models.
</details>
<details>
<summary>摘要</summary>
现在，使用智能系统检测新闻文章中的重复信息已经非常普遍，这是因为新闻媒体的扩展而为用户提供更好的体验。然而，新闻的多样性可能会导致假阳性结果：简单的规则 such as 两个新闻都是关于政治的话可以提供强大 pero 误导的下游性能。将新闻相似度数据集分成话题可以使模型学习更窄的领域中的突出特征。然而，这需要话题特定的数据集的存在，现在它们缺失。在这篇文章中，我们提出了一个新的相似新闻数据集，名为SPICED，包括七个话题：犯罪与法律、文化与娱乐、灾难与事故、经济与业务、政治与冲突、科学与技术，和体育。此外，我们提出了四种不同的新闻对生成方法，用于创建专门用于新闻相似度检测任务的数据集。我们使用MinHash、BERT、SBERT和SimCSE模型对创建的数据集进行了benchmark测试。
</details></li>
</ul>
<hr>
<h2 id="Scaling-up-COMETKIWI-Unbabel-IST-2023-Submission-for-the-Quality-Estimation-Shared-Task"><a href="#Scaling-up-COMETKIWI-Unbabel-IST-2023-Submission-for-the-Quality-Estimation-Shared-Task" class="headerlink" title="Scaling up COMETKIWI: Unbabel-IST 2023 Submission for the Quality Estimation Shared Task"></a>Scaling up COMETKIWI: Unbabel-IST 2023 Submission for the Quality Estimation Shared Task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11925">http://arxiv.org/abs/2309.11925</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ricardo Rei, Nuno M. Guerreiro, José Pombal, Daan van Stigt, Marcos Treviso, Luisa Coheur, José G. C. de Souza, André F. T. Martins</li>
<li>for: 这个论文参与了WMT 2023共同任务中的质量估计（QE）任务。</li>
<li>methods: 作者使用了COMETKIWI-22模型（Rei et al., 2022b），并采用了多语言方法。</li>
<li>results: 作者的方法在所有任务上排名第一，并达到了 sentence-和 word-level 质量预测的状态机器人表现。  Comparing to the previous state-of-the-art COMETKIWI-22, the authors show large improvements in correlation with human judgements (up to 10 Spearman points) and surpass the second-best multilingual submission to the shared-task with up to 3.8 absolute points.<details>
<summary>Abstract</summary>
We present the joint contribution of Unbabel and Instituto Superior T\'ecnico to the WMT 2023 Shared Task on Quality Estimation (QE). Our team participated on all tasks: sentence- and word-level quality prediction (task 1) and fine-grained error span detection (task 2). For all tasks, we build on the COMETKIWI-22 model (Rei et al., 2022b). Our multilingual approaches are ranked first for all tasks, reaching state-of-the-art performance for quality estimation at word-, span- and sentence-level granularity. Compared to the previous state-of-the-art COMETKIWI-22, we show large improvements in correlation with human judgements (up to 10 Spearman points). Moreover, we surpass the second-best multilingual submission to the shared-task with up to 3.8 absolute points.
</details>
<details>
<summary>摘要</summary>
我们现在把Unbabel和 Instituto Superior Técnico在WMT 2023共同任务中的贡献介绍。我们的团队参与了所有任务：句子和单词水平质量预测（任务1）以及细化错误探测（任务2）。对于所有任务，我们基于COMETKIWI-22模型（Rei等., 2022b）。我们的多语言方法在所有任务上排名第一，达到了质量预测的州际先进性水平。相比前一个州际先进COMETKIWI-22，我们显示了大幅提升与人类评估的相关度（最多10个斯宾塞分）。此外，我们超过了第二好的多语言提交到共同任务，差值最多3.8个绝对分。
</details></li>
</ul>
<hr>
<h2 id="InstructERC-Reforming-Emotion-Recognition-in-Conversation-with-a-Retrieval-Multi-task-LLMs-Framework"><a href="#InstructERC-Reforming-Emotion-Recognition-in-Conversation-with-a-Retrieval-Multi-task-LLMs-Framework" class="headerlink" title="InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework"></a>InstructERC: Reforming Emotion Recognition in Conversation with a Retrieval Multi-task LLMs Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11911">http://arxiv.org/abs/2309.11911</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/LIN-SHANG/InstructERC">https://github.com/LIN-SHANG/InstructERC</a></li>
<li>paper_authors: Shanglin Lei, Guanting Dong, Xiaoping Wang, Keheng Wang, Sirui Wang</li>
<li>for:  This paper aims to improve the development of emotion recognition in dialogue (ERC) by proposing a novel approach called InstructERC, which transforms the ERC task from a discriminative framework to a generative framework based on Large Language Models (LLMs).</li>
<li>methods:  The proposed InstructERC approach uses a simple yet effective retrieval template module to explicitly integrate multi-granularity dialogue supervision information, as well as two additional emotion alignment tasks (speaker identification and emotion prediction) to implicitly model dialogue role relationships and future emotional tendencies.</li>
<li>results:  The LLM-based plug-and-play plugin framework achieved comprehensive SOTA on three commonly used ERC datasets, outperforming all previous models. Extensive analysis of parameter-efficient and data-scaling experiments provide empirical guidance for applying InstructERC in practical scenarios.<details>
<summary>Abstract</summary>
The development of emotion recognition in dialogue (ERC) has been consistently hindered by the complexity of pipeline designs, leading to ERC models that often overfit to specific datasets and dialogue patterns. In this study, we propose a novel approach, namely   InstructERC, to reformulates the ERC task from a discriminative framework to a generative framework based on Large Language Models (LLMs) . InstructERC has two significant contributions: Firstly, InstructERC introduces a simple yet effective retrieval template module, which helps the model explicitly integrate multi-granularity dialogue supervision information by concatenating the historical dialog content, label statement, and emotional domain demonstrations with high semantic similarity. Furthermore, we introduce two additional emotion alignment tasks, namely speaker identification and emotion prediction tasks, to implicitly model the dialogue role relationships and future emotional tendencies in conversations. Our LLM-based plug-and-play plugin framework significantly outperforms all previous models and achieves comprehensive SOTA on three commonly used ERC datasets. Extensive analysis of parameter-efficient and data-scaling experiments provide empirical guidance for applying InstructERC in practical scenarios. Our code will be released after blind review.
</details>
<details>
<summary>摘要</summary>
开发对话情感识别（ERC）技术一直受到管道设计的复杂性限制，导致ERC模型经常过拟合特定数据集和对话模式。在这项研究中，我们提出了一种新的方法，即InstructERC，它将ERC任务从推断性框架转换为生成性框架，基于大语言模型（LLM）。InstructERC具有两项重要贡献：首先，InstructERC引入了一种简单 yet有效的检索模板模块，该模块通过 concatenating 历史对话内容、标签声明和情感领域示例来显式地集成多级别对话监督信息。其次，我们引入了两个附加的情感对接任务，即发言人标识和情感预测任务，以隐式地模型对话角色关系和未来情感趋势在对话中。我们的 LLM 基于插件框架在三个常用的 ERC 数据集上实现了广泛的 SOTA 性能。我们进行了参数高效和数据扩展的实验分析，以提供实践场景中应用 InstructERC 的经验指南。我们的代码将在审核后发布。
</details></li>
</ul>
<hr>
<h2 id="Focal-Inferential-Infusion-Coupled-with-Tractable-Density-Discrimination-for-Implicit-Hate-Speech-Detection"><a href="#Focal-Inferential-Infusion-Coupled-with-Tractable-Density-Discrimination-for-Implicit-Hate-Speech-Detection" class="headerlink" title="Focal Inferential Infusion Coupled with Tractable Density Discrimination for Implicit Hate Speech Detection"></a>Focal Inferential Infusion Coupled with Tractable Density Discrimination for Implicit Hate Speech Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11896">http://arxiv.org/abs/2309.11896</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lcs2-iiitd/fiadd">https://github.com/lcs2-iiitd/fiadd</a></li>
<li>paper_authors: Sarah Masud, Ashutosh Bajpai, Tanmoy Chakraborty</li>
<li>for: 本研究旨在提高大型自然语言处理模型（PLM）对含有潜在仇恨语言表达的文本识别能力。</li>
<li>methods: 本研究使用了增强外部 контекст和距离基本metric的两种方法，并将其组合成为新的FOCUSED INFERENTIAL ADAPTIVE DENSITY DISCRIMINATION（FiADD）框架。</li>
<li>results: 对三个隐式仇恨数据集进行测试，FiADD显示出了明显的提高在两类和三类仇恨分类任务中。此外，在检测讽刺、反讽和立场表达中，FiADD也显示出类似的性能提高。<details>
<summary>Abstract</summary>
Although pre-trained large language models (PLMs) have achieved state-of-the-art on many NLP tasks, they lack understanding of subtle expressions of implicit hate speech. Such nuanced and implicit hate is often misclassified as non-hate. Various attempts have been made to enhance the detection of (implicit) hate content by augmenting external context or enforcing label separation via distance-based metrics. We combine these two approaches and introduce FiADD, a novel Focused Inferential Adaptive Density Discrimination framework. FiADD enhances the PLM finetuning pipeline by bringing the surface form of an implicit hate speech closer to its implied form while increasing the inter-cluster distance among various class labels. We test FiADD on three implicit hate datasets and observe significant improvement in the two-way and three-way hate classification tasks. We further experiment on the generalizability of FiADD on three other tasks, namely detecting sarcasm, irony, and stance, in which surface and implied forms differ, and observe similar performance improvement. We analyze the generated latent space to understand its evolution under FiADD, which corroborates the advantage of employing FiADD for implicit hate speech detection.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose a novel Focused Inferential Adaptive Density Discrimination (FiADD) framework that combines these two approaches to enhance the PLM finetuning pipeline. FiADD brings the surface form of an implicit hate speech closer to its implied form while increasing the inter-cluster distance among various class labels. We test FiADD on three implicit hate datasets and observe significant improvement in the two-way and three-way hate classification tasks.Furthermore, we experiment on the generalizability of FiADD on three other tasks, namely detecting sarcasm, irony, and stance, in which surface and implied forms differ. We observe similar performance improvement, indicating the versatility of FiADD. We analyze the generated latent space to understand its evolution under FiADD, which corroborates the advantage of employing FiADD for implicit hate speech detection.
</details></li>
</ul>
<hr>
<h2 id="Is-It-Really-Useful-to-Jointly-Parse-Constituency-and-Dependency-Trees-A-Revisit"><a href="#Is-It-Really-Useful-to-Jointly-Parse-Constituency-and-Dependency-Trees-A-Revisit" class="headerlink" title="Is It Really Useful to Jointly Parse Constituency and Dependency Trees? A Revisit"></a>Is It Really Useful to Jointly Parse Constituency and Dependency Trees? A Revisit</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11888">http://arxiv.org/abs/2309.11888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanggang Gu, Yang Hou, Zhefeng Wang, Xinyu Duan, Zhenghua Li</li>
<li>for: 这个论文关注 JOIN 分析 sentence 中的 Constituency 树和 Dependency 树，即同时生成兼容的 Constituency 树和 Dependency 树。</li>
<li>methods: 该论文使用了更高效的解码算法，在训练阶段进行 JOIN 模型化，并提出了高阶分数组件来捕捉 Constituent-Dependency 之间的交互。</li>
<li>results: 论文在各种实验和分析中做出了四个方面的进步：1）更高效的解码算法，2）在训练阶段进行 JOIN 模型化，3）提出了高阶分数组件，4）通过深入的实验和分析获得了更多的启示。<details>
<summary>Abstract</summary>
This work visits the topic of jointly parsing constituency and dependency trees, i.e., to produce compatible constituency and dependency trees simultaneously for input sentences, which is attractive considering that the two types of trees are complementary in representing syntax. Compared with previous works, we make progress in four aspects: (1) adopting a much more efficient decoding algorithm, (2) exploring joint modeling at the training phase, instead of only at the inference phase, (3) proposing high-order scoring components for constituent-dependency interaction, (4) gaining more insights via in-depth experiments and analysis.
</details>
<details>
<summary>摘要</summary>
这个工作探讨了同时解析成分树和依赖树的问题，即为输入句子生成兼容的成分树和依赖树，这是吸引人的，因为这两种树是Syntax的补充。相比前一些工作，我们在四个方面进行了进步：（1）采用更高效的解码算法，（2）在训练阶段进行共同模型化，而不仅在推理阶段进行，（3）提出高阶分数组件来描述成分-依赖之间的互动，（4）通过深入实验和分析获得更多的发现。
</details></li>
</ul>
<hr>
<h2 id="Syntactic-Variation-Across-the-Grammar-Modelling-a-Complex-Adaptive-System"><a href="#Syntactic-Variation-Across-the-Grammar-Modelling-a-Complex-Adaptive-System" class="headerlink" title="Syntactic Variation Across the Grammar: Modelling a Complex Adaptive System"></a>Syntactic Variation Across the Grammar: Modelling a Complex Adaptive System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11869">http://arxiv.org/abs/2309.11869</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonathan Dunn</li>
<li>for: 本研究旨在量化语言系统中的变化，通过对49个本地英语语言变体的分类来描述语音变体之间的 sintactic 差异。</li>
<li>methods: 本研究使用了整个语法和各个语法结构之间的隔离来分类语音变体。</li>
<li>results: 结果表明，语音变体中的各个结构都存在变化，但在孤立的情况下，没有任何结构能够与整个语法一样好。这表明，语音变体中的变化部分由不同语法结构之间的交互所组成。此外，研究还发现，在不同语法结构下，语音变体之间的相似性很大。<details>
<summary>Abstract</summary>
While language is a complex adaptive system, most work on syntactic variation observes a few individual constructions in isolation from the rest of the grammar. This means that the grammar, a network which connects thousands of structures at different levels of abstraction, is reduced to a few disconnected variables. This paper quantifies the impact of such reductions by systematically modelling dialectal variation across 49 local populations of English speakers in 16 countries. We perform dialect classification with both an entire grammar as well as with isolated nodes within the grammar in order to characterize the syntactic differences between these dialects. The results show, first, that many individual nodes within the grammar are subject to variation but, in isolation, none perform as well as the grammar as a whole. This indicates that an important part of syntactic variation consists of interactions between different parts of the grammar. Second, the results show that the similarity between dialects depends heavily on the sub-set of the grammar being observed: for example, New Zealand English could be more similar to Australian English in phrasal verbs but at the same time more similar to UK English in dative phrases.
</details>
<details>
<summary>摘要</summary>
语言是一个复杂的适应系统，大多数语法变化研究通常只关注几个个体结构，忽略了语法 grammar 中其他结构之间的关系。这意味着语法网络，连接了数千个结构，被压缩成只有几个分离的变量。这篇论文测量了这种压缩的影响，通过对49个本地英语口语者群体在16个国家的语言变化进行系统性模型。我们使用整个语法以及语法中各个节点的隔离来分类方言，以Characterize语言变化的 sintactic differences。结果显示，首先，语法中很多个节点都存在变化，但是孤立地没有达到语法整体的水平。这表明，语法变化中有很重要的互动部分。其次，结果显示，对于不同的语言变化，相似性很大程度取决于观察到的语法子集。例如，新西兰英语可能与澳大利亚英语在短语动词方面更相似，而在 dative phrases 方面更相似于 UK 英语。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-Sanitization-of-Large-Language-Models"><a href="#Knowledge-Sanitization-of-Large-Language-Models" class="headerlink" title="Knowledge Sanitization of Large Language Models"></a>Knowledge Sanitization of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11852">http://arxiv.org/abs/2309.11852</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yoichi Ishibashi, Hidetoshi Shimodaira</li>
<li>for: 防止语言模型泄露敏感信息</li>
<li>methods: 精细调整语言模型，让其生成无害回答</li>
<li>results: 实验结果表明，该方法不仅减少了特定知识泄露，还保持了语言模型的总性能，从而增强了防止抽取攻击和避免生成危险内容的防御。<details>
<summary>Abstract</summary>
We explore a knowledge sanitization approach to mitigate the privacy concerns associated with large language models (LLMs). LLMs trained on a large corpus of Web data can memorize and potentially reveal sensitive or confidential information, raising critical security concerns. Our technique fine-tunes these models, prompting them to generate harmless responses such as ``I don't know'' when queried about specific information. Experimental results in a closed-book question-answering task show that our straightforward method not only minimizes particular knowledge leakage but also preserves the overall performance of LLM. These two advantages strengthen the defense against extraction attacks and reduces the emission of harmful content such as hallucinations.
</details>
<details>
<summary>摘要</summary>
我们研究了一种知识净化方法，以降低大语言模型（LLM）中的隐私问题。 LLM 通过大量网络数据训练可能会记忆和泄露敏感或机密信息，这引起了严重的安全问题。我们的技术在这些模型中进行微调，使其在特定信息 queries 时生成无害的回答，如“我不知道”。实验结果表明，我们的简单方法不仅减少了特定知识泄露，还保持了 LLM 的总性能。这两个优点强化了对抽取攻击的防御和减少了负面内容的泄露，如幻见。
</details></li>
</ul>
<hr>
<h2 id="A-Discourse-level-Multi-scale-Prosodic-Model-for-Fine-grained-Emotion-Analysis"><a href="#A-Discourse-level-Multi-scale-Prosodic-Model-for-Fine-grained-Emotion-Analysis" class="headerlink" title="A Discourse-level Multi-scale Prosodic Model for Fine-grained Emotion Analysis"></a>A Discourse-level Multi-scale Prosodic Model for Fine-grained Emotion Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11849">http://arxiv.org/abs/2309.11849</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xianhao Wei, Jia Jia, Xiang Li, Zhiyong Wu, Ziyi Wang</li>
<li>for: 这个研究旨在预测基于话语水平的细腻情感特征，以提高语音合成模型的表达性。</li>
<li>methods: 该研究使用了一种Style Transfer模型提取phoneme-level Local Prosody Embedding序列和全局风格嵌入，并提出了一种多级文本预测模型（D-MPM）来预测这两个情感特征。</li>
<li>results: 实验结果表明，多级文本信息有效地预测情感特征，并且话语水平提高了整体一致性和用户体验。而且，由于预测模型的合成效果比原始speech的风格传递效果更好，这种方法可能有助于语音合成模型更好地表达情感。<details>
<summary>Abstract</summary>
This paper explores predicting suitable prosodic features for fine-grained emotion analysis from the discourse-level text. To obtain fine-grained emotional prosodic features as predictive values for our model, we extract a phoneme-level Local Prosody Embedding sequence (LPEs) and a Global Style Embedding as prosodic speech features from the speech with the help of a style transfer model. We propose a Discourse-level Multi-scale text Prosodic Model (D-MPM) that exploits multi-scale text to predict these two prosodic features. The proposed model can be used to analyze better emotional prosodic features and thus guide the speech synthesis model to synthesize more expressive speech. To quantitatively evaluate the proposed model, we contribute a new and large-scale Discourse-level Chinese Audiobook (DCA) dataset with more than 13,000 utterances annotated sequences to evaluate the proposed model. Experimental results on the DCA dataset show that the multi-scale text information effectively helps to predict prosodic features, and the discourse-level text improves both the overall coherence and the user experience. More interestingly, although we aim at the synthesis effect of the style transfer model, the synthesized speech by the proposed text prosodic analysis model is even better than the style transfer from the original speech in some user evaluation indicators.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)这篇论文探讨了基于干支文本的细腻情感分析中适用的语音特征预测方法。为了获得更好的情感语音特征预测值，我们从语音中提取了phoneme级别的本地语音嵌入序列（LPEs）和全局风格嵌入作为语音特征特征。我们提议一种基于多级文本的语音谱proboscis模型（D-MPM），利用多级文本来预测这两个语音特征。该模型可以用来分析更好的情感语音特征，并且导引语音合成模型生成更加表达的语音。为了评估该模型，我们提供了一个大规模的Discourse-level Chinese Audiobook（DCA）数据集，包含 более than 13,000个语音短语序列。实验结果表明，多级文本信息有效地预测语音特征，并且提高了整体准确率和用户体验。而且，尽管我们target的是style transfer模型的合成效果，但是由提posed的文本语音分析模型生成的语音还是在一些用户评估指标上更好于原始语音的style transfer。
</details></li>
</ul>
<hr>
<h2 id="A-Chinese-Prompt-Attack-Dataset-for-LLMs-with-Evil-Content"><a href="#A-Chinese-Prompt-Attack-Dataset-for-LLMs-with-Evil-Content" class="headerlink" title="A Chinese Prompt Attack Dataset for LLMs with Evil Content"></a>A Chinese Prompt Attack Dataset for LLMs with Evil Content</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11830">http://arxiv.org/abs/2309.11830</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengyuan Liu, Fubang Zhao, Lizhi Qing, Yangyang Kang, Changlong Sun, Kun Kuang, Fei Wu</li>
<li>for: 本研究旨在提供一个中文提示攻击数据集（CPAD），用于评估语言模型（LLMs）对提示攻击的抵御能力。</li>
<li>methods: 我们采用了多种攻击方法，包括提示攻击、恶意提示和目标攻击，以评估LLMs的安全性。</li>
<li>results: 我们运行了多个常见的中文LLMs在我们的数据集上，结果显示，我们的提示能够让LLMs失败，成功率约为70%。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) present significant priority in text understanding and generation. However, LLMs suffer from the risk of generating harmful contents especially while being employed to applications. There are several black-box attack methods, such as Prompt Attack, which can change the behaviour of LLMs and induce LLMs to generate unexpected answers with harmful contents. Researchers are interested in Prompt Attack and Defense with LLMs, while there is no publicly available dataset to evaluate the abilities of defending prompt attack. In this paper, we introduce a Chinese Prompt Attack Dataset for LLMs, called CPAD. Our prompts aim to induce LLMs to generate unexpected outputs with several carefully designed prompt attack approaches and widely concerned attacking contents. Different from previous datasets involving safety estimation, We construct the prompts considering three dimensions: contents, attacking methods and goals, thus the responses can be easily evaluated and analysed. We run several well-known Chinese LLMs on our dataset, and the results show that our prompts are significantly harmful to LLMs, with around 70% attack success rate. We will release CPAD to encourage further studies on prompt attack and defense.
</details>
<details>
<summary>摘要</summary>
大语言模型（LLM）在文本理解和生成方面具有重要优先级。然而，LLM受到生成危险内容的风险，特别是在应用程序中使用时。现有许多黑盒攻击方法，如提示攻击，可以改变LLM的行为，使其生成意外的答案并含有危险内容。研究人员对提示攻击和LLM防御有浓厚的兴趣，但是现无公共可用的数据集来评估防御能力。在这篇论文中，我们介绍了一个中文提示攻击数据集（CPAD），用于测试LLM的防御能力。我们的提示采用三维构造：内容、攻击方法和目标，因此可以轻松地评估和分析回快。我们使用了一些知名的中文LLM在我们的数据集上进行测试，结果显示，我们的提示能够够Effectively harm LLMs，成功率约为70%。我们将CPAD公开发布，以便更多的研究人员可以进行提示攻击和防御研究。
</details></li>
</ul>
<hr>
<h2 id="Word-Embedding-with-Neural-Probabilistic-Prior"><a href="#Word-Embedding-with-Neural-Probabilistic-Prior" class="headerlink" title="Word Embedding with Neural Probabilistic Prior"></a>Word Embedding with Neural Probabilistic Prior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11824">http://arxiv.org/abs/2309.11824</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shaogang Ren, Dingcheng Li, Ping Li</li>
<li>for: 提高单词表示学习的词表示学习</li>
<li>methods: 使用概率先验来规范词表示学习</li>
<li>results: 提高了单词表示学习的表示精度和模型的稳定性<details>
<summary>Abstract</summary>
To improve word representation learning, we propose a probabilistic prior which can be seamlessly integrated with word embedding models. Different from previous methods, word embedding is taken as a probabilistic generative model, and it enables us to impose a prior regularizing word representation learning. The proposed prior not only enhances the representation of embedding vectors but also improves the model's robustness and stability. The structure of the proposed prior is simple and effective, and it can be easily implemented and flexibly plugged in most existing word embedding models. Extensive experiments show the proposed method improves word representation on various tasks.
</details>
<details>
<summary>摘要</summary>
为了提高词表示学习，我们提议一种概率先验，可以轻松地与词嵌入模型结合使用。与先前的方法不同，在我们的方法中，词嵌入被看作是一种概率生成模型，这使得我们可以对词表示学习强制一个先验。我们提出的先验不仅提高了嵌入向量的表示，还改善了模型的稳定性和鲁棒性。该结构简单而有效，可以轻松地实现并适应大多数现有的词嵌入模型。我们的实验结果表明，我们的方法可以在各种任务上提高词表示。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="SLHCat-Mapping-Wikipedia-Categories-and-Lists-to-DBpedia-by-Leveraging-Semantic-Lexical-and-Hierarchical-Features"><a href="#SLHCat-Mapping-Wikipedia-Categories-and-Lists-to-DBpedia-by-Leveraging-Semantic-Lexical-and-Hierarchical-Features" class="headerlink" title="SLHCat: Mapping Wikipedia Categories and Lists to DBpedia by Leveraging Semantic, Lexical, and Hierarchical Features"></a>SLHCat: Mapping Wikipedia Categories and Lists to DBpedia by Leveraging Semantic, Lexical, and Hierarchical Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11791">http://arxiv.org/abs/2309.11791</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhaoyi Wang, Zhenyang Zhang, Jiaxin Qin, Mizuho Iwaihara</li>
<li>for: 提高 DBpedia 类型对 CaLiGraph 分类的准确率，实现大规模 Ontology 映射。</li>
<li>methods: 利用知识图结构、语义相似性和命名实体类型，自动生成训练数据，并使用 distant supervision 方法finetune 预训练语言模型 BERT。</li>
<li>results: 比基eline模型提高25%的准确率，提供实用的大规模 Ontology 映射解决方案。<details>
<summary>Abstract</summary>
Wikipedia articles are hierarchically organized through categories and lists, providing one of the most comprehensive and universal taxonomy, but its open creation is causing redundancies and inconsistencies. Assigning DBPedia classes to Wikipedia categories and lists can alleviate the problem, realizing a large knowledge graph which is essential for categorizing digital contents through entity linking and typing. However, the existing approach of CaLiGraph is producing incomplete and non-fine grained mappings. In this paper, we tackle the problem as ontology alignment, where structural information of knowledge graphs and lexical and semantic features of ontology class names are utilized to discover confident mappings, which are in turn utilized for finetuing pretrained language models in a distant supervision fashion. Our method SLHCat consists of two main parts: 1) Automatically generating training data by leveraging knowledge graph structure, semantic similarities, and named entity typing. 2) Finetuning and prompt-tuning of the pre-trained language model BERT are carried out over the training data, to capture semantic and syntactic properties of class names. Our model SLHCat is evaluated over a benchmark dataset constructed by annotating 3000 fine-grained CaLiGraph-DBpedia mapping pairs. SLHCat is outperforming the baseline model by a large margin of 25% in accuracy, offering a practical solution for large-scale ontology mapping.
</details>
<details>
<summary>摘要</summary>
《Wikipedia文章是以类别和列表的形式归类，提供了一个非常全面和通用的分类系统，但开放创建的问题导致了重复和不一致。将DBpedia类划到Wikipedia类划和列表上可以解决这个问题，实现一个大型知识图，对涉及到数字内容的分类进行Entity链接和类型化。然而，现有的CaLiGraph方法 produces incomplete and non-fine-grained mappings。在这篇论文中，我们将这个问题看作ontology alignment，利用知识图的结构信息和ontology类名的语义和语义特征，对可信的映射进行发现，并在远程监督方式下使用预训练语言模型BERT进行训练。我们的方法SLHCat包括两个主要部分：1. 利用知识图结构、语义相似度和命名实体类型自动生成训练数据。2. 使用训练数据进行finetuning和prompt-tuning预训练语言模型BERT，以捕捉类名的语义和语法性质。我们的模型SLHCat在一个由CaLiGraph-DBpedia映射对的3000个精细标注 dataset上进行评估，与基准模型相比，SLHCat在准确率上出现25%的大幅提升，提供了一个实用的大规模ontology映射解决方案。
</details></li>
</ul>
<hr>
<h2 id="ContextRef-Evaluating-Referenceless-Metrics-For-Image-Description-Generation"><a href="#ContextRef-Evaluating-Referenceless-Metrics-For-Image-Description-Generation" class="headerlink" title="ContextRef: Evaluating Referenceless Metrics For Image Description Generation"></a>ContextRef: Evaluating Referenceless Metrics For Image Description Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11710">http://arxiv.org/abs/2309.11710</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/elisakreiss/contextref">https://github.com/elisakreiss/contextref</a></li>
<li>paper_authors: Elisa Kreiss, Eric Zelikman, Christopher Potts, Nick Haber</li>
<li>for: 这 paper 的目的是评估无参考度量表（CLIPScore）的准确性，以及这些方法是否与人类偏好相符。</li>
<li>methods: 该 paper 使用 ContextRef  benchmark，该 benchmark 包括人类评分和多种稳定性检查，以评估无参考度量表的准确性。</li>
<li>results: 研究发现，无参考度量表方法在 ContextRef  benchmark 上表现不佳，但通过精心微调可以得到显著改进。<details>
<summary>Abstract</summary>
Referenceless metrics (e.g., CLIPScore) use pretrained vision--language models to assess image descriptions directly without costly ground-truth reference texts. Such methods can facilitate rapid progress, but only if they truly align with human preference judgments. In this paper, we introduce ContextRef, a benchmark for assessing referenceless metrics for such alignment. ContextRef has two components: human ratings along a variety of established quality dimensions, and ten diverse robustness checks designed to uncover fundamental weaknesses. A crucial aspect of ContextRef is that images and descriptions are presented in context, reflecting prior work showing that context is important for description quality. Using ContextRef, we assess a variety of pretrained models, scoring functions, and techniques for incorporating context. None of the methods is successful with ContextRef, but we show that careful fine-tuning yields substantial improvements. ContextRef remains a challenging benchmark though, in large part due to the challenge of context dependence.
</details>
<details>
<summary>摘要</summary>
无参考度量（例如CLIPScore）使用预训练视觉语言模型直接评估图文描述，无需费时的参照文本。这些方法可以促进快速进步，但只有如果它们真正对人类偏好判断 align。在这篇文章中，我们介绍ContextRef，一个用于评估无参考度量的benchmark。ContextRef有两个组成部分：人类评分的多种已知质量维度，以及十种多样化的Robustness Check，用于暴露基础的弱点。ContextRef中的图文都会在上下文中展示，这与先前的工作表明上下文对描述质量很重要。使用ContextRef，我们评估了多种预训练模型、分数函数和 Context 的技术。 none of them 在ContextRef中成功，但我们显示了仔细的微调可以实现显著提高。ContextRef仍然是一个挑战性的benchmark，主要是因为上下文依赖性的挑战。
</details></li>
</ul>
<hr>
<h2 id="Memory-Augmented-LLM-Personalization-with-Short-and-Long-Term-Memory-Coordination"><a href="#Memory-Augmented-LLM-Personalization-with-Short-and-Long-Term-Memory-Coordination" class="headerlink" title="Memory-Augmented LLM Personalization with Short- and Long-Term Memory Coordination"></a>Memory-Augmented LLM Personalization with Short- and Long-Term Memory Coordination</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11696">http://arxiv.org/abs/2309.11696</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kai Zhang, Fubang Zhao, Yangyang Kang, Xiaozhong Liu</li>
<li>for: 这个研究旨在提高大语言模型（LLM）的个性化生成能力，以提高用户特定的结果。</li>
<li>methods: 该研究提出了一种新的计算机биологиMemory机制，结合高效的参数调整方案，以个性化LLM。</li>
<li>results: 实验结果表明，该方法能够有效地提高LLM的个性化生成能力，并且超过了之前的方法。<details>
<summary>Abstract</summary>
Large Language Models (LLMs), such as GPT3.5, have exhibited remarkable proficiency in comprehending and generating natural language. However, their unpersonalized generation paradigm may result in suboptimal user-specific outcomes. Typically, users converse differently based on their knowledge and preferences. This necessitates the task of enhancing user-oriented LLM which remains unexplored. While one can fully train an LLM for this objective, the resource consumption is unaffordable. Prior research has explored memory-based methods to store and retrieve knowledge to enhance generation without retraining for new queries. However, we contend that a mere memory module is inadequate to comprehend a user's preference, and fully training an LLM can be excessively costly. In this study, we propose a novel computational bionic memory mechanism, equipped with a parameter-efficient fine-tuning schema, to personalize LLMs. Our extensive experimental results demonstrate the effectiveness and superiority of the proposed approach. To encourage further research into this area, we are releasing a new conversation dataset generated entirely by LLM based on an open-source medical corpus, as well as our implementation code.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "Large Language Models" is translated as "大型语言模型" (dàxíng yǔyán módelǐ)* "such as GPT3.5" is translated as "如GPT3.5" (rú GPT3.5)* "unpersonalized generation paradigm" is translated as "无个性生成模式" (wú gèxìng shēngchén móde)* "users converse differently based on their knowledge and preferences" is translated as "用户根据知识和偏好不同地交流" (yòngzhì jīngguī jīntiān bùdìng de jiāoxìng)* "this necessitates the task of enhancing user-oriented LLM" is translated as "这需要提高用户指向的LLM任务" (zhè xūyào tímiaokè yǐngyì LLM zhìwù)* "while one can fully train an LLM for this objective" is translated as "可以完全训练LLM以实现这个目标" (kěyǐ qiánzhèng xùntraining LLM yǐ jízhèng zhè ge mùtiān)* "the resource consumption is unaffordable" is translated as "资源消耗不可持续" (zīyuàn xiāohuò bùkěcháng)* "prior research has explored memory-based methods" is translated as "先前的研究曾经探索了记忆基于的方法" (xiānpjàn de yánjiū zhèngjīn tànsuō le jiěyì bázhì de fāngché)* "a mere memory module is inadequate to comprehend a user's preference" is translated as "简单的记忆模块无法理解用户的偏好" (jiǎndān de jiěyì móudāo wúfāng lǐjiě yǐngyì yòu zhèngxìng)* "fully training an LLM can be excessively costly" is translated as "完全训练LLM的成本过高" (qióngzhèng xùntraining LLM de zhèngběn guògāo)* "in this study, we propose a novel computational bionic memory mechanism" is translated as "在本研究中，我们提出了一种新的计算机bone植入记忆机制" (zhèng yàn yánjiū zhōng, wǒmen tìshì le yī zhī xīn de jìsuàn zhīyìng jīfāng)* "equipped with a parameter-efficient fine-tuning schema" is translated as "配备有效率精度调整方案" (fùyè yǒu xiǎngyì liàngdào fāng'àn)* "to personalize LLMs" is translated as "为LLM个性化" (wèi LLM yīngróng huà)* "our extensive experimental results demonstrate the effectiveness and superiority of the proposed approach" is translated as "我们广泛的实验结果表明我们提出的方法的有效性和优势" (wǒmen guǎngfāng de shíyàn jīngqì bùmíng wǒmen tìshì le fāngché de yǒu xìngxìng)* "to encourage further research in this area" is translated as "以促进这一领域的进一步研究" (yǐ jìnshì zhè yī lǐng yè, jìnshì zhè yī jìng yè)
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/21/cs.CL_2023_09_21/" data-id="cloqtaeoy00bqgh8810cq0ixh" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_09_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/21/cs.LG_2023_09_21/" class="article-date">
  <time datetime="2023-09-21T10:00:00.000Z" itemprop="datePublished">2023-09-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/21/cs.LG_2023_09_21/">cs.LG - 2023-09-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Does-My-Dog-‘’Speak’’-Like-Me-The-Acoustic-Correlation-between-Pet-Dogs-and-Their-Human-Owners"><a href="#Does-My-Dog-‘’Speak’’-Like-Me-The-Acoustic-Correlation-between-Pet-Dogs-and-Their-Human-Owners" class="headerlink" title="Does My Dog ‘’Speak’’ Like Me? The Acoustic Correlation between Pet Dogs and Their Human Owners"></a>Does My Dog ‘’Speak’’ Like Me? The Acoustic Correlation between Pet Dogs and Their Human Owners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.13085">http://arxiv.org/abs/2309.13085</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/XSiling/EJSHIBAVOICE">https://github.com/XSiling/EJSHIBAVOICE</a></li>
<li>paper_authors: Jieyi Huang, Chunhao Zhang, Yufei Wang, Mengyue Wu, Kenny Zhu</li>
<li>for: 这个论文探讨了宠物狗的叫声与其主人语言环境之间的可能的相关性。</li>
<li>methods: 这个论文使用了一种新的数据集，来 investigate 宠物狗的叫声和其主人语言环境之间的关系。数据集包括7500个清晰的声音clip，以及这些声音clip的上下文信息，如场景类别、狗的位置和活动。</li>
<li>results: 研究发现，宠物狗在不同语言环境下发出的叫声存在显著的声音差异。此外，研究还发现了一些可能与主人语言模式相关的宠物狗叫声特征。<details>
<summary>Abstract</summary>
How hosts language influence their pets' vocalization is an interesting yet underexplored problem. This paper presents a preliminary investigation into the possible correlation between domestic dog vocal expressions and their human host's language environment. We first present a new dataset of Shiba Inu dog vocals from YouTube, which provides 7500 clean sound clips, including their contextual information of these vocals and their owner's speech clips with a carefully-designed data processing pipeline. The contextual information includes the scene category in which the vocal was recorded, the dog's location and activity. With a classification task and prominent factor analysis, we discover significant acoustic differences in the dog vocals from the two language environments. We further identify some acoustic features from dog vocalizations that are potentially correlated to their host language patterns.
</details>
<details>
<summary>摘要</summary>
< translating_language: "zh-CN" ></SYS>人类主人的语言环境如何影响宠物的叫声是一个有趣又未得到充分研究的问题。这篇论文提出了对宠物叫声和主人语言环境之间可能存在相关性的初步调查。我们首先提供了一个新的Shiba Inu狗叫音数据集，包括YouTube上的7500个干净的叫音示例和其上下文信息，以及主人的语音示例和一个仔细设计的数据处理管道。上下文信息包括叫声在录制场景中的类别、狗的位置和活动。通过分类任务和显著因子分析，我们发现了宠物叫声在两个语言环境下存在显著的声音差异。我们进一步发现了一些宠物叫声特征与主人语言模式之间的可能相关性。
</details></li>
</ul>
<hr>
<h2 id="Trip-Planning-for-Autonomous-Vehicles-with-Wireless-Data-Transfer-Needs-Using-Reinforcement-Learning"><a href="#Trip-Planning-for-Autonomous-Vehicles-with-Wireless-Data-Transfer-Needs-Using-Reinforcement-Learning" class="headerlink" title="Trip Planning for Autonomous Vehicles with Wireless Data Transfer Needs Using Reinforcement Learning"></a>Trip Planning for Autonomous Vehicles with Wireless Data Transfer Needs Using Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12534">http://arxiv.org/abs/2309.12534</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yousef AlSaqabi, Bhaskar Krishnamachari</li>
<li>for: 这篇论文目标是解决城市化自动驾驶车辆路径规划问题，考虑到数据传输需求和行驶时间之间的平衡。</li>
<li>methods: 该论文提出了一种基于强化学习的解决方案，优先选择高带宽道路，以满足车辆的数据传输需求，同时尽量减少行驶时间。</li>
<li>results: 相比于不相关的基准和带宽不相关的基准，该解决方案在不同的干线交通情况下表现明显更好，可以更好地满足车辆的数据传输需求和行驶时间需求。<details>
<summary>Abstract</summary>
With recent advancements in the field of communications and the Internet of Things, vehicles are becoming more aware of their environment and are evolving towards full autonomy. Vehicular communication opens up the possibility for vehicle-to-infrastructure interaction, where vehicles could share information with components such as cameras, traffic lights, and signage that support a countrys road system. As a result, vehicles are becoming more than just a means of transportation; they are collecting, processing, and transmitting massive amounts of data used to make driving safer and more convenient. With 5G cellular networks and beyond, there is going to be more data bandwidth available on our roads, but it may be heterogeneous because of limitations like line of sight, infrastructure, and heterogeneous traffic on the road. This paper addresses the problem of route planning for autonomous vehicles in urban areas accounting for both driving time and data transfer needs. We propose a novel reinforcement learning solution that prioritizes high bandwidth roads to meet a vehicles data transfer requirement, while also minimizing driving time. We compare this approach to traffic-unaware and bandwidth-unaware baselines to show how much better it performs under heterogeneous traffic. This solution could be used as a starting point to understand what good policies look like, which could potentially yield faster, more efficient heuristics in the future.
</details>
<details>
<summary>摘要</summary>
（注意：以下是简化中文版本，与原文可能有所不同）随着交通和互联网的技术进步，车辆正在变得更加自动化。车辆与基础设施之间的交通开发了可以让车辆与道路系统中的设备进行交换信息，如摄像头、交通灯和路标。这使得车辆不仅成为了交通工具，还开始收集、处理和传输大量数据，以提高驾驶的安全性和便利性。5G移动通信网络和更进一步的技术将在路上提供更多的数据带宽，但这可能会具有不同的限制，如视线、基础设施和路上的异化交通。本文关注城市地区自动驾驶车辆的路径规划问题，考虑到驾驶时间和数据传输需求的平衡。我们提出了一种基于强化学习的新解决方案，它会优先选择高带宽道路，以满足车辆的数据传输需求，同时尽量减少驾驶时间。我们与无规则和带宽无规则的基线相比较，以显示这种方法在异化交通情况下的性能有多好。这种解决方案可以作为未来更快、更高效的启示。
</details></li>
</ul>
<hr>
<h2 id="Confidence-Calibration-for-Systems-with-Cascaded-Predictive-Modules"><a href="#Confidence-Calibration-for-Systems-with-Cascaded-Predictive-Modules" class="headerlink" title="Confidence Calibration for Systems with Cascaded Predictive Modules"></a>Confidence Calibration for Systems with Cascaded Predictive Modules</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12510">http://arxiv.org/abs/2309.12510</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunye Gong, Yi Yao, Xiao Lin, Ajay Divakaran, Melinda Gervasio</li>
<li>for: 这种论文旨在提供一种基于协形预测的系统预测方法，以提高预测系统的可靠性和性能。</li>
<li>methods: 这种方法使用了协形预测算法，并利用模块级验证数据来characterize系统级错误分布。</li>
<li>results: 研究人员通过 theoretically justifying和实验证明，证明了这种方法的效果和性能优势。对比各个模块的预测间隔，这种方法生成的预测间隔更加准确，并提供了更好的性能保证。<details>
<summary>Abstract</summary>
Existing conformal prediction algorithms estimate prediction intervals at target confidence levels to characterize the performance of a regression model on new test samples. However, considering an autonomous system consisting of multiple modules, prediction intervals constructed for individual modules fall short of accommodating uncertainty propagation over different modules and thus cannot provide reliable predictions on system behavior. We address this limitation and present novel solutions based on conformal prediction to provide prediction intervals calibrated for a predictive system consisting of cascaded modules (e.g., an upstream feature extraction module and a downstream regression module). Our key idea is to leverage module-level validation data to characterize the system-level error distribution without direct access to end-to-end validation data. We provide theoretical justification and empirical experimental results to demonstrate the effectiveness of proposed solutions. In comparison to prediction intervals calibrated for individual modules, our solutions generate improved intervals with more accurate performance guarantees for system predictions, which are demonstrated on both synthetic systems and real-world systems performing overlap prediction for indoor navigation using the Matterport3D dataset.
</details>
<details>
<summary>摘要</summary>
现有的准确预测算法可以为新的测试样本提供预测 интерVAL，以评估回归模型的性能。然而，对于由多个模块组成的自主系统，单个模块的预测间隔无法考虑模块之间的uncertainty协同传递，因此无法提供可靠的系统行为预测。我们解决这个限制，并提出了基于准确预测的新解决方案，以提供calibrated的预测间隔，用于评估预测系统中各个模块之间的协同影响。我们的关键思想是使用模块级验证数据来描述系统级错误分布，而不需要直接访问端到端验证数据。我们提供了理论 justify和实验 result，以证明我们的解决方案的有效性。相比单个模块的预测间隔，我们的解决方案可以生成更加 precisions的预测间隔，并提供更加准确的性能保证，这些结果在 synthetic 系统和实际世界中进行 overlap 预测的 Matterport3D 数据集上得到证明。
</details></li>
</ul>
<hr>
<h2 id="A-Diffusion-Model-of-Joint-Interactive-Navigation"><a href="#A-Diffusion-Model-of-Joint-Interactive-Navigation" class="headerlink" title="A Diffusion-Model of Joint Interactive Navigation"></a>A Diffusion-Model of Joint Interactive Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12508">http://arxiv.org/abs/2309.12508</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthew Niedoba, Jonathan Wilder Lavington, Yunpeng Liu, Vasileios Lioutas, Justice Sefas, Xiaoxuan Liang, Dylan Green, Setareh Dabiri, Berend Zwartsenberg, Adam Scibior, Frank Wood</li>
<li>for: 用于生成具有多样化和现实性的自动驾驶系统 simulate traffic participants的方法。</li>
<li>methods: 使用 diffusion-based 方法，根据过去、当前或未来的状态观察，共同diffuse 所有代理的路径。</li>
<li>results: 在流行的路径预测数据集上，得到了joint trajectory metrics的state of the art表现，并且可以直接在测试时从多种有价值的决定性分布中随机抽样。<details>
<summary>Abstract</summary>
Simulation of autonomous vehicle systems requires that simulated traffic participants exhibit diverse and realistic behaviors. The use of prerecorded real-world traffic scenarios in simulation ensures realism but the rarity of safety critical events makes large scale collection of driving scenarios expensive. In this paper, we present DJINN - a diffusion based method of generating traffic scenarios. Our approach jointly diffuses the trajectories of all agents, conditioned on a flexible set of state observations from the past, present, or future. On popular trajectory forecasting datasets, we report state of the art performance on joint trajectory metrics. In addition, we demonstrate how DJINN flexibly enables direct test-time sampling from a variety of valuable conditional distributions including goal-based sampling, behavior-class sampling, and scenario editing.
</details>
<details>
<summary>摘要</summary>
simulation of autonomous vehicle systems requires that simulated traffic participants exhibit diverse and realistic behaviors. the use of prerecorded real-world traffic scenarios in simulation ensures realism, but the rarity of safety critical events makes large-scale collection of driving scenarios expensive. in this paper, we present djinn - a diffusion-based method of generating traffic scenarios. our approach jointly diffuses the trajectories of all agents, conditioned on a flexible set of state observations from the past, present, or future. on popular trajectory forecasting datasets, we report state-of-the-art performance on joint trajectory metrics. in addition, we demonstrate how djinn flexibly enables direct test-time sampling from a variety of valuable conditional distributions, including goal-based sampling, behavior-class sampling, and scenario editing.Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other countries. Traditional Chinese is used in Hong Kong, Taiwan, and other regions.
</details></li>
</ul>
<hr>
<h2 id="User-Level-Differential-Privacy-With-Few-Examples-Per-User"><a href="#User-Level-Differential-Privacy-With-Few-Examples-Per-User" class="headerlink" title="User-Level Differential Privacy With Few Examples Per User"></a>User-Level Differential Privacy With Few Examples Per User</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12500">http://arxiv.org/abs/2309.12500</a></li>
<li>repo_url: None</li>
<li>paper_authors: Badih Ghazi, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Raghu Meka, Chiyuan Zhang</li>
<li>For: 本文研究了用户级别的差分隐私（DP），并取得了以下结果：* Methods: 本文使用了item-level DP算法的通用变换，以实现用户级别的DP。此外，本文还使用了对数机制（McSherry, Talwar FOCS 2007）进行适应。* Results: 本文取得了以下结果：	+ 对 approximate-DP，我们提供了一个通用的item-level DP算法到用户级别DP算法的变换，具有$(O_{\varepsilon,\delta}(\sqrt{m}))$的优化。	+ 对 pure-DP，我们提供了一种简单的适应技术，可以应用于各种任务，如private PAC learning、假设选择和分布学习。对这些问题，我们显示了我们的 bound 是 near-optimal。<details>
<summary>Abstract</summary>
Previous work on user-level differential privacy (DP) [Ghazi et al. NeurIPS 2021, Bun et al. STOC 2023] obtained generic algorithms that work for various learning tasks. However, their focus was on the example-rich regime, where the users have so many examples that each user could themselves solve the problem. In this work we consider the example-scarce regime, where each user has only a few examples, and obtain the following results:   1. For approximate-DP, we give a generic transformation of any item-level DP algorithm to a user-level DP algorithm. Roughly speaking, the latter gives a (multiplicative) savings of $O_{\varepsilon,\delta}(\sqrt{m})$ in terms of the number of users required for achieving the same utility, where $m$ is the number of examples per user. This algorithm, while recovering most known bounds for specific problems, also gives new bounds, e.g., for PAC learning.   2. For pure-DP, we present a simple technique for adapting the exponential mechanism [McSherry, Talwar FOCS 2007] to the user-level setting. This gives new bounds for a variety of tasks, such as private PAC learning, hypothesis selection, and distribution learning. For some of these problems, we show that our bounds are near-optimal.
</details>
<details>
<summary>摘要</summary>
previous research on user-level differential privacy (DP) （Ghazi et al. NeurIPS 2021, Bun et al. STOC 2023）obtained general algorithms that work for various learning tasks. However, their focus was on the example-rich regime, where users have many examples that they can solve themselves. In this work, we consider the example-scarce regime, where each user only has a few examples, and obtain the following results:1. For approximate-DP, we provide a generic transformation of any item-level DP algorithm to a user-level DP algorithm. This roughly speaking, gives a (multiplicative) savings of $O_{\varepsilon,\delta}(\sqrt{m})$ in terms of the number of users required for achieving the same utility, where $m$ is the number of examples per user. This algorithm recovers most known bounds for specific problems and also gives new bounds, such as for PAC learning.2. For pure-DP, we present a simple technique for adapting the exponential mechanism （McSherry, Talwar FOCS 2007）to the user-level setting. This gives new bounds for a variety of tasks, such as private PAC learning, hypothesis selection, and distribution learning. For some of these problems, we show that our bounds are near-optimal.
</details></li>
</ul>
<hr>
<h2 id="Evidential-uncertainties-on-rich-labels-for-active-learning"><a href="#Evidential-uncertainties-on-rich-labels-for-active-learning" class="headerlink" title="Evidential uncertainties on rich labels for active learning"></a>Evidential uncertainties on rich labels for active learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12494">http://arxiv.org/abs/2309.12494</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arthur Hoarau, Vincent Lemaire, Arnaud Martin, Jean-Christophe Dubois, Yolande Le Gall</li>
<li>for: 这个论文目的是提出一种新的active learning方法，具体来说是对模型uncertainty进行分解，并且更准确地考虑 labels的uncertainty。</li>
<li>methods: 这个论文使用了两种方法： sampling by Klir uncertainty和sampling by evidential epistemic uncertainty。这两种方法都基于信念函数理论。</li>
<li>results: 这个论文的结果表明，使用这两种方法可以更好地解决exploration-exploitation问题，并且可以更准确地考虑labels的uncertainty。<details>
<summary>Abstract</summary>
Recent research in active learning, and more precisely in uncertainty sampling, has focused on the decomposition of model uncertainty into reducible and irreducible uncertainties. In this paper, we propose to simplify the computational phase and remove the dependence on observations, but more importantly to take into account the uncertainty already present in the labels, \emph{i.e.} the uncertainty of the oracles. Two strategies are proposed, sampling by Klir uncertainty, which addresses the exploration-exploitation problem, and sampling by evidential epistemic uncertainty, which extends the reducible uncertainty to the evidential framework, both using the theory of belief functions.
</details>
<details>
<summary>摘要</summary>
近期研究在活动学习中，更具体地说是在uncertainty sampling中，关注模型不确定性的分解。在这篇论文中，我们提议简化计算阶段，并从观察依赖中解脱，更重要的是，考虑标签上的不确定性，即观察者的不确定性。我们提出了两种策略：基于Klir不确定性的采样，解决探索与利用问题，以及基于证据性不确定性的采样，扩展可reducible uncertainty到证据框架，都使用信仰函数理论。
</details></li>
</ul>
<hr>
<h2 id="Sharpness-Aware-Minimization-and-the-Edge-of-Stability"><a href="#Sharpness-Aware-Minimization-and-the-Edge-of-Stability" class="headerlink" title="Sharpness-Aware Minimization and the Edge of Stability"></a>Sharpness-Aware Minimization and the Edge of Stability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12488">http://arxiv.org/abs/2309.12488</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-deepmind/sam_edge">https://github.com/google-deepmind/sam_edge</a></li>
<li>paper_authors: Philip M. Long, Peter L. Bartlett</li>
<li>for: 本文旨在研究一种基于梯度下降的神经网络训练方法，即锐度意识化最小化（SAM）。</li>
<li>methods: 本文使用一种名为“边缘稳定性”的计算方法，来研究SAM在训练神经网络时的稳定性。这种方法基于Localquadratic approximation of the loss函数。</li>
<li>results: 经验表明，SAM在训练神经网络时会操作在“边缘稳定性”的edge上，这个edge取决于梯度的norm。这些结果用三个深度学习训练任务进行了实证验证。<details>
<summary>Abstract</summary>
Recent experiments have shown that, often, when training a neural network with gradient descent (GD) with a step size $\eta$, the operator norm of the Hessian of the loss grows until it approximately reaches $2/\eta$, after which it fluctuates around this value. The quantity $2/\eta$ has been called the "edge of stability" based on consideration of a local quadratic approximation of the loss. We perform a similar calculation to arrive at an "edge of stability" for Sharpness-Aware Minimization (SAM), a variant of GD which has been shown to improve its generalization. Unlike the case for GD, the resulting SAM-edge depends on the norm of the gradient. Using three deep learning training tasks, we see empirically that SAM operates on the edge of stability identified by this analysis.
</details>
<details>
<summary>摘要</summary>
现在的实验表明，当使用梯度下降（GD）学习神经网络时，损失函数的偏导数的 operator  нор平方根会不断增长，直到约等于 $2/\eta$，然后会随机变化。这个值被称为 "稳定边缘"，基于Localquadratic Approximation of the loss。我们对Sharpness-Aware Minimization（SAM）进行类似的计算，并发现SAM-edge会随着梯度的norm而变化。通过三个深度学习训练任务的实证，我们发现SAM在这个分析定义的稳定边缘上运行。Note: "Simplified Chinese" is a romanization of the Chinese language, and the translation is based on the standardized system known as "Mainland Chinese" or "Mandarin". The translation may vary depending on the specific dialect or regional variation.
</details></li>
</ul>
<hr>
<h2 id="Robust-Energy-Consumption-Prediction-with-a-Missing-Value-Resilient-Metaheuristic-based-Neural-Network-in-Mobile-App-Development"><a href="#Robust-Energy-Consumption-Prediction-with-a-Missing-Value-Resilient-Metaheuristic-based-Neural-Network-in-Mobile-App-Development" class="headerlink" title="Robust Energy Consumption Prediction with a Missing Value-Resilient Metaheuristic-based Neural Network in Mobile App Development"></a>Robust Energy Consumption Prediction with a Missing Value-Resilient Metaheuristic-based Neural Network in Mobile App Development</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12484">http://arxiv.org/abs/2309.12484</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seyed Jalaleddin Mousavirad, Luís A. Alexandre</li>
<li>for: 这个研究的目的是为了提出一个基于神经网络的能源预测模型，以便在移动应用程序开发中更好地预测能源消耗。</li>
<li>methods: 这个研究使用了一个metaheuristic方法来找到适合的学习算法和它们的参数，并且决定了最佳层数和神经元数。这个metaheuristic方法 simultaneous地处理了所有的参数。</li>
<li>results: 实验结果显示，提出的方法可以获得重要的能源预测结果。<details>
<summary>Abstract</summary>
Energy consumption is a fundamental concern in mobile application development, bearing substantial significance for both developers and end-users. Moreover, it is a critical determinant in the consumer's decision-making process when considering a smartphone purchase. From the sustainability perspective, it becomes imperative to explore approaches aimed at mitigating the energy consumption of mobile devices, given the significant global consequences arising from the extensive utilisation of billions of smartphones, which imparts a profound environmental impact. Despite the existence of various energy-efficient programming practices within the Android platform, the dominant mobile ecosystem, there remains a need for documented machine learning-based energy prediction algorithms tailored explicitly for mobile app development. Hence, the main objective of this research is to propose a novel neural network-based framework, enhanced by a metaheuristic approach, to achieve robust energy prediction in the context of mobile app development. The metaheuristic approach here plays a crucial role in not only identifying suitable learning algorithms and their corresponding parameters but also determining the optimal number of layers and neurons within each layer. To the best of our knowledge, prior studies have yet to employ any metaheuristic algorithm to address all these hyperparameters simultaneously. Moreover, due to limitations in accessing certain aspects of a mobile phone, there might be missing data in the data set, and the proposed framework can handle this. In addition, we conducted an optimal algorithm selection strategy, employing 13 metaheuristic algorithms, to identify the best algorithm based on accuracy and resistance to missing values. The comprehensive experiments demonstrate that our proposed approach yields significant outcomes for energy consumption prediction.
</details>
<details>
<summary>摘要</summary>
Mobile 应用程序开发中的能源消耗是一个基本问题，对开发者和用户都具有重要意义。此外，它还是购买智能手机的决策因素之一。从可持续发展的角度来看，针对移动设备的能源消耗减少成为了必要的。虽然Android平台上有各种能效编程做法，但是还没有任何文献记录了基于机器学习的移动应用程序开发中的能源预测算法。因此，本研究的主要目标是提出一种基于神经网络的新框架，通过metaheuristic方法进行优化，以实现移动应用程序开发中的 Robust 能源预测。在我们所知道的范围内，现有的研究都没有使用metaheuristic算法来处理所有的超参数。此外，由于移动设备的一些特性是无法访问的，数据集中可能会有缺失数据，并且我们的提posed方法可以处理这种情况。此外，我们采用了最佳算法选择策略，使用13种metaheuristic算法，以确定最佳算法，基于准确率和缺失值的抗性。广泛的实验表明，我们的提posed方法可以带来显著的能源消耗预测效果。
</details></li>
</ul>
<hr>
<h2 id="A-Theory-of-Multimodal-Learning"><a href="#A-Theory-of-Multimodal-Learning" class="headerlink" title="A Theory of Multimodal Learning"></a>A Theory of Multimodal Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12458">http://arxiv.org/abs/2309.12458</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Zhou Lu</li>
<li>for: 本研究旨在提供对多Modal学习理论基础，解释在多Modal学习中模型可以超越单Modal模型的现象。</li>
<li>methods: 本研究使用了多Modal学习算法的普遍性Bounds来解释这种现象。</li>
<li>results: 研究发现，当多Modal学习存在连接和多样性时，模型可以获得更好的普遍性Bound，比单Modal学习提高到$O(\sqrt{n})$。<details>
<summary>Abstract</summary>
Human perception of the empirical world involves recognizing the diverse appearances, or 'modalities', of underlying objects. Despite the longstanding consideration of this perspective in philosophy and cognitive science, the study of multimodality remains relatively under-explored within the field of machine learning. Nevertheless, current studies of multimodal machine learning are limited to empirical practices, lacking theoretical foundations beyond heuristic arguments. An intriguing finding from the practice of multimodal learning is that a model trained on multiple modalities can outperform a finely-tuned unimodal model, even on unimodal tasks. This paper provides a theoretical framework that explains this phenomenon, by studying generalization properties of multimodal learning algorithms. We demonstrate that multimodal learning allows for a superior generalization bound compared to unimodal learning, up to a factor of $O(\sqrt{n})$, where $n$ represents the sample size. Such advantage occurs when both connection and heterogeneity exist between the modalities.
</details>
<details>
<summary>摘要</summary>
人类对现实世界的感知包括认识不同的表现形式，或“Modalities”，下面的物体。尽管这个视角在哲学和认知科学中已经有很长的历史，但在机器学习领域中对多 modal 学习的研究仍然较为少 explore。然而，当前的多 modal 学习研究仅限于实践，缺乏更加深入的理论基础，只有一些启发性的 Argument。多 modal 学习实践中的一个感人发现是，一个通过多种Modalities 训练的模型可以在单模态任务上超越精心调整的单模态模型。这篇论文提供了一个解释这种现象的理论框架，通过研究多 modal 学习算法的泛化性质。我们示出，在Modalities 之间存在连接和多样性时，多 modal 学习可以与单 modal 学习相比，提高泛化级别，最高可以达到 $O(\sqrt{n})$，其中 $n$ 表示样本大小。这种优势发生在Modalities 之间存在连接和多样性时。
</details></li>
</ul>
<hr>
<h2 id="A-Convex-Framework-for-Confounding-Robust-Inference"><a href="#A-Convex-Framework-for-Confounding-Robust-Inference" class="headerlink" title="A Convex Framework for Confounding Robust Inference"></a>A Convex Framework for Confounding Robust Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12450">http://arxiv.org/abs/2309.12450</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kstoneriv3/confounding-robust-inference">https://github.com/kstoneriv3/confounding-robust-inference</a></li>
<li>paper_authors: Kei Ishikawa, Naio He, Takafumi Kanamori</li>
<li>for: 评估离线上下文ual抽象带缺失的政策效果。</li>
<li>methods: 使用敏感分析方法来估计政策价值在最坏混乱情况下。</li>
<li>results: 提出一种通用的估计器，可以提供精确的下界估计政策价值，并且可以扩展到敏感分析、模型选择和Robust政策学习等领域。<details>
<summary>Abstract</summary>
We study policy evaluation of offline contextual bandits subject to unobserved confounders. Sensitivity analysis methods are commonly used to estimate the policy value under the worst-case confounding over a given uncertainty set. However, existing work often resorts to some coarse relaxation of the uncertainty set for the sake of tractability, leading to overly conservative estimation of the policy value. In this paper, we propose a general estimator that provides a sharp lower bound of the policy value using convex programming. The generality of our estimator enables various extensions such as sensitivity analysis with f-divergence, model selection with cross validation and information criterion, and robust policy learning with the sharp lower bound. Furthermore, our estimation method can be reformulated as an empirical risk minimization problem thanks to the strong duality, which enables us to provide strong theoretical guarantees of the proposed estimator using techniques of the M-estimation.
</details>
<details>
<summary>摘要</summary>
我们研究线上上下文抽屉策略评估，受到不观测的偏见影响。感知分析方法通常用于估计策略价值在最差折衔集下，但现有工作经常使用一些粗略放宽不确定集来简化计算，导致估计策略价值过于保守。在本文中，我们提出一种通用的估计器，可以提供精确的下界估计策略价值使用几何编程。我们的估计器具有通用性，可以进行多种扩展，如感知分析使用f-散度、模型选择使用分割validation和信息因子，以及robust策略学习使用锐下界。此外，我们的估计方法可以转化为empirical risk minimization问题，使得我们可以通过强duality提供强 тео리тиче保证我们的提议估计器。
</details></li>
</ul>
<hr>
<h2 id="Change-Management-using-Generative-Modeling-on-Digital-Twins"><a href="#Change-Management-using-Generative-Modeling-on-Digital-Twins" class="headerlink" title="Change Management using Generative Modeling on Digital Twins"></a>Change Management using Generative Modeling on Digital Twins</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12421">http://arxiv.org/abs/2309.12421</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nilanjana Das, Anantaa Kotal, Daniel Roseberry, Anupam Joshi</li>
<li>For: The paper is written for small and medium-sized businesses that need to securely manage software updates and changes, but do not have the resources to set up a non-production environment for stress testing.* Methods: The paper proposes using “digital twins” on the cloud to create a non-production environment for stress testing software changes, and using Generative Artificial Intelligence (AI) models to generate testing scenarios to check for points of failure.* Results: The paper shows how using digital twins and Generative AI models can help small and medium-sized businesses securely test software changes before releasing them into production, without the need for a dedicated non-production environment.Here is the text in Simplified Chinese:* For: 这篇论文是为小型和中型企业写的，它们需要安全地管理软件更新和变更，但是没有设置非生产环境进行压力测试的资源。* Methods: 论文提议使用云端的数字双向来创建非生产环境，并使用生成式人工智能模型来生成测试场景来检查失败点。* Results: 论文显示，通过使用数字双向和生成式人工智能模型，小型和中型企业可以安全地测试软件更新和变更，无需非生产环境。<details>
<summary>Abstract</summary>
A key challenge faced by small and medium-sized business entities is securely managing software updates and changes. Specifically, with rapidly evolving cybersecurity threats, changes/updates/patches to software systems are necessary to stay ahead of emerging threats and are often mandated by regulators or statutory authorities to counter these. However, security patches/updates require stress testing before they can be released in the production system. Stress testing in production environments is risky and poses security threats. Large businesses usually have a non-production environment where such changes can be made and tested before being released into production. Smaller businesses do not have such facilities. In this work, we show how "digital twins", especially for a mix of IT and IoT environments, can be created on the cloud. These digital twins act as a non-production environment where changes can be applied, and the system can be securely tested before patch release. Additionally, the non-production digital twin can be used to collect system data and run stress tests on the environment, both manually and automatically. In this paper, we show how using a small sample of real data/interactions, Generative Artificial Intelligence (AI) models can be used to generate testing scenarios to check for points of failure.
</details>
<details>
<summary>摘要</summary>
小和中等规模的企业面临着安全管理软件更新和变化的一个关键挑战。具体来说，随着黑客攻击的快速演化，软件系统中的更新和补丁是必须的，以保持防御力和符合法规要求。然而，安全补丁和更新在生产环境中进行压力测试是具有安全风险的。大型企业通常具有非生产环境，可以在这些环境中进行更改和测试，然后将其推送到生产环境。然而，小型企业没有这样的设施。在这种情况下，我们表明了如何使用“数字双”，特别是混合IT和IoT环境下的数字双，在云上创建。这些数字双可以作为非生产环境，应用更改并在安全测试前进行压力测试。此外，非生产数字双还可以用来收集系统数据和自动和手动执行压力测试。在这篇论文中，我们表明了如何使用小样本的实际数据和互动，生成人工智能模型来生成测试场景，检查系统的漏洞点。
</details></li>
</ul>
<hr>
<h2 id="Performance-Conditioning-for-Diffusion-Based-Multi-Instrument-Music-Synthesis"><a href="#Performance-Conditioning-for-Diffusion-Based-Multi-Instrument-Music-Synthesis" class="headerlink" title="Performance Conditioning for Diffusion-Based Multi-Instrument Music Synthesis"></a>Performance Conditioning for Diffusion-Based Multi-Instrument Music Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12283">http://arxiv.org/abs/2309.12283</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ben Maman, Johannes Zeitler, Meinard Müller, Amit H. Bermano</li>
<li>for: 本研究的目的是提高多楽器合成的控制精度，使得音乐生成模型能够更好地受到演奏和录音环境的指导，以提高音乐的时间和风格表现。</li>
<li>methods: 本研究使用了 diffusion-based 音乐生成模型，并引入了 performance conditioning 技术，将生成的音乐与特定的演奏和录音环境相关联系。</li>
<li>results: 研究使用了不净化的表演，并取得了现有最高的 FAD 实实主义分数，并允许了新的时间和风格控制。详细资讯可以参考 benadar293.github.io&#x2F;midipm。<details>
<summary>Abstract</summary>
Generating multi-instrument music from symbolic music representations is an important task in Music Information Retrieval (MIR). A central but still largely unsolved problem in this context is musically and acoustically informed control in the generation process. As the main contribution of this work, we propose enhancing control of multi-instrument synthesis by conditioning a generative model on a specific performance and recording environment, thus allowing for better guidance of timbre and style. Building on state-of-the-art diffusion-based music generative models, we introduce performance conditioning - a simple tool indicating the generative model to synthesize music with style and timbre of specific instruments taken from specific performances. Our prototype is evaluated using uncurated performances with diverse instrumentation and achieves state-of-the-art FAD realism scores while allowing novel timbre and style control. Our project page, including samples and demonstrations, is available at benadar293.github.io/midipm
</details>
<details>
<summary>摘要</summary>
Generating multi-instrument music from symbolic music representations is an important task in Music Information Retrieval (MIR). A central but still largely unsolved problem in this context is musically and acoustically informed control in the generation process. As the main contribution of this work, we propose enhancing control of multi-instrument synthesis by conditioning a generative model on a specific performance and recording environment, thus allowing for better guidance of timbre and style. Building on state-of-the-art diffusion-based music generative models, we introduce performance conditioning - a simple tool indicating the generative model to synthesize music with style and timbre of specific instruments taken from specific performances. Our prototype is evaluated using uncurated performances with diverse instrumentation and achieves state-of-the-art FAD realism scores while allowing novel timbre and style control. Our project page, including samples and demonstrations, is available at benadar293.github.io/midipm.Here's the text with traditional Chinese characters: generating multi-instrument music from symbolic music representations is an important task in Music Information Retrieval (MIR). A central but still largely unsolved problem in this context is musically and acoustically informed control in the generation process. As the main contribution of this work, we propose enhancing control of multi-instrument synthesis by conditioning a generative model on a specific performance and recording environment, thus allowing for better guidance of timbre and style. Building on state-of-the-art diffusion-based music generative models, we introduce performance conditioning - a simple tool indicating the generative model to synthesize music with style and timbre of specific instruments taken from specific performances. Our prototype is evaluated using uncurated performances with diverse instrumentation and achieves state-of-the-art FAD realism scores while allowing novel timbre and style control. Our project page, including samples and demonstrations, is available at benadar293.github.io/midipm.
</details></li>
</ul>
<hr>
<h2 id="The-Broad-Impact-of-Feature-Imitation-Neural-Enhancements-Across-Financial-Speech-and-Physiological-Domains"><a href="#The-Broad-Impact-of-Feature-Imitation-Neural-Enhancements-Across-Financial-Speech-and-Physiological-Domains" class="headerlink" title="The Broad Impact of Feature Imitation: Neural Enhancements Across Financial, Speech, and Physiological Domains"></a>The Broad Impact of Feature Imitation: Neural Enhancements Across Financial, Speech, and Physiological Domains</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12279">http://arxiv.org/abs/2309.12279</a></li>
<li>repo_url: None</li>
<li>paper_authors: Reza Khanmohammadi, Tuka Alhanai, Mohammad M. Ghassemi</li>
<li>for: 这篇研究旨在测试Feature Imitating Networks (FINs)在不同时序数据集上的应用，以提高深度学习架构的性能。</li>
<li>methods: 本研究使用FINs方法初始化神经网络的重量，以实现特定的关闭形式统计特征的近似。</li>
<li>results: 在比特币价格预测、语音情感识别和慢性颈部疼痛检测等三个实验中，FINs方法可以将性能提高约1000、3%和7%。<details>
<summary>Abstract</summary>
Initialization of neural network weights plays a pivotal role in determining their performance. Feature Imitating Networks (FINs) offer a novel strategy by initializing weights to approximate specific closed-form statistical features, setting a promising foundation for deep learning architectures. While the applicability of FINs has been chiefly tested in biomedical domains, this study extends its exploration into other time series datasets. Three different experiments are conducted in this study to test the applicability of imitating Tsallis entropy for performance enhancement: Bitcoin price prediction, speech emotion recognition, and chronic neck pain detection. For the Bitcoin price prediction, models embedded with FINs reduced the root mean square error by around 1000 compared to the baseline. In the speech emotion recognition task, the FIN-augmented model increased classification accuracy by over 3 percent. Lastly, in the CNP detection experiment, an improvement of about 7 percent was observed compared to established classifiers. These findings validate the broad utility and potency of FINs in diverse applications.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将神经网络权重初始化的策略对其性能产生决定性影响。特征模仿网络（FIN）提供了一种新的策略，将权重初始化为近似特定的关闭式统计特征，为深度学习架构设置了良好的基础。尽管FIN的可应用性主要在生物医学领域进行了证明，但本研究扩展了其探索范围到其他时间序列数据集。本研究进行了三种不同的实验来测试对 Tsallis  entropy的模仿提高性能的可能性：比特币价格预测、语音情感识别和慢性 neck 疼痛检测。在比特币价格预测任务中，含有 FIN 的模型可以相比基准下降约 1000 的平均方差误差。在语音情感识别任务中，FIN 加装后的模型可以提高分类精度高于 3%。最后，在慢性 neck 疼痛检测实验中，FIN 加装后的模型可以相比已知分类器提高约 7%的正确率。这些发现证明了 FIN 在多样化应用中的广泛适用性和能力。Note: Please note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Health-diagnosis-and-recuperation-of-aged-Li-ion-batteries-with-data-analytics-and-equivalent-circuit-modeling"><a href="#Health-diagnosis-and-recuperation-of-aged-Li-ion-batteries-with-data-analytics-and-equivalent-circuit-modeling" class="headerlink" title="Health diagnosis and recuperation of aged Li-ion batteries with data analytics and equivalent circuit modeling"></a>Health diagnosis and recuperation of aged Li-ion batteries with data analytics and equivalent circuit modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03750">http://arxiv.org/abs/2310.03750</a></li>
<li>repo_url: None</li>
<li>paper_authors: Riko I Made, Jing Lin, Jintao Zhang, Yu Zhang, Lionel C. H. Moh, Zhaolin Liu, Ning Ding, Sing Yang Chiam, Edwin Khoo, Xuesong Yin, Guangyuan Wesley Zheng<br>for:This paper aims to assess the battery health and develop a strategy for cell rejuvenation of second-life Li-ion batteries.methods:The paper presents aging and reconditioning experiments of 62 commercial high-energy type lithium iron phosphate (LFP) cells, and uses machine learning models to predict cycle life and identify important indicators of recoverable capacity.results:The paper achieves an average test error of 16.84% ± 1.87% (mean absolute percentage error) for cycle life prediction, and finds that some of the recoverable lost capacity is attributed to the lateral lithium non-uniformity within the electrodes. Additionally, the paper demonstrates how battery operation history significantly affects the capacity recovery.<details>
<summary>Abstract</summary>
Battery health assessment and recuperation play a crucial role in the utilization of second-life Li-ion batteries. However, due to ambiguous aging mechanisms and lack of correlations between the recovery effects and operational states, it is challenging to accurately estimate battery health and devise a clear strategy for cell rejuvenation. This paper presents aging and reconditioning experiments of 62 commercial high-energy type lithium iron phosphate (LFP) cells, which supplement existing datasets of high-power LFP cells. The relatively large-scale data allow us to use machine learning models to predict cycle life and identify important indicators of recoverable capacity. Considering cell-to-cell inconsistencies, an average test error of $16.84\% \pm 1.87\%$ (mean absolute percentage error) for cycle life prediction is achieved by gradient boosting regressor given information from the first 80 cycles. In addition, it is found that some of the recoverable lost capacity is attributed to the lateral lithium non-uniformity within the electrodes. An equivalent circuit model is built and experimentally validated to demonstrate how such non-uniformity can be accumulated, and how it can give rise to recoverable capacity loss. SHapley Additive exPlanations (SHAP) analysis also reveals that battery operation history significantly affects the capacity recovery.
</details>
<details>
<summary>摘要</summary>
锂离子电池寿命和恢复对二次利用锂离子电池的利用率有着关键作用。然而，由于龄测不准确和操作状态和恢复效果之间没有明确的相关性，因此难以正确地评估电池健康状况和恢复策略。本文通过62个商业高能量锂铁磷铌（LFP）电池的年轻和恢复实验，补充了现有的高功率LFP电池数据。基于大规模数据，使用机器学习模型预测循环寿命和重要的循环容量指标。考虑到电池间差异，使用树 boosting 回归器可以在第80次前的80次内实现平均测试错误率为16.84% ± 1.87%（精度error）。此外，发现一些可以恢复的失去容量是由电极铁离子不均匀引起的。通过建立等式模型和实验验证，表明这种不均匀可以在恢复过程中积累，并且可以导致可恢复容量损失。使用 SHapley Additive exPlanations（SHAP）分析也发现，电池操作历史对容量恢复产生了显著影响。
</details></li>
</ul>
<hr>
<h2 id="Soft-Merging-A-Flexible-and-Robust-Soft-Model-Merging-Approach-for-Enhanced-Neural-Network-Performance"><a href="#Soft-Merging-A-Flexible-and-Robust-Soft-Model-Merging-Approach-for-Enhanced-Neural-Network-Performance" class="headerlink" title="Soft Merging: A Flexible and Robust Soft Model Merging Approach for Enhanced Neural Network Performance"></a>Soft Merging: A Flexible and Robust Soft Model Merging Approach for Enhanced Neural Network Performance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12259">http://arxiv.org/abs/2309.12259</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Chen, Yusen Wu, Phuong Nguyen, Chao Liu, Yelena Yesha</li>
<li>for: 提高深度学习模型的性能和稳定性</li>
<li>methods: 使用soft merging方法，通过学习门控参数，将多个本地优点模型快速融合，提高模型性能，同时减少计算成本</li>
<li>results: 经过实验表明，融合后的神经网络性能明显提高，并且更加稳定，比传统的模型融合方法更好Here’s a brief explanation of each point:* “for”: The paper aims to improve the performance and stability of deep learning models.* “methods”: The authors propose a “soft merging” method that combines multiple local optima models quickly and efficiently, using a surrogate of the $l_0$ norm to learn gate parameters.* “results”: The experiments show that the merged neural networks have better performance and are more stable than traditional model merging methods.<details>
<summary>Abstract</summary>
Stochastic Gradient Descent (SGD), a widely used optimization algorithm in deep learning, is often limited to converging to local optima due to the non-convex nature of the problem. Leveraging these local optima to improve model performance remains a challenging task. Given the inherent complexity of neural networks, the simple arithmetic averaging of the obtained local optima models in undesirable results. This paper proposes a {\em soft merging} method that facilitates rapid merging of multiple models, simplifies the merging of specific parts of neural networks, and enhances robustness against malicious models with extreme values. This is achieved by learning gate parameters through a surrogate of the $l_0$ norm using hard concrete distribution without modifying the model weights of the given local optima models. This merging process not only enhances the model performance by converging to a better local optimum, but also minimizes computational costs, offering an efficient and explicit learning process integrated with stochastic gradient descent. Thorough experiments underscore the effectiveness and superior performance of the merged neural networks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Parallelizing-non-linear-sequential-models-over-the-sequence-length"><a href="#Parallelizing-non-linear-sequential-models-over-the-sequence-length" class="headerlink" title="Parallelizing non-linear sequential models over the sequence length"></a>Parallelizing non-linear sequential models over the sequence length</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12252">http://arxiv.org/abs/2309.12252</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/machine-discovery/deer">https://github.com/machine-discovery/deer</a></li>
<li>paper_authors: Yi Heng Lim, Qi Zhu, Joshua Selfridge, Muhammad Firmansyah Kasim</li>
<li>for: 这篇论文旨在探讨如何加速循环神经网络和射预 diferencial equation 的训练，以提高它们在长序列问题上的表现。</li>
<li>methods: 这篇论文提出了一个平行算法，可以在 GPU 上加速循环神经网络和射预 diferencial equation 的训练，具体来说，这个算法可以在 GPU 上训练这些模型，并且不需要任何特殊的结构。</li>
<li>results: 根据论文的数据显示，这个平行算法可以让循环神经网络和射预 diferencial equation 的训练速度提高至多达 3 倍，而且不会对输出准确性造成影响。此外，这个算法适用于各种循环神经网络和射预 diferencial equation 架构。<details>
<summary>Abstract</summary>
Sequential models, such as Recurrent Neural Networks and Neural Ordinary Differential Equations, have long suffered from slow training due to their inherent sequential nature. For many years this bottleneck has persisted, as many thought sequential models could not be parallelized. We challenge this long-held belief with our parallel algorithm that accelerates GPU evaluation of sequential models by up to 3 orders of magnitude faster without compromising output accuracy. The algorithm does not need any special structure in the sequential models' architecture, making it applicable to a wide range of architectures. Using our method, training sequential models can be more than 10 times faster than the common sequential method without any meaningful difference in the training results. Leveraging this accelerated training, we discovered the efficacy of the Gated Recurrent Unit in a long time series classification problem with 17k time samples. By overcoming the training bottleneck, our work serves as the first step to unlock the potential of non-linear sequential models for long sequence problems.
</details>
<details>
<summary>摘要</summary>
纵向模型，如回归神经网络和几何 diferencial equation，长期受到纵向性的限制，导致训练速度慢。多年来，这一限制被认为是不可改变的，许多人认为纵向模型无法并行化。我们挑战这一长期固有的信念，提出了一种并行算法，可以在 GPU 上加速纵向模型的评估，提高训练速度到3个数量级。这种算法不需要纵向模型的特殊结构，因此适用于各种架构。使用我们的方法，纵向模型的训练可以比普通纵向方法快上到10倍，而无需任何意义的训练结果差异。通过加速训练，我们发现了彩虹 Recurrent Unit 在长时间序列分类问题中的效果，并在17k个时间样本上进行了证明。通过突破训练瓶颈，我们的工作为非线性纵向模型在长序列问题中的潜力开辟了第一步。
</details></li>
</ul>
<hr>
<h2 id="Weakly-supervised-Automated-Audio-Captioning-via-text-only-training"><a href="#Weakly-supervised-Automated-Audio-Captioning-via-text-only-training" class="headerlink" title="Weakly-supervised Automated Audio Captioning via text only training"></a>Weakly-supervised Automated Audio Captioning via text only training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12242">http://arxiv.org/abs/2309.12242</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zelaki/wsac">https://github.com/zelaki/wsac</a></li>
<li>paper_authors: Theodoros Kouzelis, Vassilis Katsouros</li>
<li>for:  automatized audio captioning (AAC)</li>
<li>methods: weakly-supervised approach using contrastive language-audio pretraining (CLAP)</li>
<li>results: relative performance of up to ~$83%$ compared to fully supervised approaches, demonstrated on Clotho and AudioCaps datasets.Here’s the full text in Simplified Chinese:</li>
<li>for: 自动化语音描述 (AAC)</li>
<li>methods: 弱型指导方法，使用语音-文本预训练 (CLAP)</li>
<li>results: 与完全指导方法比较， relative performance 高达 ~$83%$, 验证于 Clotho 和 AudioCaps 数据集。<details>
<summary>Abstract</summary>
In recent years, datasets of paired audio and captions have enabled remarkable success in automatically generating descriptions for audio clips, namely Automated Audio Captioning (AAC). However, it is labor-intensive and time-consuming to collect a sufficient number of paired audio and captions. Motivated by the recent advances in Contrastive Language-Audio Pretraining (CLAP), we propose a weakly-supervised approach to train an AAC model assuming only text data and a pre-trained CLAP model, alleviating the need for paired target data. Our approach leverages the similarity between audio and text embeddings in CLAP. During training, we learn to reconstruct the text from the CLAP text embedding, and during inference, we decode using the audio embeddings. To mitigate the modality gap between the audio and text embeddings we employ strategies to bridge the gap during training and inference stages. We evaluate our proposed method on Clotho and AudioCaps datasets demonstrating its ability to achieve a relative performance of up to ~$83\%$ compared to fully supervised approaches trained with paired target data.
</details>
<details>
<summary>摘要</summary>
Recently, datasets of paired audio and captions have enabled remarkable success in automatically generating descriptions for audio clips, specifically Automated Audio Captioning (AAC). However, collecting a sufficient number of paired audio and captions is labor-intensive and time-consuming. Motivated by the recent advances in Contrastive Language-Audio Pretraining (CLAP), we propose a weakly-supervised approach to train an AAC model assuming only text data and a pre-trained CLAP model, eliminating the need for paired target data. Our approach leverages the similarity between audio and text embeddings in CLAP. During training, we learn to reconstruct the text from the CLAP text embedding, and during inference, we decode using the audio embeddings. To mitigate the modality gap between the audio and text embeddings, we employ strategies to bridge the gap during training and inference stages. We evaluate our proposed method on Clotho and AudioCaps datasets, demonstrating its ability to achieve a relative performance of up to approximately 83% compared to fully supervised approaches trained with paired target data.
</details></li>
</ul>
<hr>
<h2 id="t-EER-Parameter-Free-Tandem-Evaluation-of-Countermeasures-and-Biometric-Comparators"><a href="#t-EER-Parameter-Free-Tandem-Evaluation-of-Countermeasures-and-Biometric-Comparators" class="headerlink" title="t-EER: Parameter-Free Tandem Evaluation of Countermeasures and Biometric Comparators"></a>t-EER: Parameter-Free Tandem Evaluation of Countermeasures and Biometric Comparators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12237">http://arxiv.org/abs/2309.12237</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/takhemlata/t-eer">https://github.com/takhemlata/t-eer</a></li>
<li>paper_authors: Tomi Kinnunen, Kong Aik Lee, Hemlata Tak, Nicholas Evans, Andreas Nautsch</li>
<li>for: 本研究旨在提出一种新的tandem equal error rate（t-EER）度量，用于同时评估 spoofing 检测（PAD）和生物特征验证（biometric verification）系统的可靠性。</li>
<li>methods: 本研究使用了模态（并可能是应用）无关的模拟得分，以及真实的声波生物特征应用程序得分，来证明 t-EER 的应用性。</li>
<li>results: 研究发现，t-EER 是一个具有优点的度量，可以同时评估 PAD 和 biometric verification 系统的可靠性。<details>
<summary>Abstract</summary>
Presentation attack (spoofing) detection (PAD) typically operates alongside biometric verification to improve reliablity in the face of spoofing attacks. Even though the two sub-systems operate in tandem to solve the single task of reliable biometric verification, they address different detection tasks and are hence typically evaluated separately. Evidence shows that this approach is suboptimal. We introduce a new metric for the joint evaluation of PAD solutions operating in situ with biometric verification. In contrast to the tandem detection cost function proposed recently, the new tandem equal error rate (t-EER) is parameter free. The combination of two classifiers nonetheless leads to a \emph{set} of operating points at which false alarm and miss rates are equal and also dependent upon the prevalence of attacks. We therefore introduce the \emph{concurrent} t-EER, a unique operating point which is invariable to the prevalence of attacks. Using both modality (and even application) agnostic simulated scores, as well as real scores for a voice biometrics application, we demonstrate application of the t-EER to a wide range of biometric system evaluations under attack. The proposed approach is a strong candidate metric for the tandem evaluation of PAD systems and biometric comparators.
</details>
<details>
<summary>摘要</summary>
translate into Simplified Chinese:presentation attack (spoofing) detection (PAD) 通常与生物认证结合使用，以提高骗用攻击时的可靠性。尽管这两个子系统在解决单一任务的可靠生物认证时都会运行，但它们处理不同的检测任务，因此通常会被分别评估。证据表明，这种方法是不优化的。我们介绍了一个新的度量来评估在生物认证过程中运行的 PAD 解决方案。与最近提出的 tandem 检测成本函数不同，我们的新 tandem 相同错误率（t-EER）没有参数。尽管这两个分类器组合会导致一个集合的操作点，其中假阳数和遗漏率都是等值的，并且受到攻击频率的影响。因此，我们引入了同时concurrent 的 t-EER，这是不受攻击频率影响的唯一操作点。使用模式（甚至应用）无关的模拟得分，以及一个voice biometrics应用的实际得分，我们在攻击下进行了广泛的生物系统评估。我们的提出的方法是tandem 评估 PAD 系统和生物比较器的强有力的候选度量。
</details></li>
</ul>
<hr>
<h2 id="Smooth-ECE-Principled-Reliability-Diagrams-via-Kernel-Smoothing"><a href="#Smooth-ECE-Principled-Reliability-Diagrams-via-Kernel-Smoothing" class="headerlink" title="Smooth ECE: Principled Reliability Diagrams via Kernel Smoothing"></a>Smooth ECE: Principled Reliability Diagrams via Kernel Smoothing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12236">http://arxiv.org/abs/2309.12236</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/apple/ml-calibration">https://github.com/apple/ml-calibration</a></li>
<li>paper_authors: Jarosław Błasiok, Preetum Nakkiran</li>
<li>for: 这篇论文主要是关于如何量化和解释抽象预测器的准确性，以及如何解决常见的量化问题。</li>
<li>methods: 这篇论文提出了一种简单的修正方法，即首先使用RBF核函数滤波 Observations，然后计算这个滤波后的预测器的准确性指标。 authors 证明这种方法可以提供一个准确的准确性指标，并且可以视觉地编码这个指标。</li>
<li>results: 论文的实验结果表明，这种修正方法可以减轻常见的量化问题，并且可以提供一个更加准确的准确性指标。 此外，这种方法还可以生成一个视觉化的准确性图表，可以较好地表示预测器的准确性。<details>
<summary>Abstract</summary>
Calibration measures and reliability diagrams are two fundamental tools for measuring and interpreting the calibration of probabilistic predictors. Calibration measures quantify the degree of miscalibration, and reliability diagrams visualize the structure of this miscalibration. However, the most common constructions of reliability diagrams and calibration measures -- binning and ECE -- both suffer from well-known flaws (e.g. discontinuity). We show that a simple modification fixes both constructions: first smooth the observations using an RBF kernel, then compute the Expected Calibration Error (ECE) of this smoothed function. We prove that with a careful choice of bandwidth, this method yields a calibration measure that is well-behaved in the sense of (B{\l}asiok, Gopalan, Hu, and Nakkiran 2023a) -- a consistent calibration measure. We call this measure the SmoothECE. Moreover, the reliability diagram obtained from this smoothed function visually encodes the SmoothECE, just as binned reliability diagrams encode the BinnedECE.   We also provide a Python package with simple, hyperparameter-free methods for measuring and plotting calibration: `pip install relplot\`.
</details>
<details>
<summary>摘要</summary>
“滑动测量和可靠图是两种基本工具用于测量和解释 probabilistic 预测器的准确性。滑动测量量化了偏差的度量，而可靠图可视化了这种偏差的结构。但是，最常用的可靠图和准确度测量的构造（例如 binning 和 ECE）都受到了良好知名的缺陷（例如缺点）。我们展示了一种简单的修改可以解决这些缺陷：首先使用 RBF 核函数平滑 observation，然后计算这个平滑函数的预期准确性错误（ECE）。我们证明了，在选择合适的宽度时，这种方法可以得到一个准确的准确度测量。我们称这种测量为 SmoothECE。此外，从这个平滑函数中获得的可靠图可以视觉地编码 SmoothECE，与 binning 可靠图中的 BinnedECE 类似。我们还提供了一个 Python 包，其中包含了简单、无参数的准确度测量和可靠图plotting 方法：`pip install relplot`。”Note: The translation is in Simplified Chinese, which is one of the two standard forms of Chinese. The other form is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Smooth-Nash-Equilibria-Algorithms-and-Complexity"><a href="#Smooth-Nash-Equilibria-Algorithms-and-Complexity" class="headerlink" title="Smooth Nash Equilibria: Algorithms and Complexity"></a>Smooth Nash Equilibria: Algorithms and Complexity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12226">http://arxiv.org/abs/2309.12226</a></li>
<li>repo_url: None</li>
<li>paper_authors: Constantinos Daskalakis, Noah Golowich, Nika Haghtalab, Abhishek Shetty</li>
<li>for: 这篇论文是关于泛函游挥的一种改进方法，以提高计算效率。</li>
<li>methods: 作者引入了一种叫做$\sigma$-细腻 Nash均衡的概念，通过弱化约束来提高计算效率。</li>
<li>results: 作者证明了在一定参数 Régime 下，存在常量时间的随机算法可以查找弱$\epsilon$-近似$\sigma$-细腻 Nash均衡，以及一个多项式时间的杜氏算法可以查找强$\epsilon$-近似$\sigma$-细腻 Nash均衡。<details>
<summary>Abstract</summary>
A fundamental shortcoming of the concept of Nash equilibrium is its computational intractability: approximating Nash equilibria in normal-form games is PPAD-hard. In this paper, inspired by the ideas of smoothed analysis, we introduce a relaxed variant of Nash equilibrium called $\sigma$-smooth Nash equilibrium, for a smoothness parameter $\sigma$. In a $\sigma$-smooth Nash equilibrium, players only need to achieve utility at least as high as their best deviation to a $\sigma$-smooth strategy, which is a distribution that does not put too much mass (as parametrized by $\sigma$) on any fixed action. We distinguish two variants of $\sigma$-smooth Nash equilibria: strong $\sigma$-smooth Nash equilibria, in which players are required to play $\sigma$-smooth strategies under equilibrium play, and weak $\sigma$-smooth Nash equilibria, where there is no such requirement.   We show that both weak and strong $\sigma$-smooth Nash equilibria have superior computational properties to Nash equilibria: when $\sigma$ as well as an approximation parameter $\epsilon$ and the number of players are all constants, there is a constant-time randomized algorithm to find a weak $\epsilon$-approximate $\sigma$-smooth Nash equilibrium in normal-form games. In the same parameter regime, there is a polynomial-time deterministic algorithm to find a strong $\epsilon$-approximate $\sigma$-smooth Nash equilibrium in a normal-form game. These results stand in contrast to the optimal algorithm for computing $\epsilon$-approximate Nash equilibria, which cannot run in faster than quasipolynomial-time. We complement our upper bounds by showing that when either $\sigma$ or $\epsilon$ is an inverse polynomial, finding a weak $\epsilon$-approximate $\sigma$-smooth Nash equilibria becomes computationally intractable.
</details>
<details>
<summary>摘要</summary>
“纳什平衡概念的基本缺陷是其计算复杂性：在正常形游戏中，approximating纳什平衡是PPAD困难的。在这篇论文中，我们采纳了缓和分析的想法，并引入了一种名为$\sigma$-缓平衡的弱化版本。在$\sigma$-缓平衡中，玩家只需要实现Utility在最好的偏转前的最高水平，这个水平是一个 Distribution 不能集中过多的动作。我们分为两种类型的$\sigma$-缓平衡：强$\sigma$-缓平衡和弱$\sigma$-缓平衡。在强$\sigma$-缓平衡中，玩家在平衡状态下必须采用$\sigma$-缓动作，而在弱$\sigma$-缓平衡中，没有这种要求。我们证明了两种$\sigma$-缓平衡都有较好的计算性质：当$\sigma$ 以及approximation参数 $\epsilon$ 和玩家数量都是常数时，可以在常数时间内随机找到一个 $\epsilon$-近似的 $\sigma$-缓平衡。在同样的参数 régime 中，可以在多项时间内决定一个强 $\epsilon$-近似的 $\sigma$-缓平衡。这些结果与 оптималь的算法 для计算 $\epsilon$-近似纳什平衡不同，它们不能在更快的 quasi-polynomial 时间内运行。我们补充我们的上限 bounds ，表明当 $\sigma$ 或 $\epsilon$ 是反对数 polynomials 时，找到一个 $\epsilon$-近似的 $\sigma$-缓平衡变得计算困难。”
</details></li>
</ul>
<hr>
<h2 id="Regionally-Additive-Models-Explainable-by-design-models-minimizing-feature-interactions"><a href="#Regionally-Additive-Models-Explainable-by-design-models-minimizing-feature-interactions" class="headerlink" title="Regionally Additive Models: Explainable-by-design models minimizing feature interactions"></a>Regionally Additive Models: Explainable-by-design models minimizing feature interactions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12215">http://arxiv.org/abs/2309.12215</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/givasile/RAM">https://github.com/givasile/RAM</a></li>
<li>paper_authors: Vasilis Gkolemis, Anargiros Tzerefos, Theodore Dalamagas, Eirini Ntoutsi, Christos Diou</li>
<li>for: 用于解释性模型的应用，如数据科学和机器学习。</li>
<li>methods: 使用地域添加模型（RAMs），一种新的解释性模型，可以在多个特征之间的交互 ТерMINUS 下提高表达能力。</li>
<li>results: 对 synthetic 和实际数据进行实验，结果表明 RAMs 可以提高表达能力 compared to GAMs 而又保持可解释性。<details>
<summary>Abstract</summary>
Generalized Additive Models (GAMs) are widely used explainable-by-design models in various applications. GAMs assume that the output can be represented as a sum of univariate functions, referred to as components. However, this assumption fails in ML problems where the output depends on multiple features simultaneously. In these cases, GAMs fail to capture the interaction terms of the underlying function, leading to subpar accuracy. To (partially) address this issue, we propose Regionally Additive Models (RAMs), a novel class of explainable-by-design models. RAMs identify subregions within the feature space where interactions are minimized. Within these regions, it is more accurate to express the output as a sum of univariate functions (components). Consequently, RAMs fit one component per subregion of each feature instead of one component per feature. This approach yields a more expressive model compared to GAMs while retaining interpretability. The RAM framework consists of three steps. Firstly, we train a black-box model. Secondly, using Regional Effect Plots, we identify subregions where the black-box model exhibits near-local additivity. Lastly, we fit a GAM component for each identified subregion. We validate the effectiveness of RAMs through experiments on both synthetic and real-world datasets. The results confirm that RAMs offer improved expressiveness compared to GAMs while maintaining interpretability.
</details>
<details>
<summary>摘要</summary>
通用加itive模型（GAMs）广泛应用于不同领域的解释可能模型。GAMs假设输出可以表示为一个或多个变量函数的总和，称为组件。然而，在机器学习问题中，输出与多个特征同时相互作用，这导致GAMs无法捕捉到下面函数的交叉项，从而导致准确率下降。为解决这个问题，我们提出了地域加itive模型（RAMs），一种新的解释可能模型。RAMs将特征空间分成多个子区域，其中交叉项减少。在这些子区域内，我们可以更准确地表示输出为一个或多个变量函数的总和（组件）。因此，RAMs在每个特征上采用一个组件，而不是一个组件。这种方法比GAMs更加表达力，同时保持可解释性。RAMs的框架包括三个步骤：首先，我们训练黑盒模型；其次，使用地域效果图来确定特征空间中交叉项下降的子区域；最后，我们在每个确定的子区域内采用GAM组件。我们通过对真实数据和 sintetic 数据进行实验，证明RAMs可以提高表达力，同时保持可解释性。
</details></li>
</ul>
<hr>
<h2 id="SupeRBNN-Randomized-Binary-Neural-Network-Using-Adiabatic-Superconductor-Josephson-Devices"><a href="#SupeRBNN-Randomized-Binary-Neural-Network-Using-Adiabatic-Superconductor-Josephson-Devices" class="headerlink" title="SupeRBNN: Randomized Binary Neural Network Using Adiabatic Superconductor Josephson Devices"></a>SupeRBNN: Randomized Binary Neural Network Using Adiabatic Superconductor Josephson Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12212">http://arxiv.org/abs/2309.12212</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengang Li, Geng Yuan, Tomoharu Yamauchi, Zabihi Masoud, Yanyue Xie, Peiyan Dong, Xulong Tang, Nobuyuki Yoshikawa, Devesh Tiwari, Yanzhi Wang, Olivia Chen</li>
<li>for: 用于逻辑 neuromorphic computing 加速</li>
<li>methods: 使用 randomized behavior 和软件硬件协调</li>
<li>results: 实现了约 7.8 x 10^4 倍的能效率提升，与同级准确性相当Here’s the full translation of the paper’s abstract in Simplified Chinese:</li>
<li>for: 本文用于逻辑 neuromorphic computing 加速</li>
<li>methods: 利用 AQFP 设备的随机行为和软件硬件协调</li>
<li>results: 实现了约 7.8 x 10^4 倍的能效率提升，与同级准确性相当I hope this helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
Adiabatic Quantum-Flux-Parametron (AQFP) is a superconducting logic with extremely high energy efficiency. By employing the distinct polarity of current to denote logic `0' and `1', AQFP devices serve as excellent carriers for binary neural network (BNN) computations. Although recent research has made initial strides toward developing an AQFP-based BNN accelerator, several critical challenges remain, preventing the design from being a comprehensive solution. In this paper, we propose SupeRBNN, an AQFP-based randomized BNN acceleration framework that leverages software-hardware co-optimization to eventually make the AQFP devices a feasible solution for BNN acceleration. Specifically, we investigate the randomized behavior of the AQFP devices and analyze the impact of crossbar size on current attenuation, subsequently formulating the current amplitude into the values suitable for use in BNN computation. To tackle the accumulation problem and improve overall hardware performance, we propose a stochastic computing-based accumulation module and a clocking scheme adjustment-based circuit optimization method. We validate our SupeRBNN framework across various datasets and network architectures, comparing it with implementations based on different technologies, including CMOS, ReRAM, and superconducting RSFQ/ERSFQ. Experimental results demonstrate that our design achieves an energy efficiency of approximately 7.8x10^4 times higher than that of the ReRAM-based BNN framework while maintaining a similar level of model accuracy. Furthermore, when compared with superconductor-based counterparts, our framework demonstrates at least two orders of magnitude higher energy efficiency.
</details>
<details>
<summary>摘要</summary>
adiabatic量子流 Parametron (AQFP) 是一种超导逻辑，其能效率极高。通过使用电流的正负polarity来表示逻辑“0”和“1”，AQFP设备成为了优秀的二进制神经网络（BNN）计算器。虽然最近的研究已经做出了初步的进展，但还有许多关键挑战，使得AQFP设备无法成为全面的解决方案。在这篇论文中，我们提出了SupeRBNN框架，它是基于AQFP的随机BNN加速器，通过软件硬件协同优化来使AQFP设备成为BNN加速器的可能性。我们调查了AQFP设备的随机行为，分析了交叉板大小对电流强度的影响，并将电流强度转化为适合BNN计算的值。为了解决积累问题并提高硬件性能，我们提出了随机计算模块和时钟控制调整的电路优化方法。我们在不同的 datasets 和网络架构上验证了我们的SupeRBNN框架，与不同的技术，包括CMOS、ReRAM和超导器RSFQ/ERSFQ进行比较。实验结果表明，我们的设计可以达到约7.8亿次高于ReRAM基于BNN框架的能效率，同时保持相同的模型准确性。此外，与超导器基于的同类设计相比，我们的设计可以达到至少两个数量级的高于能效率。
</details></li>
</ul>
<hr>
<h2 id="Physics-informed-State-space-Neural-Networks-for-Transport-Phenomena"><a href="#Physics-informed-State-space-Neural-Networks-for-Transport-Phenomena" class="headerlink" title="Physics-informed State-space Neural Networks for Transport Phenomena"></a>Physics-informed State-space Neural Networks for Transport Phenomena</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12211">http://arxiv.org/abs/2309.12211</a></li>
<li>repo_url: None</li>
<li>paper_authors: Akshay J Dave, Richard B. Vilim</li>
<li>for: 这篇论文旨在提出一种基于物理约束的深度神经网络模型（PSM），用于实时优化、灵活性和系统故障异常的检测和诊断。</li>
<li>methods: 该论文使用感知数据和物理约束（PDE）来训练深度神经网络，实现物理约束的端到端可微分动态模型。</li>
<li>results: 通过两个在silico实验（加热管和冷却系统循环）的示例，证明PSMs比普通的数据驱动模型更加准确。此外，PSMs还可以用于创建非线性监管控制器和系统诊断算法。<details>
<summary>Abstract</summary>
This work introduces Physics-informed State-space neural network Models (PSMs), a novel solution to achieving real-time optimization, flexibility, and fault tolerance in autonomous systems, particularly in transport-dominated systems such as chemical, biomedical, and power plants. Traditional data-driven methods fall short due to a lack of physical constraints like mass conservation; PSMs address this issue by training deep neural networks with sensor data and physics-informing using components' Partial Differential Equations (PDEs), resulting in a physics-constrained, end-to-end differentiable forward dynamics model. Through two in silico experiments - a heated channel and a cooling system loop - we demonstrate that PSMs offer a more accurate approach than purely data-driven models.   Beyond accuracy, there are several compelling use cases for PSMs. In this work, we showcase two: the creation of a nonlinear supervisory controller through a sequentially updated state-space representation and the proposal of a diagnostic algorithm using residuals from each of the PDEs. The former demonstrates the ability of PSMs to handle both constant and time-dependent constraints, while the latter illustrates their value in system diagnostics and fault detection. We further posit that PSMs could serve as a foundation for Digital Twins, constantly updated digital representations of physical systems.
</details>
<details>
<summary>摘要</summary>
Besides accuracy, there are several compelling use cases for PSMs. In this work, we showcase two: the creation of a nonlinear supervisory controller through a sequentially updated state-space representation and the proposal of a diagnostic algorithm using residuals from each of the PDEs. The former demonstrates the ability of PSMs to handle both constant and time-dependent constraints, while the latter illustrates their value in system diagnostics and fault detection. We further propose that PSMs could serve as a foundation for Digital Twins, constantly updated digital representations of physical systems.
</details></li>
</ul>
<hr>
<h2 id="Boolformer-Symbolic-Regression-of-Logic-Functions-with-Transformers"><a href="#Boolformer-Symbolic-Regression-of-Logic-Functions-with-Transformers" class="headerlink" title="Boolformer: Symbolic Regression of Logic Functions with Transformers"></a>Boolformer: Symbolic Regression of Logic Functions with Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12207">http://arxiv.org/abs/2309.12207</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sdascoli/boolformer">https://github.com/sdascoli/boolformer</a></li>
<li>paper_authors: Stéphane d’Ascoli, Samy Bengio, Josh Susskind, Emmanuel Abbé</li>
<li>for: 该论文旨在介绍一种名为Boolformer的 transformer 架构，用于 симвоlic regression 的端到端推理。</li>
<li>methods: 该论文使用了一种名为 Boolformer 的 transformer 架构，通过使用 clean truth table 预测复杂函数的简洁表达式。</li>
<li>results: 该论文在一系列实际的二分类 datasets 上进行了评估，并示出了 Boolformer 的可解释性和高效性。  Additionally, the paper shows that Boolformer can be applied to the task of modeling gene regulatory networks, and is competitive with state-of-the-art genetic algorithms with a significant speedup.<details>
<summary>Abstract</summary>
In this work, we introduce Boolformer, the first Transformer architecture trained to perform end-to-end symbolic regression of Boolean functions. First, we show that it can predict compact formulas for complex functions which were not seen during training, when provided a clean truth table. Then, we demonstrate its ability to find approximate expressions when provided incomplete and noisy observations. We evaluate the Boolformer on a broad set of real-world binary classification datasets, demonstrating its potential as an interpretable alternative to classic machine learning methods. Finally, we apply it to the widespread task of modelling the dynamics of gene regulatory networks. Using a recent benchmark, we show that Boolformer is competitive with state-of-the art genetic algorithms with a speedup of several orders of magnitude. Our code and models are available publicly.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们介绍了Boolformer，第一个基于Transformer架构的端到端符号重 regression的布尔函数预测模型。我们首先表明，它可以在提供了干净的真值表时预测复杂函数的简洁表达。然后，我们示出它可以在提供不完整和噪声探测数据时找到近似表达。我们对一组真实世界的 binary 分类数据进行评估，示出它的可读性和可比较性。最后，我们将其应用于模型生物学制御网络的动态学习任务，使用最新的 benchmark ，并证明它与当前的遗传算法竞争。我们的代码和模型公共可用。
</details></li>
</ul>
<hr>
<h2 id="Optimal-Conditional-Inference-in-Adaptive-Experiments"><a href="#Optimal-Conditional-Inference-in-Adaptive-Experiments" class="headerlink" title="Optimal Conditional Inference in Adaptive Experiments"></a>Optimal Conditional Inference in Adaptive Experiments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12162">http://arxiv.org/abs/2309.12162</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiafeng Chen, Isaiah Andrews</li>
<li>for: 这 paper 的目的是为了推断批处理bandit实验中的参数，具体来说是在实验结束时的实现时间、分配概率和目标参数都可能会随机变化。</li>
<li>methods: 这 paper 使用了一种基于最后一批数据的推断方法，即只使用最后一批的结果进行推断。在批处理bandit实验中，如果Location-invariant的特性是保持不变，那么这种方法是最优的。在更加 restrictive 的情况下，如果实验停止时间、分配概率和目标参数都是通过数据来定义的polyhedral事件，那么可以 derivate  computationally tractable 和最优的 conditional inference 方法。</li>
<li>results: 这 paper 的结果表明，在批处理bandit实验中，使用最后一批数据进行推断是最优的。当批处理bandit实验中的特性是Location-invariant时，存在一个额外的信息，即批处理arm means的一个线性函数。在更加 restrictive 的情况下，可以 derivate  computationally tractable 和最优的 conditional inference 方法。<details>
<summary>Abstract</summary>
We study batched bandit experiments and consider the problem of inference conditional on the realized stopping time, assignment probabilities, and target parameter, where all of these may be chosen adaptively using information up to the last batch of the experiment. Absent further restrictions on the experiment, we show that inference using only the results of the last batch is optimal. When the adaptive aspects of the experiment are known to be location-invariant, in the sense that they are unchanged when we shift all batch-arm means by a constant, we show that there is additional information in the data, captured by one additional linear function of the batch-arm means. In the more restrictive case where the stopping time, assignment probabilities, and target parameter are known to depend on the data only through a collection of polyhedral events, we derive computationally tractable and optimal conditional inference procedures.
</details>
<details>
<summary>摘要</summary>
我们研究批处bandit实验，考虑实验结束时间、分配概率和目标参数的推断问题，这些参数都可能是通过实验前几批数据来采取适应性的选择。不含任何额外限制，我们显示在实验结束后使用最后一批数据进行推断是优化的。当批处arm的 adaptive 特性是位置不变的，即将所有批处arm的均值shifted by a constant，我们显示该数据中还存在一个额外的线性函数， capture 了批处arm的均值。在更restrictive的情况下， stopping time、分配概率和目标参数都是通过数据来定义的polyhedral事件集合，我们 derive  computationally tractable and optimal conditional inference procedures.Note: "批处bandit" refers to a batched bandit experiment, where the experimenter collects data by interacting with a set of arms (e.g., treatments or actions) in batches, rather than one at a time.
</details></li>
</ul>
<hr>
<h2 id="Towards-Robust-and-Truly-Large-Scale-Audio-Sheet-Music-Retrieval"><a href="#Towards-Robust-and-Truly-Large-Scale-Audio-Sheet-Music-Retrieval" class="headerlink" title="Towards Robust and Truly Large-Scale Audio-Sheet Music Retrieval"></a>Towards Robust and Truly Large-Scale Audio-Sheet Music Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12158">http://arxiv.org/abs/2309.12158</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luis Carvalho, Gerhard Widmer</li>
<li>for: 本研究旨在提供关于深度学习方法进行音频-谱面重 Retrieval的现状报告，以及解决这些问题的方法。</li>
<li>methods: 本研究使用cross-modal深度学习架构来学习谱面和音频之间的共同空间，以连接这两种不同的模式。</li>
<li>results: 研究表明，使用深度学习方法可以在不同模式之间建立连接，并且可以提高音频-谱面重 Retrieval的精度。但是，还有一些挑战需要解决，以实现大规模的应用。<details>
<summary>Abstract</summary>
A range of applications of multi-modal music information retrieval is centred around the problem of connecting large collections of sheet music (images) to corresponding audio recordings, that is, identifying pairs of audio and score excerpts that refer to the same musical content. One of the typical and most recent approaches to this task employs cross-modal deep learning architectures to learn joint embedding spaces that link the two distinct modalities - audio and sheet music images. While there has been steady improvement on this front over the past years, a number of open problems still prevent large-scale employment of this methodology. In this article we attempt to provide an insightful examination of the current developments on audio-sheet music retrieval via deep learning methods. We first identify a set of main challenges on the road towards robust and large-scale cross-modal music retrieval in real scenarios. We then highlight the steps we have taken so far to address some of these challenges, documenting step-by-step improvement along several dimensions. We conclude by analysing the remaining challenges and present ideas for solving these, in order to pave the way to a unified and robust methodology for cross-modal music retrieval.
</details>
<details>
<summary>摘要</summary>
多种多Modal音乐信息检索的应用中心于将大量的Sheet Music图像与相应的音频记录相连接，即将Audio和Sheet Music图像中的同一段音乐内容相匹配。最近的一种常见的方法是使用交叉模态深度学习建筑来学习连接两种不同模式的Audio和Sheet Music图像的共同空间。虽然在过去几年内有所进步，但还有许多未解决的问题，阻碍大规模应用这种方法。在这篇文章中，我们尝试提供了深入的检查现代深度学习方法在Audio-Sheet Music检索中的最新发展。我们首先确定了cross-modal音乐检索中的主要挑战，然后高亮我们已经采取的措施来解决一些这些挑战，并记录了一系列维度上的改进。我们最后分析了剩下的挑战，并提出了解决这些挑战的想法，以便推导一种简单、稳定的方法来实现cross-modal音乐检索。
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Contrastive-Learning-for-Robust-Audio-Sheet-Music-Retrieval-Systems"><a href="#Self-Supervised-Contrastive-Learning-for-Robust-Audio-Sheet-Music-Retrieval-Systems" class="headerlink" title="Self-Supervised Contrastive Learning for Robust Audio-Sheet Music Retrieval Systems"></a>Self-Supervised Contrastive Learning for Robust Audio-Sheet Music Retrieval Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12134">http://arxiv.org/abs/2309.12134</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hieu9955/ggggg">https://github.com/hieu9955/ggggg</a></li>
<li>paper_authors: Luis Carvalho, Tobias Washüttl, Gerhard Widmer</li>
<li>for: 提高跨模式音乐检索系统的效果</li>
<li>methods: 使用自动提取的音频和Sheet图像的对比学习</li>
<li>results: 在多种实验中，预训练模型可以更好地检索音频和Sheet图像的剪辑，并且在跨模式音乐标识任务中，检索精度从30%提高到100%。<details>
<summary>Abstract</summary>
Linking sheet music images to audio recordings remains a key problem for the development of efficient cross-modal music retrieval systems. One of the fundamental approaches toward this task is to learn a cross-modal embedding space via deep neural networks that is able to connect short snippets of audio and sheet music. However, the scarcity of annotated data from real musical content affects the capability of such methods to generalize to real retrieval scenarios. In this work, we investigate whether we can mitigate this limitation with self-supervised contrastive learning, by exposing a network to a large amount of real music data as a pre-training step, by contrasting randomly augmented views of snippets of both modalities, namely audio and sheet images. Through a number of experiments on synthetic and real piano data, we show that pre-trained models are able to retrieve snippets with better precision in all scenarios and pre-training configurations. Encouraged by these results, we employ the snippet embeddings in the higher-level task of cross-modal piece identification and conduct more experiments on several retrieval configurations. In this task, we observe that the retrieval quality improves from 30% up to 100% when real music data is present. We then conclude by arguing for the potential of self-supervised contrastive learning for alleviating the annotated data scarcity in multi-modal music retrieval models.
</details>
<details>
<summary>摘要</summary>
把乐谱图像和声音记录相连接是跨模态音乐检索系统的关键问题。一种基本的方法是通过深度神经网络学习跨模态嵌入空间，以连接短暂的声音和乐谱。但是，实际音乐内容上的标注数据的稀缺性影响这些方法在实际检索场景中的泛化能力。在这项工作中，我们研究了是否可以通过自我超vised强制学习来缓解这种限制，通过对模拟和真实音乐数据进行随机增强后，让网络对声音和乐谱两种模态进行对比。经过一些实验，我们发现在所有场景和预训练配置下，预训练模型都能够更好地进行检索。这些结果使我们对跨模态乐谱识别任务进行更多的实验，并观察到在真实音乐数据存在的情况下，检索质量从30%提高到100%。最后，我们 conclude通过自我超vised强制学习可以缓解跨模态音乐检索模型中的标注数据稀缺性。
</details></li>
</ul>
<hr>
<h2 id="Convergence-and-Recovery-Guarantees-of-Unsupervised-Neural-Networks-for-Inverse-Problems"><a href="#Convergence-and-Recovery-Guarantees-of-Unsupervised-Neural-Networks-for-Inverse-Problems" class="headerlink" title="Convergence and Recovery Guarantees of Unsupervised Neural Networks for Inverse Problems"></a>Convergence and Recovery Guarantees of Unsupervised Neural Networks for Inverse Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12128">http://arxiv.org/abs/2309.12128</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nathan Buskulic, Jalal Fadili, Yvain Quéau</li>
<li>for: 解决逆问题</li>
<li>methods: 使用无监督多层神经网络</li>
<li>results: 提供了确定的恢复和扩展 garanties，并 derive了过参数 boundsHere’s a more detailed explanation of each point:</li>
<li>for: The paper is written to solve inverse problems using unsupervised feedforward multilayer neural networks.</li>
<li>methods: The paper uses unsupervised feedforward multilayer neural networks to solve inverse problems.</li>
<li>results: The paper provides deterministic convergence and recovery guarantees for the class of unsupervised feedforward multilayer neural networks trained to solve inverse problems. Additionally, the paper derives overparametrization bounds under which a two-layers Deep Inverse Prior network with smooth activation function will benefit from the guarantees.<details>
<summary>Abstract</summary>
Neural networks have become a prominent approach to solve inverse problems in recent years. While a plethora of such methods was developed to solve inverse problems empirically, we are still lacking clear theoretical guarantees for these methods. On the other hand, many works proved convergence to optimal solutions of neural networks in a more general setting using overparametrization as a way to control the Neural Tangent Kernel. In this work we investigate how to bridge these two worlds and we provide deterministic convergence and recovery guarantees for the class of unsupervised feedforward multilayer neural networks trained to solve inverse problems. We also derive overparametrization bounds under which a two-layers Deep Inverse Prior network with smooth activation function will benefit from our guarantees.
</details>
<details>
<summary>摘要</summary>
neural networks 已成为 inverse problems 的解决方法之一，而且在过去几年中，有许多这种方法被开发出来解决 inverse problems。然而，我们仍然缺乏这些方法的明确理论保证。一方面，许多研究证明了 neural networks 在更一般情况下的抽象上是可控的，通过过 parametrization 来控制 Neural Tangent Kernel。在这篇文章中，我们尝试将这两个世界联系起来，并为 class of unsupervised feedforward multilayer neural networks 解决 inverse problems 提供确定的收敛和恢复保证。我们还 deriv overparametrization 下界，以便在 smooth activation function 的情况下，two-layers Deep Inverse Prior network 能够benefit from our guarantees。
</details></li>
</ul>
<hr>
<h2 id="Passage-Summarization-with-Recurrent-Models-for-Audio-Sheet-Music-Retrieval"><a href="#Passage-Summarization-with-Recurrent-Models-for-Audio-Sheet-Music-Retrieval" class="headerlink" title="Passage Summarization with Recurrent Models for Audio-Sheet Music Retrieval"></a>Passage Summarization with Recurrent Models for Audio-Sheet Music Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12111">http://arxiv.org/abs/2309.12111</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luis Carvalho, Gerhard Widmer</li>
<li>for: 这篇论文主要针对的是连接Sheet Music图像和音频录音的跨模态音乐检索问题。</li>
<li>methods: 该论文提出了一种基于深度神经网络学习的跨模态整合空间，通过适当的相似结构来相关短长 audio和Sheet Music snippet。</li>
<li>results: 该论文通过设计跨模态回归网络，解决了训练网络需要强相关数据和音频-Sheet Music snippet中的音乐内容差异问题。实验结果表明，该方法可以在所有可能的配置下提供更高精度的检索结果，只需要弱相关的音频-Sheet Music pair。<details>
<summary>Abstract</summary>
Many applications of cross-modal music retrieval are related to connecting sheet music images to audio recordings. A typical and recent approach to this is to learn, via deep neural networks, a joint embedding space that correlates short fixed-size snippets of audio and sheet music by means of an appropriate similarity structure. However, two challenges that arise out of this strategy are the requirement of strongly aligned data to train the networks, and the inherent discrepancies of musical content between audio and sheet music snippets caused by local and global tempo differences. In this paper, we address these two shortcomings by designing a cross-modal recurrent network that learns joint embeddings that can summarize longer passages of corresponding audio and sheet music. The benefits of our method are that it only requires weakly aligned audio-sheet music pairs, as well as that the recurrent network handles the non-linearities caused by tempo variations between audio and sheet music. We conduct a number of experiments on synthetic and real piano data and scores, showing that our proposed recurrent method leads to more accurate retrieval in all possible configurations.
</details>
<details>
<summary>摘要</summary>
很多跨Modal音乐检索应用都与将乐谱图像与音频录音相连接。一种常见的方法是通过深度神经网络学习一个共同embedding空间，以便通过适当的相似结构相关短段音频和乐谱图像。然而，这种策略存在两个挑战：首先，需要强相关的数据来训练网络；其次，由于音频和乐谱图像片段之间的本地和全局拍速差异，音频和乐谱图像之间的 Musical content会有差异。在这篇论文中，我们解决这两个缺陷，通过设计一种跨Modal循环网络，学习联合表示音频和乐谱图像的joint embedding。我们的方法的优点是：只需弱相关的音频-乐谱图像对，以及循环网络可以处理音频和乐谱图像之间的非线性。我们在synthetic和真实钢琴数据和谱面上进行了许多实验，结果表明，我们提议的循环方法可以在所有配置下实现更高精度的检索。
</details></li>
</ul>
<hr>
<h2 id="Memory-Efficient-Mixed-Precision-Optimizers"><a href="#Memory-Efficient-Mixed-Precision-Optimizers" class="headerlink" title="Memory Efficient Mixed-Precision Optimizers"></a>Memory Efficient Mixed-Precision Optimizers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12381">http://arxiv.org/abs/2309.12381</a></li>
<li>repo_url: None</li>
<li>paper_authors: Basile Lewandowski, Atli Kosson</li>
<li>for: 减少模型训练时的内存使用量和计算负担</li>
<li>methods: 使用混合精度浮点数算术和缺省梯度计算</li>
<li>results: 可以达到25%下降峰值内存使用量和15%快速训练速度，同时保持模型准确性水平<details>
<summary>Abstract</summary>
Traditional optimization methods rely on the use of single-precision floating point arithmetic, which can be costly in terms of memory size and computing power. However, mixed precision optimization techniques leverage the use of both single and half-precision floating point arithmetic to reduce memory requirements while maintaining model accuracy. We provide here an algorithm to further reduce memory usage during the training of a model by getting rid of the floating point copy of the parameters, virtually keeping only half-precision numbers. We also explore the benefits of getting rid of the gradient's value by executing the optimizer step during the back-propagation. In practice, we achieve up to 25% lower peak memory use and 15% faster training while maintaining the same level of accuracy.
</details>
<details>
<summary>摘要</summary>
（以下是简化中文版）传统优化方法通过单精度浮点数运算来实现，这可能会占用大量内存空间和计算资源。然而，混合精度优化技术利用单精度和半精度浮点数运算来减少内存需求，保持模型准确性。我们提供一种算法，以减少训练过程中模型参数的浮点复制，实际上只保留半精度数字。我们还探索了在反传propagation过程中禁用梯度值的优势，通过在反传propagation过程中执行优化器步骤。在实践中，我们达到了25%下降的峰值内存使用量和15%快速训练，同时保持同等准确性。
</details></li>
</ul>
<hr>
<h2 id="Clustering-based-Domain-Incremental-Learning"><a href="#Clustering-based-Domain-Incremental-Learning" class="headerlink" title="Clustering-based Domain-Incremental Learning"></a>Clustering-based Domain-Incremental Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12078">http://arxiv.org/abs/2309.12078</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/SOYJUN/Implement-ODR-protocol">https://github.com/SOYJUN/Implement-ODR-protocol</a></li>
<li>paper_authors: Christiaan Lamers, Rene Vidal, Nabil Belbachir, Niki van Stein, Thomas Baeck, Paris Giampouras</li>
<li>for: 解决 continual learning 中的 “灾难性忘记” 问题，即在学习新任务时，原有任务的性能下降的问题。</li>
<li>methods: 使用在线 clustering 方法，基于动态更新的 finite pool of samples 或 gradients，避免提供算法 task 变化信息。</li>
<li>results: 在域增量学习中成功避免灾难性忘记，并在实际 dataset 上进行了实验，比对state-of-the-art 方法的表现。<details>
<summary>Abstract</summary>
We consider the problem of learning multiple tasks in a continual learning setting in which data from different tasks is presented to the learner in a streaming fashion. A key challenge in this setting is the so-called "catastrophic forgetting problem", in which the performance of the learner in an "old task" decreases when subsequently trained on a "new task". Existing continual learning methods, such as Averaged Gradient Episodic Memory (A-GEM) and Orthogonal Gradient Descent (OGD), address catastrophic forgetting by minimizing the loss for the current task without increasing the loss for previous tasks. However, these methods assume the learner knows when the task changes, which is unrealistic in practice. In this paper, we alleviate the need to provide the algorithm with information about task changes by using an online clustering-based approach on a dynamically updated finite pool of samples or gradients. We thereby successfully counteract catastrophic forgetting in one of the hardest settings, namely: domain-incremental learning, a setting for which the problem was previously unsolved. We showcase the benefits of our approach by applying these ideas to projection-based methods, such as A-GEM and OGD, which lead to task-agnostic versions of them. Experiments on real datasets demonstrate the effectiveness of the proposed strategy and its promising performance compared to state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
我们考虑一个多任务学习的情况，在这个情况下，不同任务的数据会在流动的方式下提供给学习者。一个重要的挑战是所谓的“惨重遗传问题”，即在训练新任务后，学习者对旧任务的性能下降。现有的几种对策方法，如Averaged Gradient Episodic Memory（A-GEM）和Orthogonal Gradient Descent（OGD），可以避免惨重遗传，但是这些方法假设学习者知道任务的变化，这是实际上不可能的。在这篇论文中，我们解决这个问题，通过在动态更新的有限组合中使用线上剂化的方法，以避免学习者对旧任务的损害。我们运用这些想法，将A-GEM和OGD等方法转换为任务不对称的版本，并对真实数据进行实验，展示了我们的方法的有效性和与现有方法相比的应用前景。
</details></li>
</ul>
<hr>
<h2 id="S-GBDT-Frugal-Differentially-Private-Gradient-Boosting-Decision-Trees"><a href="#S-GBDT-Frugal-Differentially-Private-Gradient-Boosting-Decision-Trees" class="headerlink" title="S-GBDT: Frugal Differentially Private Gradient Boosting Decision Trees"></a>S-GBDT: Frugal Differentially Private Gradient Boosting Decision Trees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12041">http://arxiv.org/abs/2309.12041</a></li>
<li>repo_url: None</li>
<li>paper_authors: Moritz Kirschte, Thorsten Peinemann, Joshua Stock, Carlos Cotrini, Esfandiar Mohammadi</li>
<li>for: 这个研究旨在实现隐私保护的Gradient Boosting Decision Trees（GBDT）学习，以实现强大的实用性与隐私贸易。</li>
<li>methods: 本研究使用了四种主要技术来改善实用性与隐私贸易的问题：（1）改进隐私泄露的规定，使其与实际泄露规律相符；（2）将个人Rényi范围给integrated into our method，以从训练过程中未利用的数据点中学习；（3）将随机决策树分割给集中隐私预算；（4）将隐私预算优化。</li>
<li>results: 我们的评估结果显示，在Abalone dataset（约4k训练数据点）上，我们可以在隐私水平$\varepsilon&#x3D;0.15$下达到$R^2$-score的0.39，比前一代研究只能在$\varepsilon&#x3D;10.0$下达到。在Adult dataset（50k训练数据点）上，我们可以在隐私水平$\varepsilon&#x3D;0.07$下达到test error的18.7%，比前一代研究只能在$\varepsilon&#x3D;1.0$下达到。在Abalone dataset上，在隐私水平$\varepsilon&#x3D;0.54$下，我们可以达到$R^2$-score的0.47，仅次于非隐私版本的GBDT。在Adult dataset上，在隐私水平$\varepsilon&#x3D;0.54$下，我们可以达到test error的17.1%，仅次于非隐私版本的GBDT。<details>
<summary>Abstract</summary>
Privacy-preserving learning of gradient boosting decision trees (GBDT) has the potential for strong utility-privacy tradeoffs for tabular data, such as census data or medical meta data: classical GBDT learners can extract non-linear patterns from small sized datasets. The state-of-the-art notion for provable privacy-properties is differential privacy, which requires that the impact of single data points is limited and deniable. We introduce a novel differentially private GBDT learner and utilize four main techniques to improve the utility-privacy tradeoff. (1) We use an improved noise scaling approach with tighter accounting of privacy leakage of a decision tree leaf compared to prior work, resulting in noise that in expectation scales with $O(1/n)$, for $n$ data points. (2) We integrate individual R\'enyi filters to our method to learn from data points that have been underutilized during an iterative training process, which -- potentially of independent interest -- results in a natural yet effective insight to learning streams of non-i.i.d. data. (3) We incorporate the concept of random decision tree splits to concentrate privacy budget on learning leaves. (4) We deploy subsampling for privacy amplification. Our evaluation shows for the Abalone dataset ($<4k$ training data points) a $R^2$-score of $0.39$ for $\varepsilon=0.15$, which the closest prior work only achieved for $\varepsilon=10.0$. On the Adult dataset ($50k$ training data points) we achieve test error of $18.7\,\%$ for $\varepsilon=0.07$ which the closest prior work only achieved for $\varepsilon=1.0$. For the Abalone dataset for $\varepsilon=0.54$ we achieve $R^2$-score of $0.47$ which is very close to the $R^2$-score of $0.54$ for the nonprivate version of GBDT. For the Adult dataset for $\varepsilon=0.54$ we achieve test error $17.1\,\%$ which is very close to the test error $13.7\,\%$ of the nonprivate version of GBDT.
</details>
<details>
<summary>摘要</summary>
privacy-preserving 学习gradient boosting decision trees（GBDT）具有强大的用于数据的可用性-隐私贸易，例如人口普查数据或医疗数据：经典GBDT学习者可以从小型数据集中提取非线性模式。我们引入了一种新的具有可证明隐私性质的GBDT学习器，并利用以下四种主要技术来提高用于隐私贸易的质量：1. 我们使用改进的噪声涨落方法，对决策树叶的隐私泄露进行更精细的评估，从而使噪声在平均情况下与$O(1/n)$相关，其中$n$是数据点数。2. 我们将个体Rényi筛选器 integrate到我们的方法中，以利用在训练过程中尚未被利用的数据点，这可能是独立有趣的发现，可能是自然而有效的学习流程。3. 我们利用随机决策树分裂的概念，将隐私预算集中在学习叶。4. 我们使用隐私压缩。我们的评估表明，对于Abalone数据集（训练数据点数 fewer than 4k），我们可以在$\ε=0.15$下 achieved $R^2$-score of 0.39，而最接近的前一个工作只能在$\ε=10.0$下达到这个成绩。对于Adult数据集（训练数据点数为50k），我们可以在$\ε=0.07$下 achieved test error of 18.7%，而最接近的前一个工作只能在$\ε=1.0$下达到这个成绩。对于Abalone数据集，当$\varepsilon=0.54$时，我们可以 achieved $R^2$-score of 0.47，几乎与非隐私版GBDT的$R^2$-score相同（0.54）。对于Adult数据集，当$\varepsilon=0.54$时，我们可以 achieved test error of 17.1%，几乎与非隐私版GBDT的test error相同（13.7%）。
</details></li>
</ul>
<hr>
<h2 id="Uplift-vs-predictive-modeling-a-theoretical-analysis"><a href="#Uplift-vs-predictive-modeling-a-theoretical-analysis" class="headerlink" title="Uplift vs. predictive modeling: a theoretical analysis"></a>Uplift vs. predictive modeling: a theoretical analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12036">http://arxiv.org/abs/2309.12036</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/theoverhelst/uplift-predictive-paper">https://github.com/theoverhelst/uplift-predictive-paper</a></li>
<li>paper_authors: Théo Verhelst, Robin Petit, Wouter Verbeke, Gianluca Bontempi</li>
<li>for: 本研究旨在评估机器学习技术在决策中的added value，并对相关领域的实践者提供指导。</li>
<li>methods: 本文使用了causal-oriented策略，包括uplift模型和predictive方法，并对这些方法的性能进行了 theoretically 分析。</li>
<li>results: 研究发现，在某些情况下，uplift模型可以超过predictive方法的性能，但这取决于一些参数，如 Mutual Information、variance of estimators、distribution of potential outcomes 和underlying costs and benefits。<details>
<summary>Abstract</summary>
Despite the growing popularity of machine-learning techniques in decision-making, the added value of causal-oriented strategies with respect to pure machine-learning approaches has rarely been quantified in the literature. These strategies are crucial for practitioners in various domains, such as marketing, telecommunications, health care and finance. This paper presents a comprehensive treatment of the subject, starting from firm theoretical foundations and highlighting the parameters that influence the performance of the uplift and predictive approaches. The focus of the paper is on a binary outcome case and a binary action, and the paper presents a theoretical analysis of uplift modeling, comparing it with the classical predictive approach. The main research contributions of the paper include a new formulation of the measure of profit, a formal proof of the convergence of the uplift curve to the measure of profit ,and an illustration, through simulations, of the conditions under which predictive approaches still outperform uplift modeling. We show that the mutual information between the features and the outcome plays a significant role, along with the variance of the estimators, the distribution of the potential outcomes and the underlying costs and benefits of the treatment and the outcome.
</details>
<details>
<summary>摘要</summary>
尽管机器学习技术在决策中日益受欢迎，但是 causal-oriented 策略在相关文献中对于纯机器学习方法的加值 rarely been quantified. 这些策略在各个领域，如市场营销、电信、医疗和金融中都非常重要。这篇论文从公司理论基础开始， highlighting the parameters that influence the performance of the uplift and predictive approaches。文章的ocus是二分类结果的情况，并对 uplift 模型与传统预测方法进行比较。文章的主要研究贡献包括：1. 一种新的衡量利润的形式。2. 预测曲线的整合到利润的正式证明。3. 通过模拟来说明，在某些条件下，预测方法仍然超越 uplift 模型。我们发现，Feature 和结果之间的共识度和估计器的方差、潜在结果的分布、对于治疗和结果的成本和利益都对 uplift 模型的性能产生了重要影响。
</details></li>
</ul>
<hr>
<h2 id="Human-in-the-Loop-Causal-Discovery-under-Latent-Confounding-using-Ancestral-GFlowNets"><a href="#Human-in-the-Loop-Causal-Discovery-under-Latent-Confounding-using-Ancestral-GFlowNets" class="headerlink" title="Human-in-the-Loop Causal Discovery under Latent Confounding using Ancestral GFlowNets"></a>Human-in-the-Loop Causal Discovery under Latent Confounding using Ancestral GFlowNets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12032">http://arxiv.org/abs/2309.12032</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tiago da Silva, Eliezer Silva, Adèle Ribeiro, António Góis, Dominik Heider, Samuel Kaski, Diego Mesquita<br>for:The paper is written to address the issue of brittleness in causal discovery algorithms when dealing with scarce data and latent confounders, and to provide a new method that incorporates expert knowledge to improve the inference process.methods:The paper proposes a new method that uses generative flow networks to sample causal ancestral graphs proportionally to a belief distribution based on a score function, such as the Bayesian information criterion (BIC). The method also leverages an optimal experimental design to iteratively probe the expert about the relations among variables, and updates the samples with human feedback via importance sampling.results:The paper shows through experiments with synthetic observational data that the proposed method can accurately sample from distributions over ancestral graphs and greatly improve inference quality with human aid.<details>
<summary>Abstract</summary>
Structure learning is the crux of causal inference. Notably, causal discovery (CD) algorithms are brittle when data is scarce, possibly inferring imprecise causal relations that contradict expert knowledge -- especially when considering latent confounders. To aggravate the issue, most CD methods do not provide uncertainty estimates, making it hard for users to interpret results and improve the inference process. Surprisingly, while CD is a human-centered affair, no works have focused on building methods that both 1) output uncertainty estimates that can be verified by experts and 2) interact with those experts to iteratively refine CD. To solve these issues, we start by proposing to sample (causal) ancestral graphs proportionally to a belief distribution based on a score function, such as the Bayesian information criterion (BIC), using generative flow networks. Then, we leverage the diversity in candidate graphs and introduce an optimal experimental design to iteratively probe the expert about the relations among variables, effectively reducing the uncertainty of our belief over ancestral graphs. Finally, we update our samples to incorporate human feedback via importance sampling. Importantly, our method does not require causal sufficiency (i.e., unobserved confounders may exist). Experiments with synthetic observational data show that our method can accurately sample from distributions over ancestral graphs and that we can greatly improve inference quality with human aid.
</details>
<details>
<summary>摘要</summary>
STRUCTURE learning 是 causal inference 的关键。尤其是 causal discovery（CD）算法在数据稀缺时会变得脆弱，可能推断不准确的 causal 关系，而且这些关系可能与专家知识相悖。此外，大多数 CD 方法不提供 uncertainty 估计，使得用户很难 интерпретирова结果并改进推断过程。尚未有任何works 关注建立可以 both 1) 输出 uncertainty 估计，并且 2) 与专家进行迭代改进 CD 的方法。为解决这些问题，我们开始由 sampling (causal) ancestral graphs 根据信念分布（如 Bayesian information criterion，BIC）中的分配函数，使用生成流网络。然后，我们利用候选图的多样性，引入 optimal experimental design 以让专家关于变量之间的关系进行反馈，从而减少我们对 ancestral graphs 的信念不确定性。最后，我们通过 importance sampling 更新我们的样本，以反映专家的反馈。需要注意的是，我们的方法不需要 causal sufficiency（即存在无观察隐变量）。使用 sintetic observational data 的实验表明，我们的方法可以准确地从 distributions over ancestral graphs 中采样，并且可以通过专家的帮助大幅提高推断质量。
</details></li>
</ul>
<hr>
<h2 id="Methods-for-generating-and-evaluating-synthetic-longitudinal-patient-data-a-systematic-review"><a href="#Methods-for-generating-and-evaluating-synthetic-longitudinal-patient-data-a-systematic-review" class="headerlink" title="Methods for generating and evaluating synthetic longitudinal patient data: a systematic review"></a>Methods for generating and evaluating synthetic longitudinal patient data: a systematic review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12380">http://arxiv.org/abs/2309.12380</a></li>
<li>repo_url: None</li>
<li>paper_authors: Katariina Perkonoja, Kari Auranen, Joni Virta</li>
<li>for: This paper is written for researchers and developers who are interested in generating and evaluating synthetic longitudinal patient data in medicine, with the aim of addressing the issue of data privacy and availability.</li>
<li>methods: The paper presents a systematic review of 17 methods for generating and evaluating synthetic longitudinal patient data, including traditional simulation techniques and modern deep learning methods. The methods are evaluated based on their type, source code availability, and approaches used to assess resemblance, utility, and privacy.</li>
<li>results: The paper provides a comprehensive overview of the existing methods for generating and evaluating synthetic longitudinal patient data, and discusses practical guidelines and key considerations for developing such methods. The paper also highlights the challenges and limitations of these methods, and identifies future research directions in this area.<details>
<summary>Abstract</summary>
The proliferation of data in recent years has led to the advancement and utilization of various statistical and deep learning techniques, thus expediting research and development activities. However, not all industries have benefited equally from the surge in data availability, partly due to legal restrictions on data usage and privacy regulations, such as in medicine. To address this issue, various statistical disclosure and privacy-preserving methods have been proposed, including the use of synthetic data generation. Synthetic data are generated based on some existing data, with the aim of replicating them as closely as possible and acting as a proxy for real sensitive data. This paper presents a systematic review of methods for generating and evaluating synthetic longitudinal patient data, a prevalent data type in medicine. The review adheres to the PRISMA guidelines and covers literature from five databases until the end of 2022. The paper describes 17 methods, ranging from traditional simulation techniques to modern deep learning methods. The collected information includes, but is not limited to, method type, source code availability, and approaches used to assess resemblance, utility, and privacy. Furthermore, the paper discusses practical guidelines and key considerations for developing synthetic longitudinal data generation methods.
</details>
<details>
<summary>摘要</summary>
“在最近几年，数据的普及和深入应用的技术得到了普及和应用，从而加速了研究和开发活动。然而，不是所有领域都得到了同等的利益，部分是因为数据使用和隐私法规的限制，如医学。为解决这个问题，一些统计透明度和隐私保护方法被提议，包括使用 sintetic 数据生成。 sintetic 数据是基于现有数据，目的是尽可能地复制它们，并作为真正敏感数据的代理。本文发表了一项系统性的评论，涵盖了生成和评估 sintetic 长期患者数据的方法。评论遵循 PRISMA 指南，检索到2022年底止的五个数据库中的文献。文章描述了 17 种方法，从传统的模拟技术到现代的深度学习方法。收集的信息包括，但不限于：方法类型、代码可用性和用于评估相似性、有用性和隐私的方法。此外，文章还讨论了实践指南和关键考虑事项，用于开发 sintetic 长期患者数据生成方法。”
</details></li>
</ul>
<hr>
<h2 id="Robust-Approximation-Algorithms-for-Non-monotone-k-Submodular-Maximization-under-a-Knapsack-Constraint"><a href="#Robust-Approximation-Algorithms-for-Non-monotone-k-Submodular-Maximization-under-a-Knapsack-Constraint" class="headerlink" title="Robust Approximation Algorithms for Non-monotone $k$-Submodular Maximization under a Knapsack Constraint"></a>Robust Approximation Algorithms for Non-monotone $k$-Submodular Maximization under a Knapsack Constraint</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12025">http://arxiv.org/abs/2309.12025</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tantdhvan/KSE2023">https://github.com/tantdhvan/KSE2023</a></li>
<li>paper_authors: Dung T. K. Ha, Canh V. Pham, Tan D. Tran, Huan X. Hoang</li>
<li>for: 解决非MONOTONE $k$-submodular maximization问题下的隐藏环境问题（Influence Maximization和Sensor Placement等）中的瓶颈问题。</li>
<li>methods: 提出了两种权衡策略，即$\LAA$和$\RLA$，可以在$O(nk)$查询复杂度下提供竞争性改进的解决方案。</li>
<li>results: 对一些实验INSTANCES（Influence Maximization和Sensor Placement等）进行了评估，结果表明，提出的算法可以保持理论上的质量，同时减少了查询数量。<details>
<summary>Abstract</summary>
The problem of non-monotone $k$-submodular maximization under a knapsack constraint ($\kSMK$) over the ground set size $n$ has been raised in many applications in machine learning, such as data summarization, information propagation, etc. However, existing algorithms for the problem are facing questioning of how to overcome the non-monotone case and how to fast return a good solution in case of the big size of data. This paper introduces two deterministic approximation algorithms for the problem that competitively improve the query complexity of existing algorithms.   Our first algorithm, $\LAA$, returns an approximation ratio of $1/19$ within $O(nk)$ query complexity. The second one, $\RLA$, improves the approximation ratio to $1/5-\epsilon$ in $O(nk)$ queries, where $\epsilon$ is an input parameter.   Our algorithms are the first ones that provide constant approximation ratios within only $O(nk)$ query complexity for the non-monotone objective. They, therefore, need fewer the number of queries than state-of-the-the-art ones by a factor of $\Omega(\log n)$.   Besides the theoretical analysis, we have evaluated our proposed ones with several experiments in some instances: Influence Maximization and Sensor Placement for the problem. The results confirm that our algorithms ensure theoretical quality as the cutting-edge techniques and significantly reduce the number of queries.
</details>
<details>
<summary>摘要</summary>
“$\kSMK$问题中的非升渐函数最大化问题已经在机器学习中出现了多种应用，如数据概要、信息传播等。然而，现有的算法对这个问题存在两个问题：如何处理非升渐情况，以及如何快速返回良好的解决方案。这篇论文提出了两种杜氏抽象算法来解决这个问题，其中一种是$\LAA$算法，可以在$O(nk)$查询复杂度下提供$1/19$的近似比率；另一种是$\RLA$算法，可以在$O(nk)$查询复杂度下提供$1/5-\epsilon$的近似比率，其中$\epsilon$是输入参数。这些算法是第一个在非升渐情况下提供常数近似比率的$O(nk)$查询复杂度内部的算法。因此，它们比现有的算法快速返回更好的解决方案，并且可以避免$\Omega(\log n)$的查询复杂度。”I hope this helps! Let me know if you have any further questions or if you'd like me to translate anything else.
</details></li>
</ul>
<hr>
<h2 id="Enhancing-SAEAs-with-Unevaluated-Solutions-A-Case-Study-of-Relation-Model-for-Expensive-Optimization"><a href="#Enhancing-SAEAs-with-Unevaluated-Solutions-A-Case-Study-of-Relation-Model-for-Expensive-Optimization" class="headerlink" title="Enhancing SAEAs with Unevaluated Solutions: A Case Study of Relation Model for Expensive Optimization"></a>Enhancing SAEAs with Unevaluated Solutions: A Case Study of Relation Model for Expensive Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11994">http://arxiv.org/abs/2309.11994</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Hao, Xiaoqun Zhang, Aimin Zhou</li>
<li>for: 解决高效优化问题（EOPs）</li>
<li>methods: 使用模拟器帮助进化算法选择优质解决方案，并使用两种专门设计的关系模型进行可靠的选择</li>
<li>results: 在两个测试集上，相比于回归和分类模型，关系模型在选择阶段表现出了明显的优势，而使用模拟器选择的未评估解决方案也显著提高了算法的效率。<details>
<summary>Abstract</summary>
Surrogate-assisted evolutionary algorithms (SAEAs) hold significant importance in resolving expensive optimization problems~(EOPs). Extensive efforts have been devoted to improving the efficacy of SAEAs through the development of proficient model-assisted selection methods. However, generating high-quality solutions is a prerequisite for selection. The fundamental paradigm of evaluating a limited number of solutions in each generation within SAEAs reduces the variance of adjacent populations, thus impacting the quality of offspring solutions. This is a frequently encountered issue, yet it has not gained widespread attention. This paper presents a framework using unevaluated solutions to enhance the efficiency of SAEAs. The surrogate model is employed to identify high-quality solutions for direct generation of new solutions without evaluation. To ensure dependable selection, we have introduced two tailored relation models for the selection of the optimal solution and the unevaluated population. A comprehensive experimental analysis is performed on two test suites, which showcases the superiority of the relation model over regression and classification models in the selection phase. Furthermore, the surrogate-selected unevaluated solutions with high potential have been shown to significantly enhance the efficiency of the algorithm.
</details>
<details>
<summary>摘要</summary>
SAEs（代理协助进化算法）在解决成本高的优化问题（EOPs）中具有重要 significanc。 总的来说，大量的努力已经投入到提高 SAEs 的效果，特别是通过开发高效的模型协助选择方法。然而，生成高质量的解决方案是选择解决方案的前提。 SAEs 中每代评估一部分解决方案的基本思路会减少邻近 популяции的变异，从而影响下一代解决方案的质量。这是一个常见的问题，然而它尚未受到广泛关注。本文提出了一种基于未评估解决方案的框架，使用代理模型来确定高质量的解决方案，以直接生成新的解决方案而不需要评估。为确保可靠的选择，我们已经引入了两种特定的关系模型，一种用于选择优质解决方案，另一种用于选择未评估的人口。我们对两个测试集进行了全面的实验分析，结果表明，关系模型在选择阶段的性能明显超过了回归和分类模型。此外，使用代理选择的未评估解决方案显示有很大的优化效果。
</details></li>
</ul>
<hr>
<h2 id="Variational-Connectionist-Temporal-Classification-for-Order-Preserving-Sequence-Modeling"><a href="#Variational-Connectionist-Temporal-Classification-for-Order-Preserving-Sequence-Modeling" class="headerlink" title="Variational Connectionist Temporal Classification for Order-Preserving Sequence Modeling"></a>Variational Connectionist Temporal Classification for Order-Preserving Sequence Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11983">http://arxiv.org/abs/2309.11983</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zheng Nan, Ting Dang, Vidhyasaharan Sethu, Beena Ahmed</li>
<li>for: 这个论文是为了提出一种基于CTC的变量模型，以提高语音识别 task 中序列模型的泛化能力。</li>
<li>methods: 论文使用了CTC和变量模型的组合，并 derivated two 个版本的变量CTC。这两个版本都假设了不同的假设，即每个时间步骤的变量 latent 变量是独立的，以及这些变量是Markovian。</li>
<li>results: 论文显示了这两个版本的变量CTC 都可以直接优化变量下界，并提供了计算可能的实现方式。<details>
<summary>Abstract</summary>
Connectionist temporal classification (CTC) is commonly adopted for sequence modeling tasks like speech recognition, where it is necessary to preserve order between the input and target sequences. However, CTC is only applied to deterministic sequence models, where the latent space is discontinuous and sparse, which in turn makes them less capable of handling data variability when compared to variational models. In this paper, we integrate CTC with a variational model and derive loss functions that can be used to train more generalizable sequence models that preserve order. Specifically, we derive two versions of the novel variational CTC based on two reasonable assumptions, the first being that the variational latent variables at each time step are conditionally independent; and the second being that these latent variables are Markovian. We show that both loss functions allow direct optimization of the variational lower bound for the model log-likelihood, and present computationally tractable forms for implementing them.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传输连接主义（CTC）通常用于序列模型任务，如语音识别，因为需要保持输入和目标序列之间的顺序。然而，CTC只适用于决定性序列模型，其潜在空间离散和稀疏，这使得它们在数据变化时更难处理。在这篇论文中，我们将CTC与可变模型结合，并 derive loss函ls可以用来训练更一般化的序列模型，保持顺序。我们 derivTwo versions of the novel variational CTC based on two reasonable assumptions：the first is that the variational latent variables at each time step are conditionally independent; and the second is that these latent variables are Markovian。我们显示这两个损失函数可以直接优化可变下界，并提供了实现方法。Note: "潜在空间" (pinyin: "màn zì kōng chǎng") is a term used in information theory and machine learning to refer to the space of all possible states of a system, and "离散" (pinyin: "liáo chǎng") means "discrete". "Markovian" (pinyin: "mǎ kè yuán") refers to a system that satisfies the Markov property, which states that the future state of the system depends only on its current state, and not on any of its past states.
</details></li>
</ul>
<hr>
<h2 id="Generating-Hierarchical-Structures-for-Improved-Time-Series-Classification-Using-Stochastic-Splitting-Functions"><a href="#Generating-Hierarchical-Structures-for-Improved-Time-Series-Classification-Using-Stochastic-Splitting-Functions" class="headerlink" title="Generating Hierarchical Structures for Improved Time Series Classification Using Stochastic Splitting Functions"></a>Generating Hierarchical Structures for Improved Time Series Classification Using Stochastic Splitting Functions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11963">http://arxiv.org/abs/2309.11963</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alagoz/hc4tsc_hdc_ssf">https://github.com/alagoz/hc4tsc_hdc_ssf</a></li>
<li>paper_authors: Celal Alagoz</li>
<li>for: 该研究旨在提高多类时序数据集中的分类性能通过层次分类（HC），并提出了一种基于Stochastic Splitting Functions（SSFs）的层次分类方法。</li>
<li>methods: 该方法使用了随机分割函数（SSFs）来系统地将类划分为两个子集，并根据分类器来确定层次结构。</li>
<li>results: 研究表明，使用了rocket和svm分类器，和不同的分割函数，该方法在约半数和一第数据集中显著提高了分类性能。此外，研究还探讨了不同的数据特征和层次结构如何影响HC性能。<details>
<summary>Abstract</summary>
This study introduces a novel hierarchical divisive clustering approach with stochastic splitting functions (SSFs) to enhance classification performance in multi-class datasets through hierarchical classification (HC). The method has the unique capability of generating hierarchy without requiring explicit information, making it suitable for datasets lacking prior knowledge of hierarchy. By systematically dividing classes into two subsets based on their discriminability according to the classifier, the proposed approach constructs a binary tree representation of hierarchical classes. The approach is evaluated on 46 multi-class time series datasets using popular classifiers (svm and rocket) and SSFs (potr, srtr, and lsoo). The results reveal that the approach significantly improves classification performance in approximately half and a third of the datasets when using rocket and svm as the classifier, respectively. The study also explores the relationship between dataset features and HC performance. While the number of classes and flat classification (FC) score show consistent significance, variations are observed with different splitting functions. Overall, the proposed approach presents a promising strategy for enhancing classification by generating hierarchical structure in multi-class time series datasets. Future research directions involve exploring different splitting functions, classifiers, and hierarchy structures, as well as applying the approach to diverse domains beyond time series data. The source code is made openly available to facilitate reproducibility and further exploration of the method.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="On-the-Probability-of-Immunity"><a href="#On-the-Probability-of-Immunity" class="headerlink" title="On the Probability of Immunity"></a>On the Probability of Immunity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11942">http://arxiv.org/abs/2309.11942</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ZahirSen/scaling-octo-guide">https://github.com/ZahirSen/scaling-octo-guide</a></li>
<li>paper_authors: Jose M. Peña</li>
<li>for: 本文研究了免疫概率的概率论，即是否曝露后发生效果。</li>
<li>methods: 作者 derive了免疫必要和 suficient conditions，以及 $\epsilon$-bounded免疫的条件，用于估计Randomized controlled trial中效果的概率。</li>
<li>results: 作者提出了 indirect免疫的概念，并重复了之前的分析。此外，他们还提出了对免疫概率的敏感分析方法。<details>
<summary>Abstract</summary>
This work is devoted to the study of the probability of immunity, i.e. the effect occurs whether exposed or not. We derive necessary and sufficient conditions for non-immunity and $\epsilon$-bounded immunity, i.e. the probability of immunity is zero and $\epsilon$-bounded, respectively. The former allows us to estimate the probability of benefit (i.e., the effect occurs if and only if exposed) from a randomized controlled trial, and the latter allows us to produce bounds of the probability of benefit that are tighter than the existing ones. We also introduce the concept of indirect immunity (i.e., through a mediator) and repeat our previous analysis for it. Finally, we propose a method for sensitivity analysis of the probability of immunity under unmeasured confounding.
</details>
<details>
<summary>摘要</summary>
这项研究专门研究了免疫的概率，即效果发生或不发生。我们 deriv了免疫的必要和 suficient 条件，即免疫概率为零和 $\epsilon$- bounded 免疫，分别表示效果发生只有在曝露的情况下，和效果发生的概率在 $\epsilon$ 范围内。前者允许我们从随机化控制试验中估算效果发生的概率，而后者允许我们生成更紧的效果发生的概率 bounds。我们还介绍了间接免疫（通过介质）的概念，并重复了我们之前的分析。最后，我们提出了对免疫概率下无量化干扰的敏感分析方法。
</details></li>
</ul>
<hr>
<h2 id="A-Machine-Learning-oriented-Survey-on-Tiny-Machine-Learning"><a href="#A-Machine-Learning-oriented-Survey-on-Tiny-Machine-Learning" class="headerlink" title="A Machine Learning-oriented Survey on Tiny Machine Learning"></a>A Machine Learning-oriented Survey on Tiny Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11932">http://arxiv.org/abs/2309.11932</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luigi Capogrosso, Federico Cunico, Dong Seon Cheng, Franco Fummi, Marco Cristani</li>
<li>for: 这篇论文主要是为了提供一个现代化的概述，探讨在tiny machine learning（TinyML）中使用的学习算法。</li>
<li>methods: 这篇论文使用了PRISMA方法流程进行系统性的文献综述。</li>
<li>results: 论文提出了三种实现tinyml系统的工作流程（ML-oriented、HW-oriented和协同设计），并对tinyml中的学习领域进行了详细探讨，包括不同家族的模型优化和设计，以及当前领先的学习技术。<details>
<summary>Abstract</summary>
The emergence of Tiny Machine Learning (TinyML) has positively revolutionized the field of Artificial Intelligence by promoting the joint design of resource-constrained IoT hardware devices and their learning-based software architectures. TinyML carries an essential role within the fourth and fifth industrial revolutions in helping societies, economies, and individuals employ effective AI-infused computing technologies (e.g., smart cities, automotive, and medical robotics). Given its multidisciplinary nature, the field of TinyML has been approached from many different angles: this comprehensive survey wishes to provide an up-to-date overview focused on all the learning algorithms within TinyML-based solutions. The survey is based on the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) methodological flow, allowing for a systematic and complete literature survey. In particular, firstly we will examine the three different workflows for implementing a TinyML-based system, i.e., ML-oriented, HW-oriented, and co-design. Secondly, we propose a taxonomy that covers the learning panorama under the TinyML lens, examining in detail the different families of model optimization and design, as well as the state-of-the-art learning techniques. Thirdly, this survey will present the distinct features of hardware devices and software tools that represent the current state-of-the-art for TinyML intelligent edge applications. Finally, we discuss the challenges and future directions.
</details>
<details>
<summary>摘要</summary>
<sys> tinyml 的出现已经对人工智能领域产生了积极的革命，推动了资源有限的 iot 硬件设备和其学习基础架构的共同设计。 tinyml 在第四和第五个工业革命中发挥着重要的作用，帮助社会、经济和个人使用有效的 ai 混合技术（如智能城市、汽车和医疗机器人）。由于 tinyml 的多学科性质，这个领域被不同的方法研究：这篇系统性评价报告尝试提供 tinyml 基础上的所有学习算法的全面概述。本文采用 prism 方法ológico流程，以系统和完整的方式进行文献评价。特别是，我们将首先描述 tinyml 基础上的三个不同工作流程，即 ml  oriented、hw  oriented 和 co-design。其次，我们提出了 tinyml 视野下的学习天空分类，详细探讨不同家族的模型优化和设计，以及当前领域的 state-of-the-art 学习技术。 finally，这篇评价报告将介绍当前 tinyml 智能边缘应用中的最新硬件设备和软件工具。最后，我们讨论了挑战和未来方向。</sys>Note: "tinyml" in the text is translated as "小Machine Learning" in Simplified Chinese, which is a common way to refer to the field of Tiny Machine Learning.
</details></li>
</ul>
<hr>
<h2 id="Shedding-Light-on-the-Ageing-of-Extra-Virgin-Olive-Oil-Probing-the-Impact-of-Temperature-with-Fluorescence-Spectroscopy-and-Machine-Learning-Techniques"><a href="#Shedding-Light-on-the-Ageing-of-Extra-Virgin-Olive-Oil-Probing-the-Impact-of-Temperature-with-Fluorescence-Spectroscopy-and-Machine-Learning-Techniques" class="headerlink" title="Shedding Light on the Ageing of Extra Virgin Olive Oil: Probing the Impact of Temperature with Fluorescence Spectroscopy and Machine Learning Techniques"></a>Shedding Light on the Ageing of Extra Virgin Olive Oil: Probing the Impact of Temperature with Fluorescence Spectroscopy and Machine Learning Techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12377">http://arxiv.org/abs/2309.12377</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francesca Venturini, Silvan Fluri, Manas Mejari, Michael Baumgartner, Dario Piga, Umberto Michelucci</li>
<li>for: 这项研究旨在系统地研究EXTRA VIRGIN OLIVE OIL (EVOO) 的氧化过程，以便提出一种可以在存储过程中实时监测EVOO质量的方法。</li>
<li>methods: 该研究使用UV吸收和总辐射光谱来测量EVOO的氧化程度，并通过机器学习应用于高度归一化的数据来提出一种可以在场地条件下进行评估的方法。</li>
<li>results: 研究显示，辐射光谱可以准确地监测EVOO的氧化程度，并且可以通过Machine Learning来处理高度归一化的数据，从而提供一种可以在场地条件下进行评估的方法。<details>
<summary>Abstract</summary>
This work systematically investigates the oxidation of extra virgin olive oil (EVOO) under accelerated storage conditions with UV absorption and total fluorescence spectroscopy. With the large amount of data collected, it proposes a method to monitor the oil's quality based on machine learning applied to highly-aggregated data. EVOO is a high-quality vegetable oil that has earned worldwide reputation for its numerous health benefits and excellent taste. Despite its outstanding quality, EVOO degrades over time owing to oxidation, which can affect both its health qualities and flavour. Therefore, it is highly relevant to quantify the effects of oxidation on EVOO and develop methods to assess it that can be easily implemented under field conditions, rather than in specialized laboratories. The following study demonstrates that fluorescence spectroscopy has the capability to monitor the effect of oxidation and assess the quality of EVOO, even when the data are highly aggregated. It shows that complex laboratory equipment is not necessary to exploit fluorescence spectroscopy using the proposed method and that cost-effective solutions, which can be used in-field by non-scientists, could provide an easily-accessible assessment of the quality of EVOO.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Phase-Synchrony-Component-Self-Organization-in-Brain-Computer-Interface"><a href="#Phase-Synchrony-Component-Self-Organization-in-Brain-Computer-Interface" class="headerlink" title="Phase Synchrony Component Self-Organization in Brain Computer Interface"></a>Phase Synchrony Component Self-Organization in Brain Computer Interface</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.03748">http://arxiv.org/abs/2310.03748</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xu Niu, Na Lu, Huan Luo, Ruofan Yan</li>
<li>for:  This paper aims to develop a deep learning end-to-end network for motor imagery (MI) classification based on phase synchrony information, which can automatically extract optimal filters for preprocessing and channel selection, and achieve better performance than traditional methods.</li>
<li>methods: The proposed method uses a deep learning network to directly extract phase synchrony-based features from raw EEG signals and perform classification. The network learns optimal filters during training, which are obtained when the network achieves peak classification results.</li>
<li>results: The proposed method outperforms state-of-the-art methods and discovers significant phase synchronization phenomena in tongue MI, with an average PLV exceeding 0.87 across all tongue MI samples. This high PLV indicates a groundbreaking discovery in the synchrony pattern of tongue MI.<details>
<summary>Abstract</summary>
Phase synchrony information plays a crucial role in analyzing functional brain connectivity and identifying brain activities. A widely adopted feature extraction pipeline, composed of preprocessing, selection of EEG acquisition channels, and phase locking value (PLV) calculation, has achieved success in motor imagery classification (MI). However, this pipeline is manual and reliant on expert knowledge, limiting its convenience and adaptability to different application scenarios. Moreover, most studies have employed mediocre data-independent spatial filters to suppress noise, impeding the exploration of more significant phase synchronization phenomena. To address the issues, we propose the concept of phase synchrony component self-organization, which enables the adaptive learning of data-dependent spatial filters for automating both the preprocessing and channel selection procedures. Based on this concept, the first deep learning end-to-end network is developed, which directly extracts phase synchrony-based features from raw EEG signals and perform classification. The network learns optimal filters during training, which are obtained when the network achieves peak classification results. Extensive experiments have demonstrated that our network outperforms state-of-the-art methods. Remarkably, through the learned optimal filters, significant phase synchronization phenomena can be observed. Specifically, by calculating the PLV between a pair of signals extracted from each sample using two of the learned spatial filters, we have obtained an average PLV exceeding 0.87 across all tongue MI samples. This high PLV indicates a groundbreaking discovery in the synchrony pattern of tongue MI.
</details>
<details>
<summary>摘要</summary>
<<SYS>> simultanous phase information plays a crucial role in analyzing functional brain connectivity and identifying brain activities. A widely adopted feature extraction pipeline, composed of preprocessing, selection of EEG acquisition channels, and phase locking value (PLV) calculation, has achieved success in motor imagery classification (MI). However, this pipeline is manual and reliant on expert knowledge, limiting its convenience and adaptability to different application scenarios. Moreover, most studies have employed mediocre data-independent spatial filters to suppress noise, impeding the exploration of more significant phase synchronization phenomena. To address the issues, we propose the concept of phase synchrony component self-organization, which enables the adaptive learning of data-dependent spatial filters for automating both the preprocessing and channel selection procedures. Based on this concept, the first deep learning end-to-end network is developed, which directly extracts phase synchrony-based features from raw EEG signals and perform classification. The network learns optimal filters during training, which are obtained when the network achieves peak classification results. Extensive experiments have demonstrated that our network outperforms state-of-the-art methods. Remarkably, through the learned optimal filters, significant phase synchronization phenomena can be observed. Specifically, by calculating the PLV between a pair of signals extracted from each sample using two of the learned spatial filters, we have obtained an average PLV exceeding 0.87 across all tongue MI samples. This high PLV indicates a groundbreaking discovery in the synchrony pattern of tongue MI.中文简体版：同步相关信息在分析 fonctional brain connectivity 和脑活动中扮演了关键角色。一种广泛采用的特征提取管道，包括预处理、EEG采集通道选择和相位锁定值（PLV）计算，在motor imagery classification（MI）中取得了成功。然而，这个管道是手动操作的，受专家知识的限制，因此对不同应用场景的可 conveniency和适应性具有局限性。此外，大多数研究都使用了平均数据独立的空间滤波器来抑制噪声，这阻碍了更进一步的相同报时现象的探索。为解决这些问题，我们提出了相位同步组成自组织的概念，允许自动学习数据dependent的空间滤波器，以自动进行预处理和采集通道选择。基于这个概念，我们开发了首个深度学习端到端网络，直接从原始 EEG 信号中提取相位同步基于特征，并进行分类。该网络在训练时 learns 优化的滤波器，当网络达到最高分类结果时，获得最佳的滤波器。广泛的实验证明，我们的网络超过了当前的状态艺方法。另外，通过我们学习的优化滤波器，可以观察到更加明显的相同报时现象。例如，通过计算每个样本中对应的两个学习的空间滤波器之间的相位锁定值（PLV），我们在所有舌MI样本中获得了平均PLV超过0.87。这高PLV表明了一个很有前途的发现在舌MI中的同步模式。
</details></li>
</ul>
<hr>
<h2 id="From-Peptides-to-Nanostructures-A-Euclidean-Transformer-for-Fast-and-Stable-Machine-Learned-Force-Fields"><a href="#From-Peptides-to-Nanostructures-A-Euclidean-Transformer-for-Fast-and-Stable-Machine-Learned-Force-Fields" class="headerlink" title="From Peptides to Nanostructures: A Euclidean Transformer for Fast and Stable Machine Learned Force Fields"></a>From Peptides to Nanostructures: A Euclidean Transformer for Fast and Stable Machine Learned Force Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.15126">http://arxiv.org/abs/2309.15126</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thorben-frank/mlff">https://github.com/thorben-frank/mlff</a></li>
<li>paper_authors: J. Thorben Frank, Oliver T. Unke, Klaus-Robert Müller, Stefan Chmiela</li>
<li>For: The paper aims to improve the stability and efficiency of machine learned force fields (MLFFs) in molecular dynamics (MD) simulations, particularly for systems with large numbers of degrees of freedom.* Methods: The authors propose a transformer architecture called SO3krates, which combines sparse equivariant representations (Euclidean variables) with a self-attention mechanism to separate invariant and equivariant information. This allows for more efficient and stable MD simulations.* Results: The authors demonstrate the ability of SO3krates to generate stable MD trajectories for flexible peptides and supra-molecular structures with hundreds of atoms, and explore the PES topology for medium-sized chainlike molecules (e.g., small peptides) by exploring thousands of minima. The results show that SO3krates can balance the conflicting demands of stability and the emergence of new minimum-energy conformations beyond the training data, which is crucial for realistic exploration tasks in the field of biochemistry.Here is the same information in Simplified Chinese text:* 为：文章目的是提高机器学习力学场（MLFFs）在分子动力学（MD）模拟中的稳定性和效率，特别是在多个自由度系统上。* 方法：作者提出了一种名为SO3krates的变换架构，它将稀缺几何变换（Euclidean variables）与自我注意机制结合起来，以分离不变和变换的信息。这使得MD模拟更加稳定和高效。* 结果：作者demonstrate了SO3krates可以生成稳定的MD轨迹 для柔软蛋白质和含百个原子的超分子结构，并explore了中等长的链状分子（如小蛋白质）的PES顶点结构，探索了千个最低能量态。结果表明，SO3krates可以均衡稳定性和训练数据之外的新最低能量配置的出现，这是生物化学领域中的实际探索任务中的关键。<details>
<summary>Abstract</summary>
Recent years have seen vast progress in the development of machine learned force fields (MLFFs) based on ab-initio reference calculations. Despite achieving low test errors, the suitability of MLFFs in molecular dynamics (MD) simulations is being increasingly scrutinized due to concerns about instability. Our findings suggest a potential connection between MD simulation stability and the presence of equivariant representations in MLFFs, but their computational cost can limit practical advantages they would otherwise bring.   To address this, we propose a transformer architecture called SO3krates that combines sparse equivariant representations (Euclidean variables) with a self-attention mechanism that can separate invariant and equivariant information, eliminating the need for expensive tensor products. SO3krates achieves a unique combination of accuracy, stability, and speed that enables insightful analysis of quantum properties of matter on unprecedented time and system size scales. To showcase this capability, we generate stable MD trajectories for flexible peptides and supra-molecular structures with hundreds of atoms. Furthermore, we investigate the PES topology for medium-sized chainlike molecules (e.g., small peptides) by exploring thousands of minima. Remarkably, SO3krates demonstrates the ability to strike a balance between the conflicting demands of stability and the emergence of new minimum-energy conformations beyond the training data, which is crucial for realistic exploration tasks in the field of biochemistry.
</details>
<details>
<summary>摘要</summary>
近年来，Machine learned force fields（MLFFs）基于初始参考计算的发展呈现了很大的进步。尽管它们在测试中的错误很低，但MLFFs在分子动力学（MD） simulations中的适用性受到了越来越多的质疑，因为有关其稳定性的担忧。我们的发现表明MLFFs中的equivariant表示可能与MD simulations的稳定性有关，但计算成本限制了它们在实际应用中的实用性。为解决这个问题，我们提出了一种名为SO3krates的变换架构，它结合了稀缺的equivariant表示（欧几何变量）和一种自注意机制，可以分离 invariantinformation和 equivariant information，从而消除高成本的tensor乘积。SO3krates实现了一种独特的精度、稳定性和速度的平衡，使得可以在前所未有的时间和系统大小 scales上进行有用的分子性质的分析。为证明这一点，我们生成了稳定的MD trajectory дляflexible peptides和supra-molecular structures with hundreds of atoms。此外，我们还 investigate了medium-sized chainlike molecules（例如小蛋白质）的PES topology，通过探索 thousands of minimum。特别是，SO3krates表现出可以平衡稳定性和训练数据之外的新的最低能 conformations的能力，这是生物化学领域中的实际探索任务中的关键。
</details></li>
</ul>
<hr>
<h2 id="Limited-Communications-Distributed-Optimization-via-Deep-Unfolded-Distributed-ADMM"><a href="#Limited-Communications-Distributed-Optimization-via-Deep-Unfolded-Distributed-ADMM" class="headerlink" title="Limited Communications Distributed Optimization via Deep Unfolded Distributed ADMM"></a>Limited Communications Distributed Optimization via Deep Unfolded Distributed ADMM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.14353">http://arxiv.org/abs/2309.14353</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yoav Noah, Nir Shlezinger</li>
<li>for: 这个论文主要针对的是分布式优化问题，即多个智能Device在分布式环境中进行协同推理和决策。</li>
<li>methods: 这篇论文提出了一种新的分布式优化算法，即折叠分布式D-ADMM，它通过Iteratively combining local computations和message exchanges来实现分布式优化。</li>
<li>results: 该论文的数据结果表明，折叠分布式D-ADMM可以减少D-ADMM中的消息交换量，同时保持了D-ADMM的性能。此外，该论文还特化了折叠分布式D-ADMM的应用于分布式估算和分布式学习等场景。<details>
<summary>Abstract</summary>
Distributed optimization is a fundamental framework for collaborative inference and decision making in decentralized multi-agent systems. The operation is modeled as the joint minimization of a shared objective which typically depends on observations gathered locally by each agent. Distributed optimization algorithms, such as the common D-ADMM, tackle this task by iteratively combining local computations and message exchanges. One of the main challenges associated with distributed optimization, and particularly with D-ADMM, is that it requires a large number of communications, i.e., messages exchanged between the agents, to reach consensus. This can make D-ADMM costly in power, latency, and channel resources. In this work we propose unfolded D-ADMM, which follows the emerging deep unfolding methodology to enable D-ADMM to operate reliably with a predefined and small number of messages exchanged by each agent. Unfolded D-ADMM fully preserves the operation of D-ADMM, while leveraging data to tune the hyperparameters of each iteration of the algorithm. These hyperparameters can either be agent-specific, aiming at achieving the best performance within a fixed number of iterations over a given network, or shared among the agents, allowing to learn to distributedly optimize over different networks. For both settings, our unfolded D-ADMM operates with limited communications, while preserving the interpretability and flexibility of the original D-ADMM algorithm. We specialize unfolded D-ADMM for two representative settings: a distributed estimation task, considering a sparse recovery setup, and a distributed learning scenario, where multiple agents collaborate in learning a machine learning model. Our numerical results demonstrate that the proposed approach dramatically reduces the number of communications utilized by D-ADMM, without compromising on its performance.
</details>
<details>
<summary>摘要</summary>
分布式优化是多机合作推理和决策的基础框架，用于分布式多代理系统中的共同目标最小化。该操作通常基于每个代理收集本地观测数据所得到的共同目标函数。分布式优化算法，如共同D-ADMM，通过融合本地计算和信息交换来实现这个任务。但是，分布式优化具有许多通信 overhead，特别是D-ADMM，可能会占用大量的功能、延迟和通信资源。在这种情况下，我们提出了 unfolded D-ADMM，它采用深度嵌入方法来允许D-ADMM在固定并小于数量的消息交换中进行可靠地操作。 unfolded D-ADMM保留了D-ADMM的操作，并通过数据来调整每个迭代的超参数。这些超参数可以是特定于代理的，寻求在给定网络上达到最佳性能 Within 一定数量的迭代，或者是共享的，以学习分布式优化不同网络。在这两种设置下，我们的 unfolded D-ADMM 具有限制通信的特点，同时保持了原始 D-ADMM 的解释性和灵活性。我们在分布式估计任务和分布式学习场景中特化 unfolded D-ADMM，我们的数值结果表明，我们的方法可以很大幅降低 D-ADMM 使用的通信量，不会影响其性能。
</details></li>
</ul>
<hr>
<h2 id="Activation-Compression-of-Graph-Neural-Networks-using-Block-wise-Quantization-with-Improved-Variance-Minimization"><a href="#Activation-Compression-of-Graph-Neural-Networks-using-Block-wise-Quantization-with-Improved-Variance-Minimization" class="headerlink" title="Activation Compression of Graph Neural Networks using Block-wise Quantization with Improved Variance Minimization"></a>Activation Compression of Graph Neural Networks using Block-wise Quantization with Improved Variance Minimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11856">http://arxiv.org/abs/2309.11856</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/saintslab/i-exact">https://github.com/saintslab/i-exact</a></li>
<li>paper_authors: Sebastian Eliassen, Raghavendra Selvan</li>
<li>for: 大规模图 neural network 的高效训练</li>
<li>methods: 使用EXTREME activation compression 减少内存消耗，并使用块级量化中间Activation map</li>
<li>results: 可以获得更大的减少内存消耗（&gt;15%）和每 epoch 的运行速度增快（约5%），同时保持相似的性能交易Here’s the full translation of the abstract in Simplified Chinese:</li>
<li>for: 本文研究了大规模图 neural network 的高效训练，尤其是减少其内存消耗。</li>
<li>methods: 提出了EXTREME activation compression 技术，通过对中间Activation map 进行量化，以INT2 精度进行表示。这种方法可以减少 GPU 内存消耗，而且对性能没有明显的影响。本文提出了一种改进 EXACT 策略，通过使用块级量化中间Activation map。我们通过不同的块大小进行分析，并证明可以获得更大的减少内存消耗（&gt;15%）和每 epoch 的运行速度增快（约5%）。此外，我们还提出了对 EXACT 中间Activation map 的分布假设（假设为均匀分布）的修正，并证明可以提高量化和解量化步骤的变量估计。</li>
<li>results: 本文的实验结果表明，使用块级量化中间Activation map 可以减少 GPU 内存消耗和运行时间，同时保持相似的性能交易。<details>
<summary>Abstract</summary>
Efficient training of large-scale graph neural networks (GNNs) has been studied with a specific focus on reducing their memory consumption. Work by Liu et al. (2022) proposed extreme activation compression (EXACT) which demonstrated drastic reduction in memory consumption by performing quantization of the intermediate activation maps down to using INT2 precision. They showed little to no reduction in performance while achieving large reductions in GPU memory consumption. In this work, we present an improvement to the EXACT strategy by using block-wise quantization of the intermediate activation maps. We experimentally analyze different block sizes and show further reduction in memory consumption (>15%), and runtime speedup per epoch (about 5%) even when performing extreme extents of quantization with similar performance trade-offs as with the original EXACT. Further, we present a correction to the assumptions on the distribution of intermediate activation maps in EXACT (assumed to be uniform) and show improved variance estimations of the quantization and dequantization steps.
</details>
<details>
<summary>摘要</summary>
大规模图 neuron 网络（GNNs）的高效训练已经得到了研究的重点，以减少它们的内存占用。工作 by Liu et al. (2022) 提出了极化活动压缩（EXACT）策略，通过对中间活动地图进行量化，以INT2精度进行压缩，并达到了大幅减少GPU内存占用的目标。在这项工作中，我们提出了对EXACT策略的改进，通过对中间活动地图进行块式量化。我们通过不同的块大小进行实验分析，并证明了可以得到更大的内存占用减少（>15%）和每 epoch 的运行速度增加（约5%），即使在执行极端的量化时，与原始EXACT的性能交换空间保持相同。此外，我们还提出了对EXACT中对中间活动地图分布的假设（假设为均匀分布）的修正，并显示了压缩和解压缩步骤的变量估计得到了改善。
</details></li>
</ul>
<hr>
<h2 id="TMac-Temporal-Multi-Modal-Graph-Learning-for-Acoustic-Event-Classification"><a href="#TMac-Temporal-Multi-Modal-Graph-Learning-for-Acoustic-Event-Classification" class="headerlink" title="TMac: Temporal Multi-Modal Graph Learning for Acoustic Event Classification"></a>TMac: Temporal Multi-Modal Graph Learning for Acoustic Event Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11845">http://arxiv.org/abs/2309.11845</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mgithubl/tmac">https://github.com/mgithubl/tmac</a></li>
<li>paper_authors: Meng Liu, Ke Liang, Dayu Hu, Hao Yu, Yue Liu, Lingyuan Meng, Wenxuan Tu, Sihang Zhou, Xinwang Liu<br>for:This paper proposes a Temporal Multi-modal graph learning method for Acoustic event Classification, called TMac, to handle the temporal information in multi-modal data.methods:The proposed method constructs a temporal graph for each acoustic event, dividing its audio data and video data into multiple segments, and models the temporal relationships between nodes using graph learning techniques.results:Experiments demonstrate that TMac outperforms other state-of-the-art models in performance, smoothing capturing the dynamic information in intra-modal and inter-modal.<details>
<summary>Abstract</summary>
Audiovisual data is everywhere in this digital age, which raises higher requirements for the deep learning models developed on them. To well handle the information of the multi-modal data is the key to a better audiovisual modal. We observe that these audiovisual data naturally have temporal attributes, such as the time information for each frame in the video. More concretely, such data is inherently multi-modal according to both audio and visual cues, which proceed in a strict chronological order. It indicates that temporal information is important in multi-modal acoustic event modeling for both intra- and inter-modal. However, existing methods deal with each modal feature independently and simply fuse them together, which neglects the mining of temporal relation and thus leads to sub-optimal performance. With this motivation, we propose a Temporal Multi-modal graph learning method for Acoustic event Classification, called TMac, by modeling such temporal information via graph learning techniques. In particular, we construct a temporal graph for each acoustic event, dividing its audio data and video data into multiple segments. Each segment can be considered as a node, and the temporal relationships between nodes can be considered as timestamps on their edges. In this case, we can smoothly capture the dynamic information in intra-modal and inter-modal. Several experiments are conducted to demonstrate TMac outperforms other SOTA models in performance. Our code is available at https://github.com/MGitHubL/TMac.
</details>
<details>
<summary>摘要</summary>
在数字时代，audiovisual数据 everywhere，这heightened the requirements for deep learning models developed on them. To well handle the information of the multi-modal data is the key to a better audiovisual modal. We observe that these audiovisual data naturally have temporal attributes, such as the time information for each frame in the video. More concretely, such data is inherently multi-modal according to both audio and visual cues, which proceed in a strict chronological order. It indicates that temporal information is important in multi-modal acoustic event modeling for both intra- and inter-modal. However, existing methods deal with each modal feature independently and simply fuse them together, which neglects the mining of temporal relation and thus leads to sub-optimal performance. With this motivation, we propose a Temporal Multi-modal graph learning method for Acoustic event Classification, called TMac, by modeling such temporal information via graph learning techniques. In particular, we construct a temporal graph for each acoustic event, dividing its audio data and video data into multiple segments. Each segment can be considered as a node, and the temporal relationships between nodes can be considered as timestamps on their edges. In this case, we can smoothly capture the dynamic information in intra-modal and inter-modal. Several experiments are conducted to demonstrate TMac outperforms other SOTA models in performance. Our code is available at https://github.com/MGitHubL/TMac.
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Review-of-Community-Detection-in-Graphs"><a href="#A-Comprehensive-Review-of-Community-Detection-in-Graphs" class="headerlink" title="A Comprehensive Review of Community Detection in Graphs"></a>A Comprehensive Review of Community Detection in Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11798">http://arxiv.org/abs/2309.11798</a></li>
<li>repo_url: None</li>
<li>paper_authors: Songning Lai, Jiakang Li, Yonggang Lu</li>
<li>for: 本文旨在探讨复杂网络中社区结构的检测问题，以解释复杂系统的组织和功能。</li>
<li>methods: 本文介绍了多种社区检测方法，包括作者提出的新方法。</li>
<li>results: 本文 explore了多种实际应用场景，并提供了对社区检测问题的深入理解。<details>
<summary>Abstract</summary>
The study of complex networks has significantly advanced our understanding of community structures which serves as a crucial feature of real-world graphs. Detecting communities in graphs is a challenging problem with applications in sociology, biology, and computer science. Despite the efforts of an interdisciplinary community of scientists, a satisfactory solution to this problem has not yet been achieved. This review article delves into the topic of community detection in graphs, which serves as a crucial role in understanding the organization and functioning of complex systems. We begin by introducing the concept of community structure, which refers to the arrangement of vertices into clusters, with strong internal connections and weaker connections between clusters. Then, we provide a thorough exposition of various community detection methods, including a new method designed by us. Additionally, we explore real-world applications of community detection in diverse networks. In conclusion, this comprehensive review provides a deep understanding of community detection in graphs. It serves as a valuable resource for researchers and practitioners in multiple disciplines, offering insights into the challenges, methodologies, and applications of community detection in complex networks.
</details>
<details>
<summary>摘要</summary>
研究复杂网络已有很大进步，我们对社区结构的理解得到了深刻的提高。检测社区在图中的问题是一个复杂的问题，在社会学、生物学和计算机科学等领域都有着广泛的应用。尽管科学家们努力协作，但是满意的解决方案仍然没有得到。这篇文章探讨社区检测在图中的问题，这是理解复杂系统的关键组成部分。我们首先介绍社区结构的概念，即顶点的分布在团队中，具有内部强连接和 между团队的弱连接。然后，我们提供了详细的社区检测方法，包括我们自己的新方法。此外，我们还探讨了不同网络中社区检测的实际应用。结束时，这篇综述提供了对社区检测在图中的深入理解，作为多种领域的研究人员和实践者的 valuabe资源，它提供了对复杂网络的挑战、方法和应用的深入了解。
</details></li>
</ul>
<hr>
<h2 id="Privacy-Preserving-In-Context-Learning-with-Differentially-Private-Few-Shot-Generation"><a href="#Privacy-Preserving-In-Context-Learning-with-Differentially-Private-Few-Shot-Generation" class="headerlink" title="Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation"></a>Privacy-Preserving In-Context Learning with Differentially Private Few-Shot Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11765">http://arxiv.org/abs/2309.11765</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/dp-few-shot-generation">https://github.com/microsoft/dp-few-shot-generation</a></li>
<li>paper_authors: Xinyu Tang, Richard Shin, Huseyin A. Inan, Andre Manoel, Fatemehsadat Mireshghallah, Zinan Lin, Sivakanth Gopi, Janardhan Kulkarni, Robert Sim</li>
<li>for: 实现隐私内容学习（ICL） WITH大语言模型（LLM） ON私人数据。</li>
<li>methods: 提出了一个新的算法，将私人数据中的少量示例生成为Synthetic几何示例，并具有正式数据隐私（DP）保证。</li>
<li>results: 经过广泛的实验证明，我们的算法可以实现有效的ICL，并且可以保证高度的隐私水平。这些结果开启了新的可能性，允许ICL在隐私保证下进行应用。<details>
<summary>Abstract</summary>
We study the problem of in-context learning (ICL) with large language models (LLMs) on private datasets. This scenario poses privacy risks, as LLMs may leak or regurgitate the private examples demonstrated in the prompt. We propose a novel algorithm that generates synthetic few-shot demonstrations from the private dataset with formal differential privacy (DP) guarantees, and show empirically that it can achieve effective ICL. We conduct extensive experiments on standard benchmarks and compare our algorithm with non-private ICL and zero-shot solutions. Our results demonstrate that our algorithm can achieve competitive performance with strong privacy levels. These results open up new possibilities for ICL with privacy protection for a broad range of applications.
</details>
<details>
<summary>摘要</summary>
我们研究了大语言模型（LLM）在私有数据上进行境界学习（ICL）问题，这种情况可能会导致语言模型泄露或重复示例。我们提出了一种新的算法，可以从私有数据集中生成几个步骤示例，并具有正式权限保证（DP）。我们通过实验证明，该算法可以实现有效的ICL，并且与非私有ICL和零例解决方案进行比较。我们的结果表明，我们的算法可以实现竞争性的性能，同时保证隐私水平。这些结果开启了新的可能性，允许在隐私保护下进行ICL应用广泛。
</details></li>
</ul>
<hr>
<h2 id="Extracting-Physical-Causality-from-Measurements-to-Detect-and-Localize-False-Data-Injection-Attacks"><a href="#Extracting-Physical-Causality-from-Measurements-to-Detect-and-Localize-False-Data-Injection-Attacks" class="headerlink" title="Extracting Physical Causality from Measurements to Detect and Localize False Data Injection Attacks"></a>Extracting Physical Causality from Measurements to Detect and Localize False Data Injection Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.10666">http://arxiv.org/abs/2310.10666</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shengyang Wu, Jingyu Wang, Dongyuan Shi<br>for: 这个研究旨在探讨 False Data Injection Attack (FDIA) 在现代 циber-物理力系统中的问题，并提出一个基于 causal inference 和 Graph Attention Network (GAT) 的共同检测和地点化框架，以检测侵入系统中的攻击。methods: 本研究使用 X-learner 算法估算测量之间的 causality strength，生成 Measurement Causality Graphs (MCGs)，然后使用 GAT 检测 MCGs 中的异常模式，从而检测侵入系统中的攻击。results: 实验结果显示，基于 causal inference 和 GAT 的检测和地点化框架具有高度可读性和稳定性，并且能够快速和精确地检测侵入系统中的攻击。<details>
<summary>Abstract</summary>
False Data Injection Attack (FDIA) has become a growing concern in modern cyber-physical power systems. Most existing FDIA detection techniques project the raw measurement data into a high-dimensional latent space to separate normal and attacked samples. These approaches focus more on the statistical correlations of data values and are therefore susceptible to data distribution drifts induced by changes in system operating points or changes in FDIA types and strengths, especially for FDIA localization tasks. Causal inference, on the other hand, extracts the causality behind the coordinated fluctuations of different measurements. The causality patterns are determined by fundamental physical laws such as Ohm's Law and Kirchhoff's Law. They are sensitive to the violation of physical laws caused by FDIA, but tend to remain stable with the drift of system operating points. Leveraging this advantage, this paper proposes a joint FDIA detection and localization framework based on causal inference and the Graph Attention Network (GAT) to identify the attacked system nodes. The proposed framework consists of two levels. The lower level uses the X-learner algorithm to estimate the causality strength between measurements and generate Measurement Causality Graphs (MCGs). The upper level then applies a GAT to identify the anomaly patterns in the MCGs. Since the extracted causality patterns are intrinsically related to the measurements, it is easier for the upper level to figure out the attacked nodes than the existing FDIA localization approaches. The performance of the proposed framework is evaluated on the IEEE 39-bus system. Experimental results show that the causality-based FDIA detection and localization mechanism is highly interpretable and robust.
</details>
<details>
<summary>摘要</summary>
现代半导体系统中的假数据插入攻击（FDIA）已成为一种快速增长的问题。大多数现有的FDIA检测技术将原始测量数据投影到高维的干扰空间中，以分离正常和攻击的样本。这些方法更关注数据值的统计相关性，因此容易受到系统操作点的变化或攻击类型和强度的变化的影响，特别是对FDIA的本地化任务。然而， causal inference 可以提取测量数据中的 causality 模式，这些模式是基于物理法则，如奥姆的法则和基本电路的法则。它们对 FDIA 的攻击而言是不稳定的，但是对系统操作点的变化具有稳定性。基于这个优势，本文提出了一种基于 causal inference 和图注意力网络（GAT）的 Joint FDIA 检测和本地化框架，用于标识攻击的系统节点。该框架包括两层。下层使用 X-learner 算法来估算测量之间的 causality 强度，并生成 Measurement Causality Graphs（MCGs）。上层然后使用 GAT 来识别 MCGs 中的异常模式。由于提取的 causality 模式与测量数据直接相关，因此上层更容易于确定攻击的节点，而不是现有的 FDIA 本地化方法。本文的性能被评估在 IEEE 39-bus 系统上。实验结果表明，基于 causal inference 的 FDIA 检测和本地化机制具有高度可读性和稳定性。
</details></li>
</ul>
<hr>
<h2 id="Unveiling-Optimal-SDG-Pathways-An-Innovative-Approach-Leveraging-Graph-Pruning-and-Intent-Graph-for-Effective-Recommendations"><a href="#Unveiling-Optimal-SDG-Pathways-An-Innovative-Approach-Leveraging-Graph-Pruning-and-Intent-Graph-for-Effective-Recommendations" class="headerlink" title="Unveiling Optimal SDG Pathways: An Innovative Approach Leveraging Graph Pruning and Intent Graph for Effective Recommendations"></a>Unveiling Optimal SDG Pathways: An Innovative Approach Leveraging Graph Pruning and Intent Graph for Effective Recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11741">http://arxiv.org/abs/2309.11741</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhihang Yu, Shu Wang, Yunqiang Zhu, Wen Yuan, Xiaoliang Dai, Zhiqiang Zou</li>
<li>for: 这篇论文的目的是提出一种基于用户图和意图图的推荐方法，以便为实现可持续发展目标（SDGs）而建议可持续发展模式。</li>
<li>methods: 这篇论文使用了User Graph after Pruning和Intent Graph（UGPIG）方法，具体来说是利用删减后的用户图高密度连接能力来解决推荐算法对空间不均衡的问题，并且建立了意图图以捕捉目标区域的偏好。</li>
<li>results: 根据实验结果，UGPIG方法比现有的推荐算法如KGCN、KGAT和KGIN等表现更好，具体来说是在Top-3推荐性能中实现了最大提升9.61%。<details>
<summary>Abstract</summary>
The recommendation of appropriate development pathways, also known as ecological civilization patterns for achieving Sustainable Development Goals (namely, sustainable development patterns), are of utmost importance for promoting ecological, economic, social, and resource sustainability in a specific region. To achieve this, the recommendation process must carefully consider the region's natural, environmental, resource, and economic characteristics. However, current recommendation algorithms in the field of computer science fall short in adequately addressing the spatial heterogeneity related to environment and sparsity of regional historical interaction data, which limits their effectiveness in recommending sustainable development patterns. To overcome these challenges, this paper proposes a method called User Graph after Pruning and Intent Graph (UGPIG). Firstly, we utilize the high-density linking capability of the pruned User Graph to address the issue of spatial heterogeneity neglect in recommendation algorithms. Secondly, we construct an Intent Graph by incorporating the intent network, which captures the preferences for attributes including environmental elements of target regions. This approach effectively alleviates the problem of sparse historical interaction data in the region. Through extensive experiments, we demonstrate that UGPIG outperforms state-of-the-art recommendation algorithms like KGCN, KGAT, and KGIN in sustainable development pattern recommendations, with a maximum improvement of 9.61% in Top-3 recommendation performance.
</details>
<details>
<summary>摘要</summary>
“推荐合适发展路径”（简称“生态文明模式”）是实现可持续发展目标（即可持续发展模式）的重要因素。为此，推荐过程必须考虑特定区域的自然、环境、资源和经济特点。然而，现有的计算机科学领域的推荐算法对于区域当地环境和历史互动数据的稀畴性均有所缺乏，从而限制了它们在可持续发展模式推荐方面的效果。为解决这些挑战，本文提出了一种方法 called User Graph after Pruning and Intent Graph (UGPIG)。首先，我们利用高密度连结能力的删除后User Graph来解决推荐算法对于区域当地环境的忽略问题。其次，我们建立了意向图，将目标区域的意向网络融合到推荐过程中，以解决缺乏历史互动数据的问题。透过广泛的实验，我们证明UGPIG可以较前者优化可持续发展模式的推荐性能，最大改进率为9.61%。
</details></li>
</ul>
<hr>
<h2 id="Turaco-Complexity-Guided-Data-Sampling-for-Training-Neural-Surrogates-of-Programs"><a href="#Turaco-Complexity-Guided-Data-Sampling-for-Training-Neural-Surrogates-of-Programs" class="headerlink" title="Turaco: Complexity-Guided Data Sampling for Training Neural Surrogates of Programs"></a>Turaco: Complexity-Guided Data Sampling for Training Neural Surrogates of Programs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11726">http://arxiv.org/abs/2309.11726</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex Renda, Yi Ding, Michael Carbin</li>
<li>for: 本研究旨在提供一种基于神经网络的程序代理构建方法，以解决软件开发中的一些挑战。</li>
<li>methods: 本研究使用了一种基于程序行为测量的训练数据采样方法，以确定训练代理的最佳数据集。首先，研究人员计算了每个程序执行路径的学习复杂度，然后根据复杂度进行数据采样。</li>
<li>results: 研究人员在一系列实际项目上进行了实验，结果显示，复杂度指导的采样方法可以提高代理的准确性。<details>
<summary>Abstract</summary>
Programmers and researchers are increasingly developing surrogates of programs, models of a subset of the observable behavior of a given program, to solve a variety of software development challenges. Programmers train surrogates from measurements of the behavior of a program on a dataset of input examples. A key challenge of surrogate construction is determining what training data to use to train a surrogate of a given program.   We present a methodology for sampling datasets to train neural-network-based surrogates of programs. We first characterize the proportion of data to sample from each region of a program's input space (corresponding to different execution paths of the program) based on the complexity of learning a surrogate of the corresponding execution path. We next provide a program analysis to determine the complexity of different paths in a program. We evaluate these results on a range of real-world programs, demonstrating that complexity-guided sampling results in empirical improvements in accuracy.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Efficient-Core-selecting-Incentive-Mechanism-for-Data-Sharing-in-Federated-Learning"><a href="#Efficient-Core-selecting-Incentive-Mechanism-for-Data-Sharing-in-Federated-Learning" class="headerlink" title="Efficient Core-selecting Incentive Mechanism for Data Sharing in Federated Learning"></a>Efficient Core-selecting Incentive Mechanism for Data Sharing in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11722">http://arxiv.org/abs/2309.11722</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mengda Ji, Genjiu Xu, Jianjun Ge, Mingqiang Li<br>for: This paper focuses on developing an incentive mechanism for federated learning that encourages participants to input high-quality data truthfully and promotes stable cooperation.methods: The authors use game-theoretic approaches and the concept of the core from cooperative games to design an incentive mechanism. They also propose an efficient core-selecting mechanism based on sampling approximation to reduce computational overhead.results: The proposed mechanism is able to incentivize inputting high-quality data and stable cooperation, while reducing computational overhead compared to the core-selecting mechanism. Extensive experiments verify the effectiveness of the proposed mechanism.Here’s the simplified Chinese text version:for: 这篇论文关注于为联合学习建立一种奖励机制，以便参与者输入高质量数据并寻求稳定合作。methods: 作者使用游戏理论和合作游戏中的核概念来设计奖励机制。他们还提出了一种基于抽样估计的有效核选机制，以降低计算开销。results: 提出的机制能够奖励输入高质量数据和稳定合作，同时降低计算开销相比核选机制。广泛的实验证明了机制的有效性。<details>
<summary>Abstract</summary>
Federated learning is a distributed machine learning system that uses participants' data to train an improved global model. In federated learning, participants cooperatively train a global model, and they will receive the global model and payments. Rational participants try to maximize their individual utility, and they will not input their high-quality data truthfully unless they are provided with satisfactory payments based on their data quality. Furthermore, federated learning benefits from the cooperative contributions of participants. Accordingly, how to establish an incentive mechanism that both incentivizes inputting data truthfully and promotes stable cooperation has become an important issue to consider. In this paper, we introduce a data sharing game model for federated learning and employ game-theoretic approaches to design a core-selecting incentive mechanism by utilizing a popular concept in cooperative games, the core. In federated learning, the core can be empty, resulting in the core-selecting mechanism becoming infeasible. To address this, our core-selecting mechanism employs a relaxation method and simultaneously minimizes the benefits of inputting false data for all participants. However, this mechanism is computationally expensive because it requires aggregating exponential models for all possible coalitions, which is infeasible in federated learning. To address this, we propose an efficient core-selecting mechanism based on sampling approximation that only aggregates models on sampled coalitions to approximate the exact result. Extensive experiments verify that the efficient core-selecting mechanism can incentivize inputting high-quality data and stable cooperation, while it reduces computational overhead compared to the core-selecting mechanism.
</details>
<details>
<summary>摘要</summary>
federated learning 是一种分布式机器学习系统，使用参与者的数据来训练global模型。在 federated learning 中，参与者合作训练 global模型，并将收到 global模型和支付。理智参与者会尽可能地提高自己的个人利益，而不会 Inputting truthful high-quality data  Unless satisfactory payments are provided based on data quality. In addition, federated learning benefits from the cooperative contributions of participants. Therefore, how to establish an incentive mechanism that both incentivizes inputting data truthfully and promotes stable cooperation has become an important issue to consider.In this paper, we introduce a data sharing game model for federated learning and employ game-theoretic approaches to design a core-selecting incentive mechanism based on a popular concept in cooperative games, the core. In federated learning, the core can be empty, resulting in the core-selecting mechanism becoming infeasible. To address this, our core-selecting mechanism employs a relaxation method and simultaneously minimizes the benefits of inputting false data for all participants. However, this mechanism is computationally expensive because it requires aggregating exponential models for all possible coalitions, which is infeasible in federated learning.To address this, we propose an efficient core-selecting mechanism based on sampling approximation that only aggregates models on sampled coalitions to approximate the exact result. Extensive experiments verify that the efficient core-selecting mechanism can incentivize inputting high-quality data and stable cooperation, while it reduces computational overhead compared to the core-selecting mechanism.
</details></li>
</ul>
<hr>
<h2 id="Quasi-Monte-Carlo-for-3D-Sliced-Wasserstein"><a href="#Quasi-Monte-Carlo-for-3D-Sliced-Wasserstein" class="headerlink" title="Quasi-Monte Carlo for 3D Sliced Wasserstein"></a>Quasi-Monte Carlo for 3D Sliced Wasserstein</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11713">http://arxiv.org/abs/2309.11713</a></li>
<li>repo_url: None</li>
<li>paper_authors: Khai Nguyen, Nicola Bariletto, Nhat Ho</li>
<li>for: 提供一种更好的类Empirical Wasserstein（QSW）方法，用于计算三维空间中的水平概率分布之间的距离。</li>
<li>methods: 使用Quasi-Monte Carlo（QMC）方法，包括Gaussian-based mapping、等面积映射、通用卷积点和优化不准确能量等方法来构建QMC点集。</li>
<li>results: 通过实验表明，QSW和Randomized Quasi-Sliced Wasserstein（RQSW）variant具有优秀的性能，可以应用于多种三维任务，如点云比较、点云插值、图像风格传递和深度点云自动编码器的训练。<details>
<summary>Abstract</summary>
Monte Carlo (MC) approximation has been used as the standard computation approach for the Sliced Wasserstein (SW) distance, which has an intractable expectation in its analytical form. However, the MC method is not optimal in terms of minimizing the absolute approximation error. To provide a better class of empirical SW, we propose quasi-sliced Wasserstein (QSW) approximations that rely on Quasi-Monte Carlo (QMC) methods. For a comprehensive investigation of QMC for SW, we focus on the 3D setting, specifically computing the SW between probability measures in three dimensions. In greater detail, we empirically verify various ways of constructing QMC points sets on the 3D unit-hypersphere, including Gaussian-based mapping, equal area mapping, generalized spiral points, and optimizing discrepancy energies. Furthermore, to obtain an unbiased estimation for stochastic optimization, we extend QSW into Randomized Quasi-Sliced Wasserstein (RQSW) by introducing randomness to the discussed low-discrepancy sequences. For theoretical properties, we prove the asymptotic convergence of QSW and the unbiasedness of RQSW. Finally, we conduct experiments on various 3D tasks, such as point-cloud comparison, point-cloud interpolation, image style transfer, and training deep point-cloud autoencoders, to demonstrate the favorable performance of the proposed QSW and RQSW variants.
</details>
<details>
<summary>摘要</summary>
蒙特卡洛（MC）方法已经被用作水平割（SW）距离的标准计算方法，但MC方法不是最佳的精度最小化方法。为提供更好的empirical SW，我们提议 quasi-sliced Wasserstein（QSW）近似方法，基于Quasi-Monte Carlo（QMC）方法。为了进行全面的QMC方法对SW的调查，我们在3D设置中计算了SW между概率分布。在更详细的描述中，我们在3D单位球上构建了QMC点集，包括高斯映射、等面积映射、通用螺旋点和优化误差能量。此外，为了获得无偏估的优化，我们将QSW扩展到随机化 quasi-sliced Wasserstein（RQSW）中，通过引入随机性来讲谱低误差序列。我们证明了QSW的极限减少和RQSW的无偏估性。最后，我们在various 3D任务上进行了实验，如点云比较、点云插值、图像风格传递和训练深点云自动编码器，以示我们提议的QSW和RQSW变体的优异性。
</details></li>
</ul>
<hr>
<h2 id="Incentivized-Communication-for-Federated-Bandits"><a href="#Incentivized-Communication-for-Federated-Bandits" class="headerlink" title="Incentivized Communication for Federated Bandits"></a>Incentivized Communication for Federated Bandits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11702">http://arxiv.org/abs/2309.11702</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhepei Wei, Chuanhao Li, Haifeng Xu, Hongning Wang</li>
<li>for: 这篇论文的目的是为了提出一个奖励客户端分享数据的 Federated Bandit Learning 问题，并提出首个奖励通信协议（Inc-FedUCB），以获得近乎最佳的 regret 性能和通信成本保证。</li>
<li>methods: 这篇论文使用了 Contextual Linear Setting 和奖励通信协议（Inc-FedUCB），实际验证了这个方法在不同环境下的效果。</li>
<li>results: 这篇论文的实验结果显示，这个方法可以在不同的数据集和环境下获得近乎最佳的 regret 性能和通信成本保证。<details>
<summary>Abstract</summary>
Most existing works on federated bandits take it for granted that all clients are altruistic about sharing their data with the server for the collective good whenever needed. Despite their compelling theoretical guarantee on performance and communication efficiency, this assumption is overly idealistic and oftentimes violated in practice, especially when the algorithm is operated over self-interested clients, who are reluctant to share data without explicit benefits. Negligence of such self-interested behaviors can significantly affect the learning efficiency and even the practical operability of federated bandit learning. In light of this, we aim to spark new insights into this under-explored research area by formally introducing an incentivized communication problem for federated bandits, where the server shall motivate clients to share data by providing incentives. Without loss of generality, we instantiate this bandit problem with the contextual linear setting and propose the first incentivized communication protocol, namely, Inc-FedUCB, that achieves near-optimal regret with provable communication and incentive cost guarantees. Extensive empirical experiments on both synthetic and real-world datasets further validate the effectiveness of the proposed method across various environments.
</details>
<details>
<summary>摘要</summary>
大多数现有的联合搜寻工作假设所有客户端都是善于分享其数据给服务器以实现共同好的，这是一个过于理想化的假设，在实际应用中经常被违反。特别是当算法运行在自私的客户端上时，这些客户端可能会拒绝分享数据没有显式的利益。忽略这种自私行为可能会对联合搜寻的学习效率和实际运行造成重要的影响。为了提供新的思想和挑战，我们正式引入了一个奖励通信问题，即服务器应该如何鼓励客户端分享数据，以提高联合搜寻的性能。不失一般性，我们在上下文分析的情况下实例化了这个带itul bandit问题，并提出了首个奖励通信协议，即Inc-FedUCB，该协议可以实现近似优化的停损 regret，同时具有可证明的通信和奖励成本保证。在synthetic和实际数据上进行了广泛的实验，证明了我们的方法在不同环境下的效果。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/21/cs.LG_2023_09_21/" data-id="cloqtaetr00pvgh88gcwu21ly" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_09_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/21/eess.IV_2023_09_21/" class="article-date">
  <time datetime="2023-09-21T09:00:00.000Z" itemprop="datePublished">2023-09-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/21/eess.IV_2023_09_21/">eess.IV - 2023-09-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="ISLAND-Informing-Brightness-and-Surface-Temperature-Through-a-Land-Cover-based-Interpolator"><a href="#ISLAND-Informing-Brightness-and-Surface-Temperature-Through-a-Land-Cover-based-Interpolator" class="headerlink" title="ISLAND: Informing Brightness and Surface Temperature Through a Land Cover-based Interpolator"></a>ISLAND: Informing Brightness and Surface Temperature Through a Land Cover-based Interpolator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12416">http://arxiv.org/abs/2309.12416</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhao Liu, Pranavesh Panakkal, Sylvia Dee, Guha Balakrishnan, Jamie Padgett, Ashok Veeraraghavan</li>
<li>for: 这个论文是为了解决云幕干扰remote sensing thermal imaging中的问题而写的。</li>
<li>methods: 这个论文使用了一种新的方法，即ISLAND方法，该方法使用了兰达特8号卫星的热红外图像和NLCD地面覆盖数据，通过一系列的空间-时间滤波来预测云幕干扰所干扰的热度和地面温度。</li>
<li>results: 该论文通过质量和量度分析表明，ISLAND方法在不同的云幕干扰和地面覆盖条件下具有良好的重建性能，并且具有高空间-时间分辨率。 authors还提供了20个美国城市的公共数据集，以便用于证明ISLAND方法的可行性和应用性。<details>
<summary>Abstract</summary>
Cloud occlusion is a common problem in the field of remote sensing, particularly for thermal infrared imaging. Remote sensing thermal instruments onboard operational satellites are supposed to enable frequent and high-resolution observations over land; unfortunately, clouds adversely affect thermal signals by blocking outgoing longwave radiation emission from Earth's surface, interfering with the retrieved ground emission temperature. Such cloud contamination severely reduces the set of serviceable thermal images for downstream applications, making it impractical to perform intricate time-series analysis of land surface temperature (LST). In this paper, we introduce a novel method to remove cloud occlusions from Landsat 8 LST images. We call our method ISLAND, an acronym for Informing Brightness and Surface Temperature Through a Land Cover-based Interpolator. Our approach uses thermal infrared images from Landsat 8 (at 30 m resolution with 16-day revisit cycles) and the NLCD land cover dataset. Inspired by Tobler's first law of Geography, ISLAND predicts occluded brightness temperature and LST through a set of spatio-temporal filters that perform distance-weighted spatio-temporal interpolation. A critical feature of ISLAND is that the filters are land cover-class aware, making it particularly advantageous in complex urban settings with heterogeneous land cover types and distributions. Through qualitative and quantitative analysis, we show that ISLAND achieves robust reconstruction performance across a variety of cloud occlusion and surface land cover conditions, and with a high spatio-temporal resolution. We provide a public dataset of 20 U.S. cities with pre-computed ISLAND thermal infrared and LST outputs. Using several case studies, we demonstrate that ISLAND opens the door to a multitude of high-impact urban and environmental applications across the continental United States.
</details>
<details>
<summary>摘要</summary>
云层遮挡是远程感知领域中常见的问题，尤其是对于thermal infrared成像。远程感知thermal仪器装载在运行的卫星上，旨在实现频繁和高分辨率的地表观测;然而，云层会阻挡地表发射的长波辐射，使得抽取地表温度的热成像受到抑制，从而减少可用的热成像数据，使得无法进行复杂的时间序分析。在这篇文章中，我们介绍了一种新的云层遮挡除去方法，称为ISLAND（表示地表温度和辐射通过地域涂抹 interpolator）。我们的方法使用卫星8的热红外成像（分辨率30米，复杂周期16天）和NLCD地表覆盖数据。受到 Tobler's first law of Geography 的激发，ISLAND 预测云层遮挡的明亮温度和地表温度通过一系列的空间时间滤波来实现。我们的方法的一个关键特点是滤波是根据地表覆盖类型进行地域涂抹，这使得它在复杂的城市环境中具有优势。通过质量和量化分析，我们显示了ISLAND 在多种云层遮挡和地表覆盖条件下具有强健的重建性，并且具有高空间时间分辨率。我们提供了20个美国城市的前计算ISLAND 热红外成像和地表温度输出数据。通过多个案例研究，我们示出了ISLAND 可以开启许多高影响的城市和环境应用程序，覆盖整个北美大陆。
</details></li>
</ul>
<hr>
<h2 id="Bloch-Equation-Enables-Physics-informed-Neural-Network-in-Parametric-Magnetic-Resonance-Imaging"><a href="#Bloch-Equation-Enables-Physics-informed-Neural-Network-in-Parametric-Magnetic-Resonance-Imaging" class="headerlink" title="Bloch Equation Enables Physics-informed Neural Network in Parametric Magnetic Resonance Imaging"></a>Bloch Equation Enables Physics-informed Neural Network in Parametric Magnetic Resonance Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11763">http://arxiv.org/abs/2309.11763</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingrui Cai, Liuhong Zhu, Jianjun Zhou, Chen Qian, Di Guo, Xiaobo Qu</li>
<li>for: 用于非侵入性的诊断 диагности中的重要成像方法之一，即核磁共振成像（MRI）。</li>
<li>methods: 提出使用物理规则embedded into the loss of physics-informed neural network（PINN）来学习 Bloch equation，并且通过这种方法来估算T2参数和生成physically synthetic data。</li>
<li>results: 在phantom和cardiac imaging中进行了实验，并得到了这种方法的潜在应用于量化MRI中的可能性。<details>
<summary>Abstract</summary>
Magnetic resonance imaging (MRI) is an important non-invasive imaging method in clinical diagnosis. Beyond the common image structures, parametric imaging can provide the intrinsic tissue property thus could be used in quantitative evaluation. The emerging deep learning approach provides fast and accurate parameter estimation but still encounters the lack of network interpretation and enough training data. Even with a large amount of training data, the mismatch between the training and target data may introduce errors. Here, we propose one way that solely relies on the target scanned data and does not need a pre-defined training database. We provide a proof-of-concept that embeds the physical rule of MRI, the Bloch equation, into the loss of physics-informed neural network (PINN). PINN enables learning the Bloch equation, estimating the T2 parameter, and generating a series of physically synthetic data. Experimental results are conducted on phantom and cardiac imaging to demonstrate its potential in quantitative MRI.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/21/eess.IV_2023_09_21/" data-id="cloqtaf0s016xgh8802oq29h8" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_09_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/09/21/eess.SP_2023_09_21/" class="article-date">
  <time datetime="2023-09-21T08:00:00.000Z" itemprop="datePublished">2023-09-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/09/21/eess.SP_2023_09_21/">eess.SP - 2023-09-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Distributed-CSMA-CA-MAC-Protocol-for-RIS-Assisted-Networks"><a href="#Distributed-CSMA-CA-MAC-Protocol-for-RIS-Assisted-Networks" class="headerlink" title="Distributed CSMA&#x2F;CA MAC Protocol for RIS-Assisted Networks"></a>Distributed CSMA&#x2F;CA MAC Protocol for RIS-Assisted Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12526">http://arxiv.org/abs/2309.12526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhou Zhang, Saman Atapattu, Yizhu Wang, Marco Di Renzo</li>
<li>for: 提高分布式网络中多用户通道访问的优化</li>
<li>methods: 基于可配置智能面(RIS)的分布式CSMA&#x2F;CA策略，包括机会检测和避免冲突</li>
<li>results: 提出了一种优化的分布式CSMA&#x2F;CA策略，可以 maximize 系统吞吐量，并且在数据分析和实验验证中表现出色，与现有方法相比表现更优。<details>
<summary>Abstract</summary>
This paper focuses on achieving optimal multi-user channel access in distributed networks using a reconfigurable intelligent surface (RIS). The network includes wireless channels with direct links between users and RIS links connecting users to the RIS. To maximize average system throughput, an optimal channel access strategy is proposed, considering the trade-off between exploiting spatial diversity gain with RIS assistance and the overhead of channel probing. The paper proposes an optimal distributed Carrier Sense Multiple Access with Collision Avoidance (CSMA/CA) strategy with opportunistic RIS assistance, based on statistics theory of optimal sequential observation planned decision. Each source-destination pair makes decisions regarding the use of direct links and/or probing source-RIS-destination links. Channel access occurs in a distributed manner after successful channel contention. The optimality of the strategy is rigorously derived using multiple-level pure thresholds. A distributed algorithm, which achieves significantly lower online complexity at $O(1)$, is developed to implement the proposed strategy. Numerical simulations verify the theoretical results and demonstrate the superior performance compared to existing approaches.
</details>
<details>
<summary>摘要</summary>
Translation:这篇论文关注了使用分布式网络中的可配置智能表面（RIS）实现最佳多用户通道访问。网络包括无线通道和RIS连接用户和RIS之间的连接。为了最大化系统吞吐量，提出了一种最佳的多用户通道访问策略，考虑了RIS协助下的空间多普通耗和扫描过程的开销。提出了基于统计学理论的最佳分布式CSMA/CA策略，每个源-目的对象对使用直接链接和/或探测源-RIS-目的链接进行决策。通道访问发生在分布式方式下，并且在成功扫描后进行通道竞争。提出的策略的优化性基于多级纯阈值理论。开发了一种实现该策略的分布式算法，具有较低的在线复杂度($O(1)$)。numerical simulations verify the theoretical results and demonstrate the superior performance compared to existing approaches.
</details></li>
</ul>
<hr>
<h2 id="Deep-Reinforcement-Learning-for-Backscatter-Communications-Augmenting-Intelligence-in-Future-Internet-of-Things"><a href="#Deep-Reinforcement-Learning-for-Backscatter-Communications-Augmenting-Intelligence-in-Future-Internet-of-Things" class="headerlink" title="Deep Reinforcement Learning for Backscatter Communications: Augmenting Intelligence in Future Internet of Things"></a>Deep Reinforcement Learning for Backscatter Communications: Augmenting Intelligence in Future Internet of Things</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12507">http://arxiv.org/abs/2309.12507</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wali Ullah Khan, Eva Lagunas, Zain Ali, Asad Mahmood, Chandan Kumar Sheemar, Manzoor Ahmed, Symeon Chatzinotas, Björn Ottersten</li>
<li>for: 这篇论文旨在探讨深度强化学习（DRL）和回射通信（BC）技术在下一代互联网大数据网络中的应用。</li>
<li>methods: 本文首先介绍了BC系统的基本原理，然后详细介绍了多种DRL技术和其实现方式。</li>
<li>results: 研究表明，DRL可以帮助BC系统提高性能和可靠性，同时也可以减少能耗。一个使用RIS增强非对称多access BC系统的实践案例也被详细探讨，以 highlight its potential。<details>
<summary>Abstract</summary>
Backscatter communication (BC) technology offers sustainable solutions for next-generation Internet-of-Things (IoT) networks, where devices can transmit data by reflecting and adjusting incident radio frequency signals. In parallel to BC, deep reinforcement learning (DRL) has recently emerged as a promising tool to augment intelligence and optimize low-powered IoT devices. This article commences by elucidating the foundational principles underpinning BC systems, subsequently delving into the diverse array of DRL techniques and their respective practical implementations. Subsequently, it investigates potential domains and presents recent advancements in the realm of DRL-BC systems. A use case of RIS-aided non-orthogonal multiple access BC systems leveraging DRL is meticulously examined to highlight its potential. Lastly, this study identifies and investigates salient challenges and proffers prospective avenues for future research endeavors.
</details>
<details>
<summary>摘要</summary>
🇨🇳 备受关注的技术：后递射通信（BC）技术可以为下一代互联网关键设备（IoT）网络提供可持续的解决方案，其中设备可以通过反射和调整 incident 无线电频信号来传输数据。同时，深度强化学习（DRL）技术在最近几年内 emerge 为优化低功耗 IoT 设备的工具。本文从 BC 系统的基础原理出发，然后介绍了多种 DRL 技术和其实践。接着，它 investigate 了 BC-DRL 系统在不同领域的应用前景，并 analyze 了一些最新的进展。最后，本文详细介绍了 RIS-assisted 非对称多接入 BC 系统的应用，以 illustrate 其潜在的优势。总之，本文概括了 BC 技术和 DRL 技术的相互作用，并 analyze 了它们在 IoT 网络中的应用前景。此外，它还提出了未来研究的挑战和机遇。
</details></li>
</ul>
<hr>
<h2 id="Secure-Degree-of-Freedom-of-Wireless-Networks-Using-Collaborative-Pilots"><a href="#Secure-Degree-of-Freedom-of-Wireless-Networks-Using-Collaborative-Pilots" class="headerlink" title="Secure Degree of Freedom of Wireless Networks Using Collaborative Pilots"></a>Secure Degree of Freedom of Wireless Networks Using Collaborative Pilots</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12502">http://arxiv.org/abs/2309.12502</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yingbo Hua, Qingpeng Liang, Md Saydur Rahman</li>
<li>for: 这个论文旨在研究一种基于协作频道估计（ANECE）的无线网络，其中每个节点都使用同样的数量的天线进行发送和接收。这种网络可以在无线网络中提供安全的度量（SDoF），无论侦测者可能拥有多少天线。</li>
<li>methods: 本论文使用秘密键容量（SKC）来分析每对节点的安全度量。每个传输会话中有两个阶段：第一阶段用于测试，第二阶段用于随机符号。这导致了两部分的SDoF。</li>
<li>results: 研究发现了一些重要的结论，包括：a) 阶段1的SDoF相同于多用户ANECE和对等ANECE，但前者可能需要较少的时间槽数；b) 三个节点网络中的阶段2SDoF通常比对等ANECE更大；c) 两节点网络中使用修改后的ANECE，使用块形非零幂频道Matrix，可以提高总的SDoF。这些多用户ANECE和修改后的两节点ANECE在安全度量方面与每个节点使用给定数量的天线进行发送和接收是今天已知最佳的全双工协议。<details>
<summary>Abstract</summary>
A wireless network of full-duplex nodes/users, using anti-eavesdropping channel estimation (ANECE) based on collaborative pilots, can yield a positive secure degree-of-freedom (SDoF) regardless of the number of antennas an eavesdropper may have. This paper presents novel results on SDoF of ANECE by analyzing secret-key capacity (SKC) of each pair of nodes in a network of multiple collaborative nodes per channel coherence period. Each transmission session of ANECE has two phases: phase 1 is used for pilots, and phase 2 is used for random symbols. This results in two parts of SDoF of ANECE. Both lower and upper bounds on the SDoF of ANECE for any number of users are shown, and the conditions for the two bounds to meet are given. This leads to important discoveries, including: a) The phase-1 SDoF is the same for both multi-user ANECE and pair-wise ANECE while the former may require only a fraction of the number of time slots needed by the latter; b) For a three-user network, the phase-2 SDoF of all-user ANECE is generally larger than that of pair-wise ANECE; c) For a two-user network, a modified ANECE deploying square-shaped nonsingular pilot matrices yields a higher total SDoF than the original ANECE. The multi-user ANECE and the modified two-user ANECE shown in this paper appear to be the best full-duplex schemes known today in terms of SDoF subject to each node using a given number of antennas for both transmitting and receiving.
</details>
<details>
<summary>摘要</summary>
一个无线网络，由全双工节点/用户组成，使用反听抓取渠道估计（ANECE），可以获得一定的安全度量（SDoF），无论抓取者具有多少天线。这篇论文提出了新的SDoF结果，通过分析每对节点的秘密键容量（SKC），并分析每个通信会话的两个阶段：第一阶段用于测试，第二阶段用于随机符号。这导致了两个SDoF的部分，其中一个是第一阶段的SDoF，另一个是第二阶段的SDoF。这篇论文还提供了对SDoF的下界和上界，以及这两个界限之间的条件。这些结果包括：a) 第一阶段SDoF在多用户ANECE和对应的对抗式ANECE中是相同的，而后者可能需要更少的时间槽数；b) 对于三个用户网络，第二阶段SDoF的全用户ANECE通常大于对抗式ANECE的SDoF；c) 对于两个用户网络，使用方形非零幂测试矩阵的修改后ANECE可以获得更高的总SDoF，比原始ANECE更高。这些多用户ANECE和修改后的两用户ANECE在今天可能是使用给定数量天线的最佳全双工方案，从SDoF的角度来看。
</details></li>
</ul>
<hr>
<h2 id="Near-Field-Optimization-Algorithm-for-Reconfigurable-Intelligent-Surface"><a href="#Near-Field-Optimization-Algorithm-for-Reconfigurable-Intelligent-Surface" class="headerlink" title="Near Field Optimization Algorithm for Reconfigurable Intelligent Surface"></a>Near Field Optimization Algorithm for Reconfigurable Intelligent Surface</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12448">http://arxiv.org/abs/2309.12448</a></li>
<li>repo_url: None</li>
<li>paper_authors: Emanuel Colella, Luca Bastianelli, Franco Moglie, Valter Mariani Primiani</li>
<li>for: 本研究旨在开发一种可重新配置的智能表面技术，以优化无线通信场景中信号传递的性能。</li>
<li>methods: 本研究使用了一种多维度优化算法，基于GNU科学库的Multidimensional optimization算法，来重新配置智能表面。</li>
<li>results: 通过电磁动力学 simulations，研究人员发现该算法可以很有效地重新配置智能表面，使电磁波能够强制方向性地传递到点 interests。<details>
<summary>Abstract</summary>
Reconfigurable intelligent surface (RIS) is a type of wireless communication technology that uses a reconfigurable surface, such as a wall or building that is able to adjust its properties by an integrated optimization algorithm in order to optimize the signal propagation for a given communication scenario. As a reconfiguration algorithm the multidimensional optimization of the GNU scientific library was analyzed to evaluate the performance of the smart surface in the quality of signal reception. This analysis took place by means of electrodynamic simulations based on the finite difference time domain method. Through these simulations it was possible to observe the efficiency of the algorithm in the reconfiguration of the RIS, managing to focus the electromagnetic waves in a remarkable way towards the point of interest.
</details>
<details>
<summary>摘要</summary>
智能表面重配置技术 (RIS) 是一种无线通信技术，使用可重配置的表面，如墙或建筑物，通过内置优化算法来调整其属性，以优化给定通信场景中信号协议的传播。作为重配置算法，多维度优化 GNU 科学库的分析进行了评估，以评估智能表面在信号接收质量方面的性能。这种分析通过基于 Finite Difference Time Domain 方法的电磁动力学模拟来进行。通过这些模拟，可以观察智能表面重配置算法的效率，并能够很有效地将电磁波集中到 interess point。
</details></li>
</ul>
<hr>
<h2 id="RadYOLOLet-Radar-Detection-and-Parameter-Estimation-Using-YOLO-and-WaveLet"><a href="#RadYOLOLet-Radar-Detection-and-Parameter-Estimation-Using-YOLO-and-WaveLet" class="headerlink" title="RadYOLOLet: Radar Detection and Parameter Estimation Using YOLO and WaveLet"></a>RadYOLOLet: Radar Detection and Parameter Estimation Using YOLO and WaveLet</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12094">http://arxiv.org/abs/2309.12094</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shamik Sarkar, Dongning Guo, Danijela Cabric</li>
<li>for: 这篇论文的目的是探讨一种无助 partir radar 信号探测方法，以满足未来的共享频率无线网络，如公民广播电波服务 (CBRS) 的需求。</li>
<li>methods: 本篇论文提出了一种几何学 deep learning 基础的spectrum sensing方法，名为 RadYOLOLet，可以探测低功率 radar 信号在干扰的情况下，并且可以估算 radar 信号的参数。RadYOLOLet 的核心是两个不同的卷积神经网 (CNN)，名为 RadYOLO 和 Wavelet-CNN，它们是独立地训练。RadYOLO 运作在spectrograms 上，提供了 RadYOLOLet 的大部分功能。然而，它在低信号输入比例 (SNR)  regime 的情况下具有低适应率。为了解决这个问题，我们开发了 Wavelet-CNN，它运作在独立的干扰变换 (Wavelet) 上，并且仅在 RadYOLO 无法探测任何 radar 信号时使用。</li>
<li>results: 根据我们的评估，RadYOLOLet 可以在不同的实验中，实现 100% 的 radar 探测精度，并且可以在干扰输入比例 (SINR)  up to 16 dB 下运作正确。<details>
<summary>Abstract</summary>
Detection of radar signals without assistance from the radar transmitter is a crucial requirement for emerging and future shared-spectrum wireless networks like Citizens Broadband Radio Service (CBRS). In this paper, we propose a supervised deep learning-based spectrum sensing approach called RadYOLOLet that can detect low-power radar signals in the presence of interference and estimate the radar signal parameters. The core of RadYOLOLet is two different convolutional neural networks (CNN), RadYOLO and Wavelet-CNN, that are trained independently. RadYOLO operates on spectrograms and provides most of the capabilities of RadYOLOLet. However, it suffers from low radar detection accuracy in the low signal-to-noise ratio (SNR) regime. We develop Wavelet-CNN specifically to deal with this limitation of RadYOLO. Wavelet-CNN operates on continuous Wavelet transform of the captured signals, and we use it only when RadYOLO fails to detect any radar signal. We thoroughly evaluate RadYOLOLet using different experiments corresponding to different types of interference signals. Based on our evaluations, we find that RadYOLOLet can achieve 100% radar detection accuracy for our considered radar types up to 16 dB SNR, which cannot be guaranteed by other comparable methods. RadYOLOLet can also function accurately under interference up to 16 dB SINR.
</details>
<details>
<summary>摘要</summary>
“探测无助者的激光讯号是未来共享频率无线网络的重要需求，如公民广播电台服务（CBRS）。在这篇论文中，我们提出了一个监督学习基于的对应方法，名为RadYOLOLet，可以探测低功率激光讯号在干扰下的存在，并且估算激光讯号的参数。RadYOLOLet的核心是两个不同的卷积神经网（CNN）：RadYOLO和浪潮-CNN。这两个神经网在独立地训练。RadYOLO在spectrogram中运作，它提供了RadYOLOLet的大部分功能。然而，它在低信号载波比例（SNR） regime下的激光探测精度较低。我们为了解决这个问题，我们开发了特别的浪潮-CNN，它在捕捉到的信号中使用浪潮变换，并且仅在RadYOLO失败探测任何激光讯号时使用。我们对RadYOLOLet进行了不同类型的实验，包括不同类型的干扰信号。根据我们的评估，RadYOLOLet可以在考虑的激光型别上达到100%的探测精度，并且在干扰较高的16 dB SINR下还能正确运作。”
</details></li>
</ul>
<hr>
<h2 id="UAV-Swarm-Deployment-and-Trajectory-for-3D-Area-Coverage-via-Reinforcement-Learning"><a href="#UAV-Swarm-Deployment-and-Trajectory-for-3D-Area-Coverage-via-Reinforcement-Learning" class="headerlink" title="UAV Swarm Deployment and Trajectory for 3D Area Coverage via Reinforcement Learning"></a>UAV Swarm Deployment and Trajectory for 3D Area Coverage via Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11992">http://arxiv.org/abs/2309.11992</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jia He, Ziye Jia, Chao Dong, Junyu Liu, Qihui Wu, Jingxian Liu</li>
<li>For: 本文旨在研究无人飞行器群（UAV群）的投放和轨迹计划，以满足三维（3D）enario中的无线通信服务。* Methods: 本文提出了层次群组织机制，以有效地服务大面积用户。问题转化为最小化UAV群的总轨迹损失。但问题具有非托Formatter property，因此将其拆分为用户卷积、UAV群停留点选择和群 trajectory 确定。* Results: 本文采用Q学习算法加速解决效率。经过广泛的 simulations，提出的机制和算法被证明超过其他相关方法。<details>
<summary>Abstract</summary>
Unmanned aerial vehicles (UAVs) are recognized as promising technologies for area coverage due to the flexibility and adaptability. However, the ability of a single UAV is limited, and as for the large-scale three-dimensional (3D) scenario, UAV swarms can establish seamless wireless communication services. Hence, in this work, we consider a scenario of UAV swarm deployment and trajectory to satisfy 3D coverage considering the effects of obstacles. In detail, we propose a hierarchical swarm framework to efficiently serve the large-area users. Then, the problem is formulated to minimize the total trajectory loss of the UAV swarm. However, the problem is intractable due to the non-convex property, and we decompose it into smaller issues of users clustering, UAV swarm hovering points selection, and swarm trajectory determination. Moreover, we design a Q-learning based algorithm to accelerate the solution efficiency. Finally, we conduct extensive simulations to verify the proposed mechanisms, and the designed algorithm outperforms other referred methods.
</details>
<details>
<summary>摘要</summary>
无人飞行器（UAV）被认为是广泛覆盖区域的有望技术，由于它们的灵活和适应能力。然而，单个UAV的能力有限，而在大规模三维（3D）场景中，UAV群可以建立无缝无线通信服务。因此，在这项工作中，我们考虑了UAV群的部署和轨迹，以满足3D覆盖的需求，并考虑了障碍物的影响。在详细的描述中，我们提出了层次群组织，以高效地服务于大面积用户。然后，我们将问题定义为最小化UAV群的总轨迹损失。然而，问题的非核心性使得它不可解，我们将其分解为用户划分、UAV群停留点选择和群轨迹决定。此外，我们设计了Q学习算法，以加速解决效率。最后，我们进行了广泛的 simulate 来验证我们的机制，并发现我们的设计算法比其他已知方法更高效。
</details></li>
</ul>
<hr>
<h2 id="Alteration-of-skeletal-muscle-energy-metabolism-assessed-by-31P-MRS-in-clinical-routine-part-2-Clinical-application"><a href="#Alteration-of-skeletal-muscle-energy-metabolism-assessed-by-31P-MRS-in-clinical-routine-part-2-Clinical-application" class="headerlink" title="Alteration of skeletal muscle energy metabolism assessed by 31P MRS in clinical routine, part 2: Clinical application"></a>Alteration of skeletal muscle energy metabolism assessed by 31P MRS in clinical routine, part 2: Clinical application</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11934">http://arxiv.org/abs/2309.11934</a></li>
<li>repo_url: None</li>
<li>paper_authors: Antoine Naëgel, Hélène Ratiney, Jabrane Karkouri, Djahid Kennouche, Nicolas Royer, Jill M Slade, Jérôme Morel, Pierre Croisille, Magalie Viallon</li>
<li>For: This study aimed to evaluate the impact of an advanced quality control pipeline on dynamic 31P-MRS studies of two patient populations with different types of fatigue, COVID-19 and multiple sclerosis (MS).* Methods: The study used 31P-MRS on a 3T clinical MRI to collect data from 19 COVID-19 patients, 38 MS patients, and 40 healthy controls. The advanced quality control pipeline was applied to the selected patient cohorts to investigate its impact on clinical outcomes.* Results: The application of the quality control pipeline resulted in increased statistical power, changed the values of several outcome measures, and reduced variability. Significant differences were found between the two patient populations and healthy controls for several metabolite concentrations, including T1PCr and T1Pi for MS patients, and resting [PCr], [Pi], [ADP], [H2PO4-], and pH for COVID-19 patients. Additionally, the use of a fixed correction factor led to systematically higher estimated concentrations of PCr and Pi than when using individually corrected factors.<details>
<summary>Abstract</summary>
Background: In this second part of a two-part paper, we intend to demonstrate the impact of the previously proposed advanced quality control pipeline. To understand its benefit and challenge the proposed methodology in a real scenario, we chose to compare the outcome when applying it to the analysis of two patient populations with a significant but highly different types of fatigue: COVID19 and multiple sclerosis (MS). Experimental: 31P-MRS was performed on a 3T clinical MRI, in 19 COVID19 patients, 38 MS patients, and 40 matched healthy controls. Dynamic acquisitions using an MR-compatible ergometer ran over a rest(40s), exercise(2min), and a recovery phase(6min). Long and short TR acquisitions were also made at rest for T1 correction. The advanced data quality control pipeline presented in part 1 is applied to the selected patient cohorts to investigate its impact on clinical outcomes. We first used power and sample size analysis to estimate objectively the impact of adding QCS. Then, comparisons between patients and healthy control groups using validated QCS were performed using unpaired T-tests or Mann-Whitney tests (p<0.05).Results: The application of the QCS resulted in increased statistical power, changed the values of several outcome measures, and reduced variability (SD). A significant difference was found between the T1PCr and T1Pi of MS patients and healthy controls. Furthermore, the use of a fixed correction factor led to systematically higher estimated concentrations of PCr and Pi than when using individually corrected factors. We observed significant differences between the two patient populations and healthy controls for resting [PCr] -- MS only, [Pi], [ADP], [H2PO4-] and pH -- COVID19 only, and post-exercise [PCr],[Pi] and [H2PO4-] - MS only. The dynamic indicators $\tau$PCr, $\tau$Pi, ViPCr and Vmax were reduced for COVID19 and MS patients compared to controls. Conclusion: Our results show that QCS in dynamic 31P-MRS studies results in smaller data variability and therefore impacts study sample size and power. Although QCS resulted in discarded data and therefore reduced the acceptable data and subject numbers, this rigorous and unbiased approach allowed for proper assessment of muscle metabolites and metabolism in patient populations. The outcomes include an increased metabolite T1, which directly affect the T1 correction factor applied to the amplitudes of the metabolite, and a prolonged $\tau$PCr indicating reduced muscle oxidative capacity for patients with MS and COVID19.
</details>
<details>
<summary>摘要</summary>
Background: 在这篇两部分文章的第二部分中，我们想要证明先前提出的高级质量控制管道的影响。为了了解其效果和挑战，我们选择了对两种不同类型的疲劳 patient population进行比较：COVID-19和多发性硬化病（MS）。Experimental: 我们使用3T临床MRI设备进行31P-MRS测量，共有19例COVID-19患者、38例MS患者和40例健康控制群。动态获取使用MR相容的耐力测试器在休息（40秒）、运动（2分）和恢复阶段（6分）进行测量。同时，我们还进行了长TR和短TR的获取，以便对T1的修正。我们对选择的患者群进行了高级数据质量控制管道的应用，以调查其影响临床结果。我们首先使用力和样本大小分析来对添加QCS的影响进行 объектив评估。然后，我们使用无对照组T检测或曼恩-怀特评估测试（p<0.05）来比较患者和健康控制群。Results: QCS的应用导致数据变量减少，提高了统计力，并改变了一些结果探索结果。COVID-19和MS患者的T1PCr和T1Pi与健康控制群相比显著不同。此外，使用固定修正因子导致PCr和Pi的估计值高于使用个体修正因子。我们发现COVID-19和MS患者在休息期的PCr、Pi、ADP、H2PO4-和pH中具有显著差异。在运动后，COVID-19和MS患者的PCr、Pi和H2PO4-中具有显著差异。动态指标$\tau$PCr、$\tau$Pi、ViPCr和Vmax在COVID-19和MS患者中相比于控制群表现为下降。Conclusion: 我们的结果表明，在动态31P-MRS研究中应用QCS会减少数据变量，因此影响研究样本大小和 statistically power。虽然QCS导致了抛弃数据，因此减少了可接受的数据和试验者数量，但这种不偏袋中和不偏障的方法允许我们对患者群进行正确的 метабоلит和代谢评估。结果包括T1的增加，直接影响了应用于激发物质的T1修正因子，以及COVID-19和MS患者的 prolonged $\tau$PCr， indicating reduced muscle oxidative capacity.
</details></li>
</ul>
<hr>
<h2 id="Index-Modulation-based-Information-Harvesting-for-Far-Field-RF-Power-Transfer"><a href="#Index-Modulation-based-Information-Harvesting-for-Far-Field-RF-Power-Transfer" class="headerlink" title="Index Modulation-based Information Harvesting for Far-Field RF Power Transfer"></a>Index Modulation-based Information Harvesting for Far-Field RF Power Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11929">http://arxiv.org/abs/2309.11929</a></li>
<li>repo_url: None</li>
<li>paper_authors: M. Ertug Pihtili, Mehmet C. Ilter, Ertugrul Basar, Risto Wichman, Jyri Hämäläinen</li>
<li>for: 本研究旨在探讨使用现有的远场能量传输系统进行数据传输，以实现无电池设备的 battery-less 通信技术。</li>
<li>methods: 该研究提出了一种基于索引修改（IM）技术的信息收集（IH）协议，并评估了不同的性能指标。</li>
<li>results: 研究结果表明，通过在现有的远场能量传输系统中应用IM技术，可以实现数据传输，特别在下一代物联网无线网络中表现出了明显的潜力。<details>
<summary>Abstract</summary>
While wireless information transmission (WIT) is evolving into its sixth generation (6G), maintaining terminal operations that rely on limited battery capacities has become one of the most paramount challenges for Internet-of-Things (IoT) platforms. In this respect, there exists a growing interest in energy harvesting technology from ambient resources, and wireless power transfer (WPT) can be the key solution towards enabling battery-less infrastructures referred to as zero-power communication technology. Indeed, eclectic integration approaches between WPT and WIT mechanisms are becoming a vital necessity to limit the need for replacing batteries. Beyond the conventional separation between data and power components of the emitted waveforms, as in simultaneous wireless information and power transfer (SWIPT) mechanisms, a novel protocol referred to as information harvesting (IH) has recently emerged. IH leverages existing WPT mechanisms for data communication by incorporating index modulation (IM) techniques on top of the existing far-field power transfer mechanism. In this paper, a unified framework for the IM-based IH mechanisms has been presented where the feasibility of various IM techniques are evaluated based on different performance metrics. The presented results demonstrate the substantial potential to enable data communication within existing far-field WPT systems, particularly in the context of next-generation IoT wireless networks.
</details>
<details>
<summary>摘要</summary>
sixth generation 无线信息传输 (6G) 的发展，使得互联网物联网 (IoT) 平台上的终端设备靠电池能力有限的问题变得非常紧迫。在这种情况下，能量收集技术从周围环境的资源成为了一种不可或缺的解决方案。无线电力传输 (WPT) 可以是针对无电池基础设施的关键解决方案。此外，将 WPT 和无线信息传输 (WIT) 机制结合在一起，以限制更换电池的需求。在传统的数据和电力两部分分离的情况下，新的协议被称为信息收集 (IH)，利用现有的 WPT 机制来实现数据传输。在这篇论文中，一种基于 индекс修改 (IM) 技术的 IH 机制的一体化框架被提出，并对不同的性能指标进行评估。获得的结果表明，可以在现有的远场 WPT 系统中实现数据传输，特别是在下一代 IoT 无线网络中。
</details></li>
</ul>
<hr>
<h2 id="Multi-Passive-Active-IRS-Enhanced-Wireless-Coverage-Deployment-Optimization-and-Cost-Performance-Trade-off"><a href="#Multi-Passive-Active-IRS-Enhanced-Wireless-Coverage-Deployment-Optimization-and-Cost-Performance-Trade-off" class="headerlink" title="Multi-Passive&#x2F;Active-IRS Enhanced Wireless Coverage: Deployment Optimization and Cost-Performance Trade-off"></a>Multi-Passive&#x2F;Active-IRS Enhanced Wireless Coverage: Deployment Optimization and Cost-Performance Trade-off</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11918">http://arxiv.org/abs/2309.11918</a></li>
<li>repo_url: None</li>
<li>paper_authors: Min Fu, Weidong Mei, Rui Zhang</li>
<li>for: 本研究旨在增强无线网络覆盖率，通过创建多个障碍物free的垂线性连接。</li>
<li>methods: 本文使用多个Passive&#x2F;ActiveIRS（PIRS&#x2F;AIRS）和多antenna基站（BS），并研究了多个非重叠的细分区域，每个细分区域可能会有一个候选位置可以部署PIRS或AIRS。</li>
<li>results: 研究人员通过调整PIRS&#x2F;AIRS的数量和部署位置，以实现给定的信噪比（SNR）目标，同时尽量降低总部署成本。 simulation结果表明，提议的算法可以在困难的 combinatorial optimization 问题中做出优化的选择，并且在cost-performance trade-off中表现更好。<details>
<summary>Abstract</summary>
Both passive and active intelligent reflecting surfaces (IRSs) can be deployed in complex environments to enhance wireless network coverage by creating multiple blockage-free cascaded line-of-sight (LoS) links. In this paper, we study a multi-passive/active-IRS (PIRS/AIRS) aided wireless network with a multi-antenna base station (BS) in a given region. First, we divide the region into multiple non-overlapping cells, each of which may contain one candidate location that can be deployed with a single PIRS or AIRS. Then, we show several trade-offs between minimizing the total IRS deployment cost and enhancing the signal-to-noise ratio (SNR) performance over all cells via direct/cascaded LoS transmission with the BS. To reconcile these trade-offs, we formulate a joint multi-PIRS/AIRS deployment problem to select an optimal subset of all candidate locations for deploying IRS and also optimize the number of passive/active reflecting elements deployed at each selected location to satisfy a given SNR target over all cells, such that the total deployment cost is minimized. However, due to the combinatorial optimization involved, the formulated problem is difficult to be solved optimally. To tackle this difficulty, we first optimize the reflecting element numbers with given PIRS/AIRS deployed locations via sequential refinement, followed by a partial enumeration to determine the PIRS/AIRS locations. Simulation results show that our proposed algorithm achieves better cost-performance trade-offs than other baseline deployment strategies.
</details>
<details>
<summary>摘要</summary>
<<SYS>TRANSLATE_TEXT</SYS>> Both passive and active intelligent reflecting surfaces (IRSs) can be deployed in complex environments to enhance wireless network coverage by creating multiple blockage-free cascaded line-of-sight (LoS) links. In this paper, we study a multi-passive/active-IRS (PIRS/AIRS) aided wireless network with a multi-antenna base station (BS) in a given region. First, we divide the region into multiple non-overlapping cells, each of which may contain one candidate location that can be deployed with a single PIRS or AIRS. Then, we show several trade-offs between minimizing the total IRS deployment cost and enhancing the signal-to-noise ratio (SNR) performance over all cells via direct/cascaded LoS transmission with the BS. To reconcile these trade-offs, we formulate a joint multi-PIRS/AIRS deployment problem to select an optimal subset of all candidate locations for deploying IRS and also optimize the number of passive/active reflecting elements deployed at each selected location to satisfy a given SNR target over all cells, such that the total deployment cost is minimized. However, due to the combinatorial optimization involved, the formulated problem is difficult to be solved optimally. To tackle this difficulty, we first optimize the reflecting element numbers with given PIRS/AIRS deployed locations via sequential refinement, followed by a partial enumeration to determine the PIRS/AIRS locations. Simulation results show that our proposed algorithm achieves better cost-performance trade-offs than other baseline deployment strategies.Translated by Google Translate
</details></li>
</ul>
<hr>
<h2 id="REM-U-net-Deep-Learning-Based-Agile-REM-Prediction-with-Energy-Efficient-Cell-Free-Use-Case"><a href="#REM-U-net-Deep-Learning-Based-Agile-REM-Prediction-with-Energy-Efficient-Cell-Free-Use-Case" class="headerlink" title="REM-U-net: Deep Learning Based Agile REM Prediction with Energy-Efficient Cell-Free Use Case"></a>REM-U-net: Deep Learning Based Agile REM Prediction with Energy-Efficient Cell-Free Use Case</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11898">http://arxiv.org/abs/2309.11898</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hazem Sallouha, Shamik Sarkar, Enes Krijestorac, Danijela Cabric<br>for:这篇论文是为了提出一种快速、准确地预测Radio环境地图（REM）的深度学习方法，以便优化无线网络部署、提高网络性能和有效地管理频率资源。methods:该论文使用了u-net网络，并在大规模3D地图 dataset上进行了训练。此外，文章还提出了数据处理步骤来进一步改进 REM 预测精度。results:论文在2023年IEEE ICASSP Signal Processing Grand Challenge中进行了评估，得到了0.045的 normalized root-mean-square error（RMSE）和14毫秒的平均运行时间。此外，文章还示出了在CF-mMIMO网络中预测 REM 的精度可以代替大规模的折射测量，从而减少能源消耗。<details>
<summary>Abstract</summary>
Radio environment maps (REMs) hold a central role in optimizing wireless network deployment, enhancing network performance, and ensuring effective spectrum management. Conventional REM prediction methods are either excessively time-consuming, e.g., ray tracing, or inaccurate, e.g., statistical models, limiting their adoption in modern inherently dynamic wireless networks. Deep-learning-based REM prediction has recently attracted considerable attention as an appealing, accurate, and time-efficient alternative. However, existing works on REM prediction using deep learning are either confined to 2D maps or use a limited dataset. In this paper, we introduce a runtime-efficient REM prediction framework based on u-nets, trained on a large-scale 3D maps dataset. In addition, data preprocessing steps are investigated to further refine the REM prediction accuracy. The proposed u-net framework, along with preprocessing steps, are evaluated in the context of the 2023 IEEE ICASSP Signal Processing Grand Challenge, namely, the First Pathloss Radio Map Prediction Challenge. The evaluation results demonstrate that the proposed method achieves an average normalized root-mean-square error (RMSE) of 0.045 with an average of 14 milliseconds (ms) runtime. Finally, we position our achieved REM prediction accuracy in the context of a relevant cell-free massive multiple-input multiple-output (CF-mMIMO) use case. We demonstrate that one can obviate consuming energy on large-scale fading measurements and rely on predicted REM instead to decide on which sleep access points (APs) to switch on in a CF-mMIMO network that adopts a minimum propagation loss AP switch ON/OFF strategy.
</details>
<details>
<summary>摘要</summary>
Radio 环境地图 (REM) 在无线网络部署、提高网络性能和有效spectrum管理中扮演中心角色。传统的 REM 预测方法是 either 过时 consume 时间 (如射线追踪) 或者不准确 (如统计模型)，这限制了它们在现代自然动态无线网络中的采用。深度学习基于的 REM 预测在最近吸引了大量关注，因为它们是一种吸引人的、准确的和高效的替代方案。然而，现有的 REM 预测使用深度学习的工作都是 confined to 2D 地图或者使用有限的数据集。在这篇文章中，我们提出了一个高效的 REM 预测框架，基于 u-nets，在大规模 3D 地图数据集上进行训练。此外，我们也 investigate 了数据预处理步骤，以进一步精细化 REM 预测精度。我们的提出的 u-net 框架、预处理步骤和评估结果在 2023 IEEE ICASSP Signal Processing Grand Challenge 中进行了评估。结果表明，我们的方法在normalized root-mean-square error (RMSE) 方面 achieve 平均值为 0.045，并且平均运行时间为 14 毫秒。最后，我们将我们实现的 REM 预测精度与相关的 cell-free massive multiple-input multiple-output (CF-mMIMO) 应用场景进行比较。我们表明，可以不消耗大量的能源进行大规模的折射损失测量，而是可以依靠预测的 REM 来决定在 CF-mMIMO 网络中 Switch ON/OFF 的大量睡眠Access Points (APs)。
</details></li>
</ul>
<hr>
<h2 id="On-the-Performance-Analysis-of-RIS-Empowered-Communications-Over-Nakagami-m-Fading"><a href="#On-the-Performance-Analysis-of-RIS-Empowered-Communications-Over-Nakagami-m-Fading" class="headerlink" title="On the Performance Analysis of RIS-Empowered Communications Over Nakagami-m Fading"></a>On the Performance Analysis of RIS-Empowered Communications Over Nakagami-m Fading</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11893">http://arxiv.org/abs/2309.11893</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dimitris Selimis, Kostas P. Peppas, George C. Alexandropoulos, Fotis I. Lazarakis</li>
<li>for: 研究了无线通信透过具备自适应智能面（RISs）的 nakagami-m 调频通道性能。</li>
<li>methods: 考虑了两种阶段配置设计 для RIS：一个随机的和另一个基于协调频率调整。</li>
<li>results: 显示了对 binary 调变方案的停机概率、错误率和均质质量的单纯积分表达，并提出了精确的关键数据表示。<details>
<summary>Abstract</summary>
In this paper, we study the performance of wireless communications empowered by Reconfigurable Intelligent Surface (RISs) over Nakagami-m fading channels. We consider two phase configuration designs for the RIS, one random and another one based on coherent phase shifting. For both phase configuration cases, we present single-integral expressions for the outage probability and the bit error rate of binary modulation schemes, which can be efficiently evaluated numerically. In addition, we propose accurate closed-form approximations for the ergodic capacity of the considered system. For all considered metrics, we have also derived simple analytical expressions that become tight for large numbers of RIS reflecting elements. Numerically evaluated results compared with Monte Carlo simulations are presented in order to verify the correctness of the proposed analysis and showcase the impact of various system settings.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了基于可 configurable智能表面（RIS）的无线通信系统在 nakagami-m 折射通道上的性能。我们考虑了两种阶段配置设计 для RIS，一个是随机的，另一个是基于 coherent 相位调制。对于两种阶段配置情况，我们提供了单一积分表达式，可以高效地评估 numerically。此外，我们提出了准确的闭式表达式，用于评估系统的平均容量。对所有考虑的指标，我们还 deriv了简单的分析表达式，这些表达式在大量 RIS 反射元件时变得紧张。我们通过与 Monte Carlo 仿真结果进行比较，以验证我们的分析的正确性，并显示了不同系统设置对系统性能的影响。
</details></li>
</ul>
<hr>
<h2 id="Near-Field-Beam-Training-Joint-Angle-and-Range-Estimation-with-DFT-Codebook"><a href="#Near-Field-Beam-Training-Joint-Angle-and-Range-Estimation-with-DFT-Codebook" class="headerlink" title="Near-Field Beam Training: Joint Angle and Range Estimation with DFT Codebook"></a>Near-Field Beam Training: Joint Angle and Range Estimation with DFT Codebook</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11872">http://arxiv.org/abs/2309.11872</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xun Wu, Changsheng You, Jiapeng Li, Yunpu Zhang</li>
<li>for: 提高near-field beam training的效率和准确性</li>
<li>methods: 使用DFT codebook进行off-grid范围估计，并提出了两种jointly估计用户角度和范围的方法</li>
<li>results: 经过numerical simulations表明，提议方法可以大幅降低near-field beam training的训练开销和提高范围估计精度，与various benchmark schemes相比有显著优势<details>
<summary>Abstract</summary>
Prior works on near-field beam training have mostly assumed dedicated polar-domain codebook and on-grid range estimation, which, however, may suffer long training overhead and degraded estimation accuracy. To address these issues, we propose in this paper new and efficient beam training schemes with off-grid range estimation by using conventional discrete Fourier transform (DFT) codebook. Specifically, we first analyze the received beam pattern at the user when far-field beamforming vectors are used for beam scanning, and show an interesting result that this beam pattern contains useful user angle and range information. Then, we propose two efficient schemes to jointly estimate the user angle and range with the DFT codebook. The first scheme estimates the user angle based on a defined angular support and resolves the user range by leveraging an approximated angular support width, while the second scheme estimates the user range by minimizing a power ratio mean square error (MSE) to improve the range estimation accuracy. Finally, numerical simulations show that our proposed schemes greatly reduce the near-field beam training overhead and improve the range estimation accuracy as compared to various benchmark schemes.
</details>
<details>
<summary>摘要</summary>
先前的远近场域训练研究多做出了专门的极域编码ebook和在网格上的距离估计，但这些方法可能会带来长时间的训练开销和估计精度下降。为了解决这些问题，本文提出了一些新的和高效的远近场域训练方案，使用常见的快速傅立叶变换（DFT）编码ebook。 Specifically, we first analyze the received beam pattern at the user when far-field beamforming vectors are used for beam scanning, and show an interesting result that this beam pattern contains useful user angle and range information. Then, we propose two efficient schemes to jointly estimate the user angle and range with the DFT codebook. The first scheme estimates the user angle based on a defined angular support and resolves the user range by leveraging an approximated angular support width, while the second scheme estimates the user range by minimizing a power ratio mean square error (MSE) to improve the range estimation accuracy. Finally, numerical simulations show that our proposed schemes greatly reduce the near-field beam training overhead and improve the range estimation accuracy as compared to various benchmark schemes.
</details></li>
</ul>
<hr>
<h2 id="Joint-Beamforming-for-RIS-Aided-Full-Duplex-Integrated-Sensing-and-Uplink-Communication"><a href="#Joint-Beamforming-for-RIS-Aided-Full-Duplex-Integrated-Sensing-and-Uplink-Communication" class="headerlink" title="Joint Beamforming for RIS Aided Full-Duplex Integrated Sensing and Uplink Communication"></a>Joint Beamforming for RIS Aided Full-Duplex Integrated Sensing and Uplink Communication</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11850">http://arxiv.org/abs/2309.11850</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuan Guo, Yang Liu, Qingqing Wu, Xin Zeng, Qingjiang Shi</li>
<li>For: This paper studies the integrated sensing and communication (ISAC) technology in a full-duplex (FD) uplink communication system, with the aim of improving the uninterrupted target sensing and reducing self-interference (SI).* Methods: The paper employs reconfigurable intelligent surface (RIS) technology to improve the SI suppression and signal processing gain, and develops an iterative solution using convex optimization techniques such as majorization-minimization (MM) and penalty-dual-decomposition (PDD) to optimize all variables.* Results: Numerical results demonstrate the effectiveness of the proposed solution and the great benefit of employing RIS in the FD ISAC system.<details>
<summary>Abstract</summary>
This paper studies integrated sensing and communication (ISAC) technology in a full-duplex (FD) uplink communication system. As opposed to the half-duplex system, where sensing is conducted in a first-emit-then-listen manner, FD ISAC system emits and listens simultaneously and hence conducts uninterrupted target sensing. Besides, impressed by the recently emerging reconfigurable intelligent surface (RIS) technology, we also employ RIS to improve the self-interference (SI) suppression and signal processing gain. As will be seen, the joint beamforming, RIS configuration and mobile users' power allocation is a difficult optimization problem. To resolve this challenge, via leveraging the cutting-the-edge majorization-minimization (MM) and penalty-dual-decomposition (PDD) methods, we develop an iterative solution that optimizes all variables via using convex optimization techniques. Numerical results demonstrate the effectiveness of our proposed solution and the great benefit of employing RIS in the FD ISAC system.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Semi-Supervised-Variational-Inference-over-Nonlinear-Channels"><a href="#Semi-Supervised-Variational-Inference-over-Nonlinear-Channels" class="headerlink" title="Semi-Supervised Variational Inference over Nonlinear Channels"></a>Semi-Supervised Variational Inference over Nonlinear Channels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11841">http://arxiv.org/abs/2309.11841</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Burshtein, Eli Bery</li>
<li>for: 这篇论文专门针对未知非线性通信 каналом进行深度学习方法的研究。</li>
<li>methods: 这篇论文使用了 semi-supervised learning 方法，包括 Monte Carlo expectation maximization 和 variational autoencoder，以解码未知非线性通信 канаnl。</li>
<li>results: 这些方法可以充分利用少量的试验符号和数据payload，并且在充分多的数据payload情况下，variational autoencoder 也可以实现更低的错误率，比 meta learning 使用当前和前一个传输块的试验符号。<details>
<summary>Abstract</summary>
Deep learning methods for communications over unknown nonlinear channels have attracted considerable interest recently. In this paper, we consider semi-supervised learning methods, which are based on variational inference, for decoding unknown nonlinear channels. These methods, which include Monte Carlo expectation maximization and a variational autoencoder, make efficient use of few pilot symbols and the payload data. The best semi-supervised learning results are achieved with a variational autoencoder. For sufficiently many payload symbols, the variational autoencoder also has lower error rate compared to meta learning that uses the pilot data of the present as well as previous transmission blocks.
</details>
<details>
<summary>摘要</summary>
深度学习方法在未知非线性通道上进行通信已经吸引了相当多的关注。在这篇论文中，我们考虑使用变量推理的半监督学习方法来解码未知非线性通道。这些方法包括Monte Carlo预期最大化和变量自适应器，它们可以充分利用几个示例符号和数据 payload。变量自适应器在具有足够多payload符号时实现最佳半监督学习结果，并且在使用当前和前一个传输块的Meta学习时也具有较低的错误率。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Study-of-PAPR-Reduction-Techniques-for-Deep-Joint-Source-Channel-Coding-in-OFDM-Systems"><a href="#A-Comprehensive-Study-of-PAPR-Reduction-Techniques-for-Deep-Joint-Source-Channel-Coding-in-OFDM-Systems" class="headerlink" title="A Comprehensive Study of PAPR Reduction Techniques for Deep Joint Source Channel Coding in OFDM Systems"></a>A Comprehensive Study of PAPR Reduction Techniques for Deep Joint Source Channel Coding in OFDM Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11803">http://arxiv.org/abs/2309.11803</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maolin Liu, Wei Chen, Jialong Xu, Bo Ai</li>
<li>for: 这篇论文主要针对的是深度联合源渠道编码（DJSCC）系统中的干扰率（PAPR）问题。</li>
<li>methods: 本论文使用了多种OFDM干扰率减少技术，包括传统技术such as clipping、companding、SLM和PTS，以及深度学习基于的PAPR减少技术such as PAPR损失和clipping with retraining。</li>
<li>results: 我们的调查发现，虽然传统的PAPR减少技术可以应用于DJSCC，但其性能与传统的分源渠道编码不同。此外，我们发现，对信号损害PAPR减少技术，clipping with retraining可以在DJSCC中实现最好的性能，并且不会对信号重建率产生负面影响。同时，对信号非损害PAPR减少技术可以成功地减少DJSCC中的PAPR，不会影响信号重建率。<details>
<summary>Abstract</summary>
Recently, deep joint source channel coding (DJSCC) techniques have been extensively studied and have shown significant performance with limited bandwidth and low signal to noise ratio. Most DJSCC work considers discrete-time analog transmission, while combining it with orthogonal frequency division multiplexing (OFDM) creates serious high peak-to-average power ratio (PAPR) problem. This paper conducts a comprehensive analysis on the use of various OFDM PAPR reduction techniques in the DJSCC system, including both conventional techniques such as clipping, companding, SLM and PTS, and deep learning-based PAPR reduction techniques such as PAPR loss and clipping with retraining. Our investigation shows that although conventional PAPR reduction techniques can be applied to DJSCC, their performance in DJSCC is different from the conventional split source channel coding. Moreover, we observe that for signal distortion PAPR reduction techniques, clipping with retraining achieves the best performance in terms of both PAPR reduction and recovery accuracy. It is also noticed that signal non-distortion PAPR reduction techniques can successfully reduce the PAPR in DJSCC without compromise to signal reconstruction.
</details>
<details>
<summary>摘要</summary>
近来，深度联合源渠道编码（DJSCC）技术已经得到了广泛研究和应用，它可以在具有有限带宽和低信噪比的情况下显示出较高的性能。大多数DJSCC工作都是对离散时间分析传输进行研究，而将OFDM分配多谱分多层（PAPR）问题引入到DJSCC系统中会产生严重的高峰值至平均功率比（PAPR）问题。本文对DJSCC系统中OFDM PAPR减少技术的使用进行了全面的分析，包括传统技术such as clipping、companding、SLM和PTS，以及深度学习基于PAPR减少技术such as PAPR损失和clipping with retraining。我们的调查表明，虽然传统PAPR减少技术可以应用于DJSCC，但它们在DJSCC中的性能与传统分Split source channel coding不同。此外，我们发现在信号损害PAPR减少技术中，clipping with retraining可以在PAPR减少和重建精度方面达到最佳性能。此外，我们还发现了在非损信号PAPR减少技术中，可以成功地减少DJSCC中的PAPR，而无需牺牲信号重建精度。
</details></li>
</ul>
<hr>
<h2 id="Quantum-Circuits-for-Stabilizer-Error-Correcting-Codes-A-Tutorial"><a href="#Quantum-Circuits-for-Stabilizer-Error-Correcting-Codes-A-Tutorial" class="headerlink" title="Quantum Circuits for Stabilizer Error Correcting Codes: A Tutorial"></a>Quantum Circuits for Stabilizer Error Correcting Codes: A Tutorial</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11793">http://arxiv.org/abs/2309.11793</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arijit Mondal, Keshab K. Parhi</li>
<li>for: 这篇论文主要是为了介绍设计和模拟量子编码器和解码器电路，以及验证这些电路的正确性。</li>
<li>methods: 这篇论文使用了量子编码和解码的方法，并提供了五个量子比特的编码和解码电路，以及适用于五个量子比特的最近邻居兼容的编码和解码电路。</li>
<li>results: 论文验证了这些电路的正确性，并提供了使用IBM Qiskit进行验证的方法。<details>
<summary>Abstract</summary>
Quantum computers have the potential to provide exponential speedups over their classical counterparts. Quantum principles are being applied to fields such as communications, information processing, and artificial intelligence to achieve quantum advantage. However, quantum bits are extremely noisy and prone to decoherence. Thus, keeping the qubits error free is extremely important toward reliable quantum computing. Quantum error correcting codes have been studied for several decades and methods have been proposed to import classical error correcting codes to the quantum domain. However, circuits for such encoders and decoders haven't been explored in depth. This paper serves as a tutorial on designing and simulating quantum encoder and decoder circuits for stabilizer codes. We present encoding and decoding circuits for five-qubit code and Steane code, along with verification of these circuits using IBM Qiskit. We also provide nearest neighbour compliant encoder and decoder circuits for the five-qubit code.
</details>
<details>
<summary>摘要</summary>
量子计算机有可能提供指数增速于其经典对手。量子原理在通信、信息处理和人工智能等领域应用以实现量子优势。然而，量子比特非常易受噪声和降解的影响。因此，保持量子比特错误自由非常重要于可靠的量子计算。量子错误修复代码已经在几十年内研究，并提出了将经典错误修复代码引入量子领域的方法。然而，这些圈定器和解码器电路的设计和仿真还没有得到深入研究。这篇论文作为量子编码和解码电路设计和仿真的教程，我们提出了五个量子比特编码和斯特恩代码的编码和解码电路，并使用IBM Qiskit进行验证。此外，我们还提供了最近邻居兼容的编码和解码电路 для五个量子比特编码。
</details></li>
</ul>
<hr>
<h2 id="Collaborative-Fault-Identification-Reconstruction-in-Multi-Agent-Systems"><a href="#Collaborative-Fault-Identification-Reconstruction-in-Multi-Agent-Systems" class="headerlink" title="Collaborative Fault-Identification &amp; Reconstruction in Multi-Agent Systems"></a>Collaborative Fault-Identification &amp; Reconstruction in Multi-Agent Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11784">http://arxiv.org/abs/2309.11784</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiraz Khan, Inseok Hwang</li>
<li>for: 提供了一种高效的分布式FDIR机制，适用于多 Agent 应用。</li>
<li>methods: 基于sequential convex programming (SCP) 和 alternating direction method of multipliers (ADMM) 优化方法，实现分布式多 Agent FDIR算法。</li>
<li>results: 可以处理多 Agent 间测量（包括距离、方向、相对速度和夹角），确定faulty Agent 和重建其真实状态。<details>
<summary>Abstract</summary>
The conventional solutions for fault-detection, identification, and reconstruction (FDIR) require centralized decision-making mechanisms which are typically combinatorial in their nature, necessitating the design of an efficient distributed FDIR mechanism that is suitable for multi-agent applications. To this end, we develop a general framework for efficiently reconstructing a sparse vector being observed over a sensor network via nonlinear measurements. The proposed framework is used to design a distributed multi-agent FDIR algorithm based on a combination of the sequential convex programming (SCP) and the alternating direction method of multipliers (ADMM) optimization approaches. The proposed distributed FDIR algorithm can process a variety of inter-agent measurements (including distances, bearings, relative velocities, and subtended angles between agents) to identify the faulty agents and recover their true states. The effectiveness of the proposed distributed multi-agent FDIR approach is demonstrated by considering a numerical example in which the inter-agent distances are used to identify the faulty agents in a multi-agent configuration, as well as reconstruct their error vectors.
</details>
<details>
<summary>摘要</summary>
传统的瑕点检测、识别和重建（FDIR）解决方案通常需要中央决策机制，这些机制通常是 combinatorial 的性质，需要设计一种高效的分布式 FDIR 机制，适用于多机器人应用。为此，我们开发了一种高效地重建 sparse vector 在感知网络上被观察的框架。该框架基于 sequential convex programming (SCP) 和 alternating direction method of multipliers (ADMM) 优化方法来设计分布式多机器人 FDIR 算法。该算法可以处理多机器人之间的各种测量数据（包括距离、方向、相对速度和 agents 之间的夹角）来识别瑕点机器人并重建其真实状态。我们通过一个数学示例来证明提出的分布式多机器人 FDIR 方法的效果，在这个示例中，利用了机器人之间的距离测量来识别瑕点机器人和重建其错误向量。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-the-SEFDM-Performance-in-High-Doppler-Channels"><a href="#Enhancing-the-SEFDM-Performance-in-High-Doppler-Channels" class="headerlink" title="Enhancing the SEFDM Performance in High-Doppler Channels"></a>Enhancing the SEFDM Performance in High-Doppler Channels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11774">http://arxiv.org/abs/2309.11774</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahdi Shamsi, Farokh Marvasti</li>
<li>for: 该研究旨在提出一种基于 Spectrally Efficient Frequency Division Multiplexing (SEFDM) 技术的高效处理移动通信频率延迟和Doppler偏移的方法，并采用 Frequency Domain Cyclic Prefix (FDCP) 和 Modified Non-Linear (MNL) 加速技术。</li>
<li>methods: 该研究使用了 SEFDM 技术，并采用了 FDCP 和 MNL 加速技术来处理移动通信频率延迟和Doppler偏移的影响。</li>
<li>results: 该研究发现，使用 SEFDM 技术可以在移动通信频率延迟和Doppler偏移的环境中实现可靠和高质量的通信，并且可以保持传统通信系统的 spectral efficiency。<details>
<summary>Abstract</summary>
In this paper, we propose the use of Spectrally Efficient Frequency Division Multiplexing (SEFDM) with additional techniques such as Frequency Domain Cyclic Prefix (FDCP) and Modified Non-Linear (MNL) acceleration for efficient handling of the impact of delay and Doppler shift in mobile communication channels. Our approach exhibits superior performance and spectral efficiency in comparison to traditional communication systems, while maintaining low computational cost. We study a model of the SEFDM communication system and investigate the impact of MNL acceleration with soft and hard decision Inverse System on the performance of SEFDM detection in the AWGN channel. We also analyze the effectiveness of FDCP in compensating for the impact of Doppler shift, and report BER detection figures using Regularized Sphere Decoding in various simulation scenarios. Our simulations demonstrate that it is possible to achieve acceptable performance in Doppler channels while maintaining the superiority of SEFDM over OFDM in terms of spectral efficiency. The results suggest that our proposed approach can tackle the effects of delay and Doppler shift in mobile communication networks, guaranteeing dependable and high-quality communication even in extremely challenging environments.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提议使用具有频率分配多普雷斯特（SEFDM）的spectrally efficient frequency division multiplexing技术，并采用频域循环 prefix（FDCP）和修改非线性（MNL）加速技术来有效地处理移动通信频道中的延迟和Doppler偏移的影响。我们的方法在比较 tradicional communication systems的情况下表现出较高的性能和频率效率，同时保持低的计算成本。我们研究了SEFDM通信系统的模型，并investigate MNL加速器在SOFT和HARD decision inverse system中的影响。我们还分析了FDCP在补做Doppler偏移的效果，并report了在不同的 simulate scenario中的BER检测数据。我们的Simulations表明，可以在Doppler频道中实现可接受的性能，同时保持SEFDM在OFDM方面的优势。结果表明，我们提议的方法可以在移动通信网络中抵御延迟和Doppler偏移的影响，保证高质量和可靠的通信，even in extremely challenging environments。
</details></li>
</ul>
<hr>
<h2 id="Symbol-Detection-for-Coarsely-Quantized-OTFS"><a href="#Symbol-Detection-for-Coarsely-Quantized-OTFS" class="headerlink" title="Symbol Detection for Coarsely Quantized OTFS"></a>Symbol Detection for Coarsely Quantized OTFS</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11759">http://arxiv.org/abs/2309.11759</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junwei He, Haochuan Zhang, Chao Dong, Huimin Zhu</li>
<li>for: 这篇论文专门针对受限制的量化 Communication system 中的orthogonal time frequency space (OTFS) 技术，以实现成本和功率的最优化。</li>
<li>methods: 论文使用了coarse quantization 和 signal recovery 算法，包括原始的approximate message passing (AMP) 和 generalized expectation consistent for signal recovery (GEC-SR)。</li>
<li>results: 论文提出了一种低复杂度的算法，即将 GEC-SR 算法与快速归一化的 quasi-banded matrices 结合，从而降低了计算复杂度从立方体积到线性积，保持了性能水平。<details>
<summary>Abstract</summary>
This paper explicitly models a coarse and noisy quantization in a communication system empowered by orthogonal time frequency space (OTFS) for cost and power efficiency. We first point out, with coarse quantization, the effective channel is imbalanced and thus no longer able to circularly shift the transmitted symbols along the delay-Doppler domain. Meanwhile, the effective channel is non-isotropic, which imposes a significant loss to symbol detection algorithms like the original approximate message passing (AMP). Although the algorithm of generalized expectation consistent for signal recovery (GEC-SR) can mitigate this loss, the complexity in computation is prohibitively high, mainly due to an dramatic increase in the matrix size of OTFS. In this context, we propose a low-complexity algorithm that incorporates into the GEC-SR a quick inversion of quasi-banded matrices, reducing the complexity from a cubic order to a linear order while keeping the performance at the same level.
</details>
<details>
<summary>摘要</summary>
In the system, the effective channel is imbalanced and non-isotropic due to coarse quantization, which leads to a significant loss in symbol detection algorithms such as the original approximate message passing (AMP). The GEC-SR algorithm can mitigate this loss, but the high computational complexity prohibits its use. The proposed algorithm addresses this issue by reducing the computational complexity while maintaining the performance.The key idea of the proposed algorithm is to incorporate a quick inversion of quasi-banded matrices into the GEC-SR method. This allows for a significant reduction in computational complexity, from a cubic order to a linear order, while maintaining the same performance. The proposed algorithm is designed to address the issues of coarse and noisy quantization in OTFS-based communication systems, and it has important implications for cost and power efficiency.
</details></li>
</ul>
<hr>
<h2 id="Systematic-Design-and-Optimization-of-Quantum-Circuits-for-Stabilizer-Codes"><a href="#Systematic-Design-and-Optimization-of-Quantum-Circuits-for-Stabilizer-Codes" class="headerlink" title="Systematic Design and Optimization of Quantum Circuits for Stabilizer Codes"></a>Systematic Design and Optimization of Quantum Circuits for Stabilizer Codes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.12373">http://arxiv.org/abs/2309.12373</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arijit Mondal, Keshab K. Parhi</li>
<li>for: 这篇论文的目的是构建一种系统的扩展Builder的扩展Builder，以实现稳定的量子计算。</li>
<li>methods: 本文使用了一种形式化的算法，以系统地构建扩展Builder，并且提出了一种系统的优化方法，以降低扩展Builder的门数。</li>
<li>results: 本文通过使用IBM Qiskit进行验证，提出了一种优化的八个量子比特（qubit）编码器，其中使用了18个CNOT门和4个 Hadamard门，相比之下，在先前的工作中只用了14个单量子门、33个二量子门和6个CCNOT门。此外，本文还提出了优化的斯坦内码编码器和13个量子比特编码器，以降低门数。<details>
<summary>Abstract</summary>
Quantum computing is an emerging technology that has the potential to achieve exponential speedups over their classical counterparts. To achieve quantum advantage, quantum principles are being applied to fields such as communications, information processing, and artificial intelligence. However, quantum computers face a fundamental issue since quantum bits are extremely noisy and prone to decoherence. Keeping qubits error free is one of the most important steps towards reliable quantum computing. Different stabilizer codes for quantum error correction have been proposed in past decades and several methods have been proposed to import classical error correcting codes to the quantum domain. However, formal approaches towards the design and optimization of circuits for these quantum encoders and decoders have so far not been proposed. In this paper, we propose a formal algorithm for systematic construction of encoding circuits for general stabilizer codes. This algorithm is used to design encoding and decoding circuits for an eight-qubit code. Next, we propose a systematic method for the optimization of the encoder circuit thus designed. Using the proposed method, we optimize the encoding circuit in terms of the number of 2-qubit gates used. The proposed optimized eight-qubit encoder uses 18 CNOT gates and 4 Hadamard gates, as compared to 14 single qubit gates, 33 2-qubit gates, and 6 CCNOT gates in a prior work. The encoder and decoder circuits are verified using IBM Qiskit. We also present optimized encoder circuits for Steane code and a 13-qubit code in terms of the number of gates used.
</details>
<details>
<summary>摘要</summary>
量子计算是一种emerging技术，它可以实现对于类传统计算机的快速增长。为了实现量子优势，量子原理被应用到通信、信息处理和人工智能等领域。然而，量子计算机面临一个fundamental问题，那就是量子比特（qubits）具有极高的噪声和失去稳定性。保持qubits错误自由是量子计算的重要步骤。过去几十年，有多种稳定码为量子错误 corrections proposed，但 formal方法 towards the design and optimization of circuits for these quantum encoders and decoders have not been proposed.在这篇论文中，我们提出了一种系统的建构方法 для普通的稳定码编码电路。这种方法用于设计编码和解码电路 для八个量子比特的代码。然后，我们提出了一种系统的优化方法，用于优化所设计的编码电路。使用这种方法，我们优化了编码电路，使其使用的两个量子比特门的数量减少为18个CNOT门和4个 Hadamard门，与之前的14个单量子比特门、33个二量子比特门和6个CCNOT门相比。我们使用IBM Qiskit验证了编码和解码电路。此外，我们还提出了优化后的八个量子比特编码电路、Steane代码和13个量子比特代码的优化结果。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Meets-Swarm-Intelligence-for-UAV-Assisted-IoT-Coverage-in-Massive-MIMO"><a href="#Deep-Learning-Meets-Swarm-Intelligence-for-UAV-Assisted-IoT-Coverage-in-Massive-MIMO" class="headerlink" title="Deep Learning Meets Swarm Intelligence for UAV-Assisted IoT Coverage in Massive MIMO"></a>Deep Learning Meets Swarm Intelligence for UAV-Assisted IoT Coverage in Massive MIMO</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11748">http://arxiv.org/abs/2309.11748</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mobeen Mahmood, MohammadMahdi Ghadaksaz, Asil Koc, Tho Le-Ngoc</li>
<li>for: This study is written for UAV-assisted multi-user massive multiple-input multiple-output (MU-mMIMO) systems, specifically for Internet-of-Things (IoT) users.</li>
<li>methods: The study uses a joint optimization problem of hybrid beamforming (HBF), UAV relay positioning, and power allocation (PA) to maximize the total achievable rate (AR) for multiple IoT users. The study also adopts a geometry-based millimeter-wave (mmWave) channel model for both links and proposes three different swarm intelligence (SI)-based algorithmic solutions to optimize.</li>
<li>results: The study shows that the proposed algorithmic solutions can attain higher capacity and reduce average delay for delay-constrained transmissions in a UAV-assisted MU-mMIMO IoT systems. Additionally, the proposed J-HBF-DLLPA can closely approach the optimal capacity while significantly reducing the runtime by 99%, which makes the DL-based solution a promising implementation for real-time online applications in UAV-assisted MU-mMIMO IoT systems.Here is the result in Simplified Chinese text:</li>
<li>for: 这个研究是为了UAV协助多用户大规模多输入多输出（MU-mMIMO）系统，特别是互联网物联网（IoT）用户。</li>
<li>methods: 这个研究使用了一个共同优化问题，包括Hybrid beamforming（HBF）、UAV relay位置决定和功率分配（PA），以最大化多个IoT用户的总可实现率（AR）。研究还采用了一个基于几何学的毫米波（mmWave）通道模型，并提出了三种不同的群智能算法解决方案。</li>
<li>results: 研究表明，提出的算法解决方案可以在UAV协助MU-mMIMO IoT系统中实现更高的容量和减少延迟。此外，提出的J-HBF-DLLPA可以准确地预测UAV的位置和优化的功率值，以实现最大化AR。<details>
<summary>Abstract</summary>
This study considers a UAV-assisted multi-user massive multiple-input multiple-output (MU-mMIMO) systems, where a decode-and-forward (DF) relay in the form of an unmanned aerial vehicle (UAV) facilitates the transmission of multiple data streams from a base station (BS) to multiple Internet-of-Things (IoT) users. A joint optimization problem of hybrid beamforming (HBF), UAV relay positioning, and power allocation (PA) to multiple IoT users to maximize the total achievable rate (AR) is investigated. The study adopts a geometry-based millimeter-wave (mmWave) channel model for both links and proposes three different swarm intelligence (SI)-based algorithmic solutions to optimize: 1) UAV location with equal PA; 2) PA with fixed UAV location; and 3) joint PA with UAV deployment. The radio frequency (RF) stages are designed to reduce the number of RF chains based on the slow time-varying angular information, while the baseband (BB) stages are designed using the reduced-dimension effective channel matrices. Then, a novel deep learning (DL)-based low-complexity joint hybrid beamforming, UAV location and power allocation optimization scheme (J-HBF-DLLPA) is proposed via fully-connected deep neural network (DNN), consisting of an offline training phase, and an online prediction of UAV location and optimal power values for maximizing the AR. The illustrative results show that the proposed algorithmic solutions can attain higher capacity and reduce average delay for delay-constrained transmissions in a UAV-assisted MU-mMIMO IoT systems. Additionally, the proposed J-HBF-DLLPA can closely approach the optimal capacity while significantly reducing the runtime by 99%, which makes the DL-based solution a promising implementation for real-time online applications in UAV-assisted MU-mMIMO IoT systems.
</details>
<details>
<summary>摘要</summary>
To solve this optimization problem, the study proposes three different swarm intelligence (SI)-based algorithmic solutions:1. UAV location with equal PA2. PA with fixed UAV location3. Joint PA with UAV deploymentThe radio frequency (RF) stages are designed to reduce the number of RF chains based on slow time-varying angular information, while the baseband (BB) stages are designed using reduced-dimension effective channel matrices.Furthermore, a novel deep learning (DL)-based low-complexity joint hybrid beamforming, UAV location, and power allocation optimization scheme (J-HBF-DLLPA) is proposed. This scheme consists of an offline training phase and an online prediction of UAV location and optimal power values to maximize AR.The illustrative results show that the proposed algorithmic solutions can achieve higher capacity and reduce average delay for delay-constrained transmissions in a UAV-assisted MU-mMIMO IoT system. Additionally, the proposed J-HBF-DLLPA can closely approach the optimal capacity while significantly reducing the runtime by 99%, making it a promising implementation for real-time online applications in UAV-assisted MU-mMIMO IoT systems.
</details></li>
</ul>
<hr>
<h2 id="Resource-Allocation-for-Semantic-Aware-Mobile-Edge-Computing-Systems"><a href="#Resource-Allocation-for-Semantic-Aware-Mobile-Edge-Computing-Systems" class="headerlink" title="Resource Allocation for Semantic-Aware Mobile Edge Computing Systems"></a>Resource Allocation for Semantic-Aware Mobile Edge Computing Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11736">http://arxiv.org/abs/2309.11736</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yihan Cang, Ming Chen, Zhaohui Yang, Yuntao Hu, Yinlu Wang, Zhaoyang Zhang, Kai-Kit Wong</li>
<li>for: 这个论文是为了提出一种基于移动边缘计算（MEC）系统的语义意识感知通信和计算资源分配框架。</li>
<li>methods: 该论文使用了语义感知技术来减少传输负担，每个终端设备（TD）将小型EXTRACTED semantic information发送到服务器，而不是大量的原始数据。一个优化问题的 JOINT semantic-aware分配因子、通信和计算资源管理问题是形ulated，目标是最小化所有TD的执行延迟，同时满足能量消耗限制。</li>
<li>results: 通过对非对称的原始问题进行几何编程变换，并使用交互优化算法解决，得到了最优解。此外，closed-form的语义提取因子的优化解也是 derive。对比 benchmark algorithm without semantic-aware allocation，提出的算法可以减少最大执行延迟达37.10%。同时，在大任务大小和Poor channel condition下，小语义提取因子被首选。<details>
<summary>Abstract</summary>
In this paper, a semantic-aware joint communication and computation resource allocation framework is proposed for mobile edge computing (MEC) systems. In the considered system, each terminal device (TD) has a computation task, which needs to be executed by offloading to the MEC server. To further decrease the transmission burden, each TD sends the small-size extracted semantic information of tasks to the server instead of the large-size raw data. An optimization problem of joint semantic-aware division factor, communication and computation resource management is formulated. The problem aims to minimize the maximum execution delay of all TDs while satisfying energy consumption constraints. The original non-convex problem is transformed into a convex one based on the geometric programming and the optimal solution is obtained by the alternating optimization algorithm. Moreover, the closed-form optimal solution of the semantic extraction factor is derived. Simulation results show that the proposed algorithm yields up to 37.10% delay reduction compared with the benchmark algorithm without semantic-aware allocation. Furthermore, small semantic extraction factors are preferred in the case of large task sizes and poor channel conditions.
</details>
<details>
<summary>摘要</summary>
在本文中，一种基于 semantics 的集成通信和计算资源分配框架被提出用于移动边缘计算（MEC）系统。系统中每个终端设备（TD）都有一个计算任务，需要通过卸载到 MEC 服务器进行执行。为了进一步减少传输负担，每个 TD 将小型的抽取 semantic 信息发送到服务器，而不是大量的原始数据。一个协调semantic-aware分配因子、通信和计算资源管理的优化问题被形ulated。该问题的目标是 minimize 所有 TD 的执行延迟最大值，同时满足能量消耗限制。原始的非泛合函数问题被转化为一个卷积函数问题，并通过卷积编程得到了优化解决方案。此外，closed-form 优化解决方案的 semantic 抽取因子也被 derivation。 simulation 结果表明，提出的算法可以减少最多 37.10% 的延迟，相比 Without semantic-aware 分配算法。此外，小的 semantic 抽取因子在大任务大小和差annels 条件下被首选。
</details></li>
</ul>
<hr>
<h2 id="A-class-weighted-supervised-contrastive-learning-long-tailed-bearing-fault-diagnosis-approach-using-quadratic-neural-network"><a href="#A-class-weighted-supervised-contrastive-learning-long-tailed-bearing-fault-diagnosis-approach-using-quadratic-neural-network" class="headerlink" title="A class-weighted supervised contrastive learning long-tailed bearing fault diagnosis approach using quadratic neural network"></a>A class-weighted supervised contrastive learning long-tailed bearing fault diagnosis approach using quadratic neural network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2309.11717">http://arxiv.org/abs/2309.11717</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuweien1120/CCQNet">https://github.com/yuweien1120/CCQNet</a></li>
<li>paper_authors: Wei-En Yu, Jinwei Sun, Shiping Zhang, Xiaoge Zhang, Jing-Xiao Liao<br>for: 这个论文旨在提高深度学习方法对故障诊断中的表现，特别是在面临高度不均衡或长尾数据时。methods: 该论文提出了一种监督对比学习方法，使用类 weights 对决策函数进行调整，从而提高神经网络对故障诊断的特征提取能力。results: 实验结果表明，与 State-of-the-Art 方法相比，CCQNet 在面临高度不均衡或长尾数据时表现明显更好，可以更好地识别故障。<details>
<summary>Abstract</summary>
Deep learning has achieved remarkable success in bearing fault diagnosis. However, its performance oftentimes deteriorates when dealing with highly imbalanced or long-tailed data, while such cases are prevalent in industrial settings because fault is a rare event that occurs with an extremely low probability. Conventional data augmentation methods face fundamental limitations due to the scarcity of samples pertaining to the minority class. In this paper, we propose a supervised contrastive learning approach with a class-aware loss function to enhance the feature extraction capability of neural networks for fault diagnosis. The developed class-weighted contrastive learning quadratic network (CCQNet) consists of a quadratic convolutional residual network backbone, a contrastive learning branch utilizing a class-weighted contrastive loss, and a classifier branch employing logit-adjusted cross-entropy loss. By utilizing class-weighted contrastive loss and logit-adjusted cross-entropy loss, our approach encourages equidistant representation of class features, thereby inducing equal attention on all the classes. We further analyze the superior feature extraction ability of quadratic network by establishing the connection between quadratic neurons and autocorrelation in signal processing. Experimental results on public and proprietary datasets are used to validate the effectiveness of CCQNet, and computational results reveal that CCQNet outperforms SOTA methods in handling extremely imbalanced data substantially.
</details>
<details>
<summary>摘要</summary>
深度学习在滤波器疾病诊断中实现了很大的成功。然而，它在面临高度不均衡或长尾数据时表现不佳，这些情况在工业场景中却很普遍，因为疾病是一种非常罕见的事件，发生概率非常低。传统的数据扩展方法受到罕见类样本的缺乏的限制。在这篇论文中，我们提出了一种Supervised Contrastive Learning方法，使得神经网络在疾病诊断中提高特征提取能力。我们的方法包括一个quadratic convolutional residual network底层、一个使用类Weighted Contrastive Loss的对比学分支、以及一个使用Logit-adjusted Cross-Entropy Loss的分类分支。通过使用类Weighted Contrastive Loss和Logit-adjusted Cross-Entropy Loss，我们的方法促进了类别特征之间的等距耦合，从而使神经网络对所有类型的特征具有平等的注意力。我们还分析了quadratic neuron的特点，并将其与自相关函数的应用相连接，以证明quadratic neuron在信号处理中的优势。实验结果表明，CCQNet在面临高度不均衡数据时表现出了显著的优势，与SOTA方法相比，CCQNet在执行滤波器疾病诊断方面具有显著的改进。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/09/21/eess.SP_2023_09_21/" data-id="cloqtaf2d01aigh88e9ur2k46" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/34/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/33/">33</a><a class="page-number" href="/page/34/">34</a><span class="page-number current">35</span><a class="page-number" href="/page/36/">36</a><a class="page-number" href="/page/37/">37</a><span class="space">&hellip;</span><a class="page-number" href="/page/88/">88</a><a class="extend next" rel="next" href="/page/36/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">120</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">59</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">117</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">68</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">50</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
