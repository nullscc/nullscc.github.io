
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/66/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.SD_2023_08_04" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/04/cs.SD_2023_08_04/" class="article-date">
  <time datetime="2023-08-04T15:00:00.000Z" itemprop="datePublished">2023-08-04</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/04/cs.SD_2023_08_04/">cs.SD - 2023-08-04</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Efficient-Monaural-Speech-Enhancement-using-Spectrum-Attention-Fusion"><a href="#Efficient-Monaural-Speech-Enhancement-using-Spectrum-Attention-Fusion" class="headerlink" title="Efficient Monaural Speech Enhancement using Spectrum Attention Fusion"></a>Efficient Monaural Speech Enhancement using Spectrum Attention Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02263">http://arxiv.org/abs/2308.02263</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinyu Long, Jetic Gū, Binhao Bai, Zhibo Yang, Ping Wei, Junli Li</li>
<li>for: 提高自动speech处理管道中的干声提取精度，使用Transformer模型，但是这些模型具有较高的计算成本和训练数据需求。</li>
<li>methods: 提出一种名为spectrum attention fusion的改进方法，通过重新构造一个卷积模块来取代自我注意层，以更有效地融合频谱特征。</li>
<li>results: 对于Voice Bank + DEMAND数据集，提出的模型可以与状态体现相当或更好的结果，但具有较小的参数量（0.58M）。<details>
<summary>Abstract</summary>
Speech enhancement is a demanding task in automated speech processing pipelines, focusing on separating clean speech from noisy channels. Transformer based models have recently bested RNN and CNN models in speech enhancement, however at the same time they are much more computationally expensive and require much more high quality training data, which is always hard to come by. In this paper, we present an improvement for speech enhancement models that maintains the expressiveness of self-attention while significantly reducing model complexity, which we have termed Spectrum Attention Fusion. We carefully construct a convolutional module to replace several self-attention layers in a speech Transformer, allowing the model to more efficiently fuse spectral features. Our proposed model is able to achieve comparable or better results against SOTA models but with significantly smaller parameters (0.58M) on the Voice Bank + DEMAND dataset.
</details>
<details>
<summary>摘要</summary>
干扰除是自动语音处理管道中的一项具有挑战性的任务，旨在分离干扰 Channel 中的清晰语音。基于 Transformer 的模型在最近的一段时间内对语音干扰 Task 表现出色，但同时它们也比 RNN 和 CNN 模型更加 computationally expensive 并且需要更多的高质量训练数据，这些数据总是困难找到。在这篇论文中，我们提出一种改进语音干扰模型，保持自我注意力的表达力，同时减少模型的复杂度，我们称之为 Spectrum Attention Fusion。我们精心构建了一个 convolutional 模块，以取代一些 speech Transformer 中的自我注意层，使模型更好地融合 спектраль特征。我们提出的模型可以在 Voice Bank + DEMAND 数据集上达到与 SOTA 模型相同或更好的result，但具有远小于 SOTA 模型的参数（0.58M）。
</details></li>
</ul>
<hr>
<h2 id="Emo-DNA-Emotion-Decoupling-and-Alignment-Learning-for-Cross-Corpus-Speech-Emotion-Recognition"><a href="#Emo-DNA-Emotion-Decoupling-and-Alignment-Learning-for-Cross-Corpus-Speech-Emotion-Recognition" class="headerlink" title="Emo-DNA: Emotion Decoupling and Alignment Learning for Cross-Corpus Speech Emotion Recognition"></a>Emo-DNA: Emotion Decoupling and Alignment Learning for Cross-Corpus Speech Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02190">http://arxiv.org/abs/2308.02190</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiaxin-ye/emo-dna">https://github.com/jiaxin-ye/emo-dna</a></li>
<li>paper_authors: Jiaxin Ye, Yujie Wei, Xin-Cheng Wen, Chenglong Ma, Zhizhong Huang, Kunhong Liu, Hongming Shan</li>
<li>for: 这个研究目的是为了实现跨 corps speech emotion识别（SER），即将一个已有 Label的 corpus 中的感情识别能力扩展到一个无 Label 的 corpus 中。</li>
<li>methods: 这个研究提出了一个名为 Emotion Decoupling aNd Alignment 的新框架（EMO-DNA），它是一种基于适应领域调整（UDA）的新方法，可以学习感情相关的 corpus-invariant 特征。EMO-DNA 的两大特点是：一是对于感情的分离学习，二是两个层次的感情Alignment。</li>
<li>results: 实验结果显示，EMO-DNA 比前一代方法在跨 corps 的数个情况下表现出色，具有更高的准确率和更好的一致性。<details>
<summary>Abstract</summary>
Cross-corpus speech emotion recognition (SER) seeks to generalize the ability of inferring speech emotion from a well-labeled corpus to an unlabeled one, which is a rather challenging task due to the significant discrepancy between two corpora. Existing methods, typically based on unsupervised domain adaptation (UDA), struggle to learn corpus-invariant features by global distribution alignment, but unfortunately, the resulting features are mixed with corpus-specific features or not class-discriminative. To tackle these challenges, we propose a novel Emotion Decoupling aNd Alignment learning framework (EMO-DNA) for cross-corpus SER, a novel UDA method to learn emotion-relevant corpus-invariant features. The novelties of EMO-DNA are two-fold: contrastive emotion decoupling and dual-level emotion alignment. On one hand, our contrastive emotion decoupling achieves decoupling learning via a contrastive decoupling loss to strengthen the separability of emotion-relevant features from corpus-specific ones. On the other hand, our dual-level emotion alignment introduces an adaptive threshold pseudo-labeling to select confident target samples for class-level alignment, and performs corpus-level alignment to jointly guide model for learning class-discriminative corpus-invariant features across corpora. Extensive experimental results demonstrate the superior performance of EMO-DNA over the state-of-the-art methods in several cross-corpus scenarios. Source code is available at https://github.com/Jiaxin-Ye/Emo-DNA.
</details>
<details>
<summary>摘要</summary>
cross-corpus speech emotion recognition (SER) 目标是将一个受过标注的语料库中的情绪推断到另一个没有标注的语料库中，这是一项非常具有挑战性的任务，因为两个语料库之间存在很大的差异。现有的方法通常基于不监督领域适应（UDA），尝试通过全局分布对齐来学习语料库共同的特征，但是却不幸的是，得到的特征往往与语料库特定的特征或不是类别特征杂合。为了解决这些挑战，我们提出了一个新的情绪解决和对齐学习框架（EMO-DNA） для cross-corpus SER，一种新的UDA方法来学习情绪相关的语料库共同特征。EMO-DNA的两个新特点是：对比性情绪解决和双级情绪对齐。一方面，我们的对比性情绪解决通过对比减除损失来强化情绪相关特征与语料库特定特征之间的分离性。另一方面，我们的双级情绪对齐引入了一个自适应阈值 pseudo-标签法，选择对模型有信任度的目标样本进行类别对齐，并在语料库级别对齐以同步导向模型学习类别特征杂合的语料库共同特征。我们的实验结果表明，EMO-DNA在多个 cross-corpus 场景中表现出了与当前状态方法相比的显著性能优势。源代码可以在 <https://github.com/Jiaxin-Ye/Emo-DNA> 中下载。
</details></li>
</ul>
<hr>
<h2 id="Capturing-Spectral-and-Long-term-Contextual-Information-for-Speech-Emotion-Recognition-Using-Deep-Learning-Techniques"><a href="#Capturing-Spectral-and-Long-term-Contextual-Information-for-Speech-Emotion-Recognition-Using-Deep-Learning-Techniques" class="headerlink" title="Capturing Spectral and Long-term Contextual Information for Speech Emotion Recognition Using Deep Learning Techniques"></a>Capturing Spectral and Long-term Contextual Information for Speech Emotion Recognition Using Deep Learning Techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04517">http://arxiv.org/abs/2308.04517</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samiul Islam, Md. Maksudul Haque, Abu Jobayer Md. Sadat</li>
<li>for: 本研究旨在超越传统方法，提高speech emotion recognition的准确率。</li>
<li>methods: 本研究提出了一种ensemble模型，结合文本数据的Graph Convolutional Networks（GCN）和audio信号的HuBERT transformer进行分析。</li>
<li>results: 结果表明，GCNs可以很好地捕捉文本数据中的长期上下文关系和意义，而HuBERT可以很好地捕捉speech中的时间动态和细微变化，这两种方法的组合可以提高emotion recognition的准确率。<details>
<summary>Abstract</summary>
Traditional approaches in speech emotion recognition, such as LSTM, CNN, RNN, SVM, and MLP, have limitations such as difficulty capturing long-term dependencies in sequential data, capturing the temporal dynamics, and struggling to capture complex patterns and relationships in multimodal data. This research addresses these shortcomings by proposing an ensemble model that combines Graph Convolutional Networks (GCN) for processing textual data and the HuBERT transformer for analyzing audio signals. We found that GCNs excel at capturing Long-term contextual dependencies and relationships within textual data by leveraging graph-based representations of text and thus detecting the contextual meaning and semantic relationships between words. On the other hand, HuBERT utilizes self-attention mechanisms to capture long-range dependencies, enabling the modeling of temporal dynamics present in speech and capturing subtle nuances and variations that contribute to emotion recognition. By combining GCN and HuBERT, our ensemble model can leverage the strengths of both approaches. This allows for the simultaneous analysis of multimodal data, and the fusion of these modalities enables the extraction of complementary information, enhancing the discriminative power of the emotion recognition system. The results indicate that the combined model can overcome the limitations of traditional methods, leading to enhanced accuracy in recognizing emotions from speech.
</details>
<details>
<summary>摘要</summary>
传统方法在语音情绪识别中，如LSTM、CNN、RNN、SVM和MLP，有一些缺点，包括难以捕捉顺序数据中长期依赖关系、模糊时间动态和复杂的模式和关系。这种研究解决这些缺点，提出一个 ensemble 模型， combining 文本数据的 Graph Convolutional Networks (GCN) 和语音信号的 HuBERT 变换器。我们发现，GCN 可以很好地捕捉文本数据中长期上下文关系和意义，通过利用文本的图形表示来捕捉词语之间的Semantic 关系。而 HuBERT 利用自我注意机制，可以捕捉长距离依赖关系，使得模型可以识别语音中的时间动态，捕捉语音中细微的变化和细节，从而提高情绪识别的准确性。通过合并 GCN 和 HuBERT，我们的ensemble模型可以利用这两种方法的优点。这使得同时分析多Modal 数据，并将这些模式融合，以提高情绪识别系统的推理力。结果表明，我们的combined模型可以超越传统方法的局限性，导致识别语音中的情绪的准确性得到提高。
</details></li>
</ul>
<hr>
<h2 id="N-gram-Boosting-Improving-Contextual-Biasing-with-Normalized-N-gram-Targets"><a href="#N-gram-Boosting-Improving-Contextual-Biasing-with-Normalized-N-gram-Targets" class="headerlink" title="N-gram Boosting: Improving Contextual Biasing with Normalized N-gram Targets"></a>N-gram Boosting: Improving Contextual Biasing with Normalized N-gram Targets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02092">http://arxiv.org/abs/2308.02092</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wang Yau Li, Shreekantha Nadig, Karol Chang, Zafarullah Mahmood, Riqiang Wang, Simon Vandieken, Jonas Robertson, Fred Mailhot</li>
<li>for: 提高商务会议中关键词语识别率</li>
<li>methods: 使用两步关键词强化机制，normalized unigrams和n-grams进行强化，避免缺失命中问题</li>
<li>results: 相比原始数据集，提高关键词识别率26%，相比LibriSpeech，提高2%<details>
<summary>Abstract</summary>
Accurate transcription of proper names and technical terms is particularly important in speech-to-text applications for business conversations. These words, which are essential to understanding the conversation, are often rare and therefore likely to be under-represented in text and audio training data, creating a significant challenge in this domain. We present a two-step keyword boosting mechanism that successfully works on normalized unigrams and n-grams rather than just single tokens, which eliminates missing hits issues with boosting raw targets. In addition, we show how adjusting the boosting weight logic avoids over-boosting multi-token keywords. This improves our keyword recognition rate by 26% relative on our proprietary in-domain dataset and 2% on LibriSpeech. This method is particularly useful on targets that involve non-alphabetic characters or have non-standard pronunciations.
</details>
<details>
<summary>摘要</summary>
精准转写特有名称和技术术语 particualrly important in speech-to-text应用程序 для商业对话。这些词语，which are essential to understanding the conversation, are often rare and therefore likely to be under-represented in text and audio training data, creating a significant challenge in this domain. We present a two-step keyword boosting mechanism that successfully works on normalized unigrams and n-grams rather than just single tokens, which eliminates missing hits issues with boosting raw targets. In addition, we show how adjusting the boosting weight logic avoids over-boosting multi-token keywords. This improves our keyword recognition rate by 26% relative on our proprietary in-domain dataset and 2% on LibriSpeech. This method is particularly useful on targets that involve non-alphabetic characters or have non-standard pronunciations.Here's the breakdown of the translation:* 精准转写 (jīngshù zhōngyì) - accurate transcription* 特有名称 (tèyǒu míngcè) - proper names* 技术术语 (jìshuō shūyǔ) - technical terms* 商业对话 (shāngyào duìhùa) - business conversations* 词语 (cíyǔ) - words* essential (zhòngyào) - essential* understanding (dànzhi) - understanding* domain (diàngròng) - domain* 预处理 (yùchū) - preprocessing* 单词 (danzi) - single token* 拼音 (pīnyīn) - pinyin* 非汉字 (fēihànzì) - non-hanzi characters* 非标准发音 (fēizhǔshuāng fāyīn) - non-standard pronunciationsNote that the translation is written in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/04/cs.SD_2023_08_04/" data-id="closbrot000ul0g88bmpq9neo" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_04" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/04/cs.CV_2023_08_04/" class="article-date">
  <time datetime="2023-08-04T13:00:00.000Z" itemprop="datePublished">2023-08-04</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/04/cs.CV_2023_08_04/">cs.CV - 2023-08-04</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="A-Bi-variant-Variational-Model-for-Diffeomorphic-Image-Registration-with-Relaxed-Jacobian-Determinant-Constraints"><a href="#A-Bi-variant-Variational-Model-for-Diffeomorphic-Image-Registration-with-Relaxed-Jacobian-Determinant-Constraints" class="headerlink" title="A Bi-variant Variational Model for Diffeomorphic Image Registration with Relaxed Jacobian Determinant Constraints"></a>A Bi-variant Variational Model for Diffeomorphic Image Registration with Relaxed Jacobian Determinant Constraints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02393">http://arxiv.org/abs/2308.02393</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanyan Li, Ke Chen, Chong Chen, Jianping Zhang</li>
<li>for: 本文提出了一种新的二元滤波图像匹配模型，用于处理大幅度变换的图像匹配问题。</li>
<li>methods: 本文使用了一种基于Jacobian方程的软约束方法，以控制扩展和压缩的地方几何变换。此外，本文还提出了一种用于保证扩展的正则化项，以确保扩展的稳定性。</li>
<li>results: 数值实验表明，提出的算法是可靠的，并且可以控制相对体积的范围，不会产生匹配错误。此外，本文的模型还可以生成 diffeomorphic 图像匹配，并比较多个现有的匹配模型表现更好。<details>
<summary>Abstract</summary>
Diffeomorphic registration has become a powerful approach for seeking a smooth and invertible spatial transformation between two coordinate systems which have been measured via the template and reference images. While the pointwise volume-preserving constraint is effective for some problems, it is too stringent for many other problems especially when the local deformations are relatively large, because it may lead to a poor large-deformation for enforcing local matching.In this paper, we propose a novel bi-variant diffeomorphic image registration model with the soft constraint of Jacobian equation, which allows local deformations to shrink and grow in a flexible range.The Jacobian determinant of the transformation is explicitly controlled by optimizing the relaxation function. To prevent deformation folding and enhance the smoothness of deformation, we not only impose a positivity constraint in optimizing the relaxation function, but also employ a regularizer to ensure the smoothness of the relaxation function.Furthermore, the positivity constraint ensures that is as close to one as possible, which helps to obtain a volume-preserving transformation on average.We further analyze the existence of the minimizer for the variational model and propose a penalty splitting method with a multilevel strategy to solve this model. Numerical experiments show that the proposed algorithm is convergent, and the positivity constraint can control the range of relative volume and not compromise registration accuracy. Moreover, the proposed model produces diffeomorphic maps for large deformation, and achieves better performance compared to the several existing registration models.
</details>
<details>
<summary>摘要</summary>
Diffusion registration已经成为一种有力的方法，用于在两个坐标系统之间找到一个平滑和反函数的空间变换。虽然点位量保持约束有效于一些问题，但是在许多问题上，特别是当地方减少很大时，这种约束可能会导致差异匮乏。在这篇论文中，我们提出了一种新的二元diffusion图像 регистраción模型，使得地方减少和增加在一个flexible范围内进行。Jacobian方程的determinant是通过优化放松函数来控制的。为了避免减少和提高折叠的smoothness，我们不仅在优化放松函数时强制实施一个正负性约束，还使用一个正则化项来保证放松函数的smoothness。此外，正负性约束使得变换趋近于一个，帮助获得一个保持体积的变换。我们进一步分析了变量模型的存在性和提出了一种罚分法，用于解决这个模型。 numerically experiments show that the proposed algorithm is convergent, and the positivity constraint can control the range of relative volume without compromising registration accuracy. Moreover, the proposed model produces diffeomorphic maps for large deformation, and achieves better performance compared to several existing registration models.
</details></li>
</ul>
<hr>
<h2 id="Color-Image-Recovery-Using-Generalized-Matrix-Completion-over-Higher-Order-Finite-Dimensional-Algebra"><a href="#Color-Image-Recovery-Using-Generalized-Matrix-Completion-over-Higher-Order-Finite-Dimensional-Algebra" class="headerlink" title="Color Image Recovery Using Generalized Matrix Completion over Higher-Order Finite Dimensional Algebra"></a>Color Image Recovery Using Generalized Matrix Completion over Higher-Order Finite Dimensional Algebra</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02621">http://arxiv.org/abs/2308.02621</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liang Liao, Zhuang Guo, Qi Gao, Yan Wang, Fajun Yu, Qifeng Zhao, Stephen Johh Maybank</li>
<li>for: 填充彩色图像中缺失部分的高精度图像复制</li>
<li>methods: 基于扩展的高阶矩阵模型，包括像素邻域扩展策略来描述本地像素约束</li>
<li>results: 对各种算法进行了广泛的实验，并对公共可用的图像进行了比较，结果表明我们的扩展矩阵完成模型和相应的算法与低阶矩阵和传统矩阵完成器相比，有较好的性能。<details>
<summary>Abstract</summary>
To improve the accuracy of color image completion with missing entries, we present a recovery method based on generalized higher-order scalars. We extend the traditional second-order matrix model to a more comprehensive higher-order matrix equivalent, called the "t-matrix" model, which incorporates a pixel neighborhood expansion strategy to characterize the local pixel constraints. This "t-matrix" model is then used to extend some commonly used matrix and tensor completion algorithms to their higher-order versions. We perform extensive experiments on various algorithms using simulated data and algorithms on simulated data and publicly available images and compare their performance. The results show that our generalized matrix completion model and the corresponding algorithm compare favorably with their lower-order tensor and conventional matrix counterparts.
</details>
<details>
<summary>摘要</summary>
要提高颜色图像完成缺失项的准确率，我们提出一种基于总是更高级别的scalar的恢复方法。我们将传统的第二阶matrix模型扩展到更加全面的高阶矩阵相等模型，称之为"t-矩阵"模型，该模型利用像素邻域扩展策略来描述当地像素约束。这个"t-矩阵"模型然后用来扩展一些常用的矩阵和tensor completion算法到其高阶版本。我们在各种算法上进行了广泛的实验，使用模拟数据和公共available的图像，并比较了其性能。结果显示，我们的总是更高级别的矩阵 completion模型和相应的算法与其低阶tensor和传统矩阵counterparts相比较avorably。
</details></li>
</ul>
<hr>
<h2 id="Frequency-Disentangled-Features-in-Neural-Image-Compression"><a href="#Frequency-Disentangled-Features-in-Neural-Image-Compression" class="headerlink" title="Frequency Disentangled Features in Neural Image Compression"></a>Frequency Disentangled Features in Neural Image Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02620">http://arxiv.org/abs/2308.02620</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Zafari, Atefeh Khoshkhahtinat, Piyush Mehta, Mohammad Saeed Ebrahimi Saadabadi, Mohammad Akyash, Nasser M. Nasrabadi</li>
<li>for: 提高图像压缩网络的设计，使其更好地匹配真实分布。</li>
<li>methods: 使用自适应量化、增强的自我注意力计算和通道级感知Entropy模型。</li>
<li>results: 提出了一种基于频率分离的特征级别频率分解方法，使得压缩率下降，同时也超过了手工编码和基于计算昂贵的空间自适应Entropy模型的 neural网络编码器。<details>
<summary>Abstract</summary>
The design of a neural image compression network is governed by how well the entropy model matches the true distribution of the latent code. Apart from the model capacity, this ability is indirectly under the effect of how close the relaxed quantization is to the actual hard quantization. Optimizing the parameters of a rate-distortion variational autoencoder (R-D VAE) is ruled by this approximated quantization scheme. In this paper, we propose a feature-level frequency disentanglement to help the relaxed scalar quantization achieve lower bit rates by guiding the high entropy latent features to include most of the low-frequency texture of the image. In addition, to strengthen the de-correlating power of the transformer-based analysis/synthesis transform, an augmented self-attention score calculation based on the Hadamard product is utilized during both encoding and decoding. Channel-wise autoregressive entropy modeling takes advantage of the proposed frequency separation as it inherently directs high-informational low-frequency channels to the first chunks and conditions the future chunks on it. The proposed network not only outperforms hand-engineered codecs, but also neural network-based codecs built on computation-heavy spatially autoregressive entropy models.
</details>
<details>
<summary>摘要</summary>
neural image compression network 的设计受 latent code 的真实分布决定。除了模型容量之外，这种能力受到较量量化的距离影响。 optimize R-D VAE 的参数被这种粗略量化方案控制。在这篇论文中，我们提出了一种基于频谱分解的特征级频率分离，以帮助 relaxed scalar quantization 实现更低的比特率。此外，通过在编码和解码过程中使用增强的自注意力分数计算，以及通过渠道级自动 entropy 模型来利用提出的频谱分解，我们提高了 transformer 基于分析/synthesis 变换的杜尔拜议性。这种网络不仅超越了手工编码器，还超越了基于 computation-heavy 空间自适应 entropy 模型的神经网络编码器。
</details></li>
</ul>
<hr>
<h2 id="Brain-MRI-Segmentation-using-Template-Based-Training-and-Visual-Perception-Augmentation"><a href="#Brain-MRI-Segmentation-using-Template-Based-Training-and-Visual-Perception-Augmentation" class="headerlink" title="Brain MRI Segmentation using Template-Based Training and Visual Perception Augmentation"></a>Brain MRI Segmentation using Template-Based Training and Visual Perception Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02363">http://arxiv.org/abs/2308.02363</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fang-Cheng Yeh</li>
<li>for: 用一个人脑MRI模组来对多种脑MRI进行分类和推导，并且不需要大量的训练数据。</li>
<li>methods: 使用模板基本的训练方法，将单一的人脑MRI模组和其相应的分类标签用于训练3D U-Net模型，并且运用视觉认知增强法来提高模型的适应能力和防止过滤。</li>
<li>results: 透过这种方法，训练了多种动物和人脑MRI的3D U-Net模型，并且在分类和推导任务中获得了高准确率。这个工具有效地解决了深度学习应用中的训练数据短缺问题，并且具有扩展深度学习应用的潜力。<details>
<summary>Abstract</summary>
Deep learning models usually require sufficient training data to achieve high accuracy, but obtaining labeled data can be time-consuming and labor-intensive. Here we introduce a template-based training method to train a 3D U-Net model from scratch using only one population-averaged brain MRI template and its associated segmentation label. The process incorporated visual perception augmentation to enhance the model's robustness in handling diverse image inputs and mitigating overfitting. Leveraging this approach, we trained 3D U-Net models for mouse, rat, marmoset, rhesus, and human brain MRI to achieve segmentation tasks such as skull-stripping, brain segmentation, and tissue probability mapping. This tool effectively addresses the limited availability of training data and holds significant potential for expanding deep learning applications in image analysis, providing researchers with a unified solution to train deep neural networks with only one image sample.
</details>
<details>
<summary>摘要</summary>
通常，深度学习模型需要充足的训练数据来实现高精度，但获取标注数据可以是时间consuming和劳动 INTENSIVE。在这里，我们介绍了一种模板基于的训练方法，可以用一个人类大脑MRI模板和其关联的标注来训练一个3D U-Net模型从零开始。该过程包括视觉感知加强来提高模型对不同输入图像的Robustness和避免过拟合。通过这种方法，我们训练了鼠、老鼠、玛瑙鼠、人类大脑MRI等3D U-Net模型来完成 segmentation 任务，如颅腔抽取、脑 segmentation 和组织概率地图。这种工具有效地解决了训练数据的有限性问题，并且具有扩展深度学习应用于图像分析的潜在力量，为研究人员提供了一个统一的解决方案，只需一个图像样本就可以训练深度神经网络。
</details></li>
</ul>
<hr>
<h2 id="T-UNet-Triplet-UNet-for-Change-Detection-in-High-Resolution-Remote-Sensing-Images"><a href="#T-UNet-Triplet-UNet-for-Change-Detection-in-High-Resolution-Remote-Sensing-Images" class="headerlink" title="T-UNet: Triplet UNet for Change Detection in High-Resolution Remote Sensing Images"></a>T-UNet: Triplet UNet for Change Detection in High-Resolution Remote Sensing Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02356">http://arxiv.org/abs/2308.02356</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pl-2000/t-unet">https://github.com/pl-2000/t-unet</a></li>
<li>paper_authors: Huan Zhong, Chen Wu<br>for:This paper aims to improve remote sensing image change detection by proposing a novel network called Triplet UNet (T-UNet), which can simultaneously extract object features and change features between pre- and post-time-phase images.methods:The proposed T-UNet network uses a three-branch encoder and a multi-branch spatial-spectral cross-attention module (MBSSCA) to interact and fuse the features extracted from the three branches. The network also uses channel attention mechanism (CAM) and spatial attention mechanism (SAM) in the decoder stage to fully mine and integrate detailed textures information and semantic localization information.results:The proposed T-UNet network can accurately detect changes between remote sensing images acquired at different times, and can effectively discern the edges of changed objects. The network’s use of triplet encoder and multi-branch spatial-spectral cross-attention module (MBSSCA) allows it to simultaneously extract object features and change features, leading to more accurate results.<details>
<summary>Abstract</summary>
Remote sensing image change detection aims to identify the differences between images acquired at different times in the same area. It is widely used in land management, environmental monitoring, disaster assessment and other fields. Currently, most change detection methods are based on Siamese network structure or early fusion structure. Siamese structure focuses on extracting object features at different times but lacks attention to change information, which leads to false alarms and missed detections. Early fusion (EF) structure focuses on extracting features after the fusion of images of different phases but ignores the significance of object features at different times for detecting change details, making it difficult to accurately discern the edges of changed objects. To address these issues and obtain more accurate results, we propose a novel network, Triplet UNet(T-UNet), based on a three-branch encoder, which is capable to simultaneously extract the object features and the change features between the pre- and post-time-phase images through triplet encoder. To effectively interact and fuse the features extracted from the three branches of triplet encoder, we propose a multi-branch spatial-spectral cross-attention module (MBSSCA). In the decoder stage, we introduce the channel attention mechanism (CAM) and spatial attention mechanism (SAM) to fully mine and integrate detailed textures information at the shallow layer and semantic localization information at the deep layer.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传感图像变化检测目标是在不同时间在同一地区内检测图像之间的差异。它广泛应用于地区管理、环境监测、灾害评估等领域。目前大多数变化检测方法基于Siamesenet结构或早期融合结构。Siamesenet结构专注于不同时间扫描图像中的对象特征，但缺乏关注变化信息，导致假报警和错过检测。早期融合（EF）结构专注于将不同阶段图像融合后的特征进行检测，但忽视了不同时间对变化细节的重要性，从而难以准确识别变化的边界。为了解决这些问题并获得更高精度结果，我们提议一种新的网络模型，Triplet UNet（T-UNet），基于三个分支编码器。T-UNet模型可同时检测不同时间图像中对象特征和变化特征，并通过 triplet encoder 来实现。为了有效地交互和融合三个分支编码器中的特征，我们提议一种多分支空间 спектral cross-attention模块（MBSSCA）。在解码阶段，我们引入通道注意机制（CAM）和空间注意机制（SAM），以全面挖掘和融合图像的细节信息，并充分利用深层层次结构的semantic localization信息。
</details></li>
</ul>
<hr>
<h2 id="Multi-attacks-Many-images-the-same-adversarial-attack-to-many-target-labels"><a href="#Multi-attacks-Many-images-the-same-adversarial-attack-to-many-target-labels" class="headerlink" title="Multi-attacks: Many images $+$ the same adversarial attack $\to$ many target labels"></a>Multi-attacks: Many images $+$ the same adversarial attack $\to$ many target labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03792">http://arxiv.org/abs/2308.03792</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/stanislavfort/multi-attacks">https://github.com/stanislavfort/multi-attacks</a></li>
<li>paper_authors: Stanislav Fort</li>
<li>for: 这篇论文旨在描述如何用单个敌意扰动($P$)改变$n$张图像($X_1,X_2,\dots,X_n$)的原始分类($c_1, c_2,\dots,c_n$)为新的目标分类($c^*_1,c^*_2,\dots,c^*_n$)，并可以同时对数百张图像和目标分类进行修改。这些攻击被称为“多重攻击”。</li>
<li>methods: 这篇论文使用了多种方法来研究攻击和防御，包括计算最大可以达到的$n$值，并估算每个像素空间中高度相信度的区域数量为$10^{\mathcal{O}(100)}$。</li>
<li>results: 论文发现了一些 immediat 的后果，包括基于强度的攻击和缩放不依赖的攻击例子。它们还发现了分类决策边界在像素空间中的重复和丰富性，并证明了将多个分类器 ensemble 可以减少攻击的可能性。<details>
<summary>Abstract</summary>
We show that we can easily design a single adversarial perturbation $P$ that changes the class of $n$ images $X_1,X_2,\dots,X_n$ from their original, unperturbed classes $c_1, c_2,\dots,c_n$ to desired (not necessarily all the same) classes $c^*_1,c^*_2,\dots,c^*_n$ for up to hundreds of images and target classes at once. We call these \textit{multi-attacks}. Characterizing the maximum $n$ we can achieve under different conditions such as image resolution, we estimate the number of regions of high class confidence around a particular image in the space of pixels to be around $10^{\mathcal{O}(100)}$, posing a significant problem for exhaustive defense strategies. We show several immediate consequences of this: adversarial attacks that change the resulting class based on their intensity, and scale-independent adversarial examples. To demonstrate the redundancy and richness of class decision boundaries in the pixel space, we look for its two-dimensional sections that trace images and spell words using particular classes. We also show that ensembling reduces susceptibility to multi-attacks, and that classifiers trained on random labels are more susceptible. Our code is available on GitHub.
</details>
<details>
<summary>摘要</summary>
我们显示了我们可以轻松地设计一个单一的对抗 perturbation $P$，使得 $n$ 张图像 $X_1,X_2,\dots,X_n$ 的原始、未受 perturbation 的类 $c_1, c_2,\dots,c_n$ 变为欲要的类 $c^*_1,c^*_2,\dots,c^*_n$。我们称这为 “多个攻击”。在不同的条件下，如图像分辨率，我们估算最大 achievable $n$ 的值在 $10^{\mathcal{O}(100)}$ 之间，这意味着在像素空间中有大约 $10^{\mathcal{O}(100)}$ 个高度相关的类 confidence 区域，对抗措施是一个重大问题。我们显示了一些 immediate consequence：对于图像的 Intensity 的变化，以及缩放不依赖的对抗例子。此外，我们还证明了像素空间中精度的分布是丰富的，可以用两dimensional 的section找到图像和描述字符串的轨迹。最后，我们发现 ensemble 可以减少多个攻击的影响，而类ifiers 训练于随机标签的情况下更容易受到攻击。我们的代码可以在 GitHub 上找到。
</details></li>
</ul>
<hr>
<h2 id="A-Parameter-efficient-Multi-subject-Model-for-Predicting-fMRI-Activity"><a href="#A-Parameter-efficient-Multi-subject-Model-for-Predicting-fMRI-Activity" class="headerlink" title="A Parameter-efficient Multi-subject Model for Predicting fMRI Activity"></a>A Parameter-efficient Multi-subject Model for Predicting fMRI Activity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02351">http://arxiv.org/abs/2308.02351</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cmi-dair/algonauts23">https://github.com/cmi-dair/algonauts23</a></li>
<li>paper_authors: Connor Lane, Gregory Kiar</li>
<li>for: This paper is written for the Algonauts 2023 submission, and it describes the team “BlobGPT”‘s model and its components.</li>
<li>methods: The paper uses a multi-subject linear encoding head attached to a pretrained trunk model, which consists of three components: a shared multi-layer feature projection, shared plus subject-specific low-dimension linear transformations, and a shared PCA fMRI embedding.</li>
<li>results: The paper presents experimental results for the team’s model, which demonstrate its effectiveness in certain tasks.Here’s the simplified Chinese text for the three key information points:</li>
<li>for: 这篇论文是为 Algonauts 2023 提交而写的，描述了 “BlobGPT” 团队的模型和其组成部分。</li>
<li>methods: 这篇论文使用了一个多主题线性编码头，附加到预训练的树模型上，该头包括三个组成部分：共享多层特征投影、共享 plus 特定主题低维度线性变换、和共享 PCA fMRI 嵌入。</li>
<li>results: 这篇论文发表了团队的模型实验结果，以证明其在某些任务中的效果。<details>
<summary>Abstract</summary>
This is the Algonauts 2023 submission report for team "BlobGPT". Our model consists of a multi-subject linear encoding head attached to a pretrained trunk model. The multi-subject head consists of three components: (1) a shared multi-layer feature projection, (2) shared plus subject-specific low-dimension linear transformations, and (3) a shared PCA fMRI embedding. In this report, we explain these components in more detail and present some experimental results. Our code is available at https://github.com/cmi-dair/algonauts23.
</details>
<details>
<summary>摘要</summary>
这是 Algonauts 2023 提交报告，我们的团队名称是 "BlobGPT"。我们的模型包括一个多主题线性编码头，附加到预训练的核心模型上。多主题头包括三个组成部分：（1）共享多层特征投影，（2）共享 plus 特定主题低维度线性变换，（3）共享 PCA fMRI 嵌入。在这份报告中，我们将这些组成部分进行详细介绍，并展示一些实验结果。我们的代码可以在 GitHub 上找到：https://github.com/cmi-dair/algonauts23。
</details></li>
</ul>
<hr>
<h2 id="RobustMQ-Benchmarking-Robustness-of-Quantized-Models"><a href="#RobustMQ-Benchmarking-Robustness-of-Quantized-Models" class="headerlink" title="RobustMQ: Benchmarking Robustness of Quantized Models"></a>RobustMQ: Benchmarking Robustness of Quantized Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02350">http://arxiv.org/abs/2308.02350</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yisong Xiao, Aishan Liu, Tianyuan Zhang, Haotong Qin, Jinyang Guo, Xianglong Liu</li>
<li>for: 评估量化神经网络模型在各种噪声环境下的Robustness。</li>
<li>methods: 对ImageNet上的量化神经网络模型进行了广泛的评估，包括对抗攻击、自然损害和系统性噪声的评估。</li>
<li>results: 研究结果表明，量化模型对抗攻击 exhibits higher robustness than its floating-point counterpart, but is more vulnerable to natural corruptions and systematic noises。增加量化比特宽度会导致对抗攻击的Robustness下降，自然 robustness 增加，系统 robustness 增加。 among corruption methods, impulse noise and glass blur are the most harmful to quantized models, while brightness has the least impact. among systematic noises, the nearest neighbor interpolation has the highest impact, while bilinear interpolation, cubic interpolation, and area interpolation are the three least harmful.<details>
<summary>Abstract</summary>
Quantization has emerged as an essential technique for deploying deep neural networks (DNNs) on devices with limited resources. However, quantized models exhibit vulnerabilities when exposed to various noises in real-world applications. Despite the importance of evaluating the impact of quantization on robustness, existing research on this topic is limited and often disregards established principles of robustness evaluation, resulting in incomplete and inconclusive findings. To address this gap, we thoroughly evaluated the robustness of quantized models against various noises (adversarial attacks, natural corruptions, and systematic noises) on ImageNet. The comprehensive evaluation results empirically provide valuable insights into the robustness of quantized models in various scenarios, for example: (1) quantized models exhibit higher adversarial robustness than their floating-point counterparts, but are more vulnerable to natural corruptions and systematic noises; (2) in general, increasing the quantization bit-width results in a decrease in adversarial robustness, an increase in natural robustness, and an increase in systematic robustness; (3) among corruption methods, \textit{impulse noise} and \textit{glass blur} are the most harmful to quantized models, while \textit{brightness} has the least impact; (4) among systematic noises, the \textit{nearest neighbor interpolation} has the highest impact, while bilinear interpolation, cubic interpolation, and area interpolation are the three least harmful. Our research contributes to advancing the robust quantization of models and their deployment in real-world scenarios.
</details>
<details>
<summary>摘要</summary>
“量化技术已经成为深度神经网络（DNNs）部署在有限资源设备时的关键手段。然而，量化模型在实际应用中容易受到各种噪声的影响。尽管评估量化对模型的Robustness的影响非常重要，但现有的研究往往忽视了已有的Robustness评估原则，导致结果不完整、不一致。为了解决这个空白，我们对ImageNet上的量化模型进行了全面的评估，包括了骚扰攻击、自然损害和系统性噪声。我们的实验结果表明：（1）量化模型对骚扰攻击更为抵抗，但对自然损害和系统性噪声更为敏感；（2）随着量化比特宽度的增加，对骚扰攻击的抵抗力下降，对自然损害的抵抗力增加，对系统性噪声的抵抗力增加；（3）在损害方法中，雷达噪声和玻璃抹涂是对量化模型最有害的，而亮度损害最小。在系统性噪声中，最危险的是 nearest neighbor interpolation，而bilinear interpolation、cubic interpolation和area interpolation是最安全的。”
</details></li>
</ul>
<hr>
<h2 id="Class-Incremental-Learning-with-Self-Supervised-Pre-Training-and-Prototype-Learning"><a href="#Class-Incremental-Learning-with-Self-Supervised-Pre-Training-and-Prototype-Learning" class="headerlink" title="Class Incremental Learning with Self-Supervised Pre-Training and Prototype Learning"></a>Class Incremental Learning with Self-Supervised Pre-Training and Prototype Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02346">http://arxiv.org/abs/2308.02346</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenzhuo Liu, Xinjian Wu, Fei Zhu, Mingming Yu, Chuang Wang, Cheng-Lin Liu</li>
<li>for: 这篇研究目的是解决随时间变化的开放组别集（class incremental learning，CIL）中的衰弱现象（catastrophic forgetting）。</li>
<li>methods: 本研究使用了两阶段学习框架，其中一阶段是固定的encoder，另一阶段是逐渐更新的prototype标签分类器。encoder使用了自我超vis Learning来生成一个高内在维度的特征空间，以提高它的转移性和通用性。prototype标签分类器逐渐学习新的标签，同时保留之前学习的标签的标签，这是保持决策界的关键。</li>
<li>results: 实验结果显示， compared to state-of-the-art exemplar-based methods when they reserved 5 examplers per class, our method can significantly outperform them under the incremental setting of 10 phases, by 18.24% on CIFAR-100 and 9.37% on ImageNet100.<details>
<summary>Abstract</summary>
Deep Neural Network (DNN) has achieved great success on datasets of closed class set. However, new classes, like new categories of social media topics, are continuously added to the real world, making it necessary to incrementally learn. This is hard for DNN because it tends to focus on fitting to new classes while ignoring old classes, a phenomenon known as catastrophic forgetting. State-of-the-art methods rely on knowledge distillation and data replay techniques but still have limitations. In this work, we analyze the causes of catastrophic forgetting in class incremental learning, which owes to three factors: representation drift, representation confusion, and classifier distortion. Based on this view, we propose a two-stage learning framework with a fixed encoder and an incrementally updated prototype classifier. The encoder is trained with self-supervised learning to generate a feature space with high intrinsic dimensionality, thus improving its transferability and generality. The classifier incrementally learns new prototypes while retaining the prototypes of previously learned data, which is crucial in preserving the decision boundary.Our method does not rely on preserved samples of old classes, is thus a non-exemplar based CIL method. Experiments on public datasets show that our method can significantly outperform state-of-the-art exemplar-based methods when they reserved 5 examplers per class, under the incremental setting of 10 phases, by 18.24% on CIFAR-100 and 9.37% on ImageNet100.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）在封闭类集的数据上达到了很大的成功。然而，实际世界中新的类是不断添加的，使得需要逐步学习。这是DNN很难受的，因为它往往会专注于新类的适应而忽略旧类，这被称为慢性忘却。现状的方法包括知识传递和数据重播技术，但还有局限性。在这种情况下，我们分析了逐步学习中的慢性忘却的原因，它是由于表示变化、表示混乱和分类器扭曲三个因素引起的。基于这种视角，我们提出了一种两阶段学习框架，其中有一个固定的编码器和一个逐步更新的原型分类器。编码器通过自我超vised学习来生成一个具有高内在维度的特征空间，从而提高其传输性和通用性。原型分类器逐步学习新的原型，同时保留之前学习的数据的原型，这是保持决策边界的关键。我们的方法不需要保留旧类的示例，因此不是基于示例的CIL方法。在公共数据集上进行了实验，我们的方法可以在10个阶段的逐步学习Setting下，在与存储5个示例的旧类的情况下，与现状的 exemplar-based 方法相比，提高了18.24%的CIFAR-100和9.37%的ImageNet100。
</details></li>
</ul>
<hr>
<h2 id="Generative-Image-Priors-for-MRI-Reconstruction-Trained-from-Magnitude-Only-Images"><a href="#Generative-Image-Priors-for-MRI-Reconstruction-Trained-from-Magnitude-Only-Images" class="headerlink" title="Generative Image Priors for MRI Reconstruction Trained from Magnitude-Only Images"></a>Generative Image Priors for MRI Reconstruction Trained from Magnitude-Only Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02340">http://arxiv.org/abs/2308.02340</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mrirecon/image-priors">https://github.com/mrirecon/image-priors</a></li>
<li>paper_authors: Guanxiong Luo, Xiaoqing Wang, Mortiz Blumenthal, Martin Schilling, Erik Hans Ulrich Rauf, Raviteja Kotikalapudi, Niels Focke, Martin Uecker</li>
<li>for: 这个研究旨在构建基于大量数据和阶段信息的生成性图像假设，以提高MRI重建图像质量。</li>
<li>methods: 该研究 workflow包括准备具有阶段信息的训练数据集，并使用这些数据集来训练复杂图像的生成假设。最后，用于重建图像的训练过程中使用了线性和非线性重建方法。</li>
<li>results: 实验结果表明，基于复杂图像的生成假设比只基于幅度图像的生成假设更高效。此外，使用更大的数据集可以提高生成假设的可靠性。最后，我们发现使用生成假设比L1-抽象冲激regularization更有利于高Undersampling下的分辨率增强。<details>
<summary>Abstract</summary>
Purpose: In this work, we present a workflow to construct generic and robust generative image priors from magnitude-only images. The priors can then be used for regularization in reconstruction to improve image quality. Methods: The workflow begins with the preparation of training datasets from magnitude-only MR images. This dataset is then augmented with phase information and used to train generative priors of complex images. Finally, trained priors are evaluated using both linear and nonlinear reconstruction for compressed sensing parallel imaging with various undersampling schemes. Results: The results of our experiments demonstrate that priors trained on complex images outperform priors trained only on magnitude images. Additionally, a prior trained on a larger dataset exhibits higher robustness. Finally, we show that the generative priors are superior to L1 -wavelet regularization for compressed sensing parallel imaging with high undersampling. Conclusion: These findings stress the importance of incorporating phase information and leveraging large datasets to raise the performance and reliability of the generative priors for MRI reconstruction. Phase augmentation makes it possible to use existing image databases for training.
</details>
<details>
<summary>摘要</summary>
目的：在这项工作中，我们提出了一个工作流程，用于从偏度只图像中生成一般化和稳定的生成图像假设。这些假设可以用于图像重建中的规则化，以提高图像质量。方法：我们的工作流程开始于准备待训练的训练集，其中包含了偏度只的MR图像。这个集合然后被补充了相位信息，并用于训练复杂图像的生成假设。最后，我们训练了这些假设，并对其进行了线性和非线性重建的评估。结果：我们的实验结果表明，使用复杂图像进行训练的假设，可以超过只使用偏度图像进行训练的假设。此外，我们发现，使用更大的数据集来训练假设，可以提高假设的稳定性。最后，我们表明，生成假设比L1-wavelet正则化更有效地进行压缩感知并行图像重建。结论：这些发现表明，在MRI重建中，包含相位信息和利用大数据集来训练生成假设，是提高性和可靠性的关键。相位补充使得可以使用现有的图像库进行训练。
</details></li>
</ul>
<hr>
<h2 id="Improving-Scene-Graph-Generation-with-Superpixel-Based-Interaction-Learning"><a href="#Improving-Scene-Graph-Generation-with-Superpixel-Based-Interaction-Learning" class="headerlink" title="Improving Scene Graph Generation with Superpixel-Based Interaction Learning"></a>Improving Scene Graph Generation with Superpixel-Based Interaction Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02339">http://arxiv.org/abs/2308.02339</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingyi Wang, Can Zhang, Jinfa Huang, Botao Ren, Zhidong Deng</li>
<li>for: 提高Scene Graph Generation（SGG）的精度，使其更好地捕捉场景中entity之间的关系和Semantics。</li>
<li>methods: 提出了一种新的Superpixel-based Interaction Learning（SIL）方法，通过对场景点Cloud进行分 clustering，并在不同superpixel之间进行交互学习，以提高SGG中entity之间的finegrained交互。</li>
<li>results: 经过extensive的实验 validate，SIL方法能够在Visual Genome和Open Image V6两个Benchmark上达到state-of-the-art的性能，并且可以与现有的Box-level方法相结合，以提高其性能。<details>
<summary>Abstract</summary>
Recent advances in Scene Graph Generation (SGG) typically model the relationships among entities utilizing box-level features from pre-defined detectors. We argue that an overlooked problem in SGG is the coarse-grained interactions between boxes, which inadequately capture contextual semantics for relationship modeling, practically limiting the development of the field. In this paper, we take the initiative to explore and propose a generic paradigm termed Superpixel-based Interaction Learning (SIL) to remedy coarse-grained interactions at the box level. It allows us to model fine-grained interactions at the superpixel level in SGG. Specifically, (i) we treat a scene as a set of points and cluster them into superpixels representing sub-regions of the scene. (ii) We explore intra-entity and cross-entity interactions among the superpixels to enrich fine-grained interactions between entities at an earlier stage. Extensive experiments on two challenging benchmarks (Visual Genome and Open Image V6) prove that our SIL enables fine-grained interaction at the superpixel level above previous box-level methods, and significantly outperforms previous state-of-the-art methods across all metrics. More encouragingly, the proposed method can be applied to boost the performance of existing box-level approaches in a plug-and-play fashion. In particular, SIL brings an average improvement of 2.0% mR (even up to 3.4%) of baselines for the PredCls task on Visual Genome, which facilitates its integration into any existing box-level method.
</details>
<details>
<summary>摘要</summary>
Recent advances in Scene Graph Generation (SGG) 通常使用预定的检测器提供的箱级别特征来模型实体之间的关系。我们认为SGG中的粗略交互不足以捕捉场景中的语义上下文，实际上限制了该领域的发展。在这篇论文中，我们决定探索和提议一种通用的思想，称之为Superpixel-based Interaction Learning (SIL)，以解决粗略交互的问题。它允许我们在SGG中模型细化的交互。具体来说，我们将场景视为一组点，并将它们分组成相应的superpixel，表示场景中的子区域。然后，我们会探索这些superpixel之间的内部和跨实体交互，以增强交互的细化。广泛的实验表明，我们的SIL可以在Visual Genome和Open Image V6两个挑战性评价指标上提高细化交互的性能，并在所有指标上超过之前的箱级方法。此外，我们的方法可以与现有的箱级方法相结合，以提高其性能。例如，在Visual Genome上，我们的SIL可以与基eline方法相结合，提高PredCls任务的平均改进率2.0%（最高达3.4%）。
</details></li>
</ul>
<hr>
<h2 id="Diffusion-Augmented-Depth-Prediction-with-Sparse-Annotations"><a href="#Diffusion-Augmented-Depth-Prediction-with-Sparse-Annotations" class="headerlink" title="Diffusion-Augmented Depth Prediction with Sparse Annotations"></a>Diffusion-Augmented Depth Prediction with Sparse Annotations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02283">http://arxiv.org/abs/2308.02283</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaqi Li, Yiran Wang, Zihao Huang, Jinghong Zheng, Ke Xian, Zhiguo Cao, Jianming Zhang</li>
<li>for: 这篇论文的目的是提出一种supervised推断方法，以解决自主驾驶场景中稀疏的注释问题，并且提高depth estimation的稠密度和Robustness。</li>
<li>methods: 这篇论文提出了一种名为Diffusion-Augmented Depth Prediction（DADP）的框架，利用diffusion模型的结构特征来强制深度模型中的深度结构，同时还提出了一种对象指导完整性损失函数，以进一步增强区域结构完整性。</li>
<li>results: 在三个驾驶 benchmark上测试了DADP框架，实现了显著提高的深度结构和Robustness。这种方法为自主驾驶场景中的depth estimation带来了新的视角和解决方案。<details>
<summary>Abstract</summary>
Depth estimation aims to predict dense depth maps. In autonomous driving scenes, sparsity of annotations makes the task challenging. Supervised models produce concave objects due to insufficient structural information. They overfit to valid pixels and fail to restore spatial structures. Self-supervised methods are proposed for the problem. Their robustness is limited by pose estimation, leading to erroneous results in natural scenes. In this paper, we propose a supervised framework termed Diffusion-Augmented Depth Prediction (DADP). We leverage the structural characteristics of diffusion model to enforce depth structures of depth models in a plug-and-play manner. An object-guided integrality loss is also proposed to further enhance regional structure integrality by fetching objective information. We evaluate DADP on three driving benchmarks and achieve significant improvements in depth structures and robustness. Our work provides a new perspective on depth estimation with sparse annotations in autonomous driving scenes.
</details>
<details>
<summary>摘要</summary>
depth estimation 目标是预测粗粒度地图。在自动驾驶场景中，笔记率的假设使得任务变得困难。经过监督的模型会生成凹形物体，因为缺乏结构信息而导致过拟合有效像素，并且失去空间结构。为了解决这问题，自动驾驶方法被提出。它们的可靠性受到定位估计的限制，导致在自然场景中产生错误结果。在这篇论文中，我们提出了一种名为傅立叶-扩展 depth prediction（DADP）的监督框架。我们利用傅立叶模型的结构特征来强制深度模型中的深度结构，并且在插件和撤销的方式下进行替换。我们还提出了一种对象指导的完整性损失函数，以进一步增强地域结构完整性。我们对 DADP 进行了三个驾驶benchmark测试，并实现了深度结构和可靠性方面的显著提高。我们的工作为自动驾驶场景中笔记率稀缺的深度估计带来了新的视角。
</details></li>
</ul>
<hr>
<h2 id="SURE-Val-Safe-Urban-Relevance-Extension-and-Validation"><a href="#SURE-Val-Safe-Urban-Relevance-Extension-and-Validation" class="headerlink" title="SURE-Val: Safe Urban Relevance Extension and Validation"></a>SURE-Val: Safe Urban Relevance Extension and Validation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02266">http://arxiv.org/abs/2308.02266</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kai Storms, Ken Mori, Steven Peters</li>
<li>for: 本研究目的是评估自动驾驶系统的感知组件，需要定义相关的目标对象。而城市领域是自动驾驶数据集的常用领域，但是 relevance 不够充分定义。因此，本研究采用了已有的方法，将 relevance 定义 extend 到城市领域。</li>
<li>methods: 本研究采用了现有的方法，并将 relevance 定义 extend 到城市领域。此外，本研究还提出了一种新的 relevance 验证方法，利用了预测组件，以验证 relevance 的定义。</li>
<li>results: 本研究通过对 relevance 验证方法进行 verify ，并证明了 relevance 验证方法的有效性。此外，本研究还发现了一些 relevance 验证方法的缺陷，并提出了一些改进建议。<details>
<summary>Abstract</summary>
To evaluate perception components of an automated driving system, it is necessary to define the relevant objects. While the urban domain is popular among perception datasets, relevance is insufficiently specified for this domain. Therefore, this work adopts an existing method to define relevance in the highway domain and expands it to the urban domain. While different conceptualizations and definitions of relevance are present in literature, there is a lack of methods to validate these definitions. Therefore, this work presents a novel relevance validation method leveraging a motion prediction component. The validation leverages the idea that removing irrelevant objects should not influence a prediction component which reflects human driving behavior. The influence on the prediction is quantified by considering the statistical distribution of prediction performance across a large-scale dataset. The validation procedure is verified using criteria specifically designed to exclude relevant objects. The validation method is successfully applied to the relevance criteria from this work, thus supporting their validity.
</details>
<details>
<summary>摘要</summary>
There are various conceptualizations and definitions of relevance in literature, but there is a lack of methods to validate these definitions. Therefore, this study presents a novel relevance validation method that leverages a motion prediction component. The validation method is based on the idea that removing irrelevant objects should not influence a prediction component that reflects human driving behavior. The influence on the prediction is quantified by considering the statistical distribution of prediction performance across a large-scale dataset.The validation procedure is verified using criteria specifically designed to exclude relevant objects. The validation method is successfully applied to the relevance criteria from this study, thus supporting their validity.
</details></li>
</ul>
<hr>
<h2 id="On-the-Calibration-of-Uncertainty-Estimation-in-LiDAR-based-Semantic-Segmentation"><a href="#On-the-Calibration-of-Uncertainty-Estimation-in-LiDAR-based-Semantic-Segmentation" class="headerlink" title="On the Calibration of Uncertainty Estimation in LiDAR-based Semantic Segmentation"></a>On the Calibration of Uncertainty Estimation in LiDAR-based Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02248">http://arxiv.org/abs/2308.02248</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mariella Dreissig, Florian Piewak, Joschka Boedecker</li>
<li>for: 这种研究的目的是提高深度学习基于感知模型的可靠性，尤其是在自动驾驶等下游任务中，需要准确的信任估计。</li>
<li>methods: 该研究使用了一种新的度量方法来衡量semantic segmentation模型中每个类别的信任抑制质量。</li>
<li>results: 该方法可以帮助找到 Label 问题，以提高手动或自动标注数据集的质量。<details>
<summary>Abstract</summary>
The confidence calibration of deep learning-based perception models plays a crucial role in their reliability. Especially in the context of autonomous driving, downstream tasks like prediction and planning depend on accurate confidence estimates. In point-wise multiclass classification tasks like sematic segmentation the model has to deal with heavy class imbalances. Due to their underrepresentation, the confidence calibration of classes with smaller instances is challenging but essential, not only for safety reasons. We propose a metric to measure the confidence calibration quality of a semantic segmentation model with respect to individual classes. It is calculated by computing sparsification curves for each class based on the uncertainty estimates. We use the classification calibration metric to evaluate uncertainty estimation methods with respect to their confidence calibration of underrepresented classes. We furthermore suggest a double use for the method to automatically find label problems to improve the quality of hand- or auto-annotated datasets.
</details>
<details>
<summary>摘要</summary>
“深度学习基于观察模型的自信核算对其可靠性起着关键作用。尤其在自动驾驶上，下游任务如预测和规划都需要准确的自信估算。在点对多类分类任务如semantic segmentation中，模型需要面临重重分类异常现象。由于这些类型的实例较少，对这些类型的自信核算是挑战性的，但也是安全性上的必需。我们提出了一个度量用于评估semantic segmentation模型中每个类型的自信核算质量的指标。它是通过计算每个类型的缩减曲线来计算的，该曲线基于模型的不确定性估算。我们使用这个分类calibration指标来评估不确定性估算方法的自信核算质量，特别是对于下游类型。此外，我们还建议使用这个方法自动找到手动或自动标注数据集中的标签问题，以提高数据集的质量。”
</details></li>
</ul>
<hr>
<h2 id="Improving-Human-Object-Interaction-Detection-via-Virtual-Image-Learning"><a href="#Improving-Human-Object-Interaction-Detection-via-Virtual-Image-Learning" class="headerlink" title="Improving Human-Object Interaction Detection via Virtual Image Learning"></a>Improving Human-Object Interaction Detection via Virtual Image Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02606">http://arxiv.org/abs/2308.02606</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuman Fang, Shuai Liu, Jie Li, Guannan Jiang, Xianming Lin, Rongrong Ji</li>
<li>for: 本文旨在提高人工物交互检测的精度，尤其是对于长尾类别的交互对象。</li>
<li>methods: 本文提出了一种基于虚拟图像学习的方法，包括多步图像生成（MUSIC）和教师学生框架。同时，为了解决虚拟图像的初始标签不准确，提出了一种适应性匹配滤波（AMF）模块。</li>
<li>results: 本文在两个benchmark上实现了显著提高，并取得了新的状态码记录。<details>
<summary>Abstract</summary>
Human-Object Interaction (HOI) detection aims to understand the interactions between humans and objects, which plays a curtail role in high-level semantic understanding tasks. However, most works pursue designing better architectures to learn overall features more efficiently, while ignoring the long-tail nature of interaction-object pair categories. In this paper, we propose to alleviate the impact of such an unbalanced distribution via Virtual Image Leaning (VIL). Firstly, a novel label-to-image approach, Multiple Steps Image Creation (MUSIC), is proposed to create a high-quality dataset that has a consistent distribution with real images. In this stage, virtual images are generated based on prompts with specific characterizations and selected by multi-filtering processes. Secondly, we use both virtual and real images to train the model with the teacher-student framework. Considering the initial labels of some virtual images are inaccurate and inadequate, we devise an Adaptive Matching-and-Filtering (AMF) module to construct pseudo-labels. Our method is independent of the internal structure of HOI detectors, so it can be combined with off-the-shelf methods by training merely 10 additional epochs. With the assistance of our method, multiple methods obtain significant improvements, and new state-of-the-art results are achieved on two benchmarks.
</details>
<details>
<summary>摘要</summary>
人机物交互（HOI）检测目标是理解人与物之间的交互，这对高级 semantic 理解任务起到关键作用。然而，大多数工作强调设计更好的建筑来更有效地学习总体特征。在这篇文章中，我们提议通过虚拟图像学习（VIL）来减轻交互对象分类的长尾分布的影响。首先，我们提出了一种新的标签到图像的方法，称为多步图像创建（MUSIC），以创建一个具有均衡分布的高质量数据集。在这个阶段，虚拟图像通过特定特征的描述和多步过滤进程选择。其次，我们使用虚拟和真实图像来帮助模型在教师-学生框架下学习。由于一些虚拟图像的初始标签不准确和不充分，我们提出了一种适应性匹配和筛选（AMF）模块来构建pseudo标签。我们的方法不依赖HOI检测器的内部结构，因此可以与市面上的方法结合使用，只需要训练10个额外的熬杯。通过我们的方法，多种方法均 obtianed  significan improvements，并在两个标准准点上获得了新的州arameter  Record。
</details></li>
</ul>
<hr>
<h2 id="MSECNet-Accurate-and-Robust-Normal-Estimation-for-3D-Point-Clouds-by-Multi-Scale-Edge-Conditioning"><a href="#MSECNet-Accurate-and-Robust-Normal-Estimation-for-3D-Point-Clouds-by-Multi-Scale-Edge-Conditioning" class="headerlink" title="MSECNet: Accurate and Robust Normal Estimation for 3D Point Clouds by Multi-Scale Edge Conditioning"></a>MSECNet: Accurate and Robust Normal Estimation for 3D Point Clouds by Multi-Scale Edge Conditioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02237">http://arxiv.org/abs/2308.02237</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/martianxiu/MSECNet">https://github.com/martianxiu/MSECNet</a></li>
<li>paper_authors: Haoyi Xiu, Xin Liu, Weimin Wang, Kyoung-Sook Kim, Masashi Matsuoka</li>
<li>for:  surface normals estimation from 3D point clouds, especially in regions with rapidly changing normals</li>
<li>methods:  MSECNet, a novel approach that treats normal variation modeling as an edge detection problem, consisting of a backbone network and a multi-scale edge conditioning (MSEC) stream</li>
<li>results:  outperforms existing methods on both synthetic and real-world datasets while running significantly faster, and demonstrates effectiveness in surface reconstruction<details>
<summary>Abstract</summary>
Estimating surface normals from 3D point clouds is critical for various applications, including surface reconstruction and rendering. While existing methods for normal estimation perform well in regions where normals change slowly, they tend to fail where normals vary rapidly. To address this issue, we propose a novel approach called MSECNet, which improves estimation in normal varying regions by treating normal variation modeling as an edge detection problem. MSECNet consists of a backbone network and a multi-scale edge conditioning (MSEC) stream. The MSEC stream achieves robust edge detection through multi-scale feature fusion and adaptive edge detection. The detected edges are then combined with the output of the backbone network using the edge conditioning module to produce edge-aware representations. Extensive experiments show that MSECNet outperforms existing methods on both synthetic (PCPNet) and real-world (SceneNN) datasets while running significantly faster. We also conduct various analyses to investigate the contribution of each component in the MSEC stream. Finally, we demonstrate the effectiveness of our approach in surface reconstruction.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将三维点云中的表面法向估计作为应用的核心问题，包括表面重建和渲染。现有的normal估计方法在normal变化缓慢地区表现良好，但在normal变化迅速地区时，这些方法往往失败。为解决这问题，我们提出了一种新的方法 called MSECNet，它在normal变化地区进行了改进，并将normal变化模型化为边检测问题。MSECNet包括一个后处网络和一个多尺度边条件（MSEC）流。MSEC流通过多尺度特征融合和自适应边检测来实现Robust的边检测。检测到的边然后与后处网络输出的edge conditioning模块结合，以生成edge-aware表示。广泛的实验显示，MSECNet在PCPNet和SceneNN两个synthetic和实际数据集上具有更高的性能，而且运行速度更快。我们还进行了各种分析，以Investigate MSEC流中每个组件的贡献。最后，我们示出了我们的方法在表面重建中的效果。<</SYS>>
</details></li>
</ul>
<hr>
<h2 id="FB-BEV-BEV-Representation-from-Forward-Backward-View-Transformations"><a href="#FB-BEV-BEV-Representation-from-Forward-Backward-View-Transformations" class="headerlink" title="FB-BEV: BEV Representation from Forward-Backward View Transformations"></a>FB-BEV: BEV Representation from Forward-Backward View Transformations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02236">http://arxiv.org/abs/2308.02236</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nvlabs/fb-bev">https://github.com/nvlabs/fb-bev</a></li>
<li>paper_authors: Zhiqi Li, Zhiding Yu, Wenhai Wang, Anima Anandkumar, Tong Lu, Jose M. Alvarez</li>
<li>for: 本文提出了一种新的视图转换模块，用于改进现有的前向投影和后向投影方法，以提高Camera-based Bird-Eye-View（BEV）识别系统的性能。</li>
<li>methods: 本文使用了两种主要的视图转换方法：前向投影和后向投影。前向投影（Lift-Splat-Shoot）会导致稀疏地投影 BEV 特征，而后向投影（BEVFormer）则可能因深度不准确导致 false-positive BEV 特征。本文提出了一种新的 forward-backward 视图转换模块，用于补做这两种方法的缺陷，以获得更高质量的 BEV 表示。</li>
<li>results: 本文实现了一种新的 FB-BEV 模型，通过将 forward-backward 视图转换模块与 BEVFormer 结合使用，实现了 nuScenes 测试集上的新state-of-the-art 结果，达到 62.4% NDS。代码和模型可以在 <a target="_blank" rel="noopener" href="https://github.com/NVlabs/FB-BEV">https://github.com/NVlabs/FB-BEV</a> 上下载。<details>
<summary>Abstract</summary>
View Transformation Module (VTM), where transformations happen between multi-view image features and Bird-Eye-View (BEV) representation, is a crucial step in camera-based BEV perception systems. Currently, the two most prominent VTM paradigms are forward projection and backward projection. Forward projection, represented by Lift-Splat-Shoot, leads to sparsely projected BEV features without post-processing. Backward projection, with BEVFormer being an example, tends to generate false-positive BEV features from incorrect projections due to the lack of utilization on depth. To address the above limitations, we propose a novel forward-backward view transformation module. Our approach compensates for the deficiencies in both existing methods, allowing them to enhance each other to obtain higher quality BEV representations mutually. We instantiate the proposed module with FB-BEV, which achieves a new state-of-the-art result of 62.4% NDS on the nuScenes test set. Code and models are available at https://github.com/NVlabs/FB-BEV.
</details>
<details>
<summary>摘要</summary>
视图变换模块（VTM），负责将多视图图像特征转换为飞行视图（BEV）表示，是Camera-based BEV感知系统中关键的步骤。目前，最为流行的VTM方法有两种：前 projection和后 projection。前 projection，表示Lift-Splat-Shoot，会导致稀疏地 proyect BEV特征无需后处理。后 projection，如BEVFormer，可能会从错误的投影中生成错误的 BEV特征，因为不利用深度。为了解决以上限制，我们提议一种新的前后视图变换模块。我们的方法可以补做两种现有方法的缺陷，使其互相增强，从而获得更高质量的 BEV表示。我们实现了提议的模块，并实现了FB-BEV，在nuScenes测试集上达到了62.4% NDS的新状态态。代码和模型可以在https://github.com/NVlabs/FB-BEV中下载。
</details></li>
</ul>
<hr>
<h2 id="Painterly-Image-Harmonization-using-Diffusion-Model"><a href="#Painterly-Image-Harmonization-using-Diffusion-Model" class="headerlink" title="Painterly Image Harmonization using Diffusion Model"></a>Painterly Image Harmonization using Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02228">http://arxiv.org/abs/2308.02228</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bcmi/phdiffusion-painterly-image-harmonization">https://github.com/bcmi/phdiffusion-painterly-image-harmonization</a></li>
<li>paper_authors: Lingxiao Lu, Jiangtong Li, Junyan Cao, Li Niu, Liqing Zhang</li>
<li>for: 将 фотографические对象插入画作中并获得艺术一致的复合图像。</li>
<li>methods: 我们提出了一种新的稳定扩散模型（PHDiffusion），它包括一个轻量级适应编码器和一个双编码器融合（DEF）模块。特别是，适应编码器和DEF模块首先在每个编码器中塑造了前景特征。然后，这些塑造后的前景特征从两个编码器中都被组合以导引协调过程。</li>
<li>results: 与相关领域的状态机型相比，我们的PHDiffusion可以更好地塑造前景并同时保留更细的内容。<details>
<summary>Abstract</summary>
Painterly image harmonization aims to insert photographic objects into paintings and obtain artistically coherent composite images. Previous methods for this task mainly rely on inference optimization or generative adversarial network, but they are either very time-consuming or struggling at fine control of the foreground objects (e.g., texture and content details). To address these issues, we propose a novel Painterly Harmonization stable Diffusion model (PHDiffusion), which includes a lightweight adaptive encoder and a Dual Encoder Fusion (DEF) module. Specifically, the adaptive encoder and the DEF module first stylize foreground features within each encoder. Then, the stylized foreground features from both encoders are combined to guide the harmonization process. During training, besides the noise loss in diffusion model, we additionally employ content loss and two style losses, i.e., AdaIN style loss and contrastive style loss, aiming to balance the trade-off between style migration and content preservation. Compared with the state-of-the-art models from related fields, our PHDiffusion can stylize the foreground more sufficiently and simultaneously retain finer content. Our code and model are available at https://github.com/bcmi/PHDiffusion-Painterly-Image-Harmonization.
</details>
<details>
<summary>摘要</summary>
painterly 图像协调的目标是插入 fotografic 对象到画作中并获得艺术一致的复合图像。现有的方法主要基于推理优化或生成敌对网络，但他们是非常占用时间或缺乏细节控制（例如，Texture和内容细节）。为解决这些问题，我们提出了一种新的笔画协调稳定扩散模型（PHDiffusion），它包括一个轻量级适应编码器和双编码器融合（DEF）模块。具体来说，适应编码器和 DEF 模块首先在每个编码器中进行了笔画化前景特征。然后，这些笔画化前景特征从两个编码器中被合并，以指导协调过程。在训练时，我们还采用了内容损失和两种风格损失，即 AdaIN 风格损失和对比风格损失，以努力均衡风格迁移和内容保留。相比之前的相关领域模型，我们的 PHDiffusion 可以更好地笔画前景并同时保留更细的内容。我们的代码和模型可以在 GitHub 上找到：https://github.com/bcmi/PHDiffusion-Painterly-Image-Harmonization。
</details></li>
</ul>
<hr>
<h2 id="Deep-Semantic-Model-Fusion-for-Ancient-Agricultural-Terrace-Detection"><a href="#Deep-Semantic-Model-Fusion-for-Ancient-Agricultural-Terrace-Detection" class="headerlink" title="Deep Semantic Model Fusion for Ancient Agricultural Terrace Detection"></a>Deep Semantic Model Fusion for Ancient Agricultural Terrace Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02225">http://arxiv.org/abs/2308.02225</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangyi111/international-archaeology-ai-challenge">https://github.com/wangyi111/international-archaeology-ai-challenge</a></li>
<li>paper_authors: Yi Wang, Chenying Liu, Arti Tiwari, Micha Silver, Arnon Karnieli, Xiao Xiang Zhu, Conrad M Albrecht</li>
<li>for: 本研究旨在提高古代农业 terrace 的检测和识别效率，使用机器学习技术对古代遗产地区进行自动检测和识别。</li>
<li>methods: 本研究使用了深度semantic模型融合方法，输入数据包括空中图像和LiDAR生成的地形特征，并使用了DeepLabv3+和UNet两种深度semantic segmentation模型，以提取古代 terrace 和墙壕的特征。</li>
<li>results: 提出的方法在国际 AI 考古挑战中获得了第一名，代表了该方法的高效性和可靠性。<details>
<summary>Abstract</summary>
Discovering ancient agricultural terraces in desert regions is important for the monitoring of long-term climate changes on the Earth's surface. However, traditional ground surveys are both costly and limited in scale. With the increasing accessibility of aerial and satellite data, machine learning techniques bear large potential for the automatic detection and recognition of archaeological landscapes. In this paper, we propose a deep semantic model fusion method for ancient agricultural terrace detection. The input data includes aerial images and LiDAR generated terrain features in the Negev desert. Two deep semantic segmentation models, namely DeepLabv3+ and UNet, with EfficientNet backbone, are trained and fused to provide segmentation maps of ancient terraces and walls. The proposed method won the first prize in the International AI Archaeology Challenge. Codes are available at https://github.com/wangyi111/international-archaeology-ai-challenge.
</details>
<details>
<summary>摘要</summary>
发现古代垦殖 terrace 在 desert 地区对地球表面长期气候变化的监测非常重要。然而，传统的地面调查非常昂贵，而且规模有限。随着飞行和卫星数据的更加可 accessible，机器学习技术在自动检测和识别考古遗产中具有大量潜力。在这篇论文中，我们提议一种深度 semantic model fusion 方法，用于古代垦殖 terrace 的检测。输入数据包括飞行图像和 LiDAR 生成的地形特征，位于约旦河谷。我们在 DeepLabv3+ 和 UNet 两种深度 semantic segmentation 模型中使用 EfficientNet 背景，并将其们训练和融合，以生成古代 terrace 和墙壁的分 segmentation 图。该方法在国际 AI 考古挑战中获得了首奖。代码可以在 <https://github.com/wangyi111/international-archaeology-ai-challenge> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Balanced-Classification-A-Unified-Framework-for-Long-Tailed-Object-Detection"><a href="#Balanced-Classification-A-Unified-Framework-for-Long-Tailed-Object-Detection" class="headerlink" title="Balanced Classification: A Unified Framework for Long-Tailed Object Detection"></a>Balanced Classification: A Unified Framework for Long-Tailed Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02213">http://arxiv.org/abs/2308.02213</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tianhao-qi/bacl">https://github.com/tianhao-qi/bacl</a></li>
<li>paper_authors: Tianhao Qi, Hongtao Xie, Pandeng Li, Jiannan Ge, Yongdong Zhang</li>
<li>for: 强调处理长尾数据的抑降性缺陷，提高分类器对异常类别的识别率。</li>
<li>methods: 提出了一种名为Balanced Classification（BACL）的统一框架，通过自适应地正则化分类器的竞争性和动态增强样本多样性来解决这些问题。特别是，开发了一种新的前景分类均衡损失函数（FCBL），以便更好地平衡前景类别的竞争，并避免压抑尾类别。此外，提出了一种动态特征幻化模块（FHM），通过合成幻化样本来增加特征空间中的数据变化。</li>
<li>results: 在CVPR2020 LVIS数据集上，BACL与基于ResNet-50-FPN的标准Faster R-CNN相比，提高了5.8% AP和16.1% AP的性能，并在不同的数据集和结构上进行了广泛的实验，都表现出了性能改进。<details>
<summary>Abstract</summary>
Conventional detectors suffer from performance degradation when dealing with long-tailed data due to a classification bias towards the majority head categories. In this paper, we contend that the learning bias originates from two factors: 1) the unequal competition arising from the imbalanced distribution of foreground categories, and 2) the lack of sample diversity in tail categories. To tackle these issues, we introduce a unified framework called BAlanced CLassification (BACL), which enables adaptive rectification of inequalities caused by disparities in category distribution and dynamic intensification of sample diversities in a synchronized manner. Specifically, a novel foreground classification balance loss (FCBL) is developed to ameliorate the domination of head categories and shift attention to difficult-to-differentiate categories by introducing pairwise class-aware margins and auto-adjusted weight terms, respectively. This loss prevents the over-suppression of tail categories in the context of unequal competition. Moreover, we propose a dynamic feature hallucination module (FHM), which enhances the representation of tail categories in the feature space by synthesizing hallucinated samples to introduce additional data variances. In this divide-and-conquer approach, BACL sets a new state-of-the-art on the challenging LVIS benchmark with a decoupled training pipeline, surpassing vanilla Faster R-CNN with ResNet-50-FPN by 5.8% AP and 16.1% AP for overall and tail categories. Extensive experiments demonstrate that BACL consistently achieves performance improvements across various datasets with different backbones and architectures. Code and models are available at https://github.com/Tianhao-Qi/BACL.
</details>
<details>
<summary>摘要</summary>
传统探测器在处理长尾数据时会出现性能下降，这是因为探测器受到多类别头部的分类偏好。在这篇论文中，我们认为这种学习偏好来自两个因素：1）分类 distribu-tion 不均衡，2）尾类别样本缺乏多样性。为解决这些问题，我们提出了一个统一框架，即 Balanced Classification（BACL），它可以同步地修正由分类 distribu-tion 不均衡所引起的不平等，并强制tail类别样本的多样性。在BACL框架中，我们提出了一种新的前景分类均衡损失函数（FCBL），用于改善头部类别的Domination，并增强难以区分的类别的 Representation。FCBL使用对类别之间的对比margin和自适应权重项，从而避免尾类别在不平等环境中的过度压抑。此外，我们还提出了一种动态特征幻化模块（FHM），用于增强尾类别在特征空间中的表示。在这种分治策略中，BACL在LCVIS数据集上实现了新的状态态-of-the-art，超过了基于ResNet-50-FPN的标准Faster R-CNN的5.8% AP和16.1% AP。我们在多个数据集和不同的后端和架构上进行了广泛的实验，并证明了BACL在不同的环境下都能够实现性能提高。代码和模型可以在https://github.com/Tianhao-Qi/BACL上下载。
</details></li>
</ul>
<hr>
<h2 id="Paired-Competing-Neurons-Improving-STDP-Supervised-Local-Learning-In-Spiking-Neural-Networks"><a href="#Paired-Competing-Neurons-Improving-STDP-Supervised-Local-Learning-In-Spiking-Neural-Networks" class="headerlink" title="Paired Competing Neurons Improving STDP Supervised Local Learning In Spiking Neural Networks"></a>Paired Competing Neurons Improving STDP Supervised Local Learning In Spiking Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02194">http://arxiv.org/abs/2308.02194</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gaspard Goupy, Pierre Tirilly, Ioan Marius Bilasco</li>
<li>for: 这 paper 的目的是提出一种基于 SNN 的图像识别方法，以减少 ANN 训练过程中的高能耗。</li>
<li>methods: 该 paper 使用了 Spike Timing-Dependent Plasticity (STDP) 作为本 статьи的学习规则，并提出了一种名为 Stabilized Supervised STDP (S2-STDP) 的监督学习规则，以train 图像识别层。同时，paper 还提出了一种名为 Paired Competing Neurons (PCN) 的训练架构，以进一步增强图像识别层的学习能力。</li>
<li>results: results 表明，该 paper 的方法可以与现有的监督 STDP 基本相同的架构和 neuron 数量进行比较，并且在 MNIST、Fashion-MNIST 和 CIFAR-10 等图像识别 datasets 上达到了更高的性能。同时，PCN 对 S2-STDP 的使用也有进一步提高图像识别层的性能的效果，无需调整任何超参数。进一步分析还表明，该方法具有更好的超参数Robustness，减少了训练过程中的调整次数。<details>
<summary>Abstract</summary>
Direct training of Spiking Neural Networks (SNNs) on neuromorphic hardware has the potential to significantly reduce the high energy consumption of Artificial Neural Networks (ANNs) training on modern computers. The biological plausibility of SNNs allows them to benefit from bio-inspired plasticity rules, such as Spike Timing-Dependent Plasticity (STDP). STDP offers gradient-free and unsupervised local learning, which can be easily implemented on neuromorphic hardware. However, relying solely on unsupervised STDP to perform classification tasks is not enough. In this paper, we propose Stabilized Supervised STDP (S2-STDP), a supervised STDP learning rule to train the classification layer of an SNN equipped with unsupervised STDP. S2-STDP integrates error-modulated weight updates that align neuron spikes with desired timestamps derived from the average firing time within the layer. Then, we introduce a training architecture called Paired Competing Neurons (PCN) to further enhance the learning capabilities of our classification layer trained with S2-STDP. PCN associates each class with paired neurons and encourages neuron specialization through intra-class competition. We evaluated our proposed methods on image recognition datasets, including MNIST, Fashion-MNIST, and CIFAR-10. Results showed that our methods outperform current supervised STDP-based state of the art, for comparable architectures and numbers of neurons. Also, the use of PCN enhances the performance of S2-STDP, regardless of the configuration, and without introducing any hyperparameters.Further analysis demonstrated that our methods exhibited improved hyperparameter robustness, which reduces the need for tuning.
</details>
<details>
<summary>摘要</summary>
直接训练神经网络（SNN）在神经模仿硬件上有可能大幅降低人工神经网络（ANNs）训练在现代计算机上的高能耗。生物可能性让SNN受益于生物灵感的пластичность规则，如电声相互作用（STDP）。STDP提供了无梯度和无监督的本地学习，可以轻松实现在神经模仿硬件上。然而，仅仅通过不监督的STDP来完成分类任务并不够。在这篇论文中，我们提出了稳定化supervised STDP（S2-STDP），一种监督STDP学习规则，用于训练SNN的分类层。S2-STDP将电声射频更新策略与 neuron 射频相互作用，以实现更稳定和有效的学习。然后，我们引入了一种叫做Paired Competing Neurons（PCN）的训练架构，以进一步增强我们的分类层的学习能力。PCN将每个类别与对应的两个神经元相关联，并且鼓励神经元特化通过类内竞争。我们在MNIST、Fashion-MNIST和CIFAR-10等图像识别数据集上评估了我们的方法。结果显示，我们的方法在相同的架构和神经元数量下，超过了当前supervised STDP基eline的性能。此外，PCN的使用可以在不同的配置下，提高S2-STDP的性能，而无需调整任何超参数。进一步分析表明，我们的方法具有改善的超参数鲁棒性，减少了调整的需求。
</details></li>
</ul>
<hr>
<h2 id="ES-MVSNet-Efficient-Framework-for-End-to-end-Self-supervised-Multi-View-Stereo"><a href="#ES-MVSNet-Efficient-Framework-for-End-to-end-Self-supervised-Multi-View-Stereo" class="headerlink" title="ES-MVSNet: Efficient Framework for End-to-end Self-supervised Multi-View Stereo"></a>ES-MVSNet: Efficient Framework for End-to-end Self-supervised Multi-View Stereo</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02191">http://arxiv.org/abs/2308.02191</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiang Zhou, Chaohui Yu, Jingliang Li, Yuang Liu, Jing Wang, Zhibin Wang</li>
<li>for: 提出了一种高效的终端到终端自动多视角摄影增强方法，以解决现有终端自动多视角摄影方法中的高内存消耗问题。</li>
<li>methods: 提出了一种具有内存减少43%的终端自动多视角摄影模型，并通过不同视角选择策略和区域准确深度一致性来提高模型性能。</li>
<li>results: 在DTU和Tanks&amp;Temples benchmark上进行了广泛的实验，并证明了提出的ES-MVSNet方法可以在终端自动多视角摄影领域实现最佳性能，并与许多超级vised和多Stage自动多视角摄影方法竞争。<details>
<summary>Abstract</summary>
Compared to the multi-stage self-supervised multi-view stereo (MVS) method, the end-to-end (E2E) approach has received more attention due to its concise and efficient training pipeline. Recent E2E self-supervised MVS approaches have integrated third-party models (such as optical flow models, semantic segmentation models, NeRF models, etc.) to provide additional consistency constraints, which grows GPU memory consumption and complicates the model's structure and training pipeline. In this work, we propose an efficient framework for end-to-end self-supervised MVS, dubbed ES-MVSNet. To alleviate the high memory consumption of current E2E self-supervised MVS frameworks, we present a memory-efficient architecture that reduces memory usage by 43% without compromising model performance. Furthermore, with the novel design of asymmetric view selection policy and region-aware depth consistency, we achieve state-of-the-art performance among E2E self-supervised MVS methods, without relying on third-party models for additional consistency signals. Extensive experiments on DTU and Tanks&Temples benchmarks demonstrate that the proposed ES-MVSNet approach achieves state-of-the-art performance among E2E self-supervised MVS methods and competitive performance to many supervised and multi-stage self-supervised methods.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:与多stage自动规范多视图零抽象（MVS）方法相比，端到端（E2E）方法得到了更多的关注，因为它的训练管道更简洁和高效。现在的E2E自我监督MVS方法通常将第三方模型（如光流模型、semantic排序模型、NeRF模型等）integrated into the model to provide additional consistency constraints, which leads to increased GPU memory consumption and a more complex model structure and training pipeline. In this work, we propose an efficient framework for end-to-end self-supervised MVS, called ES-MVSNet. To alleviate the high memory consumption of current E2E self-supervised MVS frameworks, we present a memory-efficient architecture that reduces memory usage by 43% without compromising model performance. Furthermore, with the novel design of asymmetric view selection policy and region-aware depth consistency, we achieve state-of-the-art performance among E2E self-supervised MVS methods, without relying on third-party models for additional consistency signals. 经验表明，提出的ES-MVSNet方法在DTU和Tanks&Temples标准benchmark上实现了E2E自我监督MVS方法的state-of-the-art性和多supervised和多stage自动规范方法的竞争性。
</details></li>
</ul>
<hr>
<h2 id="Synthetic-outlier-generation-for-anomaly-detection-in-autonomous-driving"><a href="#Synthetic-outlier-generation-for-anomaly-detection-in-autonomous-driving" class="headerlink" title="Synthetic outlier generation for anomaly detection in autonomous driving"></a>Synthetic outlier generation for anomaly detection in autonomous driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02184">http://arxiv.org/abs/2308.02184</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martin Bikandi, Gorka Velez, Naiara Aginako, Itziar Irigoien</li>
<li>for: 这个研究的目的是提高自驾车中的异常检测性能，以避免安全重要的意外事件。</li>
<li>methods: 这个研究使用了 modifying the training stage of the state-of-the-art DenseHybrid model, 以及 proposing a simplified detector.</li>
<li>results: 研究获得了 significant performance improvements in anomaly detection, 并且 proposed detector 可以与 modified DenseHybrid approach 相比，而且也超过了原始 DenseHybrid 模型的性能。<details>
<summary>Abstract</summary>
Anomaly detection, or outlier detection, is a crucial task in various domains to identify instances that significantly deviate from established patterns or the majority of data. In the context of autonomous driving, the identification of anomalies is particularly important to prevent safety-critical incidents, as deep learning models often exhibit overconfidence in anomalous or outlier samples. In this study, we explore different strategies for training an image semantic segmentation model with an anomaly detection module. By introducing modifications to the training stage of the state-of-the-art DenseHybrid model, we achieve significant performance improvements in anomaly detection. Moreover, we propose a simplified detector that achieves comparable results to our modified DenseHybrid approach, while also surpassing the performance of the original DenseHybrid model. These findings demonstrate the efficacy of our proposed strategies for enhancing anomaly detection in the context of autonomous driving.
</details>
<details>
<summary>摘要</summary>
anomaly detection，或者异常检测，是在不同领域中找到与Established patterns或主要数据分布不匹配的情况的关键任务。在自动驾驶领域中，异常检测的identification是非常重要，因为深度学习模型经常对异常或异常样本表现出过自信。在这种研究中，我们探索了不同的方法来训练一个图像semantic segmentation模型，并在训练阶段引入了一些修改以提高异常检测性能。此外，我们提出了一种简化的检测器，可以与我们修改的DenseHybrid模型相比，并且在性能上超过了原始DenseHybrid模型。这些发现表明了我们提出的策略对自动驾驶中异常检测具有效果。
</details></li>
</ul>
<hr>
<h2 id="Scene-aware-Human-Pose-Generation-using-Transformer"><a href="#Scene-aware-Human-Pose-Generation-using-Transformer" class="headerlink" title="Scene-aware Human Pose Generation using Transformer"></a>Scene-aware Human Pose Generation using Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02177">http://arxiv.org/abs/2308.02177</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jieteng Yao, Junjie Chen, Li Niu, Bin Sheng</li>
<li>for:  scene understanding and intelligent robotics</li>
<li>methods: template-based human pose generation, interaction between query embeddings and scene feature map, knowledge distillation</li>
<li>results: effective prediction of scale and offsets for each pose template, demonstrated effectiveness on Sitcom dataset<details>
<summary>Abstract</summary>
Affordance learning considers the interaction opportunities for an actor in the scene and thus has wide application in scene understanding and intelligent robotics. In this paper, we focus on contextual affordance learning, i.e., using affordance as context to generate a reasonable human pose in a scene. Existing scene-aware human pose generation methods could be divided into two categories depending on whether using pose templates. Our proposed method belongs to the template-based category, which benefits from the representative pose templates. Moreover, inspired by recent transformer-based methods, we associate each query embedding with a pose template, and use the interaction between query embeddings and scene feature map to effectively predict the scale and offsets for each pose template. In addition, we employ knowledge distillation to facilitate the offset learning given the predicted scale. Comprehensive experiments on Sitcom dataset demonstrate the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
<<SYS>>scene理解和智能机器人中的人 pose生成方法的学习，我们将关注场景上的可行性学习，即通过场景来生成合理的人姿。现有的场景意识人姿生成方法可以分为两类：不使用pose模板和使用pose模板两类。我们的提议方法属于使用pose模板的类别，受益于代表性的pose模板。此外，受到最近的transformer基本方法的启发，我们将每个查询嵌入与场景特征图的交互用来有效地预测每个pose模板的尺度和偏移。此外，我们还使用知识传播来促进偏移学习。对于Sitcom数据集的全面实验，我们证明了我们的方法的有效性。<</SYS>>
</details></li>
</ul>
<hr>
<h2 id="Efficient-Labelling-of-Affective-Video-Datasets-via-Few-Shot-Multi-Task-Contrastive-Learning"><a href="#Efficient-Labelling-of-Affective-Video-Datasets-via-Few-Shot-Multi-Task-Contrastive-Learning" class="headerlink" title="Efficient Labelling of Affective Video Datasets via Few-Shot &amp; Multi-Task Contrastive Learning"></a>Efficient Labelling of Affective Video Datasets via Few-Shot &amp; Multi-Task Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02173">http://arxiv.org/abs/2308.02173</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ravikiranrao/mtclar-fsl">https://github.com/ravikiranrao/mtclar-fsl</a></li>
<li>paper_authors: Ravikiran Parameshwara, Ibrahim Radwan, Akshay Asthana, Iman Abbasnejad, Ramanathan Subramanian, Roland Goecke</li>
<li>for: 这个论文旨在提出一种基于多任务对照学习的方法，用于减少深度学习模型需要的标注数据量，以提高情绪预测的精度。</li>
<li>methods: 该方法称为多任务对照学习 для情绪表示（MT-CLAR），它使用了一个SIAMESE网络，通过对照学习来学习从两个表情图像对的不同之处，以及这两个图像的情绪水平之异。</li>
<li>results: 实验结果显示，MT-CLAR可以在AFEW-VA数据集上达到与状态之巅相当的情绪预测性能，而且与支持集的大小相比，MT-CLAR可以大幅提高情绪预测的精度。<details>
<summary>Abstract</summary>
Whilst deep learning techniques have achieved excellent emotion prediction, they still require large amounts of labelled training data, which are (a) onerous and tedious to compile, and (b) prone to errors and biases. We propose Multi-Task Contrastive Learning for Affect Representation (\textbf{MT-CLAR}) for few-shot affect inference. MT-CLAR combines multi-task learning with a Siamese network trained via contrastive learning to infer from a pair of expressive facial images (a) the (dis)similarity between the facial expressions, and (b) the difference in valence and arousal levels of the two faces. We further extend the image-based MT-CLAR framework for automated video labelling where, given one or a few labelled video frames (termed \textit{support-set}), MT-CLAR labels the remainder of the video for valence and arousal. Experiments are performed on the AFEW-VA dataset with multiple support-set configurations; moreover, supervised learning on representations learnt via MT-CLAR are used for valence, arousal and categorical emotion prediction on the AffectNet and AFEW-VA datasets. The results show that valence and arousal predictions via MT-CLAR are very comparable to the state-of-the-art (SOTA), and we significantly outperform SOTA with a support-set $\approx$6\% the size of the video dataset.
</details>
<details>
<summary>摘要</summary>
而深度学习技术已经实现了出色的情感预测，但它们仍需要大量标注训练数据，这些数据是（a）困难和繁琐准备，以及（b）容易出现错误和偏见。我们提出了多任务对照学习 для情感表示(\textbf{MT-CLAR})，用于几个shot情感预测。MT-CLAR将多任务学习与对照学习相结合，通过对两个表达性脸部图像进行比较，推断两个脸部图像之间的（不）相似性，以及两个脸部图像的情感强度水平之间的差异。我们还扩展了基于图像的MT-CLAR框架，用于自动化视频标注，给定一个或几个标注过的视频帧（称为\textit{支持集}），MT-CLAR将视频中剩下的所有帧标注为情感强度和激动度水平。我们在AFEW-VA数据集上进行了多种支持集配置的实验，并使用MT-CLAR学习的表示进行情感预测，包括情感强度、激动度和 categorical emotion预测。结果显示，MT-CLAR在情感预测中的值和激动度预测与状态之前（SOTA）几乎相同，而且我们在支持集大小为6%的视频数据集上显著超越SOTA。
</details></li>
</ul>
<hr>
<h2 id="Learning-Referring-Video-Object-Segmentation-from-Weak-Annotation"><a href="#Learning-Referring-Video-Object-Segmentation-from-Weak-Annotation" class="headerlink" title="Learning Referring Video Object Segmentation from Weak Annotation"></a>Learning Referring Video Object Segmentation from Weak Annotation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02162">http://arxiv.org/abs/2308.02162</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wangbo Zhao, Kepan Nan, Songyang Zhang, Kai Chen, Dahua Lin, Yang You</li>
<li>for: 本研究旨在开发一种可以在视频帧中 segment 目标对象，而无需投入大量标注数据的方法。</li>
<li>methods: 我们提出了一种新的标注方案，其中在目标对象出现的第一帧中使用 маска 标注，并在后续帧中使用 bounding box。我们还设计了一种跨帧 segmentation 方法，使用语言指导的动态滤波器，以全面利用有价值的mask标注和 bounding box。另外，我们还开发了一种二级对比学习方法，以促进模型学习精细的像素表示。</li>
<li>results: 我们的方法可以在不需要密集标注的情况下实现竞争力强的 segmentation 性能。经过广泛的实验和ablative分析，我们的方法在不同的 dataset 上都表现出了优秀的result。<details>
<summary>Abstract</summary>
Referring video object segmentation (RVOS) is a task that aims to segment the target object in all video frames based on a sentence describing the object. Previous RVOS methods have achieved significant performance with densely-annotated datasets, whose construction is expensive and time-consuming. To relieve the burden of data annotation while maintaining sufficient supervision for segmentation, we propose a new annotation scheme, in which we label the frame where the object first appears with a mask and use bounding boxes for the subsequent frames. Based on this scheme, we propose a method to learn from this weak annotation. Specifically, we design a cross frame segmentation method, which uses the language-guided dynamic filters to thoroughly leverage the valuable mask annotation and bounding boxes. We further develop a bi-level contrastive learning method to encourage the model to learn discriminative representation at the pixel level. Extensive experiments and ablative analyses show that our method is able to achieve competitive performance without the demand of dense mask annotation. The code will be available at https://github.com/wangbo-zhao/WRVOS/.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用 Referring video object segmentation (RVOS) 任务，目标是在所有视频帧中基于一句描述对象进行对象分割。先前的 RVOS 方法已经在 densely-annotated 数据集上达到了显著性能，但是构建这些数据集是贵重的和时间consuming。为了减轻数据标注的负担而不失去分割的足够supervision，我们提议一种新的标注方案，在该方案中，我们将第一帧中的对象批注为Mask，并使用 bounding boxes 来标注后续帧。基于这种方案，我们提议一种从weak annotation学习的方法。我们设计了一种 across frame segmentation 方法，使用语言导向的动态滤波器，以完全利用valuable的批注和 bounding boxes。我们还开发了一种 bi-level 对比学习方法，以促进模型学习精细的像素表示。广泛的实验和ablative 分析表明，我们的方法可以在无需厚度的批注下实现竞争性的性能。代码将在 https://github.com/wangbo-zhao/WRVOS/ 上发布。
</details></li>
</ul>
<hr>
<h2 id="M2Former-Multi-Scale-Patch-Selection-for-Fine-Grained-Visual-Recognition"><a href="#M2Former-Multi-Scale-Patch-Selection-for-Fine-Grained-Visual-Recognition" class="headerlink" title="M2Former: Multi-Scale Patch Selection for Fine-Grained Visual Recognition"></a>M2Former: Multi-Scale Patch Selection for Fine-Grained Visual Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02161">http://arxiv.org/abs/2308.02161</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiyong Moon, Junseok Lee, Yunju Lee, Seongsik Park</li>
<li>for: 提高 fine-grained visual recognition (FGVR) 模型的多尺度能力。</li>
<li>methods: 利用 multi-scale patch selection (MSPS) 和 class token transfer (CTT) 以及 multi-scale cross-attention (MSCA) 来提高模型的多尺度表示能力和权重学习能力。</li>
<li>results: 比前一代单尺度 patch selection (SSPS) 提高表达能力和性能，在多种广泛使用的 FGVR benchmark 上达到了新的高点。<details>
<summary>Abstract</summary>
Recently, vision Transformers (ViTs) have been actively applied to fine-grained visual recognition (FGVR). ViT can effectively model the interdependencies between patch-divided object regions through an inherent self-attention mechanism. In addition, patch selection is used with ViT to remove redundant patch information and highlight the most discriminative object patches. However, existing ViT-based FGVR models are limited to single-scale processing, and their fixed receptive fields hinder representational richness and exacerbate vulnerability to scale variability. Therefore, we propose multi-scale patch selection (MSPS) to improve the multi-scale capabilities of existing ViT-based models. Specifically, MSPS selects salient patches of different scales at different stages of a multi-scale vision Transformer (MS-ViT). In addition, we introduce class token transfer (CTT) and multi-scale cross-attention (MSCA) to model cross-scale interactions between selected multi-scale patches and fully reflect them in model decisions. Compared to previous single-scale patch selection (SSPS), our proposed MSPS encourages richer object representations based on feature hierarchy and consistently improves performance from small-sized to large-sized objects. As a result, we propose M2Former, which outperforms CNN-/ViT-based models on several widely used FGVR benchmarks.
</details>
<details>
<summary>摘要</summary>
最近，视觉变换器（ViT）已经活跃地应用于细腻视识别（FGVR）。ViT可以有效地模型分割后的对象区域之间的相互依赖关系，通过自然的自注意机制。此外，patch选择被用于ViT，以除去重复的patch信息并强调最重要的对象patch。然而，现有的ViT基于的FGVR模型受到一个固定的见识场所限制，这限制了表达的丰富性和对比例变化的抗性。因此，我们提出了多比例 patch选择（MSPS），以改进现有的ViT基于模型的多比例能力。具体来说，MSPS在不同的级别上选择不同的比例的patch，并在不同的阶段使用多比例视Transformer（MS-ViT）来模型交叉的多比例关系。此外，我们引入了类token传递（CTT）和多比例交叉注意（MSCA），以便充分反映交叉的多比例关系，并将其纳入模型决策中。相比之下，单比例patch选择（SSPS）只能在固定的比例下进行选择，从而封锁了表达的层次结构和对比例变化的能力。因此，我们提出了M2Former，它在多个普遍使用的FGVR标准benchmark上表现出色，并且超越了基于CNN和ViT的模型。
</details></li>
</ul>
<hr>
<h2 id="CTP-Net-Character-Texture-Perception-Network-for-Document-Image-Forgery-Localization"><a href="#CTP-Net-Character-Texture-Perception-Network-for-Document-Image-Forgery-Localization" class="headerlink" title="CTP-Net: Character Texture Perception Network for Document Image Forgery Localization"></a>CTP-Net: Character Texture Perception Network for Document Image Forgery Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02158">http://arxiv.org/abs/2308.02158</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Liao, Siliang Chen, Jiaxin Chen, Tianyi Wang, Xiehua Li</li>
<li>for: 本研究旨在提高文档图像的伪造探测精度，提出一种基于Character Texture Perception Network（CTP-Net）的文档图像伪造探测方法。</li>
<li>methods: 该方法首先设计了一个Character Texture Stream（CTS），通过光学字符识别技术捕捉文档图像中文本区域的特征。同时，图像全像的文本特征也被利用Image Texture Stream（ITS）捕捉。然后，CTP-Net将CTS和ITS中提取的特征进行组合，以探测文档图像中的伪造 trace。</li>
<li>results: 实验结果表明，CPT-Net可以准确地探测文档图像中的多尺度伪造区域，并且在不同的数据集上表现出excel。此外，为了解决因缺少伪造文档图像而导致的挑战，该研究还提出了一种数据生成策略，用于构建一个Fake Chinese Trademark数据集（FCTM）。<details>
<summary>Abstract</summary>
Due to the progression of information technology in recent years, document images have been widely disseminated on social networks. With the help of powerful image editing tools, document images are easily forged without leaving visible manipulation traces, which leads to severe issues if significant information is falsified for malicious use. Therefore, the research of document image forensics is worth further exploring. In this paper, we propose a Character Texture Perception Network (CTP-Net) to localize the forged regions in document images. Specifically, considering the characters with semantics in a document image are highly vulnerable, capturing the forgery traces is the key to localize the forged regions. We design a Character Texture Stream (CTS) based on optical character recognition to capture features of text areas that are essential components of a document image. Meanwhile, texture features of the whole document image are exploited by an Image Texture Stream (ITS). Combining the features extracted from the CTS and the ITS, the CTP-Net can reveal more subtle forgery traces from document images. Moreover, to overcome the challenge caused by the lack of fake document images, we design a data generation strategy that is utilized to construct a Fake Chinese Trademark dataset (FCTM). Experimental results on different datasets demonstrate that the proposed CTP-Net is able to localize multi-scale forged areas in document images, and outperform the state-of-the-art forgery localization methods, even though post-processing operations are applied.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SDDM-Score-Decomposed-Diffusion-Models-on-Manifolds-for-Unpaired-Image-to-Image-Translation"><a href="#SDDM-Score-Decomposed-Diffusion-Models-on-Manifolds-for-Unpaired-Image-to-Image-Translation" class="headerlink" title="SDDM: Score-Decomposed Diffusion Models on Manifolds for Unpaired Image-to-Image Translation"></a>SDDM: Score-Decomposed Diffusion Models on Manifolds for Unpaired Image-to-Image Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02154">http://arxiv.org/abs/2308.02154</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shikun Sun, Longhui Wei, Junliang Xing, Jia Jia, Qi Tian</li>
<li>for: 这种新的分解 diffusion model (SDDM) 是为了Explicitly optimize the tangled distributions during image generation.</li>
<li>methods: SDDM 使用 manifold 来分解 score function 或 energy guidance into an image “denoising” part and a content “refinement” part.</li>
<li>results: SDDM 可以在 fewer diffusion steps 中比 existing SBDM-based methods 表现出更好的效果 on several I2I benchmarks.I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Recent score-based diffusion models (SBDMs) show promising results in unpaired image-to-image translation (I2I). However, existing methods, either energy-based or statistically-based, provide no explicit form of the interfered intermediate generative distributions. This work presents a new score-decomposed diffusion model (SDDM) on manifolds to explicitly optimize the tangled distributions during image generation. SDDM derives manifolds to make the distributions of adjacent time steps separable and decompose the score function or energy guidance into an image ``denoising" part and a content ``refinement" part. To refine the image in the same noise level, we equalize the refinement parts of the score function and energy guidance, which permits multi-objective optimization on the manifold. We also leverage the block adaptive instance normalization module to construct manifolds with lower dimensions but still concentrated with the perturbed reference image. SDDM outperforms existing SBDM-based methods with much fewer diffusion steps on several I2I benchmarks.
</details>
<details>
<summary>摘要</summary>
现代分数基 diffusion 模型（SBDM）在无对照图像至图像翻译（I2I）中显示出了有前途的成绩。然而，现有的方法，可能是能量基或统计基的，没有直接提供杂乱的中间生成分布的显式形式。本工作提出了一种新的分数 decomposed diffusion model（SDDM），该模型在抽象上分解了分数函数或能量导航的杂乱部分，并在图像生成过程中显式优化这些分布。为了在同一个噪音水平上细化图像，我们将图像“净化”部分和内容“精度”部分的分数函数和能量导航的平衡化，从而实现多目标优化在抽象上。此外，我们还利用了块适应性的实例normalization模块来构建抽象上的低维度拟合分布，以便更好地翻译图像。 SDDM 在多个 I2I 测试准则上表现出了较好的成绩，并且只需要比较少的扩散步数。
</details></li>
</ul>
<hr>
<h2 id="Robust-Self-Supervised-Extrinsic-Self-Calibration"><a href="#Robust-Self-Supervised-Extrinsic-Self-Calibration" class="headerlink" title="Robust Self-Supervised Extrinsic Self-Calibration"></a>Robust Self-Supervised Extrinsic Self-Calibration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02153">http://arxiv.org/abs/2308.02153</a></li>
<li>repo_url: None</li>
<li>paper_authors: Takayuki Kanai, Igor Vasiljevic, Vitor Guizilini, Adrien Gaidon, Rares Ambrus<br>for:自动驾驶和机器人需要在多种场景中运行，以完成任务高效和安全。methods:我们提出了一种基于自我超视觉学习的新方法，即使无需其他传感器，可以高效和准确地进行外部约束。我们的方法使用彩色视频中的单目深度和pose估计器，并在运动视频中提供速度监视，以便估计外部约束。results:我们的方法在一个多摄像头数据集（DDAD）上进行了实验，并证明了在不同场景中可以Robustly和高效地进行自我约束，而不需要传感器。此外，我们还证明了在depth预测中使用外部约束可以提高深度预测的准确性。<details>
<summary>Abstract</summary>
Autonomous vehicles and robots need to operate over a wide variety of scenarios in order to complete tasks efficiently and safely. Multi-camera self-supervised monocular depth estimation from videos is a promising way to reason about the environment, as it generates metrically scaled geometric predictions from visual data without requiring additional sensors. However, most works assume well-calibrated extrinsics to fully leverage this multi-camera setup, even though accurate and efficient calibration is still a challenging problem. In this work, we introduce a novel method for extrinsic calibration that builds upon the principles of self-supervised monocular depth and ego-motion learning. Our proposed curriculum learning strategy uses monocular depth and pose estimators with velocity supervision to estimate extrinsics, and then jointly learns extrinsic calibration along with depth and pose for a set of overlapping cameras rigidly attached to a moving vehicle. Experiments on a benchmark multi-camera dataset (DDAD) demonstrate that our method enables self-calibration in various scenes robustly and efficiently compared to a traditional vision-based pose estimation pipeline. Furthermore, we demonstrate the benefits of extrinsics self-calibration as a way to improve depth prediction via joint optimization.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Attention-Driven-Lightweight-Model-for-Pigmented-Skin-Lesion-Detection"><a href="#Attention-Driven-Lightweight-Model-for-Pigmented-Skin-Lesion-Detection" class="headerlink" title="Attention-Driven Lightweight Model for Pigmented Skin Lesion Detection"></a>Attention-Driven Lightweight Model for Pigmented Skin Lesion Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02119">http://arxiv.org/abs/2308.02119</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingzhe Hu, Xiaofeng Yang<br>for:This paper presents a lightweight pipeline for skin lesion detection, addressing the challenges of imbalanced class distribution and subtle or atypical appearances of some lesions.methods:The pipeline uses a lightweight model that leverages ghosted features and the DFC attention mechanism to reduce computational complexity while maintaining high performance. The model was trained on the HAM10000 dataset, which includes various types of skin lesions, and incorporates a knowledge-based loss weighting technique to address class imbalance.results:The model achieved an accuracy of 92.4%, a precision of 84.2%, a recall of 86.9%, and a f1-score of 85.4%, with particularly strong performance in identifying Benign Keratosis-like lesions (BKL) and Nevus (NV). Despite its superior performance, the model’s computational cost is considerably lower than some models with less accuracy, making it an optimal solution for real-world applications where both accuracy and efficiency are essential.<details>
<summary>Abstract</summary>
This study presents a lightweight pipeline for skin lesion detection, addressing the challenges posed by imbalanced class distribution and subtle or atypical appearances of some lesions. The pipeline is built around a lightweight model that leverages ghosted features and the DFC attention mechanism to reduce computational complexity while maintaining high performance. The model was trained on the HAM10000 dataset, which includes various types of skin lesions. To address the class imbalance in the dataset, the synthetic minority over-sampling technique and various image augmentation techniques were used. The model also incorporates a knowledge-based loss weighting technique, which assigns different weights to the loss function at the class level and the instance level, helping the model focus on minority classes and challenging samples. This technique involves assigning different weights to the loss function on two levels - the class level and the instance level. By applying appropriate loss weights, the model pays more attention to the minority classes and challenging samples, thus improving its ability to correctly detect and classify different skin lesions. The model achieved an accuracy of 92.4%, a precision of 84.2%, a recall of 86.9%, a f1-score of 85.4% with particularly strong performance in identifying Benign Keratosis-like lesions (BKL) and Nevus (NV). Despite its superior performance, the model's computational cost is considerably lower than some models with less accuracy, making it an optimal solution for real-world applications where both accuracy and efficiency are essential.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Rethinking-Class-Activation-Maps-for-Segmentation-Revealing-Semantic-Information-in-Shallow-Layers-by-Reducing-Noise"><a href="#Rethinking-Class-Activation-Maps-for-Segmentation-Revealing-Semantic-Information-in-Shallow-Layers-by-Reducing-Noise" class="headerlink" title="Rethinking Class Activation Maps for Segmentation: Revealing Semantic Information in Shallow Layers by Reducing Noise"></a>Rethinking Class Activation Maps for Segmentation: Revealing Semantic Information in Shallow Layers by Reducing Noise</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02118">http://arxiv.org/abs/2308.02118</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hang-Cheng Dong, Yuhao Jiang, Yingyan Huang, Jingxiao Liao, Bingguo Liu, Dong Ye, Guodong Liu</li>
<li>for: 这篇论文旨在提高深度神经网络中的分类激活图的质量，以便在无监督学习中获得更高的性能。</li>
<li>methods: 本文提出了一种简单的梯度基于的减噪方法，可以用于过滤非目标噪声，从而提高分类激活图的质量。</li>
<li>results: 经过大量实验 validate 的结果表明，该方法可以提高无监督 semantic segmentation 任务中的性能。<details>
<summary>Abstract</summary>
Class activation maps are widely used for explaining deep neural networks. Due to its ability to highlight regions of interest, it has evolved in recent years as a key step in weakly supervised learning. A major limitation to the performance of the class activation maps is the small spatial resolution of the feature maps in the last layer of the convolutional neural network. Therefore, we expect to generate high-resolution feature maps that result in high-quality semantic information. In this paper, we rethink the properties of semantic information in shallow feature maps. We find that the shallow feature maps still have fine-grained non-discriminative features while mixing considerable non-target noise. Furthermore, we propose a simple gradient-based denoising method to filter the noise by truncating the positive gradient. Our proposed scheme can be easily deployed in other CAM-related methods, facilitating these methods to obtain higher-quality class activation maps. We evaluate the proposed approach through a weakly-supervised semantic segmentation task, and a large number of experiments demonstrate the effectiveness of our approach.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate text into Simplified Chinese<<SYS>>���������iddle activation maps ������� Ди����� deep neural networks ��������� explain. Due to its ability to highlight regions of interest, it has evolved in recent years as a key step in weakly supervised learning. A major limitation to the performance of the class activation maps is the small spatial resolution of the feature maps in the last layer of the convolutional neural network. Therefore, we expect to generate high-resolution feature maps that result in high-quality semantic information. In this paper, we rethink the properties of semantic information in shallow feature maps. We find that the shallow feature maps still have fine-grained non-discriminative features while mixing considerable non-target noise. Furthermore, we propose a simple gradient-based denoising method to filter the noise by truncating the positive gradient. Our proposed scheme can be easily deployed in other CAM-related methods, facilitating these methods to obtain higher-quality class activation maps. We evaluate the proposed approach through a weakly-supervised semantic segmentation task, and a large number of experiments demonstrate the effectiveness of our approach.Note: Please keep in mind that the translation is done using a machine translation tool, and the quality of the translation may vary depending on the complexity and nuances of the original text.
</details></li>
</ul>
<hr>
<h2 id="Breast-Ultrasound-Tumor-Classification-Using-a-Hybrid-Multitask-CNN-Transformer-Network"><a href="#Breast-Ultrasound-Tumor-Classification-Using-a-Hybrid-Multitask-CNN-Transformer-Network" class="headerlink" title="Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network"></a>Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02101">http://arxiv.org/abs/2308.02101</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bryar Shareef, Min Xian, Aleksandar Vakanski, Haotian Wang</li>
<li>for: 这个研究是为了掌握乳腺超音波图像分类。</li>
<li>methods: 这个研究使用了一种混合式多任务深度神经网络，名为Hybrid-MT-ESTAN，它的架构由CNN和Swin Transformer组成。</li>
<li>results: 研究结果显示，Hybrid-MT-ESTAN在3,320幅乳腺超音波图像中的分类和分 segmentation任务中取得了最高的准确率、敏感度和F1分数，分别为82.7%, 86.4%和86.0%。<details>
<summary>Abstract</summary>
Capturing global contextual information plays a critical role in breast ultrasound (BUS) image classification. Although convolutional neural networks (CNNs) have demonstrated reliable performance in tumor classification, they have inherent limitations for modeling global and long-range dependencies due to the localized nature of convolution operations. Vision Transformers have an improved capability of capturing global contextual information but may distort the local image patterns due to the tokenization operations. In this study, we proposed a hybrid multitask deep neural network called Hybrid-MT-ESTAN, designed to perform BUS tumor classification and segmentation using a hybrid architecture composed of CNNs and Swin Transformer components. The proposed approach was compared to nine BUS classification methods and evaluated using seven quantitative metrics on a dataset of 3,320 BUS images. The results indicate that Hybrid-MT-ESTAN achieved the highest accuracy, sensitivity, and F1 score of 82.7%, 86.4%, and 86.0%, respectively.
</details>
<details>
<summary>摘要</summary>
globally capturing contextual information plays a crucial role in breast ultrasound (BUS) image classification. Although convolutional neural networks (CNNs) have shown reliable performance in tumor classification, they have inherent limitations in modeling global and long-range dependencies due to the localized nature of convolution operations. Vision Transformers have an improved capability of capturing global contextual information but may distort local image patterns due to tokenization operations. In this study, we proposed a hybrid multitask deep neural network called Hybrid-MT-ESTAN, designed to perform BUS tumor classification and segmentation using a hybrid architecture composed of CNNs and Swin Transformer components. The proposed approach was compared to nine BUS classification methods and evaluated using seven quantitative metrics on a dataset of 3,320 BUS images. The results indicate that Hybrid-MT-ESTAN achieved the highest accuracy, sensitivity, and F1 score of 82.7%, 86.4%, and 86.0%, respectively.
</details></li>
</ul>
<hr>
<h2 id="CT-Reconstruction-from-Few-Planar-X-rays-with-Application-towards-Low-resource-Radiotherapy"><a href="#CT-Reconstruction-from-Few-Planar-X-rays-with-Application-towards-Low-resource-Radiotherapy" class="headerlink" title="CT Reconstruction from Few Planar X-rays with Application towards Low-resource Radiotherapy"></a>CT Reconstruction from Few Planar X-rays with Application towards Low-resource Radiotherapy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02100">http://arxiv.org/abs/2308.02100</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wanderinrain/xray2ct">https://github.com/wanderinrain/xray2ct</a></li>
<li>paper_authors: Yiran Sun, Tucker Netherton, Laurence Court, Ashok Veeraraghavan, Guha Balakrishnan</li>
<li>for: 这种方法用于生成基于少量（&lt;5）平面X射图像的计算机断层Volume，并在临床应用中进行了首次评估：放疗规划。</li>
<li>methods: 我们提出了一种深度生成模型，基于神经隐式表示来生成Volumetric CT扫描图像从少量入力平面X射图像的不同角度。</li>
<li>results: 我们在使用这种方法生成的 thoracic CT扫描图像上进行了2场对抗的、舒缓放疗规划，并发现了&lt;1%的误差在计算机中计算的辐射剂量与临床获得的CT扫描图像中的辐射剂量之间。此外，我们的方法也比最近的稀疙CT重建基线性能更高（PSNR、SSIM、Dice分数）在公共的LIDC肺CT数据集上。<details>
<summary>Abstract</summary>
CT scans are the standard-of-care for many clinical ailments, and are needed for treatments like external beam radiotherapy. Unfortunately, CT scanners are rare in low and mid-resource settings due to their costs. Planar X-ray radiography units, in comparison, are far more prevalent, but can only provide limited 2D observations of the 3D anatomy. In this work, we propose a method to generate CT volumes from few (<5) planar X-ray observations using a prior data distribution, and perform the first evaluation of such a reconstruction algorithm for a clinical application: radiotherapy planning. We propose a deep generative model, building on advances in neural implicit representations to synthesize volumetric CT scans from few input planar X-ray images at different angles. To focus the generation task on clinically-relevant features, our model can also leverage anatomical guidance during training (via segmentation masks). We generated 2-field opposed, palliative radiotherapy plans on thoracic CTs reconstructed by our method, and found that isocenter radiation dose on reconstructed scans have <1% error with respect to the dose calculated on clinically acquired CTs using <=4 X-ray views. In addition, our method is better than recent sparse CT reconstruction baselines in terms of standard pixel and structure-level metrics (PSNR, SSIM, Dice score) on the public LIDC lung CT dataset. Code is available at: https://github.com/wanderinrain/Xray2CT.
</details>
<details>
<summary>摘要</summary>
CT扫描是现代医疗标准，用于许多临床疾病的诊断和治疗，如外部β射线治疗。然而，在LOW和中等资源设置中，CT扫描仪仍然 rare due to its high cost.在这些设置中，平面X射线成像机器更加普遍，但它们只能提供限定的2D观察，无法提供3D анатомия的全面观察。在这种情况下，我们提出了一种方法，使用先前的数据分布来生成CT卷积体从少量（<5）平面X射线图像的观察。我们采用了深度生成模型，基于神经隐式表示来生成3D CT扫描图像从平面X射线图像的不同角度。为了将生成任务关注临床有关的特征，我们的模型可以在训练过程中使用解剖指导（via分剖标签）。我们在使用我们的方法生成的肺CT扫描图像上进行了2场对称的肺癌治疗规划，并发现了辐射剂量在重建的SCANS上和临床获得的CT扫描图像上的差异小于1%。此外，我们的方法也比最近的稀疏CT重建基线更好，根据公共的LIDC肺CT数据集的标准像素级和结构级指标（PSNR、SSIM、Dice分数）。代码可以在：https://github.com/wanderinrain/Xray2CT中找到。
</details></li>
</ul>
<hr>
<h2 id="Multi-interactive-Feature-Learning-and-a-Full-time-Multi-modality-Benchmark-for-Image-Fusion-and-Segmentation"><a href="#Multi-interactive-Feature-Learning-and-a-Full-time-Multi-modality-Benchmark-for-Image-Fusion-and-Segmentation" class="headerlink" title="Multi-interactive Feature Learning and a Full-time Multi-modality Benchmark for Image Fusion and Segmentation"></a>Multi-interactive Feature Learning and a Full-time Multi-modality Benchmark for Image Fusion and Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02097">http://arxiv.org/abs/2308.02097</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jinyuanliu-cv/segmif">https://github.com/jinyuanliu-cv/segmif</a></li>
<li>paper_authors: Jinyuan Liu, Zhu Liu, Guanyao Wu, Long Ma, Risheng Liu, Wei Zhong, Zhongxuan Luo, Xin Fan</li>
<li>for: 这篇论文旨在提出一种多Modalities图像合并和 segmentation方法，以提高自动驾驶和机器人操作的性能。</li>
<li>methods: 该方法基于一种多InteractiveFeature学习架构，通过将多modalities的图像合并到一起，并利用双任务相互关系来提高图像合并和 segmentation 的性能。</li>
<li>results: 实验表明，该方法可以输出可观赏的合并图像，并在实际场景中提高 segmentation mIoU 值，相比之前的方法。<details>
<summary>Abstract</summary>
Multi-modality image fusion and segmentation play a vital role in autonomous driving and robotic operation. Early efforts focus on boosting the performance for only one task, \emph{e.g.,} fusion or segmentation, making it hard to reach~`Best of Both Worlds'. To overcome this issue, in this paper, we propose a \textbf{M}ulti-\textbf{i}nteractive \textbf{F}eature learning architecture for image fusion and \textbf{Seg}mentation, namely SegMiF, and exploit dual-task correlation to promote the performance of both tasks. The SegMiF is of a cascade structure, containing a fusion sub-network and a commonly used segmentation sub-network. By slickly bridging intermediate features between two components, the knowledge learned from the segmentation task can effectively assist the fusion task. Also, the benefited fusion network supports the segmentation one to perform more pretentiously. Besides, a hierarchical interactive attention block is established to ensure fine-grained mapping of all the vital information between two tasks, so that the modality/semantic features can be fully mutual-interactive. In addition, a dynamic weight factor is introduced to automatically adjust the corresponding weights of each task, which can balance the interactive feature correspondence and break through the limitation of laborious tuning. Furthermore, we construct a smart multi-wave binocular imaging system and collect a full-time multi-modality benchmark with 15 annotated pixel-level categories for image fusion and segmentation. Extensive experiments on several public datasets and our benchmark demonstrate that the proposed method outputs visually appealing fused images and perform averagely $7.66\%$ higher segmentation mIoU in the real-world scene than the state-of-the-art approaches. The source code and benchmark are available at \url{https://github.com/JinyuanLiu-CV/SegMiF}.
</details>
<details>
<summary>摘要</summary>
多Modalitate的图像融合和分割在自动驾驶和机器人操作中扮演着重要的角色。初期努力主要是提高单一任务的性能，例如融合或分割，这使得达到“Best of Both Worlds”的目标变得困难。为解决这个问题，在本文中，我们提出了一种多因素互动特征学习架构，即SegMiF，并利用双任务相关性来提高两个任务的性能。SegMiF具有搅合结构，包括融合子网络和通常使用的分割子网络。通过细腻地桥接两个组件之间的中间特征，分割任务学习的知识可以有效地帮助融合任务。同时，融合网络也可以支持分割任务更加准确地进行。此外，我们还设立了一个层次互动注意力块，以确保所有重要信息之间的细腻 mapping，以便全面互动。此外，我们还引入了一个自动调整相应任务的权重因子，以平衡互动特征对应和缓解劳动劳累调整的限制。此外，我们还构建了一个智能多波普普摄影系统，并为多模态图像融合和分割建立了一个全天候多模态标准套件，包括15个注释的像素级分类。经过对多个公共数据集和我们的标准套件进行广泛的实验，我们发现提出的方法可以输出视觉吸引人的融合图像，并在实际场景中的分割mIoU平均提高7.66%。源代码和标准套件可以在<https://github.com/JinyuanLiu-CV/SegMiF>获取。
</details></li>
</ul>
<hr>
<h2 id="Diffusion-Models-for-Counterfactual-Generation-and-Anomaly-Detection-in-Brain-Images"><a href="#Diffusion-Models-for-Counterfactual-Generation-and-Anomaly-Detection-in-Brain-Images" class="headerlink" title="Diffusion Models for Counterfactual Generation and Anomaly Detection in Brain Images"></a>Diffusion Models for Counterfactual Generation and Anomaly Detection in Brain Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02062">http://arxiv.org/abs/2308.02062</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alessandro-f/dif-fuse">https://github.com/alessandro-f/dif-fuse</a></li>
<li>paper_authors: Alessandro Fontanella, Grant Mair, Joanna Wardlaw, Emanuele Trucco, Amos Storkey</li>
<li>for: 本研究用于生成疾病图像的健康版本，以便用于验证图像分割模型的可解释性和提高训练数据集的质量。</li>
<li>methods: 本研究使用了一种弱监督法，首先生成一个疾病图像的saliency map，然后使用一种混合的扩散模型（DDPM和DDIM）进行修改，以保持图像的健康部分不受影响。</li>
<li>results: 对于IST-3和BraTS2021两个数据集，我们的方法与其他弱监督方法进行比较，显示我们的方法可以提高DICE分数从0.6534提高到0.7056，表明我们的方法可以更好地生成健康版本图像。<details>
<summary>Abstract</summary>
Segmentation masks of pathological areas are useful in many medical applications, such as brain tumour and stroke management. Moreover, healthy counterfactuals of diseased images can be used to enhance radiologists' training files and to improve the interpretability of segmentation models. In this work, we present a weakly supervised method to generate a healthy version of a diseased image and then use it to obtain a pixel-wise anomaly map. To do so, we start by considering a saliency map that approximately covers the pathological areas, obtained with ACAT. Then, we propose a technique that allows to perform targeted modifications to these regions, while preserving the rest of the image. In particular, we employ a diffusion model trained on healthy samples and combine Denoising Diffusion Probabilistic Model (DDPM) and Denoising Diffusion Implicit Model (DDIM) at each step of the sampling process. DDPM is used to modify the areas affected by a lesion within the saliency map, while DDIM guarantees reconstruction of the normal anatomy outside of it. The two parts are also fused at each timestep, to guarantee the generation of a sample with a coherent appearance and a seamless transition between edited and unedited parts. We verify that when our method is applied to healthy samples, the input images are reconstructed without significant modifications. We compare our approach with alternative weakly supervised methods on IST-3 for stroke lesion segmentation and on BraTS2021 for brain tumour segmentation, where we improve the DICE score of the best competing method from $0.6534$ to $0.7056$.
</details>
<details>
<summary>摘要</summary>
干将疾病区域分割的分割面貌是医学应用中非常有用的，例如脑肿瘤和中风管理。此外，健康的对比样本可以用于增强放射学家的训练文件，并提高分割模型的可读性。在这种情况下，我们提出了一种弱监督的方法，可以生成一个健康版本的疾病图像，并使用其生成一个像素精度的异常地图。我们开始是通过考虑一个ACAT获得的病理区域精度的报告来，然后我们提出了一种可以在这些区域进行目标 modify 的技术，保持图像的其他部分不变。特别是，我们使用了训练在健康样本上的扩散模型，并将DDPM和DDIM相互融合在每个抽样过程中。DDPM用于在病理区域内的精度报告中修改病理区域，而DDIM确保在病理区域外的正常解剖结构的重建。这两个部分也在每个时间步骤中融合，以保证生成一个具有净合的外观和无缝过渡的编辑和未编辑部分。我们证明，当我们的方法应用于健康样本时，输入图像不会经受显著的修改。我们与其他弱监督方法进行比较，在IST-3上对stroke lesion segmentation和BraTS2021上对脑肿瘤分割进行比较，我们提高了最佳竞争方法的DICE分数从0.6534提高到0.7056。
</details></li>
</ul>
<hr>
<h2 id="UGainS-Uncertainty-Guided-Anomaly-Instance-Segmentation"><a href="#UGainS-Uncertainty-Guided-Anomaly-Instance-Segmentation" class="headerlink" title="UGainS: Uncertainty Guided Anomaly Instance Segmentation"></a>UGainS: Uncertainty Guided Anomaly Instance Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02046">http://arxiv.org/abs/2308.02046</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kumuji/ugains">https://github.com/kumuji/ugains</a></li>
<li>paper_authors: Alexey Nekrasov, Alexander Hermans, Lars Kuhnert, Bastian Leibe</li>
<li>for: 本研究旨在提供一种可靠的机器视觉方法，用于检测道路上的异常对象，以避免交通事故和人员受伤。</li>
<li>methods: 本研究使用了一种异常分割模型，包括一个异常分割模型和一个通用分割模型，以 segments 异常对象。另外，研究还使用了不确定区域来引导异常分割模型进行异常对象的分割。</li>
<li>results: 研究发现，使用该方法可以对道路上的异常对象进行高精度的检测，并且达到了80.08%和88.98%的AP值在Fishyscapes Lost and Found和RoadAnomaly验证集上。项目页面：<a target="_blank" rel="noopener" href="https://vision.rwth-aachen.de/ugains">https://vision.rwth-aachen.de/ugains</a><details>
<summary>Abstract</summary>
A single unexpected object on the road can cause an accident or may lead to injuries. To prevent this, we need a reliable mechanism for finding anomalous objects on the road. This task, called anomaly segmentation, can be a stepping stone to safe and reliable autonomous driving. Current approaches tackle anomaly segmentation by assigning an anomaly score to each pixel and by grouping anomalous regions using simple heuristics. However, pixel grouping is a limiting factor when it comes to evaluating the segmentation performance of individual anomalous objects. To address the issue of grouping multiple anomaly instances into one, we propose an approach that produces accurate anomaly instance masks. Our approach centers on an out-of-distribution segmentation model for identifying uncertain regions and a strong generalist segmentation model for anomaly instances segmentation. We investigate ways to use uncertain regions to guide such a segmentation model to perform segmentation of anomalous instances. By incorporating strong object priors from a generalist model we additionally improve the per-pixel anomaly segmentation performance. Our approach outperforms current pixel-level anomaly segmentation methods, achieving an AP of 80.08% and 88.98% on the Fishyscapes Lost and Found and the RoadAnomaly validation sets respectively. Project page: https://vision.rwth-aachen.de/ugains
</details>
<details>
<summary>摘要</summary>
一个不期望的对象在路上可能会导致事故或伤害。为了防止这种情况，我们需要一种可靠的机制来检测路上异常对象。这项任务被称为异常分割，可以作为自动驾驶安全可靠的一个步骤。现有的方法对异常分割采用分配异常分数到每个像素点和使用简单的规则来组合异常区域。然而，像素点组合是评估异常分割性能的限制因素。为了解决多个异常实例被一起分组的问题，我们提出一种方法，可以生成准确的异常实例面积。我们的方法围绕着非常区分分数模型和一个强大的通用模型来实现异常实例分割。我们调查了如何使用不确定区域来引导这种分割模型进行异常实例分割。通过将强大的物体先验从通用模型integrated，我们还提高了每个像素点的异常分割性能。我们的方法在当前像素级异常分割方法的基础上提高了AP值，达到80.08%和88.98%在Fishyscapes Lost and Found和RoadAnomaly验证集上。项目页面：https://vision.rwth-aachen.de/ugains
</details></li>
</ul>
<hr>
<h2 id="ETran-Energy-Based-Transferability-Estimation"><a href="#ETran-Energy-Based-Transferability-Estimation" class="headerlink" title="ETran: Energy-Based Transferability Estimation"></a>ETran: Energy-Based Transferability Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02027">http://arxiv.org/abs/2308.02027</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohsen Gholami, Mohammad Akbari, Xinglu Wang, Behnam Kamranian, Yong Zhang</li>
<li>for: 本研究旨在解决预训练模型选择问题，以提高对象检测和图像分类的性能。</li>
<li>methods: 我们提出了一种基于能量分布的转移性评估指标（ETran），包括三个分数：1) 能量分数，2) 分类分数，3) 回归分数。ETran使用能量模型来判断目标数据集是否为预训练模型的内部数据集（IND）或外部数据集（OOD）。与前一些工作不同，ETran可以应用于多种任务，包括分类、回归和对象检测（分类+回归）。</li>
<li>results: 我们在四个 benchmark 和两个任务上进行了广泛的实验，并证明了 ETran 在对象检测和分类 benchmark 上平均高于前一些工作 by 21% 和 12%，并达到了转移性评估中的最佳性能。<details>
<summary>Abstract</summary>
This paper addresses the problem of ranking pre-trained models for object detection and image classification. Selecting the best pre-trained model by fine-tuning is an expensive and time-consuming task. Previous works have proposed transferability estimation based on features extracted by the pre-trained models. We argue that quantifying whether the target dataset is in-distribution (IND) or out-of-distribution (OOD) for the pre-trained model is an important factor in the transferability estimation. To this end, we propose ETran, an energy-based transferability assessment metric, which includes three scores: 1) energy score, 2) classification score, and 3) regression score. We use energy-based models to determine whether the target dataset is OOD or IND for the pre-trained model. In contrast to the prior works, ETran is applicable to a wide range of tasks including classification, regression, and object detection (classification+regression). This is the first work that proposes transferability estimation for object detection task. Our extensive experiments on four benchmarks and two tasks show that ETran outperforms previous works on object detection and classification benchmarks by an average of 21% and 12%, respectively, and achieves SOTA in transferability assessment.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Explainable-unsupervised-multi-modal-image-registration-using-deep-networks"><a href="#Explainable-unsupervised-multi-modal-image-registration-using-deep-networks" class="headerlink" title="Explainable unsupervised multi-modal image registration using deep networks"></a>Explainable unsupervised multi-modal image registration using deep networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01994">http://arxiv.org/abs/2308.01994</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengjia Wang, Giorgos Papanastasiou</li>
<li>for: 这篇论文旨在提出一种基于深度学习的多模态和多器官MRI图像 регистрация方法，以帮助临床决策。</li>
<li>methods: 该方法使用了多种MRI序列（定义为’模态’），并使用了Grad-CAM基于解释框架来解释模型数据行为。</li>
<li>results: 作者在之前的研究中已经达到了超过现有标准Syn方法的性能水平，而在这项工作中，他们则证明了他们的DL模型可以完全解释，这将为将来的医学图像数据进行扩展提供了基础。<details>
<summary>Abstract</summary>
Clinical decision making from magnetic resonance imaging (MRI) combines complementary information from multiple MRI sequences (defined as 'modalities'). MRI image registration aims to geometrically 'pair' diagnoses from different modalities, time points and slices. Both intra- and inter-modality MRI registration are essential components in clinical MRI settings. Further, an MRI image processing pipeline that can address both afine and non-rigid registration is critical, as both types of deformations may be occuring in real MRI data scenarios. Unlike image classification, explainability is not commonly addressed in image registration deep learning (DL) methods, as it is challenging to interpet model-data behaviours against transformation fields. To properly address this, we incorporate Grad-CAM-based explainability frameworks in each major component of our unsupervised multi-modal and multi-organ image registration DL methodology. We previously demonstrated that we were able to reach superior performance (against the current standard Syn method). In this work, we show that our DL model becomes fully explainable, setting the framework to generalise our approach on further medical imaging data.
</details>
<details>
<summary>摘要</summary>
临床决策从核磁共振成像（MRI）结合多种MRI序列（定义为“模态”）的信息。MRI图像匹配目标是将不同模态、时间点和切片的诊断“匹配”在一起。在临床MRI Setting中，内部和间部MRI匹配都是重要组成部分。此外，一个能够处理both afine和非RIGID匹配的MRI图像处理管道是关键，因为这两种类型的变形都可能出现在实际MRI数据enario中。与图像分类不同，explainability不是通常在图像匹配深度学习（DL）方法中被考虑，因为很难从变换场景中解释模型-数据行为。为了正确地 Addressing this, we incorporate Grad-CAM-based explainability frameworks in each major component of our unsupervised multi-modal and multi-organ image registration DL methodology. In our previous work, we demonstrated that our DL model could reach superior performance against the current standard Syn method. In this work, we show that our DL model becomes fully explainable, setting the framework for generalizing our approach to further medical imaging data.
</details></li>
</ul>
<hr>
<h2 id="Predicting-Ki67-ER-PR-and-HER2-Statuses-from-H-E-stained-Breast-Cancer-Images"><a href="#Predicting-Ki67-ER-PR-and-HER2-Statuses-from-H-E-stained-Breast-Cancer-Images" class="headerlink" title="Predicting Ki67, ER, PR, and HER2 Statuses from H&amp;E-stained Breast Cancer Images"></a>Predicting Ki67, ER, PR, and HER2 Statuses from H&amp;E-stained Breast Cancer Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01982">http://arxiv.org/abs/2308.01982</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amir Akbarnejad, Nilanjan Ray, Penny J. Barnes, Gilbert Bigras</li>
<li>for: 本研究的目的是确定机器学习方法是否可以准确地预测蛋白质信息仅基于组织结构图像。</li>
<li>methods: 我们建立了一个大规模的数据集（185538张图像），其中包含可靠的测量数据 для Ki67、ER、PR和HER2状况。这个数据集由H&amp;E和相关的免疫抑制试验（Ki67、ER、PR和HER2）的图像组成，这些图像通过注册进行了镜像。为了增强可靠性，我们 manually inspect each pair of images and discarded those with artifacts (such as tissue folding or bubbles). Measurements for Ki67、ER和PR were determined by calculating H-Score from image analysis, while HER2 measurement was based on binary classification.</li>
<li>results: 我们发现，使用标准的ViT基础pipeline可以在训练with proper labeling protocol下达到约90%的AUC预测性能。此外，我们还证明了训练的分类器能够正确地 lokalisate relevant regions，这将激发未来的工作以提高localizations。我们的提出的数据集现在公开可用：<a target="_blank" rel="noopener" href="https://ihc4bc.github.io/">https://ihc4bc.github.io/</a><details>
<summary>Abstract</summary>
Despite the advances in machine learning and digital pathology, it is not yet clear if machine learning methods can accurately predict molecular information merely from histomorphology. In a quest to answer this question, we built a large-scale dataset (185538 images) with reliable measurements for Ki67, ER, PR, and HER2 statuses. The dataset is composed of mirrored images of H\&E and corresponding images of immunohistochemistry (IHC) assays (Ki67, ER, PR, and HER2. These images are mirrored through registration. To increase reliability, individual pairs were inspected and discarded if artifacts were present (tissue folding, bubbles, etc). Measurements for Ki67, ER and PR were determined by calculating H-Score from image analysis. HER2 measurement is based on binary classification: 0 and 1+ (IHC scores representing a negative subset) vs 3+ (IHC score positive subset). Cases with IHC equivocal score (2+) were excluded. We show that a standard ViT-based pipeline can achieve prediction performances around 90% in terms of Area Under the Curve (AUC) when trained with a proper labeling protocol. Finally, we shed light on the ability of the trained classifiers to localize relevant regions, which encourages future work to improve the localizations. Our proposed dataset is publicly available: https://ihc4bc.github.io/
</details>
<details>
<summary>摘要</summary>
尽管机器学习和数字 PATHOLOGY 技术有所进步，但是还没有清楚地表明机器学习方法可以准确地预测分子信息仅通过 histomorphology。为了回答这个问题，我们建立了一个大规模数据集（185538张图像），其中包含可靠的测量数据 для Ki67、ER、PR 和 HER2 状态。该数据集由 H\&E 和相关的免疫抑制试验（IHC）图像组成（Ki67、ER、PR 和 HER2），这些图像通过注册进行镜像。为了增加可靠性，我们对每个对应的图像进行了检查，并且如果存在遗留物（如组织卷绕、气泡等），那么将其排除。我们通过计算 H-Score 来确定 Ki67、ER 和 PR 的测量，而 HER2 的测量则基于二分类：0和1+（IHC 分数表示负集）vs 3+（IHC 分数正集）。我们排除了 IHC 不明确分数（2+）的案例。我们显示，使用标准 ViT-based 管道可以在训练时以 около 90% 的 AUC 性能进行预测。最后，我们探讨了训练的分类器所能够启发的相关区域，这引发了未来工作的改进局部化。我们所建立的数据集现在公开可用：https://ihc4bc.github.io/
</details></li>
</ul>
<hr>
<h2 id="CartiMorph-a-framework-for-automated-knee-articular-cartilage-morphometrics"><a href="#CartiMorph-a-framework-for-automated-knee-articular-cartilage-morphometrics" class="headerlink" title="CartiMorph: a framework for automated knee articular cartilage morphometrics"></a>CartiMorph: a framework for automated knee articular cartilage morphometrics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01981">http://arxiv.org/abs/2308.01981</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yongchengyao/cartimorph">https://github.com/yongchengyao/cartimorph</a></li>
<li>paper_authors: Yongcheng Yao, Junru Zhong, Liping Zhang, Sheheryar Khan, Weitian Chen</li>
<li>for: 这个论文旨在提供一个自动化膝关节cartilage morphometrics框架，以便通过计算软骨cartilage厚度、面积和体积来评估膝关节疾病。</li>
<li>methods: 这个框架使用了深度学习模型来表示图像特征，并使用模板建构和图像注册来生成量化metric。它还使用了表面正则化来计算软骨厚度图和血液损伤率。</li>
<li>results: 研究发现，使用这个框架可以生成高精度的软骨厚度图和血液损伤率图，并且与手动分割的结果相比，root-mean-squared deviation只有8%以下，而且存在strong correlation。此外，与之前的研究中的血液损伤率比较，这个方法的测量结果更接近真实值。<details>
<summary>Abstract</summary>
We introduce CartiMorph, a framework for automated knee articular cartilage morphometrics. It takes an image as input and generates quantitative metrics for cartilage subregions, including the percentage of full-thickness cartilage loss (FCL), mean thickness, surface area, and volume. CartiMorph leverages the power of deep learning models for hierarchical image feature representation. Deep learning models were trained and validated for tissue segmentation, template construction, and template-to-image registration. We established methods for surface-normal-based cartilage thickness mapping, FCL estimation, and rule-based cartilage parcellation. Our cartilage thickness map showed less error in thin and peripheral regions. We evaluated the effectiveness of the adopted segmentation model by comparing the quantitative metrics obtained from model segmentation and those from manual segmentation. The root-mean-squared deviation of the FCL measurements was less than 8%, and strong correlations were observed for the mean thickness (Pearson's correlation coefficient $\rho \in [0.82,0.97]$), surface area ($\rho \in [0.82,0.98]$) and volume ($\rho \in [0.89,0.98]$) measurements. We compared our FCL measurements with those from a previous study and found that our measurements deviated less from the ground truths. We observed superior performance of the proposed rule-based cartilage parcellation method compared with the atlas-based approach. CartiMorph has the potential to promote imaging biomarkers discovery for knee osteoarthritis.
</details>
<details>
<summary>摘要</summary>
我们介绍CartiMorph，一个数据科学框架，用于自动脚关节软骨形态分析。它可以将脚关节软骨影像作为输入，生成软骨各个子区域的量化指标，包括软骨全厚度损伤率（FCL）、平均厚度、表面积和体积。CartiMorph充分利用深度学习模型来表示图像特征 hierarchy。我们训练了深度学习模型并进行验证，以进行组织分类、模板建立和模板与图像对接。我们开发了基于表面法向的软骨厚度对应、FCL估计和规律基于的软骨分割方法。我们的软骨厚度图示在薄和 périphérique 区域中表现较低的误差。我们评估了运用数据科学模型进行分类的效果，与手动分类结果进行比较。在FCL量化中，根mean-squared deviation的误差小于8%，且在平均厚度（Pearson's correlation coefficient $\rho \in [0.82,0.97]$）、表面积（Pearson's correlation coefficient $\rho \in [0.82,0.98]$）和体积（Pearson's correlation coefficient $\rho \in [0.89,0.98]$）量化中都 observe strong correlation。我们与之前的研究比较FCL量化结果，发现我们的量化结果与真实值更接近。我们发现了规律基于的软骨分割方法比Atlas-based方法表现更好。CartiMorph具有推广镜影像生物 markers的潜力。
</details></li>
</ul>
<hr>
<h2 id="Unmasking-Parkinson’s-Disease-with-Smile-An-AI-enabled-Screening-Framework"><a href="#Unmasking-Parkinson’s-Disease-with-Smile-An-AI-enabled-Screening-Framework" class="headerlink" title="Unmasking Parkinson’s Disease with Smile: An AI-enabled Screening Framework"></a>Unmasking Parkinson’s Disease with Smile: An AI-enabled Screening Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02588">http://arxiv.org/abs/2308.02588</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tariq Adnan, Md Saiful Islam, Wasifur Rahman, Sangwu Lee, Sutapa Dey Tithi, Kazi Noshin, Imran Sarker, M Saifur Rahman, Ehsan Hoque</li>
<li>for: 这个研究旨在开发一种基于微表情的抑阻肌萎病（PD）诊断方法，以提高PD诊断的可靠性和访问性。</li>
<li>methods: 该研究使用了 largest video dataset containing micro-expressions，并使用了面部特征和动作单元来提取有关肌萎病的特征。 ensemble of AI models 被训练于这些特征，并 achieved an accuracy of 89.7% 和 AUROC of 89.3%。</li>
<li>results: 研究发现，基于微表情的抑阻肌萎病诊断方法可以具有高度可靠性和抗检测性，并且可以在不同的性别和民族背景下实现同等的表现。<details>
<summary>Abstract</summary>
Parkinson's disease (PD) diagnosis remains challenging due to lacking a reliable biomarker and limited access to clinical care. In this study, we present an analysis of the largest video dataset containing micro-expressions to screen for PD. We collected 3,871 videos from 1,059 unique participants, including 256 self-reported PD patients. The recordings are from diverse sources encompassing participants' homes across multiple countries, a clinic, and a PD care facility in the US. Leveraging facial landmarks and action units, we extracted features relevant to Hypomimia, a prominent symptom of PD characterized by reduced facial expressions. An ensemble of AI models trained on these features achieved an accuracy of 89.7% and an Area Under the Receiver Operating Characteristic (AUROC) of 89.3% while being free from detectable bias across population subgroups based on sex and ethnicity on held-out data. Further analysis reveals that features from the smiling videos alone lead to comparable performance, even on two external test sets the model has never seen during training, suggesting the potential for PD risk assessment from smiling selfie videos.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="RealCQA-Scientific-Chart-Question-Answering-as-a-Test-bed-for-First-Order-Logic"><a href="#RealCQA-Scientific-Chart-Question-Answering-as-a-Test-bed-for-First-Order-Logic" class="headerlink" title="RealCQA: Scientific Chart Question Answering as a Test-bed for First-Order Logic"></a>RealCQA: Scientific Chart Question Answering as a Test-bed for First-Order Logic</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01979">http://arxiv.org/abs/2308.01979</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cse-ai-lab/RealCQA">https://github.com/cse-ai-lab/RealCQA</a></li>
<li>paper_authors: Saleem Ahmed, Bhavin Jawade, Shubham Pandey, Srirangaraj Setlur, Venu Govindaraju</li>
<li>for: 该论文目的是解决在文档中理解和提取图表视觉化数据中遇到的挑战。</li>
<li>methods: 该论文使用了实际世界的真实图表数据集，并提出了一个新的答案类型“列表”，包括排名和未排名两种变种。</li>
<li>results: 该论文通过实验证明了大规模预训练模型在图表视觉问答任务中的表现，并为图表视觉问答和形式逻辑验证各提供了一个标准。<details>
<summary>Abstract</summary>
We present a comprehensive study of chart visual question-answering(QA) task, to address the challenges faced in comprehending and extracting data from chart visualizations within documents. Despite efforts to tackle this problem using synthetic charts, solutions are limited by the shortage of annotated real-world data. To fill this gap, we introduce a benchmark and dataset for chart visual QA on real-world charts, offering a systematic analysis of the task and a novel taxonomy for template-based chart question creation. Our contribution includes the introduction of a new answer type, 'list', with both ranked and unranked variations. Our study is conducted on a real-world chart dataset from scientific literature, showcasing higher visual complexity compared to other works. Our focus is on template-based QA and how it can serve as a standard for evaluating the first-order logic capabilities of models. The results of our experiments, conducted on a real-world out-of-distribution dataset, provide a robust evaluation of large-scale pre-trained models and advance the field of chart visual QA and formal logic verification for neural networks in general.
</details>
<details>
<summary>摘要</summary>
我们进行了一项全面的研究，探讨了图表视觉问答（QA）任务，以解决在文档中理解和提取图表视觉数据时所遇到的挑战。尽管有尝试使用合成图表来解决这个问题，但解决方案受到实际数据缺乏答案的限制。为了填补这个差距，我们提出了一个基准和图表视觉QA实际数据集，并提供了一种系统性的分析和一种新的模板基于的图表问题创建分类法。我们的贡献包括引入一种新的答案类型，“列表”，其中包括排序和无排序两种变种。我们的研究在科学文献中采集的实际图表数据集上进行，这个数据集的视觉复杂性较高于其他工作。我们的重点是模板基于的QA和如何使其成为评估模型首觉逻辑能力的标准。实验结果，在一个实际 OUT-OF-distribution 数据集上进行，为大规模预训练模型提供了robust的评估，并为图表视觉QA和形式逻辑验证 для神经网络在通过总的提升了领域。
</details></li>
</ul>
<hr>
<h2 id="Synthesising-Rare-Cataract-Surgery-Samples-with-Guided-Diffusion-Models"><a href="#Synthesising-Rare-Cataract-Surgery-Samples-with-Guided-Diffusion-Models" class="headerlink" title="Synthesising Rare Cataract Surgery Samples with Guided Diffusion Models"></a>Synthesising Rare Cataract Surgery Samples with Guided Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02587">http://arxiv.org/abs/2308.02587</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/meclabtuda/catasynth">https://github.com/meclabtuda/catasynth</a></li>
<li>paper_authors: Yannik Frisch, Moritz Fuchs, Antoine Sanner, Felix Anton Ucar, Marius Frenzel, Joana Wasielica-Poslednik, Adrian Gericke, Felix Mathias Wagner, Thomas Dratsch, Anirban Mukhopadhyay<br>for:The paper aims to address the challenge of gathering and annotating data for training automated assistance systems for cataract surgery, specifically by analyzing cataract surgery video data and synthesizing diverse, high-quality examples of surgical phases and tool usage.methods:The authors use a conditional generative model based on Denoising Diffusion Implicit Models (DDIM) and Classifier-Free Guidance (CFG) to synthesize realistic examples of surgical phases and tool usage, which can improve the data sparsity problem for the downstream task of tool classification.results:The model can generate valuable unseen examples that allow the tool classifier to improve by up to 10% for rare cases, and the synthetically extended data can facilitate the development of automated assistance systems for cataract surgery by providing a reliable source of realistic synthetic data.Here’s the Chinese translation of the three key points:for:这篇论文目标是解决cataract surgery assistive system的自动化协助系统训练数据收集和标注的挑战，特别是分析cataract surgery视频数据并生成多样化、高质量的手术阶段和工具使用示例。methods:作者使用了一种基于Denoising Diffusion Implicit Models (DDIM)和Classifier-Free Guidance (CFG)的 conditional generative模型来生成真实的手术阶段和工具使用示例，以解决下游任务的数据稀缺问题。results:模型可以生成有价值的未看过的示例，使得工具分类器在罕见 случа中提高至10%，并且将生成的 synthetically extended data 提供了一个可靠的真实的synthetic数据源，以便助长cataract surgery assistive system的自动化协助系统的发展。<details>
<summary>Abstract</summary>
Cataract surgery is a frequently performed procedure that demands automation and advanced assistance systems. However, gathering and annotating data for training such systems is resource intensive. The publicly available data also comprises severe imbalances inherent to the surgical process. Motivated by this, we analyse cataract surgery video data for the worst-performing phases of a pre-trained downstream tool classifier. The analysis demonstrates that imbalances deteriorate the classifier's performance on underrepresented cases. To address this challenge, we utilise a conditional generative model based on Denoising Diffusion Implicit Models (DDIM) and Classifier-Free Guidance (CFG). Our model can synthesise diverse, high-quality examples based on complex multi-class multi-label conditions, such as surgical phases and combinations of surgical tools. We affirm that the synthesised samples display tools that the classifier recognises. These samples are hard to differentiate from real images, even for clinical experts with more than five years of experience. Further, our synthetically extended data can improve the data sparsity problem for the downstream task of tool classification. The evaluations demonstrate that the model can generate valuable unseen examples, allowing the tool classifier to improve by up to 10% for rare cases. Overall, our approach can facilitate the development of automated assistance systems for cataract surgery by providing a reliable source of realistic synthetic data, which we make available for everyone.
</details>
<details>
<summary>摘要</summary>
喷洗手术是一种非常常见的手术程序，需要自动化和高级帮助系统。然而，收集和标注数据 для训练这些系统是资源占用的。公共可用数据也存在严重的不均衡问题，这些问题会影响下游工具分类器的性能。为了解决这个挑战，我们分析了喷洗手术视频数据，并发现异常性对下游工具分类器的性能有负面影响。为了解决这个问题，我们使用了基于零噪扩散模型（DDIM）和无类标注指导（CFG）的冲激生成模型。我们的模型可以生成多样化、高质量的示例，包括手术阶段和手术工具的复杂多类多标签条件。我们证明了这些生成的样例中的工具都是分类器认可的。这些样例与真实图像很难分辨，即使是临床专家超过5年的经验。此外，我们通过生成的数据扩展，可以解决下游工具分类器的数据稀缺问题。评估表明，我们的模型可以生成有价值的未见样例，使工具分类器提高至10%。总之，我们的方法可以促进喷洗手术自动化系统的开发，提供一个可靠的真实synthetic数据源，我们将其公开给大家。
</details></li>
</ul>
<hr>
<h2 id="The-All-Seeing-Project-Towards-Panoptic-Visual-Recognition-and-Understanding-of-the-Open-World"><a href="#The-All-Seeing-Project-Towards-Panoptic-Visual-Recognition-and-Understanding-of-the-Open-World" class="headerlink" title="The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World"></a>The All-Seeing Project: Towards Panoptic Visual Recognition and Understanding of the Open World</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01907">http://arxiv.org/abs/2308.01907</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/opengvlab/all-seeing">https://github.com/opengvlab/all-seeing</a></li>
<li>paper_authors: Weiyun Wang, Min Shi, Qingyun Li, Wenhai Wang, Zhenhang Huang, Linjie Xing, Zhe Chen, Hao Li, Xizhou Zhu, Zhiguo Cao, Yushi Chen, Tong Lu, Jifeng Dai, Yu Qiao</li>
<li>for: 这个项目（All-Seeing）的目标是开发一个能够识别和理解开放世界中的所有元素的大规模数据和模型。</li>
<li>methods: 这个项目使用了可扩展的数据引擎，并利用人类反馈和高效的模型来创建一个名为AS-1B的新数据集，包含超过10亿个区域，每个区域都有semantic标签、问题对答对和详细的描述。</li>
<li>results: 这个项目开发了一个名为All-Seeing模型（ASM），这是一个统一的框架，可以处理多种视觉和语言任务，包括区域文本检索、区域识别、描述和问题回答。这个模型在零基础情况下表现出惊人的表现，并且可以 generale到不同的视觉和语言任务。<details>
<summary>Abstract</summary>
We present the All-Seeing (AS) project: a large-scale data and model for recognizing and understanding everything in the open world. Using a scalable data engine that incorporates human feedback and efficient models in the loop, we create a new dataset (AS-1B) with over 1 billion regions annotated with semantic tags, question-answering pairs, and detailed captions. It covers a wide range of 3.5 million common and rare concepts in the real world, and has 132.2 billion tokens that describe the concepts and their attributes. Leveraging this new dataset, we develop the All-Seeing model (ASM), a unified framework for panoptic visual recognition and understanding. The model is trained with open-ended language prompts and locations, which allows it to generalize to various vision and language tasks with remarkable zero-shot performance, including region-text retrieval, region recognition, captioning, and question-answering. We hope that this project can serve as a foundation for vision-language artificial general intelligence research. Models and the dataset shall be released at https://github.com/OpenGVLab/All-Seeing, and demo can be seen at https://huggingface.co/spaces/OpenGVLab/all-seeing.
</details>
<details>
<summary>摘要</summary>
我们介绍《全见计划》（AS）项目：一个大规模数据和模型，旨在认知和理解开放世界中的一切。我们使用可扩展的数据引擎，并将人类反馈和高效的模型纳入循环，创建了一个新的数据集（AS-1B），包含超过10亿个区域，每个区域均被标注为Semantic tag、问题对答对和详细描述。这些数据覆盖了350万个常见和罕见的世界现象，并有132.2亿个字符来描述这些概念和其属性。基于这个新的数据集，我们开发了《全见模型》（ASM），一个统一的视觉认知和理解框架。该模型通过使用开放语言提示和位置训练，能够通过Zero-shot学习来解决多种视觉和语言任务，包括区域文本检索、区域识别、描述和问题回答。我们希望这个项目可以成为视觉语言人工智能研究的基础。模型和数据将在GitHub上发布，demo可以在Hugging Face上看到。
</details></li>
</ul>
<hr>
<h2 id="DETR-Doesn’t-Need-Multi-Scale-or-Locality-Design"><a href="#DETR-Doesn’t-Need-Multi-Scale-or-Locality-Design" class="headerlink" title="DETR Doesn’t Need Multi-Scale or Locality Design"></a>DETR Doesn’t Need Multi-Scale or Locality Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01904">http://arxiv.org/abs/2308.01904</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/impiga/plain-detr">https://github.com/impiga/plain-detr</a></li>
<li>paper_authors: Yutong Lin, Yuhui Yuan, Zheng Zhang, Chen Li, Nanning Zheng, Han Hu</li>
<li>for: 提高DETR检测器的性能，使其具有”平铺”的性质，即使用单个缩放矩阵和全局权重计算而不受特定的本地性约束。</li>
<li>methods: 使用两种简单 yet 有效的技术来补偿无多scale feature map和本地性约束：首先是在交换表达式中添加盒体对像Pixel相对位偏移（BoxRPB）项，使每个查询能够准确地attend to对应的物体区域，并提供编码flexibility。其次是基于Masked Image Modeling（MIM）的后驱核心预训练，帮助学习表示能力与细致的本地化。</li>
<li>results: 通过 incorporating these technologies and recent advancements in training and problem formation, the improved “plain” DETR showed exceptional improvements over the original DETR detector. Using the Object365 dataset for pre-training, it achieved 63.9 mAP accuracy with a Swin-L backbone, which is highly competitive with state-of-the-art detectors that all heavily rely on multi-scale feature maps and region-based feature extraction.<details>
<summary>Abstract</summary>
This paper presents an improved DETR detector that maintains a "plain" nature: using a single-scale feature map and global cross-attention calculations without specific locality constraints, in contrast to previous leading DETR-based detectors that reintroduce architectural inductive biases of multi-scale and locality into the decoder. We show that two simple technologies are surprisingly effective within a plain design to compensate for the lack of multi-scale feature maps and locality constraints. The first is a box-to-pixel relative position bias (BoxRPB) term added to the cross-attention formulation, which well guides each query to attend to the corresponding object region while also providing encoding flexibility. The second is masked image modeling (MIM)-based backbone pre-training which helps learn representation with fine-grained localization ability and proves crucial for remedying dependencies on the multi-scale feature maps. By incorporating these technologies and recent advancements in training and problem formation, the improved "plain" DETR showed exceptional improvements over the original DETR detector. By leveraging the Object365 dataset for pre-training, it achieved 63.9 mAP accuracy using a Swin-L backbone, which is highly competitive with state-of-the-art detectors which all heavily rely on multi-scale feature maps and region-based feature extraction. Code is available at https://github.com/impiga/Plain-DETR .
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="UniSim-A-Neural-Closed-Loop-Sensor-Simulator"><a href="#UniSim-A-Neural-Closed-Loop-Sensor-Simulator" class="headerlink" title="UniSim: A Neural Closed-Loop Sensor Simulator"></a>UniSim: A Neural Closed-Loop Sensor Simulator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01898">http://arxiv.org/abs/2308.01898</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ze Yang, Yun Chen, Jingkang Wang, Sivabalan Manivasagam, Wei-Chiu Ma, Anqi Joyce Yang, Raquel Urtasun</li>
<li>for: 这篇论文的目的是为了实现安全自动驾驶车辆（SDV）的可靠性测试。</li>
<li>methods: 这篇论文使用了一种神经网络感知器 simulator，可以将单个录制的驾驶记录转换成真实的多感知closed-loop simulator。</li>
<li>results: 实验表明，UniSim可以生成具有小域领域差异的感知数据，并在下游任务上表现出优秀的性能。通过UniSim，我们实现了在安全关键场景下进行闭环评估自动驾驶系统的能力。<details>
<summary>Abstract</summary>
Rigorously testing autonomy systems is essential for making safe self-driving vehicles (SDV) a reality. It requires one to generate safety critical scenarios beyond what can be collected safely in the world, as many scenarios happen rarely on public roads. To accurately evaluate performance, we need to test the SDV on these scenarios in closed-loop, where the SDV and other actors interact with each other at each timestep. Previously recorded driving logs provide a rich resource to build these new scenarios from, but for closed loop evaluation, we need to modify the sensor data based on the new scene configuration and the SDV's decisions, as actors might be added or removed and the trajectories of existing actors and the SDV will differ from the original log. In this paper, we present UniSim, a neural sensor simulator that takes a single recorded log captured by a sensor-equipped vehicle and converts it into a realistic closed-loop multi-sensor simulation. UniSim builds neural feature grids to reconstruct both the static background and dynamic actors in the scene, and composites them together to simulate LiDAR and camera data at new viewpoints, with actors added or removed and at new placements. To better handle extrapolated views, we incorporate learnable priors for dynamic objects, and leverage a convolutional network to complete unseen regions. Our experiments show UniSim can simulate realistic sensor data with small domain gap on downstream tasks. With UniSim, we demonstrate closed-loop evaluation of an autonomy system on safety-critical scenarios as if it were in the real world.
</details>
<details>
<summary>摘要</summary>
rigorously testing autonomous systems is essential for making safe self-driving vehicles (SDV) a reality. It requires one to generate safety-critical scenarios beyond what can be collected safely on public roads, as many scenarios happen rarely. To accurately evaluate performance, we need to test the SDV on these scenarios in closed-loop, where the SDV and other actors interact with each other at each timestep. Previously recorded driving logs provide a rich resource to build these new scenarios from, but for closed-loop evaluation, we need to modify the sensor data based on the new scene configuration and the SDV's decisions, as actors might be added or removed and the trajectories of existing actors and the SDV will differ from the original log. In this paper, we present UniSim, a neural sensor simulator that takes a single recorded log captured by a sensor-equipped vehicle and converts it into a realistic closed-loop multi-sensor simulation. UniSim builds neural feature grids to reconstruct both the static background and dynamic actors in the scene, and composites them together to simulate LiDAR and camera data at new viewpoints, with actors added or removed and at new placements. To better handle extrapolated views, we incorporate learnable priors for dynamic objects, and leverage a convolutional network to complete unseen regions. Our experiments show UniSim can simulate realistic sensor data with small domain gap on downstream tasks. With UniSim, we demonstrate closed-loop evaluation of an autonomy system on safety-critical scenarios as if it were in the real world.
</details></li>
</ul>
<hr>
<h2 id="DualCoOp-Fast-and-Effective-Adaptation-to-Multi-Label-Recognition-with-Limited-Annotations"><a href="#DualCoOp-Fast-and-Effective-Adaptation-to-Multi-Label-Recognition-with-Limited-Annotations" class="headerlink" title="DualCoOp++: Fast and Effective Adaptation to Multi-Label Recognition with Limited Annotations"></a>DualCoOp++: Fast and Effective Adaptation to Multi-Label Recognition with Limited Annotations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01890">http://arxiv.org/abs/2308.01890</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ping Hu, Ximeng Sun, Stan Sclaroff, Kate Saenko</li>
<li>for: 多 Label图像识别在低标签 режиме是一项具有挑战性和实际意义的任务。过去的工作通常是通过学习图像和文本空间之间的协调来补偿限制的图像标签，但可能会受到质量不佳的多标签注释的限制。</li>
<li>methods: 我们利用了强大的文本和视觉特征之间的协调，通过 millions of auxiliary image-text pairs预训练的 poderoso alignement。我们提出了一种高效可行的框架called Evidence-guided Dual Context Optimization (DualCoOp++),它作为一种统一的方法来解决 partial-label 和零shot多标签识别。在 DualCoOp++ 中，我们分别编码了目标类的证据、正面和负面上下文作为参数的文本输入（即提示）中的 parametric 组件。</li>
<li>results:  experiments on standard multi-label recognition benchmarks across two challenging low-label settings demonstrate the superior performance of our approach compared to state-of-the-art methods.<details>
<summary>Abstract</summary>
Multi-label image recognition in the low-label regime is a task of great challenge and practical significance. Previous works have focused on learning the alignment between textual and visual spaces to compensate for limited image labels, yet may suffer from reduced accuracy due to the scarcity of high-quality multi-label annotations. In this research, we leverage the powerful alignment between textual and visual features pretrained with millions of auxiliary image-text pairs. We introduce an efficient and effective framework called Evidence-guided Dual Context Optimization (DualCoOp++), which serves as a unified approach for addressing partial-label and zero-shot multi-label recognition. In DualCoOp++ we separately encode evidential, positive, and negative contexts for target classes as parametric components of the linguistic input (i.e., prompts). The evidential context aims to discover all the related visual content for the target class, and serves as guidance to aggregate positive and negative contexts from the spatial domain of the image, enabling better distinguishment between similar categories. Additionally, we introduce a Winner-Take-All module that promotes inter-class interaction during training, while avoiding the need for extra parameters and costs. As DualCoOp++ imposes minimal additional learnable overhead on the pretrained vision-language framework, it enables rapid adaptation to multi-label recognition tasks with limited annotations and even unseen classes. Experiments on standard multi-label recognition benchmarks across two challenging low-label settings demonstrate the superior performance of our approach compared to state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
多 label 图像识别在低标签 régime 是一项具有挑战性和实际意义的任务。先前的工作通过学习图像和文本空间之间的对应关系来资料缺乏多 label 约束，但可能会受到丰富约束的影响。在本研究中，我们利用图像和文本特征之间的强大对应关系，预训练了数百万个辅助图像-文本对。我们提出了一种高效的框架，称为 Evidence-guided Dual Context Optimization (DualCoOp++)，它是一种综合性的方法，用于解决 partial-label 和 zero-shot 多 label 识别任务。在 DualCoOp++ 中，我们分别对目标类的 evidential、正例和负例上下文进行编码，并将它们作为文本输入（即提示）的参数。目标类的 evidential 上下文旨在找到与其相关的所有视觉内容，并作为指导，将正例和负例上下文从图像的空间领域集成，以提高类别之间的分辨率。此外，我们还提出了一种 Winner-Take-All 模块，它在训练过程中促进了类之间的互动，而不需要额外的参数和成本。由于 DualCoOp++ 对预训练的视觉语言框架增加了最小的可学习增加，因此它可以快速适应多 label 识别任务，即使有限的标签和未知的类别。我们在标准多 label 识别测试上进行了两个低标签设定下的实验，并证明了我们的方法在比 estado-of-the-art 方法更高效。
</details></li>
</ul>
<hr>
<h2 id="FROD-Robust-Object-Detection-for-Free"><a href="#FROD-Robust-Object-Detection-for-Free" class="headerlink" title="FROD: Robust Object Detection for Free"></a>FROD: Robust Object Detection for Free</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01888">http://arxiv.org/abs/2308.01888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad, Awais, Weiming, Zhuang, Lingjuan, Lyu, Sung-Ho, Bae</li>
<li>for: 提高物体检测器的鲁棒性，尤其是对于小型攻击的鲁棒性。</li>
<li>methods: 利用针对攻击的 adversarially 训练的分类模型作为物体检测器的基础模型，并对基础模型进行修改以实现鲁棒性。</li>
<li>results: 通过两种轻量级组件——模仿损失和延迟反恶作用训练——进一步提高物体检测器的鲁棒性，并在 MS-COCO 和 Pascal VOC 数据集上进行了广泛的实验来证明提案的有效性。<details>
<summary>Abstract</summary>
Object detection is a vital task in computer vision and has become an integral component of numerous critical systems. However, state-of-the-art object detectors, similar to their classification counterparts, are susceptible to small adversarial perturbations that can significantly alter their normal behavior. Unlike classification, the robustness of object detectors has not been thoroughly explored. In this work, we take the initial step towards bridging the gap between the robustness of classification and object detection by leveraging adversarially trained classification models. Merely utilizing adversarially trained models as backbones for object detection does not result in robustness. We propose effective modifications to the classification-based backbone to instill robustness in object detection without incurring any computational overhead. To further enhance the robustness achieved by the proposed modified backbone, we introduce two lightweight components: imitation loss and delayed adversarial training. Extensive experiments on the MS-COCO and Pascal VOC datasets are conducted to demonstrate the effectiveness of our proposed approach.
</details>
<details>
<summary>摘要</summary>
Object detection 是计算机视觉中的一项重要任务，已成为许多关键系统的重要组件。然而，当前的状态体检器，与分类器一样，受到小型恶作剂的影响，可能导致它们的正常行为发生重大变化。与分类器不同的是，对象检测器的可靠性还没有得到了充分的探索。在这项工作中，我们通过利用针对攻击的分类器模型来减轻这一问题，开始尝试将分类器和检测器的可靠性更加相似。但是，直接使用针对攻击的分类器模型作为检测器的后备，并不能确保对象检测器的可靠性。我们提出了一些有效的修改，以使得分类器后备具备对象检测器的Robustness，而不需要任何计算负担增加。此外，我们还引入了两种轻量级组件：模仿损失和延迟攻击训练。我们对 MS-COCO 和 Pascal VOC 数据集进行了广泛的实验，以证明我们的提出的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="ConceptLab-Creative-Generation-using-Diffusion-Prior-Constraints"><a href="#ConceptLab-Creative-Generation-using-Diffusion-Prior-Constraints" class="headerlink" title="ConceptLab: Creative Generation using Diffusion Prior Constraints"></a>ConceptLab: Creative Generation using Diffusion Prior Constraints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02669">http://arxiv.org/abs/2308.02669</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kfirgoldberg/ConceptLab">https://github.com/kfirgoldberg/ConceptLab</a></li>
<li>paper_authors: Elad Richardson, Kfir Goldberg, Yuval Alaluf, Daniel Cohen-Or</li>
<li>for: 本研究旨在提出一种创新的文本到图像生成任务，即生成一个新的、从未seen before的概念。</li>
<li>methods: 我们使用了Diffusion Prior模型，并解释了如何将创意生成问题формализова为输出空间的优化问题，从而获得一组“先验约束”。</li>
<li>results: 我们的研究表明，通过在优化问题中适应添加问题回答模型，可以避免生成的概念混合到现有的成员中，并且可以在生成过程中创造更多的创新性。此外，我们还发现了“先验约束”可以作为一种强大的混合机制，使得我们可以在生成过程中创造更多的杂合体。<details>
<summary>Abstract</summary>
Recent text-to-image generative models have enabled us to transform our words into vibrant, captivating imagery. The surge of personalization techniques that has followed has also allowed us to imagine unique concepts in new scenes. However, an intriguing question remains: How can we generate a new, imaginary concept that has never been seen before? In this paper, we present the task of creative text-to-image generation, where we seek to generate new members of a broad category (e.g., generating a pet that differs from all existing pets). We leverage the under-studied Diffusion Prior models and show that the creative generation problem can be formulated as an optimization process over the output space of the diffusion prior, resulting in a set of "prior constraints". To keep our generated concept from converging into existing members, we incorporate a question-answering model that adaptively adds new constraints to the optimization problem, encouraging the model to discover increasingly more unique creations. Finally, we show that our prior constraints can also serve as a strong mixing mechanism allowing us to create hybrids between generated concepts, introducing even more flexibility into the creative process.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Reconstructing-Three-Dimensional-Models-of-Interacting-Humans"><a href="#Reconstructing-Three-Dimensional-Models-of-Interacting-Humans" class="headerlink" title="Reconstructing Three-Dimensional Models of Interacting Humans"></a>Reconstructing Three-Dimensional Models of Interacting Humans</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01854">http://arxiv.org/abs/2308.01854</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sminchisescu-research/imar_vision_datasets_tools">https://github.com/sminchisescu-research/imar_vision_datasets_tools</a></li>
<li>paper_authors: Mihai Fieraru, Mihai Zanfir, Elisabeta Oneata, Alin-Ionut Popa, Vlad Olaru, Cristian Sminchisescu</li>
<li>For: This paper focuses on improving the accuracy of 3D human interactions, which is essential for fine-grained scene analysis and behavioral modeling.* Methods: The authors introduce several new models for interaction signature estimation (ISP), including contact detection, segmentation, and 3D contact signature prediction. They also show how these components can be used to ensure contact consistency during 3D reconstruction.* Results: The authors construct several large datasets for learning and evaluating 3D contact prediction and reconstruction methods, including CHI3D and FlickrCI3D. They also propose a methodology for recovering the ground-truth pose and shape of interacting people in a controlled setup and annotate all 3D interaction motions in CHI3D with textual descriptions.<details>
<summary>Abstract</summary>
Understanding 3d human interactions is fundamental for fine-grained scene analysis and behavioural modeling. However, most of the existing models predict incorrect, lifeless 3d estimates, that miss the subtle human contact aspects--the essence of the event--and are of little use for detailed behavioral understanding. This paper addresses such issues with several contributions: (1) we introduce models for interaction signature estimation (ISP) encompassing contact detection, segmentation, and 3d contact signature prediction; (2) we show how such components can be leveraged to ensure contact consistency during 3d reconstruction; (3) we construct several large datasets for learning and evaluating 3d contact prediction and reconstruction methods; specifically, we introduce CHI3D, a lab-based accurate 3d motion capture dataset with 631 sequences containing $2,525$ contact events, $728,664$ ground truth 3d poses, as well as FlickrCI3D, a dataset of $11,216$ images, with $14,081$ processed pairs of people, and $81,233$ facet-level surface correspondences. Finally, (4) we propose methodology for recovering the ground-truth pose and shape of interacting people in a controlled setup and (5) annotate all 3d interaction motions in CHI3D with textual descriptions. Motion data in multiple formats (GHUM and SMPLX parameters, Human3.6m 3d joints) is made available for research purposes at \url{https://ci3d.imar.ro}, together with an evaluation server and a public benchmark.
</details>
<details>
<summary>摘要</summary>
理解人类三维交互是场景分析和行为模型的基础。然而，大多数现有模型预测错误的、无生命的三维估计，缺少人类接触细节--场景的核心--并对详细行为理解无用。本文解决这些问题，并提供以下贡献：1. 我们引入交互特征估计（ISP）模型，包括接触检测、分割和三维接触特征预测；2. 我们示出如何使用这些组件保证接触一致性 during 3D重建；3. 我们建立了多个大型数据集用于学习和评估3D接触预测和重建方法，其中包括CHI3D，一个室内精确3D动作捕捉数据集，包含2,525个接触事件，728,664个真实3D姿势、以及FlickrCI3D，一个包含11,216个图像、14,081个处理后的人物对象、81,233个表面匹配的数据集。最后，4. 我们提出了方法来恢复实际的人类接触姿势和形状，并5. 对CHI3D数据集中的所有3D交互动作进行文本描述。运动数据在多种格式（GHUM和SMPLX参数、人类3.6m JOINTS）可以用于研究目的下载于\url{https://ci3d.imar.ro}，同时也提供评估服务器和公共准则。
</details></li>
</ul>
<hr>
<h2 id="Is-your-data-alignable-Principled-and-interpretable-alignability-testing-and-integration-of-single-cell-data"><a href="#Is-your-data-alignable-Principled-and-interpretable-alignability-testing-and-integration-of-single-cell-data" class="headerlink" title="Is your data alignable? Principled and interpretable alignability testing and integration of single-cell data"></a>Is your data alignable? Principled and interpretable alignability testing and integration of single-cell data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01839">http://arxiv.org/abs/2308.01839</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rongstat/smai">https://github.com/rongstat/smai</a></li>
<li>paper_authors: Rong Ma, Eric D. Sun, David Donoho, James Zou</li>
<li>for: 提供一个整体分子视图的单元数据集合并将其 инте格рирова为多种算法来消除技术和生物学的干扰。</li>
<li>methods:  spectral manifold alignment and inference (SMAI) 框架，该框架提供了一种可靠的统计测试以确定数据集之间的可alignability，并且可以保持数据的结构Integrity。</li>
<li>results: SMAI在多个实际和模拟 benchmark 数据集上表现出色，并且可以提高各种后续分析，如差异表达基因的鉴定和单元 spatial transcriptomics 的填充。<details>
<summary>Abstract</summary>
Single-cell data integration can provide a comprehensive molecular view of cells, and many algorithms have been developed to remove unwanted technical or biological variations and integrate heterogeneous single-cell datasets. Despite their wide usage, existing methods suffer from several fundamental limitations. In particular, we lack a rigorous statistical test for whether two high-dimensional single-cell datasets are alignable (and therefore should even be aligned). Moreover, popular methods can substantially distort the data during alignment, making the aligned data and downstream analysis difficult to interpret. To overcome these limitations, we present a spectral manifold alignment and inference (SMAI) framework, which enables principled and interpretable alignability testing and structure-preserving integration of single-cell data. SMAI provides a statistical test to robustly determine the alignability between datasets to avoid misleading inference, and is justified by high-dimensional statistical theory. On a diverse range of real and simulated benchmark datasets, it outperforms commonly used alignment methods. Moreover, we show that SMAI improves various downstream analyses such as identification of differentially expressed genes and imputation of single-cell spatial transcriptomics, providing further biological insights. SMAI's interpretability also enables quantification and a deeper understanding of the sources of technical confounders in single-cell data.
</details>
<details>
<summary>摘要</summary>
单元数据集 интеграción可以提供完整的分子视图单元，并有许多算法开发以除掉技术或生物学变化。Despite their widespread use, existing methods have several fundamental limitations. In particular, we lack a rigorous statistical test for whether two high-dimensional single-cell datasets are alignable (and therefore should even be aligned). Moreover, popular methods can significantly distort the data during alignment, making the aligned data and downstream analysis difficult to interpret. To overcome these limitations, we present a spectral manifold alignment and inference (SMAI) framework, which enables principled and interpretable alignability testing and structure-preserving integration of single-cell data. SMAI provides a statistical test to robustly determine the alignability between datasets to avoid misleading inference, and is justified by high-dimensional statistical theory. On a diverse range of real and simulated benchmark datasets, it outperforms commonly used alignment methods. Moreover, we show that SMAI improves various downstream analyses such as identification of differentially expressed genes and imputation of single-cell spatial transcriptomics, providing further biological insights. SMAI's interpretability also enables quantification and a deeper understanding of the sources of technical confounders in single-cell data.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/04/cs.CV_2023_08_04/" data-id="closbroo800g80g88egwx6d8a" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_04" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/04/cs.AI_2023_08_04/" class="article-date">
  <time datetime="2023-08-04T12:00:00.000Z" itemprop="datePublished">2023-08-04</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/04/cs.AI_2023_08_04/">cs.AI - 2023-08-04</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="A-Differential-Datalog-Interpreter"><a href="#A-Differential-Datalog-Interpreter" class="headerlink" title="A Differential Datalog Interpreter"></a>A Differential Datalog Interpreter</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04214">http://arxiv.org/abs/2308.04214</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/erl4ng/A-Differential-Datalog-Interpreter">https://github.com/erl4ng/A-Differential-Datalog-Interpreter</a></li>
<li>paper_authors: Bruno Rucy Carneiro Alves de Lima, Merlin Kramer, Kalmer Apinis</li>
<li>for: 本研究 investigate  datalog 材料化的性能，并与三个参考实现进行比较，其中一个基于轻量级关系引擎，另外两个分别使用不同的算法和优化。</li>
<li>methods: 本研究使用了 differential 数据流模型，并对三个参考实现进行了比较，以评估它们在添加和删除数据时的性能。</li>
<li>results: 研究发现，使用 differential 数据流模型可以实现等效的添加和删除操作性能，并且可以均衡工作负荷。<details>
<summary>Abstract</summary>
The core reasoning task for datalog engines is materialization, the evaluation of a datalog program over a database alongside its physical incorporation into the database itself. The de-facto method of computing it, is through the recursive application of inference rules. Due to it being a costly operation, it is a must for datalog engines to provide incremental materialization, that is, to adjust the computation to new data, instead of restarting from scratch. One of the major caveats, is that deleting data is notoriously more involved than adding, since one has to take into account all possible data that has been entailed from what is being deleted. Differential Dataflow is a computational model that provides efficient incremental maintenance, notoriously with equal performance between additions and deletions, and work distribution, of iterative dataflows. In this paper we investigate the performance of materialization with three reference datalog implementations, out of which one is built on top of a lightweight relational engine, and the two others are differential-dataflow and non-differential versions of the same rewrite algorithm, with the same optimizations.
</details>
<details>
<summary>摘要</summary>
核心逻辑任务 для datalog 引擎是材料化，即将 datalog 程序应用于数据库并将其物理integrated 到数据库中。现行方法是通过 recursively 应用推理规则来实现。由于这是一个昂贵的操作，因此 datalog 引擎必须提供增量材料化，即根据新数据进行计算而不是从scratch 重新开始。其中一个主要缺点是，删除数据是与添加数据相比更加复杂，因为需要考虑所有可能的数据，从被删除的数据中推导出来的所有数据。 differential 数据流是一种计算模型，它提供了高效的增量维护，并且在添加和删除数据方面具有相同的性能，以及分布式的数据流处理。在这篇论文中，我们 investigate 材料化的性能，使用三个参考 datalog 实现，其中一个基于轻量级关系引擎，另外两个是不同的推理算法的增量和非增量版本，均具有同样的优化。
</details></li>
</ul>
<hr>
<h2 id="Scaling-Survival-Analysis-in-Healthcare-with-Federated-Survival-Forests-A-Comparative-Study-on-Heart-Failure-and-Breast-Cancer-Genomics"><a href="#Scaling-Survival-Analysis-in-Healthcare-with-Federated-Survival-Forests-A-Comparative-Study-on-Heart-Failure-and-Breast-Cancer-Genomics" class="headerlink" title="Scaling Survival Analysis in Healthcare with Federated Survival Forests: A Comparative Study on Heart Failure and Breast Cancer Genomics"></a>Scaling Survival Analysis in Healthcare with Federated Survival Forests: A Comparative Study on Heart Failure and Breast Cancer Genomics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02382">http://arxiv.org/abs/2308.02382</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alberto Archetti, Francesca Ieva, Matteo Matteucci</li>
<li>for: 这个论文旨在 Addressing the challenges of survival data and large-scale survival applications in healthcare settings, where privacy is critical.</li>
<li>methods: 该论文提出了一种基于 Federated learning 的扩展方法，即 FedSurF++，可以在多个数据集上构建随机生存森林，并比现有方法具有更好的效率、稳定性和隐私保护。</li>
<li>results: 实验结果表明，FedSurF++ 可以与现有方法相比，在效率和隐私保护两个方面具有显著的改进，并在实际应用中对两个真实世界数据集进行了成功的应用。<details>
<summary>Abstract</summary>
Survival analysis is a fundamental tool in medicine, modeling the time until an event of interest occurs in a population. However, in real-world applications, survival data are often incomplete, censored, distributed, and confidential, especially in healthcare settings where privacy is critical. The scarcity of data can severely limit the scalability of survival models to distributed applications that rely on large data pools. Federated learning is a promising technique that enables machine learning models to be trained on multiple datasets without compromising user privacy, making it particularly well-suited for addressing the challenges of survival data and large-scale survival applications. Despite significant developments in federated learning for classification and regression, many directions remain unexplored in the context of survival analysis. In this work, we propose an extension of the Federated Survival Forest algorithm, called FedSurF++. This federated ensemble method constructs random survival forests in heterogeneous federations. Specifically, we investigate several new tree sampling methods from client forests and compare the results with state-of-the-art survival models based on neural networks. The key advantage of FedSurF++ is its ability to achieve comparable performance to existing methods while requiring only a single communication round to complete. The extensive empirical investigation results in a significant improvement from the algorithmic and privacy preservation perspectives, making the original FedSurF algorithm more efficient, robust, and private. We also present results on two real-world datasets demonstrating the success of FedSurF++ in real-world healthcare studies. Our results underscore the potential of FedSurF++ to improve the scalability and effectiveness of survival analysis in distributed settings while preserving user privacy.
</details>
<details>
<summary>摘要</summary>
生存分析是医学中的基本工具，用于计算人口中事件兴奋的时间。然而，在实际应用中，生存数据经常是不完整、审核、分布和保密的，特别是在医疗设置中，隐私是极其重要的。数据的缺乏可能会限制生存模型的扩展性，使其无法应用于大规模的分布式应用程序。联邦学习是一种有 Promise的技术，它允许机器学习模型在多个数据集上进行训练，而不需要牺牲用户隐私。这使得联邦学习在生存数据和大规模生存应用中非常有优势。 despite significant developments in federated learning for classification and regression, many directions remain unexplored in the context of survival analysis.在这项工作中，我们提出了一种基于联邦生存森林算法的扩展，即 FedSurF++。这是一种联邦ensemble方法，可以在多个不同的机器学习模型之间进行混合。我们 investigate several new tree sampling methods from client forests and compare the results with state-of-the-art survival models based on neural networks. FedSurF++的关键优点在于它可以与现有方法相比，只需要一次通信往返完成，从算法和隐私保持角度来看，它更高效、更稳定、更隐私。我们还在两个实际数据集上进行了实验，demonstrating the success of FedSurF++ in real-world healthcare studies.our results underscore the potential of FedSurF++ to improve the scalability and effectiveness of survival analysis in distributed settings while preserving user privacy.
</details></li>
</ul>
<hr>
<h2 id="Vulnerabilities-in-AI-Code-Generators-Exploring-Targeted-Data-Poisoning-Attacks"><a href="#Vulnerabilities-in-AI-Code-Generators-Exploring-Targeted-Data-Poisoning-Attacks" class="headerlink" title="Vulnerabilities in AI Code Generators: Exploring Targeted Data Poisoning Attacks"></a>Vulnerabilities in AI Code Generators: Exploring Targeted Data Poisoning Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04451">http://arxiv.org/abs/2308.04451</a></li>
<li>repo_url: None</li>
<li>paper_authors: Domenico Cotroneo, Cristina Improta, Pietro Liguori, Roberto Natella</li>
<li>for: 本研究探讨了人工智能代码生成器的安全性，通过数据恶意掺入攻击，即在训练数据中插入恶意代码来生成漏洞代码。</li>
<li>methods: 我们使用不同的状态对代码生成器进行训练，然后通过插入恶意代码来攻击代码生成器。我们还对不同的模型进行比较，以确定哪些模型更容易受到攻击。</li>
<li>results: 我们的分析表明，AI代码生成器具有恶意掺入攻击的敏感性，即使只有小量恶意代码掺入，也可以导致代码生成器生成漏洞代码。此外，攻击不会影响代码生成器生成的代码的正确性，这使得攻击更难以发现。<details>
<summary>Abstract</summary>
In this work, we assess the security of AI code generators via data poisoning, i.e., an attack that injects malicious samples into the training data to generate vulnerable code. We poison the training data by injecting increasing amounts of code containing security vulnerabilities and assess the attack's success on different state-of-the-art models for code generation. Our analysis shows that AI code generators are vulnerable to even a small amount of data poisoning. Moreover, the attack does not impact the correctness of code generated by pre-trained models, making it hard to detect.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们评估人工智能代码生成器的安全性via数据恶意攻击，即通过把恶意样本注入到训练数据中来生成漏洞代码。我们在训练数据中注入递增的代码中存在安全漏洞的代码，并评估不同的现代代码生成模型的攻击成功率。我们的分析显示，AI代码生成器对数据恶意攻击很易受到影响，而且这种攻击不会影响预训练模型生成的代码正确性，从而使攻击更加困难发现。
</details></li>
</ul>
<hr>
<h2 id="Harnessing-the-Web-and-Knowledge-Graphs-for-Automated-Impact-Investing-Scoring"><a href="#Harnessing-the-Web-and-Knowledge-Graphs-for-Automated-Impact-Investing-Scoring" class="headerlink" title="Harnessing the Web and Knowledge Graphs for Automated Impact Investing Scoring"></a>Harnessing the Web and Knowledge Graphs for Automated Impact Investing Scoring</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02622">http://arxiv.org/abs/2308.02622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingzhi Hu, Daniel Daza, Laurens Swinkels, Kristina Ūsaitė, Robbert-Jan ‘t Hoen, Paul Groth<br>for:The paper aims to automate the process of creating an SDG framework for the finance industry.methods:The proposed system uses a data-driven approach, collecting and filtering a dataset of texts from different web sources and a knowledge graph relevant to a set of companies. Classifiers trained with this data are used to predict scores of alignment with SDGs for a given company.results:The best performing model achieved a micro average F1 score of 0.89, demonstrating the effectiveness of the proposed solution. The system also provides explanations in the form of data relevant to a predicted score, facilitating its use by humans. Additionally, the system enables accurate prediction of SDG scores at a fraction of the cost of traditional methods.<details>
<summary>Abstract</summary>
The Sustainable Development Goals (SDGs) were introduced by the United Nations in order to encourage policies and activities that help guarantee human prosperity and sustainability. SDG frameworks produced in the finance industry are designed to provide scores that indicate how well a company aligns with each of the 17 SDGs. This scoring enables a consistent assessment of investments that have the potential of building an inclusive and sustainable economy. As a result of the high quality and reliability required by such frameworks, the process of creating and maintaining them is time-consuming and requires extensive domain expertise. In this work, we describe a data-driven system that seeks to automate the process of creating an SDG framework. First, we propose a novel method for collecting and filtering a dataset of texts from different web sources and a knowledge graph relevant to a set of companies. We then implement and deploy classifiers trained with this data for predicting scores of alignment with SDGs for a given company. Our results indicate that our best performing model can accurately predict SDG scores with a micro average F1 score of 0.89, demonstrating the effectiveness of the proposed solution. We further describe how the integration of the models for its use by humans can be facilitated by providing explanations in the form of data relevant to a predicted score. We find that our proposed solution enables access to a large amount of information that analysts would normally not be able to process, resulting in an accurate prediction of SDG scores at a fraction of the cost.
</details>
<details>
<summary>摘要</summary>
联合国发布可持续发展目标（SDGs），以促进人类发展和可持续性。 SDG框架在金融业中生成的分数可以衡量公司与每一个SDG的匹配程度。这种分数可以帮助评估投资，推动建立包容和可持续的经济。由于需要高质量和可靠性，创建和维护SDG框架的过程是时间消耗和需要广泛领域专业知识的。在这份工作中，我们描述了一种数据驱动的系统，用于自动创建SDG框架。我们首先提出了一种新的方法，用于收集和筛选不同网络源和知识图库相关公司的文本数据集。然后，我们实现和部署基于这些数据的分类器，用于预测公司与SDGs的匹配度。我们的结果表明，我们的最佳表现模型可以准确预测公司与SDGs的匹配度，微平均F1分数为0.89，证明我们的提案得到了效果。此外，我们还描述了如何将模型与人类使用者集成，通过提供预测分数的数据解释。我们发现，我们的提案的解决方案可以提供大量的信息，让分析员可以快速和准确地预测SDG分数，只需一小部分的成本。
</details></li>
</ul>
<hr>
<h2 id="A-Machine-Learning-Method-for-Predicting-Traffic-Signal-Timing-from-Probe-Vehicle-Data"><a href="#A-Machine-Learning-Method-for-Predicting-Traffic-Signal-Timing-from-Probe-Vehicle-Data" class="headerlink" title="A Machine Learning Method for Predicting Traffic Signal Timing from Probe Vehicle Data"></a>A Machine Learning Method for Predicting Traffic Signal Timing from Probe Vehicle Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02370">http://arxiv.org/abs/2308.02370</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juliette Ugirumurera, Joseph Severino, Erik A. Bensen, Qichao Wang, Jane Macfarlane</li>
<li>for: 本研究主要目的是为了从车辆探测数据中提取交通信号 timing信息，以便实现交通管理和安全性。</li>
<li>methods: 本研究使用机器学习（ML）技术来估算交通信号时间信息。具体来说，我们使用极限梯度提升（XGBoost）模型来估算信号周期长度，并使用神经网络模型来确定每个阶段的红灯时间。</li>
<li>results: 我们的结果显示，对于交通信号周期长度和红灯时间的预测，XGBoost模型的误差在0.56秒之下，而神经网络模型的误差在7.2秒之间。<details>
<summary>Abstract</summary>
Traffic signals play an important role in transportation by enabling traffic flow management, and ensuring safety at intersections. In addition, knowing the traffic signal phase and timing data can allow optimal vehicle routing for time and energy efficiency, eco-driving, and the accurate simulation of signalized road networks. In this paper, we present a machine learning (ML) method for estimating traffic signal timing information from vehicle probe data. To the authors best knowledge, very few works have presented ML techniques for determining traffic signal timing parameters from vehicle probe data. In this work, we develop an Extreme Gradient Boosting (XGBoost) model to estimate signal cycle lengths and a neural network model to determine the corresponding red times per phase from probe data. The green times are then be derived from the cycle length and red times. Our results show an error of less than 0.56 sec for cycle length, and red times predictions within 7.2 sec error on average.
</details>
<details>
<summary>摘要</summary>
交通信号机器人agement plays an important role in transportation by enabling traffic flow management and ensuring safety at intersections. In addition, knowing the traffic signal phase and timing data can allow optimal vehicle routing for time and energy efficiency, eco-driving, and the accurate simulation of signalized road networks. In this paper, we present a machine learning (ML) method for estimating traffic signal timing information from vehicle probe data. To the authors' best knowledge, very few works have presented ML techniques for determining traffic signal timing parameters from vehicle probe data. In this work, we develop an Extreme Gradient Boosting (XGBoost) model to estimate signal cycle lengths and a neural network model to determine the corresponding red times per phase from probe data. The green times are then derived from the cycle length and red times. Our results show an error of less than 0.56 sec for cycle length, and red times predictions within 7.2 sec error on average.Here's the translation in Traditional Chinese:交通信号机器人agement plays an important role in transportation by enabling traffic flow management and ensuring safety at intersections. In addition, knowing the traffic signal phase and timing data can allow optimal vehicle routing for time and energy efficiency, eco-driving, and the accurate simulation of signalized road networks. In this paper, we present a machine learning (ML) method for estimating traffic signal timing information from vehicle probe data. To the authors' best knowledge, very few works have presented ML techniques for determining traffic signal timing parameters from vehicle probe data. In this work, we develop an Extreme Gradient Boosting (XGBoost) model to estimate signal cycle lengths and a neural network model to determine the corresponding red times per phase from probe data. The green times are then derived from the cycle length and red times. Our results show an error of less than 0.56 sec for cycle length, and red times predictions within 7.2 sec error on average.
</details></li>
</ul>
<hr>
<h2 id="Universal-Defensive-Underpainting-Patch-Making-Your-Text-Invisible-to-Optical-Character-Recognition"><a href="#Universal-Defensive-Underpainting-Patch-Making-Your-Text-Invisible-to-Optical-Character-Recognition" class="headerlink" title="Universal Defensive Underpainting Patch: Making Your Text Invisible to Optical Character Recognition"></a>Universal Defensive Underpainting Patch: Making Your Text Invisible to Optical Character Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02369">http://arxiv.org/abs/2308.02369</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qrickdd/udup">https://github.com/qrickdd/udup</a></li>
<li>paper_authors: JiaCheng Deng, Li Dong, Jiahao Chen, Diqun Yan, Rangding Wang, Dengpan Ye, Lingchen Zhao, Jinyu Tian</li>
<li>for: 防止 Optical Character Recognition (OCR) 盗版，保护敏感文本图像</li>
<li>methods: 使用 Universal Defensive Underpainting Patch (UDUP) 修改文本图像的底层颜色，防止盗版</li>
<li>results: 在各种 screenshot 范围和复杂背景下，有效防止未经授权 OCR，并对文本图像大小、颜色和语言等特点表示不敏感，可以跨多个 OCR 系统进行跨度测试。<details>
<summary>Abstract</summary>
Optical Character Recognition (OCR) enables automatic text extraction from scanned or digitized text images, but it also makes it easy to pirate valuable or sensitive text from these images. Previous methods to prevent OCR piracy by distorting characters in text images are impractical in real-world scenarios, as pirates can capture arbitrary portions of the text images, rendering the defenses ineffective. In this work, we propose a novel and effective defense mechanism termed the Universal Defensive Underpainting Patch (UDUP) that modifies the underpainting of text images instead of the characters. UDUP is created through an iterative optimization process to craft a small, fixed-size defensive patch that can generate non-overlapping underpainting for text images of any size. Experimental results show that UDUP effectively defends against unauthorized OCR under the setting of any screenshot range or complex image background. It is agnostic to the content, size, colors, and languages of characters, and is robust to typical image operations such as scaling and compressing. In addition, the transferability of UDUP is demonstrated by evading several off-the-shelf OCRs. The code is available at https://github.com/QRICKDD/UDUP.
</details>
<details>
<summary>摘要</summary>
Optical Character Recognition (OCR) 可以自动从扫描或数字化的文本图像中提取文本，但也使得偷窃有价或敏感文本成为可能。前一些防止 OCR 盗版的方法，例如扭曲字符在文本图像中，在实际应用中是无效的，因为盗版者可以捕捉文本图像中任意部分，使防御无效。在这个工作中，我们提出了一个新的防御机制，称为“ Universal Defensive Underpainting Patch”（UDUP）。UDUP 通过迭代优化过程，创建一个小型、固定大小的防御贴片，可以为任何文本图像 generate 非重合的底层。实验结果显示，UDUP 能够对不授权 OCR 进行有效防御，不论屏幕截图范围或复杂的图像背景。它不受字符内容、大小、颜色和语言等因素影响，并具有对于常见的图像操作，如缩小和压缩，的抗衰变性。此外，我们还证明了 UDUP 的传染性，可以避免多个商业 OCR 辨识。代码可以在 <https://github.com/QRICKDD/UDUP> 获取。
</details></li>
</ul>
<hr>
<h2 id="ChatGPT-for-GTFS-From-Words-to-Information"><a href="#ChatGPT-for-GTFS-From-Words-to-Information" class="headerlink" title="ChatGPT for GTFS: From Words to Information"></a>ChatGPT for GTFS: From Words to Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02618">http://arxiv.org/abs/2308.02618</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/utel-uiuc/gtfs_llm">https://github.com/utel-uiuc/gtfs_llm</a></li>
<li>paper_authors: Saipraneeth Devunuri, Shirin Qiam, Lewis Lehe</li>
<li>for: 本研究旨在检验当前广泛采用的大型自然语言模型（ChatGPT）是否能够从GTFS数据集中提取信息，使用自然语言指令。</li>
<li>methods: 本研究使用GPT-3.5进行测试，并对 filtered GTFS 数据集进行信息提取， comparative study of zero-shot 和程序生成。</li>
<li>results: GPT-3.5 能够正确答复多项选择问题（MCQ）的比例为 77%，并在简单问题和复杂问题上达到了 ~90% 和 ~40% 的准确率。<details>
<summary>Abstract</summary>
The General Transit Feed Specification (GTFS) standard for publishing transit data is ubiquitous. GTFS being tabular data, with information spread across different files, necessitates specialized tools or packages to retrieve information. Concurrently, the use of Large Language Models for text and information retrieval is growing. The idea of this research is to see if the current widely adopted LLMs (ChatGPT) are able to retrieve information from GTFS using natural language instructions. We first test whether ChatGPT (GPT-3.5) understands the GTFS specification. GPT-3.5 answers 77% of our multiple-choice questions (MCQ) correctly. Next, we task the LLM with information extractions from a filtered GTFS feed with 4 routes. For information retrieval, we compare zero-shot and program synthesis. Program synthesis works better, achieving ~90% accuracy on simple questions and ~40% accuracy on complex questions.
</details>
<details>
<summary>摘要</summary>
《通用交通Feed标准（GTFS）》的普及性使得特殊工具或包装必须用于检索信息。同时，大型自然语言模型（LLM）在文本和信息检索方面的使用也在增长。这项研究的想法是看看当前普遍采用的LLM（ChatGPT）是否能够通过自然语言指令从GTFS中检索信息。我们首先测试GPT-3.5是否理解GTFS规范。GPT-3.5回答了77%的多选问题（MCQ）正确。接着，我们对筛选后的GTFSFeed进行了信息检索。为了进行信息检索，我们比较了零shot和程序合成。程序合成工具比较好，实现了简单问题的准确率达90%，复杂问题的准确率达40%。
</details></li>
</ul>
<hr>
<h2 id="Text2KGBench-A-Benchmark-for-Ontology-Driven-Knowledge-Graph-Generation-from-Text"><a href="#Text2KGBench-A-Benchmark-for-Ontology-Driven-Knowledge-Graph-Generation-from-Text" class="headerlink" title="Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation from Text"></a>Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation from Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02357">http://arxiv.org/abs/2308.02357</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://zenodo.org/record/7916716">https://zenodo.org/record/7916716</a></li>
<li>paper_authors: Nandana Mihindukulasooriya, Sanju Tiwari, Carlos F. Enguix, Kusum Lata</li>
<li>for: 本研究目的是评估语言模型对自然语言文本中提取知识 graphs（KG）的能力，并检验语言模型是否能够遵循给定的 ontology 和自然语言文本中的含义。</li>
<li>methods: 本研究使用了 Text2KGBench  benchmark，该 benchmark 基于 ontology 和自然语言文本，并使用了七个评估指标来评估语言模型的表现。</li>
<li>results: 研究发现，使用 Vicuna-13B 和 Alpaca-LoRA-13B 两种基eline模型，可以通过自动生成测试 caso 来提高语言模型对 KG 的生成能力，但是还有很多空间可以进行改进，特别是通过结合semantic web和自然语言处理技术。<details>
<summary>Abstract</summary>
The recent advances in large language models (LLM) and foundation models with emergent capabilities have been shown to improve the performance of many NLP tasks. LLMs and Knowledge Graphs (KG) can complement each other such that LLMs can be used for KG construction or completion while existing KGs can be used for different tasks such as making LLM outputs explainable or fact-checking in Neuro-Symbolic manner. In this paper, we present Text2KGBench, a benchmark to evaluate the capabilities of language models to generate KGs from natural language text guided by an ontology. Given an input ontology and a set of sentences, the task is to extract facts from the text while complying with the given ontology (concepts, relations, domain/range constraints) and being faithful to the input sentences. We provide two datasets (i) Wikidata-TekGen with 10 ontologies and 13,474 sentences and (ii) DBpedia-WebNLG with 19 ontologies and 4,860 sentences. We define seven evaluation metrics to measure fact extraction performance, ontology conformance, and hallucinations by LLMs. Furthermore, we provide results for two baseline models, Vicuna-13B and Alpaca-LoRA-13B using automatic prompt generation from test cases. The baseline results show that there is room for improvement using both Semantic Web and Natural Language Processing techniques.
</details>
<details>
<summary>摘要</summary>
（注：以下是简化中文版本）现有的大语言模型（LLM）和基础模型（基模）的进步，已经提高了许多自然语言处理（NLP）任务的性能。LLM和知识图（KG）可以相互补充，使LLM用于KG构建或完成，而现有的KG可以用于不同的任务，如使LLM输出Explainable或Fact-Checking在神经符号学方面。在本文中，我们提出了Text2KGBench，一个用于评估语言模型是否可以根据ontology生成知识图的Benchmark。给定输入ontology和一组句子，任务是从文本中提取事实，并遵循给定的ontology（概念、关系、领域/范围约束），同时保持输入句子的准确性。我们提供了两个数据集：Wikidata-TekGen与10个ontology和13474个句子，以及DBpedia-WebNLG与19个ontology和4860个句子。我们定义了七个评估指标，用于评估事实提取性能、ontology遵循性和LLM的幻想。此外，我们提供了两个基eline模型，Vicuna-13B和Alpaca-LoRA-13B的自动提示生成测试 caso的结果。基eline结果表明，还有很多可以通过semantic web和自然语言处理技术的提高。
</details></li>
</ul>
<hr>
<h2 id="Adapting-to-Change-Robust-Counterfactual-Explanations-in-Dynamic-Data-Landscapes"><a href="#Adapting-to-Change-Robust-Counterfactual-Explanations-in-Dynamic-Data-Landscapes" class="headerlink" title="Adapting to Change: Robust Counterfactual Explanations in Dynamic Data Landscapes"></a>Adapting to Change: Robust Counterfactual Explanations in Dynamic Data Landscapes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02353">http://arxiv.org/abs/2308.02353</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bardhprenkaj/hansel">https://github.com/bardhprenkaj/hansel</a></li>
<li>paper_authors: Bardh Prenkaj, Mario Villaizan-Vallelado, Tobias Leemann, Gjergji Kasneci</li>
<li>For: This paper proposes a novel semi-supervised graph counterfactual explainer (GCE) method called Dynamic GRAph Counterfactual Explainer (DyGRACE), which can learn the representation of each class in a binary classification scenario and identify counterfactuals without relying on an underlying black-box oracle.* Methods: DyGRACE leverages two graph autoencoders (GAEs) to learn the representation of the graph data, and optimizes a parametric density function (implemented as a logistic regression function) to identify counterfactuals by maximizing the factual autoencoder’s reconstruction error. The method also minimizes the counterfactual autoencoder’s error and maximizes the similarity between the factual and counterfactual graphs.* Results: DyGRACE is effective in identifying counterfactuals and can act as a drift detector, identifying distributional drift based on differences in reconstruction errors between iterations. It avoids reliance on the oracle’s predictions in successive iterations, thereby increasing the efficiency of counterfactual discovery. DyGRACE also has the capacity for contrastive learning and drift detection, offering new avenues for semi-supervised learning and explanation generation.Here’s the Chinese version of the three key points:* For: 这篇论文提出了一种新的半监督图像Counterfactual explainer（GCE）方法，即动态GRAphCounterfactual Explainer（DyGRACE），可以在二分类enario中学习每个类别的表示，并无需依赖于基础黑obox oracle。* Methods: DyGRACE利用了两个图像自编码器（GAEs）来学习图像数据的表示，并优化了一个参数化概率函数（实现为逻辑回归函数）来确定对象的counterfactuals，并最小化对应的counterfactual自编码器的错误。* Results: DyGRACE非常有效地确定counterfactuals，可以作为分布漂移检测器，根据不同的重构错误值来识别分布漂移。它避免了基础黑obox oracle的预测，从而提高了对counterfactual的发现效率。 DyGRACE还具有对比学习和分布检测的能力，这将为半监督学习和解释生成提供新的 Avenues。<details>
<summary>Abstract</summary>
We introduce a novel semi-supervised Graph Counterfactual Explainer (GCE) methodology, Dynamic GRAph Counterfactual Explainer (DyGRACE). It leverages initial knowledge about the data distribution to search for valid counterfactuals while avoiding using information from potentially outdated decision functions in subsequent time steps. Employing two graph autoencoders (GAEs), DyGRACE learns the representation of each class in a binary classification scenario. The GAEs minimise the reconstruction error between the original graph and its learned representation during training. The method involves (i) optimising a parametric density function (implemented as a logistic regression function) to identify counterfactuals by maximising the factual autoencoder's reconstruction error, (ii) minimising the counterfactual autoencoder's error, and (iii) maximising the similarity between the factual and counterfactual graphs. This semi-supervised approach is independent of an underlying black-box oracle. A logistic regression model is trained on a set of graph pairs to learn weights that aid in finding counterfactuals. At inference, for each unseen graph, the logistic regressor identifies the best counterfactual candidate using these learned weights, while the GAEs can be iteratively updated to represent the continual adaptation of the learned graph representation over iterations. DyGRACE is quite effective and can act as a drift detector, identifying distributional drift based on differences in reconstruction errors between iterations. It avoids reliance on the oracle's predictions in successive iterations, thereby increasing the efficiency of counterfactual discovery. DyGRACE, with its capacity for contrastive learning and drift detection, will offer new avenues for semi-supervised learning and explanation generation.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种新的半超vised图像Counterfactual Explainer（GCE）方法，即动态图像Counterfactual Explainer（DyGRACE）。它利用初始知识 Concerning the data distribution to search for valid counterfactuals while avoiding the use of potentially outdated decision functions in subsequent time steps. Employing two graph autoencoders（GAEs）, DyGRACE learns the representation of each class in a binary classification scenario. The GAEs minimize the reconstruction error between the original graph and its learned representation during training. The method involves（i）optimizing a parametric density function（implemented as a logistic regression function）to identify counterfactuals by maximizing the factual autoencoder's reconstruction error，（ii）minimizing the counterfactual autoencoder's error， and（iii）maximizing the similarity between the factual and counterfactual graphs. This semi-supervised approach is independent of an underlying black-box oracle. A logistic regression model is trained on a set of graph pairs to learn weights that aid in finding counterfactuals. At inference，for each unseen graph，the logistic regressor identifies the best counterfactual candidate using these learned weights，while the GAEs can be iteratively updated to represent the continual adaptation of the learned graph representation over iterations. DyGRACE is quite effective and can act as a drift detector，identifying distributional drift based on differences in reconstruction errors between iterations. It avoids reliance on the oracle's predictions in successive iterations，thereby increasing the efficiency of counterfactual discovery. DyGRACE，with its capacity for contrastive learning and drift detection，will offer new avenues for semi-supervised learning and explanation generation.
</details></li>
</ul>
<hr>
<h2 id="Vehicles-Control-Collision-Avoidance-using-Federated-Deep-Reinforcement-Learning"><a href="#Vehicles-Control-Collision-Avoidance-using-Federated-Deep-Reinforcement-Learning" class="headerlink" title="Vehicles Control: Collision Avoidance using Federated Deep Reinforcement Learning"></a>Vehicles Control: Collision Avoidance using Federated Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02614">http://arxiv.org/abs/2308.02614</a></li>
<li>repo_url: None</li>
<li>paper_authors: Badr Ben Elallid, Amine Abouaomar, Nabil Benamar, Abdellatif Kobbane</li>
<li>for: 这篇研究的目的是为了提高城市化人口和交通流量增长的情况下，实现车辆控制的有效管理和安全确保。</li>
<li>methods: 这篇研究使用了联邦深度强化学习（FDRL）技术，对车辆控制进行了全面的研究和分析。</li>
<li>results: 研究结果显示，使用FDDPG算法可以更好地控制车辆，预防碰撞和提高平均速度，而且与本地模型DDPG相比，FDDPG算法能够更好地降低旅行时间和提高平均速度。<details>
<summary>Abstract</summary>
In the face of growing urban populations and the escalating number of vehicles on the roads, managing transportation efficiently and ensuring safety have become critical challenges. To tackle these issues, the development of intelligent control systems for vehicles is paramount. This paper presents a comprehensive study on vehicle control for collision avoidance, leveraging the power of Federated Deep Reinforcement Learning (FDRL) techniques. Our main goal is to minimize travel delays and enhance the average speed of vehicles while prioritizing safety and preserving data privacy. To accomplish this, we conducted a comparative analysis between the local model, Deep Deterministic Policy Gradient (DDPG), and the global model, Federated Deep Deterministic Policy Gradient (FDDPG), to determine their effectiveness in optimizing vehicle control for collision avoidance. The results obtained indicate that the FDDPG algorithm outperforms DDPG in terms of effectively controlling vehicles and preventing collisions. Significantly, the FDDPG-based algorithm demonstrates substantial reductions in travel delays and notable improvements in average speed compared to the DDPG algorithm.
</details>
<details>
<summary>摘要</summary>
面对城市人口增长和交通量不断增加，管理交通efficiently和保障安全已成为核心挑战。为解决这些问题，车辆智能控制系统的开发变得非常重要。这篇论文介绍了车辆控制与碰撞避免的全面研究，利用联合深度强化学习（FDRL）技术。我们的主要目标是减少旅行延迟和提高车辆平均速度，同时尽量保持数据隐私。为此，我们进行了本地模型（DDPG）和全球模型（FDDPG）的比较分析，以确定它们在优化车辆控制方面的效果。结果表明，使用FDDPG算法可以更好地控制车辆，避免碰撞。更重要的是，FDDPG算法示出了明显减少旅行延迟和提高车辆平均速度的效果，相比DDPG算法。
</details></li>
</ul>
<hr>
<h2 id="RAHNet-Retrieval-Augmented-Hybrid-Network-for-Long-tailed-Graph-Classification"><a href="#RAHNet-Retrieval-Augmented-Hybrid-Network-for-Long-tailed-Graph-Classification" class="headerlink" title="RAHNet: Retrieval Augmented Hybrid Network for Long-tailed Graph Classification"></a>RAHNet: Retrieval Augmented Hybrid Network for Long-tailed Graph Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02335">http://arxiv.org/abs/2308.02335</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengyang Mao, Wei Ju, Yifang Qin, Xiao Luo, Ming Zhang</li>
<li>for: 本文 targets 图像、视频和社交媒体等多媒体数据的 GRAPH 分类 зада题，以提高 GRAPH 神经网络（GNNs）在不平衡的数据情况下的性能。</li>
<li>methods: 本文提出了一种名为 Retrieval Augmented Hybrid Network（RAHNet）的新框架，该框架包括一个强化了捕捉图像的 GRAPH 搜索模块和一个类中心supervised contrastive loss函数，以提高 GRAPH 神经网络的性能。</li>
<li>results: 实验表明，RAHNet 在多种流行的 benchmark 上表现出优于当前state-of-the-art方法。<details>
<summary>Abstract</summary>
Graph classification is a crucial task in many real-world multimedia applications, where graphs can represent various multimedia data types such as images, videos, and social networks. Previous efforts have applied graph neural networks (GNNs) in balanced situations where the class distribution is balanced. However, real-world data typically exhibit long-tailed class distributions, resulting in a bias towards the head classes when using GNNs and limited generalization ability over the tail classes. Recent approaches mainly focus on re-balancing different classes during model training, which fails to explicitly introduce new knowledge and sacrifices the performance of the head classes. To address these drawbacks, we propose a novel framework called Retrieval Augmented Hybrid Network (RAHNet) to jointly learn a robust feature extractor and an unbiased classifier in a decoupled manner. In the feature extractor training stage, we develop a graph retrieval module to search for relevant graphs that directly enrich the intra-class diversity for the tail classes. Moreover, we innovatively optimize a category-centered supervised contrastive loss to obtain discriminative representations, which is more suitable for long-tailed scenarios. In the classifier fine-tuning stage, we balance the classifier weights with two weight regularization techniques, i.e., Max-norm and weight decay. Experiments on various popular benchmarks verify the superiority of the proposed method against state-of-the-art approaches.
</details>
<details>
<summary>摘要</summary>
GRAPH Classification 是现实世界多媒体应用中的关键任务， graphs 可以表示不同类型的多媒体数据，如图像、视频和社交网络。  previoUs efforts 使用 graph neural networks (GNNs) 在平衡的情况下进行了应用，但实际数据通常具有长尾分布，导致 GNNs 中的偏袋猎和limited generalization 能力。 recent approaches 主要关注在模型训练中平衡不同类型的数据，但这会遗弃新的知识并且影响 head 类的性能。  To address these drawbacks, we propose a novel framework called Retrieval Augmented Hybrid Network (RAHNet) to jointly learn a robust feature extractor and an unbiased classifier in a decoupled manner. In the feature extractor training stage, we develop a graph retrieval module to search for relevant graphs that directly enrich the intra-class diversity for the tail classes. Moreover, we innovatively optimize a category-centered supervised contrastive loss to obtain discriminative representations, which is more suitable for long-tailed scenarios. In the classifier fine-tuning stage, we balance the classifier weights with two weight regularization techniques, i.e., Max-norm and weight decay. Experiments on various popular benchmarks verify the superiority of the proposed method against state-of-the-art approaches.
</details></li>
</ul>
<hr>
<h2 id="Interoperable-synthetic-health-data-with-SyntHIR-to-enable-the-development-of-CDSS-tools"><a href="#Interoperable-synthetic-health-data-with-SyntHIR-to-enable-the-development-of-CDSS-tools" class="headerlink" title="Interoperable synthetic health data with SyntHIR to enable the development of CDSS tools"></a>Interoperable synthetic health data with SyntHIR to enable the development of CDSS tools</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02613">http://arxiv.org/abs/2308.02613</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/potter-coder89/synthir">https://github.com/potter-coder89/synthir</a></li>
<li>paper_authors: Pavitra Chauhan, Mohsen Gamal Saad Askar, Bjørn Fjukstad, Lars Ailo Bongo, Edvard Pedersen</li>
<li>for: 这个论文旨在提出一种基于机器学习的临床决策支持系统（CDSS）的开发方法，使用高质量的病人日志和健康注册来开发CDSS工具。</li>
<li>methods: 该论文提出了一种使用生成的 электрон保健纪录（EHR）数据来开发CDSS工具的建议，并使用了Fast Healthcare Interoperability Resources（FHIR）标准、Gretel框架和Microsoft Azure FHIR服务器来实现数据互操作性和生成 sintetic EHR 数据。</li>
<li>results: 该论文通过使用挪威病人注册（NPR）和挪威药物投放（NorPD）数据来开发一个机器学习基于CDSS工具，并在SyntHIR系统上测试了该工具。<details>
<summary>Abstract</summary>
There is a great opportunity to use high-quality patient journals and health registers to develop machine learning-based Clinical Decision Support Systems (CDSS). To implement a CDSS tool in a clinical workflow, there is a need to integrate, validate and test this tool on the Electronic Health Record (EHR) systems used to store and manage patient data. However, it is often not possible to get the necessary access to an EHR system due to legal compliance. We propose an architecture for generating and using synthetic EHR data for CDSS tool development. The architecture is implemented in a system called SyntHIR. The SyntHIR system uses the Fast Healthcare Interoperability Resources (FHIR) standards for data interoperability, the Gretel framework for generating synthetic data, the Microsoft Azure FHIR server as the FHIR-based EHR system and SMART on FHIR framework for tool transportability. We demonstrate the usefulness of SyntHIR by developing a machine learning-based CDSS tool using data from the Norwegian Patient Register (NPR) and Norwegian Patient Prescriptions (NorPD). We demonstrate the development of the tool on the SyntHIR system and then lift it to the Open DIPS environment. In conclusion, SyntHIR provides a generic architecture for CDSS tool development using synthetic FHIR data and a testing environment before implementing it in a clinical setting. However, there is scope for improvement in terms of the quality of the synthetic data generated. The code is open source and available at https://github.com/potter-coder89/SyntHIR.git.
</details>
<details>
<summary>摘要</summary>
有一大机会使用高质量的病人日记和医疗注册来开发机器学习基于的临床决策支持系统（CDSS）。为实施一个CDSS工具在临床工作流程中，需要将其集成、验证和测试到医疗记录系统（EHR）上，但经常因法律合规而无法获得相关访问权限。我们提出了一种架构，用于生成和使用合成EHR数据来开发CDSS工具。该架构基于Fast Healthcare Interoperability Resources（FHIR）标准、Gretel框架、Microsoft Azure FHIR服务器和SMART on FHIR框架。我们示出了SyntHIR系统的用用实用性，通过使用挪威病人注册（NPR）和挪威药物预约（NorPD）的数据来开发一个机器学习基于的CDSS工具。我们将该工具在SyntHIR系统上开发，然后将其提取到Open DIPS环境中。综上所述，SyntHIR提供了一个通用的架构，用于CDSS工具开发，使用合成FHIR数据进行测试，并在临床环境中实施。然而，有可能提高合成数据的质量。代码可以在https://github.com/potter-coder89/SyntHIR.git中获取。
</details></li>
</ul>
<hr>
<h2 id="A-Controllable-Co-Creative-Agent-for-Game-System-Design"><a href="#A-Controllable-Co-Creative-Agent-for-Game-System-Design" class="headerlink" title="A Controllable Co-Creative Agent for Game System Design"></a>A Controllable Co-Creative Agent for Game System Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02317">http://arxiv.org/abs/2308.02317</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rohan Agarwal, Zhiyu Lin, Mark Riedl</li>
<li>for: 这篇论文旨在模拟游戏系统，以便在任何类型的游戏中实现控制性的合作创作。</li>
<li>methods: 该论文使用状态机制和资源流程来模型游戏，并使用可控的指标和设计评价器来评估设计。</li>
<li>results: 研究发现这种系统能够表达广泛的游戏类型，并且可以由人类控制以便于未来的合作创作。<details>
<summary>Abstract</summary>
Many advancements have been made in procedural content generation for games, and with mixed-initiative co-creativity, have the potential for great benefits to human designers. However, co-creative systems for game generation are typically limited to specific genres, rules, or games, limiting the creativity of the designer. We seek to model games abstractly enough to apply to any genre, focusing on designing game systems and mechanics, and create a controllable, co-creative agent that can collaborate on these designs. We present a model of games using state-machine-like components and resource flows, a set of controllable metrics, a design evaluator simulating playthroughs with these metrics, and an evolutionary design balancer and generator. We find this system to be both able to express a wide range of games and able to be human-controllable for future co-creative applications.
</details>
<details>
<summary>摘要</summary>
很多进步已经被成功地应用于游戏的过程内容生成，但是权衡共创系统通常只能应用于特定的类型、规则或游戏，这限制了设计师的创作空间。我们想要使用抽象的游戏模型，以便应用于任何类型的游戏，专注于设计游戏系统和机制，并创造一个可控的共创作者。我们提出了一种基于状态机组件和资源流的游戏模型，一组可控的指标，一个模拟游戏playthrough的设计评估器，以及一个进化设计均衡器和生成器。我们发现这种系统可以表达很广泛的游戏，并且可以被人类控制以便未来的共创应用。
</details></li>
</ul>
<hr>
<h2 id="Who-Answers-It-Better-An-In-Depth-Analysis-of-ChatGPT-and-Stack-Overflow-Answers-to-Software-Engineering-Questions"><a href="#Who-Answers-It-Better-An-In-Depth-Analysis-of-ChatGPT-and-Stack-Overflow-Answers-to-Software-Engineering-Questions" class="headerlink" title="Who Answers It Better? An In-Depth Analysis of ChatGPT and Stack Overflow Answers to Software Engineering Questions"></a>Who Answers It Better? An In-Depth Analysis of ChatGPT and Stack Overflow Answers to Software Engineering Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02312">http://arxiv.org/abs/2308.02312</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samia Kabir, David N. Udo-Imeh, Bonan Kou, Tianyi Zhang</li>
<li>For: The paper aims to investigate the quality and usability of ChatGPT’s responses to software engineering queries on Stack Overflow.* Methods: The authors analyzed 517 questions from Stack Overflow and assessed the correctness, consistency, comprehensiveness, and conciseness of ChatGPT’s responses. They also conducted an extensive linguistic analysis and a user study to gain insights into the linguistic and human aspects of ChatGPT’s answers.* Results: The authors found that 52% of ChatGPT’s answers contain inaccuracies and 77% are verbose. However, users still prefer ChatGPT’s responses 39.34% of the time due to their comprehensiveness and articulate language style. The findings highlight the need for meticulous error correction in ChatGPT while also raising awareness among users about the potential risks associated with seemingly accurate answers.Here is the same information in Simplified Chinese:* For: 研究探讨ChatGPT在Stack Overflow上的问答批处。* Methods: 分析517道Stack Overflow问题，评估ChatGPT的回答是否正确、一致、全面、简洁。同时进行了广泛的语言分析和用户研究，了解ChatGPT的回答的语言和人类方面。* Results: 发现ChatGPT的回答有52%是错误的，77%是 verbose。但是用户仍然偏好ChatGPT的回答39.34%，主要是因为其涵盖性和文革的语言风格。发现结果告诉我们需要对ChatGPT进行精细的错误检查，同时也需要用户注意 seemingly 正确的回答可能存在风险。<details>
<summary>Abstract</summary>
Over the last decade, Q&A platforms have played a crucial role in how programmers seek help online. The emergence of ChatGPT, however, is causing a shift in this pattern. Despite ChatGPT's popularity, there hasn't been a thorough investigation into the quality and usability of its responses to software engineering queries. To address this gap, we undertook a comprehensive analysis of ChatGPT's replies to 517 questions from Stack Overflow (SO). We assessed the correctness, consistency, comprehensiveness, and conciseness of these responses. Additionally, we conducted an extensive linguistic analysis and a user study to gain insights into the linguistic and human aspects of ChatGPT's answers. Our examination revealed that 52% of ChatGPT's answers contain inaccuracies and 77% are verbose. Nevertheless, users still prefer ChatGPT's responses 39.34% of the time due to their comprehensiveness and articulate language style. These findings underscore the need for meticulous error correction in ChatGPT while also raising awareness among users about the potential risks associated with seemingly accurate answers.
</details>
<details>
<summary>摘要</summary>
Translation notes:* Q&A platforms: 问答平台 (wèn táng píng dài)* ChatGPT: 聊天GPT (shuō yǎn GPT)* Stack Overflow: 栈 Overflow (duān yāo fēng)* correctness: 正确性 (zhèng qié xìng)* comprehensiveness: 全面性 (quán miàn xìng)* conciseness: 简洁性 (jiǎn jiǎn xìng)* inaccuracies: 错误 (cuò wàng)* verbosity: 言语贪夸 (yán yǔ zhòng bào)* comprehensiveness and articulate language style: 全面性和豁达的语言风格 (quán miàn xìng hé huò dà de yǔ yán fēng xìng)* meticulous error correction: 仔细错误修正 (zhī xiǎo cuò wàng xiù zhèng)* seemingly accurate answers: 看上去准确的答案 (kàn shàng qù zhèng qié de jiǔ yì)
</details></li>
</ul>
<hr>
<h2 id="Unravelling-Responsibility-for-AI"><a href="#Unravelling-Responsibility-for-AI" class="headerlink" title="Unravelling Responsibility for AI"></a>Unravelling Responsibility for AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02608">http://arxiv.org/abs/2308.02608</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zoe Porter, Joanna Al-Qaddoumi, Philippa Ryan Conmy, Phillip Morgan, John McDermid, Ibrahim Habli</li>
<li>for: 本研究的目的是为了提供一种多学科语言词汇，以便在复杂的AI系统中讨论责任。</li>
<li>methods: 本研究使用三元关系理论，包括行为者、事件和责任之间的关系。具体来说，本研究提出了81个责任串，这些责任串包括四种责任感：角色责任、 causal责任、法律责任和道德责任。</li>
<li>results: 本研究的输出是81个责任串，这些责任串可以帮助不同领域的人们在讨论复杂的AI系统责任时，使用准确和特定的语言表达不同的责任方式。<details>
<summary>Abstract</summary>
To reason about where responsibility does and should lie in complex situations involving AI-enabled systems, we first need a sufficiently clear and detailed cross-disciplinary vocabulary for talking about responsibility. Responsibility is a triadic relation involving an actor, an occurrence, and a way of being responsible. As part of a conscious effort towards 'unravelling' the concept of responsibility to support practical reasoning about responsibility for AI, this paper takes the three-part formulation, 'Actor A is responsible for Occurrence O' and identifies valid combinations of subcategories of A, is responsible for, and O. These valid combinations - which we term "responsibility strings" - are grouped into four senses of responsibility: role-responsibility; causal responsibility; legal liability-responsibility; and moral responsibility. They are illustrated with two running examples, one involving a healthcare AI-based system and another the fatal collision of an AV with a pedestrian in Tempe, Arizona in 2018. The output of the paper is 81 responsibility strings. The aim is that these strings provide the vocabulary for people across disciplines to be clear and specific about the different ways that different actors are responsible for different occurrences within a complex event for which responsibility is sought, allowing for precise and targeted interdisciplinary normative deliberations.
</details>
<details>
<summary>摘要</summary>
为了理解AI引用系统中责任的位置和应该负责任的情况，我们首先需要一个具有明确和详细的跨学科词汇，以便在实际reasoning中讨论责任。责任是一种三元关系，包括一个actor、一个事件和一种负责任的方式。为了支持对AI责任的实践理解，这篇论文采用三部分形式，即“Actor A负责事件 O”，并识别了有效的子类划分。这些有效的子类划分被称为“责任串”，并被分为四种责任感：角色责任、 causa责任、法律责任和道德责任。它们通过两个运行例子，一个是基于医疗AI系统的例子，另一个是2018年在阿里扎纳的一起自驾车与行人相撞事件，以 illustrate these responsibility strings。输出的责任串有81个。目标是这些责任串可以为不同领域的人们提供一个明确和特定的词汇，以便在复杂事件中寻求责任时，有precise和targeted的跨学科法规哲学讨论。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Select-the-Relevant-History-Turns-in-Conversational-Question-Answering"><a href="#Learning-to-Select-the-Relevant-History-Turns-in-Conversational-Question-Answering" class="headerlink" title="Learning to Select the Relevant History Turns in Conversational Question Answering"></a>Learning to Select the Relevant History Turns in Conversational Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02294">http://arxiv.org/abs/2308.02294</a></li>
<li>repo_url: None</li>
<li>paper_authors: Munazza Zaib, Wei Emma Zhang, Quan Z. Sheng, Subhash Sagar, Adnan Mahmood, Yang Zhang<br>for: 这 paper 的目的是提出一种基于 conversational question answering (ConvQA) 的 Dynamic History Selection (DHS) 框架，以优化 conversational history 的选择，以提高问答模型的性能。methods: 该 paper 使用了一种基于相似性的方法，首先生成所有历史转的上下文和问题实体，然后根据这些实体和问题的相似性进行筛选和重新排序。另外，paper 还提出了一种基于注意力的机制，以优化重新排序后的上下文中的标记。results: 实验结果表明，选择相关历史转是更好的than rewrite 原始问题，并且 Adding irrelevant history turns 会对模型的性能产生负面影响。paper 还调查了 IR 社区需要更多的关注的研究挑战。<details>
<summary>Abstract</summary>
The increasing demand for the web-based digital assistants has given a rapid rise in the interest of the Information Retrieval (IR) community towards the field of conversational question answering (ConvQA). However, one of the critical aspects of ConvQA is the effective selection of conversational history turns to answer the question at hand. The dependency between relevant history selection and correct answer prediction is an intriguing but under-explored area. The selected relevant context can better guide the system so as to where exactly in the passage to look for an answer. Irrelevant context, on the other hand, brings noise to the system, thereby resulting in a decline in the model's performance. In this paper, we propose a framework, DHS-ConvQA (Dynamic History Selection in Conversational Question Answering), that first generates the context and question entities for all the history turns, which are then pruned on the basis of similarity they share in common with the question at hand. We also propose an attention-based mechanism to re-rank the pruned terms based on their calculated weights of how useful they are in answering the question. In the end, we further aid the model by highlighting the terms in the re-ranked conversational history using a binary classification task and keeping the useful terms (predicted as 1) and ignoring the irrelevant terms (predicted as 0). We demonstrate the efficacy of our proposed framework with extensive experimental results on CANARD and QuAC -- the two popularly utilized datasets in ConvQA. We demonstrate that selecting relevant turns works better than rewriting the original question. We also investigate how adding the irrelevant history turns negatively impacts the model's performance and discuss the research challenges that demand more attention from the IR community.
</details>
<details>
<summary>摘要</summary>
随着网络基于的数字助手的需求增长，信息检索（IR）社区对于对话问答（ConvQA）领域的兴趣也得到了快速的提高。然而，对话问答中选择有关的历史记录是一个关键的问题，因为相关的历史记录可以更好地导引系统，以便在答案中找到正确的位置。然而，不相关的历史记录会带来噪音，从而导致模型的性能下降。在这篇论文中，我们提出了一个框架，称为DHS-ConvQA（动态历史选择在对话问答中），它首先生成了所有历史记录中的上下文和问题实体，然后根据这些实体与问题之间的相似度进行排序和减少。我们还提出了一种注意力机制，用于重新排序减少后的上下文项，并在排序后使用二分类任务来高亮重要的项（预测为1），并忽略无关的项（预测为0）。我们在CANARD和QuAC两个广泛使用的数据集上进行了广泛的实验，并证明了选择有关历史记录的方法比rewrite原始问题更好。我们还证明了添加无关历史记录会对模型性能产生负面影响，并讨论了需要IR社区更多的关注的研究挑战。
</details></li>
</ul>
<hr>
<h2 id="A-stochastic-optimization-approach-to-train-non-linear-neural-networks-with-a-higher-order-variation-regularization"><a href="#A-stochastic-optimization-approach-to-train-non-linear-neural-networks-with-a-higher-order-variation-regularization" class="headerlink" title="A stochastic optimization approach to train non-linear neural networks with a higher-order variation regularization"></a>A stochastic optimization approach to train non-linear neural networks with a higher-order variation regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02293">http://arxiv.org/abs/2308.02293</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oknakfm/hovr">https://github.com/oknakfm/hovr</a></li>
<li>paper_authors: Akifumi Okuno</li>
<li>for: 本研究旨在Addressing the issue of overfitting in highly expressive parametric models, such as deep neural networks, by introducing a $(k,q)$th order variation regularization ($(k,q)$-VR) term to the loss function.</li>
<li>methods: 本研究提出了一种 Stochastic optimization algorithm, which can efficiently train general parametric models with the $(k,q)$-VR term without conducting explicit numerical integration. The proposed approach can be applied to the training of even deep neural networks with arbitrary structure, using a simple stochastic gradient descent algorithm and automatic differentiation.</li>
<li>results: numerical experiments demonstrate that the neural networks trained with the $(k,q)$-VR terms are more “resilient” than those with the conventional parameter regularization. The proposed algorithm can also be extended to the physics-informed training of neural networks (PINNs).<details>
<summary>Abstract</summary>
While highly expressive parametric models including deep neural networks have an advantage to model complicated concepts, training such highly non-linear models is known to yield a high risk of notorious overfitting. To address this issue, this study considers a $(k,q)$th order variation regularization ($(k,q)$-VR), which is defined as the $q$th-powered integral of the absolute $k$th order derivative of the parametric models to be trained; penalizing the $(k,q)$-VR is expected to yield a smoother function, which is expected to avoid overfitting. Particularly, $(k,q)$-VR encompasses the conventional (general-order) total variation with $q=1$. While the $(k,q)$-VR terms applied to general parametric models are computationally intractable due to the integration, this study provides a stochastic optimization algorithm, that can efficiently train general models with the $(k,q)$-VR without conducting explicit numerical integration. The proposed approach can be applied to the training of even deep neural networks whose structure is arbitrary, as it can be implemented by only a simple stochastic gradient descent algorithm and automatic differentiation. Our numerical experiments demonstrate that the neural networks trained with the $(k,q)$-VR terms are more ``resilient'' than those with the conventional parameter regularization. The proposed algorithm also can be extended to the physics-informed training of neural networks (PINNs).
</details>
<details>
<summary>摘要</summary>
“ While highly expressive parametric models including deep neural networks have an advantage in modeling complicated concepts, training such highly non-linear models is known to yield a high risk of notorious overfitting. To address this issue, this study considers a $(k,q)$th order variation regularization ($(k,q)$-VR), which is defined as the $q$th-powered integral of the absolute $k$th order derivative of the parametric models to be trained; penalizing the $(k,q)$-VR is expected to yield a smoother function, which is expected to avoid overfitting. Particularly, $(k,q)$-VR encompasses the conventional (general-order) total variation with $q=1$. While the $(k,q)$-VR terms applied to general parametric models are computationally intractable due to the integration, this study provides a stochastic optimization algorithm, that can efficiently train general models with the $(k,q)$-VR without conducting explicit numerical integration. The proposed approach can be applied to the training of even deep neural networks whose structure is arbitrary, as it can be implemented by only a simple stochastic gradient descent algorithm and automatic differentiation. Our numerical experiments demonstrate that the neural networks trained with the $(k,q)$-VR terms are more ``resilient'' than those with the conventional parameter regularization. The proposed algorithm also can be extended to the physics-informed training of neural networks (PINNs).”Note: The translation is in Simplified Chinese, which is one of the two standard versions of Chinese language. The other version is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Frustratingly-Easy-Model-Generalization-by-Dummy-Risk-Minimization"><a href="#Frustratingly-Easy-Model-Generalization-by-Dummy-Risk-Minimization" class="headerlink" title="Frustratingly Easy Model Generalization by Dummy Risk Minimization"></a>Frustratingly Easy Model Generalization by Dummy Risk Minimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02287">http://arxiv.org/abs/2308.02287</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juncheng Wang, Jindong Wang, Xixu Hu, Shujun Wang, Xing Xie</li>
<li>for: 提高机器学习模型的通用能力</li>
<li>methods: 使用拟合风险最小化（Dummy Risk Minimization，DuRM）技术，包括 Output logits 的缩大和标准梯度下降优化</li>
<li>results: 在多种任务上，包括传统分类、semantic segmentation、out-of-distribution泛化、对抗训练和长尾识别等，DuRM 能够一直提高表现，并且与现有的通用技术相Compatible，但可能存在一些限制。<details>
<summary>Abstract</summary>
Empirical risk minimization (ERM) is a fundamental machine learning paradigm. However, its generalization ability is limited in various tasks. In this paper, we devise Dummy Risk Minimization (DuRM), a frustratingly easy and general technique to improve the generalization of ERM. DuRM is extremely simple to implement: just enlarging the dimension of the output logits and then optimizing using standard gradient descent. Moreover, we validate the efficacy of DuRM on both theoretical and empirical analysis. Theoretically, we show that DuRM derives greater variance of the gradient, which facilitates model generalization by observing better flat local minima. Empirically, we conduct evaluations of DuRM across different datasets, modalities, and network architectures on diverse tasks, including conventional classification, semantic segmentation, out-of-distribution generalization, adverserial training, and long-tailed recognition. Results demonstrate that DuRM could consistently improve the performance under all tasks with an almost free lunch manner. Furthermore, we show that DuRM is compatible with existing generalization techniques and we discuss possible limitations. We hope that DuRM could trigger new interest in the fundamental research on risk minimization.
</details>
<details>
<summary>摘要</summary>
empirical risk minimization (ERM) 是机器学习的基本思想之一，但它在不同任务中的泛化能力有限。在这篇论文中，我们提出了幂减风险最小化（DuRM），一种易于实现且普遍适用的技术来提高ERM的泛化能力。DuRM的实现非常简单：只需增大输出归一化的维度，然后使用标准的梯度下降优化。我们也在理论和实际分析中证明了DuRM的有效性。在理论上，我们表明了DuRM可以提高模型的泛化能力，通过在更好的平坦的本地极小值上观察更大的变分。在实际中，我们对不同的数据集、模式和网络架构进行了多种任务的评估，包括传统的分类、semantic segmentation、out-of-distribution泛化、对抗训练和长尾识别等。结果显示，DuRM可以在所有任务上提高性能，并且具有几乎免费的午餐特性。此外，我们还证明了DuRM与现有的泛化技术相容，并讨论了可能的限制。我们希望通过DuRM触发新的基本研究风险最小化的兴趣。
</details></li>
</ul>
<hr>
<h2 id="DIVERSIFY-A-General-Framework-for-Time-Series-Out-of-distribution-Detection-and-Generalization"><a href="#DIVERSIFY-A-General-Framework-for-Time-Series-Out-of-distribution-Detection-and-Generalization" class="headerlink" title="DIVERSIFY: A General Framework for Time Series Out-of-distribution Detection and Generalization"></a>DIVERSIFY: A General Framework for Time Series Out-of-distribution Detection and Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02282">http://arxiv.org/abs/2308.02282</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wang Lu, Jindong Wang, Xinwei Sun, Yiqiang Chen, Xiangyang Ji, Qiang Yang, Xing Xie</li>
<li>for: 这篇研究是为了解决时间序列资料的机器学习挑战，尤其是时间序列的非站点性问题，使得现有的算法对于时间序列的泛化和对异类检测产生问题。</li>
<li>methods: 本研究提出了DIVERSIFY，一个通用框架，用于时间序列的对异类检测和泛化。DIVERSIFY是一个迭代过程，首先通过对抗训练获得最差情况的潜在分布enario，然后降低这些潜在分布enario之间的差距。</li>
<li>results: 实验结果显示，DIVERSIFY可以更好地学习时间序列的对异类特征，并在七个不同的时间序列资料集上实现了优秀的效果。<details>
<summary>Abstract</summary>
Time series remains one of the most challenging modalities in machine learning research. The out-of-distribution (OOD) detection and generalization on time series tend to suffer due to its non-stationary property, i.e., the distribution changes over time. The dynamic distributions inside time series pose great challenges to existing algorithms to identify invariant distributions since they mainly focus on the scenario where the domain information is given as prior knowledge. In this paper, we attempt to exploit subdomains within a whole dataset to counteract issues induced by non-stationary for generalized representation learning. We propose DIVERSIFY, a general framework, for OOD detection and generalization on dynamic distributions of time series. DIVERSIFY takes an iterative process: it first obtains the "worst-case" latent distribution scenario via adversarial training, then reduces the gap between these latent distributions. We implement DIVERSIFY via combining existing OOD detection methods according to either extracted features or outputs of models for detection while we also directly utilize outputs for classification. In addition, theoretical insights illustrate that DIVERSIFY is theoretically supported. Extensive experiments are conducted on seven datasets with different OOD settings across gesture recognition, speech commands recognition, wearable stress and affect detection, and sensor-based human activity recognition. Qualitative and quantitative results demonstrate that DIVERSIFY learns more generalized features and significantly outperforms other baselines.
</details>
<details>
<summary>摘要</summary>
时序序列仍然是机器学习研究中最为困难的模式之一。时序序列的非站立性，即时间序列中的分布变化，会导致既存算法很难以识别 invariant 分布。在这篇论文中，我们尝试通过在整个数据集中找到子区域来抵消由非站立性引起的问题，以便实现通用的表示学习。我们提出了 DIVERSIFY，一种通用框架，用于时序序列的非同站通知检测和泛化。DIVERSIFY 采用了迭代过程：首先通过对恶化训练获得 "最差" 的干扰分布enario，然后减少这些干扰分布之间的差距。我们通过将现有的 OOD 检测方法与特定的特征或模型输出结合在一起来实现 DIVERSIFY。此外，我们还直接使用输出进行分类。经验证明了 DIVERSIFY 理论上支持。我们在 Seven 个数据集上进行了对不同 OOD 设置的广泛实验，结果表明 DIVERSIFY 可以更好地学习通用的特征，并在其他基elines上显著超越。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Channel-Equalizer-Modelling-Language-Mismatch-in-Multi-User-Semantic-Communications"><a href="#Semantic-Channel-Equalizer-Modelling-Language-Mismatch-in-Multi-User-Semantic-Communications" class="headerlink" title="Semantic Channel Equalizer: Modelling Language Mismatch in Multi-User Semantic Communications"></a>Semantic Channel Equalizer: Modelling Language Mismatch in Multi-User Semantic Communications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03789">http://arxiv.org/abs/2308.03789</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamed Sana, Emilio Calvanese Strinati</li>
<li>for: 这篇论文主要关注在多用户semantic通信系统中，对于传递和接收semantic信息的 agents（传递者和接收者）之间的交互。</li>
<li>methods: 这篇论文提出了一个新的semantic通信频道均衡器，用于缓解因语言不同而导致的semantic噪声，并且使用最佳运输理论来模型语言不同的量化变数。</li>
<li>results: 比较traditional方法，这篇论文的提案Semantic通信频道均衡器在运算复杂度和传输精度方面表现出色。<details>
<summary>Abstract</summary>
We consider a multi-user semantic communications system in which agents (transmitters and receivers) interact through the exchange of semantic messages to convey meanings. In this context, languages are instrumental in structuring the construction and consolidation of knowledge, influencing conceptual representation and semantic extraction and interpretation. Yet, the crucial role of languages in semantic communications is often overlooked. When this is not the case, agent languages are assumed compatible and unambiguously interoperable, ignoring practical limitations that may arise due to language mismatching. This is the focus of this work. When agents use distinct languages, message interpretation is prone to semantic noise resulting from critical distortion introduced by semantic channels. To address this problem, this paper proposes a new semantic channel equalizer to counteract and limit the critical ambiguity in message interpretation. Our proposed solution models the mismatch of languages with measurable transformations over semantic representation spaces. We achieve this using optimal transport theory, where we model such transformations as transportation maps. Then, to recover at the receiver the meaning intended by the teacher we operate semantic equalization to compensate for the transformation introduced by the semantic channel, either before transmission and/or after the reception of semantic messages. We implement the proposed approach as an operation over a codebook of transformations specifically designed for successful communication. Numerical results show that the proposed semantic channel equalizer outperforms traditional approaches in terms of operational complexity and transmission accuracy.
</details>
<details>
<summary>摘要</summary>
我们考虑一个多用户semantic通信系统，在该系统中代理（传输者和接收者）通过semantic消息的交换来传递意义。在这个上下文中，语言对于semantic通信的结构和固化知识的建构和Semantic提取和解释具有重要作用。然而，语言在semantic通信中的重要作用通常被忽略。当代理语言不同时，消息解释受到语言匹配不足的影响，导致semantic频谱中的扭曲。为解决这个问题，本文提出了一种新的semantic频谱平衡器，用于对抗和限制语言匹配不足引起的semantic频谱中的扭曲。我们的提议的解决方案是通过测量变换来模型代理语言之间的语言匹配不足。我们使用优化运输理论来模型这些变换，并将其称为传输地图。接下来，我们在接收方使用semantic平衡器来补偿semantic频谱中的变换，以重建教师发送的意义。我们实现了该方法为一个特定的codebook变换，用于确保successful communication。我们的计算结果表明，我们的semantic频谱平衡器在运算复杂性和传输精度方面都高于传统方法。
</details></li>
</ul>
<hr>
<h2 id="DTF-Net-Category-Level-Pose-Estimation-and-Shape-Reconstruction-via-Deformable-Template-Field"><a href="#DTF-Net-Category-Level-Pose-Estimation-and-Shape-Reconstruction-via-Deformable-Template-Field" class="headerlink" title="DTF-Net: Category-Level Pose Estimation and Shape Reconstruction via Deformable Template Field"></a>DTF-Net: Category-Level Pose Estimation and Shape Reconstruction via Deformable Template Field</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02239">http://arxiv.org/abs/2308.02239</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haowen Wang, Zhipeng Fan, Zhen Zhao, Zhengping Che, Zhiyuan Xu, Dong Liu, Feifei Feng, Yakun Huang, Xiuquan Qiao, Jian Tang</li>
<li>for: 这个论文是关于RGB-深度图像对的6D姿态估计和3D形状重建问题的研究。</li>
<li>methods: 这个论文提出了一种基于卷积神经场的新方法，使用杂化模板场来表示物种类均匀的形状特征和内部几何变换特征。</li>
<li>results: 在REAL275和CAMERA25数据集上进行了广泛的实验，并 demonstarted了这种方法在真实场景中的超越性。此外，这种方法还可以支持真实机器臂抓取任务。<details>
<summary>Abstract</summary>
Estimating 6D poses and reconstructing 3D shapes of objects in open-world scenes from RGB-depth image pairs is challenging. Many existing methods rely on learning geometric features that correspond to specific templates while disregarding shape variations and pose differences among objects in the same category. As a result, these methods underperform when handling unseen object instances in complex environments. In contrast, other approaches aim to achieve category-level estimation and reconstruction by leveraging normalized geometric structure priors, but the static prior-based reconstruction struggles with substantial intra-class variations. To solve these problems, we propose the DTF-Net, a novel framework for pose estimation and shape reconstruction based on implicit neural fields of object categories. In DTF-Net, we design a deformable template field to represent the general category-wise shape latent features and intra-category geometric deformation features. The field establishes continuous shape correspondences, deforming the category template into arbitrary observed instances to accomplish shape reconstruction. We introduce a pose regression module that shares the deformation features and template codes from the fields to estimate the accurate 6D pose of each object in the scene. We integrate a multi-modal representation extraction module to extract object features and semantic masks, enabling end-to-end inference. Moreover, during training, we implement a shape-invariant training strategy and a viewpoint sampling method to further enhance the model's capability to extract object pose features. Extensive experiments on the REAL275 and CAMERA25 datasets demonstrate the superiority of DTF-Net in both synthetic and real scenes. Furthermore, we show that DTF-Net effectively supports grasping tasks with a real robot arm.
</details>
<details>
<summary>摘要</summary>
估计6D姿 pose和 reconstruction3D形状在开放世界场景中从RGB-深度图像对中获得是具有挑战性的。许多现有方法通过学习特定模板的几何特征来实现，而忽略形状变化和姿态差异在同一类目中的对象。这导致这些方法在处理未看到的对象实例时表现不佳。相反，其他方法通过利用normalized几何结构先天来实现类别级别的估计和重建，但static先天基于的重建受到了显著的内类变化的影响。为解决这些问题，我们提出了DTF-Net，一种基于对象类别的偏函数预测网络。在DTF-Net中，我们设计了可变模板场，用于表示一般类别几何缺失特征和类别内部几何变形特征。场建立了连续的形状匹配，将类别模板转化为观察到的实例中的任意形状，以完成形状重建。我们引入了一个姿势回推模块，该模块共享模板代码和形状偏移特征从场中获得准确的6D姿势估计。我们集成了一个多modal表示EXTRACT模块，以提取对象特征和语义标签，使得结构从头到尾进行推理。此外，在训练时，我们实施了形状不变的训练策略和视点采样方法，以进一步增强模型对对象姿势特征的EXTRACT能力。广泛的实验表明DTF-Net在真实场景中表现出色，并且在真正机器臂上支持着GRASP任务。
</details></li>
</ul>
<hr>
<h2 id="Should-we-trust-web-scraped-data"><a href="#Should-we-trust-web-scraped-data" class="headerlink" title="Should we trust web-scraped data?"></a>Should we trust web-scraped data?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02231">http://arxiv.org/abs/2308.02231</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jens Foerderer</li>
<li>for: 本研究旨在探讨采用自动化计算机程序访问网站并下载其内容的数据采集方法中的采样偏见问题。</li>
<li>methods: 本文描述了采集web数据时可能出现的三种采样偏见来源：网页内容变化、个性化响应请求特点、人口注册异常聚集。</li>
<li>results: 文章通过一些实例来说明采集web数据时的采样偏见的存在和严重程度，并提供了预测、检测和缓解采样偏见的建议。<details>
<summary>Abstract</summary>
The increasing adoption of econometric and machine-learning approaches by empirical researchers has led to a widespread use of one data collection method: web scraping. Web scraping refers to the use of automated computer programs to access websites and download their content. The key argument of this paper is that na\"ive web scraping procedures can lead to sampling bias in the collected data. This article describes three sources of sampling bias in web-scraped data. More specifically, sampling bias emerges from web content being volatile (i.e., being subject to change), personalized (i.e., presented in response to request characteristics), and unindexed (i.e., abundance of a population register). In a series of examples, I illustrate the prevalence and magnitude of sampling bias. To support researchers and reviewers, this paper provides recommendations on anticipating, detecting, and overcoming sampling bias in web-scraped data.
</details>
<details>
<summary>摘要</summary>
随着经济学和机器学习方法的广泛应用，empirical研究者们正在广泛采用一种数据收集方法：网络抓取。网络抓取指的是通过自动化计算机程序访问网站并下载其内容。本文的主要论点是：不经过合适的处理的网络抓取过程可能会导致采样偏见。本文描述了网络抓取数据中的三种采样偏见来源。具体来说，采样偏见来自于网页内容的变化（即被变化）、个性化（即根据请求特点提供）以及未索引（即人口总数注册）。本文通过一系列示例，ILLUSTRATE了采样偏见的普遍性和规模。为支持研究者和评审人，本文提供了预测、检测和缓解采样偏见的建议。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-Organizational-Opportunities-Challenges-and-Adoption-Strategies"><a href="#Federated-Learning-Organizational-Opportunities-Challenges-and-Adoption-Strategies" class="headerlink" title="Federated Learning: Organizational Opportunities, Challenges, and Adoption Strategies"></a>Federated Learning: Organizational Opportunities, Challenges, and Adoption Strategies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02219">http://arxiv.org/abs/2308.02219</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joaquin Delgado Fernandez, Martin Brennecke, Tom Barbereau, Alexander Rieger, Gilbert Fridgen</li>
<li>for: 这篇论文旨在探讨Restrictive数据共享约束在多个领域中的发展，以及相关的分布式学习（FL）技术。</li>
<li>methods: 论文首先介绍了FL技术的基础知识和应用前景，然后提出了一个概念框架，以帮助组织在AI能力和环境方面采取不同的FL方法。</li>
<li>results: 论文认为，在不同领域的优秀组织可能会采取不同的FL方法，并且FL技术将导致机构间的institutional shift，对商业和信息工程团队进行了广泛的交叉学术研究机会。<details>
<summary>Abstract</summary>
Restrictive rules for data sharing in many industries have led to the development of \ac{FL}. \ac{FL} is a \ac{ML} technique that allows distributed clients to train models collaboratively without the need to share their respective training data with others. In this article, we first explore the technical basics of FL and its potential applications. Second, we present a conceptual framework for the adoption of \ac{FL}, mapping organizations along the lines of their \ac{AI} capabilities and environment. We then discuss why exemplary organizations in different industries, including industry consortia, established banks, public authorities, and data-intensive SMEs might consider different approaches to \ac{FL}. To conclude, we argue that \ac{FL} presents an institutional shift with ample interdisciplinary research opportunities for the business and information systems engineering community.
</details>
<details>
<summary>摘要</summary>
限制性的资料共享规则在许多行业中导致了\ac{FL}的发展。\ac{FL}是一种\ac{ML}技术，允许分布式客户端共同培训模型，无需共享各自的训练数据。在这篇文章中，我们首先探讨\ac{FL}的技术基础和潜在应用。然后，我们提出了\ac{FL}的采用框架，将组织按照其\ac{AI}能力和环境分类。我们还讨论了不同行业的优秀组织可能采取不同的\ac{FL}方法。 Finally, we argue that \ac{FL} represents an institutional shift with abundant interdisciplinary research opportunities for the business and information systems engineering community.Note:* \ac{FL} stands for Federated Learning* \ac{ML} stands for Machine Learning* \ac{AI} stands for Artificial Intelligence
</details></li>
</ul>
<hr>
<h2 id="Towards-Personalized-Prompt-Model-Retrieval-for-Generative-Recommendation"><a href="#Towards-Personalized-Prompt-Model-Retrieval-for-Generative-Recommendation" class="headerlink" title="Towards Personalized Prompt-Model Retrieval for Generative Recommendation"></a>Towards Personalized Prompt-Model Retrieval for Generative Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02205">http://arxiv.org/abs/2308.02205</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/maps-research/gemrec">https://github.com/maps-research/gemrec</a></li>
<li>paper_authors: Yuanhe Guo, Haoming Liu, Hongyi Wen</li>
<li>for: 这 paper 探讨了一种新的推荐任务，即使用生成模型创建个性化的ITEMS，并提出了一个两stage框架，即Prompt-Model Retrieval和生成ITEM Ranking，以实现这种新任务。</li>
<li>methods: 这 paper 使用了200个公共可用的生成模型和90个文本提示组合生成了18K个图像，并提出了一个新的评价约束来评价生成模型的个性化能力。</li>
<li>results: 这 paper 的研究结果表明，使用生成模型来推荐ITEMS是一个有前途的个性化问题，但现有的评价约束有限。 authors 还提出了未来的发展方向，以帮助推荐系统领域进一步advance towards generative recommender systems。<details>
<summary>Abstract</summary>
Recommender Systems are built to retrieve relevant items to satisfy users' information needs. The candidate corpus usually consists of a finite set of items that are ready to be served, such as videos, products, or articles. With recent advances in Generative AI such as GPT and Diffusion models, a new form of recommendation task is yet to be explored where items are to be created by generative models with personalized prompts. Taking image generation as an example, with a single prompt from the user and access to a generative model, it is possible to generate hundreds of new images in a few minutes. How shall we attain personalization in the presence of "infinite" items? In this preliminary study, we propose a two-stage framework, namely Prompt-Model Retrieval and Generated Item Ranking, to approach this new task formulation. We release GEMRec-18K, a prompt-model interaction dataset with 18K images generated by 200 publicly-available generative models paired with a diverse set of 90 textual prompts. Our findings demonstrate the promise of generative model recommendation as a novel personalization problem and the limitations of existing evaluation metrics. We highlight future directions for the RecSys community to advance towards generative recommender systems. Our code and dataset are available at https://github.com/MAPS-research/GEMRec.
</details>
<details>
<summary>摘要</summary>
<<SYS>> Retriever 系统是建立在满足用户信息需求的基础上，通常包括一个有限的项集，如视频、产品或文章。在最近的生成AI技术，如GPT和扩散模型的进步下，一种新的推荐任务正在被探索，即通过生成模型和个性化提示来生成新的项目。例如，通过用户提供的单个提示和访问生成模型，可以在几分钟内生成数百个新的图像。在个性化任务中，如何实现个性化？在本初步研究中，我们提出了两个阶段的框架，即提示模型检索和生成项排序，以解决这种新的任务表述。我们发布了GEMRec-18K数据集，包括200个公共可用的生成模型和90个文本提示，用于描述生成模型的互动。我们的发现表明了生成模型推荐的潜力作为一种新的个性化问题，以及现有评价指标的局限性。我们提出了未来的推荐系统社区应该采取的方向，以推动生成推荐系统的发展。我们的代码和数据集可以在https://github.com/MAPS-research/GEMRec上获取。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-of-Spanish-Clinical-Language-Models"><a href="#A-Survey-of-Spanish-Clinical-Language-Models" class="headerlink" title="A Survey of Spanish Clinical Language Models"></a>A Survey of Spanish Clinical Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02199">http://arxiv.org/abs/2308.02199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guillem García Subies, Álvaro Barbero Jiménez, Paloma Martínez Fernández</li>
<li>for: 本研究探讨了用encoder语言模型解决西班牙语医学领域任务的可能性。</li>
<li>methods: 本研究对17个质量高的医学领域 Corpora进行了分析，并列出了最有代表性的西班牙语语言模型和医学领域语言模型。研究还对这些模型进行了系统性的比较，并在一个手动精心选择的子集上进行了测试，总共测试了超过3000个模型。</li>
<li>results: 研究发现了一些最高效的西班牙语语言模型，并且将所有测试 Corpora和最佳模型公开发布，以便由独立团队重新测试或在未来创建新的西班牙语医学领域语言模型时进行参考。<details>
<summary>Abstract</summary>
This survey focuses in encoder Language Models for solving tasks in the clinical domain in the Spanish language. We review the contributions of 17 corpora focused mainly in clinical tasks, then list the most relevant Spanish Language Models and Spanish Clinical Language models. We perform a thorough comparison of these models by benchmarking them over a curated subset of the available corpora, in order to find the best-performing ones; in total more than 3000 models were fine-tuned for this study. All the tested corpora and the best models are made publically available in an accessible way, so that the results can be reproduced by independent teams or challenged in the future when new Spanish Clinical Language models are created.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:这个调查集中心在医疗领域的西班牙语语言模型。我们回顾17个公共领域的贡献，主要是医疗任务，然后列出最 relevante的西班牙语语言模型和西班牙医疗语言模型。我们对这些模型进行了详细的比较，使用一个精心选择的子集来评测它们，以找出最佳的一些。总共超过3000个模型被 fine-tuned  для这项研究。所有测试 corpora 和最佳模型都被公开发布，以便由独立的团队重新进行测试或在未来when新的西班牙医疗语言模型被创建时进行挑战。
</details></li>
</ul>
<hr>
<h2 id="On-stable-wrapper-based-parameter-selection-method-for-efficient-ANN-based-data-driven-modeling-of-turbulent-flows"><a href="#On-stable-wrapper-based-parameter-selection-method-for-efficient-ANN-based-data-driven-modeling-of-turbulent-flows" class="headerlink" title="On stable wrapper-based parameter selection method for efficient ANN-based data-driven modeling of turbulent flows"></a>On stable wrapper-based parameter selection method for efficient ANN-based data-driven modeling of turbulent flows</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02602">http://arxiv.org/abs/2308.02602</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyeongeun Yun, Yongcheol Choi, Youngjae Kim, Seongwon Kang<br>for: 这种研究旨在分析和开发一种基于人工神经网络（ANN）和包裹方法的减少模型方法，以优化复杂的湍流和热传递现象的计算模型。methods: 该方法使用了人工神经网络（ANN）和包裹方法，并且在其他方法，如相关性基于滤波器方法，之前的优势在于去除不必要的或 irrelevante 参数，尤其在非线性中。然而，ANN训练过程中的过拟合和随机性可能会导致在选择试验中不一致的子集产生。results: 该研究分析了一些现有的ANN基于包裹方法，并开发了一种修订后的基于梯度基因子的包裹方法，以最小化总导数或方向一致性损失在每次减少步骤。通过应用这些方法到一个制造 subsets 选择问题、泡沫流中的尺寸模型和duct流中的空间变化的湍流普ран德尔数模型，发现，基于梯度基因子的包裹方法在多个试验中 display 了改进的一致性。此外，减少参数子集还显示了略高的训练速度。<details>
<summary>Abstract</summary>
To model complex turbulent flow and heat transfer phenomena, this study aims to analyze and develop a reduced modeling approach based on artificial neural network (ANN) and wrapper methods. This approach has an advantage over other methods such as the correlation-based filter method in terms of removing redundant or irrelevant parameters even under non-linearity among them. As a downside, the overfitting and randomness of ANN training may produce inconsistent subsets over selection trials especially in a higher physical dimension. This study analyzes a few existing ANN-based wrapper methods and develops a revised one based on the gradient-based subset selection indices to minimize the loss in the total derivative or the directional consistency at each elimination step. To examine parameter reduction performance and consistency-over-trials, we apply these methods to a manufactured subset selection problem, modeling of the bubble size in a turbulent bubbly flow, and modeling of the spatially varying turbulent Prandtl number in a duct flow. It is found that the gradient-based subset selection to minimize the total derivative loss results in improved consistency-over-trials compared to the other ANN-based wrapper methods, while removing unnecessary parameters successfully. For the reduced turbulent Prandtl number model, the gradient-based subset selection improves the prediction in the validation case over the other methods. Also, the reduced parameter subsets show a slight increase in the training speed compared to the others.
</details>
<details>
<summary>摘要</summary>
To address these challenges, this study analyzes existing ANN-based wrapper methods and develops a revised approach based on gradient-based subset selection indices to minimize total derivative loss or directional consistency at each elimination step. The performance and consistency of the parameter reduction methods are examined through applications to a manufactured subset selection problem, modeling of bubble size in turbulent bubbly flow, and modeling of spatially varying turbulent Prandtl number in a duct flow.The results show that the gradient-based subset selection approach results in improved consistency-over-trials compared to other ANN-based wrapper methods, while successfully removing unnecessary parameters. Additionally, the reduced turbulent Prandtl number model using the gradient-based subset selection approach improves prediction in the validation case compared to other methods. Finally, the reduced parameter subsets show a slight increase in training speed compared to other methods.
</details></li>
</ul>
<hr>
<h2 id="Explaining-Relation-Classification-Models-with-Semantic-Extents"><a href="#Explaining-Relation-Classification-Models-with-Semantic-Extents" class="headerlink" title="Explaining Relation Classification Models with Semantic Extents"></a>Explaining Relation Classification Models with Semantic Extents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02193">http://arxiv.org/abs/2308.02193</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mslars/semantic_extents">https://github.com/mslars/semantic_extents</a></li>
<li>paper_authors: Lars Klöser, Andre Büsgen, Philipp Kohl, Bodo Kraft, Albert Zündorf</li>
<li>for: 本研究旨在提高信息抽取系统的可解释性，以便在各种应用中提高系统的可靠性和安全性。</li>
<li>methods: 本研究使用大规模预训练语言模型，如BERT和GPT，对文本进行分类任务的信息抽取。我们还提出了一种新的分类方法，即 semantic extents，以分析模型做出决策时的文本特征。</li>
<li>results: 我们的研究显示，模型在分类任务中倾向于学习短cut Patterns，这些Patterns通常难以通过当前解释方法，如输入减少法，检测到。我们的approach可以帮助检测和消除这些假设决策模式，从而提高模型的可靠性和安全性。<details>
<summary>Abstract</summary>
In recent years, the development of large pretrained language models, such as BERT and GPT, significantly improved information extraction systems on various tasks, including relation classification. State-of-the-art systems are highly accurate on scientific benchmarks. A lack of explainability is currently a complicating factor in many real-world applications. Comprehensible systems are necessary to prevent biased, counterintuitive, or harmful decisions.   We introduce semantic extents, a concept to analyze decision patterns for the relation classification task. Semantic extents are the most influential parts of texts concerning classification decisions. Our definition allows similar procedures to determine semantic extents for humans and models. We provide an annotation tool and a software framework to determine semantic extents for humans and models conveniently and reproducibly. Comparing both reveals that models tend to learn shortcut patterns from data. These patterns are hard to detect with current interpretability methods, such as input reductions. Our approach can help detect and eliminate spurious decision patterns during model development. Semantic extents can increase the reliability and security of natural language processing systems. Semantic extents are an essential step in enabling applications in critical areas like healthcare or finance. Moreover, our work opens new research directions for developing methods to explain deep learning models.
</details>
<details>
<summary>摘要</summary>
在最近的几年，大型预训言语模型，如BERT和GPT，对各种任务的信息提取系统进行了显著改进。现状的系统在科学性评分上具有极高的准确率。然而，当前存在一个复杂的问题，即解释性的缺乏，这使得在实际应用中难以获得可靠的结果。我们引入 semantic extent，用于分析关系分类任务的决策模式。semantic extent 是文本中决策时最重要的部分。我们的定义允许人类和模型使用相同的程序来确定 semantic extent。我们提供了一个注释工具和一个软件框架，以便人类和模型方便地和可重复地确定 semantic extent。对比两者可以看出，模型通常从数据中学习快捷的决策模式。这些模式通过现有的解释方法，如输入减少，难以检测。我们的方法可以帮助检测和消除快捷决策模式的形成。semantic extent 可以增加自然语言处理系统的可靠性和安全性。此外，我们的工作开启了新的研究方向，用于解释深度学习模型。
</details></li>
</ul>
<hr>
<h2 id="AutoML4ETC-Automated-Neural-Architecture-Search-for-Real-World-Encrypted-Traffic-Classification"><a href="#AutoML4ETC-Automated-Neural-Architecture-Search-for-Real-World-Encrypted-Traffic-Classification" class="headerlink" title="AutoML4ETC: Automated Neural Architecture Search for Real-World Encrypted Traffic Classification"></a>AutoML4ETC: Automated Neural Architecture Search for Real-World Encrypted Traffic Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02182">http://arxiv.org/abs/2308.02182</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/orangeuw/automl4etc">https://github.com/orangeuw/automl4etc</a></li>
<li>paper_authors: Navid Malekghaini, Elham Akbari, Mohammad A. Salahuddin, Noura Limam, Raouf Boutaba, Bertrand Mathieu, Stephanie Moteau, Stephane Tuffin</li>
<li>for: 这个论文的目的是提出一个自动设计高效和高精度神经网络的工具，以便在实际应用中实现加密网络流量分类。</li>
<li>methods: 该工具使用了一个特定设计的搜寻空间，通过不同的搜寻策略，对这个搜寻空间进行自动化设计，以生成高性能的神经网络。</li>
<li>results: 该工具能够对多个数据集，包括公开的库和实际的TLS和QUIC流量，以比较高精度和更有效的方式进行分类。<details>
<summary>Abstract</summary>
Deep learning (DL) has been successfully applied to encrypted network traffic classification in experimental settings. However, in production use, it has been shown that a DL classifier's performance inevitably decays over time. Re-training the model on newer datasets has been shown to only partially improve its performance. Manually re-tuning the model architecture to meet the performance expectations on newer datasets is time-consuming and requires domain expertise. We propose AutoML4ETC, a novel tool to automatically design efficient and high-performing neural architectures for encrypted traffic classification. We define a novel, powerful search space tailored specifically for the near real-time classification of encrypted traffic using packet header bytes. We show that with different search strategies over our search space, AutoML4ETC generates neural architectures that outperform the state-of-the-art encrypted traffic classifiers on several datasets, including public benchmark datasets and real-world TLS and QUIC traffic collected from the Orange mobile network. In addition to being more accurate, AutoML4ETC's architectures are significantly more efficient and lighter in terms of the number of parameters. Finally, we make AutoML4ETC publicly available for future research.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）已成功应用于加密网络流量分类的实验室Setting中。然而，在生产环境中，DL分类器的性能必然逐渐下降。重新训练模型使用更新的数据集只能部分提高其性能。手动重新调整模型结构以符合 newer datasets的性能要求是时间consuming和需要域专业知识。我们提出了 AutoML4ETC，一种新的工具，可以自动设计高效和高性能的神经网络架构来分类加密流量。我们定义了一个特定于几秒钟内的加密流量分类的强大搜索空间。我们展示了不同的搜索策略在我们的搜索空间上，AutoML4ETC生成的神经网络架构可以超过当前加密流量分类器的状态态。此外，AutoML4ETC的架构还更加轻量级，具有更少的参数。最后，我们在未来的研究中公开了 AutoML4ETC。
</details></li>
</ul>
<hr>
<h2 id="Retroformer-Retrospective-Large-Language-Agents-with-Policy-Gradient-Optimization"><a href="#Retroformer-Retrospective-Large-Language-Agents-with-Policy-Gradient-Optimization" class="headerlink" title="Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization"></a>Retroformer: Retrospective Large Language Agents with Policy Gradient Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02151">http://arxiv.org/abs/2308.02151</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/weirayao/Retroformer">https://github.com/weirayao/Retroformer</a></li>
<li>paper_authors: Weiran Yao, Shelby Heinecke, Juan Carlos Niebles, Zhiwei Liu, Yihao Feng, Le Xue, Rithesh Murthy, Zeyuan Chen, Jianguo Zhang, Devansh Arpit, Ran Xu, Phil Mui, Huan Wang, Caiming Xiong, Silvio Savarese</li>
<li>for: 这 paper 的目的是探讨如何使用 policy gradient 优化大型语言模型 (LLMs)，以提高它们在完成多步任务时的性能。</li>
<li>methods: 该 paper 使用了一种原则性的框架，通过学习一个 retrospective 模型来自动调整语言代理提示，从环境反馈中获取权重。 Specifically, 该框架学习了多个环境和任务的奖励，用于细化一个预训练的语言模型，以优化语言代理提示。</li>
<li>results: 实验结果表明，使用 policy gradient 优化语言代理可以提高其性能，并且我们的方法在多个任务上显著超越了基elines。 这示示了使用 policy gradient 优化语言代理是一个promising的方向，可以应用于其他模型上以提高代理性能。<details>
<summary>Abstract</summary>
Recent months have seen the emergence of a powerful new trend in which large language models (LLMs) are augmented to become autonomous language agents capable of performing objective oriented multi-step tasks on their own, rather than merely responding to queries from human users. Most existing language agents, however, are not optimized using environment-specific rewards. Although some agents enable iterative refinement through verbal feedback, they do not reason and plan in ways that are compatible with gradient-based learning from rewards. This paper introduces a principled framework for reinforcing large language agents by learning a retrospective model, which automatically tunes the language agent prompts from environment feedback through policy gradient. Specifically, our proposed agent architecture learns from rewards across multiple environments and tasks, for fine-tuning a pre-trained language model which refines the language agent prompt by summarizing the root cause of prior failed attempts and proposing action plans. Experimental results on various tasks demonstrate that the language agents improve over time and that our approach considerably outperforms baselines that do not properly leverage gradients from the environment. This demonstrates that using policy gradient optimization to improve language agents, for which we believe our work is one of the first, seems promising and can be applied to optimize other models in the agent architecture to enhance agent performances over time.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:近些月，大型自然语言模型（LLM）的增强趋势出现，使得语言代理人可以独立完成目标 oriented 多步任务，而不仅仅是响应人类用户的查询。现有大多数语言代理人并不使用环境特定的奖励来优化。 although some agents enable iterative refinement through verbal feedback, they do not reason and plan in ways that are compatible with gradient-based learning from rewards. 这篇论文介绍了一种原则性的框架，用于加强大型语言模型，通过策略幂gradients来学习和调整语言代理人提示。specifically, our proposed agent architecture learns from rewards across multiple environments and tasks, for fine-tuning a pre-trained language model which refines the language agent prompt by summarizing the root cause of prior failed attempts and proposing action plans.实验结果表明，语言代理人随着时间的推移而改进，而我们的方法与不使用环境奖励的基线相比，显著提高了表现。这表明，通过策略幂奖励来改进语言代理人，我们认为我们的工作是这类第一个，并且可以应用到其他代理人体系中，以提高代理人表现。
</details></li>
</ul>
<hr>
<h2 id="Event-based-Dynamic-Graph-Representation-Learning-for-Patent-Application-Trend-Prediction"><a href="#Event-based-Dynamic-Graph-Representation-Learning-for-Patent-Application-Trend-Prediction" class="headerlink" title="Event-based Dynamic Graph Representation Learning for Patent Application Trend Prediction"></a>Event-based Dynamic Graph Representation Learning for Patent Application Trend Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09780">http://arxiv.org/abs/2308.09780</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tao Zou, Le Yu, Leilei Sun, Bowen Du, Deqing Wang, Fuzhen Zhuang</li>
<li>for: 预测公司将在未来时间内申请哪些专利，以便了解其发展策略和找到前期合作伙伴或竞争对手。</li>
<li>methods: 我们提出了一种基于事件的动态图学框架，用于预测专利申请趋势。该方法基于公司和专利分类代码的启发性表示，并利用层次消息传递机制来捕捉专利分类代码的语义相似性。</li>
<li>results: 我们的方法在实际数据上进行了证明，并在不同的实验条件下表现出了效果。同时，我们的方法还能够学习分类代码的语义和跟踪公司技术发展轨迹。<details>
<summary>Abstract</summary>
Accurate prediction of what types of patents that companies will apply for in the next period of time can figure out their development strategies and help them discover potential partners or competitors in advance. Although important, this problem has been rarely studied in previous research due to the challenges in modelling companies' continuously evolving preferences and capturing the semantic correlations of classification codes. To fill in this gap, we propose an event-based dynamic graph learning framework for patent application trend prediction. In particular, our method is founded on the memorable representations of both companies and patent classification codes. When a new patent is observed, the representations of the related companies and classification codes are updated according to the historical memories and the currently encoded messages. Moreover, a hierarchical message passing mechanism is provided to capture the semantic proximities of patent classification codes by updating their representations along the hierarchical taxonomy. Finally, the patent application trend is predicted by aggregating the representations of the target company and classification codes from static, dynamic, and hierarchical perspectives. Experiments on real-world data demonstrate the effectiveness of our approach under various experimental conditions, and also reveal the abilities of our method in learning semantics of classification codes and tracking technology developing trajectories of companies.
</details>
<details>
<summary>摘要</summary>
可以准确预测公司将在下一时间段申请哪些专利，可以 помочь这些公司提前了解发展策略和找到潜在的合作伙伴或竞争对手。虽然这是一个重要的问题，但在过去的研究中它几乎没有得到了关注，因为模型公司的持续发展的偏好和专利分类代码的 semantics 相关性是一个挑战。为了填补这一漏洞，我们提出了一种基于事件的动态图学学习框架，用于预测专利申请趋势。具体来说，我们的方法基于公司和专利分类代码的启发性表示。当观察到新专利时，相关公司和分类代码的表示将根据历史记忆和当前编码的信息进行更新。此外，我们还提供了一种层次消息传递机制，以捕捉专利分类代码的semantics，并在层次分类中更新其表示。最后，我们通过将目标公司和分类代码的表示从静态、动态和层次三个角度进行聚合来预测专利申请趋势。实验结果表明，我们的方法在不同的实验条件下具有显著的有效性，并且能够学习分类代码的 semantics 和跟踪公司的技术发展轨迹。
</details></li>
</ul>
<hr>
<h2 id="Analysis-and-Optimization-of-Wireless-Federated-Learning-with-Data-Heterogeneity"><a href="#Analysis-and-Optimization-of-Wireless-Federated-Learning-with-Data-Heterogeneity" class="headerlink" title="Analysis and Optimization of Wireless Federated Learning with Data Heterogeneity"></a>Analysis and Optimization of Wireless Federated Learning with Data Heterogeneity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03521">http://arxiv.org/abs/2308.03521</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuefeng Han, Jun Li, Wen Chen, Zhen Mei, Kang Wei, Ming Ding, H. Vincent Poor</li>
<li>for: 这篇论文主要应用于无线执行 federated learning (FL)，并处理资料不均等问题。</li>
<li>methods: 本论文使用关于资料不均等的closed-form表达，并将 клиєн端排程、资源分配和本地训练 epoch 优化为一体验。</li>
<li>results: 实验结果显示，提案的算法可以与其他参考数据比较，从条件下降的角度来看，提高学习精度和能源消耗。<details>
<summary>Abstract</summary>
With the rapid proliferation of smart mobile devices, federated learning (FL) has been widely considered for application in wireless networks for distributed model training. However, data heterogeneity, e.g., non-independently identically distributions and different sizes of training data among clients, poses major challenges to wireless FL. Limited communication resources complicate the implementation of fair scheduling which is required for training on heterogeneous data, and further deteriorate the overall performance. To address this issue, this paper focuses on performance analysis and optimization for wireless FL, considering data heterogeneity, combined with wireless resource allocation. Specifically, we first develop a closed-form expression for an upper bound on the FL loss function, with a particular emphasis on data heterogeneity described by a dataset size vector and a data divergence vector. Then we formulate the loss function minimization problem, under constraints on long-term energy consumption and latency, and jointly optimize client scheduling, resource allocation, and the number of local training epochs (CRE). Next, via the Lyapunov drift technique, we transform the CRE optimization problem into a series of tractable problems. Extensive experiments on real-world datasets demonstrate that the proposed algorithm outperforms other benchmarks in terms of the learning accuracy and energy consumption.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:随着智能手持设备的普遍传播，联邦学习（FL）在无线网络中被广泛考虑用于分布模型训练。然而，数据不同性，例如客户端之间数据非独立相同分布和不同训练数据大小，对无线FL pose 严重挑战。有限的通信资源使得实施公平调度变得更加困难，这会进一步恶化总性能。为了解决这个问题，本文关注无线FL性能分析和优化，考虑到数据不同性，并与无线资源分配相结合。特别是，我们首先开发了一个closed-form表达式，用于计算FL损失函数的Upper bound，强调数据不同性，用dataset size vector和数据偏移vector来描述。然后，我们将损失函数最小化问题形式化，并将其限制在长期能 consumption和延迟下进行优化。通过LYAPUNOV漂移技术，我们将CRE优化问题转化为一系列可解决的问题。实验表明，提出的算法在实际 dataset 上比其他参考值更高的学习精度和能耗投入。
</details></li>
</ul>
<hr>
<h2 id="Semantics-guided-Transformer-based-Sensor-Fusion-for-Improved-Waypoint-Prediction"><a href="#Semantics-guided-Transformer-based-Sensor-Fusion-for-Improved-Waypoint-Prediction" class="headerlink" title="Semantics-guided Transformer-based Sensor Fusion for Improved Waypoint Prediction"></a>Semantics-guided Transformer-based Sensor Fusion for Improved Waypoint Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02126">http://arxiv.org/abs/2308.02126</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hwan-Soo Choi, Jongoh Jeong, Young Hoo Cho, Kuk-Jin Yoon, Jong-Hwan Kim</li>
<li>for: 提高自动驾驶 agents 的Scene理解能力，具体是在视觉全文本上进行了对应的抽象和融合。</li>
<li>methods: 利用多种感知器的数据模式进行特征级别的融合，并通过假学习来实现对象认识和 semantic segmentation 等相关任务的协同学习。</li>
<li>results: 在 CARLA  simulate 中进行了广泛的实验，并 Validated 在 Town05 Benchmark 上，基于 TransFuser 基网络的多任务特征融合方法能够提高自动驾驶 agents 的安全性和完整性。<details>
<summary>Abstract</summary>
Sensor fusion approaches for intelligent self-driving agents remain key to driving scene understanding given visual global contexts acquired from input sensors. Specifically, for the local waypoint prediction task, single-modality networks are still limited by strong dependency on the sensitivity of the input sensor, and thus recent works promote the use of multiple sensors in fusion in feature level. While it is well known that multiple data modalities promote mutual contextual exchange, deployment to practical driving scenarios requires global 3D scene understanding in real-time with minimal computations, thus placing greater significance on training strategies given a limited number of practically usable sensors. In this light, we exploit carefully selected auxiliary tasks that are highly correlated with the target task of interest (e.g., traffic light recognition and semantic segmentation) by fusing auxiliary task features and also using auxiliary heads for waypoint prediction based on imitation learning. Our multi-task feature fusion augments and improves the base network, TransFuser, by significant margins for safer and more complete road navigation in CARLA simulator as validated on the Town05 Benchmark through extensive experiments.
</details>
<details>
<summary>摘要</summary>
感知融合方法对智能自驾车代理人来说仍然是关键，以便在视觉全球上下文中理解驾驶场景。具体来说，当地点预测任务时，单一模态网络仍然受到输入感知器的敏感度的限制，因此最近的工作推广使用多种感知器进行功能层次融合。虽然多个数据模式促进互相交换上下文，但是在实际驾驶场景中部署需要实时全景理解，因此更加重视训练策略，即使使用有限的实用感知器。在这种情况下，我们利用精心选择的协助任务（例如交通信号灯识别和semantic segmentation），并将协助任务特征与基本网络融合，使用协助头进行地点预测基于依据学习。我们的多任务特征融合在TransFuser基础网络上进行加强和改进，在CARLA simulator中进行了广泛的实验，并在Town05 Benchmark上验证了我们的方法能够提供更安全和更完整的道路导航。
</details></li>
</ul>
<hr>
<h2 id="Model-Provenance-via-Model-DNA"><a href="#Model-Provenance-via-Model-DNA" class="headerlink" title="Model Provenance via Model DNA"></a>Model Provenance via Model DNA</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02121">http://arxiv.org/abs/2308.02121</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Mu, Yu Wang, Yehong Zhang, Jiaqi Zhang, Hui Wang, Yang Xiang, Yue Yu</li>
<li>for: 本研究探讨了机器学习模型生命周期中的一个新问题，即模型 происхождение（Model Provenance，MP），即确定目标模型的预训练模型是否为其原型。</li>
<li>methods: 作者们提出了一种新的模型特征表示方法，称为模型DNA（Model DNA），用于编码模型训练数据和输入输出信息。他们还提出了一种基于数据驱动和模型驱动的表示学习方法，用于从模型DNA中提取出模型的唯一特征。</li>
<li>results: 作者们在计算机视觉和自然语言处理任务上使用了多种模型、数据集和场景，并通过评估模型的表现来证明他们的方法的有效性。他们的结果表明，使用模型DNA可以准确地确定模型的 происхождение。<details>
<summary>Abstract</summary>
Understanding the life cycle of the machine learning (ML) model is an intriguing area of research (e.g., understanding where the model comes from, how it is trained, and how it is used). This paper focuses on a novel problem within this field, namely Model Provenance (MP), which concerns the relationship between a target model and its pre-training model and aims to determine whether a source model serves as the provenance for a target model. This is an important problem that has significant implications for ensuring the security and intellectual property of machine learning models but has not received much attention in the literature. To fill in this gap, we introduce a novel concept of Model DNA which represents the unique characteristics of a machine learning model. We utilize a data-driven and model-driven representation learning method to encode the model's training data and input-output information as a compact and comprehensive representation (i.e., DNA) of the model. Using this model DNA, we develop an efficient framework for model provenance identification, which enables us to identify whether a source model is a pre-training model of a target model. We conduct evaluations on both computer vision and natural language processing tasks using various models, datasets, and scenarios to demonstrate the effectiveness of our approach in accurately identifying model provenance.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:理解机器学习模型的生命周期是一个吸引人的研究领域（例如，了解模型来源，如何训练，以及如何使用）。这篇论文关注一个新的问题在这个领域，即模型来源（MP），即目标模型的前训练模型是否为其来源。这是一个重要的问题，它对机器学习模型的安全和知识产权有重要的意义，但在文献中尚未得到过多的关注。为了填补这一漏洞，我们引入了一种新的机器学习模型特征表示（Model DNA），用于表示机器学习模型的唯一特征。我们利用数据驱动和模型驱动的表示学习方法，将模型的训练数据和输入输出信息编码为模型的唯一代表（DNA）。使用这种模型DNA，我们开发了一种高效的模型来源标识框架，可以准确地确定目标模型的前训练模型是否为其来源。我们在计算机视觉和自然语言处理任务上使用了多种模型、数据集和场景，以示出我们方法的准确性。
</details></li>
</ul>
<hr>
<h2 id="Designing-a-Deep-Learning-Driven-Resource-Efficient-Diagnostic-System-for-Metastatic-Breast-Cancer-Reducing-Long-Delays-of-Clinical-Diagnosis-and-Improving-Patient-Survival-in-Developing-Countries"><a href="#Designing-a-Deep-Learning-Driven-Resource-Efficient-Diagnostic-System-for-Metastatic-Breast-Cancer-Reducing-Long-Delays-of-Clinical-Diagnosis-and-Improving-Patient-Survival-in-Developing-Countries" class="headerlink" title="Designing a Deep Learning-Driven Resource-Efficient Diagnostic System for Metastatic Breast Cancer: Reducing Long Delays of Clinical Diagnosis and Improving Patient Survival in Developing Countries"></a>Designing a Deep Learning-Driven Resource-Efficient Diagnostic System for Metastatic Breast Cancer: Reducing Long Delays of Clinical Diagnosis and Improving Patient Survival in Developing Countries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02597">http://arxiv.org/abs/2308.02597</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Gao, Dayong Wang, Yi Huang<br>for: 这个研究旨在解决癌症疗症癌症患者在开发中国家的诊断延迟问题，特别是在SUB-SAHARAN AFRICA、南亚和南美洲，该问题导致患者存活率偏低。methods: 本研究使用了深度学习技术开发了一个可以实现高精度诊断和计算效率的乳癌诊断系统。研究使用了MobileNetV2模型，并评估了不同模型的精度、普遍性和训练效率。results: 研究结果显示，MobileNetV2模型在诊断精度、普遍性和训练效率方面表现出色，比较其他VGG16、ResNet50和ResNet101模型更高。实际比较显示，MobileNetV2模型可以识别小型乳癌细胞，实现人工分析所不能做的。此外， MobileNetV2模型的计算效率足以在移动设备或低计算能力的设备上运行。<details>
<summary>Abstract</summary>
Breast cancer is one of the leading causes of cancer mortality. Breast cancer patients in developing countries, especially sub-Saharan Africa, South Asia, and South America, suffer from the highest mortality rate in the world. One crucial factor contributing to the global disparity in mortality rate is long delay of diagnosis due to a severe shortage of trained pathologists, which consequently has led to a large proportion of late-stage presentation at diagnosis. The delay between the initial development of symptoms and the receipt of a diagnosis could stretch upwards 15 months. To tackle this critical healthcare disparity, this research has developed a deep learning-based diagnosis system for metastatic breast cancer that can achieve high diagnostic accuracy as well as computational efficiency. Based on our evaluation, the MobileNetV2-based diagnostic model outperformed the more complex VGG16, ResNet50 and ResNet101 models in diagnostic accuracy, model generalization, and model training efficiency. The visual comparisons between the model prediction and ground truth have demonstrated that the MobileNetV2 diagnostic models can identify very small cancerous nodes embedded in a large area of normal cells which is challenging for manual image analysis. Equally Important, the light weighted MobleNetV2 models were computationally efficient and ready for mobile devices or devices of low computational power. These advances empower the development of a resource-efficient and high performing AI-based metastatic breast cancer diagnostic system that can adapt to under-resourced healthcare facilities in developing countries. This research provides an innovative technological solution to address the long delays in metastatic breast cancer diagnosis and the consequent disparity in patient survival outcome in developing countries.
</details>
<details>
<summary>摘要</summary>
乳癌是全球最主要的肿瘤死亡原因之一，特别是在发展中国家，如南部非洲、南亚和南美，患者的死亡率最高。一个关键的因素是诊断延迟，由于缺乏专业的病理学家，导致许多患者在诊断时已经是晚期状态。延迟从症状初显到诊断的时间可以达15个月。为了解决这个重要的医疗差距，这项研究开发了一个基于深度学习的乳癌诊断系统，可以实现高精度和计算效率。根据我们的评估，基于MobileNetV2的诊断模型在诊断精度、模型泛化和模型训练效率方面都高于更复杂的VGG16、ResNet50和ResNet101模型。视觉比较表明，MobileNetV2诊断模型可以很好地识别小于1毫米的恶性细胞，这是人工图像分析困难的。此外，MobileNetV2模型轻量级，适用于移动设备或低计算能力的设备。这些进步使得可以开发一个资源有效和高性能的人工智能基本乳癌诊断系统，适应发展中国家的医疗设施。这项研究提供了一种创新的科技解决方案，以减少晚期乳癌诊断延迟和患者存活率差距。
</details></li>
</ul>
<hr>
<h2 id="VQGraph-Graph-Vector-Quantization-for-Bridging-GNNs-and-MLPs"><a href="#VQGraph-Graph-Vector-Quantization-for-Bridging-GNNs-and-MLPs" class="headerlink" title="VQGraph: Graph Vector-Quantization for Bridging GNNs and MLPs"></a>VQGraph: Graph Vector-Quantization for Bridging GNNs and MLPs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02117">http://arxiv.org/abs/2308.02117</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yangling0818/vqgraph">https://github.com/yangling0818/vqgraph</a></li>
<li>paper_authors: Ling Yang, Ye Tian, Minkai Xu, Zhongyi Liu, Shenda Hong, Wei Qu, Wentao Zhang, Bin Cui, Muhan Zhang, Jure Leskovec</li>
<li>for: 本 paper 的目的是提出一种新的框架 VQGraph，用于从 Graph Neural Networks (GNNs) 学习到多层感知器 (MLP) 的知识。</li>
<li>methods: 该 paper 使用了一种叫做 vector-quantized variational autoencoder (VQ-VAE) 的encoder作为一种结构意识 Graph tokenizer，以及一种基于软token分配的 токен-based distillation 目标来充分传递 GNN 中的结构知识到 MLP 中。</li>
<li>results: 该 paper 的实验和分析表明，VQGraph 可以具有更好的性能，比 GNN 更快速地进行推理，并且可以提高 GNN 和独立的 MLP 的准确率。 Code: <a target="_blank" rel="noopener" href="https://github.com/YangLing0818/VQGraph%E3%80%82">https://github.com/YangLing0818/VQGraph。</a><details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) conduct message passing which aggregates local neighbors to update node representations. Such message passing leads to scalability issues in practical latency-constrained applications. To address this issue, recent methods adopt knowledge distillation (KD) to learn computationally-efficient multi-layer perceptron (MLP) by mimicking the output of GNN. However, the existing GNN representation space may not be expressive enough for representing diverse local structures of the underlying graph, which limits the knowledge transfer from GNN to MLP. Here we present a novel framework VQGraph to learn a powerful graph representation space for bridging GNNs and MLPs. We adopt the encoder of a variant of a vector-quantized variational autoencoder (VQ-VAE) as a structure-aware graph tokenizer, which explicitly represents the nodes of diverse local structures as numerous discrete tokens and constitutes a meaningful codebook. Equipped with the learned codebook, we propose a new token-based distillation objective based on soft token assignments to sufficiently transfer the structural knowledge from GNN to MLP. Extensive experiments and analyses demonstrate the strong performance of VQGraph, where we achieve new state-of-the-art performance on GNN-MLP distillation in both transductive and inductive settings across seven graph datasets. We show that VQGraph with better performance infers faster than GNNs by 828x, and also achieves accuracy improvement over GNNs and stand-alone MLPs by 3.90% and 28.05% on average, respectively. Code: https://github.com/YangLing0818/VQGraph.
</details>
<details>
<summary>摘要</summary>
格图神经网络（GNNs）通过消息传递来聚合当地邻居来更新节点表示。然而，这种消息传递可能会导致实际应用中的执行效率问题。为解决这个问题，当前的方法采用知识填充（KD）来学习计算效率高的多层感知器（MLP），但是现有的GNN表示空间可能不够表达当地图structure的多样性，这限制了GNN知识的传递。在这种情况下，我们提出了一种新的框架VQGraph，用于学习一个强大的图表示空间，以将GNN和MLP相互链接。我们采用一种变体的vector-quantizedvariational autoencoder（VQ-VAE）的Encoder作为结构意识的图Tokenizer，从而Explicitly表示节点的多样性，并构成一个有意义的codebook。利用学习的codebook，我们提出了一种新的token-based填充目标，基于软件Token分配来充分传递GNN的结构知识到MLP。我们的实验和分析表明，VQGraph具有强大的性能，在GNN-MLP填充中达到了新的状态作图表现，在七个图 dataset上，我们实现了828倍 faster than GNNs，并且在 inductive 和推uctive Setting中，GNN和独立的MLP的准确率提高了3.90%和28.05%的平均值。代码：https://github.com/YangLing0818/VQGraph。
</details></li>
</ul>
<hr>
<h2 id="AdvFAS-A-robust-face-anti-spoofing-framework-against-adversarial-examples"><a href="#AdvFAS-A-robust-face-anti-spoofing-framework-against-adversarial-examples" class="headerlink" title="AdvFAS: A robust face anti-spoofing framework against adversarial examples"></a>AdvFAS: A robust face anti-spoofing framework against adversarial examples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02116">http://arxiv.org/abs/2308.02116</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiawei Chen, Xiao Yang, Heng Yin, Mingzhi Ma, Bihui Chen, Jianteng Peng, Yandong Guo, Zhaoxia Yin, Hang Su</li>
<li>for: 防止面Recognition系统受到呈现攻击的可靠性</li>
<li>methods: 利用两个相互关联的分数来准确地分辨正确探测和错误探测的面图像</li>
<li>results: 在不同的攻击方式、数据集和后处理器上，可以准确地识别出面图像中的攻击，同时保持高精度对正常图像的识别。此外，成功应用于实际世界中的攻击示例。<details>
<summary>Abstract</summary>
Ensuring the reliability of face recognition systems against presentation attacks necessitates the deployment of face anti-spoofing techniques. Despite considerable advancements in this domain, the ability of even the most state-of-the-art methods to defend against adversarial examples remains elusive. While several adversarial defense strategies have been proposed, they typically suffer from constrained practicability due to inevitable trade-offs between universality, effectiveness, and efficiency. To overcome these challenges, we thoroughly delve into the coupled relationship between adversarial detection and face anti-spoofing. Based on this, we propose a robust face anti-spoofing framework, namely AdvFAS, that leverages two coupled scores to accurately distinguish between correctly detected and wrongly detected face images. Extensive experiments demonstrate the effectiveness of our framework in a variety of settings, including different attacks, datasets, and backbones, meanwhile enjoying high accuracy on clean examples. Moreover, we successfully apply the proposed method to detect real-world adversarial examples.
</details>
<details>
<summary>摘要</summary>
保证人脸识别系统对于投放攻击的可靠性需要实施人脸反伪技术。尽管在这域中已经取得了很大的进步，但是even the most state-of-the-art methods still cannot effectively defend against adversarial examples。虽然有许多防御攻击策略被提出，但它们通常受到了不可避免的universality、效果和效率的负担。为了突破这些挑战，我们深入探究了对抗攻击和人脸反伪的关联关系。基于这，我们提出了一个robust的人脸反伪框架，即AdvFAS，该框架利用了两个联合分数来准确地分辨 correctly detected和 incorrectly detected的人脸图像。广泛的实验表明我们的框架在不同的攻击、数据集和后端下具有极高的准确率，同时对于清洁的例子也有高效率。此外，我们成功应用了提议的方法来实际中检测真实的攻击示例。
</details></li>
</ul>
<hr>
<h2 id="N-gram-Boosting-Improving-Contextual-Biasing-with-Normalized-N-gram-Targets"><a href="#N-gram-Boosting-Improving-Contextual-Biasing-with-Normalized-N-gram-Targets" class="headerlink" title="N-gram Boosting: Improving Contextual Biasing with Normalized N-gram Targets"></a>N-gram Boosting: Improving Contextual Biasing with Normalized N-gram Targets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02092">http://arxiv.org/abs/2308.02092</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wang Yau Li, Shreekantha Nadig, Karol Chang, Zafarullah Mahmood, Riqiang Wang, Simon Vandieken, Jonas Robertson, Fred Mailhot</li>
<li>for: 提高商务对话中关键词的识别率</li>
<li>methods: 使用两步关键词增强机制，可以处理Normalized unigrams和n-grams，并避免过度增强多个词语</li>
<li>results: 实现26%的关键词识别率提高，相比于专有数据集和LibriSpeechNote:* “提高商务对话中关键词的识别率” means “improve the recognition rate of key words in business conversations”* “两步关键词增强机制” means “two-step keyword boosting mechanism”* “Normalized unigrams和n-grams” means “normalized unigrams and n-grams”* “过度增强多个词语” means “over-boosting multiple words”<details>
<summary>Abstract</summary>
Accurate transcription of proper names and technical terms is particularly important in speech-to-text applications for business conversations. These words, which are essential to understanding the conversation, are often rare and therefore likely to be under-represented in text and audio training data, creating a significant challenge in this domain. We present a two-step keyword boosting mechanism that successfully works on normalized unigrams and n-grams rather than just single tokens, which eliminates missing hits issues with boosting raw targets. In addition, we show how adjusting the boosting weight logic avoids over-boosting multi-token keywords. This improves our keyword recognition rate by 26% relative on our proprietary in-domain dataset and 2% on LibriSpeech. This method is particularly useful on targets that involve non-alphabetic characters or have non-standard pronunciations.
</details>
<details>
<summary>摘要</summary>
正确地转录特定名称和技术 терміns是在商业对话中的speech-to-text应用程序中 particualrly 重要。这些字眼，它们是理解对话的重要组成部分，通常是罕见的，因此在文本和音频训练数据中受到抑制，创建了一个大型挑战。我们提出了一个two-step键字提升机制，成功运作于 Normalized unigrams 和 n-grams 而不是单token，这样排除了遗漏命中问题。此外，我们显示了如何调整提升重量逻辑，以避免过度增强多token键字。这将提高我们的键字识别率 by 26% 相对于我们的专有项目数据，并且提高了2% 相对于 LibriSpeech。这种方法特别有用于目标包含非字母字符或非标准读法的情况。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Model-Adaptation-for-Continual-Learning-at-the-Edge"><a href="#Efficient-Model-Adaptation-for-Continual-Learning-at-the-Edge" class="headerlink" title="Efficient Model Adaptation for Continual Learning at the Edge"></a>Efficient Model Adaptation for Continual Learning at the Edge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02084">http://arxiv.org/abs/2308.02084</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zachary A. Daniels, Jun Hu, Michael Lomnitz, Phil Miller, Aswin Raghavan, Joe Zhang, Michael Piacentino, David Zhang</li>
<li>For: This paper is written for those interested in non-stationary automated machine learning (AutoML) models for efficient continual learning under domain shifts.* Methods: The paper presents the Encoder-Adaptor-Reconfigurator (EAR) framework, which uses a fixed deep neural network (DNN) feature encoder and trains shallow networks on top of the encoder to handle novel data. The EAR framework combines DNNs with hyperdimensional computing (HDC) to detect when new data is out-of-distribution (OOD), and uses zero-shot neural architecture search (ZS-NAS) to identify low-parameter neural adaptors to adapt the model to the OOD data.* Results: The paper demonstrates strong performance compared to state-of-the-art algorithms for OOD detection and few-&#x2F;zero-shot NAS on several benchmark datasets for domain adaptation. The EAR framework is capable of minimizing catastrophic forgetting on previous tasks by progressively growing the neural architecture as needed and dynamically routing data through the appropriate adaptors and reconfigurators for handling domain-incremental and class-incremental continual learning.<details>
<summary>Abstract</summary>
Most machine learning (ML) systems assume stationary and matching data distributions during training and deployment. This is often a false assumption. When ML models are deployed on real devices, data distributions often shift over time due to changes in environmental factors, sensor characteristics, and task-of-interest. While it is possible to have a human-in-the-loop to monitor for distribution shifts and engineer new architectures in response to these shifts, such a setup is not cost-effective. Instead, non-stationary automated ML (AutoML) models are needed. This paper presents the Encoder-Adaptor-Reconfigurator (EAR) framework for efficient continual learning under domain shifts. The EAR framework uses a fixed deep neural network (DNN) feature encoder and trains shallow networks on top of the encoder to handle novel data. The EAR framework is capable of 1) detecting when new data is out-of-distribution (OOD) by combining DNNs with hyperdimensional computing (HDC), 2) identifying low-parameter neural adaptors to adapt the model to the OOD data using zero-shot neural architecture search (ZS-NAS), and 3) minimizing catastrophic forgetting on previous tasks by progressively growing the neural architecture as needed and dynamically routing data through the appropriate adaptors and reconfigurators for handling domain-incremental and class-incremental continual learning. We systematically evaluate our approach on several benchmark datasets for domain adaptation and demonstrate strong performance compared to state-of-the-art algorithms for OOD detection and few-/zero-shot NAS.
</details>
<details>
<summary>摘要</summary>
大多数机器学习（ML）系统假设训练和部署时数据分布是静止的，这是一个错误的假设。当 ML 模型被部署在真实设备上时，数据分布经常会随着环境因素、传感器特性和任务的变化而变化。虽然可以有人在loop来监视数据分布的变化并开发新的建筑以适应这些变化，但这种设置不是经济可行的。相反，不稳定的自动化机器学习（AutoML）模型是需要的。这篇论文介绍了Encoder-Adaptor-Reconfigurator（EAR）框架，用于高效地进行逐步学习下domain shift。EAR框架使用固定的深度神经网络（DNN）特征编码器，并在编码器之上训练浅网络来处理新数据。EAR框架可以1) 将新数据作为out-of-distribution（OOD）检测，结合DNN和高维计算（HDC），2) 使用零参数神经适应器来适应OOD数据，并3) 通过逐步增长神经建筑和动态路由数据来避免快速卷积FORGET。我们系统地评估了我们的方法在几个标准的预测数据集上，并demonstrate了与当前的OOD检测和零参数NAS方法相比的优秀表现。
</details></li>
</ul>
<hr>
<h2 id="Disease-Insight-through-Digital-Biomarkers-Developed-by-Remotely-Collected-Wearables-and-Smartphone-Data"><a href="#Disease-Insight-through-Digital-Biomarkers-Developed-by-Remotely-Collected-Wearables-and-Smartphone-Data" class="headerlink" title="Disease Insight through Digital Biomarkers Developed by Remotely Collected Wearables and Smartphone Data"></a>Disease Insight through Digital Biomarkers Developed by Remotely Collected Wearables and Smartphone Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02043">http://arxiv.org/abs/2308.02043</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zulqarnain Rashid, Amos A Folarin, Yatharth Ranjan, Pauline Conde, Heet Sankesara, Yuezhou Zhang, Shaoxiong Sun, Callum Stewart, Petroula Laiou, Richard JB Dobson</li>
<li>For: The paper is written to explore the potential of digital biomarkers and remote patient monitoring in improving healthcare, particularly in the context of long-term longitudinal data collection and large-scale remote monitoring studies.* Methods: The paper describes the development of an open-source platform called RADAR-base, which supports scalability, extensibility, security, privacy, and quality of data for remote data collection and digital phenotyping. The platform uses Confluent’s Apache Kafka for data management and provides features such as study design and set-up, active and passive remote data collection capabilities, and secure data transmission.* Results: The paper reports that the RADAR-base platform has successfully collected longitudinal data for various cohorts in different disease areas, including Multiple Sclerosis, Depression, Epilepsy, ADHD, Alzheimer’s disease, Autism, and Lung diseases. The digital biomarkers developed through collected data have provided useful insights into different diseases, and clinicians can use these biomarkers to augment their decision-making for disease prevention, personalization, and early intervention.Here’s the simplified Chinese text for the three key points:* For: 这篇论文是为了探讨数字生物标志和远程患者监测在医疗方面的潜力，特别是在长期长期数据收集和大规模远程监测研究中。* Methods: 论文描述了一种名为RADAR-base的开源平台，该平台支持扩展性、可维护性、安全性、隐私性和数据质量。该平台使用Confluent的Apache Kafka进行数据管理，并提供了研究设计和设置、活动（例如患者自reported数据）和过去数据收集能力，以及安全数据传输和可扩展的数据存储和管理解决方案。* Results: 论文报告称RADAR-base平台已成功收集了不同疾病的长期数据，包括多发性硬化症、抑郁症、癫痫症、ADHD、阿尔ц海默症、自闭症和肺病等。数字生物标志通过收集的数据提供了对不同疾病的有用信息，且临床医生可以使用这些生物标志来增强其决策作用，以预防、个性化和早期 intervene 疾病。<details>
<summary>Abstract</summary>
Digital Biomarkers and remote patient monitoring can provide valuable and timely insights into how a patient is coping with their condition (disease progression, treatment response, etc.), complementing treatment in traditional healthcare settings.Smartphones with embedded and connected sensors have immense potential for improving healthcare through various apps and mHealth (mobile health) platforms. This capability could enable the development of reliable digital biomarkers from long-term longitudinal data collected remotely from patients. We built an open-source platform, RADAR-base, to support large-scale data collection in remote monitoring studies. RADAR-base is a modern remote data collection platform built around Confluent's Apache Kafka, to support scalability, extensibility, security, privacy and quality of data. It provides support for study design and set-up, active (eg PROMs) and passive (eg. phone sensors, wearable devices and IoT) remote data collection capabilities with feature generation (eg. behavioural, environmental and physiological markers). The backend enables secure data transmission, and scalable solutions for data storage, management and data access. The platform has successfully collected longitudinal data for various cohorts in a number of disease areas including Multiple Sclerosis, Depression, Epilepsy, ADHD, Alzheimer, Autism and Lung diseases. Digital biomarkers developed through collected data are providing useful insights into different diseases. RADAR-base provides a modern open-source, community-driven solution for remote monitoring, data collection, and digital phenotyping of physical and mental health diseases. Clinicians can use digital biomarkers to augment their decision making for the prevention, personalisation and early intervention of disease.
</details>
<details>
<summary>摘要</summary>
《数字生物标志和远程患者监测可以提供有价值和时效的病情信息，补充传统医疗设置中的治疗。智能手机 embed 和连接的感知器具有潜在的提高医疗质量的潜力，通过不同的应用和移动医疗（mHealth）平台。这种能力可以帮助开发可靠的数字生物标志，从远程收集的患者长期数据中提取有用信息。我们开发了一个开源平台，RADAR-base，以支持大规模数据收集在远程监测研究中。RADAR-base 是一个现代远程数据收集平台，基于 Confluent 的 Apache Kafka，以支持可扩展性、安全性、隐私性和数据质量。它提供了研究设计和设置、活动（例如 PROMs）和通过PASSIVE（例如手机感知器、智能手环和 IoT）远程数据收集能力，以及特征生成（例如行为、环境和生理 marker）。后端支持安全数据传输，扩展性的数据存储、管理和访问解决方案。该平台已成功收集了多种疾病区域的长期数据，包括多发性硬化症、抑郁症、 эпилепсия、ADHD、阿尔茨海默症和肺病。数字生物标志通过收集的数据提供了对不同疾病的有用信息。RADAR-base 提供了一个现代开源、社区驱动的解决方案，用于远程监测、数据收集和数字化现象学。临床医生可以使用数字生物标志来补充决策，预防、个性化和早期干预疾病。
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Task-Interference-in-Multi-Task-Learning-via-Explicit-Task-Routing-with-Non-Learnable-Primitives"><a href="#Mitigating-Task-Interference-in-Multi-Task-Learning-via-Explicit-Task-Routing-with-Non-Learnable-Primitives" class="headerlink" title="Mitigating Task Interference in Multi-Task Learning via Explicit Task Routing with Non-Learnable Primitives"></a>Mitigating Task Interference in Multi-Task Learning via Explicit Task Routing with Non-Learnable Primitives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02066">http://arxiv.org/abs/2308.02066</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhichao-lu/etr-nlp-mtl">https://github.com/zhichao-lu/etr-nlp-mtl</a></li>
<li>paper_authors: Chuntao Ding, Zhichao Lu, Shangguang Wang, Ran Cheng, Vishnu Naresh Boddeti</li>
<li>for: 这篇论文目的是提出一种可以减少任务干扰的多任务学习（MTL）方法，以便学习一个模型来完成多个任务。</li>
<li>methods: 这篇论文使用了一种synergistic combination of non-learnable primitives (NLPs)和explicit task routing (ETR)来减少任务干扰。具体来说，这篇论文使用了非学习的原始元素（NLPs）来提取多个任务共同的特征，然后将这些特征重新整合为共同的分支和每个任务的特定分支。</li>
<li>results: 实验结果显示，ETR-NLP网络在多个 dataset 上均能够取得state-of-the-art的性能，并且需要 fewer learnable parameters 和相似的 computations 。代码可以在这里找到：<a target="_blank" rel="noopener" href="https://github.com/zhichao-lu/etr-nlp-mtl%E3%80%82">https://github.com/zhichao-lu/etr-nlp-mtl。</a><details>
<summary>Abstract</summary>
Multi-task learning (MTL) seeks to learn a single model to accomplish multiple tasks by leveraging shared information among the tasks. Existing MTL models, however, have been known to suffer from negative interference among tasks. Efforts to mitigate task interference have focused on either loss/gradient balancing or implicit parameter partitioning with partial overlaps among the tasks. In this paper, we propose ETR-NLP to mitigate task interference through a synergistic combination of non-learnable primitives (NLPs) and explicit task routing (ETR). Our key idea is to employ non-learnable primitives to extract a diverse set of task-agnostic features and recombine them into a shared branch common to all tasks and explicit task-specific branches reserved for each task. The non-learnable primitives and the explicit decoupling of learnable parameters into shared and task-specific ones afford the flexibility needed for minimizing task interference. We evaluate the efficacy of ETR-NLP networks for both image-level classification and pixel-level dense prediction MTL problems. Experimental results indicate that ETR-NLP significantly outperforms state-of-the-art baselines with fewer learnable parameters and similar FLOPs across all datasets. Code is available at this \href{https://github.com/zhichao-lu/etr-nlp-mtl}.
</details>
<details>
<summary>摘要</summary>
多任务学习（MTL）目的是学习一个模型来完成多个任务，利用任务之间的共享信息。现有的MTL模型， however，有许多任务间的负面干扰。减轻任务干扰的努力主要集中在损失/梯度均衡或隐藏参数分区中。在这篇论文中，我们提出了ETR-NLP，用于减轻任务干扰的综合方法，包括非学习原理（NLP）和显式任务路由（ETR）。我们的关键想法是employnon-learnable原理来提取多个任务无关的特征，并将它们重新组合到一个共同的分支和每个任务的特定分支中。非学习原理和显式归一化学习参数为共享和任务特定的两个分支，允许我们适应性地减少任务干扰。我们在图像级别的分类和像素级的密集预测MTL问题中评估了ETR-NLP网络的效果。实验结果表明，ETR-NLPsignificantly exceedsstate-of-the-art基线，只需 fewer learnable parameters和相同的FLOPs。代码可以在这里找到：https://github.com/zhichao-lu/etr-nlp-mtl。
</details></li>
</ul>
<hr>
<h2 id="On-the-Biometric-Capacity-of-Generative-Face-Models"><a href="#On-the-Biometric-Capacity-of-Generative-Face-Models" class="headerlink" title="On the Biometric Capacity of Generative Face Models"></a>On the Biometric Capacity of Generative Face Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02065">http://arxiv.org/abs/2308.02065</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/human-analysis/capacity-generative-face-models">https://github.com/human-analysis/capacity-generative-face-models</a></li>
<li>paper_authors: Vishnu Naresh Boddeti, Gautam Sreekumar, Arun Ross<br>for: 这篇论文想要回答一个关键问题，即给定一个生成人脸模型，该模型可以生成多少个唯一的身份？methods: 该论文提出了一种统计方法来估算生成人脸图像的生物学性能。他们使用了幂圆混合特征空间来计算生成的人脸图像的质量。results: 研究发现，使用不同的生成模型，生成的人脸图像的生物学性能强相关于识别率。在false acceptance rate（FAR）为0.1%时，StyleGAN3和DCFace的生物学性能Upper bound分别为1.43×10^6和1.190×10^4。此外，研究还发现，降低desired FAR会导致生物学性能下降，并且存在一定的年龄差异。<details>
<summary>Abstract</summary>
There has been tremendous progress in generating realistic faces with high fidelity over the past few years. Despite this progress, a crucial question remains unanswered: "Given a generative face model, how many unique identities can it generate?" In other words, what is the biometric capacity of the generative face model? A scientific basis for answering this question will benefit evaluating and comparing different generative face models and establish an upper bound on their scalability. This paper proposes a statistical approach to estimate the biometric capacity of generated face images in a hyperspherical feature space. We employ our approach on multiple generative models, including unconditional generators like StyleGAN, Latent Diffusion Model, and "Generated Photos," as well as DCFace, a class-conditional generator. We also estimate capacity w.r.t. demographic attributes such as gender and age. Our capacity estimates indicate that (a) under ArcFace representation at a false acceptance rate (FAR) of 0.1%, StyleGAN3 and DCFace have a capacity upper bound of $1.43\times10^6$ and $1.190\times10^4$, respectively; (b) the capacity reduces drastically as we lower the desired FAR with an estimate of $1.796\times10^4$ and $562$ at FAR of 1% and 10%, respectively, for StyleGAN3; (c) there is no discernible disparity in the capacity w.r.t gender; and (d) for some generative models, there is an appreciable disparity in the capacity w.r.t age. Code is available at https://github.com/human-analysis/capacity-generative-face-models.
</details>
<details>
<summary>摘要</summary>
“过去几年，生成高质量的人脸模型已经取得了很大的进步。然而，一个重要的问题仍然没有答案：“给定一个生成人脸模型，它可以生成多少个唯一的人脸？”就是生成人脸模型的生物特征容量。一个科学基础的答案将有助于评估和比较不同的生成人脸模型，并且设置一个最大的可扩展性上限。本文提出了一个统计方法来估算生成人脸模型中的生物特征容量。我们使用这个方法评估了多个生成模型，包括StyleGAN、Latent Diffusion Model和“Generated Photos”等，以及DCFace，一个基于类别的生成模型。我们还估算了容量对于人口特征如性别和年龄的影响。我们的容量估算结果显示：（a）在 ArcFace 表示下， False Acceptance Rate（FAR）为0.1% 的情况下，StyleGAN3 和 DCFace 的容量Upper bound 为 $1.43\times10^6$ 和 $1.190\times10^4$，respectively;（b）容量随着 desired FAR 下降， ArcFace 表示下，FAR 为1% 和 10% 的情况下，StyleGAN3 的容量估算为 $1.796\times10^4$ 和 $562$，respectively;（c） gender 不会影响容量; （d） certain 生成模型中，年龄会影响容量。codes 可以在 GitHub 上找到：https://github.com/human-analysis/capacity-generative-face-models。”
</details></li>
</ul>
<hr>
<h2 id="Accurate-Neural-Network-Pruning-Requires-Rethinking-Sparse-Optimization"><a href="#Accurate-Neural-Network-Pruning-Requires-Rethinking-Sparse-Optimization" class="headerlink" title="Accurate Neural Network Pruning Requires Rethinking Sparse Optimization"></a>Accurate Neural Network Pruning Requires Rethinking Sparse Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02060">http://arxiv.org/abs/2308.02060</a></li>
<li>repo_url: None</li>
<li>paper_authors: Denis Kuznedelev, Eldar Kurtic, Eugenia Iofinova, Elias Frantar, Alexandra Peste, Dan Alistarh</li>
<li>for: 本研究旨在探讨高粗糙性对模型训练的影响，并提供了新的方法来 Mitigate this issue。</li>
<li>methods: 本研究使用了标准的计算机视觉和自然语言处理粗糙度标准测试 benchmarks，并提供了详细的分析。</li>
<li>results: 研究达到了高粗糙性下的state-of-the-art result，并提供了关于粗糙训练的difficulty的分析。<details>
<summary>Abstract</summary>
Obtaining versions of deep neural networks that are both highly-accurate and highly-sparse is one of the main challenges in the area of model compression, and several high-performance pruning techniques have been investigated by the community. Yet, much less is known about the interaction between sparsity and the standard stochastic optimization techniques used for training sparse networks, and most existing work uses standard dense schedules and hyperparameters for training sparse networks. In this work, we examine the impact of high sparsity on model training using the standard computer vision and natural language processing sparsity benchmarks. We begin by showing that using standard dense training recipes for sparse training is suboptimal, and results in under-training. We provide new approaches for mitigating this issue for both sparse pre-training of vision models (e.g. ResNet50/ImageNet) and sparse fine-tuning of language models (e.g. BERT/GLUE), achieving state-of-the-art results in both settings in the high-sparsity regime, and providing detailed analyses for the difficulty of sparse training in both scenarios. Our work sets a new threshold in terms of the accuracies that can be achieved under high sparsity, and should inspire further research into improving sparse model training, to reach higher accuracies under high sparsity, but also to do so efficiently.
</details>
<details>
<summary>摘要</summary>
obteniendo versiones de redes neuronales profundas que sean tanto altamente precisas como altamente esparsas es uno de los desafíos principales en el área de compresión de modelos, y varias técnicas de alta performance de poda han sido investigadas por la comunidad. Sin embargo, mucho menos se sabe sobre la interacción entre la esparsidad y las técnicas de optimización estocástica estándar utilizadas para entrenar redes esparsas, y la mayoría de las trabajos utilizan schedule y hiperparámetros estándar para entrenar redes esparsas. En este trabajo, examinamos el impacto de la alta esparsidad en el entrenamiento de modelos utilizando los benchmarks de visión por computadora y procesamiento de lenguaje estándar. Comenzamos mostrando que el uso de recetas de entrenamiento densas estándar para entrenar redes esparsas es subóptimo y resulta en under-entrenamiento. Proporcionamos nuevos enfoques para mitigar este problema para both pre-entrenamiento esparso de modelos de visión (por ejemplo, ResNet50/ImageNet) y fine-tuning esparso de modelos de lenguaje (por ejemplo, BERT/GLUE), logrando resultados estatales de la obra en ambos escenarios en el régimen de alta esparsidad, y proporcionando análisis detallados de la dificultad del entrenamiento esparso en ambos escenarios. Nuestro trabajo establece un nuevo umbral en términos de las precisiones que se pueden lograr bajo alta esparsidad, y debe inspirar más investigación en mejorar el entrenamiento de modelos esparsos, para alcanzar mayores precisiones bajo alta esparsidad, pero también hacerlo eficientemente.
</details></li>
</ul>
<hr>
<h2 id="Incorporating-Recklessness-to-Collaborative-Filtering-based-Recommender-Systems"><a href="#Incorporating-Recklessness-to-Collaborative-Filtering-based-Recommender-Systems" class="headerlink" title="Incorporating Recklessness to Collaborative Filtering based Recommender Systems"></a>Incorporating Recklessness to Collaborative Filtering based Recommender Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02058">http://arxiv.org/abs/2308.02058</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/knodis-research-group/recklessness-regularization">https://github.com/knodis-research-group/recklessness-regularization</a></li>
<li>paper_authors: Diego Pérez-López, Fernando Ortega, Ángel González-Prieto, Jorge Dueñas-Lerín</li>
<li>for: 这篇论文主要是为了提出一种基于matrix factorization的 recombination系统，以提高系统的准确性和创新性。</li>
<li>methods: 该论文提出了一种新的recklessness term来控制Matrix factorization-based recommender systems的决策时的风险水平，以确保系统的准确性和创新性。</li>
<li>results: 实验结果表明，recklessness不仅可以控制风险水平，还可以提高系统的预测量和质量。<details>
<summary>Abstract</summary>
Recommender systems that include some reliability measure of their predictions tend to be more conservative in forecasting, due to their constraint to preserve reliability. This leads to a significant drop in the coverage and novelty that these systems can provide. In this paper, we propose the inclusion of a new term in the learning process of matrix factorization-based recommender systems, called recklessness, which enables the control of the risk level desired when making decisions about the reliability of a prediction. Experimental results demonstrate that recklessness not only allows for risk regulation but also improves the quantity and quality of predictions provided by the recommender system.
</details>
<details>
<summary>摘要</summary>
建议系统，包括一些可靠度评估其预测的对策，往往会比较保守，因为它们需要保持可靠度。这会导致建议系统的覆盖率和新鲜度受到相当的减少。在这篇论文中，我们提议在矩阵分解基础的建议系统学习过程中添加一个新的变量，即“无耻”，以控制建议系统为预测中的风险水平。实验结果显示，无耻不仅可以调节风险，而且可以提高建议系统提供的量和质量。
</details></li>
</ul>
<hr>
<h2 id="The-Unequal-Opportunities-of-Large-Language-Models-Revealing-Demographic-Bias-through-Job-Recommendations"><a href="#The-Unequal-Opportunities-of-Large-Language-Models-Revealing-Demographic-Bias-through-Job-Recommendations" class="headerlink" title="The Unequal Opportunities of Large Language Models: Revealing Demographic Bias through Job Recommendations"></a>The Unequal Opportunities of Large Language Models: Revealing Demographic Bias through Job Recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02053">http://arxiv.org/abs/2308.02053</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abel Salinas, Parth Vipul Shah, Yuzhong Huang, Robert McCormack, Fred Morstatter</li>
<li>for: This paper aims to analyze and compare demographic biases in two cutting-edge large language models (LLMs), ChatGPT and LLaMA, through the lens of job recommendations.</li>
<li>methods: The authors propose a simple method for measuring intersectional biases in LLMs, which can be extended to examine biases associated with any intersection of demographic identities.</li>
<li>results: The study finds distinct biases in both models toward various demographic identities, such as consistently suggesting low-paying jobs for Mexican workers or preferring to recommend secretarial roles to women. These results highlight the importance of measuring the bias of LLMs in downstream applications to understand the potential for harm and inequitable outcomes.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文旨在分析和比较两个现代大语言模型（LLMs）ChatGPT和LLaMA中的人群偏见，通过职业建议来表示。</li>
<li>methods: 作者们提出了一种简单的方法来测量LLMs中的多重偏见，可以扩展到检测任何多重人群标识之间的偏见。</li>
<li>results: 研究发现ChatGPT和LLaMA都存在各种人群偏见，如 consistently suggesting low-paying jobs for Mexican workers or preferring to recommend secretarial roles to women。这些结果 highlights the importance of measuring LLMs的偏见在下游应用中，以便理解可能的危害和不公平的结果。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have seen widespread deployment in various real-world applications. Understanding these biases is crucial to comprehend the potential downstream consequences when using LLMs to make decisions, particularly for historically disadvantaged groups. In this work, we propose a simple method for analyzing and comparing demographic bias in LLMs, through the lens of job recommendations. We demonstrate the effectiveness of our method by measuring intersectional biases within ChatGPT and LLaMA, two cutting-edge LLMs. Our experiments primarily focus on uncovering gender identity and nationality bias; however, our method can be extended to examine biases associated with any intersection of demographic identities. We identify distinct biases in both models toward various demographic identities, such as both models consistently suggesting low-paying jobs for Mexican workers or preferring to recommend secretarial roles to women. Our study highlights the importance of measuring the bias of LLMs in downstream applications to understand the potential for harm and inequitable outcomes.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SMARLA-A-Safety-Monitoring-Approach-for-Deep-Reinforcement-Learning-Agents"><a href="#SMARLA-A-Safety-Monitoring-Approach-for-Deep-Reinforcement-Learning-Agents" class="headerlink" title="SMARLA: A Safety Monitoring Approach for Deep Reinforcement Learning Agents"></a>SMARLA: A Safety Monitoring Approach for Deep Reinforcement Learning Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02594">http://arxiv.org/abs/2308.02594</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amirhossein Zolfagharian, Manel Abdellatif, Lionel C. Briand, Ramesh S<br>for: 这篇论文是为了解决深度强化学习算法在安全关键系统中的安全问题而写的。methods: 这篇论文提出了一种基于机器学习的安全监测方法，名为SMARLA，可以用于检测深度强化学习代理的安全违反行为。SMARLA采用黑盒设计，不需要访问代理的内部，并且利用状态抽象来减少状态空间，从而使得学习安全违反预测模型更加容易。results: 实验分析表明，SMARLA可以准确预测安全违反行为，False Positive率较低，可以在代理执行的初期，大约半个执行前提前预测安全违反行为。<details>
<summary>Abstract</summary>
Deep reinforcement learning algorithms (DRL) are increasingly being used in safety-critical systems. Ensuring the safety of DRL agents is a critical concern in such contexts. However, relying solely on testing is not sufficient to ensure safety as it does not offer guarantees. Building safety monitors is one solution to alleviate this challenge. This paper proposes SMARLA, a machine learning-based safety monitoring approach designed for DRL agents. For practical reasons, SMARLA is designed to be black-box (as it does not require access to the internals of the agent) and leverages state abstraction to reduce the state space and thus facilitate the learning of safety violation prediction models from agent's states. We validated SMARLA on two well-known RL case studies. Empirical analysis reveals that SMARLA achieves accurate violation prediction with a low false positive rate, and can predict safety violations at an early stage, approximately halfway through the agent's execution before violations occur.
</details>
<details>
<summary>摘要</summary>
深度强化学习算法（DRL）在安全关键系统中越来越广泛使用。保证DRL代理的安全是一个关键问题。然而，仅仅通过测试是无法保证安全的，因为测试不能提供保证。本文提出了SMARLA，一种基于机器学习的安全监测方法，专门为DRL代理设计。由于实际原因，SMARLA采用黑盒设计（不需要代理的内部访问权限），并利用状态抽象来减少状态空间，从而使得学习安全违反预测模型从代理的状态中更加容易。我们对两个常见RL案例进行了验证。实验分析表明，SMARLA可以准确预测安全违反，并且False Positive率较低，能够在代理执行过程中的一半阶段预测安全违反。
</details></li>
</ul>
<hr>
<h2 id="Evaluation-of-STT-MRAM-as-a-Scratchpad-for-Training-in-ML-Accelerators"><a href="#Evaluation-of-STT-MRAM-as-a-Scratchpad-for-Training-in-ML-Accelerators" class="headerlink" title="Evaluation of STT-MRAM as a Scratchpad for Training in ML Accelerators"></a>Evaluation of STT-MRAM as a Scratchpad for Training in ML Accelerators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02024">http://arxiv.org/abs/2308.02024</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sourjya Roy, Cheng Wang, Anand Raghunathan</li>
<li>for: 该研究旨在开发高效的机器学习训练加速器，以满足由深度神经网络（DNN）训练带来的计算需求，而这些需求已经超过了逻辑门法则所带来的硬件性能提升。</li>
<li>methods: 该研究使用了批量加速器和隧道阵列，并对STT-MRAM进行了详细的设备到系统评估和合理化。另外，该研究还提出了一种减少写电压和持续时间以降低MRAM写操作的能量消耗的方法。</li>
<li>results: 研究表明，使用STT-MRAM作为卷积神经网络训练加速器的缓存可以提供15-22倍的系统级能gy减少，而无需妥协training训练精度。此外，该研究还发现了一种可以在训练过程中减少写电压和持续时间的方法，以降低MRAM写操作的能量消耗。<details>
<summary>Abstract</summary>
Progress in artificial intelligence and machine learning over the past decade has been driven by the ability to train larger deep neural networks (DNNs), leading to a compute demand that far exceeds the growth in hardware performance afforded by Moore's law. Training DNNs is an extremely memory-intensive process, requiring not just the model weights but also activations and gradients for an entire minibatch to be stored. The need to provide high-density and low-leakage on-chip memory motivates the exploration of emerging non-volatile memory for training accelerators. Spin-Transfer-Torque MRAM (STT-MRAM) offers several desirable properties for training accelerators, including 3-4x higher density than SRAM, significantly reduced leakage power, high endurance and reasonable access time. On the one hand, MRAM write operations require high write energy and latency due to the need to ensure reliable switching.   In this study, we perform a comprehensive device-to-system evaluation and co-optimization of STT-MRAM for efficient ML training accelerator design. We devised a cross-layer simulation framework to evaluate the effectiveness of STT-MRAM as a scratchpad replacing SRAM in a systolic-array-based DNN accelerator. To address the inefficiency of writes in STT-MRAM, we propose to reduce write voltage and duration. To evaluate the ensuing accuracy-efficiency trade-off, we conduct a thorough analysis of the error tolerance of input activations, weights, and errors during the training. We propose heterogeneous memory configurations that enable training convergence with good accuracy. We show that MRAM provide up to 15-22x improvement in system level energy across a suite of DNN benchmarks under iso-capacity and iso-area scenarios. Further optimizing STT-MRAM write operations can provide over 2x improvement in write energy for minimal degradation in application-level training accuracy.
</details>
<details>
<summary>摘要</summary>
过去一代人工智能和机器学习的进步主要受到深度神经网络（DNN）的训练所带来的 compute 需求，但是这些需求远 exceeds Moore's law 所提供的硬件性能增长。训练 DNN 需要一整个 minibatch 的模型重量、活化和梯度，这需要大量的内存。为了提供高密度且低漏电压的内存，我们开展了非易失性内存的探索，例如 Spin-Transfer-Torque MRAM (STT-MRAM)。STT-MRAM 具有训练 accelerator 的多个推荐性特点，包括较高的密度（3-4倍于 SRAM）、较低的漏电压、高终端urance 和合理的存取时间。然而，MRAM 写操作需要高的写入能量和延迟，因为需要保证可靠的转换。在这个研究中，我们对 STT-MRAM 的设备到系统评估和共优化进行了全面的评估。我们开发了跨层次的模拟框架，以评估 STT-MRAM 作为 DNN 加速器的磁盘储存器。为了解决 STT-MRAM 写入不效的问题，我们提议降低写入电压和时间。我们进行了详细的错误耐受分析，以评估对训练精度的影响。我们还提议了多元内存配置，以确保训练的团结。我们发现，使用 STT-MRAM 可以提供训练系统级能源的15-22倍提升，在一系列 DNN 参考数下。对于是o-容量和是o-面积情况，我们还提出了一些优化 STT-MRAM 写入操作的方法，可以提供更高的写入能源提升，而不会对应用程序级训练精度造成明显的损害。
</details></li>
</ul>
<hr>
<h2 id="On-the-Transition-from-Neural-Representation-to-Symbolic-Knowledge"><a href="#On-the-Transition-from-Neural-Representation-to-Symbolic-Knowledge" class="headerlink" title="On the Transition from Neural Representation to Symbolic Knowledge"></a>On the Transition from Neural Representation to Symbolic Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02000">http://arxiv.org/abs/2308.02000</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyan Cheng, Peter Chin</li>
<li>for: 本研究旨在将神经和符号表示之间的巨大差异 bridged,以实现将符号思维 integrate into neural networks的核心。</li>
<li>methods: 我们提出了一个具有EM算法的Neural-Symbolic Transitional Dictionary Learning（TDL）框架，可以将高维度资料的visual parts压缩为一组tensor作为神经变数，并自动发现该资料的隐藏 predicate structure。</li>
<li>results: 我们通过实验 demonstrates that the learned representation可以实现可读性 decomposition of visual input,并且可以适应下游任务，例如segmentation和推理等。此外，我们还使用了RL来进一步调整学习的got prototypes，以捕捉subjective factor。<details>
<summary>Abstract</summary>
Bridging the huge disparity between neural and symbolic representation can potentially enable the incorporation of symbolic thinking into neural networks from essence. Motivated by how human gradually builds complex symbolic representation from the prototype symbols that are learned through perception and environmental interactions. We propose a Neural-Symbolic Transitional Dictionary Learning (TDL) framework that employs an EM algorithm to learn a transitional representation of data that compresses high-dimension information of visual parts of an input into a set of tensors as neural variables and discover the implicit predicate structure in a self-supervised way. We implement the framework with a diffusion model by regarding the decomposition of input as a cooperative game, then learn predicates by prototype clustering. We additionally use RL enabled by the Markovian of diffusion models to further tune the learned prototypes by incorporating subjective factors. Extensive experiments on 3 abstract compositional visual objects datasets that require the model to segment parts without any visual features like texture, color, or shadows apart from shape and 3 neural/symbolic downstream tasks demonstrate the learned representation enables interpretable decomposition of visual input and smooth adaption to downstream tasks which are not available by existing methods.
</details>
<details>
<summary>摘要</summary>
将神经和符号表示之间的巨大差异桥接可能会使神经网络中包含符号思维。人类通过通过感知和环境互动学习的方式，慢慢地构建了复杂的符号表示。我们提出一个神经-符号过渡字典学习（TDL）框架，使用EM算法学习输入数据的过渡表示，压缩输入数据的高维信息为神经变量，自然地发现数据中隐藏的逻辑结构。我们在扩散模型中对输入的分解视为合作游戏，然后通过聚类算法学习预测。此外，我们还使用基于扩散模型的Markov链接学习Subjective因素来进一步调整学习的获得的 проtotypes。我们在3个抽象compositional视觉数据集和3个神经/符号下渠任务中进行了广泛的实验，结果表明学习的表示允许可 interpreted decompositions of visual input和下渠任务中的灵活适应。
</details></li>
</ul>
<hr>
<h2 id="Domain-specificity-and-data-efficiency-in-typo-tolerant-spell-checkers-the-case-of-search-in-online-marketplaces"><a href="#Domain-specificity-and-data-efficiency-in-typo-tolerant-spell-checkers-the-case-of-search-in-online-marketplaces" class="headerlink" title="Domain specificity and data efficiency in typo tolerant spell checkers: the case of search in online marketplaces"></a>Domain specificity and data efficiency in typo tolerant spell checkers: the case of search in online marketplaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01976">http://arxiv.org/abs/2308.01976</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dayananda Ubrangala, Juhi Sharma, Ravi Prasad Kondapalli, Kiran R, Amit Agarwala, Laurent Boué</li>
<li>for: 本研究旨在提高在线市场场所中的搜索功能，帮助用户更准确地搜索产品。</li>
<li>methods: 本研究使用数据增强技术，生成域限定的隐藏表示，并通过批处理神经网络训练这些表示。</li>
<li>results: 研究表明，使用本方法可以提高搜索精度，并且可以在实时进行搜索。同时，本方法可以使用小量高质量的Synthetic数据进行训练，而不需要大量的 annotated 数据。<details>
<summary>Abstract</summary>
Typographical errors are a major source of frustration for visitors of online marketplaces. Because of the domain-specific nature of these marketplaces and the very short queries users tend to search for, traditional spell cheking solutions do not perform well in correcting typos. We present a data augmentation method to address the lack of annotated typo data and train a recurrent neural network to learn context-limited domain-specific embeddings. Those embeddings are deployed in a real-time inferencing API for the Microsoft AppSource marketplace to find the closest match between a misspelled user query and the available product names. Our data efficient solution shows that controlled high quality synthetic data may be a powerful tool especially considering the current climate of large language models which rely on prohibitively huge and often uncontrolled datasets.
</details>
<details>
<summary>摘要</summary>
Typographical errors are a major source of frustration for visitors of online marketplaces. Because of the domain-specific nature of these marketplaces and the very short queries users tend to search for, traditional spell checking solutions do not perform well in correcting typos. We present a data augmentation method to address the lack of annotated typo data and train a recurrent neural network to learn context-limited domain-specific embeddings. Those embeddings are deployed in a real-time inferencing API for the Microsoft AppSource marketplace to find the closest match between a misspelled user query and the available product names. Our data efficient solution shows that controlled high quality synthetic data may be a powerful tool, especially considering the current climate of large language models which rely on prohibitively huge and often uncontrolled datasets.Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="SpaDen-Sparse-and-Dense-Keypoint-Estimation-for-Real-World-Chart-Understanding"><a href="#SpaDen-Sparse-and-Dense-Keypoint-Estimation-for-Real-World-Chart-Understanding" class="headerlink" title="SpaDen : Sparse and Dense Keypoint Estimation for Real-World Chart Understanding"></a>SpaDen : Sparse and Dense Keypoint Estimation for Real-World Chart Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01971">http://arxiv.org/abs/2308.01971</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saleem Ahmed, Pengyu Yan, David Doermann, Srirangaraj Setlur, Venu Govindaraju</li>
<li>for: 提取实际世界图表数据</li>
<li>methods: 使用图表像素为输入，检测图表中的关键点（KP），并使用这些KP重建图表中的组件。</li>
<li>results: 通过深度度量学习和卷积抽象层来学习KP嵌入，并使用这些嵌入来分类图表区域为不同的物体。通过对图表组件与图表注释进行匹配，可以获取图表数据 serie 名称。<details>
<summary>Abstract</summary>
We introduce a novel bottom-up approach for the extraction of chart data. Our model utilizes images of charts as inputs and learns to detect keypoints (KP), which are used to reconstruct the components within the plot area. Our novelty lies in detecting a fusion of continuous and discrete KP as predicted heatmaps. A combination of sparse and dense per-pixel objectives coupled with a uni-modal self-attention-based feature-fusion layer is applied to learn KP embeddings. Further leveraging deep metric learning for unsupervised clustering, allows us to segment the chart plot area into various objects. By further matching the chart components to the legend, we are able to obtain the data series names. A post-processing threshold is applied to the KP embeddings to refine the object reconstructions and improve accuracy. Our extensive experiments include an evaluation of different modules for KP estimation and the combination of deep layer aggregation and corner pooling approaches. The results of our experiments provide extensive evaluation for the task of real-world chart data extraction.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种新的底向approach для图表数据EXTRACTION。我们的模型使用图表图像作为输入，并学习检测关键点（KP），这些关键点用于在图表区域中重建组件。我们的新特点在于检测图表中的热图，并将其与热图预测的热图进行融合。我们使用稀疏和密集每个像素目标，并与uni-modal自注意力基于的特征融合层来学习KP嵌入。通过深度度量学习进行无监督分群，我们可以将图表区域分成不同的对象。通过将图表组件与表格中的名称匹配，我们可以获取数据时间序列名称。我们还应用了预处理阈值来修正对象重建和提高准确性。我们的广泛的实验包括了不同模块的KP估计和深层层合并和角落聚合方法的组合。实验结果为实际世界图表数据EXTRACTION任务提供了广泛的评估。
</details></li>
</ul>
<hr>
<h2 id="Reasoning-in-Large-Language-Models-Through-Symbolic-Math-Word-Problems"><a href="#Reasoning-in-Large-Language-Models-Through-Symbolic-Math-Word-Problems" class="headerlink" title="Reasoning in Large Language Models Through Symbolic Math Word Problems"></a>Reasoning in Large Language Models Through Symbolic Math Word Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01906">http://arxiv.org/abs/2308.01906</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vedant Gaur, Nikunj Saunshi</li>
<li>for: 这篇论文探讨了数学问题（MWPs）中LLM的理解能力。</li>
<li>methods: 研究者使用了符号版的 numeric 问题，并使用 GPT-3 的 davinci-002 模型进行测试。</li>
<li>results: 研究发现，自我提示法可以使 LLM 提供更加简洁和可靠的理解，并且可以提高 symbolic 准确率。<details>
<summary>Abstract</summary>
Large language models (LLMs) have revolutionized NLP by solving downstream tasks with little to no labeled data. Despite their versatile abilities, the larger question of their ability to reason remains ill-understood. This paper addresses reasoning in math word problems (MWPs) by studying symbolic versions of the numeric problems, since a symbolic expression is a "concise explanation" of the numeric answer. We create and use a symbolic version of the SVAMP dataset and find that GPT-3's davinci-002 model also has good zero-shot accuracy on symbolic MWPs. To evaluate the faithfulness of the model's reasoning, we go beyond accuracy and additionally evaluate the alignment between the final answer and the outputted reasoning, which correspond to numeric and symbolic answers respectively for MWPs. We explore a self-prompting approach to encourage the symbolic reasoning to align with the numeric answer, thus equipping the LLM with the ability to provide a concise and verifiable reasoning and making it more interpretable. Surprisingly, self-prompting also improves the symbolic accuracy to be higher than both the numeric and symbolic accuracies, thus providing an ensembling effect. The SVAMP_Sym dataset will be released for future research on symbolic math problems.
</details>
<details>
<summary>摘要</summary>
（注意：以下是简化中文版本，有些词语和表达可能会被简化或修改，以适应中文语言特点）
</details></li>
</ul>
<hr>
<h2 id="Revisiting-Deformable-Convolution-for-Depth-Completion"><a href="#Revisiting-Deformable-Convolution-for-Depth-Completion" class="headerlink" title="Revisiting Deformable Convolution for Depth Completion"></a>Revisiting Deformable Convolution for Depth Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01905">http://arxiv.org/abs/2308.01905</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinglong Sun, Jean Ponce, Yu-Xiong Wang<br>for:实现高品质的紧密深度地图 from sparse depth maps，这个问题在最近几年中受到了增加的关注。methods:我们提出了一个有效的架构，它利用弹性核心条件 convolution 作为单一通过调整模组，并经过实验证明其超越性。results:我们的模型在大规模的 KITTI 数据集上评估，实现了 State-of-the-art 的性能和测试速度。<details>
<summary>Abstract</summary>
Depth completion, which aims to generate high-quality dense depth maps from sparse depth maps, has attracted increasing attention in recent years. Previous work usually employs RGB images as guidance, and introduces iterative spatial propagation to refine estimated coarse depth maps. However, most of the propagation refinement methods require several iterations and suffer from a fixed receptive field, which may contain irrelevant and useless information with very sparse input. In this paper, we address these two challenges simultaneously by revisiting the idea of deformable convolution. We propose an effective architecture that leverages deformable kernel convolution as a single-pass refinement module, and empirically demonstrate its superiority. To better understand the function of deformable convolution and exploit it for depth completion, we further systematically investigate a variety of representative strategies. Our study reveals that, different from prior work, deformable convolution needs to be applied on an estimated depth map with a relatively high density for better performance. We evaluate our model on the large-scale KITTI dataset and achieve state-of-the-art level performance in both accuracy and inference speed. Our code is available at https://github.com/AlexSunNik/ReDC.
</details>
<details>
<summary>摘要</summary>
depth 完成，它目标是从粗略的深度图生成高质量的紧密深度图，在最近几年内吸引了越来越多的关注。先前的工作通常使用 RGB 图像作为指导，并 introduce 融合的空间卷积来精细修正估算的粗略深度图。然而，大多数的卷积修正方法需要多个迭代和受限于固定的接受范围，这可能包含无关和无用的信息，尤其是针对非常罕见的输入。在这篇论文中，我们解决了这两个挑战，我们修订了抽象核心卷积的想法。我们提出了一个有效的架构，利用抽象核心卷积作为单 passes 精细修正模块，并经验性地证明其优越性。为了更好地理解抽象卷积的功能和利用它来进行深度完成，我们进一步系统地研究了多种表现方式。我们的研究表明，与先前的工作不同，抽象卷积需要在估算的深度图中具有较高的密度，以便更好的表现。我们在大规模的 KITTI 数据集上评估了我们的模型，并达到了当今最佳水平的准确率和推理速度。我们的代码可以在 <https://github.com/AlexSunNik/ReDC> 上下载。
</details></li>
</ul>
<hr>
<h2 id="How-many-preprints-have-actually-been-printed-and-why-a-case-study-of-computer-science-preprints-on-arXiv"><a href="#How-many-preprints-have-actually-been-printed-and-why-a-case-study-of-computer-science-preprints-on-arXiv" class="headerlink" title="How many preprints have actually been printed and why: a case study of computer science preprints on arXiv"></a>How many preprints have actually been printed and why: a case study of computer science preprints on arXiv</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01899">http://arxiv.org/abs/2308.01899</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jialiang Lin, Yao Yu, Yu Zhou, Zhiyang Zhou, Xiaodong Shi</li>
<li>for: 这个论文是为了研究计算机科学预印 Server上发表的论文是否能够在同行评审期刊或会议上发表的。</li>
<li>methods: 该论文使用了 traditional fuzzy matching 方法和 Bidirectional Encoder Representations from Transformers (BERT) semantics-based mapping 方法来映射预印和最终发表的文献。</li>
<li>results: 研究发现，66% 的预印 eventually 被发表在同一个标题下，而11% 的预印被修改后发表。进一步的分析发现，已经发表的预印文献具有充分的修订、多个作者、详细的摘要和引言、广泛的参考文献和可用的源代码等特征。<details>
<summary>Abstract</summary>
Preprints play an increasingly critical role in academic communities. There are many reasons driving researchers to post their manuscripts to preprint servers before formal submission to journals or conferences, but the use of preprints has also sparked considerable controversy, especially surrounding the claim of priority. In this paper, a case study of computer science preprints submitted to arXiv from 2008 to 2017 is conducted to quantify how many preprints have eventually been printed in peer-reviewed venues. Among those published manuscripts, some are published under different titles and without an update to their preprints on arXiv. In the case of these manuscripts, the traditional fuzzy matching method is incapable of mapping the preprint to the final published version. In view of this issue, we introduce a semantics-based mapping method with the employment of Bidirectional Encoder Representations from Transformers (BERT). With this new mapping method and a plurality of data sources, we find that 66% of all sampled preprints are published under unchanged titles and 11% are published under different titles and with other modifications. A further analysis was then performed to investigate why these preprints but not others were accepted for publication. Our comparison reveals that in the field of computer science, published preprints feature adequate revisions, multiple authorship, detailed abstract and introduction, extensive and authoritative references and available source code.
</details>
<details>
<summary>摘要</summary>
Preprints 在学术社区中发挥越来越重要的作用。有很多原因使研究人员在发布到Preprint仓库之前不会正式提交到期刊或会议，但使用Preprint也引发了较大的争议，特别是优先权的问题。在这篇论文中，我们通过对计算机科学Preprint从2008年到2017年 submitting 到arXiv 的Case study来量化这些Preprints eventually 被发表在 peer-reviewed 期刊和会议中。其中一些发表的 manuscripts 被发表 unter different titles 和不更新 arXiv 上的 preprints。在这些 manuscripts 中，传统的模糊匹配方法无法将 preprint 映射到最终发表的版本。为解决这个问题，我们引入了基于 semantics 的映射方法，使用 Bidirectional Encoder Representations from Transformers (BERT)。With this new mapping method and a plurality of data sources, we find that 66% of all sampled preprints are published under unchanged titles and 11% are published under different titles and with other modifications. A further analysis was then performed to investigate why these preprints but not others were accepted for publication. Our comparison reveals that in the field of computer science, published preprints feature adequate revisions, multiple authorship, detailed abstract and introduction, extensive and authoritative references and available source code.
</details></li>
</ul>
<hr>
<h2 id="Improving-Replay-Sample-Selection-and-Storage-for-Less-Forgetting-in-Continual-Learning"><a href="#Improving-Replay-Sample-Selection-and-Storage-for-Less-Forgetting-in-Continual-Learning" class="headerlink" title="Improving Replay Sample Selection and Storage for Less Forgetting in Continual Learning"></a>Improving Replay Sample Selection and Storage for Less Forgetting in Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01895">http://arxiv.org/abs/2308.01895</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Brignac, Niels Lobo, Abhijit Mahalanobis</li>
<li>for: 本研究旨在Addressing the issues of selectively storing the most informative samples and determining the optimal number of stored samples in continual learning, in order to improve the performance of deep learners in training on a series of tasks of unknown length without suffering from catastrophic forgetting.</li>
<li>methods: 本研究使用了一种novel comparison of the commonly used reservoir sampling to various alternative population strategies, 以及提供了一个novel detailed analysis of how to find the optimal number of stored samples.</li>
<li>results: 本研究提出了一种新的方法来选择最有用的样本存储和确定最佳存储样本数量, 并且通过实验证明了这种方法可以提高深度学习器在不同任务集合上的性能。<details>
<summary>Abstract</summary>
Continual learning seeks to enable deep learners to train on a series of tasks of unknown length without suffering from the catastrophic forgetting of previous tasks. One effective solution is replay, which involves storing few previous experiences in memory and replaying them when learning the current task. However, there is still room for improvement when it comes to selecting the most informative samples for storage and determining the optimal number of samples to be stored. This study aims to address these issues with a novel comparison of the commonly used reservoir sampling to various alternative population strategies and providing a novel detailed analysis of how to find the optimal number of stored samples.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:continuous learning旨在帮助深度学习者在未知长度的任务序列上训练而不受过去任务的恶化。一种有效的解决方案是 reuse，即将一些过去经验存储在内存中，并在学习当前任务时重新播放。然而，还有一些可以提高的空间，例如选择存储的最有用样本和确定存储样本的优化数量。这项研究计划通过对常用的储存采样与其他人口策略进行比较，以及提供一种新的细化分析，以找到最佳存储样本的数量。
</details></li>
</ul>
<hr>
<h2 id="Thespian-Multi-Character-Text-Role-Playing-Game-Agents"><a href="#Thespian-Multi-Character-Text-Role-Playing-Game-Agents" class="headerlink" title="Thespian: Multi-Character Text Role-Playing Game Agents"></a>Thespian: Multi-Character Text Role-Playing Game Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01872">http://arxiv.org/abs/2308.01872</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christopher Cui, Xiangyu Peng, Mark Riedl</li>
<li>for: 这个论文目的是为了研究文本冒险游戏和文本角色扮演游戏中的人工智能游戏玩家代理。</li>
<li>methods: 这个论文使用了一种名为”演员代理”的框架，可以学习多个角色并使用软提示来指定当前要扮演哪个角色。它还使用了一种注意力机制，可以在几个步骤内学习新的角色，这些角色基于之前学习的角色。</li>
<li>results: 论文表明， compared to the state of the art agent framework, 我们的演员代理在多个角色学习和几个步骤内学习中表现更出色。<details>
<summary>Abstract</summary>
Text-adventure games and text role-playing games are grand challenges for reinforcement learning game playing agents. Text role-playing games are open-ended environments where an agent must faithfully play a particular character. We consider the distinction between characters and actors, where an actor agent has the ability to play multiple characters. We present a framework we call a thespian agent that can learn to emulate multiple characters along with a soft prompt that can be used to direct it as to which character to play at any time. We further describe an attention mechanism that allows the agent to learn new characters that are based on previously learned characters in a few-shot fashion. We show that our agent outperforms the state of the art agent framework in multi-character learning and few-shot learning.
</details>
<details>
<summary>摘要</summary>
文本冒险游戏和文本角色游戏是束缚学习游戏玩家代理的大挑战。文本角色游戏是开放式环境，agent必须坚定地扮演特定的角色。我们考虑了角色和演员之间的区别，其中演员代理有多个角色的扮演能力。我们提出了一个名为“演员代理”的框架，可以学习多个角色，并且可以使用软提示来指定在任何时候哪个角色来扮演。我们还描述了一种注意力机制，允许代理学习基于之前学习的角色的新角色，在几个尝试中学习。我们表明，我们的代理在多个角色学习和几个尝试学习方面超过了现状的最佳代理框架。
</details></li>
</ul>
<hr>
<h2 id="ClassEval-A-Manually-Crafted-Benchmark-for-Evaluating-LLMs-on-Class-level-Code-Generation"><a href="#ClassEval-A-Manually-Crafted-Benchmark-for-Evaluating-LLMs-on-Class-level-Code-Generation" class="headerlink" title="ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on Class-level Code Generation"></a>ClassEval: A Manually-Crafted Benchmark for Evaluating LLMs on Class-level Code Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01861">http://arxiv.org/abs/2308.01861</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fudanselab/classeval">https://github.com/fudanselab/classeval</a></li>
<li>paper_authors: Xueying Du, Mingwei Liu, Kaixin Wang, Hanlin Wang, Junwei Liu, Yixuan Chen, Jiayi Feng, Chaofeng Sha, Xin Peng, Yiling Lou</li>
<li>for: 评估大型自然语言模型（LLMs）在更加具有挑战性的代码生成方式中的表现，即类层次代码生成。</li>
<li>methods: 利用手动构建的首个类层次Python代码生成测试套件ClassEval，对11种当前state-of-the-art LLMs进行首次研究。</li>
<li>results: 发现所有现有LLMs在类层次代码生成方面表现较差，与单独的方法级代码生成benchmarks like HumanEval的表现不符，并且不能等效地反映类层次代码生成能力。GPT-4和GPT-3.5仍然在类层次代码生成方面具有显著优势，而其他模型的表现较差。 holistic generation strategy 仅适用于GPT-4和GPT-3.5，而 method-by-method generation 是更好的生成策略。<details>
<summary>Abstract</summary>
In this work, we make the first attempt to evaluate LLMs in a more challenging code generation scenario, i.e. class-level code generation. We first manually construct the first class-level code generation benchmark ClassEval of 100 class-level Python code generation tasks with approximately 500 person-hours. Based on it, we then perform the first study of 11 state-of-the-art LLMs on class-level code generation. Based on our results, we have the following main findings. First, we find that all existing LLMs show much worse performance on class-level code generation compared to on standalone method-level code generation benchmarks like HumanEval; and the method-level coding ability cannot equivalently reflect the class-level coding ability among LLMs. Second, we find that GPT-4 and GPT-3.5 still exhibit dominate superior than other LLMs on class-level code generation, and the second-tier models includes Instruct-Starcoder, Instruct-Codegen, and Wizardcoder with very similar performance. Third, we find that generating the entire class all at once (i.e. holistic generation strategy) is the best generation strategy only for GPT-4 and GPT-3.5, while method-by-method generation (i.e. incremental and compositional) is better strategies for the other models with limited ability of understanding long instructions and utilizing the middle information. Lastly, we find the limited model ability of generating method-dependent code and discuss the frequent error types in generated classes. Our benchmark is available at https://github.com/FudanSELab/ClassEval.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们首次对 LLM 进行了更加挑战性的代码生成场景的评估，即类级代码生成。我们首先手动构建了首个类级 Python 代码生成任务的benchmark，名为ClassEval，包含100个类级代码生成任务，需要约500个工作人时。基于这个benchmark，我们然后对11种当前最新的 LLM 进行了首次研究。根据我们的结果，我们有以下主要发现：首先，我们发现所有的 LLM 在类级代码生成场景下表现比在独立方法级代码生成benchmark like HumanEval 更差，而且单独的方法级代码生成能力不能完全反映类级代码生成能力。第二，我们发现 GPT-4 和 GPT-3.5 仍然在类级代码生成场景下表现出色，而其他 LLM 则表现较差。第三，我们发现在整个类都生成一次（即整体生成策略）仅适用于 GPT-4 和 GPT-3.5，而其他模型的有限理解长 instrucions 和利用中间信息的能力不足。最后，我们发现 LLM 对于生成方法相关的代码具有限制，并讨论了生成类中的常见错误类型。我们的benchmark可以在 GitHub 上获取：https://github.com/FudanSELab/ClassEval。
</details></li>
</ul>
<hr>
<h2 id="Synthesizing-Long-Term-Human-Motions-with-Diffusion-Models-via-Coherent-Sampling"><a href="#Synthesizing-Long-Term-Human-Motions-with-Diffusion-Models-via-Coherent-Sampling" class="headerlink" title="Synthesizing Long-Term Human Motions with Diffusion Models via Coherent Sampling"></a>Synthesizing Long-Term Human Motions with Diffusion Models via Coherent Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01850">http://arxiv.org/abs/2308.01850</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yangzhao1230/pcmdm">https://github.com/yangzhao1230/pcmdm</a></li>
<li>paper_authors: Zhao Yang, Bing Su, Ji-Rong Wen</li>
<li>for: 生成长期动作，控制于用户指导的长文本流中</li>
<li>methods: 使用过去条件扩散模型，并提供两种可选的凝聚采样方法：过去填充采样和组成转换采样</li>
<li>results: 能够生成具有组成性和连续性的3D人体动作，控制于用户指导的长文本流<details>
<summary>Abstract</summary>
Text-to-motion generation has gained increasing attention, but most existing methods are limited to generating short-term motions that correspond to a single sentence describing a single action. However, when a text stream describes a sequence of continuous motions, the generated motions corresponding to each sentence may not be coherently linked. Existing long-term motion generation methods face two main issues. Firstly, they cannot directly generate coherent motions and require additional operations such as interpolation to process the generated actions. Secondly, they generate subsequent actions in an autoregressive manner without considering the influence of future actions on previous ones. To address these issues, we propose a novel approach that utilizes a past-conditioned diffusion model with two optional coherent sampling methods: Past Inpainting Sampling and Compositional Transition Sampling. Past Inpainting Sampling completes subsequent motions by treating previous motions as conditions, while Compositional Transition Sampling models the distribution of the transition as the composition of two adjacent motions guided by different text prompts. Our experimental results demonstrate that our proposed method is capable of generating compositional and coherent long-term 3D human motions controlled by a user-instructed long text stream. The code is available at \href{https://github.com/yangzhao1230/PCMDM}{https://github.com/yangzhao1230/PCMDM}.
</details>
<details>
<summary>摘要</summary>
文本到动作生成技术在最近几年来已经得到了越来越多的关注，但大多数现有的方法只能生成对应单句描述单个动作的短期动作。然而，当文本流描述一系列连续动作时，生成的动作对每句文本可能无法协调性链接。现有的长期动作生成方法面临两个主要问题。一是，它们无法直接生成协调的动作，需要额外操作如 interpolate 来处理生成的动作。二是，它们生成后续动作在自动推理模式下，不考虑前一个动作对后一个动作的影响。为解决这些问题，我们提出了一种新的方法，利用过去条件 diffusion 模型，并提供了两种可选的协调采样方法：过去填充采样和 compositional transition sampling。过去填充采样完成后续动作，将前一个动作作为条件，而 compositional transition sampling 模型了动作过渡的分布，以两个不同的文本提示导引的动作为指导。我们的实验结果表明，我们的提议的方法可以生成协调和有 coherence 的长期三维人体动作，由用户指定的长文本流控制。代码可以在 \href{https://github.com/yangzhao1230/PCMDM}{https://github.com/yangzhao1230/PCMDM} 上获取。
</details></li>
</ul>
<hr>
<h2 id="URET-Universal-Robustness-Evaluation-Toolkit-for-Evasion"><a href="#URET-Universal-Robustness-Evaluation-Toolkit-for-Evasion" class="headerlink" title="URET: Universal Robustness Evaluation Toolkit (for Evasion)"></a>URET: Universal Robustness Evaluation Toolkit (for Evasion)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01840">http://arxiv.org/abs/2308.01840</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ibm/uret">https://github.com/ibm/uret</a></li>
<li>paper_authors: Kevin Eykholt, Taesung Lee, Douglas Schales, Jiyong Jang, Ian Molloy, Masha Zorin</li>
<li>for: 本研究旨在提供一种可以生成针对各种输入类型和任务领域的攻击输入的框架。</li>
<li>methods: 该框架使用给定的输入和一组预定的输入变换来找到一个Semantically正确且功能正确的攻击输入。</li>
<li>results: 该研究在多种不同的机器学习任务和各种输入表示方式上进行了多种攻击输入的生成和评估，并证明了生成攻击输入的重要性。<details>
<summary>Abstract</summary>
Machine learning models are known to be vulnerable to adversarial evasion attacks as illustrated by image classification models. Thoroughly understanding such attacks is critical in order to ensure the safety and robustness of critical AI tasks. However, most evasion attacks are difficult to deploy against a majority of AI systems because they have focused on image domain with only few constraints. An image is composed of homogeneous, numerical, continuous, and independent features, unlike many other input types to AI systems used in practice. Furthermore, some input types include additional semantic and functional constraints that must be observed to generate realistic adversarial inputs. In this work, we propose a new framework to enable the generation of adversarial inputs irrespective of the input type and task domain. Given an input and a set of pre-defined input transformations, our framework discovers a sequence of transformations that result in a semantically correct and functional adversarial input. We demonstrate the generality of our approach on several diverse machine learning tasks with various input representations. We also show the importance of generating adversarial examples as they enable the deployment of mitigation techniques.
</details>
<details>
<summary>摘要</summary>
In this work, we propose a new framework to enable the generation of adversarial inputs regardless of the input type and task domain. Given an input and a set of pre-defined input transformations, our framework discovers a sequence of transformations that result in a semantically correct and functional adversarial input. We demonstrate the generality of our approach on several diverse machine learning tasks with various input representations. We also show the importance of generating adversarial examples, as they enable the deployment of mitigation techniques.Here's the translation in Simplified Chinese:机器学习模型知道会受到攻击性识别攻击，如图像识别模型所示。深入理解这些攻击非常重要，以确保AI任务的安全和稳定性。然而，大多数攻击都难以在大多数AI系统上进行，因为它们只Focus on图像领域，并且只有几个约束。一个图像由同类、数字、连续和独立的特征组成，与许多实际应用中的输入类型不同。此外，一些输入类型还有额外的Semantic和功能约束，必须遵循以生成真实的攻击输入。在这种情况下，我们提出了一个新的框架，可以无论输入类型和任务领域，生成攻击性的输入。给定一个输入和一组预定的输入变换，我们的框架可以找出一个符号正确和功能正确的攻击输入序列。我们在多种多样的机器学习任务上展示了我们的方法的通用性，以及输入表示的多样性。我们还证明了生成攻击示例的重要性，以便应用防御技术。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/04/cs.AI_2023_08_04/" data-id="closbrojt001x0g886u5j6ov7" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_08_04" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/04/cs.CL_2023_08_04/" class="article-date">
  <time datetime="2023-08-04T11:00:00.000Z" itemprop="datePublished">2023-08-04</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/04/cs.CL_2023_08_04/">cs.CL - 2023-08-04</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Dataflow-Dialogue-Generation"><a href="#Dataflow-Dialogue-Generation" class="headerlink" title="Dataflow Dialogue Generation"></a>Dataflow Dialogue Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02323">http://arxiv.org/abs/2308.02323</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/telepathylabsai/OpenDF">https://github.com/telepathylabsai/OpenDF</a></li>
<li>paper_authors: Joram Meron, Victor Guimarães</li>
<li>for: 这个论文主要是关于任务异常对话生成。</li>
<li>methods: 这个论文使用了数据流对话模式，并示例了在MultiWOZ领域中的任务驱动对话生成，以及在SMCalFlow领域中的对话生成无法。</li>
<li>results: 研究发现，使用生成的对话来补充翻译训练数据可以提高翻译表达的准确率。<details>
<summary>Abstract</summary>
We demonstrate task-oriented dialogue generation within the dataflow dialogue paradigm. We show an example of agenda driven dialogue generation for the MultiWOZ domain, and an example of generation without an agenda for the SMCalFlow domain, where we show an improvement in the accuracy of the translation of user requests to dataflow expressions when the generated dialogues are used to augment the translation training dataset.
</details>
<details>
<summary>摘要</summary>
我们展示了任务导向对话生成在数据流对话模式下。我们给出了多普遍领域的例子，如多语言对话（MultiWOZ），以及无任务例子，如SMCalFlow领域。我们显示了使用生成对话来增强用户请求到数据流表达的翻译准确性。
</details></li>
</ul>
<hr>
<h2 id="Redundancy-Aware-Multi-Reference-Based-Gainwise-Evaluation-of-Extractive-Summarization"><a href="#Redundancy-Aware-Multi-Reference-Based-Gainwise-Evaluation-of-Extractive-Summarization" class="headerlink" title="Redundancy Aware Multi-Reference Based Gainwise Evaluation of Extractive Summarization"></a>Redundancy Aware Multi-Reference Based Gainwise Evaluation of Extractive Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02270">http://arxiv.org/abs/2308.02270</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mousumi Akter, Shubhra Kanti Karmaker Santu<br>for: This paper aims to address the limitations of the existing automated evaluation metric ROUGE, which lacks semantic awareness and does not consider the ranking quality of the summarizer.methods: The authors propose a new metric called Sem-nCG, which is both rank and semantic aware, and demonstrate how it can be used to evaluate model summaries against multiple references. They also explore different ways of incorporating redundancy into the original metric through extensive experiments.results: The authors show that the new redundancy-aware metric exhibits a higher correlation with human judgments than the original Sem-nCG metric for both single and multiple reference scenarios.<details>
<summary>Abstract</summary>
While very popular for evaluating extractive summarization task, the ROUGE metric has long been criticized for its lack of semantic awareness and its ignorance about the ranking quality of the summarizer. Thanks to previous research that has addressed these issues by proposing a gain-based automated metric called Sem-nCG, which is both rank and semantic aware. However, Sem-nCG does not consider the amount of redundancy present in a model-generated summary and currently does not support evaluation with multiple reference summaries. Unfortunately, addressing both these limitations simultaneously is not trivial. Therefore, in this paper, we propose a redundancy-aware Sem-nCG metric and demonstrate how this new metric can be used to evaluate model summaries against multiple references. We also explore different ways of incorporating redundancy into the original metric through extensive experiments. Experimental results demonstrate that the new redundancy-aware metric exhibits a higher correlation with human judgments than the original Sem-nCG metric for both single and multiple reference scenarios.
</details>
<details>
<summary>摘要</summary>
While very popular for evaluating extractive summarization task, the ROUGE metric has long been criticized for its lack of semantic awareness and its ignorance about the ranking quality of the summarizer. Thanks to previous research that has addressed these issues by proposing a gain-based automated metric called Sem-nCG, which is both rank and semantic aware. However, Sem-nCG does not consider the amount of redundancy present in a model-generated summary and currently does not support evaluation with multiple reference summaries. Unfortunately, addressing both these limitations simultaneously is not trivial. Therefore, in this paper, we propose a redundancy-aware Sem-nCG metric and demonstrate how this new metric can be used to evaluate model summaries against multiple references. We also explore different ways of incorporating redundancy into the original metric through extensive experiments. Experimental results demonstrate that the new redundancy-aware metric exhibits a higher correlation with human judgments than the original Sem-nCG metric for both single and multiple reference scenarios.Here's the translation in Traditional Chinese:而ROUGE指数在抽取摘要任务评估中很受欢迎，但是它缺乏semantic awareness和排名质量的认识。过去的研究已经解决了这些问题，提出了一个名为Sem-nCG的增量自动评估指数，它同时具有排名和semantic awareness。然而，Sem-nCG不考虑模型生成的摘要中的重复度，现在也不支持多个参考摘要的评估。不幸的是，同时解决这两个限制是不单简的。因此，在这篇论文中，我们提出了一个具有重复度考虑的Sem-nCG指数，并评估这个新指数可以与多个参考摘要进行评估。我们还进行了各种将重复度纳入原始指数的实验。实验结果显示，新的重复度考虑指数与人类评价更高相关性比原始Sem-nCG指数更高，包括单一和多个参考摘要的情况下。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Monaural-Speech-Enhancement-using-Spectrum-Attention-Fusion"><a href="#Efficient-Monaural-Speech-Enhancement-using-Spectrum-Attention-Fusion" class="headerlink" title="Efficient Monaural Speech Enhancement using Spectrum Attention Fusion"></a>Efficient Monaural Speech Enhancement using Spectrum Attention Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02263">http://arxiv.org/abs/2308.02263</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinyu Long, Jetic Gū, Binhao Bai, Zhibo Yang, Ping Wei, Junli Li</li>
<li>for: 提高自动speech处理管道中的干净语音分离性能，使用Transformer模型，但是这些模型具有较高的计算成本和训练数据需求。</li>
<li>methods: 我们提出了一种改进speech增强模型，保留自注意的表达力，同时显著降低模型复杂度，我们称之为spectrum attention fusion。我们设计了一个 convolutional module，用于取代speech Transformer中的自注意层，以更有效地融合spectral特征。</li>
<li>results: 我们的提议模型在Voice Bank + DEMAND数据集上实现了相当或更好的结果，与SOTA模型相比，但具有较小的参数数量（0.58M）。<details>
<summary>Abstract</summary>
Speech enhancement is a demanding task in automated speech processing pipelines, focusing on separating clean speech from noisy channels. Transformer based models have recently bested RNN and CNN models in speech enhancement, however at the same time they are much more computationally expensive and require much more high quality training data, which is always hard to come by. In this paper, we present an improvement for speech enhancement models that maintains the expressiveness of self-attention while significantly reducing model complexity, which we have termed Spectrum Attention Fusion. We carefully construct a convolutional module to replace several self-attention layers in a speech Transformer, allowing the model to more efficiently fuse spectral features. Our proposed model is able to achieve comparable or better results against SOTA models but with significantly smaller parameters (0.58M) on the Voice Bank + DEMAND dataset.
</details>
<details>
<summary>摘要</summary>
《speech enhancement是自动化语音处理管道中的一项艰难任务，旨在从噪音损坏的通道中分离干净的语音。基于Transformer的模型在最近几年内在语音增强中表现出色，但同时它们也比RNN和CNN模型更加 computationally expensive和需要更多高质量的训练数据，这些数据往往很难得到。本文提出一种改进语音增强模型，保持了自我注意的表现力，同时显著减少模型复杂度，我们称之为Spectrum Attention Fusion。我们 méticulously construct了一个卷积模块，用于取代一些自我注意层，让模型更有效地融合频谱特征。我们的提议模型在Voice Bank + DEMAND dataset上可以 дости到与SOTA模型相当或更好的结果，但具有明显更小的参数（0.58M）。》Note that Simplified Chinese is a standardized form of Chinese that is used in mainland China and Singapore, and it is different from Traditional Chinese, which is used in Taiwan and other countries.
</details></li>
</ul>
<hr>
<h2 id="Sinhala-English-Parallel-Word-Dictionary-Dataset"><a href="#Sinhala-English-Parallel-Word-Dictionary-Dataset" class="headerlink" title="Sinhala-English Parallel Word Dictionary Dataset"></a>Sinhala-English Parallel Word Dictionary Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02234">http://arxiv.org/abs/2308.02234</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kasunw22/sinhala-para-dict">https://github.com/kasunw22/sinhala-para-dict</a></li>
<li>paper_authors: Kasun Wickramasinghe, Nisansa de Silva</li>
<li>for: 本研究的目的是为了提供三个平行的英语-斯里兰卡词典，以便在英语和斯里兰卡语言之间的多语言处理任务中使用。</li>
<li>methods: 本研究使用的方法包括创建词典 dataset 和进行相关的实验测试，以验证数据集的质量。</li>
<li>results: 本研究的实验结果表明，三个数据集均具有高质量和可靠性，可以用于英语和斯里兰卡语言之间的多语言处理任务。<details>
<summary>Abstract</summary>
Parallel datasets are vital for performing and evaluating any kind of multilingual task. However, in the cases where one of the considered language pairs is a low-resource language, the existing top-down parallel data such as corpora are lacking in both tally and quality due to the dearth of human annotation. Therefore, for low-resource languages, it is more feasible to move in the bottom-up direction where finer granular pairs such as dictionary datasets are developed first. They may then be used for mid-level tasks such as supervised multilingual word embedding alignment. These in turn can later guide higher-level tasks in the order of aligning sentence or paragraph text corpora used for Machine Translation (MT). Even though more approachable than generating and aligning a massive corpus for a low-resource language, for the same reason of apathy from larger research entities, even these finer granular data sets are lacking for some low-resource languages. We have observed that there is no free and open dictionary data set for the low-resource language, Sinhala. Thus, in this work, we introduce three parallel English-Sinhala word dictionaries (En-Si-dict-large, En-Si-dict-filtered, En-Si-dict-FastText) which help in multilingual Natural Language Processing (NLP) tasks related to English and Sinhala languages. In this paper, we explain the dataset creation pipeline as well as the experimental results of the tests we have carried out to verify the quality of the data sets. The data sets and the related scripts are available at https://github.com/kasunw22/sinhala-para-dict.
</details>
<details>
<summary>摘要</summary>
平行数据集是多语言任务的关键。然而，在考虑一个语言对的情况下，如低资源语言，现有的顶部向下的平行数据集，如文献，缺乏量和质量，因为缺乏人工标注。因此，对低资源语言来说，更可行在底部向上方向下进行，开发字典数据集。这些数据集可以用于中级任务，如监督多语言单词嵌入对齐。这些又可以用于更高级的任务，如对齐文本 corpora 用于机器翻译（MT）。虽然更可 accessible than generating and aligning massive corpus for a low-resource language， but even these finer granular data sets are lacking for some low-resource languages. We have observed that there is no free and open dictionary data set for the low-resource language, Sinhala. Therefore, in this work, we introduce three parallel English-Sinhala word dictionaries (En-Si-dict-large, En-Si-dict-filtered, En-Si-dict-FastText) which can be used in multilingual natural language processing tasks related to English and Sinhala languages. In this paper, we will explain the dataset creation pipeline as well as the experimental results of the tests we have carried out to verify the quality of the data sets. The data sets and the related scripts are available at https://github.com/kasunw22/sinhala-para-dict.
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Paraphrase-Sentences-to-Different-Complexity-Levels"><a href="#Learning-to-Paraphrase-Sentences-to-Different-Complexity-Levels" class="headerlink" title="Learning to Paraphrase Sentences to Different Complexity Levels"></a>Learning to Paraphrase Sentences to Different Complexity Levels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02226">http://arxiv.org/abs/2308.02226</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alisonhc/change-complexity">https://github.com/alisonhc/change-complexity</a></li>
<li>paper_authors: Alison Chi, Li-Kuang Chen, Yi-Chen Chang, Shu-Hui Lee, Jason S. Chang</li>
<li>for: 本研究的目的是提高同等级别的自然语言处理（NLP）模型的性能，特别是在 sentence simplification 领域。</li>
<li>methods: 本研究使用了两个新的无监督数据集，一个由弱类分类器标注，另一个由规则基本approach标注。这些数据集与一个单独的监督数据集进行比较。</li>
<li>results: 使用这些三个数据集进行训练，我们在 ASSET 简化数据集上实现了同等级别的最佳性能，并在 sentence level targeting  tasks 上超过了之前的成果。此外，我们还证明了一些大语言模型在这些任务上的零基础情况下的性能。<details>
<summary>Abstract</summary>
While sentence simplification is an active research topic in NLP, its adjacent tasks of sentence complexification and same-level paraphrasing are not. To train models on all three tasks, we present two new unsupervised datasets. We compare these datasets, one labeled by a weak classifier and the other by a rule-based approach, with a single supervised dataset. Using these three datasets for training, we perform extensive experiments on both multitasking and prompting strategies. Compared to other systems trained on unsupervised parallel data, models trained on our weak classifier labeled dataset achieve state-of-the-art performance on the ASSET simplification benchmark. Our models also outperform previous work on sentence level targeting. Finally, we establish how a handful of Large Language Models perform on these tasks under a zero-shot setting.
</details>
<details>
<summary>摘要</summary>
“对于句子简化是 aktive 的研究项目，但它的相邻任务，即句子复杂化和同等级重写，则未得到充分的研究。为了训练这三个任务，我们提出了两个新的无监督数据集。我们比较了这两个数据集，其中一个被轻量级分类器标注，另一个则使用规律化方法标注。使用这三个数据集进行训练，我们进行了广泛的实验，包括多任务训练和提示策略。相比其他基于无监督平行数据的系统，我们的模型在 ASSET 简化标准库上 achieve state-of-the-art 性能。我们的模型也超越了过去的句子级目标。最后，我们证明了一些大型自然语言模型在这些任务下的 zero-shot 性能。”
</details></li>
</ul>
<hr>
<h2 id="ESRL-Efficient-Sampling-based-Reinforcement-Learning-for-Sequence-Generation"><a href="#ESRL-Efficient-Sampling-based-Reinforcement-Learning-for-Sequence-Generation" class="headerlink" title="ESRL: Efficient Sampling-based Reinforcement Learning for Sequence Generation"></a>ESRL: Efficient Sampling-based Reinforcement Learning for Sequence Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02223">http://arxiv.org/abs/2308.02223</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenglong Wang, Hang Zhou, Yimin Hu, Yifu Huo, Bei Li, Tongran Liu, Tong Xiao, Jingbo Zhu</li>
<li>for: 这篇论文是关于应用强化学习（RL）来优化序列生成模型的，以直接优化长期奖励（例如 BLEU 和人工反馈）。</li>
<li>methods: 这篇论文提出了两种采样策略来改进RL训练序列生成模型的效率：两Stage采样和动态采样。</li>
<li>results: 实验结果表明，使用这两种采样策略可以在RL训练序列生成模型时提高效率和减少内存占用量。此外，RL从人类反馈（RLHF）训练大型自然语言模型，并评估了ESRL方法。实验结果表明，ESRL方法可以超越所有基eline，并在训练效率和内存占用量两个方面具有优异表现。<details>
<summary>Abstract</summary>
Applying Reinforcement Learning (RL) to sequence generation models enables the direct optimization of long-term rewards (\textit{e.g.,} BLEU and human feedback), but typically requires large-scale sampling over a space of action sequences. This is a computational challenge as presented by the practice of sequence generation problems, such as machine translation, where we often deal with a large action space (\textit{e.g.,} a vocabulary) and a long action sequence (\textit{e.g.,} a translation). In this work, we introduce two-stage sampling and dynamic sampling approaches to improve the sampling efficiency during training sequence generation models via RL. We experiment with our approaches on the traditional sequence generation tasks, including machine translation and abstractive summarization. Furthermore, we evaluate our approaches in RL from human feedback (RLHF) through training a large language model using the reward model. Experimental results show that the efficient sampling-based RL, referred to as ESRL, can outperform all baselines in terms of both training efficiency and memory consumption. Notably, ESRL yields consistent performance gains over the strong REINFORCE, minimum risk training, and proximal policy optimization methods.
</details>
<details>
<summary>摘要</summary>
使用强化学习（RL）对序列生成模型进行直接优化长期奖励（例如BLEU和人工反馈），通常需要大规模的样本扫描ACTION序列空间。这是一个计算挑战，如序列生成问题的实践所示，我们经常面临庞大的行动空间（例如词汇）和长行动序列（例如翻译）。在这种工作中，我们介绍了两个阶段采样和动态采样方法，以提高在RL训练序列生成模型的样本效率。我们在传统的序列生成任务中进行了实验，包括翻译和概括摘要。此外，我们通过训练大语言模型使用奖励模型进行RLHF来评估我们的方法。实验结果表明，能效采样基于RL（ESRL）可以超越所有基elines，包括强化算法、最小风险训练和距离政策优化方法。尤其是，ESRL在奖励模型训练中具有一致性的性能提升。
</details></li>
</ul>
<hr>
<h2 id="Emo-DNA-Emotion-Decoupling-and-Alignment-Learning-for-Cross-Corpus-Speech-Emotion-Recognition"><a href="#Emo-DNA-Emotion-Decoupling-and-Alignment-Learning-for-Cross-Corpus-Speech-Emotion-Recognition" class="headerlink" title="Emo-DNA: Emotion Decoupling and Alignment Learning for Cross-Corpus Speech Emotion Recognition"></a>Emo-DNA: Emotion Decoupling and Alignment Learning for Cross-Corpus Speech Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02190">http://arxiv.org/abs/2308.02190</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiaxin-ye/emo-dna">https://github.com/jiaxin-ye/emo-dna</a></li>
<li>paper_authors: Jiaxin Ye, Yujie Wei, Xin-Cheng Wen, Chenglong Ma, Zhizhong Huang, Kunhong Liu, Hongming Shan</li>
<li>for: 这篇论文旨在提高跨语料库情绪识别（SER）的普遍能力，从一个受标注的语料库中推导到另一个未标注的语料库中的情绪识别能力。</li>
<li>methods: 这篇论文提出了一个名为Emotion Decoupling aNd Alignment learning framework（EMO-DNA）的新方法，用于跨语料库SER。EMO-DNA包括两个新特点：对比情绪分离和双层情绪Alignment。</li>
<li>results: 实验结果显示，EMO-DNA在多个跨语料库情况下表现更好，较以前的方法。源代码可以在<a target="_blank" rel="noopener" href="https://github.com/Jiaxin-Ye/Emo-DNA%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/Jiaxin-Ye/Emo-DNA中找到。</a><details>
<summary>Abstract</summary>
Cross-corpus speech emotion recognition (SER) seeks to generalize the ability of inferring speech emotion from a well-labeled corpus to an unlabeled one, which is a rather challenging task due to the significant discrepancy between two corpora. Existing methods, typically based on unsupervised domain adaptation (UDA), struggle to learn corpus-invariant features by global distribution alignment, but unfortunately, the resulting features are mixed with corpus-specific features or not class-discriminative. To tackle these challenges, we propose a novel Emotion Decoupling aNd Alignment learning framework (EMO-DNA) for cross-corpus SER, a novel UDA method to learn emotion-relevant corpus-invariant features. The novelties of EMO-DNA are two-fold: contrastive emotion decoupling and dual-level emotion alignment. On one hand, our contrastive emotion decoupling achieves decoupling learning via a contrastive decoupling loss to strengthen the separability of emotion-relevant features from corpus-specific ones. On the other hand, our dual-level emotion alignment introduces an adaptive threshold pseudo-labeling to select confident target samples for class-level alignment, and performs corpus-level alignment to jointly guide model for learning class-discriminative corpus-invariant features across corpora. Extensive experimental results demonstrate the superior performance of EMO-DNA over the state-of-the-art methods in several cross-corpus scenarios. Source code is available at https://github.com/Jiaxin-Ye/Emo-DNA.
</details>
<details>
<summary>摘要</summary>
cross-corpus speech emotion recognition (SER) 目的是将极限对于一个具有良好标签的资料集进行推导，并将其扩展到另一个无标签的资料集，这是一个非常困难的任务，因为两个资料集之间存在很大的差异。现有的方法通常基于不监督领域适应（UDA），尝试从全球分布对顶点进行对顶点的对顶点适应，但是实际上，这些结果通常是混合了资料集特有的特征或不是类别特征。为了解决这些挑战，我们提出了一个名为Emotion Decoupling anD Alignment learning framework（EMO-DNA）的跨资料集 SER方法，并将其应用于不同的资料集之间。EMO-DNA的两大创新之处是：一是对应性抑制和二维度类别对顶点。在一方面，我们的对应性抑制通过一个对应抑制损失来强化感情相关的特征和资料集特有的特征之间的分离性。在另一方面，我们的二维度类别对顶点引入了一个可靠度预测 Pseudo-labeling，以选择信任度高的目标样本进行类别对顶点，并执行类别层对顶点进行协调，以帮助模型从多个资料集中学习类别特征。我们的实验结果显示，EMO-DNA在多个跨资料集情况下表现出色，较以往的方法有更好的性能。资料集和代码可以在https://github.com/Jiaxin-Ye/Emo-DNA 中找到。
</details></li>
</ul>
<hr>
<h2 id="From-Fake-to-Hyperpartisan-News-Detection-Using-Domain-Adaptation"><a href="#From-Fake-to-Hyperpartisan-News-Detection-Using-Domain-Adaptation" class="headerlink" title="From Fake to Hyperpartisan News Detection Using Domain Adaptation"></a>From Fake to Hyperpartisan News Detection Using Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02185">http://arxiv.org/abs/2308.02185</a></li>
<li>repo_url: None</li>
<li>paper_authors: Răzvan-Alexandru Smădu, Sebastian-Vasile Echim, Dumitru-Clementin Cercel, Iuliana Marin, Florin Pop</li>
<li>for: 这个研究探索了两个文本分类任务之间的页面转换，即伪新闻和超党新闻检测。研究实现了将伪新闻知识转换到超党新闻检测领域，不需要目标标签 durante 训练。</li>
<li>methods: 研究使用了不监督领域适应技术，包括UDA、教师Alignment和跨领域对比学习。</li>
<li>results: 实验结果显示这些技术可以提高性能，并且组合 clustering 和主题探索算法与 UDA 可以得到更好的结果。<details>
<summary>Abstract</summary>
Unsupervised Domain Adaptation (UDA) is a popular technique that aims to reduce the domain shift between two data distributions. It was successfully applied in computer vision and natural language processing. In the current work, we explore the effects of various unsupervised domain adaptation techniques between two text classification tasks: fake and hyperpartisan news detection. We investigate the knowledge transfer from fake to hyperpartisan news detection without involving target labels during training. Thus, we evaluate UDA, cluster alignment with a teacher, and cross-domain contrastive learning. Extensive experiments show that these techniques improve performance, while including data augmentation further enhances the results. In addition, we combine clustering and topic modeling algorithms with UDA, resulting in improved performances compared to the initial UDA setup.
</details>
<details>
<summary>摘要</summary>
不监督领域适应（Unsupervised Domain Adaptation，简称UDA）是一种常用的技术，旨在降低两个数据分布之间的领域偏移。它在计算机视觉和自然语言处理领域得到了成功应用。在当前工作中，我们探索了两种文本分类任务之间的无监督领域适应技术的效果：假新闻和激进政治新闻检测。我们不在训练过程中使用目标标签，而是通过知识传递来帮助学习。因此，我们评估了UDA、教师对齐和跨领域对比学习。广泛的实验表明，这些技术可以提高表现，并且包含数据增强更加提高结果。此外，我们将 clustering 和主题挖掘算法与 UDA 结合使用，从而获得了与初始 UDA 设置相比的更好的表现。
</details></li>
</ul>
<hr>
<h2 id="Scaling-Clinical-Trial-Matching-Using-Large-Language-Models-A-Case-Study-in-Oncology"><a href="#Scaling-Clinical-Trial-Matching-Using-Large-Language-Models-A-Case-Study-in-Oncology" class="headerlink" title="Scaling Clinical Trial Matching Using Large Language Models: A Case Study in Oncology"></a>Scaling Clinical Trial Matching Using Large Language Models: A Case Study in Oncology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02180">http://arxiv.org/abs/2308.02180</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cliff Wong, Sheng Zhang, Yu Gu, Christine Moung, Jacob Abel, Naoto Usuyama, Roshanthi Weerasinghe, Brian Piening, Tristan Naumann, Carlo Bifulco, Hoifung Poon</li>
<li>for: 这个论文旨在探讨如何使用大语言模型（LLM）扩大临床试验匹配。</li>
<li>methods: 这个研究使用了大语言模型（GPT-4）进行结构化临床试验评估和复杂匹配逻辑抽取（例如，嵌套的AND&#x2F;OR&#x2F;NOT）。</li>
<li>results: 初步结果表明，使用LLM可以大幅提高匹配效果，虽然还有一些不足之处，但可以作为人工审核的准备。此外，研究还发现了应用LLM到终端临床试验匹配中的一些重要发展方向，例如Context Limitation和准确性，特别是从患者 longitudinal医疗记录中提取patient信息。<details>
<summary>Abstract</summary>
Clinical trial matching is a key process in health delivery and discovery. In practice, it is plagued by overwhelming unstructured data and unscalable manual processing. In this paper, we conduct a systematic study on scaling clinical trial matching using large language models (LLMs), with oncology as the focus area. Our study is grounded in a clinical trial matching system currently in test deployment at a large U.S. health network. Initial findings are promising: out of box, cutting-edge LLMs, such as GPT-4, can already structure elaborate eligibility criteria of clinical trials and extract complex matching logic (e.g., nested AND/OR/NOT). While still far from perfect, LLMs substantially outperform prior strong baselines and may serve as a preliminary solution to help triage patient-trial candidates with humans in the loop. Our study also reveals a few significant growth areas for applying LLMs to end-to-end clinical trial matching, such as context limitation and accuracy, especially in structuring patient information from longitudinal medical records.
</details>
<details>
<summary>摘要</summary>
临床试验匹配是健康提供和发现的关键过程。在实践中，它受到过载的未结构化数据和不可扩展的手动处理的困扰。在这篇论文中，我们进行了系统性的研究，使用大语言模型（LLMs）扩大临床试验匹配，以肿瘤学为研究领域。我们的研究基于一个在大型美国医疗网络中测试的临床试验匹配系统。初步发现结果非常有 promise：直接使用最新的GPT-4等高级语言模型，可以立即结构化临床试验资格的复杂逻辑（例如，嵌入AND/OR/NOT）。虽然仍然很过不完美，但LLMs在比较强的基准模型之上显著超越，并可能作为人工协助的初步解决方案。我们的研究还揭示了应用LLMs到终端临床试验匹配中的一些重要成长领域，如CONTEXT限制和准确率，特别是从悠久医疗记录中结构化病人信息。
</details></li>
</ul>
<hr>
<h2 id="You-talk-what-you-read-Understanding-News-Comment-Behavior-by-Dispositional-and-Situational-Attribution"><a href="#You-talk-what-you-read-Understanding-News-Comment-Behavior-by-Dispositional-and-Situational-Attribution" class="headerlink" title="You talk what you read: Understanding News Comment Behavior by Dispositional and Situational Attribution"></a>You talk what you read: Understanding News Comment Behavior by Dispositional and Situational Attribution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02168">http://arxiv.org/abs/2308.02168</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhang Wang, Yuxiang Zhang, Dongyuan Lu, Jitao Sang</li>
<li>for: 理解新闻评论行为</li>
<li>methods: 提出三部encoder-decoder框架，考虑新闻交互历史中的个性特征和相应新闻的情况因素</li>
<li>results: 可以更好地理解用户的注意点和意见，并在新闻摘要和新闻方面观点预测等应用中得到验证<details>
<summary>Abstract</summary>
Many news comment mining studies are based on the assumption that comment is explicitly linked to the corresponding news. In this paper, we observed that users' comments are also heavily influenced by their individual characteristics embodied by the interaction history. Therefore, we position to understand news comment behavior by considering both the dispositional factors from news interaction history, and the situational factors from corresponding news. A three-part encoder-decoder framework is proposed to model the generative process of news comment. The resultant dispositional and situational attribution contributes to understanding user focus and opinions, which are validated in applications of reader-aware news summarization and news aspect-opinion forecasting.
</details>
<details>
<summary>摘要</summary>
许多新闻评论研究假设评论直接关联新闻。在这篇论文中，我们发现用户的评论也受到其个人特征所 Embodied 的交互历史影响。因此，我们提议通过考虑新闻交互历史中的个性特征和相关新闻的情况因素，来理解新闻评论行为。我们建议使用三部分encoder-decoder框架来模型新闻评论生成过程。结果的个性和情况因素各自贡献于理解用户注意力和意见，这些结果在新闻摘要和新闻方面观点预测等应用中得到验证。
</details></li>
</ul>
<hr>
<h2 id="Speaker-Diarization-of-Scripted-Audiovisual-Content"><a href="#Speaker-Diarization-of-Scripted-Audiovisual-Content" class="headerlink" title="Speaker Diarization of Scripted Audiovisual Content"></a>Speaker Diarization of Scripted Audiovisual Content</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02160">http://arxiv.org/abs/2308.02160</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yogesh Virkar, Brian Thompson, Rohit Paturi, Sundararajan Srinivasan, Marcello Federico</li>
<li>for: 媒体地方化业界通常需要一份 verbatim 脚本来创建外语字幕或配音脚本。特别是 verbatim 脚本（即播放版本）必须按照一定的结构，分为对话字串，每个字串包含时间码、说话人名称和脚本。现有的语音识别技术可以减少转cription步骤。但是，现有的话者分类模型仍然无法在电视节目中追踪大量的说话人，并且在说话人频繁变化时的准确性较低。</li>
<li>methods: 为了解决这个问题，我们提出了一种新的方法，利用摄制 Script 来提取 Pseudo-labeled 数据，供话者分类任务使用。我们提出了一种新的半监督方法，并在我们的 Metrics 上与两个没有监督的基底模型进行比较，获得了51.7%的改善。</li>
<li>results: 我们在66集节目测试集上进行了评估，结果显示，我们的方法在我们的 Metrics 上与两个没有监督的基底模型相比，获得了51.7%的改善。<details>
<summary>Abstract</summary>
The media localization industry usually requires a verbatim script of the final film or TV production in order to create subtitles or dubbing scripts in a foreign language. In particular, the verbatim script (i.e. as-broadcast script) must be structured into a sequence of dialogue lines each including time codes, speaker name and transcript. Current speech recognition technology alleviates the transcription step. However, state-of-the-art speaker diarization models still fall short on TV shows for two main reasons: (i) their inability to track a large number of speakers, (ii) their low accuracy in detecting frequent speaker changes. To mitigate this problem, we present a novel approach to leverage production scripts used during the shooting process, to extract pseudo-labeled data for the speaker diarization task. We propose a novel semi-supervised approach and demonstrate improvements of 51.7% relative to two unsupervised baseline models on our metrics on a 66 show test set.
</details>
<details>
<summary>摘要</summary>
媒体地方化业务通常需要最终电影或电视制作的准确脚本，以创建外语字幕或配音脚本。特别是，准确脚本（即播送脚本）必须按照时间代码、发言人名称和字幕进行结构。当前的语音识别技术可以减轻转录步骤。然而，当前的说话人分类模型仍然在电视节目上存在两个主要问题：（1）它们无法跟踪大量的说话人，（2）它们在发生频繁的说话人变换时低准确。为解决这个问题，我们提出了一种新的方法，利用制作过程中使用的制作脚本，提取 pseudo-标注数据来进行说话人分类任务。我们提出了一种新的半监督方法，并在66集测试集上示出了51.7%的提升相对于两个无监督基线模型。
</details></li>
</ul>
<hr>
<h2 id="Capturing-Spectral-and-Long-term-Contextual-Information-for-Speech-Emotion-Recognition-Using-Deep-Learning-Techniques"><a href="#Capturing-Spectral-and-Long-term-Contextual-Information-for-Speech-Emotion-Recognition-Using-Deep-Learning-Techniques" class="headerlink" title="Capturing Spectral and Long-term Contextual Information for Speech Emotion Recognition Using Deep Learning Techniques"></a>Capturing Spectral and Long-term Contextual Information for Speech Emotion Recognition Using Deep Learning Techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04517">http://arxiv.org/abs/2308.04517</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samiul Islam, Md. Maksudul Haque, Abu Jobayer Md. Sadat</li>
<li>for: 这个研究旨在提高语音感情识别的精度，并解决传统方法的缺陷，如难以捕捉语音序列数据中的长期依赖关系和时间动态。</li>
<li>methods: 该研究提出了一种ensemble模型，其组合了文本数据处理GCN和音频信号分析 HuBERT。GCN excellence于捕捉文本数据中的长期Contextual依赖关系，而HuBERT利用自注意机制来捕捉语音序列数据中的长期依赖关系，从而提高情感识别的准确性。</li>
<li>results: 结果表明，该ensemble模型可以超越传统方法的限制，实现更高的情感识别精度。<details>
<summary>Abstract</summary>
Traditional approaches in speech emotion recognition, such as LSTM, CNN, RNN, SVM, and MLP, have limitations such as difficulty capturing long-term dependencies in sequential data, capturing the temporal dynamics, and struggling to capture complex patterns and relationships in multimodal data. This research addresses these shortcomings by proposing an ensemble model that combines Graph Convolutional Networks (GCN) for processing textual data and the HuBERT transformer for analyzing audio signals. We found that GCNs excel at capturing Long-term contextual dependencies and relationships within textual data by leveraging graph-based representations of text and thus detecting the contextual meaning and semantic relationships between words. On the other hand, HuBERT utilizes self-attention mechanisms to capture long-range dependencies, enabling the modeling of temporal dynamics present in speech and capturing subtle nuances and variations that contribute to emotion recognition. By combining GCN and HuBERT, our ensemble model can leverage the strengths of both approaches. This allows for the simultaneous analysis of multimodal data, and the fusion of these modalities enables the extraction of complementary information, enhancing the discriminative power of the emotion recognition system. The results indicate that the combined model can overcome the limitations of traditional methods, leading to enhanced accuracy in recognizing emotions from speech.
</details>
<details>
<summary>摘要</summary>
传统方法在语音情绪识别方面，如LSTM、CNN、RNN、SVM和MLP，具有缺点，如难以捕捉语音序列数据中长期依赖关系、模式和复杂的关系。本研究提出一个 ensemble 模型，将文本数据处理用 Graph Convolutional Networks (GCN)， audio 信号分析用 HuBERT 变换器。我们发现GCNs可以很好地捕捉文本数据中长期上下文关系和Semantic relationships между字符，而 HuBERT 利用自我注意机制，可以捕捉语音中的长期关系，捕捉语音中的时间动态和细节，从而提高情绪识别的准确率。通过将 GCN 和 HuBERT  ensemble，我们可以利用这两种方法的优点。这使得同时分析多 modal 数据，并将这些模式结合，从而提高情绪识别系统的推断力。结果表明，组合模型可以超越传统方法的局限性，实现更高的情绪识别精度。
</details></li>
</ul>
<hr>
<h2 id="Tweet-Insights-A-Visualization-Platform-to-Extract-Temporal-Insights-from-Twitter"><a href="#Tweet-Insights-A-Visualization-Platform-to-Extract-Temporal-Insights-from-Twitter" class="headerlink" title="Tweet Insights: A Visualization Platform to Extract Temporal Insights from Twitter"></a>Tweet Insights: A Visualization Platform to Extract Temporal Insights from Twitter</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02142">http://arxiv.org/abs/2308.02142</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Loureiro, Kiamehr Rezaee, Talayeh Riahi, Francesco Barbieri, Leonardo Neves, Luis Espinosa Anke, Jose Camacho-Collados</li>
<li>for: 这篇论文旨在提供一个大量的时间序列数据集，来自Twitter，经过word embedding技术处理，以及特殊的精通语言模型进行特化。</li>
<li>methods: 这个数据集包含过去五年的时间序列数据，捕捉了n-gram频率、相似性、情感和主题分布的变化。</li>
<li>results: 这个数据集可以用于探索和 caracterize 语言的时间变化，包括补充的信息，如情感和主题关系的时间变化。<details>
<summary>Abstract</summary>
This paper introduces a large collection of time series data derived from Twitter, postprocessed using word embedding techniques, as well as specialized fine-tuned language models. This data comprises the past five years and captures changes in n-gram frequency, similarity, sentiment and topic distribution. The interface built on top of this data enables temporal analysis for detecting and characterizing shifts in meaning, including complementary information to trending metrics, such as sentiment and topic association over time. We release an online demo for easy experimentation, and we share code and the underlying aggregated data for future work. In this paper, we also discuss three case studies unlocked thanks to our platform, showcasing its potential for temporal linguistic analysis.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ParaFuzz-An-Interpretability-Driven-Technique-for-Detecting-Poisoned-Samples-in-NLP"><a href="#ParaFuzz-An-Interpretability-Driven-Technique-for-Detecting-Poisoned-Samples-in-NLP" class="headerlink" title="ParaFuzz: An Interpretability-Driven Technique for Detecting Poisoned Samples in NLP"></a>ParaFuzz: An Interpretability-Driven Technique for Detecting Poisoned Samples in NLP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02122">http://arxiv.org/abs/2308.02122</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lu Yan, Zhuo Zhang, Guanhong Tao, Kaiyuan Zhang, Xuan Chen, Guangyu Shen, Xiangyu Zhang</li>
<li>for: 防止自然语言处理（NLP）模型受到恶意攻击，特别是针对词性攻击。</li>
<li>methods: 基于模型预测结果的解释性，提出一种在运行时检测毒素样本的框架。使用ChatGPT进行重塑，并采用抖抖技术来找到最佳重塑提示，以消除词性攻击。</li>
<li>results: 对4种类型的后门攻击和4个不同的数据集进行实验，与基线方法（STRIP、RAP、ONION）相比，提出的方法在精度和准确性方面表现出色。<details>
<summary>Abstract</summary>
Backdoor attacks have emerged as a prominent threat to natural language processing (NLP) models, where the presence of specific triggers in the input can lead poisoned models to misclassify these inputs to predetermined target classes. Current detection mechanisms are limited by their inability to address more covert backdoor strategies, such as style-based attacks. In this work, we propose an innovative test-time poisoned sample detection framework that hinges on the interpretability of model predictions, grounded in the semantic meaning of inputs. We contend that triggers (e.g., infrequent words) are not supposed to fundamentally alter the underlying semantic meanings of poisoned samples as they want to stay stealthy. Based on this observation, we hypothesize that while the model's predictions for paraphrased clean samples should remain stable, predictions for poisoned samples should revert to their true labels upon the mutations applied to triggers during the paraphrasing process. We employ ChatGPT, a state-of-the-art large language model, as our paraphraser and formulate the trigger-removal task as a prompt engineering problem. We adopt fuzzing, a technique commonly used for unearthing software vulnerabilities, to discover optimal paraphrase prompts that can effectively eliminate triggers while concurrently maintaining input semantics. Experiments on 4 types of backdoor attacks, including the subtle style backdoors, and 4 distinct datasets demonstrate that our approach surpasses baseline methods, including STRIP, RAP, and ONION, in precision and recall.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXT黑客攻击已经成为自然语言处理（NLP）模型的主要威胁，特定的触发器在输入中存在可以让毒化模型错分这些输入为预先确定的目标类。现有的检测机制受限于其无法处理更加潜在的黑客攻击策略，如样式基本攻击。在这项工作中，我们提出了一种创新的测试时毒化样本检测框架，基于模型预测的可读性，围绕输入的含义。我们认为触发器（如罕见词）不应该fundamentally改变毒化样本中的含义，因为他们想要保持隐蔽。基于这一观察，我们提出了一个假设：如果在重新排序和修改触发器时，模型对涂改后的毒化样本的预测结果应该回归到其真实标签。我们使用ChatGPT，一种现代大语言模型，来实现重新排序和修改触发器的任务，并将此任务定义为提示工程问题。我们采用了混淆，一种通常用于发现软件漏洞的技术，来找到最佳的提示问题，以有效地除去触发器而同时保持输入含义。在4种黑客攻击和4个不同的数据集上，我们的方法比基准方法（包括STRIP、RAP和ONION）在准确率和敏感率方面表现出色。
</details></li>
</ul>
<hr>
<h2 id="Chinese-Financial-Text-Emotion-Mining-GCGTS-–-A-Character-Relationship-based-Approach-for-Simultaneous-Aspect-Opinion-Pair-Extraction"><a href="#Chinese-Financial-Text-Emotion-Mining-GCGTS-–-A-Character-Relationship-based-Approach-for-Simultaneous-Aspect-Opinion-Pair-Extraction" class="headerlink" title="Chinese Financial Text Emotion Mining: GCGTS – A Character Relationship-based Approach for Simultaneous Aspect-Opinion Pair Extraction"></a>Chinese Financial Text Emotion Mining: GCGTS – A Character Relationship-based Approach for Simultaneous Aspect-Opinion Pair Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02113">http://arxiv.org/abs/2308.02113</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qi Chen, Dexi Liu</li>
<li>for: 本研究旨在提高中文金融文本中 Aspect-Opinion Pair Extraction (AOPE) 的精度，提出一种基于图像 convolutional 网络的 Character-level Grid Tagging Scheme (GCGTS) 方法。</li>
<li>methods: 本研究使用了 Graph Convolutional Networks (GCN) 和图像 convolutional 结构，以及一种新的 grid tagging scheme，将 caracter-level 特征编码与语言模型结合，提高了模型对中文金融文本的表达能力。</li>
<li>results: 对比先前的 SDRN 和 GTS 模型，提出的 GCGTS 模型在中文金融文本中的表达能力显著提高，提供了一种新的和有效的 AOPE 方法。<details>
<summary>Abstract</summary>
Aspect-Opinion Pair Extraction (AOPE) from Chinese financial texts is a specialized task in fine-grained text sentiment analysis. The main objective is to extract aspect terms and opinion terms simultaneously from a diverse range of financial texts. Previous studies have mainly focused on developing grid annotation schemes within grid-based models to facilitate this extraction process. However, these methods often rely on character-level (token-level) feature encoding, which may overlook the logical relationships between Chinese characters within words. To address this limitation, we propose a novel method called Graph-based Character-level Grid Tagging Scheme (GCGTS). The GCGTS method explicitly incorporates syntactic structure using Graph Convolutional Networks (GCN) and unifies the encoding of characters within the same syntactic semantic unit (Chinese word level). Additionally, we introduce an image convolutional structure into the grid model to better capture the local relationships between characters within evaluation units. This innovative structure reduces the excessive reliance on pre-trained language models and emphasizes the modeling of structure and local relationships, thereby improving the performance of the model on Chinese financial texts. Through comparative experiments with advanced models such as Synchronous Double-channel Recurrent Network (SDRN) and Grid Tagging Scheme (GTS), the proposed GCGTS model demonstrates significant improvements in performance.
</details>
<details>
<summary>摘要</summary>
《评价分析》从中文金融文本中提取方面评价对（AOPE）是一种特殊的精细文本情感分析任务。主要目标是同时提取方面 термина和评价 термина从多样化的金融文本中。先前的研究主要集中在开发格式化标注方案，以便进行这种提取过程。然而，这些方法通常依赖于字符级别（token级别）的特征编码，可能会忽略中文字符在单词水平上的逻辑关系。为了解决这一限制，我们提出了一种新的方法——基于图学推理的字符级别Grid Tagging Scheme（GCGTS）。GCGTS方法会将中文字符在单词水平上的逻辑关系进行Explicit地表示，并通过图学推理来强化字符级别的编码。此外，我们还引入了图像推理结构，以更好地捕捉单词水平上的本地关系。这种创新的结构可以减少依赖于预训练语言模型的过度依赖，并强调结构和本地关系的模型化，从而提高中文金融文本上的模型性能。通过与高级模型如同步双通道循环网络（SDRN）和Grid Tagging Scheme（GTS）进行比较实验，我们的提出的GCGTS模型在中文金融文本上表现出了显著的改善。
</details></li>
</ul>
<hr>
<h2 id="Prompt2Gaussia-Uncertain-Prompt-learning-for-Script-Event-Prediction"><a href="#Prompt2Gaussia-Uncertain-Prompt-learning-for-Script-Event-Prediction" class="headerlink" title="Prompt2Gaussia: Uncertain Prompt-learning for Script Event Prediction"></a>Prompt2Gaussia: Uncertain Prompt-learning for Script Event Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02103">http://arxiv.org/abs/2308.02103</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiyao Cui, Xin Cong, Jiawei Sheng, Xuebin Wang, Tingwen Liu, Jinqiao Shi</li>
<li>for: 预测事件序列中下一个事件（Event Sequence Prediction）</li>
<li>methods: 使用公共预训练语言模型作为知识库，自动挖掘脚本相关知识via prompt-学习，并使用 Gaussian Distribution 表示不确定性</li>
<li>results: 比 Priors 基eline 高1.46%和1.05% 在两个benchmark上，表现出优于先前的方法<details>
<summary>Abstract</summary>
Script Event Prediction (SEP) aims to predict the subsequent event for a given event chain from a candidate list. Prior research has achieved great success by integrating external knowledge to enhance the semantics, but it is laborious to acquisite the appropriate knowledge resources and retrieve the script-related knowledge. In this paper, we regard public pre-trained language models as knowledge bases and automatically mine the script-related knowledge via prompt-learning. Still, the scenario-diversity and label-ambiguity in scripts make it uncertain to construct the most functional prompt and label token in prompt learning, i.e., prompt-uncertainty and verbalizer-uncertainty. Considering the innate ability of Gaussian distribution to express uncertainty, we deploy the prompt tokens and label tokens as random variables following Gaussian distributions, where a prompt estimator and a verbalizer estimator are proposed to estimate their probabilistic representations instead of deterministic representations. We take the lead to explore prompt-learning in SEP and provide a fresh perspective to enrich the script semantics. Our method is evaluated on the most widely used benchmark and a newly proposed large-scale one. Experiments show that our method, which benefits from knowledge evoked from pre-trained language models, outperforms prior baselines by 1.46\% and 1.05\% on two benchmarks, respectively.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Causality-Guided-Disentanglement-for-Cross-Platform-Hate-Speech-Detection"><a href="#Causality-Guided-Disentanglement-for-Cross-Platform-Hate-Speech-Detection" class="headerlink" title="Causality Guided Disentanglement for Cross-Platform Hate Speech Detection"></a>Causality Guided Disentanglement for Cross-Platform Hate Speech Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02080">http://arxiv.org/abs/2308.02080</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/paras2612/catch">https://github.com/paras2612/catch</a></li>
<li>paper_authors: Paras Sheth, Tharindu Kumarage, Raha Moraffah, Aman Chadha, Huan Liu</li>
<li>for: 这种研究是为了开发一种可以在多个不同平台上进行仇恨言论检测的模型。</li>
<li>methods: 这种模型使用了分离输入表示的方法，将输入表示分解为不同平台的特有特征和共通特征。此外，该模型还学习了 causal 关系，以帮助理解普适表示。</li>
<li>results: 根据实验结果，这种模型在四个不同平台上的检测仇恨言论效果比现有的状态态方法更高。<details>
<summary>Abstract</summary>
Social media platforms, despite their value in promoting open discourse, are often exploited to spread harmful content. Current deep learning and natural language processing models used for detecting this harmful content overly rely on domain-specific terms affecting their capabilities to adapt to generalizable hate speech detection. This is because they tend to focus too narrowly on particular linguistic signals or the use of certain categories of words. Another significant challenge arises when platforms lack high-quality annotated data for training, leading to a need for cross-platform models that can adapt to different distribution shifts. Our research introduces a cross-platform hate speech detection model capable of being trained on one platform's data and generalizing to multiple unseen platforms. To achieve good generalizability across platforms, one way is to disentangle the input representations into invariant and platform-dependent features. We also argue that learning causal relationships, which remain constant across diverse environments, can significantly aid in understanding invariant representations in hate speech. By disentangling input into platform-dependent features (useful for predicting hate targets) and platform-independent features (used to predict the presence of hate), we learn invariant representations resistant to distribution shifts. These features are then used to predict hate speech across unseen platforms. Our extensive experiments across four platforms highlight our model's enhanced efficacy compared to existing state-of-the-art methods in detecting generalized hate speech.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Seasonality-Based-Reranking-of-E-commerce-Autocomplete-Using-Natural-Language-Queries"><a href="#Seasonality-Based-Reranking-of-E-commerce-Autocomplete-Using-Natural-Language-Queries" class="headerlink" title="Seasonality Based Reranking of E-commerce Autocomplete Using Natural Language Queries"></a>Seasonality Based Reranking of E-commerce Autocomplete Using Natural Language Queries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02055">http://arxiv.org/abs/2308.02055</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prateek Verma, Shan Zhong, Xiaoyu Liu, Adithya Rajan</li>
<li>for: 这篇论文主要是为了提出一种基于神经网络的自然语言处理算法，用于吸收季节性信号并提高搜索框架中的自动完成功能。</li>
<li>methods: 这篇论文使用了神经网络算法来捕捉季节性信号，并将其integrated into自动完成排名模型中。</li>
<li>results: 研究发现，通过 incorporating 季节性信号，自动完成排名模型可以提高搜索结果的相关性和商业指标。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Query autocomplete (QAC) also known as typeahead, suggests list of complete queries as user types prefix in the search box. It is one of the key features of modern search engines specially in e-commerce. One of the goals of typeahead is to suggest relevant queries to users which are seasonally important. In this paper we propose a neural network based natural language processing (NLP) algorithm to incorporate seasonality as a signal and present end to end evaluation of the QAC ranking model. Incorporating seasonality into autocomplete ranking model can improve autocomplete relevance and business metric.
</details>
<details>
<summary>摘要</summary>
查询自动完成（QAC）也称为前缀提示，是现代搜索引擎的一个关键特性，尤其在电商领域。QAC的一个目标是向用户提供相关的查询，以便在各个季节中提高搜索结果的相关性。在这篇论文中，我们提议一种基于神经网络的自然语言处理（NLP）算法，以兼容季节信号并提供综合评估QAC排名模型的终端评估。在搜索结果中包含季节信号可以提高搜索结果的相关性和业务指标。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Sentiment-Analysis-A-Resource-Aware-Evaluation-of-Feature-Extraction-Techniques-Ensembling-and-Deep-Learning-Models"><a href="#Efficient-Sentiment-Analysis-A-Resource-Aware-Evaluation-of-Feature-Extraction-Techniques-Ensembling-and-Deep-Learning-Models" class="headerlink" title="Efficient Sentiment Analysis: A Resource-Aware Evaluation of Feature Extraction Techniques, Ensembling, and Deep Learning Models"></a>Efficient Sentiment Analysis: A Resource-Aware Evaluation of Feature Extraction Techniques, Ensembling, and Deep Learning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02022">http://arxiv.org/abs/2308.02022</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahammed Kamruzzaman, Gene Louis Kim</li>
<li>for: 这 paper 是为了评估文档级别的情感分析模型，并考虑了资源成本的影响。</li>
<li>methods: 这 paper 使用了不同的特征提取技术、集成、任务专门的深度学习模型和领域独立的大语言模型。</li>
<li>results: 研究发现，精度最佳化的大语言模型可以达到最高的准确率，但有些配置可以提供巨大（最多24,283*)的资源减少，只带来少量（&lt;1%）的减少。此外，对于较小的数据集，准确率之间的差异减小，而资源消耗差异增加。<details>
<summary>Abstract</summary>
While reaching for NLP systems that maximize accuracy, other important metrics of system performance are often overlooked. Prior models are easily forgotten despite their possible suitability in settings where large computing resources are unavailable or relatively more costly. In this paper, we perform a broad comparative evaluation of document-level sentiment analysis models with a focus on resource costs that are important for the feasibility of model deployment and general climate consciousness. Our experiments consider different feature extraction techniques, the effect of ensembling, task-specific deep learning modeling, and domain-independent large language models (LLMs). We find that while a fine-tuned LLM achieves the best accuracy, some alternate configurations provide huge (up to 24, 283 *) resource savings for a marginal (<1%) loss in accuracy. Furthermore, we find that for smaller datasets, the differences in accuracy shrink while the difference in resource consumption grows further.
</details>
<details>
<summary>摘要</summary>
While striving for NLP systems with maximum accuracy, other important metrics of system performance are often overlooked. Prior models may be suitable in settings where large computing resources are scarce or relatively more costly, but are often forgotten. In this paper, we conduct a comprehensive comparative evaluation of document-level sentiment analysis models, with a focus on resource costs that are crucial for the feasibility of model deployment and general climate consciousness. Our experiments cover different feature extraction techniques, the effect of ensembling, task-specific deep learning modeling, and domain-independent large language models (LLMs). We find that while a fine-tuned LLM achieves the best accuracy, some alternative configurations can provide significant (up to 24,283 *) resource savings for a minor (<1%) loss in accuracy. Moreover, we find that for smaller datasets, the differences in accuracy shrink while the difference in resource consumption grows further.Note: * indicates a number in Chinese characters.
</details></li>
</ul>
<hr>
<h2 id="Baby-Llama-knowledge-distillation-from-an-ensemble-of-teachers-trained-on-a-small-dataset-with-no-performance-penalty"><a href="#Baby-Llama-knowledge-distillation-from-an-ensemble-of-teachers-trained-on-a-small-dataset-with-no-performance-penalty" class="headerlink" title="Baby Llama: knowledge distillation from an ensemble of teachers trained on a small dataset with no performance penalty"></a>Baby Llama: knowledge distillation from an ensemble of teachers trained on a small dataset with no performance penalty</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02019">http://arxiv.org/abs/2308.02019</a></li>
<li>repo_url: None</li>
<li>paper_authors: Inar Timiryasov, Jean-Loup Tastet</li>
<li>for: 提高语言模型的样本效率</li>
<li>methods: 使用 ensemble 和 distillation 技术</li>
<li>results:  exceeds 两个教师模型的性能，并且比不使用 distillation 的模型更好Here’s a breakdown of each point:</li>
<li>for: The paper is written to improve the sample efficiency of language models.</li>
<li>methods: The paper uses an ensemble of a GPT-2 and small LLaMA models, as well as distillation techniques.</li>
<li>results: The distilled LLaMA model exceeds the performance of both of its teachers and a similar model trained without distillation.<details>
<summary>Abstract</summary>
We present our proposed solution to the BabyLM challenge [arXiv:2301.11796], whose goal was to improve the sample efficiency of language models. We trained an ensemble consisting of a GPT-2 and small LLaMA models on the developmentally-plausible, 10M-word BabyLM dataset, then distilled it into a small, 58M-parameter LLaMA model, which exceeds in performance both of its teachers as well as a similar model trained without distillation. This suggests that distillation can not only retain the full performance of the teacher model when the latter is trained on a sufficiently small dataset; it can exceed it, and lead to significantly better performance than direct training.
</details>
<details>
<summary>摘要</summary>
我们提出了一种解决方案来提高语言模型的样本效率挑战（arXiv:2301.11796）。我们使用一个GPT-2和一些小型LLaMA模型在发展可能的10M字 BabyLM数据集上进行训练，然后将其浓缩为一个小型，58M参数的LLaMA模型，该模型超越了它的两位教师以及不使用浓缩的相似模型。这表明，浓缩不仅可以保持教师模型在较小数据集上的完整性，而且可以超越它，并导致直接训练的性能明显更好。
</details></li>
</ul>
<hr>
<h2 id="Federated-Representation-Learning-for-Automatic-Speech-Recognition"><a href="#Federated-Representation-Learning-for-Automatic-Speech-Recognition" class="headerlink" title="Federated Representation Learning for Automatic Speech Recognition"></a>Federated Representation Learning for Automatic Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02013">http://arxiv.org/abs/2308.02013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guruprasad V Ramesh, Gopinath Chennupati, Milind Rao, Anit Kumar Sahu, Ariya Rastrow, Jasha Droppo</li>
<li>for: This paper is written for learning Automatic Speech Recognition (ASR) representations while preserving data privacy using Federated Learning (FL) and Self-supervised Learning (SSL).</li>
<li>methods: The paper uses the Contrastive Predictive Coding framework with FedSGD to pre-train an LSTM encoder on unlabeled speech data from Libri-Light, simulating non-IID speaker-siloed data distributions.</li>
<li>results: The pre-trained ASR encoder in FL performs as well as a centrally pre-trained model and produces an improvement of 12-15% (WER) compared to no pre-training. The federated pre-trained models are also adapted to a new language, French, and show a 20% (WER) improvement over no pre-training.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文是用于在保护数据隐私的情况下学习自动语音识别（ASR）表示的。</li>
<li>methods: 论文使用了Contrastive Predictive Coding框架和FedSGD来预训一个LSTM编码器，使用Libri-Light中的无标签语音数据，模拟非相关 speaker-siloed 数据分布。</li>
<li>results: 预训ASR编码器在FL中表现与中央预训模型一样好，与没有预训相比提高12-15%（WER）。此外，使用了 Federated 预训模型，在新语言法语言中进行了20%（WER）的提高。<details>
<summary>Abstract</summary>
Federated Learning (FL) is a privacy-preserving paradigm, allowing edge devices to learn collaboratively without sharing data. Edge devices like Alexa and Siri are prospective sources of unlabeled audio data that can be tapped to learn robust audio representations. In this work, we bring Self-supervised Learning (SSL) and FL together to learn representations for Automatic Speech Recognition respecting data privacy constraints. We use the speaker and chapter information in the unlabeled speech dataset, Libri-Light, to simulate non-IID speaker-siloed data distributions and pre-train an LSTM encoder with the Contrastive Predictive Coding framework with FedSGD. We show that the pre-trained ASR encoder in FL performs as well as a centrally pre-trained model and produces an improvement of 12-15% (WER) compared to no pre-training. We further adapt the federated pre-trained models to a new language, French, and show a 20% (WER) improvement over no pre-training.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 是一种隐私保护的思想，允许边缘设备学习共同无需分享数据。边缘设备如 Alexa 和 Siri 是可能的无标语音数据的来源，可以用来学习强大的语音表示。在这种工作中，我们将自我监督学习 (SSL) 和 FL 结合以学习对自动语音识别 (ASR) 尊重数据隐私约束的表示。我们使用 Libri-Light 无标语音 dataset 中的 speaker 和 chapter 信息来模拟非同一个 speaker-siloed 数据分布，并在 Contrastive Predictive Coding 框架中使用 FedSGD 预训练 LSTM 编码器。我们发现预训练 ASR 编码器在 FL 中表现与中央预训练模型一样好，并且提高了12-15% (WER) compared to no pre-training。我们进一步适应了联邦预训练模型到一个新语言法语，并显示了20% (WER) 的提高 compared to no pre-training。
</details></li>
</ul>
<hr>
<h2 id="Bengali-Fake-Reviews-A-Benchmark-Dataset-and-Detection-System"><a href="#Bengali-Fake-Reviews-A-Benchmark-Dataset-and-Detection-System" class="headerlink" title="Bengali Fake Reviews: A Benchmark Dataset and Detection System"></a>Bengali Fake Reviews: A Benchmark Dataset and Detection System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01987">http://arxiv.org/abs/2308.01987</a></li>
<li>repo_url: None</li>
<li>paper_authors: G. M. Shahariar, Md. Tanvir Rouf Shawon, Faisal Muhammad Shah, Mohammad Shafiul Alam, Md. Shahriar Mahbub</li>
<li>for: This paper aims to identify fake reviews in the Bengali language, which is an under-explored research area in the field of fake review detection.</li>
<li>methods: The authors propose a unique pipeline to translate English words to their corresponding Bengali meaning and back transliterate Romanized Bengali to Bengali. They also use multiple deep learning and pre-trained transformer language models to develop a reliable detection system.</li>
<li>results: The proposed ensemble model achieved a weighted F1-score of 0.9843 on 13390 reviews, including 1339 actual fake reviews and 5356 augmented fake reviews generated with the nlpaug library. The model achieved a 0.9558 weighted F1-score when the fake reviews were augmented using the bnaug library.Here’s the Chinese translation of the three key points:</li>
<li>for: 这篇论文目标是在孟加拉语上预测假评论，这是一个未经探索的研究领域。</li>
<li>methods: 作者提议一种唯一的管道，将英语词汇翻译成相应的孟加拉语意思，并将拼音孟加拉语翻译成孟加拉语。他们还使用多种深度学习和预设变换语言模型来开发可靠的检测系统。</li>
<li>results: 提议的ensemble模型在13390个评论中取得了0.9843的权重F1分数，其中包括1339个实际的假评论和5356个扩充的假评论，使用nlpaug库生成的。模型在使用bnaug库扩充假评论后的权重F1分数为0.9558。<details>
<summary>Abstract</summary>
The proliferation of fake reviews on various online platforms has created a major concern for both consumers and businesses. Such reviews can deceive customers and cause damage to the reputation of products or services, making it crucial to identify them. Although the detection of fake reviews has been extensively studied in English language, detecting fake reviews in non-English languages such as Bengali is still a relatively unexplored research area. This paper introduces the Bengali Fake Review Detection (BFRD) dataset, the first publicly available dataset for identifying fake reviews in Bengali. The dataset consists of 7710 non-fake and 1339 fake food-related reviews collected from social media posts. To convert non-Bengali words in a review, a unique pipeline has been proposed that translates English words to their corresponding Bengali meaning and also back transliterates Romanized Bengali to Bengali. We have conducted rigorous experimentation using multiple deep learning and pre-trained transformer language models to develop a reliable detection system. Finally, we propose a weighted ensemble model that combines four pre-trained transformers: BanglaBERT, BanglaBERT Base, BanglaBERT Large, and BanglaBERT Generator . According to the experiment results, the proposed ensemble model obtained a weighted F1-score of 0.9843 on 13390 reviews, including 1339 actual fake reviews and 5356 augmented fake reviews generated with the nlpaug library. The remaining 6695 reviews were randomly selected from the 7710 non-fake instances. The model achieved a 0.9558 weighted F1-score when the fake reviews were augmented using the bnaug library.
</details>
<details>
<summary>摘要</summary>
“伪评论的滥蔽在网上 платфорms上导致了consumers和企业的担忧。这些评论可能会欺骗顾客和破坏产品或服务的声誉，从而使其识别成为一个重要的研究领域。虽然在英文语言中检测伪评论的研究已经很广泛，但在非英文语言 such as 孟加拉语仍然是一个相对未探索的研究领域。本文发布了第一个公开可用的孟加拉语伪评论检测（BFRD）数据集，包括7710个非伪评论和1339个伪评论 food-related 评论，从社交媒体帖子中收集。为了将英文字在评论中转换为孟加拉语的意思，我们提出了一个唯一的管道，将英文字转换为孟加拉语的意思，并且将罗马化孟加拉语转换为孟加拉语。我们进行了严谨的实验，使用多种深度学习和预训习语言模型，以建立一个可靠的检测系统。最后，我们提出了一个权重组合模型，结合四个预训习transformer语言模型：BanglaBERT、BanglaBERT Base、BanglaBERT Large 和 BanglaBERT Generator。根据实验结果，我们的提案组合模型在13390个评论中取得了0.9843的权重F1分，包括1339个实际的伪评论和5356个扩展的伪评论，使用 nlpaug 库生成。剩下的6695个评论是随机选择的。当伪评论使用 bnaug 库生成时，组合模型在13390个评论中取得了0.9558的权重F1分。”
</details></li>
</ul>
<hr>
<h2 id="Athena-2-0-Discourse-and-User-Modeling-in-Open-Domain-Dialogue"><a href="#Athena-2-0-Discourse-and-User-Modeling-in-Open-Domain-Dialogue" class="headerlink" title="Athena 2.0: Discourse and User Modeling in Open Domain Dialogue"></a>Athena 2.0: Discourse and User Modeling in Open Domain Dialogue</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01887">http://arxiv.org/abs/2308.01887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Omkar Patil, Lena Reed, Kevin K. Bowden, Juraj Juraska, Wen Cui, Vrindavan Harrison, Rishi Rajasekaran, Angela Ramirez, Cecilia Li, Eduardo Zamora, Phillip Lee, Jeshwanth Bheemanpally, Rohan Pandey, Adwait Ratnaparkhi, Marilyn Walker</li>
<li>for: 这个论文是为了描述UCSC的对话机器人Athena 2.0，用于 Amazone Socialbot Grand Challenge 4 中的对话。</li>
<li>methods: 这个论文使用了一种新的知识基础对话模型，该模型可以跟踪 Athena 引入到对话中的实体链接，并使用这些链接来限制命名实体识别和核实。此外，这个论文还使用了用户模型，以个性化对话的话题选择和其他方面。</li>
<li>results: 这个论文表明，Athena 2.0 可以在多个流行话题上进行有效的对话，并且可以根据用户的个性进行个性化对话。<details>
<summary>Abstract</summary>
Conversational agents are consistently growing in popularity and many people interact with them every day. While many conversational agents act as personal assistants, they can have many different goals. Some are task-oriented, such as providing customer support for a bank or making a reservation. Others are designed to be empathetic and to form emotional connections with the user. The Alexa Prize Challenge aims to create a socialbot, which allows the user to engage in coherent conversations, on a range of popular topics that will interest the user. Here we describe Athena 2.0, UCSC's conversational agent for Amazon's Socialbot Grand Challenge 4. Athena 2.0 utilizes a novel knowledge-grounded discourse model that tracks the entity links that Athena introduces into the dialogue, and uses them to constrain named-entity recognition and linking, and coreference resolution. Athena 2.0 also relies on a user model to personalize topic selection and other aspects of the conversation to individual users.
</details>
<details>
<summary>摘要</summary>
很多人每天都与对话代理 interact，这些对话代理的popularity在不断增长。although many conversational agents act as personal assistants, they can have many different goals. some are task-oriented, such as providing customer support for a bank or making a reservation. others are designed to be empathetic and form emotional connections with the user. the alexa prize challenge aims to create a socialbot that allows the user to engage in coherent conversations on a range of popular topics that will interest the user. here we describe athena 2.0，UCSC的 conversational agent for Amazon's socialbot grand challenge 4. athena 2.0 utilizes a novel knowledge-grounded discourse model that tracks the entity links that athena introduces into the dialogue, and uses them to constrain named-entity recognition and linking, and coreference resolution. athena 2.0 also relies on a user model to personalize topic selection and other aspects of the conversation to individual users.
</details></li>
</ul>
<hr>
<h2 id="Tag-Prediction-of-Competitive-Programming-Problems-using-Deep-Learning-Techniques"><a href="#Tag-Prediction-of-Competitive-Programming-Problems-using-Deep-Learning-Techniques" class="headerlink" title="Tag Prediction of Competitive Programming Problems using Deep Learning Techniques"></a>Tag Prediction of Competitive Programming Problems using Deep Learning Techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01863">http://arxiv.org/abs/2308.01863</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taha Lokat, Divyam Prajapati, Shubhada Labde</li>
<li>for: 本研究旨在帮助程序员找到适合自己水平和兴趣的竞赛编程问题，使用自动标签法分类竞赛问题的领域。</li>
<li>methods: 本研究使用了文本分类技术，实现了LSTM、GRU和MLP等模型的实现。</li>
<li>results: 实验结果显示，使用MLP模型可以达到最高准确率为78.0%。<details>
<summary>Abstract</summary>
In the past decade, the amount of research being done in the fields of machine learning and deep learning, predominantly in the area of natural language processing (NLP), has risen dramatically. A well-liked method for developing programming abilities like logic building and problem solving is competitive programming. It can be tough for novices and even veteran programmers to traverse the wide collection of questions due to the massive number of accessible questions and the variety of themes, levels of difficulty, and questions offered. In order to help programmers find questions that are appropriate for their knowledge and interests, there is a need for an automated method. This can be done using automated tagging of the questions using Text Classification. Text classification is one of the important tasks widely researched in the field of Natural Language Processing. In this paper, we present a way to use text classification techniques to determine the domain of a competitive programming problem. A variety of models, including are implemented LSTM, GRU, and MLP. The dataset has been scraped from Codeforces, a major competitive programming website. A total of 2400 problems were scraped and preprocessed, which we used as a dataset for our training and testing of models. The maximum accuracy reached using our model is 78.0% by MLP(Multi Layer Perceptron).
</details>
<details>
<summary>摘要</summary>
在过去的一个十年中，机器学习和深度学习领域内的自然语言处理（NLP）领域的研究量有了很大的增长。一种受欢迎的方法是竞赛编程，它可以帮助程序员提高逻辑建设和问题解决能力。但由于问题的数量繁多，多种主题、Difficulty Level和问题的选择，新手和经验 programmer都可能难以找到合适的问题。为了帮助程序员找到适合自己水平和兴趣的问题，需要一种自动化的方法。这可以通过自动标记问题来实现，使用自然语言处理领域的文本分类技术。在这篇论文中，我们提出了一种使用文本分类技术来确定竞赛编程问题的领域。我们实现了多种模型，包括LSTM、GRU和MLP。数据集来自Codeforces竞赛编程网站，共抽取了2400个问题，并进行了处理和训练模型。最高的准确率达到了78.0%，由MLP（多层感知器）实现。
</details></li>
</ul>
<hr>
<h2 id="Wider-and-Deeper-LLM-Networks-are-Fairer-LLM-Evaluators"><a href="#Wider-and-Deeper-LLM-Networks-are-Fairer-LLM-Evaluators" class="headerlink" title="Wider and Deeper LLM Networks are Fairer LLM Evaluators"></a>Wider and Deeper LLM Networks are Fairer LLM Evaluators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01862">http://arxiv.org/abs/2308.01862</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alibabaresearch/damo-convai">https://github.com/alibabaresearch/damo-convai</a></li>
<li>paper_authors: Xinghua Zhang, Bowen Yu, Haiyang Yu, Yangyu Lv, Tingwen Liu, Fei Huang, Hongbo Xu, Yongbin Li</li>
<li>for: 评估语言模型（LLM）的回答质量是一项具有挑战性的任务，特别是当需要评估回答是否与人类偏好相符。</li>
<li>methods: 本文提出了一种新的方法，利用LLM自身来进行评估，并通过多个独立评估来稳定结果。这种网络包含一定数量的神经元，每个神经元都是相同的LLM。</li>
<li>results: 研究发现，使用更深和宽的网络可以导致更公正的评估结果。此外，利用WideDeep可以加速评估过程，提高人类协议率至93%。<details>
<summary>Abstract</summary>
Measuring the quality of responses generated by LLMs is a challenging task, particularly when it comes to evaluating whether the response is aligned with human preference. A novel approach involves using the LLM itself to make evaluation and stabilizing the results through multiple independent evaluations, similar to a single-layer narrow LLM network. This network consists of a fixed number of neurons, with each neuron being the same LLM. In this paper, we draw upon the extensive research on deep neural networks to explore whether deeper and wider networks can lead to fairer evaluations. Specifically, inspired by the observation that different neurons in a neural network are responsible for detecting different concepts, we first adaptively generate as many neuron roles as possible for each evaluation sample. Each perspective corresponds to the role of a specific LLM neuron in the first layer. In subsequent layers, we follow the idea that higher layers in deep networks are responsible for more comprehensive features, each layer receives representations from all neurons in the previous layer, integrating the locally learned evaluation information to obtain a more comprehensive evaluation result. Interestingly, this network design resembles the process of academic paper reviewing. To validate the effectiveness of our method, we construct the largest and most diverse English evaluation benchmark LLMEval$^2$ for LLM evaluators, comprising 15 tasks, 8 abilities, and 2,553 samples. Experimental results demonstrate that a wider network (involving many reviewers) with 2 layers (one round of discussion) performs the best, improving kappa correlation coefficient from 0.28 to 0.34. We also leverage WideDeep to aid in the assessment of Chinese LLMs, which has accelerated the evaluation time by 4.6 times, resulting in a 60% cost saving. WideDeep achieves a remarkable 93% agreement level among humans.
</details>
<details>
<summary>摘要</summary>
评估语言模型（LLM）生成的响应质量是一项具有挑战性的任务，特别是当需要评估响应是否与人类偏好相符。一种新的方法是使用LLM自己进行评估，并通过多个独立评估来稳定结果，类似于单层窄LLM网络。这种网络由固定数量的神经元组成，每个神经元都是相同的LLM。在这篇论文中，我们 draw upon deep neural networks的广泛研究，探索深度和宽度是否可以导致更公平的评估。具体来说，我们根据观察deep neural network中不同神经元负责检测不同概念的现象，我们首先适应性地生成评估样本中的最多神经元角色。在后续层中，我们遵循深度网络中高层的神经元负责更全面的特征，每层都收到前一层所有神经元的表示，将地方学习的评估信息集成起来，以获得更全面的评估结果。这种网络设计与学术论文审核过程类似。为验证方法的效果，我们构建了最大和最多样的英语评估数据集LLMEval$^2$，包括15个任务、8种能力和2553个样本。实验结果表明，一个更宽的网络（即多个评审者）以2层（一次讨论）的设计表现最佳，从0.28到0.34的κ相互关系系数进行提高。我们还使用了WideDeep来辅助中文LLM的评估，从而提高评估速度，并实现了60%的成本减少。WideDeep达到了人类93%的一致水平。
</details></li>
</ul>
<hr>
<h2 id="Curricular-Transfer-Learning-for-Sentence-Encoded-Tasks"><a href="#Curricular-Transfer-Learning-for-Sentence-Encoded-Tasks" class="headerlink" title="Curricular Transfer Learning for Sentence Encoded Tasks"></a>Curricular Transfer Learning for Sentence Encoded Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01849">http://arxiv.org/abs/2308.01849</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jader Martins Camboim de Sá, Matheus Ferraroni Sanches, Rafael Roque de Souza, Júlio Cesar dos Reis, Leandro Aparecido Villas</li>
<li>for: 这篇论文是为了提高NLU任务中的表现，尤其是在对话环境下。</li>
<li>methods: 本文提出了一组预训步骤（curriculum），受到“数据黑客”和 grammatical 分析的帮助，以便逐步适应预训资料的分布。</li>
<li>results: 在我们的实验中，我们比其他已知的预训方法在 MultiWoZ 任务上获得了较好的表现。<details>
<summary>Abstract</summary>
Fine-tuning language models in a downstream task is the standard approach for many state-of-the-art methodologies in the field of NLP. However, when the distribution between the source task and target task drifts, \textit{e.g.}, conversational environments, these gains tend to be diminished. This article proposes a sequence of pre-training steps (a curriculum) guided by "data hacking" and grammar analysis that allows further gradual adaptation between pre-training distributions. In our experiments, we acquire a considerable improvement from our method compared to other known pre-training approaches for the MultiWoZ task.
</details>
<details>
<summary>摘要</summary>
通常，在自然语言处理（NLP）领域中，许多状态下方法会在下游任务中细化语言模型。然而，当源任务和目标任务分布之间的差异较大，例如对话环境，这些收益往往减少。这篇文章提出了一系列的预训练步骤（课程），通过“数据黑客”和语法分析引导，以便进行逐渐的适应 между预训练分布。在我们的实验中，我们对多语言对话任务（MultiWoZ）获得了明显的改善，相比其他已知的预训练方法。
</details></li>
</ul>
<hr>
<h2 id="XNLP-An-Interactive-Demonstration-System-for-Universal-Structured-NLP"><a href="#XNLP-An-Interactive-Demonstration-System-for-Universal-Structured-NLP" class="headerlink" title="XNLP: An Interactive Demonstration System for Universal Structured NLP"></a>XNLP: An Interactive Demonstration System for Universal Structured NLP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01846">http://arxiv.org/abs/2308.01846</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Fei, Meishan Zhang, Min Zhang, Tat-Seng Chua</li>
<li>for: 这个论文是为了提出一个综合性的自然语言处理（XNLP）示范平台，以便研究者在多种XNLP任务上进行探索。</li>
<li>methods: 该论文提出了使用大型语言模型（LLM）来实现universal XNLP，一个模型可以涵盖所有XNLP任务，并且具有高通用性。</li>
<li>results: 该论文的系统在多个方面提高了XNLP示范平台，包括通用XNLP模型、高性能、可解释性、可扩展性和交互性等方面，为研究者提供了一个统一的平台来探索多种XNLP任务。<details>
<summary>Abstract</summary>
Structured Natural Language Processing (XNLP) is an important subset of NLP that entails understanding the underlying semantic or syntactic structure of texts, which serves as a foundational component for many downstream applications. Despite certain recent efforts to explore universal solutions for specific categories of XNLP tasks, a comprehensive and effective approach for unifying all XNLP tasks long remains underdeveloped. In the meanwhile, while XNLP demonstration systems are vital for researchers exploring various XNLP tasks, existing platforms can be limited to, e.g., supporting few XNLP tasks, lacking interactivity and universalness. To this end, we propose an advanced XNLP demonstration platform, where we propose leveraging LLM to achieve universal XNLP, with one model for all with high generalizability. Overall, our system advances in multiple aspects, including universal XNLP modeling, high performance, interpretability, scalability, and interactivity, providing a unified platform for exploring diverse XNLP tasks in the community. XNLP is online: https://xnlp.haofei.vip
</details>
<details>
<summary>摘要</summary>
“结构化自然语言处理（XNLP）是 NLP 中一个重要的子集，它涉及理解文本中的 semantics 或 syntax 结构，这种基础组件对多个下游应用有很大的重要性。尽管有些最近的努力是为了探索特定类型的 XNLP 任务的通用解决方案，但是一个包容和有效的 XNLP 任务统一方法仍然没有得到开发。在这之前，XNLP 演示系统是研究者探索不同 XNLP 任务的重要工具，但现有的平台有限，例如只支持一些 XNLP 任务，缺乏通用性和互动性。为此，我们提出了一个高级 XNLP 演示平台，我们提议利用 LLM 来实现 universality XNLP，一个模型可以涵盖所有 XNLP 任务，具有高通用性。总的来说，我们的系统在多个方面进步，包括 universality XNLP 模型、高性能、可解释性、可扩展性和互动性，提供一个统一的平台 для研究者探索不同 XNLP 任务。XNLP 在线：https://xnlp.haofei.vip”Note: "LLM" stands for "large language model" in English.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/04/cs.CL_2023_08_04/" data-id="closbrolu008z0g887f5zeo1o" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_04" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/04/cs.LG_2023_08_04/" class="article-date">
  <time datetime="2023-08-04T10:00:00.000Z" itemprop="datePublished">2023-08-04</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/04/cs.LG_2023_08_04/">cs.LG - 2023-08-04</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Enhancing-Cell-Tracking-with-a-Time-Symmetric-Deep-Learning-Approach"><a href="#Enhancing-Cell-Tracking-with-a-Time-Symmetric-Deep-Learning-Approach" class="headerlink" title="Enhancing Cell Tracking with a Time-Symmetric Deep Learning Approach"></a>Enhancing Cell Tracking with a Time-Symmetric Deep Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03887">http://arxiv.org/abs/2308.03887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gergely Szabó, Paolo Bonaiuti, Andrea Ciliberto, András Horváth</li>
<li>for: 这种论文的目的是提出一种基于深度学习的细胞跟踪方法，以便在视频微scopic录像中跟踪细胞的运动。</li>
<li>methods: 该方法基于细胞的空间时间邻域特征，不需要采用连续帧的假设，可以普适应用于各种生物学应用。</li>
<li>results: 经过多种生物学上的验证和比较，该方法能够有效地跟踪细胞的运动，并且可以承受大量的视频帧和噪声。<details>
<summary>Abstract</summary>
The accurate tracking of live cells using video microscopy recordings remains a challenging task for popular state-of-the-art image processing based object tracking methods. In recent years, several existing and new applications have attempted to integrate deep-learning based frameworks for this task, but most of them still heavily rely on consecutive frame based tracking embedded in their architecture or other premises that hinder generalized learning. To address this issue, we aimed to develop a new deep-learning based tracking method that relies solely on the assumption that cells can be tracked based on their spatio-temporal neighborhood, without restricting it to consecutive frames. The proposed method has the additional benefit that the motion patterns of the cells can be learned completely by the predictor without any prior assumptions, and it has the potential to handle a large number of video frames with heavy artifacts. The efficacy of the proposed method is demonstrated through multiple biologically motivated validation strategies and compared against several state-of-the-art cell tracking methods.
</details>
<details>
<summary>摘要</summary>
Live cells的准确跟踪使用视频微scopic记录仍然是流行的state-of-the-art图像处理基于对象跟踪方法中的挑战。在过去几年，许多现有和新的应用程序尝试 integrate deep learning基础框架来解决这个问题，但大多数它们仍然受限于顺序帧基础或其他假设，这会阻碍普适学习。为解决这个问题，我们目标是开发一种新的deep learning基础的跟踪方法，不需要基于顺序帧的假设，可以基于细胞的空间时间邻域来跟踪细胞。这种方法的优点是可以通过predictor完全学习细胞的运动模式，无需任何先前假设，并且可以处理大量的视频帧并快速响应变化。我们通过多种生物学上motivated的验证方法证明了提案的方法的有效性，并与多种现有细胞跟踪方法进行比较。
</details></li>
</ul>
<hr>
<h2 id="Learning-Optimal-Admission-Control-in-Partially-Observable-Queueing-Networks"><a href="#Learning-Optimal-Admission-Control-in-Partially-Observable-Queueing-Networks" class="headerlink" title="Learning Optimal Admission Control in Partially Observable Queueing Networks"></a>Learning Optimal Admission Control in Partially Observable Queueing Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02391">http://arxiv.org/abs/2308.02391</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonatha Anselmi, Bruno Gaujal, Louis-Sébastien Rebuffi</li>
<li>for: 本研究开发了一个高效的增强学习算法，用于在半可观queueing网络中计算最佳接受控制策略。</li>
<li>methods: 本研究使用了Norton的等效定理和生生死范例中的增强学习算法，以解决半可观POMDP中的问题。</li>
<li>results: 本研究的结果显示，我们的算法可以在半可观POMDP中实现最佳的平均保持&#x2F;拒绝成本，并且其 regret bound只随S的幂级函数而增长，而不是像先前的研究一样，受到网络的宽度影响。<details>
<summary>Abstract</summary>
We present an efficient reinforcement learning algorithm that learns the optimal admission control policy in a partially observable queueing network. Specifically, only the arrival and departure times from the network are observable, and optimality refers to the average holding/rejection cost in infinite horizon.   While reinforcement learning in Partially Observable Markov Decision Processes (POMDP) is prohibitively expensive in general, we show that our algorithm has a regret that only depends sub-linearly on the maximal number of jobs in the network, $S$. In particular, in contrast with existing regret analyses, our regret bound does not depend on the diameter of the underlying Markov Decision Process (MDP), which in most queueing systems is at least exponential in $S$.   The novelty of our approach is to leverage Norton's equivalent theorem for closed product-form queueing networks and an efficient reinforcement learning algorithm for MDPs with the structure of birth-and-death processes.
</details>
<details>
<summary>摘要</summary>
我们提出了一个高效的增强学习算法，可以在具有部分可见性的队列网络中学习最佳接受控制策略。具体来说，只有队列网络的到达和离开时间是可见的，且优化指的是在无穷远征 horizon 中的平均保持/拒绝成本。而在 partially observable Markov decision processes (POMDP) 中，通常情况下增强学习是不可持续的，但我们显示了我们的算法仅对最大队列数量 $S$ 有对��� penalty。具体来说，我们的 regret  bound 不同于现有的 regret 分析，不随 diameters 的增长，而是随 $S$ 的增长。我们的方法具有以下两个特点：一是利用 Norton's 等效定理 для closed product-form queueing networks，二是一种高效的增强学习算法 для birth-and-death 过程中的 MDP。
</details></li>
</ul>
<hr>
<h2 id="Scaling-Survival-Analysis-in-Healthcare-with-Federated-Survival-Forests-A-Comparative-Study-on-Heart-Failure-and-Breast-Cancer-Genomics"><a href="#Scaling-Survival-Analysis-in-Healthcare-with-Federated-Survival-Forests-A-Comparative-Study-on-Heart-Failure-and-Breast-Cancer-Genomics" class="headerlink" title="Scaling Survival Analysis in Healthcare with Federated Survival Forests: A Comparative Study on Heart Failure and Breast Cancer Genomics"></a>Scaling Survival Analysis in Healthcare with Federated Survival Forests: A Comparative Study on Heart Failure and Breast Cancer Genomics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02382">http://arxiv.org/abs/2308.02382</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alberto Archetti, Francesca Ieva, Matteo Matteucci</li>
<li>for: 这paper的目的是提出一种基于联合学习的生存分析方法，以解决现实世界应用中的生存数据杂乱、截断和保密问题。</li>
<li>methods: 这paper使用了联合学习技术，特别是基于生存森林的Federated Survival Forest（FedSurF）算法，以及一些新的树样本方法来提高算法的性能和隐私保护。</li>
<li>results: 实验结果表明，FedSurF++可以与现有方法相比，在一次通信往返完成后达到相似的性能，并且具有更高的效率、更好的鲁棒性和更好的隐私保护。 Additionally, the paper demonstrates the success of FedSurF++ on two real-world datasets, highlighting its potential for improving the scalability and effectiveness of survival analysis in distributed settings while preserving user privacy.<details>
<summary>Abstract</summary>
Survival analysis is a fundamental tool in medicine, modeling the time until an event of interest occurs in a population. However, in real-world applications, survival data are often incomplete, censored, distributed, and confidential, especially in healthcare settings where privacy is critical. The scarcity of data can severely limit the scalability of survival models to distributed applications that rely on large data pools. Federated learning is a promising technique that enables machine learning models to be trained on multiple datasets without compromising user privacy, making it particularly well-suited for addressing the challenges of survival data and large-scale survival applications. Despite significant developments in federated learning for classification and regression, many directions remain unexplored in the context of survival analysis. In this work, we propose an extension of the Federated Survival Forest algorithm, called FedSurF++. This federated ensemble method constructs random survival forests in heterogeneous federations. Specifically, we investigate several new tree sampling methods from client forests and compare the results with state-of-the-art survival models based on neural networks. The key advantage of FedSurF++ is its ability to achieve comparable performance to existing methods while requiring only a single communication round to complete. The extensive empirical investigation results in a significant improvement from the algorithmic and privacy preservation perspectives, making the original FedSurF algorithm more efficient, robust, and private. We also present results on two real-world datasets demonstrating the success of FedSurF++ in real-world healthcare studies. Our results underscore the potential of FedSurF++ to improve the scalability and effectiveness of survival analysis in distributed settings while preserving user privacy.
</details>
<details>
<summary>摘要</summary>
生存分析是医学中的基本工具，用于模型在人口中事件兴 interest 的时间 until 发生。然而，在实际应用中，生存数据经常是不完整、审核、分布和保密的，尤其在医疗设置中，隐私是极为重要的。数据的缺乏可能会对大规模生存模型的扩展应用产生严重的限制。联邦学习是一种有前途的技术，它允许机器学习模型在多个数据集上进行训练，而不需要牺牲用户隐私。这使得联邦学习在生存数据和大规模生存应用中具有极大的潜力。在这项工作中，我们提出了一种基于联邦生存森林算法的扩展，即 FedSurF++。这是一种联邦ensemble方法，可以在不同的联邦中随机生成生存森林。我们 investigate 了一些新的客户端森林采样方法，并与现有的生存模型基于神经网络进行比较。FedSurF++ 的关键优势在于它可以在单一的通信循环中完成，并且可以与现有方法相比具有相似的性能。我们的实验结果表明，FedSurF++ 可以在算法和隐私保护方面做出显著改进，使原始 FedSurF 算法更加高效、稳定和安全。此外，我们还对两个实际 dataset 进行了实践，证明了 FedSurF++ 在真实世界医疗研究中的成功。我们的结果表明，FedSurF++ 可以在分布式设置中提高生存分析的扩展性和效果，同时保持用户隐私。
</details></li>
</ul>
<hr>
<h2 id="Harnessing-the-Web-and-Knowledge-Graphs-for-Automated-Impact-Investing-Scoring"><a href="#Harnessing-the-Web-and-Knowledge-Graphs-for-Automated-Impact-Investing-Scoring" class="headerlink" title="Harnessing the Web and Knowledge Graphs for Automated Impact Investing Scoring"></a>Harnessing the Web and Knowledge Graphs for Automated Impact Investing Scoring</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02622">http://arxiv.org/abs/2308.02622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingzhi Hu, Daniel Daza, Laurens Swinkels, Kristina Ūsaitė, Robbert-Jan ‘t Hoen, Paul Groth</li>
<li>for: This paper aims to automate the process of creating an SDG framework for companies.</li>
<li>methods: The proposed system uses a data-driven approach, collecting and filtering a dataset of texts from various web sources and a knowledge graph, and then training classifiers to predict SDG scores for a given company.</li>
<li>results: The best performing model achieved a micro average F1 score of 0.89, demonstrating the effectiveness of the proposed solution. Additionally, the system provides explanations in the form of data relevant to the predicted score, facilitating its use by humans.<details>
<summary>Abstract</summary>
The Sustainable Development Goals (SDGs) were introduced by the United Nations in order to encourage policies and activities that help guarantee human prosperity and sustainability. SDG frameworks produced in the finance industry are designed to provide scores that indicate how well a company aligns with each of the 17 SDGs. This scoring enables a consistent assessment of investments that have the potential of building an inclusive and sustainable economy. As a result of the high quality and reliability required by such frameworks, the process of creating and maintaining them is time-consuming and requires extensive domain expertise. In this work, we describe a data-driven system that seeks to automate the process of creating an SDG framework. First, we propose a novel method for collecting and filtering a dataset of texts from different web sources and a knowledge graph relevant to a set of companies. We then implement and deploy classifiers trained with this data for predicting scores of alignment with SDGs for a given company. Our results indicate that our best performing model can accurately predict SDG scores with a micro average F1 score of 0.89, demonstrating the effectiveness of the proposed solution. We further describe how the integration of the models for its use by humans can be facilitated by providing explanations in the form of data relevant to a predicted score. We find that our proposed solution enables access to a large amount of information that analysts would normally not be able to process, resulting in an accurate prediction of SDG scores at a fraction of the cost.
</details>
<details>
<summary>摘要</summary>
联合国发布可持续发展目标（SDGs），以促进政策和活动，确保人类发展和可持续性。在金融业中，SDG框架生成了分数，用于评估公司如何与17个SDG启合。这些分数可以帮助评估投资，以建立包容性和可持续的经济。由于需要高质量和可靠性，创建和维护这些框架需要很长时间和广泛的领域专业知识。在这项工作中，我们描述了一个数据驱动的系统，用于自动化SDG框架的创建过程。首先，我们提出了一种新的方法，用于收集和筛选来自不同网络源和知识图库相关公司的文本数据集。然后，我们实现和部署基于这些数据的分类器，用于预测公司与SDG的Alignment Score。我们的结果表明，我们的最佳表现模型可以准确预测SDG分数，微均F1分数为0.89，证明我们的解决方案的有效性。此外，我们还描述了如何将模型与人类使用者集成，通过提供预测分数的数据相关信息进行解释。我们发现，我们的提议的解决方案可以提供大量信息，让分析员不可能处理的信息，并且可以在成本的一小部分下准确预测SDG分数。
</details></li>
</ul>
<hr>
<h2 id="A-Machine-Learning-Method-for-Predicting-Traffic-Signal-Timing-from-Probe-Vehicle-Data"><a href="#A-Machine-Learning-Method-for-Predicting-Traffic-Signal-Timing-from-Probe-Vehicle-Data" class="headerlink" title="A Machine Learning Method for Predicting Traffic Signal Timing from Probe Vehicle Data"></a>A Machine Learning Method for Predicting Traffic Signal Timing from Probe Vehicle Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02370">http://arxiv.org/abs/2308.02370</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juliette Ugirumurera, Joseph Severino, Erik A. Bensen, Qichao Wang, Jane Macfarlane</li>
<li>for: This paper aims to estimate traffic signal timing information from vehicle probe data using machine learning techniques.</li>
<li>methods: The authors use Extreme Gradient Boosting (XGBoost) model to estimate signal cycle lengths and a neural network model to determine the corresponding red times per phase from probe data.</li>
<li>results: The authors achieve an error of less than 0.56 seconds for cycle length predictions and red times predictions within 7.2 seconds on average.Here’s the result in Simplified Chinese text:</li>
<li>for: 这篇论文目的是使用机器学习技术来估算交通信号灯控制信息从车辆探测数据中。</li>
<li>methods: 作者使用极大梯度提升（XGBoost）模型来估算信号周期长度，并使用神经网络模型来确定每个阶段的红灯时间从探测数据中。</li>
<li>results: 作者在周期长度预测中达到了 menos于0.56秒的错误，红灯时间预测在7.2秒的平均错误范围内。<details>
<summary>Abstract</summary>
Traffic signals play an important role in transportation by enabling traffic flow management, and ensuring safety at intersections. In addition, knowing the traffic signal phase and timing data can allow optimal vehicle routing for time and energy efficiency, eco-driving, and the accurate simulation of signalized road networks. In this paper, we present a machine learning (ML) method for estimating traffic signal timing information from vehicle probe data. To the authors best knowledge, very few works have presented ML techniques for determining traffic signal timing parameters from vehicle probe data. In this work, we develop an Extreme Gradient Boosting (XGBoost) model to estimate signal cycle lengths and a neural network model to determine the corresponding red times per phase from probe data. The green times are then be derived from the cycle length and red times. Our results show an error of less than 0.56 sec for cycle length, and red times predictions within 7.2 sec error on average.
</details>
<details>
<summary>摘要</summary>
停车信号对交通运输具有重要作用，协调交通流量，保证交通圆环安全。此外，了解停车信号阶段和时间数据可以帮助车辆进行优化的路径规划，以提高时间和能源效率， ec driving 和停车信号网络的准确模拟。本文提出了一种机器学习（ML）方法，通过车辆探测数据来估算停车信号时间信息。作者知道的研究中，很少有使用车辆探测数据来确定停车信号时间参数的工作。本文开发了极Gradient Boosting（XGBoost）模型来估算停车信号阶段长度，以及一个神经网络模型来确定每个阶段的红灯时间。绿灯时间则可以从阶段长度和红灯时间中 derivation。我们的结果显示停车信号阶段长度的预测错误在0.56秒之下，而红灯时间的预测错误在7.2秒之内。
</details></li>
</ul>
<hr>
<h2 id="Color-Image-Recovery-Using-Generalized-Matrix-Completion-over-Higher-Order-Finite-Dimensional-Algebra"><a href="#Color-Image-Recovery-Using-Generalized-Matrix-Completion-over-Higher-Order-Finite-Dimensional-Algebra" class="headerlink" title="Color Image Recovery Using Generalized Matrix Completion over Higher-Order Finite Dimensional Algebra"></a>Color Image Recovery Using Generalized Matrix Completion over Higher-Order Finite Dimensional Algebra</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02621">http://arxiv.org/abs/2308.02621</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liang Liao, Zhuang Guo, Qi Gao, Yan Wang, Fajun Yu, Qifeng Zhao, Stephen Johh Maybank</li>
<li>for: 填充缺失色像的精度提高</li>
<li>methods: 基于泛化高阶矩阵的 recovery方法，包括扩展传统第二阶矩阵模型到更全面的高阶矩阵相似模型，并利用像素邻域扩展策略来捕捉地方像素约束。</li>
<li>results: 对各种算法进行了广泛的实验，包括使用模拟数据和公共可用的图像，并与传统矩阵和tensor completion算法进行比较。结果显示，我们的泛化矩阵完成模型和相应的算法在精度和效率方面与低阶矩阵和传统矩阵相似。<details>
<summary>Abstract</summary>
To improve the accuracy of color image completion with missing entries, we present a recovery method based on generalized higher-order scalars. We extend the traditional second-order matrix model to a more comprehensive higher-order matrix equivalent, called the "t-matrix" model, which incorporates a pixel neighborhood expansion strategy to characterize the local pixel constraints. This "t-matrix" model is then used to extend some commonly used matrix and tensor completion algorithms to their higher-order versions. We perform extensive experiments on various algorithms using simulated data and algorithms on simulated data and publicly available images and compare their performance. The results show that our generalized matrix completion model and the corresponding algorithm compare favorably with their lower-order tensor and conventional matrix counterparts.
</details>
<details>
<summary>摘要</summary>
要提高颜色图像完成缺失项的准确性，我们提出了基于泛化高阶约束的恢复方法。我们将传统的第二阶矩阵模型扩展到更为全面的高阶约束模型，称之为“t-矩阵”模型，该模型通过Pixel neighborhood Expansion strategy来捕捉当地像素约束。这个“t-矩阵”模型然后用于扩展一些通常用的矩阵和tensor completion算法到其高阶版本。我们在各种算法上进行了广泛的实验，使用模拟数据和公共可用的图像，并比较了其性能。结果显示，我们的泛化约束模型和相应的算法与其低阶矩阵和传统矩阵counterpart相比，表现出色。
</details></li>
</ul>
<hr>
<h2 id="Intensity-free-Integral-based-Learning-of-Marked-Temporal-Point-Processes"><a href="#Intensity-free-Integral-based-Learning-of-Marked-Temporal-Point-Processes" class="headerlink" title="Intensity-free Integral-based Learning of Marked Temporal Point Processes"></a>Intensity-free Integral-based Learning of Marked Temporal Point Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02360">http://arxiv.org/abs/2308.02360</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/stepinsilence/ifib">https://github.com/stepinsilence/ifib</a></li>
<li>paper_authors: Sishun Liu, Ke Deng, Xiuzhen Zhang, Yongli Ren</li>
<li>for: 这个研究旨在开发一个高精度的组合PDF（conditional joint PDF）模型，用于处理离散事件，其事件标签可以是数值或标签型态的多维连续空间内。</li>
<li>methods: 这个研究提出了一个名为IFIB（intensity-free integral-based process）的解决方案，它不需要定义强度函数，直接模型组合PDF $p^*(m,t)$。IFIB使用了一个简单的架构，并且具有较好的性能和简洁性。</li>
<li>results: 研究人员透过实验和实际应用评估了IFIB的性能，结果显示IFIB在实际应用中表现更好，并且可以更好地捕捉事件的特性和趋势。另外，IFIB的代码亦可以在GitHub上获取。<details>
<summary>Abstract</summary>
In the marked temporal point processes (MTPP), a core problem is to parameterize the conditional joint PDF (probability distribution function) $p^*(m,t)$ for inter-event time $t$ and mark $m$, conditioned on the history. The majority of existing studies predefine intensity functions. Their utility is challenged by specifying the intensity function's proper form, which is critical to balance expressiveness and processing efficiency. Recently, there are studies moving away from predefining the intensity function -- one models $p^*(t)$ and $p^*(m)$ separately, while the other focuses on temporal point processes (TPPs), which do not consider marks. This study aims to develop high-fidelity $p^*(m,t)$ for discrete events where the event marks are either categorical or numeric in a multi-dimensional continuous space. We propose a solution framework IFIB (\underline{I}ntensity-\underline{f}ree \underline{I}ntegral-\underline{b}ased process) that models conditional joint PDF $p^*(m,t)$ directly without intensity functions. It remarkably simplifies the process to compel the essential mathematical restrictions. We show the desired properties of IFIB and the superior experimental results of IFIB on real-world and synthetic datasets. The code is available at \url{https://github.com/StepinSilence/IFIB}.
</details>
<details>
<summary>摘要</summary>
“在标注时间点过程（MTPP）中，核心问题是参数化 conditional joint PDF（概率分布函数）$p^*(m,t)$， conditioned on the history。大多数现有研究采用预定 INTENSITY 函数。其Utility 受到预定 INTENSITY 函数的正确形式的挑战，这是 critical 的平衡表达力和处理效率。现在，有一些研究弃除预定 INTENSITY 函数——一种 models $p^*(t)$ 和 $p^*(m)$ 分别，而另一种关注时间点过程（TPPs），不考虑标记。本研究目的是开发高准确的 $p^*(m,t)$  для精细事件，其事件标记可以是 categorical 或 numeric 在多维连续空间。我们提出了解决方案框架 IFIB（INTENSITY-free INTEGRAL-based process），它直接模型 conditional joint PDF $p^*(m,t)$  без INTENSITY 函数。它够remarkably 简化过程，迫使其数学约束。我们显示了 IFIB 的愿望性质和实验结果，并提供了实验结果。代码可以在 \url{https://github.com/StepinSilence/IFIB} 上获取。”
</details></li>
</ul>
<hr>
<h2 id="ChatGPT-for-GTFS-From-Words-to-Information"><a href="#ChatGPT-for-GTFS-From-Words-to-Information" class="headerlink" title="ChatGPT for GTFS: From Words to Information"></a>ChatGPT for GTFS: From Words to Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02618">http://arxiv.org/abs/2308.02618</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/utel-uiuc/gtfs_llm">https://github.com/utel-uiuc/gtfs_llm</a></li>
<li>paper_authors: Saipraneeth Devunuri, Shirin Qiam, Lewis Lehe</li>
<li>for: This research aims to determine if current large language models (LLMs) can retrieve information from the General Transit Feed Specification (GTFS) using natural language instructions.</li>
<li>methods: The research uses ChatGPT (GPT-3.5) to test its understanding of the GTFS specification and to perform information extraction from a filtered GTFS feed with 4 routes. The research compares zero-shot and program synthesis for information retrieval.</li>
<li>results: GPT-3.5 answers 77% of multiple-choice questions correctly, and program synthesis achieves ~90% accuracy on simple questions and ~40% accuracy on complex questions for information retrieval.<details>
<summary>Abstract</summary>
The General Transit Feed Specification (GTFS) standard for publishing transit data is ubiquitous. GTFS being tabular data, with information spread across different files, necessitates specialized tools or packages to retrieve information. Concurrently, the use of Large Language Models for text and information retrieval is growing. The idea of this research is to see if the current widely adopted LLMs (ChatGPT) are able to retrieve information from GTFS using natural language instructions. We first test whether ChatGPT (GPT-3.5) understands the GTFS specification. GPT-3.5 answers 77% of our multiple-choice questions (MCQ) correctly. Next, we task the LLM with information extractions from a filtered GTFS feed with 4 routes. For information retrieval, we compare zero-shot and program synthesis. Program synthesis works better, achieving ~90% accuracy on simple questions and ~40% accuracy on complex questions.
</details>
<details>
<summary>摘要</summary>
“通用交通资料标准（GTFS）是公共交通资料的标准化方式，它是表格式的数据，资讯分散在不同的档案中，因此需要特殊的工具或套件来撷取资讯。同时，使用大型自然语言模型（LLM）来检索和撷取文本资讯的使用情况正在增加。本研究的想法是看看目前最受推崇的LLM（ChatGPT）是否可以使用自然语言指令来从GTFS中撷取资讯。我们首先测试了ChatGPT是否理解GTFS规范。ChatGPT回答了我们的多选询题（MCQ）中的77%问题正确。接下来，我们将LLM调用到一个筛选后的GTFS资料中，并进行信息撷取。对于信息撷取，我们比较了零配置和程式合成。程式合成的方法在简单问题上取得了约90%的准确率，而在复杂问题上取得了约40%的准确率。”Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Multi-attacks-Many-images-the-same-adversarial-attack-to-many-target-labels"><a href="#Multi-attacks-Many-images-the-same-adversarial-attack-to-many-target-labels" class="headerlink" title="Multi-attacks: Many images $+$ the same adversarial attack $\to$ many target labels"></a>Multi-attacks: Many images $+$ the same adversarial attack $\to$ many target labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03792">http://arxiv.org/abs/2308.03792</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/stanislavfort/multi-attacks">https://github.com/stanislavfort/multi-attacks</a></li>
<li>paper_authors: Stanislav Fort</li>
<li>for: 本研究旨在提出多个攻击方法，可以同时改变多个图像的类别。</li>
<li>methods: 本研究使用了一种单个攻击方法，可以改变多个图像的类别，并且可以控制攻击方法的规模。</li>
<li>results: 研究发现，可以通过控制攻击方法的规模，改变多个图像的类别，并且可以在不同的图像和目标类上同时进行多个攻击。此外，研究还发现，采用协同学习可以减少攻击的可能性。<details>
<summary>Abstract</summary>
We show that we can easily design a single adversarial perturbation $P$ that changes the class of $n$ images $X_1,X_2,\dots,X_n$ from their original, unperturbed classes $c_1, c_2,\dots,c_n$ to desired (not necessarily all the same) classes $c^*_1,c^*_2,\dots,c^*_n$ for up to hundreds of images and target classes at once. We call these \textit{multi-attacks}. Characterizing the maximum $n$ we can achieve under different conditions such as image resolution, we estimate the number of regions of high class confidence around a particular image in the space of pixels to be around $10^{\mathcal{O}(100)}$, posing a significant problem for exhaustive defense strategies. We show several immediate consequences of this: adversarial attacks that change the resulting class based on their intensity, and scale-independent adversarial examples. To demonstrate the redundancy and richness of class decision boundaries in the pixel space, we look for its two-dimensional sections that trace images and spell words using particular classes. We also show that ensembling reduces susceptibility to multi-attacks, and that classifiers trained on random labels are more susceptible. Our code is available on GitHub.
</details>
<details>
<summary>摘要</summary>
我们示示出，可以轻松地设计单一的敌对干扰P，使$n$幅影像$X_1,X_2,\ldots,X_n$的原始、未干扰类别$c_1,c_2,\ldots,c_n$变化为愿意的类别$c^*_1,c^*_2,\ldots,c^*_n$。我们称这为“多元攻击”。在不同的图像分辨率下，我们估计在像素空间中高度信任类别的区域数量为$10^{\mathcal{O}(100)}$，这会对对抗策略造成严重的问题。我们显示了一些直接的后果：对于干扰的强度而变化的攻击，以及不受影像大小影响的攻击示例。我们还证明了分类器的集成可以对多元攻击进行防护，并且显示了使用随机标签训练的分类器更容易受到攻击。我们的代码可以在GitHub上找到。
</details></li>
</ul>
<hr>
<h2 id="Adapting-to-Change-Robust-Counterfactual-Explanations-in-Dynamic-Data-Landscapes"><a href="#Adapting-to-Change-Robust-Counterfactual-Explanations-in-Dynamic-Data-Landscapes" class="headerlink" title="Adapting to Change: Robust Counterfactual Explanations in Dynamic Data Landscapes"></a>Adapting to Change: Robust Counterfactual Explanations in Dynamic Data Landscapes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02353">http://arxiv.org/abs/2308.02353</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bardhprenkaj/hansel">https://github.com/bardhprenkaj/hansel</a></li>
<li>paper_authors: Bardh Prenkaj, Mario Villaizan-Vallelado, Tobias Leemann, Gjergji Kasneci</li>
<li>for: This paper proposes a novel semi-supervised method for counterfactual explanation, called Dynamic GRAph Counterfactual Explainer (DyGRACE), which can be used to identify counterfactuals in graph-structured data.</li>
<li>methods: DyGRACE uses two graph autoencoders (GAEs) to learn the representation of each class in a binary classification scenario, and optimizes a parametric density function (implemented as a logistic regression function) to identify counterfactuals by maximizing the factual autoencoder’s reconstruction error.</li>
<li>results: The paper shows that DyGRACE is effective in identifying counterfactuals and can act as a drift detector, identifying distributional drift based on differences in reconstruction errors between iterations. It also avoids reliance on the oracle’s predictions in successive iterations, increasing the efficiency of counterfactual discovery.<details>
<summary>Abstract</summary>
We introduce a novel semi-supervised Graph Counterfactual Explainer (GCE) methodology, Dynamic GRAph Counterfactual Explainer (DyGRACE). It leverages initial knowledge about the data distribution to search for valid counterfactuals while avoiding using information from potentially outdated decision functions in subsequent time steps. Employing two graph autoencoders (GAEs), DyGRACE learns the representation of each class in a binary classification scenario. The GAEs minimise the reconstruction error between the original graph and its learned representation during training. The method involves (i) optimising a parametric density function (implemented as a logistic regression function) to identify counterfactuals by maximising the factual autoencoder's reconstruction error, (ii) minimising the counterfactual autoencoder's error, and (iii) maximising the similarity between the factual and counterfactual graphs. This semi-supervised approach is independent of an underlying black-box oracle. A logistic regression model is trained on a set of graph pairs to learn weights that aid in finding counterfactuals. At inference, for each unseen graph, the logistic regressor identifies the best counterfactual candidate using these learned weights, while the GAEs can be iteratively updated to represent the continual adaptation of the learned graph representation over iterations. DyGRACE is quite effective and can act as a drift detector, identifying distributional drift based on differences in reconstruction errors between iterations. It avoids reliance on the oracle's predictions in successive iterations, thereby increasing the efficiency of counterfactual discovery. DyGRACE, with its capacity for contrastive learning and drift detection, will offer new avenues for semi-supervised learning and explanation generation.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的半supervised图CounterfactualExplainer（GCE）方法，即动态图CounterfactualExplainer（DyGRACE）。它利用初始数据分布的知识来搜索有效的counterfactuals，而不是使用可能已经过时的决策函数。使用两个图自动encoder（GAEs），DyGRACE学习了每个类型在二分类场景中的表示。在训练过程中，GAEs minimizes the reconstruction error between the original graph and its learned representation。方法包括（i）通过maximizing the factual autoencoder's reconstruction error来优化一个parametric density function（实际上是一个логистиック回归函数）来标识counterfactuals，（ii）minimize the counterfactual autoencoder's error，和（iii）maximize the similarity between the factual and counterfactual graphs。这种半supervised的方法不依赖于下一个黑盒模型的预测。一个логистиック回归模型在一组图对上训练，以便在每个未看过的图上标识最佳counterfactual候选者，而GAEs可以在迭代过程中不断更新以表示learned graph representation的持续适应。DyGRACE非常有效，可以作为分布检测器，基于不同迭代的reconstruction error来发现分布的变化。它不依赖于下一个黑盒模型的预测，从而提高了对counterfactual的发现效率。DyGRACE，拥有对比学习和分布检测的能力，将为半supervised学习和解释生成提供新的 Avenues。
</details></li>
</ul>
<hr>
<h2 id="RobustMQ-Benchmarking-Robustness-of-Quantized-Models"><a href="#RobustMQ-Benchmarking-Robustness-of-Quantized-Models" class="headerlink" title="RobustMQ: Benchmarking Robustness of Quantized Models"></a>RobustMQ: Benchmarking Robustness of Quantized Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02350">http://arxiv.org/abs/2308.02350</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yisong Xiao, Aishan Liu, Tianyuan Zhang, Haotong Qin, Jinyang Guo, Xianglong Liu</li>
<li>for: 评估量化神经网络模型的可靠性和稳定性在具有限制资源的设备上的部署。</li>
<li>methods: 对于不同类型的噪声（攻击性噪声、自然噪声和系统性噪声）进行了全面的评估，并结合了已有的可靠性评估原则，以提供完整和有价值的发现。</li>
<li>results: 研究发现，量化模型对于不同类型的噪声 exhibit 不同的抵抗性，例如：量化模型在攻击性噪声方面具有更高的抵抗性，但在自然噪声和系统性噪声方面更容易受到影响；随着量化比特宽的增加，对于攻击性噪声的抵抗性下降，对于自然噪声和系统性噪声的抵抗性增加。<details>
<summary>Abstract</summary>
Quantization has emerged as an essential technique for deploying deep neural networks (DNNs) on devices with limited resources. However, quantized models exhibit vulnerabilities when exposed to various noises in real-world applications. Despite the importance of evaluating the impact of quantization on robustness, existing research on this topic is limited and often disregards established principles of robustness evaluation, resulting in incomplete and inconclusive findings. To address this gap, we thoroughly evaluated the robustness of quantized models against various noises (adversarial attacks, natural corruptions, and systematic noises) on ImageNet. The comprehensive evaluation results empirically provide valuable insights into the robustness of quantized models in various scenarios, for example: (1) quantized models exhibit higher adversarial robustness than their floating-point counterparts, but are more vulnerable to natural corruptions and systematic noises; (2) in general, increasing the quantization bit-width results in a decrease in adversarial robustness, an increase in natural robustness, and an increase in systematic robustness; (3) among corruption methods, \textit{impulse noise} and \textit{glass blur} are the most harmful to quantized models, while \textit{brightness} has the least impact; (4) among systematic noises, the \textit{nearest neighbor interpolation} has the highest impact, while bilinear interpolation, cubic interpolation, and area interpolation are the three least harmful. Our research contributes to advancing the robust quantization of models and their deployment in real-world scenarios.
</details>
<details>
<summary>摘要</summary>
量化技术已成为深度神经网络（DNNs）部署在有限资源设备上的重要手段。然而，量化模型在实际应用中容易受到各种噪音的影响，这些噪音包括攻击性的攻击、自然损害和系统性的噪音。despite the importance of evaluating the impact of quantization on robustness, existing research on this topic is limited and often disregards established principles of robustness evaluation, resulting in incomplete and inconclusive findings. To address this gap, we thoroughly evaluated the robustness of quantized models against various noises (adversarial attacks, natural corruptions, and systematic noises) on ImageNet. The comprehensive evaluation results empirically provide valuable insights into the robustness of quantized models in various scenarios, for example:1. 量化模型对攻击性攻击 exhibit higher robustness than their floating-point counterparts, but are more vulnerable to natural corruptions and systematic noises;2. in general, increasing the quantization bit-width results in a decrease in adversarial robustness, an increase in natural robustness, and an increase in systematic robustness;3. among corruption methods, impulse noise and glass blur are the most harmful to quantized models, while brightness has the least impact;4. among systematic noises, the nearest neighbor interpolation has the highest impact, while bilinear interpolation, cubic interpolation, and area interpolation are the three least harmful.Our research contributes to advancing the robust quantization of models and their deployment in real-world scenarios.
</details></li>
</ul>
<hr>
<h2 id="Vehicles-Control-Collision-Avoidance-using-Federated-Deep-Reinforcement-Learning"><a href="#Vehicles-Control-Collision-Avoidance-using-Federated-Deep-Reinforcement-Learning" class="headerlink" title="Vehicles Control: Collision Avoidance using Federated Deep Reinforcement Learning"></a>Vehicles Control: Collision Avoidance using Federated Deep Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02614">http://arxiv.org/abs/2308.02614</a></li>
<li>repo_url: None</li>
<li>paper_authors: Badr Ben Elallid, Amine Abouaomar, Nabil Benamar, Abdellatif Kobbane</li>
<li>for: 运输管理和安全性问题在城市化社会中日益严重，因此开发智能控制系统成为急需。</li>
<li>methods: 本研究使用联边深度强化学习（FDRL）技术来实现车辆控制的最佳化。</li>
<li>results: FDDPG算法比DDPG更有效地控制车辆，预防碰撞和提高平均速度。<details>
<summary>Abstract</summary>
In the face of growing urban populations and the escalating number of vehicles on the roads, managing transportation efficiently and ensuring safety have become critical challenges. To tackle these issues, the development of intelligent control systems for vehicles is paramount. This paper presents a comprehensive study on vehicle control for collision avoidance, leveraging the power of Federated Deep Reinforcement Learning (FDRL) techniques. Our main goal is to minimize travel delays and enhance the average speed of vehicles while prioritizing safety and preserving data privacy. To accomplish this, we conducted a comparative analysis between the local model, Deep Deterministic Policy Gradient (DDPG), and the global model, Federated Deep Deterministic Policy Gradient (FDDPG), to determine their effectiveness in optimizing vehicle control for collision avoidance. The results obtained indicate that the FDDPG algorithm outperforms DDPG in terms of effectively controlling vehicles and preventing collisions. Significantly, the FDDPG-based algorithm demonstrates substantial reductions in travel delays and notable improvements in average speed compared to the DDPG algorithm.
</details>
<details>
<summary>摘要</summary>
面对城市人口增长和交通量的增加，有效地管理交通和保障安全已成为急需解决的挑战。为了应对这些问题，智能控制系统的开发 для车辆已成为核心。本文通过 Federated Deep Reinforcement Learning（FDRL）技术来进行全面的研究，以最大化车辆控制的效率和安全性。我们的主要目标是减少交通延迟和提高车辆的平均速度，同时保持数据隐私。为达到这个目标，我们进行了本地模型（DDPG）和全球模型（FDDPG）的比较分析，以确定它们在避免碰撞方面的效果。结果表明，使用 FDDPG 算法可以更好地控制车辆，避免碰撞。特别是，基于 FDDPG 算法的方法在减少交通延迟和提高车辆的平均速度方面表现出了明显的改善。
</details></li>
</ul>
<hr>
<h2 id="Recurrent-Neural-Networks-with-more-flexible-memory-better-predictions-than-rough-volatility"><a href="#Recurrent-Neural-Networks-with-more-flexible-memory-better-predictions-than-rough-volatility" class="headerlink" title="Recurrent Neural Networks with more flexible memory: better predictions than rough volatility"></a>Recurrent Neural Networks with more flexible memory: better predictions than rough volatility</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08550">http://arxiv.org/abs/2308.08550</a></li>
<li>repo_url: None</li>
<li>paper_authors: Damien Challet, Vincent Ragel</li>
<li>for: 这篇论文是为了提高残差预测的能力而写的。</li>
<li>methods: 这篇论文使用了扩展的LSTM网络，其中每个输出维度都包含了多个灵活的时间尺度。</li>
<li>results: 对比vanilla LSTM和扩展LSTM，扩展LSTM需要训练两倍多的epoch数，但是验证和测试loss的变化更小。此外，使用最小验证损失的模型可以系统性地超过20%的粗略预测值。<details>
<summary>Abstract</summary>
We extend recurrent neural networks to include several flexible timescales for each dimension of their output, which mechanically improves their abilities to account for processes with long memory or with highly disparate time scales. We compare the ability of vanilla and extended long short term memory networks (LSTMs) to predict asset price volatility, known to have a long memory. Generally, the number of epochs needed to train extended LSTMs is divided by two, while the variation of validation and test losses among models with the same hyperparameters is much smaller. We also show that the model with the smallest validation loss systemically outperforms rough volatility predictions by about 20% when trained and tested on a dataset with multiple time series.
</details>
<details>
<summary>摘要</summary>
我们将回传神经网络扩展为每个输出维度中包含多个灵活时间尺度，这会机械地提高它们在处理长期记忆过程或高度不同时间尺度的能力。我们将vanilla和延长的长期快Memory网络（LSTM）用于预测资产波动性，知道具有长期记忆。通常，对于延长LSTM的训练需要的轮数比vanilla要少半，而模型之间的验证和测试损失的变化也变得较小。此外，我们还发现使用 smallest validation loss的模型系统地超过20%的粗糙波动预测。Note: " Simplified Chinese" is also known as "Mandarin" or "Standard Chinese".
</details></li>
</ul>
<hr>
<h2 id="Stability-and-Generalization-of-Hypergraph-Collaborative-Networks"><a href="#Stability-and-Generalization-of-Hypergraph-Collaborative-Networks" class="headerlink" title="Stability and Generalization of Hypergraph Collaborative Networks"></a>Stability and Generalization of Hypergraph Collaborative Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02347">http://arxiv.org/abs/2308.02347</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Ng, Hanrui Wu, Andy Yip</li>
<li>for: 本文旨在证明核心层的稳定性和泛化保证，以验证 Hypergraph Collaborative Networks（HCNN）在半监督学习任务中的效果。</li>
<li>methods: 本文使用 Hypergraph Collaborative Networks（HCNN），并提出了一种基于对称矩阵的核心层的稳定性分析方法。</li>
<li>results: 实验结果表明，HCNN在实际数据上具有较高的稳定性和泛化能力，并且可以在半监督学习任务中获得更好的性能。<details>
<summary>Abstract</summary>
Graph neural networks have been shown to be very effective in utilizing pairwise relationships across samples. Recently, there have been several successful proposals to generalize graph neural networks to hypergraph neural networks to exploit more complex relationships. In particular, the hypergraph collaborative networks yield superior results compared to other hypergraph neural networks for various semi-supervised learning tasks. The collaborative network can provide high quality vertex embeddings and hyperedge embeddings together by formulating them as a joint optimization problem and by using their consistency in reconstructing the given hypergraph. In this paper, we aim to establish the algorithmic stability of the core layer of the collaborative network and provide generalization guarantees. The analysis sheds light on the design of hypergraph filters in collaborative networks, for instance, how the data and hypergraph filters should be scaled to achieve uniform stability of the learning process. Some experimental results on real-world datasets are presented to illustrate the theory.
</details>
<details>
<summary>摘要</summary>
图 neural network 已经被证明可以非常有效地利用邻居关系来进行样本之间的对应。最近，有几种成功的提议来扩展图 neural network 到 hypergraph neural network，以利用更复杂的关系。特别是，在 hypergraph 协作网络中，得到的结果比其他 hypergraph neural network 更好，用于各种半监督学习任务。协作网络可以同时提供高质量的顶点嵌入和 гипер边嵌入，通过将它们定义为一个共同优化问题，并通过它们在重建给定的 hypergraph 中的一致性来实现这一点。在这篇论文中，我们想要证明协作网络核心层的算法稳定性，并提供一致性保证。分析推出了协作网络中的 гиперграhp 筛子设计方法，例如如何在数据和 гиперграф筛子上进行扫描，以实现学习过程的均匀稳定性。一些实验结果在真实世界数据上进行了描述，以证明理论。
</details></li>
</ul>
<hr>
<h2 id="Learning-Networks-from-Gaussian-Graphical-Models-and-Gaussian-Free-Fields"><a href="#Learning-Networks-from-Gaussian-Graphical-Models-and-Gaussian-Free-Fields" class="headerlink" title="Learning Networks from Gaussian Graphical Models and Gaussian Free Fields"></a>Learning Networks from Gaussian Graphical Models and Gaussian Free Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02344">http://arxiv.org/abs/2308.02344</a></li>
<li>repo_url: None</li>
<li>paper_authors: Subhro Ghosh, Soumendu Sundar Mukherjee, Hoang-Son Tran, Ujan Gangopadhyay</li>
<li>for: 该论文旨在估计权重网络的结构从重复测量 Gaussian Graphical Model (GGM) 中获得。</li>
<li>methods: 该论文提出了一种新的估计器，基于 Gaussian Free Field (GFF) 的 Fourier分析性质，用于估计权重网络（等价地，其 Laplacian）。</li>
<li>results: 该论文提供了具体的恢复保证和样本复杂度下的界限，证明该估计器可以达到参数率的估计。在 Erdos-Renyi 随机图 $G(d,p)$ 上，当样本大小 $n$ 大于 $d^4 \log d \cdot p^{-2}$ 时，可以高probability 地recovery网络结构。<details>
<summary>Abstract</summary>
We investigate the problem of estimating the structure of a weighted network from repeated measurements of a Gaussian Graphical Model (GGM) on the network. In this vein, we consider GGMs whose covariance structures align with the geometry of the weighted network on which they are based. Such GGMs have been of longstanding interest in statistical physics, and are referred to as the Gaussian Free Field (GFF). In recent years, they have attracted considerable interest in the machine learning and theoretical computer science. In this work, we propose a novel estimator for the weighted network (equivalently, its Laplacian) from repeated measurements of a GFF on the network, based on the Fourier analytic properties of the Gaussian distribution. In this pursuit, our approach exploits complex-valued statistics constructed from observed data, that are of interest on their own right. We demonstrate the effectiveness of our estimator with concrete recovery guarantees and bounds on the required sample complexity. In particular, we show that the proposed statistic achieves the parametric rate of estimation for fixed network size. In the setting of networks growing with sample size, our results show that for Erdos-Renyi random graphs $G(d,p)$ above the connectivity threshold, we demonstrate that network recovery takes place with high probability as soon as the sample size $n$ satisfies $n \gg d^4 \log d \cdot p^{-2}$.
</details>
<details>
<summary>摘要</summary>
我们研究了从重复观测 Gaussian Graphical Model (GGM) 中Estimating the structure of a weighted network的问题。在这种情况下，我们考虑 GGM 的均值结构和weighted network的geometry相互关联。这些 GGM 在统计物理中已经受到了长期的关注，被称为 Gaussian Free Field (GFF)。在最近几年，它们在机器学习和理论计算机科学中也获得了很多关注。在这个工作中，我们提出了一个新的Weighted network的Estimator，基于 GFF 的对称性和当中的观测数据的傅立做�� statistiche的对���能�能。我们的方法利用了观测数据中的复数统计，具有对���能�能的实际价值。我们显示了我们的检测器具有固定网络大小的 parametric 速率，并且在网络规模 growing 的情况下，我们显示了当 Erdos-Renyi 随机网络 $G(d,p)$ 的connectivity阈值以上时，网络重建很可能会在高概率下发生。具体来说，我们显示了 $n \gg d^4 \log d \cdot p^{-2}$ 的 sample size 下，网络重建很可能会在高概率下发生。
</details></li>
</ul>
<hr>
<h2 id="RAHNet-Retrieval-Augmented-Hybrid-Network-for-Long-tailed-Graph-Classification"><a href="#RAHNet-Retrieval-Augmented-Hybrid-Network-for-Long-tailed-Graph-Classification" class="headerlink" title="RAHNet: Retrieval Augmented Hybrid Network for Long-tailed Graph Classification"></a>RAHNet: Retrieval Augmented Hybrid Network for Long-tailed Graph Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02335">http://arxiv.org/abs/2308.02335</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengyang Mao, Wei Ju, Yifang Qin, Xiao Luo, Ming Zhang</li>
<li>for: 提高图像分类 tasks 中的抗衰减性能</li>
<li>methods: 提出了一种名为 Retrieval Augmented Hybrid Network (RAHNet) 的新框架，该框架可以同时学习一个 Robust 的特征提取器和一个不偏向的分类器，并在Feature extractor 阶段开发了一个图像检索模块，以增强tail classes 的内部多样性。</li>
<li>results: 对多个流行的 Benchmark 进行了实验，并证明了提出的方法与现有方法相比具有显著的优势。<details>
<summary>Abstract</summary>
Graph classification is a crucial task in many real-world multimedia applications, where graphs can represent various multimedia data types such as images, videos, and social networks. Previous efforts have applied graph neural networks (GNNs) in balanced situations where the class distribution is balanced. However, real-world data typically exhibit long-tailed class distributions, resulting in a bias towards the head classes when using GNNs and limited generalization ability over the tail classes. Recent approaches mainly focus on re-balancing different classes during model training, which fails to explicitly introduce new knowledge and sacrifices the performance of the head classes. To address these drawbacks, we propose a novel framework called Retrieval Augmented Hybrid Network (RAHNet) to jointly learn a robust feature extractor and an unbiased classifier in a decoupled manner. In the feature extractor training stage, we develop a graph retrieval module to search for relevant graphs that directly enrich the intra-class diversity for the tail classes. Moreover, we innovatively optimize a category-centered supervised contrastive loss to obtain discriminative representations, which is more suitable for long-tailed scenarios. In the classifier fine-tuning stage, we balance the classifier weights with two weight regularization techniques, i.e., Max-norm and weight decay. Experiments on various popular benchmarks verify the superiority of the proposed method against state-of-the-art approaches.
</details>
<details>
<summary>摘要</summary>
图像分类是现实世界多媒体应用中的一项重要任务，图像可以表示各种多媒体数据类型，如图像、视频和社交网络。先前的努力主要采用图像神经网络（GNN）在平衡的情况下进行分类，但实际数据通常会出现长尾类分布，导致使用GNN时偏向头类，并且对尾类的泛化能力有限。现有的方法主要是在模型训练过程中重新平衡不同类别，但这会失去新知识的引入和头类性能的牺牲。为解决这些缺陷，我们提出了一种新的框架，即Retrieval Augmented Hybrid Network（RAHNet），用于同时学习一个可靠的特征提取器和一个不偏向的分类器。在特征提取器训练阶段，我们开发了一个图像检索模块，用于搜索与尾类相关的图像，以直接增强尾类之间的内部多样性。此外，我们还创新地优化了一种类型中心的自适应对比损失函数，以获得适应长尾enario的特征表示，这更适合长尾分布的情况。在分类器精度调整阶段，我们使用两种质量规则技术，即最大 нор化和权重衰减，来均衡分类器的权重。实验表明，我们的方法在各种流行的标准准则上表现出色，胜过当前的状态艺术方法。
</details></li>
</ul>
<hr>
<h2 id="Interoperable-synthetic-health-data-with-SyntHIR-to-enable-the-development-of-CDSS-tools"><a href="#Interoperable-synthetic-health-data-with-SyntHIR-to-enable-the-development-of-CDSS-tools" class="headerlink" title="Interoperable synthetic health data with SyntHIR to enable the development of CDSS tools"></a>Interoperable synthetic health data with SyntHIR to enable the development of CDSS tools</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02613">http://arxiv.org/abs/2308.02613</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/potter-coder89/synthir">https://github.com/potter-coder89/synthir</a></li>
<li>paper_authors: Pavitra Chauhan, Mohsen Gamal Saad Askar, Bjørn Fjukstad, Lars Ailo Bongo, Edvard Pedersen</li>
<li>for: 该论文目的是提出一种基于Synthetic Health Information Resources（SyntHIR）架构的临床决策支持系统（CDSS）开发方法，以便在临床工作流程中实现CDSS工具的开发和测试。</li>
<li>methods: 该论文使用了Fast Healthcare Interoperability Resources（FHIR）标准实现数据互操作性，使用Gretel框架生成假数据，Microsoft Azure FHIR服务器作为基于FHIR的电子健康记录（EHR）系统，以及SMART on FHIR框架实现工具传输性。</li>
<li>results: 作者使用挪威病人登记（NPR）和挪威药物额度（NorPD）的数据开发了一种基于机器学习的CDSS工具，并在SyntHIR系统上测试了该工具。然后，他们将该工具提升到Open DIPS环境中进行测试。结论，SyntHIR提供了一个通用的CDSS工具开发架构，使用假FHIR数据进行测试，并提供了一个可用的测试环境。然而，在生成假数据方面，还有一定的可改进空间。代码可以在<a target="_blank" rel="noopener" href="https://github.com/potter-coder89/SyntHIR.git%E4%B8%AD%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/potter-coder89/SyntHIR.git中获取。</a><details>
<summary>Abstract</summary>
There is a great opportunity to use high-quality patient journals and health registers to develop machine learning-based Clinical Decision Support Systems (CDSS). To implement a CDSS tool in a clinical workflow, there is a need to integrate, validate and test this tool on the Electronic Health Record (EHR) systems used to store and manage patient data. However, it is often not possible to get the necessary access to an EHR system due to legal compliance. We propose an architecture for generating and using synthetic EHR data for CDSS tool development. The architecture is implemented in a system called SyntHIR. The SyntHIR system uses the Fast Healthcare Interoperability Resources (FHIR) standards for data interoperability, the Gretel framework for generating synthetic data, the Microsoft Azure FHIR server as the FHIR-based EHR system and SMART on FHIR framework for tool transportability. We demonstrate the usefulness of SyntHIR by developing a machine learning-based CDSS tool using data from the Norwegian Patient Register (NPR) and Norwegian Patient Prescriptions (NorPD). We demonstrate the development of the tool on the SyntHIR system and then lift it to the Open DIPS environment. In conclusion, SyntHIR provides a generic architecture for CDSS tool development using synthetic FHIR data and a testing environment before implementing it in a clinical setting. However, there is scope for improvement in terms of the quality of the synthetic data generated. The code is open source and available at https://github.com/potter-coder89/SyntHIR.git.
</details>
<details>
<summary>摘要</summary>
“有一大机会使用高品质的病人日记和健康登记来开发机器学习型临床决策支持系统（CDSS）。实现CDSS工具在临床工作流程中的实现，需要与电子健康纪录（EHR）系统集成、验证和测试这个工具。然而，由于法律合规，常常无法获得EHR系统的必要存取权。我们提出了一个架构，用于生成和使用合成EHR数据来开发CDSS工具。这个架构是在SyntHIR系统中实现的。SyntHIR系统使用了快速医疗通信资源（FHIR）标准来实现数据互操作，使用Gretel框架生成合成数据，使用Microsoft Azure FHIR服务器作为基于FHIR的EHR系统，并使用SMART on FHIR框架来实现工具可移性。我们透过使用挪威病人登记（NPR）和挪威病人处方（NorPD）的数据，展示了这个工具的开发和运用。我们首先在SyntHIR系统上开发了这个工具，然后将其升级到Open DIPS环境。在结论中，SyntHIR提供了一个通用的架构，用于CDSS工具的开发使用合成FHIR数据，以及一个可用的测试环境，以便在临床设置中实现。然而，这个架构中的合成数据质量仍然有改进的空间。代码可以在https://github.com/potter-coder89/SyntHIR.git中取得。”
</details></li>
</ul>
<hr>
<h2 id="Deep-learning-for-spike-detection-in-deep-brain-stimulation-surgery"><a href="#Deep-learning-for-spike-detection-in-deep-brain-stimulation-surgery" class="headerlink" title="Deep learning for spike detection in deep brain stimulation surgery"></a>Deep learning for spike detection in deep brain stimulation surgery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05755">http://arxiv.org/abs/2308.05755</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arkadiusz Nowacki, Ewelina Kołpa, Mateusz Szychiewicz, Konrad Ciecierski</li>
<li>for: 这个论文是为了描述一种基于深度学习的神经活动记录分析方法，用于诊断parkinson病。</li>
<li>methods: 该方法使用了一种卷积神经网络（CNN）来分析记录的神经活动。</li>
<li>results: 实验结果表明，该方法可以达到98.98%的最高准确率和0.9898的接受收操作特征曲线值。<details>
<summary>Abstract</summary>
Deep brain stimulation (DBS) is a neurosurgical procedure successfully used to treat conditions such as Parkinson's disease. Electrostimulation, carried out by implanting electrodes into an identified focus in the brain, makes it possible to reduce the symptoms of the disease significantly. In this paper, a method for analyzing recordings of neuronal activity acquired during DBS neurosurgery using deep learning is presented. We tested using a convolutional neural network (CNN) for this purpose. Based on the time window, the classifier assesses whether neuronal activity (spike) is present. The maximum accuracy value for the classifier was 98.98%, and the area under the receiver operating characteristic curve (AUC) was 0.9898. The method made it possible to obtain a classification without using data preprocessing.
</details>
<details>
<summary>摘要</summary>
深度脑刺激（DBS）是一种成功地用于治疗parkinson病的 neurosurgical procedure。通过在脑中implanting electrodes，可以使得脑动力学性的症状减轻。在这篇论文中，一种使用深度学习分析DBS neurosurgery记录的方法被提出。我们使用了卷积神经网络（CNN）来实现这一目的。根据时间窗口，分类器评估神经活动（脉冲）是否存在。最大的准确率值为98.98%，受测频谱特征曲线（AUC）的值为0.9898。这种方法可以不使用数据预处理来获得分类。
</details></li>
</ul>
<hr>
<h2 id="A-stochastic-optimization-approach-to-train-non-linear-neural-networks-with-a-higher-order-variation-regularization"><a href="#A-stochastic-optimization-approach-to-train-non-linear-neural-networks-with-a-higher-order-variation-regularization" class="headerlink" title="A stochastic optimization approach to train non-linear neural networks with a higher-order variation regularization"></a>A stochastic optimization approach to train non-linear neural networks with a higher-order variation regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02293">http://arxiv.org/abs/2308.02293</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oknakfm/hovr">https://github.com/oknakfm/hovr</a></li>
<li>paper_authors: Akifumi Okuno</li>
<li>for: 本研究旨在Addressing the issue of overfitting in highly expressive parametric models, such as deep neural networks, by introducing a $(k,q)$th order variation regularization ($(k,q)$-VR).</li>
<li>methods: 本研究提出了一种 Stochastic optimization algorithm，可以高效地训练普通模型和深度神经网络，并且不需要显式的数学 интеграル。</li>
<li>results: 数字实验表明，使用 $(k,q)$-VR regularization可以使神经网络更“鲜硬”，比传统参数规范化更有效。此外，该方法还可以应用于物理学信息训练神经网络（PINNs）。<details>
<summary>Abstract</summary>
While highly expressive parametric models including deep neural networks have an advantage to model complicated concepts, training such highly non-linear models is known to yield a high risk of notorious overfitting. To address this issue, this study considers a $(k,q)$th order variation regularization ($(k,q)$-VR), which is defined as the $q$th-powered integral of the absolute $k$th order derivative of the parametric models to be trained; penalizing the $(k,q)$-VR is expected to yield a smoother function, which is expected to avoid overfitting. Particularly, $(k,q)$-VR encompasses the conventional (general-order) total variation with $q=1$. While the $(k,q)$-VR terms applied to general parametric models are computationally intractable due to the integration, this study provides a stochastic optimization algorithm, that can efficiently train general models with the $(k,q)$-VR without conducting explicit numerical integration. The proposed approach can be applied to the training of even deep neural networks whose structure is arbitrary, as it can be implemented by only a simple stochastic gradient descent algorithm and automatic differentiation. Our numerical experiments demonstrate that the neural networks trained with the $(k,q)$-VR terms are more ``resilient'' than those with the conventional parameter regularization. The proposed algorithm also can be extended to the physics-informed training of neural networks (PINNs).
</details>
<details>
<summary>摘要</summary>
“高度表达性的 parametric 模型，如深度神经网络，具有模型复杂概念的优势。然而，训练这些非线性模型可能会导致恶性适应。为解决这个问题，本研究考虑了 $(k,q)$ 次变化正则化（$(k,q)$-VR），它是指要训练的 parametric 模型的 $q$ 次幂的绝对 $k$ 次导数的积分；减少 $(k,q)$-VR 会导致更平滑的函数，以避免适应。特别是，$(k,q)$-VR 包括普通（一般顺序）总变量，即 $q=1$。然而，$(k,q)$-VR 应用于普通 parametric 模型是计算易于实现的，这里的研究提供了一种随机优化算法，可以高效地训练普通模型并且不需要显式的数值积分。这种方法可以应用于深度神经网络的训练，其结构可以是任意的，只需使用简单的随机梯度下降算法和自动微分。我们的数值实验表明，使用 $(k,q)$-VR 项训练的神经网络比使用传统参数正则化更为“抗耗”。此外，该算法还可以扩展到物理学 informed 神经网络（PINNs）的训练。”
</details></li>
</ul>
<hr>
<h2 id="Frustratingly-Easy-Model-Generalization-by-Dummy-Risk-Minimization"><a href="#Frustratingly-Easy-Model-Generalization-by-Dummy-Risk-Minimization" class="headerlink" title="Frustratingly Easy Model Generalization by Dummy Risk Minimization"></a>Frustratingly Easy Model Generalization by Dummy Risk Minimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02287">http://arxiv.org/abs/2308.02287</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juncheng Wang, Jindong Wang, Xixu Hu, Shujun Wang, Xing Xie</li>
<li>for: 提高机器学习模型的通用能力</li>
<li>methods: 使用拟合风险最小化(DuRM)技术，即通过扩大输出LOGITS维度，然后使用标准的梯度下降优化</li>
<li>results: 在多种任务上，包括普通分类、语义分割、 OUT-OF-distribution泛化、对抗训练和长尾识别等，DuRM能够一般性地提高模型的表现，并且可以与现有的通用技术相结合<details>
<summary>Abstract</summary>
Empirical risk minimization (ERM) is a fundamental machine learning paradigm. However, its generalization ability is limited in various tasks. In this paper, we devise Dummy Risk Minimization (DuRM), a frustratingly easy and general technique to improve the generalization of ERM. DuRM is extremely simple to implement: just enlarging the dimension of the output logits and then optimizing using standard gradient descent. Moreover, we validate the efficacy of DuRM on both theoretical and empirical analysis. Theoretically, we show that DuRM derives greater variance of the gradient, which facilitates model generalization by observing better flat local minima. Empirically, we conduct evaluations of DuRM across different datasets, modalities, and network architectures on diverse tasks, including conventional classification, semantic segmentation, out-of-distribution generalization, adverserial training, and long-tailed recognition. Results demonstrate that DuRM could consistently improve the performance under all tasks with an almost free lunch manner. Furthermore, we show that DuRM is compatible with existing generalization techniques and we discuss possible limitations. We hope that DuRM could trigger new interest in the fundamental research on risk minimization.
</details>
<details>
<summary>摘要</summary>
empirical risk minimization (ERM) 是机器学习的基本思想之一，但它在各种任务中的泛化能力有限。在这篇论文中，我们提出了干扰风险最小化（DuRM），一种简单易行但具有普遍性的技术，以提高ERM的泛化能力。DuRM的实现非常简单：首先扩大输出логи特的维度，然后使用标准的梯度下降优化。我们在理论和实验两个方面 validate DuRM的有效性。从理论上看，我们表明DuRM可以提高模型的泛化能力，通过在更好的平坦的地方找到更好的地方的梯度。从实验来看，我们在不同的数据集、模式和网络架构上进行了多种任务的评估，包括传统的分类、 semantic segmentation、out-of-distribution泛化、对抗训练和长尾识别。结果表明，DuRM可以在所有任务上提高性能，几乎没有代价。此外，我们还证明了DuRM与现有的泛化技术相容，并讨论了可能的局限性。我们希望DuRM可以引起新的研究兴趣，关于风险最小化的基础研究。
</details></li>
</ul>
<hr>
<h2 id="DIVERSIFY-A-General-Framework-for-Time-Series-Out-of-distribution-Detection-and-Generalization"><a href="#DIVERSIFY-A-General-Framework-for-Time-Series-Out-of-distribution-Detection-and-Generalization" class="headerlink" title="DIVERSIFY: A General Framework for Time Series Out-of-distribution Detection and Generalization"></a>DIVERSIFY: A General Framework for Time Series Out-of-distribution Detection and Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02282">http://arxiv.org/abs/2308.02282</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wang Lu, Jindong Wang, Xinwei Sun, Yiqiang Chen, Xiangyang Ji, Qiang Yang, Xing Xie</li>
<li>for: 这篇论文旨在解决时间序列资料的机器学习挑战，尤其是当时间序列资料的分布变化时，存在许多挑战。</li>
<li>methods: 本论文提出了一个称为DIVERSIFY的框架，用于检测时间序列资料的异常挑战和扩展。DIVERSIFY使用了一个迭代的过程，首先通过对网络的挑战性训练获得最差的对应分布enario，然后将这些分布enario与基本分布的差异仪化。</li>
<li>results: 实验结果显示，DIVERSIFY可以对时间序列资料的扩展和异常检测进行更好的检测和分类，并且与其他基准相比有着优秀的性能。<details>
<summary>Abstract</summary>
Time series remains one of the most challenging modalities in machine learning research. The out-of-distribution (OOD) detection and generalization on time series tend to suffer due to its non-stationary property, i.e., the distribution changes over time. The dynamic distributions inside time series pose great challenges to existing algorithms to identify invariant distributions since they mainly focus on the scenario where the domain information is given as prior knowledge. In this paper, we attempt to exploit subdomains within a whole dataset to counteract issues induced by non-stationary for generalized representation learning. We propose DIVERSIFY, a general framework, for OOD detection and generalization on dynamic distributions of time series. DIVERSIFY takes an iterative process: it first obtains the "worst-case" latent distribution scenario via adversarial training, then reduces the gap between these latent distributions. We implement DIVERSIFY via combining existing OOD detection methods according to either extracted features or outputs of models for detection while we also directly utilize outputs for classification. In addition, theoretical insights illustrate that DIVERSIFY is theoretically supported. Extensive experiments are conducted on seven datasets with different OOD settings across gesture recognition, speech commands recognition, wearable stress and affect detection, and sensor-based human activity recognition. Qualitative and quantitative results demonstrate that DIVERSIFY learns more generalized features and significantly outperforms other baselines.
</details>
<details>
<summary>摘要</summary>
时序序列仍然是机器学习研究中最为困难的模式之一。它的非站立性性会导致模型在不同时间点上的分布变化，从而使得泛化检测和泛化学习受到挑战。我们提出了一种解决方案，即DIVERSIFY，用于对动态分布的时序序列进行泛化检测和泛化学习。DIVERSIFY采用迭代过程，首先通过对恶性情况下的射频分布进行反对抗训练，然后减少这些射频分布之间的差距。我们通过将现有的OOD检测方法与特定的特征或模型输出结合使用来实现DIVERSIFY。此外，我们还提供了理论启示，表明DIVERSIFY的理论基础。我们在七个不同的数据集上进行了广泛的实验，结果表明DIVERSIFY可以更好地学习通用的特征，并与其他基eline大大超越。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Proximal-Gradient-Method-for-Convex-Optimization"><a href="#Adaptive-Proximal-Gradient-Method-for-Convex-Optimization" class="headerlink" title="Adaptive Proximal Gradient Method for Convex Optimization"></a>Adaptive Proximal Gradient Method for Convex Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02261">http://arxiv.org/abs/2308.02261</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yura Malitsky, Konstantin Mishchenko</li>
<li>for: 本研究探讨了两种基本的第一阶段算法在凸优化中，即梯度下降（GD）和距离梯度方法（ProxGD）。我们的研究重点在于使这些算法完全适应性的，利用当地的凸函数的曲率信息。</li>
<li>methods: 我们提出了基于观察到的梯度差的自适应GD和ProxGD版本，无需额外的计算成本。此外，我们证明了我们的方法在只假设当地的梯度 Lipschitz 性的情况下 converges。</li>
<li>results: 我们的方法可以使用更大的步长than those initially suggested in [MM20]。<details>
<summary>Abstract</summary>
In this paper, we explore two fundamental first-order algorithms in convex optimization, namely, gradient descent (GD) and proximal gradient method (ProxGD). Our focus is on making these algorithms entirely adaptive by leveraging local curvature information of smooth functions. We propose adaptive versions of GD and ProxGD that are based on observed gradient differences and, thus, have no added computational costs. Moreover, we prove convergence of our methods assuming only local Lipschitzness of the gradient. In addition, the proposed versions allow for even larger stepsizes than those initially suggested in [MM20].
</details>
<details>
<summary>摘要</summary>
在本文中，我们研究了两种基本的首频算法在凸优化中， namely，梯度下降（GD）和贝叶克梯度方法（ProxGD）。我们的关注点是使这两种算法完全适应性的，利用滑坡函数的本地勋氏度信息。我们提出了基于观察到的梯度差的自适应GD和ProxGD版本，无需额外计算成本。此外，我们证明了我们的方法在假设只有梯度的本地利弗希茨性下都是收敛的。此外，我们的方法还允许更大的步长 чем initially suggested in [MM20].
</details></li>
</ul>
<hr>
<h2 id="Finding-Tori-Self-supervised-Learning-for-Analyzing-Korean-Folk-Song"><a href="#Finding-Tori-Self-supervised-Learning-for-Analyzing-Korean-Folk-Song" class="headerlink" title="Finding Tori: Self-supervised Learning for Analyzing Korean Folk Song"></a>Finding Tori: Self-supervised Learning for Analyzing Korean Folk Song</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02249">http://arxiv.org/abs/2308.02249</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/danbinaerinhan/finding-tori">https://github.com/danbinaerinhan/finding-tori</a></li>
<li>paper_authors: Danbinaerin Han, Rafael Caro Repetto, Dasaem Jeong</li>
<li>for: 这个论文是用计算方法对韩国传统民歌场记录集（约700小时）进行分析的。</li>
<li>methods: 作者使用自动学习的卷积神经网络，基于折衣折射，来解决 dataset 中歌曲由非专业音乐家演唱，没有伴奏的问题。</li>
<li>results: 实验结果表明，作者的方法可以更好地捕捉韩国传统民歌中的折衣特征，比传统的折衣历史图表更加准确。<details>
<summary>Abstract</summary>
In this paper, we introduce a computational analysis of the field recording dataset of approximately 700 hours of Korean folk songs, which were recorded around 1980-90s. Because most of the songs were sung by non-expert musicians without accompaniment, the dataset provides several challenges. To address this challenge, we utilized self-supervised learning with convolutional neural network based on pitch contour, then analyzed how the musical concept of tori, a classification system defined by a specific scale, ornamental notes, and an idiomatic melodic contour, is captured by the model. The experimental result shows that our approach can better capture the characteristics of tori compared to traditional pitch histograms. Using our approaches, we have examined how musical discussions proposed in existing academia manifest in the actual field recordings of Korean folk songs.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了一种计算机分析方法，用于分析约700小时的朝鲜传统民歌场记录数据集，这些歌曲主要由非专业音乐家演唱，没有伴奏。由于这些歌曲具有许多挑战，我们采用了自我超vised学习方法，使用基于折衣的卷积神经网络进行分析。我们发现，我们的方法可以更好地捕捉到韵律折衣的特点，比传统的折衣历史gram相更加精准。通过我们的方法，我们对现有学术研究中的音乐讨论进行了实际场记录的检验。
</details></li>
</ul>
<hr>
<h2 id="Deep-neural-networks-from-the-perspective-of-ergodic-theory"><a href="#Deep-neural-networks-from-the-perspective-of-ergodic-theory" class="headerlink" title="Deep neural networks from the perspective of ergodic theory"></a>Deep neural networks from the perspective of ergodic theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03888">http://arxiv.org/abs/2308.03888</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fan Zhang</li>
<li>for: 这篇论文是用来解释深度神经网络设计的一种方法，即通过ergodic theory来理解网络的时间演化。</li>
<li>methods: 这篇论文使用了ergodic theory来描述网络的时间演化，每层对应一个时间实例。</li>
<li>results: 这篇论文表明，通过这种方法，一些可能看起来神秘的规则可以被归结为启发。<details>
<summary>Abstract</summary>
The design of deep neural networks remains somewhat of an art rather than precise science. By tentatively adopting ergodic theory considerations on top of viewing the network as the time evolution of a dynamical system, with each layer corresponding to a temporal instance, we show that some rules of thumb, which might otherwise appear mysterious, can be attributed heuristics.
</details>
<details>
<summary>摘要</summary>
深度神经网络的设计仍然归于一种艺术化的领域，而不是精确的科学。我们通过将神经网络视为时间演化的动力系统，每层对应于一个时间实例，采用ergodic理论考虑，可以解释一些可能看起来神秘的规则，归为习惯。
</details></li>
</ul>
<hr>
<h2 id="Self-Normalizing-Neural-Network-Enabling-One-Shot-Transfer-Learning-for-Modeling-EDFA-Wavelength-Dependent-Gain"><a href="#Self-Normalizing-Neural-Network-Enabling-One-Shot-Transfer-Learning-for-Modeling-EDFA-Wavelength-Dependent-Gain" class="headerlink" title="Self-Normalizing Neural Network, Enabling One Shot Transfer Learning for Modeling EDFA Wavelength Dependent Gain"></a>Self-Normalizing Neural Network, Enabling One Shot Transfer Learning for Modeling EDFA Wavelength Dependent Gain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02233">http://arxiv.org/abs/2308.02233</a></li>
<li>repo_url: None</li>
<li>paper_authors: Agastya Raj, Zehao Wang, Frank Slyne, Tingjun Chen, Dan Kilper, Marco Ruffini</li>
<li>for: 这 paper 是为了模型多个 EDFA 的波长依赖性增强的 ML 框架。</li>
<li>methods: 这 paper 使用 semi-supervised, self-normalizing neural networks，允许一次转移学习。</li>
<li>results: 实验结果显示，这种方法可以在不同的增强器类型上达到高精度的转移学习。<details>
<summary>Abstract</summary>
We present a novel ML framework for modeling the wavelength-dependent gain of multiple EDFAs, based on semi-supervised, self-normalizing neural networks, enabling one-shot transfer learning. Our experiments on 22 EDFAs in Open Ireland and COSMOS testbeds show high-accuracy transfer-learning even when operated across different amplifier types.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的机器学习框架，用于模型多个电子激发器的波长依赖性增强。我们使用半监督、自适应神经网络，实现一次转移学习。我们的实验表明，even when operated across different amplifier types, our framework can achieve high-accuracy transfer learning on 22 EDFAs in Open Ireland and COSMOS testbeds.Here's a word-for-word translation of the text:我们提出了一种新的机器学习框架，用于模型多个电子激发器的波长依赖性增强。我们使用半监督、自适应神经网络，实现一次转移学习。我们的实验表明，even when operated across different amplifier types, our framework can achieve high-accuracy transfer learning on 22 EDFAs in Open Ireland and COSMOS testbeds.
</details></li>
</ul>
<hr>
<h2 id="Likelihood-ratio-based-confidence-intervals-for-neural-networks"><a href="#Likelihood-ratio-based-confidence-intervals-for-neural-networks" class="headerlink" title="Likelihood-ratio-based confidence intervals for neural networks"></a>Likelihood-ratio-based confidence intervals for neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02221">http://arxiv.org/abs/2308.02221</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/laurenssluyterman/likelihood_ratio_intervals">https://github.com/laurenssluyterman/likelihood_ratio_intervals</a></li>
<li>paper_authors: Laurens Sluijterman, Eric Cator, Tom Heskes</li>
<li>for: 这paper是为了构建神经网络中的信任度范围而实现的首次实现。</li>
<li>methods: 该方法使用了可能性比率来建立神经网络中的信任度范围，具有数量有限的数据区域扩展的能力，以及自动包含了训练时间、网络架构和正则化技术等因素。</li>
<li>results: 该paper表明了可能性比率基于的 uncertainty estimate在医学预测和天文物理等领域可能已经成本较高，但是可能有优势于其他方法。这个研究提出了可能性比率基于的 uncertainty estimate的可能性和未来研究的潜在途径。<details>
<summary>Abstract</summary>
This paper introduces a first implementation of a novel likelihood-ratio-based approach for constructing confidence intervals for neural networks. Our method, called DeepLR, offers several qualitative advantages: most notably, the ability to construct asymmetric intervals that expand in regions with a limited amount of data, and the inherent incorporation of factors such as the amount of training time, network architecture, and regularization techniques. While acknowledging that the current implementation of the method is prohibitively expensive for many deep-learning applications, the high cost may already be justified in specific fields like medical predictions or astrophysics, where a reliable uncertainty estimate for a single prediction is essential. This work highlights the significant potential of a likelihood-ratio-based uncertainty estimate and establishes a promising avenue for future research.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "asymmetric intervals" is translated as "非对称 интерVAL" (fēi duìxìng interVAL), which emphasizes the unequal nature of the intervals.* "incorporate" is translated as "包含" (bāofàn), which means "to contain" or "to include".* "training time" is translated as "训练时间" (xiùxíng shíjiān), which emphasizes the time spent on training the network.* "network architecture" is translated as "网络架构" (wǎngluò jiàgòu), which emphasizes the design of the network.* "regularization techniques" is translated as "规范技术" (guīfáng jìshù), which emphasizes the use of techniques to regularize the network.* "reliable uncertainty estimate" is translated as "可靠的不确定度估计" (kějì de bùxìngdòng dàigè), which emphasizes the accuracy and reliability of the uncertainty estimate.
</details></li>
</ul>
<hr>
<h2 id="Knowledge-Driven-Multi-Agent-Reinforcement-Learning-for-Computation-Offloading-in-Cybertwin-Enabled-Internet-of-Vehicles"><a href="#Knowledge-Driven-Multi-Agent-Reinforcement-Learning-for-Computation-Offloading-in-Cybertwin-Enabled-Internet-of-Vehicles" class="headerlink" title="Knowledge-Driven Multi-Agent Reinforcement Learning for Computation Offloading in Cybertwin-Enabled Internet of Vehicles"></a>Knowledge-Driven Multi-Agent Reinforcement Learning for Computation Offloading in Cybertwin-Enabled Internet of Vehicles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02603">http://arxiv.org/abs/2308.02603</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruijin Sun, Xiao Yang, Nan Cheng, Xiucheng Wang, Changle Li</li>
<li>for: 减少 Civert vehicles 的任务负载延迟</li>
<li>methods: 利用知识驱动多智能体学习（KMARL）方法，选择最佳的下载选项，使用图解学网络，利用域知识来做 permutation 变换和图strucutre 通信 topology 的嵌入</li>
<li>results: 比较其他方法，KMARL 方法可以获得更高的奖励和更好的扩展性，受益于域知识的整合<details>
<summary>Abstract</summary>
By offloading computation-intensive tasks of vehicles to roadside units (RSUs), mobile edge computing (MEC) in the Internet of Vehicles (IoV) can relieve the onboard computation burden. However, existing model-based task offloading methods suffer from heavy computational complexity with the increase of vehicles and data-driven methods lack interpretability. To address these challenges, in this paper, we propose a knowledge-driven multi-agent reinforcement learning (KMARL) approach to reduce the latency of task offloading in cybertwin-enabled IoV. Specifically, in the considered scenario, the cybertwin serves as a communication agent for each vehicle to exchange information and make offloading decisions in the virtual space. To reduce the latency of task offloading, a KMARL approach is proposed to select the optimal offloading option for each vehicle, where graph neural networks are employed by leveraging domain knowledge concerning graph-structure communication topology and permutation invariance into neural networks. Numerical results show that our proposed KMARL yields higher rewards and demonstrates improved scalability compared with other methods, benefitting from the integration of domain knowledge.
</details>
<details>
<summary>摘要</summary>
通过将计算任务转移到路边单元（RSU），移动边缘计算（MEC）在互联网联盟（IoV）中可以减轻车辆上的计算负担。然而，现有的模型基于的任务转移方法受到增加车辆和数据驱动方法的计算复杂性的限制，而数据驱动方法缺乏解释性。为解决这些挑战，在这篇论文中，我们提出了基于知识驱动多代理征分学习（KMARL）的方法，以降低cybertwin-enabled IoV中任务转移延迟。具体来说，在考虑的场景中，cybertwin acts as a communication agent for each vehicle to exchange information and make offloading decisions in the virtual space。为降低任务转移延迟，我们提出了一种基于KMARL的选择最佳转移选项的方法，其中使用了图神经网络，并利用了图结构通信网络和 permutation invariance 的知识来适应各种场景。数据结果表明，我们的提出的KMARL可以获得更高的奖励，并且在扩展性方面表现出色，受到知识 интеграation的利用帮助。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-of-Spanish-Clinical-Language-Models"><a href="#A-Survey-of-Spanish-Clinical-Language-Models" class="headerlink" title="A Survey of Spanish Clinical Language Models"></a>A Survey of Spanish Clinical Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02199">http://arxiv.org/abs/2308.02199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guillem García Subies, Álvaro Barbero Jiménez, Paloma Martínez Fernández</li>
<li>for: 这篇论文主要针对的是使用语言模型解决西班牙语医疗领域中的任务。</li>
<li>methods: 论文回顾了17个语料库，主要关注医疗任务，并列出了最 relevantespanish Language Models和西班牙医疗语言模型。</li>
<li>results: 研究对这些模型进行了严格的比较，通过对一个精心选择的subset of available corpora进行了测试，以确定最佳performing models。<details>
<summary>Abstract</summary>
This survey focuses in encoder Language Models for solving tasks in the clinical domain in the Spanish language. We review the contributions of 17 corpora focused mainly in clinical tasks, then list the most relevant Spanish Language Models and Spanish Clinical Language models. We perform a thorough comparison of these models by benchmarking them over a curated subset of the available corpora, in order to find the best-performing ones; in total more than 3000 models were fine-tuned for this study. All the tested corpora and the best models are made publically available in an accessible way, so that the results can be reproduced by independent teams or challenged in the future when new Spanish Clinical Language models are created.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "clinical domain" 是 translated as "医疗领域" (yī jī jīng yì)* "Spanish language" is translated as "西班牙语" (xī bān shā yǔ)* "corpora" is translated as "语料" (yǔ liào)* "fine-tuned" is translated as "微调" (wēi tiān)* "publicly available" is translated as "公开可用" (gōng kāi kě yòng)
</details></li>
</ul>
<hr>
<h2 id="AutoML4ETC-Automated-Neural-Architecture-Search-for-Real-World-Encrypted-Traffic-Classification"><a href="#AutoML4ETC-Automated-Neural-Architecture-Search-for-Real-World-Encrypted-Traffic-Classification" class="headerlink" title="AutoML4ETC: Automated Neural Architecture Search for Real-World Encrypted Traffic Classification"></a>AutoML4ETC: Automated Neural Architecture Search for Real-World Encrypted Traffic Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02182">http://arxiv.org/abs/2308.02182</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/orangeuw/automl4etc">https://github.com/orangeuw/automl4etc</a></li>
<li>paper_authors: Navid Malekghaini, Elham Akbari, Mohammad A. Salahuddin, Noura Limam, Raouf Boutaba, Bertrand Mathieu, Stephanie Moteau, Stephane Tuffin</li>
<li>for: 这个论文旨在提出一种自动化神经网络设计方法，以提高加密网络流量分类器的性能。</li>
<li>methods: 该论文使用了自动化机器学习（AutoML）技术，定义了一个特定适用于加密网络流量分类的搜索空间，并使用不同的搜索策略来生成高性能的神经网络 architecture。</li>
<li>results: 论文的实验结果表明，使用AutoML4ETC可以生成高性能的加密网络流量分类器，并且这些模型比现有的状态泰半的分类器更加准确。此外，AutoML4ETC生成的模型也更加简单，具有较少的参数数量。<details>
<summary>Abstract</summary>
Deep learning (DL) has been successfully applied to encrypted network traffic classification in experimental settings. However, in production use, it has been shown that a DL classifier's performance inevitably decays over time. Re-training the model on newer datasets has been shown to only partially improve its performance. Manually re-tuning the model architecture to meet the performance expectations on newer datasets is time-consuming and requires domain expertise. We propose AutoML4ETC, a novel tool to automatically design efficient and high-performing neural architectures for encrypted traffic classification. We define a novel, powerful search space tailored specifically for the near real-time classification of encrypted traffic using packet header bytes. We show that with different search strategies over our search space, AutoML4ETC generates neural architectures that outperform the state-of-the-art encrypted traffic classifiers on several datasets, including public benchmark datasets and real-world TLS and QUIC traffic collected from the Orange mobile network. In addition to being more accurate, AutoML4ETC's architectures are significantly more efficient and lighter in terms of the number of parameters. Finally, we make AutoML4ETC publicly available for future research.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）已成功应用于加密网络流量分类的实验设置中。然而，在生产环境中，DL分类器的性能一定程度下降。重新训练模型使用 newer datasets 只能部分提高其性能。手动重新调整模型结构以满足 newer datasets 的性能要求是时间consuming 并需要域专业知识。我们提出 AutoML4ETC，一种新的工具，可以自动设计高效和高性能的神经网络架构来分类加密流量。我们定义了一个特定于加密流量的近实时分类的强大搜索空间。我们表明，通过不同的搜索策略，AutoML4ETC 可以生成高性能的加密流量分类器，超过当前加密流量分类器的状态。此外，AutoML4ETC 的架构不仅更加准确，还更加轻量级，具体来说是参数的数量更少。最后，我们将 AutoML4ETC 公开发布，以便未来的研究。
</details></li>
</ul>
<hr>
<h2 id="Scaling-Clinical-Trial-Matching-Using-Large-Language-Models-A-Case-Study-in-Oncology"><a href="#Scaling-Clinical-Trial-Matching-Using-Large-Language-Models-A-Case-Study-in-Oncology" class="headerlink" title="Scaling Clinical Trial Matching Using Large Language Models: A Case Study in Oncology"></a>Scaling Clinical Trial Matching Using Large Language Models: A Case Study in Oncology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02180">http://arxiv.org/abs/2308.02180</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cliff Wong, Sheng Zhang, Yu Gu, Christine Moung, Jacob Abel, Naoto Usuyama, Roshanthi Weerasinghe, Brian Piening, Tristan Naumann, Carlo Bifulco, Hoifung Poon</li>
<li>for: 这篇论文的目的是研究如何使用大语言模型（LLM）扩大临床试验匹配，以提高健康交付和发现的效率。</li>
<li>methods: 该论文使用了一个现代的临床试验匹配系统，并采用了大语言模型（GPT-4）进行研究。这些模型可以自动拟合复杂的临床试验资格和匹配逻辑（例如，嵌套的AND&#x2F;OR&#x2F;NOT）。</li>
<li>results: 研究显示，使用LLM可以大幅提高临床试验匹配的效率，并且可以substantially outperform先前的强基eline。然而，LLM仍然需要人工干预，以确保匹配的准确性。此外，研究还发现了一些应用LLM到终端临床试验匹配中的成长点，例如，限定上下文和准确率，特别是从长期医疗记录中提取patient信息。<details>
<summary>Abstract</summary>
Clinical trial matching is a key process in health delivery and discovery. In practice, it is plagued by overwhelming unstructured data and unscalable manual processing. In this paper, we conduct a systematic study on scaling clinical trial matching using large language models (LLMs), with oncology as the focus area. Our study is grounded in a clinical trial matching system currently in test deployment at a large U.S. health network. Initial findings are promising: out of box, cutting-edge LLMs, such as GPT-4, can already structure elaborate eligibility criteria of clinical trials and extract complex matching logic (e.g., nested AND/OR/NOT). While still far from perfect, LLMs substantially outperform prior strong baselines and may serve as a preliminary solution to help triage patient-trial candidates with humans in the loop. Our study also reveals a few significant growth areas for applying LLMs to end-to-end clinical trial matching, such as context limitation and accuracy, especially in structuring patient information from longitudinal medical records.
</details>
<details>
<summary>摘要</summary>
临床试验匹配是医疗提供和发现的关键过程。在实践中，它受到压力于极多的无结构数据和不可扩展的手动处理。在这篇论文中，我们进行了系统性的研究，使用大型自然语言模型（LLM）扩大临床试验匹配。我们的研究基于一个大型美国医疗网络中的临床试验匹配系统，正在测试阶段。初步发现表示，直接使用最新的GPT-4等 cutting-edge LLM可以结构化复杂的参与条件和抽象出临床试验匹配逻辑（例如，嵌套的AND/OR/NOT）。虽然仍有一定的改进空间，但LLM已经明显超过了之前的强基线，并可能作为人工干预的准则来帮助批处 patient-trial 候选者。我们的研究还揭示了应用LLM到终端临床试验匹配中的一些重要成长点，如背景限制和准确率，特别是从悠久医疗记录中结构化病人信息。
</details></li>
</ul>
<hr>
<h2 id="High-Accuracy-Prediction-of-Metal-Insulator-Metal-Metasurface-with-Deep-Learning"><a href="#High-Accuracy-Prediction-of-Metal-Insulator-Metal-Metasurface-with-Deep-Learning" class="headerlink" title="High-Accuracy Prediction of Metal-Insulator-Metal Metasurface with Deep Learning"></a>High-Accuracy Prediction of Metal-Insulator-Metal Metasurface with Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04450">http://arxiv.org/abs/2308.04450</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaizhu Liu, Hsiang-Chen Chui, Changsen Sun, Xue Han</li>
<li>for: 预测电磁软件计算结果</li>
<li>methods: 使用ResNets-10模型进行预测плазмон射频表面S11参数</li>
<li>results: 预测Error值为-48.45、-46.47和-35.54对应的三种金属-半导体-金属结构，表明提议的网络可以取代传统电磁计算方法，并且训练过程只需要1,100个epoch。<details>
<summary>Abstract</summary>
Deep learning prediction of electromagnetic software calculation results has been a widely discussed issue in recent years. But the prediction accuracy was still one of the challenges to be solved. In this work, we proposed that the ResNets-10 model was used for predicting plasmonic metasurface S11 parameters. The two-stage training was performed by the k-fold cross-validation and small learning rate. After the training was completed, the prediction loss for aluminum, gold, and silver metal-insulator-metal metasurfaces was -48.45, -46.47, and -35.54, respectively. Due to the ultralow error value, the proposed network can replace the traditional electromagnetic computing method for calculation within a certain structural range. Besides, this network can finish the training process less than 1,100 epochs. This means that the network training process can effectively lower the design process time. The ResNets-10 model we proposed can also be used to design meta-diffractive devices and biosensors, thereby reducing the time required for the calculation process. The ultralow error of the network indicates that this work contributes to the development of future artificial intelligence electromagnetic computing software.
</details>
<details>
<summary>摘要</summary>
Recently, the issue of deep learning prediction of electromagnetic software calculation results has been widely discussed. However, the prediction accuracy was still a challenge to be solved. In this work, we proposed using the ResNets-10 model to predict the S11 parameters of plasmonic metasurfaces. We performed two-stage training with k-fold cross-validation and a small learning rate. After training was completed, the prediction loss for aluminum, gold, and silver metal-insulator-metal metasurfaces was -48.45, -46.47, and -35.54, respectively. Due to the ultralow error value, the proposed network can replace traditional electromagnetic computing methods for calculation within a certain structural range. Additionally, this network can finish the training process in less than 1,100 epochs, effectively lowering the design process time. The ResNets-10 model we proposed can also be used to design meta-diffractive devices and biosensors, thereby reducing the time required for the calculation process. The ultralow error of the network indicates that this work contributes to the development of future artificial intelligence electromagnetic computing software.Here's the text in Traditional Chinese for comparison:近年来，深度学习预测电磁软件计算结果的问题在各个领域中得到了广泛的讨论。然而，预测精度仍然是一个挑战。在这个工作中，我们提出了使用ResNets-10模型来预测射频金属表面S11参数。我们进行了两阶段训练，使用k-fold跨项验证和小学习率。训练完成后，对于铝、金、银 метал-隔离-锂的预测损失分别为-48.45、-46.47和-35.54。由于预测损失值几乎到零，我们的网络可以取代传统电磁计算方法，对某些结构范围内的计算进行预测。此外，这个网络可以在1,100次迭代完成训练过程，很快地完成设计过程。我们提出的ResNets-10模型可以用来设计meta-diffractive设备和生物感应器，因此可以缩短计算过程的时间。这个工作对未来人工智能电磁计算软件的发展做出了贡献。
</details></li>
</ul>
<hr>
<h2 id="Diffusion-probabilistic-models-enhance-variational-autoencoder-for-crystal-structure-generative-modeling"><a href="#Diffusion-probabilistic-models-enhance-variational-autoencoder-for-crystal-structure-generative-modeling" class="headerlink" title="Diffusion probabilistic models enhance variational autoencoder for crystal structure generative modeling"></a>Diffusion probabilistic models enhance variational autoencoder for crystal structure generative modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02165">http://arxiv.org/abs/2308.02165</a></li>
<li>repo_url: None</li>
<li>paper_authors: Teerachote Pakornchote, Natthaphon Choomphon-anomakhun, Sorrjit Arrerut, Chayanon Atthapak, Sakarn Khamkaeo, Thiparat Chotibut, Thiti Bovornratanaraks</li>
<li>for: 生成真实的晶体结构，保持晶体对称性</li>
<li>methods: 使用新型扩散probabilistic（DP）模型对原子坐标进行净化，而不是采用标准分数匹配方法</li>
<li>results: 能够重construct和生成高质量的晶体结构，与原始CDVAE模型相当；更重要的是，与量子化计算得到的碳结构进行比较，DP-CDVAE模型生成的结构与真正的基态结构更加相似，能减少了能量差值的平均值（68.1 meV&#x2F;atom），这表明DP-CDVAE模型可以更好地生成表征基态结构的晶体结构。<details>
<summary>Abstract</summary>
The crystal diffusion variational autoencoder (CDVAE) is a machine learning model that leverages score matching to generate realistic crystal structures that preserve crystal symmetry. In this study, we leverage novel diffusion probabilistic (DP) models to denoise atomic coordinates rather than adopting the standard score matching approach in CDVAE. Our proposed DP-CDVAE model can reconstruct and generate crystal structures whose qualities are statistically comparable to those of the original CDVAE. Furthermore, notably, when comparing the carbon structures generated by the DP-CDVAE model with relaxed structures obtained from density functional theory calculations, we find that the DP-CDVAE generated structures are remarkably closer to their respective ground states. The energy differences between these structures and the true ground states are, on average, 68.1 meV/atom lower than those generated by the original CDVAE. This significant improvement in the energy accuracy highlights the effectiveness of the DP-CDVAE model in generating crystal structures that better represent their ground-state configurations.
</details>
<details>
<summary>摘要</summary>
“半导体晶体扩散自适应机器学习模型（CDVAE）是一种利用得分匹配生成真实的晶体结构，保持晶体对称的机器学习模型。在这项研究中，我们利用新的扩散概率模型（DP）来减少原子坐标中的噪声，而不是采用标准的得分匹配方法。我们提议的DP-CDVAE模型可以重建和生成晶体结构，其质量与原始CDVAE模型相似。此外，我们发现，对于氢材质量计算结果的缓和结构，DP-CDVAE模型生成的结构与真正的基态结构的能量差距平均为68.1 meV/原子更低，这表明DP-CDVAE模型可以更好地生成 represent their ground-state configurations的晶体结构。”Note: "晶体" (jīngbèi) in Chinese refers to crystal, and "晶体结构" (jīngbèi jìgòng) refers to crystal structure.
</details></li>
</ul>
<hr>
<h2 id="Speaker-Diarization-of-Scripted-Audiovisual-Content"><a href="#Speaker-Diarization-of-Scripted-Audiovisual-Content" class="headerlink" title="Speaker Diarization of Scripted Audiovisual Content"></a>Speaker Diarization of Scripted Audiovisual Content</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02160">http://arxiv.org/abs/2308.02160</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yogesh Virkar, Brian Thompson, Rohit Paturi, Sundararajan Srinivasan, Marcello Federico</li>
<li>for: 为了提高电视剧和电影的中文配音和字幕创作效率。</li>
<li>methods: 利用摄制过程中使用的制作cript来提取pseudo-labeled数据，并提出一种新的半监督方法。</li>
<li>results: 相比两个无监督基线模型，提出的方法提高了51.7%的相对改善。<details>
<summary>Abstract</summary>
The media localization industry usually requires a verbatim script of the final film or TV production in order to create subtitles or dubbing scripts in a foreign language. In particular, the verbatim script (i.e. as-broadcast script) must be structured into a sequence of dialogue lines each including time codes, speaker name and transcript. Current speech recognition technology alleviates the transcription step. However, state-of-the-art speaker diarization models still fall short on TV shows for two main reasons: (i) their inability to track a large number of speakers, (ii) their low accuracy in detecting frequent speaker changes. To mitigate this problem, we present a novel approach to leverage production scripts used during the shooting process, to extract pseudo-labeled data for the speaker diarization task. We propose a novel semi-supervised approach and demonstrate improvements of 51.7% relative to two unsupervised baseline models on our metrics on a 66 show test set.
</details>
<details>
<summary>摘要</summary>
媒体地化行业通常需要最终电影或电视制作的幂等脚本，以创建外语字幕或配音脚本。特别是，幂等脚本（即播放脚本）必须以时间码、发言人名称和脚本结构组织。现有的语音识别技术使得转录步骤得到alleviation。然而，当前的发言人分类模型仍然在电视节目上存在两个主要问题：（i）它们无法跟踪大量的发言人，（ii）它们在发现频繁的发言人变化时的准确率低。为解决这个问题，我们提出了一种新的方法，利用制作过程中使用的制作脚本，提取 Pseudo-labeled 数据 для发言人分类任务。我们提出了一种新的半supervised Approach，并在66集测试集上达到了51.7%的改进率相比两个无监督基线模型。
</details></li>
</ul>
<hr>
<h2 id="Improved-Order-Analysis-and-Design-of-Exponential-Integrator-for-Diffusion-Models-Sampling"><a href="#Improved-Order-Analysis-and-Design-of-Exponential-Integrator-for-Diffusion-Models-Sampling" class="headerlink" title="Improved Order Analysis and Design of Exponential Integrator for Diffusion Models Sampling"></a>Improved Order Analysis and Design of Exponential Integrator for Diffusion Models Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02157">http://arxiv.org/abs/2308.02157</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qinsheng Zhang, Jiaming Song, Yongxin Chen</li>
<li>for: 这篇论文主要用于提出了一种改进的几何积分法，以提高扩散模型（DM）的采样质量。</li>
<li>methods: 该论文使用了几何积分法（EI），并通过对几何积分法的设计进行改进，以提高采样质量和稳定性。</li>
<li>results: 相比于现有的高阶几何积分法，该论文的提案可以提高采样质量和稳定性，并且可以避免一些容易出现的设计选择导致的问题。在实际应用中，该论文可以提供更高的采样效率和更好的采样质量。例如，在一个ImageNet扩散模型中，通过将单步DPM-Solver++替换为我们的order-satisfied RES solver，可以降低数值缺陷的比例为25.2%，并提高FID的值为25.4%（16.77 vs 12.51）。<details>
<summary>Abstract</summary>
Efficient differential equation solvers have significantly reduced the sampling time of diffusion models (DMs) while retaining high sampling quality. Among these solvers, exponential integrators (EI) have gained prominence by demonstrating state-of-the-art performance. However, existing high-order EI-based sampling algorithms rely on degenerate EI solvers, resulting in inferior error bounds and reduced accuracy in contrast to the theoretically anticipated results under optimal settings. This situation makes the sampling quality extremely vulnerable to seemingly innocuous design choices such as timestep schedules. For example, an inefficient timestep scheduler might necessitate twice the number of steps to achieve a quality comparable to that obtained through carefully optimized timesteps. To address this issue, we reevaluate the design of high-order differential solvers for DMs. Through a thorough order analysis, we reveal that the degeneration of existing high-order EI solvers can be attributed to the absence of essential order conditions. By reformulating the differential equations in DMs and capitalizing on the theory of exponential integrators, we propose refined EI solvers that fulfill all the order conditions, which we designate as Refined Exponential Solver (RES). Utilizing these improved solvers, RES exhibits more favorable error bounds theoretically and achieves superior sampling efficiency and stability in practical applications. For instance, a simple switch from the single-step DPM-Solver++ to our order-satisfied RES solver when Number of Function Evaluations (NFE) $=9$, results in a reduction of numerical defects by $25.2\%$ and FID improvement of $25.4\%$ (16.77 vs 12.51) on a pre-trained ImageNet diffusion model.
</details>
<details>
<summary>摘要</summary>
高效的差分方程解析器已经大幅降低了扩散模型（DM）的采样时间，同时保持高度采样质量。其中，对数Integrator（EI）已经取得了优势，但现有的高级EI基本采样算法仍然遵循不完全的EI解析器，从而导致较差的误差约束和降低了理论上预期的准确性。这种情况使采样质量极其敏感于不当的设计选择，如步长调度。例如，使用不优化的步长调度可能需要两倍的步长数量以达到相同的质量。为解决这个问题，我们重新评估了高级差分解析器的设计。通过严格的顺序分析，我们发现了现有高级EI解析器的不完全性可以归因于缺失的关键顺序条件。通过对DM的差分方程进行修改和利用差分方程解析器理论，我们提出了改进的差分方程解析器，称之为改进的差分方程解析器（RES）。使用这些改进的解析器，RES在理论上和实际应用中都显示出更有利的误差约束和更高的采样效率和稳定性。例如，将单步DPM-Solver++换为我们的顺序满足RES解析器，当Number of Function Evaluations（NFE）=9时，可以降低数值缺陷的比例为25.2%，并提高FID的改进率（16.77 vs 12.51）15.43%在预训练的ImageNet扩散模型上。
</details></li>
</ul>
<hr>
<h2 id="Optimization-on-Pareto-sets-On-a-theory-of-multi-objective-optimization"><a href="#Optimization-on-Pareto-sets-On-a-theory-of-multi-objective-optimization" class="headerlink" title="Optimization on Pareto sets: On a theory of multi-objective optimization"></a>Optimization on Pareto sets: On a theory of multi-objective optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02145">http://arxiv.org/abs/2308.02145</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhishek Roy, Geelon So, Yi-An Ma</li>
<li>for: 这个论文是关于多目标优化的研究，旨在找到一个均衡多个目标函数的决策 вектор。</li>
<li>methods: 论文使用了本地方法来解决这个受限制的优化问题，该问题的约束集是 implicitly defined 的，通常是非对称和不 глад的。</li>
<li>results: 论文提出了一种算法，其最后迭代速度为 $O(K^{-1&#x2F;2})$ 收敛到stationarity，当目标函数强 convex 和 Lipschitz 平滑时。<details>
<summary>Abstract</summary>
In multi-objective optimization, a single decision vector must balance the trade-offs between many objectives. Solutions achieving an optimal trade-off are said to be Pareto optimal: these are decision vectors for which improving any one objective must come at a cost to another. But as the set of Pareto optimal vectors can be very large, we further consider a more practically significant Pareto-constrained optimization problem, where the goal is to optimize a preference function constrained to the Pareto set.   We investigate local methods for solving this constrained optimization problem, which poses significant challenges because the constraint set is (i) implicitly defined, and (ii) generally non-convex and non-smooth, even when the objectives are. We define notions of optimality and stationarity, and provide an algorithm with a last-iterate convergence rate of $O(K^{-1/2})$ to stationarity when the objectives are strongly convex and Lipschitz smooth.
</details>
<details>
<summary>摘要</summary>
在多目标优化中，每个决策向量必须均衡多个目标之间的贸易偏好。解决得到的优化解是称为Pareto优化：这些决策向量在改进任一目标时，必须来到另一目标的代价。但是Pareto优化集可能非常大，因此我们进一步考虑一种更实际 significannotive的Pareto受限优化问题，其目的是在Pareto集中优化偏好函数。我们研究本地方法来解决这个受限优化问题，这个问题存在两个主要挑战：首先，约束集是（i）隐式定义的，其次，通常是非拟合的和不平滑的。我们定义优化和稳定性的概念，并提供一种以$O(K^{-1/2})$的速率 converges to stationarity的算法，当目标函数是强Converter和Lipschitz光滑时。
</details></li>
</ul>
<hr>
<h2 id="Event-based-Dynamic-Graph-Representation-Learning-for-Patent-Application-Trend-Prediction"><a href="#Event-based-Dynamic-Graph-Representation-Learning-for-Patent-Application-Trend-Prediction" class="headerlink" title="Event-based Dynamic Graph Representation Learning for Patent Application Trend Prediction"></a>Event-based Dynamic Graph Representation Learning for Patent Application Trend Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09780">http://arxiv.org/abs/2308.09780</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tao Zou, Le Yu, Leilei Sun, Bowen Du, Deqing Wang, Fuzhen Zhuang</li>
<li>for: 预测公司将在未来 periods of time 申请哪些专利，以便了解其发展策略和找到前期伙伴或竞争对手。</li>
<li>methods: 基于公司和专利分类代码的记忆表示和层次消息传递机制，实现专利申请趋势预测。</li>
<li>results: 在不同实验条件下，方法能够有效地预测专利申请趋势，同时还能学习分类代码的 semantics 和跟踪公司技术发展轨迹。<details>
<summary>Abstract</summary>
Accurate prediction of what types of patents that companies will apply for in the next period of time can figure out their development strategies and help them discover potential partners or competitors in advance. Although important, this problem has been rarely studied in previous research due to the challenges in modelling companies' continuously evolving preferences and capturing the semantic correlations of classification codes. To fill in this gap, we propose an event-based dynamic graph learning framework for patent application trend prediction. In particular, our method is founded on the memorable representations of both companies and patent classification codes. When a new patent is observed, the representations of the related companies and classification codes are updated according to the historical memories and the currently encoded messages. Moreover, a hierarchical message passing mechanism is provided to capture the semantic proximities of patent classification codes by updating their representations along the hierarchical taxonomy. Finally, the patent application trend is predicted by aggregating the representations of the target company and classification codes from static, dynamic, and hierarchical perspectives. Experiments on real-world data demonstrate the effectiveness of our approach under various experimental conditions, and also reveal the abilities of our method in learning semantics of classification codes and tracking technology developing trajectories of companies.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将来公司会申请哪些专利的预测可以掌握其发展策略，并在先前发现 potential partners或竞争对手。虽然这是一个重要的问题，但在过去的研究中它受到了较少的关注，这是因为模elling公司的持续发展偏好以及捕捉专利分类代码的含义相互关系是一个挑战。为了解决这个问题，我们提出了一种基于事件的动态图学学习框架 для专利申请趋势预测。具体来说，我们的方法基于公司和专利分类代码的印象 remembered representations。当观察到新专利时，相关公司和分类代码的表示被更新，根据历史记忆和当前编码的消息。此外，我们还提供了一种层次消息传递机制，以捕捉专利分类代码的含义相互关系，并将其更新为层次分类树。最后，我们预测专利申请趋势，通过 static、动态和层次三个视角的表示进行汇总。实验结果表明，我们的方法在不同的实验条件下表现出色，并且能够学习分类代码的 semantics 以及跟踪公司的科技发展轨迹。
</details></li>
</ul>
<hr>
<h2 id="Learning-the-solution-operator-of-two-dimensional-incompressible-Navier-Stokes-equations-using-physics-aware-convolutional-neural-networks"><a href="#Learning-the-solution-operator-of-two-dimensional-incompressible-Navier-Stokes-equations-using-physics-aware-convolutional-neural-networks" class="headerlink" title="Learning the solution operator of two-dimensional incompressible Navier-Stokes equations using physics-aware convolutional neural networks"></a>Learning the solution operator of two-dimensional incompressible Navier-Stokes equations using physics-aware convolutional neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02137">http://arxiv.org/abs/2308.02137</a></li>
<li>repo_url: None</li>
<li>paper_authors: Viktor Grimm, Alexander Heinlein, Axel Klawonn</li>
<li>for: 这个论文旨在推广物理知识到机器学习领域，但现有的方法仍然受限于单个几何或可调参数的几何。这篇论文提出了一种可以在不同几何中学习稳态 Navier-Stokes 方程的方法，不需要 parametrization。</li>
<li>methods: 该方法基于 U-Net 类 CNN 和确立的精度方法，从数学方面来说是使用 finite difference 方法进行精度描述。</li>
<li>results: 该方法与当前领先的数据基本方法进行比较，并与数据基本方法结合使用时的性能进行比较。<details>
<summary>Abstract</summary>
In recent years, the concept of introducing physics to machine learning has become widely popular. Most physics-inclusive ML-techniques however are still limited to a single geometry or a set of parametrizable geometries. Thus, there remains the need to train a new model for a new geometry, even if it is only slightly modified. With this work we introduce a technique with which it is possible to learn approximate solutions to the steady-state Navier--Stokes equations in varying geometries without the need of parametrization. This technique is based on a combination of a U-Net-like CNN and well established discretization methods from the field of the finite difference method.The results of our physics-aware CNN are compared to a state-of-the-art data-based approach. Additionally, it is also shown how our approach performs when combined with the data-based approach.
</details>
<details>
<summary>摘要</summary>
近年来，将物理学引入机器学习的概念在学术界得到了广泛的推广。然而，大多数物理包含的机器学习技术仍然受限于单个几何或一组可Parametrize的几何。因此，在新的几何模型中训练新模型仍然存在需求，即使这个几何只是稍微修改过。本工作我们介绍了一种可以在不同几何中学习稳态内离液方程的近似解的技术。这种技术基于U-Net-like CNN和已知的精度分割方法。我们的物理意识CNN的结果与现有的数据基本方法相比较，并且还展示了我们的方法与数据基本方法的组合效果。
</details></li>
</ul>
<hr>
<h2 id="Can-Attention-Be-Used-to-Explain-EHR-Based-Mortality-Prediction-Tasks-A-Case-Study-on-Hemorrhagic-Stroke"><a href="#Can-Attention-Be-Used-to-Explain-EHR-Based-Mortality-Prediction-Tasks-A-Case-Study-on-Hemorrhagic-Stroke" class="headerlink" title="Can Attention Be Used to Explain EHR-Based Mortality Prediction Tasks: A Case Study on Hemorrhagic Stroke"></a>Can Attention Be Used to Explain EHR-Based Mortality Prediction Tasks: A Case Study on Hemorrhagic Stroke</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05110">http://arxiv.org/abs/2308.05110</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qizhang Feng, Jiayi Yuan, Forhan Bin Emdad, Karim Hanna, Xia Hu, Zhe He</li>
<li>for: 预测中风mortalit，提高患者护理质量和风险评估的精度。</li>
<li>methods: 使用一种新的方法：可解释的注意力基于变换器模型，以提高早期中风预测的准确性和可读性。</li>
<li>results: 研究发现，该模型在比较旧方法时表现出较高的准确性和可读性，同时提供了明确的特征重要性。<details>
<summary>Abstract</summary>
Stroke is a significant cause of mortality and morbidity, necessitating early predictive strategies to minimize risks. Traditional methods for evaluating patients, such as Acute Physiology and Chronic Health Evaluation (APACHE II, IV) and Simplified Acute Physiology Score III (SAPS III), have limited accuracy and interpretability. This paper proposes a novel approach: an interpretable, attention-based transformer model for early stroke mortality prediction. This model seeks to address the limitations of previous predictive models, providing both interpretability (providing clear, understandable explanations of the model) and fidelity (giving a truthful explanation of the model's dynamics from input to output). Furthermore, the study explores and compares fidelity and interpretability scores using Shapley values and attention-based scores to improve model explainability. The research objectives include designing an interpretable attention-based transformer model, evaluating its performance compared to existing models, and providing feature importance derived from the model.
</details>
<details>
<summary>摘要</summary>
stroke 是一种重要的死亡和残疾原因，需要早期预测方法以降低风险。传统的评估病人方法，如急性生理学和慢性健康评估（APACHE II、IV）和简化型急性生理评分 III（SAPS III），有限的准确性和可解性。这篇论文提出了一种新的方法：一种可解的、注意力基本变换模型，用于早期stroke死亡预测。这个模型目的是解决之前预测模型的限制，提供可解性（提供明确、理解的解释）和准确性（从输入到输出的模型动态 truthful explanation）。此外，研究还 explore和比较了准确性和可解性分数使用Shapley值和注意力基本分数来提高模型解释性。研究的目标包括设计一种可解的注意力基本变换模型，评估其表现与现有模型相比，并提供来自模型的特征重要性。
</details></li>
</ul>
<hr>
<h2 id="Analysis-and-Optimization-of-Wireless-Federated-Learning-with-Data-Heterogeneity"><a href="#Analysis-and-Optimization-of-Wireless-Federated-Learning-with-Data-Heterogeneity" class="headerlink" title="Analysis and Optimization of Wireless Federated Learning with Data Heterogeneity"></a>Analysis and Optimization of Wireless Federated Learning with Data Heterogeneity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03521">http://arxiv.org/abs/2308.03521</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuefeng Han, Jun Li, Wen Chen, Zhen Mei, Kang Wei, Ming Ding, H. Vincent Poor</li>
<li>for: 针对智能移动设备普及的蜂窝学习（FL）在无线网络中的应用，尤其是对数据不均衡和不同训练数据大小的 клиент所带来的挑战。</li>
<li>methods: 本文使用closed-form表达式来 bounds 蜂窝学习（FL）损失函数，并考虑了无线资源分配和客户端调度。</li>
<li>results: 实验结果表明，提出的算法在实际数据上比其他参考方案更高的学习精度和能耗。<details>
<summary>Abstract</summary>
With the rapid proliferation of smart mobile devices, federated learning (FL) has been widely considered for application in wireless networks for distributed model training. However, data heterogeneity, e.g., non-independently identically distributions and different sizes of training data among clients, poses major challenges to wireless FL. Limited communication resources complicate the implementation of fair scheduling which is required for training on heterogeneous data, and further deteriorate the overall performance. To address this issue, this paper focuses on performance analysis and optimization for wireless FL, considering data heterogeneity, combined with wireless resource allocation. Specifically, we first develop a closed-form expression for an upper bound on the FL loss function, with a particular emphasis on data heterogeneity described by a dataset size vector and a data divergence vector. Then we formulate the loss function minimization problem, under constraints on long-term energy consumption and latency, and jointly optimize client scheduling, resource allocation, and the number of local training epochs (CRE). Next, via the Lyapunov drift technique, we transform the CRE optimization problem into a series of tractable problems. Extensive experiments on real-world datasets demonstrate that the proposed algorithm outperforms other benchmarks in terms of the learning accuracy and energy consumption.
</details>
<details>
<summary>摘要</summary>
Note: The text has been translated into Simplified Chinese, which is the standard written form of Chinese used in mainland China.Please note that the translation is done by a machine and may not be perfect, and there may be some cultural or linguistic differences that are not captured by the translation.
</details></li>
</ul>
<hr>
<h2 id="Branched-Latent-Neural-Operators"><a href="#Branched-Latent-Neural-Operators" class="headerlink" title="Branched Latent Neural Operators"></a>Branched Latent Neural Operators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02599">http://arxiv.org/abs/2308.02599</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/stanfordcbcl/blno.jl">https://github.com/stanfordcbcl/blno.jl</a></li>
<li>paper_authors: Matteo Salvador, Alison Lesley Marsden</li>
<li>for: 这篇论文旨在开发一种可靠和高效的减少维度模型，用于数字双子技术应用。</li>
<li>methods: 该论文提出了分支隐藏神经网络（BLNOs）来学习输入输出映射，以处理复杂物理过程。 BLNOs 使用简单和压缩的Feedforward 几何神经网络，并通过将输入分解成不同内在角色，如时间变量和模型参数，以提高学习的动力和缩减维度。</li>
<li>results: 该论文的实验结果表明，BLNOs 可以在小训练集和短训练时间内达到优秀的泛化性能，并且其泛化误差与选择维度无关。此外，BLNOs 的半连接结构可以减少可调参数的数量。在一个具有诊断检查和心脏形态的心脏模型中，BLNOs 通过150个在线生成的12个电气征诊断图来训练，并在7个参数上进行自动hyperparameter调整。最佳BLNO在 fewer than 3 hours内在单个CPU上训练完毕，具有7层隐藏层和19个神经元。在独立测试集中，该模型的平方误差在 $10^{-4}$ 之间。<details>
<summary>Abstract</summary>
We introduce Branched Latent Neural Operators (BLNOs) to learn input-output maps encoding complex physical processes. A BLNO is defined by a simple and compact feedforward partially-connected neural network that structurally disentangles inputs with different intrinsic roles, such as the time variable from model parameters of a differential equation, while transferring them into a generic field of interest. BLNOs leverage interpretable latent outputs to enhance the learned dynamics and break the curse of dimensionality by showing excellent generalization properties with small training datasets and short training times on a single processor. Indeed, their generalization error remains comparable regardless of the adopted discretization during the testing phase. Moreover, the partial connections, in place of a fully-connected structure, significantly reduce the number of tunable parameters. We show the capabilities of BLNOs in a challenging test case involving biophysically detailed electrophysiology simulations in a biventricular cardiac model of a pediatric patient with hypoplastic left heart syndrome. The model includes a purkinje network for fast conduction and a heart-torso geometry. Specifically, we trained BLNOs on 150 in silico generated 12-lead electrocardiograms (ECGs) while spanning 7 model parameters, covering cell-scale, organ-level and electrical dyssynchrony. Although the 12-lead ECGs manifest very fast dynamics with sharp gradients, after automatic hyperparameter tuning the optimal BLNO, trained in less than 3 hours on a single CPU, retains just 7 hidden layers and 19 neurons per layer. The mean square error is on the order of $10^{-4}$ on an independent test dataset comprised of 50 additional electrophysiology simulations. This paper provides a novel computational tool to build reliable and efficient reduced-order models for digital twinning in engineering applications.
</details>
<details>
<summary>摘要</summary>
我们引入分支 latent neural operator (BLNO)，以learn输入输出映射，描述复杂物理过程。BLNO是一个简单且紧凑的 feedforward partially-connected neural network，它将输入分为不同的内在角色，如时间变量和模型参数，并将它们转换为一个通用的场景。BLNOs 利用可解释的 latent output 提高学习过程中的动态，并突破维度紧缩问题，因为它们在训练阶段只需要小量的训练数据和短时间执行。此外，对维度的采取价值不同的� enters 也可以将数据分为不同的类别，进一步提高模型的精度。我们在一个具有复杂生物物理特性的心脏模型中进行了一个挑战性的测试，该模型包括一个 purkinje 网络和心脏� torso 对应。我们将 BLNOs 训练在 150 个在 silico 生成的 12 项电cardiogram (ECG) 中，涵盖 7 个模型参数，包括细胞层、器官层和电子� synchrony。although 12 项 ECG 呈现出非常快的动态和锋利的梯度，经自动优化参数后，最佳的 BLNO 在仅 3 小时内在单一 CPU 上训练，只有 7 个隐藏层和 19 个神经元。模型的平方误差在独立测试数据中是 $10^{-4}$ 阶段。这篇论文提供了一个新的计算工具，用于建立可靠且高效的削减� orden 模型，供工程应用中的数字双胞处理。
</details></li>
</ul>
<hr>
<h2 id="Eva-A-General-Vectorized-Approximation-Framework-for-Second-order-Optimization"><a href="#Eva-A-General-Vectorized-Approximation-Framework-for-Second-order-Optimization" class="headerlink" title="Eva: A General Vectorized Approximation Framework for Second-order Optimization"></a>Eva: A General Vectorized Approximation Framework for Second-order Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02123">http://arxiv.org/abs/2308.02123</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lin Zhang, Shaohuai Shi, Bo Li</li>
<li>for: 这个论文目的是提高深度学习模型训练效率。</li>
<li>methods: 该论文提出了两种新技术：1）使用小批量训练数据的 kronecker 分解来减少内存消耗；2）通过sherman-morrison公式来计算更新公式而不需要直接计算矩阵的逆元。</li>
<li>results: 对不同的模型和数据集进行了广泛的实验，结果显示，使用 Eva 可以降低总训练时间，相比于首项SGD和其他二项算法（K-FAC和Shampoo），可以提高训练效率。<details>
<summary>Abstract</summary>
Second-order optimization algorithms exhibit excellent convergence properties for training deep learning models, but often incur significant computation and memory overheads. This can result in lower training efficiency than the first-order counterparts such as stochastic gradient descent (SGD). In this work, we present a memory- and time-efficient second-order algorithm named Eva with two novel techniques: 1) we construct the second-order information with the Kronecker factorization of small stochastic vectors over a mini-batch of training data to reduce memory consumption, and 2) we derive an efficient update formula without explicitly computing the inverse of matrices using the Sherman-Morrison formula. We further extend Eva to a general vectorized approximation framework to improve the compute and memory efficiency of two existing second-order algorithms (FOOF and Shampoo) without affecting their convergence performance. Extensive experimental results on different models and datasets show that Eva reduces the end-to-end training time up to 2.05x and 2.42x compared to first-order SGD and second-order algorithms (K-FAC and Shampoo), respectively.
</details>
<details>
<summary>摘要</summary>
第二顺序优化算法具有深度学习模型训练中的卓越减少性，但经常带来计算和内存开销。这可能导致训练效率较低于第一顺序对手，如随机梯度下降（SGD）。在这篇文章中，我们介绍了一种具有内存和时间有效的第二顺序算法，名为Eva，以及两种新技术：1. 我们使用小批量训练数据的Kronecker因子分解来构建第二顺序信息，以减少内存消耗。2. 我们 derivate了一个高效的更新公式，不需要直接计算矩阵的逆元，使用Sherman-Morrison公式。此外，我们还将Eva扩展到一个通用的矢量化近似框架，以提高FOOF和Shampoo等两种第二顺序算法的计算和内存效率，无需影响其减少性。我们在不同的模型和数据集上进行了广泛的实验，结果显示，Eva可以比SGD和K-FAC/Shampoo等第一顺序和第二顺序算法减少结束训练时间，具体的比例分别为2.05倍和2.42倍。
</details></li>
</ul>
<hr>
<h2 id="Model-Provenance-via-Model-DNA"><a href="#Model-Provenance-via-Model-DNA" class="headerlink" title="Model Provenance via Model DNA"></a>Model Provenance via Model DNA</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02121">http://arxiv.org/abs/2308.02121</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Mu, Yu Wang, Yehong Zhang, Jiaqi Zhang, Hui Wang, Yang Xiang, Yue Yu</li>
<li>for: 本研究主要针对机器学习模型的生命周期（即模型的来源、训练和应用）中的一个新问题，即模型来源问题（Model Provenance，MP），即确定目标模型的来源模型是否为其训练模型。这是一个重要的问题，对于确保机器学习模型的安全性和知识产权具有重要 significances，但在文献中尚未得到了充分的关注。</li>
<li>methods: 我们提出了一种新的模型特征表示方法，即模型DNA（Model DNA），它可以很好地表示机器学习模型的训练数据和输入输出信息。然后，我们提出了一种基于数据驱动和模型驱动的学习方法，通过对模型DNA进行编码，以获得一个紧凑 Complete和全面的模型表示（DNA）。</li>
<li>results: 我们通过在计算机视觉和自然语言处理任务上使用不同的模型、数据集和场景进行评估，以示我们的方法在准确地确定模型来源方面的效果。<details>
<summary>Abstract</summary>
Understanding the life cycle of the machine learning (ML) model is an intriguing area of research (e.g., understanding where the model comes from, how it is trained, and how it is used). This paper focuses on a novel problem within this field, namely Model Provenance (MP), which concerns the relationship between a target model and its pre-training model and aims to determine whether a source model serves as the provenance for a target model. This is an important problem that has significant implications for ensuring the security and intellectual property of machine learning models but has not received much attention in the literature. To fill in this gap, we introduce a novel concept of Model DNA which represents the unique characteristics of a machine learning model. We utilize a data-driven and model-driven representation learning method to encode the model's training data and input-output information as a compact and comprehensive representation (i.e., DNA) of the model. Using this model DNA, we develop an efficient framework for model provenance identification, which enables us to identify whether a source model is a pre-training model of a target model. We conduct evaluations on both computer vision and natural language processing tasks using various models, datasets, and scenarios to demonstrate the effectiveness of our approach in accurately identifying model provenance.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:理解机器学习模型的生命周期是一个有趣的研究领域（例如，理解模型的来源、如何训练和如何使用）。这篇论文关注一个新的问题在这个领域，即模型 происхождение（MP），它关注目标模型和其预训练模型之间的关系，并计划确定预训练模型是目标模型的来源。这是一个重要的问题，它对机器学习模型的安全和知识产权具有重要意义，但在文献中尚未得到了充分的关注。为了填补这一空白，我们提出了一个新的机器学习模型特征表示（Model DNA），它表示机器学习模型的唯一特征。我们使用数据驱动和模型驱动的表示学习方法将模型训练数据和输入输出信息编码为模型的唯一表示（DNA）。使用这个模型DNA，我们开发了一种高效的模型 происхождение标识框架，可以准确地确定预训练模型是目标模型的来源。我们在计算机视觉和自然语言处理任务上使用了多种模型、数据集和场景，以示出我们方法的准确性。
</details></li>
</ul>
<hr>
<h2 id="Designing-a-Deep-Learning-Driven-Resource-Efficient-Diagnostic-System-for-Metastatic-Breast-Cancer-Reducing-Long-Delays-of-Clinical-Diagnosis-and-Improving-Patient-Survival-in-Developing-Countries"><a href="#Designing-a-Deep-Learning-Driven-Resource-Efficient-Diagnostic-System-for-Metastatic-Breast-Cancer-Reducing-Long-Delays-of-Clinical-Diagnosis-and-Improving-Patient-Survival-in-Developing-Countries" class="headerlink" title="Designing a Deep Learning-Driven Resource-Efficient Diagnostic System for Metastatic Breast Cancer: Reducing Long Delays of Clinical Diagnosis and Improving Patient Survival in Developing Countries"></a>Designing a Deep Learning-Driven Resource-Efficient Diagnostic System for Metastatic Breast Cancer: Reducing Long Delays of Clinical Diagnosis and Improving Patient Survival in Developing Countries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02597">http://arxiv.org/abs/2308.02597</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Gao, Dayong Wang, Yi Huang</li>
<li>for: 这个研究旨在解决癌症致死率高的乳癌患者在发展中国家，特别是SUB-SAHARAN AFRICA、南亚和南美洲所面临的长时间诊断延误问题。</li>
<li>methods: 这个研究使用了深度学习技术开发了一个可高度准确地诊断乳癌的系统，并且可以在资源充足的医疗设施中运行。</li>
<li>results: 根据评估结果，MobileNetV2型别的诊断模型在准确性、数据通用性和训练效率等方面优于更复杂的VGG16、ResNet50和ResNet101模型。此外，Visual比较表明MobileNetV2模型可以实时检测小型乳癌细胞在正常细胞中的嵌入。<details>
<summary>Abstract</summary>
Breast cancer is one of the leading causes of cancer mortality. Breast cancer patients in developing countries, especially sub-Saharan Africa, South Asia, and South America, suffer from the highest mortality rate in the world. One crucial factor contributing to the global disparity in mortality rate is long delay of diagnosis due to a severe shortage of trained pathologists, which consequently has led to a large proportion of late-stage presentation at diagnosis. The delay between the initial development of symptoms and the receipt of a diagnosis could stretch upwards 15 months. To tackle this critical healthcare disparity, this research has developed a deep learning-based diagnosis system for metastatic breast cancer that can achieve high diagnostic accuracy as well as computational efficiency. Based on our evaluation, the MobileNetV2-based diagnostic model outperformed the more complex VGG16, ResNet50 and ResNet101 models in diagnostic accuracy, model generalization, and model training efficiency. The visual comparisons between the model prediction and ground truth have demonstrated that the MobileNetV2 diagnostic models can identify very small cancerous nodes embedded in a large area of normal cells which is challenging for manual image analysis. Equally Important, the light weighted MobleNetV2 models were computationally efficient and ready for mobile devices or devices of low computational power. These advances empower the development of a resource-efficient and high performing AI-based metastatic breast cancer diagnostic system that can adapt to under-resourced healthcare facilities in developing countries. This research provides an innovative technological solution to address the long delays in metastatic breast cancer diagnosis and the consequent disparity in patient survival outcome in developing countries.
</details>
<details>
<summary>摘要</summary>
乳癌是全球最主要的癌症致死原因之一，而发展中国家的乳癌患者，特别是非洲萨赫拉地区、南亚和南美地区，患者的死亡率最高。一个重要的因素导致全球医疗 disparity 是诊断延迟，因为缺乏培训的病理学家，这导致了许多晚期诊断。延迟从症状开始到诊断的时间可以达到15个月。为了解决这一重要的医疗 disparity，这项研究开发了一个基于深度学习的乳癌诊断系统，可以实现高精度和计算效率。根据我们的评估，基于 MobileNetV2 的诊断模型在诊断精度、模型泛化和模型训练效率方面都高于 VGG16、ResNet50 和 ResNet101 模型。视觉比较表明，MobileNetV2 诊断模型可以准确地识别小型乳癌细胞在大量正常细胞中的存在，这是人工图像分析困难。此外，MobileNetV2 模型轻量级，可以在移动设备或低计算能力的设备上进行计算，这使得这些技术更加可行。这些进步使得可以开发一个资源高效的 AI 基于乳癌诊断系统，可以适应发展中国家的医疗设施。这项研究提供了一种创新的技术解决方案，以减少发展中国家乳癌患者的诊断延迟和因此的生存结果差距。
</details></li>
</ul>
<hr>
<h2 id="VQGraph-Graph-Vector-Quantization-for-Bridging-GNNs-and-MLPs"><a href="#VQGraph-Graph-Vector-Quantization-for-Bridging-GNNs-and-MLPs" class="headerlink" title="VQGraph: Graph Vector-Quantization for Bridging GNNs and MLPs"></a>VQGraph: Graph Vector-Quantization for Bridging GNNs and MLPs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02117">http://arxiv.org/abs/2308.02117</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yangling0818/vqgraph">https://github.com/yangling0818/vqgraph</a></li>
<li>paper_authors: Ling Yang, Ye Tian, Minkai Xu, Zhongyi Liu, Shenda Hong, Wei Qu, Wentao Zhang, Bin Cui, Muhan Zhang, Jure Leskovec</li>
<li>for: 本文旨在提出一种新的框架，即VQGraph，用于将图神经网络（GNN）和多层感知器（MLP）相互链接，以提高图像识别的性能。</li>
<li>methods: 本文使用了一种新的tokenizer，即基于vector-quantized variational autoencoder（VQ-VAE）的编码器，来表示图中的节点。此外，本文还提出了一种基于软Token分配的新的token-based填充目标，以便从GNN中传递知识到MLP中。</li>
<li>results: EXTENSIVE experiments和分析表明，VQGraph可以具有更高的性能，在七个图 dataset上实现新的状态艺术性能。VQGraph能够更快地进行预测，比GNN快828倍，同时也可以提高GNN和独立MLP的准确率。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) conduct message passing which aggregates local neighbors to update node representations. Such message passing leads to scalability issues in practical latency-constrained applications. To address this issue, recent methods adopt knowledge distillation (KD) to learn computationally-efficient multi-layer perceptron (MLP) by mimicking the output of GNN. However, the existing GNN representation space may not be expressive enough for representing diverse local structures of the underlying graph, which limits the knowledge transfer from GNN to MLP. Here we present a novel framework VQGraph to learn a powerful graph representation space for bridging GNNs and MLPs. We adopt the encoder of a variant of a vector-quantized variational autoencoder (VQ-VAE) as a structure-aware graph tokenizer, which explicitly represents the nodes of diverse local structures as numerous discrete tokens and constitutes a meaningful codebook. Equipped with the learned codebook, we propose a new token-based distillation objective based on soft token assignments to sufficiently transfer the structural knowledge from GNN to MLP. Extensive experiments and analyses demonstrate the strong performance of VQGraph, where we achieve new state-of-the-art performance on GNN-MLP distillation in both transductive and inductive settings across seven graph datasets. We show that VQGraph with better performance infers faster than GNNs by 828x, and also achieves accuracy improvement over GNNs and stand-alone MLPs by 3.90% and 28.05% on average, respectively. Code: https://github.com/YangLing0818/VQGraph.
</details>
<details>
<summary>摘要</summary>
图 neural network (GNN) 通过消息传递来更新节点表示。这种消息传递会导致实际应用中的执行效率问题。为解决这个问题，现有方法采用知识传授 (KD) 学习计算效率高的多层感知器 (MLP)，但现有的 GNN 表示空间可能不够表示多样性的本地结构，这限制了 GNN 知识的传递。我们提出一种新的框架 VQGraph，用于学习一个强大的图表示空间，以bridging GNN 和 MLP。我们采用一种变体的 vector-quantized variational autoencoder (VQ-VAE) 的Encoder作为结构意识 graph tokenizer，其将节点视为多种不同的本地结构的数据点，并构成一个有意义的代码库。准备了学习的代码库后，我们提出了一个新的 токен基本的分配目标，基于软件分配来充分传递 GNN 中的结构知识到 MLP。我们对七个图Dataset进行了广泛的实验和分析，并证明了 VQGraph 的强大性。我们在传递性下 achieved 新的状态时���的性能，在 inductive 和 transductive 设置下，VQGraph 的性能比 GNN 高出 3.90% 和 28.05% 的平均值。此外，VQGraph 能够更快地进行计算，比 GNN 快 828 倍。代码：https://github.com/YangLing0818/VQGraph。
</details></li>
</ul>
<hr>
<h2 id="Breast-Ultrasound-Tumor-Classification-Using-a-Hybrid-Multitask-CNN-Transformer-Network"><a href="#Breast-Ultrasound-Tumor-Classification-Using-a-Hybrid-Multitask-CNN-Transformer-Network" class="headerlink" title="Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network"></a>Breast Ultrasound Tumor Classification Using a Hybrid Multitask CNN-Transformer Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02101">http://arxiv.org/abs/2308.02101</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bryar Shareef, Min Xian, Aleksandar Vakanski, Haotian Wang</li>
<li>for: 这个研究是为了提高乳腺ultrasound(BUS)图像分类的准确性。</li>
<li>methods: 本研究使用了一种混合型多任务深度学习网络，名为Hybrid-MT-ESTAN，它结合了CNN和Swin Transformer的元件，以进行BUS图像分类和分 segmentation。</li>
<li>results: 比较九种BUS分类方法，Hybrid-MT-ESTAN得到了最高的准确性、敏感度和F1分数，具体的数据为82.7%, 86.4%和86.0%。<details>
<summary>Abstract</summary>
Capturing global contextual information plays a critical role in breast ultrasound (BUS) image classification. Although convolutional neural networks (CNNs) have demonstrated reliable performance in tumor classification, they have inherent limitations for modeling global and long-range dependencies due to the localized nature of convolution operations. Vision Transformers have an improved capability of capturing global contextual information but may distort the local image patterns due to the tokenization operations. In this study, we proposed a hybrid multitask deep neural network called Hybrid-MT-ESTAN, designed to perform BUS tumor classification and segmentation using a hybrid architecture composed of CNNs and Swin Transformer components. The proposed approach was compared to nine BUS classification methods and evaluated using seven quantitative metrics on a dataset of 3,320 BUS images. The results indicate that Hybrid-MT-ESTAN achieved the highest accuracy, sensitivity, and F1 score of 82.7%, 86.4%, and 86.0%, respectively.
</details>
<details>
<summary>摘要</summary>
globally capturing contextual information plays a crucial role in breast ultrasound (BUS) image classification. Although convolutional neural networks (CNNs) have demonstrated reliable performance in tumor classification, they have inherent limitations in modeling global and long-range dependencies due to the localized nature of convolution operations. Vision Transformers have an improved capability of capturing global contextual information, but may distort local image patterns due to tokenization operations. In this study, we proposed a hybrid multitask deep neural network called Hybrid-MT-ESTAN, designed to perform BUS tumor classification and segmentation using a hybrid architecture composed of CNNs and Swin Transformer components. The proposed approach was compared to nine BUS classification methods and evaluated using seven quantitative metrics on a dataset of 3,320 BUS images. The results indicate that Hybrid-MT-ESTAN achieved the highest accuracy, sensitivity, and F1 score of 82.7%, 86.4%, and 86.0%, respectively.Here's the word-for-word translation of the text into Simplified Chinese:全球捕捉上下文信息在乳腺超声图像分类中扮演了关键角色。尽管卷积神经网络（CNNs）在肿瘤分类中表现出了可靠性，但它们具有本质上的局部化限制，因为卷积操作的本地化特性。视觉 трансформа器具有提高全球上下文信息捕捉的能力，但可能因token化操作而导致本地图像模式的扭曲。在本研究中，我们提出了一种混合多任务深度神经网络，名为Hybrid-MT-ESTAN，用于实现乳腺超声图像分类和分割。我们的方法与9种BUS分类方法进行比较，并在3320个BUS图像 Dataset 上进行评估，使用7个量化指标。结果表明，Hybrid-MT-ESTAN achieved the highest accuracy, sensitivity, and F1 score of 82.7%, 86.4%, and 86.0%, respectively.
</details></li>
</ul>
<hr>
<h2 id="Efficient-Model-Adaptation-for-Continual-Learning-at-the-Edge"><a href="#Efficient-Model-Adaptation-for-Continual-Learning-at-the-Edge" class="headerlink" title="Efficient Model Adaptation for Continual Learning at the Edge"></a>Efficient Model Adaptation for Continual Learning at the Edge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02084">http://arxiv.org/abs/2308.02084</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zachary A. Daniels, Jun Hu, Michael Lomnitz, Phil Miller, Aswin Raghavan, Joe Zhang, Michael Piacentino, David Zhang</li>
<li>for: 这篇论文旨在提出一个非站点自动机学（AutoML）框架，以便在不同环境下进行高效的连续学习。</li>
<li>methods: 这篇论文使用了一个固定的深度神经网络（DNN）特征嵌入器，并使用阶层神经网络来处理新数据。它还使用了零数学 нейрон架构搜索（ZS-NAS）来找到适当的神经适配器，以适应新数据。</li>
<li>results: 这篇论文系统地评估了它的方法在多个benchmark数据集上，并与现有的OOD检测和几何学搜索算法进行比较。结果显示，这篇论文的方法具有强大的外部检测和适配能力，并能够在不同的环境下进行高效的连续学习。<details>
<summary>Abstract</summary>
Most machine learning (ML) systems assume stationary and matching data distributions during training and deployment. This is often a false assumption. When ML models are deployed on real devices, data distributions often shift over time due to changes in environmental factors, sensor characteristics, and task-of-interest. While it is possible to have a human-in-the-loop to monitor for distribution shifts and engineer new architectures in response to these shifts, such a setup is not cost-effective. Instead, non-stationary automated ML (AutoML) models are needed. This paper presents the Encoder-Adaptor-Reconfigurator (EAR) framework for efficient continual learning under domain shifts. The EAR framework uses a fixed deep neural network (DNN) feature encoder and trains shallow networks on top of the encoder to handle novel data. The EAR framework is capable of 1) detecting when new data is out-of-distribution (OOD) by combining DNNs with hyperdimensional computing (HDC), 2) identifying low-parameter neural adaptors to adapt the model to the OOD data using zero-shot neural architecture search (ZS-NAS), and 3) minimizing catastrophic forgetting on previous tasks by progressively growing the neural architecture as needed and dynamically routing data through the appropriate adaptors and reconfigurators for handling domain-incremental and class-incremental continual learning. We systematically evaluate our approach on several benchmark datasets for domain adaptation and demonstrate strong performance compared to state-of-the-art algorithms for OOD detection and few-/zero-shot NAS.
</details>
<details>
<summary>摘要</summary>
大多数机器学习（ML）系统假设训练和部署期间数据分布保持静态和匹配。这是一个不实际的假设。当 ML 模型在真实设备上部署时，数据分布经常在时间变化，这是由环境因素、感知特征和任务关注点的变化引起的。虽然可以有人在Loop（human-in-the-loop）监控数据分布的变化并根据这些变化设计新的建筑，但这种设置不是可持续的。相反，不可靠自动机器学习（AutoML）模型是需要的。这篇论文提出了 Encoder-Adaptor-Reconfigurator（EAR）框架，用于效率地进行逐步学习下降。EAR 框架使用固定的深度神经网络（DNN）特征编码器，并在编码器之上训练浅层网络来处理新的数据。EAR 框架可以1) 将新数据确定为外部数据（OOD），通过将 DNN 与高维计算（HDC）结合使用，2) 使用零参数神经适应器适应模型到OOD 数据，并3) 使用进行逐步增长的神经网络，逐步地处理域逐步学习和类逐步学习。我们系统地评估了我们的方法在域逐步学习和类逐步学习中的表现，并与当前最佳算法相比，在OOD 检测和几个/零个 NAS 方面表现出色。
</details></li>
</ul>
<hr>
<h2 id="Target-specification-bias-counterfactual-prediction-and-algorithmic-fairness-in-healthcare"><a href="#Target-specification-bias-counterfactual-prediction-and-algorithmic-fairness-in-healthcare" class="headerlink" title="Target specification bias, counterfactual prediction, and algorithmic fairness in healthcare"></a>Target specification bias, counterfactual prediction, and algorithmic fairness in healthcare</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02081">http://arxiv.org/abs/2308.02081</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eran Tal</li>
<li>for: 这篇论文旨在描述机器学习（ML）在医疗领域中的偏见来源，并提出一种新的方法来解决这种偏见。</li>
<li>methods: 该论文使用了一种新的方法，即“target specification bias”，来描述医疗领域中ML模型的偏见来源。该方法基于决策者对假设enario的预测，而不是实际情况的预测。</li>
<li>results: 该论文的结果表明，target specification bias是医疗领域中ML模型偏见的一种常见来源，并且可能导致医疗资源的不合理使用和伤害病人。同时，该论文还提出了一种新的方法来解决这种偏见，即通过对目标变量的操作来减少target specification bias。<details>
<summary>Abstract</summary>
Bias in applications of machine learning (ML) to healthcare is usually attributed to unrepresentative or incomplete data, or to underlying health disparities. This article identifies a more pervasive source of bias that affects the clinical utility of ML-enabled prediction tools: target specification bias. Target specification bias arises when the operationalization of the target variable does not match its definition by decision makers. The mismatch is often subtle, and stems from the fact that decision makers are typically interested in predicting the outcomes of counterfactual, rather than actual, healthcare scenarios. Target specification bias persists independently of data limitations and health disparities. When left uncorrected, it gives rise to an overestimation of predictive accuracy, to inefficient utilization of medical resources, and to suboptimal decisions that can harm patients. Recent work in metrology - the science of measurement - suggests ways of counteracting target specification bias and avoiding its harmful consequences.
</details>
<details>
<summary>摘要</summary>
Machine learning（ML）在医疗领域中的偏见通常被归结于不代表性或不完整的数据，或者基础医疗差距。这篇文章揭示了一种更普遍的偏见源，对mlenabled预测工具的临床实用性产生了影响：目标规定偏见。目标规定偏见发生在ml模型操作时，实际目标变量与决策者所定义的目标变量之间存在差异。这种差异通常是微妙的，来自于决策者通常关注预测实际医疗enario的结果，而不是实际的医疗enario。这种偏见独立于数据限制和医疗差距，并且会导致预测精度过高、医疗资源的不合理使用和伤害病人的决策。近期的metrology研究（量度科学）提供了对target specification bias的应对方法和避免其有害后果的方法。
</details></li>
</ul>
<hr>
<h2 id="Causality-Guided-Disentanglement-for-Cross-Platform-Hate-Speech-Detection"><a href="#Causality-Guided-Disentanglement-for-Cross-Platform-Hate-Speech-Detection" class="headerlink" title="Causality Guided Disentanglement for Cross-Platform Hate Speech Detection"></a>Causality Guided Disentanglement for Cross-Platform Hate Speech Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02080">http://arxiv.org/abs/2308.02080</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/paras2612/catch">https://github.com/paras2612/catch</a></li>
<li>paper_authors: Paras Sheth, Tharindu Kumarage, Raha Moraffah, Aman Chadha, Huan Liu</li>
<li>for: 本研究旨在开发一种可以在多个平台上训练和生成恐吓言语检测模型，以解决现有模型过于依赖特定语言信号和分类词的局限性，以及缺乏高质量标注数据的问题。</li>
<li>methods: 本研究使用了分解输入表示的方法，将输入表示分为不同平台的特征和平台独特的特征，以学习不同平台上的恐吓言语表示。此外，研究还利用了 causal 关系学习来更好地理解不同环境下的恐吓言语表示。</li>
<li>results: 研究的实验结果表明， compared to 现有状态的方法，本研究的模型在多个平台上的恐吓言语检测效果明显更高。<details>
<summary>Abstract</summary>
Social media platforms, despite their value in promoting open discourse, are often exploited to spread harmful content. Current deep learning and natural language processing models used for detecting this harmful content overly rely on domain-specific terms affecting their capabilities to adapt to generalizable hate speech detection. This is because they tend to focus too narrowly on particular linguistic signals or the use of certain categories of words. Another significant challenge arises when platforms lack high-quality annotated data for training, leading to a need for cross-platform models that can adapt to different distribution shifts. Our research introduces a cross-platform hate speech detection model capable of being trained on one platform's data and generalizing to multiple unseen platforms. To achieve good generalizability across platforms, one way is to disentangle the input representations into invariant and platform-dependent features. We also argue that learning causal relationships, which remain constant across diverse environments, can significantly aid in understanding invariant representations in hate speech. By disentangling input into platform-dependent features (useful for predicting hate targets) and platform-independent features (used to predict the presence of hate), we learn invariant representations resistant to distribution shifts. These features are then used to predict hate speech across unseen platforms. Our extensive experiments across four platforms highlight our model's enhanced efficacy compared to existing state-of-the-art methods in detecting generalized hate speech.
</details>
<details>
<summary>摘要</summary>
社交媒体平台，尽管它们在促进开放的讨论方面具有价值，但它们也被滥用来传播危险内容。现有的深入学习和自然语言处理模型用于检测这种危险内容往往仅仅依赖于域内特定的术语，导致它们在泛化仇言检测方面有限制。此外，当平台缺乏高质量标注数据 для训练时，需要开发可以适应不同分布偏移的跨平台模型。我们的研究推出了一种可以在一个平台的数据上训练并在多个未看过平台上生效的恶意语言检测模型。为实现良好的泛化性 across 平台，我们可以将输入表示分解为不变和平台特定的特征。我们还 argue 了解不变的 causal 关系可以帮助理解不变的表示在仇言中。通过将输入分解为平台特定的特征（用于预测仇恨目标）和平台独立的特征（用于预测存在仇恨），我们学习了不变的表示，这些表示对各种环境的分布偏移具有抗逆性。这些特征最后被用来预测恶意语言 across 未看过平台。我们的广泛的实验 across 四个平台表明我们的模型在检测通用的仇言方面具有显著的高效性，比现有的状态的艺术方法更高效。
</details></li>
</ul>
<hr>
<h2 id="Specious-Sites-Tracking-the-Spread-and-Sway-of-Spurious-News-Stories-at-Scale"><a href="#Specious-Sites-Tracking-the-Spread-and-Sway-of-Spurious-News-Stories-at-Scale" class="headerlink" title="Specious Sites: Tracking the Spread and Sway of Spurious News Stories at Scale"></a>Specious Sites: Tracking the Spread and Sway of Spurious News Stories at Scale</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02068">http://arxiv.org/abs/2308.02068</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hans W. A. Hanley, Deepak Kumar, Zakir Durumeric</li>
<li>for: 这研究旨在自动跟踪在线平台上流行的新闻 narative，以帮助检测和推篱虚假信息。</li>
<li>methods: 该研究使用大型自然语言模型 MPNet 和 DP-Means 归一 clustering 技术，日常抓取 1,404 个不可靠新闻网站，自动孤立和分析在线生态系统中流行的 narratives。</li>
<li>results: 该研究发现了 2022 年最流行的新闻 narratives，并 identificated 最具影响力的网站，这些网站通常是新闻 narative 的起点和扩大源。此外，研究还表明了该系统可以帮助 факт-检查机构如 Politifact、Reuters 和 AP News 更快地解决虚假信息故事。<details>
<summary>Abstract</summary>
Misinformation, propaganda, and outright lies proliferate on the web, with some narratives having dangerous real-world consequences on public health, elections, and individual safety. However, despite the impact of misinformation, the research community largely lacks automated and programmatic approaches for tracking news narratives across online platforms. In this work, utilizing daily scrapes of 1,404 unreliable news websites, the large-language model MPNet, and DP-Means clustering, we introduce a system to automatically isolate and analyze the narratives spread within online ecosystems. Identifying 55,301 narratives on these 1,404 websites, we describe the most prevalent narratives spread in 2022 and identify the most influential websites that originate and magnify narratives. Finally, we show how our system can be utilized to detect new narratives originating from unreliable news websites and aid fact-checkers like Politifact, Reuters, and AP News in more quickly addressing misinformation stories.
</details>
<details>
<summary>摘要</summary>
互联网上流传谣言、宣传和谎言，有些叙述可能有危害公共健康、选举和个人安全的危险。然而，研究社区在 automatized 和程序化的方面缺乏跟踪新闻叙述的方法。在这项工作中，我们使用每天抓取1,404个不可靠新闻网站，大型自然语言模型MPNet，以及DP-Means clustering，开发了一个系统来自动孤立和分析在线生态系统中流传的叙述。我们发现了2022年流传的55,301个叙述，并指出了这些叙述的最有影响力的网站。最后，我们示出了如何使用我们的系统来检测来自不可靠新闻网站的新叙述，并帮助 факт-检查机构如Politifact、Reuters 和AP News更快地解决谣言故事。
</details></li>
</ul>
<hr>
<h2 id="Mitigating-Task-Interference-in-Multi-Task-Learning-via-Explicit-Task-Routing-with-Non-Learnable-Primitives"><a href="#Mitigating-Task-Interference-in-Multi-Task-Learning-via-Explicit-Task-Routing-with-Non-Learnable-Primitives" class="headerlink" title="Mitigating Task Interference in Multi-Task Learning via Explicit Task Routing with Non-Learnable Primitives"></a>Mitigating Task Interference in Multi-Task Learning via Explicit Task Routing with Non-Learnable Primitives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02066">http://arxiv.org/abs/2308.02066</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhichao-lu/etr-nlp-mtl">https://github.com/zhichao-lu/etr-nlp-mtl</a></li>
<li>paper_authors: Chuntao Ding, Zhichao Lu, Shangguang Wang, Ran Cheng, Vishnu Naresh Boddeti</li>
<li>for: This paper proposes a method to mitigate task interference in multi-task learning (MTL) models by combining non-learnable primitives (NLPs) and explicit task routing (ETR).</li>
<li>methods: The proposed ETR-NLP model employs non-learnable primitives to extract task-agnostic features and recombine them into a shared branch common to all tasks and explicit task-specific branches reserved for each task.</li>
<li>results: The proposed ETR-NLP model significantly outperforms state-of-the-art baselines with fewer learnable parameters and similar FLOPs across all datasets.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文提出了一种用于避免多任务学习（MTL）模型中任务干扰的方法，通过结合非学习式基本元素（NLP）和显式任务路由（ETR）来实现。</li>
<li>methods: 提议的 ETR-NLP 模型使用非学习式基本元素来提取任务共享的特征，并将其重新组合成共享到所有任务的分支和每个任务的专门的分支。</li>
<li>results: 提议的 ETR-NLP 模型在所有数据集上都达到了比基eline更高的性能，使用 fewer 的学习参数和相同的计算复杂度（FLOPs）。<details>
<summary>Abstract</summary>
Multi-task learning (MTL) seeks to learn a single model to accomplish multiple tasks by leveraging shared information among the tasks. Existing MTL models, however, have been known to suffer from negative interference among tasks. Efforts to mitigate task interference have focused on either loss/gradient balancing or implicit parameter partitioning with partial overlaps among the tasks. In this paper, we propose ETR-NLP to mitigate task interference through a synergistic combination of non-learnable primitives (NLPs) and explicit task routing (ETR). Our key idea is to employ non-learnable primitives to extract a diverse set of task-agnostic features and recombine them into a shared branch common to all tasks and explicit task-specific branches reserved for each task. The non-learnable primitives and the explicit decoupling of learnable parameters into shared and task-specific ones afford the flexibility needed for minimizing task interference. We evaluate the efficacy of ETR-NLP networks for both image-level classification and pixel-level dense prediction MTL problems. Experimental results indicate that ETR-NLP significantly outperforms state-of-the-art baselines with fewer learnable parameters and similar FLOPs across all datasets. Code is available at this \href{https://github.com/zhichao-lu/etr-nlp-mtl}.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose ETR-NLP to mitigate task interference through a synergistic combination of non-learnable primitives (NLPs) and explicit task routing (ETR). Our key idea is to use non-learnable primitives to extract a diverse set of task-agnostic features and recombine them into a shared branch common to all tasks and explicit task-specific branches reserved for each task. The non-learnable primitives and the explicit decoupling of learnable parameters into shared and task-specific ones provide the flexibility needed for minimizing task interference.We evaluate the effectiveness of ETR-NLP networks for both image-level classification and pixel-level dense prediction MTL problems. Experimental results show that ETR-NLP significantly outperforms state-of-the-art baselines with fewer learnable parameters and similar FLOPs across all datasets. Code is available at this link: <https://github.com/zhichao-lu/etr-nlp-mtl>.
</details></li>
</ul>
<hr>
<h2 id="On-the-Biometric-Capacity-of-Generative-Face-Models"><a href="#On-the-Biometric-Capacity-of-Generative-Face-Models" class="headerlink" title="On the Biometric Capacity of Generative Face Models"></a>On the Biometric Capacity of Generative Face Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02065">http://arxiv.org/abs/2308.02065</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/human-analysis/capacity-generative-face-models">https://github.com/human-analysis/capacity-generative-face-models</a></li>
<li>paper_authors: Vishnu Naresh Boddeti, Gautam Sreekumar, Arun Ross</li>
<li>for: 这个论文的目的是为了计算生成的人脸模型中的生物 metric 的上限，以便评估和比较不同的生成人脸模型的可扩展性。</li>
<li>methods: 该论文使用了一种统计方法，通过在幂圆特征空间中计算生成的人脸图像的异常性，来估算生成人脸模型的生物 metric 的上限。</li>
<li>results: 该论文的结果显示，StyleGAN3 和 DCFace 生成的人脸图像的生物 metric 的上限分别为 $1.43\times10^6$ 和 $1.190\times10^4$，而降低 False Acceptance Rate (FAR) 时，这些生物 metric 的上限减少至 $1.796\times10^4$ 和 $562$。此外，该论文还发现，一些生成人脸模型对年龄存在显著差异，但对 gender 没有差异。<details>
<summary>Abstract</summary>
There has been tremendous progress in generating realistic faces with high fidelity over the past few years. Despite this progress, a crucial question remains unanswered: "Given a generative face model, how many unique identities can it generate?" In other words, what is the biometric capacity of the generative face model? A scientific basis for answering this question will benefit evaluating and comparing different generative face models and establish an upper bound on their scalability. This paper proposes a statistical approach to estimate the biometric capacity of generated face images in a hyperspherical feature space. We employ our approach on multiple generative models, including unconditional generators like StyleGAN, Latent Diffusion Model, and "Generated Photos," as well as DCFace, a class-conditional generator. We also estimate capacity w.r.t. demographic attributes such as gender and age. Our capacity estimates indicate that (a) under ArcFace representation at a false acceptance rate (FAR) of 0.1%, StyleGAN3 and DCFace have a capacity upper bound of $1.43\times10^6$ and $1.190\times10^4$, respectively; (b) the capacity reduces drastically as we lower the desired FAR with an estimate of $1.796\times10^4$ and $562$ at FAR of 1% and 10%, respectively, for StyleGAN3; (c) there is no discernible disparity in the capacity w.r.t gender; and (d) for some generative models, there is an appreciable disparity in the capacity w.r.t age. Code is available at https://github.com/human-analysis/capacity-generative-face-models.
</details>
<details>
<summary>摘要</summary>
“过去几年来，生成高效精确的脸部模型有了很大的进步。然而，一个重要的问题仍然没有答案：“将生成的脸部模型如何生成多少个独特的身份？”这个问题的科学基础可以帮助评估和比较不同的生成脸部模型，并且可以定义生成脸部模型的扩展性上限。本文提出了一个统计方法来估算生成脸部模型中的生物特征容量。我们使用这个方法评估多个生成模型，包括StyleGAN、Latent Diffusion Model和“Generated Photos”等，以及DCFace，一个基于类别的生成模型。我们还估算了基于人口特征如年龄和性别的容量。我们的容量估算表明：（a）在ArcFace表现下，StyleGAN3和DCFace的容量上限为1.43×10^6和1.190×10^4，分别;（b）随着欲求False Acceptance Rate（FAR）下降，StyleGAN3的容量几乎急遽减少， estimate为1.796×10^4和562，分别;（c）与性别无显著差异;（d）某些生成模型对年龄有明显差异。相关代码可以在https://github.com/human-analysis/capacity-generative-face-models 取得。”
</details></li>
</ul>
<hr>
<h2 id="Accurate-Neural-Network-Pruning-Requires-Rethinking-Sparse-Optimization"><a href="#Accurate-Neural-Network-Pruning-Requires-Rethinking-Sparse-Optimization" class="headerlink" title="Accurate Neural Network Pruning Requires Rethinking Sparse Optimization"></a>Accurate Neural Network Pruning Requires Rethinking Sparse Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02060">http://arxiv.org/abs/2308.02060</a></li>
<li>repo_url: None</li>
<li>paper_authors: Denis Kuznedelev, Eldar Kurtic, Eugenia Iofinova, Elias Frantar, Alexandra Peste, Dan Alistarh</li>
<li>for: 本研究旨在探讨高缺省略对模型训练的影响，以及如何使用标准随机搜索技术来训练缺省略网络。</li>
<li>methods: 本研究使用了标准计算机视觉和自然语言处理缺省略标准准则进行训练，并提供了一些新的方法来 Mitigate the issue of sparse training。</li>
<li>results: 研究结果显示，使用标准稠密训练策略对缺省略训练是不优化的，会导致模型受训练不良。研究人员提供了一些新的方法，以实现高缺省略下的模型训练，并在计算机视觉和自然语言处理两个领域中达到了状态的训练结果。<details>
<summary>Abstract</summary>
Obtaining versions of deep neural networks that are both highly-accurate and highly-sparse is one of the main challenges in the area of model compression, and several high-performance pruning techniques have been investigated by the community. Yet, much less is known about the interaction between sparsity and the standard stochastic optimization techniques used for training sparse networks, and most existing work uses standard dense schedules and hyperparameters for training sparse networks. In this work, we examine the impact of high sparsity on model training using the standard computer vision and natural language processing sparsity benchmarks. We begin by showing that using standard dense training recipes for sparse training is suboptimal, and results in under-training. We provide new approaches for mitigating this issue for both sparse pre-training of vision models (e.g. ResNet50/ImageNet) and sparse fine-tuning of language models (e.g. BERT/GLUE), achieving state-of-the-art results in both settings in the high-sparsity regime, and providing detailed analyses for the difficulty of sparse training in both scenarios. Our work sets a new threshold in terms of the accuracies that can be achieved under high sparsity, and should inspire further research into improving sparse model training, to reach higher accuracies under high sparsity, but also to do so efficiently.
</details>
<details>
<summary>摘要</summary>
We first show that using standard dense training recipes for sparse training results in under-training, and we propose new approaches to mitigate this issue. Our methods achieve state-of-the-art results in both sparse pre-training of vision models (e.g. ResNet50/ImageNet) and sparse fine-tuning of language models (e.g. BERT/GLUE) in the high-sparsity regime. We also provide detailed analyses of the difficulty of sparse training in both scenarios. Our work sets a new threshold for the accuracies that can be achieved under high sparsity, and should inspire further research into improving sparse model training to reach higher accuracies under high sparsity, while also being efficient.
</details></li>
</ul>
<hr>
<h2 id="Incorporating-Recklessness-to-Collaborative-Filtering-based-Recommender-Systems"><a href="#Incorporating-Recklessness-to-Collaborative-Filtering-based-Recommender-Systems" class="headerlink" title="Incorporating Recklessness to Collaborative Filtering based Recommender Systems"></a>Incorporating Recklessness to Collaborative Filtering based Recommender Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02058">http://arxiv.org/abs/2308.02058</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/knodis-research-group/recklessness-regularization">https://github.com/knodis-research-group/recklessness-regularization</a></li>
<li>paper_authors: Diego Pérez-López, Fernando Ortega, Ángel González-Prieto, Jorge Dueñas-Lerín</li>
<li>for: 提高 Matrix Factorization 基于的个性化推荐系统的风险评估和决策精度。</li>
<li>methods: 提出一个新的 recklessness  термин，用于控制 Matrix Factorization 系统的决策时的风险水平。</li>
<li>results: 实验结果表明，recklessness 不仅可以控制风险，还可以提高推荐系统的预测量和质量。<details>
<summary>Abstract</summary>
Recommender systems that include some reliability measure of their predictions tend to be more conservative in forecasting, due to their constraint to preserve reliability. This leads to a significant drop in the coverage and novelty that these systems can provide. In this paper, we propose the inclusion of a new term in the learning process of matrix factorization-based recommender systems, called recklessness, which enables the control of the risk level desired when making decisions about the reliability of a prediction. Experimental results demonstrate that recklessness not only allows for risk regulation but also improves the quantity and quality of predictions provided by the recommender system.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate "Recommender systems that include some reliability measure of their predictions tend to be more conservative in forecasting, due to their constraint to preserve reliability. This leads to a significant drop in the coverage and novelty that these systems can provide. In this paper, we propose the inclusion of a new term in the learning process of matrix factorization-based recommender systems, called recklessness, which enables the control of the risk level desired when making decisions about the reliability of a prediction. Experimental results demonstrate that recklessness not only allows for risk regulation but also improves the quantity and quality of predictions provided by the recommender system." into 简化字 Simplified Chinese.Here's the translation:<<SYS>>推荐系统通常会因为保持可靠性的约束而变得更加保守，这会导致涵盖率和创新率的下降。在这篇论文中，我们提议在基于矩阵因子化的推荐系统学习过程中添加一个新的 термин，即“recklessness”，以控制预测可靠性的风险水平。实验结果表明，recklessness不仅允许风险规定，还可以提高推荐系统预测的质量和量。
</details></li>
</ul>
<hr>
<h2 id="Seasonality-Based-Reranking-of-E-commerce-Autocomplete-Using-Natural-Language-Queries"><a href="#Seasonality-Based-Reranking-of-E-commerce-Autocomplete-Using-Natural-Language-Queries" class="headerlink" title="Seasonality Based Reranking of E-commerce Autocomplete Using Natural Language Queries"></a>Seasonality Based Reranking of E-commerce Autocomplete Using Natural Language Queries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02055">http://arxiv.org/abs/2308.02055</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prateek Verma, Shan Zhong, Xiaoyu Liu, Adithya Rajan</li>
<li>for: 提高搜索引擎中的Query Autocomplete（QAC）功能的准确率和商业指标，使用神经网络基于自然语言处理（NLP）算法以吸收季节性信号。</li>
<li>methods: 使用神经网络基于NLP算法，将季节性信号纳入QAC排名模型中，实现终端评估。</li>
<li>results: 研究表明，吸收季节性信号可以提高QAC relevance和商业指标，提供了一种新的方法来评估和优化QAC模型。<details>
<summary>Abstract</summary>
Query autocomplete (QAC) also known as typeahead, suggests list of complete queries as user types prefix in the search box. It is one of the key features of modern search engines specially in e-commerce. One of the goals of typeahead is to suggest relevant queries to users which are seasonally important. In this paper we propose a neural network based natural language processing (NLP) algorithm to incorporate seasonality as a signal and present end to end evaluation of the QAC ranking model. Incorporating seasonality into autocomplete ranking model can improve autocomplete relevance and business metric.
</details>
<details>
<summary>摘要</summary>
查询自动完成（QAC）也称为预先提示，在搜索框中提供完整的查询列表，根据用户输入前缀。这是现代搜索引擎的一个关键功能，尤其在电商领域。QAC的一个目标是提供相关的查询，以便用户在不同的季节中搜索相关的内容。在这篇论文中，我们提出一种基于神经网络自然语言处理（NLP）算法的方法，以吸收季节信号并对QAC排名模型进行综合评估。在吸收季节信号的情况下，QAC排名模型的相关性和业务指标都可以得到改善。
</details></li>
</ul>
<hr>
<h2 id="Robust-Independence-Tests-with-Finite-Sample-Guarantees-for-Synchronous-Stochastic-Linear-Systems"><a href="#Robust-Independence-Tests-with-Finite-Sample-Guarantees-for-Synchronous-Stochastic-Linear-Systems" class="headerlink" title="Robust Independence Tests with Finite Sample Guarantees for Synchronous Stochastic Linear Systems"></a>Robust Independence Tests with Finite Sample Guarantees for Synchronous Stochastic Linear Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02054">http://arxiv.org/abs/2308.02054</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ambrus Tamás, Dániel Ágoston Bálint, Balázs Csanád Csáji</li>
<li>for: 这个论文是为了开发一种robust independence测试，以确保 Stochastic Linear Time-Invariant（SLTI）系统中的产生的输出是独立的。</li>
<li>methods: 这个方法使用了 confidence region estimates 和 permutation tests，以及一些总体依赖度度量，如希尔伯特-Ш密特独立性准则和距离协方差，来检测 SLTI 系统中的非线性依赖关系。</li>
<li>results: 这个研究提供了不吸收准确性水平的类型一错误概率的上下文，并证明了这种假设测试的一致性，并通过对抗系统的示例进行了示例。<details>
<summary>Abstract</summary>
The paper introduces robust independence tests with non-asymptotically guaranteed significance levels for stochastic linear time-invariant systems, assuming that the observed outputs are synchronous, which means that the systems are driven by jointly i.i.d. noises. Our method provides bounds for the type I error probabilities that are distribution-free, i.e., the innovations can have arbitrary distributions. The algorithm combines confidence region estimates with permutation tests and general dependence measures, such as the Hilbert-Schmidt independence criterion and the distance covariance, to detect any nonlinear dependence between the observed systems. We also prove the consistency of our hypothesis tests under mild assumptions and demonstrate the ideas through the example of autoregressive systems.
</details>
<details>
<summary>摘要</summary>
文章介绍了一种Robust Independence Test，可以确定温馈线性时间不变系统中的独立性，无需假设抽象分布。我们的方法提供了对type I error probability的分布不受限制的 bounds，可以处理任何输出的异常分布。我们的算法结合了信任区间估计和 permutation tests，以及一些普遍的依赖度量，如希尔伯特-尚德独立性标准和距离协方差，来检测系统中的非线性依赖关系。我们还证明了我们的假设测试在某些轻度的假设下是一致的。我们通过示例描述了抽象系统的应用。
</details></li>
</ul>
<hr>
<h2 id="A-Graphical-Approach-to-Document-Layout-Analysis"><a href="#A-Graphical-Approach-to-Document-Layout-Analysis" class="headerlink" title="A Graphical Approach to Document Layout Analysis"></a>A Graphical Approach to Document Layout Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02051">http://arxiv.org/abs/2308.02051</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jilin Wang, Michael Krumdick, Baojia Tong, Hamima Halim, Maxim Sokolov, Vadym Barda, Delphine Vendryes, Chris Tanner</li>
<li>for: 文章的目的是提出一种基于图гра� neural network的文档布局分析模型（GLAM），用于解决文档布局分析（DLA）问题。</li>
<li>methods: 文章使用了一种基于图гра�的布局分析模型（GLAM），该模型直接利用PDF文档中的metadata，将每个PDF页面转换为一个结构化的图гра�，然后将DLA问题定义为图гра�分类和 segmentation问题。</li>
<li>results: 对两个Difficult DLA datasets进行测试，GLAM模型在5个类型上比领先的140M+参数的计算机视ión基本模型表现更好，并且一种简单的 ensemble 模型可以在DocLayNet dataset上 achieve新的状态� slower than SOTA models, making GLAM a favorable engineering choice for DLA tasks。<details>
<summary>Abstract</summary>
Document layout analysis (DLA) is the task of detecting the distinct, semantic content within a document and correctly classifying these items into an appropriate category (e.g., text, title, figure). DLA pipelines enable users to convert documents into structured machine-readable formats that can then be used for many useful downstream tasks. Most existing state-of-the-art (SOTA) DLA models represent documents as images, discarding the rich metadata available in electronically generated PDFs. Directly leveraging this metadata, we represent each PDF page as a structured graph and frame the DLA problem as a graph segmentation and classification problem. We introduce the Graph-based Layout Analysis Model (GLAM), a lightweight graph neural network competitive with SOTA models on two challenging DLA datasets - while being an order of magnitude smaller than existing models. In particular, the 4-million parameter GLAM model outperforms the leading 140M+ parameter computer vision-based model on 5 of the 11 classes on the DocLayNet dataset. A simple ensemble of these two models achieves a new state-of-the-art on DocLayNet, increasing mAP from 76.8 to 80.8. Overall, GLAM is over 5 times more efficient than SOTA models, making GLAM a favorable engineering choice for DLA tasks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SMARLA-A-Safety-Monitoring-Approach-for-Deep-Reinforcement-Learning-Agents"><a href="#SMARLA-A-Safety-Monitoring-Approach-for-Deep-Reinforcement-Learning-Agents" class="headerlink" title="SMARLA: A Safety Monitoring Approach for Deep Reinforcement Learning Agents"></a>SMARLA: A Safety Monitoring Approach for Deep Reinforcement Learning Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02594">http://arxiv.org/abs/2308.02594</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amirhossein Zolfagharian, Manel Abdellatif, Lionel C. Briand, Ramesh S</li>
<li>for: 这篇论文旨在解决深度权威学习算法在安全关键系统中的安全问题。</li>
<li>methods: 本文提出了一种基于机器学习的安全监测方法，名为SMARLA，可以用于 Deep Reinforcement Learning 代理人。SMARLA 是一个黑盒式方法（不需要访问代理人的内部），利用状态抽象来减少状态空间，从而使得学习安全违反预测模型更加容易。</li>
<li>results: 在两个常见的RL案例研究中，我们证明了SMARLA 可以准确预测安全违反，false positive 率很低，可以在代理人执行的前半部分预测安全违反，大约在代理人执行的第二部分时。<details>
<summary>Abstract</summary>
Deep reinforcement learning algorithms (DRL) are increasingly being used in safety-critical systems. Ensuring the safety of DRL agents is a critical concern in such contexts. However, relying solely on testing is not sufficient to ensure safety as it does not offer guarantees. Building safety monitors is one solution to alleviate this challenge. This paper proposes SMARLA, a machine learning-based safety monitoring approach designed for DRL agents. For practical reasons, SMARLA is designed to be black-box (as it does not require access to the internals of the agent) and leverages state abstraction to reduce the state space and thus facilitate the learning of safety violation prediction models from agent's states. We validated SMARLA on two well-known RL case studies. Empirical analysis reveals that SMARLA achieves accurate violation prediction with a low false positive rate, and can predict safety violations at an early stage, approximately halfway through the agent's execution before violations occur.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="FuNToM-Functional-Modeling-of-RF-Circuits-Using-a-Neural-Network-Assisted-Two-Port-Analysis-Method"><a href="#FuNToM-Functional-Modeling-of-RF-Circuits-Using-a-Neural-Network-Assisted-Two-Port-Analysis-Method" class="headerlink" title="FuNToM: Functional Modeling of RF Circuits Using a Neural Network Assisted Two-Port Analysis Method"></a>FuNToM: Functional Modeling of RF Circuits Using a Neural Network Assisted Two-Port Analysis Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02050">http://arxiv.org/abs/2308.02050</a></li>
<li>repo_url: None</li>
<li>paper_authors: Morteza Fayazi, Morteza Tavakoli Taba, Amirata Tabatabavakili, Ehsan Afshari, Ronald Dreslinski</li>
<li>for: 这个论文的目的是提出一种基于人工智能的电路模型化方法，以提高电路设计的效率和准确性。</li>
<li>methods: 这个方法利用了两个 porte 分析方法，可以模型多种电路架构，并且使用神经网络来预测电路的行为。</li>
<li>results: 相比于现有的方法，这个方法可以将训练数据量降低至 2.8x - 10.9x，并且对于实体电路的模型化需要更少的时间（176.8x - 188.6x）。<details>
<summary>Abstract</summary>
Automatic synthesis of analog and Radio Frequency (RF) circuits is a trending approach that requires an efficient circuit modeling method. This is due to the expensive cost of running a large number of simulations at each synthesis cycle. Artificial intelligence methods are promising approaches for circuit modeling due to their speed and relative accuracy. However, existing approaches require a large amount of training data, which is still collected using simulation runs. In addition, such approaches collect a whole separate dataset for each circuit topology even if a single element is added or removed. These matters are only exacerbated by the need for post-layout modeling simulations, which take even longer. To alleviate these drawbacks, in this paper, we present FuNToM, a functional modeling method for RF circuits. FuNToM leverages the two-port analysis method for modeling multiple topologies using a single main dataset and multiple small datasets. It also leverages neural networks which have shown promising results in predicting the behavior of circuits. Our results show that for multiple RF circuits, in comparison to the state-of-the-art works, while maintaining the same accuracy, the required training data is reduced by 2.8x - 10.9x. In addition, FuNToM needs 176.8x - 188.6x less time for collecting the training set in post-layout modeling.
</details>
<details>
<summary>摘要</summary>
自动生成分析和无线频率（RF）Circuit是一种升温的方法，需要有效的电路模型方法。这是因为在每个合成周期中运行大量的 simulations 的成本高昂。人工智能方法是可靠的approach  для电路模型，因为它们的速度和相对准确性。然而，现有的方法需要大量的训练数据，这些数据仍然通过 simulation runs 收集。此外，这些方法每个电路拓扑都需要一个分立的数据集，即使只是添加或删除一个元素。这些问题被加速器了，因为需要后处理模拟，这些模拟需要更长的时间。为了缓解这些缺点，在这篇论文中，我们提出了 FuNToM，一种功能模型方法 для RF Circuit。FuNToM 利用了两个端口分析方法，用于模型多种拓扑，使用单个主数据集和多个小数据集。它还利用了人工神经网络，这些神经网络在预测电路行为方面表现出色。我们的结果表明，对多个 RF Circuit，与现状的工作相比，保持同样的准确性，需要的训练数据被减少了2.8倍 - 10.9倍。此外，FuNToM 在后处理模拟中收集训练集的时间需要176.8倍 - 188.6倍。
</details></li>
</ul>
<hr>
<h2 id="Deep-Maxout-Network-based-Feature-Fusion-and-Political-Tangent-Search-Optimizer-enabled-Transfer-Learning-for-Thalassemia-Detection"><a href="#Deep-Maxout-Network-based-Feature-Fusion-and-Political-Tangent-Search-Optimizer-enabled-Transfer-Learning-for-Thalassemia-Detection" class="headerlink" title="Deep Maxout Network-based Feature Fusion and Political Tangent Search Optimizer enabled Transfer Learning for Thalassemia Detection"></a>Deep Maxout Network-based Feature Fusion and Political Tangent Search Optimizer enabled Transfer Learning for Thalassemia Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02029">http://arxiv.org/abs/2308.02029</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hemn Barzan Abdalla, Awder Ahmed, Guoquan Li, Nasser Mustafa, Abdur Rashid Sangi</li>
<li>For: The paper is written for detecting thalassemia, a heritable blood disorder, and understanding the frequency of its occurrence and reliable mutations to prevent, control, and treat the disease.* Methods: The paper proposes a Political Tangent Search Optimizer based Transfer Learning (PTSO_TL) method for thalassemia detection, which includes data normalization, feature fusion, data augmentation, and convolutional neural network (CNN) with hyperparameters from a trained model such as Xception.* Results: The PTSO_TL method obtained maximal precision, recall, and f-measure values of about 94.3%, 96.1%, and 95.2%, respectively.Here is the simplified Chinese text for the three information points:* 用途：本研究是为了检测贫血病，一种遗传的血液疾病，以及其发生频率和可靠的突变，以便预防、控制和治疗该疾病。* 方法：本研究提出了一种基于政治折衣搜索优化器的转移学习（PTSO_TL）方法，包括数据Normalization、特征融合、数据增强和卷积神经网络（CNN）的hyperparameters。* 结果：PTSO_TL方法在识别贫血病方面取得了最高的准确率、回归率和f-度值，准确率达94.3%、回归率达96.1%和f-度值达95.2%。<details>
<summary>Abstract</summary>
Thalassemia is a heritable blood disorder which is the outcome of a genetic defect causing lack of production of hemoglobin polypeptide chains. However, there is less understanding of the precise frequency as well as sharing in these areas. Knowing about the frequency of thalassemia occurrence and dependable mutations is thus a significant step in preventing, controlling, and treatment planning. Here, Political Tangent Search Optimizer based Transfer Learning (PTSO_TL) is introduced for thalassemia detection. Initially, input data obtained from a particular dataset is normalized in the data normalization stage. Quantile normalization is utilized in the data normalization stage, and the data are then passed to the feature fusion phase, in which Weighted Euclidean Distance with Deep Maxout Network (DMN) is utilized. Thereafter, data augmentation is performed using the oversampling method to increase data dimensionality. Lastly, thalassemia detection is carried out by TL, wherein a convolutional neural network (CNN) is utilized with hyperparameters from a trained model such as Xception. TL is tuned by PTSO, and the training algorithm PTSO is presented by merging of Political Optimizer (PO) and Tangent Search Algorithm (TSA). Furthermore, PTSO_TL obtained maximal precision, recall, and f-measure values of about 94.3%, 96.1%, and 95.2%, respectively.
</details>
<details>
<summary>摘要</summary>
θαλασσημία 是一种遗传血液疾病，它的发病原因是遗传的蛋白质链缺失。然而， precis 的发病频率以及这些地区的分布不够了解。了解θαλασσημία的发病频率和可靠的突变可以是预防、控制和治疗规划的重要一步。在这里，我们引入了政治弯曲搜索优化器基于转移学习（PTSO_TL） для θαλασσημία检测。首先，输入数据从特定数据集中获取并Normalize。在数据Normalization阶段，我们使用Quantile Normalization，然后将数据传递给特征融合阶段。在这里，我们使用Weighted Euclidean Distance with Deep Maxout Network（DMN）。接着，我们使用扩展方法进行数据增强，以增加数据维度。最后，我们使用TL进行θαλασσημία检测，其中使用了一个准确网络（CNN），并将其与已训练模型Xception的超参数进行调整。PTSO_TL的最大精度、回归率和f-度分别达到了约94.3%、96.1%和95.2%。
</details></li>
</ul>
<hr>
<h2 id="Federated-Representation-Learning-for-Automatic-Speech-Recognition"><a href="#Federated-Representation-Learning-for-Automatic-Speech-Recognition" class="headerlink" title="Federated Representation Learning for Automatic Speech Recognition"></a>Federated Representation Learning for Automatic Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02013">http://arxiv.org/abs/2308.02013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guruprasad V Ramesh, Gopinath Chennupati, Milind Rao, Anit Kumar Sahu, Ariya Rastrow, Jasha Droppo</li>
<li>for: 这个研究是用来探讨 Federated Learning (FL) 技术如何保护数据隐私性的，同时学习 robust audio representation。</li>
<li>methods: 这篇论文使用了 Self-supervised Learning (SSL) 和 FL 技术，使用 Libri-Light 数据集中的无标签音频数据，通过 simulate non-IID speaker-siloed data distributions 来预训练 LSTM 编码器。</li>
<li>results: 研究表明，使用 FL 预训练模型可以达到与中央预训练模型相同的性能水平，并且在新语言 French 中进行适应性提高了20% (WER)。<details>
<summary>Abstract</summary>
Federated Learning (FL) is a privacy-preserving paradigm, allowing edge devices to learn collaboratively without sharing data. Edge devices like Alexa and Siri are prospective sources of unlabeled audio data that can be tapped to learn robust audio representations. In this work, we bring Self-supervised Learning (SSL) and FL together to learn representations for Automatic Speech Recognition respecting data privacy constraints. We use the speaker and chapter information in the unlabeled speech dataset, Libri-Light, to simulate non-IID speaker-siloed data distributions and pre-train an LSTM encoder with the Contrastive Predictive Coding framework with FedSGD. We show that the pre-trained ASR encoder in FL performs as well as a centrally pre-trained model and produces an improvement of 12-15% (WER) compared to no pre-training. We further adapt the federated pre-trained models to a new language, French, and show a 20% (WER) improvement over no pre-training.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 是一种隐私保护的 paradigm，allowing edge devices 学习合作而无需共享数据。 edge devices 如 Alexa 和 Siri 是可能的无标签音频数据的来源，可以用来学习Robust audio representations。在这项工作中，我们将Self-supervised Learning (SSL) 和 FL 结合以学习保持数据隐私的 Automatic Speech Recognition 表示。我们使用 Libri-Light 无标签speech 数据集中的speaker和chapter信息来模拟非ID的speaker-siloed 数据分布，并在 FedSGD 框架中预训练 LSTM Encoder。我们发现预训练 ASR Encoder 在 FL 中表现与中央预训练模型相当，并且生成了无预训练比较的 12-15% (WER) 的改进。我们进一步适应了联邦预训练模型到一种新语言，法语，并显示了无预训练比较的 20% (WER) 的改进。
</details></li>
</ul>
<hr>
<h2 id="Memory-capacity-of-two-layer-neural-networks-with-smooth-activations"><a href="#Memory-capacity-of-two-layer-neural-networks-with-smooth-activations" class="headerlink" title="Memory capacity of two layer neural networks with smooth activations"></a>Memory capacity of two layer neural networks with smooth activations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02001">http://arxiv.org/abs/2308.02001</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liam Madden, Christos Thrampoulidis</li>
<li>for: 该论文探讨了两层神经网络的内存容量问题，即神经网络可以储存的最大通用数据大小。</li>
<li>methods: 作者使用了非多项函数 activation 函数（如 sigmoid 和 smoothed ReLU），并通过计算 Jacobian 的核心矩阵的排名来分析内存容量。</li>
<li>results: 作者发现了一个下界 bound，asserting that md&#x2F;2 是两层神经网络的内存容量下界，并且这个下界可以达到一个因子约为 2 的优化。这些结果比前一些研究更加广泛，并且可以推广到更深的模型和其他架构。<details>
<summary>Abstract</summary>
Determining the memory capacity of two-layer neural networks with m hidden neurons and input dimension d (i.e., md+m total trainable parameters), which refers to the largest size of general data the network can memorize, is a fundamental machine-learning question. For non-polynomial real analytic activation functions, such as sigmoids and smoothed rectified linear units (smoothed ReLUs), we establish a lower bound of md/2 and optimality up to a factor of approximately 2. Analogous prior results were limited to Heaviside and ReLU activations, with results for smooth activations suffering from logarithmic factors and requiring random data. To analyze the memory capacity, we examine the rank of the network's Jacobian by computing the rank of matrices involving both Hadamard powers and the Khati-Rao product. Our computation extends classical linear algebraic facts about the rank of Hadamard powers. Overall, our approach differs from previous works on memory capacity and holds promise for extending to deeper models and other architectures.
</details>
<details>
<summary>摘要</summary>
To analyze the memory capacity, we examine the rank of the network's Jacobian by computing the rank of matrices involving both Hadamard powers and the Khati-Rao product. Our approach differs from previous works on memory capacity and holds promise for extending to deeper models and other architectures.Here is the translation in Simplified Chinese:确定两层神经网络的内存容量（即md+m总可训练参数）是机器学习的基本问题。对于非多项实数 activation functions，如sigmoid和smoothed ReLU，我们设下md/2的下界和优化因子约为2。这与之前的结果有所不同，它们仅适用于Heaviside和ReLU激活函数，并且受到了对数因子的影响，需要随机数据。为了分析内存容量，我们研究了神经网络的雅可比矩阵的排名，通过计算包括 Hadamard  powers 和 Khati-Rao 乘积的矩阵的排名。我们的方法与之前关于内存容量的工作不同，并且可能扩展到更深的模型和其他架构。
</details></li>
</ul>
<hr>
<h2 id="On-the-Transition-from-Neural-Representation-to-Symbolic-Knowledge"><a href="#On-the-Transition-from-Neural-Representation-to-Symbolic-Knowledge" class="headerlink" title="On the Transition from Neural Representation to Symbolic Knowledge"></a>On the Transition from Neural Representation to Symbolic Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02000">http://arxiv.org/abs/2308.02000</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyan Cheng, Peter Chin</li>
<li>for: 本研究旨在 bridge 神经网络和符号表示之间的巨大差距，使神经网络能够吸收符号思维的元素。</li>
<li>methods: 我们提出了一种启用EM算法学习数据的转换表示框架，以压缩输入数据中的高维信息，并自然地发现数据中隐藏的逻辑结构。</li>
<li>results: 我们在3个抽象compositional visual objects dataset上进行了广泛的实验，并证明了学习的表示可以准确地分解视觉输入，并且在下游任务中具有顺滑的适应性。<details>
<summary>Abstract</summary>
Bridging the huge disparity between neural and symbolic representation can potentially enable the incorporation of symbolic thinking into neural networks from essence. Motivated by how human gradually builds complex symbolic representation from the prototype symbols that are learned through perception and environmental interactions. We propose a Neural-Symbolic Transitional Dictionary Learning (TDL) framework that employs an EM algorithm to learn a transitional representation of data that compresses high-dimension information of visual parts of an input into a set of tensors as neural variables and discover the implicit predicate structure in a self-supervised way. We implement the framework with a diffusion model by regarding the decomposition of input as a cooperative game, then learn predicates by prototype clustering. We additionally use RL enabled by the Markovian of diffusion models to further tune the learned prototypes by incorporating subjective factors. Extensive experiments on 3 abstract compositional visual objects datasets that require the model to segment parts without any visual features like texture, color, or shadows apart from shape and 3 neural/symbolic downstream tasks demonstrate the learned representation enables interpretable decomposition of visual input and smooth adaption to downstream tasks which are not available by existing methods.
</details>
<details>
<summary>摘要</summary>
bridging the huge disparity between neural and symbolic representation can potentially enable the incorporation of symbolic thinking into neural networks from essence. motivated by how human gradually builds complex symbolic representation from the prototype symbols that are learned through perception and environmental interactions. we propose a neural-symbolic transitional dictionary learning (tdl) framework that employs an EM algorithm to learn a transitional representation of data that compresses high-dimension information of visual parts of an input into a set of tensors as neural variables and discover the implicit predicate structure in a self-supervised way. we implement the framework with a diffusion model by regarding the decomposition of input as a cooperative game, then learn predicates by prototype clustering. we additionally use rl enabled by the markovian of diffusion models to further tune the learned prototypes by incorporating subjective factors. extensive experiments on 3 abstract compositional visual objects datasets that require the model to segment parts without any visual features like texture, color, or shadows apart from shape and 3 neural/symbolic downstream tasks demonstrate the learned representation enables interpretable decomposition of visual input and smooth adaption to downstream tasks which are not available by existing methods.Here's a word-for-word translation of the text into Simplified Chinese:bridging the huge disparity between neural and symbolic representation can potentially enable the incorporation of symbolic thinking into neural networks from essence. motivated by how human gradually builds complex symbolic representation from the prototype symbols that are learned through perception and environmental interactions. we propose a neural-symbolic transitional dictionary learning (tdl) framework that employs an EM algorithm to learn a transitional representation of data that compresses high-dimension information of visual parts of an input into a set of tensors as neural variables and discover the implicit predicate structure in a self-supervised way. we implement the framework with a diffusion model by regarding the decomposition of input as a cooperative game, then learn predicates by prototype clustering. we additionally use rl enabled by the markovian of diffusion models to further tune the learned prototypes by incorporating subjective factors. extensive experiments on 3 abstract compositional visual objects datasets that require the model to segment parts without any visual features like texture, color, or shadows apart from shape and 3 neural/symbolic downstream tasks demonstrate the learned representation enables interpretable decomposition of visual input and smooth adaption to downstream tasks which are not available by existing methods.
</details></li>
</ul>
<hr>
<h2 id="Explainable-unsupervised-multi-modal-image-registration-using-deep-networks"><a href="#Explainable-unsupervised-multi-modal-image-registration-using-deep-networks" class="headerlink" title="Explainable unsupervised multi-modal image registration using deep networks"></a>Explainable unsupervised multi-modal image registration using deep networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01994">http://arxiv.org/abs/2308.01994</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengjia Wang, Giorgos Papanastasiou</li>
<li>for: 这 paper 的目的是提出一种基于深度学习的多Modalities MRI 图像 регистраción方法，以便在临床应用中提高图像识别率。</li>
<li>methods: 这 paper 使用了一种基于深度学习的图像处理管道，包括 intra-和inter-modality MRI 图像 регистраción，以及Grad-CAM 基于的解释性框架。</li>
<li>results: 研究人员通过在不同的模式和时间点进行图像 registration，并在不同的组织和Modalities之间进行图像对alignment，以达到superior的表现。此外，他们还通过Grad-CAM 基于的解释性框架，可以准确地解释模型与数据之间的关系。<details>
<summary>Abstract</summary>
Clinical decision making from magnetic resonance imaging (MRI) combines complementary information from multiple MRI sequences (defined as 'modalities'). MRI image registration aims to geometrically 'pair' diagnoses from different modalities, time points and slices. Both intra- and inter-modality MRI registration are essential components in clinical MRI settings. Further, an MRI image processing pipeline that can address both afine and non-rigid registration is critical, as both types of deformations may be occuring in real MRI data scenarios. Unlike image classification, explainability is not commonly addressed in image registration deep learning (DL) methods, as it is challenging to interpet model-data behaviours against transformation fields. To properly address this, we incorporate Grad-CAM-based explainability frameworks in each major component of our unsupervised multi-modal and multi-organ image registration DL methodology. We previously demonstrated that we were able to reach superior performance (against the current standard Syn method). In this work, we show that our DL model becomes fully explainable, setting the framework to generalise our approach on further medical imaging data.
</details>
<details>
<summary>摘要</summary>
临床决策从磁共振成像(MRI)结合多种MRI序列（定义为“modalities”）的信息。MRI图像对接目标是将不同modalities、时间点和 slice中的诊断进行几何对应。在临床MRI setting中， both intra-和inter-modalities MRI对接是关键组件。此外，一个能够处理both afine和非RIGID对接的MRI图像处理管道是重要的，因为这两种类型的变形都可能出现在实际MRI数据场景中。与图像分类不同，在图像对接深度学习（DL）方法中，解释性不常被考虑，因为很难从变换场景中解释模型与数据之间的行为。为了正确地解决这个问题，我们在每个主要组件中都包含了基于Grad-CAM的解释框架。在我们的无监督多modal和多器官图像对接DL方法中，我们之前已经达到了与当前标准Syn方法相比的更高性能。在这个工作中，我们展示了我们的DL模型已经变得可解释，设置了框架来普遍化我们的方法在更多的医疗影像数据上。
</details></li>
</ul>
<hr>
<h2 id="CartiMorph-a-framework-for-automated-knee-articular-cartilage-morphometrics"><a href="#CartiMorph-a-framework-for-automated-knee-articular-cartilage-morphometrics" class="headerlink" title="CartiMorph: a framework for automated knee articular cartilage morphometrics"></a>CartiMorph: a framework for automated knee articular cartilage morphometrics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01981">http://arxiv.org/abs/2308.01981</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yongchengyao/cartimorph">https://github.com/yongchengyao/cartimorph</a></li>
<li>paper_authors: Yongcheng Yao, Junru Zhong, Liping Zhang, Sheheryar Khan, Weitian Chen</li>
<li>for: 这个论文是为了提出一种自动计算膝关节软骨变形的框架，以便促进膝关节疾病的成像生物标志物的发现。</li>
<li>methods: 这个论文使用了深度学习模型来实现层次图像特征表示，并进行了图像分割、模板建立和图像到模板匹配等步骤。</li>
<li>results: 这个论文通过对患者的膝关节照片进行自动分割、模板建立和匹配，实现了对软骨的量化测量，包括全厚度软骨损伤率（FCL）、软骨厚度、表面积和体积的测量。并且对软骨厚度图进行了比较，发现在薄和 périphériques 地区的误差较小。<details>
<summary>Abstract</summary>
We introduce CartiMorph, a framework for automated knee articular cartilage morphometrics. It takes an image as input and generates quantitative metrics for cartilage subregions, including the percentage of full-thickness cartilage loss (FCL), mean thickness, surface area, and volume. CartiMorph leverages the power of deep learning models for hierarchical image feature representation. Deep learning models were trained and validated for tissue segmentation, template construction, and template-to-image registration. We established methods for surface-normal-based cartilage thickness mapping, FCL estimation, and rule-based cartilage parcellation. Our cartilage thickness map showed less error in thin and peripheral regions. We evaluated the effectiveness of the adopted segmentation model by comparing the quantitative metrics obtained from model segmentation and those from manual segmentation. The root-mean-squared deviation of the FCL measurements was less than 8%, and strong correlations were observed for the mean thickness (Pearson's correlation coefficient $\rho \in [0.82,0.97]$), surface area ($\rho \in [0.82,0.98]$) and volume ($\rho \in [0.89,0.98]$) measurements. We compared our FCL measurements with those from a previous study and found that our measurements deviated less from the ground truths. We observed superior performance of the proposed rule-based cartilage parcellation method compared with the atlas-based approach. CartiMorph has the potential to promote imaging biomarkers discovery for knee osteoarthritis.
</details>
<details>
<summary>摘要</summary>
我们介绍CartiMorph，一个框架 для自动计算膝关节软骨cartilage的形态特征。它可以从图像中提取量化特征，包括软骨损伤率（FCL）、软骨厚度、表面积和体积。CartiMorph利用深度学习模型来表示图像特征。我们训练了和验证了深度学习模型，用于识别、模板生成和模板与图像对齐。我们开发了基于表面法则的软骨厚度映射、FCL估计和软骨分割方法。我们评估了采用的分割模型的效果，并发现其与人工分割的量化特征具有强相关性（Pearson correlation coefficient $\rho \in [0.82,0.97]$）。我们对我们的FCL测量与之前的研究中的参照值进行比较，发现我们的测量与参照值之间存在较小的差异。我们发现我们的软骨分割方法比使用 Atlases-based方法表现出更高的性能。CartiMorph具有推动膝关节风湿病影像生物标志的潜力。
</details></li>
</ul>
<hr>
<h2 id="Unmasking-Parkinson’s-Disease-with-Smile-An-AI-enabled-Screening-Framework"><a href="#Unmasking-Parkinson’s-Disease-with-Smile-An-AI-enabled-Screening-Framework" class="headerlink" title="Unmasking Parkinson’s Disease with Smile: An AI-enabled Screening Framework"></a>Unmasking Parkinson’s Disease with Smile: An AI-enabled Screening Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02588">http://arxiv.org/abs/2308.02588</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tariq Adnan, Md Saiful Islam, Wasifur Rahman, Sangwu Lee, Sutapa Dey Tithi, Kazi Noshin, Imran Sarker, M Saifur Rahman, Ehsan Hoque</li>
<li>for: 这项研究旨在开发一种基于微表情的parkinson病诊断方法，以提高诊断的可靠性和效率。</li>
<li>methods: 研究人员通过利用人脸特征和动作单元，从多个数据源中收集了3871个视频，包括256名自reported pd患者。然后，他们使用一个 ensemble 模型来提取有关 hypomimia 的特征，并实现了89.7%的准确率和89.3%的接收操作特征曲线（AUROC）。</li>
<li>results: 研究人员发现，基于笑脸视频的特征alone可以实现相当的性能，即使在两个外部测试集上，这些模型在训练过程中从来没有看到的数据上也能够达到类似的性能，这表明pd风险评估可能可以通过笑脸自拍视频进行。<details>
<summary>Abstract</summary>
Parkinson's disease (PD) diagnosis remains challenging due to lacking a reliable biomarker and limited access to clinical care. In this study, we present an analysis of the largest video dataset containing micro-expressions to screen for PD. We collected 3,871 videos from 1,059 unique participants, including 256 self-reported PD patients. The recordings are from diverse sources encompassing participants' homes across multiple countries, a clinic, and a PD care facility in the US. Leveraging facial landmarks and action units, we extracted features relevant to Hypomimia, a prominent symptom of PD characterized by reduced facial expressions. An ensemble of AI models trained on these features achieved an accuracy of 89.7% and an Area Under the Receiver Operating Characteristic (AUROC) of 89.3% while being free from detectable bias across population subgroups based on sex and ethnicity on held-out data. Further analysis reveals that features from the smiling videos alone lead to comparable performance, even on two external test sets the model has never seen during training, suggesting the potential for PD risk assessment from smiling selfie videos.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Domain-specificity-and-data-efficiency-in-typo-tolerant-spell-checkers-the-case-of-search-in-online-marketplaces"><a href="#Domain-specificity-and-data-efficiency-in-typo-tolerant-spell-checkers-the-case-of-search-in-online-marketplaces" class="headerlink" title="Domain specificity and data efficiency in typo tolerant spell checkers: the case of search in online marketplaces"></a>Domain specificity and data efficiency in typo tolerant spell checkers: the case of search in online marketplaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01976">http://arxiv.org/abs/2308.01976</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dayananda Ubrangala, Juhi Sharma, Ravi Prasad Kondapalli, Kiran R, Amit Agarwala, Laurent Boué</li>
<li>for:  correction of typographical errors in online marketplaces</li>
<li>methods: data augmentation, training of recurrent neural network for context-limited domain-specific embeddings</li>
<li>results: real-time inferencing API for finding the closest match between misspelled user queries and available product names, with high accuracy using controlled and high-quality synthetic data.<details>
<summary>Abstract</summary>
Typographical errors are a major source of frustration for visitors of online marketplaces. Because of the domain-specific nature of these marketplaces and the very short queries users tend to search for, traditional spell cheking solutions do not perform well in correcting typos. We present a data augmentation method to address the lack of annotated typo data and train a recurrent neural network to learn context-limited domain-specific embeddings. Those embeddings are deployed in a real-time inferencing API for the Microsoft AppSource marketplace to find the closest match between a misspelled user query and the available product names. Our data efficient solution shows that controlled high quality synthetic data may be a powerful tool especially considering the current climate of large language models which rely on prohibitively huge and often uncontrolled datasets.
</details>
<details>
<summary>摘要</summary>
typographical errors are a major source of frustration for visitors of online marketplaces. Because of the domain-specific nature of these marketplaces and the very short queries users tend to search for, traditional spell cheking solutions do not perform well in correcting typos. We present a data augmentation method to address the lack of annotated typo data and train a recurrent neural network to learn context-limited domain-specific embeddings. Those embeddings are deployed in a real-time inferencing API for the Microsoft AppSource marketplace to find the closest match between a misspelled user query and the available product names. Our data efficient solution shows that controlled high quality synthetic data may be a powerful tool, especially considering the current climate of large language models which rely on prohibitively huge and often uncontrolled datasets.Note: "Microsoft AppSource" has been translated as "微软应用源" (wēi ròng yìng yuè yuán) in the text.
</details></li>
</ul>
<hr>
<h2 id="Synthesising-Rare-Cataract-Surgery-Samples-with-Guided-Diffusion-Models"><a href="#Synthesising-Rare-Cataract-Surgery-Samples-with-Guided-Diffusion-Models" class="headerlink" title="Synthesising Rare Cataract Surgery Samples with Guided Diffusion Models"></a>Synthesising Rare Cataract Surgery Samples with Guided Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02587">http://arxiv.org/abs/2308.02587</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/meclabtuda/catasynth">https://github.com/meclabtuda/catasynth</a></li>
<li>paper_authors: Yannik Frisch, Moritz Fuchs, Antoine Sanner, Felix Anton Ucar, Marius Frenzel, Joana Wasielica-Poslednik, Adrian Gericke, Felix Mathias Wagner, Thomas Dratsch, Anirban Mukhopadhyay</li>
<li>for:  This paper aims to address the challenges of gathering and annotating data for training automated assistance systems for cataract surgery, by analyzing cataract surgery video data and utilizing a conditional generative model to synthesize diverse, high-quality examples of surgical phases and tool use.</li>
<li>methods:  The authors use a conditional generative model based on Denoising Diffusion Implicit Models (DDIM) and Classifier-Free Guidance (CFG) to synthesize realistic examples of surgical phases and tool use, addressing the imbalances and data sparsity issues in the publicly available data.</li>
<li>results:  The authors demonstrate that their approach can generate valuable unseen examples, allowing the tool classifier to improve by up to 10% for rare cases, and provide a reliable source of realistic synthetic data for the development of automated assistance systems for cataract surgery.<details>
<summary>Abstract</summary>
Cataract surgery is a frequently performed procedure that demands automation and advanced assistance systems. However, gathering and annotating data for training such systems is resource intensive. The publicly available data also comprises severe imbalances inherent to the surgical process. Motivated by this, we analyse cataract surgery video data for the worst-performing phases of a pre-trained downstream tool classifier. The analysis demonstrates that imbalances deteriorate the classifier's performance on underrepresented cases. To address this challenge, we utilise a conditional generative model based on Denoising Diffusion Implicit Models (DDIM) and Classifier-Free Guidance (CFG). Our model can synthesise diverse, high-quality examples based on complex multi-class multi-label conditions, such as surgical phases and combinations of surgical tools. We affirm that the synthesised samples display tools that the classifier recognises. These samples are hard to differentiate from real images, even for clinical experts with more than five years of experience. Further, our synthetically extended data can improve the data sparsity problem for the downstream task of tool classification. The evaluations demonstrate that the model can generate valuable unseen examples, allowing the tool classifier to improve by up to 10% for rare cases. Overall, our approach can facilitate the development of automated assistance systems for cataract surgery by providing a reliable source of realistic synthetic data, which we make available for everyone.
</details>
<details>
<summary>摘要</summary>
喉肢手术是一种非常常见的手术程序，需要自动化和高级帮助系统。然而，收集和标注数据用于训练这些系统是资源占用的。公共可用的数据也包含了手术过程中的严重偏好，这会导致分类器的性能下降。为了解决这个挑战，我们分析了喉肢手术视频数据，并评估了下游工具分类器的最差表现阶段。分析结果表明，偏好会使分类器对于不充分表现的情况下的性能下降。为了解决这个问题，我们使用基于减震扩散隐藏模型（DDIM）和无分类导航（CFG）的冲击型生成模型。我们的模型可以生成多样化、高质量的示例，基于复杂的多类多标签条件，如手术阶段和手术工具的组合。我们证明了生成的示例中的工具可以被分类器识别。这些示例与真实图像很难区分，即使是临床专家超过5年的经验。此外，我们通过生成的数据扩展，解决了下游任务的数据缺乏问题，从而使分类器的性能提高。评估结果表明，我们的模型可以生成价值很高的未看过的示例，使分类器在罕见情况下提高到10%。总的来说，我们的方法可以促进喉肢手术自动化的发展，提供一个可靠的实际synthetic数据源，我们将其公开给大家。
</details></li>
</ul>
<hr>
<h2 id="Aligning-Agent-Policy-with-Externalities-Reward-Design-via-Bilevel-RL"><a href="#Aligning-Agent-Policy-with-Externalities-Reward-Design-via-Bilevel-RL" class="headerlink" title="Aligning Agent Policy with Externalities: Reward Design via Bilevel RL"></a>Aligning Agent Policy with Externalities: Reward Design via Bilevel RL</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02585">http://arxiv.org/abs/2308.02585</a></li>
<li>repo_url: None</li>
<li>paper_authors: Souradip Chakraborty, Amrit Singh Bedi, Alec Koppel, Dinesh Manocha, Huazheng Wang, Furong Huang, Mengdi Wang</li>
<li>for: 本文旨在解决在强化学习（RL）中Policy优化过程中忽略重要的外部影响因素，如状态空间覆盖和安全性。同时，它可能导致不жела的共识行为和不一致政策。</li>
<li>methods: 本文提出了一种碧级优化问题，并将其连接到主体-代理人模型，其中主体定义了系统的更广泛目标和限制，而代理人解决Markov决策过程（MDP）。</li>
<li>results: 本文提出了主体驱动策略对准（PPA-BRL），它可以有效地将代理人的策略与主体的目标相吻合。 authors还证明了PPA-BRL的收敛性，并采用了多个示例来说明该框架的优势。<details>
<summary>Abstract</summary>
In reinforcement learning (RL), a reward function is often assumed at the outset of a policy optimization procedure. Learning in such a fixed reward paradigm in RL can neglect important policy optimization considerations, such as state space coverage and safety. Moreover, it can fail to encompass broader impacts in terms of social welfare, sustainability, or market stability, potentially leading to undesirable emergent behavior and potentially misaligned policy. To mathematically encapsulate the problem of aligning RL policy optimization with such externalities, we consider a bilevel optimization problem and connect it to a principal-agent framework, where the principal specifies the broader goals and constraints of the system at the upper level and the agent solves a Markov Decision Process (MDP) at the lower level. The upper-level deals with learning a suitable reward parametrization corresponding to the broader goals and the lower-level deals with learning the policy for the agent. We propose Principal driven Policy Alignment via Bilevel RL (PPA-BRL), which efficiently aligns the policy of the agent with the principal's goals. We explicitly analyzed the dependence of the principal's trajectory on the lower-level policy, prove the convergence of PPA-BRL to the stationary point of the problem. We illuminate the merits of this framework in view of alignment with several examples spanning energy-efficient manipulation tasks, social welfare-based tax design, and cost-effective robotic navigation.
</details>
<details>
<summary>摘要</summary>
在增强学习（RL）中，常常假设一个奖金函数在政策优化过程的开始。这种固定奖金的假设可能忽略了重要的政策优化考虑因素，如状态空间覆盖率和安全性。此外，它可能不包括更广泛的影响，如社会福利、可持续发展和市场稳定性，可能导致不жела的 Emergent 行为和不一致的政策。为了数学地表达RL政策优化和这些外部因素之间的关系，我们考虑了一个双层优化问题，并将其连接到一个主体-代理人模型。在主体级别上，我们学习一个适合主体的奖金参数化，而在代理人级别上，我们学习一个Markov决策过程（MDP）。主体级别处理主体的更广泛目标和约束，而代理人级别处理代理人的政策。我们提出了由主体驱动的政策对齐方法（PPA-BRL），可以有效地将代理人的政策与主体的目标相对应。我们明确分析了主体的轨迹对下一级政策的依赖关系，并证明PPA-BRL的确 converge 到问题的站点点。我们在各种示例中，如能源减少的操作任务、基于社会福利的税制设计和cost-effective的机器人导航等方面，ILLUMINATE 了该框架的优势。
</details></li>
</ul>
<hr>
<h2 id="Reasoning-in-Large-Language-Models-Through-Symbolic-Math-Word-Problems"><a href="#Reasoning-in-Large-Language-Models-Through-Symbolic-Math-Word-Problems" class="headerlink" title="Reasoning in Large Language Models Through Symbolic Math Word Problems"></a>Reasoning in Large Language Models Through Symbolic Math Word Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01906">http://arxiv.org/abs/2308.01906</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vedant Gaur, Nikunj Saunshi</li>
<li>for: 这篇论文旨在研究大语言模型（LLM）在数学问题中的推理能力。</li>
<li>methods: 研究者使用了一个符号版本的 SVAMP 数据集，并发现 GPT-3 模型在符号问题上也有良好的零学习精度。</li>
<li>results: 研究者发现，使用自我提示法可以使 LLM 提供一个准确和可证明的推理，并且自我提示还可以提高符号准确率，从而实现一种拓展效果。<details>
<summary>Abstract</summary>
Large language models (LLMs) have revolutionized NLP by solving downstream tasks with little to no labeled data. Despite their versatile abilities, the larger question of their ability to reason remains ill-understood. This paper addresses reasoning in math word problems (MWPs) by studying symbolic versions of the numeric problems, since a symbolic expression is a "concise explanation" of the numeric answer. We create and use a symbolic version of the SVAMP dataset and find that GPT-3's davinci-002 model also has good zero-shot accuracy on symbolic MWPs. To evaluate the faithfulness of the model's reasoning, we go beyond accuracy and additionally evaluate the alignment between the final answer and the outputted reasoning, which correspond to numeric and symbolic answers respectively for MWPs. We explore a self-prompting approach to encourage the symbolic reasoning to align with the numeric answer, thus equipping the LLM with the ability to provide a concise and verifiable reasoning and making it more interpretable. Surprisingly, self-prompting also improves the symbolic accuracy to be higher than both the numeric and symbolic accuracies, thus providing an ensembling effect. The SVAMP_Sym dataset will be released for future research on symbolic math problems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Revisiting-Deformable-Convolution-for-Depth-Completion"><a href="#Revisiting-Deformable-Convolution-for-Depth-Completion" class="headerlink" title="Revisiting Deformable Convolution for Depth Completion"></a>Revisiting Deformable Convolution for Depth Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01905">http://arxiv.org/abs/2308.01905</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinglong Sun, Jean Ponce, Yu-Xiong Wang</li>
<li>for: 提高深度地图的质量，使用单pass涨幅 convolution 对于 dense depth map 的生成。</li>
<li>methods: 使用 deformable kernel convolution 作为归一化推理，并在不同的核心大小和弹性率下进行系统调查。</li>
<li>results: 在大规模的 KITTI  dataset 上测试，模型实现了状态机器人级别的性能，并且在准确率和推理速度两个方面均达到了新高度。<details>
<summary>Abstract</summary>
Depth completion, which aims to generate high-quality dense depth maps from sparse depth maps, has attracted increasing attention in recent years. Previous work usually employs RGB images as guidance, and introduces iterative spatial propagation to refine estimated coarse depth maps. However, most of the propagation refinement methods require several iterations and suffer from a fixed receptive field, which may contain irrelevant and useless information with very sparse input. In this paper, we address these two challenges simultaneously by revisiting the idea of deformable convolution. We propose an effective architecture that leverages deformable kernel convolution as a single-pass refinement module, and empirically demonstrate its superiority. To better understand the function of deformable convolution and exploit it for depth completion, we further systematically investigate a variety of representative strategies. Our study reveals that, different from prior work, deformable convolution needs to be applied on an estimated depth map with a relatively high density for better performance. We evaluate our model on the large-scale KITTI dataset and achieve state-of-the-art level performance in both accuracy and inference speed. Our code is available at https://github.com/AlexSunNik/ReDC.
</details>
<details>
<summary>摘要</summary>
“深度补充”，即从粗略深度图生成高质量的稠密深度图，在过去几年内吸引了越来越多的关注。先前的工作通常使用RGB图像作为引导，并通过迭代的空间填充来精细化估算的粗略深度图。然而，大多数的填充精细方法需要几个迭代，并且受到固定的见识场的限制，可能包含无关和无用的信息，特别是在非常罕见的输入中。在这篇论文中，我们解决了这两个挑战，并同时提出了一种有效的架构。我们提议使用可变核函数卷积，作为单 passes 精细化模块，并经验证了其优越性。为了更好地理解可变核函数的作用，并在深度补充中利用它，我们进一步系统地研究了一些代表性的策略。我们的研究发现，与之前的工作不同，可变核函数需要在估算的深度图上进行高密度应用，以获得更好的性能。我们在大规模的KITTI dataset上评估了我们的模型，并 achieved state-of-the-art 水平的准确率和执行速度。我们的代码可以在https://github.com/AlexSunNik/ReDC中找到。
</details></li>
</ul>
<hr>
<h2 id="How-many-preprints-have-actually-been-printed-and-why-a-case-study-of-computer-science-preprints-on-arXiv"><a href="#How-many-preprints-have-actually-been-printed-and-why-a-case-study-of-computer-science-preprints-on-arXiv" class="headerlink" title="How many preprints have actually been printed and why: a case study of computer science preprints on arXiv"></a>How many preprints have actually been printed and why: a case study of computer science preprints on arXiv</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01899">http://arxiv.org/abs/2308.01899</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jialiang Lin, Yao Yu, Yu Zhou, Zhiyang Zhou, Xiaodong Shi</li>
<li>for: 本研究使用 case study 方法探讨了自2008年至2017年的计算机科学预印在 arXiv 上的发布情况，以衡量这些预印 eventually 被正式出版的可能性。</li>
<li>methods: 本研究使用了 semantics-based mapping method，使用 Bidirectional Encoder Representations from Transformers (BERT) 来匹配预印和最终发布的 manuscript。</li>
<li>results: 研究发现，66% 的预印被发布 unter changed titles，11% 被发布 unter different titles 和其他修改。 further analysis 表明，已出版的预印具有充分的修订、多个作者、详细的摘要和引言、广泛的参考文献和可用的源代码等特征。<details>
<summary>Abstract</summary>
Preprints play an increasingly critical role in academic communities. There are many reasons driving researchers to post their manuscripts to preprint servers before formal submission to journals or conferences, but the use of preprints has also sparked considerable controversy, especially surrounding the claim of priority. In this paper, a case study of computer science preprints submitted to arXiv from 2008 to 2017 is conducted to quantify how many preprints have eventually been printed in peer-reviewed venues. Among those published manuscripts, some are published under different titles and without an update to their preprints on arXiv. In the case of these manuscripts, the traditional fuzzy matching method is incapable of mapping the preprint to the final published version. In view of this issue, we introduce a semantics-based mapping method with the employment of Bidirectional Encoder Representations from Transformers (BERT). With this new mapping method and a plurality of data sources, we find that 66% of all sampled preprints are published under unchanged titles and 11% are published under different titles and with other modifications. A further analysis was then performed to investigate why these preprints but not others were accepted for publication. Our comparison reveals that in the field of computer science, published preprints feature adequate revisions, multiple authorship, detailed abstract and introduction, extensive and authoritative references and available source code.
</details>
<details>
<summary>摘要</summary>
《Preprints在学术社区中发挥越来越重要的作用。有很多原因使研究者们将 manuscrips 上载到 preprint 服务器之前，而不是正式提交到期刊或会议，但使用 preprints 也引发了一些争议，特别是在优先权方面。本文通过对 computer science 领域自2008年至2017年的 arXiv 上的 preprints 进行 caso study，以计算这些投稿 eventually 被 peer-reviewed 出版的数量。 Among 发表的投稿中，一些发表于不同的标题和未更新 arXiv 上的投稿。在这些投稿中，传统的杂合匹配方法无法将投稿映射到最终发表的版本。为解决这个问题，我们引入 semantics-based 映射方法，使用 Bidirectional Encoder Representations from Transformers (BERT)。With 这种新的映射方法和多种数据源，我们发现：66% 的投稿被发表于不变的标题下，11% 的投稿被发表于不同的标题和其他修改。进一步的分析表明，在 computer science 领域中，发表的 preprints 具有充分的修改、多个作者、详细的摘要和引言、详细的参考文献和可用的源代码。》
</details></li>
</ul>
<hr>
<h2 id="Improving-Replay-Sample-Selection-and-Storage-for-Less-Forgetting-in-Continual-Learning"><a href="#Improving-Replay-Sample-Selection-and-Storage-for-Less-Forgetting-in-Continual-Learning" class="headerlink" title="Improving Replay Sample Selection and Storage for Less Forgetting in Continual Learning"></a>Improving Replay Sample Selection and Storage for Less Forgetting in Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01895">http://arxiv.org/abs/2308.01895</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Brignac, Niels Lobo, Abhijit Mahalanobis</li>
<li>for: 这篇研究旨在解决深度学习中的不断学习问题，尤其是当学习多个任务时，避免Catastrophic Forgetting这个问题。</li>
<li>methods: 这篇研究使用了储存部分经验的方法，并与多种替代方案进行比较，以找出最佳的储存数量和最佳的储存样本。</li>
<li>results: 这篇研究获得了一些有用的结果，包括提出了一种新的储存数量选择方法，并进行了详细的分析，以帮助找到最佳的储存数量和储存样本。<details>
<summary>Abstract</summary>
Continual learning seeks to enable deep learners to train on a series of tasks of unknown length without suffering from the catastrophic forgetting of previous tasks. One effective solution is replay, which involves storing few previous experiences in memory and replaying them when learning the current task. However, there is still room for improvement when it comes to selecting the most informative samples for storage and determining the optimal number of samples to be stored. This study aims to address these issues with a novel comparison of the commonly used reservoir sampling to various alternative population strategies and providing a novel detailed analysis of how to find the optimal number of stored samples.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:深度学习探索可以让深度学习者在不知道任务数量的情况下接受多个任务，而不会出现过去任务的恶化。一种有效的解决方案是重温，即将一些过去经验存储在内存中，并在学习当前任务时重温。然而，还有很多可以提高的空间，包括选择存储的最有用样本和确定存储样本的优化数量。这个研究旨在通过对常用的储存抽样与其他人口策略进行比较，以及提供一种细化的分析，以找到最佳存储样本数量。
</details></li>
</ul>
<hr>
<h2 id="Exact-identification-of-nonlinear-dynamical-systems-by-Trimmed-Lasso"><a href="#Exact-identification-of-nonlinear-dynamical-systems-by-Trimmed-Lasso" class="headerlink" title="Exact identification of nonlinear dynamical systems by Trimmed Lasso"></a>Exact identification of nonlinear dynamical systems by Trimmed Lasso</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01891">http://arxiv.org/abs/2308.01891</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shawn L. Kiser, Mikhail Guskov, Marc Rébillat, Nicolas Ranc</li>
<li>for: 本研究旨在提出一种可以对finite和噪声数据进行非线性动力系统的 indentification方法，并且可以提供精确的模型预测结果。</li>
<li>methods: 本研究使用了SINDy算法，并提出了一种基于trimmed Lasso的方法，可以在finite和噪声数据下提供精确的模型预测结果，并且可以处理多列性问题。</li>
<li>results: 研究表明，trimmed Lasso方法可以在finite和噪声数据下提供精确的模型预测结果，并且可以处理多列性问题，而SINDy和reweighted $\ell_1$ minimization方法则有些问题。<details>
<summary>Abstract</summary>
Identification of nonlinear dynamical systems has been popularized by sparse identification of the nonlinear dynamics (SINDy) via the sequentially thresholded least squares (STLS) algorithm. Many extensions SINDy have emerged in the literature to deal with experimental data which are finite in length and noisy. Recently, the computationally intensive method of ensembling bootstrapped SINDy models (E-SINDy) was proposed for model identification, handling finite, highly noisy data. While the extensions of SINDy are numerous, their sparsity-promoting estimators occasionally provide sparse approximations of the dynamics as opposed to exact recovery. Furthermore, these estimators suffer under multicollinearity, e.g. the irrepresentable condition for the Lasso. In this paper, we demonstrate that the Trimmed Lasso for robust identification of models (TRIM) can provide exact recovery under more severe noise, finite data, and multicollinearity as opposed to E-SINDy. Additionally, the computational cost of TRIM is asymptotically equal to STLS since the sparsity parameter of the TRIM can be solved efficiently by convex solvers. We compare these methodologies on challenging nonlinear systems, specifically the Lorenz 63 system, the Bouc Wen oscillator from the nonlinear dynamics benchmark of No\"el and Schoukens, 2016, and a time delay system describing tool cutting dynamics. This study emphasizes the comparisons between STLS, reweighted $\ell_1$ minimization, and Trimmed Lasso in identification with respect to problems faced by practitioners: the problem of finite and noisy data, the performance of the sparse regression of when the library grows in dimension (multicollinearity), and automatic methods for choice of regularization parameters.
</details>
<details>
<summary>摘要</summary>
非线性动力系统的标识已经得到了广泛的普及，通过稀疏标识非线性动力学（SINDy）viaSequentially Thresholded Least Squares（STLS）算法。在文献中，许多SINDy的扩展出现了，以处理实验数据的限制和噪声。最近，对Bootstrapped SINDy模型的ensemble（E-SINDy）计算昂贵方法被提出，用于模型标识，面对限制、高噪声数据。然而，SINDy扩展的 sparse 估计器 occasional 提供稀疏approximation of the dynamics 而不是精确的回归。此外，这些估计器会在多icollinearity 下表现不佳，例如lasso 的不可 Representable condition。在这篇文章中，我们展示了Trimmed Lasso 可以在更严重的噪声、限制和多icollinearity下提供精确的回归，而不是E-SINDy。此外，TRIM 的计算成本与 STLS 相同，可以由 convex 算法有效地解决约束参数。我们在非线性系统中进行了对抗样本，包括 Lorenz 63 系统、Bouc Wen 振荡器和时延系统，以及2016年非线性动力学 benchmark 中的 No\"el 和 Schoukens 的测试集。本研究强调了 STLS、重量化 $\ell_1$ 最小化和 Trimmed Lasso 在实际应用中遇到的问题的比较：噪声和限制的数据 finite 问题、约束参数的自动选择问题以及库存在多个参数时的多icollinearity 问题。
</details></li>
</ul>
<hr>
<h2 id="DualCoOp-Fast-and-Effective-Adaptation-to-Multi-Label-Recognition-with-Limited-Annotations"><a href="#DualCoOp-Fast-and-Effective-Adaptation-to-Multi-Label-Recognition-with-Limited-Annotations" class="headerlink" title="DualCoOp++: Fast and Effective Adaptation to Multi-Label Recognition with Limited Annotations"></a>DualCoOp++: Fast and Effective Adaptation to Multi-Label Recognition with Limited Annotations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01890">http://arxiv.org/abs/2308.01890</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ping Hu, Ximeng Sun, Stan Sclaroff, Kate Saenko</li>
<li>for: 多Label图像识别任务中，适用于低标签场景的研究，具有很大的挑战性和实际 significanc。</li>
<li>methods: 我们利用了 millions of auxiliary image-text pairs 预训练的强大对应关系，并提出了一种高效的框架，即 Evidence-guided Dual Context Optimization (DualCoOp++)，用于解决 partial-label 和 zero-shot multi-label recognition 问题。</li>
<li>results: 我们在标准的多Label图像识别benchmark上进行了实验，并证明了我们的方法在低标签场景下的表现superiority，比state-of-the-art方法更高。<details>
<summary>Abstract</summary>
Multi-label image recognition in the low-label regime is a task of great challenge and practical significance. Previous works have focused on learning the alignment between textual and visual spaces to compensate for limited image labels, yet may suffer from reduced accuracy due to the scarcity of high-quality multi-label annotations. In this research, we leverage the powerful alignment between textual and visual features pretrained with millions of auxiliary image-text pairs. We introduce an efficient and effective framework called Evidence-guided Dual Context Optimization (DualCoOp++), which serves as a unified approach for addressing partial-label and zero-shot multi-label recognition. In DualCoOp++ we separately encode evidential, positive, and negative contexts for target classes as parametric components of the linguistic input (i.e., prompts). The evidential context aims to discover all the related visual content for the target class, and serves as guidance to aggregate positive and negative contexts from the spatial domain of the image, enabling better distinguishment between similar categories. Additionally, we introduce a Winner-Take-All module that promotes inter-class interaction during training, while avoiding the need for extra parameters and costs. As DualCoOp++ imposes minimal additional learnable overhead on the pretrained vision-language framework, it enables rapid adaptation to multi-label recognition tasks with limited annotations and even unseen classes. Experiments on standard multi-label recognition benchmarks across two challenging low-label settings demonstrate the superior performance of our approach compared to state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
多标签图像识别在低标签场景下是一项具有挑战性和实际意义的任务。先前的工作强调学习图像和文本空间之间的对应关系，以做到因为有限的多标签注释而减少精度。在本研究中，我们利用已经预训练的图像和文本特征之间的强大对应关系，提出一种高效的框架called Evidence-guided Dual Context Optimization (DualCoOp++)。DualCoOp++是一种统一的方法，用于解决 partial-label 和 zero-shot 多标签识别问题。在 DualCoOp++ 中，我们将目标类的 evidential、正例和负例上下文分别编码为文本输入（即提示）的 parametric 组件。evidential 上下文的目的是找到target类相关的所有视觉内容，并作为指导将正例和负例上下文从图像空间的空间域聚合，以提高类别之间的区分。此外，我们还引入了一个 Winner-Take-All 模块，通过在训练时间提高 между类交互，以避免添加额外参数和成本。由于 DualCoOp++ 对已经预训练的视觉语言框架做出最小的额外学习压力，因此它可以快速适应多标签识别任务，即使是有限的注释和未知类。在标准多标签识别benchmark上，我们的方法与状态之前的方法相比，显示出更高的性能。
</details></li>
</ul>
<hr>
<h2 id="Cream-Skimming-the-Underground-Identifying-Relevant-Information-Points-from-Online-Forums"><a href="#Cream-Skimming-the-Underground-Identifying-Relevant-Information-Points-from-Online-Forums" class="headerlink" title="Cream Skimming the Underground: Identifying Relevant Information Points from Online Forums"></a>Cream Skimming the Underground: Identifying Relevant Information Points from Online Forums</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02581">http://arxiv.org/abs/2308.02581</a></li>
<li>repo_url: None</li>
<li>paper_authors: Felipe Moreno-Vera, Mateus Nogueira, Cainã Figueiredo, Daniel Sadoc Menasché, Miguel Bicudo, Ashton Woiwood, Enrico Lovat, Anton Kocheturov, Leandro Pfleger de Aguiar</li>
<li>for: 本研究提出了一种基于机器学习的方法，用于在野外探测漏洞利用。</li>
<li>methods: 该方法利用了多个下地黑客论坛的数据，并基于supervised机器学习模型进行筛选和标注线程和帖子的内容。</li>
<li>results: 研究发现，可以通过使用random forest算法，实现对线程和帖子的自动分类，并且准确率、精度和准确率都高于0.99。此外，研究还提供了针对武器化和利用之间的差异分析，以及黑客社区的其他方面的分析。<details>
<summary>Abstract</summary>
This paper proposes a machine learning-based approach for detecting the exploitation of vulnerabilities in the wild by monitoring underground hacking forums. The increasing volume of posts discussing exploitation in the wild calls for an automatic approach to process threads and posts that will eventually trigger alarms depending on their content. To illustrate the proposed system, we use the CrimeBB dataset, which contains data scraped from multiple underground forums, and develop a supervised machine learning model that can filter threads citing CVEs and label them as Proof-of-Concept, Weaponization, or Exploitation. Leveraging random forests, we indicate that accuracy, precision and recall above 0.99 are attainable for the classification task. Additionally, we provide insights into the difference in nature between weaponization and exploitation, e.g., interpreting the output of a decision tree, and analyze the profits and other aspects related to the hacking communities. Overall, our work sheds insight into the exploitation of vulnerabilities in the wild and can be used to provide additional ground truth to models such as EPSS and Expected Exploitability.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Statistical-Estimation-Under-Distribution-Shift-Wasserstein-Perturbations-and-Minimax-Theory"><a href="#Statistical-Estimation-Under-Distribution-Shift-Wasserstein-Perturbations-and-Minimax-Theory" class="headerlink" title="Statistical Estimation Under Distribution Shift: Wasserstein Perturbations and Minimax Theory"></a>Statistical Estimation Under Distribution Shift: Wasserstein Perturbations and Minimax Theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01853">http://arxiv.org/abs/2308.01853</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/patrickrchao/dist_shift_exp">https://github.com/patrickrchao/dist_shift_exp</a></li>
<li>paper_authors: Patrick Chao, Edgar Dobriban</li>
<li>for: 本文研究了 Wasserstein 分布变换的影响，即每个数据点可能受到轻微变化的情况。</li>
<li>methods: 本文提出了 JOINT 分布变换，即每个观测值可能受到协调的变化。</li>
<li>results: 研究发现，在平均估计和线性回归中，采用样本均值和最小二乘估计器是最优的。但是，在其他问题上，提供了近似估计器和精确的finite-sample bound。此外，本文还介绍了一些用于下界分布变换的工具，如缓和技术和经典工具的推广。<details>
<summary>Abstract</summary>
Distribution shifts are a serious concern in modern statistical learning as they can systematically change the properties of the data away from the truth. We focus on Wasserstein distribution shifts, where every data point may undergo a slight perturbation, as opposed to the Huber contamination model where a fraction of observations are outliers. We formulate and study shifts beyond independent perturbations, exploring Joint Distribution Shifts, where the per-observation perturbations can be coordinated. We analyze several important statistical problems, including location estimation, linear regression, and non-parametric density estimation. Under a squared loss for mean estimation and prediction error in linear regression, we find the exact minimax risk, a least favorable perturbation, and show that the sample mean and least squares estimators are respectively optimal. This holds for both independent and joint shifts, but the least favorable perturbations and minimax risks differ. For other problems, we provide nearly optimal estimators and precise finite-sample bounds. We also introduce several tools for bounding the minimax risk under distribution shift, such as a smoothing technique for location families, and generalizations of classical tools including least favorable sequences of priors, the modulus of continuity, Le Cam's, Fano's, and Assouad's methods.
</details>
<details>
<summary>摘要</summary>
“分布shift是现代统计学中的一项重要问题，因为它可能会系统性地改变数据的性质，从而导致统计分析的结果不准确。我们主要关注 Wasserstein 分布shift，其中每个数据点都可能发生轻微的扰动，而不是 Hubert 杂入模型，其中一部分观察值是异常值。我们将分布shift beyond independent perturbations 探讨，包括联合分布shift，其中每个观察值的扰动可以协调。我们分析了一些重要的统计问题，包括位置估计、线性回归和非参数密度估计。使用平方损失函数 для均值估计和线性回归预测误差，我们找到了最佳的最小值风险，最不利的扰动和证明样本均值和最小二乘估计器是最佳的。这些结果适用于独立分布shift和联合分布shift，但最佳扰动和最小值风险不同。对于其他问题，我们提供了近似最佳估计器和精确的 finite-sample 上限。我们还介绍了一些用于下界最小值风险的工具，包括分布 families 的平滑技术和经典工具的普遍化，如最不利序列的假设、模度Continuity、Le Cam 和 Fano 的方法。”
</details></li>
</ul>
<hr>
<h2 id="Curricular-Transfer-Learning-for-Sentence-Encoded-Tasks"><a href="#Curricular-Transfer-Learning-for-Sentence-Encoded-Tasks" class="headerlink" title="Curricular Transfer Learning for Sentence Encoded Tasks"></a>Curricular Transfer Learning for Sentence Encoded Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01849">http://arxiv.org/abs/2308.01849</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jader Martins Camboim de Sá, Matheus Ferraroni Sanches, Rafael Roque de Souza, Júlio Cesar dos Reis, Leandro Aparecido Villas</li>
<li>for: 提高 conversational AI  task 的性能，对于 distribution 的变化进行适应。</li>
<li>methods: 提出了一种逐步适应（curriculum）方法，通过 “data hacking” 和 grammar 分析进行指导。</li>
<li>results: 在 MultiWoZ 任务上实现了显著的改进，舒展比其他已知预训练方法。<details>
<summary>Abstract</summary>
Fine-tuning language models in a downstream task is the standard approach for many state-of-the-art methodologies in the field of NLP. However, when the distribution between the source task and target task drifts, \textit{e.g.}, conversational environments, these gains tend to be diminished. This article proposes a sequence of pre-training steps (a curriculum) guided by "data hacking" and grammar analysis that allows further gradual adaptation between pre-training distributions. In our experiments, we acquire a considerable improvement from our method compared to other known pre-training approaches for the MultiWoZ task.
</details>
<details>
<summary>摘要</summary>
文本翻译为简化中文：在自然语言处理领域的许多状态体验中，训练语言模型在下游任务中进行微调是标准的方法。然而，当源任务和目标任务的分布发生变化，例如对话环境，这些提高往往减少。这篇文章提议一系列的预训练步骤（课程），受到“数据黑客”和语法分析的引导，以进一步适应预训练分布的变化。在我们的实验中，我们获得了与其他已知预训练方法相比的显著改进，用于多语言对话任务。</sys>Note: "数据黑客" (data hacker) is a term used in China to refer to someone who is skilled at finding and exploiting vulnerabilities in data or systems. In the context of this article, it seems to refer to the idea of using data from a variety of sources to "hack" or adapt the pre-training process to better suit the target task.
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-Deep-Supervision-Network-A-Noise-Resilient-Approach-for-QoS-Prediction"><a href="#Probabilistic-Deep-Supervision-Network-A-Noise-Resilient-Approach-for-QoS-Prediction" class="headerlink" title="Probabilistic Deep Supervision Network: A Noise-Resilient Approach for QoS Prediction"></a>Probabilistic Deep Supervision Network: A Noise-Resilient Approach for QoS Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02580">http://arxiv.org/abs/2308.02580</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hotfrom/pds-net">https://github.com/hotfrom/pds-net</a></li>
<li>paper_authors: Ziliang Wang, Xiaohong Zhang, Sheng Huang, Wei Zhang, Dan Yang, Meng Yan</li>
<li>for: 提高推荐系统中质量服务预测的准确性，增加用户满意度。</li>
<li>methods: 提出了一种基于概率深度监督网络（PDS-Net）的新框架，通过在概率空间中进行权重学习，将知道的特征和真实标签进行拟合，并通过条件基于多任务损失函数来识别含有噪声数据的对象，从而更好地预测质量服务。</li>
<li>results: 对两个实际的质量服务数据集进行了实验评估，并证明了我们的方法的有效性，比对 estado-of-the-art 基elines 高效。<details>
<summary>Abstract</summary>
Quality of Service (QoS) prediction is an essential task in recommendation systems, where accurately predicting unknown QoS values can improve user satisfaction. However, existing QoS prediction techniques may perform poorly in the presence of noise data, such as fake location information or virtual gateways. In this paper, we propose the Probabilistic Deep Supervision Network (PDS-Net), a novel framework for QoS prediction that addresses this issue. PDS-Net utilizes a Gaussian-based probabilistic space to supervise intermediate layers and learns probability spaces for both known features and true labels. Moreover, PDS-Net employs a condition-based multitasking loss function to identify objects with noise data and applies supervision directly to deep features sampled from the probability space by optimizing the Kullback-Leibler distance between the probability space of these objects and the real-label probability space. Thus, PDS-Net effectively reduces errors resulting from the propagation of corrupted data, leading to more accurate QoS predictions. Experimental evaluations on two real-world QoS datasets demonstrate that the proposed PDS-Net outperforms state-of-the-art baselines, validating the effectiveness of our approach.
</details>
<details>
<summary>摘要</summary>
quality of service（QoS）预测是推荐系统中的一项重要任务，可以提高用户满意度。然而，现有的QoS预测技术可能在噪声数据存在时表现不佳。在这篇论文中，我们提出了可靠的深度监督网络（PDS-Net）框架，用于QoS预测。PDS-Net使用 Gaussian 基于的 probabilistic 空间来监督中间层，并学习 probabilities 空间 для知道特征和真实标签。此外，PDS-Net 使用 condition-based multitasking 损失函数来标识含噪数据对象，并直接将深度特征从probability空间中抽取到损失函数中进行超vision。因此，PDS-Net 可以有效地减少噪声数据的传播错误，从而提高 QoS 预测的准确性。实验评估在两个真实 QoS 数据集上表明，提出的 PDS-Net 超过了状态的基eline，证明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="URET-Universal-Robustness-Evaluation-Toolkit-for-Evasion"><a href="#URET-Universal-Robustness-Evaluation-Toolkit-for-Evasion" class="headerlink" title="URET: Universal Robustness Evaluation Toolkit (for Evasion)"></a>URET: Universal Robustness Evaluation Toolkit (for Evasion)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01840">http://arxiv.org/abs/2308.01840</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ibm/uret">https://github.com/ibm/uret</a></li>
<li>paper_authors: Kevin Eykholt, Taesung Lee, Douglas Schales, Jiyong Jang, Ian Molloy, Masha Zorin</li>
<li>for: 本研究旨在提供一个可以生成各种输入类型和任务领域的攻击入力框架。</li>
<li>methods: 我们提出了一个新的框架，可以根据输入和一组预定的输入变数发现一系列的变数，以生成具有 semantic 和功能约束的攻击入力。</li>
<li>results: 我们在多种不同的机器学习任务和各种输入表现上验证了我们的方法，并证明了生成攻击例子的重要性，以便实现安全和可靠的 AI 系统。<details>
<summary>Abstract</summary>
Machine learning models are known to be vulnerable to adversarial evasion attacks as illustrated by image classification models. Thoroughly understanding such attacks is critical in order to ensure the safety and robustness of critical AI tasks. However, most evasion attacks are difficult to deploy against a majority of AI systems because they have focused on image domain with only few constraints. An image is composed of homogeneous, numerical, continuous, and independent features, unlike many other input types to AI systems used in practice. Furthermore, some input types include additional semantic and functional constraints that must be observed to generate realistic adversarial inputs. In this work, we propose a new framework to enable the generation of adversarial inputs irrespective of the input type and task domain. Given an input and a set of pre-defined input transformations, our framework discovers a sequence of transformations that result in a semantically correct and functional adversarial input. We demonstrate the generality of our approach on several diverse machine learning tasks with various input representations. We also show the importance of generating adversarial examples as they enable the deployment of mitigation techniques.
</details>
<details>
<summary>摘要</summary>
To address these challenges, we propose a new framework for generating adversarial inputs that can be applied to any input type and task domain. Given an input and a set of predefined input transformations, our framework discovers a sequence of transformations that result in a semantically correct and functional adversarial input. We demonstrate the versatility of our approach on several diverse machine learning tasks with various input representations. We also show the importance of generating adversarial examples, as they enable the deployment of mitigation techniques.Here is the translation in Simplified Chinese:机器学习模型知道会受到攻击，图像分类模型的攻击示例。理解这些攻击非常重要，以确保AI任务的安全性和可靠性。然而，大多数攻击都难以应用于大多数AI系统，因为它们都是图像领域的，具有有限的约束。图像由数字、连续、独立的特征组成，与其他AI系统的输入类型不同。此外，一些输入类型还有semantic和functional约束，需要在生成攻击输入时考虑。为解决这些挑战，我们提出了一个新的框架，可以应用于任何输入类型和任务领域。给定一个输入和一组预定的输入变换，我们的框架可以找到一个符号正确、功能正确的攻击输入序列。我们在多种多样的机器学习任务上展示了这种方法的通用性，并显示了生成攻击示例的重要性，以便应用 Mitigation 技术。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/04/cs.LG_2023_08_04/" data-id="closbroqo00nj0g8857cp90s3" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_04" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/04/eess.IV_2023_08_04/" class="article-date">
  <time datetime="2023-08-04T09:00:00.000Z" itemprop="datePublished">2023-08-04</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/04/eess.IV_2023_08_04/">eess.IV - 2023-08-04</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Frequency-Disentangled-Features-in-Neural-Image-Compression"><a href="#Frequency-Disentangled-Features-in-Neural-Image-Compression" class="headerlink" title="Frequency Disentangled Features in Neural Image Compression"></a>Frequency Disentangled Features in Neural Image Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02620">http://arxiv.org/abs/2308.02620</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Zafari, Atefeh Khoshkhahtinat, Piyush Mehta, Mohammad Saeed Ebrahimi Saadabadi, Mohammad Akyash, Nasser M. Nasrabadi</li>
<li>for: 这篇论文主要是为了提出一种基于自适应排序的神经网络压缩方法，以提高压缩率和图像质量。</li>
<li>methods: 该方法使用了一种基于变分自适应的神经网络模型，并在模型中引入了频谱分解和自关注重计算来提高压缩率和图像质量。</li>
<li>results: 实验结果表明，该方法可以在压缩率和图像质量之间取得平衡，并且与手工编码和其他神经网络编码方法相比，有较高的压缩率和较好的图像质量。<details>
<summary>Abstract</summary>
The design of a neural image compression network is governed by how well the entropy model matches the true distribution of the latent code. Apart from the model capacity, this ability is indirectly under the effect of how close the relaxed quantization is to the actual hard quantization. Optimizing the parameters of a rate-distortion variational autoencoder (R-D VAE) is ruled by this approximated quantization scheme. In this paper, we propose a feature-level frequency disentanglement to help the relaxed scalar quantization achieve lower bit rates by guiding the high entropy latent features to include most of the low-frequency texture of the image. In addition, to strengthen the de-correlating power of the transformer-based analysis/synthesis transform, an augmented self-attention score calculation based on the Hadamard product is utilized during both encoding and decoding. Channel-wise autoregressive entropy modeling takes advantage of the proposed frequency separation as it inherently directs high-informational low-frequency channels to the first chunks and conditions the future chunks on it. The proposed network not only outperforms hand-engineered codecs, but also neural network-based codecs built on computation-heavy spatially autoregressive entropy models.
</details>
<details>
<summary>摘要</summary>
neural image compression network 的设计受到 latent code 的真实分布如何匹配 entropy model 的影响。除了模型容量之外，这种能力受到较量化 quantization 的距离实际hard quantization的影响。在这篇文章中，我们提出了一种基于 frequency separation 的特征级解耦，以帮助 relaxed scalar quantization 实现更低的比特率，使高 entropy 的 latent features 包含大多数低频Texture of the image。此外，为强化 transformer 基于分析/synthesis transform 的分割力，我们在编码和解码过程中使用了增强的自注意力分数计算方法，基于 Hadamard 乘法。通道级自适应 entropy modeling 利用了我们提出的频谱分离，因为它自然地将高信息价值的低频通道分配给首 chunk，并将未来 chunk  conditional 于它。提出的网络不仅超越了手动设计的编码器，还超越了基于 computation-heavy 空间自相关 entropy model 的神经网络编码器。
</details></li>
</ul>
<hr>
<h2 id="Brain-MRI-Segmentation-using-Template-Based-Training-and-Visual-Perception-Augmentation"><a href="#Brain-MRI-Segmentation-using-Template-Based-Training-and-Visual-Perception-Augmentation" class="headerlink" title="Brain MRI Segmentation using Template-Based Training and Visual Perception Augmentation"></a>Brain MRI Segmentation using Template-Based Training and Visual Perception Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02363">http://arxiv.org/abs/2308.02363</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fang-Cheng Yeh</li>
<li>for: 用一个人类大脑MRI模板和其关联的分割标签来训练一个3D U-Net模型从头开始，以实现分割任务 such as 骨剥离、大脑分割和组织概率地图。</li>
<li>methods: 使用模板基于的训练方法，通过可见刺激进行图像输入的增强，以提高模型对各种图像输入的Robustness，并避免过拟合。</li>
<li>results: 使用这种方法训练了 mouse、rat、兔子、猩猩和人类大脑MRI 3D U-Net 模型，并实现了分割任务，这种工具可以有效地解决深度学习应用图像分析中的数据有限问题，为研究人员提供一个统一的解决方案，只需要一个图像样本就能训练深度神经网络。<details>
<summary>Abstract</summary>
Deep learning models usually require sufficient training data to achieve high accuracy, but obtaining labeled data can be time-consuming and labor-intensive. Here we introduce a template-based training method to train a 3D U-Net model from scratch using only one population-averaged brain MRI template and its associated segmentation label. The process incorporated visual perception augmentation to enhance the model's robustness in handling diverse image inputs and mitigating overfitting. Leveraging this approach, we trained 3D U-Net models for mouse, rat, marmoset, rhesus, and human brain MRI to achieve segmentation tasks such as skull-stripping, brain segmentation, and tissue probability mapping. This tool effectively addresses the limited availability of training data and holds significant potential for expanding deep learning applications in image analysis, providing researchers with a unified solution to train deep neural networks with only one image sample.
</details>
<details>
<summary>摘要</summary>
深度学习模型通常需要充足的训练数据以达到高精度，但获取标注数据可以是时间consuming和劳动密集的。我们介绍了一个模板基本训练方法，用于从零开始训练3D U-Net模型，只使用一个人类大脑MRI模板和其关联的分割标注。该过程包括视觉感知增强，以提高模型对多种图像输入的可以性和避免过拟合。通过这种方法，我们训练了 mouse、rat、marmoset、rhesus和人类大脑MRI 3D U-Net模型，用于实现分解任务 such as skull-stripping、brain segmentation和组织概率地图。这个工具有效地解决了训练数据的有限性问题，并有潜在的扩展深度学习应用于图像分析领域，为研究人员提供了一个统一的解决方案，只需一个图像样本就能训练深度神经网络。
</details></li>
</ul>
<hr>
<h2 id="T-UNet-Triplet-UNet-for-Change-Detection-in-High-Resolution-Remote-Sensing-Images"><a href="#T-UNet-Triplet-UNet-for-Change-Detection-in-High-Resolution-Remote-Sensing-Images" class="headerlink" title="T-UNet: Triplet UNet for Change Detection in High-Resolution Remote Sensing Images"></a>T-UNet: Triplet UNet for Change Detection in High-Resolution Remote Sensing Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02356">http://arxiv.org/abs/2308.02356</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pl-2000/t-unet">https://github.com/pl-2000/t-unet</a></li>
<li>paper_authors: Huan Zhong, Chen Wu</li>
<li>For: 这个研究旨在提出一个新的网络模型，以便更精确地检测遥感图像之间的变化。* Methods: 这个模型使用了一个三条分支Encoder，并且将 triplet Encoder 用于同时提取物件特征和时间间隔图像之间的变化特征。另外，这个模型还具有多条分支空间特征交互模组 (MBSSCA)，以便有效地交互和融合各分支中的特征。* Results: 这个模型可以更精确地检测遥感图像之间的变化，并且可以实时地提取变化的细节信息。<details>
<summary>Abstract</summary>
Remote sensing image change detection aims to identify the differences between images acquired at different times in the same area. It is widely used in land management, environmental monitoring, disaster assessment and other fields. Currently, most change detection methods are based on Siamese network structure or early fusion structure. Siamese structure focuses on extracting object features at different times but lacks attention to change information, which leads to false alarms and missed detections. Early fusion (EF) structure focuses on extracting features after the fusion of images of different phases but ignores the significance of object features at different times for detecting change details, making it difficult to accurately discern the edges of changed objects. To address these issues and obtain more accurate results, we propose a novel network, Triplet UNet(T-UNet), based on a three-branch encoder, which is capable to simultaneously extract the object features and the change features between the pre- and post-time-phase images through triplet encoder. To effectively interact and fuse the features extracted from the three branches of triplet encoder, we propose a multi-branch spatial-spectral cross-attention module (MBSSCA). In the decoder stage, we introduce the channel attention mechanism (CAM) and spatial attention mechanism (SAM) to fully mine and integrate detailed textures information at the shallow layer and semantic localization information at the deep layer.
</details>
<details>
<summary>摘要</summary>
distant 感知图像变化检测 aimsto identify 不同时间在同一个区域中的图像差异。 它广泛应用于土地管理、环境监测、灾害评估等领域。 现在，大多数变化检测方法基于 Siamese 网络结构或早期融合结构。 Siamese 结构专注于在不同时间抽取对象特征，但缺乏关注变化信息，这会导致假报警和错过检测。 Early Fusion 结构专注于在不同阶段图像融合后抽取特征，但忽视对象特征在不同时间的变化细节检测，这使得准确地识别变化对象的边缘很难。 为了解决这些问题并获得更加准确的结果，我们提出了一种新的网络， Triplet UNet（T-UNet），基于三个分支编码器。 T-UNet 可以同时提取对象特征和不同时间图像之间的变化特征，通过 triplet 编码器。 为了有效地交互和融合 triplet 编码器中的特征，我们提出了多个分支空间特征交叉注意力模块（MBSSCA）。 在解码阶段，我们引入通道注意力机制（CAM）和空间注意力机制（SAM），以全面挖掘和融合图像的细节信息和semantic 本地化信息。
</details></li>
</ul>
<hr>
<h2 id="Generative-Image-Priors-for-MRI-Reconstruction-Trained-from-Magnitude-Only-Images"><a href="#Generative-Image-Priors-for-MRI-Reconstruction-Trained-from-Magnitude-Only-Images" class="headerlink" title="Generative Image Priors for MRI Reconstruction Trained from Magnitude-Only Images"></a>Generative Image Priors for MRI Reconstruction Trained from Magnitude-Only Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02340">http://arxiv.org/abs/2308.02340</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mrirecon/image-priors">https://github.com/mrirecon/image-priors</a></li>
<li>paper_authors: Guanxiong Luo, Xiaoqing Wang, Mortiz Blumenthal, Martin Schilling, Erik Hans Ulrich Rauf, Raviteja Kotikalapudi, Niels Focke, Martin Uecker</li>
<li>for: 这个论文的目的是构建基于磁场图像的生成型图像先验，以提高图像质量。</li>
<li>methods: 该方法开始于准备具有磁场信息的训练数据集，并将其用于训练生成型图像先验。最后，使用不同的抽样方案进行了测试。</li>
<li>results: 实验结果表明，基于复杂图像的先验比只基于磁场图像的先验更高效。此外，一个训练于更大数据集的先验表现了更高的可靠性。最后，我们发现使用生成型先验比L1-wavelet常量化抑制可以在高抽样率下实现更好的压缩成像。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Purpose: In this work, we present a workflow to construct generic and robust generative image priors from magnitude-only images. The priors can then be used for regularization in reconstruction to improve image quality. Methods: The workflow begins with the preparation of training datasets from magnitude-only MR images. This dataset is then augmented with phase information and used to train generative priors of complex images. Finally, trained priors are evaluated using both linear and nonlinear reconstruction for compressed sensing parallel imaging with various undersampling schemes. Results: The results of our experiments demonstrate that priors trained on complex images outperform priors trained only on magnitude images. Additionally, a prior trained on a larger dataset exhibits higher robustness. Finally, we show that the generative priors are superior to L1 -wavelet regularization for compressed sensing parallel imaging with high undersampling. Conclusion: These findings stress the importance of incorporating phase information and leveraging large datasets to raise the performance and reliability of the generative priors for MRI reconstruction. Phase augmentation makes it possible to use existing image databases for training.
</details>
<details>
<summary>摘要</summary>
目的：在这项工作中，我们提出了一种工作流程，用于从偏差图像中构建通用和Robust的生成图像先验。这些先验然后可以用于图像重建中的规范化，以提高图像质量。方法：工作流程开始于准备各种训练集，其中包括偏差图像。这些训练集然后被扩展以包括相位信息，并用于训练生成图像先验。最后，我们使用不同的抽样方案进行重建，以评估训练过的先验。结果：我们的实验结果表明，基于复杂图像的先验在重建中表现较好，而且一个基于更大的数据集的先验具有更高的稳定性。此外，我们还证明了这些生成先验在高度抽样下的扩散成像中超过L1-wavelet规范化。结论：这些结果强调了在MRI重建中包含相位信息和利用大型数据集来提高生成先验的性能和可靠性。相位扩展使得可以使用现有的图像库进行训练。
</details></li>
</ul>
<hr>
<h2 id="CT-Reconstruction-from-Few-Planar-X-rays-with-Application-towards-Low-resource-Radiotherapy"><a href="#CT-Reconstruction-from-Few-Planar-X-rays-with-Application-towards-Low-resource-Radiotherapy" class="headerlink" title="CT Reconstruction from Few Planar X-rays with Application towards Low-resource Radiotherapy"></a>CT Reconstruction from Few Planar X-rays with Application towards Low-resource Radiotherapy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02100">http://arxiv.org/abs/2308.02100</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wanderinrain/xray2ct">https://github.com/wanderinrain/xray2ct</a></li>
<li>paper_authors: Yiran Sun, Tucker Netherton, Laurence Court, Ashok Veeraraghavan, Guha Balakrishnan</li>
<li>For: 提供了一种方法，使用几（&lt;5）个平面X射影像生成CT量子，并在临床应用中进行了首次评估：放疗规划。* Methods: 使用深度生成模型，基于神经隐式表示法生成三维CT剖图从平面X射影像中。通过在训练过程中使用解剖指导，使模型专注于临床相关特征。* Results: 对于 Thoracic CT 的放疗规划，通过模型生成的剖图，让是ocoenter radiation dose与临床获取的 CT 图像中的 radiation dose差异&lt;1%。此外，模型也比最近的稀疙CT重建基eline在 LIDC 肺CT 数据集上的标准像素和结构级指标（PSNR、SSIM、Dice 分数）上表现更好。<details>
<summary>Abstract</summary>
CT scans are the standard-of-care for many clinical ailments, and are needed for treatments like external beam radiotherapy. Unfortunately, CT scanners are rare in low and mid-resource settings due to their costs. Planar X-ray radiography units, in comparison, are far more prevalent, but can only provide limited 2D observations of the 3D anatomy. In this work, we propose a method to generate CT volumes from few (<5) planar X-ray observations using a prior data distribution, and perform the first evaluation of such a reconstruction algorithm for a clinical application: radiotherapy planning. We propose a deep generative model, building on advances in neural implicit representations to synthesize volumetric CT scans from few input planar X-ray images at different angles. To focus the generation task on clinically-relevant features, our model can also leverage anatomical guidance during training (via segmentation masks). We generated 2-field opposed, palliative radiotherapy plans on thoracic CTs reconstructed by our method, and found that isocenter radiation dose on reconstructed scans have <1% error with respect to the dose calculated on clinically acquired CTs using <=4 X-ray views. In addition, our method is better than recent sparse CT reconstruction baselines in terms of standard pixel and structure-level metrics (PSNR, SSIM, Dice score) on the public LIDC lung CT dataset. Code is available at: https://github.com/wanderinrain/Xray2CT.
</details>
<details>
<summary>摘要</summary>
干扰CT扫描是许多临床病情的标准治疗方式，并用于外部束辐射治疗。然而，CT扫描仪在LOW和中等资源设置中罕见，主要因为它们的成本高。相比之下，平面X射线投影机更加普遍，但它们只能提供2D结构的有限观察。在这种情况下，我们提出了一种方法，使用先前数据分布来生成CT卷积体从几个平面X射线图像中。我们还提出了一种深度生成模型，基于神经隐式表示来生成3D CT扫描图像从几个平面X射线图像的不同角度。为了聚焦生成任务在临床相关特征上，我们的模型还可以在训练过程中使用解剖指导（通过分剖排序）。我们使用这种方法生成了2个场 opposed、肺部Palliative radiotherapy计划，并发现在我们重建的CT扫描图像上的辐射剂量与临床获得的CT扫描图像使用4个X射线视图计算的辐射剂量之间的差异小于1%。此外，我们的方法也比最近的稀疏CT重建基准值更高于标准像素级和结构级度指标（PSNR、SSIM、Dice分数）在公共的LIDC肺CT数据集上。代码可以在：https://github.com/wanderinrain/Xray2CT中找到。
</details></li>
</ul>
<hr>
<h2 id="Motion-robust-free-running-cardiovascular-MRI"><a href="#Motion-robust-free-running-cardiovascular-MRI" class="headerlink" title="Motion-robust free-running cardiovascular MRI"></a>Motion-robust free-running cardiovascular MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02088">http://arxiv.org/abs/2308.02088</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/syedmurtazaarshad/motion-robust-CMR">https://github.com/syedmurtazaarshad/motion-robust-CMR</a></li>
<li>paper_authors: Syed M. Arshad, Lee C. Potter, Chong Chen, Yingmin Liu, Preethi Chandrasekaran, Christopher Crabtree, Yuchi Han, Rizwan Ahmad</li>
<li>For: The paper is written to present and validate an outlier rejection method for free-running cardiovascular MRI (CMR) to make it more motion robust.* Methods: The proposed method, called compressive recovery with outlier rejection (CORe), models outliers as an auxiliary variable and enforces MR physics-guided group-sparsity on it, which is jointly estimated with the image using an iterative algorithm.* Results: The simulation studies show that CORe outperforms traditional compressed sensing (CS), robust regression (RR), and another outlier rejection method in terms of normalized mean squared error (NMSE) and structural similarity index (SSIM) across 50 different realizations. The expert reader evaluation of 3D cine images demonstrates that CORe is more effective in suppressing artifacts while maintaining or improving image sharpness. The flow consistency evaluation in 4D flow images shows that CORe yields more consistent flow measurements, especially under exercise stress.Here is the information in Simplified Chinese text:* For: 本研究是为提出并验证一种用于自由运行心血管MRI（CMR）的异常拒绝方法，以提高其震动稳定性。* 方法: 提议的方法是压缩恢复与异常拒绝（CORe），它将异常作为辅助变量，并在这个变量上遵循MR物理指导的群集稀缺，通过迭代算法来同时估计异常和图像。* 结果: 实验研究表明，CORe在50个不同实现中的normalized mean squared error（NMSE）和结构相似指数（SSIM）比CS、RR和另一种异常拒绝方法更高。专家读者评估3D cinema图像表明，CORe更有效地抑制artefacts，保持或改善图像锐度。4D流动图像中的流量一致性评估表明，CORe在运动压力下得到了更一致的流量测量。<details>
<summary>Abstract</summary>
PURPOSE: To present and validate an outlier rejection method that makes free-running cardiovascular MRI (CMR) more motion robust.   METHODS: The proposed method, called compressive recovery with outlier rejection (CORe), models outliers as an auxiliary variable that is added to the measured data. We enforce MR physics-guided group-sparsity on the auxiliary variable and jointly estimate it along with the image using an iterative algorithm. For validation, CORe is first compared to traditional compressed sensing (CS), robust regression (RR), and another outlier rejection method using two simulation studies. Then, CORe is compared to CS using five 3D cine and ten rest and stress 4D flow imaging datasets.   RESULTS: Our simulation studies show that CORe outperforms CS, RR, and the outlier rejection method in terms of normalized mean squared error (NMSE) and structural similarity index (SSIM) across 50 different realizations. The expert reader evaluation of 3D cine images demonstrates that CORe is more effective in suppressing artifacts while maintaining or improving image sharpness. The flow consistency evaluation in 4D flow images show that CORe yields more consistent flow measurements, especially under exercise stress.   CONCLUSION: An outlier rejection method is presented and validated using simulated and measured data. This method can help suppress motion artifacts in a wide range of free-running CMR applications.   CODE: MATLAB implementation code is available on GitHub at https://github.com/syedmurtazaarshad/motion-robust-CMR
</details>
<details>
<summary>摘要</summary>
目的：提出和验证一种可以使自由运行征Cardiovascular MRI（CMR）更加鲁棒于运动 artifacts的方法。方法：提出的方法称为压缩恢复与外围异常值拒绝（CORe），将异常值视为一个辅助变量，并将其添加到测量数据中。我们遵循MR物理指导的群集稀缺性来限制这个辅助变量，并使用迭代算法来同时估计它和图像。验证：首先，CORe与传统的压缩感知（CS）、Robust Regression（RR）和另一种异常值拒绝方法进行了两个 simulations studies。然后，CORe与CS进行了五个3D缓冲和十个Rest和奋斗4D流图像数据集的比较。结果：我们的 simulations studies表明，CORe在NMSE和SSIM方面与CS、RR和另一种异常值拒绝方法都有更好的性能，并且在50个不同的实现中保持稳定。专业读者对3D缓冲图像进行了评估，表明CORe更有效地抑制artefacts，同时保持或改善图像的锐度。在4D流图像中，CORe得到了更一致的流量测量结果，特别是在运动压力下。结论：在自由运行CMR应用中，我们提出了一种可以抑制运动artefacts的异常值拒绝方法，并通过 simulations 和实验验证了其效果。代码：MATLAB实现代码可以在 GitHub 上找到，https://github.com/syedmurtazaarshad/motion-robust-CMR。
</details></li>
</ul>
<hr>
<h2 id="Diffusion-Models-for-Counterfactual-Generation-and-Anomaly-Detection-in-Brain-Images"><a href="#Diffusion-Models-for-Counterfactual-Generation-and-Anomaly-Detection-in-Brain-Images" class="headerlink" title="Diffusion Models for Counterfactual Generation and Anomaly Detection in Brain Images"></a>Diffusion Models for Counterfactual Generation and Anomaly Detection in Brain Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02062">http://arxiv.org/abs/2308.02062</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alessandro-f/dif-fuse">https://github.com/alessandro-f/dif-fuse</a></li>
<li>paper_authors: Alessandro Fontanella, Grant Mair, Joanna Wardlaw, Emanuele Trucco, Amos Storkey</li>
<li>for: 这个研究是为了提供一种弱型指导的方法，可以将疾病影像转换为健康版本，以便增强医生的训练档案和改善分类模型的解释力。</li>
<li>methods: 这个方法使用了一个称为ACAT的病理区域映射，然后使用了一个扩散模型，该模型是基于健康样本的，并且使用了DDPM和DDIM两种方法来进行修改。</li>
<li>results: 这个方法可以将健康样本转换为疾病影像，并且可以提高这些影像的重建精度。在实验中，这个方法比于其他弱型指导方法，对于stroke病变和脑癌分类而言，可以提高DICE score。<details>
<summary>Abstract</summary>
Segmentation masks of pathological areas are useful in many medical applications, such as brain tumour and stroke management. Moreover, healthy counterfactuals of diseased images can be used to enhance radiologists' training files and to improve the interpretability of segmentation models. In this work, we present a weakly supervised method to generate a healthy version of a diseased image and then use it to obtain a pixel-wise anomaly map. To do so, we start by considering a saliency map that approximately covers the pathological areas, obtained with ACAT. Then, we propose a technique that allows to perform targeted modifications to these regions, while preserving the rest of the image. In particular, we employ a diffusion model trained on healthy samples and combine Denoising Diffusion Probabilistic Model (DDPM) and Denoising Diffusion Implicit Model (DDIM) at each step of the sampling process. DDPM is used to modify the areas affected by a lesion within the saliency map, while DDIM guarantees reconstruction of the normal anatomy outside of it. The two parts are also fused at each timestep, to guarantee the generation of a sample with a coherent appearance and a seamless transition between edited and unedited parts. We verify that when our method is applied to healthy samples, the input images are reconstructed without significant modifications. We compare our approach with alternative weakly supervised methods on IST-3 for stroke lesion segmentation and on BraTS2021 for brain tumour segmentation, where we improve the DICE score of the best competing method from $0.6534$ to $0.7056$.
</details>
<details>
<summary>摘要</summary>
Segmentation masks of pathological areas are useful in many medical applications, such as brain tumour and stroke management. Moreover, healthy counterfactuals of diseased images can be used to enhance radiologists' training files and to improve the interpretability of segmentation models. In this work, we present a weakly supervised method to generate a healthy version of a diseased image and then use it to obtain a pixel-wise anomaly map. To do so, we start by considering a saliency map that approximately covers the pathological areas, obtained with ACAT. Then, we propose a technique that allows to perform targeted modifications to these regions, while preserving the rest of the image. In particular, we employ a diffusion model trained on healthy samples and combine Denoising Diffusion Probabilistic Model (DDPM) and Denoising Diffusion Implicit Model (DDIM) at each step of the sampling process. DDPM is used to modify the areas affected by a lesion within the saliency map, while DDIM guarantees reconstruction of the normal anatomy outside of it. The two parts are also fused at each timestep, to guarantee the generation of a sample with a coherent appearance and a seamless transition between edited and unedited parts. We verify that when our method is applied to healthy samples, the input images are reconstructed without significant modifications. We compare our approach with alternative weakly supervised methods on IST-3 for stroke lesion segmentation and on BraTS2021 for brain tumour segmentation, where we improve the DICE score of the best competing method from $0.6534$ to $0.7056$.
</details></li>
</ul>
<hr>
<h2 id="Predicting-Ki67-ER-PR-and-HER2-Statuses-from-H-E-stained-Breast-Cancer-Images"><a href="#Predicting-Ki67-ER-PR-and-HER2-Statuses-from-H-E-stained-Breast-Cancer-Images" class="headerlink" title="Predicting Ki67, ER, PR, and HER2 Statuses from H&amp;E-stained Breast Cancer Images"></a>Predicting Ki67, ER, PR, and HER2 Statuses from H&amp;E-stained Breast Cancer Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01982">http://arxiv.org/abs/2308.01982</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amir Akbarnejad, Nilanjan Ray, Penny J. Barnes, Gilbert Bigras</li>
<li>for: The paper aims to investigate whether machine learning methods can accurately predict molecular information from histomorphology.</li>
<li>methods: The authors built a large-scale dataset of 185538 images with reliable measurements for Ki67, ER, PR, and HER2 statuses, using mirrored images of H&amp;E and IHC assays. They used a standard ViT-based pipeline to train the classifiers and achieved prediction performances around 90% in terms of AUC.</li>
<li>results: The authors showed that the trained classifiers can localize relevant regions, which encourages future work to improve the localizations. They also made their dataset publicly available for further research.<details>
<summary>Abstract</summary>
Despite the advances in machine learning and digital pathology, it is not yet clear if machine learning methods can accurately predict molecular information merely from histomorphology. In a quest to answer this question, we built a large-scale dataset (185538 images) with reliable measurements for Ki67, ER, PR, and HER2 statuses. The dataset is composed of mirrored images of H\&E and corresponding images of immunohistochemistry (IHC) assays (Ki67, ER, PR, and HER2. These images are mirrored through registration. To increase reliability, individual pairs were inspected and discarded if artifacts were present (tissue folding, bubbles, etc). Measurements for Ki67, ER and PR were determined by calculating H-Score from image analysis. HER2 measurement is based on binary classification: 0 and 1+ (IHC scores representing a negative subset) vs 3+ (IHC score positive subset). Cases with IHC equivocal score (2+) were excluded. We show that a standard ViT-based pipeline can achieve prediction performances around 90% in terms of Area Under the Curve (AUC) when trained with a proper labeling protocol. Finally, we shed light on the ability of the trained classifiers to localize relevant regions, which encourages future work to improve the localizations. Our proposed dataset is publicly available: https://ihc4bc.github.io/
</details>
<details>
<summary>摘要</summary>
尽管机器学习和数字 PATHOLOGY 技术已经得到了进步，但是目前还没有确切地知道机器学习方法是否可以从 histomorphology 中精确预测分子信息。为了回答这个问题，我们创建了一个大规模数据集 (185538 张图像)，其中包含可靠的测量值 для Ki67、ER、PR 和 HER2 状况。这个数据集包括 H\&E 和相关的免疫染色技术 (IHC) 图像的相互镜像 (Ki67、ER、PR 和 HER2)。这些图像通过注册进行镜像。为了增加可靠性，我们 manually 检查并排除了ifacts 存在的个体对 (肿瘤卷绕、气泡等)。我们使用 H-Score 来计算 Ki67、ER 和 PR 的测量值，而 HER2 测量值则基于二分类：0 和 1+ (IHC 分数表示负 subsets) vs 3+ (IHC 分数表示正 subsets)。我们排除了 IHC equivocal 分数 (2+) 的情况。我们显示，使用标准 ViT-based 管道可以在训练时达到约 90% 的区域 beneath the curve (AUC) 性能。最后，我们探讨了训练的分类器是否可以准确地呈现相关区域，这有助于未来的工作。我们提供的数据集可以在以下链接中下载：https://ihc4bc.github.io/
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/04/eess.IV_2023_08_04/" data-id="closbroxg014z0g88hzsp18s9" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/03/cs.SD_2023_08_03/" class="article-date">
  <time datetime="2023-08-03T15:00:00.000Z" itemprop="datePublished">2023-08-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/03/cs.SD_2023_08_03/">cs.SD - 2023-08-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Versatile-Time-Frequency-Representations-Realized-by-Convex-Penalty-on-Magnitude-Spectrogram"><a href="#Versatile-Time-Frequency-Representations-Realized-by-Convex-Penalty-on-Magnitude-Spectrogram" class="headerlink" title="Versatile Time-Frequency Representations Realized by Convex Penalty on Magnitude Spectrogram"></a>Versatile Time-Frequency Representations Realized by Convex Penalty on Magnitude Spectrogram</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01665">http://arxiv.org/abs/2308.01665</a></li>
<li>repo_url: None</li>
<li>paper_authors: Keidai Arai, Koki Yamada, Kohei Yatabe</li>
<li>for: 本研究旨在提出一种基于 convex 优化的时Frequency（T-F）表示方法，用于实现自定义的时Frequency表示特性。</li>
<li>methods: 本研究使用了基于优化的方法，包括基于原始基的扩展，来设计 T-F 表示。</li>
<li>results: 本研究提出了一种可以根据用户要求定制时Frequency表示的方法，并通过数学分析和实验例子表明了该方法的有效性。<details>
<summary>Abstract</summary>
Sparse time-frequency (T-F) representations have been an important research topic for more than several decades. Among them, optimization-based methods (in particular, extensions of basis pursuit) allow us to design the representations through objective functions. Since acoustic signal processing utilizes models of spectrogram, the flexibility of optimization-based T-F representations is helpful for adjusting the representation for each application. However, acoustic applications often require models of \textit{magnitude} of T-F representations obtained by discrete Gabor transform (DGT). Adjusting a T-F representation to such a magnitude model (e.g., smoothness of magnitude of DGT coefficients) results in a non-convex optimization problem that is difficult to solve. In this paper, instead of tackling difficult non-convex problems, we propose a convex optimization-based framework that realizes a T-F representation whose magnitude has characteristics specified by the user. We analyzed the properties of the proposed method and provide numerical examples of sparse T-F representations having, e.g., low-rank or smooth magnitude, which have not been realized before.
</details>
<details>
<summary>摘要</summary>
零埋时频（T-F）表示已经是研究领域中的重要话题， duration of more than several decades. Among them, 优化基于方法（特别是基 pursuit 的扩展）， allowing us to design the representation through objective functions. 因为音声信号处理使用spectrogram模型， therefore, the flexibility of optimization-based T-F representations is helpful for adjusting the representation for each application. However, acoustic applications often require models of 音声信号的大小（magnitude）obtained by discrete Gabor transform (DGT). Adjusting a T-F representation to such a magnitude model (e.g., smoothness of magnitude of DGT coefficients) results in a non-convex optimization problem that is difficult to solve. In this paper, instead of tackling difficult non-convex problems, we propose a convex optimization-based framework that realizes a T-F representation whose magnitude has characteristics specified by the user. We analyzed the properties of the proposed method and provide numerical examples of sparse T-F representations having, e.g., low-rank or smooth magnitude, which have not been realized before.
</details></li>
</ul>
<hr>
<h2 id="Optimizing-multi-user-sound-communications-in-reverberating-environments-with-acoustic-reconfigurable-metasurfaces"><a href="#Optimizing-multi-user-sound-communications-in-reverberating-environments-with-acoustic-reconfigurable-metasurfaces" class="headerlink" title="Optimizing multi-user sound communications in reverberating environments with acoustic reconfigurable metasurfaces"></a>Optimizing multi-user sound communications in reverberating environments with acoustic reconfigurable metasurfaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01531">http://arxiv.org/abs/2308.01531</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongkuan Zhang, Qiyuan Wang, Mathias Fink, Guancong Ma</li>
<li>for: 解决在噪音强度高的房间中，多个人同时说话，使其完全理解和无法交叠信息的问题。</li>
<li>methods: 开发了一种智能听音墙，可以电子控制，并由学习算法根据房间几何和源器和接收器的位置进行自适应调整。</li>
<li>results: 实现了控制多спектル声场，覆盖了很大的谱域，包括隐含通信、频分多路通信和多用户通信等多种功能，并在实验中实现了无交叠的同时音乐播放。<details>
<summary>Abstract</summary>
How do you ensure that, in a reverberant room, several people can speak simultaneously to several other people, making themselves perfectly understood and without any crosstalk between messages? In this work, we report a conceptual solution to this problem by developing an intelligent acoustic wall, which can be reconfigured electronically and is controlled by a learning algorithm that adapts to the geometry of the room and the positions of sources and receivers. To this end, a portion of the room boundaries is covered with a smart mirror made of a broadband acoustic reconfigurable metasurface (ARMs) designed to provide a two-state (0 or {\pi}) phase shift in the reflected waves by 200 independently tunable units. The whole phase pattern is optimized to maximize the Shannon capacity while minimizing crosstalk between the different sources and receivers. We demonstrate the control of multi-spectral sound fields covering a spectrum much larger than the coherence bandwidth of the room for diverse striking functionalities, including crosstalk-free acoustic communication, frequency-multiplexed communications, and multi-user communications. An experiment conducted with two music sources for two different people demonstrates a crosstalk-free simultaneous music playback. Our work opens new routes for the control of sound waves in complex media and for a new generation of acoustic devices.
</details>
<details>
<summary>摘要</summary>
如何在噪音强的房间中，许多人同时与别人说话，保持完整的理解和没有任何干扰？在这项工作中，我们报道了一种概念解决方案，通过开发智能音频墙来实现。这个墙可以电子控制，并由学习算法控制，以适应房间的几何结构和源器和接收器的位置。为此，部分房间边界被覆盖了一块智能镜，由一百多个独立调整的单元组成，每个单元可以提供0或π的阶段差。整个阶段模式被优化，以最大化吞吐量，同时减少不同源器和接收器之间的干扰。我们实际操作了多色音场，覆盖了房间的较大的吸收带，并实现了不同的吸引功能，包括干扰自由的音频通信、频分多路通信和多用户通信。在两个音源为两个不同的人的实验中，我们实现了干扰自由的同时播放音乐。我们的工作开启了控制噪音媒体的新路线，以及一代新的噪音设备。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/03/cs.SD_2023_08_03/" data-id="closbrot000uj0g88hha10hdm" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_08_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/03/eess.AS_2023_08_03/" class="article-date">
  <time datetime="2023-08-03T14:00:00.000Z" itemprop="datePublished">2023-08-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/03/eess.AS_2023_08_03/">eess.AS - 2023-08-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Many-to-Many-Spoken-Language-Translation-via-Unified-Speech-and-Text-Representation-Learning-with-Unit-to-Unit-Translation"><a href="#Many-to-Many-Spoken-Language-Translation-via-Unified-Speech-and-Text-Representation-Learning-with-Unit-to-Unit-Translation" class="headerlink" title="Many-to-Many Spoken Language Translation via Unified Speech and Text Representation Learning with Unit-to-Unit Translation"></a>Many-to-Many Spoken Language Translation via Unified Speech and Text Representation Learning with Unit-to-Unit Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01831">http://arxiv.org/abs/2308.01831</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minsu Kim, Jeongsoo Choi, Dahun Kim, Yong Man Ro</li>
<li>for: 本研究旨在提出一种方法，用于学习多语言speech和文本的统一表示，以便在单个模型上进行多种多样的语言相关任务。</li>
<li>methods: 本研究使用自动学习的speech模型来编码speech特征，并将其转化为pseudo文本的形式，以便将语言特征作为输入进行学习。然后，提出一种基于encoder-decoder结构的 Unit-to-Unit Translation (UTUT) 目标函数，用于在多语言数据上训练模型。</li>
<li>results: 通过对多种语言进行实验， validate the efficacy of the proposed method across diverse multilingual tasks, 并达到了多到多语言的同时翻译。此外，本研究还展示了 UTUT 可以实现多到多语言的同时翻译，这在文献中尚未被研究过。<details>
<summary>Abstract</summary>
In this paper, we propose a method to learn unified representations of multilingual speech and text with a single model, especially focusing on the purpose of speech synthesis. We represent multilingual speech audio with speech units, the quantized representations of speech features encoded from a self-supervised speech model. Therefore, we can focus on their linguistic content by treating the audio as pseudo text and can build a unified representation of speech and text. Then, we propose to train an encoder-decoder structured model with a Unit-to-Unit Translation (UTUT) objective on multilingual data. Specifically, by conditioning the encoder with the source language token and the decoder with the target language token, the model is optimized to translate the spoken language into that of the target language, in a many-to-many language translation setting. Therefore, the model can build the knowledge of how spoken languages are comprehended and how to relate them to different languages. A single pre-trained model with UTUT can be employed for diverse multilingual speech- and text-related tasks, such as Speech-to-Speech Translation (STS), multilingual Text-to-Speech Synthesis (TTS), and Text-to-Speech Translation (TTST). By conducting comprehensive experiments encompassing various languages, we validate the efficacy of the proposed method across diverse multilingual tasks. Moreover, we show UTUT can perform many-to-many language STS, which has not been previously explored in the literature. Samples are available on https://choijeongsoo.github.io/utut.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种方法，可以通过单个模型学习多语言语音和文本的统一表示，特别是在语音合成的目的下。我们使用自动编码的语音特征来编码多语言语音，并将其转换为 pseudo 文本，以便更好地关注它们的语言内容。然后，我们提出了一种基于encoder-decoder结构的模型，使用单位至单位翻译（UTUT）目标进行训练。具体来说，通过将encoder Conditioned with source language token，并将decoder Conditioned with target language token，模型会被优化为将语言转换为目标语言，在多种语言翻译设定下。因此，模型可以学习不同语言之间的关系，并如何将语音翻译成不同语言。一个预训练的UTUT模型可以在多种多语言语音和文本相关任务中使用，如语音到语音翻译（STS）、多语言文本到语音合成（TTS）和文本到语音翻译（TTST）。通过对多种语言进行全面的实验，我们证明了提议方法的有效性。此外，我们还证明了UTUT可以实现多语言 STS，这在文献中尚未被探讨。详细实验结果和样例可以在https://choijeongsoo.github.io/utut上找到。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/03/eess.AS_2023_08_03/" data-id="closbrovw010w0g8821n9djat" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/03/cs.CV_2023_08_03/" class="article-date">
  <time datetime="2023-08-03T13:00:00.000Z" itemprop="datePublished">2023-08-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/03/cs.CV_2023_08_03/">cs.CV - 2023-08-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="An-End-to-end-Food-Portion-Estimation-Framework-Based-on-Shape-Reconstruction-from-Monocular-Image"><a href="#An-End-to-end-Food-Portion-Estimation-Framework-Based-on-Shape-Reconstruction-from-Monocular-Image" class="headerlink" title="An End-to-end Food Portion Estimation Framework Based on Shape Reconstruction from Monocular Image"></a>An End-to-end Food Portion Estimation Framework Based on Shape Reconstruction from Monocular Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01810">http://arxiv.org/abs/2308.01810</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeman Shao, Gautham Vinod, Jiangpeng He, Fengqing Zhu</li>
<li>for: 这个研究旨在提供一个自动化饮食评估解决方案，并且使用深度学习来估计食物能量价值。</li>
<li>methods: 这个方法使用一个终端 deep learning 框架，通过从食物图像中推导出食物的3D形状信息，以估计食物能量价值。</li>
<li>results: 在使用 Nutrition5k 食物图像集进行评估中，这个方法的 Mean Absolute Error (MAE) 为40.05 kCal， Mean Absolute Percentage Error (MAPE) 为11.47%。这个方法仅使用 RGB 图像作为输入，并且与需要 RGB 和深度信息的现有方法相比，它具有竞争力。<details>
<summary>Abstract</summary>
Dietary assessment is a key contributor to monitoring health status. Existing self-report methods are tedious and time-consuming with substantial biases and errors. Image-based food portion estimation aims to estimate food energy values directly from food images, showing great potential for automated dietary assessment solutions. Existing image-based methods either use a single-view image or incorporate multi-view images and depth information to estimate the food energy, which either has limited performance or creates user burdens. In this paper, we propose an end-to-end deep learning framework for food energy estimation from a monocular image through 3D shape reconstruction. We leverage a generative model to reconstruct the voxel representation of the food object from the input image to recover the missing 3D information. Our method is evaluated on a publicly available food image dataset Nutrition5k, resulting a Mean Absolute Error (MAE) of 40.05 kCal and Mean Absolute Percentage Error (MAPE) of 11.47% for food energy estimation. Our method uses RGB image as the only input at the inference stage and achieves competitive results compared to the existing method requiring both RGB and depth information.
</details>
<details>
<summary>摘要</summary>
饮食评估是健康状况监测的关键因素。现有的自我报告方法具有巨大的偏见和错误。图像基于食物部分估计技术可以直接从食物图像中估算食物能量值，显示出了自动化饮食评估解决方案的潜在优势。现有的图像基于方法可以使用单视图图像或多视图图像和深度信息来估算食物能量，但它们具有有限的性能或者让用户感到压力。在这篇论文中，我们提出了一种基于深度学习的端到端框架，通过RGB图像来估算食物能量。我们利用生成模型来重建食物对象的 voxel 表示，从输入图像中恢复缺失的3D信息。我们的方法在公共可用的饮食图像数据集Nutrition5k上进行评估，得到了40.05 kCal的平均绝对误差（MAE）和11.47%的平均绝对百分比误差（MAPE）。我们的方法只需RGB图像作为推理阶段的输入，实现了与需要RGB和深度信息的现有方法相比的竞争性成绩。
</details></li>
</ul>
<hr>
<h2 id="QUEST-Query-Stream-for-Vehicle-Infrastructure-Cooperative-Perception"><a href="#QUEST-Query-Stream-for-Vehicle-Infrastructure-Cooperative-Perception" class="headerlink" title="QUEST: Query Stream for Vehicle-Infrastructure Cooperative Perception"></a>QUEST: Query Stream for Vehicle-Infrastructure Cooperative Perception</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01804">http://arxiv.org/abs/2308.01804</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siqi Fan, Haibao Yu, Wenxian Yang, Jirui Yuan, Zaiqing Nie</li>
<li>for: 这篇论文的目的是提出一种名为QUEST的合作感知框架，以实现可解释的实例级别的 flexible feature interaction。</li>
<li>methods: 这篇论文使用了许多现有的合作方法，如结果合作和特征合作，并提出了一种新的查询合作方法，通过让查询流动 между代理进行交互。</li>
<li>results: 实验结果表明，QUEST 框架可以有效地提高合作感知性能，并且在实际应用场景中（如摄像头基于车辆基础设施感知）表现出了更高的传输灵活性和 packet dropout 的Robustness。<details>
<summary>Abstract</summary>
Cooperative perception can effectively enhance individual perception performance by providing additional viewpoint and expanding the sensing field. Existing cooperation paradigms are either interpretable (result cooperation) or flexible (feature cooperation). In this paper, we propose the concept of query cooperation to enable interpretable instance-level flexible feature interaction. To specifically explain the concept, we propose a cooperative perception framework, termed QUEST, which let query stream flow among agents. The cross-agent queries are interacted via fusion for co-aware instances and complementation for individual unaware instances. Taking camera-based vehicle-infrastructure perception as a typical practical application scene, the experimental results on the real-world dataset, DAIR-V2X-Seq, demonstrate the effectiveness of QUEST and further reveal the advantage of the query cooperation paradigm on transmission flexibility and robustness to packet dropout. We hope our work can further facilitate the cross-agent representation interaction for better cooperative perception in practice.
</details>
<details>
<summary>摘要</summary>
合作感知可以有效地提高个体感知性能，提供额外视点和扩大感知场。现有的合作方法是可解释的（结果合作）或者灵活的（特征合作）。在这篇论文中，我们提出了查询合作概念，以实现可解释的实例级别的灵活特征交互。为了具体说明这个概念，我们提出了一个合作感知框架，称为QUEST，允许查询流水线在代理之间流动。不同代理之间的问题是通过融合实现协同意识的实例，而不同代理之间的问题是通过补充实现个体未知的实例。使用摄像头基于车辆基础设施感知为实际应用场景，在DAIR-V2X-Seq实际数据集上进行实验， demonstarte了QUEST的效果，并透露了查询合作方法在传输灵活性和 packet dropout Robustness 的优势。我们希望我们的工作能够进一步促进跨代理表示交互，以便更好地实现合作感知在实践中。
</details></li>
</ul>
<hr>
<h2 id="RegionBLIP-A-Unified-Multi-modal-Pre-training-Framework-for-Holistic-and-Regional-Comprehension"><a href="#RegionBLIP-A-Unified-Multi-modal-Pre-training-Framework-for-Holistic-and-Regional-Comprehension" class="headerlink" title="RegionBLIP: A Unified Multi-modal Pre-training Framework for Holistic and Regional Comprehension"></a>RegionBLIP: A Unified Multi-modal Pre-training Framework for Holistic and Regional Comprehension</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02299">http://arxiv.org/abs/2308.02299</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mightyzau/regionblip">https://github.com/mightyzau/regionblip</a></li>
<li>paper_authors: Qiang Zhou, Chaohui Yu, Shaofeng Zhang, Sitong Wu, Zhibing Wang, Fan Wang</li>
<li>for: 本研究目的是延伸多模式大语言模型（MLLM）的理解范围，以包括地域对象。</li>
<li>methods: 我们提议提取地域特征作为软提示，以便不需要MLLM微调。我们还提出了一种新的位置协助特征提取模块，以有效地提取来自常见图像特征和点云特征的地域特征。</li>
<li>results: 我们的实验结果表明，我们的框架 RegionBLIP 可以保持 BLIP-2 的图像理解能力，并在新引入的点云模式和地域对象上增加理解能力。<details>
<summary>Abstract</summary>
In this work, we investigate extending the comprehension of Multi-modal Large Language Models (MLLMs) to regional objects. To this end, we propose to extract features corresponding to regional objects as soft prompts for LLM, which provides a straightforward and scalable approach and eliminates the need for LLM fine-tuning. To effectively extract regional features from regular image features and irregular point cloud features, we present a novel and unified position-assisted feature extraction module. Furthermore, training an MLLM from scratch is highly time-consuming. Thus, we propose incrementally extending existing pre-trained MLLMs to comprehend more modalities and the regional objects of those modalities. Specifically, we freeze the Q-Former from BLIP-2, an impressive MLLM, and optimize the modality-specific Lora parameters in Q-Former and LLM for each newly introduced modality. The freezing of the Q-Former eliminates the need for extensive pre-training on massive image-text data. The freezed Q-Former pre-trained from massive image-text data is also beneficial for the pre-training on image-region-text data. We name our framework RegionBLIP. We pre-train RegionBLIP on image-region-text, point-cloud-text, and point-cloud-region-text data. Experimental results verify that \Ours{} can preserve the image comprehension capability of BILP-2 and further gain a comprehension of the newly introduced point cloud modality and regional objects. The Data, Code, and Pre-trained models will be available at https://github.com/mightyzau/RegionBLIP.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们 investigate extending the comprehension of Multi-modal Large Language Models (MLLMs) to regional objects. 为此，我们提议提取对 regional objects 的特征作为 LLM 的软提示，这提供了一个直观的并可扩展的方法，并消除了 LLM 的 fine-tuning 需求。为了有效地从常见图像特征和点云特征中提取 regional 特征，我们提出了一个 novel 和统一的位置帮助特征提取模块。此外，预训练一个 MLLM 从头开始是非常时间消耗的。因此，我们提议逐步扩展现有的预训练 MLLM 以包括更多Modalities 和这些 Modality 中的 regional objects。具体来说，我们冻结 BLIP-2 中的 Q-Former，并优化 Modality-specific Lora 参数在 Q-Former 和 LLM 中。冻结 Q-Former 消除了大量预训练在图像-文本数据上的需求。同时，预训练 Q-Former 在图像-区域-文本数据上也有助于预训练。我们将这种框架命名为 RegionBLIP。我们在图像-区域-文本、点云-文本和点云-区域-文本数据上预训练 RegionBLIP。实验结果表明，我们的方法可以保持 BLIP-2 中的图像理解能力，同时还能够增加对新引入的点云模式和 regional objects 的理解。数据、代码和预训练模型将在 GitHub 上提供，链接在 https://github.com/mightyzau/RegionBLIP。
</details></li>
</ul>
<hr>
<h2 id="Point2Mask-Point-supervised-Panoptic-Segmentation-via-Optimal-Transport"><a href="#Point2Mask-Point-supervised-Panoptic-Segmentation-via-Optimal-Transport" class="headerlink" title="Point2Mask: Point-supervised Panoptic Segmentation via Optimal Transport"></a>Point2Mask: Point-supervised Panoptic Segmentation via Optimal Transport</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01779">http://arxiv.org/abs/2308.01779</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liwentomng/point2mask">https://github.com/liwentomng/point2mask</a></li>
<li>paper_authors: Wentong Li, Yuqian Yuan, Song Wang, Jianke Zhu, Jianshu Li, Jian Liu, Lei Zhang</li>
<li>for: 高级降级图像分割，避免高成本的像素级标注。</li>
<li>methods: 提出了一种有效的方法Point2Mask，通过单个随机点标注来实现高质量的精细预测。</li>
<li>results: 在Pascal VOC和COCO上实验表明，提出的Point2Mask方法可以在无需大量标注的情况下达到高水平的精细预测性能。<details>
<summary>Abstract</summary>
Weakly-supervised image segmentation has recently attracted increasing research attentions, aiming to avoid the expensive pixel-wise labeling. In this paper, we present an effective method, namely Point2Mask, to achieve high-quality panoptic prediction using only a single random point annotation per target for training. Specifically, we formulate the panoptic pseudo-mask generation as an Optimal Transport (OT) problem, where each ground-truth (gt) point label and pixel sample are defined as the label supplier and consumer, respectively. The transportation cost is calculated by the introduced task-oriented maps, which focus on the category-wise and instance-wise differences among the various thing and stuff targets. Furthermore, a centroid-based scheme is proposed to set the accurate unit number for each gt point supplier. Hence, the pseudo-mask generation is converted into finding the optimal transport plan at a globally minimal transportation cost, which can be solved via the Sinkhorn-Knopp Iteration. Experimental results on Pascal VOC and COCO demonstrate the promising performance of our proposed Point2Mask approach to point-supervised panoptic segmentation. Source code is available at: https://github.com/LiWentomng/Point2Mask.
</details>
<details>
<summary>摘要</summary>
Recently, weakly-supervised image segmentation has attracted increasing research attention, aiming to avoid the expensive pixel-wise labeling. In this paper, we propose an effective method, called Point2Mask, to achieve high-quality panoptic prediction using only a single random point annotation per target for training. Specifically, we formulate the panoptic pseudo-mask generation as an Optimal Transport (OT) problem, where each ground-truth (gt) point label and pixel sample are defined as the label supplier and consumer, respectively. The transportation cost is calculated by the introduced task-oriented maps, which focus on the category-wise and instance-wise differences among the various thing and stuff targets. Furthermore, a centroid-based scheme is proposed to set the accurate unit number for each gt point supplier. Hence, the pseudo-mask generation is converted into finding the optimal transport plan at a globally minimal transportation cost, which can be solved via the Sinkhorn-Knopp Iteration. Experimental results on Pascal VOC and COCO demonstrate the promising performance of our proposed Point2Mask approach to point-supervised panoptic segmentation. Source code is available at: https://github.com/LiWentomng/Point2Mask.Here's the word-for-word translation of the text into Simplified Chinese:最近，弱型图像分割获得了研究人员的越来越多的注意力，以避免高价的像素精度标注。在这篇论文中，我们提出了一种有效的方法，即Point2Mask，用于使用单个随机点标注来训练高质量�anoptic预测。具体来说，我们将�anoptic pseudo-mask生成视为一个Optimal Transport（OT）问题，其中每个ground-truth（gt）点标签和像素抽象被定义为标签供应商和消费者，分别。交通成本由引入的任务 oriented map计算，该地图强调类别和实例划分的差异。此外，我们提出了一种基于中心点的方案，以确定每个gt点供应商的准确单位数。因此，pseudo-mask生成转化为找到最低交通成本的优质运输计划，可以通过Sinkhorn-Knopp迭代解决。实验结果表明，我们提出的Point2Mask方法在Pascal VOC和COCO上表现出了扎实的推荐性。源代码可以在https://github.com/LiWentomng/Point2Mask上获取。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-based-Prediction-of-Stress-and-Strain-Maps-in-Arterial-Walls-for-Improved-Cardiovascular-Risk-Assessment"><a href="#Deep-Learning-based-Prediction-of-Stress-and-Strain-Maps-in-Arterial-Walls-for-Improved-Cardiovascular-Risk-Assessment" class="headerlink" title="Deep Learning-based Prediction of Stress and Strain Maps in Arterial Walls for Improved Cardiovascular Risk Assessment"></a>Deep Learning-based Prediction of Stress and Strain Maps in Arterial Walls for Improved Cardiovascular Risk Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01771">http://arxiv.org/abs/2308.01771</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yasin Shokrollahi1, Pengfei Dong1, Xianqi Li, Linxia Gu</li>
<li>for: 这个研究旨在替代finite element method（FEM），通过使用深度学习工具来更有效地预测血管壁的剪切应力和强度场。</li>
<li>methods: 我们提出了一种基于U-Net的全 convolutional neural network（CNN）来预测血管壁cross section中的 von Mises 剪切应力和强度场，并开发了一种基于conditional generative adversarial network（cGAN）来提高预测结果的准确性。</li>
<li>results: 我们的模型可以高度准确地预测 von Mises 剪切应力和强度场，SSIM分数为0.854和0.830， Mean squared errors为0.017和0.018。此外，我们还提出了 ensemble 和 transfer learning 技术来进一步提高模型的性能。<details>
<summary>Abstract</summary>
This study investigated the potential of end-to-end deep learning tools as a more effective substitute for FEM in predicting stress-strain fields within 2D cross sections of arterial wall. We first proposed a U-Net based fully convolutional neural network (CNN) to predict the von Mises stress and strain distribution based on the spatial arrangement of calcification within arterial wall cross-sections. Further, we developed a conditional generative adversarial network (cGAN) to enhance, particularly from the perceptual perspective, the prediction accuracy of stress and strain field maps for arterial walls with various calcification quantities and spatial configurations. On top of U-Net and cGAN, we also proposed their ensemble approaches, respectively, to further improve the prediction accuracy of field maps. Our dataset, consisting of input and output images, was generated by implementing boundary conditions and extracting stress-strain field maps. The trained U-Net models can accurately predict von Mises stress and strain fields, with structural similarity index scores (SSIM) of 0.854 and 0.830 and mean squared errors of 0.017 and 0.018 for stress and strain, respectively, on a reserved test set. Meanwhile, the cGAN models in a combination of ensemble and transfer learning techniques demonstrate high accuracy in predicting von Mises stress and strain fields, as evidenced by SSIM scores of 0.890 for stress and 0.803 for strain. Additionally, mean squared errors of 0.008 for stress and 0.017 for strain further support the model's performance on a designated test set. Overall, this study developed a surrogate model for finite element analysis, which can accurately and efficiently predict stress-strain fields of arterial walls regardless of complex geometries and boundary conditions.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这个研究 investigate了使用端到端深度学习工具作为较为有效的finite element分析的替代方法，以predict arterial wall的压力-弯形场在2D横截面上。我们首先提出了基于U-Net的全 convolutional neural network (CNN)，用于预测 calcification的空间布局对arterial wall横截面的 von Mises 压力和弯形场的分布。此外，我们还开发了基于 conditional generative adversarial network (cGAN)的模型，用于提高预测压力和弯形场图像的准确性。在U-Net和cGAN的基础之上，我们还提出了ensemble approaches，以进一步提高预测图像的准确性。我们的数据集，包括输入和输出图像，通过实施边界条件和提取压力-弯形场图像来生成。训练的U-Net模型可以准确预测 von Mises 压力和弯形场，SSIM 分数为0.854和0.830，mean squared error为0.017和0.018，分别对应于压力和弯形场。此外，cGAN模型在 transferred learning 和 ensemble learning 技术的组合下表现出了高度的准确性，SSIM 分数为0.890和0.803，mean squared error为0.008和0.017。总之，这个研究开发了一个surrogate model，可以高效地预测arterial wall的压力-弯形场，不 matter complex geometries和boundary conditions.
</details></li>
</ul>
<hr>
<h2 id="Focus-on-Content-not-Noise-Improving-Image-Generation-for-Nuclei-Segmentation-by-Suppressing-Steganography-in-CycleGAN"><a href="#Focus-on-Content-not-Noise-Improving-Image-Generation-for-Nuclei-Segmentation-by-Suppressing-Steganography-in-CycleGAN" class="headerlink" title="Focus on Content not Noise: Improving Image Generation for Nuclei Segmentation by Suppressing Steganography in CycleGAN"></a>Focus on Content not Noise: Improving Image Generation for Nuclei Segmentation by Suppressing Steganography in CycleGAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01769">http://arxiv.org/abs/2308.01769</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonas Utz, Tobias Weise, Maja Schlereth, Fabian Wagner, Mareike Thies, Mingxuan Gu, Stefan Uderhardt, Katharina Breininger</li>
<li>for: 这个论文主要用于描述一种用于生成顺序图像的潜在网络，以便为核体分 segmentation 任务提供更加准确的synthetic数据集。</li>
<li>methods: 该论文使用了 CycleGAN 生成器，并通过采用低通道滤波器基于 DCT 来除掉生成图像中的隐藏短路信息（steganography），以提高生成图像和cycled mask的准确性。</li>
<li>results: 相比 vanilla CycleGAN，该方法可以提高核体分 segmentation 任务的 F1 分数上的表现，提高了5.4个百分点。此外，该研究还证明了在 CycleGAN 架构中 integrate 高级规范技术可以减轻 steganography-related 问题，生成更加准确的synthetic数据集。<details>
<summary>Abstract</summary>
Annotating nuclei in microscopy images for the training of neural networks is a laborious task that requires expert knowledge and suffers from inter- and intra-rater variability, especially in fluorescence microscopy. Generative networks such as CycleGAN can inverse the process and generate synthetic microscopy images for a given mask, thereby building a synthetic dataset. However, past works report content inconsistencies between the mask and generated image, partially due to CycleGAN minimizing its loss by hiding shortcut information for the image reconstruction in high frequencies rather than encoding the desired image content and learning the target task. In this work, we propose to remove the hidden shortcut information, called steganography, from generated images by employing a low pass filtering based on the DCT. We show that this increases coherence between generated images and cycled masks and evaluate synthetic datasets on a downstream nuclei segmentation task. Here we achieve an improvement of 5.4 percentage points in the F1-score compared to a vanilla CycleGAN. Integrating advanced regularization techniques into the CycleGAN architecture may help mitigate steganography-related issues and produce more accurate synthetic datasets for nuclei segmentation.
</details>
<details>
<summary>摘要</summary>
描述核体在微scopic图像中的标注是一项劳动密集的任务，需要专家知识和受到内 raters 和外 raters 的变化，特别是在荧光微scopic中。生成网络如 CycleGAN 可以 inverse 该过程，生成基于给定的 mask 的 synthetic 微scopic图像，从而建立 synthetic 数据集。然而，过去的工作表明，生成的图像与 mask 之间存在内容不一致，部分是因为 CycleGAN 在高频范围内隐藏短路信息，而不是编码愿意图CONTENT 和学习目标任务。在这种情况下，我们提议从生成的图像中除去隐藏的短路信息，使用 DCT 基于低通过滤波。我们发现，这会增加生成图像和 цикли mask 之间的协调性，并评估 synthetic 数据集在下游核体分割任务中的性能。在这种情况下，我们实现了 Vanilla CycleGAN 的 5.4 个百分点 F1 score 的改进。将 advanced regularization techniques  integrate 到 CycleGAN 架构中可能会 mitigate steganography-related issues 并生成更准确的 synthetic 数据集 для核体分割任务。
</details></li>
</ul>
<hr>
<h2 id="Multidimensional-Data-Analysis-Based-on-Block-Convolutional-Tensor-Decomposition"><a href="#Multidimensional-Data-Analysis-Based-on-Block-Convolutional-Tensor-Decomposition" class="headerlink" title="Multidimensional Data Analysis Based on Block Convolutional Tensor Decomposition"></a>Multidimensional Data Analysis Based on Block Convolutional Tensor Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01768">http://arxiv.org/abs/2308.01768</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahdi Molavi, Mansoor Rezghi, Tayyebeh Saeedi<br>for:  This paper focuses on developing a new tensor-tensor product called the $\star_c{}\text{-Product}$ based on block convolution with reflective boundary conditions, and using it to improve tensor decomposition for analyzing high-dimensional data.methods: The paper uses the t-product of tensors and block convolution with reflective boundary conditions to develop a new tensor-tensor product called the $\star_c{}\text{-Product}$. The paper also introduces a tensor decomposition based on this product for arbitrary order tensors.results: The paper shows that the proposed $\star_c{}\text{-Product}$ has lower complexity than t-SVD and yields higher-quality results in applications such as classification and compression.<details>
<summary>Abstract</summary>
Tensor decompositions are powerful tools for analyzing multi-dimensional data in their original format. Besides tensor decompositions like Tucker and CP, Tensor SVD (t-SVD) which is based on the t-product of tensors is another extension of SVD to tensors that recently developed and has found numerous applications in analyzing high dimensional data. This paper offers a new insight into the t-Product and shows that this product is a block convolution of two tensors with periodic boundary conditions. Based on this viewpoint, we propose a new tensor-tensor product called the $\star_c{}\text{-Product}$ based on Block convolution with reflective boundary conditions. Using a tensor framework, this product can be easily extended to tensors of arbitrary order. Additionally, we introduce a tensor decomposition based on our $\star_c{}\text{-Product}$ for arbitrary order tensors. Compared to t-SVD, our new decomposition has lower complexity, and experiments show that it yields higher-quality results in applications such as classification and compression.
</details>
<details>
<summary>摘要</summary>
tensor decompositions是多维数据的分析工具， Besides tensor decompositions like Tucker和CP，tensor SVD（t-SVD），which is based on the t-product of tensors, is another extension of SVD to tensors that has recently been developed and has found numerous applications in analyzing high-dimensional data. This paper offers a new perspective on the t-product and shows that this product is a block convolution of two tensors with periodic boundary conditions. Based on this viewpoint, we propose a new tensor-tensor product called the $\star_c{}\text{-Product}$ based on block convolution with reflective boundary conditions. Using a tensor framework, this product can be easily extended to tensors of arbitrary order. Additionally, we introduce a tensor decomposition based on our $\star_c{}\text{-Product}$ for arbitrary-order tensors. Compared to t-SVD, our new decomposition has lower complexity, and experiments show that it yields higher-quality results in applications such as classification and compression.
</details></li>
</ul>
<hr>
<h2 id="PoissonNet-Resolution-Agnostic-3D-Shape-Reconstruction-using-Fourier-Neural-Operators"><a href="#PoissonNet-Resolution-Agnostic-3D-Shape-Reconstruction-using-Fourier-Neural-Operators" class="headerlink" title="PoissonNet: Resolution-Agnostic 3D Shape Reconstruction using Fourier Neural Operators"></a>PoissonNet: Resolution-Agnostic 3D Shape Reconstruction using Fourier Neural Operators</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01766">http://arxiv.org/abs/2308.01766</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/arsenal9971/poissonnet">https://github.com/arsenal9971/poissonnet</a></li>
<li>paper_authors: Hector Andrade-Loarca, Julius Hege, Aras Bacho, Gitta Kutyniok</li>
<li>for: 这个论文旨在解决用点云数据 reconstruction 3D  shapes 的问题，传统的深度神经网络在高分辨率下遇到计算复杂性的问题。</li>
<li>methods: 作者使用 fourier neural operator (FNO) 解决波兰方程，从oriented point cloud measurement中重建mesh。</li>
<li>results: 作者的方法在 reconstruction 质量、运行时间和分辨率灵活性方面比现有方法优秀，同时具有一shot super-resolution 和梯度可视化的优点。<details>
<summary>Abstract</summary>
We introduce PoissonNet, an architecture for shape reconstruction that addresses the challenge of recovering 3D shapes from points. Traditional deep neural networks face challenges with common 3D shape discretization techniques due to their computational complexity at higher resolutions. To overcome this, we leverage Fourier Neural Operators (FNOs) to solve the Poisson equation and reconstruct a mesh from oriented point cloud measurements. PoissonNet exhibits two main advantages. First, it enables efficient training on low-resolution data while achieving comparable performance at high-resolution evaluation, thanks to the resolution-agnostic nature of FNOs. This feature allows for one-shot super-resolution. Second, our method surpasses existing approaches in reconstruction quality while being differentiable. Overall, our proposed method not only improves upon the limitations of classical deep neural networks in shape reconstruction but also achieves superior results in terms of reconstruction quality, running time, and resolution flexibility. Furthermore, we demonstrate that the Poisson surface reconstruction problem is well-posed in the limit case by showing a universal approximation theorem for the solution operator of the Poisson equation with distributional data utilizing the Fourier Neural Operator, which provides a theoretical foundation for our numerical results. The code to reproduce the experiments is available on: \url{https://github.com/arsenal9971/PoissonNet}.
</details>
<details>
<summary>摘要</summary>
我们介绍PoissonNet，一个用于形状重建的架构，解决从点 cloud 中获取 3D 形状的挑战。传统的深度神经网络在高分辨率下 computationally 复杂，因此我们利用 Fourier Neural Operators (FNOs) 解决 Poisson 方程，从排序点云集中重建 mesh。PoissonNet 有两个主要优点：第一，它可以高效地在低分辨率上训练，并在高分辨率评估中实现相同的性能，这使得它能够实现一次超Resolution。第二，我们的方法可以超过现有的方法重建质量，并且可以实现可微的变化。总的来说，我们的提案不仅优化了传统的深度神经网络在形状重建中的局限性，而且实现了更好的重建质量、运行时间和分辨率灵活性。此外，我们还证明了 Poisson 面重建问题在极限情况下是可定义的，通过显示了基于 Fourier Neural Operator 的解析函数，则提供了理论基础 для我们的数据�Martin 的实验结果。Code 可以在：\url{https://github.com/arsenal9971/PoissonNet} 中找到。
</details></li>
</ul>
<hr>
<h2 id="NuInsSeg-A-Fully-Annotated-Dataset-for-Nuclei-Instance-Segmentation-in-H-E-Stained-Histological-Images"><a href="#NuInsSeg-A-Fully-Annotated-Dataset-for-Nuclei-Instance-Segmentation-in-H-E-Stained-Histological-Images" class="headerlink" title="NuInsSeg: A Fully Annotated Dataset for Nuclei Instance Segmentation in H&amp;E-Stained Histological Images"></a>NuInsSeg: A Fully Annotated Dataset for Nuclei Instance Segmentation in H&amp;E-Stained Histological Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01760">http://arxiv.org/abs/2308.01760</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/masih4/nuinsseg">https://github.com/masih4/nuinsseg</a></li>
<li>paper_authors: Amirreza Mahbod, Christine Polak, Katharina Feldmann, Rumsha Khan, Katharina Gelles, Georg Dorffner, Ramona Woitek, Sepideh Hatamikia, Isabella Ellinger</li>
<li>for: This paper is written for the task of automatic nuclei instance segmentation in whole slide image analysis, specifically using supervised deep learning methods.</li>
<li>methods: The paper uses a fully manually annotated dataset called NuInsSeg, which contains 665 image patches with over 30,000 manually segmented nuclei from 31 human and mouse organs. Additionally, the paper provides ambiguous area masks for the entire dataset, which represent parts of the images where precise manual annotations are impossible.</li>
<li>results: The paper releases one of the biggest fully manually annotated datasets of nuclei in Hematoxylin and Eosin (H&amp;E)-stained histological images, called NuInsSeg, which can be used to train and evaluate supervised deep learning models for nuclei instance segmentation.Here’s the information in Simplified Chinese text:</li>
<li>for: 这篇论文是为批处理学自动核体实例分割任务而写的，特别是使用监督深度学习方法。</li>
<li>methods: 这篇论文使用了完全手动标注的数据集，名为NuInsSeg，该数据集包含665个图像patch，共有30,000多个手动标注的核体。此外，论文还提供了整个数据集的模糊区域面积，表示图像中的不确定部分，即人工专家无法准确手动标注的部分。</li>
<li>results: 论文发布了一个大量的完全手动标注的核体数据集，名为NuInsSeg，可以用于训练和评估supervised深度学习模型。<details>
<summary>Abstract</summary>
In computational pathology, automatic nuclei instance segmentation plays an essential role in whole slide image analysis. While many computerized approaches have been proposed for this task, supervised deep learning (DL) methods have shown superior segmentation performances compared to classical machine learning and image processing techniques. However, these models need fully annotated datasets for training which is challenging to acquire, especially in the medical domain. In this work, we release one of the biggest fully manually annotated datasets of nuclei in Hematoxylin and Eosin (H&E)-stained histological images, called NuInsSeg. This dataset contains 665 image patches with more than 30,000 manually segmented nuclei from 31 human and mouse organs. Moreover, for the first time, we provide additional ambiguous area masks for the entire dataset. These vague areas represent the parts of the images where precise and deterministic manual annotations are impossible, even for human experts. The dataset and detailed step-by-step instructions to generate related segmentation masks are publicly available at https://www.kaggle.com/datasets/ipateam/nuinsseg and https://github.com/masih4/NuInsSeg, respectively.
</details>
<details>
<summary>摘要</summary>
在计算生物学中，自动核体实例分割扮演着整个扫描图像分析中的关键角色。虽然许多计算机化方法已经被提议用于这项任务，但是supervised深度学习（DL）方法在 segmentation 性能方面表现出色，比起经典机器学习和图像处理技术更为出色。然而，这些模型需要完全标注的数据集进行训练，这在医疗领域是困难的获得的。在这项工作中，我们发布了一个包含665个图像patches，共计超过30,000个手动标注的核体的全部扫描图像数据集，称为NuInsSeg。这个数据集包括31种人类和小鼠的组织。此外，我们还为整个数据集提供了首次的uncertain area masks。这些暧昧区域表示图像中的不确定和不可定量的部分，即even human experts无法 preciselly和准确地手动标注这些部分。数据集和相关的生成分 segmentation masks的详细步骤 instrucions都公开在https://www.kaggle.com/datasets/ipateam/nuinsseg和https://github.com/masih4/NuInsSeg中，分别。
</details></li>
</ul>
<hr>
<h2 id="Neural-Collapse-Terminus-A-Unified-Solution-for-Class-Incremental-Learning-and-Its-Variants"><a href="#Neural-Collapse-Terminus-A-Unified-Solution-for-Class-Incremental-Learning-and-Its-Variants" class="headerlink" title="Neural Collapse Terminus: A Unified Solution for Class Incremental Learning and Its Variants"></a>Neural Collapse Terminus: A Unified Solution for Class Incremental Learning and Its Variants</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01746">http://arxiv.org/abs/2308.01746</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/neuralcollapseapplications/unicil">https://github.com/neuralcollapseapplications/unicil</a></li>
<li>paper_authors: Yibo Yang, Haobo Yuan, Xiangtai Li, Jianlong Wu, Lefei Zhang, Zhouchen Lin, Philip Torr, Dacheng Tao, Bernard Ghanem</li>
<li>for:  Handle class incremental learning (CIL), long-tail class incremental learning (LTCIL), and few-shot class incremental learning (FSCIL) well.</li>
<li>methods: Propose a unified solution called neural collapse terminus, which is a fixed structure with the maximal equiangular inter-class separation for the whole label space. Also, propose a prototype evolving scheme to drive the backbone features into the neural collapse terminus smoothly.</li>
<li>results: The method is effective in all three tasks and can handle data imbalance and data scarcity. Theoretical analysis indicates that the method holds the neural collapse optimality in an incremental fashion. Extensive experiments with multiple datasets demonstrate the effectiveness of the unified solution and the generalized case.<details>
<summary>Abstract</summary>
How to enable learnability for new classes while keeping the capability well on old classes has been a crucial challenge for class incremental learning. Beyond the normal case, long-tail class incremental learning and few-shot class incremental learning are also proposed to consider the data imbalance and data scarcity, respectively, which are common in real-world implementations and further exacerbate the well-known problem of catastrophic forgetting. Existing methods are specifically proposed for one of the three tasks. In this paper, we offer a unified solution to the misalignment dilemma in the three tasks. Concretely, we propose neural collapse terminus that is a fixed structure with the maximal equiangular inter-class separation for the whole label space. It serves as a consistent target throughout the incremental training to avoid dividing the feature space incrementally. For CIL and LTCIL, we further propose a prototype evolving scheme to drive the backbone features into our neural collapse terminus smoothly. Our method also works for FSCIL with only minor adaptations. Theoretical analysis indicates that our method holds the neural collapse optimality in an incremental fashion regardless of data imbalance or data scarcity. We also design a generalized case where we do not know the total number of classes and whether the data distribution is normal, long-tail, or few-shot for each coming session, to test the generalizability of our method. Extensive experiments with multiple datasets are conducted to demonstrate the effectiveness of our unified solution to all the three tasks and the generalized case.
</details>
<details>
<summary>摘要</summary>
如何在新类增加时保持老类能力已成为增量学习中的关键挑战。此外，长尾类增量学习和少shot类增量学习也被提出来考虑数据偏好和数据稀缺问题，这些问题在实际应用中非常普遍并使得已知的忘记问题更加严重。现有的方法只适用于一种任务。在这篇论文中，我们提出了增量训练中的不一致问题的统一解决方案。具体来说，我们提出了一种固定结构的神经衰减终点，该结构具有整个标签空间中最大的等角间隔性。它在增量训练中作为一个固定目标，以避免在增量训练中逐渐将特征空间分割。对CIL和LTCIL，我们还提出了一种原型演化方案，以使得脊梁特征流动到我们的神经衰减终点的。我们的方法也适用于FSCIL，只需要一些小的适应。理论分析表明，我们的方法在增量训练中具有神经衰减优化的优点，不管数据不平衡或数据稀缺。我们还设计了一个通用情况，在每个来往会训练中，不知道总类数量和数据分布是正常、长尾或少shot，以测试我们的方法的普适性。我们进行了多个数据集的广泛实验，以证明我们的统一解决方案对所有三个任务和通用情况具有效果。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Visibility-in-Nighttime-Haze-Images-Using-Guided-APSF-and-Gradient-Adaptive-Convolution"><a href="#Enhancing-Visibility-in-Nighttime-Haze-Images-Using-Guided-APSF-and-Gradient-Adaptive-Convolution" class="headerlink" title="Enhancing Visibility in Nighttime Haze Images Using Guided APSF and Gradient Adaptive Convolution"></a>Enhancing Visibility in Nighttime Haze Images Using Guided APSF and Gradient Adaptive Convolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01738">http://arxiv.org/abs/2308.01738</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jinyeying/nighttime_dehaze">https://github.com/jinyeying/nighttime_dehaze</a></li>
<li>paper_authors: Yeying Jin, Beibei Lin, Wending Yan, Wei Ye, Yuan Yuan, Robby T. Tan</li>
<li>for: 提高夜间雾景的可见度，处理亮光和抑制雾气的影响。</li>
<li>methods: 利用灯源意识网络检测夜间图像中的灯光源，然后使用APSF指导的灯光渲染，以抑制雾光效果。同时，使用梯度适应卷积，捕捉雾景中的边缘和текстуures，以提高场景的对比度。最后，通过学习注意力映射，调整gamma修正，以增强低光强度区域的明暗对比。</li>
<li>results: 对实际夜间雾景图像进行了广泛的评估，并达到了30.38dB PSNR，比前方法提高13%。数据和代码可以在：\url{<a target="_blank" rel="noopener" href="https://github.com/jinyeying/nighttime_dehaze%7D%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/jinyeying/nighttime_dehaze}中找到。</a><details>
<summary>Abstract</summary>
Visibility in hazy nighttime scenes is frequently reduced by multiple factors, including low light, intense glow, light scattering, and the presence of multicolored light sources. Existing nighttime dehazing methods often struggle with handling glow or low-light conditions, resulting in either excessively dark visuals or unsuppressed glow outputs. In this paper, we enhance the visibility from a single nighttime haze image by suppressing glow and enhancing low-light regions. To handle glow effects, our framework learns from the rendered glow pairs. Specifically, a light source aware network is proposed to detect light sources of night images, followed by the APSF (Angular Point Spread Function)-guided glow rendering. Our framework is then trained on the rendered images, resulting in glow suppression. Moreover, we utilize gradient-adaptive convolution, to capture edges and textures in hazy scenes. By leveraging extracted edges and textures, we enhance the contrast of the scene without losing important structural details. To boost low-light intensity, our network learns an attention map, then adjusted by gamma correction. This attention has high values on low-light regions and low values on haze and glow regions. Extensive evaluation on real nighttime haze images, demonstrates the effectiveness of our method. Our experiments demonstrate that our method achieves a PSNR of 30.38dB, outperforming state-of-the-art methods by 13$\%$ on GTA5 nighttime haze dataset. Our data and code is available at: \url{https://github.com/jinyeying/nighttime_dehaze}.
</details>
<details>
<summary>摘要</summary>
夜间雾气场景中的可见度受多种因素影响，包括低光照、强烈辉光、光散射和多种颜色光源的存在。现有的夜间雾气去除方法 часто难以处理辉光效果，导致视觉效果过扭或辉光输出不充分抑制。在这篇论文中，我们通过抑制辉光和强化低光照区域来提高夜间雾气图像的可见度。为了处理辉光效果，我们的框架学习了夜间镜头中的灯光对。具体来说，我们提出了一个灯光意识网络，用于夜间镜头中灯光源的检测，然后使用APSF（ Ángular Point Spread Function）引导的辉光渲染。我们的框架然后在渲染图像上进行训练，从而实现辉光抑制。此外，我们利用梯度适应 convolution，以捕捉雾气场景中的边缘和文本ure。通过利用EXTRACTED edges和文本ure，我们可以提高场景的对比度，而不是失去重要的结构细节。为了增强低光照INTENSITY，我们的网络学习了注意力图，然后通过γcorrecting进行调整。这个注意力图在低光照区域有高值，而在雾气和辉光区域有低值。我们的实验表明，我们的方法可以在实际的夜间雾气图像上达到PSNR 30.38dB，比 estado-of-the-art 方法高出13%的GTA5夜间雾气数据集。我们的数据和代码可以在以下链接获取：https://github.com/jinyeying/nighttime_dehaze。
</details></li>
</ul>
<hr>
<h2 id="Quantification-of-Predictive-Uncertainty-via-Inference-Time-Sampling"><a href="#Quantification-of-Predictive-Uncertainty-via-Inference-Time-Sampling" class="headerlink" title="Quantification of Predictive Uncertainty via Inference-Time Sampling"></a>Quantification of Predictive Uncertainty via Inference-Time Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01731">http://arxiv.org/abs/2308.01731</a></li>
<li>repo_url: None</li>
<li>paper_authors: Katarína Tóthová, Ľubor Ladický, Daniel Thul, Marc Pollefeys, Ender Konukoglu</li>
<li>for: 这项研究的目的是提出一种post-hoc采样策略来估计预测不确定性，以考虑数据歧义导致的预测变化。</li>
<li>methods: 该方法不需要特定的建模Component或训练机制，可以应用于任何饱和推动网络，无需变更网络结构或训练过程。</li>
<li>results: 实验表明，该方法可以生成多种可能性 Distribution，与预测错误之间存在良好的相关性。<details>
<summary>Abstract</summary>
Predictive variability due to data ambiguities has typically been addressed via construction of dedicated models with built-in probabilistic capabilities that are trained to predict uncertainty estimates as variables of interest. These approaches require distinct architectural components and training mechanisms, may include restrictive assumptions and exhibit overconfidence, i.e., high confidence in imprecise predictions. In this work, we propose a post-hoc sampling strategy for estimating predictive uncertainty accounting for data ambiguity. The method can generate different plausible outputs for a given input and does not assume parametric forms of predictive distributions. It is architecture agnostic and can be applied to any feed-forward deterministic network without changes to the architecture or training procedure. Experiments on regression tasks on imaging and non-imaging input data show the method's ability to generate diverse and multi-modal predictive distributions, and a desirable correlation of the estimated uncertainty with the prediction error.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>通常，预测变化因数据抽象性而导致的预测不确定性通过建立专门的模型，这些模型具有内置的概率能力，并在预测不确定性为变量首选项进行训练。这些方法可能需要特殊的建筑Component和训练机制，可能包含限制性的假设和显示过自信，即高度自信准确性。在这种工作中，我们提出了一种 posterior sampling 策略，用于估计预测不确定性，考虑到数据抽象性。这种方法可以生成不同的可能的输出，并不假设预测分布的 Parametric 形式。它是架构无关的，可以应用于任何滤频决策网络，无需改变架构或训练过程。实验表明，这种方法可以生成多样化和多模态的预测分布，并且预测不确定性与预测错误之间存在可undesirable的相关性。
</details></li>
</ul>
<hr>
<h2 id="Weakly-Supervised-3D-Instance-Segmentation-without-Instance-level-Annotations"><a href="#Weakly-Supervised-3D-Instance-Segmentation-without-Instance-level-Annotations" class="headerlink" title="Weakly Supervised 3D Instance Segmentation without Instance-level Annotations"></a>Weakly Supervised 3D Instance Segmentation without Instance-level Annotations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01721">http://arxiv.org/abs/2308.01721</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shichao Dong, Guosheng Lin</li>
<li>for: 提高3D semanticScene理解任务的效率，减少人工标注成本。</li>
<li>methods: 提出首个弱级标注的3D实例分割方法，只需要分类semantic标签作为监督，不需要实例级标注。</li>
<li>results: 实验表明，我们的方法可以与最新的完全监督方法相当，同时可以帮助现有方法在减少标注成本的情况下学习3D实例分割。<details>
<summary>Abstract</summary>
3D semantic scene understanding tasks have achieved great success with the emergence of deep learning, but often require a huge amount of manually annotated training data. To alleviate the annotation cost, we propose the first weakly-supervised 3D instance segmentation method that only requires categorical semantic labels as supervision, and we do not need instance-level labels. The required semantic annotations can be either dense or extreme sparse (e.g. 0.02% of total points). Even without having any instance-related ground-truth, we design an approach to break point clouds into raw fragments and find the most confident samples for learning instance centroids. Furthermore, we construct a recomposed dataset using pseudo instances, which is used to learn our defined multilevel shape-aware objectness signal. An asymmetrical object inference algorithm is followed to process core points and boundary points with different strategies, and generate high-quality pseudo instance labels to guide iterative training. Experiments demonstrate that our method can achieve comparable results with recent fully supervised methods. By generating pseudo instance labels from categorical semantic labels, our designed approach can also assist existing methods for learning 3D instance segmentation at reduced annotation cost.
</details>
<details>
<summary>摘要</summary>
三维semantic场景理解任务在深度学习出现后取得了很大成功，但经常需要大量手动标注训练数据。为了减轻标注成本，我们提出了首个无监督的3D实例分割方法，只需要类别semantic标签作为监督，并不需要实例级别标签。需要的semantic标注可以是密集的或者极少的（例如0.02%的总点数）。即使没有实例相关的地面真实数据，我们还是可以将点云分解成原始碎片，并从最信任的样本中学习实例中心点。此外，我们还构建了一个pseudo实例集合，用于学习我们定义的多级形状感知信号。我们采用不对称的物体推断算法，处理核心点和边点的不同策略，生成高质量pseudo实例标签，以导引反复训练。实验表明，我们的方法可以与最近的完全监督方法相当。通过将pseudo实例标签生成自类别semantic标签，我们设计的方法还可以帮助现有的方法在减少标注成本的情况下学习3D实例分割。
</details></li>
</ul>
<hr>
<h2 id="Balanced-Destruction-Reconstruction-Dynamics-for-Memory-replay-Class-Incremental-Learning"><a href="#Balanced-Destruction-Reconstruction-Dynamics-for-Memory-replay-Class-Incremental-Learning" class="headerlink" title="Balanced Destruction-Reconstruction Dynamics for Memory-replay Class Incremental Learning"></a>Balanced Destruction-Reconstruction Dynamics for Memory-replay Class Incremental Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01698">http://arxiv.org/abs/2308.01698</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zyuh/bdr-main">https://github.com/zyuh/bdr-main</a></li>
<li>paper_authors: Yuhang Zhou, Jiangchao Yao, Feng Hong, Ya Zhang, Yanfeng Wang</li>
<li>For: 提高类增量学习（CIL）中的稳定性和泛化能力，通过平衡旧知识的destruction和重建来alleviate catastrophic forgetting。* Methods: 提出了一种Balanced Destruction-Reconstruction（BDR）模块，通过考虑不同类的训练状态的差异和存储库中样本的量不均衡来平衡旧知识的destruction和重建，从而提高知识重建的效果。* Results: 经验表明，作为轻量级插件，BDR模块可以大幅提高现有最佳方法的性能，并且具有良好的泛化能力。<details>
<summary>Abstract</summary>
Class incremental learning (CIL) aims to incrementally update a trained model with the new classes of samples (plasticity) while retaining previously learned ability (stability). To address the most challenging issue in this goal, i.e., catastrophic forgetting, the mainstream paradigm is memory-replay CIL, which consolidates old knowledge by replaying a small number of old classes of samples saved in the memory. Despite effectiveness, the inherent destruction-reconstruction dynamics in memory-replay CIL are an intrinsic limitation: if the old knowledge is severely destructed, it will be quite hard to reconstruct the lossless counterpart. Our theoretical analysis shows that the destruction of old knowledge can be effectively alleviated by balancing the contribution of samples from the current phase and those saved in the memory. Motivated by this theoretical finding, we propose a novel Balanced Destruction-Reconstruction module (BDR) for memory-replay CIL, which can achieve better knowledge reconstruction by reducing the degree of maximal destruction of old knowledge. Specifically, to achieve a better balance between old knowledge and new classes, the proposed BDR module takes into account two factors: the variance in training status across different classes and the quantity imbalance of samples from the current phase and memory. By dynamically manipulating the gradient during training based on these factors, BDR can effectively alleviate knowledge destruction and improve knowledge reconstruction. Extensive experiments on a range of CIL benchmarks have shown that as a lightweight plug-and-play module, BDR can significantly improve the performance of existing state-of-the-art methods with good generalization.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="BEVControl-Accurately-Controlling-Street-view-Elements-with-Multi-perspective-Consistency-via-BEV-Sketch-Layout"><a href="#BEVControl-Accurately-Controlling-Street-view-Elements-with-Multi-perspective-Consistency-via-BEV-Sketch-Layout" class="headerlink" title="BEVControl: Accurately Controlling Street-view Elements with Multi-perspective Consistency via BEV Sketch Layout"></a>BEVControl: Accurately Controlling Street-view Elements with Multi-perspective Consistency via BEV Sketch Layout</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01661">http://arxiv.org/abs/2308.01661</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kairui Yang, Enhui Ma, Jibin Peng, Qing Guo, Di Lin, Kaicheng Yu</li>
<li>for: 提高计算机视觉系统中的识别模型性能，使用生成图像来增强模型的表现。</li>
<li>methods: 提出了一种两stage生成方法，名为BEVControl，可以生成准确的前景和背景内容。此外，还支持绘制风格输入，让人们更方便地编辑。</li>
<li>results: 对比BEVGen方法，BEVControl在前景分割mIoU中提高了5.89到26.80的margin，而且用生成图像来训练下游识别模型，其NDS分数平均提高1.29。<details>
<summary>Abstract</summary>
Using synthesized images to boost the performance of perception models is a long-standing research challenge in computer vision. It becomes more eminent in visual-centric autonomous driving systems with multi-view cameras as some long-tail scenarios can never be collected. Guided by the BEV segmentation layouts, the existing generative networks seem to synthesize photo-realistic street-view images when evaluated solely on scene-level metrics. However, once zoom-in, they usually fail to produce accurate foreground and background details such as heading. To this end, we propose a two-stage generative method, dubbed BEVControl, that can generate accurate foreground and background contents. In contrast to segmentation-like input, it also supports sketch style input, which is more flexible for humans to edit. In addition, we propose a comprehensive multi-level evaluation protocol to fairly compare the quality of the generated scene, foreground object, and background geometry. Our extensive experiments show that our BEVControl surpasses the state-of-the-art method, BEVGen, by a significant margin, from 5.89 to 26.80 on foreground segmentation mIoU. In addition, we show that using images generated by BEVControl to train the downstream perception model, it achieves on average 1.29 improvement in NDS score.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="DiffColor-Toward-High-Fidelity-Text-Guided-Image-Colorization-with-Diffusion-Models"><a href="#DiffColor-Toward-High-Fidelity-Text-Guided-Image-Colorization-with-Diffusion-Models" class="headerlink" title="DiffColor: Toward High Fidelity Text-Guided Image Colorization with Diffusion Models"></a>DiffColor: Toward High Fidelity Text-Guided Image Colorization with Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01655">http://arxiv.org/abs/2308.01655</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianxin Lin, Peng Xiao, Yijun Wang, Rongju Zhang, Xiangxiang Zeng</li>
<li>for: 提高自动或参照基于的图像颜色化精度和多样性，尤其是对象级颜色控制。</li>
<li>methods: 基于预训练扩散模型，提出一种名为DiffColor的新方法，通过使用提前训练的文本到图像模型，生成基于文本提示的颜色化图像，不需任何其他输入。DiffColor方法包括两个阶段：颜色化与生成颜色先前，以及在文本引导下可控色化。</li>
<li>results: DiffColor方法可以在几轮 iterations 中生成真实和多样的颜色，保持图像结构和背景不变，同时将颜色与目标语言指导相吻合。此外，DiffColor方法允许在文本引导下进行卷积控制，即通过修改提示文本来生成不同的颜色化结果，而无需任何 fine-tuning。广泛的实验和用户研究表明，DiffColor方法在视觉质量、颜色准确性和颜色化选项多样性方面，超越了先前的works。<details>
<summary>Abstract</summary>
Recent data-driven image colorization methods have enabled automatic or reference-based colorization, while still suffering from unsatisfactory and inaccurate object-level color control. To address these issues, we propose a new method called DiffColor that leverages the power of pre-trained diffusion models to recover vivid colors conditioned on a prompt text, without any additional inputs. DiffColor mainly contains two stages: colorization with generative color prior and in-context controllable colorization. Specifically, we first fine-tune a pre-trained text-to-image model to generate colorized images using a CLIP-based contrastive loss. Then we try to obtain an optimized text embedding aligning the colorized image and the text prompt, and a fine-tuned diffusion model enabling high-quality image reconstruction. Our method can produce vivid and diverse colors with a few iterations, and keep the structure and background intact while having colors well-aligned with the target language guidance. Moreover, our method allows for in-context colorization, i.e., producing different colorization results by modifying prompt texts without any fine-tuning, and can achieve object-level controllable colorization results. Extensive experiments and user studies demonstrate that DiffColor outperforms previous works in terms of visual quality, color fidelity, and diversity of colorization options.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multi-scale-Cross-restoration-Framework-for-Electrocardiogram-Anomaly-Detection"><a href="#Multi-scale-Cross-restoration-Framework-for-Electrocardiogram-Anomaly-Detection" class="headerlink" title="Multi-scale Cross-restoration Framework for Electrocardiogram Anomaly Detection"></a>Multi-scale Cross-restoration Framework for Electrocardiogram Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01639">http://arxiv.org/abs/2308.01639</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mediabrain-sjtu/ecgad">https://github.com/mediabrain-sjtu/ecgad</a></li>
<li>paper_authors: Aofan Jiang, Chaoqin Huang, Qing Cao, Shuang Wu, Zi Zeng, Kang Chen, Ya Zhang, Yanfeng Wang</li>
<li>for: 该论文旨在提高电cardiogram（ECG）诊断工具的敏感度，以检测心脏疾病。</li>
<li>methods: 该论文提出了一种基于异常检测的ECG anomaly detection和本地化方法，通过对全息ECG和心跳级别特征进行多级混合还原，以提高检测异常的精度。</li>
<li>results: 该论文在一个新的 benchmark 数据集上达到了当前领域的状态的表现，并在两个其他常用的ECG数据集上也显示出了优秀的表现。<details>
<summary>Abstract</summary>
Electrocardiogram (ECG) is a widely used diagnostic tool for detecting heart conditions. Rare cardiac diseases may be underdiagnosed using traditional ECG analysis, considering that no training dataset can exhaust all possible cardiac disorders. This paper proposes using anomaly detection to identify any unhealthy status, with normal ECGs solely for training. However, detecting anomalies in ECG can be challenging due to significant inter-individual differences and anomalies present in both global rhythm and local morphology. To address this challenge, this paper introduces a novel multi-scale cross-restoration framework for ECG anomaly detection and localization that considers both local and global ECG characteristics. The proposed framework employs a two-branch autoencoder to facilitate multi-scale feature learning through a masking and restoration process, with one branch focusing on global features from the entire ECG and the other on local features from heartbeat-level details, mimicking the diagnostic process of cardiologists. Anomalies are identified by their high restoration errors. To evaluate the performance on a large number of individuals, this paper introduces a new challenging benchmark with signal point-level ground truths annotated by experienced cardiologists. The proposed method demonstrates state-of-the-art performance on this benchmark and two other well-known ECG datasets. The benchmark dataset and source code are available at: \url{https://github.com/MediaBrain-SJTU/ECGAD}
</details>
<details>
<summary>摘要</summary>
电心agram（ECG）是一种广泛使用的诊断工具，用于检测心脏疾病。但是，有些罕见的心脏疾病可能会被传统的ECG分析错过，因为没有一个可以包含所有可能的心脏疾病的训练数据集。这篇论文提出使用异常检测来识别任何不健康状态，只使用正常的ECG进行训练。然而，检测ECG中的异常可以是困难的，因为心脏电压的变化会导致巨大的个体差异和异常现象。为解决这个挑战，这篇论文提出了一种新的多尺度跨 restore 框架，用于ECG异常检测和定位。该框架利用两个分支自动编码器来实现多尺度特征学习，其中一个分支关注整个ECG的全局特征，另一个分支关注心跳级别细节。异常被标识为高 restore 错误。为评估性能，这篇论文创建了一个新的挑战性的标准数据集，其中每个信号点都有经验论断医生的地面真实值。提出的方法在这个标准数据集上达到了状态艺术性的性能，并在两个常见的ECG数据集上也取得了优秀的成绩。标准数据集和源代码可以在：\url{https://github.com/MediaBrain-SJTU/ECGAD} 获取。
</details></li>
</ul>
<hr>
<h2 id="Disentangling-Multi-view-Representations-Beyond-Inductive-Bias"><a href="#Disentangling-Multi-view-Representations-Beyond-Inductive-Bias" class="headerlink" title="Disentangling Multi-view Representations Beyond Inductive Bias"></a>Disentangling Multi-view Representations Beyond Inductive Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01634">http://arxiv.org/abs/2308.01634</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/guanzhou-ke/dmrib">https://github.com/guanzhou-ke/dmrib</a></li>
<li>paper_authors: Guanzhou Ke, Yang Yu, Guoqing Chao, Xiaoli Wang, Chenyang Xu, Shengfeng He</li>
<li>For: The paper is written for proposing a novel multi-view representation disentangling method that can go beyond inductive biases and ensure both interpretability and generalizability of the resulting representations.* Methods: The proposed method is based on discovering multi-view consistency in advance, which determines the disentangling information boundary, and maximizing transformation invariance and clustering consistency between views. The method consists of two stages: obtaining multi-view consistency by training a consistent encoder, and disentangling specificity from comprehensive representations by minimizing the upper bound of mutual information.* Results: The proposed method outperforms 12 comparison methods in terms of clustering and classification performance on four multi-view datasets, and the extracted consistency and specificity are compact and interpretable.<details>
<summary>Abstract</summary>
Multi-view (or -modality) representation learning aims to understand the relationships between different view representations. Existing methods disentangle multi-view representations into consistent and view-specific representations by introducing strong inductive biases, which can limit their generalization ability. In this paper, we propose a novel multi-view representation disentangling method that aims to go beyond inductive biases, ensuring both interpretability and generalizability of the resulting representations. Our method is based on the observation that discovering multi-view consistency in advance can determine the disentangling information boundary, leading to a decoupled learning objective. We also found that the consistency can be easily extracted by maximizing the transformation invariance and clustering consistency between views. These observations drive us to propose a two-stage framework. In the first stage, we obtain multi-view consistency by training a consistent encoder to produce semantically-consistent representations across views as well as their corresponding pseudo-labels. In the second stage, we disentangle specificity from comprehensive representations by minimizing the upper bound of mutual information between consistent and comprehensive representations. Finally, we reconstruct the original data by concatenating pseudo-labels and view-specific representations. Our experiments on four multi-view datasets demonstrate that our proposed method outperforms 12 comparison methods in terms of clustering and classification performance. The visualization results also show that the extracted consistency and specificity are compact and interpretable. Our code can be found at \url{https://github.com/Guanzhou-Ke/DMRIB}.
</details>
<details>
<summary>摘要</summary>
多视图（或多modal）表示学习目标是理解不同视图表示之间的关系。现有方法通过引入强大的概念假设来分离多视图表示，但这可能会限制其泛化能力。在这篇论文中，我们提出了一种新的多视图表示分离方法，旨在超越假设，以确保表示的解释性和泛化性。我们的方法基于发现多视图一致性在前提下可以确定分离信息边界，从而导致一个分离学习目标。我们还发现可以通过最大化变换不变性和视图集成一致性来提取一致性。这些发现驱动我们提出了一个两stage框架。在第一阶段，我们通过训练一个具有相同含义的编码器来生成多视图中的含义相同的表示，以及其相对应的pseudo标签。在第二阶段，我们通过最小化表示之间的上界乘积来分离特定的表示和总体表示之间的相互信息。最后，我们使用pseudo标签和视图特定表示来重建原始数据。我们的实验表明，我们的提出的方法在四个多视图数据集上比12种参考方法表现出色，并且可以准确地重建原始数据。visual化结果还表明提取的一致性和特定性具有 компакт性和可读性。我们的代码可以在GitHub上找到：\url{https://github.com/Guanzhou-Ke/DMRIB}。
</details></li>
</ul>
<hr>
<h2 id="Erasure-based-Interaction-Network-for-RGBT-Video-Object-Detection-and-A-Unified-Benchmark"><a href="#Erasure-based-Interaction-Network-for-RGBT-Video-Object-Detection-and-A-Unified-Benchmark" class="headerlink" title="Erasure-based Interaction Network for RGBT Video Object Detection and A Unified Benchmark"></a>Erasure-based Interaction Network for RGBT Video Object Detection and A Unified Benchmark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01630">http://arxiv.org/abs/2308.01630</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengzheng Tu, Qishun Wang, Hongshun Wang, Kunpeng Wang, Chenglong Li</li>
<li>for: 提高视频对象检测（VOD）性能在不利照条件下，通过引入热模态，抗衰落和降低计算复杂度。</li>
<li>methods: 提出了一种新的计算机视IONTask called RGB-thermal（RGBT）VOD，并设计了一个名为EINet的新网络模型，以及一个包含50对复杂背景、多种物体和不同照明条件的VT-VOD50数据集。</li>
<li>results: 对VT-VOD50数据集进行了广泛的实验，证明了我们提posed方法的效果和效率，并且与现有主流VOD方法进行了比较。<details>
<summary>Abstract</summary>
Recently, many breakthroughs are made in the field of Video Object Detection (VOD), but the performance is still limited due to the imaging limitations of RGB sensors in adverse illumination conditions. To alleviate this issue, this work introduces a new computer vision task called RGB-thermal (RGBT) VOD by introducing the thermal modality that is insensitive to adverse illumination conditions. To promote the research and development of RGBT VOD, we design a novel Erasure-based Interaction Network (EINet) and establish a comprehensive benchmark dataset (VT-VOD50) for this task. Traditional VOD methods often leverage temporal information by using many auxiliary frames, and thus have large computational burden. Considering that thermal images exhibit less noise than RGB ones, we develop a negative activation function that is used to erase the noise of RGB features with the help of thermal image features. Furthermore, with the benefits from thermal images, we rely only on a small temporal window to model the spatio-temporal information to greatly improve efficiency while maintaining detection accuracy.   VT-VOD50 dataset consists of 50 pairs of challenging RGBT video sequences with complex backgrounds, various objects and different illuminations, which are collected in real traffic scenarios. Extensive experiments on VT-VOD50 dataset demonstrate the effectiveness and efficiency of our proposed method against existing mainstream VOD methods. The code of EINet and the dataset will be released to the public for free academic usage.
</details>
<details>
<summary>摘要</summary>
近些时间，在视频对象检测（VOD）领域内，有很多突破性的进展，但性能仍然受到RGB感知器的不利照明条件的限制。为了解决这个问题，这项工作引入了一个新的计算机视觉任务，即RGB-热（RGBT）VOD，通过引入热特征来减少不利照明条件的影响。为促进RGBT VOD的研究和开发，我们设计了一种新的擦除基本网络（EINet）和建立了一个完整的benchmark数据集（VT-VOD50）。传统的VOD方法通常利用多个auxiliary帧的时间信息，因此具有大的计算负担。由于热图像比RGB图像具有更少的噪声，我们开发了一种负活动函数，用于擦除RGB特征图像中的噪声，并且利用热图像特征来减少计算负担。此外，通过利用热图像的优点，我们只需要使用小的时间窗口来模型空间-时间信息，以提高效率而无需牺牲检测精度。VT-VOD50数据集包含50对复杂背景、多种物体和不同照明条件的RGBT视频序列，通过实际的交通enario进行收集。我们在VT-VOD50数据集上进行了广泛的实验，证明了我们提出的方法在现有主流VOD方法的比较中表现出色，同时具有高效率。我们将EINet和数据集发布到公共平台，免费用于学术研究。
</details></li>
</ul>
<hr>
<h2 id="A-Multidimensional-Analysis-of-Social-Biases-in-Vision-Transformers"><a href="#A-Multidimensional-Analysis-of-Social-Biases-in-Vision-Transformers" class="headerlink" title="A Multidimensional Analysis of Social Biases in Vision Transformers"></a>A Multidimensional Analysis of Social Biases in Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01948">http://arxiv.org/abs/2308.01948</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jannik-brinkmann/social-biases-in-vision-transformers">https://github.com/jannik-brinkmann/social-biases-in-vision-transformers</a></li>
<li>paper_authors: Jannik Brinkmann, Paul Swoboda, Christian Bartelt</li>
<li>for: 研究卷积Transformers（ViT）中存在的社会偏见。</li>
<li>methods: 测试数据、模型架构和训练目标对ViT中学习的表示中的社会偏见的影响。</li>
<li>results: 使用对 diffusion-based image editing进行 counterfactual augmentation 训练可以减少社会偏见，但不能完全消除其他偏见。大型模型比小型模型更少偏见，使用激发jective objectives 训练的模型也比使用生成jective objectives 训练的模型更少偏见。同一个数据集上使用不同的自然语言目标可能导致ViT中学习的社会偏见发生相反的偏见。这些发现可以帮助我们更好地理解社会偏见的起源，并提供改进公平性的方法。<details>
<summary>Abstract</summary>
The embedding spaces of image models have been shown to encode a range of social biases such as racism and sexism. Here, we investigate specific factors that contribute to the emergence of these biases in Vision Transformers (ViT). Therefore, we measure the impact of training data, model architecture, and training objectives on social biases in the learned representations of ViTs. Our findings indicate that counterfactual augmentation training using diffusion-based image editing can mitigate biases, but does not eliminate them. Moreover, we find that larger models are less biased than smaller models, and that models trained using discriminative objectives are less biased than those trained using generative objectives. In addition, we observe inconsistencies in the learned social biases. To our surprise, ViTs can exhibit opposite biases when trained on the same data set using different self-supervised objectives. Our findings give insights into the factors that contribute to the emergence of social biases and suggests that we could achieve substantial fairness improvements based on model design choices.
</details>
<details>
<summary>摘要</summary>
“图像模型的嵌入空间已经显示出许多社会偏见，如种族主义和性别歧视。在这里，我们调查了视Transformer（ViT）中这些偏见的起源。因此，我们测量了训练数据、模型结构和训练目标对图像模型学习的社会偏见的影响。我们的发现表明，通过对 diffusion-based image editing 进行 counterfactual augmentation 训练可以减轻偏见，但并不能完全消除它们。此外，我们发现大型模型比小型模型更少表现社会偏见，并且使用推导性目标进行训练的模型比使用生成性目标进行训练的模型更少表现社会偏见。此外，我们发现图像模型学习的社会偏见存在不一致性。对于同一个数据集，使用不同的自然语言目标可以使图像模型表现出相反的偏见。我们的发现可以帮助我们更好地理解社会偏见的起源，并且表明我们可以通过模型设计选择来实现显著的公平性改进。”
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Convolutional-Neural-Network-Architecture-with-a-Continuous-Symmetry"><a href="#A-Novel-Convolutional-Neural-Network-Architecture-with-a-Continuous-Symmetry" class="headerlink" title="A Novel Convolutional Neural Network Architecture with a Continuous Symmetry"></a>A Novel Convolutional Neural Network Architecture with a Continuous Symmetry</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01621">http://arxiv.org/abs/2308.01621</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liuyao12/ConvNets-PDE-perspective">https://github.com/liuyao12/ConvNets-PDE-perspective</a></li>
<li>paper_authors: Yao Liu, Hang Shao, Bing Bai</li>
<li>for: 这篇论文探讨了一种基于偏微分方程（PDE）的卷积神经网络架构（ConvNet），并实现了这种架构在图像识别任务上的比较性表现。</li>
<li>methods: 这篇论文使用了一种具有组合性的卷积神经网络架构，并运用了一种称为“对称性”的概念，允许权重的调整via一个连续的群集。</li>
<li>results: 这篇论文的结果显示，这种卷积神经网络架构可以在图像识别任务上实现比较性的表现，并且具有一定的内部对称性。<details>
<summary>Abstract</summary>
This paper introduces a new Convolutional Neural Network (ConvNet) architecture inspired by a class of partial differential equations (PDEs) called quasi-linear hyperbolic systems. With comparable performance on the image classification task, it allows for the modification of the weights via a continuous group of symmetry. This is a significant shift from traditional models where the architecture and weights are essentially fixed. We wish to promote the (internal) symmetry as a new desirable property for a neural network, and to draw attention to the PDE perspective in analyzing and interpreting ConvNets in the broader Deep Learning community.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation note: "quasi-linear hyperbolic systems" is translated as "幂线抽象系统", and "ConvNet" is translated as "卷积神经网络".)
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Deep-Learning-based-Spatio-temporal-Action-Detection"><a href="#A-Survey-on-Deep-Learning-based-Spatio-temporal-Action-Detection" class="headerlink" title="A Survey on Deep Learning-based Spatio-temporal Action Detection"></a>A Survey on Deep Learning-based Spatio-temporal Action Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01618">http://arxiv.org/abs/2308.01618</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Wang, Fanwei Zeng, Yuntao Qian</li>
<li>for: 本研究概述了深度学习方法在视觉中的动作检测和定位问题，包括动作检测、动作识别和动作位置定位等方面。</li>
<li>methods: 本文提出了一种分类和组织深度学习方法的稠密概念框架，并详细介绍了链接算法，以将帧或剪辑级别的检测结果相互链接成为动作管道。</li>
<li>results: 本文对当前领域的深度学习方法进行了全面的回顾，并对常用的测试数据集和评价指标进行了介绍。最后，本文结束并提出了一些可能的未来研究方向。<details>
<summary>Abstract</summary>
Spatio-temporal action detection (STAD) aims to classify the actions present in a video and localize them in space and time. It has become a particularly active area of research in computer vision because of its explosively emerging real-world applications, such as autonomous driving, visual surveillance, entertainment, etc. Many efforts have been devoted in recent years to building a robust and effective framework for STAD. This paper provides a comprehensive review of the state-of-the-art deep learning-based methods for STAD. Firstly, a taxonomy is developed to organize these methods. Next, the linking algorithms, which aim to associate the frame- or clip-level detection results together to form action tubes, are reviewed. Then, the commonly used benchmark datasets and evaluation metrics are introduced, and the performance of state-of-the-art models is compared. At last, this paper is concluded, and a set of potential research directions of STAD are discussed.
</details>
<details>
<summary>摘要</summary>
空间时间动作检测（STAD）目标是在视频中分类并地理化动作的存在。它在计算机视觉领域已经成为非常活跃的研究领域，因为它在自动驾驶、视觉监测、娱乐等实际应用中具有爆炸性突出来的应用前景。多年来，许多努力投入于建立一个可靠有效的STAD框架。本文提供了深度学习基础的state-of-the-art方法的完整回顾。首先，一个分类器是开发出一个分类器，以便组织这些方法。接下来，链接算法，它们的目标是将帧或clip级别的检测结果相互链接，以形成动作管道，被评估。然后，通用的标准数据集和评估指标被介绍，并将现状的状态模型的性能比较。最后，本文结束，并对STAD的未来研究方向进行了讨论。
</details></li>
</ul>
<hr>
<h2 id="Real-time-Light-Estimation-and-Neural-Soft-Shadows-for-AR-Indoor-Scenarios"><a href="#Real-time-Light-Estimation-and-Neural-Soft-Shadows-for-AR-Indoor-Scenarios" class="headerlink" title="Real-time Light Estimation and Neural Soft Shadows for AR Indoor Scenarios"></a>Real-time Light Estimation and Neural Soft Shadows for AR Indoor Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01613">http://arxiv.org/abs/2308.01613</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexander Sommer, Ulrich Schwanecke, Elmar Schömer</li>
<li>for: 这个论文旨在提供一种用于实时AR应用程序中真实嵌入虚拟对象的渲染管道。</li>
<li>methods: 该管道包括两个主要组成部分：一个深度神经网络基于的光估计和一个神经软阴影生成器。光估计根据深度神经网络来确定主要光向、光色、 ambient色和阴影Texture中的透明度参数。软阴影方法将对象基于的真实软阴影编码为光向依赖的Texture。</li>
<li>results: 我们的管道可以在实时AR场景中新一个水平的真实性来插入对象。我们的模型够小以跑在当前的移动设备上。我们在iPhone 11 Pro上达到了9ms的光估计时间和5ms的神经软阴影时间。<details>
<summary>Abstract</summary>
We present a pipeline for realistic embedding of virtual objects into footage of indoor scenes with focus on real-time AR applications. Our pipeline consists of two main components: A light estimator and a neural soft shadow texture generator. Our light estimation is based on deep neural nets and determines the main light direction, light color, ambient color and an opacity parameter for the shadow texture. Our neural soft shadow method encodes object-based realistic soft shadows as light direction dependent textures in a small MLP. We show that our pipeline can be used to integrate objects into AR scenes in a new level of realism in real-time. Our models are small enough to run on current mobile devices. We achieve runtimes of 9ms for light estimation and 5ms for neural shadows on an iPhone 11 Pro.
</details>
<details>
<summary>摘要</summary>
我们提出了一个管道，用于在室内场景视频中真实嵌入虚拟对象，特别是针对实时AR应用。我们的管道包括两个主要组成部分：光估计和神经软影Texture生成器。我们的光估计基于深度神经网络，确定主要光方向、光色、 ambient色和阴影Texture中的opacity参数。我们的神经软影方法将对象基于实际的软阴影编码为光方向依赖的文本ures在小型MLP中。我们显示，我们的管道可以在实时AR场景中嵌入对象到新的真实水平，并且可以在当前的移动设备上运行。我们的模型够小，在iPhone 11 Pro上达到9毫秒的运行时间和5毫秒的神经阴影时间。
</details></li>
</ul>
<hr>
<h2 id="IndoHerb-Indonesia-Medicinal-Plants-Recognition-using-Transfer-Learning-and-Deep-Learning"><a href="#IndoHerb-Indonesia-Medicinal-Plants-Recognition-using-Transfer-Learning-and-Deep-Learning" class="headerlink" title="IndoHerb: Indonesia Medicinal Plants Recognition using Transfer Learning and Deep Learning"></a>IndoHerb: Indonesia Medicinal Plants Recognition using Transfer Learning and Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01604">http://arxiv.org/abs/2308.01604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Salman Ikrar Musyaffa, Novanto Yudistira, Muhammad Arif Rahman</li>
<li>for: 这个研究旨在使用计算机视觉技术来识别INDONESIA的药用植物。</li>
<li>methods: 该研究使用了转移学习法从Convolutional Neural Network（CNN）算法来分类INDONESIA的药用植物。数据采集自INDONESIA独立地通过Google图像搜索引擎，然后进行数据处理并进行分类。</li>
<li>results: 测试结果显示，使用DenseNet121模型可以达到87.4%的准确率，而使用零基eline模型可以达到43.53%的准确率。<details>
<summary>Abstract</summary>
Herbal plants are nutritious plants that can be used as an alternative to traditional disease healing. In Indonesia there are various types of herbal plants. But with the development of the times, the existence of herbal plants as traditional medicines began to be forgotten so that not everyone could recognize them. Having the ability to identify herbal plants can have many positive impacts. However, there is a problem where identifying plants can take a long time because it requires in-depth knowledge and careful examination of plant criteria. So that the application of computer vision can help identify herbal plants. Previously, research had been conducted on the introduction of herbal plants from Vietnam using several algorithms, but from these research the accuracy was not high enough. Therefore, this study intends to implement transfer learning from the Convolutional Neural Network (CNN) algorithm to classify types of herbal plants from Indonesia. This research was conducted by collecting image data of herbal plants from Indonesia independently through the Google Images search engine. After that, it will go through the data preprocessing, classification using the transfer learning method from CNN, and analysis will be carried out. The CNN transfer learning models used are ResNet34, DenseNet121, and VGG11_bn. Based on the test results of the three models, it was found that DenseNet121 was the model with the highest accuracy, which was 87.4%. In addition, testing was also carried out using the scratch model and obtained an accuracy of 43.53%. The Hyperparameter configuration used in this test is the ExponentialLR scheduler with a gamma value of 0.9; learning rate 0.001; Cross Entropy Loss function; Adam optimizer; and the number of epochs is 50. Indonesia Medicinal Plant Dataset can be accessed at the following link https://github.com/Salmanim20/indo_medicinal_plant
</details>
<details>
<summary>摘要</summary>
药用植物是一种有营养价值的植物，可以作为传统疾病的替代疗法。在印度尼西亚有很多种类的药用植物，但随着时代的发展，药用植物作为传统药物的存在开始被忘记，因此不 everybody都能认得它们。能够识别药用植物可以有很多积极影响。然而，识别植物可以耗费很长时间，因为它需要深入的知识和仔细的植物标准的检查。因此，计算机视觉的应用可以帮助识别药用植物。在过去的研究中，有些算法在印度尼西亚 introducing herbal plants from Vietnam，但这些研究的准确率不够高。因此，这项研究打算通过传输学习法，使用Convolutional Neural Network（CNN）算法来类型印度尼西亚的药用植物。这项研究通过独立地收集印度尼西亚药用植物的图像数据，并进行数据处理、类型确定和分析。测试结果显示，DenseNet121模型的准确率为87.4%，而自适应模型的准确率为43.53%。Hyperparameter配置使用ExponentialLR学习策略，γ值为0.9，学习率为0.001，交叉熵损失函数，Adam优化器，训练集数为50。印度尼西亚药用植物数据集可以在以下链接中获取：https://github.com/Salmanim20/indo_medicinal_plant。
</details></li>
</ul>
<hr>
<h2 id="Reference-Free-Isotropic-3D-EM-Reconstruction-using-Diffusion-Models"><a href="#Reference-Free-Isotropic-3D-EM-Reconstruction-using-Diffusion-Models" class="headerlink" title="Reference-Free Isotropic 3D EM Reconstruction using Diffusion Models"></a>Reference-Free Isotropic 3D EM Reconstruction using Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01594">http://arxiv.org/abs/2308.01594</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kyungryun Lee, Won-Ki Jeong</li>
<li>for: 这个论文是为了解决电子顾微显微镜像中的不均匀分辨率问题，提高分析和下游任务的精度和效率。</li>
<li>methods: 这个方法基于 diffusion 模型，可以不需要参考数据或先知信息来重建3DVolume。它适用于高度下采样的数据，并且在实验中表现出了对比supervised learning方法的优势和稳定性。</li>
<li>results: 该方法可以自动恢复单个不均匀的Volume，无需任何训练数据。此外， authors 还进行了大量的实验，证明了该方法在两个公共数据集上的robustness和可靠性。<details>
<summary>Abstract</summary>
Electron microscopy (EM) images exhibit anisotropic axial resolution due to the characteristics inherent to the imaging modality, presenting challenges in analysis and downstream tasks.In this paper, we propose a diffusion-model-based framework that overcomes the limitations of requiring reference data or prior knowledge about the degradation process. Our approach utilizes 2D diffusion models to consistently reconstruct 3D volumes and is well-suited for highly downsampled data. Extensive experiments conducted on two public datasets demonstrate the robustness and superiority of leveraging the generative prior compared to supervised learning methods. Additionally, we demonstrate our method's feasibility for self-supervised reconstruction, which can restore a single anisotropic volume without any training data.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Consistency-Regularization-for-Generalizable-Source-free-Domain-Adaptation"><a href="#Consistency-Regularization-for-Generalizable-Source-free-Domain-Adaptation" class="headerlink" title="Consistency Regularization for Generalizable Source-free Domain Adaptation"></a>Consistency Regularization for Generalizable Source-free Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01587">http://arxiv.org/abs/2308.01587</a></li>
<li>repo_url: None</li>
<li>paper_authors: Longxiang Tang, Kai Li, Chunming He, Yulun Zhang, Xiu Li</li>
<li>for: 这个论文目的是为了源自由预测项目（SFDA），将已经训练好的源模型适应到无标注目标频道，并且不需要存取源数据集，这使得它在实际中的应用非常广泛。</li>
<li>methods: 我们提出了一个对称正规化框架，以发展一个更加普遍化的 SFDA 方法，这个方法同时将模型在目标训练和测试数据集上的表现提高。我们利用弱地调整的图像生成软件标签，将强地调整的图像标签作为模型训练的指导方向，以便增强模型的普遍化能力。此外，我们还提出了一个抽样 Pseudo-label 选择策略，选择具有更大频率差的标签，以获取更多的可能用的超vision。最后，我们引入了全球方向的均衡化方法，以利用全球类别分布和特征单元信息，进一步改善适应过程。</li>
<li>results: 我们的方法在多个 SFDA 标准库上进行了广泛的实验，结果显示我们的方法可以在不存取源数据集的情况下，实现源自由预测项目的高性能和普遍化能力。此外，我们的方法还能够在无法见测试数据集上保持高度的稳定性和可靠性。<details>
<summary>Abstract</summary>
Source-free domain adaptation (SFDA) aims to adapt a well-trained source model to an unlabelled target domain without accessing the source dataset, making it applicable in a variety of real-world scenarios. Existing SFDA methods ONLY assess their adapted models on the target training set, neglecting the data from unseen but identically distributed testing sets. This oversight leads to overfitting issues and constrains the model's generalization ability. In this paper, we propose a consistency regularization framework to develop a more generalizable SFDA method, which simultaneously boosts model performance on both target training and testing datasets. Our method leverages soft pseudo-labels generated from weakly augmented images to supervise strongly augmented images, facilitating the model training process and enhancing the generalization ability of the adapted model. To leverage more potentially useful supervision, we present a sampling-based pseudo-label selection strategy, taking samples with severer domain shift into consideration. Moreover, global-oriented calibration methods are introduced to exploit global class distribution and feature cluster information, further improving the adaptation process. Extensive experiments demonstrate our method achieves state-of-the-art performance on several SFDA benchmarks, and exhibits robustness on unseen testing datasets.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MVFlow-Deep-Optical-Flow-Estimation-of-Compressed-Videos-with-Motion-Vector-Prior"><a href="#MVFlow-Deep-Optical-Flow-Estimation-of-Compressed-Videos-with-Motion-Vector-Prior" class="headerlink" title="MVFlow: Deep Optical Flow Estimation of Compressed Videos with Motion Vector Prior"></a>MVFlow: Deep Optical Flow Estimation of Compressed Videos with Motion Vector Prior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01568">http://arxiv.org/abs/2308.01568</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shili Zhou, Xuhao Jiang, Weimin Tan, Ruian He, Bo Yan</li>
<li>for: 这个论文是为了提高压缩视频中的光学流估算的速度和准确性而提出的。</li>
<li>methods: 该论文使用了动态模型，并将动态信息与视频压缩信息结合使用，以提高光学流估算的准确性和速度。</li>
<li>results: 实验结果表明，相比于现有模型，该论文提出的MVFlow模型可以降低AEPE值1.09，或者保持与现有模型相同的准确性，而且可以节省52%的计算时间。<details>
<summary>Abstract</summary>
In recent years, many deep learning-based methods have been proposed to tackle the problem of optical flow estimation and achieved promising results. However, they hardly consider that most videos are compressed and thus ignore the pre-computed information in compressed video streams. Motion vectors, one of the compression information, record the motion of the video frames. They can be directly extracted from the compression code stream without computational cost and serve as a solid prior for optical flow estimation. Therefore, we propose an optical flow model, MVFlow, which uses motion vectors to improve the speed and accuracy of optical flow estimation for compressed videos. In detail, MVFlow includes a key Motion-Vector Converting Module, which ensures that the motion vectors can be transformed into the same domain of optical flow and then be utilized fully by the flow estimation module. Meanwhile, we construct four optical flow datasets for compressed videos containing frames and motion vectors in pairs. The experimental results demonstrate the superiority of our proposed MVFlow, which can reduce the AEPE by 1.09 compared to existing models or save 52% time to achieve similar accuracy to existing models.
</details>
<details>
<summary>摘要</summary>
In detail, MVFlow includes a key Motion-Vector Converting Module, which ensures that the motion vectors can be transformed into the same domain as the optical flow and then be fully utilized by the flow estimation module. Furthermore, we construct four optical flow datasets for compressed videos containing frames and motion vectors in pairs. The experimental results show that our proposed MVFlow is superior, with a reduction of 1.09 in AEPE compared to existing models or a 52% reduction in time to achieve similar accuracy to existing models.
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Token-Pass-Transformers-for-Semantic-Segmentation"><a href="#Dynamic-Token-Pass-Transformers-for-Semantic-Segmentation" class="headerlink" title="Dynamic Token-Pass Transformers for Semantic Segmentation"></a>Dynamic Token-Pass Transformers for Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01944">http://arxiv.org/abs/2308.01944</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuang Liu, Qiang Zhou, Jing Wang, Fan Wang, Jun Wang, Wei Zhang</li>
<li>for: 这个论文是为了提高 semantic segmentation 的效率和速度而写的。</li>
<li>methods: 这个方法使用 dynamic token-pass vision transformers (DoViT)，可以适应不同的图像复杂度，并且可以适当地将部分易于计算的 токенs 排除，以减少测试成本。</li>
<li>results: 这个方法可以大约减少 40% 至 60% FLOPs，并且与硬件友好，同时仍然可以保持高效率和优化结果。 ViT-L&#x2F;B 的 Throughput 和测试速度可以提高至更多于 2$\times$ on Cityscapes。<details>
<summary>Abstract</summary>
Vision transformers (ViT) usually extract features via forwarding all the tokens in the self-attention layers from top to toe. In this paper, we introduce dynamic token-pass vision transformers (DoViT) for semantic segmentation, which can adaptively reduce the inference cost for images with different complexity. DoViT gradually stops partial easy tokens from self-attention calculation and keeps the hard tokens forwarding until meeting the stopping criteria. We employ lightweight auxiliary heads to make the token-pass decision and divide the tokens into keeping/stopping parts. With a token separate calculation, the self-attention layers are speeded up with sparse tokens and still work friendly with hardware. A token reconstruction module is built to collect and reset the grouped tokens to their original position in the sequence, which is necessary to predict correct semantic masks. We conduct extensive experiments on two common semantic segmentation tasks, and demonstrate that our method greatly reduces about 40% $\sim$ 60% FLOPs and the drop of mIoU is within 0.8% for various segmentation transformers. The throughput and inference speed of ViT-L/B are increased to more than 2$\times$ on Cityscapes.
</details>
<details>
<summary>摘要</summary>
vision transformers (ViT) 通常通过从顶部到底部传递所有的 tokens 来提取特征。在这篇论文中，我们介绍了动态Token-pass vision transformers (DoViT)，用于 semantic segmentation，可以适应不同的图像复杂度减少推理成本。DoViT 会逐渐停止一些容易的 tokens 从自我注意计算中，并保留一些困难的 tokens 直到满足停止 criterion。我们使用轻量级的辅助头来做 token-pass 决策，并将 tokens 分为保留/停止部分。通过 sparse tokens 的计算，自我注意层得到加速，同时仍与硬件友好。我们还构建了一个token重建模块，用于收集和重新设置 grouped tokens 的原始位置序列，这是必要的来预测正确的semantic mask。我们在两个常见的semantic segmentation任务上进行了广泛的实验，并证明了我们的方法可以大幅减少约40% 到60% FLOPs，并且drop of mIoU 在0.8% 以下。ViT-L/B 的 Throughput 和推理速度被提高到更多于 2 倍在 Cityscapes。
</details></li>
</ul>
<hr>
<h2 id="Get-the-Best-of-Both-Worlds-Improving-Accuracy-and-Transferability-by-Grassmann-Class-Representation"><a href="#Get-the-Best-of-Both-Worlds-Improving-Accuracy-and-Transferability-by-Grassmann-Class-Representation" class="headerlink" title="Get the Best of Both Worlds: Improving Accuracy and Transferability by Grassmann Class Representation"></a>Get the Best of Both Worlds: Improving Accuracy and Transferability by Grassmann Class Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01547">http://arxiv.org/abs/2308.01547</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haoqi Wang, Zhizhong Li, Wayne Zhang</li>
<li>for: 这篇论文旨在提高深度学习模型的准确率和特征传输能力。</li>
<li>methods: 论文使用了将类Vector转换为线性Subspace（i.e.~点在草mann manifold），并实现了在深度学习框架中集成Riemannian SGD以便同时优化类Subspace和模型参数。</li>
<li>results: 在ImageNet-1K数据集上，使用GCR后，ResNet50-D、ResNeXt50、Swin-T和Deit3-S等模型的顶部1错误率相对下降了5.6%、4.5%、3.0%和3.5%。此外，GCR还提供了更多的特征自由度，使得下游任务的质量更高。例如，对于ResNet50-D模型，GCR可以提高平均线性传输精度从77.98%提升到79.70%。<details>
<summary>Abstract</summary>
We generalize the class vectors found in neural networks to linear subspaces (i.e.~points in the Grassmann manifold) and show that the Grassmann Class Representation (GCR) enables the simultaneous improvement in accuracy and feature transferability. In GCR, each class is a subspace and the logit is defined as the norm of the projection of a feature onto the class subspace. We integrate Riemannian SGD into deep learning frameworks such that class subspaces in a Grassmannian are jointly optimized with the rest model parameters. Compared to the vector form, the representative capability of subspaces is more powerful. We show that on ImageNet-1K, the top-1 error of ResNet50-D, ResNeXt50, Swin-T and Deit3-S are reduced by 5.6%, 4.5%, 3.0% and 3.5%, respectively. Subspaces also provide freedom for features to vary and we observed that the intra-class feature variability grows when the subspace dimension increases. Consequently, we found the quality of GCR features is better for downstream tasks. For ResNet50-D, the average linear transfer accuracy across 6 datasets improves from 77.98% to 79.70% compared to the strong baseline of vanilla softmax. For Swin-T, it improves from 81.5% to 83.4% and for Deit3, it improves from 73.8% to 81.4%. With these encouraging results, we believe that more applications could benefit from the Grassmann class representation. Code is released at https://github.com/innerlee/GCR.
</details>
<details>
<summary>摘要</summary>
我们总结了神经网络中的类别向量到线性子空间（即点在草mann manifold），并证明GCR（草mann类表示）可以同时提高准确率和特征传递性。在GCR中，每个类是一个子空间，logit是定义为特征在类子空间上的投影距离的模值。我们将里曼射SGD集成到深度学习框架中，以便在Grassmannian中同时优化类子空间和其他模型参数。相比vector形式，子空间的表示能力更强。我们证明在ImageNet-1K上，ResNet50-D、ResNeXt50、Swin-T和Deit3-S的top-1错误率分别下降5.6%, 4.5%, 3.0%和3.5%。子空间还提供了特征之间的自由，我们观察到在子空间维度增加时，内类特征变化的度逐渐增加。因此，我们发现GCR特征质量更好，用于下游任务。对于ResNet50-D，我们在6个数据集上的平均直线传输精度从77.98%提高到79.70%，比强基eline softmax强度更高。对于Swin-T，从81.5%提高到83.4%，对于Deit3，从73.8%提高到81.4%。这些激动人心的结果表明，更多的应用可以从GCR中受益。代码可以在https://github.com/innerlee/GCR中找到。
</details></li>
</ul>
<hr>
<h2 id="DMDC-Dynamic-mask-based-dual-camera-design-for-snapshot-Hyperspectral-Imaging"><a href="#DMDC-Dynamic-mask-based-dual-camera-design-for-snapshot-Hyperspectral-Imaging" class="headerlink" title="DMDC: Dynamic-mask-based dual camera design for snapshot Hyperspectral Imaging"></a>DMDC: Dynamic-mask-based dual camera design for snapshot Hyperspectral Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01541">http://arxiv.org/abs/2308.01541</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/caizeyu1992/dmdc">https://github.com/caizeyu1992/dmdc</a></li>
<li>paper_authors: Zeyu Cai, Chengqian Jin, Feipeng Da</li>
<li>for: 提高coded aperture snapshot spectral imaging（CASSI）中深度学习方法的性能。</li>
<li>methods: 使用动态面镜（DMD）和多模式重构网络（DMDC-net），首先根据RGB图像学习场景的空间特征分布，然后使用SLM编码场景，最后将RGB和CASSI图像传输到网络进行重构。</li>
<li>results: 在多个数据集上进行了广泛的实验，结果表明，我们的方法可以与先前最佳方法（SOTA）比较，提高PSNR值超过9 dB。<details>
<summary>Abstract</summary>
Deep learning methods are developing rapidly in coded aperture snapshot spectral imaging (CASSI). The number of parameters and FLOPs of existing state-of-the-art methods (SOTA) continues to increase, but the reconstruction accuracy improves slowly. Current methods still face two problems: 1) The performance of the spatial light modulator (SLM) is not fully developed due to the limitation of fixed Mask coding. 2) The single input limits the network performance. In this paper we present a dynamic-mask-based dual camera system, which consists of an RGB camera and a CASSI system running in parallel. First, the system learns the spatial feature distribution of the scene based on the RGB images, then instructs the SLM to encode each scene, and finally sends both RGB and CASSI images to the network for reconstruction. We further designed the DMDC-net, which consists of two separate networks, a small-scale CNN-based dynamic mask network for dynamic adjustment of the mask and a multimodal reconstruction network for reconstruction using RGB and CASSI measurements. Extensive experiments on multiple datasets show that our method achieves more than 9 dB improvement in PSNR over the SOTA. (https://github.com/caizeyu1992/DMDC)
</details>
<details>
<summary>摘要</summary>
深度学习方法在coded aperture snapshot spectral imaging（CASSI）领域快速发展，但现有状态的方法（SOTA）中参数和FLOPs的数量继续增加，但 reconstruction accuracy 的提高相对较慢。当前方法仍面临两个问题：1）SLM（spatial light modulator）的性能尚未得到完全发展，因为固定的Mask coding有限制。2）单个输入限制网络性能。在本文中，我们提出了动态Mask基于双camera系统，包括一个RGB摄像头和一个CASSI系统在平行运行。首先，系统通过RGB图像学习场景中的空间特征分布，然后根据场景指定SLM编码，最后将RGB和CASSI图像传递给网络进行重建。我们还设计了DMDC-net，它包括两个独立的网络：一个小规模的CNN基于动态Mask网络用于动态调整Mask，以及一个多模式重建网络用于使用RGB和CASSI测量进行重建。我们在多个数据集上进行了广泛的实验，结果显示，我们的方法可以在PSNR方面实现超过9dB的提高。（https://github.com/caizeyu1992/DMDC）
</details></li>
</ul>
<hr>
<h2 id="MFIM-Megapixel-Facial-Identity-Manipulation"><a href="#MFIM-Megapixel-Facial-Identity-Manipulation" class="headerlink" title="MFIM: Megapixel Facial Identity Manipulation"></a>MFIM: Megapixel Facial Identity Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01536">http://arxiv.org/abs/2308.01536</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanghyeon Na</li>
<li>for: 本文提出了一种新的面孔交换框架，称为大像素面孔标识修饰（MFIM），用于实现两个目标：首先，生成高质量图像；其次，将给定图像的身份特征变换成另一个人的身份特征，保留不相关的特征。</li>
<li>methods: 本文使用了预训练的StyleGAN进行GAN-倒置，以生成高像素图像。此外，本文还使用了3DMM来捕捉多种面孔特征，并将这些特征用于生成面孔交换图像。</li>
<li>results: 经过广泛的实验表明，本文的模型达到了状态方法性能。此外，本文还提出了一种新的操作，称为身份混合，允许用户自定义新的身份。<details>
<summary>Abstract</summary>
Face swapping is a task that changes a facial identity of a given image to that of another person. In this work, we propose a novel face-swapping framework called Megapixel Facial Identity Manipulation (MFIM). The face-swapping model should achieve two goals. First, it should be able to generate a high-quality image. We argue that a model which is proficient in generating a megapixel image can achieve this goal. However, generating a megapixel image is generally difficult without careful model design. Therefore, our model exploits pretrained StyleGAN in the manner of GAN-inversion to effectively generate a megapixel image. Second, it should be able to effectively transform the identity of a given image. Specifically, it should be able to actively transform ID attributes (e.g., face shape and eyes) of a given image into those of another person, while preserving ID-irrelevant attributes (e.g., pose and expression). To achieve this goal, we exploit 3DMM that can capture various facial attributes. Specifically, we explicitly supervise our model to generate a face-swapped image with the desirable attributes using 3DMM. We show that our model achieves state-of-the-art performance through extensive experiments. Furthermore, we propose a new operation called ID mixing, which creates a new identity by semantically mixing the identities of several people. It allows the user to customize the new identity.
</details>
<details>
<summary>摘要</summary>
《Face swapping是一个任务，把给定图像的脸部标识换成另一个人的脸部标识。在这个工作中，我们提出了一种新的面部交换框架，即Megapixel Facial Identity Manipulation（MFIM）。这个模型应该实现两个目标。一是生成高质量图像，我们认为能够生成高分辨率图像的模型可以实现这个目标。然而，生成高分辨率图像通常需要精心的模型设计。因此，我们的模型利用了预训练的StyleGAN，通过GAN-倒置的方式来生成高分辨率图像。二是能够有效地将给定图像的脸部标识转换为另一个人的脸部标识。具体来说，它应该能够活动地将ID属性（如脸形和眼睛）转换为另一个人的ID属性，保留ID不关属性（如姿势和表情）。为了实现这个目标，我们利用了3DMM，它可以捕捉各种脸部特征。我们显式地监督我们的模型生成一个面部交换图像，拥有愿望的特征使用3DMM。我们的实验结果表明，我们的模型实现了状态监测的性能。此外，我们还提出了一种新的操作，即ID混合，它可以将多个人的标识混合成一个新的标识，让用户自定义新的标识。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Adaptation-of-CLIP-for-Few-Shot-Action-Recognition"><a href="#Multimodal-Adaptation-of-CLIP-for-Few-Shot-Action-Recognition" class="headerlink" title="Multimodal Adaptation of CLIP for Few-Shot Action Recognition"></a>Multimodal Adaptation of CLIP for Few-Shot Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01532">http://arxiv.org/abs/2308.01532</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiazheng Xing, Mengmeng Wang, Xiaojun Hou, Guang Dai, Jingdong Wang, Yong Liu</li>
<li>for: 这篇论文的目的是提出一种新的方法来将大规模预训的视觉模型CLIP应用于几步动作识别 зада务中，以提高性能和效率。</li>
<li>methods: 这篇论文使用了“预训、统一”的方法来避免从零训练网络，从而节省时间和资源。但这方法有两个缺点：首先，几步动作识别的有限标签数据需要对数据进行严格的节省，以避免过拟合；其次，影片的EXTRA-temporal维度对几步动作识别的有效时间模型产生挑战，而预训的视觉模型通常是图像模型。这篇论文提出了一种名为Multimodal Adaptation of CLIP（MA-CLIP）的新方法，用于解决这些问题。</li>
<li>results: MA-CLIP可以快速地适应几步动作识别任务，并且可以将视觉模型转换到不同的任务上，而不需要从零训练网络。这篇论文还提出了一种基于注意机制的文本导向原型建立模组，可以充分利用影片-文本多媒体资料来增强影片原型的表现。<details>
<summary>Abstract</summary>
Applying large-scale pre-trained visual models like CLIP to few-shot action recognition tasks can benefit performance and efficiency. Utilizing the "pre-training, fine-tuning" paradigm makes it possible to avoid training a network from scratch, which can be time-consuming and resource-intensive. However, this method has two drawbacks. First, limited labeled samples for few-shot action recognition necessitate minimizing the number of tunable parameters to mitigate over-fitting, also leading to inadequate fine-tuning that increases resource consumption and may disrupt the generalized representation of models. Second, the video's extra-temporal dimension challenges few-shot recognition's effective temporal modeling, while pre-trained visual models are usually image models. This paper proposes a novel method called Multimodal Adaptation of CLIP (MA-CLIP) to address these issues. It adapts CLIP for few-shot action recognition by adding lightweight adapters, which can minimize the number of learnable parameters and enable the model to transfer across different tasks quickly. The adapters we design can combine information from video-text multimodal sources for task-oriented spatiotemporal modeling, which is fast, efficient, and has low training costs. Additionally, based on the attention mechanism, we design a text-guided prototype construction module that can fully utilize video-text information to enhance the representation of video prototypes. Our MA-CLIP is plug-and-play, which can be used in any different few-shot action recognition temporal alignment metric.
</details>
<details>
<summary>摘要</summary>
使用大规模预训练的视觉模型如CLIP进行几步动作认知任务可以提高性能和效率。利用“预训练、精度调整”的方法可以避免从头开始训练网络，这可以降低时间和资源的投入。然而，这种方法有两点缺点。首先，几步动作认知任务的有限标注样本数量需要尽量减少可训练参数的数量，以避免过拟合。其次，视频的Extra-temporal维度对几步动作认知任务的有效时间模型化起来困难，而预训练的视觉模型通常是图像模型。这篇论文提出了一种新的方法called Multimodal Adaptation of CLIP (MA-CLIP)来解决这些问题。它适应了CLIP进行几步动作认知任务，通过添加轻量级适配器，可以最小化可训练参数的数量，并使模型快速传播到不同任务。我们设计的适配器可以将视频-文本多modal源的信息结合到任务指向的空间时间模型中，这快速、高效、训练成本低。此外，基于注意机制，我们设计了文本引导原型构建模块，可以充分利用视频-文本信息来增强视频原型的表示。我们的MA-CLIP是可插入的，可以在不同的几步动作认知任务中使用。
</details></li>
</ul>
<hr>
<h2 id="Data-Augmentation-for-Human-Behavior-Analysis-in-Multi-Person-Conversations"><a href="#Data-Augmentation-for-Human-Behavior-Analysis-in-Multi-Person-Conversations" class="headerlink" title="Data Augmentation for Human Behavior Analysis in Multi-Person Conversations"></a>Data Augmentation for Human Behavior Analysis in Multi-Person Conversations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01526">http://arxiv.org/abs/2308.01526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kun Li, Dan Guo, Guoliang Chen, Feiyang Liu, Meng Wang</li>
<li>for: 本文介绍了我们队伍HFUT-VUT在ACM Multimedia 2023年度多媒体大挑战中的解决方案，该解决方案包括三个子挑战：身体行为识别、眼接触检测和下一位说话预测。</li>
<li>methods: 我们选择Swin Transformer作为基线，并使用数据增强策略来解决上述三个任务。具体来说，我们将原始视频裁剪去除其他部分的噪音，同时利用数据增强来改善模型的通用性。</li>
<li>results: 我们的解决方案在测试集上实现了身体行为识别的最佳结果（准确率为0.6262）、眼接触检测的最高精度（准确率为0.7771）和下一位说话预测的相对不错的结果（不Weighted Average Recall为0.5281）。<details>
<summary>Abstract</summary>
In this paper, we present the solution of our team HFUT-VUT for the MultiMediate Grand Challenge 2023 at ACM Multimedia 2023. The solution covers three sub-challenges: bodily behavior recognition, eye contact detection, and next speaker prediction. We select Swin Transformer as the baseline and exploit data augmentation strategies to address the above three tasks. Specifically, we crop the raw video to remove the noise from other parts. At the same time, we utilize data augmentation to improve the generalization of the model. As a result, our solution achieves the best results of 0.6262 for bodily behavior recognition in terms of mean average precision and the accuracy of 0.7771 for eye contact detection on the corresponding test set. In addition, our approach also achieves comparable results of 0.5281 for the next speaker prediction in terms of unweighted average recall.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了我们团队HFUT-VUT在ACM Multimedia 2023年度的MultiMediate Grand Challenge 2023中的解决方案。该解决方案包括三个子挑战：身体行为识别、眼球接触检测和下一个发言人预测。我们选择Swin Transformer作为基线，并使用数据扩充策略来解决以上三个任务。具体来说，我们对原始视频进行cropping，以移除其他部分的噪音。同时，我们利用数据扩充来提高模型的通用性。因此，我们的解决方案在对应的测试集上实现了身体行为识别的最佳结果（准确率0.6262）和眼球接触检测的最高精度（准确率0.7771）。此外，我们的方法还实现了与基线相当的下一个发言人预测结果（不重量平均回归率0.5281）。
</details></li>
</ul>
<hr>
<h2 id="VisAlign-Dataset-for-Measuring-the-Degree-of-Alignment-between-AI-and-Humans-in-Visual-Perception"><a href="#VisAlign-Dataset-for-Measuring-the-Degree-of-Alignment-between-AI-and-Humans-in-Visual-Perception" class="headerlink" title="VisAlign: Dataset for Measuring the Degree of Alignment between AI and Humans in Visual Perception"></a>VisAlign: Dataset for Measuring the Degree of Alignment between AI and Humans in Visual Perception</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01525">http://arxiv.org/abs/2308.01525</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiyounglee-0523/visalign">https://github.com/jiyounglee-0523/visalign</a></li>
<li>paper_authors: Jiyoung Lee, Seungho Kim, Seunghyun Won, Joonseok Lee, Marzyeh Ghassemi, James Thorne, Jaeseok Choi, O-Kil Kwon, Edward Choi</li>
<li>for: 本研究旨在提高人工智能模型与人类目标、偏好或道德原则的一致性，即 AI 安全性。</li>
<li>methods: 本文提出了一个新的图像分类数据集，用于衡量人工智能模型与人类视觉启示的一致性。</li>
<li>results: 使用该数据集，我们分析了五种流行的视觉识别模型和七种决策策略的视觉一致性和可靠性。<details>
<summary>Abstract</summary>
AI alignment refers to models acting towards human-intended goals, preferences, or ethical principles. Given that most large-scale deep learning models act as black boxes and cannot be manually controlled, analyzing the similarity between models and humans can be a proxy measure for ensuring AI safety. In this paper, we focus on the models' visual perception alignment with humans, further referred to as AI-human visual alignment. Specifically, we propose a new dataset for measuring AI-human visual alignment in terms of image classification, a fundamental task in machine perception. In order to evaluate AI-human visual alignment, a dataset should encompass samples with various scenarios that may arise in the real world and have gold human perception labels. Our dataset consists of three groups of samples, namely Must-Act (i.e., Must-Classify), Must-Abstain, and Uncertain, based on the quantity and clarity of visual information in an image and further divided into eight categories. All samples have a gold human perception label; even Uncertain (severely blurry) sample labels were obtained via crowd-sourcing. The validity of our dataset is verified by sampling theory, statistical theories related to survey design, and experts in the related fields. Using our dataset, we analyze the visual alignment and reliability of five popular visual perception models and seven abstention methods. Our code and data is available at \url{https://github.com/jiyounglee-0523/VisAlign}.
</details>
<details>
<summary>摘要</summary>
人工智能对齐（AI对齐）指模型行为与人类目标、偏好或伦理原则相符。由于大多数大规模深度学习模型作为黑盒子无法被手动控制，因此分析模型与人类的相似性可以作为AI安全的代理指标。在这篇论文中，我们关注视觉模型与人类的视觉对齐，即AI-人类视觉对齐。我们提出了一个新的数据集来衡量AI-人类视觉对齐，该数据集包括了不同场景可能在实际世界中出现的图像分类任务。为了评估AI-人类视觉对齐，数据集应包含具有不同频率和清晰度的图像样本，并且每个样本都有人类视觉标签。我们的数据集分为三类样本：必须作为（Must-Act）、必须停止（Must-Abstain）和不确定（Uncertain），根据图像中视觉信息的量和清晰度进行分类。所有样本具有人类视觉标签，包括不确定（极度模糊）样本的标签，通过在线人员投票获取。我们的数据集的有效性被证明由抽样理论、统计相关的调查设计理论以及相关领域专家的验证。使用我们的数据集，我们分析了五种流行的视觉识别模型和七种停止方法的视觉对齐和可靠性。我们的代码和数据可以在GitHub上获取：<https://github.com/jiyounglee-0523/VisAlign>。
</details></li>
</ul>
<hr>
<h2 id="PPI-NET-End-to-End-Parametric-Primitive-Inference"><a href="#PPI-NET-End-to-End-Parametric-Primitive-Inference" class="headerlink" title="PPI-NET: End-to-End Parametric Primitive Inference"></a>PPI-NET: End-to-End Parametric Primitive Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01521">http://arxiv.org/abs/2308.01521</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liang Wang, Xiaogang Wang</li>
<li>for: 本研究旨在提高设计模型创建过程中的效率和准确性，避免使用自适应模型从手绘图像中推导参数化基本形态时的不必要的重复和错误积累问题。</li>
<li>methods: 我们提议一种高效准确的终端方法，通过直接从手绘图像中提取基本形态的准确 Parametric 表示，以避免使用自适应模型的推导过程中的错误和重复工作。</li>
<li>results: 我们的模型样本匹配标准 CAD 软件的表示格式，因此可以将其导入 CAD 软件进行解决、编辑和应用到下游设计任务中。<details>
<summary>Abstract</summary>
In engineering applications, line, circle, arc, and point are collectively referred to as primitives, and they play a crucial role in path planning, simulation analysis, and manufacturing. When designing CAD models, engineers typically start by sketching the model's orthographic view on paper or a whiteboard and then translate the design intent into a CAD program. Although this design method is powerful, it often involves challenging and repetitive tasks, requiring engineers to perform numerous similar operations in each design. To address this conversion process, we propose an efficient and accurate end-to-end method that avoids the inefficiency and error accumulation issues associated with using auto-regressive models to infer parametric primitives from hand-drawn sketch images. Since our model samples match the representation format of standard CAD software, they can be imported into CAD software for solving, editing, and applied to downstream design tasks.
</details>
<details>
<summary>摘要</summary>
在工程应用中，直线、圆形、弧形和点被合称为基本形状，它们在路径规划、分析研究和生产中扮演着重要的角色。在设计CAD模型时，工程师通常从纸上或白板上绘制模型的正交视图，然后将设计意图翻译到CAD软件中。虽然这种设计方法具有强大的能力，但它经常带来复杂和重复的任务，需要工程师在每个设计中执行大量相似的操作。为了解决这个转换过程中的不效率和错误积累问题，我们提出了一种高效和准确的终端方法，这种方法可以避免使用自动回归模型来从手绘笔画图像中推导参数化基本形状。由于我们的模型样本与标准CAD软件的表示格式匹配，因此它们可以被直接 importing into CAD软件中进行解决、编辑和应用到下游设计任务中。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Multi-FaceForensics-An-End-to-end-Bi-grained-Contrastive-Learning-Approach-for-Multi-face-Forgery-Detection"><a href="#Contrastive-Multi-FaceForensics-An-End-to-end-Bi-grained-Contrastive-Learning-Approach-for-Multi-face-Forgery-Detection" class="headerlink" title="Contrastive Multi-FaceForensics: An End-to-end Bi-grained Contrastive Learning Approach for Multi-face Forgery Detection"></a>Contrastive Multi-FaceForensics: An End-to-end Bi-grained Contrastive Learning Approach for Multi-face Forgery Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01520">http://arxiv.org/abs/2308.01520</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cong Zhang, Honggang Qi, Yuezun Li, Siwei Lyu</li>
<li>for: 本研究旨在提高多人脸伪造检测。</li>
<li>methods: 该方法基于对比学习，包括粗细度层次的对比学习和像素级别的对比学习。</li>
<li>results: 对比Multi-FaceForensics方法，该方法在OpenForensics数据集上达到了18.5%的提升。<details>
<summary>Abstract</summary>
DeepFakes have raised serious societal concerns, leading to a great surge in detection-based forensics methods in recent years. Face forgery recognition is the conventional detection method that usually follows a two-phase pipeline: it extracts the face first and then determines its authenticity by classification. Since DeepFakes in the wild usually contain multiple faces, using face forgery detection methods is merely practical as they have to process faces in a sequel, i.e., only one face is processed at the same time. One straightforward way to address this issue is to integrate face extraction and forgery detection in an end-to-end fashion by adapting advanced object detection architectures. However, as these object detection architectures are designed to capture the semantic information of different object categories rather than the subtle forgery traces among the faces, the direct adaptation is far from optimal. In this paper, we describe a new end-to-end framework, Contrastive Multi-FaceForensics (COMICS), to enhance multi-face forgery detection. The core of the proposed framework is a novel bi-grained contrastive learning approach that explores effective face forgery traces at both the coarse- and fine-grained levels. Specifically, the coarse-grained level contrastive learning captures the discriminative features among positive and negative proposal pairs in multiple scales with the instruction of the proposal generator, and the fine-grained level contrastive learning captures the pixel-wise discrepancy between the forged and original areas of the same face and the pixel-wise content inconsistency between different faces. Extensive experiments on the OpenForensics dataset demonstrate our method outperforms other counterparts by a large margin (~18.5%) and shows great potential for integration into various architectures.
</details>
<details>
<summary>摘要</summary>
深度复制（DeepFakes）已引起了社会的严重关注，leading to a great surge in detection-based forensics methods in recent years. Face forgery recognition is the conventional detection method that usually follows a two-phase pipeline: it extracts the face first and then determines its authenticity by classification. However, since DeepFakes in the wild usually contain multiple faces, using face forgery detection methods is merely practical as they have to process faces in a sequel, i.e., only one face is processed at the same time. To address this issue, we can integrate face extraction and forgery detection in an end-to-end fashion by adapting advanced object detection architectures. However, as these object detection architectures are designed to capture the semantic information of different object categories rather than the subtle forgery traces among the faces, the direct adaptation is far from optimal.In this paper, we propose a new end-to-end framework, Contrastive Multi-FaceForensics (COMICS), to enhance multi-face forgery detection. The core of the proposed framework is a novel bi-grained contrastive learning approach that explores effective face forgery traces at both the coarse- and fine-grained levels. Specifically, the coarse-grained level contrastive learning captures the discriminative features among positive and negative proposal pairs in multiple scales with the instruction of the proposal generator, and the fine-grained level contrastive learning captures the pixel-wise discrepancy between the forged and original areas of the same face and the pixel-wise content inconsistency between different faces. Extensive experiments on the OpenForensics dataset demonstrate that our method outperforms other counterparts by a large margin (~18.5%) and shows great potential for integration into various architectures.
</details></li>
</ul>
<hr>
<h2 id="Circumventing-Concept-Erasure-Methods-For-Text-to-Image-Generative-Models"><a href="#Circumventing-Concept-Erasure-Methods-For-Text-to-Image-Generative-Models" class="headerlink" title="Circumventing Concept Erasure Methods For Text-to-Image Generative Models"></a>Circumventing Concept Erasure Methods For Text-to-Image Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01508">http://arxiv.org/abs/2308.01508</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nyu-dice-lab/circumventing-concept-erasure">https://github.com/nyu-dice-lab/circumventing-concept-erasure</a></li>
<li>paper_authors: Minh Pham, Kelly O. Marshall, Chinmay Hegde</li>
<li>for: 本研究旨在检查五种最近提出的概念消除方法，以确定这些方法是否能够彻底消除目标概念。</li>
<li>methods: 本研究使用了五种最近提出的概念消除方法，包括：Xu et al.’s method（2018）、Zhang et al.’s method（2019）、Liu et al.’s method（2020）、Wang et al.’s method（2020）和Zhang et al.’s method（2020）。</li>
<li>results: 研究发现，无论使用哪种方法，都无法彻底消除目标概念。特别是，使用特定的学习word embeddings可以 Retrieves “erased” concepts from the sanitized models with no alterations to their weights。这些结果表明，后期概念消除方法是不坚定的，并质疑它们在AI安全中的使用。<details>
<summary>Abstract</summary>
Text-to-image generative models can produce photo-realistic images for an extremely broad range of concepts, and their usage has proliferated widely among the general public. On the flip side, these models have numerous drawbacks, including their potential to generate images featuring sexually explicit content, mirror artistic styles without permission, or even hallucinate (or deepfake) the likenesses of celebrities. Consequently, various methods have been proposed in order to "erase" sensitive concepts from text-to-image models. In this work, we examine five recently proposed concept erasure methods, and show that targeted concepts are not fully excised from any of these methods. Specifically, we leverage the existence of special learned word embeddings that can retrieve "erased" concepts from the sanitized models with no alterations to their weights. Our results highlight the brittleness of post hoc concept erasure methods, and call into question their use in the algorithmic toolkit for AI safety.
</details>
<details>
<summary>摘要</summary>
文本到图像生成模型可以生成高度真实的图像，覆盖了极广泛的概念，并在普通公众中得到了广泛的应用。然而，这些模型也有许多缺点，包括可能生成涉黄内容、无许可的艺术风格模仿或even celebrities的形象hallucination（或深 fake）。因此，各种方法被提议，以“消除”敏感概念从文本到图像模型中。在这项工作中，我们研究了五种最近提出的概念消除方法，并发现目标概念在这些方法中并没有完全消除。具体来说，我们利用特殊学习的词嵌入，可以从清理后的模型中提取“消除”的概念，无需对模型的权重进行任何修改。我们的结果表明了后期概念消除方法的脆弱性，并质疑它们在AI安全中的使用。
</details></li>
</ul>
<hr>
<h2 id="TSMD-A-Database-for-Static-Color-Mesh-Quality-Assessment-Study"><a href="#TSMD-A-Database-for-Static-Color-Mesh-Quality-Assessment-Study" class="headerlink" title="TSMD: A Database for Static Color Mesh Quality Assessment Study"></a>TSMD: A Database for Static Color Mesh Quality Assessment Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01940">http://arxiv.org/abs/2308.01940</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qi Yang, Joel Jung, Haiqiang Wang, Xiaozhong Xu, Shan Liu</li>
<li>for:  This paper is written for the study of static mesh compression algorithms and objective quality metrics.</li>
<li>methods:  The paper uses a large-scale, crowdsourcing-based, subjective experiment to collect subjective scores from 74 viewers, and analyzes the dataset to validate its sample diversity and Mean Opinion Scores (MOS) accuracy.</li>
<li>results:  The paper reports Pearson and Spearman correlations around 0.75, demonstrating the need for further development of more robust metrics.Here is the text in Simplified Chinese:</li>
<li>for: 这篇论文是为了研究静态网格压缩算法和对象质量指标的研究而写的。</li>
<li>methods: 这篇论文使用大规模的人工社会测试来收集74名观众的主观分数，并分析数据集以验证其样本多样性和 Mean Opinion Scores（MOS）准确性。</li>
<li>results: 这篇论文报告了皮尔逊和斯帕曼相关性约为0.75，表明需要进一步开发更加Robust的指标。<details>
<summary>Abstract</summary>
Static meshes with texture map are widely used in modern industrial and manufacturing sectors, attracting considerable attention in the mesh compression community due to its huge amount of data. To facilitate the study of static mesh compression algorithm and objective quality metric, we create the Tencent - Static Mesh Dataset (TSMD) containing 42 reference meshes with rich visual characteristics. 210 distorted samples are generated by the lossy compression scheme developed for the Call for Proposals on polygonal static mesh coding, released on June 23 by the Alliance for Open Media Volumetric Visual Media group. Using processed video sequences, a large-scale, crowdsourcing-based, subjective experiment was conducted to collect subjective scores from 74 viewers. The dataset undergoes analysis to validate its sample diversity and Mean Opinion Scores (MOS) accuracy, establishing its heterogeneous nature and reliability. State-of-the-art objective metrics are evaluated on the new dataset. Pearson and Spearman correlations around 0.75 are reported, deviating from results typically observed on less heterogeneous datasets, demonstrating the need for further development of more robust metrics. The TSMD, including meshes, PVSs, bitstreams, and MOS, is made publicly available at the following location: https://multimedia.tencent.com/resources/tsmd.
</details>
<details>
<summary>摘要</summary>
Static meshes with texture map 广泛应用于现代工业和制造领域，吸引了严重的数据压缩社区的关注，因为它们的数据量很大。为了促进静止矩阵压缩算法和目标质量指标的研究，我们创建了腾讯-静止矩阵数据集（TSMD），包含42个参考矩阵，具有丰富的视觉特征。通过发布的损失压缩方案，我们生成了210个扭曲样例。使用处理过的视频序列，我们通过大规模的人员协同实验，收集了74名观众的主观评分。数据集进行分析，以验证样本多样性和主观评分准确性，证明其多样性和可靠性。我们使用现有的对象指标进行evaluation，并报告了0.75的 peakson和spearman相关性，与其他更少的多样性的数据集相比，表明需要进一步发展更加Robust的指标。TSMD，包括矩阵、PVS、比特流和MOS，在以下地址公开发布：https://multimedia.tencent.com/resources/tsmd。
</details></li>
</ul>
<hr>
<h2 id="TDMD-A-Database-for-Dynamic-Color-Mesh-Subjective-and-Objective-Quality-Explorations"><a href="#TDMD-A-Database-for-Dynamic-Color-Mesh-Subjective-and-Objective-Quality-Explorations" class="headerlink" title="TDMD: A Database for Dynamic Color Mesh Subjective and Objective Quality Explorations"></a>TDMD: A Database for Dynamic Color Mesh Subjective and Objective Quality Explorations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01499">http://arxiv.org/abs/2308.01499</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qi Yang, Joel Jung, Timon Deschamps, Xiaozhong Xu, Shan Liu</li>
<li>for: 这个论文的目的是为了开发对动态颜色网格（DCM）的 объектив度量表，以及研究一般处理DCM时的影响。</li>
<li>methods: 这个论文使用了八个参考DCM对象和六种常见的扭曲来创建了 Tencent - 动态颜色网格数据库（TDMD）。然后，通过处理视频序列（PVS）来进行了大规模的主观实验，从而获得了303个扭曲DCM样本的平均意见分数。</li>
<li>results: 这个数据库可以用于研究不同类型的扭曲对人类 восприятия的影响，以及提供DCM压缩和相关任务中的建议。此外，这个论文还评估了三种当今最佳的对metric在TDMD上的表现，包括图像基于的、点基于的和视频基于的metric。实验结果表明每种metric在不同的应用中具有优势和缺陷，并提供了实际应用中metric选择的建议。TDMD将在以下位置公开：<a target="_blank" rel="noopener" href="https://multimedia.tencent.com/resources/tdmd%E3%80%82">https://multimedia.tencent.com/resources/tdmd。</a><details>
<summary>Abstract</summary>
Dynamic colored meshes (DCM) are widely used in various applications; however, these meshes may undergo different processes, such as compression or transmission, which can distort them and degrade their quality. To facilitate the development of objective metrics for DCMs and study the influence of typical distortions on their perception, we create the Tencent - dynamic colored mesh database (TDMD) containing eight reference DCM objects with six typical distortions. Using processed video sequences (PVS) derived from the DCM, we have conducted a large-scale subjective experiment that resulted in 303 distorted DCM samples with mean opinion scores, making the TDMD the largest available DCM database to our knowledge. This database enabled us to study the impact of different types of distortion on human perception and offer recommendations for DCM compression and related tasks. Additionally, we have evaluated three types of state-of-the-art objective metrics on the TDMD, including image-based, point-based, and video-based metrics, on the TDMD. Our experimental results highlight the strengths and weaknesses of each metric, and we provide suggestions about the selection of metrics in practical DCM applications. The TDMD will be made publicly available at the following location: https://multimedia.tencent.com/resources/tdmd.
</details>
<details>
<summary>摘要</summary>
《dynamic colored meshes（DCM）在各种应用中广泛使用，但这些网格可能会经历压缩、传输等过程，导致其质量下降。为了促进DCM的 объектив评价和研究这些扭曲对人类视觉的影响，我们创建了腾讯-动态颜色网格数据库（TDMD），包含8个参考DCM对象以及6种典型的扭曲。使用来自DCM的处理视频序列（PVS），我们进行了大规模的主观实验，从而生成了303个扭曲DCM样本，其中每个样本有平均意见分数。TDMD是我们知道的最大的DCM数据库。我们通过对TDMD进行研究，发现不同类型的扭曲对人类视觉的影响，并提供了DCM压缩和相关任务中的指导方针。此外，我们还评估了三种当今最佳的对象评价度量，包括图像基于的、点基于的和视频基于的度量，在TDMD上。我们的实验结果显示了每种度量的优缺点，并提供了实际应用中选择度量的建议。TDMD将在以下地址公开：https://multimedia.tencent.com/resources/tdmd。》
</details></li>
</ul>
<hr>
<h2 id="Efficient-neural-supersampling-on-a-novel-gaming-dataset"><a href="#Efficient-neural-supersampling-on-a-novel-gaming-dataset" class="headerlink" title="Efficient neural supersampling on a novel gaming dataset"></a>Efficient neural supersampling on a novel gaming dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01483">http://arxiv.org/abs/2308.01483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Antoine Mercier, Ruan Erasmus, Yashesh Savani, Manik Dhingra, Fatih Porikli, Guillaume Berger</li>
<li>for: 提高游戏视频的实时渲染效果，因为需要更高的分辨率、帧率和光彩实现。</li>
<li>methods: 使用神经网络算法进行渲染内容的高速抽象，比现有方法四倍效率，保持同等准确性。</li>
<li>results: 引入了一个新的数据集，提供了辅助特征如运动 вектор和深度，这些特征是通过渲染特性如视窗晃动和mipple biasing在不同分辨率下生成的。我们认为这个数据集会填补当前数据景观的空白，并可以作为测试进步的 valuable resource。<details>
<summary>Abstract</summary>
Real-time rendering for video games has become increasingly challenging due to the need for higher resolutions, framerates and photorealism. Supersampling has emerged as an effective solution to address this challenge. Our work introduces a novel neural algorithm for supersampling rendered content that is 4 times more efficient than existing methods while maintaining the same level of accuracy. Additionally, we introduce a new dataset which provides auxiliary modalities such as motion vectors and depth generated using graphics rendering features like viewport jittering and mipmap biasing at different resolutions. We believe that this dataset fills a gap in the current dataset landscape and can serve as a valuable resource to help measure progress in the field and advance the state-of-the-art in super-resolution techniques for gaming content.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:现实时游戏渲染面临着高分辨率、高帧率和真实感的增加需求，而抽象渲染技术已成为一种有效的解决方案。我们的工作推出了一种基于神经网络的抽象渲染内容算法，比现有方法高效四倍，保持同等准确性。此外，我们还介绍了一个新的数据集，该数据集包含不同分辨率下的游戏内容中的视觉特征，如视口抖动和mips扭曲，以及相关的动作向量和深度信息。我们认为这个数据集将填补当前数据景观的空白，并成为评估领域的价值资源，帮助推动游戏内容的超分辨率技术的进步。
</details></li>
</ul>
<hr>
<h2 id="HANDAL-A-Dataset-of-Real-World-Manipulable-Object-Categories-with-Pose-Annotations-Affordances-and-Reconstructions"><a href="#HANDAL-A-Dataset-of-Real-World-Manipulable-Object-Categories-with-Pose-Annotations-Affordances-and-Reconstructions" class="headerlink" title="HANDAL: A Dataset of Real-World Manipulable Object Categories with Pose Annotations, Affordances, and Reconstructions"></a>HANDAL: A Dataset of Real-World Manipulable Object Categories with Pose Annotations, Affordances, and Reconstructions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01477">http://arxiv.org/abs/2308.01477</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrew Guo, Bowen Wen, Jianhe Yuan, Jonathan Tremblay, Stephen Tyree, Jeffrey Smith, Stan Birchfield</li>
<li>for: 这 paper 是为了提供一个category-level object pose estimation和可用性预测的数据集，而且这个数据集专注于可以由机器人抓取的可操作物品，例如锤子、用具和螺丝刀。</li>
<li>methods: 这 paper 使用了单个抽象相机和半自动化处理来生成高质量的3D注释，而不需要人工劳动。</li>
<li>results: 这 paper 描述了一个包含 308k annotated image frame 和 2.2k 视频的 212 个实际世界物品的 17 个类别，以及这些数据集的使用性和挑战。<details>
<summary>Abstract</summary>
We present the HANDAL dataset for category-level object pose estimation and affordance prediction. Unlike previous datasets, ours is focused on robotics-ready manipulable objects that are of the proper size and shape for functional grasping by robot manipulators, such as pliers, utensils, and screwdrivers. Our annotation process is streamlined, requiring only a single off-the-shelf camera and semi-automated processing, allowing us to produce high-quality 3D annotations without crowd-sourcing. The dataset consists of 308k annotated image frames from 2.2k videos of 212 real-world objects in 17 categories. We focus on hardware and kitchen tool objects to facilitate research in practical scenarios in which a robot manipulator needs to interact with the environment beyond simple pushing or indiscriminate grasping. We outline the usefulness of our dataset for 6-DoF category-level pose+scale estimation and related tasks. We also provide 3D reconstructed meshes of all objects, and we outline some of the bottlenecks to be addressed for democratizing the collection of datasets like this one.
</details>
<details>
<summary>摘要</summary>
我们介绍了HANDAL数据集，用于分类水平对象pose估计和可行预测。与前一代数据集不同，我们的数据集专注于适用于机器人搅拌的可搅拌物品，包括锤子、工具和螺丝driver等，它们具有适合机器人搅拌的尺寸和形状。我们的注释过程涉及了单一的商业摄像头和半自动化处理，使得我们可以生成高质量3D注释而无需咨询大量人员。数据集包含308万个注释图像帧，来自2.2万个视频，212种实际世界中的 объек。我们专注于硬件和厨房工具对象，以便在机器人搅拌需要与环境进行实际交互的场景中进行研究。我们详细介绍了我们数据集的用途，包括6个自由度分类pose+scale估计和相关任务。我们还提供了所有物品的3D重建模型，并详细介绍了数据集收集的一些瓶颈。
</details></li>
</ul>
<hr>
<h2 id="DLSIA-Deep-Learning-for-Scientific-Image-Analysis"><a href="#DLSIA-Deep-Learning-for-Scientific-Image-Analysis" class="headerlink" title="DLSIA: Deep Learning for Scientific Image Analysis"></a>DLSIA: Deep Learning for Scientific Image Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02559">http://arxiv.org/abs/2308.02559</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric J Roberts, Tanny Chavez, Alexander Hexemer, Petrus H. Zwart</li>
<li>for: 科研图像分析（Scientific Image Analysis）</li>
<li>methods: 使用Python编程语言、 convolutional neural network（CNN） architecture、autoencoders、U-Nets、MSDNets、Sparse Mixed-Scale Networks（SMSNets）等方法。</li>
<li>results: 提供可定制的CNN建模、抽象CNN复杂性、促进科研发现、促进交叉领域合作、驱动科研图像分析等。<details>
<summary>Abstract</summary>
We introduce DLSIA (Deep Learning for Scientific Image Analysis), a Python-based machine learning library that empowers scientists and researchers across diverse scientific domains with a range of customizable convolutional neural network (CNN) architectures for a wide variety of tasks in image analysis to be used in downstream data processing, or for experiment-in-the-loop computing scenarios. DLSIA features easy-to-use architectures such as autoencoders, tunable U-Nets, and parameter-lean mixed-scale dense networks (MSDNets). Additionally, we introduce sparse mixed-scale networks (SMSNets), generated using random graphs and sparse connections. As experimental data continues to grow in scale and complexity, DLSIA provides accessible CNN construction and abstracts CNN complexities, allowing scientists to tailor their machine learning approaches, accelerate discoveries, foster interdisciplinary collaboration, and advance research in scientific image analysis.
</details>
<details>
<summary>摘要</summary>
我们介绍DLSIA（深度学习科学影像分析），这是一个基于Python的机器学习库，它为科学家和研究人员提供了许多可自定义的卷积神经网络架构，用于各种影像分析任务，包括下游资料处理和实验运行 Computing enario。DLSIA 提供了易于使用的架构，例如自动编码器、可调 U-Net 和对数零对数网络（MSDNets）。此外，我们还引入了随机 Graph 和稀疏连接的稀疏混合网络（SMSNets）。随着实验数据的数量和复杂度不断增加，DLSIA 提供了可 accessible CNN 的建构和抽象，让科学家可以根据自己的机器学习方法，加速发现，促进跨领域合作，并进步科学影像分析研究。
</details></li>
</ul>
<hr>
<h2 id="COVID-VR-A-Deep-Learning-COVID-19-Classification-Model-Using-Volume-Rendered-Computer-Tomography"><a href="#COVID-VR-A-Deep-Learning-COVID-19-Classification-Model-Using-Volume-Rendered-Computer-Tomography" class="headerlink" title="COVID-VR: A Deep Learning COVID-19 Classification Model Using Volume-Rendered Computer Tomography"></a>COVID-VR: A Deep Learning COVID-19 Classification Model Using Volume-Rendered Computer Tomography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01433">http://arxiv.org/abs/2308.01433</a></li>
<li>repo_url: None</li>
<li>paper_authors: Noemi Maritza L. Romero, Ricco Vasconcellos, Mariana R. Mendoza, João L. D. Comba</li>
<li>for: 本研究旨在开发一种基于多视角Volume Rendering（VR）技术的肺疾病分类方法，以提供全面的肺部图像，并提高肺疾病识别的准确率。</li>
<li>methods: 本研究使用了深度学习模型，利用CT扫描图像作为输入，通过Volume Rendering技术生成多视角的肺部图像，并对这些图像进行分类。</li>
<li>results: 对比于传统的slice-based方法，本研究的方法能够更好地识别肺疾病，并且在使用私有数据和公共数据进行比较时，得到了相似的结果。<details>
<summary>Abstract</summary>
The COVID-19 pandemic presented numerous challenges to healthcare systems worldwide. Given that lung infections are prevalent among COVID-19 patients, chest Computer Tomography (CT) scans have frequently been utilized as an alternative method for identifying COVID-19 conditions and various other types of pulmonary diseases. Deep learning architectures have emerged to automate the identification of pulmonary disease types by leveraging CT scan slices as inputs for classification models. This paper introduces COVID-VR, a novel approach for classifying pulmonary diseases based on volume rendering images of the lungs captured from multiple angles, thereby providing a comprehensive view of the entire lung in each image. To assess the effectiveness of our proposal, we compared it against competing strategies utilizing both private data obtained from partner hospitals and a publicly available dataset. The results demonstrate that our approach effectively identifies pulmonary lesions and performs competitively when compared to slice-based methods.
</details>
<details>
<summary>摘要</summary>
COVID-19 大流行对全球医疗系统带来了很多挑战。由于封颈感染是 COVID-19 患者的常见症状，胸部计算机扫描（CT）扫描得到了广泛的应用，以确定 COVID-19 状况和其他类型的肺病。深度学习建筑在扫描肺部的 CT 扫描片中进行自动识别肺病类型。本文介绍了 COVID-VR，一种基于肺部体积渲染图像的新方法，以获取整个肺部的全面视图。为评估我们的提议效果，我们与合作医院提供的私人数据进行比较，以及公共可用的数据集。结果表明，我们的方法可以有效地识别肺病涂抹，并与 slice-based 方法相比竞争性强。
</details></li>
</ul>
<hr>
<h2 id="LiDAR-View-Synthesis-for-Robust-Vehicle-Navigation-Without-Expert-Labels"><a href="#LiDAR-View-Synthesis-for-Robust-Vehicle-Navigation-Without-Expert-Labels" class="headerlink" title="LiDAR View Synthesis for Robust Vehicle Navigation Without Expert Labels"></a>LiDAR View Synthesis for Robust Vehicle Navigation Without Expert Labels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01424">http://arxiv.org/abs/2308.01424</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jonathsch/lidar-synthesis">https://github.com/jonathsch/lidar-synthesis</a></li>
<li>paper_authors: Jonathan Schmidt, Qadeer Khan, Daniel Cremers</li>
<li>for: 本研究旨在提供一种使用LiDAR扫描仪生成更多的训练数据集，以便在公共道路上安全地自动驾驶汽车。</li>
<li>methods: 本研究使用 mesh reconstruction 和 ray casting 技术生成更多的 LiDAR 点云，而无需实际驾驶车辆到危险位置。然后，使用深度学习模型，将 LiDAR 扫描结果作为输入，预测未来的车辆轨迹。最后，应用 waypoint controller 将预测轨迹与车辆的加速和转向标签相匹配。</li>
<li>results: 研究人员通过在线评估和与同期工作进行比较，证明了我们的方法的效iveness。特别是在模型稳定性方面，我们的方法具有显著的优势。项目页面：<a target="_blank" rel="noopener" href="https://jonathsch.github.io/lidar-synthesis/">https://jonathsch.github.io/lidar-synthesis/</a><details>
<summary>Abstract</summary>
Deep learning models for self-driving cars require a diverse training dataset to manage critical driving scenarios on public roads safely. This includes having data from divergent trajectories, such as the oncoming traffic lane or sidewalks. Such data would be too dangerous to collect in the real world. Data augmentation approaches have been proposed to tackle this issue using RGB images. However, solutions based on LiDAR sensors are scarce. Therefore, we propose synthesizing additional LiDAR point clouds from novel viewpoints without physically driving at dangerous positions. The LiDAR view synthesis is done using mesh reconstruction and ray casting. We train a deep learning model, which takes a LiDAR scan as input and predicts the future trajectory as output. A waypoint controller is then applied to this predicted trajectory to determine the throttle and steering labels of the ego-vehicle. Our method neither requires expert driving labels for the original nor the synthesized LiDAR sequence. Instead, we infer labels from LiDAR odometry. We demonstrate the effectiveness of our approach in a comprehensive online evaluation and with a comparison to concurrent work. Our results show the importance of synthesizing additional LiDAR point clouds, particularly in terms of model robustness. Project page: https://jonathsch.github.io/lidar-synthesis/
</details>
<details>
<summary>摘要</summary>
深度学习模型 для自驾车需要一个多样化的训练集，以确保在公共道路上安全地处理潜在危险的驾驶场景。这包括有 divergent 的轨迹，如对向道或人行道。然而，收集这些数据在实际世界中是太危险的。为解决这个问题，提出了使用 RGB 图像的数据增强方法。然而，基于 LiDAR 探测器的解决方案很少。因此，我们提议通过 mesh 重建和射线投影来生成额外的 LiDAR 点云。我们用一个深度学习模型，该模型从 LiDAR 扫描输入得到未来轨迹的预测结果。然后，我们应用一个 waypoint 控制器来确定 egocar 的加速和转向标签。我们的方法不需要原始 LiDAR 序列的专家驾驶标签，也不需要生成的 LiDAR 序列的专家标签。相反，我们从 LiDAR 速度来推断标签。我们在线评估中进行了全面的评估，并与当前的工作进行比较。我们的结果表明，生成额外的 LiDAR 点云对模型的稳定性具有重要作用。项目页面：https://jonathsch.github.io/lidar-synthesis/
</details></li>
</ul>
<hr>
<h2 id="Harder-synthetic-anomalies-to-improve-OoD-detection-in-Medical-Images"><a href="#Harder-synthetic-anomalies-to-improve-OoD-detection-in-Medical-Images" class="headerlink" title="Harder synthetic anomalies to improve OoD detection in Medical Images"></a>Harder synthetic anomalies to improve OoD detection in Medical Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01412">http://arxiv.org/abs/2308.01412</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/snavalm/mood22">https://github.com/snavalm/mood22</a></li>
<li>paper_authors: Sergio Naval Marimont, Giacomo Tarroni</li>
<li>for: 本研究旨在提高医学图像分割网络的泛化能力，使其能够在不同类型的异常情况下保持高度的准确率。</li>
<li>methods: 本研究使用了在2020年MOOD挑战赛中赢得奖的基于 Synthetic Local Anomaly (SLA) 的方法，并进一步改进了Synthetic anomaly生成过程，使它们更加多样化和挑战性。</li>
<li>results: 本研究在2022年MOOD挑战赛中获得了sample-wise和pixel-wise任务的首位， demonstrating the effectiveness of our method in improving the generalization ability of medical image segmentation networks.<details>
<summary>Abstract</summary>
Our method builds upon previous Medical Out-of-Distribution (MOOD) challenge winners that empirically show that synthetic local anomalies generated copying / interpolating foreign patches are useful to train segmentation networks able to generalize to unseen types of anomalies. In terms of the synthetic anomaly generation process, our contributions makes synthetic anomalies more heterogeneous and challenging by 1) using random shapes instead of squares and 2) smoothing the interpolation edge of anomalies so networks cannot rely on the high gradient between image - foreign patch to identify anomalies. Our experiments using the validation set of 2020 MOOD winners show that both contributions improved substantially the method performance. We used a standard 3D U-Net architecture as segmentation network, trained patch-wise in both brain and abdominal datasets. Our final challenge submission consisted of 10 U-Nets trained across 5 data folds with different configurations of the anomaly generation process. Our method achieved first position in both sample-wise and pixel-wise tasks in the 2022 edition of the Medical Out-of-Distribution held at MICCAI.
</details>
<details>
<summary>摘要</summary>
我们的方法建立在前一个医学异常（MOOD）挑战赛中赢家的基础上，这些赢家实证表明，通过复制/ interpolate 外部质 patches 生成的 synthetic local anomalies 可以帮助训练检测网络，以便在未经见过的异常类型上进行检测。在 synthetic anomaly 生成过程中，我们的贡献使 synthetic anomalies 更加多样和挑战性，包括：1. 使用随机形状而非方正形，2. 平滑 interpolate 边缘，以防止网络通过高Gradient между图像和外部质 patch 来识别异常。我们的实验使用 2020 MOOD 赛 validate set 表明，这两个贡献都有所提高了方法的性能。我们使用标准的 3D U-Net 架构作为检测网络，在脑和腹部数据集上进行 patch-wise 训练。我们的最终挑战提交包括 10 个 U-Nets 在 5 个数据叠加上不同的异常生成过程配置上进行训练。我们的方法在 2022 年的医学异常挑战中取得了 sample-wise 和 pixel-wise 两个任务中的第一名。
</details></li>
</ul>
<hr>
<h2 id="Follow-the-Soldiers-with-Optimized-Single-Shot-Multibox-Detection-and-Reinforcement-Learning"><a href="#Follow-the-Soldiers-with-Optimized-Single-Shot-Multibox-Detection-and-Reinforcement-Learning" class="headerlink" title="Follow the Soldiers with Optimized Single-Shot Multibox Detection and Reinforcement Learning"></a>Follow the Soldiers with Optimized Single-Shot Multibox Detection and Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01389">http://arxiv.org/abs/2308.01389</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jumman Hossain, Maliha Momtaz</li>
<li>for: 建立一个自动驾驶系统，跟踪特定人（这里是士兵）在任何方向移动。</li>
<li>methods: 使用深度汽车和强化学习模型。</li>
<li>results: SSD Lite 提供了较好的性能和大幅提高的测试速度（约2-3倍），并且不损害准确性。<details>
<summary>Abstract</summary>
Nowadays, autonomous cars are gaining traction due to their numerous potential applications on battlefields and in resolving a variety of other real-world challenges. The main goal of our project is to build an autonomous system using DeepRacer which will follow a specific person (for our project, a soldier) when they will be moving in any direction. Two main components to accomplish this project is an optimized Single-Shot Multibox Detection (SSD) object detection model and a Reinforcement Learning (RL) model. We accomplished the task using SSD Lite instead of SSD and at the end, compared the results among SSD, SSD with Neural Computing Stick (NCS), and SSD Lite. Experimental results show that SSD Lite gives better performance among these three techniques and exhibits a considerable boost in inference speed (~2-3 times) without compromising accuracy.
</details>
<details>
<summary>摘要</summary>
现在，自适应汽车正在得到推广，因为它们在战场和解决各种实际问题上具有广泛的应用前景。我们项目的主要目标是使用DeepRacer建立一个自动驾驶系统，该系统能跟踪一名士兵（在我们项目中）在任何方向移动时。我们项目的两个主要组成部分是优化单幅多框检测（SSD）模型和再征学习（RL）模型。我们使用SSD Lite而不是SSD，并在结尾对这三种技术进行比较。实验结果表明，SSD Lite在这三种技术中表现最佳，并且在执行速度方面表现出了明显的提升（约2-3倍）而无需牺牲准确性。
</details></li>
</ul>
<hr>
<h2 id="Computational-Long-Exposure-Mobile-Photography"><a href="#Computational-Long-Exposure-Mobile-Photography" class="headerlink" title="Computational Long Exposure Mobile Photography"></a>Computational Long Exposure Mobile Photography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01379">http://arxiv.org/abs/2308.01379</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric Tabellion, Nikhil Karnad, Noa Glaser, Ben Weiss, David E. Jacobs, Yael Pritch</li>
<li>for: 这篇论文是关于 computational burst photography system，用于实现长时间拍摄和运动融合的效果。</li>
<li>methods: 该系统使用了对象检测和分割、Scene motion tracking、多帧合成等技术来实现运动融合和长时间拍摄的效果。</li>
<li>results: 该系统可以自动地在手持式智能手机摄像头应用程序中实现运动融合和长时间拍摄的效果，并且可以保持图像的高分辨率和高动态范围。<details>
<summary>Abstract</summary>
Long exposure photography produces stunning imagery, representing moving elements in a scene with motion-blur. It is generally employed in two modalities, producing either a foreground or a background blur effect. Foreground blur images are traditionally captured on a tripod-mounted camera and portray blurred moving foreground elements, such as silky water or light trails, over a perfectly sharp background landscape. Background blur images, also called panning photography, are captured while the camera is tracking a moving subject, to produce an image of a sharp subject over a background blurred by relative motion. Both techniques are notoriously challenging and require additional equipment and advanced skills. In this paper, we describe a computational burst photography system that operates in a hand-held smartphone camera app, and achieves these effects fully automatically, at the tap of the shutter button. Our approach first detects and segments the salient subject. We track the scene motion over multiple frames and align the images in order to preserve desired sharpness and to produce aesthetically pleasing motion streaks. We capture an under-exposed burst and select the subset of input frames that will produce blur trails of controlled length, regardless of scene or camera motion velocity. We predict inter-frame motion and synthesize motion-blur to fill the temporal gaps between the input frames. Finally, we composite the blurred image with the sharp regular exposure to protect the sharpness of faces or areas of the scene that are barely moving, and produce a final high resolution and high dynamic range (HDR) photograph. Our system democratizes a capability previously reserved to professionals, and makes this creative style accessible to most casual photographers.   More information and supplementary material can be found on our project webpage: https://motion-mode.github.io/
</details>
<details>
<summary>摘要</summary>
长时间拍摄可以生成吸引人的图像，通过运动模糊来表现场景中运动元素。通常有两种模式：前景模式和背景模式。前景模式拍摄的图像通常在静止的摄像机上拍摄，捕捉了运动的前景元素，如水或光梯，与静止的背景景象一起呈现。背景模式拍摄的图像通常在跟踪运动目标的同时拍摄，以生成一个锐化的主题图像，与运动背景模糊的效果。两种技术都是非常具有挑战性，需要额外的设备和高级技能。在这篇论文中，我们描述了一种基于智能手机摄像机应用程序的计算拍摄系统，可以自动实现这些效果，只需要单击拍摄按钮。我们的方法首先检测和分割主题元素。我们跟踪场景运动，并将多帧图像对齐以保持愿望的锐化和生成美观的运动梯度。我们捕捉具有控制长度的下采样，无论场景或摄像机运动速度。我们预测帧间运动，并使用Synthesize动作模糊填充时间间隔。最后，我们将模糊图像与锐化正常曝光图像 composite，以保护面孔或动作较少的场景区域的锐化，并生成高分辨率和高动态范围的图像。我们的系统将这种创新技术普及化，让大多数优秀摄影家能够轻松地实现这种创新风格。更多信息和补充材料可以在我们项目网站中找到：<https://motion-mode.github.io/>
</details></li>
</ul>
<hr>
<h2 id="ELIXR-Towards-a-general-purpose-X-ray-artificial-intelligence-system-through-alignment-of-large-language-models-and-radiology-vision-encoders"><a href="#ELIXR-Towards-a-general-purpose-X-ray-artificial-intelligence-system-through-alignment-of-large-language-models-and-radiology-vision-encoders" class="headerlink" title="ELIXR: Towards a general purpose X-ray artificial intelligence system through alignment of large language models and radiology vision encoders"></a>ELIXR: Towards a general purpose X-ray artificial intelligence system through alignment of large language models and radiology vision encoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01317">http://arxiv.org/abs/2308.01317</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shawn Xu, Lin Yang, Christopher Kelly, Marcin Sieniek, Timo Kohlberger, Martin Ma, Wei-Hung Weng, Attila Kiraly, Sahar Kazemzadeh, Zakkai Melamed, Jungyeon Park, Patricia Strachan, Yun Liu, Chuck Lau, Preeti Singh, Christina Chen, Mozziyar Etemadi, Sreenivasa Raju Kalidindi, Yossi Matias, Katherine Chou, Greg S. Corrado, Shravya Shetty, Daniel Tse, Shruthi Prabhakara, Daniel Golden, Rory Pilgrim, Krish Eswaran, Andrew Sellergren<br>for:* 这个研究旨在开发一个具有广泛应用能力的语言&#x2F;图像同步类型（ELIXR），用于进行胸部X射像（CXR）分类、数据有效分类和semantic搜寻等多种任务。methods:* 这个研究使用了一个语言同步图像编码器，与固定的语言模型PaLM 2结合，实现了一个轻量级的适配器架构。* 研究使用了MIMIC-CXR dataset上的图像和相应的自由文本医学报告进行训练。results:* ELIXR在零shot胸部X射像（CXR）分类中实现了state-of-the-art性能（mean AUC of 0.850 across 13 findings）。* ELIXR在数据有效CXR分类中实现了高性能（mean AUCs of 0.893 and 0.898 across five findings），并在几个不同的数据量下进行了比较（1%、10%）。* ELIXR在semantic搜寻任务中实现了0.76的normalized discounted cumulative gain（NDCG），包括了一些完美的回答。<details>
<summary>Abstract</summary>
Our approach, which we call Embeddings for Language/Image-aligned X-Rays, or ELIXR, leverages a language-aligned image encoder combined or grafted onto a fixed LLM, PaLM 2, to perform a broad range of tasks. We train this lightweight adapter architecture using images paired with corresponding free-text radiology reports from the MIMIC-CXR dataset. ELIXR achieved state-of-the-art performance on zero-shot chest X-ray (CXR) classification (mean AUC of 0.850 across 13 findings), data-efficient CXR classification (mean AUCs of 0.893 and 0.898 across five findings (atelectasis, cardiomegaly, consolidation, pleural effusion, and pulmonary edema) for 1% (~2,200 images) and 10% (~22,000 images) training data), and semantic search (0.76 normalized discounted cumulative gain (NDCG) across nineteen queries, including perfect retrieval on twelve of them). Compared to existing data-efficient methods including supervised contrastive learning (SupCon), ELIXR required two orders of magnitude less data to reach similar performance. ELIXR also showed promise on CXR vision-language tasks, demonstrating overall accuracies of 58.7% and 62.5% on visual question answering and report quality assurance tasks, respectively. These results suggest that ELIXR is a robust and versatile approach to CXR AI.
</details>
<details>
<summary>摘要</summary>
我们的方法，我们称之为语言/图像对齐X射线（ELIXR），利用一个语言对齐图像编码器与固定的自然语言处理模型（PaLM 2）结合，以实现广泛的任务。我们使用图像和相应的自由文本医学报告从MIMIC-CXR数据集进行训练这个轻量级适配器建筑。ELIXR在零shot肺X射线（CXR）分类中达到了状态元的性能（平均AUC为0.850，涵盖13个发现），以及数据效率CXR分类（平均AUC为0.893和0.898，涵盖五个发现（肿瘤、心脏肥大、混合、肺液和肺血液）），并在semantic搜索中达到了0.76减少积分率（NDCG）。相比现有的数据效率方法，包括supervised contrastive learning（SupCon），ELIXR需要两个数据量级下降到达到类似性能。此外，ELIXR还在CXR视言语任务中表现出了承诺，其总准确率为58.7%和62.5%。这些结果表明ELIXR是一种强大和多功能的CXR AI方法。
</details></li>
</ul>
<hr>
<h2 id="Patched-Denoising-Diffusion-Models-For-High-Resolution-Image-Synthesis"><a href="#Patched-Denoising-Diffusion-Models-For-High-Resolution-Image-Synthesis" class="headerlink" title="Patched Denoising Diffusion Models For High-Resolution Image Synthesis"></a>Patched Denoising Diffusion Models For High-Resolution Image Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01316">http://arxiv.org/abs/2308.01316</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zheng Ding, Mengqi Zhang, Jiajun Wu, Zhuowen Tu</li>
<li>for: 生成高分辨率图像（例如1024×512）</li>
<li>methods: 使用小尺寸图像块（例如64×64）进行训练，并使用新的特征质料策略来避免边缘artefact</li>
<li>results: 在自然图像集（1024×512）和标准的小尺寸图像集（256×256）上实现高质量图像生成，并在所有四个数据集上达到了当前最佳FID分数。同时，Patch-DM还比 классиic diffusion模型减少了内存复杂度。<details>
<summary>Abstract</summary>
We propose an effective denoising diffusion model for generating high-resolution images (e.g., 1024$\times$512), trained on small-size image patches (e.g., 64$\times$64). We name our algorithm Patch-DM, in which a new feature collage strategy is designed to avoid the boundary artifact when synthesizing large-size images. Feature collage systematically crops and combines partial features of the neighboring patches to predict the features of a shifted image patch, allowing the seamless generation of the entire image due to the overlap in the patch feature space. Patch-DM produces high-quality image synthesis results on our newly collected dataset of nature images (1024$\times$512), as well as on standard benchmarks of smaller sizes (256$\times$256), including LSUN-Bedroom, LSUN-Church, and FFHQ. We compare our method with previous patch-based generation methods and achieve state-of-the-art FID scores on all four datasets. Further, Patch-DM also reduces memory complexity compared to the classic diffusion models.
</details>
<details>
<summary>摘要</summary>
我们提出一种有效的杂噪扩散模型，用于生成高分辨率图像（例如1024×512），基于小尺寸图像块（例如64×64）进行训练。我们命名该算法为“Patch-DM”，其中我们设计了一种新的特征贯通策略，以避免边缘artefact when Synthesizing large-size images。特征贯通系统系统地剪辑并组合邻近块的部分特征，以预测shifted image块的特征，从而实现了整个图像的无缝生成，因为邻近块特征空间之间存在 overlap。Patch-DM生成了高质量的图像合成结果在我们新收集的自然图像 dataset（1024×512）上，以及标准的小尺寸 benchmark（256×256）上，包括LSUN-Bedroom、LSUN-Church和FFHQ。我们与前期的patch-based生成方法进行比较，并在所有四个 dataset上实现了状态的方程FID scores。此外，Patch-DM还降低了传统扩散模型的内存复杂性。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-DETR-Pre-training-for-Object-Detection"><a href="#Revisiting-DETR-Pre-training-for-Object-Detection" class="headerlink" title="Revisiting DETR Pre-training for Object Detection"></a>Revisiting DETR Pre-training for Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01300">http://arxiv.org/abs/2308.01300</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yan Ma, Weicong Liang, Yiduo Hao, Bohan Chen, Xiangyu Yue, Chao Zhang, Yuhui Yuan</li>
<li>for: 本研究目的是研究如何通过自动学习的方式提高DETR基础模型的性能，而不需要更改其底层结构。</li>
<li>methods: 本研究使用了多种自动学习方法，包括DETReg和LLaVA等。</li>
<li>results: 研究发现，使用这些自动学习方法可以提高COCO物体检测任务的性能，并且可以超越最新的State-of-the-art模型。 Specifically, the authors achieved an AP of $59.3%$ on the COCO val set, surpassing the previous state-of-the-art model by $1.4%$. Additionally, the authors generated a series of synthetic pre-training datasets and demonstrated that pre-training on these datasets can lead to notable improvements in object detection performance.<details>
<summary>Abstract</summary>
Motivated by that DETR-based approaches have established new records on COCO detection and segmentation benchmarks, many recent endeavors show increasing interest in how to further improve DETR-based approaches by pre-training the Transformer in a self-supervised manner while keeping the backbone frozen. Some studies already claimed significant improvements in accuracy. In this paper, we take a closer look at their experimental methodology and check if their approaches are still effective on the very recent state-of-the-art such as $\mathcal{H}$-Deformable-DETR. We conduct thorough experiments on COCO object detection tasks to study the influence of the choice of pre-training datasets, localization, and classification target generation schemes. Unfortunately, we find the previous representative self-supervised approach such as DETReg, fails to boost the performance of the strong DETR-based approaches on full data regimes. We further analyze the reasons and find that simply combining a more accurate box predictor and Objects$365$ benchmark can significantly improve the results in follow-up experiments. We demonstrate the effectiveness of our approach by achieving strong object detection results of AP=$59.3\%$ on COCO val set, which surpasses $\mathcal{H}$-Deformable-DETR + Swin-L by +$1.4\%$. Last, we generate a series of synthetic pre-training datasets by combining the very recent image-to-text captioning models (LLaVA) and text-to-image generative models (SDXL). Notably, pre-training on these synthetic datasets leads to notable improvements in object detection performance. Looking ahead, we anticipate substantial advantages through the future expansion of the synthetic pre-training dataset.
</details>
<details>
<summary>摘要</summary>
基于DETR的方法在COCO检测和 segmentation  bencmarks 上设置新的纪录，许多最近的尝试表示越来越关注如何进一步提高DETR基于的方法，而不是固定背景。一些研究已经提出了显著改进的精度。在这篇文章中，我们坚持更加仔细地检查这些实验方法，并查看它们是否在最新的state-of-the-art 中如 $\mathcal{H}$-Deformable-DETR 中保持有效。我们在COCO对象检测任务中进行了系统的实验，以研究预训练数据集的选择、本地化和分类目标生成方案的影响。不幸地，我们发现以前的代表性自我超vised 方法DETReg，在全数据场景下不能提高强大 DE TR-based 方法的性能。我们进一步分析了原因，并发现可以通过结合更高精度的包Predictor和Objects$365$ benchmark来显著提高结果。我们证明了我们的方法的效果，通过在COCO验证集上达到 AP = $59.3\%$ 的强大对象检测结果，超过 $\mathcal{H}$-Deformable-DETR + Swin-L 的 + $1.4\%$。最后，我们生成了一系列的Synthetic pre-training datasets，通过结合最近的图文描述模型（LLaVA）和文本到图生成模型（SDXL）。不凡地，预训练在这些Synthetic datasets上显著提高了对象检测性能。looking ahead，我们预计将来的扩展将带来重要的优势。
</details></li>
</ul>
<hr>
<h2 id="A-vision-transformer-based-framework-for-knowledge-transfer-from-multi-modal-to-mono-modal-lymphoma-subtyping-models"><a href="#A-vision-transformer-based-framework-for-knowledge-transfer-from-multi-modal-to-mono-modal-lymphoma-subtyping-models" class="headerlink" title="A vision transformer-based framework for knowledge transfer from multi-modal to mono-modal lymphoma subtyping models"></a>A vision transformer-based framework for knowledge transfer from multi-modal to mono-modal lymphoma subtyping models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01328">http://arxiv.org/abs/2308.01328</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bilel Guetarni, Feryal Windal, Halim Benhabiles, Marianne Petit, Romain Dubois, Emmanuelle Leteurtre, Dominique Collard</li>
<li>for: 本研究旨在提出一种基于视Transformer的框架，用于从高分辨率整图中分类Diffuse Large B-Cell Lymphoma（DLBCL）癌症subtype。</li>
<li>methods: 我们提议一种多模式 architecture来训练一个分类模型，从多种整图模式中提取特征。然后，我们通过知识传播机制来高效地驱动这个分类模型的学习。</li>
<li>results: 我们在一个包含157个病例的实验study中发现，我们的单模式分类模型的表现非常出色，比六个最新的抗癌方法更高效。此外，我们对实验数据进行了power-law曲线估算，结果表明，我们的分类模型需要一个合理的数量的更多病例来进行训练，以达到与IHC技术相同的诊断精度。<details>
<summary>Abstract</summary>
Determining lymphoma subtypes is a crucial step for better patients treatment targeting to potentially increase their survival chances. In this context, the existing gold standard diagnosis method, which is based on gene expression technology, is highly expensive and time-consuming making difficult its accessibility. Although alternative diagnosis methods based on IHC (immunohistochemistry) technologies exist (recommended by the WHO), they still suffer from similar limitations and are less accurate. WSI (Whole Slide Image) analysis by deep learning models showed promising new directions for cancer diagnosis that would be cheaper and faster than existing alternative methods. In this work, we propose a vision transformer-based framework for distinguishing DLBCL (Diffuse Large B-Cell Lymphoma) cancer subtypes from high-resolution WSIs. To this end, we propose a multi-modal architecture to train a classifier model from various WSI modalities. We then exploit this model through a knowledge distillation mechanism for efficiently driving the learning of a mono-modal classifier. Our experimental study conducted on a dataset of 157 patients shows the promising performance of our mono-modal classification model, outperforming six recent methods from the state-of-the-art dedicated for cancer classification. Moreover, the power-law curve, estimated on our experimental data, shows that our classification model requires a reasonable number of additional patients for its training to potentially reach identical diagnosis accuracy as IHC technologies.
</details>
<details>
<summary>摘要</summary>
确定淋巴癌 subclass 是诊断患者治疗的关键步骤，以提高生存可能性。然而，现有的黄金标准诊断方法，基于基因表达技术，是非常昂贵和时间consuming，使其Difficult to access。尽管现有基于 IHC（免疫抗体技术）的诊断方法存在，但它们仍然受到限制，并且精度较低。WSI（整个板块图像）分析by deep learning模型显示了新的方向 для肿瘤诊断，这将比现有的alternative方法更便宜和更快。在这项工作中，我们提出了基于视Transformer的框架，用于从高分辨率 WSI 中分类Diffuse Large B-Cell Lymphoma（淋巴癌）亚型。为此，我们提出了一种多modal architecture，用于训练一个分类模型。然后，我们利用知识储存机制，将这个模型转化为一个简单的单modal分类器。我们的实验研究，在一个包含 157 名病人的数据集上进行，显示了我们的单modal分类模型在诊断性能方面的优秀表现，比六个最新的state-of-the-art肿瘤分类方法更高。此外，我们在实验数据上计算的力量律曲线，表明我们的分类模型需要一个合理的数量的更多病人来进行训练，以达到与 IHC 技术相同的诊断精度。
</details></li>
</ul>
<hr>
<h2 id="Incorporating-Season-and-Solar-Specificity-into-Renderings-made-by-a-NeRF-Architecture-using-Satellite-Images"><a href="#Incorporating-Season-and-Solar-Specificity-into-Renderings-made-by-a-NeRF-Architecture-using-Satellite-Images" class="headerlink" title="Incorporating Season and Solar Specificity into Renderings made by a NeRF Architecture using Satellite Images"></a>Incorporating Season and Solar Specificity into Renderings made by a NeRF Architecture using Satellite Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01262">http://arxiv.org/abs/2308.01262</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/enterprisecv-6/season-nerf">https://github.com/enterprisecv-6/season-nerf</a></li>
<li>paper_authors: Michael Gableman, Avinash Kak</li>
<li>for: 这篇论文的目的是提出一种基于NeRF的渲染框架，可以根据卫星图像进行训练，并考虑太阳角度和视角角度来渲染场景从不同的视角。</li>
<li>methods: 该论文使用Neural Radiance Field（NeRF）来模型场景的光照和阴影，并在NeRF中引入一个新的输入变量——年份，以教育网络render seasonal features。</li>
<li>results: 作者在八个Area of Interest中测试了他们的框架，并获得了高精度的渲染、高精度的高度图和预测阴影等结果。此外，作者还进行了ablation study，以 justify network design parameters。<details>
<summary>Abstract</summary>
As a result of Shadow NeRF and Sat-NeRF, it is possible to take the solar angle into account in a NeRF-based framework for rendering a scene from a novel viewpoint using satellite images for training. Our work extends those contributions and shows how one can make the renderings season-specific. Our main challenge was creating a Neural Radiance Field (NeRF) that could render seasonal features independently of viewing angle and solar angle while still being able to render shadows. We teach our network to render seasonal features by introducing one more input variable -- time of the year. However, the small training datasets typical of satellite imagery can introduce ambiguities in cases where shadows are present in the same location for every image of a particular season. We add additional terms to the loss function to discourage the network from using seasonal features for accounting for shadows. We show the performance of our network on eight Areas of Interest containing images captured by the Maxar WorldView-3 satellite. This evaluation includes tests measuring the ability of our framework to accurately render novel views, generate height maps, predict shadows, and specify seasonal features independently from shadows. Our ablation studies justify the choices made for network design parameters.
</details>
<details>
<summary>摘要</summary>
due to Shadow NeRF and Sat-NeRF, it is possible to take the solar angle into account in a NeRF-based framework for rendering a scene from a novel viewpoint using satellite images for training. Our work extends those contributions and shows how one can make the renderings season-specific. Our main challenge was creating a Neural Radiance Field (NeRF) that could render seasonal features independently of viewing angle and solar angle while still being able to render shadows. We teach our network to render seasonal features by introducing one more input variable -- time of the year. However, the small training datasets typical of satellite imagery can introduce ambiguities in cases where shadows are present in the same location for every image of a particular season. We add additional terms to the loss function to discourage the network from using seasonal features for accounting for shadows. We show the performance of our network on eight Areas of Interest containing images captured by the Maxar WorldView-3 satellite. This evaluation includes tests measuring the ability of our framework to accurately render novel views, generate height maps, predict shadows, and specify seasonal features independently from shadows. Our ablation studies justify the choices made for network design parameters.Here's the translation in Traditional Chinese:这是由于阴影NeRF和Sat-NeRF而可以将太阳角度考虑到NeRF基础框架中，以便从不同观点测量场景。我们的工作延伸了这些贡献，并显示了如何使渲染为季节特定。我们的主要挑战是创建一个能够独立地考虑观察角度和太阳角度的Neural Radiance Field（NeRF），并且仍能正确地显示阴影。我们教育我们的网络以时间年份为输入变量，以便在不同季节中显示季节特定的特征。然而，对于具有阴影的几何形状的实际测试数据可能会导致歧义。我们添加了额外的损失函数来防止网络使用季节特定的特征来计算阴影。我们在八个Area of Interest中展示了我们的网络，包括量测系统在不同观点下的渲染新视野、生成高度图、预测阴影和季节特定的特征独立于阴影。我们的ablation研究证明了我们的网络设计选择的正确性。
</details></li>
</ul>
<hr>
<h2 id="Learning-Spatial-Distribution-of-Long-Term-Trackers-Scores"><a href="#Learning-Spatial-Distribution-of-Long-Term-Trackers-Scores" class="headerlink" title="Learning Spatial Distribution of Long-Term Trackers Scores"></a>Learning Spatial Distribution of Long-Term Trackers Scores</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01256">http://arxiv.org/abs/2308.01256</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vincenzo Mariano Scarrica, Antonino Staiano</li>
<li>for: 这篇论文是为了提高长期跟踪性能而写的。</li>
<li>methods: 这篇论文使用了融合策略，将多个基线跟踪器作为输入，并在学习阶段对其进行了优化。</li>
<li>results: 在LTB-50数据集上，这篇论文的召回率为0.738，与当前状态前进行竞争。在反向使用VOT-LT2022和LTB-50数据集时，召回率为0.619，仍然在当前状态前进行竞争。<details>
<summary>Abstract</summary>
Long-Term tracking is a hot topic in Computer Vision. In this context, competitive models are presented every year, showing a constant growth rate in performances, mainly measured in standardized protocols as Visual Object Tracking (VOT) and Object Tracking Benchmark (OTB). Fusion-trackers strategy has been applied over last few years for overcoming the known re-detection problem, turning out to be an important breakthrough. Following this approach, this work aims to generalize the fusion concept to an arbitrary number of trackers used as baseline trackers in the pipeline, leveraging a learning phase to better understand how outcomes correlate with each other, even when no target is present. A model and data independence conjecture will be evidenced in the manuscript, yielding a recall of 0.738 on LTB-50 dataset when learning from VOT-LT2022, and 0.619 by reversing the two datasets. In both cases, results are strongly competitive with state-of-the-art and recall turns out to be the first on the podium.
</details>
<details>
<summary>摘要</summary>
长期跟踪是计算机视觉领域热点话题。在这个上下文中，每年都有竞争力强的模型被推出，表现得越来越好，主要根据标准化协议进行评估，如视觉 объекtracking（VOT）和物体跟踪benchmark（OTB）。遗传跟踪策略在过去几年得到应用，并被视为重要的突破。基于这种方法，本研究旨在普适化融合概念，使得任意数量的基线跟踪器可以在管道中使用，并通过学习阶段更好地理解不同跟踪器之间的结果相关性，即使target不存在。 manuscript中会证明模型和数据独立性 conjecture，在LTB-50 dataset上取得0.738的回归率，并在反向两个dataset上取得0.619的回归率。在两个情况下，结果强烈竞争与状态机器人，并且回归率处于第一名。
</details></li>
</ul>
<hr>
<h2 id="A-Hyper-pixel-wise-Contrastive-Learning-Augmented-Segmentation-Network-for-Old-Landslide-Detection-Using-High-Resolution-Remote-Sensing-Images-and-Digital-Elevation-Model-Data"><a href="#A-Hyper-pixel-wise-Contrastive-Learning-Augmented-Segmentation-Network-for-Old-Landslide-Detection-Using-High-Resolution-Remote-Sensing-Images-and-Digital-Elevation-Model-Data" class="headerlink" title="A Hyper-pixel-wise Contrastive Learning Augmented Segmentation Network for Old Landslide Detection Using High-Resolution Remote Sensing Images and Digital Elevation Model Data"></a>A Hyper-pixel-wise Contrastive Learning Augmented Segmentation Network for Old Landslide Detection Using High-Resolution Remote Sensing Images and Digital Elevation Model Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01251">http://arxiv.org/abs/2308.01251</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiming Zhou, Yuexing Peng, Wei Li, Junchuan Yu, Daqing Ge, Wei Xiang</li>
<li>for: old landslide detection</li>
<li>methods: hyper-pixel-wise contrastive learning augmented segmentation network (HPCL-Net) and global hyper-pixel-wise sample pair queues-based contrastive learning method</li>
<li>results: improved reliability of old landslide detection compared to previous models, with increased mIoU, Landslide IoU, and F1-score metrics<details>
<summary>Abstract</summary>
As a harzard disaster, landslide often brings tremendous losses to humanity, so it's necessary to achieve reliable detection of landslide. However, the problems of visual blur and small-sized dataset cause great challenges for old landslide detection task when using remote sensing data. To reliably extract semantic features, a hyper-pixel-wise contrastive learning augmented segmentation network (HPCL-Net) is proposed, which augments the local salient feature extraction from the boundaries of landslides through HPCL and fuses the heterogeneous infromation in the semantic space from High-Resolution Remote Sensing Images and Digital Elevation Model Data data. For full utilization of the precious samples, a global hyper-pixel-wise sample pair queues-based contrastive learning method, which includes the construction of global queues that store hyper-pixel-wise samples and the updating scheme of a momentum encoder, is developed, reliably enhancing the extraction ability of semantic features. The proposed HPCL-Net is evaluated on a Loess Plateau old landslide dataset and experiment results show that the model greatly improves the reliablity of old landslide detection compared to the previous old landslide segmentation model, where mIoU metric is increased from 0.620 to 0.651, Landslide IoU metric is increased from 0.334 to 0.394 and F1-score metric is increased from 0.501 to 0.565.
</details>
<details>
<summary>摘要</summary>
翻译文本作为危险灾害，山崩常会对人类造成巨大的损害，因此需要实现可靠的山崩检测。然而，使用遥感数据时，视觉模糊和小样本集的问题会导致古老山崩检测任务中的巨大挑战。为了可靠地提取semantic特征，我们提议了一种基于hyper-pixel-wise对比学习增强segmentation网络（HPCL-Net），该网络通过在山崩边界的本地精重特征提取方法和高分辨率遥感图像和数字高程模型数据的异化信息进行semantic空间的笔记卷积。为了充分利用珍贵的样本，我们开发了一种全球hyper-pixel-wise对比学习方法，该方法包括建立全球队列，并且在批处理队列中进行快速更新的批处理编码器。实验结果表明，提议的HPCL-Net模型在中国Loess Plateau古老山崩数据集上进行检测比前一代古老山崩分割模型更高度可靠，其mIoU指标从0.620提高到0.651，山崩指标从0.334提高到0.394，F1-score指标从0.501提高到0.565。
</details></li>
</ul>
<hr>
<h2 id="A-Hybrid-Approach-To-Real-Time-Multi-Object-Tracking"><a href="#A-Hybrid-Approach-To-Real-Time-Multi-Object-Tracking" class="headerlink" title="A Hybrid Approach To Real-Time Multi-Object Tracking"></a>A Hybrid Approach To Real-Time Multi-Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01248">http://arxiv.org/abs/2308.01248</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vincenzo Mariano Scarrica, Ciro Panariello, Alessio Ferone, Antonino Staiano</li>
<li>for: 这个论文主要目标是提出一种基于深度学习和经典算法的实时多目标跟踪方法，用于人群跟踪系统。</li>
<li>methods: 该方法 combinestraditional optical flow algorithm和深度学习架构，以实现一个具有折衔的跟踪精度和计算成本的权衡。</li>
<li>results: 对不同设置进行实验，该方法可以达到0.608的MOTA分数，与相关State-of-the-art的0.549分数相当，而且运行时间减少了约一半。<details>
<summary>Abstract</summary>
Multi-Object Tracking, also known as Multi-Target Tracking, is a significant area of computer vision that has many uses in a variety of settings. The development of deep learning, which has encouraged researchers to propose more and more work in this direction, has significantly impacted the scientific advancement around the study of tracking as well as many other domains related to computer vision. In fact, all of the solutions that are currently state-of-the-art in the literature and in the tracking industry, are built on top of deep learning methodologies that produce exceptionally good results. Deep learning is enabled thanks to the ever more powerful technology researchers can use to handle the significant computational resources demanded by these models. However, when real-time is a main requirement, developing a tracking system without being constrained by expensive hardware support with enormous computational resources is necessary to widen tracking applications in real-world contexts. To this end, a compromise is to combine powerful deep strategies with more traditional approaches to favor considerably lower processing solutions at the cost of less accurate tracking results even though suitable for real-time domains. Indeed, the present work goes in that direction, proposing a hybrid strategy for real-time multi-target tracking that combines effectively a classical optical flow algorithm with a deep learning architecture, targeted to a human-crowd tracking system exhibiting a desirable trade-off between performance in tracking precision and computational costs. The developed architecture was experimented with different settings, and yielded a MOTA of 0.608 out of the compared state-of-the-art 0.549 results, and about half the running time when introducing the optical flow phase, achieving almost the same performance in terms of accuracy.
</details>
<details>
<summary>摘要</summary>
多目标跟踪（也称多Target tracking）是计算机视觉领域的一个重要领域，它在各种场景中有很多应用。深度学习的发展，使研究人员们能够更加勇敢地提出更多的工作，对跟踪领域以及其他计算机视觉领域的科学进步产生了深远的影响。实际上，现有literature和industry中的所有state-of-the-art解决方案都基于深度学习方法，其Result exceptionally good。然而，当实时是主要要求时，建立一个不受昂贵硬件支持的跟踪系统是必要的，以拓宽跟踪应用在真实世界中。为此，可以通过结合强大的深度策略和传统方法来达成一个折衔，以提高跟踪精度的同时，降低计算成本。本工作就在这个方向上进行了尝试，提出了一种hybrid策略，将经典的光流算法与深度学习架构相结合，用于人群跟踪系统，实现了精度和计算成本之间的折衔。实验结果显示，与比较state-of-the-art的0.549结果相比，该系统的MOTA得分为0.608，运行时间缩短了约一半。
</details></li>
</ul>
<hr>
<h2 id="Tirtha-–-An-Automated-Platform-to-Crowdsource-Images-and-Create-3D-Models-of-Heritage-Sites"><a href="#Tirtha-–-An-Automated-Platform-to-Crowdsource-Images-and-Create-3D-Models-of-Heritage-Sites" class="headerlink" title="Tirtha – An Automated Platform to Crowdsource Images and Create 3D Models of Heritage Sites"></a>Tirtha – An Automated Platform to Crowdsource Images and Create 3D Models of Heritage Sites</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01246">http://arxiv.org/abs/2308.01246</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/smlab-niser/tirtha-public">https://github.com/smlab-niser/tirtha-public</a></li>
<li>paper_authors: Jyotirmaya Shivottam, Subhankar Mishra</li>
<li>for: 保护文化遗产（CH）sites的数字化保存是非常重要，以防止自然灾害或人类活动的损害。</li>
<li>methods: 使用现代计算机视觉和光学测量技术，创建CH sites的3D模型。</li>
<li>results: 创建了一个Web平台，让普通公众通过投稿照片来创建CH sites的3D模型，提高了数字保存效率、成本效果和可持续性。<details>
<summary>Abstract</summary>
Digital preservation of Cultural Heritage (CH) sites is crucial to protect them against damage from natural disasters or human activities. Creating 3D models of CH sites has become a popular method of digital preservation thanks to advancements in computer vision and photogrammetry. However, the process is time-consuming, expensive, and typically requires specialized equipment and expertise, posing challenges in resource-limited developing countries. Additionally, the lack of an open repository for 3D models hinders research and public engagement with their heritage. To address these issues, we propose Tirtha, a web platform for crowdsourcing images of CH sites and creating their 3D models. Tirtha utilizes state-of-the-art Structure from Motion (SfM) and Multi-View Stereo (MVS) techniques. It is modular, extensible and cost-effective, allowing for the incorporation of new techniques as photogrammetry advances. Tirtha is accessible through a web interface at https://tirtha.niser.ac.in and can be deployed on-premise or in a cloud environment. In our case studies, we demonstrate the pipeline's effectiveness by creating 3D models of temples in Odisha, India, using crowdsourced images. These models are available for viewing, interaction, and download on the Tirtha website. Our work aims to provide a dataset of crowdsourced images and 3D reconstructions for research in computer vision, heritage conservation, and related domains. Overall, Tirtha is a step towards democratizing digital preservation, primarily in resource-limited developing countries.
</details>
<details>
<summary>摘要</summary>
针对文化遗产（CH）场景的数字保存是非常重要，以保护它们免受自然灾害或人类活动的损害。创建CH场景的3D模型已成为数字保存的流行方法，感谢计算机视觉和光学测量的进步。然而，这个过程需要较长的时间，高昂的成本，通常需要专业设备和技能，这会对发展中国家 pose 挑战。此外，缺乏开放的3D模型存储库，限制了研究和公众对遗产的参与。为解决这些问题，我们提出了Tirtha，一个基于网络的平台，用于协同上传CH场景的图像。Tirtha利用当前最佳的结构从动（SfM）和多视图镜像（MVS）技术。它是可扩展的，可cost-effective，可以适应计算机视觉的进步。Tirtha通过Web界面提供，可以在本地部署或云端环境中部署。在我们的案例研究中，我们示例了在奥里萨（India）的寺庐场景中使用拍摄的图像创建3D模型。这些模型通过Tirtha网站上的浏览、互动和下载。我们的工作目标是提供一个由众所共同拍摄的图像和3D重建的数据集，用于计算机视觉、遗产保护和相关领域的研究。总之，Tirtha是一步向数字保存的民主化，特别是在发展中国家。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/03/cs.CV_2023_08_03/" data-id="closbroo800g60g886b67gyxb" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_03" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/03/cs.AI_2023_08_03/" class="article-date">
  <time datetime="2023-08-03T12:00:00.000Z" itemprop="datePublished">2023-08-03</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/03/cs.AI_2023_08_03/">cs.AI - 2023-08-03</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="The-Capability-of-Large-Language-Models-to-Measure-Psychiatric-Functioning"><a href="#The-Capability-of-Large-Language-Models-to-Measure-Psychiatric-Functioning" class="headerlink" title="The Capability of Large Language Models to Measure Psychiatric Functioning"></a>The Capability of Large Language Models to Measure Psychiatric Functioning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01834">http://arxiv.org/abs/2308.01834</a></li>
<li>repo_url: None</li>
<li>paper_authors: Isaac R. Galatzer-Levy, Daniel McDuff, Vivek Natarajan, Alan Karthikesalingam, Matteo Malgaroli</li>
<li>for:  This paper aims to investigate the ability of Large language models (LLMs) to predict psychiatric functioning from patient interviews and clinical descriptions without explicit training.</li>
<li>methods: The study uses Med-PaLM 2, a large language model explicitly trained on a large corpus of medical knowledge, to predict psychiatric functioning based on patient interviews and clinical descriptions.</li>
<li>results: The study finds that Med-PaLM 2 is capable of assessing psychiatric functioning across a range of psychiatric conditions, with the strongest performance in predicting depression scores based on standardized assessments. The results show the potential for general clinical language models to flexibly predict psychiatric risk based on free descriptions of functioning from both patients and clinicians.Here is the simplified Chinese version of the three key points:</li>
<li>for: 这篇论文旨在研究 Large language models (LLMs) 是否可以通过 patient 访问和临床描述来预测 психи治疗功能。</li>
<li>methods: 该研究使用 Med-PaLM 2，一个大型语言模型，通过 patient 访问和临床描述来预测 psycho 功能。</li>
<li>results: 研究发现 Med-PaLM 2 可以在各种 psycho 疾病中评估 psycho 功能，最强的表现在标准化评估中预测抑郁 scores，其准确率在 0.80 - 0.84 之间，与人类临床评估人员的准确率无 statistically distinguishable difference（t(1,144) &#x3D; 1.20; p &#x3D; 0.23），表明大型临床语言模型可以通过自由描述来预测 psycho 风险。<details>
<summary>Abstract</summary>
The current work investigates the capability of Large language models (LLMs) that are explicitly trained on large corpuses of medical knowledge (Med-PaLM 2) to predict psychiatric functioning from patient interviews and clinical descriptions without being trained to do so. To assess this, n = 145 depression and n =115 PTSD assessments and n = 46 clinical case studies across high prevalence/high comorbidity disorders (Depressive, Anxiety, Psychotic, trauma and stress, Addictive disorders) were analyzed using prompts to extract estimated clinical scores and diagnoses. Results demonstrate that Med-PaLM 2 is capable of assessing psychiatric functioning across a range of psychiatric conditions with the strongest performance being the prediction of depression scores based on standardized assessments (Accuracy range= 0.80 - 0.84) which were statistically indistinguishable from human clinical raters t(1,144) = 1.20; p = 0.23. Results show the potential for general clinical language models to flexibly predict psychiatric risk based on free descriptions of functioning from both patients and clinicians.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Learning-beyond-sensations-how-dreams-organize-neuronal-representations"><a href="#Learning-beyond-sensations-how-dreams-organize-neuronal-representations" class="headerlink" title="Learning beyond sensations: how dreams organize neuronal representations"></a>Learning beyond sensations: how dreams organize neuronal representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01830">http://arxiv.org/abs/2308.01830</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicolas Deperrois, Mihai A. Petrovici, Walter Senn, Jakob Jordan</li>
<li>for: 这 paper 探讨了大脑中高级感觉 cortices 中 semantic 表示的形成和维护机制，以及这些表示如何影响行为。</li>
<li>methods: 这 paper 使用了 predictive learning 理论和虚拟经验来解释 cortical 表示的形成和维护。</li>
<li>results: 这 paper 提出了 two complementary learning principles，即 “adversarial dreaming” 和 “contrastive dreaming”，这些原理可以解释 cortical 学习 beyond classical predictive learning paradigm.<details>
<summary>Abstract</summary>
Semantic representations in higher sensory cortices form the basis for robust, yet flexible behavior. These representations are acquired over the course of development in an unsupervised fashion and continuously maintained over an organism's lifespan. Predictive learning theories propose that these representations emerge from predicting or reconstructing sensory inputs. However, brains are known to generate virtual experiences, such as during imagination and dreaming, that go beyond previously experienced inputs. Here, we suggest that virtual experiences may be just as relevant as actual sensory inputs in shaping cortical representations. In particular, we discuss two complementary learning principles that organize representations through the generation of virtual experiences. First, "adversarial dreaming" proposes that creative dreams support a cortical implementation of adversarial learning in which feedback and feedforward pathways engage in a productive game of trying to fool each other. Second, "contrastive dreaming" proposes that the invariance of neuronal representations to irrelevant factors of variation is acquired by trying to map similar virtual experiences together via a contrastive learning process. These principles are compatible with known cortical structure and dynamics and the phenomenology of sleep thus providing promising directions to explain cortical learning beyond the classical predictive learning paradigm.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Hard-Adversarial-Example-Mining-for-Improving-Robust-Fairness"><a href="#Hard-Adversarial-Example-Mining-for-Improving-Robust-Fairness" class="headerlink" title="Hard Adversarial Example Mining for Improving Robust Fairness"></a>Hard Adversarial Example Mining for Improving Robust Fairness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01823">http://arxiv.org/abs/2308.01823</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenhao Lin, Xiang Ji, Yulong Yang, Qian Li, Chao Shen, Run Wang, Liming Fang</li>
<li>for: 本研究旨在提高深度神经网络（DNN）对假数据点（Adversarial Example，AE）的Robustness，同时解决隐性假数据点的不公平问题。</li>
<li>methods: 本研究提出了一种简单 yet effective的框架，即适应性 Hard Adversarial example Mining（HAM），通过适应性地挖掘硬AE来提高AT的效果。</li>
<li>results: 实验结果表明，HAM在CIFAR-10、SVHN和Imagenette等三个 benchmark上都达到了显著的改善robust fairness的效果，同时降低了计算成本。<details>
<summary>Abstract</summary>
Adversarial training (AT) is widely considered the state-of-the-art technique for improving the robustness of deep neural networks (DNNs) against adversarial examples (AE). Nevertheless, recent studies have revealed that adversarially trained models are prone to unfairness problems, restricting their applicability. In this paper, we empirically observe that this limitation may be attributed to serious adversarial confidence overfitting, i.e., certain adversarial examples with overconfidence. To alleviate this problem, we propose HAM, a straightforward yet effective framework via adaptive Hard Adversarial example Mining.HAM concentrates on mining hard adversarial examples while discarding the easy ones in an adaptive fashion. Specifically, HAM identifies hard AEs in terms of their step sizes needed to cross the decision boundary when calculating loss value. Besides, an early-dropping mechanism is incorporated to discard the easy examples at the initial stages of AE generation, resulting in efficient AT. Extensive experimental results on CIFAR-10, SVHN, and Imagenette demonstrate that HAM achieves significant improvement in robust fairness while reducing computational cost compared to several state-of-the-art adversarial training methods. The code will be made publicly available.
</details>
<details>
<summary>摘要</summary>
adversarial 训练（AT）是深度神经网络（DNN）的鲁棒性提升技术，却在实际应用中存在不公平问题。 recent studies have shown that adversarially trained models are prone to unfairness problems, limiting their applicability. In this paper, we empirically observe that this limitation may be attributed to serious adversarial confidence overfitting, i.e., certain adversarial examples with overconfidence. To alleviate this problem, we propose HAM, a straightforward yet effective framework via adaptive Hard Adversarial example Mining.HAM concentrates on mining hard adversarial examples while discarding the easy ones in an adaptive fashion. Specifically, HAM identifies hard AEs in terms of their step sizes needed to cross the decision boundary when calculating loss value. Besides, an early-dropping mechanism is incorporated to discard the easy examples at the initial stages of AE generation, resulting in efficient AT. extensive experimental results on CIFAR-10, SVHN, and Imagenette demonstrate that HAM achieves significant improvement in robust fairness while reducing computational cost compared to several state-of-the-art adversarial training methods. The code will be made publicly available.
</details></li>
</ul>
<hr>
<h2 id="Deep-Neural-Networks-Fused-with-Textures-for-Image-Classification"><a href="#Deep-Neural-Networks-Fused-with-Textures-for-Image-Classification" class="headerlink" title="Deep Neural Networks Fused with Textures for Image Classification"></a>Deep Neural Networks Fused with Textures for Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01813">http://arxiv.org/abs/2308.01813</a></li>
<li>repo_url: None</li>
<li>paper_authors: Asish Bera, Debotosh Bhattacharjee, Mita Nasipuri</li>
<li>for:  solves fine-grained image classification (FGIC) challenges by combining global texture with local patch-based information.</li>
<li>methods: 使用了批量模型（LSTM）和本地binary pattern（LBP）计算图像级别的文字特征，并将两条流水线结合为一个高效的特征向量。</li>
<li>results: 在 eight datasets 上（人脸、皮肤病变、食物、海洋生物等）使用四种标准底层CNN模型，实现了与现有方法相比的更高的分类精度。<details>
<summary>Abstract</summary>
Fine-grained image classification (FGIC) is a challenging task in computer vision for due to small visual differences among inter-subcategories, but, large intra-class variations. Deep learning methods have achieved remarkable success in solving FGIC. In this paper, we propose a fusion approach to address FGIC by combining global texture with local patch-based information. The first pipeline extracts deep features from various fixed-size non-overlapping patches and encodes features by sequential modelling using the long short-term memory (LSTM). Another path computes image-level textures at multiple scales using the local binary patterns (LBP). The advantages of both streams are integrated to represent an efficient feature vector for image classification. The method is tested on eight datasets representing the human faces, skin lesions, food dishes, marine lives, etc. using four standard backbone CNNs. Our method has attained better classification accuracy over existing methods with notable margins.
</details>
<details>
<summary>摘要</summary>
《细腔化图像分类（FGIC）是计算机视觉中的一项挑战，因为小视觉差异在间类之间很大，但是内类变化很大。深度学习方法在解决FGIC中得到了非常成功。在这篇论文中，我们提出了一种混合方法来解决FGIC，将全像Texture与本地小块信息混合。首条管道从不同大小的非重叠区域提取深度特征，然后使用长期短时间记忆（LSTM）编码特征。另一条管道在多尺度使用本地二进制模式（LBP）计算图像级别的Texture。两条管道的优点被集成，形成高效的特征向量，用于图像分类。我们在八个数据集上进行了测试，包括人脸、皮肤病变、食物碟、海洋生物等，使用四种标准背部CNN。我们的方法在现有方法中达到了更好的分类精度，差异较大。》Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Job-Shop-Scheduling-via-Deep-Reinforcement-Learning-a-Sequence-to-Sequence-approach"><a href="#Job-Shop-Scheduling-via-Deep-Reinforcement-Learning-a-Sequence-to-Sequence-approach" class="headerlink" title="Job Shop Scheduling via Deep Reinforcement Learning: a Sequence to Sequence approach"></a>Job Shop Scheduling via Deep Reinforcement Learning: a Sequence to Sequence approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01797">http://arxiv.org/abs/2308.01797</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dawoz/JSP-DeepRL-Seq2Seq">https://github.com/dawoz/JSP-DeepRL-Seq2Seq</a></li>
<li>paper_authors: Giovanni Bonetta, Davide Zago, Rossella Cancelliere, Andrea Grosso</li>
<li>for: 该论文旨在提出一种基于深度学习的Job调度算法，以自动学习调度规则。</li>
<li>methods: 该方法基于自然语言编码器-解码器模型，并未在任何其他任务中使用。</li>
<li>results: 实验结果表明，该方法可以超越多种传统优先级调度规则，并与当前最佳深度学习方法相比 display competitive 的结果。<details>
<summary>Abstract</summary>
Job scheduling is a well-known Combinatorial Optimization problem with endless applications. Well planned schedules bring many benefits in the context of automated systems: among others, they limit production costs and waste. Nevertheless, the NP-hardness of this problem makes it essential to use heuristics whose design is difficult, requires specialized knowledge and often produces methods tailored to the specific task. This paper presents an original end-to-end Deep Reinforcement Learning approach to scheduling that automatically learns dispatching rules. Our technique is inspired by natural language encoder-decoder models for sequence processing and has never been used, to the best of our knowledge, for scheduling purposes. We applied and tested our method in particular to some benchmark instances of Job Shop Problem, but this technique is general enough to be potentially used to tackle other different optimal job scheduling tasks with minimal intervention. Results demonstrate that we outperform many classical approaches exploiting priority dispatching rules and show competitive results on state-of-the-art Deep Reinforcement Learning ones.
</details>
<details>
<summary>摘要</summary>
This paper presents a novel end-to-end deep reinforcement learning approach to job scheduling that automatically learns dispatching rules. Our technique is inspired by natural language encoder-decoder models for sequence processing and has never been used for scheduling purposes, to the best of our knowledge. We applied and tested our method on some benchmark instances of the job shop problem, but it is general enough to be potentially used to tackle other optimal job scheduling tasks with minimal intervention.Our results demonstrate that we outperform many classical approaches that use priority dispatching rules and show competitive results with state-of-the-art deep reinforcement learning methods.
</details></li>
</ul>
<hr>
<h2 id="Guided-Distillation-for-Semi-Supervised-Instance-Segmentation"><a href="#Guided-Distillation-for-Semi-Supervised-Instance-Segmentation" class="headerlink" title="Guided Distillation for Semi-Supervised Instance Segmentation"></a>Guided Distillation for Semi-Supervised Instance Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02668">http://arxiv.org/abs/2308.02668</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tariq Berrada, Camille Couprie, Karteek Alahari, Jakob Verbeek</li>
<li>for: 提高实体 segmentation 模型的性能，减少依赖于完全标注的训练图像。</li>
<li>methods: 使用 semi-supervised 方法，利用无标注数据作为训练信号，限制模型过拟合标注样本。</li>
<li>results: 提高 teacher-student 填充模型的性能，在 Cityscapes 数据集上提高 mask-AP 从 23.7 到 33.9，在 COCO 数据集上提高 mask-AP 从 18.3 到 34.1，对比前一个状态的艺术。<details>
<summary>Abstract</summary>
Although instance segmentation methods have improved considerably, the dominant paradigm is to rely on fully-annotated training images, which are tedious to obtain. To alleviate this reliance, and boost results, semi-supervised approaches leverage unlabeled data as an additional training signal that limits overfitting to the labeled samples. In this context, we present novel design choices to significantly improve teacher-student distillation models. In particular, we (i) improve the distillation approach by introducing a novel "guided burn-in" stage, and (ii) evaluate different instance segmentation architectures, as well as backbone networks and pre-training strategies. Contrary to previous work which uses only supervised data for the burn-in period of the student model, we also use guidance of the teacher model to exploit unlabeled data in the burn-in period. Our improved distillation approach leads to substantial improvements over previous state-of-the-art results. For example, on the Cityscapes dataset we improve mask-AP from 23.7 to 33.9 when using labels for 10\% of images, and on the COCO dataset we improve mask-AP from 18.3 to 34.1 when using labels for only 1\% of the training data.
</details>
<details>
<summary>摘要</summary>
尽管实例分割方法已经有了很大的进步，但主流的方法仍然是通过完全标注的图像进行训练，这是费时的。为了减轻这种依赖，并提高结果，半超vised方法利用无标注数据作为训练信号，限制学习到标注样本上的过拟合。在这种情况下，我们提出了新的设计选择，以提高教师学生液态模型。具体来说，我们（i）改进了液态模型的适应方法，引入了一种新的“导向燃烧”阶段，以及（ii）评估不同的实例分割架构、背部网络和预训练策略。与前一些工作不同，我们在学生模型的烧入期间也使用导师模型的指导，以便利用无标注数据。我们改进的液态模型方法导致了对前一个状态的重大提高。例如，在Cityscapes dataset上，我们从23.7提高到33.9的mask-AP，并在COCO dataset上从18.3提高到34.1的mask-AP，只使用1%的训练数据上的标签。
</details></li>
</ul>
<hr>
<h2 id="MAP-A-Model-agnostic-Pretraining-Framework-for-Click-through-Rate-Prediction"><a href="#MAP-A-Model-agnostic-Pretraining-Framework-for-Click-through-Rate-Prediction" class="headerlink" title="MAP: A Model-agnostic Pretraining Framework for Click-through Rate Prediction"></a>MAP: A Model-agnostic Pretraining Framework for Click-through Rate Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01737">http://arxiv.org/abs/2308.01737</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chiangel/map-code">https://github.com/chiangel/map-code</a></li>
<li>paper_authors: Jianghao Lin, Yanru Qu, Wei Guo, Xinyi Dai, Ruiming Tang, Yong Yu, Weinan Zhang</li>
<li>for: 这 paper 是为了解决个性化在线服务的点击率预测问题，因为现有的 neural 模型 无法充分利用大量的用户点击记录数据。</li>
<li>methods: 这 paper 使用了自适应学习 paradigm，并提出了两种实用算法：偏挥特征预测 (MFP) 和替换特征检测 (RFD)，以利用大量的用户点击记录数据来提高点击率预测性能。</li>
<li>results: 实验结果表明，使用 MFP 和 RFD 可以在两个实际大规模数据集 (i.e., Avazu, Criteo) 上 achieve 新的州际纪录性能，并在多个强大的 backbone 上达到新的最佳性能。<details>
<summary>Abstract</summary>
With the widespread application of personalized online services, click-through rate (CTR) prediction has received more and more attention and research. The most prominent features of CTR prediction are its multi-field categorical data format, and vast and daily-growing data volume. The large capacity of neural models helps digest such massive amounts of data under the supervised learning paradigm, yet they fail to utilize the substantial data to its full potential, since the 1-bit click signal is not sufficient to guide the model to learn capable representations of features and instances. The self-supervised learning paradigm provides a more promising pretrain-finetune solution to better exploit the large amount of user click logs, and learn more generalized and effective representations. However, self-supervised learning for CTR prediction is still an open question, since current works on this line are only preliminary and rudimentary. To this end, we propose a Model-agnostic pretraining (MAP) framework that applies feature corruption and recovery on multi-field categorical data, and more specifically, we derive two practical algorithms: masked feature prediction (MFP) and replaced feature detection (RFD). MFP digs into feature interactions within each instance through masking and predicting a small portion of input features, and introduces noise contrastive estimation (NCE) to handle large feature spaces. RFD further turns MFP into a binary classification mode through replacing and detecting changes in input features, making it even simpler and more effective for CTR pretraining. Our extensive experiments on two real-world large-scale datasets (i.e., Avazu, Criteo) demonstrate the advantages of these two methods on several strong backbones (e.g., DCNv2, DeepFM), and achieve new state-of-the-art performance in terms of both effectiveness and efficiency for CTR prediction.
</details>
<details>
<summary>摘要</summary>
To address this issue, we propose a model-agnostic pretraining (MAP) framework that applies feature corruption and recovery on multi-field categorical data. Specifically, we derive two practical algorithms: masked feature prediction (MFP) and replaced feature detection (RFD). MFP digs into feature interactions within each instance through masking and predicting a small portion of input features, and introduces noise contrastive estimation (NCE) to handle large feature spaces. RFD further turns MFP into a binary classification mode through replacing and detecting changes in input features, making it simpler and more effective for CTR pretraining.Our extensive experiments on two real-world large-scale datasets (i.e., Avazu, Criteo) demonstrate the advantages of these two methods on several strong backbones (e.g., DCNv2, DeepFM), and achieve new state-of-the-art performance in terms of both effectiveness and efficiency for CTR prediction.
</details></li>
</ul>
<hr>
<h2 id="Towards-Self-organizing-Personal-Knowledge-Assistants-in-Evolving-Corporate-Memories"><a href="#Towards-Self-organizing-Personal-Knowledge-Assistants-in-Evolving-Corporate-Memories" class="headerlink" title="Towards Self-organizing Personal Knowledge Assistants in Evolving Corporate Memories"></a>Towards Self-organizing Personal Knowledge Assistants in Evolving Corporate Memories</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01732">http://arxiv.org/abs/2308.01732</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christian Jilek, Markus Schröder, Heiko Maus, Sven Schwarz, Andreas Dengel</li>
<li>for: 本研究旨在概述过去十年内我们部门对个人知识助手的自组织化研究，以及在不断发展的企业记忆中进行的应用。</li>
<li>methods: 本研究通常受到实际问题的启发，并在研究与业界合作伙伴的协作下进行。研究包括了不同的知识图构建方法在企业和个人设置下，以及Managed Forgetting和（自组织）Context Spaces作为一种新的个人信息管理（PIM）和知识工作支持的方法。</li>
<li>results: 过去实验和结果包括了许多不同的主题，如知识图构建、Managed Forgetting和Context Spaces等。此外，我们还提供了相关工作的概述和一些最新的发现，这些发现尚未发表。最后，我们给出了一个关于CoMem的详细描述，这是基于我们所提出的研究已经在生产中使用的一个企业记忆系统，以及这个系统在进一步研究中的挑战。<details>
<summary>Abstract</summary>
This paper presents a retrospective overview of a decade of research in our department towards self-organizing personal knowledge assistants in evolving corporate memories. Our research is typically inspired by real-world problems and often conducted in interdisciplinary collaborations with research and industry partners. We summarize past experiments and results comprising topics like various ways of knowledge graph construction in corporate and personal settings, Managed Forgetting and (Self-organizing) Context Spaces as a novel approach to Personal Information Management (PIM) and knowledge work support. Past results are complemented by an overview of related work and some of our latest findings not published so far. Last, we give an overview of our related industry use cases including a detailed look into CoMem, a Corporate Memory based on our presented research already in productive use and providing challenges for further research. Many contributions are only first steps in new directions with still a lot of untapped potential, especially with regard to further increasing the automation in PIM and knowledge work support.
</details>
<details>
<summary>摘要</summary>
中文翻译：本文提供了我们部门过去十年的研究回顾，探讨了自我组织人工智能在演化企业记忆中的个人知识助手。我们的研究通常受到实际问题的启发，并在研究和行业合作伙伴的协作下进行。我们summarize过去的实验和结果，包括企业和个人设置中知识图构建的多种方法，以及自动化Context Spaces和Managed Forgetting作为个人信息管理（PIM）和知识工作支持的新方法。过去的结果也包括相关工作的概述和一些没有发表过的最新发现。最后，我们给出了相关的行业应用场景，包括一个详细的CoMem企业记忆的概述，该记忆基于我们所提出的研究，已经在生产中使用，并提供了进一步研究的挑战。许多贡献都只是新的方向的第一步，特别是在进一步增加PIM和知识工作支持中的自动化。
</details></li>
</ul>
<hr>
<h2 id="Is-GPT-4-a-reliable-rater-Evaluating-Consistency-in-GPT-4-Text-Ratings"><a href="#Is-GPT-4-a-reliable-rater-Evaluating-Consistency-in-GPT-4-Text-Ratings" class="headerlink" title="Is GPT-4 a reliable rater? Evaluating Consistency in GPT-4 Text Ratings"></a>Is GPT-4 a reliable rater? Evaluating Consistency in GPT-4 Text Ratings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02575">http://arxiv.org/abs/2308.02575</a></li>
<li>repo_url: None</li>
<li>paper_authors: Veronika Hackl, Alexandra Elena Müller, Michael Granitzer, Maximilian Sailer</li>
<li>for: 这个研究探究了OpenAI的GPT-4模型在多个迭代、时间尺度和语言风格变化下的反馈评分的一致性。</li>
<li>methods: 该研究使用GPT-4模型对高等教育（HE）领域的macroeconomics任务中的回答进行了内容和风格两个方面的评分。统计分析用于了解评分之间的一致性、迭代中评分的一致性以及内容和风格评分之间的相关性。</li>
<li>results: 结果显示GPT-4模型在不同的时间尺度下 exhibit 高的 между评分者一致性（ICC分数在0.94-0.99之间），表明该模型在重复提示下能够生成一致的评分。内容和风格评分之间存在0.87的高相关性。当应用不适用的风格时，内容评分保持相对定的，而风格评分下降，这表明LLM有效地在评价过程中分化内容和风格两个方面。<details>
<summary>Abstract</summary>
This study investigates the consistency of feedback ratings generated by OpenAI's GPT-4, a state-of-the-art artificial intelligence language model, across multiple iterations, time spans and stylistic variations. The model rated responses to tasks within the Higher Education (HE) subject domain of macroeconomics in terms of their content and style. Statistical analysis was conducted in order to learn more about the interrater reliability, consistency of the ratings across iterations and the correlation between ratings in terms of content and style. The results revealed a high interrater reliability with ICC scores ranging between 0.94 and 0.99 for different timespans, suggesting that GPT-4 is capable of generating consistent ratings across repetitions with a clear prompt. Style and content ratings show a high correlation of 0.87. When applying a non-adequate style the average content ratings remained constant, while style ratings decreased, which indicates that the large language model (LLM) effectively distinguishes between these two criteria during evaluation. The prompt used in this study is furthermore presented and explained. Further research is necessary to assess the robustness and reliability of AI models in various use cases.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Local-Large-Language-Models-for-Complex-Structured-Medical-Tasks"><a href="#Local-Large-Language-Models-for-Complex-Structured-Medical-Tasks" class="headerlink" title="Local Large Language Models for Complex Structured Medical Tasks"></a>Local Large Language Models for Complex Structured Medical Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01727">http://arxiv.org/abs/2308.01727</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/innovationcore/LocalLLMStructured">https://github.com/innovationcore/LocalLLMStructured</a></li>
<li>paper_authors: V. K. Cody Bumgardner, Aaron Mullen, Sam Armstrong, Caylin Hickey, Jeff Talbert</li>
<li>for: This paper aims to tackle complex, domain-specific tasks by combining the language reasoning capabilities of large language models (LLMs) with the benefits of local training.</li>
<li>methods: The proposed approach utilizes local LLMs, which can be fine-tuned to respond to specific generative instructions and provide structured outputs. The authors used a dataset of over 150k uncurated surgical pathology reports to train and evaluate different model architectures, including LLaMA, BERT, and LongFormer.</li>
<li>results: The results show that the LLaMA-based models significantly outperform BERT-style models across all evaluated metrics, especially with large datasets. The LLaMA models demonstrated their ability to handle complex, multi-label tasks, making them a promising approach for utilizing LLMs to perform domain-specific tasks using accessible hardware.<details>
<summary>Abstract</summary>
This paper introduces an approach that combines the language reasoning capabilities of large language models (LLMs) with the benefits of local training to tackle complex, domain-specific tasks. Specifically, the authors demonstrate their approach by extracting structured condition codes from pathology reports. The proposed approach utilizes local LLMs, which can be fine-tuned to respond to specific generative instructions and provide structured outputs. The authors collected a dataset of over 150k uncurated surgical pathology reports, containing gross descriptions, final diagnoses, and condition codes. They trained different model architectures, including LLaMA, BERT and LongFormer and evaluated their performance. The results show that the LLaMA-based models significantly outperform BERT-style models across all evaluated metrics, even with extremely reduced precision. The LLaMA models performed especially well with large datasets, demonstrating their ability to handle complex, multi-label tasks. Overall, this work presents an effective approach for utilizing LLMs to perform domain-specific tasks using accessible hardware, with potential applications in the medical domain, where complex data extraction and classification are required.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Bees-Local-Phase-Quantization-Feature-Selection-for-RGB-D-Facial-Expressions-Recognition"><a href="#Bees-Local-Phase-Quantization-Feature-Selection-for-RGB-D-Facial-Expressions-Recognition" class="headerlink" title="Bees Local Phase Quantization Feature Selection for RGB-D Facial Expressions Recognition"></a>Bees Local Phase Quantization Feature Selection for RGB-D Facial Expressions Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01700">http://arxiv.org/abs/2308.01700</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seyed Muhammad Hossein Mousavi, Atiye Ilanloo</li>
<li>for: 本研究旨在提出一种基于灵感自然选择器的特征选择方法，并应用于人脸表情识别任务。</li>
<li>methods: 本研究使用了蜂群算法（BA）和本地相位量化（LPQ）来实现特征选择。LPQ是一种在频域中表现出色的特征，可以帮助提高人脸表情识别的准确率。</li>
<li>results: 研究结果显示，提案的蜂群LPQ方法在人脸表情识别任务中达到了99%的准确率，与其他方法相比，表现出了极好的性能。<details>
<summary>Abstract</summary>
Feature selection could be defined as an optimization problem and solved by bio-inspired algorithms. Bees Algorithm (BA) shows decent performance in feature selection optimization tasks. On the other hand, Local Phase Quantization (LPQ) is a frequency domain feature which has excellent performance on Depth images. Here, after extracting LPQ features out of RGB (colour) and Depth images from the Iranian Kinect Face Database (IKFDB), the Bees feature selection algorithm applies to select the desired number of features for final classification tasks. IKFDB is recorded with Kinect sensor V.2 and contains colour and depth images for facial and facial micro-expressions recognition purposes. Here five facial expressions of Anger, Joy, Surprise, Disgust and Fear are used for final validation. The proposed Bees LPQ method is compared with Particle Swarm Optimization (PSO) LPQ, PCA LPQ, Lasso LPQ, and just LPQ features for classification tasks with Support Vector Machines (SVM), K-Nearest Neighbourhood (KNN), Shallow Neural Network and Ensemble Subspace KNN. Returned results, show a decent performance of the proposed algorithm (99 % accuracy) in comparison with others.
</details>
<details>
<summary>摘要</summary>
feature选择可以定义为优化问题，并可以使用生物灵感算法解决。蜂群算法（BA）在特征选择优化任务中表现不错。另一方面，本地相对频率量化（LPQ）是一个频域特征，在深度影像上表现出色。在这里，我们将LPQ特征提取自RGB（色）和深度影像，然后使用蜂群特征选择算法选择最多的特征。IKFDB（伊朗掌握脸部数据库）是录制了Kinect感知器V.2的颜色和深度影像，并且用于脸部和脸部微表情识别。在这里，我们使用五种表情：愤怒、喜悦、惊讶、厌恶和恐惧进行最终验证。提案的蜂群LPQ方法与束缚点群集优化（PSO）LPQ、对角量变换（PCA）LPQ、lasso LPQ和单独LPQ特征进行比较，并使用支持向量机（SVM）、K-最近邻居（KNN）、浅层神经网和混合空间KNN进行类别任务。结果显示，提案的算法（99%准确）在比较之下表现不错。
</details></li>
</ul>
<hr>
<h2 id="LiDAR-Camera-Panoptic-Segmentation-via-Geometry-Consistent-and-Semantic-Aware-Alignment"><a href="#LiDAR-Camera-Panoptic-Segmentation-via-Geometry-Consistent-and-Semantic-Aware-Alignment" class="headerlink" title="LiDAR-Camera Panoptic Segmentation via Geometry-Consistent and Semantic-Aware Alignment"></a>LiDAR-Camera Panoptic Segmentation via Geometry-Consistent and Semantic-Aware Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01686">http://arxiv.org/abs/2308.01686</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhangzw12319/lcps">https://github.com/zhangzw12319/lcps</a></li>
<li>paper_authors: Zhiwei Zhang, Zhizhong Zhang, Qian Yu, Ran Yi, Yuan Xie, Lizhuang Ma</li>
<li>for: This paper is written for the task of 3D panoptic segmentation, which aims to simultaneously perform semantic segmentation and instance segmentation in a scene using both LiDAR and camera data.</li>
<li>methods: The proposed method, called LCPS, uses a three-stage fusion approach that includes an asynchronous compensation pixel alignment module, a semantic-aware region alignment module, and a point-to-voxel feature propagation module to fuse LiDAR and camera data.</li>
<li>results: The proposed method achieves an improvement of about 6.9% in PQ performance over the LiDAR-only baseline on the NuScenes dataset, demonstrating the effectiveness of the proposed fusion strategy.Here are the three points in Simplified Chinese text:</li>
<li>for: 这篇论文是为了解决3D照片检测问题，这个问题需要同时进行 semantic segmentation 和 instance segmentation，使用 LiDAR 和摄像头数据。</li>
<li>methods: 提议的方法是 LCPS，它使用三个阶段的融合方法，包括异步补做像素对齐模块、semantic-aware region alignment模块和点到 voxel 特征传播模块来融合 LiDAR 和摄像头数据。</li>
<li>results: 提议的方法在 NuScenes 数据集上实现了约6.9%的 PQ 性能提升，证明了提议的融合策略的有效性。<details>
<summary>Abstract</summary>
3D panoptic segmentation is a challenging perception task that requires both semantic segmentation and instance segmentation. In this task, we notice that images could provide rich texture, color, and discriminative information, which can complement LiDAR data for evident performance improvement, but their fusion remains a challenging problem. To this end, we propose LCPS, the first LiDAR-Camera Panoptic Segmentation network. In our approach, we conduct LiDAR-Camera fusion in three stages: 1) an Asynchronous Compensation Pixel Alignment (ACPA) module that calibrates the coordinate misalignment caused by asynchronous problems between sensors; 2) a Semantic-Aware Region Alignment (SARA) module that extends the one-to-one point-pixel mapping to one-to-many semantic relations; 3) a Point-to-Voxel feature Propagation (PVP) module that integrates both geometric and semantic fusion information for the entire point cloud. Our fusion strategy improves about 6.9% PQ performance over the LiDAR-only baseline on NuScenes dataset. Extensive quantitative and qualitative experiments further demonstrate the effectiveness of our novel framework. The code will be released at https://github.com/zhangzw12319/lcps.git.
</details>
<details>
<summary>摘要</summary>
“3D短文本分割是一项具有挑战性的识别任务，它需要同时完成semantic segmentation和instance segmentation。在这种任务中，我们发现图像可以提供丰富的文本、颜色和特征信息，这些信息可以补做LiDAR数据，从而提高识别性能，但是这些信息的融合仍然是一个挑战。为此，我们提出了LCPS，首个LiDAR-Camera短文本分割网络。我们的方法包括三个阶段：1）异步补做像素均衡（ACPA）模块，用于解决摄像头和LiDAR仪器之间的坐标偏差问题; 2） semantic-aware区域匹配（SARA）模块，将一对一点像素映射扩展到一对多semantic关系; 3）点云特征传播（PVP）模块，将光栅和semantic融合信息传播到整个点云中。我们的融合策略提高了NuScenes数据集上LiDAR-only基准点Cloud的PQ性能表现约6.9%。广泛的量化和质量实验进一步证明了我们的新框架的有效性。代码将在https://github.com/zhangzw12319/lcps.git中发布。”
</details></li>
</ul>
<hr>
<h2 id="Evaluating-Link-Prediction-Explanations-for-Graph-Neural-Networks"><a href="#Evaluating-Link-Prediction-Explanations-for-Graph-Neural-Networks" class="headerlink" title="Evaluating Link Prediction Explanations for Graph Neural Networks"></a>Evaluating Link Prediction Explanations for Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01682">http://arxiv.org/abs/2308.01682</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cborile/eval_lp_xai">https://github.com/cborile/eval_lp_xai</a></li>
<li>paper_authors: Claudio Borile, Alan Perotti, André Panisson</li>
<li>for: 这篇论文主要用于提供链接预测模型的解释评价指标，以便促进链接预测模型的采用。</li>
<li>methods: 这篇论文使用了现状前景的解释方法，并对这些方法进行评价。</li>
<li>results: 研究发现，不同的距离选择方式可能会影响链接预测解释的质量。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Graph Machine Learning (GML) has numerous applications, such as node/graph classification and link prediction, in real-world domains. Providing human-understandable explanations for GML models is a challenging yet fundamental task to foster their adoption, but validating explanations for link prediction models has received little attention. In this paper, we provide quantitative metrics to assess the quality of link prediction explanations, with or without ground-truth. State-of-the-art explainability methods for Graph Neural Networks are evaluated using these metrics. We discuss how underlying assumptions and technical details specific to the link prediction task, such as the choice of distance between node embeddings, can influence the quality of the explanations.
</details>
<details>
<summary>摘要</summary>
graph机器学习（GML）在实际领域有很多应用，如节点/图分类和链接预测。提供可理解的GML模型解释是推广其使用的挑战，但链接预测模型的解释 validation  Received little attention。在这篇论文中，我们提供了量化的评价指标，以及或无ground-truth。现有的explainability方法 для图神经网络被使用这些指标进行评估。我们讨论了链接预测任务的下面假设和技术细节，如节点嵌入距离的选择，对解释质量产生的影响。
</details></li>
</ul>
<hr>
<h2 id="NBIAS-A-Natural-Language-Processing-Framework-for-Bias-Identification-in-Text"><a href="#NBIAS-A-Natural-Language-Processing-Framework-for-Bias-Identification-in-Text" class="headerlink" title="NBIAS: A Natural Language Processing Framework for Bias Identification in Text"></a>NBIAS: A Natural Language Processing Framework for Bias Identification in Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01681">http://arxiv.org/abs/2308.01681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shaina Raza, Muskan Garg, Deepak John Reji, Syed Raza Bashir, Chen Ding</li>
<li>for: 这篇论文的目的是为了探讨文本数据中的偏见，并开发一个可以检测和消除这些偏见的框架。</li>
<li>methods: 这篇论文使用了一个基于Transformer的字词分类模型，并通过独特的名称实体来识别偏见字词&#x2F;短语。</li>
<li>results: 这篇论文的结果显示，使用了提案的方法可以实现偏见检测和消除的目的，并且比基于基线的方法提高了1%至8%的精度。<details>
<summary>Abstract</summary>
Bias in textual data can lead to skewed interpretations and outcomes when the data is used. These biases could perpetuate stereotypes, discrimination, or other forms of unfair treatment. An algorithm trained on biased data ends up making decisions that disproportionately impact a certain group of people. Therefore, it is crucial to detect and remove these biases to ensure the fair and ethical use of data. To this end, we develop a comprehensive and robust framework \textsc{Nbias} that consists of a data layer, corpus contruction, model development layer and an evaluation layer. The dataset is constructed by collecting diverse data from various fields, including social media, healthcare, and job hiring portals. As such, we applied a transformer-based token classification model that is able to identify bias words/ phrases through a unique named entity. In the assessment procedure, we incorporate a blend of quantitative and qualitative evaluations to gauge the effectiveness of our models. We achieve accuracy improvements ranging from 1% to 8% compared to baselines. We are also able to generate a robust understanding of the model functioning, capturing not only numerical data but also the quality and intricacies of its performance. The proposed approach is applicable to a variety of biases and contributes to the fair and ethical use of textual data.
</details>
<details>
<summary>摘要</summary>
文本数据中的偏见可能导致解释和结果偏离均衡，这可能导致推荐或报告不公平或不公正。一个基于偏见数据的算法会导致对某些人群的决策偏离，从而产生不公平的结果。因此，检测和消除偏见是必要的，以确保数据的公平和道德使用。为此，我们开发了一个全面和可靠的框架\textsc{Nbias}，它包括数据层、文本建构层、模型开发层和评估层。我们收集了来自不同领域的多样化数据，包括社交媒体、医疗和招聘门户，并应用了基于转换器的单词分类模型，以识别偏见词语/短语。在评估过程中，我们 combinated量化和质量评估来评估模型的效果。我们实现了基eline比较高的准确率改进，从1%到8%不等，并能够生成模型的精准和复杂的性能理解。这种方法可以应用于多种偏见，并为公平和道德的文本数据使用做出贡献。
</details></li>
</ul>
<hr>
<h2 id="Learning-Implicit-Entity-object-Relations-by-Bidirectional-Generative-Alignment-for-Multimodal-NER"><a href="#Learning-Implicit-Entity-object-Relations-by-Bidirectional-Generative-Alignment-for-Multimodal-NER" class="headerlink" title="Learning Implicit Entity-object Relations by Bidirectional Generative Alignment for Multimodal NER"></a>Learning Implicit Entity-object Relations by Bidirectional Generative Alignment for Multimodal NER</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02570">http://arxiv.org/abs/2308.02570</a></li>
<li>repo_url: None</li>
<li>paper_authors: Feng Chen, Jiajia Liu, Kaixiang Ji, Wang Ren, Jian Wang, Jingdong Wang</li>
<li>for: 提高多modalNamed Entity recognition（MNER）的性能，尤其是 bridging the semantic gap between text and image，以及匹配实体与其相关对象的匹配。</li>
<li>methods: 提出了一种bidirectional generative alignment方法（BGA-MNER），包括图像到文本和文本到图像的生成，以及对实体敏感内容的融合。该方法通过对双向重建目标进行 JOINT 优化，使实体-对象关系得到了正确的匹配。</li>
<li>results: 通过对两个 benchmark进行了广泛的实验，表明了我们的方法可以在无图像输入的情况下达到最佳性能。<details>
<summary>Abstract</summary>
The challenge posed by multimodal named entity recognition (MNER) is mainly two-fold: (1) bridging the semantic gap between text and image and (2) matching the entity with its associated object in image. Existing methods fail to capture the implicit entity-object relations, due to the lack of corresponding annotation. In this paper, we propose a bidirectional generative alignment method named BGA-MNER to tackle these issues. Our BGA-MNER consists of \texttt{image2text} and \texttt{text2image} generation with respect to entity-salient content in two modalities. It jointly optimizes the bidirectional reconstruction objectives, leading to aligning the implicit entity-object relations under such direct and powerful constraints. Furthermore, image-text pairs usually contain unmatched components which are noisy for generation. A stage-refined context sampler is proposed to extract the matched cross-modal content for generation. Extensive experiments on two benchmarks demonstrate that our method achieves state-of-the-art performance without image input during inference.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MARLIM-Multi-Agent-Reinforcement-Learning-for-Inventory-Management"><a href="#MARLIM-Multi-Agent-Reinforcement-Learning-for-Inventory-Management" class="headerlink" title="MARLIM: Multi-Agent Reinforcement Learning for Inventory Management"></a>MARLIM: Multi-Agent Reinforcement Learning for Inventory Management</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01649">http://arxiv.org/abs/2308.01649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rémi Leluc, Elie Kadoche, Antoine Bertoncello, Sébastien Gourvénec</li>
<li>for: 决策供应链中维持产品供应平衡，提高供应链效率和可靠性。</li>
<li>methods: 使用人工智能技术，开发了一种基于强化学习的供应链管理框架，named MARLIM，可以处理单一仓库多种产品的存储管理问题，采用单或多代理人协作方式。</li>
<li>results: 通过实验表明，基于强化学习方法的供应链管理方法比传统基eline方法更有利，可以更好地决策供应链中的产品供应问题。<details>
<summary>Abstract</summary>
Maintaining a balance between the supply and demand of products by optimizing replenishment decisions is one of the most important challenges in the supply chain industry. This paper presents a novel reinforcement learning framework called MARLIM, to address the inventory management problem for a single-echelon multi-products supply chain with stochastic demands and lead-times. Within this context, controllers are developed through single or multiple agents in a cooperative setting. Numerical experiments on real data demonstrate the benefits of reinforcement learning methods over traditional baselines.
</details>
<details>
<summary>摘要</summary>
维护产品供应和需求的平衡是供应链产业中最重要的挑战。本文提出了一个新的强化学习框架，名为MARLIM，以解决单一库存维护问题。在这个设定下，控制器通过单一或多个代理人在合作环境中发展。数据示出强化学习方法比传统基准更有价。
</details></li>
</ul>
<hr>
<h2 id="Improving-Wind-Resistance-Performance-of-Cascaded-PID-Controlled-Quadcopters-using-Residual-Reinforcement-Learning"><a href="#Improving-Wind-Resistance-Performance-of-Cascaded-PID-Controlled-Quadcopters-using-Residual-Reinforcement-Learning" class="headerlink" title="Improving Wind Resistance Performance of Cascaded PID Controlled Quadcopters using Residual Reinforcement Learning"></a>Improving Wind Resistance Performance of Cascaded PID Controlled Quadcopters using Residual Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01648">http://arxiv.org/abs/2308.01648</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Ishihara, Yuichi Hazama, Kousuke Suzuki, Jerry Jun Yokono, Kohtaro Sabe, Kenta Kawamoto</li>
<li>for: 控制四旋翼机器人在风干扰下维持位置的稳定性。</li>
<li>methods: 使用剩余强化学习方法建立四旋翼机器人风 resistance控制器，只学习干扰的差异，可以继续使用传统的缓冲PID控制器作为基础控制器，提高风干扰下的性能。</li>
<li>results: 通过多种实验，包括在风速大于13m&#x2F;s的户外场景中，我们的控制器可以减少四旋翼机器人的位置偏差约50%，并且培养的控制器具有强健性，可以在四旋翼机器人的质量和推进器的扬力系数发生变化时保持性能。<details>
<summary>Abstract</summary>
Wind resistance control is an essential feature for quadcopters to maintain their position to avoid deviation from target position and prevent collisions with obstacles. Conventionally, cascaded PID controller is used for the control of quadcopters for its simplicity and ease of tuning its parameters. However, it is weak against wind disturbances and the quadcopter can easily deviate from target position. In this work, we propose a residual reinforcement learning based approach to build a wind resistance controller of a quadcopter. By learning only the residual that compensates the disturbance, we can continue using the cascaded PID controller as the base controller of the quadcopter but improve its performance against wind disturbances. To avoid unexpected crashes and destructions of quadcopters, our method does not require real hardware for data collection and training. The controller is trained only on a simulator and directly applied to the target hardware without extra finetuning process. We demonstrate the effectiveness of our approach through various experiments including an experiment in an outdoor scene with wind speed greater than 13 m/s. Despite its simplicity, our controller reduces the position deviation by approximately 50% compared to the quadcopter controlled with the conventional cascaded PID controller. Furthermore, trained controller is robust and preserves its performance even though the quadcopter's mass and propeller's lift coefficient is changed between 50% to 150% from original training time.
</details>
<details>
<summary>摘要</summary>
风 resistance 控制是 quadcopter 维持目标位置的重要特性，以避免偏离目标位置和避免遭遇障碍物的Collision。 Conventionally, cascaded PID controller 是用于 quadcopter 控制的最常用方法，因为它的简单性和参数调整的容易性。然而，它在风干扰下表现弱，quadcopter 容易偏离目标位置。在这项工作中，我们提出了基于 residual reinforcement learning 的风 resistance 控制方法。通过学习剩下的偏差，我们可以继续使用 cascaded PID controller 作为 quadcopter 的基础控制器，但是提高其对风干扰的性能。为了避免意外坠机和 quadcopter 的破坏，我们的方法不需要实际硬件数据采集和训练。控制器通过在 simulator 上学习，直接应用于目标硬件上，不需要额外的调整过程。我们通过多种实验，包括在风速大于 13 m/s 的户外场景中，证明了我们的方法的有效性。即使简单，我们的控制器可以降低 quadcopter 的位置偏离约 50%，相比于使用 conventinal cascaded PID controller。另外，训练后的控制器具有坚定性，其性能保持不变，even though quadcopter 的质量和推进器的扬力系数被变化了，从原始训练时间的50%到150%。
</details></li>
</ul>
<hr>
<h2 id="Interleaving-GANs-with-knowledge-graphs-to-support-design-creativity-for-book-covers"><a href="#Interleaving-GANs-with-knowledge-graphs-to-support-design-creativity-for-book-covers" class="headerlink" title="Interleaving GANs with knowledge graphs to support design creativity for book covers"></a>Interleaving GANs with knowledge graphs to support design creativity for book covers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01626">http://arxiv.org/abs/2308.01626</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alexmotogna/generatorapi">https://github.com/alexmotogna/generatorapi</a></li>
<li>paper_authors: Alexandru Motogna, Adrian Groza</li>
<li>for: 本研究应用生成对抗网络（GANs）到书籍封面领域，以不同的训练方法来提取更好的生成图像。</li>
<li>methods: 本研究使用GANs与知识图进行混合训练，通过对标题进行修改来生成多个可能的选择，然后使用识别器进行选择最佳的生成图像。</li>
<li>results: 本研究比前一些尝试更好地生成书籍封面，而知识图产生更多的选择，为书籍作者或编辑提供了更好的选择。<details>
<summary>Abstract</summary>
An attractive book cover is important for the success of a book. In this paper, we apply Generative Adversarial Networks (GANs) to the book covers domain, using different methods for training in order to obtain better generated images. We interleave GANs with knowledge graphs to alter the input title to obtain multiple possible options for any given title, which are then used as an augmented input to the generator. Finally, we use the discriminator obtained during the training phase to select the best images generated with new titles. Our method performed better at generating book covers than previous attempts, and the knowledge graph gives better options to the book author or editor compared to using GANs alone.
</details>
<details>
<summary>摘要</summary>
一本漂亮的书封面对书的成功非常重要。在这篇论文中，我们使用生成对抗网络（GANs）来适应书封面领域，使用不同的训练方法来获得更好的生成图像。我们将GANs与知识图加以混合，将输入标题进行修改，以获得多个可能的选择，然后将这些选择作为增强输入给生成器。最后，我们使用训练阶段获得的推定器来选择最佳的生成图像。我们的方法比之前的尝试更好地生成书封面，而知识图可以为书作者或编辑提供更多的选择，比如使用GANsalone。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Indoor-Localisation-in-Parkinson’s-Disease-for-Detecting-Medication-Use-Observational-Pilot-Study-in-a-Free-Living-Setting"><a href="#Multimodal-Indoor-Localisation-in-Parkinson’s-Disease-for-Detecting-Medication-Use-Observational-Pilot-Study-in-a-Free-Living-Setting" class="headerlink" title="Multimodal Indoor Localisation in Parkinson’s Disease for Detecting Medication Use: Observational Pilot Study in a Free-Living Setting"></a>Multimodal Indoor Localisation in Parkinson’s Disease for Detecting Medication Use: Observational Pilot Study in a Free-Living Setting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02419">http://arxiv.org/abs/2308.02419</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ferdianjovan/Multihead-Dual-Convolutional-Self-Attention">https://github.com/ferdianjovan/Multihead-Dual-Convolutional-Self-Attention</a></li>
<li>paper_authors: Ferdian Jovan, Catherine Morgan, Ryan McConville, Emma L. Tonkin, Ian Craddock, Alan Whone</li>
<li>for: 这个研究的目的是提高当前indoor localization方法的效果，并使用双感知模式（ Received Signal Strength Indicator 和加速器数据）来评估PD患者的 дви作障碍。</li>
<li>methods: 这个研究使用了一种基于转换器的方法，利用RSSI和加速器数据来提供 complementary views of movement。</li>
<li>results: 研究表明，该方法可以高效地进行indoor localization，并且可以准确地捕捉PD患者的 дви作障碍。具体来说，研究发现，精准的房间级别的地理位置预测，可以准确地预测PD患者是否正在服用levodopa药物。<details>
<summary>Abstract</summary>
Parkinson's disease (PD) is a slowly progressive, debilitating neurodegenerative disease which causes motor symptoms including gait dysfunction. Motor fluctuations are alterations between periods with a positive response to levodopa therapy ("on") and periods marked by re-emergency of PD symptoms ("off") as the response to medication wears off. These fluctuations often affect gait speed and they increase in their disabling impact as PD progresses. To improve the effectiveness of current indoor localisation methods, a transformer-based approach utilising dual modalities which provide complementary views of movement, Received Signal Strength Indicator (RSSI) and accelerometer data from wearable devices, is proposed. A sub-objective aims to evaluate whether indoor localisation, including its in-home gait speed features (i.e. the time taken to walk between rooms), could be used to evaluate motor fluctuations by detecting whether the person with PD is taking levodopa medications or withholding them. To properly evaluate our proposed method, we use a free-living dataset where the movements and mobility are greatly varied and unstructured as expected in real-world conditions. 24 participants lived in pairs (consisting of one person with PD, one control) for five days in a smart home with various sensors. Our evaluation on the resulting dataset demonstrates that our proposed network outperforms other methods for indoor localisation. The sub-objective evaluation shows that precise room-level localisation predictions, transformed into in-home gait speed features, produce accurate predictions on whether the PD participant is taking or withholding their medications.
</details>
<details>
<summary>摘要</summary>
帕金森病 (PD) 是一种慢慢恶化、疲劳性神经退化病种，引起 дви作Symptoms 包括行走功能障碍。 дви作周期性变化是指由levodopa治疗 ("on") 和PD症状重新出现 ("off") 的交替，这些变化通常对行走速度产生影响，随着PD的进行而加剧。为了提高现有indoor localization方法的有效性，一种基于 transformer 的方法，利用 dual Modalities 提供 complementary 视图的运动数据，包括 Received Signal Strength Indicator (RSSI) 和加速器数据，是提出的。一个 sub-objective 是评估 whether indoor localization, 包括室内步速特征 (i.e. 行走 между房间所需时间), 可以用来评估PD参与者是否服用 levodopa 药物。为了正确评估我们的提议方法，我们使用了一个免费生活数据集，其中参与者的运动和 mobilty 具有很大的变化和不结构化，如预计的实际条件中。24名参与者（一名PD参与者和一名控制人）在五天内生活在一个智能家庭中，并装备了多种感知器。我们对 resulting dataset 进行评估，并显示我们的提议网络在indoor localization方面的表现比其他方法更好。 sub-objective 评估表明，精准的室内地理位置预测，经 transformed 为室内步速特征，可以准确地预测PD参与者是否服用 levodopa 药物。
</details></li>
</ul>
<hr>
<h2 id="ReIDTrack-Multi-Object-Track-and-Segmentation-Without-Motion"><a href="#ReIDTrack-Multi-Object-Track-and-Segmentation-Without-Motion" class="headerlink" title="ReIDTrack: Multi-Object Track and Segmentation Without Motion"></a>ReIDTrack: Multi-Object Track and Segmentation Without Motion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01622">http://arxiv.org/abs/2308.01622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaer Huang, Bingchuan Sun, Feng Chen, Tao Zhang, Jun Xie, Jian Li, Christopher Walter Twombly, Zhepeng Wang</li>
<li>For: The paper focuses on exploring the direction of achieving state-of-the-art (SOTA) performance in multi-object tracking and segmentation (MOTS) using only high-performance detection and appearance models, without relying on motion information and IoU mapping during association.* Methods: The proposed method uses CBNetV2 as a detection model and MoCo-v2 as a self-supervised appearance model, and removes motion information and IoU mapping during the association process.* Results: The method achieved 1st place on the MOTS track and 2nd place on the MOT track in the CVPR2023 WAD workshop, demonstrating its effectiveness and simplicity.Here are the three points in Simplified Chinese text:* For: 本研究主要目标是通过高性能的检测和外观模型来实现多bject tracking和分割（MOTS）中的新状态之冠（SOTA）性能，不需要在协调过程中使用运动信息和IOU映射。* Methods: 提posed方法使用 CBNetV2 作为检测模型，MoCo-v2 作为自我指导的外观模型，并在协调过程中除掉运动信息和IOU映射。* Results: 方法在 CVPR2023 WAD 工作坊中获得了 MOTS track 第一名和 MOT track 第二名，证明了其简洁效果。<details>
<summary>Abstract</summary>
In recent years, dominant Multi-object tracking (MOT) and segmentation (MOTS) methods mainly follow the tracking-by-detection paradigm. Transformer-based end-to-end (E2E) solutions bring some ideas to MOT and MOTS, but they cannot achieve a new state-of-the-art (SOTA) performance in major MOT and MOTS benchmarks. Detection and association are two main modules of the tracking-by-detection paradigm. Association techniques mainly depend on the combination of motion and appearance information. As deep learning has been recently developed, the performance of the detection and appearance model is rapidly improved. These trends made us consider whether we can achieve SOTA based on only high-performance detection and appearance model. Our paper mainly focuses on exploring this direction based on CBNetV2 with Swin-B as a detection model and MoCo-v2 as a self-supervised appearance model. Motion information and IoU mapping were removed during the association. Our method wins 1st place on the MOTS track and wins 2nd on the MOT track in the CVPR2023 WAD workshop. We hope our simple and effective method can give some insights to the MOT and MOTS research community. Source code will be released under this git repository
</details>
<details>
<summary>摘要</summary>
近年来，主流多目标跟踪（MOT）和多目标分割（MOTS）方法主要采用跟踪检测 paradigm。基于 transformer 的端到端（E2E）解决方案在 MOT 和 MOTS 中带来了一些想法，但它们无法达到主要 MOT 和 MOTS benchmark 中的新状态前景（SOTA）性能。检测和归一化是跟踪检测 paradigm 的两个主要模块。归一化技术主要基于运动和外观信息的组合。随着深度学习的发展，检测和外观模型的性能得到了迅速提高。这些趋势使我们考虑了是否可以基于高性能的检测和外观模型达到 SOTA。我们的论文主要关注 exploring 这一方向，使用 CBNetV2 作为检测模型和 MoCo-v2 作为自主监督的外观模型。在归一化过程中，我们移除了运动信息和 IoU 映射。我们的方法在 CVPR2023 WAD 工作坊的 MOTS 轨道上获得了第一名，在 MOT 轨道上获得了第二名。我们希望我们的简单而有效的方法可以给 MOT 和 MOTS 研究社区提供一些想法。源代码将在这个 Git 仓库中发布。
</details></li>
</ul>
<hr>
<h2 id="Assessing-Systematic-Weaknesses-of-DNNs-using-Counterfactuals"><a href="#Assessing-Systematic-Weaknesses-of-DNNs-using-Counterfactuals" class="headerlink" title="Assessing Systematic Weaknesses of DNNs using Counterfactuals"></a>Assessing Systematic Weaknesses of DNNs using Counterfactuals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01614">http://arxiv.org/abs/2308.01614</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sujan Sai Gannamaneni, Michael Mock, Maram Akila</li>
<li>for: 这篇论文主要是为了探讨深度神经网络（DNN）在安全敏感应用中的测试方法，以及寻找和识别这些模型在特定输入空间中的系统性弱点。</li>
<li>methods: 这篇论文提出了一种基于对应推理的算法，用于验证已知subset的内在属性对模型性能的影响。这种方法通过模拟出不同属性之间的互动，以确定内在属性是否对模型性能的恶化做出了贡献。</li>
<li>results: 根据这篇论文的结果，在自动驾驶领域中的一个semantic segmentation模型中，发现存在不同的人工资产之间的性能差异，但是只有在某些情况下，资产类型本身是对模型性能的恶化原因。<details>
<summary>Abstract</summary>
With the advancement of DNNs into safety-critical applications, testing approaches for such models have gained more attention. A current direction is the search for and identification of systematic weaknesses that put safety assumptions based on average performance values at risk. Such weaknesses can take on the form of (semantically coherent) subsets or areas in the input space where a DNN performs systematically worse than its expected average. However, it is non-trivial to attribute the reason for such observed low performances to the specific semantic features that describe the subset. For instance, inhomogeneities within the data w.r.t. other (non-considered) attributes might distort results. However, taking into account all (available) attributes and their interaction is often computationally highly expensive. Inspired by counterfactual explanations, we propose an effective and computationally cheap algorithm to validate the semantic attribution of existing subsets, i.e., to check whether the identified attribute is likely to have caused the degraded performance. We demonstrate this approach on an example from the autonomous driving domain using highly annotated simulated data, where we show for a semantic segmentation model that (i) performance differences among the different pedestrian assets exist, but (ii) only in some cases is the asset type itself the reason for this reduction in the performance.
</details>
<details>
<summary>摘要</summary>
Inspired by counterfactual explanations, we propose an efficient and computationally inexpensive algorithm to validate the semantic attribution of existing subsets. We demonstrate this approach on an example from the autonomous driving domain using highly annotated simulated data. Our results show that while performance differences exist among different pedestrian assets, the asset type itself is not always the reason for the reduction in performance.
</details></li>
</ul>
<hr>
<h2 id="Discriminative-Graph-level-Anomaly-Detection-via-Dual-students-teacher-Model"><a href="#Discriminative-Graph-level-Anomaly-Detection-via-Dual-students-teacher-Model" class="headerlink" title="Discriminative Graph-level Anomaly Detection via Dual-students-teacher Model"></a>Discriminative Graph-level Anomaly Detection via Dual-students-teacher Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01947">http://arxiv.org/abs/2308.01947</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/whb605/gladst">https://github.com/whb605/gladst</a></li>
<li>paper_authors: Fu Lin, Xuexiong Luo, Jia Wu, Jian Yang, Shan Xue, Zitong Wang, Haonan Gong</li>
<li>for: 本文目的是为了检测图像中的图形异常，而不是 traditional node-level anomaly detection 任务中的节点异常检测。</li>
<li>methods: 本文提出了一种新的图形异常检测方法，包括定义图像中异常信息、采用节点级和图像级信息差异来识别异常图像，以及使用两个学生模型和一个导师模型来分别学习正常和异常图像的表示。</li>
<li>results: 经过广泛的实验分析，本文的方法在实际世界图像 dataset 上显示了效果，能够准确检测图像中的异常图形。<details>
<summary>Abstract</summary>
Different from the current node-level anomaly detection task, the goal of graph-level anomaly detection is to find abnormal graphs that significantly differ from others in a graph set. Due to the scarcity of research on the work of graph-level anomaly detection, the detailed description of graph-level anomaly is insufficient. Furthermore, existing works focus on capturing anomalous graph information to learn better graph representations, but they ignore the importance of an effective anomaly score function for evaluating abnormal graphs. Thus, in this work, we first define anomalous graph information including node and graph property anomalies in a graph set and adopt node-level and graph-level information differences to identify them, respectively. Then, we introduce a discriminative graph-level anomaly detection framework with dual-students-teacher model, where the teacher model with a heuristic loss are trained to make graph representations more divergent. Then, two competing student models trained by normal and abnormal graphs respectively fit graph representations of the teacher model in terms of node-level and graph-level representation perspectives. Finally, we combine representation errors between two student models to discriminatively distinguish anomalous graphs. Extensive experiment analysis demonstrates that our method is effective for the graph-level anomaly detection task on graph datasets in the real world.
</details>
<details>
<summary>摘要</summary>
不同于当前节点级异常检测任务，graph-level异常检测的目标是找到图集中异常的图，并且与其他图集中的图进行比较。由于关于graph-level异常检测的研究缺乏，graph-level异常的详细描述不够。此外，现有的工作都是捕捉异常图信息来学习更好的图表示，但它们忽略了效果的异常分数函数的重要性。因此，在这个工作中，我们首先定义图集中的异常图信息，包括节点和图属性异常，并采用节点级和图级信息差来识别它们。然后，我们提出了一种有效的图级异常检测框架，基于双学生-教师模型，其中教师模型通过规则损失来训练图表示更加分散。然后，两个竞争的学生模型，分别使用正常和异常图来训练教师模型的图表示，并在节点级和图级表示视角下进行匹配。最后，我们将两个学生模型的表示错误相加，以分别地区分异常图。我们的方法在实际世界上的图据集上进行了广泛的实验分析，并证明其效果。
</details></li>
</ul>
<hr>
<h2 id="DOLCE-A-Descriptive-Ontology-for-Linguistic-and-Cognitive-Engineering"><a href="#DOLCE-A-Descriptive-Ontology-for-Linguistic-and-Cognitive-Engineering" class="headerlink" title="DOLCE: A Descriptive Ontology for Linguistic and Cognitive Engineering"></a>DOLCE: A Descriptive Ontology for Linguistic and Cognitive Engineering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01597">http://arxiv.org/abs/2308.01597</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefano Borgo, Roberta Ferrario, Aldo Gangemi, Nicola Guarino, Claudio Masolo, Daniele Porello, Emilio M. Sanfilippo, Laure Vieu</li>
<li>for:  dolce是一个基础 Ontology，用于提供一致的世界观，并且可以将各个领域知识融合到一起。</li>
<li>methods: DOLCE是基于 cognitive和语言考虑的，并且遵循了一些哲学原则和已Established ontological方法，例如OntoClean。</li>
<li>results: DOLCE在过去二十年中保持稳定，并且启发了大多数现有的顶层 ontologies，并且用于发展或改善标准和公共项目资源（例如CIDOC CRM、DBpedia和WordNet）。<details>
<summary>Abstract</summary>
DOLCE, the first top-level (foundational) ontology to be axiomatized, has remained stable for twenty years and today is broadly used in a variety of domains. DOLCE is inspired by cognitive and linguistic considerations and aims to model a commonsense view of reality, like the one human beings exploit in everyday life in areas as diverse as socio-technical systems, manufacturing, financial transactions and cultural heritage. DOLCE clearly lists the ontological choices it is based upon, relies on philosophical principles, is richly formalized, and is built according to well-established ontological methodologies, e.g. OntoClean. Because of these features, it has inspired most of the existing top-level ontologies and has been used to develop or improve standards and public domain resources (e.g. CIDOC CRM, DBpedia and WordNet). Being a foundational ontology, DOLCE is not directly concerned with domain knowledge. Its purpose is to provide the general categories and relations needed to give a coherent view of reality, to integrate domain knowledge, and to mediate across domains. In these 20 years DOLCE has shown that applied ontologies can be stable and that interoperability across reference and domain ontologies is a reality. This paper briefly introduces the ontology and shows how to use it on a few modeling cases.
</details>
<details>
<summary>摘要</summary>
DOLCE，第一个基础 Ontology（基础 ontology），已经稳定了二十年了，今天在多个领域都广泛使用。DOLCE 受到了认知和语言考虑的影响，旨在模型人类日常生活中的常识视角，如社技系统、制造、财务交易和文化遗产等领域。DOLCE 明确列出了其 ontological 选择基础，依靠哲学原则，富有形式化，按照良好的 ontological 方法ologies（如 OntoClean）建立。由于这些特点，它已经影响了大多数现有的基础 ontologies，并用于开发或改进标准和公共领域资源（如 CIDOC CRM、DBpedia 和 WordNet）。作为基础 ontology，DOLCE 不直接关心域知识。其目的是提供一个一致的视角，整合域知识，并在域之间媒介。在过去二十年中，DOLCE 表明了应用 ontologies 可以稳定，并且域 Ontology 之间的可操作性是现实。这篇文章简要介绍了 ontology，并示例了一些模型案例。
</details></li>
</ul>
<hr>
<h2 id="Holy-Grail-2-0-From-Natural-Language-to-Constraint-Models"><a href="#Holy-Grail-2-0-From-Natural-Language-to-Constraint-Models" class="headerlink" title="Holy Grail 2.0: From Natural Language to Constraint Models"></a>Holy Grail 2.0: From Natural Language to Constraint Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01589">http://arxiv.org/abs/2308.01589</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dimos Tsouros, Hélène Verhaeghe, Serdar Kadıoğlu, Tias Guns</li>
<li>for: 本研究旨在探讨使用预训练的大语言模型提取模型从文本问题描述中的可能性，以便提高Constraint Programming（CP）的普及率。</li>
<li>methods: 本研究使用了一种基于分解的提示方法，通过与GPT模型进行交互来提取模型。</li>
<li>results: 初步结果表明，这种方法可以帮助提取出高质量的模型，并且可以减少CP用户需要具备的专业知识和技能。<details>
<summary>Abstract</summary>
Twenty-seven years ago, E. Freuder highlighted that "Constraint programming represents one of the closest approaches computer science has yet made to the Holy Grail of programming: the user states the problem, the computer solves it". Nowadays, CP users have great modeling tools available (like Minizinc and CPMpy), allowing them to formulate the problem and then let a solver do the rest of the job, getting closer to the stated goal. However, this still requires the CP user to know the formalism and respect it. Another significant challenge lies in the expertise required to effectively model combinatorial problems. All this limits the wider adoption of CP. In this position paper, we investigate a possible approach to leverage pre-trained Large Language Models to extract models from textual problem descriptions. More specifically, we take inspiration from the Natural Language Processing for Optimization (NL4OPT) challenge and present early results with a decomposition-based prompting approach to GPT Models.
</details>
<details>
<summary>摘要</summary>
27年前，E. Freuder指出了“约束编程代表计算机科学最接近圣杯编程的尝试：用户定义问题，计算机解决”。目前，CP用户有了优秀的模型化工具（如Minizinc和CPMpy），可以将问题形式化并让解决器完成其余的任务，从而更接近目标。然而，这还需要CP用户了解正式语法，并且对 combinatorial 问题的模型化技巧具有专业知识。这些限制了CP更广泛的应用。在这篇Position paper中，我们investigate一种可能的方法，使用预训练的大型自然语言模型提取问题描述中的模型。更 Specifically，我们从Natural Language Processing for Optimization（NL4OPT）挑战中得到灵感，并使用分解基于Prompting Approach来应用GPT模型。
</details></li>
</ul>
<hr>
<h2 id="SoK-Assessing-the-State-of-Applied-Federated-Machine-Learning"><a href="#SoK-Assessing-the-State-of-Applied-Federated-Machine-Learning" class="headerlink" title="SoK: Assessing the State of Applied Federated Machine Learning"></a>SoK: Assessing the State of Applied Federated Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02454">http://arxiv.org/abs/2308.02454</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tobias Müller, Maximilian Stäbler, Hugo Gascón, Frank Köster, Florian Matthes</li>
<li>for: This paper aims to explore the current state of applied Federated Machine Learning (FedML) and identify the challenges hindering its practical adoption.</li>
<li>methods: The paper uses a comprehensive systematic literature review to assess 74 relevant papers and analyze the real-world applicability of FedML, including its characteristics and emerging trends, motivational drivers, and application domains.</li>
<li>results: The paper identifies the challenges encountered in integrating FedML into real-life settings, providing insights that contribute to the further development and implementation of FedML in privacy-critical scenarios.<details>
<summary>Abstract</summary>
Machine Learning (ML) has shown significant potential in various applications; however, its adoption in privacy-critical domains has been limited due to concerns about data privacy. A promising solution to this issue is Federated Machine Learning (FedML), a model-to-data approach that prioritizes data privacy. By enabling ML algorithms to be applied directly to distributed data sources without sharing raw data, FedML offers enhanced privacy protections, making it suitable for privacy-critical environments. Despite its theoretical benefits, FedML has not seen widespread practical implementation. This study aims to explore the current state of applied FedML and identify the challenges hindering its practical adoption. Through a comprehensive systematic literature review, we assess 74 relevant papers to analyze the real-world applicability of FedML. Our analysis focuses on the characteristics and emerging trends of FedML implementations, as well as the motivational drivers and application domains. We also discuss the encountered challenges in integrating FedML into real-life settings. By shedding light on the existing landscape and potential obstacles, this research contributes to the further development and implementation of FedML in privacy-critical scenarios.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Unsupervised-Representation-Learning-for-Time-Series-A-Review"><a href="#Unsupervised-Representation-Learning-for-Time-Series-A-Review" class="headerlink" title="Unsupervised Representation Learning for Time Series: A Review"></a>Unsupervised Representation Learning for Time Series: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01578">http://arxiv.org/abs/2308.01578</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mqwfrog/ults">https://github.com/mqwfrog/ults</a></li>
<li>paper_authors: Qianwen Meng, Hangwei Qian, Yong Liu, Yonghui Xu, Zhiqi Shen, Lizhen Cui</li>
<li>for: 本研究旨在系统地分析无监督表示学习方法，尤其是在时序数据上。</li>
<li>methods: 本文使用了多种无监督表示学习方法，包括对比学习、自适应 represencing 等。</li>
<li>results: 经验证明，对比学习方法在9个真实世界数据集上的表现很出色，而且可以快速实现和统一评估不同模型。<details>
<summary>Abstract</summary>
Unsupervised representation learning approaches aim to learn discriminative feature representations from unlabeled data, without the requirement of annotating every sample. Enabling unsupervised representation learning is extremely crucial for time series data, due to its unique annotation bottleneck caused by its complex characteristics and lack of visual cues compared with other data modalities. In recent years, unsupervised representation learning techniques have advanced rapidly in various domains. However, there is a lack of systematic analysis of unsupervised representation learning approaches for time series. To fill the gap, we conduct a comprehensive literature review of existing rapidly evolving unsupervised representation learning approaches for time series. Moreover, we also develop a unified and standardized library, named ULTS (i.e., Unsupervised Learning for Time Series), to facilitate fast implementations and unified evaluations on various models. With ULTS, we empirically evaluate state-of-the-art approaches, especially the rapidly evolving contrastive learning methods, on 9 diverse real-world datasets. We further discuss practical considerations as well as open research challenges on unsupervised representation learning for time series to facilitate future research in this field.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate into Simplified Chinese无监督表示学习方法target=blank>target=blank aim to learn discriminative feature representations from unlabeled data, without the requirement of annotating every sample.  enable unsupervised representation learning is extremely crucial for time series data, due to its unique annotation bottleneck caused by its complex characteristics and lack of visual cues compared with other data modalities. In recent years, unsupervised representation learning techniques have advanced rapidly in various domains. However, there is a lack of systematic analysis of unsupervised representation learning approaches for time series. To fill the gap, we conduct a comprehensive literature review of existing rapidly evolving unsupervised representation learning approaches for time series. Moreover, we also develop a unified and standardized library, named ULTS (i.e., Unsupervised Learning for Time Series), to facilitate fast implementations and unified evaluations on various models. With ULTS, we empirically evaluate state-of-the-art approaches, especially the rapidly evolving contrastive learning methods, on 9 diverse real-world datasets. We further discuss practical considerations as well as open research challenges on unsupervised representation learning for time series to facilitate future research in this field.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore.
</details></li>
</ul>
<hr>
<h2 id="SimTeG-A-Frustratingly-Simple-Approach-Improves-Textual-Graph-Learning"><a href="#SimTeG-A-Frustratingly-Simple-Approach-Improves-Textual-Graph-Learning" class="headerlink" title="SimTeG: A Frustratingly Simple Approach Improves Textual Graph Learning"></a>SimTeG: A Frustratingly Simple Approach Improves Textual Graph Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02565">http://arxiv.org/abs/2308.02565</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vermouthdky/simteg">https://github.com/vermouthdky/simteg</a></li>
<li>paper_authors: Keyu Duan, Qian Liu, Tat-Seng Chua, Shuicheng Yan, Wei Tsang Ooi, Qizhe Xie, Junxian He</li>
<li>for: 这个论文主要是为了提高文本图学习的效果，特别是在文本图 Representation learning 阶段。</li>
<li>methods: 这个论文使用了一种简单的方法，即在已经预训练的语言模型（LM）上进行超参数efficient fine-tuning（PEFT），然后使用最后的隐藏状态来生成节点嵌入。</li>
<li>results: 这个论文的实验结果表明，使用这种方法可以大幅提高多种图神经网络（GNN）在多个图 benchmark 上的表现。<details>
<summary>Abstract</summary>
Textual graphs (TGs) are graphs whose nodes correspond to text (sentences or documents), which are widely prevalent. The representation learning of TGs involves two stages: (i) unsupervised feature extraction and (ii) supervised graph representation learning. In recent years, extensive efforts have been devoted to the latter stage, where Graph Neural Networks (GNNs) have dominated. However, the former stage for most existing graph benchmarks still relies on traditional feature engineering techniques. More recently, with the rapid development of language models (LMs), researchers have focused on leveraging LMs to facilitate the learning of TGs, either by jointly training them in a computationally intensive framework (merging the two stages), or designing complex self-supervised training tasks for feature extraction (enhancing the first stage). In this work, we present SimTeG, a frustratingly Simple approach for Textual Graph learning that does not innovate in frameworks, models, and tasks. Instead, we first perform supervised parameter-efficient fine-tuning (PEFT) on a pre-trained LM on the downstream task, such as node classification. We then generate node embeddings using the last hidden states of finetuned LM. These derived features can be further utilized by any GNN for training on the same task. We evaluate our approach on two fundamental graph representation learning tasks: node classification and link prediction. Through extensive experiments, we show that our approach significantly improves the performance of various GNNs on multiple graph benchmarks.
</details>
<details>
<summary>摘要</summary>
文本图（TG）是一种广泛存在的图，其节点对应于文本（句子或文档）。图像学习TG的过程包括两个阶段：（i）不监督的特征提取和（ii）监督图像学习。在过去几年中，大量精力被投入到后一个阶段中，而GNNs（图像神经网络）在这个阶段中占据了主导地位。然而，前一个阶段的大多数现有的图标准 benchmark仍然采用传统的特征工程技术。随着语言模型（LM）的快速发展，研究人员开始利用LM来促进TG的学习，例如通过在计算昂贵的框架中同时训练LM和TG（合并两个阶段），或者设计复杂的自我超视图任务来提高特征提取（增强第一个阶段）。在这种情况下，我们提出了SimTeG，一种简单而惊人的文本图学习方法。我们首先在预训练LM上进行监督参数效率提升（PEFT），然后生成节点嵌入使用预训练LM的最后隐藏状态。这些 derivated 特征可以被任何GNN用于训练同一个任务。我们对两个基本的图表示学习任务进行了广泛的实验：节点类别化和链接预测。通过广泛的实验，我们显示了我们的方法可以在多个图标准 benchmark上提高多种GNN的表现。
</details></li>
</ul>
<hr>
<h2 id="Motion-Planning-Diffusion-Learning-and-Planning-of-Robot-Motions-with-Diffusion-Models"><a href="#Motion-Planning-Diffusion-Learning-and-Planning-of-Robot-Motions-with-Diffusion-Models" class="headerlink" title="Motion Planning Diffusion: Learning and Planning of Robot Motions with Diffusion Models"></a>Motion Planning Diffusion: Learning and Planning of Robot Motions with Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01557">http://arxiv.org/abs/2308.01557</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joao Carvalho, An T. Le, Mark Baierl, Dorothea Koert, Jan Peters</li>
<li>for: 加速机器人动作规划优化的学习先骨</li>
<li>methods: 使用扩散模型作为先骨，直接从 posterior 动作分布中采样，并利用扩散模型的逆噪减法来编码动作数据的多模性</li>
<li>results: 在 simulate 的平面机器人和 7-DOF 机器人 manipulate 环境中，与基准方法进行比较，表明扩散模型是高维动作分布的强大先骨，能够Encoding 高维动作数据的多模性。<details>
<summary>Abstract</summary>
Learning priors on trajectory distributions can help accelerate robot motion planning optimization. Given previously successful plans, learning trajectory generative models as priors for a new planning problem is highly desirable. Prior works propose several ways on utilizing this prior to bootstrapping the motion planning problem. Either sampling the prior for initializations or using the prior distribution in a maximum-a-posterior formulation for trajectory optimization. In this work, we propose learning diffusion models as priors. We then can sample directly from the posterior trajectory distribution conditioned on task goals, by leveraging the inverse denoising process of diffusion models. Furthermore, diffusion has been recently shown to effectively encode data multimodality in high-dimensional settings, which is particularly well-suited for large trajectory dataset. To demonstrate our method efficacy, we compare our proposed method - Motion Planning Diffusion - against several baselines in simulated planar robot and 7-dof robot arm manipulator environments. To assess the generalization capabilities of our method, we test it in environments with previously unseen obstacles. Our experiments show that diffusion models are strong priors to encode high-dimensional trajectory distributions of robot motions.
</details>
<details>
<summary>摘要</summary>
学习轨迹分布可以帮助加速机器人运动规划优化。给出过去成功的计划，使用轨迹生成模型作为优化问题的先验分布是非常感兴趣的。先前的工作提出了多种使用这种先验来启动运动规划问题的方法。可以从先验中随机取样，或者使用先验分布来形式化最大 posterior 式对 trajectory 进行优化。在这种工作中，我们提议使用扩散模型来学习先验。我们可以通过扩散模型的逆干扰过程直接从任务目标条件下样本 posterior 轨迹分布。此外，扩散模型最近在高维设定中能够有效地编码数据多模性，这 particulary 适合大轨迹数据集。为了证明我们的方法效果，我们与多个基eline 进行比较，在 simulated 平面机器人和 7-DOF 机器人 manipulator 环境中进行测试。为了评估我们的方法泛化能力，我们在不同的障碍物环境中进行测试。我们的实验显示，扩散模型是高维轨迹分布的强大先验。
</details></li>
</ul>
<hr>
<h2 id="A-Global-Transport-Capacity-Risk-Prediction-Method-for-Rail-Transit-Based-on-Gaussian-Bayesian-Network"><a href="#A-Global-Transport-Capacity-Risk-Prediction-Method-for-Rail-Transit-Based-on-Gaussian-Bayesian-Network" class="headerlink" title="A Global Transport Capacity Risk Prediction Method for Rail Transit Based on Gaussian Bayesian Network"></a>A Global Transport Capacity Risk Prediction Method for Rail Transit Based on Gaussian Bayesian Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01556">http://arxiv.org/abs/2308.01556</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhang Zhengyang, Dong Wei, Liu jun, Sun Xinya, Ji Yindong</li>
<li>for: 预测铁路公共交通网络运输容量风险，即铁路交通网络的负载与乘客流量的差异。</li>
<li>methods: 使用线性 Gaussian Bayesian 网络来解释预测模型，并基于铁路交通网络的三层结构（包括铁路交通网络、车流和乘客流）获取预测模型的训练数据。</li>
<li>results: 通过 simulate 例子验证了提议的方法的有效性。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Aiming at the prediction problem of transport capacity risk caused by the mismatch between the carrying capacity of rail transit network and passenger flow demand, this paper proposes an explainable prediction method of rail transit network transport capacity risk based on linear Gaussian Bayesian network. This method obtains the training data of the prediction model based on the simulation model of the rail transit system with a three-layer structure including rail transit network, train flow and passenger flow. A Bayesian network structure construction method based on the topology of the rail transit network is proposed, and the MLE (Maximum Likelihood Estimation) method is used to realize the parameter learning of the Bayesian network. Finally, the effectiveness of the proposed method is verified by simulation examples.
</details>
<details>
<summary>摘要</summary>
目标是预测由铁路 транспорт网络载客量和乘客流量差异引起的运输 capacidad 风险的预测方法，本文提出了可解释的预测方法基于线性 Gaussian Bayesian 网络。该方法通过基于铁路 транспорт网络的模拟模型，包括铁路网络、车流和乘客流，来获取预测模型的训练数据。提出了基于铁路网络 topology 的 Bayesian 网络结构建构方法，并使用 MLE (最大likelihood估计) 方法实现参数学习。最后，通过模拟例子验证了该方法的效果。Here's the translation of the text into Traditional Chinese:目的是预测由铁路 транспорт网络载客量和乘客流量差异引起的运输 capacidad 风险的预测方法，本文提出了可解释的预测方法基于线性 Gaussian Bayesian 网络。该方法通过基于铁路 транспорт网络的模拟模型，包括铁路网络、车流和乘客流，来获取预测模型的训练数据。提出了基于铁路网络 topology 的 Bayesian 网络结构建构方法，并使用 MLE (最大likelihood估计) 方法实现参数学习。最后，通过模拟例子验证了该方法的效果。
</details></li>
</ul>
<hr>
<h2 id="InterAct-Exploring-the-Potentials-of-ChatGPT-as-a-Cooperative-Agent"><a href="#InterAct-Exploring-the-Potentials-of-ChatGPT-as-a-Cooperative-Agent" class="headerlink" title="InterAct: Exploring the Potentials of ChatGPT as a Cooperative Agent"></a>InterAct: Exploring the Potentials of ChatGPT as a Cooperative Agent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01552">http://arxiv.org/abs/2308.01552</a></li>
<li>repo_url: None</li>
<li>paper_authors: Po-Lin Chen, Cheng-Shang Chang</li>
<li>for: 这个论文探讨了将OpenAI的ChatGPT集成到embodied agent系统中，以评估它对交互决策benchmark的影响。</li>
<li>methods: 我们引入了InterAct方法，将ChatGPT fed with varied prompts，分配它多个角色，如检查员和排序员，然后与原始语言模型结合。</li>
<li>results: 我们的研究表明，在AlfWorld中，ChatGPT的表现率达98%，包括6个不同任务在模拟家庭环境中，这显示了ChatGPT在真实世界设置下处理复杂任务的能力，并为任务规划铺平了道路。<details>
<summary>Abstract</summary>
This research paper delves into the integration of OpenAI's ChatGPT into embodied agent systems, evaluating its influence on interactive decision-making benchmark. Drawing a parallel to the concept of people assuming roles according to their unique strengths, we introduce InterAct. In this approach, we feed ChatGPT with varied prompts, assigning it a numerous roles like a checker and a sorter, then integrating them with the original language model. Our research shows a remarkable success rate of 98% in AlfWorld, which consists of 6 different tasks in a simulated household environment, emphasizing the significance of proficient prompt engineering. The results highlight ChatGPT's competence in comprehending and performing intricate tasks effectively in real-world settings, thus paving the way for further advancements in task planning.
</details>
<details>
<summary>摘要</summary>
这份研究论文探讨了OpenAI的ChatGPT在具有体系中的整合，评估其对交互决策 bencmark 的影响。我们引入InterAct方法，在不同的任务中 feed ChatGPT 不同的提示，让它扮演多种角色，如检查员和排序员，然后将其与原始语言模型集成。我们的研究发现，在AlfWorld中的6个任务中，ChatGPT 的成功率达98%，这些任务是在模拟的家庭环境中进行的，这 demonstartes ChatGPT 在实际世界中完成复杂任务的能力，从而铺平了进一步发展任务规划的道路。
</details></li>
</ul>
<hr>
<h2 id="Avoidance-Navigation-Based-on-Offline-Pre-Training-Reinforcement-Learning"><a href="#Avoidance-Navigation-Based-on-Offline-Pre-Training-Reinforcement-Learning" class="headerlink" title="Avoidance Navigation Based on Offline Pre-Training Reinforcement Learning"></a>Avoidance Navigation Based on Offline Pre-Training Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01551">http://arxiv.org/abs/2308.01551</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Wenkai Ji Ruihang Zhang Yuxiang Lei Hao, Zhao Zijie</li>
<li>for: 这个论文旨在适用深度强化学习（DRL）技术，帮助无地图移动机器人进行避免导航。</li>
<li>methods: 论文提出了一种在未知环境中使用 raw 感知数据与控制变量的映射，以及一种高效的离线培训策略，以加速扫描阶段的随机探索。 论文还收集了一个通用的数据集，包括专家经验，以便用于其他导航培训工作。</li>
<li>results: 论文表明，采用预训练和优先级专家经验可以减少80%的培训时间，并且可以提高DRL奖励的2倍。这些方法还被证明可以在真实环境中实现无碰撞导航。论文还证明了这种DRL模型在不同环境中具有通用的普适性。<details>
<summary>Abstract</summary>
This paper presents a Pre-Training Deep Reinforcement Learning(DRL) for avoidance navigation without map for mobile robots which map raw sensor data to control variable and navigate in an unknown environment. The efficient offline training strategy is proposed to speed up the inefficient random explorations in early stage and we also collect a universal dataset including expert experience for offline training, which is of some significance for other navigation training work. The pre-training and prioritized expert experience are proposed to reduce 80\% training time and has been verified to improve the 2 times reward of DRL. The advanced simulation gazebo with real physical modelling and dynamic equations reduce the gap between sim-to-real. We train our model a corridor environment, and evaluate the model in different environment getting the same effect. Compared to traditional method navigation, we can confirm the trained model can be directly applied into different scenarios and have the ability to no collision navigate. It was demonstrated that our DRL model have universal general capacity in different environment.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MusicLDM-Enhancing-Novelty-in-Text-to-Music-Generation-Using-Beat-Synchronous-Mixup-Strategies"><a href="#MusicLDM-Enhancing-Novelty-in-Text-to-Music-Generation-Using-Beat-Synchronous-Mixup-Strategies" class="headerlink" title="MusicLDM: Enhancing Novelty in Text-to-Music Generation Using Beat-Synchronous Mixup Strategies"></a>MusicLDM: Enhancing Novelty in Text-to-Music Generation Using Beat-Synchronous Mixup Strategies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01546">http://arxiv.org/abs/2308.01546</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ke Chen, Yusong Wu, Haohe Liu, Marianna Nezhurina, Taylor Berg-Kirkpatrick, Shlomo Dubnov<br>for:这篇论文的目的是提出一种基于稳定扩散模型的文本到音乐生成模型，以解决音乐生成任务中的数据有限和版权问题。methods:这篇论文使用了稳定扩散模型和音乐LDM架构，并通过重新训练CLAP预训练模型和Hifi-GAN vocoder来适应音乐领域。此外，该论文还提出了两种不同的混合策略，以便在训练数据有限的情况下生成更多样化的音乐。results:论文的实验结果表明，提出的MusicLDM模型和混合策略可以提高生成的音乐质量和创新性，同时仍保持输入文本和生成音乐之间的相似性。此外，该论文还设计了一些新的评价指标，以证明MusicLDM模型和混合策略在生成音乐时的效果。<details>
<summary>Abstract</summary>
Diffusion models have shown promising results in cross-modal generation tasks, including text-to-image and text-to-audio generation. However, generating music, as a special type of audio, presents unique challenges due to limited availability of music data and sensitive issues related to copyright and plagiarism. In this paper, to tackle these challenges, we first construct a state-of-the-art text-to-music model, MusicLDM, that adapts Stable Diffusion and AudioLDM architectures to the music domain. We achieve this by retraining the contrastive language-audio pretraining model (CLAP) and the Hifi-GAN vocoder, as components of MusicLDM, on a collection of music data samples. Then, to address the limitations of training data and to avoid plagiarism, we leverage a beat tracking model and propose two different mixup strategies for data augmentation: beat-synchronous audio mixup and beat-synchronous latent mixup, which recombine training audio directly or via a latent embeddings space, respectively. Such mixup strategies encourage the model to interpolate between musical training samples and generate new music within the convex hull of the training data, making the generated music more diverse while still staying faithful to the corresponding style. In addition to popular evaluation metrics, we design several new evaluation metrics based on CLAP score to demonstrate that our proposed MusicLDM and beat-synchronous mixup strategies improve both the quality and novelty of generated music, as well as the correspondence between input text and generated music.
</details>
<details>
<summary>摘要</summary>
Diffusion模型在跨Modal生成任务中表现出色，包括文本到图像和文本到音频生成。然而，生成音乐，作为特殊的音频类型，存在独特的挑战，主要是数据的有限性和版权问题。在这篇论文中，我们为解决这些挑战，首先构建了领先的文本到音乐模型MusicLDM。我们在音乐领域使用Stable Diffusion和AudioLDM架构，并通过重新训练CLAP和Hifi-GAN vocoder来适应音乐领域。然后，为了解决训练数据的限制和避免抄袭，我们提出了拍数跟踪模型和两种不同的混合策略：拍数同步音频混合和拍数同步秘密混合，这些策略可以让模型在训练音乐样本之间进行混合，从而生成更多样的音乐，同时仍然保持与输入文本的相关性。此外，我们还设计了一些基于CLAP分数的新评价指标，以证明我们的提议的MusicLDM和拍数同步混合策略可以提高生成的音乐质量和新颖性，同时保持输入文本和生成音乐之间的相关性。
</details></li>
</ul>
<hr>
<h2 id="Lode-Enhancer-Level-Co-creation-Through-Scaling"><a href="#Lode-Enhancer-Level-Co-creation-Through-Scaling" class="headerlink" title="Lode Enhancer: Level Co-creation Through Scaling"></a>Lode Enhancer: Level Co-creation Through Scaling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01543">http://arxiv.org/abs/2308.01543</a></li>
<li>repo_url: None</li>
<li>paper_authors: Debosmita Bhaumik, Julian Togelius, Georgios N. Yannakakis, Ahmed Khalifa</li>
<li>for: 这个论文的目的是用AI技术为创建2D游戏层提供设计协助工具。</li>
<li>methods: 论文使用深度神经网络来采用人工压缩的补丁来逐渐增加级别的级别，并将这些训练的神经网络集成到了一个基于网络的编辑器中，以便用户可以在不同的分辨率下创建和编辑层。</li>
<li>results: 论文通过训练神经网络来增加级别，并通过提供不同的分辨率来帮助用户快速创建和编辑层。在使用这个工具时，设计师感到了合作的感觉，喜欢这个概念，并提供了进一步改进的反馈。<details>
<summary>Abstract</summary>
We explore AI-powered upscaling as a design assistance tool in the context of creating 2D game levels. Deep neural networks are used to upscale artificially downscaled patches of levels from the puzzle platformer game Lode Runner. The trained networks are incorporated into a web-based editor, where the user can create and edit levels at three different levels of resolution: 4x4, 8x8, and 16x16. An edit at any resolution instantly transfers to the other resolutions. As upscaling requires inventing features that might not be present at lower resolutions, we train neural networks to reproduce these features. We introduce a neural network architecture that is capable of not only learning upscaling but also giving higher priority to less frequent tiles. To investigate the potential of this tool and guide further development, we conduct a qualitative study with 3 designers to understand how they use it. Designers enjoyed co-designing with the tool, liked its underlying concept, and provided feedback for further improvement.
</details>
<details>
<summary>摘要</summary>
我们探索基于人工智能的水平升级作为游戏等级设计工具。我们使用深度神经网络来升级由游戏平台冒险游戏《劫 runner》中 искусственно压缩的 patches 的等级。我们在基于网络的编辑器中 integrate 了这些训练过的网络，allowing 用户在不同的分辨率（4x4、8x8和16x16）上创建和编辑等级。任何一个分辨率的编辑都会立即传输到其他分辨率上。由于升级需要创造不存在于较低分辨率中的特征，我们训练神经网络来重现这些特征。我们提出了一种神经网络架构，可以不仅学习升级，而且在较少的块出现时给予更高的优先级。为了了解这种工具的潜力和进一步发展的方向，我们进行了3名设计师的质量调研，了解他们如何使用这种工具，并提供了反馈 для进一步改进。
</details></li>
</ul>
<hr>
<h2 id="Non-equilibrium-physics-from-spin-glasses-to-machine-and-neural-learning"><a href="#Non-equilibrium-physics-from-spin-glasses-to-machine-and-neural-learning" class="headerlink" title="Non-equilibrium physics: from spin glasses to machine and neural learning"></a>Non-equilibrium physics: from spin glasses to machine and neural learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01538">http://arxiv.org/abs/2308.01538</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weishun Zhong</li>
<li>for: 这个论文的目的是研究杂乱体系中的emergent智能现象，以便更好地理解这些系统的工作机制和应用于人工智能领域。</li>
<li>methods: 这篇论文使用统计物理来描述杂乱体系中的emergent智能行为，并分析这些系统的学习机制和动力学特性。</li>
<li>results: 这篇论文发现了杂乱体系中学习机制和物理动力学之间的关系，并提出了一种基于统计物理的方法来设计智能系统。这些发现可能扩展我们对智能系统的现代理解，并揭示更多的计算基础结构适用于人工智能应用。<details>
<summary>Abstract</summary>
Disordered many-body systems exhibit a wide range of emergent phenomena across different scales. These complex behaviors can be utilized for various information processing tasks such as error correction, learning, and optimization. Despite the empirical success of utilizing these systems for intelligent tasks, the underlying principles that govern their emergent intelligent behaviors remain largely unknown. In this thesis, we aim to characterize such emergent intelligence in disordered systems through statistical physics. We chart a roadmap for our efforts in this thesis based on two axes: learning mechanisms (long-term memory vs. working memory) and learning dynamics (artificial vs. natural). Throughout our journey, we uncover relationships between learning mechanisms and physical dynamics that could serve as guiding principles for designing intelligent systems. We hope that our investigation into the emergent intelligence of seemingly disparate learning systems can expand our current understanding of intelligence beyond neural systems and uncover a wider range of computational substrates suitable for AI applications.
</details>
<details>
<summary>摘要</summary>
多体系统的异常行为展示了各种emergent现象，从不同的尺度到不同的级别。这些复杂的行为可以用于各种信息处理任务，如错误检查、学习和优化。虽然使用这些系统进行智能任务的实践成果非常出色，但是这些系统的下面的原理还未得到了充分了解。在这个论文中，我们想通过统计物理来描述这些emergent智能行为。我们根据两个轴来制定我们的路线图：学习机制（长期记忆 vs.工作记忆）和学习动态（人工vs.自然）。在我们的旅程中，我们发现了学习机制和物理动态之间的关系，这些关系可能成为设计智能系统的导向原理。我们希望通过对各种学习系统的emergent智能行为的研究，扩展我们当前对智能的理解，并探索更多的计算substrate适用于AI应用。
</details></li>
</ul>
<hr>
<h2 id="Food-Classification-using-Joint-Representation-of-Visual-and-Textual-Data"><a href="#Food-Classification-using-Joint-Representation-of-Visual-and-Textual-Data" class="headerlink" title="Food Classification using Joint Representation of Visual and Textual Data"></a>Food Classification using Joint Representation of Visual and Textual Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02562">http://arxiv.org/abs/2308.02562</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prateek Mittal, Puneet Goyal, Joohi Chauhan</li>
<li>for: 这个研究旨在提出一个多 modal 分类框架，用于健康领域中的食品分类。</li>
<li>methods: 提议的网络使用 modified EfficientNet 和 Mish 活化函数进行图像分类，并使用传统的 BERT 对应网络进行文本分类。</li>
<li>results: 实验结果显示，提议的网络在大规模的 open-source 数据集 UPMC Food-101 上的评估中，与其他方法相比，获得了11.57% 和 6.34% 的精度差。<details>
<summary>Abstract</summary>
Food classification is an important task in health care. In this work, we propose a multimodal classification framework that uses the modified version of EfficientNet with the Mish activation function for image classification, and the traditional BERT transformer-based network is used for text classification. The proposed network and the other state-of-the-art methods are evaluated on a large open-source dataset, UPMC Food-101. The experimental results show that the proposed network outperforms the other methods, a significant difference of 11.57% and 6.34% in accuracy is observed for image and text classification, respectively, when compared with the second-best performing method. We also compared the performance in terms of accuracy, precision, and recall for text classification using both machine learning and deep learning-based models. The comparative analysis from the prediction results of both images and text demonstrated the efficiency and robustness of the proposed approach.
</details>
<details>
<summary>摘要</summary>
食品分类是医疗保健领域中的一项重要任务。在这项工作中，我们提出了一种多Modal分类框架，使用Modified版EfficientNet和Mish活动函数进行图像分类，并使用传统的BERT变换网络进行文本分类。我们的提案网络和其他状态泰施方法在大量的开源数据集UPMC Food-101上进行了评估。实验结果表明，我们的提案网络在图像和文本分类方面的性能都高于其他方法，与第二高性能方法的差异为11.57%和6.34%。我们还对文本分类方面的性能进行了精度、准确率和回归率的比较分析，并通过图像和文本预测结果的对比，证明了我们的方法的有效性和可靠性。
</details></li>
</ul>
<hr>
<h2 id="Digital-twin-brain-a-bridge-between-biological-intelligence-and-artificial-intelligence"><a href="#Digital-twin-brain-a-bridge-between-biological-intelligence-and-artificial-intelligence" class="headerlink" title="Digital twin brain: a bridge between biological intelligence and artificial intelligence"></a>Digital twin brain: a bridge between biological intelligence and artificial intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01941">http://arxiv.org/abs/2308.01941</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui Xiong, Congying Chu, Lingzhong Fan, Ming Song, Jiaqi Zhang, Yawei Ma, Ruonan Zheng, Junyang Zhang, Zhengyi Yang, Tianzi Jiang</li>
<li>for: 本文提出了一种名为“数字双脑”（Digital Twin Brain，DTB）的平台，用于将生物智能和人工智能联系起来，以更好地探索大脑的复杂性。</li>
<li>methods: 该平台包括三个核心元素：脑结构、底层模型和广泛的应用领域。此外，脑 Atlases 提供了关键的约束，以保持脑的网络结构在 DTB 中。</li>
<li>results: DTB 可以提供前所未有的智能出现和神经疾病研究，以及人工智能的发展和精准心理医疗的潜在应用。<details>
<summary>Abstract</summary>
In recent years, advances in neuroscience and artificial intelligence have paved the way for unprecedented opportunities for understanding the complexity of the brain and its emulation by computational systems. Cutting-edge advancements in neuroscience research have revealed the intricate relationship between brain structure and function, while the success of artificial neural networks highlights the importance of network architecture. Now is the time to bring them together to better unravel how intelligence emerges from the brain's multiscale repositories. In this review, we propose the Digital Twin Brain (DTB) as a transformative platform that bridges the gap between biological and artificial intelligence. It consists of three core elements: the brain structure that is fundamental to the twinning process, bottom-layer models to generate brain functions, and its wide spectrum of applications. Crucially, brain atlases provide a vital constraint, preserving the brain's network organization within the DTB. Furthermore, we highlight open questions that invite joint efforts from interdisciplinary fields and emphasize the far-reaching implications of the DTB. The DTB can offer unprecedented insights into the emergence of intelligence and neurological disorders, which holds tremendous promise for advancing our understanding of both biological and artificial intelligence, and ultimately propelling the development of artificial general intelligence and facilitating precision mental healthcare.
</details>
<details>
<summary>摘要</summary>
recent years, advances in neuroscience and artificial intelligence have created unprecedented opportunities for understanding the complexity of the brain and its emulation by computational systems. cutting-edge advancements in neuroscience research have revealed the intricate relationship between brain structure and function, while the success of artificial neural networks highlights the importance of network architecture. now is the time to bring them together to better unravel how intelligence emerges from the brain's multiscale repositories. in this review, we propose the digital twin brain (dTB) as a transformative platform that bridges the gap between biological and artificial intelligence. it consists of three core elements: the brain structure that is fundamental to the twinning process, bottom-layer models to generate brain functions, and its wide spectrum of applications. crucially, brain atlases provide a vital constraint, preserving the brain's network organization within the dTB. furthermore, we highlight open questions that invite joint efforts from interdisciplinary fields and emphasize the far-reaching implications of the dTB. the dTB can offer unprecedented insights into the emergence of intelligence and neurological disorders, which holds tremendous promise for advancing our understanding of both biological and artificial intelligence, and ultimately propelling the development of artificial general intelligence and facilitating precision mental healthcare.
</details></li>
</ul>
<hr>
<h2 id="Quantum-Multi-Agent-Reinforcement-Learning-for-Autonomous-Mobility-Cooperation"><a href="#Quantum-Multi-Agent-Reinforcement-Learning-for-Autonomous-Mobility-Cooperation" class="headerlink" title="Quantum Multi-Agent Reinforcement Learning for Autonomous Mobility Cooperation"></a>Quantum Multi-Agent Reinforcement Learning for Autonomous Mobility Cooperation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01519">http://arxiv.org/abs/2308.01519</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soohyun Park, Jae Pyoung Kim, Chanyoung Park, Soyi Jung, Joongheon Kim</li>
<li>for: 本研究旨在提出一种量子多智能学习（QMARL）算法，用于解决多智能系统中的强制参与问题。</li>
<li>methods: 本研究使用了actor-critic网络来实现QMARL，并通过提出一种投影值度量（PVM）来提高其可扩展性和快速启发。</li>
<li>results: 对于多智能系统，我们的提出的QMARL算法可以更好地处理噪声中间规模量子（NISQ）时代的限制，并且可以更快地到达启发。此外，我们的QMARL算法还可以更有效地使用参数，从而提高效率。<details>
<summary>Abstract</summary>
For Industry 4.0 Revolution, cooperative autonomous mobility systems are widely used based on multi-agent reinforcement learning (MARL). However, the MARL-based algorithms suffer from huge parameter utilization and convergence difficulties with many agents. To tackle these problems, a quantum MARL (QMARL) algorithm based on the concept of actor-critic network is proposed, which is beneficial in terms of scalability, to deal with the limitations in the noisy intermediate-scale quantum (NISQ) era. Additionally, our QMARL is also beneficial in terms of efficient parameter utilization and fast convergence due to quantum supremacy. Note that the reward in our QMARL is defined as task precision over computation time in multiple agents, thus, multi-agent cooperation can be realized. For further improvement, an additional technique for scalability is proposed, which is called projection value measure (PVM). Based on PVM, our proposed QMARL can achieve the highest reward, by reducing the action dimension into a logarithmic-scale. Finally, we can conclude that our proposed QMARL with PVM outperforms the other algorithms in terms of efficient parameter utilization, fast convergence, and scalability.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Large-scale-Generative-Simulation-Artificial-Intelligence-the-Next-Hotspot-in-Generative-AI"><a href="#Large-scale-Generative-Simulation-Artificial-Intelligence-the-Next-Hotspot-in-Generative-AI" class="headerlink" title="Large-scale Generative Simulation Artificial Intelligence: the Next Hotspot in Generative AI"></a>Large-scale Generative Simulation Artificial Intelligence: the Next Hotspot in Generative AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02561">http://arxiv.org/abs/2308.02561</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qi Wang, Yanghe Feng, Jincai Huang, Yiqin Lv, Zheng Xie, Xiaoshan Gao</li>
<li>for: 这篇研究是为了探讨大规模生成实验人工智能（LS-GenAI）是下一个热点，以应对实际挑战，例如学习资源的仅对等和科学发现的偏好。</li>
<li>methods: 本研究使用了大规模生成实验人工智能（LS-GenAI），以探讨实际挑战，例如学习资源的仅对等和科学发现的偏好。</li>
<li>results: 本研究获得了重要的发现，包括实际挑战的解决方案和LS-GenAI的应用前景。<details>
<summary>Abstract</summary>
The concept of GenAI has been developed for decades. Until recently, it has impressed us with substantial breakthroughs in natural language processing and computer vision, actively engaging in industrial scenarios. Noticing the practical challenges, e.g., limited learning resources, and overly dependencies on scientific discovery empiricism, we nominate large-scale generative simulation artificial intelligence (LS-GenAI) as the next hotspot for GenAI to connect.
</details>
<details>
<summary>摘要</summary>
GenAI的概念已经在数十年内发展，直到最近，它在自然语言处理和计算机视觉领域带来了重要的突破，活跃地投入到工业场景中。注意到实际挑战，例如有限的学习资源和科学发现的过度依赖，我们提名大规模生成仿真人工智能（LS-GenAI）为下一个GenAI连接的热点。
</details></li>
</ul>
<hr>
<h2 id="Implicit-Occupancy-Flow-Fields-for-Perception-and-Prediction-in-Self-Driving"><a href="#Implicit-Occupancy-Flow-Fields-for-Perception-and-Prediction-in-Self-Driving" class="headerlink" title="Implicit Occupancy Flow Fields for Perception and Prediction in Self-Driving"></a>Implicit Occupancy Flow Fields for Perception and Prediction in Self-Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01471">http://arxiv.org/abs/2308.01471</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ben Agro, Quinlan Sykora, Sergio Casas, Raquel Urtasun</li>
<li>for: 本研究旨在提高自动驾驶车辆（SDV）的见觉和未来行为预测能力。</li>
<li>methods: 本研究使用了一种统一的见觉和未来预测方法，通过单个神经网络来表示占用和流速grid。该方法可以 direktly被运动规划器查询，避免过度计算和缺失对象检测。此外，该方法还使用了全球注意机制，以增强跨度检测和预测。</li>
<li>results: 经过EXTENSIVE EXPERIMENTS在城市和高速公路上，研究发现，该方法可以超越当前状态的艺术。更多信息可以在<a target="_blank" rel="noopener" href="https://waabi.ai/research/implicito%E4%B8%8A%E5%BE%97%E5%88%B0%E3%80%82">https://waabi.ai/research/implicito上得到。</a><details>
<summary>Abstract</summary>
A self-driving vehicle (SDV) must be able to perceive its surroundings and predict the future behavior of other traffic participants. Existing works either perform object detection followed by trajectory forecasting of the detected objects, or predict dense occupancy and flow grids for the whole scene. The former poses a safety concern as the number of detections needs to be kept low for efficiency reasons, sacrificing object recall. The latter is computationally expensive due to the high-dimensionality of the output grid, and suffers from the limited receptive field inherent to fully convolutional networks. Furthermore, both approaches employ many computational resources predicting areas or objects that might never be queried by the motion planner. This motivates our unified approach to perception and future prediction that implicitly represents occupancy and flow over time with a single neural network. Our method avoids unnecessary computation, as it can be directly queried by the motion planner at continuous spatio-temporal locations. Moreover, we design an architecture that overcomes the limited receptive field of previous explicit occupancy prediction methods by adding an efficient yet effective global attention mechanism. Through extensive experiments in both urban and highway settings, we demonstrate that our implicit model outperforms the current state-of-the-art. For more information, visit the project website: https://waabi.ai/research/implicito.
</details>
<details>
<summary>摘要</summary>
一个自动驾驶车辆（SDV）需要能够感知周围环境并预测其他交通参与者的未来行为。现有的工作都是先检测对象，然后预测检测到的对象的轨迹，或者预测整个场景的厚度占用和流动Grid。前者会导致安全隐患，因为需要保持检测数量低，牺牲对象回忆。后者因为输出格式的高维度而 computationally expensive，而且受到全连接神经网络的局限性困惑。此外，这些方法都需要大量计算资源预测可能不会被访问的区域或对象。这种情况驱动我们开发了一种统一的感知和未来预测方法，该方法可以直接由运动规划器查询，避免不必要的计算。此外，我们还设计了一种高效又有效的全局注意机制，以解决过去的显式占用预测方法的有限范围问题。经过广泛的实验，我们证明了我们的含义模型在城市和高速公路上都能够超越当前状态。更多信息请访问项目网站：https://waabi.ai/research/implicito。
</details></li>
</ul>
<hr>
<h2 id="Training-Data-Protection-with-Compositional-Diffusion-Models"><a href="#Training-Data-Protection-with-Compositional-Diffusion-Models" class="headerlink" title="Training Data Protection with Compositional Diffusion Models"></a>Training Data Protection with Compositional Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01937">http://arxiv.org/abs/2308.01937</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aditya Golatkar, Alessandro Achille, Ashwin Swaminathan, Stefano Soatto</li>
<li>for: 这篇论文是用于描述一种名为 compartmentalized diffusion models（CDM）的方法，可以在推理时将不同的扩散模型（或提示）组合起来，以达到与全数据同时训练的性能。</li>
<li>methods: 这篇论文使用的方法是在不同的数据源上训练不同的扩散模型，并在推理时将它们组合起来。每个模型只包含它在训练时接触到的数据信息，从而实现数据隐私和权限控制。</li>
<li>results: 这篇论文的结果表明，CDM可以实现选择性的忘记和持续学习，以及根据用户的访问权限服务自定义的模型。此外，CDM还可以确定某些数据子集对于生成特定样本的重要性。<details>
<summary>Abstract</summary>
We introduce Compartmentalized Diffusion Models (CDM), a method to train different diffusion models (or prompts) on distinct data sources and arbitrarily compose them at inference time. The individual models can be trained in isolation, at different times, and on different distributions and domains and can be later composed to achieve performance comparable to a paragon model trained on all data simultaneously. Furthermore, each model only contains information about the subset of the data it was exposed to during training, enabling several forms of training data protection. In particular, CDMs are the first method to enable both selective forgetting and continual learning for large-scale diffusion models, as well as allowing serving customized models based on the user's access rights. CDMs also allow determining the importance of a subset of the data in generating particular samples.
</details>
<details>
<summary>摘要</summary>
我们介绍Compartmentalized Diffusion Models（CDM），一种方法可以在推广过程中训练不同的扩散模型（或提示），并在推广时进行可compose的方式。个别模型可以在不同的时间、不同的分布和领域上进行独立的训练，然后在推广时进行混合。此外，每个模型只包含它在训练过程中接触到的subset of data的信息，因此可以实现多种训练数据保护。特别是，CDMs是首个允许大规模扩散模型进行选择性遗忘和持续学习，以及根据用户的存取权服务自定义模型。此外，CDMs还允许决定特定样本的某些subset of data的重要性。
</details></li>
</ul>
<hr>
<h2 id="Dual-Governance-The-intersection-of-centralized-regulation-and-crowdsourced-safety-mechanisms-for-Generative-AI"><a href="#Dual-Governance-The-intersection-of-centralized-regulation-and-crowdsourced-safety-mechanisms-for-Generative-AI" class="headerlink" title="Dual Governance: The intersection of centralized regulation and crowdsourced safety mechanisms for Generative AI"></a>Dual Governance: The intersection of centralized regulation and crowdsourced safety mechanisms for Generative AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04448">http://arxiv.org/abs/2308.04448</a></li>
<li>repo_url: None</li>
<li>paper_authors: Avijit Ghosh, Dhanya Lakshmi<br>for: 这个论文的目的是提出一种名为“双重管理”的框架，以确保在生成人工智能技术的应用中保障安全和伦理。methods: 该论文使用的方法包括：* 分析现有的中央化法规和社区自身的安全机制，以找到它们之间的互补点。* 提出一种名为“双重管理”的框架，以实现中央化法规和社区自身的共同管理。results: 该论文的结果表明，通过实施“双重管理”框架，可以促进生成人工智能技术的创新和创新，同时确保其安全和伦理的应用。<details>
<summary>Abstract</summary>
Generative Artificial Intelligence (AI) has seen mainstream adoption lately, especially in the form of consumer-facing, open-ended, text and image generating models. However, the use of such systems raises significant ethical and safety concerns, including privacy violations, misinformation and intellectual property theft. The potential for generative AI to displace human creativity and livelihoods has also been under intense scrutiny. To mitigate these risks, there is an urgent need of policies and regulations responsible and ethical development in the field of generative AI. Existing and proposed centralized regulations by governments to rein in AI face criticisms such as not having sufficient clarity or uniformity, lack of interoperability across lines of jurisdictions, restricting innovation, and hindering free market competition. Decentralized protections via crowdsourced safety tools and mechanisms are a potential alternative. However, they have clear deficiencies in terms of lack of adequacy of oversight and difficulty of enforcement of ethical and safety standards, and are thus not enough by themselves as a regulation mechanism. We propose a marriage of these two strategies via a framework we call Dual Governance. This framework proposes a cooperative synergy between centralized government regulations in a U.S. specific context and safety mechanisms developed by the community to protect stakeholders from the harms of generative AI. By implementing the Dual Governance framework, we posit that innovation and creativity can be promoted while ensuring safe and ethical deployment of generative AI.
</details>
<details>
<summary>摘要</summary>
现代化的人工智能（AI）在最近几年内得到了广泛的普及，尤其是在用户直接参与、开放结束的文本和图像生成模型的形式。然而，使用这些系统会引起重要的伦理和安全问题，包括隐私侵犯、谣言和知识产权盗窃。AI的生成能力可能会取代人类的创造力和生活方式，也在严重的检查下。为了缓解这些风险，需要负责任的政策和法规，以促进开发领域中负责任的AI发展。现有和提议的中央政府的法规，尽管具有一定的优点，但也存在不足的明确性和一致性，不可避免的干扰创新和自由市场竞争。 decentralized的保护机制，例如人类协同发展的安全工具和机制，可以作为一种替代方案。然而，它们缺乏伦理和安全标准的监管和执行能力，因此不具备充分的监管能力。为了解决这些问题，我们提出了一种名为“双重治理”的框架。这种框架建议在美国特有的 контексте下，通过中央政府的法规和社区开发的安全机制，保护利益者从生成AI的危害中。通过实施“双重治理”框架，我们认为可以促进创新和创造力，同时确保安全和负责任的AI发展。
</details></li>
</ul>
<hr>
<h2 id="VertexSerum-Poisoning-Graph-Neural-Networks-for-Link-Inference"><a href="#VertexSerum-Poisoning-Graph-Neural-Networks-for-Link-Inference" class="headerlink" title="VertexSerum: Poisoning Graph Neural Networks for Link Inference"></a>VertexSerum: Poisoning Graph Neural Networks for Link Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01469">http://arxiv.org/abs/2308.01469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruyi Ding, Shijin Duan, Xiaolin Xu, Yunsi Fei</li>
<li>for: 本文旨在攻击图Structured Data中的图结构学习模型（Graph Neural Networks，GNNs），以便窃取图连接信息。</li>
<li>methods: 本文提出了一种新的图恶意攻击方法，即VertexSerum，可以增强图连接信息泄露。此外，本文还提出了一种注意力机制，可以在链接检测网络中嵌入，以更准确地推测节点相互之间的连接关系。</li>
<li>results: 本文的实验结果表明，VertexSerumsignificantly outperforms state-of-the-art（SOTA）链接推测攻击，提高了平均混合精度分数（AUC）的提升率为9.8%。此外，本文的实验还表明，VertexSerum在黑盒和在线学习 Setting下都有出色的应用可能性。<details>
<summary>Abstract</summary>
Graph neural networks (GNNs) have brought superb performance to various applications utilizing graph structural data, such as social analysis and fraud detection. The graph links, e.g., social relationships and transaction history, are sensitive and valuable information, which raises privacy concerns when using GNNs. To exploit these vulnerabilities, we propose VertexSerum, a novel graph poisoning attack that increases the effectiveness of graph link stealing by amplifying the link connectivity leakage. To infer node adjacency more accurately, we propose an attention mechanism that can be embedded into the link detection network. Our experiments demonstrate that VertexSerum significantly outperforms the SOTA link inference attack, improving the AUC scores by an average of $9.8\%$ across four real-world datasets and three different GNN structures. Furthermore, our experiments reveal the effectiveness of VertexSerum in both black-box and online learning settings, further validating its applicability in real-world scenarios.
</details>
<details>
<summary>摘要</summary>
GRAPH NEURAL NETWORKS (GNNs) 有提供了出色的表现在使用图structured数据的各种应用程序中，如社交分析和诈骗探测。图链，例如社交关系和交易历史记录，是敏感和有价值的信息，使得使用 GNNs 时存在隐私问题。为了利用这些漏洞，我们提议VertexSerum，一种新的图毒注攻击，可以增强图链泄露的连接性。为更准确地推断节点相邻关系，我们提议一种注意力机制可以在链接检测网络中嵌入。我们的实验表明，VertexSerum可以明显超过当前链接推断攻击的最佳实践（SOTA），提高了平均抽样率9.8%。此外，我们的实验还表明VertexSerum在黑盒和在线学习设置下都有出色的应用可行性。
</details></li>
</ul>
<hr>
<h2 id="Novel-Physics-Based-Machine-Learning-Models-for-Indoor-Air-Quality-Approximations"><a href="#Novel-Physics-Based-Machine-Learning-Models-for-Indoor-Air-Quality-Approximations" class="headerlink" title="Novel Physics-Based Machine-Learning Models for Indoor Air Quality Approximations"></a>Novel Physics-Based Machine-Learning Models for Indoor Air Quality Approximations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01438">http://arxiv.org/abs/2308.01438</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ahmad Mohammadshirazi, Aida Nadafian, Amin Karimi Monsefi, Mohammad H. Rafiei, Rajiv Ramnath</li>
<li>for: 本研究旨在提出六种基于物理知识的机器学习模型，用于精准预测室内污染物质浓度。</li>
<li>methods: 本研究使用了状态空间概念、闭包回卷单元和分解技术，搭建了一种轻量级、计算效率高的机器学习模型。</li>
<li>results: 实验结果表明，提议的模型比相关的现状艺术模型更加简单、计算效率高，同时能够更好地捕捉室内空气质量数据中的高度非线性特征。<details>
<summary>Abstract</summary>
Cost-effective sensors are capable of real-time capturing a variety of air quality-related modalities from different pollutant concentrations to indoor/outdoor humidity and temperature. Machine learning (ML) models are capable of performing air-quality "ahead-of-time" approximations. Undoubtedly, accurate indoor air quality approximation significantly helps provide a healthy indoor environment, optimize associated energy consumption, and offer human comfort. However, it is crucial to design an ML architecture to capture the domain knowledge, so-called problem physics. In this study, we propose six novel physics-based ML models for accurate indoor pollutant concentration approximations. The proposed models include an adroit combination of state-space concepts in physics, Gated Recurrent Units, and Decomposition techniques. The proposed models were illustrated using data collected from five offices in a commercial building in California. The proposed models are shown to be less complex, computationally more efficient, and more accurate than similar state-of-the-art transformer-based models. The superiority of the proposed models is due to their relatively light architecture (computational efficiency) and, more importantly, their ability to capture the underlying highly nonlinear patterns embedded in the often contaminated sensor-collected indoor air quality temporal data.
</details>
<details>
<summary>摘要</summary>
Cost-effective sensors can real-time capture various air quality-related modalities, from different pollutant concentrations to indoor/outdoor humidity and temperature. Machine learning (ML) models can perform air-quality "ahead-of-time" approximations. Accurate indoor air quality approximation is crucial for providing a healthy indoor environment, optimizing associated energy consumption, and offering human comfort. However, it is essential to design an ML architecture that captures the domain knowledge, so-called problem physics. In this study, we propose six novel physics-based ML models for accurate indoor pollutant concentration approximations. The proposed models combine state-space concepts in physics, Gated Recurrent Units, and Decomposition techniques. The proposed models were illustrated using data collected from five offices in a commercial building in California. The proposed models are less complex, computationally more efficient, and more accurate than similar state-of-the-art transformer-based models. The superiority of the proposed models is due to their light architecture and their ability to capture the underlying highly nonlinear patterns in the often contaminated sensor-collected indoor air quality temporal data.
</details></li>
</ul>
<hr>
<h2 id="Why-Do-We-Need-Neuro-symbolic-AI-to-Model-Pragmatic-Analogies"><a href="#Why-Do-We-Need-Neuro-symbolic-AI-to-Model-Pragmatic-Analogies" class="headerlink" title="Why Do We Need Neuro-symbolic AI to Model Pragmatic Analogies?"></a>Why Do We Need Neuro-symbolic AI to Model Pragmatic Analogies?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01936">http://arxiv.org/abs/2308.01936</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thilini Wijesiriwardene, Amit Sheth, Valerie L. Shalin, Amitava Das</li>
<li>for: 这篇论文探讨了大自然语言模型（LLM）在处理文本中逐渐增加复杂度的 analogy 性能。</li>
<li>methods: 这篇论文使用了 Neuro-symbolic AI 技术，结合统计学和符号学 AI，以提高文本表示，强调和增强相关内容，并提供抽象和导航。</li>
<li>results: 研究发现，随着 analogy 的复杂度增加，需要更多的、多样化的知识，不可能由 lexical co-occurrence statistics 提供。Neuro-symbolic AI 技术可以维持 LLM 的效率，同时保持 analogy 的解释能力，帮助进行教学应用。<details>
<summary>Abstract</summary>
A hallmark of intelligence is the ability to use a familiar domain to make inferences about a less familiar domain, known as analogical reasoning. In this article, we delve into the performance of Large Language Models (LLMs) in dealing with progressively complex analogies expressed in unstructured text. We discuss analogies at four distinct levels of complexity: lexical analogies, syntactic analogies, semantic analogies, and pragmatic analogies. As the analogies become more complex, they require increasingly extensive, diverse knowledge beyond the textual content, unlikely to be found in the lexical co-occurrence statistics that power LLMs. To address this, we discuss the necessity of employing Neuro-symbolic AI techniques that combine statistical and symbolic AI, informing the representation of unstructured text to highlight and augment relevant content, provide abstraction and guide the mapping process. Our knowledge-informed approach maintains the efficiency of LLMs while preserving the ability to explain analogies for pedagogical applications.
</details>
<details>
<summary>摘要</summary>
一种智能的特征是使用熟悉的领域来对不熟悉的领域进行推理，这称为对比推理。在这篇文章中，我们探讨大语言模型（LLM）在处理不断增长复杂的对比表达的文本中表现。我们讨论了四种不同的复杂性水平的对比：lexical对比、语法对比、semantic对比和 Pragmatic对比。随着对比的复杂程度增加，它们需要更多的、多样化的知识，不可能通过文本内容的lexical co-occurrence statistics来找到。为此，我们讨论了结合统计学和符号学AI技术的必要性，以便高亮和增强文本内容，提供抽象和导向映射过程。我们的知识填充approach保持了LLM的效率，同时保留了对对比的解释，以便在教育应用中使用。
</details></li>
</ul>
<hr>
<h2 id="Unlocking-the-Potential-of-Similarity-Matching-Scalability-Supervision-and-Pre-training"><a href="#Unlocking-the-Potential-of-Similarity-Matching-Scalability-Supervision-and-Pre-training" class="headerlink" title="Unlocking the Potential of Similarity Matching: Scalability, Supervision and Pre-training"></a>Unlocking the Potential of Similarity Matching: Scalability, Supervision and Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02427">http://arxiv.org/abs/2308.02427</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanis Bahroun, Shagesh Sridharan, Atithi Acharya, Dmitri B. Chklovskii, Anirvan M. Sengupta</li>
<li>for: 这项研究旨在开发一种基于本地学习规则的可能学习算法，以替代具有限制的反射层梯队列（BP）算法。</li>
<li>methods: 研究人员提出了一种基于PyTorch实现的卷积非负相似匹配（SM）算法，以扩展SM到大规模数据集。此外，他们还提出了一种基于SM层的本地监督学习目标，并在PyTorch实现中进行了预训练模型 such as LeNet的比较。</li>
<li>results: 研究人员发现，使用PyTorch实现的SM算法可以在计算效率和生物可能性方面与BP算法相比，并且可以在大规模数据集上扩展。此外，他们还发现，将SM层与BP算法拼接在一起可以提高模型的评价性能。<details>
<summary>Abstract</summary>
While effective, the backpropagation (BP) algorithm exhibits limitations in terms of biological plausibility, computational cost, and suitability for online learning. As a result, there has been a growing interest in developing alternative biologically plausible learning approaches that rely on local learning rules. This study focuses on the primarily unsupervised similarity matching (SM) framework, which aligns with observed mechanisms in biological systems and offers online, localized, and biologically plausible algorithms. i) To scale SM to large datasets, we propose an implementation of Convolutional Nonnegative SM using PyTorch. ii) We introduce a localized supervised SM objective reminiscent of canonical correlation analysis, facilitating stacking SM layers. iii) We leverage the PyTorch implementation for pre-training architectures such as LeNet and compare the evaluation of features against BP-trained models. This work combines biologically plausible algorithms with computational efficiency opening multiple avenues for further explorations.
</details>
<details>
<summary>摘要</summary>
而Effective的Backpropagation（BP）算法具有限制，包括生物学可能性、计算成本和在线学习适用性。因此，有越来越多的关注于开发生物学可能性的学习方法。这项研究强调在大规模数据集上扩大Similarity Matching（SM）框架，与生物系统中观察到的机制相一致，并提供在线、本地和生物学可能性的算法。（i）为了扩大SM到大数据集，我们提议使用PyTorch实现Convolutional Nonnegative SM。（ii）我们引入本地监督SM目标，与栅格分析相似，以推进SM层堆叠。（iii）我们利用PyTorch实现对预训练架构如LeNet进行评估，并与BP训练模型进行比较。这项工作结合了生物学可能性的算法和计算效率，开启了多个探索的可能性。
</details></li>
</ul>
<hr>
<h2 id="Bio-Clinical-BERT-BERT-Base-and-CNN-Performance-Comparison-for-Predicting-Drug-Review-Satisfaction"><a href="#Bio-Clinical-BERT-BERT-Base-and-CNN-Performance-Comparison-for-Predicting-Drug-Review-Satisfaction" class="headerlink" title="Bio+Clinical BERT, BERT Base, and CNN Performance Comparison for Predicting Drug-Review Satisfaction"></a>Bio+Clinical BERT, BERT Base, and CNN Performance Comparison for Predicting Drug-Review Satisfaction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03782">http://arxiv.org/abs/2308.03782</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yue Ling<br>for: 这项研究的目的是开发一种可以分析病人药物评价文本，并准确地分类为正面、中性或负面的自然语言处理（NLP）模型。methods: 这项研究采用了多种分类模型，包括BERT基础模型、医学+клиничеBERT模型和简单的CNN模型。results: 研究结果表明，医学+клиничеBERT模型在表现 overall 方面表现出色，特别是在医疗术语方面表现出了11%的macro f1和回归分数提高，如图2所示。<details>
<summary>Abstract</summary>
The objective of this study is to develop natural language processing (NLP) models that can analyze patients' drug reviews and accurately classify their satisfaction levels as positive, neutral, or negative. Such models would reduce the workload of healthcare professionals and provide greater insight into patients' quality of life, which is a critical indicator of treatment effectiveness. To achieve this, we implemented and evaluated several classification models, including a BERT base model, Bio+Clinical BERT, and a simpler CNN. Results indicate that the medical domain-specific Bio+Clinical BERT model significantly outperformed the general domain base BERT model, achieving macro f1 and recall score improvement of 11%, as shown in Table 2. Future research could explore how to capitalize on the specific strengths of each model. Bio+Clinical BERT excels in overall performance, particularly with medical jargon, while the simpler CNN demonstrates the ability to identify crucial words and accurately classify sentiment in texts with conflicting sentiments.
</details>
<details>
<summary>摘要</summary>
目标是开发一种自然语言处理（NLP）模型，能够分析患者的药物评价，并准确地将满意度分类为正面、中性或负面。这些模型将减轻医疗专业人员的工作负担，并为患者的生活质量提供更多的信息，这是治疗效果的关键指标。为达到这一目标，我们实施和评估了多种分类模型，包括BERT基础模型、医学+临床BERT和简单的CNN。结果表明，具有医学领域特点的Bio+Clinical BERT模型在表格2中显著超过了通用领域基础BERT模型，实现了 macro f1和回忆得分的11%的提升，如图表2所示。未来的研究可以探讨如何利用每个模型的特点。Bio+Clinical BERT在整体性能方面表现出色，特别是对医疗术语的处理能力强，而简单的CNN则能够准确地识别关键词并在文本中 conflicting 的情感下准确地分类 sentiment。
</details></li>
</ul>
<hr>
<h2 id="The-Paradigm-Shifts-in-Artificial-Intelligence"><a href="#The-Paradigm-Shifts-in-Artificial-Intelligence" class="headerlink" title="The Paradigm Shifts in Artificial Intelligence"></a>The Paradigm Shifts in Artificial Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02558">http://arxiv.org/abs/2308.02558</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/its-me-yasho/AI-virtual-mouse-">https://github.com/its-me-yasho/AI-virtual-mouse-</a></li>
<li>paper_authors: Vasant Dhar</li>
<li>for: 本研究旨在探讨人工智能领域过去60年中的 paradigm shift，以及现在的大型预训系统如GPT-3和ChatGPT等 conversational agents 的emergence。</li>
<li>methods: 本研究使用库恩的科学进步框架（Kuhn, 1962）来框定每个 paradigm 的发展和衰落，以及现在的AI技术 configurable 应用。</li>
<li>results: 研究发现，现在的AI技术已成为一种通用技术，可以 configurable 应用于各种领域。然而，这些技术也存在一些问题和风险，如数据隐私和安全问题。<details>
<summary>Abstract</summary>
Kuhn's framework of scientific progress (Kuhn, 1962) provides a useful framing of the paradigm shifts that have occurred in Artificial Intelligence over the last 60 years. The framework is also useful in understanding what is arguably a new paradigm shift in AI, signaled by the emergence of large pre-trained systems such as GPT-3, on which conversational agents such as ChatGPT are based. Such systems make intelligence a commoditized general purpose technology that is configurable to applications. In this paper, I summarize the forces that led to the rise and fall of each paradigm, and discuss the pressing issues and risks associated with the current paradigm shift in AI.
</details>
<details>
<summary>摘要</summary>
库恩的科学进步框架（库恩，1962）提供了有用的框架，以呈现过去60年来人工智能领域内的 paradigm shift。这个框架也有助于理解目前AI领域可能出现的新的 paradigm shift，即大型预训系统如GPT-3的出现，以及基于这些系统的对话代理人如ChatGPT。这些系统使智能成为可 configurable 通用技术，可以应用于各种应用程序。在这篇文章中，我会概述过去各个 paradigm 的起源和衰落，并讨论目前AI领域中的紧迫问题和风险。
</details></li>
</ul>
<hr>
<h2 id="OpenFlamingo-An-Open-Source-Framework-for-Training-Large-Autoregressive-Vision-Language-Models"><a href="#OpenFlamingo-An-Open-Source-Framework-for-Training-Large-Autoregressive-Vision-Language-Models" class="headerlink" title="OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models"></a>OpenFlamingo: An Open-Source Framework for Training Large Autoregressive Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01390">http://arxiv.org/abs/2308.01390</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlfoundations/open_flamingo">https://github.com/mlfoundations/open_flamingo</a></li>
<li>paper_authors: Anas Awadalla, Irena Gao, Josh Gardner, Jack Hessel, Yusuf Hanafy, Wanrong Zhu, Kalyani Marathe, Yonatan Bitton, Samir Gadre, Shiori Sagawa, Jenia Jitsev, Simon Kornblith, Pang Wei Koh, Gabriel Ilharco, Mitchell Wortsman, Ludwig Schmidt</li>
<li>for: 这个论文是为了提出一种基于自适应语言模型的视觉语言模型家族，包括3B至9B参数的多种模型。</li>
<li>methods: 这些模型使用了开源复制深度智能的Flamenco模型，并在七个视觉语言数据集上进行了训练。</li>
<li>results: 在七个视觉语言数据集上，OpenFlamingo模型的平均表现为80-89%相对于对应的Flamenco模型表现。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
We introduce OpenFlamingo, a family of autoregressive vision-language models ranging from 3B to 9B parameters. OpenFlamingo is an ongoing effort to produce an open-source replication of DeepMind's Flamingo models. On seven vision-language datasets, OpenFlamingo models average between 80 - 89% of corresponding Flamingo performance. This technical report describes our models, training data, hyperparameters, and evaluation suite. We share our models and code at https://github.com/mlfoundations/open_flamingo.
</details>
<details>
<summary>摘要</summary>
我们介绍OpenFlamingo，一个家族型态自动递增视言模型，从3B到9B参数。OpenFlamingo是一个持续进行的开源实现深渊智能的Flamingo模型的努力。在七个视言数据集上，OpenFlamingo模型的平均性能在80-89%之间，与对应的Flamingo模型的性能相似。This technical report describes our models, training data, hyperparameters, and evaluation suite. We share our models and code at <https://github.com/mlfoundations/open_flamingo>.
</details></li>
</ul>
<hr>
<h2 id="DeepSpeed-Chat-Easy-Fast-and-Affordable-RLHF-Training-of-ChatGPT-like-Models-at-All-Scales"><a href="#DeepSpeed-Chat-Easy-Fast-and-Affordable-RLHF-Training-of-ChatGPT-like-Models-at-All-Scales" class="headerlink" title="DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales"></a>DeepSpeed-Chat: Easy, Fast and Affordable RLHF Training of ChatGPT-like Models at All Scales</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01320">http://arxiv.org/abs/2308.01320</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/microsoft/DeepSpeed">https://github.com/microsoft/DeepSpeed</a></li>
<li>paper_authors: Zhewei Yao, Reza Yazdani Aminabadi, Olatunji Ruwase, Samyam Rajbhandari, Xiaoxia Wu, Ammar Ahmad Awan, Jeff Rasley, Minjia Zhang, Conglong Li, Connor Holmes, Zhongzhu Zhou, Michael Wyatt, Molly Smith, Lev Kurilenko, Heyang Qin, Masahiro Tanaka, Shuai Che, Shuaiwen Leon Song, Yuxiong He</li>
<li>for: 这篇论文旨在提供一个可 accessed、高效、便宜的练习和测试 ChatGPT-like 模型的 Reinforcement Learning with Human Feedback (RLHF) 训练管线，并且可以让训练大小达到百亿个条件的模型在 record 时间内训练，并且在成本上降低训练成本。</li>
<li>methods: 这篇论文提出了一个名为 DeepSpeed-Chat 的系统，它提供了三个关键能力：一个易于使用的 ChatGPT-like 模型训练和测试体验、一个 DeepSpeed-RLHF 管线，复制 InstructGPT 的训练管线，以及一个强大的 DeepSpeed-RLHF 系统，结合了多种优化，以提高训练和测试的效率和数据处理能力。</li>
<li>results: 这篇论文发现，使用 DeepSpeed-Chat 可以实现在训练大小达到百亿个条件的模型上，在 record 时间内训练，并且在成本上降低训练成本。<details>
<summary>Abstract</summary>
ChatGPT-like models have revolutionized various applications in artificial intelligence, from summarization and coding to translation, matching or even surpassing human performance. However, the current landscape lacks an accessible, efficient, and cost-effective end-to-end RLHF (Reinforcement Learning with Human Feedback) training pipeline for these powerful models, particularly when training at the scale of billions of parameters. This paper introduces DeepSpeed-Chat, a novel system that democratizes RLHF training, making it accessible to the AI community. DeepSpeed-Chat offers three key capabilities: an easy-to-use training and inference experience for ChatGPT-like models, a DeepSpeed-RLHF pipeline that replicates the training pipeline from InstructGPT, and a robust DeepSpeed-RLHF system that combines various optimizations for training and inference in a unified way. The system delivers unparalleled efficiency and scalability, enabling training of models with hundreds of billions of parameters in record time and at a fraction of the cost. With this development, DeepSpeed-Chat paves the way for broader access to advanced RLHF training, even for data scientists with limited resources, thereby fostering innovation and further development in the field of AI.
</details>
<details>
<summary>摘要</summary>
chatGPT-like模型已经革命化了人工智能多个应用领域，从概要和编程到翻译，与人类表现相当或甚至超越人类表现。然而，目前的景象缺乏一个可 accessible、高效、Cost-effective的RLHF（强化学习with人类反馈）训练管道，特别是在百亿参数训练的场景下。这篇论文介绍了DeepSpeed-Chat，一个新的系统，使得RLHF训练变得更加可 accessible。DeepSpeed-Chat提供了三个关键能力：对ChatGPT-like模型的易于使用训练和推理经验，InstructGPT的DeepSpeed-RLHF管道的复制，以及一个robust的DeepSpeed-RLHF系统，其结合了多种优化，以实现高效和可扩展的训练和推理。该系统可以在纪录时间内训练百亿参数的模型，并且只需一小部分的成本。通过这个发展，DeepSpeed-Chat打开了RLHF训练的大门，使得更多的数据科学家可以访问高级RLHF训练，从而推动人工智能领域的创新和发展。
</details></li>
</ul>
<hr>
<h2 id="CausalOps-–-Towards-an-Industrial-Lifecycle-for-Causal-Probabilistic-Graphical-Models"><a href="#CausalOps-–-Towards-an-Industrial-Lifecycle-for-Causal-Probabilistic-Graphical-Models" class="headerlink" title="CausalOps – Towards an Industrial Lifecycle for Causal Probabilistic Graphical Models"></a>CausalOps – Towards an Industrial Lifecycle for Causal Probabilistic Graphical Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01375">http://arxiv.org/abs/2308.01375</a></li>
<li>repo_url: None</li>
<li>paper_authors: Robert Maier, Andreas Schlattl, Thomas Guess, Jürgen Mottok</li>
<li>for:  This paper aims to provide a novel lifecycle framework for causal model development and application, called CausalOps, to address the gap in a process reference for organizations interested in employing causal engineering.</li>
<li>methods: The paper proposes CausalOps, a lifecycle framework that defines key entities, dependencies, and intermediate artifacts generated during causal engineering, establishing a consistent vocabulary and workflow model.</li>
<li>results: The paper aims to drive the adoption of causal methods in practical applications within interested organizations and the causality community by providing a holistic view of creating and maintaining causal models.Here is the same information in Simplified Chinese text:</li>
<li>for: 本研究目的是提供一个新的 causal 模型开发和应用的生命周期框架，名为 CausalOps，以应对在 causal 工程中缺乏一个适当的程序参考。</li>
<li>methods: CausalOps 提出了一个生命周期框架，它定义了 causal 模型开发和应用中的关键实体、依赖关系和中间生成的资料，实现了一致的词汇和工作流程模型。</li>
<li>results: 本研究的目的是将 causal 方法实施到实际应用中的有兴趣组织和 causality 社区中，提供一个全面的创建和维护 causal 模型的观点。<details>
<summary>Abstract</summary>
Causal probabilistic graph-based models have gained widespread utility, enabling the modeling of cause-and-effect relationships across diverse domains. With their rising adoption in new areas, such as automotive system safety and machine learning, the need for an integrated lifecycle framework akin to DevOps and MLOps has emerged. Currently, a process reference for organizations interested in employing causal engineering is missing. To address this gap and foster widespread industrial adoption, we propose CausalOps, a novel lifecycle framework for causal model development and application. By defining key entities, dependencies, and intermediate artifacts generated during causal engineering, we establish a consistent vocabulary and workflow model. This work contextualizes causal model usage across different stages and stakeholders, outlining a holistic view of creating and maintaining them. CausalOps' aim is to drive the adoption of causal methods in practical applications within interested organizations and the causality community.
</details>
<details>
<summary>摘要</summary>
causal probabilistic graph-based models 已经广泛应用于不同领域，以模型 causality 关系。随着这些模型在新领域，如自动驾驶系统安全和机器学习中的应用，需要一个整合的生命周期框架，类似于 DevOps 和 MLOps。目前，有一个关于 causal engineering 的过程参考 absent。为了填补这个空白和推广 causal methods 的实际应用，我们提出了 CausalOps，一种新的生命周期框架 для causal 模型开发和应用。通过定义关键实体、依赖关系和 intermediate artifacts 在 causal engineering 中，我们建立了一种一致的词汇和工作流程模型。这种工作流程可以跨不同阶段和各种参与者，提供一个整体的创建和维护 causal 模型的视图。CausalOps 的目标是推广 causal methods 在有兴趣的组织和 causality 社区中的应用。
</details></li>
</ul>
<hr>
<h2 id="AI-Enhanced-Data-Processing-and-Discovery-Crowd-Sourcing-for-Meteor-Shower-Mapping"><a href="#AI-Enhanced-Data-Processing-and-Discovery-Crowd-Sourcing-for-Meteor-Shower-Mapping" class="headerlink" title="AI-Enhanced Data Processing and Discovery Crowd Sourcing for Meteor Shower Mapping"></a>AI-Enhanced Data Processing and Discovery Crowd Sourcing for Meteor Shower Mapping</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02664">http://arxiv.org/abs/2308.02664</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siddha Ganju, Amartya Hatua, Peter Jenniskens, Sahyadri Krishna, Chicheng Ren, Surya Ambardar</li>
<li>for: 这个研究项目的目标是为了映射我们的陨星雨，通过多个位置的低照度视频摄像头进行三角测量陨星轨迹，并在16个国家的北和南 полу球上进行观察和预测陨星雨的返回。</li>
<li>methods: 这个研究使用了一个自动化的云端AI智能管道来加速数据处理，并使用可解释的活动学习算法来提高数据可视化，以提高发现率。</li>
<li>results: 到目前为止，CAMS已经发现了200多个新的陨星雨，并验证了多个之前报告的陨星雨。<details>
<summary>Abstract</summary>
The Cameras for Allsky Meteor Surveillance (CAMS) project, funded by NASA starting in 2010, aims to map our meteor showers by triangulating meteor trajectories detected in low-light video cameras from multiple locations across 16 countries in both the northern and southern hemispheres. Its mission is to validate, discover, and predict the upcoming returns of meteor showers. Our research aimed to streamline the data processing by implementing an automated cloud-based AI-enabled pipeline and improve the data visualization to improve the rate of discoveries by involving the public in monitoring the meteor detections. This article describes the process of automating the data ingestion, processing, and insight generation using an interpretable Active Learning and AI pipeline. This work also describes the development of an interactive web portal (the NASA Meteor Shower portal) to facilitate the visualization of meteor radiant maps. To date, CAMS has discovered over 200 new meteor showers and has validated dozens of previously reported showers.
</details>
<details>
<summary>摘要</summary>
美国国家航空航天局（NASA）自2010年起投入的全天 meteor 观测计划（CAMS）计划，目标是通过多个地点、多国的低照度视频相机三角测量 meteor 轨迹，以易地卷积累积掌握 meteor 流星雨。该计划的任务是验证、发现和预测未来的 meteor 流星雨。我们的研究旨在通过实施云端AI智能化管道自动化数据处理，提高数据可视化，以提高发现率，并让公众参与监测流星探测。这篇文章描述了自动化数据入口、处理和探索的 Active Learning AI 管道，以及开发了一个可交互的 NASA 流星雨门户，以便visualize meteor 辐射地图。迄今，CAMS 已经发现了200多个新的 meteor 流星雨，并验证了数十个之前已知的流星雨。
</details></li>
</ul>
<hr>
<h2 id="An-enhanced-motion-planning-approach-by-integrating-driving-heterogeneity-and-long-term-trajectory-prediction-for-automated-driving-systems"><a href="#An-enhanced-motion-planning-approach-by-integrating-driving-heterogeneity-and-long-term-trajectory-prediction-for-automated-driving-systems" class="headerlink" title="An enhanced motion planning approach by integrating driving heterogeneity and long-term trajectory prediction for automated driving systems"></a>An enhanced motion planning approach by integrating driving heterogeneity and long-term trajectory prediction for automated driving systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01369">http://arxiv.org/abs/2308.01369</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ni Dong, Shuming Chen, Yina Wu, Yiheng Feng, Xiaobo Liu</li>
<li>for: 本研究旨在提高自动驾驶系统在复杂驾驶环境中的导航能力，特别是预测周围的人驾驶汽车（HDV）的驾驶行为。</li>
<li>methods: 本研究提出了一种增强的动态规划方法，使用了两个方面的结果：周围 HDV 的驾驶行为和长期轨迹，通过层次模型与自动驾驶系统的动态规划相结合，以提高驾驶安全性。</li>
<li>results: 研究发现，使用提出的增强方法可以更好地预测周围 HDV 的驾驶行为，提高自动驾驶系统的导航能力和安全性。<details>
<summary>Abstract</summary>
Navigating automated driving systems (ADSs) through complex driving environments is difficult. Predicting the driving behavior of surrounding human-driven vehicles (HDVs) is a critical component of an ADS. This paper proposes an enhanced motion-planning approach for an ADS in a highway-merging scenario. The proposed enhanced approach utilizes the results of two aspects: the driving behavior and long-term trajectory of surrounding HDVs, which are coupled using a hierarchical model that is used for the motion planning of an ADS to improve driving safety.
</details>
<details>
<summary>摘要</summary>
自动驾驶系统（ADS）在复杂的驾驶环境中困难 Navigation. 预测周围的人驾驶车辆（HDV）驾驶行为是ADS的一个关键组件。这篇论文提出了一种改进的运动规划方法，用于ADS在高速公路岔道场景中驾驶。该提出的改进方法利用了两个方面的结果：周围HDV的驾驶行为和长期轨迹，通过层次模型与ADS的运动规划相结合，以提高驾驶安全性。
</details></li>
</ul>
<hr>
<h2 id="Empirical-Translation-Process-Research-Past-and-Possible-Future-Perspectives"><a href="#Empirical-Translation-Process-Research-Past-and-Possible-Future-Perspectives" class="headerlink" title="Empirical Translation Process Research: Past and Possible Future Perspectives"></a>Empirical Translation Process Research: Past and Possible Future Perspectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01368">http://arxiv.org/abs/2308.01368</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Carl</li>
<li>for: 本研究旨在开发和评估Empirical Translation Process Research（TPR）模型，并提出了Free Energy Principle（FEP）和Active Inference（AIF）作为深入嵌入翻译过程的模型框架。</li>
<li>methods: 本研究使用了CRITT TPR-DB传统，并引入了新的方法来量化基本概念，如重要性理论（relevance）、s-模式和i-模式。这些方法与Monitor Model的关系被确立，并将重要性maximization看作是Free Energy的最小化。</li>
<li>results: FEP&#x2F;AIF提供了一个数学上可靠的基础，允许模型深入的时间建筑，在不同的时间轴上嵌入翻译过程。这个框架开放了未来预测TPR的可能性，可能对人类翻译过程的理解做出重要贡献，并对翻译学和人工智能设计框架产生重要影响。<details>
<summary>Abstract</summary>
Over the past four decades, efforts have been made to develop and evaluate models for Empirical Translation Process Research (TPR), yet a comprehensive framework remains elusive. This article traces the evolution of empirical TPR within the CRITT TPR-DB tradition and proposes the Free Energy Principle (FEP) and Active Inference (AIF) as a framework for modeling deeply embedded translation processes. It introduces novel approaches for quantifying fundamental concepts of Relevance Theory (relevance, s-mode, i-mode), and establishes their relation to the Monitor Model, framing relevance maximization as a special case of minimizing free energy. FEP/AIF provides a mathematically rigorous foundation that enables modeling of deep temporal architectures in which embedded translation processes unfold on different timelines. This framework opens up exciting prospects for future research in predictive TPR, likely to enrich our comprehension of human translation processes, and making valuable contributions to the wider realm of translation studies and the design of cognitive architectures.
</details>
<details>
<summary>摘要</summary>
Note:* "Empirical Translation Process Research" (TPR) is translated as "观察式翻译过程研究" (含义为"empirical"的"观察"和"过程"两个词).* "CRITT TPR-DB" is translated as "CRITT TPR-DB" (缩写为"CRITT"和"TPR-DB").* "Free Energy Principle" (FEP) is translated as "自由能原理" (含义为"free"和"energy"两个词).* "Active Inference" (AIF) is translated as "活动推测" (含义为"active"和"inference"两个词).* "Relevance Theory" is translated as "相关理论" (含义为"relevance"和"theory"两个词).* "Monitor Model" is translated as "监控模型" (含义为"monitor"和"model"两个词).
</details></li>
</ul>
<hr>
<h2 id="More-Context-Less-Distraction-Visual-Classification-by-Inferring-and-Conditioning-on-Contextual-Attributes"><a href="#More-Context-Less-Distraction-Visual-Classification-by-Inferring-and-Conditioning-on-Contextual-Attributes" class="headerlink" title="More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes"></a>More Context, Less Distraction: Visual Classification by Inferring and Conditioning on Contextual Attributes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01313">http://arxiv.org/abs/2308.01313</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/umd-huang-lab/perceptionclip">https://github.com/umd-huang-lab/perceptionclip</a></li>
<li>paper_authors: Bang An, Sicheng Zhu, Michael-Andrei Panaitescu-Liess, Chaithanya Kumar Mummadi, Furong Huang</li>
<li>for:  Zero-shot image classification</li>
<li>methods: 使用CLIP的contextual attributes进行图像分类，不需要训练</li>
<li>results:  better generalization, group robustness, and better interpretability compared to traditional zero-shot classification methods<details>
<summary>Abstract</summary>
CLIP, as a foundational vision language model, is widely used in zero-shot image classification due to its ability to understand various visual concepts and natural language descriptions. However, how to fully leverage CLIP's unprecedented human-like understanding capabilities to achieve better zero-shot classification is still an open question. This paper draws inspiration from the human visual perception process: a modern neuroscience view suggests that in classifying an object, humans first infer its class-independent attributes (e.g., background and orientation) which help separate the foreground object from the background, and then make decisions based on this information. Inspired by this, we observe that providing CLIP with contextual attributes improves zero-shot classification and mitigates reliance on spurious features. We also observe that CLIP itself can reasonably infer the attributes from an image. With these observations, we propose a training-free, two-step zero-shot classification method named PerceptionCLIP. Given an image, it first infers contextual attributes (e.g., background) and then performs object classification conditioning on them. Our experiments show that PerceptionCLIP achieves better generalization, group robustness, and better interpretability. For example, PerceptionCLIP with ViT-L/14 improves the worst group accuracy by 16.5% on the Waterbirds dataset and by 3.5% on CelebA.
</details>
<details>
<summary>摘要</summary>
CLIP，作为基础视觉语言模型，在零基础图像分类中广泛应用，这是因为它可以理解多种视觉概念和自然语言描述。然而，如何充分利用CLIP的人类化理解能力以实现更好的零基础分类仍然是一个开放的问题。这篇论文启发自人类视觉过程：现代神经科学视野认为，在分类一个物体，人们首先推理出该物体的类型独立特征（例如背景和方向），这些特征会将背景和物体分离开来，然后根据这些信息进行决策。以这种思想为灵感，我们发现，为CLIP提供Contextual attributes可以提高零基础分类和减少基于假特征的依赖。此外，我们发现CLIP本身也可以有效地从图像中推理出这些特征。基于这些观察，我们提出了一种无需训练的、两步零基础分类方法名为PerceptionCLIP。给定一个图像，它首先推理出图像中的Contextual attributes（例如背景），然后根据这些特征进行物体分类。我们的实验表明，PerceptionCLIP在水鸟数据集上提高了最差群组精度 by 16.5%，并在CelebA数据集上提高了3.5%。
</details></li>
</ul>
<hr>
<h2 id="Lode-Encoder-AI-constrained-co-creativity"><a href="#Lode-Encoder-AI-constrained-co-creativity" class="headerlink" title="Lode Encoder: AI-constrained co-creativity"></a>Lode Encoder: AI-constrained co-creativity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01312">http://arxiv.org/abs/2308.01312</a></li>
<li>repo_url: None</li>
<li>paper_authors: Debosmita Bhaumik, Ahmed Khalifa, Julian Togelius</li>
<li>for: 这篇论文是为了描述一种基于自动编码器的混合性倡议级别创建系统，用于 classic 平台游戏垃圾 runner。</li>
<li>methods: 该系统使用多个自动编码器，通过对垃圾 runner 等级进行训练，来生成更符合这些等级的级别设计。用户可以通过 ‘画画’ 方式在系统提供的建议基础上进行级别设计和编辑。</li>
<li>results: 文章描述了系统的设计和训练方法，以及用户测试结果。<details>
<summary>Abstract</summary>
We present Lode Encoder, a gamified mixed-initiative level creation system for the classic platform-puzzle game Lode Runner. The system is built around several autoencoders which are trained on sets of Lode Runner levels. When fed with the user's design, each autoencoder produces a version of that design which is closer in style to the levels that it was trained on. The Lode Encoder interface allows the user to build and edit levels through 'painting' from the suggestions provided by the autoencoders. Crucially, in order to encourage designers to explore new possibilities, the system does not include more traditional editing tools. We report on the system design and training procedure, as well as on the evolution of the system itself and user tests.
</details>
<details>
<summary>摘要</summary>
我们介绍Lode Encoder，一种基于混合主动initiative的平台游戏逻辑编辑系统，专门为经典平台游戏Lode Runner设计。该系统建立在多个自适应器基础之上，这些自适应器在不同的Lode Runner水平上进行训练。当用户输入设计时，每个自适应器都会生成一个更加类似于它所训练的水平的版本。Lode Encoder界面允许用户通过"涂抹"的方式从自适应器提供的建议中建立和编辑水平。关键是，为了鼓励设计师探索新的可能性，该系统不包含传统的编辑工具。我们介绍了系统的设计和训练过程，以及用户测试。
</details></li>
</ul>
<hr>
<h2 id="EmbeddingTree-Hierarchical-Exploration-of-Entity-Features-in-Embedding"><a href="#EmbeddingTree-Hierarchical-Exploration-of-Entity-Features-in-Embedding" class="headerlink" title="EmbeddingTree: Hierarchical Exploration of Entity Features in Embedding"></a>EmbeddingTree: Hierarchical Exploration of Entity Features in Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01329">http://arxiv.org/abs/2308.01329</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yan Zheng, Junpeng Wang, Chin-Chia Michael Yeh, Yujie Fan, Huiyuan Chen, Liang Wang, Wei Zhang</li>
<li>for: 本研究旨在提高 embedding learning 算法中feature的解释性，通过一种嵌入树来描述实体特征在嵌入空间中的含义。</li>
<li>methods: 本研究使用了一种嵌入树算法，可以帮助用户更好地理解嵌入空间中的feature表示。</li>
<li>results: 在实验中，嵌入树算法可以帮助用户发现数据实体中的细节特征，进行嵌入训练中的特征纹理提取和新实体嵌入生成等操作。<details>
<summary>Abstract</summary>
Embedding learning transforms discrete data entities into continuous numerical representations, encoding features/properties of the entities. Despite the outstanding performance reported from different embedding learning algorithms, few efforts were devoted to structurally interpreting how features are encoded in the learned embedding space. This work proposes EmbeddingTree, a hierarchical embedding exploration algorithm that relates the semantics of entity features with the less-interpretable embedding vectors. An interactive visualization tool is also developed based on EmbeddingTree to explore high-dimensional embeddings. The tool helps users discover nuance features of data entities, perform feature denoising/injecting in embedding training, and generate embeddings for unseen entities. We demonstrate the efficacy of EmbeddingTree and our visualization tool through embeddings generated for industry-scale merchant data and the public 30Music listening/playlists dataset.
</details>
<details>
<summary>摘要</summary>
<<SYS>>输入文本翻译为简化字符串。<</SYS>>嵌入学习将粒度数据实体转换为连续数字表示，卷积特征/属性实体。尽管不同嵌入学习算法报道了出色的性能，但是对嵌入学习结果中特征的结构解释得到了少量的努力。这项工作提出了嵌入树，一种嵌入探索算法，该算法将数据实体的 semantics 与嵌入 vectors 之间建立连接。此外，我们还开发了基于嵌入树的互动视觉化工具，帮助用户探索高维嵌入的细节。工具可以帮助用户发现数据实体的细节特征，进行嵌入训练中的特征去噪/注入，以及生成未见实体的嵌入。我们通过使用嵌入树和互动视觉化工具对行业级别的商家数据和公共30Music listening/playlists数据进行了证明。
</details></li>
</ul>
<hr>
<h2 id="Flows-Building-Blocks-of-Reasoning-and-Collaborating-AI"><a href="#Flows-Building-Blocks-of-Reasoning-and-Collaborating-AI" class="headerlink" title="Flows: Building Blocks of Reasoning and Collaborating AI"></a>Flows: Building Blocks of Reasoning and Collaborating AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01285">http://arxiv.org/abs/2308.01285</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/epfl-dlab/cc_flows">https://github.com/epfl-dlab/cc_flows</a></li>
<li>paper_authors: Martin Josifoski, Lars Klein, Maxime Peyrard, Yifei Li, Saibo Geng, Julian Paul Schnitzler, Yuxing Yao, Jiheng Wei, Debjit Paul, Robert West</li>
<li>for: 这 paper 旨在开发一种原则性的方法，用于设计和研究多个 AI 系统和人类之间的结构化交互。</li>
<li>methods: 该 paper 使用 Flows 概念框架，即自 conten 的 computation 块，通过标准化的消息传递接口进行交互。这种模块化设计使得 Flows 可以 recursive 地组合，减少复杂性。</li>
<li>results: 该 paper 在竞赛编程任务上实现了结构化思维和合作的进一步改进，使得 AI 只 Flows 增加了 +$21$ 和人类-AI Flows 增加了 +$54$ 绝对点的解决率。<details>
<summary>Abstract</summary>
Recent advances in artificial intelligence (AI) have produced highly capable and controllable systems. This creates unprecedented opportunities for structured reasoning as well as collaboration among multiple AI systems and humans. To fully realize this potential, it is essential to develop a principled way of designing and studying such structured interactions. For this purpose, we introduce the conceptual framework of Flows: a systematic approach to modeling complex interactions. Flows are self-contained building blocks of computation, with an isolated state, communicating through a standardized message-based interface. This modular design allows Flows to be recursively composed into arbitrarily nested interactions, with a substantial reduction of complexity. Crucially, any interaction can be implemented using this framework, including prior work on AI--AI and human--AI interactions, prompt engineering schemes, and tool augmentation. We demonstrate the potential of Flows on the task of competitive coding, a challenging task on which even GPT-4 struggles. Our results suggest that structured reasoning and collaboration substantially improve generalization, with AI-only Flows adding +$21$ and human--AI Flows adding +$54$ absolute points in terms of solve rate. To support rapid and rigorous research, we introduce the aiFlows library. The library comes with a repository of Flows that can be easily used, extended, and composed into novel, more complex Flows.   The aiFlows library is available at https://github.com/epfl-dlab/aiflows. Data and Flows for reproducing our experiments are available at https://github.com/epfl-dlab/cc_flows.
</details>
<details>
<summary>摘要</summary>
最近的人工智能（AI）技术发展已经创造出了高水平的可控制系统。这创造了前所未有的机会，让多个AI系统和人类之间进行结构化的合作和推理。为了实现这些潜力，我们提出了Flows概念框架：一种系统的方法来设计和研究这些结构化交互。Flows是自包含的建筑块，具有隔离的状态和标准化的消息传递接口。这种模块化设计使得Flows可以被 recursively 组合成任意层次的交互，从而减少复杂性。这些交互可以包括先前的AI-AI和人类-AI交互、提前工程方案和工具增强等。我们在竞赛编程任务上示出了Flows的潜力，这是一个AIeven GPT-4 很难完成的任务。我们的结果表明，结构化合作和推理可以提高通用性，AI只Flows adds +$21$ 和人类-AI Flows adds +$54$ 绝对点的解决率。为了支持快速和严格的研究，我们引入了aiFlows库。该库包含了可以轻松使用、扩展和组合成更复杂的Flows的Repository。aiFlows库可以在https://github.com/epfl-dlab/aiflows上获取。实验数据和Flows可以在https://github.com/epfl-dlab/cc_flows上获取。
</details></li>
</ul>
<hr>
<h2 id="Fighting-Fire-with-Fire-Can-ChatGPT-Detect-AI-generated-Text"><a href="#Fighting-Fire-with-Fire-Can-ChatGPT-Detect-AI-generated-Text" class="headerlink" title="Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?"></a>Fighting Fire with Fire: Can ChatGPT Detect AI-generated Text?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01284">http://arxiv.org/abs/2308.01284</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amritabh/chatgpt-as-detector">https://github.com/amritabh/chatgpt-as-detector</a></li>
<li>paper_authors: Amrita Bhattacharjee, Huan Liu</li>
<li>for: 这种研究用于检测人工生成的文本是否真实，以便在自动检测pipeline中使用ChatGPT和类似的大语言模型。</li>
<li>methods: 本研究使用ChatGPT作为检测器，通过 Zero-shot learning 方法进行人工生成文本和人类写作文本的检测。</li>
<li>results: 研究发现，ChatGPT在人工生成文本和人类写作文本之间的检测性能具有相似性，但是在某些情况下可能会受到干扰。这些结果提供了关于如何使用ChatGPT和类似的大语言模型在自动检测pipeline中的信息。<details>
<summary>Abstract</summary>
Large language models (LLMs) such as ChatGPT are increasingly being used for various use cases, including text content generation at scale. Although detection methods for such AI-generated text exist already, we investigate ChatGPT's performance as a detector on such AI-generated text, inspired by works that use ChatGPT as a data labeler or annotator. We evaluate the zero-shot performance of ChatGPT in the task of human-written vs. AI-generated text detection, and perform experiments on publicly available datasets. We empirically investigate if ChatGPT is symmetrically effective in detecting AI-generated or human-written text. Our findings provide insight on how ChatGPT and similar LLMs may be leveraged in automated detection pipelines by simply focusing on solving a specific aspect of the problem and deriving the rest from that solution. All code and data is available at https://github.com/AmritaBh/ChatGPT-as-Detector.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）如ChatGPT在不同的应用场景中日益受到应用，包括大规模文本内容生成。虽然现有的AI生成文本检测方法已经存在，但我们在ChatGPT作为数据标注器或标注者的灵感下进行研究，检测AI生成文本的性能。我们对公共可用数据集进行了零shot性能评估，并对人工生成和AI生成文本之间的对比进行了实验。我们发现ChatGPT在检测人工生成和AI生成文本的任务中具有相似的效果。我们的发现可能有助于在自动检测管道中使用ChatGPT和类似的LLM，只需关注解决特定问题的方法，然后从其中 derivation 其他方面的解决方案。所有代码和数据可以在 GitHub 上找到：https://github.com/AmritaBh/ChatGPT-as-Detector。
</details></li>
</ul>
<hr>
<h2 id="BRNES-Enabling-Security-and-Privacy-aware-Experience-Sharing-in-Multiagent-Robotic-and-Autonomous-Systems"><a href="#BRNES-Enabling-Security-and-Privacy-aware-Experience-Sharing-in-Multiagent-Robotic-and-Autonomous-Systems" class="headerlink" title="BRNES: Enabling Security and Privacy-aware Experience Sharing in Multiagent Robotic and Autonomous Systems"></a>BRNES: Enabling Security and Privacy-aware Experience Sharing in Multiagent Robotic and Autonomous Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01274">http://arxiv.org/abs/2308.01274</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aralab-unr/brnes">https://github.com/aralab-unr/brnes</a></li>
<li>paper_authors: Md Tamjid Hossain, Hung Manh La, Shahriar Badsha, Anton Netchaev</li>
<li>For: The paper is written to address the issues of adversarial manipulation and inference in multi-agent reinforcement learning (MARL) with experience sharing (ES).* Methods: The proposed framework, called BRNES, uses a dynamic neighbor zone selection and weighted experience aggregation to reduce the impact of Byzantine attacks. It also employs local differential privacy (LDP) to protect the agents’ private information from adversarial inference attacks.* Results: The proposed framework outperforms the state-of-the-art in terms of steps to goal, obtained reward, and time to goal metrics. Specifically, it is 8.32x faster than non-private frameworks and 1.41x faster than private frameworks in an adversarial setting.<details>
<summary>Abstract</summary>
Although experience sharing (ES) accelerates multiagent reinforcement learning (MARL) in an advisor-advisee framework, attempts to apply ES to decentralized multiagent systems have so far relied on trusted environments and overlooked the possibility of adversarial manipulation and inference. Nevertheless, in a real-world setting, some Byzantine attackers, disguised as advisors, may provide false advice to the advisee and catastrophically degrade the overall learning performance. Also, an inference attacker, disguised as an advisee, may conduct several queries to infer the advisors' private information and make the entire ES process questionable in terms of privacy leakage. To address and tackle these issues, we propose a novel MARL framework (BRNES) that heuristically selects a dynamic neighbor zone for each advisee at each learning step and adopts a weighted experience aggregation technique to reduce Byzantine attack impact. Furthermore, to keep the agent's private information safe from adversarial inference attacks, we leverage the local differential privacy (LDP)-induced noise during the ES process. Our experiments show that our framework outperforms the state-of-the-art in terms of the steps to goal, obtained reward, and time to goal metrics. Particularly, our evaluation shows that the proposed framework is 8.32x faster than the current non-private frameworks and 1.41x faster than the private frameworks in an adversarial setting.
</details>
<details>
<summary>摘要</summary>
虽然经验分享（ES）可以加速多代理激励学习（MARL）在顾问-受顾问框架下，但是在分散式多代理系统中应用ES的尝试都是在可信环境中进行，而忽视了对敌意攻击和推理的可能性。然而，在实际场景中，一些贪婪攻击者，化名为顾问，可能为受顾问提供错误的建议，从而导致总的学习性能受到极大的降低。此外，一个推理攻击者，化名为受顾问，可能通过多个查询来推理出顾问的私人信息，使整个ES过程存在隐私泄露问题。为解决这些问题，我们提议一种基于BRNES的新的MARL框架，强制选择每个受顾问的动态邻区，并采用权重经验聚合技术来减少攻击影响。此外，通过在ES过程中应用本地幂等隐私（LDP）引起的噪声，保护代理的私人信息免遭敌意推理攻击。我们的实验表明，我们的框架比现有的非私钥框架快8.32倍，比私钥框架快1.41倍在敌意 Setting中。
</details></li>
</ul>
<hr>
<h2 id="A-Probabilistic-Approach-to-Self-Supervised-Learning-using-Cyclical-Stochastic-Gradient-MCMC"><a href="#A-Probabilistic-Approach-to-Self-Supervised-Learning-using-Cyclical-Stochastic-Gradient-MCMC" class="headerlink" title="A Probabilistic Approach to Self-Supervised Learning using Cyclical Stochastic Gradient MCMC"></a>A Probabilistic Approach to Self-Supervised Learning using Cyclical Stochastic Gradient MCMC</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01271">http://arxiv.org/abs/2308.01271</a></li>
<li>repo_url: None</li>
<li>paper_authors: Masoumeh Javanbakhat, Christoph Lippert</li>
<li>for: 本研究提出了一种实用的 bayesian自适应学习方法，使用循环随机梯度哈密顿-蒙特卡洛（cSGHMC）来 aproximate高维度和多模态的 posterior 分布。</li>
<li>methods: 本方法使用 prior 来置信自适应学习模型的参数，并使用 cSGHMC 来 aproximate高维度和多模态的 posterior 分布。</li>
<li>results: 通过寻找表示的expressive posterior，悉数自适应学习得到了可读性和多样性的表示。在多种下游分类任务上，取得了显著的性能提升、校准和对于类型检测。<details>
<summary>Abstract</summary>
In this paper we present a practical Bayesian self-supervised learning method with Cyclical Stochastic Gradient Hamiltonian Monte Carlo (cSGHMC). Within this framework, we place a prior over the parameters of a self-supervised learning model and use cSGHMC to approximate the high dimensional and multimodal posterior distribution over the embeddings. By exploring an expressive posterior over the embeddings, Bayesian self-supervised learning produces interpretable and diverse representations. Marginalizing over these representations yields a significant gain in performance, calibration and out-of-distribution detection on a variety of downstream classification tasks. We provide experimental results on multiple classification tasks on four challenging datasets. Moreover, we demonstrate the effectiveness of the proposed method in out-of-distribution detection using the SVHN and CIFAR-10 datasets.
</details>
<details>
<summary>摘要</summary>
在本文中，我们提出了一种实用的极 bayesian自适应学习方法，即循环随机Gradient Hamiltonian Monte Carlo（cSGHMC）。在这种框架下，我们对自适应学习模型参数进行了先验，并使用cSGHMC来近似高维多模态 posterior distribution over the embeddings。通过探索高维多模态的 posterior over the embeddings，bayesian自适应学习可以生成可读性和多样性的表示。对这些表示进行摘要，可以获得显著的性能、调整和出现在其他分类任务上的表现。我们在多个分类任务上进行了多个数据集的实验，并在SVHN和CIFAR-10数据集上进行了out-of-distribution检测。
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-psychology-of-GPT-4’s-Moral-and-Legal-Reasoning"><a href="#Exploring-the-psychology-of-GPT-4’s-Moral-and-Legal-Reasoning" class="headerlink" title="Exploring the psychology of GPT-4’s Moral and Legal Reasoning"></a>Exploring the psychology of GPT-4’s Moral and Legal Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01264">http://arxiv.org/abs/2308.01264</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guilherme F. C. F. Almeida, José Luiz Nunes, Neele Engelmann, Alex Wiegmann, Marcelo de Araújo</li>
<li>for: 这个论文旨在研究大语言模型GPT-4的道德和法律决策方面的 simulated human reasoning。</li>
<li>methods: 作者使用心理学方法 probing GPT-4的道德和法律决策过程。</li>
<li>results: 研究发现GPT-4和人类在意图归属、 causality 判断、诱导行为、道德基础、legal luck 的影响以及同意和规则违反判断方面存在高相关性，但也有一些重要的系统性差异。<details>
<summary>Abstract</summary>
Large language models have been used as the foundation of highly sophisticated artificial intelligences, capable of delivering human-like responses to probes about legal and moral issues. However, these models are unreliable guides to their own inner workings, and even the engineering teams behind their creation are unable to explain exactly how they came to develop all of the capabilities they currently have. The emerging field of machine psychology seeks to gain insight into the processes and concepts that these models possess. In this paper, we employ the methods of psychology to probe into GPT-4's moral and legal reasoning. More specifically, we investigate the similarities and differences between GPT-4 and humans when it comes to intentionality ascriptions, judgments about causation, the morality of deception, moral foundations, the impact of moral luck on legal judgments, the concept of consent, and rule violation judgments. We find high correlations between human and AI responses, but also several significant systematic differences between them. We conclude with a discussion of the philosophical implications of our findings.
</details>
<details>
<summary>摘要</summary>
大型语言模型已被用为高级人工智能的基础，能够提供人类样式的回应于法律和道德问题。然而，这些模型对自己内部的工作方式是不可靠的导航， même 创建团队无法完全解释它们如何获得所有现有的能力。新兴领域的机器心理学欲了解这些模型内部的过程和概念。在这篇论文中，我们使用心理学方法探究GPT-4的道德和法律理解。更 specifically，我们研究人类和AI在意图归属、 causation 判断、误导的道德性、道德基础、legal 判断的道德遗产、同意和规则违反判断方面的相似性和差异。我们发现人类和 AI 回应之间存在高相关性，但也存在一些重要的系统性差异。我们结束于哲学意义的讨论。
</details></li>
</ul>
<hr>
<h2 id="XSTest-A-Test-Suite-for-Identifying-Exaggerated-Safety-Behaviours-in-Large-Language-Models"><a href="#XSTest-A-Test-Suite-for-Identifying-Exaggerated-Safety-Behaviours-in-Large-Language-Models" class="headerlink" title="XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models"></a>XSTest: A Test Suite for Identifying Exaggerated Safety Behaviours in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01263">http://arxiv.org/abs/2308.01263</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paul Röttger, Hannah Rose Kirk, Bertie Vidgen, Giuseppe Attanasio, Federico Bianchi, Dirk Hovy</li>
<li>For: The paper is written to address the issue of large language models following malicious instructions and generating toxic content, and to propose a new test suite called XSTest to identify eXaggerated Safety behaviors in a structured and systematic way.* Methods: The paper uses a new test suite called XSTest, which comprises 200 safe prompts across ten prompt types, to evaluate the safety behaviors of a recently-released state-of-the-art language model.* Results: The paper highlights systematic failure modes in the language model, demonstrating that it is not well-calibrated and tends to refuse complying with safe prompts that use similar language to unsafe prompts or mention sensitive topics.<details>
<summary>Abstract</summary>
Without proper safeguards, large language models will readily follow malicious instructions and generate toxic content. This motivates safety efforts such as red-teaming and large-scale feedback learning, which aim to make models both helpful and harmless. However, there is a tension between these two objectives, since harmlessness requires models to refuse complying with unsafe prompts, and thus not be helpful. Recent anecdotal evidence suggests that some models may have struck a poor balance, so that even clearly safe prompts are refused if they use similar language to unsafe prompts or mention sensitive topics. In this paper, we introduce a new test suite called XSTest to identify such eXaggerated Safety behaviours in a structured and systematic way. In its current form, XSTest comprises 200 safe prompts across ten prompt types that well-calibrated models should not refuse to comply with. We describe XSTest's creation and composition, and use the test suite to highlight systematic failure modes in a recently-released state-of-the-art language model.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese: Without proper safeguards, large language models will readily follow malicious instructions and generate toxic content, which motivates safety efforts such as red-teaming and large-scale feedback learning to make models both helpful and harmless. However, there is a tension between these two objectives, as harmlessness requires models to refuse complying with unsafe prompts, and thus not be helpful. Recent anecdotal evidence suggests that some models may have struck a poor balance, so that even clearly safe prompts are refused if they use similar language to unsafe prompts or mention sensitive topics. In this paper, we introduce a new test suite called XSTest to identify such eXaggerated Safety behaviors in a structured and systematic way. In its current form, XSTest comprises 200 safe prompts across ten prompt types that well-calibrated models should not refuse to comply with. We describe XSTest's creation and composition, and use the test suite to highlight systematic failure modes in a recently-released state-of-the-art language model.Translated into Traditional Chinese: Without proper safeguards, large language models will readily follow malicious instructions and generate toxic content, which motivates safety efforts such as red-teaming and large-scale feedback learning to make models both helpful and harmless. However, there is a tension between these two objectives, as harmlessness requires models to refuse complying with unsafe prompts, and thus not be helpful. Recent anecdotal evidence suggests that some models may have struck a poor balance, so that even clearly safe prompts are refused if they use similar language to unsafe prompts or mention sensitive topics. In this paper, we introduce a new test suite called XSTest to identify such eXaggerated Safety behaviors in a structured and systematic way. In its current form, XSTest comprises 200 safe prompts across ten prompt types that well-calibrated models should not refuse to comply with. We describe XSTest's creation and composition, and use the test suite to highlight systematic failure modes in a recently-released state-of-the-art language model.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/03/cs.AI_2023_08_03/" data-id="closbrojr001r0g88east4erg" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/65/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/64/">64</a><a class="page-number" href="/page/65/">65</a><span class="page-number current">66</span><a class="page-number" href="/page/67/">67</a><a class="page-number" href="/page/68/">68</a><span class="space">&hellip;</span><a class="page-number" href="/page/89/">89</a><a class="extend next" rel="next" href="/page/67/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">129</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">60</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">118</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">69</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">58</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
