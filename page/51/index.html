
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/51/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.LG_2023_08_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/21/cs.LG_2023_08_21/" class="article-date">
  <time datetime="2023-08-21T10:00:00.000Z" itemprop="datePublished">2023-08-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/21/cs.LG_2023_08_21/">cs.LG - 2023-08-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Graph-Neural-Bandits"><a href="#Graph-Neural-Bandits" class="headerlink" title="Graph Neural Bandits"></a>Graph Neural Bandits</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10808">http://arxiv.org/abs/2308.10808</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lasgroup/GNNBO">https://github.com/lasgroup/GNNBO</a></li>
<li>paper_authors: Yunzhe Qi, Yikun Ban, Jingrui He</li>
<li>for: 本研究旨在提出一种基于图神经网络的推荐框架，以优化推荐策略并解决推荐问题中的挖掘-探索之间的矛盾。</li>
<li>methods: 本研究使用图神经网络模型来建模用户之间的协同关系，并分别使用GNN-based模型来适应不同的探索和利用策略。</li>
<li>results: 经过理论分析和实验研究，本研究在多个真实数据集上与现有基elines进行比较，并证明了GNB框架的效果。<details>
<summary>Abstract</summary>
Contextual bandits algorithms aim to choose the optimal arm with the highest reward out of a set of candidates based on the contextual information. Various bandit algorithms have been applied to real-world applications due to their ability of tackling the exploitation-exploration dilemma. Motivated by online recommendation scenarios, in this paper, we propose a framework named Graph Neural Bandits (GNB) to leverage the collaborative nature among users empowered by graph neural networks (GNNs). Instead of estimating rigid user clusters as in existing works, we model the "fine-grained" collaborative effects through estimated user graphs in terms of exploitation and exploration respectively. Then, to refine the recommendation strategy, we utilize separate GNN-based models on estimated user graphs for exploitation and adaptive exploration. Theoretical analysis and experimental results on multiple real data sets in comparison with state-of-the-art baselines are provided to demonstrate the effectiveness of our proposed framework.
</details>
<details>
<summary>摘要</summary>
Contextual bandits algorithms target 选择最佳臂 基于候选人的各种情况信息。各种bandit算法在实际应用中得到了广泛应用，因为它们可以解决探索-投入之间的矛盾。在这篇论文中，我们提出了一个名为图ael Neural Bandits（GNB）的框架，以利用用户 empowered by graph neural networks（GNNs）的协同性。而不是现有的rigid用户群集 estimation，我们通过估算用户图中的exploitation和exploration的协同效果来模型"细化的"协同效果。然后，为了细化推荐策略，我们使用了分开的 GNN-based 模型来适应 estimated user graphs 中的exploitation和适应性。我们提供了理论分析和多个实际数据集的实验结果，以证明我们提出的框架的有效性。
</details></li>
</ul>
<hr>
<h2 id="DynED-Dynamic-Ensemble-Diversification-in-Data-Stream-Classification"><a href="#DynED-Dynamic-Ensemble-Diversification-in-Data-Stream-Classification" class="headerlink" title="DynED: Dynamic Ensemble Diversification in Data Stream Classification"></a>DynED: Dynamic Ensemble Diversification in Data Stream Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10807">http://arxiv.org/abs/2308.10807</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/soheilabadifard/dyned">https://github.com/soheilabadifard/dyned</a></li>
<li>paper_authors: Soheil Abadifard, Sepehr Bakhshi, Sanaz Gheibuni, Fazli Can</li>
<li>for: 提高数据流环境中分类精度，因为数据分布变化导致模型性能下降。</li>
<li>methods: 使用MMR方法动态组合多个组件，以提高 ensemble 的各种性能和多样性。</li>
<li>results: 在实验中，提出的方法（DynED）与五种基准方法相比，平均含义准确率更高。<details>
<summary>Abstract</summary>
Ensemble methods are commonly used in classification due to their remarkable performance. Achieving high accuracy in a data stream environment is a challenging task considering disruptive changes in the data distribution, also known as concept drift. A greater diversity of ensemble components is known to enhance prediction accuracy in such settings. Despite the diversity of components within an ensemble, not all contribute as expected to its overall performance. This necessitates a method for selecting components that exhibit high performance and diversity. We present a novel ensemble construction and maintenance approach based on MMR (Maximal Marginal Relevance) that dynamically combines the diversity and prediction accuracy of components during the process of structuring an ensemble. The experimental results on both four real and 11 synthetic datasets demonstrate that the proposed approach (DynED) provides a higher average mean accuracy compared to the five state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
ensemble 方法通常在分类 task 中使用，因为它们的表现非常出色。在数据流环境中达到高精度是一项具有挑战性的任务，因为数据分布的变化可能会导致模型的训练失败。更多的 ensemble 组件可以提高预测精度在这些设置下。 despite ensemble 中的组件的多样性，不 todas 都会如期提供贡献。这种情况需要一种方法来选择表现出色并且多样的组件。我们提出了一种基于 MMR（最大最大关注度）的ensemble construction 和维护方法，可以在结构 ensemble 时间动态结合多样性和预测精度的组件。实验结果表明，提出的方法（DynED）在四个实际数据集和11个 sintetic 数据集上的平均含义精度比五种现有基准高。
</details></li>
</ul>
<hr>
<h2 id="Differentiable-Frank-Wolfe-Optimization-Layer"><a href="#Differentiable-Frank-Wolfe-Optimization-Layer" class="headerlink" title="Differentiable Frank-Wolfe Optimization Layer"></a>Differentiable Frank-Wolfe Optimization Layer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10806">http://arxiv.org/abs/2308.10806</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zixuan Liu, Liu Liu, Xueqian Wang, Peilin Zhao</li>
<li>for: 提高大规模问题中的可 diferenciable优化效率</li>
<li>methods: 基于Frank-Wolfe算法的可 differentiable层（DFWLayer）</li>
<li>results: 提供了一种高效的可 diferenciable优化方法，可以在大规模问题中实现紧跟约束和高速计算。<details>
<summary>Abstract</summary>
Differentiable optimization has received a significant amount of attention due to its foundational role in the domain of machine learning based on neural networks. The existing methods leverages the optimality conditions and implicit function theorem to obtain the Jacobian matrix of the output, which increases the computational cost and limits the application of differentiable optimization. In addition, some non-differentiable constraints lead to more challenges when using prior differentiable optimization layers. This paper proposes a differentiable layer, named Differentiable Frank-Wolfe Layer (DFWLayer), by rolling out the Frank-Wolfe method, a well-known optimization algorithm which can solve constrained optimization problems without projections and Hessian matrix computations, thus leading to a efficient way of dealing with large-scale problems. Theoretically, we establish a bound on the suboptimality gap of the DFWLayer in the context of l1-norm constraints. Experimental assessments demonstrate that the DFWLayer not only attains competitive accuracy in solutions and gradients but also consistently adheres to constraints. Moreover, it surpasses the baselines in both forward and backward computational speeds.
</details>
<details>
<summary>摘要</summary>
differential optimization 已经收到了广泛关注，因为它在机器学习领域中的神经网络上发挥了基本作用。现有的方法利用优化条件和隐函数定理来获取输出 Jacobian 矩阵，这会增加计算成本并限制 differentiable optimization 的应用。此外，一些非 differentiable 约束会导致使用先前的 differentiable optimization 层更加困难。本文提出了一个 differentiable 层，名为 Differentiable Frank-Wolfe Layer (DFWLayer)，通过折衣 Frank-Wolfe 算法，这是一种可以解决约束优化问题的优化算法，不需要投影和卷积矩阵计算，因此可以更好地处理大规模问题。我们在理论上也设置了 l1-norm 约束下 DFWLayer 的优化误差 bound。实验评估表明，DFWLayer 不仅可以达到竞争性的解和梯度准确度，还能够一致地遵循约束。此外，它在前进和后退计算速度上也超过了基eline。
</details></li>
</ul>
<hr>
<h2 id="Stabilizing-Unsupervised-Environment-Design-with-a-Learned-Adversary"><a href="#Stabilizing-Unsupervised-Environment-Design-with-a-Learned-Adversary" class="headerlink" title="Stabilizing Unsupervised Environment Design with a Learned Adversary"></a>Stabilizing Unsupervised Environment Design with a Learned Adversary</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10797">http://arxiv.org/abs/2308.10797</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/dcd">https://github.com/facebookresearch/dcd</a></li>
<li>paper_authors: Ishita Mediratta, Minqi Jiang, Jack Parker-Holder, Michael Dennis, Eugene Vinitsky, Tim Rocktäschel</li>
<li>for: train generally-capable agents and design training tasks that facilitate broad generalization and robustness to environment variations</li>
<li>methods: reinforcement learning (RL) to train a teacher policy to design tasks from scratch</li>
<li>results: proposed solutions to several key shortcomings of PAIRED, enabling PAIRED to match or exceed state-of-the-art methods in several established challenging procedurally-generated environments<details>
<summary>Abstract</summary>
A key challenge in training generally-capable agents is the design of training tasks that facilitate broad generalization and robustness to environment variations. This challenge motivates the problem setting of Unsupervised Environment Design (UED), whereby a student agent trains on an adaptive distribution of tasks proposed by a teacher agent. A pioneering approach for UED is PAIRED, which uses reinforcement learning (RL) to train a teacher policy to design tasks from scratch, making it possible to directly generate tasks that are adapted to the agent's current capabilities. Despite its strong theoretical backing, PAIRED suffers from a variety of challenges that hinder its practical performance. Thus, state-of-the-art methods currently rely on curation and mutation rather than generation of new tasks. In this work, we investigate several key shortcomings of PAIRED and propose solutions for each shortcoming. As a result, we make it possible for PAIRED to match or exceed state-of-the-art methods, producing robust agents in several established challenging procedurally-generated environments, including a partially-observed maze navigation task and a continuous-control car racing environment. We believe this work motivates a renewed emphasis on UED methods based on learned models that directly generate challenging environments, potentially unlocking more open-ended RL training and, as a result, more general agents.
</details>
<details>
<summary>摘要</summary>
一个主要挑战在训练通用的代理人是设计训练任务，以促进广泛的普遍化和环境变化的响应力。这个挑战驱使了无监督环境设计（UED）的问题设定，其中学生代理人通过教师代理人提出的适应性任务来训练。一种开创性的方法是PAIRED，它使用征激学习（RL）来训练教师政策，从scratch生成任务，使得可以直接生成适应到代理人的现有能力的任务。 despite its strong theoretical backing, PAIRED suffers from several challenges that hinder its practical performance. Therefore, state-of-the-art methods currently rely on curation and mutation rather than generation of new tasks. In this work, we investigate several key shortcomings of PAIRED and propose solutions for each shortcoming. As a result, we make it possible for PAIRED to match or exceed state-of-the-art methods, producing robust agents in several established challenging procedurally-generated environments, including a partially-observed maze navigation task and a continuous-control car racing environment. We believe this work motivates a renewed emphasis on UED methods based on learned models that directly generate challenging environments, potentially unlocking more open-ended RL training and, as a result, more general agents.Note: Please note that the translation is in Simplified Chinese, which is one of the two standard versions of Chinese. If you prefer Traditional Chinese, please let me know and I can provide the translation in that version as well.
</details></li>
</ul>
<hr>
<h2 id="MGMAE-Motion-Guided-Masking-for-Video-Masked-Autoencoding"><a href="#MGMAE-Motion-Guided-Masking-for-Video-Masked-Autoencoding" class="headerlink" title="MGMAE: Motion Guided Masking for Video Masked Autoencoding"></a>MGMAE: Motion Guided Masking for Video Masked Autoencoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10794">http://arxiv.org/abs/2308.10794</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bingkun Huang, Zhiyu Zhao, Guozhen Zhang, Yu Qiao, Limin Wang</li>
<li>For: This paper aims to improve the performance of video masked autoencoding by introducing a motion guided masking strategy to incorporate motion information during pre-training.* Methods: The proposed method, called Motion Guided Masked Autoencoder (MGMAE), uses an online efficient optical flow estimator and backward masking map warping strategy to build a temporal consistent masking volume and track unmasked tokens in time.* Results: The proposed MGMAE outperforms the original VideoMAE on the Something-Something V2 and Kinetics-400 datasets, and provides visualization analysis to illustrate the effectiveness of the motion-adaptive sampling of temporal consistent cubes for video pre-training.Here’s the Chinese version of the three points:* For: 这篇论文目标是提高视频掩码自动编码器的性能，通过引入运动导向掩码策略来在预训练中包含运动信息。* Methods: 提议的方法是动态掩码自动编码器（MGMAE），使用在线高效的滤色流估计器和倒掩码地图折叠策略来建立时间一致的掩码量和跟踪时间中的未掩码标签。* Results: MGMAE在Something-Something V2和Kinetics-400数据集上表现出优于原始VideoMAE，并提供视觉分析来证明该方法在时间一致的掩码采样中更有效地进行视频预训练。<details>
<summary>Abstract</summary>
Masked autoencoding has shown excellent performance on self-supervised video representation learning. Temporal redundancy has led to a high masking ratio and customized masking strategy in VideoMAE. In this paper, we aim to further improve the performance of video masked autoencoding by introducing a motion guided masking strategy. Our key insight is that motion is a general and unique prior in video, which should be taken into account during masked pre-training. Our motion guided masking explicitly incorporates motion information to build temporal consistent masking volume. Based on this masking volume, we can track the unmasked tokens in time and sample a set of temporal consistent cubes from videos. These temporal aligned unmasked tokens will further relieve the information leakage issue in time and encourage the MGMAE to learn more useful structure information. We implement our MGMAE with an online efficient optical flow estimator and backward masking map warping strategy. We perform experiments on the datasets of Something-Something V2 and Kinetics-400, demonstrating the superior performance of our MGMAE to the original VideoMAE. In addition, we provide the visualization analysis to illustrate that our MGMAE can sample temporal consistent cubes in a motion-adaptive manner for more effective video pre-training.
</details>
<details>
<summary>摘要</summary>
《面具自编码》已经在无监督视频表征学习中展现出色的表现。视频中的时间重复性导致了高的面具率和定制化面具策略，在VideoMAE中。在这篇论文中，我们希望进一步提高视频面具自编码的性能，通过引入运动指导的面具策略。我们的关键发现是，运动是视频中的一致性和特有的特征，应该在面具预训练中考虑。我们运动指导的面具Explicitly incorporates motion information to build temporal consistent masking volume。基于这个遮盖体积，我们可以在时间上跟踪未遮盖的 токен，并从视频中抽取一组时间相对的一致的 куби。这些时间相对的一致的 куби将进一步减轻时间泄露问题，使MGMAE学习更有用的结构信息。我们实现了我们的MGMAE，使用了在线高效的Optical flow estimator和后向遮盖Map折叠策略。我们在Something-Something V2和Kinetics-400 datasets上进行了实验，示出了我们MGMAE比原始VideoMAE的更高性能。此外，我们还提供了视觉分析，以 Illustrate that our MGMAE can sample temporal consistent cubes in a motion-adaptive manner for more effective video pre-training.
</details></li>
</ul>
<hr>
<h2 id="Instruction-Tuning-for-Large-Language-Models-A-Survey"><a href="#Instruction-Tuning-for-Large-Language-Models-A-Survey" class="headerlink" title="Instruction Tuning for Large Language Models: A Survey"></a>Instruction Tuning for Large Language Models: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10792">http://arxiv.org/abs/2308.10792</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shengyu Zhang, Linfeng Dong, Xiaoya Li, Sen Zhang, Xiaofei Sun, Shuhe Wang, Jiwei Li, Runyi Hu, Tianwei Zhang, Fei Wu, Guoyin Wang</li>
<li>for: 本研究审视了大语言模型（LLM）的指令调整（IT）技术，以提高LLM的能力和可控性。</li>
<li>methods: 本研究使用了一种系统性的Literature Review方法，涵盖了IT的通用方法、指令集建构、模型训练以及不同Modalities、领域和应用程序。</li>
<li>results: 研究发现了一些关键因素影响IT的结果（如生成指令输出和指令集大小），以及潜在的潜在问题和批评，并提出了一些可能的解决方案。<details>
<summary>Abstract</summary>
This paper surveys research works in the quickly advancing field of instruction tuning (IT), a crucial technique to enhance the capabilities and controllability of large language models (LLMs). Instruction tuning refers to the process of further training LLMs on a dataset consisting of \textsc{(instruction, output)} pairs in a supervised fashion, which bridges the gap between the next-word prediction objective of LLMs and the users' objective of having LLMs adhere to human instructions. In this work, we make a systematic review of the literature, including the general methodology of IT, the construction of IT datasets, the training of IT models, and applications to different modalities, domains and applications, along with an analysis on aspects that influence the outcome of IT (e.g., generation of instruction outputs, size of the instruction dataset, etc). We also review the potential pitfalls of IT along with criticism against it, along with efforts pointing out current deficiencies of existing strategies and suggest some avenues for fruitful research.
</details>
<details>
<summary>摘要</summary>
The paper covers the general methodology of IT, IT dataset construction, IT model training, and applications across different modalities, domains, and applications. It also discusses factors that affect IT outcomes, such as generating instruction outputs and dataset size. Additionally, the paper reviews potential pitfalls and criticisms of IT, as well as efforts to address current deficiencies and suggest promising research directions.Here is the translation in Simplified Chinese:这篇论文回顾了大语言模型（LLM）的指令调整（IT）研究，这是一种提高 LLM 的能力和可控性的关键技术。IT 通过在监督下将 LLM 训练在指令和输出对的数据集上，bridge LLM 的下一个词预测目标和用户的指令遵从目标。论文涵盖了 IT 的总方法、指令集成构建、模型训练和应用于不同的模式、领域和应用程序。它还讨论了 IT 的结果受到的因素，如生成指令输出和数据集大小。此外，论文还回顾了 IT 的潜在缺陷和批评，以及改进现有策略的努力。最后，论文还提出了一些有前途的研究方向。
</details></li>
</ul>
<hr>
<h2 id="Zero-and-Few-Shot-Prompting-with-LLMs-A-Comparative-Study-with-Fine-tuned-Models-for-Bangla-Sentiment-Analysis"><a href="#Zero-and-Few-Shot-Prompting-with-LLMs-A-Comparative-Study-with-Fine-tuned-Models-for-Bangla-Sentiment-Analysis" class="headerlink" title="Zero- and Few-Shot Prompting with LLMs: A Comparative Study with Fine-tuned Models for Bangla Sentiment Analysis"></a>Zero- and Few-Shot Prompting with LLMs: A Comparative Study with Fine-tuned Models for Bangla Sentiment Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10783">http://arxiv.org/abs/2308.10783</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md. Arid Hasan, Shudipta Das, Afiyat Anjum, Firoj Alam, Anika Anjum, Avijit Sarker, Sheak Rashed Haider Noori</li>
<li>for: 这篇论文主要是为了探讨孟加拉语 sentiment analysis 的问题，以及大语言模型在这种语言下的表现。</li>
<li>methods: 这篇论文使用了许多不同的语言模型，包括 Flan-T5、GPT-4 和 Bloomz，并进行了比较分析。</li>
<li>results: 研究发现，单语言 transformer 型模型在零和几个shot情况下一直表现出色，并且在不同的语言模型中表现最佳。<details>
<summary>Abstract</summary>
The rapid expansion of the digital world has propelled sentiment analysis into a critical tool across diverse sectors such as marketing, politics, customer service, and healthcare. While there have been significant advancements in sentiment analysis for widely spoken languages, low-resource languages, such as Bangla, remain largely under-researched due to resource constraints. Furthermore, the recent unprecedented performance of Large Language Models (LLMs) in various applications highlights the need to evaluate them in the context of low-resource languages. In this study, we present a sizeable manually annotated dataset encompassing 33,605 Bangla news tweets and Facebook comments. We also investigate zero- and few-shot in-context learning with several language models, including Flan-T5, GPT-4, and Bloomz, offering a comparative analysis against fine-tuned models. Our findings suggest that monolingual transformer-based models consistently outperform other models, even in zero and few-shot scenarios. To foster continued exploration, we intend to make this dataset and our research tools publicly available to the broader research community. In the spirit of further research, we plan to make this dataset and our experimental resources publicly accessible to the wider research community.
</details>
<details>
<summary>摘要</summary>
随着数字世界的快速扩张，情感分析已成为多个领域的关键工具，包括市场营销、政治、客户服务和医疗等。虽然拥有了显著的进步，但低资源语言，如孟加拉语，仍然受到资源限制，未能得到足够的研究。此外，最新的无前例的表现表明需要在低资源语言上评估LLMs。本研究提供了33605个孟加拉语新闻微博和Facebook评论的大量手动标注数据集。我们还进行了零和几个shot在场景下的 zero-和几个shot具体学习，包括Flan-T5、GPT-4和Bloomz等语言模型，并进行了比较分析。我们的发现表明，单语言变换器基本模型在零和几个shot场景下一直表现出色，超越其他模型。为了激发更多的探索，我们计划将这些数据集和研究工具公开提供给更广泛的研究社区。
</details></li>
</ul>
<hr>
<h2 id="Sparse-Linear-Concept-Discovery-Models"><a href="#Sparse-Linear-Concept-Discovery-Models" class="headerlink" title="Sparse Linear Concept Discovery Models"></a>Sparse Linear Concept Discovery Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10782">http://arxiv.org/abs/2308.10782</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/konpanousis/conceptdiscoverymodels">https://github.com/konpanousis/conceptdiscoverymodels</a></li>
<li>paper_authors: Konstantinos P. Panousis, Dino Ienco, Diego Marcos</li>
<li>for: 提高深度学习模型的解释性和性能</li>
<li>methods: 使用对比语言图像模型和单个稀疏线性层</li>
<li>results: 比对其他CBM方法更高的准确率和每个例子的概率性数量<details>
<summary>Abstract</summary>
The recent mass adoption of DNNs, even in safety-critical scenarios, has shifted the focus of the research community towards the creation of inherently intrepretable models. Concept Bottleneck Models (CBMs) constitute a popular approach where hidden layers are tied to human understandable concepts allowing for investigation and correction of the network's decisions. However, CBMs usually suffer from: (i) performance degradation and (ii) lower interpretability than intended due to the sheer amount of concepts contributing to each decision. In this work, we propose a simple yet highly intuitive interpretable framework based on Contrastive Language Image models and a single sparse linear layer. In stark contrast to related approaches, the sparsity in our framework is achieved via principled Bayesian arguments by inferring concept presence via a data-driven Bernoulli distribution. As we experimentally show, our framework not only outperforms recent CBM approaches accuracy-wise, but it also yields high per example concept sparsity, facilitating the individual investigation of the emerging concepts.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "DNNs"  Deep Neural Networks* "CBMs" Concept Bottleneck Models* "interpretable" 可解释的* "safety-critical" 安全关键的* "performance degradation" 性能下降* "lower interpretability" 更低的可解释性* "sparse" 稀疏的* "Bayesian arguments"  bayesian Arguments* " Bernoulli distribution"  Бернулли 分布
</details></li>
</ul>
<hr>
<h2 id="Mixed-Integer-Projections-for-Automated-Data-Correction-of-EMRs-Improve-Predictions-of-Sepsis-among-Hospitalized-Patients"><a href="#Mixed-Integer-Projections-for-Automated-Data-Correction-of-EMRs-Improve-Predictions-of-Sepsis-among-Hospitalized-Patients" class="headerlink" title="Mixed-Integer Projections for Automated Data Correction of EMRs Improve Predictions of Sepsis among Hospitalized Patients"></a>Mixed-Integer Projections for Automated Data Correction of EMRs Improve Predictions of Sepsis among Hospitalized Patients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10781">http://arxiv.org/abs/2308.10781</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mehak Arora, Hassan Mortagy, Nathan Dwarshius, Swati Gupta, Andre L. Holder, Rishikesan Kamaleswaran</li>
<li>for: 这篇研究旨在提高机器学习（ML）模型在诊断过程中的自动化，但储存在过去研究中的一个显著缺陷是不足以处理电子医疗记录（EMR）数据的错误和偏差。</li>
<li>methods: 本研究引入了一种创新的投影方法，让临床专家知识成为领域约束，从而生成重要的元数据，可以在机器学习工作流程中使用。特别是，使用高维混合整数程式来捕捉生物和生物physiological约束，以corrrect пацієnt数据。</li>
<li>results: 我们的框架可以在预后检测 sepsepsis 中提高机器学习分类器的性能，AUROC 为 0.865，精度为 0.922，比没有这些投影的模型更好。<details>
<summary>Abstract</summary>
Machine learning (ML) models are increasingly pivotal in automating clinical decisions. Yet, a glaring oversight in prior research has been the lack of proper processing of Electronic Medical Record (EMR) data in the clinical context for errors and outliers. Addressing this oversight, we introduce an innovative projections-based method that seamlessly integrates clinical expertise as domain constraints, generating important meta-data that can be used in ML workflows. In particular, by using high-dimensional mixed-integer programs that capture physiological and biological constraints on patient vitals and lab values, we can harness the power of mathematical "projections" for the EMR data to correct patient data. Consequently, we measure the distance of corrected data from the constraints defining a healthy range of patient data, resulting in a unique predictive metric we term as "trust-scores". These scores provide insight into the patient's health status and significantly boost the performance of ML classifiers in real-life clinical settings. We validate the impact of our framework in the context of early detection of sepsis using ML. We show an AUROC of 0.865 and a precision of 0.922, that surpasses conventional ML models without such projections.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Spear-and-Shield-Adversarial-Attacks-and-Defense-Methods-for-Model-Based-Link-Prediction-on-Continuous-Time-Dynamic-Graphs"><a href="#Spear-and-Shield-Adversarial-Attacks-and-Defense-Methods-for-Model-Based-Link-Prediction-on-Continuous-Time-Dynamic-Graphs" class="headerlink" title="Spear and Shield: Adversarial Attacks and Defense Methods for Model-Based Link Prediction on Continuous-Time Dynamic Graphs"></a>Spear and Shield: Adversarial Attacks and Defense Methods for Model-Based Link Prediction on Continuous-Time Dynamic Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10779">http://arxiv.org/abs/2308.10779</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongjin Lee, Juho Lee, Kijung Shin</li>
<li>for: This paper focuses on investigating the vulnerabilities of Temporal Graph Neural Networks (TGNNs) against adversarial attacks, specifically for link prediction tasks on continuous-time dynamic graphs.</li>
<li>methods: The proposed method, T-SPEAR, injects edge perturbations into the data that are unnoticeable yet effective in causing malfunction in the victim model. Additionally, the proposed robust training approach, T-SHIELD, uses edge filtering and temporal smoothness to enhance the robustness of the victim model.</li>
<li>results: The paper demonstrates that T-SPEAR significantly degrades the victim model’s performance on link prediction tasks, and the attacks are transferable to other TGNNs. Moreover, T-SHIELD effectively filters out adversarial edges and exhibits robustness against adversarial attacks, surpassing the link prediction performance of the naive TGNN by up to 11.2% under T-SPEAR.Here is the format you requested for the results:</li>
<li>for: 这篇论文专注于investigating TGNNs中的攻击性 vulnerabilities，具体是针对连接预测任务在时间 kontinuous dynamic graphs上。</li>
<li>methods: T-SPEAR方法会将关系变化注入到数据中，这些变化是不可见的，但对犯人模型造成严重的影响。另外，T-SHIELD方法使用边节滤波和时间稳定性来强化犯人模型的抗性。</li>
<li>results: 论文显示T-SPEAR可以对犯人模型进行高效的攻击，并且这些攻击可以转移到其他TGNNs上。另外，T-SHIELD方法可以有效地遮盾掉攻击性关系，并且在适当的情况下超过了简单TGNN的连接预测性能。<details>
<summary>Abstract</summary>
Real-world graphs are dynamic, constantly evolving with new interactions, such as financial transactions in financial networks. Temporal Graph Neural Networks (TGNNs) have been developed to effectively capture the evolving patterns in dynamic graphs. While these models have demonstrated their superiority, being widely adopted in various important fields, their vulnerabilities against adversarial attacks remain largely unexplored. In this paper, we propose T-SPEAR, a simple and effective adversarial attack method for link prediction on continuous-time dynamic graphs, focusing on investigating the vulnerabilities of TGNNs. Specifically, before the training procedure of a victim model, which is a TGNN for link prediction, we inject edge perturbations to the data that are unnoticeable in terms of the four constraints we propose, and yet effective enough to cause malfunction of the victim model. Moreover, we propose a robust training approach T-SHIELD to mitigate the impact of adversarial attacks. By using edge filtering and enforcing temporal smoothness to node embeddings, we enhance the robustness of the victim model. Our experimental study shows that T-SPEAR significantly degrades the victim model's performance on link prediction tasks, and even more, our attacks are transferable to other TGNNs, which differ from the victim model assumed by the attacker. Moreover, we demonstrate that T-SHIELD effectively filters out adversarial edges and exhibits robustness against adversarial attacks, surpassing the link prediction performance of the naive TGNN by up to 11.2% under T-SPEAR.
</details>
<details>
<summary>摘要</summary>
实际世界中的图是动态的，不断发生新的交互，如金融交易在金融网络中。快速图神经网络（TGNN）已经开发出来，以便有效地捕捉动态图中的演变趋势。虽然这些模型已经广泛应用于多个重要领域，但它们的抗击黑客攻击的漏洞仍然未得到了足够的探索。在这篇论文中，我们提出了T-SPEAR，一种简单而有效的黑客攻击方法，用于链接预测任务中的图动态图。具体来说，在受试模型的训练过程之前，我们会注入到数据中的边扰动，这些扰动在我们提出的四个约束下是不可见的，但却足够导致受试模型失效。此外，我们还提出了一种robust训练方法T-SHIELD，用于抗击黑客攻击。通过对边进行筛选和对节点嵌入的时间稳定性来增强受试模型的 robustness。我们的实验研究表明，T-SPEAR会对链接预测任务造成显著的性能下降，而且我们的攻击可以传播到其他不同的TGNNs，即黑客攻击者不知道的模型。此外，我们还证明了T-SHIELD可以有效地筛选出黑客攻击的边，并且在链接预测任务中表现出robustness，超过了 Naive TGNN 的链接预测性能 by up to 11.2% under T-SPEAR.
</details></li>
</ul>
<hr>
<h2 id="A-Modular-and-Adaptive-System-for-Business-Email-Compromise-Detection"><a href="#A-Modular-and-Adaptive-System-for-Business-Email-Compromise-Detection" class="headerlink" title="A Modular and Adaptive System for Business Email Compromise Detection"></a>A Modular and Adaptive System for Business Email Compromise Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10776">http://arxiv.org/abs/2308.10776</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jan Brabec, Filip Šrajer, Radek Starosta, Tomáš Sixta, Marc Dupont, Miloš Lenoch, Jiří Menšík, Florian Becker, Jakub Boros, Tomáš Pop, Pavel Novák</li>
<li>for: 防茧防诈攻击 (BEC) 和对特定目标进行攻击的电子邮件攻击</li>
<li>methods: 复合多种机器学习方法和数据模式，包括自然语言理解 (NLU)，检测电子邮件中的 BEC 相关行为，例如文本、图像、元数据和电子邮件交互 контекст</li>
<li>results: 在生产环境中证明了超过两年的有效性，并且可以适应不断更新的攻击方法，并且可以提供可解释的鉴定结果<details>
<summary>Abstract</summary>
The growing sophistication of Business Email Compromise (BEC) and spear phishing attacks poses significant challenges to organizations worldwide. The techniques featured in traditional spam and phishing detection are insufficient due to the tailored nature of modern BEC attacks as they often blend in with the regular benign traffic. Recent advances in machine learning, particularly in Natural Language Understanding (NLU), offer a promising avenue for combating such attacks but in a practical system, due to limitations such as data availability, operational costs, verdict explainability requirements or a need to robustly evolve the system, it is essential to combine multiple approaches together. We present CAPE, a comprehensive and efficient system for BEC detection that has been proven in a production environment for a period of over two years. Rather than being a single model, CAPE is a system that combines independent ML models and algorithms detecting BEC-related behaviors across various email modalities such as text, images, metadata and the email's communication context. This decomposition makes CAPE's verdicts naturally explainable. In the paper, we describe the design principles and constraints behind its architecture, as well as the challenges of model design, evaluation and adapting the system continuously through a Bayesian approach that combines limited data with domain knowledge. Furthermore, we elaborate on several specific behavioral detectors, such as those based on Transformer neural architectures.
</details>
<details>
<summary>摘要</summary>
现代商业电子邮件攻击（BEC）和特攻钓鱼诈骗攻击的发展日益复杂，对全球企业造成巨大挑战。传统的防范邮件和钓鱼攻击的方法已经不能满足现在的需求，因为这些攻击通常与正常的干扰交通混合在一起。新的机器学习技术，特别是自然语言理解（NLU），提供了一个有希望的途径来对抗这些攻击，但在实践中，由于数据可用性、运营成本、解释性要求或需要不断进化系统的要求，需要结合多种方法。我们介绍了CAPE，一个全面和高效的BEC检测系统，已经在生产环境中运行了超过两年。而不是单一的模型，CAPE是一个结合独立的机器学习模型和算法，检测邮件中的BEC相关行为，包括文本、图像、元数据和邮件的通信上下文。这种分解使CAPE的裁决自然可解释。在文章中，我们介绍了CAPE的设计原则和限制，以及模型设计、评估和持续更新的挑战。此外，我们还详细介绍了一些特定的行为检测器，如基于Transformer神经网络架构的检测器。
</details></li>
</ul>
<hr>
<h2 id="GBM-based-Bregman-Proximal-Algorithms-for-Constrained-Learning"><a href="#GBM-based-Bregman-Proximal-Algorithms-for-Constrained-Learning" class="headerlink" title="GBM-based Bregman Proximal Algorithms for Constrained Learning"></a>GBM-based Bregman Proximal Algorithms for Constrained Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10767">http://arxiv.org/abs/2308.10767</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhenweilin/constrainedgbm">https://github.com/zhenweilin/constrainedgbm</a></li>
<li>paper_authors: Zhenwei Lin, Qi Deng</li>
<li>for: 这个研究是为了开发一个能够满足更加复杂的学习任务的新型机器学习算法，特别是适用于不具有投影构造的条件学习任务，如Neyman-Pearson类别和公平类别。</li>
<li>methods: 这个研究使用了Bregman proximal算法来适应受条件学习任务限制的机器学习问题。它 introduce了一个新的Bregman主要-副主要方法，并且在几何函数下具有全球最佳性保证。在非凸函数下，我们显示了我们的算法仍然能够在Bregman proximal点架构下获得良好的效果。</li>
<li>results: 我们提供了丰富的实验证据，证明了我们的算法框架在NPC和公平类别等条件学习应用中的有效性。而我们的算法框架可以与现有的GBM实现（如XGBoost和LightGBM）集成，不需要更改现有的代码或架构，这使得它具有与现有算法相似的可用性和易用性。<details>
<summary>Abstract</summary>
As the complexity of learning tasks surges, modern machine learning encounters a new constrained learning paradigm characterized by more intricate and data-driven function constraints. Prominent applications include Neyman-Pearson classification (NPC) and fairness classification, which entail specific risk constraints that render standard projection-based training algorithms unsuitable. Gradient boosting machines (GBMs) are among the most popular algorithms for supervised learning; however, they are generally limited to unconstrained settings. In this paper, we adapt the GBM for constrained learning tasks within the framework of Bregman proximal algorithms. We introduce a new Bregman primal-dual method with a global optimality guarantee when the learning objective and constraint functions are convex. In cases of nonconvex functions, we demonstrate how our algorithm remains effective under a Bregman proximal point framework. Distinct from existing constrained learning algorithms, ours possess a unique advantage in their ability to seamlessly integrate with publicly available GBM implementations such as XGBoost (Chen and Guestrin, 2016) and LightGBM (Ke et al., 2017), exclusively relying on their public interfaces. We provide substantial experimental evidence to showcase the effectiveness of the Bregman algorithm framework. While our primary focus is on NPC and fairness ML, our framework holds significant potential for a broader range of constrained learning applications. The source code is currently freely available at https://github.com/zhenweilin/ConstrainedGBM}{https://github.com/zhenweilin/ConstrainedGBM.
</details>
<details>
<summary>摘要</summary>
As the complexity of learning tasks increases, modern machine learning encounters a new constrained learning paradigm with more intricate and data-driven function constraints. Prominent applications include Neyman-Pearson classification (NPC) and fairness classification, which involve specific risk constraints that make standard projection-based training algorithms unsuitable. Gradient boosting machines (GBMs) are one of the most popular algorithms for supervised learning, but they are generally limited to unconstrained settings. In this paper, we adapt the GBM for constrained learning tasks within the framework of Bregman proximal algorithms. We introduce a new Bregman primal-dual method with a global optimality guarantee when the learning objective and constraint functions are convex. In cases of nonconvex functions, we demonstrate how our algorithm remains effective under a Bregman proximal point framework. Unlike existing constrained learning algorithms, ours has a unique advantage in its ability to seamlessly integrate with publicly available GBM implementations such as XGBoost (Chen and Guestrin, 2016) and LightGBM (Ke et al., 2017), relying exclusively on their public interfaces. We provide substantial experimental evidence to showcase the effectiveness of the Bregman algorithm framework. While our primary focus is on NPC and fairness ML, our framework has significant potential for a broader range of constrained learning applications. The source code is currently freely available at <https://github.com/zhenweilin/ConstrainedGBM>.
</details></li>
</ul>
<hr>
<h2 id="To-Whom-are-You-Talking-A-Deep-Learning-Model-to-Endow-Social-Robots-with-Addressee-Estimation-Skills"><a href="#To-Whom-are-You-Talking-A-Deep-Learning-Model-to-Endow-Social-Robots-with-Addressee-Estimation-Skills" class="headerlink" title="To Whom are You Talking? A Deep Learning Model to Endow Social Robots with Addressee Estimation Skills"></a>To Whom are You Talking? A Deep Learning Model to Endow Social Robots with Addressee Estimation Skills</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10757">http://arxiv.org/abs/2308.10757</a></li>
<li>repo_url: None</li>
<li>paper_authors: Carlo Mazzola, Marta Romeo, Francesco Rea, Alessandra Sciutti, Angelo Cangelosi</li>
<li>for: 理解人类对话的动态和社会环境中机器人的整合</li>
<li>methods: 结合卷积层和LSTM层的卷积神经网络模型，利用发言人的非语言表征来解释话语的收件人</li>
<li>results: 模型可以在环境自然的场景中解决对话中的收件人定位问题<details>
<summary>Abstract</summary>
Communicating shapes our social word. For a robot to be considered social and being consequently integrated in our social environment it is fundamental to understand some of the dynamics that rule human-human communication. In this work, we tackle the problem of Addressee Estimation, the ability to understand an utterance's addressee, by interpreting and exploiting non-verbal bodily cues from the speaker. We do so by implementing an hybrid deep learning model composed of convolutional layers and LSTM cells taking as input images portraying the face of the speaker and 2D vectors of the speaker's body posture. Our implementation choices were guided by the aim to develop a model that could be deployed on social robots and be efficient in ecological scenarios. We demonstrate that our model is able to solve the Addressee Estimation problem in terms of addressee localisation in space, from a robot ego-centric point of view.
</details>
<details>
<summary>摘要</summary>
人类与机器人之间的交流 shapes our 社会言语。如果一个机器人想被认为是社交的，那么它必须理解一些人类之间的交流 dynamics。在这项工作中，我们面临着发言者对象估算（Addressee Estimation）问题，即理解一句话的发言者对象。我们通过利用发言者的非语言性身体姿势来解释和利用深度学习模型，该模型由 convolutional layers 和 LSTM cells 组成，并将图像和发言者的姿势 vectors 作为输入。我们的实现方式受到了在社交机器人上部署模型并在生态环境中高效运行的目标的指导。我们证明了我们的模型可以解决发言者对象估算问题，从机器人自身视角来看。
</details></li>
</ul>
<hr>
<h2 id="On-the-Adversarial-Robustness-of-Multi-Modal-Foundation-Models"><a href="#On-the-Adversarial-Robustness-of-Multi-Modal-Foundation-Models" class="headerlink" title="On the Adversarial Robustness of Multi-Modal Foundation Models"></a>On the Adversarial Robustness of Multi-Modal Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10741">http://arxiv.org/abs/2308.10741</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christian Schlarmann, Matthias Hein</li>
<li>for: 保护用户免受恶意内容的误导和宣扬 fake information</li>
<li>methods: 使用隐藏式攻击破坏图像，改变多模态基础模型的描述输出</li>
<li>results: 显示了恶意内容提供者可以使用这种攻击方法诱导用户访问 malicious websites 或 broadcast fake information，需要对多模态基础模型进行防御措施<details>
<summary>Abstract</summary>
Multi-modal foundation models combining vision and language models such as Flamingo or GPT-4 have recently gained enormous interest. Alignment of foundation models is used to prevent models from providing toxic or harmful output. While malicious users have successfully tried to jailbreak foundation models, an equally important question is if honest users could be harmed by malicious third-party content. In this paper we show that imperceivable attacks on images in order to change the caption output of a multi-modal foundation model can be used by malicious content providers to harm honest users e.g. by guiding them to malicious websites or broadcast fake information. This indicates that countermeasures to adversarial attacks should be used by any deployed multi-modal foundation model.
</details>
<details>
<summary>摘要</summary>
多模态基础模型，如FLAMINGO或GPT-4，在最近吸引了巨大的关注。对基础模型的Alignment用于防止模型提供恶意或有害输出。然而，恶意用户已成功地破坏基础模型，另一个重要问题是可以否由正常用户受到恶意第三方内容的伤害。在本文中，我们示出了图像透明攻击可以让恶意内容提供者通过改变多模态基础模型的图像描述来诱导正常用户访问黑客网站或播放假信息。这表明，在部署多模态基础模型时应该使用防御性攻击countermeasure。
</details></li>
</ul>
<hr>
<h2 id="We-Don’t-Need-No-Adam-All-We-Need-Is-EVE-On-The-Variance-of-Dual-Learning-Rate-And-Beyond"><a href="#We-Don’t-Need-No-Adam-All-We-Need-Is-EVE-On-The-Variance-of-Dual-Learning-Rate-And-Beyond" class="headerlink" title="We Don’t Need No Adam, All We Need Is EVE: On The Variance of Dual Learning Rate And Beyond"></a>We Don’t Need No Adam, All We Need Is EVE: On The Variance of Dual Learning Rate And Beyond</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10740">http://arxiv.org/abs/2308.10740</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/akhadangi/EVE">https://github.com/akhadangi/EVE</a></li>
<li>paper_authors: Afshin Khadangi</li>
<li>for: 优化深度学习模型</li>
<li>methods: 采用不同学习率分别对不同分量的梯度进行学习率分化</li>
<li>results: 比较 EXISTS 优化技术在各种标准数据集和架构上的表现，实验结果显示 EVE 方法可以快速减少损失函数的搜索空间，提高模型的性能和稳定性。<details>
<summary>Abstract</summary>
In the rapidly advancing field of deep learning, optimising deep neural networks is paramount. This paper introduces a novel method, Enhanced Velocity Estimation (EVE), which innovatively applies different learning rates to distinct components of the gradients. By bifurcating the learning rate, EVE enables more nuanced control and faster convergence, addressing the challenges associated with traditional single learning rate approaches. Utilising a momentum term that adapts to the learning landscape, the method achieves a more efficient navigation of the complex loss surface, resulting in enhanced performance and stability. Extensive experiments demonstrate that EVE significantly outperforms existing optimisation techniques across various benchmark datasets and architectures.
</details>
<details>
<summary>摘要</summary>
在深度学习领域的快速发展中，优化深度神经网络的重要性日益减震。本文介绍了一种新方法——加速率分配（EVE），它创新地将不同的学习率应用到不同的梯度组件。通过分化学习率，EVE允许更细化的控制和更快的收敛，解决了传统单学习率方法所遇到的挑战。通过适应学习地带的滑动项，方法实现了更加有效的搜索和稳定性。广泛的实验表明，EVE在多种 benchmark 数据集和架构上显著超越了现有的优化技术。
</details></li>
</ul>
<hr>
<h2 id="UGSL-A-Unified-Framework-for-Benchmarking-Graph-Structure-Learning"><a href="#UGSL-A-Unified-Framework-for-Benchmarking-Graph-Structure-Learning" class="headerlink" title="UGSL: A Unified Framework for Benchmarking Graph Structure Learning"></a>UGSL: A Unified Framework for Benchmarking Graph Structure Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10737">http://arxiv.org/abs/2308.10737</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/google-research/google-research">https://github.com/google-research/google-research</a></li>
<li>paper_authors: Bahare Fatemi, Sami Abu-El-Haija, Anton Tsitsulin, Mehran Kazemi, Dustin Zelle, Neslihan Bulut, Jonathan Halcrow, Bryan Perozzi</li>
<li>For: 本研究提出了一种统一框架，用于评估扩展 Graph Neural Networks (GNNs) 的应用范围。* Methods: 本研究使用了多种现有的 GNN 模型，并在一个统一的框架中实现了它们。* Results: 研究对多种组件的影响进行了广泛的分析，并提供了这些方法的优缺点。<details>
<summary>Abstract</summary>
Graph neural networks (GNNs) demonstrate outstanding performance in a broad range of applications. While the majority of GNN applications assume that a graph structure is given, some recent methods substantially expanded the applicability of GNNs by showing that they may be effective even when no graph structure is explicitly provided. The GNN parameters and a graph structure are jointly learned. Previous studies adopt different experimentation setups, making it difficult to compare their merits. In this paper, we propose a benchmarking strategy for graph structure learning using a unified framework. Our framework, called Unified Graph Structure Learning (UGSL), reformulates existing models into a single model. We implement a wide range of existing models in our framework and conduct extensive analyses of the effectiveness of different components in the framework. Our results provide a clear and concise understanding of the different methods in this area as well as their strengths and weaknesses. The benchmark code is available at https://github.com/google-research/google-research/tree/master/ugsl.
</details>
<details>
<summary>摘要</summary>
GRAPH NEURAL NETWORKS (GNNs) 在各种应用场景中表现出色。虽然大多数 GNN 应用场景假设已知图Structured，但一些最近的方法已经扩展了 GNN 的应用范围，并证明它们可以在没有明确提供图结构的情况下也表现出色。这些方法在学习 GNN 参数和图结构时同时进行了学习。先前的研究采用了不同的实验设置，这使得对它们的评价变得困难。在这篇论文中，我们提出了一种图结构学习的 benchmarking 策略，我们称之为 Unified Graph Structure Learning (UGSL)。我们将现有的模型重新表述为单一的模型，并在这个框架中实现了广泛的现有模型。我们进行了广泛的分析，以了解不同组件在这个领域中的效果和优劣点。我们的结果提供了对这些方法的清晰和简洁的理解，以及它们在不同情况下的优劣点。 UGSL 框架的代码可以在 GitHub 上获取：https://github.com/google-research/google-research/tree/master/ugsl。
</details></li>
</ul>
<hr>
<h2 id="Artificial-intelligence-driven-antimicrobial-peptide-discovery"><a href="#Artificial-intelligence-driven-antimicrobial-peptide-discovery" class="headerlink" title="Artificial intelligence-driven antimicrobial peptide discovery"></a>Artificial intelligence-driven antimicrobial peptide discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10921">http://arxiv.org/abs/2308.10921</a></li>
<li>repo_url: None</li>
<li>paper_authors: Paulina Szymczak, Ewa Szczurek</li>
<li>for: 抗微生物蛋白质（AMPs）作为替代性抗生素，以扩展抗生素耐药性的选项。</li>
<li>methods: 人工智能（AI）在AMP发现中发掘新的方法，包括预测蛋白质性能和毒性，以及生成新的AMP候选者。</li>
<li>results: AI在AMP发现中获得了成果，包括透过预测和生成新的AMP候选者，以及控制生成AMPs的性能。<details>
<summary>Abstract</summary>
Antimicrobial peptides (AMPs) emerge as promising agents against antimicrobial resistance, providing an alternative to conventional antibiotics. Artificial intelligence (AI) revolutionized AMP discovery through both discrimination and generation approaches. The discriminators aid the identification of promising candidates by predicting key peptide properties such as activity and toxicity, while the generators learn the distribution over peptides and enable sampling novel AMP candidates, either de novo, or as analogues of a prototype peptide. Moreover, the controlled generation of AMPs with desired properties is achieved by discriminator-guided filtering, positive-only learning, latent space sampling, as well as conditional and optimized generation. Here we review recent achievements in AI-driven AMP discovery, highlighting the most exciting directions.
</details>
<details>
<summary>摘要</summary>
安提米克rob潜血蛋白（AMPs）在抗生素耐荷性方面emerges as promising agents, providing an alternative to conventional antibiotics.人工智能（AI）在AMP发现方面发挥了革命性的作用，通过both discrimination和generation approaches。拒绝器帮助确定优秀候选者，预测蛋白质活性和致病性，而生成器学习蛋白质分布，可以采样新的AMP候选者，或者是蛋白质原型的analogues。此外，控制生成AMPs的拓展和质量的方法还包括拒绝器导向的筛选、正面 alone learning、秘密空间抽样、以及条件和优化的生成。本文回顾了最近的AI驱动的AMP发现成果，强调最有前途的方向。
</details></li>
</ul>
<hr>
<h2 id="What’s-Race-Got-to-do-with-it-Predicting-Youth-Depression-Across-Racial-Groups-Using-Machine-and-Deep-Learning"><a href="#What’s-Race-Got-to-do-with-it-Predicting-Youth-Depression-Across-Racial-Groups-Using-Machine-and-Deep-Learning" class="headerlink" title="What’s Race Got to do with it? Predicting Youth Depression Across Racial Groups Using Machine and Deep Learning"></a>What’s Race Got to do with it? Predicting Youth Depression Across Racial Groups Using Machine and Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11591">http://arxiv.org/abs/2308.11591</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nathan Zhong, Nikhil Yadav</li>
<li>for: 这个研究旨在运用机器学习（ML）和人工神经网络（ANN）模型来诊断高中生中的抑郁症状。</li>
<li>methods: 本研究使用了全国青少年风险行为调查系统（YRBSS）调查数据，并运用了不同的种族子集（白人、黑人和其他少数民族）进行分组训练和测试。</li>
<li>results: 研究发现不同的种族子集有不同的诊断因素，并且发现了一些特定的变量可以帮助预测抑郁症状。ANN模型在整个数据集上 achieve 的F1分数为82.90%，而最佳机器学习模型（支持向量机）则 achieve 81.90%。<details>
<summary>Abstract</summary>
Depression is a common yet serious mental disorder that affects millions of U.S. high schoolers every year. Still, accurate diagnosis and early detection remain significant challenges. In the field of public health, research shows that neural networks produce promising results in identifying other diseases such as cancer and HIV. This study proposes a similar approach, utilizing machine learning (ML) and artificial neural network (ANN) models to classify depression in a student. Additionally, the study highlights the differences in relevant factors for race subgroups and advocates the need for more extensive and diverse datasets. The models train on nationwide Youth Risk Behavior Surveillance System (YRBSS) survey data, in which the most relevant factors of depression are found with statistical analysis. The survey data is a structured dataset with 15000 entries including three race subsets each consisting of 900 entries. For classification, the research problem is modeled as a supervised learning binary classification problem. Factors relevant to depression for different racial subgroups are also identified. The ML and ANN models are trained on the entire dataset followed by different race subsets to classify whether an individual has depression. The ANN model achieves the highest F1 score of 82.90% while the best-performing machine learning model, support vector machines (SVM), achieves a score of 81.90%. This study reveals that different parameters are more valuable for modeling depression across diverse racial groups and furthers research regarding American youth depression.
</details>
<details>
<summary>摘要</summary>
每年数百万美国高中生都会被抑郁症病例所困扰。然而，准确诊断和早期发现仍然是一项重要挑战。在公共卫生领域，研究表明，神经网络生成出了识别其他疾病的可能性。这项研究提议了类似的方法，利用机器学习（ML）和人工神经网络（ANN）模型来诊断抑郁症。此外，研究还指出了不同的种族 subgroup 中相关因素的差异，并且强调了更大和多样化的数据集的需要。这些模型在全国青少年风险行为监测系统（YRBSS）调查数据上训练，该数据集包含15000个数据点，每个数据点包含三个种族 subsets，每个subset 包含900个数据点。为分类，研究问题被定义为一种指导学习二分类问题。不同种族 subgroup 中对抑郁症的相关因素也被 indentified。ML 和 ANN 模型在整个数据集上进行训练，然后在不同种族 subsets 中进行分类，以确定个体是否患有抑郁症。ANN 模型 achievesthe highest F1 score of 82.90%，而最佳机器学习模型，支持向量机（SVM）， achievesthe score of 81.90%。这项研究表明，不同种族 subgroup 中的参数更有价值于模型抑郁症，并且推动了美国青年抑郁症的进一步研究。
</details></li>
</ul>
<hr>
<h2 id="Test-time-augmentation-based-active-learning-and-self-training-for-label-efficient-segmentation"><a href="#Test-time-augmentation-based-active-learning-and-self-training-for-label-efficient-segmentation" class="headerlink" title="Test-time augmentation-based active learning and self-training for label-efficient segmentation"></a>Test-time augmentation-based active learning and self-training for label-efficient segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10727">http://arxiv.org/abs/2308.10727</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bella Specktor-Fadida, Anna Levchakov, Dana Schonberger, Liat Ben-Sira, Dafna Ben-Bashat, Leo Joskowicz<br>for:This paper proposes a new method that combines self-training (ST) with active learning (AL) using Test-Time Augmentations (TTA) for medical image segmentation tasks. The method aims to reduce the annotation burden and improve the performance of the segmentation models.methods:The proposed method combines ST with AL using TTA. TTA is performed on an initial teacher network, and cases for annotation are selected based on the lowest estimated Dice score. The selected annotated cases are trained with existing annotated cases and ST cases with border slices annotations.results:The results show that ST is highly effective for both fetal body and placenta segmentation tasks, boosting performance for in-distribution (ID) and out-of-distribution (OOD) data. However, the combination of AL and ST did not improve performance for single-sequence fetal body segmentation, and AL was more effective for high-variability placenta data. The method achieved a Dice score of 0.961 for fetal body segmentation with only 6 original scans and 2 new sequence scans, and the results using 15 high-variability placenta cases were similar to those using 50 cases.<details>
<summary>Abstract</summary>
Deep learning techniques depend on large datasets whose annotation is time-consuming. To reduce annotation burden, the self-training (ST) and active-learning (AL) methods have been developed as well as methods that combine them in an iterative fashion. However, it remains unclear when each method is the most useful, and when it is advantageous to combine them. In this paper, we propose a new method that combines ST with AL using Test-Time Augmentations (TTA). First, TTA is performed on an initial teacher network. Then, cases for annotation are selected based on the lowest estimated Dice score. Cases with high estimated scores are used as soft pseudo-labels for ST. The selected annotated cases are trained with existing annotated cases and ST cases with border slices annotations. We demonstrate the method on MRI fetal body and placenta segmentation tasks with different data variability characteristics. Our results indicate that ST is highly effective for both tasks, boosting performance for in-distribution (ID) and out-of-distribution (OOD) data. However, while self-training improved the performance of single-sequence fetal body segmentation when combined with AL, it slightly deteriorated performance of multi-sequence placenta segmentation on ID data. AL was helpful for the high variability placenta data, but did not improve upon random selection for the single-sequence body data. For fetal body segmentation sequence transfer, combining AL with ST following ST iteration yielded a Dice of 0.961 with only 6 original scans and 2 new sequence scans. Results using only 15 high-variability placenta cases were similar to those using 50 cases. Code is available at: https://github.com/Bella31/TTA-quality-estimation-ST-AL
</details>
<details>
<summary>摘要</summary>
深度学习技术需要大量数据进行注释，但这些注释可以是时间consuming的。为了减轻注释负担，自动训练（ST）和活动学习（AL）方法已经被开发出来，同时也有将这两种方法相互融合的方法。然而，还没有一个明确的时候，哪种方法是最有用，并且在哪些情况下合理使用它们。在这篇论文中，我们提出了一种新的方法，即将ST与AL相互融合，使用测试时数据扩展（TTA）。首先，TTA被应用于初始教师网络。然后，根据最低估计的 dice 分数选择简单的注释案例。高估分的案例用作软 Pseudo-标签，并将其与已有注释案例和ST案例进行训练。我们在MRI胎Body和 Placenta分割任务上进行了实验，并证明了ST是这两个任务中非常有效的。然而，在单个序列Body分割任务中，杂合AL与ST时，ST会提高ID数据和OOD数据的性能，但是在单个序列Body分割任务中，杂合AL与ST时，ST会轻微下降ID数据的性能。在多个序列Placenta分割任务中，AL可以帮助高度变化的数据，但是在单个序列Body分割任务中，AL无法提高随机选择的性能。在胎Body分割序列传输任务中，将AL与ST相互融合，并在ST迭代后进行AL，可以达到0.961的Dice值，只需要6个原始扫描和2个新序列扫描。在50个高度变化的Placenta数据中，使用只有15个高度变化的Placenta数据可以达到类似的性能。我们的代码可以在以下github上找到：https://github.com/Bella31/TTA-quality-estimation-ST-AL。
</details></li>
</ul>
<hr>
<h2 id="Clustered-Linear-Contextual-Bandits-with-Knapsacks"><a href="#Clustered-Linear-Contextual-Bandits-with-Knapsacks" class="headerlink" title="Clustered Linear Contextual Bandits with Knapsacks"></a>Clustered Linear Contextual Bandits with Knapsacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10722">http://arxiv.org/abs/2308.10722</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yichuan Deng, Michalis Mamakos, Zhao Song</li>
<li>for: 本研究探讨了归一化上下文抽奖问题，即奖励和资源消耗是由群集特定的线性模型决定的。 arms 被分成 clusters，cluster 的成员身份不知道给算法。</li>
<li>methods: 我们提供了一种算法，可以在不知道所有 arm 的情况下，在数量较少的时间 periods 内具有减少 regret 的性能。我们使用了 econometrics 和抽奖 constrained  литературе中的技术，并实现了一种高效的 clustering 方法。</li>
<li>results: 我们证明了这种算法可以在数量较少的时间 periods 内具有减少 regret 的性能，而不需要访问所有 arm。特别是，我们发现可以通过在一个随机选择的 subset 上进行 clustering，来实现这一点。<details>
<summary>Abstract</summary>
In this work, we study clustered contextual bandits where rewards and resource consumption are the outcomes of cluster-specific linear models. The arms are divided in clusters, with the cluster memberships being unknown to an algorithm. Pulling an arm in a time period results in a reward and in consumption for each one of multiple resources, and with the total consumption of any resource exceeding a constraint implying the termination of the algorithm. Thus, maximizing the total reward requires learning not only models about the reward and the resource consumption, but also cluster memberships. We provide an algorithm that achieves regret sublinear in the number of time periods, without requiring access to all of the arms. In particular, we show that it suffices to perform clustering only once to a randomly selected subset of the arms. To achieve this result, we provide a sophisticated combination of techniques from the literature of econometrics and of bandits with constraints.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们研究集中的上下文投机，其中奖励和资源消耗是集中的线性模型的结果。武器被分成集群，集群成员身份不知道算法。在一个时间段内抽取一个武器会得到奖励和每种多种资源的消耗，而任何资源的总消耗超过限制就意味着算法终止。因此，最大化总奖励需要学习不仅奖励和资源消耗的模型，还需要集群成员身份。我们提供一个可以在时间期限内达到减少于数量的 regret的算法，不需要访问所有武器。特别是，我们显示了可以在随机选择的 subset of 武器上进行分 clustering。为了实现这个结果，我们提供了来自 econometrics 和投机 WITH 限制的 литераature 中的复杂组合技术。
</details></li>
</ul>
<hr>
<h2 id="CoMIX-A-Multi-agent-Reinforcement-Learning-Training-Architecture-for-Efficient-Decentralized-Coordination-and-Independent-Decision-Making"><a href="#CoMIX-A-Multi-agent-Reinforcement-Learning-Training-Architecture-for-Efficient-Decentralized-Coordination-and-Independent-Decision-Making" class="headerlink" title="CoMIX: A Multi-agent Reinforcement Learning Training Architecture for Efficient Decentralized Coordination and Independent Decision Making"></a>CoMIX: A Multi-agent Reinforcement Learning Training Architecture for Efficient Decentralized Coordination and Independent Decision Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10721">http://arxiv.org/abs/2308.10721</a></li>
<li>repo_url: None</li>
<li>paper_authors: Giovanni Minelli, Mirco Musolesi</li>
<li>for: 这篇论文是为了提出一种基于协调QMIX（CoMIX）的培训框架，以便在分布式代理中实现稳定协调。</li>
<li>methods: 该论文使用了自适应策略，让每个代理在决策过程中独立做出决定，同时也能够适应不同情况，协调决策。</li>
<li>results: 在多种 simulate环境中进行的实验表明，CoMIX在合作任务上表现更好于基线值，这 validate了我们的增量策略方法是一种有效的协调技术。<details>
<summary>Abstract</summary>
Robust coordination skills enable agents to operate cohesively in shared environments, together towards a common goal and, ideally, individually without hindering each other's progress. To this end, this paper presents Coordinated QMIX (CoMIX), a novel training framework for decentralized agents that enables emergent coordination through flexible policies, allowing at the same time independent decision-making at individual level. CoMIX models selfish and collaborative behavior as incremental steps in each agent's decision process. This allows agents to dynamically adapt their behavior to different situations balancing independence and collaboration. Experiments using a variety of simulation environments demonstrate that CoMIX outperforms baselines on collaborative tasks. The results validate our incremental policy approach as effective technique for improving coordination in multi-agent systems.
</details>
<details>
<summary>摘要</summary>
Robust协调技能使代理人在共享环境中协同工作，共同向共同目标努力，并理想地不干扰别的进步。为了实现这一目标，这篇论文提出了协调QMIX（CoMIX），一种新的培训框架 для分布式代理人，允许 agents在各自决策过程中动态适应不同情况，同时保持独立决策能力。CoMIX将自利和合作行为视为各自决策过程中的逐步增量。这使得代理人可以在不同情况下动态地适应，均衡独立和合作。实验结果表明，CoMIX在合作任务上比基eline表现出色，这证明了我们的逐步政策方法是有效的。
</details></li>
</ul>
<hr>
<h2 id="Relax-and-penalize-a-new-bilevel-approach-to-mixed-binary-hyperparameter-optimization"><a href="#Relax-and-penalize-a-new-bilevel-approach-to-mixed-binary-hyperparameter-optimization" class="headerlink" title="Relax and penalize: a new bilevel approach to mixed-binary hyperparameter optimization"></a>Relax and penalize: a new bilevel approach to mixed-binary hyperparameter optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10711">http://arxiv.org/abs/2308.10711</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marianna de Santis, Jordan Frecon, Francesco Rinaldi, Saverio Salzo, Martin Schmidt</li>
<li>for: 这篇论文主要是为了提高机器学习模型中高维度超参数的优化。</li>
<li>methods: 该论文使用了等价连续双层 reformulation 以处理混合二进制超参数的优化问题。</li>
<li>results: 试验结果表明，该方法可以在 regression 问题中更好地 estimating 群体稀缺结构，并且超过了现有的 relaxation 和 rounding 方法的性能。<details>
<summary>Abstract</summary>
In recent years, bilevel approaches have become very popular to efficiently estimate high-dimensional hyperparameters of machine learning models. However, to date, binary parameters are handled by continuous relaxation and rounding strategies, which could lead to inconsistent solutions. In this context, we tackle the challenging optimization of mixed-binary hyperparameters by resorting to an equivalent continuous bilevel reformulation based on an appropriate penalty term. We propose an algorithmic framework that, under suitable assumptions, is guaranteed to provide mixed-binary solutions. Moreover, the generality of the method allows to safely use existing continuous bilevel solvers within the proposed framework. We evaluate the performance of our approach for a specific machine learning problem, i.e., the estimation of the group-sparsity structure in regression problems. Reported results clearly show that our method outperforms state-of-the-art approaches based on relaxation and rounding
</details>
<details>
<summary>摘要</summary>
近年来，二级方法在高维参数估计机器学习模型中变得非常流行。然而，到目前为止， binary 参数都是通过连续弹性和圆拟约法来处理，这可能会导致不一致的解决方案。在这个上下文中，我们解决了高维混合二级参数的困难优化问题，通过一个适当的罚项来转化为连续二级形式。我们提出了一个框架，以下所述的假设下，能够提供混合二级解决方案。此外，我们的方法总体上允许使用现有的连续二级解决方案。我们对一个具体的机器学习问题，即回归问题中的群集稀缺结构估计，进行了评估。报告的结果表明，我们的方法在比较 state-of-the-art 方法（基于弹性和圆拟约）的基础上具有明显的优势。
</details></li>
</ul>
<hr>
<h2 id="Measuring-the-Effect-of-Causal-Disentanglement-on-the-Adversarial-Robustness-of-Neural-Network-Models"><a href="#Measuring-the-Effect-of-Causal-Disentanglement-on-the-Adversarial-Robustness-of-Neural-Network-Models" class="headerlink" title="Measuring the Effect of Causal Disentanglement on the Adversarial Robustness of Neural Network Models"></a>Measuring the Effect of Causal Disentanglement on the Adversarial Robustness of Neural Network Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10708">http://arxiv.org/abs/2308.10708</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/prebenness/causal_disentanglement_robustness">https://github.com/prebenness/causal_disentanglement_robustness</a></li>
<li>paper_authors: Preben M. Ness, Dusica Marijan, Sunanda Bose</li>
<li>for: 这些纸上的文章是为了证明 causal Neural Network 模型在针对性攻击方面具有高度的 robustness，以及在几种推理任务中具有增强的能力，如少数shot学习和罕见上下文分类。</li>
<li>methods: 这些模型使用 causal Neural Network 模型，并利用 Computer Vision 领域中的内容&#x2F;风格分离指标来衡量不同方面的 causal 分离度。</li>
<li>results: 研究发现，模型的 causal 分离度与针对性攻击的Robustness 之间存在强相关关系（r&#x3D;0.820，p&#x3D;0.001），同时，干扰信号中像素级信息含量与针对性攻击Robustness 存在负相关关系（r&#x3D;-0.597，p&#x3D;0.040）。<details>
<summary>Abstract</summary>
Causal Neural Network models have shown high levels of robustness to adversarial attacks as well as an increased capacity for generalisation tasks such as few-shot learning and rare-context classification compared to traditional Neural Networks. This robustness is argued to stem from the disentanglement of causal and confounder input signals. However, no quantitative study has yet measured the level of disentanglement achieved by these types of causal models or assessed how this relates to their adversarial robustness.   Existing causal disentanglement metrics are not applicable to deterministic models trained on real-world datasets. We, therefore, utilise metrics of content/style disentanglement from the field of Computer Vision to measure different aspects of the causal disentanglement for four state-of-the-art causal Neural Network models. By re-implementing these models with a common ResNet18 architecture we are able to fairly measure their adversarial robustness on three standard image classification benchmarking datasets under seven common white-box attacks. We find a strong association (r=0.820, p=0.001) between the degree to which models decorrelate causal and confounder signals and their adversarial robustness. Additionally, we find a moderate negative association between the pixel-level information content of the confounder signal and adversarial robustness (r=-0.597, p=0.040).
</details>
<details>
<summary>摘要</summary>
causal neural network 模型在对抗攻击和一些几个shot学习和罕见情况分类任务中表现出了高水平的鲁棒性，相比传统神经网络。这种鲁棒性 argued to come from the separation of causal and confounding input signals。然而，没有任何数值研究 measuring the level of disentanglement achieved by these types of causal models or assessing how this relates to their adversarial robustness。  existing causal disentanglement metrics are not applicable to deterministic models trained on real-world datasets。We therefore use metrics of content/style disentanglement from the field of computer vision to measure different aspects of the causal disentanglement for four state-of-the-art causal neural network models。By re-implementing these models with a common ResNet18 architecture, we are able to fairly measure their adversarial robustness on three standard image classification benchmarking datasets under seven common white-box attacks。We find a strong association (r=0.820, p=0.001) between the degree to which models decorrelate causal and confounder signals and their adversarial robustness。In addition, we find a moderate negative association between the pixel-level information content of the confounder signal and adversarial robustness (r=-0.597, p=0.040).
</details></li>
</ul>
<hr>
<h2 id="Sampling-From-Autoencoders’-Latent-Space-via-Quantization-And-Probability-Mass-Function-Concepts"><a href="#Sampling-From-Autoencoders’-Latent-Space-via-Quantization-And-Probability-Mass-Function-Concepts" class="headerlink" title="Sampling From Autoencoders’ Latent Space via Quantization And Probability Mass Function Concepts"></a>Sampling From Autoencoders’ Latent Space via Quantization And Probability Mass Function Concepts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10704">http://arxiv.org/abs/2308.10704</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aymene Mohammed Bouayed, Adrian Iaccovelli, David Naccache</li>
<li>for: 本研究旨在从生成模型基于 autoencoder 的含义空间采样，以便生成真实的图像。</li>
<li>methods: 我们提出了一种基于概率质量函数的新采样算法，并将其与量化处理结合。该算法在输入数据的含义空间中定义了一个邻域，然后从这些定义的邻域中采样含义向量。这种策略确保了采样的含义向量主要居住在高概率区域，从而可以高效地转换为真实的图像。</li>
<li>results: 我们的采样算法在多种模型和数据集上表现出色，比如 MNIST 数据集上，我们的方法与基于 Gaussian mixture models（GMM）采样相比，可以获得 notable 的改善 ($0.89$ 的 FID 值）。此外，当生成图像的类型是人脸和眼睛图像时，我们的方法也显示出了明显的改善（FID 值分别提高 $1.69$ 和 $0.87$）。最后，我们通过 Wasserstein distance 来证明我们的方法在估计含义空间分布上的效果，与 GMM 采样相比。<details>
<summary>Abstract</summary>
In this study, we focus on sampling from the latent space of generative models built upon autoencoders so as the reconstructed samples are lifelike images. To do to, we introduce a novel post-training sampling algorithm rooted in the concept of probability mass functions, coupled with a quantization process. Our proposed algorithm establishes a vicinity around each latent vector from the input data and then proceeds to draw samples from these defined neighborhoods. This strategic approach ensures that the sampled latent vectors predominantly inhabit high-probability regions, which, in turn, can be effectively transformed into authentic real-world images. A noteworthy point of comparison for our sampling algorithm is the sampling technique based on Gaussian mixture models (GMM), owing to its inherent capability to represent clusters. Remarkably, we manage to improve the time complexity from the previous $\mathcal{O}(n\times d \times k \times i)$ associated with GMM sampling to a much more streamlined $\mathcal{O}(n\times d)$, thereby resulting in substantial speedup during runtime. Moreover, our experimental results, gauged through the Fr\'echet inception distance (FID) for image generation, underscore the superior performance of our sampling algorithm across a diverse range of models and datasets. On the MNIST benchmark dataset, our approach outperforms GMM sampling by yielding a noteworthy improvement of up to $0.89$ in FID value. Furthermore, when it comes to generating images of faces and ocular images, our approach showcases substantial enhancements with FID improvements of $1.69$ and $0.87$ respectively, as compared to GMM sampling, as evidenced on the CelebA and MOBIUS datasets. Lastly, we substantiate our methodology's efficacy in estimating latent space distributions in contrast to GMM sampling, particularly through the lens of the Wasserstein distance.
</details>
<details>
<summary>摘要</summary>
在这个研究中，我们关注在基于 autoencoder 的生成模型的 latent space 中采样，以便生成生动的图像。为此，我们提出了一种新的后期采样算法，基于概率质量函数，并且进行量化处理。我们的提议的算法会定义 latent vector 的邻域，然后从这些定义的邻域中采样。这种策略确保了采样 latent vector 主要居住在高概率区域中，从而可以有效地转换为真实的世界图像。与基于 Gaussian mixture models (GMM) 的采样技术相比，我们的采样算法具有更高的时间复杂度，从 $\mathcal{O}(n\times d \times k \times i)$ 降低到 $\mathcal{O}(n\times d)$，从而在运行时间中获得了显著的加速。此外，我们的实验结果，通过 Fréchet inception distance (FID) 来衡量图像生成的性能，表明我们的采样算法在不同的模型和数据集上具有显著的优势。在 MNIST 数据集上，我们的方法与 GMM 采样相比，提高了 FID 值的不同程度，最高可达 $0.89$。此外，当生成面部和眼部图像时，我们的方法还显示了重要的改进，FID 改进值分别为 $1.69$ 和 $0.87$，在 GMM 采样的基础上具有显著的优势。最后，我们验证了我们的方法在估计 latent space 分布方面的有效性，特别是通过 Wasserstein distance 的验证。
</details></li>
</ul>
<hr>
<h2 id="Refashioning-Emotion-Recognition-Modelling-The-Advent-of-Generalised-Large-Models"><a href="#Refashioning-Emotion-Recognition-Modelling-The-Advent-of-Generalised-Large-Models" class="headerlink" title="Refashioning Emotion Recognition Modelling: The Advent of Generalised Large Models"></a>Refashioning Emotion Recognition Modelling: The Advent of Generalised Large Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11578">http://arxiv.org/abs/2308.11578</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zixing Zhang, Liyizhe Peng, Tao Pang, Jing Han, Huan Zhao, Bjorn W. Schuller</li>
<li>for: 这 paper 的目的是 investigate how large language models (LLMs) perform in emotion recognition, and to offer insights and pose potential challenges for enhancing emotion recognition in the new era of advanced and generalised large models.</li>
<li>methods: 这 paper 使用了 diverse aspects, including in-context learning, few-shot learning, accuracy, generalisation, and explanation, to evaluate the performance of LLMs in emotion recognition.</li>
<li>results: 这 paper 的结果表明 that LLMs can significantly boost the performance of emotion recognition models, and can achieve the best results on different benchmarks. However, the paper also poses potential challenges and offers insights for enhancing emotion recognition in the new era of advanced and generalised large models.<details>
<summary>Abstract</summary>
After the inception of emotion recognition or affective computing, it has increasingly become an active research topic due to its broad applications. Over the past couple of decades, emotion recognition models have gradually migrated from statistically shallow models to neural network-based deep models, which can significantly boost the performance of emotion recognition models and consistently achieve the best results on different benchmarks. Therefore, in recent years, deep models have always been considered the first option for emotion recognition. However, the debut of large language models (LLMs), such as ChatGPT, has remarkably astonished the world due to their emerged capabilities of zero/few-shot learning, in-context learning, chain-of-thought, and others that are never shown in previous deep models. In the present paper, we comprehensively investigate how the LLMs perform in emotion recognition in terms of diverse aspects, including in-context learning, few-short learning, accuracy, generalisation, and explanation. Moreover, we offer some insights and pose other potential challenges, hoping to ignite broader discussions about enhancing emotion recognition in the new era of advanced and generalised large models.
</details>
<details>
<summary>摘要</summary>
после 几十年的情感认知或情感计算的出现，这已经成为了活跃的研究话题，因为它的广泛应用。过去几十年，情感认知模型逐渐从统计学上的浅层模型迁移到神经网络基于深度模型，这可以大幅提高情感认知模型的性能，并一直在不同的benchmark上达到最佳结果。因此，在最近几年，深度模型一直被视为情感认知的第一选择。然而，大语言模型（LLMs），如ChatGPT，在全球引发了惊叹，因为它们在前一代深度模型中未经过显示的特性，包括零/几个shot学习、上下文学习、串行思维等。在 presente 文章中，我们全面调查了LLMs在情感认知方面的性能，包括上下文学习、几个shot学习、准确率、泛化和解释。此外，我们还提供了一些启示和提出了其他潜在的挑战，希望能够激发更广泛的讨论，以提高情感认知在新的高级通用大模型时代的发展。
</details></li>
</ul>
<hr>
<h2 id="An-engine-to-simulate-insurance-fraud-network-data"><a href="#An-engine-to-simulate-insurance-fraud-network-data" class="headerlink" title="An engine to simulate insurance fraud network data"></a>An engine to simulate insurance fraud network data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11659">http://arxiv.org/abs/2308.11659</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bavo D. C. Campo, Katrien Antonio<br>for: 这个研究旨在开发一个高效且准确的探索阴谋保险laims（fraudulent insurance claims）的方法。methods: 本研究使用了社交网络中所 involve的 party 的特征 engineering 作为 input 进行学习。results: 这个研究使用了一个 simulation machine 来生成synthetic data，并允许使用者控制数据生成机制，以测试不同的方法和模型。<details>
<summary>Abstract</summary>
Traditionally, the detection of fraudulent insurance claims relies on business rules and expert judgement which makes it a time-consuming and expensive process (\'Oskarsd\'ottir et al., 2022). Consequently, researchers have been examining ways to develop efficient and accurate analytic strategies to flag suspicious claims. Feeding learning methods with features engineered from the social network of parties involved in a claim is a particularly promising strategy (see for example Van Vlasselaer et al. (2016); Tumminello et al. (2023)). When developing a fraud detection model, however, we are confronted with several challenges. The uncommon nature of fraud, for example, creates a high class imbalance which complicates the development of well performing analytic classification models. In addition, only a small number of claims are investigated and get a label, which results in a large corpus of unlabeled data. Yet another challenge is the lack of publicly available data. This hinders not only the development of new methods, but also the validation of existing techniques. We therefore design a simulation machine that is engineered to create synthetic data with a network structure and available covariates similar to the real life insurance fraud data set analyzed in \'Oskarsd\'ottir et al. (2022). Further, the user has control over several data-generating mechanisms. We can specify the total number of policyholders and parties, the desired level of imbalance and the (effect size of the) features in the fraud generating model. As such, the simulation engine enables researchers and practitioners to examine several methodological challenges as well as to test their (development strategy of) insurance fraud detection models in a range of different settings. Moreover, large synthetic data sets can be generated to evaluate the predictive performance of (advanced) machine learning techniques.
</details>
<details>
<summary>摘要</summary>
传统上，探测保险 fraud 的方法依赖于企业规则和专家判断，这使得过程时间consuming 和成本高（'Oskarsd\'ottir et al., 2022）。因此，研究人员在尝试开发高效和准确的分析策略来检测可疑的laim。从社交网络中提取和引擎特征来训练学习方法是一种非常有前途的策略（如 Van Vlasselaer et al. (2016)；Tumminello et al. (2023)）。在开发探测模型时，我们面临了一些挑战。例如，诈骗的不常见性导致分类模型的性能差，而且只有一小部分的laim被调查和标注，导致大量的无标注数据。此外，没有公共可用的数据也限制了新方法的发展和现有技术的验证。为了解决这些问题，我们设计了一个可以生成Synthetic data的 simulate 机器，其中可以控制数据生成机制的一些参数。我们可以指定policyholders和相关方数量，欲要的分类模型性能等级，以及诈骗生成模型中特征的效应大小。因此，这个 simulate 机器可以帮助研究人员和实践人员在不同的设定下测试他们的探测模型，以及解决一些方法学挑战。此外，可以生成大量的Synthetic data，以评估先进机器学习技术的预测性能。
</details></li>
</ul>
<hr>
<h2 id="Cost-Efficient-Online-Decision-Making-A-Combinatorial-Multi-Armed-Bandit-Approach"><a href="#Cost-Efficient-Online-Decision-Making-A-Combinatorial-Multi-Armed-Bandit-Approach" class="headerlink" title="Cost-Efficient Online Decision Making: A Combinatorial Multi-Armed Bandit Approach"></a>Cost-Efficient Online Decision Making: A Combinatorial Multi-Armed Bandit Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10699">http://arxiv.org/abs/2308.10699</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arman Rahbar, Niklas Åkerblom, Morteza Haghir Chehreghani</li>
<li>for: 这篇论文目的是解决在许多实际应用中的在线决策问题，这些决策通常基于对入围数据点的测试序列。</li>
<li>methods: 论文提出了一种基于 combinatorial 多臂投机的新形式化方法，该方法考虑了测试成本。</li>
<li>results: 论文提供了一个新的成本效率的在线决策框架，可以使用 posterior sampling 或 BayesUCB 进行探索。 论文还提供了严格的理论分析和各种实验结果，证明了其在实际问题中的可行性。<details>
<summary>Abstract</summary>
Online decision making plays a crucial role in numerous real-world applications. In many scenarios, the decision is made based on performing a sequence of tests on the incoming data points. However, performing all tests can be expensive and is not always possible. In this paper, we provide a novel formulation of the online decision making problem based on combinatorial multi-armed bandits and take the cost of performing tests into account. Based on this formulation, we provide a new framework for cost-efficient online decision making which can utilize posterior sampling or BayesUCB for exploration. We provide a rigorous theoretical analysis for our framework and present various experimental results that demonstrate its applicability to real-world problems.
</details>
<details>
<summary>摘要</summary>
在许多实际应用中，在线决策扮演着关键的角色。在许多场景中，决策基于对进来数据点的测试进行序列。然而，执行所有测试可能是昂贵的，而且不一定可行。在这篇论文中，我们提供了一种新的在线决策问题的形式ulation，考虑了测试成本。基于这种形式ulation，我们提供了一个新的cost-efficient的在线决策框架，可以利用 posterior sampling 或 BayesUCB 进行探索。我们提供了一个严格的理论分析，并在各种实验中证明了其可应用性。
</details></li>
</ul>
<hr>
<h2 id="Beyond-expectations-Residual-Dynamic-Mode-Decomposition-and-Variance-for-Stochastic-Dynamical-Systems"><a href="#Beyond-expectations-Residual-Dynamic-Mode-Decomposition-and-Variance-for-Stochastic-Dynamical-Systems" class="headerlink" title="Beyond expectations: Residual Dynamic Mode Decomposition and Variance for Stochastic Dynamical Systems"></a>Beyond expectations: Residual Dynamic Mode Decomposition and Variance for Stochastic Dynamical Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10697">http://arxiv.org/abs/2308.10697</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matthew J. Colbrook, Qin Li, Ryan V. Raut, Alex Townsend</li>
<li>for: 这篇论文是关于非线性动力系统的线性化的研究，具体来说是关于科普曼算子的spectral information的研究。</li>
<li>methods: 这篇论文使用了一种名为Dynamic Mode Decomposition（DMD）的投影方法来近似科普曼算子的特征属性。</li>
<li>results: 这篇论文提出了一种包括偏差和方差的科普曼框架，以控制投影错误。此外，paper还介绍了一种名为variance-pseudospectra的概念，用于评估统计相关性。最后，paper还提供了一些有关科普曼算子特征量的收敛结果。<details>
<summary>Abstract</summary>
Koopman operators linearize nonlinear dynamical systems, making their spectral information of crucial interest. Numerous algorithms have been developed to approximate these spectral properties, and Dynamic Mode Decomposition (DMD) stands out as the poster child of projection-based methods. Although the Koopman operator itself is linear, the fact that it acts in an infinite-dimensional space of observables poses various challenges. These include spurious modes, essential spectra, and the verification of Koopman mode decompositions. While recent work has addressed these challenges for deterministic systems, there remains a notable gap in verified DMD methods tailored for stochastic systems, where the Koopman operator measures the expectation of observables. We show that it is necessary to go beyond expectations to address these issues. By incorporating variance into the Koopman framework, we address these challenges. Through an additional DMD-type matrix, we approximate the sum of a squared residual and a variance term, each of which can be approximated individually using batched snapshot data. This allows verified computation of the spectral properties of stochastic Koopman operators, controlling the projection error. We also introduce the concept of variance-pseudospectra to gauge statistical coherency. Finally, we present a suite of convergence results for the spectral quantities of stochastic Koopman operators. Our study concludes with practical applications using both simulated and experimental data. In neural recordings from awake mice, we demonstrate how variance-pseudospectra can reveal physiologically significant information unavailable to standard expectation-based dynamical models.
</details>
<details>
<summary>摘要</summary>
库曼运算符linear化非线性动力系统的spectral信息非常重要。numerous algorithms have been developed to approximate这些spectral properties，and Dynamic Mode Decomposition (DMD) stands out as the poster child of projection-based methods。although the Koopman operator itself is linear，the fact that it acts in an infinite-dimensional space of observables poses various challenges。These include spurious modes，essential spectra，and the verification of Koopman mode decompositions。While recent work has addressed these challenges for deterministic systems，there remains a notable gap in verified DMD methods tailored for stochastic systems，where the Koopman operator measures the expectation of observables。We show that it is necessary to go beyond expectations to address these issues。By incorporating variance into the Koopman framework，we address these challenges。Through an additional DMD-type matrix，we approximate the sum of a squared residual and a variance term，each of which can be approximated individually using batched snapshot data。This allows verified computation of the spectral properties of stochastic Koopman operators，controlling the projection error。We also introduce the concept of variance-pseudospectra to gauge statistical coherency。Finally，we present a suite of convergence results for the spectral quantities of stochastic Koopman operators。Our study concludes with practical applications using both simulated and experimental data。In neural recordings from awake mice，we demonstrate how variance-pseudospectra can reveal physiologically significant information unavailable to standard expectation-based dynamical models。
</details></li>
</ul>
<hr>
<h2 id="An-Improved-Best-of-both-worlds-Algorithm-for-Bandits-with-Delayed-Feedback"><a href="#An-Improved-Best-of-both-worlds-Algorithm-for-Bandits-with-Delayed-Feedback" class="headerlink" title="An Improved Best-of-both-worlds Algorithm for Bandits with Delayed Feedback"></a>An Improved Best-of-both-worlds Algorithm for Bandits with Delayed Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10675">http://arxiv.org/abs/2308.10675</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saeed Masoudian, Julian Zimmert, Yevgeny Seldin</li>
<li>for: 该文章是为了解决带延迟反馈的矩阵问题提出了一种新的算法。</li>
<li>methods: 该算法利用了 counts of outstanding observations（在行动时观察到的量）而不需要估计最大延迟 $d_{\max}$，并提供了更紧张的 regret bound。</li>
<li>results: 该算法可以控制分布漂移，并且可以预测延迟反馈中出现的异常情况。<details>
<summary>Abstract</summary>
We propose a new best-of-both-worlds algorithm for bandits with variably delayed feedback. The algorithm improves on prior work by Masoudian et al. [2022] by eliminating the need in prior knowledge of the maximal delay $d_{\mathrm{max}$ and providing tighter regret bounds in both regimes. The algorithm and its regret bounds are based on counts of outstanding observations (a quantity that is observed at action time) rather than delays or the maximal delay (quantities that are only observed when feedback arrives). One major contribution is a novel control of distribution drift, which is based on biased loss estimators and skipping of observations with excessively large delays. Another major contribution is demonstrating that the complexity of best-of-both-worlds bandits with delayed feedback is characterized by the cumulative count of outstanding observations after skipping of observations with excessively large delays, rather than the delays or the maximal delay.
</details>
<details>
<summary>摘要</summary>
我们提出一个新的best-of-both-worlds算法 для抽筋棒杠问题，这个算法超越先前的 Masoudian et al. （2022）的工作，不需要先知道最大延迟 $d_{\max}$ ，并且在两种情况下提供了更紧密的 regret bound。这个算法和其 regret bound 基于在动作时观察到的尚未完成观察数据（count of outstanding observations）而不是延迟或最大延迟（只有在反馈 arrives 时才能观察到）。我们的一个重要贡献是基于偏好的损失估计器和延迟过大的观察 skip 的控制方法，另一个重要贡献是显示了best-of-both-worlds抽筋棒杠问题的复杂性是由尚未完成观察数据的累总而不是延迟或最大延迟。
</details></li>
</ul>
<hr>
<h2 id="A-Safe-Deep-Reinforcement-Learning-Approach-for-Energy-Efficient-Federated-Learning-in-Wireless-Communication-Networks"><a href="#A-Safe-Deep-Reinforcement-Learning-Approach-for-Energy-Efficient-Federated-Learning-in-Wireless-Communication-Networks" class="headerlink" title="A Safe Deep Reinforcement Learning Approach for Energy Efficient Federated Learning in Wireless Communication Networks"></a>A Safe Deep Reinforcement Learning Approach for Energy Efficient Federated Learning in Wireless Communication Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10664">http://arxiv.org/abs/2308.10664</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikolaos Koursioumpas, Lina Magoula, Nikolaos Petropouleas, Alexandros-Ioannis Thanopoulos, Theodora Panagea, Nancy Alonistioti, M. A. Gutierrez-Estevez, Ramin Khalili</li>
<li>for: 降低艺术智能（AI）驱动无线网络中的环境影响，提高 Privacy Preserving 技术 Federated Learning（FL）的能效性。</li>
<li>methods: 提议在FL процессе中调度设备的计算和通信资源，以最小化总能 consumption，保证模型的性能，同时采用 Soft Actor Critic Deep Reinforcement Learning（DRL）解决方案，增加环境约束，保证安全的RL进程。</li>
<li>results: 对四个参考解决方案进行比较，实现降低总能 consumption的最高减少率达94%，在静态和动态环境中都有显著的改善。<details>
<summary>Abstract</summary>
Progressing towards a new era of Artificial Intelligence (AI) - enabled wireless networks, concerns regarding the environmental impact of AI have been raised both in industry and academia. Federated Learning (FL) has emerged as a key privacy preserving decentralized AI technique. Despite efforts currently being made in FL, its environmental impact is still an open problem. Targeting the minimization of the overall energy consumption of an FL process, we propose the orchestration of computational and communication resources of the involved devices to minimize the total energy required, while guaranteeing a certain performance of the model. To this end, we propose a Soft Actor Critic Deep Reinforcement Learning (DRL) solution, where a penalty function is introduced during training, penalizing the strategies that violate the constraints of the environment, and ensuring a safe RL process. A device level synchronization method, along with a computationally cost effective FL environment are proposed, with the goal of further reducing the energy consumption and communication overhead. Evaluation results show the effectiveness of the proposed scheme compared to four state-of-the-art baseline solutions in both static and dynamic environments, achieving a decrease of up to 94% in the total energy consumption.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Practical-Parallel-Algorithms-for-Non-Monotone-Submodular-Maximization"><a href="#Practical-Parallel-Algorithms-for-Non-Monotone-Submodular-Maximization" class="headerlink" title="Practical Parallel Algorithms for Non-Monotone Submodular Maximization"></a>Practical Parallel Algorithms for Non-Monotone Submodular Maximization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10656">http://arxiv.org/abs/2308.10656</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuang Cui, Kai Han, Jing Tang, He Huang, Xueying Li, Aakas Zhiyuli, Hanxiao Li</li>
<li>for:  This paper is written for the field of artificial intelligence, specifically for submodular maximization in machine learning, computer vision, and natural language processing.</li>
<li>methods:  The paper proposes two algorithms for submodular maximization: one for non-monotone submodular maximization subject to a knapsack constraint, and the other for non-monotone submodular maximization subject to a $k$-system constraint. Both algorithms have provable approximation ratios and sublinear adaptive complexities.</li>
<li>results:  The paper achieves an $(8+\epsilon)$-approximation under $\mathcal{O}(\log n)$ adaptive complexity for non-monotone submodular maximization subject to a knapsack constraint, which is optimal up to a factor of $\mathcal{O}(\log\log n)$. Additionally, the paper proposes the first algorithm with both provable approximation ratio and sublinear adaptive complexity for non-monotone submodular maximization subject to a $k$-system constraint. The two algorithms are also applied to the special case of submodular maximization subject to a cardinality constraint, achieving performance bounds comparable with those of state-of-the-art algorithms.<details>
<summary>Abstract</summary>
Submodular maximization has found extensive applications in various domains within the field of artificial intelligence, including but not limited to machine learning, computer vision, and natural language processing. With the increasing size of datasets in these domains, there is a pressing need to develop efficient and parallelizable algorithms for submodular maximization. One measure of the parallelizability of a submodular maximization algorithm is its adaptive complexity, which indicates the number of sequential rounds where a polynomial number of queries to the objective function can be executed in parallel. In this paper, we study the problem of non-monotone submodular maximization subject to a knapsack constraint, and propose the first combinatorial algorithm achieving an $(8+\epsilon)$-approximation under $\mathcal{O}(\log n)$ adaptive complexity, which is \textit{optimal} up to a factor of $\mathcal{O}(\log\log n)$. Moreover, we also propose the first algorithm with both provable approximation ratio and sublinear adaptive complexity for the problem of non-monotone submodular maximization subject to a $k$-system constraint. As a by-product, we show that our two algorithms can also be applied to the special case of submodular maximization subject to a cardinality constraint, and achieve performance bounds comparable with those of state-of-the-art algorithms. Finally, the effectiveness of our approach is demonstrated by extensive experiments on real-world applications.
</details>
<details>
<summary>摘要</summary>
“对于人工智能中不同领域的应用，如机器学习、计算机视觉和自然语言处理，Submodular maximization 已经获得了广泛的应用。随着这些领域中的数据集的规模增加，开发高效和平行化的Submodular maximization 算法成为了一个紧要的需求。一个Measure of 平行化的Submodular maximization 算法的可行性是其适应复杂度，它表示在执行多个轮次的时候，可以在平行的方式进行多个几何种的询问。在这篇论文中，我们研究了非单调Submodular maximization 问题下的体统统计限制，并提出了首个具有$(8+\epsilon)$-估计的Combinatorial算法，其适应性为 $\mathcal{O}(\log n)$。此外，我们还提出了首个具有证明的近似比率和对应复杂度的Submodular maximization 算法，它可以在$k$-系统限制下进行应用。作为一个副产品，我们显示了我们的两个算法可以在特殊情况下进行Submodular maximization 问题，并达到了现有算法的性能 bound。最后，我们通过实际实验证明了我们的方法的实用性。”
</details></li>
</ul>
<hr>
<h2 id="Deep-Evidential-Learning-for-Bayesian-Quantile-Regression"><a href="#Deep-Evidential-Learning-for-Bayesian-Quantile-Regression" class="headerlink" title="Deep Evidential Learning for Bayesian Quantile Regression"></a>Deep Evidential Learning for Bayesian Quantile Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10650">http://arxiv.org/abs/2308.10650</a></li>
<li>repo_url: None</li>
<li>paper_authors: Frederik Boe Hüttel, Filipe Rodrigues, Francisco Câmara Pereira</li>
<li>for: 该文章提出了一种深度 bayesian 量化回归模型，可以估计连续目标分布的Quantile without Gaussian assumption。</li>
<li>methods: 该方法基于显示学习，可以捕捉 aleatoric 和 epistemic 不确定性，并且通过单个推测过程来实现。</li>
<li>results: 该方法可以实现准确的不确定性估计，并且可以分解 aleatoric 和 epistemic 不确定性，同时具有对 out-of-distribution 样本的Robustness。<details>
<summary>Abstract</summary>
It is desirable to have accurate uncertainty estimation from a single deterministic forward-pass model, as traditional methods for uncertainty quantification are computationally expensive. However, this is difficult because single forward-pass models do not sample weights during inference and often make assumptions about the target distribution, such as assuming it is Gaussian. This can be restrictive in regression tasks, where the mean and standard deviation are inadequate to model the target distribution accurately. This paper proposes a deep Bayesian quantile regression model that can estimate the quantiles of a continuous target distribution without the Gaussian assumption. The proposed method is based on evidential learning, which allows the model to capture aleatoric and epistemic uncertainty with a single deterministic forward-pass model. This makes the method efficient and scalable to large models and datasets. We demonstrate that the proposed method achieves calibrated uncertainties on non-Gaussian distributions, disentanglement of aleatoric and epistemic uncertainty, and robustness to out-of-distribution samples.
</details>
<details>
<summary>摘要</summary>
希望通过单个决定性前向模型获得准确的不确定性估计，但这很难实现，因为单个前向模型在推理过程中不会采样权重，而且常常假设目标分布是高斯分布。这可能是回归任务中的限制，因为均值和标准差无法准确地模型目标分布。本文提出了深度 bayesian 量化回归模型，可以无需假设高斯分布来估计连续目标分布的quantiles。该方法基于证据学习，允许模型捕捉 aleatoric 和 epistemic 不确定性，并且可以通过单个决定性前向模型来实现高效和扩展性。我们示示了该方法在非高斯分布上具有准确的不确定性估计、分解 aleatoric 和 epistemic 不确定性、以及对非标准样本的Robustness。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Learning-Based-Sensor-Optimization-for-Bio-markers"><a href="#Reinforcement-Learning-Based-Sensor-Optimization-for-Bio-markers" class="headerlink" title="Reinforcement Learning Based Sensor Optimization for Bio-markers"></a>Reinforcement Learning Based Sensor Optimization for Bio-markers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10649">http://arxiv.org/abs/2308.10649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sajal Khandelwal, Pawan Kumar, Syed Azeemuddin</li>
<li>for: 本研究旨在提高基于电极设计和脚宽的IDC频率生物感测器的敏感度。</li>
<li>methods: 该研究使用了新的强化学习基于二进制群体潮涌优化（RLBPSO）方法来优化感测器的设计参数，并与现有的ACO和其他状态前方法进行比较。</li>
<li>results: 研究发现，RLBPSO方法可以在不同频率范围内提高感测器的敏感度，并且在不同的电极设计和脚宽下显示出优异性。<details>
<summary>Abstract</summary>
Radio frequency (RF) biosensors, in particular those based on inter-digitated capacitors (IDCs), are pivotal in areas like biomedical diagnosis, remote sensing, and wireless communication. Despite their advantages of low cost and easy fabrication, their sensitivity can be hindered by design imperfections, environmental factors, and circuit noise. This paper investigates enhancing the sensitivity of IDC-based RF sensors using novel reinforcement learning based Binary Particle Swarm Optimization (RLBPSO), and it is compared to Ant Colony Optimization (ACO), and other state-of-the-art methods. By focusing on optimizing design parameters like electrode design and finger width, the proposed study found notable improvements in sensor sensitivity. The proposed RLBPSO method shows best optimized design for various frequency ranges when compared to current state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
Radio frequency (RF) 感测器，尤其是基于交叠式电极（IDC）的感测器，在生物医学诊断、远程探测和无线通信等领域具有重要的应用价值。尽管它们具有低成本和易于制造的优点，但是设计瑕疵、环境因素和电路噪声可能会削弱它们的敏感度。本文通过使用新型的强化学习基于二进制蜂群优化（RLBPSO）方法来提高 IDC-based RF 感测器的敏感度，并与现有的 Ant Colony Optimization（ACO）方法和其他当前最佳方法进行比较。通过关注优化设计参数，如电极设计和脚宽，该研究发现了明显提高感测器敏感度的改进。RLBPSO 方法在不同频率范围内具有最佳的设计优化效果，比较现有的方法更为出色。
</details></li>
</ul>
<hr>
<h2 id="Faster-Training-of-Neural-ODEs-Using-Gaus-Legendre-Quadrature"><a href="#Faster-Training-of-Neural-ODEs-Using-Gaus-Legendre-Quadrature" class="headerlink" title="Faster Training of Neural ODEs Using Gauß-Legendre Quadrature"></a>Faster Training of Neural ODEs Using Gauß-Legendre Quadrature</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10644">http://arxiv.org/abs/2308.10644</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/a-norcliffe/torch_gq_adjoint">https://github.com/a-norcliffe/torch_gq_adjoint</a></li>
<li>paper_authors: Alexander Norcliffe, Marc Peter Deisenroth</li>
<li>for: 加速神经ODE的训练，提高生成和时间序列模型的性能。</li>
<li>methods: 使用Gau{\ss}-Legendre quadrature来更快地解决积分，而不需要精确地解决ODE。</li>
<li>results: 提高神经ODE的训练速度，特别是 для大型模型。还提供了一种新的SDE训练方法。<details>
<summary>Abstract</summary>
Neural ODEs demonstrate strong performance in generative and time-series modelling. However, training them via the adjoint method is slow compared to discrete models due to the requirement of numerically solving ODEs. To speed neural ODEs up, a common approach is to regularise the solutions. However, this approach may affect the expressivity of the model; when the trajectory itself matters, this is particularly important. In this paper, we propose an alternative way to speed up the training of neural ODEs. The key idea is to speed up the adjoint method by using Gau{\ss}-Legendre quadrature to solve integrals faster than ODE-based methods while remaining memory efficient. We also extend the idea to training SDEs using the Wong-Zakai theorem, by training a corresponding ODE and transferring the parameters. Our approach leads to faster training of neural ODEs, especially for large models. It also presents a new way to train SDE-based models.
</details>
<details>
<summary>摘要</summary>
neural ODEs 在生成和时间序列模型中表现出色，但通过逆变法训练它们比粒子模型慢，这是因为需要数字化解 ODEs。为了快速 neural ODEs，常见的方法是减少解。然而，这种方法可能会affect the model's expressiveness; 当轨迹本身重要时，这非常重要。在这篇论文中，我们提出了一种将 neural ODEs 快速训练的 alternativapproach。关键思想是通过 Gau{\ss}-Legendre  quadrature 更快地解决积分，而不是使用 ODE-based 方法，同时保持内存效率。我们还扩展了这个想法，将其应用于 SDEs 的训练，使用 Wong-Zakai 定理，通过训练相应的 ODE 并转移参数。我们的方法使得 neural ODEs 的训练变得更快，特别是大型模型。此外，它还提供了一种新的 SDE-based 模型训练方法。
</details></li>
</ul>
<hr>
<h2 id="SCULPT-Shape-Conditioned-Unpaired-Learning-of-Pose-dependent-Clothed-and-Textured-Human-Meshes"><a href="#SCULPT-Shape-Conditioned-Unpaired-Learning-of-Pose-dependent-Clothed-and-Textured-Human-Meshes" class="headerlink" title="SCULPT: Shape-Conditioned Unpaired Learning of Pose-dependent Clothed and Textured Human Meshes"></a>SCULPT: Shape-Conditioned Unpaired Learning of Pose-dependent Clothed and Textured Human Meshes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10638">http://arxiv.org/abs/2308.10638</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soubhik Sanyal, Partha Ghosh, Jinlong Yang, Michael J. Black, Justus Thies, Timo Bolkart</li>
<li>for: 这个论文是为了研究如何生成披衣人体3D模型而写的。</li>
<li>methods: 这个论文使用了一种深度神经网络来表示人体geometry和外观分布。它们使用了3D扫描数据和2D图像数据来训练这个神经网络，并使用了一种无关的学习过程来学习pose-dependent的披衣人体模型。</li>
<li>results: 这个论文通过对SCULPT数据集进行验证来证明了其效果。它们比较了自己的方法与现有的3D生成模型，并发现自己的方法可以更好地生成披衣人体3D模型。<details>
<summary>Abstract</summary>
We present SCULPT, a novel 3D generative model for clothed and textured 3D meshes of humans. Specifically, we devise a deep neural network that learns to represent the geometry and appearance distribution of clothed human bodies. Training such a model is challenging, as datasets of textured 3D meshes for humans are limited in size and accessibility. Our key observation is that there exist medium-sized 3D scan datasets like CAPE, as well as large-scale 2D image datasets of clothed humans and multiple appearances can be mapped to a single geometry. To effectively learn from the two data modalities, we propose an unpaired learning procedure for pose-dependent clothed and textured human meshes. Specifically, we learn a pose-dependent geometry space from 3D scan data. We represent this as per vertex displacements w.r.t. the SMPL model. Next, we train a geometry conditioned texture generator in an unsupervised way using the 2D image data. We use intermediate activations of the learned geometry model to condition our texture generator. To alleviate entanglement between pose and clothing type, and pose and clothing appearance, we condition both the texture and geometry generators with attribute labels such as clothing types for the geometry, and clothing colors for the texture generator. We automatically generated these conditioning labels for the 2D images based on the visual question answering model BLIP and CLIP. We validate our method on the SCULPT dataset, and compare to state-of-the-art 3D generative models for clothed human bodies. We will release the codebase for research purposes.
</details>
<details>
<summary>摘要</summary>
我们介绍了SCULPT，一种新的3D生成模型，用于 clothed和textured 3D meshes of humans。我们设计了一个深度神经网络，用于表示人体的几何和外观分布。训练这种模型具有挑战性，因为人类 clothed 3D mesh 数据集的大小和可访问性有限。我们的关键观察是，存在中等大小的 3D 扫描数据集，如 CAPE，以及大规模的2D图像数据集，包括衣物的多种样式。为了有效地从两种数据模式学习，我们提议一种不同于对应的学习过程。 Specifically，我们从 3D 扫描数据集中学习一个 pose-dependent 几何空间。我们表示这为每个顶点的插值 relative to the SMPL 模型。然后，我们在无监督的情况下使用 2D 图像数据集来训练一个几何受控的Texture生成器。我们使用 learned geometry 模型的中间响应来condition our texture generator。为了消除姿势和服装类型之间的紧张关系，以及姿势和服装外观之间的紧张关系，我们将 conditioning 标签添加到 texture 和 geometry 生成器中，这些标签基于 visual question answering 模型 BLIP 和 CLIP 自动生成的 attribute labels。我们验证了我们的方法在 SCULPT 数据集上，并与现有的3D生成模型进行比较。我们将发布代码库用于研究用途。
</details></li>
</ul>
<hr>
<h2 id="Foundation-Model-oriented-Robustness-Robust-Image-Model-Evaluation-with-Pretrained-Models"><a href="#Foundation-Model-oriented-Robustness-Robust-Image-Model-Evaluation-with-Pretrained-Models" class="headerlink" title="Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models"></a>Foundation Model-oriented Robustness: Robust Image Model Evaluation with Pretrained Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10632">http://arxiv.org/abs/2308.10632</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peiyan Zhang, Haoyang Liu, Chaozhuo Li, Xing Xie, Sunghun Kim, Haohan Wang</li>
<li>for: 这 paper 的目的是提出一种新的Robustness measurement，用于评估图像分类模型在真实世界中的性能。</li>
<li>methods: 这 paper 使用了一种基于 surrogate oracle (i.e., foundation model) 的评估方法，并设计了一种可以超越 fixes benchmarks 的评估方法。</li>
<li>results: 这 paper 通过使用新生成的图像数据，提供了一种新的评估方法，具有不受 fix benchmarks 或受限的杂乱影响的优势。 新方法可以评估模型在真实世界中的Robustness性能，尽管落后于人工智能用户 (i.e., oracle)。<details>
<summary>Abstract</summary>
Machine learning has demonstrated remarkable performance over finite datasets, yet whether the scores over the fixed benchmarks can sufficiently indicate the model's performance in the real world is still in discussion. In reality, an ideal robust model will probably behave similarly to the oracle (e.g., the human users), thus a good evaluation protocol is probably to evaluate the models' behaviors in comparison to the oracle. In this paper, we introduce a new robustness measurement that directly measures the image classification model's performance compared with a surrogate oracle (i.e., a foundation model). Besides, we design a simple method that can accomplish the evaluation beyond the scope of the benchmarks. Our method extends the image datasets with new samples that are sufficiently perturbed to be distinct from the ones in the original sets, but are still bounded within the same image-label structure the original test image represents, constrained by a foundation model pretrained with a large amount of samples. As a result, our new method will offer us a new way to evaluate the models' robustness performance, free of limitations of fixed benchmarks or constrained perturbations, although scoped by the power of the oracle. In addition to the evaluation results, we also leverage our generated data to understand the behaviors of the model and our new evaluation strategies.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Homogenization-Approach-for-Gradient-Dominated-Stochastic-Optimization"><a href="#A-Homogenization-Approach-for-Gradient-Dominated-Stochastic-Optimization" class="headerlink" title="A Homogenization Approach for Gradient-Dominated Stochastic Optimization"></a>A Homogenization Approach for Gradient-Dominated Stochastic Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10630">http://arxiv.org/abs/2308.10630</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiyuan Tan, Chenyu Xue, Chuwen Zhang, Qi Deng, Dongdong Ge, Yinyu Ye</li>
<li>for:  Gradient-dominated optimization with $\alpha \in [1, 2]$</li>
<li>methods:  Stochastic homogeneous second-order descent method (SHSODM) with homogenization approach</li>
<li>results:  Achieves a sample complexity of $O(\epsilon^{-7&#x2F;(2 \alpha) +1})$ for $\alpha \in [1, 3&#x2F;2)$ and $\tilde{O}(\epsilon^{-2&#x2F;\alpha})$ for $\alpha \in [3&#x2F;2, 2]$, with an improved sample complexity of $O( \epsilon ^{-( 7-3\alpha ) &#x2F;( 2\alpha )})$ for $\alpha \in [1,3&#x2F;2)$.<details>
<summary>Abstract</summary>
Gradient dominance property is a condition weaker than strong convexity, yet it sufficiently ensures global convergence for first-order methods even in non-convex optimization. This property finds application in various machine learning domains, including matrix decomposition, linear neural networks, and policy-based reinforcement learning (RL). In this paper, we study the stochastic homogeneous second-order descent method (SHSODM) for gradient-dominated optimization with $\alpha \in [1, 2]$ based on a recently proposed homogenization approach. Theoretically, we show that SHSODM achieves a sample complexity of $O(\epsilon^{-7/(2 \alpha) +1})$ for $\alpha \in [1, 3/2)$ and $\tilde{O}(\epsilon^{-2/\alpha})$ for $\alpha \in [3/2, 2]$. We further provide a SHSODM with a variance reduction technique enjoying an improved sample complexity of $O( \epsilon ^{-( 7-3\alpha ) /( 2\alpha )})$ for $\alpha \in [1,3/2)$. Our results match the state-of-the-art sample complexity bounds for stochastic gradient-dominated optimization without \emph{cubic regularization}. Since the homogenization approach only relies on solving extremal eigenvector problems instead of Newton-type systems, our methods gain the advantage of cheaper iterations and robustness in ill-conditioned problems. Numerical experiments on several RL tasks demonstrate the efficiency of SHSODM compared to other off-the-shelf methods.
</details>
<details>
<summary>摘要</summary>
Gradient dominance 性质是一种弱于强制的 convexity 的条件，但它足够保证全局收敛性 для第一阶方法，包括非对称优化。这种性质在机器学习领域中找到了广泛的应用，例如矩阵分解、线性神经网络和政策基于的强化学习（RL）。在这篇论文中，我们研究了随机同质二阶减少法（SHSODM）在梯度控制的优化中的性能。理论上，我们证明了 SHSODM 的样本复杂度为 $O(\epsilon^{-7/(2\alpha)+1})$ for $\alpha \in [1, 3/2)$ 和 $\tilde{O}(\epsilon^{-2/\alpha})$ for $\alpha \in [3/2, 2]$。我们还提供了一种带有减少噪声技术的 SHSODM，其样本复杂度为 $O( \epsilon ^{-(7-3\alpha )/(2\alpha)})$ for $\alpha \in [1,3/2)$。我们的结果与无 кубиック regularization 的梯度-控制优化的状态艺术sample complexity bound匹配。由于homogenization approach 仅仅需要解决极值 eigenvector 问题而不是 Newton-type 系统，我们的方法在糟糕条件下具有更低的迭代次数和更加稳定的性能。 numerically experiments on several RL tasks demonstrate the efficiency of SHSODM compared to other off-the-shelf methods.
</details></li>
</ul>
<hr>
<h2 id="GaitPT-Skeletons-Are-All-You-Need-For-Gait-Recognition"><a href="#GaitPT-Skeletons-Are-All-You-Need-For-Gait-Recognition" class="headerlink" title="GaitPT: Skeletons Are All You Need For Gait Recognition"></a>GaitPT: Skeletons Are All You Need For Gait Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10623">http://arxiv.org/abs/2308.10623</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andy Catruna, Adrian Cosma, Emilian Radoi</li>
<li>for:  automatic person identification at a distance</li>
<li>methods:  pose estimation skeletons, hierarchical transformer architecture</li>
<li>results:  state-of-the-art performance, surpassing other works by a margin of 6%, outperforming both skeleton-based and appearance-based approaches<details>
<summary>Abstract</summary>
The analysis of patterns of walking is an important area of research that has numerous applications in security, healthcare, sports and human-computer interaction. Lately, walking patterns have been regarded as a unique fingerprinting method for automatic person identification at a distance. In this work, we propose a novel gait recognition architecture called Gait Pyramid Transformer (GaitPT) that leverages pose estimation skeletons to capture unique walking patterns, without relying on appearance information. GaitPT adopts a hierarchical transformer architecture that effectively extracts both spatial and temporal features of movement in an anatomically consistent manner, guided by the structure of the human skeleton. Our results show that GaitPT achieves state-of-the-art performance compared to other skeleton-based gait recognition works, in both controlled and in-the-wild scenarios. GaitPT obtains 82.6% average accuracy on CASIA-B, surpassing other works by a margin of 6%. Moreover, it obtains 52.16% Rank-1 accuracy on GREW, outperforming both skeleton-based and appearance-based approaches.
</details>
<details>
<summary>摘要</summary>
研究人们的行走模式是一个重要的领域，它有很多应用于安全、医疗、体育和人机交互等领域。最近，行走模式被视为一种唯一的指纹方法 для自动识别人员，不需要依赖于外观信息。在这项工作中，我们提出了一种新的步态识别架构，即步态 pyramid transformer（GaitPT），它利用 pose estimation skeleton 来捕捉独特的行走模式，不需要依赖于外观信息。GaitPT 采用一种层次 transformer 架构，有效地提取行走运动中的空间和时间特征，以遵循人体骨架的结构。我们的结果显示，GaitPT 在 CASIA-B 上取得了82.6% 的平均准确率，比其他skeleton-based gait recognition 工作高出6%。此外，它在 GREW 上取得了52.16% 的排名第一准确率，超过了skeleton-based和 appearance-based方法。
</details></li>
</ul>
<hr>
<h2 id="Weighting-by-Tying-A-New-Approach-to-Weighted-Rank-Correlation"><a href="#Weighting-by-Tying-A-New-Approach-to-Weighted-Rank-Correlation" class="headerlink" title="Weighting by Tying: A New Approach to Weighted Rank Correlation"></a>Weighting by Tying: A New Approach to Weighted Rank Correlation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10622">http://arxiv.org/abs/2308.10622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sascha Henzgen, Eyke Hüllermeier</li>
<li>for: 这篇论文旨在提出一种基于杂分函数的权重排名相关度指标，用于捕捉两个排序序列之间的协调度。</li>
<li>methods: 该论文基于杂分函数来定义一种权重排名相关度指标，其中每个排名位置具有不同的权重。</li>
<li>results: 该论文提出了一种基于杂分函数的权重排名相关度指标，其具有坚实的形式质量和灵活的权重分配方式。<details>
<summary>Abstract</summary>
Measures of rank correlation are commonly used in statistics to capture the degree of concordance between two orderings of the same set of items. Standard measures like Kendall's tau and Spearman's rho coefficient put equal emphasis on each position of a ranking. Yet, motivated by applications in which some of the positions (typically those on the top) are more important than others, a few weighted variants of these measures have been proposed. Most of these generalizations fail to meet desirable formal properties, however. Besides, they are often quite inflexible in the sense of committing to a fixed weighing scheme. In this paper, we propose a weighted rank correlation measure on the basis of fuzzy order relations. Our measure, called scaled gamma, is related to Goodman and Kruskal's gamma rank correlation. It is parametrized by a fuzzy equivalence relation on the rank positions, which in turn is specified conveniently by a so-called scaling function. This approach combines soundness with flexibility: it has a sound formal foundation and allows for weighing rank positions in a flexible way.
</details>
<details>
<summary>摘要</summary>
通用的排名相关度度量在统计学中广泛应用，用于捕捉两个对象集中元素的排名之间的协调程度。标准度量如肯德尔的tau和斯帕曼的rho系数都强调每个排名位置的等重要性。然而，基于应用中一些排名位置（通常是排名顺序的前几位）的重要性更高的情况，一些加权变体已经被提出。然而，大多数这些扩展都不具备愉悦的正式性质，而且通常具有固定的加权方案。在本文中，我们提出一种基于杂化顺序关系的加权排名相关度度量，称为尺度化γ。它与柯德曼和库斯卡尔的γ排名相关度度量相关。它由杂化rank位置之间的等化关系参数化，该等化关系由一个称为涨函数的扩展函数来定义。这种方法结合了准确性与灵活性：它具有准确的正式基础，并允许在灵活的加权方案下进行排名相关度度量的计算。
</details></li>
</ul>
<hr>
<h2 id="centroIDA-Cross-Domain-Class-Discrepancy-Minimization-Based-on-Accumulative-Class-Centroids-for-Imbalanced-Domain-Adaptation"><a href="#centroIDA-Cross-Domain-Class-Discrepancy-Minimization-Based-on-Accumulative-Class-Centroids-for-Imbalanced-Domain-Adaptation" class="headerlink" title="centroIDA: Cross-Domain Class Discrepancy Minimization Based on Accumulative Class-Centroids for Imbalanced Domain Adaptation"></a>centroIDA: Cross-Domain Class Discrepancy Minimization Based on Accumulative Class-Centroids for Imbalanced Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10619">http://arxiv.org/abs/2308.10619</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaona Sun, Zhenyu Wu, Yichen Liu, Saier Hu, Zhiqiang Zhan, Yang Ji</li>
<li>for:  addresses the imbalanced domain adaptation (IDA) problem, which involves both covariate and long-tailed label shifts across domains.</li>
<li>methods:  proposes a cross-domain class discrepancy minimization method based on accumulative class-centroids (centroIDA), which includes class-based re-sampling, accumulative class-centroids alignment, and class-wise feature alignment.</li>
<li>results:  outperforms other state-of-the-art (SOTA) methods on the IDA problem, especially when the degree of label shift increases.Here is the Chinese translation of the three key information points:</li>
<li>for:  addresses the 非平衡领域适应 (IDA) 问题，这个问题中covariate和长尾标签差异都存在于领域之间。</li>
<li>methods: 提出了一种跨领域类别差异最小化方法 (centroIDA)，这个方法包括类别基于的重抽样方法、类别集中心对领域之间的平衡，以及类别对特征表示的优化。</li>
<li>results: 与其他现有的state-of-the-art (SOTA) 方法相比，它在IDA问题上表现出色，特别是随着标签差异的增加而表现更好。<details>
<summary>Abstract</summary>
Unsupervised Domain Adaptation (UDA) approaches address the covariate shift problem by minimizing the distribution discrepancy between the source and target domains, assuming that the label distribution is invariant across domains. However, in the imbalanced domain adaptation (IDA) scenario, covariate and long-tailed label shifts both exist across domains. To tackle the IDA problem, some current research focus on minimizing the distribution discrepancies of each corresponding class between source and target domains. Such methods rely much on the reliable pseudo labels' selection and the feature distributions estimation for target domain, and the minority classes with limited numbers makes the estimations more uncertainty, which influences the model's performance. In this paper, we propose a cross-domain class discrepancy minimization method based on accumulative class-centroids for IDA (centroIDA). Firstly, class-based re-sampling strategy is used to obtain an unbiased classifier on source domain. Secondly, the accumulative class-centroids alignment loss is proposed for iterative class-centroids alignment across domains. Finally, class-wise feature alignment loss is used to optimize the feature representation for a robust classification boundary. A series of experiments have proved that our method outperforms other SOTA methods on IDA problem, especially with the increasing degree of label shift.
</details>
<details>
<summary>摘要</summary>
Unsupervised domain adaptation (UDA)方法解决了covariate shift问题，即源频率和目标频率之间的分布差异，假设标签分布在各个频率上是一致的。然而，在不平衡频率适应（IDA）场景中，covariate和长尾标签都存在在不同频率上的差异。为了解决IDA问题，一些当前的研究集中着精力地针对每个对应的类之间的分布差异进行最小化。这些方法具有可靠的pseudo标签选择和目标频率的特征分布估计，以及少数类的数量增加，这会使估计更加不确定，从而影响模型的性能。在本文中，我们提出了一种基于积累类中心的IDA方法，称为centroIDA。首先，我们使用类型基于的重抽样策略来在源频率上获得一个不偏的类ifier。然后，我们提出了积累类中心Alignment损失，用于在各个频率上进行类中心的iterative aligning。最后，我们使用类别特征对齐损失来优化特征表示，以确定一个可靠的分类边界。一系列实验证明了我们的方法在IDA问题上表现出了Superiority，特别是随着标签偏移度的增加。
</details></li>
</ul>
<hr>
<h2 id="ST-RAP-A-Spatio-Temporal-Framework-for-Real-Estate-Appraisal"><a href="#ST-RAP-A-Spatio-Temporal-Framework-for-Real-Estate-Appraisal" class="headerlink" title="ST-RAP: A Spatio-Temporal Framework for Real Estate Appraisal"></a>ST-RAP: A Spatio-Temporal Framework for Real Estate Appraisal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10609">http://arxiv.org/abs/2308.10609</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dojeon-ai/strap">https://github.com/dojeon-ai/strap</a></li>
<li>paper_authors: Hojoon Lee, Hawon Jeong, Byungkun Lee, Kyungyup Lee, Jaegul Choo</li>
<li>for: 这个论文是为了提出一种基于空间和时间的Real estate APpraisal框架，帮助更好地评估不同地点的房地产价值。</li>
<li>methods: 该框架使用层次架构和异质图内存网络，同时兼容时间动态和空间关系，从而更好地捕捉房地产价值的变化趋势。</li>
<li>results: 经过对大规模房地产数据集进行广泛的实验，ST-RAP方法比前一些方法更高效，表明了在房地产评估中同时考虑空间和时间方面的integration具有显著的优势。<details>
<summary>Abstract</summary>
In this paper, we introduce ST-RAP, a novel Spatio-Temporal framework for Real estate APpraisal. ST-RAP employs a hierarchical architecture with a heterogeneous graph neural network to encapsulate temporal dynamics and spatial relationships simultaneously. Through comprehensive experiments on a large-scale real estate dataset, ST-RAP outperforms previous methods, demonstrating the significant benefits of integrating spatial and temporal aspects in real estate appraisal. Our code and dataset are available at https://github.com/dojeon-ai/STRAP.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了ST-RAP，一种新的空间-时间框架 для房地产评估。ST-RAP使用层次架构和异质图 neural network来同时捕捉时间动态和空间关系。经过对大规模房地产数据集进行了广泛的实验，ST-RAP比前一些方法高效，这说明了在房地产评估中同时考虑空间和时间方面的优势。我们的代码和数据集可以在https://github.com/dojeon-ai/STRAP中下载。
</details></li>
</ul>
<hr>
<h2 id="FocalDreamer-Text-driven-3D-Editing-via-Focal-fusion-Assembly"><a href="#FocalDreamer-Text-driven-3D-Editing-via-Focal-fusion-Assembly" class="headerlink" title="FocalDreamer: Text-driven 3D Editing via Focal-fusion Assembly"></a>FocalDreamer: Text-driven 3D Editing via Focal-fusion Assembly</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10608">http://arxiv.org/abs/2308.10608</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhan Li, Yishun Dou, Yue Shi, Yu Lei, Xuanhong Chen, Yi Zhang, Peng Zhou, Bingbing Ni</li>
<li>for: 这篇论文目的是提出一种基于文本指示的3D编辑框架，以便在 désirable 区域内进行精细编辑。</li>
<li>methods: 该框架使用基本形状和可编辑部分的结合，以及geometry union和双路渲染技术，将独立的3D部件组合成完整的物体，并且支持方便的实例重用和部件控制。</li>
<li>results: 对比其他方法，福калreamer可以提供更高的精细编辑能力，并且可以生成高质量的Geometry和PBR Textures，可以与广泛使用的图形引擎相容。<details>
<summary>Abstract</summary>
While text-3D editing has made significant strides in leveraging score distillation sampling, emerging approaches still fall short in delivering separable, precise and consistent outcomes that are vital to content creation. In response, we introduce FocalDreamer, a framework that merges base shape with editable parts according to text prompts for fine-grained editing within desired regions. Specifically, equipped with geometry union and dual-path rendering, FocalDreamer assembles independent 3D parts into a complete object, tailored for convenient instance reuse and part-wise control. We propose geometric focal loss and style consistency regularization, which encourage focal fusion and congruent overall appearance. Furthermore, FocalDreamer generates high-fidelity geometry and PBR textures which are compatible with widely-used graphics engines. Extensive experiments have highlighted the superior editing capabilities of FocalDreamer in both quantitative and qualitative evaluations.
</details>
<details>
<summary>摘要</summary>
“文本三维编辑已经做出了 significativ strides，但现有approaches仍然无法提供可分离、精度和一致的结果，这些结果对内容创建是非常重要。为此，我们介绍了 FocalDreamer 框架，它将基本形状与可编辑部分结合在一起，根据文本提示进行细化编辑，并在desired region中进行精度编辑。具有geometry union和双路渲染功能，FocalDreamer可以独立地组装3D部件，以便方便的实例重用和部件控制。我们还提出了geometry focal loss和样式一致规则，以促进集中融合和一致的整体外观。此外，FocalDreamer可以生成高质量的geometry和PBR Texture，与广泛使用的图形引擎相容。我们的实验表明，FocalDreamer在量化和质量上都具有出色的编辑能力。”
</details></li>
</ul>
<hr>
<h2 id="Analyzing-Complex-Systems-with-Cascades-Using-Continuous-Time-Bayesian-Networks"><a href="#Analyzing-Complex-Systems-with-Cascades-Using-Continuous-Time-Bayesian-Networks" class="headerlink" title="Analyzing Complex Systems with Cascades Using Continuous-Time Bayesian Networks"></a>Analyzing Complex Systems with Cascades Using Continuous-Time Bayesian Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10606">http://arxiv.org/abs/2308.10606</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alessandro Bregoli, Karin Rathsman, Marco Scutari, Fabio Stella, Søren Wengel Mogensen</li>
<li>for: 本研究旨在分析复杂系统中事件的冲击行为，以便更好地理解系统中哪些状态会触发冲击。</li>
<li>methods: 本研究使用连续时间感知网络（CTBN）模型来分析冲击行为，并使用新的知识提取方法来提取有用信息。</li>
<li>results: 研究发现，使用CTBN模型可以快速和有效地描述事件在系统中传播的方式，并可以标识可能导致冲击行为的系统状态。<details>
<summary>Abstract</summary>
Interacting systems of events may exhibit cascading behavior where events tend to be temporally clustered. While the cascades themselves may be obvious from the data, it is important to understand which states of the system trigger them. For this purpose, we propose a modeling framework based on continuous-time Bayesian networks (CTBNs) to analyze cascading behavior in complex systems. This framework allows us to describe how events propagate through the system and to identify likely sentry states, that is, system states that may lead to imminent cascading behavior. Moreover, CTBNs have a simple graphical representation and provide interpretable outputs, both of which are important when communicating with domain experts. We also develop new methods for knowledge extraction from CTBNs and we apply the proposed methodology to a data set of alarms in a large industrial system.
</details>
<details>
<summary>摘要</summary>
互动系统的事件可能会表现出堆叠行为，其中事件往往在时间上叠加。虽然堆叠自身可能从数据上直观，但是要理解触发它们的系统状态很重要。为了实现这一目标，我们提出了基于连续时间感知网络（CTBN）的模型化框架，用于分析复杂系统中的堆叠行为。这种框架允许我们描述事件在系统中传播的方式，并提取可能导致堆叠行为的系统状态。此外，CTBN具有简单的图形表示和可解释的输出，这两点都是与领域专家通信时非常重要。我们还开发了新的知识提取方法，并对一个大型工业系统的数据集应用了该方法。
</details></li>
</ul>
<hr>
<h2 id="BackTrack-Robust-template-update-via-Backward-Tracking-of-candidate-template"><a href="#BackTrack-Robust-template-update-via-Backward-Tracking-of-candidate-template" class="headerlink" title="BackTrack: Robust template update via Backward Tracking of candidate template"></a>BackTrack: Robust template update via Backward Tracking of candidate template</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10604">http://arxiv.org/abs/2308.10604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongwook Lee, Wonjun Choi, Seohyung Lee, ByungIn Yoo, Eunho Yang, Seongju Hwang</li>
<li>for: 提高视觉对象跟踪性能，增强对象追踪稳定性</li>
<li>methods: 使用返回跟踪方法，根据追踪前几帧的图像快照，计算目标对象在屏幕上的变化</li>
<li>results: 与已有跟踪方法相比，提供更高的跟踪精度和稳定性，在多种跟踪 benchmark 上达到了最高性能<details>
<summary>Abstract</summary>
Variations of target appearance such as deformations, illumination variance, occlusion, etc., are the major challenges of visual object tracking that negatively impact the performance of a tracker. An effective method to tackle these challenges is template update, which updates the template to reflect the change of appearance in the target object during tracking. However, with template updates, inadequate quality of new templates or inappropriate timing of updates may induce a model drift problem, which severely degrades the tracking performance. Here, we propose BackTrack, a robust and reliable method to quantify the confidence of the candidate template by backward tracking it on the past frames. Based on the confidence score of candidates from BackTrack, we can update the template with a reliable candidate at the right time while rejecting unreliable candidates. BackTrack is a generic template update scheme and is applicable to any template-based trackers. Extensive experiments on various tracking benchmarks verify the effectiveness of BackTrack over existing template update algorithms, as it achieves SOTA performance on various tracking benchmarks.
</details>
<details>
<summary>摘要</summary>
目标物体的变化，如形态变化、照明变化、遮挡等，是视觉对象跟踪中主要的挑战，它们会对跟踪性能产生负面影响。一种有效的方法是模板更新，该方法在跟踪过程中更新模板，以反映目标物体的形态变化。然而，在模板更新中，新模板质量不够或更新时间不合适可能导致模型漂移问题，这会严重降低跟踪性能。在这种情况下，我们提出了BackTrack方法，它可以评估候选模板的可靠性，并在过去帧中反向跟踪它们。基于候选模板的可靠性分数，我们可以在合适的时间更新模板，并抛弃不可靠的候选模板。BackTrack是一种通用的模板更新方案，适用于任何模板基的跟踪器。广泛的实验表明，BackTrack方法在各种跟踪标准准则上达到了最佳性能。
</details></li>
</ul>
<hr>
<h2 id="Improving-the-Transferability-of-Adversarial-Examples-with-Arbitrary-Style-Transfer"><a href="#Improving-the-Transferability-of-Adversarial-Examples-with-Arbitrary-Style-Transfer" class="headerlink" title="Improving the Transferability of Adversarial Examples with Arbitrary Style Transfer"></a>Improving the Transferability of Adversarial Examples with Arbitrary Style Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10601">http://arxiv.org/abs/2308.10601</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhijin-ge/stm">https://github.com/zhijin-ge/stm</a></li>
<li>paper_authors: Zhijin Ge, Fanhua Shang, Hongying Liu, Yuanyuan Liu, Liang Wan, Wei Feng, Xiaosen Wang</li>
<li>for: 针对深度神经网络受到人类不可见的攻击，提高黑盒Setting中的攻击效果。</li>
<li>methods: 使用域映射网络进行预处理，并在不同域上进行数据增强，以提高攻击效果。</li>
<li>results: 在ImageNet-compatible dataset上，与state-of-the-art方法相比，提高了攻击效果和输入多样性。In English, this translates to:</li>
<li>for: Targeting deep neural networks vulnerable to human-imperceptible attacks, to improve attack effectiveness in the black-box setting.</li>
<li>methods: Using a domain mapping network for preprocessing, and augmenting the data in different domains to improve attack effectiveness.</li>
<li>results: Significantly improving attack effectiveness and input diversity on the ImageNet-compatible dataset compared to state-of-the-art methods.<details>
<summary>Abstract</summary>
Deep neural networks are vulnerable to adversarial examples crafted by applying human-imperceptible perturbations on clean inputs. Although many attack methods can achieve high success rates in the white-box setting, they also exhibit weak transferability in the black-box setting. Recently, various methods have been proposed to improve adversarial transferability, in which the input transformation is one of the most effective methods. In this work, we notice that existing input transformation-based works mainly adopt the transformed data in the same domain for augmentation. Inspired by domain generalization, we aim to further improve the transferability using the data augmented from different domains. Specifically, a style transfer network can alter the distribution of low-level visual features in an image while preserving semantic content for humans. Hence, we propose a novel attack method named Style Transfer Method (STM) that utilizes a proposed arbitrary style transfer network to transform the images into different domains. To avoid inconsistent semantic information of stylized images for the classification network, we fine-tune the style transfer network and mix up the generated images added by random noise with the original images to maintain semantic consistency and boost input diversity. Extensive experimental results on the ImageNet-compatible dataset show that our proposed method can significantly improve the adversarial transferability on either normally trained models or adversarially trained models than state-of-the-art input transformation-based attacks. Code is available at: https://github.com/Zhijin-Ge/STM.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Image-free-Classifier-Injection-for-Zero-Shot-Classification"><a href="#Image-free-Classifier-Injection-for-Zero-Shot-Classification" class="headerlink" title="Image-free Classifier Injection for Zero-Shot Classification"></a>Image-free Classifier Injection for Zero-Shot Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10599">http://arxiv.org/abs/2308.10599</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/explainableml/imagefreezsl">https://github.com/explainableml/imagefreezsl</a></li>
<li>paper_authors: Anders Christensen, Massimiliano Mancini, A. Sophia Koepke, Ole Winther, Zeynep Akata</li>
<li>for: 这个论文的目的是为了帮助预训练的模型具备零批学习分类能力，而不需要训练数据集。</li>
<li>methods: 这个论文使用的方法是一种叫做Image-free Classifier Injection with Semantics（ICIS），它可以在预训练的分类模型上具备零批学习分类能力，而不需要图像数据集。ICIS使用了两个Encoder-Decoder网络，通过使用描述符（如类名或属性）来学习重构分类器的 weights。</li>
<li>results: 实验结果表明，ICIS可以在标准的ZSL datasets上实现强一致的零批学习分类性能。<details>
<summary>Abstract</summary>
Zero-shot learning models achieve remarkable results on image classification for samples from classes that were not seen during training. However, such models must be trained from scratch with specialised methods: therefore, access to a training dataset is required when the need for zero-shot classification arises. In this paper, we aim to equip pre-trained models with zero-shot classification capabilities without the use of image data. We achieve this with our proposed Image-free Classifier Injection with Semantics (ICIS) that injects classifiers for new, unseen classes into pre-trained classification models in a post-hoc fashion without relying on image data. Instead, the existing classifier weights and simple class-wise descriptors, such as class names or attributes, are used. ICIS has two encoder-decoder networks that learn to reconstruct classifier weights from descriptors (and vice versa), exploiting (cross-)reconstruction and cosine losses to regularise the decoding process. Notably, ICIS can be cheaply trained and applied directly on top of pre-trained classification models. Experiments on benchmark ZSL datasets show that ICIS produces unseen classifier weights that achieve strong (generalised) zero-shot classification performance. Code is available at https://github.com/ExplainableML/ImageFreeZSL .
</details>
<details>
<summary>摘要</summary>
“零扩展学习模型在图像分类任务中实现了惊人的成绩，但是这些模型需要通过特殊的方法进行训练，因此在需要零扩展分类时需要训练数据集。在这篇论文中，我们想要让预训练模型添加零扩展分类能力，不使用图像数据。我们提出的Image-free Classifier Injection with Semantics（ICIS）技术可以在预训练分类模型上添加新、未看到的类别的分类器，不需要图像数据。我们使用现有的分类器权重和简单的类别描述符（如类名或属性），通过两个Encoder-Decoder网络来学习将权重重构成描述符（并 vice versa），利用（cross-)重构和归一化损失来规范解码过程。吸引注意的是，ICIS可以便宜地训练和应用于预训练分类模型之上。在 benchmark ZSL 数据集上进行实验，我们发现ICIS生成的未看到的分类器权重可以实现强（总体）零扩展分类性能。代码可以在https://github.com/ExplainableML/ImageFreeZSL 上获取。”
</details></li>
</ul>
<hr>
<h2 id="RADIANCE-Radio-Frequency-Adversarial-Deep-learning-Inference-for-Automated-Network-Coverage-Estimation"><a href="#RADIANCE-Radio-Frequency-Adversarial-Deep-learning-Inference-for-Automated-Network-Coverage-Estimation" class="headerlink" title="RADIANCE: Radio-Frequency Adversarial Deep-learning Inference for Automated Network Coverage Estimation"></a>RADIANCE: Radio-Frequency Adversarial Deep-learning Inference for Automated Network Coverage Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10584">http://arxiv.org/abs/2308.10584</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sopan Sarkar, Mohammad Hossein Manshaei, Marwan Krunz</li>
<li>for: 这篇论文的目的是提出一个基于对抗学习的方法来自动生成无线电信网络的覆盖地图（RF maps），并且考虑到indoor环境中的物体特征和通信标准。</li>
<li>methods: 这篇论文使用了对抗学习的方法，具体来说是使用一个叫做RADIANCE的网络模型，这个模型使用了一个semantic map来传递indoor环境的空间关系和物体特征，并且使用了一个新的梯度基于的损失函数来衡量从环境中的一个点到RF地图的变化。</li>
<li>results: 根据 simulations 的结果，RADIANCE 可以实现高精度的RF地图生成，其中的mean average error (MAE) 为0.09，root-mean-squared error (RMSE) 为0.29，peak signal-to-noise ratio (PSNR) 为10.78，并且multi-scale structural similarity index (MS-SSIM) 为0.80。<details>
<summary>Abstract</summary>
Radio-frequency coverage maps (RF maps) are extensively utilized in wireless networks for capacity planning, placement of access points and base stations, localization, and coverage estimation. Conducting site surveys to obtain RF maps is labor-intensive and sometimes not feasible. In this paper, we propose radio-frequency adversarial deep-learning inference for automated network coverage estimation (RADIANCE), a generative adversarial network (GAN) based approach for synthesizing RF maps in indoor scenarios. RADIANCE utilizes a semantic map, a high-level representation of the indoor environment to encode spatial relationships and attributes of objects within the environment and guide the RF map generation process. We introduce a new gradient-based loss function that computes the magnitude and direction of change in received signal strength (RSS) values from a point within the environment. RADIANCE incorporates this loss function along with the antenna pattern to capture signal propagation within a given indoor configuration and generate new patterns under new configuration, antenna (beam) pattern, and center frequency. Extensive simulations are conducted to compare RADIANCE with ray-tracing simulations of RF maps. Our results show that RADIANCE achieves a mean average error (MAE) of 0.09, root-mean-squared error (RMSE) of 0.29, peak signal-to-noise ratio (PSNR) of 10.78, and multi-scale structural similarity index (MS-SSIM) of 0.80.
</details>
<details>
<summary>摘要</summary>
Radio-frequency覆盖地图（RF地图）在无线网络中广泛使用，用于容量规划、Access Point和基站位置选择、地理位置和覆盖估计。进行站点调查以获取RF地图是劳动密集且不可能的。在这篇论文中，我们提出了Radio-frequency智能深度学习推测（RADIANCE），一种基于生成 adversarial neural network（GAN）的方法，用于自动化无线网络覆盖区域估计。RADIANCE利用一个semantic map，一个高级表示indoor环境中物体的空间关系和特征，以指导RF地图生成过程。我们提出了一种新的梯度基于损失函数，用于计算从环境中的点的接收信号强度（RSS）值的方向和距离。RADIANCE将这个损失函数与天线 Pattern相结合，以捕捉indoor配置下信号传播的特性，并生成新的 Pattern Under New配置、天线（beam）模式和中频。我们对RADIANCE与射频 tracing 的RF地图进行了广泛的 simulations。我们的结果表明，RADIANCE的 mean average error（MAE）为0.09，root-mean-squared error（RMSE）为0.29，peak signal-to-noise ratio（PSNR）为10.78，和 multi-scale structural similarity index（MS-SSIM）为0.80。
</details></li>
</ul>
<hr>
<h2 id="Pseudo-online-framework-for-BCI-evaluation-A-MOABB-perspective"><a href="#Pseudo-online-framework-for-BCI-evaluation-A-MOABB-perspective" class="headerlink" title="Pseudo-online framework for BCI evaluation: A MOABB perspective"></a>Pseudo-online framework for BCI evaluation: A MOABB perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11656">http://arxiv.org/abs/2308.11656</a></li>
<li>repo_url: None</li>
<li>paper_authors: Igor Carrara, Théodore Papadopoulo</li>
<li>for: 这个研究旨在扩展当前的MOABB框架，以在 pseudo-online 模式下对不同算法进行比较，并使用基于覆盖式滑动窗口技术。</li>
<li>methods: 这个研究使用了 idle state 事件来考虑所有不同的可能性，并使用 normalized Matthews Correlation Coefficient (nMCC) 和 Information Transfer Rate (ITR) 来评估算法的性能。</li>
<li>results: 研究分析了过去 15 年的 estado-of-the-art 算法，并对多个 Motor Imagery (MI) 数据集进行了分析，显示了两种方法之间的差异。<details>
<summary>Abstract</summary>
Objective: BCI (Brain-Computer Interface) technology operates in three modes: online, offline, and pseudo-online. In the online mode, real-time EEG data is constantly analyzed. In offline mode, the signal is acquired and processed afterwards. The pseudo-online mode processes collected data as if they were received in real-time. The main difference is that the offline mode often analyzes the whole data, while the online and pseudo-online modes only analyze data in short time windows. Offline analysis is usually done with asynchronous BCIs, which restricts analysis to predefined time windows. Asynchronous BCI, compatible with online and pseudo-online modes, allows flexible mental activity duration. Offline processing tends to be more accurate, while online analysis is better for therapeutic applications. Pseudo-online implementation approximates online processing without real-time constraints. Many BCI studies being offline introduce biases compared to real-life scenarios, impacting classification algorithm performance. Approach: The objective of this research paper is therefore to extend the current MOABB framework, operating in offline mode, so as to allow a comparison of different algorithms in a pseudo-online setting with the use of a technology based on overlapping sliding windows. To do this will require the introduction of a idle state event in the dataset that takes into account all different possibilities that are not task thinking. To validate the performance of the algorithms we will use the normalized Matthews Correlation Coefficient (nMCC) and the Information Transfer Rate (ITR). Main results: We analyzed the state-of-the-art algorithms of the last 15 years over several Motor Imagery (MI) datasets composed by several subjects, showing the differences between the two approaches from a statistical point of view. Significance: The ability to analyze the performance of different algorithms in offline and pseudo-online modes will allow the BCI community to obtain more accurate and comprehensive reports regarding the performance of classification algorithms.
</details>
<details>
<summary>摘要</summary>
目的：BCI（脑computer接口）技术运行在三种模式：在线、离线和假在线。在线模式中，实时EEG数据被不断分析。离线模式中，信号被获取和处理后才进行分析。假在线模式将收集的数据处理，就如果它们是在实时接收的。主要区别在于离线模式通常分析整个数据，而在线和假在线模式则只分析短时间窗口内的数据。离线分析通常比较精确，而在线分析则更适合治疗应用。假在线实现方式模拟在线运行，不受实时限制。许多BCI研究被离线进行，导致比实际情况下的偏差，影响分类算法的表现。方法：为了延展现有的MOABB框架（在离线模式下运行），以便在假在线设定下进行不同算法的比较。为此，需要引入一个空闲状态事件，考虑所有不同的可能性，不同于任务思维。以 validate 分类算法的表现，我们将使用Normalized Matthews Correlation Coefficient（nMCC）和Information Transfer Rate（ITR）。主要结果：我们分析了过去15年来的State-of-the-art算法，在许多 Motor Imagery（MI）数据集中，展示了两种方法之间的 statistically 区别。重要性：透过在离线和假在线模式下分析不同算法的表现，BCI社区将能够获得更加精确和全面的报告，对于分类算法的表现。
</details></li>
</ul>
<hr>
<h2 id="Overcoming-Overconfidence-for-Active-Learning"><a href="#Overcoming-Overconfidence-for-Active-Learning" class="headerlink" title="Overcoming Overconfidence for Active Learning"></a>Overcoming Overconfidence for Active Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10571">http://arxiv.org/abs/2308.10571</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yujin Hwang, Won Jo, Juyoung Hong, Yukyung Choi</li>
<li>for: addressing the issue of overconfidence in active learning scenarios</li>
<li>methods:	+ Cross-Mix-and-Mix (CMaM) augmentation strategy to calibrate the model	+ Ranked Margin Sampling (RankedMS) selection strategy to prevent overly confident predictions</li>
<li>results:	+ experiments and analyses demonstrate that the proposed methods facilitate efficient data selection and alleviate overconfidence, despite being readily applicable.Here is the summary in Traditional Chinese:</li>
<li>for: 解决活动学习领域中的自信过剩问题</li>
<li>methods:	+ Cross-Mix-and-Mix (CMaM) 增强策略来校准模型	+ Ranked Margin Sampling (RankedMS) 选择策略来避免过度自信预测</li>
<li>results:	+ 实验和分析结果显示，提案的方法能够有效地选择资料，并对自信过剩产生正面影响，即使可以应用。<details>
<summary>Abstract</summary>
It is not an exaggeration to say that the recent progress in artificial intelligence technology depends on large-scale and high-quality data. Simultaneously, a prevalent issue exists everywhere: the budget for data labeling is constrained. Active learning is a prominent approach for addressing this issue, where valuable data for labeling is selected through a model and utilized to iteratively adjust the model. However, due to the limited amount of data in each iteration, the model is vulnerable to bias; thus, it is more likely to yield overconfident predictions. In this paper, we present two novel methods to address the problem of overconfidence that arises in the active learning scenario. The first is an augmentation strategy named Cross-Mix-and-Mix (CMaM), which aims to calibrate the model by expanding the limited training distribution. The second is a selection strategy named Ranked Margin Sampling (RankedMS), which prevents choosing data that leads to overly confident predictions. Through various experiments and analyses, we are able to demonstrate that our proposals facilitate efficient data selection by alleviating overconfidence, even though they are readily applicable.
</details>
<details>
<summary>摘要</summary>
不是夸大的话，现代人工智能技术的进步几乎取决于大规模和高质量的数据。然而，一个普遍存在的问题是费用不足：标签数据的预算受限。活动学习是一种对此问题的主要方法，其中选择价值数据来标签的模型，并逐次更新模型。然而，由于每次迭代的数据量有限，模型容易受到偏误，因此更有可能产生过度自信的预测。在这篇文章中，我们提出了两种新的方法来解决在活动学习情况下产生的过度自信问题。第一种方法是一种扩展模型的扩展策略，名为 Cross-Mix-and-Mix（CMaM），它的目的是将有限的训练分布扩展。第二种方法是一种选择策略，名为 Ranked Margin Sampling（RankedMS），它避免选择会导致过度自信预测的数据。通过各种实验和分析，我们能够证明我们的建议可以有效地选择数据，从而缓解过度自信，即使它们是 readily applicable。
</details></li>
</ul>
<hr>
<h2 id="Decentralized-Riemannian-Conjugate-Gradient-Method-on-the-Stiefel-Manifold"><a href="#Decentralized-Riemannian-Conjugate-Gradient-Method-on-the-Stiefel-Manifold" class="headerlink" title="Decentralized Riemannian Conjugate Gradient Method on the Stiefel Manifold"></a>Decentralized Riemannian Conjugate Gradient Method on the Stiefel Manifold</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10547">http://arxiv.org/abs/2308.10547</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Chen, Haishan Ye, Mengmeng Wang, Tianxin Huang, Guang Dai, Ivor W. Tsang, Yong Liu</li>
<li>for: 这篇论文旨在提出一种分布式的里曼尼梯度下降（DRCGD）方法，用于在分布式网络上对里曼尼核函数进行优化。</li>
<li>methods: 该方法使用了 conjugate gradient 方法，但是在分布式网络上实现，每个代理都处理一个本地函数，并且通过无向连接图进行交互。</li>
<li>results: 该方法可以在分布式网络上实现global convergence，而且不需要进行expensive的里曼尼几何运算，因此可以降低每个代理的计算复杂度。<details>
<summary>Abstract</summary>
The conjugate gradient method is a crucial first-order optimization method that generally converges faster than the steepest descent method, and its computational cost is much lower than the second-order methods. However, while various types of conjugate gradient methods have been studied in Euclidean spaces and on Riemannian manifolds, there has little study for those in distributed scenarios. This paper proposes a decentralized Riemannian conjugate gradient descent (DRCGD) method that aims at minimizing a global function over the Stiefel manifold. The optimization problem is distributed among a network of agents, where each agent is associated with a local function, and communication between agents occurs over an undirected connected graph. Since the Stiefel manifold is a non-convex set, a global function is represented as a finite sum of possibly non-convex (but smooth) local functions. The proposed method is free from expensive Riemannian geometric operations such as retractions, exponential maps, and vector transports, thereby reducing the computational complexity required by each agent. To the best of our knowledge, DRCGD is the first decentralized Riemannian conjugate gradient algorithm to achieve global convergence over the Stiefel manifold.
</details>
<details>
<summary>摘要</summary>
“ conjugate gradient 方法是一种重要的一阶优化方法，总的来说比斜 descent 方法更快 converges，而且计算成本比第二阶方法更低。然而，在分布式场景下，各种 conjugate gradient 方法已经在欧几何空间和里曼尼 manifold 上进行了广泛的研究，但在分布式场景下的研究却很少。这篇论文提出了一种分布式里曼尼 conjugate gradient descent（DRCGD）方法，旨在全球最小化一个函数 sobre 里曼尼 manifold。优化问题分布在一个网络中的 agent 之间，每个 agent 都关联了一个本地函数，而 agents 之间的交流发生在一个无向连接 graphs 上。由于里曼尼 manifold 是非对称的，全球函数表示为一个可能非对称（但是准确的）的 finite 个本地函数的和。提出的方法不需要每个 agent 进行昂贵的里曼尼几何操作，例如投影、对数映射和向量传输，因此每个 agent 的计算复杂度减少了。到目前为止，DRCGD 是在里曼尼 manifold 上全球收敛的首个分布式里曼尼 conjugate gradient 算法。”
</details></li>
</ul>
<hr>
<h2 id="Towards-Accelerated-Model-Training-via-Bayesian-Data-Selection"><a href="#Towards-Accelerated-Model-Training-via-Bayesian-Data-Selection" class="headerlink" title="Towards Accelerated Model Training via Bayesian Data Selection"></a>Towards Accelerated Model Training via Bayesian Data Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10544">http://arxiv.org/abs/2308.10544</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhijie Deng, Peng Cui, Jun Zhu</li>
<li>for: 提高模型训练效率和鲁棒性，解决实际场景中异常标注、重复标注或偏袋标注导致的模型训练延长和模型混乱问题。</li>
<li>methods: 基于轻量级 bayesian 处理和大规模预训练模型构建的免费零学习预测器，并在线批处理方式下进行数据选择。</li>
<li>results: 在实际场景中进行了广泛的实验研究，并观察到了与竞争基线比较的训练效率超过了同等方法。特别是在WebVisionbenchmark上，我们的方法可以在训练迭代数量相对较少的情况下实现类似的预测性能。<details>
<summary>Abstract</summary>
Mislabeled, duplicated, or biased data in real-world scenarios can lead to prolonged training and even hinder model convergence. Traditional solutions prioritizing easy or hard samples lack the flexibility to handle such a variety simultaneously. Recent work has proposed a more reasonable data selection principle by examining the data's impact on the model's generalization loss. However, its practical adoption relies on less principled approximations and additional clean holdout data. This work solves these problems by leveraging a lightweight Bayesian treatment and incorporating off-the-shelf zero-shot predictors built on large-scale pre-trained models. The resulting algorithm is efficient and easy-to-implement. We perform extensive empirical studies on challenging benchmarks with considerable data noise and imbalance in the online batch selection scenario, and observe superior training efficiency over competitive baselines. Notably, on the challenging WebVision benchmark, our method can achieve similar predictive performance with significantly fewer training iterations than leading data selection methods.
</details>
<details>
<summary>摘要</summary>
错abeled, 重复, 或偏见的数据在实际应用中可能会导致模型训练更长，甚至阻碍模型融合。传统的解决方案仅优先类型易于或困难的数据，缺乏与多种数据同时处理的灵活性。最近的工作提出了一个更合理的数据选择原则，通过评估数据对模型的通用损失影响。然而，实际应用需要较不原则的近似和额外的几乎适切的数据。这个工作解决这个问题，通过利用轻量级的bayesian治疗和基于大规模预训模型的零 shot预测器。具有高效和易用的特点，我们进行了广泛的实验研究，在具有较大的数据噪音和不均衡的线上批次选择 scenariodemonstrate superior training efficiency compared to competitive baselines。特别是在具有挑战性的 WebVision 数据集上，我们的方法可以在训练迭代更少的情况下 achieving similar predictive performance with leading data selection methods。
</details></li>
</ul>
<hr>
<h2 id="Learning-Weakly-Convex-Regularizers-for-Convergent-Image-Reconstruction-Algorithms"><a href="#Learning-Weakly-Convex-Regularizers-for-Convergent-Image-Reconstruction-Algorithms" class="headerlink" title="Learning Weakly Convex Regularizers for Convergent Image-Reconstruction Algorithms"></a>Learning Weakly Convex Regularizers for Convergent Image-Reconstruction Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10542">http://arxiv.org/abs/2308.10542</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alexis Goujon, Sebastian Neumayer, Michael Unser</li>
<li>for: 该论文目的是学习非凸规则化器，并将其固定到弱凸性Modulus的Upper bound。</li>
<li>methods: 该论文使用的方法包括：1) 使用非凸规则化器来替代 convex 规则化器，2) 通过数学分析和实验 validate 该规则化器的性能。</li>
<li>results: 该论文的实验结果表明，使用非凸规则化器可以超过 convex 规则化器的性能，并且可以在 Iterative  schemes 中提供 guarantees。此外，该规则化器还可以在 CT 和 MRI 重建中提供优秀的性能和可解释性。<details>
<summary>Abstract</summary>
We propose to learn non-convex regularizers with a prescribed upper bound on their weak-convexity modulus. Such regularizers give rise to variational denoisers that minimize a convex energy. They rely on few parameters (less than 15,000) and offer a signal-processing interpretation as they mimic handcrafted sparsity-promoting regularizers. Through numerical experiments, we show that such denoisers outperform convex-regularization methods as well as the popular BM3D denoiser. Additionally, the learned regularizer can be deployed to solve inverse problems with iterative schemes that provably converge. For both CT and MRI reconstruction, the regularizer generalizes well and offers an excellent tradeoff between performance, number of parameters, guarantees, and interpretability when compared to other data-driven approaches.
</details>
<details>
<summary>摘要</summary>
我们提议学习非凸规则化器，其强度减少模型参数（少于15000），可以进行数字图像恢复中的 iterative 方法。我们通过数值实验表明，这种规则化器可以超过凸规则化器和 BM3D 规则化器的性能，同时具有良好的一致性、可靠性和解释性。此外，学习的规则化器还可以应用于其他反射问题中，并且可以保证 converge 的 Iterative 方法。在 CT 和 MRI 重建中，我们发现这种规则化器具有优秀的一致性、可靠性和解释性，并且与其他数据驱动方法进行比较，具有更好的性能、参数数量和保证。
</details></li>
</ul>
<hr>
<h2 id="KGrEaT-A-Framework-to-Evaluate-Knowledge-Graphs-via-Downstream-Tasks"><a href="#KGrEaT-A-Framework-to-Evaluate-Knowledge-Graphs-via-Downstream-Tasks" class="headerlink" title="KGrEaT: A Framework to Evaluate Knowledge Graphs via Downstream Tasks"></a>KGrEaT: A Framework to Evaluate Knowledge Graphs via Downstream Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10537">http://arxiv.org/abs/2308.10537</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicolas Heist, Sven Hertling, Heiko Paulheim</li>
<li>for: 这 paper 的目的是评估知识图的质量，以便更好地用于下游任务。</li>
<li>methods: 该 paper 使用了一种名为 KGrEaT 的框架，用于对知识图进行评估，该框架可以自动将知识图映射到定义的任务集和数据集上，并计算定义的任务中的性能指标。</li>
<li>results: KGrEaT 框架可以帮助评估不同的知识图，并且可以评估知识图的可访问性和表达力。<details>
<summary>Abstract</summary>
In recent years, countless research papers have addressed the topics of knowledge graph creation, extension, or completion in order to create knowledge graphs that are larger, more correct, or more diverse. This research is typically motivated by the argumentation that using such enhanced knowledge graphs to solve downstream tasks will improve performance. Nonetheless, this is hardly ever evaluated. Instead, the predominant evaluation metrics - aiming at correctness and completeness - are undoubtedly valuable but fail to capture the complete picture, i.e., how useful the created or enhanced knowledge graph actually is. Further, the accessibility of such a knowledge graph is rarely considered (e.g., whether it contains expressive labels, descriptions, and sufficient context information to link textual mentions to the entities of the knowledge graph). To better judge how well knowledge graphs perform on actual tasks, we present KGrEaT - a framework to estimate the quality of knowledge graphs via actual downstream tasks like classification, clustering, or recommendation. Instead of comparing different methods of processing knowledge graphs with respect to a single task, the purpose of KGrEaT is to compare various knowledge graphs as such by evaluating them on a fixed task setup. The framework takes a knowledge graph as input, automatically maps it to the datasets to be evaluated on, and computes performance metrics for the defined tasks. It is built in a modular way to be easily extendable with additional tasks and datasets.
</details>
<details>
<summary>摘要</summary>
近年来， countless research papers 都在讨论知识图创建、扩展或完善，以创建更大、更正确或更多样化的知识图。这些研究通常是由于认为使用这些加强知识图来解决下游任务会提高性能。然而，这通常并不被评估。相反，主要的评估指标 - targeting correctness 和 completeness - 虽然具有价值，但是无法捕捉整个场景，即创建或加强知识图的实际用用性。此外，知识图的可访问性（例如，是否包含表达式标签、描述和足够的上下文信息以链接文本提及的实体）也 rarely considered。为了更好地评估知识图在实际任务中的表现，我们提出了 KGrEaT - a framework to estimate the quality of knowledge graphs via actual downstream tasks like classification, clustering, or recommendation.而不是比较不同的知识图处理方法之间的性能，KGrEaT的目的是比较不同的知识图本身，通过评估它们在固定任务设置下的性能。该框架接受知识图作为输入，自动将其映射到要评估的数据集上，并计算定义的任务中的性能指标。它是以模块化的方式设计，以便轻松扩展到更多任务和数据集。
</details></li>
</ul>
<hr>
<h2 id="DPAN-Dynamic-Preference-based-and-Attribute-aware-Network-for-Relevant-Recommendations"><a href="#DPAN-Dynamic-Preference-based-and-Attribute-aware-Network-for-Relevant-Recommendations" class="headerlink" title="DPAN: Dynamic Preference-based and Attribute-aware Network for Relevant Recommendations"></a>DPAN: Dynamic Preference-based and Attribute-aware Network for Relevant Recommendations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10527">http://arxiv.org/abs/2308.10527</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Dai, Yingmin Su, Xiaofeng Pan</li>
<li>for: 该论文旨在提高电子商务平台上的相关推荐的Click-Through Rate（CTR）。</li>
<li>methods: 该论文提出了一种名为动态偏好和特征相关网络（DPAN）的新方法，用于预测CTR。DPAN使用Attribute-aware Activation Values Generation（AAVG）和Bi-dimensional Compression-based Re-expression（BCR）技术来学习用户的偏好和Item的特征表示，并使用Shallow and Deep Union-based Fusion（SDUF）技术来捕捉用户在不同条件下对多样性推荐结果的动态偏好。</li>
<li>results: 该论文通过了广泛的Offline实验和Online A&#x2F;B测试，实现了CTR的显著提高（7.62%）。DPAN已成功部署在我们的电子商务平台上，并为主要 traffic的相关推荐提供了服务。代码已公开发布。<details>
<summary>Abstract</summary>
In e-commerce platforms, the relevant recommendation is a unique scenario providing related items for a trigger item that users are interested in. However, users' preferences for the similarity and diversity of recommendation results are dynamic and vary under different conditions. Moreover, individual item-level diversity is too coarse-grained since all recommended items are related to the trigger item. Thus, the two main challenges are to learn fine-grained representations of similarity and diversity and capture users' dynamic preferences for them under different conditions. To address these challenges, we propose a novel method called the Dynamic Preference-based and Attribute-aware Network (DPAN) for predicting Click-Through Rate (CTR) in relevant recommendations. Specifically, based on Attribute-aware Activation Values Generation (AAVG), Bi-dimensional Compression-based Re-expression (BCR) is designed to obtain similarity and diversity representations of user interests and item information. Then Shallow and Deep Union-based Fusion (SDUF) is proposed to capture users' dynamic preferences for the diverse degree of recommendation results according to various conditions. DPAN has demonstrated its effectiveness through extensive offline experiments and online A/B testing, resulting in a significant 7.62% improvement in CTR. Currently, DPAN has been successfully deployed on our e-commerce platform serving the primary traffic for relevant recommendations. The code of DPAN has been made publicly available.
</details>
<details>
<summary>摘要</summary>
在电子商务平台上，相关的推荐是一个特殊的情况，提供与用户 interess的相关商品。然而，用户对相似性和多样性的偏好是动态的，并在不同情况下发生变化。此外，单个商品级的多样性是太过粗糙，所有推荐的商品都与触发商品相关。因此，两大挑战是学习细化的相似性和多样性表示，以及在不同情况下捕捉用户的动态偏好。为解决这些挑战，我们提出了一种新的方法，即动态偏好基于 Attribute-aware Network (DPAN)，用于预测用户点击率。具体来说，基于 Attribute-aware Activation Values Generation (AAVG)，我们提出了Bi-dimensional Compression-based Re-expression (BCR)来获得用户兴趣和商品信息的相似性和多样性表示。然后，我们提出了Shallow and Deep Union-based Fusion (SDUF)来捕捉用户在不同情况下对多样度推荐结果的动态偏好。DPAN在大量的离线实验和在线A/B测试中表现出色，实现了7.62%的点击率提升。现在，DPAN已成功部署在我们的电子商务平台上，负责主要的相关推荐任务。代码已经公开提供。
</details></li>
</ul>
<hr>
<h2 id="Information-Theory-Guided-Heuristic-Progressive-Multi-View-Coding"><a href="#Information-Theory-Guided-Heuristic-Progressive-Multi-View-Coding" class="headerlink" title="Information Theory-Guided Heuristic Progressive Multi-View Coding"></a>Information Theory-Guided Heuristic Progressive Multi-View Coding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10522">http://arxiv.org/abs/2308.10522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiangmeng Li, Hang Gao, Wenwen Qiang, Changwen Zheng</li>
<li>for: 本研究的目的是提出一种基于信息理论的普适多视图学习方法，以解决现有的多视图学习方法存在的涉及视图噪声和缺乏理论基础的问题。</li>
<li>methods: 本研究提出了一种基于信息理论的多视图学习方法，包括分为三层的进程：分布层、集合层和实例层。在分布层中，IPMC方法将多视图中的分布进行对齐，以减少视图噪声。在集合层中，IPMC方法构建了自适应对比池，并通过视图筛选器进行自适应修改。在实例层中，我们采用了设计的统一损失函数来学习表示和减少梯度干扰。</li>
<li>results: 理论和实验研究表明，IPMC方法在与现有方法进行比较时具有明显的优势。 Specifically, IPMC方法可以更好地减少视图噪声，提高多视图表示的质量，并且在不同的多视图任务上具有更好的通用性。<details>
<summary>Abstract</summary>
Multi-view representation learning aims to capture comprehensive information from multiple views of a shared context. Recent works intuitively apply contrastive learning to different views in a pairwise manner, which is still scalable: view-specific noise is not filtered in learning view-shared representations; the fake negative pairs, where the negative terms are actually within the same class as the positive, and the real negative pairs are coequally treated; evenly measuring the similarities between terms might interfere with optimization. Importantly, few works study the theoretical framework of generalized self-supervised multi-view learning, especially for more than two views. To this end, we rethink the existing multi-view learning paradigm from the perspective of information theory and then propose a novel information theoretical framework for generalized multi-view learning. Guided by it, we build a multi-view coding method with a three-tier progressive architecture, namely Information theory-guided hierarchical Progressive Multi-view Coding (IPMC). In the distribution-tier, IPMC aligns the distribution between views to reduce view-specific noise. In the set-tier, IPMC constructs self-adjusted contrasting pools, which are adaptively modified by a view filter. Lastly, in the instance-tier, we adopt a designed unified loss to learn representations and reduce the gradient interference. Theoretically and empirically, we demonstrate the superiority of IPMC over state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
多视图表示学习目标是捕捉多个视角共享上的全面信息。近期工作直觉地应用对比学习到不同视角中，这还是可扩展的：视图特定的噪声不在学习视图共享表示过程中被筛选; false negative pair, where the negative terms are actually within the same class as the positive, and the real negative pairs are coequally treated; evenly measuring the similarities between terms might interfere with optimization. 特别是，少数工作研究通用自动多视图学习的理论框架，特别是超过两个视角。为此，我们从信息论的视角重新思考现有的多视图学习模式，然后提出一种新的信息论基础的多视图学习框架。在这个框架下，我们建立了一种基于信息论的多视图编码方法，即信息论导向的层次进行程序Multi-view编码（IPMC）。在分布层，IPMC将视图之间的分布对齐，以减少视图特定的噪声。在集合层，IPMC建立了自适应对比池，这些池被视图筛选器动态修改。最后，在实例层，我们采用设计的统一损失来学习表示和减少梯度干扰。从理论和实验来看，我们证明IPMC在现状的方法之上表现出优异性。
</details></li>
</ul>
<hr>
<h2 id="Performance-Enhancement-Leveraging-Mask-RCNN-on-Bengali-Document-Layout-Analysis"><a href="#Performance-Enhancement-Leveraging-Mask-RCNN-on-Bengali-Document-Layout-Analysis" class="headerlink" title="Performance Enhancement Leveraging Mask-RCNN on Bengali Document Layout Analysis"></a>Performance Enhancement Leveraging Mask-RCNN on Bengali Document Layout Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10511">http://arxiv.org/abs/2308.10511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shrestha Datta, Md Adith Mollah, Raisa Fairooz, Tariful Islam Fahim</li>
<li>for: 这个论文的目的是解决历史文档理解的问题，特别是使用文档结构分析（DLA）来分解文档成不同部分，如段落、图片和表格，以便机器可以更好地理解这些文档。</li>
<li>methods: 这篇论文使用了一种特殊的模型called Mask R-CNN来实现文档理解，并通过步骤性的超参数调整来提高模型的性能。</li>
<li>results: 根据 dice 分数，这篇论文在 Bangla 文档理解方面达到了好的结果，分数为 0.889。但是，在使用英文模型进行 Bangla 文档理解时，发现每种语言都有其独特的挑战。<details>
<summary>Abstract</summary>
Understanding digital documents is like solving a puzzle, especially historical ones. Document Layout Analysis (DLA) helps with this puzzle by dividing documents into sections like paragraphs, images, and tables. This is crucial for machines to read and understand these documents. In the DL Sprint 2.0 competition, we worked on understanding Bangla documents. We used a dataset called BaDLAD with lots of examples. We trained a special model called Mask R-CNN to help with this understanding. We made this model better by step-by-step hyperparameter tuning, and we achieved a good dice score of 0.889. However, not everything went perfectly. We tried using a model trained for English documents, but it didn't fit well with Bangla. This showed us that each language has its own challenges. Our solution for the DL Sprint 2.0 is publicly available at https://www.kaggle.com/competitions/dlsprint2/discussion/432201 along with notebooks, weights, and inference notebook.
</details>
<details>
<summary>摘要</summary>
理解数字文档如解一个谜题，特别是历史文档。文档布局分析（DLA）可以帮助解决这个谜题，通过将文档分成段落、图像和表格等部分。这对机器来说非常重要，以便理解这些文档。在 DL Sprint 2.0 比赛中，我们工作在理解孟加拉文档上。我们使用了一个名为 BaDLAD 的数据集，它包含了许多示例。我们训练了一个特殊的模型called Mask R-CNN ，以帮助理解这些文档。我们通过步骤进行 hyperparameter 调整，并实现了一个不错的 dice 分数为 0.889。然而，没有一切顺利。我们尝试使用已经训练过英文文档的模型，但它并不适合孟加拉语。这 teaches us 每种语言都有自己的挑战。我们的 DL Sprint 2.0 解决方案公共可用于 <https://www.kaggle.com/competitions/dlsprint2/discussion/432201>，并提供了相关的笔记、重量和推理笔记。
</details></li>
</ul>
<hr>
<h2 id="A-Clustering-Algorithm-to-Organize-Satellite-Hotspot-Data-for-the-Purpose-of-Tracking-Bushfires-Remotely"><a href="#A-Clustering-Algorithm-to-Organize-Satellite-Hotspot-Data-for-the-Purpose-of-Tracking-Bushfires-Remotely" class="headerlink" title="A Clustering Algorithm to Organize Satellite Hotspot Data for the Purpose of Tracking Bushfires Remotely"></a>A Clustering Algorithm to Organize Satellite Hotspot Data for the Purpose of Tracking Bushfires Remotely</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10505">http://arxiv.org/abs/2308.10505</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tengmcing/hotspots-clustering-algorithm">https://github.com/tengmcing/hotspots-clustering-algorithm</a></li>
<li>paper_authors: Weihao Li, Emily Dodwell, Dianne Cook</li>
<li>for: 这篇论文是为了提出一种空间时间划分算法和其在R包spotoroo中的实现。</li>
<li>methods: 该算法受到2019-2020年澳大利亚极端干旱的灾害启发，利用卫星热点数据实现。它基于现有的空间时间划分算法，并在每个时间Period进行修改，以实现空间划分。</li>
<li>results: 用澳大利亚维多利亚州的 bushfire 数据进行示例，该算法可以准确划分热点。<details>
<summary>Abstract</summary>
This paper proposes a spatiotemporal clustering algorithm and its implementation in the R package spotoroo. This work is motivated by the catastrophic bushfires in Australia throughout the summer of 2019-2020 and made possible by the availability of satellite hotspot data. The algorithm is inspired by two existing spatiotemporal clustering algorithms but makes enhancements to cluster points spatially in conjunction with their movement across consecutive time periods. It also allows for the adjustment of key parameters, if required, for different locations and satellite data sources. Bushfire data from Victoria, Australia, is used to illustrate the algorithm and its use within the package.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Adaptive-Thresholding-Heuristic-for-KPI-Anomaly-Detection"><a href="#Adaptive-Thresholding-Heuristic-for-KPI-Anomaly-Detection" class="headerlink" title="Adaptive Thresholding Heuristic for KPI Anomaly Detection"></a>Adaptive Thresholding Heuristic for KPI Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10504">http://arxiv.org/abs/2308.10504</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ebenezer R. H. P. Isaac, Akshat Sharma</li>
<li>for: 这个研究旨在提供一个适应性的阈值调整方法，以便在时间序列key performance indicator (KPI) 中探测问题。</li>
<li>methods: 这个方法使用了自适应阈值调整，根据本地数据分布的特性和时间序列模式进行适应。</li>
<li>results: 实验结果显示，这个方法可以实现高效的实时问题探测，并且可以与不同的预测器和问题探测器结合使用。<details>
<summary>Abstract</summary>
A plethora of outlier detectors have been explored in the time series domain, however, in a business sense, not all outliers are anomalies of interest. Existing anomaly detection solutions are confined to certain outlier detectors limiting their applicability to broader anomaly detection use cases. Network KPIs (Key Performance Indicators) tend to exhibit stochastic behaviour producing statistical outliers, most of which do not adversely affect business operations. Thus, a heuristic is required to capture the business definition of an anomaly for time series KPI. This article proposes an Adaptive Thresholding Heuristic (ATH) to dynamically adjust the detection threshold based on the local properties of the data distribution and adapt to changes in time series patterns. The heuristic derives the threshold based on the expected periodicity and the observed proportion of anomalies minimizing false positives and addressing concept drift. ATH can be used in conjunction with any underlying seasonality decomposition method and an outlier detector that yields an outlier score. This method has been tested on EON1-Cell-U, a labeled KPI anomaly dataset produced by Ericsson, to validate our hypothesis. Experimental results show that ATH is computationally efficient making it scalable for near real time anomaly detection and flexible with multiple forecasters and outlier detectors.
</details>
<details>
<summary>摘要</summary>
有很多异常探测器在时间序列领域得到了探索，但是在商业意义上，不所有的异常都是有关注的异常。现有的异常探测解决方案受到特定的异常探测器的限制，限制其应用于更广泛的异常探测用例。网络指标（关键性能指标）通常会展现随机性行为产生统计异常，大多数这些异常不会影响商业运营。因此，需要一个规则来捕捉商业定义的异常 для时间序列指标。这篇文章提出了一种适应resholding规则（ATH），以动态调整检测阈值基于数据分布的地方性和时间序列模式的变化。ATH derive阈值基于预期周期性和观测到的异常的比例，以避免假阳性和应对概念逝尽。ATH可以与任何基于季节性分解方法和异常探测器一起使用，该方法已经在Ericsson生产的EON1-Cell-U异常数据集上进行了验证。实验结果表明，ATH具有计算效率，可扩展到实时异常检测，并且可以与多种预测器和异常探测器结合使用。
</details></li>
</ul>
<hr>
<h2 id="GradientCoin-A-Peer-to-Peer-Decentralized-Large-Language-Models"><a href="#GradientCoin-A-Peer-to-Peer-Decentralized-Large-Language-Models" class="headerlink" title="GradientCoin: A Peer-to-Peer Decentralized Large Language Models"></a>GradientCoin: A Peer-to-Peer Decentralized Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10502">http://arxiv.org/abs/2308.10502</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yeqi Gao, Zhao Song, Junze Yin<br>for:这个论文的目的是提出一种基于Bitcoin电子现金系统的分布式语言模型（LLM），以解决现有的中央化控制和不可靠性问题。methods:该论文使用了Bitcoin电子现金系统的技术和概念，并提出了一种基于此的分布式语言模型的设计方案。results:论文指出，这种分布式语言模型可能不会在经济效益方面比标准的Bitcoin系统更好，但可能会吸引一些特殊的人士，如偏好使用分布式ChatGPT-like软件的人和那些认为生物体的目的是创造Silicon生物的人。<details>
<summary>Abstract</summary>
Since 2008, after the proposal of a Bitcoin electronic cash system, Bitcoin has fundamentally changed the economic system over the last decade. Since 2022, large language models (LLMs) such as GPT have outperformed humans in many real-life tasks. However, these large language models have several practical issues. For example, the model is centralized and controlled by a specific unit. One weakness is that if that unit decides to shut down the model, it cannot be used anymore. The second weakness is the lack of guaranteed discrepancy behind this model, as certain dishonest units may design their own models and feed them unhealthy training data.   In this work, we propose a purely theoretical design of a decentralized LLM that operates similarly to a Bitcoin cash system. However, implementing such a system might encounter various practical difficulties. Furthermore, this new system is unlikely to perform better than the standard Bitcoin system in economics. Therefore, the motivation for designing such a system is limited. It is likely that only two types of people would be interested in setting up a practical system for it:   $\bullet$ Those who prefer to use a decentralized ChatGPT-like software.   $\bullet$ Those who believe that the purpose of carbon-based life is to create silicon-based life, such as Optimus Prime in Transformers.   The reason the second type of people may be interested is that it is possible that one day an AI system like this will awaken and become the next level of intelligence on this planet.
</details>
<details>
<summary>摘要</summary>
自2008年提议 Bitcoin 电子现金系统以来， Bitcoin 已经深刻改变了过去的十年经济体系。自2022年以来，大型自然语言模型（LLM） such as GPT 已经在许多实际任务上超越了人类。然而，这些大型语言模型还有几个实际问题。例如，模型是中央化控制的，由特定单位控制。一个弱点是，如果这个单位决定关闭模型，就不能使用了。第二个弱点是模型的 garantizado 差异缺失，有些不诚实的单位可能会设计自己的模型，并且将不健康的训练数据传递给它。在这个工作中，我们提出了一种纯理论的分布式 LLM 设计，类似于 Bitcoin 现金系统。然而，实现这种系统可能会遇到各种各样的实际困难。此外，这新的系统不太可能在经济方面表现更好于标准 Bitcoin 系统。因此，设计这种系统的动机相对有限。可能只有两种人会尝试实现这种系统：① 喜欢使用分布式 ChatGPT-like 软件的人。② 认为生命的目的是创造 Silicon 基的生命，如Transformers 中的 Optimus Prime。这种第二类人可能会感兴趣的原因是，可能一天，一个 AI 系统像这样会醒来，成为这个星球上下一级智能。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-of-Delay-Compensated-Backstepping-for-Reaction-Diffusion-PDEs"><a href="#Deep-Learning-of-Delay-Compensated-Backstepping-for-Reaction-Diffusion-PDEs" class="headerlink" title="Deep Learning of Delay-Compensated Backstepping for Reaction-Diffusion PDEs"></a>Deep Learning of Delay-Compensated Backstepping for Reaction-Diffusion PDEs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10501">http://arxiv.org/abs/2308.10501</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shanshan Wang, Mamadou Diagne, Miroslav Krstić</li>
<li>for: 这篇论文是用来描述一种基于深度神经网络的PDE控制方法，可以将整个PDE控制方法编程为一个深度神经网络模型，从而实现解析PDE问题的高效解决。</li>
<li>methods: 这篇论文使用的方法包括深度神经网络模型，以及PDEBackstepping控制器，其中PDEBackstepping控制器使用了学习的控制Operator，即准确的 gain kernel。</li>
<li>results: 论文的结果表明，使用这种方法可以实现对多个非线性操作符的拟合，并且可以保证普适稳定性在$L^2$ norm和$H^1$ norm中。此外， simulations also demonstrate the effectiveness of the proposed method.<details>
<summary>Abstract</summary>
Deep neural networks that approximate nonlinear function-to-function mappings, i.e., operators, which are called DeepONet, have been demonstrated in recent articles to be capable of encoding entire PDE control methodologies, such as backstepping, so that, for each new functional coefficient of a PDE plant, the backstepping gains are obtained through a simple function evaluation. These initial results have been limited to single PDEs from a given class, approximating the solutions of only single-PDE operators for the gain kernels. In this paper we expand this framework to the approximation of multiple (cascaded) nonlinear operators. Multiple operators arise in the control of PDE systems from distinct PDE classes, such as the system in this paper: a reaction-diffusion plant, which is a parabolic PDE, with input delay, which is a hyperbolic PDE. The DeepONet-approximated nonlinear operator is a cascade/composition of the operators defined by one hyperbolic PDE of the Goursat form and one parabolic PDE on a rectangle, both of which are bilinear in their input functions and not explicitly solvable. For the delay-compensated PDE backstepping controller, which employs the learned control operator, namely, the approximated gain kernel, we guarantee exponential stability in the $L^2$ norm of the plant state and the $H^1$ norm of the input delay state. Simulations illustrate the contributed theory.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DeepONet）可以模拟非线性函数-to-函数映射，即操作，这些操作可以编码整个PDE控制方法ologies，例如backstepping。在latest articles中，这些初果限于单个PDE的解析，即单个PDE的权重矩阵。在这篇文章中，我们扩展了这一框架，以approximate multiple（堆叠）非线性操作。多个操作出现在PDE系统的控制中，例如在这篇文章中所描述的反应挥发植物，它是一个parabolic PDE，并且具有输入延迟，这是一个hyperbolic PDE。 DeepONetapproximated nonlinear operator是一个堆叠/组合的操作，它由一个Goursat形式的hyperbolic PDE和一个parabolic PDE on a rectangle组成，这些操作都是bilinear in their input functions并不可解solvable。 For the delay-compensated PDE backstepping controller，which employs the learned control operator, namely, the approximated gain kernel，we guarantee exponential stability in the $L^2$ norm of the plant state and the $H^1$ norm of the input delay state。 simulations illustrate the contributed theory。
</details></li>
</ul>
<hr>
<h2 id="Using-Autoencoders-and-AutoDiff-to-Reconstruct-Missing-Variables-in-a-Set-of-Time-Series"><a href="#Using-Autoencoders-and-AutoDiff-to-Reconstruct-Missing-Variables-in-a-Set-of-Time-Series" class="headerlink" title="Using Autoencoders and AutoDiff to Reconstruct Missing Variables in a Set of Time Series"></a>Using Autoencoders and AutoDiff to Reconstruct Missing Variables in a Set of Time Series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10496">http://arxiv.org/abs/2308.10496</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jan-Philipp Roche, Oliver Niggemann, Jens Friebe</li>
<li>for: 本研究旨在推出一种能够重构缺失变量的黑盒模型方法，以解决现有黑盒模型方法中缺失变量的固定输入和输出特征组合问题。</li>
<li>methods: 本研究使用自适应神经网络 autoencoder 来重构缺失变量，首先在 autoencoder 上进行常规训练，然后定义缺失变量为 autoencoder 输入中的搜索变量，通过自动微分优化，对可用特征的损失进行优化。通过这种方法，可以实现不同的输入和输出特征组合，无需再次训练 autoencoder。</li>
<li>results: 研究表明，这种方法在一种强不平滑的电子组件上工作良好，能够重构缺失的一个变量，并且可以处理多个缺失变量。<details>
<summary>Abstract</summary>
Existing black box modeling approaches in machine learning suffer from a fixed input and output feature combination. In this paper, a new approach to reconstruct missing variables in a set of time series is presented. An autoencoder is trained as usual with every feature on both sides and the neural network parameters are fixed after this training. Then, the searched variables are defined as missing variables at the autoencoder input and optimized via automatic differentiation. This optimization is performed with respect to the available features loss calculation. With this method, different input and output feature combinations of the trained model can be realized by defining the searched variables as missing variables and reconstructing them. The combination can be changed without training the autoencoder again. The approach is evaluated on the base of a strongly nonlinear electrical component. It is working well for one of four variables missing and generally even for multiple missing variables.
</details>
<details>
<summary>摘要</summary>
Traditional黑盒模型方法在机器学习中受到固定输入和输出特征组合的限制。在这篇论文中，一种新的方法用于重建时序序列中缺失的变量被介绍。一个自适应神经网络被训练得标准的方式，并且神经网络参数在训练后被固定。然后，搜索的变量被定义为自动encoder输入中缺失的变量，并通过自动微分优化。这种优化是基于可用特征损失计算。通过这种方法，不同的输入和输出特征组合可以被实现，只需要定义搜索变量为缺失变量，然后重建它们。这种组合可以更改无需再次训练自动encoder。该方法在一种强不平滑电子组件上进行评估，并且在一个变量缺失的情况下表现良好，甚至可以处理多个缺失变量。
</details></li>
</ul>
<hr>
<h2 id="Deciphering-Raw-Data-in-Neuro-Symbolic-Learning-with-Provable-Guarantees"><a href="#Deciphering-Raw-Data-in-Neuro-Symbolic-Learning-with-Provable-Guarantees" class="headerlink" title="Deciphering Raw Data in Neuro-Symbolic Learning with Provable Guarantees"></a>Deciphering Raw Data in Neuro-Symbolic Learning with Provable Guarantees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10487">http://arxiv.org/abs/2308.10487</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lue Tao, Yu-Xuan Huang, Wang-Zhou Dai, Yuan Jiang</li>
<li>for: 这篇论文旨在探讨神经符号系统的学习可能性，以及一种基于知识库的推理来优化神经网络模型的启示。</li>
<li>methods: 该论文提出了一种新的方法来 caracterize 知识库中的指导信号，并建立了一个判断知识库是否能够成功地促进学习的标准。</li>
<li>results: 实验结果表明，该方法可以有效地判断知识库的有效性，并且可以通过对知识库进行修改来提高学习的成功率。<details>
<summary>Abstract</summary>
Neuro-symbolic hybrid systems are promising for integrating machine learning and symbolic reasoning, where perception models are facilitated with information inferred from a symbolic knowledge base through logical reasoning. Despite empirical evidence showing the ability of hybrid systems to learn accurate perception models, the theoretical understanding of learnability is still lacking. Hence, it remains unclear why a hybrid system succeeds for a specific task and when it may fail given a different knowledge base. In this paper, we introduce a novel way of characterising supervision signals from a knowledge base, and establish a criterion for determining the knowledge's efficacy in facilitating successful learning. This, for the first time, allows us to address the two questions above by inspecting the knowledge base under investigation. Our analysis suggests that many knowledge bases satisfy the criterion, thus enabling effective learning, while some fail to satisfy it, indicating potential failures. Comprehensive experiments confirm the utility of our criterion on benchmark tasks.
</details>
<details>
<summary>摘要</summary>
Here is the text in Simplified Chinese:神经-符号 hybrid系统显示推荐使用机器学习和符号理解，其中感知模型得到了基于符号知识库的信息推理的帮助。 despite empirical evidence showing the ability of hybrid systems to learn accurate perception models, the theoretical understanding of learnability is still lacking. Therefore, it is unclear why a hybrid system might succeed or fail for a specific task, depending on the knowledge base used. In this paper, we propose a new way of characterizing supervision signals from a knowledge base and establish a criterion for determining the knowledge's effectiveness in facilitating successful learning. This allows us to address the two questions above by examining the knowledge base under investigation. Our analysis shows that many knowledge bases satisfy the criterion, enabling effective learning, while others fail to do so, indicating potential failures. Comprehensive experiments confirm the utility of our criterion on benchmark tasks.
</details></li>
</ul>
<hr>
<h2 id="Deep-Metric-Loss-for-Multimodal-Learning"><a href="#Deep-Metric-Loss-for-Multimodal-Learning" class="headerlink" title="Deep Metric Loss for Multimodal Learning"></a>Deep Metric Loss for Multimodal Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10486">http://arxiv.org/abs/2308.10486</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sehwan Moon, Hyunju Lee</li>
<li>for: 这篇论文的目的是提出一种新的多模式损失函数（MultiModal loss），用于多模式学习，以便更好地处理不同的数据模式。</li>
<li>methods: 这篇论文使用了一种新的损失函数，叫做MultiModal loss，它可以 subgroup instances 根据不同的数据模式，以提高多模式学习的性能。</li>
<li>results: 在实验中，这篇论文显示了MultiModal loss可以对四个真实的多模式数据集进行改进，并且可以避免过拟合和不精确地预测。<details>
<summary>Abstract</summary>
Multimodal learning often outperforms its unimodal counterparts by exploiting unimodal contributions and cross-modal interactions. However, focusing only on integrating multimodal features into a unified comprehensive representation overlooks the unimodal characteristics. In real data, the contributions of modalities can vary from instance to instance, and they often reinforce or conflict with each other. In this study, we introduce a novel \text{MultiModal} loss paradigm for multimodal learning, which subgroups instances according to their unimodal contributions. \text{MultiModal} loss can prevent inefficient learning caused by overfitting and efficiently optimize multimodal models. On synthetic data, \text{MultiModal} loss demonstrates improved classification performance by subgrouping difficult instances within certain modalities. On four real multimodal datasets, our loss is empirically shown to improve the performance of recent models. Ablation studies verify the effectiveness of our loss. Additionally, we show that our loss generates a reliable prediction score for each modality, which is essential for subgrouping. Our \text{MultiModal} loss is a novel loss function to subgroup instances according to the contribution of modalities in multimodal learning and is applicable to a variety of multimodal models with unimodal decisions. Our code is available at https://github.com/SehwanMoon/MultiModalLoss.
</details>
<details>
<summary>摘要</summary>
多模态学习经常超越单模态对手，通过利用单模态贡献和跨模态互动来提高性能。然而，只是将多模态特征集成到一个综合表示中，忽略了单模态特征。在实际数据中，不同模式之间的贡献可能会随着实例而变化，并且经常强制或冲突。在本研究中，我们提出了一种新的多模态损失函数（MultiModal loss），用于多模态学习。这种损失函数将实例 subgrouping 根据各个模式的贡献。MultiModal loss 可以避免过拟合和有效地优化多模态模型。在 sintetic 数据上，我们证明了 MultiModal loss 可以提高分类性能。在四个真实多模态数据集上，我们的损失函数被证明可以提高最近的模型的性能。我们还进行了ablation 研究，证明了我们的损失函数的有效性。此外，我们还证明了我们的损失函数可以生成可靠的预测分数，这是 subgrouping 的关键。我们的 MultiModal loss 是一种新的损失函数，用于根据多模态中的贡献 subgrouping 实例，适用于多种多模态模型。我们的代码可以在 <https://github.com/SehwanMoon/MultiModalLoss> 上获取。
</details></li>
</ul>
<hr>
<h2 id="An-Effective-Method-using-Phrase-Mechanism-in-Neural-Machine-Translation"><a href="#An-Effective-Method-using-Phrase-Mechanism-in-Neural-Machine-Translation" class="headerlink" title="An Effective Method using Phrase Mechanism in Neural Machine Translation"></a>An Effective Method using Phrase Mechanism in Neural Machine Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10482">http://arxiv.org/abs/2308.10482</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/phuongnm94/PhraseTransformer">https://github.com/phuongnm94/PhraseTransformer</a></li>
<li>paper_authors: Phuong Minh Nguyen, Le Minh Nguyen</li>
<li>for: 本研究旨在提高基于Transformer的Neural Machine Translation（NMT）系统，特别是在 parallel corpora 上的 Vietnamese-Chinese 语对。</li>
<li>methods: 本研究使用了一种新的短语机制，即PhraseTransformer，以提高基于Transformer的NMT系统的性能。</li>
<li>results: 我们在 VLSP 2022 竞赛的 MT 数据集上进行了实验，并取得了 Vietnamese to Chinese 的 BLEU 分数为 35.3，以及 Chinese to Vietnamese 的 BLEU 分数为 33.2。<details>
<summary>Abstract</summary>
Machine Translation is one of the essential tasks in Natural Language Processing (NLP), which has massive applications in real life as well as contributing to other tasks in the NLP research community. Recently, Transformer -based methods have attracted numerous researchers in this domain and achieved state-of-the-art results in most of the pair languages. In this paper, we report an effective method using a phrase mechanism, PhraseTransformer, to improve the strong baseline model Transformer in constructing a Neural Machine Translation (NMT) system for parallel corpora Vietnamese-Chinese. Our experiments on the MT dataset of the VLSP 2022 competition achieved the BLEU score of 35.3 on Vietnamese to Chinese and 33.2 BLEU scores on Chinese to Vietnamese data. Our code is available at https://github.com/phuongnm94/PhraseTransformer.
</details>
<details>
<summary>摘要</summary>
机器翻译是自然语言处理（NLP）领域的一项重要任务，它在实际生活中有很大的应用前景，同时也对NLP研究领域中的其他任务产生了贡献。现在，基于Transformer算法的方法在这个领域中吸引了大量研究人员，并在大多数对应语言的情况下达到了状态的艺术级结果。在这篇论文中，我们报道了一种使用短语机制，PhraseTransformer，以提高基eline模型Transformer在构建 neural machine translation（NMT）系统的方法。我们在VLSP 2022大赛的MT数据集上进行了实验，得到了Vietnamese to Chinese的BLEU分数为35.3，以及Chinese to Vietnamese的BLEU分数为33.2。我们的代码可以在GitHub上找到：https://github.com/phuongnm94/PhraseTransformer。
</details></li>
</ul>
<hr>
<h2 id="Deep-Semi-supervised-Anomaly-Detection-with-Metapath-based-Context-Knowledge"><a href="#Deep-Semi-supervised-Anomaly-Detection-with-Metapath-based-Context-Knowledge" class="headerlink" title="Deep Semi-supervised Anomaly Detection with Metapath-based Context Knowledge"></a>Deep Semi-supervised Anomaly Detection with Metapath-based Context Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10918">http://arxiv.org/abs/2308.10918</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hwan Kim, Junghoon Kim, Byung Suk Lee, Sungsu Lim</li>
<li>for: 本研究旨在提出一种基于中维度semi-supervised learning的图像异常检测方法，以解决现有方法的局限性。</li>
<li>methods: 本方法基于GCN层在编码器和解码器中，有效地传递了上下文信息 между异常和正常节点。该方法还使用了特制的异常社区和中维度信息来增强学习异常结构和属性的差异。</li>
<li>results: 经过对七个真实网络的全面实验，本研究证明了MSAD方法在比特当前技术的情况下显著超越。这些成功的结果为未来的研究提供了道路，关注中维度异常检测的优化和分析，以进一步提高图像异常检测的效果。<details>
<summary>Abstract</summary>
Graph anomaly detection has attracted considerable attention in recent years. This paper introduces a novel approach that leverages metapath-based semi-supervised learning, addressing the limitations of previous methods. We present a new framework, Metapath-based Semi-supervised Anomaly Detection (MSAD), incorporating GCN layers in both the encoder and decoder to efficiently propagate context information between abnormal and normal nodes. The design of metapath-based context information and a specifically crafted anomaly community enhance the process of learning differences in structures and attributes, both globally and locally. Through a comprehensive set of experiments conducted on seven real-world networks, this paper demonstrates the superiority of the MSAD method compared to state-of-the-art techniques. The promising results of this study pave the way for future investigations, focusing on the optimization and analysis of metapath patterns to further enhance the effectiveness of anomaly detection on attributed networks.
</details>
<details>
<summary>摘要</summary>
GRAPH anomaly detection has attracted considerable attention in recent years. This paper introduces a novel approach that leverages metapath-based semi-supervised learning, addressing the limitations of previous methods. We present a new framework, Metapath-based Semi-supervised Anomaly Detection (MSAD), incorporating GCN layers in both the encoder and decoder to efficiently propagate context information between abnormal and normal nodes. The design of metapath-based context information and a specifically crafted anomaly community enhance the process of learning differences in structures and attributes, both globally and locally. Through a comprehensive set of experiments conducted on seven real-world networks, this paper demonstrates the superiority of the MSAD method compared to state-of-the-art techniques. The promising results of this study pave the way for future investigations, focusing on the optimization and analysis of metapath patterns to further enhance the effectiveness of anomaly detection on attributed networks.Here's the word-for-word translation of the text into Simplified Chinese: GRAPH anomaly detection 在最近几年内吸引了较大的关注。这篇论文介绍了一种新的方法，基于мета路强化 semi-supervised learning，解决先前方法的局限性。我们提出了一个新的框架，基于 мета路强化 semi-supervised anomaly detection (MSAD)，在编码器和解码器中嵌入GCN层，有效地传递context信息 между异常和正常节点。基于 мета路强化的context信息和特定设计的异常社区，使得学习不同结构和属性的差异，global和local都得到了加强。通过对七个实际网络进行了全面的实验，这篇论文证明了 MSAD 方法与先前技术相比，具有更高的效果。这些有前途的结果为将来的研究提供了平台，集中于优化和分析 мета路征 Patterns 以进一步提高异常检测在归属网络上的效果。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Parameter-Efficient-Fine-Tuning-Techniques-for-Code-Generation-with-Large-Language-Models"><a href="#Exploring-Parameter-Efficient-Fine-Tuning-Techniques-for-Code-Generation-with-Large-Language-Models" class="headerlink" title="Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation with Large Language Models"></a>Exploring Parameter-Efficient Fine-Tuning Techniques for Code Generation with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10462">http://arxiv.org/abs/2308.10462</a></li>
<li>repo_url: None</li>
<li>paper_authors: Martin Weyssow, Xin Zhou, Kisub Kim, David Lo, Houari Sahraoui</li>
<li>for: 本研究旨在探讨大语言模型（LLMs）在自然语言意图下生成代码的情况，特别是在资源匮乏的情况下使用 Parameter-Efficient Fine-Tuning（PEFT）技术来特化模型。</li>
<li>methods: 本研究使用了多种PEFT技术，包括简单的权重调整、权重学习率调整和权重梯度衰减等，以提高模型的特化性和性能。</li>
<li>results: 研究结果表明，PEFT技术可以有效地提高LLMs的特化性和性能，并且可以降低计算成本。此外，PEFT技术在不同的LLMs中的表现也有一定的相似性和稳定性。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) possess impressive capabilities to generate meaningful code snippets given natural language intents in zero-shot, i.e., without the need for specific fine-tuning. In the perspective of unleashing their full potential, prior work has demonstrated the benefits of fine-tuning the models to task-specific data. However, fine-tuning process demands heavy computational costs and is intractable when resources are scarce, especially for models with billions of parameters. In light of these challenges, previous studies explored In-Context Learning (ICL) as an effective strategy to generate contextually appropriate code without fine-tuning. However, it operates at inference time and does not involve learning task-specific parameters, potentially limiting the model's performance on downstream tasks. In this context, we foresee that Parameter-Efficient Fine-Tuning (PEFT) techniques carry a high potential for efficiently specializing LLMs to task-specific data. In this paper, we deliver a comprehensive study of LLMs with the impact of PEFT techniques under the automated code generation scenario. Our experimental results reveal the superiority and potential of such techniques over ICL on a wide range of LLMs in reducing the computational burden and improving performance. Therefore, the study opens opportunities for broader applications of PEFT in software engineering scenarios.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）拥有出色的能力生成相关代码块，无需特定的精细调整。在激发其全部潜力的视角下，先前的研究表明了特定任务数据的调整可以提高模型性能。然而，调整过程具有重大的计算成本，特别是当参数数量庞大时，尤其是当资源匮乏时。为此，先前的研究探索了在下游任务中进行具体任务学习（ICL），以生成Contextually appropriate的代码，不需要特定的调整。然而，ICL在推理时运行，并不涉及学习特定任务参数，可能会限制模型在下游任务中的表现。在这种情况下，我们认为Parameter-Efficient Fine-Tuning（PEFT）技术具有高效地特化LLMs到特定任务数据的潜力。在这篇论文中，我们进行了LLMs在自动代码生成场景下的PEFT技术的全面研究。我们的实验结果表明，PEFT技术在许多LLMs上具有准确性和可扩展性，在减少计算成本和提高性能方面表现出色。因此，这种研究开创了在软件工程场景中PEFT技术的更广泛应用前景。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Local-Steps-Federated-Learning-with-Differential-Privacy-Driven-by-Convergence-Analysis"><a href="#Adaptive-Local-Steps-Federated-Learning-with-Differential-Privacy-Driven-by-Convergence-Analysis" class="headerlink" title="Adaptive Local Steps Federated Learning with Differential Privacy Driven by Convergence Analysis"></a>Adaptive Local Steps Federated Learning with Differential Privacy Driven by Convergence Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10457">http://arxiv.org/abs/2308.10457</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinpeng Ling, Jie Fu, Zhili Chen</li>
<li>for: 这篇论文是关于如何在分布式机器学习（Federated Learning，FL）中保护敏感资料，并且在资源有限的情况下实现隐私保证。</li>
<li>methods: 这篇论文使用了差异攻击（differential privacy）来保护敏感资料，并且提出了一个适应性的地方步骤差异隐私 federated learning（ALS-DPFL）算法。</li>
<li>results: 这篇论文通过实验表明，ALS-DPFL算法可以在资源有限的情况下，实现隐私保证并且获得良好的性能。<details>
<summary>Abstract</summary>
Federated Learning (FL) is a distributed machine learning technique that allows model training among multiple devices or organizations without sharing data. However, while FL ensures that the raw data is not directly accessible to external adversaries, adversaries can still obtain some statistical information about the data through differential attacks. Differential Privacy (DP) has been proposed, which adds noise to the model or gradients to prevent adversaries from inferring private information from the transmitted parameters. We reconsider the framework of differential privacy federated learning in resource-constrained scenarios (privacy budget and communication resources). We analyze the convergence of federated learning with differential privacy (DPFL) on resource-constrained scenarios and propose an Adaptive Local Steps Differential Privacy Federated Learning (ALS-DPFL) algorithm. We experiment our algorithm on the FashionMNIST and Cifar-10 datasets and achieve quite good performance relative to previous work.
</details>
<details>
<summary>摘要</summary>
联邦学习（FL）是一种分布式机器学习技术，让多个设备或组织共同训练模型，不需要分享数据。然而，FL可以保证数据没有直接泄露到外部攻击者，但攻击者可以从传输的模型或梯度中获得一些关于数据的统计信息。对于这种情况，提出了几何秘𫓾（DP），它将加入随机误差到模型或梯度中，以防止攻击者从传输的参数中获取私人信息。我们在资源有限的情况下重新考虑了几何秘𫓾联邦学习（DPFL）的框架，并分析了DPFL在资源有限情况下的整合性。我们还提出了一个适应性本地步骤几何秘𫓾联邦学习（ALS-DPFL）算法。我们对于时装MNIST和Cifar-10 datasets进行了实验，并获得了与前一些工作相对的很好的性能。
</details></li>
</ul>
<hr>
<h2 id="DOMINO-Domain-aware-Loss-Regularization-for-Deep-Learning-Generalizability"><a href="#DOMINO-Domain-aware-Loss-Regularization-for-Deep-Learning-Generalizability" class="headerlink" title="DOMINO++: Domain-aware Loss Regularization for Deep Learning Generalizability"></a>DOMINO++: Domain-aware Loss Regularization for Deep Learning Generalizability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10453">http://arxiv.org/abs/2308.10453</a></li>
<li>repo_url: None</li>
<li>paper_authors: Skylar E. Stolte, Kyle Volle, Aprinda Indahlastari, Alejandro Albizu, Adam J. Woods, Kevin Brink, Matthew Hale, Ruogu Fang</li>
<li>For: This paper focuses on improving the out-of-distribution (OOD) generalization of deep learning (DL) models for reliable deployment in real-world applications.* Methods: The proposed method, DOMINO++, utilizes dual-guidance and dynamic domain-aware loss regularization to integrate expert-guided and data-guided knowledge for OOD generalization. Unlike previous methods, DOMINO++, adapts the regularization rate dynamically and improves the performance on OOD data.* Results: The proposed method outperforms the baseline model and DOMINO on OOD data, including synthetic noisy and rotated datasets, as well as real data from a different MRI scanner. This demonstrates the potential of DOMINO++ for improving the trustworthy deployment of DL models in clinical applications.Here is the simplified Chinese text for the three key points:* For: 这篇论文关注深度学习（DL）模型在真实应用中可靠部署的外部数据泛化问题。* Methods: 提议的方法是 DOMINO++，它利用双引导和动态领域相关损失补偿来结合专家指导和数据指导知识来提高OOD泛化性能。与之前的方法不同的是，DOMION++ 适应常量补偿的幂等因子和补偿率。* Results: 提议的方法在OOD数据上表现出色，比基eline模型和 DOMINO 更高。OOD数据包括随机噪音和旋转数据集，以及来自不同MRI扫描仪的真实数据。这表明 DOMINO++ 可能为深度学习模型在临床应用中可靠部署提供了可能。<details>
<summary>Abstract</summary>
Out-of-distribution (OOD) generalization poses a serious challenge for modern deep learning (DL). OOD data consists of test data that is significantly different from the model's training data. DL models that perform well on in-domain test data could struggle on OOD data. Overcoming this discrepancy is essential to the reliable deployment of DL. Proper model calibration decreases the number of spurious connections that are made between model features and class outputs. Hence, calibrated DL can improve OOD generalization by only learning features that are truly indicative of the respective classes. Previous work proposed domain-aware model calibration (DOMINO) to improve DL calibration, but it lacks designs for model generalizability to OOD data. In this work, we propose DOMINO++, a dual-guidance and dynamic domain-aware loss regularization focused on OOD generalizability. DOMINO++ integrates expert-guided and data-guided knowledge in its regularization. Unlike DOMINO which imposed a fixed scaling and regularization rate, DOMINO++ designs a dynamic scaling factor and an adaptive regularization rate. Comprehensive evaluations compare DOMINO++ with DOMINO and the baseline model for head tissue segmentation from magnetic resonance images (MRIs) on OOD data. The OOD data consists of synthetic noisy and rotated datasets, as well as real data using a different MRI scanner from a separate site. DOMINO++'s superior performance demonstrates its potential to improve the trustworthy deployment of DL on real clinical data.
</details>
<details>
<summary>摘要</summary>
现代深度学习（DL）面临着出版物领域（Out-of-distribution，OOD）泛化的严重挑战。OOD数据包括测试数据，与DL模型训练数据有显著差异。DL模型在域内测试数据上表现良好，但在OOD数据上却表现不佳。解决这个差异是DL模型可靠部署的必要条件。正确地调整DL模型可以减少模型特征与类输出之间的假Connection。因此，调整DL可以提高OOD泛化，只学习真正指示各类的特征。之前的工作提出了领域意识模型calibration（DOMINO）以提高DL calibration，但它缺乏对OOD数据的设计。在这种工作中，我们提出了DOMINO++，一种双向引导和动态领域意识损失补偿。DOMINO++结合了专家指导和数据指导的知识在其补偿中。与DOMINO不同的是，DOMINO++不设置固定的缩放因子和补偿率，而是动态设置缩放因子和适应的补偿率。对DOMINO++与DOMINO以及基eline模型进行了广泛的评估，用于头部组织分割MRIs的OOD数据。OOD数据包括Synthetic噪音和旋转数据集，以及实际数据使用不同MRI扫描仪从另一个站点。DOMINO++的优秀表现表明它在真实的临床数据上可靠部署DL模型。
</details></li>
</ul>
<hr>
<h2 id="PACS-Prediction-and-analysis-of-cancer-subtypes-from-multi-omics-data-based-on-a-multi-head-attention-mechanism-model"><a href="#PACS-Prediction-and-analysis-of-cancer-subtypes-from-multi-omics-data-based-on-a-multi-head-attention-mechanism-model" class="headerlink" title="PACS: Prediction and analysis of cancer subtypes from multi-omics data based on a multi-head attention mechanism model"></a>PACS: Prediction and analysis of cancer subtypes from multi-omics data based on a multi-head attention mechanism model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10917">http://arxiv.org/abs/2308.10917</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liangrui Pan, Dazheng Liu, Zhichao Feng, Wenjuan Liu, Shaoliang Peng<br>for: 这个研究旨在精确分类不同癌症亚型，帮助医生选择最适合的治疗方案，提高治疗效果，并提供更准确的病人存活预测。methods: 本研究提出了一个监督式多头注意力机制模型（SMA），使用多头注意力嵌入和特征分享模块，成功地学习多种资料的全球和本地特征信息。其中，多头注意力嵌入可以实现当前资料的弹性转换，提高模型的准确性和稳定性；特征分享模块可以将不同类型的资料共享和结合，提高模型的表现力。results: 透过广泛的实验验证，SMA模型在资料验证、单细胞资料和癌症多种资料中实现了最高准确性、F1权重、F1几何和精确的癌症亚型分类，比AE、CNN和GNN-based模型高。因此，我们对未来多种资料的研究做出了贡献。<details>
<summary>Abstract</summary>
Due to the high heterogeneity and clinical characteristics of cancer, there are significant differences in multi-omic data and clinical characteristics among different cancer subtypes. Therefore, accurate classification of cancer subtypes can help doctors choose the most appropriate treatment options, improve treatment outcomes, and provide more accurate patient survival predictions. In this study, we propose a supervised multi-head attention mechanism model (SMA) to classify cancer subtypes successfully. The attention mechanism and feature sharing module of the SMA model can successfully learn the global and local feature information of multi-omics data. Second, it enriches the parameters of the model by deeply fusing multi-head attention encoders from Siamese through the fusion module. Validated by extensive experiments, the SMA model achieves the highest accuracy, F1 macroscopic, F1 weighted, and accurate classification of cancer subtypes in simulated, single-cell, and cancer multiomics datasets compared to AE, CNN, and GNN-based models. Therefore, we contribute to future research on multiomics data using our attention-based approach.
</details>
<details>
<summary>摘要</summary>
因为肿瘤多样性和临床特征的高度不同，不同的肿瘤亚型之间存在显著的多 Omics 数据和临床特征差异。因此，正确地分类肿瘤亚型可以帮助医生选择最合适的治疗方案，提高治疗效果，并为患者提供更加准确的存活预测。在本研究中，我们提议一种supervised多头注意机制模型（SMA），成功地分类肿瘤亚型。注意机制和特征共享模块在SMA模型中可以学习多 Omics 数据的全球和本地特征信息。其次，通过深度融合多头注意编码器，增强模型参数的SMA模型。经验证了广泛的实验，SMA模型在 simulate、单细胞和肿瘤多Omics 数据集上实现了最高精度、F1大致、F1平均和正确地分类肿瘤亚型，比AE、CNN和GNN-based模型高。因此，我们对未来的多Omics 数据研究做出了贡献。
</details></li>
</ul>
<hr>
<h2 id="CVFC-Attention-Based-Cross-View-Feature-Consistency-for-Weakly-Supervised-Semantic-Segmentation-of-Pathology-Images"><a href="#CVFC-Attention-Based-Cross-View-Feature-Consistency-for-Weakly-Supervised-Semantic-Segmentation-of-Pathology-Images" class="headerlink" title="CVFC: Attention-Based Cross-View Feature Consistency for Weakly Supervised Semantic Segmentation of Pathology Images"></a>CVFC: Attention-Based Cross-View Feature Consistency for Weakly Supervised Semantic Segmentation of Pathology Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10449">http://arxiv.org/abs/2308.10449</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liangrui Pan, Lian Wang, Zhichao Feng, Liwen Xu, Shaoliang Peng</li>
<li>For: 本研究旨在提出一种基于注意力机制的跨视图特征一致朴素pseudoMask生成框架CVFC，以解决 histopathology图像分割需要高质量Mask的问题。* Methods: CVFC是一个三极结构的端到端框架，包括两个 Resnet38 和一个 Resnet50，以及独立支持多比例缩放的独立支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例缩放的支持多比例�<details>
<summary>Abstract</summary>
Histopathology image segmentation is the gold standard for diagnosing cancer, and can indicate cancer prognosis. However, histopathology image segmentation requires high-quality masks, so many studies now use imagelevel labels to achieve pixel-level segmentation to reduce the need for fine-grained annotation. To solve this problem, we propose an attention-based cross-view feature consistency end-to-end pseudo-mask generation framework named CVFC based on the attention mechanism. Specifically, CVFC is a three-branch joint framework composed of two Resnet38 and one Resnet50, and the independent branch multi-scale integrated feature map to generate a class activation map (CAM); in each branch, through down-sampling and The expansion method adjusts the size of the CAM; the middle branch projects the feature matrix to the query and key feature spaces, and generates a feature space perception matrix through the connection layer and inner product to adjust and refine the CAM of each branch; finally, through the feature consistency loss and feature cross loss to optimize the parameters of CVFC in co-training mode. After a large number of experiments, An IoU of 0.7122 and a fwIoU of 0.7018 are obtained on the WSSS4LUAD dataset, which outperforms HistoSegNet, SEAM, C-CAM, WSSS-Tissue, and OEEM, respectively.
</details>
<details>
<summary>摘要</summary>
《 histopathology 图像分割是诊断癌症的标准方法，可以预测癌症诊断。但 histopathology 图像分割需要高质量的面Mask，因此许多研究现在使用图像水平标签来实现像素级分割，以降低细致的注解量。为解决这个问题，我们提出了一种基于注意机制的跨视图特征一致末级 pseudo-Mask 生成框架 named CVFC。具体来说，CVFC 是一个三棵分支结构，包括两个 Resnet38 和一个 Resnet50，以及独立分支多缩放维度集成特征图来生成类Activation Map (CAM)。在每个棵分支中，通过下降和扩展方法调整特征图的大小；中间棵分支将特征矩阵 проек到查询和关键特征空间，并生成特征空间感知矩阵通过连接层和内积来调整和细化每个棵分支的 CAM；最后，通过特征一致损失和特征交叉损失来优化 CVFC 的参数。经过大量实验，在 WSSS4LUAD 数据集上，CVFC 实现了 IoU 0.7122 和 fwIoU 0.7018，超越 HistoSegNet、SEAM、C-CAM、WSSS-Tissue 和 OEEM，分别。
</details></li>
</ul>
<hr>
<h2 id="DySuse-Susceptibility-Estimation-in-Dynamic-Social-Networks"><a href="#DySuse-Susceptibility-Estimation-in-Dynamic-Social-Networks" class="headerlink" title="DySuse: Susceptibility Estimation in Dynamic Social Networks"></a>DySuse: Susceptibility Estimation in Dynamic Social Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10442">http://arxiv.org/abs/2308.10442</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yingdan Shi, Jingya Zhou, Congcong Zhang</li>
<li>for: 预测社交网络中流行的潜在影响范围。</li>
<li>methods: 提出了一种基于动态图 embedding 技术的框架，名为 DySuse，以独立捕捉每幅图像的结构信息，并通过进步机制和自注意力块来耦合结构和时间信息。</li>
<li>results: 实验结果表明，我们的框架在多种流行传播模型下有较高的预测性能，并且超过了现有的动态图 embedding 模型。<details>
<summary>Abstract</summary>
Influence estimation aims to predict the total influence spread in social networks and has received surged attention in recent years. Most current studies focus on estimating the total number of influenced users in a social network, and neglect susceptibility estimation that aims to predict the probability of each user being influenced from the individual perspective. As a more fine-grained estimation task, susceptibility estimation is full of attractiveness and practical value. Based on the significance of susceptibility estimation and dynamic properties of social networks, we propose a task, called susceptibility estimation in dynamic social networks, which is even more realistic and valuable in real-world applications. Susceptibility estimation in dynamic networks has yet to be explored so far and is computationally intractable to naively adopt Monte Carlo simulation to obtain the results. To this end, we propose a novel end-to-end framework DySuse based on dynamic graph embedding technology. Specifically, we leverage a structural feature module to independently capture the structural information of influence diffusion on each single graph snapshot. Besides, {we propose the progressive mechanism according to the property of influence diffusion,} to couple the structural and temporal information during diffusion tightly. Moreover, a self-attention block {is designed to} further capture temporal dependency by flexibly weighting historical timestamps. Experimental results show that our framework is superior to the existing dynamic graph embedding models and has satisfactory prediction performance in multiple influence diffusion models.
</details>
<details>
<summary>摘要</summary>
社会网络的影响估计已经在最近几年内收到了极大的关注，大多数当前的研究都是关注社会网络中总的影响范围的估计，而忽略了每个用户从个人角度上的抵触可能性的估计。作为一个更加细化的估计任务，抵触估计充满了吸引力和实际价值。基于社会网络的动态特性和抵触估计的重要性，我们提出了一项任务，即动态社会网络中的抵触估计任务，这个任务更加真实和有价值在实际应用中。动态网络中的抵触估计还没有被探索过，Naive使用Monte Carlo simulations来获取结果是计算拥堵的。为此，我们提出了一个新的框架，即 DySuse，基于动态图嵌入技术。specifically，我们利用一个结构特征模块来独立地捕捉影响扩散在每个单图Snapshot中的结构信息。另外，我们提出了一种进步机制，根据影响扩散的性质，将结构和时间信息在扩散过程中紧密相连。此外，我们还设计了一个自注意阶段，以捕捉流传过程中的时间相关性。实验结果表明，我们的框架在多种影响扩散模型下具有优秀的预测性能，与现有的动态图嵌入模型相比，有显著的优势。
</details></li>
</ul>
<hr>
<h2 id="Approximately-Equivariant-Graph-Networks"><a href="#Approximately-Equivariant-Graph-Networks" class="headerlink" title="Approximately Equivariant Graph Networks"></a>Approximately Equivariant Graph Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10436">http://arxiv.org/abs/2308.10436</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nhuang37/approx_equivariant_graph_nets">https://github.com/nhuang37/approx_equivariant_graph_nets</a></li>
<li>paper_authors: Ningyuan Huang, Ron Levie, Soledad Villar</li>
<li>for: 这个论文主要针对 Graph Neural Networks (GNNs) 的几何对称性问题，具体来说是研究 GNNs 在图像上的学习问题。</li>
<li>methods: 这篇论文使用了 Graph Neural Networks (GNNs) 来学习图像上的信号，并对 GNNs 的几何对称性进行了研究。</li>
<li>results: 该论文通过对各种图像上的信号进行学习，并分析了 GNNs 的几何对称性，提出了一种基于自动同构的几何对称性约束，并证明了这种约束可以提高 GNNs 的泛化性能。<details>
<summary>Abstract</summary>
Graph neural networks (GNNs) are commonly described as being permutation equivariant with respect to node relabeling in the graph. This symmetry of GNNs is often compared to the translation equivariance symmetry of Euclidean convolution neural networks (CNNs). However, these two symmetries are fundamentally different: The translation equivariance of CNNs corresponds to symmetries of the fixed domain acting on the image signal (sometimes known as active symmetries), whereas in GNNs any permutation acts on both the graph signals and the graph domain (sometimes described as passive symmetries). In this work, we focus on the active symmetries of GNNs, by considering a learning setting where signals are supported on a fixed graph. In this case, the natural symmetries of GNNs are the automorphisms of the graph. Since real-world graphs tend to be asymmetric, we relax the notion of symmetries by formalizing approximate symmetries via graph coarsening. We present a bias-variance formula that quantifies the tradeoff between the loss in expressivity and the gain in the regularity of the learned estimator, depending on the chosen symmetry group. To illustrate our approach, we conduct extensive experiments on image inpainting, traffic flow prediction, and human pose estimation with different choices of symmetries. We show theoretically and empirically that the best generalization performance can be achieved by choosing a suitably larger group than the graph automorphism group, but smaller than the full permutation group.
</details>
<details>
<summary>摘要</summary>
图 neural network (GNN) 常被描述为对节点重新标记的图有 permutation 对称性。这种 GNN 的对称性与图像 convolution neural network (CNN) 中的平移对称性有所不同：图像 CNN 中的平移对称性是图像信号上的活动对称性，而 GNN 中任意 permutation 都会影响图像信号和图像Domain（有时被称为被动对称性）。在这项工作中，我们关注 GNN 中的活动对称性，通过考虑固定图上支持的信号来进行学习设定。在这种情况下，GNN 的自然对称性是图形自动同构。由于实际的图都很偏 asymmetric，我们将对称性的定义放松，通过图像粗化来形式化approximate symmetries。我们提出了一个 bias-variance 方程，这方程量化了在选择的对称性组中loss in expressivity和学习的regulatory gain之间的负责任性。为了证明我们的方法，我们在图像填充、交通流预测和人姿估计中进行了广泛的实验，并证明了理论和实验上，可以通过选择合适的对称性组来获得最佳的总结性表现。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-Robust-to-Byzantine-Attacks-Achieving-Zero-Optimality-Gap"><a href="#Federated-Learning-Robust-to-Byzantine-Attacks-Achieving-Zero-Optimality-Gap" class="headerlink" title="Federated Learning Robust to Byzantine Attacks: Achieving Zero Optimality Gap"></a>Federated Learning Robust to Byzantine Attacks: Achieving Zero Optimality Gap</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10427">http://arxiv.org/abs/2308.10427</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiyuan Zuo, Rongfei Fan, Han Hu, Ning Zhang, Shimin Gong</li>
<li>for: 提出了一种鲁棒的聚合方法，用于防止Byzantine攻击的 federated learning (FL)</li>
<li>methods: 每个用户首先更新模型参数，然后直接将更新后的参数传输到聚合中心，减少了聚合中心和用户之间的交互次数，并且允许每个用户在不同迭代中设置自己的训练参数，从而减轻计算负担。聚合中心使用几何平均来组合来自每个用户的模型参数。</li>
<li>results: 证明了我们提出的方法可以具有零优化差和线性收敛，只要Byzantine攻击者的比例小于一半。数字结果也证明了我们的方法的有效性。<details>
<summary>Abstract</summary>
In this paper, we propose a robust aggregation method for federated learning (FL) that can effectively tackle malicious Byzantine attacks. At each user, model parameter is firstly updated by multiple steps, which is adjustable over iterations, and then pushed to the aggregation center directly. This decreases the number of interactions between the aggregation center and users, allows each user to set training parameter in a flexible way, and reduces computation burden compared with existing works that need to combine multiple historical model parameters. At the aggregation center, geometric median is leveraged to combine the received model parameters from each user. Rigorous proof shows that zero optimality gap is achieved by our proposed method with linear convergence, as long as the fraction of Byzantine attackers is below half. Numerical results verify the effectiveness of our proposed method.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种鲁棒的聚合方法 для federated learning (FL)，可以有效地应对恶意的拜尼阶攻击。每个用户的模型参数首先通过多个步骤进行更新，这些步骤可以在迭代过程中调整，然后直接将更新后的模型参数Push到聚合中心。这将减少聚合中心和用户之间的交互次数，让每个用户可以自由地设置训练参数，并且比现有的方法减少计算负担。在聚合中心，我们使用 геометрический médian来聚合来自每个用户的接收到的模型参数。严格的证明显示，我们的提议方法可以在拜尼攻击者占用 fraction 下于半的情况下 achieves zero optimality gap，并且 linear convergence 。数字结果证明了我们的提议方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Spatio-Temporal-Adaptive-Embedding-Makes-Vanilla-Transformer-SOTA-for-Traffic-Forecasting"><a href="#Spatio-Temporal-Adaptive-Embedding-Makes-Vanilla-Transformer-SOTA-for-Traffic-Forecasting" class="headerlink" title="Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer SOTA for Traffic Forecasting"></a>Spatio-Temporal Adaptive Embedding Makes Vanilla Transformer SOTA for Traffic Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10425">http://arxiv.org/abs/2308.10425</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xdzhelheim/staeformer">https://github.com/xdzhelheim/staeformer</a></li>
<li>paper_authors: Hangchen Liu, Zheng Dong, Renhe Jiang, Jiewen Deng, Jinliang Deng, Quanjun Chen, Xuan Song</li>
<li>for: 本研究旨在提出一种基于封装的变换器，以优化 traffic forecasting  task 的性能。</li>
<li>methods: 本研究使用了一种新的组件 called spatio-temporal adaptive embedding，该组件可以帮助模型更好地捕捉 traffic 时序数据中的空间 temporal 关系。</li>
<li>results: 研究表明，使用 STAEformer 可以在五个实际 traffic forecasting 数据集上 achieve state-of-the-art 性能。此外，实验还表明了 spatio-temporal adaptive embedding 在 traffic forecasting 中的重要作用，即能够有效地捕捉 traffic 时序数据中的内在空间 temporal 关系和时间序列信息。<details>
<summary>Abstract</summary>
With the rapid development of the Intelligent Transportation System (ITS), accurate traffic forecasting has emerged as a critical challenge. The key bottleneck lies in capturing the intricate spatio-temporal traffic patterns. In recent years, numerous neural networks with complicated architectures have been proposed to address this issue. However, the advancements in network architectures have encountered diminishing performance gains. In this study, we present a novel component called spatio-temporal adaptive embedding that can yield outstanding results with vanilla transformers. Our proposed Spatio-Temporal Adaptive Embedding transformer (STAEformer) achieves state-of-the-art performance on five real-world traffic forecasting datasets. Further experiments demonstrate that spatio-temporal adaptive embedding plays a crucial role in traffic forecasting by effectively capturing intrinsic spatio-temporal relations and chronological information in traffic time series.
</details>
<details>
<summary>摘要</summary>
随着智能交通系统（ITS）的快速发展，准确的交通预测已成为一项关键挑战。关键瓶颈在于捕捉复杂的空间-时间交通模式。在过去几年，许多基于神经网络的复杂架构的方法已经被提出来解决这个问题。然而，网络架构的提高不断带来逐渐减少的性能提升。在本研究中，我们提出了一种新的组件 called 空间-时间适应嵌入（STAEformer），它可以在基于 transformer 的模型中实现出色的表现。我们的提posed STAEformer 在五个实际交通预测数据集上实现了状态机器的性能。进一步的实验表明，空间-时间适应嵌入在交通预测中发挥了关键的作用，能够有效地捕捉交通时序序列中的内在空间-时间关系和时间信息。
</details></li>
</ul>
<hr>
<h2 id="TokenSplit-Using-Discrete-Speech-Representations-for-Direct-Refined-and-Transcript-Conditioned-Speech-Separation-and-Recognition"><a href="#TokenSplit-Using-Discrete-Speech-Representations-for-Direct-Refined-and-Transcript-Conditioned-Speech-Separation-and-Recognition" class="headerlink" title="TokenSplit: Using Discrete Speech Representations for Direct, Refined, and Transcript-Conditioned Speech Separation and Recognition"></a>TokenSplit: Using Discrete Speech Representations for Direct, Refined, and Transcript-Conditioned Speech Separation and Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10415">http://arxiv.org/abs/2308.10415</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hakan Erdogan, Scott Wisdom, Xuankai Chang, Zalán Borsos, Marco Tagliasacchi, Neil Zeghidour, John R. Hershey</li>
<li>for: 这个论文是为了提出一种基于TokenSequence的语音分离模型，用于分离多个语音源并同时进行语音识别和语音生成。</li>
<li>methods: 该模型使用Transformer架构，并通过输入填充和输出掩码来实现多任务同时训练。</li>
<li>results: 该模型在对象metric和主观MUSHRA听测中表现出色，无论是否在文本条件下进行训练。此外，模型还可以提供高质量的自动语音识别（ASR）性能和语音合成示例。<details>
<summary>Abstract</summary>
We present TokenSplit, a speech separation model that acts on discrete token sequences. The model is trained on multiple tasks simultaneously: separate and transcribe each speech source, and generate speech from text. The model operates on transcripts and audio token sequences and achieves multiple tasks through masking of inputs. The model is a sequence-to-sequence encoder-decoder model that uses the Transformer architecture. We also present a "refinement" version of the model that predicts enhanced audio tokens from the audio tokens of speech separated by a conventional separation model. Using both objective metrics and subjective MUSHRA listening tests, we show that our model achieves excellent performance in terms of separation, both with or without transcript conditioning. We also measure the automatic speech recognition (ASR) performance and provide audio samples of speech synthesis to demonstrate the additional utility of our model.
</details>
<details>
<summary>摘要</summary>
我们介绍TokenSplit，一种基于字符序列的语音分离模型。该模型同时进行多个任务的训练：分离每个语音源，并将语音转化为文本。模型对字符序列和音频token序列进行Masking操作，并使用Transformer架构。我们还提出了一种“精度提升”版本的模型，可以通过 convential分离模型生成优化的音频token。通过对象指标和主观MUSHRA听测，我们证明了我们的模型在分离方面具有出色的表现，无论是否受到文本conditioning的影响。此外，我们还测试了自动语音识别（ASR）性能，并提供了语音合成示例以证明该模型的额外价值。
</details></li>
</ul>
<hr>
<h2 id="Federated-Learning-for-Connected-and-Automated-Vehicles-A-Survey-of-Existing-Approaches-and-Challenges"><a href="#Federated-Learning-for-Connected-and-Automated-Vehicles-A-Survey-of-Existing-Approaches-and-Challenges" class="headerlink" title="Federated Learning for Connected and Automated Vehicles: A Survey of Existing Approaches and Challenges"></a>Federated Learning for Connected and Automated Vehicles: A Survey of Existing Approaches and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10407">http://arxiv.org/abs/2308.10407</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vishnu Pandi Chellapandi, Liangqi Yuan, Christopher G. Brinton, Stanislaw H Zak, Ziran Wang</li>
<li>for: 本研究写了一篇评论文章，探讨了在自动驾驶汽车（CAV）中应用 Federated Learning（FL）的最新进展。</li>
<li>methods: 本文分析了中央化和分散化的FL框架，包括其主要特征和方法。同时也评论了CAV中FL的各种数据来源、模型和数据安全技术，强调了它们在维护车辆数据隐私和安全方面的重要性。</li>
<li>results: 本文对FL在CAV中的各种应用进行了评论，包括它们的基本模型和数据集。最后，文章点出了FL4CAV的现有挑战和未来研究的可能方向，以将FL在CAV中的效率和可靠性进一步提高。<details>
<summary>Abstract</summary>
Machine learning (ML) is widely used for key tasks in Connected and Automated Vehicles (CAV), including perception, planning, and control. However, its reliance on vehicular data for model training presents significant challenges related to in-vehicle user privacy and communication overhead generated by massive data volumes. Federated learning (FL) is a decentralized ML approach that enables multiple vehicles to collaboratively develop models, broadening learning from various driving environments, enhancing overall performance, and simultaneously securing local vehicle data privacy and security. This survey paper presents a review of the advancements made in the application of FL for CAV (FL4CAV). First, centralized and decentralized frameworks of FL are analyzed, highlighting their key characteristics and methodologies. Second, diverse data sources, models, and data security techniques relevant to FL in CAVs are reviewed, emphasizing their significance in ensuring privacy and confidentiality. Third, specific and important applications of FL are explored, providing insight into the base models and datasets employed for each application. Finally, existing challenges for FL4CAV are listed and potential directions for future work are discussed to further enhance the effectiveness and efficiency of FL in the context of CAV.
</details>
<details>
<summary>摘要</summary>
First, centralized and decentralized frameworks of FL are analyzed, highlighting their key characteristics and methodologies. Second, diverse data sources, models, and data security techniques relevant to FL in CAVs are reviewed, emphasizing their significance in ensuring privacy and confidentiality. Third, specific and important applications of FL are explored, providing insight into the base models and datasets employed for each application. Finally, existing challenges for FL4CAV are listed and potential directions for future work are discussed to further enhance the effectiveness and efficiency of FL in the context of CAV.Translation in Simplified Chinese:机器学习（ML）在connected和自动驾车（CAV）中广泛应用于关键任务，包括感知、规划和控制。然而，它对于车辆数据的训练而言存在重要的用户隐私和通信负担问题。联邦学习（FL）是一种分布式机器学习方法，它可以让多辆车辆共同开发模型，从而拓宽学习不同驾驶环境，提高总性能，同时保护车辆数据隐私和安全。本文将对FL在CAV中的应用进行评论。首先，中央化和分布式框架的FL被分析，强调其关键特征和方法。其次，CAV中 relevante的数据来源、模型和数据安全技术被评审，强调它们在保护隐私和Confidentiality方面的重要性。第三，FL在CAV中的特定应用被探讨，提供了每个应用的基本模型和数据集使用情况。最后，FL4CAV的挑战和未来工作的可能方向被列出，以进一步提高FL在CAV中的效果和效率。
</details></li>
</ul>
<hr>
<h2 id="Label-Selection-Approach-to-Learning-from-Crowds"><a href="#Label-Selection-Approach-to-Learning-from-Crowds" class="headerlink" title="Label Selection Approach to Learning from Crowds"></a>Label Selection Approach to Learning from Crowds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10396">http://arxiv.org/abs/2308.10396</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ssatsuki/label-selection-layer">https://github.com/ssatsuki/label-selection-layer</a></li>
<li>paper_authors: Kosuke Yoshimura, Hisashi Kashima</li>
<li>for: 本研究旨在提高supervised learning中使用来自众所� Discogs 的标注数据的精度，并提出了一种基于SelectiveNet的新方法，即Label Selection Layer，可以自动选择工作者的标注数据是否使用于训练。</li>
<li>methods: 本研究使用了一种基于Selector网络的方法，即Label Selection Layer，来自动选择工作者的标注数据是否使用于训练。</li>
<li>results: 实验结果显示，提出的方法在大多数情况下与Crowd Layer相当或更好，只有在回归问题时有所下降。<details>
<summary>Abstract</summary>
Supervised learning, especially supervised deep learning, requires large amounts of labeled data. One approach to collect large amounts of labeled data is by using a crowdsourcing platform where numerous workers perform the annotation tasks. However, the annotation results often contain label noise, as the annotation skills vary depending on the crowd workers and their ability to complete the task correctly. Learning from Crowds is a framework which directly trains the models using noisy labeled data from crowd workers. In this study, we propose a novel Learning from Crowds model, inspired by SelectiveNet proposed for the selective prediction problem. The proposed method called Label Selection Layer trains a prediction model by automatically determining whether to use a worker's label for training using a selector network. A major advantage of the proposed method is that it can be applied to almost all variants of supervised learning problems by simply adding a selector network and changing the objective function for existing models, without explicitly assuming a model of the noise in crowd annotations. The experimental results show that the performance of the proposed method is almost equivalent to or better than the Crowd Layer, which is one of the state-of-the-art methods for Deep Learning from Crowds, except for the regression problem case.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换文本到简化中文。<</SYS>>超级vised学习，特别是超级vised深度学习，需要大量标注数据。一种采集大量标注数据的方法是通过群组工作平台，让多名工作者完成标注任务。然而，标注结果经常含有标签噪音，因为群工作者的标注技能因人而异，完成任务正确性不一致。本研究提出了一种名为学习群体（Learning from Crowds）的框架，直接使用群体标注数据来训练模型。在本研究中，我们提出了一种新的学习群体模型，受到选择网络（Selector Network）的启发。这种方法被称为标签选择层（Label Selection Layer），它可以自动决定是否使用群体成员的标签来训练预测模型。本方法的一个优点是可以适用于大多数超级vised学习问题，只需要将选择网络和目标函数添加到现有模型中，无需显式假设群体标注噪音模型。实验结果表明，提出的方法与state-of-the-art方法之一的Deep Learning from Crowds（Crowd Layer）的性能几乎相同，除了回归问题 caso。
</details></li>
</ul>
<hr>
<h2 id="DiffPrep-Differentiable-Data-Preprocessing-Pipeline-Search-for-Learning-over-Tabular-Data"><a href="#DiffPrep-Differentiable-Data-Preprocessing-Pipeline-Search-for-Learning-over-Tabular-Data" class="headerlink" title="DiffPrep: Differentiable Data Preprocessing Pipeline Search for Learning over Tabular Data"></a>DiffPrep: Differentiable Data Preprocessing Pipeline Search for Learning over Tabular Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10915">http://arxiv.org/abs/2308.10915</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chu-data-lab/diffprep">https://github.com/chu-data-lab/diffprep</a></li>
<li>paper_authors: Peng Li, Zhiyi Chen, Xu Chu, Kexin Rong</li>
<li>for: 提高机器学习模型的性能，自动搜索数据预处理管道</li>
<li>methods: 使用梯度下降法搜索数据预处理管道，将搜索空间转换为连续和可导的空间</li>
<li>results: 在15个实际世界数据集上达到最佳测试准确率，提高模型测试准确率最多6.6个百分点<details>
<summary>Abstract</summary>
Data preprocessing is a crucial step in the machine learning process that transforms raw data into a more usable format for downstream ML models. However, it can be costly and time-consuming, often requiring the expertise of domain experts. Existing automated machine learning (AutoML) frameworks claim to automate data preprocessing. However, they often use a restricted search space of data preprocessing pipelines which limits the potential performance gains, and they are often too slow as they require training the ML model multiple times. In this paper, we propose DiffPrep, a method that can automatically and efficiently search for a data preprocessing pipeline for a given tabular dataset and a differentiable ML model such that the performance of the ML model is maximized. We formalize the problem of data preprocessing pipeline search as a bi-level optimization problem. To solve this problem efficiently, we transform and relax the discrete, non-differential search space into a continuous and differentiable one, which allows us to perform the pipeline search using gradient descent with training the ML model only once. Our experiments show that DiffPrep achieves the best test accuracy on 15 out of the 18 real-world datasets evaluated and improves the model's test accuracy by up to 6.6 percentage points.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>机器学习过程中的数据处理步骤是一个关键步骤，将原始数据转换成下游机器学习模型更加使用的格式。然而，这可能是成本和时间consuming的，经常需要域专家的帮助。现有的自动机器学习（AutoML）框架声称可以自动化数据处理。然而，它们通常使用restricted的数据处理管道搜索空间，这限制了性能提升的 potential，并且它们通常太慢，需要训练机器学习模型多次。在这篇论文中，我们提出了DiffPrep，一种方法可以自动和高效地搜索给定的表格数据集和弹性机器学习模型中的数据处理管道，以最大化机器学习模型的性能。我们将数据处理管道搜索问题формализова为二级优化问题。为了解决这个问题高效，我们将离散、非 diferencial的搜索空间转换为连续和微分的一个，这allow我们使用梯度下降来搜索管道，只需训练机器学习模型一次。我们的实验表明，DiffPrep在18个真实世界数据集中测试精度为15个最好，并提高机器学习模型的测试精度达6.6个百分点。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Opinion-Aggregation-–-A-Statistical-Perspective"><a href="#Unsupervised-Opinion-Aggregation-–-A-Statistical-Perspective" class="headerlink" title="Unsupervised Opinion Aggregation – A Statistical Perspective"></a>Unsupervised Opinion Aggregation – A Statistical Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10386">http://arxiv.org/abs/2308.10386</a></li>
<li>repo_url: None</li>
<li>paper_authors: Noyan C. Sevuktekin, Andrew C. Singer</li>
<li>For: This paper is written for decision-makers who rely on opinions from multiple experts to make complex decisions, but have limited or no access to the ground truth.* Methods: The paper proposes a statistical approach to infer the competence of each expert based on their opinions, without any need for the ground truth. The approach measures the competence of each expert by their likeliness to agree with their peers, and leverages this fact to propose a completely unsupervised version of the na&quot;{i}ve Bayes classifier.* Results: The paper shows that the proposed technique is asymptotically optimal for a large class of problems, and can be applied for online opinion aggregation and decision-making based on a limited number of opinions.<details>
<summary>Abstract</summary>
Complex decision-making systems rarely have direct access to the current state of the world and they instead rely on opinions to form an understanding of what the ground truth could be. Even in problems where experts provide opinions without any intention to manipulate the decision maker, it is challenging to decide which expert's opinion is more reliable -- a challenge that is further amplified when decision-maker has limited, delayed, or no access to the ground truth after the fact. This paper explores a statistical approach to infer the competence of each expert based on their opinions without any need for the ground truth. Echoing the logic behind what is commonly referred to as \textit{the wisdom of crowds}, we propose measuring the competence of each expert by their likeliness to agree with their peers. We further show that the more reliable an expert is the more likely it is that they agree with their peers. We leverage this fact to propose a completely unsupervised version of the na\"{i}ve Bayes classifier and show that the proposed technique is asymptotically optimal for a large class of problems. In addition to aggregating a large block of opinions, we further apply our technique for online opinion aggregation and for decision-making based on a limited the number of opinions.
</details>
<details>
<summary>摘要</summary>
决策系统很少直接访问现实世界的当前状态，而是基于意见来形成决策者对真实状态的理解。即使专家不 INTENTIONALLY 操纵决策者，仍然困难判断每位专家的可靠性——这种问题在决策者没有或延迟了真实状态的情况下变得更加严重。本文探讨一种统计方法，用于无需真实状态的情况下评估每位专家的能力。根据《群智》的逻辑，我们提议根据专家们之间的一致性来评估每位专家的能力。我们还证明了，更可靠的专家更有可能与其他专家一致。我们利用这一点，提出了一种完全无监督的na\"{i}ve Bayes分类器，并证明该技术在一类问题上是 asymptotically 优化的。除了聚合大量意见外，我们还应用了该技术于在线意见聚合和基于有限数量的意见进行决策。
</details></li>
</ul>
<hr>
<h2 id="Automated-mapping-of-virtual-environments-with-visual-predictive-coding"><a href="#Automated-mapping-of-virtual-environments-with-visual-predictive-coding" class="headerlink" title="Automated mapping of virtual environments with visual predictive coding"></a>Automated mapping of virtual environments with visual predictive coding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10913">http://arxiv.org/abs/2308.10913</a></li>
<li>repo_url: None</li>
<li>paper_authors: James Gornet, Matthew Thomson</li>
<li>for: 这个论文旨在探讨大脑如何直接从感知输入中构建内部的认知地图，以及这种方法如何普适地应用于听觉、感觉和语言输入。</li>
<li>methods: 这篇论文使用预测编码方法来描述大脑如何使用感知数据构建内部的认知地图。具体来说，论文使用一个自我注意力装备 convolutional neural network 来实现预测编码。</li>
<li>results: 研究发现，使用预测编码方法可以自动从视觉数据中提取环境内部的信息，并且可以准确地识别环境中的特征点。此外，研究还发现，预测编码可以将视觉、感觉和语言输入都 mapping 到同一个内部空间中，从而实现 vector 导航。<details>
<summary>Abstract</summary>
Humans construct internal cognitive maps of their environment directly from sensory inputs without access to a system of explicit coordinates or distance measurements. While machine learning algorithms like SLAM utilize specialized visual inference procedures to identify visual features and construct spatial maps from visual and odometry data, the general nature of cognitive maps in the brain suggests a unified mapping algorithmic strategy that can generalize to auditory, tactile, and linguistic inputs. Here, we demonstrate that predictive coding provides a natural and versatile neural network algorithm for constructing spatial maps using sensory data. We introduce a framework in which an agent navigates a virtual environment while engaging in visual predictive coding using a self-attention-equipped convolutional neural network. While learning a next image prediction task, the agent automatically constructs an internal representation of the environment that quantitatively reflects distances. The internal map enables the agent to pinpoint its location relative to landmarks using only visual information.The predictive coding network generates a vectorized encoding of the environment that supports vector navigation where individual latent space units delineate localized, overlapping neighborhoods in the environment. Broadly, our work introduces predictive coding as a unified algorithmic framework for constructing cognitive maps that can naturally extend to the mapping of auditory, sensorimotor, and linguistic inputs.
</details>
<details>
<summary>摘要</summary>
人类直接从感知输入中构建内部的认知地图，没有访问专门的坐标系或距离测量。而机器学习算法如SLAM则使用专门的视觉推理过程来标识视觉特征并从视觉和运动数据中构建空间地图。然而，大脑中的认知地图的通用性表明了一种统一的映射算法策略，可以扩展到听觉、感觉和语言输入。在这里，我们表明了预测编码提供了一种自然和灵活的神经网络算法，用于通过感知数据构建空间地图。我们在虚拟环境中训练一个使用自我注意力束重Convolutional Neural Network（CNN）进行视觉预测任务的agent，而该任务自动构建了agent内部的环境表示，其中quantitatively表示距离。这个内部地图允许agent使用 только视觉信息确定其所处的位置。预测编码网络生成了一个vector化编码环境，该编码支持vector导航，其中个别的latent space单元界定了环境中的Localized, Overlapping Neighborhoods。总的来说，我们的工作引入预测编码作为一种统一的算法框架，可以自然扩展到 mapped听觉、感觉和语言输入。
</details></li>
</ul>
<hr>
<h2 id="HoSNN-Adversarially-Robust-Homeostatic-Spiking-Neural-Networks-with-Adaptive-Firing-Thresholds"><a href="#HoSNN-Adversarially-Robust-Homeostatic-Spiking-Neural-Networks-with-Adaptive-Firing-Thresholds" class="headerlink" title="HoSNN: Adversarially-Robust Homeostatic Spiking Neural Networks with Adaptive Firing Thresholds"></a>HoSNN: Adversarially-Robust Homeostatic Spiking Neural Networks with Adaptive Firing Thresholds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10373">http://arxiv.org/abs/2308.10373</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hejia Geng, Peng Li</li>
<li>for: 防御 adversarial attacks 的 SNN 模型</li>
<li>methods: 使用 bio-inspired 方法，即 neural homeostasis，开发一种具有自适应阈值调整功能的 leaky integrate-and-fire (TA-LIF)  neuron 模型，并将其应用于 constructing 防御型 SNN (HoSNN)</li>
<li>results: 对 CIFAR-10 进行测试，提高了对 FGSM 和 PGD 攻击的抵抗力，并在无需显式 adversarial 训练的情况下达到了高度的精度提升（up to 72.6% and 54.19%），并且在 FGSM 攻击下超过了先前的模型（29.99%），表明了 HoSNN 的具有很强的鲁棒性和防御能力。<details>
<summary>Abstract</summary>
Spiking neural networks (SNNs) offer promise for efficient and powerful neurally inspired computation. Common to other types of neural networks, however, SNNs face the severe issue of vulnerability to adversarial attacks. We present the first study that draws inspiration from neural homeostasis to develop a bio-inspired solution that counters the susceptibilities of SNNs to adversarial onslaughts. At the heart of our approach is a novel threshold-adapting leaky integrate-and-fire (TA-LIF) neuron model, which we adopt to construct the proposed adversarially robust homeostatic SNN (HoSNN). Distinct from traditional LIF models, our TA-LIF model incorporates a self-stabilizing dynamic thresholding mechanism, curtailing adversarial noise propagation and safeguarding the robustness of HoSNNs in an unsupervised manner. Theoretical analysis is presented to shed light on the stability and convergence properties of the TA-LIF neurons, underscoring their superior dynamic robustness under input distributional shifts over traditional LIF neurons. Remarkably, without explicit adversarial training, our HoSNNs demonstrate inherent robustness on CIFAR-10, with accuracy improvements to 72.6% and 54.19% against FGSM and PGD attacks, up from 20.97% and 0.6%, respectively. Furthermore, with minimal FGSM adversarial training, our HoSNNs surpass previous models by 29.99% under FGSM and 47.83% under PGD attacks on CIFAR-10. Our findings offer a new perspective on harnessing biological principles for bolstering SNNs adversarial robustness and defense, paving the way to more resilient neuromorphic computing.
</details>
<details>
<summary>摘要</summary>
斯坦尼尔神经网络（SNN）具有高效和强大的神经逻辑计算的承诺。然而，SNN也面临着严重的抗击性攻击问题，这是其他类型神经网络一样的问题。我们的研究是首次启用神经自适应性来开发一种生物启发的解决方案，以抵抗SNN对抗性攻击的感受性。我们的方法的核心是一种新的阈值自适应泄漏 integrate-and-fire（TA-LIF）神经元模型。与传统的LIF模型不同，我们的TA-LIF模型包含一种自我稳定的动态阈值调节机制，这有助于防止抗击噪音的传播和保护HoSNN的稳定性。我们对TA-LIF神经元的稳定性和整合性进行了理论分析，并证明它们在输入分布变化时具有更高的动态稳定性。这些成果表明，不需要显式的抗击训练，我们的HoSNN可以自动具有很高的抗击性。我们的实验表明，我们的HoSNN在CIFAR-10上的准确率可以提高到72.6%和54.19%，比传统的FGSM和PGD攻击提高了29.99%和47.83%。此外，我们的HoSNN通过最小化FGSM抗击训练来超过之前的模型。这些成果表明，可以通过利用生物原理来强化SNN的抗击性和防御，为更可靠的神经omorphic计算提供新的思路。
</details></li>
</ul>
<hr>
<h2 id="Developing-a-Machine-Learning-Based-Clinical-Decision-Support-Tool-for-Uterine-Tumor-Imaging"><a href="#Developing-a-Machine-Learning-Based-Clinical-Decision-Support-Tool-for-Uterine-Tumor-Imaging" class="headerlink" title="Developing a Machine Learning-Based Clinical Decision Support Tool for Uterine Tumor Imaging"></a>Developing a Machine Learning-Based Clinical Decision Support Tool for Uterine Tumor Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10372">http://arxiv.org/abs/2308.10372</a></li>
<li>repo_url: None</li>
<li>paper_authors: Darryl E. Wright, Adriana V. Gregory, Deema Anaam, Sepideh Yadollahi, Sumana Ramanathan, Kafayat A. Oyemade, Reem Alsibai, Heather Holmes, Harrison Gottlich, Cherie-Akilah G. Browne, Sarah L. Cohen Rassier, Isabel Green, Elizabeth A. Stewart, Hiroaki Takahashi, Bohyun Kim, Shannon Laughlin-Tommaso, Timothy L. Kline</li>
<li>For: The paper aims to develop an automated method for 3D segmentation of the uterus and uterine tumors (UTs) that is close to human-level performance with fewer than 150 annotated images.* Methods: The authors use a deep learning approach called nnU-Net and explore the effect of training set size on performance by randomly generating subsets with 25, 45, 65, and 85 training set images. They also evaluate the ability of radiomic features to distinguish between types of UTs.* Results: The authors achieve a test set F1-score of 0.80 for classifying degenerated leiomyoma (LM) from leiomyosarcoma (LMS), and F1-scores of 0.53 and 0.80 for classifying benign versus malignant and degenerated LM versus LMS, respectively. However, the authors note that reliable automatic differentiation of UTs remains a challenge.<details>
<summary>Abstract</summary>
Uterine leiomyosarcoma (LMS) is a rare but aggressive malignancy. On imaging, it is difficult to differentiate LMS from, for example, degenerated leiomyoma (LM), a prevalent but benign condition. We curated a data set of 115 axial T2-weighted MRI images from 110 patients (mean [range] age=45 [17-81] years) with UTs that included five different tumor types. These data were randomly split stratifying on tumor volume into training (n=85) and test sets (n=30). An independent second reader (reader 2) provided manual segmentations for all test set images. To automate segmentation, we applied nnU-Net and explored the effect of training set size on performance by randomly generating subsets with 25, 45, 65 and 85 training set images. We evaluated the ability of radiomic features to distinguish between types of UT individually and when combined through feature selection and machine learning. Using the entire training set the mean [95% CI] fibroid DSC was measured as 0.87 [0.59-1.00] and the agreement between the two readers was 0.89 [0.77-1.0] on the test set. When classifying degenerated LM from LMS we achieve a test set F1-score of 0.80. Classifying UTs based on radiomic features we identify classifiers achieving F1-scores of 0.53 [0.45, 0.61] and 0.80 [0.80, 0.80] on the test set for the benign versus malignant, and degenerated LM versus LMS tasks. We show that it is possible to develop an automated method for 3D segmentation of the uterus and UT that is close to human-level performance with fewer than 150 annotated images. For distinguishing UT types, while we train models that merit further investigation with additional data, reliable automatic differentiation of UTs remains a challenge.
</details>
<details>
<summary>摘要</summary>
uterine leiomyosarcoma (LMS) 是一种罕见 pero 严重的恶性肿瘤。在成像方面，与例如变性的 лейкомиома (LM) 相比，困难于 diferenciar LMS 的形态。我们收集了115个轴向 T2 磁共振成像图像，来自110名患者（平均年龄为45岁，年龄范围为17-81岁），以便自动分割肾脏和uterus的图像。这些数据被随机分割，以便在训练集（n=85）和测试集（n=30）之间进行分布式训练。一名独立的第二读者（读者2）为测试集图像提供了手动分割。为了自动分割，我们应用了 nnU-Net，并研究了训练集大小对性能的影响，通过随机生成25、45、65和85个训练集图像。我们评估了在不同类型的uterus和肾脏图像上的 радиологических特征的分化能力，并通过特征选择和机器学习来结合这些特征。使用整个训练集，我们测量了 mean [95% CI] 的 fibroid DSC 为0.87 [0.59-1.00]，并且测试集上的两个读者之间的一致性为0.89 [0.77-1.0]。在分类 degenerated LM 和 LMS 之间，我们在测试集上取得了 F1 分数为0.80。基于 радиialogical 特征，我们标识出了分类器，在测试集上取得了 F1 分数为0.53 [0.45, 0.61] 和 0.80 [0.80, 0.80]。我们表明，可以通过使用 fewer than 150 个标注图像来开发一种自动方法，以便三维分割uterus和肾脏，并且这种方法的性能接近人类水平。然而，在分类不同类型的uterus和肾脏图像时，我们发现，可靠地自动分类 UT 仍然是一个挑战。
</details></li>
</ul>
<hr>
<h2 id="SE-3-Equivariant-Augmented-Coupling-Flows"><a href="#SE-3-Equivariant-Augmented-Coupling-Flows" class="headerlink" title="SE(3) Equivariant Augmented Coupling Flows"></a>SE(3) Equivariant Augmented Coupling Flows</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10364">http://arxiv.org/abs/2308.10364</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lollcat/se3-augmented-coupling-flows">https://github.com/lollcat/se3-augmented-coupling-flows</a></li>
<li>paper_authors: Laurence I. Midgley, Vincent Stimper, Javier Antorán, Emile Mathieu, Bernhard Schölkopf, José Miguel Hernández-Lobato</li>
<li>for: 这 paper 是为了提出一种可以保持 SE(3) 和 permutation 对称的 coupling flow，用于probabilistic modeling of physical systems。</li>
<li>methods: 该 paper 使用了coordinate splits along additional augmented dimensions，将 atoms 的位置映射到 learned SE(3) 对称的基准系中，然后应用标准 flow transformations，如 monotonic rational-quadratic splines。</li>
<li>results: 该 flow 可以保持 fast sampling 和 density evaluation，并可以生成不偏的 expectation 值 estimates with respect to the target distribution via importance sampling。在 DW4, LJ13 和 QM9-positional 数据集上训练，该 flow 与 equivariant continuous normalizing flows 相比，可以 sampling 两个阶段 faster，并且是首次learn the full Boltzmann distribution of alanine dipeptide by only modeling the Cartesian positions of its atoms。最后，paper 还示出了该 flow 可以approximately sample from the Boltzmann distribution of DW4 和 LJ13 particle systems using only their energy functions。<details>
<summary>Abstract</summary>
Coupling normalizing flows allow for fast sampling and density evaluation, making them the tool of choice for probabilistic modeling of physical systems. However, the standard coupling architecture precludes endowing flows that operate on the Cartesian coordinates of atoms with the SE(3) and permutation invariances of physical systems. This work proposes a coupling flow that preserves SE(3) and permutation equivariance by performing coordinate splits along additional augmented dimensions. At each layer, the flow maps atoms' positions into learned SE(3) invariant bases, where we apply standard flow transformations, such as monotonic rational-quadratic splines, before returning to the original basis. Crucially, our flow preserves fast sampling and density evaluation, and may be used to produce unbiased estimates of expectations with respect to the target distribution via importance sampling. When trained on the DW4, LJ13 and QM9-positional datasets, our flow is competitive with equivariant continuous normalizing flows, while allowing sampling two orders of magnitude faster. Moreover, to the best of our knowledge, we are the first to learn the full Boltzmann distribution of alanine dipeptide by only modeling the Cartesian positions of its atoms. Lastly, we demonstrate that our flow can be trained to approximately sample from the Boltzmann distribution of the DW4 and LJ13 particle systems using only their energy functions.
</details>
<details>
<summary>摘要</summary>
通过协同Normalizing Flows可以快速采样和density评估，使其成为物理系统的概率模型的工具 Choice. However, 标准的 coupling architecture 缺乏 SE(3) 和 Permutation 不变性 Physical systems. This work proposes a coupling flow that preserves SE(3) and permutation equivariance by performing coordinate splits along additional augmented dimensions. At each layer, the flow maps atoms' positions into learned SE(3) invariant bases, where we apply standard flow transformations, such as monotonic rational-quadratic splines, before returning to the original basis. Crucially, our flow preserves fast sampling and density evaluation, and may be used to produce unbiased estimates of expectations with respect to the target distribution via importance sampling. When trained on the DW4, LJ13 and QM9-positional datasets, our flow is competitive with equivariant continuous normalizing flows, while allowing sampling two orders of magnitude faster. Moreover, to the best of our knowledge, we are the first to learn the full Boltzmann distribution of alanine dipeptide by only modeling the Cartesian positions of its atoms. Lastly, we demonstrate that our flow can be trained to approximately sample from the Boltzmann distribution of the DW4 and LJ13 particle systems using only their energy functions.Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Can-Large-Language-Models-Find-And-Fix-Vulnerable-Software"><a href="#Can-Large-Language-Models-Find-And-Fix-Vulnerable-Software" class="headerlink" title="Can Large Language Models Find And Fix Vulnerable Software?"></a>Can Large Language Models Find And Fix Vulnerable Software?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10345">http://arxiv.org/abs/2308.10345</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Noever</li>
<li>for: 这个研究是为了评估大语言模型（LLMs），特别是OpenAI的GPT-4，在检测软件漏洞方面的能力，并与传统的静态代码分析器如Snyk和Fortify进行比较。</li>
<li>methods: 我们的分析涵盖了多个仓库，包括NASA和美国国防部的仓库。GPT-4可以检测到大约四倍于其他工具的漏洞，并提供可行的修复方案，false positives的率很低。我们的测试包括129个代码样本 across eight programming languages，发现 PHP 和 JavaScript 的漏洞最高。GPT-4 的代码更正 Led to a 90% reduction in vulnerabilities, requiring only an 11% increase in code lines。</li>
<li>results: GPT-4 的代码更正 led to a 90% reduction in vulnerabilities, requiring only an 11% increase in code lines。这表明 LLMS 的自我审查能力，并且在检测到漏洞时可以提供可行的修复方案。未来的研究应该探索系统级别的漏洞和将多个静态代码分析器集成到 LLMS 的潜在能力中。<details>
<summary>Abstract</summary>
In this study, we evaluated the capability of Large Language Models (LLMs), particularly OpenAI's GPT-4, in detecting software vulnerabilities, comparing their performance against traditional static code analyzers like Snyk and Fortify. Our analysis covered numerous repositories, including those from NASA and the Department of Defense. GPT-4 identified approximately four times the vulnerabilities than its counterparts. Furthermore, it provided viable fixes for each vulnerability, demonstrating a low rate of false positives. Our tests encompassed 129 code samples across eight programming languages, revealing the highest vulnerabilities in PHP and JavaScript. GPT-4's code corrections led to a 90% reduction in vulnerabilities, requiring only an 11% increase in code lines. A critical insight was LLMs' ability to self-audit, suggesting fixes for their identified vulnerabilities and underscoring their precision. Future research should explore system-level vulnerabilities and integrate multiple static code analyzers for a holistic perspective on LLMs' potential.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们评估了大语言模型（LLM），特别是OpenAI的GPT-4，在检测软件漏洞方面的能力，与传统的静态代码分析器如Snyk和Fortify进行比较。我们的分析覆盖了多个仓库，包括NASA和国防部的仓库。GPT-4在检测漏洞方面表现出色，比其他Counterparts多出了约四倍的漏洞数。另外，它还提供了每个漏洞的可行修复方案，表明了低 False Positive 率。我们的测试包括129个代码样本 across eight种编程语言，发现最高的漏洞出现在 PHP 和 JavaScript 中。GPT-4 的代码更正引起了漏洞数量的90%减少，仅需要11%的代码行数增加。我们发现 LLMS 可以自我审查，提供检测到的漏洞的修复方案，这种精度是其中的一个关键点。未来的研究应该探索系统级别的漏洞和将多种静态代码分析器集成到 LLMS 的潜在能力中。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Empirical-Evaluation-on-Online-Continual-Learning"><a href="#A-Comprehensive-Empirical-Evaluation-on-Online-Continual-Learning" class="headerlink" title="A Comprehensive Empirical Evaluation on Online Continual Learning"></a>A Comprehensive Empirical Evaluation on Online Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10328">http://arxiv.org/abs/2308.10328</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/albinsou/ocl_survey">https://github.com/albinsou/ocl_survey</a></li>
<li>paper_authors: Albin Soutif–Cormerais, Antonio Carta, Andrea Cossu, Julio Hurtado, Vincenzo Lomonaco, Joost Van de Weijer, Hamed Hemati<br>for: 这个论文主要针对的是在流动数据中进行在线连续学习，以实现更加接近真实生活中的学习经验。methods: 本文对现有文献中的多种在线连续学习方法进行评估，具体来说是在图像分类任务中的分类增量 setting。results: 结果显示大多数方法受到稳定性和过拟合问题的影响，但是学习得到的表示相当于随机抽样训练下的同等计算预算。没有一个明确的赢家 emerges，基本的经验回快是一个非常强的基eline。<details>
<summary>Abstract</summary>
Online continual learning aims to get closer to a live learning experience by learning directly on a stream of data with temporally shifting distribution and by storing a minimum amount of data from that stream. In this empirical evaluation, we evaluate various methods from the literature that tackle online continual learning. More specifically, we focus on the class-incremental setting in the context of image classification, where the learner must learn new classes incrementally from a stream of data. We compare these methods on the Split-CIFAR100 and Split-TinyImagenet benchmarks, and measure their average accuracy, forgetting, stability, and quality of the representations, to evaluate various aspects of the algorithm at the end but also during the whole training period. We find that most methods suffer from stability and underfitting issues. However, the learned representations are comparable to i.i.d. training under the same computational budget. No clear winner emerges from the results and basic experience replay, when properly tuned and implemented, is a very strong baseline. We release our modular and extensible codebase at https://github.com/AlbinSou/ocl_survey based on the avalanche framework to reproduce our results and encourage future research.
</details>
<details>
<summary>摘要</summary>
在线 kontinual learning 目的是通过直接学习数据流中的时间推移分布来减少数据存储量，从而更接近实时学习经验。在这项实验中，我们评估了文献中的多种在线 kontinual learning 方法。更具体地说，我们在图像分类上下文中关注了分类增量 Setting，learner需要从数据流中逐渐学习新类。我们在 Split-CIFAR100 和 Split-TinyImagenet 测试准则上对这些方法进行了评估，并测量了它们的均值精度、忘记、稳定性和表示质量，以评估它们的不同方面。我们发现大多数方法受到稳定性和下降问题的困扰。然而，学习的表示相对于 i.i.d. 训练相同计算资源下的表示相似。无论是在结果还是在训练过程中，基本的经验回放在概念上是非常强的基准。我们在 GitHub 上发布了我们的模块化和可扩展的代码库，访问 https://github.com/AlbinSou/ocl_survey，以便复制我们的结果并鼓励未来的研究。
</details></li>
</ul>
<hr>
<h2 id="Quantum-State-Tomography-using-Quantum-Machine-Learning"><a href="#Quantum-State-Tomography-using-Quantum-Machine-Learning" class="headerlink" title="Quantum State Tomography using Quantum Machine Learning"></a>Quantum State Tomography using Quantum Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10327">http://arxiv.org/abs/2308.10327</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hongyehu/Machine_Learning_Quantum_State_Tomography">https://github.com/hongyehu/Machine_Learning_Quantum_State_Tomography</a></li>
<li>paper_authors: Nouhaila Innan, Owais Ishtiaq Siddiqui, Shivang Arora, Tamojit Ghosh, Yasemin Poyraz Koçak, Dominic Paragas, Abdullah Al Omar Galib, Muhammad Al-Zafar Khan, Mohamed Bennai</li>
<li>for: 本研究旨在提高量子状态 Tomatoes （QST）的效率，以便在大规模量子系统上应用。</li>
<li>methods: 本研究使用量子机器学习（QML）技术来提高QST的效率，并 investigate了不同的类型的QST方法，包括类型化和量子方法。</li>
<li>results: 我们的结果显示，我们的QML-based QST方法可以 дости到高准确率（98%），并且需要 fewer measurements than conventional methods，这使得它成为实际应用中的可能性。<details>
<summary>Abstract</summary>
Quantum State Tomography (QST) is a fundamental technique in Quantum Information Processing (QIP) for reconstructing unknown quantum states. However, the conventional QST methods are limited by the number of measurements required, which makes them impractical for large-scale quantum systems. To overcome this challenge, we propose the integration of Quantum Machine Learning (QML) techniques to enhance the efficiency of QST. In this paper, we conduct a comprehensive investigation into various approaches for QST, encompassing both classical and quantum methodologies; We also implement different QML approaches for QST and demonstrate their effectiveness on various simulated and experimental quantum systems, including multi-qubit networks. Our results show that our QML-based QST approach can achieve high fidelity (98%) with significantly fewer measurements than conventional methods, making it a promising tool for practical QIP applications.
</details>
<details>
<summary>摘要</summary>
量子状态测测（QST）是量子信息处理（QIP）中重要的技术，用于重constructing未知量子状态。然而，传统的QST方法受限于测量数量的限制，使其对大规模量子系统不实用。为超越这个挑战，我们提议通过量子机器学习（QML）技术来提高QST的效率。在这篇论文中，我们进行了对各种QST方法的全面调查，包括класси方法和量子方法；我们还实现了不同的QML方法 дляQST，并在 simulate 和实验性量子系统中证明其效果。我们的结果表明，我们的QML基于QST方法可以达到高准确率（98%），并且使用了远 fewer 测量，与传统方法相比，这使其在实际QIP应用中具有承诺的潜力。
</details></li>
</ul>
<hr>
<h2 id="Homogenising-SoHO-EIT-and-SDO-AIA-171A-Images-A-Deep-Learning-Approach"><a href="#Homogenising-SoHO-EIT-and-SDO-AIA-171A-Images-A-Deep-Learning-Approach" class="headerlink" title="Homogenising SoHO&#x2F;EIT and SDO&#x2F;AIA 171Å$~$ Images: A Deep Learning Approach"></a>Homogenising SoHO&#x2F;EIT and SDO&#x2F;AIA 171Å$~$ Images: A Deep Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10322">http://arxiv.org/abs/2308.10322</a></li>
<li>repo_url: None</li>
<li>paper_authors: Subhamoy Chatterjee, Andrés Muñoz-Jaramillo, Maher Dayeh, Hazel M. Bain, Kimberly Moreland</li>
<li>for: 这个论文的目的是创建一个同一个时间段内的多频率欧文图像合并，以便进行空天气预测任务。</li>
<li>methods: 该论文使用了深度学习模型，通过将多个调查结果合并成一个同一个时间段内的同一个图像来实现合并。</li>
<li>results: 该论文发现，使用多个模型的ensemble可以减少模型的不确定性，并且在测试数据中显示出更高的不确定性，表明模型在不良代表性的数据上表现更好。<details>
<summary>Abstract</summary>
Extreme Ultraviolet images of the Sun are becoming an integral part of space weather prediction tasks. However, having different surveys requires the development of instrument-specific prediction algorithms. As an alternative, it is possible to combine multiple surveys to create a homogeneous dataset. In this study, we utilize the temporal overlap of SoHO/EIT and SDO/AIA 171~\AA ~surveys to train an ensemble of deep learning models for creating a single homogeneous survey of EUV images for 2 solar cycles. Prior applications of deep learning have focused on validating the homogeneity of the output while overlooking the systematic estimation of uncertainty. We use an approach called `Approximate Bayesian Ensembling' to generate an ensemble of models whose uncertainty mimics that of a fully Bayesian neural network at a fraction of the cost. We find that ensemble uncertainty goes down as the training set size increases. Additionally, we show that the model ensemble adds immense value to the prediction by showing higher uncertainty in test data that are not well represented in the training data.
</details>
<details>
<summary>摘要</summary>
extremely ultraviolet images of the sun are becoming an integral part of space weather prediction tasks. however, having different surveys requires the development of instrument-specific prediction algorithms. as an alternative, it is possible to combine multiple surveys to create a homogeneous dataset. in this study, we utilize the temporal overlap of soho/eit and sdo/aia 171 ~\aa ~surveys to train an ensemble of deep learning models for creating a single homogeneous survey of euv images for 2 solar cycles. prior applications of deep learning have focused on validating the homogeneity of the output while overlooking the systematic estimation of uncertainty. we use an approach called 'approximate bayesian ensembling' to generate an ensemble of models whose uncertainty mimics that of a fully bayesian neural network at a fraction of the cost. we find that ensemble uncertainty goes down as the training set size increases. additionally, we show that the model ensemble adds immense value to the prediction by showing higher uncertainty in test data that are not well represented in the training data.Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Towards-Sustainable-Development-A-Novel-Integrated-Machine-Learning-Model-for-Holistic-Environmental-Health-Monitoring"><a href="#Towards-Sustainable-Development-A-Novel-Integrated-Machine-Learning-Model-for-Holistic-Environmental-Health-Monitoring" class="headerlink" title="Towards Sustainable Development: A Novel Integrated Machine Learning Model for Holistic Environmental Health Monitoring"></a>Towards Sustainable Development: A Novel Integrated Machine Learning Model for Holistic Environmental Health Monitoring</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10317">http://arxiv.org/abs/2308.10317</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anirudh Mazumder, Sarthak Engala, Aditya Nallaparaju</li>
<li>for: 帮助政府确定 intervención点，改善规划和保护努力，以促进可持续发展。</li>
<li>methods: 使用机器学习技术来识别环境状况的预测特征，并将污染物水平和粉尘物作为环境状况的指标。</li>
<li>results: 通过识别环境状况的预测特征，帮助政府确定干预点，改善规划和保护努力，以促进可持续发展。<details>
<summary>Abstract</summary>
Urbanization enables economic growth but also harms the environment through degradation. Traditional methods of detecting environmental issues have proven inefficient. Machine learning has emerged as a promising tool for tracking environmental deterioration by identifying key predictive features. Recent research focused on developing a predictive model using pollutant levels and particulate matter as indicators of environmental state in order to outline challenges. Machine learning was employed to identify patterns linking areas with worse conditions. This research aims to assist governments in identifying intervention points, improving planning and conservation efforts, and ultimately contributing to sustainable development.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Demystifying-the-Performance-of-Data-Transfers-in-High-Performance-Research-Networks"><a href="#Demystifying-the-Performance-of-Data-Transfers-in-High-Performance-Research-Networks" class="headerlink" title="Demystifying the Performance of Data Transfers in High-Performance Research Networks"></a>Demystifying the Performance of Data Transfers in High-Performance Research Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10312">http://arxiv.org/abs/2308.10312</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ehsan Saeedizade, Bing Zhang, Engin Arslan</li>
<li>for: 本研究旨在提高高速数据传输网络中数据传输的效率，帮助解决数据传输中的性能问题。</li>
<li>methods: 本研究使用了一种可扩展的端到端监控框架，收集和存储关键性能指标，以便更好地了解数据传输的性能。</li>
<li>results: 评估结果显示，提posed框架可以同时监控400个转移每个主机，总共超过40,000个转移，并且可以在一秒钟精度下收集性能统计数据。此外，我们还提出了一种自动处理收集到的性能指标的启发方法，可以自动标识性能异常的根本原因，并且其F-score在87-98%之间。<details>
<summary>Abstract</summary>
High-speed research networks are built to meet the ever-increasing needs of data-intensive distributed workflows. However, data transfers in these networks often fail to attain the promised transfer rates for several reasons, including I/O and network interference, server misconfigurations, and network anomalies. Although understanding the root causes of performance issues is critical to mitigating them and increasing the utilization of expensive network infrastructures, there is currently no available mechanism to monitor data transfers in these networks. In this paper, we present a scalable, end-to-end monitoring framework to gather and store key performance metrics for file transfers to shed light on the performance of transfers. The evaluation results show that the proposed framework can monitor up to 400 transfers per host and more than 40, 000 transfers in total while collecting performance statistics at one-second precision. We also introduce a heuristic method to automatically process the gathered performance metrics and identify the root causes of performance anomalies with an F-score of 87 - 98%.
</details>
<details>
<summary>摘要</summary>
高速研究网络是为了满足数据敏感分布式工作流的不断增长需求而建立的。然而，在这些网络中数据传输经常无法实现承诺的传输速率，这可能由多种原因引起，包括I/O和网络干扰、服务器配置错误和网络异常。虽然了解性能问题的根本原因非常重要，以便解决它们并提高昂贵的网络基础设施的使用率，但目前并无可用的监控数据传输机制。在这篇论文中，我们提出了一种可扩展的终端到终端监控框架，用于收集和存储关键性能指标。我们的评估结果表明，我们的框架可以监控每个主机400个传输，总共超过40,000个传输，并且在一秒钟精度下收集性能统计数据。我们还提出了一种启发式方法，用于自动处理收集的性能指标，并识别性能异常的根本原因，F-分数为87-98%。
</details></li>
</ul>
<hr>
<h2 id="I-O-Burst-Prediction-for-HPC-Clusters-using-Darshan-Logs"><a href="#I-O-Burst-Prediction-for-HPC-Clusters-using-Darshan-Logs" class="headerlink" title="I&#x2F;O Burst Prediction for HPC Clusters using Darshan Logs"></a>I&#x2F;O Burst Prediction for HPC Clusters using Darshan Logs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10311">http://arxiv.org/abs/2308.10311</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ehsan Saeedizade, Roya Taheri, Engin Arslan</li>
<li>for: 本研究旨在分析大规模高性能计算（HPC）集群中的读写IO patrern，以优化IO性能和应用运行时间。</li>
<li>methods: 本研究使用Darshan报告数据分析系统级别的读写IO率，并使用机器学习模型预测IO峰值事件。</li>
<li>results: 研究发现系统级别的IO峰值事件频繁发生，并可以使用机器学习模型高度准确预测IO峰值事件（准确率超过90%）。此外，研究还提出了一种基于IO峰值预测的应用调度策略，可以减少应用运行时间。<details>
<summary>Abstract</summary>
Understanding cluster-wide I/O patterns of large-scale HPC clusters is essential to minimize the occurrence and impact of I/O interference. Yet, most previous work in this area focused on monitoring and predicting task and node-level I/O burst events. This paper analyzes Darshan reports from three supercomputers to extract system-level read and write I/O rates in five minutes intervals. We observe significant (over 100x) fluctuations in read and write I/O rates in all three clusters. We then train machine learning models to estimate the occurrence of system-level I/O bursts 5 - 120 minutes ahead. Evaluation results show that we can predict I/O bursts with more than 90% accuracy (F-1 score) five minutes ahead and more than 87% accuracy two hours ahead. We also show that the ML models attain more than 70% accuracy when estimating the degree of the I/O burst. We believe that high-accuracy predictions of I/O bursts can be used in multiple ways, such as postponing delay-tolerant I/O operations (e.g., checkpointing), pausing nonessential applications (e.g., file system scrubbers), and devising I/O-aware job scheduling methods. To validate this claim, we simulated a burst-aware job scheduler that can postpone the start time of applications to avoid I/O bursts. We show that the burst-aware job scheduling can lead to an up to 5x decrease in application runtime.
</details>
<details>
<summary>摘要</summary>
理解大规模HPC集群中的各种I/O模式是必要的，以避免I/O干扰的发生和影响。然而，大多数前一些工作都是关注监测和预测任务和节点级I/O异常事件。本文分析了Darshan报告从三个超级计算机，以提取系统级读写I/O速率的五分钟间隔。我们发现所有三个集群中有显著的读写I/O速率波动（超过100倍）。然后，我们训练机器学习模型，以估计系统级I/O异常事件的发生5-120分钟前。评估结果表明，我们可以在5分钟前预测I/O异常事件的occurrence高于90%（F-1分数），并在2小时前预测高于87%。此外，我们还证明了ML模型可以在70%以上的情况下估计I/O异常事件的严重程度。我们认为高精度的I/O异常预测可以用于多种方式，如延迟允许延迟I/O操作（例如检查点）、挫止非关键应用程序（例如文件系统扫描），以及开发I/O感知的任务调度方法。为证明这一点，我们模拟了一种基于I/O异常预测的任务调度策略，可以在I/O异常事件发生时推迟应用程序的启动时间。我们显示该策略可以降低应用程序的运行时间，最高可达5倍。
</details></li>
</ul>
<hr>
<h2 id="Co-Evolution-of-Pose-and-Mesh-for-3D-Human-Body-Estimation-from-Video"><a href="#Co-Evolution-of-Pose-and-Mesh-for-3D-Human-Body-Estimation-from-Video" class="headerlink" title="Co-Evolution of Pose and Mesh for 3D Human Body Estimation from Video"></a>Co-Evolution of Pose and Mesh for 3D Human Body Estimation from Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10305">http://arxiv.org/abs/2308.10305</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kasvii/pmce">https://github.com/kasvii/pmce</a></li>
<li>paper_authors: Yingxuan You, Hong Liu, Ti Wang, Wenhao Li, Runwei Ding, Xia Li</li>
<li>for: 该论文目的是提出一种基于视频的3D人体模型重建方法，以提高现有方法的精度和准确性。</li>
<li>methods: 该方法使用了一种名为Pose and Mesh Co-Evolution网络（PMCE），它将该任务分解为两个部分：1）视频基于3D人体 pose 估计，2）从估计的3Dpose和时间像素特征中进行顶点 regression。</li>
<li>results: 对于三个 benchmark 数据集（3DPW、Human3.6M 和 MPI-INF-3DHP），该方法的实验结果表明，PMCE 在每帧精度和时间一致性方面都有较前方法的优势。<details>
<summary>Abstract</summary>
Despite significant progress in single image-based 3D human mesh recovery, accurately and smoothly recovering 3D human motion from a video remains challenging. Existing video-based methods generally recover human mesh by estimating the complex pose and shape parameters from coupled image features, whose high complexity and low representation ability often result in inconsistent pose motion and limited shape patterns. To alleviate this issue, we introduce 3D pose as the intermediary and propose a Pose and Mesh Co-Evolution network (PMCE) that decouples this task into two parts: 1) video-based 3D human pose estimation and 2) mesh vertices regression from the estimated 3D pose and temporal image feature. Specifically, we propose a two-stream encoder that estimates mid-frame 3D pose and extracts a temporal image feature from the input image sequence. In addition, we design a co-evolution decoder that performs pose and mesh interactions with the image-guided Adaptive Layer Normalization (AdaLN) to make pose and mesh fit the human body shape. Extensive experiments demonstrate that the proposed PMCE outperforms previous state-of-the-art methods in terms of both per-frame accuracy and temporal consistency on three benchmark datasets: 3DPW, Human3.6M, and MPI-INF-3DHP. Our code is available at https://github.com/kasvii/PMCE.
</details>
<details>
<summary>摘要</summary>
尽管单个图像基于3D人体模lesh recovering已经做出了 significativ progress,但从视频中准确和平滑地recover3D人体运动仍然是一个挑战。现有的视频基本方法通常通过计算复杂的姿势和形态参数来恢复人体模lesh， whose high complexity and low representation ability often result in inconsistent pose motion and limited shape patterns. To address this issue, we introduce 3D pose as the intermediary and propose a Pose and Mesh Co-Evolution network (PMCE) that decouples this task into two parts: 1) video-based 3D human pose estimation and 2) mesh vertices regression from the estimated 3D pose and temporal image feature. Specifically, we propose a two-stream encoder that estimates mid-frame 3D pose and extracts a temporal image feature from the input image sequence. In addition, we design a co-evolution decoder that performs pose and mesh interactions with the image-guided Adaptive Layer Normalization (AdaLN) to make pose and mesh fit the human body shape. Extensive experiments demonstrate that the proposed PMCE outperforms previous state-of-the-art methods in terms of both per-frame accuracy and temporal consistency on three benchmark datasets: 3DPW, Human3.6M, and MPI-INF-3DHP. Our code is available at https://github.com/kasvii/PMCE.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/21/cs.LG_2023_08_21/" data-id="clohum99h00njpj889tc5gj0z" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_21" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/21/eess.IV_2023_08_21/" class="article-date">
  <time datetime="2023-08-21T09:00:00.000Z" itemprop="datePublished">2023-08-21</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/21/eess.IV_2023_08_21/">eess.IV - 2023-08-21</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Extraction-of-Text-from-Optic-Nerve-Optical-Coherence-Tomography-Reports"><a href="#Extraction-of-Text-from-Optic-Nerve-Optical-Coherence-Tomography-Reports" class="headerlink" title="Extraction of Text from Optic Nerve Optical Coherence Tomography Reports"></a>Extraction of Text from Optic Nerve Optical Coherence Tomography Reports</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10790">http://arxiv.org/abs/2308.10790</a></li>
<li>repo_url: None</li>
<li>paper_authors: Iyad Majid, Youchen Victor Zhang, Robert Chang, Sophia Y. Wang</li>
<li>for: 这项研究的目的是开发和评估基于规则的算法，以提高光学同步 Tomatoes OCT扫描报告中的文本数据提取，包括肾脚层（RNFL）值和其他神经细胞计数（GCC）数据。</li>
<li>methods: 这项研究使用了DICOM文件，其中包含PDF报告，并使用PaddleOCR Python包进行光学字符识别。基于规则的算法被设计和优化，以提高RNFL和GCC数据提取的精度。</li>
<li>results: 研究显示，开发的算法可以准确地从RNFL和GCC扫描报告中提取数据，其中OD和OS之间的准确率有所不同。这些值可以大幅提高大规模的OCT结果提取速度。<details>
<summary>Abstract</summary>
Purpose: The purpose of this study was to develop and evaluate rule-based algorithms to enhance the extraction of text data, including retinal nerve fiber layer (RNFL) values and other ganglion cell count (GCC) data, from Zeiss Cirrus optical coherence tomography (OCT) scan reports. Methods: DICOM files that contained encapsulated PDF reports with RNFL or Ganglion Cell in their document titles were identified from a clinical imaging repository at a single academic ophthalmic center. PDF reports were then converted into image files and processed using the PaddleOCR Python package for optical character recognition. Rule-based algorithms were designed and iteratively optimized for improved performance in extracting RNFL and GCC data. Evaluation of the algorithms was conducted through manual review of a set of RNFL and GCC reports. Results: The developed algorithms demonstrated high precision in extracting data from both RNFL and GCC scans. Precision was slightly better for the right eye in RNFL extraction (OD: 0.9803 vs. OS: 0.9046), and for the left eye in GCC extraction (OD: 0.9567 vs. OS: 0.9677). Some values presented more challenges in extraction, particularly clock hours 5 and 6 for RNFL thickness, and signal strength for GCC. Conclusions: A customized optical character recognition algorithm can identify numeric results from optical coherence scan reports with high precision. Automated processing of PDF reports can greatly reduce the time to extract OCT results on a large scale.
</details>
<details>
<summary>摘要</summary>
目的：本研究旨在开发和评估基于规则的算法，以提高从Zeiss Cirrus光学同步图像（OCT）扫描报告中提取文本数据的精度，包括视网膜神经层（RNFL）值和其他神经细胞计数（GCC）数据。方法：从一所学术眼科中心的临床扫描存储库中提取符合DICOM文件格式的PDF报告，其中文档标题包含“RNFL”或“GCC”。PDF报告被转换为图像文件，并使用Python中的PaddleOCR包进行光学字符识别。为了提高数据提取的精度，我们设计了规则基本的算法，并在多个迭代优化过程中进行优化。结果：开发的算法在RNFL和GCC扫描报告中的数据提取中具有高精度。对于右眼RNFL提取，精度为0.9803，对于左眼GCC提取，精度为0.9567。然而，某些值在提取时存在更大的挑战，包括时钟小时5和6的RNFL厚度，以及GCC的信号强度。结论：可以使用自定义的光学字符识别算法来从OCT扫描报告中提取数据，并且自动处理PDF报告可以大幅降低在大规模上提取OCT结果的时间。
</details></li>
</ul>
<hr>
<h2 id="Dense-Error-Map-Estimation-for-MRI-Ultrasound-Registration-in-Brain-Tumor-Surgery-Using-Swin-UNETR"><a href="#Dense-Error-Map-Estimation-for-MRI-Ultrasound-Registration-in-Brain-Tumor-Surgery-Using-Swin-UNETR" class="headerlink" title="Dense Error Map Estimation for MRI-Ultrasound Registration in Brain Tumor Surgery Using Swin UNETR"></a>Dense Error Map Estimation for MRI-Ultrasound Registration in Brain Tumor Surgery Using Swin UNETR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10784">http://arxiv.org/abs/2308.10784</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soorena Salari, Amirhossein Rasoulian, Hassan Rivaz, Yiming Xiao</li>
<li>for: 降低手术死亡率的早期脑肿瘤手术是关键，但是手术期间脑组织变形（脑Shift）会使得先前的图像无效。因此，成本低廉，可携带的内部手术超声（iUS）可以跟踪脑Shift，并准确地将MRI-iUS注射技术与先前的图像进行匹配。这可以提高手术安全性和效果，最大化肿瘤除除 while avoiding critical regions.</li>
<li>methods: 我们提出了一种基于深度学习（DL）的框架，使用Swin UNITER来自动评估MRI-iUS注射结果的3D密集错误地图，并在实际临床数据上显示其性能。</li>
<li>results: 我们的方法可以准确地评估MRI-iUS注射结果的质量，并且可以在实际临床情况下提高手术安全性和效果。<details>
<summary>Abstract</summary>
Early surgical treatment of brain tumors is crucial in reducing patient mortality rates. However, brain tissue deformation (called brain shift) occurs during the surgery, rendering pre-operative images invalid. As a cost-effective and portable tool, intra-operative ultrasound (iUS) can track brain shift, and accurate MRI-iUS registration techniques can update pre-surgical plans and facilitate the interpretation of iUS. This can boost surgical safety and outcomes by maximizing tumor removal while avoiding eloquent regions. However, manual assessment of MRI-iUS registration results in real-time is difficult and prone to errors due to the 3D nature of the data. Automatic algorithms that can quantify the quality of inter-modal medical image registration outcomes can be highly beneficial. Therefore, we propose a novel deep-learning (DL) based framework with the Swin UNETR to automatically assess 3D-patch-wise dense error maps for MRI-iUS registration in iUS-guided brain tumor resection and show its performance with real clinical data for the first time.
</details>
<details>
<summary>摘要</summary>
早期脑肿手术治疗是减少病人死亡率的关键。然而，手术期间脑组织变形（称为脑移动）会使先前的成像无效。作为一种可靠且可搬运的工具，实时ultrasound（iUS）可以跟踪脑移动，并且精准的MRI-iUS注册技术可以更新先前的计划，并且可以帮助解释iUS。这可以提高手术安全性和效果，最大化肿瘤除除而避免重要区域。然而，手动评估MRI-iUS注册结果的实时性困难，并且容易出错，因为数据的3D性。自动的算法可以评估多Modal医疗影像注册结果的质量。因此，我们提出了一种基于深度学习（DL）的框架，使用Swin UNITER来自动评估3D-patch-wise稠密错误地图 дляMRI-iUS注册，并且在实际临床数据上展示其性能。
</details></li>
</ul>
<hr>
<h2 id="Automated-Identification-of-Failure-Cases-in-Organ-at-Risk-Segmentation-Using-Distance-Metrics-A-Study-on-CT-Data"><a href="#Automated-Identification-of-Failure-Cases-in-Organ-at-Risk-Segmentation-Using-Distance-Metrics-A-Study-on-CT-Data" class="headerlink" title="Automated Identification of Failure Cases in Organ at Risk Segmentation Using Distance Metrics: A Study on CT Data"></a>Automated Identification of Failure Cases in Organ at Risk Segmentation Using Distance Metrics: A Study on CT Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10636">http://arxiv.org/abs/2308.10636</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amin Honarmandi Shandiz, Attila Rádics, Rajesh Tamada, Makk Árpád, Karolina Glowacka, Lehel Ferenczi, Sandeep Dutta, Michael Fanariotis</li>
<li>for: 提高自动组织器的肿瘤识别精度，以避免治疗规划错误。</li>
<li>methods: 使用自动模型生成的肿瘤边界概率分布，并使用Dice和 Hausdorff距离的组合来自动标识失败案例。</li>
<li>results: 通过设置Dice和 Hausdorff距离的阈值，可以快速自动标识失败案例，并且可以 diferenciate 不同类型的失败案例。<details>
<summary>Abstract</summary>
Automated organ at risk (OAR) segmentation is crucial for radiation therapy planning in CT scans, but the generated contours by automated models can be inaccurate, potentially leading to treatment planning issues. The reasons for these inaccuracies could be varied, such as unclear organ boundaries or inaccurate ground truth due to annotation errors. To improve the model's performance, it is necessary to identify these failure cases during the training process and to correct them with some potential post-processing techniques. However, this process can be time-consuming, as traditionally it requires manual inspection of the predicted output. This paper proposes a method to automatically identify failure cases by setting a threshold for the combination of Dice and Hausdorff distances. This approach reduces the time-consuming task of visually inspecting predicted outputs, allowing for faster identification of failure case candidates. The method was evaluated on 20 cases of six different organs in CT images from clinical expert curated datasets. By setting the thresholds for the Dice and Hausdorff distances, the study was able to differentiate between various states of failure cases and evaluate over 12 cases visually. This thresholding approach could be extended to other organs, leading to faster identification of failure cases and thereby improving the quality of radiation therapy planning.
</details>
<details>
<summary>摘要</summary>
自动化的器官在险 (OAR) 分 segmentation 是辐射疗程规划 CT 扫描中的关键，但自动生成的界限可能不准确，可能导致治疗规划问题。这些不准确的原因可能是不清晰的器官边界或不准确的真实数据 due to 注释错误。要提高模型的表现，需要在训练过程中确认这些失败案例，并使用一些可能的后处理技术来更正它们。但是，这个过程可能会占用时间，因为传统上需要手动检查预测的输出。这篇论文提出了一种方法，通过设置 Dice 和 Hausdorff 距离的组合来自动确定失败案例。这种方法可以减少手动检查预测输出的时间消耗，使得更快地确定失败案例候选者。本研究在 20 个不同的器官中进行了 CT 图像的评估，并通过设置 Dice 和 Hausdorff 距离的阈值，可以区分不同的失败案例状态，并评估了 12 个案例。这种阈值设定方法可以扩展到其他器官，从而更快地确定失败案例，提高辐射疗程规划的质量。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Medical-Image-Segmentation-Optimizing-Cross-Entropy-Weights-and-Post-Processing-with-Autoencoders"><a href="#Enhancing-Medical-Image-Segmentation-Optimizing-Cross-Entropy-Weights-and-Post-Processing-with-Autoencoders" class="headerlink" title="Enhancing Medical Image Segmentation: Optimizing Cross-Entropy Weights and Post-Processing with Autoencoders"></a>Enhancing Medical Image Segmentation: Optimizing Cross-Entropy Weights and Post-Processing with Autoencoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10488">http://arxiv.org/abs/2308.10488</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pranav Singh, Luoyao Chen, Mei Chen, Jinqian Pan, Raviteja Chukkapalli, Shravan Chaudhari, Jacopo Cirrone<br>for:This paper is written for the task of medical image segmentation, specifically focusing on the analysis of cell inflammation and interaction in autoimmune diseases like dermatomyositis.methods:The proposed method uses a deep-learning approach tailored for medical image segmentation, which includes the use of U-Net and U-Net++ architectures with optimized loss function weights.results:The proposed method outperforms the current state-of-the-art techniques by an average of 12.26% for U-Net and 12.04% for U-Net++ across the ResNet family of encoders on the dermatomyositis dataset.<details>
<summary>Abstract</summary>
The task of medical image segmentation presents unique challenges, necessitating both localized and holistic semantic understanding to accurately delineate areas of interest, such as critical tissues or aberrant features. This complexity is heightened in medical image segmentation due to the high degree of inter-class similarities, intra-class variations, and possible image obfuscation. The segmentation task further diversifies when considering the study of histopathology slides for autoimmune diseases like dermatomyositis. The analysis of cell inflammation and interaction in these cases has been less studied due to constraints in data acquisition pipelines. Despite the progressive strides in medical science, we lack a comprehensive collection of autoimmune diseases. As autoimmune diseases globally escalate in prevalence and exhibit associations with COVID-19, their study becomes increasingly essential. While there is existing research that integrates artificial intelligence in the analysis of various autoimmune diseases, the exploration of dermatomyositis remains relatively underrepresented. In this paper, we present a deep-learning approach tailored for Medical image segmentation. Our proposed method outperforms the current state-of-the-art techniques by an average of 12.26% for U-Net and 12.04% for U-Net++ across the ResNet family of encoders on the dermatomyositis dataset. Furthermore, we probe the importance of optimizing loss function weights and benchmark our methodology on three challenging medical image segmentation tasks
</details>
<details>
<summary>摘要</summary>
医学影像分割任务存在独特的挑战，需要同时具备地方化和整体的semantic理解，以准确地界定关键组织或异常特征。这种复杂性由医学影像分割中高度的间类相似性、内类变化和可能存在的图像掩蔽所增加。在医学影像分割任务中，考虑 histopathology 扫描片的涂抹病例，如dermatomyositis，分割任务会更加多样化。由于医学科学的进步，我们缺乏一个全面的自适应病种集成。随着自适应病种的全球流行病例和COVID-19的相关性，其研究变得越来越重要。虽然现有的研究已经将人工智能Integrated into the analysis of various autoimmune diseases，但dermatomyositis的研究仍然相对落后。在这篇文章中，我们提出了一种适应医学影像分割的深度学习方法。我们的提议方法在ResNet家族encoder上的dermatomyositis数据集上比现状前景技术平均提高12.26%和12.04%。此外，我们还探索了优化损失函数的权重和对三个困难的医学影像分割任务进行比较。
</details></li>
</ul>
<hr>
<h2 id="Prediction-of-Pneumonia-and-COVID-19-Using-Deep-Neural-Networks"><a href="#Prediction-of-Pneumonia-and-COVID-19-Using-Deep-Neural-Networks" class="headerlink" title="Prediction of Pneumonia and COVID-19 Using Deep Neural Networks"></a>Prediction of Pneumonia and COVID-19 Using Deep Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10368">http://arxiv.org/abs/2308.10368</a></li>
<li>repo_url: None</li>
<li>paper_authors: M. S. Haque, M. S. Taluckder, S. B. Shawkat, M. A. Shahriyar, M. A. Sayed, C. Modak</li>
<li>for: 这个研究旨在采用医疗图像分析技术来检测肺炎。</li>
<li>methods: 该研究使用了多种机器学习模型，包括 DenseNet121、Inception Resnet-v2、Inception Resnet-v3、Resnet50 和 Xception，以分析肺 X 光图像。</li>
<li>results: 研究发现，DenseNet121 模型在肺炎检测中表现最佳，准确率达到 99.58%。<details>
<summary>Abstract</summary>
Pneumonia, caused by bacteria and viruses, is a rapidly spreading viral infection with global implications. Prompt identification of infected individuals is crucial for containing its transmission. This study explores the potential of medical image analysis to address this challenge. We propose machine-learning techniques for predicting Pneumonia from chest X-ray images. Chest X-ray imaging is vital for Pneumonia diagnosis due to its accessibility and cost-effectiveness. However, interpreting X-rays for Pneumonia detection can be complex, as radiographic features can overlap with other respiratory conditions. We evaluate the performance of different machine learning models, including DenseNet121, Inception Resnet-v2, Inception Resnet-v3, Resnet50, and Xception, using chest X-ray images of pneumonia patients. Performance measures and confusion matrices are employed to assess and compare the models. The findings reveal that DenseNet121 outperforms other models, achieving an accuracy rate of 99.58%. This study underscores the significance of machine learning in the accurate detection of Pneumonia, leveraging chest X-ray images. Our study offers insights into the potential of technology to mitigate the spread of pneumonia through precise diagnostics.
</details>
<details>
<summary>摘要</summary>
“肺炎，由病毒和 бактеリум引起，是一种快速传播的病毒感染，具有全球化的意义。 Prompt 识别感染者是防止传播的关键。这项研究探讨医疗图像分析可以解决这个挑战。我们提出运用机器学习技术预测肺炎的方法。颈部X线图像是肺炎诊断的重要工具，因为它具有访问性和成本效益。但是，解释颈部X线可能会与其他呼吸道疾病相似，因此需要进一步的分析。我们评估了不同的机器学习模型，包括DenseNet121、Inception Resnet-v2、Inception Resnet-v3、Resnet50和Xception，使用颈部X线图像。我们使用性能指标和混淆矩阵来评估和比较这些模型。研究结果显示DenseNet121最高的准确率为99.58%。这项研究认为机器学习可以帮助精确诊断肺炎，利用颈部X线图像。我们的研究给出了技术可以减少肺炎的传播的可能性。”Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/21/eess.IV_2023_08_21/" data-id="clohum9ff013wpj885g645n1p" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/20/cs.SD_2023_08_20/" class="article-date">
  <time datetime="2023-08-20T15:00:00.000Z" itemprop="datePublished">2023-08-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/20/cs.SD_2023_08_20/">cs.SD - 2023-08-20</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Indonesian-Automatic-Speech-Recognition-with-XLSR-53"><a href="#Indonesian-Automatic-Speech-Recognition-with-XLSR-53" class="headerlink" title="Indonesian Automatic Speech Recognition with XLSR-53"></a>Indonesian Automatic Speech Recognition with XLSR-53</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11589">http://arxiv.org/abs/2308.11589</a></li>
<li>repo_url: None</li>
<li>paper_authors: Panji Arisaputra, Amalia Zahra</li>
<li>For: 这个研究旨在开发一个使用XLSR-53预训练模型的印度尼西亚自动语音识别（ASR）系统，以减少非英语语言的训练数据量，以达到竞争力很高的单词错误率（WER）。* Methods: 该研究使用的方法包括使用XLSR-53预训练模型，并使用TITML-IDN、Magic Data和Common Voice等数据集进行训练。* Results: 该研究的结果显示，使用XLSR-53预训练模型可以在WER20%的基础上减少约8%的错误率，从而实现了在相似的模型中减少训练数据量的目标。<details>
<summary>Abstract</summary>
This study focuses on the development of Indonesian Automatic Speech Recognition (ASR) using the XLSR-53 pre-trained model, the XLSR stands for cross-lingual speech representations. The use of this XLSR-53 pre-trained model is to significantly reduce the amount of training data in non-English languages required to achieve a competitive Word Error Rate (WER). The total amount of data used in this study is 24 hours, 18 minutes, and 1 second: (1) TITML-IDN 14 hours and 31 minutes; (2) Magic Data 3 hours and 33 minutes; and (3) Common Voice 6 hours, 14 minutes, and 1 second. With a WER of 20%, the model built in this study can compete with similar models using the Common Voice dataset split test. WER can be decreased by around 8% using a language model, resulted in WER from 20% to 12%. Thus, the results of this study have succeeded in perfecting previous research in contributing to the creation of a better Indonesian ASR with a smaller amount of data.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/20/cs.SD_2023_08_20/" data-id="clohum9bo00typj88cbifgny2" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/20/cs.CV_2023_08_20/" class="article-date">
  <time datetime="2023-08-20T13:00:00.000Z" itemprop="datePublished">2023-08-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/20/cs.CV_2023_08_20/">cs.CV - 2023-08-20</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Boosting-Adversarial-Transferability-by-Block-Shuffle-and-Rotation"><a href="#Boosting-Adversarial-Transferability-by-Block-Shuffle-and-Rotation" class="headerlink" title="Boosting Adversarial Transferability by Block Shuffle and Rotation"></a>Boosting Adversarial Transferability by Block Shuffle and Rotation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10299">http://arxiv.org/abs/2308.10299</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kunyu Wang, Xuanran He, Wenxuan Wang, Xiaosen Wang</li>
<li>for: This paper focuses on improving the transferability of adversarial examples in the black-box setting.</li>
<li>methods: The proposed method, called block shuffle and rotation (BSR), uses input transformation to create a set of new images for gradient calculation.</li>
<li>results: The BSR method achieves significantly better transferability than existing input transformation based methods under single-model and ensemble-model settings, and combining BSR with current input transformation methods further improves transferability.Here’s the simplified Chinese version:</li>
<li>for: 这篇论文关注在黑盒Setting下的攻击 transferred examples的改进。</li>
<li>methods: 提议的方法是block shuffle and rotation (BSR)，通过输入变换创建一组新图像进行梯度计算。</li>
<li>results: BSR方法在单个模型和ensemble-model Settings下表现出了显著更好的传输性能，并且将BSR方法与当前输入变换方法组合使用可以减少攻击性能。<details>
<summary>Abstract</summary>
Adversarial examples mislead deep neural networks with imperceptible perturbations and have brought significant threats to deep learning. An important aspect is their transferability, which refers to their ability to deceive other models, thus enabling attacks in the black-box setting. Though various methods have been proposed to boost transferability, the performance still falls short compared with white-box attacks. In this work, we observe that existing input transformation based attacks, one of the mainstream transfer-based attacks, result in different attention heatmaps on various models, which might limit the transferability. We also find that breaking the intrinsic relation of the image can disrupt the attention heatmap of the original image. Based on this finding, we propose a novel input transformation based attack called block shuffle and rotation (BSR). Specifically, BSR splits the input image into several blocks, then randomly shuffles and rotates these blocks to construct a set of new images for gradient calculation. Empirical evaluations on the ImageNet dataset demonstrate that BSR could achieve significantly better transferability than the existing input transformation based methods under single-model and ensemble-model settings. Combining BSR with the current input transformation method can further improve the transferability, which significantly outperforms the state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
深度学习系统中的敌对示例会使用微小的扰动来诱导深度神经网络，从而带来了深度学习的重要威胁。其中一个重要的方面是它们的传输性，即它们能够在黑盒Setting中欺骗其他模型，从而实现攻击。虽然已有许多方法提出来增强传输性，但其性能仍然落后于白盒攻击。在这个工作中，我们发现了现有的输入变换基于攻击方法中的一个主要问题，即输入变换后的图像的注意力热图与不同的模型存在差异，这可能限制了传输性。我们还发现，将图像的内在关系打破可以破坏原始图像的注意力热图。基于这一发现，我们提出了一种新的输入变换基于攻击方法，即块排序和旋转（BSR）。具体来说，BSR将输入图像分成多个块，然后随机排序和旋转这些块来构建一组新的图像，用于计算梯度。我们对ImageNet dataset进行了实验，表明BSR可以在单模型和集成模型的设置下实现显著更好的传输性，并且与现有的输入变换方法结合使用可以进一步提高传输性，与当前最佳方法强制升级。
</details></li>
</ul>
<hr>
<h2 id="DomainAdaptor-A-Novel-Approach-to-Test-time-Adaptation"><a href="#DomainAdaptor-A-Novel-Approach-to-Test-time-Adaptation" class="headerlink" title="DomainAdaptor: A Novel Approach to Test-time Adaptation"></a>DomainAdaptor: A Novel Approach to Test-time Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10297">http://arxiv.org/abs/2308.10297</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jian Zhang, Lei Qi, Yinghuan Shi, Yang Gao</li>
<li>for: 这个论文的目的是如何在试用时进行预测 task 中对应预测数据的预测问题，并且对于缺乏资料的情况下进行更好的预测。</li>
<li>methods: 这个论文提出了一个叫做 DomainAdaptor 的方法，它包括一个 AdaMixBN 模组和一个 Generalized Entropy Minimization (GEM) 损失函数。AdaMixBN 模组通过动态混合系数和统计转换操作来适应训练和试用数据之间的领域差异。而 GEM 损失函数则是将 Entropy Minimization 损失函数扩展以更好地利用试用数据中的信息。</li>
<li>results: 实验结果显示，DomainAdaptor 可以与现有的方法相比，在四个 benchmark 上实现更高的预测性能。此外，在缺乏数据的情况下，DomainAdaptor 对于几个缺乏数据的benchmark 也实现了更大的改进。<details>
<summary>Abstract</summary>
To deal with the domain shift between training and test samples, current methods have primarily focused on learning generalizable features during training and ignore the specificity of unseen samples that are also critical during the test. In this paper, we investigate a more challenging task that aims to adapt a trained CNN model to unseen domains during the test. To maximumly mine the information in the test data, we propose a unified method called DomainAdaptor for the test-time adaptation, which consists of an AdaMixBN module and a Generalized Entropy Minimization (GEM) loss. Specifically, AdaMixBN addresses the domain shift by adaptively fusing training and test statistics in the normalization layer via a dynamic mixture coefficient and a statistic transformation operation. To further enhance the adaptation ability of AdaMixBN, we design a GEM loss that extends the Entropy Minimization loss to better exploit the information in the test data. Extensive experiments show that DomainAdaptor consistently outperforms the state-of-the-art methods on four benchmarks. Furthermore, our method brings more remarkable improvement against existing methods on the few-data unseen domain. The code is available at https://github.com/koncle/DomainAdaptor.
</details>
<details>
<summary>摘要</summary>
Current methods have primarily focused on learning generalizable features during training and ignore the specificity of unseen samples, which are also critical during the test. In this paper, we investigate a more challenging task that aims to adapt a trained CNN model to unseen domains during the test. To maximize the information in the test data, we propose a unified method called DomainAdaptor for the test-time adaptation, which consists of an AdaMixBN module and a Generalized Entropy Minimization (GEM) loss. Specifically, AdaMixBN addresses the domain shift by adaptively fusing training and test statistics in the normalization layer via a dynamic mixture coefficient and a statistic transformation operation. To further enhance the adaptation ability of AdaMixBN, we design a GEM loss that extends the Entropy Minimization loss to better exploit the information in the test data. Extensive experiments show that DomainAdaptor consistently outperforms the state-of-the-art methods on four benchmarks. Furthermore, our method brings more remarkable improvement against existing methods on the few-data unseen domain. The code is available at https://github.com/koncle/DomainAdaptor.Here's the Chinese translation of each sentence:现在的方法主要关注在训练时学习通用特征，而忽略了测试时的特定样本，这些样本也是非常重要的。在这篇论文中，我们调查了一个更加具有挑战性的任务，即在测试时对未seen域进行适应。以maximize测试数据中的信息，我们提出了一种统一的方法 called DomainAdaptor，它包括 AdaMixBN 模块和一种通用 Entropy Minimization (GEM) 损失函数。具体来说，AdaMixBN 模块通过在normalization层中动态混合训练和测试统计信息，来 Address the domain shift。此外，我们还设计了一种 GEM 损失函数，它将 Entropy Minimization 损失函数扩展到更好地利用测试数据中的信息。经过广泛的实验，我们发现 DomainAdaptor 可以一直性地超越当前的方法在四个标准benchmark上。此外，我们的方法在几个数据少的未seen域上带来更加卓越的改进。代码可以在https://github.com/koncle/DomainAdaptor 中下载。
</details></li>
</ul>
<hr>
<h2 id="Privileged-Anatomical-and-Protocol-Discrimination-in-Trackerless-3D-Ultrasound-Reconstruction"><a href="#Privileged-Anatomical-and-Protocol-Discrimination-in-Trackerless-3D-Ultrasound-Reconstruction" class="headerlink" title="Privileged Anatomical and Protocol Discrimination in Trackerless 3D Ultrasound Reconstruction"></a>Privileged Anatomical and Protocol Discrimination in Trackerless 3D Ultrasound Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10293">http://arxiv.org/abs/2308.10293</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qi Li, Ziyi Shen, Qian Li, Dean C. Barratt, Thomas Dowrick, Matthew J. Clarkson, Tom Vercauteren, Yipeng Hu</li>
<li>for: 这 paper 是为了提高深度神经网络（DNN）无需外部跟踪设备的三维自由手 Ultrasound（US）重建的研究。</li>
<li>methods: 这 paper 使用了两个可能的改进 DNN-based 重建方法的因素：解剖学和协议。 authors 提议使用这两个因素作为静观信息，以提高现有的 DNN-based 方法。</li>
<li>results: 实验结果表明，解剖学和协议变化都是 DNN-based US 重建的能量因素；学习不同的主体（解剖学变化）和预先定义的扫描路径（协议变化）都能显著提高帧预测精度、重建覆盖率、累积跟踪误差和最终漂移。<details>
<summary>Abstract</summary>
Three-dimensional (3D) freehand ultrasound (US) reconstruction without using any additional external tracking device has seen recent advances with deep neural networks (DNNs). In this paper, we first investigated two identified contributing factors of the learned inter-frame correlation that enable the DNN-based reconstruction: anatomy and protocol. We propose to incorporate the ability to represent these two factors - readily available during training - as the privileged information to improve existing DNN-based methods. This is implemented in a new multi-task method, where the anatomical and protocol discrimination are used as auxiliary tasks. We further develop a differentiable network architecture to optimise the branching location of these auxiliary tasks, which controls the ratio between shared and task-specific network parameters, for maximising the benefits from the two auxiliary tasks. Experimental results, on a dataset with 38 forearms of 19 volunteers acquired with 6 different scanning protocols, show that 1) both anatomical and protocol variances are enabling factors for DNN-based US reconstruction; 2) learning how to discriminate different subjects (anatomical variance) and predefined types of scanning paths (protocol variance) both significantly improve frame prediction accuracy, volume reconstruction overlap, accumulated tracking error and final drift, using the proposed algorithm.
</details>
<details>
<summary>摘要</summary>
三维自由手操作超声成像（US）已经在最近得到了深度神经网络（DNN）的进步。在这篇论文中，我们首先调查了两个促进学习的交叉帧相关性的因素：解剖学和协议。我们提议将这两个因素作为特权信息，以改进现有的DNN基于方法。我们实现了一种新的多任务方法，其中解剖学和协议歧义被用作辅助任务。我们进一步开发了可导网络架构，以优化分支位置，控制分支位置中共享和任务特定的网络参数的比例，以最大化来自两个辅助任务的利益。实验结果，在38只臂和19名志愿者通过6种扫描协议获得的数据集上，显示了以下结论：1）解剖学和协议的差异都是US成像中的促进因素；2）学习不同主体（解剖学差异）和预定的扫描路径（协议差异）都能够显著提高帧预测精度、重建 overlap、累积跟踪误差和最终漂移。使用我们提议的算法可以获得这些结果。
</details></li>
</ul>
<hr>
<h2 id="Efficient-VRNet-An-Exquisite-Fusion-Network-for-Riverway-Panoptic-Perception-based-on-Asymmetric-Fair-Fusion-of-Vision-and-4D-mmWave-Radar"><a href="#Efficient-VRNet-An-Exquisite-Fusion-Network-for-Riverway-Panoptic-Perception-based-on-Asymmetric-Fair-Fusion-of-Vision-and-4D-mmWave-Radar" class="headerlink" title="Efficient-VRNet: An Exquisite Fusion Network for Riverway Panoptic Perception based on Asymmetric Fair Fusion of Vision and 4D mmWave Radar"></a>Efficient-VRNet: An Exquisite Fusion Network for Riverway Panoptic Perception based on Asymmetric Fair Fusion of Vision and 4D mmWave Radar</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10287">http://arxiv.org/abs/2308.10287</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/GuanRunwei/Efficient-VRNet">https://github.com/GuanRunwei/Efficient-VRNet</a></li>
<li>paper_authors: Runwei Guan, Shanliang Yao, Xiaohui Zhu, Ka Lok Man, Yong Yue, Jeremy Smith, Eng Gee Lim, Yutao Yue</li>
<li>for: 这个论文的目的是提出一个基于 USV 的河道全景感知方法，以提高自动航行的精度和安全性。</li>
<li>methods: 本论文使用了 Contextual Clustering (CoC) 和非对称的视觉和4D mmWave 激光数据融合，实现了同时进行物体检测和 semantic segmentation。</li>
<li>results: 在实验中，我们的 Efficient-VRNet 模型在我们自己收集的数据集上表现出色，特别是在不良天气和环境下，其性能比其他单模型更好。<details>
<summary>Abstract</summary>
Panoptic perception is essential to unmanned surface vehicles (USVs) for autonomous navigation. The current panoptic perception scheme is mainly based on vision only, that is, object detection and semantic segmentation are performed simultaneously based on camera sensors. Nevertheless, the fusion of camera and radar sensors is regarded as a promising method which could substitute pure vision methods, but almost all works focus on object detection only. Therefore, how to maximize and subtly fuse the features of vision and radar to improve both detection and segmentation is a challenge. In this paper, we focus on riverway panoptic perception based on USVs, which is a considerably unexplored field compared with road panoptic perception. We propose Efficient-VRNet, a model based on Contextual Clustering (CoC) and the asymmetric fusion of vision and 4D mmWave radar, which treats both vision and radar modalities fairly. Efficient-VRNet can simultaneously perform detection and segmentation of riverway objects and drivable area segmentation. Furthermore, we adopt an uncertainty-based panoptic perception training strategy to train Efficient-VRNet. In the experiments, our Efficient-VRNet achieves better performances on our collected dataset than other uni-modal models, especially in adverse weather and environment with poor lighting conditions. Our code and models are available at \url{https://github.com/GuanRunwei/Efficient-VRNet}.
</details>
<details>
<summary>摘要</summary>
паноптическое восприятие是关键 для无人水面车（USV）的自主导航。目前的паноптическое восприятие方案主要基于视觉Only，即同时进行对象探测和semantic segmentation基于摄像头感知器。然而，混合摄像头和雷达感知器的方法被视为有前途的，但大多数工作都集中在对象探测上。因此，如何最大化和细致地融合视觉和雷达感知器的特征以提高探测和分割是一个挑战。在这篇论文中，我们关注USV在河道上的паноптиче восприятие，这是与公路上的panoramic perception相比较未探索的领域。我们提出了高效的VRNet，基于Contextual Clustering（CoC）和不对称的视觉和4D mmWave雷达混合，可以同时进行对象探测和分割，以及 drivable area segmentation。此外，我们采用了不确定性基本的panoramic perception训练策略来训练高效的VRNet。在实验中，我们的高效的VRNet在我们收集的数据集上表现更好than其他单modal模型，特别是在恶劣天气和环境下。我们的代码和模型可以在 \url{https://github.com/GuanRunwei/Efficient-VRNet} 中获取。
</details></li>
</ul>
<hr>
<h2 id="DomainDrop-Suppressing-Domain-Sensitive-Channels-for-Domain-Generalization"><a href="#DomainDrop-Suppressing-Domain-Sensitive-Channels-for-Domain-Generalization" class="headerlink" title="DomainDrop: Suppressing Domain-Sensitive Channels for Domain Generalization"></a>DomainDrop: Suppressing Domain-Sensitive Channels for Domain Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10285">http://arxiv.org/abs/2308.10285</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jintao Guo, Lei Qi, Yinghuan Shi</li>
<li>for: 提高模型对不同频率域数据的抗频率性能</li>
<li>methods: 提出了一种基于频率域特征图的频率域抗频率法，通过使用频率域特征图来增强通道的稳定性，提高模型的抗频率性能</li>
<li>results: 经验表明，提出的方法可以在多个 benchmark 上达到领先的性能水平，并且可以与其他竞争方法进行比较<details>
<summary>Abstract</summary>
Deep Neural Networks have exhibited considerable success in various visual tasks. However, when applied to unseen test datasets, state-of-the-art models often suffer performance degradation due to domain shifts. In this paper, we introduce a novel approach for domain generalization from a novel perspective of enhancing the robustness of channels in feature maps to domain shifts. We observe that models trained on source domains contain a substantial number of channels that exhibit unstable activations across different domains, which are inclined to capture domain-specific features and behave abnormally when exposed to unseen target domains. To address the issue, we propose a DomainDrop framework to continuously enhance the channel robustness to domain shifts, where a domain discriminator is used to identify and drop unstable channels in feature maps of each network layer during forward propagation. We theoretically prove that our framework could effectively lower the generalization bound. Extensive experiments on several benchmarks indicate that our framework achieves state-of-the-art performance compared to other competing methods. Our code is available at https://github.com/lingeringlight/DomainDrop.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MacFormer-Map-Agent-Coupled-Transformer-for-Real-time-and-Robust-Trajectory-Prediction"><a href="#MacFormer-Map-Agent-Coupled-Transformer-for-Real-time-and-Robust-Trajectory-Prediction" class="headerlink" title="MacFormer: Map-Agent Coupled Transformer for Real-time and Robust Trajectory Prediction"></a>MacFormer: Map-Agent Coupled Transformer for Real-time and Robust Trajectory Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10280">http://arxiv.org/abs/2308.10280</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Feng, Hangning Zhou, Huadong Lin, Zhigang Zhang, Ziyao Xu, Chi Zhang, Boyu Zhou, Shaojie Shen</li>
<li>for: 预测自驾车行为的未来行为</li>
<li>methods: 使用 Map-Agent Coupled Transformer (MacFormer) 框架，并实现了约束映射和参考提取模块，以及一种多任务优化策略 (MTOS) 来增强网络学习。</li>
<li>results: 在 Argoverse 1、Argoverse 2 和 nuScenes 实验室中，实现了最佳性能，并且具有最低的推理延迟和最小的模型大小。  experiments 还表明，我们的框架可以抗性不准确的轨迹输入。<details>
<summary>Abstract</summary>
Predicting the future behavior of agents is a fundamental task in autonomous vehicle domains. Accurate prediction relies on comprehending the surrounding map, which significantly regularizes agent behaviors. However, existing methods have limitations in exploiting the map and exhibit a strong dependence on historical trajectories, which yield unsatisfactory prediction performance and robustness. Additionally, their heavy network architectures impede real-time applications. To tackle these problems, we propose Map-Agent Coupled Transformer (MacFormer) for real-time and robust trajectory prediction. Our framework explicitly incorporates map constraints into the network via two carefully designed modules named coupled map and reference extractor. A novel multi-task optimization strategy (MTOS) is presented to enhance learning of topology and rule constraints. We also devise bilateral query scheme in context fusion for a more efficient and lightweight network. We evaluated our approach on Argoverse 1, Argoverse 2, and nuScenes real-world benchmarks, where it all achieved state-of-the-art performance with the lowest inference latency and smallest model size. Experiments also demonstrate that our framework is resilient to imperfect tracklet inputs. Furthermore, we show that by combining with our proposed strategies, classical models outperform their baselines, further validating the versatility of our framework.
</details>
<details>
<summary>摘要</summary>
预测自驾车代理行为是自驾车领域的基本任务。准确预测需要理解周围环境，这会有效地规范代理行为。然而，现有方法在利用地图和历史轨迹上有限制，导致预测性能和稳定性不 satisfactory。另外，他们的网络架构过于复杂，阻碍实时应用。为解决这些问题，我们提出了 Map-Agent Coupled Transformer（MacFormer），用于实时和可靠的轨迹预测。我们的框架直接将地图约束 incorporated into the network via two  специаль地设计的模块： coupling map和 reference extractor。我们还提出了一种多任务优化策略（MTOS），以提高学习 topology 和规则约束。此外，我们还提出了一种 bilateral query scheme 在上下文融合中，以更有效地和更轻量级地网络。我们在 Argoverse 1、Argoverse 2 和 nuScenes 实验室中进行了评估，并在所有benchmark上实现了状态前的性能，同时拥有最低的推理延迟和最小的模型大小。实验还表明，我们的框架可以快速地适应不完整的轨迹输入。此外，我们还证明了我们的方法可以与经典模型结合使用，以提高其性能。
</details></li>
</ul>
<hr>
<h2 id="Turning-Waste-into-Wealth-Leveraging-Low-Quality-Samples-for-Enhancing-Continuous-Conditional-Generative-Adversarial-Networks"><a href="#Turning-Waste-into-Wealth-Leveraging-Low-Quality-Samples-for-Enhancing-Continuous-Conditional-Generative-Adversarial-Networks" class="headerlink" title="Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing Continuous Conditional Generative Adversarial Networks"></a>Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing Continuous Conditional Generative Adversarial Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10273">http://arxiv.org/abs/2308.10273</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Ding, Yongwei Wang, Zuheng Xu</li>
<li>for: 提高 conditional generative adversarial networks (CcGANs) 的生成质量，使其能够生成 conditional 的图像。</li>
<li>methods: 提出了一种新的 Negative Data Augmentation (NDA) 方法，称为 Dual-NDA，该方法使用了两种不同的负样本：一是通过预训练 CcGAN 生成的视觉不真实的图像，二是通过修改实际图像的标签来生成的标签不一致的图像。</li>
<li>results: 对 UTKFace 和 Steering Angle 进行了实验研究，发现 Dual-NDA 可以提高 CcGANs 生成的图像的视觉质量和标签一致性，并且可以使 CcGANs 超越当前状态的 conditional GANs 和涂抹模型，达到新的高水平性能。<details>
<summary>Abstract</summary>
Continuous Conditional Generative Adversarial Networks (CcGANs) enable generative modeling conditional on continuous scalar variables (termed regression labels). However, they can produce subpar fake images due to limited training data. Although Negative Data Augmentation (NDA) effectively enhances unconditional and class-conditional GANs by introducing anomalies into real training images, guiding the GANs away from low-quality outputs, its impact on CcGANs is limited, as it fails to replicate negative samples that may occur during the CcGAN sampling. We present a novel NDA approach called Dual-NDA specifically tailored for CcGANs to address this problem. Dual-NDA employs two types of negative samples: visually unrealistic images generated from a pre-trained CcGAN and label-inconsistent images created by manipulating real images' labels. Leveraging these negative samples, we introduce a novel discriminator objective alongside a modified CcGAN training algorithm. Empirical analysis on UTKFace and Steering Angle reveals that Dual-NDA consistently enhances the visual fidelity and label consistency of fake images generated by CcGANs, exhibiting a substantial performance gain over the vanilla NDA. Moreover, by applying Dual-NDA, CcGANs demonstrate a remarkable advancement beyond the capabilities of state-of-the-art conditional GANs and diffusion models, establishing a new pinnacle of performance.
</details>
<details>
<summary>摘要</summary>
双重 NDA 使用两种负样本：基于预训练 CcGAN 生成的视觉不真实的图像，以及 manipulate 真实图像的标签来创造的标签不一致的图像。通过这些负样本，我们引入了一种新的Discriminator 目标 alongside 修改后 CcGAN 训练算法。我们的实验表明，使用 Dual-NDA，CcGANs 可以在 UTKFace 和扭转角度上提高视觉准确性和标签一致性的假图像生成性能，并且与状态项 conditional GANs 和液体模型相比，显示出remarkable进步。
</details></li>
</ul>
<hr>
<h2 id="Domain-Reduction-Strategy-for-Non-Line-of-Sight-Imaging"><a href="#Domain-Reduction-Strategy-for-Non-Line-of-Sight-Imaging" class="headerlink" title="Domain Reduction Strategy for Non Line of Sight Imaging"></a>Domain Reduction Strategy for Non Line of Sight Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10269">http://arxiv.org/abs/2308.10269</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyunbo Shim, In Cho, Daekyu Kwon, Seon Joo Kim</li>
<li>for: 非直线视野（NLOS）图像重建，实现隐藏的场景重建。</li>
<li>methods: 利用光子返回的独立计算，建立一个缩小领域来排除空间，以提高优化的计算效率。</li>
<li>results: 在不同的NLOS场景中，包括非平面遮盾墙、罕发扫描模式、对焦和非对焦等，实现高效率和高精度的图像重建。<details>
<summary>Abstract</summary>
This paper presents a novel optimization-based method for non-line-of-sight (NLOS) imaging that aims to reconstruct hidden scenes under various setups. Our method is built upon the observation that photons returning from each point in hidden volumes can be independently computed if the interactions between hidden surfaces are trivially ignored. We model the generalized light propagation function to accurately represent the transients as a linear combination of these functions. Moreover, our proposed method includes a domain reduction procedure to exclude empty areas of the hidden volumes from the set of propagation functions, thereby improving computational efficiency of the optimization. We demonstrate the effectiveness of the method in various NLOS scenarios, including non-planar relay wall, sparse scanning patterns, confocal and non-confocal, and surface geometry reconstruction. Experiments conducted on both synthetic and real-world data clearly support the superiority and the efficiency of the proposed method in general NLOS scenarios.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Make-It-4D-Synthesizing-a-Consistent-Long-Term-Dynamic-Scene-Video-from-a-Single-Image"><a href="#Make-It-4D-Synthesizing-a-Consistent-Long-Term-Dynamic-Scene-Video-from-a-Single-Image" class="headerlink" title="Make-It-4D: Synthesizing a Consistent Long-Term Dynamic Scene Video from a Single Image"></a>Make-It-4D: Synthesizing a Consistent Long-Term Dynamic Scene Video from a Single Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10257">http://arxiv.org/abs/2308.10257</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/leoShen917/Make-It-4D">https://github.com/leoShen917/Make-It-4D</a></li>
<li>paper_authors: Liao Shen, Xingyi Li, Huiqiang Sun, Juewen Peng, Ke Xian, Zhiguo Cao, Guosheng Lin<br>for:This paper aims to synthesize a long-term dynamic video from a single image, addressing the challenges of consistent visual content movements and large camera motions.methods:The proposed method, Make-It-4D, utilizes layered depth images (LDIs) and motion estimation to estimate the underlying 4D representation of the scene, including 3D geometry and scene motion. The method also employs a pretrained diffusion model to inpaint and outpaint the input image, filling in occluded regions.results:The proposed method demonstrates effective rendering results, showcasing compelling dynamic video synthesis from a single input image. The method is also training-free, saving a significant amount of training time.<details>
<summary>Abstract</summary>
We study the problem of synthesizing a long-term dynamic video from only a single image. This is challenging since it requires consistent visual content movements given large camera motions. Existing methods either hallucinate inconsistent perpetual views or struggle with long camera trajectories. To address these issues, it is essential to estimate the underlying 4D (including 3D geometry and scene motion) and fill in the occluded regions. To this end, we present Make-It-4D, a novel method that can generate a consistent long-term dynamic video from a single image. On the one hand, we utilize layered depth images (LDIs) to represent a scene, and they are then unprojected to form a feature point cloud. To animate the visual content, the feature point cloud is displaced based on the scene flow derived from motion estimation and the corresponding camera pose. Such 4D representation enables our method to maintain the global consistency of the generated dynamic video. On the other hand, we fill in the occluded regions by using a pretrained diffusion model to inpaint and outpaint the input image. This enables our method to work under large camera motions. Benefiting from our design, our method can be training-free which saves a significant amount of training time. Experimental results demonstrate the effectiveness of our approach, which showcases compelling rendering results.
</details>
<details>
<summary>摘要</summary>
我们研究将单一图像转换为长期动态影片的问题。这是一个挑战，因为需要在大型镜头运动下维持一致的视觉内容运动。现有的方法 Either hallucinate不一致的无限视野或对大型镜头轨迹进行适应。为解决这些问题，我们需要估计场景中的底层4D（包括3D几何和场景运动），并填充遮盖区域。为此，我们提出了Make-It-4D，一种新的方法，可以将单一图像转换为一致的长期动态影片。我们使用层级深度图像（LDIs）来表示场景，然后将它们投影到形成一个特征点云。为了将视觉内容动态化，我们将特征点云根据场景流和相应的镜头pose进行偏移。这样的4D表示方式使我们的方法能够维持生成的动态影片的全球一致性。另一方面，我们使用预训数据模型填充和外填充输入图像，以解决大型镜头运动下的遮盖区域问题。由于我们的设计，我们的方法不需要训练，这样可以大幅降低训练时间。实验结果显示我们的方法有着吸引人的渲染效果。
</details></li>
</ul>
<hr>
<h2 id="Generic-Attention-model-Explainability-by-Weighted-Relevance-Accumulation"><a href="#Generic-Attention-model-Explainability-by-Weighted-Relevance-Accumulation" class="headerlink" title="Generic Attention-model Explainability by Weighted Relevance Accumulation"></a>Generic Attention-model Explainability by Weighted Relevance Accumulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10240">http://arxiv.org/abs/2308.10240</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiming Huang, Aozhe Jia, Xiaodan Zhang, Jiawei Zhang</li>
<li>For: This paper aims to improve the explainability of attention-based transformer models in multi-modal tasks, such as visual question answering.* Methods: The proposed method uses a weighted relevancy strategy to take into account the importance of token values when accumulating relevance, reducing distortion in the attention process.* Results: The proposed method outperforms existing methods in terms of explainability, as validated through extensive perturbation tests on visual question answering and image captioning.Here’s the Chinese version of the three key points:* For: 这篇论文的目的是提高基于转换器模型的多模态任务，如视觉问答的解释性。* Methods: 提议的方法使用了权重相关性策略，根据Token值的重要性来增加相关性，从而降低了注意力过程中的扭曲。* Results: 提议的方法在解释性方面表现出色，通过对视觉问答和图文描述进行广泛的干扰测试 Validated 表明，其解释性方法超过了现有的方法。<details>
<summary>Abstract</summary>
Attention-based transformer models have achieved remarkable progress in multi-modal tasks, such as visual question answering. The explainability of attention-based methods has recently attracted wide interest as it can explain the inner changes of attention tokens by accumulating relevancy across attention layers. Current methods simply update relevancy by equally accumulating the token relevancy before and after the attention processes. However, the importance of token values is usually different during relevance accumulation. In this paper, we propose a weighted relevancy strategy, which takes the importance of token values into consideration, to reduce distortion when equally accumulating relevance. To evaluate our method, we propose a unified CLIP-based two-stage model, named CLIPmapper, to process Vision-and-Language tasks through CLIP encoder and a following mapper. CLIPmapper consists of self-attention, cross-attention, single-modality, and cross-modality attention, thus it is more suitable for evaluating our generic explainability method. Extensive perturbation tests on visual question answering and image captioning validate that our explainability method outperforms existing methods.
</details>
<details>
<summary>摘要</summary>
注意基于转换器模型已经取得了多模式任务中的很大进步，如视觉问答。现在的解释可能性方法吸引了广泛的关注，因为它可以解释关注令牌的内部变化。现有方法简单地将关注令牌的相关性更新为平等地积累关注层中的令牌相关性。然而，令牌值的重要性通常在相关性积累中不同。在这篇论文中，我们提议一种权重 relevancy 策略，该策略考虑令牌值的重要性，以减少积累时的扭曲。为评估我们的方法，我们提出了一种基于 CLIP 的两stage 模型，名为 CLIPmapper，该模型通过 CLIP Encoder 和后续的映射器来处理视觉语言任务。CLIPmapper 包括自注意、交叉注意、单模态和交叉模态注意，因此它更适合评估我们的通用解释可能性方法。对于视觉问答和图文描述等任务，我们进行了广泛的干扰测试，并证明了我们的解释可能性方法在现有方法中表现出色。
</details></li>
</ul>
<hr>
<h2 id="From-Global-to-Local-Multi-scale-Out-of-distribution-Detection"><a href="#From-Global-to-Local-Multi-scale-Out-of-distribution-Detection" class="headerlink" title="From Global to Local: Multi-scale Out-of-distribution Detection"></a>From Global to Local: Multi-scale Out-of-distribution Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10239">http://arxiv.org/abs/2308.10239</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jimzai/mode-ood">https://github.com/jimzai/mode-ood</a></li>
<li>paper_authors: Ji Zhang, Lianli Gao, Bingguang Hao, Hao Huang, Jingkuan Song, Hengtao Shen</li>
<li>for: 这个论文的目的是提出一个新的 OUT-OF-DISTRIBUTION（OOD）检测方法，以检测“未知”的数据，即在训练过程中没有见过的标签。</li>
<li>methods: 这个方法使用了Multi-scale OOD DEtection（MODE）框架，利用了全域图像信息和本地区域细节来增强OOD检测。具体来说，这个方法首先发现现有的模型因为标签训练和OOD检测的规模不同，所以无法捕捉到有用的本地表示。为了解决这个问题，这个方法提出了Attention-based Local PropAgation（ALPA）的对话式目标，将本地区域的对话捕捉到ID训练过程中。</li>
<li>results: 这个方法在多个 bencmarks 上显示了优秀的效果，与之前的最佳性能相比，平均提高了19.24%的False Positive Rate（FPR）和2.77%的AUCROC。代码可以在<a target="_blank" rel="noopener" href="https://github.com/JimZAI/MODE-OOD">https://github.com/JimZAI/MODE-OOD</a> 获取。<details>
<summary>Abstract</summary>
Out-of-distribution (OOD) detection aims to detect "unknown" data whose labels have not been seen during the in-distribution (ID) training process. Recent progress in representation learning gives rise to distance-based OOD detection that recognizes inputs as ID/OOD according to their relative distances to the training data of ID classes. Previous approaches calculate pairwise distances relying only on global image representations, which can be sub-optimal as the inevitable background clutter and intra-class variation may drive image-level representations from the same ID class far apart in a given representation space. In this work, we overcome this challenge by proposing Multi-scale OOD DEtection (MODE), a first framework leveraging both global visual information and local region details of images to maximally benefit OOD detection. Specifically, we first find that existing models pretrained by off-the-shelf cross-entropy or contrastive losses are incompetent to capture valuable local representations for MODE, due to the scale-discrepancy between the ID training and OOD detection processes. To mitigate this issue and encourage locally discriminative representations in ID training, we propose Attention-based Local PropAgation (ALPA), a trainable objective that exploits a cross-attention mechanism to align and highlight the local regions of the target objects for pairwise examples. During test-time OOD detection, a Cross-Scale Decision (CSD) function is further devised on the most discriminative multi-scale representations to distinguish ID/OOD data more faithfully. We demonstrate the effectiveness and flexibility of MODE on several benchmarks -- on average, MODE outperforms the previous state-of-the-art by up to 19.24% in FPR, 2.77% in AUROC. Code is available at https://github.com/JimZAI/MODE-OOD.
</details>
<details>
<summary>摘要</summary>
OUT-OF-DISTRIBUTION (OOD) 检测目标是检测未知数据，其标签在 ID 训练过程中没有出现过。 recent progress in representation learning 使得距离基本的 OOD 检测变得更加重要。在这种情况下，我们提出了 Multi-scale OOD DEtection (MODE) 框架，它利用了全球视觉信息和本地区域细节来最大化 OOD 检测的效果。具体来说，我们发现现有的模型通常通过预训练的 cross-entropy 或对比损失来学习全球视觉信息，但这些模型在 OOD 检测过程中可能无法捕捉到有价值的本地表示。为了解决这个问题，我们提出了 Attention-based Local PropAgation (ALPA) 目标函数，它利用了交叉注意机制来对 ID 训练过程中的本地区域进行匹配和强调。在测试时 OOD 检测过程中，我们还提出了 Cross-Scale Decision (CSD) 函数，用于在不同缩放级别上进行分类。我们在多个 benchmark 上进行了实验，得到了 MODE 的效果和灵活性。在 average 的情况下，MODE 可以与前一个状态的艺术品的 FPR 和 AUROC 进行比较，提高了 19.24% 和 2.77%。代码可以在 <https://github.com/JimZAI/MODE-OOD> 上找到。
</details></li>
</ul>
<hr>
<h2 id="FedSIS-Federated-Split-Learning-with-Intermediate-Representation-Sampling-for-Privacy-preserving-Generalized-Face-Presentation-Attack-Detection"><a href="#FedSIS-Federated-Split-Learning-with-Intermediate-Representation-Sampling-for-Privacy-preserving-Generalized-Face-Presentation-Attack-Detection" class="headerlink" title="FedSIS: Federated Split Learning with Intermediate Representation Sampling for Privacy-preserving Generalized Face Presentation Attack Detection"></a>FedSIS: Federated Split Learning with Intermediate Representation Sampling for Privacy-preserving Generalized Face Presentation Attack Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10236">http://arxiv.org/abs/2308.10236</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/naiftt/fedsis">https://github.com/naiftt/fedsis</a></li>
<li>paper_authors: Naif Alkhunaizi, Koushik Srivatsan, Faris Almalik, Ibrahim Almakky, Karthik Nandakumar<br>for:This paper is written for those who are interested in face presentation attack detection (FacePAD) and want to improve the generalization of their algorithms to unseen domains&#x2F;attacks.methods:The paper proposes a novel framework called Federated Split learning with Intermediate representation Sampling (FedSIS) which combines federated learning (FL) and split learning to achieve privacy-preserving domain generalization. The FedSIS approach uses a hybrid Vision Transformer (ViT) architecture and a shared adapter network to distill discriminative information from intermediate blocks.results:The paper demonstrates that the FedSIS approach can achieve state-of-the-art generalization performance on two well-known benchmarks for cross-domain FacePAD without any data sharing, thereby preserving privacy.<details>
<summary>Abstract</summary>
Lack of generalization to unseen domains/attacks is the Achilles heel of most face presentation attack detection (FacePAD) algorithms. Existing attempts to enhance the generalizability of FacePAD solutions assume that data from multiple source domains are available with a single entity to enable centralized training. In practice, data from different source domains may be collected by diverse entities, who are often unable to share their data due to legal and privacy constraints. While collaborative learning paradigms such as federated learning (FL) can overcome this problem, standard FL methods are ill-suited for domain generalization because they struggle to surmount the twin challenges of handling non-iid client data distributions during training and generalizing to unseen domains during inference. In this work, a novel framework called Federated Split learning with Intermediate representation Sampling (FedSIS) is introduced for privacy-preserving domain generalization. In FedSIS, a hybrid Vision Transformer (ViT) architecture is learned using a combination of FL and split learning to achieve robustness against statistical heterogeneity in the client data distributions without any sharing of raw data (thereby preserving privacy). To further improve generalization to unseen domains, a novel feature augmentation strategy called intermediate representation sampling is employed, and discriminative information from intermediate blocks of a ViT is distilled using a shared adapter network. The FedSIS approach has been evaluated on two well-known benchmarks for cross-domain FacePAD to demonstrate that it is possible to achieve state-of-the-art generalization performance without data sharing. Code: https://github.com/Naiftt/FedSIS
</details>
<details>
<summary>摘要</summary>
缺乏对未经看过的领域/攻击的泛化是大多数人脸展示攻击检测（FacePAD）算法的致命弱点。现有的增强FacePAD解决方案假设有多个源领域的数据可以进行中央化训练。在实际情况下，不同的源领域数据可能由不同的实体收集，这些实体通常因为法律和隐私限制无法分享其数据。而合作学习 paradigm such as federated learning（FL）可以解决这个问题，但标准FL方法在适应非同一样的客户端数据分布时具有困难。在这种情况下，一种名为 Federated Split learning with Intermediate representation Sampling（FedSIS）的新框架被引入，用于保护隐私的领域泛化。在 FedSIS 中，使用一种混合的 Computer Vision Transformer（ViT）架构，通过将 FL 和 split learning 结合使得模型对客户端数据分布的统计差异具有抗性，而无需分享Raw数据（因此保护隐私）。为了进一步提高对未经看过的领域的泛化，我们采用了一种新的特征增强策略，即中间表示采样策略，并将 ViT 中的中间块特征通过一个共享适配器网络进行精炼。FedSIS 方法在两个常用的 cross-domain FacePAD 测试集上进行评估，并证明了在不分享数据情况下可以实现状态 искусственный泛化性能。代码：https://github.com/Naiftt/FedSIS
</details></li>
</ul>
<hr>
<h2 id="Real-time-Regular-Expression-Matching"><a href="#Real-time-Regular-Expression-Matching" class="headerlink" title="Real-time Regular Expression Matching"></a>Real-time Regular Expression Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10208">http://arxiv.org/abs/2308.10208</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/charbelrami/regex-element">https://github.com/charbelrami/regex-element</a></li>
<li>paper_authors: Alexandra Bernadotte</li>
<li>for: 这篇论文主要针对金字塔自动机、正则表达式匹配、模式识别以及对正则表达式长度增长而导致的加速问题。</li>
<li>methods: 该论文提出了一种理论和硬件解决方案，用于解决一些复杂的正则语言类型的加速问题，这些问题在网络入侵检测系统中带来严重的限制。</li>
<li>results: 文章提供了一些正则表达式匹配的正确性和复杂性 theorem，以支持其解决方案的可行性和效果。<details>
<summary>Abstract</summary>
This paper is devoted to finite state automata, regular expression matching, pattern recognition, and the exponential blow-up problem, which is the growing complexity of automata exponentially depending on regular expression length. This paper presents a theoretical and hardware solution to the exponential blow-up problem for some complicated classes of regular languages, which caused severe limitations in Network Intrusion Detection Systems work. The article supports the solution with theorems on correctness and complexity.
</details>
<details>
<summary>摘要</summary>
这篇论文专注于finite state自动机、正则表达式匹配、模式识别和 exponential blow-up 问题（正则表达式长度增长导致自动机复杂度呈指数增长）。这篇论文提出了一种理论和硬件解决方案，以解决一些复杂的正则语言 exponential blow-up 问题，这些问题在网络入侵检测系统中带来严重的限制。文章证明了解决方案的正确性和复杂度。
</details></li>
</ul>
<hr>
<h2 id="GeT-Generative-Target-Structure-Debiasing-for-Domain-Adaptation"><a href="#GeT-Generative-Target-Structure-Debiasing-for-Domain-Adaptation" class="headerlink" title="GeT: Generative Target Structure Debiasing for Domain Adaptation"></a>GeT: Generative Target Structure Debiasing for Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10205">http://arxiv.org/abs/2308.10205</a></li>
<li>repo_url: None</li>
<li>paper_authors: Can Zhang, Gim Hee Lee</li>
<li>for: 本研究的目的是提出一种能够减少源数据偏见的预测模型，以便在不同预测任务中进行更好的预测。</li>
<li>methods: 本研究使用了 semi-supervised learning 技术，并提出了一种基于 pseudo labeling 的方法来减少源数据偏见。</li>
<li>results: 实验结果表明，我们提出的方法可以在不同的预测任务中减少 source data bias，并且可以在不同的预测任务中获得更好的预测性能。<details>
<summary>Abstract</summary>
Domain adaptation (DA) aims to transfer knowledge from a fully labeled source to a scarcely labeled or totally unlabeled target under domain shift. Recently, semi-supervised learning-based (SSL) techniques that leverage pseudo labeling have been increasingly used in DA. Despite the competitive performance, these pseudo labeling methods rely heavily on the source domain to generate pseudo labels for the target domain and therefore still suffer considerably from source data bias. Moreover, class distribution bias in the target domain is also often ignored in the pseudo label generation and thus leading to further deterioration of performance. In this paper, we propose GeT that learns a non-bias target embedding distribution with high quality pseudo labels. Specifically, we formulate an online target generative classifier to induce the target distribution into distinctive Gaussian components weighted by their class priors to mitigate source data bias and enhance target class discriminability. We further propose a structure similarity regularization framework to alleviate target class distribution bias and further improve target class discriminability. Experimental results show that our proposed GeT is effective and achieves consistent improvements under various DA settings with and without class distribution bias. Our code is available at: https://lulusindazc.github.io/getproject/.
</details>
<details>
<summary>摘要</summary>
域适应（DA）的目标是将来源域中完全标注的知识传递到目标域中具有域shift的场景中，但目标域通常具有少量或无标注数据。最近，半监督学习（SSL）技术在DA中越来越广泛应用，但这些假标注方法仍然受到源域的限制，即使在 pseudo label 生成过程中，它们仍然受到源数据偏见的影响。此外，目标域中类分布偏见也经常被忽略在假标注生成过程中，这会导致性能下降。在这篇论文中，我们提出了 GeT，它可以学习一个不偏见的目标域分布，并生成高质量的假标注。具体来说，我们提出了在线目标生成类分类器，通过将目标分布划分成不同的 Gaussian 组件，并通过类偏见来补偿源数据偏见，以提高目标类分riminability。此外，我们还提出了结构相似regularization框架，以减少目标类分布偏见，并进一步提高目标类分riminability。实验结果表明，我们的提出的 GeT 是有效的，在不同的 DA 设置下，它都可以获得鲁棒的提高。我们的代码可以在以下链接中找到：https://lulusindazc.github.io/getproject/.
</details></li>
</ul>
<hr>
<h2 id="Blind-Face-Restoration-for-Under-Display-Camera-via-Dictionary-Guided-Transformer"><a href="#Blind-Face-Restoration-for-Under-Display-Camera-via-Dictionary-Guided-Transformer" class="headerlink" title="Blind Face Restoration for Under-Display Camera via Dictionary Guided Transformer"></a>Blind Face Restoration for Under-Display Camera via Dictionary Guided Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10196">http://arxiv.org/abs/2308.10196</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingfan Tan, Xiaoxu Chen, Tao Wang, Kaihao Zhang, Wenhan Luo, Xiaocun Cao</li>
<li>for: 提供用户全屏体验，但是由于显示器的特点，UDC图像受到质量下降的影响。</li>
<li>methods: 提出了UDC图像修复方法，并实现了进步。但是还没有专门的UDC图像修复方法和数据集，这可能是UDC场景中最常见的问题。</li>
<li>results: 我们提出了一种两stage网络UDC降解模型网络（UDC-DMNet），并使用UDC-DMNet和高质量的face图像从FFHQ和CelebA-Test创建了UDC face修复数据集FFHQ-P&#x2F;T和测试数据集CelebA-Test-P&#x2F;T。我们还提出了一种新的字典引导 transformer网络（DGFormer），通过引入人脸组成字典和UDC图像的特点，使DGFormer能够实现盲人脸修复在UDC场景中。实验表明，我们的DGFormer和UDC-DMNet实现了状态的末点性能。<details>
<summary>Abstract</summary>
By hiding the front-facing camera below the display panel, Under-Display Camera (UDC) provides users with a full-screen experience. However, due to the characteristics of the display, images taken by UDC suffer from significant quality degradation. Methods have been proposed to tackle UDC image restoration and advances have been achieved. There are still no specialized methods and datasets for restoring UDC face images, which may be the most common problem in the UDC scene. To this end, considering color filtering, brightness attenuation, and diffraction in the imaging process of UDC, we propose a two-stage network UDC Degradation Model Network named UDC-DMNet to synthesize UDC images by modeling the processes of UDC imaging. Then we use UDC-DMNet and high-quality face images from FFHQ and CelebA-Test to create UDC face training datasets FFHQ-P/T and testing datasets CelebA-Test-P/T for UDC face restoration. We propose a novel dictionary-guided transformer network named DGFormer. Introducing the facial component dictionary and the characteristics of the UDC image in the restoration makes DGFormer capable of addressing blind face restoration in UDC scenarios. Experiments show that our DGFormer and UDC-DMNet achieve state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
“隐藏前置摄像头在显示面板下，Under-Display Camera（UDC）为用户提供了全屏体验。然而，由于显示器的特点，UDC拍摄的图像会受到显著质量下降的影响。已经提出了一些方法来解决UDC图像修复问题，但是还没有专门的方法和数据集来修复UDC face图像，这可能是UDC场景中最常见的问题。为此，我们考虑了UDC拍摄过程中的颜色滤波、亮度减弱和折射，并提出了一个两Stage网络UDC降低模型网络（UDC-DMNet），用于模拟UDC拍摄过程。然后，我们使用UDC-DMNet和高质量的face图像从FFHQ和CelebA-Test创建了UDC face培训集FFHQ-P/T和测试集CelebA-Test-P/T。我们还提出了一种新的字典指导变换网络名为DGFormer。通过引入面部字典和UDC图像的特点，DGFormer能够 Addresses blind face修复问题在UDC场景中。实验结果表明，我们的DGFormer和UDC-DMNet都达到了状态精算的性能。”
</details></li>
</ul>
<hr>
<h2 id="EDDense-Net-Fully-Dense-Encoder-Decoder-Network-for-Joint-Segmentation-of-Optic-Cup-and-Disc"><a href="#EDDense-Net-Fully-Dense-Encoder-Decoder-Network-for-Joint-Segmentation-of-Optic-Cup-and-Disc" class="headerlink" title="EDDense-Net: Fully Dense Encoder Decoder Network for Joint Segmentation of Optic Cup and Disc"></a>EDDense-Net: Fully Dense Encoder Decoder Network for Joint Segmentation of Optic Cup and Disc</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10192">http://arxiv.org/abs/2308.10192</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mehwish Mehmood, Khuram Naveed, Haroon Ahmed Khan, Syed S. Naqvi<br>for: 这项研究的目的是为了提供一种用于诊断和分析глау科病例的自助系统，以帮助医学眼科医生进行诊断。methods: 该网络使用了EDDense-NetSegmentation网络，该网络包括Encoder和Decoder，它们都是由密集块组成的，每个块包括了 grouped convolutional layer，这使得网络能够同时从图像中获取和传递空间信息，而且降低网络的复杂性。而且，在涉及到semantic segmentation的部分，使用了 dice pixel classification来缓解类别偏袋问题。results: 在两个公共可用的数据集上进行评估，该网络的准确率和效率都高于现有的状态的艺术方法。因此，该方法可以用于作为医学眼科医生的第二意见系统，帮助他们进行诊断和分析 glaucoma 病例。<details>
<summary>Abstract</summary>
Glaucoma is an eye disease that causes damage to the optic nerve, which can lead to visual loss and permanent blindness. Early glaucoma detection is therefore critical in order to avoid permanent blindness. The estimation of the cup-to-disc ratio (CDR) during an examination of the optical disc (OD) is used for the diagnosis of glaucoma. In this paper, we present the EDDense-Net segmentation network for the joint segmentation of OC and OD. The encoder and decoder in this network are made up of dense blocks with a grouped convolutional layer in each block, allowing the network to acquire and convey spatial information from the image while simultaneously reducing the network's complexity. To reduce spatial information loss, the optimal number of filters in all convolution layers were utilised. In semantic segmentation, dice pixel classification is employed in the decoder to alleviate the problem of class imbalance. The proposed network was evaluated on two publicly available datasets where it outperformed existing state-of-the-art methods in terms of accuracy and efficiency. For the diagnosis and analysis of glaucoma, this method can be used as a second opinion system to assist medical ophthalmologists.
</details>
<details>
<summary>摘要</summary>
glaucoma 是一种眼病，可以导致视网膜损害，从而引起视力减退和永久失明。 early detection of glaucoma 是非常重要的，以避免永久失明。 during an examination of the optical disc (OD), the estimation of the cup-to-disc ratio (CDR) is used for the diagnosis of glaucoma. 在这篇论文中，我们提出了 ED-DenseNet  segmentation 网络，用于joint segmentation of OC 和 OD。这个网络的编码器和解码器都由密集层组成，每个密集层都包含了 grouped convolutional layer，使网络能够从图像中获取和传递空间信息，同时减少网络的复杂度。为了避免空间信息损失，我们在所有卷积层中使用了最佳的筛选器数量。在semantic segmentation中，我们使用了 dice pixel classification 来缓解类别不均衡问题。我们的方法在两个公共可用的数据集上进行了评估，并在精度和效率方面超过了现有的状态图方法。这种方法可以作为医学眼科专业人员的第二意见系统，帮助 диагности和分析 glaucoma。
</details></li>
</ul>
<hr>
<h2 id="Spiking-Diffusion-Vector-Quantized-Discrete-Diffusion-Model-with-Spiking-Neural-Networks"><a href="#Spiking-Diffusion-Vector-Quantized-Discrete-Diffusion-Model-with-Spiking-Neural-Networks" class="headerlink" title="Spiking-Diffusion: Vector Quantized Discrete Diffusion Model with Spiking Neural Networks"></a>Spiking-Diffusion: Vector Quantized Discrete Diffusion Model with Spiking Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10187">http://arxiv.org/abs/2308.10187</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Arktis2022/Spiking-Diffusion">https://github.com/Arktis2022/Spiking-Diffusion</a></li>
<li>paper_authors: Mingxuan Liu, Rui Wen, Hong Chen</li>
<li>for: 这个论文主要用于实现基于神经网络的印象生成模型，并且使用脳神经网络（SNN）来实现能效的 neuromorphic 处理器。</li>
<li>methods: 这个论文使用了 vector quantized 秘密自适应网络（VQ-SVAE）来学习离散的伪想空间，并且使用 SNN 实现吸引状态传播和扩散图像复原。</li>
<li>results: 这个论文的实验结果显示，使用 Spiking-Diffusion 模型可以实现更好的印象生成效果，并且比较过去的 SNN-based 生成模型有更好的表现。实验结果显示，这个模型在 MNIST、FMNIST、KMNIST 和 Letters 等数据集上实现了更好的表现，并且比较过去的 SNN-based 生成模型有更好的表现。<details>
<summary>Abstract</summary>
Spiking neural networks (SNNs) have tremendous potential for energy-efficient neuromorphic chips due to their binary and event-driven architecture. SNNs have been primarily used in classification tasks, but limited exploration on image generation tasks. To fill the gap, we propose a Spiking-Diffusion model, which is based on the vector quantized discrete diffusion model. First, we develop a vector quantized variational autoencoder with SNNs (VQ-SVAE) to learn a discrete latent space for images. With VQ-SVAE, image features are encoded using both the spike firing rate and postsynaptic potential, and an adaptive spike generator is designed to restore embedding features in the form of spike trains. Next, we perform absorbing state diffusion in the discrete latent space and construct a diffusion image decoder with SNNs to denoise the image. Our work is the first to build the diffusion model entirely from SNN layers. Experimental results on MNIST, FMNIST, KMNIST, and Letters demonstrate that Spiking-Diffusion outperforms the existing SNN-based generation model. We achieve FIDs of 37.50, 91.98, 59.23 and 67.41 on the above datasets respectively, with reductions of 58.60\%, 18.75\%, 64.51\%, and 29.75\% in FIDs compared with the state-of-art work.
</details>
<details>
<summary>摘要</summary>
神经网络（SNN）具有巨大的能效可能性，因其架构为二进制和事件驱动的。SNN在分类任务中广泛使用，但对图像生成任务的探索很少。为填补这个差距，我们提议了一种叫做神经网络扩散模型（Spiking-Diffusion model），它基于矢量量化离散扩散模型。首先，我们开发了一种基于SNN的矢量量化自适应编码器（VQ-SVAE），以学习图像的离散特征空间。VQ-SVAE中，图像特征被编码通过神经元发射率和后生电位，并设计了适应的神经元发射器来重建嵌入特征在形式为脉冲列表的形式。接着，我们在离散特征空间中进行吸引状态扩散，并构建了基于SNN层的扩散图像解码器来降噪图像。我们的工作是首次将扩散模型完全建立在SNN层之上。实验结果在MNIST、FMNIST、KMNIST和Letters等 dataset上表明，Spiking-Diffusion模型比 existed SNN-based generation模型更高效，我们在这些dataset上实现了FID值为37.50、91.98、59.23和67.41，相比 existed work，我们的FID值下降58.60%、18.75%、64.51%和29.75%。
</details></li>
</ul>
<hr>
<h2 id="ViT-Lens-Towards-Omni-modal-Representations"><a href="#ViT-Lens-Towards-Omni-modal-Representations" class="headerlink" title="ViT-Lens: Towards Omni-modal Representations"></a>ViT-Lens: Towards Omni-modal Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10185">http://arxiv.org/abs/2308.10185</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/TencentARC/ViT-Lens">https://github.com/TencentARC/ViT-Lens</a></li>
<li>paper_authors: Weixian Lei, Yixiao Ge, Jianfeng Zhang, Dylan Sun, Kun Yi, Ying Shan, Mike Zheng Shou</li>
<li>for: 这篇论文是为了提出一种能够有效地处理多个模式（如3D、声音等）的方法，以便在不同的任务和领域中使用已经预训练的 ViT 模型。</li>
<li>methods: 这篇论文使用了一种名为 ViT-Lens 的方法，它可以使用已经预训练的 ViT 模型来处理多个模式，并将这些模式Project到一个共同的 embedding 空间中。然后，使用强大的 ViT 模型来处理这些embedding，以获得高效的多模式表示学习。</li>
<li>results: 根据论文的测试结果，ViT-Lens 在 zero-shot 3D 分类任务中实现了显著的提升，其中 Objaverse-LVIS 上的准确率为 52.0%，ModelNet40 上的准确率为 87.4%，ScanObjectNN 上的准确率为 60.6%。此外，通过简单地将已经训练的 3D 透镜 integrate 到 InstructBLIP 模型中，实现了 zero-shot 3D 问答。<details>
<summary>Abstract</summary>
Though the success of CLIP-based training recipes in vision-language models, their scalability to more modalities (e.g., 3D, audio, etc.) is limited to large-scale data, which is expensive or even inapplicable for rare modalities. In this paper, we present ViT-Lens that facilitates efficient omni-modal representation learning by perceiving novel modalities with a pretrained ViT and aligning to a pre-defined space. Specifically, the modality-specific lens is tuned to project multimodal signals to the shared embedding space, which are then processed by a strong ViT that carries pre-trained image knowledge. The encoded multimodal representations are optimized toward aligning with the modal-independent space, pre-defined by off-the-shelf foundation models. A well-trained lens with a ViT backbone has the potential to serve as one of these foundation models, supervising the learning of subsequent modalities. ViT-Lens provides a unified solution for representation learning of increasing modalities with two appealing benefits: (i) Exploiting the pretrained ViT across tasks and domains effectively with efficient data regime; (ii) Emergent downstream capabilities of novel modalities are demonstrated due to the modality alignment space. We evaluate ViT-Lens in the context of 3D as an initial verification. In zero-shot 3D classification, ViT-Lens achieves substantial improvements over previous state-of-the-art, showing 52.0% accuracy on Objaverse-LVIS, 87.4% on ModelNet40, and 60.6% on ScanObjectNN. Furthermore, we enable zero-shot 3D question-answering by simply integrating the trained 3D lens into the InstructBLIP model without any adaptation. We will release the results of ViT-Lens on more modalities in the near future.
</details>
<details>
<summary>摘要</summary>
尽管CLIP基于训练辑recipes在视觉语模型中获得成功，但它们在更多Modalities（例如3D、音频等）的扩展是受限于大规模数据的，这些数据可能是costly或者even inapplicable for rare modalities。在这篇论文中，我们提出了ViT-Lens，它可以有效地进行多modalities的表示学习，通过将novel modalities projected to a predefined shared embedding space，然后由一个强大的ViT进行处理，该ViT已经预训练了图像知识。所得到的多modalities表示被优化以与modal-independent space相align，这个空间是由off-the-shelf foundation models预定的。一个很好地训练的lens可以作为这些基础模型，监督后续modalities的学习。ViT-Lens提供了一个统一的解决方案，可以在多modalities的表示学习中获得两个优点：（i）可以有效地利用预训练的ViT，并且在有限的数据上进行efficient training;（ii）由于modalities的对齐空间，可以实现 novel modalities的emergent downstream capabilities。我们在3D上进行了首次验证，并达到了substantial improvement，包括Objaverse-LVIS的52.0%准确率、ModelNet40的87.4%准确率和ScanObjectNN的60.6%准确率。此外，我们还可以通过简单地将训练好的3D镜头 integrate into the InstructBLIP模型，实现zero-shot 3D问答。我们将在未来发布更多modalities的结果。
</details></li>
</ul>
<hr>
<h2 id="BAVS-Bootstrapping-Audio-Visual-Segmentation-by-Integrating-Foundation-Knowledge"><a href="#BAVS-Bootstrapping-Audio-Visual-Segmentation-by-Integrating-Foundation-Knowledge" class="headerlink" title="BAVS: Bootstrapping Audio-Visual Segmentation by Integrating Foundation Knowledge"></a>BAVS: Bootstrapping Audio-Visual Segmentation by Integrating Foundation Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10175">http://arxiv.org/abs/2308.10175</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Liu, Peike Li, Hu Zhang, Lincheng Li, Zi Huang, Dadong Wang, Xin Yu<br>for:这个研究旨在提高audiovisual segmentation（AVS）的精度，以便在实际场景中更好地定位声音来源。methods:我们提出了一个两阶段的增强AVS框架，包括多modal基础知识的整合。在第一阶段，我们使用一个分类模型来将可能的声音来源从视觉数据中分类，不受污染的音频讯号影响。在第二阶段，我们发展了一个音频视觉 semantic统合策略（AVIS），以确定真正有声音来源。我们建立了一个音频视觉树，根据声音和物类分类的层次相互对应。然后，我们评估了对应物类和类别化的音频标签之间的标签一致性。results:我们的方法在AVS datasets上进行了广泛的实验，特别是在背景噪音的情况下表现出色。我们的方法能够更好地定位真正有声音来源。<details>
<summary>Abstract</summary>
Given an audio-visual pair, audio-visual segmentation (AVS) aims to locate sounding sources by predicting pixel-wise maps. Previous methods assume that each sound component in an audio signal always has a visual counterpart in the image. However, this assumption overlooks that off-screen sounds and background noise often contaminate the audio recordings in real-world scenarios. They impose significant challenges on building a consistent semantic mapping between audio and visual signals for AVS models and thus impede precise sound localization. In this work, we propose a two-stage bootstrapping audio-visual segmentation framework by incorporating multi-modal foundation knowledge. In a nutshell, our BAVS is designed to eliminate the interference of background noise or off-screen sounds in segmentation by establishing the audio-visual correspondences in an explicit manner. In the first stage, we employ a segmentation model to localize potential sounding objects from visual data without being affected by contaminated audio signals. Meanwhile, we also utilize a foundation audio classification model to discern audio semantics. Considering the audio tags provided by the audio foundation model are noisy, associating object masks with audio tags is not trivial. Thus, in the second stage, we develop an audio-visual semantic integration strategy (AVIS) to localize the authentic-sounding objects. Here, we construct an audio-visual tree based on the hierarchical correspondence between sounds and object categories. We then examine the label concurrency between the localized objects and classified audio tags by tracing the audio-visual tree. With AVIS, we can effectively segment real-sounding objects. Extensive experiments demonstrate the superiority of our method on AVS datasets, particularly in scenarios involving background noise. Our project website is https://yenanliu.github.io/AVSS.github.io/.
</details>
<details>
<summary>摘要</summary>
audio-visual分割（AVS）目的是通过预测像素级地图来确定声音来源。先前的方法假设每个声音 ком ponent in 音频信号总是有视觉对应在图像中。然而，这种假设过looks 忽略了实际情况中的后台噪声和屏幕外声音污染音频记录。这些噪声对AVS模型建立一致的semantic mapping between 音频和视觉信号的建立带来了很大挑战，从而降低了精确的声音定位。在这种情况下，我们提出了一个两stage bootstrapping 音频视觉分割框架。简而言之，我们的BAVS是通过明确的方式来消除噪声或屏幕外声音的污染，从而提高AVS的精度。在第一stage，我们使用一个分割模型来从视觉数据中 lokalisieren potential sounding objects，不受噪声音频信号的影响。同时，我们还利用一个基础Audio classification模型来理解音频semantics。由于audio标签提供by the audio foundation model是噪声的，因此将对象面积与audio标签相关联是不rivial的。因此，在第二stage，我们开发了一种音频视觉semantic интеграation策略（AVIS），以确定真实听起来的对象。我们在音频视觉树中建立了层次相应的声音和对象类别之间的 hierarchical correspondence。然后，我们跟踪音频视觉树，并对 lokalisierten对象和分类的audio标签进行标concurrentlabeling。通过AVIS，我们可以有效地分割真实听起来的对象。我们的项目网站是https://yenanliu.github.io/AVSS.github.io/.
</details></li>
</ul>
<hr>
<h2 id="Neural-Interactive-Keypoint-Detection"><a href="#Neural-Interactive-Keypoint-Detection" class="headerlink" title="Neural Interactive Keypoint Detection"></a>Neural Interactive Keypoint Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10174">http://arxiv.org/abs/2308.10174</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/idea-research/click-pose">https://github.com/idea-research/click-pose</a></li>
<li>paper_authors: Jie Yang, Ailing Zeng, Feng Li, Shilong Liu, Ruimao Zhang, Lei Zhang</li>
<li>for: 这个研究旨在开发一个端到端神经交互关键点检测框架，名为Click-Pose，可以将2D关键点标注的时间和努力减少至10倍以上。</li>
<li>methods: Click-Pose使用了一个对话式人工标注 Loop，让用户点击预测的关键点进行更正，并使用一个独特的姿势错误模型来提高模型的自我更正能力。</li>
<li>results: Click-Pose在COCO和Human-Art等两个测试集上显示了优秀的效果，只需1.97和6.45次点击（NoC）@95（精度95%）来标注，较前一代模型（ViTPose）的手动更正需要31.4%和36.3%的努力。此外，不需要用户点击，Click-Pose仍然可以超越先前的端到端模型。代码可以在<a target="_blank" rel="noopener" href="https://github.com/IDEA-Research/Click-Pose%E4%B8%8A%E5%8F%96%E5%BE%97%E3%80%82">https://github.com/IDEA-Research/Click-Pose上取得。</a><details>
<summary>Abstract</summary>
This work proposes an end-to-end neural interactive keypoint detection framework named Click-Pose, which can significantly reduce more than 10 times labeling costs of 2D keypoint annotation compared with manual-only annotation. Click-Pose explores how user feedback can cooperate with a neural keypoint detector to correct the predicted keypoints in an interactive way for a faster and more effective annotation process. Specifically, we design the pose error modeling strategy that inputs the ground truth pose combined with four typical pose errors into the decoder and trains the model to reconstruct the correct poses, which enhances the self-correction ability of the model. Then, we attach an interactive human-feedback loop that allows receiving users' clicks to correct one or several predicted keypoints and iteratively utilizes the decoder to update all other keypoints with a minimum number of clicks (NoC) for efficient annotation. We validate Click-Pose in in-domain, out-of-domain scenes, and a new task of keypoint adaptation. For annotation, Click-Pose only needs 1.97 and 6.45 NoC@95 (at precision 95%) on COCO and Human-Art, reducing 31.4% and 36.3% efforts than the SOTA model (ViTPose) with manual correction, respectively. Besides, without user clicks, Click-Pose surpasses the previous end-to-end model by 1.4 AP on COCO and 3.0 AP on Human-Art. The code is available at https://github.com/IDEA-Research/Click-Pose.
</details>
<details>
<summary>摘要</summary>
这个工作提出了一种名为Click-Pose的结束到终端神经互动关键点检测框架，可以减少更多于10倍的2D关键点标注成本，比手动标注更快和有效。Click-Poseexplores如何用户反馈与神经关键点检测器共同 correction predicted关键点，以实现更快和更有效的标注过程。我们设计了 pose error 模型，将真实pose与四种常见pose error 输入到decoder中，并训练模型可以重建正确的pose，从而提高自修复能力。然后，我们附加了一个交互式人工反馈循环，让用户点击correct predicted关键点，并 iteratively使用decoder更新所有关键点，最少clicks (NoC)  для高效的标注。我们验证Click-Pose在域内、域外场景和新任务关键点适应中。对于标注，Click-Pose只需1.97和6.45 NoC@95 (精度95%) 在COCO和人类艺术上，相比SOTA模型（ViTPose）的手动更正，减少了31.4%和36.3%的努力。此外，无需用户点击，Click-Pose超过了之前的端到终模型1.4 AP在COCO和3.0 AP在人类艺术上。代码可以在https://github.com/IDEA-Research/Click-Pose中找到。
</details></li>
</ul>
<hr>
<h2 id="VLN-PETL-Parameter-Efficient-Transfer-Learning-for-Vision-and-Language-Navigation"><a href="#VLN-PETL-Parameter-Efficient-Transfer-Learning-for-Vision-and-Language-Navigation" class="headerlink" title="VLN-PETL: Parameter-Efficient Transfer Learning for Vision-and-Language Navigation"></a>VLN-PETL: Parameter-Efficient Transfer Learning for Vision-and-Language Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10172">http://arxiv.org/abs/2308.10172</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yanyuanqiao/vln-petl">https://github.com/yanyuanqiao/vln-petl</a></li>
<li>paper_authors: Yanyuan Qiao, Zheng Yu, Qi Wu</li>
<li>for: 本研究旨在提高大型预训练视言语模型在视言语 Navigation~(VLN) 任务上的性能，并且减少全量微调预训练模型的成本。</li>
<li>methods: 本研究提出了一种特点是 VLN 任务的Parameter-Efficient Transfer Learning~(PETL) 方法，包括两个特有的 PETL 模块：历史互动增强器（HIB）和 crossing modal 互动增强器（CIB）。</li>
<li>results: 在四种主流 VLN 任务（R2R、REVERIE、NDH、RxR）的广泛实验结果表明，提出的 VLN-PETL 方法可以与全微调和其他 PETL 方法相比，达到相同或更好的性能，并且具有更好的抗衰减性。<details>
<summary>Abstract</summary>
The performance of the Vision-and-Language Navigation~(VLN) tasks has witnessed rapid progress recently thanks to the use of large pre-trained vision-and-language models. However, full fine-tuning the pre-trained model for every downstream VLN task is becoming costly due to the considerable model size. Recent research hotspot of Parameter-Efficient Transfer Learning (PETL) shows great potential in efficiently tuning large pre-trained models for the common CV and NLP tasks, which exploits the most of the representation knowledge implied in the pre-trained model while only tunes a minimal set of parameters. However, simply utilizing existing PETL methods for the more challenging VLN tasks may bring non-trivial degeneration to the performance. Therefore, we present the first study to explore PETL methods for VLN tasks and propose a VLN-specific PETL method named VLN-PETL. Specifically, we design two PETL modules: Historical Interaction Booster (HIB) and Cross-modal Interaction Booster (CIB). Then we combine these two modules with several existing PETL methods as the integrated VLN-PETL. Extensive experimental results on four mainstream VLN tasks (R2R, REVERIE, NDH, RxR) demonstrate the effectiveness of our proposed VLN-PETL, where VLN-PETL achieves comparable or even better performance to full fine-tuning and outperforms other PETL methods with promising margins.
</details>
<details>
<summary>摘要</summary>
“在最近，视觉语言导航（VLN）任务的性能得到了迅速的进步，归功于使用大型预训练的视觉语言模型。然而，对于每个下游VLN任务进行全面的预训练模型 fine-tuning 成本增加，因为模型的大小很大。目前研究热点 Parameter-Efficient Transfer Learning（PETL）表现出了巨大的潜力，可以有效地调参大型预训练模型，并且只需要调参最小的参数集。然而，直接使用现有的 PETL 方法来处理更加具有挑战性的 VLN 任务可能会导致性能下降。因此，我们提出了首次对 VLN 任务使用 PETL 方法的研究，并提出了一种特定于 VLN 的 PETL 方法 named VLN-PETL。特别是，我们设计了两个 PETL 模块：历史互动加速器（HIB）和交叉模式互动加速器（CIB）。然后，我们将这两个模块与一些现有的 PETL 方法相结合，形成了集成的 VLN-PETL。我们对四个主流 VLN 任务（R2R、REVERIE、NDH、RxR）进行了广泛的实验，结果表明，我们提出的 VLN-PETL 方法可以与全面 fine-tuning 和其他 PETL 方法相比，具有同等或更好的性能。”
</details></li>
</ul>
<hr>
<h2 id="Cell-Spatial-Analysis-in-Crohn’s-Disease-Unveiling-Local-Cell-Arrangement-Pattern-with-Graph-based-Signatures"><a href="#Cell-Spatial-Analysis-in-Crohn’s-Disease-Unveiling-Local-Cell-Arrangement-Pattern-with-Graph-based-Signatures" class="headerlink" title="Cell Spatial Analysis in Crohn’s Disease: Unveiling Local Cell Arrangement Pattern with Graph-based Signatures"></a>Cell Spatial Analysis in Crohn’s Disease: Unveiling Local Cell Arrangement Pattern with Graph-based Signatures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10166">http://arxiv.org/abs/2308.10166</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shunxing Bao, Sichen Zhu, Vasantha L Kolachala, Lucas W. Remedios, Yeonjoo Hwang, Yutong Sun, Ruining Deng, Can Cui, Yike Li, Jia Li, Joseph T. Roland, Qi Liu, Ken S. Lau, Subra Kugathasan, Peng Qiu, Keith T. Wilson, Lori A. Coburn, Bennett A. Landman, Yuankai Huo</li>
<li>for: 本研究旨在描述crohn病（CD）活动的抑菌环境，尤其是在肠道区域。</li>
<li>methods: 研究人员使用了 Hematoxylin and Eosin 染色技术（H&amp;E），并分类了6种不同的细胞类型。然后，他们使用了 t-SNE 和 Kernel Density Estimation 来分析细胞环境的地方特征。</li>
<li>results: 研究发现了不同的细胞嵌入模式，尤其是在RECTUM区域。这些差异强调了数据不同性对细胞空间安排的影响。此外，研究还发现了两个研究机构之间的数据分布差异，这指出了协作医疗机构的重要性。<details>
<summary>Abstract</summary>
Crohn's disease (CD) is a chronic and relapsing inflammatory condition that affects segments of the gastrointestinal tract. CD activity is determined by histological findings, particularly the density of neutrophils observed on Hematoxylin and Eosin stains (H&E) imaging. However, understanding the broader morphometry and local cell arrangement beyond cell counting and tissue morphology remains challenging. To address this, we characterize six distinct cell types from H&E images and develop a novel approach for the local spatial signature of each cell. Specifically, we create a 10-cell neighborhood matrix, representing neighboring cell arrangements for each individual cell. Utilizing t-SNE for non-linear spatial projection in scatter-plot and Kernel Density Estimation contour-plot formats, our study examines patterns of differences in the cellular environment associated with the odds ratio of spatial patterns between active CD and control groups. This analysis is based on data collected at the two research institutes. The findings reveal heterogeneous nearest-neighbor patterns, signifying distinct tendencies of cell clustering, with a particular focus on the rectum region. These variations underscore the impact of data heterogeneity on cell spatial arrangements in CD patients. Moreover, the spatial distribution disparities between the two research sites highlight the significance of collaborative efforts among healthcare organizations. All research analysis pipeline tools are available at https://github.com/MASILab/cellNN.
</details>
<details>
<summary>摘要</summary>
crohn病 (CD) 是一种 chronic 和 relapsing 的Inflammatory condition ，影响 digestive tract 的一部分。 CD 的活动由 histological 发现决定，特别是 neutrophils 的密度在 Hematoxylin 和 Eosin 染色 (H&E) 图像中。然而，理解更广泛的 morphometry 和 local cell arrangement 还是一个挑战。为了解决这个问题，我们将 six 种不同的细胞类型从 H&E 图像中分类，并开发了一种 novel approach 以获取每个细胞的本地空间签名。 Specifically, we create a 10-cell neighborhood matrix, representing neighboring cell arrangements for each individual cell. 使用 t-SNE  для非线性空间投影，我们在 scatter-plot 和 Kernel Density Estimation 折线图中进行了 pattern 的分析，以探讨 CD 和 control 组之间的cellular environment 差异。这种分析基于在两个研究机构收集的数据。我们发现 heterogeneous 的 nearest-neighbor 模式，表明 CD 病人的细胞含量具有明显的差异，尤其是在 rectum 区域。这些差异 highlights 数据的多样性对细胞空间安排的影响。此外，研究站之间的 spatial distribution 差异也表明了卫生机构之间的合作是非常重要。所有的研究分析管道工具可以在 https://github.com/MASILab/cellNN 上找到。
</details></li>
</ul>
<hr>
<h2 id="ThermRad-A-Multi-modal-Dataset-for-Robust-3D-Object-Detection-under-Challenging-Conditions"><a href="#ThermRad-A-Multi-modal-Dataset-for-Robust-3D-Object-Detection-under-Challenging-Conditions" class="headerlink" title="ThermRad: A Multi-modal Dataset for Robust 3D Object Detection under Challenging Conditions"></a>ThermRad: A Multi-modal Dataset for Robust 3D Object Detection under Challenging Conditions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10161">http://arxiv.org/abs/2308.10161</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiao Yan, Yihan Wang</li>
<li>for: 提高3D物体检测的稳定性和可靠性在极端天气和照明条件下。</li>
<li>methods: 提出了一种新的多模态融合方法，即RTDF-RCNN，利用4D雷达和热成像仪器的优势进行对象检测。</li>
<li>results: 对比其他方法，RTDF-RCNN在检测车辆、人员和自行车等对象方面有显著提高（超过7.98%、24.27%和27.15%），同时与LiDAR方法具有相似的性能。<details>
<summary>Abstract</summary>
Robust 3D object detection in extreme weather and illumination conditions is a challenging task. While radars and thermal cameras are known for their resilience to these conditions, few studies have been conducted on radar-thermal fusion due to the lack of corresponding datasets. To address this gap, we first present a new multi-modal dataset called ThermRad, which includes a 3D LiDAR, a 4D radar, an RGB camera and a thermal camera. This dataset is unique because it includes data from all four sensors in extreme weather conditions, providing a valuable resource for future research in this area. To validate the robustness of 4D radars and thermal cameras for 3D object detection in challenging weather conditions, we propose a new multi-modal fusion method called RTDF-RCNN, which leverages the complementary strengths of 4D radars and thermal cameras to boost object detection performance. To further prove the effectiveness of our proposed framework, we re-implement state-of-the-art (SOTA) 3D detectors on our dataset as benchmarks for evaluation. Our method achieves significant enhancements in detecting cars, pedestrians, and cyclists, with improvements of over 7.98%, 24.27%, and 27.15%, respectively, while achieving comparable results to LiDAR-based approaches. Our contributions in both the ThermRad dataset and the new multi-modal fusion method provide a new approach to robust 3D object detection in adverse weather and illumination conditions. The ThermRad dataset will be released.
</details>
<details>
<summary>摘要</summary>
“Robust 3D物体探测在极端天气和照明条件下是一项具有挑战性的任务。尽管雷达和热成像仪器在这些条件下显示出了抗性，但由于数据集的缺乏，关于雷达-热成像融合的研究受到了限制。为了解决这个差距，我们首先提供了一个新的多模态数据集，称为ThermRad，该数据集包括3D LiDAR、4D雷达、RGB摄像头和热成像仪器。这个数据集独特之处在于它包含了所有四种感知器的数据，并在极端天气条件下进行数据采集，提供了未来研究的优质资源。为了证明4D雷达和热成像仪器在极端天气条件下的 robustness，我们提出了一种新的多模态融合方法，称为RTDF-RCNN，该方法利用了4D雷达和热成像仪器之间的共同优势，以提高物体探测性能。为了进一步证明我们的提出的方法的效果，我们重新实现了状态计算机视觉（SOTA）3D探测器在我们的数据集上进行评估。我们的方法在检测汽车、人员和自行车方面获得了显著提升，提升率分别为7.98%、24.27%和27.15%，而同时与LiDAR基本上的方法具有相似的结果。我们的贡献在ThermRad数据集和新的多模态融合方法方面，为robust 3D物体探测在极端天气和照明条件下提供了一个新的方法。ThermRad数据集将会公开发布。”
</details></li>
</ul>
<hr>
<h2 id="HODN-Disentangling-Human-Object-Feature-for-HOI-Detection"><a href="#HODN-Disentangling-Human-Object-Feature-for-HOI-Detection" class="headerlink" title="HODN: Disentangling Human-Object Feature for HOI Detection"></a>HODN: Disentangling Human-Object Feature for HOI Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10158">http://arxiv.org/abs/2308.10158</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuman Fang, Zhiwen Lin, Ke Yan, Jie Li, Xianming Lin, Rongrong Ji</li>
<li>for: 本文目标是提高人物物体互动检测的精度，并提出了一种基于变换器的人物物体分离网络（HODN），以显著提高现有方法的性能。</li>
<li>methods: 本文使用了两个独立的分离解码器来检测人物和物体，然后将其传递给互动解码器进行互动检测。为了确保互动解码器关注人类中心的区域，我们提出了一种人类导引链接方法。此外，我们还提出了一种停止梯度机制，以防止互动导引对物体检测的影响，但允许它们对人类检测的影响。</li>
<li>results: 我们的提议方法在V-COCO和HICO-Det数据集上达到了竞争性表现，可以与现有方法相结合以实现最佳效果。<details>
<summary>Abstract</summary>
The task of Human-Object Interaction (HOI) detection is to detect humans and their interactions with surrounding objects, where transformer-based methods show dominant advances currently. However, these methods ignore the relationship among humans, objects, and interactions: 1) human features are more contributive than object ones to interaction prediction; 2) interactive information disturbs the detection of objects but helps human detection. In this paper, we propose a Human and Object Disentangling Network (HODN) to model the HOI relationships explicitly, where humans and objects are first detected by two disentangling decoders independently and then processed by an interaction decoder. Considering that human features are more contributive to interaction, we propose a Human-Guide Linking method to make sure the interaction decoder focuses on the human-centric regions with human features as the positional embeddings. To handle the opposite influences of interactions on humans and objects, we propose a Stop-Gradient Mechanism to stop interaction gradients from optimizing the object detection but to allow them to optimize the human detection. Our proposed method achieves competitive performance on both the V-COCO and the HICO-Det datasets. It can be combined with existing methods easily for state-of-the-art results.
</details>
<details>
<summary>摘要</summary>
人机物互动检测任务的目标是检测人类和他们与周围物体之间的互动，而transformer基本方法在当前得到了主导地位。然而，这些方法忽略了人类、物体和互动之间的关系：1）人类特征更加重要于互动预测;2）互动信息会干扰物体检测，但是帮助人类检测。在这篇论文中，我们提议了一个人类和物体分离网络（HODN），以显式地模型HOI关系，其中人类和物体被两个独立的分离解码器独立地检测，然后被交互解码器处理。由于人类特征更加重要于互动预测，我们提议了一个人类引导链接方法，以确保交互解码器专注于人类中心的区域，并将人类特征作为位域嵌入。为了处理人类和物体之间的对称影响，我们提议了一个停止梯度机制，以停止互动梯度在物体检测中优化，但是允许它们在人类检测中优化。我们的提议方法在V-COCO和HICO-Det datasets上达到了竞争性的性能。它可以轻松地与现有方法结合使用，以实现当前最佳结果。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Diffusion-Model-with-Auxiliary-Guidance-for-Coarse-to-Fine-PET-Reconstruction"><a href="#Contrastive-Diffusion-Model-with-Auxiliary-Guidance-for-Coarse-to-Fine-PET-Reconstruction" class="headerlink" title="Contrastive Diffusion Model with Auxiliary Guidance for Coarse-to-Fine PET Reconstruction"></a>Contrastive Diffusion Model with Auxiliary Guidance for Coarse-to-Fine PET Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10157">http://arxiv.org/abs/2308.10157</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/show-han/pet-reconstruction">https://github.com/show-han/pet-reconstruction</a></li>
<li>paper_authors: Zeyu Han, Yuhan Wang, Luping Zhou, Peng Wang, Binyu Yan, Jiliu Zhou, Yan Wang, Dinggang Shen</li>
<li>for: 提高高质量的 пози特摄影图像，降低人体辐射暴露</li>
<li>methods: 使用抽象敌方网络（GANs）和扩散概率模型（DPMs），以及一种协同逐步优化模型</li>
<li>results: 对两个人脑 Positron Emission Tomography（PET）数据集进行了广泛的实验，并证明了该方法可以高效地提高 clinical 可靠性<details>
<summary>Abstract</summary>
To obtain high-quality positron emission tomography (PET) scans while reducing radiation exposure to the human body, various approaches have been proposed to reconstruct standard-dose PET (SPET) images from low-dose PET (LPET) images. One widely adopted technique is the generative adversarial networks (GANs), yet recently, diffusion probabilistic models (DPMs) have emerged as a compelling alternative due to their improved sample quality and higher log-likelihood scores compared to GANs. Despite this, DPMs suffer from two major drawbacks in real clinical settings, i.e., the computationally expensive sampling process and the insufficient preservation of correspondence between the conditioning LPET image and the reconstructed PET (RPET) image. To address the above limitations, this paper presents a coarse-to-fine PET reconstruction framework that consists of a coarse prediction module (CPM) and an iterative refinement module (IRM). The CPM generates a coarse PET image via a deterministic process, and the IRM samples the residual iteratively. By delegating most of the computational overhead to the CPM, the overall sampling speed of our method can be significantly improved. Furthermore, two additional strategies, i.e., an auxiliary guidance strategy and a contrastive diffusion strategy, are proposed and integrated into the reconstruction process, which can enhance the correspondence between the LPET image and the RPET image, further improving clinical reliability. Extensive experiments on two human brain PET datasets demonstrate that our method outperforms the state-of-the-art PET reconstruction methods. The source code is available at \url{https://github.com/Show-han/PET-Reconstruction}.
</details>
<details>
<summary>摘要</summary>
要获得高质量的 позиトрон释发tomography（PET）图像，同时减少人体暴露到辐射的方法，Various approaches have been proposed to reconstruct standard-dose PET (SPET) images from low-dose PET (LPET) images. One widely adopted technique is the generative adversarial networks (GANs), yet recently, diffusion probabilistic models (DPMs) have emerged as a compelling alternative due to their improved sample quality and higher log-likelihood scores compared to GANs. Despite this, DPMs suffer from two major drawbacks in real clinical settings, i.e., the computationally expensive sampling process and the insufficient preservation of correspondence between the conditioning LPET image and the reconstructed PET (RPET) image. To address the above limitations, this paper presents a coarse-to-fine PET reconstruction framework that consists of a coarse prediction module (CPM) and an iterative refinement module (IRM). The CPM generates a coarse PET image via a deterministic process, and the IRM samples the residual iteratively. By delegating most of the computational overhead to the CPM, the overall sampling speed of our method can be significantly improved. Furthermore, two additional strategies, i.e., an auxiliary guidance strategy and a contrastive diffusion strategy, are proposed and integrated into the reconstruction process, which can enhance the correspondence between the LPET image and the RPET image, further improving clinical reliability. Extensive experiments on two human brain PET datasets demonstrate that our method outperforms the state-of-the-art PET reconstruction methods. The source code is available at \url{https://github.com/Show-han/PET-Reconstruction}.Here's the translation in Traditional Chinese:要获得高质量的 позиトрон释放tomography（PET）图像，同时减少人体暴露到辐射的方法，Various approaches have been proposed to reconstruct standard-dose PET (SPET) images from low-dose PET (LPET) images. One widely adopted technique is the generative adversarial networks (GANs), yet recently, diffusion probabilistic models (DPMs) have emerged as a compelling alternative due to their improved sample quality and higher log-likelihood scores compared to GANs. Despite this, DPMs suffer from two major drawbacks in real clinical settings, i.e., the computationally expensive sampling process and the insufficient preservation of correspondence between the conditioning LPET image and the reconstructed PET (RPET) image. To address the above limitations, this paper presents a coarse-to-fine PET reconstruction framework that consists of a coarse prediction module (CPM) and an iterative refinement module (IRM). The CPM generates a coarse PET image via a deterministic process, and the IRM samples the residual iteratively. By delegating most of the computational overhead to the CPM, the overall sampling speed of our method can be significantly improved. Furthermore, two additional strategies, i.e., an auxiliary guidance strategy and a contrastive diffusion strategy, are proposed and integrated into the reconstruction process, which can enhance the correspondence between the LPET image and the RPET image, further improving clinical reliability. Extensive experiments on two human brain PET datasets demonstrate that our method outperforms the state-of-the-art PET reconstruction methods. The source code is available at \url{https://github.com/Show-han/PET-Reconstruction}.
</details></li>
</ul>
<hr>
<h2 id="Unilaterally-Aggregated-Contrastive-Learning-with-Hierarchical-Augmentation-for-Anomaly-Detection"><a href="#Unilaterally-Aggregated-Contrastive-Learning-with-Hierarchical-Augmentation-for-Anomaly-Detection" class="headerlink" title="Unilaterally Aggregated Contrastive Learning with Hierarchical Augmentation for Anomaly Detection"></a>Unilaterally Aggregated Contrastive Learning with Hierarchical Augmentation for Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10155">http://arxiv.org/abs/2308.10155</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guodong Wang, Yunhong Wang, Jie Qin, Dongming Zhang, Xiuguo Bao, Di Huang</li>
<li>for: 这篇论文的目的是提出一种基于自适应学习的异常检测方法（Unilaterally Aggregated Contrastive Learning with Hierarchical Augmentation，UniCon-HA），以满足安全关键应用中异常检测的需求。</li>
<li>methods: 这篇论文使用了自适应学习的方法，包括对异常样本进行批量聚合，以及采用层次增强的批量聚合策略。同时，它还引入了一种软重要机制，以保证异常样本的纯净集中。</li>
<li>results: 这篇论文的实验结果显示，UniCon-HA方法在三种异常检测设定中（无标签一类、无标签多类和标签多类）均达到了其他竞争者的超越。<details>
<summary>Abstract</summary>
Anomaly detection (AD), aiming to find samples that deviate from the training distribution, is essential in safety-critical applications. Though recent self-supervised learning based attempts achieve promising results by creating virtual outliers, their training objectives are less faithful to AD which requires a concentrated inlier distribution as well as a dispersive outlier distribution. In this paper, we propose Unilaterally Aggregated Contrastive Learning with Hierarchical Augmentation (UniCon-HA), taking into account both the requirements above. Specifically, we explicitly encourage the concentration of inliers and the dispersion of virtual outliers via supervised and unsupervised contrastive losses, respectively. Considering that standard contrastive data augmentation for generating positive views may induce outliers, we additionally introduce a soft mechanism to re-weight each augmented inlier according to its deviation from the inlier distribution, to ensure a purified concentration. Moreover, to prompt a higher concentration, inspired by curriculum learning, we adopt an easy-to-hard hierarchical augmentation strategy and perform contrastive aggregation at different depths of the network based on the strengths of data augmentation. Our method is evaluated under three AD settings including unlabeled one-class, unlabeled multi-class, and labeled multi-class, demonstrating its consistent superiority over other competitors.
</details>
<details>
<summary>摘要</summary>
预测异常（AD），找到训练分布不同的样本，在安全关键应用中是非常重要的。虽然最近的自我超vised学习基于尝试得到了可观的结果，但它们的训练目标不符合AD的需求，AD需要一个集中的异常样本分布以及一个散布的异常样本分布。在这篇论文中，我们提出了一种带有层次增强的对比学习方法（UniCon-HA），该方法考虑了上述两个需求。具体来说，我们明确地鼓励异常样本的集中和虚拟异常样本的散布，通过自我对比和不对比的损失函数来实现。由于标准的对比数据增强可能会生成异常样本，我们还提出了一种软机制来重新评估每个增强后的异常样本，以确保它们的集中程度。此外，为了提高集中程度，我们采用了一种易到difficult的层次增强策略，并在网络的不同层次上进行对比归一化，根据数据增强的强度。我们的方法在三种AD设定下进行评估，包括一类、多类和多类标注的情况，并示出了与其他竞争者相比的一致性优势。
</details></li>
</ul>
<hr>
<h2 id="ESTextSpotter-Towards-Better-Scene-Text-Spotting-with-Explicit-Synergy-in-Transformer"><a href="#ESTextSpotter-Towards-Better-Scene-Text-Spotting-with-Explicit-Synergy-in-Transformer" class="headerlink" title="ESTextSpotter: Towards Better Scene Text Spotting with Explicit Synergy in Transformer"></a>ESTextSpotter: Towards Better Scene Text Spotting with Explicit Synergy in Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10147">http://arxiv.org/abs/2308.10147</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mxin262/estextspotter">https://github.com/mxin262/estextspotter</a></li>
<li>paper_authors: Mingxin Huang, Jiaxin Zhang, Dezhi Peng, Hao Lu, Can Huang, Yuliang Liu, Xiang Bai, Lianwen Jin</li>
<li>for: 提高文本检测和识别的同时性能</li>
<li>methods: 提出了一种新的Explicit Synergy-based Text Spotting Transformer框架(ESTextSpotter),通过在单个解码器中模型特定的文本检测和识别特征来实现显式的同时性。</li>
<li>results: 实验结果表明，我们的模型在比较前的状态提高了文本检测和识别的性能。代码可以在<a target="_blank" rel="noopener" href="https://github.com/mxin262/ESTextSpotter%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/mxin262/ESTextSpotter上获取。</a><details>
<summary>Abstract</summary>
In recent years, end-to-end scene text spotting approaches are evolving to the Transformer-based framework. While previous studies have shown the crucial importance of the intrinsic synergy between text detection and recognition, recent advances in Transformer-based methods usually adopt an implicit synergy strategy with shared query, which can not fully realize the potential of these two interactive tasks. In this paper, we argue that the explicit synergy considering distinct characteristics of text detection and recognition can significantly improve the performance text spotting. To this end, we introduce a new model named Explicit Synergy-based Text Spotting Transformer framework (ESTextSpotter), which achieves explicit synergy by modeling discriminative and interactive features for text detection and recognition within a single decoder. Specifically, we decompose the conventional shared query into task-aware queries for text polygon and content, respectively. Through the decoder with the proposed vision-language communication module, the queries interact with each other in an explicit manner while preserving discriminative patterns of text detection and recognition, thus improving performance significantly. Additionally, we propose a task-aware query initialization scheme to ensure stable training. Experimental results demonstrate that our model significantly outperforms previous state-of-the-art methods. Code is available at https://github.com/mxin262/ESTextSpotter.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="OCHID-Fi-Occlusion-Robust-Hand-Pose-Estimation-in-3D-via-RF-Vision"><a href="#OCHID-Fi-Occlusion-Robust-Hand-Pose-Estimation-in-3D-via-RF-Vision" class="headerlink" title="OCHID-Fi: Occlusion-Robust Hand Pose Estimation in 3D via RF-Vision"></a>OCHID-Fi: Occlusion-Robust Hand Pose Estimation in 3D via RF-Vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10146">http://arxiv.org/abs/2308.10146</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shujie Zhang, Tianyue Zheng, Zhe Chen, Jingzhi Hu, Abdelwahed Khamis, Jiajun Liu, Jun Luo</li>
<li>for: 提高手势识别率在 occluded  scenarios</li>
<li>methods: 使用 radio-frequency-vision (RF-vision) 技术，并提出 OCHID-Fi 方法，使用宽带 RF 感知器在增强的 LoS 条件下检测手势 pose</li>
<li>results: 实验结果表明 OCHID-Fi 方法可以在 occluded  scenarios 中保持 comparable 的精度，并且可以在新领域中进行推广Here’s a more detailed explanation of each point:</li>
<li>for: The paper aims to improve hand pose estimation accuracy in occluded scenarios, which is a challenging problem in many applications such as virtual reality, robotics, and human-computer interaction.</li>
<li>methods: The proposed method uses radio-frequency-vision (RF-vision) technology, which can bypass obstacles and capture hand pose information behind them. The method introduces OCHID-Fi, a complex-valued RF-HPE network that is trained using a cross-modality and cross-domain training process. The network is guided by a pre-trained CM-HPE network and a synchronized CM&#x2F;RF dataset, and it uses adversarial learning to transfer knowledge from labeled LoS domain to unlabeled occluded domain.</li>
<li>results: The experimental results show that OCHID-Fi achieves comparable accuracy to CM-HPE under normal conditions while maintaining such accuracy even in occluded scenarios. The method also demonstrates empirical evidence for its generalizability to new domains.<details>
<summary>Abstract</summary>
Hand Pose Estimation (HPE) is crucial to many applications, but conventional cameras-based CM-HPE methods are completely subject to Line-of-Sight (LoS), as cameras cannot capture occluded objects. In this paper, we propose to exploit Radio-Frequency-Vision (RF-vision) capable of bypassing obstacles for achieving occluded HPE, and we introduce OCHID-Fi as the first RF-HPE method with 3D pose estimation capability. OCHID-Fi employs wideband RF sensors widely available on smart devices (e.g., iPhones) to probe 3D human hand pose and extract their skeletons behind obstacles. To overcome the challenge in labeling RF imaging given its human incomprehensible nature, OCHID-Fi employs a cross-modality and cross-domain training process. It uses a pre-trained CM-HPE network and a synchronized CM/RF dataset, to guide the training of its complex-valued RF-HPE network under LoS conditions. It further transfers knowledge learned from labeled LoS domain to unlabeled occluded domain via adversarial learning, enabling OCHID-Fi to generalize to unseen occluded scenarios. Experimental results demonstrate the superiority of OCHID-Fi: it achieves comparable accuracy to CM-HPE under normal conditions while maintaining such accuracy even in occluded scenarios, with empirical evidence for its generalizability to new domains.
</details>
<details>
<summary>摘要</summary>
手势识别 (HPE) 是许多应用程序的关键，但传统的摄像头基于CM-HPE方法是完全受到视线（LoS）的限制，因为摄像头无法捕捉遮盖物体。在这篇论文中，我们提议利用无线电视觉（RF-vision），可以绕过障碍物来实现遮盖物体HPE，并引入OCHID-Fi作为首个RF-HPE方法，具有3D手势 pose estimation能力。OCHID-Fi使用通用在智能设备（例如iPhone）上广泛可用的宽频RF传感器来探测3D人类手势pose和提取其骨架。为了解决RF成像的标注挑战，OCHID-Fi采用了交叉模式和交叉领域的训练过程。它使用一个先行训练的CM-HPE网络和一个同步的CM/RF数据集，以引导RF-HPE网络的训练。它还通过对LoS频谱频率进行挑战学习，将学习于标注的LoS频谱频率转移到未标注的遮盖频谱频率，使OCHID-Fi能够通过频谱频率的挑战学习来泛化到新的频谱频率。实验结果表明，OCHID-Fi具有优于CM-HPE的性能，在正常情况下与CM-HPE具有相同的精度，而且在遮盖情况下保持精度，并且在新的频谱频率上进行泛化。
</details></li>
</ul>
<hr>
<h2 id="Polymerized-Feature-based-Domain-Adaptation-for-Cervical-Cancer-Dose-Map-Prediction"><a href="#Polymerized-Feature-based-Domain-Adaptation-for-Cervical-Cancer-Dose-Map-Prediction" class="headerlink" title="Polymerized Feature-based Domain Adaptation for Cervical Cancer Dose Map Prediction"></a>Polymerized Feature-based Domain Adaptation for Cervical Cancer Dose Map Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10142">http://arxiv.org/abs/2308.10142</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Zeng, Zeyu Han, Xingchen Peng, Jianghong Xiao, Peng Wang, Yan Wang</li>
<li>for: 提高乳腺癌辐射规划的准确性，使用深度学习自动化和加速辐射规划</li>
<li>methods: 通过领域适应而增强深度学习预测辐射规划表现，将乳腺癌和肛癌的知识转移到辐射规划中</li>
<li>results: 实验结果表明，提出的方法在两个内部临床数据集上显示出优于现有方法的性能<details>
<summary>Abstract</summary>
Recently, deep learning (DL) has automated and accelerated the clinical radiation therapy (RT) planning significantly by predicting accurate dose maps. However, most DL-based dose map prediction methods are data-driven and not applicable for cervical cancer where only a small amount of data is available. To address this problem, this paper proposes to transfer the rich knowledge learned from another cancer, i.e., rectum cancer, which has the same scanning area and more clinically available data, to improve the dose map prediction performance for cervical cancer through domain adaptation. In order to close the congenital domain gap between the source (i.e., rectum cancer) and the target (i.e., cervical cancer) domains, we develop an effective Transformer-based polymerized feature module (PFM), which can generate an optimal polymerized feature distribution to smoothly align the two input distributions. Experimental results on two in-house clinical datasets demonstrate the superiority of the proposed method compared with state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
To close the congenital domain gap between the source (i.e., rectum cancer) and the target (i.e., cervical cancer) domains, we develop an effective Transformer-based polymerized feature module (PFM). This module can generate an optimal polymerized feature distribution to smoothly align the two input distributions. Experimental results on two in-house clinical datasets demonstrate the superiority of the proposed method compared with state-of-the-art methods.
</details></li>
</ul>
<hr>
<h2 id="March-in-Chat-Interactive-Prompting-for-Remote-Embodied-Referring-Expression"><a href="#March-in-Chat-Interactive-Prompting-for-Remote-Embodied-Referring-Expression" class="headerlink" title="March in Chat: Interactive Prompting for Remote Embodied Referring Expression"></a>March in Chat: Interactive Prompting for Remote Embodied Referring Expression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10141">http://arxiv.org/abs/2308.10141</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yanyuanqiao/mic">https://github.com/yanyuanqiao/mic</a></li>
<li>paper_authors: Yanyuan Qiao, Yuankai Qi, Zheng Yu, Jing Liu, Qi Wu</li>
<li>for: The paper is written for proposing a March-in-Chat (MiC) model that can talk to a Large Language Model (LLM) on the fly and plan dynamically based on a newly proposed Room-and-Object Aware Scene Perceiver (ROASP) to improve the performance of Vision-and-Language Navigation (VLN) tasks, specifically in the REVERIE setting.</li>
<li>methods: The paper uses a MiC model that incorporates a ROASP to enable the LLM to plan actions based on the current visual observation and adapt to the larger and more complex REVERIE environment.</li>
<li>results: The paper shows that the proposed MiC model outperforms the previous state-of-the-art by large margins in terms of SPL and RGSPL metrics on the REVERIE benchmark.<details>
<summary>Abstract</summary>
Many Vision-and-Language Navigation (VLN) tasks have been proposed in recent years, from room-based to object-based and indoor to outdoor. The REVERIE (Remote Embodied Referring Expression) is interesting since it only provides high-level instructions to the agent, which are closer to human commands in practice. Nevertheless, this poses more challenges than other VLN tasks since it requires agents to infer a navigation plan only based on a short instruction. Large Language Models (LLMs) show great potential in robot action planning by providing proper prompts. Still, this strategy has not been explored under the REVERIE settings. There are several new challenges. For example, the LLM should be environment-aware so that the navigation plan can be adjusted based on the current visual observation. Moreover, the LLM planned actions should be adaptable to the much larger and more complex REVERIE environment. This paper proposes a March-in-Chat (MiC) model that can talk to the LLM on the fly and plan dynamically based on a newly proposed Room-and-Object Aware Scene Perceiver (ROASP). Our MiC model outperforms the previous state-of-the-art by large margins by SPL and RGSPL metrics on the REVERIE benchmark.
</details>
<details>
<summary>摘要</summary>
很多视觉语言导航（VLN）任务在最近几年内被提出，从房间基于的到物体基于的和室内到户外的。REVERIE（远程身体引用表达）是有趣的，因为它只提供高级指令给代理人，这些指令更加接近实际的人类命令。然而，这会提高代理人需要根据短 instrucion 生成导航计划的挑战。大语言模型（LLM）在机器人行动规划方面表现出了极大的潜力，但这种策略在 REVERIE 设置下尚未被探讨。新的挑战包括：LLM 需要环境意识，以便根据当前视觉观察更新导航计划。此外，LLM 计划的行动需要适应 REVERIE 环境中的更大和更复杂的环境。这篇论文提出了一种 March-in-Chat（MiC）模型，可以在 fly 中与 LLM 交流，并基于一种新的 Room-and-Object Aware Scene Perceiver（ROASP）进行动态规划。我们的 MiC 模型在 REVERIE benchmark 上比前一个状态的平均值大幅度超越了 SPL 和 RGSPL 指标。
</details></li>
</ul>
<hr>
<h2 id="HollowNeRF-Pruning-Hashgrid-Based-NeRFs-with-Trainable-Collision-Mitigation"><a href="#HollowNeRF-Pruning-Hashgrid-Based-NeRFs-with-Trainable-Collision-Mitigation" class="headerlink" title="HollowNeRF: Pruning Hashgrid-Based NeRFs with Trainable Collision Mitigation"></a>HollowNeRF: Pruning Hashgrid-Based NeRFs with Trainable Collision Mitigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10122">http://arxiv.org/abs/2308.10122</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiufeng Xie, Riccardo Gherardi, Zhihong Pan, Stephen Huang</li>
<li>for: 提高 NeRF 训练和评估的效率，使用 hashgrid-based 位置编码和神经网络，但是有效地利用三维场景的空间稀疏性仍然是一个挑战。</li>
<li>methods: 我们提出了一种新的压缩解决方案，即 HollowNeRF，它在训练阶段自动精炼 hashgrid-based NeRF 的特征网格。它通过训练一个粗略的三维感知掩模，以及使用 alternating direction method of multipliers (ADMM) 压缩器来精炼三维感知掩模，从而实现了高质量渲染的同时采用较少的参数。</li>
<li>results: 我们的方法可以与 Instant-NGP 相比，提供类似的渲染质量，但是使用的参数数量只有 Instant-NGP 的 31%。此外，我们的方法可以在 PSNR 精度上增加至 1dB，使用的参数数量仅占 Instant-NGP 的 56%。<details>
<summary>Abstract</summary>
Neural radiance fields (NeRF) have garnered significant attention, with recent works such as Instant-NGP accelerating NeRF training and evaluation through a combination of hashgrid-based positional encoding and neural networks. However, effectively leveraging the spatial sparsity of 3D scenes remains a challenge. To cull away unnecessary regions of the feature grid, existing solutions rely on prior knowledge of object shape or periodically estimate object shape during training by repeated model evaluations, which are costly and wasteful.   To address this issue, we propose HollowNeRF, a novel compression solution for hashgrid-based NeRF which automatically sparsifies the feature grid during the training phase. Instead of directly compressing dense features, HollowNeRF trains a coarse 3D saliency mask that guides efficient feature pruning, and employs an alternating direction method of multipliers (ADMM) pruner to sparsify the 3D saliency mask during training. By exploiting the sparsity in the 3D scene to redistribute hash collisions, HollowNeRF improves rendering quality while using a fraction of the parameters of comparable state-of-the-art solutions, leading to a better cost-accuracy trade-off. Our method delivers comparable rendering quality to Instant-NGP, while utilizing just 31% of the parameters. In addition, our solution can achieve a PSNR accuracy gain of up to 1dB using only 56% of the parameters.
</details>
<details>
<summary>摘要</summary>
为解决这个问题，我们提出了 HollowNeRF，一种新的压缩解决方案，用于在 hashgrid-based NeRF 训练阶段自动稀疏特征网格。而不是直接压缩密集特征，HollowNeRF 通过训练一个粗略的三维焦点映射来引导高效的特征剔除，并使用 alternating direction method of multipliers (ADMM) 剔除器在训练阶段稀疏着色映射。通过利用场景中的稀疏性来重新分配哈希冲突，HollowNeRF 可以提高渲染质量，使用相对较少的参数，从而实现更好的成本准确性质量比。我们的方法可以与 Instant-NGP 相比，在同等参数下提供相同的渲染质量，而使用的参数只占 Instant-NGP 的31%。此外，我们的方法还可以在56%的参数下实现PSNR准确性增加达1dB。
</details></li>
</ul>
<hr>
<h2 id="PDL-Regularizing-Multiple-Instance-Learning-with-Progressive-Dropout-Layers"><a href="#PDL-Regularizing-Multiple-Instance-Learning-with-Progressive-Dropout-Layers" class="headerlink" title="PDL: Regularizing Multiple Instance Learning with Progressive Dropout Layers"></a>PDL: Regularizing Multiple Instance Learning with Progressive Dropout Layers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10112">http://arxiv.org/abs/2308.10112</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chongqingnosubway/pdl">https://github.com/chongqingnosubway/pdl</a></li>
<li>paper_authors: Wenhui Zhu, Peijie Qiu, Oana M. Dumitrascu, Yalin Wang</li>
<li>for: 本研究旨在提高多个实例学习（MIL）模型的性能，特别是在弱监督学习情况下。</li>
<li>methods: 本研究提出了一种新的进步Dropout层（PDL），用于在MIL模型中进行规范。PDL不仅能够降低过拟合，还能够帮助MIL模型找到更加复杂和有力的特征表示。</li>
<li>results: 在多个MILbenchmark dataset上进行了广泛的评估，结果显示了将PDL integrate into多种MIL方法可以不仅提高分类性能，还能够增强其弱监督特征地图localization的能力。<details>
<summary>Abstract</summary>
Multiple instance learning (MIL) was a weakly supervised learning approach that sought to assign binary class labels to collections of instances known as bags. However, due to their weak supervision nature, the MIL methods were susceptible to overfitting and required assistance in developing comprehensive representations of target instances. While regularization typically effectively combated overfitting, its integration with the MIL model has been frequently overlooked in prior studies. Meanwhile, current regularization methods for MIL have shown limitations in their capacity to uncover a diverse array of representations. In this study, we delve into the realm of regularization within the MIL model, presenting a novel approach in the form of a Progressive Dropout Layer (PDL). We aim to not only address overfitting but also empower the MIL model in uncovering intricate and impactful feature representations. The proposed method was orthogonal to existing MIL methods and could be easily integrated into them to boost performance. Our extensive evaluation across a range of MIL benchmark datasets demonstrated that the incorporation of the PDL into multiple MIL methods not only elevated their classification performance but also augmented their potential for weakly-supervised feature localizations.
</details>
<details>
<summary>摘要</summary>
在这个研究中，我们探究MIL模型中的常见化，提出了一种Progressive Dropout Layer（PDL）方法。我们不仅想要解决过拟合问题，还想要让MIL模型探索复杂且影响力大的特征表示。提出的方法与现有MIL方法 orthogonal，可以轻松地与之集成以提高性能。我们在多种MIL benchmark数据集上进行了广泛的评估，发现在 integrate PDL 到多种MIL方法后，不仅提高了分类性能，还扩大了它们的弱监督学习特征地址 localization 的潜力。
</details></li>
</ul>
<hr>
<h2 id="Controllable-Multi-domain-Semantic-Artwork-Synthesis"><a href="#Controllable-Multi-domain-Semantic-Artwork-Synthesis" class="headerlink" title="Controllable Multi-domain Semantic Artwork Synthesis"></a>Controllable Multi-domain Semantic Artwork Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10111">http://arxiv.org/abs/2308.10111</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuantian Huang, Satoshi Iizuka, Edgar Simo-Serra, Kazuhiro Fukui</li>
<li>for: 该论文目的是提出一种多域合成艺术作品的框架，以解决艺术合成 tasks 缺乏公共可用的分割数据的问题。</li>
<li>methods: 该论文提出了一个名为 ArtSem 的数据集，包含 40,000 个艺术作品的 semantic 标签地图，以及一种基于 Conditional GAN 的方法，可以高质量地从 semantic 地图生成艺术作品，无需对训练数据进行对应。此外，论文还提出了一种域dependent variational encoder 来实现高质量的多域合成。</li>
<li>results: 论文的实验结果表明，该模型可以学习 joint 表示 style 和 semantic 信息，从而实现更好的艺术作品生成。此外，通过分析 latent space 中域分隔的hyperplane，我们还可以实现细化控制生成的艺术作品。相比之前的方法，我们的模型可以生成更高质量的艺术作品。<details>
<summary>Abstract</summary>
We present a novel framework for multi-domain synthesis of artwork from semantic layouts. One of the main limitations of this challenging task is the lack of publicly available segmentation datasets for art synthesis. To address this problem, we propose a dataset, which we call ArtSem, that contains 40,000 images of artwork from 4 different domains with their corresponding semantic label maps. We generate the dataset by first extracting semantic maps from landscape photography and then propose a conditional Generative Adversarial Network (GAN)-based approach to generate high-quality artwork from the semantic maps without necessitating paired training data. Furthermore, we propose an artwork synthesis model that uses domain-dependent variational encoders for high-quality multi-domain synthesis. The model is improved and complemented with a simple but effective normalization method, based on normalizing both the semantic and style jointly, which we call Spatially STyle-Adaptive Normalization (SSTAN). In contrast to previous methods that only take semantic layout as input, our model is able to learn a joint representation of both style and semantic information, which leads to better generation quality for synthesizing artistic images. Results indicate that our model learns to separate the domains in the latent space, and thus, by identifying the hyperplanes that separate the different domains, we can also perform fine-grained control of the synthesized artwork. By combining our proposed dataset and approach, we are able to generate user-controllable artwork that is of higher quality than existing
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的框架，用于多域合成艺术作品的 semantic 布局。这个挑战性任务的一个主要 limitation 是没有公共可用的分割数据集 для艺术合成。为了解决这个问题，我们提出了一个名为 ArtSem 的数据集，包含 40,000 个艺术作品从 4 个不同域的图像和其对应的 semantic 标签地图。我们使用 conditional Generative Adversarial Network (GAN) 方法生成高质量的艺术作品从 semantic 地图，无需 paired 训练数据。此外，我们提出了一种基于域 dependent 变量编码器的高质量多域合成模型。该模型通过将 semantic 和样式信息结合在一起，学习到了joint 表示，从而实现更好的生成质量。结果表明，我们的模型可以在 latent 空间中分离不同域，因此，通过识别不同域之间的分界面，也可以实现细致控制生成的艺术作品。通过我们提出的数据集和方法，我们能够生成高质量的用户控制的艺术作品。
</details></li>
</ul>
<hr>
<h2 id="Root-Pose-Decomposition-Towards-Generic-Non-rigid-3D-Reconstruction-with-Monocular-Videos"><a href="#Root-Pose-Decomposition-Towards-Generic-Non-rigid-3D-Reconstruction-with-Monocular-Videos" class="headerlink" title="Root Pose Decomposition Towards Generic Non-rigid 3D Reconstruction with Monocular Videos"></a>Root Pose Decomposition Towards Generic Non-rigid 3D Reconstruction with Monocular Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10089">http://arxiv.org/abs/2308.10089</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yikai Wang, Yinpeng Dong, Fuchun Sun, Xiao Yang</li>
<li>for: 这个论文旨在实现基于单色RGB视频序列的非固定对象三维重建。</li>
<li>methods: 该方法基于Root Pose Decomposition（RPD），保持每帧根pose变换，同时建立了局部变换的恰当空间。点注册到Canonical space进行优化。</li>
<li>results: RPD可以在复杂的情况下进行非固定对象的三维重建，包括对象受损、人体差异、 occlusion 等。该管道可能扩展到多种对象。实验表明，RPD超过了当前状态艺技。<details>
<summary>Abstract</summary>
This work focuses on the 3D reconstruction of non-rigid objects based on monocular RGB video sequences. Concretely, we aim at building high-fidelity models for generic object categories and casually captured scenes. To this end, we do not assume known root poses of objects, and do not utilize category-specific templates or dense pose priors. The key idea of our method, Root Pose Decomposition (RPD), is to maintain a per-frame root pose transformation, meanwhile building a dense field with local transformations to rectify the root pose. The optimization of local transformations is performed by point registration to the canonical space. We also adapt RPD to multi-object scenarios with object occlusions and individual differences. As a result, RPD allows non-rigid 3D reconstruction for complicated scenarios containing objects with large deformations, complex motion patterns, occlusions, and scale diversities of different individuals. Such a pipeline potentially scales to diverse sets of objects in the wild. We experimentally show that RPD surpasses state-of-the-art methods on the challenging DAVIS, OVIS, and AMA datasets.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MeDM-Mediating-Image-Diffusion-Models-for-Video-to-Video-Translation-with-Temporal-Correspondence-Guidance"><a href="#MeDM-Mediating-Image-Diffusion-Models-for-Video-to-Video-Translation-with-Temporal-Correspondence-Guidance" class="headerlink" title="MeDM: Mediating Image Diffusion Models for Video-to-Video Translation with Temporal Correspondence Guidance"></a>MeDM: Mediating Image Diffusion Models for Video-to-Video Translation with Temporal Correspondence Guidance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10079">http://arxiv.org/abs/2308.10079</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ernie Chu, Tzuhsuan Huang, Shuo-Yen Lin, Jun-Cheng Chen</li>
<li>for: 本研究提出了一种高效和可靠的方法，MeDM，利用预训练的图像扩散模型进行视频到视频翻译，保持 temporal 流动的一致性。</li>
<li>methods: 该方法使用显式的光学流动来构建实用的编码，并对生成的帧进行独立分数。通过利用这种编码，可以将生成的视频中的每帧照合到物理约束，从而解决视频翻译中的困难。</li>
<li>results: 通过对多个标准 bencmark 进行广泛的质量和主观测试，研究表明，MeDM 的方法可以准确地将视频翻译成目标视频，并且比传统方法更有优势。<details>
<summary>Abstract</summary>
This study introduces an efficient and effective method, MeDM, that utilizes pre-trained image Diffusion Models for video-to-video translation with consistent temporal flow. The proposed framework can render videos from scene position information, such as a normal G-buffer, or perform text-guided editing on videos captured in real-world scenarios. We employ explicit optical flows to construct a practical coding that enforces physical constraints on generated frames and mediates independent frame-wise scores. By leveraging this coding, maintaining temporal consistency in the generated videos can be framed as an optimization problem with a closed-form solution. To ensure compatibility with Stable Diffusion, we also suggest a workaround for modifying observed-space scores in latent-space Diffusion Models. Notably, MeDM does not require fine-tuning or test-time optimization of the Diffusion Models. Through extensive qualitative, quantitative, and subjective experiments on various benchmarks, the study demonstrates the effectiveness and superiority of the proposed approach.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Sensitivity-analysis-of-AI-based-algorithms-for-autonomous-driving-on-optical-wavefront-aberrations-induced-by-the-windshield"><a href="#Sensitivity-analysis-of-AI-based-algorithms-for-autonomous-driving-on-optical-wavefront-aberrations-induced-by-the-windshield" class="headerlink" title="Sensitivity analysis of AI-based algorithms for autonomous driving on optical wavefront aberrations induced by the windshield"></a>Sensitivity analysis of AI-based algorithms for autonomous driving on optical wavefront aberrations induced by the windshield</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11711">http://arxiv.org/abs/2308.11711</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dominik Werner Wolf, Markus Ulrich, Nikhil Kapoor</li>
<li>For: 本研究旨在解决自动驾驶感知技术中的领域转移问题，通过评估两种感知模型对不同风镜配置的敏感性。* Methods: 本研究使用了 Fourier optics 基于的威胁模型来评估感知模型对风镜配置的影响，并对两种感知模型的 neural network benchmark 指标和光学质量函数之间的相关性进行分析。* Results: 研究发现，风镜配置会导致感知模型表现下降，而现有的光学指标可能不够用于评估感知模型的性能。<details>
<summary>Abstract</summary>
Autonomous driving perception techniques are typically based on supervised machine learning models that are trained on real-world street data. A typical training process involves capturing images with a single car model and windshield configuration. However, deploying these trained models on different car types can lead to a domain shift, which can potentially hurt the neural networks performance and violate working ADAS requirements. To address this issue, this paper investigates the domain shift problem further by evaluating the sensitivity of two perception models to different windshield configurations. This is done by evaluating the dependencies between neural network benchmark metrics and optical merit functions by applying a Fourier optics based threat model. Our results show that there is a performance gap introduced by windshields and existing optical metrics used for posing requirements might not be sufficient.
</details>
<details>
<summary>摘要</summary>
自主驾驶感知技术通常基于supervised机器学习模型，通过实际街道数据进行训练。一般训练过程中会使用单车型和车窗配置拍摄图像。但是，将训练过的模型部署到不同车型上可能会导致域名shift，这可能会影响神经网络性能，并违反工作ADAS要求。为解决这个问题，本文进一步研究域名shift问题，评估两种感知模型对不同车窗配置的敏感性。通过应用 Fourier optics based threat model，我们发现存在由车窗引入的性能差距，现有的光学指标可能不够。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/20/cs.CV_2023_08_20/" data-id="clohum97700g7pj88fsx85hmb" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/20/cs.AI_2023_08_20/" class="article-date">
  <time datetime="2023-08-20T12:00:00.000Z" itemprop="datePublished">2023-08-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/20/cs.AI_2023_08_20/">cs.AI - 2023-08-20</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Towards-Few-shot-Coordination-Revisiting-Ad-hoc-Teamplay-Challenge-In-the-Game-of-Hanabi"><a href="#Towards-Few-shot-Coordination-Revisiting-Ad-hoc-Teamplay-Challenge-In-the-Game-of-Hanabi" class="headerlink" title="Towards Few-shot Coordination: Revisiting Ad-hoc Teamplay Challenge In the Game of Hanabi"></a>Towards Few-shot Coordination: Revisiting Ad-hoc Teamplay Challenge In the Game of Hanabi</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10284">http://arxiv.org/abs/2308.10284</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hadi Nekoei, Xutong Zhao, Janarthanan Rajendran, Miao Liu, Sarath Chandar</li>
<li>for: 这项研究旨在解决在多智能体协同学习中零shot协调问题。</li>
<li>methods: 研究人员使用了现状最佳算法和独立学习算法来评估多智能体协同学习算法的适应性。</li>
<li>results: 研究发现，使用现状最佳算法和独立学习算法可以快速适应不同合作伙伴，但需要训练数据的多样性和优化过程的控制。<details>
<summary>Abstract</summary>
Cooperative Multi-agent Reinforcement Learning (MARL) algorithms with Zero-Shot Coordination (ZSC) have gained significant attention in recent years. ZSC refers to the ability of agents to coordinate zero-shot (without additional interaction experience) with independently trained agents. While ZSC is crucial for cooperative MARL agents, it might not be possible for complex tasks and changing environments. Agents also need to adapt and improve their performance with minimal interaction with other agents. In this work, we show empirically that state-of-the-art ZSC algorithms have poor performance when paired with agents trained with different learning methods, and they require millions of interaction samples to adapt to these new partners. To investigate this issue, we formally defined a framework based on a popular cooperative multi-agent game called Hanabi to evaluate the adaptability of MARL methods. In particular, we created a diverse set of pre-trained agents and defined a new metric called adaptation regret that measures the agent's ability to efficiently adapt and improve its coordination performance when paired with some held-out pool of partners on top of its ZSC performance. After evaluating several SOTA algorithms using our framework, our experiments reveal that naive Independent Q-Learning (IQL) agents in most cases adapt as quickly as the SOTA ZSC algorithm Off-Belief Learning (OBL). This finding raises an interesting research question: How to design MARL algorithms with high ZSC performance and capability of fast adaptation to unseen partners. As a first step, we studied the role of different hyper-parameters and design choices on the adaptability of current MARL algorithms. Our experiments show that two categories of hyper-parameters controlling the training data diversity and optimization process have a significant impact on the adaptability of Hanabi agents.
</details>
<details>
<summary>摘要</summary>
合作多智能体强化学习（MARL）算法与零shot协调（ZSC）在最近几年内获得了广泛关注。ZSC指代智能体可以零shot（无需额外互动经验）协调独立训练的智能体。然而，ZSC可能不适用于复杂任务和变化环境中。智能体还需要适应和改进其性能，只需最小化与其他智能体的互动。在这个工作中，我们通过实验表明，现状最佳ZSC算法与其他学习方法训练的智能体 pairing 时，性能很差，需要数百万互动样本来适应这些新伙伴。为了探索这个问题，我们正式定义了基于流行的合作多智能体游戏哈那比（Hanabi）的框架，以评估MARL方法的适应性。具体来说，我们创建了一个多样化的预训练智能体集合，并定义了一个新的度量叫做适应 regret，用于衡量智能体在与一些封锁的伙伴中进行协调时，能够快速适应和提高协调性能。经过我们的实验，我们发现，简单粗略的独立Q学习（IQL）智能体在大多数情况下能够和SOTA ZSC算法OFF-BELIEF学习（OBL）一样快速适应。这一发现提出了一个有趣的研究问题：如何设计MARL算法，具有高度的ZSC性能和适应不seen伙伴的能力。作为一个初步探索，我们研究了当前MARL算法的不同超参数和设计选择对适应性的影响。我们的实验显示，控制训练数据多样性和优化过程的两类超参数有重要的影响于哈那比智能体的适应性。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Spatiotemporal-Traffic-Prediction-through-Urban-Human-Activity-Analysis"><a href="#Enhancing-Spatiotemporal-Traffic-Prediction-through-Urban-Human-Activity-Analysis" class="headerlink" title="Enhancing Spatiotemporal Traffic Prediction through Urban Human Activity Analysis"></a>Enhancing Spatiotemporal Traffic Prediction through Urban Human Activity Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10282">http://arxiv.org/abs/2308.10282</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/suminhan/traffic-uagcrntf">https://github.com/suminhan/traffic-uagcrntf</a></li>
<li>paper_authors: Sumin Han, Youngjun Park, Minji Lee, Jisun An, Dongman Lee</li>
<li>For: 提高城市交通安全和便利性，改进现有的交通预测模型。* Methods: 使用图 convolution deep learning算法，利用国家户室旅行调查数据增强 causal 关系 между活动和交通模式。* Results: 对现有的图 convolutional recurrent networks 和图 convolutional transformer 架构进行修改，实现 state-of-the-art 性能而不增加计算负担。<details>
<summary>Abstract</summary>
Traffic prediction is one of the key elements to ensure the safety and convenience of citizens. Existing traffic prediction models primarily focus on deep learning architectures to capture spatial and temporal correlation. They often overlook the underlying nature of traffic. Specifically, the sensor networks in most traffic datasets do not accurately represent the actual road network exploited by vehicles, failing to provide insights into the traffic patterns in urban activities. To overcome these limitations, we propose an improved traffic prediction method based on graph convolution deep learning algorithms. We leverage human activity frequency data from National Household Travel Survey to enhance the inference capability of a causal relationship between activity and traffic patterns. Despite making minimal modifications to the conventional graph convolutional recurrent networks and graph convolutional transformer architectures, our approach achieves state-of-the-art performance without introducing excessive computational overhead.
</details>
<details>
<summary>摘要</summary>
traffic prediction 是确保市民安全便利的关键元素之一。现有的交通预测模型主要利用深度学习架构捕捉空间和时间相关性。它们经常忽视交通的本质。 Specifically, 交通感知网络在大多数交通数据集中不准确反映实际行驶路网络， fail to provide insights into traffic patterns in urban activities。 To overcome these limitations, we propose an improved traffic prediction method based on graph convolution deep learning algorithms. We leverage human activity frequency data from National Household Travel Survey to enhance the inference capability of a causal relationship between activity and traffic patterns. Despite making minimal modifications to the conventional graph convolutional recurrent networks and graph convolutional transformer architectures, our approach achieves state-of-the-art performance without introducing excessive computational overhead.Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="The-DKU-DUKEECE-System-for-the-Manipulation-Region-Location-Task-of-ADD-2023"><a href="#The-DKU-DUKEECE-System-for-the-Manipulation-Region-Location-Task-of-ADD-2023" class="headerlink" title="The DKU-DUKEECE System for the Manipulation Region Location Task of ADD 2023"></a>The DKU-DUKEECE System for the Manipulation Region Location Task of ADD 2023</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10281">http://arxiv.org/abs/2308.10281</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zexin Cai, Weiqing Wang, Yikang Wang, Ming Li</li>
<li>for: 本研究是为了解决 Audio Deepfake Detection Challenge (ADD 2023) 中的 Track 2 任务，即检测受到修改的音频段别。</li>
<li>methods: 本研究使用了多种检测系统，包括边界检测系统和深度迷伪检测系统，以及专门使用真实数据训练的 VAE 模型来确定音频clip的真实性。</li>
<li>results: 通过将这三个系统融合，我们实现了82.23%的句子准确率和60.66%的 F1 分数，最终ADD分数为0.6713，在 Track 2 中得到第一名。<details>
<summary>Abstract</summary>
This paper introduces our system designed for Track 2, which focuses on locating manipulated regions, in the second Audio Deepfake Detection Challenge (ADD 2023). Our approach involves the utilization of multiple detection systems to identify splicing regions and determine their authenticity. Specifically, we train and integrate two frame-level systems: one for boundary detection and the other for deepfake detection. Additionally, we employ a third VAE model trained exclusively on genuine data to determine the authenticity of a given audio clip. Through the fusion of these three systems, our top-performing solution for the ADD challenge achieves an impressive 82.23% sentence accuracy and an F1 score of 60.66%. This results in a final ADD score of 0.6713, securing the first rank in Track 2 of ADD 2023.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了我们为Track 2而设计的系统，这个Track focuses on locating manipulated regions in the second Audio Deepfake Detection Challenge (ADD 2023)。我们的方法是利用多个检测系统来确定剪辑区域的真实性。具体来说，我们训练并集成了两个帧级系统：一个用于边界检测，另一个用于深伪检测。此外，我们还使用了专门为真实数据训练的VAE模型来确定声音片断的真实性。通过这三个系统的融合，我们的最高表现解决方案在ADD挑战中获得了82.23%的句子准确率和60.66%的F1分数。这导致了我们在Track 2的ADD分数为0.6713，在ADD 2023中取得了第一名。
</details></li>
</ul>
<hr>
<h2 id="Learning-Disentangled-Representation-with-Mutual-Information-Maximization-for-Real-Time-UAV-Tracking"><a href="#Learning-Disentangled-Representation-with-Mutual-Information-Maximization-for-Real-Time-UAV-Tracking" class="headerlink" title="Learning Disentangled Representation with Mutual Information Maximization for Real-Time UAV Tracking"></a>Learning Disentangled Representation with Mutual Information Maximization for Real-Time UAV Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10262">http://arxiv.org/abs/2308.10262</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xucheng Wang, Xiangyang Yang, Hengzhou Ye, Shuiwang Li</li>
<li>for: 提高 UAV 跟踪中的效率和精度，使用 DL 模型压缩和分解表示。</li>
<li>methods: 使用 DR-MIM 技术实现分解表示，提高模型的表示效果，并且使用 mutual information maximization 提高模型的精度。</li>
<li>results: 在四个 UAV 测试benchmark上，DR-MIM 跟踪器与现有状态的 UAV 跟踪方法相比，显示了显著的提高。<details>
<summary>Abstract</summary>
Efficiency has been a critical problem in UAV tracking due to limitations in computation resources, battery capacity, and unmanned aerial vehicle maximum load. Although discriminative correlation filters (DCF)-based trackers prevail in this field for their favorable efficiency, some recently proposed lightweight deep learning (DL)-based trackers using model compression demonstrated quite remarkable CPU efficiency as well as precision. Unfortunately, the model compression methods utilized by these works, though simple, are still unable to achieve satisfying tracking precision with higher compression rates. This paper aims to exploit disentangled representation learning with mutual information maximization (DR-MIM) to further improve DL-based trackers' precision and efficiency for UAV tracking. The proposed disentangled representation separates the feature into an identity-related and an identity-unrelated features. Only the latter is used, which enhances the effectiveness of the feature representation for subsequent classification and regression tasks. Extensive experiments on four UAV benchmarks, including UAV123@10fps, DTB70, UAVDT and VisDrone2018, show that our DR-MIM tracker significantly outperforms state-of-the-art UAV tracking methods.
</details>
<details>
<summary>摘要</summary>
efficiency 是 UAV 跟踪领域中的一个关键问题，因为计算资源、电池容量和无人飞行器最大负荷受限。 although 使用推荐相关矩阵（DCF）的trackers 在这个领域占据主导地位，因为它们具有良好的效率。 unfortunately，这些最近提出的轻量级深度学习（DL）基于的trackers 使用的模型压缩方法，虽然简单，仍然无法在更高的压缩率下实现满意的跟踪精度。 this paper aims to exploit 分解表示学习（DR）和共享信息最大化（MIM）来进一步提高 DL 基于的trackers 的精度和效率 для UAV 跟踪。 the proposed 分解表示 separates the feature into an identity-related and an identity-unrelated features。 only the latter is used, which enhances the effectiveness of the feature representation for subsequent classification and regression tasks. extensive experiments on four UAV benchmarks, including UAV123@10fps, DTB70, UAVDT and VisDrone2018, show that our DR-MIM tracker significantly outperforms state-of-the-art UAV tracking methods.
</details></li>
</ul>
<hr>
<h2 id="Large-Transformers-are-Better-EEG-Learners"><a href="#Large-Transformers-are-Better-EEG-Learners" class="headerlink" title="Large Transformers are Better EEG Learners"></a>Large Transformers are Better EEG Learners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11654">http://arxiv.org/abs/2308.11654</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bingxin Wang, Xiaowen Fu, Yuan Lan, Luchan Zhang, Yang Xiang</li>
<li>for: 这 paper 是为了研究如何使用预训练的大型变换器模型来进行电enzephalogram (EEG) 数据预测任务。</li>
<li>methods: 这 paper 使用了一种名为 AdaCE（适应器 для转换 EEG 数据）来直接在预训练的视觉和语言变换器模型上进行 EEG 数据预测任务的细化。</li>
<li>results: 这 paper 的实验结果表明，使用 AdaCE 模块可以很好地细化预训练的变换器模型，并在多种 EEG 预测任务上达到了状态的艺术性表现。例如，在 UCI HAR 任务上，AdaCE 在预训练的 Swin-Transformer 上 achieve 99.6%，相对于预训练的模型，提高了9.2%。此外，这 paper 还证明了，通过应用 AdaCE 模块来细化更大的预训练模型，可以在 EEG 预测任务上实现更好的表现，这表明了我们的适应器的潜在应用前景。<details>
<summary>Abstract</summary>
Pre-trained large transformer models have achieved remarkable performance in the fields of natural language processing and computer vision. Since the magnitude of available labeled electroencephalogram (EEG) data is much lower than that of text and image data, it is difficult for transformer models pre-trained from EEG to be developed as large as GPT-4 100T to fully unleash the potential of this architecture. In this paper, we show that transformers pre-trained from images as well as text can be directly fine-tuned for EEG-based prediction tasks. We design AdaCE, plug-and-play Adapters for Converting EEG data into image as well as text forms, to fine-tune pre-trained vision and language transformers. The proposed AdaCE module is highly effective for fine-tuning pre-trained transformers while achieving state-of-the-art performance on diverse EEG-based prediction tasks. For example, AdaCE on the pre-trained Swin-Transformer achieves 99.6%, an absolute improvement of 9.2%, on the EEG-decoding task of human activity recognition (UCI HAR). Furthermore, we empirically show that applying the proposed AdaCE to fine-tune larger pre-trained models can achieve better performance on EEG-based predicting tasks, indicating the potential of our adapters for even larger transformers. The plug-and-play AdaCE module can be applied to fine-tuning most of the popular pre-trained transformers on many other time-series data with multiple channels, not limited to EEG data and the models we use. Our code will be available at https://github.com/wangbxj1234/AdaCE.
</details>
<details>
<summary>摘要</summary>
<<SYS>>转换给定文本到简化中文。<</SYS>>大型预训练变换器模型在自然语言处理和计算机视觉领域已经取得了非常出色的表现。由于可用的电enzephalogram（EEG）数据量与文本和图像数据量相比较少，因此预训练自EEG的变换器模型难以达到GPT-4 100T的规模，以全面发挥这种架构的潜力。在这篇论文中，我们表明可以将预训练自图像以及文本的变换器模型直接精度调整为EEG预测任务。我们设计了AdaCE模块，即适配器转换EEG数据为图像和文本形式，以精度调整预训练的视觉和语言变换器。我们的AdaCE模块非常有效地精度调整预训练的变换器，并在多种EEG预测任务上达到了状态 искусственный智能的性能。例如，AdaCE在预训练的Swin-Transformer上达到了99.6%，相对于基eline的9.2%提升。此外，我们也证明了将AdaCE应用于精度调整更大的预训练模型可以在EEG预测任务中达到更好的性能，表明我们的适配器对更大的变换器有潜力。AdaCE模块可以应用于多种 популяр的预训练变换器，并不限于EEG数据和我们使用的模型。我们的代码将在GitHub上公开。
</details></li>
</ul>
<hr>
<h2 id="LMTuner-An-user-friendly-and-highly-integrable-Training-Framework-for-fine-tuning-Large-Language-Models"><a href="#LMTuner-An-user-friendly-and-highly-integrable-Training-Framework-for-fine-tuning-Large-Language-Models" class="headerlink" title="LMTuner: An user-friendly and highly-integrable Training Framework for fine-tuning Large Language Models"></a>LMTuner: An user-friendly and highly-integrable Training Framework for fine-tuning Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10252">http://arxiv.org/abs/2308.10252</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wengsyx/lmtuner">https://github.com/wengsyx/lmtuner</a></li>
<li>paper_authors: Yixuan Weng, Zhiqi Wang, Huanxuan Liao, Shizhu He, Shengping Liu, Kang Liu, Jun Zhao</li>
<li>for: 本研究旨在提高大语言模型（LLM）的快速增量训练，以满足特定领域和行业的需求。</li>
<li>methods: 该研究提出了一种名为LMTuner的高度可用、可integrable和可扩展的系统，用于快速训练LLM。LMTuner包括交互模块、训练模块和推理模块。</li>
<li>results: 研究表明，LMTuner可以帮助用户快速启动LLM的训练，只需5分钟即可。此外，LMTuner还支持许多高效精细调整方法，如LoRA和QLoRA等，可以在单个服务器上训练300M到130B参数的语言模型。<details>
<summary>Abstract</summary>
With the burgeoning development in the realm of large language models (LLMs), the demand for efficient incremental training tailored to specific industries and domains continues to increase. Currently, the predominantly employed frameworks lack modular design, it often takes a lot of coding work to kickstart the training of LLM. To address this, we present "LMTuner", a highly usable, integrable, and scalable system for training LLMs expeditiously and with minimal user-input. LMTuner comprises three main modules - the Interaction, Training, and Inference Modules. We advocate that LMTuner's usability and integrality alleviate the complexities in training large language models. Remarkably, even a novice user could commence training large language models within five minutes. Furthermore, it integrates DeepSpeed frameworks and supports Efficient Fine-Tuning methodologies like Low Rank Adaptation (LoRA), Quantized LoRA (QLoRA), etc., enabling the training of language models scaling from 300M to a whopping 130B parameters using a single server. The LMTuner's homepage (https://wengsyx.github.io/LMTuner/)and screencast video (https://youtu.be/nsXmWOmN3rE) are now publicly available.
</details>
<details>
<summary>摘要</summary>
随着大型语言模型（LLM）的发展，需要高效、逐步培训适应特定领域和领域的需求不断增长。目前主要使用的框架缺乏模块化设计，经常需要大量代码工作以开始LLM的培训。为解决这个问题，我们提出了“LMTuner”系统，它具有高度可用性、可插入性和可扩展性，可以快速、需要 minimal user-input 培训大型语言模型。LMTuner包括三个主要模块：交互模块、培训模块和推理模块。我们认为LMTuner的可用性和可插入性可以减轻大型语言模型培训的复杂性。特别是，even a novice user可以在5分钟内开始培训大型语言模型。此外，它还支持深速框架和高效精度调整方法（如LoRA、QLoRA等），可以在单个服务器上培训语言模型，从300M到130B参数的训练。LMTuner的主页（https://wengsyx.github.io/LMTuner/)和屏幕录制视频（https://youtu.be/nsXmWOmN3rE）现在都已经公开。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-powered-Combinatorial-Clock-Auction"><a href="#Machine-Learning-powered-Combinatorial-Clock-Auction" class="headerlink" title="Machine Learning-powered Combinatorial Clock Auction"></a>Machine Learning-powered Combinatorial Clock Auction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10226">http://arxiv.org/abs/2308.10226</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/marketdesignresearch/ml-cca">https://github.com/marketdesignresearch/ml-cca</a></li>
<li>paper_authors: Ermis Soumalias, Jakob Weissteiner, Jakob Heiss, Sven Seuken</li>
<li>for: 提高实际 iterative combinatorial auctions (ICA) 的设计效率，尤其是在 bundle space  exponentially 增长的情况下。</li>
<li>methods: 使用机器学习 (ML) 技术进行 preference elicitation，并提出一种基于 demand queries 的 ML-powered combinatorial clock auction。</li>
<li>results: 在 spectrum auction 多个领域进行实验，并与最常用的实际 ICA（combined clock auction）进行比较，结果显示了 significanly 高效性和 clearer potential。<details>
<summary>Abstract</summary>
We study the design of iterative combinatorial auctions (ICAs). The main challenge in this domain is that the bundle space grows exponentially in the number of items. To address this, several papers have recently proposed machine learning (ML)-based preference elicitation algorithms that aim to elicit only the most important information from bidders. However, from a practical point of view, the main shortcoming of this prior work is that those designs elicit bidders' preferences via value queries (i.e., ``What is your value for the bundle $\{A,B\}$?''). In most real-world ICA domains, value queries are considered impractical, since they impose an unrealistically high cognitive burden on bidders, which is why they are not used in practice. In this paper, we address this shortcoming by designing an ML-powered combinatorial clock auction that elicits information from the bidders only via demand queries (i.e., ``At prices $p$, what is your most preferred bundle of items?''). We make two key technical contributions: First, we present a novel method for training an ML model on demand queries. Second, based on those trained ML models, we introduce an efficient method for determining the demand query with the highest clearing potential, for which we also provide a theoretical foundation. We experimentally evaluate our ML-based demand query mechanism in several spectrum auction domains and compare it against the most established real-world ICA: the combinatorial clock auction (CCA). Our mechanism significantly outperforms the CCA in terms of efficiency in all domains, it achieves higher efficiency in a significantly reduced number of rounds, and, using linear prices, it exhibits vastly higher clearing potential. Thus, with this paper we bridge the gap between research and practice and propose the first practical ML-powered ICA.
</details>
<details>
<summary>摘要</summary>
我们研究联合推价 combinatorial auction（ICA）的设计。主要挑战在这域的是，套件空间随着物品数量的增加而呈指数增长。为解决这个问题，一些最近的论文已经提出了基于机器学习（ML）的偏好探索算法，目的是获取价值询问（i.e., What is your value for the bundle \{A,B\}?）。但实际上，这些设计仍然存在一个问题，那是它们透过价值询问来探索投得者的偏好，这种方法在实际应用中被视为不切实际。在这篇论文中，我们解决这个问题，通过设计一个基于ML的联合时钟推价（Combinatorial Clock Auction，CCA），这个推价方式只透过需求询问（i.e., At prices $p$, what is your most preferred bundle of items?）来探索投得者的偏好。我们做了两个关键的技术贡献：首先，我们提出了一种基于需求询问的ML模型训练方法。其次，基于这些训练的ML模型，我们引入了一个高效的需求询问选择方法，并提供了理论基础。我们将这些结果实际应用于几个频谱拍卖领域，并与现有的CCA进行比较。我们的机制在所有领域中具有更高的效率，可以在许多领域中取得更高的效率，并且使用线性价格，它的推价 potential  exhibits vastly higher clearing potential。因此，这篇论文 bridges the gap between research and practice，并提出了首个实际可行的ML-powered ICA。
</details></li>
</ul>
<hr>
<h2 id="ChatEDA-A-Large-Language-Model-Powered-Autonomous-Agent-for-EDA"><a href="#ChatEDA-A-Large-Language-Model-Powered-Autonomous-Agent-for-EDA" class="headerlink" title="ChatEDA: A Large Language Model Powered Autonomous Agent for EDA"></a>ChatEDA: A Large Language Model Powered Autonomous Agent for EDA</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10204">http://arxiv.org/abs/2308.10204</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuolun He, Haoyuan Wu, Xinyun Zhang, Xufeng Yao, Su Zheng, Haisheng Zheng, Bei Yu</li>
<li>for: 提高电路设计工作流程的自动化和效率，使用大型自然语言处理模型来增强电子设计自动化工具之间的协同合作。</li>
<li>methods: 使用大型自然语言处理模型AutoMage，并与电子设计自动化工具相结合，实现了自动化的任务规划、脚本生成和任务执行。</li>
<li>results: 通过全面的实验评估，ChatEDA已经表明了在处理多样化的需求方面的强大能力，并且 fine-tuned AutoMage 模型在 GPT-4 和其他类似 LLM 中表现出色。<details>
<summary>Abstract</summary>
The integration of a complex set of Electronic Design Automation (EDA) tools to enhance interoperability is a critical concern for circuit designers. Recent advancements in large language models (LLMs) have showcased their exceptional capabilities in natural language processing and comprehension, offering a novel approach to interfacing with EDA tools. This research paper introduces ChatEDA, an autonomous agent for EDA empowered by a large language model, AutoMage, complemented by EDA tools serving as executors. ChatEDA streamlines the design flow from the Register-Transfer Level (RTL) to the Graphic Data System Version II (GDSII) by effectively managing task planning, script generation, and task execution. Through comprehensive experimental evaluations, ChatEDA has demonstrated its proficiency in handling diverse requirements, and our fine-tuned AutoMage model has exhibited superior performance compared to GPT-4 and other similar LLMs.
</details>
<details>
<summary>摘要</summary>
electronic design automation (EDA) 工具集成是电路设计师面临的一个关键问题。近年来，大型自然语言模型（LLM）的发展受到了关注，因为它们在自然语言处理和理解方面表现出了出色的能力，这提供了一种新的方法来与 EDA 工具进行交互。本研讨稿介绍了 ChatEDA，一个基于大型自然语言模型 AutoMage 的自主代理人，与 EDA 工具合作来实现从Register-Transfer Level (RTL) 到 Graphic Data System Version II (GDSII) 的设计流程的自动化。通过全面的实验评估，ChatEDA 已经证明了它在处理多样化的需求方面的能力，而我们精心调整的 AutoMage 模型则与 GPT-4 和其他类似的 LLM 相比，表现出了更高的性能。
</details></li>
</ul>
<hr>
<h2 id="Soft-Decomposed-Policy-Critic-Bridging-the-Gap-for-Effective-Continuous-Control-with-Discrete-RL"><a href="#Soft-Decomposed-Policy-Critic-Bridging-the-Gap-for-Effective-Continuous-Control-with-Discrete-RL" class="headerlink" title="Soft Decomposed Policy-Critic: Bridging the Gap for Effective Continuous Control with Discrete RL"></a>Soft Decomposed Policy-Critic: Bridging the Gap for Effective Continuous Control with Discrete RL</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10203">http://arxiv.org/abs/2308.10203</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yechen Zhang, Jian Sun, Gang Wang, Zhuo Li, Wei Chen</li>
<li>For: The paper aims to address the challenges of applying discrete reinforcement learning (RL) algorithms to continuous control problems, and to develop a novel architecture that can effectively overcome these challenges.* Methods: The paper proposes the Soft Decomposed Policy-Critic (SDPC) architecture, which combines soft RL and actor-critic techniques with discrete RL methods. The SDPC architecture discretizes each action dimension independently and employs a shared critic network to maximize the soft $Q$-function. The paper also introduces two types of policies: decomposed actors that lead to the Soft Decomposed Actor-Critic (SDAC) algorithm, and decomposed $Q$-networks that generate Boltzmann soft exploration policies, resulting in the Soft Decomposed-Critic Q (SDCQ) algorithm.* Results: The paper presents extensive experimental results that demonstrate the effectiveness of the proposed SDPC architecture in addressing the challenges associated with continuous control. The results show that the SDPC algorithm outperforms state-of-the-art continuous RL algorithms in a variety of continuous control tasks, including Mujoco’s Humanoid and Box2d’s BipedalWalker.Here is the simplified Chinese text for the three key points:* 用途: 本文旨在解决离散RL算法应用到连续控制问题时存在的挑战，并提出一种新的架构来有效地解决这些挑战。* 方法: 本文提出了软分解策略评估器（SDPC）架构，它结合软RL和演员评估技术，并将离散RL方法应用到连续控制问题中。SDPC将每个动作维度独立地分解，并使用共享评估器网络来最大化软$Q$-函数。这种新的方法使得SDPC可以支持两种策略：分解演员，导致Soft Decomposed Actor-Critic（SDAC）算法，以及分解$Q$-网络，生成Boltzmann软探索策略，导致Soft Decomposed-Critic Q（SDCQ）算法。* 结果: 本文提供了广泛的实验结果，证明了SDPC架构在连续控制问题中的效果。结果显示，SDPC算法在Mujoco的人工智能和Box2d的两脚步行器等多个连续控制任务中表现出色，超过了当前最佳连续RL算法的表现。这些实验结果证明了SDPC架构在连续控制问题中的有效性。<details>
<summary>Abstract</summary>
Discrete reinforcement learning (RL) algorithms have demonstrated exceptional performance in solving sequential decision tasks with discrete action spaces, such as Atari games. However, their effectiveness is hindered when applied to continuous control problems due to the challenge of dimensional explosion. In this paper, we present the Soft Decomposed Policy-Critic (SDPC) architecture, which combines soft RL and actor-critic techniques with discrete RL methods to overcome this limitation. SDPC discretizes each action dimension independently and employs a shared critic network to maximize the soft $Q$-function. This novel approach enables SDPC to support two types of policies: decomposed actors that lead to the Soft Decomposed Actor-Critic (SDAC) algorithm, and decomposed $Q$-networks that generate Boltzmann soft exploration policies, resulting in the Soft Decomposed-Critic Q (SDCQ) algorithm. Through extensive experiments, we demonstrate that our proposed approach outperforms state-of-the-art continuous RL algorithms in a variety of continuous control tasks, including Mujoco's Humanoid and Box2d's BipedalWalker. These empirical results validate the effectiveness of the SDPC architecture in addressing the challenges associated with continuous control.
</details>
<details>
<summary>摘要</summary>
离散强化学习（RL）算法在解决顺序决策任务中的离散动作空间上表现出色，如Atari游戏。然而，在连续控制问题上，它们的效果受到维度爆炸的限制。在这篇论文中，我们提出了软分解政策评估器（SDPC）架构，它将离散RL和演示器-评估器技术与离散RL方法结合，以解决这一问题。SDPC独立地离散每个动作维度，并使用共享评估器网络来最大化软$Q$-函数。这种新的方法使得SDPC可以支持两种策略：分解演示者，导致的软分解演示者-评估器（SDAC）算法，以及分解$Q$-网络，生成博尔茨曼软探索策略，导致的软分解评估器Q（SDCQ）算法。通过广泛的实验，我们证明了我们提出的方法在多种连续控制任务中比州场RL算法表现出色，包括Mujoco的人工智能和Box2d的双脚行走器。这些实验结果证明了SDPC架构在连续控制问题上的有效性。
</details></li>
</ul>
<hr>
<h2 id="Deep-Reinforcement-Learning-for-Artificial-Upwelling-Energy-Management"><a href="#Deep-Reinforcement-Learning-for-Artificial-Upwelling-Energy-Management" class="headerlink" title="Deep Reinforcement Learning for Artificial Upwelling Energy Management"></a>Deep Reinforcement Learning for Artificial Upwelling Energy Management</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10199">http://arxiv.org/abs/2308.10199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiyuan Zhang, Wei Fan</li>
<li>for: 本研究旨在提高人工温顺升（AU）系统的效率，以便更好地刺激海藻生长和提高海洋碳储存。</li>
<li>methods: 本研究使用深度强化学习（DRL）算法来开发高效的空气喷射策略，以优化AU系统的运行。</li>
<li>results: 对于 simulate 的数据，我们的DRL算法可以更好地减少能源浪费，同时保证AU系统的稳定和高效运行。<details>
<summary>Abstract</summary>
The potential of artificial upwelling (AU) as a means of lifting nutrient-rich bottom water to the surface, stimulating seaweed growth, and consequently enhancing ocean carbon sequestration, has been gaining increasing attention in recent years. This has led to the development of the first solar-powered and air-lifted AU system (AUS) in China. However, efficient scheduling of air injection systems remains a crucial challenge in operating AUS, as it holds the potential to significantly improve system efficiency. Conventional approaches based on rules or models are often impractical due to the complex and heterogeneous nature of the marine environment and its associated disturbances. To address this challenge, we propose a novel energy management approach that utilizes deep reinforcement learning (DRL) algorithm to develop efficient strategies for operating AUS. Through extensive simulations, we evaluate the performance of our algorithm and demonstrate its superior effectiveness over traditional rule-based approaches and other DRL algorithms in reducing energy wastage while ensuring the stable and efficient operation of AUS. Our findings suggest that a DRL-based approach offers a promising way for improving the efficiency of AUS and enhancing the sustainability of seaweed cultivation and carbon sequestration in the ocean.
</details>
<details>
<summary>摘要</summary>
人们在最近几年内对人工升浮（AU）作为吸引燃料富含底水而升到水面，促进海藻生长，并因此增强海洋碳储存的潜力的可能性已经吸引了越来越多的注意。这导致了中国首个太阳能驱动、空气升降AU系统（AUS）的开发。然而，AU系统的有效的调度仍然是一个关键的挑战，因为它可以大幅提高系统的效率。传统的方法，如规则或模型，经常因为marine环境的复杂和多样性而无法实施。为解决这个挑战，我们提出了一种基于深度强化学习（DRL）算法的能源管理方法。通过广泛的 simulations，我们评估了我们的算法的性能，并证明它在降低能源浪费的同时保证AU系统的稳定和高效运行。我们的发现表明，使用DRL算法可以提高AU系统的效率，并且对海洋藻类培植和碳储存具有扩展性。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Real-time-Path-Planning-with-Self-evolving-Particle-Swarm-Optimization-in-Dynamic-Scenarios"><a href="#Efficient-Real-time-Path-Planning-with-Self-evolving-Particle-Swarm-Optimization-in-Dynamic-Scenarios" class="headerlink" title="Efficient Real-time Path Planning with Self-evolving Particle Swarm Optimization in Dynamic Scenarios"></a>Efficient Real-time Path Planning with Self-evolving Particle Swarm Optimization in Dynamic Scenarios</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10169">http://arxiv.org/abs/2308.10169</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xinjinghao/real-time-path-planning-with-sepso">https://github.com/xinjinghao/real-time-path-planning-with-sepso</a></li>
<li>paper_authors: Jinghao Xin, Zhi Li, Yang Zhang, Ning Li</li>
<li>for: 本研究旨在提高Particle Swarm Optimization（PSO）的计算效率和避免偏差问题，以便应用于动态场景中的路径规划问题。</li>
<li>methods: 本研究提出了一种基于Tensor Operation Form（TOF）的Self-Evolving Particle Swarm Optimization（SEPSO）算法，具有自适应的距离权重补偿和自适应的准则权重补偿，以提高计算效率和避免偏差。</li>
<li>results: 实验结果表明，SEPSO可以在四个常用的优化函数上实现更好的路径规划，并且在动态场景中具有较高的计算效率（每秒67个路径计算）和更好的实时性。<details>
<summary>Abstract</summary>
Particle Swarm Optimization (PSO) has demonstrated efficacy in addressing static path planning problems. Nevertheless, such application on dynamic scenarios has been severely precluded by PSO's low computational efficiency and premature convergence downsides. To address these limitations, we proposed a Tensor Operation Form (TOF) that converts particle-wise manipulations to tensor operations, thereby enhancing computational efficiency. Harnessing the computational advantage of TOF, a variant of PSO, designated as Self-Evolving Particle Swarm Optimization (SEPSO) was developed. The SEPSO is underpinned by a novel Hierarchical Self-Evolving Framework (HSEF) that enables autonomous optimization of its own hyper-parameters to evade premature convergence. Additionally, a Priori Initialization (PI) mechanism and an Auto Truncation (AT) mechanism that substantially elevates the real-time performance of SEPSO on dynamic path planning problems were introduced. Comprehensive experiments on four widely used benchmark optimization functions have been initially conducted to corroborate the validity of SEPSO. Following this, a dynamic simulation environment that encompasses moving start/target points and dynamic/static obstacles was employed to assess the effectiveness of SEPSO on the dynamic path planning problem. Simulation results exhibit that the proposed SEPSO is capable of generating superior paths with considerably better real-time performance (67 path planning computations per second in a regular desktop computer) in contrast to alternative methods. The code of this paper can be accessed here.
</details>
<details>
<summary>摘要</summary>
particle swarm optimization (PSO) 已经在静止路径规划问题上展示了效果。然而，在动态场景下，PSO的计算效率低下和迟速 converges 的缺点限制了其应用。为了解决这些限制，我们提出了一种tensor操作形式（TOF），它将 particle-wise 操作转化为tensor操作，从而提高计算效率。基于TOF的一种PSO变体，称为自适应 particule swarm optimization（SEPSO），在自适应层次结构（HSEF）的支持下，可以自动调整它的自身超参数，以避免迟速 converges。此外，我们还提出了一种先验初始化（PI）机制和一种自动舒缩（AT）机制，这些机制可以大幅提高REPSO在动态路径规划问题上的实时性表现。我们在四个通用优化函数上进行了初步的实验，以证明SEPSO的有效性。然后，我们使用包括移动起点/目标点和动态/静态障碍物的动态 simulations 环境来评估SEPSO在动态路径规划问题上的效果。实验结果显示，提议的SEPSO可以生成优化的路径，并且在实时性方面表现出色（每秒67个路径规划计算在常规桌面电脑上），相比于其他方法。代码可以在这里获取。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Client-Drift-in-Federated-Learning-A-Logit-Perspective"><a href="#Rethinking-Client-Drift-in-Federated-Learning-A-Logit-Perspective" class="headerlink" title="Rethinking Client Drift in Federated Learning: A Logit Perspective"></a>Rethinking Client Drift in Federated Learning: A Logit Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10162">http://arxiv.org/abs/2308.10162</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunlu Yan, Chun-Mei Feng, Mang Ye, Wangmeng Zuo, Ping Li, Rick Siow Mong Goh, Lei Zhu, C. L. Philip Chen</li>
<li>for: 这个论文旨在解决 federated learning (FL) 中 client drift 问题，并提高 FL 的性能。</li>
<li>methods: 本文提出了一个新的 FedCSD 算法，它是一个 federated framework 中的 class prototype similarity distillation 方法，用于将 local 和 global 模型之间的差异调节。</li>
<li>results: 实验结果显示，FedCSD 方法在不同的多元环境下比 state-of-the-art 的 federated learning 方法表现更好，并且可以增强 global 模型的质量。<details>
<summary>Abstract</summary>
Federated Learning (FL) enables multiple clients to collaboratively learn in a distributed way, allowing for privacy protection. However, the real-world non-IID data will lead to client drift which degrades the performance of FL. Interestingly, we find that the difference in logits between the local and global models increases as the model is continuously updated, thus seriously deteriorating FL performance. This is mainly due to catastrophic forgetting caused by data heterogeneity between clients. To alleviate this problem, we propose a new algorithm, named FedCSD, a Class prototype Similarity Distillation in a federated framework to align the local and global models. FedCSD does not simply transfer global knowledge to local clients, as an undertrained global model cannot provide reliable knowledge, i.e., class similarity information, and its wrong soft labels will mislead the optimization of local models. Concretely, FedCSD introduces a class prototype similarity distillation to align the local logits with the refined global logits that are weighted by the similarity between local logits and the global prototype. To enhance the quality of global logits, FedCSD adopts an adaptive mask to filter out the terrible soft labels of the global models, thereby preventing them to mislead local optimization. Extensive experiments demonstrate the superiority of our method over the state-of-the-art federated learning approaches in various heterogeneous settings. The source code will be released.
</details>
<details>
<summary>摘要</summary>
联合学习（FL）允许多个客户端共同学习，以保护隐私。但是，实际世界中的非相同数据将导致客户端的漂移，严重损害FL的性能。可是，我们发现在模型不断更新时，本地和全球模型之间的差异将逐渐增加，严重损害FL的性能。这主要是由于资料不均衡引起的严重遗忘，导致本地模型的优化失败。为解决这问题，我们提出了一个新的算法，名为FedCSD，它是一个基于联合架构的类型对应对数据分析方法。FedCSD不仅将全球知识转移到本地客户端，因为一个尚未训练的全球模型无法提供可靠的知识，即类型对应信息，而且其对应的软件标签将会误导本地优化。具体来说，FedCSD引入一个类型对应对数据分析来调整本地値值和重新调整的全球値值，并运用适应mask来筛选全球模型的差异软件标签，以避免它们误导本地优化。实际实验表明我们的方法在多种不同设定下表现出色，与现有的联合学习方法相比。我们将发布源代码。
</details></li>
</ul>
<hr>
<h2 id="SSMG-Spatial-Semantic-Map-Guided-Diffusion-Model-for-Free-form-Layout-to-Image-Generation"><a href="#SSMG-Spatial-Semantic-Map-Guided-Diffusion-Model-for-Free-form-Layout-to-Image-Generation" class="headerlink" title="SSMG: Spatial-Semantic Map Guided Diffusion Model for Free-form Layout-to-Image Generation"></a>SSMG: Spatial-Semantic Map Guided Diffusion Model for Free-form Layout-to-Image Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10156">http://arxiv.org/abs/2308.10156</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengyou Jia, Minnan Luo, Zhuohang Dang, Guang Dai, Xiaojun Chang, Mengmeng Wang, Jingdong Wang</li>
<li>for: 该 paper  targets 提高 Text-to-Image (T2I) 生成模型的细节控制能力，具体来说是通过 Layout-to-Image (L2I) 生成模型，从用户指定的布局信息中提取更多的空间和semantic信息，以提高生成的图像质量和控制性。</li>
<li>methods: 该 paper 提出了一种新的 Spatial-Semantic Map Guided (SSMG) 扩散模型，通过使用布局信息中的特征图来为生成过程提供指导，以获得更高质量和更多的控制性。此外，paper 还提出了 Relation-Sensitive Attention (RSA) 和 Location-Sensitive Attention (LSA) 机制，用于模型多对多对象之间的关系和空间信息。</li>
<li>results: EXTENSIVE experiments 表明，SSMG 可以 achieve highly promising results，在多个维度上（包括准确率、多样性和控制性）超越前一代的模型。<details>
<summary>Abstract</summary>
Despite significant progress in Text-to-Image (T2I) generative models, even lengthy and complex text descriptions still struggle to convey detailed controls. In contrast, Layout-to-Image (L2I) generation, aiming to generate realistic and complex scene images from user-specified layouts, has risen to prominence. However, existing methods transform layout information into tokens or RGB images for conditional control in the generative process, leading to insufficient spatial and semantic controllability of individual instances. To address these limitations, we propose a novel Spatial-Semantic Map Guided (SSMG) diffusion model that adopts the feature map, derived from the layout, as guidance. Owing to rich spatial and semantic information encapsulated in well-designed feature maps, SSMG achieves superior generation quality with sufficient spatial and semantic controllability compared to previous works. Additionally, we propose the Relation-Sensitive Attention (RSA) and Location-Sensitive Attention (LSA) mechanisms. The former aims to model the relationships among multiple objects within scenes while the latter is designed to heighten the model's sensitivity to the spatial information embedded in the guidance. Extensive experiments demonstrate that SSMG achieves highly promising results, setting a new state-of-the-art across a range of metrics encompassing fidelity, diversity, and controllability.
</details>
<details>
<summary>摘要</summary>
尽管文本到图像（T2I）生成模型已经取得了重要进展，但是也有许多长度和复杂度的文本描述仍然很难以传递细致的控制。相比之下，图像排版到图像（L2I）生成，它的目标是从用户指定的排版中生成真实和复杂的场景图像，在过程中获得了更多的焦点。然而，现有的方法将排版信息转换为token或RGB图像，用于conditional控制生成过程中，导致个体实例的空间和semantic控制不充分。为了解决这些局限性，我们提出了一种新的空间semantic映射指南（SSMG）扩散模型，该模型采用由排版 derivation 的特征图进行导航。由于特征图具有较好的设计，它们可以储存大量的空间和semantic信息，因此SSMG在生成质量和控制方面达到了前所未有的水平。此外，我们还提出了关系敏感注意力（RSA）和位置敏感注意力（LSA）机制。前者用于模型场景中的物体之间的关系，而后者是为了增强模型对空间信息的敏感度。经验证明，SSMG在多个维度上达到了非常出色的结果，创造了新的state-of-the-art。
</details></li>
</ul>
<hr>
<h2 id="Federated-Pseudo-Modality-Generation-for-Incomplete-Multi-Modal-MRI-Reconstruction"><a href="#Federated-Pseudo-Modality-Generation-for-Incomplete-Multi-Modal-MRI-Reconstruction" class="headerlink" title="Federated Pseudo Modality Generation for Incomplete Multi-Modal MRI Reconstruction"></a>Federated Pseudo Modality Generation for Incomplete Multi-Modal MRI Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10910">http://arxiv.org/abs/2308.10910</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunlu Yan, Chun-Mei Feng, Yuexiang Li, Rick Siow Mong Goh, Lei Zhu</li>
<li>for:  addresses the missing modality challenge in federated multi-modal MRI reconstruction.</li>
<li>methods:  utilizes a pseudo modality generation mechanism to recover the missing modality for each single-modal client by sharing the distribution information of the amplitude spectrum in frequency space, and introduces a clustering scheme to reduce communication costs.</li>
<li>results:  can effectively complete the missing modality within an acceptable communication cost, and attains similar performance with the ideal scenario.<details>
<summary>Abstract</summary>
While multi-modal learning has been widely used for MRI reconstruction, it relies on paired multi-modal data which is difficult to acquire in real clinical scenarios. Especially in the federated setting, the common situation is that several medical institutions only have single-modal data, termed the modality missing issue. Therefore, it is infeasible to deploy a standard federated learning framework in such conditions. In this paper, we propose a novel communication-efficient federated learning framework, namely Fed-PMG, to address the missing modality challenge in federated multi-modal MRI reconstruction. Specifically, we utilize a pseudo modality generation mechanism to recover the missing modality for each single-modal client by sharing the distribution information of the amplitude spectrum in frequency space. However, the step of sharing the original amplitude spectrum leads to heavy communication costs. To reduce the communication cost, we introduce a clustering scheme to project the set of amplitude spectrum into finite cluster centroids, and share them among the clients. With such an elaborate design, our approach can effectively complete the missing modality within an acceptable communication cost. Extensive experiments demonstrate that our proposed method can attain similar performance with the ideal scenario, i.e., all clients have the full set of modalities. The source code will be released.
</details>
<details>
<summary>摘要</summary>
多Modal学习已经广泛应用于MRI重建，但它需要对配对多Modal数据进行学习，这在实际临床场景中很Difficult to obtain.特别是在联合设定下，许多医疗机构只有单Modal数据，称为模式缺失问题。因此，在这种情况下不可能采用标准的联合学习框架。在这篇论文中，我们提出一种新的通信效率高的联合学习框架，即Fed-PMG，用于解决联合多Modal MRI重建中的模式缺失问题。特别是，我们利用pseudo模式生成机制来恢复每个单Modal客户端缺失的模式。然而，将原始振荡谱分享给客户端会导致重大的通信成本。为了降低通信成本，我们引入一种分区 schemes，将振荡谱Project到finite的中心点集中，然后将其分享给客户端。与此棋子的设计，我们的方法可以效果地完成缺失模式，并且在可接受的通信成本下完成。广泛的实验表明，我们提出的方法可以达到与理想情况相同的性能，即所有客户端都有完整的模式。源代码将会发布。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Fairness-in-Large-Language-Models"><a href="#A-Survey-on-Fairness-in-Large-Language-Models" class="headerlink" title="A Survey on Fairness in Large Language Models"></a>A Survey on Fairness in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10149">http://arxiv.org/abs/2308.10149</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yingji Li, Mengnan Du, Rui Song, Xin Wang, Ying Wang</li>
<li>for: 本文旨在概述关于LLM中公平性的相关研究，包括中等规模LLM的评估指标和降低偏见方法，以及大规模LLM的公平性研究。</li>
<li>methods: 本文介绍了对LLM中偏见的评估指标和降低偏见方法，包括内在偏见和外在偏见的评估指标和方法。</li>
<li>results: 本文总结了大规模LLM的公平性研究，包括偏见评估、偏见原因和降低偏见方法。同时，文章还提供了对LLM公平性发展的未来方向和挑战。<details>
<summary>Abstract</summary>
Large language models (LLMs) have shown powerful performance and development prospect and are widely deployed in the real world. However, LLMs can capture social biases from unprocessed training data and propagate the biases to downstream tasks. Unfair LLM systems have undesirable social impacts and potential harms. In this paper, we provide a comprehensive review of related research on fairness in LLMs. First, for medium-scale LLMs, we introduce evaluation metrics and debiasing methods from the perspectives of intrinsic bias and extrinsic bias, respectively. Then, for large-scale LLMs, we introduce recent fairness research, including fairness evaluation, reasons for bias, and debiasing methods. Finally, we discuss and provide insight on the challenges and future directions for the development of fairness in LLMs.
</details>
<details>
<summary>摘要</summary>
For medium-scale LLMs, we introduce evaluation metrics and debiasing methods from two perspectives: intrinsic bias and extrinsic bias. Then, for large-scale LLMs, we discuss recent fairness research, including fairness evaluation, reasons for bias, and debiasing methods. Finally, we discuss the challenges and future directions for developing fairness in LLMs.
</details></li>
</ul>
<hr>
<h2 id="ExpeL-LLM-Agents-Are-Experiential-Learners"><a href="#ExpeL-LLM-Agents-Are-Experiential-Learners" class="headerlink" title="ExpeL: LLM Agents Are Experiential Learners"></a>ExpeL: LLM Agents Are Experiential Learners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10144">http://arxiv.org/abs/2308.10144</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Andrewzh112/ExpeL">https://github.com/Andrewzh112/ExpeL</a></li>
<li>paper_authors: Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, Gao Huang</li>
<li>for: 这paper的目的是提出一种新的语言模型，用于自动学习和做出决策。</li>
<li>methods: 该paper使用的方法包括自然语言处理和机器学习技术，以EXTRACT知识和经验从训练任务中。</li>
<li>results:  experiments show that the proposed ExpeL agent exhibits robust learning efficacy and consistently enhances its performance as it accumulates experiences. Additionally, the paper explores the emerging capabilities and transfer learning potential of the ExpeL agent through qualitative observations and additional experiments.<details>
<summary>Abstract</summary>
The recent surge in research interest in applying large language models (LLMs) to decision-making tasks has flourished by leveraging the extensive world knowledge embedded in LLMs. While there is a growing demand to tailor LLMs for custom decision-making tasks, finetuning them for specific tasks is resource-intensive and may diminish the model's generalization capabilities. Moreover, state-of-the-art language models like GPT-4 and Claude are primarily accessible through API calls, with their parametric weights remaining proprietary and unavailable to the public. This scenario emphasizes the growing need for new methodologies that allow learning from agent experiences without requiring parametric updates. To address these problems, we introduce the Experiential Learning (ExpeL) agent. Our agent autonomously gathers experiences and extracts knowledge using natural language from a collection of training tasks. At inference, the agent recalls its extracted insights and past experiences to make informed decisions. Our empirical results highlight the robust learning efficacy of the ExpeL agent, indicating a consistent enhancement in its performance as it accumulates experiences. We further explore the emerging capabilities and transfer learning potential of the ExpeL agent through qualitative observations and additional experiments.
</details>
<details>
<summary>摘要</summary>
近些年，巨型语言模型（LLM）在决策任务上的研究兴趣呈现出了激增趋势，通过利用 LLM 中嵌入的广泛世界知识来实现。然而，为特定任务进行训练和优化 LLM 可能会占用资源，同时可能会降低模型的通用化能力。另外，当前的语言模型如 GPT-4 和 Claude 通常通过 API 调用来提供，其参数权重则是商业秘密，不可公开。这种情况强调了需要新的方法来学习从代理体验中。为解决这些问题，我们介绍了经验学（ExpeL）代理人。我们的代理人可以自动从训练任务中收集经验，使用自然语言提取知识。在推理时，代理人可以回忆提取的洞察和过去经验，做出 Informed 决策。我们的实验结果表明，ExpeL 代理人的学习效果是稳定和可靠的，其性能随着经验的增加而提高。我们还通过观察和其他实验进行资深探索，探讨 ExpeL 代理人的出现的能力和转移学习潜力。
</details></li>
</ul>
<hr>
<h2 id="A-Review-on-Objective-Driven-Artificial-Intelligence"><a href="#A-Review-on-Objective-Driven-Artificial-Intelligence" class="headerlink" title="A Review on Objective-Driven Artificial Intelligence"></a>A Review on Objective-Driven Artificial Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10135">http://arxiv.org/abs/2308.10135</a></li>
<li>repo_url: None</li>
<li>paper_authors: Apoorv Singh</li>
<li>For: The paper aims to address the limitations of current AI technologies in understanding context, nuances, and subtle cues in communication, and to close the gap between human and machine intelligence.* Methods: The paper reviews prospective Machine Intelligence candidates, including hierarchical planning-based approaches, energy-based, latent-variable methods, and joint embedding predictive architecture methods.* Results: The paper discusses how these methods can help machines better understand context, make logical inferences, and predict outcomes in various situations, ultimately bridging the gap between human and machine intelligence.Here’s the information in Simplified Chinese text:</li>
<li>for: 本文目标是解决当前人工智能技术中对语言上的上下文、细节和含义的理解 limitation, 以及将人工智能与人类智能之间的差距缩小。</li>
<li>methods: 本文评论了可能的机器智能候选人，包括层次规划基本方法、能量基本方法、隐变量方法和共同嵌入预测建筑方法。</li>
<li>results: 本文讲述了这些方法如何帮助机器更好地理解上下文, 做出逻辑推理, 预测结果等，从而bridging人工智能与人类智能之间的差距。<details>
<summary>Abstract</summary>
While advancing rapidly, Artificial Intelligence still falls short of human intelligence in several key aspects due to inherent limitations in current AI technologies and our understanding of cognition. Humans have an innate ability to understand context, nuances, and subtle cues in communication, which allows us to comprehend jokes, sarcasm, and metaphors. Machines struggle to interpret such contextual information accurately. Humans possess a vast repository of common-sense knowledge that helps us make logical inferences and predictions about the world. Machines lack this innate understanding and often struggle with making sense of situations that humans find trivial. In this article, we review the prospective Machine Intelligence candidates, a review from Prof. Yann LeCun, and other work that can help close this gap between human and machine intelligence. Specifically, we talk about what's lacking with the current AI techniques such as supervised learning, reinforcement learning, self-supervised learning, etc. Then we show how Hierarchical planning-based approaches can help us close that gap and deep-dive into energy-based, latent-variable methods and Joint embedding predictive architecture methods.
</details>
<details>
<summary>摘要</summary>
In this article, we review prospective Machine Intelligence candidates, a review from Prof. Yann LeCun, and other work that can help close the gap between human and machine intelligence. Specifically, we discuss what's lacking with current AI techniques such as supervised learning, reinforcement learning, self-supervised learning, etc. Then, we show how Hierarchical planning-based approaches can help close that gap and deep-dive into energy-based, latent-variable methods and Joint embedding predictive architecture methods.
</details></li>
</ul>
<hr>
<h2 id="TransFace-Calibrating-Transformer-Training-for-Face-Recognition-from-a-Data-Centric-Perspective"><a href="#TransFace-Calibrating-Transformer-Training-for-Face-Recognition-from-a-Data-Centric-Perspective" class="headerlink" title="TransFace: Calibrating Transformer Training for Face Recognition from a Data-Centric Perspective"></a>TransFace: Calibrating Transformer Training for Face Recognition from a Data-Centric Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10133">http://arxiv.org/abs/2308.10133</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/danjun6737/transface">https://github.com/danjun6737/transface</a></li>
<li>paper_authors: Jun Dan, Yang Liu, Haoyu Xie, Jiankang Deng, Haoran Xie, Xuansong Xie, Baigui Sun</li>
<li>for: 这篇论文主要应用于面Recognition (FR) 任务中，以优化ViTs-based FR 模型的性能。</li>
<li>methods: 本论文提出了一个名为 TransFace 的FR模型，使用了一种名为 DPAP 的 patch-level 数据增强策略和一种名为 EHSM 的困难样本挑战策略。DPAP 会随机对主要 patches 进行振荡变化，以扩大样本多样性，使ViTs 减少遗传学的问题。EHSM 使用了本地征别的信息熵来动态调整训练中的重要性负载，导致更稳定的预测。</li>
<li>results: 实验结果显示，TransFace 可以在多个 Benchmark 上超越原有的 FR 模型。<details>
<summary>Abstract</summary>
Vision Transformers (ViTs) have demonstrated powerful representation ability in various visual tasks thanks to their intrinsic data-hungry nature. However, we unexpectedly find that ViTs perform vulnerably when applied to face recognition (FR) scenarios with extremely large datasets. We investigate the reasons for this phenomenon and discover that the existing data augmentation approach and hard sample mining strategy are incompatible with ViTs-based FR backbone due to the lack of tailored consideration on preserving face structural information and leveraging each local token information. To remedy these problems, this paper proposes a superior FR model called TransFace, which employs a patch-level data augmentation strategy named DPAP and a hard sample mining strategy named EHSM. Specially, DPAP randomly perturbs the amplitude information of dominant patches to expand sample diversity, which effectively alleviates the overfitting problem in ViTs. EHSM utilizes the information entropy in the local tokens to dynamically adjust the importance weight of easy and hard samples during training, leading to a more stable prediction. Experiments on several benchmarks demonstrate the superiority of our TransFace. Code and models are available at https://github.com/DanJun6737/TransFace.
</details>
<details>
<summary>摘要</summary>
vision transformers (vits) 有 demonstrated 强大的表示能力 在不同的视觉任务中，归功于它们的内在的数据吃虫性。然而，我们意外地发现，当应用于人脸认知（FR）场景时，vits 表现弱化了。我们调查了这种现象的原因，发现现有的数据增强方法和困难样本挖掘策略与 vits-based FR 脊梁不兼容，这是因为缺乏适应保持人脸结构信息和利用每个本地 токен信息的考虑。为了解决这些问题，本文提出了一种超越 FR 模型，即 TransFace，该模型使用了 patch-level 数据增强策略名为 DPAP 和一种困难样本挖掘策略名为 EHSM。具体来说，DPAP 随机地对主导的 patches 进行扰动，以扩大样本多样性，从而解决 vits 中的过拟合问题。EHSM 利用了本地 токен中的信息熵来动态调整训练期间的重要性Weight，导致更稳定的预测。我们在多个 benchmark 上进行了实验，并证明了 TransFace 的优越性。代码和模型可以在 <https://github.com/DanJun6737/TransFace> 上获取。
</details></li>
</ul>
<hr>
<h2 id="3D-Aware-Neural-Body-Fitting-for-Occlusion-Robust-3D-Human-Pose-Estimation"><a href="#3D-Aware-Neural-Body-Fitting-for-Occlusion-Robust-3D-Human-Pose-Estimation" class="headerlink" title="3D-Aware Neural Body Fitting for Occlusion Robust 3D Human Pose Estimation"></a>3D-Aware Neural Body Fitting for Occlusion Robust 3D Human Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10123">http://arxiv.org/abs/2308.10123</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/edz-o/3dnbf">https://github.com/edz-o/3dnbf</a></li>
<li>paper_authors: Yi Zhang, Pengliang Ji, Angtian Wang, Jieru Mei, Adam Kortylewski, Alan Yuille</li>
<li>for: 3D human pose estimation with occlusion robustness</li>
<li>methods: 3D-aware Neural Body Fitting (3DNBF) with generative model of deep features and contrastive learning</li>
<li>results: outperforms other approaches on both occluded and standard benchmarks<details>
<summary>Abstract</summary>
Regression-based methods for 3D human pose estimation directly predict the 3D pose parameters from a 2D image using deep networks. While achieving state-of-the-art performance on standard benchmarks, their performance degrades under occlusion. In contrast, optimization-based methods fit a parametric body model to 2D features in an iterative manner. The localized reconstruction loss can potentially make them robust to occlusion, but they suffer from the 2D-3D ambiguity.   Motivated by the recent success of generative models in rigid object pose estimation, we propose 3D-aware Neural Body Fitting (3DNBF) - an approximate analysis-by-synthesis approach to 3D human pose estimation with SOTA performance and occlusion robustness. In particular, we propose a generative model of deep features based on a volumetric human representation with Gaussian ellipsoidal kernels emitting 3D pose-dependent feature vectors. The neural features are trained with contrastive learning to become 3D-aware and hence to overcome the 2D-3D ambiguity.   Experiments show that 3DNBF outperforms other approaches on both occluded and standard benchmarks. Code is available at https://github.com/edz-o/3DNBF
</details>
<details>
<summary>摘要</summary>
“复复基于方法用深度网络估计3D人姿 Parameters directly from a 2D image。尽管在标准 benchmark 上达到了现有的州首性表现，但它们在 occlusion 情况下表现不佳。相反，优化基于方法将 parametric body model 适束到 2D 特征，并且使用局部重建损失可能对 occlusion 有优化作用，但它们受到 2D-3D 歧义的影响。”“驱动 motivated by the recent success of generative models in rigid object pose estimation, we propose 3D-aware Neural Body Fitting (3DNBF) - an approximate analysis-by-synthesis approach to 3D human pose estimation with SOTA performance and occlusion robustness。 Specifically, we propose a generative model of deep features based on a volumetric human representation with Gaussian ellipsoidal kernels emitting 3D pose-dependent feature vectors。 The neural features are trained with contrastive learning to become 3D-aware and hence to overcome the 2D-3D ambiguity。”“实验结果显示，3DNBF 比其他方法在 occluded 和标准 benchmark 上表现更好。代码可以在 https://github.com/edz-o/3DNBF 上取得。”
</details></li>
</ul>
<hr>
<h2 id="Robust-Mixture-of-Expert-Training-for-Convolutional-Neural-Networks"><a href="#Robust-Mixture-of-Expert-Training-for-Convolutional-Neural-Networks" class="headerlink" title="Robust Mixture-of-Expert Training for Convolutional Neural Networks"></a>Robust Mixture-of-Expert Training for Convolutional Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10110">http://arxiv.org/abs/2308.10110</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/optml-group/robust-moe-cnn">https://github.com/optml-group/robust-moe-cnn</a></li>
<li>paper_authors: Yihua Zhang, Ruisi Cai, Tianlong Chen, Guanhua Zhang, Huan Zhang, Pin-Yu Chen, Shiyu Chang, Zhangyang Wang, Sijia Liu<br>for: 这个论文旨在探讨如何使用 Mixture of Expert (MoE) 进行 adversarial robustness 的 CNN 模型。methods: 该论文使用了 adversarial training (AT) 机制，并分析了 MoE 模型中的两个维度：路由器的稳定性和专家的稳定性。它还提出了一种新的 router-expert alternating Adversarial training 框架，以提高 MoE 模型的 adversarial robustness。results: 该论文的实验结果表明，AdvMoE 可以在 4 种常用的 CNN 模型架构和 4 个 benchmark 数据集上提高 adversarial robustness 1% ~ 4%，同时保持了 MoE 模型的效率优势，实现了 более чем 50% 的计算成本减少。<details>
<summary>Abstract</summary>
Sparsely-gated Mixture of Expert (MoE), an emerging deep model architecture, has demonstrated a great promise to enable high-accuracy and ultra-efficient model inference. Despite the growing popularity of MoE, little work investigated its potential to advance convolutional neural networks (CNNs), especially in the plane of adversarial robustness. Since the lack of robustness has become one of the main hurdles for CNNs, in this paper we ask: How to adversarially robustify a CNN-based MoE model? Can we robustly train it like an ordinary CNN model? Our pilot study shows that the conventional adversarial training (AT) mechanism (developed for vanilla CNNs) no longer remains effective to robustify an MoE-CNN. To better understand this phenomenon, we dissect the robustness of an MoE-CNN into two dimensions: Robustness of routers (i.e., gating functions to select data-specific experts) and robustness of experts (i.e., the router-guided pathways defined by the subnetworks of the backbone CNN). Our analyses show that routers and experts are hard to adapt to each other in the vanilla AT. Thus, we propose a new router-expert alternating Adversarial training framework for MoE, termed AdvMoE. The effectiveness of our proposal is justified across 4 commonly-used CNN model architectures over 4 benchmark datasets. We find that AdvMoE achieves 1% ~ 4% adversarial robustness improvement over the original dense CNN, and enjoys the efficiency merit of sparsity-gated MoE, leading to more than 50% inference cost reduction. Codes are available at https://github.com/OPTML-Group/Robust-MoE-CNN.
</details>
<details>
<summary>摘要</summary>
“罕见的 Mixture of Expert（MoE）模型架构，已经表现出高精度和高效的模型推理承诺。尽管MoE在推理领域受到广泛关注，但是对于它在卷积神经网络（CNN）领域的潜在应用还有很少的研究。在这篇论文中，我们问：如何使一个基于MoE的CNN模型具有鲁棒性？可以如何针对这个问题进行鲁棒训练？我们的初步研究表明，对于MoE-CNN模型，使用传统的鲁棒训练机制（开发为普通的CNN模型）不再有效。为了更好地理解这种现象，我们分析了MoE-CNN模型的鲁棒性的两个维度：路由器（即选择数据特定专家的闭包函数）的鲁棒性和专家（即路由器引导的卷积神经网络的子网络）的鲁棒性。我们的分析表明，路由器和专家在传统的鲁棒训练中很难相互适应。因此，我们提出了一种新的路由器-专家 alternate adversarial training框架，称为AdvMoE。我们的提案的效果被证明在4种常用的CNN模型架构和4个标准数据集上，与原始密集CNN模型相比，AdvMoE可以提高1%～4%的鲁棒性表现，同时保留了MoE的稀疏性优势，实现了More than 50%的推理成本减少。代码可以在https://github.com/OPTML-Group/Robust-MoE-CNN上下载。”
</details></li>
</ul>
<hr>
<h2 id="ASPIRE-Language-Guided-Augmentation-for-Robust-Image-Classification"><a href="#ASPIRE-Language-Guided-Augmentation-for-Robust-Image-Classification" class="headerlink" title="ASPIRE: Language-Guided Augmentation for Robust Image Classification"></a>ASPIRE: Language-Guided Augmentation for Robust Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10103">http://arxiv.org/abs/2308.10103</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sreyan Ghosh, Chandra Kiran Reddy Evuru, Sonal Kumar, Utkarsh Tyagi, Sakshi Singh, Sanjoy Chowdhury, Dinesh Manocha</li>
<li>for: 本研究旨在提高神经图像分类器在真实世界中的表现，使其能够更好地适应不同的场景和数据。</li>
<li>methods: 本研究使用了一种名为ASPIRE的简单 yet有效的解决方案，通过在训练集中添加语言指导的数据增强来减少对不相关的特征的依赖。</li>
<li>results: 研究表明，使用ASPIRE可以提高神经图像分类器的分类精度，在4个dataset上与9个基线方法进行比较，分别提高精度by 1%-38%.<details>
<summary>Abstract</summary>
Neural image classifiers can often learn to make predictions by overly relying on non-predictive features that are spuriously correlated with the class labels in the training data. This leads to poor performance in real-world atypical scenarios where such features are absent. Supplementing the training dataset with images without such spurious features can aid robust learning against spurious correlations via better generalization. This paper presents ASPIRE (Language-guided data Augmentation for SPurIous correlation REmoval), a simple yet effective solution for expanding the training dataset with synthetic images without spurious features. ASPIRE, guided by language, generates these images without requiring any form of additional supervision or existing examples. Precisely, we employ LLMs to first extract foreground and background features from textual descriptions of an image, followed by advanced language-guided image editing to discover the features that are spuriously correlated with the class label. Finally, we personalize a text-to-image generation model to generate diverse in-domain images without spurious features. We demonstrate the effectiveness of ASPIRE on 4 datasets, including the very challenging Hard ImageNet dataset, and 9 baselines and show that ASPIRE improves the classification accuracy of prior methods by 1% - 38%. Code soon at: https://github.com/Sreyan88/ASPIRE.
</details>
<details>
<summary>摘要</summary>
神经图像分类器可以很容易地学习通过过度依赖不可预测的特征来预测类别标签。这会导致在实际世界中不常见的情况下表现不佳，因为这些特征在真实数据中缺失。补充训练集中的图像可以帮助神经图像分类器学习更加稳健，以避免基于不可预测的特征的欺骗。这篇论文提出了ASPIRE（语言引导数据增强为排除SPurIous correlation的解决方案），它是一种简单而有效的解决方案。ASPIRE，受语言引导，可以生成不需要任何形式的额外监督或现有示例的图像。具体来说，我们使用自然语言处理技术来首先提取图像中的前景和背景特征，然后使用高级语言导向的图像编辑技术来找出与类别标签相关的不可预测特征。最后，我们个性化文本到图像生成模型，以生成具有不可预测特征的域内多样化图像。我们在4个 dataset上进行了测试，包括非常困难的 Hard ImageNet dataset，并与9个基线进行比较，显示ASPIRE可以提高先前方法的分类精度 by 1% - 38%。代码即将在 GitHub 上发布。
</details></li>
</ul>
<hr>
<h2 id="Open-Closed-or-Small-Language-Models-for-Text-Classification"><a href="#Open-Closed-or-Small-Language-Models-for-Text-Classification" class="headerlink" title="Open, Closed, or Small Language Models for Text Classification?"></a>Open, Closed, or Small Language Models for Text Classification?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10092">http://arxiv.org/abs/2308.10092</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Yu, Zachary Yang, Kellin Pelrine, Jean Francois Godbout, Reihaneh Rabbany</li>
<li>for: 这个研究旨在检验三类模型在三种任务上的表现：命名实体识别、政党预测和谣言检测。</li>
<li>methods: 研究使用了八个数据集和三类模型进行评估：开源模型、关闭源模型和生成模型。</li>
<li>results: 研究发现，大型语言模型在多个任务上表现出色，但是开源模型可以与关闭源模型相匹配，而小型模型如RoBERTa在某些数据集上可以达到与生成模型相同或更高的性能。然而，关闭模型在需要最高普遍性的任务中仍保持优势。<details>
<summary>Abstract</summary>
Recent advancements in large language models have demonstrated remarkable capabilities across various NLP tasks. But many questions remain, including whether open-source models match closed ones, why these models excel or struggle with certain tasks, and what types of practical procedures can improve performance. We address these questions in the context of classification by evaluating three classes of models using eight datasets across three distinct tasks: named entity recognition, political party prediction, and misinformation detection. While larger LLMs often lead to improved performance, open-source models can rival their closed-source counterparts by fine-tuning. Moreover, supervised smaller models, like RoBERTa, can achieve similar or even greater performance in many datasets compared to generative LLMs. On the other hand, closed models maintain an advantage in hard tasks that demand the most generalizability. This study underscores the importance of model selection based on task requirements
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="GNNPipe-Accelerating-Distributed-Full-Graph-GNN-Training-with-Pipelined-Model-Parallelism"><a href="#GNNPipe-Accelerating-Distributed-Full-Graph-GNN-Training-with-Pipelined-Model-Parallelism" class="headerlink" title="GNNPipe: Accelerating Distributed Full-Graph GNN Training with Pipelined Model Parallelism"></a>GNNPipe: Accelerating Distributed Full-Graph GNN Training with Pipelined Model Parallelism</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10087">http://arxiv.org/abs/2308.10087</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingji Chen, Zhuoming Chen, Xuehai Qian</li>
<li>for: 本研究 targets at improving the efficiency of distributed full-graph GNN training methods.</li>
<li>methods: 我们提出了一种新的训练方法 named GNNPipe，它采用了模型并行 instead of 图并行，具有较低的最坏情况极限通信复杂度。我们还提出了一种 chunk-based 管道式训练方法，以确保 GPU 资源的高Utilization。</li>
<li>results: 我们的方法可以减少每个epoch的训练时间，并且可以减少通信量和开销。 experiments show that our method reduces the per-epoch training time by up to 2.45x (on average 2.03x) and reduces the communication volume and overhead by up to 22.51x and 27.21x (on average 10.27x and 14.96x), respectively, while achieving a comparable level of model accuracy and convergence speed compared to graph parallelism.<details>
<summary>Abstract</summary>
Current distributed full-graph GNN training methods adopt a variant of data parallelism, namely graph parallelism, in which the whole graph is divided into multiple partitions (subgraphs) and each GPU processes one of them. This incurs high communication overhead because of the inter-partition message passing at each layer. To this end, we proposed a new training method named GNNPipe that adopts model parallelism instead, which has a lower worst-case asymptotic communication complexity than graph parallelism. To ensure high GPU utilization, we proposed to combine model parallelism with a chunk-based pipelined training method, in which each GPU processes a different chunk of graph data at different layers concurrently. We further proposed hybrid parallelism that combines model and graph parallelism when the model-level parallelism is insufficient. We also introduced several tricks to ensure convergence speed and model accuracies to accommodate embedding staleness introduced by pipelining. Extensive experiments show that our method reduces the per-epoch training time by up to 2.45x (on average 2.03x) and reduces the communication volume and overhead by up to 22.51x and 27.21x (on average 10.27x and 14.96x), respectively, while achieving a comparable level of model accuracy and convergence speed compared to graph parallelism.
</details>
<details>
<summary>摘要</summary>
当前的分布式全图GNNS培训方法采用了一种变体的数据并行性，即图并行性，在其中整个图被分成多个分区（子图），每个GPU处理一个分区。这会产生高度的通信开销，因为每层都需要进行交互式的分区消息传递。为了解决这个问题，我们提出了一种新的培训方法，名为GNPipe，它采用了模型并行性，它的最差情况的极限级别的通信复杂度比图并行性低。为保证高效的GPU使用率，我们提出了将模型并行性与 chunk-based 管道式培训方法结合使用，在不同的层次上同时处理不同的图数据块。此外，我们还提出了将模型并行性与图并行性结合使用，当模型级别的并行性不足时。此外，我们还提出了一些技巧来确保快速的整体训练速度和模型精度，以适应嵌入过时引起的管道化。广泛的实验表明，我们的方法可以将每个轮次训练时间减少至最多2.45倍（平均2.03倍），并且可以减少通信量和开销至最多22.51倍和27.21倍（平均10.27倍和14.96倍），而保持与图并行性相比的相似水平的模型精度和训练速度。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Learning-for-Non-Local-Graphs-with-Multi-Resolution-Structural-Views"><a href="#Contrastive-Learning-for-Non-Local-Graphs-with-Multi-Resolution-Structural-Views" class="headerlink" title="Contrastive Learning for Non-Local Graphs with Multi-Resolution Structural Views"></a>Contrastive Learning for Non-Local Graphs with Multi-Resolution Structural Views</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10077">http://arxiv.org/abs/2308.10077</a></li>
<li>repo_url: None</li>
<li>paper_authors: Asif Khan, Amos Storkey</li>
<li>for: 本研究旨在学习不同类型图像之间的相似性，以提高图像检测和蛋白质功能预测等应用。</li>
<li>methods: 我们提出了一种新的多视图对照学习方法，通过对图像进行多种扩充，捕捉到图像之间的结构相似性，从而揭示隐藏的关系和相似性。</li>
<li>results: 我们的方法在synthetic和实际结构数据上比基eline高$16.06%$，$3.27%$和$8.04%$。此外，它在邻近任务上表现优于基eline，说明它可以更好地捕捉结构信息，提高下游应用的性能。<details>
<summary>Abstract</summary>
Learning node-level representations of heterophilic graphs is crucial for various applications, including fraudster detection and protein function prediction. In such graphs, nodes share structural similarity identified by the equivalence of their connectivity which is implicitly encoded in the form of higher-order hierarchical information in the graphs. The contrastive methods are popular choices for learning the representation of nodes in a graph. However, existing contrastive methods struggle to capture higher-order graph structures. To address this limitation, we propose a novel multiview contrastive learning approach that integrates diffusion filters on graphs. By incorporating multiple graph views as augmentations, our method captures the structural equivalence in heterophilic graphs, enabling the discovery of hidden relationships and similarities not apparent in traditional node representations. Our approach outperforms baselines on synthetic and real structural datasets, surpassing the best baseline by $16.06\%$ on Cornell, $3.27\%$ on Texas, and $8.04\%$ on Wisconsin. Additionally, it consistently achieves superior performance on proximal tasks, demonstrating its effectiveness in uncovering structural information and improving downstream applications.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="UniDoc-A-Universal-Large-Multimodal-Model-for-Simultaneous-Text-Detection-Recognition-Spotting-and-Understanding"><a href="#UniDoc-A-Universal-Large-Multimodal-Model-for-Simultaneous-Text-Detection-Recognition-Spotting-and-Understanding" class="headerlink" title="UniDoc: A Universal Large Multimodal Model for Simultaneous Text Detection, Recognition, Spotting and Understanding"></a>UniDoc: A Universal Large Multimodal Model for Simultaneous Text Detection, Recognition, Spotting and Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11592">http://arxiv.org/abs/2308.11592</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Feng, Zijian Wang, Jingqun Tang, Jinghui Lu, Wengang Zhou, Houqiang Li, Can Huang</li>
<li>for: 这 paper 的目的是提出一种新的多Modal模型，能够同时检测、识别和理解文本，以提高文本理解的性能。</li>
<li>methods: 这 paper 使用了 UniDoc 模型，该模型具有文本检测和识别功能，并且可以充分利用大型预训练模型的表示能力和世界知识。此外，UniDoc 还能够充分利用任务之间的有益关系，提高每个任务的性能。</li>
<li>results: 实验结果显示，UniDoc 在多个复杂的 benchmark 上达到了州际纪录级的成绩。这是目前已知的首个同时检测、识别、spotting 和理解的大型多Modal模型。<details>
<summary>Abstract</summary>
In the era of Large Language Models (LLMs), tremendous strides have been made in the field of multimodal understanding. However, existing advanced algorithms are limited to effectively utilizing the immense representation capabilities and rich world knowledge inherent to these large pre-trained models, and the beneficial connections among tasks within the context of text-rich scenarios have not been sufficiently explored. In this work, we introduce UniDoc, a novel multimodal model equipped with text detection and recognition capabilities, which are deficient in existing approaches. Moreover, UniDoc capitalizes on the beneficial interactions among tasks to enhance the performance of each individual task. To implement UniDoc, we perform unified multimodal instruct tuning on the contributed large-scale instruction following datasets. Quantitative and qualitative experimental results show that UniDoc sets state-of-the-art scores across multiple challenging benchmarks. To the best of our knowledge, this is the first large multimodal model capable of simultaneous text detection, recognition, spotting, and understanding.
</details>
<details>
<summary>摘要</summary>
在大语言模型（LLMs）时代，我们在多模式理解领域已经做出了巨大的进步。然而，现有的高级算法尚未能充分利用大型预训练模型中的庞大表示能力和丰富的世界知识，也没有充分探索了在文本丰富场景下任务之间的有利连接。在这项工作中，我们介绍了UniDoc，一种新的多模式模型，具有文本检测和识别功能，现存的方法缺乏这些功能。此外，UniDoc利用任务之间的有利连接来提高每个任务的性能。为实现UniDoc，我们在大规模的 instrucion following 数据集上进行了统一多模式 instru Tuning。量化和质量上的实验结果表明，UniDoc在多个复杂的benchmark上设置了state-of-the-art 得分。据我们所知，这是第一个同时检测、识别、点名和理解的大型多模式模型。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/20/cs.AI_2023_08_20/" data-id="clohum9340033pj889g1c0cbt" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_08_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/20/cs.CL_2023_08_20/" class="article-date">
  <time datetime="2023-08-20T11:00:00.000Z" itemprop="datePublished">2023-08-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/20/cs.CL_2023_08_20/">cs.CL - 2023-08-20</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="CharacterChat-Learning-towards-Conversational-AI-with-Personalized-Social-Support"><a href="#CharacterChat-Learning-towards-Conversational-AI-with-Personalized-Social-Support" class="headerlink" title="CharacterChat: Learning towards Conversational AI with Personalized Social Support"></a>CharacterChat: Learning towards Conversational AI with Personalized Social Support</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10278">http://arxiv.org/abs/2308.10278</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/morecry/characterchat">https://github.com/morecry/characterchat</a></li>
<li>paper_authors: Quan Tu, Chuanqi Chen, Jinpeng Li, Yanran Li, Shuo Shang, Dongyan Zhao, Ran Wang, Rui Yan</li>
<li>for: 提供个性化社交支持</li>
<li>methods: 使用人类类型分解法（MBTI）和虚拟人物银行（MBTI-1024 Bank），开发了一个基于角色和记忆的对话系统（CharacterChat），并实现了人类类型匹配机制，以提供个性化的社交支持</li>
<li>results: 实验结果表明，CharacterChat 可以提供高效的个性化社交支持，并且人类类型匹配机制具有显著的优势。<details>
<summary>Abstract</summary>
In our modern, fast-paced, and interconnected world, the importance of mental well-being has grown into a matter of great urgency. However, traditional methods such as Emotional Support Conversations (ESC) face challenges in effectively addressing a diverse range of individual personalities. In response, we introduce the Social Support Conversation (S2Conv) framework. It comprises a series of support agents and the interpersonal matching mechanism, linking individuals with persona-compatible virtual supporters. Utilizing persona decomposition based on the MBTI (Myers-Briggs Type Indicator), we have created the MBTI-1024 Bank, a group that of virtual characters with distinct profiles. Through improved role-playing prompts with behavior preset and dynamic memory, we facilitate the development of the MBTI-S2Conv dataset, which contains conversations between the characters in the MBTI-1024 Bank. Building upon these foundations, we present CharacterChat, a comprehensive S2Conv system, which includes a conversational model driven by personas and memories, along with an interpersonal matching plugin model that dispatches the optimal supporters from the MBTI-1024 Bank for individuals with specific personas. Empirical results indicate the remarkable efficacy of CharacterChat in providing personalized social support and highlight the substantial advantages derived from interpersonal matching. The source code is available in \url{https://github.com/morecry/CharacterChat}.
</details>
<details>
<summary>摘要</summary>
在我们现代、快速发展、全球连接的世界中，个人心理健康的重要性日益提高。然而，传统的方法如情感支持对话（ESC）面临着困难，因为它们难以满足个人多样化的需求。为此，我们提出了社交支持对话（S2Conv）框架。它包括一系列的支持代理和人际匹配机制，将个人与具有相似人格特质的虚拟支持者联系起来。通过基于MBTI（Myers-Briggs Type Indicator）的人格分解，我们建立了MBTI-1024银行，一组包含具有明确特征的虚拟人物。我们通过改进的角色扮演提示和动态记忆，实现了MBTI-S2Conv数据集的开发，这些对话发生在MBTI-1024银行中。基于这些基础，我们介绍了CharacterChat，一个完整的S2Conv系统，包括驱动角色和记忆的对话模型，以及一个人际匹配插件模型，可以从MBTI-1024银行中派发最佳的支持者 для特定的人格类型。实验结果表明CharacterChat在提供个性化社交支持方面表现出了极高的效果，并且人际匹配带来了显著的优势。代码可以在<https://github.com/morecry/CharacterChat>上获取。
</details></li>
</ul>
<hr>
<h2 id="Scaled-up-Discovery-of-Latent-Concepts-in-Deep-NLP-Models"><a href="#Scaled-up-Discovery-of-Latent-Concepts-in-Deep-NLP-Models" class="headerlink" title="Scaled-up Discovery of Latent Concepts in Deep NLP Models"></a>Scaled-up Discovery of Latent Concepts in Deep NLP Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10263">http://arxiv.org/abs/2308.10263</a></li>
<li>repo_url: None</li>
<li>paper_authors: Majd Hawasly, Fahim Dalvi, Nadir Durrani</li>
<li>for: 这个研究是为了比较不同的聚类算法，以找出预训练语言模型中表示的编码概念。</li>
<li>methods: 这个研究使用了三种聚类算法：聚合 Hierarchical Clustering、Leaders Algorithm 和 K-Means Clustering，以确定它们在 humans 定义的 ontology 上的对应。</li>
<li>results: 研究结果表明，K-Means 算法有可能扩展到非常大的数据集，以获得丰富的干ovat 概念发现，包括单词和短语水平。<details>
<summary>Abstract</summary>
Pre-trained language models (pLMs) learn intricate patterns and contextual dependencies via unsupervised learning on vast text data, driving breakthroughs across NLP tasks. Despite these achievements, these models remain black boxes, necessitating research into understanding their decision-making processes. Recent studies explore representation analysis by clustering latent spaces within pre-trained models. However, these approaches are limited in terms of scalability and the scope of interpretation because of high computation costs of clustering algorithms. This study focuses on comparing clustering algorithms for the purpose of scaling encoded concept discovery of representations from pLMs. Specifically, we compare three algorithms in their capacity to unveil the encoded concepts through their alignment to human-defined ontologies: Agglomerative Hierarchical Clustering, Leaders Algorithm, and K-Means Clustering. Our results show that K-Means has the potential to scale to very large datasets, allowing rich latent concept discovery, both on the word and phrase level.
</details>
<details>
<summary>摘要</summary>
пре-trained语言模型（pLMs）通过自动学习大量文本数据，学习到了复杂的模式和语义依赖关系，导致了各种自然语言处理任务的突破。尽管如此，这些模型仍然是黑盒子，需要研究其决策过程。latest studies explore representation analysis by clustering latent spaces within pre-trained models. However, these approaches are limited in terms of scalability and the scope of interpretation because of high computation costs of clustering algorithms. This study focuses on comparing clustering algorithms for the purpose of scaling encoded concept discovery of representations from pLMs. Specifically, we compare three algorithms in their capacity to unveil the encoded concepts through their alignment to human-defined ontologies: Agglomerative Hierarchical Clustering, Leaders Algorithm, and K-Means Clustering. Our results show that K-Means has the potential to scale to very large datasets, allowing rich latent concept discovery, both on the word and phrase level.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. Traditional Chinese is used in Taiwan, Hong Kong, and other countries.
</details></li>
</ul>
<hr>
<h2 id="How-Good-Are-Large-Language-Models-at-Out-of-Distribution-Detection"><a href="#How-Good-Are-Large-Language-Models-at-Out-of-Distribution-Detection" class="headerlink" title="How Good Are Large Language Models at Out-of-Distribution Detection?"></a>How Good Are Large Language Models at Out-of-Distribution Detection?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10261">http://arxiv.org/abs/2308.10261</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020">https://github.com/chrisneagu/FTC-Skystone-Dark-Angels-Romania-2020</a></li>
<li>paper_authors: Bo Liu, Liming Zhan, Zexin Lu, Yujie Feng, Lei Xue, Xiao-Ming Wu</li>
<li>for: 这个研究探讨了大型自然语言模型（LLM）在不同语言模型中进行Out-of-distribution（OOD）探测的可靠性。</li>
<li>methods: 这个研究使用了各种常见的OOD探测器，并对它们进行了zero-grad和精确调整的评估。此外，研究者还将先前的探测性内部训练改为生成式训练，以更好地适应LLM的预训练目标和下游任务。</li>
<li>results: 研究结果显示，一个简单的径向距离OOD探测器在LLM中表现出色，超越其他OOD探测器。研究者提供了一个新的理解，即LLM的嵌入空间具有iso对称性，这使得LLM更容易探测OOD数据。这个新的理解可以帮助提高LLM的适应力和可靠性在动态环境中。<details>
<summary>Abstract</summary>
Out-of-distribution (OOD) detection plays a vital role in enhancing the reliability of machine learning (ML) models. The emergence of large language models (LLMs) has catalyzed a paradigm shift within the ML community, showcasing their exceptional capabilities across diverse natural language processing tasks. While existing research has probed OOD detection with relative small-scale Transformers like BERT, RoBERTa and GPT-2, the stark differences in scales, pre-training objectives, and inference paradigms call into question the applicability of these findings to LLMs. This paper embarks on a pioneering empirical investigation of OOD detection in the domain of LLMs, focusing on LLaMA series ranging from 7B to 65B in size. We thoroughly evaluate commonly-used OOD detectors, scrutinizing their performance in both zero-grad and fine-tuning scenarios. Notably, we alter previous discriminative in-distribution fine-tuning into generative fine-tuning, aligning the pre-training objective of LLMs with downstream tasks. Our findings unveil that a simple cosine distance OOD detector demonstrates superior efficacy, outperforming other OOD detectors. We provide an intriguing explanation for this phenomenon by highlighting the isotropic nature of the embedding spaces of LLMs, which distinctly contrasts with the anisotropic property observed in smaller BERT family models. The new insight enhances our understanding of how LLMs detect OOD data, thereby enhancing their adaptability and reliability in dynamic environments.
</details>
<details>
<summary>摘要</summary>
大量语言模型（LLM）在机器学习（ML）领域的应用已经促使了一场 Paradigma shift。 existing research 探索了使用小型 transformer  like BERT, RoBERTa 和 GPT-2 的 OOD 检测，但是这些发现的可靠性是否适用于 LLM 仍然存在问题。这篇文章开始了对 LLM 领域 OOD 检测的先锋性实验研究，专注于 LLaMA 系列模型，从 7B 到 65B 的大小。我们仔细评估了常用的 OOD 检测器，在零个 grad 和精度调整两种场景中进行了全面的评估。另外，我们改变了先前的推荐准确预测 OOD 检测器，转换为生成式调整，使得 LLM 的预训练目标与下游任务更加一致。我们的发现表明，一个简单的偏度距离 OOD 检测器在 LLM 中表现出色，超过其他 OOD 检测器。我们提供了一个有趣的解释，强调 LLMA 的均匀空间特性，与小型 BERT 家族模型所见的极性特性不同。这一新发现改善了我们对 LLM 的检测 OOD 数据的理解，从而提高了它们在动态环境中的适应性和可靠性。
</details></li>
</ul>
<hr>
<h2 id="StableLLaVA-Enhanced-Visual-Instruction-Tuning-with-Synthesized-Image-Dialogue-Data"><a href="#StableLLaVA-Enhanced-Visual-Instruction-Tuning-with-Synthesized-Image-Dialogue-Data" class="headerlink" title="StableLLaVA: Enhanced Visual Instruction Tuning with Synthesized Image-Dialogue Data"></a>StableLLaVA: Enhanced Visual Instruction Tuning with Synthesized Image-Dialogue Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10253">http://arxiv.org/abs/2308.10253</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/icoz69/stablellava">https://github.com/icoz69/stablellava</a></li>
<li>paper_authors: Yanda Li, Chi Zhang, Gang Yu, Zhibin Wang, Bin Fu, Guosheng Lin, Chunhua Shen, Ling Chen, Yunchao Wei</li>
<li>for: 研究者们希望通过开发多模态大型语言模型（LLMs）来实现更好地融合文本和视觉模态，并在理解人类指令时进行更好的对接。</li>
<li>methods: 研究者们提出了一种新的数据收集方法，即同步生成图像和对话，以便为视觉指令调整。这种方法利用了生成模型的能力，将文本生成模型和图像生成模型结合起来，以生成多样化和可控的图像数据集。</li>
<li>results: 研究人员对多个数据集进行了广泛的实验，并使用开源的 LLAVA 模型作为测试平台。结果表明，该方法可以提高多达十个常见的能力指标，包括图像生成、对话生成和多模态对接等。<details>
<summary>Abstract</summary>
The remarkable multimodal capabilities demonstrated by OpenAI's GPT-4 have sparked significant interest in the development of multimodal Large Language Models (LLMs). A primary research objective of such models is to align visual and textual modalities effectively while comprehending human instructions. Current methodologies often rely on annotations derived from benchmark datasets to construct image-dialogue datasets for training purposes, akin to instruction tuning in LLMs. However, these datasets often exhibit domain bias, potentially constraining the generative capabilities of the models. In an effort to mitigate these limitations, we propose a novel data collection methodology that synchronously synthesizes images and dialogues for visual instruction tuning. This approach harnesses the power of generative models, marrying the abilities of ChatGPT and text-to-image generative models to yield a diverse and controllable dataset with varied image content. This not only provides greater flexibility compared to existing methodologies but also significantly enhances several model capabilities. Our research includes comprehensive experiments conducted on various datasets using the open-source LLAVA model as a testbed for our proposed pipeline. Our results underscore marked enhancements across more than ten commonly assessed capabilities,
</details>
<details>
<summary>摘要</summary>
“OpenAI的GPT-4的多Modal功能已经引起了很大的关注，导致多Modal大型语言模型（LLM）的开发获得更多的注意。主要研究目标之一是让文字和影像模式有效地调和，并且理解人类的指令。现有的方法ologies往往靠摄取来自测试集的标注来建立图像对话集，类似于执行调整LLMs。但这些数据集 часто会受到领域偏见，这可能对模型的生成能力产生限制。为了解决这些限制，我们提出了一种新的数据收集方法， synchronously 将图像和对话聚合在一起，以便对图像进行调整。这种方法利用了生成模型的能力，结合了ChatGPT和文本到图像生成模型，从而产生了多样化且可控的数据集。这不仅提供了更大的灵活性，而且也对模型的多个功能进行了明显改善。我们的研究包括了对不同数据集进行了广泛的实验，使用了开源的Llava模型作为我们的提案流水线的测试床。我们的结果显示，在多于十种常规评估能力上，我们的方法实现了明显的改善。”
</details></li>
</ul>
<hr>
<h2 id="Activation-Addition-Steering-Language-Models-Without-Optimization"><a href="#Activation-Addition-Steering-Language-Models-Without-Optimization" class="headerlink" title="Activation Addition: Steering Language Models Without Optimization"></a>Activation Addition: Steering Language Models Without Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10248">http://arxiv.org/abs/2308.10248</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex Turner, Lisa Thiergart, David Udell, Gavin Leech, Ulisse Mini, Monte MacDiarmid</li>
<li>for: 控制大型自然语言模型（LLM）的行为是一个当前仍然没有解决的问题。现有的方法包括监督微调、人工回馈学习（RLHF）、提示工程和导航式解码。我们却 investigate activation engineering：在推理时修改激活函数以预测性地改变模型行为。特别是，我们在推理过程中添加一个“导航向量”，这个向量通过自然语言来隐式地定义。</li>
<li>methods: 我们的ActAdd方法不同于过去的工作（Subramani et al. 2022；Hernandez et al. 2023），它不需要学习这些导航向量。而是通过对提示集中的激活差异来计算导航向量。</li>
<li>results: 我们在GPT-2上进行了OpenWebText和ConceptNet的测试，发现我们的推理时间方法可以控制输出的高级属性，并且保持目标模型性能不受影响。这种方法比监督微调或RLHF需要更少的计算和实现努力，允许用户通过自然语言提示来Specify要求，并且其负担随模型大小呈线性增长。<details>
<summary>Abstract</summary>
Reliably controlling the behavior of large language models (LLMs) is a pressing open problem. Existing methods include supervised finetuning, reinforcement learning from human feedback (RLHF), prompt engineering and guided decoding. We instead investigate activation engineering: modifying activations at inference time to predictably alter model behavior. In particular, we bias the forward pass with an added 'steering vector' implicitly specified through natural language.   Unlike past work which learned these steering vectors (Subramani, Suresh, and Peters 2022; Hernandez, Li, and Andreas 2023), our Activation Addition (ActAdd) method computes them by taking the activation differences that result from pairs of prompts. We demonstrate ActAdd on GPT-2 on OpenWebText and ConceptNet. Our inference-time approach yields control over high-level properties of output and preserves off-target model performance. It involves far less compute and implementation effort compared to finetuning or RLHF, allows users to provide natural language specifications, and its overhead scales naturally with model size.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的可靠控制问题是一个开放的问题。现有的方法包括监督微调、人工反馈学习（RLHF）、提示工程和导航解码。我们尝试 investigate 活动工程：在推理时修改活动以predictably 改变模型行为。特别是，我们使用添加的 "导航向量" 隐式地由自然语言特定。与过去的工作不同（Subramani et al. 2022；Hernandez et al. 2023），我们的 Activation Addition（ActAdd）方法不是学习这些导航向量，而是通过对提示的活动差异来计算它们。我们在 GPT-2 上对 OpenWebText 和 ConceptNet 进行了测试，并证明了我们的推理时间方法可以控制输出的高级属性，并保持目标模型性能。它比 finetuning 或 RLHF 需要更少的计算和实现努力，允许用户提供自然语言规范，并且其开销随模型大小呈线性增长。
</details></li>
</ul>
<hr>
<h2 id="Indonesian-Automatic-Speech-Recognition-with-XLSR-53"><a href="#Indonesian-Automatic-Speech-Recognition-with-XLSR-53" class="headerlink" title="Indonesian Automatic Speech Recognition with XLSR-53"></a>Indonesian Automatic Speech Recognition with XLSR-53</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11589">http://arxiv.org/abs/2308.11589</a></li>
<li>repo_url: None</li>
<li>paper_authors: Panji Arisaputra, Amalia Zahra</li>
<li>For: The paper aims to develop an Indonesian Automatic Speech Recognition (ASR) system using the XLSR-53 pre-trained model to reduce the amount of training data required to achieve a competitive Word Error Rate (WER).* Methods: The study uses the XLSR-53 pre-trained model and a combination of three datasets: TITML-IDN, Magic Data, and Common Voice, with a total of 24 hours, 18 minutes, and 1 second of data. The model is further improved using a language model to reduce the WER by around 8%.* Results: The study achieves a WER of 20%, which is competitive with similar models using the Common Voice dataset split test. Additionally, the use of a language model results in a WER of 12%, representing an 8% reduction in error rate. The results demonstrate the effectiveness of the proposed approach in developing a better Indonesian ASR system with a smaller amount of data.<details>
<summary>Abstract</summary>
This study focuses on the development of Indonesian Automatic Speech Recognition (ASR) using the XLSR-53 pre-trained model, the XLSR stands for cross-lingual speech representations. The use of this XLSR-53 pre-trained model is to significantly reduce the amount of training data in non-English languages required to achieve a competitive Word Error Rate (WER). The total amount of data used in this study is 24 hours, 18 minutes, and 1 second: (1) TITML-IDN 14 hours and 31 minutes; (2) Magic Data 3 hours and 33 minutes; and (3) Common Voice 6 hours, 14 minutes, and 1 second. With a WER of 20%, the model built in this study can compete with similar models using the Common Voice dataset split test. WER can be decreased by around 8% using a language model, resulted in WER from 20% to 12%. Thus, the results of this study have succeeded in perfecting previous research in contributing to the creation of a better Indonesian ASR with a smaller amount of data.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="WMFormer-Nested-Transformer-for-Visible-Watermark-Removal-via-Implict-Joint-Learning"><a href="#WMFormer-Nested-Transformer-for-Visible-Watermark-Removal-via-Implict-Joint-Learning" class="headerlink" title="WMFormer++: Nested Transformer for Visible Watermark Removal via Implict Joint Learning"></a>WMFormer++: Nested Transformer for Visible Watermark Removal via Implict Joint Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10195">http://arxiv.org/abs/2308.10195</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongjian Huo, Zehong Zhang, Hanjing Su, Guanbin Li, Chaowei Fang, Qingyao Wu</li>
<li>for: 提高水印图像的权利保护和防范水印图像的篡改</li>
<li>methods: 基于隐式联合学习和跨通道注意力的水印除法</li>
<li>results: 比前方法提高较多，在多种复杂的benchmark上展示出极高的效果<details>
<summary>Abstract</summary>
Watermarking serves as a widely adopted approach to safeguard media copyright. In parallel, the research focus has extended to watermark removal techniques, offering an adversarial means to enhance watermark robustness and foster advancements in the watermarking field. Existing watermark removal methods mainly rely on UNet with task-specific decoder branches--one for watermark localization and the other for background image restoration. However, watermark localization and background restoration are not isolated tasks; precise watermark localization inherently implies regions necessitating restoration, and the background restoration process contributes to more accurate watermark localization. To holistically integrate information from both branches, we introduce an implicit joint learning paradigm. This empowers the network to autonomously navigate the flow of information between implicit branches through a gate mechanism. Furthermore, we employ cross-channel attention to facilitate local detail restoration and holistic structural comprehension, while harnessing nested structures to integrate multi-scale information. Extensive experiments are conducted on various challenging benchmarks to validate the effectiveness of our proposed method. The results demonstrate our approach's remarkable superiority, surpassing existing state-of-the-art methods by a large margin.
</details>
<details>
<summary>摘要</summary>
水印加密是一种广泛采用的媒体版权保护方法。同时，研究焦点已经扩展到水印去除技术，提供了一种对水印的敌对性加强和 watermarking 领域的进步。现有的水印去除方法主要基于 UNet  WITH task-specific decoder branches，一个用于水印localization，另一个用于背景图像修复。但水印localization 和背景修复不是独立的任务，准确的水印localization 直接影响了需要修复的区域，而背景修复过程也会提高水印localization的准确性。为了整合这两个分支的信息，我们引入了隐式联合学习 paradigm。这使得网络可以自动地在两个分支之间流动信息，通过门 mechanism。此外，我们使用交叉通道注意力来促进地方细节修复和整体结构认知，同时利用嵌入结构来集成多尺度信息。我们在多个挑战性的标准底下进行了广泛的实验，以验证我们的提议的效果。结果表明，我们的方法在与现有状态的方法进行比较时表现出了很大的优势。
</details></li>
</ul>
<hr>
<h2 id="FoodGPT-A-Large-Language-Model-in-Food-Testing-Domain-with-Incremental-Pre-training-and-Knowledge-Graph-Prompt"><a href="#FoodGPT-A-Large-Language-Model-in-Food-Testing-Domain-with-Incremental-Pre-training-and-Knowledge-Graph-Prompt" class="headerlink" title="FoodGPT: A Large Language Model in Food Testing Domain with Incremental Pre-training and Knowledge Graph Prompt"></a>FoodGPT: A Large Language Model in Food Testing Domain with Incremental Pre-training and Knowledge Graph Prompt</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10173">http://arxiv.org/abs/2308.10173</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhixiao Qi, Yijiong Yu, Meiqi Tu, Junyi Tan, Yongfeng Huang</li>
<li>for: 这篇论文是为了开发一个适用于食品测试的大型自然语言处理模型而写的。</li>
<li>methods: 该论文提出了一种处理结构化知识和扫描文档的增量预训练方法，以及一种使用知识图来支持大语言模型中的检索。</li>
<li>results: 该论文未提供实验数据， future versions 将报告specific experimental data。<details>
<summary>Abstract</summary>
Currently, the construction of large language models in specific domains is done by fine-tuning on a base model. Some models also incorporate knowledge bases without the need for pre-training. This is because the base model already contains domain-specific knowledge during the pre-training process. We build a large language model for food testing. Unlike the above approach, a significant amount of data in this domain exists in Scanning format for domain standard documents. In addition, there is a large amount of untrained structured knowledge. Therefore, we introduce an incremental pre-training step to inject this knowledge into a large language model. In this paper, we propose a method for handling structured knowledge and scanned documents in incremental pre-training. To overcome the problem of machine hallucination, we constructe a knowledge graph to serve as an external knowledge base for supporting retrieval in the large language model. It is worth mentioning that this paper is a technical report of our pre-release version, and we will report our specific experimental data in future versions.
</details>
<details>
<summary>摘要</summary>
当前，大语言模型在特定领域的构建通常通过精度调整base模型来实现。一些模型还会integrate知识库，无需先行预训练。这是因为基模型在预训练过程中已经包含了领域特定的知识。我们构建了一个食品测试领域的大语言模型。与之前的方法不同的是，食品领域的大量数据存在扫描格式的域标准文档中，同时也有大量未训练的结构化知识。因此，我们介绍了一种递增预训练步骤，以注入这些知识到大语言模型中。在这篇论文中，我们提出了处理结构化知识和扫描文档的递增预训练方法。为了解决机器幻觉的问题，我们构建了一个知识图以作为大语言模型的外部知识库，以支持模型中的检索。值得一提的是，这篇论文是我们预发版的技术报告，未来版本中将公布我们的具体实验数据。
</details></li>
</ul>
<hr>
<h2 id="FashionNTM-Multi-turn-Fashion-Image-Retrieval-via-Cascaded-Memory"><a href="#FashionNTM-Multi-turn-Fashion-Image-Retrieval-via-Cascaded-Memory" class="headerlink" title="FashionNTM: Multi-turn Fashion Image Retrieval via Cascaded Memory"></a>FashionNTM: Multi-turn Fashion Image Retrieval via Cascaded Memory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10170">http://arxiv.org/abs/2308.10170</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anwesan Pal, Sahil Wadhwa, Ayush Jaiswal, Xu Zhang, Yue Wu, Rakesh Chada, Pradeep Natarajan, Henrik I. Christensen</li>
<li>For: 这项研究关注了现实世界中的多轮图像检索系统，其中用户可以逐次提供信息来细化检索结果，直到找到满足所有要求的项目。* Methods: 我们提出了一种新的储存器基于方法，called FashionNTM，它使用了新的叠加型内存神经机器人（CM-NTM）方法来实现隐式状态管理，以学习将所有过去轮的信息集成到新的图像检索中。与普通的神经内存机器人（NTM）不同，CM-NTM可以处理多个输入，并通过 individuak 读写头与各自的内存进行交互，以学习复杂的关系。* Results: 我们的提出方法在Multi-turn FashionIQ数据集上进行了广泛的评估，并与前一代状态下的算法相比，提高了50.5%的性能。此外，我们还创建了一个扩展自Single-turn Shoes数据集的Multi-turn Shoes数据集，并在这个数据集上进行了进一步的分析和用户研究。最终，我们的模型在实际交互 Setting中展现了两个重要的特点：记忆保持 across turns，和不依赖于轮次顺序的反馈。用户研究结果表明，由FashionNTM所 retrieve 的图像被用户 preference  над其他多轮模型的83.1%。项目页面：<a target="_blank" rel="noopener" href="https://sites.google.com/eng.ucsd.edu/fashionntm">https://sites.google.com/eng.ucsd.edu/fashionntm</a><details>
<summary>Abstract</summary>
Multi-turn textual feedback-based fashion image retrieval focuses on a real-world setting, where users can iteratively provide information to refine retrieval results until they find an item that fits all their requirements. In this work, we present a novel memory-based method, called FashionNTM, for such a multi-turn system. Our framework incorporates a new Cascaded Memory Neural Turing Machine (CM-NTM) approach for implicit state management, thereby learning to integrate information across all past turns to retrieve new images, for a given turn. Unlike vanilla Neural Turing Machine (NTM), our CM-NTM operates on multiple inputs, which interact with their respective memories via individual read and write heads, to learn complex relationships. Extensive evaluation results show that our proposed method outperforms the previous state-of-the-art algorithm by 50.5%, on Multi-turn FashionIQ -- the only existing multi-turn fashion dataset currently, in addition to having a relative improvement of 12.6% on Multi-turn Shoes -- an extension of the single-turn Shoes dataset that we created in this work. Further analysis of the model in a real-world interactive setting demonstrates two important capabilities of our model -- memory retention across turns, and agnosticity to turn order for non-contradictory feedback. Finally, user study results show that images retrieved by FashionNTM were favored by 83.1% over other multi-turn models. Project page: https://sites.google.com/eng.ucsd.edu/fashionntm
</details>
<details>
<summary>摘要</summary>
多回文本反馈基于时尚图像检索是关注现实场景，用户可以逐 turno 提供信息来细化检索结果，直到找到符合所有需求的图像。在这种多回系统中，我们提出了一种新的记忆型方法，即时尚NTM（FashionNTM）。我们的框架利用新的层次结构神经图计算机（CM-NTM）方法，以实现隐式状态管理，从而学习将所有过去的回合信息集成到新的图像检索中。不同于普通的神经图计算机（NTM），我们的CM-NTM可以处理多个输入，并通过个性化的读写头与各自的记忆进行交互，以学习复杂的关系。我们对Multi-turn FashionIQ和Multi-turn Shoes两个数据集进行了广泛的评估。结果表明，我们的提出的方法在Multi-turn FashionIQ上比前一个状态艺术算法提高50.5%，同时在Multi-turn Shoes上相对提高12.6%。进一步的分析表明，我们的模型在真实的交互设置下具有两个重要特点：首先，它可以保持多个回合的记忆，其次，它不依赖于回合顺序，对于不相互矛盾的反馈。最后，我们进行了用户研究，发现用户对FashionNTM所呈现的图像的偏好率为83.1%。项目页面：https://sites.google.com/eng.ucsd.edu/fashionntm
</details></li>
</ul>
<hr>
<h2 id="Head-to-Tail-How-Knowledgeable-are-Large-Language-Models-LLM-A-K-A-Will-LLMs-Replace-Knowledge-Graphs"><a href="#Head-to-Tail-How-Knowledgeable-are-Large-Language-Models-LLM-A-K-A-Will-LLMs-Replace-Knowledge-Graphs" class="headerlink" title="Head-to-Tail: How Knowledgeable are Large Language Models (LLM)? A.K.A. Will LLMs Replace Knowledge Graphs?"></a>Head-to-Tail: How Knowledgeable are Large Language Models (LLM)? A.K.A. Will LLMs Replace Knowledge Graphs?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10168">http://arxiv.org/abs/2308.10168</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kai Sun, Yifan Ethan Xu, Hanwen Zha, Yue Liu, Xin Luna Dong</li>
<li>for: 本研究试图回答一些关于大语言模型（LLM）的问题，具体来说是 LLM 是如何掌握知识的？</li>
<li>methods: 作者构建了一个名为 Head-to-Tail 的benchmark，包含 18K 问题答案对 regarding 头、躯体和尾部事实的知名度。他们设计了一种自动评价方法和一组紧接近 LLM 内化知识的度量。</li>
<li>results: 通过对 14 种公共可用的 LLM 进行全面评估，作者显示了现有 LLM 对事实知识的掌握仍然很差，特别是对躯体到尾部实体的知识。<details>
<summary>Abstract</summary>
Since the recent prosperity of Large Language Models (LLMs), there have been interleaved discussions regarding how to reduce hallucinations from LLM responses, how to increase the factuality of LLMs, and whether Knowledge Graphs (KGs), which store the world knowledge in a symbolic form, will be replaced with LLMs. In this paper, we try to answer these questions from a new angle: How knowledgeable are LLMs?   To answer this question, we constructed Head-to-Tail, a benchmark that consists of 18K question-answer (QA) pairs regarding head, torso, and tail facts in terms of popularity. We designed an automated evaluation method and a set of metrics that closely approximate the knowledge an LLM confidently internalizes. Through a comprehensive evaluation of 14 publicly available LLMs, we show that existing LLMs are still far from being perfect in terms of their grasp of factual knowledge, especially for facts of torso-to-tail entities.
</details>
<details>
<summary>摘要</summary>
自大语言模型（LLM）的繁荣以来，有许多关于如何减少LLM回答中的幻觉、如何提高LLM的事实性、以及是否将知识图（KG）取代LLM的讨论。在这篇论文中，我们尝试从一个新的角度回答这些问题：LLM们有多“知识”吗？为answer这个问题，我们构建了Head-to-Tail，一个包含18000个问题回答（QA）对 Regarding popularity的头、躯体和尾部事实。我们设计了自动评估方法和一组 metros that closely approximate the knowledge that LLM confidently internalizes。通过对14个公开available LLMs进行全面评估，我们发现现有LLMs仍然很遥谱于事实知识，尤其是 torso-to-tail entity的事实。
</details></li>
</ul>
<hr>
<h2 id="Bayes-Risk-Transducer-Transducer-with-Controllable-Alignment-Prediction"><a href="#Bayes-Risk-Transducer-Transducer-with-Controllable-Alignment-Prediction" class="headerlink" title="Bayes Risk Transducer: Transducer with Controllable Alignment Prediction"></a>Bayes Risk Transducer: Transducer with Controllable Alignment Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10107">http://arxiv.org/abs/2308.10107</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/espnet/espnet">https://github.com/espnet/espnet</a></li>
<li>paper_authors: Jinchuan Tian, Jianwei Yu, Hangting Chen, Brian Yan, Chao Weng, Dong Yu, Shinji Watanabe</li>
<li>for: 这个研究目的是为了实现控制式的语音识别预测，使得预测结果能够满足特定的想定property。</li>
<li>methods: 这个研究使用了Bayes risk函数来设定低风险值，以将预测结果与想定的property相对准确。</li>
<li>results: 实验结果显示，提案的BRT可以节省推断成本，并且降低了整个系统延迟。 Specifically, BRT可以降低非流式ASR的推断成本 by up to 46%，并且降低流式ASR系统的整体延迟 by 41%.<details>
<summary>Abstract</summary>
Automatic speech recognition (ASR) based on transducers is widely used. In training, a transducer maximizes the summed posteriors of all paths. The path with the highest posterior is commonly defined as the predicted alignment between the speech and the transcription. While the vanilla transducer does not have a prior preference for any of the valid paths, this work intends to enforce the preferred paths and achieve controllable alignment prediction. Specifically, this work proposes Bayes Risk Transducer (BRT), which uses a Bayes risk function to set lower risk values to the preferred paths so that the predicted alignment is more likely to satisfy specific desired properties. We further demonstrate that these predicted alignments with intentionally designed properties can provide practical advantages over the vanilla transducer. Experimentally, the proposed BRT saves inference cost by up to 46% for non-streaming ASR and reduces overall system latency by 41% for streaming ASR.
</details>
<details>
<summary>摘要</summary>
自动语音识别（ASR）基于传感器广泛应用。在训练中，一个传感器最大化总 posterior的所有路径。路径的 posterior 最高的路径通常定义为 Speech 和转录的预测Alignment。而 vanilla 传感器没有任何有效路径的偏好，这项工作计划强制执行 Preferred 路径并实现可控制的预测Alignment。特别是，这项工作提出了 Bayes 风险函数来设置更低的风险值 для Preferred 路径，以便预测Alignment 满足特定的愿望性质。我们进一步示出，这些预测的Alignment 可以提供非常实用的优势，比如降低总系统延迟时间41%。Experiments 实验表明，提议的 BRT 可以在非流式 ASR 中降低推理成本达46%，并在流式 ASR 中降低总系统延迟时间41%。
</details></li>
</ul>
<hr>
<h2 id="PACE-Improving-Prompt-with-Actor-Critic-Editing-for-Large-Language-Model"><a href="#PACE-Improving-Prompt-with-Actor-Critic-Editing-for-Large-Language-Model" class="headerlink" title="PACE: Improving Prompt with Actor-Critic Editing for Large Language Model"></a>PACE: Improving Prompt with Actor-Critic Editing for Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10088">http://arxiv.org/abs/2308.10088</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yihong Dong, Kangcheng Luo, Xue Jiang, Zhi Jin, Ge Li</li>
<li>for: 提高大语言模型（LLM）的表现，使其能够自动编辑提示。</li>
<li>methods: 基于actor-critic算法的Prompt with Actor-Critic Editing（PACE）方法，使用LLM作为 dual 角色的actor和critic，将提示视为策略。</li>
<li>results: 对24个指令生成任务和21个大规模任务进行了广泛的实验，结果表明，PACE可以提高中等&#x2F;低质量人工写的提示的相对性能，最高提高98%，与高质量人工写提示的表现相当。此外，PACE还表现出了remarkable的提示生成能力。<details>
<summary>Abstract</summary>
Large language models (LLMs) have showcased remarkable potential across various tasks by conditioning on prompts. However, the quality of different human-written prompts leads to substantial discrepancies in LLMs' performance, and improving prompts usually necessitates considerable human effort and expertise. To this end, this paper proposes Prompt with Actor-Critic Editing (PACE) for LLMs to enable automatic prompt editing. Drawing inspiration from the actor-critic algorithm in reinforcement learning, PACE leverages LLMs as the dual roles of actors and critics, conceptualizing prompt as a type of policy. PACE refines prompt, taking into account the feedback from both actors performing prompt and critics criticizing response. This process helps LLMs better align prompt to a specific task, thanks to real responses and thinking from LLMs. We conduct extensive experiments on 24 instruction induction tasks and 21 big-bench tasks. Experimental results indicate that PACE elevates the relative performance of medium/low-quality human-written prompts by up to 98\%, which has comparable performance to high-quality human-written prompts. Moreover, PACE also exhibits notable efficacy for prompt generation.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在不同任务上展现了惊人的潜力，但不同的人工写的提示导致了 LLM 的性能差异很大，通常需要大量的人工努力和专业知识来改进提示。为解决这问题，本文提出了基于actor-critic算法的提示编辑方法（PACE），以便自动编辑提示。在actor-critic算法中，LLM 扮演了两个角色：actor和critic，将提示视为策略。PACE 利用 LLM 对提示的反馈，以及对响应的批评，来优化提示，使 LLM 更好地适应特定任务。我们在 24 个指令生成任务和 21 个大型任务上进行了广泛的实验。实验结果表明，PACE 可以提高人工写的中等/低质量提示的相对性能，最高提高达 98%，与高质量人工写提示的性能相当。此外，PACE 还显示了明显的生成提示效果。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/20/cs.CL_2023_08_20/" data-id="clohum951009ipj88f0k632ej" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/20/cs.LG_2023_08_20/" class="article-date">
  <time datetime="2023-08-20T10:00:00.000Z" itemprop="datePublished">2023-08-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/20/cs.LG_2023_08_20/">cs.LG - 2023-08-20</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Preserving-Specificity-in-Federated-Graph-Learning-for-fMRI-based-Neurological-Disorder-Identification"><a href="#Preserving-Specificity-in-Federated-Graph-Learning-for-fMRI-based-Neurological-Disorder-Identification" class="headerlink" title="Preserving Specificity in Federated Graph Learning for fMRI-based Neurological Disorder Identification"></a>Preserving Specificity in Federated Graph Learning for fMRI-based Neurological Disorder Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10302">http://arxiv.org/abs/2308.10302</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junhao Zhang, Qianqian Wang, Xiaochuan Wang, Lishan Qiao, Mingxia Liu</li>
<li>for: 这个研究旨在探索用resting-state功能磁共振成像（rs-fMRI）检测脑部疾病的不同类型之间的连接性，并使用强化图 neural network（GNN）来学习rs-fMRI表示。</li>
<li>methods: 这个研究使用了联邦学习（Federated Learning，FL）来进行脑部疾病分析，并将多个实验中心&#x2F;站点的数据集中心化。每个客户端都有一个共享和专用分支，其中共享分支中的参数将被发送到服务器，而专用分支中的参数则会保留在本地。这可以帮助知识分享和维护站点特有的特征。在共享分支中，我们使用了空间-时间注意力图像同步网络来学习动态rs-fMRI表示。在专用分支中，我们组合了 вектор化的民生资讯（例如年龄、性别和教育年数）和功能连接网络，以保留站点特有的特征。</li>
<li>results: 实验结果显示，SFGL比较多种现有的方法更高的精度，并且可以保留站点特有的特征。<details>
<summary>Abstract</summary>
Resting-state functional magnetic resonance imaging (rs-fMRI) offers a non-invasive approach to examining abnormal brain connectivity associated with brain disorders. Graph neural network (GNN) gains popularity in fMRI representation learning and brain disorder analysis with powerful graph representation capabilities. Training a general GNN often necessitates a large-scale dataset from multiple imaging centers/sites, but centralizing multi-site data generally faces inherent challenges related to data privacy, security, and storage burden. Federated Learning (FL) enables collaborative model training without centralized multi-site fMRI data. Unfortunately, previous FL approaches for fMRI analysis often ignore site-specificity, including demographic factors such as age, gender, and education level. To this end, we propose a specificity-aware federated graph learning (SFGL) framework for rs-fMRI analysis and automated brain disorder identification, with a server and multiple clients/sites for federated model aggregation and prediction. At each client, our model consists of a shared and a personalized branch, where parameters of the shared branch are sent to the server while those of the personalized branch remain local. This can facilitate knowledge sharing among sites and also helps preserve site specificity. In the shared branch, we employ a spatio-temporal attention graph isomorphism network to learn dynamic fMRI representations. In the personalized branch, we integrate vectorized demographic information (i.e., age, gender, and education years) and functional connectivity networks to preserve site-specific characteristics. Representations generated by the two branches are then fused for classification. Experimental results on two fMRI datasets with a total of 1,218 subjects suggest that SFGL outperforms several state-of-the-art approaches.
</details>
<details>
<summary>摘要</summary>
resting-state功能核磁共振成像（rs-fMRI）为脑病诊断提供了一种非侵入性的方法。图 neural network（GNN）在fMRI表示学习中得到了广泛的应用，但是训练一个普通的GNN通常需要大规模的数据集，而这些数据集来自多个成像中心/站点。 federated learning（FL）可以实现多个站点的模型训练，无需集中多个站点的数据。然而，前一些FL方法往往忽略了站点特有的特征，包括人口特征如年龄、性别和教育水平。为此，我们提出了特征意识 Federated Graph Learning（SFGL）框架，用于rs-fMRI分析和自动诊断脑病。在这个框架中，服务器和多个客户端/站点之间进行联合模型训练和预测。每个客户端都有一个共享和个性化分支，其中共享分支中的参数将被发送到服务器，而个性化分支中的参数将保留在本地。这可以促进站点之间的知识共享，同时也可以保持站点特有的特征。在共享分支中，我们采用了空间-时间注意力图同构网络，以学习动态的fMRI表示。在个性化分支中，我们将年龄、性别和教育年数Vector化后与功能连接网络相结合，以保留站点特有的特征。两个分支生成的表示后，将被混合以进行分类。实验结果表明，SFGL在两个fMRI数据集上，共计1,218名参与者，超过了一些当前的状态艺法。
</details></li>
</ul>
<hr>
<h2 id="An-interpretable-deep-learning-method-for-bearing-fault-diagnosis"><a href="#An-interpretable-deep-learning-method-for-bearing-fault-diagnosis" class="headerlink" title="An interpretable deep learning method for bearing fault diagnosis"></a>An interpretable deep learning method for bearing fault diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10292">http://arxiv.org/abs/2308.10292</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Lu, Austin M. Bray, Chao Hu, Andrew T. Zimmerman, Hongyi Xu</li>
<li>For: 本研究旨在提高深度学习（DL）模型的可解释性，以便在安全关键维护任务中提供更加可信的推荐。* Methods: 该研究使用了卷积神经网络（CNN），并使用梯度权重分割映射（Grad-CAM）来形成可解释的DL方法，用于分类滤波器故障。在训练过程中，我们使用Grad-CAM来确定训练样本的特征重要性，并建立了一个健康图书馆（health library），包含训练样本的彩色映射。在评估过程中，我们使用健康图书馆中的相似性来选择预测基础样本。* Results: 该方法可以轻松地应用于任何CNN模型，不需要修改模型结构。我们的实验结果表明，该方法可以选择基于实际和物理意义的预测基础样本，从而提高DL模型的可信度。<details>
<summary>Abstract</summary>
Deep learning (DL) has gained popularity in recent years as an effective tool for classifying the current health and predicting the future of industrial equipment. However, most DL models have black-box components with an underlying structure that is too complex to be interpreted and explained to human users. This presents significant challenges when deploying these models for safety-critical maintenance tasks, where non-technical personnel often need to have complete trust in the recommendations these models give. To address these challenges, we utilize a convolutional neural network (CNN) with Gradient-weighted Class Activation Mapping (Grad-CAM) activation map visualizations to form an interpretable DL method for classifying bearing faults. After the model training process, we apply Grad-CAM to identify a training sample's feature importance and to form a library of diagnosis knowledge (or health library) containing training samples with annotated feature maps. During the model evaluation process, the proposed approach retrieves prediction basis samples from the health library according to the similarity of the feature importance. The proposed method can be easily applied to any CNN model without modifying the model architecture, and our experimental results show that this method can select prediction basis samples that are intuitively and physically meaningful, improving the model's trustworthiness for human users.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Towards-Few-shot-Coordination-Revisiting-Ad-hoc-Teamplay-Challenge-In-the-Game-of-Hanabi"><a href="#Towards-Few-shot-Coordination-Revisiting-Ad-hoc-Teamplay-Challenge-In-the-Game-of-Hanabi" class="headerlink" title="Towards Few-shot Coordination: Revisiting Ad-hoc Teamplay Challenge In the Game of Hanabi"></a>Towards Few-shot Coordination: Revisiting Ad-hoc Teamplay Challenge In the Game of Hanabi</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10284">http://arxiv.org/abs/2308.10284</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hadi Nekoei, Xutong Zhao, Janarthanan Rajendran, Miao Liu, Sarath Chandar</li>
<li>For: This paper focuses on cooperative multi-agent reinforcement learning (MARL) algorithms with zero-shot coordination (ZSC) and their ability to adapt to unseen partners.* Methods: The paper uses a popular cooperative multi-agent game called Hanabi to evaluate the adaptability of MARL methods, and creates a diverse set of pre-trained agents to test their performance.* Results: The paper finds that naive Independent Q-Learning (IQL) agents can adapt as quickly as state-of-the-art ZSC algorithms in most cases, and identifies two categories of hyper-parameters that have a significant impact on the adaptability of Hanabi agents.Here are the three points in Simplified Chinese text:* For: 这篇论文关注了合作多代理权划学习算法（MARL）的零shot协调（ZSC），以及其在未看到合作伙伴时的适应性。* Methods: 论文使用了一个流行的合作多代理权划游戏called Hanabi来评估MARL方法的适应性，并创造了一组多样化的预训练代理来测试其性能。* Results: 论文发现，naive Independent Q-Learning（IQL）代理在大多数情况下可以和现有的ZSC算法快速适应，并identified两类Hyperparameter对合作 Hanabi 代理的适应性有重要影响。<details>
<summary>Abstract</summary>
Cooperative Multi-agent Reinforcement Learning (MARL) algorithms with Zero-Shot Coordination (ZSC) have gained significant attention in recent years. ZSC refers to the ability of agents to coordinate zero-shot (without additional interaction experience) with independently trained agents. While ZSC is crucial for cooperative MARL agents, it might not be possible for complex tasks and changing environments. Agents also need to adapt and improve their performance with minimal interaction with other agents. In this work, we show empirically that state-of-the-art ZSC algorithms have poor performance when paired with agents trained with different learning methods, and they require millions of interaction samples to adapt to these new partners. To investigate this issue, we formally defined a framework based on a popular cooperative multi-agent game called Hanabi to evaluate the adaptability of MARL methods. In particular, we created a diverse set of pre-trained agents and defined a new metric called adaptation regret that measures the agent's ability to efficiently adapt and improve its coordination performance when paired with some held-out pool of partners on top of its ZSC performance. After evaluating several SOTA algorithms using our framework, our experiments reveal that naive Independent Q-Learning (IQL) agents in most cases adapt as quickly as the SOTA ZSC algorithm Off-Belief Learning (OBL). This finding raises an interesting research question: How to design MARL algorithms with high ZSC performance and capability of fast adaptation to unseen partners. As a first step, we studied the role of different hyper-parameters and design choices on the adaptability of current MARL algorithms. Our experiments show that two categories of hyper-parameters controlling the training data diversity and optimization process have a significant impact on the adaptability of Hanabi agents.
</details>
<details>
<summary>摘要</summary>
合作多智能 reinforcement learning（MARL）算法 Zero-Shot 协调（ZSC）在过去几年内吸引了广泛关注。ZSC 指 agents 可以在不经过额外交互经验的情况下协调。虽然 ZSC 对合作 MARL 代理是非常重要，但可能在复杂任务和变化环境中不可能实现。代理还需要适应和改进其性能，只需要最小化与其他代理的交互。在这种情况下，我们证明了，当与其他代理进行交互时，当前的 ZSC 算法的性能不佳，需要数百万次交互样本来适应这些新合作伙伴。为了探讨这个问题，我们提出了一个基于流行的合作多智能游戏 Hanabi 的框架，用于评估 MARL 方法的适应性。特别是，我们创建了一个多样化的预训练代理集和一个新的度量叫做 adaptive regret，用于衡量代理在与一些储存的合作伙伴交互时的协调性能。经过评估多个 SOTA 算法，我们的实验发现，简单的独立 Q-学习（IQL）代理在大多数情况下快速适应，与 SOTA ZSC 算法 Off-Belief Learning（OBL）相当。这一发现提出了一个有趣的研究问题：如何设计 MARL 算法，同时具有高 ZSC 性能和快速适应未见伙伴的能力。作为首先的步骤，我们研究了当前 MARL 算法的不同超参数和设计选择对适应性的影响。我们的实验表明，控制训练数据多样性和优化过程的两类超参数具有重要的影响于 Hanabi 代理的适应性。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Uncertainty-Guided-Model-Selection-for-Data-Driven-PDE-Discovery"><a href="#Adaptive-Uncertainty-Guided-Model-Selection-for-Data-Driven-PDE-Discovery" class="headerlink" title="Adaptive Uncertainty-Guided Model Selection for Data-Driven PDE Discovery"></a>Adaptive Uncertainty-Guided Model Selection for Data-Driven PDE Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10283">http://arxiv.org/abs/2308.10283</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pongpisit-thanasutives/ubic">https://github.com/pongpisit-thanasutives/ubic</a></li>
<li>paper_authors: Pongpisit Thanasutives, Takashi Morita, Masayuki Numao, Ken-ichi Fukui</li>
<li>for: 用于优选具有少量可靠项的噪声空间时间观察数据的参数适应不确定性加权信息条件（UBIC）。</li>
<li>methods: 使用参数适应不确定性加权信息条件（UBIC）来优选具有少量可靠项的噪声空间时间观察数据的参数适应PDE。</li>
<li>results: 经过实验证明，UBIC能够成功地确定true governing PDE，并且发现了清理观察数据可以改善模型复杂度和不确定性之间的贝叶тов。Here’s the translation of the abstract in English:</li>
<li>for: To propose a new parameter-adaptive uncertainty-penalized Bayesian information criterion (UBIC) for selecting the parsimonious partial differential equation (PDE) that best governs noisy spatial-temporal observed data with few reliable terms.</li>
<li>methods: Using the UBIC to select the PDE that adapts to the parameters of the observed data, which is penalized by both the complexity of the PDE and the quantified uncertainty derived from the model supports’ coefficient of variation in a probabilistic view.</li>
<li>results: Numerical results confirm the successful application of the UBIC in identifying the true governing PDE, and reveal an interesting effect of denoising the observed data on improving the trade-off between the BIC score and model complexity.<details>
<summary>Abstract</summary>
We propose a new parameter-adaptive uncertainty-penalized Bayesian information criterion (UBIC) to prioritize the parsimonious partial differential equation (PDE) that sufficiently governs noisy spatial-temporal observed data with few reliable terms. Since the naive use of the BIC for model selection has been known to yield an undesirable overfitted PDE, the UBIC penalizes the found PDE not only by its complexity but also the quantified uncertainty, derived from the model supports' coefficient of variation in a probabilistic view. We also introduce physics-informed neural network learning as a simulation-based approach to further validate the selected PDE flexibly against the other discovered PDE. Numerical results affirm the successful application of the UBIC in identifying the true governing PDE. Additionally, we reveal an interesting effect of denoising the observed data on improving the trade-off between the BIC score and model complexity. Code is available at https://github.com/Pongpisit-Thanasutives/UBIC.
</details>
<details>
<summary>摘要</summary>
我们提出一种新的参数适应 uncertainty-penalized Bayesian信息整合因子（UBIC），用于优先选择具有噪声空间时间观测数据少量可靠项的简洁偏微分方程（PDE）。由于直接使用BIC来进行模型选择可能会导致过度适应PDE，UBIC不仅penalizes发现的PDE的复杂性，还penalizes其所具有的量化不确定性，从probabilistic视角来 derivation。我们还引入物理学 Informed Neural Network学习作为一种基于实验的方法，以验证选择的PDE的可行性。numerical result confirm the successful application of UBIC in identifying the true governing PDE。此外，我们发现对观测数据进行去噪化可以提高模型复杂性和BIC分数之间的负荷平衡。代码可以在https://github.com/Pongpisit-Thanasutives/UBIC上获取。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Spatiotemporal-Traffic-Prediction-through-Urban-Human-Activity-Analysis"><a href="#Enhancing-Spatiotemporal-Traffic-Prediction-through-Urban-Human-Activity-Analysis" class="headerlink" title="Enhancing Spatiotemporal Traffic Prediction through Urban Human Activity Analysis"></a>Enhancing Spatiotemporal Traffic Prediction through Urban Human Activity Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10282">http://arxiv.org/abs/2308.10282</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/suminhan/traffic-uagcrntf">https://github.com/suminhan/traffic-uagcrntf</a></li>
<li>paper_authors: Sumin Han, Youngjun Park, Minji Lee, Jisun An, Dongman Lee</li>
<li>for:  traffic prediction （交通预测）</li>
<li>methods: graph convolution deep learning algorithms （图 convolution 深度学习算法）</li>
<li>results: state-of-the-art performance without introducing excessive computational overhead （无需增加过分计算开销，达到了当前最佳性能）<details>
<summary>Abstract</summary>
Traffic prediction is one of the key elements to ensure the safety and convenience of citizens. Existing traffic prediction models primarily focus on deep learning architectures to capture spatial and temporal correlation. They often overlook the underlying nature of traffic. Specifically, the sensor networks in most traffic datasets do not accurately represent the actual road network exploited by vehicles, failing to provide insights into the traffic patterns in urban activities. To overcome these limitations, we propose an improved traffic prediction method based on graph convolution deep learning algorithms. We leverage human activity frequency data from National Household Travel Survey to enhance the inference capability of a causal relationship between activity and traffic patterns. Despite making minimal modifications to the conventional graph convolutional recurrent networks and graph convolutional transformer architectures, our approach achieves state-of-the-art performance without introducing excessive computational overhead.
</details>
<details>
<summary>摘要</summary>
交通预测是公民安全和便利的关键元素之一。现有的交通预测模型主要采用深度学习架构，以捕捉空间和时间相关性。它们往往忽略交通的本质。具体来说，交通数据集中的感知网络不准确表示实际行驶路网，不能提供交通模式的趋势信息。为了解决这些限制，我们提议一种基于图 convolution 深度学习算法的改进交通预测方法。我们利用国家家庭旅游调查数据来增强 causal 关系 между活动和交通模式的推理能力。虽然我们对传统的图 convolutional recurrent networks 和图 convolutional transformer 架构进行了最小的修改，但我们的方法可以达到当今最佳性能，无需增加过多的计算负担。
</details></li>
</ul>
<hr>
<h2 id="The-DKU-DUKEECE-System-for-the-Manipulation-Region-Location-Task-of-ADD-2023"><a href="#The-DKU-DUKEECE-System-for-the-Manipulation-Region-Location-Task-of-ADD-2023" class="headerlink" title="The DKU-DUKEECE System for the Manipulation Region Location Task of ADD 2023"></a>The DKU-DUKEECE System for the Manipulation Region Location Task of ADD 2023</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10281">http://arxiv.org/abs/2308.10281</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zexin Cai, Weiqing Wang, Yikang Wang, Ming Li</li>
<li>for: 本文是为了参加第二届音频深伪检测挑战（ADD 2023）的跟踪2类别而设计的系统。</li>
<li>methods: 本文使用多种检测系统来定位剪辑区域并确定其真实性。包括边界检测和深伪检测两个帧级系统，以及专门使用真实数据训练的VAE模型来确定音频clip的真实性。</li>
<li>results: 通过这三种系统的 fusión，我们的答案在ADD挑战中得到了82.23%的句子准确率和60.66%的F1分数，最终得到了ADD分数0.6713，在Track 2中排名第一。<details>
<summary>Abstract</summary>
This paper introduces our system designed for Track 2, which focuses on locating manipulated regions, in the second Audio Deepfake Detection Challenge (ADD 2023). Our approach involves the utilization of multiple detection systems to identify splicing regions and determine their authenticity. Specifically, we train and integrate two frame-level systems: one for boundary detection and the other for deepfake detection. Additionally, we employ a third VAE model trained exclusively on genuine data to determine the authenticity of a given audio clip. Through the fusion of these three systems, our top-performing solution for the ADD challenge achieves an impressive 82.23% sentence accuracy and an F1 score of 60.66%. This results in a final ADD score of 0.6713, securing the first rank in Track 2 of ADD 2023.
</details>
<details>
<summary>摘要</summary>
这份论文介绍了我们为Track 2设计的系统，专注于找到修改区域。这是2023年音频深刻投影检测挑战（ADD 2023）的第二轮比赛。我们的方法是利用多个检测系统来标识剪辑区域并确定它们的真实性。我们训练并集成了两个帧级系统：一个用于边界检测，另一个用于深刻检测。此外，我们还使用专门用于真实数据训练的VAE模型来确定一个音频clip的真实性。通过这三个系统的融合，我们的ADD挑战首名解决方案在ADD挑战中实现了82.23%的句子准确率和60.66%的F1分数。这导致了我们在ADD挑战中的最终得分为0.6713，在Track 2中名列第一。
</details></li>
</ul>
<hr>
<h2 id="GPFL-Simultaneously-Learning-Global-and-Personalized-Feature-Information-for-Personalized-Federated-Learning"><a href="#GPFL-Simultaneously-Learning-Global-and-Personalized-Feature-Information-for-Personalized-Federated-Learning" class="headerlink" title="GPFL: Simultaneously Learning Global and Personalized Feature Information for Personalized Federated Learning"></a>GPFL: Simultaneously Learning Global and Personalized Feature Information for Personalized Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10279">http://arxiv.org/abs/2308.10279</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianqing Zhang, Yang Hua, Hao Wang, Tao Song, Zhengui Xue, Ruhui Ma, Jian Cao, Haibing Guan</li>
<li>for: 本研究旨在提出一种新的个性化联合学习（pFL）方法，以满足联合学习和个性化学习的两个目标。</li>
<li>methods: 本方法使用了一种新的特征提取方法，可以同时学习全局和个体特征信息。</li>
<li>results: 对六个数据集进行了三种统计上不同的设置，并对十种现有方法进行了比较。结果显示，GPFL方法在效果、可扩展性、公平性、稳定性和隐私方面都有优势，并且可以避免过拟合和基线方法的超越。<details>
<summary>Abstract</summary>
Federated Learning (FL) is popular for its privacy-preserving and collaborative learning capabilities. Recently, personalized FL (pFL) has received attention for its ability to address statistical heterogeneity and achieve personalization in FL. However, from the perspective of feature extraction, most existing pFL methods only focus on extracting global or personalized feature information during local training, which fails to meet the collaborative learning and personalization goals of pFL. To address this, we propose a new pFL method, named GPFL, to simultaneously learn global and personalized feature information on each client. We conduct extensive experiments on six datasets in three statistically heterogeneous settings and show the superiority of GPFL over ten state-of-the-art methods regarding effectiveness, scalability, fairness, stability, and privacy. Besides, GPFL mitigates overfitting and outperforms the baselines by up to 8.99% in accuracy.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 是因其隐私保护和协同学习能力而受欢迎。 最近，个性化 federated learning (pFL) 已引起关注，因为它可以解决统计不同性问题并实现个性化。然而，在特征提取方面，大多数现有的 pFL 方法只是在本地训练中提取全局或个性化特征信息，这与 pFL 的协同学习和个性化目标不符。为了解决这个问题，我们提出了一种新的 pFL 方法，名为 GPFL，它可以在每个客户端上同时学习全局和个性化特征信息。我们在六个数据集上进行了三种统计不同性的设置，并对 GPFL 与十种现状很好的方法进行了广泛的实验。结果表明，GPFL 在效果、可扩展性、公平性、稳定性和隐私方面与现状很好的方法之间具有明显的优势。此外，GPFL 可以避免过拟合并超过基线方法的性能。
</details></li>
</ul>
<hr>
<h2 id="Minimalist-Traffic-Prediction-Linear-Layer-Is-All-You-Need"><a href="#Minimalist-Traffic-Prediction-Linear-Layer-Is-All-You-Need" class="headerlink" title="Minimalist Traffic Prediction: Linear Layer Is All You Need"></a>Minimalist Traffic Prediction: Linear Layer Is All You Need</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10276">http://arxiv.org/abs/2308.10276</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wenyingduan/STLinear">https://github.com/wenyingduan/STLinear</a></li>
<li>paper_authors: Wenying Duan, Hong Rao, Wei Huang, Xiaoxi He</li>
<li>for: 交通预测是智能交通系统（ITS）和智能城市的关键，而STGNNs在这个领域表现出了承诺，但它们还存在计算复杂性、梯度问题和资源浪费等问题。这篇论文提出了三个解决方案，以解决这些问题。</li>
<li>methods: 本文提出了三个解决方案，包括节点嵌入方法、时间序列分解和周期学习。我们还介绍了STLinear模型架构，它是一种最优化的、高效的模型，与传统STGNNs不同，它完全地在本地进行计算，不需要间接数据交换，仅仅使用直线层，这大幅降低了计算占用的复杂性。</li>
<li>results: 我们的实验表明，STLinear模型在实际数据上具有极高的准确率，与状态lejardin2023年的STGNN基线模型匹配或超越，但计算负担减少了大于95%。总之，STLinear emerges as a powerful and efficient alternative to traditional STGNNs, with far-reaching implications for the future of ITS and smart city initiatives.<details>
<summary>Abstract</summary>
Traffic prediction is essential for the progression of Intelligent Transportation Systems (ITS) and the vision of smart cities. While Spatial-Temporal Graph Neural Networks (STGNNs) have shown promise in this domain by leveraging Graph Neural Networks (GNNs) integrated with either RNNs or Transformers, they present challenges such as computational complexity, gradient issues, and resource-intensiveness. This paper addresses these challenges, advocating for three main solutions: a node-embedding approach, time series decomposition, and periodicity learning. We introduce STLinear, a minimalist model architecture designed for optimized efficiency and performance. Unlike traditional STGNNs, STlinear operates fully locally, avoiding inter-node data exchanges, and relies exclusively on linear layers, drastically cutting computational demands. Our empirical studies on real-world datasets confirm STLinear's prowess, matching or exceeding the accuracy of leading STGNNs, but with significantly reduced complexity and computation overhead (more than 95% reduction in MACs per epoch compared to state-of-the-art STGNN baseline published in 2023). In summary, STLinear emerges as a potent, efficient alternative to conventional STGNNs, with profound implications for the future of ITS and smart city initiatives.
</details>
<details>
<summary>摘要</summary>
traffic prediction 是智能交通系统（ITS）和智能城市的发展所必需的。而 spatial-temporal graph neural networks（STGNNs）在这个领域已经表现出了承诺，通过结合图神经网络（GNNs）和 either RNNs 或 Transformers。但 STGNNs 也存在一些挑战，例如计算复杂性、梯度问题和资源浪费。这篇文章提出了三个主要解决方案：节点嵌入方法、时间序列分解和周期学习。我们介绍了 STLinear，一种最优化的模型建 architecture，与传统的 STGNNs 不同，STLinear 完全地在本地进行操作，不需要节点之间数据交换，并且仅仅使用线性层，大幅降低计算需求。我们对实际数据集进行了实验，并证明 STLinear 能够匹配或超越现有的 STGNNs 的精度，但是计算过程中的复杂度和负担减少了超过 95% （相比于2023年发表的state-of-the-art STGNN 基eline）。总之，STLinear  emerges 作为一种高效、可靠的 STGNNs 代替方案，对智能交通系统和智能城市的未来产生了深远的影响。
</details></li>
</ul>
<hr>
<h2 id="SBSM-Pro-Support-Bio-sequence-Machine-for-Proteins"><a href="#SBSM-Pro-Support-Bio-sequence-Machine-for-Proteins" class="headerlink" title="SBSM-Pro: Support Bio-sequence Machine for Proteins"></a>SBSM-Pro: Support Bio-sequence Machine for Proteins</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10275">http://arxiv.org/abs/2308.10275</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wyzbio/support-bio-sequence-machine">https://github.com/wyzbio/support-bio-sequence-machine</a></li>
<li>paper_authors: Yizheng Wang, Yixiao Zhai, Yijie Ding, Quan Zou</li>
<li>for: 本研究旨在提出一种特定 для生物序列分类的支持vector机器学习模型（SBSM-Pro），以帮助和导引生物实验。</li>
<li>methods: 该模型从原始序列开始，将氨基酸按照其物理化学性质分组，并使用序列对比来衡量蛋白质之间的相似性。它还使用一种新的MKL方法将多种信息集成，并使用支持向量机器学习进行分类预测。</li>
<li>results: 研究结果表明，SBSM-Pro在10个数据集中表现出色地预测蛋白质功能和后转化 modify。这项研究不仅代表了生物序列分类领域的 estado dell’arte，还开辟了新的方向，为生物序列分类 plataform 的开发做出了有益的贡献。<details>
<summary>Abstract</summary>
Proteins play a pivotal role in biological systems. The use of machine learning algorithms for protein classification can assist and even guide biological experiments, offering crucial insights for biotechnological applications. We propose a support bio-sequence machine for proteins, a model specifically designed for biological sequence classification. This model starts with raw sequences and groups amino acids based on their physicochemical properties. It incorporates sequence alignment to measure the similarities between proteins and uses a novel MKL approach to integrate various types of information, utilizing support vector machines for classification prediction. The results indicate that our model demonstrates commendable performance across 10 datasets in terms of the identification of protein function and posttranslational modification. This research not only showcases state-of-the-art work in protein classification but also paves the way for new directions in this domain, representing a beneficial endeavour in the development of platforms tailored for biological sequence classification. SBSM-Pro is available for access at http://lab.malab.cn/soft/SBSM-Pro/.
</details>
<details>
<summary>摘要</summary>
生物系统中，蛋白质扮演着重要的角色。通过机器学习算法进行蛋白质分类可以帮助和导引生物实验，提供生物技术应用中的重要关键。我们提议一个生物序列机器学习模型（SBSM-Pro），特别设计用于生物序列分类。这个模型从原始序列开始，根据蛋白质的物理化化性将氨基酸分组。它还包括序列对比来衡量蛋白质之间的相似性，并使用一种新的MKL方法集成不同类型的信息，使用支持向量机器学习进行预测。结果显示，我们的模型在10个数据集上表现出色，对蛋白质功能和后译 modificatory 进行识别。这个研究不仅代表了生物分类领域的 estado-of-the-art，也开启了新的方向，实现了针对生物序列分类的平台的开发。SBSM-Pro可以在http://lab.malab.cn/soft/SBSM-Pro/ 上获取。
</details></li>
</ul>
<hr>
<h2 id="An-alternative-to-SVM-Method-for-Data-Classification"><a href="#An-alternative-to-SVM-Method-for-Data-Classification" class="headerlink" title="An alternative to SVM Method for Data Classification"></a>An alternative to SVM Method for Data Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11579">http://arxiv.org/abs/2308.11579</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/himanshub1007/Alzhimers-Disease-Prediction-Using-Deep-learning">https://github.com/himanshub1007/Alzhimers-Disease-Prediction-Using-Deep-learning</a></li>
<li>paper_authors: Lakhdar Remaki</li>
<li>for: 这 paper 是为了提出一种新的分类方法，以解决支持向量机（SVM）方法的一些缺陷。</li>
<li>methods: 这 paper 使用了一种基于最小距离到优化Subspace的方法，其中Subspace 是包含原始类的映射。</li>
<li>results: 该方法与 SVM 方法有相似的性能，但具有改进了的一些缺陷，如时间处理、高维度情况下的优化过程的风险、多类分类、不均衡类别和动态分类。<details>
<summary>Abstract</summary>
Support vector machine (SVM), is a popular kernel method for data classification that demonstrated its efficiency for a large range of practical applications. The method suffers, however, from some weaknesses including; time processing, risk of failure of the optimization process for high dimension cases, generalization to multi-classes, unbalanced classes, and dynamic classification. In this paper an alternative method is proposed having a similar performance, with a sensitive improvement of the aforementioned shortcomings. The new method is based on a minimum distance to optimal subspaces containing the mapped original classes.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Turning-Waste-into-Wealth-Leveraging-Low-Quality-Samples-for-Enhancing-Continuous-Conditional-Generative-Adversarial-Networks"><a href="#Turning-Waste-into-Wealth-Leveraging-Low-Quality-Samples-for-Enhancing-Continuous-Conditional-Generative-Adversarial-Networks" class="headerlink" title="Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing Continuous Conditional Generative Adversarial Networks"></a>Turning Waste into Wealth: Leveraging Low-Quality Samples for Enhancing Continuous Conditional Generative Adversarial Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10273">http://arxiv.org/abs/2308.10273</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Ding, Yongwei Wang, Zuheng Xu</li>
<li>for: 提高 conditional GANs 的可视化质量和标签一致性</li>
<li>methods: 使用 dual-NDA 方法，包括两种不同类型的负样本：可见不真实的样本生成自预训练 CcGAN，以及 manipulate 真实图像的标签来生成 label-inconsistent 的负样本。</li>
<li>results: Dual-NDA 可以帮助 CcGANs 生成更加可见性和标签一致性的假图像，在 UTKFace 和 Steering Angle 上进行了实验证明，并且可以超越当前状态的 conditional GANs 和液体模型。<details>
<summary>Abstract</summary>
Continuous Conditional Generative Adversarial Networks (CcGANs) enable generative modeling conditional on continuous scalar variables (termed regression labels). However, they can produce subpar fake images due to limited training data. Although Negative Data Augmentation (NDA) effectively enhances unconditional and class-conditional GANs by introducing anomalies into real training images, guiding the GANs away from low-quality outputs, its impact on CcGANs is limited, as it fails to replicate negative samples that may occur during the CcGAN sampling. We present a novel NDA approach called Dual-NDA specifically tailored for CcGANs to address this problem. Dual-NDA employs two types of negative samples: visually unrealistic images generated from a pre-trained CcGAN and label-inconsistent images created by manipulating real images' labels. Leveraging these negative samples, we introduce a novel discriminator objective alongside a modified CcGAN training algorithm. Empirical analysis on UTKFace and Steering Angle reveals that Dual-NDA consistently enhances the visual fidelity and label consistency of fake images generated by CcGANs, exhibiting a substantial performance gain over the vanilla NDA. Moreover, by applying Dual-NDA, CcGANs demonstrate a remarkable advancement beyond the capabilities of state-of-the-art conditional GANs and diffusion models, establishing a new pinnacle of performance.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Large-Transformers-are-Better-EEG-Learners"><a href="#Large-Transformers-are-Better-EEG-Learners" class="headerlink" title="Large Transformers are Better EEG Learners"></a>Large Transformers are Better EEG Learners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11654">http://arxiv.org/abs/2308.11654</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bingxin Wang, Xiaowen Fu, Yuan Lan, Luchan Zhang, Yang Xiang</li>
<li>for: 这篇论文的目的是探讨如何将预训transformer模型 fine-tune 以适应电enzephalogram（EEG）资料，以提高预测性能。</li>
<li>methods: 本篇论文使用了 AdaCE，即插件和平行对应器，将EEG数据转换为图像和文本形式，以便将预训的vision和language transformer模型 fine-tune 以适应EEG资料。</li>
<li>results: 本篇论文的实验结果显示，使用AdaCE可以将预训的transformer模型 fine-tune 以适应EEG资料，并 achiev 州度之前的最佳性能。例如，AdaCE在预训Swin-Transformer模型时，在人活动识别（UCI HAR）任务中取得了99.6%的准确率，升幅9.2%。此外，我们还证明了，将更大的预训模型 fine-tune 以适应EEG资料，可以获得更好的性能。<details>
<summary>Abstract</summary>
Pre-trained large transformer models have achieved remarkable performance in the fields of natural language processing and computer vision. Since the magnitude of available labeled electroencephalogram (EEG) data is much lower than that of text and image data, it is difficult for transformer models pre-trained from EEG to be developed as large as GPT-4 100T to fully unleash the potential of this architecture. In this paper, we show that transformers pre-trained from images as well as text can be directly fine-tuned for EEG-based prediction tasks. We design AdaCE, plug-and-play Adapters for Converting EEG data into image as well as text forms, to fine-tune pre-trained vision and language transformers. The proposed AdaCE module is highly effective for fine-tuning pre-trained transformers while achieving state-of-the-art performance on diverse EEG-based prediction tasks. For example, AdaCE on the pre-trained Swin-Transformer achieves 99.6%, an absolute improvement of 9.2%, on the EEG-decoding task of human activity recognition (UCI HAR). Furthermore, we empirically show that applying the proposed AdaCE to fine-tune larger pre-trained models can achieve better performance on EEG-based predicting tasks, indicating the potential of our adapters for even larger transformers. The plug-and-play AdaCE module can be applied to fine-tuning most of the popular pre-trained transformers on many other time-series data with multiple channels, not limited to EEG data and the models we use. Our code will be available at https://github.com/wangbxj1234/AdaCE.
</details>
<details>
<summary>摘要</summary>
“将预训大型 трансформа器模型应用于生物类时间序列数据中，具有优异的表现。由于生物类时间序列数据的量较文本和图像数据为低，因此预训自EEG的transformer模型难以发展到GPT-4 100T的水平，以全面发挥这个架构的潜力。本文提出了将图像和文本预训的transformer模型直接调整为EEG数据预测任务的方法。我们设计了 AdaCE，即将EEG数据转换为图像和文本形式的插件，以调整预训的vision和language transformer模型。我们的AdaCE模组具有高效性，可以对预训的transformer模型进行高性能的调整，并在多种EEG预测任务中获得州charts的表现。例如，AdaCE在预训Swin-Transformer上的EEG解oding任务中取得99.6%，相对于原始模型的提升为9.2%。此外，我们还证明了将AdaCE应用于调整更大的预训模型可以在EEG预测任务中获得更好的表现，这表明了我们的插件在更大的transformer模型中的潜力。我们的AdaCE模组可以对多种时间序列数据进行调整，不仅限于EEG数据和我们使用的模型。我们的代码将会在https://github.com/wangbxj1234/AdaCE上公开。”
</details></li>
</ul>
<hr>
<h2 id="Towards-Synthesizing-Datasets-for-IEEE-802-1-Time-sensitive-Networking"><a href="#Towards-Synthesizing-Datasets-for-IEEE-802-1-Time-sensitive-Networking" class="headerlink" title="Towards Synthesizing Datasets for IEEE 802.1 Time-sensitive Networking"></a>Towards Synthesizing Datasets for IEEE 802.1 Time-sensitive Networking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10255">http://arxiv.org/abs/2308.10255</a></li>
<li>repo_url: None</li>
<li>paper_authors: Doğanalp Ergenç, Nurefşan Sertbaş Bülbül, Lisa Maile, Anna Arestova, Mathias Fischer</li>
<li>for: This paper highlights the need for TSN datasets to support research on AI&#x2F;ML-based techniques for TSN systems.</li>
<li>methods: The paper discusses the main requirements and alternative designs for building a TSN platform to synthesize realistic datasets.</li>
<li>results: The paper aims to recapitulate the need for TSN datasets to flourish research on AI&#x2F;ML-based techniques for TSN systems.Here is the text in Simplified Chinese:</li>
<li>for: 这篇论文强调需要TSN数据集，以便为TSN系统中的AI&#x2F;ML技术进行研究。</li>
<li>methods: 论文讨论了TSN平台的主要要求和代理设计，以生成真实的数据集。</li>
<li>results: 论文目的是重点强调TSN数据集的需要，以推动TSN系统中的AI&#x2F;ML技术研究。<details>
<summary>Abstract</summary>
IEEE 802.1 Time-sensitive Networking (TSN) protocols have recently been proposed to replace legacy networking technologies across different mission-critical systems (MCSs). Design, configuration, and maintenance of TSN within MCSs require advanced methods to tackle the highly complex and interconnected nature of those systems. Accordingly, artificial intelligence (AI) and machine learning (ML) models are the most prominent enablers to develop such methods. However, they usually require a significant amount of data for model training, which is not easily accessible. This short paper aims to recapitulate the need for TSN datasets to flourish research on AI/ML-based techniques for TSN systems. Moreover, it analyzes the main requirements and alternative designs to build a TSN platform to synthesize realistic datasets.
</details>
<details>
<summary>摘要</summary>
IEEE 802.1 时间敏感网络（TSN）协议最近被提议用于取代传统网络技术，以满足不同的使命关键系统（MCS）的需求。 TSN 的设计、配置和维护在 MCS 中需要高级的方法来处理这些系统的高度复杂和相互关联的特点。因此，人工智能（AI）和机器学习（ML）模型是TSN 研究的最佳推动力。然而，这些模型通常需要大量数据进行训练，这些数据往往不易获取。这篇短篇论文想要强调TSN 数据的需求，以便鼓励AI/ML 基于技术的TSN 系统研究。此外，它还分析了TSN 平台的主要需求和代替设计，以生成真实的数据集。
</details></li>
</ul>
<hr>
<h2 id="StableLLaVA-Enhanced-Visual-Instruction-Tuning-with-Synthesized-Image-Dialogue-Data"><a href="#StableLLaVA-Enhanced-Visual-Instruction-Tuning-with-Synthesized-Image-Dialogue-Data" class="headerlink" title="StableLLaVA: Enhanced Visual Instruction Tuning with Synthesized Image-Dialogue Data"></a>StableLLaVA: Enhanced Visual Instruction Tuning with Synthesized Image-Dialogue Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10253">http://arxiv.org/abs/2308.10253</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/icoz69/stablellava">https://github.com/icoz69/stablellava</a></li>
<li>paper_authors: Yanda Li, Chi Zhang, Gang Yu, Zhibin Wang, Bin Fu, Guosheng Lin, Chunhua Shen, Ling Chen, Yunchao Wei<br>for:The paper aims to address the limitations of current multimodal Large Language Model (LLM) training methods, specifically the domain bias of image-dialogue datasets.methods:The proposed methodology synchronously synthesizes images and dialogues for visual instruction tuning, leveraging the power of generative models such as ChatGPT and text-to-image models.results:The proposed pipeline leads to marked enhancements in more than ten commonly assessed capabilities of the open-source LLAVA model, including improved performance on various datasets.<details>
<summary>Abstract</summary>
The remarkable multimodal capabilities demonstrated by OpenAI's GPT-4 have sparked significant interest in the development of multimodal Large Language Models (LLMs). A primary research objective of such models is to align visual and textual modalities effectively while comprehending human instructions. Current methodologies often rely on annotations derived from benchmark datasets to construct image-dialogue datasets for training purposes, akin to instruction tuning in LLMs. However, these datasets often exhibit domain bias, potentially constraining the generative capabilities of the models. In an effort to mitigate these limitations, we propose a novel data collection methodology that synchronously synthesizes images and dialogues for visual instruction tuning. This approach harnesses the power of generative models, marrying the abilities of ChatGPT and text-to-image generative models to yield a diverse and controllable dataset with varied image content. This not only provides greater flexibility compared to existing methodologies but also significantly enhances several model capabilities. Our research includes comprehensive experiments conducted on various datasets using the open-source LLAVA model as a testbed for our proposed pipeline. Our results underscore marked enhancements across more than ten commonly assessed capabilities,
</details>
<details>
<summary>摘要</summary>
“OpenAI的GPT-4的多模态能力吸引了大量关注，推动了多模态大语言模型（LLM）的开发。主要研究目标之一是将文字和图像模态有效地规避，并理解人类指令。现有的方法ologies often rely on来自 referential datasets的注釈来构建图像对话集合用于训练purposes，类似于 instruction tuning in LLMs。但这些数据集经常受到领域偏见的限制，可能压缩模型的生成能力。为了缓解这些局限性，我们提出了一种新的数据采集方法，同时生成图像和对话。这种方法利用生成模型的能力，结合ChatGPT和文本到图像生成模型，生成了多样化和可控的数据集。这不仅提供了更大的灵活性，而且显著提高了许多常评价的能力。我们的研究包括对多个数据集使用开源的Lava模型进行了广泛的实验。我们的结果表明，我们的提案的管道显著提高了超过十种常评价的能力。”Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know and I can provide the translation in that form instead.
</details></li>
</ul>
<hr>
<h2 id="Activation-Addition-Steering-Language-Models-Without-Optimization"><a href="#Activation-Addition-Steering-Language-Models-Without-Optimization" class="headerlink" title="Activation Addition: Steering Language Models Without Optimization"></a>Activation Addition: Steering Language Models Without Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10248">http://arxiv.org/abs/2308.10248</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex Turner, Lisa Thiergart, David Udell, Gavin Leech, Ulisse Mini, Monte MacDiarmid</li>
<li>for: 这篇论文目标是控制大型自然语言模型（LLM）的行为。</li>
<li>methods: 该论文提出了一种活动工程（ActAdd）方法，通过在推理时添加激活向量来预测性地改变模型行为。</li>
<li>results: 论文通过在GPT-2上进行实验，表明ActAdd方法可以在OpenWebText和ConceptNet上控制输出的高级特性，而且不会影响目标模型性能。此外，该方法需要远少于精通化或RLHF的计算资源，同时允许用户提供自然语言指令，其开销随 modelo 大小而增加。<details>
<summary>Abstract</summary>
Reliably controlling the behavior of large language models (LLMs) is a pressing open problem. Existing methods include supervised finetuning, reinforcement learning from human feedback (RLHF), prompt engineering and guided decoding. We instead investigate activation engineering: modifying activations at inference time to predictably alter model behavior. In particular, we bias the forward pass with an added 'steering vector' implicitly specified through natural language.   Unlike past work which learned these steering vectors (Subramani, Suresh, and Peters 2022; Hernandez, Li, and Andreas 2023), our Activation Addition (ActAdd) method computes them by taking the activation differences that result from pairs of prompts. We demonstrate ActAdd on GPT-2 on OpenWebText and ConceptNet. Our inference-time approach yields control over high-level properties of output and preserves off-target model performance. It involves far less compute and implementation effort compared to finetuning or RLHF, allows users to provide natural language specifications, and its overhead scales naturally with model size.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）的可靠控制是一个开放的问题。现有的方法包括监督微调、人类反馈学习（RLHF）、提示工程和导航解码。我们则 investigate 活动工程：在推理时修改活动以预测性地改变模型行为。特别是，我们在前进通道添加了一个“导航向量”，这些向量通过自然语言进行隐式定义。与过去的工作不同（Subramani et al. 2022；Hernandez et al. 2023），我们的 Activation Addition（ActAdd）方法不是学习这些导航向量，而是通过对提示对的活动差异来计算它们。我们在 GPT-2 上进行了 ActAdd 测试，并在 OpenWebText 和 ConceptNet 上实现了控制输出的高级属性，同时保持了目标模型性能。这种在推理时进行的方法比 finetuning 或 RLHF 需要更少的计算和实现努力，允许用户通过自然语言指定，并且其开销随 modelo 大小呈线性增长。
</details></li>
</ul>
<hr>
<h2 id="From-Global-to-Local-Multi-scale-Out-of-distribution-Detection"><a href="#From-Global-to-Local-Multi-scale-Out-of-distribution-Detection" class="headerlink" title="From Global to Local: Multi-scale Out-of-distribution Detection"></a>From Global to Local: Multi-scale Out-of-distribution Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10239">http://arxiv.org/abs/2308.10239</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jimzai/mode-ood">https://github.com/jimzai/mode-ood</a></li>
<li>paper_authors: Ji Zhang, Lianli Gao, Bingguang Hao, Hao Huang, Jingkuan Song, Hengtao Shen</li>
<li>for: The paper is written for detecting out-of-distribution (OOD) data in the context of representation learning.</li>
<li>methods: The paper proposes a new framework called Multi-scale OOD DEtection (MODE) that leverages both global visual information and local region details of images to improve OOD detection. The framework includes a new trainable objective called Attention-based Local PropAgation (ALPA) to encourage locally discriminative representations in ID training, and a Cross-Scale Decision (CSD) function to distinguish ID&#x2F;OOD data during test-time.</li>
<li>results: The paper demonstrates the effectiveness and flexibility of MODE on several benchmarks, achieving an average improvement of up to 19.24% in false positive rate (FPR) and 2.77% in area under the receiver operating characteristic curve (AUROC) compared to previous state-of-the-art methods.<details>
<summary>Abstract</summary>
Out-of-distribution (OOD) detection aims to detect "unknown" data whose labels have not been seen during the in-distribution (ID) training process. Recent progress in representation learning gives rise to distance-based OOD detection that recognizes inputs as ID/OOD according to their relative distances to the training data of ID classes. Previous approaches calculate pairwise distances relying only on global image representations, which can be sub-optimal as the inevitable background clutter and intra-class variation may drive image-level representations from the same ID class far apart in a given representation space. In this work, we overcome this challenge by proposing Multi-scale OOD DEtection (MODE), a first framework leveraging both global visual information and local region details of images to maximally benefit OOD detection. Specifically, we first find that existing models pretrained by off-the-shelf cross-entropy or contrastive losses are incompetent to capture valuable local representations for MODE, due to the scale-discrepancy between the ID training and OOD detection processes. To mitigate this issue and encourage locally discriminative representations in ID training, we propose Attention-based Local PropAgation (ALPA), a trainable objective that exploits a cross-attention mechanism to align and highlight the local regions of the target objects for pairwise examples. During test-time OOD detection, a Cross-Scale Decision (CSD) function is further devised on the most discriminative multi-scale representations to distinguish ID/OOD data more faithfully. We demonstrate the effectiveness and flexibility of MODE on several benchmarks -- on average, MODE outperforms the previous state-of-the-art by up to 19.24% in FPR, 2.77% in AUROC. Code is available at https://github.com/JimZAI/MODE-OOD.
</details>
<details>
<summary>摘要</summary>
外部数据检测（OOD）的目标是检测“未知”的数据，其标签在ID（彩色）训练过程中未被见过。现代表各学习技术的进步使得距离基于OOD检测变得更加有力，它通过在ID类型数据的训练过程中计算对应的距离来认定输入数据是ID还是OOD。但是，以前的方法只基于全局图像表示，这可能会导致图像水平的噪声和类别变化，使得ID类型图像在给定的表示空间中被迫分离。在这种情况下，我们提出了多scale OOD检测（MODE）框架，它首次利用全局视觉信息和本地区域细节来最大限度地提高OOD检测。具体来说，我们发现现有的模型通过预训练的架构损失或对比损失来学习的是无法捕捉ID训练过程中的本地表示，这是因为ID训练和OOD检测过程的比例不同。为了解决这个问题并在ID训练过程中吸引更多的本地表示，我们提出了带有对比机制的注意力归一化（ALPA）对象，它可以在ID训练过程中帮助模型学习更多的本地表示。在测试时OOD检测中，我们还提出了十字缩放决策（CSD）函数，用于在最有价值的多级表示上进行ID/OOD数据的更加准确的分类。我们在多个标准 bencmarks 上展示了MODE 的效果和灵活性，其中平均与前一个状态的探测器相比，MODE 的 False Positive Rate 下降了19.24%，AUC ROC 上升了2.77%。代码可以在 https://github.com/JimZAI/MODE-OOD 上获取。
</details></li>
</ul>
<hr>
<h2 id="Thompson-Sampling-for-Real-Valued-Combinatorial-Pure-Exploration-of-Multi-Armed-Bandit"><a href="#Thompson-Sampling-for-Real-Valued-Combinatorial-Pure-Exploration-of-Multi-Armed-Bandit" class="headerlink" title="Thompson Sampling for Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit"></a>Thompson Sampling for Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10238">http://arxiv.org/abs/2308.10238</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shintaro Nakamura, Masashi Sugiyama</li>
<li>for: 解决了多支武器带有不同奖励分布的实用值 combinatorial pure exploration问题（R-CPE-MAB），并提供了一个可靠的算法来解决这个问题。</li>
<li>methods: 使用了一种名为Generalized Thompson Sampling Explore（GenTS-Explore）算法，该算法可以在action set的大小是指数增长的情况下运行，而不是先前的算法假设action set的大小是多项式增长的。</li>
<li>results: 提供了一个问题依赖的样本复杂度下界，并证明了GenTS-Explore算法可以达到最佳样本复杂度下界，即在问题依赖的常数因子下。<details>
<summary>Abstract</summary>
We study the real-valued combinatorial pure exploration of the multi-armed bandit (R-CPE-MAB) problem. In R-CPE-MAB, a player is given $d$ stochastic arms, and the reward of each arm $s\in\{1, \ldots, d\}$ follows an unknown distribution with mean $\mu_s$. In each time step, a player pulls a single arm and observes its reward. The player's goal is to identify the optimal \emph{action} $\boldsymbol{\pi}^{*} = \argmax_{\boldsymbol{\pi} \in \mathcal{A} \boldsymbol{\mu}^{\top}\boldsymbol{\pi}$ from a finite-sized real-valued \emph{action set} $\mathcal{A}\subset \mathbb{R}^{d}$ with as few arm pulls as possible. Previous methods in the R-CPE-MAB assume that the size of the action set $\mathcal{A}$ is polynomial in $d$. We introduce an algorithm named the Generalized Thompson Sampling Explore (GenTS-Explore) algorithm, which is the first algorithm that can work even when the size of the action set is exponentially large in $d$. We also introduce a novel problem-dependent sample complexity lower bound of the R-CPE-MAB problem, and show that the GenTS-Explore algorithm achieves the optimal sample complexity up to a problem-dependent constant factor.
</details>
<details>
<summary>摘要</summary>
我们研究实数值的 combinatorial纯exploration多重抓拍机（R-CPE-MAB）问题。在R-CPE-MAB中，一个玩家被给$d$个随机Arm，每个arm $s\in\{1, \ldots, d\}$的奖励follows未知分布的mean $\mu_s$。在每个时间步骤中，一个玩家抓一个arm并观察其奖励。玩家的目标是从一个有限大小的实数值动作集$\mathcal{A}\subset \mathbb{R}^{d}$中选择最佳动作 $\boldsymbol{\pi}^{*} = \argmax_{\boldsymbol{\pi} \in \mathcal{A} \boldsymbol{\mu}^{\top}\boldsymbol{\pi}$，使用最少的arm pulls。先前的R-CPE-MAB方法假设动作集$\mathcal{A}$的大小是 polynomial in $d$。我们介绍了一个名为Generalized Thompson Sampling Explore（GenTS-Explore）算法，这是第一个可以在动作集的大小是 exponentially large in $d$ 时运行的算法。我们还介绍了一个问题依赖性的样本复杂度下界，并证明GenTS-Explore算法实现了最佳样本复杂度的上界，减去一个问题依赖性的常量因子。
</details></li>
</ul>
<hr>
<h2 id="FedSIS-Federated-Split-Learning-with-Intermediate-Representation-Sampling-for-Privacy-preserving-Generalized-Face-Presentation-Attack-Detection"><a href="#FedSIS-Federated-Split-Learning-with-Intermediate-Representation-Sampling-for-Privacy-preserving-Generalized-Face-Presentation-Attack-Detection" class="headerlink" title="FedSIS: Federated Split Learning with Intermediate Representation Sampling for Privacy-preserving Generalized Face Presentation Attack Detection"></a>FedSIS: Federated Split Learning with Intermediate Representation Sampling for Privacy-preserving Generalized Face Presentation Attack Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10236">http://arxiv.org/abs/2308.10236</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/naiftt/fedsis">https://github.com/naiftt/fedsis</a></li>
<li>paper_authors: Naif Alkhunaizi, Koushik Srivatsan, Faris Almalik, Ibrahim Almakky, Karthik Nandakumar</li>
<li>for: 防止面部攻击探测算法（FacePAD）的 Achilles heel，即缺乏对未见领域&#x2F;攻击的扩展能力。</li>
<li>methods: 联合学习（Federated Learning，FL）和分组学习（Split Learning）的混合方法，以及一个名为“中介表示抽样”的新特点增强技术。</li>
<li>results: 在两个知名的跨领域FacePAD测试集上，证明了无需分享原始数据就可以 achieving state-of-the-art 的扩展性性能。Here’s the detailed summary of the paper:The paper addresses the challenge of lacking generalization to unseen domains&#x2F;attacks in face presentation attack detection (FacePAD) algorithms. Existing methods assume that data from multiple source domains are available for centralized training, but in practice, data from different source domains may be collected by diverse entities who cannot share their data due to legal and privacy constraints. To overcome this problem, the authors propose a novel framework called Federated Split learning with Intermediate representation Sampling (FedSIS).FedSIS combines federated learning (FL) and split learning to achieve robustness against statistical heterogeneity in the client data distributions without any sharing of raw data, thereby preserving privacy. In addition, the authors employ a novel feature augmentation strategy called intermediate representation sampling to further improve generalization to unseen domains. The shared adapter network is used to distill discriminative information from intermediate blocks of a Vision Transformer (ViT).The FedSIS approach is evaluated on two well-known benchmarks for cross-domain FacePAD, and the results demonstrate that it is possible to achieve state-of-the-art generalization performance without data sharing. The code for FedSIS is available on GitHub.<details>
<summary>Abstract</summary>
Lack of generalization to unseen domains/attacks is the Achilles heel of most face presentation attack detection (FacePAD) algorithms. Existing attempts to enhance the generalizability of FacePAD solutions assume that data from multiple source domains are available with a single entity to enable centralized training. In practice, data from different source domains may be collected by diverse entities, who are often unable to share their data due to legal and privacy constraints. While collaborative learning paradigms such as federated learning (FL) can overcome this problem, standard FL methods are ill-suited for domain generalization because they struggle to surmount the twin challenges of handling non-iid client data distributions during training and generalizing to unseen domains during inference. In this work, a novel framework called Federated Split learning with Intermediate representation Sampling (FedSIS) is introduced for privacy-preserving domain generalization. In FedSIS, a hybrid Vision Transformer (ViT) architecture is learned using a combination of FL and split learning to achieve robustness against statistical heterogeneity in the client data distributions without any sharing of raw data (thereby preserving privacy). To further improve generalization to unseen domains, a novel feature augmentation strategy called intermediate representation sampling is employed, and discriminative information from intermediate blocks of a ViT is distilled using a shared adapter network. The FedSIS approach has been evaluated on two well-known benchmarks for cross-domain FacePAD to demonstrate that it is possible to achieve state-of-the-art generalization performance without data sharing. Code: https://github.com/Naiftt/FedSIS
</details>
<details>
<summary>摘要</summary>
缺乏对未经见的领域/攻击的总体化是现有的面呈现攻击检测（FacePAD）算法的 Achilles heel。现有的增强FacePAD解决方案假设可以在单一实体上进行中央化训练，但在实际应用中，数据来源可能是多个不同的实体，这些实体通常因法律和隐私问题无法共享其数据。而合作学习 paradigm such as federated learning（FL）可以解决这个问题，但标准的FL方法在适应不同领域时存在两个主要挑战：处理非标一个客户端数据分布 During training和在推理中适应未经见的领域。在这种情况下，一种新的框架called Federated Split learning with Intermediate representation Sampling（FedSIS）被引入，以保护隐私。在FedSIS中，一个混合的 Computer Vision Transformer（ViT）架构被学习使用分布式学习和分割学习来实现对统计学 heterogeneity 在客户端数据分布中的Robustness，而无需分享Raw数据。为了进一步提高推理中的适应，一种新的特征扩充策略called intermediate representation sampling被采用，并通过一个共享adapter网络来浓缩出ViT中的特征。FedSIS方法在两个常用的 cross-domain FacePADbenchmark上进行评估，以示其可以在不进行数据分享的情况下实现状态的总体化性能。代码：https://github.com/Naiftt/FedSIS
</details></li>
</ul>
<hr>
<h2 id="Karma-Adaptive-Video-Streaming-via-Causal-Sequence-Modeling"><a href="#Karma-Adaptive-Video-Streaming-via-Causal-Sequence-Modeling" class="headerlink" title="Karma: Adaptive Video Streaming via Causal Sequence Modeling"></a>Karma: Adaptive Video Streaming via Causal Sequence Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10230">http://arxiv.org/abs/2308.10230</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fcbw2012/Karma">https://github.com/fcbw2012/Karma</a></li>
<li>paper_authors: Bowei Xu, Hao Chen, Zhan Ma</li>
<li>for: 提高 adaptive bitrate (ABR) 决策的优化，以提高用户体验质量 (QoE)。</li>
<li>methods: 使用 causal sequence modeling 技术，通过考虑过去观察、返回和行动之间的相互关系，以及时地调整行动，以提高 Generalization 性。</li>
<li>results: 在 trace-driven  simulations 和实际场景测试中，karma 比现有的状态艺术 algoritms 表现出优于平均 QoE 提高率为 10.8% 到 18.7%，并且在未看到的网络条件下表现出强大的泛化能力。<details>
<summary>Abstract</summary>
Optimal adaptive bitrate (ABR) decision depends on a comprehensive characterization of state transitions that involve interrelated modalities over time including environmental observations, returns, and actions. However, state-of-the-art learning-based ABR algorithms solely rely on past observations to decide the next action. This paradigm tends to cause a chain of deviations from optimal action when encountering unfamiliar observations, which consequently undermines the model generalization. This paper presents Karma, an ABR algorithm that utilizes causal sequence modeling to improve generalization by comprehending the interrelated causality among past observations, returns, and actions and timely refining action when deviation occurs. Unlike direct observation-to-action mapping, Karma recurrently maintains a multi-dimensional time series of observations, returns, and actions as input and employs causal sequence modeling via a decision transformer to determine the next action. In the input sequence, Karma uses the maximum cumulative future quality of experience (QoE) (a.k.a, QoE-to-go) as an extended return signal, which is periodically estimated based on current network conditions and playback status. We evaluate Karma through trace-driven simulations and real-world field tests, demonstrating superior performance compared to existing state-of-the-art ABR algorithms, with an average QoE improvement ranging from 10.8% to 18.7% across diverse network conditions. Furthermore, Karma exhibits strong generalization capabilities, showing leading performance under unseen networks in both simulations and real-world tests.
</details>
<details>
<summary>摘要</summary>
优化的适应比特率（ABR）决策取决于全面的状态转移，包括时间上的相关Modalities和环境观测。然而，当前的学习型ABR算法仅仅基于过去的观测来决定下一步行动。这种方法可能会导致在不熟悉的观测下链地偏离优化的行动，从而降低模型泛化性。本文介绍了Karma算法，它利用 causal sequence modeling来提高泛化性，通过理解过去观测、返回和行动之间的相关 causality来及时修正偏离。不同于直接观测到行动的映射，Karma使用循环维护一个多维时间序列，并使用 causal sequence modeling via 决策变换来确定下一步行动。在输入序列中，Karma使用最大总共计未来体验质量（QoE）（即QoE-to-go）作为扩展返回信号，该信号在当前网络 conditio 和播放状态基础上定期估计。我们通过跟踪驱动的 simulations 和实际场景测试评估了Karma，并证明其与当前状态的art算法相比，在多种网络条件下表现出较高的QoE提升，平均提升率在10.8%到18.7%之间。此外，Karma表现出了强大的泛化能力，在不看到的网络上也表现出领先的表现。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-powered-Combinatorial-Clock-Auction"><a href="#Machine-Learning-powered-Combinatorial-Clock-Auction" class="headerlink" title="Machine Learning-powered Combinatorial Clock Auction"></a>Machine Learning-powered Combinatorial Clock Auction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10226">http://arxiv.org/abs/2308.10226</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/marketdesignresearch/ml-cca">https://github.com/marketdesignresearch/ml-cca</a></li>
<li>paper_authors: Ermis Soumalias, Jakob Weissteiner, Jakob Heiss, Sven Seuken</li>
<li>for: This paper aims to address the challenge of designing iterative combinatorial auctions (ICAs) in high-dimensional item spaces, where traditional methods are impractical due to the exponential growth of the bundle space.</li>
<li>methods: The paper proposes an ML-powered combinatorial clock auction that elicits information from bidders only via demand queries, which are more practical and less cognitively burdensome than traditional value queries. The paper also presents a novel method for training ML models on demand queries and an efficient method for determining the demand query with the highest clearing potential.</li>
<li>results: The paper experimentally evaluates the ML-based demand query mechanism in several spectrum auction domains and compares it against the most established real-world ICA, the combinatorial clock auction (CCA). The results show that the ML-based mechanism significantly outperforms the CCA in terms of efficiency, achieves higher efficiency in a significantly reduced number of rounds, and exhibits vastly higher clearing potential using linear prices.<details>
<summary>Abstract</summary>
We study the design of iterative combinatorial auctions (ICAs). The main challenge in this domain is that the bundle space grows exponentially in the number of items. To address this, several papers have recently proposed machine learning (ML)-based preference elicitation algorithms that aim to elicit only the most important information from bidders. However, from a practical point of view, the main shortcoming of this prior work is that those designs elicit bidders' preferences via value queries (i.e., ``What is your value for the bundle $\{A,B\}$?''). In most real-world ICA domains, value queries are considered impractical, since they impose an unrealistically high cognitive burden on bidders, which is why they are not used in practice. In this paper, we address this shortcoming by designing an ML-powered combinatorial clock auction that elicits information from the bidders only via demand queries (i.e., ``At prices $p$, what is your most preferred bundle of items?''). We make two key technical contributions: First, we present a novel method for training an ML model on demand queries. Second, based on those trained ML models, we introduce an efficient method for determining the demand query with the highest clearing potential, for which we also provide a theoretical foundation. We experimentally evaluate our ML-based demand query mechanism in several spectrum auction domains and compare it against the most established real-world ICA: the combinatorial clock auction (CCA). Our mechanism significantly outperforms the CCA in terms of efficiency in all domains, it achieves higher efficiency in a significantly reduced number of rounds, and, using linear prices, it exhibits vastly higher clearing potential. Thus, with this paper we bridge the gap between research and practice and propose the first practical ML-powered ICA.
</details>
<details>
<summary>摘要</summary>
我们研究Iterative Combinatorial Auctions（ICA）的设计。ICA的主要挑战在bundlespace exponentiationally grows with the number of items。为解决这个问题，一些最近的论文提出了基于机器学习（ML）的偏好提取算法，以便只提取拍手者的重要信息。然而，从实践角度来看，这些设计都是通过值查询（即“你对合并{$A,B}$的价值是多少？”）来提取拍手者的偏好。在现实世界ICA中，值查询是不实用的，因为它们具有不现实的认知卷积，所以在实践中不被使用。在这篇论文中，我们解决这一缺点，设计了一种基于ML的combined clock auction，该 auction只通过需求查询（即“在价格$p$下，你最有价值的合并哪些ITEMS？”）来提取拍手者的信息。我们做了两个关键的技术贡献：首先，我们提出了一种基于需求查询的ML模型训练方法。其次，基于这些训练过的ML模型，我们引入了一种高效的确定需求查询具有最高清算潜力的方法，并提供了理论基础。我们在多个频谱拍卖领域进行了实验性评估，与现实世界ICA最常用的combined clock auction（CCA）进行了比较。我们的机器学习基于需求查询机制在所有领域中显著高效，在一个明显更少的数量的回合中达到了更高的效率，使用线性价格时，其显示出了极高的清算潜力。因此，我们通过这篇论文，将研究与实践之间的差距 bridge，并提出了实用的ML-powered ICA。
</details></li>
</ul>
<hr>
<h2 id="Soft-Decomposed-Policy-Critic-Bridging-the-Gap-for-Effective-Continuous-Control-with-Discrete-RL"><a href="#Soft-Decomposed-Policy-Critic-Bridging-the-Gap-for-Effective-Continuous-Control-with-Discrete-RL" class="headerlink" title="Soft Decomposed Policy-Critic: Bridging the Gap for Effective Continuous Control with Discrete RL"></a>Soft Decomposed Policy-Critic: Bridging the Gap for Effective Continuous Control with Discrete RL</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10203">http://arxiv.org/abs/2308.10203</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yechen Zhang, Jian Sun, Gang Wang, Zhuo Li, Wei Chen</li>
<li>for: 解决连续控制问题中的维度爆炸问题</li>
<li>methods:  combining soft RL和actor-critic技术，独立地对每个动作维度进行拟合，并使用共享批处理网络来最大化软$Q$-函数</li>
<li>results: 在Mujoco的人型和Box2d的双脚行走任务中，比对当前最佳连续RL算法表现出色，证明了SDPC架构在连续控制问题中的效iveness。<details>
<summary>Abstract</summary>
Discrete reinforcement learning (RL) algorithms have demonstrated exceptional performance in solving sequential decision tasks with discrete action spaces, such as Atari games. However, their effectiveness is hindered when applied to continuous control problems due to the challenge of dimensional explosion. In this paper, we present the Soft Decomposed Policy-Critic (SDPC) architecture, which combines soft RL and actor-critic techniques with discrete RL methods to overcome this limitation. SDPC discretizes each action dimension independently and employs a shared critic network to maximize the soft $Q$-function. This novel approach enables SDPC to support two types of policies: decomposed actors that lead to the Soft Decomposed Actor-Critic (SDAC) algorithm, and decomposed $Q$-networks that generate Boltzmann soft exploration policies, resulting in the Soft Decomposed-Critic Q (SDCQ) algorithm. Through extensive experiments, we demonstrate that our proposed approach outperforms state-of-the-art continuous RL algorithms in a variety of continuous control tasks, including Mujoco's Humanoid and Box2d's BipedalWalker. These empirical results validate the effectiveness of the SDPC architecture in addressing the challenges associated with continuous control.
</details>
<details>
<summary>摘要</summary>
精细激励学习（RL）算法在解决序列决策任务中的逻辑划分空间时表现出色，如Atari游戏。然而，在连续控制问题中，它们的效果受到维度爆炸的挑战。在这篇论文中，我们提出了软分解策略-评估器（SDPC）架构，它将软RL和演员-评估器技术与精细RL方法相结合，以超越这些限制。SDPC独立地对每个动作维度进行粒度化，并使用共享评估器网络来最大化软$Q$-函数。这种新的方法使得SDPC可以支持两种类型的策略：分解演员，导致的软分解演员-评估器（SDAC）算法，以及分解$Q$-网络，生成博尔tz曼软探索策略，导致的软分解评估器Q（SDCQ）算法。经过广泛的实验，我们证明了我们提出的方法在多种连续控制任务中表现出色，包括Mujoco的人形机器人和Box2d的双脚行走器。这些实验结果证明了SDPC架构在连续控制问题中的有效性。
</details></li>
</ul>
<hr>
<h2 id="Hiding-Backdoors-within-Event-Sequence-Data-via-Poisoning-Attacks"><a href="#Hiding-Backdoors-within-Event-Sequence-Data-via-Poisoning-Attacks" class="headerlink" title="Hiding Backdoors within Event Sequence Data via Poisoning Attacks"></a>Hiding Backdoors within Event Sequence Data via Poisoning Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10201">http://arxiv.org/abs/2308.10201</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elizaveta Kovtun, Alina Ermilova, Dmitry Berestnev, Alexey Zaytsev</li>
<li>for: 该论文旨在描述如何在深度学习模型中引入潜在的攻击点，以便在金融业中使用深度学习模型时提高安全性。</li>
<li>methods: 该论文使用了潜在攻击的技术，包括插入后门和模型权重修改等方法，以便在深度学习模型中引入潜在的攻击点。</li>
<li>results: 实验结果表明，在三个开源交易数据集和三种架构（LSTM、CNN和Transformer）上，潜在攻击可以成功地影响深度学习模型的输出。这些结果不仅揭示了当今模型的漏洞，还可以帮助建立更加安全的系统。<details>
<summary>Abstract</summary>
The financial industry relies on deep learning models for making important decisions. This adoption brings new danger, as deep black-box models are known to be vulnerable to adversarial attacks. In computer vision, one can shape the output during inference by performing an adversarial attack called poisoning via introducing a backdoor into the model during training. For sequences of financial transactions of a customer, insertion of a backdoor is harder to perform, as models operate over a more complex discrete space of sequences, and systematic checks for insecurities occur. We provide a method to introduce concealed backdoors, creating vulnerabilities without altering their functionality for uncontaminated data. To achieve this, we replace a clean model with a poisoned one that is aware of the availability of a backdoor and utilize this knowledge. Our most difficult for uncovering attacks include either additional supervised detection step of poisoned data activated during the test or well-hidden model weight modifications. The experimental study provides insights into how these effects vary across different datasets, architectures, and model components. Alternative methods and baselines, such as distillation-type regularization, are also explored but found to be less efficient. Conducted on three open transaction datasets and architectures, including LSTM, CNN, and Transformer, our findings not only illuminate the vulnerabilities in contemporary models but also can drive the construction of more robust systems.
</details>
<details>
<summary>摘要</summary>
金融业务中使用深度学习模型作出重要决策，这种采用带来新的威胁，因为深度黑盒模型容易受到对抗攻击。在计算机视觉领域，可以在推理过程中形成输出的偏误，通过在训练过程中引入一个后门。但是对于金融交易序列的客户数据，插入后门更加困难，因为模型操作在更复杂的逻辑空间上，并且系统性的安全检查会发生。我们提供了一种引入隐藏后门的方法，创造漏洞而无需改变功能性的数据。我们将干净模型换成恶意模型，并利用这种知识。我们的最难于发现攻击包括额外的超visisted检测步骤， Activated During Test，以及隐藏的模型Weight修改。我们的实验研究提供了不同的数据集、结构和模型组件之间如何影响这些效果的深入理解。我们还explored alternative methods和基线，如distillation-type regularization，但发现它们较为不效。我们在三个公开的交易数据集和结构上进行了实验，包括LSTM、CNN和Transformer。我们的发现不仅揭示了当代模型中的漏洞，而且可以驱动建立更加Robust的系统。
</details></li>
</ul>
<hr>
<h2 id="Deep-Reinforcement-Learning-for-Artificial-Upwelling-Energy-Management"><a href="#Deep-Reinforcement-Learning-for-Artificial-Upwelling-Energy-Management" class="headerlink" title="Deep Reinforcement Learning for Artificial Upwelling Energy Management"></a>Deep Reinforcement Learning for Artificial Upwelling Energy Management</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10199">http://arxiv.org/abs/2308.10199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiyuan Zhang, Wei Fan</li>
<li>For: 本研究旨在开发一种基于深度强化学习（DRL）算法的能源管理策略，以提高人工温升系统（AUS）的效率和可持续性。* Methods: 本研究使用DRL算法来开发高效的AUS操作策略，并通过大量的 simulations 来评估其性能。* Results: 研究结果表明，DRL算法可以有效地减少AUS中的能源浪费，并确保系统的稳定和高效运行。此外，DRL算法也比传统的规则编程方法和其他DRL算法更有效。<details>
<summary>Abstract</summary>
The potential of artificial upwelling (AU) as a means of lifting nutrient-rich bottom water to the surface, stimulating seaweed growth, and consequently enhancing ocean carbon sequestration, has been gaining increasing attention in recent years. This has led to the development of the first solar-powered and air-lifted AU system (AUS) in China. However, efficient scheduling of air injection systems remains a crucial challenge in operating AUS, as it holds the potential to significantly improve system efficiency. Conventional approaches based on rules or models are often impractical due to the complex and heterogeneous nature of the marine environment and its associated disturbances. To address this challenge, we propose a novel energy management approach that utilizes deep reinforcement learning (DRL) algorithm to develop efficient strategies for operating AUS. Through extensive simulations, we evaluate the performance of our algorithm and demonstrate its superior effectiveness over traditional rule-based approaches and other DRL algorithms in reducing energy wastage while ensuring the stable and efficient operation of AUS. Our findings suggest that a DRL-based approach offers a promising way for improving the efficiency of AUS and enhancing the sustainability of seaweed cultivation and carbon sequestration in the ocean.
</details>
<details>
<summary>摘要</summary>
人工升采 (AU) 的潜在优势在刚刚几年内得到了越来越多的关注，即通过升采具有营养物质的底层水到表层，促进海藻生长，并因此提高海洋碳储存。在中国，已经开发了第一个阳光动力和空气升采系统 (AUS)。然而，AU系统的有效调度仍然是一个关键挑战，因为它可以大幅提高系统的效率。传统的方法，如规则或模型，经常因marine环境的复杂和多样性而成为不实际。为解决这个挑战，我们提出了一种新的能源管理方法，利用深度强化学习 (DRL) 算法来开发有效的AU系统操作策略。通过广泛的 simulations，我们评估了我们的算法的性能，并证明它在降低能源浪费的同时，保证AU系统的稳定和高效操作。我们的发现表明，使用DRL算法可以有效地提高AU系统的效率，并推动海洋中的海藻培养和碳储存的可持续发展。
</details></li>
</ul>
<hr>
<h2 id="ProSpire-Proactive-Spatial-Prediction-of-Radio-Environment-Using-Deep-Learning"><a href="#ProSpire-Proactive-Spatial-Prediction-of-Radio-Environment-Using-Deep-Learning" class="headerlink" title="ProSpire: Proactive Spatial Prediction of Radio Environment Using Deep Learning"></a>ProSpire: Proactive Spatial Prediction of Radio Environment Using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10193">http://arxiv.org/abs/2308.10193</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shamik Sarkar, Dongning Guo, Danijela Cabric<br>for: 这篇论文旨在提供一种基于深度学习的批处理框架，以实现频率分享。methods: 该框架利用了人群协助，在常规操作过程中收集数据，并使用深度学习的图像到图像翻译方法（RSSu-net）进行预测。results: 论文的实验结果表明，RSSu-net可以准确预测信号强度水平，其Error Mean Absolute Percentage（EMA）为5dB，与其他相关方法相当。此外，RSSu-net可以为 transmitter 创建 проaktiv 的预测边界，使其Activation 的概率达97%，在预测频率分享方面表现出19%的提升。<details>
<summary>Abstract</summary>
Spatial prediction of the radio propagation environment of a transmitter can assist and improve various aspects of wireless networks. The majority of research in this domain can be categorized as 'reactive' spatial prediction, where the predictions are made based on a small set of measurements from an active transmitter whose radio environment is to be predicted. Emerging spectrum-sharing paradigms would benefit from 'proactive' spatial prediction of the radio environment, where the spatial predictions must be done for a transmitter for which no measurement has been collected.   This paper proposes a novel, supervised deep learning-based framework, ProSpire, that enables spectrum sharing by leveraging the idea of proactive spatial prediction. We carefully address several challenges in ProSpire, such as designing a framework that conveniently collects training data for learning, performing the predictions in a fast manner, enabling operations without an area map, and ensuring that the predictions do not lead to undesired interference. ProSpire relies on the crowdsourcing of transmitters and receivers during their normal operations to address some of the aforementioned challenges. The core component of ProSpire is a deep learning-based image-to-image translation method, which we call RSSu-net. We generate several diverse datasets using ray tracing software and numerically evaluate ProSpire. Our evaluations show that RSSu-net performs reasonably well in terms of signal strength prediction, 5 dB mean absolute error, which is comparable to the average error of other relevant methods. Importantly, due to the merits of RSSu-net, ProSpire creates proactive boundaries around transmitters such that they can be activated with 97% probability of not causing interference. In this regard, the performance of RSSu-net is 19% better than that of other comparable methods.
</details>
<details>
<summary>摘要</summary>
通过预测发射器的广播环境，可以提高无线网络的多个方面。大多数研究在这个领域可以分为“反应性”的广播环境预测，其中预测基于活跃发射器的一小部分测量数据。新兴的spectrum-sharing paradigms需要“主动”的广播环境预测，其中预测是基于没有测量数据的发射器。这篇论文提出了一种新的、 надёжный深度学习基本框架——ProSpire，以便启用spectrum-sharing。我们在ProSpire中谨慎地解决了多个挑战，例如设计一个框架可以方便地收集教程数据，在快速模式下进行预测，不需要地图，并确保预测不会导致不良干扰。ProSpire利用发射器和接收器在正常操作中的拥有者协助来解决一些上述挑战。ProSpire的核心 ком成分是一种基于深度学习的图像到图像翻译方法，我们称之为RSSu-net。我们使用RAY tracing软件生成了多个多样化的数据集，并 numerically evaluates ProSpire。我们的评估表明，RSSu-net在信号强度预测方面的性能 reasonably well，相对于其他相关方法的平均错误率为5dB。此外，由于RSSu-net的优点，ProSpire可以创建主动的边界，使发射器在97%的概率下不会导致干扰。在这个方面，RSSu-net的性能比其他相似方法高19%。
</details></li>
</ul>
<hr>
<h2 id="Mimicking-To-Dominate-Imitation-Learning-Strategies-for-Success-in-Multiagent-Competitive-Games"><a href="#Mimicking-To-Dominate-Imitation-Learning-Strategies-for-Success-in-Multiagent-Competitive-Games" class="headerlink" title="Mimicking To Dominate: Imitation Learning Strategies for Success in Multiagent Competitive Games"></a>Mimicking To Dominate: Imitation Learning Strategies for Success in Multiagent Competitive Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10188">http://arxiv.org/abs/2308.10188</a></li>
<li>repo_url: None</li>
<li>paper_authors: The Viet Bui, Tien Mai, Thanh Hong Nguyen<br>for: 这项研究的目的是解决多体游戏中的训练问题，特别是因为环境和对手的策略的影响而导致的不确定性。methods: 这项研究使用了模仿学习来理解和预测对手的行为，以减少不确定性。具体来说，他们提出了一种新的多体游戏模仿学习模型，可以预测对手的下一步行动，并将这种模型与策略训练结合在一起。results: 实验结果显示，该方法在三个复杂的游戏环境中表现出优于现有state-of-the-art多体游戏RL算法。<details>
<summary>Abstract</summary>
Training agents in multi-agent competitive games presents significant challenges due to their intricate nature. These challenges are exacerbated by dynamics influenced not only by the environment but also by opponents' strategies. Existing methods often struggle with slow convergence and instability. To address this, we harness the potential of imitation learning to comprehend and anticipate opponents' behavior, aiming to mitigate uncertainties with respect to the game dynamics. Our key contributions include: (i) a new multi-agent imitation learning model for predicting next moves of the opponents -- our model works with hidden opponents' actions and local observations; (ii) a new multi-agent reinforcement learning algorithm that combines our imitation learning model and policy training into one single training process; and (iii) extensive experiments in three challenging game environments, including an advanced version of the Star-Craft multi-agent challenge (i.e., SMACv2). Experimental results show that our approach achieves superior performance compared to existing state-of-the-art multi-agent RL algorithms.
</details>
<details>
<summary>摘要</summary>
培训多体智能机器人在多体竞争游戏中存在严重的挑战，这些挑战由环境以及对手策略的影响强化。现有方法经常受到慢 converges 和不稳定的问题困扰。为解决这些问题，我们利用仿制学来理解和预测对手的行为，以降低对游戏动力学的不确定性。我们的关键贡献包括：1. 一种新的多体仿制学模型，用于预测对手下一步的行动——我们的模型可以处理隐藏的对手行动和本地观察;2. 一种新的多体强化学习算法，将我们的仿制学模型和策略训练结合在一起;3. 在三个复杂游戏环境中进行了广泛的实验，包括星际战II（SMACv2）的高级版本。实验结果表明，我们的方法在现有状态艺术多体RL算法中显示出优于性能。
</details></li>
</ul>
<hr>
<h2 id="Quantization-based-Optimization-with-Perspective-of-Quantum-Mechanics"><a href="#Quantization-based-Optimization-with-Perspective-of-Quantum-Mechanics" class="headerlink" title="Quantization-based Optimization with Perspective of Quantum Mechanics"></a>Quantization-based Optimization with Perspective of Quantum Mechanics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11594">http://arxiv.org/abs/2308.11594</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinwuk Seok, Changsik Cho</li>
<li>for: 本研究探讨了基于量子力学的全球优化算法的新研究框架。</li>
<li>methods: 本研究使用了量子化基于Schrödinger方程的优化方法，并通过对这些方法的分析，揭示了量子力学中允许全球优化的性质。</li>
<li>results: 研究发现，基于量子力学的优化方法中的穿透效应，允许逃脱本地最优点。此外，这种穿透效应与量子力学基于全球优化的性质相同。实验结果表明，提出的分析是正确的。<details>
<summary>Abstract</summary>
Statistical and stochastic analysis based on thermodynamics has been the main analysis framework for stochastic global optimization. Recently, appearing quantum annealing or quantum tunneling algorithm for global optimization, we require a new researching framework for global optimization algorithms. In this paper, we provide the analysis for quantization-based optimization based on the Schr\"odinger equation to reveal what property in quantum mechanics enables global optimization. We present that the tunneling effect derived by the Schr\"odinger equation in quantization-based optimization enables to escape of a local minimum. Additionally, we confirm that this tunneling effect is the same property included in quantum mechanics-based global optimization. Experiments with standard multi-modal benchmark functions represent that the proposed analysis is valid.
</details>
<details>
<summary>摘要</summary>
统计和随机分析基于 термодина学已经是全球优化的主要分析框架。最近，出现了量子气化或量子逃逸算法用于全球优化，我们需要一个新的研究框架来研究全球优化算法。在这篇论文中，我们提供了量子化基于Schrödinger方程的优化分析，以探索量子力学中允许全球优化的性质。我们发现，量子化中的逃逸效应使得可以跃出本地最小值。此外，我们证明这种逃逸效应与量子力学基于全球优化中的性质相同。实验使用标准多模函数表示，我们的分析是有效的。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Client-Drift-in-Federated-Learning-A-Logit-Perspective"><a href="#Rethinking-Client-Drift-in-Federated-Learning-A-Logit-Perspective" class="headerlink" title="Rethinking Client Drift in Federated Learning: A Logit Perspective"></a>Rethinking Client Drift in Federated Learning: A Logit Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10162">http://arxiv.org/abs/2308.10162</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunlu Yan, Chun-Mei Feng, Mang Ye, Wangmeng Zuo, Ping Li, Rick Siow Mong Goh, Lei Zhu, C. L. Philip Chen</li>
<li>For: The paper focuses on addressing the issue of client drift in Federated Learning (FL) caused by non-IID data, which degrades the performance of FL.* Methods: The proposed method, called FedCSD, uses class prototype similarity distillation to align local logits with refined global logits weighted by the similarity between local logits and the global prototype. Additionally, an adaptive mask is used to filter out terrible soft labels of global models to prevent them from misleading local optimization.* Results: The proposed method outperforms state-of-the-art federated learning approaches in various heterogeneous settings, as demonstrated by extensive experiments.Here is the same information in Simplified Chinese:* For: 论文旨在解决 Federated Learning (FL) 中客户端漂移问题，即因异步数据导致 FL 性能下降。* Methods: 提议的方法是 FedCSD，它使用类prototype相似抽象来协调本地logits与重视类 prototype 的全局模型。此外，适应性 másc 用于筛选全局模型的差异 Soft Label，以避免它们导致本地优化的干扰。* Results: 比较 experiments 表明，提议的方法在多种不同的设置下表现出色，超过了现有的 Federated Learning 方法。I hope that helps!<details>
<summary>Abstract</summary>
Federated Learning (FL) enables multiple clients to collaboratively learn in a distributed way, allowing for privacy protection. However, the real-world non-IID data will lead to client drift which degrades the performance of FL. Interestingly, we find that the difference in logits between the local and global models increases as the model is continuously updated, thus seriously deteriorating FL performance. This is mainly due to catastrophic forgetting caused by data heterogeneity between clients. To alleviate this problem, we propose a new algorithm, named FedCSD, a Class prototype Similarity Distillation in a federated framework to align the local and global models. FedCSD does not simply transfer global knowledge to local clients, as an undertrained global model cannot provide reliable knowledge, i.e., class similarity information, and its wrong soft labels will mislead the optimization of local models. Concretely, FedCSD introduces a class prototype similarity distillation to align the local logits with the refined global logits that are weighted by the similarity between local logits and the global prototype. To enhance the quality of global logits, FedCSD adopts an adaptive mask to filter out the terrible soft labels of the global models, thereby preventing them to mislead local optimization. Extensive experiments demonstrate the superiority of our method over the state-of-the-art federated learning approaches in various heterogeneous settings. The source code will be released.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 允许多个客户端共同学习，以保护隐私。然而，实际世界中的非相同数据会导致客户端漂移，从而下降FL的性能。奇怪的是，我们发现，在模型不断更新后，本地和全球模型之间的差异在增加，这会严重降低FL的性能。这主要是因为数据不同性导致的忘记抛弃。为了解决这个问题，我们提出了一种新的算法，名为FedCSD，即在 federated 框架中进行类prototype相似液化。FedCSD不simply将全球知识传递给本地客户端，因为一个未经训练的全球模型无法提供可靠的知识，即类相似信息，而其假软标签会mislead本地优化。具体来说，FedCSD引入一种类prototype相似液化，将本地征值与全球prototype之间的相似性进行对齐。为了提高全球征值的质量，FedCSD采用了一个适应性的面罩，从而防止全球模型的假软标签对本地优化产生负面影响。我们的实验表明，我们的方法在不同的各种各样的设置下比现状的联邦学习方法表现出色。代码将于发布。
</details></li>
</ul>
<hr>
<h2 id="Resource-Adaptive-Newton’s-Method-for-Distributed-Learning"><a href="#Resource-Adaptive-Newton’s-Method-for-Distributed-Learning" class="headerlink" title="Resource-Adaptive Newton’s Method for Distributed Learning"></a>Resource-Adaptive Newton’s Method for Distributed Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10154">http://arxiv.org/abs/2308.10154</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuzhen Chen, Yuan Yuan, Youming Tao, Zhipeng Cai, Dongxiao Yu</li>
<li>for: 这篇论文旨在提出一种高效的分布式数据优化方法，以优化对数学运算和通信成本的构成。</li>
<li>methods: 这篇论文使用了新顿法，并将其与分布式环境整合，以解决实际应用中的高计算和通信成本问题。</li>
<li>results: 论文显示了这种新方法可以实现高效的线性传播速率，并且可以适应可用资源和高效率。它还可以轻松地减少问题的条件数量，并且不需要复杂的参数调整。<details>
<summary>Abstract</summary>
Distributed stochastic optimization methods based on Newton's method offer significant advantages over first-order methods by leveraging curvature information for improved performance. However, the practical applicability of Newton's method is hindered in large-scale and heterogeneous learning environments due to challenges such as high computation and communication costs associated with the Hessian matrix, sub-model diversity, staleness in training, and data heterogeneity. To address these challenges, this paper introduces a novel and efficient algorithm called RANL, which overcomes the limitations of Newton's method by employing a simple Hessian initialization and adaptive assignments of training regions. The algorithm demonstrates impressive convergence properties, which are rigorously analyzed under standard assumptions in stochastic optimization. The theoretical analysis establishes that RANL achieves a linear convergence rate while effectively adapting to available resources and maintaining high efficiency. Unlike traditional first-order methods, RANL exhibits remarkable independence from the condition number of the problem and eliminates the need for complex parameter tuning. These advantages make RANL a promising approach for distributed stochastic optimization in practical scenarios.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Global-Warming-In-Ghana’s-Major-Cities-Based-on-Statistical-Analysis-of-NASA’s-POWER-Over-3-Decades"><a href="#Global-Warming-In-Ghana’s-Major-Cities-Based-on-Statistical-Analysis-of-NASA’s-POWER-Over-3-Decades" class="headerlink" title="Global Warming In Ghana’s Major Cities Based on Statistical Analysis of NASA’s POWER Over 3-Decades"></a>Global Warming In Ghana’s Major Cities Based on Statistical Analysis of NASA’s POWER Over 3-Decades</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10909">http://arxiv.org/abs/2308.10909</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joshua Attih</li>
<li>for: 本研究旨在探讨加纳四大城市的长期气温趋势，以提高气候变化策略的理解。</li>
<li>methods: 研究使用NASA的Prediction of Worldwide Energy Resource（POWER）数据进行统计分析，以评估当地气候变化的趋势。 Linear regression 特征分析和eXtreme Gradient Boosting（XGBoost）机器学习方法预测气温变化。 RSLab平台生成的Land Surface Temperature（LST）profile图表提高了准确性。</li>
<li>results: 研究发现当地气温趋势，尤其是工业化的阿克拉地区。 人口density不是关键因素。 XGBoost模型的低Root Mean Square Error（RMSE）得分表明其能够准确捕捉气温趋势。 瓦 unexpectedly有最高的平均气温（30.76℃）。 预测2023年中的气温为：阿克拉27.86℃，库马西27.15℃，基特-克拉chi29.39℃，瓦30.76℃。<details>
<summary>Abstract</summary>
Global warming's impact on high temperatures in various parts of the world has raised concerns. This study investigates long-term temperature trends in four major Ghanaian cities representing distinct climatic zones. Using NASA's Prediction of Worldwide Energy Resource (POWER) data, statistical analyses assess local climate warming and its implications. Linear regression trend analysis and eXtreme Gradient Boosting (XGBoost) machine learning predict temperature variations. Land Surface Temperature (LST) profile maps generated from the RSLab platform enhance accuracy. Results reveal local warming trends, particularly in industrialized Accra. Demographic factors aren't significant. XGBoost model's low Root Mean Square Error (RMSE) scores demonstrate effectiveness in capturing temperature patterns. Wa unexpectedly has the highest mean temperature. Estimated mean temperatures for mid-2023 are: Accra 27.86{\deg}C, Kumasi 27.15{\deg}C, Kete-Krachi 29.39{\deg}C, and Wa 30.76{\deg}C. These findings improve understanding of local climate warming for policymakers and communities, aiding climate change strategies.
</details>
<details>
<summary>摘要</summary>
全球变暖对各地高温的影响已引起关注。这项研究研究了加纳四大城市的长期温度趋势，代表不同气候区。使用NASA的Prediction of Worldwide Energy Resource（POWER）数据，统计分析评估地方气候变暖和其意义。线性回归趋势分析和Machine Learning的eXtreme Gradient Boosting（XGBoost）模型预测温度变化。RSLab平台生成的Land Surface Temperature（LST）profile图表提高了准确性。结果显示了地方温升趋势，特别是工业化的Accra。人口因素不显著。XGBoost模型的低Root Mean Square Error（RMSE）分数表明其能够准确捕捉温度模式。意外地，Wa市有最高的mean温度。预计2023年中期的Accra温度为27.86℃，Kumasi温度为27.15℃，Kete-Krachi温度为29.39℃，Wa温度为30.76℃。这些发现可以帮助政策 makers和社区更好地理解本地气候变化，提高气候变化策略。
</details></li>
</ul>
<hr>
<h2 id="OCHID-Fi-Occlusion-Robust-Hand-Pose-Estimation-in-3D-via-RF-Vision"><a href="#OCHID-Fi-Occlusion-Robust-Hand-Pose-Estimation-in-3D-via-RF-Vision" class="headerlink" title="OCHID-Fi: Occlusion-Robust Hand Pose Estimation in 3D via RF-Vision"></a>OCHID-Fi: Occlusion-Robust Hand Pose Estimation in 3D via RF-Vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10146">http://arxiv.org/abs/2308.10146</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shujie Zhang, Tianyue Zheng, Zhe Chen, Jingzhi Hu, Abdelwahed Khamis, Jiajun Liu, Jun Luo</li>
<li>For: The paper proposes a new method for hand pose estimation (HPE) that can overcome the limitations of cameras-based methods, which are subject to Line-of-Sight (LoS) and cannot capture occluded objects.* Methods: The proposed method, called OCHID-Fi, uses radio-frequency-vision (RF-vision) to bypass obstacles and achieve occluded HPE. It employs wideband RF sensors widely available on smart devices to probe 3D human hand pose and extract their skeletons behind obstacles. To overcome the challenge in labeling RF imaging, OCHID-Fi uses a cross-modality and cross-domain training process that combines a pre-trained CM-HPE network and a synchronized CM&#x2F;RF dataset.* Results: The paper demonstrates the superiority of OCHID-Fi through experimental results, showing that it achieves comparable accuracy to cameras-based HPE under normal conditions while maintaining such accuracy even in occluded scenarios, with empirical evidence for its generalizability to new domains.Here is the simplified Chinese text for the three key points:* For: 这篇论文提出了一种新的手势估计（HPE）方法，可以超越传统摄像头基于方法的限制，该方法不能捕捉障碍物。* Methods: 该方法使用无线电频视（RF-vision）绕过障碍物实现 occluded HPE，并使用各种智能设备（如 iPhone）上广泛可用的宽频 RF 感知器探测3D人手势和其后方障碍物。* Results: 论文通过实验结果显示，OCHID-Fi 可以在正常情况下与摄像头基于方法相比具有相同的准确率，而且在障碍物情况下仍然保持相同的准确率，并且在新领域中进行了实质性的推广。<details>
<summary>Abstract</summary>
Hand Pose Estimation (HPE) is crucial to many applications, but conventional cameras-based CM-HPE methods are completely subject to Line-of-Sight (LoS), as cameras cannot capture occluded objects. In this paper, we propose to exploit Radio-Frequency-Vision (RF-vision) capable of bypassing obstacles for achieving occluded HPE, and we introduce OCHID-Fi as the first RF-HPE method with 3D pose estimation capability. OCHID-Fi employs wideband RF sensors widely available on smart devices (e.g., iPhones) to probe 3D human hand pose and extract their skeletons behind obstacles. To overcome the challenge in labeling RF imaging given its human incomprehensible nature, OCHID-Fi employs a cross-modality and cross-domain training process. It uses a pre-trained CM-HPE network and a synchronized CM/RF dataset, to guide the training of its complex-valued RF-HPE network under LoS conditions. It further transfers knowledge learned from labeled LoS domain to unlabeled occluded domain via adversarial learning, enabling OCHID-Fi to generalize to unseen occluded scenarios. Experimental results demonstrate the superiority of OCHID-Fi: it achieves comparable accuracy to CM-HPE under normal conditions while maintaining such accuracy even in occluded scenarios, with empirical evidence for its generalizability to new domains.
</details>
<details>
<summary>摘要</summary>
手势识别（HPE）对许多应用程序是关键，但传统的相机基于CM-HPE方法是完全依赖于直线视野（LoS），因为相机无法捕捉遮盖物体。在这篇论文中，我们提议利用无线电视视野（RF-vision），以绕过障碍物实现遮盖物体HPE，并引入了OCHID-Fi作为首个RF-HPE方法，具有3D手势 pose estimation能力。OCHID-Fi使用常见的宽频RF传感器（例如iPhone上的RF传感器）探测3D人类手势pose并提取其骨架。为了解决RF成像的标注挑战，OCHID-Fi采用了交叉模态和交叉领域的训练过程。它使用一个预训练的CM-HPE网络和一个同步CM/RF数据集，以导引其复杂的RF-HPE网络在LoS条件下进行训练。它还通过对LoS频谱域的标注数据进行反向学习，使得OCHID-Fi能够在未看到障碍物的情况下保持同等精度。实验结果表明，OCHID-Fi具有优于CM-HPE的优势：在正常情况下和障碍情况下都可以保持同等精度，并且在新领域中进行扩展。
</details></li>
</ul>
<hr>
<h2 id="Wasserstein-Geodesic-Generator-for-Conditional-Distributions"><a href="#Wasserstein-Geodesic-Generator-for-Conditional-Distributions" class="headerlink" title="Wasserstein Geodesic Generator for Conditional Distributions"></a>Wasserstein Geodesic Generator for Conditional Distributions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10145">http://arxiv.org/abs/2308.10145</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kyg0910/wasserstein-geodesic-generator-for-conditional-distributions">https://github.com/kyg0910/wasserstein-geodesic-generator-for-conditional-distributions</a></li>
<li>paper_authors: Young-geun Kim, Kyungbok Lee, Youngwon Choi, Joong-Ho Won, Myunghee Cho Paik</li>
<li>for: 这篇论文的目的是提出一种新的条件生成算法，用于生成基于不同频率的数据中的条件数据。</li>
<li>methods: 这篇论文使用估计条件分布的方法，包括 derivation of tractable upper bound of Wasserstein distance between conditional distributions，以及使用 optimal transport theory 提出的 Wasserstein geodesic generator。</li>
<li>results: 这篇论文的实验结果显示，提出的条件生成算法可以将 conditional distributions given observed domains 和 unobserved intermediate domains 连接起来，并且可以learns both conditional distributions for observed domains and optimal transport maps between them。<details>
<summary>Abstract</summary>
Generating samples given a specific label requires estimating conditional distributions. We derive a tractable upper bound of the Wasserstein distance between conditional distributions to lay the theoretical groundwork to learn conditional distributions. Based on this result, we propose a novel conditional generation algorithm where conditional distributions are fully characterized by a metric space defined by a statistical distance. We employ optimal transport theory to propose the Wasserstein geodesic generator, a new conditional generator that learns the Wasserstein geodesic. The proposed method learns both conditional distributions for observed domains and optimal transport maps between them. The conditional distributions given unobserved intermediate domains are on the Wasserstein geodesic between conditional distributions given two observed domain labels. Experiments on face images with light conditions as domain labels demonstrate the efficacy of the proposed method.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将给定文本翻译成简化中文。<</SYS>>生成样本需要估计条件分布。我们 derivates a tractable upper bound of Wasserstein distance between conditional distributions, laying the theoretical groundwork to learn conditional distributions。 Based on this result, we propose a novel conditional generation algorithm, where conditional distributions are fully characterized by a metric space defined by a statistical distance。 We employ optimal transport theory to propose the Wasserstein geodesic generator, a new conditional generator that learns the Wasserstein geodesic。 The proposed method learns both conditional distributions for observed domains and optimal transport maps between them。 The conditional distributions given unobserved intermediate domains are on the Wasserstein geodesic between conditional distributions given two observed domain labels。 Experiments on face images with light conditions as domain labels demonstrate the efficacy of the proposed method。Note: The translation is in Simplified Chinese, which is one of the two standard versions of Chinese used in mainland China. The other version is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="ExpeL-LLM-Agents-Are-Experiential-Learners"><a href="#ExpeL-LLM-Agents-Are-Experiential-Learners" class="headerlink" title="ExpeL: LLM Agents Are Experiential Learners"></a>ExpeL: LLM Agents Are Experiential Learners</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10144">http://arxiv.org/abs/2308.10144</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Andrewzh112/ExpeL">https://github.com/Andrewzh112/ExpeL</a></li>
<li>paper_authors: Andrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, Gao Huang</li>
<li>for: 这个论文的目的是提出一种新的机器学习方法，帮助机器学习模型在决策任务中学习和提高表现。</li>
<li>methods: 这个论文使用的方法是基于自然语言处理技术，通过自动收集经验和提取知识来让机器学习模型在决策任务中学习和提高表现。</li>
<li>results: 论文的实验结果表明，使用这种方法可以帮助机器学习模型在决策任务中表现更好，并且随着经验的积累，模型的性能会越来越好。<details>
<summary>Abstract</summary>
The recent surge in research interest in applying large language models (LLMs) to decision-making tasks has flourished by leveraging the extensive world knowledge embedded in LLMs. While there is a growing demand to tailor LLMs for custom decision-making tasks, finetuning them for specific tasks is resource-intensive and may diminish the model's generalization capabilities. Moreover, state-of-the-art language models like GPT-4 and Claude are primarily accessible through API calls, with their parametric weights remaining proprietary and unavailable to the public. This scenario emphasizes the growing need for new methodologies that allow learning from agent experiences without requiring parametric updates. To address these problems, we introduce the Experiential Learning (ExpeL) agent. Our agent autonomously gathers experiences and extracts knowledge using natural language from a collection of training tasks. At inference, the agent recalls its extracted insights and past experiences to make informed decisions. Our empirical results highlight the robust learning efficacy of the ExpeL agent, indicating a consistent enhancement in its performance as it accumulates experiences. We further explore the emerging capabilities and transfer learning potential of the ExpeL agent through qualitative observations and additional experiments.
</details>
<details>
<summary>摘要</summary>
Recent research has seen a surge in interest in applying large language models (LLMs) to decision-making tasks, leveraging the extensive world knowledge embedded in LLMs. However, finetuning them for specific tasks is resource-intensive and may diminish the model's generalization capabilities. Moreover, state-of-the-art language models like GPT-4 and Claude are primarily accessible through API calls, with their parametric weights remaining proprietary and unavailable to the public. In response to these challenges, we introduce the Experiential Learning (ExpeL) agent.Our agent autonomously gathers experiences and extracts knowledge using natural language from a collection of training tasks. At inference, the agent recalls its extracted insights and past experiences to make informed decisions. Our empirical results show that the ExpeL agent exhibits robust learning efficacy, with consistent enhancements in its performance as it accumulates experiences. We also explore the emerging capabilities and transfer learning potential of the ExpeL agent through qualitative observations and additional experiments.
</details></li>
</ul>
<hr>
<h2 id="A-Review-on-Objective-Driven-Artificial-Intelligence"><a href="#A-Review-on-Objective-Driven-Artificial-Intelligence" class="headerlink" title="A Review on Objective-Driven Artificial Intelligence"></a>A Review on Objective-Driven Artificial Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10135">http://arxiv.org/abs/2308.10135</a></li>
<li>repo_url: None</li>
<li>paper_authors: Apoorv Singh</li>
<li>for: 论文旨在探讨人工智能和人类智能之间的差距，以及如何使用 Hierarchical planning-based 方法和能量基的方法来填补这些差距。</li>
<li>methods: 论文使用了多种人工智能技术，包括supervised learning、reinforcement learning、self-supervised learning等，并对这些方法的局限性进行了批判。</li>
<li>results: 论文表明，使用 Hierarchical planning-based 方法和能量基的方法可以有效地填补人工智能和人类智能之间的差距，并提供了一些可能的解决方案。<details>
<summary>Abstract</summary>
While advancing rapidly, Artificial Intelligence still falls short of human intelligence in several key aspects due to inherent limitations in current AI technologies and our understanding of cognition. Humans have an innate ability to understand context, nuances, and subtle cues in communication, which allows us to comprehend jokes, sarcasm, and metaphors. Machines struggle to interpret such contextual information accurately. Humans possess a vast repository of common-sense knowledge that helps us make logical inferences and predictions about the world. Machines lack this innate understanding and often struggle with making sense of situations that humans find trivial. In this article, we review the prospective Machine Intelligence candidates, a review from Prof. Yann LeCun, and other work that can help close this gap between human and machine intelligence. Specifically, we talk about what's lacking with the current AI techniques such as supervised learning, reinforcement learning, self-supervised learning, etc. Then we show how Hierarchical planning-based approaches can help us close that gap and deep-dive into energy-based, latent-variable methods and Joint embedding predictive architecture methods.
</details>
<details>
<summary>摘要</summary>
Artificial Intelligence 在发展迅速的同时，仍然缺乏人工智能在一些关键方面的能力，这主要归结于当前的 AI 技术和我们认知心理学的限制。人类具有内生的能力来理解上下文、含义和微妙的通信缺失，这使得我们能够理解笑话、讽刺和 мета喻。机器则困难准确地理解上下文信息。人类拥有庞大的常识知识库，这 помо助我们作出逻辑的推理和世界上的预测。机器缺乏这种内生的理解，经常对人类觉得懵逼的情况下发。在这篇文章中，我们评论了目前的机器智能候选人选，包括 Prof. Yann LeCun 的评论以及其他的工作，以帮助将人类和机器智能之间的差距降低。我们首先介绍了当前 AI 技术的缺陷，如监督学习、奖励学习、自监学习等。然后，我们详细介绍了层次规划基础方法，如能量基础、隐变量方法和联合嵌入预测建筑方法，以帮助我们关闭人类和机器智能之间的差距。
</details></li>
</ul>
<hr>
<h2 id="AutoReP-Automatic-ReLU-Replacement-for-Fast-Private-Network-Inference"><a href="#AutoReP-Automatic-ReLU-Replacement-for-Fast-Private-Network-Inference" class="headerlink" title="AutoReP: Automatic ReLU Replacement for Fast Private Network Inference"></a>AutoReP: Automatic ReLU Replacement for Fast Private Network Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10134">http://arxiv.org/abs/2308.10134</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/harveyp123/autorep">https://github.com/harveyp123/autorep</a></li>
<li>paper_authors: Hongwu Peng, Shaoyi Huang, Tong Zhou, Yukui Luo, Chenghong Wang, Zigeng Wang, Jiahui Zhao, Xi Xie, Ang Li, Tony Geng, Kaleel Mahmood, Wujie Wen, Xiaolin Xu, Caiwen Ding</li>
<li>for: 提高机器学习服务市场中客户数据隐私和安全问题的解决方案。</li>
<li>methods: 使用 криптографических primitives 的私有推理（PI）技术，但它们可能具有高计算和通信成本，尤其是非线性运算如 ReLU。</li>
<li>results: 提出了一种梯度基本方法，可以减少非线性运算并缓解这些问题，并且可以自动选择 ReLU 和多项式函数，以加速 PI 应用。实验结果显示，对于 CIFAR-10、CIFAR-100 和 Tiny-ImageNet 等 datasets，可以达到6.12%、8.39% 和 9.45% 的准确率提高，相比之前的状态之法，如 SNL。此外，AutoReP 还应用于 ImageNet 数据集上的 EfficientNet-B2 模型，实现了176.1倍 ReLU 预算减少，并达到75.55% 的准确率。<details>
<summary>Abstract</summary>
The growth of the Machine-Learning-As-A-Service (MLaaS) market has highlighted clients' data privacy and security issues. Private inference (PI) techniques using cryptographic primitives offer a solution but often have high computation and communication costs, particularly with non-linear operators like ReLU. Many attempts to reduce ReLU operations exist, but they may need heuristic threshold selection or cause substantial accuracy loss. This work introduces AutoReP, a gradient-based approach to lessen non-linear operators and alleviate these issues. It automates the selection of ReLU and polynomial functions to speed up PI applications and introduces distribution-aware polynomial approximation (DaPa) to maintain model expressivity while accurately approximating ReLUs. Our experimental results demonstrate significant accuracy improvements of 6.12% (94.31%, 12.9K ReLU budget, CIFAR-10), 8.39% (74.92%, 12.9K ReLU budget, CIFAR-100), and 9.45% (63.69%, 55K ReLU budget, Tiny-ImageNet) over current state-of-the-art methods, e.g., SNL. Morever, AutoReP is applied to EfficientNet-B2 on ImageNet dataset, and achieved 75.55% accuracy with 176.1 times ReLU budget reduction.
</details>
<details>
<summary>摘要</summary>
机器学习服务（MLaaS）市场的增长对客户的数据隐私和安全问题提出了问题。隐私（PI）技术使用加密基础设计可以解决这些问题，但是它们可能会有高 computation和通信成本，尤其是在非线性操作符如ReLU中。许多尝试减少ReLU操作的方法已经存在，但是它们可能需要调整阈值或导致重大准确损失。本研究则引入自动ReP，一种Gradient-based的方法，以减少非线性操作和解决这些问题。它自动选择ReLU和多项式函数，以加速PI应用程序，并 introduce了分布式数据掌控多项式拟合（DaPa），以维持模型表达力而准确地拟合ReLUs。我们的实验结果显示，与现有的方法相比，AutoReP可以获得了6.12%（94.31%, 12.9K ReLU预算、CIFAR-10）、8.39%（74.92%, 12.9K ReLU预算、CIFAR-100）和9.45%（63.69%, 55K ReLU预算、Tiny-ImageNet）的准确度提升。此外，我们还应用了AutoReP到EfficientNet-B2 ImageNet dataset，获得了75.55%的准确度，并在ReLU预算下降75.55倍。
</details></li>
</ul>
<hr>
<h2 id="Intelligent-Communication-Planning-for-Constrained-Environmental-IoT-Sensing-with-Reinforcement-Learning"><a href="#Intelligent-Communication-Planning-for-Constrained-Environmental-IoT-Sensing-with-Reinforcement-Learning" class="headerlink" title="Intelligent Communication Planning for Constrained Environmental IoT Sensing with Reinforcement Learning"></a>Intelligent Communication Planning for Constrained Environmental IoT Sensing with Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10124">http://arxiv.org/abs/2308.10124</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Hu, Jinhang Zuo, Bob Iannucci, Carlee Joe-Wong</li>
<li>for: 这个论文旨在优化互联网络传感器在环境监测中的通信规划，以提高环境监测的准确性。</li>
<li>methods: 这个论文使用多代理学习法（MARL）来找到优化环境数据收集的通信策略，以最大化环境监测准确性。</li>
<li>results: 实验表明，使用MARL方法可以在不知道带宽限制的情况下，平衡收集足够数据来预测野火蔓延与环境数据的协调。<details>
<summary>Abstract</summary>
Internet of Things (IoT) technologies have enabled numerous data-driven mobile applications and have the potential to significantly improve environmental monitoring and hazard warnings through the deployment of a network of IoT sensors. However, these IoT devices are often power-constrained and utilize wireless communication schemes with limited bandwidth. Such power constraints limit the amount of information each device can share across the network, while bandwidth limitations hinder sensors' coordination of their transmissions. In this work, we formulate the communication planning problem of IoT sensors that track the state of the environment. We seek to optimize sensors' decisions in collecting environmental data under stringent resource constraints. We propose a multi-agent reinforcement learning (MARL) method to find the optimal communication policies for each sensor that maximize the tracking accuracy subject to the power and bandwidth limitations. MARL learns and exploits the spatial-temporal correlation of the environmental data at each sensor's location to reduce the redundant reports from the sensors. Experiments on wildfire spread with LoRA wireless network simulators show that our MARL method can learn to balance the need to collect enough data to predict wildfire spread with unknown bandwidth limitations.
</details>
<details>
<summary>摘要</summary>
互联网物品（IoT）技术已经启用了大量数据驱动的 mobil 应用程序，并具有改善环境监控和危机警告的潜在潜力。然而，这些 IoT 设备通常受到能源限制和有限带宽通信方案的限制。这些限制限制每个设备可以在网络上传输的资料量，而带宽限制则阻碍感应器对传输的调控。在这个工作中，我们形式化了 IoT 感应器在监控环境状态时的通信规划问题。我们寻找最佳的通信策略，以确保感应器可以在 stringent 资源限制下传输环境数据，并且可以最大化追踪精度。我们提出了一种多代理强化学习（MARL）方法，以确保感应器在受限的资源下可以对环境数据进行最佳化追踪。MARL 方法可以学习和利用每个感应器的位置空间时间相关性，以减少感应器之间的重复报告。在使用 LoRA 无线网络模拟器进行野火传播实验中，我们发现我们的 MARL 方法可以寻找具有不知名带宽限制的情况下对野火传播进行最佳化追踪。
</details></li>
</ul>
<hr>
<h2 id="Deep-Generative-Modeling-based-Data-Augmentation-with-Demonstration-using-the-BFBT-Benchmark-Void-Fraction-Datasets"><a href="#Deep-Generative-Modeling-based-Data-Augmentation-with-Demonstration-using-the-BFBT-Benchmark-Void-Fraction-Datasets" class="headerlink" title="Deep Generative Modeling-based Data Augmentation with Demonstration using the BFBT Benchmark Void Fraction Datasets"></a>Deep Generative Modeling-based Data Augmentation with Demonstration using the BFBT Benchmark Void Fraction Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10120">http://arxiv.org/abs/2308.10120</a></li>
<li>repo_url: None</li>
<li>paper_authors: Farah Alsafadi, Xu Wu</li>
<li>for: 本研究用了深度学习（DL）来解决因数据稀缺而困难进行研究的核工程问题。</li>
<li>methods: 本研究使用了深度生成模型（DGM），包括生成对抗网络（GAN）、归一化函数（NF）、变量自动编码器（VAE）和条件VAE（CVAE）等，来学习训练数据集中的下式分布。</li>
<li>results: 研究发现，使用DGM生成的数据可以增加训练数据集的大小，并且可以提高深度学习模型的准确率。CVAE的表现最佳，其生成的数据Error最小。<details>
<summary>Abstract</summary>
Deep learning (DL) has achieved remarkable successes in many disciplines such as computer vision and natural language processing due to the availability of ``big data''. However, such success cannot be easily replicated in many nuclear engineering problems because of the limited amount of training data, especially when the data comes from high-cost experiments. To overcome such a data scarcity issue, this paper explores the applications of deep generative models (DGMs) that have been widely used for image data generation to scientific data augmentation. DGMs, such as generative adversarial networks (GANs), normalizing flows (NFs), variational autoencoders (VAEs), and conditional VAEs (CVAEs), can be trained to learn the underlying probabilistic distribution of the training dataset. Once trained, they can be used to generate synthetic data that are similar to the training data and significantly expand the dataset size. By employing DGMs to augment TRACE simulated data of the steady-state void fractions based on the NUPEC Boiling Water Reactor Full-size Fine-mesh Bundle Test (BFBT) benchmark, this study demonstrates that VAEs, CVAEs, and GANs have comparable generative performance with similar errors in the synthetic data, with CVAEs achieving the smallest errors. The findings shows that DGMs have a great potential to augment scientific data in nuclear engineering, which proves effective for expanding the training dataset and enabling other DL models to be trained more accurately.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）在许多领域取得了杰出的成就，如计算机视觉和自然语言处理，这主要归功于大量数据的可用性。然而，在核工程领域，由于数据的有限性，特别是高成本实验数据，因此DL模型的训练成本很高。为了解决这个数据缺乏问题，本文研究了使用深度生成模型（DGM）来增强科学数据。DGM包括生成对抗网络（GAN）、正常化流（NF）、变量自动编码器（VAE）和条件VAE（CVAE）等，可以根据训练数据的分布学习下来。一旦训练完成，它们可以生成与训练数据相似的 sintetic 数据，并显著增加数据量。在使用DGM增强TRACE模拟数据的稳态气体含量基于NUPEC沸水堆全size细膙测试（BFBT） benchmark的研究中，这种研究发现了VAE、CVAE和GAN在生成数据中的相似性，CVAE的错误最小。这些发现表明DGM在核工程领域有很大的潜力，可以增强科学数据，并且可以帮助DL模型更加准确地训练。
</details></li>
</ul>
<hr>
<h2 id="Modeling-Random-Networks-with-Heterogeneous-Reciprocity"><a href="#Modeling-Random-Networks-with-Heterogeneous-Reciprocity" class="headerlink" title="Modeling Random Networks with Heterogeneous Reciprocity"></a>Modeling Random Networks with Heterogeneous Reciprocity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10113">http://arxiv.org/abs/2308.10113</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Cirkovic, Tiandong Wang</li>
<li>for: 这个论文主要研究了社交网络中用户之间的信息交换行为，以及这种行为如何影响社交网络的发展。</li>
<li>methods: 作者提出了一种基于偏好附属的模型，用于模拟社交网络中不同水平的reciprocal行为。该模型考虑了用户吸引受户的偏好，以及用户之间的不同类型的reciprocity行为。</li>
<li>results: 作者通过对Facebook墙post网络数据进行分析，发现存在多个用户群体，每个群体都有不同的回快行为模式。模型能够捕捉Facebook数据中实际度分布的重创尾性特征，并且可以Identify不同用户群体的特征。<details>
<summary>Abstract</summary>
Reciprocity, or the tendency of individuals to mirror behavior, is a key measure that describes information exchange in a social network. Users in social networks tend to engage in different levels of reciprocal behavior. Differences in such behavior may indicate the existence of communities that reciprocate links at varying rates. In this paper, we develop methodology to model the diverse reciprocal behavior in growing social networks. In particular, we present a preferential attachment model with heterogeneous reciprocity that imitates the attraction users have for popular users, plus the heterogeneous nature by which they reciprocate links. We compare Bayesian and frequentist model fitting techniques for large networks, as well as computationally efficient variational alternatives. Cases where the number of communities are known and unknown are both considered. We apply the presented methods to the analysis of a Facebook wallpost network where users have non-uniform reciprocal behavior patterns. The fitted model captures the heavy-tailed nature of the empirical degree distributions in the Facebook data and identifies multiple groups of users that differ in their tendency to reply to and receive responses to wallposts.
</details>
<details>
<summary>摘要</summary>
互助性（reciprocity），或社交网络中个体响应行为的倾向，是社交网络中信息交换的关键指标。社交网络中的用户们通常在不同的水平上进行反馈行为。不同的反馈行为可能表明社交网络中存在不同的社区，这些社区在链接复制速率上有不同的偏好。在这篇论文中，我们开发了用于模型社交网络中多种反馈行为的方法ологи。特别是，我们提出了带有不同reciprocity的偏好附着模型，该模型模拟用户对流行用户的吸引，以及不同的反馈行为。我们对大型网络中的bayesian和频率统计方法进行比较，以及计算效率高的变量替代方法。我们还考虑了知道和不知道社区数量的两种情况。我们在Facebook墙上的墙posts网络中应用了提出的方法，并发现了墙posts网络中用户的反馈行为具有重 tailed性特征，并分化出多个用户群体，这些用户群体在链接复制上有不同的偏好。
</details></li>
</ul>
<hr>
<h2 id="Robust-Mixture-of-Expert-Training-for-Convolutional-Neural-Networks"><a href="#Robust-Mixture-of-Expert-Training-for-Convolutional-Neural-Networks" class="headerlink" title="Robust Mixture-of-Expert Training for Convolutional Neural Networks"></a>Robust Mixture-of-Expert Training for Convolutional Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10110">http://arxiv.org/abs/2308.10110</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/optml-group/robust-moe-cnn">https://github.com/optml-group/robust-moe-cnn</a></li>
<li>paper_authors: Yihua Zhang, Ruisi Cai, Tianlong Chen, Guanhua Zhang, Huan Zhang, Pin-Yu Chen, Shiyu Chang, Zhangyang Wang, Sijia Liu</li>
<li>for: 这篇论文的目的是探讨如何将对抗式训练（Adversarial Training，AT） Mechanism 应用到具有混合专家（Mixture of Experts，MoE）架构的卷积神经网络（Convolutional Neural Networks，CNNs）中，以提高它们的抗衰弱性。</li>
<li>methods: 这篇论文使用了一种称为 AdvMoE 的新的对抗式训练框架，它将对抗式训练与MoE架构结合，以提高卷积神经网络的抗衰弱性。</li>
<li>results: 这篇论文的结果显示，使用 AdvMoE 框架可以将卷积神经网络的抗衰弱性提高 1% ~ 4%，并且可以降低 inference 成本超过 50%。<details>
<summary>Abstract</summary>
Sparsely-gated Mixture of Expert (MoE), an emerging deep model architecture, has demonstrated a great promise to enable high-accuracy and ultra-efficient model inference. Despite the growing popularity of MoE, little work investigated its potential to advance convolutional neural networks (CNNs), especially in the plane of adversarial robustness. Since the lack of robustness has become one of the main hurdles for CNNs, in this paper we ask: How to adversarially robustify a CNN-based MoE model? Can we robustly train it like an ordinary CNN model? Our pilot study shows that the conventional adversarial training (AT) mechanism (developed for vanilla CNNs) no longer remains effective to robustify an MoE-CNN. To better understand this phenomenon, we dissect the robustness of an MoE-CNN into two dimensions: Robustness of routers (i.e., gating functions to select data-specific experts) and robustness of experts (i.e., the router-guided pathways defined by the subnetworks of the backbone CNN). Our analyses show that routers and experts are hard to adapt to each other in the vanilla AT. Thus, we propose a new router-expert alternating Adversarial training framework for MoE, termed AdvMoE. The effectiveness of our proposal is justified across 4 commonly-used CNN model architectures over 4 benchmark datasets. We find that AdvMoE achieves 1% ~ 4% adversarial robustness improvement over the original dense CNN, and enjoys the efficiency merit of sparsity-gated MoE, leading to more than 50% inference cost reduction. Codes are available at https://github.com/OPTML-Group/Robust-MoE-CNN.
</details>
<details>
<summary>摘要</summary>
新型的稀疑隐藏 gates mixture of expert (MoE) 模型，已经展示出高精度和高效的模型推理能力。 despite the growing popularity of MoE, little work has investigated its potential to advance convolutional neural networks (CNNs), especially in the area of adversarial robustness. since the lack of robustness has become one of the main obstacles for CNNs, in this paper we ask: how to adversarially robustify a CNN-based MoE model? can we train it like an ordinary CNN model? our pilot study shows that the conventional adversarial training (AT) mechanism (developed for vanilla CNNs) no longer remains effective to robustify an MoE-CNN. to better understand this phenomenon, we dissect the robustness of an MoE-CNN into two dimensions: the robustness of routers (i.e., gating functions to select data-specific experts) and the robustness of experts (i.e., the router-guided pathways defined by the subnetworks of the backbone CNN). our analyses show that routers and experts are hard to adapt to each other in the vanilla AT. thus, we propose a new router-expert alternating adversarial training framework for MoE, termed AdvMoE. the effectiveness of our proposal is justified across 4 commonly-used CNN model architectures over 4 benchmark datasets. we find that AdvMoE achieves 1% ~ 4% adversarial robustness improvement over the original dense CNN, and enjoys the efficiency merit of sparsity-gated MoE, leading to more than 50% inference cost reduction. codes are available at https://github.com/OPTML-Group/Robust-MoE-CNN.
</details></li>
</ul>
<hr>
<h2 id="An-Online-Multiple-Kernel-Parallelizable-Learning-Scheme"><a href="#An-Online-Multiple-Kernel-Parallelizable-Learning-Scheme" class="headerlink" title="An Online Multiple Kernel Parallelizable Learning Scheme"></a>An Online Multiple Kernel Parallelizable Learning Scheme</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10101">http://arxiv.org/abs/2308.10101</a></li>
<li>repo_url: None</li>
<li>paper_authors: Emilio Ruiz-Moreno, Baltasar Beferull-Lozano</li>
<li>for: 这 paper 的目的是提出一种可扩展性的多 kernel 学习方法，以降低 kernel 选择的偏见。</li>
<li>methods: 这 paper 使用了多 kernel 学习方法，其中每个 kernel 都是一种不同的特征选择方法。</li>
<li>results: 实验表明，这 paper 的提出的多 kernel 学习方法可以在数据丰富任务中提高解决效果，并且可以平行计算，以便分布计算负担。<details>
<summary>Abstract</summary>
The performance of reproducing kernel Hilbert space-based methods is known to be sensitive to the choice of the reproducing kernel. Choosing an adequate reproducing kernel can be challenging and computationally demanding, especially in data-rich tasks without prior information about the solution domain. In this paper, we propose a learning scheme that scalably combines several single kernel-based online methods to reduce the kernel-selection bias. The proposed learning scheme applies to any task formulated as a regularized empirical risk minimization convex problem. More specifically, our learning scheme is based on a multi-kernel learning formulation that can be applied to widen any single-kernel solution space, thus increasing the possibility of finding higher-performance solutions. In addition, it is parallelizable, allowing for the distribution of the computational load across different computing units. We show experimentally that the proposed learning scheme outperforms the combined single-kernel online methods separately in terms of the cumulative regularized least squares cost metric.
</details>
<details>
<summary>摘要</summary>
“ kernel 希尔伯特空间基于方法的性能复制性受选择 reproduce kernel 的影响。选择合适的 reproduce kernel 可以是具有挑战性和计算强度的，特别是在没有关于解决空间的先验信息的情况下。在这篇论文中，我们提出了一种学习方案，可以可扩展性地组合多个单kernel-based 在线方法，以降低 kernel-selection 偏见。该学习方案适用于任何形式为正则化empirical risk minimization  convex问题。更 Specifically，我们的学习方案基于多kernel learning 形式，可以扩大任何单kernel 解决空间，从而增加高性能解决方案的可能性。此外，它可以并行化，以分配计算负担到不同的计算单元。我们实验表明，提出的学习方案在累积正则化最小二乘Cost  metric上超过了单个单kernel 在线方法的总和。”
</details></li>
</ul>
<hr>
<h2 id="Geometric-instability-of-graph-neural-networks-on-large-graphs"><a href="#Geometric-instability-of-graph-neural-networks-on-large-graphs" class="headerlink" title="Geometric instability of graph neural networks on large graphs"></a>Geometric instability of graph neural networks on large graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10099">http://arxiv.org/abs/2308.10099</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/brs96/geometric-instability-gnn-large-graphs">https://github.com/brs96/geometric-instability-gnn-large-graphs</a></li>
<li>paper_authors: Emily Morris, Haotian Shen, Weiling Du, Muhammad Hamza Sajjad, Borun Shi</li>
<li>for: 这 paper  investigate 图 neural network (GNN) 生成的嵌入的几何不稳定性。</li>
<li>methods: 该 paper 提出了一种简单、高效的图根本的图agram Gram Index (GGI) 来度量这种不稳定性，该方法是卷积、旋转、平移和评估顺序无关的。</li>
<li>results: 该 paper 通过使用 GGI 来研究 GNN 嵌入在大图上的不稳定性行为，并对节点分类和链接预测进行了研究。<details>
<summary>Abstract</summary>
We analyse the geometric instability of embeddings produced by graph neural networks (GNNs). Existing methods are only applicable for small graphs and lack context in the graph domain. We propose a simple, efficient and graph-native Graph Gram Index (GGI) to measure such instability which is invariant to permutation, orthogonal transformation, translation and order of evaluation. This allows us to study the varying instability behaviour of GNN embeddings on large graphs for both node classification and link prediction.
</details>
<details>
<summary>摘要</summary>
我们分析图 neural network (GNN) 生成的嵌入的几何不稳定性。现有的方法只适用于小图，缺乏图域上的上下文。我们提议一个简单、高效、图native的图agram Gram Index (GGI) 来测量这种不稳定性，该指标对Permutation、正交变换、翻译和评估顺序具有抗变换性。这使得我们可以研究大图上 GNN 嵌入的不同不稳定行为，包括节点分类和链接预测。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Bilevel-Learning-with-Inexact-Line-Search"><a href="#Dynamic-Bilevel-Learning-with-Inexact-Line-Search" class="headerlink" title="Dynamic Bilevel Learning with Inexact Line Search"></a>Dynamic Bilevel Learning with Inexact Line Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10098">http://arxiv.org/abs/2308.10098</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Sadegh Salehi, Subhadip Mukherjee, Lindon Roberts, Matthias J. Ehrhardt</li>
<li>for: 这篇论文的目的是解决具有多个传播常数的泛化正规化项目中的偏好参数配置问题。</li>
<li>methods: 本文使用层次学习来学习传播常数的偏好参数，并使用批量学习来找到适当的传播常数。</li>
<li>results: 本文的 numrical experiments 显示了对于具有多个传播常数的泛化正规化项目中的偏好参数配置问题，提供了一个可证的不精准的内推搜索法，并且可以自动决定需要的精度。<details>
<summary>Abstract</summary>
In various domains within imaging and data science, particularly when addressing tasks modeled utilizing the variational regularization approach, manually configuring regularization parameters presents a formidable challenge. The difficulty intensifies when employing regularizers involving a large number of hyperparameters. To overcome this challenge, bilevel learning is employed to learn suitable hyperparameters. However, due to the use of numerical solvers, the exact gradient with respect to the hyperparameters is unattainable, necessitating the use of methods relying on approximate gradients. State-of-the-art inexact methods a priori select a decreasing summable sequence of the required accuracy and only assure convergence given a sufficiently small fixed step size. Despite this, challenges persist in determining the Lipschitz constant of the hypergradient and identifying an appropriate fixed step size. Conversely, computing exact function values is not feasible, impeding the use of line search. In this work, we introduce a provably convergent inexact backtracking line search involving inexact function evaluations and hypergradients. We show convergence to a stationary point of the loss with respect to hyperparameters. Additionally, we propose an algorithm to determine the required accuracy dynamically. Our numerical experiments demonstrate the efficiency and feasibility of our approach for hyperparameter estimation in variational regularization problems, alongside its robustness in terms of the initial accuracy and step size choices.
</details>
<details>
<summary>摘要</summary>
在各种图像和数据科学领域中，特别是使用变量正则化方法进行任务模型化时，手动配置正则化参数是一项具有挑战性的任务。难度增加了当使用含有大量超参数的正则化器。为了解决这个挑战，我们使用二级学习来学习适当的超参数。然而，由于使用数值解 sols，无法获得正则化器中的精确梯度，因此需要使用approximate gradients的方法。现有的state-of-the-art不精确方法会选择一个减少的总和序列，并且只有在具有足够小的固定步长时才能保证收敛。然而，在确定梯度Lipsilon constant和适当的固定步长方面，还存在挑战。此外，计算精确函数值是不可能的，这阻碍了使用梯度下降法。在这种情况下，我们介绍了一种可证明收敛的不精确返回搜索，该搜索包括不精确函数评估和梯度。我们表明，该搜索会收敛到loss中的超参数中的站点点。此外，我们还提出了一种动态确定所需的精度的算法。我们的数值实验表明，我们的方法可以高效地进行超参数估算，并且具有鲁棒性，即初始精度和步长选择的影响。
</details></li>
</ul>
<hr>
<h2 id="MLOps-A-Review"><a href="#MLOps-A-Review" class="headerlink" title="MLOps: A Review"></a>MLOps: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10908">http://arxiv.org/abs/2308.10908</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jenningst/ecommerce-ops">https://github.com/jenningst/ecommerce-ops</a></li>
<li>paper_authors: Samar Wazir, Gautam Siddharth Kashyap, Parag Saxena</li>
<li>for: 本研究探讨了机器学习操作（MLOps）方法的重要性，以帮助开发者更好地创建使用机器学习算法的软件。</li>
<li>methods: 作者评估了多种MLOps方法的特性和操作性，以选择适合特定项目的最佳工具结构。</li>
<li>results: 研究发现现有的MLOps方法尚未具备完全有效的自动化功能，人类参与度仍然较高。<details>
<summary>Abstract</summary>
Recently, Machine Learning (ML) has become a widely accepted method for significant progress that is rapidly evolving. Since it employs computational methods to teach machines and produce acceptable answers. The significance of the Machine Learning Operations (MLOps) methods, which can provide acceptable answers for such problems, is examined in this study. To assist in the creation of software that is simple to use, the authors research MLOps methods. To choose the best tool structure for certain projects, the authors also assess the features and operability of various MLOps methods. A total of 22 papers were assessed that attempted to apply the MLOps idea. Finally, the authors admit the scarcity of fully effective MLOps methods based on which advancements can self-regulate by limiting human engagement.
</details>
<details>
<summary>摘要</summary>
近期，机器学习（ML）已成为广泛接受的方法，迅速进步的方法。由于它使用计算方法教育机器并生成可接受的答案。本研究 изучает机器学习操作（MLOps）方法的重要性，这些方法可以为这些问题提供可接受的答案。为便于创建易于使用的软件，作者研究了 MLOps 方法。为选择特定项目最佳工具结构，作者也评估了不同 MLOps 方法的特性和操作性。总共评估了 22 篇尝试应用 MLOps 想法的论文。最后，作者承认机器学习操作方法完全自主进步的缺乏，即限制人类参与度。Note: Please keep in mind that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Securing-Pathways-with-Orthogonal-Robots"><a href="#Securing-Pathways-with-Orthogonal-Robots" class="headerlink" title="Securing Pathways with Orthogonal Robots"></a>Securing Pathways with Orthogonal Robots</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10093">http://arxiv.org/abs/2308.10093</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hamid Hoorfar, Faraneh Fathi, Sara Moshtaghi Largani, Alireza Bagheri</li>
<li>for: 保护路径的重要性在多个领域，如城市规划、交通、监视和安全中具有极高的意义。</li>
<li>methods: 本文提出了一种创新的方法，利用正交机器人来保护路径。研究专注于最小化正交机器人数量来有效地监视正交区域。</li>
<li>results: 研究表明，可以在线性时间内确定最小化正交机器人数量。但是，对于简单多边形的普通可见情况，即使是正交情况，则是NP困难的。研究强调了机器人可以在多边形的边界或内部任意地放置。<details>
<summary>Abstract</summary>
The protection of pathways holds immense significance across various domains, including urban planning, transportation, surveillance, and security. This article introduces a groundbreaking approach to safeguarding pathways by employing orthogonal robots. The study specifically addresses the challenge of efficiently guarding orthogonal areas with the minimum number of orthogonal robots. The primary focus is on orthogonal pathways, characterized by a path-like dual graph of vertical decomposition. It is demonstrated that determining the minimum number of orthogonal robots for pathways can be achieved in linear time. However, it is essential to note that the general problem of finding the minimum number of robots for simple polygons with general visibility, even in the orthogonal case, is known to be NP-hard. Emphasis is placed on the flexibility of placing robots anywhere within the polygon, whether on the boundary or in the interior.
</details>
<details>
<summary>摘要</summary>
保护路径具有广泛的应用场景，包括城市规划、交通、监测和安全等领域。这篇文章介绍了一种创新的路径保护方法，利用正交机器人。研究特点在于最小化正交机器人数量，以确保有效地监测正交区域。研究主要关注正交路径，即垂直分解图中的路径类 dual graph。实验表明，可以在线时确定最小正交机器人数量。然而，需要注意的是，找到最小机器人数量的普通多边形问题，即NP-hard问题。文章强调机器人的位置 flexibility，可以在边界或内部的任何位置进行布置。
</details></li>
</ul>
<hr>
<h2 id="Minimizing-Turns-in-Watchman-Robot-Navigation-Strategies-and-Solutions"><a href="#Minimizing-Turns-in-Watchman-Robot-Navigation-Strategies-and-Solutions" class="headerlink" title="Minimizing Turns in Watchman Robot Navigation: Strategies and Solutions"></a>Minimizing Turns in Watchman Robot Navigation: Strategies and Solutions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10090">http://arxiv.org/abs/2308.10090</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hamid Hoorfar, Sara Moshtaghi Largani, Reza Rahimi, Alireza Bagheri</li>
<li>for: 本研究旨在提出一种高效的直线时间算法，用于解决监视人员路径问题（OWRP），以便在机器人系统中优化监视和护卫任务。</li>
<li>methods: 本研究使用了一种简单的直线时间算法，基于监视人员路径问题的假设环境是卷积的。</li>
<li>results: 研究发现，该算法可以在线性时间内解决监视人员路径问题，并且可以减少路径中转次数，从而提高机器人的涵盖率和耗时效率。<details>
<summary>Abstract</summary>
The Orthogonal Watchman Route Problem (OWRP) entails the search for the shortest path, known as the watchman route, that a robot must follow within a polygonal environment. The primary objective is to ensure that every point in the environment remains visible from at least one point on the route, allowing the robot to survey the entire area in a single, continuous sweep. This research places particular emphasis on reducing the number of turns in the route, as it is crucial for optimizing navigation in watchman routes within the field of robotics. The cost associated with changing direction is of significant importance, especially for specific types of robots. This paper introduces an efficient linear-time algorithm for solving the OWRP under the assumption that the environment is monotone. The findings of this study contribute to the progress of robotic systems by enabling the design of more streamlined patrol robots. These robots are capable of efficiently navigating complex environments while minimizing the number of turns. This advancement enhances their coverage and surveillance capabilities, making them highly effective in various real-world applications.
</details>
<details>
<summary>摘要</summary>
《Orthogonal Watchman Route Problem（OWRP）》的研究目标是找到在多边形环境中最短的路径，称为“看守路径”，以确保机器人可以在一次连续扫描所有环境点。主要目标是尽量减少路径中转数量，因为这对于某些机器人类型来说非常重要。这篇论文提出了一种高效的线性时间算法，用于解决在 monotone 环境下的 OWRP。这些发现对机器人系统的进步做出了贡献，使得机器人可以更加高效地在复杂环境中导航，最小化转弯数量。这种进步提高了机器人的覆盖和监测能力，使其在各种实际应用中表现出色。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Learning-for-Non-Local-Graphs-with-Multi-Resolution-Structural-Views"><a href="#Contrastive-Learning-for-Non-Local-Graphs-with-Multi-Resolution-Structural-Views" class="headerlink" title="Contrastive Learning for Non-Local Graphs with Multi-Resolution Structural Views"></a>Contrastive Learning for Non-Local Graphs with Multi-Resolution Structural Views</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10077">http://arxiv.org/abs/2308.10077</a></li>
<li>repo_url: None</li>
<li>paper_authors: Asif Khan, Amos Storkey</li>
<li>for: 本文主要针对于疑似诈骗者检测和蛋白质功能预测等应用场景，掌握积极的图结构信息是关键。</li>
<li>methods: 本文提出了一种基于多视图对照学习的图表示学习方法，利用多个视图作为增强器，捕捉到积极图中结构相似性，从而揭示隐藏的关系和相似性。</li>
<li>results: 对于synthetic和实际结构数据集，本文的方法与基eline进行比较，达到了$16.06%$的提升（在Cornell数据集上）、$3.27%$的提升（在Texas数据集上）和$8.04%$的提升（在Wisconsin数据集上）。此外，本文在邻近任务上表现出了superior的性能，证明了其在揭示结构信息和提高下游应用中的效果。<details>
<summary>Abstract</summary>
Learning node-level representations of heterophilic graphs is crucial for various applications, including fraudster detection and protein function prediction. In such graphs, nodes share structural similarity identified by the equivalence of their connectivity which is implicitly encoded in the form of higher-order hierarchical information in the graphs. The contrastive methods are popular choices for learning the representation of nodes in a graph. However, existing contrastive methods struggle to capture higher-order graph structures. To address this limitation, we propose a novel multiview contrastive learning approach that integrates diffusion filters on graphs. By incorporating multiple graph views as augmentations, our method captures the structural equivalence in heterophilic graphs, enabling the discovery of hidden relationships and similarities not apparent in traditional node representations. Our approach outperforms baselines on synthetic and real structural datasets, surpassing the best baseline by $16.06\%$ on Cornell, $3.27\%$ on Texas, and $8.04\%$ on Wisconsin. Additionally, it consistently achieves superior performance on proximal tasks, demonstrating its effectiveness in uncovering structural information and improving downstream applications.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ILCAS-Imitation-Learning-Based-Configuration-Adaptive-Streaming-for-Live-Video-Analytics-with-Cross-Camera-Collaboration"><a href="#ILCAS-Imitation-Learning-Based-Configuration-Adaptive-Streaming-for-Live-Video-Analytics-with-Cross-Camera-Collaboration" class="headerlink" title="ILCAS: Imitation Learning-Based Configuration-Adaptive Streaming for Live Video Analytics with Cross-Camera Collaboration"></a>ILCAS: Imitation Learning-Based Configuration-Adaptive Streaming for Live Video Analytics with Cross-Camera Collaboration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10068">http://arxiv.org/abs/2308.10068</a></li>
<li>repo_url: None</li>
<li>paper_authors: Duo Wu, Dayou Zhang, Miao Zhang, Ruoyu Zhang, Fangxin Wang, Shuguang Cui</li>
<li>For: 这个研究的目的是为了提高现场视频分析（VA）中的深度神经网络（DNN）的准确率和资源效率。* Methods: 这个研究使用了循环学习（IL）和动态视觉感知（motion feature maps）来应对现场视频的内容变化，并且将多标的相机联合使用以利用空间时间相互联系。* Results: 实验结果显示，与现有解决方案相比，这个方法可以提高了2-20.9%的准确率和19.9-85.3%的块上传延误。<details>
<summary>Abstract</summary>
The high-accuracy and resource-intensive deep neural networks (DNNs) have been widely adopted by live video analytics (VA), where camera videos are streamed over the network to resource-rich edge/cloud servers for DNN inference. Common video encoding configurations (e.g., resolution and frame rate) have been identified with significant impacts on striking the balance between bandwidth consumption and inference accuracy and therefore their adaption scheme has been a focus of optimization. However, previous profiling-based solutions suffer from high profiling cost, while existing deep reinforcement learning (DRL) based solutions may achieve poor performance due to the usage of fixed reward function for training the agent, which fails to craft the application goals in various scenarios. In this paper, we propose ILCAS, the first imitation learning (IL) based configuration-adaptive VA streaming system. Unlike DRL-based solutions, ILCAS trains the agent with demonstrations collected from the expert which is designed as an offline optimal policy that solves the configuration adaption problem through dynamic programming. To tackle the challenge of video content dynamics, ILCAS derives motion feature maps based on motion vectors which allow ILCAS to visually ``perceive'' video content changes. Moreover, ILCAS incorporates a cross-camera collaboration scheme to exploit the spatio-temporal correlations of cameras for more proper configuration selection. Extensive experiments confirm the superiority of ILCAS compared with state-of-the-art solutions, with 2-20.9% improvement of mean accuracy and 19.9-85.3% reduction of chunk upload lag.
</details>
<details>
<summary>摘要</summary>
高精度和资源占用深度神经网络（DNN）在实时视频分析（VA）中广泛应用，其中电影摄像头推送到edge/云服务器进行DNN推理。常见的视频编码配置（如分辨率和帧率）对于寻求平衡带宽消耗和推理精度有显著影响，因此其适应方案成为优化的焦点。然而，先前的 Profiling 基本解决方案受到高 Profiling 成本的限制，而现有的深度强化学习（DRL）基本解决方案可能因为使用固定奖励函数进行训练代理人而达到低效果，不能适应不同场景中的应用目标。在这篇论文中，我们提出了ILCAS，首个基于依达学习（IL）的配置适应VA流动系统。与DRL基本解决方案不同，ILCAS 通过从专家设计的精度优化策略收集示例来训练代理人，通过动态Programming解决配置适应问题。为了解决视频内容变化的挑战，ILCAS  derivates Motion Feature Maps based on motion vectors，allowing ILCAS to "perceive" video content changes visually。此外，ILCAS 还采用相机间协作方案，以利用相机之间的空间时间相关性进行更加合适的配置选择。实验证明ILCAS 比现有解决方案有2-20.9%的提高精度和19.9-85.3%的减少块上传延迟。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/20/cs.LG_2023_08_20/" data-id="clohum99a00mzpj88gpqbgznd" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_20" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/20/eess.IV_2023_08_20/" class="article-date">
  <time datetime="2023-08-20T09:00:00.000Z" itemprop="datePublished">2023-08-20</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/20/eess.IV_2023_08_20/">eess.IV - 2023-08-20</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Boosting-Adversarial-Transferability-by-Block-Shuffle-and-Rotation"><a href="#Boosting-Adversarial-Transferability-by-Block-Shuffle-and-Rotation" class="headerlink" title="Boosting Adversarial Transferability by Block Shuffle and Rotation"></a>Boosting Adversarial Transferability by Block Shuffle and Rotation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10299">http://arxiv.org/abs/2308.10299</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kunyu Wang, Xuanran He, Wenxuan Wang, Xiaosen Wang</li>
<li>for: 防止深度学习模型受到攻击，增强深度学习模型的安全性。</li>
<li>methods: 使用输入变换基于的攻击方法，包括块混淆和旋转（BSR）。</li>
<li>results: BSR方法可以在单模型和集成模型下实现显著更高的传输性，并且可以与现有输入变换方法组合使用，以达到更高的传输性和安全性。<details>
<summary>Abstract</summary>
Adversarial examples mislead deep neural networks with imperceptible perturbations and have brought significant threats to deep learning. An important aspect is their transferability, which refers to their ability to deceive other models, thus enabling attacks in the black-box setting. Though various methods have been proposed to boost transferability, the performance still falls short compared with white-box attacks. In this work, we observe that existing input transformation based attacks, one of the mainstream transfer-based attacks, result in different attention heatmaps on various models, which might limit the transferability. We also find that breaking the intrinsic relation of the image can disrupt the attention heatmap of the original image. Based on this finding, we propose a novel input transformation based attack called block shuffle and rotation (BSR). Specifically, BSR splits the input image into several blocks, then randomly shuffles and rotates these blocks to construct a set of new images for gradient calculation. Empirical evaluations on the ImageNet dataset demonstrate that BSR could achieve significantly better transferability than the existing input transformation based methods under single-model and ensemble-model settings. Combining BSR with the current input transformation method can further improve the transferability, which significantly outperforms the state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
深度学习模型被攻击性例子所欺骗，通过不可见的扰动而导致模型错误。其中一个重要方面是其可传递性，即它们能够在黑盒 Setting中攻击其他模型，从而对深度学习 pose 威胁。虽然多种方法已经被提出来提高可传递性，但其性能仍然落后于白盒攻击。在这种情况下，我们发现现有的输入变换基于攻击方法中的 attention heatmap 可能会受限制可传递性。我们还发现，对图像的内部关系的扰动可以破坏原始图像的 attention heatmap。基于这一发现，我们提出了一种新的输入变换基于攻击方法 called block shuffle and rotation (BSR)。具体来说，BSR 将输入图像分成多个块，然后随机排序和旋转这些块来构建一组新的图像，用于计算梯度。我们的实验表明，BSR 在 ImageNet 数据集上可以达到单模型和集成模型的情况下，与现有的输入变换基于方法相比，有显著更好的可传递性。此外，将 BSR 与当前的输入变换方法相结合，可以进一步提高可传递性，并与当前的状态OF-the-art方法相比，具有显著更好的性能。
</details></li>
</ul>
<hr>
<h2 id="Domain-Reduction-Strategy-for-Non-Line-of-Sight-Imaging"><a href="#Domain-Reduction-Strategy-for-Non-Line-of-Sight-Imaging" class="headerlink" title="Domain Reduction Strategy for Non Line of Sight Imaging"></a>Domain Reduction Strategy for Non Line of Sight Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10269">http://arxiv.org/abs/2308.10269</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyunbo Shim, In Cho, Daekyu Kwon, Seon Joo Kim</li>
<li>for: 非直线视野（NLOS）图像重建，目的是在不同设置下重建隐藏的场景。</li>
<li>methods: 提出了一种优化基于方法，利用了干扰 superficies 的观察，通过简单地忽略隐藏表面之间的交互，独立计算每个隐藏点的光子回射。采用了一种域减少程序，从折射函数中排除无用的区域，提高优化的计算效率。</li>
<li>results: 在多种NLOS场景下，包括非平面关墙、稀疏扫描模式、射频和非射频、和表面几何重建等，实验结果表明提出的方法在一般NLOS场景中具有优越性和高效性。<details>
<summary>Abstract</summary>
This paper presents a novel optimization-based method for non-line-of-sight (NLOS) imaging that aims to reconstruct hidden scenes under various setups. Our method is built upon the observation that photons returning from each point in hidden volumes can be independently computed if the interactions between hidden surfaces are trivially ignored. We model the generalized light propagation function to accurately represent the transients as a linear combination of these functions. Moreover, our proposed method includes a domain reduction procedure to exclude empty areas of the hidden volumes from the set of propagation functions, thereby improving computational efficiency of the optimization. We demonstrate the effectiveness of the method in various NLOS scenarios, including non-planar relay wall, sparse scanning patterns, confocal and non-confocal, and surface geometry reconstruction. Experiments conducted on both synthetic and real-world data clearly support the superiority and the efficiency of the proposed method in general NLOS scenarios.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Crucial-Feature-Capture-and-Discrimination-for-Limited-Training-Data-SAR-ATR"><a href="#Crucial-Feature-Capture-and-Discrimination-for-Limited-Training-Data-SAR-ATR" class="headerlink" title="Crucial Feature Capture and Discrimination for Limited Training Data SAR ATR"></a>Crucial Feature Capture and Discrimination for Limited Training Data SAR ATR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10911">http://arxiv.org/abs/2308.10911</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cwwangsaratr/saratr_feacapture_discrimination">https://github.com/cwwangsaratr/saratr_feacapture_discrimination</a></li>
<li>paper_authors: Chenwei Wang, Siyi Luo, Jifang Pei, Yulin Huang, Yin Zhang, Jianyu Yang<br>for: 这个研究旨在提高SAR ATR的表现，对于具有限制training samples的情况进行设计。methods: 本研究提出了一个SAR ATR框架，包括两个支线和两个模组：全球协助支线和本地增强支线，特征捕捉模组和特征区别模组。在每次训练过程中，全球协助支线首先完成了初始识别，基于整个图像。然后，特征捕捉模组自动搜寻并锁定了重要图像区域，我们称之为图像的“金钥”。最后，本地增强支线对捕捉到的本地特征进行了进一步处理。results: 我们通过模型健全性实验和实验结果展示了我们的方法的有效性。在MSTAR和OPENSAR上进行了比较，我们的方法已经实现了Superior的识别性能。<details>
<summary>Abstract</summary>
Although deep learning-based methods have achieved excellent performance on SAR ATR, the fact that it is difficult to acquire and label a lot of SAR images makes these methods, which originally performed well, perform weakly. This may be because most of them consider the whole target images as input, but the researches find that, under limited training data, the deep learning model can't capture discriminative image regions in the whole images, rather focus on more useless even harmful image regions for recognition. Therefore, the results are not satisfactory. In this paper, we design a SAR ATR framework under limited training samples, which mainly consists of two branches and two modules, global assisted branch and local enhanced branch, feature capture module and feature discrimination module. In every training process, the global assisted branch first finishes the initial recognition based on the whole image. Based on the initial recognition results, the feature capture module automatically searches and locks the crucial image regions for correct recognition, which we named as the golden key of image. Then the local extract the local features from the captured crucial image regions. Finally, the overall features and local features are input into the classifier and dynamically weighted using the learnable voting parameters to collaboratively complete the final recognition under limited training samples. The model soundness experiments demonstrate the effectiveness of our method through the improvement of feature distribution and recognition probability. The experimental results and comparisons on MSTAR and OPENSAR show that our method has achieved superior recognition performance.
</details>
<details>
<summary>摘要</summary>
尽管深度学习基本方法在Synthetic Aperture Radar（SAR）特征识别（ATR）中表现出色，但由于获得和标注SAR图像困难，这些方法在限制性训练数据下表现弱化。这可能是因为大多数方法将整个目标图像作为输入，但研究人员发现，在有限的训练样本下，深度学习模型无法捕捉权重图像区域，而是专注于无用甚至害图像区域的识别。因此，结果不 satisfactory。在这篇论文中，我们设计了一个基于有限训练样本的SAR ATR框架，主要包括两个分支和两个模块：全球协助分支和本地增强分支，特征捕捉模块和特征分类模块。在每次训练过程中，全球协助分支首先基于整个图像完成初步识别。基于初步识别结果，特征捕捉模块自动搜索和锁定正确识别的关键图像区域，我们称之为图像的“金钥匙”。然后，本地EXTRACTLOCAL特征从捕捉到的关键图像区域中提取本地特征。最后，总特征和本地特征通过可学习投票参数进行相互协同完成最终识别。实验证明我们的方法有效性，通过改善特征分布和识别概率。实验结果和MSTAR和OPENSAR的比较表明，我们的方法在限制性训练样本下实现了superior的识别性能。
</details></li>
</ul>
<hr>
<h2 id="An-Entropy-Awareness-Meta-Learning-Method-for-SAR-Open-Set-ATR"><a href="#An-Entropy-Awareness-Meta-Learning-Method-for-SAR-Open-Set-ATR" class="headerlink" title="An Entropy-Awareness Meta-Learning Method for SAR Open-Set ATR"></a>An Entropy-Awareness Meta-Learning Method for SAR Open-Set ATR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10251">http://arxiv.org/abs/2308.10251</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenwei Wang, Siyi Luo, Jifang Pei, Xiaoyu Liu, Yulin Huang, Yin Zhang, Jianyu Yang<br>for: 这个论文主要针对的是开放集Recognition（OSR）问题，即使用Synthetic Aperture Radar自动目标识别（SAR ATR）方法对不同的目标类进行分类。methods: 该方法基于Entropy-awareness meta-learning技术，通过meta-学任务来学习建立动态分配的知识类别的特征空间，以便同时分类已知类别并排除未知类别。results: 实验结果表明，该方法在Moving and Stationary Target Acquisition and Recognition（MSTAR）数据集上表现出色，能够同时分类动态分配的知识类别和排除未知类别。<details>
<summary>Abstract</summary>
Existing synthetic aperture radar automatic target recognition (SAR ATR) methods have been effective for the classification of seen target classes. However, it is more meaningful and challenging to distinguish the unseen target classes, i.e., open set recognition (OSR) problem, which is an urgent problem for the practical SAR ATR. The key solution of OSR is to effectively establish the exclusiveness of feature distribution of known classes. In this letter, we propose an entropy-awareness meta-learning method that improves the exclusiveness of feature distribution of known classes which means our method is effective for not only classifying the seen classes but also encountering the unseen other classes. Through meta-learning tasks, the proposed method learns to construct a feature space of the dynamic-assigned known classes. This feature space is required by the tasks to reject all other classes not belonging to the known classes. At the same time, the proposed entropy-awareness loss helps the model to enhance the feature space with effective and robust discrimination between the known and unknown classes. Therefore, our method can construct a dynamic feature space with discrimination between the known and unknown classes to simultaneously classify the dynamic-assigned known classes and reject the unknown classes. Experiments conducted on the moving and stationary target acquisition and recognition (MSTAR) dataset have shown the effectiveness of our method for SAR OSR.
</details>
<details>
<summary>摘要</summary>
现有的Synthetic Aperture Radar自动目标识别（SAR ATR）方法已经有效地分类了见到的目标类。然而，更重要和挑战性的是分类未经见到的目标类，即开放集 recognition（OSR）问题，这是实际SAR ATR中的一个紧迫问题。OSR的关键解决方案是有效地建立已知类别的特征分布的独特性。在这封信中，我们提出了一种基于熵意识的meta-学习方法，该方法可以提高已知类别的特征分布独特性，即我们的方法可以不仅分类见到的类别，也可以遇到未经见到的其他类别。通过meta-学习任务，我们提出的方法学习了动态分配的已知类别的特征空间。这个特征空间是由任务需要拒绝不属于已知类别的所有其他类别。同时，我们的熵意识损失帮助模型增强特征空间的有效和可靠地区分已知和未知类别。因此，我们的方法可以建立动态的特征空间，同时分类动态分配的已知类别和拒绝未知类别。在MSTAR数据集上进行的实验表明了我们的方法在SAR OSR中的效果。
</details></li>
</ul>
<hr>
<h2 id="SAR-Ship-Target-Recognition-via-Selective-Feature-Discrimination-and-Multifeature-Center-Classifier"><a href="#SAR-Ship-Target-Recognition-via-Selective-Feature-Discrimination-and-Multifeature-Center-Classifier" class="headerlink" title="SAR Ship Target Recognition via Selective Feature Discrimination and Multifeature Center Classifier"></a>SAR Ship Target Recognition via Selective Feature Discrimination and Multifeature Center Classifier</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10250">http://arxiv.org/abs/2308.10250</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenwei Wang, Siyi Luo, Jifang Pei, Yulin Huang, Yin Zhang, Jianyu Yang</li>
<li>For: 本研究旨在提高空中遥感船舶目标识别精度，尤其是在资源价格较低的情况下。* Methods: 本研究提出了一种基于选择性特征分化和多特征中心分类器的SAR船舶目标识别方法。选择性特征分化自动地寻找最相似的多个类别之间的相似特征，并将不相似的特征提高为更大的内类分布。多特征中心分类器将每个船舶类别分配多个学习可能的特征中心，以分解大内类分布。* Results: 实验结果显示，我们的方法在对OpenSARShip和FUSAR-Ship datasets进行测试时，实现了与训练数据减少的高精度识别。<details>
<summary>Abstract</summary>
Maritime surveillance is not only necessary for every country, such as in maritime safeguarding and fishing controls, but also plays an essential role in international fields, such as in rescue support and illegal immigration control. Most of the existing automatic target recognition (ATR) methods directly send the extracted whole features of SAR ships into one classifier. The classifiers of most methods only assign one feature center to each class. However, the characteristics of SAR ship images, large inner-class variance, and small interclass difference lead to the whole features containing useless partial features and a single feature center for each class in the classifier failing with large inner-class variance. We proposes a SAR ship target recognition method via selective feature discrimination and multifeature center classifier. The selective feature discrimination automatically finds the similar partial features from the most similar interclass image pairs and the dissimilar partial features from the most dissimilar inner-class image pairs. It then provides a loss to enhance these partial features with more interclass separability. Motivated by divide and conquer, the multifeature center classifier assigns multiple learnable feature centers for each ship class. In this way, the multifeature centers divide the large inner-class variance into several smaller variances and conquered by combining all feature centers of one ship class. Finally, the probability distribution over all feature centers is considered comprehensively to achieve an accurate recognition of SAR ship images. The ablation experiments and experimental results on OpenSARShip and FUSAR-Ship datasets show that our method has achieved superior recognition performance under decreasing training SAR ship samples.
</details>
<details>
<summary>摘要</summary>
海上监控不仅是每个国家必需的，如海上安全和渔业控制，而且在国际领域也扮演着关键角色，如救援支持和非法移民控制。现有的自动目标识别（ATR）方法大多直接将扫描后的整个特征向量传递给一个分类器。但是，抛物线船图像的特征是巨大的内类差异和小的 между类差异，这导致整个特征向量包含了无用的部分特征和单个特征中心为每个类别的分类器失败。我们提出了一种基于选择特征筛选和多特征中心分类器的SAR船目标识别方法。选择特征筛选自动从最相似的interclass图像对中找到相似的部分特征和最不相似的inner-class图像对中找到不相似的部分特征，然后为这些部分特征提供损失以提高它们的 между类差异性。以分类器为核心，多特征中心分类器将每个船类分配多个学习的特征中心。这样，多个特征中心将内类差异分解为多个较小的差异，并通过将所有特征中心的一个船类拟合而 conquer。最后，对所有特征中心的概率分布进行全面考虑，以实现准确地识别SAR船图像。ablation实验和OpenSARShip和FUSAR-Ship数据集的实验结果表明，我们的方法在减少待学SAR船样本的情况下实现了superior的识别性能。
</details></li>
</ul>
<hr>
<h2 id="SAR-Ship-Target-Recognition-Via-Multi-Scale-Feature-Attention-and-Adaptive-Weighed-Classifier"><a href="#SAR-Ship-Target-Recognition-Via-Multi-Scale-Feature-Attention-and-Adaptive-Weighed-Classifier" class="headerlink" title="SAR Ship Target Recognition Via Multi-Scale Feature Attention and Adaptive-Weighed Classifier"></a>SAR Ship Target Recognition Via Multi-Scale Feature Attention and Adaptive-Weighed Classifier</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10247">http://arxiv.org/abs/2308.10247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenwei Wang, Jifang Pei, Siyi Luo, Weibo Huo, Yulin Huang, Yin Zhang, Jianyu Yang</li>
<li>for: 本研究旨在提高SAR船舶识别精度，解决SAR船舶特征之间的大内类差异和交叠问题。</li>
<li>methods: 我们提出了一种基于多级特征注意和自适应权重分类器的SAR船舶识别方法，通过提高每级特征的表征能力，适应选择有效的特征级别来实现高精度识别。</li>
<li>results: 通过对OpenSARship数据集进行实验和比较，我们的方法 Validated to achieve state-of-the-art performance for SAR ship recognition。<details>
<summary>Abstract</summary>
Maritime surveillance is indispensable for civilian fields, including national maritime safeguarding, channel monitoring, and so on, in which synthetic aperture radar (SAR) ship target recognition is a crucial research field. The core problem to realizing accurate SAR ship target recognition is the large inner-class variance and inter-class overlap of SAR ship features, which limits the recognition performance. Most existing methods plainly extract multi-scale features of the network and utilize equally each feature scale in the classification stage. However, the shallow multi-scale features are not discriminative enough, and each scale feature is not equally effective for recognition. These factors lead to the limitation of recognition performance. Therefore, we proposed a SAR ship recognition method via multi-scale feature attention and adaptive-weighted classifier to enhance features in each scale, and adaptively choose the effective feature scale for accurate recognition. We first construct an in-network feature pyramid to extract multi-scale features from SAR ship images. Then, the multi-scale feature attention can extract and enhance the principal components from the multi-scale features with more inner-class compactness and inter-class separability. Finally, the adaptive weighted classifier chooses the effective feature scales in the feature pyramid to achieve the final precise recognition. Through experiments and comparisons under OpenSARship data set, the proposed method is validated to achieve state-of-the-art performance for SAR ship recognition.
</details>
<details>
<summary>摘要</summary>
海上监测是民用领域不可或缺的，包括国家海上安全、水道监测等，Synthetic Aperture Radar（SAR）船target认识是一个关键的研究领域。recognition的核心问题是SAR船特征的大内类差和间类重叠，这限制了认识性能。现有方法通常是简单地提取网络中的多尺度特征，然后在分类阶段使用等效的每个特征尺度。然而，这些浅层多尺度特征并不是够精准的，每个尺度特征都不是等效的认识。这些因素导致了认识性能的限制。因此，我们提出了一种基于多尺度特征注意力和自适应权重分类器的SAR船认识方法，以提高每个尺度特征的表征力。我们首先在网络中构建了一个内部特征 piramid，以提取SAR船图像中的多尺度特征。然后，多尺度特征注意力可以提取和增强多尺度特征中的主成分，具有更高的内类紧密度和间类分化度。最后，自适应权重分类器可以选择网络中的有效特征尺度，以实现最终的精准认识。经过实验和比较，我们的方法在OpenSARship数据集上得到了国际顶尖的性能。
</details></li>
</ul>
<hr>
<h2 id="SAR-ATR-Method-with-Limited-Training-Data-via-an-Embedded-Feature-Augmenter-and-Dynamic-Hierarchical-Feature-Refiner"><a href="#SAR-ATR-Method-with-Limited-Training-Data-via-an-Embedded-Feature-Augmenter-and-Dynamic-Hierarchical-Feature-Refiner" class="headerlink" title="SAR ATR Method with Limited Training Data via an Embedded Feature Augmenter and Dynamic Hierarchical-Feature Refiner"></a>SAR ATR Method with Limited Training Data via an Embedded Feature Augmenter and Dynamic Hierarchical-Feature Refiner</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10243">http://arxiv.org/abs/2308.10243</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenwei Wang, Siyi Luo, Yulin Huang, Jifang Pei, Yin Zhang, Jianyu Yang</li>
<li>for: 提高SAR自动目标识别（ATR）性能，解决有限training数据的问题</li>
<li>methods: 提出了一种新的方法，包括：	1. 嵌入式特征增强器，用于增强EXTRACTED的虚拟特征，使其更加靠近类中心。	2. 动态嵌入特征改进器，用于捕捉样本中的特征，并将其与全局特征结合。</li>
<li>results: 实验结果表明，提出的方法可以在有限SAR训练数据的情况下提高ATR性能，并且在MSTAR、OpenSARShip和FUSAR-Ship测试数据集上达到了出色的性能。<details>
<summary>Abstract</summary>
Without sufficient data, the quantity of information available for supervised training is constrained, as obtaining sufficient synthetic aperture radar (SAR) training data in practice is frequently challenging. Therefore, current SAR automatic target recognition (ATR) algorithms perform poorly with limited training data availability, resulting in a critical need to increase SAR ATR performance. In this study, a new method to improve SAR ATR when training data are limited is proposed. First, an embedded feature augmenter is designed to enhance the extracted virtual features located far away from the class center. Based on the relative distribution of the features, the algorithm pulls the corresponding virtual features with different strengths toward the corresponding class center. The designed augmenter increases the amount of information available for supervised training and improves the separability of the extracted features. Second, a dynamic hierarchical-feature refiner is proposed to capture the discriminative local features of the samples. Through dynamically generated kernels, the proposed refiner integrates the discriminative local features of different dimensions into the global features, further enhancing the inner-class compactness and inter-class separability of the extracted features. The proposed method not only increases the amount of information available for supervised training but also extracts the discriminative features from the samples, resulting in superior ATR performance in problems with limited SAR training data. Experimental results on the moving and stationary target acquisition and recognition (MSTAR), OpenSARShip, and FUSAR-Ship benchmark datasets demonstrate the robustness and outstanding ATR performance of the proposed method in response to limited SAR training data.
</details>
<details>
<summary>摘要</summary>
Without sufficient data, the quantity of information available for supervised training is constrained, as obtaining sufficient synthetic aperture radar (SAR) training data in practice is frequently challenging. Therefore, current SAR automatic target recognition (ATR) algorithms perform poorly with limited training data availability, resulting in a critical need to increase SAR ATR performance. In this study, a new method to improve SAR ATR when training data are limited is proposed. First, an embedded feature augmenter is designed to enhance the extracted virtual features located far away from the class center. Based on the relative distribution of the features, the algorithm pulls the corresponding virtual features with different strengths toward the corresponding class center. The designed augmenter increases the amount of information available for supervised training and improves the separability of the extracted features. Second, a dynamic hierarchical-feature refiner is proposed to capture the discriminative local features of the samples. Through dynamically generated kernels, the proposed refiner integrates the discriminative local features of different dimensions into the global features, further enhancing the inner-class compactness and inter-class separability of the extracted features. The proposed method not only increases the amount of information available for supervised training but also extracts the discriminative features from the samples, resulting in superior ATR performance in problems with limited SAR training data. Experimental results on the moving and stationary target acquisition and recognition (MSTAR), OpenSARShip, and FUSAR-Ship benchmark datasets demonstrate the robustness and outstanding ATR performance of the proposed method in response to limited SAR training data.Note that the translation is in Simplified Chinese, which is one of the two standard versions of Chinese. The other version is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Blind-Face-Restoration-for-Under-Display-Camera-via-Dictionary-Guided-Transformer"><a href="#Blind-Face-Restoration-for-Under-Display-Camera-via-Dictionary-Guided-Transformer" class="headerlink" title="Blind Face Restoration for Under-Display Camera via Dictionary Guided Transformer"></a>Blind Face Restoration for Under-Display Camera via Dictionary Guided Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10196">http://arxiv.org/abs/2308.10196</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingfan Tan, Xiaoxu Chen, Tao Wang, Kaihao Zhang, Wenhan Luo, Xiaocun Cao<br>for:The paper aims to address the problem of restoring face images taken by under-display cameras (UDCs), which are affected by significant quality degradation due to the characteristics of the display.methods:The proposed method uses a two-stage network called UDC-DMNet to synthesize UDC images by modeling the processes of UDC imaging. Additionally, a novel dictionary-guided transformer network named DGFormer is proposed, which incorporates a facial component dictionary and the characteristics of UDC images to address blind face restoration in UDC scenarios.results:The proposed methods achieve state-of-the-art performance in restoring face images taken by UDCs, with the DGFormer and UDC-DMNet achieving high restoration performance.<details>
<summary>Abstract</summary>
By hiding the front-facing camera below the display panel, Under-Display Camera (UDC) provides users with a full-screen experience. However, due to the characteristics of the display, images taken by UDC suffer from significant quality degradation. Methods have been proposed to tackle UDC image restoration and advances have been achieved. There are still no specialized methods and datasets for restoring UDC face images, which may be the most common problem in the UDC scene. To this end, considering color filtering, brightness attenuation, and diffraction in the imaging process of UDC, we propose a two-stage network UDC Degradation Model Network named UDC-DMNet to synthesize UDC images by modeling the processes of UDC imaging. Then we use UDC-DMNet and high-quality face images from FFHQ and CelebA-Test to create UDC face training datasets FFHQ-P/T and testing datasets CelebA-Test-P/T for UDC face restoration. We propose a novel dictionary-guided transformer network named DGFormer. Introducing the facial component dictionary and the characteristics of the UDC image in the restoration makes DGFormer capable of addressing blind face restoration in UDC scenarios. Experiments show that our DGFormer and UDC-DMNet achieve state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
By hiding the front-facing camera below the display panel, Under-Display Camera (UDC) provides users with a full-screen experience. However, due to the characteristics of the display, images taken by UDC suffer from significant quality degradation. Methods have been proposed to tackle UDC image restoration, and advances have been achieved. However, there are still no specialized methods and datasets for restoring UDC face images, which may be the most common problem in the UDC scene.To address this issue, we propose a two-stage network called UDC Degradation Model Network (UDC-DMNet) to synthesize UDC images by modeling the processes of UDC imaging. We use UDC-DMNet and high-quality face images from FFHQ and CelebA-Test to create UDC face training datasets FFHQ-P/T and testing datasets CelebA-Test-P/T for UDC face restoration.Furthermore, we propose a novel dictionary-guided transformer network named DGFormer. By introducing the facial component dictionary and the characteristics of the UDC image in the restoration, DGFormer is capable of addressing blind face restoration in UDC scenarios. Experiments show that our DGFormer and UDC-DMNet achieve state-of-the-art performance.
</details></li>
</ul>
<hr>
<h2 id="WMFormer-Nested-Transformer-for-Visible-Watermark-Removal-via-Implict-Joint-Learning"><a href="#WMFormer-Nested-Transformer-for-Visible-Watermark-Removal-via-Implict-Joint-Learning" class="headerlink" title="WMFormer++: Nested Transformer for Visible Watermark Removal via Implict Joint Learning"></a>WMFormer++: Nested Transformer for Visible Watermark Removal via Implict Joint Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10195">http://arxiv.org/abs/2308.10195</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongjian Huo, Zehong Zhang, Hanjing Su, Guanbin Li, Chaowei Fang, Qingyao Wu</li>
<li>for: 本研究旨在提高水印 removing 技术的 robustness，以便更好地保护媒体 copyright。</li>
<li>methods: 本研究使用了一种新的 JOINT learning 方法，该方法可以自动地 navigates 信息 между不同的 branche，以提高水印 localization 和背景图像 Restoration 的效果。</li>
<li>results: 实验结果表明，本研究的方法在多种 challenging  bencmarks 上具有remarkable 的超越性，与现有的状态 искусственный智能方法相比，具有大量的优势。<details>
<summary>Abstract</summary>
Watermarking serves as a widely adopted approach to safeguard media copyright. In parallel, the research focus has extended to watermark removal techniques, offering an adversarial means to enhance watermark robustness and foster advancements in the watermarking field. Existing watermark removal methods mainly rely on UNet with task-specific decoder branches--one for watermark localization and the other for background image restoration. However, watermark localization and background restoration are not isolated tasks; precise watermark localization inherently implies regions necessitating restoration, and the background restoration process contributes to more accurate watermark localization. To holistically integrate information from both branches, we introduce an implicit joint learning paradigm. This empowers the network to autonomously navigate the flow of information between implicit branches through a gate mechanism. Furthermore, we employ cross-channel attention to facilitate local detail restoration and holistic structural comprehension, while harnessing nested structures to integrate multi-scale information. Extensive experiments are conducted on various challenging benchmarks to validate the effectiveness of our proposed method. The results demonstrate our approach's remarkable superiority, surpassing existing state-of-the-art methods by a large margin.
</details>
<details>
<summary>摘要</summary>
水印技术是现代媒体版权保护的广泛采用方法之一。同时，研究焦点已经扩展到水印去除技术，提供了一种对抗性的方法，以增强水印的鲁棒性和促进水印技术的发展。现有的水印去除方法主要基于UNet架构，包括一个用于水印定位和另一个用于背景图像修复的任务特定分支。然而，水印定位和背景修复不是独立的任务，准确的水印定位直接 implies 需要修复的区域，而背景修复过程也会提高水印定位的准确性。为了整合这两个分支的信息，我们引入了隐式联合学习 paradigm。这使得网络可以自动地在两个分支之间流动信息，通过门 mechanism。此外，我们还使用了跨通道注意力来促进地方细节修复和整体结构认知，同时利用嵌入结构来整合多尺度信息。我们对多个挑战性的标准均衡进行了广泛的实验，以验证我们的提出的方法的有效性。结果表明，我们的方法在与现有状态态的方法进行比较时表现出了很大的超越。
</details></li>
</ul>
<hr>
<h2 id="EDDense-Net-Fully-Dense-Encoder-Decoder-Network-for-Joint-Segmentation-of-Optic-Cup-and-Disc"><a href="#EDDense-Net-Fully-Dense-Encoder-Decoder-Network-for-Joint-Segmentation-of-Optic-Cup-and-Disc" class="headerlink" title="EDDense-Net: Fully Dense Encoder Decoder Network for Joint Segmentation of Optic Cup and Disc"></a>EDDense-Net: Fully Dense Encoder Decoder Network for Joint Segmentation of Optic Cup and Disc</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10192">http://arxiv.org/abs/2308.10192</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mehwish Mehmood, Khuram Naveed, Haroon Ahmed Khan, Syed S. Naqvi</li>
<li>for: 该论文用于检测和诊断眼内病变，尤其是检测患有眼内疾病的人群中的视网膜损害。</li>
<li>methods: 该论文提出了一种基于 dense block 的 ED-Dense-Net  segmentation网络，用于同时 segmentation 眼内粘膜（OC）和视网膜（OD）。该网络包括编码器和解码器，每个块都包含了分组 convolutional layer，以便网络能够从图像中获取和传递空间信息，同时降低网络的复杂度。</li>
<li>results: 该论文在两个公共可用的数据集上进行了评估，并与现有的状态态的方法进行了比较。结果显示，该方法在准确率和效率方面都高于现有的方法。因此，该方法可以作为医学针对系统，帮助医学眼科医生进行诊断和分析。<details>
<summary>Abstract</summary>
Glaucoma is an eye disease that causes damage to the optic nerve, which can lead to visual loss and permanent blindness. Early glaucoma detection is therefore critical in order to avoid permanent blindness. The estimation of the cup-to-disc ratio (CDR) during an examination of the optical disc (OD) is used for the diagnosis of glaucoma. In this paper, we present the EDDense-Net segmentation network for the joint segmentation of OC and OD. The encoder and decoder in this network are made up of dense blocks with a grouped convolutional layer in each block, allowing the network to acquire and convey spatial information from the image while simultaneously reducing the network's complexity. To reduce spatial information loss, the optimal number of filters in all convolution layers were utilised. In semantic segmentation, dice pixel classification is employed in the decoder to alleviate the problem of class imbalance. The proposed network was evaluated on two publicly available datasets where it outperformed existing state-of-the-art methods in terms of accuracy and efficiency. For the diagnosis and analysis of glaucoma, this method can be used as a second opinion system to assist medical ophthalmologists.
</details>
<details>
<summary>摘要</summary>
Glaucoma 是一种影视疾病，可以导致视网膜损害，从而引起视力下降和永久溃疡。 Early detection of glaucoma 是非常重要，以避免永久溃疡。在诊断 glaucoma 时， estimation of cup-to-disc ratio (CDR) 是非常重要的。在这篇论文中，我们提出了 EDDense-Net  segmentation 网络，用于同时 segments OC 和 OD。这个网络的encoder 和 decoder 都由密集层组成，每个密集层都有 grouped convolutional layer，使网络可以从图像中获取和传递空间信息，同时减少网络的复杂性。为了避免空间信息损失，我们使用了最佳数量的 filters 在所有卷积层中。在 semantic segmentation 中，我们使用了 dice pixel classification 来缓解类别不均衡问题。我们的方法在两个公共可用的数据集上进行了评估，并在精度和效率方面超过了现有的状态对照方法。这种方法可以作为医疗视科医生的第二意见系统，帮助他们诊断和分析 glaucoma。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Diffusion-Model-with-Auxiliary-Guidance-for-Coarse-to-Fine-PET-Reconstruction"><a href="#Contrastive-Diffusion-Model-with-Auxiliary-Guidance-for-Coarse-to-Fine-PET-Reconstruction" class="headerlink" title="Contrastive Diffusion Model with Auxiliary Guidance for Coarse-to-Fine PET Reconstruction"></a>Contrastive Diffusion Model with Auxiliary Guidance for Coarse-to-Fine PET Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10157">http://arxiv.org/abs/2308.10157</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/show-han/pet-reconstruction">https://github.com/show-han/pet-reconstruction</a></li>
<li>paper_authors: Zeyu Han, Yuhan Wang, Luping Zhou, Peng Wang, Binyu Yan, Jiliu Zhou, Yan Wang, Dinggang Shen<br>for:  This paper aims to improve the quality of standard-dose positron emission tomography (PET) scans while reducing radiation exposure to the human body.methods:  The proposed method uses a coarse-to-fine framework that consists of a coarse prediction module (CPM) and an iterative refinement module (IRM). The CPM generates a coarse PET image via a deterministic process, while the IRM samples the residual iteratively. Additionally, two strategies are proposed and integrated into the reconstruction process to enhance the correspondence between the low-dose PET (LPET) image and the reconstructed PET (RPET) image.results:  The proposed method outperforms state-of-the-art PET reconstruction methods in terms of clinical reliability, as demonstrated by extensive experiments on two human brain PET datasets.<details>
<summary>Abstract</summary>
To obtain high-quality positron emission tomography (PET) scans while reducing radiation exposure to the human body, various approaches have been proposed to reconstruct standard-dose PET (SPET) images from low-dose PET (LPET) images. One widely adopted technique is the generative adversarial networks (GANs), yet recently, diffusion probabilistic models (DPMs) have emerged as a compelling alternative due to their improved sample quality and higher log-likelihood scores compared to GANs. Despite this, DPMs suffer from two major drawbacks in real clinical settings, i.e., the computationally expensive sampling process and the insufficient preservation of correspondence between the conditioning LPET image and the reconstructed PET (RPET) image. To address the above limitations, this paper presents a coarse-to-fine PET reconstruction framework that consists of a coarse prediction module (CPM) and an iterative refinement module (IRM). The CPM generates a coarse PET image via a deterministic process, and the IRM samples the residual iteratively. By delegating most of the computational overhead to the CPM, the overall sampling speed of our method can be significantly improved. Furthermore, two additional strategies, i.e., an auxiliary guidance strategy and a contrastive diffusion strategy, are proposed and integrated into the reconstruction process, which can enhance the correspondence between the LPET image and the RPET image, further improving clinical reliability. Extensive experiments on two human brain PET datasets demonstrate that our method outperforms the state-of-the-art PET reconstruction methods. The source code is available at \url{https://github.com/Show-han/PET-Reconstruction}.
</details>
<details>
<summary>摘要</summary>
为了获得高质量的 positron emission tomography（PET）扫描图像，同时减少人体被暴露于辐射的风险，不同的方法已经被提议用于从低剂量PET（LPET）图像中重建标准剂量PET（SPET）图像。一种广泛采用的方法是生成 adversarial networks（GANs），然而，最近，扩散概率模型（DPMs）已经出现为一种吸引人的替代方案，因为它们可以提供更高的样本质量和更高的logslikelihood分数。然而，DPMs在实际临床应用中受到两个主要的限制：一是计算昂贵的采样过程，二是不足的保留LPET图像和重建PET图像之间的对应关系。为了解决以上限制，本文提出了一种粗略到细节的PET重建框架，包括一个粗略预测模块（CPM）和一个迭代优化模块（IRM）。CPM使用权重函数生成一个粗略PET图像，而IRM采样了剩余的信息，并在每次迭代中优化PET图像。通过委托大部分计算负担给CPM，我们的方法的总采样速度可以得到明显的提高。此外，我们还提出了两种附加策略，即auxiliary guidance strategy和contrastive diffusion strategy，并将它们纳入重建过程中，以进一步提高LPET图像和重建PET图像之间的对应关系，从而提高临床可靠性。我们在两个人脑PET数据集上进行了广泛的实验，结果表明，我们的方法超过了现有的PET重建方法。源代码可以在 \url{https://github.com/Show-han/PET-Reconstruction} 中下载。
</details></li>
</ul>
<hr>
<h2 id="Federated-Pseudo-Modality-Generation-for-Incomplete-Multi-Modal-MRI-Reconstruction"><a href="#Federated-Pseudo-Modality-Generation-for-Incomplete-Multi-Modal-MRI-Reconstruction" class="headerlink" title="Federated Pseudo Modality Generation for Incomplete Multi-Modal MRI Reconstruction"></a>Federated Pseudo Modality Generation for Incomplete Multi-Modal MRI Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10910">http://arxiv.org/abs/2308.10910</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunlu Yan, Chun-Mei Feng, Yuexiang Li, Rick Siow Mong Goh, Lei Zhu</li>
<li>for:  addresses the missing modality challenge in federated multi-modal MRI reconstruction</li>
<li>methods:  utilizes a pseudo modality generation mechanism to recover the missing modality, and introduces a clustering scheme to reduce communication costs</li>
<li>results:  can effectively complete the missing modality within an acceptable communication cost, with similar performance to the ideal scenario<details>
<summary>Abstract</summary>
While multi-modal learning has been widely used for MRI reconstruction, it relies on paired multi-modal data which is difficult to acquire in real clinical scenarios. Especially in the federated setting, the common situation is that several medical institutions only have single-modal data, termed the modality missing issue. Therefore, it is infeasible to deploy a standard federated learning framework in such conditions. In this paper, we propose a novel communication-efficient federated learning framework, namely Fed-PMG, to address the missing modality challenge in federated multi-modal MRI reconstruction. Specifically, we utilize a pseudo modality generation mechanism to recover the missing modality for each single-modal client by sharing the distribution information of the amplitude spectrum in frequency space. However, the step of sharing the original amplitude spectrum leads to heavy communication costs. To reduce the communication cost, we introduce a clustering scheme to project the set of amplitude spectrum into finite cluster centroids, and share them among the clients. With such an elaborate design, our approach can effectively complete the missing modality within an acceptable communication cost. Extensive experiments demonstrate that our proposed method can attain similar performance with the ideal scenario, i.e., all clients have the full set of modalities. The source code will be released.
</details>
<details>
<summary>摘要</summary>
在多模式学习广泛应用于MRI重建中，它依赖于对应的多模式数据，但在实际临床场景下获得这些数据是困难的。特别在联邦设置下，许多医疗机构只有单模式数据，称之为模式缺失问题。因此，使用标准联邦学习框架是无法实现的。在这篇论文中，我们提出了一种新的通信效率高的联邦学习框架，即Fed-PMG，以解决联邦多模式MRI重建中的模式缺失问题。特别是，我们利用 pseudo 模式生成机制来为每个单模式客户端 recuperate 缺失的模式。然而，在共享原始幅谱信息时，会导致重大的通信成本。为了减少通信成本，我们提出了一种归一化 schemes，将幅谱信息Project 到finite cluster centroids，并在客户端之间分享它们。与这种细化的设计相比，我们的方法可以有效地完成缺失模式，并且在接受ABLE 的通信成本下。我们的实验结果表明，我们的提议方法可以达到与理想情况（即所有客户端具有完整的模式）的相似性。源代码将发布。
</details></li>
</ul>
<hr>
<h2 id="Polymerized-Feature-based-Domain-Adaptation-for-Cervical-Cancer-Dose-Map-Prediction"><a href="#Polymerized-Feature-based-Domain-Adaptation-for-Cervical-Cancer-Dose-Map-Prediction" class="headerlink" title="Polymerized Feature-based Domain Adaptation for Cervical Cancer Dose Map Prediction"></a>Polymerized Feature-based Domain Adaptation for Cervical Cancer Dose Map Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10142">http://arxiv.org/abs/2308.10142</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Zeng, Zeyu Han, Xingchen Peng, Jianghong Xiao, Peng Wang, Yan Wang</li>
<li>for: 这篇论文是为了提高乳腺癌规划辅助的深度学习（DL）方法，以增强输入数据的对应性和预测精度。</li>
<li>methods: 本研究使用了对另一种肝癌（rectum cancer）的丰富知识进行领域适应，以优化乳腺癌的剂量地图预测性能。具体来说，我们开发了一个高效的Transformer型态变分布（PFM）模组，可以生成一个最佳的共聚分布，以缓和两个输入分布的对应关系。</li>
<li>results: 实验结果显示，提案的方法比现有方法更高效，能够更好地预测乳腺癌的剂量地图。<details>
<summary>Abstract</summary>
Recently, deep learning (DL) has automated and accelerated the clinical radiation therapy (RT) planning significantly by predicting accurate dose maps. However, most DL-based dose map prediction methods are data-driven and not applicable for cervical cancer where only a small amount of data is available. To address this problem, this paper proposes to transfer the rich knowledge learned from another cancer, i.e., rectum cancer, which has the same scanning area and more clinically available data, to improve the dose map prediction performance for cervical cancer through domain adaptation. In order to close the congenital domain gap between the source (i.e., rectum cancer) and the target (i.e., cervical cancer) domains, we develop an effective Transformer-based polymerized feature module (PFM), which can generate an optimal polymerized feature distribution to smoothly align the two input distributions. Experimental results on two in-house clinical datasets demonstrate the superiority of the proposed method compared with state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
近期，深度学习（DL）已经自动化和加速了临床辐射治疗（RT）规划，并且预测精确剂量图。然而，大多数DL基于的剂量图预测方法是数据驱动的，而且不适用于颈部癌，因为颈部癌的数据很少。为解决这个问题，本文提出了将另一种癌种（ namely，肛门癌）的丰富知识传播到颈部癌中，以提高剂量图预测性能。为了关闭预生域差距 между源（即肛门癌）和目标（即颈部癌）域，我们开发了一种高效的Transformer基于的聚合特征模块（PFM），可以生成一个最佳的聚合特征分布，以平滑地将两个输入分布对齐。实验结果表明，提出的方法在两个自有临床数据集上比状态元方法更高效。
</details></li>
</ul>
<hr>
<h2 id="Sensitivity-analysis-of-AI-based-algorithms-for-autonomous-driving-on-optical-wavefront-aberrations-induced-by-the-windshield"><a href="#Sensitivity-analysis-of-AI-based-algorithms-for-autonomous-driving-on-optical-wavefront-aberrations-induced-by-the-windshield" class="headerlink" title="Sensitivity analysis of AI-based algorithms for autonomous driving on optical wavefront aberrations induced by the windshield"></a>Sensitivity analysis of AI-based algorithms for autonomous driving on optical wavefront aberrations induced by the windshield</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11711">http://arxiv.org/abs/2308.11711</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dominik Werner Wolf, Markus Ulrich, Nikhil Kapoor</li>
<li>for: 这篇论文是关于自动驾驶感知技术的，具体来说是研究这些技术在不同车辆和镜头配置下的性能问题。</li>
<li>methods: 这篇论文使用了supervised机器学习模型，并在实际街道数据上进行了训练。但是，将这些训练模型应用于不同的车辆和镜头配置可能会导致域名shift问题，这可能会影响机器学习模型的性能和工作ADAS的要求。</li>
<li>results: 这篇论文通过evaluating两个感知模型对不同镜头配置的敏感性来研究域名shift问题。结果显示，镜头配置会导致性能差距，而现有的光学度量函数可能不够用于 pose 要求。<details>
<summary>Abstract</summary>
Autonomous driving perception techniques are typically based on supervised machine learning models that are trained on real-world street data. A typical training process involves capturing images with a single car model and windshield configuration. However, deploying these trained models on different car types can lead to a domain shift, which can potentially hurt the neural networks performance and violate working ADAS requirements. To address this issue, this paper investigates the domain shift problem further by evaluating the sensitivity of two perception models to different windshield configurations. This is done by evaluating the dependencies between neural network benchmark metrics and optical merit functions by applying a Fourier optics based threat model. Our results show that there is a performance gap introduced by windshields and existing optical metrics used for posing requirements might not be sufficient.
</details>
<details>
<summary>摘要</summary>
自主驾驶感知技术通常基于指导学习模型，这些模型通过实际街道数据进行训练。一般来说，训练过程中使用单一汽车型和车窗配置拍摄图像。然而，将这些训练过的模型部署到不同的汽车类型上可能会导致域shift问题，这可能会影响神经网络性能并违反工作ADAS要求。为解决这个问题，本文进一步调查了域shift问题，并评估了两种感知模型对不同车窗配置的敏感性。我们通过应用 Fourier optics 基于威胁模型来评估神经网络指标与光学功能函数之间的相互关系。我们的结果显示，车窗会引入性能差距，而现有的光学指标可能不够用于满足工作ADAS要求。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/20/eess.IV_2023_08_20/" data-id="clohum9fc013qpj88fqrc80rn" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_19" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/19/cs.SD_2023_08_19/" class="article-date">
  <time datetime="2023-08-19T15:00:00.000Z" itemprop="datePublished">2023-08-19</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/19/cs.SD_2023_08_19/">cs.SD - 2023-08-19</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Spatial-Reconstructed-Local-Attention-Res2Net-with-F0-Subband-for-Fake-Speech-Detection"><a href="#Spatial-Reconstructed-Local-Attention-Res2Net-with-F0-Subband-for-Fake-Speech-Detection" class="headerlink" title="Spatial Reconstructed Local Attention Res2Net with F0 Subband for Fake Speech Detection"></a>Spatial Reconstructed Local Attention Res2Net with F0 Subband for Fake Speech Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09944">http://arxiv.org/abs/2308.09944</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cunhang Fan, Jun Xue, Jianhua Tao, Jiangyan Yi, Chenglong Wang, Chengshi Zheng, Zhao Lv<br>for: 本研究旨在提高假语音识别（FSD）任务的性能，特别是对于rhythm of synthetic speech too smooth的问题。methods: 本文提出了一种新的F0子带，以及一种具有spatial reconstructed local attention的Res2Net网络（SR-LA Res2Net）。results: 在ASVspoof 2019 LA数据集上，我们的提议方法实现了EER值为0.47%和min t-DCF值为0.0159，与所有单个系统中的最佳性能相当。<details>
<summary>Abstract</summary>
The rhythm of synthetic speech is usually too smooth, which causes that the fundamental frequency (F0) of synthetic speech is significantly different from that of real speech. It is expected that the F0 feature contains the discriminative information for the fake speech detection (FSD) task. In this paper, we propose a novel F0 subband for FSD. In addition, to effectively model the F0 subband so as to improve the performance of FSD, the spatial reconstructed local attention Res2Net (SR-LA Res2Net) is proposed. Specifically, Res2Net is used as a backbone network to obtain multiscale information, and enhanced with a spatial reconstruction mechanism to avoid losing important information when the channel group is constantly superimposed. In addition, local attention is designed to make the model focus on the local information of the F0 subband. Experimental results on the ASVspoof 2019 LA dataset show that our proposed method obtains an equal error rate (EER) of 0.47% and a minimum tandem detection cost function (min t-DCF) of 0.0159, achieving the state-of-the-art performance among all of the single systems.
</details>
<details>
<summary>摘要</summary>
文本中的人工语音的节奏通常太平滑，导致人工语音的基本频率（F0）与实际语音的F0有所不同。这些F0特征含有识别假语音的重要信息。在这篇论文中，我们提出了一种新的F0子带 для假语音检测（FSD）任务。此外，为了有效地模型F0子带，我们还提出了一种空间重建本地注意力Res2Net（SR-LA Res2Net）。具体来说，Res2Net被用作背景网络，以获取多尺度信息，并在核心矩阵上添加空间重建机制，以避免损失重要信息。此外，本地注意力被设计来使模型关注F0子带的本地信息。实验结果表明，我们提出的方法在ASVspoof 2019 LA数据集上达到了单个系统的状态略进行性表现，其EER为0.47%，min t-DCF为0.0159。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/19/cs.SD_2023_08_19/" data-id="clohum9bm00tspj8820sq4opn" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_19" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/19/cs.CV_2023_08_19/" class="article-date">
  <time datetime="2023-08-19T13:00:00.000Z" itemprop="datePublished">2023-08-19</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/19/cs.CV_2023_08_19/">cs.CV - 2023-08-19</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="DPL-Decoupled-Prompt-Learning-for-Vision-Language-Models"><a href="#DPL-Decoupled-Prompt-Learning-for-Vision-Language-Models" class="headerlink" title="DPL: Decoupled Prompt Learning for Vision-Language Models"></a>DPL: Decoupled Prompt Learning for Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10061">http://arxiv.org/abs/2308.10061</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Xu, Yuhan Zhu, Guozhen Zhang, Haocheng Shen, Yixuan Liao, Xiaoxin Chen, Gangshan Wu, Limin Wang</li>
<li>for: 本研究旨在提高CLIP模型的下游任务迁移效果，但现有方法通常会过拟合已经看过的类别， thereby limiting its generalization ability for unseen classes.</li>
<li>methods: 我们提出了一种新的方法，即分离提示学习（DPL），它通过重新定义提示学习的注意力进程来解决这个问题。 Specifically, we theoretically investigate the collaborative process between prompts and instances (i.e., image patches&#x2F;text tokens) by reformulating the original self-attention into four separate sub-processes.</li>
<li>results: 我们的方法可以在三个代表性的 benchmark 上取得状态机器的表现，包括15个图像识别数据集，而且不需要任何辅助正则化任务或额外训练数据，进一步表明了其惊人的泛化能力。<details>
<summary>Abstract</summary>
Prompt learning has emerged as an efficient and effective approach for transferring foundational Vision-Language Models (e.g., CLIP) to downstream tasks. However, current methods tend to overfit to seen categories, thereby limiting their generalization ability for unseen classes. In this paper, we propose a new method, Decoupled Prompt Learning (DPL), which reformulates the attention in prompt learning to alleviate this problem. Specifically, we theoretically investigate the collaborative process between prompts and instances (i.e., image patches/text tokens) by reformulating the original self-attention into four separate sub-processes. Through detailed analysis, we observe that certain sub-processes can be strengthened to bolster robustness and generalizability by some approximation techniques. Furthermore, we introduce language-conditioned textual prompting based on decoupled attention to naturally preserve the generalization of text input. Our approach is flexible for both visual and textual modalities, making it easily extendable to multi-modal prompt learning. By combining the proposed techniques, our approach achieves state-of-the-art performance on three representative benchmarks encompassing 15 image recognition datasets, while maintaining parameter-efficient. Moreover, our DPL does not rely on any auxiliary regularization task or extra training data, further demonstrating its remarkable generalization ability.
</details>
<details>
<summary>摘要</summary>
提高学习（Prompt Learning）已经成为跨类 Task 迁移Foundational Vision-Language Models（例如 CLIP）的有效和高效的方法。然而，现有方法往往会遇到seen类，从而限制其对未seen类的泛化能力。在这篇论文中，我们提出了一种新的方法：异步Prompt Learning（DPL），该方法通过重新推导提问的注意力来缓解这个问题。 Specifically，我们对提问和实例（即图像 patches/文本token）之间的协作过程进行了理论性的调查，并将原始自注意转化为四个独立的子过程。通过详细分析，我们发现了一些子过程可以通过一些抽象技巧加强，以提高抗衰假性和泛化能力。此外，我们引入了基于异步注意力的语言条件文本提问，以保持文本输入的泛化。我们的方法可以轻松扩展到多模态提问学习。通过结合我们的方法，我们的DPL实现了三个代表性的标准准则，包括15个图像识别数据集，而不需要额外的训练数据或auxiliary regularization任务，再次证明了它的强大泛化能力。
</details></li>
</ul>
<hr>
<h2 id="R-C-P-Method-An-Autonomous-Volume-Calculation-Method-Using-Image-Processing-and-Machine-Vision"><a href="#R-C-P-Method-An-Autonomous-Volume-Calculation-Method-Using-Image-Processing-and-Machine-Vision" class="headerlink" title="R-C-P Method: An Autonomous Volume Calculation Method Using Image Processing and Machine Vision"></a>R-C-P Method: An Autonomous Volume Calculation Method Using Image Processing and Machine Vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10058">http://arxiv.org/abs/2308.10058</a></li>
<li>repo_url: None</li>
<li>paper_authors: MA Muktadir, Sydney Parker, Sun Yi</li>
<li>for: 这个论文的目的是提供一种基于多个2D相机的实时三维空间量化和变化信息获取方法，以取代深度摄像头。</li>
<li>methods: 该方法使用图像处理和边检测技术，开发了ROW-COLUMN-PIXEL（纵列像素）方法，可以实时测量物体的面积和变化。</li>
<li>results: 实验结果表明，ROW-COLUMN-PIXEL方法可以准确地测量物体的面积和变化，并且可以检测物体上的不连续边或体积。<details>
<summary>Abstract</summary>
Machine vision and image processing are often used with sensors for situation awareness in autonomous systems, from industrial robots to self-driving cars. The 3D depth sensors, such as LiDAR (Light Detection and Ranging), Radar, are great invention for autonomous systems. Due to the complexity of the setup, LiDAR may not be suitable for some operational environments, for example, a space environment. This study was motivated by a desire to get real-time volumetric and change information with multiple 2D cameras instead of a depth camera. Two cameras were used to measure the dimensions of a rectangular object in real-time. The R-C-P (row-column-pixel) method is developed using image processing and edge detection. In addition to the surface areas, the R-C-P method also detects discontinuous edges or volumes. Lastly, experimental work is presented for illustration of the R-C-P method, which provides the equations for calculating surface area dimensions. Using the equations with given distance information between the object and the camera, the vision system provides the dimensions of actual objects.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ControlCom-Controllable-Image-Composition-using-Diffusion-Model"><a href="#ControlCom-Controllable-Image-Composition-using-Diffusion-Model" class="headerlink" title="ControlCom: Controllable Image Composition using Diffusion Model"></a>ControlCom: Controllable Image Composition using Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10040">http://arxiv.org/abs/2308.10040</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bcmi/controlcom-image-composition">https://github.com/bcmi/controlcom-image-composition</a></li>
<li>paper_authors: Bo Zhang, Yuxuan Duan, Jun Lan, Yan Hong, Huijia Zhu, Weiqiang Wang, Li Niu</li>
<li>for: 本研究旨在实现一种可控的图像组合方法，能够生成真实、自然的组合图像。</li>
<li>methods: 本方法基于大型预训练的扩散模型，并实现了四个任务的混合：图像融合、图像和谐、视觉合成和生成组合。</li>
<li>results: 对于公共benchmark数据和实际数据，我们的方法可以生成更加忠诚和可控的组合图像，比现有方法更高效。<details>
<summary>Abstract</summary>
Image composition targets at synthesizing a realistic composite image from a pair of foreground and background images. Recently, generative composition methods are built on large pretrained diffusion models to generate composite images, considering their great potential in image generation. However, they suffer from lack of controllability on foreground attributes and poor preservation of foreground identity. To address these challenges, we propose a controllable image composition method that unifies four tasks in one diffusion model: image blending, image harmonization, view synthesis, and generative composition. Meanwhile, we design a self-supervised training framework coupled with a tailored pipeline of training data preparation. Moreover, we propose a local enhancement module to enhance the foreground details in the diffusion model, improving the foreground fidelity of composite images. The proposed method is evaluated on both public benchmark and real-world data, which demonstrates that our method can generate more faithful and controllable composite images than existing approaches. The code and model will be available at https://github.com/bcmi/ControlCom-Image-Composition.
</details>
<details>
<summary>摘要</summary>
Image composition targets at synthesizing a realistic composite image from a pair of foreground and background images. Recently, generative composition methods are built on large pretrained diffusion models to generate composite images, considering their great potential in image generation. However, they suffer from lack of controllability on foreground attributes and poor preservation of foreground identity. To address these challenges, we propose a controllable image composition method that unifies four tasks in one diffusion model: image blending, image harmonization, view synthesis, and generative composition. Meanwhile, we design a self-supervised training framework coupled with a tailored pipeline of training data preparation. Moreover, we propose a local enhancement module to enhance the foreground details in the diffusion model, improving the foreground fidelity of composite images. The proposed method is evaluated on both public benchmark and real-world data, which demonstrates that our method can generate more faithful and controllable composite images than existing approaches. The code and model will be available at https://github.com/bcmi/ControlCom-Image-Composition.
</details></li>
</ul>
<hr>
<h2 id="CRC-ICM-Colorectal-Cancer-Immune-Cell-Markers-Pattern-Dataset"><a href="#CRC-ICM-Colorectal-Cancer-Immune-Cell-Markers-Pattern-Dataset" class="headerlink" title="CRC-ICM: Colorectal Cancer Immune Cell Markers Pattern Dataset"></a>CRC-ICM: Colorectal Cancer Immune Cell Markers Pattern Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10033">http://arxiv.org/abs/2308.10033</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zahra Mokhtari, Elham Amjadi, Hamidreza Bolhasani, Zahra Faghih, AmirReza Dehghanian, Marzieh Rezaei</li>
<li>For: The paper is written to explore the differences in immune checkpoints expression in primary tumors located in the right and left sides of the colon, and to investigate the prognostic value of these checkpoints in colorectal cancer (CRC).* Methods: The study uses a dataset of 1756 images related to 136 patients, stained with specific antibodies for CD3, CD8, CD45RO, PD-1, LAG3, and Tim3.* Results: The study found that tumors on the left and right sides of the colon have different immune landscapes, with differences in the expression of immune checkpoints such as PD-1, LAG3, and Tim3. These differences may have implications for the prognosis of CRC patients.<details>
<summary>Abstract</summary>
Colorectal Cancer (CRC) is the second most common cause of cancer death in the world, ad can be identified by the location of the primary tumor in the large intestine: right and left colon, and rectum. Based on the location, CRC shows differences in chromosomal and molecular characteristics, microbiomes incidence, pathogenesis, and outcome. It has been shown that tumors on left and right sides also have different immune landscape, so the prognosis may be different based on the primary tumor locations. It is widely accepted that immune components of the tumor microenvironment (TME) plays a critical role in tumor development. One of the critical regulatory molecules in the TME is immune checkpoints that as the gatekeepers of immune responses regulate the infiltrated immune cell functions. Inhibitory immune checkpoints such as PD-1, Tim3, and LAG3, as the main mechanism of immune suppression in TME overexpressed and result in further development of the tumor. The images of this dataset have been taken from colon tissues of patients with CRC, stained with specific antibodies for CD3, CD8, CD45RO, PD-1, LAG3 and Tim3. The name of this dataset is CRC-ICM and contains 1756 images related to 136 patients. The initial version of CRC-ICM is published on Elsevier Mendeley dataset portal, and the latest version is accessible via: https://databiox.com
</details>
<details>
<summary>摘要</summary>
“幽门肉瘤癌（CRC）是全球第二常见的癌症死亡原因，可以根据主癌肿 locus在大小肠中进行定位：右和左大肠、RECTUM。根据位置，CRC具有不同的染色体和分子特征、微生物发生率、生成和结果。已经证明左右两侧的肿均具有不同的免疫景观，因此诊断结果可能因primary tumor location而异。广泛认可的是，免疫组件在肿瘤微环境（TME）中扮演了关键的角色，其中一种关键的调控分子是免疫检查点。压缩性免疫检查点如PD-1、Tim3和LAG3等，是TME中免疫抑制的主要机制，过度表达导致肿瘤进一步发展。这些图像来自于患有CRC的大肠组织，用specific抗体染色CD3、CD8、CD45RO、PD-1、LAG3和Tim3。该数据集名为CRC-ICM，包含1756张图像，与136名患者相关。最初版本在Elsevier Mendeley数据集门户上发布，最新版本可以通过以下链接访问：https://databiox.com”
</details></li>
</ul>
<hr>
<h2 id="Single-Image-Reflection-Separation-via-Component-Synergy"><a href="#Single-Image-Reflection-Separation-via-Component-Synergy" class="headerlink" title="Single Image Reflection Separation via Component Synergy"></a>Single Image Reflection Separation via Component Synergy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10027">http://arxiv.org/abs/2308.10027</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mingcv/dsrnet">https://github.com/mingcv/dsrnet</a></li>
<li>paper_authors: Qiming Hu, Xiaojie Guo</li>
<li>for: 本研究旨在提出更一般的折射模型，以更好地捕捉剩下的信息，使分解层更加完整。</li>
<li>methods: 该研究基于现有模型的缺陷进行调查，并引入学习式偏移项，以捕捉剩下的信息。同时，我们还设计了网络结构，包括一种新型的双流交互机制和一种强大的分解网络。</li>
<li>results: 我们通过广泛的实验和减少研究，证明我们的方法在多个真实世界的标准 benchmark 数据集上表现出色，胜过当前的状态艺术方法。我们的代码可以在 <a target="_blank" rel="noopener" href="https://github.com/mingcv/DSRNet">https://github.com/mingcv/DSRNet</a> 上获取。<details>
<summary>Abstract</summary>
The reflection superposition phenomenon is complex and widely distributed in the real world, which derives various simplified linear and nonlinear formulations of the problem. In this paper, based on the investigation of the weaknesses of existing models, we propose a more general form of the superposition model by introducing a learnable residue term, which can effectively capture residual information during decomposition, guiding the separated layers to be complete. In order to fully capitalize on its advantages, we further design the network structure elaborately, including a novel dual-stream interaction mechanism and a powerful decomposition network with a semantic pyramid encoder. Extensive experiments and ablation studies are conducted to verify our superiority over state-of-the-art approaches on multiple real-world benchmark datasets. Our code is publicly available at https://github.com/mingcv/DSRNet.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "The reflection superposition phenomenon is complex and widely distributed in the real world, which derives various simplified linear and nonlinear formulations of the problem. In this paper, based on the investigation of the weaknesses of existing models, we propose a more general form of the superposition model by introducing a learnable residue term, which can effectively capture residual information during decomposition, guiding the separated layers to be complete. In order to fully capitalize on its advantages, we further design the network structure elaborately, including a novel dual-stream interaction mechanism and a powerful decomposition network with a semantic pyramid encoder. Extensive experiments and ablation studies are conducted to verify our superiority over state-of-the-art approaches on multiple real-world benchmark datasets. Our code is publicly available at https://github.com/mingcv/DSRNet." into Simplified Chinese.Translation:<<SYS>>现实世界中各种复杂的反射积累现象，导致了许多简化的线性和非线性形式化问题。在这篇论文中，我们基于现有模型的缺陷进行调查，并提出了更一般的积累模型，通过引入学习型剩余项，能够有效地捕捉反射信息的剩余信息，导引分解层成为完整的。为了充分利用其优势，我们还设计了网络结构，包括一种新的双流交互机制和一个强大的分解网络，具有含义层Encoder。我们进行了广泛的实验和减少研究，以证明我们在多个实际世界标准数据集上的优越性。我们的代码可以在https://github.com/mingcv/DSRNet中获得。
</details></li>
</ul>
<hr>
<h2 id="Interpretation-on-Multi-modal-Visual-Fusion"><a href="#Interpretation-on-Multi-modal-Visual-Fusion" class="headerlink" title="Interpretation on Multi-modal Visual Fusion"></a>Interpretation on Multi-modal Visual Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10019">http://arxiv.org/abs/2308.10019</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Chen, Haoran Zhou, Yongjian Deng</li>
<li>for: 本文提出了一种分析框架和一种新的评估指标，用于解释多Modal视觉社区中的解释。</li>
<li>methods: 我们的方法包括在不同modalities和层次上测量提议的semantic variance和特征相似性，并通过广泛的实验进行semantic和量化分析。</li>
<li>results: 我们的研究发现了跨modalities的特征不一致和多modal的合作规则，这些发现有助于重新评估和设计多Modal视觉融合模型。<details>
<summary>Abstract</summary>
In this paper, we present an analytical framework and a novel metric to shed light on the interpretation of the multimodal vision community. Our approach involves measuring the proposed semantic variance and feature similarity across modalities and levels, and conducting semantic and quantitative analyses through comprehensive experiments. Specifically, we investigate the consistency and speciality of representations across modalities, evolution rules within each modality, and the collaboration logic used when optimizing a multi-modality model. Our studies reveal several important findings, such as the discrepancy in cross-modal features and the hybrid multi-modal cooperation rule, which highlights consistency and speciality simultaneously for complementary inference. Through our dissection and findings on multi-modal fusion, we facilitate a rethinking of the reasonability and necessity of popular multi-modal vision fusion strategies. Furthermore, our work lays the foundation for designing a trustworthy and universal multi-modal fusion model for a variety of tasks in the future.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种分析框架和一种新的度量来探讨多模态视觉社区的解释。我们的方法是在不同的modalities和层次上测量提议的 semantics variance和特征相似性，并通过全面的实验进行semantic和量化的分析。我们专门investigates the consistency和特点of representations across modalities, evolution rules within each modality, and the collaboration logic used when optimizing a multi-modality model。我们的研究发现了一些重要的发现，如cross-modal features的差异和hybrid multi-modal cooperation rule，这些发现揭示了同时具有一致和特点的hybrid multi-modal合作。通过我们的分析和发现，我们促进了对多模态视觉混合的重新思考，并为未来多种任务的多模态混合模型设计一个可靠和通用的基础。
</details></li>
</ul>
<hr>
<h2 id="Pseudo-Flow-Consistency-for-Self-Supervised-6D-Object-Pose-Estimation"><a href="#Pseudo-Flow-Consistency-for-Self-Supervised-6D-Object-Pose-Estimation" class="headerlink" title="Pseudo Flow Consistency for Self-Supervised 6D Object Pose Estimation"></a>Pseudo Flow Consistency for Self-Supervised 6D Object Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10016">http://arxiv.org/abs/2308.10016</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yanghai-1218/pseudoflow">https://github.com/yanghai-1218/pseudoflow</a></li>
<li>paper_authors: Yang Hai, Rui Song, Jiaojiao Li, David Ferstl, Yinlin Hu</li>
<li>for: 这篇论文主要针对的是无需额外信息的自主学习6D对象pose估计问题。</li>
<li>methods: 该方法首先从使用synthetic图像生成的网络获得粗略的pose初始值，然后引入了一种基于干扰图像对数据集的geometry约束的精度调整策略。该约束由多个不同视角的synthetic-to-real图像对形成，并通过动态生成的pseudo标签来表示。</li>
<li>results: 对三个复杂的数据集进行评估，该方法与无需2D标注和额外深度图像的前一代自主学习方法相比，显著地提高了性能。<details>
<summary>Abstract</summary>
Most self-supervised 6D object pose estimation methods can only work with additional depth information or rely on the accurate annotation of 2D segmentation masks, limiting their application range. In this paper, we propose a 6D object pose estimation method that can be trained with pure RGB images without any auxiliary information. We first obtain a rough pose initialization from networks trained on synthetic images rendered from the target's 3D mesh. Then, we introduce a refinement strategy leveraging the geometry constraint in synthetic-to-real image pairs from multiple different views. We formulate this geometry constraint as pixel-level flow consistency between the training images with dynamically generated pseudo labels. We evaluate our method on three challenging datasets and demonstrate that it outperforms state-of-the-art self-supervised methods significantly, with neither 2D annotations nor additional depth images.
</details>
<details>
<summary>摘要</summary>
大多数自我指导的6D对象姿态估计方法需要额外深度信息或者精确的2D分割标签，这限制了它们的应用范围。在这篇论文中，我们提出了不需要 auxiliary信息的6D对象姿态估计方法。我们首先从目标对象的3D meshRendered的Synthetic图像中获取初步姿态 initialization。然后，我们引入了一种改善策略，利用多个不同视角的Synthetic-to-real图像对的geometry约束。我们将这种geometry约束表示为多个不同视角的Synthetic图像之间的像素水平流consistency。我们对三个具有挑战性的数据集进行评估，并证明了我们的方法在自我指导方法中具有明显的优势，无需2D标签也无需额外深度图像。
</details></li>
</ul>
<hr>
<h2 id="DyFFPAD-Dynamic-Fusion-of-Convolutional-and-Handcrafted-Features-for-Fingerprint-Presentation-Attack-Detection"><a href="#DyFFPAD-Dynamic-Fusion-of-Convolutional-and-Handcrafted-Features-for-Fingerprint-Presentation-Attack-Detection" class="headerlink" title="DyFFPAD: Dynamic Fusion of Convolutional and Handcrafted Features for Fingerprint Presentation Attack Detection"></a>DyFFPAD: Dynamic Fusion of Convolutional and Handcrafted Features for Fingerprint Presentation Attack Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10015">http://arxiv.org/abs/2308.10015</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anuj Rai, Parsheel Kumar Tiwari, Jyotishna Baishya, Ram Prakash Sharma, Somnath Dey</li>
<li>for: The paper is written for the purpose of detecting presentation attacks in automatic fingerprint recognition systems, which are a threat to their wide range of applications in areas including national borders and commercial applications.</li>
<li>methods: The paper proposes a dynamic ensemble of deep learning and handcrafted features to detect presentation attacks in known-material and unknown-material protocols. The proposed model combines both deep CNN and handcrafted features, and learns their parameters together to exhibit better performance than individual results.</li>
<li>results: The proposed model is validated using benchmark LivDet 2015, 2017, and 2019 databases, and achieves an overall accuracy of 96.10%, 96.49%, and 95.99% on them, respectively. The proposed model outperforms state-of-the-art methods in benchmark protocols of presentation attack detection in terms of classification accuracy.Here are the three key points in Simplified Chinese text:</li>
<li>for: 这篇论文是为检测自动指纹识别系统中的示现攻击而写的。</li>
<li>methods: 这篇论文提出了一种动态集成深度学习和手工特征的方法来检测示现攻击。该模型将深度学习和手工特征结合使用，并同时学习它们的参数。</li>
<li>results: 该模型在livDet2015、livDet2017和livDet2019等数据库上进行了验证，并达到了96.10%、96.49%和95.99%的总准确率。这个模型在示现攻击检测中的benchmark协议中表现出了更好的性能。<details>
<summary>Abstract</summary>
Automatic fingerprint recognition systems suffer from the threat of presentation attacks due to their wide range of applications in areas including national borders and commercial applications. Presentation attacks can be performed by fabricating the fake fingerprint of a user with or without the intention of the subject. This paper presents a dynamic ensemble of deep learning and handcrafted features to detect presentation attacks in known-material and unknown-material protocols. The proposed model is a dynamic ensemble of deep CNN and handcrafted features empowered deep neural networks both of which learn their parameters together. The proposed presentation attack detection model, in this way, utilizes the capabilities of both classification techniques and exhibits better performance than their individual results. The proposed model's performance is validated using benchmark LivDet 2015, 2017, and 2019 databases, with an overall accuracy of 96.10\%, 96.49\%, and 95.99\% attained on them, respectively. The proposed model outperforms state-of-the-art methods in benchmark protocols of presentation attack detection in terms of classification accuracy.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Partition-and-Debias-Agnostic-Biases-Mitigation-via-A-Mixture-of-Biases-Specific-Experts"><a href="#Partition-and-Debias-Agnostic-Biases-Mitigation-via-A-Mixture-of-Biases-Specific-Experts" class="headerlink" title="Partition-and-Debias: Agnostic Biases Mitigation via A Mixture of Biases-Specific Experts"></a>Partition-and-Debias: Agnostic Biases Mitigation via A Mixture of Biases-Specific Experts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10005">http://arxiv.org/abs/2308.10005</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Jiaxuan-Li/PnD">https://github.com/Jiaxuan-Li/PnD</a></li>
<li>paper_authors: Jiaxuan Li, Duc Minh Vo, Hideki Nakayama</li>
<li>for: 减少图像分类中的偏见（bias mitigation），特别是面对不确定或多种偏见的情况。</li>
<li>methods: 提出了一种名为Partition-and-Debias（PnD）方法，通过一组偏见特定的专家来分解偏见空间，并使用一个阻断模块来实现专家之间的协调，以达到减少偏见的分类。</li>
<li>results: 在公共和自定义的benchmark上进行了实验，并证明了PnD方法的有效性。<details>
<summary>Abstract</summary>
Bias mitigation in image classification has been widely researched, and existing methods have yielded notable results. However, most of these methods implicitly assume that a given image contains only one type of known or unknown bias, failing to consider the complexities of real-world biases. We introduce a more challenging scenario, agnostic biases mitigation, aiming at bias removal regardless of whether the type of bias or the number of types is unknown in the datasets. To address this difficult task, we present the Partition-and-Debias (PnD) method that uses a mixture of biases-specific experts to implicitly divide the bias space into multiple subspaces and a gating module to find a consensus among experts to achieve debiased classification. Experiments on both public and constructed benchmarks demonstrated the efficacy of the PnD. Code is available at: https://github.com/Jiaxuan-Li/PnD.
</details>
<details>
<summary>摘要</summary>
<<音� simpified>>偏调缓和图像分类中的研究已经广泛，现有的方法已经获得了 Notable results。然而，大多数这些方法预设假设一个图像只包含一种已知或未知的偏调，忽略了实际世界中的复杂偏调。我们引入一个更加问题的场景：agnostic biases mitigation， aiming at bias removal regardless of whether the type of bias or the number of types is unknown in the datasets。为了解决这个困难的任务，我们提出了 Partition-and-Debias（PnD）方法，使用一种混合偏调特有的专家来隐式地分解偏调空间 into multiple subspaces，并使用一个闸道模组来获得专家们之间的一致，以达到 debiased classification。实验结果显示，PnD方法在公共和自己建立的benchmark上具有优良的效果。代码可以在：https://github.com/Jiaxuan-Li/PnD 中找到。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Multi-View-Inverse-Rendering-Using-a-Hybrid-Differentiable-Rendering-Method"><a href="#Efficient-Multi-View-Inverse-Rendering-Using-a-Hybrid-Differentiable-Rendering-Method" class="headerlink" title="Efficient Multi-View Inverse Rendering Using a Hybrid Differentiable Rendering Method"></a>Efficient Multi-View Inverse Rendering Using a Hybrid Differentiable Rendering Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10003">http://arxiv.org/abs/2308.10003</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/HsiangYangChu/DRBIR">https://github.com/HsiangYangChu/DRBIR</a></li>
<li>paper_authors: Xiangyang Zhu, Yiling Pan, Bailin Deng, Bin Wang</li>
<li>for: 这篇论文的目的是用hybrid differentiable rendering方法 efficiently recovering real-world object的3D geometry和reflectance从多视图图像中。</li>
<li>methods: 该方法包括两个阶段：初始化阶段使用传统的SfM和MVS方法重建虚拟场景，优化阶段使用混合方法同时优化几何和反射特性，其中几何使用伪优化方法，反射使用物理基于优化方法。</li>
<li>results: 对于synthetic和实际数据，我们的方法可以生成与状态前方法相同或更高质量的重建结果，同时更高效。<details>
<summary>Abstract</summary>
Recovering the shape and appearance of real-world objects from natural 2D images is a long-standing and challenging inverse rendering problem. In this paper, we introduce a novel hybrid differentiable rendering method to efficiently reconstruct the 3D geometry and reflectance of a scene from multi-view images captured by conventional hand-held cameras. Our method follows an analysis-by-synthesis approach and consists of two phases. In the initialization phase, we use traditional SfM and MVS methods to reconstruct a virtual scene roughly matching the real scene. Then in the optimization phase, we adopt a hybrid approach to refine the geometry and reflectance, where the geometry is first optimized using an approximate differentiable rendering method, and the reflectance is optimized afterward using a physically-based differentiable rendering method. Our hybrid approach combines the efficiency of approximate methods with the high-quality results of physically-based methods. Extensive experiments on synthetic and real data demonstrate that our method can produce reconstructions with similar or higher quality than state-of-the-art methods while being more efficient.
</details>
<details>
<summary>摘要</summary>
recuperar la forma y apariencia de objetos del mundo real desde imágenes 2D naturales es un problema de inverse rendering largo standing y desafiante. En este artículo, presentamos un método de renderizado diferenciable híbrido para eficientemente reconstruir la geometría 3D y la refracción de una escena a partir de imágenes multiview capturadas por cámaras portátiles convencionales. Nuestro método sigue un enfoque de análisis por síntesis y consta de dos fases. En la fase de inicio, utilizamos métodos SfM y MVS tradicionales para reconstruir una escena virtual que approximate la escena real. Luego, en la fase de optimización, adoptamos un enfoque híbrido para refinar la geometría y la refracción, donde la geometría se optimiza primero utilizando un método de renderizado diferenciable aproximado, y la refracción se optimiza después utilizando un método de renderizado diferenciable físicamente basado. Nuestro enfoque híbrido combina la eficiencia de los métodos aproximados con los resultados de alta calidad de los métodos físicamente basados. Los experimentos extensivos en datos sintéticos y reales demuestran que nuestro método puede producir reconstrucciones con calidad similar o superior a los métodos estado del arte mientras es más eficiente.
</details></li>
</ul>
<hr>
<h2 id="AltNeRF-Learning-Robust-Neural-Radiance-Field-via-Alternating-Depth-Pose-Optimization"><a href="#AltNeRF-Learning-Robust-Neural-Radiance-Field-via-Alternating-Depth-Pose-Optimization" class="headerlink" title="AltNeRF: Learning Robust Neural Radiance Field via Alternating Depth-Pose Optimization"></a>AltNeRF: Learning Robust Neural Radiance Field via Alternating Depth-Pose Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10001">http://arxiv.org/abs/2308.10001</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kun Wang, Zhiqiang Yan, Huang Tian, Zhenyu Zhang, Xiang Li, Jun Li, Jian Yang</li>
<li>for: 实现高品质的新视角生成（Novel View Synthesis） from sparse scene images.</li>
<li>methods: 使用自我监督的单目深度测量（SMDE）自MONOCULAR VIDEOS中学习深度和pose prior，并与NeRF进行交互式调整。</li>
<li>results: 产生高传真度和可靠的新视角，并且能够处理不确定的摄像机位置和缺乏明确的3D超级vision。<details>
<summary>Abstract</summary>
Neural Radiance Fields (NeRF) have shown promise in generating realistic novel views from sparse scene images. However, existing NeRF approaches often encounter challenges due to the lack of explicit 3D supervision and imprecise camera poses, resulting in suboptimal outcomes. To tackle these issues, we propose AltNeRF -- a novel framework designed to create resilient NeRF representations using self-supervised monocular depth estimation (SMDE) from monocular videos, without relying on known camera poses. SMDE in AltNeRF masterfully learns depth and pose priors to regulate NeRF training. The depth prior enriches NeRF's capacity for precise scene geometry depiction, while the pose prior provides a robust starting point for subsequent pose refinement. Moreover, we introduce an alternating algorithm that harmoniously melds NeRF outputs into SMDE through a consistence-driven mechanism, thus enhancing the integrity of depth priors. This alternation empowers AltNeRF to progressively refine NeRF representations, yielding the synthesis of realistic novel views. Additionally, we curate a distinctive dataset comprising indoor videos captured via mobile devices. Extensive experiments showcase the compelling capabilities of AltNeRF in generating high-fidelity and robust novel views that closely resemble reality.
</details>
<details>
<summary>摘要</summary>
neural radiance fields (NeRF) 已经示示出在使用稀疏场景图像生成真实的新视图时的承诺。然而，现有的 NeRF 方法经常遇到缺乏显式的3D监督和不准确的相机位置问题，导致优化结果不佳。为解决这些问题，我们提出了 AltNeRF -- 一种新的框架，通过使用单目视频中的自我监督深度估计 (SMDE)，不需要知道相机位置，创建了鲜明的 NeRF 表示。SMDE 在 AltNeRF 中熟练地学习了深度和pose prior，以规则 NeRF 训练。深度先导提高了 NeRF 的场景几何描述能力，而pose先导提供了 robust的开始点，用于后续的pose修正。此外，我们还引入了一种相互律动的算法，将 NeRF 输出与 SMDE 融合在一起，通过一种具有一致性的机制，以强化深度先导的完整性。这种相互律动使得 AltNeRF 能够不断地加工 NeRF 表示，Synthesize 出真实的新视图。此外，我们还制作了一个特有的indoor视频 captured via mobile devices的数据集。广泛的实验表明，AltNeRF 能够生成高质量和Robust的新视图，与实际相似。
</details></li>
</ul>
<hr>
<h2 id="TTPOINT-A-Tensorized-Point-Cloud-Network-for-Lightweight-Action-Recognition-with-Event-Cameras"><a href="#TTPOINT-A-Tensorized-Point-Cloud-Network-for-Lightweight-Action-Recognition-with-Event-Cameras" class="headerlink" title="TTPOINT: A Tensorized Point Cloud Network for Lightweight Action Recognition with Event Cameras"></a>TTPOINT: A Tensorized Point Cloud Network for Lightweight Action Recognition with Event Cameras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09993">http://arxiv.org/abs/2308.09993</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongwei Ren, Yue Zhou, Haotian Fu, Yulong Huang, Renjing Xu, Bojun Cheng</li>
<li>for: 本研究旨在提出一种轻量级、通用的点云网络（TTPOINT），用于行动识别任务。</li>
<li>methods: 该模型采用点云方式进行数据采集，并使用tensor-train压缩特征提取器来减少计算复杂度和参数量。</li>
<li>results: TTPOINT在三个 dataset 上达到了状态平台（SOTA）水平，并在所有五个 dataset 上达到了点云方法的SOTA水平。此外，通过使用tensor-train压缩方法，模型的精度几乎不受参数大小压缩的影响。<details>
<summary>Abstract</summary>
Event cameras have gained popularity in computer vision due to their data sparsity, high dynamic range, and low latency. As a bio-inspired sensor, event cameras generate sparse and asynchronous data, which is inherently incompatible with the traditional frame-based method. Alternatively, the point-based method can avoid additional modality transformation and naturally adapt to the sparsity of events. Still, it typically cannot reach a comparable accuracy as the frame-based method. We propose a lightweight and generalized point cloud network called TTPOINT which achieves competitive results even compared to the state-of-the-art (SOTA) frame-based method in action recognition tasks while only using 1.5 % of the computational resources. The model is adept at abstracting local and global geometry by hierarchy structure. By leveraging tensor-train compressed feature extractors, TTPOINT can be designed with minimal parameters and computational complexity. Additionally, we developed a straightforward downsampling algorithm to maintain the spatio-temporal feature. In the experiment, TTPOINT emerged as the SOTA method on three datasets while also attaining SOTA among point cloud methods on all five datasets. Moreover, by using the tensor-train decomposition method, the accuracy of the proposed TTPOINT is almost unaffected while compressing the parameter size by 55 % in all five datasets.
</details>
<details>
<summary>摘要</summary>
事件摄像机在计算机视觉中得到了普遍应用，因为它们的数据稀疏、高动态范围和低延迟时间。作为生物体发现的感知器，事件摄像机生成的数据是不兼容传统框架方法的异常快照式数据。相反，点云方法可以避免额外模态变换，并自然适应事件的稀疏性。然而，它通常无法达到与框架方法相当的准确性。我们提出了一种轻量级、通用的点云网络 called TTPOINT，它在动作识别任务中达到了与状态前方法相当的结果，只使用了1.5%的计算资源。该模型能够层次结构中抽象本地和全局几何。通过利用张量约束压缩特征提取器，TTPOINT可以设计为最小参数和计算复杂度。此外，我们开发了一种简单的下采样算法，以保持空间时间特征。在实验中，TTPOINT被认为状态前方法在三个数据集上，同时在五个数据集上也成为点云方法的最佳方法。此外，通过使用张量约束压缩方法，提议的TTPOINT的准确率几乎不受参数大小压缩55%的影响。
</details></li>
</ul>
<hr>
<h2 id="AltDiffusion-A-Multilingual-Text-to-Image-Diffusion-Model"><a href="#AltDiffusion-A-Multilingual-Text-to-Image-Diffusion-Model" class="headerlink" title="AltDiffusion: A Multilingual Text-to-Image Diffusion Model"></a>AltDiffusion: A Multilingual Text-to-Image Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09991">http://arxiv.org/abs/2308.09991</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/superhero-7/altdiffuson">https://github.com/superhero-7/altdiffuson</a></li>
<li>paper_authors: Fulong Ye, Guang Liu, Xinya Wu, Ledell Wu<br>for: 这个论文是为了推广大语言环境下的文本到图像（T2I）扩散模型，以便为不同语言用户提供更好的服务。methods: 这篇论文使用了知识传播学习（KD）来训练一个多语言文本编码器，然后把其插入到一个预训练的英文只 diffusion 模型中，通过两个阶段的Schema来提高多语言能力。results: 这篇论文在一个大规模多语言 dataset 上进行了两个阶段的Schema，包括概念对接和质量改进阶段，并在多语言总体评价和文化特有概念评价中表现出色，超过了现有的状态之艺 T2I 模型。<details>
<summary>Abstract</summary>
Large Text-to-Image(T2I) diffusion models have shown a remarkable capability to produce photorealistic and diverse images based on text inputs. However, existing works only support limited language input, e.g., English, Chinese, and Japanese, leaving users beyond these languages underserved and blocking the global expansion of T2I models. Therefore, this paper presents AltDiffusion, a novel multilingual T2I diffusion model that supports eighteen different languages. Specifically, we first train a multilingual text encoder based on the knowledge distillation. Then we plug it into a pretrained English-only diffusion model and train the model with a two-stage schema to enhance the multilingual capability, including concept alignment and quality improvement stage on a large-scale multilingual dataset. Furthermore, we introduce a new benchmark, which includes Multilingual-General-18(MG-18) and Multilingual-Cultural-18(MC-18) datasets, to evaluate the capabilities of T2I diffusion models for generating high-quality images and capturing culture-specific concepts in different languages. Experimental results on both MG-18 and MC-18 demonstrate that AltDiffusion outperforms current state-of-the-art T2I models, e.g., Stable Diffusion in multilingual understanding, especially with respect to culture-specific concepts, while still having comparable capability for generating high-quality images. All source code and checkpoints could be found in https://github.com/superhero-7/AltDiffuson.
</details>
<details>
<summary>摘要</summary>
大型文本到图像（T2I）扩散模型已经显示出产生高质量和多样化的图像的remarkable能力，但现有的工作只支持有限的语言输入，例如英语、中文和日语，这使得用户使用其他语言被忽略和限制了全球的扩展。因此，本文提出了AltDiffusion，一种新的多语言T2I扩散模型，支持 eighteen种不同的语言。 Specifically，我们首先训练了一个多语言文本编码器，基于知识传承。然后，我们插入到一个预训练的英语只 diffusion model 中，并在一个两个阶段的Schema中进行增强多语言能力，包括概念对齐和质量提升阶段。此外，我们 introduce a new benchmark，包括 Multilingual-General-18（MG-18）和 Multilingual-Cultural-18（MC-18）数据集，以评估 T2I 扩散模型在生成高质量图像和捕捉不同语言文化特性方面的能力。实验结果表明，AltDiffusion 在 MG-18 和 MC-18 上表现出优于当前状态的扩散模型，特别是在文化特性方面，而且仍然与生成高质量图像有相同的能力。所有源代码和检查点可以在 <https://github.com/superhero-7/AltDiffuson> 找到。
</details></li>
</ul>
<hr>
<h2 id="TSAR-MVS-Textureless-aware-Segmentation-and-Correlative-Refinement-Guided-Multi-View-Stereo"><a href="#TSAR-MVS-Textureless-aware-Segmentation-and-Correlative-Refinement-Guided-Multi-View-Stereo" class="headerlink" title="TSAR-MVS: Textureless-aware Segmentation and Correlative Refinement Guided Multi-View Stereo"></a>TSAR-MVS: Textureless-aware Segmentation and Correlative Refinement Guided Multi-View Stereo</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09990">http://arxiv.org/abs/2308.09990</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenlong Yuan, Jiakai Cao, Hao Jiang, Zhaoqi Wang, Zhaoxin Li</li>
<li>for: 增强多视图ステレオ（MVS）中缺失文本区域的重建问题的解决方案。</li>
<li>methods: 提议的方法包括：一、 joint hypothesis filtering，二、iterative correlation refinement，三、 textureless-aware segmentation。</li>
<li>results: 实验结果表明，提议的方法在大量数据集上表现出色，与大多数非学习方法比较，具有较高的精度和稳定性，同时能够保留细节。<details>
<summary>Abstract</summary>
The reconstruction of textureless areas has long been a challenging problem in MVS due to lack of reliable pixel correspondences between images. In this paper, we propose the Textureless-aware Segmentation And Correlative Refinement guided Multi-View Stereo (TSAR-MVS), a novel method that effectively tackles challenges posed by textureless areas in 3D reconstruction through filtering, refinement and segmentation. First, we implement joint hypothesis filtering, a technique that merges a confidence estimator with a disparity discontinuity detector to eliminate incorrect depth estimations. Second, to spread the pixels with confident depth, we introduce a iterative correlation refinement strategy that leverages RANSAC to generate superpixels, succeeded by a median filter for broadening the influence of accurately determined pixels.Finally, we present a textureless-aware segmentation method that leverages edge detection and line detection for accurately identify large textureless regions to be fitted using 3D planes. Experiments on extensive datasets demonstrate that our method significantly outperforms most non-learning methods and exhibits robustness to textureless areas while preserving fine details.
</details>
<details>
<summary>摘要</summary>
文本无纹区域重建问题在多视图深度（MVS）中一直是一个挑战，因为缺乏可靠的像素对应关系。在这篇论文中，我们提出了Textureless-aware Segmentation And Correlative Refinement guided Multi-View Stereo（TSAR-MVS），一种新的方法，可以有效地解决由缺纹区域引起的3D重建问题。首先，我们实现了联合假设筛选，这是一种将信度估计器与分辨率缺乏检测器结合在一起，以消除错误的深度估计。其次，为了将具有信任度的像素扩展到更多的像素，我们引入了一种迭代相关级联策略，该策略利用RANSAC生成超像素，然后使用中值滤波器来扩大正确确定的像素的影响。最后，我们提出了一种具有纹理性的分割方法，该方法利用边检测和直线检测来准确地识别大面积的缺纹区域，并将其适用3D平面来适应。我们对广泛的数据集进行了实验，结果显示，我们的方法在非学习方法中显著超越，并且具有对缺纹区域的鲁棒性，同时保留细节。
</details></li>
</ul>
<hr>
<h2 id="Prototypical-Cross-domain-Knowledge-Transfer-for-Cervical-Dysplasia-Visual-Inspection"><a href="#Prototypical-Cross-domain-Knowledge-Transfer-for-Cervical-Dysplasia-Visual-Inspection" class="headerlink" title="Prototypical Cross-domain Knowledge Transfer for Cervical Dysplasia Visual Inspection"></a>Prototypical Cross-domain Knowledge Transfer for Cervical Dysplasia Visual Inspection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09983">http://arxiv.org/abs/2308.09983</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yichen Zhang, Yifang Yin, Ying Zhang, Zhenguang Liu, Zheng Wang, Roger Zimmermann<br>for: 这个研究的目的是提高自动诊断阴道异常的准确率，以便在低资源设置下提供更好的阴道癌诊断。methods: 我们提出了一种使用跨领域阴道照片进行学习，以增强模型的性能。我们还提出了一种具有转移性的知识范例选择方法，以便对目标阴道照片集进行训练。results: 我们的方法在三个真实世界 benchmark 阴道照片集上进行了实验，结果显示我们的方法在阴道异常诊断中的顶尖一致率、精度、准确率和ROC-AUC上有4.7%、7.0%、1.4%和4.6%的提升，优于现有的阴道异常诊断方法。<details>
<summary>Abstract</summary>
Early detection of dysplasia of the cervix is critical for cervical cancer treatment. However, automatic cervical dysplasia diagnosis via visual inspection, which is more appropriate in low-resource settings, remains a challenging problem. Though promising results have been obtained by recent deep learning models, their performance is significantly hindered by the limited scale of the available cervix datasets. Distinct from previous methods that learn from a single dataset, we propose to leverage cross-domain cervical images that were collected in different but related clinical studies to improve the model's performance on the targeted cervix dataset. To robustly learn the transferable information across datasets, we propose a novel prototype-based knowledge filtering method to estimate the transferability of cross-domain samples. We further optimize the shared feature space by aligning the cross-domain image representations simultaneously on domain level with early alignment and class level with supervised contrastive learning, which endows model training and knowledge transfer with stronger robustness. The empirical results on three real-world benchmark cervical image datasets show that our proposed method outperforms the state-of-the-art cervical dysplasia visual inspection by an absolute improvement of 4.7% in top-1 accuracy, 7.0% in precision, 1.4% in recall, 4.6% in F1 score, and 0.05 in ROC-AUC.
</details>
<details>
<summary>摘要</summary>
早期检测颈部癌变是肺癌治疗的关键，但自动诊断颈部癌变via视觉检查，更适合在低资源环境中进行，仍然是一个挑战。虽然最近的深度学习模型已经获得了有前途的结果，但它们的性能受到有限的颈部数据集的限制。与前方方法不同，我们提议利用跨频道颈部图像，从不同但相关的临床研究中收集的图像来提高模型的性能。为了强制学习跨频道图像中的共同信息，我们提出了一种新的原型基于知识筛选方法，以估算跨频道样本的传输性。此外，我们还使用了同时对域级和类别级进行对齐，以提高共享特征空间的定制。通过这种方法，我们可以强制训练模型并传输知识，使其在目标颈部数据集上表现更加稳定。实验结果表明，我们的提议方法在三个实际预测颈部癌变的数据集上表现出色，与状态之前的诊断性能相比，提高了4.7%的排名前一精度、7.0%的精度、1.4%的准确率、4.6%的F1分数和0.05的ROC-AUC。
</details></li>
</ul>
<hr>
<h2 id="Breast-Lesion-Diagnosis-Using-Static-Images-and-Dynamic-Video"><a href="#Breast-Lesion-Diagnosis-Using-Static-Images-and-Dynamic-Video" class="headerlink" title="Breast Lesion Diagnosis Using Static Images and Dynamic Video"></a>Breast Lesion Diagnosis Using Static Images and Dynamic Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09980">http://arxiv.org/abs/2308.09980</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunwen Huang, Hongyu Hu, Ying Zhu, Yi Xu<br>for: 这个研究旨在开发一个基于深度学习的电脑助诊系统，以帮助诊断乳腺癌。methods: 这个系统使用多 modal 的乳腺ultrasound影像和动态影像，并将它们融合为一个多Modal Feature。在这个过程中，我们将使用专家选择的静止影像来导航动态影像的特征聚合。results: 我们在一个包含897个乳腺ultrasound影像和动态影像的 dataset上进行验证，结果显示我们的模型可以提高了诊断的精度，其AUC值为90.0%，并且精度为81.7%。<details>
<summary>Abstract</summary>
Deep learning based Computer Aided Diagnosis (CAD) systems have been developed to treat breast ultrasound. Most of them focus on a single ultrasound imaging modality, either using representative static images or the dynamic video of a real-time scan. In fact, these two image modalities are complementary for lesion diagnosis. Dynamic videos provide detailed three-dimensional information about the lesion, while static images capture the typical sections of the lesion. In this work, we propose a multi-modality breast tumor diagnosis model to imitate the diagnosing process of radiologists, which learns the features of both static images and dynamic video and explores the potential relationship between the two modalities. Considering that static images are carefully selected by professional radiologists, we propose to aggregate dynamic video features under the guidance of domain knowledge from static images before fusing multi-modality features. Our work is validated on a breast ultrasound dataset composed of 897 sets of ultrasound images and videos. Experimental results show that our model boosts the performance of Benign/Malignant classification, achieving 90.0% in AUC and 81.7% in accuracy.
</details>
<details>
<summary>摘要</summary>
深度学习基于计算机辅助诊断（CAD）系统已经开发以治疗乳腺癌。大多数其中都专注于单一的乳腺ultrasound图像模式，可以是使用代表性的静止图像或实时扫描的动态视频。事实上，这两种图像模式是诊断癌变的补充。动态视频提供癌变三维信息的详细信息，而静止图像捕捉癌变典型部分。在这种工作中，我们提议一种多Modal breast tumor诊断模型，以模拟医生的诊断过程，学习静止图像和动态视频中的特征，并探索这两种模式之间的潜在关系。考虑到静止图像由专业医生 manually selects，我们提议将动态视频特征与静止图像特征相互融合，然后将多模式特征进行融合。我们的工作被验证在897组乳腺ultrasound图像和视频组成的 dataset上。实验结果表明，我们的模型可以提高了抑准/癌变分类的性能，达到了90.0%的AUC和81.7%的准确率。
</details></li>
</ul>
<hr>
<h2 id="Whether-you-can-locate-or-not-Interactive-Referring-Expression-Generation"><a href="#Whether-you-can-locate-or-not-Interactive-Referring-Expression-Generation" class="headerlink" title="Whether you can locate or not? Interactive Referring Expression Generation"></a>Whether you can locate or not? Interactive Referring Expression Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09977">http://arxiv.org/abs/2308.09977</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/superhero-7/ireg">https://github.com/superhero-7/ireg</a></li>
<li>paper_authors: Fulong Ye, Yuxing Long, Fangxiang Feng, Xiaojie Wang</li>
<li>for: 本研究旨在生成不ambiguous的 Referring Expressions (REs)，并实现 Referring Expression Comprehension (REC) 任务。</li>
<li>methods: 我们提出了一种Interactive REG (IREG) 模型，可以与真实的 REC 模型交互，利用显示对象所在视觉区域和对象是否已经找到的信号来慢慢修改 REs。</li>
<li>results: 我们在 RefCOCO、RefCOCO+ 和 RefCOCOg 三个 RE  benchmark 数据集上进行了实验，结果显示，IREG 可以比前一代方法在各种评价指标上取得更高的性能。此外，人工评价也表明，IREG 能够更好地生成 REs 并具有交互能力。<details>
<summary>Abstract</summary>
Referring Expression Generation (REG) aims to generate unambiguous Referring Expressions (REs) for objects in a visual scene, with a dual task of Referring Expression Comprehension (REC) to locate the referred object. Existing methods construct REG models independently by using only the REs as ground truth for model training, without considering the potential interaction between REG and REC models. In this paper, we propose an Interactive REG (IREG) model that can interact with a real REC model, utilizing signals indicating whether the object is located and the visual region located by the REC model to gradually modify REs. Our experimental results on three RE benchmark datasets, RefCOCO, RefCOCO+, and RefCOCOg show that IREG outperforms previous state-of-the-art methods on popular evaluation metrics. Furthermore, a human evaluation shows that IREG generates better REs with the capability of interaction.
</details>
<details>
<summary>摘要</summary>
《referring表达生成（REG）》的目标是生成清晰无ambiguity的引用表达（RE），同时通过引用表达理解（REC）来确定引用的对象所在位置。现有方法通常是独立构建REG模型，只使用RE作为模型训练的真实值，而不考虑REG和REC模型之间的可能的互动。在这篇论文中，我们提出了一种互动式REG（IREG）模型，可以与真实的REC模型进行互动，通过视觉区域和对象所在位置的信号来慢慢修改RE。我们的实验结果表明，IREG在三个REFCOCO数据集上表现出色，与前一代方法相比，在流行的评价指标上表现出色。此外，人工评价也表明，IREG能够更好地生成引用表达，并具有互动的能力。
</details></li>
</ul>
<hr>
<h2 id="DESOBAv2-Towards-Large-scale-Real-world-Dataset-for-Shadow-Generation"><a href="#DESOBAv2-Towards-Large-scale-Real-world-Dataset-for-Shadow-Generation" class="headerlink" title="DESOBAv2: Towards Large-scale Real-world Dataset for Shadow Generation"></a>DESOBAv2: Towards Large-scale Real-world Dataset for Shadow Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09972">http://arxiv.org/abs/2308.09972</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingyang Liu, Jianting Wang, Li Niu</li>
<li>for: 本研究旨在生成真实的阴影，以使composite image更加真实。</li>
<li>methods: 使用object-shadow detection和inpainting技术生成阴影，并使用pretrained填充模型进行填充。</li>
<li>results: 创建了一个大规模的DESOBAv2 dataset，可以用于评估阴影生成器的性能。<details>
<summary>Abstract</summary>
Image composition refers to inserting a foreground object into a background image to obtain a composite image. In this work, we focus on generating plausible shadow for the inserted foreground object to make the composite image more realistic. To supplement the existing small-scale dataset DESOBA, we create a large-scale dataset called DESOBAv2 by using object-shadow detection and inpainting techniques. Specifically, we collect a large number of outdoor scene images with object-shadow pairs. Then, we use pretrained inpainting model to inpaint the shadow region, resulting in the deshadowed images. Based on real images and deshadowed images, we can construct pairs of synthetic composite images and ground-truth target images. Dataset is available at https://github.com/bcmi/Object-Shadow-Generation-Dataset-DESOBAv2.
</details>
<details>
<summary>摘要</summary>
Image composition指的是将前景对象 inserts 到背景图像中获得复合图像。在这种工作中，我们关注于生成合理的阴影，以使复合图像更加真实。为了补充现有的小规模数据集DESOBA，我们创建了一个大规模数据集DESOBAv2，使用对象阴影检测和填充技术。具体来说，我们收集了大量的室外场景图像和对象阴影对。然后，我们使用预训练的填充模型填充阴影区域，得到了抹掉阴影的图像。基于真实图像和抹掉阴影图像，我们可以构建对应的 sintetic 复合图像和实际目标图像的对。数据集可以在https://github.com/bcmi/Object-Shadow-Generation-Dataset-DESOBAv2上下载。
</details></li>
</ul>
<hr>
<h2 id="NeutrEx-A-3D-Quality-Component-Measure-on-Facial-Expression-Neutrality"><a href="#NeutrEx-A-3D-Quality-Component-Measure-on-Facial-Expression-Neutrality" class="headerlink" title="NeutrEx: A 3D Quality Component Measure on Facial Expression Neutrality"></a>NeutrEx: A 3D Quality Component Measure on Facial Expression Neutrality</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09963">http://arxiv.org/abs/2308.09963</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marcel Grimmer, Christian Rathgeb, Raymond Veldhuis, Christoph Busch</li>
<li>for: 这个论文的目的是提出一个基于3D人脸重建的表达质量评估方法，以便确保低质量的人脸图像不会影响辨识率。</li>
<li>methods: 这个方法使用了一个基于支持向量机器的expression辨识方法，并使用了一个预训练的对应神经网络来提取面孔嵌入。</li>
<li>results: 该方法比基于面孔嵌入的基eline方法表现出色，并且可以提供可解释的评估结果，包括每个颅骨的距离值，以帮助操作员给予有用的反馈。<details>
<summary>Abstract</summary>
Accurate face recognition systems are increasingly important in sensitive applications like border control or migration management. Therefore, it becomes crucial to quantify the quality of facial images to ensure that low-quality images are not affecting recognition accuracy. In this context, the current draft of ISO/IEC 29794-5 introduces the concept of component quality to estimate how single factors of variation affect recognition outcomes. In this study, we propose a quality measure (NeutrEx) based on the accumulated distances of a 3D face reconstruction to a neutral expression anchor. Our evaluations demonstrate the superiority of our proposed method compared to baseline approaches obtained by training Support Vector Machines on face embeddings extracted from a pre-trained Convolutional Neural Network for facial expression classification. Furthermore, we highlight the explainable nature of our NeutrEx measures by computing per-vertex distances to unveil the most impactful face regions and allow operators to give actionable feedback to subjects.
</details>
<details>
<summary>摘要</summary>
正确的面部识别系统在敏感应用中如国境控制或移民管理中日益重要。因此，它成为了评估面部图像质量的关键。在这个上下文中，ISO/IEC 29794-5 的现行稿引入了面部成分质量的概念，以估计单一因素的变化对于识别结果的影响。在这个研究中，我们提出了基于三维面部重建的累累距离对于中性表情参照点的质量指标（NeutrEx）。我们的评估结果显示，我们的提案方法比基于预训条件支持向量机器学习的面部嵌入式表情分类模型来得到更高的表现。此外，我们还高亮了我们的NeutrEx指标的可解释性，通过计算每个颅骨距离以揭露面部最重要的影响区域，并允许操作者给予适当的反馈给主体。
</details></li>
</ul>
<hr>
<h2 id="UniAP-Towards-Universal-Animal-Perception-in-Vision-via-Few-shot-Learning"><a href="#UniAP-Towards-Universal-Animal-Perception-in-Vision-via-Few-shot-Learning" class="headerlink" title="UniAP: Towards Universal Animal Perception in Vision via Few-shot Learning"></a>UniAP: Towards Universal Animal Perception in Vision via Few-shot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09953">http://arxiv.org/abs/2308.09953</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rese1f/UniAP">https://github.com/rese1f/UniAP</a></li>
<li>paper_authors: Meiqi Sun, Zhonghan Zhao, Wenhao Chai, Hanjun Luo, Shidong Cao, Yanting Zhang, Jenq-Neng Hwang, Gaoang Wang</li>
<li>for: 用于自动监测动物健康、理解动物行为和助助动物研究。</li>
<li>methods: 使用几拟学习来实现跨种动物视觉识别模型，通过共享视觉特征来传递知识。</li>
<li>results: 实现了跨种动物视觉任务的泛化和适应，可以快速适应新种类和有限数量的标注数据。<details>
<summary>Abstract</summary>
Animal visual perception is an important technique for automatically monitoring animal health, understanding animal behaviors, and assisting animal-related research. However, it is challenging to design a deep learning-based perception model that can freely adapt to different animals across various perception tasks, due to the varying poses of a large diversity of animals, lacking data on rare species, and the semantic inconsistency of different tasks. We introduce UniAP, a novel Universal Animal Perception model that leverages few-shot learning to enable cross-species perception among various visual tasks. Our proposed model takes support images and labels as prompt guidance for a query image. Images and labels are processed through a Transformer-based encoder and a lightweight label encoder, respectively. Then a matching module is designed for aggregating information between prompt guidance and the query image, followed by a multi-head label decoder to generate outputs for various tasks. By capitalizing on the shared visual characteristics among different animals and tasks, UniAP enables the transfer of knowledge from well-studied species to those with limited labeled data or even unseen species. We demonstrate the effectiveness of UniAP through comprehensive experiments in pose estimation, segmentation, and classification tasks on diverse animal species, showcasing its ability to generalize and adapt to new classes with minimal labeled examples.
</details>
<details>
<summary>摘要</summary>
生物视觉技术是重要的自动监测动物健康、理解动物行为和帮助动物研究的方法。然而，设计一个基于深度学习的视觉感知模型，能够自由地适应不同的动物和多种视觉任务，是一项挑战。这是因为动物的姿势变化多样、罕见的种类缺乏数据，以及不同任务的semantic不一致。我们介绍UniAP，一种新的通用动物感知模型，利用几何学学习来实现跨种pecie的视觉感知。我们提posed模型通过在支持图像和标签作为引导图像的query图像。图像和标签通过Transformer基于encoder和轻量级标签encoder处理。然后，我们设计了一个匹配模块，用于聚合引导图像和查询图像之间的信息，并由一个多头标签解码器生成多种任务的输出。通过利用不同动物和任务之间的共同视觉特征，UniAP允许知识从已经学习的种类传递到有限数据或者even未经见过的种类。我们通过对多种动物种类的pose估计、分割和分类任务进行了广泛的实验，证明UniAP的有效性，并显示其能够通过少量标签示例进行泛化和适应新类。
</details></li>
</ul>
<hr>
<h2 id="Semantics-Meets-Temporal-Correspondence-Self-supervised-Object-centric-Learning-in-Videos"><a href="#Semantics-Meets-Temporal-Correspondence-Self-supervised-Object-centric-Learning-in-Videos" class="headerlink" title="Semantics Meets Temporal Correspondence: Self-supervised Object-centric Learning in Videos"></a>Semantics Meets Temporal Correspondence: Self-supervised Object-centric Learning in Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09951">http://arxiv.org/abs/2308.09951</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui Qian, Shuangrui Ding, Xian Liu, Dahua Lin</li>
<li>for: 本 paper 旨在强化对象中心表示，提高视频对象发现和分类性能。</li>
<li>methods: 该 paper 使用了自助学习方法，包括 query slot attention 和 random sampling based slot attention，以提取高级 semantics 和低级时间匹配信息。另外，它还提出了一种新的masked slot attention方法，以强化对象中心表示。</li>
<li>results: 该 paper 的实验结果表明，使用自助学习方法和masked slot attention可以提高视频对象发现和分类性能，并且可以实现对象中心表示。此外，它还达到了 dense label propagation 任务的最佳性能，demonstrating the potential for object-centric analysis。<details>
<summary>Abstract</summary>
Self-supervised methods have shown remarkable progress in learning high-level semantics and low-level temporal correspondence. Building on these results, we take one step further and explore the possibility of integrating these two features to enhance object-centric representations. Our preliminary experiments indicate that query slot attention can extract different semantic components from the RGB feature map, while random sampling based slot attention can exploit temporal correspondence cues between frames to assist instance identification. Motivated by this, we propose a novel semantic-aware masked slot attention on top of the fused semantic features and correspondence maps. It comprises two slot attention stages with a set of shared learnable Gaussian distributions. In the first stage, we use the mean vectors as slot initialization to decompose potential semantics and generate semantic segmentation masks through iterative attention. In the second stage, for each semantics, we randomly sample slots from the corresponding Gaussian distribution and perform masked feature aggregation within the semantic area to exploit temporal correspondence patterns for instance identification. We adopt semantic- and instance-level temporal consistency as self-supervision to encourage temporally coherent object-centric representations. Our model effectively identifies multiple object instances with semantic structure, reaching promising results on unsupervised video object discovery. Furthermore, we achieve state-of-the-art performance on dense label propagation tasks, demonstrating the potential for object-centric analysis. The code is released at https://github.com/shvdiwnkozbw/SMTC.
</details>
<details>
<summary>摘要</summary>
自我监督方法已经在学习高级 semantics 和低级时间匹配方面进行了非常出色的进步。基于这些结果，我们尝试一步更远，探索将这两个特征集成到对象中心表示中以提高对象识别的可能性。我们的初步实验表明，Query slot attention可以从 RGB 特征地图中提取不同的semantic 分量，而Random sampling based slot attention可以在帧中使用时间匹配规律来帮助实例识别。这些灵感下，我们提议一种新的semantic-aware masked slot attention，它包括两个槽注意阶段，每个阶段都有一组共享学习的Gaussian 分布。在第一个阶段，我们使用极值向量作为槽初始化，以iterative attention decomposition potential semantics并生成semantic segmentation mask。在第二个阶段，对每个semantics，我们随机从相应的Gaussian分布中选择槽，并在semantic区域内进行masked feature aggregation，以利用时间匹配模式来提高实例识别。我们采用semantic-和instance-level时间一致性自我监督，以鼓励对象中心表示的时间一致性。我们的模型能够有效地识别多个对象实例，同时保持semantic结构，在无监督视频对象发现任务中达到了可观的结果。此外，我们在 dense label propagation 任务中实现了state-of-the-art 性能，表明对象中心分析的潜力。代码可以在 <https://github.com/shvdiwnkozbw/SMTC> 上下载。
</details></li>
</ul>
<hr>
<h2 id="Scene-Aware-Feature-Matching"><a href="#Scene-Aware-Feature-Matching" class="headerlink" title="Scene-Aware Feature Matching"></a>Scene-Aware Feature Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09949">http://arxiv.org/abs/2308.09949</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/USTCPCS/CVPR2018_attention">https://github.com/USTCPCS/CVPR2018_attention</a></li>
<li>paper_authors: Xiaoyong Lu, Yaping Yan, Tong Wei, Songlin Du</li>
<li>for: The paper is written for improving the performance of feature matching in computer vision tasks, particularly in handling challenging scenes with large viewpoint and illumination changes.</li>
<li>methods: The paper proposes a novel model named SAM, which applies attentional grouping to guide Scene-Aware feature Matching. The model uses attention layers to handle multi-level features, including image tokens and group tokens, and groups the image tokens with the proposed token grouping module.</li>
<li>results: The paper achieves state-of-the-art performance on various applications, including homography estimation, pose estimation, and image matching, and demonstrates that the proposed model is more accurate, robust, and interpretable than conventional feature matching models.<details>
<summary>Abstract</summary>
Current feature matching methods focus on point-level matching, pursuing better representation learning of individual features, but lacking further understanding of the scene. This results in significant performance degradation when handling challenging scenes such as scenes with large viewpoint and illumination changes. To tackle this problem, we propose a novel model named SAM, which applies attentional grouping to guide Scene-Aware feature Matching. SAM handles multi-level features, i.e., image tokens and group tokens, with attention layers, and groups the image tokens with the proposed token grouping module. Our model can be trained by ground-truth matches only and produce reasonable grouping results. With the sense-aware grouping guidance, SAM is not only more accurate and robust but also more interpretable than conventional feature matching models. Sufficient experiments on various applications, including homography estimation, pose estimation, and image matching, demonstrate that our model achieves state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
当前的特征匹配方法主要关注点级匹配，尝试更好地学习个体特征的表示学习，但缺乏更深入的场景理解。这会导致对复杂场景（如大视角和照明变化）的处理而受到显著性能下降。为解决这个问题，我们提出了一种新的模型，即SAM，它通过注意力组合来引导场景意识的特征匹配。SAM处理多级特征，即图像token和组token，使用注意力层，并通过我们提议的token grouping模块将图像token分组。我们的模型可以通过真实匹配只需要训练，并且生成合理的分组结果。与传统的特征匹配模型相比，SAM不仅更准确和Robust，还更易于解释。我们在多种应用，包括Homography估计、pose估计和图像匹配等，进行了详细的实验，结果显示我们的模型在状态艺术性能。
</details></li>
</ul>
<hr>
<h2 id="Weakly-Supervised-Action-Localization-by-Hierarchically-structured-Latent-Attention-Modeling"><a href="#Weakly-Supervised-Action-Localization-by-Hierarchically-structured-Latent-Attention-Modeling" class="headerlink" title="Weakly-Supervised Action Localization by Hierarchically-structured Latent Attention Modeling"></a>Weakly-Supervised Action Localization by Hierarchically-structured Latent Attention Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09946">http://arxiv.org/abs/2308.09946</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guiqin Wang, Peng Zhao, Cong Zhao, Shusen Yang, Jie Cheng, Luziwei Leng, Jianxing Liao, Qinghai Guo</li>
<li>for: 这个论文主要针对的是强度不足的动作地理学问题，即在没有时间标注的视频中识别和地理化动作实例。</li>
<li>methods: 我们提出了一种新的注意力基于层次结构的隐藏模型，用于学习视频特征的时间变化 semantics。该模型包括两个组件：第一个是一个不supervised的变化点检测模块，通过学习视频特征的时间层次结构来检测变化点；第二个是一个注意力基于分类模型，用于选择变化点的背景。</li>
<li>results: 我们在THUMOS-14和ActivityNet-v1.3两个 benchmark dataset上进行了广泛的实验，结果显示，我们的方法可以比现有的方法表现更好，甚至与完全监督的方法相当。<details>
<summary>Abstract</summary>
Weakly-supervised action localization aims to recognize and localize action instancese in untrimmed videos with only video-level labels. Most existing models rely on multiple instance learning(MIL), where the predictions of unlabeled instances are supervised by classifying labeled bags. The MIL-based methods are relatively well studied with cogent performance achieved on classification but not on localization. Generally, they locate temporal regions by the video-level classification but overlook the temporal variations of feature semantics. To address this problem, we propose a novel attention-based hierarchically-structured latent model to learn the temporal variations of feature semantics. Specifically, our model entails two components, the first is an unsupervised change-points detection module that detects change-points by learning the latent representations of video features in a temporal hierarchy based on their rates of change, and the second is an attention-based classification model that selects the change-points of the foreground as the boundaries. To evaluate the effectiveness of our model, we conduct extensive experiments on two benchmark datasets, THUMOS-14 and ActivityNet-v1.3. The experiments show that our method outperforms current state-of-the-art methods, and even achieves comparable performance with fully-supervised methods.
</details>
<details>
<summary>摘要</summary>
weakly-supervised action localization aims to recognize and localize action instances in untrimmed videos with only video-level labels. most existing models rely on multiple instance learning(MIL), where the predictions of unlabeled instances are supervised by classifying labeled bags. the MIL-based methods are relatively well studied with cogent performance achieved on classification but not on localization. generally, they locate temporal regions by the video-level classification but overlook the temporal variations of feature semantics. to address this problem, we propose a novel attention-based hierarchically-structured latent model to learn the temporal variations of feature semantics. specifically, our model entails two components, the first is an unsupervised change-points detection module that detects change-points by learning the latent representations of video features in a temporal hierarchy based on their rates of change, and the second is an attention-based classification model that selects the change-points of the foreground as the boundaries. to evaluate the effectiveness of our model, we conduct extensive experiments on two benchmark datasets, THUMOS-14 and ActivityNet-v1.3. the experiments show that our method outperforms current state-of-the-art methods, and even achieves comparable performance with fully-supervised methods.Here's the text with traditional Chinese characters:weakly-supervised action localization aims to recognize and localize action instances in untrimmed videos with only video-level labels. most existing models rely on multiple instance learning(MIL), where the predictions of unlabeled instances are supervised by classifying labeled bags. the MIL-based methods are relatively well studied with cogent performance achieved on classification but not on localization. generally, they locate temporal regions by the video-level classification but overlook the temporal variations of feature semantics. to address this problem, we propose a novel attention-based hierarchically-structured latent model to learn the temporal variations of feature semantics. specifically, our model entails two components, the first is an unsupervised change-points detection module that detects change-points by learning the latent representations of video features in a temporal hierarchy based on their rates of change, and the second is an attention-based classification model that selects the change-points of the foreground as the boundaries. to evaluate the effectiveness of our model, we conduct extensive experiments on two benchmark datasets, THUMOS-14 and ActivityNet-v1.3. the experiments show that our method outperforms current state-of-the-art methods, and even achieves comparable performance with fully-supervised methods.
</details></li>
</ul>
<hr>
<h2 id="Dual-Branch-Deep-Learning-Network-for-Detection-and-Stage-Grading-of-Diabetic-Retinopathy"><a href="#Dual-Branch-Deep-Learning-Network-for-Detection-and-Stage-Grading-of-Diabetic-Retinopathy" class="headerlink" title="Dual Branch Deep Learning Network for Detection and Stage Grading of Diabetic Retinopathy"></a>Dual Branch Deep Learning Network for Detection and Stage Grading of Diabetic Retinopathy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09945">http://arxiv.org/abs/2308.09945</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hossein Shakibania, Sina Raoufi, Behnam Pourafkham, Hassan Khotanlou, Muharram Mansoorizadeh</li>
<li>for: 这篇论文旨在提出一种基于深度学习的视网膜病变检测和分级方法，以帮助早期识别和治疗糖尿病 relacionais complications。</li>
<li>methods: 本论文使用了两个现有的优秀预训练模型作为特征提取器，并对其进行了微调，以适应一个新的数据集。模型在一个大型多中心数据集上进行了训练，包括APTOS 2019数据集。</li>
<li>results: 本论文的提出的方法在APTOS 2019数据集上实现了优秀的视网膜病变检测和分级性能，比过去Literature中的成果更高。在二分类任务中，提出的方法取得了98.50%的准确率，99.46%的敏感度和97.51%的特异度。在分级任务中，它取得了93.00%的 quadratic weighted kappa，89.60%的准确率，89.60%的敏感度和97.72%的特异度。<details>
<summary>Abstract</summary>
Diabetic retinopathy is a severe complication of diabetes that can lead to permanent blindness if not treated promptly. Early and accurate diagnosis of the disease is essential for successful treatment. This paper introduces a deep learning method for the detection and stage grading of diabetic retinopathy, using a single fundus retinal image. Our model utilizes transfer learning, employing two state-of-the-art pre-trained models as feature extractors and fine-tuning them on a new dataset. The proposed model is trained on a large multi-center dataset, including the APTOS 2019 dataset, obtained from publicly available sources. It achieves remarkable performance in diabetic retinopathy detection and stage classification on the APTOS 2019, outperforming the established literature. For binary classification, the proposed approach achieves an accuracy of 98.50%, a sensitivity of 99.46%, and a specificity of 97.51%. In stage grading, it achieves a quadratic weighted kappa of 93.00%, an accuracy of 89.60%, a sensitivity of 89.60%, and a specificity of 97.72%. The proposed approach serves as a reliable screening and stage grading tool for diabetic retinopathy, offering significant potential to enhance clinical decision-making and patient care.
</details>
<details>
<summary>摘要</summary>
糖尿病 retinopathy 是糖尿病的严重合并症状，可能会导致永久潦倒盲视，如果不及时治疗。早期和准确的诊断是治疗的关键。本文介绍了一种深度学习方法，用于检测和评分糖尿病 retinopathy，只需要一张背景照片。我们的模型使用了传输学习，利用了两个现有的状态体验模型作为特征提取器，并在新的数据集上进行了微调。我们的模型在APTOS 2019 数据集上进行了训练，包括公共可用的数据集。它在糖尿病 retinopathy 检测和评分中实现了显著的表现，超过了现有文献。对二分类问题，我们的方法实现了98.50%的准确率，99.46%的敏感度和97.51%的特异度。在评分方面，我们的方法实现了93.00%的 quadratic 权重κ值，89.60%的准确率，89.60%的敏感度和97.72%的特异度。我们的方法可以作为糖尿病 retinopathy 的可靠检测和评分工具，提供了对临床决策和患者护理的显著潜在优势。
</details></li>
</ul>
<hr>
<h2 id="On-the-Robustness-of-Open-World-Test-Time-Training-Self-Training-with-Dynamic-Prototype-Expansion"><a href="#On-the-Robustness-of-Open-World-Test-Time-Training-Self-Training-with-Dynamic-Prototype-Expansion" class="headerlink" title="On the Robustness of Open-World Test-Time Training: Self-Training with Dynamic Prototype Expansion"></a>On the Robustness of Open-World Test-Time Training: Self-Training with Dynamic Prototype Expansion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09942">http://arxiv.org/abs/2308.09942</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yushu-li/owttt">https://github.com/yushu-li/owttt</a></li>
<li>paper_authors: Yushu Li, Xun Xu, Yongyi Su, Kui Jia</li>
<li>for: 这篇论文旨在提高 unknown target domain distribution 下的 deep learning 模型鲁棒性，并且可以在低延迟下进行 test-time training&#x2F;adaptation (TTT&#x2F;TTA)。</li>
<li>methods: 该论文提出了一种 adaptive strong OOD pruning 技术，以及一种动态扩展 prototype 以区分强 OOD 样本和弱 OOD 样本。此外，论文还提出了一种 distribution alignment REG regularization，以提高 self-training 的效果。</li>
<li>results: 该论文在 5 个 OWTTT benchmark 上达到了 state-of-the-art 性能。<details>
<summary>Abstract</summary>
Generalizing deep learning models to unknown target domain distribution with low latency has motivated research into test-time training/adaptation (TTT/TTA). Existing approaches often focus on improving test-time training performance under well-curated target domain data. As figured out in this work, many state-of-the-art methods fail to maintain the performance when the target domain is contaminated with strong out-of-distribution (OOD) data, a.k.a. open-world test-time training (OWTTT). The failure is mainly due to the inability to distinguish strong OOD samples from regular weak OOD samples. To improve the robustness of OWTTT we first develop an adaptive strong OOD pruning which improves the efficacy of the self-training TTT method. We further propose a way to dynamically expand the prototypes to represent strong OOD samples for an improved weak/strong OOD data separation. Finally, we regularize self-training with distribution alignment and the combination yields the state-of-the-art performance on 5 OWTTT benchmarks. The code is available at https://github.com/Yushu-Li/OWTTT.
</details>
<details>
<summary>摘要</summary>
通用深度学习模型到未知目标频率分布下进行普通化（Test-Time Training/Adaptation，TTT/TTA）已经引起了研究者的关注。现有的方法 oftentimes 专注于在well-curated 目标频率数据下提高测试时训练性能。在这项工作中，我们发现许多状态 искусственный智能方法在受到强外部数据杂化（Out-of-Distribution，OOD）影响时失效，主要原因是不能正确分辨强OOD样本和弱OOD样本。为了改善OWTTT的Robustness，我们首先开发了适应强OOD检索，该方法可以提高自动训练 TTT 方法的效果。我们还提出了在运行时动态扩展prototype来表示强OOD样本，以提高弱/强OOD数据的分离。最后，我们使用分布对齐和组合，并得到了5个OWTTT benchmark上的状态对齐性。代码可以在https://github.com/Yushu-Li/OWTTT中找到。
</details></li>
</ul>
<hr>
<h2 id="BLIVA-A-Simple-Multimodal-LLM-for-Better-Handling-of-Text-Rich-Visual-Questions"><a href="#BLIVA-A-Simple-Multimodal-LLM-for-Better-Handling-of-Text-Rich-Visual-Questions" class="headerlink" title="BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual Questions"></a>BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09936">http://arxiv.org/abs/2308.09936</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlpc-ucsd/bliva">https://github.com/mlpc-ucsd/bliva</a></li>
<li>paper_authors: Wenbo Hu, Yifan Xu, Yi Li, Weiyue Li, Zeyuan Chen, Zhuowen Tu</li>
<li>for: 提高实际图像中文本的理解和处理能力，以便更好地解决实际场景中的视觉问答任务。</li>
<li>methods:  combines InstructBLIP和Visual Assistant，Directly project encoded patch embeddings into the LLM，以帮助模型更好地捕捉图像中的细节。</li>
<li>results: 在处理文本含有图像的VQA benchmark tasks上显著提高性能（up to 17.76% in OCR-VQA benchmark），并在典型VQA benchmark tasks上也获得了显著提高（up to 7.9% in Visual Spatial Reasoning benchmark），并且可以在实际图像中处理文本不存在的情况下也表现出色。<details>
<summary>Abstract</summary>
Vision Language Models (VLMs), which extend Large Language Models (LLM) by incorporating visual understanding capability, have demonstrated significant advancements in addressing open-ended visual question-answering (VQA) tasks. However, these models cannot accurately interpret images infused with text, a common occurrence in real-world scenarios. Standard procedures for extracting information from images often involve learning a fixed set of query embeddings. These embeddings are designed to encapsulate image contexts and are later used as soft prompt inputs in LLMs. Yet, this process is limited to the token count, potentially curtailing the recognition of scenes with text-rich context. To improve upon them, the present study introduces BLIVA: an augmented version of InstructBLIP with Visual Assistant. BLIVA incorporates the query embeddings from InstructBLIP and also directly projects encoded patch embeddings into the LLM, a technique inspired by LLaVA. This approach assists the model to capture intricate details potentially missed during the query decoding process. Empirical evidence demonstrates that our model, BLIVA, significantly enhances performance in processing text-rich VQA benchmarks (up to 17.76\% in OCR-VQA benchmark) and in undertaking typical VQA benchmarks (up to 7.9\% in Visual Spatial Reasoning benchmark), comparing to our baseline InstructBLIP. BLIVA demonstrates significant capability in decoding real-world images, irrespective of text presence. To demonstrate the broad industry applications enabled by BLIVA, we evaluate the model using a new dataset comprising YouTube thumbnails paired with question-answer sets across 13 diverse categories. For researchers interested in further exploration, our code and models are freely accessible at https://github.com/mlpc-ucsd/BLIVA.git
</details>
<details>
<summary>摘要</summary>
大多数视语模型（VLM）通过结合视觉理解能力和大语言模型（LLM）来解决开放式视觉问答（VQA）任务，但是这些模型无法正确地理解包含文本的图像，这是现实世界中非常常见的情况。标准的图像信息抽取方法通常包括学习固定的查询嵌入。这些嵌入是用于捕捉图像上下文，并且在LLM中使用为软提示输入。然而，这种过程受到固定嵌入数量的限制，可能会遮盖捕捉场景中的文本背景。为了解决这个问题，本研究提出了BLIVA：一种基于InstructBLIP的增强版，它包括InstructBLIP的查询嵌入以及直接将编码补丁嵌入 proyect到LLM中，这种方法灵感于LLaVA。这种方法帮助模型捕捉细节信息，可能在查询解码过程中被遗弃。实验证明，我们的模型BLIVA在处理具有文本背景的VQA benchmark中表现出色，与基线InstructBLIP相比，提高了17.76%（在OCR-VQA benchmark中）和7.9%（在Visual Spatial Reasoning benchmark中）。BLIVA示出了在现实图像中捕捉文本背景的能力，不受文本存在或不存在的限制。为了展示BLIVA在广泛的 industrielles 应用中的可能性，我们使用了一个新的 YouTube 频道封面和问答集合，并对13种不同的类别进行评估。如果您想进一步探索，我们的代码和模型都可以免费下载于https://github.com/mlpc-ucsd/BLIVA.git。
</details></li>
</ul>
<hr>
<h2 id="TDG-Text-guided-Domain-Generalization"><a href="#TDG-Text-guided-Domain-Generalization" class="headerlink" title="TDG: Text-guided Domain Generalization"></a>TDG: Text-guided Domain Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09931">http://arxiv.org/abs/2308.09931</a></li>
<li>repo_url: None</li>
<li>paper_authors: Geng Liu, Yuxi Wang</li>
<li>for: 本文旨在推广基于单个或多个源领域的模型到未见的目标领域。</li>
<li>methods: 我们提出了一种新的文本引导领域泛化（TDG）方法，包括三个方面：首先，我们开发了一种自动生成域特有词汇的方法，以扩展当前领域的描述。然后，我们使用提案学习基于文本特征生成方法，将生成的域信息与图像特征共同卷积在同一个表示空间中。最后，我们使用输入图像特征和生成的文本特征来训练一个特殊的分类器，以便在未见目标领域中进行泛化。</li>
<li>results: 我们的实验结果表明，通过在TDG中引入生成的文本信息，可以提高领域泛化的性能，而且这种方法的实现非常容易。我们在多个领域泛化 benchmark 上进行了实验，并证明了我们的提出的框架可以在不同的领域中达到更高的性能。<details>
<summary>Abstract</summary>
Domain generalization (DG) attempts to generalize a model trained on single or multiple source domains to the unseen target domain. Benefiting from the success of Visual-and-Language Pre-trained models in recent years, we argue that it is crucial for domain generalization by introducing extra text information. In this paper, we develop a novel Text-guided Domain Generalization (TDG) paradigm for domain generalization, which includes three following aspects. Specifically, we first devise an automatic words generation method to extend the description of current domains with novel domain-relevant words. Then, we embed the generated domain information into the text feature space, by the proposed prompt learning-based text feature generation method, which shares a common representation space with the image feature. Finally, we utilize both input image features and generated text features to train a specially designed classifier that generalizes well on unseen target domains, while the image encoder is also updated under the supervision of gradients back propagated from the classifier. Our experimental results show that the techniques incorporated by TDG contribute to the performance in an easy implementation manner. Experimental results on several domain generalization benchmarks show that our proposed framework achieves superior performance by effectively leveraging generated text information in domain generalization.
</details>
<details>
<summary>摘要</summary>
域间泛化（DG）目标是将单个或多个源域模型泛化到未看过的目标域。受最近几年视觉语言预训模型的成功影响，我们认为在域间泛化中具有重要作用的是引入文本信息。在这篇论文中，我们提出了一种新的文本准导域泛化（TDG）方法，它包括以下三个方面：首先，我们开发了一种自动生成域关键词方法，以扩展当前域的描述，并添加新域相关的词语。然后，我们将生成的域信息embedded到文本特征空间中，通过我们提出的提示学习基于文本特征生成方法，这个方法与图像特征空间共享表示。最后，我们利用输入图像特征和生成的文本特征来训练一个专门设计的分类器，这个分类器可以在未看过的目标域上进行广泛的泛化，而图像编码器也在分类器的监督下更新。我们的实验结果表明，TDG方法可以在易于实现的情况下提高域泛化的性能。我们在多个域泛化 benchmark 上进行了实验，并证明了我们提出的方法可以有效地利用生成的文本信息，以提高域泛化的性能。
</details></li>
</ul>
<hr>
<h2 id="MDCS-More-Diverse-Experts-with-Consistency-Self-distillation-for-Long-tailed-Recognition"><a href="#MDCS-More-Diverse-Experts-with-Consistency-Self-distillation-for-Long-tailed-Recognition" class="headerlink" title="MDCS: More Diverse Experts with Consistency Self-distillation for Long-tailed Recognition"></a>MDCS: More Diverse Experts with Consistency Self-distillation for Long-tailed Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09922">http://arxiv.org/abs/2308.09922</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fistyee/mdcs">https://github.com/fistyee/mdcs</a></li>
<li>paper_authors: Qihao Zhao, Chen Jiang, Wei Hu, Fan Zhang, Jun Liu</li>
<li>for: 提高长尾识别（LTR）精度</li>
<li>methods: 使用更多的专家和自我泛化（CS）提高模型的多样性和稳定性</li>
<li>results: 与先前方法比较，MDCS方法可以提高识别精度，降低模型的偏差，并提高专家的多样性。在五个流行的长尾识别 bencmarks 上，MDCS方法比前一代 лучperform，提高精度1% 至 2%。<details>
<summary>Abstract</summary>
Recently, multi-expert methods have led to significant improvements in long-tail recognition (LTR). We summarize two aspects that need further enhancement to contribute to LTR boosting: (1) More diverse experts; (2) Lower model variance. However, the previous methods didn't handle them well. To this end, we propose More Diverse experts with Consistency Self-distillation (MDCS) to bridge the gap left by earlier methods. Our MDCS approach consists of two core components: Diversity Loss (DL) and Consistency Self-distillation (CS). In detail, DL promotes diversity among experts by controlling their focus on different categories. To reduce the model variance, we employ KL divergence to distill the richer knowledge of weakly augmented instances for the experts' self-distillation. In particular, we design Confident Instance Sampling (CIS) to select the correctly classified instances for CS to avoid biased/noisy knowledge. In the analysis and ablation study, we demonstrate that our method compared with previous work can effectively increase the diversity of experts, significantly reduce the variance of the model, and improve recognition accuracy. Moreover, the roles of our DL and CS are mutually reinforcing and coupled: the diversity of experts benefits from the CS, and the CS cannot achieve remarkable results without the DL. Experiments show our MDCS outperforms the state-of-the-art by 1% $\sim$ 2% on five popular long-tailed benchmarks, including CIFAR10-LT, CIFAR100-LT, ImageNet-LT, Places-LT, and iNaturalist 2018. The code is available at https://github.com/fistyee/MDCS.
</details>
<details>
<summary>摘要</summary>
近些时间，多专家方法已经导致长尾识别（LTR）中的显著改进。我们总结了两个需要进一步改进以提高LTR的方面：（1）更多的专家；（2）模型变量下降。然而，之前的方法没有很好地处理这两个方面。为此，我们提出了更多的专家与自我照成（MDCS），以填补之前方法留下的差距。我们的MDCS方法包括两个核心组成部分：多样性损失（DL）和自我照成（CS）。在详细说明下，DL使得专家们对不同类别的焦点控制，以提高多样性。为了降低模型变量，我们使用KL散度来让弱增强的实例对专家自我照成进行泛化。特别是，我们设计了信心实例选择（CIS），以确保选择正确分类的实例，以避免偏倚/噪音知识。我们的分析和割裁研究表明，与之前的工作相比，我们的方法可以有效增加专家的多样性，显著降低模型变量，并提高识别精度。此外，我们的DL和CS之间存在互相强化和结合关系：专家的多样性受益于CS，而CS无法取得显著成果不包括DL。实验表明，我们的MDCS在五个流行的长尾benchmark上比前一个最佳的实现1% $\sim$ 2%的提高。代码可以在https://github.com/fistyee/MDCS上获取。
</details></li>
</ul>
<hr>
<h2 id="VI-Net-Boosting-Category-level-6D-Object-Pose-Estimation-via-Learning-Decoupled-Rotations-on-the-Spherical-Representations"><a href="#VI-Net-Boosting-Category-level-6D-Object-Pose-Estimation-via-Learning-Decoupled-Rotations-on-the-Spherical-Representations" class="headerlink" title="VI-Net: Boosting Category-level 6D Object Pose Estimation via Learning Decoupled Rotations on the Spherical Representations"></a>VI-Net: Boosting Category-level 6D Object Pose Estimation via Learning Decoupled Rotations on the Spherical Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09916">http://arxiv.org/abs/2308.09916</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiehonglin/vi-net">https://github.com/jiehonglin/vi-net</a></li>
<li>paper_authors: Jiehong Lin, Zewei Wei, Yabin Zhang, Kui Jia</li>
<li>for: 高精度 объекpose数据集上的6D对象pose估计，即使没有可用的CAD模型。</li>
<li>methods: 提议一种新的旋转估计网络，名为VI-Net，它通过分解旋转为视点旋转和平面旋转的组合来简化非线性空间SO(3)中的学习。</li>
<li>results: 实验表明，提议的VI-Net方法在高精度 regime下可以大幅超过现有方法。<details>
<summary>Abstract</summary>
Rotation estimation of high precision from an RGB-D object observation is a huge challenge in 6D object pose estimation, due to the difficulty of learning in the non-linear space of SO(3). In this paper, we propose a novel rotation estimation network, termed as VI-Net, to make the task easier by decoupling the rotation as the combination of a viewpoint rotation and an in-plane rotation. More specifically, VI-Net bases the feature learning on the sphere with two individual branches for the estimates of two factorized rotations, where a V-Branch is employed to learn the viewpoint rotation via binary classification on the spherical signals, while another I-Branch is used to estimate the in-plane rotation by transforming the signals to view from the zenith direction. To process the spherical signals, a Spherical Feature Pyramid Network is constructed based on a novel design of SPAtial Spherical Convolution (SPA-SConv), which settles the boundary problem of spherical signals via feature padding and realizesviewpoint-equivariant feature extraction by symmetric convolutional operations. We apply the proposed VI-Net to the challenging task of category-level 6D object pose estimation for predicting the poses of unknown objects without available CAD models; experiments on the benchmarking datasets confirm the efficacy of our method, which outperforms the existing ones with a large margin in the regime of high precision.
</details>
<details>
<summary>摘要</summary>
rotation 估计高精度从RGB-D对象观察是6D对象pose估计中的巨大挑战，由于非线性空间SO(3)学习的困难。在本文中，我们提出了一种新的 rotate estimation network，称为VI-Net，以使任务更加容易，通过分解旋转为两个因素旋转的组合。更具体地说，VI-Net基于特有的SPAtial Spherical Convolution（SPA-SConv）设计，在特定的圆形信号上进行特征学习，并通过将信号变换到zenith方向来估计平面旋转。为处理圆形信号，我们构建了一个叫做Spherical Feature Pyramid Network（SFPN），该网络通过特有的SPA-SConv设计解决了圆形信号的边界问题，并实现了视角平衡的特征提取。我们应用提出的VI-Net来解决6D对象pose估计中的category-level高精度任务，对于未知对象而言，不需要可用的CAD模型；在标准测试集上进行了实验，并证明了我们的方法在高精度 режи下表现出了明显的优势。
</details></li>
</ul>
<hr>
<h2 id="EGANS-Evolutionary-Generative-Adversarial-Network-Search-for-Zero-Shot-Learning"><a href="#EGANS-Evolutionary-Generative-Adversarial-Network-Search-for-Zero-Shot-Learning" class="headerlink" title="EGANS: Evolutionary Generative Adversarial Network Search for Zero-Shot Learning"></a>EGANS: Evolutionary Generative Adversarial Network Search for Zero-Shot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09915">http://arxiv.org/abs/2308.09915</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiming Chen, Shihuang Chen, Wenjin Hou, Weiping Ding, Xinge You</li>
<li>for: 这篇论文的目的是提出一种基于进化的对抗学习方法（EGANS），以自动设计适应性和稳定性优化的生成网络，并在不同数据集&#x2F;场景下进行可靠的视觉特征样本生成，以提高零对零学习（ZSL）的性能。</li>
<li>methods: 这篇论文使用了协同对抗进化搜索（cooperative dual evolution）来进行神经网络架构搜索，包括生成器和检测器两个部分。在演化生成器架构搜索阶段，运用了多对一对抗训练策略来演化生成器。然后，使用了相似的演化搜索算法来进行检测器架构搜索。</li>
<li>results: 实验结果显示，EGANS可以稳定地提高现有的生成ZSL方法的性能，在标准的CUB、SUN、AWA2和FLO数据集上均有显著的表现提升。这些表现提升显示了进化性的神经架构搜索在ZSL领域中的可能性。<details>
<summary>Abstract</summary>
Zero-shot learning (ZSL) aims to recognize the novel classes which cannot be collected for training a prediction model. Accordingly, generative models (e.g., generative adversarial network (GAN)) are typically used to synthesize the visual samples conditioned by the class semantic vectors and achieve remarkable progress for ZSL. However, existing GAN-based generative ZSL methods are based on hand-crafted models, which cannot adapt to various datasets/scenarios and fails to model instability. To alleviate these challenges, we propose evolutionary generative adversarial network search (termed EGANS) to automatically design the generative network with good adaptation and stability, enabling reliable visual feature sample synthesis for advancing ZSL. Specifically, we adopt cooperative dual evolution to conduct a neural architecture search for both generator and discriminator under a unified evolutionary adversarial framework. EGANS is learned by two stages: evolution generator architecture search and evolution discriminator architecture search. During the evolution generator architecture search, we adopt a many-to-one adversarial training strategy to evolutionarily search for the optimal generator. Then the optimal generator is further applied to search for the optimal discriminator in the evolution discriminator architecture search with a similar evolution search algorithm. Once the optimal generator and discriminator are searched, we entail them into various generative ZSL baselines for ZSL classification. Extensive experiments show that EGANS consistently improve existing generative ZSL methods on the standard CUB, SUN, AWA2 and FLO datasets. The significant performance gains indicate that the evolutionary neural architecture search explores a virgin field in ZSL.
</details>
<details>
<summary>摘要</summary>
zero-shot learning（ZSL）的目标是识别无法在训练预测模型的新类。因此，通常使用生成模型（如生成对抗网络（GAN））来生成基于类含义 вектор的视觉样本，并取得了remarkable进步。然而，现有的GAN基于的生成ZSL方法都是基于手工设计的模型，无法适应不同的数据集/场景，并且容易出现模型不稳定的问题。为了解决这些挑战，我们提出了进化生成对抗网络搜索（EGANS），用于自动设计生成网络，以便在不同数据集/场景中具有良好的适应和稳定性，从而实现可靠的视觉特征样本生成，以提高ZSL的进步。EGANS采用了合作双向进化来进行神经网络搜索，包括生成器和判断器的搜索。在生成器搜索阶段，我们采用了多对一对抗训练策略来进行进化搜索，以找到最佳的生成器。然后，我们将最佳的生成器应用于判断器搜索阶段，通过类似的进化搜索策略来找到最佳的判断器。一旦找到了最佳的生成器和判断器，我们将它们与不同的生成ZSL基线方法进行比较，以评估EGANS的性能。实验结果表明，EGANS在标准的CUB、SUN、AWA2和FLO数据集上具有显著的性能提升，这表明了进化神经网络搜索在ZSL中探索了一个新的领域。
</details></li>
</ul>
<hr>
<h2 id="Noisy-Correspondence-Learning-for-Text-to-Image-Person-Re-identification"><a href="#Noisy-Correspondence-Learning-for-Text-to-Image-Person-Re-identification" class="headerlink" title="Noisy-Correspondence Learning for Text-to-Image Person Re-identification"></a>Noisy-Correspondence Learning for Text-to-Image Person Re-identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09911">http://arxiv.org/abs/2308.09911</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tencentyouturesearch/personretrieval-ivt">https://github.com/tencentyouturesearch/personretrieval-ivt</a></li>
<li>paper_authors: Yang Qin, Yingke Chen, Dezhong Peng, Xi Peng, Joey Tianyi Zhou, Peng Hu</li>
<li>for: 提高 Text-to-image person re-identification（TIReID）方法的Robustness，以便在实际场景中处理受到干扰的图像和文本对应关系。</li>
<li>methods: 提出了一种名为 Robust Dual Embedding（RDE）的新方法，包括两个主要组成部分：1）一个Confident Consensus Division（CCD）模块，利用双重排序模块的双重决策来获取一个纯净的训练数据集，以便学习正确和可靠的视Semantic关系。2）一个Triplet-Alignment Loss（TAL），将传统的 triplet-ranking损失函数改进为对所有负样本进行征逐，以避免模型过度依赖干扰的图像-文本对应关系。</li>
<li>results: 通过在三个公共评测 dataset（CUHK-PEDES、ICFG-PEDES和RSTPReID）进行广泛的实验，证明了我们的RDE方法在不受NC干扰的情况下和受NC干扰的情况下均 achieve 状态的最佳Result。<details>
<summary>Abstract</summary>
Text-to-image person re-identification (TIReID) is a compelling topic in the cross-modal community, which aims to retrieve the target person based on a textual query. Although numerous TIReID methods have been proposed and achieved promising performance, they implicitly assume the training image-text pairs are correctly aligned, which is not always the case in real-world scenarios. In practice, the image-text pairs inevitably exist under-correlated or even false-correlated, a.k.a noisy correspondence (NC), due to the low quality of the images and annotation errors. To address this problem, we propose a novel Robust Dual Embedding method (RDE) that can learn robust visual-semantic associations even with NC. Specifically, RDE consists of two main components: 1) A Confident Consensus Division (CCD) module that leverages the dual-grained decisions of dual embedding modules to obtain a consensus set of clean training data, which enables the model to learn correct and reliable visual-semantic associations. 2) A Triplet-Alignment Loss (TAL) relaxes the conventional triplet-ranking loss with hardest negatives, which tends to rapidly overfit NC, to a log-exponential upper bound over all negatives, thus preventing the model from overemphasizing false image-text pairs. We conduct extensive experiments on three public benchmarks, namely CUHK-PEDES, ICFG-PEDES, and RSTPReID, to evaluate the performance and robustness of our RDE. Our method achieves state-of-the-art results both with and without synthetic noisy correspondences on all three datasets.
</details>
<details>
<summary>摘要</summary>
Text-to-image人重识别（TIReID）是跨模态社区中吸引人的话题，它目的是基于文本查询来 retrieve目标人。虽然多种 TIReID 方法已经被提出并实现了各种表现，但它们在假设训练图像文本对应是正确的情况下进行学习，而在实际场景中，图像文本对应存在偏差或假的对应关系（NC），即低质量图像和注释错误。为解决这问题，我们提出了一种robust dual embedding方法（RDE），可以学习具有NC的视Semantic关系。RDE包括两个主要组件： 1. 自信投票分区（CCD）模块，通过双重权重分配模块的双重决策来获得一个净的训练数据集，使模型可以学习正确和可靠的视Semantic关系。 2.  triplet对齐损失（TAL），通过放弃硬iest negative triplet损失，而是将 triplet损失Relax到log-exponential upper bound上，以防止模型过度强调NC。我们在三个公共Benchmark上进行了广泛的实验，分别是CUHK-PEDES、ICFG-PEDES和RSTPReID，以评估我们的RDE表现和稳定性。我们的方法在所有三个数据集上都实现了状态的art表现，并且在Synthetic NC情况下也具有优秀的表现。
</details></li>
</ul>
<hr>
<h2 id="Physics-Guided-Human-Motion-Capture-with-Pose-Probability-Modeling"><a href="#Physics-Guided-Human-Motion-Capture-with-Pose-Probability-Modeling" class="headerlink" title="Physics-Guided Human Motion Capture with Pose Probability Modeling"></a>Physics-Guided Human Motion Capture with Pose Probability Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09910">http://arxiv.org/abs/2308.09910</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/me-ditto/physics-guided-mocap">https://github.com/me-ditto/physics-guided-mocap</a></li>
<li>paper_authors: Jingyi Ju, Buzhen Huang, Chen Zhu, Zhihao Li, Yangang Wang</li>
<li>for: 提高人体动作捕捉的精度和成功率，避免漂浮、脚部滑动和地面凿入等误差。</li>
<li>methods: 采用物理学为导向，在反卷积过程中使用物理学来降噪减雷，从模型 pose 分布中重建物理可能性最高的人体动作。</li>
<li>results: 与前一代物理学基本方法相比，本方法在 JOINT 精度和成功率方面具有显著的提高，可以更好地捕捉人体动作。更多信息可以查看 \url{<a target="_blank" rel="noopener" href="https://github.com/Me-Ditto/Physics-Guided-Mocap%7D%E3%80%82">https://github.com/Me-Ditto/Physics-Guided-Mocap}。</a><details>
<summary>Abstract</summary>
Incorporating physics in human motion capture to avoid artifacts like floating, foot sliding, and ground penetration is a promising direction. Existing solutions always adopt kinematic results as reference motions, and the physics is treated as a post-processing module. However, due to the depth ambiguity, monocular motion capture inevitably suffers from noises, and the noisy reference often leads to failure for physics-based tracking. To address the obstacles, our key-idea is to employ physics as denoising guidance in the reverse diffusion process to reconstruct physically plausible human motion from a modeled pose probability distribution. Specifically, we first train a latent gaussian model that encodes the uncertainty of 2D-to-3D lifting to facilitate reverse diffusion. Then, a physics module is constructed to track the motion sampled from the distribution. The discrepancies between the tracked motion and image observation are used to provide explicit guidance for the reverse diffusion model to refine the motion. With several iterations, the physics-based tracking and kinematic denoising promote each other to generate a physically plausible human motion. Experimental results show that our method outperforms previous physics-based methods in both joint accuracy and success rate. More information can be found at \url{https://github.com/Me-Ditto/Physics-Guided-Mocap}.
</details>
<details>
<summary>摘要</summary>
将物理学 incorporated into 人体动作捕捉，以避免浮动、脚部滑块和地面嵌入的artefacts是一个Promising方向。现有的解决方案都是采用骨骼结果作为参考动作，并将物理学当作后处理模块。然而，由于深度的模糊，单目动作捕捉不可避免噪音，这些噪音经常导致物理学基于跟踪失败。为了解决这些障碍，我们的关键思想是使用物理学作为减噪指导，在反卷积过程中重建可靠的人体动作。specifically，我们首先训练了一个卷积学习模型，用于编码2D-to-3D的不确定性，以便在反卷积过程中进行减噪。然后，我们构建了物理模块，以跟踪从分布中抽取的动作。图像观测与跟踪的差异被用于直接提供反卷积模型的减噪指导，以便在几次迭代中改进动作。通过这种方式，物理学基于跟踪和骨骼减噪促进了对人体动作的重建。实验结果表明，我们的方法在 JOINT 精度和成功率方面都高于前期物理学基于方法。更多信息可以参考 \url{https://github.com/Me-Ditto/Physics-Guided-Mocap}.
</details></li>
</ul>
<hr>
<h2 id="DiffusionTrack-Diffusion-Model-For-Multi-Object-Tracking"><a href="#DiffusionTrack-Diffusion-Model-For-Multi-Object-Tracking" class="headerlink" title="DiffusionTrack: Diffusion Model For Multi-Object Tracking"></a>DiffusionTrack: Diffusion Model For Multi-Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09905">http://arxiv.org/abs/2308.09905</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rainbowluocs/diffusiontrack">https://github.com/rainbowluocs/diffusiontrack</a></li>
<li>paper_authors: Run Luo, Zikai Song, Lintao Ma, Jinlin Wei, Wei Yang, Min Yang</li>
<li>for: 这 paper 的目的是提出一种简单 yet robust 的多目标跟踪 (MOT) 方法，以解决现有 MOT 方法 的一些问题，如 global or local inconsistency, 模型复杂性和灵活性不足。</li>
<li>methods: 这 paper 使用的方法是通过 Paired Noise Boxes 到 Paired Ground-Truth Boxes 的一种逐步减噪演化策略，来实现对象检测和跟踪的一体化。在训练阶段，模型通过减噪演化过程来学习检测和跟踪，而在测试阶段，模型通过一种灵活的一步或多步减噪演化来更新检测和跟踪结果。</li>
<li>results: 这 paper 的实验结果表明，使用这种方法可以在三个常用的 MOT  benchmark 上达到与当前状态的识别方法相当的性能，包括 MOT17, MOT20 和 Dancetrack。<details>
<summary>Abstract</summary>
Multi-object tracking (MOT) is a challenging vision task that aims to detect individual objects within a single frame and associate them across multiple frames. Recent MOT approaches can be categorized into two-stage tracking-by-detection (TBD) methods and one-stage joint detection and tracking (JDT) methods. Despite the success of these approaches, they also suffer from common problems, such as harmful global or local inconsistency, poor trade-off between robustness and model complexity, and lack of flexibility in different scenes within the same video. In this paper we propose a simple but robust framework that formulates object detection and association jointly as a consistent denoising diffusion process from paired noise boxes to paired ground-truth boxes. This novel progressive denoising diffusion strategy substantially augments the tracker's effectiveness, enabling it to discriminate between various objects. During the training stage, paired object boxes diffuse from paired ground-truth boxes to random distribution, and the model learns detection and tracking simultaneously by reversing this noising process. In inference, the model refines a set of paired randomly generated boxes to the detection and tracking results in a flexible one-step or multi-step denoising diffusion process. Extensive experiments on three widely used MOT benchmarks, including MOT17, MOT20, and Dancetrack, demonstrate that our approach achieves competitive performance compared to the current state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
多目标跟踪（MOT）是一项视觉任务，旨在单帧内检测个体对象并在多帧中相关联。现代MOT方法可以分为两种阶段的跟踪检测（TBD）方法和一体的检测和跟踪（JDT）方法。尽管这些方法具有成功，但它们也存在一些共同的问题，如全局或局部的不一致、轻度的模型复杂度和不同场景中的灵活性不足。在这篇论文中，我们提出了一个简单 yet robust的框架，它将对象检测和相关联视为一个一致的降噪演进程，从对应的噪声框到对应的真实框进行进行逐步降噪。在训练阶段，对象框从对应的真实框降噪到随机分布，并且模型同时学习检测和跟踪的过程。在推断阶段，模型将一组随机生成的对象框进行精细的逐步降噪处理，以实现一步或多步的检测和跟踪结果。我们在MOT17、MOT20和Dancetrack等三个常用的MOT标准 benchmark上进行了广泛的实验，结果显示我们的方法与当前状态的方法相比，具有竞争性的性能。
</details></li>
</ul>
<hr>
<h2 id="Scalable-Video-Object-Segmentation-with-Simplified-Framework"><a href="#Scalable-Video-Object-Segmentation-with-Simplified-Framework" class="headerlink" title="Scalable Video Object Segmentation with Simplified Framework"></a>Scalable Video Object Segmentation with Simplified Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09903">http://arxiv.org/abs/2308.09903</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiangqiang Wu, Tianyu Yang, Wei WU, Antoni Chan</li>
<li>for: 这个论文主要针对视频对象分割（VOS）领域的问题，即如何使用简单的模型来实现高效的目标检测和分割。</li>
<li>methods: 这篇论文提出了一种可扩展的Simplified VOS（SimVOS）框架，利用单一的变换器底层来同时进行特征提取和匹配。此外，论文还提出了一种在框架中使用的快速注意力机制和新的токен精细化模块，以提高运行速度和避免计算成本增加。</li>
<li>results: 实验表明，我们的SimVOS可以在流行的视频对象分割数据集上达到最佳效果，包括DAVIS-2017（88.0% J&amp;F）、DAVIS-2016（92.9% J&amp;F）和YouTube-VOS 2019（84.2% J&amp;F）等数据集，而无需应用任何 sintética video 或 BL30K 预训练。<details>
<summary>Abstract</summary>
The current popular methods for video object segmentation (VOS) implement feature matching through several hand-crafted modules that separately perform feature extraction and matching. However, the above hand-crafted designs empirically cause insufficient target interaction, thus limiting the dynamic target-aware feature learning in VOS. To tackle these limitations, this paper presents a scalable Simplified VOS (SimVOS) framework to perform joint feature extraction and matching by leveraging a single transformer backbone. Specifically, SimVOS employs a scalable ViT backbone for simultaneous feature extraction and matching between query and reference features. This design enables SimVOS to learn better target-ware features for accurate mask prediction. More importantly, SimVOS could directly apply well-pretrained ViT backbones (e.g., MAE) for VOS, which bridges the gap between VOS and large-scale self-supervised pre-training. To achieve a better performance-speed trade-off, we further explore within-frame attention and propose a new token refinement module to improve the running speed and save computational cost. Experimentally, our SimVOS achieves state-of-the-art results on popular video object segmentation benchmarks, i.e., DAVIS-2017 (88.0% J&F), DAVIS-2016 (92.9% J&F) and YouTube-VOS 2019 (84.2% J&F), without applying any synthetic video or BL30K pre-training used in previous VOS approaches.
</details>
<details>
<summary>摘要</summary>
当前流行的视频对象分割（VOS）方法通常通过多个手动设计的模块来实现特征匹配。然而，这些手动设计在实践中会导致不充分的目标互动，从而限制VOS中的动态目标感知特征学习。为了解决这些限制，本文提出了一个可扩展的简化VOS（SimVOS）框架，用于同时执行特征提取和匹配。具体来说，SimVOS使用可扩展的ViT脊梁来同时提取和匹配查询和参照特征。这种设计使得SimVOS能够学习更好的目标相关特征，以提高掩模预测的准确性。此外，SimVOS可以直接应用已经预训练的ViT脊梁（例如MAE）来进行VOS，这种 bridging 可以将VOS和大规模自动预训练相连接。为了实现更好的性能-速度交易，我们进一步探索了 Within-frame 注意力和一种新的 токен细化模块，以提高运行速度并降低计算成本。实验结果表明，我们的 SimVOS 在流行的视频对象分割标准 bencmarks 上 achieve state-of-the-art 结果，无需应用任何 sintetic video 或 BL30K 预训练，这些预训练在前一代 VOS 方法中通常被使用。
</details></li>
</ul>
<hr>
<h2 id="Towards-a-High-Performance-Object-Detector-Insights-from-Drone-Detection-Using-ViT-and-CNN-based-Deep-Learning-Models"><a href="#Towards-a-High-Performance-Object-Detector-Insights-from-Drone-Detection-Using-ViT-and-CNN-based-Deep-Learning-Models" class="headerlink" title="Towards a High-Performance Object Detector: Insights from Drone Detection Using ViT and CNN-based Deep Learning Models"></a>Towards a High-Performance Object Detector: Insights from Drone Detection Using ViT and CNN-based Deep Learning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09899">http://arxiv.org/abs/2308.09899</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyang Zhang</li>
<li>for: 避免无人机和自驾车与无人机相撞、防御无人机入侵和自驾车自动降落。</li>
<li>methods: 使用 CNN 和 ViT 模型，实现单一无人机检测和多无人机检测。</li>
<li>results: 比较 CNN 和 ViT 模型的性能，发现 ViT 在单一无人机检测中表现4.6倍更好，但需要更多的训练数据、computational power 和高级设计来完全超越 CNN 检测器。<details>
<summary>Abstract</summary>
Accurate drone detection is strongly desired in drone collision avoidance, drone defense and autonomous Unmanned Aerial Vehicle (UAV) self-landing. With the recent emergence of the Vision Transformer (ViT), this critical task is reassessed in this paper using a UAV dataset composed of 1359 drone photos. We construct various CNN and ViT-based models, demonstrating that for single-drone detection, a basic ViT can achieve performance 4.6 times more robust than our best CNN-based transfer learning models. By implementing the state-of-the-art You Only Look Once (YOLO v7, 200 epochs) and the experimental ViT-based You Only Look At One Sequence (YOLOS, 20 epochs) in multi-drone detection, we attain impressive 98% and 96% mAP values, respectively. We find that ViT outperforms CNN at the same epoch, but also requires more training data, computational power, and sophisticated, performance-oriented designs to fully surpass the capabilities of cutting-edge CNN detectors. We summarize the distinct characteristics of ViT and CNN models to aid future researchers in developing more efficient deep learning models.
</details>
<details>
<summary>摘要</summary>
准确的飞行器探测在无人机冲突避免、无人机防御和自适应无人机自降中是非常重要的。随着最近的视力变换器（ViT）的出现，我们在这篇论文中使用了一个无人机数据集，包含1359个飞行器照片，重新评估了这个关键任务。我们构建了不同的CNN和ViT基本模型，发现在单飞行器探测任务中，一个基本的ViT可以达到与我们最佳CNN基本传播学习模型的4.6倍的性能。通过在多飞行器探测任务中实现了state-of-the-art的You Only Look Once（YOLO v7，200 epochs）和实验性的ViT基本You Only Look At One Sequence（YOLOS，20 epochs），我们获得了各种98%和96%的mAP值。我们发现ViT比CNN在同一个熬煮值下表现更好，但也需要更多的训练数据、计算能力和复杂的性能设计来完全超越现有的CNN探测器。我们总结了ViT和CNN模型的特点，以帮助未来的研究人员开发更高效的深度学习模型。
</details></li>
</ul>
<hr>
<h2 id="Spatial-Temporal-Alignment-Network-for-Action-Recognition"><a href="#Spatial-Temporal-Alignment-Network-for-Action-Recognition" class="headerlink" title="Spatial-Temporal Alignment Network for Action Recognition"></a>Spatial-Temporal Alignment Network for Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09897">http://arxiv.org/abs/2308.09897</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinhui Ye, Junwei Liang</li>
<li>for: 本文旨在提出一种视角不变特征表示方法，用于改进现有动作识别架构。</li>
<li>methods: 该方法基于一种名为空间-时间对应网络（STAN），该网络可以学习geometry invariant的表示。</li>
<li>results: 实验结果表明，在训练从scratch的情况下，STAN模型可以在UCf101和HMDB51等广泛使用的数据集上提高动作识别任务的性能。<details>
<summary>Abstract</summary>
This paper studies introducing viewpoint invariant feature representations in existing action recognition architecture. Despite significant progress in action recognition, efficiently handling geometric variations in large-scale datasets remains challenging. To tackle this problem, we propose a novel Spatial-Temporal Alignment Network (STAN), which explicitly learns geometric invariant representations for action recognition. Notably, the STAN model is light-weighted and generic, which could be plugged into existing action recognition models (e.g., MViTv2) with a low extra computational cost. We test our STAN model on widely-used datasets like UCF101 and HMDB51. The experimental results show that the STAN model can consistently improve the state-of-the-art models in action recognition tasks in trained-from-scratch settings.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Semantic-Human-Neural-Rendering-of-Humans-from-Monocular-Video-with-Human-Parsing"><a href="#Semantic-Human-Neural-Rendering-of-Humans-from-Monocular-Video-with-Human-Parsing" class="headerlink" title="Semantic-Human: Neural Rendering of Humans from Monocular Video with Human Parsing"></a>Semantic-Human: Neural Rendering of Humans from Monocular Video with Human Parsing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09894">http://arxiv.org/abs/2308.09894</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Zhang, Pengcheng Shi, Zaiwang Gu, Yiyang Zhou, Zhi Wang</li>
<li>for: 本研究旨在提高人体 нейрон渲染的质量，同时实现人体解析。</li>
<li>methods: 本文提出了一种名为Semantic-Human的新方法，它可以同时实现高品质的渲染和视角相关的人体解析。特别是，该方法在NeRF基础上扩展了semantics, appearance和geometry的编码，以实现基于噪声批量标签的高精度2D semantic labels。此外，该方法还引入了基于SMPL表面的运动场和恢复的三维几何学regularization。</li>
<li>results: 在使用ZJU-MoCap数据集进行评估时，Semantic-Human方法得到了非常竞争力的结果，证明了该方法的有效性。此外，该方法还可以实现多种有趣的应用，如标签噪声除除、标签生成和图像修改等，并且经验 Validate了其优势性。<details>
<summary>Abstract</summary>
The neural rendering of humans is a topic of great research significance. However, previous works mostly focus on achieving photorealistic details, neglecting the exploration of human parsing. Additionally, classical semantic work are all limited in their ability to efficiently represent fine results in complex motions. Human parsing is inherently related to radiance reconstruction, as similar appearance and geometry often correspond to similar semantic part. Furthermore, previous works often design a motion field that maps from the observation space to the canonical space, while it tends to exhibit either underfitting or overfitting, resulting in limited generalization. In this paper, we present Semantic-Human, a novel method that achieves both photorealistic details and viewpoint-consistent human parsing for the neural rendering of humans. Specifically, we extend neural radiance fields (NeRF) to jointly encode semantics, appearance and geometry to achieve accurate 2D semantic labels using noisy pseudo-label supervision. Leveraging the inherent consistency and smoothness properties of NeRF, Semantic-Human achieves consistent human parsing in both continuous and novel views. We also introduce constraints derived from the SMPL surface for the motion field and regularization for the recovered volumetric geometry. We have evaluated the model using the ZJU-MoCap dataset, and the obtained highly competitive results demonstrate the effectiveness of our proposed Semantic-Human. We also showcase various compelling applications, including label denoising, label synthesis and image editing, and empirically validate its advantageous properties.
</details>
<details>
<summary>摘要</summary>
“人体神经渲染是研究领域的热点话题。然而，前一些工作强调了实现光真实细节，忽略了人体解析的探索。此外，传统的 semantic 工作都受到了复杂动作中的细节表示的限制。人体解析与光重建密切相关，因为类似的外观和结构通常对应于类似的semantic部分。此外，以前的工作通常将动作场景映射到了 canonical 空间，而这经常导致过拟合或者下降抑制，限制了其泛化能力。在本文中，我们提出了 Semantic-Human，一种新的方法，能够同时实现光真实细节和视点一致的人体解析。具体来说，我们扩展了神经辐射场（NeRF），使其同时编码semantics、外观和geometry以实现基于噪声假标签的高精度2D semantic标签。利用NeRF的自然协调性和平滑性属性，Semantic-Human在连续和新视图下实现了一致的人体解析。我们还引入了基于 SMPL  поверхност的运动场景约束和 recovered volumetric geometry 的正则化。我们在 ZJU-MoCap 数据集上评估了模型，并获得了非常竞争力的结果，证明了我们提出的 Semantic-Human 的效果。我们还展示了多种吸引人的应用，包括标签噪声去除、标签生成和图像修改，并且实际验证了它的优点性质。”
</details></li>
</ul>
<hr>
<h2 id="DUAW-Data-free-Universal-Adversarial-Watermark-against-Stable-Diffusion-Customization"><a href="#DUAW-Data-free-Universal-Adversarial-Watermark-against-Stable-Diffusion-Customization" class="headerlink" title="DUAW: Data-free Universal Adversarial Watermark against Stable Diffusion Customization"></a>DUAW: Data-free Universal Adversarial Watermark against Stable Diffusion Customization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09889">http://arxiv.org/abs/2308.09889</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyu Ye, Hao Huang, Jiaqi An, Yongtao Wang<br>for:  This paper aims to address the issue of copyright infringement in Stable Diffusion (SD) customization approaches by proposing an invisible data-free universal adversarial watermark (DUAW) to protect a myriad of copyrighted images.methods:  The proposed DUAW is designed to disrupt the variational autoencoder during SD customization, and it operates in a data-free context using synthetic images produced by a Large Language Model (LLM) and a pretrained SD model.results:  Experimental results demonstrate that DUAW can effectively distort the outputs of fine-tuned SD models, rendering them discernible to both human observers and a simple classifier, thereby protecting copyrighted images from plagiarism.<details>
<summary>Abstract</summary>
Stable Diffusion (SD) customization approaches enable users to personalize SD model outputs, greatly enhancing the flexibility and diversity of AI art. However, they also allow individuals to plagiarize specific styles or subjects from copyrighted images, which raises significant concerns about potential copyright infringement. To address this issue, we propose an invisible data-free universal adversarial watermark (DUAW), aiming to protect a myriad of copyrighted images from different customization approaches across various versions of SD models. First, DUAW is designed to disrupt the variational autoencoder during SD customization. Second, DUAW operates in a data-free context, where it is trained on synthetic images produced by a Large Language Model (LLM) and a pretrained SD model. This approach circumvents the necessity of directly handling copyrighted images, thereby preserving their confidentiality. Once crafted, DUAW can be imperceptibly integrated into massive copyrighted images, serving as a protective measure by inducing significant distortions in the images generated by customized SD models. Experimental results demonstrate that DUAW can effectively distort the outputs of fine-tuned SD models, rendering them discernible to both human observers and a simple classifier.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Calibrating-Uncertainty-for-Semi-Supervised-Crowd-Counting"><a href="#Calibrating-Uncertainty-for-Semi-Supervised-Crowd-Counting" class="headerlink" title="Calibrating Uncertainty for Semi-Supervised Crowd Counting"></a>Calibrating Uncertainty for Semi-Supervised Crowd Counting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09887">http://arxiv.org/abs/2308.09887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Li, Xiaoling Hu, Shahira Abousamra, Chao Chen</li>
<li>for: 这篇论文的目的是提出一种用于半指导人数推断的新方法，以提高这种任务的性能。</li>
<li>methods: 这篇论文使用了一种基于模型不确定性的方法，通过调教一个价值函数来训练模型。这个方法使用了一种匹配函数来更好地估计人数推断的不确定性。</li>
<li>results: 这篇论文的结果显示，使用这种方法可以生成可靠的伪标签，并且可以实现semi-supervised人数推断的state-of-the-art性能。<details>
<summary>Abstract</summary>
Semi-supervised crowd counting is an important yet challenging task. A popular approach is to iteratively generate pseudo-labels for unlabeled data and add them to the training set. The key is to use uncertainty to select reliable pseudo-labels. In this paper, we propose a novel method to calibrate model uncertainty for crowd counting. Our method takes a supervised uncertainty estimation strategy to train the model through a surrogate function. This ensures the uncertainty is well controlled throughout the training. We propose a matching-based patch-wise surrogate function to better approximate uncertainty for crowd counting tasks. The proposed method pays a sufficient amount of attention to details, while maintaining a proper granularity. Altogether our method is able to generate reliable uncertainty estimation, high quality pseudolabels, and achieve state-of-the-art performance in semisupervised crowd counting.
</details>
<details>
<summary>摘要</summary>
semi-supervised crowd counting 是一项重要又挑战性的任务。一种popular approach是iteratively generating pseudo-labels for unlabeled data and adding them to the training set。关键在于使用uncertainty选择可靠的pseudo-labels。在这篇论文中，我们提出了一种novel method to calibrate model uncertainty for crowd counting。我们的方法通过一个supervised uncertainty estimation strategy to train the model through a surrogate function，这 garantizesthat uncertainty is well controlled throughout the training。我们提出了一种matching-based patch-wise surrogate function to better approximate uncertainty for crowd counting tasks。提议的方法具有 suficient amount of attention to details，同时保持proper granularity。总之，我们的方法能够生成可靠的uncertainty estimation，高质量的pseudolabels，并实现semisupervised crowd counting的state-of-the-art performance。
</details></li>
</ul>
<hr>
<h2 id="Forecast-MAE-Self-supervised-Pre-training-for-Motion-Forecasting-with-Masked-Autoencoders"><a href="#Forecast-MAE-Self-supervised-Pre-training-for-Motion-Forecasting-with-Masked-Autoencoders" class="headerlink" title="Forecast-MAE: Self-supervised Pre-training for Motion Forecasting with Masked Autoencoders"></a>Forecast-MAE: Self-supervised Pre-training for Motion Forecasting with Masked Autoencoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09882">http://arxiv.org/abs/2308.09882</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jchengai/forecast-mae">https://github.com/jchengai/forecast-mae</a></li>
<li>paper_authors: Jie Cheng, Xiaodong Mei, Ming Liu</li>
<li>for: 这个研究探索了自监学习（SSL）在动态预测任务中的应用，这是计算机视觉和自然语言处理领域中广泛成功的 SSL 方法，却尚未得到广泛研究。</li>
<li>methods: 我们引入了 Forecast-MAE，一种基于面积自适应神经网络（Transformer）块的 SSL 框架，特意设计用于自监学习动态预测任务。我们的方法包括一种新的面 másking 策略，利用agent trajectory 和路网之间强联系，通过补做agent future trajectory 和历史 trajectory的 complementary másking，以及随机 másking 路网段。</li>
<li>results: 我们在 Argoverse 2 动态预测测试集上进行了实验，显示 Forecast-MAE 在与 supervised learning 和复杂设计的方法相比，在竞争性Task 中具有竞争性的性能。此外，它还超过了之前的自监学习方法，表明 Forecast-MAE 可以充分利用 SSL 来预测动态Scene。<details>
<summary>Abstract</summary>
This study explores the application of self-supervised learning (SSL) to the task of motion forecasting, an area that has not yet been extensively investigated despite the widespread success of SSL in computer vision and natural language processing. To address this gap, we introduce Forecast-MAE, an extension of the mask autoencoders framework that is specifically designed for self-supervised learning of the motion forecasting task. Our approach includes a novel masking strategy that leverages the strong interconnections between agents' trajectories and road networks, involving complementary masking of agents' future or history trajectories and random masking of lane segments. Our experiments on the challenging Argoverse 2 motion forecasting benchmark show that Forecast-MAE, which utilizes standard Transformer blocks with minimal inductive bias, achieves competitive performance compared to state-of-the-art methods that rely on supervised learning and sophisticated designs. Moreover, it outperforms the previous self-supervised learning method by a significant margin. Code is available at https://github.com/jchengai/forecast-mae.
</details>
<details>
<summary>摘要</summary>
这种研究探讨了使用自动教学学习（SSL）来解决运动预测任务，这是一个尚未得到广泛探讨的领域，尽管SSL在计算机视觉和自然语言处理领域得到了广泛的成功。为了解决这个遗漏，我们介绍了 Forecast-MAE，一种特制的mask autoencoders框架，用于自动教学学习运动预测任务。我们的方法包括一种新的面积策略，利用汽车轨迹和公路网络之间的强相关性，包括补做未来或历史轨迹的随机掩码和路段掩码。我们在Argoverse 2运动预测测试benchmark上进行了实验，发现 Forecast-MAE，使用标准Transformer块和最小适应性，可以与supervised learning和复杂设计的方法相比肩，并且超过了之前的自动教学方法，性能较好。代码可以在https://github.com/jchengai/forecast-mae中找到。
</details></li>
</ul>
<hr>
<h2 id="DatasetEquity-Are-All-Samples-Created-Equal-In-The-Quest-For-Equity-Within-Datasets"><a href="#DatasetEquity-Are-All-Samples-Created-Equal-In-The-Quest-For-Equity-Within-Datasets" class="headerlink" title="DatasetEquity: Are All Samples Created Equal? In The Quest For Equity Within Datasets"></a>DatasetEquity: Are All Samples Created Equal? In The Quest For Equity Within Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09878">http://arxiv.org/abs/2308.09878</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/towardsautonomy/datasetequity">https://github.com/towardsautonomy/datasetequity</a></li>
<li>paper_authors: Shubham Shrivastava, Xianling Zhang, Sushruth Nagesh, Armin Parchami</li>
<li>for: 本研究旨在解决机器学习中的数据不均衡问题，具体来说是针对computer vision领域中的数据偏见问题。</li>
<li>methods: 本研究使用了深度感知嵌入和聚类算法来计算图像出现的可能性，然后使用这些可能性来减轻数据不均衡的影响。另外，提出了一种新的$\textbf{普适吸引损失函数}$来调整训练过程中的样本权重。</li>
<li>results: 实验表明，该方法可以提高3D物体检测方法的性能，特别是对于少见的类别（自行车手）在KITTI数据集上的AP效果提高了超过200%。这些结果表明该方法是通用的，可以补充现有的技术，并在小数据集和少见的类别上特别有效。<details>
<summary>Abstract</summary>
Data imbalance is a well-known issue in the field of machine learning, attributable to the cost of data collection, the difficulty of labeling, and the geographical distribution of the data. In computer vision, bias in data distribution caused by image appearance remains highly unexplored. Compared to categorical distributions using class labels, image appearance reveals complex relationships between objects beyond what class labels provide. Clustering deep perceptual features extracted from raw pixels gives a richer representation of the data. This paper presents a novel method for addressing data imbalance in machine learning. The method computes sample likelihoods based on image appearance using deep perceptual embeddings and clustering. It then uses these likelihoods to weigh samples differently during training with a proposed $\textbf{Generalized Focal Loss}$ function. This loss can be easily integrated with deep learning algorithms. Experiments validate the method's effectiveness across autonomous driving vision datasets including KITTI and nuScenes. The loss function improves state-of-the-art 3D object detection methods, achieving over $200\%$ AP gains on under-represented classes (Cyclist) in the KITTI dataset. The results demonstrate the method is generalizable, complements existing techniques, and is particularly beneficial for smaller datasets and rare classes. Code is available at: https://github.com/towardsautonomy/DatasetEquity
</details>
<details>
<summary>摘要</summary>
“数据不均衡是机器学习领域的一个常见问题，这主要归结于数据收集成本、标签难度和数据的地域分布。在计算机视觉领域，图像外观的偏见对数据分布仍然具有很大的潜在探索空间。相比于使用类别分布的类标签，图像外观表现出了更复杂的对象之间的关系。使用深度感知特征提取自原始像素的归一化可以提供更丰富的数据表示。本文提出了一种 novel 的数据不均衡解决方案，该方法通过使用深度感知嵌入和归一化计算样本概率。然后使用这些概率对样本进行不同权重训练，使用我们提议的 $\textbf{通用强化损失}$ 函数。这种损失函数可以轻松地与深度学习算法结合使用。实验证明了该方法的有效性，在 KITTI 和 nuScenes 自动驾驶视觉数据集上实现了超过 200% AP 提升的 Results 表明该方法是通用的，可以补偿现有技术，特别有利于小型数据集和罕见类。代码可以在 GitHub 上找到：https://github.com/towardsautonomy/DatasetEquity。”Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other countries. If you need Traditional Chinese, please let me know and I'll be happy to provide it.
</details></li>
</ul>
<hr>
<h2 id="A-Theory-of-Topological-Derivatives-for-Inverse-Rendering-of-Geometry"><a href="#A-Theory-of-Topological-Derivatives-for-Inverse-Rendering-of-Geometry" class="headerlink" title="A Theory of Topological Derivatives for Inverse Rendering of Geometry"></a>A Theory of Topological Derivatives for Inverse Rendering of Geometry</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09865">http://arxiv.org/abs/2308.09865</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ishit Mehta, Manmohan Chandraker, Ravi Ramamoorthi</li>
<li>for: 这篇论文旨在提出一种可微 differentiable 表面演化理论，以便通过变分函数优化图像函数。</li>
<li>methods: 该理论使用 topological derivatives 来实现不同的拓扑结构变化，而不是先前的 silhouette gradients。</li>
<li>results: 该理论可以实现可微的形态异常，包括孔子核生成和相位异常。这些结果可以用于改进图像向量化、vector-graphics生成、单图像重建形意agram和多视图3D重建等应用。<details>
<summary>Abstract</summary>
We introduce a theoretical framework for differentiable surface evolution that allows discrete topology changes through the use of topological derivatives for variational optimization of image functionals. While prior methods for inverse rendering of geometry rely on silhouette gradients for topology changes, such signals are sparse. In contrast, our theory derives topological derivatives that relate the introduction of vanishing holes and phases to changes in image intensity. As a result, we enable differentiable shape perturbations in the form of hole or phase nucleation. We validate the proposed theory with optimization of closed curves in 2D and surfaces in 3D to lend insights into limitations of current methods and enable improved applications such as image vectorization, vector-graphics generation from text prompts, single-image reconstruction of shape ambigrams and multi-view 3D reconstruction.
</details>
<details>
<summary>摘要</summary>
我们提出了一种可 diferenciable 表面演化理论，允许离散topology变化通过使用图像函数的topological导数进行variational优化。而以前的对geometry inverse rendering方法依赖于silhouette导数进行topology变化，这些信号是稀疏的。相比之下，我们的理论 derivates topological导数，将引入vanishing holes和阶段相关到图像强度的变化。因此，我们可以实现可微形状变化，包括孔悉散和阶段悉散。我们验证了提出的理论，通过在2D和3D中优化closed curves和surfaces来增加应用，如图像vectorization、vector-graphics生成from文本提示、单个图像重建shape ambigrams和多视图3D重建。
</details></li>
</ul>
<hr>
<h2 id="Microscopy-Image-Segmentation-via-Point-and-Shape-Regularized-Data-Synthesis"><a href="#Microscopy-Image-Segmentation-via-Point-and-Shape-Regularized-Data-Synthesis" class="headerlink" title="Microscopy Image Segmentation via Point and Shape Regularized Data Synthesis"></a>Microscopy Image Segmentation via Point and Shape Regularized Data Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09835">http://arxiv.org/abs/2308.09835</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shijie Li, Mengwei Ren, Thomas Ach, Guido Gerig</li>
<li>for: 这篇论文主要针对微scopic图像分类问题提出了一个新的方法，它可以使用简单的点标注来进行训练，而不需要大量的实际标注数据。</li>
<li>methods: 这篇论文提出了一个三阶段的框架，包括：1）将点标注转换为伪稠密分类面组件，并受限于物体形状假设；2）使用对称的图像生成模型，将伪稠密分类面组件转换为真实的微scopic图像；3）使用伪稠密分类面组件和生成的图像，进行训练专门的分类模型。</li>
<li>results: 这篇论文的实验结果显示，使用这个新的方法可以在公共的 MoNuSeg 数据集上生成更多的多标的图像，并且保持高度的标注与生成图像之间的协调性。此外，这个方法可以与使用pseudo-labels或基准生成的图像进行比较，实现更高的分类精度。<details>
<summary>Abstract</summary>
Current deep learning-based approaches for the segmentation of microscopy images heavily rely on large amount of training data with dense annotation, which is highly costly and laborious in practice. Compared to full annotation where the complete contour of objects is depicted, point annotations, specifically object centroids, are much easier to acquire and still provide crucial information about the objects for subsequent segmentation. In this paper, we assume access to point annotations only during training and develop a unified pipeline for microscopy image segmentation using synthetically generated training data. Our framework includes three stages: (1) it takes point annotations and samples a pseudo dense segmentation mask constrained with shape priors; (2) with an image generative model trained in an unpaired manner, it translates the mask to a realistic microscopy image regularized by object level consistency; (3) the pseudo masks along with the synthetic images then constitute a pairwise dataset for training an ad-hoc segmentation model. On the public MoNuSeg dataset, our synthesis pipeline produces more diverse and realistic images than baseline models while maintaining high coherence between input masks and generated images. When using the identical segmentation backbones, the models trained on our synthetic dataset significantly outperform those trained with pseudo-labels or baseline-generated images. Moreover, our framework achieves comparable results to models trained on authentic microscopy images with dense labels, demonstrating its potential as a reliable and highly efficient alternative to labor-intensive manual pixel-wise annotations in microscopy image segmentation. The code is available.
</details>
<details>
<summary>摘要</summary>
当前的深度学习基于方法 для微scopic影像分割强调大量的训练数据，包括密集的标注。在实际应用中，这种标注是非常成本高昂和劳动密集的。相比拥有完整的标注，其中包含对象的完整边界，点标注更加容易获得，并且仍然提供了对对象的重要信息。在这篇论文中，我们假设在训练时有点标注可用。我们提出了一个简化的框架，包括以下三个阶段：1. 使用点标注，生成一个 Pseudo density 分割面，受限于形态约束。2. 使用一种没有对应关系的图像生成模型，将分割面翻译成一个真实的微scopic影像，并对其进行对象水平的准确性补做。3. 使用生成的 Pseudo 分割面和实际图像组成一个对应的数据集，用于训练适应性强的分割模型。在公共的 MoNuSeg 数据集上，我们的生成框架生成了更加多样化和真实的图像，同时保持了输入权重的高准确性。当使用同一个分割后端时，我们在我们的生成数据集上训练的模型比使用 pseudo-标签 或基eline-生成的图像训练得更好。此外，我们的框架可以与密集标注的模型相比，在微scopic影像分割任务中达到相同的性能水平。代码可以获得。
</details></li>
</ul>
<hr>
<h2 id="Cross-modality-Attention-based-Multimodal-Fusion-for-Non-small-Cell-Lung-Cancer-NSCLC-Patient-Survival-Prediction"><a href="#Cross-modality-Attention-based-Multimodal-Fusion-for-Non-small-Cell-Lung-Cancer-NSCLC-Patient-Survival-Prediction" class="headerlink" title="Cross-modality Attention-based Multimodal Fusion for Non-small Cell Lung Cancer (NSCLC) Patient Survival Prediction"></a>Cross-modality Attention-based Multimodal Fusion for Non-small Cell Lung Cancer (NSCLC) Patient Survival Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09831">http://arxiv.org/abs/2308.09831</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruining Deng, Nazim Shaikh, Gareth Shannon, Yao Nie</li>
<li>for: 预测非小细胞肺癌患者存活result, 即computer-aided diagnosis和prognosis在医学应用中的提高。</li>
<li>methods: 跨模态注意力基本的多模态融合管道，该方法不仅将不同模式的特征简单 concatenate或sum，而是通过跨模态关系 gauges each modality’s importance for feature fusion。</li>
<li>results: 在实验中，提议的融合方法在NSCLC患者存活预测中实现了c-index 0.6587，较单模式（使用 solely tissue image data或RNA-seq data）的c-index 0.5772和0.5885高出2.3%和1.6%。<details>
<summary>Abstract</summary>
Cancer prognosis and survival outcome predictions are crucial for therapeutic response estimation and for stratifying patients into various treatment groups. Medical domains concerned with cancer prognosis are abundant with multiple modalities, including pathological image data and non-image data such as genomic information. To date, multimodal learning has shown potential to enhance clinical prediction model performance by extracting and aggregating information from different modalities of the same subject. This approach could outperform single modality learning, thus improving computer-aided diagnosis and prognosis in numerous medical applications. In this work, we propose a cross-modality attention-based multimodal fusion pipeline designed to integrate modality-specific knowledge for patient survival prediction in non-small cell lung cancer (NSCLC). Instead of merely concatenating or summing up the features from different modalities, our method gauges the importance of each modality for feature fusion with cross-modality relationship when infusing the multimodal features. Compared with single modality, which achieved c-index of 0.5772 and 0.5885 using solely tissue image data or RNA-seq data, respectively, the proposed fusion approach achieved c-index 0.6587 in our experiment, showcasing the capability of assimilating modality-specific knowledge from varied modalities.
</details>
<details>
<summary>摘要</summary>
cancer 诊断和生存结果预测是临床应用中的关键任务，可以用于评估治疗效果和将患者分配到不同的治疗组。医疗领域中关于 cancer 诊断的数据非常丰富，包括生物pathological 图像数据和非图像数据，如基因信息。迄今为止，多Modal learning 已经展现出能够提高诊断模型性能，通过抽取和汇集不同模式的信息来提高计算机助成诊断和预测的能力。在这个工作中，我们提议一种跨模式关注机制的多模式融合管道，用于将不同模式的特征融合，以提高患者存活预测的准确性。相比单模式学习，我们的方法可以评估不同模式之间的关系，从而更好地汇集模式特征。在我们的实验中，我们的方法实现了c-index 0.6587，比单模式学习的c-index 0.5772和0.5885更高，这显示了我们的方法可以充分利用不同模式之间的关系，以提高诊断和预测的准确性。
</details></li>
</ul>
<hr>
<h2 id="EAVL-Explicitly-Align-Vision-and-Language-for-Referring-Image-Segmentation"><a href="#EAVL-Explicitly-Align-Vision-and-Language-for-Referring-Image-Segmentation" class="headerlink" title="EAVL: Explicitly Align Vision and Language for Referring Image Segmentation"></a>EAVL: Explicitly Align Vision and Language for Referring Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09779">http://arxiv.org/abs/2308.09779</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yichen Yan, Xingjian He, Wenxuan Wang, Sihan Chen, Jing Liu</li>
<li>for: This paper is written for the task of image segmentation using natural language references.</li>
<li>methods: The paper proposes a new method called Explicitly Align the Vision and Language for Referring Image Segmentation (EAVL), which explicitly aligns vision and language features in the segmentation stage using a series of unfixed convolution kernels generated based on the input language expression.</li>
<li>results: The paper achieves state-of-the-art performance on three benchmark datasets (RefCOCO, RefCOCO+, and G-Ref) by effectively fusing vision and language features and exploiting their potential in the segmentation stage, while also achieving language-related localization.<details>
<summary>Abstract</summary>
Referring image segmentation aims to segment an object mentioned in natural language from an image. A main challenge is language-related localization, which means locating the object with the relevant language. Previous approaches mainly focus on the fusion of vision and language features without fully addressing language-related localization. In previous approaches, fused vision-language features are directly fed into a decoder and pass through a convolution with a fixed kernel to obtain the result, which follows a similar pattern as traditional image segmentation. This approach does not explicitly align language and vision features in the segmentation stage, resulting in a suboptimal language-related localization. Different from previous methods, we propose Explicitly Align the Vision and Language for Referring Image Segmentation (EAVL). Instead of using a fixed convolution kernel, we propose an Aligner which explicitly aligns the vision and language features in the segmentation stage. Specifically, a series of unfixed convolution kernels are generated based on the input l, and then are use to explicitly align the vision and language features. To achieve this, We generate multiple queries that represent different emphases of the language expression. These queries are transformed into a series of query-based convolution kernels. Then, we utilize these kernels to do convolutions in the segmentation stage and obtain a series of segmentation masks. The final result is obtained through the aggregation of all masks. Our method can not only fuse vision and language features effectively but also exploit their potential in the segmentation stage. And most importantly, we explicitly align language features of different emphases with the image features to achieve language-related localization. Our method surpasses previous state-of-the-art methods on RefCOCO, RefCOCO+, and G-Ref by large margins.
</details>
<details>
<summary>摘要</summary>
Traditional image segmentation methods mainly focus on fusing vision and language features without fully addressing the challenge of language-related localization. Previous approaches typically use a fixed convolution kernel to fuse the features, which does not explicitly align the language and vision features in the segmentation stage, leading to suboptimal localization.In this paper, we propose a novel method called Explicitly Align the Vision and Language for Referring Image Segmentation (EAVL). Our approach uses an Aligner to explicitly align the vision and language features in the segmentation stage, rather than using a fixed convolution kernel. We generate multiple queries that represent different emphases of the language expression and transform them into a series of query-based convolution kernels. These kernels are then used to do convolutions in the segmentation stage, resulting in a series of segmentation masks. The final result is obtained through the aggregation of all masks.Our method not only effectively fuses vision and language features but also exploits their potential in the segmentation stage. Moreover, we explicitly align language features of different emphases with the image features, achieving language-related localization. Our method outperforms previous state-of-the-art methods on RefCOCO, RefCOCO+, and G-Ref by large margins.
</details></li>
</ul>
<hr>
<h2 id="Long-range-Multimodal-Pretraining-for-Movie-Understanding"><a href="#Long-range-Multimodal-Pretraining-for-Movie-Understanding" class="headerlink" title="Long-range Multimodal Pretraining for Movie Understanding"></a>Long-range Multimodal Pretraining for Movie Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09775">http://arxiv.org/abs/2308.09775</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dawitmureja/LMP">https://github.com/dawitmureja/LMP</a></li>
<li>paper_authors: Dawit Mureja Argaw, Joon-Young Lee, Markus Woodson, In So Kweon, Fabian Caba Heilbron</li>
<li>for: 这个论文的目的是提出一种基于电影数据的多模态预训练策略，以便在电影理解任务中实现更好的表现。</li>
<li>methods: 这个论文使用了长距离多模态预训练策略，通过观察和提取电影中各种modalities之间的关系，从而学习多模态和交叉模态编码器。</li>
<li>results: 这个论文在LVU测试集上进行了缺失学习和模型选择研究，并证明了其在多个benchmark任务上的传送性。其中，模型在LVU任务上达到了状态略于前者，并且在五个不同的benchmark任务中设置了新的状态略。<details>
<summary>Abstract</summary>
Learning computer vision models from (and for) movies has a long-standing history. While great progress has been attained, there is still a need for a pretrained multimodal model that can perform well in the ever-growing set of movie understanding tasks the community has been establishing. In this work, we introduce Long-range Multimodal Pretraining, a strategy, and a model that leverages movie data to train transferable multimodal and cross-modal encoders. Our key idea is to learn from all modalities in a movie by observing and extracting relationships over a long-range. After pretraining, we run ablation studies on the LVU benchmark and validate our modeling choices and the importance of learning from long-range time spans. Our model achieves state-of-the-art on several LVU tasks while being much more data efficient than previous works. Finally, we evaluate our model's transferability by setting a new state-of-the-art in five different benchmarks.
</details>
<details>
<summary>摘要</summary>
学习电影中的计算机视觉模型有很长的历史。虽然已经取得了很大的进步，但还有一些需求，例如需要一个预训练的多modal模型，可以在电影理解任务中表现出色。在这项工作中，我们介绍了远程多modal预训练策略和模型，该模型利用电影数据来训练可转移的多modal和跨modal编码器。我们的关键思想是从电影中所有modalities中学习和提取关系，并且在远程时间范围内做出关系。在预训练后，我们进行了ablation研究， validate我们的模型设计和学习长时间范围的重要性。我们的模型在LVU标准准则上实现了多个任务的state-of-the-art，并且比前一些工作更加数据效率。最后，我们测试了我们的模型的传输性，并在五个不同的标准准则上设置了新的state-of-the-art。
</details></li>
</ul>
<hr>
<h2 id="Towards-Large-scale-3D-Representation-Learning-with-Multi-dataset-Point-Prompt-Training"><a href="#Towards-Large-scale-3D-Representation-Learning-with-Multi-dataset-Point-Prompt-Training" class="headerlink" title="Towards Large-scale 3D Representation Learning with Multi-dataset Point Prompt Training"></a>Towards Large-scale 3D Representation Learning with Multi-dataset Point Prompt Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09718">http://arxiv.org/abs/2308.09718</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Pointcept/Pointcept">https://github.com/Pointcept/Pointcept</a></li>
<li>paper_authors: Xiaoyang Wu, Zhuotao Tian, Xin Wen, Bohao Peng, Xihui Liu, Kaicheng Yu, Hengshuang Zhao</li>
<li>for: 提高3D深度学习模型的性能和通用性，即使只使用有限的大规模3D数据。</li>
<li>methods: 提出Point Prompt Training（PPT）框架，支持多种预训练方法，包括Prompt-driven Normalization和Language-guided Categorical Alignment等技术。</li>
<li>results: 经验表明，PPT可以缓解多 dataset 学习中的负转移现象，并生成高质量的表示。在多种不同的3D下世界任务上，PPT在单个模型下实现了最佳性能，并在多种预训练方法中占据了主导地位。<details>
<summary>Abstract</summary>
The rapid advancement of deep learning models often attributes to their ability to leverage massive training data. In contrast, such privilege has not yet fully benefited 3D deep learning, mainly due to the limited availability of large-scale 3D datasets. Merging multiple available data sources and letting them collaboratively train a single model is a potential solution. However, due to the large domain gap between 3D point cloud datasets, such mixed supervision could adversely affect the model's performance and lead to degenerated performance (i.e., negative transfer) compared to single-dataset training. In view of this challenge, we introduce Point Prompt Training (PPT), a novel framework for multi-dataset synergistic learning in the context of 3D representation learning that supports multiple pre-training paradigms. Based on this framework, we propose Prompt-driven Normalization, which adapts the model to different datasets with domain-specific prompts and Language-guided Categorical Alignment that decently unifies the multiple-dataset label spaces by leveraging the relationship between label text. Extensive experiments verify that PPT can overcome the negative transfer associated with synergistic learning and produce generalizable representations. Notably, it achieves state-of-the-art performance on each dataset using a single weight-shared model with supervised multi-dataset training. Moreover, when served as a pre-training framework, it outperforms other pre-training approaches regarding representation quality and attains remarkable state-of-the-art performance across over ten diverse downstream tasks spanning both indoor and outdoor 3D scenarios.
</details>
<details>
<summary>摘要</summary>
“深度学习模型的快速进步 frequently 归功于它们可以利用大量的训练数据。然而，三维深度学习尚未得到完全的利益，主要是因为三维数据集的有限性。将多个可用的数据源合并并让它们共同训练单个模型是一个可能的解决方案。然而，由于三维点云数据集之间的域 gap 较大，这种混合超vision 可能会对模型的性能产生负面影响（即负向传播），而不是单 dataset 训练。为此，我们介绍 Point Prompt Training（PPT），一种多数据集协同学习框架，支持多种预训练方法。基于这个框架，我们提出 Prompt-driven Normalization，使模型适应不同数据集的域特定提示，并Language-guided Categorical Alignment，通过利用标签文本之间的关系，有效地统一多个数据集的标签空间。广泛的实验表明，PPT 可以超越负向传播，生成普适的表示。其中，使用单个权重共享模型进行多数据集超vised 训练，可以达到每个数据集的最优性能。此外，作为预训练框架，PPT 比其他预训练方法在表示质量和下游任务中表现出色，在室内和室外的多种3D场景中具有惊人的状态 искусternal 表现。”
</details></li>
</ul>
<hr>
<h2 id="Smoothness-Similarity-Regularization-for-Few-Shot-GAN-Adaptation"><a href="#Smoothness-Similarity-Regularization-for-Few-Shot-GAN-Adaptation" class="headerlink" title="Smoothness Similarity Regularization for Few-Shot GAN Adaptation"></a>Smoothness Similarity Regularization for Few-Shot GAN Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09717">http://arxiv.org/abs/2308.09717</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vadim Sushko, Ruyu Wang, Juergen Gall</li>
<li>for: 这个研究的目的是提高几张训练图像下的GAN适应率，并且可以处理两个不同结构的资料集。</li>
<li>methods: 这个研究提出了一个新的平滑相似性规范，用于将预训练的GAN模型转换到几张训练图像的目标领域，即使两个领域的物件结构很不同。</li>
<li>results: 这个研究的结果显示，在两个不同结构的资料集中，这个新的平滑相似性规范可以将预训练的GAN模型转换到几张训练图像的目标领域，并且与预训练的GAN模型相比，可以提高适应率。<details>
<summary>Abstract</summary>
The task of few-shot GAN adaptation aims to adapt a pre-trained GAN model to a small dataset with very few training images. While existing methods perform well when the dataset for pre-training is structurally similar to the target dataset, the approaches suffer from training instabilities or memorization issues when the objects in the two domains have a very different structure. To mitigate this limitation, we propose a new smoothness similarity regularization that transfers the inherently learned smoothness of the pre-trained GAN to the few-shot target domain even if the two domains are very different. We evaluate our approach by adapting an unconditional and a class-conditional GAN to diverse few-shot target domains. Our proposed method significantly outperforms prior few-shot GAN adaptation methods in the challenging case of structurally dissimilar source-target domains, while performing on par with the state of the art for similar source-target domains.
</details>
<details>
<summary>摘要</summary>
文本：几张图像ew-shot GAN适应的任务是使得预训练GAN模型适应一个具有非常少的训练图像的小数据集。现有的方法在预训练数据集和目标数据集的结构相似时表现良好，但是这些方法在物体在两个领域中具有非常不同的结构时受训练不稳定或记忆问题的影响。为了解决这些限制，我们提出了一种新的平滑相似性规范，将预训练GAN中内在学习的平滑性传递到几张图像目标领域，即使两个领域具有非常不同的结构。我们通过对无条件GAN和类别GAN进行适应，评估了我们的方法。我们的提议方法在预训练和目标领域结构不相似的情况下显著超过先前的几张图像GAN适应方法，并在相似的预训练和目标领域情况下与状态的艺术相当。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-3D-Gaussians-Tracking-by-Persistent-Dynamic-View-Synthesis"><a href="#Dynamic-3D-Gaussians-Tracking-by-Persistent-Dynamic-View-Synthesis" class="headerlink" title="Dynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis"></a>Dynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09713">http://arxiv.org/abs/2308.09713</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonathon Luiten, Georgios Kopanas, Bastian Leibe, Deva Ramanan</li>
<li>for: 该 paper 旨在同时解决动态场景新视图合成和六自由度（6-DOF）跟踪所有紧凑场景元素的问题。</li>
<li>methods: 作者采用了分析合成框架， Drawing inspiration from recent work that models scenes as a collection of 3D Gaussians, which are optimized to reconstruct input images via differentiable rendering.</li>
<li>results: 作者实现了一种可以同时解决动态场景新视图合成和6-DOF跟踪的方法，并且不需要输入任何匹配或流体。这种方法可以自动捕捉和跟踪场景中的所有紧凑元素，包括场景的旋转。<details>
<summary>Abstract</summary>
We present a method that simultaneously addresses the tasks of dynamic scene novel-view synthesis and six degree-of-freedom (6-DOF) tracking of all dense scene elements. We follow an analysis-by-synthesis framework, inspired by recent work that models scenes as a collection of 3D Gaussians which are optimized to reconstruct input images via differentiable rendering. To model dynamic scenes, we allow Gaussians to move and rotate over time while enforcing that they have persistent color, opacity, and size. By regularizing Gaussians' motion and rotation with local-rigidity constraints, we show that our Dynamic 3D Gaussians correctly model the same area of physical space over time, including the rotation of that space. Dense 6-DOF tracking and dynamic reconstruction emerges naturally from persistent dynamic view synthesis, without requiring any correspondence or flow as input. We demonstrate a large number of downstream applications enabled by our representation, including first-person view synthesis, dynamic compositional scene synthesis, and 4D video editing.
</details>
<details>
<summary>摘要</summary>
我们提出了一种方法，同时解决动态场景新视角合成和所有精细场景元素的六度自由（6-DOF）跟踪问题。我们采用分析合成框架，受到最近的Scene模型研究的启发，将场景视为一个集合的3D Gaussian，通过可导渲染来重建输入图像。为模型动态场景，我们允许Gaussian在时间上移动和旋转，并且保持颜色、透明度和大小的 persistency。通过对Gaussian的运动和旋转进行地方刚性约束，我们证明了我们的动态3D Gaussian correctly模型了物理空间的同一个区域在时间上的变化，包括空间的旋转。基于持续动态视思操作，我们无需输入对应或流动，直接从持续动态视思渲染中获得精细6-DOF跟踪和动态重建。我们示出了大量的下游应用，包括首人视图合成、动态组合场景合成和4D视频编辑。
</details></li>
</ul>
<hr>
<h2 id="HumanLiff-Layer-wise-3D-Human-Generation-with-Diffusion-Model"><a href="#HumanLiff-Layer-wise-3D-Human-Generation-with-Diffusion-Model" class="headerlink" title="HumanLiff: Layer-wise 3D Human Generation with Diffusion Model"></a>HumanLiff: Layer-wise 3D Human Generation with Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09712">http://arxiv.org/abs/2308.09712</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shoukang Hu, Fangzhou Hong, Tao Hu, Liang Pan, Haiyi Mei, Weiye Xiao, Lei Yang, Ziwei Liu</li>
<li>for: 本研究旨在提出一种层 wise 3D 人体生成模型，即 HumanLiff，该模型可以具有高精度和控制性，并能够生成层 wise 3D 人体。</li>
<li>methods: HumanLiff 模型使用了 diffusion-based 3D 条件生成方法，首先生成 minimal-clothed 人体，然后逐层生成衣物。另外，为了提高 3D 生成的精度，该模型还提出了 tri-plane shift 操作和层 wise 特征融合方法。</li>
<li>results: 对于 SynBody 和 TightCap 两个层 wise 3D 人体数据集，HumanLiff 模型在层 wise 3D 人体生成方面表现出了显著的优异性，与现有的状态对比方法相比，它可以生成更精度和更控制性的 3D 人体。<details>
<summary>Abstract</summary>
3D human generation from 2D images has achieved remarkable progress through the synergistic utilization of neural rendering and generative models. Existing 3D human generative models mainly generate a clothed 3D human as an undetectable 3D model in a single pass, while rarely considering the layer-wise nature of a clothed human body, which often consists of the human body and various clothes such as underwear, outerwear, trousers, shoes, etc. In this work, we propose HumanLiff, the first layer-wise 3D human generative model with a unified diffusion process. Specifically, HumanLiff firstly generates minimal-clothed humans, represented by tri-plane features, in a canonical space, and then progressively generates clothes in a layer-wise manner. In this way, the 3D human generation is thus formulated as a sequence of diffusion-based 3D conditional generation. To reconstruct more fine-grained 3D humans with tri-plane representation, we propose a tri-plane shift operation that splits each tri-plane into three sub-planes and shifts these sub-planes to enable feature grid subdivision. To further enhance the controllability of 3D generation with 3D layered conditions, HumanLiff hierarchically fuses tri-plane features and 3D layered conditions to facilitate the 3D diffusion model learning. Extensive experiments on two layer-wise 3D human datasets, SynBody (synthetic) and TightCap (real-world), validate that HumanLiff significantly outperforms state-of-the-art methods in layer-wise 3D human generation. Our code will be available at https://skhu101.github.io/HumanLiff.
</details>
<details>
<summary>摘要</summary>
人体三维生成从二维图像中得到了惊人的进步，通过神经渲染和生成模型的共同使用。现有的三维人体生成模型主要生成一个穿着衣服的三维人体，而rarely考虑人体层次结构，人体通常由躯体和衣服组成，如内衣、外衣、裤子、鞋等。在这项工作中，我们提出了人类生命（HumanLiff），首先生成最小化穿着衣服的三维人体，用三个平面特征表示，然后逐层生成衣服。因此，三维人体生成被定义为一个序列的扩散基于三维条件的生成。为了重建更细腻的三维人体，我们提出了三个平面移动操作，将每个平面分成三个子平面，并将这些子平面移动以实现特征网格分解。此外，为了进一步提高三维生成的控制性，人类生命层次融合三个平面特征和三维层次条件，以便扩散模型学习。广泛的实验表明，人类生命在两个层次三维人体数据集（SynBody和TightCap）上显著超越了当前的状态艺术法。我们的代码将在https://skhu101.github.io/HumanLiff上公开。
</details></li>
</ul>
<hr>
<h2 id="Robust-Monocular-Depth-Estimation-under-Challenging-Conditions"><a href="#Robust-Monocular-Depth-Estimation-under-Challenging-Conditions" class="headerlink" title="Robust Monocular Depth Estimation under Challenging Conditions"></a>Robust Monocular Depth Estimation under Challenging Conditions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09711">http://arxiv.org/abs/2308.09711</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/md4all/md4all">https://github.com/md4all/md4all</a></li>
<li>paper_authors: Stefano Gasperini, Nils Morbitzer, HyunJun Jung, Nassir Navab, Federico Tombari</li>
<li>for: 提高单目深度估计的可靠性，特别是在不良环境和天气条件下。</li>
<li>methods: 利用现有方法的效果，生成复杂样本集，并通过自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自<details>
<summary>Abstract</summary>
While state-of-the-art monocular depth estimation approaches achieve impressive results in ideal settings, they are highly unreliable under challenging illumination and weather conditions, such as at nighttime or in the presence of rain. In this paper, we uncover these safety-critical issues and tackle them with md4all: a simple and effective solution that works reliably under both adverse and ideal conditions, as well as for different types of learning supervision. We achieve this by exploiting the efficacy of existing methods under perfect settings. Therefore, we provide valid training signals independently of what is in the input. First, we generate a set of complex samples corresponding to the normal training ones. Then, we train the model by guiding its self- or full-supervision by feeding the generated samples and computing the standard losses on the corresponding original images. Doing so enables a single model to recover information across diverse conditions without modifications at inference time. Extensive experiments on two challenging public datasets, namely nuScenes and Oxford RobotCar, demonstrate the effectiveness of our techniques, outperforming prior works by a large margin in both standard and challenging conditions. Source code and data are available at: https://md4all.github.io.
</details>
<details>
<summary>摘要</summary>
当前最先进的单目深度估计方法在理想的Setting下可以达到印象人的结果，但在具有挑战性的照明和天气条件下（如夜晚或雨天），它们的可靠性却非常低。在这篇论文中，我们揭示了这些安全关键问题，并使用md4all：一种简单而有效的解决方案，可靠地在不 идеаль的Setting下运行，并且可以处理不同类型的学习监督。我们通过利用现有方法在完美 Setting下的效果，来提供有效的训练信号，无论输入内容如何。首先，我们生成了一组复杂的样本，与常见的训练样本相对应。然后，我们使用这些生成的样本进行自我或全自监督，通过计算相应的原始图像上的标准损失来训练模型。这样做的好处是，一个模型可以在执行时不需要修改，就能够在多种Setting下恢复信息。我们在两个公共的挑战性数据集（即nuScenes和Oxford RobotCar）进行了广泛的实验，并证明了我们的技术的有效性，与先前的成果相比，在标准和挑战性的Setting下都有大幅度的提高。软件代码和数据可以在以下网址获取：https://md4all.github.io。
</details></li>
</ul>
<hr>
<h2 id="Training-with-Product-Digital-Twins-for-AutoRetail-Checkout"><a href="#Training-with-Product-Digital-Twins-for-AutoRetail-Checkout" class="headerlink" title="Training with Product Digital Twins for AutoRetail Checkout"></a>Training with Product Digital Twins for AutoRetail Checkout</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09708">http://arxiv.org/abs/2308.09708</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yorkeyao/automated-retail-checkout">https://github.com/yorkeyao/automated-retail-checkout</a></li>
<li>paper_authors: Yue Yao, Xinyu Tian, Zheng Tang, Sujit Biswas, Huan Lei, Tom Gedeon, Liang Zheng</li>
<li>for: 这 paper 的目的是为了自动化商业 checkout 过程，提高用户体验和效率。</li>
<li>methods: 该 paper 使用了产品 3D 模型，通过图形引擎渲染来生成快速、灵活、大规模的训练数据。它还提出了一种训练数据优化框架，通过使用产品 3D 模型来生成“数字双胞胎”，以增强训练数据的可靠性和效果。</li>
<li>results: 该 paper 的实验表明，使用“数字双胞胎”训练集可以提高产品检测和跟踪模型的准确率，并且可以与 Pseudo-labeled 的实际检查数据组合使用，进一步提高模型的性能。<details>
<summary>Abstract</summary>
Automating the checkout process is important in smart retail, where users effortlessly pass products by hand through a camera, triggering automatic product detection, tracking, and counting. In this emerging area, due to the lack of annotated training data, we introduce a dataset comprised of product 3D models, which allows for fast, flexible, and large-scale training data generation through graphic engine rendering. Within this context, we discern an intriguing facet, because of the user "hands-on" approach, bias in user behavior leads to distinct patterns in the real checkout process. The existence of such patterns would compromise training effectiveness if training data fail to reflect the same. To address this user bias problem, we propose a training data optimization framework, i.e., training with digital twins (DtTrain). Specifically, we leverage the product 3D models and optimize their rendering viewpoint and illumination to generate "digital twins" that visually resemble representative user images. These digital twins, inherit product labels and, when augmented, form the Digital Twin training set (DT set). Because the digital twins individually mimic user bias, the resulting DT training set better reflects the characteristics of the target scenario and allows us to train more effective product detection and tracking models. In our experiment, we show that DT set outperforms training sets created by existing dataset synthesis methods in terms of counting accuracy. Moreover, by combining DT set with pseudo-labeled real checkout data, further improvement is observed. The code is available at https://github.com/yorkeyao/Automated-Retail-Checkout.
</details>
<details>
<summary>摘要</summary>
自动化购物过程是智能零售中的重要方面，用户可以轻松地通过摄像头传输产品，触发自动产品检测、跟踪和计数。在这个emerging领域中，由于缺乏标注的训练数据，我们提出了一个包含产品3D模型的数据集，允许快速、灵活和大规模的训练数据生成。在这个上下文中，我们发现了一个有趣的特点，即由于用户“手动”的方式，用户的行为偏好会导致实际检查出 процесс中的差异。如果训练数据不能够反映这些差异， то这将对训练效果产生负面影响。为解决这个用户偏好问题，我们提出了一个训练数据优化框架，即使用数字双子（DtTrain）训练。具体来说，我们利用产品3D模型，并且优化它们的渲染视角和照明，以生成“数字双子”，这些数字双子 inherit 产品标签，并且当加以扩展时，组成了数字双子训练集（DT集）。由于数字双子具有用户偏好，DT集更好地反映了目标场景的特点，可以训练更有效的产品检测和跟踪模型。在我们的实验中，我们发现DT集比现有的数据集生成方法在计数准确性方面表现出色。此外，通过组合DT集和 Pseudo-labeled 实际检查数据，进一步提高了性能。代码可以在 <https://github.com/yorkeyao/Automated-Retail-Checkout> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Guide3D-Create-3D-Avatars-from-Text-and-Image-Guidance"><a href="#Guide3D-Create-3D-Avatars-from-Text-and-Image-Guidance" class="headerlink" title="Guide3D: Create 3D Avatars from Text and Image Guidance"></a>Guide3D: Create 3D Avatars from Text and Image Guidance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09705">http://arxiv.org/abs/2308.09705</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yukangcao/Guide3D">https://github.com/yukangcao/Guide3D</a></li>
<li>paper_authors: Yukang Cao, Yan-Pei Cao, Kai Han, Ying Shan, Kwan-Yee K. Wong</li>
<li>for: 本研究旨在开发一种高效的文本和图像引导的三维生成模型，用于生成高分辨率的纹理网格。</li>
<li>methods: 我们提出了一种基于扩散模型的零引入文本和图像引导生成模型，包括生成多视图图像并jointly优化多分辨率响应的抽象四角体网格。我们还提出了一种相似性意识的特征融合策略，以有效地集成不同视图的特征。</li>
<li>results: 我们的框架在生成三维 geometry和高分辨率纹理上达到了现状之最，并且可以直接将二维生成的图像传递到三维空间中。我们的代码将会公开发布。<details>
<summary>Abstract</summary>
Recently, text-to-image generation has exhibited remarkable advancements, with the ability to produce visually impressive results. In contrast, text-to-3D generation has not yet reached a comparable level of quality. Existing methods primarily rely on text-guided score distillation sampling (SDS), and they encounter difficulties in transferring 2D attributes of the generated images to 3D content. In this work, we aim to develop an effective 3D generative model capable of synthesizing high-resolution textured meshes by leveraging both textual and image information. To this end, we introduce Guide3D, a zero-shot text-and-image-guided generative model for 3D avatar generation based on diffusion models. Our model involves (1) generating sparse-view images of a text-consistent character using diffusion models, and (2) jointly optimizing multi-resolution differentiable marching tetrahedral grids with pixel-aligned image features. We further propose a similarity-aware feature fusion strategy for efficiently integrating features from different views. Moreover, we introduce two novel training objectives as an alternative to calculating SDS, significantly enhancing the optimization process. We thoroughly evaluate the performance and components of our framework, which outperforms the current state-of-the-art in producing topologically and structurally correct geometry and high-resolution textures. Guide3D enables the direct transfer of 2D-generated images to the 3D space. Our code will be made publicly available.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:最近，文本到图像生成技术已经做出了很大的进步，能够生成非常印象深刻的图像。相比之下，文本到3D生成技术还没有达到相同的水平。现有方法主要依靠文本指导分数散热抽取样本（SDS），但它们在将2D生成图像中的特征传递到3D内容上遇到了困难。在这个工作中，我们目标是开发一种高效的3D生成模型，能够通过文本和图像信息来生成高分辨率的纹理镜面。为此，我们提出了 Guide3D，一种基于扩散模型的零shot文本和图像引导的3D人物生成模型。我们的模型包括（1）通过扩散模型生成文本一致的人物各个视角的稀疏图像，以及（2）同时优化多resolution的可 diferentiable marching tetrahedral网格和像素对齐的图像特征。我们还提出了一种相似性意识的特征融合策略，以高效地将不同视角的特征集成。此外，我们引入了两种新的训练目标，作为SDS的代替方法，有助于优化过程。我们 thorougly评估了我们的框架的性能和组件，其表现超越当前状态的艺术，能够生成正确的 topology和结构，以及高分辨率的纹理。 Guide3D可以将2D生成的图像直接传递到3D空间。我们的代码将公开发布。
</details></li>
</ul>
<hr>
<h2 id="Invariant-Training-2D-3D-Joint-Hard-Samples-for-Few-Shot-Point-Cloud-Recognition"><a href="#Invariant-Training-2D-3D-Joint-Hard-Samples-for-Few-Shot-Point-Cloud-Recognition" class="headerlink" title="Invariant Training 2D-3D Joint Hard Samples for Few-Shot Point Cloud Recognition"></a>Invariant Training 2D-3D Joint Hard Samples for Few-Shot Point Cloud Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09694">http://arxiv.org/abs/2308.09694</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuanyu Yi, Jiajun Deng, Qianru Sun, Xian-Sheng Hua, Joo-Hwee Lim, Hanwang Zhang</li>
<li>for: 增强ew-shot点云识别任务中数据稀缺问题的解决方案，使用一个joint预测方法，即一个常见的3D模型和一个培养得非常好的2D模型。</li>
<li>methods: 使用一种新的 invariant 训练策略，称为InvJoint，不仅更强调训练’’joint困难样本’’，还寻找2D和3D模型之间的相互关系。</li>
<li>results: 对ModelNet10&#x2F;40、ScanObjectNN和Toys4K等三个领域进行了广泛的实验，证明了InvJoint可以学习更好的2D和3D表示，从而提高 ensemble 的性能。<details>
<summary>Abstract</summary>
We tackle the data scarcity challenge in few-shot point cloud recognition of 3D objects by using a joint prediction from a conventional 3D model and a well-trained 2D model. Surprisingly, such an ensemble, though seems trivial, has hardly been shown effective in recent 2D-3D models. We find out the crux is the less effective training for the ''joint hard samples'', which have high confidence prediction on different wrong labels, implying that the 2D and 3D models do not collaborate well. To this end, our proposed invariant training strategy, called InvJoint, does not only emphasize the training more on the hard samples, but also seeks the invariance between the conflicting 2D and 3D ambiguous predictions. InvJoint can learn more collaborative 2D and 3D representations for better ensemble. Extensive experiments on 3D shape classification with widely adopted ModelNet10/40, ScanObjectNN and Toys4K, and shape retrieval with ShapeNet-Core validate the superiority of our InvJoint.
</details>
<details>
<summary>摘要</summary>
我们解决了很少样本点云识别三维物体中的数据缺乏挑战，通过使用一个 conjunction 的预测，来 combinational 一个常见的三维模型和一个已经训练好的二维模型。尽管这种ensemble 看起来很简单，但它在最近的二维-三维模型中几乎没有被研究过。我们发现，问题的关键在于“联合困难样本”的训练不够有效，这些样本有高信心地预测不同的错误标签，表明二维和三维模型之间没有协作良好。为此，我们提出了一种不变训练策略，即 InvJoint，不仅更多地训练“联合困难样本”，而且寻求这些样本之间的不变性。InvJoint 能够学习更好地协作的二维和三维表示，从而提高ensemble的性能。我们在广泛采用的 ModelNet10/40、ScanObjectNN 和 Toys4K 等三维形状分类和 ShapeNet-Core 等形状检索任务上进行了广泛的实验，并证明了 InvJoint 的超越性。
</details></li>
</ul>
<hr>
<h2 id="A-Lightweight-Transformer-for-Faster-and-Robust-EBSD-Data-Collection"><a href="#A-Lightweight-Transformer-for-Faster-and-Robust-EBSD-Data-Collection" class="headerlink" title="A Lightweight Transformer for Faster and Robust EBSD Data Collection"></a>A Lightweight Transformer for Faster and Robust EBSD Data Collection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09693">http://arxiv.org/abs/2308.09693</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hdong920/ebsd_slice_recovery">https://github.com/hdong920/ebsd_slice_recovery</a></li>
<li>paper_authors: Harry Dong, Sean Donegan, Megna Shah, Yuejie Chi</li>
<li>for: 提高3D EBSD数据质量和收集效率</li>
<li>methods: 使用变换器模型和投影算法进行数据处理和恢复</li>
<li>results: 使用自我超视觉学习和 Synthetic 3D EBSD数据进行训练，在实际3D EBSD数据上获得更高的恢复精度 compared to 现有方法<details>
<summary>Abstract</summary>
Three dimensional electron back-scattered diffraction (EBSD) microscopy is a critical tool in many applications in materials science, yet its data quality can fluctuate greatly during the arduous collection process, particularly via serial-sectioning. Fortunately, 3D EBSD data is inherently sequential, opening up the opportunity to use transformers, state-of-the-art deep learning architectures that have made breakthroughs in a plethora of domains, for data processing and recovery. To be more robust to errors and accelerate this 3D EBSD data collection, we introduce a two step method that recovers missing slices in an 3D EBSD volume, using an efficient transformer model and a projection algorithm to process the transformer's outputs. Overcoming the computational and practical hurdles of deep learning with scarce high dimensional data, we train this model using only synthetic 3D EBSD data with self-supervision and obtain superior recovery accuracy on real 3D EBSD data, compared to existing methods.
</details>
<details>
<summary>摘要</summary>
三维电子反射干扰diffraction（EBSD）镜像是物理科学中多种应用的重要工具，但其数据质量可能会在收集过程中出现大幅波动，特别是通过串行sectioning。幸运的是，3D EBSD数据是串行的，这开 up了使用 transformers，当前领域的最先进深度学习架构，进行数据处理和恢复的机会。为了更加鲁棒地处理错误和加速3D EBSD数据收集，我们介绍了一种两步方法，使用高效的 transformer 模型和投影算法来处理 transformer 的输出。通过对深度学习的计算和实践障碍而不是高维数据，我们使用只有自我超vision的 Synthetic 3D EBSD 数据进行训练，并在实际3D EBSD数据上获得了比现有方法更高的恢复精度。
</details></li>
</ul>
<hr>
<h2 id="Audiovisual-Moments-in-Time-A-Large-Scale-Annotated-Dataset-of-Audiovisual-Actions"><a href="#Audiovisual-Moments-in-Time-A-Large-Scale-Annotated-Dataset-of-Audiovisual-Actions" class="headerlink" title="Audiovisual Moments in Time: A Large-Scale Annotated Dataset of Audiovisual Actions"></a>Audiovisual Moments in Time: A Large-Scale Annotated Dataset of Audiovisual Actions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09685">http://arxiv.org/abs/2308.09685</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mjoannou/audiovisual-moments-in-time">https://github.com/mjoannou/audiovisual-moments-in-time</a></li>
<li>paper_authors: Michael Joannou, Pia Rotshtein, Uta Noppeney</li>
<li>for: 这个论文主要是为了提供一个大规模的audiovisual动作事件数据集（AVMIT），以便用于计算机模型和人类参与者之间的研究。</li>
<li>methods: 这篇论文使用了一个大规模的注释任务，采集了3秒的audiovisual视频，并由11名参与者进行了分类。每个试验都需要参与者确定 audiovisual动作事件是否存在，以及这个事件是否是视频中最显著的特征。</li>
<li>results: 论文表明，使用AVMIT注释数据集可以提高audiovisual事件认识性能，特别是在 audiovisual对应性是关键的研究问题上。在6个回归神经网络（RNN）中，通过专门在audiovisual事件上进行训练，可以提高测试集的准确率，而不是使用模式性无关的事件。<details>
<summary>Abstract</summary>
We present Audiovisual Moments in Time (AVMIT), a large-scale dataset of audiovisual action events. In an extensive annotation task 11 participants labelled a subset of 3-second audiovisual videos from the Moments in Time dataset (MIT). For each trial, participants assessed whether the labelled audiovisual action event was present and whether it was the most prominent feature of the video. The dataset includes the annotation of 57,177 audiovisual videos, each independently evaluated by 3 of 11 trained participants. From this initial collection, we created a curated test set of 16 distinct action classes, with 60 videos each (960 videos). We also offer 2 sets of pre-computed audiovisual feature embeddings, using VGGish/YamNet for audio data and VGG16/EfficientNetB0 for visual data, thereby lowering the barrier to entry for audiovisual DNN research. We explored the advantages of AVMIT annotations and feature embeddings to improve performance on audiovisual event recognition. A series of 6 Recurrent Neural Networks (RNNs) were trained on either AVMIT-filtered audiovisual events or modality-agnostic events from MIT, and then tested on our audiovisual test set. In all RNNs, top 1 accuracy was increased by 2.71-5.94\% by training exclusively on audiovisual events, even outweighing a three-fold increase in training data. We anticipate that the newly annotated AVMIT dataset will serve as a valuable resource for research and comparative experiments involving computational models and human participants, specifically when addressing research questions where audiovisual correspondence is of critical importance.
</details>
<details>
<summary>摘要</summary>
我们介绍Audiovisual Moments in Time（AVMIT）数据集，这是一个大规模的 audiovisual 动作事件数据集。在一项大规模的注释任务中，11名参与者对 Mit 数据集（Moments in Time）中的3秒audiovisual视频进行了注释。为每个试验，参与者判断 audiovisual 动作事件是否存在，以及它是视频中最出色的特征。该数据集包括57,177个 audiovisual 视频，每个视频都被3名训练参与者独立地评估。从这个初始集合中，我们创建了一个精心选择的测试集，包含16种不同的动作类别，每个类别有60个视频（共960个视频）。我们还提供了2个预计算的 audiovisual 特征嵌入，使用VGGish/YamNet для音频数据和VGG16/EfficientNetB0 для视频数据，从而降低了audiovisual DNN研究的门槛。我们explored AVMIT 注释和特征嵌入的优点，以提高audiovisual事件认识的性能。6个回归神经网络（RNNs）在AVMIT中过滤 audiovisual 事件或MIT中的模态无关事件，然后在我们的audiovisual测试集上进行测试。在所有RNNs中，在训练 exclusively 于 audiovisual 事件上，精度提高了2.71-5.94%，甚至超过了模态无关事件的三倍增长。我们预计，新注释的 AVMIT 数据集将成为研究计算模型和人类参与者之间的 valuable 资源，特别是在研究问题中，audiovisual 协调的重要性非常高。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/19/cs.CV_2023_08_19/" data-id="clohum97800gdpj885gk77die" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/50/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/49/">49</a><a class="page-number" href="/page/50/">50</a><span class="page-number current">51</span><a class="page-number" href="/page/52/">52</a><a class="page-number" href="/page/53/">53</a><span class="space">&hellip;</span><a class="page-number" href="/page/84/">84</a><a class="extend next" rel="next" href="/page/52/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">116</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">56</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">112</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">62</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
