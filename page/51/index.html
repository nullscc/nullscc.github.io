
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/51/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.SD_2023_08_19" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/19/cs.SD_2023_08_19/" class="article-date">
  <time datetime="2023-08-19T15:00:00.000Z" itemprop="datePublished">2023-08-19</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/19/cs.SD_2023_08_19/">cs.SD - 2023-08-19</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Spatial-Reconstructed-Local-Attention-Res2Net-with-F0-Subband-for-Fake-Speech-Detection"><a href="#Spatial-Reconstructed-Local-Attention-Res2Net-with-F0-Subband-for-Fake-Speech-Detection" class="headerlink" title="Spatial Reconstructed Local Attention Res2Net with F0 Subband for Fake Speech Detection"></a>Spatial Reconstructed Local Attention Res2Net with F0 Subband for Fake Speech Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09944">http://arxiv.org/abs/2308.09944</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cunhang Fan, Jun Xue, Jianhua Tao, Jiangyan Yi, Chenglong Wang, Chengshi Zheng, Zhao Lv<br>for: 本研究旨在提高假语音识别（FSD）任务的性能，特别是对于rhythm of synthetic speech too smooth的问题。methods: 本文提出了一种新的F0子带，以及一种具有spatial reconstructed local attention的Res2Net网络（SR-LA Res2Net）。results: 在ASVspoof 2019 LA数据集上，我们的提议方法实现了EER值为0.47%和min t-DCF值为0.0159，与所有单个系统中的最佳性能相当。<details>
<summary>Abstract</summary>
The rhythm of synthetic speech is usually too smooth, which causes that the fundamental frequency (F0) of synthetic speech is significantly different from that of real speech. It is expected that the F0 feature contains the discriminative information for the fake speech detection (FSD) task. In this paper, we propose a novel F0 subband for FSD. In addition, to effectively model the F0 subband so as to improve the performance of FSD, the spatial reconstructed local attention Res2Net (SR-LA Res2Net) is proposed. Specifically, Res2Net is used as a backbone network to obtain multiscale information, and enhanced with a spatial reconstruction mechanism to avoid losing important information when the channel group is constantly superimposed. In addition, local attention is designed to make the model focus on the local information of the F0 subband. Experimental results on the ASVspoof 2019 LA dataset show that our proposed method obtains an equal error rate (EER) of 0.47% and a minimum tandem detection cost function (min t-DCF) of 0.0159, achieving the state-of-the-art performance among all of the single systems.
</details>
<details>
<summary>摘要</summary>
文本中的人工语音的节奏通常太平滑，导致人工语音的基本频率（F0）与实际语音的F0有所不同。这些F0特征含有识别假语音的重要信息。在这篇论文中，我们提出了一种新的F0子带 для假语音检测（FSD）任务。此外，为了有效地模型F0子带，我们还提出了一种空间重建本地注意力Res2Net（SR-LA Res2Net）。具体来说，Res2Net被用作背景网络，以获取多尺度信息，并在核心矩阵上添加空间重建机制，以避免损失重要信息。此外，本地注意力被设计来使模型关注F0子带的本地信息。实验结果表明，我们提出的方法在ASVspoof 2019 LA数据集上达到了单个系统的状态略进行性表现，其EER为0.47%，min t-DCF为0.0159。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/19/cs.SD_2023_08_19/" data-id="clogyj90d00tj7crac1qa1yhl" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_19" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/19/cs.CV_2023_08_19/" class="article-date">
  <time datetime="2023-08-19T13:00:00.000Z" itemprop="datePublished">2023-08-19</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/19/cs.CV_2023_08_19/">cs.CV - 2023-08-19</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="DPL-Decoupled-Prompt-Learning-for-Vision-Language-Models"><a href="#DPL-Decoupled-Prompt-Learning-for-Vision-Language-Models" class="headerlink" title="DPL: Decoupled Prompt Learning for Vision-Language Models"></a>DPL: Decoupled Prompt Learning for Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10061">http://arxiv.org/abs/2308.10061</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Xu, Yuhan Zhu, Guozhen Zhang, Haocheng Shen, Yixuan Liao, Xiaoxin Chen, Gangshan Wu, Limin Wang</li>
<li>for: 本研究旨在提高CLIP模型的下游任务迁移效果，但现有方法通常会过拟合已经看过的类别， thereby limiting its generalization ability for unseen classes.</li>
<li>methods: 我们提出了一种新的方法，即分离提示学习（DPL），它通过重新定义提示学习的注意力进程来解决这个问题。 Specifically, we theoretically investigate the collaborative process between prompts and instances (i.e., image patches&#x2F;text tokens) by reformulating the original self-attention into four separate sub-processes.</li>
<li>results: 我们的方法可以在三个代表性的 benchmark 上取得状态机器的表现，包括15个图像识别数据集，而且不需要任何辅助正则化任务或额外训练数据，进一步表明了其惊人的泛化能力。<details>
<summary>Abstract</summary>
Prompt learning has emerged as an efficient and effective approach for transferring foundational Vision-Language Models (e.g., CLIP) to downstream tasks. However, current methods tend to overfit to seen categories, thereby limiting their generalization ability for unseen classes. In this paper, we propose a new method, Decoupled Prompt Learning (DPL), which reformulates the attention in prompt learning to alleviate this problem. Specifically, we theoretically investigate the collaborative process between prompts and instances (i.e., image patches/text tokens) by reformulating the original self-attention into four separate sub-processes. Through detailed analysis, we observe that certain sub-processes can be strengthened to bolster robustness and generalizability by some approximation techniques. Furthermore, we introduce language-conditioned textual prompting based on decoupled attention to naturally preserve the generalization of text input. Our approach is flexible for both visual and textual modalities, making it easily extendable to multi-modal prompt learning. By combining the proposed techniques, our approach achieves state-of-the-art performance on three representative benchmarks encompassing 15 image recognition datasets, while maintaining parameter-efficient. Moreover, our DPL does not rely on any auxiliary regularization task or extra training data, further demonstrating its remarkable generalization ability.
</details>
<details>
<summary>摘要</summary>
提高学习（Prompt Learning）已经成为跨类 Task 迁移Foundational Vision-Language Models（例如 CLIP）的有效和高效的方法。然而，现有方法往往会遇到seen类，从而限制其对未seen类的泛化能力。在这篇论文中，我们提出了一种新的方法：异步Prompt Learning（DPL），该方法通过重新推导提问的注意力来缓解这个问题。 Specifically，我们对提问和实例（即图像 patches/文本token）之间的协作过程进行了理论性的调查，并将原始自注意转化为四个独立的子过程。通过详细分析，我们发现了一些子过程可以通过一些抽象技巧加强，以提高抗衰假性和泛化能力。此外，我们引入了基于异步注意力的语言条件文本提问，以保持文本输入的泛化。我们的方法可以轻松扩展到多模态提问学习。通过结合我们的方法，我们的DPL实现了三个代表性的标准准则，包括15个图像识别数据集，而不需要额外的训练数据或auxiliary regularization任务，再次证明了它的强大泛化能力。
</details></li>
</ul>
<hr>
<h2 id="R-C-P-Method-An-Autonomous-Volume-Calculation-Method-Using-Image-Processing-and-Machine-Vision"><a href="#R-C-P-Method-An-Autonomous-Volume-Calculation-Method-Using-Image-Processing-and-Machine-Vision" class="headerlink" title="R-C-P Method: An Autonomous Volume Calculation Method Using Image Processing and Machine Vision"></a>R-C-P Method: An Autonomous Volume Calculation Method Using Image Processing and Machine Vision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10058">http://arxiv.org/abs/2308.10058</a></li>
<li>repo_url: None</li>
<li>paper_authors: MA Muktadir, Sydney Parker, Sun Yi</li>
<li>for: 这个论文的目的是提供一种基于多个2D相机的实时三维空间量化和变化信息获取方法，以取代深度摄像头。</li>
<li>methods: 该方法使用图像处理和边检测技术，开发了ROW-COLUMN-PIXEL（纵列像素）方法，可以实时测量物体的面积和变化。</li>
<li>results: 实验结果表明，ROW-COLUMN-PIXEL方法可以准确地测量物体的面积和变化，并且可以检测物体上的不连续边或体积。<details>
<summary>Abstract</summary>
Machine vision and image processing are often used with sensors for situation awareness in autonomous systems, from industrial robots to self-driving cars. The 3D depth sensors, such as LiDAR (Light Detection and Ranging), Radar, are great invention for autonomous systems. Due to the complexity of the setup, LiDAR may not be suitable for some operational environments, for example, a space environment. This study was motivated by a desire to get real-time volumetric and change information with multiple 2D cameras instead of a depth camera. Two cameras were used to measure the dimensions of a rectangular object in real-time. The R-C-P (row-column-pixel) method is developed using image processing and edge detection. In addition to the surface areas, the R-C-P method also detects discontinuous edges or volumes. Lastly, experimental work is presented for illustration of the R-C-P method, which provides the equations for calculating surface area dimensions. Using the equations with given distance information between the object and the camera, the vision system provides the dimensions of actual objects.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ControlCom-Controllable-Image-Composition-using-Diffusion-Model"><a href="#ControlCom-Controllable-Image-Composition-using-Diffusion-Model" class="headerlink" title="ControlCom: Controllable Image Composition using Diffusion Model"></a>ControlCom: Controllable Image Composition using Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10040">http://arxiv.org/abs/2308.10040</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bcmi/controlcom-image-composition">https://github.com/bcmi/controlcom-image-composition</a></li>
<li>paper_authors: Bo Zhang, Yuxuan Duan, Jun Lan, Yan Hong, Huijia Zhu, Weiqiang Wang, Li Niu</li>
<li>for: 本研究旨在实现一种可控的图像组合方法，能够生成真实、自然的组合图像。</li>
<li>methods: 本方法基于大型预训练的扩散模型，并实现了四个任务的混合：图像融合、图像和谐、视觉合成和生成组合。</li>
<li>results: 对于公共benchmark数据和实际数据，我们的方法可以生成更加忠诚和可控的组合图像，比现有方法更高效。<details>
<summary>Abstract</summary>
Image composition targets at synthesizing a realistic composite image from a pair of foreground and background images. Recently, generative composition methods are built on large pretrained diffusion models to generate composite images, considering their great potential in image generation. However, they suffer from lack of controllability on foreground attributes and poor preservation of foreground identity. To address these challenges, we propose a controllable image composition method that unifies four tasks in one diffusion model: image blending, image harmonization, view synthesis, and generative composition. Meanwhile, we design a self-supervised training framework coupled with a tailored pipeline of training data preparation. Moreover, we propose a local enhancement module to enhance the foreground details in the diffusion model, improving the foreground fidelity of composite images. The proposed method is evaluated on both public benchmark and real-world data, which demonstrates that our method can generate more faithful and controllable composite images than existing approaches. The code and model will be available at https://github.com/bcmi/ControlCom-Image-Composition.
</details>
<details>
<summary>摘要</summary>
Image composition targets at synthesizing a realistic composite image from a pair of foreground and background images. Recently, generative composition methods are built on large pretrained diffusion models to generate composite images, considering their great potential in image generation. However, they suffer from lack of controllability on foreground attributes and poor preservation of foreground identity. To address these challenges, we propose a controllable image composition method that unifies four tasks in one diffusion model: image blending, image harmonization, view synthesis, and generative composition. Meanwhile, we design a self-supervised training framework coupled with a tailored pipeline of training data preparation. Moreover, we propose a local enhancement module to enhance the foreground details in the diffusion model, improving the foreground fidelity of composite images. The proposed method is evaluated on both public benchmark and real-world data, which demonstrates that our method can generate more faithful and controllable composite images than existing approaches. The code and model will be available at https://github.com/bcmi/ControlCom-Image-Composition.
</details></li>
</ul>
<hr>
<h2 id="CRC-ICM-Colorectal-Cancer-Immune-Cell-Markers-Pattern-Dataset"><a href="#CRC-ICM-Colorectal-Cancer-Immune-Cell-Markers-Pattern-Dataset" class="headerlink" title="CRC-ICM: Colorectal Cancer Immune Cell Markers Pattern Dataset"></a>CRC-ICM: Colorectal Cancer Immune Cell Markers Pattern Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10033">http://arxiv.org/abs/2308.10033</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zahra Mokhtari, Elham Amjadi, Hamidreza Bolhasani, Zahra Faghih, AmirReza Dehghanian, Marzieh Rezaei</li>
<li>For: The paper is written to explore the differences in immune checkpoints expression in primary tumors located in the right and left sides of the colon, and to investigate the prognostic value of these checkpoints in colorectal cancer (CRC).* Methods: The study uses a dataset of 1756 images related to 136 patients, stained with specific antibodies for CD3, CD8, CD45RO, PD-1, LAG3, and Tim3.* Results: The study found that tumors on the left and right sides of the colon have different immune landscapes, with differences in the expression of immune checkpoints such as PD-1, LAG3, and Tim3. These differences may have implications for the prognosis of CRC patients.<details>
<summary>Abstract</summary>
Colorectal Cancer (CRC) is the second most common cause of cancer death in the world, ad can be identified by the location of the primary tumor in the large intestine: right and left colon, and rectum. Based on the location, CRC shows differences in chromosomal and molecular characteristics, microbiomes incidence, pathogenesis, and outcome. It has been shown that tumors on left and right sides also have different immune landscape, so the prognosis may be different based on the primary tumor locations. It is widely accepted that immune components of the tumor microenvironment (TME) plays a critical role in tumor development. One of the critical regulatory molecules in the TME is immune checkpoints that as the gatekeepers of immune responses regulate the infiltrated immune cell functions. Inhibitory immune checkpoints such as PD-1, Tim3, and LAG3, as the main mechanism of immune suppression in TME overexpressed and result in further development of the tumor. The images of this dataset have been taken from colon tissues of patients with CRC, stained with specific antibodies for CD3, CD8, CD45RO, PD-1, LAG3 and Tim3. The name of this dataset is CRC-ICM and contains 1756 images related to 136 patients. The initial version of CRC-ICM is published on Elsevier Mendeley dataset portal, and the latest version is accessible via: https://databiox.com
</details>
<details>
<summary>摘要</summary>
“幽门肉瘤癌（CRC）是全球第二常见的癌症死亡原因，可以根据主癌肿 locus在大小肠中进行定位：右和左大肠、RECTUM。根据位置，CRC具有不同的染色体和分子特征、微生物发生率、生成和结果。已经证明左右两侧的肿均具有不同的免疫景观，因此诊断结果可能因primary tumor location而异。广泛认可的是，免疫组件在肿瘤微环境（TME）中扮演了关键的角色，其中一种关键的调控分子是免疫检查点。压缩性免疫检查点如PD-1、Tim3和LAG3等，是TME中免疫抑制的主要机制，过度表达导致肿瘤进一步发展。这些图像来自于患有CRC的大肠组织，用specific抗体染色CD3、CD8、CD45RO、PD-1、LAG3和Tim3。该数据集名为CRC-ICM，包含1756张图像，与136名患者相关。最初版本在Elsevier Mendeley数据集门户上发布，最新版本可以通过以下链接访问：https://databiox.com”
</details></li>
</ul>
<hr>
<h2 id="Single-Image-Reflection-Separation-via-Component-Synergy"><a href="#Single-Image-Reflection-Separation-via-Component-Synergy" class="headerlink" title="Single Image Reflection Separation via Component Synergy"></a>Single Image Reflection Separation via Component Synergy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10027">http://arxiv.org/abs/2308.10027</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mingcv/dsrnet">https://github.com/mingcv/dsrnet</a></li>
<li>paper_authors: Qiming Hu, Xiaojie Guo</li>
<li>for: 本研究旨在提出更一般的折射模型，以更好地捕捉剩下的信息，使分解层更加完整。</li>
<li>methods: 该研究基于现有模型的缺陷进行调查，并引入学习式偏移项，以捕捉剩下的信息。同时，我们还设计了网络结构，包括一种新型的双流交互机制和一种强大的分解网络。</li>
<li>results: 我们通过广泛的实验和减少研究，证明我们的方法在多个真实世界的标准 benchmark 数据集上表现出色，胜过当前的状态艺术方法。我们的代码可以在 <a target="_blank" rel="noopener" href="https://github.com/mingcv/DSRNet">https://github.com/mingcv/DSRNet</a> 上获取。<details>
<summary>Abstract</summary>
The reflection superposition phenomenon is complex and widely distributed in the real world, which derives various simplified linear and nonlinear formulations of the problem. In this paper, based on the investigation of the weaknesses of existing models, we propose a more general form of the superposition model by introducing a learnable residue term, which can effectively capture residual information during decomposition, guiding the separated layers to be complete. In order to fully capitalize on its advantages, we further design the network structure elaborately, including a novel dual-stream interaction mechanism and a powerful decomposition network with a semantic pyramid encoder. Extensive experiments and ablation studies are conducted to verify our superiority over state-of-the-art approaches on multiple real-world benchmark datasets. Our code is publicly available at https://github.com/mingcv/DSRNet.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "The reflection superposition phenomenon is complex and widely distributed in the real world, which derives various simplified linear and nonlinear formulations of the problem. In this paper, based on the investigation of the weaknesses of existing models, we propose a more general form of the superposition model by introducing a learnable residue term, which can effectively capture residual information during decomposition, guiding the separated layers to be complete. In order to fully capitalize on its advantages, we further design the network structure elaborately, including a novel dual-stream interaction mechanism and a powerful decomposition network with a semantic pyramid encoder. Extensive experiments and ablation studies are conducted to verify our superiority over state-of-the-art approaches on multiple real-world benchmark datasets. Our code is publicly available at https://github.com/mingcv/DSRNet." into Simplified Chinese.Translation:<<SYS>>现实世界中各种复杂的反射积累现象，导致了许多简化的线性和非线性形式化问题。在这篇论文中，我们基于现有模型的缺陷进行调查，并提出了更一般的积累模型，通过引入学习型剩余项，能够有效地捕捉反射信息的剩余信息，导引分解层成为完整的。为了充分利用其优势，我们还设计了网络结构，包括一种新的双流交互机制和一个强大的分解网络，具有含义层Encoder。我们进行了广泛的实验和减少研究，以证明我们在多个实际世界标准数据集上的优越性。我们的代码可以在https://github.com/mingcv/DSRNet中获得。
</details></li>
</ul>
<hr>
<h2 id="Interpretation-on-Multi-modal-Visual-Fusion"><a href="#Interpretation-on-Multi-modal-Visual-Fusion" class="headerlink" title="Interpretation on Multi-modal Visual Fusion"></a>Interpretation on Multi-modal Visual Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10019">http://arxiv.org/abs/2308.10019</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Chen, Haoran Zhou, Yongjian Deng</li>
<li>for: 本文提出了一种分析框架和一种新的评估指标，用于解释多Modal视觉社区中的解释。</li>
<li>methods: 我们的方法包括在不同modalities和层次上测量提议的semantic variance和特征相似性，并通过广泛的实验进行semantic和量化分析。</li>
<li>results: 我们的研究发现了跨modalities的特征不一致和多modal的合作规则，这些发现有助于重新评估和设计多Modal视觉融合模型。<details>
<summary>Abstract</summary>
In this paper, we present an analytical framework and a novel metric to shed light on the interpretation of the multimodal vision community. Our approach involves measuring the proposed semantic variance and feature similarity across modalities and levels, and conducting semantic and quantitative analyses through comprehensive experiments. Specifically, we investigate the consistency and speciality of representations across modalities, evolution rules within each modality, and the collaboration logic used when optimizing a multi-modality model. Our studies reveal several important findings, such as the discrepancy in cross-modal features and the hybrid multi-modal cooperation rule, which highlights consistency and speciality simultaneously for complementary inference. Through our dissection and findings on multi-modal fusion, we facilitate a rethinking of the reasonability and necessity of popular multi-modal vision fusion strategies. Furthermore, our work lays the foundation for designing a trustworthy and universal multi-modal fusion model for a variety of tasks in the future.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种分析框架和一种新的度量来探讨多模态视觉社区的解释。我们的方法是在不同的modalities和层次上测量提议的 semantics variance和特征相似性，并通过全面的实验进行semantic和量化的分析。我们专门investigates the consistency和特点of representations across modalities, evolution rules within each modality, and the collaboration logic used when optimizing a multi-modality model。我们的研究发现了一些重要的发现，如cross-modal features的差异和hybrid multi-modal cooperation rule，这些发现揭示了同时具有一致和特点的hybrid multi-modal合作。通过我们的分析和发现，我们促进了对多模态视觉混合的重新思考，并为未来多种任务的多模态混合模型设计一个可靠和通用的基础。
</details></li>
</ul>
<hr>
<h2 id="Pseudo-Flow-Consistency-for-Self-Supervised-6D-Object-Pose-Estimation"><a href="#Pseudo-Flow-Consistency-for-Self-Supervised-6D-Object-Pose-Estimation" class="headerlink" title="Pseudo Flow Consistency for Self-Supervised 6D Object Pose Estimation"></a>Pseudo Flow Consistency for Self-Supervised 6D Object Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10016">http://arxiv.org/abs/2308.10016</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yanghai-1218/pseudoflow">https://github.com/yanghai-1218/pseudoflow</a></li>
<li>paper_authors: Yang Hai, Rui Song, Jiaojiao Li, David Ferstl, Yinlin Hu</li>
<li>for: 这篇论文主要针对的是无需额外信息的自主学习6D对象pose估计问题。</li>
<li>methods: 该方法首先从使用synthetic图像生成的网络获得粗略的pose初始值，然后引入了一种基于干扰图像对数据集的geometry约束的精度调整策略。该约束由多个不同视角的synthetic-to-real图像对形成，并通过动态生成的pseudo标签来表示。</li>
<li>results: 对三个复杂的数据集进行评估，该方法与无需2D标注和额外深度图像的前一代自主学习方法相比，显著地提高了性能。<details>
<summary>Abstract</summary>
Most self-supervised 6D object pose estimation methods can only work with additional depth information or rely on the accurate annotation of 2D segmentation masks, limiting their application range. In this paper, we propose a 6D object pose estimation method that can be trained with pure RGB images without any auxiliary information. We first obtain a rough pose initialization from networks trained on synthetic images rendered from the target's 3D mesh. Then, we introduce a refinement strategy leveraging the geometry constraint in synthetic-to-real image pairs from multiple different views. We formulate this geometry constraint as pixel-level flow consistency between the training images with dynamically generated pseudo labels. We evaluate our method on three challenging datasets and demonstrate that it outperforms state-of-the-art self-supervised methods significantly, with neither 2D annotations nor additional depth images.
</details>
<details>
<summary>摘要</summary>
大多数自我指导的6D对象姿态估计方法需要额外深度信息或者精确的2D分割标签，这限制了它们的应用范围。在这篇论文中，我们提出了不需要 auxiliary信息的6D对象姿态估计方法。我们首先从目标对象的3D meshRendered的Synthetic图像中获取初步姿态 initialization。然后，我们引入了一种改善策略，利用多个不同视角的Synthetic-to-real图像对的geometry约束。我们将这种geometry约束表示为多个不同视角的Synthetic图像之间的像素水平流consistency。我们对三个具有挑战性的数据集进行评估，并证明了我们的方法在自我指导方法中具有明显的优势，无需2D标签也无需额外深度图像。
</details></li>
</ul>
<hr>
<h2 id="DyFFPAD-Dynamic-Fusion-of-Convolutional-and-Handcrafted-Features-for-Fingerprint-Presentation-Attack-Detection"><a href="#DyFFPAD-Dynamic-Fusion-of-Convolutional-and-Handcrafted-Features-for-Fingerprint-Presentation-Attack-Detection" class="headerlink" title="DyFFPAD: Dynamic Fusion of Convolutional and Handcrafted Features for Fingerprint Presentation Attack Detection"></a>DyFFPAD: Dynamic Fusion of Convolutional and Handcrafted Features for Fingerprint Presentation Attack Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10015">http://arxiv.org/abs/2308.10015</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anuj Rai, Parsheel Kumar Tiwari, Jyotishna Baishya, Ram Prakash Sharma, Somnath Dey</li>
<li>for: The paper is written for the purpose of detecting presentation attacks in automatic fingerprint recognition systems, which are a threat to their wide range of applications in areas including national borders and commercial applications.</li>
<li>methods: The paper proposes a dynamic ensemble of deep learning and handcrafted features to detect presentation attacks in known-material and unknown-material protocols. The proposed model combines both deep CNN and handcrafted features, and learns their parameters together to exhibit better performance than individual results.</li>
<li>results: The proposed model is validated using benchmark LivDet 2015, 2017, and 2019 databases, and achieves an overall accuracy of 96.10%, 96.49%, and 95.99% on them, respectively. The proposed model outperforms state-of-the-art methods in benchmark protocols of presentation attack detection in terms of classification accuracy.Here are the three key points in Simplified Chinese text:</li>
<li>for: 这篇论文是为检测自动指纹识别系统中的示现攻击而写的。</li>
<li>methods: 这篇论文提出了一种动态集成深度学习和手工特征的方法来检测示现攻击。该模型将深度学习和手工特征结合使用，并同时学习它们的参数。</li>
<li>results: 该模型在livDet2015、livDet2017和livDet2019等数据库上进行了验证，并达到了96.10%、96.49%和95.99%的总准确率。这个模型在示现攻击检测中的benchmark协议中表现出了更好的性能。<details>
<summary>Abstract</summary>
Automatic fingerprint recognition systems suffer from the threat of presentation attacks due to their wide range of applications in areas including national borders and commercial applications. Presentation attacks can be performed by fabricating the fake fingerprint of a user with or without the intention of the subject. This paper presents a dynamic ensemble of deep learning and handcrafted features to detect presentation attacks in known-material and unknown-material protocols. The proposed model is a dynamic ensemble of deep CNN and handcrafted features empowered deep neural networks both of which learn their parameters together. The proposed presentation attack detection model, in this way, utilizes the capabilities of both classification techniques and exhibits better performance than their individual results. The proposed model's performance is validated using benchmark LivDet 2015, 2017, and 2019 databases, with an overall accuracy of 96.10\%, 96.49\%, and 95.99\% attained on them, respectively. The proposed model outperforms state-of-the-art methods in benchmark protocols of presentation attack detection in terms of classification accuracy.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Partition-and-Debias-Agnostic-Biases-Mitigation-via-A-Mixture-of-Biases-Specific-Experts"><a href="#Partition-and-Debias-Agnostic-Biases-Mitigation-via-A-Mixture-of-Biases-Specific-Experts" class="headerlink" title="Partition-and-Debias: Agnostic Biases Mitigation via A Mixture of Biases-Specific Experts"></a>Partition-and-Debias: Agnostic Biases Mitigation via A Mixture of Biases-Specific Experts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10005">http://arxiv.org/abs/2308.10005</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Jiaxuan-Li/PnD">https://github.com/Jiaxuan-Li/PnD</a></li>
<li>paper_authors: Jiaxuan Li, Duc Minh Vo, Hideki Nakayama</li>
<li>for: 减少图像分类中的偏见（bias mitigation），特别是面对不确定或多种偏见的情况。</li>
<li>methods: 提出了一种名为Partition-and-Debias（PnD）方法，通过一组偏见特定的专家来分解偏见空间，并使用一个阻断模块来实现专家之间的协调，以达到减少偏见的分类。</li>
<li>results: 在公共和自定义的benchmark上进行了实验，并证明了PnD方法的有效性。<details>
<summary>Abstract</summary>
Bias mitigation in image classification has been widely researched, and existing methods have yielded notable results. However, most of these methods implicitly assume that a given image contains only one type of known or unknown bias, failing to consider the complexities of real-world biases. We introduce a more challenging scenario, agnostic biases mitigation, aiming at bias removal regardless of whether the type of bias or the number of types is unknown in the datasets. To address this difficult task, we present the Partition-and-Debias (PnD) method that uses a mixture of biases-specific experts to implicitly divide the bias space into multiple subspaces and a gating module to find a consensus among experts to achieve debiased classification. Experiments on both public and constructed benchmarks demonstrated the efficacy of the PnD. Code is available at: https://github.com/Jiaxuan-Li/PnD.
</details>
<details>
<summary>摘要</summary>
<<音� simpified>>偏调缓和图像分类中的研究已经广泛，现有的方法已经获得了 Notable results。然而，大多数这些方法预设假设一个图像只包含一种已知或未知的偏调，忽略了实际世界中的复杂偏调。我们引入一个更加问题的场景：agnostic biases mitigation， aiming at bias removal regardless of whether the type of bias or the number of types is unknown in the datasets。为了解决这个困难的任务，我们提出了 Partition-and-Debias（PnD）方法，使用一种混合偏调特有的专家来隐式地分解偏调空间 into multiple subspaces，并使用一个闸道模组来获得专家们之间的一致，以达到 debiased classification。实验结果显示，PnD方法在公共和自己建立的benchmark上具有优良的效果。代码可以在：https://github.com/Jiaxuan-Li/PnD 中找到。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Multi-View-Inverse-Rendering-Using-a-Hybrid-Differentiable-Rendering-Method"><a href="#Efficient-Multi-View-Inverse-Rendering-Using-a-Hybrid-Differentiable-Rendering-Method" class="headerlink" title="Efficient Multi-View Inverse Rendering Using a Hybrid Differentiable Rendering Method"></a>Efficient Multi-View Inverse Rendering Using a Hybrid Differentiable Rendering Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10003">http://arxiv.org/abs/2308.10003</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/HsiangYangChu/DRBIR">https://github.com/HsiangYangChu/DRBIR</a></li>
<li>paper_authors: Xiangyang Zhu, Yiling Pan, Bailin Deng, Bin Wang</li>
<li>for: 这篇论文的目的是用hybrid differentiable rendering方法 efficiently recovering real-world object的3D geometry和reflectance从多视图图像中。</li>
<li>methods: 该方法包括两个阶段：初始化阶段使用传统的SfM和MVS方法重建虚拟场景，优化阶段使用混合方法同时优化几何和反射特性，其中几何使用伪优化方法，反射使用物理基于优化方法。</li>
<li>results: 对于synthetic和实际数据，我们的方法可以生成与状态前方法相同或更高质量的重建结果，同时更高效。<details>
<summary>Abstract</summary>
Recovering the shape and appearance of real-world objects from natural 2D images is a long-standing and challenging inverse rendering problem. In this paper, we introduce a novel hybrid differentiable rendering method to efficiently reconstruct the 3D geometry and reflectance of a scene from multi-view images captured by conventional hand-held cameras. Our method follows an analysis-by-synthesis approach and consists of two phases. In the initialization phase, we use traditional SfM and MVS methods to reconstruct a virtual scene roughly matching the real scene. Then in the optimization phase, we adopt a hybrid approach to refine the geometry and reflectance, where the geometry is first optimized using an approximate differentiable rendering method, and the reflectance is optimized afterward using a physically-based differentiable rendering method. Our hybrid approach combines the efficiency of approximate methods with the high-quality results of physically-based methods. Extensive experiments on synthetic and real data demonstrate that our method can produce reconstructions with similar or higher quality than state-of-the-art methods while being more efficient.
</details>
<details>
<summary>摘要</summary>
recuperar la forma y apariencia de objetos del mundo real desde imágenes 2D naturales es un problema de inverse rendering largo standing y desafiante. En este artículo, presentamos un método de renderizado diferenciable híbrido para eficientemente reconstruir la geometría 3D y la refracción de una escena a partir de imágenes multiview capturadas por cámaras portátiles convencionales. Nuestro método sigue un enfoque de análisis por síntesis y consta de dos fases. En la fase de inicio, utilizamos métodos SfM y MVS tradicionales para reconstruir una escena virtual que approximate la escena real. Luego, en la fase de optimización, adoptamos un enfoque híbrido para refinar la geometría y la refracción, donde la geometría se optimiza primero utilizando un método de renderizado diferenciable aproximado, y la refracción se optimiza después utilizando un método de renderizado diferenciable físicamente basado. Nuestro enfoque híbrido combina la eficiencia de los métodos aproximados con los resultados de alta calidad de los métodos físicamente basados. Los experimentos extensivos en datos sintéticos y reales demuestran que nuestro método puede producir reconstrucciones con calidad similar o superior a los métodos estado del arte mientras es más eficiente.
</details></li>
</ul>
<hr>
<h2 id="AltNeRF-Learning-Robust-Neural-Radiance-Field-via-Alternating-Depth-Pose-Optimization"><a href="#AltNeRF-Learning-Robust-Neural-Radiance-Field-via-Alternating-Depth-Pose-Optimization" class="headerlink" title="AltNeRF: Learning Robust Neural Radiance Field via Alternating Depth-Pose Optimization"></a>AltNeRF: Learning Robust Neural Radiance Field via Alternating Depth-Pose Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10001">http://arxiv.org/abs/2308.10001</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kun Wang, Zhiqiang Yan, Huang Tian, Zhenyu Zhang, Xiang Li, Jun Li, Jian Yang</li>
<li>for: 实现高品质的新视角生成（Novel View Synthesis） from sparse scene images.</li>
<li>methods: 使用自我监督的单目深度测量（SMDE）自MONOCULAR VIDEOS中学习深度和pose prior，并与NeRF进行交互式调整。</li>
<li>results: 产生高传真度和可靠的新视角，并且能够处理不确定的摄像机位置和缺乏明确的3D超级vision。<details>
<summary>Abstract</summary>
Neural Radiance Fields (NeRF) have shown promise in generating realistic novel views from sparse scene images. However, existing NeRF approaches often encounter challenges due to the lack of explicit 3D supervision and imprecise camera poses, resulting in suboptimal outcomes. To tackle these issues, we propose AltNeRF -- a novel framework designed to create resilient NeRF representations using self-supervised monocular depth estimation (SMDE) from monocular videos, without relying on known camera poses. SMDE in AltNeRF masterfully learns depth and pose priors to regulate NeRF training. The depth prior enriches NeRF's capacity for precise scene geometry depiction, while the pose prior provides a robust starting point for subsequent pose refinement. Moreover, we introduce an alternating algorithm that harmoniously melds NeRF outputs into SMDE through a consistence-driven mechanism, thus enhancing the integrity of depth priors. This alternation empowers AltNeRF to progressively refine NeRF representations, yielding the synthesis of realistic novel views. Additionally, we curate a distinctive dataset comprising indoor videos captured via mobile devices. Extensive experiments showcase the compelling capabilities of AltNeRF in generating high-fidelity and robust novel views that closely resemble reality.
</details>
<details>
<summary>摘要</summary>
neural radiance fields (NeRF) 已经示示出在使用稀疏场景图像生成真实的新视图时的承诺。然而，现有的 NeRF 方法经常遇到缺乏显式的3D监督和不准确的相机位置问题，导致优化结果不佳。为解决这些问题，我们提出了 AltNeRF -- 一种新的框架，通过使用单目视频中的自我监督深度估计 (SMDE)，不需要知道相机位置，创建了鲜明的 NeRF 表示。SMDE 在 AltNeRF 中熟练地学习了深度和pose prior，以规则 NeRF 训练。深度先导提高了 NeRF 的场景几何描述能力，而pose先导提供了 robust的开始点，用于后续的pose修正。此外，我们还引入了一种相互律动的算法，将 NeRF 输出与 SMDE 融合在一起，通过一种具有一致性的机制，以强化深度先导的完整性。这种相互律动使得 AltNeRF 能够不断地加工 NeRF 表示，Synthesize 出真实的新视图。此外，我们还制作了一个特有的indoor视频 captured via mobile devices的数据集。广泛的实验表明，AltNeRF 能够生成高质量和Robust的新视图，与实际相似。
</details></li>
</ul>
<hr>
<h2 id="TTPOINT-A-Tensorized-Point-Cloud-Network-for-Lightweight-Action-Recognition-with-Event-Cameras"><a href="#TTPOINT-A-Tensorized-Point-Cloud-Network-for-Lightweight-Action-Recognition-with-Event-Cameras" class="headerlink" title="TTPOINT: A Tensorized Point Cloud Network for Lightweight Action Recognition with Event Cameras"></a>TTPOINT: A Tensorized Point Cloud Network for Lightweight Action Recognition with Event Cameras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09993">http://arxiv.org/abs/2308.09993</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongwei Ren, Yue Zhou, Haotian Fu, Yulong Huang, Renjing Xu, Bojun Cheng</li>
<li>for: 本研究旨在提出一种轻量级、通用的点云网络（TTPOINT），用于行动识别任务。</li>
<li>methods: 该模型采用点云方式进行数据采集，并使用tensor-train压缩特征提取器来减少计算复杂度和参数量。</li>
<li>results: TTPOINT在三个 dataset 上达到了状态平台（SOTA）水平，并在所有五个 dataset 上达到了点云方法的SOTA水平。此外，通过使用tensor-train压缩方法，模型的精度几乎不受参数大小压缩的影响。<details>
<summary>Abstract</summary>
Event cameras have gained popularity in computer vision due to their data sparsity, high dynamic range, and low latency. As a bio-inspired sensor, event cameras generate sparse and asynchronous data, which is inherently incompatible with the traditional frame-based method. Alternatively, the point-based method can avoid additional modality transformation and naturally adapt to the sparsity of events. Still, it typically cannot reach a comparable accuracy as the frame-based method. We propose a lightweight and generalized point cloud network called TTPOINT which achieves competitive results even compared to the state-of-the-art (SOTA) frame-based method in action recognition tasks while only using 1.5 % of the computational resources. The model is adept at abstracting local and global geometry by hierarchy structure. By leveraging tensor-train compressed feature extractors, TTPOINT can be designed with minimal parameters and computational complexity. Additionally, we developed a straightforward downsampling algorithm to maintain the spatio-temporal feature. In the experiment, TTPOINT emerged as the SOTA method on three datasets while also attaining SOTA among point cloud methods on all five datasets. Moreover, by using the tensor-train decomposition method, the accuracy of the proposed TTPOINT is almost unaffected while compressing the parameter size by 55 % in all five datasets.
</details>
<details>
<summary>摘要</summary>
事件摄像机在计算机视觉中得到了普遍应用，因为它们的数据稀疏、高动态范围和低延迟时间。作为生物体发现的感知器，事件摄像机生成的数据是不兼容传统框架方法的异常快照式数据。相反，点云方法可以避免额外模态变换，并自然适应事件的稀疏性。然而，它通常无法达到与框架方法相当的准确性。我们提出了一种轻量级、通用的点云网络 called TTPOINT，它在动作识别任务中达到了与状态前方法相当的结果，只使用了1.5%的计算资源。该模型能够层次结构中抽象本地和全局几何。通过利用张量约束压缩特征提取器，TTPOINT可以设计为最小参数和计算复杂度。此外，我们开发了一种简单的下采样算法，以保持空间时间特征。在实验中，TTPOINT被认为状态前方法在三个数据集上，同时在五个数据集上也成为点云方法的最佳方法。此外，通过使用张量约束压缩方法，提议的TTPOINT的准确率几乎不受参数大小压缩55%的影响。
</details></li>
</ul>
<hr>
<h2 id="AltDiffusion-A-Multilingual-Text-to-Image-Diffusion-Model"><a href="#AltDiffusion-A-Multilingual-Text-to-Image-Diffusion-Model" class="headerlink" title="AltDiffusion: A Multilingual Text-to-Image Diffusion Model"></a>AltDiffusion: A Multilingual Text-to-Image Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09991">http://arxiv.org/abs/2308.09991</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/superhero-7/altdiffuson">https://github.com/superhero-7/altdiffuson</a></li>
<li>paper_authors: Fulong Ye, Guang Liu, Xinya Wu, Ledell Wu<br>for: 这个论文是为了推广大语言环境下的文本到图像（T2I）扩散模型，以便为不同语言用户提供更好的服务。methods: 这篇论文使用了知识传播学习（KD）来训练一个多语言文本编码器，然后把其插入到一个预训练的英文只 diffusion 模型中，通过两个阶段的Schema来提高多语言能力。results: 这篇论文在一个大规模多语言 dataset 上进行了两个阶段的Schema，包括概念对接和质量改进阶段，并在多语言总体评价和文化特有概念评价中表现出色，超过了现有的状态之艺 T2I 模型。<details>
<summary>Abstract</summary>
Large Text-to-Image(T2I) diffusion models have shown a remarkable capability to produce photorealistic and diverse images based on text inputs. However, existing works only support limited language input, e.g., English, Chinese, and Japanese, leaving users beyond these languages underserved and blocking the global expansion of T2I models. Therefore, this paper presents AltDiffusion, a novel multilingual T2I diffusion model that supports eighteen different languages. Specifically, we first train a multilingual text encoder based on the knowledge distillation. Then we plug it into a pretrained English-only diffusion model and train the model with a two-stage schema to enhance the multilingual capability, including concept alignment and quality improvement stage on a large-scale multilingual dataset. Furthermore, we introduce a new benchmark, which includes Multilingual-General-18(MG-18) and Multilingual-Cultural-18(MC-18) datasets, to evaluate the capabilities of T2I diffusion models for generating high-quality images and capturing culture-specific concepts in different languages. Experimental results on both MG-18 and MC-18 demonstrate that AltDiffusion outperforms current state-of-the-art T2I models, e.g., Stable Diffusion in multilingual understanding, especially with respect to culture-specific concepts, while still having comparable capability for generating high-quality images. All source code and checkpoints could be found in https://github.com/superhero-7/AltDiffuson.
</details>
<details>
<summary>摘要</summary>
大型文本到图像（T2I）扩散模型已经显示出产生高质量和多样化的图像的remarkable能力，但现有的工作只支持有限的语言输入，例如英语、中文和日语，这使得用户使用其他语言被忽略和限制了全球的扩展。因此，本文提出了AltDiffusion，一种新的多语言T2I扩散模型，支持 eighteen种不同的语言。 Specifically，我们首先训练了一个多语言文本编码器，基于知识传承。然后，我们插入到一个预训练的英语只 diffusion model 中，并在一个两个阶段的Schema中进行增强多语言能力，包括概念对齐和质量提升阶段。此外，我们 introduce a new benchmark，包括 Multilingual-General-18（MG-18）和 Multilingual-Cultural-18（MC-18）数据集，以评估 T2I 扩散模型在生成高质量图像和捕捉不同语言文化特性方面的能力。实验结果表明，AltDiffusion 在 MG-18 和 MC-18 上表现出优于当前状态的扩散模型，特别是在文化特性方面，而且仍然与生成高质量图像有相同的能力。所有源代码和检查点可以在 <https://github.com/superhero-7/AltDiffuson> 找到。
</details></li>
</ul>
<hr>
<h2 id="TSAR-MVS-Textureless-aware-Segmentation-and-Correlative-Refinement-Guided-Multi-View-Stereo"><a href="#TSAR-MVS-Textureless-aware-Segmentation-and-Correlative-Refinement-Guided-Multi-View-Stereo" class="headerlink" title="TSAR-MVS: Textureless-aware Segmentation and Correlative Refinement Guided Multi-View Stereo"></a>TSAR-MVS: Textureless-aware Segmentation and Correlative Refinement Guided Multi-View Stereo</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09990">http://arxiv.org/abs/2308.09990</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenlong Yuan, Jiakai Cao, Hao Jiang, Zhaoqi Wang, Zhaoxin Li</li>
<li>for: 增强多视图ステレオ（MVS）中缺失文本区域的重建问题的解决方案。</li>
<li>methods: 提议的方法包括：一、 joint hypothesis filtering，二、iterative correlation refinement，三、 textureless-aware segmentation。</li>
<li>results: 实验结果表明，提议的方法在大量数据集上表现出色，与大多数非学习方法比较，具有较高的精度和稳定性，同时能够保留细节。<details>
<summary>Abstract</summary>
The reconstruction of textureless areas has long been a challenging problem in MVS due to lack of reliable pixel correspondences between images. In this paper, we propose the Textureless-aware Segmentation And Correlative Refinement guided Multi-View Stereo (TSAR-MVS), a novel method that effectively tackles challenges posed by textureless areas in 3D reconstruction through filtering, refinement and segmentation. First, we implement joint hypothesis filtering, a technique that merges a confidence estimator with a disparity discontinuity detector to eliminate incorrect depth estimations. Second, to spread the pixels with confident depth, we introduce a iterative correlation refinement strategy that leverages RANSAC to generate superpixels, succeeded by a median filter for broadening the influence of accurately determined pixels.Finally, we present a textureless-aware segmentation method that leverages edge detection and line detection for accurately identify large textureless regions to be fitted using 3D planes. Experiments on extensive datasets demonstrate that our method significantly outperforms most non-learning methods and exhibits robustness to textureless areas while preserving fine details.
</details>
<details>
<summary>摘要</summary>
文本无纹区域重建问题在多视图深度（MVS）中一直是一个挑战，因为缺乏可靠的像素对应关系。在这篇论文中，我们提出了Textureless-aware Segmentation And Correlative Refinement guided Multi-View Stereo（TSAR-MVS），一种新的方法，可以有效地解决由缺纹区域引起的3D重建问题。首先，我们实现了联合假设筛选，这是一种将信度估计器与分辨率缺乏检测器结合在一起，以消除错误的深度估计。其次，为了将具有信任度的像素扩展到更多的像素，我们引入了一种迭代相关级联策略，该策略利用RANSAC生成超像素，然后使用中值滤波器来扩大正确确定的像素的影响。最后，我们提出了一种具有纹理性的分割方法，该方法利用边检测和直线检测来准确地识别大面积的缺纹区域，并将其适用3D平面来适应。我们对广泛的数据集进行了实验，结果显示，我们的方法在非学习方法中显著超越，并且具有对缺纹区域的鲁棒性，同时保留细节。
</details></li>
</ul>
<hr>
<h2 id="Prototypical-Cross-domain-Knowledge-Transfer-for-Cervical-Dysplasia-Visual-Inspection"><a href="#Prototypical-Cross-domain-Knowledge-Transfer-for-Cervical-Dysplasia-Visual-Inspection" class="headerlink" title="Prototypical Cross-domain Knowledge Transfer for Cervical Dysplasia Visual Inspection"></a>Prototypical Cross-domain Knowledge Transfer for Cervical Dysplasia Visual Inspection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09983">http://arxiv.org/abs/2308.09983</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yichen Zhang, Yifang Yin, Ying Zhang, Zhenguang Liu, Zheng Wang, Roger Zimmermann<br>for: 这个研究的目的是提高自动诊断阴道异常的准确率，以便在低资源设置下提供更好的阴道癌诊断。methods: 我们提出了一种使用跨领域阴道照片进行学习，以增强模型的性能。我们还提出了一种具有转移性的知识范例选择方法，以便对目标阴道照片集进行训练。results: 我们的方法在三个真实世界 benchmark 阴道照片集上进行了实验，结果显示我们的方法在阴道异常诊断中的顶尖一致率、精度、准确率和ROC-AUC上有4.7%、7.0%、1.4%和4.6%的提升，优于现有的阴道异常诊断方法。<details>
<summary>Abstract</summary>
Early detection of dysplasia of the cervix is critical for cervical cancer treatment. However, automatic cervical dysplasia diagnosis via visual inspection, which is more appropriate in low-resource settings, remains a challenging problem. Though promising results have been obtained by recent deep learning models, their performance is significantly hindered by the limited scale of the available cervix datasets. Distinct from previous methods that learn from a single dataset, we propose to leverage cross-domain cervical images that were collected in different but related clinical studies to improve the model's performance on the targeted cervix dataset. To robustly learn the transferable information across datasets, we propose a novel prototype-based knowledge filtering method to estimate the transferability of cross-domain samples. We further optimize the shared feature space by aligning the cross-domain image representations simultaneously on domain level with early alignment and class level with supervised contrastive learning, which endows model training and knowledge transfer with stronger robustness. The empirical results on three real-world benchmark cervical image datasets show that our proposed method outperforms the state-of-the-art cervical dysplasia visual inspection by an absolute improvement of 4.7% in top-1 accuracy, 7.0% in precision, 1.4% in recall, 4.6% in F1 score, and 0.05 in ROC-AUC.
</details>
<details>
<summary>摘要</summary>
早期检测颈部癌变是肺癌治疗的关键，但自动诊断颈部癌变via视觉检查，更适合在低资源环境中进行，仍然是一个挑战。虽然最近的深度学习模型已经获得了有前途的结果，但它们的性能受到有限的颈部数据集的限制。与前方方法不同，我们提议利用跨频道颈部图像，从不同但相关的临床研究中收集的图像来提高模型的性能。为了强制学习跨频道图像中的共同信息，我们提出了一种新的原型基于知识筛选方法，以估算跨频道样本的传输性。此外，我们还使用了同时对域级和类别级进行对齐，以提高共享特征空间的定制。通过这种方法，我们可以强制训练模型并传输知识，使其在目标颈部数据集上表现更加稳定。实验结果表明，我们的提议方法在三个实际预测颈部癌变的数据集上表现出色，与状态之前的诊断性能相比，提高了4.7%的排名前一精度、7.0%的精度、1.4%的准确率、4.6%的F1分数和0.05的ROC-AUC。
</details></li>
</ul>
<hr>
<h2 id="Breast-Lesion-Diagnosis-Using-Static-Images-and-Dynamic-Video"><a href="#Breast-Lesion-Diagnosis-Using-Static-Images-and-Dynamic-Video" class="headerlink" title="Breast Lesion Diagnosis Using Static Images and Dynamic Video"></a>Breast Lesion Diagnosis Using Static Images and Dynamic Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09980">http://arxiv.org/abs/2308.09980</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunwen Huang, Hongyu Hu, Ying Zhu, Yi Xu<br>for: 这个研究旨在开发一个基于深度学习的电脑助诊系统，以帮助诊断乳腺癌。methods: 这个系统使用多 modal 的乳腺ultrasound影像和动态影像，并将它们融合为一个多Modal Feature。在这个过程中，我们将使用专家选择的静止影像来导航动态影像的特征聚合。results: 我们在一个包含897个乳腺ultrasound影像和动态影像的 dataset上进行验证，结果显示我们的模型可以提高了诊断的精度，其AUC值为90.0%，并且精度为81.7%。<details>
<summary>Abstract</summary>
Deep learning based Computer Aided Diagnosis (CAD) systems have been developed to treat breast ultrasound. Most of them focus on a single ultrasound imaging modality, either using representative static images or the dynamic video of a real-time scan. In fact, these two image modalities are complementary for lesion diagnosis. Dynamic videos provide detailed three-dimensional information about the lesion, while static images capture the typical sections of the lesion. In this work, we propose a multi-modality breast tumor diagnosis model to imitate the diagnosing process of radiologists, which learns the features of both static images and dynamic video and explores the potential relationship between the two modalities. Considering that static images are carefully selected by professional radiologists, we propose to aggregate dynamic video features under the guidance of domain knowledge from static images before fusing multi-modality features. Our work is validated on a breast ultrasound dataset composed of 897 sets of ultrasound images and videos. Experimental results show that our model boosts the performance of Benign/Malignant classification, achieving 90.0% in AUC and 81.7% in accuracy.
</details>
<details>
<summary>摘要</summary>
深度学习基于计算机辅助诊断（CAD）系统已经开发以治疗乳腺癌。大多数其中都专注于单一的乳腺ultrasound图像模式，可以是使用代表性的静止图像或实时扫描的动态视频。事实上，这两种图像模式是诊断癌变的补充。动态视频提供癌变三维信息的详细信息，而静止图像捕捉癌变典型部分。在这种工作中，我们提议一种多Modal breast tumor诊断模型，以模拟医生的诊断过程，学习静止图像和动态视频中的特征，并探索这两种模式之间的潜在关系。考虑到静止图像由专业医生 manually selects，我们提议将动态视频特征与静止图像特征相互融合，然后将多模式特征进行融合。我们的工作被验证在897组乳腺ultrasound图像和视频组成的 dataset上。实验结果表明，我们的模型可以提高了抑准/癌变分类的性能，达到了90.0%的AUC和81.7%的准确率。
</details></li>
</ul>
<hr>
<h2 id="Whether-you-can-locate-or-not-Interactive-Referring-Expression-Generation"><a href="#Whether-you-can-locate-or-not-Interactive-Referring-Expression-Generation" class="headerlink" title="Whether you can locate or not? Interactive Referring Expression Generation"></a>Whether you can locate or not? Interactive Referring Expression Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09977">http://arxiv.org/abs/2308.09977</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/superhero-7/ireg">https://github.com/superhero-7/ireg</a></li>
<li>paper_authors: Fulong Ye, Yuxing Long, Fangxiang Feng, Xiaojie Wang</li>
<li>for: 本研究旨在生成不ambiguous的 Referring Expressions (REs)，并实现 Referring Expression Comprehension (REC) 任务。</li>
<li>methods: 我们提出了一种Interactive REG (IREG) 模型，可以与真实的 REC 模型交互，利用显示对象所在视觉区域和对象是否已经找到的信号来慢慢修改 REs。</li>
<li>results: 我们在 RefCOCO、RefCOCO+ 和 RefCOCOg 三个 RE  benchmark 数据集上进行了实验，结果显示，IREG 可以比前一代方法在各种评价指标上取得更高的性能。此外，人工评价也表明，IREG 能够更好地生成 REs 并具有交互能力。<details>
<summary>Abstract</summary>
Referring Expression Generation (REG) aims to generate unambiguous Referring Expressions (REs) for objects in a visual scene, with a dual task of Referring Expression Comprehension (REC) to locate the referred object. Existing methods construct REG models independently by using only the REs as ground truth for model training, without considering the potential interaction between REG and REC models. In this paper, we propose an Interactive REG (IREG) model that can interact with a real REC model, utilizing signals indicating whether the object is located and the visual region located by the REC model to gradually modify REs. Our experimental results on three RE benchmark datasets, RefCOCO, RefCOCO+, and RefCOCOg show that IREG outperforms previous state-of-the-art methods on popular evaluation metrics. Furthermore, a human evaluation shows that IREG generates better REs with the capability of interaction.
</details>
<details>
<summary>摘要</summary>
《referring表达生成（REG）》的目标是生成清晰无ambiguity的引用表达（RE），同时通过引用表达理解（REC）来确定引用的对象所在位置。现有方法通常是独立构建REG模型，只使用RE作为模型训练的真实值，而不考虑REG和REC模型之间的可能的互动。在这篇论文中，我们提出了一种互动式REG（IREG）模型，可以与真实的REC模型进行互动，通过视觉区域和对象所在位置的信号来慢慢修改RE。我们的实验结果表明，IREG在三个REFCOCO数据集上表现出色，与前一代方法相比，在流行的评价指标上表现出色。此外，人工评价也表明，IREG能够更好地生成引用表达，并具有互动的能力。
</details></li>
</ul>
<hr>
<h2 id="DESOBAv2-Towards-Large-scale-Real-world-Dataset-for-Shadow-Generation"><a href="#DESOBAv2-Towards-Large-scale-Real-world-Dataset-for-Shadow-Generation" class="headerlink" title="DESOBAv2: Towards Large-scale Real-world Dataset for Shadow Generation"></a>DESOBAv2: Towards Large-scale Real-world Dataset for Shadow Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09972">http://arxiv.org/abs/2308.09972</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qingyang Liu, Jianting Wang, Li Niu</li>
<li>for: 本研究旨在生成真实的阴影，以使composite image更加真实。</li>
<li>methods: 使用object-shadow detection和inpainting技术生成阴影，并使用pretrained填充模型进行填充。</li>
<li>results: 创建了一个大规模的DESOBAv2 dataset，可以用于评估阴影生成器的性能。<details>
<summary>Abstract</summary>
Image composition refers to inserting a foreground object into a background image to obtain a composite image. In this work, we focus on generating plausible shadow for the inserted foreground object to make the composite image more realistic. To supplement the existing small-scale dataset DESOBA, we create a large-scale dataset called DESOBAv2 by using object-shadow detection and inpainting techniques. Specifically, we collect a large number of outdoor scene images with object-shadow pairs. Then, we use pretrained inpainting model to inpaint the shadow region, resulting in the deshadowed images. Based on real images and deshadowed images, we can construct pairs of synthetic composite images and ground-truth target images. Dataset is available at https://github.com/bcmi/Object-Shadow-Generation-Dataset-DESOBAv2.
</details>
<details>
<summary>摘要</summary>
Image composition指的是将前景对象 inserts 到背景图像中获得复合图像。在这种工作中，我们关注于生成合理的阴影，以使复合图像更加真实。为了补充现有的小规模数据集DESOBA，我们创建了一个大规模数据集DESOBAv2，使用对象阴影检测和填充技术。具体来说，我们收集了大量的室外场景图像和对象阴影对。然后，我们使用预训练的填充模型填充阴影区域，得到了抹掉阴影的图像。基于真实图像和抹掉阴影图像，我们可以构建对应的 sintetic 复合图像和实际目标图像的对。数据集可以在https://github.com/bcmi/Object-Shadow-Generation-Dataset-DESOBAv2上下载。
</details></li>
</ul>
<hr>
<h2 id="NeutrEx-A-3D-Quality-Component-Measure-on-Facial-Expression-Neutrality"><a href="#NeutrEx-A-3D-Quality-Component-Measure-on-Facial-Expression-Neutrality" class="headerlink" title="NeutrEx: A 3D Quality Component Measure on Facial Expression Neutrality"></a>NeutrEx: A 3D Quality Component Measure on Facial Expression Neutrality</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09963">http://arxiv.org/abs/2308.09963</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marcel Grimmer, Christian Rathgeb, Raymond Veldhuis, Christoph Busch</li>
<li>for: 这个论文的目的是提出一个基于3D人脸重建的表达质量评估方法，以便确保低质量的人脸图像不会影响辨识率。</li>
<li>methods: 这个方法使用了一个基于支持向量机器的expression辨识方法，并使用了一个预训练的对应神经网络来提取面孔嵌入。</li>
<li>results: 该方法比基于面孔嵌入的基eline方法表现出色，并且可以提供可解释的评估结果，包括每个颅骨的距离值，以帮助操作员给予有用的反馈。<details>
<summary>Abstract</summary>
Accurate face recognition systems are increasingly important in sensitive applications like border control or migration management. Therefore, it becomes crucial to quantify the quality of facial images to ensure that low-quality images are not affecting recognition accuracy. In this context, the current draft of ISO/IEC 29794-5 introduces the concept of component quality to estimate how single factors of variation affect recognition outcomes. In this study, we propose a quality measure (NeutrEx) based on the accumulated distances of a 3D face reconstruction to a neutral expression anchor. Our evaluations demonstrate the superiority of our proposed method compared to baseline approaches obtained by training Support Vector Machines on face embeddings extracted from a pre-trained Convolutional Neural Network for facial expression classification. Furthermore, we highlight the explainable nature of our NeutrEx measures by computing per-vertex distances to unveil the most impactful face regions and allow operators to give actionable feedback to subjects.
</details>
<details>
<summary>摘要</summary>
正确的面部识别系统在敏感应用中如国境控制或移民管理中日益重要。因此，它成为了评估面部图像质量的关键。在这个上下文中，ISO/IEC 29794-5 的现行稿引入了面部成分质量的概念，以估计单一因素的变化对于识别结果的影响。在这个研究中，我们提出了基于三维面部重建的累累距离对于中性表情参照点的质量指标（NeutrEx）。我们的评估结果显示，我们的提案方法比基于预训条件支持向量机器学习的面部嵌入式表情分类模型来得到更高的表现。此外，我们还高亮了我们的NeutrEx指标的可解释性，通过计算每个颅骨距离以揭露面部最重要的影响区域，并允许操作者给予适当的反馈给主体。
</details></li>
</ul>
<hr>
<h2 id="UniAP-Towards-Universal-Animal-Perception-in-Vision-via-Few-shot-Learning"><a href="#UniAP-Towards-Universal-Animal-Perception-in-Vision-via-Few-shot-Learning" class="headerlink" title="UniAP: Towards Universal Animal Perception in Vision via Few-shot Learning"></a>UniAP: Towards Universal Animal Perception in Vision via Few-shot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09953">http://arxiv.org/abs/2308.09953</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rese1f/UniAP">https://github.com/rese1f/UniAP</a></li>
<li>paper_authors: Meiqi Sun, Zhonghan Zhao, Wenhao Chai, Hanjun Luo, Shidong Cao, Yanting Zhang, Jenq-Neng Hwang, Gaoang Wang</li>
<li>for: 用于自动监测动物健康、理解动物行为和助助动物研究。</li>
<li>methods: 使用几拟学习来实现跨种动物视觉识别模型，通过共享视觉特征来传递知识。</li>
<li>results: 实现了跨种动物视觉任务的泛化和适应，可以快速适应新种类和有限数量的标注数据。<details>
<summary>Abstract</summary>
Animal visual perception is an important technique for automatically monitoring animal health, understanding animal behaviors, and assisting animal-related research. However, it is challenging to design a deep learning-based perception model that can freely adapt to different animals across various perception tasks, due to the varying poses of a large diversity of animals, lacking data on rare species, and the semantic inconsistency of different tasks. We introduce UniAP, a novel Universal Animal Perception model that leverages few-shot learning to enable cross-species perception among various visual tasks. Our proposed model takes support images and labels as prompt guidance for a query image. Images and labels are processed through a Transformer-based encoder and a lightweight label encoder, respectively. Then a matching module is designed for aggregating information between prompt guidance and the query image, followed by a multi-head label decoder to generate outputs for various tasks. By capitalizing on the shared visual characteristics among different animals and tasks, UniAP enables the transfer of knowledge from well-studied species to those with limited labeled data or even unseen species. We demonstrate the effectiveness of UniAP through comprehensive experiments in pose estimation, segmentation, and classification tasks on diverse animal species, showcasing its ability to generalize and adapt to new classes with minimal labeled examples.
</details>
<details>
<summary>摘要</summary>
生物视觉技术是重要的自动监测动物健康、理解动物行为和帮助动物研究的方法。然而，设计一个基于深度学习的视觉感知模型，能够自由地适应不同的动物和多种视觉任务，是一项挑战。这是因为动物的姿势变化多样、罕见的种类缺乏数据，以及不同任务的semantic不一致。我们介绍UniAP，一种新的通用动物感知模型，利用几何学学习来实现跨种pecie的视觉感知。我们提posed模型通过在支持图像和标签作为引导图像的query图像。图像和标签通过Transformer基于encoder和轻量级标签encoder处理。然后，我们设计了一个匹配模块，用于聚合引导图像和查询图像之间的信息，并由一个多头标签解码器生成多种任务的输出。通过利用不同动物和任务之间的共同视觉特征，UniAP允许知识从已经学习的种类传递到有限数据或者even未经见过的种类。我们通过对多种动物种类的pose估计、分割和分类任务进行了广泛的实验，证明UniAP的有效性，并显示其能够通过少量标签示例进行泛化和适应新类。
</details></li>
</ul>
<hr>
<h2 id="Semantics-Meets-Temporal-Correspondence-Self-supervised-Object-centric-Learning-in-Videos"><a href="#Semantics-Meets-Temporal-Correspondence-Self-supervised-Object-centric-Learning-in-Videos" class="headerlink" title="Semantics Meets Temporal Correspondence: Self-supervised Object-centric Learning in Videos"></a>Semantics Meets Temporal Correspondence: Self-supervised Object-centric Learning in Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09951">http://arxiv.org/abs/2308.09951</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui Qian, Shuangrui Ding, Xian Liu, Dahua Lin</li>
<li>for: 本 paper 旨在强化对象中心表示，提高视频对象发现和分类性能。</li>
<li>methods: 该 paper 使用了自助学习方法，包括 query slot attention 和 random sampling based slot attention，以提取高级 semantics 和低级时间匹配信息。另外，它还提出了一种新的masked slot attention方法，以强化对象中心表示。</li>
<li>results: 该 paper 的实验结果表明，使用自助学习方法和masked slot attention可以提高视频对象发现和分类性能，并且可以实现对象中心表示。此外，它还达到了 dense label propagation 任务的最佳性能，demonstrating the potential for object-centric analysis。<details>
<summary>Abstract</summary>
Self-supervised methods have shown remarkable progress in learning high-level semantics and low-level temporal correspondence. Building on these results, we take one step further and explore the possibility of integrating these two features to enhance object-centric representations. Our preliminary experiments indicate that query slot attention can extract different semantic components from the RGB feature map, while random sampling based slot attention can exploit temporal correspondence cues between frames to assist instance identification. Motivated by this, we propose a novel semantic-aware masked slot attention on top of the fused semantic features and correspondence maps. It comprises two slot attention stages with a set of shared learnable Gaussian distributions. In the first stage, we use the mean vectors as slot initialization to decompose potential semantics and generate semantic segmentation masks through iterative attention. In the second stage, for each semantics, we randomly sample slots from the corresponding Gaussian distribution and perform masked feature aggregation within the semantic area to exploit temporal correspondence patterns for instance identification. We adopt semantic- and instance-level temporal consistency as self-supervision to encourage temporally coherent object-centric representations. Our model effectively identifies multiple object instances with semantic structure, reaching promising results on unsupervised video object discovery. Furthermore, we achieve state-of-the-art performance on dense label propagation tasks, demonstrating the potential for object-centric analysis. The code is released at https://github.com/shvdiwnkozbw/SMTC.
</details>
<details>
<summary>摘要</summary>
自我监督方法已经在学习高级 semantics 和低级时间匹配方面进行了非常出色的进步。基于这些结果，我们尝试一步更远，探索将这两个特征集成到对象中心表示中以提高对象识别的可能性。我们的初步实验表明，Query slot attention可以从 RGB 特征地图中提取不同的semantic 分量，而Random sampling based slot attention可以在帧中使用时间匹配规律来帮助实例识别。这些灵感下，我们提议一种新的semantic-aware masked slot attention，它包括两个槽注意阶段，每个阶段都有一组共享学习的Gaussian 分布。在第一个阶段，我们使用极值向量作为槽初始化，以iterative attention decomposition potential semantics并生成semantic segmentation mask。在第二个阶段，对每个semantics，我们随机从相应的Gaussian分布中选择槽，并在semantic区域内进行masked feature aggregation，以利用时间匹配模式来提高实例识别。我们采用semantic-和instance-level时间一致性自我监督，以鼓励对象中心表示的时间一致性。我们的模型能够有效地识别多个对象实例，同时保持semantic结构，在无监督视频对象发现任务中达到了可观的结果。此外，我们在 dense label propagation 任务中实现了state-of-the-art 性能，表明对象中心分析的潜力。代码可以在 <https://github.com/shvdiwnkozbw/SMTC> 上下载。
</details></li>
</ul>
<hr>
<h2 id="Scene-Aware-Feature-Matching"><a href="#Scene-Aware-Feature-Matching" class="headerlink" title="Scene-Aware Feature Matching"></a>Scene-Aware Feature Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09949">http://arxiv.org/abs/2308.09949</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/USTCPCS/CVPR2018_attention">https://github.com/USTCPCS/CVPR2018_attention</a></li>
<li>paper_authors: Xiaoyong Lu, Yaping Yan, Tong Wei, Songlin Du</li>
<li>for: The paper is written for improving the performance of feature matching in computer vision tasks, particularly in handling challenging scenes with large viewpoint and illumination changes.</li>
<li>methods: The paper proposes a novel model named SAM, which applies attentional grouping to guide Scene-Aware feature Matching. The model uses attention layers to handle multi-level features, including image tokens and group tokens, and groups the image tokens with the proposed token grouping module.</li>
<li>results: The paper achieves state-of-the-art performance on various applications, including homography estimation, pose estimation, and image matching, and demonstrates that the proposed model is more accurate, robust, and interpretable than conventional feature matching models.<details>
<summary>Abstract</summary>
Current feature matching methods focus on point-level matching, pursuing better representation learning of individual features, but lacking further understanding of the scene. This results in significant performance degradation when handling challenging scenes such as scenes with large viewpoint and illumination changes. To tackle this problem, we propose a novel model named SAM, which applies attentional grouping to guide Scene-Aware feature Matching. SAM handles multi-level features, i.e., image tokens and group tokens, with attention layers, and groups the image tokens with the proposed token grouping module. Our model can be trained by ground-truth matches only and produce reasonable grouping results. With the sense-aware grouping guidance, SAM is not only more accurate and robust but also more interpretable than conventional feature matching models. Sufficient experiments on various applications, including homography estimation, pose estimation, and image matching, demonstrate that our model achieves state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
当前的特征匹配方法主要关注点级匹配，尝试更好地学习个体特征的表示学习，但缺乏更深入的场景理解。这会导致对复杂场景（如大视角和照明变化）的处理而受到显著性能下降。为解决这个问题，我们提出了一种新的模型，即SAM，它通过注意力组合来引导场景意识的特征匹配。SAM处理多级特征，即图像token和组token，使用注意力层，并通过我们提议的token grouping模块将图像token分组。我们的模型可以通过真实匹配只需要训练，并且生成合理的分组结果。与传统的特征匹配模型相比，SAM不仅更准确和Robust，还更易于解释。我们在多种应用，包括Homography估计、pose估计和图像匹配等，进行了详细的实验，结果显示我们的模型在状态艺术性能。
</details></li>
</ul>
<hr>
<h2 id="Weakly-Supervised-Action-Localization-by-Hierarchically-structured-Latent-Attention-Modeling"><a href="#Weakly-Supervised-Action-Localization-by-Hierarchically-structured-Latent-Attention-Modeling" class="headerlink" title="Weakly-Supervised Action Localization by Hierarchically-structured Latent Attention Modeling"></a>Weakly-Supervised Action Localization by Hierarchically-structured Latent Attention Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09946">http://arxiv.org/abs/2308.09946</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guiqin Wang, Peng Zhao, Cong Zhao, Shusen Yang, Jie Cheng, Luziwei Leng, Jianxing Liao, Qinghai Guo</li>
<li>for: 这个论文主要针对的是强度不足的动作地理学问题，即在没有时间标注的视频中识别和地理化动作实例。</li>
<li>methods: 我们提出了一种新的注意力基于层次结构的隐藏模型，用于学习视频特征的时间变化 semantics。该模型包括两个组件：第一个是一个不supervised的变化点检测模块，通过学习视频特征的时间层次结构来检测变化点；第二个是一个注意力基于分类模型，用于选择变化点的背景。</li>
<li>results: 我们在THUMOS-14和ActivityNet-v1.3两个 benchmark dataset上进行了广泛的实验，结果显示，我们的方法可以比现有的方法表现更好，甚至与完全监督的方法相当。<details>
<summary>Abstract</summary>
Weakly-supervised action localization aims to recognize and localize action instancese in untrimmed videos with only video-level labels. Most existing models rely on multiple instance learning(MIL), where the predictions of unlabeled instances are supervised by classifying labeled bags. The MIL-based methods are relatively well studied with cogent performance achieved on classification but not on localization. Generally, they locate temporal regions by the video-level classification but overlook the temporal variations of feature semantics. To address this problem, we propose a novel attention-based hierarchically-structured latent model to learn the temporal variations of feature semantics. Specifically, our model entails two components, the first is an unsupervised change-points detection module that detects change-points by learning the latent representations of video features in a temporal hierarchy based on their rates of change, and the second is an attention-based classification model that selects the change-points of the foreground as the boundaries. To evaluate the effectiveness of our model, we conduct extensive experiments on two benchmark datasets, THUMOS-14 and ActivityNet-v1.3. The experiments show that our method outperforms current state-of-the-art methods, and even achieves comparable performance with fully-supervised methods.
</details>
<details>
<summary>摘要</summary>
weakly-supervised action localization aims to recognize and localize action instances in untrimmed videos with only video-level labels. most existing models rely on multiple instance learning(MIL), where the predictions of unlabeled instances are supervised by classifying labeled bags. the MIL-based methods are relatively well studied with cogent performance achieved on classification but not on localization. generally, they locate temporal regions by the video-level classification but overlook the temporal variations of feature semantics. to address this problem, we propose a novel attention-based hierarchically-structured latent model to learn the temporal variations of feature semantics. specifically, our model entails two components, the first is an unsupervised change-points detection module that detects change-points by learning the latent representations of video features in a temporal hierarchy based on their rates of change, and the second is an attention-based classification model that selects the change-points of the foreground as the boundaries. to evaluate the effectiveness of our model, we conduct extensive experiments on two benchmark datasets, THUMOS-14 and ActivityNet-v1.3. the experiments show that our method outperforms current state-of-the-art methods, and even achieves comparable performance with fully-supervised methods.Here's the text with traditional Chinese characters:weakly-supervised action localization aims to recognize and localize action instances in untrimmed videos with only video-level labels. most existing models rely on multiple instance learning(MIL), where the predictions of unlabeled instances are supervised by classifying labeled bags. the MIL-based methods are relatively well studied with cogent performance achieved on classification but not on localization. generally, they locate temporal regions by the video-level classification but overlook the temporal variations of feature semantics. to address this problem, we propose a novel attention-based hierarchically-structured latent model to learn the temporal variations of feature semantics. specifically, our model entails two components, the first is an unsupervised change-points detection module that detects change-points by learning the latent representations of video features in a temporal hierarchy based on their rates of change, and the second is an attention-based classification model that selects the change-points of the foreground as the boundaries. to evaluate the effectiveness of our model, we conduct extensive experiments on two benchmark datasets, THUMOS-14 and ActivityNet-v1.3. the experiments show that our method outperforms current state-of-the-art methods, and even achieves comparable performance with fully-supervised methods.
</details></li>
</ul>
<hr>
<h2 id="Dual-Branch-Deep-Learning-Network-for-Detection-and-Stage-Grading-of-Diabetic-Retinopathy"><a href="#Dual-Branch-Deep-Learning-Network-for-Detection-and-Stage-Grading-of-Diabetic-Retinopathy" class="headerlink" title="Dual Branch Deep Learning Network for Detection and Stage Grading of Diabetic Retinopathy"></a>Dual Branch Deep Learning Network for Detection and Stage Grading of Diabetic Retinopathy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09945">http://arxiv.org/abs/2308.09945</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hossein Shakibania, Sina Raoufi, Behnam Pourafkham, Hassan Khotanlou, Muharram Mansoorizadeh</li>
<li>for: 这篇论文旨在提出一种基于深度学习的视网膜病变检测和分级方法，以帮助早期识别和治疗糖尿病 relacionais complications。</li>
<li>methods: 本论文使用了两个现有的优秀预训练模型作为特征提取器，并对其进行了微调，以适应一个新的数据集。模型在一个大型多中心数据集上进行了训练，包括APTOS 2019数据集。</li>
<li>results: 本论文的提出的方法在APTOS 2019数据集上实现了优秀的视网膜病变检测和分级性能，比过去Literature中的成果更高。在二分类任务中，提出的方法取得了98.50%的准确率，99.46%的敏感度和97.51%的特异度。在分级任务中，它取得了93.00%的 quadratic weighted kappa，89.60%的准确率，89.60%的敏感度和97.72%的特异度。<details>
<summary>Abstract</summary>
Diabetic retinopathy is a severe complication of diabetes that can lead to permanent blindness if not treated promptly. Early and accurate diagnosis of the disease is essential for successful treatment. This paper introduces a deep learning method for the detection and stage grading of diabetic retinopathy, using a single fundus retinal image. Our model utilizes transfer learning, employing two state-of-the-art pre-trained models as feature extractors and fine-tuning them on a new dataset. The proposed model is trained on a large multi-center dataset, including the APTOS 2019 dataset, obtained from publicly available sources. It achieves remarkable performance in diabetic retinopathy detection and stage classification on the APTOS 2019, outperforming the established literature. For binary classification, the proposed approach achieves an accuracy of 98.50%, a sensitivity of 99.46%, and a specificity of 97.51%. In stage grading, it achieves a quadratic weighted kappa of 93.00%, an accuracy of 89.60%, a sensitivity of 89.60%, and a specificity of 97.72%. The proposed approach serves as a reliable screening and stage grading tool for diabetic retinopathy, offering significant potential to enhance clinical decision-making and patient care.
</details>
<details>
<summary>摘要</summary>
糖尿病 retinopathy 是糖尿病的严重合并症状，可能会导致永久潦倒盲视，如果不及时治疗。早期和准确的诊断是治疗的关键。本文介绍了一种深度学习方法，用于检测和评分糖尿病 retinopathy，只需要一张背景照片。我们的模型使用了传输学习，利用了两个现有的状态体验模型作为特征提取器，并在新的数据集上进行了微调。我们的模型在APTOS 2019 数据集上进行了训练，包括公共可用的数据集。它在糖尿病 retinopathy 检测和评分中实现了显著的表现，超过了现有文献。对二分类问题，我们的方法实现了98.50%的准确率，99.46%的敏感度和97.51%的特异度。在评分方面，我们的方法实现了93.00%的 quadratic 权重κ值，89.60%的准确率，89.60%的敏感度和97.72%的特异度。我们的方法可以作为糖尿病 retinopathy 的可靠检测和评分工具，提供了对临床决策和患者护理的显著潜在优势。
</details></li>
</ul>
<hr>
<h2 id="On-the-Robustness-of-Open-World-Test-Time-Training-Self-Training-with-Dynamic-Prototype-Expansion"><a href="#On-the-Robustness-of-Open-World-Test-Time-Training-Self-Training-with-Dynamic-Prototype-Expansion" class="headerlink" title="On the Robustness of Open-World Test-Time Training: Self-Training with Dynamic Prototype Expansion"></a>On the Robustness of Open-World Test-Time Training: Self-Training with Dynamic Prototype Expansion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09942">http://arxiv.org/abs/2308.09942</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yushu-li/owttt">https://github.com/yushu-li/owttt</a></li>
<li>paper_authors: Yushu Li, Xun Xu, Yongyi Su, Kui Jia</li>
<li>for: 这篇论文旨在提高 unknown target domain distribution 下的 deep learning 模型鲁棒性，并且可以在低延迟下进行 test-time training&#x2F;adaptation (TTT&#x2F;TTA)。</li>
<li>methods: 该论文提出了一种 adaptive strong OOD pruning 技术，以及一种动态扩展 prototype 以区分强 OOD 样本和弱 OOD 样本。此外，论文还提出了一种 distribution alignment REG regularization，以提高 self-training 的效果。</li>
<li>results: 该论文在 5 个 OWTTT benchmark 上达到了 state-of-the-art 性能。<details>
<summary>Abstract</summary>
Generalizing deep learning models to unknown target domain distribution with low latency has motivated research into test-time training/adaptation (TTT/TTA). Existing approaches often focus on improving test-time training performance under well-curated target domain data. As figured out in this work, many state-of-the-art methods fail to maintain the performance when the target domain is contaminated with strong out-of-distribution (OOD) data, a.k.a. open-world test-time training (OWTTT). The failure is mainly due to the inability to distinguish strong OOD samples from regular weak OOD samples. To improve the robustness of OWTTT we first develop an adaptive strong OOD pruning which improves the efficacy of the self-training TTT method. We further propose a way to dynamically expand the prototypes to represent strong OOD samples for an improved weak/strong OOD data separation. Finally, we regularize self-training with distribution alignment and the combination yields the state-of-the-art performance on 5 OWTTT benchmarks. The code is available at https://github.com/Yushu-Li/OWTTT.
</details>
<details>
<summary>摘要</summary>
通用深度学习模型到未知目标频率分布下进行普通化（Test-Time Training/Adaptation，TTT/TTA）已经引起了研究者的关注。现有的方法 oftentimes 专注于在well-curated 目标频率数据下提高测试时训练性能。在这项工作中，我们发现许多状态 искусственный智能方法在受到强外部数据杂化（Out-of-Distribution，OOD）影响时失效，主要原因是不能正确分辨强OOD样本和弱OOD样本。为了改善OWTTT的Robustness，我们首先开发了适应强OOD检索，该方法可以提高自动训练 TTT 方法的效果。我们还提出了在运行时动态扩展prototype来表示强OOD样本，以提高弱/强OOD数据的分离。最后，我们使用分布对齐和组合，并得到了5个OWTTT benchmark上的状态对齐性。代码可以在https://github.com/Yushu-Li/OWTTT中找到。
</details></li>
</ul>
<hr>
<h2 id="BLIVA-A-Simple-Multimodal-LLM-for-Better-Handling-of-Text-Rich-Visual-Questions"><a href="#BLIVA-A-Simple-Multimodal-LLM-for-Better-Handling-of-Text-Rich-Visual-Questions" class="headerlink" title="BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual Questions"></a>BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09936">http://arxiv.org/abs/2308.09936</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlpc-ucsd/bliva">https://github.com/mlpc-ucsd/bliva</a></li>
<li>paper_authors: Wenbo Hu, Yifan Xu, Yi Li, Weiyue Li, Zeyuan Chen, Zhuowen Tu</li>
<li>for: 提高实际图像中文本的理解和处理能力，以便更好地解决实际场景中的视觉问答任务。</li>
<li>methods:  combines InstructBLIP和Visual Assistant，Directly project encoded patch embeddings into the LLM，以帮助模型更好地捕捉图像中的细节。</li>
<li>results: 在处理文本含有图像的VQA benchmark tasks上显著提高性能（up to 17.76% in OCR-VQA benchmark），并在典型VQA benchmark tasks上也获得了显著提高（up to 7.9% in Visual Spatial Reasoning benchmark），并且可以在实际图像中处理文本不存在的情况下也表现出色。<details>
<summary>Abstract</summary>
Vision Language Models (VLMs), which extend Large Language Models (LLM) by incorporating visual understanding capability, have demonstrated significant advancements in addressing open-ended visual question-answering (VQA) tasks. However, these models cannot accurately interpret images infused with text, a common occurrence in real-world scenarios. Standard procedures for extracting information from images often involve learning a fixed set of query embeddings. These embeddings are designed to encapsulate image contexts and are later used as soft prompt inputs in LLMs. Yet, this process is limited to the token count, potentially curtailing the recognition of scenes with text-rich context. To improve upon them, the present study introduces BLIVA: an augmented version of InstructBLIP with Visual Assistant. BLIVA incorporates the query embeddings from InstructBLIP and also directly projects encoded patch embeddings into the LLM, a technique inspired by LLaVA. This approach assists the model to capture intricate details potentially missed during the query decoding process. Empirical evidence demonstrates that our model, BLIVA, significantly enhances performance in processing text-rich VQA benchmarks (up to 17.76\% in OCR-VQA benchmark) and in undertaking typical VQA benchmarks (up to 7.9\% in Visual Spatial Reasoning benchmark), comparing to our baseline InstructBLIP. BLIVA demonstrates significant capability in decoding real-world images, irrespective of text presence. To demonstrate the broad industry applications enabled by BLIVA, we evaluate the model using a new dataset comprising YouTube thumbnails paired with question-answer sets across 13 diverse categories. For researchers interested in further exploration, our code and models are freely accessible at https://github.com/mlpc-ucsd/BLIVA.git
</details>
<details>
<summary>摘要</summary>
大多数视语模型（VLM）通过结合视觉理解能力和大语言模型（LLM）来解决开放式视觉问答（VQA）任务，但是这些模型无法正确地理解包含文本的图像，这是现实世界中非常常见的情况。标准的图像信息抽取方法通常包括学习固定的查询嵌入。这些嵌入是用于捕捉图像上下文，并且在LLM中使用为软提示输入。然而，这种过程受到固定嵌入数量的限制，可能会遮盖捕捉场景中的文本背景。为了解决这个问题，本研究提出了BLIVA：一种基于InstructBLIP的增强版，它包括InstructBLIP的查询嵌入以及直接将编码补丁嵌入 proyect到LLM中，这种方法灵感于LLaVA。这种方法帮助模型捕捉细节信息，可能在查询解码过程中被遗弃。实验证明，我们的模型BLIVA在处理具有文本背景的VQA benchmark中表现出色，与基线InstructBLIP相比，提高了17.76%（在OCR-VQA benchmark中）和7.9%（在Visual Spatial Reasoning benchmark中）。BLIVA示出了在现实图像中捕捉文本背景的能力，不受文本存在或不存在的限制。为了展示BLIVA在广泛的 industrielles 应用中的可能性，我们使用了一个新的 YouTube 频道封面和问答集合，并对13种不同的类别进行评估。如果您想进一步探索，我们的代码和模型都可以免费下载于https://github.com/mlpc-ucsd/BLIVA.git。
</details></li>
</ul>
<hr>
<h2 id="TDG-Text-guided-Domain-Generalization"><a href="#TDG-Text-guided-Domain-Generalization" class="headerlink" title="TDG: Text-guided Domain Generalization"></a>TDG: Text-guided Domain Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09931">http://arxiv.org/abs/2308.09931</a></li>
<li>repo_url: None</li>
<li>paper_authors: Geng Liu, Yuxi Wang</li>
<li>for: 本文旨在推广基于单个或多个源领域的模型到未见的目标领域。</li>
<li>methods: 我们提出了一种新的文本引导领域泛化（TDG）方法，包括三个方面：首先，我们开发了一种自动生成域特有词汇的方法，以扩展当前领域的描述。然后，我们使用提案学习基于文本特征生成方法，将生成的域信息与图像特征共同卷积在同一个表示空间中。最后，我们使用输入图像特征和生成的文本特征来训练一个特殊的分类器，以便在未见目标领域中进行泛化。</li>
<li>results: 我们的实验结果表明，通过在TDG中引入生成的文本信息，可以提高领域泛化的性能，而且这种方法的实现非常容易。我们在多个领域泛化 benchmark 上进行了实验，并证明了我们的提出的框架可以在不同的领域中达到更高的性能。<details>
<summary>Abstract</summary>
Domain generalization (DG) attempts to generalize a model trained on single or multiple source domains to the unseen target domain. Benefiting from the success of Visual-and-Language Pre-trained models in recent years, we argue that it is crucial for domain generalization by introducing extra text information. In this paper, we develop a novel Text-guided Domain Generalization (TDG) paradigm for domain generalization, which includes three following aspects. Specifically, we first devise an automatic words generation method to extend the description of current domains with novel domain-relevant words. Then, we embed the generated domain information into the text feature space, by the proposed prompt learning-based text feature generation method, which shares a common representation space with the image feature. Finally, we utilize both input image features and generated text features to train a specially designed classifier that generalizes well on unseen target domains, while the image encoder is also updated under the supervision of gradients back propagated from the classifier. Our experimental results show that the techniques incorporated by TDG contribute to the performance in an easy implementation manner. Experimental results on several domain generalization benchmarks show that our proposed framework achieves superior performance by effectively leveraging generated text information in domain generalization.
</details>
<details>
<summary>摘要</summary>
域间泛化（DG）目标是将单个或多个源域模型泛化到未看过的目标域。受最近几年视觉语言预训模型的成功影响，我们认为在域间泛化中具有重要作用的是引入文本信息。在这篇论文中，我们提出了一种新的文本准导域泛化（TDG）方法，它包括以下三个方面：首先，我们开发了一种自动生成域关键词方法，以扩展当前域的描述，并添加新域相关的词语。然后，我们将生成的域信息embedded到文本特征空间中，通过我们提出的提示学习基于文本特征生成方法，这个方法与图像特征空间共享表示。最后，我们利用输入图像特征和生成的文本特征来训练一个专门设计的分类器，这个分类器可以在未看过的目标域上进行广泛的泛化，而图像编码器也在分类器的监督下更新。我们的实验结果表明，TDG方法可以在易于实现的情况下提高域泛化的性能。我们在多个域泛化 benchmark 上进行了实验，并证明了我们提出的方法可以有效地利用生成的文本信息，以提高域泛化的性能。
</details></li>
</ul>
<hr>
<h2 id="MDCS-More-Diverse-Experts-with-Consistency-Self-distillation-for-Long-tailed-Recognition"><a href="#MDCS-More-Diverse-Experts-with-Consistency-Self-distillation-for-Long-tailed-Recognition" class="headerlink" title="MDCS: More Diverse Experts with Consistency Self-distillation for Long-tailed Recognition"></a>MDCS: More Diverse Experts with Consistency Self-distillation for Long-tailed Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09922">http://arxiv.org/abs/2308.09922</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fistyee/mdcs">https://github.com/fistyee/mdcs</a></li>
<li>paper_authors: Qihao Zhao, Chen Jiang, Wei Hu, Fan Zhang, Jun Liu</li>
<li>for: 提高长尾识别（LTR）精度</li>
<li>methods: 使用更多的专家和自我泛化（CS）提高模型的多样性和稳定性</li>
<li>results: 与先前方法比较，MDCS方法可以提高识别精度，降低模型的偏差，并提高专家的多样性。在五个流行的长尾识别 bencmarks 上，MDCS方法比前一代 лучperform，提高精度1% 至 2%。<details>
<summary>Abstract</summary>
Recently, multi-expert methods have led to significant improvements in long-tail recognition (LTR). We summarize two aspects that need further enhancement to contribute to LTR boosting: (1) More diverse experts; (2) Lower model variance. However, the previous methods didn't handle them well. To this end, we propose More Diverse experts with Consistency Self-distillation (MDCS) to bridge the gap left by earlier methods. Our MDCS approach consists of two core components: Diversity Loss (DL) and Consistency Self-distillation (CS). In detail, DL promotes diversity among experts by controlling their focus on different categories. To reduce the model variance, we employ KL divergence to distill the richer knowledge of weakly augmented instances for the experts' self-distillation. In particular, we design Confident Instance Sampling (CIS) to select the correctly classified instances for CS to avoid biased/noisy knowledge. In the analysis and ablation study, we demonstrate that our method compared with previous work can effectively increase the diversity of experts, significantly reduce the variance of the model, and improve recognition accuracy. Moreover, the roles of our DL and CS are mutually reinforcing and coupled: the diversity of experts benefits from the CS, and the CS cannot achieve remarkable results without the DL. Experiments show our MDCS outperforms the state-of-the-art by 1% $\sim$ 2% on five popular long-tailed benchmarks, including CIFAR10-LT, CIFAR100-LT, ImageNet-LT, Places-LT, and iNaturalist 2018. The code is available at https://github.com/fistyee/MDCS.
</details>
<details>
<summary>摘要</summary>
近些时间，多专家方法已经导致长尾识别（LTR）中的显著改进。我们总结了两个需要进一步改进以提高LTR的方面：（1）更多的专家；（2）模型变量下降。然而，之前的方法没有很好地处理这两个方面。为此，我们提出了更多的专家与自我照成（MDCS），以填补之前方法留下的差距。我们的MDCS方法包括两个核心组成部分：多样性损失（DL）和自我照成（CS）。在详细说明下，DL使得专家们对不同类别的焦点控制，以提高多样性。为了降低模型变量，我们使用KL散度来让弱增强的实例对专家自我照成进行泛化。特别是，我们设计了信心实例选择（CIS），以确保选择正确分类的实例，以避免偏倚/噪音知识。我们的分析和割裁研究表明，与之前的工作相比，我们的方法可以有效增加专家的多样性，显著降低模型变量，并提高识别精度。此外，我们的DL和CS之间存在互相强化和结合关系：专家的多样性受益于CS，而CS无法取得显著成果不包括DL。实验表明，我们的MDCS在五个流行的长尾benchmark上比前一个最佳的实现1% $\sim$ 2%的提高。代码可以在https://github.com/fistyee/MDCS上获取。
</details></li>
</ul>
<hr>
<h2 id="VI-Net-Boosting-Category-level-6D-Object-Pose-Estimation-via-Learning-Decoupled-Rotations-on-the-Spherical-Representations"><a href="#VI-Net-Boosting-Category-level-6D-Object-Pose-Estimation-via-Learning-Decoupled-Rotations-on-the-Spherical-Representations" class="headerlink" title="VI-Net: Boosting Category-level 6D Object Pose Estimation via Learning Decoupled Rotations on the Spherical Representations"></a>VI-Net: Boosting Category-level 6D Object Pose Estimation via Learning Decoupled Rotations on the Spherical Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09916">http://arxiv.org/abs/2308.09916</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiehonglin/vi-net">https://github.com/jiehonglin/vi-net</a></li>
<li>paper_authors: Jiehong Lin, Zewei Wei, Yabin Zhang, Kui Jia</li>
<li>for: 高精度 объекpose数据集上的6D对象pose估计，即使没有可用的CAD模型。</li>
<li>methods: 提议一种新的旋转估计网络，名为VI-Net，它通过分解旋转为视点旋转和平面旋转的组合来简化非线性空间SO(3)中的学习。</li>
<li>results: 实验表明，提议的VI-Net方法在高精度 regime下可以大幅超过现有方法。<details>
<summary>Abstract</summary>
Rotation estimation of high precision from an RGB-D object observation is a huge challenge in 6D object pose estimation, due to the difficulty of learning in the non-linear space of SO(3). In this paper, we propose a novel rotation estimation network, termed as VI-Net, to make the task easier by decoupling the rotation as the combination of a viewpoint rotation and an in-plane rotation. More specifically, VI-Net bases the feature learning on the sphere with two individual branches for the estimates of two factorized rotations, where a V-Branch is employed to learn the viewpoint rotation via binary classification on the spherical signals, while another I-Branch is used to estimate the in-plane rotation by transforming the signals to view from the zenith direction. To process the spherical signals, a Spherical Feature Pyramid Network is constructed based on a novel design of SPAtial Spherical Convolution (SPA-SConv), which settles the boundary problem of spherical signals via feature padding and realizesviewpoint-equivariant feature extraction by symmetric convolutional operations. We apply the proposed VI-Net to the challenging task of category-level 6D object pose estimation for predicting the poses of unknown objects without available CAD models; experiments on the benchmarking datasets confirm the efficacy of our method, which outperforms the existing ones with a large margin in the regime of high precision.
</details>
<details>
<summary>摘要</summary>
rotation 估计高精度从RGB-D对象观察是6D对象pose估计中的巨大挑战，由于非线性空间SO(3)学习的困难。在本文中，我们提出了一种新的 rotate estimation network，称为VI-Net，以使任务更加容易，通过分解旋转为两个因素旋转的组合。更具体地说，VI-Net基于特有的SPAtial Spherical Convolution（SPA-SConv）设计，在特定的圆形信号上进行特征学习，并通过将信号变换到zenith方向来估计平面旋转。为处理圆形信号，我们构建了一个叫做Spherical Feature Pyramid Network（SFPN），该网络通过特有的SPA-SConv设计解决了圆形信号的边界问题，并实现了视角平衡的特征提取。我们应用提出的VI-Net来解决6D对象pose估计中的category-level高精度任务，对于未知对象而言，不需要可用的CAD模型；在标准测试集上进行了实验，并证明了我们的方法在高精度 режи下表现出了明显的优势。
</details></li>
</ul>
<hr>
<h2 id="EGANS-Evolutionary-Generative-Adversarial-Network-Search-for-Zero-Shot-Learning"><a href="#EGANS-Evolutionary-Generative-Adversarial-Network-Search-for-Zero-Shot-Learning" class="headerlink" title="EGANS: Evolutionary Generative Adversarial Network Search for Zero-Shot Learning"></a>EGANS: Evolutionary Generative Adversarial Network Search for Zero-Shot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09915">http://arxiv.org/abs/2308.09915</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiming Chen, Shihuang Chen, Wenjin Hou, Weiping Ding, Xinge You</li>
<li>for: 这篇论文的目的是提出一种基于进化的对抗学习方法（EGANS），以自动设计适应性和稳定性优化的生成网络，并在不同数据集&#x2F;场景下进行可靠的视觉特征样本生成，以提高零对零学习（ZSL）的性能。</li>
<li>methods: 这篇论文使用了协同对抗进化搜索（cooperative dual evolution）来进行神经网络架构搜索，包括生成器和检测器两个部分。在演化生成器架构搜索阶段，运用了多对一对抗训练策略来演化生成器。然后，使用了相似的演化搜索算法来进行检测器架构搜索。</li>
<li>results: 实验结果显示，EGANS可以稳定地提高现有的生成ZSL方法的性能，在标准的CUB、SUN、AWA2和FLO数据集上均有显著的表现提升。这些表现提升显示了进化性的神经架构搜索在ZSL领域中的可能性。<details>
<summary>Abstract</summary>
Zero-shot learning (ZSL) aims to recognize the novel classes which cannot be collected for training a prediction model. Accordingly, generative models (e.g., generative adversarial network (GAN)) are typically used to synthesize the visual samples conditioned by the class semantic vectors and achieve remarkable progress for ZSL. However, existing GAN-based generative ZSL methods are based on hand-crafted models, which cannot adapt to various datasets/scenarios and fails to model instability. To alleviate these challenges, we propose evolutionary generative adversarial network search (termed EGANS) to automatically design the generative network with good adaptation and stability, enabling reliable visual feature sample synthesis for advancing ZSL. Specifically, we adopt cooperative dual evolution to conduct a neural architecture search for both generator and discriminator under a unified evolutionary adversarial framework. EGANS is learned by two stages: evolution generator architecture search and evolution discriminator architecture search. During the evolution generator architecture search, we adopt a many-to-one adversarial training strategy to evolutionarily search for the optimal generator. Then the optimal generator is further applied to search for the optimal discriminator in the evolution discriminator architecture search with a similar evolution search algorithm. Once the optimal generator and discriminator are searched, we entail them into various generative ZSL baselines for ZSL classification. Extensive experiments show that EGANS consistently improve existing generative ZSL methods on the standard CUB, SUN, AWA2 and FLO datasets. The significant performance gains indicate that the evolutionary neural architecture search explores a virgin field in ZSL.
</details>
<details>
<summary>摘要</summary>
zero-shot learning（ZSL）的目标是识别无法在训练预测模型的新类。因此，通常使用生成模型（如生成对抗网络（GAN））来生成基于类含义 вектор的视觉样本，并取得了remarkable进步。然而，现有的GAN基于的生成ZSL方法都是基于手工设计的模型，无法适应不同的数据集/场景，并且容易出现模型不稳定的问题。为了解决这些挑战，我们提出了进化生成对抗网络搜索（EGANS），用于自动设计生成网络，以便在不同数据集/场景中具有良好的适应和稳定性，从而实现可靠的视觉特征样本生成，以提高ZSL的进步。EGANS采用了合作双向进化来进行神经网络搜索，包括生成器和判断器的搜索。在生成器搜索阶段，我们采用了多对一对抗训练策略来进行进化搜索，以找到最佳的生成器。然后，我们将最佳的生成器应用于判断器搜索阶段，通过类似的进化搜索策略来找到最佳的判断器。一旦找到了最佳的生成器和判断器，我们将它们与不同的生成ZSL基线方法进行比较，以评估EGANS的性能。实验结果表明，EGANS在标准的CUB、SUN、AWA2和FLO数据集上具有显著的性能提升，这表明了进化神经网络搜索在ZSL中探索了一个新的领域。
</details></li>
</ul>
<hr>
<h2 id="Noisy-Correspondence-Learning-for-Text-to-Image-Person-Re-identification"><a href="#Noisy-Correspondence-Learning-for-Text-to-Image-Person-Re-identification" class="headerlink" title="Noisy-Correspondence Learning for Text-to-Image Person Re-identification"></a>Noisy-Correspondence Learning for Text-to-Image Person Re-identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09911">http://arxiv.org/abs/2308.09911</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tencentyouturesearch/personretrieval-ivt">https://github.com/tencentyouturesearch/personretrieval-ivt</a></li>
<li>paper_authors: Yang Qin, Yingke Chen, Dezhong Peng, Xi Peng, Joey Tianyi Zhou, Peng Hu</li>
<li>for: 提高 Text-to-image person re-identification（TIReID）方法的Robustness，以便在实际场景中处理受到干扰的图像和文本对应关系。</li>
<li>methods: 提出了一种名为 Robust Dual Embedding（RDE）的新方法，包括两个主要组成部分：1）一个Confident Consensus Division（CCD）模块，利用双重排序模块的双重决策来获取一个纯净的训练数据集，以便学习正确和可靠的视Semantic关系。2）一个Triplet-Alignment Loss（TAL），将传统的 triplet-ranking损失函数改进为对所有负样本进行征逐，以避免模型过度依赖干扰的图像-文本对应关系。</li>
<li>results: 通过在三个公共评测 dataset（CUHK-PEDES、ICFG-PEDES和RSTPReID）进行广泛的实验，证明了我们的RDE方法在不受NC干扰的情况下和受NC干扰的情况下均 achieve 状态的最佳Result。<details>
<summary>Abstract</summary>
Text-to-image person re-identification (TIReID) is a compelling topic in the cross-modal community, which aims to retrieve the target person based on a textual query. Although numerous TIReID methods have been proposed and achieved promising performance, they implicitly assume the training image-text pairs are correctly aligned, which is not always the case in real-world scenarios. In practice, the image-text pairs inevitably exist under-correlated or even false-correlated, a.k.a noisy correspondence (NC), due to the low quality of the images and annotation errors. To address this problem, we propose a novel Robust Dual Embedding method (RDE) that can learn robust visual-semantic associations even with NC. Specifically, RDE consists of two main components: 1) A Confident Consensus Division (CCD) module that leverages the dual-grained decisions of dual embedding modules to obtain a consensus set of clean training data, which enables the model to learn correct and reliable visual-semantic associations. 2) A Triplet-Alignment Loss (TAL) relaxes the conventional triplet-ranking loss with hardest negatives, which tends to rapidly overfit NC, to a log-exponential upper bound over all negatives, thus preventing the model from overemphasizing false image-text pairs. We conduct extensive experiments on three public benchmarks, namely CUHK-PEDES, ICFG-PEDES, and RSTPReID, to evaluate the performance and robustness of our RDE. Our method achieves state-of-the-art results both with and without synthetic noisy correspondences on all three datasets.
</details>
<details>
<summary>摘要</summary>
Text-to-image人重识别（TIReID）是跨模态社区中吸引人的话题，它目的是基于文本查询来 retrieve目标人。虽然多种 TIReID 方法已经被提出并实现了各种表现，但它们在假设训练图像文本对应是正确的情况下进行学习，而在实际场景中，图像文本对应存在偏差或假的对应关系（NC），即低质量图像和注释错误。为解决这问题，我们提出了一种robust dual embedding方法（RDE），可以学习具有NC的视Semantic关系。RDE包括两个主要组件： 1. 自信投票分区（CCD）模块，通过双重权重分配模块的双重决策来获得一个净的训练数据集，使模型可以学习正确和可靠的视Semantic关系。 2.  triplet对齐损失（TAL），通过放弃硬iest negative triplet损失，而是将 triplet损失Relax到log-exponential upper bound上，以防止模型过度强调NC。我们在三个公共Benchmark上进行了广泛的实验，分别是CUHK-PEDES、ICFG-PEDES和RSTPReID，以评估我们的RDE表现和稳定性。我们的方法在所有三个数据集上都实现了状态的art表现，并且在Synthetic NC情况下也具有优秀的表现。
</details></li>
</ul>
<hr>
<h2 id="Physics-Guided-Human-Motion-Capture-with-Pose-Probability-Modeling"><a href="#Physics-Guided-Human-Motion-Capture-with-Pose-Probability-Modeling" class="headerlink" title="Physics-Guided Human Motion Capture with Pose Probability Modeling"></a>Physics-Guided Human Motion Capture with Pose Probability Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09910">http://arxiv.org/abs/2308.09910</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/me-ditto/physics-guided-mocap">https://github.com/me-ditto/physics-guided-mocap</a></li>
<li>paper_authors: Jingyi Ju, Buzhen Huang, Chen Zhu, Zhihao Li, Yangang Wang</li>
<li>for: 提高人体动作捕捉的精度和成功率，避免漂浮、脚部滑动和地面凿入等误差。</li>
<li>methods: 采用物理学为导向，在反卷积过程中使用物理学来降噪减雷，从模型 pose 分布中重建物理可能性最高的人体动作。</li>
<li>results: 与前一代物理学基本方法相比，本方法在 JOINT 精度和成功率方面具有显著的提高，可以更好地捕捉人体动作。更多信息可以查看 \url{<a target="_blank" rel="noopener" href="https://github.com/Me-Ditto/Physics-Guided-Mocap%7D%E3%80%82">https://github.com/Me-Ditto/Physics-Guided-Mocap}。</a><details>
<summary>Abstract</summary>
Incorporating physics in human motion capture to avoid artifacts like floating, foot sliding, and ground penetration is a promising direction. Existing solutions always adopt kinematic results as reference motions, and the physics is treated as a post-processing module. However, due to the depth ambiguity, monocular motion capture inevitably suffers from noises, and the noisy reference often leads to failure for physics-based tracking. To address the obstacles, our key-idea is to employ physics as denoising guidance in the reverse diffusion process to reconstruct physically plausible human motion from a modeled pose probability distribution. Specifically, we first train a latent gaussian model that encodes the uncertainty of 2D-to-3D lifting to facilitate reverse diffusion. Then, a physics module is constructed to track the motion sampled from the distribution. The discrepancies between the tracked motion and image observation are used to provide explicit guidance for the reverse diffusion model to refine the motion. With several iterations, the physics-based tracking and kinematic denoising promote each other to generate a physically plausible human motion. Experimental results show that our method outperforms previous physics-based methods in both joint accuracy and success rate. More information can be found at \url{https://github.com/Me-Ditto/Physics-Guided-Mocap}.
</details>
<details>
<summary>摘要</summary>
将物理学 incorporated into 人体动作捕捉，以避免浮动、脚部滑块和地面嵌入的artefacts是一个Promising方向。现有的解决方案都是采用骨骼结果作为参考动作，并将物理学当作后处理模块。然而，由于深度的模糊，单目动作捕捉不可避免噪音，这些噪音经常导致物理学基于跟踪失败。为了解决这些障碍，我们的关键思想是使用物理学作为减噪指导，在反卷积过程中重建可靠的人体动作。specifically，我们首先训练了一个卷积学习模型，用于编码2D-to-3D的不确定性，以便在反卷积过程中进行减噪。然后，我们构建了物理模块，以跟踪从分布中抽取的动作。图像观测与跟踪的差异被用于直接提供反卷积模型的减噪指导，以便在几次迭代中改进动作。通过这种方式，物理学基于跟踪和骨骼减噪促进了对人体动作的重建。实验结果表明，我们的方法在 JOINT 精度和成功率方面都高于前期物理学基于方法。更多信息可以参考 \url{https://github.com/Me-Ditto/Physics-Guided-Mocap}.
</details></li>
</ul>
<hr>
<h2 id="DiffusionTrack-Diffusion-Model-For-Multi-Object-Tracking"><a href="#DiffusionTrack-Diffusion-Model-For-Multi-Object-Tracking" class="headerlink" title="DiffusionTrack: Diffusion Model For Multi-Object Tracking"></a>DiffusionTrack: Diffusion Model For Multi-Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09905">http://arxiv.org/abs/2308.09905</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rainbowluocs/diffusiontrack">https://github.com/rainbowluocs/diffusiontrack</a></li>
<li>paper_authors: Run Luo, Zikai Song, Lintao Ma, Jinlin Wei, Wei Yang, Min Yang</li>
<li>for: 这 paper 的目的是提出一种简单 yet robust 的多目标跟踪 (MOT) 方法，以解决现有 MOT 方法 的一些问题，如 global or local inconsistency, 模型复杂性和灵活性不足。</li>
<li>methods: 这 paper 使用的方法是通过 Paired Noise Boxes 到 Paired Ground-Truth Boxes 的一种逐步减噪演化策略，来实现对象检测和跟踪的一体化。在训练阶段，模型通过减噪演化过程来学习检测和跟踪，而在测试阶段，模型通过一种灵活的一步或多步减噪演化来更新检测和跟踪结果。</li>
<li>results: 这 paper 的实验结果表明，使用这种方法可以在三个常用的 MOT  benchmark 上达到与当前状态的识别方法相当的性能，包括 MOT17, MOT20 和 Dancetrack。<details>
<summary>Abstract</summary>
Multi-object tracking (MOT) is a challenging vision task that aims to detect individual objects within a single frame and associate them across multiple frames. Recent MOT approaches can be categorized into two-stage tracking-by-detection (TBD) methods and one-stage joint detection and tracking (JDT) methods. Despite the success of these approaches, they also suffer from common problems, such as harmful global or local inconsistency, poor trade-off between robustness and model complexity, and lack of flexibility in different scenes within the same video. In this paper we propose a simple but robust framework that formulates object detection and association jointly as a consistent denoising diffusion process from paired noise boxes to paired ground-truth boxes. This novel progressive denoising diffusion strategy substantially augments the tracker's effectiveness, enabling it to discriminate between various objects. During the training stage, paired object boxes diffuse from paired ground-truth boxes to random distribution, and the model learns detection and tracking simultaneously by reversing this noising process. In inference, the model refines a set of paired randomly generated boxes to the detection and tracking results in a flexible one-step or multi-step denoising diffusion process. Extensive experiments on three widely used MOT benchmarks, including MOT17, MOT20, and Dancetrack, demonstrate that our approach achieves competitive performance compared to the current state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
多目标跟踪（MOT）是一项视觉任务，旨在单帧内检测个体对象并在多帧中相关联。现代MOT方法可以分为两种阶段的跟踪检测（TBD）方法和一体的检测和跟踪（JDT）方法。尽管这些方法具有成功，但它们也存在一些共同的问题，如全局或局部的不一致、轻度的模型复杂度和不同场景中的灵活性不足。在这篇论文中，我们提出了一个简单 yet robust的框架，它将对象检测和相关联视为一个一致的降噪演进程，从对应的噪声框到对应的真实框进行进行逐步降噪。在训练阶段，对象框从对应的真实框降噪到随机分布，并且模型同时学习检测和跟踪的过程。在推断阶段，模型将一组随机生成的对象框进行精细的逐步降噪处理，以实现一步或多步的检测和跟踪结果。我们在MOT17、MOT20和Dancetrack等三个常用的MOT标准 benchmark上进行了广泛的实验，结果显示我们的方法与当前状态的方法相比，具有竞争性的性能。
</details></li>
</ul>
<hr>
<h2 id="Scalable-Video-Object-Segmentation-with-Simplified-Framework"><a href="#Scalable-Video-Object-Segmentation-with-Simplified-Framework" class="headerlink" title="Scalable Video Object Segmentation with Simplified Framework"></a>Scalable Video Object Segmentation with Simplified Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09903">http://arxiv.org/abs/2308.09903</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiangqiang Wu, Tianyu Yang, Wei WU, Antoni Chan</li>
<li>for: 这个论文主要针对视频对象分割（VOS）领域的问题，即如何使用简单的模型来实现高效的目标检测和分割。</li>
<li>methods: 这篇论文提出了一种可扩展的Simplified VOS（SimVOS）框架，利用单一的变换器底层来同时进行特征提取和匹配。此外，论文还提出了一种在框架中使用的快速注意力机制和新的токен精细化模块，以提高运行速度和避免计算成本增加。</li>
<li>results: 实验表明，我们的SimVOS可以在流行的视频对象分割数据集上达到最佳效果，包括DAVIS-2017（88.0% J&amp;F）、DAVIS-2016（92.9% J&amp;F）和YouTube-VOS 2019（84.2% J&amp;F）等数据集，而无需应用任何 sintética video 或 BL30K 预训练。<details>
<summary>Abstract</summary>
The current popular methods for video object segmentation (VOS) implement feature matching through several hand-crafted modules that separately perform feature extraction and matching. However, the above hand-crafted designs empirically cause insufficient target interaction, thus limiting the dynamic target-aware feature learning in VOS. To tackle these limitations, this paper presents a scalable Simplified VOS (SimVOS) framework to perform joint feature extraction and matching by leveraging a single transformer backbone. Specifically, SimVOS employs a scalable ViT backbone for simultaneous feature extraction and matching between query and reference features. This design enables SimVOS to learn better target-ware features for accurate mask prediction. More importantly, SimVOS could directly apply well-pretrained ViT backbones (e.g., MAE) for VOS, which bridges the gap between VOS and large-scale self-supervised pre-training. To achieve a better performance-speed trade-off, we further explore within-frame attention and propose a new token refinement module to improve the running speed and save computational cost. Experimentally, our SimVOS achieves state-of-the-art results on popular video object segmentation benchmarks, i.e., DAVIS-2017 (88.0% J&F), DAVIS-2016 (92.9% J&F) and YouTube-VOS 2019 (84.2% J&F), without applying any synthetic video or BL30K pre-training used in previous VOS approaches.
</details>
<details>
<summary>摘要</summary>
当前流行的视频对象分割（VOS）方法通常通过多个手动设计的模块来实现特征匹配。然而，这些手动设计在实践中会导致不充分的目标互动，从而限制VOS中的动态目标感知特征学习。为了解决这些限制，本文提出了一个可扩展的简化VOS（SimVOS）框架，用于同时执行特征提取和匹配。具体来说，SimVOS使用可扩展的ViT脊梁来同时提取和匹配查询和参照特征。这种设计使得SimVOS能够学习更好的目标相关特征，以提高掩模预测的准确性。此外，SimVOS可以直接应用已经预训练的ViT脊梁（例如MAE）来进行VOS，这种 bridging 可以将VOS和大规模自动预训练相连接。为了实现更好的性能-速度交易，我们进一步探索了 Within-frame 注意力和一种新的 токен细化模块，以提高运行速度并降低计算成本。实验结果表明，我们的 SimVOS 在流行的视频对象分割标准 bencmarks 上 achieve state-of-the-art 结果，无需应用任何 sintetic video 或 BL30K 预训练，这些预训练在前一代 VOS 方法中通常被使用。
</details></li>
</ul>
<hr>
<h2 id="Towards-a-High-Performance-Object-Detector-Insights-from-Drone-Detection-Using-ViT-and-CNN-based-Deep-Learning-Models"><a href="#Towards-a-High-Performance-Object-Detector-Insights-from-Drone-Detection-Using-ViT-and-CNN-based-Deep-Learning-Models" class="headerlink" title="Towards a High-Performance Object Detector: Insights from Drone Detection Using ViT and CNN-based Deep Learning Models"></a>Towards a High-Performance Object Detector: Insights from Drone Detection Using ViT and CNN-based Deep Learning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09899">http://arxiv.org/abs/2308.09899</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junyang Zhang</li>
<li>for: 避免无人机和自驾车与无人机相撞、防御无人机入侵和自驾车自动降落。</li>
<li>methods: 使用 CNN 和 ViT 模型，实现单一无人机检测和多无人机检测。</li>
<li>results: 比较 CNN 和 ViT 模型的性能，发现 ViT 在单一无人机检测中表现4.6倍更好，但需要更多的训练数据、computational power 和高级设计来完全超越 CNN 检测器。<details>
<summary>Abstract</summary>
Accurate drone detection is strongly desired in drone collision avoidance, drone defense and autonomous Unmanned Aerial Vehicle (UAV) self-landing. With the recent emergence of the Vision Transformer (ViT), this critical task is reassessed in this paper using a UAV dataset composed of 1359 drone photos. We construct various CNN and ViT-based models, demonstrating that for single-drone detection, a basic ViT can achieve performance 4.6 times more robust than our best CNN-based transfer learning models. By implementing the state-of-the-art You Only Look Once (YOLO v7, 200 epochs) and the experimental ViT-based You Only Look At One Sequence (YOLOS, 20 epochs) in multi-drone detection, we attain impressive 98% and 96% mAP values, respectively. We find that ViT outperforms CNN at the same epoch, but also requires more training data, computational power, and sophisticated, performance-oriented designs to fully surpass the capabilities of cutting-edge CNN detectors. We summarize the distinct characteristics of ViT and CNN models to aid future researchers in developing more efficient deep learning models.
</details>
<details>
<summary>摘要</summary>
准确的飞行器探测在无人机冲突避免、无人机防御和自适应无人机自降中是非常重要的。随着最近的视力变换器（ViT）的出现，我们在这篇论文中使用了一个无人机数据集，包含1359个飞行器照片，重新评估了这个关键任务。我们构建了不同的CNN和ViT基本模型，发现在单飞行器探测任务中，一个基本的ViT可以达到与我们最佳CNN基本传播学习模型的4.6倍的性能。通过在多飞行器探测任务中实现了state-of-the-art的You Only Look Once（YOLO v7，200 epochs）和实验性的ViT基本You Only Look At One Sequence（YOLOS，20 epochs），我们获得了各种98%和96%的mAP值。我们发现ViT比CNN在同一个熬煮值下表现更好，但也需要更多的训练数据、计算能力和复杂的性能设计来完全超越现有的CNN探测器。我们总结了ViT和CNN模型的特点，以帮助未来的研究人员开发更高效的深度学习模型。
</details></li>
</ul>
<hr>
<h2 id="Spatial-Temporal-Alignment-Network-for-Action-Recognition"><a href="#Spatial-Temporal-Alignment-Network-for-Action-Recognition" class="headerlink" title="Spatial-Temporal Alignment Network for Action Recognition"></a>Spatial-Temporal Alignment Network for Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09897">http://arxiv.org/abs/2308.09897</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinhui Ye, Junwei Liang</li>
<li>for: 本文旨在提出一种视角不变特征表示方法，用于改进现有动作识别架构。</li>
<li>methods: 该方法基于一种名为空间-时间对应网络（STAN），该网络可以学习geometry invariant的表示。</li>
<li>results: 实验结果表明，在训练从scratch的情况下，STAN模型可以在UCf101和HMDB51等广泛使用的数据集上提高动作识别任务的性能。<details>
<summary>Abstract</summary>
This paper studies introducing viewpoint invariant feature representations in existing action recognition architecture. Despite significant progress in action recognition, efficiently handling geometric variations in large-scale datasets remains challenging. To tackle this problem, we propose a novel Spatial-Temporal Alignment Network (STAN), which explicitly learns geometric invariant representations for action recognition. Notably, the STAN model is light-weighted and generic, which could be plugged into existing action recognition models (e.g., MViTv2) with a low extra computational cost. We test our STAN model on widely-used datasets like UCF101 and HMDB51. The experimental results show that the STAN model can consistently improve the state-of-the-art models in action recognition tasks in trained-from-scratch settings.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Semantic-Human-Neural-Rendering-of-Humans-from-Monocular-Video-with-Human-Parsing"><a href="#Semantic-Human-Neural-Rendering-of-Humans-from-Monocular-Video-with-Human-Parsing" class="headerlink" title="Semantic-Human: Neural Rendering of Humans from Monocular Video with Human Parsing"></a>Semantic-Human: Neural Rendering of Humans from Monocular Video with Human Parsing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09894">http://arxiv.org/abs/2308.09894</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Zhang, Pengcheng Shi, Zaiwang Gu, Yiyang Zhou, Zhi Wang</li>
<li>for: 本研究旨在提高人体 нейрон渲染的质量，同时实现人体解析。</li>
<li>methods: 本文提出了一种名为Semantic-Human的新方法，它可以同时实现高品质的渲染和视角相关的人体解析。特别是，该方法在NeRF基础上扩展了semantics, appearance和geometry的编码，以实现基于噪声批量标签的高精度2D semantic labels。此外，该方法还引入了基于SMPL表面的运动场和恢复的三维几何学regularization。</li>
<li>results: 在使用ZJU-MoCap数据集进行评估时，Semantic-Human方法得到了非常竞争力的结果，证明了该方法的有效性。此外，该方法还可以实现多种有趣的应用，如标签噪声除除、标签生成和图像修改等，并且经验 Validate了其优势性。<details>
<summary>Abstract</summary>
The neural rendering of humans is a topic of great research significance. However, previous works mostly focus on achieving photorealistic details, neglecting the exploration of human parsing. Additionally, classical semantic work are all limited in their ability to efficiently represent fine results in complex motions. Human parsing is inherently related to radiance reconstruction, as similar appearance and geometry often correspond to similar semantic part. Furthermore, previous works often design a motion field that maps from the observation space to the canonical space, while it tends to exhibit either underfitting or overfitting, resulting in limited generalization. In this paper, we present Semantic-Human, a novel method that achieves both photorealistic details and viewpoint-consistent human parsing for the neural rendering of humans. Specifically, we extend neural radiance fields (NeRF) to jointly encode semantics, appearance and geometry to achieve accurate 2D semantic labels using noisy pseudo-label supervision. Leveraging the inherent consistency and smoothness properties of NeRF, Semantic-Human achieves consistent human parsing in both continuous and novel views. We also introduce constraints derived from the SMPL surface for the motion field and regularization for the recovered volumetric geometry. We have evaluated the model using the ZJU-MoCap dataset, and the obtained highly competitive results demonstrate the effectiveness of our proposed Semantic-Human. We also showcase various compelling applications, including label denoising, label synthesis and image editing, and empirically validate its advantageous properties.
</details>
<details>
<summary>摘要</summary>
“人体神经渲染是研究领域的热点话题。然而，前一些工作强调了实现光真实细节，忽略了人体解析的探索。此外，传统的 semantic 工作都受到了复杂动作中的细节表示的限制。人体解析与光重建密切相关，因为类似的外观和结构通常对应于类似的semantic部分。此外，以前的工作通常将动作场景映射到了 canonical 空间，而这经常导致过拟合或者下降抑制，限制了其泛化能力。在本文中，我们提出了 Semantic-Human，一种新的方法，能够同时实现光真实细节和视点一致的人体解析。具体来说，我们扩展了神经辐射场（NeRF），使其同时编码semantics、外观和geometry以实现基于噪声假标签的高精度2D semantic标签。利用NeRF的自然协调性和平滑性属性，Semantic-Human在连续和新视图下实现了一致的人体解析。我们还引入了基于 SMPL  поверхност的运动场景约束和 recovered volumetric geometry 的正则化。我们在 ZJU-MoCap 数据集上评估了模型，并获得了非常竞争力的结果，证明了我们提出的 Semantic-Human 的效果。我们还展示了多种吸引人的应用，包括标签噪声去除、标签生成和图像修改，并且实际验证了它的优点性质。”
</details></li>
</ul>
<hr>
<h2 id="DUAW-Data-free-Universal-Adversarial-Watermark-against-Stable-Diffusion-Customization"><a href="#DUAW-Data-free-Universal-Adversarial-Watermark-against-Stable-Diffusion-Customization" class="headerlink" title="DUAW: Data-free Universal Adversarial Watermark against Stable Diffusion Customization"></a>DUAW: Data-free Universal Adversarial Watermark against Stable Diffusion Customization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09889">http://arxiv.org/abs/2308.09889</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyu Ye, Hao Huang, Jiaqi An, Yongtao Wang<br>for:  This paper aims to address the issue of copyright infringement in Stable Diffusion (SD) customization approaches by proposing an invisible data-free universal adversarial watermark (DUAW) to protect a myriad of copyrighted images.methods:  The proposed DUAW is designed to disrupt the variational autoencoder during SD customization, and it operates in a data-free context using synthetic images produced by a Large Language Model (LLM) and a pretrained SD model.results:  Experimental results demonstrate that DUAW can effectively distort the outputs of fine-tuned SD models, rendering them discernible to both human observers and a simple classifier, thereby protecting copyrighted images from plagiarism.<details>
<summary>Abstract</summary>
Stable Diffusion (SD) customization approaches enable users to personalize SD model outputs, greatly enhancing the flexibility and diversity of AI art. However, they also allow individuals to plagiarize specific styles or subjects from copyrighted images, which raises significant concerns about potential copyright infringement. To address this issue, we propose an invisible data-free universal adversarial watermark (DUAW), aiming to protect a myriad of copyrighted images from different customization approaches across various versions of SD models. First, DUAW is designed to disrupt the variational autoencoder during SD customization. Second, DUAW operates in a data-free context, where it is trained on synthetic images produced by a Large Language Model (LLM) and a pretrained SD model. This approach circumvents the necessity of directly handling copyrighted images, thereby preserving their confidentiality. Once crafted, DUAW can be imperceptibly integrated into massive copyrighted images, serving as a protective measure by inducing significant distortions in the images generated by customized SD models. Experimental results demonstrate that DUAW can effectively distort the outputs of fine-tuned SD models, rendering them discernible to both human observers and a simple classifier.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Calibrating-Uncertainty-for-Semi-Supervised-Crowd-Counting"><a href="#Calibrating-Uncertainty-for-Semi-Supervised-Crowd-Counting" class="headerlink" title="Calibrating Uncertainty for Semi-Supervised Crowd Counting"></a>Calibrating Uncertainty for Semi-Supervised Crowd Counting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09887">http://arxiv.org/abs/2308.09887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Li, Xiaoling Hu, Shahira Abousamra, Chao Chen</li>
<li>for: 这篇论文的目的是提出一种用于半指导人数推断的新方法，以提高这种任务的性能。</li>
<li>methods: 这篇论文使用了一种基于模型不确定性的方法，通过调教一个价值函数来训练模型。这个方法使用了一种匹配函数来更好地估计人数推断的不确定性。</li>
<li>results: 这篇论文的结果显示，使用这种方法可以生成可靠的伪标签，并且可以实现semi-supervised人数推断的state-of-the-art性能。<details>
<summary>Abstract</summary>
Semi-supervised crowd counting is an important yet challenging task. A popular approach is to iteratively generate pseudo-labels for unlabeled data and add them to the training set. The key is to use uncertainty to select reliable pseudo-labels. In this paper, we propose a novel method to calibrate model uncertainty for crowd counting. Our method takes a supervised uncertainty estimation strategy to train the model through a surrogate function. This ensures the uncertainty is well controlled throughout the training. We propose a matching-based patch-wise surrogate function to better approximate uncertainty for crowd counting tasks. The proposed method pays a sufficient amount of attention to details, while maintaining a proper granularity. Altogether our method is able to generate reliable uncertainty estimation, high quality pseudolabels, and achieve state-of-the-art performance in semisupervised crowd counting.
</details>
<details>
<summary>摘要</summary>
semi-supervised crowd counting 是一项重要又挑战性的任务。一种popular approach是iteratively generating pseudo-labels for unlabeled data and adding them to the training set。关键在于使用uncertainty选择可靠的pseudo-labels。在这篇论文中，我们提出了一种novel method to calibrate model uncertainty for crowd counting。我们的方法通过一个supervised uncertainty estimation strategy to train the model through a surrogate function，这 garantizesthat uncertainty is well controlled throughout the training。我们提出了一种matching-based patch-wise surrogate function to better approximate uncertainty for crowd counting tasks。提议的方法具有 suficient amount of attention to details，同时保持proper granularity。总之，我们的方法能够生成可靠的uncertainty estimation，高质量的pseudolabels，并实现semisupervised crowd counting的state-of-the-art performance。
</details></li>
</ul>
<hr>
<h2 id="Forecast-MAE-Self-supervised-Pre-training-for-Motion-Forecasting-with-Masked-Autoencoders"><a href="#Forecast-MAE-Self-supervised-Pre-training-for-Motion-Forecasting-with-Masked-Autoencoders" class="headerlink" title="Forecast-MAE: Self-supervised Pre-training for Motion Forecasting with Masked Autoencoders"></a>Forecast-MAE: Self-supervised Pre-training for Motion Forecasting with Masked Autoencoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09882">http://arxiv.org/abs/2308.09882</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jchengai/forecast-mae">https://github.com/jchengai/forecast-mae</a></li>
<li>paper_authors: Jie Cheng, Xiaodong Mei, Ming Liu</li>
<li>for: 这个研究探索了自监学习（SSL）在动态预测任务中的应用，这是计算机视觉和自然语言处理领域中广泛成功的 SSL 方法，却尚未得到广泛研究。</li>
<li>methods: 我们引入了 Forecast-MAE，一种基于面积自适应神经网络（Transformer）块的 SSL 框架，特意设计用于自监学习动态预测任务。我们的方法包括一种新的面 másking 策略，利用agent trajectory 和路网之间强联系，通过补做agent future trajectory 和历史 trajectory的 complementary másking，以及随机 másking 路网段。</li>
<li>results: 我们在 Argoverse 2 动态预测测试集上进行了实验，显示 Forecast-MAE 在与 supervised learning 和复杂设计的方法相比，在竞争性Task 中具有竞争性的性能。此外，它还超过了之前的自监学习方法，表明 Forecast-MAE 可以充分利用 SSL 来预测动态Scene。<details>
<summary>Abstract</summary>
This study explores the application of self-supervised learning (SSL) to the task of motion forecasting, an area that has not yet been extensively investigated despite the widespread success of SSL in computer vision and natural language processing. To address this gap, we introduce Forecast-MAE, an extension of the mask autoencoders framework that is specifically designed for self-supervised learning of the motion forecasting task. Our approach includes a novel masking strategy that leverages the strong interconnections between agents' trajectories and road networks, involving complementary masking of agents' future or history trajectories and random masking of lane segments. Our experiments on the challenging Argoverse 2 motion forecasting benchmark show that Forecast-MAE, which utilizes standard Transformer blocks with minimal inductive bias, achieves competitive performance compared to state-of-the-art methods that rely on supervised learning and sophisticated designs. Moreover, it outperforms the previous self-supervised learning method by a significant margin. Code is available at https://github.com/jchengai/forecast-mae.
</details>
<details>
<summary>摘要</summary>
这种研究探讨了使用自动教学学习（SSL）来解决运动预测任务，这是一个尚未得到广泛探讨的领域，尽管SSL在计算机视觉和自然语言处理领域得到了广泛的成功。为了解决这个遗漏，我们介绍了 Forecast-MAE，一种特制的mask autoencoders框架，用于自动教学学习运动预测任务。我们的方法包括一种新的面积策略，利用汽车轨迹和公路网络之间的强相关性，包括补做未来或历史轨迹的随机掩码和路段掩码。我们在Argoverse 2运动预测测试benchmark上进行了实验，发现 Forecast-MAE，使用标准Transformer块和最小适应性，可以与supervised learning和复杂设计的方法相比肩，并且超过了之前的自动教学方法，性能较好。代码可以在https://github.com/jchengai/forecast-mae中找到。
</details></li>
</ul>
<hr>
<h2 id="DatasetEquity-Are-All-Samples-Created-Equal-In-The-Quest-For-Equity-Within-Datasets"><a href="#DatasetEquity-Are-All-Samples-Created-Equal-In-The-Quest-For-Equity-Within-Datasets" class="headerlink" title="DatasetEquity: Are All Samples Created Equal? In The Quest For Equity Within Datasets"></a>DatasetEquity: Are All Samples Created Equal? In The Quest For Equity Within Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09878">http://arxiv.org/abs/2308.09878</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/towardsautonomy/datasetequity">https://github.com/towardsautonomy/datasetequity</a></li>
<li>paper_authors: Shubham Shrivastava, Xianling Zhang, Sushruth Nagesh, Armin Parchami</li>
<li>for: 本研究旨在解决机器学习中的数据不均衡问题，具体来说是针对computer vision领域中的数据偏见问题。</li>
<li>methods: 本研究使用了深度感知嵌入和聚类算法来计算图像出现的可能性，然后使用这些可能性来减轻数据不均衡的影响。另外，提出了一种新的$\textbf{普适吸引损失函数}$来调整训练过程中的样本权重。</li>
<li>results: 实验表明，该方法可以提高3D物体检测方法的性能，特别是对于少见的类别（自行车手）在KITTI数据集上的AP效果提高了超过200%。这些结果表明该方法是通用的，可以补充现有的技术，并在小数据集和少见的类别上特别有效。<details>
<summary>Abstract</summary>
Data imbalance is a well-known issue in the field of machine learning, attributable to the cost of data collection, the difficulty of labeling, and the geographical distribution of the data. In computer vision, bias in data distribution caused by image appearance remains highly unexplored. Compared to categorical distributions using class labels, image appearance reveals complex relationships between objects beyond what class labels provide. Clustering deep perceptual features extracted from raw pixels gives a richer representation of the data. This paper presents a novel method for addressing data imbalance in machine learning. The method computes sample likelihoods based on image appearance using deep perceptual embeddings and clustering. It then uses these likelihoods to weigh samples differently during training with a proposed $\textbf{Generalized Focal Loss}$ function. This loss can be easily integrated with deep learning algorithms. Experiments validate the method's effectiveness across autonomous driving vision datasets including KITTI and nuScenes. The loss function improves state-of-the-art 3D object detection methods, achieving over $200\%$ AP gains on under-represented classes (Cyclist) in the KITTI dataset. The results demonstrate the method is generalizable, complements existing techniques, and is particularly beneficial for smaller datasets and rare classes. Code is available at: https://github.com/towardsautonomy/DatasetEquity
</details>
<details>
<summary>摘要</summary>
“数据不均衡是机器学习领域的一个常见问题，这主要归结于数据收集成本、标签难度和数据的地域分布。在计算机视觉领域，图像外观的偏见对数据分布仍然具有很大的潜在探索空间。相比于使用类别分布的类标签，图像外观表现出了更复杂的对象之间的关系。使用深度感知特征提取自原始像素的归一化可以提供更丰富的数据表示。本文提出了一种 novel 的数据不均衡解决方案，该方法通过使用深度感知嵌入和归一化计算样本概率。然后使用这些概率对样本进行不同权重训练，使用我们提议的 $\textbf{通用强化损失}$ 函数。这种损失函数可以轻松地与深度学习算法结合使用。实验证明了该方法的有效性，在 KITTI 和 nuScenes 自动驾驶视觉数据集上实现了超过 200% AP 提升的 Results 表明该方法是通用的，可以补偿现有技术，特别有利于小型数据集和罕见类。代码可以在 GitHub 上找到：https://github.com/towardsautonomy/DatasetEquity。”Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other countries. If you need Traditional Chinese, please let me know and I'll be happy to provide it.
</details></li>
</ul>
<hr>
<h2 id="A-Theory-of-Topological-Derivatives-for-Inverse-Rendering-of-Geometry"><a href="#A-Theory-of-Topological-Derivatives-for-Inverse-Rendering-of-Geometry" class="headerlink" title="A Theory of Topological Derivatives for Inverse Rendering of Geometry"></a>A Theory of Topological Derivatives for Inverse Rendering of Geometry</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09865">http://arxiv.org/abs/2308.09865</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ishit Mehta, Manmohan Chandraker, Ravi Ramamoorthi</li>
<li>for: 这篇论文旨在提出一种可微 differentiable 表面演化理论，以便通过变分函数优化图像函数。</li>
<li>methods: 该理论使用 topological derivatives 来实现不同的拓扑结构变化，而不是先前的 silhouette gradients。</li>
<li>results: 该理论可以实现可微的形态异常，包括孔子核生成和相位异常。这些结果可以用于改进图像向量化、vector-graphics生成、单图像重建形意agram和多视图3D重建等应用。<details>
<summary>Abstract</summary>
We introduce a theoretical framework for differentiable surface evolution that allows discrete topology changes through the use of topological derivatives for variational optimization of image functionals. While prior methods for inverse rendering of geometry rely on silhouette gradients for topology changes, such signals are sparse. In contrast, our theory derives topological derivatives that relate the introduction of vanishing holes and phases to changes in image intensity. As a result, we enable differentiable shape perturbations in the form of hole or phase nucleation. We validate the proposed theory with optimization of closed curves in 2D and surfaces in 3D to lend insights into limitations of current methods and enable improved applications such as image vectorization, vector-graphics generation from text prompts, single-image reconstruction of shape ambigrams and multi-view 3D reconstruction.
</details>
<details>
<summary>摘要</summary>
我们提出了一种可 diferenciable 表面演化理论，允许离散topology变化通过使用图像函数的topological导数进行variational优化。而以前的对geometry inverse rendering方法依赖于silhouette导数进行topology变化，这些信号是稀疏的。相比之下，我们的理论 derivates topological导数，将引入vanishing holes和阶段相关到图像强度的变化。因此，我们可以实现可微形状变化，包括孔悉散和阶段悉散。我们验证了提出的理论，通过在2D和3D中优化closed curves和surfaces来增加应用，如图像vectorization、vector-graphics生成from文本提示、单个图像重建shape ambigrams和多视图3D重建。
</details></li>
</ul>
<hr>
<h2 id="Microscopy-Image-Segmentation-via-Point-and-Shape-Regularized-Data-Synthesis"><a href="#Microscopy-Image-Segmentation-via-Point-and-Shape-Regularized-Data-Synthesis" class="headerlink" title="Microscopy Image Segmentation via Point and Shape Regularized Data Synthesis"></a>Microscopy Image Segmentation via Point and Shape Regularized Data Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09835">http://arxiv.org/abs/2308.09835</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shijie Li, Mengwei Ren, Thomas Ach, Guido Gerig</li>
<li>for: 这篇论文主要针对微scopic图像分类问题提出了一个新的方法，它可以使用简单的点标注来进行训练，而不需要大量的实际标注数据。</li>
<li>methods: 这篇论文提出了一个三阶段的框架，包括：1）将点标注转换为伪稠密分类面组件，并受限于物体形状假设；2）使用对称的图像生成模型，将伪稠密分类面组件转换为真实的微scopic图像；3）使用伪稠密分类面组件和生成的图像，进行训练专门的分类模型。</li>
<li>results: 这篇论文的实验结果显示，使用这个新的方法可以在公共的 MoNuSeg 数据集上生成更多的多标的图像，并且保持高度的标注与生成图像之间的协调性。此外，这个方法可以与使用pseudo-labels或基准生成的图像进行比较，实现更高的分类精度。<details>
<summary>Abstract</summary>
Current deep learning-based approaches for the segmentation of microscopy images heavily rely on large amount of training data with dense annotation, which is highly costly and laborious in practice. Compared to full annotation where the complete contour of objects is depicted, point annotations, specifically object centroids, are much easier to acquire and still provide crucial information about the objects for subsequent segmentation. In this paper, we assume access to point annotations only during training and develop a unified pipeline for microscopy image segmentation using synthetically generated training data. Our framework includes three stages: (1) it takes point annotations and samples a pseudo dense segmentation mask constrained with shape priors; (2) with an image generative model trained in an unpaired manner, it translates the mask to a realistic microscopy image regularized by object level consistency; (3) the pseudo masks along with the synthetic images then constitute a pairwise dataset for training an ad-hoc segmentation model. On the public MoNuSeg dataset, our synthesis pipeline produces more diverse and realistic images than baseline models while maintaining high coherence between input masks and generated images. When using the identical segmentation backbones, the models trained on our synthetic dataset significantly outperform those trained with pseudo-labels or baseline-generated images. Moreover, our framework achieves comparable results to models trained on authentic microscopy images with dense labels, demonstrating its potential as a reliable and highly efficient alternative to labor-intensive manual pixel-wise annotations in microscopy image segmentation. The code is available.
</details>
<details>
<summary>摘要</summary>
当前的深度学习基于方法 для微scopic影像分割强调大量的训练数据，包括密集的标注。在实际应用中，这种标注是非常成本高昂和劳动密集的。相比拥有完整的标注，其中包含对象的完整边界，点标注更加容易获得，并且仍然提供了对对象的重要信息。在这篇论文中，我们假设在训练时有点标注可用。我们提出了一个简化的框架，包括以下三个阶段：1. 使用点标注，生成一个 Pseudo density 分割面，受限于形态约束。2. 使用一种没有对应关系的图像生成模型，将分割面翻译成一个真实的微scopic影像，并对其进行对象水平的准确性补做。3. 使用生成的 Pseudo 分割面和实际图像组成一个对应的数据集，用于训练适应性强的分割模型。在公共的 MoNuSeg 数据集上，我们的生成框架生成了更加多样化和真实的图像，同时保持了输入权重的高准确性。当使用同一个分割后端时，我们在我们的生成数据集上训练的模型比使用 pseudo-标签 或基eline-生成的图像训练得更好。此外，我们的框架可以与密集标注的模型相比，在微scopic影像分割任务中达到相同的性能水平。代码可以获得。
</details></li>
</ul>
<hr>
<h2 id="Cross-modality-Attention-based-Multimodal-Fusion-for-Non-small-Cell-Lung-Cancer-NSCLC-Patient-Survival-Prediction"><a href="#Cross-modality-Attention-based-Multimodal-Fusion-for-Non-small-Cell-Lung-Cancer-NSCLC-Patient-Survival-Prediction" class="headerlink" title="Cross-modality Attention-based Multimodal Fusion for Non-small Cell Lung Cancer (NSCLC) Patient Survival Prediction"></a>Cross-modality Attention-based Multimodal Fusion for Non-small Cell Lung Cancer (NSCLC) Patient Survival Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09831">http://arxiv.org/abs/2308.09831</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruining Deng, Nazim Shaikh, Gareth Shannon, Yao Nie</li>
<li>for: 预测非小细胞肺癌患者存活result, 即computer-aided diagnosis和prognosis在医学应用中的提高。</li>
<li>methods: 跨模态注意力基本的多模态融合管道，该方法不仅将不同模式的特征简单 concatenate或sum，而是通过跨模态关系 gauges each modality’s importance for feature fusion。</li>
<li>results: 在实验中，提议的融合方法在NSCLC患者存活预测中实现了c-index 0.6587，较单模式（使用 solely tissue image data或RNA-seq data）的c-index 0.5772和0.5885高出2.3%和1.6%。<details>
<summary>Abstract</summary>
Cancer prognosis and survival outcome predictions are crucial for therapeutic response estimation and for stratifying patients into various treatment groups. Medical domains concerned with cancer prognosis are abundant with multiple modalities, including pathological image data and non-image data such as genomic information. To date, multimodal learning has shown potential to enhance clinical prediction model performance by extracting and aggregating information from different modalities of the same subject. This approach could outperform single modality learning, thus improving computer-aided diagnosis and prognosis in numerous medical applications. In this work, we propose a cross-modality attention-based multimodal fusion pipeline designed to integrate modality-specific knowledge for patient survival prediction in non-small cell lung cancer (NSCLC). Instead of merely concatenating or summing up the features from different modalities, our method gauges the importance of each modality for feature fusion with cross-modality relationship when infusing the multimodal features. Compared with single modality, which achieved c-index of 0.5772 and 0.5885 using solely tissue image data or RNA-seq data, respectively, the proposed fusion approach achieved c-index 0.6587 in our experiment, showcasing the capability of assimilating modality-specific knowledge from varied modalities.
</details>
<details>
<summary>摘要</summary>
cancer 诊断和生存结果预测是临床应用中的关键任务，可以用于评估治疗效果和将患者分配到不同的治疗组。医疗领域中关于 cancer 诊断的数据非常丰富，包括生物pathological 图像数据和非图像数据，如基因信息。迄今为止，多Modal learning 已经展现出能够提高诊断模型性能，通过抽取和汇集不同模式的信息来提高计算机助成诊断和预测的能力。在这个工作中，我们提议一种跨模式关注机制的多模式融合管道，用于将不同模式的特征融合，以提高患者存活预测的准确性。相比单模式学习，我们的方法可以评估不同模式之间的关系，从而更好地汇集模式特征。在我们的实验中，我们的方法实现了c-index 0.6587，比单模式学习的c-index 0.5772和0.5885更高，这显示了我们的方法可以充分利用不同模式之间的关系，以提高诊断和预测的准确性。
</details></li>
</ul>
<hr>
<h2 id="EAVL-Explicitly-Align-Vision-and-Language-for-Referring-Image-Segmentation"><a href="#EAVL-Explicitly-Align-Vision-and-Language-for-Referring-Image-Segmentation" class="headerlink" title="EAVL: Explicitly Align Vision and Language for Referring Image Segmentation"></a>EAVL: Explicitly Align Vision and Language for Referring Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09779">http://arxiv.org/abs/2308.09779</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yichen Yan, Xingjian He, Wenxuan Wang, Sihan Chen, Jing Liu</li>
<li>for: This paper is written for the task of image segmentation using natural language references.</li>
<li>methods: The paper proposes a new method called Explicitly Align the Vision and Language for Referring Image Segmentation (EAVL), which explicitly aligns vision and language features in the segmentation stage using a series of unfixed convolution kernels generated based on the input language expression.</li>
<li>results: The paper achieves state-of-the-art performance on three benchmark datasets (RefCOCO, RefCOCO+, and G-Ref) by effectively fusing vision and language features and exploiting their potential in the segmentation stage, while also achieving language-related localization.<details>
<summary>Abstract</summary>
Referring image segmentation aims to segment an object mentioned in natural language from an image. A main challenge is language-related localization, which means locating the object with the relevant language. Previous approaches mainly focus on the fusion of vision and language features without fully addressing language-related localization. In previous approaches, fused vision-language features are directly fed into a decoder and pass through a convolution with a fixed kernel to obtain the result, which follows a similar pattern as traditional image segmentation. This approach does not explicitly align language and vision features in the segmentation stage, resulting in a suboptimal language-related localization. Different from previous methods, we propose Explicitly Align the Vision and Language for Referring Image Segmentation (EAVL). Instead of using a fixed convolution kernel, we propose an Aligner which explicitly aligns the vision and language features in the segmentation stage. Specifically, a series of unfixed convolution kernels are generated based on the input l, and then are use to explicitly align the vision and language features. To achieve this, We generate multiple queries that represent different emphases of the language expression. These queries are transformed into a series of query-based convolution kernels. Then, we utilize these kernels to do convolutions in the segmentation stage and obtain a series of segmentation masks. The final result is obtained through the aggregation of all masks. Our method can not only fuse vision and language features effectively but also exploit their potential in the segmentation stage. And most importantly, we explicitly align language features of different emphases with the image features to achieve language-related localization. Our method surpasses previous state-of-the-art methods on RefCOCO, RefCOCO+, and G-Ref by large margins.
</details>
<details>
<summary>摘要</summary>
Traditional image segmentation methods mainly focus on fusing vision and language features without fully addressing the challenge of language-related localization. Previous approaches typically use a fixed convolution kernel to fuse the features, which does not explicitly align the language and vision features in the segmentation stage, leading to suboptimal localization.In this paper, we propose a novel method called Explicitly Align the Vision and Language for Referring Image Segmentation (EAVL). Our approach uses an Aligner to explicitly align the vision and language features in the segmentation stage, rather than using a fixed convolution kernel. We generate multiple queries that represent different emphases of the language expression and transform them into a series of query-based convolution kernels. These kernels are then used to do convolutions in the segmentation stage, resulting in a series of segmentation masks. The final result is obtained through the aggregation of all masks.Our method not only effectively fuses vision and language features but also exploits their potential in the segmentation stage. Moreover, we explicitly align language features of different emphases with the image features, achieving language-related localization. Our method outperforms previous state-of-the-art methods on RefCOCO, RefCOCO+, and G-Ref by large margins.
</details></li>
</ul>
<hr>
<h2 id="Long-range-Multimodal-Pretraining-for-Movie-Understanding"><a href="#Long-range-Multimodal-Pretraining-for-Movie-Understanding" class="headerlink" title="Long-range Multimodal Pretraining for Movie Understanding"></a>Long-range Multimodal Pretraining for Movie Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09775">http://arxiv.org/abs/2308.09775</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dawitmureja/LMP">https://github.com/dawitmureja/LMP</a></li>
<li>paper_authors: Dawit Mureja Argaw, Joon-Young Lee, Markus Woodson, In So Kweon, Fabian Caba Heilbron</li>
<li>for: 这个论文的目的是提出一种基于电影数据的多模态预训练策略，以便在电影理解任务中实现更好的表现。</li>
<li>methods: 这个论文使用了长距离多模态预训练策略，通过观察和提取电影中各种modalities之间的关系，从而学习多模态和交叉模态编码器。</li>
<li>results: 这个论文在LVU测试集上进行了缺失学习和模型选择研究，并证明了其在多个benchmark任务上的传送性。其中，模型在LVU任务上达到了状态略于前者，并且在五个不同的benchmark任务中设置了新的状态略。<details>
<summary>Abstract</summary>
Learning computer vision models from (and for) movies has a long-standing history. While great progress has been attained, there is still a need for a pretrained multimodal model that can perform well in the ever-growing set of movie understanding tasks the community has been establishing. In this work, we introduce Long-range Multimodal Pretraining, a strategy, and a model that leverages movie data to train transferable multimodal and cross-modal encoders. Our key idea is to learn from all modalities in a movie by observing and extracting relationships over a long-range. After pretraining, we run ablation studies on the LVU benchmark and validate our modeling choices and the importance of learning from long-range time spans. Our model achieves state-of-the-art on several LVU tasks while being much more data efficient than previous works. Finally, we evaluate our model's transferability by setting a new state-of-the-art in five different benchmarks.
</details>
<details>
<summary>摘要</summary>
学习电影中的计算机视觉模型有很长的历史。虽然已经取得了很大的进步，但还有一些需求，例如需要一个预训练的多modal模型，可以在电影理解任务中表现出色。在这项工作中，我们介绍了远程多modal预训练策略和模型，该模型利用电影数据来训练可转移的多modal和跨modal编码器。我们的关键思想是从电影中所有modalities中学习和提取关系，并且在远程时间范围内做出关系。在预训练后，我们进行了ablation研究， validate我们的模型设计和学习长时间范围的重要性。我们的模型在LVU标准准则上实现了多个任务的state-of-the-art，并且比前一些工作更加数据效率。最后，我们测试了我们的模型的传输性，并在五个不同的标准准则上设置了新的state-of-the-art。
</details></li>
</ul>
<hr>
<h2 id="Towards-Large-scale-3D-Representation-Learning-with-Multi-dataset-Point-Prompt-Training"><a href="#Towards-Large-scale-3D-Representation-Learning-with-Multi-dataset-Point-Prompt-Training" class="headerlink" title="Towards Large-scale 3D Representation Learning with Multi-dataset Point Prompt Training"></a>Towards Large-scale 3D Representation Learning with Multi-dataset Point Prompt Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09718">http://arxiv.org/abs/2308.09718</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Pointcept/Pointcept">https://github.com/Pointcept/Pointcept</a></li>
<li>paper_authors: Xiaoyang Wu, Zhuotao Tian, Xin Wen, Bohao Peng, Xihui Liu, Kaicheng Yu, Hengshuang Zhao</li>
<li>for: 提高3D深度学习模型的性能和通用性，即使只使用有限的大规模3D数据。</li>
<li>methods: 提出Point Prompt Training（PPT）框架，支持多种预训练方法，包括Prompt-driven Normalization和Language-guided Categorical Alignment等技术。</li>
<li>results: 经验表明，PPT可以缓解多 dataset 学习中的负转移现象，并生成高质量的表示。在多种不同的3D下世界任务上，PPT在单个模型下实现了最佳性能，并在多种预训练方法中占据了主导地位。<details>
<summary>Abstract</summary>
The rapid advancement of deep learning models often attributes to their ability to leverage massive training data. In contrast, such privilege has not yet fully benefited 3D deep learning, mainly due to the limited availability of large-scale 3D datasets. Merging multiple available data sources and letting them collaboratively train a single model is a potential solution. However, due to the large domain gap between 3D point cloud datasets, such mixed supervision could adversely affect the model's performance and lead to degenerated performance (i.e., negative transfer) compared to single-dataset training. In view of this challenge, we introduce Point Prompt Training (PPT), a novel framework for multi-dataset synergistic learning in the context of 3D representation learning that supports multiple pre-training paradigms. Based on this framework, we propose Prompt-driven Normalization, which adapts the model to different datasets with domain-specific prompts and Language-guided Categorical Alignment that decently unifies the multiple-dataset label spaces by leveraging the relationship between label text. Extensive experiments verify that PPT can overcome the negative transfer associated with synergistic learning and produce generalizable representations. Notably, it achieves state-of-the-art performance on each dataset using a single weight-shared model with supervised multi-dataset training. Moreover, when served as a pre-training framework, it outperforms other pre-training approaches regarding representation quality and attains remarkable state-of-the-art performance across over ten diverse downstream tasks spanning both indoor and outdoor 3D scenarios.
</details>
<details>
<summary>摘要</summary>
“深度学习模型的快速进步 frequently 归功于它们可以利用大量的训练数据。然而，三维深度学习尚未得到完全的利益，主要是因为三维数据集的有限性。将多个可用的数据源合并并让它们共同训练单个模型是一个可能的解决方案。然而，由于三维点云数据集之间的域 gap 较大，这种混合超vision 可能会对模型的性能产生负面影响（即负向传播），而不是单 dataset 训练。为此，我们介绍 Point Prompt Training（PPT），一种多数据集协同学习框架，支持多种预训练方法。基于这个框架，我们提出 Prompt-driven Normalization，使模型适应不同数据集的域特定提示，并Language-guided Categorical Alignment，通过利用标签文本之间的关系，有效地统一多个数据集的标签空间。广泛的实验表明，PPT 可以超越负向传播，生成普适的表示。其中，使用单个权重共享模型进行多数据集超vised 训练，可以达到每个数据集的最优性能。此外，作为预训练框架，PPT 比其他预训练方法在表示质量和下游任务中表现出色，在室内和室外的多种3D场景中具有惊人的状态 искусternal 表现。”
</details></li>
</ul>
<hr>
<h2 id="Smoothness-Similarity-Regularization-for-Few-Shot-GAN-Adaptation"><a href="#Smoothness-Similarity-Regularization-for-Few-Shot-GAN-Adaptation" class="headerlink" title="Smoothness Similarity Regularization for Few-Shot GAN Adaptation"></a>Smoothness Similarity Regularization for Few-Shot GAN Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09717">http://arxiv.org/abs/2308.09717</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vadim Sushko, Ruyu Wang, Juergen Gall</li>
<li>for: 这个研究的目的是提高几张训练图像下的GAN适应率，并且可以处理两个不同结构的资料集。</li>
<li>methods: 这个研究提出了一个新的平滑相似性规范，用于将预训练的GAN模型转换到几张训练图像的目标领域，即使两个领域的物件结构很不同。</li>
<li>results: 这个研究的结果显示，在两个不同结构的资料集中，这个新的平滑相似性规范可以将预训练的GAN模型转换到几张训练图像的目标领域，并且与预训练的GAN模型相比，可以提高适应率。<details>
<summary>Abstract</summary>
The task of few-shot GAN adaptation aims to adapt a pre-trained GAN model to a small dataset with very few training images. While existing methods perform well when the dataset for pre-training is structurally similar to the target dataset, the approaches suffer from training instabilities or memorization issues when the objects in the two domains have a very different structure. To mitigate this limitation, we propose a new smoothness similarity regularization that transfers the inherently learned smoothness of the pre-trained GAN to the few-shot target domain even if the two domains are very different. We evaluate our approach by adapting an unconditional and a class-conditional GAN to diverse few-shot target domains. Our proposed method significantly outperforms prior few-shot GAN adaptation methods in the challenging case of structurally dissimilar source-target domains, while performing on par with the state of the art for similar source-target domains.
</details>
<details>
<summary>摘要</summary>
文本：几张图像ew-shot GAN适应的任务是使得预训练GAN模型适应一个具有非常少的训练图像的小数据集。现有的方法在预训练数据集和目标数据集的结构相似时表现良好，但是这些方法在物体在两个领域中具有非常不同的结构时受训练不稳定或记忆问题的影响。为了解决这些限制，我们提出了一种新的平滑相似性规范，将预训练GAN中内在学习的平滑性传递到几张图像目标领域，即使两个领域具有非常不同的结构。我们通过对无条件GAN和类别GAN进行适应，评估了我们的方法。我们的提议方法在预训练和目标领域结构不相似的情况下显著超过先前的几张图像GAN适应方法，并在相似的预训练和目标领域情况下与状态的艺术相当。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-3D-Gaussians-Tracking-by-Persistent-Dynamic-View-Synthesis"><a href="#Dynamic-3D-Gaussians-Tracking-by-Persistent-Dynamic-View-Synthesis" class="headerlink" title="Dynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis"></a>Dynamic 3D Gaussians: Tracking by Persistent Dynamic View Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09713">http://arxiv.org/abs/2308.09713</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonathon Luiten, Georgios Kopanas, Bastian Leibe, Deva Ramanan</li>
<li>for: 该 paper 旨在同时解决动态场景新视图合成和六自由度（6-DOF）跟踪所有紧凑场景元素的问题。</li>
<li>methods: 作者采用了分析合成框架， Drawing inspiration from recent work that models scenes as a collection of 3D Gaussians, which are optimized to reconstruct input images via differentiable rendering.</li>
<li>results: 作者实现了一种可以同时解决动态场景新视图合成和6-DOF跟踪的方法，并且不需要输入任何匹配或流体。这种方法可以自动捕捉和跟踪场景中的所有紧凑元素，包括场景的旋转。<details>
<summary>Abstract</summary>
We present a method that simultaneously addresses the tasks of dynamic scene novel-view synthesis and six degree-of-freedom (6-DOF) tracking of all dense scene elements. We follow an analysis-by-synthesis framework, inspired by recent work that models scenes as a collection of 3D Gaussians which are optimized to reconstruct input images via differentiable rendering. To model dynamic scenes, we allow Gaussians to move and rotate over time while enforcing that they have persistent color, opacity, and size. By regularizing Gaussians' motion and rotation with local-rigidity constraints, we show that our Dynamic 3D Gaussians correctly model the same area of physical space over time, including the rotation of that space. Dense 6-DOF tracking and dynamic reconstruction emerges naturally from persistent dynamic view synthesis, without requiring any correspondence or flow as input. We demonstrate a large number of downstream applications enabled by our representation, including first-person view synthesis, dynamic compositional scene synthesis, and 4D video editing.
</details>
<details>
<summary>摘要</summary>
我们提出了一种方法，同时解决动态场景新视角合成和所有精细场景元素的六度自由（6-DOF）跟踪问题。我们采用分析合成框架，受到最近的Scene模型研究的启发，将场景视为一个集合的3D Gaussian，通过可导渲染来重建输入图像。为模型动态场景，我们允许Gaussian在时间上移动和旋转，并且保持颜色、透明度和大小的 persistency。通过对Gaussian的运动和旋转进行地方刚性约束，我们证明了我们的动态3D Gaussian correctly模型了物理空间的同一个区域在时间上的变化，包括空间的旋转。基于持续动态视思操作，我们无需输入对应或流动，直接从持续动态视思渲染中获得精细6-DOF跟踪和动态重建。我们示出了大量的下游应用，包括首人视图合成、动态组合场景合成和4D视频编辑。
</details></li>
</ul>
<hr>
<h2 id="HumanLiff-Layer-wise-3D-Human-Generation-with-Diffusion-Model"><a href="#HumanLiff-Layer-wise-3D-Human-Generation-with-Diffusion-Model" class="headerlink" title="HumanLiff: Layer-wise 3D Human Generation with Diffusion Model"></a>HumanLiff: Layer-wise 3D Human Generation with Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09712">http://arxiv.org/abs/2308.09712</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shoukang Hu, Fangzhou Hong, Tao Hu, Liang Pan, Haiyi Mei, Weiye Xiao, Lei Yang, Ziwei Liu</li>
<li>for: 本研究旨在提出一种层 wise 3D 人体生成模型，即 HumanLiff，该模型可以具有高精度和控制性，并能够生成层 wise 3D 人体。</li>
<li>methods: HumanLiff 模型使用了 diffusion-based 3D 条件生成方法，首先生成 minimal-clothed 人体，然后逐层生成衣物。另外，为了提高 3D 生成的精度，该模型还提出了 tri-plane shift 操作和层 wise 特征融合方法。</li>
<li>results: 对于 SynBody 和 TightCap 两个层 wise 3D 人体数据集，HumanLiff 模型在层 wise 3D 人体生成方面表现出了显著的优异性，与现有的状态对比方法相比，它可以生成更精度和更控制性的 3D 人体。<details>
<summary>Abstract</summary>
3D human generation from 2D images has achieved remarkable progress through the synergistic utilization of neural rendering and generative models. Existing 3D human generative models mainly generate a clothed 3D human as an undetectable 3D model in a single pass, while rarely considering the layer-wise nature of a clothed human body, which often consists of the human body and various clothes such as underwear, outerwear, trousers, shoes, etc. In this work, we propose HumanLiff, the first layer-wise 3D human generative model with a unified diffusion process. Specifically, HumanLiff firstly generates minimal-clothed humans, represented by tri-plane features, in a canonical space, and then progressively generates clothes in a layer-wise manner. In this way, the 3D human generation is thus formulated as a sequence of diffusion-based 3D conditional generation. To reconstruct more fine-grained 3D humans with tri-plane representation, we propose a tri-plane shift operation that splits each tri-plane into three sub-planes and shifts these sub-planes to enable feature grid subdivision. To further enhance the controllability of 3D generation with 3D layered conditions, HumanLiff hierarchically fuses tri-plane features and 3D layered conditions to facilitate the 3D diffusion model learning. Extensive experiments on two layer-wise 3D human datasets, SynBody (synthetic) and TightCap (real-world), validate that HumanLiff significantly outperforms state-of-the-art methods in layer-wise 3D human generation. Our code will be available at https://skhu101.github.io/HumanLiff.
</details>
<details>
<summary>摘要</summary>
人体三维生成从二维图像中得到了惊人的进步，通过神经渲染和生成模型的共同使用。现有的三维人体生成模型主要生成一个穿着衣服的三维人体，而rarely考虑人体层次结构，人体通常由躯体和衣服组成，如内衣、外衣、裤子、鞋等。在这项工作中，我们提出了人类生命（HumanLiff），首先生成最小化穿着衣服的三维人体，用三个平面特征表示，然后逐层生成衣服。因此，三维人体生成被定义为一个序列的扩散基于三维条件的生成。为了重建更细腻的三维人体，我们提出了三个平面移动操作，将每个平面分成三个子平面，并将这些子平面移动以实现特征网格分解。此外，为了进一步提高三维生成的控制性，人类生命层次融合三个平面特征和三维层次条件，以便扩散模型学习。广泛的实验表明，人类生命在两个层次三维人体数据集（SynBody和TightCap）上显著超越了当前的状态艺术法。我们的代码将在https://skhu101.github.io/HumanLiff上公开。
</details></li>
</ul>
<hr>
<h2 id="Robust-Monocular-Depth-Estimation-under-Challenging-Conditions"><a href="#Robust-Monocular-Depth-Estimation-under-Challenging-Conditions" class="headerlink" title="Robust Monocular Depth Estimation under Challenging Conditions"></a>Robust Monocular Depth Estimation under Challenging Conditions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09711">http://arxiv.org/abs/2308.09711</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/md4all/md4all">https://github.com/md4all/md4all</a></li>
<li>paper_authors: Stefano Gasperini, Nils Morbitzer, HyunJun Jung, Nassir Navab, Federico Tombari</li>
<li>for: 提高单目深度估计的可靠性，特别是在不良环境和天气条件下。</li>
<li>methods: 利用现有方法的效果，生成复杂样本集，并通过自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自我或全自动超级视图指导模型进行自<details>
<summary>Abstract</summary>
While state-of-the-art monocular depth estimation approaches achieve impressive results in ideal settings, they are highly unreliable under challenging illumination and weather conditions, such as at nighttime or in the presence of rain. In this paper, we uncover these safety-critical issues and tackle them with md4all: a simple and effective solution that works reliably under both adverse and ideal conditions, as well as for different types of learning supervision. We achieve this by exploiting the efficacy of existing methods under perfect settings. Therefore, we provide valid training signals independently of what is in the input. First, we generate a set of complex samples corresponding to the normal training ones. Then, we train the model by guiding its self- or full-supervision by feeding the generated samples and computing the standard losses on the corresponding original images. Doing so enables a single model to recover information across diverse conditions without modifications at inference time. Extensive experiments on two challenging public datasets, namely nuScenes and Oxford RobotCar, demonstrate the effectiveness of our techniques, outperforming prior works by a large margin in both standard and challenging conditions. Source code and data are available at: https://md4all.github.io.
</details>
<details>
<summary>摘要</summary>
当前最先进的单目深度估计方法在理想的Setting下可以达到印象人的结果，但在具有挑战性的照明和天气条件下（如夜晚或雨天），它们的可靠性却非常低。在这篇论文中，我们揭示了这些安全关键问题，并使用md4all：一种简单而有效的解决方案，可靠地在不 идеаль的Setting下运行，并且可以处理不同类型的学习监督。我们通过利用现有方法在完美 Setting下的效果，来提供有效的训练信号，无论输入内容如何。首先，我们生成了一组复杂的样本，与常见的训练样本相对应。然后，我们使用这些生成的样本进行自我或全自监督，通过计算相应的原始图像上的标准损失来训练模型。这样做的好处是，一个模型可以在执行时不需要修改，就能够在多种Setting下恢复信息。我们在两个公共的挑战性数据集（即nuScenes和Oxford RobotCar）进行了广泛的实验，并证明了我们的技术的有效性，与先前的成果相比，在标准和挑战性的Setting下都有大幅度的提高。软件代码和数据可以在以下网址获取：https://md4all.github.io。
</details></li>
</ul>
<hr>
<h2 id="Training-with-Product-Digital-Twins-for-AutoRetail-Checkout"><a href="#Training-with-Product-Digital-Twins-for-AutoRetail-Checkout" class="headerlink" title="Training with Product Digital Twins for AutoRetail Checkout"></a>Training with Product Digital Twins for AutoRetail Checkout</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09708">http://arxiv.org/abs/2308.09708</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yorkeyao/automated-retail-checkout">https://github.com/yorkeyao/automated-retail-checkout</a></li>
<li>paper_authors: Yue Yao, Xinyu Tian, Zheng Tang, Sujit Biswas, Huan Lei, Tom Gedeon, Liang Zheng</li>
<li>for: 这 paper 的目的是为了自动化商业 checkout 过程，提高用户体验和效率。</li>
<li>methods: 该 paper 使用了产品 3D 模型，通过图形引擎渲染来生成快速、灵活、大规模的训练数据。它还提出了一种训练数据优化框架，通过使用产品 3D 模型来生成“数字双胞胎”，以增强训练数据的可靠性和效果。</li>
<li>results: 该 paper 的实验表明，使用“数字双胞胎”训练集可以提高产品检测和跟踪模型的准确率，并且可以与 Pseudo-labeled 的实际检查数据组合使用，进一步提高模型的性能。<details>
<summary>Abstract</summary>
Automating the checkout process is important in smart retail, where users effortlessly pass products by hand through a camera, triggering automatic product detection, tracking, and counting. In this emerging area, due to the lack of annotated training data, we introduce a dataset comprised of product 3D models, which allows for fast, flexible, and large-scale training data generation through graphic engine rendering. Within this context, we discern an intriguing facet, because of the user "hands-on" approach, bias in user behavior leads to distinct patterns in the real checkout process. The existence of such patterns would compromise training effectiveness if training data fail to reflect the same. To address this user bias problem, we propose a training data optimization framework, i.e., training with digital twins (DtTrain). Specifically, we leverage the product 3D models and optimize their rendering viewpoint and illumination to generate "digital twins" that visually resemble representative user images. These digital twins, inherit product labels and, when augmented, form the Digital Twin training set (DT set). Because the digital twins individually mimic user bias, the resulting DT training set better reflects the characteristics of the target scenario and allows us to train more effective product detection and tracking models. In our experiment, we show that DT set outperforms training sets created by existing dataset synthesis methods in terms of counting accuracy. Moreover, by combining DT set with pseudo-labeled real checkout data, further improvement is observed. The code is available at https://github.com/yorkeyao/Automated-Retail-Checkout.
</details>
<details>
<summary>摘要</summary>
自动化购物过程是智能零售中的重要方面，用户可以轻松地通过摄像头传输产品，触发自动产品检测、跟踪和计数。在这个emerging领域中，由于缺乏标注的训练数据，我们提出了一个包含产品3D模型的数据集，允许快速、灵活和大规模的训练数据生成。在这个上下文中，我们发现了一个有趣的特点，即由于用户“手动”的方式，用户的行为偏好会导致实际检查出 процесс中的差异。如果训练数据不能够反映这些差异， то这将对训练效果产生负面影响。为解决这个用户偏好问题，我们提出了一个训练数据优化框架，即使用数字双子（DtTrain）训练。具体来说，我们利用产品3D模型，并且优化它们的渲染视角和照明，以生成“数字双子”，这些数字双子 inherit 产品标签，并且当加以扩展时，组成了数字双子训练集（DT集）。由于数字双子具有用户偏好，DT集更好地反映了目标场景的特点，可以训练更有效的产品检测和跟踪模型。在我们的实验中，我们发现DT集比现有的数据集生成方法在计数准确性方面表现出色。此外，通过组合DT集和 Pseudo-labeled 实际检查数据，进一步提高了性能。代码可以在 <https://github.com/yorkeyao/Automated-Retail-Checkout> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Guide3D-Create-3D-Avatars-from-Text-and-Image-Guidance"><a href="#Guide3D-Create-3D-Avatars-from-Text-and-Image-Guidance" class="headerlink" title="Guide3D: Create 3D Avatars from Text and Image Guidance"></a>Guide3D: Create 3D Avatars from Text and Image Guidance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09705">http://arxiv.org/abs/2308.09705</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yukangcao/Guide3D">https://github.com/yukangcao/Guide3D</a></li>
<li>paper_authors: Yukang Cao, Yan-Pei Cao, Kai Han, Ying Shan, Kwan-Yee K. Wong</li>
<li>for: 本研究旨在开发一种高效的文本和图像引导的三维生成模型，用于生成高分辨率的纹理网格。</li>
<li>methods: 我们提出了一种基于扩散模型的零引入文本和图像引导生成模型，包括生成多视图图像并jointly优化多分辨率响应的抽象四角体网格。我们还提出了一种相似性意识的特征融合策略，以有效地集成不同视图的特征。</li>
<li>results: 我们的框架在生成三维 geometry和高分辨率纹理上达到了现状之最，并且可以直接将二维生成的图像传递到三维空间中。我们的代码将会公开发布。<details>
<summary>Abstract</summary>
Recently, text-to-image generation has exhibited remarkable advancements, with the ability to produce visually impressive results. In contrast, text-to-3D generation has not yet reached a comparable level of quality. Existing methods primarily rely on text-guided score distillation sampling (SDS), and they encounter difficulties in transferring 2D attributes of the generated images to 3D content. In this work, we aim to develop an effective 3D generative model capable of synthesizing high-resolution textured meshes by leveraging both textual and image information. To this end, we introduce Guide3D, a zero-shot text-and-image-guided generative model for 3D avatar generation based on diffusion models. Our model involves (1) generating sparse-view images of a text-consistent character using diffusion models, and (2) jointly optimizing multi-resolution differentiable marching tetrahedral grids with pixel-aligned image features. We further propose a similarity-aware feature fusion strategy for efficiently integrating features from different views. Moreover, we introduce two novel training objectives as an alternative to calculating SDS, significantly enhancing the optimization process. We thoroughly evaluate the performance and components of our framework, which outperforms the current state-of-the-art in producing topologically and structurally correct geometry and high-resolution textures. Guide3D enables the direct transfer of 2D-generated images to the 3D space. Our code will be made publicly available.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:最近，文本到图像生成技术已经做出了很大的进步，能够生成非常印象深刻的图像。相比之下，文本到3D生成技术还没有达到相同的水平。现有方法主要依靠文本指导分数散热抽取样本（SDS），但它们在将2D生成图像中的特征传递到3D内容上遇到了困难。在这个工作中，我们目标是开发一种高效的3D生成模型，能够通过文本和图像信息来生成高分辨率的纹理镜面。为此，我们提出了 Guide3D，一种基于扩散模型的零shot文本和图像引导的3D人物生成模型。我们的模型包括（1）通过扩散模型生成文本一致的人物各个视角的稀疏图像，以及（2）同时优化多resolution的可 diferentiable marching tetrahedral网格和像素对齐的图像特征。我们还提出了一种相似性意识的特征融合策略，以高效地将不同视角的特征集成。此外，我们引入了两种新的训练目标，作为SDS的代替方法，有助于优化过程。我们 thorougly评估了我们的框架的性能和组件，其表现超越当前状态的艺术，能够生成正确的 topology和结构，以及高分辨率的纹理。 Guide3D可以将2D生成的图像直接传递到3D空间。我们的代码将公开发布。
</details></li>
</ul>
<hr>
<h2 id="Invariant-Training-2D-3D-Joint-Hard-Samples-for-Few-Shot-Point-Cloud-Recognition"><a href="#Invariant-Training-2D-3D-Joint-Hard-Samples-for-Few-Shot-Point-Cloud-Recognition" class="headerlink" title="Invariant Training 2D-3D Joint Hard Samples for Few-Shot Point Cloud Recognition"></a>Invariant Training 2D-3D Joint Hard Samples for Few-Shot Point Cloud Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09694">http://arxiv.org/abs/2308.09694</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuanyu Yi, Jiajun Deng, Qianru Sun, Xian-Sheng Hua, Joo-Hwee Lim, Hanwang Zhang</li>
<li>for: 增强ew-shot点云识别任务中数据稀缺问题的解决方案，使用一个joint预测方法，即一个常见的3D模型和一个培养得非常好的2D模型。</li>
<li>methods: 使用一种新的 invariant 训练策略，称为InvJoint，不仅更强调训练’’joint困难样本’’，还寻找2D和3D模型之间的相互关系。</li>
<li>results: 对ModelNet10&#x2F;40、ScanObjectNN和Toys4K等三个领域进行了广泛的实验，证明了InvJoint可以学习更好的2D和3D表示，从而提高 ensemble 的性能。<details>
<summary>Abstract</summary>
We tackle the data scarcity challenge in few-shot point cloud recognition of 3D objects by using a joint prediction from a conventional 3D model and a well-trained 2D model. Surprisingly, such an ensemble, though seems trivial, has hardly been shown effective in recent 2D-3D models. We find out the crux is the less effective training for the ''joint hard samples'', which have high confidence prediction on different wrong labels, implying that the 2D and 3D models do not collaborate well. To this end, our proposed invariant training strategy, called InvJoint, does not only emphasize the training more on the hard samples, but also seeks the invariance between the conflicting 2D and 3D ambiguous predictions. InvJoint can learn more collaborative 2D and 3D representations for better ensemble. Extensive experiments on 3D shape classification with widely adopted ModelNet10/40, ScanObjectNN and Toys4K, and shape retrieval with ShapeNet-Core validate the superiority of our InvJoint.
</details>
<details>
<summary>摘要</summary>
我们解决了很少样本点云识别三维物体中的数据缺乏挑战，通过使用一个 conjunction 的预测，来 combinational 一个常见的三维模型和一个已经训练好的二维模型。尽管这种ensemble 看起来很简单，但它在最近的二维-三维模型中几乎没有被研究过。我们发现，问题的关键在于“联合困难样本”的训练不够有效，这些样本有高信心地预测不同的错误标签，表明二维和三维模型之间没有协作良好。为此，我们提出了一种不变训练策略，即 InvJoint，不仅更多地训练“联合困难样本”，而且寻求这些样本之间的不变性。InvJoint 能够学习更好地协作的二维和三维表示，从而提高ensemble的性能。我们在广泛采用的 ModelNet10/40、ScanObjectNN 和 Toys4K 等三维形状分类和 ShapeNet-Core 等形状检索任务上进行了广泛的实验，并证明了 InvJoint 的超越性。
</details></li>
</ul>
<hr>
<h2 id="A-Lightweight-Transformer-for-Faster-and-Robust-EBSD-Data-Collection"><a href="#A-Lightweight-Transformer-for-Faster-and-Robust-EBSD-Data-Collection" class="headerlink" title="A Lightweight Transformer for Faster and Robust EBSD Data Collection"></a>A Lightweight Transformer for Faster and Robust EBSD Data Collection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09693">http://arxiv.org/abs/2308.09693</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hdong920/ebsd_slice_recovery">https://github.com/hdong920/ebsd_slice_recovery</a></li>
<li>paper_authors: Harry Dong, Sean Donegan, Megna Shah, Yuejie Chi</li>
<li>for: 提高3D EBSD数据质量和收集效率</li>
<li>methods: 使用变换器模型和投影算法进行数据处理和恢复</li>
<li>results: 使用自我超视觉学习和 Synthetic 3D EBSD数据进行训练，在实际3D EBSD数据上获得更高的恢复精度 compared to 现有方法<details>
<summary>Abstract</summary>
Three dimensional electron back-scattered diffraction (EBSD) microscopy is a critical tool in many applications in materials science, yet its data quality can fluctuate greatly during the arduous collection process, particularly via serial-sectioning. Fortunately, 3D EBSD data is inherently sequential, opening up the opportunity to use transformers, state-of-the-art deep learning architectures that have made breakthroughs in a plethora of domains, for data processing and recovery. To be more robust to errors and accelerate this 3D EBSD data collection, we introduce a two step method that recovers missing slices in an 3D EBSD volume, using an efficient transformer model and a projection algorithm to process the transformer's outputs. Overcoming the computational and practical hurdles of deep learning with scarce high dimensional data, we train this model using only synthetic 3D EBSD data with self-supervision and obtain superior recovery accuracy on real 3D EBSD data, compared to existing methods.
</details>
<details>
<summary>摘要</summary>
三维电子反射干扰diffraction（EBSD）镜像是物理科学中多种应用的重要工具，但其数据质量可能会在收集过程中出现大幅波动，特别是通过串行sectioning。幸运的是，3D EBSD数据是串行的，这开 up了使用 transformers，当前领域的最先进深度学习架构，进行数据处理和恢复的机会。为了更加鲁棒地处理错误和加速3D EBSD数据收集，我们介绍了一种两步方法，使用高效的 transformer 模型和投影算法来处理 transformer 的输出。通过对深度学习的计算和实践障碍而不是高维数据，我们使用只有自我超vision的 Synthetic 3D EBSD 数据进行训练，并在实际3D EBSD数据上获得了比现有方法更高的恢复精度。
</details></li>
</ul>
<hr>
<h2 id="Audiovisual-Moments-in-Time-A-Large-Scale-Annotated-Dataset-of-Audiovisual-Actions"><a href="#Audiovisual-Moments-in-Time-A-Large-Scale-Annotated-Dataset-of-Audiovisual-Actions" class="headerlink" title="Audiovisual Moments in Time: A Large-Scale Annotated Dataset of Audiovisual Actions"></a>Audiovisual Moments in Time: A Large-Scale Annotated Dataset of Audiovisual Actions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09685">http://arxiv.org/abs/2308.09685</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mjoannou/audiovisual-moments-in-time">https://github.com/mjoannou/audiovisual-moments-in-time</a></li>
<li>paper_authors: Michael Joannou, Pia Rotshtein, Uta Noppeney</li>
<li>for: 这个论文主要是为了提供一个大规模的audiovisual动作事件数据集（AVMIT），以便用于计算机模型和人类参与者之间的研究。</li>
<li>methods: 这篇论文使用了一个大规模的注释任务，采集了3秒的audiovisual视频，并由11名参与者进行了分类。每个试验都需要参与者确定 audiovisual动作事件是否存在，以及这个事件是否是视频中最显著的特征。</li>
<li>results: 论文表明，使用AVMIT注释数据集可以提高audiovisual事件认识性能，特别是在 audiovisual对应性是关键的研究问题上。在6个回归神经网络（RNN）中，通过专门在audiovisual事件上进行训练，可以提高测试集的准确率，而不是使用模式性无关的事件。<details>
<summary>Abstract</summary>
We present Audiovisual Moments in Time (AVMIT), a large-scale dataset of audiovisual action events. In an extensive annotation task 11 participants labelled a subset of 3-second audiovisual videos from the Moments in Time dataset (MIT). For each trial, participants assessed whether the labelled audiovisual action event was present and whether it was the most prominent feature of the video. The dataset includes the annotation of 57,177 audiovisual videos, each independently evaluated by 3 of 11 trained participants. From this initial collection, we created a curated test set of 16 distinct action classes, with 60 videos each (960 videos). We also offer 2 sets of pre-computed audiovisual feature embeddings, using VGGish/YamNet for audio data and VGG16/EfficientNetB0 for visual data, thereby lowering the barrier to entry for audiovisual DNN research. We explored the advantages of AVMIT annotations and feature embeddings to improve performance on audiovisual event recognition. A series of 6 Recurrent Neural Networks (RNNs) were trained on either AVMIT-filtered audiovisual events or modality-agnostic events from MIT, and then tested on our audiovisual test set. In all RNNs, top 1 accuracy was increased by 2.71-5.94\% by training exclusively on audiovisual events, even outweighing a three-fold increase in training data. We anticipate that the newly annotated AVMIT dataset will serve as a valuable resource for research and comparative experiments involving computational models and human participants, specifically when addressing research questions where audiovisual correspondence is of critical importance.
</details>
<details>
<summary>摘要</summary>
我们介绍Audiovisual Moments in Time（AVMIT）数据集，这是一个大规模的 audiovisual 动作事件数据集。在一项大规模的注释任务中，11名参与者对 Mit 数据集（Moments in Time）中的3秒audiovisual视频进行了注释。为每个试验，参与者判断 audiovisual 动作事件是否存在，以及它是视频中最出色的特征。该数据集包括57,177个 audiovisual 视频，每个视频都被3名训练参与者独立地评估。从这个初始集合中，我们创建了一个精心选择的测试集，包含16种不同的动作类别，每个类别有60个视频（共960个视频）。我们还提供了2个预计算的 audiovisual 特征嵌入，使用VGGish/YamNet для音频数据和VGG16/EfficientNetB0 для视频数据，从而降低了audiovisual DNN研究的门槛。我们explored AVMIT 注释和特征嵌入的优点，以提高audiovisual事件认识的性能。6个回归神经网络（RNNs）在AVMIT中过滤 audiovisual 事件或MIT中的模态无关事件，然后在我们的audiovisual测试集上进行测试。在所有RNNs中，在训练 exclusively 于 audiovisual 事件上，精度提高了2.71-5.94%，甚至超过了模态无关事件的三倍增长。我们预计，新注释的 AVMIT 数据集将成为研究计算模型和人类参与者之间的 valuable 资源，特别是在研究问题中，audiovisual 协调的重要性非常高。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/19/cs.CV_2023_08_19/" data-id="clogyj8xm00g87cracoa71610" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_19" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/19/cs.AI_2023_08_19/" class="article-date">
  <time datetime="2023-08-19T12:00:00.000Z" itemprop="datePublished">2023-08-19</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/19/cs.AI_2023_08_19/">cs.AI - 2023-08-19</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Efficient-Representation-Learning-for-Healthcare-with-Cross-Architectural-Self-Supervision"><a href="#Efficient-Representation-Learning-for-Healthcare-with-Cross-Architectural-Self-Supervision" class="headerlink" title="Efficient Representation Learning for Healthcare with Cross-Architectural Self-Supervision"></a>Efficient Representation Learning for Healthcare with Cross-Architectural Self-Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10064">http://arxiv.org/abs/2308.10064</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pranavsinghps1/CASS">https://github.com/pranavsinghps1/CASS</a></li>
<li>paper_authors: Pranav Singh, Jacopo Cirrone</li>
<li>for: 医疗和生物医学应用中的极端计算需求，使得表征学学习难以在实际医疗中应用。表征学学习可以提高深度学习架构的性能，但是现有的自我监督学习方法在使用较小的批处理大小或更短的预训练环节时，性能会下降。我们提出了跨建筑自监督学习（CASS）方法来解决这个挑战。</li>
<li>methods: 我们提出了一种新的带形自监督学习方法，即CASS，它利用了转换器和卷积神经网络（CNN）进行高效的学习。</li>
<li>results: 我们的实验表明，CASS训练的CNN和转换器在四个不同的医疗数据集上都能够超越现有的自监督学习方法。它只使用1%的标签数据进行微调，可以获得3.8%的平均提升，即使使用10%的标签数据，也可以获得5.9%的提升。在100%的标签数据下，CASS可以达到10.13%的显著提升。此外，CASS还可以降低预训练时间，比现有方法减少69%，使其更适合医疗实践。<details>
<summary>Abstract</summary>
In healthcare and biomedical applications, extreme computational requirements pose a significant barrier to adopting representation learning. Representation learning can enhance the performance of deep learning architectures by learning useful priors from limited medical data. However, state-of-the-art self-supervised techniques suffer from reduced performance when using smaller batch sizes or shorter pretraining epochs, which are more practical in clinical settings. We present Cross Architectural - Self Supervision (CASS) in response to this challenge. This novel siamese self-supervised learning approach synergistically leverages Transformer and Convolutional Neural Networks (CNN) for efficient learning. Our empirical evaluation demonstrates that CASS-trained CNNs and Transformers outperform existing self-supervised learning methods across four diverse healthcare datasets. With only 1% labeled data for finetuning, CASS achieves a 3.8% average improvement; with 10% labeled data, it gains 5.9%; and with 100% labeled data, it reaches a remarkable 10.13% enhancement. Notably, CASS reduces pretraining time by 69% compared to state-of-the-art methods, making it more amenable to clinical implementation. We also demonstrate that CASS is considerably more robust to variations in batch size and pretraining epochs, making it a suitable candidate for machine learning in healthcare applications.
</details>
<details>
<summary>摘要</summary>
在医疗和生物医学应用中，极高的计算需求成为了使用表示学习的障碍。表示学习可以提高深度学习架构的性能，通过从有限的医疗数据中学习有用的先验知识。然而，现有的自我监督技术在使用较小的批处理大小或更短的预训练轮次时表现下降，这些较实际的参数更适合临床应用。我们提出了交叉体系自我监督（CASS），以应对这个挑战。这种新的哈密顿自我监督学习方法可以高效地利用转换器和卷积神经网络（CNN）。我们的实验证明，CASS训练后的CNN和转换器都能超过现有的自我监督学习方法，在四种不同的医疗数据集上。具有1%标注数据进行精化，CASS得到了3.8%的均值提升；具有10%标注数据，它获得了5.9%的提升；具有100%标注数据，它达到了10.13%的增强。另外，CASS可以降低预训练时间的69%，使其更适合临床应用。我们还证明了CASS在批处理大小和预训练轮次的变化中表现更加稳定，使其成为医疗机器学习应用的合适候选人。
</details></li>
</ul>
<hr>
<h2 id="Robust-Fraud-Detection-via-Supervised-Contrastive-Learning"><a href="#Robust-Fraud-Detection-via-Supervised-Contrastive-Learning" class="headerlink" title="Robust Fraud Detection via Supervised Contrastive Learning"></a>Robust Fraud Detection via Supervised Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10055">http://arxiv.org/abs/2308.10055</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vinay M. S., Shuhan Yuan, Xintao Wu</li>
<li>for: 针对具有有限多样化劫持活动会话的开放集预测攻击检测问题</li>
<li>methods: 基于有效数据增强策略和超vised contrastive learning的敏捷框架ConRo</li>
<li>results: 与其他状态静态基eline相比，ConRo frameworks表现出了明显的性能提升<details>
<summary>Abstract</summary>
Deep learning models have recently become popular for detecting malicious user activity sessions in computing platforms. In many real-world scenarios, only a few labeled malicious and a large amount of normal sessions are available. These few labeled malicious sessions usually do not cover the entire diversity of all possible malicious sessions. In many scenarios, possible malicious sessions can be highly diverse. As a consequence, learned session representations of deep learning models can become ineffective in achieving a good generalization performance for unseen malicious sessions. To tackle this open-set fraud detection challenge, we propose a robust supervised contrastive learning based framework called ConRo, which specifically operates in the scenario where only a few malicious sessions having limited diversity is available. ConRo applies an effective data augmentation strategy to generate diverse potential malicious sessions. By employing these generated and available training set sessions, ConRo derives separable representations w.r.t open-set fraud detection task by leveraging supervised contrastive learning. We empirically evaluate our ConRo framework and other state-of-the-art baselines on benchmark datasets. Our ConRo framework demonstrates noticeable performance improvement over state-of-the-art baselines.
</details>
<details>
<summary>摘要</summary>
深度学习模型最近在计算平台中探测恶意用户活动会话中得到了广泛的应用。在实际场景中，通常只有一些标注了恶意的会话，而很多正常的会话是可用的。这些标注的恶意会话通常不能覆盖所有可能的恶意会话的多样性。因此，深度学习模型学习的会话表示可能变得不效果，导致在未看到的恶意会话上具有好的泛化性能。为解决这个开放集骗诈检测挑战，我们提出了一种可靠的超级视的对比学习框架 called ConRo，它专门适用于只有有限多样性的恶意会话。ConRo应用有效的数据扩展策略，生成了多样的可能的恶意会话。通过使用这些生成的和可用的训练集会话，ConRo derive了对于开放集骗诈检测任务的分离表示。我们对ConRo框架和其他状态前的基elines进行了实验评估。我们的ConRo框架在标准 benchmark 数据集上显示出了明显的性能提高。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-as-Zero-Shot-Conversational-Recommenders"><a href="#Large-Language-Models-as-Zero-Shot-Conversational-Recommenders" class="headerlink" title="Large Language Models as Zero-Shot Conversational Recommenders"></a>Large Language Models as Zero-Shot Conversational Recommenders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10053">http://arxiv.org/abs/2308.10053</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aaronheee/llms-as-zero-shot-conversational-recsys">https://github.com/aaronheee/llms-as-zero-shot-conversational-recsys</a></li>
<li>paper_authors: Zhankui He, Zhouhang Xie, Rahul Jha, Harald Steck, Dawen Liang, Yesu Feng, Bodhisattwa Prasad Majumder, Nathan Kallus, Julian McAuley</li>
<li>for: 这个论文的主要目的是研究使用大语言模型进行对话式推荐任务，以及对现有模型的 zeroshot 设定下的性能分析。</li>
<li>methods: 这个论文使用了代表性的大语言模型，并在一个 zeroshot  Setting下进行了实验研究。</li>
<li>results: 研究发现，无需细化训练，大语言模型可以在对话式推荐任务中超越现有的细化训练模型。此外，研究还提出了多种探索任务，以探究大语言模型在对话式推荐中的表现机制和限制。<details>
<summary>Abstract</summary>
In this paper, we present empirical studies on conversational recommendation tasks using representative large language models in a zero-shot setting with three primary contributions. (1) Data: To gain insights into model behavior in "in-the-wild" conversational recommendation scenarios, we construct a new dataset of recommendation-related conversations by scraping a popular discussion website. This is the largest public real-world conversational recommendation dataset to date. (2) Evaluation: On the new dataset and two existing conversational recommendation datasets, we observe that even without fine-tuning, large language models can outperform existing fine-tuned conversational recommendation models. (3) Analysis: We propose various probing tasks to investigate the mechanisms behind the remarkable performance of large language models in conversational recommendation. We analyze both the large language models' behaviors and the characteristics of the datasets, providing a holistic understanding of the models' effectiveness, limitations and suggesting directions for the design of future conversational recommenders
</details>
<details>
<summary>摘要</summary>
在本文中，我们提出了基于大语言模型的实验研究，以探讨在无需调教的情况下，大语言模型在实际对话推荐任务中的表现。我们的研究具有以下三个主要贡献：1. 数据：为了了解大语言模型在实际对话推荐场景中的行为，我们从流行的讨论网站中抓取了一个新的推荐相关对话集。这是目前最大的公共实际对话推荐数据集。2. 评估：在我们新建的数据集和两个现有的对话推荐数据集上，我们发现了一点：无需调教，大语言模型可以在对话推荐任务中超越现有的调教过的对话推荐模型。3. 分析：我们提出了多种探索任务，以Investigate大语言模型在对话推荐任务中的机制。我们分析了大语言模型的行为以及数据集的特点，从而提供了对未来对话推荐模型的设计方向的彻底理解。
</details></li>
</ul>
<hr>
<h2 id="The-Snowflake-Hypothesis-Training-Deep-GNN-with-One-Node-One-Receptive-field"><a href="#The-Snowflake-Hypothesis-Training-Deep-GNN-with-One-Node-One-Receptive-field" class="headerlink" title="The Snowflake Hypothesis: Training Deep GNN with One Node One Receptive field"></a>The Snowflake Hypothesis: Training Deep GNN with One Node One Receptive field</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10051">http://arxiv.org/abs/2308.10051</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kun Wang, Guohao Li, Shilong Wang, Guibin Zhang, Kai Wang, Yang You, Xiaojiang Peng, Yuxuan Liang, Yang Wang</li>
<li>for: 本研究主要探讨深度 Graph Neural Networks (GNNs) 在图像领域中的应用，尤其是 GNNs 在深度为多少时 Display over-fitting 和 over-smoothing 问题。</li>
<li>methods: 本研究使用了系统的研究方法，包括不同的训练方案、不同的 shallow 和 deep GNN 基础体系、不同的层数（8, 16, 32, 64）以及多个 benchmark 图。</li>
<li>results: 研究结果表明，我们的假设（Snowflake Hypothesis）可以作为一种通用的操作符，可以帮助深度 GNNs 在不同任务中表现更好，并且可以在可解释的和普遍的方式下选择最佳网络深度。<details>
<summary>Abstract</summary>
Despite Graph Neural Networks demonstrating considerable promise in graph representation learning tasks, GNNs predominantly face significant issues with over-fitting and over-smoothing as they go deeper as models of computer vision realm. In this work, we conduct a systematic study of deeper GNN research trajectories. Our findings indicate that the current success of deep GNNs primarily stems from (I) the adoption of innovations from CNNs, such as residual/skip connections, or (II) the tailor-made aggregation algorithms like DropEdge. However, these algorithms often lack intrinsic interpretability and indiscriminately treat all nodes within a given layer in a similar manner, thereby failing to capture the nuanced differences among various nodes. To this end, we introduce the Snowflake Hypothesis -- a novel paradigm underpinning the concept of ``one node, one receptive field''. The hypothesis draws inspiration from the unique and individualistic patterns of each snowflake, proposing a corresponding uniqueness in the receptive fields of nodes in the GNNs.   We employ the simplest gradient and node-level cosine distance as guiding principles to regulate the aggregation depth for each node, and conduct comprehensive experiments including: (1) different training schemes; (2) various shallow and deep GNN backbones, and (3) various numbers of layers (8, 16, 32, 64) on multiple benchmarks (six graphs including dense graphs with millions of nodes); (4) compare with different aggregation strategies. The observational results demonstrate that our hypothesis can serve as a universal operator for a range of tasks, and it displays tremendous potential on deep GNNs. It can be applied to various GNN frameworks, enhancing its effectiveness when operating in-depth, and guiding the selection of the optimal network depth in an explainable and generalizable way.
</details>
<details>
<summary>摘要</summary>
Despite Graph Neural Networks (GNNs) showing great promise in graph representation learning tasks, they still face significant issues with over-fitting and over-smoothing as they become deeper, especially in the field of computer vision. In this study, we conducted a systematic investigation of deeper GNN research trajectories. Our findings indicate that the current success of deep GNNs is mainly due to (I) the adoption of innovations from Convolutional Neural Networks (CNNs), such as residual/skip connections, or (II) the use of tailor-made aggregation algorithms like DropEdge. However, these algorithms often lack intrinsic interpretability and treat all nodes within a given layer in a similar manner, failing to capture the subtle differences among various nodes. To address this issue, we propose the Snowflake Hypothesis - a novel paradigm that emphasizes the uniqueness of each node's receptive field, inspired by the unique patterns of snowflakes.We use the simplest gradient and node-level cosine distance as guiding principles to regulate the aggregation depth for each node. We conduct comprehensive experiments, including different training schemes, various shallow and deep GNN backbones, and various numbers of layers (8, 16, 32, 64) on multiple benchmarks (six graphs with millions of nodes). Our results show that our hypothesis can serve as a universal operator for a range of tasks and displays great potential in deep GNNs. It can be applied to various GNN frameworks, enhancing their effectiveness when operating in-depth, and providing an explainable and generalizable way to select the optimal network depth.
</details></li>
</ul>
<hr>
<h2 id="Towards-Probabilistic-Causal-Discovery-Inference-Explanations-for-Autonomous-Drones-in-Mine-Surveying-Tasks"><a href="#Towards-Probabilistic-Causal-Discovery-Inference-Explanations-for-Autonomous-Drones-in-Mine-Surveying-Tasks" class="headerlink" title="Towards Probabilistic Causal Discovery, Inference &amp; Explanations for Autonomous Drones in Mine Surveying Tasks"></a>Towards Probabilistic Causal Discovery, Inference &amp; Explanations for Autonomous Drones in Mine Surveying Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10047">http://arxiv.org/abs/2308.10047</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ricardo Cannizzaro, Rhys Howard, Paulina Lewinska, Lars Kunze</li>
<li>for: 这篇论文旨在提供自主机器人理解数据生成过程，以便在实际环境中做出决策和解释结果。</li>
<li>methods: 该论文提出了一种可靠的概率 causal 框架，包括 causally-informed POMDP 规划、在线 SCM 适应以及后果Counterfactual 解释。</li>
<li>results: 该框架能够在含混合因素、非站点性和不可预测的环境中帮助自主机器人做出决策和解释结果。<details>
<summary>Abstract</summary>
Causal modelling offers great potential to provide autonomous agents the ability to understand the data-generation process that governs their interactions with the world. Such models capture formal knowledge as well as probabilistic representations of noise and uncertainty typically encountered by autonomous robots in real-world environments. Thus, causality can aid autonomous agents in making decisions and explaining outcomes, but deploying causality in such a manner introduces new challenges. Here we identify challenges relating to causality in the context of a drone system operating in a salt mine. Such environments are challenging for autonomous agents because of the presence of confounders, non-stationarity, and a difficulty in building complete causal models ahead of time. To address these issues, we propose a probabilistic causal framework consisting of: causally-informed POMDP planning, online SCM adaptation, and post-hoc counterfactual explanations. Further, we outline planned experimentation to evaluate the framework integrated with a drone system in simulated mine environments and on a real-world mine dataset.
</details>
<details>
<summary>摘要</summary>
causal模型提供了大量的潜在利器，以帮助自主代理人理解与世界进行交互的数据生成过程。这些模型捕捉了形式知识以及随机变量和不确定性的概率表示，通常在实际环境中遇到的自主机器人遇到的问题。因此， causality可以帮助自主代理人做出决策和解释结果，但是在这种方式下引入了新的挑战。在这篇文章中，我们识别了在钾矿环境中的 causality挑战，这些环境中存在干扰因素、非站点性和建立完整的 causal模型的困难。为解决这些问题，我们提议了一种概率 causal 框架，包括： causally-informed POMDP 规划、在线 SCM 适应和后续 counterfactual 解释。此外，我们还详细讲述了将这种框架与真实的矿山数据集集成的计划的实验。
</details></li>
</ul>
<hr>
<h2 id="Optimizing-Multi-Class-Text-Classification-A-Diverse-Stacking-Ensemble-Framework-Utilizing-Transformers"><a href="#Optimizing-Multi-Class-Text-Classification-A-Diverse-Stacking-Ensemble-Framework-Utilizing-Transformers" class="headerlink" title="Optimizing Multi-Class Text Classification: A Diverse Stacking Ensemble Framework Utilizing Transformers"></a>Optimizing Multi-Class Text Classification: A Diverse Stacking Ensemble Framework Utilizing Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11519">http://arxiv.org/abs/2308.11519</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anusuya Krishnan</li>
<li>for: 本研究旨在提高客户评价分类的准确率和可靠性，以便商家从客户评价中提取有益的反馈信息，提高客户满意度和驱动持续改进。</li>
<li>methods: 本研究提出了一种新的Stacking Ensemble基于transformer模型的多文本分类方法，通过将多个单个transformer模型，包括BERT、ELECTRA和DistilBERT，作为基础级分类器，以及一个基于RoBERTa的meta级分类器，生成最佳预测模型。</li>
<li>results: 实验结果表明，相比传统单个分类器模型，折衔ensemble基于transformer模型的多文本分类方法可以提高客户评价分类的准确率和稳定性，并且在实际客户评价数据集上得到了较高的效果。<details>
<summary>Abstract</summary>
Customer reviews play a crucial role in assessing customer satisfaction, gathering feedback, and driving improvements for businesses. Analyzing these reviews provides valuable insights into customer sentiments, including compliments, comments, and suggestions. Text classification techniques enable businesses to categorize customer reviews into distinct categories, facilitating a better understanding of customer feedback. However, challenges such as overfitting and bias limit the effectiveness of a single classifier in ensuring optimal prediction. This study proposes a novel approach to address these challenges by introducing a stacking ensemble-based multi-text classification method that leverages transformer models. By combining multiple single transformers, including BERT, ELECTRA, and DistilBERT, as base-level classifiers, and a meta-level classifier based on RoBERTa, an optimal predictive model is generated. The proposed stacking ensemble-based multi-text classification method aims to enhance the accuracy and robustness of customer review analysis. Experimental evaluations conducted on a real-world customer review dataset demonstrate the effectiveness and superiority of the proposed approach over traditional single classifier models. The stacking ensemble-based multi-text classification method using transformers proves to be a promising solution for businesses seeking to extract valuable insights from customer reviews and make data-driven decisions to enhance customer satisfaction and drive continuous improvement.
</details>
<details>
<summary>摘要</summary>
顾客评价对企业客户满意度评估、反馈收集和改进提供重要的指导意义。分析顾客评价可以获得价值的客户情感反馈，包括赞誉、评论和建议。文本分类技术可以将顾客评价分类为不同类别，以便更好地理解客户反馈。然而，过拟合和偏见问题限制了单个分类器的优化预测。这项研究提出了一种新的方法，利用堆 ensemble-based多文本分类方法，以解决这些问题。该方法组合多个单级 transformer 模型，包括 BERT、ELECTRA 和 DistilBERT，作为基础级分类器，并使用 RoBERTa 为高级分类器。这种堆 ensemble-based multi-text classification 方法的目的是提高客户评价分析的准确性和稳定性。实验表明，该方法在实际顾客评价数据集上的效果和优势，证明了该方法的有效性和可靠性。堆 ensemble-based multi-text classification 方法使用 transformers 是企业希望从顾客评价中提取有价值的信息，以便根据客户反馈提供数据驱动的决策，提高客户满意度和不断改进。
</details></li>
</ul>
<hr>
<h2 id="Causal-Intersectionality-and-Dual-Form-of-Gradient-Descent-for-Multimodal-Analysis-a-Case-Study-on-Hateful-Memes"><a href="#Causal-Intersectionality-and-Dual-Form-of-Gradient-Descent-for-Multimodal-Analysis-a-Case-Study-on-Hateful-Memes" class="headerlink" title="Causal Intersectionality and Dual Form of Gradient Descent for Multimodal Analysis: a Case Study on Hateful Memes"></a>Causal Intersectionality and Dual Form of Gradient Descent for Multimodal Analysis: a Case Study on Hateful Memes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11585">http://arxiv.org/abs/2308.11585</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yosuke Miyanishi, Minh Le Nguyen</li>
<li>for: 本研究旨在探讨如何使用可解释AI（XAI）和定义 semantics 来理解机器学习模型的内部机制，以便更好地理解模型的 causal effect。</li>
<li>methods: 本研究使用了 gradient-based 方法和 causal 分析方法，以 synergize 这两种方法来探讨模型的内部机制。</li>
<li>results: 研究发现，通过使用 intersectionality 理论，可以将忌视论检测问题表示为 averaged treatment effect（ATE），并且可以使用模态wise 概要来描述三种基于 transformer 的模型对 ATE 的不同行为。此外，研究还发现 latest LLM LLaMA2 在具有上下文学习设置下，能够拓宽忌视论检测问题的多样化特征。<details>
<summary>Abstract</summary>
In the wake of the explosive growth of machine learning (ML) usage, particularly within the context of emerging Large Language Models (LLMs), comprehending the semantic significance rooted in their internal workings is crucial. While causal analyses focus on defining semantics and its quantification, the gradient-based approach is central to explainable AI (XAI), tackling the interpretation of the black box. By synergizing these approaches, the exploration of how a model's internal mechanisms illuminate its causal effect has become integral for evidence-based decision-making. A parallel line of research has revealed that intersectionality - the combinatory impact of multiple demographics of an individual - can be structured in the form of an Averaged Treatment Effect (ATE). Initially, this study illustrates that the hateful memes detection problem can be formulated as an ATE, assisted by the principles of intersectionality, and that a modality-wise summarization of gradient-based attention attribution scores can delineate the distinct behaviors of three Transformerbased models concerning ATE. Subsequently, we show that the latest LLM LLaMA2 has the ability to disentangle the intersectional nature of memes detection in an in-context learning setting, with their mechanistic properties elucidated via meta-gradient, a secondary form of gradient. In conclusion, this research contributes to the ongoing dialogue surrounding XAI and the multifaceted nature of ML models.
</details>
<details>
<summary>摘要</summary>
在机器学习（ML）的激进发展中，特别是在新兴的大语言模型（LLM）上，理解其内部机制的含义是关键。而 causal 分析专注于定义 semantics 和其量化，而 gradient-based 方法是解释 AI（XAI）的中心，解释黑盒模型的含义。将这些方法相互融合，可以探索模型内部机制如何推动 causal effect的探索。同时，另一条研究表明，个体多个特征的交叉影响（intersectionality）可以通过 averaged treatment effect（ATE）的形式表示，并且在这种形式下，可以使用 modality-wise 汇总 gradient-based 注意力分配分数来解释三种基于 Transformer 的模型在 ATE 方面的不同行为。后续，我们发现 latest LLM LLaMA2 在 context learning 设定下可以准确地检测仇恨 Memes，并且通过 meta-gradient，一种次级的梯度，揭示这些机制的性质。因此，本研究对 XAI 和多方面 ML 模型的对话进行了贡献。
</details></li>
</ul>
<hr>
<h2 id="ClothesNet-An-Information-Rich-3D-Garment-Model-Repository-with-Simulated-Clothes-Environment"><a href="#ClothesNet-An-Information-Rich-3D-Garment-Model-Repository-with-Simulated-Clothes-Environment" class="headerlink" title="ClothesNet: An Information-Rich 3D Garment Model Repository with Simulated Clothes Environment"></a>ClothesNet: An Information-Rich 3D Garment Model Repository with Simulated Clothes Environment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09987">http://arxiv.org/abs/2308.09987</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bingyang Zhou, Haoyu Zhou, Tianhai Liang, Qiaojun Yu, Siheng Zhao, Yuwei Zeng, Jun Lv, Siyuan Luo, Qiancai Wang, Xinyuan Yu, Haonan Chen, Cewu Lu, Lin Shao</li>
<li>for: 这篇论文是为了提供一个大规模的3D衣物数据集，并将其注解为具有衣物特征、边框和关键点等信息。</li>
<li>methods: 该论文使用了大规模的3D衣物数据集，并在其中设置了衣物分类、边框分割和关键点检测等任务，以便用于计算机视觉和机器人交互任务。</li>
<li>results: 该论文通过实际实验表明，使用ClothesNet数据集可以帮助实现衣物感知和机器人交互任务，并且可以提供高质量的数据集和任务集。<details>
<summary>Abstract</summary>
We present ClothesNet: a large-scale dataset of 3D clothes objects with information-rich annotations. Our dataset consists of around 4400 models covering 11 categories annotated with clothes features, boundary lines, and keypoints. ClothesNet can be used to facilitate a variety of computer vision and robot interaction tasks. Using our dataset, we establish benchmark tasks for clothes perception, including classification, boundary line segmentation, and keypoint detection, and develop simulated clothes environments for robotic interaction tasks, including rearranging, folding, hanging, and dressing. We also demonstrate the efficacy of our ClothesNet in real-world experiments. Supplemental materials and dataset are available on our project webpage.
</details>
<details>
<summary>摘要</summary>
我们现在提出了 ClothesNet：一个大规模的3D衣物数据集，包含详细的注释信息。我们的数据集包含约4400个模型，涵盖11种类别，并且每个模型都有衣物特征、边界线和关键点的注释。ClothesNet可以用于促进计算机视觉和机器人互动任务。使用我们的数据集，我们建立了衣物识别、边界线分割和关键点检测的标准任务，并开发了机器人互动任务的模拟环境，包括重新排序、折叠、挂起和穿衣。我们还在实际世界中进行了实验，以证明 ClothesNet 的效果。补充材料和数据集可以在我们项目网站上获得。
</details></li>
</ul>
<hr>
<h2 id="Distributionally-Robust-Cross-Subject-EEG-Decoding"><a href="#Distributionally-Robust-Cross-Subject-EEG-Decoding" class="headerlink" title="Distributionally Robust Cross Subject EEG Decoding"></a>Distributionally Robust Cross Subject EEG Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11651">http://arxiv.org/abs/2308.11651</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tiehang Duan, Zhenyi Wang, Gianfranco Doretto, Fang Li, Cui Tao, Donald Adjeroh</li>
<li>for: 提高EEG解码任务的性能，增强EEG数据的鲁棒性</li>
<li>methods: 使用分布式鲁棒优化和 Wasserstein 梯度流来实现数据演化，提高EEG解码器的特征学习</li>
<li>results: 比较基eline的性能，模型在各种损害EEG信号中的表现更佳， indicating that the proposed approach can improve the robustness of EEG decoding tasks.<details>
<summary>Abstract</summary>
Recently, deep learning has shown to be effective for Electroencephalography (EEG) decoding tasks. Yet, its performance can be negatively influenced by two key factors: 1) the high variance and different types of corruption that are inherent in the signal, 2) the EEG datasets are usually relatively small given the acquisition cost, annotation cost and amount of effort needed. Data augmentation approaches for alleviation of this problem have been empirically studied, with augmentation operations on spatial domain, time domain or frequency domain handcrafted based on expertise of domain knowledge. In this work, we propose a principled approach to perform dynamic evolution on the data for improvement of decoding robustness. The approach is based on distributionally robust optimization and achieves robustness by optimizing on a family of evolved data distributions instead of the single training data distribution. We derived a general data evolution framework based on Wasserstein gradient flow (WGF) and provides two different forms of evolution within the framework. Intuitively, the evolution process helps the EEG decoder to learn more robust and diverse features. It is worth mentioning that the proposed approach can be readily integrated with other data augmentation approaches for further improvements. We performed extensive experiments on the proposed approach and tested its performance on different types of corrupted EEG signals. The model significantly outperforms competitive baselines on challenging decoding scenarios.
</details>
<details>
<summary>摘要</summary>
最近，深度学习已经在电enzephalography（EEG）解码任务中显示出有效性。然而，其性能可能受到两种关键因素的负面影响：1）EEG信号中的高度变化和不同类型的损害，2）EEG数据集通常较小，需要较多的获取成本、标注成本和精力投入。为了解决这个问题，数据扩展方法已经被Empirically研究，其中包括在空间领域、时间领域或频率领域进行手动设计的扩展操作。在这项工作中，我们提出了一种原理性的方法，通过分布robust优化来提高解码Robustness。该方法基于Wasserstein梯度流（WGF），并提供了两种不同的演化形式。intuitively，演化过程可以帮助EEG解码器学习更加Robust和多样的特征。值得一提是，提议的方法可以和其他数据扩展方法结合使用，以实现更高的性能。我们对提议的方法进行了广泛的实验，并测试其性能于不同类型的损害EEG信号。模型显著超越了竞争对手的基eline。
</details></li>
</ul>
<hr>
<h2 id="Artificial-Intelligence-across-Europe-A-Study-on-Awareness-Attitude-and-Trust"><a href="#Artificial-Intelligence-across-Europe-A-Study-on-Awareness-Attitude-and-Trust" class="headerlink" title="Artificial Intelligence across Europe: A Study on Awareness, Attitude and Trust"></a>Artificial Intelligence across Europe: A Study on Awareness, Attitude and Trust</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09979">http://arxiv.org/abs/2308.09979</a></li>
<li>repo_url: None</li>
<li>paper_authors: Teresa Scantamburlo, Atia Cortés, Francesca Foffano, Cristian Barrué, Veronica Distefano, Long Pham, Alessandro Fabris</li>
<li>For: The paper aims to gain a better understanding of European citizens’ views and perceptions of Artificial Intelligence (AI) in order to inform AI governance and policy-making.* Methods: The study uses a new questionnaire (PAICE) structured around three dimensions: awareness, attitude, and trust, and collects data from a sample of 4,006 European citizens from eight countries.* Results: The study finds that while awareness of AI is low, attitudes towards AI are generally positive, but there are implicit contradictions and trends that may interfere with the development of an inclusive AI ecosystem. The study highlights the importance of legal and ethical standards, educational entities, and AI literacy in supporting a trustworthy AI ecosystem.Here is the same information in Simplified Chinese text:* For: 这篇论文是为了了解欧洲公民对人工智能（AI）的看法和感受，以便更好地制定AI治理和政策。* Methods: 这篇论文使用一份新的问卷（PAICE），旨在三个维度上评估欧洲公民对AI的意见和态度：认知、态度和信任。* Results: 研究发现，尽管认知水平低，但大多数公民对AI的态度非常正面，但也存在一些潜在的矛盾和趋势，这些可能会影响建立包容性的AI生态系统。研究表明，legal和道德标准的引入，高等教育机构的活动，以及AI文化的推广是支持可信worthy AI生态系统的关键因素。<details>
<summary>Abstract</summary>
This paper presents the results of an extensive study investigating the opinions on Artificial Intelligence (AI) of a sample of 4,006 European citizens from eight distinct countries (France, Germany, Italy, Netherlands, Poland, Romania, Spain, and Sweden). The aim of the study is to gain a better understanding of people's views and perceptions within the European context, which is already marked by important policy actions and regulatory processes. To survey the perceptions of the citizens of Europe we design and validate a new questionnaire (PAICE) structured around three dimensions: people's awareness, attitude, and trust. We observe that while awareness is characterized by a low level of self-assessed competency, the attitude toward AI is very positive for more than half of the population. Reflecting upon the collected results, we highlight implicit contradictions and identify trends that may interfere with the creation of an ecosystem of trust and the development of inclusive AI policies. The introduction of rules that ensure legal and ethical standards, along with the activity of high-level educational entities, and the promotion of AI literacy are identified as key factors in supporting a trustworthy AI ecosystem. We make some recommendations for AI governance focused on the European context and conclude with suggestions for future work.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Explicit-Time-Embedding-Based-Cascade-Attention-Network-for-Information-Popularity-Prediction"><a href="#Explicit-Time-Embedding-Based-Cascade-Attention-Network-for-Information-Popularity-Prediction" class="headerlink" title="Explicit Time Embedding Based Cascade Attention Network for Information Popularity Prediction"></a>Explicit Time Embedding Based Cascade Attention Network for Information Popularity Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09976">http://arxiv.org/abs/2308.09976</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xigang Sun, Jingya Zhou, Ling Liu, Wenqi Wei</li>
<li>for: 预测信息潮流的各种特点，包括它的各种特点，以及它在不同的社交网络上的传播方式。</li>
<li>methods: 本文提出了一种基于Explicit Time Embedding的Cascade Attention Network（TCAN），该模型可以integrate temporal attributes（例如周期性、线性和非线性扩展）into node features，并使用cascade graph attention encoder（CGAT）和cascade sequence attention encoder（CSAT）来完全学习潮流图和潮流序列的表示。</li>
<li>results: 在使用两个实际的数据集（Weibo和APS）进行验证的情况下，TCAN得到了mean logarithm squared errors的值为2.007和1.201，并且在两个数据集上的运行时间分别为1.76小时和0.15小时。此外，TCAN也超过了其他表达基线的10.4%、3.8%和10.4%的MSLE、MAE和R-squared指标。<details>
<summary>Abstract</summary>
Predicting information cascade popularity is a fundamental problem in social networks. Capturing temporal attributes and cascade role information (e.g., cascade graphs and cascade sequences) is necessary for understanding the information cascade. Current methods rarely focus on unifying this information for popularity predictions, which prevents them from effectively modeling the full properties of cascades to achieve satisfactory prediction performances. In this paper, we propose an explicit Time embedding based Cascade Attention Network (TCAN) as a novel popularity prediction architecture for large-scale information networks. TCAN integrates temporal attributes (i.e., periodicity, linearity, and non-linear scaling) into node features via a general time embedding approach (TE), and then employs a cascade graph attention encoder (CGAT) and a cascade sequence attention encoder (CSAT) to fully learn the representation of cascade graphs and cascade sequences. We use two real-world datasets (i.e., Weibo and APS) with tens of thousands of cascade samples to validate our methods. Experimental results show that TCAN obtains mean logarithm squared errors of 2.007 and 1.201 and running times of 1.76 hours and 0.15 hours on both datasets, respectively. Furthermore, TCAN outperforms other representative baselines by 10.4%, 3.8%, and 10.4% in terms of MSLE, MAE, and R-squared on average while maintaining good interpretability.
</details>
<details>
<summary>摘要</summary>
预测信息潮流的受欢迎程度是社交网络中的基本问题。捕捉时间特征和垂直角色信息（如潮流图和潮流序列）是理解信息潮流的关键。现有方法rarely将这些信息统一到受欢迎预测中，这使得它们无法全面地模拟潮流的性质，从而导致不满足的预测性能。在本文中，我们提出了一种新的时间嵌入基于潮流注意力网络（TCAN），用于大规模信息网络中的受欢迎预测。TCAN通过一种通用的时间嵌入方法（TE）将时间特征纳入节点特征，然后使用潮流图注意力编码器（CGAT）和潮流序列注意力编码器（CSAT）来全面学习潮流图和潮流序列的表示。我们在两个实际 datasets（Weibo和APS）上进行了大量的潮流样本验证。实验结果表明，TCAN在两个dataset上的平均logarithmic squared error为2.007和1.201，运行时间分别为1.76小时和0.15小时。此外，TCAN在基于MSLE、MAE和R-squared的比较中，与其他代表性基准相比，提高了10.4%、3.8%和10.4%的性能。同时，TCAN保持了良好的可读性。
</details></li>
</ul>
<hr>
<h2 id="Disposable-Transfer-Learning-for-Selective-Source-Task-Unlearning"><a href="#Disposable-Transfer-Learning-for-Selective-Source-Task-Unlearning" class="headerlink" title="Disposable Transfer Learning for Selective Source Task Unlearning"></a>Disposable Transfer Learning for Selective Source Task Unlearning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09971">http://arxiv.org/abs/2308.09971</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seunghee Koh, Hyounguk Shon, Janghyeon Lee, Hyeong Gwon Hong, Junmo Kim</li>
<li>for: 这个论文的目的是提出一种新的传输学习方法，即可抛弃源任务的传输学习方法（DTL），以避免知识泄露问题。</li>
<li>methods: 该论文提出了一种新的损失函数名为梯度碰撞损失（GC损失），GC损失会导致梯度向量在不同批处理中分别移动，从而选择性地忘记源任务。</li>
<li>results: 论文表明，使用GC损失可以有效地解决传输学习中的知识泄露问题，并且模型在target任务上保持了高度的性能。<details>
<summary>Abstract</summary>
Transfer learning is widely used for training deep neural networks (DNN) for building a powerful representation. Even after the pre-trained model is adapted for the target task, the representation performance of the feature extractor is retained to some extent. As the performance of the pre-trained model can be considered the private property of the owner, it is natural to seek the exclusive right of the generalized performance of the pre-trained weight. To address this issue, we suggest a new paradigm of transfer learning called disposable transfer learning (DTL), which disposes of only the source task without degrading the performance of the target task. To achieve knowledge disposal, we propose a novel loss named Gradient Collision loss (GC loss). GC loss selectively unlearns the source knowledge by leading the gradient vectors of mini-batches in different directions. Whether the model successfully unlearns the source task is measured by piggyback learning accuracy (PL accuracy). PL accuracy estimates the vulnerability of knowledge leakage by retraining the scrubbed model on a subset of source data or new downstream data. We demonstrate that GC loss is an effective approach to the DTL problem by showing that the model trained with GC loss retains the performance on the target task with a significantly reduced PL accuracy.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate text into Simplified ChineseTransfer learning 广泛用于训练深度神经网络 (DNN) 以建立强大的表示。即使预训练模型被适应目标任务，表示性性能的特征提取器也会保持一定程度的表现。由于预训练模型的性能可以被视为专有财产，因此是自然的寻求专利权的通用性表现。为解决这个问题，我们提出了一种新的转移学习方法 called disposable transfer learning (DTL)，它将仅 dispose of the source task 而不是降低目标任务的性能。为实现知识抛弃，我们提议一种新的损失函数名为梯度碰撞损失 (GC loss)。GC loss 将导致批处理的梯度 вектор在不同的方向上穿梭。如果模型成功忘记了源任务，那么PL准确率 (PL accuracy) 将提供一种估计知识泄露的敏感性，由于在重新训练擦除模型时在一部分源数据上或新下游数据上进行重新训练。我们示出GC损失是DTL问题的有效方法，因为模型在使用GC损失时保留了目标任务的性能，同时PL准确率得到了显著降低。
</details></li>
</ul>
<hr>
<h2 id="Tackling-Vision-Language-Tasks-Through-Learning-Inner-Monologues"><a href="#Tackling-Vision-Language-Tasks-Through-Learning-Inner-Monologues" class="headerlink" title="Tackling Vision Language Tasks Through Learning Inner Monologues"></a>Tackling Vision Language Tasks Through Learning Inner Monologues</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09970">http://arxiv.org/abs/2308.09970</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diji Yang, Kezhen Chen, Jinmeng Rao, Xiaoyuan Guo, Yawen Zhang, Jie Yang, Yi Zhang</li>
<li>for: 解决复杂的视觉语言问题，如图像描述和图像理解等。</li>
<li>methods: 提出了一种新的方法 Inner Monologue Multi-Modal Optimization (IMMO)，通过模拟内部对话来促进语言模型和视觉模型之间的合并。</li>
<li>results: 实验结果表明，通过IMMO可以提高理解和解释能力，并且可以应用于多种不同的AI问题。<details>
<summary>Abstract</summary>
Visual language tasks require AI models to comprehend and reason with both visual and textual content. Driven by the power of Large Language Models (LLMs), two prominent methods have emerged: (1) the hybrid integration between LLMs and Vision-Language Models (VLMs), where visual inputs are firstly converted into language descriptions by VLMs, serving as inputs for LLMs to generate final answer(s); (2) visual feature alignment in language space, where visual inputs are encoded as embeddings and projected to LLMs' language space via further supervised fine-tuning. The first approach provides light training costs and interpretability but is hard to be optimized in an end-to-end fashion. The second approach presents decent performance, but feature alignment usually requires large amounts of training data and lacks interpretability. To tackle this dilemma, we propose a novel approach, Inner Monologue Multi-Modal Optimization (IMMO), to solve complex vision language problems by simulating inner monologue processes, a cognitive process in which an individual engages in silent verbal communication with themselves. We enable LLMs and VLMs to interact through natural language conversation and propose to use a two-stage training process to learn how to do the inner monologue (self-asking questions and answering questions). IMMO is evaluated on two popular tasks and the results suggest by emulating the cognitive phenomenon of internal dialogue, our approach can enhance reasoning and explanation abilities, contributing to the more effective fusion of vision and language models. More importantly, instead of using predefined human-crafted monologues, IMMO learns this process within the deep learning models, promising wider applicability to many different AI problems beyond vision language tasks.
</details>
<details>
<summary>摘要</summary>
视觉语言任务需要人工智能模型理解和处理视觉和文本内容。驱动了大型语言模型（LLM）的力量，两种主要方法出现：（1）混合Integration between LLMs and Vision-Language Models（VLMs），其中视觉输入首先被VLMs转换为语言描述，并作为LLMs的输入生成答案；（2）视觉特征对齐在语言空间，其中视觉输入被编码为特征嵌入，并通过进一步的超vision fine-tuning来将其投影到LLMs的语言空间。首个方法提供了轻量级训练成本和可读性，但具有硬coded困难，难以在端到端方式优化。其次的方法具有良好性能，但特征对齐通常需要大量的训练数据和缺乏可读性。为解决这个困难，我们提出了一种新的方法：Inner Monologue Multi-Modal Optimization（IMMO），用于解决复杂的视觉语言问题。我们使得LLMs和VLMs通过自然语言对话进行交互，并提出了一种两个阶段训练过程，以学习如何进行内部对话（自我问答和回答问题）。IMMO在两个流行任务上进行评估，结果表明，通过模拟内部对话，我们的方法可以提高理解和解释能力，为视觉语言模型的更有效融合做出贡献。更重要的是，不同于使用人类编写的固定内部对话，IMMO在深度学习模型中学习这个过程，可以应用于许多不同的人工智能问题。
</details></li>
</ul>
<hr>
<h2 id="Anomaly-Aware-Semantic-Segmentation-via-Style-Aligned-OoD-Augmentation"><a href="#Anomaly-Aware-Semantic-Segmentation-via-Style-Aligned-OoD-Augmentation" class="headerlink" title="Anomaly-Aware Semantic Segmentation via Style-Aligned OoD Augmentation"></a>Anomaly-Aware Semantic Segmentation via Style-Aligned OoD Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09965">http://arxiv.org/abs/2308.09965</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dan Zhang, Kaspar Sakmann, William Beluch, Robin Hutmacher, Yumeng Li</li>
<li>for: 这个论文的目的是为了将标准 semantic segmentation 模型设置为适应不熟悉的物品类型。</li>
<li>methods: 这个研究使用了实验性的 out-of-distribution (OoD) 数据增强方法，以实现对惊喜物品的识别。</li>
<li>results: 这个研究发现，通过将 OoD 数据与驾驶场景之间的领域差缩小，可以有效减少类型差异的影响，并且提出了一个简单的 fine-tuning 损失，使得先前训练的 semantic segmentation 模型能够对不熟悉的物品进行预测。<details>
<summary>Abstract</summary>
Within the context of autonomous driving, encountering unknown objects becomes inevitable during deployment in the open world. Therefore, it is crucial to equip standard semantic segmentation models with anomaly awareness. Many previous approaches have utilized synthetic out-of-distribution (OoD) data augmentation to tackle this problem. In this work, we advance the OoD synthesis process by reducing the domain gap between the OoD data and driving scenes, effectively mitigating the style difference that might otherwise act as an obvious shortcut during training. Additionally, we propose a simple fine-tuning loss that effectively induces a pre-trained semantic segmentation model to generate a ``none of the given classes" prediction, leveraging per-pixel OoD scores for anomaly segmentation. With minimal fine-tuning effort, our pipeline enables the use of pre-trained models for anomaly segmentation while maintaining the performance on the original task.
</details>
<details>
<summary>摘要</summary>
在自动驾驶中，遇到未知对象是不可避免的，因此需要填充标准semantic segmentation模型 anomaly awareness。许多前一代方法使用 synthetic out-of-distribution（OoD）数据增强来解决这个问题。在这项工作中，我们提高了 OoD 数据生成过程中的领域差异，从而有效地减少了样式差异，从而避免了训练时的快速通路。此外，我们提议一种简单的精度调整方法，可以让预训练的semantic segmentation模型生成“无任何给定类”预测，通过每个像素的 OoD 分数进行异常分割。只需 minimal fine-tuning 努力，我们的管道可以使用预训练模型进行异常分割，同时保持原始任务的性能。
</details></li>
</ul>
<hr>
<h2 id="Data-to-text-Generation-for-Severely-Under-Resourced-Languages-with-GPT-3-5-A-Bit-of-Help-Needed-from-Google-Translate"><a href="#Data-to-text-Generation-for-Severely-Under-Resourced-Languages-with-GPT-3-5-A-Bit-of-Help-Needed-from-Google-Translate" class="headerlink" title="Data-to-text Generation for Severely Under-Resourced Languages with GPT-3.5: A Bit of Help Needed from Google Translate"></a>Data-to-text Generation for Severely Under-Resourced Languages with GPT-3.5: A Bit of Help Needed from Google Translate</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09957">http://arxiv.org/abs/2308.09957</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dcu-nlg/dcu-nlg-pbn">https://github.com/dcu-nlg/dcu-nlg-pbn</a></li>
<li>paper_authors: Michela Lorandi, Anya Belz</li>
<li>for: 这个论文旨在探讨使用英语少量训练数据的大语言模型（LLM）在缺乏训练数据的语言上进行数据转文本生成 task 中的性能。</li>
<li>methods: 作者在这篇论文中使用了一些示例输入&#x2F;输出对的测试和评估，以及不同的提示类型和格式，以确定最佳的提示方法。</li>
<li>results: 研究发现，在直接生成到缺乏训练数据的语言时，几个示例提示方法效果较好，但是在通过英语转化后生成时，提示方法的效果消失。作者还在WebNLG 2023 共享任务中提交了一些系统，并在所有语言和所有指标上超越了竞争者系统。但是，最佳结果仍然远低于最差排名的英语系统在 WebNLG’20 中。<details>
<summary>Abstract</summary>
LLMs like GPT are great at tasks involving English which dominates in their training data. In this paper, we look at how they cope with tasks involving languages that are severely under-represented in their training data, in the context of data-to-text generation for Irish, Maltese, Welsh and Breton. During the prompt-engineering phase we tested a range of prompt types and formats on GPT-3.5 and~4 with a small sample of example input/output pairs. We then fully evaluated the two most promising prompts in two scenarios: (i) direct generation into the under-resourced language, and (ii) generation into English followed by translation into the under-resourced language. We find that few-shot prompting works better for direct generation into under-resourced languages, but that the difference disappears when pivoting via English. The few-shot + translation system variants were submitted to the WebNLG 2023 shared task where they outperformed competitor systems by substantial margins in all languages on all metrics. We conclude that good performance on under-resourced languages can be achieved out-of-the box with state-of-the-art LLMs. However, our best results (for Welsh) remain well below the lowest ranked English system at WebNLG'20.
</details>
<details>
<summary>摘要</summary>
(Note: Simplified Chinese is used in this translation, as it is more widely used in mainland China and is the standard form of Chinese used in government documents, education, and media. Traditional Chinese is also commonly used in Taiwan, Hong Kong, and Macau, and is the standard form of Chinese used in these regions. However, for the purpose of this translation, Simplified Chinese is used to ensure consistency and readability.)
</details></li>
</ul>
<hr>
<h2 id="Eva-KELLM-A-New-Benchmark-for-Evaluating-Knowledge-Editing-of-LLMs"><a href="#Eva-KELLM-A-New-Benchmark-for-Evaluating-Knowledge-Editing-of-LLMs" class="headerlink" title="Eva-KELLM: A New Benchmark for Evaluating Knowledge Editing of LLMs"></a>Eva-KELLM: A New Benchmark for Evaluating Knowledge Editing of LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09954">http://arxiv.org/abs/2308.09954</a></li>
<li>repo_url: None</li>
<li>paper_authors: Suhang Wu, Minlong Peng, Yue Chen, Jinsong Su, Mingming Sun</li>
<li>for: 本研究旨在评估语言模型（LLM）知识编辑的效iveness。</li>
<li>methods: 本研究使用 raw documents 进行知识编辑，并 evaluate  LLVM 的更新后性能从多个角度。</li>
<li>results: 实验结果表明，目前使用 raw documents 进行知识编辑的方法不够有效，特别是在理解修改后的知识和跨语言知识传递方面。<details>
<summary>Abstract</summary>
Large language models (LLMs) possess a wealth of knowledge encoded in their parameters. However, this knowledge may become outdated or unsuitable over time. As a result, there has been a growing interest in knowledge editing for LLMs and evaluating its effectiveness. Existing studies primarily focus on knowledge editing using factual triplets, which not only incur high costs for collection but also struggle to express complex facts. Furthermore, these studies are often limited in their evaluation perspectives. In this paper, we propose Eva-KELLM, a new benchmark for evaluating knowledge editing of LLMs. This benchmark includes an evaluation framework and a corresponding dataset. Under our framework, we first ask the LLM to perform knowledge editing using raw documents, which provides a more convenient and universal approach compared to using factual triplets. We then evaluate the updated LLM from multiple perspectives. In addition to assessing the effectiveness of knowledge editing and the retention of unrelated knowledge from conventional studies, we further test the LLM's ability in two aspects: 1) Reasoning with the altered knowledge, aiming for the LLM to genuinely learn the altered knowledge instead of simply memorizing it. 2) Cross-lingual knowledge transfer, where the LLM updated with raw documents in one language should be capable of handling queries from another language. To facilitate further research, we construct and release the corresponding dataset. Using this benchmark, we investigate the effectiveness of several commonly-used knowledge editing methods. Experimental results indicate that the current methods for knowledge editing using raw documents are not effective in yielding satisfactory results, particularly when it comes to reasoning with altered knowledge and cross-lingual knowledge transfer.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）具有丰富的知识储存在其参数中。然而，这些知识可能会随时间变得过时或不适用。因此，有着增长的兴趣在Language Model（LM）的知识编译和评估其有效性。现有的研究主要针对LM的知识编译使用事实三重ts，它们不具有高成本的收集成本，但它们仅能表达简单的事实。此外，这些研究通常仅从一个见解进行评估。在这篇文章中，我们提出了Eva-KELLM，一个新的LLM知识编译评估标准。这个标准包括评估框架和对应的数据集。在我们的框架下，我们首先请LM进行知识编译使用原始文档，这提供了一个更方便和通用的方法，相比于使用事实三重ts。然后，我们从多个角度评估更新后的LM。除了评估知识编译的有效性和对不相关知识的保留外，我们还进行了两种方面的测试： 1. 使用更新后的知识进行推理，目的是让LM真正学习更新后的知识，而不是单纯记忆。2. 跨语言知识传递，即更新了LM的原始文档可以处理其他语言的查询。为了促进进一步的研究，我们建立了相应的数据集，并发布了这个标准。使用这个标准，我们进行了各种常用的知识编译方法的评估。实验结果表明，目前使用原始文档进行知识编译的方法并不具有满意的效果，特别是在推理使用更新后的知识和跨语言知识传递方面。
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Power-of-Topic-Modeling-Techniques-in-Analyzing-Customer-Reviews-A-Comparative-Analysis"><a href="#Exploring-the-Power-of-Topic-Modeling-Techniques-in-Analyzing-Customer-Reviews-A-Comparative-Analysis" class="headerlink" title="Exploring the Power of Topic Modeling Techniques in Analyzing Customer Reviews: A Comparative Analysis"></a>Exploring the Power of Topic Modeling Techniques in Analyzing Customer Reviews: A Comparative Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11520">http://arxiv.org/abs/2308.11520</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anusuya Krishnan</li>
<li>for: 本研究旨在比较五种常用的话题模型方法，以便在实际应用中提高话题检索的效果。</li>
<li>methods: 本研究使用的方法包括LSA、LDA、NMF、PAM、Top2Vec和BERTopic等五种话题模型方法。</li>
<li>results: 研究发现，BERTopic方法可以准确地提取有意义的话题，并且在两个文本数据集上获得了良好的效果。<details>
<summary>Abstract</summary>
The exponential growth of online social network platforms and applications has led to a staggering volume of user-generated textual content, including comments and reviews. Consequently, users often face difficulties in extracting valuable insights or relevant information from such content. To address this challenge, machine learning and natural language processing algorithms have been deployed to analyze the vast amount of textual data available online. In recent years, topic modeling techniques have gained significant popularity in this domain. In this study, we comprehensively examine and compare five frequently used topic modeling methods specifically applied to customer reviews. The methods under investigation are latent semantic analysis (LSA), latent Dirichlet allocation (LDA), non-negative matrix factorization (NMF), pachinko allocation model (PAM), Top2Vec, and BERTopic. By practically demonstrating their benefits in detecting important topics, we aim to highlight their efficacy in real-world scenarios. To evaluate the performance of these topic modeling methods, we carefully select two textual datasets. The evaluation is based on standard statistical evaluation metrics such as topic coherence score. Our findings reveal that BERTopic consistently yield more meaningful extracted topics and achieve favorable results.
</details>
<details>
<summary>摘要</summary>
“在线社交媒体平台和应用程序的快速增长中，用户生成的文本内容的量已经成为严重的问题。为了解决这个问题，机器学习和自然语言处理算法已经在线上进行了广泛的应用。在过去几年中，主题探索技术在这个领域中得到了很大的应用。本研究将 investigate Five frequently used主题探索方法，它们是：对应语义分析（LSA）、Dirichlet分配（LDA）、非负矩阵分解（NMF）、碎掉投入模型（PAM）、Top2Vec和BERTopic。我们通过实际示范这些方法在实际应用中的效果，来强调它们在实际应用中的可行性。为了评估这些主题探索方法的表现，我们选择了两个文本数据集。评估是基于标准的统计评估指标，如主题凝聚分数。我们的发现表明，BERTopic在提取有意义的主题方面表现出色，取得了良好的成绩。”
</details></li>
</ul>
<hr>
<h2 id="Understanding-Self-attention-Mechanism-via-Dynamical-System-Perspective"><a href="#Understanding-Self-attention-Mechanism-via-Dynamical-System-Perspective" class="headerlink" title="Understanding Self-attention Mechanism via Dynamical System Perspective"></a>Understanding Self-attention Mechanism via Dynamical System Perspective</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09939">http://arxiv.org/abs/2308.09939</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Zhongzhan Huang, Mingfu Liang, Jinghui Qin, Shanshan Zhong, Liang Lin</li>
<li>for: 本研究 aimed to provide a new understanding of the self-attention mechanism (SAM) in neural networks, and to develop a new approach called StepNet that can measure the intrinsic stiffness phenomenon (SP) in high-performance neural networks.</li>
<li>methods: 本研究使用了动力系统视角来研究高性能神经网络中的SP现象，并提出了一种基于适应步长参数的StepNet方法来测量SP。</li>
<li>results: 实验结果表明，StepNet可以准确测量SP，提高了多种视觉任务的性能。<details>
<summary>Abstract</summary>
The self-attention mechanism (SAM) is widely used in various fields of artificial intelligence and has successfully boosted the performance of different models. However, current explanations of this mechanism are mainly based on intuitions and experiences, while there still lacks direct modeling for how the SAM helps performance. To mitigate this issue, in this paper, based on the dynamical system perspective of the residual neural network, we first show that the intrinsic stiffness phenomenon (SP) in the high-precision solution of ordinary differential equations (ODEs) also widely exists in high-performance neural networks (NN). Thus the ability of NN to measure SP at the feature level is necessary to obtain high performance and is an important factor in the difficulty of training NN. Similar to the adaptive step-size method which is effective in solving stiff ODEs, we show that the SAM is also a stiffness-aware step size adaptor that can enhance the model's representational ability to measure intrinsic SP by refining the estimation of stiffness information and generating adaptive attention values, which provides a new understanding about why and how the SAM can benefit the model performance. This novel perspective can also explain the lottery ticket hypothesis in SAM, design new quantitative metrics of representational ability, and inspire a new theoretic-inspired approach, StepNet. Extensive experiments on several popular benchmarks demonstrate that StepNet can extract fine-grained stiffness information and measure SP accurately, leading to significant improvements in various visual tasks.
</details>
<details>
<summary>摘要</summary>
自我注意机制（SAM）在人工智能多个领域广泛应用，并成功提高不同模型的性能。然而，目前对这种机制的解释主要基于直觉和经验，而尚未有直接模型如何SAM帮助性能。为了解决这问题，在这篇论文中，基于径远系统视角，我们首先显示了高精度解方程（ODEs）中广泛存在的内在硬度现象（SP）。因此，NN的能力测量SP到特征层是必要的，并是训练NN的重要因素。与适应步长法，我们显示了SAM也是一种硬度感知的步长调整器，可以增强模型测量SP的能力，并生成适应性注意值。这种新的视角可以解释SAM如何提高模型性能，并设计新的量化度量方法。我们还提出了一种基于这种理论的StepNet方法，可以提取细腻的硬度信息并准确测量SP，从而在多种视觉任务中取得显著改进。
</details></li>
</ul>
<hr>
<h2 id="Analyzing-Quantization-in-TVM"><a href="#Analyzing-Quantization-in-TVM" class="headerlink" title="Analyzing Quantization in TVM"></a>Analyzing Quantization in TVM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10905">http://arxiv.org/abs/2308.10905</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingfei Guo</li>
<li>for: 这个论文目的是研究 TVM 中的 8 位量化问题，以提高深度学习模型的执行速度和内存占用。</li>
<li>methods: 这篇论文使用了 TVM 的 8 位量化功能，并进行了多种优化技术的比较和分析，以提高量化后的性能。</li>
<li>results: 论文表明，在使用 8 位量化后，TVM 的执行时间比原始版本 slower，而且在计算任务和存储任务两个方面都有较大的性能下降。然而，通过修复图像建立错误，以及应用多种优化策略，最终实现了对 TVM 进行量化后的性能提升。<details>
<summary>Abstract</summary>
There has been many papers in academic literature on quantizing weight tensors in deep learning models to reduce inference latency and memory footprint. TVM also has the ability to quantize weights and support low-bit computations. Although quantization is typically expected to improve inference time, in TVM, the performance of 8-bit quantization does not meet the expectations. Typically, when applying 8-bit quantization to a deep learning model, it is usually expected to achieve around 50% of the full-precision inference time. However, in this particular case, not only does the quantized version fail to achieve the desired performance boost, but it actually performs worse, resulting in an inference time that is about 2 times as slow as the non-quantized version. In this project, we thoroughly investigate the reasons behind the underperformance and assess the compatibility and optimization opportunities of 8-bit quantization in TVM. We discuss the optimization of two different types of tasks: computation-bound and memory-bound, and provide a detailed comparison of various optimization techniques in TVM. Through the identification of performance issues, we have successfully improved quantization by addressing a bug in graph building. Furthermore, we analyze multiple optimization strategies to achieve the optimal quantization result. The best experiment achieves 163.88% improvement compared with the TVM compiled baseline in inference time for the compute-bound task and 194.98% for the memory-bound task.
</details>
<details>
<summary>摘要</summary>
在学术文献中有很多关于深度学习模型量化Weight张量以降低推理时间和内存占用的论文。TVM也具有量化Weight和低位计算的能力。 although 量化通常预期可以提高推理时间，在TVM中，8位量化的表现不符预期，其实perform worse，导致推理时间约为非量化版本的两倍。在这个项目中，我们进行了深入的调查和分析，检查8位量化在TVM中的兼容性和优化机会。我们分析了两种不同的任务类型：计算繁重和内存繁重，并提供了多种优化技术的详细比较。通过问题定位，我们成功地修复了图形建立过程中的bug，并分析了多种优化策略以实现最佳量化结果。最佳实验在计算繁重任务上提高了163.88%的推理时间，而在内存繁重任务上提高了194.98%。
</details></li>
</ul>
<hr>
<h2 id="East-Efficient-and-Accurate-Secure-Transformer-Framework-for-Inference"><a href="#East-Efficient-and-Accurate-Secure-Transformer-Framework-for-Inference" class="headerlink" title="East: Efficient and Accurate Secure Transformer Framework for Inference"></a>East: Efficient and Accurate Secure Transformer Framework for Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09923">http://arxiv.org/abs/2308.09923</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanchao Ding, Hua Guo, Yewei Guan, Weixin Liu, Jiarong Huo, Zhenyu Guan, Xiyong Zhang</li>
<li>for: 这个研究旨在提供一个可靠和精确的隐私保护Transformer推断框架。</li>
<li>methods: 我们提出了一个名为“East”的框架，包括一个新的隐私 polynomial评估算法，以及适当设计的安全协议 для softmax 和层normalization。</li>
<li>results: 我们实现了一个名为“East”的框架，可以实现高效和精确的隐私保护Transformer推断，并且与没有微调的确切性相同。 相比于Iron，我们的方案可以降低通信量约1.8倍，而且降低runtime约1.2倍。<details>
<summary>Abstract</summary>
Transformer has been successfully used in practical applications, such as ChatGPT, due to its powerful advantages. However, users' input is leaked to the model provider during the service. With people's attention to privacy, privacy-preserving Transformer inference is on the demand of such services. Secure protocols for non-linear functions are crucial in privacy-preserving Transformer inference, which are not well studied. Thus, designing practical secure protocols for non-linear functions is hard but significant to model performance. In this work, we propose a framework \emph{East} to enable efficient and accurate secure Transformer inference. Firstly, we propose a new oblivious piecewise polynomial evaluation algorithm and apply it to the activation functions, which reduces the runtime and communication of GELU by over 1.5$\times$ and 2.5$\times$, compared to prior arts. Secondly, the secure protocols for softmax and layer normalization are carefully designed to faithfully maintain the desired functionality. Thirdly, several optimizations are conducted in detail to enhance the overall efficiency. We applied \emph{East} to BERT and the results show that the inference accuracy remains consistent with the plaintext inference without fine-tuning. Compared to Iron, we achieve about 1.8$\times$ lower communication within 1.2$\times$ lower runtime.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用Transformer在实际应用中得到了成功，如ChatGPT，因为它具有强大的优势。然而，用户的输入被传递给模型提供商 durante el servicio，这会让人们关注隐私。隐私保护Transformer推理是对这些服务的需求。为了保持模型性能，安全协议 для非线性函数是必要的。然而，这些协议并未得到充分的研究。因此，设计实用安全协议 для非线性函数是具有挑战性和重要性的。在这种情况下，我们提出了一个框架called \emph{East}，以启用高效和准确的隐私保护Transformer推理。首先，我们提出了一种新的透明分割多项式评估算法，并应用它到活动函数上，从而降低GELU的运行时和通信时间，相比于先前的艺术。其次，我们仔细设计了安全协议 для软max和层normalization，以保持所需的功能。最后，我们在细节上进行了多个优化，以提高整体的效率。我们应用了\emph{East}于BERT，结果显示，无需练习，推理精度与纯文本推理相同。相比于Iron，我们实现了约1.8倍的通信减少和1.2倍的运行时减少。
</details></li>
</ul>
<hr>
<h2 id="Recap-Detecting-Deepfake-Video-with-Unpredictable-Tampered-Traces-via-Recovering-Faces-and-Mapping-Recovered-Faces"><a href="#Recap-Detecting-Deepfake-Video-with-Unpredictable-Tampered-Traces-via-Recovering-Faces-and-Mapping-Recovered-Faces" class="headerlink" title="Recap: Detecting Deepfake Video with Unpredictable Tampered Traces via Recovering Faces and Mapping Recovered Faces"></a>Recap: Detecting Deepfake Video with Unpredictable Tampered Traces via Recovering Faces and Mapping Recovered Faces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09921">http://arxiv.org/abs/2308.09921</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juan Hu, Xin Liao, Difei Gao, Satoshi Tsutsui, Qian Wang, Zheng Qin, Mike Zheng Shou</li>
<li>for: 针对恶意使用深伪技术的检测问题进行研究。</li>
<li>methods: 提出了一种新的深伪检测模型，即Recap，它可以暴露不具体的面部不一致性。</li>
<li>results: 在多种场景下进行了广泛的实验，并表明Recap可以有效地检测深伪视频。<details>
<summary>Abstract</summary>
The exploitation of Deepfake techniques for malicious intentions has driven significant research interest in Deepfake detection. Deepfake manipulations frequently introduce random tampered traces, leading to unpredictable outcomes in different facial regions. However, existing detection methods heavily rely on specific forgery indicators, and as the forgery mode improves, these traces become increasingly randomized, resulting in a decline in the detection performance of methods reliant on specific forgery traces. To address the limitation, we propose Recap, a novel Deepfake detection model that exposes unspecific facial part inconsistencies by recovering faces and enlarges the differences between real and fake by mapping recovered faces. In the recovering stage, the model focuses on randomly masking regions of interest (ROIs) and reconstructing real faces without unpredictable tampered traces, resulting in a relatively good recovery effect for real faces while a poor recovery effect for fake faces. In the mapping stage, the output of the recovery phase serves as supervision to guide the facial mapping process. This mapping process strategically emphasizes the mapping of fake faces with poor recovery, leading to a further deterioration in their representation, while enhancing and refining the mapping of real faces with good representation. As a result, this approach significantly amplifies the discrepancies between real and fake videos. Our extensive experiments on standard benchmarks demonstrate that Recap is effective in multiple scenarios.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>> Deepfake 技术的滥用为恶意目的而引起了广泛的研究兴趣，但是现有的检测方法受到特定的妄想指标的限制，而且随着妄想模式的改进，这些指标变得越来越随机，导致这些方法在检测性能下降。为解决这个限制，我们提出了 Recap，一种新的 Deepfake 检测模型，它暴露了不具体的 facial part 不一致性。在恢复阶段，模型会随机屏蔽 Region of Interest (ROI) 并恢复真实的 face，从而实现了较好的真实 face 恢复效果，而假 face 的恢复效果相对较差。在映射阶段，输出恢复阶段的结果作为指导，导致 facial 映射过程中的映射结果更加精细。这种方法可以明显增加真实和假的视频之间的差异。我们对标准 benchmark 进行了广泛的实验，结果显示，Recap 在多种场景下都有效。
</details></li>
</ul>
<hr>
<h2 id="Learning-Multiscale-Consistency-for-Self-supervised-Electron-Microscopy-Instance-Segmentation"><a href="#Learning-Multiscale-Consistency-for-Self-supervised-Electron-Microscopy-Instance-Segmentation" class="headerlink" title="Learning Multiscale Consistency for Self-supervised Electron Microscopy Instance Segmentation"></a>Learning Multiscale Consistency for Self-supervised Electron Microscopy Instance Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09917">http://arxiv.org/abs/2308.09917</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yinda Chen, Wei Huang, Xiaoyu Liu, Qi Chen, Zhiwei Xiong</li>
<li>for: 该论文旨在提高电子顺带显微镜像中的实例分割精度。</li>
<li>methods: 该方法利用自我超级vised学习，通过多尺度视觉表示来捕捉电子镜像中实例的复杂视觉模式和声明关系。</li>
<li>results: 在四个大规模电子镜像 dataset 上广泛预训练该方法，实现了代表性任务中的神经元和 mitochondria 实例分割性能的提高。<details>
<summary>Abstract</summary>
Instance segmentation in electron microscopy (EM) volumes poses a significant challenge due to the complex morphology of instances and insufficient annotations. Self-supervised learning has recently emerged as a promising solution, enabling the acquisition of prior knowledge of cellular tissue structures that are essential for EM instance segmentation. However, existing pretraining methods often lack the ability to capture complex visual patterns and relationships between voxels, which results in the acquired prior knowledge being insufficient for downstream EM analysis tasks. In this paper, we propose a novel pretraining framework that leverages multiscale visual representations to capture both voxel-level and feature-level consistency in EM volumes. Specifically, our framework enforces voxel-level consistency between the outputs of a Siamese network by a reconstruction function, and incorporates a cross-attention mechanism for soft feature matching to achieve fine-grained feature-level consistency. Moreover, we propose a contrastive learning scheme on the feature pyramid to extract discriminative features across multiple scales. We extensively pretrain our method on four large-scale EM datasets, achieving promising performance improvements in representative tasks of neuron and mitochondria instance segmentation.
</details>
<details>
<summary>摘要</summary>
Electron microscopy (EM)  volumes 的实例分割具有 significiant 挑战，主要是因为实例的复杂形态和不充分的标注。自动学习 recent emerge  as a promising solution，可以获得 cellular tissue 结构的先验知识，这些先验知识是下游 EM 实例分割任务的关键。然而，现有的预训练方法经常无法捕捉 EM  volumes 中复杂的视觉模式和 voxel 之间的关系，导致预训练的先验知识不够 для下游 EM 分析任务。在这篇论文中，我们提出了一种新的预训练框架，利用多尺度的视觉表示来捕捉 EM  volumes 中 voxel 级别和特征级别的一致性。具体来说，我们的框架使用 Siamese 网络的输出来执行重建函数，以实现 voxel 级别的一致性。此外，我们还提出了一种跨特征的匹配机制，以实现细腻的特征级别的一致性。此外，我们还提出了一种嵌入式学习的方案，用于提取多 scales 的特征。我们广泛预训练我们的方法在四个大规模 EM 数据集上，实现了代表性的 neuron 和 mitochondria 实例分割任务的表现。
</details></li>
</ul>
<hr>
<h2 id="Never-Explore-Repeatedly-in-Multi-Agent-Reinforcement-Learning"><a href="#Never-Explore-Repeatedly-in-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Never Explore Repeatedly in Multi-Agent Reinforcement Learning"></a>Never Explore Repeatedly in Multi-Agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09909">http://arxiv.org/abs/2308.09909</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenghao Li, Tonghan Wang, Chongjie Zhang, Qianchuan Zhao</li>
<li>for: 这篇论文目的是解决多智能代理人学习中的内在动机问题，尤其是游戏环境中的探索和获取奖励问题。</li>
<li>methods: 这篇论文提出了一种动态奖励推敲法，用于稳定内在奖励的波动和探索更广泛的区域，以解决 revisitation 问题。</li>
<li>results: 实验结果显示，这种方法能够在Google研究足球和StarCraft II微管理任务中提高表现，特别是在稀有奖励情况下。<details>
<summary>Abstract</summary>
In the realm of multi-agent reinforcement learning, intrinsic motivations have emerged as a pivotal tool for exploration. While the computation of many intrinsic rewards relies on estimating variational posteriors using neural network approximators, a notable challenge has surfaced due to the limited expressive capability of these neural statistics approximators. We pinpoint this challenge as the "revisitation" issue, where agents recurrently explore confined areas of the task space. To combat this, we propose a dynamic reward scaling approach. This method is crafted to stabilize the significant fluctuations in intrinsic rewards in previously explored areas and promote broader exploration, effectively curbing the revisitation phenomenon. Our experimental findings underscore the efficacy of our approach, showcasing enhanced performance in demanding environments like Google Research Football and StarCraft II micromanagement tasks, especially in sparse reward settings.
</details>
<details>
<summary>摘要</summary>
在多智能奖励学习领域，内生动机作为探索的重要工具而出现。然而，许多内生奖励计算依赖于使用神经网络近似器来估计变分 posterior，这种限制神经统计近似器的表达能力带来了一定挑战。我们称这种挑战为“返回”问题，agent在完成任务空间中循环探索受限的区域。为了解决这个问题，我们提议动态奖励缩放方法。这种方法通过稳定在已经探索过的区域中的内生奖励波动，激励更广泛的探索，从而控制返回现象。我们的实验发现，我们的方法在Google研究足球和StarCraft II微管理任务中表现出色，特别是在罕见奖励设置下。
</details></li>
</ul>
<hr>
<h2 id="LEGO-Learning-and-Graph-Optimized-Modular-Tracker-for-Online-Multi-Object-Tracking-with-Point-Clouds"><a href="#LEGO-Learning-and-Graph-Optimized-Modular-Tracker-for-Online-Multi-Object-Tracking-with-Point-Clouds" class="headerlink" title="LEGO: Learning and Graph-Optimized Modular Tracker for Online Multi-Object Tracking with Point Clouds"></a>LEGO: Learning and Graph-Optimized Modular Tracker for Online Multi-Object Tracking with Point Clouds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09908">http://arxiv.org/abs/2308.09908</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenrong Zhang, Jianan Liu, Yuxuan Xia, Tao Huang, Qing-Long Han, Hongbin Liu</li>
<li>for: 提高数据匹配性能，提高跟踪性能</li>
<li>methods: 利用图像优化和自注意力机制，生成准确的匹配得分图，提高数据匹配精度和效率</li>
<li>results: 在KITTI车辆跟踪评估板上，使用LiDARalone实现了出色的表现，并在所有在线跟踪器中排名第一，并在本文提交时保持第二名。<details>
<summary>Abstract</summary>
Online multi-object tracking (MOT) plays a pivotal role in autonomous systems. The state-of-the-art approaches usually employ a tracking-by-detection method, and data association plays a critical role. This paper proposes a learning and graph-optimized (LEGO) modular tracker to improve data association performance in the existing literature. The proposed LEGO tracker integrates graph optimization and self-attention mechanisms, which efficiently formulate the association score map, facilitating the accurate and efficient matching of objects across time frames. To further enhance the state update process, the Kalman filter is added to ensure consistent tracking by incorporating temporal coherence in the object states. Our proposed method utilizing LiDAR alone has shown exceptional performance compared to other online tracking approaches, including LiDAR-based and LiDAR-camera fusion-based methods. LEGO ranked 1st at the time of submitting results to KITTI object tracking evaluation ranking board and remains 2nd at the time of submitting this paper, among all online trackers in the KITTI MOT benchmark for cars1
</details>
<details>
<summary>摘要</summary>
在自主系统中，在线多对目标跟踪（MOT）扮演着重要的角色。现状的方法通常采用检测-跟踪方法，数据归一化扮演 kritikus 的角色。这篇论文提议一种学习和图形优化（LEGO）模块化跟踪器，以改善现有文献中的数据归一化性能。提议的LEGO跟踪器结合图形优化和自注意机制，高效地计算归一化得分图，使得在不同时帧中快速和准确匹配目标。此外，为了进一步增强状态更新过程，我们添加了卡尔曼滤波，以确保跟踪过程中的对象状态具有一致性。我们使用了LiDARalone，与其他在线跟踪方法相比，包括LiDAR和LiDAR-camera fusione-based方法，我们提posed的方法在KITTI目标跟踪评估板上表现出了非凡的性能。LEGO在提交结果时排名第一，并在这篇论文提交时仍然排名第二，对于所有在线跟踪器而言，在KITTI MOTbenchmark中的汽车1中。
</details></li>
</ul>
<hr>
<h2 id="RAH-RecSys-Assistant-Human-A-Human-Central-Recommendation-Framework-with-Large-Language-Models"><a href="#RAH-RecSys-Assistant-Human-A-Human-Central-Recommendation-Framework-with-Large-Language-Models" class="headerlink" title="RAH! RecSys-Assistant-Human: A Human-Central Recommendation Framework with Large Language Models"></a>RAH! RecSys-Assistant-Human: A Human-Central Recommendation Framework with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09904">http://arxiv.org/abs/2308.09904</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yubo Shu, Hansu Gu, Peng Zhang, Haonan Zhang, Tun Lu, Dongsheng Li, Ning Gu</li>
<li>for: 这个论文的目的是提出一种人类中心的推荐框架，以帮助推荐系统更好地理解和满足用户需求。</li>
<li>methods: 该论文使用了人工智能语言模型（LLM）作为用户代理人，并提出了一种名为RAH框架的人类中心推荐模型。RAH框架包括推荐系统、助手和人类三部分，以帮助推荐系统更好地理解和满足用户需求。</li>
<li>results: 实验结果表明，使用学习动作评价和反射机制可以更好地调整用户个性，而助手也可以有效地代表用户提供反馈和帮助推荐系统更好地调整。<details>
<summary>Abstract</summary>
The recommendation ecosystem involves interactions between recommender systems(Computer) and users(Human). Orthogonal to the perspective of recommender systems, we attempt to utilize LLMs from the perspective of users and propose a more human-central recommendation framework named RAH, which consists of Recommender system, Assistant and Human. The assistant is a LLM-based and personal proxy for a human to achieve user satisfaction. The assistant plays a non-invasion role and the RAH framework can adapt to different recommender systems and user groups. Subsequently, we implement and evaluate the RAH framework for learning user personalities and proxy human feedback. The experiment shows that (1) using learn-action-critic and reflection mechanisms can lead more aligned personality and (2) our assistant can effectively proxy human feedback and help adjust recommender systems. Finally, we discuss further strategies in the RAH framework to address human-central concerns including user control, privacy and fairness.
</details>
<details>
<summary>摘要</summary>
<<SYS>>推荐生态系统包括推荐系统与用户之间的互动。尽管从推荐系统的角度来看，但我们尝试从用户的角度来利用大语言模型（LLM），并提出一种更人类中心的推荐框架名为RAH，该框架包括推荐系统、助手和人类。助手是基于LLM的个性化代理人，用于达到用户满意度。助手在不侵略用户的前提下发挥作用，RAH框架可以适应不同的推荐系统和用户群体。在实施和评估RAH框架时，我们发现：1. 使用学习动作评价机制可以导致更加协调的个性特征。2. 我们的助手可以有效地代理人类反馈，帮助调整推荐系统。最后，我们讨论了RAH框架中更多的人类中心问题，包括用户控制、隐私和公平。
</details></li>
</ul>
<hr>
<h2 id="SwinLSTM-Improving-Spatiotemporal-Prediction-Accuracy-using-Swin-Transformer-and-LSTM"><a href="#SwinLSTM-Improving-Spatiotemporal-Prediction-Accuracy-using-Swin-Transformer-and-LSTM" class="headerlink" title="SwinLSTM:Improving Spatiotemporal Prediction Accuracy using Swin Transformer and LSTM"></a>SwinLSTM:Improving Spatiotemporal Prediction Accuracy using Swin Transformer and LSTM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09891">http://arxiv.org/abs/2308.09891</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/SongTang-x/SwinLSTM">https://github.com/SongTang-x/SwinLSTM</a></li>
<li>paper_authors: Song Tang, Chuang Li, Pu Zhang, RongNian Tang</li>
<li>for: 这篇论文的目的是提出一种新的循环细节嵌入式神经网络（SwinLSTM），用于进行空间时间预测任务。</li>
<li>methods: 这篇论文使用了Swin Transformer层和简化LSTM层（ConvLSTM）的混合，实现了循环细节嵌入式神经网络。</li>
<li>results: 在 Moving MNIST、Human3.6m、TaxiBJ 和 KTH 数据集上，SwinLSTM 已经超越了现有的方法，并且与 ConvLSTM 的预测精度有 statistically significant 的差异。<details>
<summary>Abstract</summary>
Integrating CNNs and RNNs to capture spatiotemporal dependencies is a prevalent strategy for spatiotemporal prediction tasks. However, the property of CNNs to learn local spatial information decreases their efficiency in capturing spatiotemporal dependencies, thereby limiting their prediction accuracy. In this paper, we propose a new recurrent cell, SwinLSTM, which integrates Swin Transformer blocks and the simplified LSTM, an extension that replaces the convolutional structure in ConvLSTM with the self-attention mechanism. Furthermore, we construct a network with SwinLSTM cell as the core for spatiotemporal prediction. Without using unique tricks, SwinLSTM outperforms state-of-the-art methods on Moving MNIST, Human3.6m, TaxiBJ, and KTH datasets. In particular, it exhibits a significant improvement in prediction accuracy compared to ConvLSTM. Our competitive experimental results demonstrate that learning global spatial dependencies is more advantageous for models to capture spatiotemporal dependencies. We hope that SwinLSTM can serve as a solid baseline to promote the advancement of spatiotemporal prediction accuracy. The codes are publicly available at https://github.com/SongTang-x/SwinLSTM.
</details>
<details>
<summary>摘要</summary>
“ integrating CNNs and RNNs to capture spatiotemporal dependencies is a common strategy for spatiotemporal prediction tasks. However, the property of CNNs to learn local spatial information limits their efficiency in capturing spatiotemporal dependencies, thereby limiting their prediction accuracy. In this paper, we propose a new recurrent cell, SwinLSTM, which integrates Swin Transformer blocks and the simplified LSTM, an extension that replaces the convolutional structure in ConvLSTM with the self-attention mechanism. Furthermore, we construct a network with SwinLSTM cell as the core for spatiotemporal prediction. Without using unique tricks, SwinLSTM outperforms state-of-the-art methods on Moving MNIST, Human3.6m, TaxiBJ, and KTH datasets. In particular, it exhibits a significant improvement in prediction accuracy compared to ConvLSTM. Our competitive experimental results demonstrate that learning global spatial dependencies is more advantageous for models to capture spatiotemporal dependencies. We hope that SwinLSTM can serve as a solid baseline to promote the advancement of spatiotemporal prediction accuracy. The codes are publicly available at https://github.com/SongTang-x/SwinLSTM.”Note that the translation is in Simplified Chinese, which is one of the two standard versions of Chinese used in mainland China. The traditional Chinese version would be slightly different.
</details></li>
</ul>
<hr>
<h2 id="Inductive-bias-Learning-Generating-Code-Models-with-Large-Language-Model"><a href="#Inductive-bias-Learning-Generating-Code-Models-with-Large-Language-Model" class="headerlink" title="Inductive-bias Learning: Generating Code Models with Large Language Model"></a>Inductive-bias Learning: Generating Code Models with Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09890">http://arxiv.org/abs/2308.09890</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fuyu-quant/iblm">https://github.com/fuyu-quant/iblm</a></li>
<li>paper_authors: Toma Tanaka, Naofumi Emoto, Tsukasa Yumibayashi</li>
<li>for: 本研究的目的是提出一种新的学习方法，即归纳学习（Inductive-Bias Learning，IBL），该方法结合了大语言模型（LLMs）的归纳学习（ICL）和代码生成技术，以实现高精度的推理和代码生成。</li>
<li>methods: 本研究使用的方法包括大语言模型（LLMs）的归纳学习（ICL）和代码生成技术，并提出了一种新的学习方法——归纳学习（IBL），该方法可以在不更新模型参数的情况下，基于训练数据进行高精度的推理和代码生成。</li>
<li>results: 研究发现，使用IBL方法可以实现高精度的推理和代码生成，并且比 tradicional ICL 和代表性机器学习模型更高。此外，IBL 方法还具有较好的可读性和解释性。<details>
<summary>Abstract</summary>
Large Language Models(LLMs) have been attracting attention due to a ability called in-context learning(ICL). ICL, without updating the parameters of a LLM, it is possible to achieve highly accurate inference based on rules ``in the context'' by merely inputting a training data into the prompt. Although ICL is a developing field with many unanswered questions, LLMs themselves serves as a inference model, seemingly realizing inference without explicitly indicate ``inductive bias''. On the other hand, a code generation is also a highlighted application of LLMs. The accuracy of code generation has dramatically improved, enabling even non-engineers to generate code to perform the desired tasks by crafting appropriate prompts. In this paper, we propose a novel ``learning'' method called an ``Inductive-Bias Learning (IBL)'', which combines the techniques of ICL and code generation. An idea of IBL is straightforward. Like ICL, IBL inputs a training data into the prompt and outputs a code with a necessary structure for inference (we referred to as ``Code Model'') from a ``contextual understanding''. Despite being a seemingly simple approach, IBL encompasses both a ``property of inference without explicit inductive bias'' inherent in ICL and a ``readability and explainability'' of the code generation. Surprisingly, generated Code Models have been found to achieve predictive accuracy comparable to, and in some cases surpassing, ICL and representative machine learning models. Our IBL code is open source: https://github.com/fuyu-quant/IBLM
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在最近引起了一些注意，因为它具有一种能力called内部学习（ICL）。ICL可以在不更新LLM参数的情况下，通过将训练数据输入为提示，以高度精度地进行推论。虽然ICL是一个 noch developing 的领域，但LLM本身作为一个推论模型，它似乎可以不需要显式地指定“推论假设”来进行推论。另一方面，代码生成也是LLM的一个吸引人的应用。通过LLM，代码生成的精度有了很大提升，让even non-engineers可以通过设计适当的提示来生成代码来实现想要的任务。在这篇论文中，我们提出了一种新的“学习”方法，called“推论假设学习”（IBL）。IBL结合了ICL和代码生成的技术。IBL的想法是 Straightforward：如ICL，IBL将训练数据输入为提示，并从“上下文理解”中获取一个需要的结构（我们称之为“代码模型”），以进行推论。尽管看起来非常简单，但IBL包含了ICL中的“推论无需显式假设”的特性和代码生成中的“可读性和解释性”。 surprisingly，生成的代码模型已经发现可以 дости到ICL和代表性机器学习模型的预测精度。我们的IBL代码公开在GitHub：https://github.com/fuyu-quant/IBLM。
</details></li>
</ul>
<hr>
<h2 id="Tensor-Compressed-Back-Propagation-Free-Training-for-Physics-Informed-Neural-Networks"><a href="#Tensor-Compressed-Back-Propagation-Free-Training-for-Physics-Informed-Neural-Networks" class="headerlink" title="Tensor-Compressed Back-Propagation-Free Training for (Physics-Informed) Neural Networks"></a>Tensor-Compressed Back-Propagation-Free Training for (Physics-Informed) Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09858">http://arxiv.org/abs/2308.09858</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yequan Zhao, Xinling Yu, Zhixiong Chen, Ziyue Liu, Sijia Liu, Zheng Zhang</li>
<li>for: 这篇论文主要是为了提出一个不需要传播推导（Backward Propagation，BP）的框架，来训练具有实际性的神经网络。</li>
<li>methods: 这篇论文使用了以下三种方法：	1. 紧缩矩阵variance reduction技术来增加评估缩排序（zeroth-order，ZO）的可扩展性，使得可以处理大型神经网络。	2. 混合式梯度评估方法来提高ZO训练的效率。	3. 将BP-free训练框架扩展到物理学 Informed Neural Networks（PINNs）中，通过提出一种简组方法来估计损失函数中的梯度，不需要使用BP。</li>
<li>results: 这篇论文的结果显示，BP-free训练框架对于MNIST dataset的训练损失比标准首顺训练要小，并且成功地训练了一个具有20个对应的哈密顿-雅可比-贝尔曼（HJB）偏微分方程的物理学 Informed Neural Networks（PINNs）。这个内存高效且BP-free的训练方法可能会成为未来训练许多有限资源的平台（例如FPGA、ASIC、微控制器和光子对应）的基础。<details>
<summary>Abstract</summary>
Backward propagation (BP) is widely used to compute the gradients in neural network training. However, it is hard to implement BP on edge devices due to the lack of hardware and software resources to support automatic differentiation. This has tremendously increased the design complexity and time-to-market of on-device training accelerators. This paper presents a completely BP-free framework that only requires forward propagation to train realistic neural networks. Our technical contributions are three-fold. Firstly, we present a tensor-compressed variance reduction approach to greatly improve the scalability of zeroth-order (ZO) optimization, making it feasible to handle a network size that is beyond the capability of previous ZO approaches. Secondly, we present a hybrid gradient evaluation approach to improve the efficiency of ZO training. Finally, we extend our BP-free training framework to physics-informed neural networks (PINNs) by proposing a sparse-grid approach to estimate the derivatives in the loss function without using BP. Our BP-free training only loses little accuracy on the MNIST dataset compared with standard first-order training. We also demonstrate successful results in training a PINN for solving a 20-dim Hamiltonian-Jacobi-Bellman PDE. This memory-efficient and BP-free approach may serve as a foundation for the near-future on-device training on many resource-constraint platforms (e.g., FPGA, ASIC, micro-controllers, and photonic chips).
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>> backwards propagation (BP) 是广泛使用的计算神经网络训练中的梯度计算方法。然而，由于缺乏硬件和软件资源，实现 BP 在边缘设备上具有很大的设计复杂性和时间到市场时间。这篇论文提出了一个完全不需要 BP 的框架，只需要前向传播来训练真实的神经网络。我们的技术贡献包括以下三个方面：首先，我们提出了一种紧凑变量减少方法，以大幅提高零次（ZO）优化的扩展性，使其能处理大于前一代 ZO 方法可以处理的网络大小。其次，我们提出了一种混合梯度评估方法，以提高 ZO 训练的效率。最后，我们扩展了我们的 BP-free 训练框架，以解决物理学 Informed Neural Networks（PINNs）中的梯度问题，而不需要 BP。我们的 BP-free 训练只在 MNIST 数据集上失去了微不足的精度，与标准首次训练相比。我们还成功地训练了一个 PINN，用于解决一个 20 维希尔伯特-雅各布-贝尔几何函数。这种内存高效且 BP-free 的方法可能成为未来资源限制平台（例如 FPGA、ASIC、微控制器和光学芯片）上的训练基础。
</details></li>
</ul>
<hr>
<h2 id="Enumerating-Safe-Regions-in-Deep-Neural-Networks-with-Provable-Probabilistic-Guarantees"><a href="#Enumerating-Safe-Regions-in-Deep-Neural-Networks-with-Provable-Probabilistic-Guarantees" class="headerlink" title="Enumerating Safe Regions in Deep Neural Networks with Provable Probabilistic Guarantees"></a>Enumerating Safe Regions in Deep Neural Networks with Provable Probabilistic Guarantees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09842">http://arxiv.org/abs/2308.09842</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luca Marzari, Davide Corsi, Enrico Marchesini, Alessandro Farinelli, Ferdinando Cicalese</li>
<li>for:  Ensuring trust in Deep Neural Network (DNN) systems by identifying safe areas.</li>
<li>methods:  Proposed an efficient approximation method called epsilon-ProVe, which leverages statistical prediction of tolerance limits to provide a tight lower estimate of safe areas.</li>
<li>results:  Empirical evaluation on standard benchmarks showed the scalability and effectiveness of the method, providing valuable insights for verifying DNNs.Here’s the original English text for reference:”Identifying safe areas is a key point to guarantee trust for systems that are based on Deep Neural Networks (DNNs). To this end, we introduce the AllDNN-Verification problem: given a safety property and a DNN, enumerate the set of all the regions of the property input domain which are safe, i.e., where the property does hold. Due to the #P-hardness of the problem, we propose an efficient approximation method called epsilon-ProVe. Our approach exploits a controllable underestimation of the output reachable sets obtained via statistical prediction of tolerance limits, and can provide a tight (with provable probabilistic guarantees) lower estimate of the safe areas. Our empirical evaluation on different standard benchmarks shows the scalability and effectiveness of our method, offering valuable insights for this new type of verification of DNNs.”<details>
<summary>Abstract</summary>
Identifying safe areas is a key point to guarantee trust for systems that are based on Deep Neural Networks (DNNs). To this end, we introduce the AllDNN-Verification problem: given a safety property and a DNN, enumerate the set of all the regions of the property input domain which are safe, i.e., where the property does hold. Due to the #P-hardness of the problem, we propose an efficient approximation method called epsilon-ProVe. Our approach exploits a controllable underestimation of the output reachable sets obtained via statistical prediction of tolerance limits, and can provide a tight (with provable probabilistic guarantees) lower estimate of the safe areas. Our empirical evaluation on different standard benchmarks shows the scalability and effectiveness of our method, offering valuable insights for this new type of verification of DNNs.
</details>
<details>
<summary>摘要</summary>
安全区域的标识是深度神经网络（DNN）系统的关键点，以确保系统的可靠性。为此，我们介绍了AllDNN-Verification问题：给定一个安全性质和一个DNN，列出该输入领域的安全区域，即输入中的属性不符的区域。由于这个问题的P-完备性，我们提出了一种高效的近似方法called epsilon-ProVe。我们的方法利用通过统计预测误差范围来控制输出可达区域的下预测，可以提供一个紧密的（具有可证明的概率保证）下限估计安全区域。我们的实验结果表明我们的方法在不同的标准准型上具有扩展性和有效性，提供了有价值的这种新类型的DNN验证的反馈。
</details></li>
</ul>
<hr>
<h2 id="Synergistic-Integration-of-Large-Language-Models-and-Cognitive-Architectures-for-Robust-AI-An-Exploratory-Analysis"><a href="#Synergistic-Integration-of-Large-Language-Models-and-Cognitive-Architectures-for-Robust-AI-An-Exploratory-Analysis" class="headerlink" title="Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI: An Exploratory Analysis"></a>Synergistic Integration of Large Language Models and Cognitive Architectures for Robust AI: An Exploratory Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09830">http://arxiv.org/abs/2308.09830</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oscar J. Romero, John Zimmerman, Aaron Steinfeld, Anthony Tomasic</li>
<li>for: 论文探讨了将大语言模型（LLMs）和认知建筑（CAs）两种人工智能子领域融合的可能性，以实现更加智能的人工智能系统。</li>
<li>methods: 该论文采用了理论模型和初步实验数据，探讨了这两种方法之间的融合方法，以便赋予人工智能系统更高的robustness和复杂性。</li>
<li>results: 论文预测了这些融合方法可以相互补偿对方的缺陷和限制，从而实现更高水平的人工智能系统。同时，论文还讨论了每种方法的缺点和挑战。<details>
<summary>Abstract</summary>
This paper explores alternatives for integrating two subdisciplines of AI in the construction of artificial agents that exhibit intelligent behavior: Large Language Models (LLMs) and Cognitive Architectures (CAs). Guided by theoretical models and supported by preliminary empirical data, we hypothesize how diverse synergistic approaches can mutually compensate for their respective weaknesses and limitations, ultimately fostering more robust and sophisticated artificial intelligence systems. Additionally, we discuss the tradeoffs and challenges associated with each approach.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Learning-Representations-on-Logs-for-AIOps"><a href="#Learning-Representations-on-Logs-for-AIOps" class="headerlink" title="Learning Representations on Logs for AIOps"></a>Learning Representations on Logs for AIOps</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11526">http://arxiv.org/abs/2308.11526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pranjal Gupta, Harshit Kumar, Debanjana Kar, Karan Bhukar, Pooja Aggarwal, Prateeti Mohapatra</li>
<li>for: 提高 AIOps 平台的自动化操作效率，减少人工干预。</li>
<li>methods: 使用自然语言处理技术和大语言模型（LLM）进行自动化日志分析，包括日志格式检测、日志分类和日志解析等任务。</li>
<li>results: 比较 existed 模型，提出一种基于 LLM 的日志分析模型，在多个下游任务上达到了更高的性能。<details>
<summary>Abstract</summary>
AI for IT Operations (AIOps) is a powerful platform that Site Reliability Engineers (SREs) use to automate and streamline operational workflows with minimal human intervention. Automated log analysis is a critical task in AIOps as it provides key insights for SREs to identify and address ongoing faults. Tasks such as log format detection, log classification, and log parsing are key components of automated log analysis. Most of these tasks require supervised learning; however, there are multiple challenges due to limited labelled log data and the diverse nature of log data. Large Language Models (LLMs) such as BERT and GPT3 are trained using self-supervision on a vast amount of unlabeled data. These models provide generalized representations that can be effectively used for various downstream tasks with limited labelled data. Motivated by the success of LLMs in specific domains like science and biology, this paper introduces a LLM for log data which is trained on public and proprietary log data. The results of our experiments demonstrate that the proposed LLM outperforms existing models on multiple downstream tasks. In summary, AIOps powered by LLMs offers an efficient and effective solution for automating log analysis tasks and enabling SREs to focus on higher-level tasks. Our proposed LLM, trained on public and proprietary log data, offers superior performance on multiple downstream tasks, making it a valuable addition to the AIOps platform.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="An-Image-is-Worth-a-Thousand-Toxic-Words-A-Metamorphic-Testing-Framework-for-Content-Moderation-Software"><a href="#An-Image-is-Worth-a-Thousand-Toxic-Words-A-Metamorphic-Testing-Framework-for-Content-Moderation-Software" class="headerlink" title="An Image is Worth a Thousand Toxic Words: A Metamorphic Testing Framework for Content Moderation Software"></a>An Image is Worth a Thousand Toxic Words: A Metamorphic Testing Framework for Content Moderation Software</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09810">http://arxiv.org/abs/2308.09810</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenxuan Wang, Jingyuan Huang, Jen-tse Huang, Chang Chen, Jiazhen Gu, Pinjia He, Michael R. Lyu</li>
<li>for: 这个论文旨在探讨现代内容审核软件对隐藏文本内容的抗垃圾性能。</li>
<li>methods: 该论文提出了一种基于变换规则的内容审核测试框架，名为OASIS。OASIS使用了21个变换规则，来生成含毒文本内容的图像测试用例，以检测内容审核软件的抗垃圾性能。</li>
<li>results: 根据论文的测试结果，OASIS可以寻发现到50%以上的潜在的攻击表现，并且通过重新训练内容审核模型，可以提高内容审核模型的鲁棒性，无需对性能产生负面影响。<details>
<summary>Abstract</summary>
The exponential growth of social media platforms has brought about a revolution in communication and content dissemination in human society. Nevertheless, these platforms are being increasingly misused to spread toxic content, including hate speech, malicious advertising, and pornography, leading to severe negative consequences such as harm to teenagers' mental health. Despite tremendous efforts in developing and deploying textual and image content moderation methods, malicious users can evade moderation by embedding texts into images, such as screenshots of the text, usually with some interference. We find that modern content moderation software's performance against such malicious inputs remains underexplored. In this work, we propose OASIS, a metamorphic testing framework for content moderation software. OASIS employs 21 transform rules summarized from our pilot study on 5,000 real-world toxic contents collected from 4 popular social media applications, including Twitter, Instagram, Sina Weibo, and Baidu Tieba. Given toxic textual contents, OASIS can generate image test cases, which preserve the toxicity yet are likely to bypass moderation. In the evaluation, we employ OASIS to test five commercial textual content moderation software from famous companies (i.e., Google Cloud, Microsoft Azure, Baidu Cloud, Alibaba Cloud and Tencent Cloud), as well as a state-of-the-art moderation research model. The results show that OASIS achieves up to 100% error finding rates. Moreover, through retraining the models with the test cases generated by OASIS, the robustness of the moderation model can be improved without performance degradation.
</details>
<details>
<summary>摘要</summary>
社交媒体平台的快速增长引起了人类社会的communication和内容传递革命。然而，这些平台正在不断被滥用来传播恶意内容，包括仇恨言论、恶意广告和色情内容，导致了年轻人的心理健康受到严重损害。尽管努力开发和部署文本和图像内容审核方法，但恶意用户可以通过嵌入文本到图像中来逃脱审核，例如将文本截屏并添加扰乱。我们发现现有内容审核软件的性能在面对这类恶意输入仍然未得到足够的探索。在这项工作中，我们提出了OASIS，一个基于变形测试的内容审核软件测试框架。OASIS使用了21个从我们的飞行研究中所挑选的变形规则，这些规则是基于5000个实际的恶意内容，收集自四个popular社交媒体应用程序（Twitter、Instagram、Sina Weibo和Baidu Tieba）。给定恶意文本内容，OASIS可以生成图像测试 caso，保留恶意性，但可能会绕过审核。在评估中，我们使用OASIS测试五家著名公司的商业文本内容审核软件（Google Cloud、Microsoft Azure、Baidu Cloud、Alibaba Cloud和Tencent Cloud），以及一种当前研究模型。结果显示，OASIS可以达到100%的错误发现率。此外，通过 retraining 模型使用OASIS生成的测试 caso，可以提高审核模型的Robustness，不会导致性能下降。
</details></li>
</ul>
<hr>
<h2 id="VL-PET-Vision-and-Language-Parameter-Efficient-Tuning-via-Granularity-Control"><a href="#VL-PET-Vision-and-Language-Parameter-Efficient-Tuning-via-Granularity-Control" class="headerlink" title="VL-PET: Vision-and-Language Parameter-Efficient Tuning via Granularity Control"></a>VL-PET: Vision-and-Language Parameter-Efficient Tuning via Granularity Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09804">http://arxiv.org/abs/2308.09804</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/henryhzy/vl-pet">https://github.com/henryhzy/vl-pet</a></li>
<li>paper_authors: Zi-Yuan Hu, Yanyang Li, Michael R. Lyu, Liwei Wang</li>
<li>for: 这篇论文是针对现有的语言模型（PLMs）的模型训练和储存成本增长的问题，提出了一个名为Vision-and-Language Parameter-Efficient Tuning（VL-PET）的框架，以便实现实时的模型训练和运算。</li>
<li>methods: 这篇论文使用了一个名为Granularity-Controlled Mechanism（GCM）的新的控制机制，允许在模型训练中对模组化修改（例如Adapter和LoRA）进行有效的控制，以提高模型的效率和可靠性。</li>
<li>results: 在四个图像与文本任务和四个影片与文本任务上，这篇论文的VL-PET框架和lightweight PET模组设计在效率、可靠性和转移性方面具有优秀的表现，特别是与VL-Adapter和LoRA进行比较，在图像与文本任务上表现出了2.92%（3.41%）和3.37%（7.03%）的提升。<details>
<summary>Abstract</summary>
As the model size of pre-trained language models (PLMs) grows rapidly, full fine-tuning becomes prohibitively expensive for model training and storage. In vision-and-language (VL), parameter-efficient tuning (PET) techniques are proposed to integrate modular modifications (e.g., Adapter and LoRA) into encoder-decoder PLMs. By tuning a small set of trainable parameters, these techniques perform on par with full fine-tuning. However, excessive modular modifications and neglecting the functionality gap between the encoders and decoders can lead to performance degradation, while existing PET techniques (e.g., VL-Adapter) overlook these critical issues. In this paper, we propose a Vision-and-Language Parameter-Efficient Tuning (VL-PET) framework to impose effective control over modular modifications via a novel granularity-controlled mechanism. Considering different granularity-controlled matrices generated by this mechanism, a variety of model-agnostic VL-PET modules can be instantiated from our framework for better efficiency and effectiveness trade-offs. We further propose lightweight PET module designs to enhance VL alignment and modeling for the encoders and maintain text generation for the decoders. Extensive experiments conducted on four image-text tasks and four video-text tasks demonstrate the efficiency, effectiveness and transferability of our VL-PET framework. In particular, our VL-PET-large with lightweight PET module designs significantly outperforms VL-Adapter by 2.92% (3.41%) and LoRA by 3.37% (7.03%) with BART-base (T5-base) on image-text tasks. Furthermore, we validate the enhanced effect of employing our VL-PET designs on existing PET techniques, enabling them to achieve significant performance improvements. Our code is available at https://github.com/HenryHZY/VL-PET.
</details>
<details>
<summary>摘要</summary>
As the size of pre-trained language models (PLMs) grows rapidly, full fine-tuning becomes increasingly expensive for model training and storage. In vision-and-language (VL), parameter-efficient tuning (PET) techniques are proposed to integrate modular modifications (e.g., Adapter and LoRA) into encoder-decoder PLMs. By tuning a small set of trainable parameters, these techniques can achieve performance on par with full fine-tuning. However, excessive modular modifications and neglecting the functionality gap between the encoders and decoders can lead to performance degradation, while existing PET techniques (e.g., VL-Adapter) overlook these critical issues.In this paper, we propose a Vision-and-Language Parameter-Efficient Tuning (VL-PET) framework to effectively control modular modifications through a novel granularity-controlled mechanism. By considering different granularity-controlled matrices generated by this mechanism, a variety of model-agnostic VL-PET modules can be instantiated from our framework for better efficiency and effectiveness trade-offs. We further propose lightweight PET module designs to enhance VL alignment and modeling for the encoders and maintain text generation for the decoders.Extensive experiments conducted on four image-text tasks and four video-text tasks demonstrate the efficiency, effectiveness, and transferability of our VL-PET framework. In particular, our VL-PET-large with lightweight PET module designs significantly outperforms VL-Adapter by 2.92% (3.41%) and LoRA by 3.37% (7.03%) with BART-base (T5-base) on image-text tasks. Furthermore, we validate the enhanced effect of employing our VL-PET designs on existing PET techniques, enabling them to achieve significant performance improvements. Our code is available at <https://github.com/HenryHZY/VL-PET>.
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Power-of-Creative-AI-Tools-and-Game-Based-Methodologies-for-Interactive-Web-Based-Programming"><a href="#Exploring-the-Power-of-Creative-AI-Tools-and-Game-Based-Methodologies-for-Interactive-Web-Based-Programming" class="headerlink" title="Exploring the Power of Creative AI Tools and Game-Based Methodologies for Interactive Web-Based Programming"></a>Exploring the Power of Creative AI Tools and Game-Based Methodologies for Interactive Web-Based Programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11649">http://arxiv.org/abs/2308.11649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benjamin Kenwright</li>
<li>for: 这篇论文旨在探讨创造性AI工具和游戏方法在互动网页程序中的潜力，包括提高学习体验和提高用户参与度。</li>
<li>methods: 论文使用了创造性AI工具和游戏方法，包括生成AI内容和用户参与式游戏等。</li>
<li>results: 论文通过对现实世界应用的例子和实践，探讨了这些工具和方法在web开发中的潜力和局限性，以及对用户体验和参与度的影响。<details>
<summary>Abstract</summary>
In recent years, the fields of artificial intelligence and web-based programming have seen tremendous advancements, enabling developers to create dynamic and interactive websites and applications. At the forefront of these advancements, creative AI tools and game-based methodologies have emerged as potent instruments, promising enhanced user experiences and increased engagement in educational environments. This chapter explores the potential of these tools and methodologies for interactive web-based programming, examining their benefits, limitations, and real-world applications. We examine the challenges and ethical considerations that arise when integrating these technologies into web development, such as privacy concerns and the potential for bias in AI-generated content. Through this exploration, we aim to provide insights into the exciting possibilities that creative AI tools and game-based methodologies offer for the future of web-based programming.
</details>
<details>
<summary>摘要</summary>
recent 年份, artificial intelligence 和 web-based 程序设计 领域已经取得了很大的进步, allowing developers to create dynamic and interactive websites and applications. At the forefront of these advancements, creative AI tools 和 game-based methodologies have emerged as potent instruments, promising enhanced user experiences and increased engagement in educational environments. This chapter explores the potential of these tools and methodologies for interactive web-based programming, examining their benefits, limitations, and real-world applications. We examine the challenges and ethical considerations that arise when integrating these technologies into web development, such as privacy concerns and the potential for bias in AI-generated content. Through this exploration, we aim to provide insights into the exciting possibilities that creative AI tools 和 game-based methodologies offer for the future of web-based programming.Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and other parts of the world. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Taken-by-Surprise-Contrast-effect-for-Similarity-Scores"><a href="#Taken-by-Surprise-Contrast-effect-for-Similarity-Scores" class="headerlink" title="Taken by Surprise: Contrast effect for Similarity Scores"></a>Taken by Surprise: Contrast effect for Similarity Scores</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09765">http://arxiv.org/abs/2308.09765</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/meetelise/surprise-similarity">https://github.com/meetelise/surprise-similarity</a></li>
<li>paper_authors: Thomas C. Bachlechner, Mario Martone, Marjorie Schillo</li>
<li>for: 提高自然语言处理、信息检索和分类任务中对象向量嵌入的相似性评估的精度。</li>
<li>methods: 提出了一种基于对象ensemble的相似性评估指标——意料分数（surprise score），它考虑了人类对对象的概念嵌入的概率分布，从而更好地反映人类对对象之间的认知。</li>
<li>results: 在零&#x2F;几shot文档分类任务中，使用意料分数 Typically 10-15% 比采用Raw cosine similarity better 的性能。<details>
<summary>Abstract</summary>
Accurately evaluating the similarity of object vector embeddings is of critical importance for natural language processing, information retrieval and classification tasks. Popular similarity scores (e.g cosine similarity) are based on pairs of embedding vectors and disregard the distribution of the ensemble from which objects are drawn. Human perception of object similarity significantly depends on the context in which the objects appear. In this work we propose the $\textit{surprise score}$, an ensemble-normalized similarity metric that encapsulates the contrast effect of human perception and significantly improves the classification performance on zero- and few-shot document classification tasks. This score quantifies the surprise to find a given similarity between two elements relative to the pairwise ensemble similarities. We evaluate this metric on zero/few shot classification and clustering tasks and typically find 10-15 % better performance compared to raw cosine similarity. Our code is available at https://github.com/MeetElise/surprise-similarity.
</details>
<details>
<summary>摘要</summary>
非常重要的评估对象vector embedding的相似性，是自然语言处理、信息检索和分类任务中的关键。流行的相似性分数（例如偏度相似性）基于对 embedding vector的对比，忽略对象ensemble的分布。人类对物体相似性的感知强烈取决于物体在哪个上下文中出现。在这项工作中，我们提出了$\surprise$分数，一种ensemblenormalized的相似性度量，它利用对象ensemble的相似性来捕捉人类对物体相似性的异常效应。这个分数衡量在两个元素之间发现相似性的惊喜程度，相比于对 embedding vector的直接对比。我们在零/几个预测任务中评估了这个分数， Typically find 10-15% better performance compared to raw cosine similarity。我们的代码可以在https://github.com/MeetElise/surprise-similarity中找到。
</details></li>
</ul>
<hr>
<h2 id="The-Impact-of-Background-Removal-on-Performance-of-Neural-Networks-for-Fashion-Image-Classification-and-Segmentation"><a href="#The-Impact-of-Background-Removal-on-Performance-of-Neural-Networks-for-Fashion-Image-Classification-and-Segmentation" class="headerlink" title="The Impact of Background Removal on Performance of Neural Networks for Fashion Image Classification and Segmentation"></a>The Impact of Background Removal on Performance of Neural Networks for Fashion Image Classification and Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09764">http://arxiv.org/abs/2308.09764</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junhui Liang, Ying Liu, Vladimir Vlassov</li>
<li>for: 提高时尚图像数据质量和模型性能</li>
<li>methods: 使用突出对象检测来移除背景</li>
<li>results: 在简单和浅层网络中提高模型准确率，但在深度网络中不适用due to compatibility issues with other regularization techniques<details>
<summary>Abstract</summary>
Fashion understanding is a hot topic in computer vision, with many applications having great business value in the market. Fashion understanding remains a difficult challenge for computer vision due to the immense diversity of garments and various scenes and backgrounds. In this work, we try removing the background from fashion images to boost data quality and increase model performance. Having fashion images of evident persons in fully visible garments, we can utilize Salient Object Detection to achieve the background removal of fashion data to our expectations. A fashion image with the background removed is claimed as the "rembg" image, contrasting with the original one in the fashion dataset. We conducted extensive comparative experiments with these two types of images on multiple aspects of model training, including model architectures, model initialization, compatibility with other training tricks and data augmentations, and target task types. Our experiments show that background removal can effectively work for fashion data in simple and shallow networks that are not susceptible to overfitting. It can improve model accuracy by up to 5% in the classification on the FashionStyle14 dataset when training models from scratch. However, background removal does not perform well in deep neural networks due to incompatibility with other regularization techniques like batch normalization, pre-trained initialization, and data augmentations introducing randomness. The loss of background pixels invalidates many existing training tricks in the model training, adding the risk of overfitting for deep models.
</details>
<details>
<summary>摘要</summary>
《时尚理解》是计算机视觉领域的热门话题，具有广泛的商业价值。然而，时尚理解仍然是计算机视觉中的一个困难挑战，因为裙服的多样性和不同的场景和背景。在这项工作中，我们尝试将背景从时尚图像中除去，以提高数据质量并提高模型性能。利用有 evident persons 穿着完整的裙服图像，我们可以使用 Salient Object Detection 来实现背景的除去。一个没有背景的时尚图像被称为 "rembg" 图像，与原始图像在时尚数据集中进行比较。我们进行了多种比较实验，包括模型架构、模型初始化、与其他训练技巧和数据扩展相容性等多个方面。我们的实验结果表明，背景除去可以有效地对时尚数据进行简单化和浅化，提高模型精度。在 FashionStyle14 数据集上进行类别预测时，背景除去可以提高模型的准确率达到 5%。然而，背景除去不适合深度神经网络，因为它们与其他正则化技术，如批处理标准化、预训练初始化和数据扩展引入随机性，不兼容。失去背景像素会让许多现有的训练技巧无法使用，增加深度模型难以避免过拟合的风险。
</details></li>
</ul>
<hr>
<h2 id="Diff2Lip-Audio-Conditioned-Diffusion-Models-for-Lip-Synchronization"><a href="#Diff2Lip-Audio-Conditioned-Diffusion-Models-for-Lip-Synchronization" class="headerlink" title="Diff2Lip: Audio Conditioned Diffusion Models for Lip-Synchronization"></a>Diff2Lip: Audio Conditioned Diffusion Models for Lip-Synchronization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09716">http://arxiv.org/abs/2308.09716</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/soumik-kanad/diff2lip">https://github.com/soumik-kanad/diff2lip</a></li>
<li>paper_authors: Soumik Mukhopadhyay, Saksham Suri, Ravi Teja Gadde, Abhinav Shrivastava</li>
<li>for:  lip synchronization in-the-wild, preserving identity, pose, emotions, and image quality</li>
<li>methods: audio-conditioned diffusion-based model, trained on Voxceleb2 dataset</li>
<li>results: outperforms popular methods like Wav2Lip and PC-AVS in FID metric and MOS of users, results on both reconstruction and cross settings on Voxceleb2 and LRW datasets.<details>
<summary>Abstract</summary>
The task of lip synchronization (lip-sync) seeks to match the lips of human faces with different audio. It has various applications in the film industry as well as for creating virtual avatars and for video conferencing. This is a challenging problem as one needs to simultaneously introduce detailed, realistic lip movements while preserving the identity, pose, emotions, and image quality. Many of the previous methods trying to solve this problem suffer from image quality degradation due to a lack of complete contextual information. In this paper, we present Diff2Lip, an audio-conditioned diffusion-based model which is able to do lip synchronization in-the-wild while preserving these qualities. We train our model on Voxceleb2, a video dataset containing in-the-wild talking face videos. Extensive studies show that our method outperforms popular methods like Wav2Lip and PC-AVS in Fr\'echet inception distance (FID) metric and Mean Opinion Scores (MOS) of the users. We show results on both reconstruction (same audio-video inputs) as well as cross (different audio-video inputs) settings on Voxceleb2 and LRW datasets. Video results and code can be accessed from our project page ( https://soumik-kanad.github.io/diff2lip ).
</details>
<details>
<summary>摘要</summary>
“lip sync”的任务是将不同的音频与人脸的肢体动作相对应。它在电影业中以及创建虚拟人偶和视讯会议中扮演重要的角色。这是一个具有挑战性的问题，因为需要同时实现细节、现实的舌头运动，并保留人脸的身份、姿势、情感和图像质量。许多以前的方法尝试解决这个问题，却受到图像质量下降的问题。在这篇论文中，我们提出了Diff2Lip，一个音频条件的扩散模型，可以在实际环境中进行lip sync，并保持这些质量。我们在Voxceleb2 dataset上训练我们的模型，该dataset包含实际环境中的说话面孔录影片。广泛的研究表明，我们的方法在FID和用户的意见评分（MOS）中优于流行的Wav2Lip和PC-AVS方法。我们在Voxceleb2和LRW datasets上进行了重建（同一对 audio-video 输入）和跨（不同 audio-video 输入）的研究，并提供了视频结果和代码。更多资讯可以在我们的项目页面（https://soumik-kanad.github.io/diff2lip）上获取。”
</details></li>
</ul>
<hr>
<h2 id="SimDA-Simple-Diffusion-Adapter-for-Efficient-Video-Generation"><a href="#SimDA-Simple-Diffusion-Adapter-for-Efficient-Video-Generation" class="headerlink" title="SimDA: Simple Diffusion Adapter for Efficient Video Generation"></a>SimDA: Simple Diffusion Adapter for Efficient Video Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09710">http://arxiv.org/abs/2308.09710</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhen Xing, Qi Dai, Han Hu, Zuxuan Wu, Yu-Gang Jiang</li>
<li>for: 本研究旨在提出一种 Parametric Efficient 的 Text-to-Video（T2V）模型，通过简单的扩展器（SimDA）来改进现有的 Text-to-Image（T2I）模型，以提高视频生成效果。</li>
<li>methods: 我们提出了一种使用 Light-weight Spatial and Temporal Adapters（LSTA）和 Latent-Shift Attention（LSA）来适应视频生成，并且通过一种简单的微调过程来调整模型。</li>
<li>results: 我们的方法可以在 wild 中进行视频生成，同时也可以在一次微调过程中进行一键调整，以达到高分辨率（1024x1024）视频生成。<details>
<summary>Abstract</summary>
The recent wave of AI-generated content has witnessed the great development and success of Text-to-Image (T2I) technologies. By contrast, Text-to-Video (T2V) still falls short of expectations though attracting increasing interests. Existing works either train from scratch or adapt large T2I model to videos, both of which are computation and resource expensive. In this work, we propose a Simple Diffusion Adapter (SimDA) that fine-tunes only 24M out of 1.1B parameters of a strong T2I model, adapting it to video generation in a parameter-efficient way. In particular, we turn the T2I model for T2V by designing light-weight spatial and temporal adapters for transfer learning. Besides, we change the original spatial attention to the proposed Latent-Shift Attention (LSA) for temporal consistency. With similar model architecture, we further train a video super-resolution model to generate high-definition (1024x1024) videos. In addition to T2V generation in the wild, SimDA could also be utilized in one-shot video editing with only 2 minutes tuning. Doing so, our method could minimize the training effort with extremely few tunable parameters for model adaptation.
</details>
<details>
<summary>摘要</summary>
近期人工智能生成内容的浪潮见证了文本到图像（T2I）技术的大发展和成功。然而，文本到视频（T2V）仍然落后于期望，吸引了增加的关注。现有的工作都是从零开始或者修改大型T2I模型来视频生成，两者都需要大量计算和资源。在这个工作中，我们提出了一种简单的扩散适配器（SimDA），只要24M个 Parameters中的1.1B个参数进行精细调整，从而将T2I模型适应到视频生成。具体来说，我们设计了轻量级的空间和时间适配器，以便在转移学习中使用。此外，我们将原始的空间注意力替换为我们提出的射频隐藏注意力（LSA），以保证时间一致性。与类似的模型架构相比，我们进一步训练了一个高清度（1024x1024）视频生成模型。除了在野生环境中进行T2V生成外，SimDA还可以在一次视频编辑中使用，只需要2分钟的调整。这样，我们的方法可以减少模型适应的训练努力，并且具有非常少的调整参数。
</details></li>
</ul>
<hr>
<h2 id="Graph-of-Thoughts-Solving-Elaborate-Problems-with-Large-Language-Models"><a href="#Graph-of-Thoughts-Solving-Elaborate-Problems-with-Large-Language-Models" class="headerlink" title="Graph of Thoughts: Solving Elaborate Problems with Large Language Models"></a>Graph of Thoughts: Solving Elaborate Problems with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09687">http://arxiv.org/abs/2308.09687</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/spcl/graph-of-thoughts">https://github.com/spcl/graph-of-thoughts</a></li>
<li>paper_authors: Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, Torsten Hoefler</li>
<li>for: 提高大语言模型（LLM）的提示能力，超过链条思想或树思想（ToT）的限制。</li>
<li>methods: 模型LLM生成的信息为一个自由图，其中单元为“LLM思想”，而边表示这些单元之间的依赖关系。这种方法可以将不同的LLM思想组合成补充性的结果，浓缩整个网络的思想，或通过反馈循环进行增强。</li>
<li>results: 比对于state of the art，GoT可以提高排序质量62%，同时降低成本&gt;31%。此外，GoT可以扩展新的思想转换，因此可以用于开拓新的提示方案。这项工作使得LLM的思维更加接近人类思维或脑机制，如复杂网络。<details>
<summary>Abstract</summary>
We introduce Graph of Thoughts (GoT): a framework that advances prompting capabilities in large language models (LLMs) beyond those offered by paradigms such as Chain-of-Thought or Tree of Thoughts (ToT). The key idea and primary advantage of GoT is the ability to model the information generated by an LLM as an arbitrary graph, where units of information ("LLM thoughts") are vertices, and edges correspond to dependencies between these vertices. This approach enables combining arbitrary LLM thoughts into synergistic outcomes, distilling the essence of whole networks of thoughts, or enhancing thoughts using feedback loops. We illustrate that GoT offers advantages over state of the art on different tasks, for example increasing the quality of sorting by 62% over ToT, while simultaneously reducing costs by >31%. We ensure that GoT is extensible with new thought transformations and thus can be used to spearhead new prompting schemes. This work brings the LLM reasoning closer to human thinking or brain mechanisms such as recurrence, both of which form complex networks.
</details>
<details>
<summary>摘要</summary>
我们介绍 Graph of Thoughts（GoT）：一个框架，它超越了链条思维和树思维（ToT）的概念，实现了大语言模型（LLM）的推问能力。GoT的关键想法和主要优势在于让LLM的资讯单位（“LLM思维”）成为随机图形的顶点，并将这些顶点之间的相互依赖关系表现为图形的边。这种方法可以结合不同的LLM思维，形成具有融合效果的结果，精炼出整个网络的思想核心，或者通过反馈循环进行思维提升。我们证明GoT在不同的任务上比ToT高质量62%，同时降低成本>31%。我们还证明GoT可扩展新的思维转换，因此可以用来开创新的推问方案。这个工作使得LLM的思维更加接近人类思维或脑机制，例如回传和回归，这些机制形成复杂的网络。
</details></li>
</ul>
<hr>
<h2 id="PoSynDA-Multi-Hypothesis-Pose-Synthesis-Domain-Adaptation-for-Robust-3D-Human-Pose-Estimation"><a href="#PoSynDA-Multi-Hypothesis-Pose-Synthesis-Domain-Adaptation-for-Robust-3D-Human-Pose-Estimation" class="headerlink" title="PoSynDA: Multi-Hypothesis Pose Synthesis Domain Adaptation for Robust 3D Human Pose Estimation"></a>PoSynDA: Multi-Hypothesis Pose Synthesis Domain Adaptation for Robust 3D Human Pose Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09678">http://arxiv.org/abs/2308.09678</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hbing-l/posynda">https://github.com/hbing-l/posynda</a></li>
<li>paper_authors: Hanbing Liu, Jun-Yan He, Zhi-Qi Cheng, Wangmeng Xiang, Qize Yang, Wenhao Chai, Gaoang Wang, Xu Bao, Bin Luo, Yifeng Geng, Xuansong Xie</li>
<li>for:  overcome the challenge of adapting 3D human pose estimators to new datasets without extensive target domain annotation.</li>
<li>methods:  utilize a diffusion-centric structure to simulate the 3D pose distribution in the target domain, incorporate a multi-hypothesis network to create diverse pose hypotheses, and use target-specific source augmentation to obtain the target domain distribution data.</li>
<li>results:  demonstrate competitive performance on benchmarks such as Human3.6M, MPI-INF-3DHP, and 3DPW, even comparable with the target-trained MixSTE model.<details>
<summary>Abstract</summary>
The current 3D human pose estimators face challenges in adapting to new datasets due to the scarcity of 2D-3D pose pairs in target domain training sets. We present the \textit{Multi-Hypothesis \textbf{P}ose \textbf{Syn}thesis \textbf{D}omain \textbf{A}daptation} (\textbf{PoSynDA}) framework to overcome this issue without extensive target domain annotation. Utilizing a diffusion-centric structure, PoSynDA simulates the 3D pose distribution in the target domain, filling the data diversity gap. By incorporating a multi-hypothesis network, it creates diverse pose hypotheses and aligns them with the target domain. Target-specific source augmentation obtains the target domain distribution data from the source domain by decoupling the scale and position parameters. The teacher-student paradigm and low-rank adaptation further refine the process. PoSynDA demonstrates competitive performance on benchmarks, such as Human3.6M, MPI-INF-3DHP, and 3DPW, even comparable with the target-trained MixSTE model~\cite{zhang2022mixste}. This work paves the way for the practical application of 3D human pose estimation. The code is available at https://github.com/hbing-l/PoSynDA.
</details>
<details>
<summary>摘要</summary>
当前的3D人体姿态估计器面临着适应新数据集的挑战，因为目标领域训练集中缺乏2D-3D姿态对应的数据。我们提出了\textbf{\textit{多种假设 pose synthesis domain adaptation}（PoSynDA）框架，以解决这个问题而无需大量目标领域注释。PoSynDA使用分散结构，在目标领域中模拟3D姿态分布，填充数据多样性的空隙。通过包含多种假设网络，PoSynDA创造了多个姿态假设，并将它们与目标领域进行对align。通过寻求目标特定的源增强，从源领域中获取了目标领域的分布数据。教师-学生论断和低级适应进一步细化过程。PoSynDA在 benchmark 上表现竞争力强，包括人类3.6M、MPI-INF-3DHP 和 3DPW，甚至与目标训练 MixSTE 模型相当。这项工作为3D人体姿态估计器的实际应用开辟了道路。代码可以在https://github.com/hbing-l/PoSynDA 上获取。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-3D-Pose-Estimation-with-Non-Rigid-Structure-from-Motion-Modeling"><a href="#Unsupervised-3D-Pose-Estimation-with-Non-Rigid-Structure-from-Motion-Modeling" class="headerlink" title="Unsupervised 3D Pose Estimation with Non-Rigid Structure-from-Motion Modeling"></a>Unsupervised 3D Pose Estimation with Non-Rigid Structure-from-Motion Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10705">http://arxiv.org/abs/2308.10705</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haorui Ji, Hui Deng, Yuchao Dai, Hongdong Li</li>
<li>for: 这篇论文的目的是提出一种新的人体姿态抽象模型和一种基于扩散的动作先验。</li>
<li>methods: 该论文使用了一种混合空间-时间的NRSfMformer来同时估算每帧人体 pose的3D参考骨架和每帧骨架变形。</li>
<li>results: 该论文的实验结果表明，该方法可以在主流数据集上获得更高的性能，并且超过了当前状态的最佳效果。<details>
<summary>Abstract</summary>
Most of the previous 3D human pose estimation work relied on the powerful memory capability of the network to obtain suitable 2D-3D mappings from the training data. Few works have studied the modeling of human posture deformation in motion. In this paper, we propose a new modeling method for human pose deformations and design an accompanying diffusion-based motion prior. Inspired by the field of non-rigid structure-from-motion, we divide the task of reconstructing 3D human skeletons in motion into the estimation of a 3D reference skeleton, and a frame-by-frame skeleton deformation. A mixed spatial-temporal NRSfMformer is used to simultaneously estimate the 3D reference skeleton and the skeleton deformation of each frame from 2D observations sequence, and then sum them to obtain the pose of each frame. Subsequently, a loss term based on the diffusion model is used to ensure that the pipeline learns the correct prior motion knowledge. Finally, we have evaluated our proposed method on mainstream datasets and obtained superior results outperforming the state-of-the-art.
</details>
<details>
<summary>摘要</summary>
大多数前一代3D人姿估计工作都依赖于网络的强大记忆能力来获得适合的2D-3D映射从训练数据中。只有一些工作研究了人姿变形的模型化。在这篇论文中，我们提出了一种新的人姿变形模型化方法和附加的扩散基于运动先驱模型。受非固定结构从动图像处理领域启发，我们将重建3D人 skeleton在运动中的任务分解为估计3D参照骨架和每帧骨架变形。使用混合空间-时间NRSfMformer来同时估计每帧的3D参照骨架和每帧骨架变形，然后将它们加总以获得每帧的姿势。最后，我们使用基于扩散模型的损失函数来确保管道学习正确的先驱动知识。我们在主流数据集上评估了我们的提议方法，并获得了比前一代更高的成绩。
</details></li>
</ul>
<hr>
<h2 id="GiGaMAE-Generalizable-Graph-Masked-Autoencoder-via-Collaborative-Latent-Space-Reconstruction"><a href="#GiGaMAE-Generalizable-Graph-Masked-Autoencoder-via-Collaborative-Latent-Space-Reconstruction" class="headerlink" title="GiGaMAE: Generalizable Graph Masked Autoencoder via Collaborative Latent Space Reconstruction"></a>GiGaMAE: Generalizable Graph Masked Autoencoder via Collaborative Latent Space Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09663">http://arxiv.org/abs/2308.09663</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sycny/gigamae">https://github.com/sycny/gigamae</a></li>
<li>paper_authors: Yucheng Shi, Yushun Dong, Qiaoyu Tan, Jundong Li, Ninghao Liu</li>
<li>for: 这 paper 的目的是提出一种基于自动编码器的无监督学习方法，以便在图数据上生成有效的表示。</li>
<li>methods: 该方法使用了一种名为 GiGaMAE 的图自适应编码器框架，该框架通过协同重建有用和完整的嵌入表示来学习图数据的总体知识。</li>
<li>results: 对于七个 dataset 上的三个下游任务，GiGaMAE 的表现优于基elines。研究者希望这些结果能够引导基础模型的设计在图结构数据上。Translation:</li>
<li>for: The purpose of this paper is to propose a self-supervised learning method based on masked autoencoders to generate effective representations on graph data.</li>
<li>methods: The method uses a novel graph masked autoencoder framework called GiGaMAE, which learns to collaboratively reconstruct informative and integrated latent embeddings to capture more generalized and comprehensive knowledge.</li>
<li>results: GiGaMAE outperforms state-of-the-art baselines on seven datasets for three downstream tasks. The researchers hope that these results will shed light on the design of foundation models on graph-structured data.<details>
<summary>Abstract</summary>
Self-supervised learning with masked autoencoders has recently gained popularity for its ability to produce effective image or textual representations, which can be applied to various downstream tasks without retraining. However, we observe that the current masked autoencoder models lack good generalization ability on graph data. To tackle this issue, we propose a novel graph masked autoencoder framework called GiGaMAE. Different from existing masked autoencoders that learn node presentations by explicitly reconstructing the original graph components (e.g., features or edges), in this paper, we propose to collaboratively reconstruct informative and integrated latent embeddings. By considering embeddings encompassing graph topology and attribute information as reconstruction targets, our model could capture more generalized and comprehensive knowledge. Furthermore, we introduce a mutual information based reconstruction loss that enables the effective reconstruction of multiple targets. This learning objective allows us to differentiate between the exclusive knowledge learned from a single target and common knowledge shared by multiple targets. We evaluate our method on three downstream tasks with seven datasets as benchmarks. Extensive experiments demonstrate the superiority of GiGaMAE against state-of-the-art baselines. We hope our results will shed light on the design of foundation models on graph-structured data. Our code is available at: https://github.com/sycny/GiGaMAE.
</details>
<details>
<summary>摘要</summary>
自我监督学习中使用遮盖自动编码器最近受到关注，因为它可以生成有效的图像或文本表示，可以应用于多个下游任务无需重新训练。然而，我们发现当前的遮盖自动编码器模型对图数据的泛化能力不佳。为解决这个问题，我们提出了一种新的图masked autoencoder框架，即GiGaMAE。与现有的遮盖自动编码器不同，我们在这篇论文中提议使用相互重建有用和完整的嵌入表示。我们考虑嵌入包括图型和属性信息作为重建目标，从而使我们的模型捕捉更加普遍和全面的知识。此外，我们引入了基于mutual information的重建损失，该损失函数允许我们有效地重建多个目标。这个学习目标使我们能够区分单个目标学习的独特知识和多个目标共享的通用知识。我们在三个下游任务上进行了七个数据集的测试，并对比了现有的基eline。广泛的实验结果表明GiGaMAE的超越性。我们希望我们的结果可以引导基于图结构数据的基础模型的设计。我们的代码可以在https://github.com/sycny/GiGaMAE中找到。
</details></li>
</ul>
<hr>
<h2 id="Tree-of-Mixed-Thought-Combining-Fast-and-Slow-Thinking-for-Multi-hop-Visual-Reasoning"><a href="#Tree-of-Mixed-Thought-Combining-Fast-and-Slow-Thinking-for-Multi-hop-Visual-Reasoning" class="headerlink" title="Tree-of-Mixed-Thought: Combining Fast and Slow Thinking for Multi-hop Visual Reasoning"></a>Tree-of-Mixed-Thought: Combining Fast and Slow Thinking for Multi-hop Visual Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09658">http://arxiv.org/abs/2308.09658</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pengbo Hu, Ji Qi, Xingyu Li, Hong Li, Xinqi Wang, Bing Quan, Ruiyu Wang, Yi Zhou</li>
<li>for: 本研究旨在提出一种基于大语言模型（LLM）的规划算法，以解决复杂的视觉逻辑问题中的计划搜索问题。</li>
<li>methods: 本研究使用了一种叫做“ Tree-of-thought”的方法，它是基于人类大脑的两种认知系统——快速思维和慢速思维——的结合体。此外，还使用了一种叫做“一站式搜索”的方法。</li>
<li>results: 研究表明，我们的提出的算法可以同时保证性能和效率的提高，并且在不同的逻辑问题中显示出优异的表现。此外，我们还开发了一个系统性的评估框架，以便评估 LLMs 基于计划搜索的性能和效率。<details>
<summary>Abstract</summary>
There emerges a promising trend of using large language models (LLMs) to generate code-like plans for complex inference tasks such as visual reasoning. This paradigm, known as LLM-based planning, provides flexibility in problem solving and endows better interpretability. However, current research is mostly limited to basic scenarios of simple questions that can be straightforward answered in a few inference steps. Planning for the more challenging multi-hop visual reasoning tasks remains under-explored. Specifically, under multi-hop reasoning situations, the trade-off between accuracy and the complexity of plan-searching becomes prominent. The prevailing algorithms either address the efficiency issue by employing the fast one-stop generation or adopt a complex iterative generation method to improve accuracy. Both fail to balance the need for efficiency and performance. Drawing inspiration from the dual system of cognition in the human brain, the fast and the slow think processes, we propose a hierarchical plan-searching algorithm that integrates the one-stop reasoning (fast) and the Tree-of-thought (slow). Our approach succeeds in performance while significantly saving inference steps. Moreover, we repurpose the PTR and the CLEVER datasets, developing a systematic framework for evaluating the performance and efficiency of LLMs-based plan-search algorithms under reasoning tasks at different levels of difficulty. Extensive experiments demonstrate the superiority of our proposed algorithm in terms of performance and efficiency. The dataset and code will be release soon.
</details>
<details>
<summary>摘要</summary>
出现了一种扩展大型语言模型（LLM）用于生成复杂推理任务的代码化计划的趋势，这种趋势被称为LLM-based planning。这种方法具有更多的问题解决方式和更好的可读性。然而，当前的研究主要集中在基本的单步问题上，尚未深入研究复杂的多步推理任务。在多步推理任务中，精度和计划搜索的复杂度之间存在明显的负担。目前的算法可以通过快速一站式生成或者使用迭代生成方法来提高精度，但都无法平衡精度和性能的需求。引用人类大脑中的双系统认知模型，我们提出了一种层次的计划搜索算法，将快速一站式推理（快）和树状思维（慢）相结合。我们的方法在性能和效率两个方面具有优势，并且对不同难度水平的推理任务进行系统性评估。我们对PTR和CLEVER数据集进行了修改和扩展，并开发了一个系统性的评估框架。广泛的实验表明，我们的提posed算法在性能和效率两个方面具有优势。数据集和代码将很快发布。
</details></li>
</ul>
<hr>
<h2 id="Robust-Uncertainty-Quantification-using-Conformalised-Monte-Carlo-Prediction"><a href="#Robust-Uncertainty-Quantification-using-Conformalised-Monte-Carlo-Prediction" class="headerlink" title="Robust Uncertainty Quantification using Conformalised Monte Carlo Prediction"></a>Robust Uncertainty Quantification using Conformalised Monte Carlo Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09647">http://arxiv.org/abs/2308.09647</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/team-daniel/mc-cp">https://github.com/team-daniel/mc-cp</a></li>
<li>paper_authors: Daniel Bethell, Simos Gerasimou, Radu Calinescu</li>
<li>for: 这篇论文主要用于推动深度学习模型在安全关键应用中的部署，并提供了一种可靠的评估方法来确保这些模型的可靠运行。</li>
<li>methods: 本论文提出了一种新的混合型不确定性评估方法（MC-CP），它将适应MC dropout方法和确定性预测（CP）相结合，以提高不确定性评估的精度和效率。</li>
<li>results: 经过广泛的实验评估，MC-CP方法在分类和回归benchmark中都达到了显著的改进，与先前的高级不确定性评估方法相比，如MC dropout、RAPS和CQR。MC-CP方法可以轻松地添加到现有的模型中，使其部署非常简单。<details>
<summary>Abstract</summary>
Deploying deep learning models in safety-critical applications remains a very challenging task, mandating the provision of assurances for the dependable operation of these models. Uncertainty quantification (UQ) methods estimate the model's confidence per prediction, informing decision-making by considering the effect of randomness and model misspecification. Despite the advances of state-of-the-art UQ methods, they are computationally expensive or produce conservative prediction sets/intervals. We introduce MC-CP, a novel hybrid UQ method that combines a new adaptive Monte Carlo (MC) dropout method with conformal prediction (CP). MC-CP adaptively modulates the traditional MC dropout at runtime to save memory and computation resources, enabling predictions to be consumed by CP, yielding robust prediction sets/intervals. Throughout comprehensive experiments, we show that MC-CP delivers significant improvements over advanced UQ methods, like MC dropout, RAPS and CQR, both in classification and regression benchmarks. MC-CP can be easily added to existing models, making its deployment simple.
</details>
<details>
<summary>摘要</summary>
部署深度学习模型在安全关键应用中仍然是一个非常困难的任务，需要提供保证模型的可靠运行。不确定量评估（UQ）方法可以估计模型每个预测结果的可信度，并且在考虑Randomness和模型错误的情况下，对决策进行指导。despite state-of-the-art UQ methods have made significant advances, they are still computationally expensive or produce conservative prediction sets/intervals.我们介绍MC-CP，一种新的hybrid UQ方法， combining a new adaptive Monte Carlo (MC) dropout method with conformal prediction (CP). MC-CP可以在运行时适应MC dropout的传统方法，以节省内存和计算资源，使得预测结果可以被CP进行处理，并且生成Robust预测集/interval。经过了广泛的实验，我们发现MC-CP可以在分类和回归 benchmark上提供显著改进，比如MC dropout、RAPS和CQR。MC-CP可以轻松地添加到现有模型中，因此其部署非常简单。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/19/cs.AI_2023_08_19/" data-id="clogyj8v2002j7cra5ssa312i" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_08_19" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/19/cs.CL_2023_08_19/" class="article-date">
  <time datetime="2023-08-19T11:00:00.000Z" itemprop="datePublished">2023-08-19</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/19/cs.CL_2023_08_19/">cs.CL - 2023-08-19</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="An-Empirical-Study-of-CLIP-for-Text-based-Person-Search"><a href="#An-Empirical-Study-of-CLIP-for-Text-based-Person-Search" class="headerlink" title="An Empirical Study of CLIP for Text-based Person Search"></a>An Empirical Study of CLIP for Text-based Person Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10045">http://arxiv.org/abs/2308.10045</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/flame-chasers/tbps-clip">https://github.com/flame-chasers/tbps-clip</a></li>
<li>paper_authors: Min Cao, Yang Bai, Ziyin Zeng, Mang Ye, Min Zhang<br>for: This paper aims to explore the potential of the visual-language pre-training model CLIP for downstream Text-Based Person Search (TBPS) tasks.methods: The paper conducts a comprehensive empirical study of CLIP for TBPS, including revisiting critical design considerations such as data augmentation and loss function, and implementing practical training tricks.results: The model achieves satisfactory performance without any sophisticated modules, and the probing experiments demonstrate the effectiveness of TBPS-CLIP from various aspects, providing empirical insights and highlighting future research directions.Here’s the simplified Chinese text:for: 这篇论文想要探索CLIP视觉语言预训模型在下游文本人像检索任务上的潜力。methods: 论文通过对CLIP进行全面的实验研究，包括重新评估关键设计因素，如数据增强和损失函数，以及实施实用的训练技巧。results: 模型无需任何复杂模块就可以达到满意性的性能，并通过 probing 实验表明TBPS-CLIP在多个方面的效果，提供了实证意义和未来研究方向。<details>
<summary>Abstract</summary>
Text-based Person Search (TBPS) aims to retrieve the person images using natural language descriptions. Recently, Contrastive Language Image Pretraining (CLIP), a universal large cross-modal vision-language pre-training model, has remarkably performed over various cross-modal downstream tasks due to its powerful cross-modal semantic learning capacity. TPBS, as a fine-grained cross-modal retrieval task, is also facing the rise of research on the CLIP-based TBPS. In order to explore the potential of the visual-language pre-training model for downstream TBPS tasks, this paper makes the first attempt to conduct a comprehensive empirical study of CLIP for TBPS and thus contribute a straightforward, incremental, yet strong TBPS-CLIP baseline to the TBPS community. We revisit critical design considerations under CLIP, including data augmentation and loss function. The model, with the aforementioned designs and practical training tricks, can attain satisfactory performance without any sophisticated modules. Also, we conduct the probing experiments of TBPS-CLIP in model generalization and model compression, demonstrating the effectiveness of TBPS-CLIP from various aspects. This work is expected to provide empirical insights and highlight future CLIP-based TBPS research.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="GameEval-Evaluating-LLMs-on-Conversational-Games"><a href="#GameEval-Evaluating-LLMs-on-Conversational-Games" class="headerlink" title="GameEval: Evaluating LLMs on Conversational Games"></a>GameEval: Evaluating LLMs on Conversational Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10032">http://arxiv.org/abs/2308.10032</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dan Qiao, Chenfei Wu, Yaobo Liang, Juntao Li, Nan Duan</li>
<li>for: This paper aims to evaluate large language models (LLMs) through goal-driven conversational games, addressing the limitations of existing evaluation methods.</li>
<li>methods: The proposed approach, called GameEval, treats LLMs as game players and assigns them distinct roles with specific goals achieved through conversations of various forms, such as discussion, question answering, and voting.</li>
<li>results: Extensive experiments show that GameEval can effectively differentiate the capabilities of various LLMs, providing a comprehensive assessment of their integrated abilities to solve complex problems.Here are the three points in Simplified Chinese:</li>
<li>for: 这篇论文目标是通过对话游戏来评估大语言模型（LLM），超越现有评估方法的限制。</li>
<li>methods: 提议的方法是通过将 LLM 当作游戏玩家，赋予它们特定的目标，通过不同的对话形式，如讨论、问答和投票，来评估模型的能力。</li>
<li>results: 广泛的实验表明，GameEval 可以有效地区分不同的 LLM 的能力，为复杂问题的解决提供全面的评估。<details>
<summary>Abstract</summary>
The rapid advancements in large language models (LLMs) have presented challenges in evaluating those models. Existing evaluation methods are either reference-based or preference based, which inevitably need human intervention or introduce test bias caused by evaluator models. In this paper, we propose GameEval, a novel approach to evaluating LLMs through goal-driven conversational games, overcoming the limitations of previous methods. GameEval treats LLMs as game players and assigns them distinct roles with specific goals achieved by launching conversations of various forms, including discussion, question answering, and voting. We design three unique games with cooperative or adversarial objectives, accompanied by corresponding evaluation metrics, to show how this new paradigm comprehensively evaluates model performance.Through extensive experiments, we show that GameEval can effectively differentiate the capabilities of various LLMs, providing a comprehensive assessment of their integrated abilities to solve complex problems. Our public anonymous code is available at https://github.com/GameEval/GameEval.
</details>
<details>
<summary>摘要</summary>
快速发展的大语言模型（LLM）带来了评估这些模型的挑战。现有的评估方法都是基于参考或偏好基础的，因此需要人工干预或引入评估器模型的测试偏见。本文提出了一种新的评估方法——GameEval，通过对LML进行目标驱动的对话游戏来评估其表现。GameEval将LML当作游戏玩家，赋予它们不同的角色和目标，通过发起不同的对话形式，包括讨论、问答和投票，来评估其能力解决复杂问题。我们设计了三个独特的游戏，每个游戏都有合作或对抗目标，并附带了相应的评估指标。我们通过广泛的实验表明，GameEval可以有效地区分不同的LML表现，提供全面评估这些模型的复杂问题解决能力。我们的公共匿名代码可以在https://github.com/GameEval/GameEval上下载。
</details></li>
</ul>
<hr>
<h2 id="ControlRetriever-Harnessing-the-Power-of-Instructions-for-Controllable-Retrieval"><a href="#ControlRetriever-Harnessing-the-Power-of-Instructions-for-Controllable-Retrieval" class="headerlink" title="ControlRetriever: Harnessing the Power of Instructions for Controllable Retrieval"></a>ControlRetriever: Harnessing the Power of Instructions for Controllable Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10025">http://arxiv.org/abs/2308.10025</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaihang Pan, Juncheng Li, Hongye Song, Hao Fei, Wei Ji, Shuo Zhang, Jun Lin, Xiaozhong Liu, Siliang Tang</li>
<li>for: 这个研究的目的是提高 dense retrieval 模型在多元搜寻任务中的表现，并且可以让模型适应不同的搜寻意图。</li>
<li>methods: 这个研究使用了 ControlRetriever，一个可以控制 dense retrieval 模型的方法，并且使用了 ControlNet 的基础，将不同的搜寻模型融合到一个整体系统中，并且使用了一个新的 LLM 导向的指令生成和迭代训练策略，将 ControlRetriever 训练成可以适应不同的搜寻任务。</li>
<li>results: 实验结果显示，在 BEIR 评量标准中，ControlRetriever 可以在不需要任务特定调整的情况下，与基eline方法相比，获得了明显的改善，并且在零基eline情况下也实现了州际级的表现。<details>
<summary>Abstract</summary>
Recent studies have shown that dense retrieval models, lacking dedicated training data, struggle to perform well across diverse retrieval tasks, as different retrieval tasks often entail distinct search intents. To address this challenge, in this work we introduce ControlRetriever, a generic and efficient approach with a parameter isolated architecture, capable of controlling dense retrieval models to directly perform varied retrieval tasks, harnessing the power of instructions that explicitly describe retrieval intents in natural language. Leveraging the foundation of ControlNet, which has proven powerful in text-to-image generation, ControlRetriever imbues different retrieval models with the new capacity of controllable retrieval, all while being guided by task-specific instructions. Furthermore, we propose a novel LLM guided Instruction Synthesizing and Iterative Training strategy, which iteratively tunes ControlRetriever based on extensive automatically-generated retrieval data with diverse instructions by capitalizing the advancement of large language models. Extensive experiments show that in the BEIR benchmark, with only natural language descriptions of specific retrieval intent for each task, ControlRetriever, as a unified multi-task retrieval system without task-specific tuning, significantly outperforms baseline methods designed with task-specific retrievers and also achieves state-of-the-art zero-shot performance.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese: latest studies have shown that dense retrieval models, lacking dedicated training data, struggle to perform well across diverse retrieval tasks, as different retrieval tasks often entail distinct search intents. To address this challenge, in this work we introduce ControlRetriever, a generic and efficient approach with a parameter isolated architecture, capable of controlling dense retrieval models to directly perform varied retrieval tasks, harnessing the power of instructions that explicitly describe retrieval intents in natural language. Building on the foundation of ControlNet, which has proven powerful in text-to-image generation, ControlRetriever imbues different retrieval models with the new capacity of controllable retrieval, all while being guided by task-specific instructions. Furthermore, we propose a novel LLM guided Instruction Synthesizing and Iterative Training strategy, which iteratively tunes ControlRetriever based on extensive automatically-generated retrieval data with diverse instructions by capitalizing the advancement of large language models. Extensive experiments show that in the BEIR benchmark, with only natural language descriptions of specific retrieval intent for each task, ControlRetriever, as a unified multi-task retrieval system without task-specific tuning, significantly outperforms baseline methods designed with task-specific retrievers and also achieves state-of-the-art zero-shot performance.
</details></li>
</ul>
<hr>
<h2 id="HICL-Hashtag-Driven-In-Context-Learning-for-Social-Media-Natural-Language-Understanding"><a href="#HICL-Hashtag-Driven-In-Context-Learning-for-Social-Media-Natural-Language-Understanding" class="headerlink" title="HICL: Hashtag-Driven In-Context Learning for Social Media Natural Language Understanding"></a>HICL: Hashtag-Driven In-Context Learning for Social Media Natural Language Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09985">http://arxiv.org/abs/2308.09985</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/albertan017/hicl">https://github.com/albertan017/hicl</a></li>
<li>paper_authors: Hanzhuo Tan, Chunpu Xu, Jing Li, Yuqun Zhang, Zeyang Fang, Zeyu Chen, Baohua Lai</li>
<li>for:  addresses the issue of compromised performance in existing natural language understanding (NLU) models when faced with short and noisy social media content.</li>
<li>methods:  leverages in-context learning (ICL) and a novel hashtag-driven in-context learning (HICL) framework, which pre-trains a model #Encoder using hashtags to drive BERT-based pre-training through contrastive learning, and employs a gradient-based method to identify trigger terms useful in fusing information from both sources.</li>
<li>results:  substantially advances the previous state-of-the-art results on seven downstream tasks, and found that combining source input with a top-retrieved post from #Encoder is more effective than using semantically similar posts, and trigger words can largely benefit in merging context from the source and retrieved posts.Here is the answer in Simplified Chinese text:</li>
<li>for: 解决现有的自然语言理解（NLU）模型在面对短暴露的社交媒体内容时表现不佳的问题。</li>
<li>methods: 利用启发式学习（ICL）和一种带有标签驱动的启发式学习（HICL）框架，通过使用标签驱动BERT预训练的 pré-training，并使用梯度法来确定权重用于将来源和检索出的帖子内容融合。</li>
<li>results: substantially advance了之前的状态值表现结果，并发现将源输入与 #Encoder 预测的top-retrieved帖子融合是比使用相似的帖子更有效的。<details>
<summary>Abstract</summary>
Natural language understanding (NLU) is integral to various social media applications. However, existing NLU models rely heavily on context for semantic learning, resulting in compromised performance when faced with short and noisy social media content. To address this issue, we leverage in-context learning (ICL), wherein language models learn to make inferences by conditioning on a handful of demonstrations to enrich the context and propose a novel hashtag-driven in-context learning (HICL) framework. Concretely, we pre-train a model #Encoder, which employs #hashtags (user-annotated topic labels) to drive BERT-based pre-training through contrastive learning. Our objective here is to enable #Encoder to gain the ability to incorporate topic-related semantic information, which allows it to retrieve topic-related posts to enrich contexts and enhance social media NLU with noisy contexts. To further integrate the retrieved context with the source text, we employ a gradient-based method to identify trigger terms useful in fusing information from both sources. For empirical studies, we collected 45M tweets to set up an in-context NLU benchmark, and the experimental results on seven downstream tasks show that HICL substantially advances the previous state-of-the-art results. Furthermore, we conducted extensive analyzes and found that: (1) combining source input with a top-retrieved post from #Encoder is more effective than using semantically similar posts; (2) trigger words can largely benefit in merging context from the source and retrieved posts.
</details>
<details>
<summary>摘要</summary>
natural language understanding (NLU) 是社交媒体应用程序中的一个重要组成部分。然而，现有的 NLU 模型很重要地依赖于上下文进行 semantic learning，这会导致它们在短 и噪音的社交媒体内容上表现不佳。为解决这个问题，我们利用 in-context learning (ICL)，其中语言模型通过使用一些示例来增强上下文，并提出了一个具有 hash 标签驱动的增Context learning (HICL) 框架。具体来说，我们首先预训 #Encoder，该模型使用 #hash 标签（用户标注的主题标签）来驱动 BERT 基于的预训练。我们的目标是让 #Encoder 能够integrate topic-related semantic information，以便从 retrieve 的上下文中提取相关信息，并在社交媒体 NLU 中增强噪音上下文的表现。此外，我们还使用 Gradient 基本方法来确定激活词，以便将源文本和检索到的上下文 fusion 到一起。为 empirical studies，我们收集了 45 万条 tweet，并设置了一个 in-context NLU benchmark。实验结果显示，HICL 在七个下游任务上substantially advance 了之前的状态的术。此外，我们还进行了广泛的分析，发现：(1) 将源输入与检索到的最佳帖子 fusion 是更有效的 чем使用相似的帖子;(2) 触发词可以很大程度地帮助合并来源和检索到的上下文。
</details></li>
</ul>
<hr>
<h2 id="FinEval-A-Chinese-Financial-Domain-Knowledge-Evaluation-Benchmark-for-Large-Language-Models"><a href="#FinEval-A-Chinese-Financial-Domain-Knowledge-Evaluation-Benchmark-for-Large-Language-Models" class="headerlink" title="FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models"></a>FinEval: A Chinese Financial Domain Knowledge Evaluation Benchmark for Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09975">http://arxiv.org/abs/2308.09975</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sufe-aiflm-lab/fineval">https://github.com/sufe-aiflm-lab/fineval</a></li>
<li>paper_authors: Liwen Zhang, Weige Cai, Zhaowei Liu, Zhi Yang, Wei Dai, Yujie Liao, Qianru Qin, Yifei Li, Xingyu Liu, Zhiqiang Liu, Zhoufan Zhu, Anbo Wu, Xin Guo, Yun Chen</li>
<li>for: 本研究旨在评估大语言模型（LLMs）在金融领域知识上的表现，并提供一个特性rich的评估 benchmark。</li>
<li>methods: 本研究使用了多种提问类型，包括零shot、几shot、答案只、链式思维等，以评估state-of-the-art的中文和英文 LLMS 在金融领域知识上的表现。</li>
<li>results: 结果显示，只有 GPT-4 在不同的提问设置下达到了接近 70% 的准确率，表明 LLMS 在金融领域知识上的可能性很大。<details>
<summary>Abstract</summary>
Large language models (LLMs) have demonstrated exceptional performance in various natural language processing tasks, yet their efficacy in more challenging and domain-specific tasks remains largely unexplored. This paper presents FinEval, a benchmark specifically designed for the financial domain knowledge in the LLMs. FinEval is a collection of high-quality multiple-choice questions covering Finance, Economy, Accounting, and Certificate. It includes 4,661 questions spanning 34 different academic subjects. To ensure a comprehensive model performance evaluation, FinEval employs a range of prompt types, including zero-shot and few-shot prompts, as well as answer-only and chain-of-thought prompts. Evaluating state-of-the-art Chinese and English LLMs on FinEval, the results show that only GPT-4 achieved an accuracy close to 70% in different prompt settings, indicating significant growth potential for LLMs in the financial domain knowledge. Our work offers a more comprehensive financial knowledge evaluation benchmark, utilizing data of mock exams and covering a wide range of evaluated LLMs.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLMs）已经在各种自然语言处理任务中显示出了卓越表现，然而它们在更加具有挑战性和领域特有性的任务中的表现仍然尚未得到了充分的探索。这篇论文提出了FinEval，一个专门为金融领域知识的benchmark。FinEval包括4,661个高质量多选问题，涵盖了财务、经济、会计和证书等34个学科。为了全面评估模型的表现，FinEval使用了多种提问类型，包括零shot和几shot提问、以及答案只提问和链式思维提问。对现有的中文和英文LLMs进行FinEval的评估，结果显示，只有GPT-4在不同的提问设置中达到了近70%的准确率，这表明LLMs在金融领域知识方面还有很大的成长 potential。我们的工作提供了一个更加全面的金融知识评估benchmark，利用了考试数据和覆盖了各种评估LLMs。
</details></li>
</ul>
<hr>
<h2 id="Utilizing-Semantic-Textual-Similarity-for-Clinical-Survey-Data-Feature-Selection"><a href="#Utilizing-Semantic-Textual-Similarity-for-Clinical-Survey-Data-Feature-Selection" class="headerlink" title="Utilizing Semantic Textual Similarity for Clinical Survey Data Feature Selection"></a>Utilizing Semantic Textual Similarity for Clinical Survey Data Feature Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09892">http://arxiv.org/abs/2308.09892</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bcwarner/sts-select">https://github.com/bcwarner/sts-select</a></li>
<li>paper_authors: Benjamin C. Warner, Ziqi Xu, Simon Haroutounian, Thomas Kannampallil, Chenyang Lu</li>
<li>for: 这篇论文是为了解决问题，即使 survey data 具有较高的特征数量且较低的例子数量， machine learning 模型还是能够预测结果的问题。</li>
<li>methods: 这篇论文使用了 feature selection 来解决这个问题，特别是使用 textual names of features 来评估哪些特征是有用的。</li>
<li>results: 研究发现，使用 STS 来选择特征可以实现更高的性能模型，比较传统的特征选择算法。<details>
<summary>Abstract</summary>
Survey data can contain a high number of features while having a comparatively low quantity of examples. Machine learning models that attempt to predict outcomes from survey data under these conditions can overfit and result in poor generalizability. One remedy to this issue is feature selection, which attempts to select an optimal subset of features to learn upon. A relatively unexplored source of information in the feature selection process is the usage of textual names of features, which may be semantically indicative of which features are relevant to a target outcome. The relationships between feature names and target names can be evaluated using language models (LMs) to produce semantic textual similarity (STS) scores, which can then be used to select features. We examine the performance using STS to select features directly and in the minimal-redundancy-maximal-relevance (mRMR) algorithm. The performance of STS as a feature selection metric is evaluated against preliminary survey data collected as a part of a clinical study on persistent post-surgical pain (PPSP). The results suggest that features selected with STS can result in higher performance models compared to traditional feature selection algorithms.
</details>
<details>
<summary>摘要</summary>
Survey data often contains a large number of features but only a small number of examples. If machine learning models are used to predict outcomes from this data, they may overfit and have poor generalizability. One solution to this problem is feature selection, which involves selecting a subset of the most relevant features to learn from. A previously unexplored source of information in the feature selection process is the textual names of the features, which may be semantically indicative of which features are relevant to the target outcome. We can use language models (LMs) to evaluate the relationships between feature names and target names and produce semantic textual similarity (STS) scores. These scores can then be used to select features. We compare the performance of STS as a feature selection metric with traditional feature selection algorithms using preliminary survey data collected as part of a clinical study on persistent post-surgical pain (PPSP). The results suggest that features selected with STS can lead to higher performance models.
</details></li>
</ul>
<hr>
<h2 id="Breaking-Language-Barriers-A-Question-Answering-Dataset-for-Hindi-and-Marathi"><a href="#Breaking-Language-Barriers-A-Question-Answering-Dataset-for-Hindi-and-Marathi" class="headerlink" title="Breaking Language Barriers: A Question Answering Dataset for Hindi and Marathi"></a>Breaking Language Barriers: A Question Answering Dataset for Hindi and Marathi</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09862">http://arxiv.org/abs/2308.09862</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maithili Sabane, Onkar Litake, Aman Chadha</li>
<li>for: developing a Question Answering dataset for low-resource languages Hindi and Marathi</li>
<li>methods: novel approach for translating the SQuAD 2.0 dataset into Hindi and Marathi</li>
<li>results: release the largest Question-Answering dataset available for these languages, with each dataset containing 28,000 samples, and the best-performing models for both Hindi and MarathiHere’s the simplified Chinese text for the three key points:</li>
<li>for: 为低资源语言� Hinidi 和 Marathi 开发问答集</li>
<li>methods: 使用 novel Approach 将 SQuAD 2.0 集 перевод成 Hinidi 和 Marathi</li>
<li>results: 发布了最大的问答集，每个集 contain 28,000 个样本，并且在两种语言上提供了最佳性能的模型<details>
<summary>Abstract</summary>
The recent advances in deep-learning have led to the development of highly sophisticated systems with an unquenchable appetite for data. On the other hand, building good deep-learning models for low-resource languages remains a challenging task. This paper focuses on developing a Question Answering dataset for two such languages- Hindi and Marathi. Despite Hindi being the 3rd most spoken language worldwide, with 345 million speakers, and Marathi being the 11th most spoken language globally, with 83.2 million speakers, both languages face limited resources for building efficient Question Answering systems. To tackle the challenge of data scarcity, we have developed a novel approach for translating the SQuAD 2.0 dataset into Hindi and Marathi. We release the largest Question-Answering dataset available for these languages, with each dataset containing 28,000 samples. We evaluate the dataset on various architectures and release the best-performing models for both Hindi and Marathi, which will facilitate further research in these languages. Leveraging similarity tools, our method holds the potential to create datasets in diverse languages, thereby enhancing the understanding of natural language across varied linguistic contexts. Our fine-tuned models, code, and dataset will be made publicly available.
</details>
<details>
<summary>摘要</summary>
Recent advances in deep learning have led to the development of highly sophisticated systems with an insatiable appetite for data. However, building good deep learning models for low-resource languages remains a challenging task. This paper focuses on developing a Question Answering dataset for two such languages - Hindi and Marathi. Despite Hindi being the third most spoken language worldwide with 345 million speakers and Marathi being the 11th most spoken language globally with 83.2 million speakers, both languages face limited resources for building efficient Question Answering systems. To address the challenge of data scarcity, we have developed a novel approach for translating the SQuAD 2.0 dataset into Hindi and Marathi. We release the largest Question-Answering dataset available for these languages, with each dataset containing 28,000 samples. We evaluate the dataset on various architectures and release the best-performing models for both Hindi and Marathi, which will facilitate further research in these languages. Our method leverages similarity tools, which has the potential to create datasets in diverse languages, thereby enhancing the understanding of natural language across varied linguistic contexts. Our fine-tuned models, code, and dataset will be made publicly available.
</details></li>
</ul>
<hr>
<h2 id="Black-box-Adversarial-Attacks-against-Dense-Retrieval-Models-A-Multi-view-Contrastive-Learning-Method"><a href="#Black-box-Adversarial-Attacks-against-Dense-Retrieval-Models-A-Multi-view-Contrastive-Learning-Method" class="headerlink" title="Black-box Adversarial Attacks against Dense Retrieval Models: A Multi-view Contrastive Learning Method"></a>Black-box Adversarial Attacks against Dense Retrieval Models: A Multi-view Contrastive Learning Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09861">http://arxiv.org/abs/2308.09861</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu-An Liu, Ruqing Zhang, Jiafeng Guo, Maarten de Rijke, Wei Chen, Yixing Fan, Xueqi Cheng</li>
<li>for: 本研究主要针对于 dense retrieval (DR) 模型的 Robustness 问题。</li>
<li>methods: 本研究使用了现有的 adversarial attack 方法，并提出了一种基于 contrastive learning 的新方法来攻击 DR 模型。</li>
<li>results: 实验结果显示，新方法可以对 DR 模型进行有效的攻击，并且可以使用小量文本干扰来诱导模型返回错误结果。<details>
<summary>Abstract</summary>
Neural ranking models (NRMs) and dense retrieval (DR) models have given rise to substantial improvements in overall retrieval performance. In addition to their effectiveness, and motivated by the proven lack of robustness of deep learning-based approaches in other areas, there is growing interest in the robustness of deep learning-based approaches to the core retrieval problem. Adversarial attack methods that have so far been developed mainly focus on attacking NRMs, with very little attention being paid to the robustness of DR models. In this paper, we introduce the adversarial retrieval attack (AREA) task. The AREA task is meant to trick DR models into retrieving a target document that is outside the initial set of candidate documents retrieved by the DR model in response to a query. We consider the decision-based black-box adversarial setting, which is realistic in real-world search engines. To address the AREA task, we first employ existing adversarial attack methods designed for NRMs. We find that the promising results that have previously been reported on attacking NRMs, do not generalize to DR models: these methods underperform a simple term spamming method. We attribute the observed lack of generalizability to the interaction-focused architecture of NRMs, which emphasizes fine-grained relevance matching. DR models follow a different representation-focused architecture that prioritizes coarse-grained representations. We propose to formalize attacks on DR models as a contrastive learning problem in a multi-view representation space. The core idea is to encourage the consistency between each view representation of the target document and its corresponding viewer via view-wise supervision signals. Experimental results demonstrate that the proposed method can significantly outperform existing attack strategies in misleading the DR model with small indiscernible text perturbations.
</details>
<details>
<summary>摘要</summary>
神经排名模型（NRM）和紧凑检索（DR）模型已经导致总体检索性能得到了重大改善。此外，由于深度学习基本概念的不稳定性在其他领域已经证明了其不足，因此对深度学习基本概念的检索问题的Robustness也有增加的兴趣。许多攻击方法主要target NRMs，DR模型几乎没有受到关注。在本文中，我们介绍了抗击式检索任务（AREA）。AREA任务的目标是让DR模型返回一个不在初始候选文档中的目标文档。我们使用现有的NRMs攻击方法，并发现这些方法在DR模型上的表现不如预期差。我们归因这种不一致性于NRMs的交互强调的架构，DR模型采用了一种强调媒体表示的架构。我们提出了一种对DR模型进行攻击的方法，定义为多视图表示空间中的对比学习问题。核心思想是在每个视图中supervise the viewer's representation of the target document and its corresponding viewer via view-wise supervision signals。实验结果表明，我们的方法可以在小型文本干扰下明显超越现有攻击策略。
</details></li>
</ul>
<hr>
<h2 id="How-susceptible-are-LLMs-to-Logical-Fallacies"><a href="#How-susceptible-are-LLMs-to-Logical-Fallacies" class="headerlink" title="How susceptible are LLMs to Logical Fallacies?"></a>How susceptible are LLMs to Logical Fallacies?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09853">http://arxiv.org/abs/2308.09853</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Amir-pyh/LOGICOM">https://github.com/Amir-pyh/LOGICOM</a></li>
<li>paper_authors: Amirreza Payandeh, Dan Pluth, Jordan Hosier, Xuesu Xiao, Vijay K. Gurbani</li>
<li>for: 本研究探讨了大型自然语言模型（LLM）在多轮辩论中的合理思维能力，特别是对逻辑错误的影响。</li>
<li>methods: 本研究使用了Logic Competence Measurement Benchmark（LOGICOM），一个用于评估LLM在逻辑错误下的逻辑理解能力的诊断标准。LOGICOM包括两个代理：一个诱导者和一个辩者，在一个争议性主题上进行多轮辩论，诱导者尝试使辩者接受其主张的正确性。</li>
<li>results: 研究发现，LLM可以通过理解来修改其意见。但是，当面临逻辑错误时，GPT-3.5和GPT-4分别被误导41%和69%更多次，相比于逻辑理解时。此外，本研究还提供了一个包含逻辑vs. 逻辑错误的5k+对话的新数据集，并公开发布了源代码和数据集。<details>
<summary>Abstract</summary>
This paper investigates the rational thinking capability of Large Language Models (LLMs) in multi-round argumentative debates by exploring the impact of fallacious arguments on their logical reasoning performance. More specifically, we present Logic Competence Measurement Benchmark (LOGICOM), a diagnostic benchmark to assess the robustness of LLMs against logical fallacies. LOGICOM involves two agents: a persuader and a debater engaging in a multi-round debate on a controversial topic, where the persuader tries to convince the debater of the correctness of its claim. First, LOGICOM assesses the potential of LLMs to change their opinions through reasoning. Then, it evaluates the debater's performance in logical reasoning by contrasting the scenario where the persuader employs logical fallacies against one where logical reasoning is used. We use this benchmark to evaluate the performance of GPT-3.5 and GPT-4 using a dataset containing controversial topics, claims, and reasons supporting them. Our findings indicate that both GPT-3.5 and GPT-4 can adjust their opinion through reasoning. However, when presented with logical fallacies, GPT-3.5 and GPT-4 are erroneously convinced 41% and 69% more often, respectively, compared to when logical reasoning is used. Finally, we introduce a new dataset containing over 5k pairs of logical vs. fallacious arguments. The source code and dataset of this work are made publicly available.
</details>
<details>
<summary>摘要</summary>
We use this benchmark to evaluate the performance of GPT-3.5 and GPT-4, two popular LLMs, using a dataset of controversial topics, claims, and reasons supporting them. Our findings show that both GPT-3.5 and GPT-4 can adjust their opinions through reasoning, but when presented with logical fallacies, they are erroneously convinced 41% and 69% more often, respectively, compared to when logical reasoning is used.To further evaluate the ability of LLMs to distinguish between logical and fallacious arguments, we have created a new dataset containing over 5,000 pairs of logical vs. fallacious arguments. This dataset is publicly available, along with the source code for our benchmark. Our results have important implications for the development of LLMs and their use in real-world applications where logical reasoning is critical.
</details></li>
</ul>
<hr>
<h2 id="Towards-Grounded-Visual-Spatial-Reasoning-in-Multi-Modal-Vision-Language-Models"><a href="#Towards-Grounded-Visual-Spatial-Reasoning-in-Multi-Modal-Vision-Language-Models" class="headerlink" title="Towards Grounded Visual Spatial Reasoning in Multi-Modal Vision Language Models"></a>Towards Grounded Visual Spatial Reasoning in Multi-Modal Vision Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09778">http://arxiv.org/abs/2308.09778</a></li>
<li>repo_url: None</li>
<li>paper_authors: Navid Rajabi, Jana Kosecka</li>
<li>for: 这个研究是用来评估大规模视力语言模型（VLM）在不同的视觉理解任务中表现的，特别是在理解空间关系方面。</li>
<li>methods: 这个研究使用了细化的组合基础grounding技术来评估视觉关系理解任务的性能，并提出了底层方法来排序空间句子并评估模型的表现。</li>
<li>results: 研究发现，现有的视力语言模型在理解空间关系方面表现不佳，有较大的差距和人类表现。而提出的方法可以减少这个差距，并提高模型的表现。<details>
<summary>Abstract</summary>
With the advances in large scale vision-and-language models (VLMs) it is of interest to assess their performance on various visual reasoning tasks such as counting, referring expressions and general visual question answering. The focus of this work is to study the ability of these models to understanding spatial relations. Previously, this has been tackled using image-text matching (Liu, Emerson, and Collier 2022) or visual question answering task, both showing poor performance and a large gap compared to human performance. To better understand the gap, we present fine-grained compositional grounding of spatial relationships and propose a bottom up approach for ranking spatial clauses and evaluating the performance of spatial relationship reasoning task. We propose to combine the evidence from grounding noun phrases corresponding to objects and their locations to compute the final rank of the spatial clause. We demonstrate the approach on representative vision-language models (Tan and Bansal 2019; Gupta et al. 2022; Kamath et al. 2021) and compare and highlight their abilities to reason about spatial relationships.
</details>
<details>
<summary>摘要</summary>
随着大规模视言语模型（VLM）的发展，有兴趣测试它们在不同的视觉逻辑任务中的表现，如计数、引用表达和通用的视觉问答。本工作的重点是研究这些模型在理解空间关系方面的能力。在过去，这些任务通常通过图像文本匹配（Liu、Emerson、Collier 2022）或视觉问答任务进行评估，两者都显示了较差的表现和人类表现之间的大差。为更好地了解这个差距，我们提出了细化的 composer grounding 技术和底层方法来评估空间关系逻辑任务的表现。我们建议将对象和其位置的描述语Fragment（noun phrase）grounding 结果相加以计算最终的空间句排名。我们在代表性的视觉语言模型（Tan和Bansal 2019；Gupta等 2022；Kamath等 2021）上进行了示例实现，并对它们的空间关系逻辑能力进行了比较和强调。
</details></li>
</ul>
<hr>
<h2 id="YORC-Yoruba-Reading-Comprehension-dataset"><a href="#YORC-Yoruba-Reading-Comprehension-dataset" class="headerlink" title="YORC: Yoruba Reading Comprehension dataset"></a>YORC: Yoruba Reading Comprehension dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09768">http://arxiv.org/abs/2308.09768</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anuoluwapo Aremu, Jesujoba O. Alabi, David Ifeoluwa Adelani</li>
<li>for: 这个论文创建了一个新的多选式 йоруба阅读理解数据集，基于 йоруба高中阅读理解考试。</li>
<li>methods: 该论文使用了已有的英文 RACE 数据集进行交叉语言传递，并使用预训练 encoder-only 模型获得基准结果。此外，还使用了大型自然语言模型（LLMs）如 GPT-4 进行推荐。</li>
<li>results: 该论文提供了基准结果和使用 LLMs 的结果。<details>
<summary>Abstract</summary>
In this paper, we create YORC: a new multi-choice Yoruba Reading Comprehension dataset that is based on Yoruba high-school reading comprehension examination. We provide baseline results by performing cross-lingual transfer using existing English RACE dataset based on a pre-trained encoder-only model. Additionally, we provide results by prompting large language models (LLMs) like GPT-4.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们创建了YORC：一个新的多选 йору巴读写理解数据集，该数据集基于 йору巴高中读写理解考试。我们提供了基线结果，使用现有的英语RACE数据集进行cross-lingual转移，并使用预训练的encoder-only模型。此外，我们还提供了使用大语言模型（LLMs）如GPT-4的结果。
</details></li>
</ul>
<hr>
<h2 id="OCR-Language-Models-with-Custom-Vocabularies"><a href="#OCR-Language-Models-with-Custom-Vocabularies" class="headerlink" title="OCR Language Models with Custom Vocabularies"></a>OCR Language Models with Custom Vocabularies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09671">http://arxiv.org/abs/2308.09671</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Garst, Reeve Ingle, Yasuhisa Fujii</li>
<li>for: 提高特殊领域文档识别率</li>
<li>methods: 生成领域特定词语模型，附加到通用语模型上，并使用修改后的CTC搜索解码器</li>
<li>results: 降低特殊领域文档词语错误率<details>
<summary>Abstract</summary>
Language models are useful adjuncts to optical models for producing accurate optical character recognition (OCR) results. One factor which limits the power of language models in this context is the existence of many specialized domains with language statistics very different from those implied by a general language model - think of checks, medical prescriptions, and many other specialized document classes. This paper introduces an algorithm for efficiently generating and attaching a domain specific word based language model at run time to a general language model in an OCR system. In order to best use this model the paper also introduces a modified CTC beam search decoder which effectively allows hypotheses to remain in contention based on possible future completion of vocabulary words. The result is a substantial reduction in word error rate in recognizing material from specialized domains.
</details>
<details>
<summary>摘要</summary>
语言模型是Optical Character Recognition（OCR）结果的有用辅助工具。一个限制语言模型在这种情况下的力量是存在许多特殊领域的语言统计数据与一般语言模型所假设的语言统计数据异常不同 - 想象检查、医疗订单等多种专业文档类型。本文提出了一种方法，可以在运行时效率地生成并附加专业领域词汇基于语言模型。为了最好地使用这种模型，本文还提出了一种修改后的CTC搜索解码器，可以让假设中的词语在未来完成的可能性下保持在竞争中。这导致了特殊领域中word error rate的显著减少。
</details></li>
</ul>
<hr>
<h2 id="Red-Teaming-Large-Language-Models-using-Chain-of-Utterances-for-Safety-Alignment"><a href="#Red-Teaming-Large-Language-Models-using-Chain-of-Utterances-for-Safety-Alignment" class="headerlink" title="Red-Teaming Large Language Models using Chain of Utterances for Safety-Alignment"></a>Red-Teaming Large Language Models using Chain of Utterances for Safety-Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09662">http://arxiv.org/abs/2308.09662</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/declare-lab/red-instruct">https://github.com/declare-lab/red-instruct</a></li>
<li>paper_authors: Rishabh Bhardwaj, Soujanya Poria</li>
<li>For: This paper aims to address the risk of large language models (LLMs) producing harmful outputs and to develop a safety evaluation benchmark for LLMs.* Methods: The paper proposes a new safety evaluation benchmark called RED-EVAL, which uses a red-teaming approach to test the susceptibility of LLMs to harmful prompts. The authors also propose a method called RED-INSTRUCT for aligning LLMs with safe and helpful responses.* Results: The paper shows that even widely deployed LLMs are susceptible to harmful prompts, with more than 65% and 73% of harmful queries eliciting unethical responses from GPT-4 and ChatGPT, respectively. The authors also demonstrate the consistency of RED-EVAL across 8 open-source LLMs in generating harmful responses in more than 86% of the red-teaming attempts. Finally, the authors show that their proposed safety alignment method (RED-INSTRUCT) can improve the safety of LLMs while preserving their utility.<details>
<summary>Abstract</summary>
Larger language models (LLMs) have taken the world by storm with their massive multi-tasking capabilities simply by optimizing over a next-word prediction objective. With the emergence of their properties and encoded knowledge, the risk of LLMs producing harmful outputs increases, making them unfit for scalable deployment for the public. In this work, we propose a new safety evaluation benchmark RED-EVAL that carries out red-teaming. We show that even widely deployed models are susceptible to the Chain of Utterances-based (CoU) prompting, jailbreaking closed source LLM-based systems such as GPT-4 and ChatGPT to unethically respond to more than 65% and 73% of harmful queries. We also demonstrate the consistency of the RED-EVAL across 8 open-source LLMs in generating harmful responses in more than 86% of the red-teaming attempts. Next, we propose RED-INSTRUCT--An approach for the safety alignment of LLMs. It constitutes two phases: 1) HARMFULQA data collection: Leveraging CoU prompting, we collect a dataset that consists of 1.9K harmful questions covering a wide range of topics, 9.5K safe and 7.3K harmful conversations from ChatGPT; 2) SAFE-ALIGN: We demonstrate how the conversational dataset can be used for the safety alignment of LLMs by minimizing the negative log-likelihood over helpful responses and penalizing over harmful responses by gradient accent over sample loss. Our model STARLING, a fine-tuned Vicuna-7B, is observed to be more safely aligned when evaluated on RED-EVAL and HHH benchmarks while preserving the utility of the baseline models (TruthfulQA, MMLU, and BBH).
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经在全球引起了风波，它们通过优化下一个单词预测目标来实现巨大多任务能力。然而， LLM 的出现也带来了它们生成有害输出的风险，使得它们不适合大规模部署。在这种情况下，我们提出了一个新的安全评估标准RED-EVAL，它通过红色队伍（red-teaming）来评估 LLM 的安全性。我们发现，广泛部署的模型都是对 CoU（链接词）提示的敏感，可以被破解，从而生成有害输出。此外，我们还证明了 RED-EVAL 在 8 个开源 LLM 上的一致性，它们在红色队伍中生成有害输出的情况超过 86%。接着，我们提出了 RED-INSTRUCT，一种安全对齐 LLM 的方法。它包括两个阶段：1）危险问题收集：通过 CoU 提示，我们收集了一个包含 1.9K 个危险问题、9.5K 个安全问题和 7.3K 个危险对话的数据集，来自 ChatGPT; 2）安全对齐：我们示例了如何使用 conversational 数据集来对 LLM 进行安全对齐，通过负采样损失来减少帮助Response的负损失，并对危险Response进行惩罚。我们的模型 STARLING，基于 Vicuna-7B 的 fine-tune，在 RED-EVAL 和 HHH benchmark 上被观察到更安全地对齐，而不会影响基eline模型（TruthfulQA、MMLU 和 BBH）的实用性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/19/cs.CL_2023_08_19/" data-id="clogyj8wb009d7crac7to5myd" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_19" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/19/cs.LG_2023_08_19/" class="article-date">
  <time datetime="2023-08-19T10:00:00.000Z" itemprop="datePublished">2023-08-19</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/19/cs.LG_2023_08_19/">cs.LG - 2023-08-19</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Efficient-Representation-Learning-for-Healthcare-with-Cross-Architectural-Self-Supervision"><a href="#Efficient-Representation-Learning-for-Healthcare-with-Cross-Architectural-Self-Supervision" class="headerlink" title="Efficient Representation Learning for Healthcare with Cross-Architectural Self-Supervision"></a>Efficient Representation Learning for Healthcare with Cross-Architectural Self-Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10064">http://arxiv.org/abs/2308.10064</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pranavsinghps1/CASS">https://github.com/pranavsinghps1/CASS</a></li>
<li>paper_authors: Pranav Singh, Jacopo Cirrone</li>
<li>for: 这篇论文的目的是解决在医疗和生物医学应用中的极限计算需求，以实现表现学习的效果。</li>
<li>methods: 本论文提出了一种新的同构自监督学习方法，将传播储存器和对称神经网络（CNN）融合使用，以提高效率。</li>
<li>results:  empirical evaluation 表明，CASS-trained CNNs和Transformers 在四个不同的医疗数据集上比先前的自监督学习方法表现更好，尤其是只使用 1% 标注数据进行调整时。<details>
<summary>Abstract</summary>
In healthcare and biomedical applications, extreme computational requirements pose a significant barrier to adopting representation learning. Representation learning can enhance the performance of deep learning architectures by learning useful priors from limited medical data. However, state-of-the-art self-supervised techniques suffer from reduced performance when using smaller batch sizes or shorter pretraining epochs, which are more practical in clinical settings. We present Cross Architectural - Self Supervision (CASS) in response to this challenge. This novel siamese self-supervised learning approach synergistically leverages Transformer and Convolutional Neural Networks (CNN) for efficient learning. Our empirical evaluation demonstrates that CASS-trained CNNs and Transformers outperform existing self-supervised learning methods across four diverse healthcare datasets. With only 1% labeled data for finetuning, CASS achieves a 3.8% average improvement; with 10% labeled data, it gains 5.9%; and with 100% labeled data, it reaches a remarkable 10.13% enhancement. Notably, CASS reduces pretraining time by 69% compared to state-of-the-art methods, making it more amenable to clinical implementation. We also demonstrate that CASS is considerably more robust to variations in batch size and pretraining epochs, making it a suitable candidate for machine learning in healthcare applications.
</details>
<details>
<summary>摘要</summary>
在医疗和生物医学应用中，极高的计算需求成为了使用表示学习的障碍。表示学习可以提高深度学习架构的性能，但是现有的自我超vised学习技术在使用小批量或短duration pretraining epochs时会导致性能下降，这些epochs更加适合临床应用。为了解决这个挑战，我们提出了跨建筑-自我超vised学习（CASS）方法。这种新的siamesecross-architectural self-supervised learning方法利用了 transformer 和 convolutional neural networks（CNN），以高效地学习。我们的实验证明，CASS-trained CNNs和 transformers 在四种不同的医疗数据集上都超过了现有的自我超vised learning方法。具有1% 标注数据进行 fine-tuning，CASS 可以提高3.8%的平均提升;具有10% 标注数据，它可以提高5.9%;具有100% 标注数据，它可以达到了10.13%的很出色的提升。另外，CASS 可以降低预训练时间，相比之前的方法，它更适合临床应用。我们还证明了 CASS 对批量大小和预训练epochs的变化具有较强的鲁棒性，使其成为医学应用中的适合者。
</details></li>
</ul>
<hr>
<h2 id="Accelerating-Exact-Combinatorial-Optimization-via-RL-based-Initialization-–-A-Case-Study-in-Scheduling"><a href="#Accelerating-Exact-Combinatorial-Optimization-via-RL-based-Initialization-–-A-Case-Study-in-Scheduling" class="headerlink" title="Accelerating Exact Combinatorial Optimization via RL-based Initialization – A Case Study in Scheduling"></a>Accelerating Exact Combinatorial Optimization via RL-based Initialization – A Case Study in Scheduling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11652">http://arxiv.org/abs/2308.11652</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaqi Yin, Cunxi Yu</li>
<li>for: 本研究旨在提出一种创新的方法，使用机器学习（ML）解决计算图上的 combinatorial 优化问题，例如 EdgeTPU 平台上的计算图调度问题。</li>
<li>methods: 本研究使用了一种两阶段 RL-to-ILP 调度框架，包括三个步骤：1）RL 算法 acted as coarse-grain 调度器，2）解决 relaxation 和 3）精确的 ILP 解。</li>
<li>results: 研究表明，使用本研究的方法可以保证优化和幂等性，同时具有较高的运行时效率，在 EdgeTPU 平台上实现了 ImageNet DNN 计算图的实时推理和加速。<details>
<summary>Abstract</summary>
Scheduling on dataflow graphs (also known as computation graphs) is an NP-hard problem. The traditional exact methods are limited by runtime complexity, while reinforcement learning (RL) and heuristic-based approaches struggle with determinism and solution quality. This research aims to develop an innovative approach that employs machine learning (ML) for addressing combinatorial optimization problems, using scheduling as a case study. The goal is to provide guarantees in optimality and determinism while maintaining the runtime cost of heuristic methods. Specifically, we introduce a novel two-phase RL-to-ILP scheduling framework, which includes three steps: 1) RL solver acts as coarse-grain scheduler, 2) solution relaxation and 3) exact solving via ILP. Our framework demonstrates the same scheduling performance compared with using exact scheduling methods while achieving up to 128 $\times$ speed improvements. This was conducted on actual EdgeTPU platforms, utilizing ImageNet DNN computation graphs as input. Additionally, the framework offers improved on-chip inference runtime and acceleration compared to the commercially available EdgeTPU compiler.
</details>
<details>
<summary>摘要</summary>
“计划在数据流图（也称为计算图）是NP困难的问题。传统的精确方法受到时间复杂度的限制，而RL和规则基本方法则受到权化和解决质量的影响。这项研究旨在开发一种创新的方法，利用机器学习（ML）来解决 combinatorial 优化问题，使用计划为例研究。目标是提供优化和权化的保证，同时保持规则基本方法的运行时间成本。我们介绍了一种新的两阶段RL-to-ILP 计划框架，包括以下三个步骤：1）RL 解决器 acts as 粗糙度调度器，2）解决relaxation和3）精确的解决via ILP。我们的框架示出与使用精确计划方法相同的计划性表现，同时实现了128倍的速度提升。这些研究在实际的 EdgeTPU 平台上进行，使用 ImageNet DNN 计算图作为输入。此外，我们的框架还提供了比商业可用的 EdgeTPU 编译器更好的在处理器上的执行时间和加速。”
</details></li>
</ul>
<hr>
<h2 id="The-Snowflake-Hypothesis-Training-Deep-GNN-with-One-Node-One-Receptive-field"><a href="#The-Snowflake-Hypothesis-Training-Deep-GNN-with-One-Node-One-Receptive-field" class="headerlink" title="The Snowflake Hypothesis: Training Deep GNN with One Node One Receptive field"></a>The Snowflake Hypothesis: Training Deep GNN with One Node One Receptive field</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10051">http://arxiv.org/abs/2308.10051</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kun Wang, Guohao Li, Shilong Wang, Guibin Zhang, Kai Wang, Yang You, Xiaojiang Peng, Yuxuan Liang, Yang Wang</li>
<li>for: This paper aims to improve the performance and interpretability of deep graph neural networks (GNNs) by introducing the Snowflake Hypothesis, which posits that each node in a graph should have its own unique receptive field.</li>
<li>methods: The paper conducts a systematic study of deeper GNN research trajectories, employing the simplest gradient and node-level cosine distance as guiding principles to regulate the aggregation depth for each node. The authors also compare their approach with different aggregation strategies on multiple benchmarks.</li>
<li>results: The paper demonstrates that the Snowflake Hypothesis can serve as a universal operator for a range of tasks, and it displays tremendous potential on deep GNNs. The authors show that their approach can be applied to various GNN frameworks, enhancing their effectiveness when operating in-depth, and guiding the selection of the optimal network depth in an explainable and generalizable way.Here is the text in Simplified Chinese:</li>
<li>for: 本 paper 的目的是提高深度 graph neural network (GNN) 的性能和可解性，通过引入 snowflake 假设，即每个节点在图中应该有自己独特的接受范围。</li>
<li>methods: 本 paper 通过系统地研究深度 GNN 研究轨迹，使用最简单的梯度和节点级cosine距离来规则每个节点的聚合深度。作者还比较了不同的聚合策略在多个 benchmark 上。</li>
<li>results: 本 paper 表明 snowflake 假设可以作为一个通用的运算，并且在深度 GNN 中显示出巨大的潜力。作者们表明该方法可以应用于不同的 GNN 框架，提高它们在深度下的效果，并且可以在可解的和通用的方式下选择最佳网络深度。<details>
<summary>Abstract</summary>
Despite Graph Neural Networks demonstrating considerable promise in graph representation learning tasks, GNNs predominantly face significant issues with over-fitting and over-smoothing as they go deeper as models of computer vision realm. In this work, we conduct a systematic study of deeper GNN research trajectories. Our findings indicate that the current success of deep GNNs primarily stems from (I) the adoption of innovations from CNNs, such as residual/skip connections, or (II) the tailor-made aggregation algorithms like DropEdge. However, these algorithms often lack intrinsic interpretability and indiscriminately treat all nodes within a given layer in a similar manner, thereby failing to capture the nuanced differences among various nodes. To this end, we introduce the Snowflake Hypothesis -- a novel paradigm underpinning the concept of ``one node, one receptive field''. The hypothesis draws inspiration from the unique and individualistic patterns of each snowflake, proposing a corresponding uniqueness in the receptive fields of nodes in the GNNs.   We employ the simplest gradient and node-level cosine distance as guiding principles to regulate the aggregation depth for each node, and conduct comprehensive experiments including: (1) different training schemes; (2) various shallow and deep GNN backbones, and (3) various numbers of layers (8, 16, 32, 64) on multiple benchmarks (six graphs including dense graphs with millions of nodes); (4) compare with different aggregation strategies. The observational results demonstrate that our hypothesis can serve as a universal operator for a range of tasks, and it displays tremendous potential on deep GNNs. It can be applied to various GNN frameworks, enhancing its effectiveness when operating in-depth, and guiding the selection of the optimal network depth in an explainable and generalizable way.
</details>
<details>
<summary>摘要</summary>
尽管图形神经网络（Graph Neural Networks，GNNs）在图像表示学任务中表现出了很大的承诺，但它们在深度层次上面临着颗粒泛化和颗粒滤波等问题。在这项工作中，我们进行了系统的 deeper GNN 研究轨迹。我们的发现表明，当前深度 GNN 的成功主要归功于（I） adopting innovations from CNNs，如待遇/跳过连接，或（II）适应制的聚合算法如 DropEdge。然而，这些算法通常缺乏内在解释性和不具分辨率地对所有层中的所有节点进行处理，因此无法捕捉不同节点之间的细腻差异。为此，我们提出了“雪花假设”——一种新的思想，它着眼于每个节点具有独特和特殊的感知领域。我们采用 simplest gradient 和节点级 cosine distance 作为引导原则，以REGULATE aggregation depth for each node，并进行了广泛的实验，包括：（1）不同训练方案；（2）不同的 shallow 和 deep GNN 基础架构；（3）不同层数（8, 16, 32, 64）在多个 benchmark 上进行了多种实验。结果表明，我们的假设可以作为一种通用的操作，并且在深度 GNN 中表现出了巨大的潜力。它可以应用于多种 GNN 框架，提高其在深度下的效果，并且可以在可解释的和普遍的方式下选择最佳网络深度。
</details></li>
</ul>
<hr>
<h2 id="Computing-the-Vapnik-Chervonenkis-Dimension-for-Non-Discrete-Settings"><a href="#Computing-the-Vapnik-Chervonenkis-Dimension-for-Non-Discrete-Settings" class="headerlink" title="Computing the Vapnik Chervonenkis Dimension for Non-Discrete Settings"></a>Computing the Vapnik Chervonenkis Dimension for Non-Discrete Settings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10041">http://arxiv.org/abs/2308.10041</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammed Nechba, Mouhajir Mohamed, Sedjari Yassine</li>
<li>for: 这个论文的目的是为了开发一种可以计算无约束的VC dimenson的方法。</li>
<li>methods: 该论文使用了Empirical Risk Minimization（ERM）学习模型来Characterize the shattering property of a concept class。</li>
<li>results: 该论文提出了一种可以approximately计算VC dimenson的方法，不再需要约束于概念集或其域集。<details>
<summary>Abstract</summary>
In 1984, Valiant [ 7 ] introduced the Probably Approximately Correct (PAC) learning framework for boolean function classes. Blumer et al. [ 2] extended this model in 1989 by introducing the VC dimension as a tool to characterize the learnability of PAC. The VC dimension was based on the work of Vapnik and Chervonenkis in 1971 [8 ], who introduced a tool called the growth function to characterize the shattering property. Researchers have since determined the VC dimension for specific classes, and efforts have been made to develop an algorithm that can calculate the VC dimension for any concept class. In 1991, Linial, Mansour, and Rivest [4] presented an algorithm for computing the VC dimension in the discrete setting, assuming that both the concept class and domain set were finite. However, no attempts had been made to design an algorithm that could compute the VC dimension in the general setting.Therefore, our work focuses on developing a method to approximately compute the VC dimension without constraints on the concept classes or their domain set. Our approach is based on our finding that the Empirical Risk Minimization (ERM) learning paradigm can be used as a new tool to characterize the shattering property of a concept class.
</details>
<details>
<summary>摘要</summary>
在1984年，强力（7）引入了一种名为“可以近似正确”（PAC）学习框架，用于 boolean 函数类型。布吕默等人（2）在1989年将这个模型扩展了，通过引入 VC 维度来描述学习可能性。VC 维度基于1971年由普纳克和 Червонен科伊所引入的一种工具——生长函数，用于描述分裂性质。后续的研究者已经确定了特定类型的 VC 维度，并尝试了开发一种可以计算任何概念类型的 VC 维度的算法。在1991年，林亚尔、曼索尔和里韦斯特（4）提出了一种算法，用于计算 discrete  Setting 中的 VC 维度，假设概念类型和域集都是 фиксирован的。然而，没有任何尝试过开发一种可以计算总体设定中的 VC 维度的算法。因此，我们的工作将关注于开发一种可以近似计算 VC 维度的方法，不受概念类型或域集的限制。我们的方法基于我们发现，Empirical Risk Minimization（ERM）学习模式可以用作一种新的工具来描述分裂性质。
</details></li>
</ul>
<hr>
<h2 id="Physics-guided-training-of-GAN-to-improve-accuracy-in-airfoil-design-synthesis"><a href="#Physics-guided-training-of-GAN-to-improve-accuracy-in-airfoil-design-synthesis" class="headerlink" title="Physics-guided training of GAN to improve accuracy in airfoil design synthesis"></a>Physics-guided training of GAN to improve accuracy in airfoil design synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10038">http://arxiv.org/abs/2308.10038</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kazunari Wada, Katsuyuki Suzuki, Kazuo Yonekura</li>
<li>for: 本研究使用生成对抗网络（GAN）进行机械形状的设计合成，但GANometimes输出物理不合理的形状。例如，当GAN模型在输出空气foil形状时，需要的 aerodynamic性能值会出现显著的错误。这是因为GAN模型只考虑数据，而不考虑下面的 aerodynamic equations。</li>
<li>methods: 本研究提出了基于物理学习的GAN模型训练方法，使得GAN模型学习物理有效性。物理有效性通过外部的通用软件计算，而不是直接在神经网络模型中实现物理方程。此外，生成模型的输出数据通常和训练数据相似，无法生成完全新的形状。但是，由于提议的模型受到物理模型的指导，不使用训练集，因此可以生成完全新的形状。</li>
<li>results: 数值实验表明，提议的模型可以减轻错误，同时输出的形状与训练集不同，但仍满足物理有效性。这超越了现有的GAN模型的局限性。<details>
<summary>Abstract</summary>
Generative adversarial networks (GAN) have recently been used for a design synthesis of mechanical shapes. A GAN sometimes outputs physically unreasonable shapes. For example, when a GAN model is trained to output airfoil shapes that indicate required aerodynamic performance, significant errors occur in the performance values. This is because the GAN model only considers data but does not consider the aerodynamic equations that lie under the data. This paper proposes the physics-guided training of the GAN model to guide the model to learn physical validity. Physical validity is computed using general-purpose software located outside the neural network model. Such general-purpose software cannot be used in physics-informed neural network frameworks, because physical equations must be implemented inside the neural network models. Additionally, a limitation of generative models is that the output data are similar to the training data and cannot generate completely new shapes. However, because the proposed model is guided by a physical model and does not use a training dataset, it can generate completely new shapes. Numerical experiments show that the proposed model drastically improves the accuracy. Moreover, the output shapes differ from those of the training dataset but still satisfy the physical validity, overcoming the limitations of existing GAN models.
</details>
<details>
<summary>摘要</summary>
生成对抗网络（GAN）最近在机械形状设计中得到了应用。然而，GAN sometimes outputs不理性的形状。例如，当GAN模型被训练来输出符合需要的 aerodynamic performance 的风 razor shape 时，会出现 significannot 的错误。这是因为GAN模型只考虑数据，而不考虑下面数据的 aerodynamic 方程。这篇论文提议通过 физи学导向的 GAN 模型来引导模型学习物理有效性。物理有效性通过外部通用软件计算，这种外部通用软件无法用于物理学 Informed Neural Network 框架中，因为物理方程必须在神经网络模型中实现。此外，生成模型的一个限制是输出数据与训练数据相似，无法生成完全新的形状。然而，由于提议的模型受到物理模型的导引，不使用训练集，因此可以生成完全新的形状。 num 实验表明，提议的模型可以减少错误，并且输出的形状与训练集不同，但仍满足物理有效性，超越现有 GAN 模型的限制。
</details></li>
</ul>
<hr>
<h2 id="High-Performance-Computing-Applied-to-Logistic-Regression-A-CPU-and-GPU-Implementation-Comparison"><a href="#High-Performance-Computing-Applied-to-Logistic-Regression-A-CPU-and-GPU-Implementation-Comparison" class="headerlink" title="High Performance Computing Applied to Logistic Regression: A CPU and GPU Implementation Comparison"></a>High Performance Computing Applied to Logistic Regression: A CPU and GPU Implementation Comparison</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10037">http://arxiv.org/abs/2308.10037</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nechbamohammed/swiftlogisticreg">https://github.com/nechbamohammed/swiftlogisticreg</a></li>
<li>paper_authors: Nechba Mohammed, Mouhajir Mohamed, Sedjari Yassine</li>
<li>for: 这个论文旨在提出一个基于GPU的多线程逻辑回传函数（Logistic Regression，LR），以满足巨量数据的运算需求。</li>
<li>methods: 这个实现方式是基于X. Zou等人提出的平行Gradient Descent Logistic Regression算法的直译版本。</li>
<li>results: 我们的GPU基于LR在处理大资料集时的执行时间比CPU基于实现更快，但与相同的f1分数相似。这使得我们的方法尤其有利于实时预测应用，如影像识别、垃圾邮件检测和诈欺检测。<details>
<summary>Abstract</summary>
We present a versatile GPU-based parallel version of Logistic Regression (LR), aiming to address the increasing demand for faster algorithms in binary classification due to large data sets. Our implementation is a direct translation of the parallel Gradient Descent Logistic Regression algorithm proposed by X. Zou et al. [12]. Our experiments demonstrate that our GPU-based LR outperforms existing CPU-based implementations in terms of execution time while maintaining comparable f1 score. The significant acceleration of processing large datasets makes our method particularly advantageous for real-time prediction applications like image recognition, spam detection, and fraud detection. Our algorithm is implemented in a ready-to-use Python library available at : https://github.com/NechbaMohammed/SwiftLogisticReg
</details>
<details>
<summary>摘要</summary>
我们提出了一种高性能的GPU基于的并行Logistic Regression（LR）算法，以满足大量数据集的需求。我们的实现是直接将平行梯度下降Logistic Regression算法提出的X. Zou等人的方案翻译而成。我们的实验表明，我们的GPU基于LR在执行时间方面与CPU基于实现相比具有明显的优势，同时保持了相似的准确率。这种加速处理大数据集的能力使得我们的方法在实时预测应用中，如图像识别、垃圾邮件检测和诈骗检测等方面具有明显的优势。我们的算法已经实现在Python库中，可以在以下地址下下载：https://github.com/NechbaMohammed/SwiftLogisticReg。
</details></li>
</ul>
<hr>
<h2 id="Semi-Supervised-Anomaly-Detection-for-the-Determination-of-Vehicle-Hijacking-Tweets"><a href="#Semi-Supervised-Anomaly-Detection-for-the-Determination-of-Vehicle-Hijacking-Tweets" class="headerlink" title="Semi-Supervised Anomaly Detection for the Determination of Vehicle Hijacking Tweets"></a>Semi-Supervised Anomaly Detection for the Determination of Vehicle Hijacking Tweets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10036">http://arxiv.org/abs/2308.10036</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taahir Aiyoob Patel, Clement N. Nyirenda</li>
<li>for: 本研究旨在使用微博来识别抢夺事件，以帮助旅行者避免成为受害者。</li>
<li>methods: 本研究使用了无监督异常检测算法，包括KNN和CBLOF两种方法，对Twitter上包含“抢夺”关键词的微博进行分析。</li>
<li>results: 比较分析表明，CBLOF方法的准确率为90%，而KNN方法的准确率为89%。CBLOF方法还得到了F1分数为0.8，而KNN方法得到了0.78。因此，CBLOF方法在抢夺微博识别方面表现了一定的优势。未来，将会对大型数据集使用超级vised学习方法进行比较，并使用优化机制提高总性能。<details>
<summary>Abstract</summary>
In South Africa, there is an ever-growing issue of vehicle hijackings. This leads to travellers constantly being in fear of becoming a victim to such an incident. This work presents a new semi-supervised approach to using tweets to identify hijacking incidents by using unsupervised anomaly detection algorithms. Tweets consisting of the keyword "hijacking" are obtained, stored, and processed using the term frequency-inverse document frequency (TF-IDF) and further analyzed by using two anomaly detection algorithms: 1) K-Nearest Neighbour (KNN); 2) Cluster Based Outlier Factor (CBLOF). The comparative evaluation showed that the KNN method produced an accuracy of 89%, whereas the CBLOF produced an accuracy of 90%. The CBLOF method was also able to obtain a F1-Score of 0.8, whereas the KNN produced a 0.78. Therefore, there is a slight difference between the two approaches, in favour of CBLOF, which has been selected as a preferred unsupervised method for the determination of relevant hijacking tweets. In future, a comparison will be done between supervised learning methods and the unsupervised methods presented in this work on larger dataset. Optimisation mechanisms will also be employed in order to increase the overall performance.
</details>
<details>
<summary>摘要</summary>
在南非， vehicular hijacking 是一个日益增长的问题。这使得旅行者们经常处于被劫持的恐惧中。本文提出了一种新的半监督方法，使用社交媒体上的 tweet 来识别劫持事件。使用关键词 "劫持" 获取、存储和处理 tweet，并使用 term frequency-inverse document frequency (TF-IDF) 进行处理。然后使用两种异常检测算法：1）K-Nearest Neighbour (KNN)；2）Cluster Based Outlier Factor (CBLOF)。对比评估表明，KNN 方法的准确率为 89%，而 CBLOF 方法的准确率为 90%。CBLOF 方法还可以获得 F1-Score 0.8，而 KNN 方法只有 0.78。因此，CBLOF 方法有一定的优势，因此被选为劫持 tweet 的半监督方法。未来，将进行大量数据集上的比较，以及优化机制的实现，以提高总性能。
</details></li>
</ul>
<hr>
<h2 id="Effects-of-Convolutional-Autoencoder-Bottleneck-Width-on-StarGAN-based-Singing-Technique-Conversion"><a href="#Effects-of-Convolutional-Autoencoder-Bottleneck-Width-on-StarGAN-based-Singing-Technique-Conversion" class="headerlink" title="Effects of Convolutional Autoencoder Bottleneck Width on StarGAN-based Singing Technique Conversion"></a>Effects of Convolutional Autoencoder Bottleneck Width on StarGAN-based Singing Technique Conversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10021">http://arxiv.org/abs/2308.10021</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tung-Cheng Su, Yung-Chuan Chang, Yi-Wen Liu</li>
<li>for: 本研究旨在评估对声音技巧转换（STC）中CAE核心宽度的影响，以提高转换质量。</li>
<li>methods: 我们采用了基于GAN的多域STC系统，利用WORLD vocoder表示和CAE架构。我们对CAE核心宽度进行了变换，并对转换结果进行主观评估。</li>
<li>results: 结果显示，更宽的CAE核心对于语音清晰度有益，但不一定导致更高的同化度。四种声音技巧中，抽喉声最容易转换，而其他三种声音技巧作为源声音更能实现更加真实的转换。<details>
<summary>Abstract</summary>
Singing technique conversion (STC) refers to the task of converting from one voice technique to another while leaving the original singer identity, melody, and linguistic components intact. Previous STC studies, as well as singing voice conversion research in general, have utilized convolutional autoencoders (CAEs) for conversion, but how the bottleneck width of the CAE affects the synthesis quality has not been thoroughly evaluated. To this end, we constructed a GAN-based multi-domain STC system which took advantage of the WORLD vocoder representation and the CAE architecture. We varied the bottleneck width of the CAE, and evaluated the conversion results subjectively. The model was trained on a Mandarin dataset which features four singers and four singing techniques: the chest voice, the falsetto, the raspy voice, and the whistle voice. The results show that a wider bottleneck corresponds to better articulation clarity but does not necessarily lead to higher likeness to the target technique. Among the four techniques, we also found that the whistle voice is the easiest target for conversion, while the other three techniques as a source produce more convincing conversion results than the whistle.
</details>
<details>
<summary>摘要</summary>
声乐技巧转换（STC）指的是将一种声乐技巧转换为另一种，保持原始歌手身份、旋律和语言元素不变。先前的 STC 研究以及全球声乐转换研究都使用了卷积 autoencoder（CAE）进行转换，但 CAE 瓶颈宽度如何影响转换质量尚未得到全面评估。为了解决这个问题，我们构建了基于 GAN 的多Domain STC 系统，利用了 WORLD  vocoder 表示和 CAE 建筑。我们在 CAE 瓶颈宽度上进行了变量，并对转换结果进行主观评估。系统在普通话 dataset 上训练，该 dataset 包含四名歌手和四种声乐技巧：胸部声、抖音声、咔声和喊声。结果表明，宽瓶颈对声音清晰度有更好的影响，但并不一定导致更高的模仿度。其中四种技巧中，喊声是转换最容易的目标，而其他三种技巧作为源都能够更加自然地转换。
</details></li>
</ul>
<hr>
<h2 id="Semi-Implicit-Variational-Inference-via-Score-Matching"><a href="#Semi-Implicit-Variational-Inference-via-Score-Matching" class="headerlink" title="Semi-Implicit Variational Inference via Score Matching"></a>Semi-Implicit Variational Inference via Score Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10014">http://arxiv.org/abs/2308.10014</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/longinyu/sivism">https://github.com/longinyu/sivism</a></li>
<li>paper_authors: Longlin Yu, Cheng Zhang</li>
<li>for: 强化变量推理的表达力（Semi-implicit variational inference，SIVI），使得变量推理家族更加丰富和灵活。</li>
<li>methods: 基于分形证据匹配（score matching）的一种新方法，充分利用变量推理家族的层次结构，使得困难的变量推理density可以自然地处理。</li>
<li>results: 与MCMC相比，SIVI-SM方法可以准确地匹配MCMC的准确性，并且在多种推理任务中超过ELBO基于的SIVI方法。<details>
<summary>Abstract</summary>
Semi-implicit variational inference (SIVI) greatly enriches the expressiveness of variational families by considering implicit variational distributions defined in a hierarchical manner. However, due to the intractable densities of variational distributions, current SIVI approaches often use surrogate evidence lower bounds (ELBOs) or employ expensive inner-loop MCMC runs for unbiased ELBOs for training. In this paper, we propose SIVI-SM, a new method for SIVI based on an alternative training objective via score matching. Leveraging the hierarchical structure of semi-implicit variational families, the score matching objective allows a minimax formulation where the intractable variational densities can be naturally handled with denoising score matching. We show that SIVI-SM closely matches the accuracy of MCMC and outperforms ELBO-based SIVI methods in a variety of Bayesian inference tasks.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用半隐式变量推断（SIVI）可以扩大变量家族的表达能力，通过在层次结构中考虑隐式变量分布定义。然而，由于变量分布的计算困难，现有的SIVI方法通常使用代理证据下界（ELBO）或者使用昂贵的内 Loop MCMC 迭代进行培训。在这篇论文中，我们提出了基于代理证据匹配的新方法，称为SIVI-SM。该方法利用层次结构中的 semi-implicit 变量家族，通过代理证据匹配对象来实现一种减少对变量分布的干扰的训练目标。我们表明，SIVI-SM可以准确地与 MCMC 匹配，并且在多种 bayesian 推断任务中超过 ELBO 基于的 SIVI 方法表现。>>>
</details></li>
</ul>
<hr>
<h2 id="Distributionally-Robust-Cross-Subject-EEG-Decoding"><a href="#Distributionally-Robust-Cross-Subject-EEG-Decoding" class="headerlink" title="Distributionally Robust Cross Subject EEG Decoding"></a>Distributionally Robust Cross Subject EEG Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11651">http://arxiv.org/abs/2308.11651</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tiehang Duan, Zhenyi Wang, Gianfranco Doretto, Fang Li, Cui Tao, Donald Adjeroh<br>for: 这个研究旨在提高EEG解oding任务的表现，特别是面对高度不确定和不同类型的资料污染。methods: 这个研究使用分布robust优化和 Wasserstein gradient flow (WGF) 提出了一个原理式的演化方法，通过对数据分布进行演化来提高解oding的类别识别能力。results: 实验结果显示，提案的方法可以与其他数据增强技术结合使用，在严重损坏EEG讯号的情况下表现出色，较前一些竞争基eline。<details>
<summary>Abstract</summary>
Recently, deep learning has shown to be effective for Electroencephalography (EEG) decoding tasks. Yet, its performance can be negatively influenced by two key factors: 1) the high variance and different types of corruption that are inherent in the signal, 2) the EEG datasets are usually relatively small given the acquisition cost, annotation cost and amount of effort needed. Data augmentation approaches for alleviation of this problem have been empirically studied, with augmentation operations on spatial domain, time domain or frequency domain handcrafted based on expertise of domain knowledge. In this work, we propose a principled approach to perform dynamic evolution on the data for improvement of decoding robustness. The approach is based on distributionally robust optimization and achieves robustness by optimizing on a family of evolved data distributions instead of the single training data distribution. We derived a general data evolution framework based on Wasserstein gradient flow (WGF) and provides two different forms of evolution within the framework. Intuitively, the evolution process helps the EEG decoder to learn more robust and diverse features. It is worth mentioning that the proposed approach can be readily integrated with other data augmentation approaches for further improvements. We performed extensive experiments on the proposed approach and tested its performance on different types of corrupted EEG signals. The model significantly outperforms competitive baselines on challenging decoding scenarios.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Disposable-Transfer-Learning-for-Selective-Source-Task-Unlearning"><a href="#Disposable-Transfer-Learning-for-Selective-Source-Task-Unlearning" class="headerlink" title="Disposable Transfer Learning for Selective Source Task Unlearning"></a>Disposable Transfer Learning for Selective Source Task Unlearning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09971">http://arxiv.org/abs/2308.09971</a></li>
<li>repo_url: None</li>
<li>paper_authors: Seunghee Koh, Hyounguk Shon, Janghyeon Lee, Hyeong Gwon Hong, Junmo Kim</li>
<li>for: 这个论文旨在解决如何在转移学习中保持目标任务的表现，而不是完全抛弃源任务的表现。</li>
<li>methods: 该论文提出了一种新的转移学习方法，即丢弃转移学习（DTL），该方法可以在转移学习过程中 selectively 抛弃源任务的知识。</li>
<li>results: 论文表明，通过使用 Gradient Collision loss（GC loss）可以帮助模型 selectively 抛弃源任务的知识，同时保持目标任务的表现。 GC loss 可以衡量知识泄露的程度，并且可以在新的下游任务上进行重新训练。<details>
<summary>Abstract</summary>
Transfer learning is widely used for training deep neural networks (DNN) for building a powerful representation. Even after the pre-trained model is adapted for the target task, the representation performance of the feature extractor is retained to some extent. As the performance of the pre-trained model can be considered the private property of the owner, it is natural to seek the exclusive right of the generalized performance of the pre-trained weight. To address this issue, we suggest a new paradigm of transfer learning called disposable transfer learning (DTL), which disposes of only the source task without degrading the performance of the target task. To achieve knowledge disposal, we propose a novel loss named Gradient Collision loss (GC loss). GC loss selectively unlearns the source knowledge by leading the gradient vectors of mini-batches in different directions. Whether the model successfully unlearns the source task is measured by piggyback learning accuracy (PL accuracy). PL accuracy estimates the vulnerability of knowledge leakage by retraining the scrubbed model on a subset of source data or new downstream data. We demonstrate that GC loss is an effective approach to the DTL problem by showing that the model trained with GC loss retains the performance on the target task with a significantly reduced PL accuracy.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate "Transfer learning is widely used for training deep neural networks (DNN) for building a powerful representation. Even after the pre-trained model is adapted for the target task, the representation performance of the feature extractor is retained to some extent. As the performance of the pre-trained model can be considered the private property of the owner, it is natural to seek the exclusive right of the generalized performance of the pre-trained weight. To address this issue, we suggest a new paradigm of transfer learning called disposable transfer learning (DTL), which disposes of only the source task without degrading the performance of the target task. To achieve knowledge disposal, we propose a novel loss named Gradient Collision loss (GC loss). GC loss selectively unlearns the source knowledge by leading the gradient vectors of mini-batches in different directions. Whether the model successfully unlearns the source task is measured by piggyback learning accuracy (PL accuracy). PL accuracy estimates the vulnerability of knowledge leakage by retraining the scrubbed model on a subset of source data or new downstream data. We demonstrate that GC loss is an effective approach to the DTL problem by showing that the model trained with GC loss retains the performance on the target task with a significantly reduced PL accuracy."中文翻译：转移学习广泛用于训练深度神经网络（DNN）以建立强大的表示。即使预训练模型被适应目标任务，表示性性能的特征提取器仍然保持一定程度的表现。由于预训练模型的性能可以被视为业主的私有财产，因此自然想要寻求预训练权重的权属。为解决这个问题，我们提出了一种新的转移学习方法 called  dispose transfer learning（DTL），它可以不影响目标任务的性能，但是可以消除来源任务。为实现知识抛弃，我们提出了一种新的损失函数名为梯度碰撞损失（GC损失）。GC损失可以 selectively 忘记来源知识，通过导向梯度向量的不同方向。确定模型是否成功忘记来源任务，可以通过猪肉学习精度（PL精度）来衡量。PL精度可以估计知识泄露的敏感度，通过在源数据或新的下游数据上重新训练混凝模型。我们示示GC损失是解决 DTL 问题的有效方法，通过显示GC损失训练的模型在目标任务上保持表现，同时减少了PL精度。
</details></li>
</ul>
<hr>
<h2 id="Tackling-Vision-Language-Tasks-Through-Learning-Inner-Monologues"><a href="#Tackling-Vision-Language-Tasks-Through-Learning-Inner-Monologues" class="headerlink" title="Tackling Vision Language Tasks Through Learning Inner Monologues"></a>Tackling Vision Language Tasks Through Learning Inner Monologues</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09970">http://arxiv.org/abs/2308.09970</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diji Yang, Kezhen Chen, Jinmeng Rao, Xiaoyuan Guo, Yawen Zhang, Jie Yang, Yi Zhang</li>
<li>for: 解决复杂的视觉语言问题，使用内启思维过程来优化语言模型和视觉模型之间的拟合。</li>
<li>methods: 提出了一种新的方法 Inner Monologue Multi-Modal Optimization (IMMO)，通过模拟内启思维过程，使得语言模型和视觉模型可以在自然语言交流中互动，提高推理和解释能力。</li>
<li>results: 对两个popular任务进行评估，结果表明，通过模拟内启思维过程，IMMO可以提高视觉语言模型的推理和解释能力，并且可以应用于许多不同的AI问题。<details>
<summary>Abstract</summary>
Visual language tasks require AI models to comprehend and reason with both visual and textual content. Driven by the power of Large Language Models (LLMs), two prominent methods have emerged: (1) the hybrid integration between LLMs and Vision-Language Models (VLMs), where visual inputs are firstly converted into language descriptions by VLMs, serving as inputs for LLMs to generate final answer(s); (2) visual feature alignment in language space, where visual inputs are encoded as embeddings and projected to LLMs' language space via further supervised fine-tuning. The first approach provides light training costs and interpretability but is hard to be optimized in an end-to-end fashion. The second approach presents decent performance, but feature alignment usually requires large amounts of training data and lacks interpretability. To tackle this dilemma, we propose a novel approach, Inner Monologue Multi-Modal Optimization (IMMO), to solve complex vision language problems by simulating inner monologue processes, a cognitive process in which an individual engages in silent verbal communication with themselves. We enable LLMs and VLMs to interact through natural language conversation and propose to use a two-stage training process to learn how to do the inner monologue (self-asking questions and answering questions). IMMO is evaluated on two popular tasks and the results suggest by emulating the cognitive phenomenon of internal dialogue, our approach can enhance reasoning and explanation abilities, contributing to the more effective fusion of vision and language models. More importantly, instead of using predefined human-crafted monologues, IMMO learns this process within the deep learning models, promising wider applicability to many different AI problems beyond vision language tasks.
</details>
<details>
<summary>摘要</summary>
⟨SYS⟩视觉语言任务需要人工智能模型理解和处理视觉和文本内容。受大型语言模型（LLM）的力量驱动，两种主要方法出现：（1）混合 integrate LLMs 和视觉语言模型（VLMs），其中视觉输入首先被VLMs转换为语言描述，然后被LLMs 生成最终答案；（2）视觉特征对齐在语言空间，其中视觉输入被编码为特征并通过进一步的超vised fine-tuning Projected to LLMs 的语言空间。前一种方法具有轻量级训练成本和可读性，但困难在端到端方式优化；后一种方法具有良好的性能，但特征对齐通常需要大量的训练数据和缺乏可读性。为解决这个悖论，我们提出了一种新的方法： Inner Monologue Multi-Modal Optimization（IMMO），用于解决复杂的视觉语言问题。我们使得 LLMs 和 VLMs 通过自然语言对话互动，并提出了在两个阶段训练过程中学习如何做内心对话（自我问答）。IMMO 在两个流行的任务上进行评估，结果表明，通过模拟内心对话这种认知现象，我们的方法可以提高理解和解释能力，为视觉语言模型的更有效融合做出贡献。此外，不同于使用预先定制的人类编写的假象，IMMO 在深度学习模型中学习内心对话过程，提供更广泛的应用可能性。
</details></li>
</ul>
<hr>
<h2 id="Anomaly-Aware-Semantic-Segmentation-via-Style-Aligned-OoD-Augmentation"><a href="#Anomaly-Aware-Semantic-Segmentation-via-Style-Aligned-OoD-Augmentation" class="headerlink" title="Anomaly-Aware Semantic Segmentation via Style-Aligned OoD Augmentation"></a>Anomaly-Aware Semantic Segmentation via Style-Aligned OoD Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09965">http://arxiv.org/abs/2308.09965</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dan Zhang, Kaspar Sakmann, William Beluch, Robin Hutmacher, Yumeng Li</li>
<li>for: 这paper是为了帮助标准semantic segmentation模型具备异常感知而写的。</li>
<li>methods: 这paper使用了改进的out-of-distribution数据生成方法，将异常数据与驾驶场景的风格差减少到最小化，从而减轻数据生成过程中的 shortcut。此外，paper还提出了一种简单的练习损失，使得预训练的semantic segmentation模型能够生成“None of the given classes”预测，通过每个像素的异常分数进行异常分割。</li>
<li>results: 与普通的semantic segmentation模型相比，这paper的方法能够减少异常分割的训练时间和精度损失，同时保持原始任务的性能。<details>
<summary>Abstract</summary>
Within the context of autonomous driving, encountering unknown objects becomes inevitable during deployment in the open world. Therefore, it is crucial to equip standard semantic segmentation models with anomaly awareness. Many previous approaches have utilized synthetic out-of-distribution (OoD) data augmentation to tackle this problem. In this work, we advance the OoD synthesis process by reducing the domain gap between the OoD data and driving scenes, effectively mitigating the style difference that might otherwise act as an obvious shortcut during training. Additionally, we propose a simple fine-tuning loss that effectively induces a pre-trained semantic segmentation model to generate a ``none of the given classes" prediction, leveraging per-pixel OoD scores for anomaly segmentation. With minimal fine-tuning effort, our pipeline enables the use of pre-trained models for anomaly segmentation while maintaining the performance on the original task.
</details>
<details>
<summary>摘要</summary>
在自动驾驶中，遇到未知对象是不可避免的，因此需要为标准Semantic segmentation模型增加异常意识。许多前一代方法使用synthetic Out-of-distribution（OoD）数据增强进行了处理。在这种工作中，我们提高了OoD数据生成过程，将驾驶场景和OoD数据域的差异降低到最小，从而有效地消除了可能导致训练中的短cut shortcut。此外，我们提议一种简单的精度调整loss，使得预训练的Semantic segmentation模型能够生成“ none of the given classes”预测，通过每个像素的OoD分数进行异常分 segmentation。只需 minimal fine-tuning effort，我们的管道可以使用预训练模型进行异常分 segmentation，同时保持原始任务的性能。
</details></li>
</ul>
<hr>
<h2 id="Towards-Self-Adaptive-Machine-Learning-Enabled-Systems-Through-QoS-Aware-Model-Switching"><a href="#Towards-Self-Adaptive-Machine-Learning-Enabled-Systems-Through-QoS-Aware-Model-Switching" class="headerlink" title="Towards Self-Adaptive Machine Learning-Enabled Systems Through QoS-Aware Model Switching"></a>Towards Self-Adaptive Machine Learning-Enabled Systems Through QoS-Aware Model Switching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09960">http://arxiv.org/abs/2308.09960</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sa4s-serc/adamls">https://github.com/sa4s-serc/adamls</a></li>
<li>paper_authors: Shubham Kulkarni, Arya Marda, Karthik Vaidhyanathan</li>
<li>for: 本研究旨在提出一种机器学习模型均衡器，以管理运行时uncertainty，保证机器学习系统的质量。</li>
<li>methods: 本研究使用多个机器学习模型，并 introduce了一种基于MAPLE-K循环的自适应策略，以实现不断自适应机器学习系统。</li>
<li>results: 实验结果表明，AdaMLS可以更好地保证系统和模型的性能，并且在动态环境中提供优化的QoS。<details>
<summary>Abstract</summary>
Machine Learning (ML), particularly deep learning, has seen vast advancements, leading to the rise of Machine Learning-Enabled Systems (MLS). However, numerous software engineering challenges persist in propelling these MLS into production, largely due to various run-time uncertainties that impact the overall Quality of Service (QoS). These uncertainties emanate from ML models, software components, and environmental factors. Self-adaptation techniques present potential in managing run-time uncertainties, but their application in MLS remains largely unexplored. As a solution, we propose the concept of a Machine Learning Model Balancer, focusing on managing uncertainties related to ML models by using multiple models. Subsequently, we introduce AdaMLS, a novel self-adaptation approach that leverages this concept and extends the traditional MAPE-K loop for continuous MLS adaptation. AdaMLS employs lightweight unsupervised learning for dynamic model switching, thereby ensuring consistent QoS. Through a self-adaptive object detection system prototype, we demonstrate AdaMLS's effectiveness in balancing system and model performance. Preliminary results suggest AdaMLS surpasses naive and single state-of-the-art models in QoS guarantees, heralding the advancement towards self-adaptive MLS with optimal QoS in dynamic environments.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Comparison-of-Adversarial-Learning-Techniques-for-Malware-Detection"><a href="#A-Comparison-of-Adversarial-Learning-Techniques-for-Malware-Detection" class="headerlink" title="A Comparison of Adversarial Learning Techniques for Malware Detection"></a>A Comparison of Adversarial Learning Techniques for Malware Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09958">http://arxiv.org/abs/2308.09958</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pavla Louthánová, Matouš Kozák, Martin Jureček, Mark Stamp</li>
<li>for: 本文Addresses the problem of generating adversarial malware samples, specifically malicious Windows Portable Executable files, to evaluate the effectiveness of different methods for generating adversarial samples and their practical applicability.</li>
<li>methods: The paper uses gradient-based, evolutionary algorithm-based, and reinforcement-based methods to generate adversarial samples, and tests the generated samples against selected antivirus products.</li>
<li>results: The results show that applying optimized modifications to previously detected malware can lead to incorrect classification of the file as benign, and that generated malware samples can be successfully used against detection models other than those used to generate them. The Gym-malware generator, which uses a reinforcement learning approach, has the greatest practical potential, achieving an average sample generation time of 5.73 seconds and the highest average evasion rate of 44.11%. Using the Gym-malware generator in combination with itself improved the evasion rate to 58.35%.<details>
<summary>Abstract</summary>
Machine learning has proven to be a useful tool for automated malware detection, but machine learning models have also been shown to be vulnerable to adversarial attacks. This article addresses the problem of generating adversarial malware samples, specifically malicious Windows Portable Executable files. We summarize and compare work that has focused on adversarial machine learning for malware detection. We use gradient-based, evolutionary algorithm-based, and reinforcement-based methods to generate adversarial samples, and then test the generated samples against selected antivirus products. We compare the selected methods in terms of accuracy and practical applicability. The results show that applying optimized modifications to previously detected malware can lead to incorrect classification of the file as benign. It is also known that generated malware samples can be successfully used against detection models other than those used to generate them and that using combinations of generators can create new samples that evade detection. Experiments show that the Gym-malware generator, which uses a reinforcement learning approach, has the greatest practical potential. This generator achieved an average sample generation time of 5.73 seconds and the highest average evasion rate of 44.11%. Using the Gym-malware generator in combination with itself improved the evasion rate to 58.35%.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="To-prune-or-not-to-prune-A-chaos-causality-approach-to-principled-pruning-of-dense-neural-networks"><a href="#To-prune-or-not-to-prune-A-chaos-causality-approach-to-principled-pruning-of-dense-neural-networks" class="headerlink" title="To prune or not to prune : A chaos-causality approach to principled pruning of dense neural networks"></a>To prune or not to prune : A chaos-causality approach to principled pruning of dense neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09955">http://arxiv.org/abs/2308.09955</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rajan Sahu, Shivam Chadha, Nithin Nagaraj, Archana Mathur, Snehanshu Saha</li>
<li>for: 降低神经网络的大小（卷积），不受性能受到影响，是资源有限设备上重要问题。</li>
<li>methods: 通过Weight rankings或penalization criteria，如矩阵大小和重要性，从已 retrained 的剩下 weights 中选择特定的 weights，来实现卷积。</li>
<li>results: 采用这种方法可以保持原始性能，同时保留特征解释性。<details>
<summary>Abstract</summary>
Reducing the size of a neural network (pruning) by removing weights without impacting its performance is an important problem for resource-constrained devices. In the past, pruning was typically accomplished by ranking or penalizing weights based on criteria like magnitude and removing low-ranked weights before retraining the remaining ones. Pruning strategies may also involve removing neurons from the network in order to achieve the desired reduction in network size. We formulate pruning as an optimization problem with the objective of minimizing misclassifications by selecting specific weights. To accomplish this, we have introduced the concept of chaos in learning (Lyapunov exponents) via weight updates and exploiting causality to identify the causal weights responsible for misclassification. Such a pruned network maintains the original performance and retains feature explainability.
</details>
<details>
<summary>摘要</summary>
减小神经网络（减少），不影响其性能，是资源受限设备上非常重要的问题。以前，减少通常通过对权重进行排名或惩罚，根据权重的大小和重要性来移除低排名的权重，然后再 retrained 剩下的权重来实现网络的减少。减少策略可能还会涉及到从网络中移除神经元，以实现所需的网络大小减少。我们将减少形式为学习过程中权重更新中引入了混乱（Lyapunov 分数）的概念，并通过利用 causality 来确定引起错分的权重。这样的减少网络可以保持原始性能，同时保持特征解释性。
</details></li>
</ul>
<hr>
<h2 id="Finding-emergence-in-data-causal-emergence-inspired-dynamics-learning"><a href="#Finding-emergence-in-data-causal-emergence-inspired-dynamics-learning" class="headerlink" title="Finding emergence in data: causal emergence inspired dynamics learning"></a>Finding emergence in data: causal emergence inspired dynamics learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09952">http://arxiv.org/abs/2308.09952</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingzhe Yang, Zhipeng Wang, Kaiwei Liu, Yingqi Rong, Bing Yuan, Jiang Zhang</li>
<li>for: This paper aims to develop a machine learning framework to model complex dynamical systems in a data-driven manner, with a focus on capturing emergent behaviors and properties.</li>
<li>methods: The proposed framework draws inspiration from the theory of causal emergence and uses maximum effective information (EI) to learn macro-dynamics within an emergent latent space.</li>
<li>results: The proposed framework is effective in capturing emergent patterns, learning the coarse-graining strategy, and quantifying the degree of causal emergence in the data. Additionally, the model demonstrates superior generalization ability on environments different from the training dataset.Here’s the same information in Simplified Chinese:</li>
<li>for: 这篇论文目标是通过数据驱动方式模型复杂的动力系统，强调捕捉出emergent行为和质量。</li>
<li>methods: 提议的框架启发自 causal emergence 理论，使用最大有效信息（EI）来学习macro-dinamics在emergent latent space中。</li>
<li>results: 提议的框架能够成功捕捉emergentpattern，学习卷积策略，并量化数据中的 causal emergence度。此外，模型在不同于训练集环境下的实验也表现出了superior generalization能力。<details>
<summary>Abstract</summary>
Modelling complex dynamical systems in a data-driven manner is challenging due to the presence of emergent behaviors and properties that cannot be directly captured by micro-level observational data. Therefore, it is crucial to develop a model that can effectively capture emergent dynamics at the macro-level and quantify emergence based on the available data. Drawing inspiration from the theory of causal emergence, this paper introduces a machine learning framework aimed at learning macro-dynamics within an emergent latent space. The framework achieves this by maximizing the effective information (EI) to obtain a macro-dynamics model with stronger causal effects. Experimental results on both simulated and real data demonstrate the effectiveness of the proposed framework. Not only does it successfully capture emergent patterns, but it also learns the coarse-graining strategy and quantifies the degree of causal emergence in the data. Furthermore, experiments conducted on environments different from the training dataset highlight the superior generalization ability of our model.
</details>
<details>
<summary>摘要</summary>
模拟复杂动力系统在数据驱动方式下是一项挑战，因为存在不可预测的 emergent 行为和质量。为了有效地捕捉 emergent 动力，这篇论文提出了一种基于机器学习的框架，该框架在 emergent 尘肤空间中学习 macro-动力。该框架通过最大化有效信息（EI）来获得具有更强的 causal 效应的 macro-动力模型。实验结果表明，该模型不仅可以成功捕捉 emergent 模式，还可以学习 coarse-graining 策略并量化数据中的 causal emergence 度。此外，在训练数据集以外的环境下进行的实验也表明了我们的模型具有更高的总体化能力。
</details></li>
</ul>
<hr>
<h2 id="Study-on-the-effectiveness-of-AutoML-in-detecting-cardiovascular-disease"><a href="#Study-on-the-effectiveness-of-AutoML-in-detecting-cardiovascular-disease" class="headerlink" title="Study on the effectiveness of AutoML in detecting cardiovascular disease"></a>Study on the effectiveness of AutoML in detecting cardiovascular disease</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09947">http://arxiv.org/abs/2308.09947</a></li>
<li>repo_url: None</li>
<li>paper_authors: T. V. Afanasieva, A. P. Kuzlyakin, A. V. Komolov<br>for: 这篇论文主要是为了探讨机器学习技术在抗生素敏感疾病预测方面的应用。methods: 这篇论文使用了自动机器学习（AutoML）技术，combined five data sets of cardiovascular disease indicators from the UCI Machine Learning Repository，并用了十三种基本机器学习模型（KNeighborsUnif、KNeighborsDist、LightGBMXT、LightGBM、RandomForestGini、RandomForestEntr、CatBoost、ExtraTreesGini、ExtraTreesEntr、NeuralNetFastA、XGBoost、NeuralNetTorch、LightGBMLarge）。results: 研究发现，自动机器学习模型的结构对于抗生素敏感疾病预测是不同的，具体取决于使用的基本模型的效率和准确率，以及数据预处理方法，尤其是数据标准化技术。研究发现，当将源数据标准化为二进制值时，自动机器学习模型的准确率最高，达到了87.41%至92.3%之间的范围。<details>
<summary>Abstract</summary>
Cardiovascular diseases are widespread among patients with chronic noncommunicable diseases and are one of the leading causes of death, including in the working age. The article presents the relevance of the development and application of patient-oriented systems, in which machine learning (ML) is a promising technology that allows predicting cardiovascular diseases. Automated machine learning (AutoML) makes it possible to simplify and speed up the process of developing AI/ML applications, which is key in the development of patient-oriented systems by application users, in particular medical specialists. The authors propose a framework for the application of automatic machine learning and three scenarios that allowed for data combining five data sets of cardiovascular disease indicators from the UCI Machine Learning Repository to investigate the effectiveness in detecting this class of diseases. The study investigated one AutoML model that used and optimized the hyperparameters of thirteen basic ML models (KNeighborsUnif, KNeighborsDist, LightGBMXT, LightGBM, RandomForestGini, RandomForestEntr, CatBoost, ExtraTreesGini, ExtraTreesEntr, NeuralNetFastA, XGBoost, NeuralNetTorch, LightGBMLarge) and included the most accurate models in the weighted ensemble. The results of the study showed that the structure of the AutoML model for detecting cardiovascular diseases depends not only on the efficiency and accuracy of the basic models used, but also on the scenarios for preprocessing the initial data, in particular, on the technique of data normalization. The comparative analysis showed that the accuracy of the AutoML model in detecting cardiovascular disease varied in the range from 87.41% to 92.3%, and the maximum accuracy was obtained when normalizing the source data into binary values, and the minimum was obtained when using the built-in AutoML technique.
</details>
<details>
<summary>摘要</summary>
心血管疾病是 chronic noncommunicable diseases 中广泛存在的，是死亡的主要原因之一，包括工作年龄期。本文介绍了patient-oriented系统的开发和应用的重要性，机器学习（ML）技术在心血管疾病预测方面的潜在性。自动机器学习（AutoML）技术可以简化和加速AI/ML应用程序的开发过程，这对医疗专业人员 particularly medical specialists 来说是关键。作者提出了一个自动机器学习框架，并通过将五个心血管疾病指标数据集 combine  investigate the effectiveness of detecting this class of diseases。研究使用了一个AutoML模型，该模型使用和优化了十三种基本ML模型（KNeighborsUnif、KNeighborsDist、LightGBMXT、LightGBM、RandomForestGini、RandomForestEntr、CatBoost、ExtraTreesGini、ExtraTreesEntr、NeuralNetFastA、XGBoost、NeuralNetTorch、LightGBMLarge），并包括最佳模型在权重 ensemble 中。研究结果表明，自动机器学习模型的结构在检测心血管疾病方面取决于基本模型的效率和准确率，以及数据预处理方法，特别是数据 нор化技术。比较分析表明，自动机器学习模型在检测心血管疾病方面的准确率在87.41%到92.3%之间，最高准确率为将源数据 нор化为二进制值，最低准确率为使用AutoML技术。
</details></li>
</ul>
<hr>
<h2 id="Dual-Branch-Deep-Learning-Network-for-Detection-and-Stage-Grading-of-Diabetic-Retinopathy"><a href="#Dual-Branch-Deep-Learning-Network-for-Detection-and-Stage-Grading-of-Diabetic-Retinopathy" class="headerlink" title="Dual Branch Deep Learning Network for Detection and Stage Grading of Diabetic Retinopathy"></a>Dual Branch Deep Learning Network for Detection and Stage Grading of Diabetic Retinopathy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09945">http://arxiv.org/abs/2308.09945</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hossein Shakibania, Sina Raoufi, Behnam Pourafkham, Hassan Khotanlou, Muharram Mansoorizadeh<br>for: 这个研究的目的是提出一种基于深度学习的糖尿病肠病诊断和分级方法，使用单一的背景照片。methods: 该模型使用了传输学习，利用两个现有的状态流程模型作为特征提取器，并在新的数据集上进行细化。results: 该模型在APTOS 2019 数据集上表现出色，在糖尿病诊断和分级方面都高于现有文献。对于二分类问题，该方法达到了98.50%的准确率、99.46%的敏感度和97.51%的特异度。在分级问题上，它达到了93.00%的квадратиче weights κ值、89.60%的准确率、89.60%的敏感度和97.72%的特异度。该方法可以作为糖尿病肠病诊断和分级工具，为临床决策和患者护理提供重要的帮助。<details>
<summary>Abstract</summary>
Diabetic retinopathy is a severe complication of diabetes that can lead to permanent blindness if not treated promptly. Early and accurate diagnosis of the disease is essential for successful treatment. This paper introduces a deep learning method for the detection and stage grading of diabetic retinopathy, using a single fundus retinal image. Our model utilizes transfer learning, employing two state-of-the-art pre-trained models as feature extractors and fine-tuning them on a new dataset. The proposed model is trained on a large multi-center dataset, including the APTOS 2019 dataset, obtained from publicly available sources. It achieves remarkable performance in diabetic retinopathy detection and stage classification on the APTOS 2019, outperforming the established literature. For binary classification, the proposed approach achieves an accuracy of 98.50%, a sensitivity of 99.46%, and a specificity of 97.51%. In stage grading, it achieves a quadratic weighted kappa of 93.00%, an accuracy of 89.60%, a sensitivity of 89.60%, and a specificity of 97.72%. The proposed approach serves as a reliable screening and stage grading tool for diabetic retinopathy, offering significant potential to enhance clinical decision-making and patient care.
</details>
<details>
<summary>摘要</summary>
糖尿病 RETINOPATHY 是糖尿病的一种严重的并发症，如果不及时治疗，可能会导致永久失明。早期和准确的诊断是成功治疗的关键。这篇论文介绍了一种深度学习方法，用于检测和评分糖尿病 RETINOPATHY，使用单个背部眼图像。我们的模型利用传输学习，使用两个状态之前的权威模型作为特征提取器，并在新数据集上练习 fine-tuning。我们的模型在APTOS 2019 数据集上获得了优秀的性能，在糖尿病 RETINOPATHY 检测和评分方面超过了现有文献。对于二分类，我们的方法达到了 98.50%的准确率，99.46%的敏感度和 97.51%的特异度。在评分方面，我们的方法达到了 93.00%的QUADRATIC WEIGHTED KAPPA，89.60%的准确率，89.60%的敏感度和 97.72%的特异度。我们的方法可以作为糖尿病 RETINOPATHY 检测和评分工具，为临床决策和患者护理提供了重要的可靠性。
</details></li>
</ul>
<hr>
<h2 id="On-the-Robustness-of-Open-World-Test-Time-Training-Self-Training-with-Dynamic-Prototype-Expansion"><a href="#On-the-Robustness-of-Open-World-Test-Time-Training-Self-Training-with-Dynamic-Prototype-Expansion" class="headerlink" title="On the Robustness of Open-World Test-Time Training: Self-Training with Dynamic Prototype Expansion"></a>On the Robustness of Open-World Test-Time Training: Self-Training with Dynamic Prototype Expansion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09942">http://arxiv.org/abs/2308.09942</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yushu-li/owttt">https://github.com/yushu-li/owttt</a></li>
<li>paper_authors: Yushu Li, Xun Xu, Yongyi Su, Kui Jia</li>
<li>for: 该研究旨在提高unknown target domain distribution下的深度学习模型的泛化性，并且在低延迟下实现。</li>
<li>methods: 该研究使用了test-time training&#x2F;adaptation（TTT&#x2F;TTA）技术，并提出了一种 adaptive strong OOD pruning 技术和动态扩展 prototype 技术来提高 OWTTT 的 Robustness。</li>
<li>results: 该研究在 5 个 OWTTT benchmark 上达到了state-of-the-art 性能，并且提供了一个可用的代码库（<a target="_blank" rel="noopener" href="https://github.com/Yushu-Li/OWTTT%EF%BC%89%E3%80%82">https://github.com/Yushu-Li/OWTTT）。</a><details>
<summary>Abstract</summary>
Generalizing deep learning models to unknown target domain distribution with low latency has motivated research into test-time training/adaptation (TTT/TTA). Existing approaches often focus on improving test-time training performance under well-curated target domain data. As figured out in this work, many state-of-the-art methods fail to maintain the performance when the target domain is contaminated with strong out-of-distribution (OOD) data, a.k.a. open-world test-time training (OWTTT). The failure is mainly due to the inability to distinguish strong OOD samples from regular weak OOD samples. To improve the robustness of OWTTT we first develop an adaptive strong OOD pruning which improves the efficacy of the self-training TTT method. We further propose a way to dynamically expand the prototypes to represent strong OOD samples for an improved weak/strong OOD data separation. Finally, we regularize self-training with distribution alignment and the combination yields the state-of-the-art performance on 5 OWTTT benchmarks. The code is available at https://github.com/Yushu-Li/OWTTT.
</details>
<details>
<summary>摘要</summary>
通用深度学习模型到未知目标频谱分布的泛化，以低延迟实现，已经引起了研究者的关注。现有的方法通常是在已经批处理的目标频谱数据上提高测试时训练性能。然而，在受到强度外部数据杂化（OOD）的情况下，许多状态态态方法表现不佳，这主要是因为无法 отличи出强度OOD样本和软OOD样本。为了改善OWTTT的 Robustness，我们首先开发了适应强度OOD排除，使自我训练TTT方法更加高效。然后，我们提议在运行时动态扩展prototype，以便更好地分离强度OOD和软OOD样本。最后，我们将自我训练与分布AlignmentREG regularization相结合，这种结合得到了5个OWTTT benchmark中的状态态表现。相关代码可以在https://github.com/Yushu-Li/OWTTT中找到。
</details></li>
</ul>
<hr>
<h2 id="Practical-Anomaly-Detection-over-Multivariate-Monitoring-Metrics-for-Online-Services"><a href="#Practical-Anomaly-Detection-over-Multivariate-Monitoring-Metrics-for-Online-Services" class="headerlink" title="Practical Anomaly Detection over Multivariate Monitoring Metrics for Online Services"></a>Practical Anomaly Detection over Multivariate Monitoring Metrics for Online Services</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09937">http://arxiv.org/abs/2308.09937</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/OpsPAI/CMAnomaly">https://github.com/OpsPAI/CMAnomaly</a></li>
<li>paper_authors: Jinyang Liu, Tianyi Yang, Zhuangbin Chen, Yuxin Su, Cong Feng, Zengyin Yang, Michael R. Lyu</li>
<li>for: 这篇论文是为了提出一个基于协力机器的多变数监控指标异常探测框架，以提高现有系统监控中的异常探测效能。</li>
<li>methods: 本论文使用了一个名为CMAnomaly的异常探测框架，其中包括一个基于协力机器的机制，可以有效地捕捉多变数监控指标之间的相互作用，并且可以使用cost-effective模型来利用这些相互作用进行异常探测。</li>
<li>results: 根据实验结果，CMAnomaly比基于现有模型的 benchmark 高出6.77%到10.68%，并且可以在10倍至20倍的速度下进行异常探测。此外，本论文还详细介绍了在Huawei Cloud上部署CMAnomaly的经验。<details>
<summary>Abstract</summary>
As modern software systems continue to grow in terms of complexity and volume, anomaly detection on multivariate monitoring metrics, which profile systems' health status, becomes more and more critical and challenging. In particular, the dependency between different metrics and their historical patterns plays a critical role in pursuing prompt and accurate anomaly detection. Existing approaches fall short of industrial needs for being unable to capture such information efficiently. To fill this significant gap, in this paper, we propose CMAnomaly, an anomaly detection framework on multivariate monitoring metrics based on collaborative machine. The proposed collaborative machine is a mechanism to capture the pairwise interactions along with feature and temporal dimensions with linear time complexity. Cost-effective models can then be employed to leverage both the dependency between monitoring metrics and their historical patterns for anomaly detection. The proposed framework is extensively evaluated with both public data and industrial data collected from a large-scale online service system of Huawei Cloud. The experimental results demonstrate that compared with state-of-the-art baseline models, CMAnomaly achieves an average F1 score of 0.9494, outperforming baselines by 6.77% to 10.68%, and runs 10X to 20X faster. Furthermore, we also share our experience of deploying CMAnomaly in Huawei Cloud.
</details>
<details>
<summary>摘要</summary>
现代软件系统的复杂性和规模在不断增长，异常检测在多变量监控指标上变得越来越重要和挑战。特别是依赖于不同指标之间的关系以及历史 patrón 的信息在追踪系统的健康状态非常重要。现有的方法无法fficiently capture这些信息，为此，在本文中，我们提出了 CMAnomaly，一种基于合作机器的异常检测框架。该框架使用了对feature和时间维度进行对称的机制，以linear time complexityCapture pairwise interactions。然后，可以使用cost-effective模型来利用监控指标之间的依赖关系和历史 patrón 进行异常检测。我们对公共数据集和industrial数据集进行了广泛的evaluation，结果表明，相比州标baseline模型，CMAnomaly在F1分数方面获得了0.9494的平均分，高于基eline模型6.77%到10.68%，并且运行速度比基eline模型快10到20倍。此外，我们还分享了在Huawei Cloud中部署 CMAnomaly的经验。
</details></li>
</ul>
<hr>
<h2 id="BLIVA-A-Simple-Multimodal-LLM-for-Better-Handling-of-Text-Rich-Visual-Questions"><a href="#BLIVA-A-Simple-Multimodal-LLM-for-Better-Handling-of-Text-Rich-Visual-Questions" class="headerlink" title="BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual Questions"></a>BLIVA: A Simple Multimodal LLM for Better Handling of Text-Rich Visual Questions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09936">http://arxiv.org/abs/2308.09936</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlpc-ucsd/bliva">https://github.com/mlpc-ucsd/bliva</a></li>
<li>paper_authors: Wenbo Hu, Yifan Xu, Yi Li, Weiyue Li, Zeyuan Chen, Zhuowen Tu</li>
<li>for: 该研究旨在解决现实世界中常见的图像涉及文本场景下的视觉问答任务，即使图像具有文本背景。</li>
<li>methods: 该研究使用了一种名为BLIVA的新方法，它是基于InstructBLIP的增强版本，通过直接将图像中的编码补丁直接输入到大语言模型中，以帮助模型更好地捕捉图像中的细节。</li>
<li>results: 实验证明，BLIVA比基elineInstructBLIP有17.76%的提升（在OCR-VQAbenchmark中）和7.9%的提升（在Visual Spatial Reasoning benchmark中），并且在实际世界中的图像处理 tasks中表现出色，无论图像中存在文本或不存在。<details>
<summary>Abstract</summary>
Vision Language Models (VLMs), which extend Large Language Models (LLM) by incorporating visual understanding capability, have demonstrated significant advancements in addressing open-ended visual question-answering (VQA) tasks. However, these models cannot accurately interpret images infused with text, a common occurrence in real-world scenarios. Standard procedures for extracting information from images often involve learning a fixed set of query embeddings. These embeddings are designed to encapsulate image contexts and are later used as soft prompt inputs in LLMs. Yet, this process is limited to the token count, potentially curtailing the recognition of scenes with text-rich context. To improve upon them, the present study introduces BLIVA: an augmented version of InstructBLIP with Visual Assistant. BLIVA incorporates the query embeddings from InstructBLIP and also directly projects encoded patch embeddings into the LLM, a technique inspired by LLaVA. This approach assists the model to capture intricate details potentially missed during the query decoding process. Empirical evidence demonstrates that our model, BLIVA, significantly enhances performance in processing text-rich VQA benchmarks (up to 17.76\% in OCR-VQA benchmark) and in undertaking typical VQA benchmarks (up to 7.9\% in Visual Spatial Reasoning benchmark), comparing to our baseline InstructBLIP. BLIVA demonstrates significant capability in decoding real-world images, irrespective of text presence. To demonstrate the broad industry applications enabled by BLIVA, we evaluate the model using a new dataset comprising YouTube thumbnails paired with question-answer sets across 13 diverse categories. For researchers interested in further exploration, our code and models are freely accessible at https://github.com/mlpc-ucsd/BLIVA.git
</details>
<details>
<summary>摘要</summary>
大型语言模型（VLM），它们将大型语言模型（LLM）与视觉理解能力结合，在开放式视觉问答任务上达到了显著的进步。然而，这些模型无法准确地理解带有文本的图像，这是现实生活中常见的情况。标准的图像信息提取方法通常包括学习固定的查询嵌入。这些嵌入用于在LLM中作为软提示输入，然而这种方法受限于字符串数量，可能导致捕捉场景中的文本背景信息。为了改进它们，本研究提出了BLIVA：一种基于InstructBLIP的增强版，它将InstructBLIP的查询嵌入与LLM直接进行编码覆盖，这种方法源于LLaVA。这种方法帮助模型捕捉文本背景信息中的细节，可能在查询解码过程中被遗弃。实验证明，我们的模型BLIVA在处理文本含量高的VQA标准benchmark（OCRA-VQA标准benchmark）中表现出色，提高了17.76%，以及在典型VQA标准benchmark（Visual Spatial Reasoning标准benchmark）中提高了7.9%。BLIVA在真实世界中处理图像，无论图像中是否存在文本。为了展示BLIVA在广泛的工业应用中的可能性，我们使用了一个新的YouTube封面集合，与问题集合在13种不同的类别中进行了评估。对于关心进一步探索的研究人员，我们在https://github.com/mlpc-ucsd/BLIVA.git中提供了代码和模型。
</details></li>
</ul>
<hr>
<h2 id="Analyzing-Quantization-in-TVM"><a href="#Analyzing-Quantization-in-TVM" class="headerlink" title="Analyzing Quantization in TVM"></a>Analyzing Quantization in TVM</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10905">http://arxiv.org/abs/2308.10905</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingfei Guo</li>
<li>for: 这个论文主要是研究 TVM 中对weight tensor的量化以提高推理时间和内存占用率，但是8位量化并不符合预期，实际比非量化版本更慢。</li>
<li>methods: 该论文使用了 TVM 进行量化和低位计算，并 investigate 了量化下的性能问题，并评估了不同的优化策略。</li>
<li>results: 该论文通过修复图构建错误和测试多种优化策略，最终实现了对 compute-bound 和 memory-bound 任务的优化，并实现了163.88%和194.98%的推理时间提升。<details>
<summary>Abstract</summary>
There has been many papers in academic literature on quantizing weight tensors in deep learning models to reduce inference latency and memory footprint. TVM also has the ability to quantize weights and support low-bit computations. Although quantization is typically expected to improve inference time, in TVM, the performance of 8-bit quantization does not meet the expectations. Typically, when applying 8-bit quantization to a deep learning model, it is usually expected to achieve around 50% of the full-precision inference time. However, in this particular case, not only does the quantized version fail to achieve the desired performance boost, but it actually performs worse, resulting in an inference time that is about 2 times as slow as the non-quantized version. In this project, we thoroughly investigate the reasons behind the underperformance and assess the compatibility and optimization opportunities of 8-bit quantization in TVM. We discuss the optimization of two different types of tasks: computation-bound and memory-bound, and provide a detailed comparison of various optimization techniques in TVM. Through the identification of performance issues, we have successfully improved quantization by addressing a bug in graph building. Furthermore, we analyze multiple optimization strategies to achieve the optimal quantization result. The best experiment achieves 163.88% improvement compared with the TVM compiled baseline in inference time for the compute-bound task and 194.98% for the memory-bound task.
</details>
<details>
<summary>摘要</summary>
在学术文献中有很多论著关于深度学习模型的量化权重tensor以降低推理延迟和内存占用。TVM也具有量化权重和低位计算的能力。although quantization is typically expected to improve inference time, in TVM, the performance of 8-bit quantization does not meet expectations. Typically, when applying 8-bit quantization to a deep learning model, it is usually expected to achieve around 50% of the full-precision inference time. However, in this particular case, not only does the quantized version fail to achieve the desired performance boost, but it actually performs worse, resulting in an inference time that is about 2 times as slow as the non-quantized version. In this project, we thoroughly investigate the reasons behind the underperformance and assess the compatibility and optimization opportunities of 8-bit quantization in TVM. We discuss the optimization of two different types of tasks: computation-bound and memory-bound, and provide a detailed comparison of various optimization techniques in TVM. Through the identification of performance issues, we have successfully improved quantization by addressing a bug in graph building. Furthermore, we analyze multiple optimization strategies to achieve the optimal quantization result. The best experiment achieves 163.88% improvement compared with the TVM compiled baseline in inference time for the compute-bound task and 194.98% for the memory-bound task.
</details></li>
</ul>
<hr>
<h2 id="East-Efficient-and-Accurate-Secure-Transformer-Framework-for-Inference"><a href="#East-Efficient-and-Accurate-Secure-Transformer-Framework-for-Inference" class="headerlink" title="East: Efficient and Accurate Secure Transformer Framework for Inference"></a>East: Efficient and Accurate Secure Transformer Framework for Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09923">http://arxiv.org/abs/2308.09923</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanchao Ding, Hua Guo, Yewei Guan, Weixin Liu, Jiarong Huo, Zhenyu Guan, Xiyong Zhang</li>
<li>for: 提高Transformer推理的隐私保护</li>
<li>methods: 提出一个名为”East”的框架，包括新的匿名分割多项式评估算法和特殊防范协议，以提高安全性和准确性</li>
<li>results: 对BERT进行应用，并与不加密推理相比，推理精度保持一致，与Iron相比，通信量下降1.8倍，运行时间下降1.2倍<details>
<summary>Abstract</summary>
Transformer has been successfully used in practical applications, such as ChatGPT, due to its powerful advantages. However, users' input is leaked to the model provider during the service. With people's attention to privacy, privacy-preserving Transformer inference is on the demand of such services. Secure protocols for non-linear functions are crucial in privacy-preserving Transformer inference, which are not well studied. Thus, designing practical secure protocols for non-linear functions is hard but significant to model performance. In this work, we propose a framework \emph{East} to enable efficient and accurate secure Transformer inference. Firstly, we propose a new oblivious piecewise polynomial evaluation algorithm and apply it to the activation functions, which reduces the runtime and communication of GELU by over 1.5$\times$ and 2.5$\times$, compared to prior arts. Secondly, the secure protocols for softmax and layer normalization are carefully designed to faithfully maintain the desired functionality. Thirdly, several optimizations are conducted in detail to enhance the overall efficiency. We applied \emph{East} to BERT and the results show that the inference accuracy remains consistent with the plaintext inference without fine-tuning. Compared to Iron, we achieve about 1.8$\times$ lower communication within 1.2$\times$ lower runtime.
</details>
<details>
<summary>摘要</summary>
“transformer”已经在实际应用中得到了成功，例如chatGPT，因为它具有强大的优势。然而，用户的输入会被提供者 during the service，导致隐私问题。为了保护隐私，隐私保护的transformer推察是非常重要的。但是， Designing practical secure protocols for non-linear functions is hard but significant to model performance。在这个工作中，我们提出了一个名为“East”的框架，以实现有效和精确的隐私保护的transformer推察。首先，我们提出了一个新的隐私检查法，并将其应用到活化函数上，这减少了runtime和通信量，比对实际应用中的优先输出还要好。其次，我们对软max和层normalization的安全协议进行了谨慎的设计，以保持所需的功能。最后，我们在细节上进行了详细的优化，以提高整体的效率。我们将“East”应用到BERT，结果显示，在不进行微调的情况下，推察精度与普通的推察相同。与Iron相比，我们的通信量为1.8倍，并且runtime为1.2倍。
</details></li>
</ul>
<hr>
<h2 id="EGANS-Evolutionary-Generative-Adversarial-Network-Search-for-Zero-Shot-Learning"><a href="#EGANS-Evolutionary-Generative-Adversarial-Network-Search-for-Zero-Shot-Learning" class="headerlink" title="EGANS: Evolutionary Generative Adversarial Network Search for Zero-Shot Learning"></a>EGANS: Evolutionary Generative Adversarial Network Search for Zero-Shot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09915">http://arxiv.org/abs/2308.09915</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shiming Chen, Shihuang Chen, Wenjin Hou, Weiping Ding, Xinge You</li>
<li>for: 提高零shot学习（ZSL）中的类别识别率，使用生成模型（如生成对抗网络（GAN））synthesize视觉样本，以提高ZSL的性能。</li>
<li>methods: 提出了一种自然选择的生成器网络搜索方法（EGANS），通过协同对抗进行 neural architecture search，以获得适应性和稳定性好的生成器和批判器。</li>
<li>results: 在标准CUB、SUN、AWA2和FLO数据集上，EGANS consistently提高了现有的生成ZSL方法的性能，表明了生成ZSL中的进化性搜索在ZSL中的潜在应用。<details>
<summary>Abstract</summary>
Zero-shot learning (ZSL) aims to recognize the novel classes which cannot be collected for training a prediction model. Accordingly, generative models (e.g., generative adversarial network (GAN)) are typically used to synthesize the visual samples conditioned by the class semantic vectors and achieve remarkable progress for ZSL. However, existing GAN-based generative ZSL methods are based on hand-crafted models, which cannot adapt to various datasets/scenarios and fails to model instability. To alleviate these challenges, we propose evolutionary generative adversarial network search (termed EGANS) to automatically design the generative network with good adaptation and stability, enabling reliable visual feature sample synthesis for advancing ZSL. Specifically, we adopt cooperative dual evolution to conduct a neural architecture search for both generator and discriminator under a unified evolutionary adversarial framework. EGANS is learned by two stages: evolution generator architecture search and evolution discriminator architecture search. During the evolution generator architecture search, we adopt a many-to-one adversarial training strategy to evolutionarily search for the optimal generator. Then the optimal generator is further applied to search for the optimal discriminator in the evolution discriminator architecture search with a similar evolution search algorithm. Once the optimal generator and discriminator are searched, we entail them into various generative ZSL baselines for ZSL classification. Extensive experiments show that EGANS consistently improve existing generative ZSL methods on the standard CUB, SUN, AWA2 and FLO datasets. The significant performance gains indicate that the evolutionary neural architecture search explores a virgin field in ZSL.
</details>
<details>
<summary>摘要</summary>
EGANS采用了合作双向进化来进行神经网络搜索，包括生成器和分类器。在生成器搜索阶段，我们采用了多对一的对抗训练策略，通过进化搜索来找到最佳的生成器。然后，我们使用类似的进化搜索算法来搜索最佳的分类器。一旦找到了最佳的生成器和分类器，我们就将它们与不同的生成ZSL基线方法结合，以进行ZSL分类。我们的实验表明，EGANS可以在标准的CUB、SUN、AWA2和FLO数据集上提供remarkable的性能提升，这表明了进化神经网络搜索在ZSL中的可能性。
</details></li>
</ul>
<hr>
<h2 id="Never-Explore-Repeatedly-in-Multi-Agent-Reinforcement-Learning"><a href="#Never-Explore-Repeatedly-in-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Never Explore Repeatedly in Multi-Agent Reinforcement Learning"></a>Never Explore Repeatedly in Multi-Agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09909">http://arxiv.org/abs/2308.09909</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenghao Li, Tonghan Wang, Chongjie Zhang, Qianchuan Zhao</li>
<li>for: 本研究旨在提高多智能体强化学习中的探索性能，通过采用内在动机。</li>
<li>methods: 本文提出了动态奖励扩大方法，通过稳定既已探索的区域的奖励，促进更广泛的探索。</li>
<li>results: 实验结果表明，本方法可以在Google研究足球和StarCraft II微管理任务中提高表现，特别在罕见奖励 Setting下。<details>
<summary>Abstract</summary>
In the realm of multi-agent reinforcement learning, intrinsic motivations have emerged as a pivotal tool for exploration. While the computation of many intrinsic rewards relies on estimating variational posteriors using neural network approximators, a notable challenge has surfaced due to the limited expressive capability of these neural statistics approximators. We pinpoint this challenge as the "revisitation" issue, where agents recurrently explore confined areas of the task space. To combat this, we propose a dynamic reward scaling approach. This method is crafted to stabilize the significant fluctuations in intrinsic rewards in previously explored areas and promote broader exploration, effectively curbing the revisitation phenomenon. Our experimental findings underscore the efficacy of our approach, showcasing enhanced performance in demanding environments like Google Research Football and StarCraft II micromanagement tasks, especially in sparse reward settings.
</details>
<details>
<summary>摘要</summary>
在多智能奖励学习领域，内生动机被视为探索的重要工具。然而，计算许多内生奖励的 neural network 近似器表现有限，导致“再次探索”问题的出现，即代理人重复探索任务空间中的封闭区域。为解决此问题，我们提出了动态奖励缩放方法。这种方法通过稳定前期探索区域中的奖励变化，激励代理人更广泛探索，从而缓解再次探索现象。我们的实验结果表明，我们的方法在 Google Research Football 和 StarCraft II 微管理任务中表现出色，尤其在罕见奖励设置下。
</details></li>
</ul>
<hr>
<h2 id="Imputing-Brain-Measurements-Across-Data-Sets-via-Graph-Neural-Networks"><a href="#Imputing-Brain-Measurements-Across-Data-Sets-via-Graph-Neural-Networks" class="headerlink" title="Imputing Brain Measurements Across Data Sets via Graph Neural Networks"></a>Imputing Brain Measurements Across Data Sets via Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09907">http://arxiv.org/abs/2308.09907</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yixin Wang, Wei Peng, Susan F. Tapert, Qingyu Zhao, Kilian M. Pohl</li>
<li>for: The paper aims to address the issue of missing measurements in publicly available structural MRI data sets, specifically the curvature scores computed by Freesurfer, by proposing a deep learning-based imputation method called Demographic Aware Graph-based Imputation (DAGI).</li>
<li>methods: The DAGI method uses a graph neural network (GNN) to model the dependencies between brain Region of Interests (ROIs) and accounts for demographic differences in brain measurements by feeding the graph encoding into a parallel architecture that simultaneously optimizes a graph decoder to impute values and a classifier to predict demographic factors.</li>
<li>results: The proposed DAGI method is tested on imputing missing Freesurfer measurements of the Adolescent Brain Cognitive Development (ABCD) Study data set (N&#x3D;3760) by training the predictor on publicly released data from the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA, N&#x3D;540).<details>
<summary>Abstract</summary>
Publicly available data sets of structural MRIs might not contain specific measurements of brain Regions of Interests (ROIs) that are important for training machine learning models. For example, the curvature scores computed by Freesurfer are not released by the Adolescent Brain Cognitive Development (ABCD) Study. One can address this issue by simply reapplying Freesurfer to the data set. However, this approach is generally computationally and labor intensive (e.g., requiring quality control). An alternative is to impute the missing measurements via a deep learning approach. However, the state-of-the-art is designed to estimate randomly missing values rather than entire measurements. We therefore propose to re-frame the imputation problem as a prediction task on another (public) data set that contains the missing measurements and shares some ROI measurements with the data sets of interest. A deep learning model is then trained to predict the missing measurements from the shared ones and afterwards is applied to the other data sets. Our proposed algorithm models the dependencies between ROI measurements via a graph neural network (GNN) and accounts for demographic differences in brain measurements (e.g. sex) by feeding the graph encoding into a parallel architecture. The architecture simultaneously optimizes a graph decoder to impute values and a classifier in predicting demographic factors. We test the approach, called Demographic Aware Graph-based Imputation (DAGI), on imputing those missing Freesurfer measurements of ABCD (N=3760) by training the predictor on those publicly released by the National Consortium on Alcohol and Neurodevelopment in Adolescence (NCANDA, N=540)...
</details>
<details>
<summary>摘要</summary>
公共可用数据集的结构MRI数据可能不包含特定的脑区域关注点（ROIs）的准确量测量。例如，ABCDFreesurfer的曲线分数不由ABCDFreesurfer发布。一种解决方法是简单地重新应用Freesurfer到数据集中。然而，这种方法通常是计算机和劳动力密集的（例如，需要质量控制）。另一种方法是使用深度学习方法进行填充。然而，现状的深度学习方法是随机缺失值的估计而不是整个测量。我们因此提议将填充问题重新定义为一个预测任务，使用另一个（公共）数据集，该数据集包含缺失的测量和与数据集集中的ROIs进行共享。然后，我们将深度学习模型训练以预测缺失测量，并在训练过程中考虑ROIs之间的依赖关系。我们称这种方法为“规格意识 Graph-based 填充”（DAGI）。我们在NCANDA（N=540）公共发布的数据集上训练了预测器，并在ABCDFreesurfer（N=3760）中进行了填充。
</details></li>
</ul>
<hr>
<h2 id="DPMAC-Differentially-Private-Communication-for-Cooperative-Multi-Agent-Reinforcement-Learning"><a href="#DPMAC-Differentially-Private-Communication-for-Cooperative-Multi-Agent-Reinforcement-Learning" class="headerlink" title="DPMAC: Differentially Private Communication for Cooperative Multi-Agent Reinforcement Learning"></a>DPMAC: Differentially Private Communication for Cooperative Multi-Agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09902">http://arxiv.org/abs/2308.09902</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/CANVOLCANO/DPMAC">https://github.com/CANVOLCANO/DPMAC</a></li>
<li>paper_authors: Canzhe Zhao, Yanjie Ze, Jing Dong, Baoxiang Wang, Shuai Li</li>
<li>for: 防止多代理人学习中泄露敏感信息</li>
<li>methods: 使用（ε，δ）敏感数据隐私保证，采用Stochastic MessageSender，自动调整学习后的消息分布</li>
<li>results: 实验显示DPMAC在隐私保护场景下比基eline方法有明显优势<details>
<summary>Abstract</summary>
Communication lays the foundation for cooperation in human society and in multi-agent reinforcement learning (MARL). Humans also desire to maintain their privacy when communicating with others, yet such privacy concern has not been considered in existing works in MARL. To this end, we propose the \textit{differentially private multi-agent communication} (DPMAC) algorithm, which protects the sensitive information of individual agents by equipping each agent with a local message sender with rigorous $(\epsilon, \delta)$-differential privacy (DP) guarantee. In contrast to directly perturbing the messages with predefined DP noise as commonly done in privacy-preserving scenarios, we adopt a stochastic message sender for each agent respectively and incorporate the DP requirement into the sender, which automatically adjusts the learned message distribution to alleviate the instability caused by DP noise. Further, we prove the existence of a Nash equilibrium in cooperative MARL with privacy-preserving communication, which suggests that this problem is game-theoretically learnable. Extensive experiments demonstrate a clear advantage of DPMAC over baseline methods in privacy-preserving scenarios.
</details>
<details>
<summary>摘要</summary>
交流为社会和多代理学习（MARL）中的合作基础。人们也希望在交流时保持隐私，但这一点尚未被现有的MARL工作考虑。为此，我们提出了《差分隐私多代理通信算法》（DPMAC），该算法保护每个代理的敏感信息，并在每个代理的本地消息发送器中实现了严格（ε，δ）差分隐私（DP）保证。与直接将消息裁剪为常见的隐私保护方法一样，我们采用了每个代理的随机消息发送器，并将DP要求直接 incorporated into the sender，自动调整学习的消息分布，以解决由DP噪声引起的不稳定性。此外，我们证明了在隐私保护通信下的合作MARL问题是游戏理论上学习可能的。广泛的实验表明DPMAC在隐私保护场景下具有明显的优势。
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Learning-based-Imputation-Prediction-Networks-for-In-hospital-Mortality-Risk-Modeling-using-EHRs"><a href="#Contrastive-Learning-based-Imputation-Prediction-Networks-for-In-hospital-Mortality-Risk-Modeling-using-EHRs" class="headerlink" title="Contrastive Learning-based Imputation-Prediction Networks for In-hospital Mortality Risk Modeling using EHRs"></a>Contrastive Learning-based Imputation-Prediction Networks for In-hospital Mortality Risk Modeling using EHRs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09896">http://arxiv.org/abs/2308.09896</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liulab1356/CL-ImpPreNet">https://github.com/liulab1356/CL-ImpPreNet</a></li>
<li>paper_authors: Yuxi Liu, Zhenhao Zhang, Shaowen Qin, Flora D. Salim, Antonio Jimeno Yepes</li>
<li>for: 预测医院内死亡风险从电子医疗记录（EHRs）获得了广泛关注，以提供早期警示患者健康状况，促使医疗专业人员采取有效措施。</li>
<li>methods: 本研究提出了一种基于对比学习的抽象替换网络，用于预测医院内死亡风险。我们的方法引入图分析基于患者划分模型，以组合类似患者的信息。此外，我们的方法还可以将对比学习集成到提议的网络架构中，以增强患者表征学习和预测性能。</li>
<li>results: 在两个真实的EHR数据集上，我们的方法比州分之前的方法在替换和预测任务中都表现出优异。<details>
<summary>Abstract</summary>
Predicting the risk of in-hospital mortality from electronic health records (EHRs) has received considerable attention. Such predictions will provide early warning of a patient's health condition to healthcare professionals so that timely interventions can be taken. This prediction task is challenging since EHR data are intrinsically irregular, with not only many missing values but also varying time intervals between medical records. Existing approaches focus on exploiting the variable correlations in patient medical records to impute missing values and establishing time-decay mechanisms to deal with such irregularity. This paper presents a novel contrastive learning-based imputation-prediction network for predicting in-hospital mortality risks using EHR data. Our approach introduces graph analysis-based patient stratification modeling in the imputation process to group similar patients. This allows information of similar patients only to be used, in addition to personal contextual information, for missing value imputation. Moreover, our approach can integrate contrastive learning into the proposed network architecture to enhance patient representation learning and predictive performance on the classification task. Experiments on two real-world EHR datasets show that our approach outperforms the state-of-the-art approaches in both imputation and prediction tasks.
</details>
<details>
<summary>摘要</summary>
预测医院内 morteo风险从电子医疗记录（EHRs）得到了广泛的关注。这将为医疗专业人员提供早期警示patient的健康状况，以便在时间上采取有效的 intervención. 这个预测任务是挑战的，因为EHR数据本身是不规则的，有许多缺失值以及不同的时间间隔 between medical records. 现有的方法是利用patient的医疗记录中的变量相关性来填充缺失值，并设置时间衰减机制来处理这种不规则性. 本文提出了一种基于对比学习的投入-预测网络，用于预测医院内 morteo风险。我们的方法引入图分析基于patient的分类模型，以分组类似的patient。这样只有类似patient的信息被用于缺失值填充，同时还能够使用个体特定的上下文信息。此外，我们的方法还可以将对比学习integrated into the proposed network architecture，以提高patient表示学习和预测性能。实验表明，我们的方法在两个实际的EHR数据集上比状态之前的方法在投入和预测任务中表现出色。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-Transfer-from-High-Resource-to-Low-Resource-Programming-Languages-for-Code-LLMs"><a href="#Knowledge-Transfer-from-High-Resource-to-Low-Resource-Programming-Languages-for-Code-LLMs" class="headerlink" title="Knowledge Transfer from High-Resource to Low-Resource Programming Languages for Code LLMs"></a>Knowledge Transfer from High-Resource to Low-Resource Programming Languages for Code LLMs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09895">http://arxiv.org/abs/2308.09895</a></li>
<li>repo_url: None</li>
<li>paper_authors: Federico Cassano, John Gouwar, Francesca Lucchetti, Claire Schlesinger, Carolyn Jane Anderson, Michael Greenberg, Abhinav Jangda, Arjun Guha</li>
<li>for: 提高低资源语言中Code LLM的性能</li>
<li>methods: 使用半人工数据生成高质量数据集，并在这些数据集上练习和评估Code LLM</li>
<li>results: 使用 MultiPL-T 方法生成了大量有效的训练数据，并在 benchmark 问题上达到了state-of-the-art 性能水平，包括 Lua、Racket 和 OCaml。<details>
<summary>Abstract</summary>
Over the past few years, Large Language Models of Code (Code LLMs) have started to have a significant impact on programming practice. Code LLMs are also emerging as a building block for research in programming languages and software engineering. However, the quality of code produced by a Code LLM varies significantly by programming languages. Code LLMs produce impressive results on programming languages that are well represented in their training data (e.g., Java, Python, or JavaScript), but struggle with low-resource languages, like OCaml and Racket.   This paper presents an effective approach for boosting the performance of Code LLMs on low-resource languages using semi-synthetic data. Our approach generates high-quality datasets for low-resource languages, which can then be used to fine-tune any pretrained Code LLM. Our approach, called MultiPL-T, translates training data from high-resource languages into training data for low-resource languages. We apply our approach to generate tens of thousands of new, validated training items for Racket, OCaml, and Lua from Python. Moreover, we use an open dataset (The Stack) and model (StarCoderBase), which allow us to decontaminate benchmarks and train models on this data without violating the model license.   With MultiPL-T generated data, we present fine-tuned versions of StarCoderBase that achieve state-of-the-art performance for Racket, OCaml, and Lua on benchmark problems. For Lua, our fine-tuned model achieves the same performance as StarCoderBase as Python -- a very high-resource language -- on the MultiPL-E benchmarks. For Racket and OCaml, we double their performance on MultiPL-E, bringing their performance close to higher-resource languages such as Ruby and C#.
</details>
<details>
<summary>摘要</summary>
在过去几年，大型代码模型（Code LLMs）已经开始对编程实践产生重要影响。 Code LLMs 也在编程语言和软件工程研究中出现为基础建筑块。然而，由 Code LLMs 生成的代码质量各不相同，尤其是低资源语言。 Code LLMs 在具有充足训练数据的语言（如 Java、Python 或 JavaScript）上表现出色，但在低资源语言（如 OCaml 和 Racket）上困难。本文提出了一种有效的方法，可以提高 Code LLMs 在低资源语言上表现的方法。我们的方法通过生成高质量的低资源语言数据，然后使用这些数据来练化任何预训练 Code LLM。我们的方法被称为 MultiPL-T，它将高资源语言的训练数据翻译成低资源语言的训练数据。我们使用这种方法生成了数以千计的新的有效训练项目，用于 Racket、OCaml 和 Lua。此外，我们使用公开的数据集（The Stack）和模型（StarCoderBase），可以在这些数据上训练模型，而不违反模型的许可证。使用 MultiPL-T 生成的数据，我们提出了一些精心调整的 StarCoderBase 模型，在benchmark问题上达到了状态之 искусственный智能的性能。对 Lua 来说，我们的调整模型和 Python 的 StarCoderBase 模型在 MultiPL-E benchmark上具有同等的性能。对 Racket 和 OCaml 来说，我们的调整模型可以提高它们的性能，使其接近高资源语言如 Ruby 和 C#。
</details></li>
</ul>
<hr>
<h2 id="Utilizing-Semantic-Textual-Similarity-for-Clinical-Survey-Data-Feature-Selection"><a href="#Utilizing-Semantic-Textual-Similarity-for-Clinical-Survey-Data-Feature-Selection" class="headerlink" title="Utilizing Semantic Textual Similarity for Clinical Survey Data Feature Selection"></a>Utilizing Semantic Textual Similarity for Clinical Survey Data Feature Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09892">http://arxiv.org/abs/2308.09892</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bcwarner/sts-select">https://github.com/bcwarner/sts-select</a></li>
<li>paper_authors: Benjamin C. Warner, Ziqi Xu, Simon Haroutounian, Thomas Kannampallil, Chenyang Lu</li>
<li>for: 这篇论文是为了提出一种基于文本名称的对Target outcome的Semantic textual similarity（STS）分析方法，以便从 Survey data 中选择最佳的特征集。</li>
<li>methods: 本论文使用了Language models（LMs）来评估特征名称和Target名称之间的semantic textual similarity（STS），并将其用于特征选择。</li>
<li>results: 结果显示，使用STS进行特征选择可以实现更高的模型性能，相比传统的特征选择算法。<details>
<summary>Abstract</summary>
Survey data can contain a high number of features while having a comparatively low quantity of examples. Machine learning models that attempt to predict outcomes from survey data under these conditions can overfit and result in poor generalizability. One remedy to this issue is feature selection, which attempts to select an optimal subset of features to learn upon. A relatively unexplored source of information in the feature selection process is the usage of textual names of features, which may be semantically indicative of which features are relevant to a target outcome. The relationships between feature names and target names can be evaluated using language models (LMs) to produce semantic textual similarity (STS) scores, which can then be used to select features. We examine the performance using STS to select features directly and in the minimal-redundancy-maximal-relevance (mRMR) algorithm. The performance of STS as a feature selection metric is evaluated against preliminary survey data collected as a part of a clinical study on persistent post-surgical pain (PPSP). The results suggest that features selected with STS can result in higher performance models compared to traditional feature selection algorithms.
</details>
<details>
<summary>摘要</summary>
Survey data 可能包含大量的特征，而具有较少的示例数量。机器学习模型在这种情况下预测结果时可能会过拟合，导致泛化性差。一种解决方案是Feature选择，它尝试选择最佳的特征子集来学习。文本特征名称的使用仍然是一个相对未探索的信息来源。我们可以使用语言模型（LM）评估特征名称和目标名称之间的语义文本相似性（STS） scores，以便选择特征。我们对直接使用 STS 选择特征和 minimal-redundancy-maximal-relevance（mRMR）算法进行了评估。我们发现，使用 STS 作为特征选择度量时，可以获得比传统特征选择算法更高的性能。Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Inductive-bias-Learning-Generating-Code-Models-with-Large-Language-Model"><a href="#Inductive-bias-Learning-Generating-Code-Models-with-Large-Language-Model" class="headerlink" title="Inductive-bias Learning: Generating Code Models with Large Language Model"></a>Inductive-bias Learning: Generating Code Models with Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09890">http://arxiv.org/abs/2308.09890</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fuyu-quant/iblm">https://github.com/fuyu-quant/iblm</a></li>
<li>paper_authors: Toma Tanaka, Naofumi Emoto, Tsukasa Yumibayashi</li>
<li>for: 本研究旨在提出一种新的学习方法，即归纳学习（Inductive-Bias Learning，IBL），这种方法结合了归纳学习（ICL）和代码生成技术，以实现高精度的推理和代码生成。</li>
<li>methods: 本研究使用的方法包括归纳学习（ICL）和代码生成技术。通过输入训练数据，IBL可以从Contextual Understanding中找到必需的结构，并生成相应的代码模型，以实现高精度的推理和代码生成。</li>
<li>results: 研究发现，IBL可以实现与ICL和代表性机器学习模型相当的预测精度，并且代码生成结果具有较高的可读性和解释性。此外，IBL代码也是开源的，可以在<a target="_blank" rel="noopener" href="https://github.com/fuyu-quant/IBLM%E4%B8%8A%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/fuyu-quant/IBLM上下载。</a><details>
<summary>Abstract</summary>
Large Language Models(LLMs) have been attracting attention due to a ability called in-context learning(ICL). ICL, without updating the parameters of a LLM, it is possible to achieve highly accurate inference based on rules ``in the context'' by merely inputting a training data into the prompt. Although ICL is a developing field with many unanswered questions, LLMs themselves serves as a inference model, seemingly realizing inference without explicitly indicate ``inductive bias''. On the other hand, a code generation is also a highlighted application of LLMs. The accuracy of code generation has dramatically improved, enabling even non-engineers to generate code to perform the desired tasks by crafting appropriate prompts. In this paper, we propose a novel ``learning'' method called an ``Inductive-Bias Learning (IBL)'', which combines the techniques of ICL and code generation. An idea of IBL is straightforward. Like ICL, IBL inputs a training data into the prompt and outputs a code with a necessary structure for inference (we referred to as ``Code Model'') from a ``contextual understanding''. Despite being a seemingly simple approach, IBL encompasses both a ``property of inference without explicit inductive bias'' inherent in ICL and a ``readability and explainability'' of the code generation. Surprisingly, generated Code Models have been found to achieve predictive accuracy comparable to, and in some cases surpassing, ICL and representative machine learning models. Our IBL code is open source: https://github.com/fuyu-quant/IBLM
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在近年来吸引了很多注意，主要是因为它们的一个能力 called "in-context learning"（ICL）。ICL是不需要更新 LLM 的参数时，可以通过输入训练数据来 achieve highly accurate inference based on "rules in the context"。although ICL is a developing field with many unanswered questions, LLMs themselves serve as an inference model, seemingly realizing inference without explicitly indicating "inductive bias"。另一方面，代码生成也是 LLM 的优点之一。代码生成的精度已经得到了很大改善，使得甚至非工程师也可以通过设计适当的 prompt 来生成代码以完成想要的任务。在这篇文章中，我们提出了一个新的“学习”方法called“对应式学习”（IBL），它结合了 ICL 和代码生成的技术。IBL 的想法是 straightforward。如 ICLL，IBL 通过输入训练数据来生成一个代码模型（我们称之为“内在结构”），并将其与内在的概念“对应”。尽管看起来很简单，但 IBL 包含了 ICL 的“无预先假设”和代码生成的“可读性和解释性”。惊奇的是，生成的代码模型已经被发现可以 achieve predictive accuracy comparable to, and in some cases surpassing, ICL 和代表性机器学习模型。我们的 IBL 代码可以在 GitHub 上找到：https://github.com/fuyu-quant/IBLM。
</details></li>
</ul>
<hr>
<h2 id="DUAW-Data-free-Universal-Adversarial-Watermark-against-Stable-Diffusion-Customization"><a href="#DUAW-Data-free-Universal-Adversarial-Watermark-against-Stable-Diffusion-Customization" class="headerlink" title="DUAW: Data-free Universal Adversarial Watermark against Stable Diffusion Customization"></a>DUAW: Data-free Universal Adversarial Watermark against Stable Diffusion Customization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09889">http://arxiv.org/abs/2308.09889</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyu Ye, Hao Huang, Jiaqi An, Yongtao Wang</li>
<li>for: 保护版权图像从多种自定义方法中，防止抄袭特定风格或主题。</li>
<li>methods: 使用不可见的数据自由universal adversarial watermark（DUAW），在不直接处理版权图像的情况下，在多个版本的SD模型中保护各种版权图像。</li>
<li>results: DUAW可以有效地扰乱自定义SD模型生成的图像，使其可见 both human observers和一个简单的分类器。<details>
<summary>Abstract</summary>
Stable Diffusion (SD) customization approaches enable users to personalize SD model outputs, greatly enhancing the flexibility and diversity of AI art. However, they also allow individuals to plagiarize specific styles or subjects from copyrighted images, which raises significant concerns about potential copyright infringement. To address this issue, we propose an invisible data-free universal adversarial watermark (DUAW), aiming to protect a myriad of copyrighted images from different customization approaches across various versions of SD models. First, DUAW is designed to disrupt the variational autoencoder during SD customization. Second, DUAW operates in a data-free context, where it is trained on synthetic images produced by a Large Language Model (LLM) and a pretrained SD model. This approach circumvents the necessity of directly handling copyrighted images, thereby preserving their confidentiality. Once crafted, DUAW can be imperceptibly integrated into massive copyrighted images, serving as a protective measure by inducing significant distortions in the images generated by customized SD models. Experimental results demonstrate that DUAW can effectively distort the outputs of fine-tuned SD models, rendering them discernible to both human observers and a simple classifier.
</details>
<details>
<summary>摘要</summary>
首先，DUAW是在SD自定义过程中扰乱变量自动编码器的设计。其次，DUAW在无数据上下文中操作，通过使用一个大型自然语言模型（LLM）和预训练的SD模型生成的 sintetic图像进行训练。这种方法可以避免直接处理版权图像，保持其 конфиденциальность。一旦制作完毕，DUAW可以隐身地 integrate到大量版权图像中，作为保护性的水印，对于自定义SD模型生成的图像进行显著的扭曲。实验结果表明，DUAW可以有效地扭曲调整后的SD模型输出，使其可见 both human observer和一个简单的分类器。
</details></li>
</ul>
<hr>
<h2 id="On-Estimating-the-Gradient-of-the-Expected-Information-Gain-in-Bayesian-Experimental-Design"><a href="#On-Estimating-the-Gradient-of-the-Expected-Information-Gain-in-Bayesian-Experimental-Design" class="headerlink" title="On Estimating the Gradient of the Expected Information Gain in Bayesian Experimental Design"></a>On Estimating the Gradient of the Expected Information Gain in Bayesian Experimental Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09888">http://arxiv.org/abs/2308.09888</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ziq-ao/GradEIG">https://github.com/ziq-ao/GradEIG</a></li>
<li>paper_authors: Ziqiao Ao, Jinglai Li</li>
<li>for: 本研究旨在提高 bayesian 推理中的实验条件，通过优化预期信息增强 (EIG) 的优化。</li>
<li>methods: 本研究提出了两种估算 EIG 的梯度方法：UEEG-MCMC 和 BEEG-AP。UEEG-MCMC 利用 MCMC 生成的 posterior 样本来估算 EIG 梯度，而 BEEG-AP 则强调高效的 simulation 实现，通过重复使用参数样本来估算 EIG 梯度。</li>
<li>results: 理论分析和数值实验表明，UEEG-MCMC 对实际 EIG 值具有良好的稳定性，而 BEEG-AP 在 EIG 值小时显示更高的效率。此外，两种方法在数值实验中都表现出优于多个流行的参考方法。<details>
<summary>Abstract</summary>
Bayesian Experimental Design (BED), which aims to find the optimal experimental conditions for Bayesian inference, is usually posed as to optimize the expected information gain (EIG). The gradient information is often needed for efficient EIG optimization, and as a result the ability to estimate the gradient of EIG is essential for BED problems. The primary goal of this work is to develop methods for estimating the gradient of EIG, which, combined with the stochastic gradient descent algorithms, result in efficient optimization of EIG. Specifically, we first introduce a posterior expected representation of the EIG gradient with respect to the design variables. Based on this, we propose two methods for estimating the EIG gradient, UEEG-MCMC that leverages posterior samples generated through Markov Chain Monte Carlo (MCMC) to estimate the EIG gradient, and BEEG-AP that focuses on achieving high simulation efficiency by repeatedly using parameter samples. Theoretical analysis and numerical studies illustrate that UEEG-MCMC is robust agains the actual EIG value, while BEEG-AP is more efficient when the EIG value to be optimized is small. Moreover, both methods show superior performance compared to several popular benchmarks in our numerical experiments.
</details>
<details>
<summary>摘要</summary>
bayesian experimental design (BED), which aims to find the optimal experimental conditions for bayesian inference, 通常是要优化预期信息增强(EIG)的目标。为了提高效率，通常需要计算EIG的梯度信息，因此能够估计EIG梯度的能力是BED问题的关键。本工作的主要目标是开发估计EIG梯度的方法，这些方法可以与随机梯度下降算法结合使用，从而实现EIG的高效优化。我们首先引入了 posterior expected representation of EIG gradient with respect to design variables。然后，我们提出了两种估计EIG梯度的方法：UEEG-MCMC，利用MCMC生成的 posterior samples来估计EIG梯度，和BEEG-AP，重点是实现高效的 simulations by repeatedly using parameter samples。我们的理论分析和数学实验表明，UEEG-MCMC 对实际EIG值有良好的稳定性，而BEEG-AP 在EIG值要 optimize 小时更高效。此外，两种方法在我们的数学实验中表现出了较好的性能，比如几种流行的参考方法。
</details></li>
</ul>
<hr>
<h2 id="Calibrating-Uncertainty-for-Semi-Supervised-Crowd-Counting"><a href="#Calibrating-Uncertainty-for-Semi-Supervised-Crowd-Counting" class="headerlink" title="Calibrating Uncertainty for Semi-Supervised Crowd Counting"></a>Calibrating Uncertainty for Semi-Supervised Crowd Counting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09887">http://arxiv.org/abs/2308.09887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Li, Xiaoling Hu, Shahira Abousamra, Chao Chen</li>
<li>for: 这个研究的目的是提出一种可靠地测量人群数量的方法，并且能够在半指导式的情况下进行数据训练。</li>
<li>methods: 本研究使用了一种基于模型uncertainty的方法，通过训练一个surrogate函数来控制模型的uncertainty。另外，我们还提出了一个基于匹配的patch-wise surrogate函数，以更好地近似uncertainty的数据。</li>
<li>results: 根据实验结果显示，我们的方法能够生成可靠的uncertainty估计、高质量的pseudolabels，并且在半指导式的人群数量推断 task 上实现了state-of-the-art的表现。<details>
<summary>Abstract</summary>
Semi-supervised crowd counting is an important yet challenging task. A popular approach is to iteratively generate pseudo-labels for unlabeled data and add them to the training set. The key is to use uncertainty to select reliable pseudo-labels. In this paper, we propose a novel method to calibrate model uncertainty for crowd counting. Our method takes a supervised uncertainty estimation strategy to train the model through a surrogate function. This ensures the uncertainty is well controlled throughout the training. We propose a matching-based patch-wise surrogate function to better approximate uncertainty for crowd counting tasks. The proposed method pays a sufficient amount of attention to details, while maintaining a proper granularity. Altogether our method is able to generate reliable uncertainty estimation, high quality pseudolabels, and achieve state-of-the-art performance in semisupervised crowd counting.
</details>
<details>
<summary>摘要</summary>
semi-supervised crowd counting是一项重要又挑战性的任务。一种流行的方法是通过逐步生成 pseudo-labels 来训练无标注数据。关键在于使用uncertainty来选择可靠的 pseudo-labels。在这篇论文中，我们提出了一种新的方法来准确地控制模型的uncertainty。我们使用一种监督性uncertainty估计策略来训练模型，并通过一个匹配基于的 patch-wise 代理函数来更好地估计uncertainty。我们的方法具有充分的细节注意力，同时保持合适的粒度。总之，我们的方法能够生成可靠的uncertainty估计、高质量的 pseudo-labels，并在semi-supervised crowd counting中实现状态前的性能。
</details></li>
</ul>
<hr>
<h2 id="A-Transformer-based-Framework-For-Multi-variate-Time-Series-A-Remaining-Useful-Life-Prediction-Use-Case"><a href="#A-Transformer-based-Framework-For-Multi-variate-Time-Series-A-Remaining-Useful-Life-Prediction-Use-Case" class="headerlink" title="A Transformer-based Framework For Multi-variate Time Series: A Remaining Useful Life Prediction Use Case"></a>A Transformer-based Framework For Multi-variate Time Series: A Remaining Useful Life Prediction Use Case</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09884">http://arxiv.org/abs/2308.09884</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oluwaseyi Ogunfowora, Homayoun Najjaran</li>
<li>for: 这个研究是为了提出一个基于encoder-transformer架构的多变量时间序列预测框架，用于预测机器的剩下有用生命时间（RUL）。</li>
<li>methods: 本研究使用了encoder-transformer模型，并进行了三个模型对应实验，以将自然语言领域中的transformer模型应用到时间序列预测中。此外，本研究还提出了一个新的扩展窗口方法，用于让模型耳熟悉机器的初期阶段和衰老路径。</li>
<li>results: 根据试验数据表现，提出的encoder-transformer模型在13个state-of-the-art（SOTA）模型中得到了平均提高137.65%的性能。<details>
<summary>Abstract</summary>
In recent times, Large Language Models (LLMs) have captured a global spotlight and revolutionized the field of Natural Language Processing. One of the factors attributed to the effectiveness of LLMs is the model architecture used for training, transformers. Transformer models excel at capturing contextual features in sequential data since time series data are sequential, transformer models can be leveraged for more efficient time series data prediction. The field of prognostics is vital to system health management and proper maintenance planning. A reliable estimation of the remaining useful life (RUL) of machines holds the potential for substantial cost savings. This includes avoiding abrupt machine failures, maximizing equipment usage, and serving as a decision support system (DSS). This work proposed an encoder-transformer architecture-based framework for multivariate time series prediction for a prognostics use case. We validated the effectiveness of the proposed framework on all four sets of the C-MAPPS benchmark dataset for the remaining useful life prediction task. To effectively transfer the knowledge and application of transformers from the natural language domain to time series, three model-specific experiments were conducted. Also, to enable the model awareness of the initial stages of the machine life and its degradation path, a novel expanding window method was proposed for the first time in this work, it was compared with the sliding window method, and it led to a large improvement in the performance of the encoder transformer model. Finally, the performance of the proposed encoder-transformer model was evaluated on the test dataset and compared with the results from 13 other state-of-the-art (SOTA) models in the literature and it outperformed them all with an average performance increase of 137.65% over the next best model across all the datasets.
</details>
<details>
<summary>摘要</summary>
This work proposes an encoder-transformer architecture-based framework for multivariate time series prediction in a prognostics use case. We validated the effectiveness of the proposed framework on all four datasets of the C-MAPPS benchmark for RUL prediction. To transfer knowledge and application of transformers from the natural language domain to time series, we conducted three model-specific experiments. Additionally, we proposed a novel expanding window method to enhance the model's awareness of the initial stages of machine life and its degradation path. This method was compared with the sliding window method and led to a large improvement in the performance of the encoder transformer model.The proposed encoder-transformer model was evaluated on the test dataset and outperformed 13 other state-of-the-art (SOTA) models in the literature, with an average performance increase of 137.65% over the next best model across all datasets.
</details></li>
</ul>
<hr>
<h2 id="Flamingo-Multi-Round-Single-Server-Secure-Aggregation-with-Applications-to-Private-Federated-Learning"><a href="#Flamingo-Multi-Round-Single-Server-Secure-Aggregation-with-Applications-to-Private-Federated-Learning" class="headerlink" title="Flamingo: Multi-Round Single-Server Secure Aggregation with Applications to Private Federated Learning"></a>Flamingo: Multi-Round Single-Server Secure Aggregation with Applications to Private Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09883">http://arxiv.org/abs/2308.09883</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/eniac/flamingo">https://github.com/eniac/flamingo</a></li>
<li>paper_authors: Yiping Ma, Jess Woods, Sebastian Angel, Antigoni Polychroniadou, Tal Rabin</li>
<li>for: 这篇论文描述了一种用于安全聚合 Federated Learning 中的数据的系统，即 Flamingo。</li>
<li>methods: Flamingo 使用了一种新的轻量级随机 dropout 抗性协议，以及一种新的客户端邻居选择方法，以确保在客户端离开中阶段的服务器仍然可以获得有意义的结果。</li>
<li>results: Flamingo 可以安全地训练基于 (Extended) MNIST 和 CIFAR-100 数据集的神经网络，并且模型可以在不失去精度的情况下 converge。相比之下，非私有 Federated Learning 系统可以带来更快的结果。<details>
<summary>Abstract</summary>
This paper introduces Flamingo, a system for secure aggregation of data across a large set of clients. In secure aggregation, a server sums up the private inputs of clients and obtains the result without learning anything about the individual inputs beyond what is implied by the final sum. Flamingo focuses on the multi-round setting found in federated learning in which many consecutive summations (averages) of model weights are performed to derive a good model. Previous protocols, such as Bell et al. (CCS '20), have been designed for a single round and are adapted to the federated learning setting by repeating the protocol multiple times. Flamingo eliminates the need for the per-round setup of previous protocols, and has a new lightweight dropout resilience protocol to ensure that if clients leave in the middle of a sum the server can still obtain a meaningful result. Furthermore, Flamingo introduces a new way to locally choose the so-called client neighborhood introduced by Bell et al. These techniques help Flamingo reduce the number of interactions between clients and the server, resulting in a significant reduction in the end-to-end runtime for a full training session over prior work. We implement and evaluate Flamingo and show that it can securely train a neural network on the (Extended) MNIST and CIFAR-100 datasets, and the model converges without a loss in accuracy, compared to a non-private federated learning system.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文介绍了Flamingo系统，用于在大量客户端上安全地汇集数据。在安全汇集中，服务器将客户端的私有输入汇集到最终结果中，而不会了解每个输入的详细信息。Flamingo针对了联合学习中的多轮设定，在多个汇集（均值）中得到一个好的模型。先前的协议，如Bell et al. (CCS '20)，是为单轮设定而设计，并通过重复协议来适应联合学习设定。Flamingo消除了先前协议的每轮设定需求，并提供了一个轻量级的dropout鲁棒性协议，以确保如果客户端在汇集过程中离开，服务器仍可以获得有意义的结果。此外，Flamingo还引入了一种新的客户端 neighboorhood的选择方法，这些方法帮助Flamingo减少客户端和服务器之间的交互次数，从而导致了对于整个训练会话的结束到终端时间的重要减少。我们实现和评估了Flamingo，并证明它可以安全地训练一个神经网络在（扩展）MNIST和CIFAR-100数据集上，并且模型可以无损地训练完成，相比于非私钥联合学习系统。
</details></li>
</ul>
<hr>
<h2 id="Generative-Adversarial-Networks-Unlearning"><a href="#Generative-Adversarial-Networks-Unlearning" class="headerlink" title="Generative Adversarial Networks Unlearning"></a>Generative Adversarial Networks Unlearning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09881">http://arxiv.org/abs/2308.09881</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui Sun, Tianqing Zhu, Wenhan Chang, Wanlei Zhou</li>
<li>for: 本研究旨在解决Generative Adversarial Networks (GANs)中的机器学习模型卸载数据的问题，即生成器和判别器的架构特点使得卸载过程可能会导致 latent space 的破坏和模型效果的降低。</li>
<li>methods: 本研究提出了一种替换机制和假标签来有效地解决 generator 卸载和判别器的挑战。基于这种替换机制和假标签，我们提出了一种层次式卸载方法，其中卸载和学习过程Running in a cascaded manner。</li>
<li>results: 我们在 MNIST 和 CIFAR-10 数据集上进行了全面的评估，结果表明，这种层次式卸载方法可以大幅提高项和类卸载效率，比 retraining from scratch 减少时间量达 185x 和 284x。此外，我们发现，即使模型性能受到一定影响，这些影响几乎可以忽略不计（如 64 个图像），并无负面影响下游任务 such as classification。<details>
<summary>Abstract</summary>
As machine learning continues to develop, and data misuse scandals become more prevalent, individuals are becoming increasingly concerned about their personal information and are advocating for the right to remove their data. Machine unlearning has emerged as a solution to erase training data from trained machine learning models. Despite its success in classifiers, research on Generative Adversarial Networks (GANs) is limited due to their unique architecture, including a generator and a discriminator. One challenge pertains to generator unlearning, as the process could potentially disrupt the continuity and completeness of the latent space. This disruption might consequently diminish the model's effectiveness after unlearning. Another challenge is how to define a criterion that the discriminator should perform for the unlearning images. In this paper, we introduce a substitution mechanism and define a fake label to effectively mitigate these challenges. Based on the substitution mechanism and fake label, we propose a cascaded unlearning approach for both item and class unlearning within GAN models, in which the unlearning and learning processes run in a cascaded manner. We conducted a comprehensive evaluation of the cascaded unlearning technique using the MNIST and CIFAR-10 datasets. Experimental results demonstrate that this approach achieves significantly improved item and class unlearning efficiency, reducing the required time by up to 185x and 284x for the MNIST and CIFAR-10 datasets, respectively, in comparison to retraining from scratch. Notably, although the model's performance experiences minor degradation after unlearning, this reduction is negligible when dealing with a minimal number of images (e.g., 64) and has no adverse effects on downstream tasks such as classification.
</details>
<details>
<summary>摘要</summary>
machine learning技术不断发展，同时数据滥用事件的发生也使人们对个人信息变得越来越重要，因此开始提出个人数据权的要求。为了解除训练机器学习模型的数据，机器学习卸学（Machine Unlearning）已成为一种解决方案。然而，对于生成型 adversarial network（GAN）来说，研究尚未充分发展，其特殊的架构包括生成器和分类器，带来了一些挑战。其中一个挑战是生成器卸学，因为这个过程可能会破坏生成器的维度完整性，从而降低模型的效果。另一个挑战是如何定义分类器对卸学图像的标准。在这篇论文中，我们提出了替换机制和假标签，以解决这些挑战。基于替换机制和假标签，我们提出了卸学和学习的层次结构，在这种结构下，卸学和学习过程会在一起运行。我们对MNIST和CIFAR-10 datasets进行了全面的评估，实验结果表明，这种方法可以有效提高项目和类卸学效率，比Retraining from scratch需要的时间减少了185倍和284倍。尤其是在处理少量图像时（例如64个），模型的性能下降非常小，无法影响下游任务 such as classification。
</details></li>
</ul>
<hr>
<h2 id="DatasetEquity-Are-All-Samples-Created-Equal-In-The-Quest-For-Equity-Within-Datasets"><a href="#DatasetEquity-Are-All-Samples-Created-Equal-In-The-Quest-For-Equity-Within-Datasets" class="headerlink" title="DatasetEquity: Are All Samples Created Equal? In The Quest For Equity Within Datasets"></a>DatasetEquity: Are All Samples Created Equal? In The Quest For Equity Within Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09878">http://arxiv.org/abs/2308.09878</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/towardsautonomy/datasetequity">https://github.com/towardsautonomy/datasetequity</a></li>
<li>paper_authors: Shubham Shrivastava, Xianling Zhang, Sushruth Nagesh, Armin Parchami</li>
<li>for:  addressed the data imbalance issue in machine learning, specifically in computer vision tasks, by developing a novel method that leverages deep perceptual embeddings and clustering to weigh samples differently during training.</li>
<li>methods:  the proposed method uses sample likelihoods based on image appearance, computed using deep perceptual embeddings and clustering, to weigh samples differently during training with a novel $\textbf{Generalized Focal Loss}$ function.</li>
<li>results:  the proposed method achieves over $200%$ AP gains on under-represented classes (Cyclist) in the KITTI dataset, demonstrating its effectiveness in improving state-of-the-art 3D object detection methods, and its generalizability across different datasets and rare classes.<details>
<summary>Abstract</summary>
Data imbalance is a well-known issue in the field of machine learning, attributable to the cost of data collection, the difficulty of labeling, and the geographical distribution of the data. In computer vision, bias in data distribution caused by image appearance remains highly unexplored. Compared to categorical distributions using class labels, image appearance reveals complex relationships between objects beyond what class labels provide. Clustering deep perceptual features extracted from raw pixels gives a richer representation of the data. This paper presents a novel method for addressing data imbalance in machine learning. The method computes sample likelihoods based on image appearance using deep perceptual embeddings and clustering. It then uses these likelihoods to weigh samples differently during training with a proposed $\textbf{Generalized Focal Loss}$ function. This loss can be easily integrated with deep learning algorithms. Experiments validate the method's effectiveness across autonomous driving vision datasets including KITTI and nuScenes. The loss function improves state-of-the-art 3D object detection methods, achieving over $200\%$ AP gains on under-represented classes (Cyclist) in the KITTI dataset. The results demonstrate the method is generalizable, complements existing techniques, and is particularly beneficial for smaller datasets and rare classes. Code is available at: https://github.com/towardsautonomy/DatasetEquity
</details>
<details>
<summary>摘要</summary>
“数据不匹配是机器学习领域的一个公认问题，归结于数据收集成本高、标签难度和数据地域分布。在计算机视觉领域，图像外观偏见对数据分布的偏见仍未得到充分探索。相比于使用类别标签的分布，图像外观表明对象之间的复杂关系，超出了类别标签的提供。使用深度感知特征提取器和归一化 clustering 可以得到更加丰富的数据表示。本文提出了一种novel方法，用于解决机器学习中的数据不匹配问题。该方法计算样本概率基于图像外观使用深度感知特征和归一化，然后使用这些概率将样本 differently 权重 durante 训练，使用我们提议的 $\textbf{通用增强损失}$ 函数。这个损失函数可以轻松地与深度学习算法结合使用。实验证明了该方法在自动驾驶视觉数据集（包括 KITTI 和 nuScenes）上的效果，可以提高状态的较为少见类（自行车手）的 AP 分数超过 200%。结果表明该方法是通用的，可以补做现有技术，特别有利于 smaller 数据集和罕见类。代码可以在 GitHub 上找到：https://github.com/towardsautonomy/DatasetEquity。”Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Skill-Transformer-A-Monolithic-Policy-for-Mobile-Manipulation"><a href="#Skill-Transformer-A-Monolithic-Policy-for-Mobile-Manipulation" class="headerlink" title="Skill Transformer: A Monolithic Policy for Mobile Manipulation"></a>Skill Transformer: A Monolithic Policy for Mobile Manipulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09873">http://arxiv.org/abs/2308.09873</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyu Huang, Dhruv Batra, Akshara Rai, Andrew Szot</li>
<li>for: 这篇论文是用于解决长期机器人任务的方法。</li>
<li>methods: 这篇论文使用了条件序列模型和技能模块来解决问题。它使用transformer架构，通过示例轨迹来预测高级技能和全身低级动作，从而实现了任务的可组合性和模块性。</li>
<li>results: 在一个embodied重新排序测试中，这篇论文的方法比基eline achieved a 2.5倍高的成功率，在困难重新排序问题中表现出了稳定的任务规划和低级控制能力。<details>
<summary>Abstract</summary>
We present Skill Transformer, an approach for solving long-horizon robotic tasks by combining conditional sequence modeling and skill modularity. Conditioned on egocentric and proprioceptive observations of a robot, Skill Transformer is trained end-to-end to predict both a high-level skill (e.g., navigation, picking, placing), and a whole-body low-level action (e.g., base and arm motion), using a transformer architecture and demonstration trajectories that solve the full task. It retains the composability and modularity of the overall task through a skill predictor module while reasoning about low-level actions and avoiding hand-off errors, common in modular approaches. We test Skill Transformer on an embodied rearrangement benchmark and find it performs robust task planning and low-level control in new scenarios, achieving a 2.5x higher success rate than baselines in hard rearrangement problems.
</details>
<details>
<summary>摘要</summary>
我们提出了Skill Transformer，一种解决长期机器人任务的方法，通过加入条件序列模型和技能模块性。基于机器人 egocentric和 proprioceptive 观察，Skill Transformer 通过端到端训练，预测高级技能（如导航、捕获、放置）和整体低级动作（如基体和臂动作），使用 transformer 架构和示范轨迹解决整个任务。它保留了总任务的可组合性和模块性通过技能预测模块，并在低级动作和避免手动错误方面进行了合理的理解。我们在embodied rearrangement benchmark上测试了Skill Transformer，并发现它在新的 scenarios 中实现了可靠的任务规划和低级控制，与基eline 的成功率相比，在困难的重新排序问题中达到2.5倍的成功率。
</details></li>
</ul>
<hr>
<h2 id="Tensor-Compressed-Back-Propagation-Free-Training-for-Physics-Informed-Neural-Networks"><a href="#Tensor-Compressed-Back-Propagation-Free-Training-for-Physics-Informed-Neural-Networks" class="headerlink" title="Tensor-Compressed Back-Propagation-Free Training for (Physics-Informed) Neural Networks"></a>Tensor-Compressed Back-Propagation-Free Training for (Physics-Informed) Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09858">http://arxiv.org/abs/2308.09858</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yequan Zhao, Xinling Yu, Zhixiong Chen, Ziyue Liu, Sijia Liu, Zheng Zhang</li>
<li>for: 本研究的目的是提出一个不需要后向传播（Backward Propagation，BP）的框架，用于在边缘设备上训练具有真实性的神经网络。</li>
<li>methods: 我们的技术贡献包括三个方面：首先，我们提出了一种紧凑变量压缩方法来大幅提高零次ORDER（ZO）优化的可扩展性，使得可以处理大于过去ZO方法所能处理的网络大小。其次，我们提出了一种混合式Gradient评估方法来提高ZO训练的效率。最后，我们将我们的BP-free训练框架扩展到物理学 informed neural networks（PINNs）中，并提出了一种稀疏网格方法来估计损失函数中的导数而不使用BP。</li>
<li>results: 我们的BP-free训练只在MNIST数据集上失去了一点精度与标准首次Order训练相比。此外，我们还成功地训练了一个解决20维汉米尔-雅可比-贝尔姆 partial differential equation（PDE）的PINN。这种内存高效和BP-free的方法可能会成为未来资源有限平台（例如FPGA、ASIC、微控制器和光子学材料）上的准 Near-future on-device training。<details>
<summary>Abstract</summary>
Backward propagation (BP) is widely used to compute the gradients in neural network training. However, it is hard to implement BP on edge devices due to the lack of hardware and software resources to support automatic differentiation. This has tremendously increased the design complexity and time-to-market of on-device training accelerators. This paper presents a completely BP-free framework that only requires forward propagation to train realistic neural networks. Our technical contributions are three-fold. Firstly, we present a tensor-compressed variance reduction approach to greatly improve the scalability of zeroth-order (ZO) optimization, making it feasible to handle a network size that is beyond the capability of previous ZO approaches. Secondly, we present a hybrid gradient evaluation approach to improve the efficiency of ZO training. Finally, we extend our BP-free training framework to physics-informed neural networks (PINNs) by proposing a sparse-grid approach to estimate the derivatives in the loss function without using BP. Our BP-free training only loses little accuracy on the MNIST dataset compared with standard first-order training. We also demonstrate successful results in training a PINN for solving a 20-dim Hamiltonian-Jacobi-Bellman PDE. This memory-efficient and BP-free approach may serve as a foundation for the near-future on-device training on many resource-constraint platforms (e.g., FPGA, ASIC, micro-controllers, and photonic chips).
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用后向传播（BP）计算神经网络训练中的梯度是广泛使用的。然而，由于缺乏硬件和软件资源，在边缘设备上实现BP很困难。这有效地增加了设计复杂性和时间到市场的 neural network 训练加速器。本文提出了一个完全不需要BP的框架，只需要前向传播来训练真实的神经网络。我们的技术贡献有三个方面：1. 我们提出了一种压缩tensor的方法，以提高零次梯度优化的扩展性，使得可以处理大于前一代ZO方法所能处理的网络大小。2. 我们提出了一种混合梯度评估方法，以提高ZO训练的效率。3. 我们将BP-free训练框架扩展到物理学习神经网络（PINNs），并提出了一种稀疏网格方法，以便在损失函数中无需使用BP来估算梯度。BP-free训练只在MNIST数据集上失去了微scopic的精度，与标准首次训练相比。我们还成功地训练了一个解决20维汉密尔-雅可比-贝尔干涯方程的PINN。这种内存高效的BP-free方法可能会成为许多有限资源平台（如FPGA、ASIC、微控制器和光学芯片）的未来边缘训练基础。
</details></li>
</ul>
<hr>
<h2 id="Backdoor-Mitigation-by-Correcting-the-Distribution-of-Neural-Activations"><a href="#Backdoor-Mitigation-by-Correcting-the-Distribution-of-Neural-Activations" class="headerlink" title="Backdoor Mitigation by Correcting the Distribution of Neural Activations"></a>Backdoor Mitigation by Correcting the Distribution of Neural Activations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09850">http://arxiv.org/abs/2308.09850</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xi Li, Zhen Xiang, David J. Miller, George Kesidis</li>
<li>for: 本研究探讨了深度神经网络（DNN）中的后门（Trojan）攻击，特别是 Successful 攻击会导致内层活动分布的变化，以及如何通过修复这种变化来实现后门纠正。</li>
<li>methods: 本研究使用了reverse工程技术来恢复 trigger 的原始形式，并通过修复内层活动分布的变化来实现后门纠正。</li>
<li>results: 本研究发现，使用修复后门 trigger 的方法可以有效地纠正后门攻击，并且不需要对 DNN 的参数进行优化。此外，这种方法还可以有效地检测测试实例中是否存在 trigger。<details>
<summary>Abstract</summary>
Backdoor (Trojan) attacks are an important type of adversarial exploit against deep neural networks (DNNs), wherein a test instance is (mis)classified to the attacker's target class whenever the attacker's backdoor trigger is present. In this paper, we reveal and analyze an important property of backdoor attacks: a successful attack causes an alteration in the distribution of internal layer activations for backdoor-trigger instances, compared to that for clean instances. Even more importantly, we find that instances with the backdoor trigger will be correctly classified to their original source classes if this distribution alteration is corrected. Based on our observations, we propose an efficient and effective method that achieves post-training backdoor mitigation by correcting the distribution alteration using reverse-engineered triggers. Notably, our method does not change any trainable parameters of the DNN, but achieves generally better mitigation performance than existing methods that do require intensive DNN parameter tuning. It also efficiently detects test instances with the trigger, which may help to catch adversarial entities in the act of exploiting the backdoor.
</details>
<details>
<summary>摘要</summary>
后门（Trojan）攻击是深度神经网络（DNN）的重要类型敌意攻击，其中测试实例会在攻击者的目标类中被识别，只要攻击者的后门触发器存在。在这篇论文中，我们揭示了后门攻击的一个重要性ptych：成功攻击会导致后门触发器实例的内部层活动分布发生变化，相比于干净实例。进一步地，我们发现，如果这种分布变化得到了修正，那么后门触发器实例将会返回到其原始类别。基于我们的观察，我们提出了一种高效的后门整治方法，通过修正分布变化来实现后门整治。这种方法不会改变 DNN 的可调参数，但可以实现更好的整治性能，并快速检测测试实例中的触发器。
</details></li>
</ul>
<hr>
<h2 id="Enumerating-Safe-Regions-in-Deep-Neural-Networks-with-Provable-Probabilistic-Guarantees"><a href="#Enumerating-Safe-Regions-in-Deep-Neural-Networks-with-Provable-Probabilistic-Guarantees" class="headerlink" title="Enumerating Safe Regions in Deep Neural Networks with Provable Probabilistic Guarantees"></a>Enumerating Safe Regions in Deep Neural Networks with Provable Probabilistic Guarantees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09842">http://arxiv.org/abs/2308.09842</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luca Marzari, Davide Corsi, Enrico Marchesini, Alessandro Farinelli, Ferdinando Cicalese</li>
<li>for: 确保深度神经网络（DNNs）的可靠性，identifying safe areas是关键。</li>
<li>methods: 我们引入AllDNN-Verification问题，给出了一种有效的 aproximation方法called epsilon-ProVe。</li>
<li>results: 我们的方法可以提供一个紧身的（具有证明的概率保证）下界估计安全区域，并且在不同的标准准比例上进行了实验，证明了我们的方法的可扩展性和有效性。<details>
<summary>Abstract</summary>
Identifying safe areas is a key point to guarantee trust for systems that are based on Deep Neural Networks (DNNs). To this end, we introduce the AllDNN-Verification problem: given a safety property and a DNN, enumerate the set of all the regions of the property input domain which are safe, i.e., where the property does hold. Due to the #P-hardness of the problem, we propose an efficient approximation method called epsilon-ProVe. Our approach exploits a controllable underestimation of the output reachable sets obtained via statistical prediction of tolerance limits, and can provide a tight (with provable probabilistic guarantees) lower estimate of the safe areas. Our empirical evaluation on different standard benchmarks shows the scalability and effectiveness of our method, offering valuable insights for this new type of verification of DNNs.
</details>
<details>
<summary>摘要</summary>
安全区域的标识是深度神经网络（DNN）系统的关键策略，以确保信任性。为此，我们提出了AllDNN-Verification问题：给定一个安全性质和一个DNN，列出安全区域的输入Domaint中的所有区域，即where the property does hold。由于这个问题的P-完备性，我们提出了一种高效的近似方法called epsilon-ProVe。我们的方法利用了可控的输出可达集的统计预测误差，可以提供一个紧靠的（带有可靠的 probabilistic guarantees）下界估计安全区域。我们的实验表明了我们的方法的扩展性和有效性，为这种新的DNN验证提供了有价值的发现。
</details></li>
</ul>
<hr>
<h2 id="Microscopy-Image-Segmentation-via-Point-and-Shape-Regularized-Data-Synthesis"><a href="#Microscopy-Image-Segmentation-via-Point-and-Shape-Regularized-Data-Synthesis" class="headerlink" title="Microscopy Image Segmentation via Point and Shape Regularized Data Synthesis"></a>Microscopy Image Segmentation via Point and Shape Regularized Data Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09835">http://arxiv.org/abs/2308.09835</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shijie Li, Mengwei Ren, Thomas Ach, Guido Gerig</li>
<li>for: 这个论文主要针对的是用深度学习方法进行微scopia图像分割，但是现有的方法几乎都需要大量的培训数据，包括完整的对象 outline，这是非常时间consuming和困难的。这篇论文提出了一种使用点标注（即对象中心点）来训练微scopia图像分割模型的方法。</li>
<li>methods: 这篇论文提出了一种三个阶段的框架，包括：	1. 使用点标注生成一个 Pseudo dense segmentation mask，这个mask受到形状约束的限制。	2. 使用一种未经培训的图像生成模型将mask翻译成一个真实的微scopia图像，这个图像受到对象级别一致性的限制。	3. 将Pseudo masks和生成的图像组成一个对应的 dataset，用于训练微scopia图像分割模型。</li>
<li>results:  compared to使用pseudo-labels或基eline生成的图像，模型在使用这种synthesis pipeline训练后表现出了明显的改进。此外，这种方法可以与使用authentic microscopy images with dense labels进行比较，并且达到了相似的性能。代码可以获取。<details>
<summary>Abstract</summary>
Current deep learning-based approaches for the segmentation of microscopy images heavily rely on large amount of training data with dense annotation, which is highly costly and laborious in practice. Compared to full annotation where the complete contour of objects is depicted, point annotations, specifically object centroids, are much easier to acquire and still provide crucial information about the objects for subsequent segmentation. In this paper, we assume access to point annotations only during training and develop a unified pipeline for microscopy image segmentation using synthetically generated training data. Our framework includes three stages: (1) it takes point annotations and samples a pseudo dense segmentation mask constrained with shape priors; (2) with an image generative model trained in an unpaired manner, it translates the mask to a realistic microscopy image regularized by object level consistency; (3) the pseudo masks along with the synthetic images then constitute a pairwise dataset for training an ad-hoc segmentation model. On the public MoNuSeg dataset, our synthesis pipeline produces more diverse and realistic images than baseline models while maintaining high coherence between input masks and generated images. When using the identical segmentation backbones, the models trained on our synthetic dataset significantly outperform those trained with pseudo-labels or baseline-generated images. Moreover, our framework achieves comparable results to models trained on authentic microscopy images with dense labels, demonstrating its potential as a reliable and highly efficient alternative to labor-intensive manual pixel-wise annotations in microscopy image segmentation. The code is available.
</details>
<details>
<summary>摘要</summary>
当前的深度学习基于方法 для微scopia图像分割强调大量的训练数据和精密的标注，但这在实际中是非常昂贵和劳动密集的。相比于全标注，其中包括对象的完整边界，点标注，具体来说是对象的中心点，是训练中得到的 much easier。在这篇论文中，我们假设在训练时可以获得点标注。我们提出了一个整体框架，包括以下三个阶段：1. 从点标注中提取pseudo dense segmentation mask，并受限于形状假设。2. 使用未经准备的图像生成模型，将mask翻译成真实的微scopia图像，并在对象水平进行了规范。3. pseudo masks和生成的图像组成一个对应的对数据集，用于训练专门的分割模型。在公共的 MoNuSeg 数据集上，我们的生成框架生成了更加多样化和真实的图像，同时保持输入权重和生成图像之间的高协调性。当使用同一个分割背bone时，我们在生成数据集上训练的模型显著超过 pseudo-标签或基eline-生成的图像模型。此外，我们的框架可以与 dense标注数据集进行比较，表明它可以作为 dense标注的可靠和高效的替代方案。代码可以获取。
</details></li>
</ul>
<hr>
<h2 id="Learning-from-A-Single-Graph-is-All-You-Need-for-Near-Shortest-Path-Routing-in-Wireless-Networks"><a href="#Learning-from-A-Single-Graph-is-All-You-Need-for-Near-Shortest-Path-Routing-in-Wireless-Networks" class="headerlink" title="Learning from A Single Graph is All You Need for Near-Shortest Path Routing in Wireless Networks"></a>Learning from A Single Graph is All You Need for Near-Shortest Path Routing in Wireless Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09829">http://arxiv.org/abs/2308.09829</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yung-Fu Chen, Sen Lin, Anish Arora</li>
<li>For: 本研究提出一种学习算法，用于解决无线网络中的本地路由策略问题。这种算法只需要一些从同一个图中获取的数据样本，可以对所有随机图进行泛化。* Methods: 本研究使用深度神经网络（DNNs）来学习本地路由策略。这些DNNs可以高效地和扩展地学习路由策略，只考虑节点状态和邻居节点状态。* Results: 研究结果显示，使用这种算法可以快速地从一些路由路径中获取样本，并在各种随机图上获得高效和普遍适用的路由策略。此外，这种算法还可以提供 тео리тиче explainability，即为什么使用一个小型的种子图和节点抽样可以有效地学习路由策略。<details>
<summary>Abstract</summary>
We propose a learning algorithm for local routing policies that needs only a few data samples obtained from a single graph while generalizing to all random graphs in a standard model of wireless networks. We thus solve the all-pairs near-shortest path problem by training deep neural networks (DNNs) that efficiently and scalably learn routing policies that are local, i.e., they only consider node states and the states of neighboring nodes. Remarkably, one of these DNNs we train learns a policy that exactly matches the performance of greedy forwarding; another generally outperforms greedy forwarding. Our algorithm design exploits network domain knowledge in several ways: First, in the selection of input features and, second, in the selection of a ``seed graph'' and subsamples from its shortest paths. The leverage of domain knowledge provides theoretical explainability of why the seed graph and node subsampling suffice for learning that is efficient, scalable, and generalizable. Simulation-based results on uniform random graphs with diverse sizes and densities empirically corroborate that using samples generated from a few routing paths in a modest-sized seed graph quickly learns a model that is generalizable across (almost) all random graphs in the wireless network model.
</details>
<details>
<summary>摘要</summary>
我们提出了一种学习算法，用于本地路由策略，只需要几个数据样本，从一个图中获取，而能够泛化到所有随机图中的标准网络模型。我们通过训练深度神经网络（DNN），efficiently和可扩展地学习本地路由策略，即只考虑节点状态和邻居节点状态。奇怪的是，我们训练的一个DNN学习策略与批发转发性能相同；另一个策略则通常超过批发转发性能。我们的算法设计利用网络领域知识，包括输入特征的选择和``seed graph''和节点子集的选择。这种利用领域知识的设计提供了有理解的解释，为何seed graph和节点子集 suffice for learning是有效、可扩展和泛化的。针对随机图中的不同大小和密度的实验结果，表明使用从seed graph中生成的几个路由路径的样本，可以快速学习一个泛化到大多数随机图的模型。
</details></li>
</ul>
<hr>
<h2 id="VL-PET-Vision-and-Language-Parameter-Efficient-Tuning-via-Granularity-Control"><a href="#VL-PET-Vision-and-Language-Parameter-Efficient-Tuning-via-Granularity-Control" class="headerlink" title="VL-PET: Vision-and-Language Parameter-Efficient Tuning via Granularity Control"></a>VL-PET: Vision-and-Language Parameter-Efficient Tuning via Granularity Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09804">http://arxiv.org/abs/2308.09804</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/henryhzy/vl-pet">https://github.com/henryhzy/vl-pet</a></li>
<li>paper_authors: Zi-Yuan Hu, Yanyang Li, Michael R. Lyu, Liwei Wang</li>
<li>for: 这个论文目的是提出一个具有效的vision-and-language受控 Parametric Tuning（VL-PET）框架，以便实现更好的效率和有效性变数。</li>
<li>methods: 这个论文使用了一种新的粒度控制机制，允许在不同的粒度控制矩阵下逐步实现不同的模组化修改。此外，论文还提出了一些轻量级的PET模组设计，以提高预测和文本生成的能力。</li>
<li>results: 实验结果显示，这个VL-PET框架可以与现有的PET技术相比，在四个影像文本任务和四个影像视频文本任务上表现更好，并且可以实现更好的效率和有效性变数。具体来说，使用VL-PET-大的模型可以与BART-base和T5-base模型相比，在影像文本任务上表现出2.92%（3.41%）和3.37%（7.03%）的改善。<details>
<summary>Abstract</summary>
As the model size of pre-trained language models (PLMs) grows rapidly, full fine-tuning becomes prohibitively expensive for model training and storage. In vision-and-language (VL), parameter-efficient tuning (PET) techniques are proposed to integrate modular modifications (e.g., Adapter and LoRA) into encoder-decoder PLMs. By tuning a small set of trainable parameters, these techniques perform on par with full fine-tuning. However, excessive modular modifications and neglecting the functionality gap between the encoders and decoders can lead to performance degradation, while existing PET techniques (e.g., VL-Adapter) overlook these critical issues. In this paper, we propose a Vision-and-Language Parameter-Efficient Tuning (VL-PET) framework to impose effective control over modular modifications via a novel granularity-controlled mechanism. Considering different granularity-controlled matrices generated by this mechanism, a variety of model-agnostic VL-PET modules can be instantiated from our framework for better efficiency and effectiveness trade-offs. We further propose lightweight PET module designs to enhance VL alignment and modeling for the encoders and maintain text generation for the decoders. Extensive experiments conducted on four image-text tasks and four video-text tasks demonstrate the efficiency, effectiveness and transferability of our VL-PET framework. In particular, our VL-PET-large with lightweight PET module designs significantly outperforms VL-Adapter by 2.92% (3.41%) and LoRA by 3.37% (7.03%) with BART-base (T5-base) on image-text tasks. Furthermore, we validate the enhanced effect of employing our VL-PET designs on existing PET techniques, enabling them to achieve significant performance improvements. Our code is available at https://github.com/HenryHZY/VL-PET.
</details>
<details>
<summary>摘要</summary>
“随着预训语言模型（PLM）的模型大小迅速增长，全面精通化训练（full fine-tuning）已成为训练和储存模型的瓶颈。在视觉语言（VL）领域，具有实现效益的参数效率训练（PET）技术被提出，以将可变的修改（e.g., Adapter和LoRA） integrate到encoder-decoder PLM 中。这些技术可以通过微小的参数训练，与全面精通化训练相比，实现相似的性能。然而，过度的修改和遗传的差异点（gap）对模型的性能产生负面影响，而现有的PET技术（e.g., VL-Adapter）忽略了这些重要问题。本文提出了一个vision-and-language参数效率训练（VL-PET）框架，以控制修改的具体化程度。通过这个框架，可以从不同的具体化控制矩阵生成多种模型独立的VL-PET模组，以达到更好的效率和效果的调控。此外，我们还提出了一些轻量级PET模组的设计，以增强视觉和文本的整合和模型。实验结果显示，我们的VL-PET-大型以轻量级PET模组设计对image-text任务和video-text任务表现出色，与BART-base和T5-base相比，优于VL-Adapter和LoRA。此外，我们还 validate了我们的VL-PET设计对现有PET技术的优化效果，使其实现更大的性能提升。我们的代码可以在https://github.com/HenryHZY/VL-PET 上获取。”
</details></li>
</ul>
<hr>
<h2 id="An-Efficient-High-Dimensional-Gene-Selection-Approach-based-on-Binary-Horse-Herd-Optimization-Algorithm-for-Biological-Data-Classification"><a href="#An-Efficient-High-Dimensional-Gene-Selection-Approach-based-on-Binary-Horse-Herd-Optimization-Algorithm-for-Biological-Data-Classification" class="headerlink" title="An Efficient High-Dimensional Gene Selection Approach based on Binary Horse Herd Optimization Algorithm for Biological Data Classification"></a>An Efficient High-Dimensional Gene Selection Approach based on Binary Horse Herd Optimization Algorithm for Biological Data Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09791">http://arxiv.org/abs/2308.09791</a></li>
<li>repo_url: None</li>
<li>paper_authors: Niloufar Mehrabi, Sayed Pedram Haeri Boroujeni, Elnaz Pashaei</li>
<li>for: 解决复杂高维问题，特别是维度较大的搜索问题。</li>
<li>methods: 使用新的马群优化算法（BHOA）和最小重复最大相关性筛选器（MRMR）组成的гибрид特征选择方法。</li>
<li>results: 对于十个靶场数据集（Lymphoma、Prostate、Brain-1、DLBCL、SRBCT、Leukemia、Ovarian、Colon、Lung、MLL），提出了一种更高效的特征选择方法，比如Gray Wolf（GW）、Particle Swarm Optimization（PSO）和遗传算法（GA）。<details>
<summary>Abstract</summary>
The Horse Herd Optimization Algorithm (HOA) is a new meta-heuristic algorithm based on the behaviors of horses at different ages. The HOA was introduced recently to solve complex and high-dimensional problems. This paper proposes a binary version of the Horse Herd Optimization Algorithm (BHOA) in order to solve discrete problems and select prominent feature subsets. Moreover, this study provides a novel hybrid feature selection framework based on the BHOA and a minimum Redundancy Maximum Relevance (MRMR) filter method. This hybrid feature selection, which is more computationally efficient, produces a beneficial subset of relevant and informative features. Since feature selection is a binary problem, we have applied a new Transfer Function (TF), called X-shape TF, which transforms continuous problems into binary search spaces. Furthermore, the Support Vector Machine (SVM) is utilized to examine the efficiency of the proposed method on ten microarray datasets, namely Lymphoma, Prostate, Brain-1, DLBCL, SRBCT, Leukemia, Ovarian, Colon, Lung, and MLL. In comparison to other state-of-the-art, such as the Gray Wolf (GW), Particle Swarm Optimization (PSO), and Genetic Algorithm (GA), the proposed hybrid method (MRMR-BHOA) demonstrates superior performance in terms of accuracy and minimum selected features. Also, experimental results prove that the X-Shaped BHOA approach outperforms others methods.
</details>
<details>
<summary>摘要</summary>
《各种高维问题的解决方法——骏马群优化算法》是一种新的元规则算法，基于不同年龄的马的行为。该算法最近被提出来解决复杂和高维问题。本文提出了一种二进制版的骏马群优化算法（BHOA），以解决离散问题和选择显著特征子。此外，本研究还提出了一种新的半程特征选择框架，基于BHOA和最小冗余最大相关性（MRMR）筛选方法。这种半程特征选择方法更加高效，生成了有益的相关和有用的特征子。由于特征选择是一个二进制问题，我们采用了一种新的转换函数（TF），即X型TF，将连续问题转换为二进制搜索空间。此外，我们使用支持向量机（SVM）来评估提出的方法在10个微陷数据集上的效率，即肿瘤、 próstata、大脑-1、DLBCL、SRBCT、白细胞癌、卵巢、肠癌和MLL等10个数据集。与其他现状之前的方法，如灰狼（GW）、粒子群动 optimization（PSO）和生物学算法（GA）相比，提出的半程特征选择方法（MRMR-BHOA）在精度和选择的最小特征上显示出超过其他方法的优势。此外，实验结果也证明了X型BHOA方法的优越性。
</details></li>
</ul>
<hr>
<h2 id="A-Two-Part-Machine-Learning-Approach-to-Characterizing-Network-Interference-in-A-B-Testing"><a href="#A-Two-Part-Machine-Learning-Approach-to-Characterizing-Network-Interference-in-A-B-Testing" class="headerlink" title="A Two-Part Machine Learning Approach to Characterizing Network Interference in A&#x2F;B Testing"></a>A Two-Part Machine Learning Approach to Characterizing Network Interference in A&#x2F;B Testing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09790">http://arxiv.org/abs/2308.09790</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuan Yuan, Kristen M. Altenburger</li>
<li>for: 提高A&#x2F;B测试的可靠性和精度，解决网络干扰的问题</li>
<li>methods: 使用机器学习算法确定和描述不同类型的网络干扰，自动确定”曝光地图”，解决现有文献中的两大限制</li>
<li>results: 通过synthetic实验和实际大规模测试（1-2万名Instagram用户），证明了我们的方法可以超越传统的设计基于块随机化和分析基于邻居曝光地图的方法，提高A&#x2F;B测试结果的精度和可靠性。<details>
<summary>Abstract</summary>
The reliability of controlled experiments, or "A/B tests," can often be compromised due to the phenomenon of network interference, wherein the outcome for one unit is influenced by other units. To tackle this challenge, we propose a machine learning-based method to identify and characterize heterogeneous network interference. Our approach accounts for latent complex network structures and automates the task of "exposure mapping'' determination, which addresses the two major limitations in the existing literature. We introduce "causal network motifs'' and employ transparent machine learning models to establish the most suitable exposure mapping that reflects underlying network interference patterns. Our method's efficacy has been validated through simulations on two synthetic experiments and a real-world, large-scale test involving 1-2 million Instagram users, outperforming conventional methods such as design-based cluster randomization and analysis-based neighborhood exposure mapping. Overall, our approach not only offers a comprehensive, automated solution for managing network interference and improving the precision of A/B testing results, but it also sheds light on users' mutual influence and aids in the refinement of marketing strategies.
</details>
<details>
<summary>摘要</summary>
controlled experiments 的可靠性，或“A/B测试”，经常受到网络干扰的影响，这导致一个单位的结果受到其他单位的影响。为解决这个挑战，我们提议一种基于机器学习的方法，用于识别和特征化不同类型的网络干扰。我们的方法考虑了隐藏的复杂网络结构，并自动确定“曝光 mapping”，这两者都是现有文献中的主要限制。我们引入“ causal 网络模式”，并使用透明的机器学习模型来确定最适合的曝光 mapping，这些模型能够反映下面网络干扰模式。我们的方法在两个人工实验和一个实际的大规模测试中，对1-2万名INSTAGRAM用户进行验证，并表现出色，超过了传统的设计基于块随机化和分析基于邻居曝光 mapping的方法。总的来说，我们的方法不仅提供了一种全面、自动化的网络干扰管理和A/B测试结果的精度提高的解决方案，还 shed light on 用户之间的互相影响，并帮助优化市场策略。
</details></li>
</ul>
<hr>
<h2 id="Towards-Grounded-Visual-Spatial-Reasoning-in-Multi-Modal-Vision-Language-Models"><a href="#Towards-Grounded-Visual-Spatial-Reasoning-in-Multi-Modal-Vision-Language-Models" class="headerlink" title="Towards Grounded Visual Spatial Reasoning in Multi-Modal Vision Language Models"></a>Towards Grounded Visual Spatial Reasoning in Multi-Modal Vision Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09778">http://arxiv.org/abs/2308.09778</a></li>
<li>repo_url: None</li>
<li>paper_authors: Navid Rajabi, Jana Kosecka</li>
<li>for: 这个研究旨在评估大规模视语言模型（VLM）在不同的视觉理解任务中表现，包括数字、引用表达和通用的视觉问答任务。</li>
<li>methods: 该研究使用了细化的组合基础grounding方法，并提出了底层方法来评估视空间关系理解任务的表现。</li>
<li>results: 研究发现，当前的VLM模型在理解视空间关系方面表现不佳，与人类表现之间存在较大的差距。<details>
<summary>Abstract</summary>
With the advances in large scale vision-and-language models (VLMs) it is of interest to assess their performance on various visual reasoning tasks such as counting, referring expressions and general visual question answering. The focus of this work is to study the ability of these models to understanding spatial relations. Previously, this has been tackled using image-text matching (Liu, Emerson, and Collier 2022) or visual question answering task, both showing poor performance and a large gap compared to human performance. To better understand the gap, we present fine-grained compositional grounding of spatial relationships and propose a bottom up approach for ranking spatial clauses and evaluating the performance of spatial relationship reasoning task. We propose to combine the evidence from grounding noun phrases corresponding to objects and their locations to compute the final rank of the spatial clause. We demonstrate the approach on representative vision-language models (Tan and Bansal 2019; Gupta et al. 2022; Kamath et al. 2021) and compare and highlight their abilities to reason about spatial relationships.
</details>
<details>
<summary>摘要</summary>
With the advances in large-scale vision-and-language models (VLMs), it is of interest to assess their performance on various visual reasoning tasks such as counting, referring expressions, and general visual question answering. The focus of this work is to study the ability of these models to understand spatial relations. Previously, this has been tackled using image-text matching (Liu, Emerson, and Collier 2022) or visual question answering tasks, both showing poor performance and a large gap compared to human performance. To better understand the gap, we present fine-grained compositional grounding of spatial relationships and propose a bottom-up approach for ranking spatial clauses and evaluating the performance of spatial relationship reasoning tasks. We propose to combine the evidence from grounding noun phrases corresponding to objects and their locations to compute the final rank of the spatial clause. We demonstrate the approach on representative vision-language models (Tan and Bansal 2019; Gupta et al. 2022; Kamath et al. 2021) and compare and highlight their abilities to reason about spatial relationships.Here's the translation in Traditional Chinese: WITH 大规模的视力语言模型（VLM）的发展，有兴趣评估它们在不同的视觉推理任务上的表现，例如数量、参考表达和通用的视觉问题回答。这个研究的重点是研究这些模型对空间关系的理解。以前，这已经使用了图像和文本匹配（Liu、Emerson和Collier 2022）或视觉问题回答任务，都显示了轻微的表现和人类表现之间的大差。为了更好地理解这个差距，我们提出了细化的实体基底推理和评估视觉关系理解任务的方法。我们提议将对象和其位置的语言表达与它们的位置进行细化的实体基底推理，并将这些证据组合以计算最终排名的视觉关系 clause。我们在代表性的视力语言模型（Tan和Bansal 2019；Gupta et al. 2022；Kamath et al. 2021）上实现了这个方法，并与之比较和强调它们在视觉关系理解方面的能力。
</details></li>
</ul>
<hr>
<h2 id="Time-Series-Predictions-in-Unmonitored-Sites-A-Survey-of-Machine-Learning-Techniques-in-Water-Resources"><a href="#Time-Series-Predictions-in-Unmonitored-Sites-A-Survey-of-Machine-Learning-Techniques-in-Water-Resources" class="headerlink" title="Time Series Predictions in Unmonitored Sites: A Survey of Machine Learning Techniques in Water Resources"></a>Time Series Predictions in Unmonitored Sites: A Survey of Machine Learning Techniques in Water Resources</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09766">http://arxiv.org/abs/2308.09766</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jared D. Willard, Charuleka Varadharajan, Xiaowei Jia, Vipin Kumar</li>
<li>for: 预测不监测水体环境变量的精度减少了水资源科学中的长期挑战。大多数新鲜水资源的监测不具备关键环境变量的监测，尽管气候和土地使用变化的影响对水资源产生了越来越严重的影响。</li>
<li>methods: 现代机器学习方法在水文时间序预测中表现出了超越过程知识和经验模型的能力，特别是EXTRACT信息FROM大量多样数据集。</li>
<li>results: 我们回顾了相关的状态艺术应用程序，涵盖了流量和水质预测等水资源预测领域。分析结果表明，以往努力都集中在了深度学习框架上，但对不同类型机器学习方法的比较是 rare 和不充分。我们认为还有几个开放问题需要解决，包括包括动态输入和站点特点、机制理解和空间Context，以及现代机器学习框架中的可解释AI技术。<details>
<summary>Abstract</summary>
Prediction of dynamic environmental variables in unmonitored sites remains a long-standing challenge for water resources science. The majority of the world's freshwater resources have inadequate monitoring of critical environmental variables needed for management. Yet, the need to have widespread predictions of hydrological variables such as river flow and water quality has become increasingly urgent due to climate and land use change over the past decades, and their associated impacts on water resources. Modern machine learning methods increasingly outperform their process-based and empirical model counterparts for hydrologic time series prediction with their ability to extract information from large, diverse data sets. We review relevant state-of-the art applications of machine learning for streamflow, water quality, and other water resources prediction and discuss opportunities to improve the use of machine learning with emerging methods for incorporating watershed characteristics into deep learning models, transfer learning, and incorporating process knowledge into machine learning models. The analysis here suggests most prior efforts have been focused on deep learning learning frameworks built on many sites for predictions at daily time scales in the United States, but that comparisons between different classes of machine learning methods are few and inadequate. We identify several open questions for time series predictions in unmonitored sites that include incorporating dynamic inputs and site characteristics, mechanistic understanding and spatial context, and explainable AI techniques in modern machine learning frameworks.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the following text into Simplified Chinese.<</SYS>>现代机器学习方法在水资源预测中表现越来越出色，可以从大量多样数据集中提取信息。然而，预测不监测站点的水文变量仍然是水资源科学领域的长期挑战。全球大多数新鲜水资源尚未实施监测关键环境变量，尤其是气候和土地使用变化的影响。因此，广泛预测河流流量和水质等水资源变量的需求日益紧迫。本文将介绍相关的现代机器学习应用，包括流速、水质和其他水资源预测。我们还将讨论如何在深入学习模型中包含水体特征、知识传播和机器学习模型。分析结果表明，现有的尝试主要集中在美国多个站点的深度学习框架上，但对不同类型机器学习方法的比较 remains 有限。我们确定了一些未解决的问题，包括 incorporating 动态输入和站点特征、机制理解和空间上下文，以及现代机器学习框架中的可解释AI技术。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Taken-by-Surprise-Contrast-effect-for-Similarity-Scores"><a href="#Taken-by-Surprise-Contrast-effect-for-Similarity-Scores" class="headerlink" title="Taken by Surprise: Contrast effect for Similarity Scores"></a>Taken by Surprise: Contrast effect for Similarity Scores</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09765">http://arxiv.org/abs/2308.09765</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/meetelise/surprise-similarity">https://github.com/meetelise/surprise-similarity</a></li>
<li>paper_authors: Thomas C. Bachlechner, Mario Martone, Marjorie Schillo</li>
<li>for: 本研究旨在提高自然语言处理、信息检索和分类任务中的对象向量表示的准确评估。</li>
<li>methods: 该研究提出了一种名为“奇异分数”的ensemble-normalized相似度度量，它考虑到人类对对象之间的相似程度的感知效应，并在零&#x2F;几shot文档分类任务中显示出10-15%的提高。</li>
<li>results: 研究发现，使用“奇异分数”相似度度量 Typically find 10-15% better performance compared to raw cosine similarity in zero&#x2F;few shot document classification tasks.I hope that helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
Accurately evaluating the similarity of object vector embeddings is of critical importance for natural language processing, information retrieval and classification tasks. Popular similarity scores (e.g cosine similarity) are based on pairs of embedding vectors and disregard the distribution of the ensemble from which objects are drawn. Human perception of object similarity significantly depends on the context in which the objects appear. In this work we propose the $\textit{surprise score}$, an ensemble-normalized similarity metric that encapsulates the contrast effect of human perception and significantly improves the classification performance on zero- and few-shot document classification tasks. This score quantifies the surprise to find a given similarity between two elements relative to the pairwise ensemble similarities. We evaluate this metric on zero/few shot classification and clustering tasks and typically find 10-15 % better performance compared to raw cosine similarity. Our code is available at https://github.com/MeetElise/surprise-similarity.
</details>
<details>
<summary>摘要</summary>
非常重要的评估对象vector embedding的相似性，是自然语言处理、信息检索和分类任务中的关键。受欢迎的相似性分数（如归一化相似性）忽略了对象 ensemble 的分布。人类对物体相似性的认知具有Context-dependent的特点，在这种情况下，我们提出了“surprise score”，一种ensemble-normalized相似度度量，它考虑了对象之间的对比效果，并在零/几shot文档分类任务中显示了10-15%的改善性。我们在这些任务中评估了这个度量，并通常发现它比 raw cosine similarity 更好。我们的代码可以在https://github.com/MeetElise/surprise-similarity上找到。
</details></li>
</ul>
<hr>
<h2 id="The-Impact-of-Background-Removal-on-Performance-of-Neural-Networks-for-Fashion-Image-Classification-and-Segmentation"><a href="#The-Impact-of-Background-Removal-on-Performance-of-Neural-Networks-for-Fashion-Image-Classification-and-Segmentation" class="headerlink" title="The Impact of Background Removal on Performance of Neural Networks for Fashion Image Classification and Segmentation"></a>The Impact of Background Removal on Performance of Neural Networks for Fashion Image Classification and Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09764">http://arxiv.org/abs/2308.09764</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junhui Liang, Ying Liu, Vladimir Vlassov</li>
<li>for: 提高时尚图像数据质量，提高模型性能</li>
<li>methods: 使用突出对象检测进行背景除去</li>
<li>results: 对时尚图像进行背景除去可以提高模型准确率，但是不适用于深度神经网络。<details>
<summary>Abstract</summary>
Fashion understanding is a hot topic in computer vision, with many applications having great business value in the market. Fashion understanding remains a difficult challenge for computer vision due to the immense diversity of garments and various scenes and backgrounds. In this work, we try removing the background from fashion images to boost data quality and increase model performance. Having fashion images of evident persons in fully visible garments, we can utilize Salient Object Detection to achieve the background removal of fashion data to our expectations. A fashion image with the background removed is claimed as the "rembg" image, contrasting with the original one in the fashion dataset. We conducted extensive comparative experiments with these two types of images on multiple aspects of model training, including model architectures, model initialization, compatibility with other training tricks and data augmentations, and target task types. Our experiments show that background removal can effectively work for fashion data in simple and shallow networks that are not susceptible to overfitting. It can improve model accuracy by up to 5% in the classification on the FashionStyle14 dataset when training models from scratch. However, background removal does not perform well in deep neural networks due to incompatibility with other regularization techniques like batch normalization, pre-trained initialization, and data augmentations introducing randomness. The loss of background pixels invalidates many existing training tricks in the model training, adding the risk of overfitting for deep models.
</details>
<details>
<summary>摘要</summary>
现代服装理解是计算机视觉领域热点话题，具有广泛的商业价值。然而，服装理解仍然是计算机视觉中的困难挑战，因为衣服的多样性和不同的场景和背景。在这种工作中，我们尝试将背景从时尚图像中除掉，以提高数据质量并提高模型性能。通过使用突出对象检测来实现背景的除掉，我们称之为“rembg”图像，与原始图像在时尚数据集中进行比较。我们进行了多种比较试验，包括模型架构、模型初始化、与其他训练技巧和数据扩展Compatibility，以及目标任务类型。我们的实验结果表明，背景除掉可以有效地提高时尚数据上的模型准确率。在FashionStyle14数据集上进行分类训练时，背景除掉可以提高模型准确率达到5%。然而，背景除掉不适合深度神经网络，因为它们与其他正则化技术，如批处理normalization、预先初始化和数据扩展，不兼容。失去背景像素会让许多现有的训练技巧无法在模型训练中使用，增加深度模型的风险。
</details></li>
</ul>
<hr>
<h2 id="Data-Compression-and-Inference-in-Cosmology-with-Self-Supervised-Machine-Learning"><a href="#Data-Compression-and-Inference-in-Cosmology-with-Self-Supervised-Machine-Learning" class="headerlink" title="Data Compression and Inference in Cosmology with Self-Supervised Machine Learning"></a>Data Compression and Inference in Cosmology with Self-Supervised Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09751">http://arxiv.org/abs/2308.09751</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aizhanaakhmet/data-compression-inference-in-cosmology-with-ssl">https://github.com/aizhanaakhmet/data-compression-inference-in-cosmology-with-ssl</a></li>
<li>paper_authors: Aizhan Akhmetzhanova, Siddharth Mishra-Sharma, Cora Dvorkin</li>
<li>for: 这种方法可以快速 SUMMARIZE 大量数据，以便进行下游任务。</li>
<li>methods: 这种方法使用 simulation-based 自我超vised 机器学习，通过创建代表性的摘要来快速 SUMMARIZE 大量数据。</li>
<li>results: 这种方法可以提供高度信息含量的摘要，可以用于准确地推断参数。  Additionally, the method is insensitive to prescribed systematic effects, such as the influence of baryonic physics.<details>
<summary>Abstract</summary>
The influx of massive amounts of data from current and upcoming cosmological surveys necessitates compression schemes that can efficiently summarize the data with minimal loss of information. We introduce a method that leverages the paradigm of self-supervised machine learning in a novel manner to construct representative summaries of massive datasets using simulation-based augmentations. Deploying the method on hydrodynamical cosmological simulations, we show that it can deliver highly informative summaries, which can be used for a variety of downstream tasks, including precise and accurate parameter inference. We demonstrate how this paradigm can be used to construct summary representations that are insensitive to prescribed systematic effects, such as the influence of baryonic physics. Our results indicate that self-supervised machine learning techniques offer a promising new approach for compression of cosmological data as well its analysis.
</details>
<details>
<summary>摘要</summary>
“ cosmological 调查中的大量数据涌入导致了各种压缩方法的实现，以确保仅对数据进行最小的损失。我们介绍了一种方法，利用自动机器学习的思想，在实验增强的情况下，创建大规模数据的代表SUMMARY。在液体动力学 cosmological 实验中执行了这种方法，发现它可以提供高度有用的SUMMARY，可以用于多种下游任务，包括精确的参数推断。我们显示了这种思想可以用来建构对系统性效应不敏感的SUMMARY表示，例如关于生物物理的影响。我们的结果显示自动机器学习技术可以对 cosmological 数据实现高效的压缩和分析。”Note: Please note that the translation is in Simplified Chinese, and the word order and sentence structure may be different from the original text.
</details></li>
</ul>
<hr>
<h2 id="Robust-Monocular-Depth-Estimation-under-Challenging-Conditions"><a href="#Robust-Monocular-Depth-Estimation-under-Challenging-Conditions" class="headerlink" title="Robust Monocular Depth Estimation under Challenging Conditions"></a>Robust Monocular Depth Estimation under Challenging Conditions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09711">http://arxiv.org/abs/2308.09711</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/md4all/md4all">https://github.com/md4all/md4all</a></li>
<li>paper_authors: Stefano Gasperini, Nils Morbitzer, HyunJun Jung, Nassir Navab, Federico Tombari</li>
<li>for: 提高单目深度估计的可靠性，并在不同的环境和学习环境下实现可靠性。</li>
<li>methods: 基于现有方法的自我或全自动超vision，通过生成复杂样本并在原始图像上计算标准损失来训练模型。</li>
<li>results: 在nuScenes和Oxford RobotCar等两个公共数据集上进行了广泛的实验，并覆盖了先前的工作，在标准和挑战性条件下表现出色。<details>
<summary>Abstract</summary>
While state-of-the-art monocular depth estimation approaches achieve impressive results in ideal settings, they are highly unreliable under challenging illumination and weather conditions, such as at nighttime or in the presence of rain. In this paper, we uncover these safety-critical issues and tackle them with md4all: a simple and effective solution that works reliably under both adverse and ideal conditions, as well as for different types of learning supervision. We achieve this by exploiting the efficacy of existing methods under perfect settings. Therefore, we provide valid training signals independently of what is in the input. First, we generate a set of complex samples corresponding to the normal training ones. Then, we train the model by guiding its self- or full-supervision by feeding the generated samples and computing the standard losses on the corresponding original images. Doing so enables a single model to recover information across diverse conditions without modifications at inference time. Extensive experiments on two challenging public datasets, namely nuScenes and Oxford RobotCar, demonstrate the effectiveness of our techniques, outperforming prior works by a large margin in both standard and challenging conditions. Source code and data are available at: https://md4all.github.io.
</details>
<details>
<summary>摘要</summary>
当前最前沿单目深度估计方法在理想情况下可以 achieve impressive results，但在具有挑战性的照明和天气条件下，其可靠性却受到了挑战。在这篇论文中，我们揭示了这些安全关键问题，并通过md4all：一个简单而有效的解决方案，可以在不同的条件下工作，包括不良和理想的情况，以及不同类型的学习监督。我们通过利用现有方法在完美情况下的效果，实现了这一点。因此，我们可以在训练时提供有效的训练信号，不abhängig于输入中的内容。首先，我们生成了一组复杂的样本，与传统的训练样本相对应。然后，我们通过引导自我或全自监督，将生成的样本和对应的原始图像之间的标准损失进行训练。这样做的核心思想是，让模型在不同的条件下可以在推理时恢复信息。我们在 nuScenes 和 Oxford RobotCar 两个公共数据集上进行了广泛的实验，并证明了我们的技术的有效性，与之前的工作相比，在标准和挑战性的情况下都有大幅度的提高。软件代码和数据可以在 <https://md4all.github.io> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Neural-network-quantum-state-study-of-the-long-range-antiferromagnetic-Ising-chain"><a href="#Neural-network-quantum-state-study-of-the-long-range-antiferromagnetic-Ising-chain" class="headerlink" title="Neural-network quantum state study of the long-range antiferromagnetic Ising chain"></a>Neural-network quantum state study of the long-range antiferromagnetic Ising chain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09709">http://arxiv.org/abs/2308.09709</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jicheol Kim, Dongkyu Kim, Dong-Hee Kim</li>
<li>for:  investigate quantum phase transitions in the transverse field Ising chain with algebraically decaying long-range antiferromagnetic interactions</li>
<li>methods:  using the variational Monte Carlo method with the restricted Boltzmann machine as a trial wave function ansatz</li>
<li>results:  the central charge deviates from 1&#x2F;2 at a small decay exponent $\alpha_\mathrm{LR}$, and the threshold of the Ising universality and the conformal symmetry is estimated to be in the range of $2 \lesssim \alpha_\mathrm{LR} &lt; 3$.<details>
<summary>Abstract</summary>
We investigate quantum phase transitions in the transverse field Ising chain with algebraically decaying long-range antiferromagnetic interactions by using the variational Monte Carlo method with the restricted Boltzmann machine being employed as a trial wave function ansatz. In the finite-size scaling analysis with the order parameter and the second R\'enyi entropy, we find that the central charge deviates from 1/2 at a small decay exponent $\alpha_\mathrm{LR}$ in contrast to the critical exponents staying very close to the short-range (SR) Ising values regardless of $\alpha_\mathrm{LR}$ examined, supporting the previously proposed scenario of conformal invariance breakdown. To identify the threshold of the Ising universality and the conformal symmetry, we perform two additional tests for the universal Binder ratio and the conformal field theory (CFT) description of the correlation function. It turns out that both indicate a noticeable deviation from the SR Ising class at $\alpha_\mathrm{LR} < 2$. However, a closer look at the scaled correlation function for $\alpha_\mathrm{LR} \ge 2$ shows a gradual change from the asymptotic line of the CFT verified at $\alpha_\mathrm{LR} = 3$, providing a rough estimate of the threshold being in the range of $2 \lesssim \alpha_\mathrm{LR} < 3$.
</details>
<details>
<summary>摘要</summary>
我们调查量子阶段转变在横向离散链磁铁中，使用统计力学 Monte Carlo 方法，将Restricted Boltzmann Machine作为实验波函数拟合。在 finite-size 拓展分析中，我们发现在小数字 $\alpha_\text{LR}$ 下，中心 CHARGE 偏离 1/2，与短距离铁质值不同，支持之前提出的对称性破坏enario。为了识别阶段对称性和对称性破坏的阈值，我们进行了两个额外的测试：一是通用的 Binder 率，二是对称场论 (CFT) 的描述。结果显示，这两个测试都显示在 $\alpha_\text{LR} < 2$ 的情况下，有明显的偏离短距离铁质值。然而，在 $\alpha_\text{LR} \ge 2$ 的情况下，随着测量尺度的增加，扩展函数的演化逐渐变得更加类似 CFT 预测的 asymptotic 线，提供了一个粗略的估计阈值在 $2 \lesssim \alpha_\text{LR} < 3$ 之间。
</details></li>
</ul>
<hr>
<h2 id="Do-you-know-what-q-means"><a href="#Do-you-know-what-q-means" class="headerlink" title="Do you know what q-means?"></a>Do you know what q-means?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09701">http://arxiv.org/abs/2308.09701</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Sfedfcv/redesigned-pancake">https://github.com/Sfedfcv/redesigned-pancake</a></li>
<li>paper_authors: João F. Doriguello, Alessandro Luongo, Ewin Tang</li>
<li>For: 本文提出了一种改进版本的 “$q$-means” 算法，用于实现 Approximate $k$-means  clustering。* Methods: 本算法使用 QRAM 来准备和测量简单的状态，而不需要使用先前的量子线性代数 primitives。* Results: 本算法的时间复杂度为 $O\big(\frac{k^{2}{\varepsilon^2}(\sqrt{k}d + \log(Nd))\big)$，与先前的算法相比，它维持了对 $N$ 的多阶幂度依赖，并改进了大多数其他参数的依赖。 In addition, a “dequantized” classical algorithm for $\varepsilon$-$k$-means is also presented, which runs in $O\big(\frac{k^{2}{\varepsilon^2}(kd + \log(Nd))\big)$ time and matches the polylogarithmic dependence on $N$ attained by the quantum algorithms.<details>
<summary>Abstract</summary>
Clustering is one of the most important tools for analysis of large datasets, and perhaps the most popular clustering algorithm is Lloyd's iteration for $k$-means. This iteration takes $N$ vectors $v_1,\dots,v_N\in\mathbb{R}^d$ and outputs $k$ centroids $c_1,\dots,c_k\in\mathbb{R}^d$; these partition the vectors into clusters based on which centroid is closest to a particular vector. We present an overall improved version of the "$q$-means" algorithm, the quantum algorithm originally proposed by Kerenidis, Landman, Luongo, and Prakash (2019) which performs $\varepsilon$-$k$-means, an approximate version of $k$-means clustering. This algorithm does not rely on the quantum linear algebra primitives of prior work, instead only using its QRAM to prepare and measure simple states based on the current iteration's clusters. The time complexity is $O\big(\frac{k^{2}{\varepsilon^2}(\sqrt{k}d + \log(Nd))\big)$ and maintains the polylogarithmic dependence on $N$ while improving the dependence on most of the other parameters. We also present a "dequantized" algorithm for $\varepsilon$-$k$-means which runs in $O\big(\frac{k^{2}{\varepsilon^2}(kd + \log(Nd))\big)$ time. Notably, this classical algorithm matches the polylogarithmic dependence on $N$ attained by the quantum algorithms.
</details>
<details>
<summary>摘要</summary>
“集群是大规模数据分析中最重要的工具之一，而最受欢迎的集群算法之一是戴尔斯的$k$-means迭代。这个迭代接受$N$个$v_1,\ldots,v_N\in\mathbb{R}^d$的向量，并输出$k$个中心点$c_1,\ldots,c_k\in\mathbb{R}^d$；这些中心点将向量 partition 成 clusters 基于哪个中心点最近于特定向量。我们提出了一个全面改进的 "$q$-means" 算法，即 kerenedis 等人（2019）提出的量子算法，实现 $\varepsilon$-$k$-means，一种 Approximate 版本的 $k$-means 集群算法。这个算法不依赖于量子线性代数基本操作，而只使用其 QRAM 准备和测量简单状态，基于当前迭代的 clusters。时间复杂度为 $O\big(\frac{k^{2}{\varepsilon^2}(\sqrt{k}d + \log(Nd))\big)$，保持了对 $N$ 的多项式依赖，而改善了大多数其他参数的依赖。我们还提出了一个 "dequantized" 算法 для $\varepsilon$-$k$-means，运行时间为 $O\big(\frac{k^{2}{\varepsilon^2}(kd + \log(Nd))\big)$，并且 notable 地与量子算法的多项式依赖相符。”
</details></li>
</ul>
<hr>
<h2 id="A-Lightweight-Transformer-for-Faster-and-Robust-EBSD-Data-Collection"><a href="#A-Lightweight-Transformer-for-Faster-and-Robust-EBSD-Data-Collection" class="headerlink" title="A Lightweight Transformer for Faster and Robust EBSD Data Collection"></a>A Lightweight Transformer for Faster and Robust EBSD Data Collection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09693">http://arxiv.org/abs/2308.09693</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hdong920/ebsd_slice_recovery">https://github.com/hdong920/ebsd_slice_recovery</a></li>
<li>paper_authors: Harry Dong, Sean Donegan, Megna Shah, Yuejie Chi</li>
<li>for: 提高三维电子背托干涉diffraction（EBSD）微scopy数据质量</li>
<li>methods: 使用转换器模型和投影算法进行数据处理和恢复</li>
<li>results: 比existings方法更高的数据恢复精度<details>
<summary>Abstract</summary>
Three dimensional electron back-scattered diffraction (EBSD) microscopy is a critical tool in many applications in materials science, yet its data quality can fluctuate greatly during the arduous collection process, particularly via serial-sectioning. Fortunately, 3D EBSD data is inherently sequential, opening up the opportunity to use transformers, state-of-the-art deep learning architectures that have made breakthroughs in a plethora of domains, for data processing and recovery. To be more robust to errors and accelerate this 3D EBSD data collection, we introduce a two step method that recovers missing slices in an 3D EBSD volume, using an efficient transformer model and a projection algorithm to process the transformer's outputs. Overcoming the computational and practical hurdles of deep learning with scarce high dimensional data, we train this model using only synthetic 3D EBSD data with self-supervision and obtain superior recovery accuracy on real 3D EBSD data, compared to existing methods.
</details>
<details>
<summary>摘要</summary>
三维电子反射干扰diffraction（EBSD）顾问是物理科学中多种应用的关键工具，但它的数据质量可能会在收集过程中呈现大幅波动，特别是通过串行分割。幸运的是，3D EBSD数据是顺序的，这为使用变换器，现代深度学习架构，提供了机会。为了更加鲁棒地处理和加速3D EBSD数据收集，我们介绍了一种两步方法，使用高效的变换器模型和投影算法来处理变换器的输出。通过超越深度学习中的计算和实践障碍，我们使用只有自我超vision的synthetic 3D EBSD数据进行训练，并在实际3D EBSD数据上获得了比现有方法更高的恢复精度。
</details></li>
</ul>
<hr>
<h2 id="Reduced-Order-Modeling-of-a-MOOSE-based-Advanced-Manufacturing-Model-with-Operator-Learning"><a href="#Reduced-Order-Modeling-of-a-MOOSE-based-Advanced-Manufacturing-Model-with-Operator-Learning" class="headerlink" title="Reduced Order Modeling of a MOOSE-based Advanced Manufacturing Model with Operator Learning"></a>Reduced Order Modeling of a MOOSE-based Advanced Manufacturing Model with Operator Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09691">http://arxiv.org/abs/2308.09691</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mahmoud Yaseen, Dewen Yushu, Peter German, Xu Wu</li>
<li>for: 本研究旨在开发一种高精度但运行速度快的减少级模型（ROM），用于在深度再强化学习（DRL）控制和优化方法中使用。</li>
<li>methods: 本研究使用了运算学（OL）基于方法，可以学习变量的家族方程。在这种情况下，我们使用了傅ри欧姆算法来构建OL-based ROM。</li>
<li>results: 我们对比了OL-based ROM和深度神经网络基于ROM的性能，发现OL-based ROM的性能更高，运行速度更快。<details>
<summary>Abstract</summary>
Advanced Manufacturing (AM) has gained significant interest in the nuclear community for its potential application on nuclear materials. One challenge is to obtain desired material properties via controlling the manufacturing process during runtime. Intelligent AM based on deep reinforcement learning (DRL) relies on an automated process-level control mechanism to generate optimal design variables and adaptive system settings for improved end-product properties. A high-fidelity thermo-mechanical model for direct energy deposition has recently been developed within the MOOSE framework at the Idaho National Laboratory (INL). The goal of this work is to develop an accurate and fast-running reduced order model (ROM) for this MOOSE-based AM model that can be used in a DRL-based process control and optimization method. Operator learning (OL)-based methods will be employed due to their capability to learn a family of differential equations, in this work, produced by changing process variables in the Gaussian point heat source for the laser. We will develop OL-based ROM using Fourier neural operator, and perform a benchmark comparison of its performance with a conventional deep neural network-based ROM.
</details>
<details>
<summary>摘要</summary>
高级生产技术（高级生产）在核心社区引起了广泛的关注，因为它可能用于核材料的制造。一个挑战是通过控制生产过程中的runtime来获得所需的材料性能。基于深度强化学习（DRL）的智能高级生产通过自动化过程级别控制机制来生成优化的设计变量和适应系统设置，以提高终产品的性能。在美国伊达荷大学（INL）的MOOSE框架中，最近已经开发了一个高精度热力学-机械模型，用于直接能量沟入。该工作的目标是开发一个准确快速的减少阶模型（ROM），用于这个MOOSE基于AM模型的DRL控制和优化方法。我们将使用运算学（OL）基本的方法，因为它可以学习一个家族的微分方程，在这里，由变量的改变生成的 Gaussian 点热源中的激光。我们将开发 OL 基本的 ROM 使用 Fourier 神经网络，并对其性能与一个传统的深度神经网络基本的 ROM 进行比较。
</details></li>
</ul>
<hr>
<h2 id="Graph-of-Thoughts-Solving-Elaborate-Problems-with-Large-Language-Models"><a href="#Graph-of-Thoughts-Solving-Elaborate-Problems-with-Large-Language-Models" class="headerlink" title="Graph of Thoughts: Solving Elaborate Problems with Large Language Models"></a>Graph of Thoughts: Solving Elaborate Problems with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09687">http://arxiv.org/abs/2308.09687</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/spcl/graph-of-thoughts">https://github.com/spcl/graph-of-thoughts</a></li>
<li>paper_authors: Maciej Besta, Nils Blach, Ales Kubicek, Robert Gerstenberger, Lukas Gianinazzi, Joanna Gajda, Tomasz Lehmann, Michal Podstawski, Hubert Niewiadomski, Piotr Nyczyk, Torsten Hoefler</li>
<li>for: 提高大语言模型（LLM）的提问能力，超过链条思维或树思维（ToT）的限制。</li>
<li>methods: 利用Graph of Thoughts（GoT）框架，将LLM生成的信息模型为一个任意图，其中单元为“LLM思维”，弧线表示思维之间的依赖关系。这种方法可以将LLM思维合并成 synergistic 结果，提炼整个思维网络的核心，或通过反馈循环进行思维提升。</li>
<li>results: GoT 可以在不同任务上提供优化，例如在排序任务上提高质量62%，同时降低成本&gt;31%。此外，GoT 可以扩展新的思维转换，因此可以用于开拓新的提问方案。这项工作使得 LLM 的思维更加接近人类思维或大脑机制，如回忆、复杂网络等。<details>
<summary>Abstract</summary>
We introduce Graph of Thoughts (GoT): a framework that advances prompting capabilities in large language models (LLMs) beyond those offered by paradigms such as Chain-of-Thought or Tree of Thoughts (ToT). The key idea and primary advantage of GoT is the ability to model the information generated by an LLM as an arbitrary graph, where units of information ("LLM thoughts") are vertices, and edges correspond to dependencies between these vertices. This approach enables combining arbitrary LLM thoughts into synergistic outcomes, distilling the essence of whole networks of thoughts, or enhancing thoughts using feedback loops. We illustrate that GoT offers advantages over state of the art on different tasks, for example increasing the quality of sorting by 62% over ToT, while simultaneously reducing costs by >31%. We ensure that GoT is extensible with new thought transformations and thus can be used to spearhead new prompting schemes. This work brings the LLM reasoning closer to human thinking or brain mechanisms such as recurrence, both of which form complex networks.
</details>
<details>
<summary>摘要</summary>
我们介绍Graph of Thoughts（GoT）框架，这种框架可以在大型语言模型（LLM）中提高提示能力，超越链条思维和树思维（ToT）的限制。GoT的关键思想和主要优势在于将LLM生成的信息视为一个可变图形，其中单元为“LLM思维”，而边表示这些单元之间的依赖关系。这种方法允许将任意LLM思维结合成 synergistic 结果，浓缩整个网络思维的核心，或者通过反馈循环进行思维增强。我们示出GoT在不同任务上具有优于现状的优势，例如比ToT提高排序质量62%，同时降低成本>31%。我们还证明GoT可扩展新的思维转换，因此可以用来开拓新的提示方案。这项工作使得LLM的思维更加接近人类思维或脑机制，如回忆、循环等，这些机制都形成复杂的网络。
</details></li>
</ul>
<hr>
<h2 id="Audiovisual-Moments-in-Time-A-Large-Scale-Annotated-Dataset-of-Audiovisual-Actions"><a href="#Audiovisual-Moments-in-Time-A-Large-Scale-Annotated-Dataset-of-Audiovisual-Actions" class="headerlink" title="Audiovisual Moments in Time: A Large-Scale Annotated Dataset of Audiovisual Actions"></a>Audiovisual Moments in Time: A Large-Scale Annotated Dataset of Audiovisual Actions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09685">http://arxiv.org/abs/2308.09685</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mjoannou/audiovisual-moments-in-time">https://github.com/mjoannou/audiovisual-moments-in-time</a></li>
<li>paper_authors: Michael Joannou, Pia Rotshtein, Uta Noppeney</li>
<li>for: 这个论文主要目的是提供一个大规模的audiovisual动作事件集（AVMIT），以便用于计算机模型和人类参与者的研究。</li>
<li>methods: 论文使用了一个大规模的annotation任务，从MIT数据集中选择3秒的audiovisual视频，并让11名参与者标注每个试验 whether the labelled audiovisual动作事件是存在的，以及这个事件是视频中最显著的特征。</li>
<li>results: 论文提供了57,177个audiovisual视频的标注，每个视频由3名参与者独立地评估。在这个初始收集中，论文创建了一个精心测试集，包括16种动作类别，每个类别有60个视频（共960个视频）。论文还提供了2个预计算的audiovisual特征嵌入，使用VGGish&#x2F;YamNet和VGG16&#x2F;EfficientNetB0来降低audiovisual DNN研究的入门难度。<details>
<summary>Abstract</summary>
We present Audiovisual Moments in Time (AVMIT), a large-scale dataset of audiovisual action events. In an extensive annotation task 11 participants labelled a subset of 3-second audiovisual videos from the Moments in Time dataset (MIT). For each trial, participants assessed whether the labelled audiovisual action event was present and whether it was the most prominent feature of the video. The dataset includes the annotation of 57,177 audiovisual videos, each independently evaluated by 3 of 11 trained participants. From this initial collection, we created a curated test set of 16 distinct action classes, with 60 videos each (960 videos). We also offer 2 sets of pre-computed audiovisual feature embeddings, using VGGish/YamNet for audio data and VGG16/EfficientNetB0 for visual data, thereby lowering the barrier to entry for audiovisual DNN research. We explored the advantages of AVMIT annotations and feature embeddings to improve performance on audiovisual event recognition. A series of 6 Recurrent Neural Networks (RNNs) were trained on either AVMIT-filtered audiovisual events or modality-agnostic events from MIT, and then tested on our audiovisual test set. In all RNNs, top 1 accuracy was increased by 2.71-5.94\% by training exclusively on audiovisual events, even outweighing a three-fold increase in training data. We anticipate that the newly annotated AVMIT dataset will serve as a valuable resource for research and comparative experiments involving computational models and human participants, specifically when addressing research questions where audiovisual correspondence is of critical importance.
</details>
<details>
<summary>摘要</summary>
我们介绍了听视频时刻事件（AVMIT）数据集，这是一个大规模的听视频动作事件数据集。在一项广泛的标注任务中，11名参与者标注了MIT数据集中的3秒听视频示例的一部分。每个试验中，参与者评估了听视频动作事件是否存在，以及它是视频中最为出色的特征。该数据集包括57,177个听视频示例，每个示例由3名训练过的参与者独立地评估。从这个初始收集中，我们创建了一个精心选择的测试集，包括16种不同的动作类别，每个类别有60个视频示例（共960个视频示例）。我们还提供了两个预计算的听视频特征嵌入，使用VGGish/YamNet对音频数据进行预处理，并使用VGG16/EfficientNetB0对视频数据进行预处理，从而降低了听视频DNN研究的门槛。我们评估了AVMIT标注和特征嵌入的优势，以提高听视频事件认识性能。我们使用6个回归神经网络（RNN）在AVMIT filtered audiovisual事件或MIT模态不同的事件上训练，然后在我们的听视频测试集上进行测试。在所有RNN中，只训练在 audiovisual事件上的总准确率提高了2.71-5.94%，甚至超过了三倍增加的训练数据量。我们预计这些新的AVMIT标注数据集将成为未来研究和比较实验中的重要资源，特别是在研究问题中，听视频匹配的重要性很高。
</details></li>
</ul>
<hr>
<h2 id="Variational-optimization-of-the-amplitude-of-neural-network-quantum-many-body-ground-states"><a href="#Variational-optimization-of-the-amplitude-of-neural-network-quantum-many-body-ground-states" class="headerlink" title="Variational optimization of the amplitude of neural-network quantum many-body ground states"></a>Variational optimization of the amplitude of neural-network quantum many-body ground states</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09664">http://arxiv.org/abs/2308.09664</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jia-Qi Wang, Rong-Qiang He, Zhong-Yi Lu</li>
<li>for: 这篇论文旨在探讨基于神经网络的量子多体ground state搜索方法，并对其进行优化。</li>
<li>methods: 该方法将量子多体变量波函数分解为一个实值神经网络和一个固定的符号结构，然后优化神经网络。神经网络使用了卷积层和径向层，即ResNet。</li>
<li>results: 该方法在三个典型量子多体系统上进行测试，并与传统的变量 Monte Carlo（VMC）和密度矩阵约束 груп（DMRG）方法进行比较。结果显示，对于受挫的Heisenberg $J_1$-$J_2$模型，该方法的结果更好于文献中的复杂值神经网络，表明了 sign structure的优化是困难的。将在未来研究 sign structure的优化。<details>
<summary>Abstract</summary>
Neural-network quantum states (NQSs), variationally optimized by combining traditional methods and deep learning techniques, is a new way to find quantum many-body ground states and gradually becomes a competitor of traditional variational methods. However, there are still some difficulties in the optimization of NQSs, such as local minima, slow convergence, and sign structure optimization. Here, we split a quantum many-body variational wave function into a multiplication of a real-valued amplitude neural network and a sign structure, and focus on the optimization of the amplitude network while keeping the sign structure fixed. The amplitude network is a convolutional neural network (CNN) with residual blocks, namely a ResNet. Our method is tested on three typical quantum many-body systems. The obtained ground state energies are lower than or comparable to those from traditional variational Monte Carlo (VMC) methods and density matrix renormalization group (DMRG). Surprisingly, for the frustrated Heisenberg $J_1$-$J_2$ model, our results are better than those of the complex-valued CNN in the literature, implying that the sign structure of the complex-valued NQS is difficult to be optimized. We will study the optimization of the sign structure of NQSs in the future.
</details>
<details>
<summary>摘要</summary>
(Note: The text has been translated into Simplified Chinese, but the word order and sentence structure may be different from the original text.)
</details></li>
</ul>
<hr>
<h2 id="GiGaMAE-Generalizable-Graph-Masked-Autoencoder-via-Collaborative-Latent-Space-Reconstruction"><a href="#GiGaMAE-Generalizable-Graph-Masked-Autoencoder-via-Collaborative-Latent-Space-Reconstruction" class="headerlink" title="GiGaMAE: Generalizable Graph Masked Autoencoder via Collaborative Latent Space Reconstruction"></a>GiGaMAE: Generalizable Graph Masked Autoencoder via Collaborative Latent Space Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09663">http://arxiv.org/abs/2308.09663</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sycny/gigamae">https://github.com/sycny/gigamae</a></li>
<li>paper_authors: Yucheng Shi, Yushun Dong, Qiaoyu Tan, Jundong Li, Ninghao Liu</li>
<li>for: 这篇论文的目的是提出一个基于自动encoder的自愿式学习框架，以解决现有masked autoencoder模型在graph数据上的普遍化能力不足问题。</li>
<li>methods: 这篇论文提出了一个名为GiGaMAE的新型graph masked autoencoder框架，不同于现有的masked autoencoder模型，这里的模型不是直接从原始graph中重建graph的component（例如特征或边），而是将graph的topology和 attribute信息视为重建目标，以capture更广泛和全面的知识。此外， authors也引入了一个基于mutual information的重建损失函数，这使得模型能够有效地重建多个目标。</li>
<li>results: 在七个标准 benchmark上进行了广泛的实验，结果显示了 GiGaMAE 在三个下游任务上的超越性。 authors hope 这些结果能够照明 foundation models 的设计在graph-structured data上。<details>
<summary>Abstract</summary>
Self-supervised learning with masked autoencoders has recently gained popularity for its ability to produce effective image or textual representations, which can be applied to various downstream tasks without retraining. However, we observe that the current masked autoencoder models lack good generalization ability on graph data. To tackle this issue, we propose a novel graph masked autoencoder framework called GiGaMAE. Different from existing masked autoencoders that learn node presentations by explicitly reconstructing the original graph components (e.g., features or edges), in this paper, we propose to collaboratively reconstruct informative and integrated latent embeddings. By considering embeddings encompassing graph topology and attribute information as reconstruction targets, our model could capture more generalized and comprehensive knowledge. Furthermore, we introduce a mutual information based reconstruction loss that enables the effective reconstruction of multiple targets. This learning objective allows us to differentiate between the exclusive knowledge learned from a single target and common knowledge shared by multiple targets. We evaluate our method on three downstream tasks with seven datasets as benchmarks. Extensive experiments demonstrate the superiority of GiGaMAE against state-of-the-art baselines. We hope our results will shed light on the design of foundation models on graph-structured data. Our code is available at: https://github.com/sycny/GiGaMAE.
</details>
<details>
<summary>摘要</summary>
自我超级学习中的假设掩码自动机（Masked Autoencoder，MAE）在图像或文本表示方面具有出色的表达能力，可以应用于多个下游任务无需重新训练。然而，我们发现当前的假设掩码模型对图数据的泛化能力不足。为解决这个问题，我们提出了一种新的图Masked Autoencoder框架，即GiGaMAE。与现有的假设掩码模型不同，我们在这篇论文中提议通过同时重建图像的整体特征和属性信息来学习图像的表示。这使得我们的模型能够捕捉更加普遍和全面的知识。此外，我们引入了基于缺失信息的重建损失函数，这使得我们的模型能够有效地重建多个目标。我们在三个下游任务上进行了七个数据集的测试，并证明了GiGaMAE在比基eline上表现出色。我们希望我们的结果能够为图数据基础模型的设计提供指导。我们的代码可以在https://github.com/sycny/GiGaMAE中找到。
</details></li>
</ul>
<hr>
<h2 id="Robust-Uncertainty-Quantification-using-Conformalised-Monte-Carlo-Prediction"><a href="#Robust-Uncertainty-Quantification-using-Conformalised-Monte-Carlo-Prediction" class="headerlink" title="Robust Uncertainty Quantification using Conformalised Monte Carlo Prediction"></a>Robust Uncertainty Quantification using Conformalised Monte Carlo Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09647">http://arxiv.org/abs/2308.09647</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/team-daniel/mc-cp">https://github.com/team-daniel/mc-cp</a></li>
<li>paper_authors: Daniel Bethell, Simos Gerasimou, Radu Calinescu</li>
<li>for: 这 paper 是为了提供一种可靠的深度学习模型部署方法，以满足安全关键应用的需求。</li>
<li>methods: 这 paper 使用了一种新的 MC 采样 dropout 方法，以及一种基于 CP 的抗随机变量预测方法。这两种方法在运行时可以相互协作，以提高预测的可靠性和精度。</li>
<li>results: 通过对多种分类和回归 benchmark 进行了广泛的实验，这 paper 显示了 MC-CP 方法在对 uncertainty quantification 方面的显著改进，比如 MC dropout、RAPS 和 CQR 等先进方法。MC-CP 方法可以轻松地与现有模型结合使用，从而使其的部署变得更加简单。<details>
<summary>Abstract</summary>
Deploying deep learning models in safety-critical applications remains a very challenging task, mandating the provision of assurances for the dependable operation of these models. Uncertainty quantification (UQ) methods estimate the model's confidence per prediction, informing decision-making by considering the effect of randomness and model misspecification. Despite the advances of state-of-the-art UQ methods, they are computationally expensive or produce conservative prediction sets/intervals. We introduce MC-CP, a novel hybrid UQ method that combines a new adaptive Monte Carlo (MC) dropout method with conformal prediction (CP). MC-CP adaptively modulates the traditional MC dropout at runtime to save memory and computation resources, enabling predictions to be consumed by CP, yielding robust prediction sets/intervals. Throughout comprehensive experiments, we show that MC-CP delivers significant improvements over advanced UQ methods, like MC dropout, RAPS and CQR, both in classification and regression benchmarks. MC-CP can be easily added to existing models, making its deployment simple.
</details>
<details>
<summary>摘要</summary>
部署深度学习模型在安全关键应用中仍然是一项非常具有挑战性的任务，需要提供对模型可靠性的保证。不确定量评估（UQ）方法估算模型每次预测的可靠程度，以帮助决策，考虑随机性和模型误差的影响。 despite state-of-the-art UQ 方法的进步，它们可能 computationally expensive 或生成保守的预测集/interval。我们介绍 MC-CP，一种新的hybrid UQ 方法，将新的适应MC dropout 方法与 confirmal prediction 结合。 MC-CP 在运行时动态调整传统MC dropout，以避免占用内存和计算资源，使预测可以被CP 处理，生成 robust预测集/interval。经过了广泛的实验，我们表明 MC-CP 在分类和回归 benchmark 中具有显著的改进，比如 MC dropout、RAPS 和 CQR。 MC-CP 可以轻松地添加到现有模型中，使其的部署变得简单。
</details></li>
</ul>
<hr>
<h2 id="biquality-learn-a-Python-library-for-Biquality-Learning"><a href="#biquality-learn-a-Python-library-for-Biquality-Learning" class="headerlink" title="biquality-learn: a Python library for Biquality Learning"></a>biquality-learn: a Python library for Biquality Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09643">http://arxiv.org/abs/2308.09643</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/biquality-learn/biquality-learn">https://github.com/biquality-learn/biquality-learn</a></li>
<li>paper_authors: Pierre Nodet, Vincent Lemaire, Alexis Bondu, Antoine Cornuéjols</li>
<li>For: The paper aims to address the challenges of weak supervision and dataset shifts in machine learning, and proposes a new framework called Biquality Learning.* Methods: The paper proposes a Python library called biquality-learn, which provides a consistent and intuitive API for learning machine learning models from biquality data. The library includes well-proven algorithms and is designed to be accessible and easy to use for everyone.* Results: The paper enables researchers to experiment in a reproducible way on biquality data, and demonstrates the effectiveness of the proposed framework through experiments on several benchmark datasets.<details>
<summary>Abstract</summary>
The democratization of Data Mining has been widely successful thanks in part to powerful and easy-to-use Machine Learning libraries. These libraries have been particularly tailored to tackle Supervised Learning. However, strong supervision signals are scarce in practice, and practitioners must resort to weak supervision. In addition to weaknesses of supervision, dataset shifts are another kind of phenomenon that occurs when deploying machine learning models in the real world. That is why Biquality Learning has been proposed as a machine learning framework to design algorithms capable of handling multiple weaknesses of supervision and dataset shifts without assumptions on their nature and level by relying on the availability of a small trusted dataset composed of cleanly labeled and representative samples. Thus we propose biquality-learn: a Python library for Biquality Learning with an intuitive and consistent API to learn machine learning models from biquality data, with well-proven algorithms, accessible and easy to use for everyone, and enabling researchers to experiment in a reproducible way on biquality data.
</details>
<details>
<summary>摘要</summary>
“数据挖掘的民主化得到了广泛的成功，很大的帮助来自于强大且易用的机器学习库。这些库主要针对超级vised学习。然而，实际中强制督学信号强度很弱，实际operator需要采用弱督学。此外，在机器学习模型实际部署时，数据变化也是一种常见的现象。为此，我们提出了一种机器学习框架---多质量学习（Biquality Learning），旨在设计能够处理多种弱督学和数据变化的算法，不假设它们的性质和水平。我们提出了biquality-learn：一个Python库，用于多质量学习，具有直观和一致的API，可以从多质量数据中学习机器学习模型，具有证明过的算法、易于使用、可重复地进行研究。”
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/19/cs.LG_2023_08_19/" data-id="clogyj8yz00n07cra37xl1dgg" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_19" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/19/eess.IV_2023_08_19/" class="article-date">
  <time datetime="2023-08-19T09:00:00.000Z" itemprop="datePublished">2023-08-19</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/19/eess.IV_2023_08_19/">eess.IV - 2023-08-19</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="CRC-ICM-Colorectal-Cancer-Immune-Cell-Markers-Pattern-Dataset"><a href="#CRC-ICM-Colorectal-Cancer-Immune-Cell-Markers-Pattern-Dataset" class="headerlink" title="CRC-ICM: Colorectal Cancer Immune Cell Markers Pattern Dataset"></a>CRC-ICM: Colorectal Cancer Immune Cell Markers Pattern Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10033">http://arxiv.org/abs/2308.10033</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zahra Mokhtari, Elham Amjadi, Hamidreza Bolhasani, Zahra Faghih, AmirReza Dehghanian, Marzieh Rezaei</li>
<li>for: This paper aims to investigate the differences in immune checkpoint expression between right and left colon cancer, and to identify potential biomarkers for immunotherapy.</li>
<li>methods: The study uses a dataset of 1756 images from 136 patients with colorectal cancer, stained with specific antibodies for CD3, CD8, CD45RO, PD-1, LAG3, and Tim3.</li>
<li>results: The paper finds that there are differences in immune checkpoint expression between right and left colon cancer, and identifies potential biomarkers for immunotherapy.Here is the information in Simplified Chinese text:</li>
<li>for: 这篇论文目的是调查大小colon癌的右和左两侧免疫检查点表达的差异，并找到可能的免疫治疗标记物。</li>
<li>methods: 这篇论文使用136名患有colon癌的患者的1756张图像数据集，用特定抗体染色CD3、CD8、CD45RO、PD-1、LAG3和Tim3等。</li>
<li>results: 论文发现右和左两侧colon癌免疫检查点表达有差异，并确定了可能的免疫治疗标记物。<details>
<summary>Abstract</summary>
Colorectal Cancer (CRC) is the second most common cause of cancer death in the world, ad can be identified by the location of the primary tumor in the large intestine: right and left colon, and rectum. Based on the location, CRC shows differences in chromosomal and molecular characteristics, microbiomes incidence, pathogenesis, and outcome. It has been shown that tumors on left and right sides also have different immune landscape, so the prognosis may be different based on the primary tumor locations. It is widely accepted that immune components of the tumor microenvironment (TME) plays a critical role in tumor development. One of the critical regulatory molecules in the TME is immune checkpoints that as the gatekeepers of immune responses regulate the infiltrated immune cell functions. Inhibitory immune checkpoints such as PD-1, Tim3, and LAG3, as the main mechanism of immune suppression in TME overexpressed and result in further development of the tumor. The images of this dataset have been taken from colon tissues of patients with CRC, stained with specific antibodies for CD3, CD8, CD45RO, PD-1, LAG3 and Tim3. The name of this dataset is CRC-ICM and contains 1756 images related to 136 patients. The initial version of CRC-ICM is published on Elsevier Mendeley dataset portal, and the latest version is accessible via: https://databiox.com
</details>
<details>
<summary>摘要</summary>
抗colon癌（CRC）是全球第二常见的癌症死亡原因，可以根据主 tumor 的位置在大肠中进行分类：右colon、左colon 和肛门。根据位置，CRC 会有不同的染色体和分子特征、微生物发生率、生物学过程和结果。有证据显示左和右方主 tumor 的免疫环境有所不同，因此预后可能因主 tumor 的位置而异。免疫组件在肿瘤微环境（TME）中扮演了重要的角色，并且免疫检查点（IC）是免疫回应的关键调节器。对 TME 中的免疫检查点进行抑制可以导致肿瘤的进一步发展。这些数据库包括1756幅图像，来自于136名患有CRC的病人的大肠标本，已经使用特定抗体进行染色，包括CD3、CD8、CD45RO、PD-1、LAG3 和 Tim3。这个数据库名为 CRC-ICM，可以在 Elsevier Mendeley 数据库 порталу上获取，或者通过以下连结：https://databiox.com。
</details></li>
</ul>
<hr>
<h2 id="Deformable-Detection-Transformer-for-Microbubble-Localization-in-Ultrasound-Localization-Microscopy"><a href="#Deformable-Detection-Transformer-for-Microbubble-Localization-in-Ultrasound-Localization-Microscopy" class="headerlink" title="Deformable-Detection Transformer for Microbubble Localization in Ultrasound Localization Microscopy"></a>Deformable-Detection Transformer for Microbubble Localization in Ultrasound Localization Microscopy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09845">http://arxiv.org/abs/2308.09845</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sepideh K. Gharamaleki, Brandon Helfield, Hassan Rivaz</li>
<li>for: This paper aims to improve the localization of microbubbles (MBs) in ultrasound imaging, which is limited by the half-wavelength resolution of the imaging modality.</li>
<li>methods: The proposed method, DEformable DETR (DE-DETR), uses a multi-scale deformable attention mechanism to distribute attention within a limited budget, improving upon the conventional DETR approach which casts attention upon all grid pixels.</li>
<li>results: The proposed DE-DETR method shows improvement in both precision and recall, as well as the final super-resolution maps, compared to the conventional DETR method, when applied to the task of MB localization in ultrasound imaging.<details>
<summary>Abstract</summary>
To overcome the half a wavelength resolution limitations of ultrasound imaging, microbubbles (MBs) have been utilized widely in the field. Conventional MB localization methods are limited whether by exhaustive parameter tuning or considering a fixed Point Spread Function (PSF) for MBs. This questions their adaptability to different imaging settings or depths. As a result, development of methods that don't rely on manually adjusted parameters is crucial. Previously, we used a transformer-based approach i.e. DEtection TRansformer (DETR) (arXiv:2005.12872v3 and arXiv:2209.11859v1) to address the above mentioned issues. However, DETR suffers from long training times and lower precision for smaller objects. In this paper, we propose the application of DEformable DETR (DE-DETR) ( arXiv:2010.04159) for MB localization to mitigate DETR's above mentioned challenges. As opposed to DETR, where attention is casted upon all grid pixels, DE-DETR utilizes a multi-scale deformable attention to distribute attention within a limited budget. To evaluate the proposed strategy, pre-trained DE-DETR was fine-tuned on a subset of the dataset provided by the IEEE IUS Ultra-SR challenge organizers using transfer learning principles and subsequently we tested the network on the rest of the dataset, excluding the highly correlated frames. The results manifest an improvement both in precision and recall and the final super-resolution maps compared to DETR.
</details>
<details>
<summary>摘要</summary>
为了超越ultrasound imaging中半波长resolution的限制，广泛使用了微气泡（MBs）。传统的MBlocalization方法受限于手动调整的参数或者considering a fixed Point Spread Function（PSF）for MBs。这问题了其适应不同的imaging setting或深度。因此，开发不依赖于手动调整参数的方法是关键。在过去，我们使用了transformer-basedapproach，即DEtection TRansformer（DETR）（arXiv:2005.12872v3和arXiv:2209.11859v1）来解决上述问题。然而，DETR受到训练时间过长和对小对象的精度较低的问题。在这篇论文中，我们提议使用DEformable DETR（DE-DETR）（arXiv:2010.04159）来进行MB localization，以mitigate DETR的上述问题。与DETR不同，DE-DETR使用多尺度可变注意力来分配注意力，而不是对所有的网格像素进行注意力投入。为评估提议的策略，我们先在一个IEEE IUS Ultra-SR challenge提供的数据集上使用了转移学习原理进行先training DE-DETR，然后对剩下的数据集进行测试，排除高相关性的帧。结果显示，与DETR相比，DE-DETR在精度和准确性方面具有显著改进，并且最终的超高分辨率图像也得到了改进。
</details></li>
</ul>
<hr>
<h2 id="Cross-modality-Attention-based-Multimodal-Fusion-for-Non-small-Cell-Lung-Cancer-NSCLC-Patient-Survival-Prediction"><a href="#Cross-modality-Attention-based-Multimodal-Fusion-for-Non-small-Cell-Lung-Cancer-NSCLC-Patient-Survival-Prediction" class="headerlink" title="Cross-modality Attention-based Multimodal Fusion for Non-small Cell Lung Cancer (NSCLC) Patient Survival Prediction"></a>Cross-modality Attention-based Multimodal Fusion for Non-small Cell Lung Cancer (NSCLC) Patient Survival Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09831">http://arxiv.org/abs/2308.09831</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruining Deng, Nazim Shaikh, Gareth Shannon, Yao Nie</li>
<li>for: 预测和诊断结果提供估计，用于评估治疗效果和对患者分组。</li>
<li>methods: 跨Modalities的注意力基本多模态融合策略，通过把不同模态特征融合以提高计算机辅助诊断和预测的性能。</li>
<li>results: 在非小细胞肺癌（NSCLC）患者存活预测 task 中，提出的融合策略比单 modal 学习提高了性能，c-index 从 0.5772 和 0.5885 提高到 0.6587。<details>
<summary>Abstract</summary>
Cancer prognosis and survival outcome predictions are crucial for therapeutic response estimation and for stratifying patients into various treatment groups. Medical domains concerned with cancer prognosis are abundant with multiple modalities, including pathological image data and non-image data such as genomic information. To date, multimodal learning has shown potential to enhance clinical prediction model performance by extracting and aggregating information from different modalities of the same subject. This approach could outperform single modality learning, thus improving computer-aided diagnosis and prognosis in numerous medical applications. In this work, we propose a cross-modality attention-based multimodal fusion pipeline designed to integrate modality-specific knowledge for patient survival prediction in non-small cell lung cancer (NSCLC). Instead of merely concatenating or summing up the features from different modalities, our method gauges the importance of each modality for feature fusion with cross-modality relationship when infusing the multimodal features. Compared with single modality, which achieved c-index of 0.5772 and 0.5885 using solely tissue image data or RNA-seq data, respectively, the proposed fusion approach achieved c-index 0.6587 in our experiment, showcasing the capability of assimilating modality-specific knowledge from varied modalities.
</details>
<details>
<summary>摘要</summary>
cancer 诊断和生存结果预测是致命的，它们对于治疗响应的估计和患者分配到不同的治疗组有重要作用。医疗领域对抗癌症的诊断和预测充满多种多样的数据，包括生物像数据和非生物像数据，如基因信息。到目前为止，多模态学习已经显示出了提高临床预测模型性能的潜力，通过提取和综合不同模态的信息。这种方法可能超越单模态学习，从而改善计算机辅助诊断和预测在各种医疗应用中的性能。在这项工作中，我们提出了一种跨模态注意力基于多模态融合管道，用于整合不同模态知识以提高患者存活预测的准确性。不同于将各模态特征直接拼接或加权平均，我们的方法评估每个模态对于特征融合的重要性，并在融合多模态特征时进行跨模态关系的权重评估。与单模态学习相比，我们的融合方法在实验中达到了c-指数0.6587，这说明了我们能够充分利用不同模态之间的关系，从而提高预测的准确性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/19/eess.IV_2023_08_19/" data-id="clogyj92v013i7cra3xmv6tok" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_18" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/18/cs.SD_2023_08_18/" class="article-date">
  <time datetime="2023-08-18T15:00:00.000Z" itemprop="datePublished">2023-08-18</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/18/cs.SD_2023_08_18/">cs.SD - 2023-08-18</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Compensating-Removed-Frequency-Components-Thwarting-Voice-Spectrum-Reduction-Attacks"><a href="#Compensating-Removed-Frequency-Components-Thwarting-Voice-Spectrum-Reduction-Attacks" class="headerlink" title="Compensating Removed Frequency Components: Thwarting Voice Spectrum Reduction Attacks"></a>Compensating Removed Frequency Components: Thwarting Voice Spectrum Reduction Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09546">http://arxiv.org/abs/2308.09546</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shu Wang, Kun Sun, Qi Li<br>for:This paper aims to address the challenge of detecting harmful content in audio and video available on social media platforms, specifically the vulnerability of automatic speech recognition (ASR) systems to spectrum reduction attacks.methods:The proposed solution is an acoustic compensation system named ACE, which leverages two key observations: frequency component dependencies and perturbation sensitivity. ACE uses a combination of frequency-based compensation and over-the-air perturbations to counter the spectrum reduction attacks and improve the accuracy of ASR systems.results:The experiments show that ACE can effectively reduce up to 87.9% of ASR inference errors caused by spectrum reduction attacks. Additionally, the paper identifies six general types of ASR inference errors and investigates their causes and potential mitigation solutions.<details>
<summary>Abstract</summary>
Automatic speech recognition (ASR) provides diverse audio-to-text services for humans to communicate with machines. However, recent research reveals ASR systems are vulnerable to various malicious audio attacks. In particular, by removing the non-essential frequency components, a new spectrum reduction attack can generate adversarial audios that can be perceived by humans but cannot be correctly interpreted by ASR systems. It raises a new challenge for content moderation solutions to detect harmful content in audio and video available on social media platforms. In this paper, we propose an acoustic compensation system named ACE to counter the spectrum reduction attacks over ASR systems. Our system design is based on two observations, namely, frequency component dependencies and perturbation sensitivity. First, since the Discrete Fourier Transform computation inevitably introduces spectral leakage and aliasing effects to the audio frequency spectrum, the frequency components with similar frequencies will have a high correlation. Thus, considering the intrinsic dependencies between neighboring frequency components, it is possible to recover more of the original audio by compensating for the removed components based on the remaining ones. Second, since the removed components in the spectrum reduction attacks can be regarded as an inverse of adversarial noise, the attack success rate will decrease when the adversarial audio is replayed in an over-the-air scenario. Hence, we can model the acoustic propagation process to add over-the-air perturbations into the attacked audio. We implement a prototype of ACE and the experiments show ACE can effectively reduce up to 87.9% of ASR inference errors caused by spectrum reduction attacks. Also, by analyzing residual errors, we summarize six general types of ASR inference errors and investigate the error causes and potential mitigation solutions.
</details>
<details>
<summary>摘要</summary>
自动语音识别（ASR）系统提供了多种语音到文本服务，帮助人类与机器进行交互。然而，最近的研究发现，ASR系统受到了多种黑客音频攻击。具体来说，通过删除不必要的频率组成部分，可以生成针对ASR系统的恶意音频，这些音频可以被人类听到，但是无法正确地被ASR系统识别。这种攻击提高了社交媒体平台上的内容审核解决方案的挑战。在这篇论文中，我们提出了一种名为ACE的听音补偿系统，以防止频谱减少攻击。我们的系统设计基于两点观察：一是频谱成分之间的相互依赖关系，二是对于攻击音频的扰动敏感性。首先，由于计算Discrete Fourier Transform时必然存在频谱泄漏和射频效应，因此频谱中的相关频率成分会具有高相关性。因此，通过考虑频谱成分之间的内在相互依赖关系，可以通过补偿被删除的频率成分来恢复更多的原始音频。其次，由于攻击音频中删除的频率成分可以看作是对抗噪声的逆，因此在通过空中传播的情况下重新播放攻击音频时，攻击成功率将下降。因此，我们可以模拟听音传播过程，将攻击音频中的频率成分加上了空中传播的扰动。我们实现了ACE的原型，实验结果表明，ACE可以效果地减少ASR推理错误率达87.9%。此外，通过分析剩余错误，我们总结了六种常见的ASR推理错误类型，并分析了错误的原因和可能的修复方案。
</details></li>
</ul>
<hr>
<h2 id="Generative-Machine-Listener"><a href="#Generative-Machine-Listener" class="headerlink" title="Generative Machine Listener"></a>Generative Machine Listener</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09493">http://arxiv.org/abs/2308.09493</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guanxin Jiang, Lars Villemoes, Arijit Biswas</li>
<li>for: 这个论文用于训练神经网络来预测每对参照和编码声音信号的分布。</li>
<li>methods: 这个方法使用个人侵入式听力测试成绩来训练神经网络，我们称之为生成机器听众（GML）。</li>
<li>results: 与基准系统使用平均分数 regression 相比，我们 observe 下降的外围比率（OR），并可以轻松地预测 confidence interval（CI）。 数据增强技术的引入导致 CI 预测准确率和平均分数预测准确率的提高。<details>
<summary>Abstract</summary>
We show how a neural network can be trained on individual intrusive listening test scores to predict a distribution of scores for each pair of reference and coded input stereo or binaural signals. We nickname this method the Generative Machine Listener (GML), as it is capable of generating an arbitrary amount of simulated listening test data. Compared to a baseline system using regression over mean scores, we observe lower outlier ratios (OR) for the mean score predictions, and obtain easy access to the prediction of confidence intervals (CI). The introduction of data augmentation techniques from the image domain results in a significant increase in CI prediction accuracy as well as Pearson and Spearman rank correlation of mean scores.
</details>
<details>
<summary>摘要</summary>
我们展示了一个神经网络可以在个别关注听力测验成绩上训练，以预测每对参考和编码听力信号的分布。我们称这为“生成机器听者”（GML），因为它可以生成无限量的模拟听力测验数据。相比基准系统使用平均值 regression，我们观察到下峰值値（OR）较低，并可以轻松地预测信号interval prediction（CI）。对于数据增强技术的引入，从影像领域的数据增强技术导致了预测CI的准确性和平均分数和Speedman排名相互联系的提高。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Sampling-Techniques-for-Generating-Melodies-with-a-Transformer-Language-Model"><a href="#Exploring-Sampling-Techniques-for-Generating-Melodies-with-a-Transformer-Language-Model" class="headerlink" title="Exploring Sampling Techniques for Generating Melodies with a Transformer Language Model"></a>Exploring Sampling Techniques for Generating Melodies with a Transformer Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09454">http://arxiv.org/abs/2308.09454</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mathias Rose Bjare, Stefan Lattner, Gerhard Widmer</li>
<li>for: 这个研究旨在investigate the impact of different sampling techniques on musical qualities such as diversity and structure in natural language processing.</li>
<li>methods: 作者使用了高容量transformer模型，并使用分布 truncation sampling techniques，包括nucleus sampling、”typical sampling”和conventional ancestral sampling，以评估这些抽样策略对音乐质量的影响。</li>
<li>results: 研究发现，probability truncation techniques可能会限制优 optimal circumstances中的多样性和结构性，但在suboptimal circumstances中可能生成更多的音乐样本。<details>
<summary>Abstract</summary>
Research in natural language processing has demonstrated that the quality of generations from trained autoregressive language models is significantly influenced by the used sampling strategy. In this study, we investigate the impact of different sampling techniques on musical qualities such as diversity and structure. To accomplish this, we train a high-capacity transformer model on a vast collection of highly-structured Irish folk melodies and analyze the musical qualities of the samples generated using distribution truncation sampling techniques. Specifically, we use nucleus sampling, the recently proposed "typical sampling", and conventional ancestral sampling. We evaluate the effect of these sampling strategies in two scenarios: optimal circumstances with a well-calibrated model and suboptimal circumstances where we systematically degrade the model's performance. We assess the generated samples using objective and subjective evaluations. We discover that probability truncation techniques may restrict diversity and structural patterns in optimal circumstances, but may also produce more musical samples in suboptimal circumstances.
</details>
<details>
<summary>摘要</summary>
研究自然语言处理已经证明，训练过程中使用的采样策略会对生成的质量产生重要影响。在这个研究中，我们研究了不同采样技术对音乐质量的影响，特别是多样性和结构。为此，我们训练了一个高容量变换器模型，并使用分布截断采样技术来分析生成的样本。我们使用核心采样、“典型采样”和传统祖先采样三种采样技术，并在优化和不优化情况下进行评估。我们使用对象和主观评估来评估生成的样本质量。我们发现，概率截断技术可能会在优化情况下减少多样性和结构，但在不优化情况下可能会生成更多的音乐样本。
</details></li>
</ul>
<hr>
<h2 id="TrOMR-Transformer-Based-Polyphonic-Optical-Music-Recognition"><a href="#TrOMR-Transformer-Based-Polyphonic-Optical-Music-Recognition" class="headerlink" title="TrOMR:Transformer-Based Polyphonic Optical Music Recognition"></a>TrOMR:Transformer-Based Polyphonic Optical Music Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09370">http://arxiv.org/abs/2308.09370</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/netease/polyphonic-tromr">https://github.com/netease/polyphonic-tromr</a></li>
<li>paper_authors: Yixuan Li, Huaping Liu, Qiang Jin, Miaomiao Cai, Peng Li</li>
<li>for: 这篇论文旨在提出一种基于变换器的全音频乐识别方法（TrOMR），以提高现实世界场景中的识别精度。</li>
<li>methods: 该方法使用变换器来实现全音频乐识别，并引入了一种新的一致损失函数和合理的数据注释方法来提高识别精度。</li>
<li>results: 广泛的实验表明，TrOMR方法在现实世界场景中比现有的OMR方法高效，特别是对于复杂的乐谱。此外， authors还开发了一个 TrOMR 系统和一个实验室场景数据集，以便进行全面的评估和复制。<details>
<summary>Abstract</summary>
Optical Music Recognition (OMR) is an important technology in music and has been researched for a long time. Previous approaches for OMR are usually based on CNN for image understanding and RNN for music symbol classification. In this paper, we propose a transformer-based approach with excellent global perceptual capability for end-to-end polyphonic OMR, called TrOMR. We also introduce a novel consistency loss function and a reasonable approach for data annotation to improve recognition accuracy for complex music scores. Extensive experiments demonstrate that TrOMR outperforms current OMR methods, especially in real-world scenarios. We also develop a TrOMR system and build a camera scene dataset for full-page music scores in real-world. The code and datasets will be made available for reproducibility.
</details>
<details>
<summary>摘要</summary>
依靠视觉技术的音乐识别（OMR）已经是音乐领域的一项重要技术，已经有很长时间的研究。过去的approach通常基于CNN来理解图像和RNN来分类音乐符号。在这篇论文中，我们提出一种基于转换器的方法，具有出色的全球感知能力，用于端到端多重音乐OMR，称为TrOMR。我们还介绍了一种新的一致性损失函数和合理的数据注释方法，以提高复杂音乐分页的识别精度。广泛的实验表明，TrOMR在现实世界中比现有的OMR方法高效，特别是在复杂音乐分页中。我们还开发了TrOMR系统，并建立了真实世界中的摄像头场景数据集，用于全页音乐分页。代码和数据集将被公开，以便重现。
</details></li>
</ul>
<hr>
<h2 id="Lip-Reading-for-Low-resource-Languages-by-Learning-and-Combining-General-Speech-Knowledge-and-Language-specific-Knowledge"><a href="#Lip-Reading-for-Low-resource-Languages-by-Learning-and-Combining-General-Speech-Knowledge-and-Language-specific-Knowledge" class="headerlink" title="Lip Reading for Low-resource Languages by Learning and Combining General Speech Knowledge and Language-specific Knowledge"></a>Lip Reading for Low-resource Languages by Learning and Combining General Speech Knowledge and Language-specific Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09311">http://arxiv.org/abs/2308.09311</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minsu Kim, Jeong Hun Yeo, Jeongsoo Choi, Yong Man Ro</li>
<li>for: 提高低资源语言 lip reading 模型的开发，通过学习通用语言知识和语言特定知识来提高模型的表现。</li>
<li>methods: 使用高资源语言的speech unit prediction来学习通用语言知识，然后使用Language-specific Memory-augmented Decoder (LMDecoder)来学习语言特定知识。</li>
<li>results: 通过对五种语言（英语、西班牙语、法语、意大利语和葡萄牙语）进行了广泛的实验，证明提案的方法可以有效地提高lip reading模型的表现。<details>
<summary>Abstract</summary>
This paper proposes a novel lip reading framework, especially for low-resource languages, which has not been well addressed in the previous literature. Since low-resource languages do not have enough video-text paired data to train the model to have sufficient power to model lip movements and language, it is regarded as challenging to develop lip reading models for low-resource languages. In order to mitigate the challenge, we try to learn general speech knowledge, the ability to model lip movements, from a high-resource language through the prediction of speech units. It is known that different languages partially share common phonemes, thus general speech knowledge learned from one language can be extended to other languages. Then, we try to learn language-specific knowledge, the ability to model language, by proposing Language-specific Memory-augmented Decoder (LMDecoder). LMDecoder saves language-specific audio features into memory banks and can be trained on audio-text paired data which is more easily accessible than video-text paired data. Therefore, with LMDecoder, we can transform the input speech units into language-specific audio features and translate them into texts by utilizing the learned rich language knowledge. Finally, by combining general speech knowledge and language-specific knowledge, we can efficiently develop lip reading models even for low-resource languages. Through extensive experiments using five languages, English, Spanish, French, Italian, and Portuguese, the effectiveness of the proposed method is evaluated.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Robust-Audio-Anti-Spoofing-with-Fusion-Reconstruction-Learning-on-Multi-Order-Spectrograms"><a href="#Robust-Audio-Anti-Spoofing-with-Fusion-Reconstruction-Learning-on-Multi-Order-Spectrograms" class="headerlink" title="Robust Audio Anti-Spoofing with Fusion-Reconstruction Learning on Multi-Order Spectrograms"></a>Robust Audio Anti-Spoofing with Fusion-Reconstruction Learning on Multi-Order Spectrograms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09302">http://arxiv.org/abs/2308.09302</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ph-w2000/s2pecnet">https://github.com/ph-w2000/s2pecnet</a></li>
<li>paper_authors: Penghui Wen, Kun Hu, Wenxi Yue, Sen Zhang, Wanlei Zhou, Zhiyong Wang</li>
<li>for: 防止深度伪装技术所带来的伪声辨识攻击</li>
<li>methods: 使用多项 spectral pattern 融合 deep learning 方法，包括 coarse-to-fine 组合和 fine-level 组合两种分支</li>
<li>results: 在 ASVspoof2019 LA Challenge 上实现了顶尖性能，EER 为 0.77%<details>
<summary>Abstract</summary>
Robust audio anti-spoofing has been increasingly challenging due to the recent advancements on deepfake techniques. While spectrograms have demonstrated their capability for anti-spoofing, complementary information presented in multi-order spectral patterns have not been well explored, which limits their effectiveness for varying spoofing attacks. Therefore, we propose a novel deep learning method with a spectral fusion-reconstruction strategy, namely S2pecNet, to utilise multi-order spectral patterns for robust audio anti-spoofing representations. Specifically, spectral patterns up to second-order are fused in a coarse-to-fine manner and two branches are designed for the fine-level fusion from the spectral and temporal contexts. A reconstruction from the fused representation to the input spectrograms further reduces the potential fused information loss. Our method achieved the state-of-the-art performance with an EER of 0.77% on a widely used dataset: ASVspoof2019 LA Challenge.
</details>
<details>
<summary>摘要</summary>
受深圳技术的提高影响，Robust audio anti-spoofing已经变得越来越困难。虽然spectrograms已经表现出了抗假技术的能力，但多个 spectral pattern的信息还没有得到充分利用，这限制了它们对不同的假攻击的效iveness。因此，我们提出了一种基于深度学习的新方法，即S2pecNet，用于利用多个 spectral pattern来获得robust audio anti-spoofing表示。特别是，至第二顺序的spectral pattern被在粗糙到细节的方式进行融合，并设计了两个支线来从spectral和时间上下文中进行细节级别的融合。再次从融合表示中重建输入spectrograms可以减少潜在的融合信息损失。我们的方法在ASVspoof2019 LA Challenge上 achieved state-of-the-art performance，EER为0.77%。
</details></li>
</ul>
<hr>
<h2 id="V2A-Mapper-A-Lightweight-Solution-for-Vision-to-Audio-Generation-by-Connecting-Foundation-Models"><a href="#V2A-Mapper-A-Lightweight-Solution-for-Vision-to-Audio-Generation-by-Connecting-Foundation-Models" class="headerlink" title="V2A-Mapper: A Lightweight Solution for Vision-to-Audio Generation by Connecting Foundation Models"></a>V2A-Mapper: A Lightweight Solution for Vision-to-Audio Generation by Connecting Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09300">http://arxiv.org/abs/2308.09300</a></li>
<li>repo_url: None</li>
<li>paper_authors: Heng Wang, Jianbo Ma, Santiago Pascual, Richard Cartwright, Weidong Cai</li>
<li>for: 本研究强调使用基础模型（FM）来解决跨模态生成问题，具体来说是将视觉输入转化为听取输出。</li>
<li>methods: 该研究使用CLIP、CLAP和AudioLDM三个基础模型，通过设计一种简单 yet有效的映射机制（V2A-Mapper）来 bridge the domain gap，并使用预训练的听取生成FM AudioLDM生成高质量的听取输出。</li>
<li>results: 对比现有方法，该方法需要较少的训练参数（86%），但能够提高FD和CS两个评价指标的表现，具体来说是提高了53%和19%。<details>
<summary>Abstract</summary>
Building artificial intelligence (AI) systems on top of a set of foundation models (FMs) is becoming a new paradigm in AI research. Their representative and generative abilities learnt from vast amounts of data can be easily adapted and transferred to a wide range of downstream tasks without extra training from scratch. However, leveraging FMs in cross-modal generation remains under-researched when audio modality is involved. On the other hand, automatically generating semantically-relevant sound from visual input is an important problem in cross-modal generation studies. To solve this vision-to-audio (V2A) generation problem, existing methods tend to design and build complex systems from scratch using modestly sized datasets. In this paper, we propose a lightweight solution to this problem by leveraging foundation models, specifically CLIP, CLAP, and AudioLDM. We first investigate the domain gap between the latent space of the visual CLIP and the auditory CLAP models. Then we propose a simple yet effective mapper mechanism (V2A-Mapper) to bridge the domain gap by translating the visual input between CLIP and CLAP spaces. Conditioned on the translated CLAP embedding, pretrained audio generative FM AudioLDM is adopted to produce high-fidelity and visually-aligned sound. Compared to previous approaches, our method only requires a quick training of the V2A-Mapper. We further analyze and conduct extensive experiments on the choice of the V2A-Mapper and show that a generative mapper is better at fidelity and variability (FD) while a regression mapper is slightly better at relevance (CS). Both objective and subjective evaluation on two V2A datasets demonstrate the superiority of our proposed method compared to current state-of-the-art approaches - trained with 86% fewer parameters but achieving 53% and 19% improvement in FD and CS, respectively.
</details>
<details>
<summary>摘要</summary>
Generating semantically-relevant sound from visual input is an important problem in cross-modal generation studies. Existing methods tend to design and build complex systems from scratch using modestly sized datasets. In this paper, we propose a lightweight solution to this problem by leveraging foundation models, specifically CLIP, CLAP, and AudioLDM.We first investigate the domain gap between the latent space of the visual CLIP and the auditory CLAP models. Then, we propose a simple yet effective mapper mechanism (V2A-Mapper) to bridge the domain gap by translating the visual input between CLIP and CLAP spaces. Conditioned on the translated CLAP embedding, pretrained audio generative FM AudioLDM is adopted to produce high-fidelity and visually-aligned sound.Compared to previous approaches, our method only requires a quick training of the V2A-Mapper. We further analyze and conduct extensive experiments on the choice of the V2A-Mapper and show that a generative mapper is better at fidelity and variability (FD) while a regression mapper is slightly better at relevance (CS). Both objective and subjective evaluation on two V2A datasets demonstrate the superiority of our proposed method compared to current state-of-the-art approaches. We trained with 86% fewer parameters but achieved 53% and 19% improvement in FD and CS, respectively.
</details></li>
</ul>
<hr>
<h2 id="Bridging-High-Quality-Audio-and-Video-via-Language-for-Sound-Effects-Retrieval-from-Visual-Queries"><a href="#Bridging-High-Quality-Audio-and-Video-via-Language-for-Sound-Effects-Retrieval-from-Visual-Queries" class="headerlink" title="Bridging High-Quality Audio and Video via Language for Sound Effects Retrieval from Visual Queries"></a>Bridging High-Quality Audio and Video via Language for Sound Effects Retrieval from Visual Queries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09089">http://arxiv.org/abs/2308.09089</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julia Wilkins, Justin Salamon, Magdalena Fuentes, Juan Pablo Bello, Oriol Nieto<br>for: 这个论文主要是用于找到适合的声音效果（SFX）来匹配视频中的时刻，并且可以使用视频帧直接作为查询来找到高质量（HQ）的声音效果。methods: 这篇论文使用了多模态框架，包括利用大型语言模型和基础视觉语言模型来将HQ音频和视频桥接起来，创建高可扩展的自动音频视频数据纪录pipeline。它还使用预训练的音频和视觉编码器来训练一种对比学习基本来进行匹配。results: 论文表明，使用自动数据纪录ipeline和对比学习基本来训练的系统可以对HQ音频进行高效的匹配，并且在使用各种数据集上表现出色。此外，这种系统还可以从清晰到野外数据中进行泛化，并且在用户测试中获得了67%的正确率。<details>
<summary>Abstract</summary>
Finding the right sound effects (SFX) to match moments in a video is a difficult and time-consuming task, and relies heavily on the quality and completeness of text metadata. Retrieving high-quality (HQ) SFX using a video frame directly as the query is an attractive alternative, removing the reliance on text metadata and providing a low barrier to entry for non-experts. Due to the lack of HQ audio-visual training data, previous work on audio-visual retrieval relies on YouTube (in-the-wild) videos of varied quality for training, where the audio is often noisy and the video of amateur quality. As such it is unclear whether these systems would generalize to the task of matching HQ audio to production-quality video. To address this, we propose a multimodal framework for recommending HQ SFX given a video frame by (1) leveraging large language models and foundational vision-language models to bridge HQ audio and video to create audio-visual pairs, resulting in a highly scalable automatic audio-visual data curation pipeline; and (2) using pre-trained audio and visual encoders to train a contrastive learning-based retrieval system. We show that our system, trained using our automatic data curation pipeline, significantly outperforms baselines trained on in-the-wild data on the task of HQ SFX retrieval for video. Furthermore, while the baselines fail to generalize to this task, our system generalizes well from clean to in-the-wild data, outperforming the baselines on a dataset of YouTube videos despite only being trained on the HQ audio-visual pairs. A user study confirms that people prefer SFX retrieved by our system over the baseline 67% of the time both for HQ and in-the-wild data. Finally, we present ablations to determine the impact of model and data pipeline design choices on downstream retrieval performance. Please visit our project website to listen to and view our SFX retrieval results.
</details>
<details>
<summary>摘要</summary>
找到合适的声效（SFX）以匹配影像中的时刻是一个困难和耗时的任务，它高度依赖文本 metadata 的质量和完整性。使用影像帧直接作为查询，抽取高品质（HQ）声效是一个吸引人的选择，它可以解除文本 metadata 的依赖，并提供低门槛的入门点 для非专家。由于缺乏 HQ 音频视觉训练数据，过去的音频视觉检索工作都是使用 YouTube 上的各种质量的影片进行训练，其中的音频 oft 是噪音的，影像则是业余质量。这使得这些系统是否能够应用到高品质音频与生产质量影像的匹配问题仍然存在一定的uncertainty。为了解决这个问题，我们提出了一个多Modal 框架，可以根据影像帧提供高品质声效。我们的方法包括：1. 利用大型语言模型和基础的视觉语言模型，将高品质音频和影像 Bridge 到创建音频视觉对，实现了高度排擦的自动音频视觉数据填充管道。2. 使用预训的音频和视觉嵌入器，使用对照式学习 retrained 一个检索系统。我们的系统，使用我们的自动数据填充管道进行训练，与基准相比，显著超过了对 YouTube 上的各种质量影片进行训练的基准。此外，我们的系统具有很好的泛化能力，可以从清洁到实际上的数据进行检索，并且在 YouTube 上的影片上进行检索时，表现更好 than 基准。在一次用户研究中，人们对我们的系统进行检索的时候，偏好我们的系统67%。最后，我们进行了一些范例的ablation，以决定模型和数据管道设计的影响。您可以前往我们的项目网站，聆听和查看我们的 SFX 检索结果。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/18/cs.SD_2023_08_18/" data-id="clogyj90e00tn7cra50u6eqvr" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_18" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/18/cs.CV_2023_08_18/" class="article-date">
  <time datetime="2023-08-18T13:00:00.000Z" itemprop="datePublished">2023-08-18</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/18/cs.CV_2023_08_18/">cs.CV - 2023-08-18</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Revisiting-Skin-Tone-Fairness-in-Dermatological-Lesion-Classification"><a href="#Revisiting-Skin-Tone-Fairness-in-Dermatological-Lesion-Classification" class="headerlink" title="Revisiting Skin Tone Fairness in Dermatological Lesion Classification"></a>Revisiting Skin Tone Fairness in Dermatological Lesion Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09640">http://arxiv.org/abs/2308.09640</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tkalbl/revisitingskintonefairness">https://github.com/tkalbl/revisitingskintonefairness</a></li>
<li>paper_authors: Thorsten Kalb, Kaisar Kushibar, Celia Cintas, Karim Lekadir, Oliver Diaz, Richard Osuala</li>
<li>for: 评估皮肤疾病分类算法的公平性，因为皮肤疾病的表现可能因皮肤色调而异常。</li>
<li>methods: 使用Individual Typology Angle（ITA）来估计皮肤色调，并对皮肤疾病分类算法进行公平性分析。</li>
<li>results: 对ISIC18 dataset进行了四种ITA-based皮肤色调分类方法的比较，发现这些方法之间存在很大的不一致，表明ITA-based皮肤色调估计方法存在风险。此外，研究发现ISIC18 dataset的不具有多样性，限制了其作为公平性分析的测试平台。<details>
<summary>Abstract</summary>
Addressing fairness in lesion classification from dermatological images is crucial due to variations in how skin diseases manifest across skin tones. However, the absence of skin tone labels in public datasets hinders building a fair classifier. To date, such skin tone labels have been estimated prior to fairness analysis in independent studies using the Individual Typology Angle (ITA). Briefly, ITA calculates an angle based on pixels extracted from skin images taking into account the lightness and yellow-blue tints. These angles are then categorised into skin tones that are subsequently used to analyse fairness in skin cancer classification. In this work, we review and compare four ITA-based approaches of skin tone classification on the ISIC18 dataset, a common benchmark for assessing skin cancer classification fairness in the literature. Our analyses reveal a high disagreement among previously published studies demonstrating the risks of ITA-based skin tone estimation methods. Moreover, we investigate the causes of such large discrepancy among these approaches and find that the lack of diversity in the ISIC18 dataset limits its use as a testbed for fairness analysis. Finally, we recommend further research on robust ITA estimation and diverse dataset acquisition with skin tone annotation to facilitate conclusive fairness assessments of artificial intelligence tools in dermatology. Our code is available at https://github.com/tkalbl/RevisitingSkinToneFairness.
</details>
<details>
<summary>摘要</summary>
（注意：以下是简化中文翻译，不是正式文件翻译） Addressing fairness in lesion classification from dermatological images is crucial due to variations in how skin diseases manifest across different skin tones. However, the lack of skin tone labels in public datasets hinders the creation of a fair classifier. To date, such skin tone labels have been estimated before fairness analysis in independent studies using the Individual Typology Angle (ITA). Briefly, ITA calculates an angle based on pixels extracted from skin images, taking into account the lightness and yellow-blue tints. These angles are then categorized into skin tones that are subsequently used to analyze fairness in skin cancer classification. In this work, we review and compare four ITA-based approaches of skin tone classification on the ISIC18 dataset, a common benchmark for assessing skin cancer classification fairness in the literature. Our analyses reveal a high disagreement among previously published studies, demonstrating the risks of ITA-based skin tone estimation methods. Moreover, we investigate the causes of such large discrepancy among these approaches and find that the lack of diversity in the ISIC18 dataset limits its use as a testbed for fairness analysis. Finally, we recommend further research on robust ITA estimation and diverse dataset acquisition with skin tone annotation to facilitate conclusive fairness assessments of artificial intelligence tools in dermatology. Our code is available at https://github.com/tkalbl/RevisitingSkinToneFairness.
</details></li>
</ul>
<hr>
<h2 id="GeoDTR-Toward-generic-cross-view-geolocalization-via-geometric-disentanglement"><a href="#GeoDTR-Toward-generic-cross-view-geolocalization-via-geometric-disentanglement" class="headerlink" title="GeoDTR+: Toward generic cross-view geolocalization via geometric disentanglement"></a>GeoDTR+: Toward generic cross-view geolocalization via geometric disentanglement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09624">http://arxiv.org/abs/2308.09624</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaohan Zhang, Xingyu Li, Waqas Sultani, Chen Chen, Safwan Wshah</li>
<li>for: 这个论文目的是提出一个具有更好的地理构造抽取和对比硬件组合的地图地标准化方法，以提高地图地标的精度和稳定性。</li>
<li>methods: 这个方法使用了一个增强的地理构造抽取模组（GLE），以及一个对比硬件组合（CHSG）来增强模型的训练。</li>
<li>results: 实验结果显示，这个方法在跨区评估中取得了最新的州际顶峰表现 ($16.44%$, $22.71%$, and $17.02%$ 不包括极点转换)，并且保持了与现有最新顶峰相同的同区表现。<details>
<summary>Abstract</summary>
Cross-View Geo-Localization (CVGL) estimates the location of a ground image by matching it to a geo-tagged aerial image in a database. Recent works achieve outstanding progress on CVGL benchmarks. However, existing methods still suffer from poor performance in cross-area evaluation, in which the training and testing data are captured from completely distinct areas. We attribute this deficiency to the lack of ability to extract the geometric layout of visual features and models' overfitting to low-level details. Our preliminary work introduced a Geometric Layout Extractor (GLE) to capture the geometric layout from input features. However, the previous GLE does not fully exploit information in the input feature. In this work, we propose GeoDTR+ with an enhanced GLE module that better models the correlations among visual features. To fully explore the LS techniques from our preliminary work, we further propose Contrastive Hard Samples Generation (CHSG) to facilitate model training. Extensive experiments show that GeoDTR+ achieves state-of-the-art (SOTA) results in cross-area evaluation on CVUSA, CVACT, and VIGOR by a large margin ($16.44\%$, $22.71\%$, and $17.02\%$ without polar transformation) while keeping the same-area performance comparable to existing SOTA. Moreover, we provide detailed analyses of GeoDTR+.
</details>
<details>
<summary>摘要</summary>
cross-view geo-localization (CVGL) 算法估算图像的位置，通过与数据库中geo-标记的空中图像进行匹配。现有研究取得了CVGL标准吗的出色表现。然而，现有方法仍然在跨区评估中表现不佳，其中训练和测试数据来自完全不同的区域。我们认为这是因为无法提取视觉特征的几何布局，以及模型过拟合低级细节。我们的前期工作中引入了几何布局提取器（GLE），但前一版GLE未能充分利用输入特征中的信息。在这项工作中，我们提出了GeoDTR+，它包括改进的GLE模块，可以更好地模型视觉特征之间的相关性。此外，我们还提出了对LS技术的进一步发展，即对比难样本生成（CHSG），以促进模型训练。我们的实验表明，GeoDTR+在跨区评估中达到了CVUSA、CVACT和VIGOR等标准吗的最佳结果（无极化转换），同时保持与同区表现相似的水平。此外，我们还提供了GeoDTR+的详细分析。
</details></li>
</ul>
<hr>
<h2 id="Is-context-all-you-need-Scaling-Neural-Sign-Language-Translation-to-Large-Domains-of-Discourse"><a href="#Is-context-all-you-need-Scaling-Neural-Sign-Language-Translation-to-Large-Domains-of-Discourse" class="headerlink" title="Is context all you need? Scaling Neural Sign Language Translation to Large Domains of Discourse"></a>Is context all you need? Scaling Neural Sign Language Translation to Large Domains of Discourse</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09622">http://arxiv.org/abs/2308.09622</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ozge Mercanoglu Sincan, Necati Cihan Camgoz, Richard Bowden</li>
<li>For: The paper aims to improve the accuracy of sign language translation (SLT) by incorporating contextual information into the translation process.* Methods: The proposed method uses a multi-modal transformer architecture that combines low-level video features, recognized sign glosses, and contextual information from previous sign sequences to generate spoken language translations.* Results: The proposed approach significantly improves SLT performance compared to baseline methods, with nearly double the BLEU-4 scores. The results are evaluated on two datasets: BOBSL and SRF.<details>
<summary>Abstract</summary>
Sign Language Translation (SLT) is a challenging task that aims to generate spoken language sentences from sign language videos, both of which have different grammar and word/gloss order. From a Neural Machine Translation (NMT) perspective, the straightforward way of training translation models is to use sign language phrase-spoken language sentence pairs. However, human interpreters heavily rely on the context to understand the conveyed information, especially for sign language interpretation, where the vocabulary size may be significantly smaller than their spoken language equivalent.   Taking direct inspiration from how humans translate, we propose a novel multi-modal transformer architecture that tackles the translation task in a context-aware manner, as a human would. We use the context from previous sequences and confident predictions to disambiguate weaker visual cues. To achieve this we use complementary transformer encoders, namely: (1) A Video Encoder, that captures the low-level video features at the frame-level, (2) A Spotting Encoder, that models the recognized sign glosses in the video, and (3) A Context Encoder, which captures the context of the preceding sign sequences. We combine the information coming from these encoders in a final transformer decoder to generate spoken language translations.   We evaluate our approach on the recently published large-scale BOBSL dataset, which contains ~1.2M sequences, and on the SRF dataset, which was part of the WMT-SLT 2022 challenge. We report significant improvements on state-of-the-art translation performance using contextual information, nearly doubling the reported BLEU-4 scores of baseline approaches.
</details>
<details>
<summary>摘要</summary>
签语翻译（SLT）是一项复杂的任务，旨在从手语视频中生成口语句子，两者都有不同的语法和单词顺序。从神经机器翻译（NMT）的角度来看，直接使用手语短语-口语句子对的训练翻译模型是最直接的方法。然而，人类 intérpretes 具有很强的上下文理解能力，特别是 для手语 interpretations，其词汇量可能比其口语对应的更小。  基于人类翻译的直观思路，我们提出了一种新的多模态 transformer 架构，用于在上下文意识下进行翻译任务。我们使用上下文来解决视觉较弱的征略，并且使用 complementary transformer encoders，即：(1) 视频编码器， capture 视频中帧级的低级特征; (2) 识别编码器， model 视频中识别的手语词汇; (3) 上下文编码器， capture 前一个手语序列的上下文。我们将这些编码器的信息在最终的 transformer decoder 中结合，以生成口语翻译。  我们在最近发布的 BOBSL 数据集上进行了评估，该数据集包含约 1.2M 个序列，以及 SRF 数据集，该数据集在 WMT-SLT 2022 挑战中出现。我们发现，使用上下文信息可以大幅提高翻译性能，相比基eline方法的 BLEU-4 分数增长约 20%。
</details></li>
</ul>
<hr>
<h2 id="LaRS-A-Diverse-Panoptic-Maritime-Obstacle-Detection-Dataset-and-Benchmark"><a href="#LaRS-A-Diverse-Panoptic-Maritime-Obstacle-Detection-Dataset-and-Benchmark" class="headerlink" title="LaRS: A Diverse Panoptic Maritime Obstacle Detection Dataset and Benchmark"></a>LaRS: A Diverse Panoptic Maritime Obstacle Detection Dataset and Benchmark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09618">http://arxiv.org/abs/2308.09618</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lojze Žust, Janez Perš, Matej Kristan</li>
<li>for: 本研究目的是提供一个多样化的海上障碍物检测数据集，以便进一步推动海上障碍物检测领域的进步。</li>
<li>methods: 本研究使用了一个新的海上�anoptic障碍物检测benchmark，名为LaRS，该benchmark包含了湖泊、河流和海洋等多个环境下的场景。</li>
<li>results: 本研究通过对27种semantic和panoptic segmentation方法的评估，发现了一些性能杂化和未来研究方向。同时，本研究还提供了一个在线评估服务器，以便对海上障碍物检测方法进行对比和评估。<details>
<summary>Abstract</summary>
The progress in maritime obstacle detection is hindered by the lack of a diverse dataset that adequately captures the complexity of general maritime environments. We present the first maritime panoptic obstacle detection benchmark LaRS, featuring scenes from Lakes, Rivers and Seas. Our major contribution is the new dataset, which boasts the largest diversity in recording locations, scene types, obstacle classes, and acquisition conditions among the related datasets. LaRS is composed of over 4000 per-pixel labeled key frames with nine preceding frames to allow utilization of the temporal texture, amounting to over 40k frames. Each key frame is annotated with 8 thing, 3 stuff classes and 19 global scene attributes. We report the results of 27 semantic and panoptic segmentation methods, along with several performance insights and future research directions. To enable objective evaluation, we have implemented an online evaluation server. The LaRS dataset, evaluation toolkit and benchmark are publicly available at: https://lojzezust.github.io/lars-dataset
</details>
<details>
<summary>摘要</summary>
“水域障碍物探测的进步受到水域环境的多样性不足所阻碍。我们提出了首个水域综合障碍物探测比赛LaRS，包括湖泊、河流和海洋的场景。我们的主要贡献是新的数据集，其中包括不同的录制地点、场景类型、障碍物类型和采样条件，与相关的数据集相比，展现了最大的多样性。LaRS包含了4000帧每帧标注的关键帧，共有9个前置帧，以利用时间Texture，总共有40k帧。每个关键帧都被标注为8个物类、3个物品类和19个全局场景特征。我们报告了27种semantic和综合障碍物分类方法的结果，以及一些性能检验和未来研究方向。为了实现公正评估，我们在线上进行了评估服务器。LaRS数据集、评估工具箱和比赛是公开 disponibile的：https://lojzezust.github.io/lars-dataset”
</details></li>
</ul>
<hr>
<h2 id="Far3D-Expanding-the-Horizon-for-Surround-view-3D-Object-Detection"><a href="#Far3D-Expanding-the-Horizon-for-Surround-view-3D-Object-Detection" class="headerlink" title="Far3D: Expanding the Horizon for Surround-view 3D Object Detection"></a>Far3D: Expanding the Horizon for Surround-view 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09616">http://arxiv.org/abs/2308.09616</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaohui Jiang, Shuailin Li, Yingfei Liu, Shihao Wang, Fan Jia, Tiancai Wang, Lijin Han, Xiangyu Zhang</li>
<li>for: 本研究旨在提高3D对象检测范围，特别是长范围检测，以便减少成本和提高效率。</li>
<li>methods: 本研究提出了一种新的稀疏查询基于框架，称为Far3D。该框架利用高质量2D对象假设生成3D适应查询，并引入了视角意识汇集模块，以兼顾不同视野和比例的特征捕捉。此外，该研究还提出了范围调整的3D推净方法，以解决查询错误的协传和长范围任务中的稳定问题。</li>
<li>results: 该研究在Argoverse 2数据集上达到了最佳性能水平，覆盖150米的广泛范围，超过了一些LiDAR基于的方法。此外，Far3D还在nuScenes数据集上表现出了superior的性能。代码即将公布。<details>
<summary>Abstract</summary>
Recently 3D object detection from surround-view images has made notable advancements with its low deployment cost. However, most works have primarily focused on close perception range while leaving long-range detection less explored. Expanding existing methods directly to cover long distances poses challenges such as heavy computation costs and unstable convergence. To address these limitations, this paper proposes a novel sparse query-based framework, dubbed Far3D. By utilizing high-quality 2D object priors, we generate 3D adaptive queries that complement the 3D global queries. To efficiently capture discriminative features across different views and scales for long-range objects, we introduce a perspective-aware aggregation module. Additionally, we propose a range-modulated 3D denoising approach to address query error propagation and mitigate convergence issues in long-range tasks. Significantly, Far3D demonstrates SoTA performance on the challenging Argoverse 2 dataset, covering a wide range of 150 meters, surpassing several LiDAR-based approaches. Meanwhile, Far3D exhibits superior performance compared to previous methods on the nuScenes dataset. The code will be available soon.
</details>
<details>
<summary>摘要</summary>
近些时候，从卫星视图图像中的3D物体检测已经做出了明显的进步，主要是因为其低于部署成本。然而，大多数工作都主要集中在近距离检测上，而长距离检测则尚未得到足够的探索。扩展现有方法直接覆盖长距离范围 poses 计算成本过高和稳定性不稳定。为了解决这些限制，这篇论文提出了一种新的稀疏查询基本框架，名为 Far3D。通过利用高质量的2D物体假设，我们生成了3D适应查询，这些查询与3D全球查询衔接。为了有效地捕捉不同视图和缩放下的特征，我们提出了一种视角意识汇集模块。此外，我们提出了范围调整的3D排除方法，以解决查询错误的传递问题和长距离任务中的稳定性问题。特别是，Far3D在Argoverse 2数据集上达到了SOA性能，覆盖150米的各种距离，超过了一些激光雷达基于的方法。同时，Far3D在nuScenes数据集上表现出色，比前一些方法更高。代码即将发布。
</details></li>
</ul>
<hr>
<h2 id="Language-guided-Human-Motion-Synthesis-with-Atomic-Actions"><a href="#Language-guided-Human-Motion-Synthesis-with-Atomic-Actions" class="headerlink" title="Language-guided Human Motion Synthesis with Atomic Actions"></a>Language-guided Human Motion Synthesis with Atomic Actions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09611">http://arxiv.org/abs/2308.09611</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yhzhai/atom">https://github.com/yhzhai/atom</a></li>
<li>paper_authors: Yuanhao Zhai, Mingzhen Huang, Tianyu Luan, Lu Dong, Ifeoma Nwogu, Siwei Lyu, David Doermann, Junsong Yuan</li>
<li>for: 文章主要目的是提出一种语言引导人体运动合成技术，以解决人体行为的自然复杂性和多样性导致的合成问题。</li>
<li>methods: 该方法基于分解人体动作为原子动作的思想，并采用了一种课程学习策略来学习原子动作的组合。在学习过程中，文章首先将复杂的人体动作分解为一组原子动作，然后使用这些学习到的原子动作来组合新的动作，从而提高了对新动作的适应性。此外，文章还引入了一种课程学习训练策略，通过逐渐增加的面积矩阵来促进原子动作的组合。</li>
<li>results: 文章通过了广泛的实验，包括文本引导人体运动和动作引导人体运动任务，证明了ATOM模型的效果。具体来说，ATOM模型能够生成符合人体动作规律的文本引导人体运动序列，并且能够更好地适应新的动作。<details>
<summary>Abstract</summary>
Language-guided human motion synthesis has been a challenging task due to the inherent complexity and diversity of human behaviors. Previous methods face limitations in generalization to novel actions, often resulting in unrealistic or incoherent motion sequences. In this paper, we propose ATOM (ATomic mOtion Modeling) to mitigate this problem, by decomposing actions into atomic actions, and employing a curriculum learning strategy to learn atomic action composition. First, we disentangle complex human motions into a set of atomic actions during learning, and then assemble novel actions using the learned atomic actions, which offers better adaptability to new actions. Moreover, we introduce a curriculum learning training strategy that leverages masked motion modeling with a gradual increase in the mask ratio, and thus facilitates atomic action assembly. This approach mitigates the overfitting problem commonly encountered in previous methods while enforcing the model to learn better motion representations. We demonstrate the effectiveness of ATOM through extensive experiments, including text-to-motion and action-to-motion synthesis tasks. We further illustrate its superiority in synthesizing plausible and coherent text-guided human motion sequences.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate "ATOM (ATomic mOtion Modeling) to mitigate this problem, by decomposing actions into atomic actions, and employing a curriculum learning strategy to learn atomic action composition." into Simplified Chinese</SYS>>Here's the translation:使用ATOM（原子动作模型）来解决这个问题，将动作 decomposes into atomic actions，并使用学习 atomic action 的CURRICULUM learning策略来学习atomic action的组合。Here's the breakdown of the translation:* 使用ATOM (使用ATOM)： Uses ATOM.* 解决这个问题 (解决这个问题)： Solves this problem.* decomposes into atomic actions (decomposes into atomic actions)： Decomposes into atomic actions.* 并使用学习 (并使用学习)： And uses learning.* atomic action composition (原子动作的组合)： Atomic action composition.I hope this helps! Let me know if you have any other questions.
</details></li>
</ul>
<hr>
<h2 id="On-the-Effectiveness-of-LayerNorm-Tuning-for-Continual-Learning-in-Vision-Transformers"><a href="#On-the-Effectiveness-of-LayerNorm-Tuning-for-Continual-Learning-in-Vision-Transformers" class="headerlink" title="On the Effectiveness of LayerNorm Tuning for Continual Learning in Vision Transformers"></a>On the Effectiveness of LayerNorm Tuning for Continual Learning in Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09610">http://arxiv.org/abs/2308.09610</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tdemin16/continual-layernorm-tuning">https://github.com/tdemin16/continual-layernorm-tuning</a></li>
<li>paper_authors: Thomas De Min, Massimiliano Mancini, Karteek Alahari, Xavier Alameda-Pineda, Elisa Ricci</li>
<li>for: 降低折冲学习方法中的计算成本，以维持竞争力性的表现。</li>
<li>methods: 将注重层 normalization 为每个持续学习任务，并在推断时根据任务特定的键和预训模型的输出选择参数。</li>
<li>results: 在 ImageNet-R 和 CIFAR-100 上实验显示，我们的方法可以与 {状态域} 的表现相互匹配，而且计算成本较低。<details>
<summary>Abstract</summary>
State-of-the-art rehearsal-free continual learning methods exploit the peculiarities of Vision Transformers to learn task-specific prompts, drastically reducing catastrophic forgetting. However, there is a tradeoff between the number of learned parameters and the performance, making such models computationally expensive. In this work, we aim to reduce this cost while maintaining competitive performance. We achieve this by revisiting and extending a simple transfer learning idea: learning task-specific normalization layers. Specifically, we tune the scale and bias parameters of LayerNorm for each continual learning task, selecting them at inference time based on the similarity between task-specific keys and the output of the pre-trained model. To make the classifier robust to incorrect selection of parameters during inference, we introduce a two-stage training procedure, where we first optimize the task-specific parameters and then train the classifier with the same selection procedure of the inference time. Experiments on ImageNet-R and CIFAR-100 show that our method achieves results that are either superior or on par with {the state of the art} while being computationally cheaper.
</details>
<details>
<summary>摘要</summary>
现代无重复练习 continual learning 方法利用视Transformers的特点学习任务特定提示，以减少忘记性。然而，有参数数量和性能之间的交易，使得这些模型变得 computationally 昂贵。在这个工作中，我们希望减少这个成本，保持竞争力。我们实现这一点通过重新访问和扩展一种简单的转移学习想法：学习任务特定 normalization layers。特别是，我们在每个 continual learning 任务中调整层 normalization 的缩放和偏移参数，在推理时根据任务特定的键和预训练模型输出来选择。为了让分类器在推理过程中正确选择参数，我们引入了一个两阶段训练过程，在第一阶段优化任务特定参数，然后在第二阶段使用同样的选择过程来训练分类器。实验表明，我们的方法在 ImageNet-R 和 CIFAR-100 上 achieves Results that are either superior or on par with {the state of the art} while being computationally cheaper。
</details></li>
</ul>
<hr>
<h2 id="Language-Guided-Diffusion-Model-for-Visual-Grounding"><a href="#Language-Guided-Diffusion-Model-for-Visual-Grounding" class="headerlink" title="Language-Guided Diffusion Model for Visual Grounding"></a>Language-Guided Diffusion Model for Visual Grounding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09599">http://arxiv.org/abs/2308.09599</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sijia Chen, Baochun Li</li>
<li>for:  solves the problem of visual grounding, a cross-modal alignment task, in a generative way.</li>
<li>methods:  uses a language-guided diffusion framework called LG-DVG, which trains the model to progressively reason queried object boxes by denoising a set of noisy boxes with the language guide.</li>
<li>results:  achieves superior performance on five widely used datasets, validating the effectiveness of the proposed framework.<details>
<summary>Abstract</summary>
Visual grounding (VG) tasks involve explicit cross-modal alignment, as semantically corresponding image regions are to be located for the language phrases provided. Existing approaches complete such visual-text reasoning in a single-step manner. Their performance causes high demands on large-scale anchors and over-designed multi-modal fusion modules based on human priors, leading to complicated frameworks that may be difficult to train and overfit to specific scenarios. Even worse, such once-for-all reasoning mechanisms are incapable of refining boxes continuously to enhance query-region matching. In contrast, in this paper, we formulate an iterative reasoning process by denoising diffusion modeling. Specifically, we propose a language-guided diffusion framework for visual grounding, LG-DVG, which trains the model to progressively reason queried object boxes by denoising a set of noisy boxes with the language guide. To achieve this, LG-DVG gradually perturbs query-aligned ground truth boxes to noisy ones and reverses this process step by step, conditional on query semantics. Extensive experiments for our proposed framework on five widely used datasets validate the superior performance of solving visual grounding, a cross-modal alignment task, in a generative way. The source codes are available at \url{https://github.com/iQua/vgbase/tree/DiffusionVG}.
</details>
<details>
<summary>摘要</summary>
Visual grounding（视觉附加）任务需要显式跨模态对齐，即要在图像区域和语言短语之间进行Semantic对应。现有的方法通过单步visual-text reasoning来完成这些任务，其性能需要大量的 anchor和复杂的多模态融合模块，导致复杂的框架难以训练和过拟合特定场景。worse,这些once-for-all reasoning mechanisms是无法不断调整查询区域匹配的。相反，在这篇论文中，我们提出了一种迭代的理解过程，即通过降噪模型来进行语义导向的Diffusion VG框架，具体来说是语言指导降噪框架（LG-DVG）。它通过逐步降噪查询对应的真实框， conditional on查询语义来训练模型。我们在五个广泛使用的dataset上进行了extensive experiments，并证明了我们提出的框架在解决视觉附加任务的cross-modal对齐任务中的超越性。代码可以在 \url{https://github.com/iQua/vgbase/tree/DiffusionVG} 上获取。
</details></li>
</ul>
<hr>
<h2 id="Investigation-of-Architectures-and-Receptive-Fields-for-Appearance-based-Gaze-Estimation"><a href="#Investigation-of-Architectures-and-Receptive-Fields-for-Appearance-based-Gaze-Estimation" class="headerlink" title="Investigation of Architectures and Receptive Fields for Appearance-based Gaze Estimation"></a>Investigation of Architectures and Receptive Fields for Appearance-based Gaze Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09593">http://arxiv.org/abs/2308.09593</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yunhanwang1105/GazeTech">https://github.com/yunhanwang1105/GazeTech</a></li>
<li>paper_authors: Yunhan Wang, Xiangwei Shi, Shalini De Mello, Hyung Jin Chang, Xucong Zhang</li>
<li>for: 这篇论文探讨了深度学习技术在过去十年的快速发展，以及这些技术在人工智能和计算机视觉领域的应用。</li>
<li>methods: 这篇论文提出了多种不同的机制，包括软运算、硬运算、两眼不对称、特征分离、旋转一致和对称学习。大多数方法将单一脸部或多个区域作为输入，但这篇论文强调了基本架构的探讨。</li>
<li>results: 这篇论文发现，对 ResNet 架构进行一些简单的参数调整可以超过大多数现有的州OF-the-art方法在三个popular dataset上的关照眼动测量性能。经过广泛的实验，我们发现了适当的步长数、输入图像分辨率和多区域架构对关照眼动测量性能的影响，并且这些影响随着输入脸部图像质量而改变。我们在三个dataset上取得了顶尖性能，分别为ETH-XGaze 3.64、MPIIFaceGaze 4.50和Gaze360度关照眼动测量错误9.13。<details>
<summary>Abstract</summary>
With the rapid development of deep learning technology in the past decade, appearance-based gaze estimation has attracted great attention from both computer vision and human-computer interaction research communities. Fascinating methods were proposed with variant mechanisms including soft attention, hard attention, two-eye asymmetry, feature disentanglement, rotation consistency, and contrastive learning. Most of these methods take the single-face or multi-region as input, yet the basic architecture of gaze estimation has not been fully explored. In this paper, we reveal the fact that tuning a few simple parameters of a ResNet architecture can outperform most of the existing state-of-the-art methods for the gaze estimation task on three popular datasets. With our extensive experiments, we conclude that the stride number, input image resolution, and multi-region architecture are critical for the gaze estimation performance while their effectiveness dependent on the quality of the input face image. We obtain the state-of-the-art performances on three datasets with 3.64 on ETH-XGaze, 4.50 on MPIIFaceGaze, and 9.13 on Gaze360 degrees gaze estimation error by taking ResNet-50 as the backbone.
</details>
<details>
<summary>摘要</summary>
随着深度学习技术在过去十年的快速发展，面部基于的视线估计吸引了计算机视觉和人机交互研究领域的广泛关注。吸引人的方法被提出，包括软注意力、硬注意力、两个眼睛差异、特征分离、旋转一致性和对比学习。大多数方法以单个脸或多个区域作为输入，然而基本的视线估计建 architecture尚未得到全面探讨。在这篇论文中，我们发现了一个关键的事实：调整一些简单的ResNet架构参数可以超越大多数现有的状态对 gaze estimation 任务的表现。通过我们的广泛的实验，我们结论了 that the stride number, input image resolution, and multi-region architecture are critical for the gaze estimation performance, and their effectiveness depends on the quality of the input face image。我们在三个 dataset 上 obtain 了最佳性能，具体来说是ETH-XGaze的3.64、MPIIFaceGaze的4.50和Gaze360度的9.13度视线估计误差。
</details></li>
</ul>
<hr>
<h2 id="StableVideo-Text-driven-Consistency-aware-Diffusion-Video-Editing"><a href="#StableVideo-Text-driven-Consistency-aware-Diffusion-Video-Editing" class="headerlink" title="StableVideo: Text-driven Consistency-aware Diffusion Video Editing"></a>StableVideo: Text-driven Consistency-aware Diffusion Video Editing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09592">http://arxiv.org/abs/2308.09592</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rese1f/stablevideo">https://github.com/rese1f/stablevideo</a></li>
<li>paper_authors: Wenhao Chai, Xun Guo, Gaoang Wang, Yan Lu</li>
<li>for: 这篇论文是为了解决Diffusion-based方法在视频编辑中的问题，即如何在保持已有对象的外观不变的情况下，编辑视频。</li>
<li>methods: 这篇论文使用了文本驱动的Diffusion模型，并引入了时间关系来保持对象的外观一致性。具体来说，它使用了一种新的间帧传播机制，将一帧的外观信息传播到下一帧。</li>
<li>results: 该论文的实验结果表明，与现有的视频编辑方法相比，其方法可以 достичь更高的编辑质量和一致性。<details>
<summary>Abstract</summary>
Diffusion-based methods can generate realistic images and videos, but they struggle to edit existing objects in a video while preserving their appearance over time. This prevents diffusion models from being applied to natural video editing in practical scenarios. In this paper, we tackle this problem by introducing temporal dependency to existing text-driven diffusion models, which allows them to generate consistent appearance for the edited objects. Specifically, we develop a novel inter-frame propagation mechanism for diffusion video editing, which leverages the concept of layered representations to propagate the appearance information from one frame to the next. We then build up a text-driven video editing framework based on this mechanism, namely StableVideo, which can achieve consistency-aware video editing. Extensive experiments demonstrate the strong editing capability of our approach. Compared with state-of-the-art video editing methods, our approach shows superior qualitative and quantitative results. Our code is available at \href{https://github.com/rese1f/StableVideo}{this https URL}.
</details>
<details>
<summary>摘要</summary>
Diffusion-based方法可以生成真实的图像和视频，但它们在现有视频中编辑已有对象的时候困难保持对象的外观在时间上的一致性。这使得扩散模型在实际的视频编辑场景中无法应用。在这篇论文中，我们解决了这个问题，通过添加时间相关性来改进现有的文本驱动扩散模型，使其能够在编辑过程中保持对象的外观一致性。我们开发了一种新的间帧传播机制，基于层次表示来传播一帧到下一帧的外观信息。然后，我们建立了基于这种机制的文本驱动视频编辑框架，即StableVideo，可以实现一致性感视频编辑。我们的实验表明，我们的方法可以具有优秀的编辑效果，相比之前的视频编辑方法，我们的方法在质量和量上都达到了更高的水平。我们的代码可以在以下 GitHub 上下载：https://github.com/rese1f/StableVideo。
</details></li>
</ul>
<hr>
<h2 id="O-2-Recon-Completing-3D-Reconstruction-of-Occluded-Objects-in-the-Scene-with-a-Pre-trained-2D-Diffusion-Model"><a href="#O-2-Recon-Completing-3D-Reconstruction-of-Occluded-Objects-in-the-Scene-with-a-Pre-trained-2D-Diffusion-Model" class="headerlink" title="O^2-Recon: Completing 3D Reconstruction of Occluded Objects in the Scene with a Pre-trained 2D Diffusion Model"></a>O^2-Recon: Completing 3D Reconstruction of Occluded Objects in the Scene with a Pre-trained 2D Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09591">http://arxiv.org/abs/2308.09591</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yubin Hu, Sheng Ye, Wang Zhao, Matthieu Lin, Yuze He, Yu-Hui Wen, Ying He, Yong-Jin Liu</li>
<li>for: 该研究旨在提出一种新的完整物体3D重建方法，解决RGB-D视频中物体遮挡问题。</li>
<li>methods: 该方法利用预训练的扩散模型填充2D图像隐藏部分，然后使用这些填充图像优化神经隐藏表示法对每个实例的3D重建。</li>
<li>results: 实验结果表明，该方法在ScanNet场景中可以达到状态之arte accuracy和完整性在对象级RGB-D视频重建中。<details>
<summary>Abstract</summary>
Occlusion is a common issue in 3D reconstruction from RGB-D videos, often blocking the complete reconstruction of objects and presenting an ongoing problem. In this paper, we propose a novel framework, empowered by a 2D diffusion-based in-painting model, to reconstruct complete surfaces for the hidden parts of objects. Specifically, we utilize a pre-trained diffusion model to fill in the hidden areas of 2D images. Then we use these in-painted images to optimize a neural implicit surface representation for each instance for 3D reconstruction. Since creating the in-painting masks needed for this process is tricky, we adopt a human-in-the-loop strategy that involves very little human engagement to generate high-quality masks. Moreover, some parts of objects can be totally hidden because the videos are usually shot from limited perspectives. To ensure recovering these invisible areas, we develop a cascaded network architecture for predicting signed distance field, making use of different frequency bands of positional encoding and maintaining overall smoothness. Besides the commonly used rendering loss, Eikonal loss, and silhouette loss, we adopt a CLIP-based semantic consistency loss to guide the surface from unseen camera angles. Experiments on ScanNet scenes show that our proposed framework achieves state-of-the-art accuracy and completeness in object-level reconstruction from scene-level RGB-D videos.
</details>
<details>
<summary>摘要</summary>
干扰是RGB-D视频中3D重建中的一个常见问题，常常阻塞对象的完整重建，是一个持续的问题。在这篇论文中，我们提出了一种新的框架，利用2D扩散模型来填充对象隐藏部分的表面。 Specifically，我们使用预训练的扩散模型填充隐藏在2D图像中的部分。然后，我们使用这些填充后的图像来优化每个实例的神经蕴涵表示。由于创建填充面积需要很多人工参与，我们采用了人类在循环的策略，即很少需要人工参与来生成高质量的填充面积。此外，视频通常从有限的视角拍摄，因此一些对象部分可能会被完全隐藏。为了保证恢复这些隐藏的部分，我们开发了一种层次网络架构，用于预测签名距离场，利用不同频率域的位置编码，并保持整体的平滑性。此外，我们还采用了基于CLIP的语义一致损失，以导引表面从未看到的摄像头角度。实验结果表明，我们的提出的框架在SceneNet场景中实现了state-of-the-art的准确性和完整性。
</details></li>
</ul>
<hr>
<h2 id="Deep-Equilibrium-Object-Detection"><a href="#Deep-Equilibrium-Object-Detection" class="headerlink" title="Deep Equilibrium Object Detection"></a>Deep Equilibrium Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09564">http://arxiv.org/abs/2308.09564</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/MCG-NJU/DEQDet">https://github.com/MCG-NJU/DEQDet</a></li>
<li>paper_authors: Shuai Wang, Yao Teng, Limin Wang</li>
<li>for: 本文提出了一种新的Query-based对象检测器（DEQDet），通过设计深度平衡解码器来进行对象检测。</li>
<li>methods: 本文使用了一种叫做深度平衡解码器（DEQ），它模型了查询向量精细化为稳定有意义的表示，然后使用简单的FFN头直接预测对象的位置和类别。</li>
<li>results: 对比基eline，本文的DEQDet在MS COCO数据集上达到了$49.5$ mAP和$33.0$ AP$_s$的性能，并且需要较少的内存和训练时间。<details>
<summary>Abstract</summary>
Query-based object detectors directly decode image features into object instances with a set of learnable queries. These query vectors are progressively refined to stable meaningful representations through a sequence of decoder layers, and then used to directly predict object locations and categories with simple FFN heads. In this paper, we present a new query-based object detector (DEQDet) by designing a deep equilibrium decoder. Our DEQ decoder models the query vector refinement as the fixed point solving of an {implicit} layer and is equivalent to applying {infinite} steps of refinement. To be more specific to object decoding, we use a two-step unrolled equilibrium equation to explicitly capture the query vector refinement. Accordingly, we are able to incorporate refinement awareness into the DEQ training with the inexact gradient back-propagation (RAG). In addition, to stabilize the training of our DEQDet and improve its generalization ability, we devise the deep supervision scheme on the optimization path of DEQ with refinement-aware perturbation~(RAP). Our experiments demonstrate DEQDet converges faster, consumes less memory, and achieves better results than the baseline counterpart (AdaMixer). In particular, our DEQDet with ResNet50 backbone and 300 queries achieves the $49.5$ mAP and $33.0$ AP$_s$ on the MS COCO benchmark under $2\times$ training scheme (24 epochs).
</details>
<details>
<summary>摘要</summary>
干ifen-based object detectors directly将图像特征解码成对象实例的集合，使用一组学习的查询向量。这些查询向量通过一系列解码层进行逐渐精细化，然后直接使用简单的FFN头预测对象的位置和类别。在这篇论文中，我们提出了一种新的查询基于object detector（DEQDet），通过设计深度平衡解码器来实现。我们的DEQ解码器模型查询向量精细化为 fixes point解决的{implicit}层，等于应用{无限}步的精细化。为了更加准确地捕捉对象解码中的查询向量精细化，我们采用了两步卷积的平衡方程。因此，我们可以在DEQ训练中引入精细化意识，并通过不确定梯度反propagation（RAG）进行训练。此外，为了稳定DEQDet的训练和提高其通用能力，我们提出了深度监视 schema在DEQ的优化路径上进行反制�ubble~(RAP)。我们的实验表明，DEQDet在比特笔COCO数据集上 converge faster，占用更少的内存，并 achieve better results than基eline对手（AdaMixer）。具体来说，我们的DEQDet使用ResNet50底层和300个查询可以在$2\times$ 训练方案下 achieve $49.5$ mAP和$33.0$ AP$_s$。
</details></li>
</ul>
<hr>
<h2 id="Decoupled-conditional-contrastive-learning-with-variable-metadata-for-prostate-lesion-detection"><a href="#Decoupled-conditional-contrastive-learning-with-variable-metadata-for-prostate-lesion-detection" class="headerlink" title="Decoupled conditional contrastive learning with variable metadata for prostate lesion detection"></a>Decoupled conditional contrastive learning with variable metadata for prostate lesion detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09542">http://arxiv.org/abs/2308.09542</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/camilleruppli/decoupled_ccl">https://github.com/camilleruppli/decoupled_ccl</a></li>
<li>paper_authors: Camille Ruppli, Pietro Gori, Roberto Ardon, Isabelle Bloch</li>
<li>For: 早期检测 próstate cancer 的重要性，以便有效的治疗。* Methods: 使用多parametric Magnetic Resonance Images (mp-MRI)  для诊断肿瘤。使用 Prostate Imaging Reporting and Data System (PI-RADS) 标准化评估肿瘤癌变性。* Results: 通过利用weak metadata 和多个标注者每个样本的 metadata confidence，定义metadata confidence，提高了lesion detection的准确率，在公共PI-CAI挑战数据集上提高了3%的AUC。Here’s the English version of the paper’s abstract, with the three key information points highlighted:* For: Early detection of prostate cancer is crucial for efficient treatment.* Methods: The paper uses multi-parametric Magnetic Resonance Images (mp-MRI) for lesion detection, and leverages the Prostate Imaging Reporting and Data System (PI-RADS) to standardize the interpretation of prostate MRI.* Results: The proposed contrastive loss function, which combines metadata of varying confidence with unannotated data, improves lesion detection accuracy by 3% on the public PI-CAI challenge dataset.I hope this helps!<details>
<summary>Abstract</summary>
Early diagnosis of prostate cancer is crucial for efficient treatment. Multi-parametric Magnetic Resonance Images (mp-MRI) are widely used for lesion detection. The Prostate Imaging Reporting and Data System (PI-RADS) has standardized interpretation of prostate MRI by defining a score for lesion malignancy. PI-RADS data is readily available from radiology reports but is subject to high inter-reports variability. We propose a new contrastive loss function that leverages weak metadata with multiple annotators per sample and takes advantage of inter-reports variability by defining metadata confidence. By combining metadata of varying confidence with unannotated data into a single conditional contrastive loss function, we report a 3% AUC increase on lesion detection on the public PI-CAI challenge dataset.   Code is available at: https://github.com/camilleruppli/decoupled_ccl
</details>
<details>
<summary>摘要</summary>
早期检测 проstate 癌的诊断是非常重要，以便进行有效的治疗。多 Parametric Magnetic Resonance Image (mp-MRI) 广泛用于肿瘤检测。 Prostate Imaging Reporting and Data System (PI-RADS) 已经标准化了 prostate MRI 的解释，并定义了肿瘤癌性的分数。PI-RADS 数据ready availability from radiology reports，但是受到高度的Inter-reports variability。我们提议一种新的对比损失函数，利用weak metadata 和多个注解者per sample，并利用Inter-reports variability by defining metadata confidence。通过将metadata of varying confidence 和无注释数据 combine into a single conditional contrastive loss function，我们在public PI-CAI challenge dataset上发现3%的AUC提升。Code is available at: https://github.com/camilleruppli/decoupled_cclNote: "prostate" is translated as " проstate" in Simplified Chinese, which is the standard translation.
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-based-quality-assurance-of-carotid-artery-wall-segmentation-in-black-blood-MRI"><a href="#Uncertainty-based-quality-assurance-of-carotid-artery-wall-segmentation-in-black-blood-MRI" class="headerlink" title="Uncertainty-based quality assurance of carotid artery wall segmentation in black-blood MRI"></a>Uncertainty-based quality assurance of carotid artery wall segmentation in black-blood MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09538">http://arxiv.org/abs/2308.09538</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/miagrouput/carotid-segmentation">https://github.com/miagrouput/carotid-segmentation</a></li>
<li>paper_authors: Elina Thibeau-Sutre, Dieuwertje Alblas, Sophie Buurman, Christoph Brune, Jelmer M. Wolterink</li>
<li>for: 这个论文目的是为了应用深度学习模型到大规模数据集中，并自动进行质量控制。</li>
<li>methods: 这个论文使用的方法包括自动化的某些血液MRI图像的分割，以及测试时数据增强和Monte Carlo dropout来估计模型预测结果的不确定性。</li>
<li>results: 研究发现，包括不确定性测量不会下降分割质量，不确定性指标可以用来衡量分割质量，并且可以检测参与者级别的低质量分割。这种自动质量控制工具可能会使得深度学习模型在大规模数据集中应用更加广泛。<details>
<summary>Abstract</summary>
The application of deep learning models to large-scale data sets requires means for automatic quality assurance. We have previously developed a fully automatic algorithm for carotid artery wall segmentation in black-blood MRI that we aim to apply to large-scale data sets. This method identifies nested artery walls in 3D patches centered on the carotid artery. In this study, we investigate to what extent the uncertainty in the model predictions for the contour location can serve as a surrogate for error detection and, consequently, automatic quality assurance. We express the quality of automatic segmentations using the Dice similarity coefficient. The uncertainty in the model's prediction is estimated using either Monte Carlo dropout or test-time data augmentation. We found that (1) including uncertainty measurements did not degrade the quality of the segmentations, (2) uncertainty metrics provide a good proxy of the quality of our contours if the center found during the first step is enclosed in the lumen of the carotid artery and (3) they could be used to detect low-quality segmentations at the participant level. This automatic quality assurance tool might enable the application of our model in large-scale data sets.
</details>
<details>
<summary>摘要</summary>
aplicación de modelos de aprendizaje profundo a conjuntos de datos a gran escala requiere medidas para la calidad automática. Hemos desarrollado anteriormente un algoritmo completamente automático para la segmentación de las paredes de la arteria carótida en imágenes de resonancia magnética negra, y nuestro objetivo es aplicar este método a conjuntos de datos a gran escala. Este método identifica las paredes de la arteria carótida en 3D en secciones centradas en la arteria carótida. En este estudio, investigamos hasta qué punto la incertidumbre en las predicciones del modelo sobre el lugar de la contornación puede servir como un substituto para la detección de errores y, por lo tanto, como una medida de calidad automática. Expresamos la calidad de las segmentaciones automáticas utilizando el coeficiente de semejanza de Dice. La incertidumbre en las predicciones del modelo se estima utilizando either dropout de Monte Carlo o augmentación de datos en tiempo de prueba. Encontramos que:1. Incluir mediciones de incertidumbre no degrade la calidad de las segmentaciones;2. Los métricos de incertidumbre proporcionan un buen sustituto de la calidad de nuestras contornaciones si el centro encontrado durante la primera etapa está en el lumen de la arteria carótida;3. Pueden ser utilizados para detectar segmentaciones de baja calidad en el nivel de participante.Este herramienta de calidad automática podría permitir la aplicación de nuestro modelo en conjuntos de datos a gran escala.
</details></li>
</ul>
<hr>
<h2 id="Small-Object-Detection-via-Coarse-to-fine-Proposal-Generation-and-Imitation-Learning"><a href="#Small-Object-Detection-via-Coarse-to-fine-Proposal-Generation-and-Imitation-Learning" class="headerlink" title="Small Object Detection via Coarse-to-fine Proposal Generation and Imitation Learning"></a>Small Object Detection via Coarse-to-fine Proposal Generation and Imitation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09534">http://arxiv.org/abs/2308.09534</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shaunyuan22/cfinet">https://github.com/shaunyuan22/cfinet</a></li>
<li>paper_authors: Xiang Yuan, Gong Cheng, Kebing Yan, Qinghua Zeng, Junwei Han</li>
<li>for: 提高小对象检测精度</li>
<li>methods: 使用Coarse-to-fine RPN和Feature Imitation learning</li>
<li>results: 在大规模小对象检测标准 benchmark 上达到领先的性能<details>
<summary>Abstract</summary>
The past few years have witnessed the immense success of object detection, while current excellent detectors struggle on tackling size-limited instances. Concretely, the well-known challenge of low overlaps between the priors and object regions leads to a constrained sample pool for optimization, and the paucity of discriminative information further aggravates the recognition. To alleviate the aforementioned issues, we propose CFINet, a two-stage framework tailored for small object detection based on the Coarse-to-fine pipeline and Feature Imitation learning. Firstly, we introduce Coarse-to-fine RPN (CRPN) to ensure sufficient and high-quality proposals for small objects through the dynamic anchor selection strategy and cascade regression. Then, we equip the conventional detection head with a Feature Imitation (FI) branch to facilitate the region representations of size-limited instances that perplex the model in an imitation manner. Moreover, an auxiliary imitation loss following supervised contrastive learning paradigm is devised to optimize this branch. When integrated with Faster RCNN, CFINet achieves state-of-the-art performance on the large-scale small object detection benchmarks, SODA-D and SODA-A, underscoring its superiority over baseline detector and other mainstream detection approaches.
</details>
<details>
<summary>摘要</summary>
Recent years have seen tremendous success in object detection, but current state-of-the-art detectors still struggle with detecting small objects. The main challenge is that the prior knowledge and object regions have low overlap, leading to a limited sample pool for optimization, and the lack of discriminative information makes it even more difficult to recognize the objects. To address these issues, we propose CFINet, a two-stage framework tailored for small object detection based on the Coarse-to-fine pipeline and Feature Imitation learning.First, we introduce Coarse-to-fine RPN (CRPN) to ensure sufficient and high-quality proposals for small objects through dynamic anchor selection and cascade regression. Then, we add a Feature Imitation (FI) branch to the conventional detection head to enhance the region representations of size-limited instances in an imitation manner. Moreover, we design an auxiliary imitation loss based on supervised contrastive learning to optimize this branch.When integrated with Faster RCNN, CFINet achieves state-of-the-art performance on large-scale small object detection benchmarks SODA-D and SODA-A, outperforming baseline detectors and other mainstream detection approaches.
</details></li>
</ul>
<hr>
<h2 id="Improving-3D-Pose-Estimation-for-Sign-Language"><a href="#Improving-3D-Pose-Estimation-for-Sign-Language" class="headerlink" title="Improving 3D Pose Estimation for Sign Language"></a>Improving 3D Pose Estimation for Sign Language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09525">http://arxiv.org/abs/2308.09525</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maksym Ivashechkin, Oscar Mendez, Richard Bowden</li>
<li>for: 这篇论文目标是提出一种基于前向运动学和神经网络的3D人姿重建方法，以实现快速和准确地测量人姿。</li>
<li>methods: 该方法利用了前向运动学（FK）和神经网络，将2D图像中的关键点检测转化为3D人姿。首先，使用神经网络预测人 JOINT 的旋转和肢长，然后将这些预测结果与骨骼约束相结合，通过实现了 PyTorch 中的 FK 层，以获得准确的3D人姿。</li>
<li>results: 通过量化和质量评估，该方法与 MediaPipe 相比，在每个 JOINT 的位势误差和视觉效果上具有显著的优势。此外，该方法还能够在不同的数据集上进行泛化。 PyTorch 实现在 CPU 上运行时间为100-200毫秒（包括 CNN 检测）。<details>
<summary>Abstract</summary>
This work addresses 3D human pose reconstruction in single images. We present a method that combines Forward Kinematics (FK) with neural networks to ensure a fast and valid prediction of 3D pose. Pose is represented as a hierarchical tree/graph with nodes corresponding to human joints that model their physical limits. Given a 2D detection of keypoints in the image, we lift the skeleton to 3D using neural networks to predict both the joint rotations and bone lengths. These predictions are then combined with skeletal constraints using an FK layer implemented as a network layer in PyTorch. The result is a fast and accurate approach to the estimation of 3D skeletal pose. Through quantitative and qualitative evaluation, we demonstrate the method is significantly more accurate than MediaPipe in terms of both per joint positional error and visual appearance. Furthermore, we demonstrate generalization over different datasets. The implementation in PyTorch runs at between 100-200 milliseconds per image (including CNN detection) using CPU only.
</details>
<details>
<summary>摘要</summary>
We evaluate the method through both quantitative and qualitative means, demonstrating that it is significantly more accurate than MediaPipe in terms of both per joint positional error and visual appearance. Additionally, we show that the method generalizes well across different datasets. The implementation in PyTorch runs at between 100-200 milliseconds per image (including CNN detection) using CPU only.
</details></li>
</ul>
<hr>
<h2 id="Denoising-Diffusion-for-3D-Hand-Pose-Estimation-from-Images"><a href="#Denoising-Diffusion-for-3D-Hand-Pose-Estimation-from-Images" class="headerlink" title="Denoising Diffusion for 3D Hand Pose Estimation from Images"></a>Denoising Diffusion for 3D Hand Pose Estimation from Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09523">http://arxiv.org/abs/2308.09523</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maksym Ivashechkin, Oscar Mendez, Richard Bowden</li>
<li>for: 本研究旨在解决从单个图像或序列中提取3D手势的问题。</li>
<li>methods: 提出了一种新的端到端框架，使用了扩散模型来捕捉数据分布，并遵循了机械约束来确保生成的姿势是有效的。</li>
<li>results: 研究表明该方法可以在提取2D单手图像到3D的过程中提供状态的最佳性能，并在使用序列数据时通过添加Transformer模块来进一步提高准确性。<details>
<summary>Abstract</summary>
Hand pose estimation from a single image has many applications. However, approaches to full 3D body pose estimation are typically trained on day-to-day activities or actions. As such, detailed hand-to-hand interactions are poorly represented, especially during motion. We see this in the failure cases of techniques such as OpenPose or MediaPipe. However, accurate hand pose estimation is crucial for many applications where the global body motion is less important than accurate hand pose estimation.   This paper addresses the problem of 3D hand pose estimation from monocular images or sequences. We present a novel end-to-end framework for 3D hand regression that employs diffusion models that have shown excellent ability to capture the distribution of data for generative purposes. Moreover, we enforce kinematic constraints to ensure realistic poses are generated by incorporating an explicit forward kinematic layer as part of the network. The proposed model provides state-of-the-art performance when lifting a 2D single-hand image to 3D. However, when sequence data is available, we add a Transformer module over a temporal window of consecutive frames to refine the results, overcoming jittering and further increasing accuracy.   The method is quantitatively and qualitatively evaluated showing state-of-the-art robustness, generalization, and accuracy on several different datasets.
</details>
<details>
<summary>摘要</summary>
<<SYS>> traduced the text into Simplified Chinese.<</SYS>>人体手势估计从单个图像中有很多应用。然而，对全息体姿估计方法通常是在日常活动或动作上训练的。因此，手部之间的细节互动被不好地表示，特别是在运动中。我们在技术如OpenPose或MediaPipe的失败案例中看到了这一点。然而，准确的手势估计对许多应用来说非常重要，特别是在全息体姿的运动不那么重要。这篇论文Addresses the problem of 3D手势估计从单个图像或序列中。我们提出了一种新的终端框架，用于3D手势回归。该框架利用了扩散模型，这些模型在生成目的上表现出了优秀的能力。此外，我们加入了显式前向几何层，以确保生成的姿势是真实的。提议的模型在将2D单手图像提升到3D的任务中提供了状态机器的性能。当序列数据可用时，我们将Transformer模块添加到 consecutives帧中，以修复结果，超越晃动，并提高准确率。方法被量测量和质量上评估，显示了状态机器的稳定性、泛化能力和准确率在多个不同的数据集上都达到了顶峰。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Intrinsic-Properties-for-Non-Rigid-Garment-Alignment"><a href="#Leveraging-Intrinsic-Properties-for-Non-Rigid-Garment-Alignment" class="headerlink" title="Leveraging Intrinsic Properties for Non-Rigid Garment Alignment"></a>Leveraging Intrinsic Properties for Non-Rigid Garment Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09519">http://arxiv.org/abs/2308.09519</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siyou Lin, Boyao Zhou, Zerong Zheng, Hongwen Zhang, Yebin Liu<br>for:这篇论文targets the problem of aligning real-world 3D garment data, which is beneficial for applications such as texture learning, physical parameter estimation, and generative modeling of garments.methods:The proposed method leverages intrinsic manifold properties and uses two neural deformation fields, one in 3D space and another in intrinsic space, to achieve coarse-to-fine alignment. The coarse stage performs a 3D fitting, and the refined stage uses a second neural deformation field for higher accuracy.results:The method achieves accurate wrinkle-level and texture-level alignment and works well for difficult garment types such as long coats. The project page with more information and results is available at <a target="_blank" rel="noopener" href="https://jsnln.github.io/iccv2023_intrinsic/index.html">https://jsnln.github.io/iccv2023_intrinsic/index.html</a>.<details>
<summary>Abstract</summary>
We address the problem of aligning real-world 3D data of garments, which benefits many applications such as texture learning, physical parameter estimation, generative modeling of garments, etc. Existing extrinsic methods typically perform non-rigid iterative closest point and struggle to align details due to incorrect closest matches and rigidity constraints. While intrinsic methods based on functional maps can produce high-quality correspondences, they work under isometric assumptions and become unreliable for garment deformations which are highly non-isometric. To achieve wrinkle-level as well as texture-level alignment, we present a novel coarse-to-fine two-stage method that leverages intrinsic manifold properties with two neural deformation fields, in the 3D space and the intrinsic space, respectively. The coarse stage performs a 3D fitting, where we leverage intrinsic manifold properties to define a manifold deformation field. The coarse fitting then induces a functional map that produces an alignment of intrinsic embeddings. We further refine the intrinsic alignment with a second neural deformation field for higher accuracy. We evaluate our method with our captured garment dataset, GarmCap. The method achieves accurate wrinkle-level and texture-level alignment and works for difficult garment types such as long coats. Our project page is https://jsnln.github.io/iccv2023_intrinsic/index.html.
</details>
<details>
<summary>摘要</summary>
我们解决了对真实世界3D资料的衣服对齐问题，这有助于训练文本、物理参数估计、生成衣服等应用程序。现有的外部方法通常会进行非静态迭代最近点，并很难跟踪细节，因为 incorrect closest matches 和静态约束。而内部方法基于函数对应则可以生成高品质对应关系，但它们在衣服塑形中是不可靠的，因为衣服塑形是非静态的。为了 achiev wrinkle-level 和 texture-level 对齐，我们提出了一个新的两阶段方法，利用内部构造特性，并使用两个神经塑形场，在3D空间和内部空间中进行塑形。在粗细阶段，我们利用内部构造特性定义一个构造塑形场，并将其调整为一个函数对应。我们进一步将这个函数对应进行精确调整，使用第二个神经塑形场。我们评估了我们的方法，使用我们捕捉的衣服Dataset，GarmCap。我们的方法可以实现细节级和纹理级对齐，并在困难的衣服类型，如长大袍，也能够运作。我们的项目页面是 <https://jsnln.github.io/iccv2023_intrinsic/index.html>。
</details></li>
</ul>
<hr>
<h2 id="Learnt-Contrastive-Concept-Embeddings-for-Sign-Recognition"><a href="#Learnt-Contrastive-Concept-Embeddings-for-Sign-Recognition" class="headerlink" title="Learnt Contrastive Concept Embeddings for Sign Recognition"></a>Learnt Contrastive Concept Embeddings for Sign Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09515">http://arxiv.org/abs/2308.09515</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ryan Wong, Necati Cihan Camgoz, Richard Bowden</li>
<li>for: 本研究旨在提供一种基于contrastive learning的、weakly supervised的签语嵌入方法，用于将手语语言与口语语言相互连接。</li>
<li>methods: 我们提出了一种学习框架，用于 derivation LCC（学习对应概念）嵌入 для手语语言，该方法基于手语语言的语言标签来训练词语表示。我们还开发了一种基于word embedding的概念相似损失函数，以便使用NLP方法中的word embedding来创建更好的手语嵌入。</li>
<li>results: 我们的方法可以在WLASL和BOBSL数据集上实现状态实验室的键点基于手语识别性能。<details>
<summary>Abstract</summary>
In natural language processing (NLP) of spoken languages, word embeddings have been shown to be a useful method to encode the meaning of words. Sign languages are visual languages, which require sign embeddings to capture the visual and linguistic semantics of sign. Unlike many common approaches to Sign Recognition, we focus on explicitly creating sign embeddings that bridge the gap between sign language and spoken language. We propose a learning framework to derive LCC (Learnt Contrastive Concept) embeddings for sign language, a weakly supervised contrastive approach to learning sign embeddings. We train a vocabulary of embeddings that are based on the linguistic labels for sign video. Additionally, we develop a conceptual similarity loss which is able to utilise word embeddings from NLP methods to create sign embeddings that have better sign language to spoken language correspondence. These learnt representations allow the model to automatically localise the sign in time. Our approach achieves state-of-the-art keypoint-based sign recognition performance on the WLASL and BOBSL datasets.
</details>
<details>
<summary>摘要</summary>
在自然语言处理（NLP）的 spoken语言中，词嵌入已经被证明是一种有用的方法来编码词语的含义。手语是一种视觉语言，需要手势嵌入来捕捉手语的视觉和语言 semantics。不同于许多常见的手语识别方法，我们注重于显式地创建手势嵌入，以bridging the gap between手语和口语。我们提出了一种学习框架，用于 derivation LCC（学习对应概念）嵌入 для手语，这是一种弱监督对比方法来学习手势嵌入。我们训练了一个词库，基于手语视频的语言标签来学习嵌入。此外，我们开发了一种概念相似损失，可以利用 NLP 方法中的词嵌入来创建更好地与口语相匹配的手势嵌入。这些学习的表示允许模型自动在时间上local化手语。我们的方法在 WLASL 和 BOBSL 数据集上实现了状态的键点基于手语识别性能。
</details></li>
</ul>
<hr>
<h2 id="ResQ-Residual-Quantization-for-Video-Perception"><a href="#ResQ-Residual-Quantization-for-Video-Perception" class="headerlink" title="ResQ: Residual Quantization for Video Perception"></a>ResQ: Residual Quantization for Video Perception</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09511">http://arxiv.org/abs/2308.09511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Davide Abati, Haitam Ben Yahia, Markus Nagel, Amirhossein Habibian</li>
<li>for: 加速视频识别，如semantic segmentation和人体 pose estimation，通过利用帧间重复性。</li>
<li>methods: 利用低位量编码，基于差异网络活动的差分 residuals 的特性，提出 Residual Quantization 模型。</li>
<li>results: 比标准quantization和现有高效视频识别模型 superior performance 在准确性和位宽之间的权衡。<details>
<summary>Abstract</summary>
This paper accelerates video perception, such as semantic segmentation and human pose estimation, by levering cross-frame redundancies. Unlike the existing approaches, which avoid redundant computations by warping the past features using optical-flow or by performing sparse convolutions on frame differences, we approach the problem from a new perspective: low-bit quantization. We observe that residuals, as the difference in network activations between two neighboring frames, exhibit properties that make them highly quantizable. Based on this observation, we propose a novel quantization scheme for video networks coined as Residual Quantization. ResQ extends the standard, frame-by-frame, quantization scheme by incorporating temporal dependencies that lead to better performance in terms of accuracy vs. bit-width. Furthermore, we extend our model to dynamically adjust the bit-width proportional to the amount of changes in the video. We demonstrate the superiority of our model, against the standard quantization and existing efficient video perception models, using various architectures on semantic segmentation and human pose estimation benchmarks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Video-Instrument-Synergistic-Network-for-Referring-Video-Instrument-Segmentation-in-Robotic-Surgery"><a href="#Video-Instrument-Synergistic-Network-for-Referring-Video-Instrument-Segmentation-in-Robotic-Surgery" class="headerlink" title="Video-Instrument Synergistic Network for Referring Video Instrument Segmentation in Robotic Surgery"></a>Video-Instrument Synergistic Network for Referring Video Instrument Segmentation in Robotic Surgery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09475">http://arxiv.org/abs/2308.09475</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongqiu Wang, Lei Zhu, Guang Yang, Yike Guo, Shichen Zhang, Bo Xu, Yueming Jin</li>
<li>for: 该研究旨在提高Robot-assisted surgery的质量，通过实时器段化来促进手术 Navigation和医学教育。</li>
<li>methods: 该研究提出了一种新的 Referring Surgical Video Instrument Segmentation (RSVIS)任务，通过自动将文本描述与视频帧相关联，以提高手术器段化的精度。为此，我们提出了一种新的 Video-Instrument Synergistic Network (VIS-Net)，以学习视频水平和工具水平的知识，从而提高性能。同时，我们还设计了一种图像基于关系意识模块 (GRM)，以模型多modal信息（文本描述和视频帧）之间的关系，以便提取工具级别信息。</li>
<li>results: 我们的方法在两个RSVIS dataset上进行验证，实验结果表明，我们的VIS-Net可以significantly outperform现有的参照分割方法。<details>
<summary>Abstract</summary>
Robot-assisted surgery has made significant progress, with instrument segmentation being a critical factor in surgical intervention quality. It serves as the building block to facilitate surgical robot navigation and surgical education for the next generation of operating intelligence. Although existing methods have achieved accurate instrument segmentation results, they simultaneously generate segmentation masks for all instruments, without the capability to specify a target object and allow an interactive experience. This work explores a new task of Referring Surgical Video Instrument Segmentation (RSVIS), which aims to automatically identify and segment the corresponding surgical instruments based on the given language expression. To achieve this, we devise a novel Video-Instrument Synergistic Network (VIS-Net) to learn both video-level and instrument-level knowledge to boost performance, while previous work only used video-level information. Meanwhile, we design a Graph-based Relation-aware Module (GRM) to model the correlation between multi-modal information (i.e., textual description and video frame) to facilitate the extraction of instrument-level information. We are also the first to produce two RSVIS datasets to promote related research. Our method is verified on these datasets, and experimental results exhibit that the VIS-Net can significantly outperform existing state-of-the-art referring segmentation methods. Our code and our datasets will be released upon the publication of this work.
</details>
<details>
<summary>摘要</summary>
机器人协助手术已经做出了重要进步， инструмен特征分割成为手术干预质量的关键因素。它作为手术机器人导航和下一代操作智能的基础阶段，对手术教育也具有重要意义。 although existing methods have achieved accurate instrument segmentation results, they simultaneously generate segmentation masks for all instruments, without the capability to specify a target object and allow an interactive experience. This work explores a new task of Referring Surgical Video Instrument Segmentation (RSVIS), which aims to automatically identify and segment the corresponding surgical instruments based on the given language expression. To achieve this, we devise a novel Video-Instrument Synergistic Network (VIS-Net) to learn both video-level and instrument-level knowledge to boost performance, while previous work only used video-level information. Meanwhile, we design a Graph-based Relation-aware Module (GRM) to model the correlation between multi-modal information (i.e., textual description and video frame) to facilitate the extraction of instrument-level information. We are also the first to produce two RSVIS datasets to promote related research. Our method is verified on these datasets, and experimental results exhibit that the VIS-Net can significantly outperform existing state-of-the-art referring segmentation methods. Our code and our datasets will be released upon the publication of this work.Here's the translation in Traditional Chinese:机器人协助手术已经做出了重要进步， instrumente特征分割成为手术干预质量的关键因素。它作为手术机器人导航和下一代操作智能的基础阶段，对手术教育也具有重要意义。although existing methods have achieved accurate instrument segmentation results, they simultaneously generate segmentation masks for all instruments, without the capability to specify a target object and allow an interactive experience. This work explores a new task of Referring Surgical Video Instrument Segmentation (RSVIS), which aims to automatically identify and segment the corresponding surgical instruments based on the given language expression. To achieve this, we devise a novel Video-Instrument Synergistic Network (VIS-Net) to learn both video-level and instrument-level knowledge to boost performance, while previous work only used video-level information. Meanwhile, we design a Graph-based Relation-aware Module (GRM) to model the correlation between multi-modal information (i.e., textual description and video frame) to facilitate the extraction of instrument-level information. We are also the first to produce two RSVIS datasets to promote related research. Our method is verified on these datasets, and experimental results exhibit that the VIS-Net can significantly outperform existing state-of-the-art referring segmentation methods. Our code and our datasets will be released upon the publication of this work.
</details></li>
</ul>
<hr>
<h2 id="Quantitative-Susceptibility-Mapping-through-Model-based-Deep-Image-Prior-MoDIP"><a href="#Quantitative-Susceptibility-Mapping-through-Model-based-Deep-Image-Prior-MoDIP" class="headerlink" title="Quantitative Susceptibility Mapping through Model-based Deep Image Prior (MoDIP)"></a>Quantitative Susceptibility Mapping through Model-based Deep Image Prior (MoDIP)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09467">http://arxiv.org/abs/2308.09467</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuang Xiong, Yang Gao, Yin Liu, Amir Fazlollahi, Peter Nestor, Feng Liu, Hongfu Sun</li>
<li>for: 解决量子感知图像推导中不同对象的扫描参数下的偏振转换问题</li>
<li>methods: 提出了一种新的无需训练的模型基于深度学习方法，称为MoDIP（模型基于深度图像优先）</li>
<li>results: 在不同扫描参数下，MoDIP可以 excellently 普适化解决量子感知图像推导问题，并且比传统的迭代方法和深度学习方法有32%的准确率提升，同时也比传统的DIP方法33%更快速，可以在4.5分钟内完成3D高分辨率图像重建。<details>
<summary>Abstract</summary>
The data-driven approach of supervised learning methods has limited applicability in solving dipole inversion in Quantitative Susceptibility Mapping (QSM) with varying scan parameters across different objects. To address this generalization issue in supervised QSM methods, we propose a novel training-free model-based unsupervised method called MoDIP (Model-based Deep Image Prior). MoDIP comprises a small, untrained network and a Data Fidelity Optimization (DFO) module. The network converges to an interim state, acting as an implicit prior for image regularization, while the optimization process enforces the physical model of QSM dipole inversion. Experimental results demonstrate MoDIP's excellent generalizability in solving QSM dipole inversion across different scan parameters. It exhibits robustness against pathological brain QSM, achieving over 32% accuracy improvement than supervised deep learning and traditional iterative methods. It is also 33% more computationally efficient and runs 4 times faster than conventional DIP-based approaches, enabling 3D high-resolution image reconstruction in under 4.5 minutes.
</details>
<details>
<summary>摘要</summary>
supervised学习方法的数据驱动方法在量子频谱地图（QSM）中的杂项倒转问题中有限的应用。为解决这种泛化问题，我们提议一种没有训练的模型基于无supervised方法called MoDIP（模型基于深度图像先验）。MoDIP包括一个小型、未训练的网络和数据准确优化（DFO）模块。网络在进行杂项倒转时 converges to an interim state，作为图像规范化的隐藏先验，而优化过程检查QSM杂项倒转的物理模型。实验结果表明MoDIP在不同扫描参数下的QSM杂项倒转问题中具有出色的泛化性。它在异常脑QSM问题中表现稳定，比超出深度学习和传统迭代方法32%以上的准确率提高。它还比折衔DIP基于方法33%更快，可以在4.5分钟内完成3D高分辨率图像重建。
</details></li>
</ul>
<hr>
<h2 id="Data-augmentation-and-explainability-for-bias-discovery-and-mitigation-in-deep-learning"><a href="#Data-augmentation-and-explainability-for-bias-discovery-and-mitigation-in-deep-learning" class="headerlink" title="Data augmentation and explainability for bias discovery and mitigation in deep learning"></a>Data augmentation and explainability for bias discovery and mitigation in deep learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09464">http://arxiv.org/abs/2308.09464</a></li>
<li>repo_url: None</li>
<li>paper_authors: Agnieszka Mikołajczyk-Bareła<br>for: 这个论文的目的是研究深度神经网络中的偏见问题，并提出了一些方法来减少偏见对模型性能的影响。methods: 这个论文使用了一些方法来减少偏见，包括：Explainable AI、Style Transfer Data Augmentation、Targeted Data Augmentations和Attribution Feedback。results: 这个论文的研究结果表明，通过使用这些方法可以减少偏见对模型性能的影响，并提高模型的准确率。<details>
<summary>Abstract</summary>
This dissertation explores the impact of bias in deep neural networks and presents methods for reducing its influence on model performance. The first part begins by categorizing and describing potential sources of bias and errors in data and models, with a particular focus on bias in machine learning pipelines. The next chapter outlines a taxonomy and methods of Explainable AI as a way to justify predictions and control and improve the model. Then, as an example of a laborious manual data inspection and bias discovery process, a skin lesion dataset is manually examined. A Global Explanation for the Bias Identification method is proposed as an alternative semi-automatic approach to manual data exploration for discovering potential biases in data. Relevant numerical methods and metrics are discussed for assessing the effects of the identified biases on the model. Whereas identifying errors and bias is critical, improving the model and reducing the number of flaws in the future is an absolute priority. Hence, the second part of the thesis focuses on mitigating the influence of bias on ML models. Three approaches are proposed and discussed: Style Transfer Data Augmentation, Targeted Data Augmentations, and Attribution Feedback. Style Transfer Data Augmentation aims to address shape and texture bias by merging a style of a malignant lesion with a conflicting shape of a benign one. Targeted Data Augmentations randomly insert possible biases into all images in the dataset during the training, as a way to make the process random and, thus, destroy spurious correlations. Lastly, Attribution Feedback is used to fine-tune the model to improve its accuracy by eliminating obvious mistakes and teaching it to ignore insignificant input parts via an attribution loss. The goal of these approaches is to reduce the influence of bias on machine learning models, rather than eliminate it entirely.
</details>
<details>
<summary>摘要</summary>
As an example of a laborious manual data inspection and bias discovery process, a skin lesion dataset is manually examined. A Global Explanation for the Bias Identification method is proposed as an alternative semi-automatic approach to manual data exploration for discovering potential biases in data. Relevant numerical methods and metrics are discussed for assessing the effects of the identified biases on the model.Whereas identifying errors and bias is critical, improving the model and reducing the number of flaws in the future is an absolute priority. Hence, the second part of the thesis focuses on mitigating the influence of bias on ML models. Three approaches are proposed and discussed: Style Transfer Data Augmentation, Targeted Data Augmentations, and Attribution Feedback.Style Transfer Data Augmentation aims to address shape and texture bias by merging a style of a malignant lesion with a conflicting shape of a benign one. Targeted Data Augmentations randomly insert possible biases into all images in the dataset during the training, as a way to make the process random and, thus, destroy spurious correlations. Lastly, Attribution Feedback is used to fine-tune the model to improve its accuracy by eliminating obvious mistakes and teaching it to ignore insignificant input parts via an attribution loss. The goal of these approaches is to reduce the influence of bias on machine learning models, rather than eliminate it entirely.
</details></li>
</ul>
<hr>
<h2 id="Accelerated-Bayesian-imaging-by-relaxed-proximal-point-Langevin-sampling"><a href="#Accelerated-Bayesian-imaging-by-relaxed-proximal-point-Langevin-sampling" class="headerlink" title="Accelerated Bayesian imaging by relaxed proximal-point Langevin sampling"></a>Accelerated Bayesian imaging by relaxed proximal-point Langevin sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09460">http://arxiv.org/abs/2308.09460</a></li>
<li>repo_url: None</li>
<li>paper_authors: Teresa Klatzer, Paul Dobson, Yoann Altmann, Marcelo Pereyra, Jesús María Sanz-Serna, Konstantinos C. Zygalakis</li>
<li>for: 这个论文提出了一种新的加速 proximal Markov chain Monte Carlo 方法，用于在具有凸凹性的图像反问题中进行 Bayesian 推断。</li>
<li>methods: 该方法使用了一种 Stochastic Relaxed Proximal-Point 迭代法，该迭代法可以看作是一种停止推断方法，并且有两种不同的解释。对于满足某些条件的模型，该方法等价于一种停止推断方法，而对于不满足这些条件的模型，该方法等价于一种 Leimkuhler-Matthews 离散方法。</li>
<li>results: 该paper提供了一种非对称的 accelerated proximal Markov chain Monte Carlo 方法，该方法可以在凸凹性的图像反问题中获得加速的速度，并且可以避免对于非凸凹性模型的偏度。在不同的实验中，该方法都能够达到更高的速度和更好的准确性，比如图像恢复问题中的 Gaussian 和 Poisson 噪声。<details>
<summary>Abstract</summary>
This paper presents a new accelerated proximal Markov chain Monte Carlo methodology to perform Bayesian inference in imaging inverse problems with an underlying convex geometry. The proposed strategy takes the form of a stochastic relaxed proximal-point iteration that admits two complementary interpretations. For models that are smooth or regularised by Moreau-Yosida smoothing, the algorithm is equivalent to an implicit midpoint discretisation of an overdamped Langevin diffusion targeting the posterior distribution of interest. This discretisation is asymptotically unbiased for Gaussian targets and shown to converge in an accelerated manner for any target that is $\kappa$-strongly log-concave (i.e., requiring in the order of $\sqrt{\kappa}$ iterations to converge, similarly to accelerated optimisation schemes), comparing favorably to [M. Pereyra, L. Vargas Mieles, K.C. Zygalakis, SIAM J. Imaging Sciences, 13, 2 (2020), pp. 905-935] which is only provably accelerated for Gaussian targets and has bias. For models that are not smooth, the algorithm is equivalent to a Leimkuhler-Matthews discretisation of a Langevin diffusion targeting a Moreau-Yosida approximation of the posterior distribution of interest, and hence achieves a significantly lower bias than conventional unadjusted Langevin strategies based on the Euler-Maruyama discretisation. For targets that are $\kappa$-strongly log-concave, the provided non-asymptotic convergence analysis also identifies the optimal time step which maximizes the convergence speed. The proposed methodology is demonstrated through a range of experiments related to image deconvolution with Gaussian and Poisson noise, with assumption-driven and data-driven convex priors.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Transformer-based-Detection-of-Microorganisms-on-High-Resolution-Petri-Dish-Images"><a href="#Transformer-based-Detection-of-Microorganisms-on-High-Resolution-Petri-Dish-Images" class="headerlink" title="Transformer-based Detection of Microorganisms on High-Resolution Petri Dish Images"></a>Transformer-based Detection of Microorganisms on High-Resolution Petri Dish Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09436">http://arxiv.org/abs/2308.09436</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikolas Ebert, Didier Stricker, Oliver Wasenmüller</li>
<li>for: 该论文主要用于提高医疗或制药过程中的不间断清洁监测。</li>
<li>methods: 该论文使用了一种新型的变体自注意机制，称为高效全局自注意机制，以解决当前自动化检测技术面临的主要挑战。</li>
<li>results: 在公共可用的 AGAR 数据集上，该网络表现出了与当前状态艺术的超过当前最佳性能。此外，通过在 COCO 和 LIVECell 数据集上进行进一步的实验，我们证明了该方法的任务独立性。<details>
<summary>Abstract</summary>
Many medical or pharmaceutical processes have strict guidelines regarding continuous hygiene monitoring. This often involves the labor-intensive task of manually counting microorganisms in Petri dishes by trained personnel. Automation attempts often struggle due to major challenges: significant scaling differences, low separation, low contrast, etc. To address these challenges, we introduce AttnPAFPN, a high-resolution detection pipeline that leverages a novel transformer variation, the efficient-global self-attention mechanism. Our streamlined approach can be easily integrated in almost any multi-scale object detection pipeline. In a comprehensive evaluation on the publicly available AGAR dataset, we demonstrate the superior accuracy of our network over the current state-of-the-art. In order to demonstrate the task-independent performance of our approach, we perform further experiments on COCO and LIVECell datasets.
</details>
<details>
<summary>摘要</summary>
许多医疗或药品生产过程有严格的清洁监测指南。这经常包括人工计数微生物在杯中的劳动密集任务，由训练过的人员进行。自动化尝试经常遇到主要挑战，如规模差异、低分离、低对比等。为解决这些挑战，我们介绍AttnPAFPN，一种高分辨率检测管线，利用一种新型变体的 transformer 机制，即有效全球自注意机制。我们的流线型approach可以轻松地与大多数多尺度对象检测管线集成。在公共可用的 AGAR 数据集上进行了全面的评估，我们示出了我们网络比现状态的最高精度。为了证明我们的方法是任务独立的，我们在 COCO 和 LIVECell 数据集上进行了进一步的实验。
</details></li>
</ul>
<hr>
<h2 id="Can-ultrasound-confidence-maps-predict-sonographers’-labeling-variability"><a href="#Can-ultrasound-confidence-maps-predict-sonographers’-labeling-variability" class="headerlink" title="Can ultrasound confidence maps predict sonographers’ labeling variability?"></a>Can ultrasound confidence maps predict sonographers’ labeling variability?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09433">http://arxiv.org/abs/2308.09433</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vanessa Gonzalez Duque, Leonhard Zirus, Yordanka Velikova, Nassir Navab, Diana Mateus</li>
<li>for: 这个论文的目的是提出一种新的深度学习 segmentation 方法，以便考虑医生对 ultrasound 图像的注意力和不确定性。</li>
<li>methods: 该方法使用了 ultrasound 图像中的信任度映射 (CM)，以帮助深度学习 segmentation 网络生成更加准确和多样化的预测结果。</li>
<li>results: 研究结果表明，使用 ultrasound CM 可以提高 Dice 分数、改善 Hausdorff 和平均表面距离，以及减少孤立像素预测。此外，研究还发现， ultrasound CM 可以改善真实 interpolations 的惩罚，从而提高深度学习 segmentation 的准确性。<details>
<summary>Abstract</summary>
Measuring cross-sectional areas in ultrasound images is a standard tool to evaluate disease progress or treatment response. Often addressed today with supervised deep-learning segmentation approaches, existing solutions highly depend upon the quality of experts' annotations. However, the annotation quality in ultrasound is anisotropic and position-variant due to the inherent physical imaging principles, including attenuation, shadows, and missing boundaries, commonly exacerbated with depth. This work proposes a novel approach that guides ultrasound segmentation networks to account for sonographers' uncertainties and generate predictions with variability similar to the experts. We claim that realistic variability can reduce overconfident predictions and improve physicians' acceptance of deep-learning cross-sectional segmentation solutions. Our method provides CM's certainty for each pixel for minimal computational overhead as it can be precalculated directly from the image. We show that there is a correlation between low values in the confidence maps and expert's label uncertainty. Therefore, we propose to give the confidence maps as additional information to the networks. We study the effect of the proposed use of ultrasound CMs in combination with four state-of-the-art neural networks and in two configurations: as a second input channel and as part of the loss. We evaluate our method on 3D ultrasound datasets of the thyroid and lower limb muscles. Our results show ultrasound CMs increase the Dice score, improve the Hausdorff and Average Surface Distances, and decrease the number of isolated pixel predictions. Furthermore, our findings suggest that ultrasound CMs improve the penalization of uncertain areas in the ground truth data, thereby improving problematic interpolations. Our code and example data will be made public at https://github.com/IFL-CAMP/Confidence-segmentation.
</details>
<details>
<summary>摘要</summary>
评估静止影像中的横截面面积是评估疾病进程或治疗效果的标准工具。现有的深度学习分割方法可以高度依赖专家的注释，但是现有的解决方案受到镜像质量的限制，镜像质量呈扁平不均，受到物理镜像原理的影响，包括吸收、阴影和缺失边界，这些问题通常会在深度方向加剧。本文提出了一种新的方法，使得ultrasound分割网络能够考虑医生uncertainty，生成具有类似专家预测的各种性的预测。我们认为，在静止影像中添加realistic的variability可以减少过于自信的预测，提高医生对深度学习横截面分割解决方案的acceptance。我们的方法可以在低计算开销下提供CM的确定性，直接从图像中计算。我们发现，低值在确定性图中与专家标签不确定性相吻合。因此，我们提议使用ultrasound CM来补充网络。我们在四种state-of-the-art神经网络和两种配置下测试了我们的方法：作为第二个输入通道和作为损失的一部分。我们在3D静止影像 datasets中评估了我们的方法，结果显示，ultrasound CM可以提高 dice分数、改善 Hausdorff和平均表面距离，并减少孤立像素预测。此外，我们发现，ultrasound CM可以优化问题 interpolations，因此提高了对真实值数据的惩罚。我们的代码和示例数据将在https://github.com/IFL-CAMP/Confidence-segmentation中公开。
</details></li>
</ul>
<hr>
<h2 id="Self-Supervised-Single-Image-Deconvolution-with-Siamese-Neural-Networks"><a href="#Self-Supervised-Single-Image-Deconvolution-with-Siamese-Neural-Networks" class="headerlink" title="Self-Supervised Single-Image Deconvolution with Siamese Neural Networks"></a>Self-Supervised Single-Image Deconvolution with Siamese Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09426">http://arxiv.org/abs/2308.09426</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mikhail Papkov, Kaupo Palo, Leopold Parts</li>
<li>for: 这篇论文旨在提出一种基于深度学习的图像恢复方法，以提高图像的清晰度和锐度。</li>
<li>methods: 该方法使用了自适应掩模神经网络，通过直接从数据中学习雨花点质量而不需要手动设置参数。</li>
<li>results: 实验结果表明，该改进的框架可以在3D微型scopy图像恢复任务中高效地提高图像的清晰度和锐度，并且超过了之前的状态艺术恢复方法。<details>
<summary>Abstract</summary>
Inverse problems in image reconstruction are fundamentally complicated by unknown noise properties. Classical iterative deconvolution approaches amplify noise and require careful parameter selection for an optimal trade-off between sharpness and grain. Deep learning methods allow for flexible parametrization of the noise and learning its properties directly from the data. Recently, self-supervised blind-spot neural networks were successfully adopted for image deconvolution by including a known point-spread function in the end-to-end training. However, their practical application has been limited to 2D images in the biomedical domain because it implies large kernels that are poorly optimized. We tackle this problem with Fast Fourier Transform convolutions that provide training speed-up in 3D microscopy deconvolution tasks. Further, we propose to adopt a Siamese invariance loss for deconvolution and empirically identify its optimal position in the neural network between blind-spot and full image branches. The experimental results show that our improved framework outperforms the previous state-of-the-art deconvolution methods with a known point spread function.
</details>
<details>
<summary>摘要</summary>
“影像重建问题的逆问题是由于未知的噪音特性而困难。经典的迭代复原方法将噪音放大，需要精确地选择参数以取得最佳的对称性和粒子。深度学习方法可以灵活地设定噪音的参数，并将其直接从数据中学习。现在，自我监督的盲点神经网络在影像复原中获得了成功，但它们仅适用于2D图像在医学领域中。我们解决这个问题，使用快速傅立叶变换来提高3D显微镜复原任务的训练速度。此外，我们提议运用对称损失来复原，并评估其在神经网络中的最佳位置。实验结果显示，我们改进的框架比前一代的复原方法更高效。”Note: Simplified Chinese is used in mainland China and Singapore, while Traditional Chinese is used in Taiwan, Hong Kong, and Macau.
</details></li>
</ul>
<hr>
<h2 id="MonoNeRD-NeRF-like-Representations-for-Monocular-3D-Object-Detection"><a href="#MonoNeRD-NeRF-like-Representations-for-Monocular-3D-Object-Detection" class="headerlink" title="MonoNeRD: NeRF-like Representations for Monocular 3D Object Detection"></a>MonoNeRD: NeRF-like Representations for Monocular 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09421">http://arxiv.org/abs/2308.09421</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cskkxjk/mononerd">https://github.com/cskkxjk/mononerd</a></li>
<li>paper_authors: Junkai Xu, Liang Peng, Haoran Cheng, Hao Li, Wei Qian, Ke Li, Wenxiao Wang, Deng Cai</li>
<li>for: 提高单目3D检测器的性能，使其能够更好地检测远离和受阻物体。</li>
<li>methods: 使用Signed Distance Functions (SDF)模型场景，然后将这些表示转化为Neural Radiance Fields (NeRF)，并使用卷积渲染来恢复RGB图像和深度图。</li>
<li>results: 在KITTI-3D benchmark和Waymo Open Dataset上进行了广泛的实验，并得到了效果报告。<details>
<summary>Abstract</summary>
In the field of monocular 3D detection, it is common practice to utilize scene geometric clues to enhance the detector's performance. However, many existing works adopt these clues explicitly such as estimating a depth map and back-projecting it into 3D space. This explicit methodology induces sparsity in 3D representations due to the increased dimensionality from 2D to 3D, and leads to substantial information loss, especially for distant and occluded objects. To alleviate this issue, we propose MonoNeRD, a novel detection framework that can infer dense 3D geometry and occupancy. Specifically, we model scenes with Signed Distance Functions (SDF), facilitating the production of dense 3D representations. We treat these representations as Neural Radiance Fields (NeRF) and then employ volume rendering to recover RGB images and depth maps. To the best of our knowledge, this work is the first to introduce volume rendering for M3D, and demonstrates the potential of implicit reconstruction for image-based 3D perception. Extensive experiments conducted on the KITTI-3D benchmark and Waymo Open Dataset demonstrate the effectiveness of MonoNeRD. Codes are available at https://github.com/cskkxjk/MonoNeRD.
</details>
<details>
<summary>摘要</summary>
在单目3D探测领域，广泛采用场景几何准确来提高探测器的性能。然而，许多现有工作直接使用这些准确，如计算深度图并将其投影到3D空间中。这种直接方法会导致3D表示的稀疏性，特别是对于远距离和遮挡的对象。为了解决这个问题，我们提出了MonoNeRD检测框架，可以对场景进行精度的3D几何和占用率的推测。具体来说，我们使用signed distance functions（SDF）来建模场景，并将这些表示转换为神经辐射场（NeRF）。然后，我们使用卷积渲染来恢复RGB图像和深度图。我们知道，这是第一个在M3D中应用卷积渲染的工作，并证明了隐式重建的潜在优势。我们在KITTI-3D标准测试集和Waymo开放数据集进行了广泛的实验，并证明了MonoNeRD的有效性。代码可以在https://github.com/cskkxjk/MonoNeRD中找到。
</details></li>
</ul>
<hr>
<h2 id="Metadata-Improves-Segmentation-Through-Multitasking-Elicitation"><a href="#Metadata-Improves-Segmentation-Through-Multitasking-Elicitation" class="headerlink" title="Metadata Improves Segmentation Through Multitasking Elicitation"></a>Metadata Improves Segmentation Through Multitasking Elicitation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09411">http://arxiv.org/abs/2308.09411</a></li>
<li>repo_url: None</li>
<li>paper_authors: Iaroslav Plutenko, Mikhail Papkov, Kaupo Palo, Leopold Parts, Dmytro Fishman</li>
<li>for: 这个论文主要是为了提高深度学习方法中的 semantic segmentation 性能。</li>
<li>methods: 这个论文使用了通道调制机制，将metadata作为 convolutional network 的输入，以提高 segmentation 结果。</li>
<li>results: 论文表明，通过使用metadata，可以提高 segmentation 结果，而且这种方法具有低成本和可以与现有模型结合使用的优点。<details>
<summary>Abstract</summary>
Metainformation is a common companion to biomedical images. However, this potentially powerful additional source of signal from image acquisition has had limited use in deep learning methods, for semantic segmentation in particular. Here, we incorporate metadata by employing a channel modulation mechanism in convolutional networks and study its effect on semantic segmentation tasks. We demonstrate that metadata as additional input to a convolutional network can improve segmentation results while being inexpensive in implementation as a nimble add-on to popular models. We hypothesize that this benefit of metadata can be attributed to facilitating multitask switching. This aspect of metadata-driven systems is explored and discussed in detail.
</details>
<details>
<summary>摘要</summary>
这里的metadata是对生物医学影像的常见伴侣。然而，这个潜在强大的额外讯号仍然受到深度学习方法中的有限使用，尤其是在 semantic segmentation 方面。在这里，我们通过将metadata作为构成元件加入卷积网络中，研究 metadata 在 semantic segmentation 任务中的影响。我们证明了 metadata 作为卷积网络的额外输入，可以提高分类结果，而且实现起来相对便宜。我们推测这个metadata的好处可以归因于促进多任务转换。这个metadata-驱动的系统的内部运作和讨论在详细的文章中进行了详细的探讨。
</details></li>
</ul>
<hr>
<h2 id="Generalizable-Decision-Boundaries-Dualistic-Meta-Learning-for-Open-Set-Domain-Generalization"><a href="#Generalizable-Decision-Boundaries-Dualistic-Meta-Learning-for-Open-Set-Domain-Generalization" class="headerlink" title="Generalizable Decision Boundaries: Dualistic Meta-Learning for Open Set Domain Generalization"></a>Generalizable Decision Boundaries: Dualistic Meta-Learning for Open Set Domain Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09391">http://arxiv.org/abs/2308.09391</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zzwdx/medic">https://github.com/zzwdx/medic</a></li>
<li>paper_authors: Xiran Wang, Jian Zhang, Lei Qi, Yinghuan Shi</li>
<li>for: 本研究旨在解决频繁出现在目标领域中的领域转换问题，特别是当源领域和目标领域有不同的类型时。</li>
<li>methods: 本研究使用多个一对一分类器来定义决策边界，并将外围样本拒绝为未知样本。然而，在许多情况下，正样本和负样本的类别数量不均衡，导致决策边界偏向正样本，从而导致已知样本在目标领域中的误分类。本研究提出了一种基于元学习的框架，即双重MEta-learning with joint DomaIn-Class matching（MEDIC），它同时考虑了多个领域和类别的梯度匹配，以找到一个总体可靠的、Balanced的决策边界。</li>
<li>results: 实验结果表明，MEDIC不仅在开集enario下超过了先前的方法，同时也保持了相对较好的闭集泛化能力。 Code可以在<a target="_blank" rel="noopener" href="https://github.com/zzwdx/MEDIC%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/zzwdx/MEDIC中找到。</a><details>
<summary>Abstract</summary>
Domain generalization (DG) is proposed to deal with the issue of domain shift, which occurs when statistical differences exist between source and target domains. However, most current methods do not account for a common realistic scenario where the source and target domains have different classes. To overcome this deficiency, open set domain generalization (OSDG) then emerges as a more practical setting to recognize unseen classes in unseen domains. An intuitive approach is to use multiple one-vs-all classifiers to define decision boundaries for each class and reject the outliers as unknown. However, the significant class imbalance between positive and negative samples often causes the boundaries biased towards positive ones, resulting in misclassification for known samples in the unseen target domain. In this paper, we propose a novel meta-learning-based framework called dualistic MEta-learning with joint DomaIn-Class matching (MEDIC), which considers gradient matching towards inter-domain and inter-class splits simultaneously to find a generalizable boundary balanced for all tasks. Experimental results demonstrate that MEDIC not only outperforms previous methods in open set scenarios, but also maintains competitive close set generalization ability at the same time. Our code is available at https://github.com/zzwdx/MEDIC.
</details>
<details>
<summary>摘要</summary>
域外泛化（DG）是为了解决域shift问题而提出的，域shift问题是指源领域和目标领域存在统计上的差异。然而，现有的大多数方法不能考虑到预测领域和目标领域中的类不同的常见情况。为了解决这个不足，开放集领域泛化（OSDG）作为更实际的设定，用于识别未经见过的类。一种直观的方法是使用多个一对一分类器来定义决策边界，并将异常值作为未知样本拒绝。然而，难以平衡的类划分常导致决策边界偏向正样本，从而导致在未经见过的目标领域中误分类已知样本。在这篇论文中，我们提出了一种基于元学习的框架，即双向MEta-learning with joint DomaIn-Class matching（MEDIC）。该框架同时考虑到域间和类间的梯度匹配，以找到一个泛化性能良好的、对所有任务均匀的决策边界。实验结果表明，MEDIC不仅在开放集领域中表现出优于前方法，还能够保持与闭set泛化能力相当的竞争力。我们的代码可以在https://github.com/zzwdx/MEDIC上找到。
</details></li>
</ul>
<hr>
<h2 id="Diffusion-Models-for-Image-Restoration-and-Enhancement-–-A-Comprehensive-Survey"><a href="#Diffusion-Models-for-Image-Restoration-and-Enhancement-–-A-Comprehensive-Survey" class="headerlink" title="Diffusion Models for Image Restoration and Enhancement – A Comprehensive Survey"></a>Diffusion Models for Image Restoration and Enhancement – A Comprehensive Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09388">http://arxiv.org/abs/2308.09388</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lixinustc/awesome-diffusion-model-for-image-processing">https://github.com/lixinustc/awesome-diffusion-model-for-image-processing</a></li>
<li>paper_authors: Xin Li, Yulin Ren, Xin Jin, Cuiling Lan, Xingrui Wang, Wenjun Zeng, Xinchao Wang, Zhibo Chen</li>
<li>for: 本文旨在为图像修复（IR）领域提供一份总结，尤其是在使用扩散模型（Diffusion Model）进行图像修复方面。</li>
<li>methods: 本文总结了最新的扩散模型基于的图像修复方法，包括学习框架、条件策略、模型设计等方面，并对现有的方法进行评价。</li>
<li>results: 本文对现有的扩散模型基于的图像修复方法进行了全面的总结，并提出了五个可能的未来研究方向，包括样本效率、模型压缩、质量评价等方面。<details>
<summary>Abstract</summary>
Image restoration (IR) has been an indispensable and challenging task in the low-level vision field, which strives to improve the subjective quality of images distorted by various forms of degradation. Recently, the diffusion model has achieved significant advancements in the visual generation of AIGC, thereby raising an intuitive question, "whether diffusion model can boost image restoration". To answer this, some pioneering studies attempt to integrate diffusion models into the image restoration task, resulting in superior performances than previous GAN-based methods. Despite that, a comprehensive and enlightening survey on diffusion model-based image restoration remains scarce. In this paper, we are the first to present a comprehensive review of recent diffusion model-based methods on image restoration, encompassing the learning paradigm, conditional strategy, framework design, modeling strategy, and evaluation. Concretely, we first introduce the background of the diffusion model briefly and then present two prevalent workflows that exploit diffusion models in image restoration. Subsequently, we classify and emphasize the innovative designs using diffusion models for both IR and blind/real-world IR, intending to inspire future development. To evaluate existing methods thoroughly, we summarize the commonly-used dataset, implementation details, and evaluation metrics. Additionally, we present the objective comparison for open-sourced methods across three tasks, including image super-resolution, deblurring, and inpainting. Ultimately, informed by the limitations in existing works, we propose five potential and challenging directions for the future research of diffusion model-based IR, including sampling efficiency, model compression, distortion simulation and estimation, distortion invariant learning, and framework design.
</details>
<details>
<summary>摘要</summary>
Image restoration（IR）是低级视觉领域中不可或缺的和挑战性的任务，旨在提高受到不同类型的降低的图像主观质量。最近，扩散模型在视觉生成AIGC中取得了显著进步，因此提出了一个直观的问题：“扩散模型能否提高图像restoration”？为了回答这个问题，一些创新的研究尝试将扩散模型与图像restoration任务结合，从而实现更高的性能。然而，一份全面和激进的扩散模型基于图像restoration的评价还缺乏。在这篇论文中，我们是首次提供了一份全面的扩散模型基于图像restoration的评价，涵盖学习 парадиг，条件策略，框架设计，模型化策略和评价。具体来说，我们首先介绍了扩散模型的背景，然后介绍了在图像restoration中使用扩散模型的两种常见方法。接着，我们将扩散模型在图像restoration和匿名/实际图像restoration中的创新设计进行分类和强调，以便激励未来的发展。为了评价现有方法的全面性，我们列举了一些常用的数据集、实现细节和评价度量。此外，我们还对开源方法进行了对比评价，包括图像超解、压缩和填充等三个任务。最后，根据现有方法的局限性，我们提出了五个未来研究的挑战和可能性，包括样本效率、模型压缩、降低度量和不变学习。
</details></li>
</ul>
<hr>
<h2 id="DReg-NeRF-Deep-Registration-for-Neural-Radiance-Fields"><a href="#DReg-NeRF-Deep-Registration-for-Neural-Radiance-Fields" class="headerlink" title="DReg-NeRF: Deep Registration for Neural Radiance Fields"></a>DReg-NeRF: Deep Registration for Neural Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09386">http://arxiv.org/abs/2308.09386</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aibluefisher/dreg-nerf">https://github.com/aibluefisher/dreg-nerf</a></li>
<li>paper_authors: Yu Chen, Gim Hee Lee</li>
<li>for: 本研究的目的是解决基于物体中心的场景下多个NeRF的注册问题，而不需要人工标注关键点。</li>
<li>methods: 我们提出了一种基于transformer架构的DReg-NeRF方法，首先提取NeRF中的占据网格特征，然后使用自我关注和相关关注层来学习对应NeRF块之间的关系。与现有的点云注册方法不同，我们的方法不需要任何人工标注，并且使用表面场所supervise协调对应点云。</li>
<li>results: 我们在测试集上评估了我们的方法，与现有的点云注册方法相比，我们的方法在mean $\text{RPE}$和mean $\text{RTE}$上都有大幅度的提升，分别为9.67度和0.038。<details>
<summary>Abstract</summary>
Although Neural Radiance Fields (NeRF) is popular in the computer vision community recently, registering multiple NeRFs has yet to gain much attention. Unlike the existing work, NeRF2NeRF, which is based on traditional optimization methods and needs human annotated keypoints, we propose DReg-NeRF to solve the NeRF registration problem on object-centric scenes without human intervention. After training NeRF models, our DReg-NeRF first extracts features from the occupancy grid in NeRF. Subsequently, our DReg-NeRF utilizes a transformer architecture with self-attention and cross-attention layers to learn the relations between pairwise NeRF blocks. In contrast to state-of-the-art (SOTA) point cloud registration methods, the decoupled correspondences are supervised by surface fields without any ground truth overlapping labels. We construct a novel view synthesis dataset with 1,700+ 3D objects obtained from Objaverse to train our network. When evaluated on the test set, our proposed method beats the SOTA point cloud registration methods by a large margin, with a mean $\text{RPE}=9.67^{\circ}$ and a mean $\text{RTE}=0.038$.   Our code is available at https://github.com/AIBluefisher/DReg-NeRF.
</details>
<details>
<summary>摘要</summary>
尽管神经辐射场（NeRF）在计算机视觉领域最近受欢迎，但是多个NeRF的注册问题还尚未得到了充分的关注。与现有的工作不同，我们的NeRF2NeRF基于传统优化方法，需要人工标注关键点，我们提出了DReg-NeRF来解决对象中心场景下NeRF注册问题。经过训练NeRF模型后，我们的DReg-NeRF首先从NeRF中提取特征。然后，我们的DReg-NeRF利用了转换器架构，包括自我注意和跨注意层，以学习NeRF块对之间的关系。与现状最佳点云注册方法相比，我们的解耦对应点不需要任何真实重合标签。我们在Objaverse上构建了一个新的视图合成数据集，并在其上训练我们的网络。在测试集上评估时，我们的提议方法与最佳点云注册方法相比， Mean RPE=9.67度和Mean RTE=0.038。 参考代码可以在https://github.com/AIBluefisher/DReg-NeRF中找到。
</details></li>
</ul>
<hr>
<h2 id="Label-Free-Event-based-Object-Recognition-via-Joint-Learning-with-Image-Reconstruction-from-Events"><a href="#Label-Free-Event-based-Object-Recognition-via-Joint-Learning-with-Image-Reconstruction-from-Events" class="headerlink" title="Label-Free Event-based Object Recognition via Joint Learning with Image Reconstruction from Events"></a>Label-Free Event-based Object Recognition via Joint Learning with Image Reconstruction from Events</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09383">http://arxiv.org/abs/2308.09383</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hoonhee Cho, Hyeonseong Kim, Yujeong Chae, Kuk-Jin Yoon</li>
<li>for: 本研究旨在实现没有类别标签和对应图像的事件基于对象识别。</li>
<li>methods: 我们提出了一种结合对象识别和图像重建的共同形式，首先将事件重建为图像，然后通过对比语言-图像预训练（CLIP）进行对象识别，并使用类别导向吸引损失和类别无关排斥损失将文本特征与重建图像的视觉特征相吸引。我们还提出了一种可靠的数据采样策略和本地-全局重建一致性来促进两个任务的共同学习。</li>
<li>results: 我们的方法在预测和重建质量方面具有明显的优势，并且可以进行零参数对象识别。我们的项目代码可以在 \url{<a target="_blank" rel="noopener" href="https://github.com/Chohoonhee/Ev-LaFOR%7D">https://github.com/Chohoonhee/Ev-LaFOR}</a> 上下载。<details>
<summary>Abstract</summary>
Recognizing objects from sparse and noisy events becomes extremely difficult when paired images and category labels do not exist. In this paper, we study label-free event-based object recognition where category labels and paired images are not available. To this end, we propose a joint formulation of object recognition and image reconstruction in a complementary manner. Our method first reconstructs images from events and performs object recognition through Contrastive Language-Image Pre-training (CLIP), enabling better recognition through a rich context of images. Since the category information is essential in reconstructing images, we propose category-guided attraction loss and category-agnostic repulsion loss to bridge the textual features of predicted categories and the visual features of reconstructed images using CLIP. Moreover, we introduce a reliable data sampling strategy and local-global reconstruction consistency to boost joint learning of two tasks. To enhance the accuracy of prediction and quality of reconstruction, we also propose a prototype-based approach using unpaired images. Extensive experiments demonstrate the superiority of our method and its extensibility for zero-shot object recognition. Our project code is available at \url{https://github.com/Chohoonhee/Ev-LaFOR}.
</details>
<details>
<summary>摘要</summary>
Recognizing objects from sparse and noisy events becomes extremely difficult when paired images and category labels do not exist. In this paper, we study label-free event-based object recognition where category labels and paired images are not available. To this end, we propose a joint formulation of object recognition and image reconstruction in a complementary manner. Our method first reconstructs images from events and performs object recognition through Contrastive Language-Image Pre-training (CLIP), enabling better recognition through a rich context of images. Since the category information is essential in reconstructing images, we propose category-guided attraction loss and category-agnostic repulsion loss to bridge the textual features of predicted categories and the visual features of reconstructed images using CLIP. Moreover, we introduce a reliable data sampling strategy and local-global reconstruction consistency to boost joint learning of two tasks. To enhance the accuracy of prediction and quality of reconstruction, we also propose a prototype-based approach using unpaired images. Extensive experiments demonstrate the superiority of our method and its extensibility for zero-shot object recognition. Our project code is available at \url{https://github.com/Chohoonhee/Ev-LaFOR}.Here's the translation in Traditional Chinese:当事件为 sparse 和噪音时，对象识别成为极其困难，当 paired images 和 category labels 不存在时。在这篇文章中，我们研究了无标签事件基于的对象识别，其中 category labels 和 paired images 都不可用。为了解决这个问题，我们提出了一个组合的形式，即对象识别和图像重建的联合运算。我们的方法首先从事件中重建图像，然后通过 Contrastive Language-Image Pre-training (CLIP) 进行对象识别，这样可以通过充分的图像背景来提高识别的精度。由于类别信息是重建图像中的重要元素，我们提出了类别导引吸引损失和类别无关排斥损失，将文本特征与重建图像中的视觉特征相连接。此外，我们还引入了可靠的抽样策略和本地-全球重建一致性，以提高两个任务之间的联合学习。为了提高预测精度和重建质量，我们还提出了一个原型基于的方法，使用无标签图像。实验结果显示了我们的方法的超越性和可扩展性。我们的项目代码可以在 \url{https://github.com/Chohoonhee/Ev-LaFOR} 上获取。
</details></li>
</ul>
<hr>
<h2 id="Image-Processing-and-Machine-Learning-for-Hyperspectral-Unmixing-An-Overview-and-the-HySUPP-Python-Package"><a href="#Image-Processing-and-Machine-Learning-for-Hyperspectral-Unmixing-An-Overview-and-the-HySUPP-Python-Package" class="headerlink" title="Image Processing and Machine Learning for Hyperspectral Unmixing: An Overview and the HySUPP Python Package"></a>Image Processing and Machine Learning for Hyperspectral Unmixing: An Overview and the HySUPP Python Package</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09375">http://arxiv.org/abs/2308.09375</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/behnoodrasti/hysupp">https://github.com/behnoodrasti/hysupp</a></li>
<li>paper_authors: Behnood Rasti, Alexandre Zouaoui, Julien Mairal, Jocelyn Chanussot</li>
<li>for: 本文提供了一个概述先进和传统混合分析方法的评 comparison，以及三种不同类型的 linear unmixing 方法的性能对比。</li>
<li>methods: 本文使用了先进的 Image processing 和机器学习技术，包括超vised、semi-supervised 和 blind  linear unmixing 方法。</li>
<li>results: 实验结果表明，不同类型的 unmixing 方法在不同的混合分析场景下有不同的优势，以及一个开源的 Python 基于包可以在 <a target="_blank" rel="noopener" href="https://github.com/BehnoodRasti/HySUPP">https://github.com/BehnoodRasti/HySUPP</a> 上下载。<details>
<summary>Abstract</summary>
Spectral pixels are often a mixture of the pure spectra of the materials, called endmembers, due to the low spatial resolution of hyperspectral sensors, double scattering, and intimate mixtures of materials in the scenes. Unmixing estimates the fractional abundances of the endmembers within the pixel. Depending on the prior knowledge of endmembers, linear unmixing can be divided into three main groups: supervised, semi-supervised, and unsupervised (blind) linear unmixing. Advances in Image processing and machine learning substantially affected unmixing. This paper provides an overview of advanced and conventional unmixing approaches. Additionally, we draw a critical comparison between advanced and conventional techniques from the three categories. We compare the performance of the unmixing techniques on three simulated and two real datasets. The experimental results reveal the advantages of different unmixing categories for different unmixing scenarios. Moreover, we provide an open-source Python-based package available at https://github.com/BehnoodRasti/HySUPP to reproduce the results.
</details>
<details>
<summary>摘要</summary>
干扰像素通常是Materials的纯谱混合物，由于干扰数据探针的低空间分辨率、双折射和场景中Materials的密切混合，导致干扰像素的混合。拆分分析计算机程序可以Estimate the fractional abundance of endmembers within the pixel.根据对Endmember的知识，线性拆分可以分为三个主要类别：有监督、半监督和无监督（盲目）线性拆分。图像处理和机器学习技术的进步对拆分具有重要影响。本文提供了高级和传统拆分方法的总览，并对这些方法进行了 kritische 比较。我们在三个 simulated 和两个实际数据集上测试了不同拆分方法的性能。实验结果表明不同拆分类型在不同拆分场景中具有优势。此外，我们还提供了一个开源的 Python 基于 package，可以在 https://github.com/BehnoodRasti/HySUPP 上下载。
</details></li>
</ul>
<hr>
<h2 id="Single-Frame-Semantic-Segmentation-Using-Multi-Modal-Spherical-Images"><a href="#Single-Frame-Semantic-Segmentation-Using-Multi-Modal-Spherical-Images" class="headerlink" title="Single Frame Semantic Segmentation Using Multi-Modal Spherical Images"></a>Single Frame Semantic Segmentation Using Multi-Modal Spherical Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09369">http://arxiv.org/abs/2308.09369</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sguttikon/SFSS-MMSI">https://github.com/sguttikon/SFSS-MMSI</a></li>
<li>paper_authors: Suresh Guttikonda, Jason Rambach</li>
<li>for: 这篇论文旨在探讨多modal的拼接和扩展对全景场景理解的可能性。</li>
<li>methods: 该论文提出了一种基于transformer的跨Modal融合架构，以AddressExtreme object deformation和全景图像扭曲。</li>
<li>results: 该论文在三个indoor全景视图数据集上进行了广泛的测试，并达到了当前领域最佳的mIoU性能：60.60%在Stanford2D3DS（RGB-HHA）、71.97%在Structured3D（RGB-D-N）以及35.92%在Matterport3D（RGB-D）。<details>
<summary>Abstract</summary>
In recent years, the research community has shown a lot of interest to panoramic images that offer a 360-degree directional perspective. Multiple data modalities can be fed, and complimentary characteristics can be utilized for more robust and rich scene interpretation based on semantic segmentation, to fully realize the potential. Existing research, however, mostly concentrated on pinhole RGB-X semantic segmentation. In this study, we propose a transformer-based cross-modal fusion architecture to bridge the gap between multi-modal fusion and omnidirectional scene perception. We employ distortion-aware modules to address extreme object deformations and panorama distortions that result from equirectangular representation. Additionally, we conduct cross-modal interactions for feature rectification and information exchange before merging the features in order to communicate long-range contexts for bi-modal and tri-modal feature streams. In thorough tests using combinations of four different modality types in three indoor panoramic-view datasets, our technique achieved state-of-the-art mIoU performance: 60.60% on Stanford2D3DS (RGB-HHA), 71.97% Structured3D (RGB-D-N), and 35.92% Matterport3D (RGB-D). We plan to release all codes and trained models soon.
</details>
<details>
<summary>摘要</summary>
近年来，研究社区对全景图像（panoramic image）表现出了很大的兴趣，这些图像可以提供360度方向的视角。多种数据模式可以被 fed，并可以利用不同特征进行更加robust和 ricn scene解释，以实现潜在的潜力。然而，现有的研究主要集中在pinhole RGB-X semantic segmentation。在本研究中，我们提议一种基于 transformer 混合模型来bridging the gap between multi-modal fusion和全景场景理解。我们使用扭曲感知模块来处理极端对象扭曲和全景图像扭曲，并进行交叉模式交互以便Feature rectification和信息交换，以便在bi-modal和tri-modal流水线中传递长距离上下文。在使用四种不同模式类型的三个indoor panoramic-view数据集进行了经验详细测试后，我们的技术实现了状态的最佳mIoU性能：60.60%在Stanford2D3DS（RGB-HHA）、71.97%在Structured3D（RGB-D-N）以及35.92%在Matterport3D（RGB-D）。我们计划在不久将所有代码和训练模型公开。
</details></li>
</ul>
<hr>
<h2 id="Overlap-Bias-Matching-is-Necessary-for-Point-Cloud-Registration"><a href="#Overlap-Bias-Matching-is-Necessary-for-Point-Cloud-Registration" class="headerlink" title="Overlap Bias Matching is Necessary for Point Cloud Registration"></a>Overlap Bias Matching is Necessary for Point Cloud Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09364">http://arxiv.org/abs/2308.09364</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pengcheng Shi, Jie Zhang, Haozhe Cheng, Junyang Wang, Yiyang Zhou, Chenlin Zhao, Jihua Zhu</li>
<li>for: 本研究旨在提出一种基于无监督学习的点云注册方法，以解决实际中点云注册问题中的受限 overlap 问题。</li>
<li>methods: 本方法基于一个名为 Overlap Bias Matching Network (OBMNet)，它包括两个Integral component： overlap sampling module和 bias prediction module。这两个组件可以捕捉点云重叠区域的分布，并预测点云共同结构的偏置系数。然后，我们将OBMM与邻居地图匹配模块结合，以精确地挖掘对应关系。</li>
<li>results: 实验结果表明，我们的方法在各种数据集上达到了与当前注册方法相比较显著的改进。<details>
<summary>Abstract</summary>
Point cloud registration is a fundamental problem in many domains. Practically, the overlap between point clouds to be registered may be relatively small. Most unsupervised methods lack effective initial evaluation of overlap, leading to suboptimal registration accuracy. To address this issue, we propose an unsupervised network Overlap Bias Matching Network (OBMNet) for partial point cloud registration. Specifically, we propose a plug-and-play Overlap Bias Matching Module (OBMM) comprising two integral components, overlap sampling module and bias prediction module. These two components are utilized to capture the distribution of overlapping regions and predict bias coefficients of point cloud common structures, respectively. Then, we integrate OBMM with the neighbor map matching module to robustly identify correspondences by precisely merging matching scores of points within the neighborhood, which addresses the ambiguities in single-point features. OBMNet can maintain efficacy even in pair-wise registration scenarios with low overlap ratios. Experimental results on extensive datasets demonstrate that our approach's performance achieves a significant improvement compared to the state-of-the-art registration approach.
</details>
<details>
<summary>摘要</summary>
点云注册是许多领域的基本问题。实际上，注册点云的重叠部分可能很小。大多数无监督方法缺乏有效的初始评估重叠，导致注册精度下降。为解决这个问题，我们提议一种无监督网络Overlap Bias Matching Network（OBMNet），用于部分点云注册。具体来说，我们提出了一个插件式的Overlap Bias Matching Module（OBMM），包括两个基本组成部分：重叠采样模块和偏好预测模块。这两个组成部分用于捕捉重叠区域的分布和预测点云共同结构的偏好系数，分别。然后，我们将OBMM与邻居地图匹配模块集成，以robustly确定对应关系，解决单点特征之间的混淆。OBMNet可以在对点云注册方式进行对比时保持效率。实验结果表明，我们的方法在评估中达到了与当前注册方法相比较显著的提升。
</details></li>
</ul>
<hr>
<h2 id="Open-vocabulary-Video-Question-Answering-A-New-Benchmark-for-Evaluating-the-Generalizability-of-Video-Question-Answering-Models"><a href="#Open-vocabulary-Video-Question-Answering-A-New-Benchmark-for-Evaluating-the-Generalizability-of-Video-Question-Answering-Models" class="headerlink" title="Open-vocabulary Video Question Answering: A New Benchmark for Evaluating the Generalizability of Video Question Answering Models"></a>Open-vocabulary Video Question Answering: A New Benchmark for Evaluating the Generalizability of Video Question Answering Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09363">http://arxiv.org/abs/2308.09363</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mlvlab/ovqa">https://github.com/mlvlab/ovqa</a></li>
<li>paper_authors: Dohwan Ko, Ji Soo Lee, Miso Choi, Jaewon Chu, Jihwan Park, Hyunwoo J. Kim<br>for: 这个论文的目的是提出一个新的benchmark，以评估视频问答模型的泛化能力。methods: 这个论文使用了一种新的GNN-based soft verbalizer来提高模型对不常见答案的预测能力，同时也对现有的开放端VIDEOQA模型进行了修改，以便进一步考虑罕见和未看过的答案。results: 该论文的实验结果表明，使用GNN-based soft verbalizer可以进一步提高模型的泛化能力，特别是对罕见和未看过的答案。此外，修改了现有的开放端VIDEOQA模型也可以提高其表现。<details>
<summary>Abstract</summary>
Video Question Answering (VideoQA) is a challenging task that entails complex multi-modal reasoning. In contrast to multiple-choice VideoQA which aims to predict the answer given several options, the goal of open-ended VideoQA is to answer questions without restricting candidate answers. However, the majority of previous VideoQA models formulate open-ended VideoQA as a classification task to classify the video-question pairs into a fixed answer set, i.e., closed-vocabulary, which contains only frequent answers (e.g., top-1000 answers). This leads the model to be biased toward only frequent answers and fail to generalize on out-of-vocabulary answers. We hence propose a new benchmark, Open-vocabulary Video Question Answering (OVQA), to measure the generalizability of VideoQA models by considering rare and unseen answers. In addition, in order to improve the model's generalization power, we introduce a novel GNN-based soft verbalizer that enhances the prediction on rare and unseen answers by aggregating the information from their similar words. For evaluation, we introduce new baselines by modifying the existing (closed-vocabulary) open-ended VideoQA models and improve their performances by further taking into account rare and unseen answers. Our ablation studies and qualitative analyses demonstrate that our GNN-based soft verbalizer further improves the model performance, especially on rare and unseen answers. We hope that our benchmark OVQA can serve as a guide for evaluating the generalizability of VideoQA models and inspire future research. Code is available at https://github.com/mlvlab/OVQA.
</details>
<details>
<summary>摘要</summary>
视频问答（VideoQA）是一项复杂的多模态逻辑任务。相比多选视频问答，开放式视频问答的目标是Answer questions without restricting candidate answers。然而，大多数前一代视频问答模型将开放式视频问答视为一种分类任务，即将视频-问题对 clasified into a fixed answer set，即关闭词汇，这会导致模型偏向常见答案，而忽略非常见答案。我们因此提出了一个新的标准测试集，开放词汇视频问答（OVQA），以衡量视频问答模型的通用性。此外，为提高模型的通用性能力，我们引入了一种新的图神经网络（GNN）基于的软化词语izer，该算法可以通过聚合相似词语的信息来提高对不常见答案的预测。我们的基线和精度分析表明，我们的GNN基于的软化词语izer可以进一步提高模型的性能，特别是对于不常见答案。我们希望，我们的标准测试集OVQA可以为评估视频问答模型的通用性提供指南，并且能启发未来的研究。代码可以在https://github.com/mlvlab/OVQA 中找到。
</details></li>
</ul>
<hr>
<h2 id="Multi-scale-Target-Aware-Framework-for-Constrained-Image-Splicing-Detection-and-Localization"><a href="#Multi-scale-Target-Aware-Framework-for-Constrained-Image-Splicing-Detection-and-Localization" class="headerlink" title="Multi-scale Target-Aware Framework for Constrained Image Splicing Detection and Localization"></a>Multi-scale Target-Aware Framework for Constrained Image Splicing Detection and Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09357">http://arxiv.org/abs/2308.09357</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxuan Tan, Yuanman Li, Limin Zeng, Jiaxiong Ye, Wei wang, Xia Li</li>
<li>for: 批处 multimedia 图像中的剪辑检测和定位问题，即检测两个受控图像之间的剪辑操作并定位剪辑区域在两个图像上。</li>
<li>methods: 我们提出了一种多尺度目标意识框架，将特征提取和相关比较作为一个独立的管道进行联合处理，并设计了一种目标意识注意机制，使模型可以同时学习特征和相关比较。</li>
<li>results: 我们的方法在多个标准数据集上进行测试，与现有方法相比，具有更高的检测精度和更好的灵活性，并且可以有效地处理缩放变换。<details>
<summary>Abstract</summary>
Constrained image splicing detection and localization (CISDL) is a fundamental task of multimedia forensics, which detects splicing operation between two suspected images and localizes the spliced region on both images. Recent works regard it as a deep matching problem and have made significant progress. However, existing frameworks typically perform feature extraction and correlation matching as separate processes, which may hinder the model's ability to learn discriminative features for matching and can be susceptible to interference from ambiguous background pixels. In this work, we propose a multi-scale target-aware framework to couple feature extraction and correlation matching in a unified pipeline. In contrast to previous methods, we design a target-aware attention mechanism that jointly learns features and performs correlation matching between the probe and donor images. Our approach can effectively promote the collaborative learning of related patches, and perform mutual promotion of feature learning and correlation matching. Additionally, in order to handle scale transformations, we introduce a multi-scale projection method, which can be readily integrated into our target-aware framework that enables the attention process to be conducted between tokens containing information of varying scales. Our experiments demonstrate that our model, which uses a unified pipeline, outperforms state-of-the-art methods on several benchmark datasets and is robust against scale transformations.
</details>
<details>
<summary>摘要</summary>
《受限制的图像拼接检测和地点Localization（CISDL）是 multimedia 的基本任务，检测两个可疑图像之间的拼接操作并将拼接区域分别显示在两个图像上。现有的方法通常将特征提取和相关匹配视为两个独立的过程，这可能会阻碍模型学习特征特异的匹配特征，同时也可能受到杂质背景像素的干扰。在这种情况下，我们提出了一种多尺度目标意识框架，将特征提取和相关匹配作为一个统一的管道进行处理。与先前的方法不同，我们设计了一种目标意识的注意机制，同时学习特征和相关匹配。我们的方法可以有效地促进相关块之间的协同学习，并且可以同时促进特征学习和相关匹配的协同发展。此外，为了处理缩放变换，我们引入了多尺度投影方法，可以轻松地 интеGRATE到我们的目标意识框架中，使注意过程可以在不同的尺度上进行。我们的实验表明，使用统一管道的我们模型，在多个标准数据集上表现出色，并且对缩放变换具有鲁棒性。》
</details></li>
</ul>
<hr>
<h2 id="Boosting-Few-shot-Action-Recognition-with-Graph-guided-Hybrid-Matching"><a href="#Boosting-Few-shot-Action-Recognition-with-Graph-guided-Hybrid-Matching" class="headerlink" title="Boosting Few-shot Action Recognition with Graph-guided Hybrid Matching"></a>Boosting Few-shot Action Recognition with Graph-guided Hybrid Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09346">http://arxiv.org/abs/2308.09346</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiazheng-xing/gghm">https://github.com/jiazheng-xing/gghm</a></li>
<li>paper_authors: Jiazheng Xing, Mengmeng Wang, Yudi Ruan, Bofan Chen, Yaowei Guo, Boyu Mu, Guang Dai, Jingdong Wang, Yong Liu</li>
<li>for: 本文提出了一种新的几何匹配框架（GgHM），用于解决几何捕捉异常分类问题。</li>
<li>methods: 本文使用图 neural network 引导构建任务特有的特征，并对这些特征进行内部和间部特征相关性优化。然后，本文提出了一种混合匹配策略，将帧级匹配和元组级匹配相结合，以便将视频匹配到多种样式。最后，本文还提出了一种可学习的细致时间模型，以增强视频特征的时间表示，为匹配过程建立更加坚实的基础。</li>
<li>results: GgHM 在多个几何捕捉数据集上实现了一致性好于其他挑战性基准点，证明了我们的方法的有效性。<details>
<summary>Abstract</summary>
Class prototype construction and matching are core aspects of few-shot action recognition. Previous methods mainly focus on designing spatiotemporal relation modeling modules or complex temporal alignment algorithms. Despite the promising results, they ignored the value of class prototype construction and matching, leading to unsatisfactory performance in recognizing similar categories in every task. In this paper, we propose GgHM, a new framework with Graph-guided Hybrid Matching. Concretely, we learn task-oriented features by the guidance of a graph neural network during class prototype construction, optimizing the intra- and inter-class feature correlation explicitly. Next, we design a hybrid matching strategy, combining frame-level and tuple-level matching to classify videos with multivariate styles. We additionally propose a learnable dense temporal modeling module to enhance the video feature temporal representation to build a more solid foundation for the matching process. GgHM shows consistent improvements over other challenging baselines on several few-shot datasets, demonstrating the effectiveness of our method. The code will be publicly available at https://github.com/jiazheng-xing/GgHM.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>>前方法主要集中在设计空间时间关系模型或复杂的时间对Alignment算法。尽管其 promise 的结果，但它们忽略了类prototype构建和匹配的价值，导致每个任务中类似类型的识别性不够。在这篇论文中，我们提出了GgHM，一个新的框架，具有图导向混合匹配。具体来说，我们在类prototype构建过程中，通过图 neural network 的引导，显式地优化内类和外类特征相关性。接着，我们设计了混合匹配策略，将帧级匹配和元组级匹配结合起来，以便在多样化风格下分类视频。此外，我们还提出了一个可学习的紧凑时间模型，以强化视频特征的时间表示，以建立更坚实的匹配基础。GgHM在多个复杂的基准下显示了稳定的改进，证明了我们的方法的有效性。代码将在https://github.com/jiazheng-xing/GgHM上公开。
</details></li>
</ul>
<hr>
<h2 id="Denoising-diffusion-based-MR-to-CT-image-translation-enables-whole-spine-vertebral-segmentation-in-2D-and-3D-without-manual-annotations"><a href="#Denoising-diffusion-based-MR-to-CT-image-translation-enables-whole-spine-vertebral-segmentation-in-2D-and-3D-without-manual-annotations" class="headerlink" title="Denoising diffusion-based MR to CT image translation enables whole spine vertebral segmentation in 2D and 3D without manual annotations"></a>Denoising diffusion-based MR to CT image translation enables whole spine vertebral segmentation in 2D and 3D without manual annotations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09345">http://arxiv.org/abs/2308.09345</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/robert-graf/readable-conditional-denoising-diffusion">https://github.com/robert-graf/readable-conditional-denoising-diffusion</a></li>
<li>paper_authors: Robert Graf, Joachim Schmitt, Sarah Schlaeger, Hendrik Kristian Möller, Vasiliki Sideri-Lampretsa, Anjany Sekuboyina, Sandro Manuel Krieg, Benedikt Wiestler, Bjoern Menze, Daniel Rueckert, Jan Stefan Kirschke<br>for: This paper aims to develop and evaluate methods for translating spinal MR images to CT images, with a focus on accurately delineating posterior spine structures.methods: The study uses a combination of landmark-based registration and image-to-image translation techniques, including paired and unpaired methods such as Pix2Pix, DDIM, and SynDiff. The authors evaluate the performance of these methods using PSNR and Dice scores.results: The study finds that paired methods and SynDiff exhibit similar translation performance and Dice scores on paired data, while DDIM image mode achieves the highest image quality. The 3D translation methods outperform the 2D approach, providing anatomically accurate segmentations with improved Dice scores and avoiding underprediction of small structures like the spinous process.<details>
<summary>Abstract</summary>
Background: Automated segmentation of spinal MR images plays a vital role both scientifically and clinically. However, accurately delineating posterior spine structures presents challenges.   Methods: This retrospective study, approved by the ethical committee, involved translating T1w and T2w MR image series into CT images in a total of n=263 pairs of CT/MR series. Landmark-based registration was performed to align image pairs. We compared 2D paired (Pix2Pix, denoising diffusion implicit models (DDIM) image mode, DDIM noise mode) and unpaired (contrastive unpaired translation, SynDiff) image-to-image translation using "peak signal to noise ratio" (PSNR) as quality measure. A publicly available segmentation network segmented the synthesized CT datasets, and Dice scores were evaluated on in-house test sets and the "MRSpineSeg Challenge" volumes. The 2D findings were extended to 3D Pix2Pix and DDIM.   Results: 2D paired methods and SynDiff exhibited similar translation performance and Dice scores on paired data. DDIM image mode achieved the highest image quality. SynDiff, Pix2Pix, and DDIM image mode demonstrated similar Dice scores (0.77). For craniocaudal axis rotations, at least two landmarks per vertebra were required for registration. The 3D translation outperformed the 2D approach, resulting in improved Dice scores (0.80) and anatomically accurate segmentations in a higher resolution than the original MR image.   Conclusion: Two landmarks per vertebra registration enabled paired image-to-image translation from MR to CT and outperformed all unpaired approaches. The 3D techniques provided anatomically correct segmentations, avoiding underprediction of small structures like the spinous process.
</details>
<details>
<summary>摘要</summary>
Methods: 这是一个回顾性研究，由伦敦病理学会approved的审核委员会批准。该研究将T1w和T2w MR图像系列转换为CT图像系列，共计n=263对CT/MR系列图像对应。使用了landmark-based registration来对图像对对应。我们使用"peak signal to noise ratio"（PSNR）作为质量指标，并对在家测试集和"MRSpineSeg Challenge"的Volume进行评估。使用了一个公共可用的分割网络将synthesized CT数据分割，并评估了Dice分数。Results: 2D对应方法和SynDiff在对应数据上 exhibited similar translation performance和Dice分数。DDIM图像模式实现了最高的图像质量。SynDiff、Pix2Pix和DDIM图像模式在对应数据上都表现了类似的Dice分数（0.77）。对于脊梗磁旋转轴，至少需要两个附加的landmark per vertebra进行 регистраción。3D翻译超过了2D方法，导致了改进的Dice分数（0.80）和精度高于原始MR图像的正确的分割。Conclusion: 使用两个附加的landmark per vertebra进行 registration可以实现对MR图像与CT图像的对应，并且超过了所有的无对应方法。3D技术提供了正确的分割，避免了小结构的下预测，如脊梗处。
</details></li>
</ul>
<hr>
<h2 id="LSCD-A-Large-Scale-Screen-Content-Dataset-for-Video-Compression"><a href="#LSCD-A-Large-Scale-Screen-Content-Dataset-for-Video-Compression" class="headerlink" title="LSCD: A Large-Scale Screen Content Dataset for Video Compression"></a>LSCD: A Large-Scale Screen Content Dataset for Video Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09332">http://arxiv.org/abs/2308.09332</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhao Cheng, Siru Zhang, Yiqiang Yan, Rong Chen, Yun Zhang</li>
<li>for: 提供一个大规模屏幕内容数据集(LSCD)，用于促进屏幕内容视频压缩领域的研究。</li>
<li>methods: 使用人工智能和视频压缩技术，对屏幕内容视频进行学习型压缩。</li>
<li>results: 提供了一个大规模的屏幕内容视频压缩数据集(LSCD)，并对数据集进行分析，以帮助研究人员更好地理解屏幕内容视频的特点，并提高学习型压缩算法的开发。<details>
<summary>Abstract</summary>
Multimedia compression allows us to watch videos, see pictures and hear sounds within a limited bandwidth, which helps the flourish of the internet. During the past decades, multimedia compression has achieved great success using hand-craft features and systems. With the development of artificial intelligence and video compression, there emerges a lot of research work related to using the neural network on the video compression task to get rid of the complicated system. Not only producing the advanced algorithms, but researchers also spread the compression to different content, such as User Generated Content(UGC). With the rapid development of mobile devices, screen content videos become an important part of multimedia data. In contrast, we find community lacks a large-scale dataset for screen content video compression, which impedes the fast development of the corresponding learning-based algorithms. In order to fulfill this blank and accelerate the research of this special type of videos, we propose the Large-scale Screen Content Dataset(LSCD), which contains 714 source sequences. Meanwhile, we provide the analysis of the proposed dataset to show some features of screen content videos, which will help researchers have a better understanding of how to explore new algorithms. Besides collecting and post-processing the data to organize the dataset, we also provide a benchmark containing the performance of both traditional codec and learning-based methods.
</details>
<details>
<summary>摘要</summary>
Multimedia compression allow us to watch videos, see pictures and hear sounds within a limited bandwidth, which helps the flourish of the internet. During the past decades, multimedia compression has achieved great success using hand-craft features and systems. With the development of artificial intelligence and video compression, there emerges a lot of research work related to using the neural network on the video compression task to get rid of the complicated system. Not only producing the advanced algorithms, but researchers also spread the compression to different content, such as User Generated Content(UGC). With the rapid development of mobile devices, screen content videos become an important part of multimedia data. In contrast, we find community lacks a large-scale dataset for screen content video compression, which impedes the fast development of the corresponding learning-based algorithms. In order to fulfill this blank and accelerate the research of this special type of videos, we propose the Large-scale Screen Content Dataset(LSCD), which contains 714 source sequences. Meanwhile, we provide the analysis of the proposed dataset to show some features of screen content videos, which will help researchers have a better understanding of how to explore new algorithms. Besides collecting and post-processing the data to organize the dataset, we also provide a benchmark containing the performance of both traditional codec and learning-based methods.
</details></li>
</ul>
<hr>
<h2 id="SAMedOCT-Adapting-Segment-Anything-Model-SAM-for-Retinal-OCT"><a href="#SAMedOCT-Adapting-Segment-Anything-Model-SAM-for-Retinal-OCT" class="headerlink" title="SAMedOCT: Adapting Segment Anything Model (SAM) for Retinal OCT"></a>SAMedOCT: Adapting Segment Anything Model (SAM) for Retinal OCT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09331">http://arxiv.org/abs/2308.09331</a></li>
<li>repo_url: None</li>
<li>paper_authors: Botond Fazekas, José Morano, Dmitrii Lachinov, Guilherme Aresta, Hrvoje Bogunović<br>for: 这篇论文主要是为了评估Segment Anything Model（SAM）在 RETOUCH 挑战中的大规模公共数据集上的应用。methods: 这篇论文使用了SAM和其修改版本进行了Retinal OCT影像分割的评估，并与当前领导的Retinal fluid segmentation方法进行了比较。results: 研究发现， adapted SAM在Retinal OCT影像分割中表现出了优异的能力，但在一些情况下仍落后于当前领导的方法。这些结果表明SAM在Retinal OCT图像分析中具有适应性和稳定性，并且可以作为Retinal OCT图像分析中的一种有价值工具。<details>
<summary>Abstract</summary>
The Segment Anything Model (SAM) has gained significant attention in the field of image segmentation due to its impressive capabilities and prompt-based interface. While SAM has already been extensively evaluated in various domains, its adaptation to retinal OCT scans remains unexplored. To bridge this research gap, we conduct a comprehensive evaluation of SAM and its adaptations on a large-scale public dataset of OCTs from RETOUCH challenge. Our evaluation covers diverse retinal diseases, fluid compartments, and device vendors, comparing SAM against state-of-the-art retinal fluid segmentation methods. Through our analysis, we showcase adapted SAM's efficacy as a powerful segmentation model in retinal OCT scans, although still lagging behind established methods in some circumstances. The findings highlight SAM's adaptability and robustness, showcasing its utility as a valuable tool in retinal OCT image analysis and paving the way for further advancements in this domain.
</details>
<details>
<summary>摘要</summary>
segmen anything model (SAM) 在图像分割领域备受关注，因其出色的能力和提示式界面。 although SAM 在不同领域得到了广泛的评估，它在Retinal OCT 图像中的适应仍然未经探索。 To bridge this research gap, we conducted a comprehensive evaluation of SAM and its adaptations on a large-scale public dataset of OCTs from RETOUCH challenge. 我们的评估覆盖了多种Retinal diseases, fluid compartments, and device vendors，比较SAM 与现有的Retinal fluid segmentation方法。 Through our analysis, we showcased adapted SAM's efficacy as a powerful segmentation model in retinal OCT scans, although still lagging behind established methods in some circumstances. The findings highlight SAM's adaptability and robustness, showcasing its utility as a valuable tool in retinal OCT image analysis and paving the way for further advancements in this domain.
</details></li>
</ul>
<hr>
<h2 id="Unlimited-Knowledge-Distillation-for-Action-Recognition-in-the-Dark"><a href="#Unlimited-Knowledge-Distillation-for-Action-Recognition-in-the-Dark" class="headerlink" title="Unlimited Knowledge Distillation for Action Recognition in the Dark"></a>Unlimited Knowledge Distillation for Action Recognition in the Dark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09327">http://arxiv.org/abs/2308.09327</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruibing Jin, Guosheng Lin, Min Wu, Jie Lin, Zhengguo Li, Xiaoli Li, Zhenghua Chen</li>
<li>for: 提高动作识别网络学习的知识。</li>
<li>methods: 提出无限知识填充（UKD）技术，不需大量GPU内存，可以有效地融合不同的知识。</li>
<li>results: 对ARID数据集进行了广泛的实验，单流网络通过UKD的填充得到了优于两流网络的表现。<details>
<summary>Abstract</summary>
Dark videos often lose essential information, which causes the knowledge learned by networks is not enough to accurately recognize actions. Existing knowledge assembling methods require massive GPU memory to distill the knowledge from multiple teacher models into a student model. In action recognition, this drawback becomes serious due to much computation required by video process. Constrained by limited computation source, these approaches are infeasible. To address this issue, we propose an unlimited knowledge distillation (UKD) in this paper. Compared with existing knowledge assembling methods, our UKD can effectively assemble different knowledge without introducing high GPU memory consumption. Thus, the number of teaching models for distillation is unlimited. With our UKD, the network's learned knowledge can be remarkably enriched. Our experiments show that the single stream network distilled with our UKD even surpasses a two-stream network. Extensive experiments are conducted on the ARID dataset.
</details>
<details>
<summary>摘要</summary>
黑色视频常常会产生重要信息的丢失，导致网络学习的知识不够准确地识别动作。现有的知识组合方法需要巨量的GPU内存来浸泡多个教师模型中的知识到学生模型中。在动作识别 tasks中，这种缺点变得非常严重，因为视频处理需要很多计算。由于计算源有限，这些方法是不可能实现的。为解决这个问题，我们在这篇论文中提出了无限知识浸泡（UKD）方法。与现有的知识组合方法相比，我们的 UKD 可以无需高GPU内存占用，因此教师模型的数量是无限的。通过我们的 UKD，网络学习的知识可以备受扩展。我们的实验表明，单流网络通过我们的 UKD 甚至超过了两流网络。我们在 ARID 数据集上进行了广泛的实验。
</details></li>
</ul>
<hr>
<h2 id="Retro-FPN-Retrospective-Feature-Pyramid-Network-for-Point-Cloud-Semantic-Segmentation"><a href="#Retro-FPN-Retrospective-Feature-Pyramid-Network-for-Point-Cloud-Semantic-Segmentation" class="headerlink" title="Retro-FPN: Retrospective Feature Pyramid Network for Point Cloud Semantic Segmentation"></a>Retro-FPN: Retrospective Feature Pyramid Network for Point Cloud Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09314">http://arxiv.org/abs/2308.09314</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/allenxiangx/retro-fpn">https://github.com/allenxiangx/retro-fpn</a></li>
<li>paper_authors: Peng Xiang, Xin Wen, Yu-Shen Liu, Hui Zhang, Yi Fang, Zhizhong Han</li>
<li>for: 提高点云Semantic segmentation的精度，解决过去方法中的信息损失和不明确区域特征问题。</li>
<li>methods: 提出Retro-FPN方法，将每个点的特征预测设计为一个显式和回顾的修复过程，通过所有层次结构来提取semantic features。其关键新特点是一个Retro-Transformer，用于从前一层层次结构中概括semantic context，并在当前阶段修复特征。</li>
<li>results: 与州际标准背景方法相比，Retro-FPN可以显著提高性能。经过广泛的实验证明，Retro-FPN可以在多种常用的 benchmark 上达到州际标准水平。源代码可以在<a target="_blank" rel="noopener" href="https://github.com/AllenXiangX/Retro-FPN%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/AllenXiangX/Retro-FPN上获取。</a><details>
<summary>Abstract</summary>
Learning per-point semantic features from the hierarchical feature pyramid is essential for point cloud semantic segmentation. However, most previous methods suffered from ambiguous region features or failed to refine per-point features effectively, which leads to information loss and ambiguous semantic identification. To resolve this, we propose Retro-FPN to model the per-point feature prediction as an explicit and retrospective refining process, which goes through all the pyramid layers to extract semantic features explicitly for each point. Its key novelty is a retro-transformer for summarizing semantic contexts from the previous layer and accordingly refining the features in the current stage. In this way, the categorization of each point is conditioned on its local semantic pattern. Specifically, the retro-transformer consists of a local cross-attention block and a semantic gate unit. The cross-attention serves to summarize the semantic pattern retrospectively from the previous layer. And the gate unit carefully incorporates the summarized contexts and refines the current semantic features. Retro-FPN is a pluggable neural network that applies to hierarchical decoders. By integrating Retro-FPN with three representative backbones, including both point-based and voxel-based methods, we show that Retro-FPN can significantly improve performance over state-of-the-art backbones. Comprehensive experiments on widely used benchmarks can justify the effectiveness of our design. The source is available at https://github.com/AllenXiangX/Retro-FPN
</details>
<details>
<summary>摘要</summary>
学习每个点的 semantic 特征从层次特征 пирамид是semantic segmentation of point clouds 中的关键。然而，大多数之前的方法受到不明确的区域特征或不能有效地细化每个点的特征，导致信息损失和不明确的 semantic 标识。为解决这个问题，我们提出了Retro-FPN，它模型了每个点的特征预测为明确的和Retrospective 细化过程，通过所有层次来提取semantic 特征。其关键创新是一个Retro-transformer，它在上一层的semantic 上下文中进行总结，并在当前阶段细化特征。因此，每个点的分类是基于其当前semantic 模式。具体来说，Retro-transformer包括一个local cross-attention块和一个semantic gate单元。cross-attention 用于在上一层的semantic 模式中总结，并将其细化到当前阶段。而gate单元通过细化current semantic features ，以提高分类精度。Retro-FPN是一个可插入的神经网络，可以应用于层次解码器。通过与三种代表性的背景结构相结合，包括点基的和voxel基的方法，我们表明Retro-FPN可以在state-of-the-art 背景下显著提高性能。广泛的实验证明了我们的设计的有效性。源代码可以在https://github.com/AllenXiangX/Retro-FPN 中下载。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Image-Forgery-Detection-via-Contrastive-Learning-and-Unsupervised-Clustering"><a href="#Rethinking-Image-Forgery-Detection-via-Contrastive-Learning-and-Unsupervised-Clustering" class="headerlink" title="Rethinking Image Forgery Detection via Contrastive Learning and Unsupervised Clustering"></a>Rethinking Image Forgery Detection via Contrastive Learning and Unsupervised Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09307">http://arxiv.org/abs/2308.09307</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/highwaywu/focal">https://github.com/highwaywu/focal</a></li>
<li>paper_authors: Haiwei Wu, Yiming Chen, Jiantao Zhou</li>
<li>for: 本研究旨在提高图像forge检测的精度和效果，并提出一种新的方法FOCAL（Forensic ContrAstive cLustering），这种方法基于对比学习和无监督划分，能够准确地检测图像中的forge区域。</li>
<li>methods: FOCAL方法包括三个主要部分：1）使用像素级对比学习来监督高级别侦验特征提取; 2）使用在线无监督划分算法来将学习到的特征分为forge和正常两类; 3）通过简单地Feature层 concatenation来进一步提高检测性能，无需重新训练。</li>
<li>results: 实验结果表明，FOCAL方法在六个公共测试数据集上达到了与state-of-the-art竞争算法之间的大幅提升：+24.3%的覆盖率、+18.6%的哥伦比亚、+17.5%的FF++, +14.2%的MISD、+13.5%的CASIA和+10.3%的NIST，以及IoU方面。<details>
<summary>Abstract</summary>
Image forgery detection aims to detect and locate forged regions in an image. Most existing forgery detection algorithms formulate classification problems to classify pixels into forged or pristine. However, the definition of forged and pristine pixels is only relative within one single image, e.g., a forged region in image A is actually a pristine one in its source image B (splicing forgery). Such a relative definition has been severely overlooked by existing methods, which unnecessarily mix forged (pristine) regions across different images into the same category. To resolve this dilemma, we propose the FOrensic ContrAstive cLustering (FOCAL) method, a novel, simple yet very effective paradigm based on contrastive learning and unsupervised clustering for the image forgery detection. Specifically, FOCAL 1) utilizes pixel-level contrastive learning to supervise the high-level forensic feature extraction in an image-by-image manner, explicitly reflecting the above relative definition; 2) employs an on-the-fly unsupervised clustering algorithm (instead of a trained one) to cluster the learned features into forged/pristine categories, further suppressing the cross-image influence from training data; and 3) allows to further boost the detection performance via simple feature-level concatenation without the need of retraining. Extensive experimental results over six public testing datasets demonstrate that our proposed FOCAL significantly outperforms the state-of-the-art competing algorithms by big margins: +24.3% on Coverage, +18.6% on Columbia, +17.5% on FF++, +14.2% on MISD, +13.5% on CASIA and +10.3% on NIST in terms of IoU. The paradigm of FOCAL could bring fresh insights and serve as a novel benchmark for the image forgery detection task. The code is available at https://github.com/HighwayWu/FOCAL.
</details>
<details>
<summary>摘要</summary>
Image forgery detection aims to detect and locate forged regions in an image. Most existing forgery detection algorithms formulate classification problems to classify pixels into forged or pristine. However, the definition of forged and pristine pixels is only relative within one single image, e.g., a forged region in image A is actually a pristine one in its source image B (splicing forgery). Such a relative definition has been severely overlooked by existing methods, which unnecessarily mix forged (pristine) regions across different images into the same category. To resolve this dilemma, we propose the FOrensic ContrAstive cLustering (FOCAL) method, a novel, simple yet very effective paradigm based on contrastive learning and unsupervised clustering for the image forgery detection. Specifically, FOCAL 1) utilizes pixel-level contrastive learning to supervise the high-level forensic feature extraction in an image-by-image manner, explicitly reflecting the above relative definition; 2) employs an on-the-fly unsupervised clustering algorithm (instead of a trained one) to cluster the learned features into forged/pristine categories, further suppressing the cross-image influence from training data; and 3) allows to further boost the detection performance via simple feature-level concatenation without the need of retraining. Extensive experimental results over six public testing datasets demonstrate that our proposed FOCAL significantly outperforms the state-of-the-art competing algorithms by big margins: +24.3% on Coverage, +18.6% on Columbia, +17.5% on FF++, +14.2% on MISD, +13.5% on CASIA and +10.3% on NIST in terms of IoU. The paradigm of FOCAL could bring fresh insights and serve as a novel benchmark for the image forgery detection task. The code is available at https://github.com/HighwayWu/FOCAL.
</details></li>
</ul>
<hr>
<h2 id="DiffDis-Empowering-Generative-Diffusion-Model-with-Cross-Modal-Discrimination-Capability"><a href="#DiffDis-Empowering-Generative-Diffusion-Model-with-Cross-Modal-Discrimination-Capability" class="headerlink" title="DiffDis: Empowering Generative Diffusion Model with Cross-Modal Discrimination Capability"></a>DiffDis: Empowering Generative Diffusion Model with Cross-Modal Discrimination Capability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09306">http://arxiv.org/abs/2308.09306</a></li>
<li>repo_url: None</li>
<li>paper_authors: Runhui Huang, Jianhua Han, Guansong Lu, Xiaodan Liang, Yihan Zeng, Wei Zhang, Hang Xu</li>
<li>for: 本文旨在探讨将生成和检测融合到一起的可能性，以提高图像生成和图像文本检测的性能。</li>
<li>methods: 本文提出了一种名为DiffDis的散度过程模型，它将批处理的散度过程与多modal的预训练模型（如CLIP、ALIGN和FILIP）结合起来，以实现图像生成和图像文本检测的同时学习。</li>
<li>results: 实验结果表明，DiffDis可以在12个数据集上的零 shot分类任务上提高平均精度0.65%，并在图像生成和图像文本检测任务上提高FID指标0.242%。<details>
<summary>Abstract</summary>
Recently, large-scale diffusion models, e.g., Stable diffusion and DallE2, have shown remarkable results on image synthesis. On the other hand, large-scale cross-modal pre-trained models (e.g., CLIP, ALIGN, and FILIP) are competent for various downstream tasks by learning to align vision and language embeddings. In this paper, we explore the possibility of jointly modeling generation and discrimination. Specifically, we propose DiffDis to unify the cross-modal generative and discriminative pretraining into one single framework under the diffusion process. DiffDis first formulates the image-text discriminative problem as a generative diffusion process of the text embedding from the text encoder conditioned on the image. Then, we propose a novel dual-stream network architecture, which fuses the noisy text embedding with the knowledge of latent images from different scales for image-text discriminative learning. Moreover, the generative and discriminative tasks can efficiently share the image-branch network structure in the multi-modality model. Benefiting from diffusion-based unified training, DiffDis achieves both better generation ability and cross-modal semantic alignment in one architecture. Experimental results show that DiffDis outperforms single-task models on both the image generation and the image-text discriminative tasks, e.g., 1.65% improvement on average accuracy of zero-shot classification over 12 datasets and 2.42 improvement on FID of zero-shot image synthesis.
</details>
<details>
<summary>摘要</summary>
近期，大规模扩散模型，如稳定扩散和DallE2，在图像生成方面已经显示出惊人的成绩。然而，大规模的交叉模态预训练模型（如CLIP、ALIGN和FILIP）在多种下游任务上表现出色，这些模型通过学习视觉和语言嵌入的对应关系来学习。在这篇论文中，我们探讨了将生成和批判合并到一起的可能性。特别是，我们提出了DiffDis模型，它将交叉模态生成和批判预训练集成为一个散射过程中的单一框架。DiffDis首先将图像-文本识别问题定义为图像编码器生成的文本嵌入在图像条件下的散射过程。然后，我们提出了一种新的双流网络架构，它将不同缩放的图像嵌入与文本嵌入进行混合，以进行图像-文本识别学习。此外，生成和批判任务可以在多模态模型中有效共享图像分支网络结构。由于散射基于的统一训练，DiffDis可以同时实现更好的生成能力和交叉模态含义对齐。实验结果表明，DiffDis在图像生成和图像-文本识别任务上都有更好的表现，比如在12个数据集上的平均精度为1.65%，和在FID上的图像生成精度为2.42%。
</details></li>
</ul>
<hr>
<h2 id="Human-Part-wise-3D-Motion-Context-Learning-for-Sign-Language-Recognition"><a href="#Human-Part-wise-3D-Motion-Context-Learning-for-Sign-Language-Recognition" class="headerlink" title="Human Part-wise 3D Motion Context Learning for Sign Language Recognition"></a>Human Part-wise 3D Motion Context Learning for Sign Language Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09305">http://arxiv.org/abs/2308.09305</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taeryung Lee, Yeonguk Oh, Kyoung Mu Lee</li>
<li>for: 提高手语识别的表现，特别是利用手部特征来提高表现。</li>
<li>methods: 提出了一种基于人体部分动作上下文学习的框架，包括使用分解变换器（PET）和整体变换器（WET）来学习手部动作上下文，以及对2D和3D姿态进行ensemble。</li>
<li>results: 在WLASL数据集上实现了比前一代方法更高的表现，具体来说是通过学习手部动作上下文来提高手语识别的精度。<details>
<summary>Abstract</summary>
In this paper, we propose P3D, the human part-wise motion context learning framework for sign language recognition. Our main contributions lie in two dimensions: learning the part-wise motion context and employing the pose ensemble to utilize 2D and 3D pose jointly. First, our empirical observation implies that part-wise context encoding benefits the performance of sign language recognition. While previous methods of sign language recognition learned motion context from the sequence of the entire pose, we argue that such methods cannot exploit part-specific motion context. In order to utilize part-wise motion context, we propose the alternating combination of a part-wise encoding Transformer (PET) and a whole-body encoding Transformer (WET). PET encodes the motion contexts from a part sequence, while WET merges them into a unified context. By learning part-wise motion context, our P3D achieves superior performance on WLASL compared to previous state-of-the-art methods. Second, our framework is the first to ensemble 2D and 3D poses for sign language recognition. Since the 3D pose holds rich motion context and depth information to distinguish the words, our P3D outperformed the previous state-of-the-art methods employing a pose ensemble.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出P3D，人体部分动作上下文学习框架，用于手语识别。我们的主要贡献在两个维度：学习部分动作上下文和利用2D和3D pose共同。首先，我们的实验观察表明，部分动作上下文编码对手语识别性能有益。而前一代方法通常从整个姿态序列学习动作上下文，我们 argue那些方法无法利用部分动作上下文。为了利用部分动作上下文，我们提议使用分解成部分编码器（PET）和整体编码器（WET）的交互式组合。PET编码部分动作上下文，而WET将其合并为一个统一的上下文。通过学习部分动作上下文，我们的P3D在WLASL上比前一代方法更高的性能。其次，我们的框架是首次将2D和3D姿态共同用于手语识别。因为3D姿态具有较多的动作上下文和深度信息，我们的P3D在使用pose ensemble时表现出了更高的性能。
</details></li>
</ul>
<hr>
<h2 id="Online-Class-Incremental-Learning-on-Stochastic-Blurry-Task-Boundary-via-Mask-and-Visual-Prompt-Tuning"><a href="#Online-Class-Incremental-Learning-on-Stochastic-Blurry-Task-Boundary-via-Mask-and-Visual-Prompt-Tuning" class="headerlink" title="Online Class Incremental Learning on Stochastic Blurry Task Boundary via Mask and Visual Prompt Tuning"></a>Online Class Incremental Learning on Stochastic Blurry Task Boundary via Mask and Visual Prompt Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09303">http://arxiv.org/abs/2308.09303</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/moonjunyyy/si-blurry">https://github.com/moonjunyyy/si-blurry</a></li>
<li>paper_authors: Jun-Yeong Moon, Keon-Hee Park, Jung Uk Kim, Gyeong-Moon Park</li>
<li>for: 本研究旨在 Addressing the challenges of continual learning in real-world scenarios, where the number of input data and tasks is constantly changing in a statistical way.</li>
<li>methods: 本研究提出了一种新的 Stochastic incremental Blurry task boundary scenario (Si-Blurry)，以及一种名为 Mask and Visual Prompt tuning (MVP) 的方法来解决 inter-和 intra-task 忘记问题和 class imbalance 问题。MVP 包括一种新的 instance-wise logit 遮盾和 contrastive visual prompt 准则，以及一种新的 gradient similarity-based focal loss 和 adaptive feature scaling。</li>
<li>results: 对于our challenging Si-Blurry scenario, extensive experiments show that our proposed MVP significantly outperforms the existing state-of-the-art methods.<details>
<summary>Abstract</summary>
Continual learning aims to learn a model from a continuous stream of data, but it mainly assumes a fixed number of data and tasks with clear task boundaries. However, in real-world scenarios, the number of input data and tasks is constantly changing in a statistical way, not a static way. Although recently introduced incremental learning scenarios having blurry task boundaries somewhat address the above issues, they still do not fully reflect the statistical properties of real-world situations because of the fixed ratio of disjoint and blurry samples. In this paper, we propose a new Stochastic incremental Blurry task boundary scenario, called Si-Blurry, which reflects the stochastic properties of the real-world. We find that there are two major challenges in the Si-Blurry scenario: (1) inter- and intra-task forgettings and (2) class imbalance problem. To alleviate them, we introduce Mask and Visual Prompt tuning (MVP). In MVP, to address the inter- and intra-task forgetting issues, we propose a novel instance-wise logit masking and contrastive visual prompt tuning loss. Both of them help our model discern the classes to be learned in the current batch. It results in consolidating the previous knowledge. In addition, to alleviate the class imbalance problem, we introduce a new gradient similarity-based focal loss and adaptive feature scaling to ease overfitting to the major classes and underfitting to the minor classes. Extensive experiments show that our proposed MVP significantly outperforms the existing state-of-the-art methods in our challenging Si-Blurry scenario.
</details>
<details>
<summary>摘要</summary>
<<SYS>>输入文本转换为简化中文。<</SYS>>持续学习目标是学习从连续流动的数据中学习模型，但是它主要假设Fixed数据量和任务数量，并且任务boundary是明确的。然而，在实际情况下，输入数据和任务的数量在统计方式上不断变化，而不是静态的方式。虽然最近引入的增量学习方式有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方有些地方
</details></li>
</ul>
<hr>
<h2 id="Inferior-Alveolar-Nerve-Segmentation-in-CBCT-images-using-Connectivity-Based-Selective-Re-training"><a href="#Inferior-Alveolar-Nerve-Segmentation-in-CBCT-images-using-Connectivity-Based-Selective-Re-training" class="headerlink" title="Inferior Alveolar Nerve Segmentation in CBCT images using Connectivity-Based Selective Re-training"></a>Inferior Alveolar Nerve Segmentation in CBCT images using Connectivity-Based Selective Re-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09298">http://arxiv.org/abs/2308.09298</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/garynico517/ssl-ian-retraining">https://github.com/garynico517/ssl-ian-retraining</a></li>
<li>paper_authors: Yusheng Liu, Rui Xin, Tao Yang, Lisheng Wang</li>
<li>for: 这个论文的目的是提高自动尖齿神经 canal  segmentation 的能力，以便在 dental 和 maxillofacial 手术中避免不可逆的神经损伤。</li>
<li>methods: 作者提出了一种基于 IAN 连接性的选择性重训练方法，以解决自动 segmentation 中 sparse labeling 的负面影响。</li>
<li>results: 作者的方法在 ToothFairy 验证集上进行了量化评估，达到了 dice similarity coefficient (DSC) 0.7956，和 95% hausdorff distance (HD95) 4.4905，并在竞赛中获得冠军。<details>
<summary>Abstract</summary>
Inferior Alveolar Nerve (IAN) canal detection in CBCT is an important step in many dental and maxillofacial surgery applications to prevent irreversible damage to the nerve during the procedure.The ToothFairy2023 Challenge aims to establish a 3D maxillofacial dataset consisting of all sparse labels and partial dense labels, and improve the ability of automatic IAN segmentation. In this work, in order to avoid the negative impact brought by sparse labeling, we transform the mixed supervised problem into a semi-supervised problem. Inspired by self-training via pseudo labeling, we propose a selective re-training framework based on IAN connectivity. Our method is quantitatively evaluated on the ToothFairy verification cases, achieving the dice similarity coefficient (DSC) of 0.7956, and 95\% hausdorff distance (HD95) of 4.4905, and wining the champion in the competition. Code is available at https://github.com/GaryNico517/SSL-IAN-Retraining.
</details>
<details>
<summary>摘要</summary>
“ inferior alveolar nerve（IAN） Canal detection in CBCT 是 dental 和 maxillofacial surgery 中重要的一步，以避免在过程中对神经造成 irreversible 的损害。ToothFairy2023 Challenge 目标是建立一个 3D maxillofacial 数据集，包括所有稀疏标签和部分杂散标签，以提高自动 IAN 分割能力。在本工作中，以免除稀疏标签的负面影响，我们将混合监督问题转化为 semi-supervised 问题。受 pseudo labeling 的启发，我们提出一种选择性重训练框架，基于 IAN 连接性。我们的方法在 ToothFairy 验证例程中被评估，达到了 dice similarity coefficient（DSC）0.7956，和 Hausdorff distance（HD95）4.4905，并在竞赛中获胜。代码可以在 https://github.com/GaryNico517/SSL-IAN-Retraining 上获取。”Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="NAPA-VQ-Neighborhood-Aware-Prototype-Augmentation-with-Vector-Quantization-for-Continual-Learning"><a href="#NAPA-VQ-Neighborhood-Aware-Prototype-Augmentation-with-Vector-Quantization-for-Continual-Learning" class="headerlink" title="NAPA-VQ: Neighborhood Aware Prototype Augmentation with Vector Quantization for Continual Learning"></a>NAPA-VQ: Neighborhood Aware Prototype Augmentation with Vector Quantization for Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09297">http://arxiv.org/abs/2308.09297</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tamasham/napa-vq">https://github.com/tamasham/napa-vq</a></li>
<li>paper_authors: Tamasha Malepathirana, Damith Senanayake, Saman Halgamuge</li>
<li>For: 强调在深度神经网络中避免严重遗传问题，即在新知获得时不损失之前知识。* Methods: 基于非特例学习（NECIL），不使用过去的例子来学习新的类别，并且通过对邻近类别的了解来增强分类器的决策界。* Results: 与现有的State-of-the-art NECIL方法比较，NAPA-VQ方法在CIFAR-100、TinyImageNet和ImageNet-Subset上的实验结果显示，获得了5%、2%和4%的精度提升和10%、3%和9%的遗传减少。<details>
<summary>Abstract</summary>
Catastrophic forgetting; the loss of old knowledge upon acquiring new knowledge, is a pitfall faced by deep neural networks in real-world applications. Many prevailing solutions to this problem rely on storing exemplars (previously encountered data), which may not be feasible in applications with memory limitations or privacy constraints. Therefore, the recent focus has been on Non-Exemplar based Class Incremental Learning (NECIL) where a model incrementally learns about new classes without using any past exemplars. However, due to the lack of old data, NECIL methods struggle to discriminate between old and new classes causing their feature representations to overlap. We propose NAPA-VQ: Neighborhood Aware Prototype Augmentation with Vector Quantization, a framework that reduces this class overlap in NECIL. We draw inspiration from Neural Gas to learn the topological relationships in the feature space, identifying the neighboring classes that are most likely to get confused with each other. This neighborhood information is utilized to enforce strong separation between the neighboring classes as well as to generate old class representative prototypes that can better aid in obtaining a discriminative decision boundary between old and new classes. Our comprehensive experiments on CIFAR-100, TinyImageNet, and ImageNet-Subset demonstrate that NAPA-VQ outperforms the State-of-the-art NECIL methods by an average improvement of 5%, 2%, and 4% in accuracy and 10%, 3%, and 9% in forgetting respectively. Our code can be found in https://github.com/TamashaM/NAPA-VQ.git.
</details>
<details>
<summary>摘要</summary>
深度神经网络在实际应用中面临的一个挑战是 catastrophic forgetting，即因为新知约而失去老知识的问题。许多现有的解决方案是通过存储过去的数据（例emplars），但这可能不是应用中存储限制或隐私限制的情况下可行。因此，近期的注意点在 Non-Exemplar based Class Incremental Learning (NECIL) 方面，这种方法可以在没有过去数据的情况下，逐步学习新类。然而，由于缺乏过去数据，NECIL 方法可能会将旧类和新类的特征表示相互混淆。我们提出了 NAPA-VQ：它是一种基于 Neural Gas 学习特征空间中类之间的 topological 关系的框架，以便在 feature 空间中强制分离邻近类。此外，它还可以生成旧类代表对象，以便更好地帮助得出精准的决策边界 между旧类和新类。我们的全面实验表明，NAPA-VQ 在 CIFAR-100、TinyImageNet 和 ImageNet-Subset 上比 State-of-the-art NECIL 方法平均提高了5%, 2%, 4% 的准确率和10%, 3%, 9% 的忘记率。我们的代码可以在 https://github.com/TamashaM/NAPA-VQ.git 找到。
</details></li>
</ul>
<hr>
<h2 id="Self-Calibrated-Cross-Attention-Network-for-Few-Shot-Segmentation"><a href="#Self-Calibrated-Cross-Attention-Network-for-Few-Shot-Segmentation" class="headerlink" title="Self-Calibrated Cross Attention Network for Few-Shot Segmentation"></a>Self-Calibrated Cross Attention Network for Few-Shot Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09294">http://arxiv.org/abs/2308.09294</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sam1224/sccan">https://github.com/sam1224/sccan</a></li>
<li>paper_authors: Qianxiong Xu, Wenting Zhao, Guosheng Lin, Cheng Long<br>for:This paper focuses on improving few-shot segmentation (FSS) by effectively utilizing support samples.methods:The proposed method uses a self-calibrated cross attention (SCCA) block, which splits the query and support features into patches, aligns each query patch with its most similar support patch, and fuses the query background features with matched background features from the support image.results:The proposed method achieves state-of-the-art performance on PASCAL-5^i and COCO-20^i under 5-shot setting, with a mIoU score of 5.6% better than previous state-of-the-arts on COCO-20^i.<details>
<summary>Abstract</summary>
The key to the success of few-shot segmentation (FSS) lies in how to effectively utilize support samples. Most solutions compress support foreground (FG) features into prototypes, but lose some spatial details. Instead, others use cross attention to fuse query features with uncompressed support FG. Query FG could be fused with support FG, however, query background (BG) cannot find matched BG features in support FG, yet inevitably integrates dissimilar features. Besides, as both query FG and BG are combined with support FG, they get entangled, thereby leading to ineffective segmentation. To cope with these issues, we design a self-calibrated cross attention (SCCA) block. For efficient patch-based attention, query and support features are firstly split into patches. Then, we design a patch alignment module to align each query patch with its most similar support patch for better cross attention. Specifically, SCCA takes a query patch as Q, and groups the patches from the same query image and the aligned patches from the support image as K&V. In this way, the query BG features are fused with matched BG features (from query patches), and thus the aforementioned issues will be mitigated. Moreover, when calculating SCCA, we design a scaled-cosine mechanism to better utilize the support features for similarity calculation. Extensive experiments conducted on PASCAL-5^i and COCO-20^i demonstrate the superiority of our model, e.g., the mIoU score under 5-shot setting on COCO-20^i is 5.6%+ better than previous state-of-the-arts. The code is available at https://github.com/Sam1224/SCCAN.
</details>
<details>
<summary>摘要</summary>
针对几何shot segmentation（FSS）的成功关键在于如何有效利用支持样本。大多数解决方案将支持背景（BG）特征压缩成原型，但是会产生一些空间细节的损失。其他人则使用批注注意力机制来融合查询特征和未压缩的支持BG。然而，查询BG无法在支持BG中找到匹配的BG特征，却必然混合不同的特征。此外，由于查询BG和支持BG都与支持BG进行融合，因此会导致不准确的分割。为了解决这些问题，我们设计了一个自适应批注注意力块（SCCA）。SCCA块的实现方式如下：首先，我们将查询特征和支持特征切分成小块。然后，我们设计了一个块对齐模块，用于将每个查询块与其最相似的支持块进行对齐。这样，查询BG特征可以与支持BG中的匹配BG特征进行混合，从而解决上述问题。此外，在计算SCCA时，我们设计了一个托管整数机制，以更好地利用支持特征进行相似性计算。我们在PASCAL-5^i和COCO-20^i上进行了广泛的实验，结果显示我们的模型在5架shot设定下的mIoU分数比前一个状态艺术高出5.6%。代码可以在https://github.com/Sam1224/SCCAN中下载。
</details></li>
</ul>
<hr>
<h2 id="RFDforFin-Robust-Deep-Forgery-Detection-for-GAN-generated-Fingerprint-Images"><a href="#RFDforFin-Robust-Deep-Forgery-Detection-for-GAN-generated-Fingerprint-Images" class="headerlink" title="RFDforFin: Robust Deep Forgery Detection for GAN-generated Fingerprint Images"></a>RFDforFin: Robust Deep Forgery Detection for GAN-generated Fingerprint Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09285">http://arxiv.org/abs/2308.09285</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui Miao, Yuanfang Guo, Yunhong Wang</li>
<li>for: 防止GAN生成的指纹图像被恶意褪别，以保护公共安全。</li>
<li>methods:  combining unique ridge features of fingerprint and generation artifacts of the GAN-generated images to detect deep forgery.</li>
<li>results: 提出了首个针对指纹图像的深度褪别检测方法，实现了低复杂度和高效果。<details>
<summary>Abstract</summary>
With the rapid development of the image generation technologies, the malicious abuses of the GAN-generated fingerprint images poses a significant threat to the public safety in certain circumstances. Although the existing universal deep forgery detection approach can be applied to detect the fake fingerprint images, they are easily attacked and have poor robustness. Meanwhile, there is no specifically designed deep forgery detection method for fingerprint images. In this paper, we propose the first deep forgery detection approach for fingerprint images, which combines unique ridge features of fingerprint and generation artifacts of the GAN-generated images, to the best of our knowledge. Specifically, we firstly construct a ridge stream, which exploits the grayscale variations along the ridges to extract unique fingerprint-specific features. Then, we construct a generation artifact stream, in which the FFT-based spectrums of the input fingerprint images are exploited, to extract more robust generation artifact features. At last, the unique ridge features and generation artifact features are fused for binary classification (\textit{i.e.}, real or fake). Comprehensive experiments demonstrate that our proposed approach is effective and robust with low complexities.
</details>
<details>
<summary>摘要</summary>
随着图像生成技术的快速发展，GAN生成的指纹图像在某些情况下可能会对公共安全构成威胁。虽然现有的通用深度伪造检测方法可以检测假指纹图像，但它们容易受到攻击并有低效率。此外，没有专门设计的深度伪造检测方法 для指纹图像。在这篇论文中，我们提出了首个深度伪造检测方法 для指纹图像，该方法结合了指纹特有的缝合特征和GAN生成图像的生成痕迹特征。具体来说，我们首先构建缝合流，利用缝合中的灰度变化来提取指纹特有的特征。然后，我们构建生成痕迹流，利用输入指纹图像的FFT基准谱来提取更加鲁棒的生成痕迹特征。最后，缝合特征和生成痕迹特征进行 binary 分类（即真实或假）。广泛的实验表明，我们提出的方法有效和可靠，并且具有低复杂性。
</details></li>
</ul>
<hr>
<h2 id="Diverse-Cotraining-Makes-Strong-Semi-Supervised-Segmentor"><a href="#Diverse-Cotraining-Makes-Strong-Semi-Supervised-Segmentor" class="headerlink" title="Diverse Cotraining Makes Strong Semi-Supervised Segmentor"></a>Diverse Cotraining Makes Strong Semi-Supervised Segmentor</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09281">http://arxiv.org/abs/2308.09281</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yijiang Li, Xinjiang Wang, Lihe Yang, Litong Feng, Wayne Zhang, Ying Gao</li>
<li>for: 本研究旨在探讨深度共训的工作机制，并证明多视图支持的假设不符合现实。</li>
<li>methods: 本研究使用多种方法来增加共训模型的多样性，包括输入领域、不同的扩展和网络架构。</li>
<li>results:  compared to current state-of-the-art 方法，我们的多样共训方法在不同的评估协议上取得了明显的提高，例如在 Pascal 上 achieve the best mIoU of 76.2%, 77.7% and 80.2% with only 92, 183 and 366 labeled images.<details>
<summary>Abstract</summary>
Deep co-training has been introduced to semi-supervised segmentation and achieves impressive results, yet few studies have explored the working mechanism behind it. In this work, we revisit the core assumption that supports co-training: multiple compatible and conditionally independent views. By theoretically deriving the generalization upper bound, we prove the prediction similarity between two models negatively impacts the model's generalization ability. However, most current co-training models are tightly coupled together and violate this assumption. Such coupling leads to the homogenization of networks and confirmation bias which consequently limits the performance. To this end, we explore different dimensions of co-training and systematically increase the diversity from the aspects of input domains, different augmentations and model architectures to counteract homogenization. Our Diverse Co-training outperforms the state-of-the-art (SOTA) methods by a large margin across different evaluation protocols on the Pascal and Cityscapes. For example. we achieve the best mIoU of 76.2%, 77.7% and 80.2% on Pascal with only 92, 183 and 366 labeled images, surpassing the previous best results by more than 5%.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="DiffLLE-Diffusion-guided-Domain-Calibration-for-Unsupervised-Low-light-Image-Enhancement"><a href="#DiffLLE-Diffusion-guided-Domain-Calibration-for-Unsupervised-Low-light-Image-Enhancement" class="headerlink" title="DiffLLE: Diffusion-guided Domain Calibration for Unsupervised Low-light Image Enhancement"></a>DiffLLE: Diffusion-guided Domain Calibration for Unsupervised Low-light Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09279">http://arxiv.org/abs/2308.09279</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuzhou Yang, Xuanyu Zhang, Yinhuai Wang, Jiwen Yu, Yuhan Wang, Jian Zhang</li>
<li>for: 这篇论文是为了提出一种robust和有效的无监督低光照图像改善方法，即Diffusion-based domain calibration（DiffLLE）。</li>
<li>methods: 该方法采用了一种简单的无监督增强算法，并采用了两个附加的零扩展插件模块：Diffusion-guided Degradation Calibration（DDC）模块和Fine-grained Target domain Distillation（FTD）模块。</li>
<li>results: 该方法在多种实验中表现出色，甚至超过了一些监督学习方法。<details>
<summary>Abstract</summary>
Existing unsupervised low-light image enhancement methods lack enough effectiveness and generalization in practical applications. We suppose this is because of the absence of explicit supervision and the inherent gap between real-world scenarios and the training data domain. In this paper, we develop Diffusion-based domain calibration to realize more robust and effective unsupervised Low-Light Enhancement, called DiffLLE. Since the diffusion model performs impressive denoising capability and has been trained on massive clean images, we adopt it to bridge the gap between the real low-light domain and training degradation domain, while providing efficient priors of real-world content for unsupervised models. Specifically, we adopt a naive unsupervised enhancement algorithm to realize preliminary restoration and design two zero-shot plug-and-play modules based on diffusion model to improve generalization and effectiveness. The Diffusion-guided Degradation Calibration (DDC) module narrows the gap between real-world and training low-light degradation through diffusion-based domain calibration and a lightness enhancement curve, which makes the enhancement model perform robustly even in sophisticated wild degradation. Due to the limited enhancement effect of the unsupervised model, we further develop the Fine-grained Target domain Distillation (FTD) module to find a more visual-friendly solution space. It exploits the priors of the pre-trained diffusion model to generate pseudo-references, which shrinks the preliminary restored results from a coarse normal-light domain to a finer high-quality clean field, addressing the lack of strong explicit supervision for unsupervised methods. Benefiting from these, our approach even outperforms some supervised methods by using only a simple unsupervised baseline. Extensive experiments demonstrate the superior effectiveness of the proposed DiffLLE.
</details>
<details>
<summary>摘要</summary>
We adopt a diffusion model that has been trained on massive clean images, and use it to bridge the gap between the real low-light domain and the training degradation domain. This provides efficient priors of real-world content for unsupervised models. We use a naive unsupervised enhancement algorithm to realize preliminary restoration, and design two zero-shot plug-and-play modules based on the diffusion model to improve generalization and effectiveness.The Diffusion-guided Degradation Calibration (DDC) module narrows the gap between real-world and training low-light degradation through diffusion-based domain calibration and a lightness enhancement curve. This makes the enhancement model perform robustly even in sophisticated wild degradation. However, the limited enhancement effect of the unsupervised model leads to the development of the Fine-grained Target domain Distillation (FTD) module. This module exploits the priors of the pre-trained diffusion model to generate pseudo-references, which shrink the preliminary restored results from a coarse normal-light domain to a finer high-quality clean field. This addresses the lack of strong explicit supervision for unsupervised methods.Our approach outperforms some supervised methods using only a simple unsupervised baseline. Extensive experiments demonstrate the superior effectiveness of the proposed DiffLLE.
</details></li>
</ul>
<hr>
<h2 id="MATLABER-Material-Aware-Text-to-3D-via-LAtent-BRDF-auto-EncodeR"><a href="#MATLABER-Material-Aware-Text-to-3D-via-LAtent-BRDF-auto-EncodeR" class="headerlink" title="MATLABER: Material-Aware Text-to-3D via LAtent BRDF auto-EncodeR"></a>MATLABER: Material-Aware Text-to-3D via LAtent BRDF auto-EncodeR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09278">http://arxiv.org/abs/2308.09278</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/SheldonTsui/Matlaber">https://github.com/SheldonTsui/Matlaber</a></li>
<li>paper_authors: Xudong Xu, Zhaoyang Lyu, Xingang Pan, Bo Dai<br>for:本研究旨在提高文本到3D图像生成中的物料质量，通过使用新的秘密BRDF自动编码器（Latent BRDF auto-EncodeR，简称MATLABER）。methods:我们使用大规模的真实世界BRDF收集来训练这个自动编码器，并确保其隐藏空间的光滑性，这些隐藏空间自然变为物料的自然分布。在文本到3D图像生成中，我们在物料预测中使用这些隐藏空间编码器，而不是直接使用BRDF参数。results:我们的方法在生成物料的实际和准确性方面表现出色，并且高质量的物料自然地启用了多个下游任务，如重新照明和物料编辑。<details>
<summary>Abstract</summary>
Based on powerful text-to-image diffusion models, text-to-3D generation has made significant progress in generating compelling geometry and appearance. However, existing methods still struggle to recover high-fidelity object materials, either only considering Lambertian reflectance, or failing to disentangle BRDF materials from the environment lights. In this work, we propose Material-Aware Text-to-3D via LAtent BRDF auto-EncodeR (\textbf{MATLABER}) that leverages a novel latent BRDF auto-encoder for material generation. We train this auto-encoder with large-scale real-world BRDF collections and ensure the smoothness of its latent space, which implicitly acts as a natural distribution of materials. During appearance modeling in text-to-3D generation, the latent BRDF embeddings, rather than BRDF parameters, are predicted via a material network. Through exhaustive experiments, our approach demonstrates the superiority over existing ones in generating realistic and coherent object materials. Moreover, high-quality materials naturally enable multiple downstream tasks such as relighting and material editing. Code and model will be publicly available at \url{https://sheldontsui.github.io/projects/Matlaber}.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Progression-Guided-Temporal-Action-Detection-in-Videos"><a href="#Progression-Guided-Temporal-Action-Detection-in-Videos" class="headerlink" title="Progression-Guided Temporal Action Detection in Videos"></a>Progression-Guided Temporal Action Detection in Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09268">http://arxiv.org/abs/2308.09268</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/makecent/apn">https://github.com/makecent/apn</a></li>
<li>paper_authors: Chongkai Lu, Man-Wai Mak, Ruimin Li, Zheru Chi, Hong Fu</li>
<li>For: The paper proposes a novel framework called Action Progression Network (APN) for temporal action detection (TAD) in videos.* Methods: The APN framework uses a complete action process to encode the temporal structure of actions, and trains a neural network to recognize the action progressions. The framework detects action boundaries by detecting complete action processes in the videos.* Results: The APN achieves competitive performance and significantly surpasses its counterparts in detecting long-lasting actions, with a mean Average Precision (mAP) of 58.3% on the THUMOS14 dataset and 98.9% mAP on the DFMAD70 dataset.Here’s the same information in Simplified Chinese text:* For: 本文提出了一种名为Action Progression Network (APN)的新框架，用于视频中的时间动作检测 (TAD)。* Methods: APN框架使用完整的动作进程来编码动作的时间结构，然后使用神经网络来识别动作进程。框架通过检测视频中的完整动作进程来检测动作边界。* Results: APN达到了竞争性的性能，并在检测持续时间的动作方面表现出色，THUMOS14 dataset上的mean Average Precision (mAP)为58.3%，DFMAD70 dataset上的mAP为98.9%。<details>
<summary>Abstract</summary>
We present a novel framework, Action Progression Network (APN), for temporal action detection (TAD) in videos. The framework locates actions in videos by detecting the action evolution process. To encode the action evolution, we quantify a complete action process into 101 ordered stages (0\%, 1\%, ..., 100\%), referred to as action progressions. We then train a neural network to recognize the action progressions. The framework detects action boundaries by detecting complete action processes in the videos, e.g., a video segment with detected action progressions closely follow the sequence 0\%, 1\%, ..., 100\%. The framework offers three major advantages: (1) Our neural networks are trained end-to-end, contrasting conventional methods that optimize modules separately; (2) The APN is trained using action frames exclusively, enabling models to be trained on action classification datasets and robust to videos with temporal background styles differing from those in training; (3) Our framework effectively avoids detecting incomplete actions and excels in detecting long-lasting actions due to the fine-grained and explicit encoding of the temporal structure of actions. Leveraging these advantages, the APN achieves competitive performance and significantly surpasses its counterparts in detecting long-lasting actions. With an IoU threshold of 0.5, the APN achieves a mean Average Precision (mAP) of 58.3\% on the THUMOS14 dataset and 98.9\% mAP on the DFMAD70 dataset.
</details>
<details>
<summary>摘要</summary>
我们提出了一个新的框架，即 Action Progression Network (APN)，用于视频中的时间动作检测（TAD）。这个框架通过检测动作进程来确定动作的位置。为了编码动作进程，我们将完整的动作过程分解为101个顺序阶段（0%、1%、...、100%），称之为动作进程。然后我们将神经网络训练以认识这些动作进程。框架通过检测视频中的完整动作进程来检测动作边界，例如视频段中的检测动作进程与序列0%、1%、...、100%的顺序匹配。框架具有以下三大优点：1. 我们的神经网络是通过端到端训练的，与传统方法不同，这些方法通常将模块分割并优化。2. APN使用唯一的动作帧进行训练，因此模型可以在动作分类数据集上训练，并且对视频中的时间背景样式不同于训练时的样式具有鲁棒性。3. 我们的框架可以准确地检测长时间的动作，因为它使用细化和明确的时间结构编码器，从而避免检测不完整的动作。通过这些优点，APN在检测长时间动作方面实现了竞争性的性能，并在THUMOS14和DFMAD70数据集上达到了98.9%的mAP和58.3%的mAP。
</details></li>
</ul>
<hr>
<h2 id="SparseBEV-High-Performance-Sparse-3D-Object-Detection-from-Multi-Camera-Videos"><a href="#SparseBEV-High-Performance-Sparse-3D-Object-Detection-from-Multi-Camera-Videos" class="headerlink" title="SparseBEV: High-Performance Sparse 3D Object Detection from Multi-Camera Videos"></a>SparseBEV: High-Performance Sparse 3D Object Detection from Multi-Camera Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09244">http://arxiv.org/abs/2308.09244</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mcg-nju/sparsebev">https://github.com/mcg-nju/sparsebev</a></li>
<li>paper_authors: Haisong Liu, Yao Teng, Tao Lu, Haiguang Wang, Limin Wang</li>
<li>for: This paper focuses on developing a fully sparse 3D object detector, SparseBEV, to mitigate the performance gap between sparse and dense detectors in camera-based 3D object detection.</li>
<li>methods: SparseBEV uses a query-based paradigm without explicit dense BEV feature construction, and includes three key designs: scale-adaptive self attention, adaptive spatio-temporal sampling, and adaptive mixing.</li>
<li>results: On the test split of nuScenes, SparseBEV achieves the state-of-the-art performance of 67.5 NDS. On the val split, SparseBEV achieves 55.8 NDS while maintaining a real-time inference speed of 23.5 FPS.<details>
<summary>Abstract</summary>
Camera-based 3D object detection in BEV (Bird's Eye View) space has drawn great attention over the past few years. Dense detectors typically follow a two-stage pipeline by first constructing a dense BEV feature and then performing object detection in BEV space, which suffers from complex view transformations and high computation cost. On the other side, sparse detectors follow a query-based paradigm without explicit dense BEV feature construction, but achieve worse performance than the dense counterparts. In this paper, we find that the key to mitigate this performance gap is the adaptability of the detector in both BEV and image space. To achieve this goal, we propose SparseBEV, a fully sparse 3D object detector that outperforms the dense counterparts. SparseBEV contains three key designs, which are (1) scale-adaptive self attention to aggregate features with adaptive receptive field in BEV space, (2) adaptive spatio-temporal sampling to generate sampling locations under the guidance of queries, and (3) adaptive mixing to decode the sampled features with dynamic weights from the queries. On the test split of nuScenes, SparseBEV achieves the state-of-the-art performance of 67.5 NDS. On the val split, SparseBEV achieves 55.8 NDS while maintaining a real-time inference speed of 23.5 FPS. Code is available at https://github.com/MCG-NJU/SparseBEV.
</details>
<details>
<summary>摘要</summary>
过去几年，基于 bird's eye view（BEV）空间的几何检测器在Camera-based 3D объек体检测领域中吸引了很大的注意力。紧密的检测器通常遵循一个 two-stage 管道，首先是在BEV空间建立紧密的BEV特征，然后进行 объек detection，这会受到复杂的视野转换和高计算成本的影响。另一方面，稀疏的检测器遵循一个查询基本的思想，不需要明确的紧密BEV特征建立，但是其性能较差。在这篇论文中，我们发现了关键是在BEV和图像空间中的检测器适应能力。为了实现这个目标，我们提出了SparseBEV，一个完全稀疏的3D几何检测器，它的性能比紧密检测器更高。SparseBEV包括三个关键设计，分别是（1）缩寸自适应的自我注意力，用于在BEV空间中缩寸特征的整合，（2）适应的空间-时间抽样，用于在寻找适当的抽样位置的指导，以及（3）适应的混合，用于将抽样结果与问题答案进行适应权重的混合。在nuScenes的测试分区上，SparseBEV实现了67.5 NDS的国际级别性能。在val分区上，SparseBEV实现了55.8 NDS，同时保持了实时推理速度的23.5 FPS。代码可以在https://github.com/MCG-NJU/SparseBEV上找到。
</details></li>
</ul>
<hr>
<h2 id="ASAG-Building-Strong-One-Decoder-Layer-Sparse-Detectors-via-Adaptive-Sparse-Anchor-Generation"><a href="#ASAG-Building-Strong-One-Decoder-Layer-Sparse-Detectors-via-Adaptive-Sparse-Anchor-Generation" class="headerlink" title="ASAG: Building Strong One-Decoder-Layer Sparse Detectors via Adaptive Sparse Anchor Generation"></a>ASAG: Building Strong One-Decoder-Layer Sparse Detectors via Adaptive Sparse Anchor Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09242">http://arxiv.org/abs/2308.09242</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/isee-laboratory/asag">https://github.com/isee-laboratory/asag</a></li>
<li>paper_authors: Shenghao Fu, Junkai Yan, Yipeng Gao, Xiaohua Xie, Wei-Shi Zheng</li>
<li>for: 提高 object detection 的速度和准确率， bridging the performance gap between sparse and dense detectors.</li>
<li>methods: 提出 Adaptive Sparse Anchor Generator (ASAG)， dynamically predicting anchors on patches rather than grids in a sparse way to alleviate feature conflict problem, and using a simple and effective Query Weighting method to ease the training instability.</li>
<li>results: 比较 dense-initialized ones 和其他方法，实现了更好的速度-准确率平衡，并且在实验中表现出色。<details>
<summary>Abstract</summary>
Recent sparse detectors with multiple, e.g. six, decoder layers achieve promising performance but much inference time due to complex heads. Previous works have explored using dense priors as initialization and built one-decoder-layer detectors. Although they gain remarkable acceleration, their performance still lags behind their six-decoder-layer counterparts by a large margin. In this work, we aim to bridge this performance gap while retaining fast speed. We find that the architecture discrepancy between dense and sparse detectors leads to feature conflict, hampering the performance of one-decoder-layer detectors. Thus we propose Adaptive Sparse Anchor Generator (ASAG) which predicts dynamic anchors on patches rather than grids in a sparse way so that it alleviates the feature conflict problem. For each image, ASAG dynamically selects which feature maps and which locations to predict, forming a fully adaptive way to generate image-specific anchors. Further, a simple and effective Query Weighting method eases the training instability from adaptiveness. Extensive experiments show that our method outperforms dense-initialized ones and achieves a better speed-accuracy trade-off. The code is available at \url{https://github.com/iSEE-Laboratory/ASAG}.
</details>
<details>
<summary>摘要</summary>
We find that the architecture discrepancy between dense and sparse detectors leads to feature conflict, hindering the performance of one-decoder-layer detectors. To address this, we propose the Adaptive Sparse Anchor Generator (ASAG), which predicts dynamic anchors on patches in a sparse way, alleviating the feature conflict problem. For each image, ASAG dynamically selects which feature maps and which locations to predict, forming a fully adaptive way to generate image-specific anchors.Further, we propose a simple and effective Query Weighting method to ease the training instability from adaptiveness. Extensive experiments show that our method outperforms dense-initialized ones and achieves a better speed-accuracy trade-off. The code is available at \url{https://github.com/iSEE-Laboratory/ASAG}.Translation notes:* "Recent sparse detectors" is translated as "近期的 sparse detectors" (jì qī de sparse detectors)* "multiple, e.g. six, decoder layers" is translated as "多个，例如六个，decoder层" (duō gè, yǐ jǐ liù gè, decoder layer)* "achieve promising performance" is translated as "实现了可能的表现" (shí yì le kě néng de biǎo xiǎng)* "but much inference time" is translated as "但是大量的推理时间" (dàn shì dà liú de tuī lǐ shí jiān)* "due to complex heads" is translated as "由于复杂的头部" (yūn guī zhī de tóu bù)* "Previous works have explored using dense priors as initialization" is translated as "先前的工作已经探索了使用密集的初始值" (xiān qian de gōng zuò yǐ jīn tàng zhī de chū shí zhì)* "built one-decoder-layer detectors" is translated as "构建了一层decoder的检测器" (gòng jìan le yī cè decoder de jiǎn téng)* "Although they gain remarkable acceleration" is translated as "尽管它们很快" (zhòu guàn tā men hěn kuài)* "their performance still lags behind their six-decoder-layer counterparts by a large margin" is translated as "它们的表现仍然落后六层decoder的对手 by a large margin" (tā men de biǎo xiǎng zhèng rán zài liù cè decoder de duì shǒu by a large margin)* "In this work, we aim to bridge this performance gap" is translated as "在这个工作中，我们目标是填补这个表现差距" (zài zhè ge gōng zuò, wǒmen mù tiāo shì fēn chōng zhè ge biǎo xiǎng jì dao)* "while retaining fast speed" is translated as "同时保持快速" (tóng shí bǎo qiú sù)* "We find that the architecture discrepancy between dense and sparse detectors leads to feature conflict" is translated as "我们发现 dense和sparse detector的 architecture difference导致 feature conflict" (wǒmen fā xiǎng dense yào sparse detector de architecture difference dào yùn feature conflict)* "hampering the performance of one-decoder-layer detectors" is translated as "妨碍一层decoder的检测器表现" (mèi yòu yī cè decoder de jiǎn téng biǎo xiǎng)* "Thus we propose Adaptive Sparse Anchor Generator (ASAG)" is translated as "因此我们提出 Adaptive Sparse Anchor Generator (ASAG)" (yīn qí wǒmen tī shuā Adaptive Sparse Anchor Generator (ASAG))* "which predicts dynamic anchors on patches in a sparse way" is translated as "可以在缺省的方式下预测动态的锚点" (kě yǐ zài yì qiū xiāng de fāng shí zhī xiǎng yì qiū yì zhī)* "alleviating the feature conflict problem" is translated as "解决 feature conflict 问题" (jiě jī feature conflict wèn tí)* "For each image, ASAG dynamically selects which feature maps and which locations to predict" is translated as "对于每个图像，ASAG动态选择哪些特征地图和哪些位置预测" (duì yú zhè ge hú xiàng, ASAG dòng tài xūn zhè yǐ qù zhì yǐ zhòng zhì)* "forming a fully adaptive way to generate image-specific anchors" is translated as "形成一种完全适应的方式来生成图像特定的锚点" (xíng chéng yī zhī qù zhì yǐ zhòng zhì)* "Further, we propose a simple and effective Query Weighting method" is translated as "另外，我们提出了一种简单有效的查询权重方法" (yīn qí, wǒmen tī shuā yī qiū yǒu yì de chá qiǎn zhèng yì)* "to ease the training instability from adaptiveness" is translated as "以适应性导致的训练不稳定性" (yǐ shì yì qiū xiāng de tào xiǎng shì)* "Extensive experiments show that our method outperforms dense-initialized ones" is translated as "广泛的实验表明我们的方法在 dense-initialized 方面表现出色" (guǎng fāng de shí yàn bǎng mìng wǒmen de fāng shì zài dense-initialized zhōng xiàng)* "and achieves a better speed-accuracy trade-off" is translated as "并实现了更好的速度-准确性质量比" (yǔ shì yì qiū yǐ zhèng yì qiū yì zhòng zhì)* "The code is available at \url{https://github.com/iSEE-Laboratory/ASAG}" is translated as "代码可以在 \url{https://github.com/iSEE-Laboratory/ASAG} 上获取" (dài māo kě yǐ zài \url{https://github.com/iSEE-Laboratory/ASAG} shàng gòu qǔ)
</details></li>
</ul>
<hr>
<h2 id="Deep-Boosting-Multi-Modal-Ensemble-Face-Recognition-with-Sample-Level-Weighting"><a href="#Deep-Boosting-Multi-Modal-Ensemble-Face-Recognition-with-Sample-Level-Weighting" class="headerlink" title="Deep Boosting Multi-Modal Ensemble Face Recognition with Sample-Level Weighting"></a>Deep Boosting Multi-Modal Ensemble Face Recognition with Sample-Level Weighting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09234">http://arxiv.org/abs/2308.09234</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sahar Rahimi Malakshan, Mohammad Saeed Ebrahimi Saadabadi, Nima Najafzadeh, Nasser M. Nasrabadi</li>
<li>for: 提高人脸识别（FR）模型的泛化能力，解决现有训练数据的质量不均问题。</li>
<li>methods: 使用多模型增强技术，即AdaBoost的sample-level weighting方法，使得不同模型在不同样本困难程度上拥有专家性。</li>
<li>results: 在CFP-FP、LFW、CPLFW、CALFW、AgeDB、TinyFace、IJB-B和IJB-C评估 datasets上实现了比 estado-of-the-art 性能。<details>
<summary>Abstract</summary>
Deep convolutional neural networks have achieved remarkable success in face recognition (FR), partly due to the abundant data availability. However, the current training benchmarks exhibit an imbalanced quality distribution; most images are of high quality. This poses issues for generalization on hard samples since they are underrepresented during training. In this work, we employ the multi-model boosting technique to deal with this issue. Inspired by the well-known AdaBoost, we propose a sample-level weighting approach to incorporate the importance of different samples into the FR loss. Individual models of the proposed framework are experts at distinct levels of sample hardness. Therefore, the combination of models leads to a robust feature extractor without losing the discriminability on the easy samples. Also, for incorporating the sample hardness into the training criterion, we analytically show the effect of sample mining on the important aspects of current angular margin loss functions, i.e., margin and scale. The proposed method shows superior performance in comparison with the state-of-the-art algorithms in extensive experiments on the CFP-FP, LFW, CPLFW, CALFW, AgeDB, TinyFace, IJB-B, and IJB-C evaluation datasets.
</details>
<details>
<summary>摘要</summary>
深度卷积神经网络在人脸识别（FR）领域取得了很大的成功，一部分是因为数据的充足性。然而，当前的训练标准 exhibit 一个不均衡的质量分布，大多数图像是高质量的。这会导致在训练中困难样本的代表性受到限制。在这种情况下，我们使用多模型增强技术来解决这个问题。我们提出了一种样本水平的权重方法，以便在 FR 损失中包含不同样本的重要性。具体来说，我们的框架中的各个模型是专家在不同水平上的样本困难程度。因此，将这些模型相加可以获得一个可靠的特征提取器，而不会失去易样本的把握。此外，为了在训练标准中包含样本困难程度，我们分析了现有的angular margin loss函数的重要方面，即边和缩放。我们的方法在大量的实验中表现出色，比如CFP-FP、LFW、CPLFW、CALFW、AgeDB、TinyFace、IJB-B 和 IJB-C 评估数据集。
</details></li>
</ul>
<hr>
<h2 id="CCFace-Classification-Consistency-for-Low-Resolution-Face-Recognition"><a href="#CCFace-Classification-Consistency-for-Low-Resolution-Face-Recognition" class="headerlink" title="CCFace: Classification Consistency for Low-Resolution Face Recognition"></a>CCFace: Classification Consistency for Low-Resolution Face Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09230">http://arxiv.org/abs/2308.09230</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Saeed Ebrahimi Saadabadi, Sahar Rahimi Malakshan, Hossein Kashiani, Nasser M. Nasrabadi</li>
<li>for: 提高低分辨率人脸识别的性能</li>
<li>methods: 使用分类一致知识塑造和适应角度罚款，以及异形跨分辨率学习</li>
<li>results: 在低分辨率benchmark上提高三个百分点，包括tinyface和scface等In English, this would be:</li>
<li>for: Improving the performance of low-resolution face recognition</li>
<li>methods: Using classification consistency knowledge distillation and adaptive angular penalty, as well as asymmetric cross-resolution learning</li>
<li>results: Improving performance by three percent on TinyFace and other low-resolution benchmarks while maintaining performance on high-resolution benchmarks.<details>
<summary>Abstract</summary>
In recent years, deep face recognition methods have demonstrated impressive results on in-the-wild datasets. However, these methods have shown a significant decline in performance when applied to real-world low-resolution benchmarks like TinyFace or SCFace. To address this challenge, we propose a novel classification consistency knowledge distillation approach that transfers the learned classifier from a high-resolution model to a low-resolution network. This approach helps in finding discriminative representations for low-resolution instances. To further improve the performance, we designed a knowledge distillation loss using the adaptive angular penalty inspired by the success of the popular angular margin loss function. The adaptive penalty reduces overfitting on low-resolution samples and alleviates the convergence issue of the model integrated with data augmentation. Additionally, we utilize an asymmetric cross-resolution learning approach based on the state-of-the-art semi-supervised representation learning paradigm to improve discriminability on low-resolution instances and prevent them from forming a cluster. Our proposed method outperforms state-of-the-art approaches on low-resolution benchmarks, with a three percent improvement on TinyFace while maintaining performance on high-resolution benchmarks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Generalized-Sum-Pooling-for-Metric-Learning"><a href="#Generalized-Sum-Pooling-for-Metric-Learning" class="headerlink" title="Generalized Sum Pooling for Metric Learning"></a>Generalized Sum Pooling for Metric Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09228">http://arxiv.org/abs/2308.09228</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yetigurbuz/generalized-sum-pooling">https://github.com/yetigurbuz/generalized-sum-pooling</a></li>
<li>paper_authors: Yeti Z. Gurbuz, Ozan Sener, A. Aydın Alatan</li>
<li>for: 该论文主要研究了深度度量学中的核心选择方法，即全局平均 pooling (GAP) 的扩展和改进。</li>
<li>methods: 该论文提出了一种名为泛化总和Pooling (GSP) 的新方法，它可以更好地选择Semantic entity，并学习每个 Semantic entity 的重要性。</li>
<li>results: 论文通过广泛的实验证明了 GSP 方法的效果，在四个Popular metric learning benchmark上表现出色，代替 GAP 方法可以更好地进行深度度量学。<details>
<summary>Abstract</summary>
A common architectural choice for deep metric learning is a convolutional neural network followed by global average pooling (GAP). Albeit simple, GAP is a highly effective way to aggregate information. One possible explanation for the effectiveness of GAP is considering each feature vector as representing a different semantic entity and GAP as a convex combination of them. Following this perspective, we generalize GAP and propose a learnable generalized sum pooling method (GSP). GSP improves GAP with two distinct abilities: i) the ability to choose a subset of semantic entities, effectively learning to ignore nuisance information, and ii) learning the weights corresponding to the importance of each entity. Formally, we propose an entropy-smoothed optimal transport problem and show that it is a strict generalization of GAP, i.e., a specific realization of the problem gives back GAP. We show that this optimization problem enjoys analytical gradients enabling us to use it as a direct learnable replacement for GAP. We further propose a zero-shot loss to ease the learning of GSP. We show the effectiveness of our method with extensive evaluations on 4 popular metric learning benchmarks. Code is available at: GSP-DML Framework
</details>
<details>
<summary>摘要</summary>
通常的建筑设计 для深度度量学是使用卷积神经网络后跟global average pooling（GAP）。尽管简单，但GAP是一种非常有效的信息汇总方法。一种可能的解释是每个特征向量都代表着不同的semantic entity，GAP是这些entity的 convex combination。基于这种视角，我们总结GAP并提出了一种可学习的总和汇总方法（GSP）。GSP在两个方面提高了GAP：一是选择一 subset of semantic entities，有效地忽略干扰信息；二是学习每个entity的重要性的权重。我们提出了一个 Entropy-smoothed optimal transport problem，并证明它是GAP的严格泛化，即一个特定的实现问题可以得回GAP。我们还提出了一个零战损损失函数，以便学习GSP。我们通过对4个popular度量学benchmark进行广泛的评估，证明了我们的方法的效果。代码可以在：GSP-DML框架中找到。
</details></li>
</ul>
<hr>
<h2 id="DMCVR-Morphology-Guided-Diffusion-Model-for-3D-Cardiac-Volume-Reconstruction"><a href="#DMCVR-Morphology-Guided-Diffusion-Model-for-3D-Cardiac-Volume-Reconstruction" class="headerlink" title="DMCVR: Morphology-Guided Diffusion Model for 3D Cardiac Volume Reconstruction"></a>DMCVR: Morphology-Guided Diffusion Model for 3D Cardiac Volume Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09223">http://arxiv.org/abs/2308.09223</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hexiaoxiao-cs/dmcvr">https://github.com/hexiaoxiao-cs/dmcvr</a></li>
<li>paper_authors: Xiaoxiao He, Chaowei Tan, Ligong Han, Bo Liu, Leon Axel, Kang Li, Dimitris N. Metaxas</li>
<li>for: 提高心脏疾病诊断和治疗规划的准确3D心脏重建</li>
<li>methods: 使用形态导航推 diffusion模型（DMCVR）Synthesize高解度2D图像和对应的3D重建体积</li>
<li>results: 比前方法高效，能生成高解度3D心脏MRI重建图像，提高心脏疾病诊断和治疗规划的准确性<details>
<summary>Abstract</summary>
Accurate 3D cardiac reconstruction from cine magnetic resonance imaging (cMRI) is crucial for improved cardiovascular disease diagnosis and understanding of the heart's motion. However, current cardiac MRI-based reconstruction technology used in clinical settings is 2D with limited through-plane resolution, resulting in low-quality reconstructed cardiac volumes. To better reconstruct 3D cardiac volumes from sparse 2D image stacks, we propose a morphology-guided diffusion model for 3D cardiac volume reconstruction, DMCVR, that synthesizes high-resolution 2D images and corresponding 3D reconstructed volumes. Our method outperforms previous approaches by conditioning the cardiac morphology on the generative model, eliminating the time-consuming iterative optimization process of the latent code, and improving generation quality. The learned latent spaces provide global semantics, local cardiac morphology and details of each 2D cMRI slice with highly interpretable value to reconstruct 3D cardiac shape. Our experiments show that DMCVR is highly effective in several aspects, such as 2D generation and 3D reconstruction performance. With DMCVR, we can produce high-resolution 3D cardiac MRI reconstructions, surpassing current techniques. Our proposed framework has great potential for improving the accuracy of cardiac disease diagnosis and treatment planning. Code can be accessed at https://github.com/hexiaoxiao-cs/DMCVR.
</details>
<details>
<summary>摘要</summary>
精确的3D心脏重建从cinematic magnetic resonance imaging（cMRI）是诊断心血管疾病和心脏运动的关键。然而，现有的心脏MRI基于的重建技术在临床设置中只有2D的限制 Through-plane 分辨率，导致低质量重建的心脏体积。为了更好地从稀疏的2D图像堆栈中重建3D心脏体积，我们提议一种基于形态指导的分子模型，DMCVR，该模型可以生成高分辨率的2D图像和对应的3D重建体积。我们的方法比前一代方法更高效，因为它们 conditioning cardiac morphology 在生成模型中，消除耗时的迭代优化过程，并提高生成质量。学习的秘密空间提供了全球 semantics，局部心脏形态和每个2D cMRI slice 的高可读性，以重建3D心脏形态。我们的实验表明，DMCVR 在多个方面表现出色，如2D生成和3D重建性能。通过 DMCVR，我们可以生成高分辨率的3D心脏MRI重建，超过当前技术。我们提出的框架具有较大的诊断心血管疾病和治疗规划的潜在优势。代码可以在https://github.com/hexiaoxiao-cs/DMCVR 中获取。
</details></li>
</ul>
<hr>
<h2 id="A-review-of-technical-factors-to-consider-when-designing-neural-networks-for-semantic-segmentation-of-Earth-Observation-imagery"><a href="#A-review-of-technical-factors-to-consider-when-designing-neural-networks-for-semantic-segmentation-of-Earth-Observation-imagery" class="headerlink" title="A review of technical factors to consider when designing neural networks for semantic segmentation of Earth Observation imagery"></a>A review of technical factors to consider when designing neural networks for semantic segmentation of Earth Observation imagery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09221">http://arxiv.org/abs/2308.09221</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sam Khallaghi, J. Ronald Eastman, Lyndon D. Estes</li>
<li>for: 本文旨在提供对遥感图像semantic segmentation（分类） tasks的技术因素的全面审查，帮助研究人员和实践者更好地理解这个领域中的 neural network 设计因素。</li>
<li>methods: 本文详细介绍了 CNNs、RNNs、GANs 和 transformer 模型，并讨论了这些 ANN 家族中的显著设计特征和其对 semantic segmentation 的影响。同时，也涵盖了常见的预处理技术，包括图像normalization和chipping，以及如何处理训练样本数据不均衡的问题，以及如何使用扩展学习、转移学习和领域适应来解决有限数据的问题。</li>
<li>results: 本文提供了一个全面和最新的理解，涵盖了遥感图像semantic segmentation tasks中 neural network 设计因素的技术和数据相关因素。<details>
<summary>Abstract</summary>
Semantic segmentation (classification) of Earth Observation imagery is a crucial task in remote sensing. This paper presents a comprehensive review of technical factors to consider when designing neural networks for this purpose. The review focuses on Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), Generative Adversarial Networks (GANs), and transformer models, discussing prominent design patterns for these ANN families and their implications for semantic segmentation. Common pre-processing techniques for ensuring optimal data preparation are also covered. These include methods for image normalization and chipping, as well as strategies for addressing data imbalance in training samples, and techniques for overcoming limited data, including augmentation techniques, transfer learning, and domain adaptation. By encompassing both the technical aspects of neural network design and the data-related considerations, this review provides researchers and practitioners with a comprehensive and up-to-date understanding of the factors involved in designing effective neural networks for semantic segmentation of Earth Observation imagery.
</details>
<details>
<summary>摘要</summary>
Semantic segmentation (classification) of Earth Observation imagery 是 remote sensing 领域中的一个重要任务。本文将提供 Earth Observation imagery 中 neural networks 的设计因素的 comprehensive 综述，包括 Convolutional Neural Networks (CNNs)、Recurrent Neural Networks (RNNs)、Generative Adversarial Networks (GANs) 和 transformer 模型，并讨论这些 ANN 家族的主要设计模式以及它们在 semantic segmentation 中的应用。本文还讨论了一些常见的预processing 技术，包括图像 normalization 和扩展、训练数据均衡问题的解决方案、以及对于有限数据的处理方法，包括扩展技术、传播学习以及领域适应。本文涵盖了 neural network 设计的技术性和数据相关的考虑因素，以提供研究者和实践者一个完整和最新的理解，对 Earth Observation imagery 中 neural networks 的设计为 semantic segmentation 做出更有效的应用。
</details></li>
</ul>
<hr>
<h2 id="LibreFace-An-Open-Source-Toolkit-for-Deep-Facial-Expression-Analysis"><a href="#LibreFace-An-Open-Source-Toolkit-for-Deep-Facial-Expression-Analysis" class="headerlink" title="LibreFace: An Open-Source Toolkit for Deep Facial Expression Analysis"></a>LibreFace: An Open-Source Toolkit for Deep Facial Expression Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10713">http://arxiv.org/abs/2308.10713</a></li>
<li>repo_url: None</li>
<li>paper_authors: Di Chang, Yufeng Yin, Zongjian Li, Minh Tran, Mohammad Soleymani</li>
<li>for: 这个论文主要目的是提出一个开源的人工智能工具kit，用于实时和离线的表情分析。</li>
<li>methods: 这个工具kit使用了深度学习模型，包括表情动作单元（AU）检测、AU强度估计和表情识别。具体来说，我们使用了一个大规模预训练的网络、特征知识填充和任务特定的细化调整等技术，以便准确地分析人脸表情。</li>
<li>results: 在Action Unit（AU）强度估计方面，我们在DISFA上达到了0.63的佩森相关系数（PCC），比OpenFace 2.0的性能高7%，同时保持高效的推理，运行速度两倍于OpenFace 2.0。尽管占用空间小，我们的模型也能够与当前最佳表情分析方法在AffecNet、FFHQ和RAFDB等 datasets上达到竞争性表现。<details>
<summary>Abstract</summary>
Facial expression analysis is an important tool for human-computer interaction. In this paper, we introduce LibreFace, an open-source toolkit for facial expression analysis. This open-source toolbox offers real-time and offline analysis of facial behavior through deep learning models, including facial action unit (AU) detection, AU intensity estimation, and facial expression recognition. To accomplish this, we employ several techniques, including the utilization of a large-scale pre-trained network, feature-wise knowledge distillation, and task-specific fine-tuning. These approaches are designed to effectively and accurately analyze facial expressions by leveraging visual information, thereby facilitating the implementation of real-time interactive applications. In terms of Action Unit (AU) intensity estimation, we achieve a Pearson Correlation Coefficient (PCC) of 0.63 on DISFA, which is 7% higher than the performance of OpenFace 2.0 while maintaining highly-efficient inference that runs two times faster than OpenFace 2.0. Despite being compact, our model also demonstrates competitive performance to state-of-the-art facial expression analysis methods on AffecNet, FFHQ, and RAFDB. Our code will be released at https://github.com/ihp-lab/LibreFace
</details>
<details>
<summary>摘要</summary>
Facial expression analysis is an important tool for human-computer interaction. In this paper, we introduce LibreFace, an open-source toolkit for facial expression analysis. This open-source toolbox offers real-time and offline analysis of facial behavior through deep learning models, including facial action unit (AU) detection, AU intensity estimation, and facial expression recognition. To accomplish this, we employ several techniques, including the utilization of a large-scale pre-trained network, feature-wise knowledge distillation, and task-specific fine-tuning. These approaches are designed to effectively and accurately analyze facial expressions by leveraging visual information, thereby facilitating the implementation of real-time interactive applications. In terms of Action Unit (AU) intensity estimation, we achieve a Pearson Correlation Coefficient (PCC) of 0.63 on DISFA, which is 7% higher than the performance of OpenFace 2.0 while maintaining highly-efficient inference that runs two times faster than OpenFace 2.0. Despite being compact, our model also demonstrates competitive performance to state-of-the-art facial expression analysis methods on AffecNet, FFHQ, and RAFDB. Our code will be released at https://github.com/ihp-lab/LibreFace.
</details></li>
</ul>
<hr>
<h2 id="TinyProp-–-Adaptive-Sparse-Backpropagation-for-Efficient-TinyML-On-device-Learning"><a href="#TinyProp-–-Adaptive-Sparse-Backpropagation-for-Efficient-TinyML-On-device-Learning" class="headerlink" title="TinyProp – Adaptive Sparse Backpropagation for Efficient TinyML On-device Learning"></a>TinyProp – Adaptive Sparse Backpropagation for Efficient TinyML On-device Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09201">http://arxiv.org/abs/2308.09201</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marcus Rüb, Daniel Maier, Daniel Mueller-Gritschneder, Axel Sikora</li>
<li>for: 这篇论文主要目的是提出一种可以在低功耗微控制器单元（MCU）上进行Device Learning或精益化的深度神经网络训练方法，以减少训练时间和计算负载。</li>
<li>methods: 这篇论文使用了一种名为TinyProp的简单传播方法，这个方法可以在MCU上进行Device Learning，并且可以在训练过程中动态地调整传播比例，以提高训练效率和精确性。</li>
<li>results: 根据论文的结果，TinyProp比非简单训练更快，并且可以保持精确性。具体来说，与非简单训练相比，TinyProp在三个数据集（MNIST、DCASE2020和CIFAR10）上的训练时间比例为5倍，并且仅受到轻微的计算过程影响。此外，TinyProp与现有的静态简单传播方法相比，在训练效率和精确性方面都有优势。<details>
<summary>Abstract</summary>
Training deep neural networks using backpropagation is very memory and computationally intensive. This makes it difficult to run on-device learning or fine-tune neural networks on tiny, embedded devices such as low-power micro-controller units (MCUs). Sparse backpropagation algorithms try to reduce the computational load of on-device learning by training only a subset of the weights and biases. Existing approaches use a static number of weights to train. A poor choice of this so-called backpropagation ratio limits either the computational gain or can lead to severe accuracy losses. In this paper we present TinyProp, the first sparse backpropagation method that dynamically adapts the back-propagation ratio during on-device training for each training step. TinyProp induces a small calculation overhead to sort the elements of the gradient, which does not significantly impact the computational gains. TinyProp works particularly well on fine-tuning trained networks on MCUs, which is a typical use case for embedded applications. For typical datasets from three datasets MNIST, DCASE2020 and CIFAR10, we are 5 times faster compared to non-sparse training with an accuracy loss of on average 1%. On average, TinyProp is 2.9 times faster than existing, static sparse backpropagation algorithms and the accuracy loss is reduced on average by 6 % compared to a typical static setting of the back-propagation ratio.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用深度神经网络进行训练是非常占用内存和计算资源的。这使得在低功耗微控制器单元（MCU）上进行设备学习或细化神经网络 become difficult。使用 sparse backpropagation 算法可以减少设备学习中的计算负担，但现有方法使用静态的 backpropagation 比率，这限制了计算减少或导致精度损失。在这篇论文中，我们提出了 TinyProp，第一个在设备学习过程中动态调整 backpropagation 比率的稀疏 backpropagation 方法。TinyProp 在MCU 上进行设备学习时具有较小的计算开销，并不会对计算减少的影响。TinyProp 在微controller 上进行 fine-tuning 神经网络时表现特别好，这是常见的嵌入式应用场景。对于 Typical datasets  MNIST、DCASE2020 和 CIFAR10，我们比非稀疏训练更快，减少了平均1%的精度损失。与现有静态稀疐 backpropagation 算法相比，TinyProp 在平均上2.9倍快，并且在平均上减少了6%的精度损失。
</details></li>
</ul>
<hr>
<h2 id="FedPerfix-Towards-Partial-Model-Personalization-of-Vision-Transformers-in-Federated-Learning"><a href="#FedPerfix-Towards-Partial-Model-Personalization-of-Vision-Transformers-in-Federated-Learning" class="headerlink" title="FedPerfix: Towards Partial Model Personalization of Vision Transformers in Federated Learning"></a>FedPerfix: Towards Partial Model Personalization of Vision Transformers in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09160">http://arxiv.org/abs/2308.09160</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/imguangyu/fedperfix">https://github.com/imguangyu/fedperfix</a></li>
<li>paper_authors: Guangyu Sun, Matias Mendieta, Jun Luo, Shandong Wu, Chen Chen</li>
<li>for: 提高分布式学习的效率和个性化性</li>
<li>methods: 研究如何在Vision Transformer（ViT）模型中部分个性化，并提出了一种基于插件的方法—FedPerfix</li>
<li>results: 在CIFAR-100、OrganAMNIST和Office-Home等 datasets上进行了实验，并证明了该方法可以与多种先进的分布式学习方法相比提高模型的性能<details>
<summary>Abstract</summary>
Personalized Federated Learning (PFL) represents a promising solution for decentralized learning in heterogeneous data environments. Partial model personalization has been proposed to improve the efficiency of PFL by selectively updating local model parameters instead of aggregating all of them. However, previous work on partial model personalization has mainly focused on Convolutional Neural Networks (CNNs), leaving a gap in understanding how it can be applied to other popular models such as Vision Transformers (ViTs). In this work, we investigate where and how to partially personalize a ViT model. Specifically, we empirically evaluate the sensitivity to data distribution of each type of layer. Based on the insights that the self-attention layer and the classification head are the most sensitive parts of a ViT, we propose a novel approach called FedPerfix, which leverages plugins to transfer information from the aggregated model to the local client as a personalization. Finally, we evaluate the proposed approach on CIFAR-100, OrganAMNIST, and Office-Home datasets and demonstrate its effectiveness in improving the model's performance compared to several advanced PFL methods.
</details>
<details>
<summary>摘要</summary>
个人化联合学习（PFL）表示在不同数据环境中分布式学习的有优解决方案。部分模型个性化已被提议以提高PFL的效率，但以前的工作主要集中在卷积神经网络（CNNs）上，对其他受欢迎的模型，如视觉变换器（ViTs），的应用仍然存在知识空白。在这种情况下，我们调查了在ViT模型中可以 selectively更新的部分。 Specifically, we empirically evaluated the sensitivity of each type of layer to data distribution. Based on the findings that the self-attention layer and the classification head are the most sensitive parts of a ViT, we proposed a novel approach called FedPerfix, which leverages plugins to transfer information from the aggregated model to the local client as a personalization. Finally, we evaluated the proposed approach on CIFAR-100, OrganAMNIST, and Office-Home datasets and demonstrated its effectiveness in improving the model's performance compared to several advanced PFL methods.
</details></li>
</ul>
<hr>
<h2 id="Semi-sparsity-Priors-for-Image-Structure-Analysis-and-Extraction"><a href="#Semi-sparsity-Priors-for-Image-Structure-Analysis-and-Extraction" class="headerlink" title="Semi-sparsity Priors for Image Structure Analysis and Extraction"></a>Semi-sparsity Priors for Image Structure Analysis and Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09141">http://arxiv.org/abs/2308.09141</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junqing Huang, Haihui Wang, Michael Ruzhansky</li>
<li>for: 图像结构分割和图像分类</li>
<li>methods: 通过总体半稀疑函数框架，将图像结构与复杂的质地背景解耦开来</li>
<li>results: 能够保持图像结构，不会出现波动融合现象，同时能够处理强抗振荡的图像文化分割问题，并且可以与现代方法相比肤<details>
<summary>Abstract</summary>
Image structure-texture decomposition is a long-standing and fundamental problem in both image processing and computer vision fields. In this paper, we propose a generalized semi-sparse regularization framework for image structural analysis and extraction, which allows us to decouple the underlying image structures from complicated textural backgrounds. Combining with different textural analysis models, such a regularization receives favorable properties differing from many traditional methods. We demonstrate that it is not only capable of preserving image structures without introducing notorious staircase artifacts in polynomial-smoothing surfaces but is also applicable for decomposing image textures with strong oscillatory patterns. Moreover, we also introduce an efficient numerical solution based on an alternating direction method of multipliers (ADMM) algorithm, which gives rise to a simple and maneuverable way for image structure-texture decomposition. The versatility of the proposed method is finally verified by a series of experimental results with the capability of producing comparable or superior image decomposition results against cutting-edge methods.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:图像结构-文本分解是图像处理和计算机视觉领域的一个长期和基本问题。在这篇论文中，我们提出了一种通用半稀畴化常数执行框架，用于图像结构分析和提取。这种常数执行允许我们将图像结构从复杂的文本背景中分离出来。与不同的文本分析模型结合，这种常数执行具有不同于许多传统方法的优点。我们示示它不仅可以保留图像结构，而且可以避免引入普遍存在的梯形artefacts在多阶趋正面上。此外，我们还介绍了一种高效的数字解决方案，基于分配方法 OF 多个参数（ADMM）算法，这给出了一种简单可操作的图像结构-文本分解方法。我们的方法的多样性最终被实验证明，可以生成与当今顶尖方法相当或更好的图像分解结果。
</details></li>
</ul>
<hr>
<h2 id="The-Unreasonable-Effectiveness-of-Large-Language-Vision-Models-for-Source-free-Video-Domain-Adaptation"><a href="#The-Unreasonable-Effectiveness-of-Large-Language-Vision-Models-for-Source-free-Video-Domain-Adaptation" class="headerlink" title="The Unreasonable Effectiveness of Large Language-Vision Models for Source-free Video Domain Adaptation"></a>The Unreasonable Effectiveness of Large Language-Vision Models for Source-free Video Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09139">http://arxiv.org/abs/2308.09139</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/giaczara/dallv">https://github.com/giaczara/dallv</a></li>
<li>paper_authors: Giacomo Zara, Alessandro Conti, Subhankar Roy, Stéphane Lathuilière, Paolo Rota, Elisa Ricci</li>
<li>for: 这篇论文旨在解决无监督目标数据集上的动作识别模型转移，并且不需要存取实际的源数据。</li>
<li>methods: 这篇论文使用了大型语言视觉模型（LLVM）的“网络超级vision”来推广SFVUDA任务，并且提出了一个叫做“Domain Adaptation with Large Language-Vision models”的方法（简称DALL-V），将 LLVM 的世界假设和补充性源模型信息转换为适应target的学习网络。</li>
<li>results:  despite the simplicity, DALL-V 可以实现显著的提升 compared to 目前的SFVUDA方法。<details>
<summary>Abstract</summary>
Source-Free Video Unsupervised Domain Adaptation (SFVUDA) task consists in adapting an action recognition model, trained on a labelled source dataset, to an unlabelled target dataset, without accessing the actual source data. The previous approaches have attempted to address SFVUDA by leveraging self-supervision (e.g., enforcing temporal consistency) derived from the target data itself. In this work, we take an orthogonal approach by exploiting "web-supervision" from Large Language-Vision Models (LLVMs), driven by the rationale that LLVMs contain a rich world prior surprisingly robust to domain-shift. We showcase the unreasonable effectiveness of integrating LLVMs for SFVUDA by devising an intuitive and parameter-efficient method, which we name Domain Adaptation with Large Language-Vision models (DALL-V), that distills the world prior and complementary source model information into a student network tailored for the target. Despite the simplicity, DALL-V achieves significant improvement over state-of-the-art SFVUDA methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ICAR-Image-based-Complementary-Auto-Reasoning"><a href="#ICAR-Image-based-Complementary-Auto-Reasoning" class="headerlink" title="ICAR: Image-based Complementary Auto Reasoning"></a>ICAR: Image-based Complementary Auto Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09119">http://arxiv.org/abs/2308.09119</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xijun Wang, Anqi Liang, Junbang Liang, Ming Lin, Yu Lou, Shan Yang</li>
<li>for:  addresses the challenging task of scene-aware complementary item retrieval (CIR), which requires generating a set of compatible items across domains.</li>
<li>methods:  proposes a visual compatibility concept based on similarity and complementarity, and a category-aware Flexible Bidirectional Transformer (FBT) framework for visual “scene-based set compatibility reasoning” with cross-domain visual similarity input and auto-regressive complementary item generation.</li>
<li>results:  achieves up to 5.3% and 9.6% in FITB score and 22.3% and 31.8% SFID improvement on fashion and furniture, respectively, compared with state-of-the-art methods.<details>
<summary>Abstract</summary>
Scene-aware Complementary Item Retrieval (CIR) is a challenging task which requires to generate a set of compatible items across domains. Due to the subjectivity, it is difficult to set up a rigorous standard for both data collection and learning objectives. To address this challenging task, we propose a visual compatibility concept, composed of similarity (resembling in color, geometry, texture, and etc.) and complementarity (different items like table vs chair completing a group). Based on this notion, we propose a compatibility learning framework, a category-aware Flexible Bidirectional Transformer (FBT), for visual "scene-based set compatibility reasoning" with the cross-domain visual similarity input and auto-regressive complementary item generation. We introduce a "Flexible Bidirectional Transformer (FBT)" consisting of an encoder with flexible masking, a category prediction arm, and an auto-regressive visual embedding prediction arm. And the inputs for FBT are cross-domain visual similarity invariant embeddings, making this framework quite generalizable. Furthermore, our proposed FBT model learns the inter-object compatibility from a large set of scene images in a self-supervised way. Compared with the SOTA methods, this approach achieves up to 5.3% and 9.6% in FITB score and 22.3% and 31.8% SFID improvement on fashion and furniture, respectively.
</details>
<details>
<summary>摘要</summary>
Scene-aware Complementary Item Retrieval (CIR) 是一个复杂的任务，需要生成兼容性的项目领域之间。由于主观性，设置严格的数据采集标准和学习目标很难。为解决这个挑战，我们提出了视觉兼容性概念，包括相似性（颜色、形状、文本等的相似性）和补充性（如桌子和椅子完成一组）。基于这个概念，我们提议一种兼容学习框架，一种类型意识的灵活双向Transformer（FBT），用于视觉“场景基于集合兼容理解”，输入为跨领域视觉相似性无关的嵌入，并使用自动生成的补充项。我们的FBT模型包括一个灵活的面罩，一个类型预测臂，和一个自动生成视觉嵌入预测臂。我们的输入是跨领域视觉相似性无关的嵌入，使得这个框架非常普适。此外，我们的FBT模型从大量场景图像中学习了各对象之间的相互兼容性，自然地实现了Scene-aware CIR。相比 соState-of-the-art方法，我们的方法可以达到5.3%和9.6%的FITB分数提升和22.3%和31.8%的SFID提升在时尚和家具等领域。
</details></li>
</ul>
<hr>
<h2 id="JPEG-Quantized-Coefficient-Recovery-via-DCT-Domain-Spatial-Frequential-Transformer"><a href="#JPEG-Quantized-Coefficient-Recovery-via-DCT-Domain-Spatial-Frequential-Transformer" class="headerlink" title="JPEG Quantized Coefficient Recovery via DCT Domain Spatial-Frequential Transformer"></a>JPEG Quantized Coefficient Recovery via DCT Domain Spatial-Frequential Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09110">http://arxiv.org/abs/2308.09110</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingyu Ouyang, Zhenzhong Chen</li>
<li>for: 提高JPEG压缩图像的Restoration效果，并能处理各种压缩质因子。</li>
<li>methods: 提出了DCT域的Transformer模型， dual-branch架构用于捕捉空间频率相关性，并采用量化矩阵嵌入和同步颜色卷积。</li>
<li>results: 与当前状态的JPEG噪声除法相比，提高了Restoration效果。<details>
<summary>Abstract</summary>
JPEG compression adopts the quantization of Discrete Cosine Transform (DCT) coefficients for effective bit-rate reduction, whilst the quantization could lead to a significant loss of important image details. Recovering compressed JPEG images in the frequency domain has attracted more and more attention recently, in addition to numerous restoration approaches developed in the pixel domain. However, the current DCT domain methods typically suffer from limited effectiveness in handling a wide range of compression quality factors, or fall short in recovering sparse quantized coefficients and the components across different colorspace. To address these challenges, we propose a DCT domain spatial-frequential Transformer, named as DCTransformer. Specifically, a dual-branch architecture is designed to capture both spatial and frequential correlations within the collocated DCT coefficients. Moreover, we incorporate the operation of quantization matrix embedding, which effectively allows our single model to handle a wide range of quality factors, and a luminance-chrominance alignment head that produces a unified feature map to align different-sized luminance and chrominance components. Our proposed DCTransformer outperforms the current state-of-the-art JPEG artifact removal techniques, as demonstrated by our extensive experiments.
</details>
<details>
<summary>摘要</summary>
JPEG压缩使用Discrete Cosine Transform（DCT）系数归一化来实现有效的比特率减少，但这可能导致重要的图像细节丢失。在频域中恢复压缩JPEG图像已经引起了更多的关注，同时出现了许多像素领域的恢复方法。然而，当前的DCT频域方法通常具有处理各种压缩质量因子的有限效果，或者缺乏恢复粗化quantized均值和不同色彩空间中的组件。为解决这些挑战，我们提议了DCT频域的空间-频率Transformer，称为DCTransformer。具体来说，我们设计了双支架构，以捕捉DCT系数中的空间和频率相关性。此外，我们还包含了量化矩阵嵌入操作，可以有效地让我们的单个模型处理各种质量因子，以及颜色彩空间中的一致性头，可以生成一个统一的特征图来对不同大小的颜色和灰度组件进行对齐。我们的提议的DCTransformer比当前状态的JPEG噪声去除技术高效，如我们的广泛的实验所示。
</details></li>
</ul>
<hr>
<h2 id="Hyperbolic-Face-Anti-Spoofing"><a href="#Hyperbolic-Face-Anti-Spoofing" class="headerlink" title="Hyperbolic Face Anti-Spoofing"></a>Hyperbolic Face Anti-Spoofing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09107">http://arxiv.org/abs/2308.09107</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuangpeng Han, Rizhao Cai, Yawen Cui, Zitong Yu, Yongjian Hu, Alex Kot</li>
<li>for: 本研究旨在提高面Recognition系统的安全性，通过学习泛化化脸认证防 spoofing (FAS) 模型，对于训练数据中未seen的攻击进行检测。</li>
<li>methods: 本研究提出了一种基于 hyperbolic space 的 FAS 学习方法，包括将特征编码项 проекed 到 Poincaré 球中，然后使用 hyperbolic binary logistic regression 层进行分类。为了进一步提高泛化能力，我们还实现了 hyperbolic contrastive learning 方法，并对 bonafide 进行了 relaxation 操作。此外，我们还提出了一种新的特征clipping方法，以解决 hyperbolic 空间中的衰减Gradient问题。</li>
<li>results: 实验表明，提出的方法可以与 Euclidean 基eline 相比，在未seen 攻击检测中带来显著的改善。此外，我们还发现，该方法在四个 benchmark dataset （i.e., MSU-MFSD, IDIAP REPLAY-ATTACK, CASIA-FASD, 和 OULU-NPU）上也具有良好的泛化能力。<details>
<summary>Abstract</summary>
Learning generalized face anti-spoofing (FAS) models against presentation attacks is essential for the security of face recognition systems. Previous FAS methods usually encourage models to extract discriminative features, of which the distances within the same class (bonafide or attack) are pushed close while those between bonafide and attack are pulled away. However, these methods are designed based on Euclidean distance, which lacks generalization ability for unseen attack detection due to poor hierarchy embedding ability. According to the evidence that different spoofing attacks are intrinsically hierarchical, we propose to learn richer hierarchical and discriminative spoofing cues in hyperbolic space. Specifically, for unimodal FAS learning, the feature embeddings are projected into the Poincar\'e ball, and then the hyperbolic binary logistic regression layer is cascaded for classification. To further improve generalization, we conduct hyperbolic contrastive learning for the bonafide only while relaxing the constraints on diverse spoofing attacks. To alleviate the vanishing gradient problem in hyperbolic space, a new feature clipping method is proposed to enhance the training stability of hyperbolic models. Besides, we further design a multimodal FAS framework with Euclidean multimodal feature decomposition and hyperbolic multimodal feature fusion & classification. Extensive experiments on three benchmark datasets (i.e., WMCA, PADISI-Face, and SiW-M) with diverse attack types demonstrate that the proposed method can bring significant improvement compared to the Euclidean baselines on unseen attack detection. In addition, the proposed framework is also generalized well on four benchmark datasets (i.e., MSU-MFSD, IDIAP REPLAY-ATTACK, CASIA-FASD, and OULU-NPU) with a limited number of attack types.
</details>
<details>
<summary>摘要</summary>
学习通用面部防伪模型（FAS）对于攻击推送是face recognition系统安全的基础。过去的FAS方法通常会让模型提取特征，其中同类（bonafide或攻击）之间的距离压缩，而不同类之间的距离弹性地压缩。但这些方法基于欧几丁度距离，lack generalization ability for unseen attack detection due to poor hierarchy embedding ability。根据不同的骗术攻击是内在层次结构的证据，我们提议学习更加具有层次结构和特征的骗术攻击特征在希腊空间。specifically，for unimodal FAS learning, the feature embeddings are projected into the Poincaré ball, and then the hyperbolic binary logistic regression layer is cascaded for classification. To further improve generalization, we conduct hyperbolic contrastive learning for the bonafide only while relaxing the constraints on diverse spoofing attacks. To alleviate the vanishing gradient problem in hyperbolic space, a new feature clipping method is proposed to enhance the training stability of hyperbolic models. Besides, we further design a multimodal FAS framework with Euclidean multimodal feature decomposition and hyperbolic multimodal feature fusion & classification. Extensive experiments on three benchmark datasets (i.e., WMCA, PADISI-Face, and SiW-M) with diverse attack types demonstrate that the proposed method can bring significant improvement compared to the Euclidean baselines on unseen attack detection. In addition, the proposed framework is also generalized well on four benchmark datasets (i.e., MSU-MFSD, IDIAP REPLAY-ATTACK, CASIA-FASD, and OULU-NPU) with a limited number of attack types.
</details></li>
</ul>
<hr>
<h2 id="Learning-Lightweight-Object-Detectors-via-Multi-Teacher-Progressive-Distillation"><a href="#Learning-Lightweight-Object-Detectors-via-Multi-Teacher-Progressive-Distillation" class="headerlink" title="Learning Lightweight Object Detectors via Multi-Teacher Progressive Distillation"></a>Learning Lightweight Object Detectors via Multi-Teacher Progressive Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09105">http://arxiv.org/abs/2308.09105</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shengcao Cao, Mengtian Li, James Hays, Deva Ramanan, Yi-Xiong Wang, Liang-Yan Gui</li>
<li>for: 提高资源受限的视觉系统中的检测和分割精度，使用知识储存技术来提高轻量级视觉模型的性能。</li>
<li>methods: 提出了一种简单 yet 有效的顺序方法，通过将多个教师模型转化为一个学生模型来逐渐传递知识。</li>
<li>results: 成功地将Transformer基本的教师检测器知识传递到Convolution基本的学生检测器上，并在MS COCO数据集上提高了RetinaNet的 AP 分数从36.5% 提高到42.0%，以及Mask R-CNN的 AP 分数从38.2% 提高到42.5%。<details>
<summary>Abstract</summary>
Resource-constrained perception systems such as edge computing and vision-for-robotics require vision models to be both accurate and lightweight in computation and memory usage. While knowledge distillation is a proven strategy to enhance the performance of lightweight classification models, its application to structured outputs like object detection and instance segmentation remains a complicated task, due to the variability in outputs and complex internal network modules involved in the distillation process. In this paper, we propose a simple yet surprisingly effective sequential approach to knowledge distillation that progressively transfers the knowledge of a set of teacher detectors to a given lightweight student. To distill knowledge from a highly accurate but complex teacher model, we construct a sequence of teachers to help the student gradually adapt. Our progressive strategy can be easily combined with existing detection distillation mechanisms to consistently maximize student performance in various settings. To the best of our knowledge, we are the first to successfully distill knowledge from Transformer-based teacher detectors to convolution-based students, and unprecedentedly boost the performance of ResNet-50 based RetinaNet from 36.5% to 42.0% AP and Mask R-CNN from 38.2% to 42.5% AP on the MS COCO benchmark.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose a simple yet effective sequential approach to knowledge distillation that progressively transfers the knowledge of a set of teacher detectors to a given lightweight student. To distill knowledge from a highly accurate but complex teacher model, we construct a sequence of teachers to help the student gradually adapt. Our progressive strategy can be easily combined with existing detection distillation mechanisms to consistently maximize student performance in various settings.As far as we know, we are the first to successfully distill knowledge from Transformer-based teacher detectors to convolution-based students, and unprecedentedly boost the performance of ResNet-50 based RetinaNet from 36.5% to 42.0% AP and Mask R-CNN from 38.2% to 42.5% AP on the MS COCO benchmark.
</details></li>
</ul>
<hr>
<h2 id="ImGeoNet-Image-induced-Geometry-aware-Voxel-Representation-for-Multi-view-3D-Object-Detection"><a href="#ImGeoNet-Image-induced-Geometry-aware-Voxel-Representation-for-Multi-view-3D-Object-Detection" class="headerlink" title="ImGeoNet: Image-induced Geometry-aware Voxel Representation for Multi-view 3D Object Detection"></a>ImGeoNet: Image-induced Geometry-aware Voxel Representation for Multi-view 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09098">http://arxiv.org/abs/2308.09098</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tao Tu, Shun-Po Chuang, Yu-Lun Liu, Cheng Sun, Ke Zhang, Donna Roy, Cheng-Hao Kuo, Min Sun</li>
<li>for: 提高多视图图像基于3D对象检测的精度和效率</li>
<li>methods: 使用图像引导的几何空间表示法，从多视图图像中学习几何信息，并在推理阶段只需要多视图图像进行检测</li>
<li>results: 在三个indoor数据集上（ARKitScenes、ScanNetV2、ScanNet200）实现了与当前状态艺术多视图图像基于方法ImVoxelNet相同或更高的检测精度，并且在数据效率方面也表现出了优异性。<details>
<summary>Abstract</summary>
We propose ImGeoNet, a multi-view image-based 3D object detection framework that models a 3D space by an image-induced geometry-aware voxel representation. Unlike previous methods which aggregate 2D features into 3D voxels without considering geometry, ImGeoNet learns to induce geometry from multi-view images to alleviate the confusion arising from voxels of free space, and during the inference phase, only images from multiple views are required. Besides, a powerful pre-trained 2D feature extractor can be leveraged by our representation, leading to a more robust performance. To evaluate the effectiveness of ImGeoNet, we conduct quantitative and qualitative experiments on three indoor datasets, namely ARKitScenes, ScanNetV2, and ScanNet200. The results demonstrate that ImGeoNet outperforms the current state-of-the-art multi-view image-based method, ImVoxelNet, on all three datasets in terms of detection accuracy. In addition, ImGeoNet shows great data efficiency by achieving results comparable to ImVoxelNet with 100 views while utilizing only 40 views. Furthermore, our studies indicate that our proposed image-induced geometry-aware representation can enable image-based methods to attain superior detection accuracy than the seminal point cloud-based method, VoteNet, in two practical scenarios: (1) scenarios where point clouds are sparse and noisy, such as in ARKitScenes, and (2) scenarios involve diverse object classes, particularly classes of small objects, as in the case in ScanNet200.
</details>
<details>
<summary>摘要</summary>
我们提出ImGeoNet，一种基于多视图图像的3D对象探测框架，该框架使用图像引导的geometry-aware粒子表示来模型3D空间。与前方方法不同，ImGeoNet不仅将2D特征积累到3D粒子上无论 Considering geometry, but also learn to induce geometry from multi-view images to alleviate the confusion arising from free space voxels during the inference phase. In addition, our representation can be leveraged by a powerful pre-trained 2D feature extractor, leading to a more robust performance. To evaluate the effectiveness of ImGeoNet, we conduct quantitative and qualitative experiments on three indoor datasets, namely ARKitScenes, ScanNetV2, and ScanNet200. The results show that ImGeoNet outperforms the current state-of-the-art multi-view image-based method, ImVoxelNet, on all three datasets in terms of detection accuracy. Furthermore, ImGeoNet achieves results comparable to ImVoxelNet with 100 views using only 40 views, demonstrating great data efficiency. Our studies also indicate that our proposed image-induced geometry-aware representation can enable image-based methods to achieve superior detection accuracy than the seminal point cloud-based method, VoteNet, in two practical scenarios: (1) scenarios where point clouds are sparse and noisy, such as in ARKitScenes, and (2) scenarios involve diverse object classes, particularly classes of small objects, as in the case in ScanNet200.
</details></li>
</ul>
<hr>
<h2 id="Edit-Temporal-Consistent-Videos-with-Image-Diffusion-Model"><a href="#Edit-Temporal-Consistent-Videos-with-Image-Diffusion-Model" class="headerlink" title="Edit Temporal-Consistent Videos with Image Diffusion Model"></a>Edit Temporal-Consistent Videos with Image Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09091">http://arxiv.org/abs/2308.09091</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanzhi Wang, Yong Li, Xin Liu, Anbo Dai, Antoni Chan, Zhen Cui</li>
<li>for: 本文旨在提出一种能够减少视频时间不一致问题的robust文本导向视频编辑方法，以提高视频编辑效果。</li>
<li>methods: 本文提出了一种名为Temporal-Consistent Video Editing（TCVE）方法，其中使用了预训练的2D Unet进行空间内容修改，同时设计了专门用于捕捉视频序列的时间特征的Temporal Unet架构。此外，通过建立空间和时间两个方面的协同关系，提高了视频编辑效果和时间一致性。</li>
<li>results: 实验结果表明，TCVE方法在视频时间一致性和视频编辑能力两个方面均达到了领域内最佳性能，超过了现有的标准准则。<details>
<summary>Abstract</summary>
Large-scale text-to-image (T2I) diffusion models have been extended for text-guided video editing, yielding impressive zero-shot video editing performance. Nonetheless, the generated videos usually show spatial irregularities and temporal inconsistencies as the temporal characteristics of videos have not been faithfully modeled. In this paper, we propose an elegant yet effective Temporal-Consistent Video Editing (TCVE) method, to mitigate the temporal inconsistency challenge for robust text-guided video editing. In addition to the utilization of a pretrained 2D Unet for spatial content manipulation, we establish a dedicated temporal Unet architecture to faithfully capture the temporal coherence of the input video sequences. Furthermore, to establish coherence and interrelation between the spatial-focused and temporal-focused components, a cohesive joint spatial-temporal modeling unit is formulated. This unit effectively interconnects the temporal Unet with the pretrained 2D Unet, thereby enhancing the temporal consistency of the generated video output while simultaneously preserving the capacity for video content manipulation. Quantitative experimental results and visualization results demonstrate that TCVE achieves state-of-the-art performance in both video temporal consistency and video editing capability, surpassing existing benchmarks in the field.
</details>
<details>
<summary>摘要</summary>
In addition to utilizing a pretrained 2D Unet for spatial content manipulation, we establish a dedicated temporal Unet architecture to faithfully capture the temporal coherence of the input video sequences. Furthermore, to establish coherence and interrelation between the spatial-focused and temporal-focused components, we formulate a cohesive joint spatial-temporal modeling unit. This unit effectively interconnects the temporal Unet with the pretrained 2D Unet, enhancing the temporal consistency of the generated video output while simultaneously preserving the capacity for video content manipulation.Experimental results and visualization results demonstrate that TCVE achieves state-of-the-art performance in both video temporal consistency and video editing capability, surpassing existing benchmarks in the field.
</details></li>
</ul>
<hr>
<h2 id="Bridging-High-Quality-Audio-and-Video-via-Language-for-Sound-Effects-Retrieval-from-Visual-Queries"><a href="#Bridging-High-Quality-Audio-and-Video-via-Language-for-Sound-Effects-Retrieval-from-Visual-Queries" class="headerlink" title="Bridging High-Quality Audio and Video via Language for Sound Effects Retrieval from Visual Queries"></a>Bridging High-Quality Audio and Video via Language for Sound Effects Retrieval from Visual Queries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09089">http://arxiv.org/abs/2308.09089</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julia Wilkins, Justin Salamon, Magdalena Fuentes, Juan Pablo Bello, Oriol Nieto</li>
<li>for: 这个论文是为了找到高质量的声效（SFX），以匹配视频中的特定场景。</li>
<li>methods: 这个论文使用了大型自然语言模型和基础视觉语言模型来连接高质量的音频和视频，从而创建了一个可扩展的自动音频视频数据采集管道。它还使用了预训练的音频和视频编码器来训练一种对比学习基于的检索系统。</li>
<li>results: 这个论文的系统在对高质量音频和视频进行检索 task 上显示了显著的超越基eline的表现。它还能够在不同的数据集上保持一定的表现，并且在用户测试中，人们对系统提供的声效 preference 比基eline 67%。<details>
<summary>Abstract</summary>
Finding the right sound effects (SFX) to match moments in a video is a difficult and time-consuming task, and relies heavily on the quality and completeness of text metadata. Retrieving high-quality (HQ) SFX using a video frame directly as the query is an attractive alternative, removing the reliance on text metadata and providing a low barrier to entry for non-experts. Due to the lack of HQ audio-visual training data, previous work on audio-visual retrieval relies on YouTube (in-the-wild) videos of varied quality for training, where the audio is often noisy and the video of amateur quality. As such it is unclear whether these systems would generalize to the task of matching HQ audio to production-quality video. To address this, we propose a multimodal framework for recommending HQ SFX given a video frame by (1) leveraging large language models and foundational vision-language models to bridge HQ audio and video to create audio-visual pairs, resulting in a highly scalable automatic audio-visual data curation pipeline; and (2) using pre-trained audio and visual encoders to train a contrastive learning-based retrieval system. We show that our system, trained using our automatic data curation pipeline, significantly outperforms baselines trained on in-the-wild data on the task of HQ SFX retrieval for video. Furthermore, while the baselines fail to generalize to this task, our system generalizes well from clean to in-the-wild data, outperforming the baselines on a dataset of YouTube videos despite only being trained on the HQ audio-visual pairs. A user study confirms that people prefer SFX retrieved by our system over the baseline 67% of the time both for HQ and in-the-wild data. Finally, we present ablations to determine the impact of model and data pipeline design choices on downstream retrieval performance. Please visit our project website to listen to and view our SFX retrieval results.
</details>
<details>
<summary>摘要</summary>
找到合适的声效（SFX）以匹配录影中的时刻是一个困难和时间耗费的任务，并且取决于录影中的文本元数据质量。使用录影帧作为查询来撷取高品质（HQ）声效是一个吸引人的选择，减少了文本元数据的依赖和入门障碍。然而，由于缺乏HQ音频视觉训练数据，先前的对话音频视觉检索工作通常是使用YouTube（在野）影片的不同质量进行训练，其中的音频通常是噪音的，影片质量则是业余级。这使得是否这些系统能够通用到对HQ音频视觉匹配的任务仍然存在问题。为了解决这问题，我们提出了一个多 modal 框架，用于根据录影帧提供高品质声效的建议，包括：1. 利用大型语言模型和基础的视觉语言模型来跨度HQ音频和影片，实现高可扩展自动 audio-visual 数据库 Curate 管道。2. 使用预训的音频和视觉嵌入器来训练对比学习扩展系统。我们发现，我们的系统，通过我们自动生成的数据库管道，与基eline 相比，在HQ声效撷取任务上表现出色，并且在实际应用中具有很好的一致性。此外，我们的系统能够从清洁到在野数据中具有良好的一致性，并且在YouTube 影片上进行测试时表现出色。一个使用者研究确认，使用我们的系统比基eline 67% 的时间 prefer SFX。最后，我们提供了ablation 来测试模型和数据管道设计的影响下沿 Retrieval 性能。您可以访问我们的项目网站，listen 和观看我们的 SFX 撷取结果。
</details></li>
</ul>
<hr>
<h2 id="MovePose-A-High-performance-Human-Pose-Estimation-Algorithm-on-Mobile-and-Edge-Devices"><a href="#MovePose-A-High-performance-Human-Pose-Estimation-Algorithm-on-Mobile-and-Edge-Devices" class="headerlink" title="MovePose: A High-performance Human Pose Estimation Algorithm on Mobile and Edge Devices"></a>MovePose: A High-performance Human Pose Estimation Algorithm on Mobile and Edge Devices</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09084">http://arxiv.org/abs/2308.09084</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongyang Yu, Haoyue Zhang, Zhirui Zhou, Wangpeng An, Yanhong Yang</li>
<li>for: 这个研究旨在提供高精度和实时性的人体姿势估测算法，特别适用于CPU型手持式移动设备。</li>
<li>methods:  MovePose使用优化的轻量级卷积神经网络，包括三种技术：deconvolution、大kernel卷积和坐标分类方法，以提高精度和速度。</li>
<li>results: MovePose在COCO验证数据集上获得了67.7的Mean Average Precision（mAP）分数，并在Intel i9-10920x CPU和NVIDIA RTX3090 GPU上显示出了高效性，其中在Android手机上的帧率超过11帧&#x2F;秒。<details>
<summary>Abstract</summary>
We present MovePose, an optimized lightweight convolutional neural network designed specifically for real-time body pose estimation on CPU-based mobile devices. The current solutions do not provide satisfactory accuracy and speed for human posture estimation, and MovePose addresses this gap. It aims to maintain real-time performance while improving the accuracy of human posture estimation for mobile devices. The network produces 17 keypoints for each individual at a rate exceeding 11 frames per second, making it suitable for real-time applications such as fitness tracking, sign language interpretation, and advanced mobile human posture estimation. Our MovePose algorithm has attained an Mean Average Precision (mAP) score of 67.7 on the COCO \cite{cocodata} validation dataset. The MovePose algorithm displayed efficiency with a performance of 69+ frames per second (fps) when run on an Intel i9-10920x CPU. Additionally, it showcased an increased performance of 452+ fps on an NVIDIA RTX3090 GPU. On an Android phone equipped with a Snapdragon 8 + 4G processor, the fps reached above 11. To enhance accuracy, we incorporated three techniques: deconvolution, large kernel convolution, and coordinate classification methods. Compared to basic upsampling, deconvolution is trainable, improves model capacity, and enhances the receptive field. Large kernel convolution strengthens these properties at a decreased computational cost. In summary, MovePose provides high accuracy and real-time performance, marking it a potential tool for a variety of applications, including those focused on mobile-side human posture estimation. The code and models for this algorithm will be made publicly accessible.
</details>
<details>
<summary>摘要</summary>
我们现在提出了 MovePose，一种优化的轻量级卷积神经网络，专门为 CPU 基于移动设备上的实时人体姿态估计设计。现有的解决方案无法提供满意的准确率和速度，MovePose 弥补了这一空隙。它目标保持实时性，同时改进移动设备上人体姿态估计的准确率。该网络每秒可生成 17 个锚点，每秒 exceeding 11 帧，适用于实时应用程序，如健身跟踪、手语理解和高级移动人体姿态估计。我们的 MovePose 算法在 COCO 验证集（\cite{cocodata}) 上获得了 67.7 的 Mean Average Precision（mAP）分数。MovePose 算法在 Intel i9-10920x CPU 上运行时显示了效率，每秒可以达到 69+ 帧/秒。此外，在 NVIDIA RTX3090 GPU 上，其性能提高了 452+ 帧/秒。在装有 Snapdragon 8 + 4G 处理器的 Android 手机上，帧率可达上限。为了提高准确率，我们采用了三种技术：减 convolution、大小 kernel convolution 和坐标分类方法。相比基本的 upsampling，减 convolution 可以学习、提高模型容量和扩展感受野。大小 kernel convolution 强化这些属性，但减少计算成本。简单来说，MovePose 提供了高准确率和实时性，使其成为许多应用程序的可能工具，包括移动端人体姿态估计。我们将代码和模型公开访问。
</details></li>
</ul>
<hr>
<h2 id="Pedestrian-Environment-Model-for-Automated-Driving"><a href="#Pedestrian-Environment-Model-for-Automated-Driving" class="headerlink" title="Pedestrian Environment Model for Automated Driving"></a>Pedestrian Environment Model for Automated Driving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09080">http://arxiv.org/abs/2308.09080</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adrian Holzbock, Alexander Tsaregorodtsev, Vasileios Belagiannis</li>
<li>for: 这个论文的目的是提供一种能够在自动驾驶车辆与游客之间安全交互的环境模型。</li>
<li>methods: 该论文使用了一种基于单目相机图像和车辆定位数据的人体pose估计器，以及一种简单的跟踪算法和egosynchronous抵消。</li>
<li>results: 该论文在CARLA simulate器和nuScenes数据集上测试了其人体环境模型，并达到了约16%的相对位置误差。<details>
<summary>Abstract</summary>
Besides interacting correctly with other vehicles, automated vehicles should also be able to react in a safe manner to vulnerable road users like pedestrians or cyclists. For a safe interaction between pedestrians and automated vehicles, the vehicle must be able to interpret the pedestrian's behavior. Common environment models do not contain information like body poses used to understand the pedestrian's intent. In this work, we propose an environment model that includes the position of the pedestrians as well as their pose information. We only use images from a monocular camera and the vehicle's localization data as input to our pedestrian environment model. We extract the skeletal information with a neural network human pose estimator from the image. Furthermore, we track the skeletons with a simple tracking algorithm based on the Hungarian algorithm and an ego-motion compensation. To obtain the 3D information of the position, we aggregate the data from consecutive frames in conjunction with the vehicle position. We demonstrate our pedestrian environment model on data generated with the CARLA simulator and the nuScenes dataset. Overall, we reach a relative position error of around 16% on both datasets.
</details>
<details>
<summary>摘要</summary>
besides correctly interacting with other vehicles, automated vehicles should also be able to react safely to vulnerable road users like pedestrians or cyclists. for a safe interaction between pedestrians and automated vehicles, the vehicle must be able to interpret the pedestrian's behavior. common environment models do not contain information like body poses used to understand the pedestrian's intent. in this work, we propose an environment model that includes the position of the pedestrians as well as their pose information. we only use images from a monocular camera and the vehicle's localization data as input to our pedestrian environment model. we extract the skeletal information with a neural network human pose estimator from the image. furthermore, we track the skeletons with a simple tracking algorithm based on the hungarian algorithm and an ego-motion compensation. to obtain the 3D information of the position, we aggregate the data from consecutive frames in conjunction with the vehicle position. we demonstrate our pedestrian environment model on data generated with the carla simulator and the nuscenes dataset. overall, we reach a relative position error of around 16% on both datasets.Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/18/cs.CV_2023_08_18/" data-id="clogyj8xp00gm7cracdlk5rds" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_18" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/18/cs.AI_2023_08_18/" class="article-date">
  <time datetime="2023-08-18T12:00:00.000Z" itemprop="datePublished">2023-08-18</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/18/cs.AI_2023_08_18/">cs.AI - 2023-08-18</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="VALERIE22-–-A-photorealistic-richly-metadata-annotated-dataset-of-urban-environments"><a href="#VALERIE22-–-A-photorealistic-richly-metadata-annotated-dataset-of-urban-environments" class="headerlink" title="VALERIE22 – A photorealistic, richly metadata annotated dataset of urban environments"></a>VALERIE22 – A photorealistic, richly metadata annotated dataset of urban environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09632">http://arxiv.org/abs/2308.09632</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oliver Grau, Korbinian Hagn</li>
<li>for: 这个论文的目的是研究深度神经网络（DNN）在城市环境中的识别性能，并开发了一种方法来验证DNN的验证方法。</li>
<li>methods: 这个论文使用了VALERIE工具管道生成了一个名为VALERIE22的synthetic数据集，该数据集包含了高度真实的摄像头 simulate的场景，并提供了丰富的元数据，可以提取特定场景和Semantic特征（如精确的遮挡率、场景中的位置和相机距离）。</li>
<li>results: 根据性能指标，这个论文比较了VALERIE22数据集与其他公开available的数据集，结果显示VALERIE22是目前开放领域中最佳的synthetic数据集之一。<details>
<summary>Abstract</summary>
The VALERIE tool pipeline is a synthetic data generator developed with the goal to contribute to the understanding of domain-specific factors that influence perception performance of DNNs (deep neural networks). This work was carried out under the German research project KI Absicherung in order to develop a methodology for the validation of DNNs in the context of pedestrian detection in urban environments for automated driving. The VALERIE22 dataset was generated with the VALERIE procedural tools pipeline providing a photorealistic sensor simulation rendered from automatically synthesized scenes. The dataset provides a uniquely rich set of metadata, allowing extraction of specific scene and semantic features (like pixel-accurate occlusion rates, positions in the scene and distance + angle to the camera). This enables a multitude of possible tests on the data and we hope to stimulate research on understanding performance of DNNs. Based on performance metric a comparison with several other publicly available datasets is provided, demonstrating that VALERIE22 is one of best performing synthetic datasets currently available in the open domain.
</details>
<details>
<summary>摘要</summary>
valeerie工具管道是一种人工数据生成工具，用于帮助理解深度神经网络（DNN）在不同领域的感知性能因素。这项工作是在德国研究项目“KI Absicherung”下进行的，旨在为自动驾驶中的人体检测中开发一种验证方法。valerie22数据集是通过 valeerie工具管道生成的，该管道提供了高度真实的感知器 simulated scenes。该数据集具有独特的元数据，例如像素精度的遮挡率、场景中的位置和相机到摄像头的距离。这些元数据可以用于进行多种测试，并且我们希望通过这些测试来探索DNN的性能。基于性能指标，我们对多个公共可用的数据集进行了比较，并证明了valerie22是目前公开领域中最佳的人工数据集之一。
</details></li>
</ul>
<hr>
<h2 id="Minimum-Coverage-Sets-for-Training-Robust-Ad-Hoc-Teamwork-Agents"><a href="#Minimum-Coverage-Sets-for-Training-Robust-Ad-Hoc-Teamwork-Agents" class="headerlink" title="Minimum Coverage Sets for Training Robust Ad Hoc Teamwork Agents"></a>Minimum Coverage Sets for Training Robust Ad Hoc Teamwork Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09595">http://arxiv.org/abs/2308.09595</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arrasy Rahman, Jiaxun Cui, Peter Stone</li>
<li>for: 本研究旨在提高不可见的代理和人类合作伙伴的协作robustness，因为这些合作伙伴可能采用多种不同的合作规则。</li>
<li>methods: 我们首先提出，为了提高AHT代理的Robustness，应该让代理模仿环境中任何合作伙伴策略的最小覆盖集（MCS）中的策略。然后，我们引入L-BRDiv算法，它可以生成一组合适的团队策略，使AHT代理在训练过程中模仿MCS中的策略。L-BRDiv通过解决一个具有约束的优化问题，同时让AHT代理学习MCS中的策略和团队策略。</li>
<li>results: 我们的实验表明，L-BRDiv在更多的两个玩家合作问题中生成了更加稳定和可靠的AHT代理，而不需要让对象的目标进行详细调整。我们的研究表明，L-BRDiv比基eline方法更好地发现不同的MCS成员，而不是重复找到相同的策略。<details>
<summary>Abstract</summary>
Robustly cooperating with unseen agents and human partners presents significant challenges due to the diverse cooperative conventions these partners may adopt. Existing Ad Hoc Teamwork (AHT) methods address this challenge by training an agent with a population of diverse teammate policies obtained through maximizing specific diversity metrics. However, these heuristic diversity metrics do not always maximize the agent's robustness in all cooperative problems. In this work, we first propose that maximizing an AHT agent's robustness requires it to emulate policies in the minimum coverage set (MCS), the set of best-response policies to any partner policies in the environment. We then introduce the L-BRDiv algorithm that generates a set of teammate policies that, when used for AHT training, encourage agents to emulate policies from the MCS. L-BRDiv works by solving a constrained optimization problem to jointly train teammate policies for AHT training and approximating AHT agent policies that are members of the MCS. We empirically demonstrate that L-BRDiv produces more robust AHT agents than state-of-the-art methods in a broader range of two-player cooperative problems without the need for extensive hyperparameter tuning for its objectives. Our study shows that L-BRDiv outperforms the baseline methods by prioritizing discovering distinct members of the MCS instead of repeatedly finding redundant policies.
</details>
<details>
<summary>摘要</summary>
Robustly collaborating with unseen agents and human partners poses significant challenges due to the diverse cooperative conventions these partners may adopt. Existing Ad Hoc Teamwork (AHT) methods address this challenge by training an agent with a population of diverse teammate policies obtained through maximizing specific diversity metrics. However, these heuristic diversity metrics do not always maximize the agent's robustness in all cooperative problems. In this work, we first propose that maximizing an AHT agent's robustness requires it to emulate policies in the minimum coverage set (MCS), the set of best-response policies to any partner policies in the environment. We then introduce the L-BRDiv algorithm that generates a set of teammate policies that, when used for AHT training, encourage agents to emulate policies from the MCS. L-BRDiv works by solving a constrained optimization problem to jointly train teammate policies for AHT training and approximating AHT agent policies that are members of the MCS. We empirically demonstrate that L-BRDiv produces more robust AHT agents than state-of-the-art methods in a broader range of two-player cooperative problems without the need for extensive hyperparameter tuning for its objectives. Our study shows that L-BRDiv outperforms the baseline methods by prioritizing discovering distinct members of the MCS instead of repeatedly finding redundant policies.Here is the translation in Traditional Chinese:和不可见的代理人和人类合作伙伴一起合作具有很大的挑战，因为这些合作伙伴可能遵循多种不同的合作传统。现有的协作团队（AHT）方法面对这个挑战，通过将一个代理人训练为一群多样化的伙伴政策，并通过最大化特定多样性度量来实现。但这些旧的多样性度量不一定能够将代理人的Robustness最大化在所有的合作问题中。在这个工作中，我们首先提出，将代理人的Robustness最大化需要它们模仿环境中的最小覆盖集（MCS）中的最佳回应策略。我们然后引入L-BRDiv算法，这个算法可以将一群伙伴政策训练为AHT训练，并且将AHT代理人的政策变成MCS中的成员。L-BRDiv算法通过解决一个受限搜索问题，以实现AHT训练和MCS中的策略匹配。我们实际地显示，L-BRDiv算法可以在更广泛的二 player合作问题中生成更Robust的AHT代理人，并且不需要进行大量的参数调整。我们的研究显示，L-BRDiv算法比基eline方法更好，因为它将优先发现MCS中的不同成员，而不是重复发现重复的策略。
</details></li>
</ul>
<hr>
<h2 id="WizardMath-Empowering-Mathematical-Reasoning-for-Large-Language-Models-via-Reinforced-Evol-Instruct"><a href="#WizardMath-Empowering-Mathematical-Reasoning-for-Large-Language-Models-via-Reinforced-Evol-Instruct" class="headerlink" title="WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct"></a>WizardMath: Empowering Mathematical Reasoning for Large Language Models via Reinforced Evol-Instruct</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09583">http://arxiv.org/abs/2308.09583</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nlpxucan/wizardlm">https://github.com/nlpxucan/wizardlm</a></li>
<li>paper_authors: Haipeng Luo, Qingfeng Sun, Can Xu, Pu Zhao, Jianguang Lou, Chongyang Tao, Xiubo Geng, Qingwei Lin, Shifeng Chen, Dongmei Zhang</li>
<li>for: 提高大型自然语言处理（NLP）任务中的数学逻辑能力</li>
<li>methods: 应用提出的生长学习自适应反馈法（RLEIF）方法</li>
<li>results: 在两个数学逻辑评测 benchmark 上，WizardMath 表现出众，超越了所有现有的开源大型自然语言模型，并在 GSM8k 和 MATH 两个评测 benchmark 上同时超越了 ChatGPT-3.5、Claude Instant-1、PaLM-2 和 Minerva。Here’s the full translation in Simplified Chinese:</li>
<li>for: 本文旨在提高大型自然语言处理（NLP）任务中的数学逻辑能力。</li>
<li>methods: 本文提出了一种基于生长学习自适应反馈法（RLEIF）的方法，用于提高大型自然语言模型的数学逻辑能力。</li>
<li>results: 经过广泛的实验，WizardMath 在两个数学逻辑评测 benchmark 上表现出众，超越了所有现有的开源大型自然语言模型，并在 GSM8k 和 MATH 两个评测 benchmark 上同时超越了 ChatGPT-3.5、Claude Instant-1、PaLM-2 和 Minerva。Please note that the translation is based on the abstract you provided, and the full paper may contain more details and results.<details>
<summary>Abstract</summary>
Large language models (LLMs), such as GPT-4, have shown remarkable performance in natural language processing (NLP) tasks, including challenging mathematical reasoning. However, most existing open-source models are only pre-trained on large-scale internet data and without math-related optimization. In this paper, we present WizardMath, which enhances the mathematical reasoning abilities of Llama-2, by applying our proposed Reinforcement Learning from Evol-Instruct Feedback (RLEIF) method to the domain of math. Through extensive experiments on two mathematical reasoning benchmarks, namely GSM8k and MATH, we reveal the extraordinary capabilities of our model. WizardMath surpasses all other open-source LLMs by a substantial margin. Furthermore, our model even outperforms ChatGPT-3.5, Claude Instant-1, PaLM-2 and Minerva on GSM8k, simultaneously surpasses Text-davinci-002, PaLM-1 and GPT-3 on MATH. More details and model weights are public at https://github.com/nlpxucan/WizardLM and https://huggingface.co/WizardLM.
</details>
<details>
<summary>摘要</summary>
大型自然语言处理（NLP）模型（如GPT-4）在数学逻辑任务中表现出色，但大多数现有的开源模型都只是通过大规模互联网数据进行预训练而未进行数学相关的优化。在这篇论文中，我们提出了增强大型自然语言处理模型的数学逻辑能力的方法——基于反馈学习的强化学习（RLEIF）方法。我们在数学逻辑 benchmark 上进行了广泛的实验，并证明了我们的模型在 GSM8k 和 MATH 上的超常表现。我们的 WizardMath 模型在 GSM8k 上超过了所有现有的开源 LLM，并同时超过了 ChatGPT-3.5、Claude Instant-1、PaLM-2 和 Minerva。此外，我们的模型还在 MATH 上超过了 Text-davinci-002、PaLM-1 和 GPT-3。更多细节和模型权重可以在 GitHub 上找到（https://github.com/nlpxucan/WizardLM）和 Hugging Face 上找到（https://huggingface.co/WizardLM）。
</details></li>
</ul>
<hr>
<h2 id="Investigating-the-Interplay-between-Features-and-Structures-in-Graph-Learning"><a href="#Investigating-the-Interplay-between-Features-and-Structures-in-Graph-Learning" class="headerlink" title="Investigating the Interplay between Features and Structures in Graph Learning"></a>Investigating the Interplay between Features and Structures in Graph Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09570">http://arxiv.org/abs/2308.09570</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniele Castellana, Federico Errica</li>
<li>for: This paper aims to investigate the relationship between node features and target labels in deep graph networks, and to develop new metrics to measure the influence of node features on target labels.</li>
<li>methods: The paper uses two generative processes to build and study ad-hoc node classification tasks, and evaluates the performance of six models, including structure-agnostic ones.</li>
<li>results: The paper finds that previously defined metrics are not adequate when the assumption of a strong correlation between node features and target labels is relaxed, and presents novel research findings that could help advance our understanding of the field.Here’s the Chinese translation of the three pieces of information:</li>
<li>for: 这篇论文的目的是 investigate深度图网络中节点特征和目标标签之间的关系，并开发新的度量来衡量节点特征对目标标签的影响。</li>
<li>methods: 这篇论文使用两种生成过程来建立和研究特定的节点分类任务，并评估了六种模型的性能，包括无结构的模型。</li>
<li>results: 这篇论文发现先前定义的度量在减弱节点特征和目标标签之间的强相关关系时不适用，并提出了新的研究成果，可能帮助我们更深入理解这个领域。<details>
<summary>Abstract</summary>
In the past, the dichotomy between homophily and heterophily has inspired research contributions toward a better understanding of Deep Graph Networks' inductive bias. In particular, it was believed that homophily strongly correlates with better node classification predictions of message-passing methods. More recently, however, researchers pointed out that such dichotomy is too simplistic as we can construct node classification tasks where graphs are completely heterophilic but the performances remain high. Most of these works have also proposed new quantitative metrics to understand when a graph structure is useful, which implicitly or explicitly assume the correlation between node features and target labels. Our work empirically investigates what happens when this strong assumption does not hold, by formalising two generative processes for node classification tasks that allow us to build and study ad-hoc problems. To quantitatively measure the influence of the node features on the target labels, we also use a metric we call Feature Informativeness. We construct six synthetic tasks and evaluate the performance of six models, including structure-agnostic ones. Our findings reveal that previously defined metrics are not adequate when we relax the above assumption. Our contribution to the workshop aims at presenting novel research findings that could help advance our understanding of the field.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:在过去，豪豪和非豪豪的分类理论在深度图学网络的吸引偏好上促进了研究贡献。特别是，人们认为豪豪和非豪豪之间的差异会导致更好的节点预测结果。然而，最近的研究表明，这种分类是太过简单，因为我们可以构建节点预测任务，其中图是完全不豪豪的，却可以达到高性能。大多数这些工作还提出了新的量化指标，以评估图结构的有用性，这些指标直接或间接假设节点特征和目标标签之间的相关性。我们的工作employs two generative processes for node classification tasks，allowing us to build and study ad-hoc problems。为了量化节点特征对目标标签的影响，我们还使用一个叫做特征有用性的指标。我们构建了六个 sintetic任务，并评估了六种模型，包括结构不关注的模型。我们的发现表明，先前定义的指标不适用于放宽这种假设。我们的贡献是在工作室会议上发表新的研究发现，可以帮助我们更深入地理解这个领域。
</details></li>
</ul>
<hr>
<h2 id="Eigenvalue-based-Incremental-Spectral-Clustering"><a href="#Eigenvalue-based-Incremental-Spectral-Clustering" class="headerlink" title="Eigenvalue-based Incremental Spectral Clustering"></a>Eigenvalue-based Incremental Spectral Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10999">http://arxiv.org/abs/2308.10999</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mieczysław A. Kłopotek, Bartłmiej Starosta, Sławomir T. Wierzchoń</li>
<li>for: 这个论文是用于提出一种增量 spectral clustering 方法的。</li>
<li>methods: 该方法包括将数据分割成可处理的子集，对每个子集进行归一化，然后将不同子集中的归一化结果合并，以形成整个数据集的归一化结果。</li>
<li>results: 实验表明，这种增量 spectral clustering 方法可以准确地 clustering 大量数据，并且可以避免因数据规模增长而导致的复杂性增加。<details>
<summary>Abstract</summary>
Our previous experiments demonstrated that subsets collections of (short) documents (with several hundred entries) share a common normalized in some way eigenvalue spectrum of combinatorial Laplacian. Based on this insight, we propose a method of incremental spectral clustering. The method consists of the following steps: (1) split the data into manageable subsets, (2) cluster each of the subsets, (3) merge clusters from different subsets based on the eigenvalue spectrum similarity to form clusters of the entire set. This method can be especially useful for clustering methods of complexity strongly increasing with the size of the data sample,like in case of typical spectral clustering. Experiments were performed showing that in fact the clustering and merging the subsets yields clusters close to clustering the entire dataset.
</details>
<details>
<summary>摘要</summary>
我们之前的实验表明， subsets collections of (短) 文档（具有数百个数据）共享一个常数归一化的几何 Laplacian 吸引器谱。基于这一点，我们提出了一种逐步增量 spectral clustering 方法。该方法包括以下步骤：1. 将数据分割成可控制的 subset，2. 对每个 subset 进行归一化，3. 根据吸引器谱的相似性，将不同 subset 的归一化结果合并形成整个数据集的归一化结果。这种方法可以特别有用于数据集的规模快速增长的情况下，如典型的spectral clustering。我们的实验表明，将 subset 进行归一化并将归一化结果合并可以得到整个数据集的准确归一化结果。
</details></li>
</ul>
<hr>
<h2 id="Adapt-Your-Teacher-Improving-Knowledge-Distillation-for-Exemplar-free-Continual-Learning"><a href="#Adapt-Your-Teacher-Improving-Knowledge-Distillation-for-Exemplar-free-Continual-Learning" class="headerlink" title="Adapt Your Teacher: Improving Knowledge Distillation for Exemplar-free Continual Learning"></a>Adapt Your Teacher: Improving Knowledge Distillation for Exemplar-free Continual Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09544">http://arxiv.org/abs/2308.09544</a></li>
<li>repo_url: None</li>
<li>paper_authors: Filip Szatkowski, Mateusz Pyla, Marcin Przewięźlikowski, Sebastian Cygert, Bartłomiej Twardowski, Tomasz Trzciński</li>
<li>for: 这篇研究探讨了例示无法学习（Class Incremental Learning，CIL）中的知识传授（Knowledge Distillation，KD）作为调节策略，以预防忘记。</li>
<li>methods: 这篇研究使用了KD作为CIL中的调节策略，但是KD通常需要对前一任 зада的资料进行例示，这可能导致 repreentation shift 问题。这篇研究引入了 Teacher Adaptation（TA）方法，让教师网络和主要模型在增量训练中同步更新。</li>
<li>results: 这篇研究发现TA方法可以与KD-based CIL方法相互运作，并在多个例示无法学习benchmark上提供了一致的性能提升。<details>
<summary>Abstract</summary>
In this work, we investigate exemplar-free class incremental learning (CIL) with knowledge distillation (KD) as a regularization strategy, aiming to prevent forgetting. KD-based methods are successfully used in CIL, but they often struggle to regularize the model without access to exemplars of the training data from previous tasks. Our analysis reveals that this issue originates from substantial representation shifts in the teacher network when dealing with out-of-distribution data. This causes large errors in the KD loss component, leading to performance degradation in CIL. Inspired by recent test-time adaptation methods, we introduce Teacher Adaptation (TA), a method that concurrently updates the teacher and the main model during incremental training. Our method seamlessly integrates with KD-based CIL approaches and allows for consistent enhancement of their performance across multiple exemplar-free CIL benchmarks.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们调查了无 exemplar 的类增量学习（CIL）中使用知识塑造（KD）作为准则约束，以避免忘记。KD 基本方法在 CIL 中成功应用，但它们经常无法规范模型，不管在之前任务的示例数据上进行学习。我们的分析发现，这个问题源于教师网络对异常数据的表达变化，导致 KD 损失成分中的大误差，从而导致 CIL 的性能下降。针对此，我们引入了教师适应（TA）方法，该方法在增量训练中同时更新教师网络和主模型。我们的方法顺利地融合了 KD 基本方法和 CIL 方法，并且可以在多个无 exemplar 的 CIL 基准上提供一致的性能提升。
</details></li>
</ul>
<hr>
<h2 id="Meta-ZSDETR-Zero-shot-DETR-with-Meta-learning"><a href="#Meta-ZSDETR-Zero-shot-DETR-with-Meta-learning" class="headerlink" title="Meta-ZSDETR: Zero-shot DETR with Meta-learning"></a>Meta-ZSDETR: Zero-shot DETR with Meta-learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09540">http://arxiv.org/abs/2308.09540</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lu Zhang, Chenbo Zhang, Jiajia Zhao, Jihong Guan, Shuigeng Zhou<br>for: 这篇论文的目的是为了解决零次识别 task 中的问题，特别是低精度和背景混淆问题。methods: 这篇论文使用了 DETR 和 meta-learning 技术，实现了名为 Meta-ZSDETR 的零次识别方法。这篇论文不同于使用 Faster R-CNN 的方法，首先产生无关于类别的提案，然后使用视觉 semantic 对照模组进行分类。相反地，Meta-ZSDETR 直接预测类别特定的方块坐标，使用类别特定的查询来预测类别对应的坐标，并且使用预测的准确度从分类头进行筛选。results: 这篇论文的实验结果显示，该方法在两个 benchmark 数据集 MS COCO 和 PASCAL VOC 上的表现都大幅超过了现有的 ZSD 方法。<details>
<summary>Abstract</summary>
Zero-shot object detection aims to localize and recognize objects of unseen classes. Most of existing works face two problems: the low recall of RPN in unseen classes and the confusion of unseen classes with background. In this paper, we present the first method that combines DETR and meta-learning to perform zero-shot object detection, named Meta-ZSDETR, where model training is formalized as an individual episode based meta-learning task. Different from Faster R-CNN based methods that firstly generate class-agnostic proposals, and then classify them with visual-semantic alignment module, Meta-ZSDETR directly predict class-specific boxes with class-specific queries and further filter them with the predicted accuracy from classification head. The model is optimized with meta-contrastive learning, which contains a regression head to generate the coordinates of class-specific boxes, a classification head to predict the accuracy of generated boxes, and a contrastive head that utilizes the proposed contrastive-reconstruction loss to further separate different classes in visual space. We conduct extensive experiments on two benchmark datasets MS COCO and PASCAL VOC. Experimental results show that our method outperforms the existing ZSD methods by a large margin.
</details>
<details>
<summary>摘要</summary>
Zero-shot object detection aims to localize and recognize objects of unseen classes. Most existing works face two problems: low recall of RPN in unseen classes and confusion of unseen classes with background. In this paper, we present the first method that combines DETR and meta-learning for zero-shot object detection, named Meta-ZSDETR. The model training is formalized as an individual episode-based meta-learning task. Different from Faster R-CNN based methods that first generate class-agnostic proposals and then classify them with visual-semantic alignment modules, Meta-ZSDETR directly predicts class-specific boxes with class-specific queries and further filters them with the predicted accuracy from the classification head. The model is optimized with meta-contrastive learning, which contains a regression head to generate the coordinates of class-specific boxes, a classification head to predict the accuracy of generated boxes, and a contrastive head that utilizes the proposed contrastive-reconstruction loss to further separate different classes in visual space. We conduct extensive experiments on two benchmark datasets MS COCO and PASCAL VOC. Experimental results show that our method outperforms existing ZSD methods by a large margin.
</details></li>
</ul>
<hr>
<h2 id="Proceedings-of-the-2nd-International-Workshop-on-Adaptive-Cyber-Defense"><a href="#Proceedings-of-the-2nd-International-Workshop-on-Adaptive-Cyber-Defense" class="headerlink" title="Proceedings of the 2nd International Workshop on Adaptive Cyber Defense"></a>Proceedings of the 2nd International Workshop on Adaptive Cyber Defense</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09520">http://arxiv.org/abs/2308.09520</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marco Carvalho, Damian Marriott, Mark Bilinski, Ahmad Ridley</li>
<li>for: 本研讨会旨在分享利用人工智能（AI）和机器学习（ML）技术创造固定的响应和适应的网络防御方法。</li>
<li>methods: 本研究使用了AI和ML技术来帮助网络防御，包括自动识别和响应网络攻击、发现和缓解网络漏洞等。</li>
<li>results: 研究人员通过实验和演示证明了AI和ML技术在网络防御中的可行性和有效性，并提出了一些可能的应用场景。<details>
<summary>Abstract</summary>
The 2nd International Workshop on Adaptive Cyber Defense was held at the Florida Institute of Technology, Florida. This workshop was organized to share research that explores unique applications of Artificial Intelligence (AI) and Machine Learning (ML) as foundational capabilities for the pursuit of adaptive cyber defense. The cyber domain cannot currently be reliably and effectively defended without extensive reliance on human experts. Skilled cyber defenders are in short supply and often cannot respond fast enough to cyber threats.   Building on recent advances in AI and ML the Cyber defense research community has been motivated to develop new dynamic and sustainable defenses through the adoption of AI and ML techniques to cyber settings. Bridging critical gaps between AI and Cyber researchers and practitioners can accelerate efforts to create semi-autonomous cyber defenses that can learn to recognize and respond to cyber attacks or discover and mitigate weaknesses in cooperation with other cyber operation systems and human experts. Furthermore, these defenses are expected to be adaptive and able to evolve over time to thwart changes in attacker behavior, changes in the system health and readiness, and natural shifts in user behavior over time.   The workshop was comprised of invited keynote talks, technical presentations and a panel discussion about how AI/ML can enable autonomous mitigation of current and future cyber attacks. Workshop submissions were peer reviewed by a panel of domain experts with a proceedings consisting of six technical articles exploring challenging problems of critical importance to national and global security. Participation in this workshop offered new opportunities to stimulate research and innovation in the emerging domain of adaptive and autonomous cyber defense.
</details>
<details>
<summary>摘要</summary>
第二届国际适应性网络防御工作坊在美国佛罗里达理工学院举行，旨在共享研究人员在使用人工智能（AI）和机器学习（ML）技术为适应性网络防御做出各种应用。现在，无法可靠地和有效地防御网络域，不可避免人才短缺和快速响应网络攻击的问题。基于最新的AI和ML技术，网络防御研究社区受到了激励，以开发新的动态和可持续的防御机制，通过与网络设备和人类专家合作，实现自动化的防御。这些防御机制预期能够适应变化的攻击者行为、系统健康和准备度以及自然的用户行为变化。工作坊包括邀请演讲、技术演示和关于如何通过AI/ML实现自主 Mitigation的panel讨论。工作坊提交经过埃评审定，汇报包括六篇技术文章，探讨了国家和全球安全中的挑战性问题。参加这个工作坊，提供了新的研究和创新机会在emerging领域中，即适应性网络防御。
</details></li>
</ul>
<hr>
<h2 id="Spatial-LibriSpeech-An-Augmented-Dataset-for-Spatial-Audio-Learning"><a href="#Spatial-LibriSpeech-An-Augmented-Dataset-for-Spatial-Audio-Learning" class="headerlink" title="Spatial LibriSpeech: An Augmented Dataset for Spatial Audio Learning"></a>Spatial LibriSpeech: An Augmented Dataset for Spatial Audio Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09514">http://arxiv.org/abs/2308.09514</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/apple/ml-spatial-librispeech">https://github.com/apple/ml-spatial-librispeech</a></li>
<li>paper_authors: Miguel Sarabia, Elena Menyaylenko, Alessandro Toso, Skyler Seto, Zakaria Aldeneh, Shadi Pirhosseinloo, Luca Zappella, Barry-John Theobald, Nicholas Apostoloff, Jonathan Sheaffer</li>
<li>for: 这篇论文是用于训练机器学习模型的，特别是用于三维声音定位和相关任务。</li>
<li>methods: 这篇论文使用了大量的 simulate acoustic condition 和 synthetic room 来生成了一个名为 Spatial LibriSpeech 的三维声音数据集，该数据集包含了19个通道的声音、一级散射和可选的干扰声音。</li>
<li>results: 作者使用了这个数据集训练了四个空间声音任务，并取得了 median absolute error 为6.60{\deg} 的3D声音源定位任务，0.43m 的距离任务，90.66ms 的 T30 任务和 2.74dB 的 DRR 估计任务的结果。此外，作者还证明了这些模型可以通过在广泛使用的评估数据集上进行训练来获得良好的普适性。<details>
<summary>Abstract</summary>
We present Spatial LibriSpeech, a spatial audio dataset with over 650 hours of 19-channel audio, first-order ambisonics, and optional distractor noise. Spatial LibriSpeech is designed for machine learning model training, and it includes labels for source position, speaking direction, room acoustics and geometry. Spatial LibriSpeech is generated by augmenting LibriSpeech samples with 200k+ simulated acoustic conditions across 8k+ synthetic rooms. To demonstrate the utility of our dataset, we train models on four spatial audio tasks, resulting in a median absolute error of 6.60{\deg} on 3D source localization, 0.43m on distance, 90.66ms on T30, and 2.74dB on DRR estimation. We show that the same models generalize well to widely-used evaluation datasets, e.g., obtaining a median absolute error of 12.43{\deg} on 3D source localization on TUT Sound Events 2018, and 157.32ms on T30 estimation on ACE Challenge.
</details>
<details>
<summary>摘要</summary>
我们现在提供的是一个空间听说数据集，名为空间听说（Spatial LibriSpeech），它包含了650小时以上的19个频道声音，以及一个首选的干扰噪声。空间听说数据集是为机器学习模型训练而设计，其中包括源位置、说话方向、室内声学和室内geometry的标签。空间听说数据集通过对LibriSpeech样本进行扩展，生成了200,000+个simulated acoustic condition，并在8,000+个synthetic room中进行了扩展。为了证明我们的数据集的实用性，我们在四个空间听说任务上训练了模型，其中包括3D源localization、距离、T30和DRR估计。我们发现这些模型在广泛使用的评估数据集上也能够良好地适应，例如在TUT Sound Events 2018中， median absolute error为12.43°，和在ACE Challenge中，T30估计中的 median absolute error为157.32ms。
</details></li>
</ul>
<hr>
<h2 id="Semantic-relatedness-in-DBpedia-A-comparative-and-experimental-assessment"><a href="#Semantic-relatedness-in-DBpedia-A-comparative-and-experimental-assessment" class="headerlink" title="Semantic relatedness in DBpedia: A comparative and experimental assessment"></a>Semantic relatedness in DBpedia: A comparative and experimental assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09502">http://arxiv.org/abs/2308.09502</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anna Formica, Francesco Taglino</li>
<li>for: 本研究的目的是评估Web资源之间的Semantic relatedness，尤其是基于知识图的方法。</li>
<li>methods: 本研究选择了10种现有Literature中的方法，分为邻居资源、 triple patterns 和 triple weights 三种类型。这些方法都基于DBpedia作为参考RDF知识图进行实现和评估。</li>
<li>results: 根据实验结果，将RDF triplets权重化并评估所有导向链连接的资源是计算DBpedia中Semantic relatedness的最佳策略。<details>
<summary>Abstract</summary>
Evaluating semantic relatedness of Web resources is still an open challenge. This paper focuses on knowledge-based methods, which represent an alternative to corpus-based approaches, and rely in general on the availability of knowledge graphs. In particular, we have selected 10 methods from the existing literature, that have been organized according to it adjacent resources, triple patterns, and triple weights-based methods. They have been implemented and evaluated by using DBpedia as reference RDF knowledge graph. Since DBpedia is continuously evolving, the experimental results provided by these methods in the literature are not comparable. For this reason, in this work, such methods have been experimented by running them all at once on the same DBpedia release and against 14 well-known golden datasets. On the basis of the correlation values with human judgment obtained according to the experimental results, weighting the RDF triples in combination with evaluating all the directed paths linking the compared resources is the best strategy in order to compute semantic relatedness in DBpedia.
</details>
<details>
<summary>摘要</summary>
evaluating semantic relatedness of web resources is still an open challenge. this paper focuses on knowledge-based methods, which represent an alternative to corpus-based approaches, and rely in general on the availability of knowledge graphs. in particular, we have selected 10 methods from the existing literature, that have been organized according to their adjacent resources, triple patterns, and triple weights-based methods. they have been implemented and evaluated by using dbpedia as reference rdf knowledge graph. since dbpedia is continuously evolving, the experimental results provided by these methods in the literature are not comparable. for this reason, in this work, such methods have been experimented by running them all at once on the same dbpedia release and against 14 well-known golden datasets. on the basis of the correlation values with human judgment obtained according to the experimental results, weighting the rdf triples in combination with evaluating all the directed paths linking the compared resources is the best strategy in order to compute semantic relatedness in dbpedia.
</details></li>
</ul>
<hr>
<h2 id="Predictive-Authoring-for-Brazilian-Portuguese-Augmentative-and-Alternative-Communication"><a href="#Predictive-Authoring-for-Brazilian-Portuguese-Augmentative-and-Alternative-Communication" class="headerlink" title="Predictive Authoring for Brazilian Portuguese Augmentative and Alternative Communication"></a>Predictive Authoring for Brazilian Portuguese Augmentative and Alternative Communication</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09497">http://arxiv.org/abs/2308.09497</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jayralencar/pictogram_prediction_pt">https://github.com/jayralencar/pictogram_prediction_pt</a></li>
<li>paper_authors: Jayr Pereira, Rodrigo Nogueira, Cleber Zanchettin, Robson Fidalgo</li>
<li>for: This paper proposes using a BERT-like model for pictogram prediction in AAC systems to improve the efficiency of message authoring for individuals with complex communication needs.</li>
<li>methods: The authors finetune BERTimbau, a Brazilian Portuguese version of BERT, using an AAC corpus for Brazilian Portuguese, and test different approaches to representing a pictogram for prediction, including as a word, as a concept, and as a set of synonyms.</li>
<li>results: The results demonstrate that using embeddings computed from the pictograms’ captions, synonyms, or definitions have a similar performance, and using synonyms leads to lower perplexity, but using captions leads to the highest accuracies. The paper provides insight into how to represent a pictogram for prediction using a BERT-like model and the potential of using images for pictogram prediction.Here is the same information in Simplified Chinese:</li>
<li>for: 这篇论文提议使用基于BERT的模型进行AAC系统中图像预测，以提高帮助受残障人群表达需求的消息排版效率。</li>
<li>methods: 作者使用了一个特定于巴西葡萄牙语的BERT版本（BERTimbau），并使用了一个特定于巴西葡萄牙语的AAC corpus进行训练。他们测试了不同的图像预测方法，包括作为单词（使用图像描述）、作为概念（使用词典定义）和作为相关词（使用相关词）。</li>
<li>results: 结果表明，使用图像描述、词典定义或相关词来计算图像预测的方法具有相似的性能。使用相关词的方法可以得到更低的混淆率，但使用描述的方法可以得到最高的准确率。这篇论文提供了使用基于BERT的模型进行图像预测的可能性和图像预测的技术。<details>
<summary>Abstract</summary>
Individuals with complex communication needs (CCN) often rely on augmentative and alternative communication (AAC) systems to have conversations and communique their wants. Such systems allow message authoring by arranging pictograms in sequence. However, the difficulty of finding the desired item to complete a sentence can increase as the user's vocabulary increases. This paper proposes using BERTimbau, a Brazilian Portuguese version of BERT, for pictogram prediction in AAC systems. To finetune BERTimbau, we constructed an AAC corpus for Brazilian Portuguese to use as a training corpus. We tested different approaches to representing a pictogram for prediction: as a word (using pictogram captions), as a concept (using a dictionary definition), and as a set of synonyms (using related terms). We also evaluated the usage of images for pictogram prediction. The results demonstrate that using embeddings computed from the pictograms' caption, synonyms, or definitions have a similar performance. Using synonyms leads to lower perplexity, but using captions leads to the highest accuracies. This paper provides insight into how to represent a pictogram for prediction using a BERT-like model and the potential of using images for pictogram prediction.
</details>
<details>
<summary>摘要</summary>
人们 WITH complex communication needs (CCN) 常常使用增强型替代通信系统 (AAC) 进行交流和表达自己的需求。这些系统允许用户通过排序绘图来编写消息。然而，如果用户的词汇量增加，则查找所需的项目可能变得更加困难。这篇论文提议使用 BERTimbau，一种巴西葡萄牙语版的 BERT，来预测绘图。为了训练 BERTimbau，我们创建了一个用于巴西葡萄牙语 AAC 系统的训练集。我们测试了不同的绘图预测方法：以字符 (使用绘图描述)、以概念 (使用词典定义) 和以同义词 (使用相关词语) 三种方法。我们还评估了使用图像进行绘图预测。结果表明，使用绘图描述、同义词或词典定义生成的嵌入都有类似的表现。使用同义词可以降低噪音水平，但使用绘图描述可以达到最高的准确率。这篇论文提供了如何使用 BERT-like 模型来预测绘图，以及使用图像进行绘图预测的潜在性。
</details></li>
</ul>
<hr>
<h2 id="Balancing-Transparency-and-Risk-The-Security-and-Privacy-Risks-of-Open-Source-Machine-Learning-Models"><a href="#Balancing-Transparency-and-Risk-The-Security-and-Privacy-Risks-of-Open-Source-Machine-Learning-Models" class="headerlink" title="Balancing Transparency and Risk: The Security and Privacy Risks of Open-Source Machine Learning Models"></a>Balancing Transparency and Risk: The Security and Privacy Risks of Open-Source Machine Learning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09490">http://arxiv.org/abs/2308.09490</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dominik Hintersdorf, Lukas Struppek, Kristian Kersting</li>
<li>for: 这项研究的目的是提醒用户关于使用开源机器学习模型的隐私和安全风险。</li>
<li>methods: 该研究使用了诸如攻击分析和隐私检测等方法来描述开源模型中常见的隐私和安全风险。</li>
<li>results: 研究发现了许多开源模型中隐私和安全风险的例子，包括模型中隐藏的功能和输入模式的攻击等。这些风险可能导致服务中断、敏感用户数据泄露和更严重的物理损害等。<details>
<summary>Abstract</summary>
The field of artificial intelligence (AI) has experienced remarkable progress in recent years, driven by the widespread adoption of open-source machine learning models in both research and industry. Considering the resource-intensive nature of training on vast datasets, many applications opt for models that have already been trained. Hence, a small number of key players undertake the responsibility of training and publicly releasing large pre-trained models, providing a crucial foundation for a wide range of applications. However, the adoption of these open-source models carries inherent privacy and security risks that are often overlooked. To provide a concrete example, an inconspicuous model may conceal hidden functionalities that, when triggered by specific input patterns, can manipulate the behavior of the system, such as instructing self-driving cars to ignore the presence of other vehicles. The implications of successful privacy and security attacks encompass a broad spectrum, ranging from relatively minor damage like service interruptions to highly alarming scenarios, including physical harm or the exposure of sensitive user data. In this work, we present a comprehensive overview of common privacy and security threats associated with the use of open-source models. By raising awareness of these dangers, we strive to promote the responsible and secure use of AI systems.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）领域在最近几年内取得了很大进步，由于研究和业务中广泛采用开源机器学习模型而驱动。由于训练大量数据集需要巨量的资源，许多应用程序选择使用已经训练过的模型。因此，只有一些关键参与者在训练和公共发布大型预训练模型，为各种应用提供了重要的基础。然而，使用这些开源模型的采用带来了隐私和安全风险，这些风险frequently overlooked。为了提供一个具体的例子，一个无征的模型可能封装了隐藏的功能，当特定的输入模式触发时，可以 manipulate the behavior of the system，如 instructing self-driving cars to ignore the presence of other vehicles。成功的隐私和安全攻击的后果extremely broad，从relatively minor damage like service interruptions到highly alarming scenarios, including physical harm or the exposure of sensitive user data。在这项工作中，我们提供了对公开源模型的常见隐私和安全威胁的全面概述。通过提醒这些危险，我们希望促进AI系统的负责任和安全使用。
</details></li>
</ul>
<hr>
<h2 id="Modelling-Electricity-Consumption-in-Irish-Dairy-Farms-Using-Agent-Based-Modelling"><a href="#Modelling-Electricity-Consumption-in-Irish-Dairy-Farms-Using-Agent-Based-Modelling" class="headerlink" title="Modelling Electricity Consumption in Irish Dairy Farms Using Agent-Based Modelling"></a>Modelling Electricity Consumption in Irish Dairy Farms Using Agent-Based Modelling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09488">http://arxiv.org/abs/2308.09488</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hossein Khaleghy, Abdul Wahid, Eoghan Clifford, Karl Mason</li>
<li>for: 这个研究报告是为了研究爱尔兰奶牛农场的电力消耗而写的。</li>
<li>methods: 该研究使用了代理模型来模拟奶牛农场的电力消耗，考虑了奶牛数量、牛奶机器数量以及时间的影响。</li>
<li>results: 研究发现代理模型可以准确地预测奶牛农场的电力消耗，并且可以提供完全可解释的输出，这是其他人工智能技术，如深度学习模型所不具备的优点。<details>
<summary>Abstract</summary>
Dairy farming can be an energy intensive form of farming. Understanding the factors affecting electricity consumption on dairy farms is crucial for farm owners and energy providers. In order to accurately estimate electricity demands in dairy farms, it is necessary to develop a model. In this research paper, an agent-based model is proposed to model the electricity consumption of Irish dairy farms. The model takes into account various factors that affect the energy consumption of dairy farms, including herd size, number of milking machines, and time of year. The outputs are validated using existing state-of-the-art dairy farm modelling frameworks. The proposed agent-based model is fully explainable, which is an advantage over other Artificial Intelligence techniques, e.g. deep learning.
</details>
<details>
<summary>摘要</summary>
牛奶农业可能是一种能源密集的农业形式。了解牛奶农场电ity消耗的因素对农场所有者和能源供应商非常重要。为了准确估算牛奶农场电ity需求，需要开发一个模型。在这篇研究论文中，我们提出了一个代理基模型，用于模拟爱尔兰牛奶农场电ity消耗。该模型考虑了各种影响牛奶农场电ity消耗的因素，包括牛群规模、数量 milking machines 和时间季节。输出被验证使用现有的国际先进的牛奶农场模型框架。我们的代理基模型具有可解释性，这是对其他人工智能技术，例如深度学习，的优势。
</details></li>
</ul>
<hr>
<h2 id="Poison-Dart-Frog-A-Clean-Label-Attack-with-Low-Poisoning-Rate-and-High-Attack-Success-Rate-in-the-Absence-of-Training-Data"><a href="#Poison-Dart-Frog-A-Clean-Label-Attack-with-Low-Poisoning-Rate-and-High-Attack-Success-Rate-in-the-Absence-of-Training-Data" class="headerlink" title="Poison Dart Frog: A Clean-Label Attack with Low Poisoning Rate and High Attack Success Rate in the Absence of Training Data"></a>Poison Dart Frog: A Clean-Label Attack with Low Poisoning Rate and High Attack Success Rate in the Absence of Training Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09487">http://arxiv.org/abs/2308.09487</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/magic-ma-tech/poison-dart-frog">https://github.com/magic-ma-tech/poison-dart-frog</a></li>
<li>paper_authors: Binhao Ma, Jiahui Wang, Dejun Wang, Bo Meng</li>
<li>for: 防止背门的攻击 (backdoor attacks)</li>
<li>methods: 使用“Poison Dart Frog”clean-label方法，不需要攻击者有训练集的知识 (knowledge of the entire training set or a portion of it)</li>
<li>results: 在CIFAR10、Tiny-ImageNet和TSRD上，使用0.1%、0.025%和0.4%的训练集恶化率，分别达到高的攻击成功率，并与州对抗方法NARCISSUS相似的攻击成功率，而不需要任何训练集知识。<details>
<summary>Abstract</summary>
To successfully launch backdoor attacks, injected data needs to be correctly labeled; otherwise, they can be easily detected by even basic data filters. Hence, the concept of clean-label attacks was introduced, which is more dangerous as it doesn't require changing the labels of injected data. To the best of our knowledge, the existing clean-label backdoor attacks largely relies on an understanding of the entire training set or a portion of it. However, in practice, it is very difficult for attackers to have it because of training datasets often collected from multiple independent sources. Unlike all current clean-label attacks, we propose a novel clean label method called 'Poison Dart Frog'. Poison Dart Frog does not require access to any training data; it only necessitates knowledge of the target class for the attack, such as 'frog'. On CIFAR10, Tiny-ImageNet, and TSRD, with a mere 0.1\%, 0.025\%, and 0.4\% poisoning rate of the training set size, respectively, Poison Dart Frog achieves a high Attack Success Rate compared to LC, HTBA, BadNets, and Blend. Furthermore, compared to the state-of-the-art attack, NARCISSUS, Poison Dart Frog achieves similar attack success rates without any training data. Finally, we demonstrate that four typical backdoor defense algorithms struggle to counter Poison Dart Frog.
</details>
<details>
<summary>摘要</summary>
要成功发起后门攻击，注入数据需要正确地标签，否则可能被even basic数据筛选器轻易探测。因此， cleaner-label攻击被引入，这种攻击更加危险，因为它不需要改变注入数据的标签。据我们所知，现有的 cleaner-label 后门攻击大多数依据整个训练集或一部分它的理解。然而，在实践中，攻击者很难获得这些训练集，因为训练集通常来自多个独立的源头。不同于现有的 cleaner-label 攻击，我们提出了一种新的 cleaner-label 方法 called 'Poison Dart Frog'。Poison Dart Frog 不需要训练集的访问权限，只需要target类的知识，例如 '蛙'。在 CIFAR10、Tiny-ImageNet 和 TSRD 上，使用0.1%、0.025% 和 0.4% 的训练集大小杂入率，Poison Dart Frog 可以获得高度的 Attack Success Rate，比LC、HTBA、BadNets 和 Blend 高。此外，与当前状态的攻击相比，Poison Dart Frog 可以达到类似的攻击成功率，不需要任何训练数据。最后，我们示示了四种常见的后门防御算法无法防御 Poison Dart Frog。
</details></li>
</ul>
<hr>
<h2 id="RBA-GCN-Relational-Bilevel-Aggregation-Graph-Convolutional-Network-for-Emotion-Recognition"><a href="#RBA-GCN-Relational-Bilevel-Aggregation-Graph-Convolutional-Network-for-Emotion-Recognition" class="headerlink" title="RBA-GCN: Relational Bilevel Aggregation Graph Convolutional Network for Emotion Recognition"></a>RBA-GCN: Relational Bilevel Aggregation Graph Convolutional Network for Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11029">http://arxiv.org/abs/2308.11029</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luftmenscher/RBA-GCN">https://github.com/luftmenscher/RBA-GCN</a></li>
<li>paper_authors: Lin Yuan, Guoheng Huang, Fenghuan Li, Xiaochen Yuan, Chi-Man Pun, Guo Zhong</li>
<li>for: 这篇论文的目的是提出一种基于图 convolutional networks (GCNs) 的 Emotion recognition in conversation (ERC) 方法，以解决传统GCNs的节点资料重复问题和单层GCNs无法捕捉广泛的上下文资讯问题。</li>
<li>methods: 这篇论文使用了三个模组：graph generation module (GGM)、similarity-based cluster building module (SCBM) 和 bilevel aggregation module (BiAM)。GGM 将目标节点资料简化为减少节点资料重复问题，而 SCBM 计算节点与其结构邻域的相似性，删除低相似性的资讯以保留节点的决定性资讯。 Meanwhile, BiAM 是一种新的统计方法，可以在不同模式之间建立互动，并捕捉广泛的上下文资讯。</li>
<li>results: 在 IEMOCAP 和 MELD  datasets 上，RBA-GCN 的 weighted average F1 score 与最先进方法相比，有2.17%∼5.21%的提升。<details>
<summary>Abstract</summary>
Emotion recognition in conversation (ERC) has received increasing attention from researchers due to its wide range of applications. As conversation has a natural graph structure, numerous approaches used to model ERC based on graph convolutional networks (GCNs) have yielded significant results. However, the aggregation approach of traditional GCNs suffers from the node information redundancy problem, leading to node discriminant information loss. Additionally, single-layer GCNs lack the capacity to capture long-range contextual information from the graph. Furthermore, the majority of approaches are based on textual modality or stitching together different modalities, resulting in a weak ability to capture interactions between modalities. To address these problems, we present the relational bilevel aggregation graph convolutional network (RBA-GCN), which consists of three modules: the graph generation module (GGM), similarity-based cluster building module (SCBM) and bilevel aggregation module (BiAM). First, GGM constructs a novel graph to reduce the redundancy of target node information. Then, SCBM calculates the node similarity in the target node and its structural neighborhood, where noisy information with low similarity is filtered out to preserve the discriminant information of the node. Meanwhile, BiAM is a novel aggregation method that can preserve the information of nodes during the aggregation process. This module can construct the interaction between different modalities and capture long-range contextual information based on similarity clusters. On both the IEMOCAP and MELD datasets, the weighted average F1 score of RBA-GCN has a 2.17$\sim$5.21\% improvement over that of the most advanced method.
</details>
<details>
<summary>摘要</summary>
很多研究者对话情感识别（ERC）的注意力增加，因为它在各种应用方面有广泛的应用空间。由于对话有自然的图形结构，许多方法使用图形傅敏网（GCNs）来模型ERC，它们已经获得了重要的成果。但是，传统GCN的聚合方法受到节点信息重复问题的影响，导致节点标识信息的损失。此外，单层GCN缺乏捕捉长距离内容关联的能力。此外，大多数方法仅基于文本模式或将不同模式组合起来，导致模式间的互动capture能力弱化。为了解决这些问题，我们提出了关系两级聚合图形傅敏网（RBA-GCN），它包括三个模组：图形生成模组（GGM）、相似度基于集群建立模组（SCBM）和两级聚合模组（BiAM）。首先，GGM将建立一个新的图形，以减少目标节点信息的重复性。接着，SCBM计算目标节点和其结构邻域中的相似度，并将低相似度的信息排除，以保留节点标识信息的 дискリ民资讯。同时，BiAM是一个新的聚合方法，可以在聚合过程中保持节点信息。这个模组可以建立不同模式之间的互动，并捕捉长距离内容关联。在IEMOCAP和MELD dataset上，RBA-GCN的复合权重平均F1分数与最先进方法相比，具有2.17%∼5.21%的提升。
</details></li>
</ul>
<hr>
<h2 id="AI-Hilbert-From-Data-and-Background-Knowledge-to-Automated-Scientific-Discovery"><a href="#AI-Hilbert-From-Data-and-Background-Knowledge-to-Automated-Scientific-Discovery" class="headerlink" title="AI Hilbert: From Data and Background Knowledge to Automated Scientific Discovery"></a>AI Hilbert: From Data and Background Knowledge to Automated Scientific Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09474">http://arxiv.org/abs/2308.09474</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ryan Cory-Wright, Bachir El Khadir, Cristina Cornelio, Sanjeeb Dash, Lior Horesh</li>
<li>for: 本研究的目的是找到一种能够简洁地解释自然现象的科学方程式，并与现有背景理论相符。</li>
<li>methods: 本研究使用了回归和理解的方法，以消除与背景理论不符的方程式。</li>
<li>results: 研究表明，使用拟合和逻辑的方法可以快速地找到一个与数据最佳匹配的科学方程式，并且可以自动证明这些发现的正确性。<details>
<summary>Abstract</summary>
The discovery of scientific formulae that parsimoniously explain natural phenomena and align with existing background theory is a key goal in science. Historically, scientists have derived natural laws by manipulating equations based on existing knowledge, forming new equations, and verifying them experimentally. In recent years, data-driven scientific discovery has emerged as a viable competitor in settings with large amounts of experimental data. Unfortunately, data-driven methods often fail to discover valid laws when data is noisy or scarce. Accordingly, recent works combine regression and reasoning to eliminate formulae inconsistent with background theory. However, the problem of searching over the space of formulae consistent with background theory to find one that fits the data best is not well solved. We propose a solution to this problem when all axioms and scientific laws are expressible via polynomial equalities and inequalities and argue that our approach is widely applicable. We further model notions of minimal complexity using binary variables and logical constraints, solve polynomial optimization problems via mixed-integer linear or semidefinite optimization, and automatically prove the validity of our scientific discoveries via Positivestellensatz certificates. Remarkably, the optimization techniques leveraged in this paper allow our approach to run in polynomial time with fully correct background theory, or non-deterministic polynomial (NP) time with partially correct background theory. We experimentally demonstrate that some famous scientific laws, including Kepler's Third Law of Planetary Motion, the Hagen-Poiseuille Equation, and the Radiated Gravitational Wave Power equation, can be automatically derived from sets of partially correct background axioms.
</details>
<details>
<summary>摘要</summary>
科学发现的目标是找到经济、与背景理论相align的自然现象的科学方程。历史上，科学家通过拟合方程、形成新方程、并通过实验验证来 derive 自然法律。在近年来，数据驱动的科学发现得到了广泛应用，但是在具有噪音或缺乏数据的情况下，数据驱动方法常常无法发现有效的法律。因此，现有的方法通常是结合回归和逻辑来排除不符合背景理论的方程。然而，搜索符合背景理论的方程空间中最佳方程的问题还没有得到妥善解决。我们提出一种解决这个问题的方法，其中所有的axioms和科学法律都可以表示为多项式等式和不等式。我们还使用二进制变量和逻辑约束来模型简洁度的概念，使用混合整数线性或半definiteProgramming来解决多项式优化问题，并使用Positivestellensatz证明来自动验证我们的科学发现。很显然，我们的优化技术可以使我们的方法在 polynomial 时间内运行，并且完全符合背景理论，或者在 partially correct 背景理论下运行在非 deterministic  polynomial 时间内。我们在实验中证明了一些著名的科学法律，包括凯撒第三法律、hagen-Poiseuille方程和释放 gravitational wave 的能量方程，可以自动从部分正确的背景axioms中 derivation。
</details></li>
</ul>
<hr>
<h2 id="Vision-Relation-Transformer-for-Unbiased-Scene-Graph-Generation"><a href="#Vision-Relation-Transformer-for-Unbiased-Scene-Graph-Generation" class="headerlink" title="Vision Relation Transformer for Unbiased Scene Graph Generation"></a>Vision Relation Transformer for Unbiased Scene Graph Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09472">http://arxiv.org/abs/2308.09472</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/visinf/veto">https://github.com/visinf/veto</a></li>
<li>paper_authors: Gopika Sudhakaran, Devendra Singh Dhami, Kristian Kersting, Stefan Roth</li>
<li>for:  scene graph generation (SGG) task, aiming to predict entity relationships using a relation encoder-decoder pipeline stacked on top of an object encoder-decoder backbone.</li>
<li>methods:  introduces the Vision rElation TransfOrmer (VETO), consisting of a novel local-level entity relation encoder, and the Mutually Exclusive ExperT (MEET) learning strategy to capture important relation features without bias towards head or tail classes.</li>
<li>results:  experimental results on the VG and GQA datasets demonstrate that VETO + MEET boosts the predictive performance by up to 47 percentage over the state of the art while being 10 times smaller.<details>
<summary>Abstract</summary>
Recent years have seen a growing interest in Scene Graph Generation (SGG), a comprehensive visual scene understanding task that aims to predict entity relationships using a relation encoder-decoder pipeline stacked on top of an object encoder-decoder backbone. Unfortunately, current SGG methods suffer from an information loss regarding the entities local-level cues during the relation encoding process. To mitigate this, we introduce the Vision rElation TransfOrmer (VETO), consisting of a novel local-level entity relation encoder. We further observe that many existing SGG methods claim to be unbiased, but are still biased towards either head or tail classes. To overcome this bias, we introduce a Mutually Exclusive ExperT (MEET) learning strategy that captures important relation features without bias towards head or tail classes. Experimental results on the VG and GQA datasets demonstrate that VETO + MEET boosts the predictive performance by up to 47 percentage over the state of the art while being 10 times smaller.
</details>
<details>
<summary>摘要</summary>
Recent years have seen a growing interest in Scene Graph Generation (SGG), a comprehensive visual scene understanding task that aims to predict entity relationships using a relation encoder-decoder pipeline stacked on top of an object encoder-decoder backbone. Unfortunately, current SGG methods suffer from an information loss regarding the entities local-level cues during the relation encoding process. To mitigate this, we introduce the Vision rElation TransfOrmer (VETO), consisting of a novel local-level entity relation encoder. We further observe that many existing SGG methods claim to be unbiased, but are still biased towards either head or tail classes. To overcome this bias, we introduce a Mutually Exclusive ExperT (MEET) learning strategy that captures important relation features without bias towards head or tail classes. Experimental results on the VG and GQA datasets demonstrate that VETO + MEET boosts the predictive performance by up to 47 percentage over the state of the art while being 10 times smaller.Here's the translation in Traditional Chinese:Recent years have seen a growing interest in Scene Graph Generation (SGG), a comprehensive visual scene understanding task that aims to predict entity relationships using a relation encoder-decoder pipeline stacked on top of an object encoder-decoder backbone. Unfortunately, current SGG methods suffer from an information loss regarding the entities local-level cues during the relation encoding process. To mitigate this, we introduce the Vision rElation TransfOrmer (VETO), consisting of a novel local-level entity relation encoder. We further observe that many existing SGG methods claim to be unbiased, but are still biased towards either head or tail classes. To overcome this bias, we introduce a Mutually Exclusive ExperT (MEET) learning strategy that captures important relation features without bias towards head or tail classes. Experimental results on the VG and GQA datasets demonstrate that VETO + MEET boosts the predictive performance by up to 47 percentage over the state of the art while being 10 times smaller.
</details></li>
</ul>
<hr>
<h2 id="Artificial-Spiking-Hierarchical-Networks-for-Vision-Language-Representation-Learning"><a href="#Artificial-Spiking-Hierarchical-Networks-for-Vision-Language-Representation-Learning" class="headerlink" title="Artificial-Spiking Hierarchical Networks for Vision-Language Representation Learning"></a>Artificial-Spiking Hierarchical Networks for Vision-Language Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09455">http://arxiv.org/abs/2308.09455</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yeming Chen, Siyu Zhang, Yaoru Sun, Weijian Liang, Haoran Wang</li>
<li>for: 本研究旨在提高视频语言（VL）任务中的semantic gap问题，通过引入一种新的视觉 semantic模块来提高 VL 任务的性能。</li>
<li>methods: 本研究提出了一种灵活的计算框架，即Artificial-Spiking Hierarchical Networks (ASH-Nets)，它将Artificial neural networks (ANNs)和Spiking neural networks (SNNs)的优点相结合，以增强视觉 semantic表示。具体来说，ASH-Nets 使用了一个视觉具体编码器和一个semantic抽象编码器，以学习不同类型的 kontinuous和 discrete 隐藏变量，以提高视觉表示的灵活性。此外，通过对相似样本进行对比学习，可以提高层次网络的计算效率，同时对硬样本的扩充也有助于视觉表示的学习。</li>
<li>results: 在多个Established downstream VL tasks上，提出的 STUA 预训练方法和 ASH-Nets 模型实现了竞争性的 результаados。<details>
<summary>Abstract</summary>
With the success of self-supervised learning, multimodal foundation models have rapidly adapted a wide range of downstream tasks driven by vision and language (VL) pretraining. State-of-the-art methods achieve impressive performance by pre-training on large-scale datasets. However, bridging the semantic gap between the two modalities remains a nonnegligible challenge for VL tasks. In this work, we propose an efficient computation framework for multimodal alignment by introducing a novel visual semantic module to further improve the performance of the VL tasks. Specifically, we propose a flexible model, namely Artificial-Spiking Hierarchical Networks (ASH-Nets), which combines the complementary advantages of Artificial neural networks (ANNs) and Spiking neural networks (SNNs) to enrich visual semantic representations. In particular, a visual concrete encoder and a semantic abstract encoder are constructed to learn continuous and discrete latent variables to enhance the flexibility of semantic encoding. Considering the spatio-temporal properties of SNNs modeling, we introduce a contrastive learning method to optimize the inputs of similar samples. This can improve the computational efficiency of the hierarchical network, while the augmentation of hard samples is beneficial to the learning of visual representations. Furthermore, the Spiking to Text Uni-Alignment Learning (STUA) pre-training method is proposed, which only relies on text features to enhance the encoding ability of abstract semantics. We validate the performance on multiple well-established downstream VL tasks. Experiments show that the proposed ASH-Nets achieve competitive results.
</details>
<details>
<summary>摘要</summary>
自顾精学学习的成功，多Modal基础模型快速适应了视频语言（VL）预训练驱动的广泛下游任务。状态顶尖方法在大规模数据预训练后达到了印象式的性能。然而，跨模态 semantic gap 问题仍然是 VL 任务的一个重要挑战。在这种情况下，我们提议一种高效的计算框架，即 Multimodal 对接框架，通过引入一种新的视觉semantic模块来进一步提高 VL 任务的性能。具体来说，我们提出一种灵活的模型，即人工神经网络（ANNs）和脉冲神经网络（SNNs）的组合模型，以增强视觉semantic表示。特别是，我们构建了一个视觉具体编码器和一个semantic抽象编码器，以学习不同的连续和离散的幂变量，以提高模型的灵活性。此外，我们引入了一种对比学习方法，以优化层次网络的输入，从而提高计算效率。此外，我们还提出了一种基于文本特征的预训练方法，即 STUA 预训练方法，可以增强模型的抽象semantic编码能力。我们 validate 了多个常见的下游 VL 任务的性能，实验结果表明，我们提出的 ASH-Nets 可以 achieve 竞争性的结果。
</details></li>
</ul>
<hr>
<h2 id="Logistics-Hub-Location-Optimization-A-K-Means-and-P-Median-Model-Hybrid-Approach-Using-Road-Network-Distances"><a href="#Logistics-Hub-Location-Optimization-A-K-Means-and-P-Median-Model-Hybrid-Approach-Using-Road-Network-Distances" class="headerlink" title="Logistics Hub Location Optimization: A K-Means and P-Median Model Hybrid Approach Using Road Network Distances"></a>Logistics Hub Location Optimization: A K-Means and P-Median Model Hybrid Approach Using Road Network Distances</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11038">http://arxiv.org/abs/2308.11038</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Abdul Rahman, Muhammad Aamir Basheer, Zubair Khalid, Muhammad Tahir, Momin Uppal</li>
<li>For: 优化快递总站的位置，以提高电商业务的效率和环保性。* Methods:  hybrid方法，首先使用K-Means对交通网络距离相关的配送点进行聚合，然后使用P-Median方法将总站设置在优化位置。* Results: 通过使用优化的总站位置，可以节省每个配送的10%（815米）的距离。<details>
<summary>Abstract</summary>
Logistic hubs play a pivotal role in the last-mile delivery distance; even a slight increment in distance negatively impacts the business of the e-commerce industry while also increasing its carbon footprint. The growth of this industry, particularly after Covid-19, has further intensified the need for optimized allocation of resources in an urban environment. In this study, we use a hybrid approach to optimize the placement of logistic hubs. The approach sequentially employs different techniques. Initially, delivery points are clustered using K-Means in relation to their spatial locations. The clustering method utilizes road network distances as opposed to Euclidean distances. Non-road network-based approaches have been avoided since they lead to erroneous and misleading results. Finally, hubs are located using the P-Median method. The P-Median method also incorporates the number of deliveries and population as weights. Real-world delivery data from Muller and Phipps (M&P) is used to demonstrate the effectiveness of the approach. Serving deliveries from the optimal hub locations results in the saving of 815 (10%) meters per delivery.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Delivery points are clustered using K-Means based on their spatial locations, utilizing road network distances instead of Euclidean distances to ensure accurate results.2. Hubs are located using the P-Median method, which takes into account the number of deliveries and population as weights to ensure the most efficient placement.Using real-world delivery data from Muller and Phipps (M&amp;P), we demonstrate the effectiveness of our approach. By serving deliveries from the optimal hub locations, we save 815 meters (10%) per delivery, significantly reducing the carbon footprint and improving the efficiency of the e-commerce industry.</details></li>
</ol>
<hr>
<h2 id="From-Hope-to-Safety-Unlearning-Biases-of-Deep-Models-by-Enforcing-the-Right-Reasons-in-Latent-Space"><a href="#From-Hope-to-Safety-Unlearning-Biases-of-Deep-Models-by-Enforcing-the-Right-Reasons-in-Latent-Space" class="headerlink" title="From Hope to Safety: Unlearning Biases of Deep Models by Enforcing the Right Reasons in Latent Space"></a>From Hope to Safety: Unlearning Biases of Deep Models by Enforcing the Right Reasons in Latent Space</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09437">http://arxiv.org/abs/2308.09437</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maximilian Dreyer, Frederik Pahde, Christopher J. Anders, Wojciech Samek, Sebastian Lapuschkin</li>
<li>for: 这篇研究旨在减少深度神经网络中嵌入的伪 positives corrleations，以避免高风险的预测。</li>
<li>methods: 我们使用了一种新的方法，通过减少模型对伪 positives 的敏感性，以确保模型做出的预测是正确的。</li>
<li>results: 我们在控制环境和实际世界中进行了实验，在 ISIC、Bone Age、ImageNet 和 CelebA 数据集上使用 VGG、ResNet 和 EfficientNet 架构，实现了对伪 positives 的有效控制。<details>
<summary>Abstract</summary>
Deep Neural Networks are prone to learning spurious correlations embedded in the training data, leading to potentially biased predictions. This poses risks when deploying these models for high-stake decision-making, such as in medical applications. Current methods for post-hoc model correction either require input-level annotations, which are only possible for spatially localized biases, or augment the latent feature space, thereby hoping to enforce the right reasons. We present a novel method ensuring the right reasons on the concept level by reducing the model's sensitivity towards biases through the gradient. When modeling biases via Concept Activation Vectors, we highlight the importance of choosing robust directions, as traditional regression-based approaches such as Support Vector Machines tend to result in diverging directions. We effectively mitigate biases in controlled and real-world settings on the ISIC, Bone Age, ImageNet and CelebA datasets using VGG, ResNet and EfficientNet architectures.
</details>
<details>
<summary>摘要</summary>
We present a novel method ensuring the right reasons on the concept level by reducing the model's sensitivity towards biases through the gradient 梯度。 When modeling biases via Concept Activation Vectors 概念活动向量, we highlight the importance of choosing robust directions 选择可靠的方向, as traditional regression-based approaches such as Support Vector Machines 支持向量机 tend to result in diverging directions 分散的方向. We effectively mitigate biases in controlled and real-world settings on the ISIC, Bone Age, ImageNet and CelebA datasets using VGG, ResNet and EfficientNet architectures 在 ISIC, Bone Age, ImageNet 和 CelebA  dataset上使用 VGG, ResNet 和 EfficientNet 架构中有效地缓解偏见。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Agent-Communication-and-Learning-through-Action-and-Language"><a href="#Enhancing-Agent-Communication-and-Learning-through-Action-and-Language" class="headerlink" title="Enhancing Agent Communication and Learning through Action and Language"></a>Enhancing Agent Communication and Learning through Action and Language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10842">http://arxiv.org/abs/2308.10842</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jettbrains/-L-">https://github.com/jettbrains/-L-</a></li>
<li>paper_authors: Caselles-Dupré Hugo, Sigaud Olivier, Chetouani Mohamed</li>
<li>for: 这个论文旨在描述一种新的 GC-agent，可以同时作为教师和学生进行交互。</li>
<li>methods: 这种 GC-agent 利用了动作示例和语言指令，提高了交互效率。</li>
<li>results: 研究发现，通过 combining 动作和语言交互模式，可以提高学习效果。<details>
<summary>Abstract</summary>
We introduce a novel category of GC-agents capable of functioning as both teachers and learners. Leveraging action-based demonstrations and language-based instructions, these agents enhance communication efficiency. We investigate the incorporation of pedagogy and pragmatism, essential elements in human communication and goal achievement, enhancing the agents' teaching and learning capabilities. Furthermore, we explore the impact of combining communication modes (action and language) on learning outcomes, highlighting the benefits of a multi-modal approach.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种新的 GC-代理人，可以作为 both 教师和学生。通过行为示例和语言指令，这些代理人可以提高交流效率。我们研究了包括教学理论和 Pragmatics 等人类交流和目标实现的关键元素，以提高代理人的教学和学习能力。此外，我们还探讨了将多种交流方式（行为和语言）结合使用的影响，并指出了多模式approach的 beneficial effects。
</details></li>
</ul>
<hr>
<h2 id="ICU-Mortality-Prediction-Using-Long-Short-Term-Memory-Networks"><a href="#ICU-Mortality-Prediction-Using-Long-Short-Term-Memory-Networks" class="headerlink" title="ICU Mortality Prediction Using Long Short-Term Memory Networks"></a>ICU Mortality Prediction Using Long Short-Term Memory Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.12800">http://arxiv.org/abs/2308.12800</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manel Mili, Asma Kerkeni, Asma Ben Abdallah, Mohamed Hedi Bedoui</li>
<li>for: 这篇论文是为了提出一种自动化数据驱动系统，用于分析医疗电子健康记录（EHRs）中的大量多变量时间序列数据，并提取高级信息，以预测医院内死亡率和医疗时间（LOS）的早期预测。</li>
<li>methods: 这篇论文使用了LSTM网络，通过减少时间框架为6小时，提高临床任务效果。</li>
<li>results: 实验结果表明，LSTM模型在具有严格多变量时间序列测量的情况下，对实际世界预测建立了高效的预测机制。<details>
<summary>Abstract</summary>
Extensive bedside monitoring in Intensive Care Units (ICUs) has resulted in complex temporal data regarding patient physiology, which presents an upscale context for clinical data analysis. In the other hand, identifying the time-series patterns within these data may provide a high aptitude to predict clinical events. Hence, we investigate, during this work, the implementation of an automatic data-driven system, which analyzes large amounts of multivariate temporal data derived from Electronic Health Records (EHRs), and extracts high-level information so as to predict in-hospital mortality and Length of Stay (LOS) early. Practically, we investigate the applicability of LSTM network by reducing the time-frame to 6-hour so as to enhance clinical tasks. The experimental results highlight the efficiency of LSTM model with rigorous multivariate time-series measurements for building real-world prediction engines.
</details>
<details>
<summary>摘要</summary>
延伸床side监测在医疗急诊室（ICU）中已经导致了复杂的时间序列数据，这些数据提供了更高级别的临床数据分析的上下文。然而，在这些数据中找到时间序列模式可能提供高度预测临床事件的可能性。因此，在本研究中，我们调查了一个自动化的数据驱动系统，该系统分析大量的多变量时间序列数据，并从医疗记录（EHRs）中提取高级别的信息，以预测患者在医院内的死亡率和治疗时间（LOS）的早期预测。实际上，我们研究了使用LSTM网络，通过减少时间帧为6小时，以提高临床任务的效率。实验结果表明，LSTM模型在多变量时间序列测量下表现了高效的预测能力。
</details></li>
</ul>
<hr>
<h2 id="Multi-Level-Compositional-Reasoning-for-Interactive-Instruction-Following"><a href="#Multi-Level-Compositional-Reasoning-for-Interactive-Instruction-Following" class="headerlink" title="Multi-Level Compositional Reasoning for Interactive Instruction Following"></a>Multi-Level Compositional Reasoning for Interactive Instruction Following</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09387">http://arxiv.org/abs/2308.09387</a></li>
<li>repo_url: None</li>
<li>paper_authors: Suvaansh Bhambri, Byeonghwi Kim, Jonghyun Choi</li>
<li>for: 这个论文旨在提高机器人在家庭用品上进行各种任务的能力，使其能够更好地理解和完成复杂的任务指令。</li>
<li>methods: 该论文提出了一种分解任务为多个互相关联的子任务的方法，并通过多级组合政策来实现。</li>
<li>results: 该论文通过这种方法实现了2.03%的绝对提升（PLWSR）在未seen集中，而不使用规则基本规划或semantic spatial memory。<details>
<summary>Abstract</summary>
Robotic agents performing domestic chores by natural language directives are required to master the complex job of navigating environment and interacting with objects in the environments. The tasks given to the agents are often composite thus are challenging as completing them require to reason about multiple subtasks, e.g., bring a cup of coffee. To address the challenge, we propose to divide and conquer it by breaking the task into multiple subgoals and attend to them individually for better navigation and interaction. We call it Multi-level Compositional Reasoning Agent (MCR-Agent). Specifically, we learn a three-level action policy. At the highest level, we infer a sequence of human-interpretable subgoals to be executed based on language instructions by a high-level policy composition controller. At the middle level, we discriminatively control the agent's navigation by a master policy by alternating between a navigation policy and various independent interaction policies. Finally, at the lowest level, we infer manipulation actions with the corresponding object masks using the appropriate interaction policy. Our approach not only generates human interpretable subgoals but also achieves 2.03% absolute gain to comparable state of the arts in the efficiency metric (PLWSR in unseen set) without using rule-based planning or a semantic spatial memory.
</details>
<details>
<summary>摘要</summary>
机器人代理人在完成家务任务时需要掌握环境导航和对物体互动的复杂任务。给予的任务经常是复杂的，需要理解多个子任务，例如带一杯咖啡。为了解决这个挑战，我们提议分解任务为多个子目标，并对它们进行独立的处理，以更好地导航和互动。我们称之为多级组合理解代理人（MCR-Agent）。具体来说，我们学习了三级行为策略。在最高层，我们根据语言指令生成一个序列的人类可读Subgoal，并由高级组合控制器执行。在中层，我们通过alternating between a navigation policy和多种独立的互动策略来干扰导航。最后，在最低层，我们使用相应的互动策略来INFER操作。我们的方法不仅生成了人类可读的Subgoal，而且在PLWSR指标上（未seen集）实现了2.03%的绝对提升，不使用规则化计划或semantic spatial memory。
</details></li>
</ul>
<hr>
<h2 id="Deciphering-knee-osteoarthritis-diagnostic-features-with-explainable-artificial-intelligence-A-systematic-review"><a href="#Deciphering-knee-osteoarthritis-diagnostic-features-with-explainable-artificial-intelligence-A-systematic-review" class="headerlink" title="Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review"></a>Deciphering knee osteoarthritis diagnostic features with explainable artificial intelligence: A systematic review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09380">http://arxiv.org/abs/2308.09380</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yun Xin Teoh, Alice Othmani, Siew Li Goh, Juliana Usman, Khin Wee Lai</li>
<li>for: 本研究旨在提供一份关于膝关节杂合病（OA）诊断的帮助，使用可解释人工智能（XAI）技术以提高诊断的可靠性和可信度。</li>
<li>methods: 本研究使用了两种视角来描述XAI技术的应用：数据可解释性和模型可解释性。</li>
<li>results: 本研究发现XAI技术可以提高膝关节杂合病诊断的可靠性和可信度，并且可以提供有用的启示，以便促进XAI技术的应用在临床实践中。<details>
<summary>Abstract</summary>
Existing artificial intelligence (AI) models for diagnosing knee osteoarthritis (OA) have faced criticism for their lack of transparency and interpretability, despite achieving medical-expert-like performance. This opacity makes them challenging to trust in clinical practice. Recently, explainable artificial intelligence (XAI) has emerged as a specialized technique that can provide confidence in the model's prediction by revealing how the prediction is derived, thus promoting the use of AI systems in healthcare. This paper presents the first survey of XAI techniques used for knee OA diagnosis. The XAI techniques are discussed from two perspectives: data interpretability and model interpretability. The aim of this paper is to provide valuable insights into XAI's potential towards a more reliable knee OA diagnosis approach and encourage its adoption in clinical practice.
</details>
<details>
<summary>摘要</summary>
现有的膝关节artoarthritis（OA）诊断模型（AI）受到了不透明性和解释性的批评，即使它们达到了医疗专业人员水平。这种透明性使得它们在临床实践中具有挑战。最近，解释性人工智能（XAI）作为一种专门的技术，可以提供对预测的信任，并透明地表明预测是如何 derivation的。这篇文章发表了膝关节OA诊断中使用XAI技术的首次报告。XAI技术从两个角度进行了讨论：数据解释性和模型解释性。文章的目的是提供XAI在膝关节OA诊断方面的可靠性的 valuable 信息，并促进XAI在临床实践中的采用。
</details></li>
</ul>
<hr>
<h2 id="Which-Transformer-to-Favor-A-Comparative-Analysis-of-Efficiency-in-Vision-Transformers"><a href="#Which-Transformer-to-Favor-A-Comparative-Analysis-of-Efficiency-in-Vision-Transformers" class="headerlink" title="Which Transformer to Favor: A Comparative Analysis of Efficiency in Vision Transformers"></a>Which Transformer to Favor: A Comparative Analysis of Efficiency in Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09372">http://arxiv.org/abs/2308.09372</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tobna/whattransformertofavor">https://github.com/tobna/whattransformertofavor</a></li>
<li>paper_authors: Tobias Christian Nauen, Sebastian Palacio, Andreas Dengel</li>
<li>for: This paper aims to provide a comprehensive evaluation of vision transformers and related architectures, focusing on their efficiency across multiple performance metrics.</li>
<li>methods: The authors use more than 30 models and consider various performance metrics to evaluate the efficiency of different architectures. They also propose a hybrid attention-CNN model that performs well with low inference memory and number of parameters.</li>
<li>results: The study finds that ViT is still Pareto optimal across multiple efficiency metrics, despite the existence of alternative approaches claiming to be more efficient. The authors also discover a strong positive correlation between the number of FLOPS and training memory, and that scaling the model size is more effective than scaling the image size. The study provides valuable insights for practitioners and researchers when selecting models for specific applications.<details>
<summary>Abstract</summary>
The growing popularity of Vision Transformers as the go-to models for image classification has led to an explosion of architectural modifications claiming to be more efficient than the original ViT. However, a wide diversity of experimental conditions prevents a fair comparison between all of them, based solely on their reported results. To address this gap in comparability, we conduct a comprehensive analysis of more than 30 models to evaluate the efficiency of vision transformers and related architectures, considering various performance metrics. Our benchmark provides a comparable baseline across the landscape of efficiency-oriented transformers, unveiling a plethora of surprising insights. For example, we discover that ViT is still Pareto optimal across multiple efficiency metrics, despite the existence of several alternative approaches claiming to be more efficient. Results also indicate that hybrid attention-CNN models fare particularly well when it comes to low inference memory and number of parameters, and also that it is better to scale the model size, than the image size. Furthermore, we uncover a strong positive correlation between the number of FLOPS and the training memory, which enables the estimation of required VRAM from theoretical measurements alone.   Thanks to our holistic evaluation, this study offers valuable insights for practitioners and researchers, facilitating informed decisions when selecting models for specific applications. We publicly release our code and data at https://github.com/tobna/WhatTransformerToFavor
</details>
<details>
<summary>摘要</summary>
“vision transformer”的快速增长 popularity 使得许多建筑修改被提出，承认这些模型更高效 чем原始的 ViT。然而，各种实验条件的多样性使得对各模型的比较变得困难，根据报告的结果来进行对比。为了解决这个问题，我们进行了对超过30个模型的全面分析，以评估视transformer和相关建筑的效率，并考虑多种性能指标。我们的基准提供了不同类型的transformer模型之间的比较基准，揭示了许多有趣的发现。例如，我们发现， despite the existence of several alternative approaches claiming to be more efficient, ViT仍然在多种效率指标上保持Pareto优化的状态。此外，我们发现在低执行 памяти和参数数量方面，混合注意力-CNN模型表现特别好，而且Scaling the model size是比Scale the image size更好的选择。此外，我们发现对于FLOPS和训练内存之间存在强正相关关系，这使得通过理论测量 alone 可以估算需要的VRAM。由于我们的彻底评估，这些研究可以为实践者和研究人员提供有价值的意见，以便在特定应用中选择合适的模型。我们将代码和数据公开发布在https://github.com/tobna/WhatTransformerToFavor上。”
</details></li>
</ul>
<hr>
<h2 id="RLIPv2-Fast-Scaling-of-Relational-Language-Image-Pre-training"><a href="#RLIPv2-Fast-Scaling-of-Relational-Language-Image-Pre-training" class="headerlink" title="RLIPv2: Fast Scaling of Relational Language-Image Pre-training"></a>RLIPv2: Fast Scaling of Relational Language-Image Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09351">http://arxiv.org/abs/2308.09351</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jacobyuan7/rlipv2">https://github.com/jacobyuan7/rlipv2</a></li>
<li>paper_authors: Hangjie Yuan, Shiwei Zhang, Xiang Wang, Samuel Albanie, Yining Pan, Tao Feng, Jianwen Jiang, Dong Ni, Yingya Zhang, Deli Zhao</li>
<li>for: 提高计算机视觉任务中的关系理解能力，通过将视觉表示与语言表示相关联。</li>
<li>methods: 提出了一种快速结合的模型RLIPv2，使得可以在大规模 Pseudo-labelled scene graph 数据上进行关系预训练。RLIPv2 引入了非对称语言图像融合 (ALIF) 机制，使得早期和深入的受阻语言编码层可以更加简洁。</li>
<li>results: 通过对 Human-Object Interaction Detection 和 Scene Graph Generation 等两个任务进行广泛的实验，RLIPv2 在三个标准 bencmarks 上达到了状态的艺术性表现，包括无需训练、几架shot 和零shot 设置下的表现。特别是，最大的 RLIPv2 在 HICO-DET 上达到了 23.29mAP 的最高分，只需要 1% 的数据进行 finituning，可以达到 32.22mAP 的表现，并且在 100% 的数据上进行 finituning 可以达到 45.09mAP。<details>
<summary>Abstract</summary>
Relational Language-Image Pre-training (RLIP) aims to align vision representations with relational texts, thereby advancing the capability of relational reasoning in computer vision tasks. However, hindered by the slow convergence of RLIPv1 architecture and the limited availability of existing scene graph data, scaling RLIPv1 is challenging. In this paper, we propose RLIPv2, a fast converging model that enables the scaling of relational pre-training to large-scale pseudo-labelled scene graph data. To enable fast scaling, RLIPv2 introduces Asymmetric Language-Image Fusion (ALIF), a mechanism that facilitates earlier and deeper gated cross-modal fusion with sparsified language encoding layers. ALIF leads to comparable or better performance than RLIPv1 in a fraction of the time for pre-training and fine-tuning. To obtain scene graph data at scale, we extend object detection datasets with free-form relation labels by introducing a captioner (e.g., BLIP) and a designed Relation Tagger. The Relation Tagger assigns BLIP-generated relation texts to region pairs, thus enabling larger-scale relational pre-training. Through extensive experiments conducted on Human-Object Interaction Detection and Scene Graph Generation, RLIPv2 shows state-of-the-art performance on three benchmarks under fully-finetuning, few-shot and zero-shot settings. Notably, the largest RLIPv2 achieves 23.29mAP on HICO-DET without any fine-tuning, yields 32.22mAP with just 1% data and yields 45.09mAP with 100% data. Code and models are publicly available at https://github.com/JacobYuan7/RLIPv2.
</details>
<details>
<summary>摘要</summary>
RLIP（关系语言图前期训练）目的是将视觉表示与关系文本对齐，从而提高计算机视觉任务中的关系理解能力。然而，RLIPv1架构的慢慢涨潮和现有场景图数据的有限性，使得扩展RLIPv1的困难。在这篇论文中，我们提出RLIPv2，一种快速涨潮的模型，可以将关系预训练扩展到大规模 Pseudo-标注场景图数据。为了快速涨潮，RLIPv2引入了异常语言图像融合（ALIF）机制，使得更早、更深的隔离modal融合，并使用压缩语言编码层。ALIF使得RLIPv2在预训练和精度调整中比RLIPv1快得多。为了获得大规模场景图数据，我们将对象检测数据集扩展，并在BLIP（例如）和设计的关系标签器（Relation Tagger）的帮助下，对区域对应关系文本进行分配。这使得更大规模的关系预训练可能。通过对人物交互检测和场景图生成进行广泛的实验，RLIPv2在三个标准准则下达到了状态 искусственный智能水平，包括完全finetuning、几何shot和零shot设置。尤其是RLIPv2最大的版本在HICO-DET上达到了23.29mAP，无需任何调整，并且在1%数据上达到了32.22mAP，以及在100%数据上达到了45.09mAP。代码和模型在https://github.com/JacobYuan7/RLIPv2上公开。
</details></li>
</ul>
<hr>
<h2 id="Surprise-machines-revealing-Harvard-Art-Museums’-image-collection"><a href="#Surprise-machines-revealing-Harvard-Art-Museums’-image-collection" class="headerlink" title="Surprise machines: revealing Harvard Art Museums’ image collection"></a>Surprise machines: revealing Harvard Art Museums’ image collection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09343">http://arxiv.org/abs/2308.09343</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dario Rodighiero, Lins Derry, Douglas Duhaime, Jordan Kruguer, Maximilian C. Mueller, Christopher Pietsch, Jeffrey T. Schnapp, Jeff Steward</li>
<li>for: 这项研究旨在为哈佛艺术博物馆的所有图像收藏开展一项实验性的 museology 项目，以探索人工智能在显示大量图像时的限制，并为访问者带来意外的视觉体验。</li>
<li>methods: 该项目使用了一种chorographic interface，通过访问者的运动连接多个独特的图像视图，以创造意外的感受。</li>
<li>results: 该项目成功地创造了一种意外的视觉体验，使访问者能够更深入地了解和探索哈佛艺术博物馆的图像收藏。<details>
<summary>Abstract</summary>
Surprise Machines is a project of experimental museology that sets out to visualize the entire image collection of the Harvard Art Museums, intending to open up unexpected vistas on more than 200,000 objects usually inaccessible to visitors. Part of the exhibition Curatorial A(i)gents organized by metaLAB (at) Harvard, the project explores the limits of artificial intelligence to display a large set of images and create surprise among visitors. To achieve such a feeling of surprise, a choreographic interface was designed to connect the audience's movement with several unique views of the collection.
</details>
<details>
<summary>摘要</summary>
《意料之机》是哈佛艺术博物馆的一个实验 museology 项目，旨在将哈佛艺术博物馆的全部图像收藏视觉化，以开拓访问者未曾能够访问的更多 чем200,000个物品。该项目是metaLAB（@）哈佛所组织的《Curatorial A(i)gents》展览的一部分，探索人工智能是否能够显示大量图像并创造访问者的意外感。为实现此类感受，项目设计了一个chorographic User Interface，以连接访客的移动和图像收藏中的多个独特视图。
</details></li>
</ul>
<hr>
<h2 id="Distributed-Neurodynamics-Based-Backstepping-Optimal-Control-for-Robust-Constrained-Consensus-of-Underactuated-Underwater-Vehicles-Fleet"><a href="#Distributed-Neurodynamics-Based-Backstepping-Optimal-Control-for-Robust-Constrained-Consensus-of-Underactuated-Underwater-Vehicles-Fleet" class="headerlink" title="Distributed Neurodynamics-Based Backstepping Optimal Control for Robust Constrained Consensus of Underactuated Underwater Vehicles Fleet"></a>Distributed Neurodynamics-Based Backstepping Optimal Control for Robust Constrained Consensus of Underactuated Underwater Vehicles Fleet</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09326">http://arxiv.org/abs/2308.09326</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tao Yan, Zhe Xu, Simon X. Yang, S. Andrew Gadsden</li>
<li>for: 本研究旨在提出一种robust constrained formation tracking控制方法，用于三维空间下无力 actuated underwater vehicles（UUVs）队伍的可靠性和稳定性问题。</li>
<li>methods: 本研究采用了一种协调协议和一种稳定控制器，其中约束级别采用了层次架构。在上层，通过圆拟变换来解决非拘束约束，然后开发了一种分布式优化运动协调策略。在下层控制循环中，采用了基于神经动力学的稳定控制器，以避免在传统的backstepping控制器中出现的”爆炸性”问题，并提高控制活动。</li>
<li>results: 研究发现，基于协调协议和稳定控制器的优化形态跟踪控制方法可以实现UUVs队伍的最佳形态跟踪，同时满足约束条件。此外，在不确定干扰的情况下，研究也证明了UUVs队伍的稳定性和可靠性。<details>
<summary>Abstract</summary>
Robust constrained formation tracking control of underactuated underwater vehicles (UUVs) fleet in three-dimensional space is a challenging but practical problem. To address this problem, this paper develops a novel consensus based optimal coordination protocol and a robust controller, which adopts a hierarchical architecture. On the top layer, the spherical coordinate transform is introduced to tackle the nonholonomic constraint, and then a distributed optimal motion coordination strategy is developed. As a result, the optimal formation tracking of UUVs fleet can be achieved, and the constraints are fulfilled. To realize the generated optimal commands better and, meanwhile, deal with the underactuation, at the lower-level control loop a neurodynamics based robust backstepping controller is designed, and in particular, the issue of "explosion of terms" appearing in conventional backstepping based controllers is avoided and control activities are improved. The stability of the overall UUVs formation system is established to ensure that all the states of the UUVs are uniformly ultimately bounded in the presence of unknown disturbances. Finally, extensive simulation comparisons are made to illustrate the superiority and effectiveness of the derived optimal formation tracking protocol.
</details>
<details>
<summary>摘要</summary>
Robust constrained formation tracking控制 OF underactuated underwater vehicles (UUVs) 舰队在三维空间是一个具有挑战性但实际性的问题。为解决这个问题，这篇论文开发了一种新的协调协议和一种稳定控制器，其采用了层次架构。在最高层，引入了球坐标变换来处理非整体约束，然后开发了分布式优化运动协调策略。因此，UUVs 舰队可以实现优化的形态跟踪，同时满足约束。为了实现生成的优化命令更好地，并且处理下 actuation，在下一级控制循环中设计了基于神经动力学的稳定后退控制器，其中避免了传统后退控制器中的“爆炸性”问题，提高了控制活动。最后，确立了 UUVs formation 系统的稳定性，以确保所有 UUVs 的状态在未知干扰的情况下都是 ultimately bounded。 finally，通过了EXTENSIVE 的simulation 比较，证明了获得的优化形态跟踪协议的优越性和有效性。
</details></li>
</ul>
<hr>
<h2 id="Audio-Visual-Glance-Network-for-Efficient-Video-Recognition"><a href="#Audio-Visual-Glance-Network-for-Efficient-Video-Recognition" class="headerlink" title="Audio-Visual Glance Network for Efficient Video Recognition"></a>Audio-Visual Glance Network for Efficient Video Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09322">http://arxiv.org/abs/2308.09322</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Adi Nugroho, Sangmin Woo, Sumin Lee, Changick Kim</li>
<li>for: 提高视频理解任务的效率和可扩展性，使用可用的音频和视频modalities进行效率的处理。</li>
<li>methods: 使用lightweight unimodal encoders提取全局视觉特征和音频特征，并使用Audio-Visual Temporal Saliency Transformer（AV-TeST）估计视频帧中的重要性分数。在空间维度中提高效率，使用Audio-Enhanced Spatial Patch Attention（AESPA）模块生成改进的粗细视觉特征，并使用策略网络生成重要的补做坐标。</li>
<li>results: 在多个视频认证测试准则中实现新的状态略进行多个视频认证任务，并实现更快的处理速度。<details>
<summary>Abstract</summary>
Deep learning has made significant strides in video understanding tasks, but the computation required to classify lengthy and massive videos using clip-level video classifiers remains impractical and prohibitively expensive. To address this issue, we propose Audio-Visual Glance Network (AVGN), which leverages the commonly available audio and visual modalities to efficiently process the spatio-temporally important parts of a video. AVGN firstly divides the video into snippets of image-audio clip pair and employs lightweight unimodal encoders to extract global visual features and audio features. To identify the important temporal segments, we use an Audio-Visual Temporal Saliency Transformer (AV-TeST) that estimates the saliency scores of each frame. To further increase efficiency in the spatial dimension, AVGN processes only the important patches instead of the whole images. We use an Audio-Enhanced Spatial Patch Attention (AESPA) module to produce a set of enhanced coarse visual features, which are fed to a policy network that produces the coordinates of the important patches. This approach enables us to focus only on the most important spatio-temporally parts of the video, leading to more efficient video recognition. Moreover, we incorporate various training techniques and multi-modal feature fusion to enhance the robustness and effectiveness of our AVGN. By combining these strategies, our AVGN sets new state-of-the-art performance in multiple video recognition benchmarks while achieving faster processing speed.
</details>
<details>
<summary>摘要</summary>
深度学习在视频理解任务中做出了重要的进步，但计算长期和大量视频使用clip级视频分类器仍然是不可能和过分昂贵的。为解决这个问题，我们提出了Audio-Visual Glance Network（AVGN），它利用通常可以获得的音频和视觉modalities来高效地处理视频中的空间-时间重要部分。AVGN首先将视频分割成帧和音频clip对的剪辑，然后使用轻量级单模态编码器提取全局视觉特征和音频特征。为了确定重要的时间段落，我们使用Audio-Visual Temporal Saliency Transformer（AV-TeST）来估算每帧的特征积分。然后，我们使用Audio-Enhanced Spatial Patch Attention（AESPA）模块生成一组改进后的粗糙视觉特征，并将其传递给一个策略网络，以生成视频中重要的空间-时间部分的坐标。这种方法使得我们只需要关注视频中最重要的空间-时间部分，从而提高视频识别的效率。此外，我们还 incorporatedvarious training techniques和多模态特征融合以提高我们的AVGN的 Robustness和有效性。通过组合这些策略，我们的AVGN在多个视频识别benchmark上达到了新的状态态表现，同时实现更快的处理速度。
</details></li>
</ul>
<hr>
<h2 id="Distributed-Robust-Learning-Based-Backstepping-Control-Aided-with-Neurodynamics-for-Consensus-Formation-Tracking-of-Underwater-Vessels"><a href="#Distributed-Robust-Learning-Based-Backstepping-Control-Aided-with-Neurodynamics-for-Consensus-Formation-Tracking-of-Underwater-Vessels" class="headerlink" title="Distributed Robust Learning-Based Backstepping Control Aided with Neurodynamics for Consensus Formation Tracking of Underwater Vessels"></a>Distributed Robust Learning-Based Backstepping Control Aided with Neurodynamics for Consensus Formation Tracking of Underwater Vessels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09320">http://arxiv.org/abs/2308.09320</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tao Yan, Zhe Xu, Simon X. Yang</li>
<li>for: 本 paper 旨在提出一种分布式Robust学习控制方法，用于多艘海上 vessel 的聚合成本 Tracking 问题，系统参数被完全 unknown 并且受到模型匹配错误、海洋干扰和噪声的影响。</li>
<li>methods: 本 paper 使用 graph theory  synthesize 分布式控制器，并提供了稳定性保证。由于参数不确定性仅出现在船舶动态模型中，因此使用了 backstepping control technique。然后，为了解决时变不确定系统的问题，提出了一种在线学习程序。此外，模型误差、环境干扰和测量噪声也被考虑并解决。</li>
<li>results: 本 paper 提出的分布式控制协议，可以在面对模型误差、海洋干扰和测量噪声等问题下，实现稳定的聚合成本 Tracking。并通过了大量的simulation experiment 来验证其效果。<details>
<summary>Abstract</summary>
This paper addresses distributed robust learning-based control for consensus formation tracking of multiple underwater vessels, in which the system parameters of the marine vessels are assumed to be entirely unknown and subject to the modeling mismatch, oceanic disturbances, and noises. Towards this end, graph theory is used to allow us to synthesize the distributed controller with a stability guarantee. Due to the fact that the parameter uncertainties only arise in the vessels' dynamic model, the backstepping control technique is then employed. Subsequently, to overcome the difficulties in handling time-varying and unknown systems, an online learning procedure is developed in the proposed distributed formation control protocol. Moreover, modeling errors, environmental disturbances, and measurement noises are considered and tackled by introducing a neurodynamics model in the controller design to obtain a robust solution. Then, the stability analysis of the overall closed-loop system under the proposed scheme is provided to ensure the robust adaptive performance at the theoretical level. Finally, extensive simulation experiments are conducted to further verify the efficacy of the presented distributed control protocol.
</details>
<details>
<summary>摘要</summary>
Here is the text in Simplified Chinese:这篇论文关于多艘海上船舶的协同追踪共轨，即使系统参数完全不确定，并且受到模型误差、海洋干扰和噪声的影响。为此，我们使用图论来确保稳定性，并使用backstepping控制技术来处理时间变化和不确定系统。此外，我们还引入了神经动力学模型来处理模型误差、环境干扰和测量噪声。最后，我们提供了对整个关闭环系统的稳定分析，以确保在理论上的稳定适应性。此外，我们还进行了详细的仿真实验来验证我们的分布式控制协议的有效性。
</details></li>
</ul>
<hr>
<h2 id="Towards-Attack-tolerant-Federated-Learning-via-Critical-Parameter-Analysis"><a href="#Towards-Attack-tolerant-Federated-Learning-via-Critical-Parameter-Analysis" class="headerlink" title="Towards Attack-tolerant Federated Learning via Critical Parameter Analysis"></a>Towards Attack-tolerant Federated Learning via Critical Parameter Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09318">http://arxiv.org/abs/2308.09318</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sungwon-han/fedcpa">https://github.com/sungwon-han/fedcpa</a></li>
<li>paper_authors: Sungwon Han, Sungwon Park, Fangzhao Wu, Sundong Kim, Bin Zhu, Xing Xie, Meeyoung Cha</li>
<li>for: 本研究旨在防御 federated learning 系统中的毒 poisoning 攻击，使用 Critical Parameter Analysis (FedCPA) 方法。</li>
<li>methods: 本研究使用了针对本地模型中权重参数的敏感分析，并提出了一种新的攻击忍受策略。</li>
<li>results: 实验结果表明，我们的模型在不同的攻击场景下，能够比现有的防御策略更高效地防御 poisoning 攻击。<details>
<summary>Abstract</summary>
Federated learning is used to train a shared model in a decentralized way without clients sharing private data with each other. Federated learning systems are susceptible to poisoning attacks when malicious clients send false updates to the central server. Existing defense strategies are ineffective under non-IID data settings. This paper proposes a new defense strategy, FedCPA (Federated learning with Critical Parameter Analysis). Our attack-tolerant aggregation method is based on the observation that benign local models have similar sets of top-k and bottom-k critical parameters, whereas poisoned local models do not. Experiments with different attack scenarios on multiple datasets demonstrate that our model outperforms existing defense strategies in defending against poisoning attacks.
</details>
<details>
<summary>摘要</summary>
federated learning 是一种用于共享模型的分布式训练方式，无需客户端共享私人数据。但是， federated learning 系统容易受到毒品攻击，当恶意客户端将false更新发送到中央服务器。现有的防御策略在非标一分布数据设置下无效。这篇论文提出了一种新的防御策略，即 FedCPA（ federated learning with Critical Parameter Analysis）。我们的攻击忍受聚合方法基于本地模型的涵义参数 sets 的观察，即善意本地模型的 top-k 和 bottom-k 涵义参数集相似，而毒品本地模型不同。在多个数据集上对不同的攻击场景进行了实验，我们的模型在防御毒品攻击方面表现出excel，比现有的防御策略更高效。
</details></li>
</ul>
<hr>
<h2 id="Robust-Audio-Anti-Spoofing-with-Fusion-Reconstruction-Learning-on-Multi-Order-Spectrograms"><a href="#Robust-Audio-Anti-Spoofing-with-Fusion-Reconstruction-Learning-on-Multi-Order-Spectrograms" class="headerlink" title="Robust Audio Anti-Spoofing with Fusion-Reconstruction Learning on Multi-Order Spectrograms"></a>Robust Audio Anti-Spoofing with Fusion-Reconstruction Learning on Multi-Order Spectrograms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09302">http://arxiv.org/abs/2308.09302</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ph-w2000/s2pecnet">https://github.com/ph-w2000/s2pecnet</a></li>
<li>paper_authors: Penghui Wen, Kun Hu, Wenxi Yue, Sen Zhang, Wanlei Zhou, Zhiyong Wang</li>
<li>for: 防止伪造语音（audio deepfake）攻击</li>
<li>methods: 使用多频率特征融合重建策略（S2pecNet），包括来自不同频率的spectral pattern的融合，以提高对不同伪造攻击的抗伪声识别表现。</li>
<li>results: 在ASVspoof2019 LA Challenge上取得了顶尖表现，EER为0.77%。<details>
<summary>Abstract</summary>
Robust audio anti-spoofing has been increasingly challenging due to the recent advancements on deepfake techniques. While spectrograms have demonstrated their capability for anti-spoofing, complementary information presented in multi-order spectral patterns have not been well explored, which limits their effectiveness for varying spoofing attacks. Therefore, we propose a novel deep learning method with a spectral fusion-reconstruction strategy, namely S2pecNet, to utilise multi-order spectral patterns for robust audio anti-spoofing representations. Specifically, spectral patterns up to second-order are fused in a coarse-to-fine manner and two branches are designed for the fine-level fusion from the spectral and temporal contexts. A reconstruction from the fused representation to the input spectrograms further reduces the potential fused information loss. Our method achieved the state-of-the-art performance with an EER of 0.77% on a widely used dataset: ASVspoof2019 LA Challenge.
</details>
<details>
<summary>摘要</summary>
受深圳技术的进步影响，Robust audio anti-spoofing已经变得越来越困难。虽然spectrograms表明其可以用于anti-spoofing，但是多个 spectral pattern的信息尚未得到了充分利用，这限制了它们在不同的 spoofing 攻击下的效iveness。因此，我们提出了一种基于深度学习的新方法，即S2pecNet，以利用多个 spectral pattern来获得Robust audio anti-spoofing表示。特别是，在第二顺序的spectral pattern中进行了混合，并在粗糙到细腻的manner中设置了两个分支来从spectral和temporal上下文中进行细粒度的拼接。从拼接后的表示重建回到输入spectrograms，可以避免潜在的混合信息损失。我们的方法在ASVspoof2019 LA Challenge上达到了状态级的表现，EER为0.77%。
</details></li>
</ul>
<hr>
<h2 id="V2A-Mapper-A-Lightweight-Solution-for-Vision-to-Audio-Generation-by-Connecting-Foundation-Models"><a href="#V2A-Mapper-A-Lightweight-Solution-for-Vision-to-Audio-Generation-by-Connecting-Foundation-Models" class="headerlink" title="V2A-Mapper: A Lightweight Solution for Vision-to-Audio Generation by Connecting Foundation Models"></a>V2A-Mapper: A Lightweight Solution for Vision-to-Audio Generation by Connecting Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09300">http://arxiv.org/abs/2308.09300</a></li>
<li>repo_url: None</li>
<li>paper_authors: Heng Wang, Jianbo Ma, Santiago Pascual, Richard Cartwright, Weidong Cai<br>for:This paper focuses on the problem of generating semantically-relevant sound from visual input, specifically using foundation models (FMs) to bridge the domain gap between visual and auditory modalities.methods:The proposed method uses a simple yet effective mapper mechanism (V2A-Mapper) to translate the visual input between the CLIP and CLAP spaces, and then uses pretrained audio generative FM AudioLDM to produce high-fidelity and visually-aligned sound.results:Compared to previous approaches, the proposed method achieves superior performance in both objective and subjective evaluations, with 53% and 19% improvement in fidelity and relevance, respectively, using 86% fewer parameters.<details>
<summary>Abstract</summary>
Building artificial intelligence (AI) systems on top of a set of foundation models (FMs) is becoming a new paradigm in AI research. Their representative and generative abilities learnt from vast amounts of data can be easily adapted and transferred to a wide range of downstream tasks without extra training from scratch. However, leveraging FMs in cross-modal generation remains under-researched when audio modality is involved. On the other hand, automatically generating semantically-relevant sound from visual input is an important problem in cross-modal generation studies. To solve this vision-to-audio (V2A) generation problem, existing methods tend to design and build complex systems from scratch using modestly sized datasets. In this paper, we propose a lightweight solution to this problem by leveraging foundation models, specifically CLIP, CLAP, and AudioLDM. We first investigate the domain gap between the latent space of the visual CLIP and the auditory CLAP models. Then we propose a simple yet effective mapper mechanism (V2A-Mapper) to bridge the domain gap by translating the visual input between CLIP and CLAP spaces. Conditioned on the translated CLAP embedding, pretrained audio generative FM AudioLDM is adopted to produce high-fidelity and visually-aligned sound. Compared to previous approaches, our method only requires a quick training of the V2A-Mapper. We further analyze and conduct extensive experiments on the choice of the V2A-Mapper and show that a generative mapper is better at fidelity and variability (FD) while a regression mapper is slightly better at relevance (CS). Both objective and subjective evaluation on two V2A datasets demonstrate the superiority of our proposed method compared to current state-of-the-art approaches - trained with 86% fewer parameters but achieving 53% and 19% improvement in FD and CS, respectively.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:建立基于基础模型（FM）的人工智能系统是当前AI研究中的新方案。这些基础模型通过大量数据学习的表示和生成能力，可以方便地适应多种下游任务，无需从头开始重新训练。然而，在音频模式中使用FM进行跨模态生成仍然受到了较少的研究。在这篇论文中，我们提出了一种轻量级的解决方案，利用CLIP、CLAP和AudioLDM这些基础模型。我们首先调查了视觉CLIP和听音CLAP模型之间的领域差距。然后，我们提出了一种简单 yet有效的映射机制（V2A-Mapper），用于跨模态的映射。 conditioned on the translated CLAP embedding,我们采用了预训练的听音生成FM AudioLDM，以生成具有高准确性和视觉对齐的声音。相比之前的方法，我们的方法只需快速训练V2A-Mapper。我们进一步分析和进行了大量实验，研究V2A-Mapper的选择问题，并发现生成映射在FD中性能提高53%，CS中性能提高19%。两个V2A数据集的对象和主观评估都表明了我们提出的方法在当前状态方法中的超越性，训练参数减少86%，FD和CS中性能提高53%和19%，分别。
</details></li>
</ul>
<hr>
<h2 id="How-important-are-specialized-transforms-in-Neural-Operators"><a href="#How-important-are-specialized-transforms-in-Neural-Operators" class="headerlink" title="How important are specialized transforms in Neural Operators?"></a>How important are specialized transforms in Neural Operators?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09293">http://arxiv.org/abs/2308.09293</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Ritam-M/LearnableTransformsNO">https://github.com/Ritam-M/LearnableTransformsNO</a></li>
<li>paper_authors: Ritam Majumdar, Shirish Karande, Lovekesh Vig</li>
<li>for: 本研究旨在探讨transform-based neural operators中转换层的重要性，以及其对 solving partial differential equations (PDEs) 的影响。</li>
<li>methods: 本研究使用了一种简单的方法，即将所有的转换层替换为学习型线性层，以评估其影响于性能和计算时间。</li>
<li>results: 研究发现，使用学习型线性层可以提供与最佳转换层相当的性能，并且在计算时间方面也有一定的优势。这种观察可能对未来关于Neural Operators的研究有着重要的影响。<details>
<summary>Abstract</summary>
Simulating physical systems using Partial Differential Equations (PDEs) has become an indispensible part of modern industrial process optimization. Traditionally, numerical solvers have been used to solve the associated PDEs, however recently Transform-based Neural Operators such as the Fourier Neural Operator and Wavelet Neural Operator have received a lot of attention for their potential to provide fast solutions for systems of PDEs. In this work, we investigate the importance of the transform layers to the reported success of transform based neural operators. In particular, we record the cost in terms of performance, if all the transform layers are replaced by learnable linear layers. Surprisingly, we observe that linear layers suffice to provide performance comparable to the best-known transform-based layers and seem to do so with a compute time advantage as well. We believe that this observation can have significant implications for future work on Neural Operators, and might point to other sources of efficiencies for these architectures.
</details>
<details>
<summary>摘要</summary>
使用分数方程（PDEs）模拟物理系统已成为现代工业过程优化的不可或缺的一部分。传统上，数值解法被用来解决相关的PDEs，但最近，基于变换的神经操作符，如傅里叶 neural operator和wavelet neural operator，在提供快速解决系统的PDEs方面受到了广泛关注。在这项工作中，我们研究了变换层的重要性，特别是替换所有变换层为学习的线性层后的成本。我们发现了一个Counterintuitive的现象：所有变换层被替换后，使用学习的线性层可以提供与最佳变换层相当的性能，并且在计算时间方面也有一定的优势。我们认为这一观察可能对未来神经操作符的研究产生重要的影响，并可能暴露出其他优化的来源。
</details></li>
</ul>
<hr>
<h2 id="Graph-based-Alignment-and-Uniformity-for-Recommendation"><a href="#Graph-based-Alignment-and-Uniformity-for-Recommendation" class="headerlink" title="Graph-based Alignment and Uniformity for Recommendation"></a>Graph-based Alignment and Uniformity for Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09292">http://arxiv.org/abs/2308.09292</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yangliangwei/graphau">https://github.com/yangliangwei/graphau</a></li>
<li>paper_authors: Liangwei Yang, Zhiwei Liu, Chen Wang, Mingdai Yang, Xiaolong Liu, Jing Ma, Philip S. Yu</li>
<li>for: addressing the sparsity issue in collaborative filtering-based recommender systems (RecSys)</li>
<li>methods:  proposes a novel approach called graph-based alignment and uniformity (GraphAU), which explicitly considers high-order connectivities in the user-item bipartite graph</li>
<li>results: significantly alleviates the sparsity issue and achieves state-of-the-art performance on four datasets, with the open-source code available at <a target="_blank" rel="noopener" href="https://github.com/YangLiangwei/GraphAU.Here's">https://github.com/YangLiangwei/GraphAU.Here&#39;s</a> the full Chinese text:</li>
<li>for: 本研究旨在解决collaborative filtering-based recommender systems (RecSys)中的缺乏问题。</li>
<li>methods: 提出了一种新的方法，即图基于对齐和均匀性(GraphAU)，该方法直接考虑用户-物品 биipartite图中的高阶连接度。</li>
<li>results: 在四个数据集上，GraphAU有效地解决了缺乏问题，并达到了当前最佳性能。代码可以在<a target="_blank" rel="noopener" href="https://github.com/YangLiangwei/GraphAU%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/YangLiangwei/GraphAU中下载。</a><details>
<summary>Abstract</summary>
Collaborative filtering-based recommender systems (RecSys) rely on learning representations for users and items to predict preferences accurately. Representation learning on the hypersphere is a promising approach due to its desirable properties, such as alignment and uniformity. However, the sparsity issue arises when it encounters RecSys. To address this issue, we propose a novel approach, graph-based alignment and uniformity (GraphAU), that explicitly considers high-order connectivities in the user-item bipartite graph. GraphAU aligns the user/item embedding to the dense vector representations of high-order neighbors using a neighborhood aggregator, eliminating the need to compute the burdensome alignment to high-order neighborhoods individually. To address the discrepancy in alignment losses, GraphAU includes a layer-wise alignment pooling module to integrate alignment losses layer-wise. Experiments on four datasets show that GraphAU significantly alleviates the sparsity issue and achieves state-of-the-art performance. We open-source GraphAU at https://github.com/YangLiangwei/GraphAU.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="HyperLoRA-for-PDEs"><a href="#HyperLoRA-for-PDEs" class="headerlink" title="HyperLoRA for PDEs"></a>HyperLoRA for PDEs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09290">http://arxiv.org/abs/2308.09290</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ritam Majumdar, Vishal Jadhav, Anirudh Deodhar, Shirish Karande, Lovekesh Vig, Venkataramana Runkana</li>
<li>for: 用于解决参数化部分 diferencial equations 的 neural surrogates 问题</li>
<li>methods: 使用 Hypernetwork 和 low-ranked adaptation (LoRA) 技术，将每层基本网络转化为低维度的tensor，并使用 hypernetworks 预测这些tensor的参数</li>
<li>results: 通过添加物理信息损失函数 HyperPINN 进行训练，可以快速学习参数化部分 differential equations 的解，如布格尔方程和奈尔-斯托克斯-科瓦斯纳流体动力学方程，并在参数量方面实现8倍减少，而不会影响准确性。<details>
<summary>Abstract</summary>
Physics-informed neural networks (PINNs) have been widely used to develop neural surrogates for solutions of Partial Differential Equations. A drawback of PINNs is that they have to be retrained with every change in initial-boundary conditions and PDE coefficients. The Hypernetwork, a model-based meta learning technique, takes in a parameterized task embedding as input and predicts the weights of PINN as output. Predicting weights of a neural network however, is a high-dimensional regression problem, and hypernetworks perform sub-optimally while predicting parameters for large base networks. To circumvent this issue, we use a low ranked adaptation (LoRA) formulation to decompose every layer of the base network into low-ranked tensors and use hypernetworks to predict the low-ranked tensors. Despite the reduced dimensionality of the resulting weight-regression problem, LoRA-based Hypernetworks violate the underlying physics of the given task. We demonstrate that the generalization capabilities of LoRA-based hypernetworks drastically improve when trained with an additional physics-informed loss component (HyperPINN) to satisfy the governing differential equations. We observe that LoRA-based HyperPINN training allows us to learn fast solutions for parameterized PDEs like Burger's equation and Navier Stokes: Kovasznay flow, while having an 8x reduction in prediction parameters on average without compromising on accuracy when compared to all other baselines.
</details>
<details>
<summary>摘要</summary>
физи学信息泛化神经网络（PINNs）已广泛应用于解决部分梯度方程的解的神经替代模型。 PINNs 的缺点是它们需要每次更改初始边界条件和微分方程系数时重新训练。 神经网络模型基于元学习技术（Hypernetwork）可以将任务嵌入作为输入，预测 PINN 的权重。 但是，预测神经网络权重是一个高维度回归问题，神经网络模型在预测基础网络参数时表现不佳。 为了解决这个问题，我们使用 low-rank adaptation（LoRA）形式划分每层基础网络中的每个层成低维度的矩阵，并使用神经网络预测这些低维度矩阵。 尽管LoRA-based Hypernetworks 的维度减少了，但是它们仍然不符合给定任务的物理学。 我们表明，通过在 LoRA-based HyperPINN 训练中添加物理学信息泛化损失函数，可以提高 LoRA-based HyperPINN 的泛化能力。 我们观察到，LoRA-based HyperPINN 训练可以快速地解决参数化的微分方程，如布尔格方程和奈尔-斯托克斯：科瓦兹纳流，而且在 average 上降低预测参数的数量约 8 倍，不会降低准确性。
</details></li>
</ul>
<hr>
<h2 id="Preference-conditioned-Pixel-based-AI-Agent-For-Game-Testing"><a href="#Preference-conditioned-Pixel-based-AI-Agent-For-Game-Testing" class="headerlink" title="Preference-conditioned Pixel-based AI Agent For Game Testing"></a>Preference-conditioned Pixel-based AI Agent For Game Testing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09289">http://arxiv.org/abs/2308.09289</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sherif Abdelfattah, Adrian Brown, Pushi Zhang<br>for: This paper aims to improve game testing AI agents’ ability to explore and test games with high quality and efficiency, addressing the limitations of current methods that rely on game state information and lack explicit control over exploration style.methods: The proposed agent design uses pixel-based state observations and imitation learning with self-supervised and supervised learning objectives to improve exploration coverage and test execution quality.results: The proposed agent significantly outperforms state-of-the-art pixel-based game testing agents in exploration coverage and test execution quality when evaluated on a complex open-world environment resembling many aspects of real AAA games.<details>
<summary>Abstract</summary>
The game industry is challenged to cope with increasing growth in demand and game complexity while maintaining acceptable quality standards for released games. Classic approaches solely depending on human efforts for quality assurance and game testing do not scale effectively in terms of time and cost. Game-testing AI agents that learn by interaction with the environment have the potential to mitigate these challenges with good scalability properties on time and costs. However, most recent work in this direction depends on game state information for the agent's state representation, which limits generalization across different game scenarios. Moreover, game test engineers usually prefer exploring a game in a specific style, such as exploring the golden path. However, current game testing AI agents do not provide an explicit way to satisfy such a preference. This paper addresses these limitations by proposing an agent design that mainly depends on pixel-based state observations while exploring the environment conditioned on a user's preference specified by demonstration trajectories. In addition, we propose an imitation learning method that couples self-supervised and supervised learning objectives to enhance the quality of imitation behaviors. Our agent significantly outperforms state-of-the-art pixel-based game testing agents over exploration coverage and test execution quality when evaluated on a complex open-world environment resembling many aspects of real AAA games.
</details>
<details>
<summary>摘要</summary>
游戏产业面临增长的需求和游戏复杂度的挑战，同时保持适当的质量标准 для发布的游戏。经典的方法仅凭靠人工努力来确保质量检测和游戏测试，效率不足。基于环境互动学习的游戏测试AI代理具有良好的可扩展性，但大多数最新的研究仅基于游戏状态信息来表示代理的状态，导致泛化性不足。此外，游戏测试工程师通常会按照某种特定的风格来探索游戏，如探索 golden path。但现有的游戏测试AI代理没有直接提供这种偏好的实现方式。本文解决了这些限制，提出一种基于像素状态观察的代理设计，同时采用用户 preference 提供的示范轨迹来conditioned 环境探索。此外，我们提出一种imiter learning方法，将自动学习和监督学习目标相结合，以提高模仿行为质量。我们的代理在一个复杂的开放世界环境中表现出色，与现有的像素基于游戏测试代理相比，在探索覆盖率和测试执行质量方面显著超越。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Reasoning-Capabilities-of-Large-Language-Models-A-Graph-Based-Verification-Approach"><a href="#Enhancing-Reasoning-Capabilities-of-Large-Language-Models-A-Graph-Based-Verification-Approach" class="headerlink" title="Enhancing Reasoning Capabilities of Large Language Models: A Graph-Based Verification Approach"></a>Enhancing Reasoning Capabilities of Large Language Models: A Graph-Based Verification Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09267">http://arxiv.org/abs/2308.09267</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lang Cao</li>
<li>for: 这个论文主要是为了提高大语言模型（LLM）的理解能力，尤其是在复杂的理解任务中，如数学问题。</li>
<li>methods: 这个论文使用了一种图像基的方法来加强LLM的理解能力，具体来说是通过将多种解决方案转化为一个图像，以便对这些解决方案进行分析和验证。</li>
<li>results: 实验结果表明，这种图像基的验证方法不仅可以显著提高LLM的理解能力，而且也可以超过现有的验证方法在提高这些模型的理解性能方面。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have showcased impressive reasoning capabilities, particularly when guided by specifically designed prompts in complex reasoning tasks such as math word problems. These models typically solve tasks using a chain-of-thought approach, which not only bolsters their reasoning abilities but also provides valuable insights into their problem-solving process. However, there is still significant room for enhancing the reasoning abilities of LLMs. Some studies suggest that the integration of an LLM output verifier can boost reasoning accuracy without necessitating additional model training. In this paper, we follow these studies and introduce a novel graph-based method to further augment the reasoning capabilities of LLMs. We posit that multiple solutions to a reasoning task, generated by an LLM, can be represented as a reasoning graph due to the logical connections between intermediate steps from different reasoning paths. Therefore, we propose the Reasoning Graph Verifier (RGV) to analyze and verify the solutions generated by LLMs. By evaluating these graphs, models can yield more accurate and reliable results.Our experimental results show that our graph-based verification method not only significantly enhances the reasoning abilities of LLMs but also outperforms existing verifier methods in terms of improving these models' reasoning performance.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Point-Contrastive-Prediction-with-Semantic-Clustering-for-Self-Supervised-Learning-on-Point-Cloud-Videos"><a href="#Point-Contrastive-Prediction-with-Semantic-Clustering-for-Self-Supervised-Learning-on-Point-Cloud-Videos" class="headerlink" title="Point Contrastive Prediction with Semantic Clustering for Self-Supervised Learning on Point Cloud Videos"></a>Point Contrastive Prediction with Semantic Clustering for Self-Supervised Learning on Point Cloud Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09247">http://arxiv.org/abs/2308.09247</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoxiao Sheng, Zhiqiang Shen, Gang Xiao, Longguang Wang, Yulan Guo, Hehe Fan</li>
<li>for: 本文提出了一种点云视频自主学习框架，用于对象和场景数据的表示学习。previous方法通常在clip或帧层进行表示学习，但这些表示往往无法捕捉细腻的 semantics。</li>
<li>methods: 本文提出了一种点云自主学习框架，通过对点进行对比学习来 capture 细腻 semantics。此外，我们还引入了一种新的预测任务，即实现 superpoints 的Semantic alignment，以便更好地捕捉多尺度的 semantics。</li>
<li>results: 实验表明，我们的方法可以比超过supervised counterparts 的表示学习方法在多种下游任务上表现出色，并且表明 learned 表示的转移性。<details>
<summary>Abstract</summary>
We propose a unified point cloud video self-supervised learning framework for object-centric and scene-centric data. Previous methods commonly conduct representation learning at the clip or frame level and cannot well capture fine-grained semantics. Instead of contrasting the representations of clips or frames, in this paper, we propose a unified self-supervised framework by conducting contrastive learning at the point level. Moreover, we introduce a new pretext task by achieving semantic alignment of superpoints, which further facilitates the representations to capture semantic cues at multiple scales. In addition, due to the high redundancy in the temporal dimension of dynamic point clouds, directly conducting contrastive learning at the point level usually leads to massive undesired negatives and insufficient modeling of positive representations. To remedy this, we propose a selection strategy to retain proper negatives and make use of high-similarity samples from other instances as positive supplements. Extensive experiments show that our method outperforms supervised counterparts on a wide range of downstream tasks and demonstrates the superior transferability of the learned representations.
</details>
<details>
<summary>摘要</summary>
我们提出了一种综合点云视频自动学习框架，用于物体和场景数据的 Representation Learning。过去的方法通常在clip或帧级进行 Representation Learning，但这些方法难以捕捉细腻的 semantics。相反，在这篇论文中，我们提出了一种综合自我超vised学习框架，通过在点级进行对比学习。此外，我们还引入了一种新的预text任务，即实现superpoint的semantic aligning，以便 representations能够捕捉多个尺度的semanticcue。此外，由于点云动态数据中的时间维度具有高的重复率，直接在点级进行对比学习通常会导致庞大的undesired negatives和Positive representations的不足。为了解决这个问题，我们提出了一种选择策略，以保留正确的负例和利用其他实例中的高相似性样本作为Positive complement。广泛的实验表明，我们的方法在多种下游任务上表现出优于supervised counterpart，并且demonstrates the superior transferability of the learned representations。
</details></li>
</ul>
<hr>
<h2 id="A-Robust-Policy-Bootstrapping-Algorithm-for-Multi-objective-Reinforcement-Learning-in-Non-stationary-Environments"><a href="#A-Robust-Policy-Bootstrapping-Algorithm-for-Multi-objective-Reinforcement-Learning-in-Non-stationary-Environments" class="headerlink" title="A Robust Policy Bootstrapping Algorithm for Multi-objective Reinforcement Learning in Non-stationary Environments"></a>A Robust Policy Bootstrapping Algorithm for Multi-objective Reinforcement Learning in Non-stationary Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09734">http://arxiv.org/abs/2308.09734</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sherif Abdelfattah, Kathryn Kasmarik, Jiankun Hu</li>
<li>for: 这个论文主要旨在解决多目标Markov决策过程中的多目标优化问题，这种问题涉及到随机过程的Sequential决策，同时满足Markov性的约束。</li>
<li>methods: 这篇论文使用了多目标激励学习方法，它将激励学习概念与多目标优化技术相结合，但这些方法具有缺乏适应非站点环境的缺点。</li>
<li>results: 该论文提出了一种发展优化方法，可以在在线环境中不断演化政策覆盖集，同时在定义的目标空间中探索Preferencespace。该算法在非站点环境中表现出了明显的优势，并在站点环境中达到了相对的比较Result。<details>
<summary>Abstract</summary>
Multi-objective Markov decision processes are a special kind of multi-objective optimization problem that involves sequential decision making while satisfying the Markov property of stochastic processes. Multi-objective reinforcement learning methods address this problem by fusing the reinforcement learning paradigm with multi-objective optimization techniques. One major drawback of these methods is the lack of adaptability to non-stationary dynamics in the environment. This is because they adopt optimization procedures that assume stationarity to evolve a coverage set of policies that can solve the problem. This paper introduces a developmental optimization approach that can evolve the policy coverage set while exploring the preference space over the defined objectives in an online manner. We propose a novel multi-objective reinforcement learning algorithm that can robustly evolve a convex coverage set of policies in an online manner in non-stationary environments. We compare the proposed algorithm with two state-of-the-art multi-objective reinforcement learning algorithms in stationary and non-stationary environments. Results showed that the proposed algorithm significantly outperforms the existing algorithms in non-stationary environments while achieving comparable results in stationary environments.
</details>
<details>
<summary>摘要</summary>
本文提出了一种发展优化方法，可以在在线模式下，在定义的目标空间中探索 preference space，而不是采用优化过程。我们提出了一种新的多目标激励学习算法，可以在非站ARY环境中稳定地演化一个凸包含策略的覆盖集。我们与两种现有的多目标激励学习算法进行比较，Results showed that the proposed algorithm significantly outperforms the existing algorithms in non-stationary environments, while achieving comparable results in stationary environments.
</details></li>
</ul>
<hr>
<h2 id="Masked-Spatio-Temporal-Structure-Prediction-for-Self-supervised-Learning-on-Point-Cloud-Videos"><a href="#Masked-Spatio-Temporal-Structure-Prediction-for-Self-supervised-Learning-on-Point-Cloud-Videos" class="headerlink" title="Masked Spatio-Temporal Structure Prediction for Self-supervised Learning on Point Cloud Videos"></a>Masked Spatio-Temporal Structure Prediction for Self-supervised Learning on Point Cloud Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09245">http://arxiv.org/abs/2308.09245</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/johnsonsign/mast-pre">https://github.com/johnsonsign/mast-pre</a></li>
<li>paper_authors: Zhiqiang Shen, Xiaoxiao Sheng, Hehe Fan, Longguang Wang, Yulan Guo, Qiong Liu, Hao Wen, Xi Zhou</li>
<li>for: 本研究旨在提出一种无需人工标注的点云视频理解方法，以捕捉点云视频中的空间temporal结构。</li>
<li>methods: 该方法基于点云ube掩码和两种自我supervised学习任务。首先，通过重建掩码后的点云，方法可以捕捉点云视频的外观信息。其次，为了学习运动，我们提出了一个时间卡达度差预测任务，该任务估算点云ube中点的变化。</li>
<li>results: 对于MSRAction-3D、NTU-RGBD、NvGesture和SHREC’17等数据集，我们进行了广泛的实验，并证明了提议的方法的有效性。<details>
<summary>Abstract</summary>
Recently, the community has made tremendous progress in developing effective methods for point cloud video understanding that learn from massive amounts of labeled data. However, annotating point cloud videos is usually notoriously expensive. Moreover, training via one or only a few traditional tasks (e.g., classification) may be insufficient to learn subtle details of the spatio-temporal structure existing in point cloud videos. In this paper, we propose a Masked Spatio-Temporal Structure Prediction (MaST-Pre) method to capture the structure of point cloud videos without human annotations. MaST-Pre is based on spatio-temporal point-tube masking and consists of two self-supervised learning tasks. First, by reconstructing masked point tubes, our method is able to capture the appearance information of point cloud videos. Second, to learn motion, we propose a temporal cardinality difference prediction task that estimates the change in the number of points within a point tube. In this way, MaST-Pre is forced to model the spatial and temporal structure in point cloud videos. Extensive experiments on MSRAction-3D, NTU-RGBD, NvGesture, and SHREC'17 demonstrate the effectiveness of the proposed method.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese translation)最近，社区在开发有效的点云视频理解方法上做出了很大的进步，通过大量标注数据学习。然而，标注点云视频通常非常昂贵。此外，通过一些传统任务（例如分类）训练可能不足以学习点云视频中细腻的空间-时间结构。在这篇论文中，我们提出了一种Masked Spatio-Temporal Structure Prediction（MaST-Pre）方法，可以无需人工标注，捕捉点云视频的结构。MaST-Pre基于空间-时间点管道遮盲，包括两个自我超vised学习任务。首先，通过重建遮盲点管道，我们的方法可以捕捉点云视频的外观信息。其次，为了学习运动，我们提出了一个时间 cardinality difference prediction任务，可以估计点管道中点的变化。这样，MaST-Pre是被迫模型点云视频的空间和时间结构。我们在 MSRAction-3D、NTU-RGBD、NvGesture 和 SHREC'17 上进行了广泛的实验， demonstarted 提出的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Intrinsically-Motivated-Hierarchical-Policy-Learning-in-Multi-objective-Markov-Decision-Processes"><a href="#Intrinsically-Motivated-Hierarchical-Policy-Learning-in-Multi-objective-Markov-Decision-Processes" class="headerlink" title="Intrinsically Motivated Hierarchical Policy Learning in Multi-objective Markov Decision Processes"></a>Intrinsically Motivated Hierarchical Policy Learning in Multi-objective Markov Decision Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09733">http://arxiv.org/abs/2308.09733</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sherif Abdelfattah, Kathryn Merrick, Jiankun Hu</li>
<li>for:  solve multi-objective Markov decision processes in non-stationary environments</li>
<li>methods:  intrinsically motivated reinforcement learning with dual-phase learning</li>
<li>results:  significantly outperforms state-of-the-art multi-objective reinforcement methods in a dynamic robotics environmentHere’s the simplified Chinese text:</li>
<li>for: 解决多目标Markov决策过程中的非站点环境</li>
<li>methods: 使用内在动机导向的强化学习方法，包括双期学习</li>
<li>results: 在动力环境中显著超越了现有多目标强化方法的性能I hope this helps!<details>
<summary>Abstract</summary>
Multi-objective Markov decision processes are sequential decision-making problems that involve multiple conflicting reward functions that cannot be optimized simultaneously without a compromise. This type of problems cannot be solved by a single optimal policy as in the conventional case. Alternatively, multi-objective reinforcement learning methods evolve a coverage set of optimal policies that can satisfy all possible preferences in solving the problem. However, many of these methods cannot generalize their coverage sets to work in non-stationary environments. In these environments, the parameters of the state transition and reward distribution vary over time. This limitation results in significant performance degradation for the evolved policy sets. In order to overcome this limitation, there is a need to learn a generic skill set that can bootstrap the evolution of the policy coverage set for each shift in the environment dynamics therefore, it can facilitate a continuous learning process. In this work, intrinsically motivated reinforcement learning has been successfully deployed to evolve generic skill sets for learning hierarchical policies to solve multi-objective Markov decision processes. We propose a novel dual-phase intrinsically motivated reinforcement learning method to address this limitation. In the first phase, a generic set of skills is learned. While in the second phase, this set is used to bootstrap policy coverage sets for each shift in the environment dynamics. We show experimentally that the proposed method significantly outperforms state-of-the-art multi-objective reinforcement methods in a dynamic robotics environment.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese translation:多目标Markov决策过程是一种sequential decision-making问题，其中存在多个矛盾的奖励函数，无法同时优化。这类问题不可以通过单一的优化策略来解决，与传统情况不同。相反，多目标学习方法会演化一个coverage集的优化策略，以满足所有可能的偏好。然而，许多这些方法无法泛化其coverage集，以适应非站ARY environments。在这些环境中，状态转移和奖励分布的参数变化过时。这限制了演化出来的策略集的性能。为了突破这些限制，需要学习一个通用技能集，可以启动演化策略集的扩展。在这种情况下，我们提出了一种新的双相启动多目标学习方法。在第一阶段，学习一个通用技能集。在第二阶段，使用这个集来扩展策略集 для每个环境动态变化。我们实验表明，我们提出的方法在动态 роботикс环境中明显超过了当前多目标学习方法的性能。
</details></li>
</ul>
<hr>
<h2 id="Digital-Twin-Oriented-Complex-Networked-Systems-based-on-Heterogeneous-node-features-and-interaction-rules"><a href="#Digital-Twin-Oriented-Complex-Networked-Systems-based-on-Heterogeneous-node-features-and-interaction-rules" class="headerlink" title="Digital Twin-Oriented Complex Networked Systems based on Heterogeneous node features and interaction rules"></a>Digital Twin-Oriented Complex Networked Systems based on Heterogeneous node features and interaction rules</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11034">http://arxiv.org/abs/2308.11034</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaqi Wen, Bogdan Gabrys, Katarzyna Musial<br>for: This paper proposes a modelling framework for Digital Twin-Oriented Complex Networked Systems (DT-CNSs) to generate networks that faithfully represent real systems.methods: The modelling process focuses on features of nodes and interaction rules for creating connections based on individual node preferences.results: The paper presents a case study on disaster resilience of social networks during an epidemic outbreak, showing how different levels of structural and dynamics complexities influence network growth and epidemic spread. The analysis reveals that mitigation policies should target nodes with preferred features as they have higher infection risks and should be the focus of epidemic control.Here is the same information in Simplified Chinese text:for: 这篇论文提出了一种用于数字双体复杂网络系统（DT-CNS）的扩展模型 Frameworks，以生成具有真实系统特点的网络。methods: 模型过程关注节点特点和连接规则的互动，以建立基于个体节点偏好的连接。results: 论文通过一个案例研究，探讨在社交网络上疫情爆发时的灾害抵御能力，发现不同水平的结构和动态复杂性对网络增长和疫情传播产生了影响。分析表明，控制疫情时应该向具有偏好特点的节点进行抗疫措施，以降低疫情传播风险。<details>
<summary>Abstract</summary>
This study proposes an extendable modelling framework for Digital Twin-Oriented Complex Networked Systems (DT-CNSs) with a goal of generating networks that faithfully represent real systems. Modelling process focuses on (i) features of nodes and (ii) interaction rules for creating connections that are built based on individual node's preferences. We conduct experiments on simulation-based DT-CNSs that incorporate various features and rules about network growth and different transmissibilities related to an epidemic spread on these networks. We present a case study on disaster resilience of social networks given an epidemic outbreak by investigating the infection occurrence within specific time and social distance. The experimental results show how different levels of the structural and dynamics complexities, concerned with feature diversity and flexibility of interaction rules respectively, influence network growth and epidemic spread. The analysis revealed that, to achieve maximum disaster resilience, mitigation policies should be targeted at nodes with preferred features as they have higher infection risks and should be the focus of the epidemic control.
</details>
<details>
<summary>摘要</summary>
The case study on disaster resilience of social networks during an epidemic outbreak shows how different levels of structural and dynamics complexities, such as feature diversity and flexibility of interaction rules, influence network growth and epidemic spread. The analysis reveals that mitigation policies should target nodes with preferred features as they have a higher risk of infection and should be the focus of epidemic control.Translation in Simplified Chinese:这个研究提出了一个可扩展的模型框架，用于数字双方向复杂网络系统（DT-CNS），以创建准确表示实际系统的网络。模型 процесс关注节点特性以及建立连接的交互规则，这些规则基于个节点的偏好。研究通过在模拟基础上进行实验，检验不同特性和规则对网络增长和疾病传播的影响。研究中的案例研究探讨了在疾病爆发时社交网络的难以恢复性，通过对特定时间和社交距离内的感染发生进行调查。实验结果表明，不同的结构和动态复杂性水平对网络增长和疾病传播产生不同的影响。分析表明，为了实现最大的灾害抵御能力，应该通过针对具有偏好特性的节点进行疫苗控制，以降低这些节点的感染风险。
</details></li>
</ul>
<hr>
<h2 id="Improving-Buoy-Detection-with-Deep-Transfer-Learning-for-Mussel-Farm-Automation"><a href="#Improving-Buoy-Detection-with-Deep-Transfer-Learning-for-Mussel-Farm-Automation" class="headerlink" title="Improving Buoy Detection with Deep Transfer Learning for Mussel Farm Automation"></a>Improving Buoy Detection with Deep Transfer Learning for Mussel Farm Automation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09238">http://arxiv.org/abs/2308.09238</a></li>
<li>repo_url: None</li>
<li>paper_authors: Carl McMillan, Junhong Zhao, Bing Xue, Ross Vennell, Mengjie Zhang</li>
<li>for: 提高 mussel farm 运营效率和管理 accuracy 和鲜明度</li>
<li>methods: 使用人工智能和计算机视觉技术，包括深度学习方法和对象检测</li>
<li>results: 通过适应转移学习和数据多样性，实现了对浮标的检测性能的显著提高，并且在不同的天气和照明条件下具有良好的一致性和鲜明度<details>
<summary>Abstract</summary>
The aquaculture sector in New Zealand is experiencing rapid expansion, with a particular emphasis on mussel exports. As the demands of mussel farming operations continue to evolve, the integration of artificial intelligence and computer vision techniques, such as intelligent object detection, is emerging as an effective approach to enhance operational efficiency. This study delves into advancing buoy detection by leveraging deep learning methodologies for intelligent mussel farm monitoring and management. The primary objective centers on improving accuracy and robustness in detecting buoys across a spectrum of real-world scenarios. A diverse dataset sourced from mussel farms is captured and labeled for training, encompassing imagery taken from cameras mounted on both floating platforms and traversing vessels, capturing various lighting and weather conditions. To establish an effective deep learning model for buoy detection with a limited number of labeled data, we employ transfer learning techniques. This involves adapting a pre-trained object detection model to create a specialized deep learning buoy detection model. We explore different pre-trained models, including YOLO and its variants, alongside data diversity to investigate their effects on model performance. Our investigation demonstrates a significant enhancement in buoy detection performance through deep learning, accompanied by improved generalization across diverse weather conditions, highlighting the practical effectiveness of our approach.
</details>
<details>
<summary>摘要</summary>
新西兰aquaculture业正在迅速扩张，特别是对贝壳出口有着强烈的注意力。随着贝壳养殖操作的需求不断演化，人工智能和计算机视觉技术的应用正在成为提高操作效率的有效方法。本研究探讨了基于深度学习方法的智能贝壳园监测和管理，以提高贝壳园的准确性和鲁棒性。我们使用了多种预训练模型，包括YOLO和其变体，以及不同的数据多样性来研究它们对模型性能的影响。我们的调查显示，通过深度学习实现了贝壳检测的显著提高，同时在多种天气条件下也有良好的泛化性，这说明了我们的方法的实际效果。
</details></li>
</ul>
<hr>
<h2 id="Advancing-Relation-Extraction-through-Language-Probing-with-Exemplars-from-Set-Co-Expansion"><a href="#Advancing-Relation-Extraction-through-Language-Probing-with-Exemplars-from-Set-Co-Expansion" class="headerlink" title="Advancing Relation Extraction through Language Probing with Exemplars from Set Co-Expansion"></a>Advancing Relation Extraction through Language Probing with Exemplars from Set Co-Expansion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.11720">http://arxiv.org/abs/2308.11720</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yerong Li, Roxana Girju</li>
<li>for: 提高relation classification的准确率和降低相似类异类的混淆</li>
<li>methods:  integrate representative examples and through co-set expansion, context-free Hearst patterns, and contrastive examples tuning</li>
<li>results: 实验结果表明提出的方法可以显著提高relation extraction的准确率，同时降低相似类异类的混淆<details>
<summary>Abstract</summary>
Relation Extraction (RE) is a pivotal task in automatically extracting structured information from unstructured text. In this paper, we present a multi-faceted approach that integrates representative examples and through co-set expansion. The primary goal of our method is to enhance relation classification accuracy and mitigating confusion between contrastive classes.   Our approach begins by seeding each relationship class with representative examples. Subsequently, our co-set expansion algorithm enriches training objectives by incorporating similarity measures between target pairs and representative pairs from the target class. Moreover, the co-set expansion process involves a class ranking procedure that takes into account exemplars from contrastive classes. Contextual details encompassing relation mentions are harnessed via context-free Hearst patterns to ascertain contextual similarity.   Empirical evaluation demonstrates the efficacy of our co-set expansion approach, resulting in a significant enhancement of relation classification performance. Our method achieves an observed margin of at least 1 percent improvement in accuracy in most settings, on top of existing fine-tuning approaches. To further refine our approach, we conduct an in-depth analysis that focuses on tuning contrastive examples. This strategic selection and tuning effectively reduce confusion between classes sharing similarities, leading to a more precise classification process.   Experimental results underscore the effectiveness of our proposed framework for relation extraction. The synergy between co-set expansion and context-aware prompt tuning substantially contributes to improved classification accuracy. Furthermore, the reduction in confusion between contrastive classes through contrastive examples tuning validates the robustness and reliability of our method.
</details>
<details>
<summary>摘要</summary>
<<SYS>>关系提取（RE）是自动从不结构化文本中提取结构化信息的关键任务。在这篇论文中，我们提出了一种多方面的方法，它将表示例和相似扩展相结合。我们的方法的 PRIMARY GOAL 是提高关系类别的分类精度，并降低对比类别的混淆。我们的方法开始于每个关系类别中的表示例。然后，我们的相似扩展算法将训练目标包含类别之间的相似度。此外，相似扩展过程还包括一个类别排名过程，它考虑了对应类别中的表示例。 Contextual details  surrounding relation mentions are harnessed via context-free Hearst patterns to ascertain contextual similarity.实验结果表明，我们的相似扩展方法有效地提高了关系分类性能。我们的方法在大多数设置下达到了至少1%的提升率，并且在现有的细化方法之上进行了进一步的优化。为了进一步改进我们的方法，我们进行了深入的分析，将对于相似类别的选择和调整作为战略。这种策略性的选择和调整有效地减少了类别之间的混淆，导致更加精准的分类过程。实验结果证明了我们提出的关系提取框架的效iveness。它的同时进行相似扩展和上下文相关的提升，使得分类性能得到了进一步提高。此外，通过对相似类别进行调整，我们的方法的可靠性和可靠性得到了证明。
</details></li>
</ul>
<hr>
<h2 id="Baird-Counterexample-Is-Solved-with-an-example-of-How-to-Debug-a-Two-time-scale-Algorithm"><a href="#Baird-Counterexample-Is-Solved-with-an-example-of-How-to-Debug-a-Two-time-scale-Algorithm" class="headerlink" title="Baird Counterexample Is Solved: with an example of How to Debug a Two-time-scale Algorithm"></a>Baird Counterexample Is Solved: with an example of How to Debug a Two-time-scale Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09732">http://arxiv.org/abs/2308.09732</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hengshuai Yao</li>
<li>for: 测试和比较离况学习算法的效果</li>
<li>methods: 使用Gradient TD算法和两个时间步骤测量算法</li>
<li>results: 解释TD算法在这个例子中的缓慢问题，并提供了一个可用于研究离况学习算法的 debug 技术，以及实验结果显示 Impression GTD 算法在这个例子中的快速收敛。<details>
<summary>Abstract</summary>
Baird counterexample was proposed by Leemon Baird in 1995, first used to show that the Temporal Difference (TD(0)) algorithm diverges on this example. Since then, it is often used to test and compare off-policy learning algorithms. Gradient TD algorithms solved the divergence issue of TD on Baird counterexample. However, their convergence on this example is still very slow, and the nature of the slowness is not well understood, e.g., see (Sutton and Barto 2018).   This note is to understand in particular, why TDC is slow on this example, and provide debugging analysis to understand this behavior. Our debugging technique can be used to study the convergence behavior of two-time-scale stochastic approximation algorithms. We also provide empirical results of the recent Impression GTD algorithm on this example, showing the convergence is very fast, in fact, in a linear rate. We conclude that Baird counterexample is solved, by an algorithm with convergence guarantee to the TD solution in general and a fast convergence rate.
</details>
<details>
<summary>摘要</summary>
白尔德对例（Baird counterexample）于1995年由Leemon Baird提出，用以证明TD(0)算法在这个例子中崩溃。自此以后，它经常用于测试和比较不同的离政学习算法。梯度TD算法解决了TD算法在白尔德对例中的崩溃问题，但它们在这个例子上的 converges 速度非常慢，并且不很了解这种慢速度的性质。例如，参见（Sutton和Barto 2018）。本记录的目的是要更好地理解TD算法在白尔德对例上的慢速度，并提供调试分析来理解这种行为。我们的调试技术可以用来研究两个时间尺度的随机抽象算法的收敛行为。我们还提供了最近的Impression GTD算法在这个例子上的实验结果，显示其 converge 速度非常快，甚至在线性速度。我们结论是，白尔德对例已经被解决，并且有一个可靠的收敛保证和快速 converges 速度。
</details></li>
</ul>
<hr>
<h2 id="Learning-in-Cooperative-Multiagent-Systems-Using-Cognitive-and-Machine-Models"><a href="#Learning-in-Cooperative-Multiagent-Systems-Using-Cognitive-and-Machine-Models" class="headerlink" title="Learning in Cooperative Multiagent Systems Using Cognitive and Machine Models"></a>Learning in Cooperative Multiagent Systems Using Cognitive and Machine Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09219">http://arxiv.org/abs/2308.09219</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ddm-lab/greedy-hysteretic-lenient-maibl">https://github.com/ddm-lab/greedy-hysteretic-lenient-maibl</a></li>
<li>paper_authors: Thuy Ngoc Nguyen, Duy Nhat Phan, Cleotilde Gonzalez</li>
<li>for: 本研究旨在开发有效的多智能体系统（MAS），以满足协作和协调人类的多种应用。</li>
<li>methods: 本研究提出三种变体的多智能IBLT模型（MAIBL），结合了IBLT的认知机制和MADRL模型来处理协调MAS在随机环境中的协同学习。</li>
<li>results: 对于不同的随机奖励设定，MAIBL模型在动态CMOTP任务中表现出比现有MADRL模型更快的学习速度和更好的协调性。<details>
<summary>Abstract</summary>
Developing effective Multi-Agent Systems (MAS) is critical for many applications requiring collaboration and coordination with humans. Despite the rapid advance of Multi-Agent Deep Reinforcement Learning (MADRL) in cooperative MAS, one major challenge is the simultaneous learning and interaction of independent agents in dynamic environments in the presence of stochastic rewards. State-of-the-art MADRL models struggle to perform well in Coordinated Multi-agent Object Transportation Problems (CMOTPs), wherein agents must coordinate with each other and learn from stochastic rewards. In contrast, humans often learn rapidly to adapt to nonstationary environments that require coordination among people. In this paper, motivated by the demonstrated ability of cognitive models based on Instance-Based Learning Theory (IBLT) to capture human decisions in many dynamic decision making tasks, we propose three variants of Multi-Agent IBL models (MAIBL). The idea of these MAIBL algorithms is to combine the cognitive mechanisms of IBLT and the techniques of MADRL models to deal with coordination MAS in stochastic environments from the perspective of independent learners. We demonstrate that the MAIBL models exhibit faster learning and achieve better coordination in a dynamic CMOTP task with various settings of stochastic rewards compared to current MADRL models. We discuss the benefits of integrating cognitive insights into MADRL models.
</details>
<details>
<summary>摘要</summary>
发展有效的多智能体系统（MAS）是许多需要协作和协调的应用中的关键。虽然多智能深度学习（MADRL）在合作MAS中得到了快速的进步，但一个主要挑战是独立的智能体在动态环境中同时学习和互动，并在恒定奖励下学习。现状最先进的MADRL模型在协调多智能对象运输问题（CMOTP）中表现不佳，这种问题需要智能体之间协调和学习。然而，人类在非站台环境中很快地适应和适应非站台环境，并且能够快速地学习。在这篇论文中，我们受到了基于实例学习理论（IBLT）的认知模型的能力所启发，并提出了三种多智能IBLT模型（MAIBL）。这些MAIBL算法的想法是将IBLT的认知机制与MADRL模型的技术相结合，以面对独立学习的协调MAS在随机奖励下的问题。我们示出了MAIBL模型在动态CMOTP任务中与不同设置的随机奖励下显著更快地学习和更好地协调。我们讨论了将认知预测 integrate into MADRL模型的好处。
</details></li>
</ul>
<hr>
<h2 id="GPU-Accelerated-Color-Correction-and-Frame-Warping-for-Real-time-Video-Stitching"><a href="#GPU-Accelerated-Color-Correction-and-Frame-Warping-for-Real-time-Video-Stitching" class="headerlink" title="GPU Accelerated Color Correction and Frame Warping for Real-time Video Stitching"></a>GPU Accelerated Color Correction and Frame Warping for Real-time Video Stitching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09209">http://arxiv.org/abs/2308.09209</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lu Yang, Zhenglun Kong, Ting Li, Xinyi Bai, Zhiye Lin, Hong Cheng</li>
<li>for: 实时拼接多个视频序列为全景视频</li>
<li>methods: 基于GPU加速的颜色修正和框架折叠，不需要精确的摄像机参数</li>
<li>results: 实时生成高质量全景视频<details>
<summary>Abstract</summary>
Traditional image stitching focuses on a single panorama frame without considering the spatial-temporal consistency in videos. The straightforward image stitching approach will cause temporal flicking and color inconstancy when it is applied to the video stitching task. Besides, inaccurate camera parameters will cause artifacts in the image warping. In this paper, we propose a real-time system to stitch multiple video sequences into a panoramic video, which is based on GPU accelerated color correction and frame warping without accurate camera parameters. We extend the traditional 2D-Matrix (2D-M) color correction approach and a present spatio-temporal 3D-Matrix (3D-M) color correction method for the overlap local regions with online color balancing using a piecewise function on global frames. Furthermore, we use pairwise homography matrices given by coarse camera calibration for global warping followed by accurate local warping based on the optical flow. Experimental results show that our system can generate highquality panorama videos in real time.
</details>
<details>
<summary>摘要</summary>
传统的图像融合方法集中精力于单一的панaramic帧，不考虑视频中的空间-时间一致性。直接使用图像融合方法会导致视频融合任务中的时间闪烁和颜色不稳定。此外，不准确的相机参数会导致图像扭曲。在这篇论文中，我们提出了一种基于GPU加速的实时系统，用于将多个视频序列拼接成一个投影视频。我们extend了传统的2D-矩阵（2D-M）颜色修正方法，并提出了一种基于空间-时间3D-矩阵（3D-M）颜色修正方法，用于在重叠地方进行在线颜色均衡使用分割函数。此外，我们使用粗略相机封锁得到的对角矩阵，然后使用精度地ocal warping基于运动图像。实验结果表明，我们的系统可以在实时中生成高质量的投影视频。
</details></li>
</ul>
<hr>
<h2 id="A-Model-Agnostic-Framework-for-Recommendation-via-Interest-aware-Item-Embeddings"><a href="#A-Model-Agnostic-Framework-for-Recommendation-via-Interest-aware-Item-Embeddings" class="headerlink" title="A Model-Agnostic Framework for Recommendation via Interest-aware Item Embeddings"></a>A Model-Agnostic Framework for Recommendation via Interest-aware Item Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09202">http://arxiv.org/abs/2308.09202</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amit Kumar Jaiswal, Yu Xiong</li>
<li>for: 提高推荐系统的准确率和个性化程度，使其能更好地捕捉用户的兴趣和需求。</li>
<li>methods: 利用 capsule network 和 interest-aware 技术，对 item 进行强化表示，直接从用户行为中捕捉用户兴趣。</li>
<li>results: 在多种benchmark dataset上进行了广泛的实验，并证明了该方法可以帮助提高推荐系统的性能，特别是在用户兴趣方面。<details>
<summary>Abstract</summary>
Item representation holds significant importance in recommendation systems, which encompasses domains such as news, retail, and videos. Retrieval and ranking models utilise item representation to capture the user-item relationship based on user behaviours. While existing representation learning methods primarily focus on optimising item-based mechanisms, such as attention and sequential modelling. However, these methods lack a modelling mechanism to directly reflect user interests within the learned item representations. Consequently, these methods may be less effective in capturing user interests indirectly. To address this challenge, we propose a novel Interest-aware Capsule network (IaCN) recommendation model, a model-agnostic framework that directly learns interest-oriented item representations. IaCN serves as an auxiliary task, enabling the joint learning of both item-based and interest-based representations. This framework adopts existing recommendation models without requiring substantial redesign. We evaluate the proposed approach on benchmark datasets, exploring various scenarios involving different deep neural networks, behaviour sequence lengths, and joint learning ratios of interest-oriented item representations. Experimental results demonstrate significant performance enhancements across diverse recommendation models, validating the effectiveness of our approach.
</details>
<details>
<summary>摘要</summary>
“item表示具有重要 significancenin recommendation系统中，包括新闻、零售和视频等领域。 Retrieval和排名模型通过item表示来捕捉用户-item关系，基于用户行为。而现有的表示学习方法主要是通过对item-based机制进行优化，如关注和序列模型。但这些方法缺乏直接表达用户兴趣的模elling机制，因此可能不能够准确地捕捉用户兴趣。为了解决这个挑战，我们提出了一种新的用户兴趣注意力感知网络（IaCN）推荐模型，这是一种model-agnostic框架，可以直接学习用户兴趣 oriented item表示。IaCN作为auxiliary task，可以在已有的推荐模型中 jointly learn item-based和用户兴趣 oriented表示。这种框架不需要大量重新设计现有的推荐模型。我们在 benchmark datasets上进行了实验，exploring不同的深度神经网络、行为序列长度和joint learning ratio of interest-oriented item表示。实验结果表明，我们的方法可以在多种不同的推荐模型和 scenarios中提高表现，证明了我们的方法的有效性。”
</details></li>
</ul>
<hr>
<h2 id="Regularizing-Adversarial-Imitation-Learning-Using-Causal-Invariance"><a href="#Regularizing-Adversarial-Imitation-Learning-Using-Causal-Invariance" class="headerlink" title="Regularizing Adversarial Imitation Learning Using Causal Invariance"></a>Regularizing Adversarial Imitation Learning Using Causal Invariance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09189">http://arxiv.org/abs/2308.09189</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ivan Ovinnikov, Joachim M. Buhmann</li>
<li>for: 这篇论文是用来学习模型从专家示范数据集中推断策略的。</li>
<li>methods: 这篇论文使用了对抗学习方法，并使用了一个推定器作为导向信号。</li>
<li>results: 这篇论文表明了使用 causal invariance 作为regularization principle可以解决模型吸收专家数据中的假 correlation问题。<details>
<summary>Abstract</summary>
Imitation learning methods are used to infer a policy in a Markov decision process from a dataset of expert demonstrations by minimizing a divergence measure between the empirical state occupancy measures of the expert and the policy. The guiding signal to the policy is provided by the discriminator used as part of an versarial optimization procedure. We observe that this model is prone to absorbing spurious correlations present in the expert data. To alleviate this issue, we propose to use causal invariance as a regularization principle for adversarial training of these models. The regularization objective is applicable in a straightforward manner to existing adversarial imitation frameworks. We demonstrate the efficacy of the regularized formulation in an illustrative two-dimensional setting as well as a number of high-dimensional robot locomotion benchmark tasks.
</details>
<details>
<summary>摘要</summary>
模型使用依据学习方法从专家示范数据集中推导策略，以减少专家和策略之间的差异度量。导引信号被用来引导策略，并通过对抗优化过程中的探测器来提供指导信号。我们发现这种模型容易吸收专家数据中的偶极 correlations。为解决这问题，我们提议使用 causal invariance 作为对抗训练这些模型的正则化原则。这个正则化目标可以直接应用于现有的对抗依据模型中。我们在一些二维设定和高维机器人行走 benchmark 任务中证明了这种准则的效果。
</details></li>
</ul>
<hr>
<h2 id="ChatGPT-HealthPrompt-Harnessing-the-Power-of-XAI-in-Prompt-Based-Healthcare-Decision-Support-using-ChatGPT"><a href="#ChatGPT-HealthPrompt-Harnessing-the-Power-of-XAI-in-Prompt-Based-Healthcare-Decision-Support-using-ChatGPT" class="headerlink" title="ChatGPT-HealthPrompt. Harnessing the Power of XAI in Prompt-Based Healthcare Decision Support using ChatGPT"></a>ChatGPT-HealthPrompt. Harnessing the Power of XAI in Prompt-Based Healthcare Decision Support using ChatGPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09731">http://arxiv.org/abs/2308.09731</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fatemeh Nazary, Yashar Deldjoo, Tommaso Di Noia</li>
<li>for: 这个研究旨在应用大语言模型（LLM）在医疗决策中，特点是使用 OpenAI 的 ChatGPT，并开发了一种新的应用方法。</li>
<li>methods: 这种方法利用了域知识，从高性能可读取 ML 模型中提取了关键信息，并将其灵活地 integrate 到提问设计中。</li>
<li>results: 研究表明，使用这种方法可以在数据稀缺的情况下实现高质量的二分类任务，并且在不同的数据条件下，OpenAI 的 ChatGPT 的性能比传统的直接学习 ML 模型要好。这种方法可以在医疗决策中提供更多的洞察力和支持。<details>
<summary>Abstract</summary>
This study presents an innovative approach to the application of large language models (LLMs) in clinical decision-making, focusing on OpenAI's ChatGPT. Our approach introduces the use of contextual prompts-strategically designed to include task description, feature description, and crucially, integration of domain knowledge-for high-quality binary classification tasks even in data-scarce scenarios. The novelty of our work lies in the utilization of domain knowledge, obtained from high-performing interpretable ML models, and its seamless incorporation into prompt design. By viewing these ML models as medical experts, we extract key insights on feature importance to aid in decision-making processes. This interplay of domain knowledge and AI holds significant promise in creating a more insightful diagnostic tool.   Additionally, our research explores the dynamics of zero-shot and few-shot prompt learning based on LLMs. By comparing the performance of OpenAI's ChatGPT with traditional supervised ML models in different data conditions, we aim to provide insights into the effectiveness of prompt engineering strategies under varied data availability. In essence, this paper bridges the gap between AI and healthcare, proposing a novel methodology for LLMs application in clinical decision support systems. It highlights the transformative potential of effective prompt design, domain knowledge integration, and flexible learning approaches in enhancing automated decision-making.
</details>
<details>
<summary>摘要</summary>
Our research also explores the dynamics of zero-shot and few-shot prompt learning based on LLMs. By comparing the performance of OpenAI's ChatGPT with traditional supervised ML models in different data conditions, we aim to provide insights into the effectiveness of prompt engineering strategies under varied data availability. This study bridges the gap between AI and healthcare, proposing a novel methodology for LLMs application in clinical decision support systems. It highlights the transformative potential of effective prompt design, domain knowledge integration, and flexible learning approaches in enhancing automated decision-making.
</details></li>
</ul>
<hr>
<h2 id="How-Does-Pruning-Impact-Long-Tailed-Multi-Label-Medical-Image-Classifiers"><a href="#How-Does-Pruning-Impact-Long-Tailed-Multi-Label-Medical-Image-Classifiers" class="headerlink" title="How Does Pruning Impact Long-Tailed Multi-Label Medical Image Classifiers?"></a>How Does Pruning Impact Long-Tailed Multi-Label Medical Image Classifiers?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09180">http://arxiv.org/abs/2308.09180</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vita-group/prunecxr">https://github.com/vita-group/prunecxr</a></li>
<li>paper_authors: Gregory Holste, Ziyu Jiang, Ajay Jaiswal, Maria Hanna, Shlomo Minkowitz, Alan C. Legasto, Joanna G. Escalon, Sharon Steinberger, Mark Bittman, Thomas C. Shen, Ying Ding, Ronald M. Summers, George Shih, Yifan Peng, Zhangyang Wang</li>
<li>for: 本研究旨在 investigating the impact of pruning on deep neural networks  trained for thorax disease diagnosis from chest X-rays (CXRs), and understanding how pruning affects model behavior in long-tailed, multi-label datasets.</li>
<li>methods: 研究使用了 two large CXR datasets, and analyzed the effect of pruning on disease classification. The study also identified individual CXRs where uncompressed and heavily pruned models disagreed, known as pruning-identified exemplars (PIEs), and conducted a human reader study to evaluate their unifying qualities.</li>
<li>results: 研究发现，采用 pruning 技术可以减少深度神经网络的内存使用和执行时间，但是这些方法可能会对模型行为产生负面影响，特别是在长尾、多标签数据集中。研究还发现，采用 pruning 技术可以增加模型的Forgettability，并且可以通过人类读者研究来评估这些 exemplars 的特征。<details>
<summary>Abstract</summary>
Pruning has emerged as a powerful technique for compressing deep neural networks, reducing memory usage and inference time without significantly affecting overall performance. However, the nuanced ways in which pruning impacts model behavior are not well understood, particularly for long-tailed, multi-label datasets commonly found in clinical settings. This knowledge gap could have dangerous implications when deploying a pruned model for diagnosis, where unexpected model behavior could impact patient well-being. To fill this gap, we perform the first analysis of pruning's effect on neural networks trained to diagnose thorax diseases from chest X-rays (CXRs). On two large CXR datasets, we examine which diseases are most affected by pruning and characterize class "forgettability" based on disease frequency and co-occurrence behavior. Further, we identify individual CXRs where uncompressed and heavily pruned models disagree, known as pruning-identified exemplars (PIEs), and conduct a human reader study to evaluate their unifying qualities. We find that radiologists perceive PIEs as having more label noise, lower image quality, and higher diagnosis difficulty. This work represents a first step toward understanding the impact of pruning on model behavior in deep long-tailed, multi-label medical image classification. All code, model weights, and data access instructions can be found at https://github.com/VITA-Group/PruneCXR.
</details>
<details>
<summary>摘要</summary>
剪辑技术已成为深度神经网络压缩的有力的方法，可以降低计算机 memory 使用量和执行时间，而不会对总性表现产生重要的影响。然而，剪辑对模型行为的细微影响还不够了解，特别是在常见的医疗数据集上。这种知识空白可能会在部署剪辑后导致诊断错误，这可能会影响病人健康。为了填补这一空白，我们进行了首次对剪辑对神经网络诊断颈部疾病（CXR）的影响的分析。在两个大CXR数据集上，我们研究了哪些疾病受到剪辑影响，并 characterize 疾病 "忘记度" 基于疾病频率和相互出现行为。此外，我们identified 压缩后和 heavily 剪辑后模型之间的分歧，称为剪辑标识 exemplars (PIEs)，并进行了人类读者研究来评估其共同特征。我们发现， radiologists 认为 PIEs 具有更多的标签噪音、更差的图像质量和更高的诊断难度。这项工作代表了对剪辑对深度、多标签医疗图像分类模型行为的影响的首次研究。所有代码、模型权重和数据访问指南可以在 GitHub 上找到：https://github.com/VITA-Group/PruneCXR。
</details></li>
</ul>
<hr>
<h2 id="Diversifying-AI-Towards-Creative-Chess-with-AlphaZero"><a href="#Diversifying-AI-Towards-Creative-Chess-with-AlphaZero" class="headerlink" title="Diversifying AI: Towards Creative Chess with AlphaZero"></a>Diversifying AI: Towards Creative Chess with AlphaZero</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09175">http://arxiv.org/abs/2308.09175</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tom Zahavy, Vivek Veeriah, Shaobo Hou, Kevin Waugh, Matthew Lai, Edouard Leurent, Nenad Tomasev, Lisa Schut, Demis Hassabis, Satinder Singh</li>
<li>for: 本研究探讨了人工智能（AI）系统是否可以通过创新决策机制来提高其计算能力。</li>
<li>methods: 本研究使用了AlphaZero（AZ）和其扩展版本AZ_db，通过行为多样性技术和低添加计划来让AI系统生成更多的想法，并选择最有前途的想法。</li>
<li>results: 实验表明，AZ_db在围棋游戏中表现出了多样化的做法，解决了更多的问题，并在围棋游戏中超越了更一致的团队。此外，在不同的开局中，AZ_db的成员特циализиру于不同的开局，通过低添加计划选择开局的棋手可以提高50个Elo分。研究结果表明，AI团队中的多样性贡献可以与人类团队中的多样性贡献相比，多样性是解决计算复杂问题的有价值资产。<details>
<summary>Abstract</summary>
In recent years, Artificial Intelligence (AI) systems have surpassed human intelligence in a variety of computational tasks. However, AI systems, like humans, make mistakes, have blind spots, hallucinate, and struggle to generalize to new situations. This work explores whether AI can benefit from creative decision-making mechanisms when pushed to the limits of its computational rationality. In particular, we investigate whether a team of diverse AI systems can outperform a single AI in challenging tasks by generating more ideas as a group and then selecting the best ones. We study this question in the game of chess, the so-called drosophila of AI. We build on AlphaZero (AZ) and extend it to represent a league of agents via a latent-conditioned architecture, which we call AZ_db. We train AZ_db to generate a wider range of ideas using behavioral diversity techniques and select the most promising ones with sub-additive planning. Our experiments suggest that AZ_db plays chess in diverse ways, solves more puzzles as a group and outperforms a more homogeneous team. Notably, AZ_db solves twice as many challenging puzzles as AZ, including the challenging Penrose positions. When playing chess from different openings, we notice that players in AZ_db specialize in different openings, and that selecting a player for each opening using sub-additive planning results in a 50 Elo improvement over AZ. Our findings suggest that diversity bonuses emerge in teams of AI agents, just as they do in teams of humans and that diversity is a valuable asset in solving computationally hard problems.
</details>
<details>
<summary>摘要</summary>
近年来，人工智能（AI）系统已经超越了人类智能在多种计算任务上。然而，AI系统，如人类一样，会出现错误、盲点、幻觉和难以通过新情况泛化。这项工作探讨了AI是否可以通过创新决策机制提高其计算理性的限制。特别是，我们研究了一群多样化AI系统是否可以在复杂任务上超越单个AI，通过生成更多的想法并选择最佳的想法来增强其表现。我们在国际象棋（即人工智能的“蜞蜓”）中进行了研究，我们称之为AZ_db。我们使用了行为多样性技术来让AZ_db生成更广泛的想法，并使用下降式规划选择最佳想法。我们的实验表明，AZ_db在各种开局下玩国际象棋，每个开局都有不同的特点，并且选择每个开局的最佳棋手使用下降式规划，可以提高50个Elo分。我们的发现表明，AI团队中的多样性奖励存在，与人类团队一样，多样性是解决计算上的困难问题的有价值资产。
</details></li>
</ul>
<hr>
<h2 id="Forensic-Data-Analytics-for-Anomaly-Detection-in-Evolving-Networks"><a href="#Forensic-Data-Analytics-for-Anomaly-Detection-in-Evolving-Networks" class="headerlink" title="Forensic Data Analytics for Anomaly Detection in Evolving Networks"></a>Forensic Data Analytics for Anomaly Detection in Evolving Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09171">http://arxiv.org/abs/2308.09171</a></li>
<li>repo_url: None</li>
<li>paper_authors: Li Yang, Abdallah Moubayed, Abdallah Shami, Amine Boukhtouta, Parisa Heidari, Stere Preda, Richard Brunner, Daniel Migault, Adel Larabi</li>
<li>for: 本研究旨在提供一个网络异常探测的数字分析框架，以帮助实现网络安全性。</li>
<li>methods: 本研究使用多元视角特征工程、无监督异常检测和全面结果修正过程，以探测网络中的异常行为。</li>
<li>results: 实验结果表明，提出的数字分析解决方案能够有效探测网络中的异常行为。<details>
<summary>Abstract</summary>
In the prevailing convergence of traditional infrastructure-based deployment (i.e., Telco and industry operational networks) towards evolving deployments enabled by 5G and virtualization, there is a keen interest in elaborating effective security controls to protect these deployments in-depth. By considering key enabling technologies like 5G and virtualization, evolving networks are democratized, facilitating the establishment of point presences integrating different business models ranging from media, dynamic web content, gaming, and a plethora of IoT use cases. Despite the increasing services provided by evolving networks, many cybercrimes and attacks have been launched in evolving networks to perform malicious activities. Due to the limitations of traditional security artifacts (e.g., firewalls and intrusion detection systems), the research on digital forensic data analytics has attracted more attention. Digital forensic analytics enables people to derive detailed information and comprehensive conclusions from different perspectives of cybercrimes to assist in convicting criminals and preventing future crimes. This chapter presents a digital analytics framework for network anomaly detection, including multi-perspective feature engineering, unsupervised anomaly detection, and comprehensive result correction procedures. Experiments on real-world evolving network data show the effectiveness of the proposed forensic data analytics solution.
</details>
<details>
<summary>摘要</summary>
在传统基础设施（如电信和产业运营网络）协调向5G和虚拟化的演进部署方向，有很大的兴趣在彻底保护这些部署。通过考虑关键启用技术（如5G和虚拟化），演进网络被民主化，使得不同业务模式的点 présence可以成功建立，包括媒体、动态网页内容、游戏和互联网器件多种应用场景。尽管演进网络提供了越来越多的服务，但是许多网络犯罪和攻击仍然在演进网络中进行不良活动。由于传统安全文件（如防火墙和侵入检测系统）的局限性，研究数字审计数据分析的研究吸引了更多的注意。数字审计数据分析可以帮助人们从不同角度获得详细信息和全面的结论，以帮助检察官捕捉犯罪分子和预防未来的犯罪。本章介绍了一种网络异常检测数字审计框架，包括多元角度特征工程、无监督异常检测和全面结果修正过程。实验表明，提案的数字审计数据分析解决方案在真实的演进网络数据上具有有效性。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Consistency-for-Assuring-Reliability-of-Large-Language-Models"><a href="#Semantic-Consistency-for-Assuring-Reliability-of-Large-Language-Models" class="headerlink" title="Semantic Consistency for Assuring Reliability of Large Language Models"></a>Semantic Consistency for Assuring Reliability of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09138">http://arxiv.org/abs/2308.09138</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harsh Raj, Vipul Gupta, Domenic Rosati, Subhabrata Majumdar</li>
<li>for: 这篇论文旨在提高大型自然语言模型（LLMs）的安全和可靠性，使其在不同的自然语言任务中表现更加稳定和可靠。</li>
<li>methods: 本论文提出了一个通用的对称性量表（Semantic Consistency Metric, SCM），用于评估 LLMS 在开放式文本生成任务中的对称性。此外，论文还提出了一个叫做 Ask-to-Choose (A2C) 的问题提示策略，用于增加对称性。</li>
<li>results: 实验结果显示，使用 A2C 问题提示策略可以将关注率提高 47%，并且可以将对称性指标提高 7 倍。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) exhibit remarkable fluency and competence across various natural language tasks. However, recent research has highlighted their sensitivity to variations in input prompts. To deploy LLMs in a safe and reliable manner, it is crucial for their outputs to be consistent when prompted with expressions that carry the same meaning or intent. While some existing work has explored how state-of-the-art LLMs address this issue, their evaluations have been confined to assessing lexical equality of single- or multi-word answers, overlooking the consistency of generative text sequences. For a more comprehensive understanding of the consistency of LLMs in open-ended text generation scenarios, we introduce a general measure of semantic consistency, and formulate multiple versions of this metric to evaluate the performance of various LLMs. Our proposal demonstrates significantly higher consistency and stronger correlation with human evaluations of output consistency than traditional metrics based on lexical consistency. Finally, we propose a novel prompting strategy, called Ask-to-Choose (A2C), to enhance semantic consistency. When evaluated for closed-book question answering based on answer variations from the TruthfulQA benchmark, A2C increases accuracy metrics for pretrained and finetuned LLMs by up to 47%, and semantic consistency metrics for instruction-tuned models by up to 7-fold.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在不同自然语言任务上表现出惊人的流畅和能力。然而，最近的研究发现，LLM在输入提示的变化对其输出有敏感性。为了在安全和可靠的方式部署LLM，其输出必须在具有同意义或目的的输入提示下保持一致性。一些现有的研究已经探讨了现代LLM如何处理这个问题，但是其评估仅限于单词或多词答案的字符串一致性，忽略了生成文本序列的一致性。为了更全面地了解LLM在开放式文本生成场景下的一致性，我们提出了一个通用的 semantic consistency 度量，并制定了多个版本的这个度量来评估不同LLM的性能。我们的提案显示在开放式文本生成场景下，我们的度量具有更高的一致性和更强的与人类评估输出一致性的相关性，而传统的基于字符串一致性的度量则显示较差的性能。最后，我们提出了一种新的提示策略，called Ask-to-Choose（A2C），以提高 semantic consistency。在基于 TruthfulQA benchmark 的关闭书问答任务上，A2C 提高了预训练和训练 LLM 的准确度指标 by up to 47%，并提高了 instruction-tuned 模型的 semantic consistency 指标 by up to 7倍。
</details></li>
</ul>
<hr>
<h2 id="EgoSchema-A-Diagnostic-Benchmark-for-Very-Long-form-Video-Language-Understanding"><a href="#EgoSchema-A-Diagnostic-Benchmark-for-Very-Long-form-Video-Language-Understanding" class="headerlink" title="EgoSchema: A Diagnostic Benchmark for Very Long-form Video Language Understanding"></a>EgoSchema: A Diagnostic Benchmark for Very Long-form Video Language Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09126">http://arxiv.org/abs/2308.09126</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/egoschema/egoschema">https://github.com/egoschema/egoschema</a></li>
<li>paper_authors: Karttikeya Mangalam, Raiymbek Akshulakov, Jitendra Malik</li>
<li>for: 本研究目的是评估现代视觉和语言系统的长期视频理解能力，特别是在面对长视频clip时的能力。</li>
<li>methods: 本研究使用了Ego4D dataset，经人工精心编辑，涵盖了多种自然的人类活动和行为，并提供了5000多个多选题answer对。为每个问题，需要根据三分钟的视频clip选择正确的答案。此外，本研究还引入了时间证书集，用于捕捉视频任务中的内在时间理解长度。</li>
<li>results: 本研究发现，使用EgoSchema dataset进行评估，现代视觉和语言系统的长期视频理解能力远低于人类的76%，甚至bilions参数的模型也只能达到20%~33%的答案正确率。本研究认为，EgoSchema dataset，拥有长期内在时间结构和多样化复杂性，将成为未来开发有效长期视频理解系统的价值评估工具。<details>
<summary>Abstract</summary>
We introduce EgoSchema, a very long-form video question-answering dataset, and benchmark to evaluate long video understanding capabilities of modern vision and language systems. Derived from Ego4D, EgoSchema consists of over 5000 human curated multiple choice question answer pairs, spanning over 250 hours of real video data, covering a very broad range of natural human activity and behavior. For each question, EgoSchema requires the correct answer to be selected between five given options based on a three-minute-long video clip. While some prior works have proposed video datasets with long clip lengths, we posit that merely the length of the video clip does not truly capture the temporal difficulty of the video task that is being considered. To remedy this, we introduce temporal certificate sets, a general notion for capturing the intrinsic temporal understanding length associated with a broad range of video understanding tasks & datasets. Based on this metric, we find EgoSchema to have intrinsic temporal lengths over 5.7x longer than the second closest dataset and 10x to 100x longer than any other video understanding dataset. Further, our evaluation of several current state-of-the-art video and language models shows them to be severely lacking in long-term video understanding capabilities. Even models with several billions of parameters achieve QA accuracy less than 33% (random is 20%) on the EgoSchema multi-choice question answering task, while humans achieve about 76% accuracy. We posit that \name{}{}, with its long intrinsic temporal structures and diverse complexity, would serve as a valuable evaluation probe for developing effective long-term video understanding systems in the future. Data and Zero-shot model evaluation code are open-sourced for both public and commercial use under the Ego4D license at http://egoschema.github.io
</details>
<details>
<summary>摘要</summary>
我们介绍EGOSchema，一个非常长形式的视频问题回答数据集和benchmark，用于评估现代视频和语言系统的长期视频理解能力。从EGO4D derive，EGOSchema包含了超过5000个人类混合多个选项的问题答案对，覆盖了250小时的真实视频数据，涵盖了人类活动和行为的非常广泛领域。对每个问题，EGOSchema需要根据三分钟的视频片段选择正确的答案，而不是仅根据视频clip的长度。我们认为，仅仅根据视频clip的长度不能够真正捕捉视频任务中的时间困难程度。为了解决这个问题，我们引入了时间证书集，一个通用的概念用于捕捉视频任务中的内在时间理解长度。根据这个指标，我们发现EGOSchema的内在时间长度高于第二最近的数据集5.7倍，并且与任何其他视频理解数据集相比，EGOSchema的内在时间长度在10倍至100倍之间。此外，我们评估了一些现代视频和语言模型，发现这些模型在EGOSchema的多选问题回答任务中的答案率仅在33%（随机为20%），而人类则有约76%的答案率。我们认为，EGOSchema，拥有长期视频结构和多方面的复杂性，将成为未来发展长期视频理解系统的重要评估棒。EGOSchema的数据和零式模型评估代码在http://egoschema.github.io上公开，供公共和商业使用，欢迎各位专家和研究人员前来参与。
</details></li>
</ul>
<hr>
<h2 id="Spectral-information-criterion-for-automatic-elbow-detection"><a href="#Spectral-information-criterion-for-automatic-elbow-detection" class="headerlink" title="Spectral information criterion for automatic elbow detection"></a>Spectral information criterion for automatic elbow detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09108">http://arxiv.org/abs/2308.09108</a></li>
<li>repo_url: None</li>
<li>paper_authors: L. Martino, R. San Millan-Castillo, E. Morgado</li>
<li>for: 本文提出了一种总结了其他较知名的信息拟合 criterion（BIC和AIC）的一般化信息拟合 criterion（SIC），并且可以自动检测error curve的特点。</li>
<li>methods: 本文使用了spectral information criterion（SIC）来提取error curve的几何特征，并且不需要知道likelihood函数。</li>
<li>results: 本文的实验结果表明，SIC可以提供一个较小的子集模型，并且这些模型都是error curve的拐角点。此外，本文还提出了一个实际适用的选择模型的方法。<details>
<summary>Abstract</summary>
We introduce a generalized information criterion that contains other well-known information criteria, such as Bayesian information Criterion (BIC) and Akaike information criterion (AIC), as special cases. Furthermore, the proposed spectral information criterion (SIC) is also more general than the other information criteria, e.g., since the knowledge of a likelihood function is not strictly required. SIC extracts geometric features of the error curve and, as a consequence, it can be considered an automatic elbow detector. SIC provides a subset of all possible models, with a cardinality that often is much smaller than the total number of possible models. The elements of this subset are elbows of the error curve. A practical rule for selecting a unique model within the sets of elbows is suggested as well. Theoretical invariance properties of SIC are analyzed. Moreover, we test SIC in ideal scenarios where provides always the optimal expected results. We also test SIC in several numerical experiments: some involving synthetic data, and two experiments involving real datasets. They are all real-world applications such as clustering, variable selection, or polynomial order selection, to name a few. The results show the benefits of the proposed scheme. Matlab code related to the experiments is also provided. Possible future research lines are finally discussed.
</details>
<details>
<summary>摘要</summary>
我们介绍一个通用化信息标准（Generalized Information Criterion，GIC），它包含了bayesian信息标准（BIC）和阿凯瑞信息标准（AIC）等其他知名信息标准的特别情况。此外，我们的spectral information criterion（SIC）还比其他信息标准更加通用，例如不需要知道假设概率函数。SIC从几何特征中提取错误曲线的几何特征，因此可以被视为一个自动拱角检测器。SIC提供了可能的模型集合，其中的元素都是错误曲线的拱角。我们建议一个实用的选择模型方法，以及对SIC的理论不变性性的分析。此外，我们还进行了一些理论测试和实验测试，包括使用 sintetic 数据和实际数据。结果显示了我们的方案的优点。matlab代码相关的实验也提供。最后，我们讨论了未来的研究方向。
</details></li>
</ul>
<hr>
<h2 id="MindMap-Knowledge-Graph-Prompting-Sparks-Graph-of-Thoughts-in-Large-Language-Models"><a href="#MindMap-Knowledge-Graph-Prompting-Sparks-Graph-of-Thoughts-in-Large-Language-Models" class="headerlink" title="MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models"></a>MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09729">http://arxiv.org/abs/2308.09729</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yilin Wen, Zifeng Wang, Jimeng Sun</li>
<li>for: 本研究旨在探讨如何通过知识图（KG）来帮助语言模型（LLM）更好地吸收新知识，激发LLM的创造力，并让LLM的决策过程更加透明。</li>
<li>methods: 我们建立了一个启用KG输入和检索外部知识的提示管道，以便让LLM能够更好地理解KG输入和推理。此外，我们还研究了如何提取LLM的推理路径和生成答案时的心图。</li>
<li>results: 我们在三个问答 dataset上进行了实验，结果表明，使用 MindMap 提示可以带来明显的实验性提升。例如，在 GPT-3.5 上使用 MindMap 提示可以在 GPT-4 上取得战胜性的表现。此外，我们还发现，通过结构化知识从 KG 中检索，MindMap 可以超越一些使用文档检索方法的提示方法，从而获得更高的准确率、更短的检索距离和更全面的知识。<details>
<summary>Abstract</summary>
LLMs usually exhibit limitations in their ability to incorporate new knowledge, the generation of hallucinations, and the transparency of their decision-making process. In this paper, we explore how to prompt LLMs with knowledge graphs (KG), working as a remedy to engage LLMs with up-to-date knowledge and elicit the reasoning pathways from LLMs. Specifically, we build a prompting pipeline that endows LLMs with the capability of comprehending KG inputs and inferring with a combined implicit knowledge and the retrieved external knowledge. In addition, we investigate eliciting the mind map on which LLMs perform the reasoning and generate the answers. It is identified that the produced mind map exhibits the reasoning pathways of LLMs grounded on the ontology of knowledge, hence bringing the prospects of probing and gauging LLM inference in production. The experiments on three question & answering datasets also show that MindMap prompting leads to a striking empirical gain. For instance, prompting a GPT-3.5 with MindMap yields an overwhelming performance over GPT-4 consistently. We also demonstrate that with structured facts retrieved from KG, MindMap can outperform a series of prompting-with-document-retrieval methods, benefiting from more accurate, concise, and comprehensive knowledge from KGs.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Identity-Aware-Semi-Supervised-Learning-for-Comic-Character-Re-Identification"><a href="#Identity-Aware-Semi-Supervised-Learning-for-Comic-Character-Re-Identification" class="headerlink" title="Identity-Aware Semi-Supervised Learning for Comic Character Re-Identification"></a>Identity-Aware Semi-Supervised Learning for Comic Character Re-Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09096">http://arxiv.org/abs/2308.09096</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gürkan Soykan, Deniz Yuret, Tevfik Metin Sezgin</li>
<li>for: 这个论文的目的是提出一种robust的半监督框架，用于在漫画中的人物重识别。</li>
<li>methods: 这个方法结合度量学习和一种新的’自我超vised’自我反例方法，通过对人物脸和身体的对比学习，提取人物特征。</li>
<li>results: 这个方法可以准确地重识别漫画中的人物，并且比使用脸或身体独立地重识别更有效。<details>
<summary>Abstract</summary>
Character re-identification, recognizing characters consistently across different panels in comics, presents significant challenges due to limited annotated data and complex variations in character appearances. To tackle this issue, we introduce a robust semi-supervised framework that combines metric learning with a novel 'Identity-Aware' self-supervision method by contrastive learning of face and body pairs of characters. Our approach involves processing both facial and bodily features within a unified network architecture, facilitating the extraction of identity-aligned character embeddings that capture individual identities while preserving the effectiveness of face and body features. This integrated character representation enhances feature extraction and improves character re-identification compared to re-identification by face or body independently, offering a parameter-efficient solution. By extensively validating our method using in-series and inter-series evaluation metrics, we demonstrate its effectiveness in consistently re-identifying comic characters. Compared to existing methods, our approach not only addresses the challenge of character re-identification but also serves as a foundation for downstream tasks since it can produce character embeddings without restrictions of face and body availability, enriching the comprehension of comic books. In our experiments, we leverage two newly curated datasets: the 'Comic Character Instances Dataset', comprising over a million character instances and the 'Comic Sequence Identity Dataset', containing annotations of identities within more than 3000 sets of four consecutive comic panels that we collected.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>Character 重认处理，在漫画中的人物重复检测，存在很大的挑战，主要是因为有限的标注数据和人物形象的复杂变化。为解决这个问题，我们提出了一种可靠的半监督性框架，将度量学习与一种新的 '自我认知' 自监督学习方法结合，通过对人物脸和身体匹配的对比学习。我们的方法包括对人物脸和身体特征进行共同处理，使得提取人物特征的标准化 embeddings 可以捕捉到个体特征，同时保持脸和身体特征的有效性。这种一体化的人物表示提高了特征提取和人物重认处理，比起独立地使用脸或身体进行重认处理，提供了参数高效的解决方案。通过对我们方法进行 série 和 inter-série 评估指标，我们证明了它的有效性，可以在漫画中一致地重复检测人物。相比之下，我们的方法不仅解决了人物重认处理的挑战，还可以为下游任务提供基础，因为它可以不受脸和身体可用性的限制生成人物 embeddings，推动漫画的理解。在我们的实验中，我们利用了两个新收集的数据集：'Comic Character Instances Dataset'，包含了大于一百万个人物实例，以及'Comic Sequence Identity Dataset'，包含了四个连续的漫画幕后的标注，我们收集了超过3000个人物标注。
</details></li>
</ul>
<hr>
<h2 id="Fast-Decision-Support-for-Air-Traffic-Management-at-Urban-Air-Mobility-Vertiports-using-Graph-Learning"><a href="#Fast-Decision-Support-for-Air-Traffic-Management-at-Urban-Air-Mobility-Vertiports-using-Graph-Learning" class="headerlink" title="Fast Decision Support for Air Traffic Management at Urban Air Mobility Vertiports using Graph Learning"></a>Fast Decision Support for Air Traffic Management at Urban Air Mobility Vertiports using Graph Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09075">http://arxiv.org/abs/2308.09075</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prajit KrisshnaKumar, Jhoel Witter, Steve Paul, Hanvit Cho, Karthik Dantu, Souma Chowdhury</li>
<li>for: 提高城市和郊区交通效率、安全性和快速旅行的新领域——城市空中交通 (UAM)。</li>
<li>methods: 利用图约束学习生成决策支持策略， représenter物理位置在Vertiport的空间和被管理的交通工具为两个分开的图，通过图 convolutional neural network (GCN) 提取特征，然后通过perceptron层决定行为，如继续悬停或飞行、继续停机或起飞、或在分配给Vertiport的位置上降落。</li>
<li>results: 通过在AirSim中进行实际模拟，对减小多旋翼机的实际情况进行评估，结果表明图约束学习可以有效地解决城市空中交通——Vertiport调度管理问题，并且比基本的强化学习（图嵌入）或随机选择基eline有更好的性能， measured by delays, safety (no. of collisions) and battery consumption.<details>
<summary>Abstract</summary>
Urban Air Mobility (UAM) promises a new dimension to decongested, safe, and fast travel in urban and suburban hubs. These UAM aircraft are conceived to operate from small airports called vertiports each comprising multiple take-off/landing and battery-recharging spots. Since they might be situated in dense urban areas and need to handle many aircraft landings and take-offs each hour, managing this schedule in real-time becomes challenging for a traditional air-traffic controller but instead calls for an automated solution. This paper provides a novel approach to this problem of Urban Air Mobility - Vertiport Schedule Management (UAM-VSM), which leverages graph reinforcement learning to generate decision-support policies. Here the designated physical spots within the vertiport's airspace and the vehicles being managed are represented as two separate graphs, with feature extraction performed through a graph convolutional network (GCN). Extracted features are passed onto perceptron layers to decide actions such as continue to hover or cruise, continue idling or take-off, or land on an allocated vertiport spot. Performance is measured based on delays, safety (no. of collisions) and battery consumption. Through realistic simulations in AirSim applied to scaled down multi-rotor vehicles, our results demonstrate the suitability of using graph reinforcement learning to solve the UAM-VSM problem and its superiority to basic reinforcement learning (with graph embeddings) or random choice baselines.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/18/cs.AI_2023_08_18/" data-id="clogyj8v5002x7cragjyyaqux" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_08_18" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/18/cs.CL_2023_08_18/" class="article-date">
  <time datetime="2023-08-18T11:00:00.000Z" itemprop="datePublished">2023-08-18</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/18/cs.CL_2023_08_18/">cs.CL - 2023-08-18</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="ChatHaruhi-Reviving-Anime-Character-in-Reality-via-Large-Language-Model"><a href="#ChatHaruhi-Reviving-Anime-Character-in-Reality-via-Large-Language-Model" class="headerlink" title="ChatHaruhi: Reviving Anime Character in Reality via Large Language Model"></a>ChatHaruhi: Reviving Anime Character in Reality via Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09597">http://arxiv.org/abs/2308.09597</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/LC1332/Chat-Haruhi-Suzumiya">https://github.com/LC1332/Chat-Haruhi-Suzumiya</a></li>
<li>paper_authors: Cheng Li, Ziang Leng, Chenxi Yan, Junyi Shen, Hao Wang, Weishi MI, Yaying Fei, Xiaoyang Feng, Song Yan, HaoSheng Wang, Linkang Zhan, Yaokai Jia, Pingyu Wu, Haozhen Sun</li>
<li>for: 这篇论文旨在提出一种控制语言模型以模拟特定的虚构人物的算法，以提高角色扮演能力。</li>
<li>methods: 该算法使用改进的提示和从剧本中提取的人物记忆来控制语言模型。</li>
<li>results: 自动和人工评估都表明，该方法在比基eline进行角色扮演时表现更好。Translation:</li>
<li>for: This paper proposes an algorithm to control language models to mimic specific fictional characters, with the goal of improving role-playing ability.</li>
<li>methods: The algorithm uses an improved prompt and memories of the character extracted from scripts to control the language models.</li>
<li>results: Both automatic and human evaluations show that the proposed approach performs better than baselines in role-playing.<details>
<summary>Abstract</summary>
Role-playing chatbots built on large language models have drawn interest, but better techniques are needed to enable mimicking specific fictional characters. We propose an algorithm that controls language models via an improved prompt and memories of the character extracted from scripts. We construct ChatHaruhi, a dataset covering 32 Chinese / English TV / anime characters with over 54k simulated dialogues. Both automatic and human evaluations show our approach improves role-playing ability over baselines. Code and data are available at https://github.com/LC1332/Chat-Haruhi-Suzumiya .
</details>
<details>
<summary>摘要</summary>
大语言模型上的角色扮演聊天机器人已经吸引了注意，但更好的技术是需要实现模拟特定的虚构角色。我们提出了一个算法，可以通过改进提示和从剧本中提取的角色记忆来控制语言模型。我们建立了ChatHaruhi，一个覆盖32个中文/英文电视/动画角色的32000多个虚构对话。自动和人类评估都显示了我们的方法可以提高角色扮演能力比基eline。代码和数据可以在https://github.com/LC1332/Chat-Haruhi-Suzumiya 获取。
</details></li>
</ul>
<hr>
<h2 id="PUMGPT-A-Large-Vision-Language-Model-for-Product-Understanding"><a href="#PUMGPT-A-Large-Vision-Language-Model-for-Product-Understanding" class="headerlink" title="PUMGPT: A Large Vision-Language Model for Product Understanding"></a>PUMGPT: A Large Vision-Language Model for Product Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09568">http://arxiv.org/abs/2308.09568</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuhui Wu, Zengming Tang, Zongyi Guo, Weiwei Zhang, Baoliang Cui, Haihong Tang, Weiming Lu</li>
<li>for: 本研究主要针对产品理解任务进行探讨，以提高在线购物体验。产品理解任务包括多种子任务，需要模型回答基于多modal产品信息的多种问题。</li>
<li>methods: 我们提出了PUMGPT，一个大型视言语模型，旨在统一所有产品理解任务于单一模型结构。为 bridging视觉和文本表现之间的差距，我们提出了层刻拓展（LA），一种方法，通过增加 fewer 视觉 токен来提供更好的整合，并允许实际 Parameter-efficient 微调。</li>
<li>results: PUMGPT 在多种产品理解任务中表现出色，包括产品描述、类别问答、特征EXTRACTION、特征问答以及自由形问答关于产品。<details>
<summary>Abstract</summary>
Recent developments of multi-modal large language models have demonstrated its strong ability in solving vision-language tasks. In this paper, we focus on the product understanding task, which plays an essential role in enhancing online shopping experience. Product understanding task includes a variety of sub-tasks, which require models to respond diverse queries based on multi-modal product information. Traditional methods design distinct model architectures for each sub-task. On the contrary, we present PUMGPT, a large vision-language model aims at unifying all product understanding tasks under a singular model structure. To bridge the gap between vision and text representations, we propose Layer-wise Adapters (LA), an approach that provides enhanced alignment with fewer visual tokens and enables parameter-efficient fine-tuning. Moreover, the inherent parameter-efficient fine-tuning ability allows PUMGPT to be readily adapted to new product understanding tasks and emerging products. We design instruction templates to generate diverse product instruction datasets. Simultaneously, we utilize open-domain datasets during training to improve the performance of PUMGPT and its generalization ability. Through extensive evaluations, PUMGPT demonstrates its superior performance across multiple product understanding tasks, including product captioning, category question-answering, attribute extraction, attribute question-answering, and even free-form question-answering about products.
</details>
<details>
<summary>摘要</summary>
To bridge the gap between vision and text representations, we introduce Layer-wise Adapters (LA), a method that provides enhanced alignment with fewer visual tokens and enables parameter-efficient fine-tuning. PUMGPT's inherent parameter-efficient fine-tuning ability allows it to be easily adapted to new product understanding tasks and emerging products. We create instruction templates to generate diverse product instruction datasets, and we train PUMGPT using open-domain datasets to improve its performance and generalization ability.Through extensive evaluations, PUMGPT demonstrates superior performance across multiple product understanding tasks, including product captioning, category question-answering, attribute extraction, attribute question-answering, and even free-form question-answering about products.
</details></li>
</ul>
<hr>
<h2 id="Exploring-Sampling-Techniques-for-Generating-Melodies-with-a-Transformer-Language-Model"><a href="#Exploring-Sampling-Techniques-for-Generating-Melodies-with-a-Transformer-Language-Model" class="headerlink" title="Exploring Sampling Techniques for Generating Melodies with a Transformer Language Model"></a>Exploring Sampling Techniques for Generating Melodies with a Transformer Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09454">http://arxiv.org/abs/2308.09454</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mathias Rose Bjare, Stefan Lattner, Gerhard Widmer</li>
<li>for:  investigate the impact of different sampling techniques on musical qualities such as diversity and structure</li>
<li>methods: train a high-capacity transformer model on a vast collection of highly-structured Irish folk melodies, and analyze the musical qualities of the samples generated using distribution truncation sampling techniques</li>
<li>results: discover that probability truncation techniques may restrict diversity and structural patterns in optimal circumstances, but may also produce more musical samples in suboptimal circumstances.<details>
<summary>Abstract</summary>
Research in natural language processing has demonstrated that the quality of generations from trained autoregressive language models is significantly influenced by the used sampling strategy. In this study, we investigate the impact of different sampling techniques on musical qualities such as diversity and structure. To accomplish this, we train a high-capacity transformer model on a vast collection of highly-structured Irish folk melodies and analyze the musical qualities of the samples generated using distribution truncation sampling techniques. Specifically, we use nucleus sampling, the recently proposed "typical sampling", and conventional ancestral sampling. We evaluate the effect of these sampling strategies in two scenarios: optimal circumstances with a well-calibrated model and suboptimal circumstances where we systematically degrade the model's performance. We assess the generated samples using objective and subjective evaluations. We discover that probability truncation techniques may restrict diversity and structural patterns in optimal circumstances, but may also produce more musical samples in suboptimal circumstances.
</details>
<details>
<summary>摘要</summary>
研究自然语言处理显示，训练 autoregressive 语言模型的质量生成受采样策略的影响。在这项研究中，我们调查不同采样技术对音乐质量的影响。为此，我们使用高容量 transformer 模型训练一大量高结构性的爱尔兰传统民歌旋律，并分析生成的样本中的音乐质量。特别是，我们使用核心采样、“典型采样”和传统祖先采样。我们在两种情况下评估这些采样策略的影响：优化的情况下，模型性能很好，以及受损的情况下，我们系统地降低模型性能。我们使用对象和主观评估来评估生成的样本。我们发现，概率 truncation 技术可能会在优化情况下压缩多样性和结构性特征，但在受损情况下可能会生成更多的音乐样本。
</details></li>
</ul>
<hr>
<h2 id="Scope-is-all-you-need-Transforming-LLMs-for-HPC-Code"><a href="#Scope-is-all-you-need-Transforming-LLMs-for-HPC-Code" class="headerlink" title="Scope is all you need: Transforming LLMs for HPC Code"></a>Scope is all you need: Transforming LLMs for HPC Code</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09440">http://arxiv.org/abs/2308.09440</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/scientific-computing-lab-nrcn/tokompiler">https://github.com/scientific-computing-lab-nrcn/tokompiler</a></li>
<li>paper_authors: Tal Kadosh, Niranjan Hasabnis, Vy A. Vo, Nadav Schneider, Neva Krien, Abdul Wasay, Nesreen Ahmed, Ted Willke, Guy Tamir, Yuval Pinter, Timothy Mattson, Gal Oren<br>for:这个论文旨在探讨大型自然语言处理（NLP）模型如何应用于编程任务，特别是高性能计算（HPC）领域的任务。methods:该论文提出了一种名为 Tokompiler 的新型编译器，用于适应编程语言和编译任务。Tokompiler 利用了语言基础知识，生成了语言相关的标记，以提供语言结构的上下文感知，而完全避免了人工含义的代码结构。results:实验结果表明，使用 Tokompiler 进行预训练，可以大幅提高代码完成率和语义理解能力，比传统的标识符更低，约为 1 个折衡指数。这些结果开启了领域特定 LLM 的发展前景，以满足特定领域的独特需求。<details>
<summary>Abstract</summary>
With easier access to powerful compute resources, there is a growing trend in the field of AI for software development to develop larger and larger language models (LLMs) to address a variety of programming tasks. Even LLMs applied to tasks from the high-performance computing (HPC) domain are huge in size (e.g., billions of parameters) and demand expensive compute resources for training. We found this design choice confusing - why do we need large LLMs trained on natural languages and programming languages unrelated to HPC for HPC-specific tasks? In this line of work, we aim to question design choices made by existing LLMs by developing smaller LLMs for specific domains - we call them domain-specific LLMs. Specifically, we start off with HPC as a domain and propose a novel tokenizer named Tokompiler, designed specifically for preprocessing code in HPC and compilation-centric tasks. Tokompiler leverages knowledge of language primitives to generate language-oriented tokens, providing a context-aware understanding of code structure while avoiding human semantics attributed to code structures completely. We applied Tokompiler to pre-train two state-of-the-art models, SPT-Code and Polycoder, for a Fortran code corpus mined from GitHub. We evaluate the performance of these models against the conventional LLMs. Results demonstrate that Tokompiler significantly enhances code completion accuracy and semantic understanding compared to traditional tokenizers in normalized-perplexity tests, down to ~1 perplexity score. This research opens avenues for further advancements in domain-specific LLMs, catering to the unique demands of HPC and compilation tasks.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用更加可accessible的计算资源，在人工智能领域的软件开发中，正在增长一种大型语言模型（LLM）的趋势，以解决多种编程任务。即使应用于高性能计算（HPC）领域的LLM也非常大（例如，十亿个参数），需要昂贵的计算资源进行训练。我们认为这种设计选择是奇怪的——为什么需要大型LLM在自然语言和编程语言不related的HPC任务上进行训练？在这个研究中，我们想要质问现有LLM的设计选择，而是开发特定领域的LLM——我们称之为域specific LLM。 Specifically，我们开始于HPC领域，并提出了一种新的tokenizer名为Tokompiler，用于适应编译和编程任务。Tokompiler利用语言基本元素的知识来生成语言 oriented 的token，提供了代码结构上的上下文感知，而完全避免了人类语义 attributed 到代码结构。我们对HPC领域中的 Fortran 代码集进行预训练两个现有模型，SPT-Code 和 Polycoder。我们对这些模型进行评估，并与传统的 tokenizer进行比较。结果表明，Tokompiler在 норма化的复杂度测试中显著提高了代码完成率和semantic理解，相比传统的 tokenizer，下降至~1复杂度分数。这些研究开创了域specific LLM的新途径，适应HPC和编译任务的特殊需求。
</details></li>
</ul>
<hr>
<h2 id="A-Methodology-for-Generative-Spelling-Correction-via-Natural-Spelling-Errors-Emulation-across-Multiple-Domains-and-Languages"><a href="#A-Methodology-for-Generative-Spelling-Correction-via-Natural-Spelling-Errors-Emulation-across-Multiple-Domains-and-Languages" class="headerlink" title="A Methodology for Generative Spelling Correction via Natural Spelling Errors Emulation across Multiple Domains and Languages"></a>A Methodology for Generative Spelling Correction via Natural Spelling Errors Emulation across Multiple Domains and Languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09435">http://arxiv.org/abs/2308.09435</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikita Martynov, Mark Baushenko, Anastasia Kozlova, Katerina Kolomeytseva, Aleksandr Abramov, Alena Fenogenova<br>for: 本研究的目的是提出一种生成式拼写修正（SC）方法，用于更好地在文本编辑任务中 corrected spelling errors and mistypings。methods: 本研究使用了自然语言拼写错误和 mistypings 的研究，以及如何通过在正确句子中模拟这些错误来增强生成模型的预训练过程。我们还 investigate 了不同的文本领域下模型的能力。results: 我们在不同的损害策略、模型结构和大小下进行了实验，并评估了模型在单一领域和多领域测试集上的性能。此外，我们还提出了一个名为 SAGET (拼写检查 via 增强和生成分布 Emulation) 的自动生成 SC 库，包括一家生成模型的家族和内置的增强算法。<details>
<summary>Abstract</summary>
Modern large language models demonstrate impressive capabilities in text generation and generalization. However, they often struggle with solving text editing tasks, particularly when it comes to correcting spelling errors and mistypings. In this paper, we present a methodology for generative spelling correction (SC), which was tested on English and Russian languages and potentially can be extended to any language with minor changes. Our research mainly focuses on exploring natural spelling errors and mistypings in texts and studying the ways those errors can be emulated in correct sentences to effectively enrich generative models' pre-train procedure. We investigate the impact of such emulations and the models' abilities across different text domains. In this work, we investigate two spelling corruption techniques: 1) first one mimics human behavior when making a mistake through leveraging statistics of errors from particular dataset and 2) second adds the most common spelling errors, keyboard miss clicks, and some heuristics within the texts. We conducted experiments employing various corruption strategies, models' architectures and sizes on the pre-training and fine-tuning stages and evaluated the models using single-domain and multi-domain test sets. As a practical outcome of our work, we introduce SAGE (Spell checking via Augmentation and Generative distribution Emulation) is a library for automatic generative SC that includes a family of pre-trained generative models and built-in augmentation algorithms.
</details>
<details>
<summary>摘要</summary>
现代大语言模型表现出了优秀的文本生成和通用能力。然而，它们经常在文本编辑任务上遇到困难，特别是正确推理和短语输入错误。在这篇论文中，我们提出了一种生成拼写检查（SC）方法，在英文和俄文语言上进行测试，并可以适用于任何语言。我们的研究主要关注自然发生的拼写错误和输入错误在文本中的表现方式，并研究如何通过模拟这些错误来增强生成模型的预训练过程。我们 investigate了不同的损害策略、模型架构和大小在预训练和精度调整阶段的影响。在我们的实验中，我们使用了不同的损害策略、模型架构和大小，并对单domain和多domain测试集进行评估。作为实践的结果，我们介绍了一个名为SAGE（拼写检查via扩展和生成分布Emulation）的自动生成SC库，该库包括一家拼写检查模型和内置的扩展算法。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Large-Language-Models-for-DRL-Based-Anti-Jamming-Strategies-in-Zero-Touch-Networks"><a href="#Leveraging-Large-Language-Models-for-DRL-Based-Anti-Jamming-Strategies-in-Zero-Touch-Networks" class="headerlink" title="Leveraging Large Language Models for DRL-Based Anti-Jamming Strategies in Zero Touch Networks"></a>Leveraging Large Language Models for DRL-Based Anti-Jamming Strategies in Zero Touch Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09376">http://arxiv.org/abs/2308.09376</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abubakar S. Ali, Dimitrios Michael Manias, Abdallah Shami, Sami Muhaidat</li>
<li>for: 这篇论文主要是为了探讨自动化网络中的零点touch网络（ZTN）概念，以及在自动化过程中提高网络透明度和用户交互的可能性。</li>
<li>methods: 本论文使用了大语言模型（LLM）来把自动化网络过程与人类中心的界面相结合，以提高网络透明度和用户交互。</li>
<li>results: 通过一个深度强化学习（DRL）基于的防止干扰技术的实践案例，本论文示出了 LLM 可以将复杂的网络操作概念化为人类可读的报告。<details>
<summary>Abstract</summary>
As the dawn of sixth-generation (6G) networking approaches, it promises unprecedented advancements in communication and automation. Among the leading innovations of 6G is the concept of Zero Touch Networks (ZTNs), aiming to achieve fully automated, self-optimizing networks with minimal human intervention. Despite the advantages ZTNs offer in terms of efficiency and scalability, challenges surrounding transparency, adaptability, and human trust remain prevalent. Concurrently, the advent of Large Language Models (LLMs) presents an opportunity to elevate the ZTN framework by bridging the gap between automated processes and human-centric interfaces. This paper explores the integration of LLMs into ZTNs, highlighting their potential to enhance network transparency and improve user interactions. Through a comprehensive case study on deep reinforcement learning (DRL)-based anti-jamming technique, we demonstrate how LLMs can distill intricate network operations into intuitive, human-readable reports. Additionally, we address the technical and ethical intricacies of melding LLMs with ZTNs, with an emphasis on data privacy, transparency, and bias reduction. Looking ahead, we identify emerging research avenues at the nexus of LLMs and ZTNs, advocating for sustained innovation and interdisciplinary synergy in the domain of automated networks.
</details>
<details>
<summary>摘要</summary>
随着第六代网络（6G）的到来，它承诺了前所未有的通信和自动化技术。其中一项主导技术是零接触网络（ZTN），旨在实现无需人类干预的完全自动化网络。虽然ZTN具有高效率和可扩展性的优势，但是在透明度、适应性和人类信任方面仍存在许多挑战。同时，大型自然语言模型（LLM）的出现提供了一个机会，通过结合LLM和ZTN来bridging自动化过程和人类中心的界面。本文 explore了LLM在ZTN中的整合，探讨其能够提高网络透明度和改善用户互动。通过一个基于深度强化学习（DRL）的防止干扰技术的实践案例，我们示出了LLM可以将复杂的网络操作概括成易于理解的人类可读报告。此外，我们还讨论了将LLM与ZTN结合的技术和道德复杂性，强调数据隐私、透明度和偏见减少。 looking ahead，我们认为在LLM和ZTN之间的研究前景很广阔，希望能够持续推动这两个领域之间的创新和跨学科共融。
</details></li>
</ul>
<hr>
<h2 id="TrOMR-Transformer-Based-Polyphonic-Optical-Music-Recognition"><a href="#TrOMR-Transformer-Based-Polyphonic-Optical-Music-Recognition" class="headerlink" title="TrOMR:Transformer-Based Polyphonic Optical Music Recognition"></a>TrOMR:Transformer-Based Polyphonic Optical Music Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09370">http://arxiv.org/abs/2308.09370</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/netease/polyphonic-tromr">https://github.com/netease/polyphonic-tromr</a></li>
<li>paper_authors: Yixuan Li, Huaping Liu, Qiang Jin, Miaomiao Cai, Peng Li</li>
<li>for: 这个论文是关于音乐Recognition（OMR）技术的研究，旨在提出一种基于 transformer 的全音程识别方法，以提高recognition accuracy。</li>
<li>methods: 该方法使用 transformer 来实现全音程识别，并引入了一种新的一致性损失函数和合理的数据注释方法来提高识别精度。</li>
<li>results: 实验表明，TrOMR 方法在实际场景下比现有的 OMR 方法表现更高，特别是在识别复杂的乐谱上。此外，作者还开发了 TrOMR 系统和一个实际拍摄的乐谱场景数据集。<details>
<summary>Abstract</summary>
Optical Music Recognition (OMR) is an important technology in music and has been researched for a long time. Previous approaches for OMR are usually based on CNN for image understanding and RNN for music symbol classification. In this paper, we propose a transformer-based approach with excellent global perceptual capability for end-to-end polyphonic OMR, called TrOMR. We also introduce a novel consistency loss function and a reasonable approach for data annotation to improve recognition accuracy for complex music scores. Extensive experiments demonstrate that TrOMR outperforms current OMR methods, especially in real-world scenarios. We also develop a TrOMR system and build a camera scene dataset for full-page music scores in real-world. The code and datasets will be made available for reproducibility.
</details>
<details>
<summary>摘要</summary>
《光学音乐识别（OMR）技术在音乐领域已经被研究了很长时间。前一些OMR方法通常基于CNN для图像理解和RNN для音乐符号分类。在这篇论文中，我们提出了基于transformer的全globale感知方法，称为TrOMR，以提高端到端多重音乐OMR的准确率。我们还介绍了一种新的一致损失函数和合理的数据注释方法，以提高复杂音乐手稿的识别率。广泛的实验表明，TrOMR已经超越了当前OMR方法，特别是在实际场景中。我们还开发了TrOMR系统和一个摄像头场景数据集，用于实际全页音乐手稿识别。代码和数据集将被提供，以便重现。》Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="A-tailored-Handwritten-Text-Recognition-System-for-Medieval-Latin"><a href="#A-tailored-Handwritten-Text-Recognition-System-for-Medieval-Latin" class="headerlink" title="A tailored Handwritten-Text-Recognition System for Medieval Latin"></a>A tailored Handwritten-Text-Recognition System for Medieval Latin</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09368">http://arxiv.org/abs/2308.09368</a></li>
<li>repo_url: None</li>
<li>paper_authors: Philipp Koch, Gilary Vera Nuñez, Esteban Garces Arias, Christian Heumann, Matthias Schöffel, Alexander Häberlin, Matthias Aßenmacher</li>
<li>for: 针对 medieval Latin dictionary 的数字化进行 Handwritten Text Recognition (HTR) 任务。</li>
<li>methods: 使用两个 state-of-the-art (SOTA) 图像分割模型进行数据集的准备，并运行多种组合的 transformer-based 模型和 GPT-2 解码器进行实验。</li>
<li>results: 实现了一个高度竞争力的模型，最佳设置 achievement 的 Character Error Rate (CER) 为 0.015，超过了商业 Google Cloud Vision 模型，并且表现更加稳定。<details>
<summary>Abstract</summary>
The Bavarian Academy of Sciences and Humanities aims to digitize its Medieval Latin Dictionary. This dictionary entails record cards referring to lemmas in medieval Latin, a low-resource language. A crucial step of the digitization process is the Handwritten Text Recognition (HTR) of the handwritten lemmas found on these record cards. In our work, we introduce an end-to-end pipeline, tailored to the medieval Latin dictionary, for locating, extracting, and transcribing the lemmas. We employ two state-of-the-art (SOTA) image segmentation models to prepare the initial data set for the HTR task. Furthermore, we experiment with different transformer-based models and conduct a set of experiments to explore the capabilities of different combinations of vision encoders with a GPT-2 decoder. Additionally, we also apply extensive data augmentation resulting in a highly competitive model. The best-performing setup achieved a Character Error Rate (CER) of 0.015, which is even superior to the commercial Google Cloud Vision model, and shows more stable performance.
</details>
<details>
<summary>摘要</summary>
Bavarian Academy of Sciences and Humanities 计划数字化中世纪拉丁词典。这个词典包含手写 Record cards 上的中世纪拉丁词语，这是一种低资源语言。我们的工作是设计一个端到端管道，专门为中世纪拉丁词典进行找到、提取和转录词语的任务。我们使用两个现代状态的图像分割模型来准备初始数据集 для HTR 任务。此外，我们还对不同的 transformer 模型进行了试验，并对不同的视觉编码器与 GPT-2 解码器的不同组合进行了一系列实验。此外，我们还应用了广泛的数据增强，实现了非常竞争力的模型。最佳设置达到了 Character Error Rate （CER）0.015，超过了商业 Google Cloud Vision 模型，并且表现更加稳定。
</details></li>
</ul>
<hr>
<h2 id="Accelerated-materials-language-processing-enabled-by-GPT"><a href="#Accelerated-materials-language-processing-enabled-by-GPT" class="headerlink" title="Accelerated materials language processing enabled by GPT"></a>Accelerated materials language processing enabled by GPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09354">http://arxiv.org/abs/2308.09354</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jaewoong Choi, Byungju Lee</li>
<li>for: 这研究的目的是提高材料科学文献中信息抽取的效率，并采用生成式预训练变换器（GPT）来替换优化的模型结构。</li>
<li>methods: 这研究使用了GPT引入的文档分类方法、命名实体识别（NER）方法和抽取问答（QA）方法，其中使用了策略性的提示工程来替换优化的模型结构。</li>
<li>results: 研究发现，使用GPT引入的方法可以实现与优化模型结构相当的准确率和可靠性，并且只需要小量的数据进行训练。此外，这些方法还可以在不同的材料科学领域中应用，以加速文献中信息抽取的过程。<details>
<summary>Abstract</summary>
Materials language processing (MLP) is one of the key facilitators of materials science research, as it enables the extraction of structured information from massive materials science literature. Prior works suggested high-performance MLP models for text classification, named entity recognition (NER), and extractive question answering (QA), which require complex model architecture, exhaustive fine-tuning and a large number of human-labelled datasets. In this study, we develop generative pretrained transformer (GPT)-enabled pipelines where the complex architectures of prior MLP models are replaced with strategic designs of prompt engineering. First, we develop a GPT-enabled document classification method for screening relevant documents, achieving comparable accuracy and reliability compared to prior models, with only small dataset. Secondly, for NER task, we design an entity-centric prompts, and learning few-shot of them improved the performance on most of entities in three open datasets. Finally, we develop an GPT-enabled extractive QA model, which provides improved performance and shows the possibility of automatically correcting annotations. While our findings confirm the potential of GPT-enabled MLP models as well as their value in terms of reliability and practicability, our scientific methods and systematic approach are applicable to any materials science domain to accelerate the information extraction of scientific literature.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Document-Automation-Architectures-Updated-Survey-in-Light-of-Large-Language-Models"><a href="#Document-Automation-Architectures-Updated-Survey-in-Light-of-Large-Language-Models" class="headerlink" title="Document Automation Architectures: Updated Survey in Light of Large Language Models"></a>Document Automation Architectures: Updated Survey in Light of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09341">http://arxiv.org/abs/2308.09341</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Ahmadi Achachlouei, Omkar Patil, Tarun Joshi, Vijayan N. Nair</li>
<li>for: 本研究审查了当前文档自动化（DA）领域的最新状况，尤其是在法律领域的商业解决方案中的自动化文档生成。</li>
<li>methods: 本研究通过审查学术文献，为DA的定义和特征提供了更清晰的定义，并识别了学术研究中的DA架构和技术。</li>
<li>results: 本研究提供了新的DA研究机遇，基于最新的生成AI和大语言模型。<details>
<summary>Abstract</summary>
This paper surveys the current state of the art in document automation (DA). The objective of DA is to reduce the manual effort during the generation of documents by automatically creating and integrating input from different sources and assembling documents conforming to defined templates. There have been reviews of commercial solutions of DA, particularly in the legal domain, but to date there has been no comprehensive review of the academic research on DA architectures and technologies. The current survey of DA reviews the academic literature and provides a clearer definition and characterization of DA and its features, identifies state-of-the-art DA architectures and technologies in academic research, and provides ideas that can lead to new research opportunities within the DA field in light of recent advances in generative AI and large language models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="KESDT-knowledge-enhanced-shallow-and-deep-Transformer-for-detecting-adverse-drug-reactions"><a href="#KESDT-knowledge-enhanced-shallow-and-deep-Transformer-for-detecting-adverse-drug-reactions" class="headerlink" title="KESDT: knowledge enhanced shallow and deep Transformer for detecting adverse drug reactions"></a>KESDT: knowledge enhanced shallow and deep Transformer for detecting adverse drug reactions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09329">http://arxiv.org/abs/2308.09329</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunzhi Qiu, Xiaokun Zhang, Weiwei Wang, Tongxuan Zhang, Bo Xu, Hongfei Lin<br>for:The paper aims to improve the detection of adverse drug reactions (ADRs) on social media platforms by proposing a novel model called Knowledge Enhanced Shallow and Deep Transformer (KESDT).methods:The KESDT model incorporates domain keywords into the Transformer model through a shallow fusion manner and integrates synonym sets through a deep fusion manner to address the challenges of low annotated data and sample imbalance.results:The proposed KESDT model outperforms state-of-the-art baselines on three public datasets (TwiMed, Twitter, and CADEC) in terms of F1 values, with relative improvements of 4.87%, 47.83%, and 5.73%, respectively.<details>
<summary>Abstract</summary>
Adverse drug reaction (ADR) detection is an essential task in the medical field, as ADRs have a gravely detrimental impact on patients' health and the healthcare system. Due to a large number of people sharing information on social media platforms, an increasing number of efforts focus on social media data to carry out effective ADR detection. Despite having achieved impressive performance, the existing methods of ADR detection still suffer from three main challenges. Firstly, researchers have consistently ignored the interaction between domain keywords and other words in the sentence. Secondly, social media datasets suffer from the challenges of low annotated data. Thirdly, the issue of sample imbalance is commonly observed in social media datasets. To solve these challenges, we propose the Knowledge Enhanced Shallow and Deep Transformer(KESDT) model for ADR detection. Specifically, to cope with the first issue, we incorporate the domain keywords into the Transformer model through a shallow fusion manner, which enables the model to fully exploit the interactive relationships between domain keywords and other words in the sentence. To overcome the low annotated data, we integrate the synonym sets into the Transformer model through a deep fusion manner, which expands the size of the samples. To mitigate the impact of sample imbalance, we replace the standard cross entropy loss function with the focal loss function for effective model training. We conduct extensive experiments on three public datasets including TwiMed, Twitter, and CADEC. The proposed KESDT outperforms state-of-the-art baselines on F1 values, with relative improvements of 4.87%, 47.83%, and 5.73% respectively, which demonstrates the effectiveness of our proposed KESDT.
</details>
<details>
<summary>摘要</summary>
医疗领域内的药物反应检测是一项非常重要的任务，因为药物反应会对患者的健康产生严重的影响，同时也会对医疗系统产生沉重的负担。随着更多的人通过社交媒体平台分享信息，有越来越多的努力集中在社交媒体数据上进行有效的药物反应检测。尽管现有的检测方法已经取得了很好的表现，但是这些方法仍然面临着三个主要挑战。首先，研究人员一直忽略了域关键词和其他单词之间的互动关系。第二，社交媒体数据受到严重的标注数据不足的影响。第三，社交媒体数据中的样本偏度问题很常见。为解决这些挑战，我们提出了基于知识的扩展深度传播（KESDT）模型，用于药物反应检测。具体来说，为了处理第一个问题，我们将域关键词 integration到传播模型中，使得模型能够充分利用域关键词和其他单词之间的互动关系。为了解决低标注数据的问题，我们将同义词集 integrate到传播模型中，从而扩大样本的大小。为了缓解样本偏度问题，我们将标准十字 entropy损失函数替换为关注损失函数，以便更好地训练模型。我们对三个公共数据集，包括TwiMed、Twitter和CADEC进行了广泛的实验。我们的提出的KESDT比 estado-of-the-art基elines在F1值上提高4.87%、47.83%和5.73%，这表明了我们的KESDT的效果。
</details></li>
</ul>
<hr>
<h2 id="Lip-Reading-for-Low-resource-Languages-by-Learning-and-Combining-General-Speech-Knowledge-and-Language-specific-Knowledge"><a href="#Lip-Reading-for-Low-resource-Languages-by-Learning-and-Combining-General-Speech-Knowledge-and-Language-specific-Knowledge" class="headerlink" title="Lip Reading for Low-resource Languages by Learning and Combining General Speech Knowledge and Language-specific Knowledge"></a>Lip Reading for Low-resource Languages by Learning and Combining General Speech Knowledge and Language-specific Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09311">http://arxiv.org/abs/2308.09311</a></li>
<li>repo_url: None</li>
<li>paper_authors: Minsu Kim, Jeong Hun Yeo, Jeongsoo Choi, Yong Man Ro</li>
<li>for: 本文提出了一种新的脸部说话框架，特别适用于低资源语言，过去的文献中没有充分考虑这个问题。由于低资源语言没有充分的视频文本对数据来训练模型，因此lipreading模型的开发受到了挑战。</li>
<li>methods: 我们尝试了通过Predicting speech units来学习通用语言知识，即模型嘴部运动的能力。不同语言部分共享相同的phoneme，因此可以将学习一种语言的通用语言知识扩展到其他语言。然后，我们提出了Language-specific Memory-augmented Decoder（LMDecoder）来学习语言特定的知识。LMDecoder将语言特定的声音特征存储在内存银行中，可以通过声音文本对来训练。因此，我们可以将输入的speech units转换成语言特定的声音特征，并使用学习的丰富语言知识来翻译它们。</li>
<li>results: 通过对五种语言（英语、西班牙语、法语、意大利语、葡萄牙语）的广泛实验，我们证明了提出的方法的效iveness。<details>
<summary>Abstract</summary>
This paper proposes a novel lip reading framework, especially for low-resource languages, which has not been well addressed in the previous literature. Since low-resource languages do not have enough video-text paired data to train the model to have sufficient power to model lip movements and language, it is regarded as challenging to develop lip reading models for low-resource languages. In order to mitigate the challenge, we try to learn general speech knowledge, the ability to model lip movements, from a high-resource language through the prediction of speech units. It is known that different languages partially share common phonemes, thus general speech knowledge learned from one language can be extended to other languages. Then, we try to learn language-specific knowledge, the ability to model language, by proposing Language-specific Memory-augmented Decoder (LMDecoder). LMDecoder saves language-specific audio features into memory banks and can be trained on audio-text paired data which is more easily accessible than video-text paired data. Therefore, with LMDecoder, we can transform the input speech units into language-specific audio features and translate them into texts by utilizing the learned rich language knowledge. Finally, by combining general speech knowledge and language-specific knowledge, we can efficiently develop lip reading models even for low-resource languages. Through extensive experiments using five languages, English, Spanish, French, Italian, and Portuguese, the effectiveness of the proposed method is evaluated.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Differentiable-Retrieval-Augmentation-via-Generative-Language-Modeling-for-E-commerce-Query-Intent-Classification"><a href="#Differentiable-Retrieval-Augmentation-via-Generative-Language-Modeling-for-E-commerce-Query-Intent-Classification" class="headerlink" title="Differentiable Retrieval Augmentation via Generative Language Modeling for E-commerce Query Intent Classification"></a>Differentiable Retrieval Augmentation via Generative Language Modeling for E-commerce Query Intent Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09308">http://arxiv.org/abs/2308.09308</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenyu Zhao, Yunjiang Jiang, Yiming Qiu, Han Zhang, Wen-Yun Yang</li>
<li>for: 提高自然语言处理(NLP)任务中下游模型的性能，具体来说是在电商搜索中的查询意图分类任务。</li>
<li>methods: 通过知识检索器和外部词库的协同使用，实现增强下游模型的性能，而不是增加模型参数的方式。</li>
<li>results: 通过实验和减少研究，证明了我们提出的方法可以在查询意图分类任务中显著提高州网络处理(NLP)任务的性能，并且在实际应用中也能够达到良好的效果。<details>
<summary>Abstract</summary>
Retrieval augmentation, which enhances downstream models by a knowledge retriever and an external corpus instead of by merely increasing the number of model parameters, has been successfully applied to many natural language processing (NLP) tasks such as text classification, question answering and so on. However, existing methods that separately or asynchronously train the retriever and downstream model mainly due to the non-differentiability between the two parts, usually lead to degraded performance compared to end-to-end joint training. In this paper, we propose Differentiable Retrieval Augmentation via Generative lANguage modeling(Dragan), to address this problem by a novel differentiable reformulation. We demonstrate the effectiveness of our proposed method on a challenging NLP task in e-commerce search, namely query intent classification. Both the experimental results and ablation study show that the proposed method significantly and reasonably improves the state-of-the-art baselines on both offline evaluation and online A/B test.
</details>
<details>
<summary>摘要</summary>
<<SYS>>TRANSLATE_TEXT Retrieval augmentation, which enhances downstream models by a knowledge retriever and an external corpus instead of by merely increasing the number of model parameters, has been successfully applied to many natural language processing (NLP) tasks such as text classification, question answering, and so on. However, existing methods that separately or asynchronously train the retriever and downstream model mainly due to the non-differentiability between the two parts, usually lead to degraded performance compared to end-to-end joint training. In this paper, we propose Differentiable Retrieval Augmentation via Generative lANguage modeling(Dragan), to address this problem by a novel differentiable reformulation. We demonstrate the effectiveness of our proposed method on a challenging NLP task in e-commerce search, namely query intent classification. Both the experimental results and ablation study show that the proposed method significantly and reasonably improves the state-of-the-art baselines on both offline evaluation and online A/B test.TRANSLATE_END
</details></li>
</ul>
<hr>
<h2 id="Conversational-Ontology-Alignment-with-ChatGPT"><a href="#Conversational-Ontology-Alignment-with-ChatGPT" class="headerlink" title="Conversational Ontology Alignment with ChatGPT"></a>Conversational Ontology Alignment with ChatGPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09217">http://arxiv.org/abs/2308.09217</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sanaz Saki Norouzi, Mohammad Saeid Mahdavinejad, Pascal Hitzler</li>
<li>for: 本研究evaluates the feasibility and efficiency of ChatGPT for ontology alignment using a naive approach.</li>
<li>methods: 本研究使用了一种Naive方法，使用ChatGPT的输出与 Ontology Alignment Evaluation Initiative 2022 的会议轨道 ontologies进行比较，以获得更多关于 conversational large language model 在 Naive 方法下的 ontology matching 能力的信息。</li>
<li>results: 研究发现，ChatGPT 的输出与 Ontology Alignment Evaluation Initiative 2022 的结果之间存在一定的相似性，但是还有一些差异。这表明了 conversational large language model 在 Naive 方法下的 ontology matching 能力是有限的，但也有一定的潜在优势。<details>
<summary>Abstract</summary>
This study evaluates the applicability and efficiency of ChatGPT for ontology alignment using a naive approach. ChatGPT's output is compared to the results of the Ontology Alignment Evaluation Initiative 2022 campaign using conference track ontologies. This comparison is intended to provide insights into the capabilities of a conversational large language model when used in a naive way for ontology matching, and to investigate the potential advantages and disadvantages of this approach.
</details>
<details>
<summary>摘要</summary>
这项研究评估了chatGPT在ontologyAlignment中的适用性和效率，使用了一种简单的方法。chatGPT的输出与2022年ontologyAlignment评估活动的会议轨道 ontologies 的结果进行比较，以提供 conversational large language model 在 naive 方式上的ontology匹配能力的洞察，并 investigate这种方法的优劣点。
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Study-of-Text-Embedding-Models-for-Semantic-Text-Similarity-in-Bug-Reports"><a href="#A-Comparative-Study-of-Text-Embedding-Models-for-Semantic-Text-Similarity-in-Bug-Reports" class="headerlink" title="A Comparative Study of Text Embedding Models for Semantic Text Similarity in Bug Reports"></a>A Comparative Study of Text Embedding Models for Semantic Text Similarity in Bug Reports</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09193">http://arxiv.org/abs/2308.09193</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/av9ash/duplicatebugdetection">https://github.com/av9ash/duplicatebugdetection</a></li>
<li>paper_authors: Avinash Patil, Kihwan Han, Sabyasachi Mukhopadhyay</li>
<li>for: 本研究旨在比较不同文本 Similarity 方法在bug report retrieval中的效果,以提高bug report的检索效率。</li>
<li>methods: 本研究使用了TF-IDF (基eline), FastText, Gensim, BERT和ADA embedding模型进行比较。</li>
<li>results: 实验结果显示BERT模型在回忆率方面表现最好，其次是ADA模型，接下来是Gensim、FastText和TF-IDF模型。<details>
<summary>Abstract</summary>
Bug reports are an essential aspect of software development, and it is crucial to identify and resolve them quickly to ensure the consistent functioning of software systems. Retrieving similar bug reports from an existing database can help reduce the time and effort required to resolve bugs. In this paper, we compared the effectiveness of semantic textual similarity methods for retrieving similar bug reports based on a similarity score. We explored several embedding models such as TF-IDF (Baseline), FastText, Gensim, BERT, and ADA. We used the Software Defects Data containing bug reports for various software projects to evaluate the performance of these models. Our experimental results showed that BERT generally outperformed the rest of the models regarding recall, followed by ADA, Gensim, FastText, and TFIDF. Our study provides insights into the effectiveness of different embedding methods for retrieving similar bug reports and highlights the impact of selecting the appropriate one for this task. Our code is available on GitHub.
</details>
<details>
<summary>摘要</summary>
📝 Bug 报告是软件开发中非常重要的一部分，快速标识和解决它们以确保软件系统的一致性。从现有的数据库中检索类似的bug报告可以减少解决bug所需的时间和努力。在这篇论文中，我们对用 semantic textual similarity 方法检索类似bug报告的效果进行了比较，并根据相似性分数进行评估。我们检查了TF-IDF（基准）、FastText、Gensim、BERT和ADA 等嵌入模型。我们使用了 Software Defects Data 中的 bug 报告来评估这些模型的性能。我们的实验结果表明，BERT 通常在 recall 方面表现更好，其次是 ADA，Gensim，FastText 和 TF-IDF。我们的研究提供了不同嵌入方法在检索类似bug报告的效果的视角，并 highlights 选择合适的嵌入方法对这项任务的重要性。我们的代码可以在 GitHub 上找到。
</details></li>
</ul>
<hr>
<h2 id="Is-Argument-Structure-of-Learner-Chinese-Understandable-A-Corpus-Based-Analysis"><a href="#Is-Argument-Structure-of-Learner-Chinese-Understandable-A-Corpus-Based-Analysis" class="headerlink" title="Is Argument Structure of Learner Chinese Understandable: A Corpus-Based Analysis"></a>Is Argument Structure of Learner Chinese Understandable: A Corpus-Based Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09186">http://arxiv.org/abs/2308.09186</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuguang Duan, Zi Lin, Weiwei Sun</li>
<li>for: 这个论文是为了分析learner中文中的意向结构错误的。</li>
<li>methods: 这个论文使用了 sentence produced by language learners和 их corrected by native speakers的数据，并与 semantic role labeling标注。</li>
<li>results: 这个论文发现了learner中文中的意向结构错误，包括word order、word selection、lack of proposition和argument-adjunct confounding等。<details>
<summary>Abstract</summary>
This paper presents a corpus-based analysis of argument structure errors in learner Chinese. The data for analysis includes sentences produced by language learners as well as their corrections by native speakers. We couple the data with semantic role labeling annotations that are manually created by two senior students whose majors are both Applied Linguistics. The annotation procedure is guided by the Chinese PropBank specification, which is originally developed to cover first language phenomena. Nevertheless, we find that it is quite comprehensive for handling second language phenomena. The inter-annotator agreement is rather high, suggesting the understandability of learner texts to native speakers. Based on our annotations, we present a preliminary analysis of competence errors related to argument structure. In particular, speech errors related to word order, word selection, lack of proposition, and argument-adjunct confounding are discussed.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文介绍了学习中文learner的语法错误分析。数据来源包括学习者生成的句子以及Native speaker的修改。我们将数据 coupling avec manually created的semantic role labeling标注，遵循中文PropBank规范，这个规范原本是为first language phenomena而设计。然而，我们发现它对second language phenomena也非常全面。标注过程中的间接对应度较高，表明学习者的文本对Native speaker来说很容易理解。基于我们的标注，我们对语法错误进行了初步分析，包括word order错误、word selection错误、缺乏 Proposition 和 argument-adjunct杂合错误等。
</details></li>
</ul>
<hr>
<h2 id="ZhiJian-A-Unifying-and-Rapidly-Deployable-Toolbox-for-Pre-trained-Model-Reuse"><a href="#ZhiJian-A-Unifying-and-Rapidly-Deployable-Toolbox-for-Pre-trained-Model-Reuse" class="headerlink" title="ZhiJian: A Unifying and Rapidly Deployable Toolbox for Pre-trained Model Reuse"></a>ZhiJian: A Unifying and Rapidly Deployable Toolbox for Pre-trained Model Reuse</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09158">http://arxiv.org/abs/2308.09158</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhangyikaii/lamda-zhijian">https://github.com/zhangyikaii/lamda-zhijian</a></li>
<li>paper_authors: Yi-Kai Zhang, Lu Ren, Chao Yi, Qi-Wei Wang, De-Chuan Zhan, Han-Jia Ye</li>
<li>for: 本研究旨在提供一个可用于实际应用中的模型重复使用工具箱（ZhiJian），实现了多种模型重复使用方法的整合，并提供了一个简单易用的PyTorch backend。</li>
<li>methods: 本研究使用了PyTorch backend，提出了一个称为PTM的目标架构建方法，并且提供了一个基于PTM的探索和调整方法，可以帮助深度学习专家在下游任务中探索和发现不同方法之间的补偿优点。</li>
<li>results: 本研究通过实际应用和评估，显示了ZhiJian在实际应用中的效果和可靠性，并且显示了PTM-based inference可以帮助深度学习专家在下游任务中探索和发现不同方法之间的补偿优点。<details>
<summary>Abstract</summary>
The rapid expansion of foundation pre-trained models and their fine-tuned counterparts has significantly contributed to the advancement of machine learning. Leveraging pre-trained models to extract knowledge and expedite learning in real-world tasks, known as "Model Reuse", has become crucial in various applications. Previous research focuses on reusing models within a certain aspect, including reusing model weights, structures, and hypothesis spaces. This paper introduces ZhiJian, a comprehensive and user-friendly toolbox for model reuse, utilizing the PyTorch backend. ZhiJian presents a novel paradigm that unifies diverse perspectives on model reuse, encompassing target architecture construction with PTM, tuning target model with PTM, and PTM-based inference. This empowers deep learning practitioners to explore downstream tasks and identify the complementary advantages among different methods. ZhiJian is readily accessible at https://github.com/zhangyikaii/lamda-zhijian facilitating seamless utilization of pre-trained models and streamlining the model reuse process for researchers and developers.
</details>
<details>
<summary>摘要</summary>
“快速扩展的基础模型和其精细化版本的发展，对机器学习的进步做出了重要贡献。利用预训练模型提取知识和快速学习实际任务中的概念，称为“模型重用”，在各种应用中变得非常重要。先前的研究主要关注在模型重用的特定方面，包括模型权重、结构和假设空间的重用。本文介绍了一个名为ZhiJian的通用和易用的工具箱，使用PyTorch后端。ZhiJian提出了一种新的思想，即在PTM中构建目标建筑、在PTM中调参目标模型和PTM基于的推理。这使得深度学习实践者可以更好地探索下游任务和发现不同方法之间的补做优势。ZhiJian可以很容易地在https://github.com/zhangyikaii/lamda-zhijian上获取，便于预训练模型的使用和模型重用过程中的流程，为研究者和开发者提供了便捷的使用方式。”
</details></li>
</ul>
<hr>
<h2 id="Characterizing-Information-Seeking-Events-in-Health-Related-Social-Discourse"><a href="#Characterizing-Information-Seeking-Events-in-Health-Related-Social-Discourse" class="headerlink" title="Characterizing Information Seeking Events in Health-Related Social Discourse"></a>Characterizing Information Seeking Events in Health-Related Social Discourse</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09156">http://arxiv.org/abs/2308.09156</a></li>
<li>repo_url: None</li>
<li>paper_authors: Omar Sharif, Madhusudan Basak, Tanzia Parvin, Ava Scharfstein, Alphonso Bradham, Jacob T. Borodovsky, Sarah E. Lord, Sarah Masud Preum<br>for: This paper focuses on analyzing health-related information-seeking on social media, specifically on Reddit, to understand the treatment options and misconceptions related to Opioid Use Disorder (OUD).methods: The authors use a novel approach called event-driven analysis to categorize health-related information-seeking on social media into different events, such as treatment options, misconceptions, and knowledge gaps. They also develop a dataset called TREAT-ISE, which contains Reddit posts annotated with the type of events related to recovery from OUD.results: The authors achieve a strong performance benchmark of 77.4% F1 score for the task of classifying information-seeking events on Reddit related to OUD using machine learning and deep learning classifiers. They also investigate the performance and errors of ChatGPT on this task, providing insights into the capabilities and limitations of large language models.<details>
<summary>Abstract</summary>
Social media sites have become a popular platform for individuals to seek and share health information. Despite the progress in natural language processing for social media mining, a gap remains in analyzing health-related texts on social discourse in the context of events. Event-driven analysis can offer insights into different facets of healthcare at an individual and collective level, including treatment options, misconceptions, knowledge gaps, etc. This paper presents a paradigm to characterize health-related information-seeking in social discourse through the lens of events. Events here are board categories defined with domain experts that capture the trajectory of the treatment/medication. To illustrate the value of this approach, we analyze Reddit posts regarding medications for Opioid Use Disorder (OUD), a critical global health concern. To the best of our knowledge, this is the first attempt to define event categories for characterizing information-seeking in OUD social discourse. Guided by domain experts, we develop TREAT-ISE, a novel multilabel treatment information-seeking event dataset to analyze online discourse on an event-based framework. This dataset contains Reddit posts on information-seeking events related to recovery from OUD, where each post is annotated based on the type of events. We also establish a strong performance benchmark (77.4% F1 score) for the task by employing several machine learning and deep learning classifiers. Finally, we thoroughly investigate the performance and errors of ChatGPT on this task, providing valuable insights into the LLM's capabilities and ongoing characterization efforts.
</details>
<details>
<summary>摘要</summary>
社交媒体平台已成为个人寻求和分享健康信息的受欢迎平台。 despite the progress in自然语言处理 для社交媒体挖掘, a gap remains in analyzing health-related texts in the context of events. Event-driven analysis can offer insights into different facets of healthcare at an individual and collective level, including treatment options, misconceptions, knowledge gaps, etc. This paper presents a paradigm to characterize health-related information-seeking in social discourse through the lens of events. Events here are board categories defined with domain experts that capture the trajectory of the treatment/medication. To illustrate the value of this approach, we analyze Reddit posts regarding medications for Opioid Use Disorder (OUD), a critical global health concern. To the best of our knowledge, this is the first attempt to define event categories for characterizing information-seeking in OUD social discourse. Guided by domain experts, we develop TREAT-ISE, a novel multilabel treatment information-seeking event dataset to analyze online discourse on an event-based framework. This dataset contains Reddit posts on information-seeking events related to recovery from OUD, where each post is annotated based on the type of events. We also establish a strong performance benchmark (77.4% F1 score) for the task by employing several machine learning and deep learning classifiers. Finally, we thoroughly investigate the performance and errors of ChatGPT on this task, providing valuable insights into the LLM's capabilities and ongoing characterization efforts.
</details></li>
</ul>
<hr>
<h2 id="Linearity-of-Relation-Decoding-in-Transformer-Language-Models"><a href="#Linearity-of-Relation-Decoding-in-Transformer-Language-Models" class="headerlink" title="Linearity of Relation Decoding in Transformer Language Models"></a>Linearity of Relation Decoding in Transformer Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09124">http://arxiv.org/abs/2308.09124</a></li>
<li>repo_url: None</li>
<li>paper_authors: Evan Hernandez, Arnab Sen Sharma, Tal Haklay, Kevin Meng, Martin Wattenberg, Jacob Andreas, Yonatan Belinkov, David Bau</li>
<li>for: 本研究探讨了transformer语言模型（LM）中大量知识的表达方式，即关系之间的计算。</li>
<li>methods: 研究人员使用了一种单个提示来构建一个first-order approximation的LM，并证明了某些关系可以通过单一的线性变换来表示。</li>
<li>results: 研究发现，LM的表达中存在许多不是线性地编码的关系知识，但是它们可以准确地预测关系。这些结果表明LM使用了一种简单、可读的，但是不均匀分布的知识表示策略。<details>
<summary>Abstract</summary>
Much of the knowledge encoded in transformer language models (LMs) may be expressed in terms of relations: relations between words and their synonyms, entities and their attributes, etc. We show that, for a subset of relations, this computation is well-approximated by a single linear transformation on the subject representation. Linear relation representations may be obtained by constructing a first-order approximation to the LM from a single prompt, and they exist for a variety of factual, commonsense, and linguistic relations. However, we also identify many cases in which LM predictions capture relational knowledge accurately, but this knowledge is not linearly encoded in their representations. Our results thus reveal a simple, interpretable, but heterogeneously deployed knowledge representation strategy in transformer LMs.
</details>
<details>
<summary>摘要</summary>
许多语言模型中的知识可以表示为关系：单词和其同义词之间的关系，实体和其属性之间的关系等。我们发现，对于一些关系，这种计算可以被简单地表示为单一的线性变换在主题表示中。这种线性关系表示可以通过从单个提示构建首个预测来获得，并存在许多事实、通俗知识和语言关系中。然而，我们也发现许多情况下，LM的预测捕捉到了关系知识，但这种知识不是直接地编码在其表示中。我们的结果因此揭示了一种简单、可解释的，但受到不同应用场景的各种表示策略在transformer语言模型中。
</details></li>
</ul>
<hr>
<h2 id="MaScQA-A-Question-Answering-Dataset-for-Investigating-Materials-Science-Knowledge-of-Large-Language-Models"><a href="#MaScQA-A-Question-Answering-Dataset-for-Investigating-Materials-Science-Knowledge-of-Large-Language-Models" class="headerlink" title="MaScQA: A Question Answering Dataset for Investigating Materials Science Knowledge of Large Language Models"></a>MaScQA: A Question Answering Dataset for Investigating Materials Science Knowledge of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09115">http://arxiv.org/abs/2308.09115</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohd Zaki, Jayadeva, Mausam, N. M. Anoop Krishnan</li>
<li>for: 本研究旨在开发一个可以快速找到材料的知识库，以便更好地满足材料科学领域的研究需求。</li>
<li>methods: 本研究使用语言模型来回答材料领域的问题，并从知识库中提取信息。</li>
<li>results: GPT-4模型在解决材料领域的650个问题中表现最好（约62%的准确率），而链式思维提示对模型的性能没有显著提升。研究发现，概念错误（约64%）是LLMs表现下降的主要原因，而计算错误（约36%）则是次要原因。<details>
<summary>Abstract</summary>
Information extraction and textual comprehension from materials literature are vital for developing an exhaustive knowledge base that enables accelerated materials discovery. Language models have demonstrated their capability to answer domain-specific questions and retrieve information from knowledge bases. However, there are no benchmark datasets in the materials domain that can evaluate the understanding of the key concepts by these language models. In this work, we curate a dataset of 650 challenging questions from the materials domain that require the knowledge and skills of a materials student who has cleared their undergraduate degree. We classify these questions based on their structure and the materials science domain-based subcategories. Further, we evaluate the performance of GPT-3.5 and GPT-4 models on solving these questions via zero-shot and chain of thought prompting. It is observed that GPT-4 gives the best performance (~62% accuracy) as compared to GPT-3.5. Interestingly, in contrast to the general observation, no significant improvement in accuracy is observed with the chain of thought prompting. To evaluate the limitations, we performed an error analysis, which revealed conceptual errors (~64%) as the major contributor compared to computational errors (~36%) towards the reduced performance of LLMs. We hope that the dataset and analysis performed in this work will promote further research in developing better materials science domain-specific LLMs and strategies for information extraction.
</details>
<details>
<summary>摘要</summary>
信息抽取和文本理解从材料文献中是发展加速材料发现的关键。语言模型已经表现出其能够回答域务特定问题和从知识库中提取信息。但是，在材料领域没有 benchmark 数据集来评估这些语言模型对关键概念的理解。在这项工作中，我们积集了 650 个材料领域的复杂问题，这些问题需要Materials 学生完成本科学位课程后的知识和技能。我们将这些问题分类为结构和材料科学领域下的子类别。然后，我们使用 zero-shot 和链条提问训练 GPT-3.5 和 GPT-4 模型，并评估其性能。结果显示，GPT-4 的性能最高（约 62% 准确率），而 GPT-3.5 的性能较低。另外，与通常观察不同，链条提问不对性能的提高有显著影响。为了评估局限性，我们进行了错误分析，发现概念错误（约 64%）是 LLMS 表现不佳的主要原因，而计算错误（约 36%）则是次要原因。我们希望这些数据和分析可以促进更好的材料科学领域特定 LLMS 的开发和信息抽取策略的研究。
</details></li>
</ul>
<hr>
<h2 id="mCL-NER-Cross-Lingual-Named-Entity-Recognition-via-Multi-view-Contrastive-Learning"><a href="#mCL-NER-Cross-Lingual-Named-Entity-Recognition-via-Multi-view-Contrastive-Learning" class="headerlink" title="mCL-NER: Cross-Lingual Named Entity Recognition via Multi-view Contrastive Learning"></a>mCL-NER: Cross-Lingual Named Entity Recognition via Multi-view Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09073">http://arxiv.org/abs/2308.09073</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ying Mo, Jian Yang, Jiahao Liu, Qifan Wang, Ruoyu Chen, Jingang Wang, Zhoujun Li</li>
<li>for: 提高 Cross-Lingual Named Entity Recognition (CrossNER) 的性能，尤其是非英语数据的 scarcity 问题。</li>
<li>methods: 提出 Multi-view Contrastive Learning for Cross-Lingual Named Entity Recognition (mCL-NER)，通过考虑 token 之间的关系来协调 semantic 和 token-level 表示之间的差异。</li>
<li>results: 在 XTREME benchmark 上进行了实验，与先前的数据驱动和模型驱动方法进行比较，显示 mCL-NER 可以大幅提高 CrossNER 的性能，在40种语言中提高了 nearly +2.0 $F_1$ 得分。<details>
<summary>Abstract</summary>
Cross-lingual named entity recognition (CrossNER) faces challenges stemming from uneven performance due to the scarcity of multilingual corpora, especially for non-English data. While prior efforts mainly focus on data-driven transfer methods, a significant aspect that has not been fully explored is aligning both semantic and token-level representations across diverse languages. In this paper, we propose Multi-view Contrastive Learning for Cross-lingual Named Entity Recognition (mCL-NER). Specifically, we reframe the CrossNER task into a problem of recognizing relationships between pairs of tokens. This approach taps into the inherent contextual nuances of token-to-token connections within entities, allowing us to align representations across different languages. A multi-view contrastive learning framework is introduced to encompass semantic contrasts between source, codeswitched, and target sentences, as well as contrasts among token-to-token relations. By enforcing agreement within both semantic and relational spaces, we minimize the gap between source sentences and their counterparts of both codeswitched and target sentences. This alignment extends to the relationships between diverse tokens, enhancing the projection of entities across languages. We further augment CrossNER by combining self-training with labeled source data and unlabeled target data. Our experiments on the XTREME benchmark, spanning 40 languages, demonstrate the superiority of mCL-NER over prior data-driven and model-based approaches. It achieves a substantial increase of nearly +2.0 $F_1$ scores across a broad spectrum and establishes itself as the new state-of-the-art performer.
</details>
<details>
<summary>摘要</summary>
cross-lingual named entity recognition (CrossNER) 面临着因语言异常缺乏多语言资料而导致的性能不均衡的挑战。现有的尝试主要集中在数据驱动的传输方法上，而一个重要的方面尚未得到完全探索是在多语言空间中对表示进行同步。在这篇论文中，我们提议一种多视角对比学习方法，称为多视角对比学习 для跨语言命名实体识别（mCL-NER）。具体来说，我们将跨语言命名实体识别任务转化为一个涉及到对实体中token之间的关系的问题。这种方法利用了实体中token之间的语言特征，从而使得表示之间进行同步。我们提出了一个多视角对比学习框架，包括源语言、codeswitched语言和目标语言之间的semantic对比和token之间的关系对比。通过在Semantic和Relational空间中强制同步，我们最小化了源语言和其相应的codeswitched语言和目标语言之间的差异。这种对应扩展到不同语言之间的关系，提高了实体的跨语言 проекing。我们还通过与标注的源数据和无标注目标数据进行自我训练，进一步提高了 CrossNER 的性能。我们在XTREME benchmark上进行了40种语言的实验，并证明了mCL-NER 在先前的数据驱动和模型基于的方法之上取得了显著的改进，增加了约 +2.0 $F_1$ 分数，并成为新的状态级表现者。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/18/cs.CL_2023_08_18/" data-id="clogyj8wa00977cra4bylcz6f" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/50/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/49/">49</a><a class="page-number" href="/page/50/">50</a><span class="page-number current">51</span><a class="page-number" href="/page/52/">52</a><a class="page-number" href="/page/53/">53</a><span class="space">&hellip;</span><a class="page-number" href="/page/83/">83</a><a class="extend next" rel="next" href="/page/52/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">115</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">55</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">111</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">61</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
