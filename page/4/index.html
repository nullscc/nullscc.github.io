
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/4/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.AI_2023_10_28" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/28/cs.AI_2023_10_28/" class="article-date">
  <time datetime="2023-10-28T12:00:00.000Z" itemprop="datePublished">2023-10-28</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/28/cs.AI_2023_10_28/">cs.AI - 2023-10-28</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="AI-for-Open-Science-A-Multi-Agent-Perspective-for-Ethically-Translating-Data-to-Knowledge"><a href="#AI-for-Open-Science-A-Multi-Agent-Perspective-for-Ethically-Translating-Data-to-Knowledge" class="headerlink" title="AI for Open Science: A Multi-Agent Perspective for Ethically Translating Data to Knowledge"></a>AI for Open Science: A Multi-Agent Perspective for Ethically Translating Data to Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18852">http://arxiv.org/abs/2310.18852</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chase Yakaboski, Gregory Hyde, Clement Nyanhongo, Eugene Santos Jr</li>
<li>for: 本文提出了一种名为“AI for Open Science”（AI4OS）的概念，以便在科学实验室中提高开放性，并且将科学发现的开放化视为核心原则。</li>
<li>methods: 本文使用了知识发现和数据挖掘（KDD）的原则来正式化AI4OS的语言。并详细介绍了AI4OS系统中知识翻译的三个关键阶段，以及在这些阶段中应用开放性的具体方法。</li>
<li>results: 本文提出了一种用于评估AI4OS的理论指标，并阐述了这种指标的伦理意义。作者希望通过强调AI4OS，使AI4科学的自动化实验室不仅对开发者而言是有利，而且对社会也是有益。<details>
<summary>Abstract</summary>
AI for Science (AI4Science), particularly in the form of self-driving labs, has the potential to sideline human involvement and hinder scientific discovery within the broader community. While prior research has focused on ensuring the responsible deployment of AI applications, enhancing security, and ensuring interpretability, we also propose that promoting openness in AI4Science discoveries should be carefully considered. In this paper, we introduce the concept of AI for Open Science (AI4OS) as a multi-agent extension of AI4Science with the core principle of maximizing open knowledge translation throughout the scientific enterprise rather than a single organizational unit. We use the established principles of Knowledge Discovery and Data Mining (KDD) to formalize a language around AI4OS. We then discuss three principle stages of knowledge translation embedded in AI4Science systems and detail specific points where openness can be applied to yield an AI4OS alternative. Lastly, we formulate a theoretical metric to assess AI4OS with a supporting ethical argument highlighting its importance. Our goal is that by drawing attention to AI4OS we can ensure the natural consequence of AI4Science (e.g., self-driving labs) is a benefit not only for its developers but for society as a whole.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在科学领域（AI4Science），特别是自动驾驶室，有可能削弱人类参与度和阻碍科学发现。而且，现有研究主要集中在负责AI应用部署、加强安全性和保持可解释性等方面。我们还建议在AI4Science发现中保持开放性应该仔细考虑。在本文中，我们提出了AI для开放科学（AI4OS）的概念，它是AI4Science的多代理扩展，核心原则是在科学产业中最大化开放知识翻译。我们使用已有的知识发现和数据挖掘（KDD）原则来正式化AI4OS的语言。然后，我们讨论了AI4Science系统中知识翻译的三个基本阶段，并详细介绍了在每个阶段中开放性可以如何应用，以生成一种AI4OS的替代方案。最后，我们提出了一个理论指标来评估AI4OS，并附加了一个伦理论据，强调其重要性。我们的目标是通过吸引关注AI4OS，使AI4Science的自然后果（例如自动驾驶室）对发展者和社会都带来好处。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Data-Augmentations-on-Self-Semi-Fully-Supervised-Pre-trained-Models"><a href="#Exploring-Data-Augmentations-on-Self-Semi-Fully-Supervised-Pre-trained-Models" class="headerlink" title="Exploring Data Augmentations on Self-&#x2F;Semi-&#x2F;Fully- Supervised Pre-trained Models"></a>Exploring Data Augmentations on Self-&#x2F;Semi-&#x2F;Fully- Supervised Pre-trained Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18850">http://arxiv.org/abs/2310.18850</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shentong Mo, Zhun Sun, Chao Li</li>
<li>for:  investigate the effectiveness of data augmentation techniques in vision pre-trained models</li>
<li>methods:  apply 4 types of data augmentations (Random Erasing, CutOut, CutMix, and MixUp) to self-&#x2F;semi-&#x2F;fully-supervised pre-trained models</li>
<li>results:  observe that masking regions of images decreases invariance but increases diversity, while MixUp approach improves diversity with minimal decrease in invariance.Here’s the full text in Simplified Chinese:</li>
<li>for: 研究视觉预训模型中数据增强技术的效果</li>
<li>methods: 对自助&#x2F;半助&#x2F;全助预训模型应用4种数据增强方法（随机覆盖、剪辑、混合和混合）</li>
<li>results: 发现，对图像masking区域可以降低学习的不变性，但提供更大的多样性；而混合方法可以提高多样性，只是有一定的减少不变性。<details>
<summary>Abstract</summary>
Data augmentation has become a standard component of vision pre-trained models to capture the invariance between augmented views. In practice, augmentation techniques that mask regions of a sample with zero/mean values or patches from other samples are commonly employed in pre-trained models with self-/semi-/fully-supervised contrastive losses. However, the underlying mechanism behind the effectiveness of these augmentation techniques remains poorly explored. To investigate the problems, we conduct an empirical study to quantify how data augmentation affects performance. Concretely, we apply 4 types of data augmentations termed with Random Erasing, CutOut, CutMix and MixUp to a series of self-/semi-/fully- supervised pre-trained models. We report their performance on vision tasks such as image classification, object detection, instance segmentation, and semantic segmentation. We then explicitly evaluate the invariance and diversity of the feature embedding. We observe that: 1) Masking regions of the images decreases the invariance of the learned feature embedding while providing a more considerable diversity. 2) Manual annotations do not change the invariance or diversity of the learned feature embedding. 3) The MixUp approach improves the diversity significantly, with only a marginal decrease in terms of the invariance.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化中文。<</SYS>>预训练模型中的数据扩充已成为标准组件，以捕捉不同扩充视图之间的不变性。在实践中，通常使用随机将区域Masking为零或平均值的技术来实现预训练模型，并使用自我/半自动/全自动对比损失。然而，这些扩充技术的下面机制仍然不够了解。为了调查问题，我们进行了一项实验来衡量数据扩充对性能的影响。具体来说，我们将4种数据扩充方法称为随机擦除、CutOut、CutMix和MixUp应用于一系列自我/半自动/全自动预训练模型。我们则Report它们在视觉任务中的性能，包括图像分类、物体检测、实例分割和semantic segmentation。然后，我们显式评估扩充后feature embedding的不变性和多样性。我们发现：1. 将图像中的区域Masking为零或平均值会降低学习的feature embedding不变性，同时提供更大的多样性。2. 手动标注没有改变学习的feature embedding不变性或多样性。3. MixUp方法可以提高多样性，只有小量地降低不变性。
</details></li>
</ul>
<hr>
<h2 id="BanditPAM-Faster-k-medoids-Clustering"><a href="#BanditPAM-Faster-k-medoids-Clustering" class="headerlink" title="BanditPAM++: Faster $k$-medoids Clustering"></a>BanditPAM++: Faster $k$-medoids Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18844">http://arxiv.org/abs/2310.18844</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thrungroup/banditpam_plusplus_experiments">https://github.com/thrungroup/banditpam_plusplus_experiments</a></li>
<li>paper_authors: Mo Tiwari, Ryan Kang, Donghyun Lee, Sebastian Thrun, Chris Piech, Ilan Shomorony, Martin Jinye Zhang</li>
<li>for: 这个论文主要关注于提高$k$-medoids clustering算法的效率和准确性。</li>
<li>methods: 该论文提出了两种算法优化方法，即在每个迭代中重用归一化信息，以及在不同迭代之间重用信息。</li>
<li>results: 实验结果表明，使用提出的 BanditPAM++ 算法可以在 CIFAR10 数据集上返回同样的 clustering 解决方案，但是运行速度比 BanditPAM 快得多，例如在 CIFAR10 数据集上，BanditPAM++ 运行时间是 BanditPAM 的10倍以上。<details>
<summary>Abstract</summary>
Clustering is a fundamental task in data science with wide-ranging applications. In $k$-medoids clustering, cluster centers must be actual datapoints and arbitrary distance metrics may be used; these features allow for greater interpretability of the cluster centers and the clustering of exotic objects in $k$-medoids clustering, respectively. $k$-medoids clustering has recently grown in popularity due to the discovery of more efficient $k$-medoids algorithms. In particular, recent research has proposed BanditPAM, a randomized $k$-medoids algorithm with state-of-the-art complexity and clustering accuracy. In this paper, we present BanditPAM++, which accelerates BanditPAM via two algorithmic improvements, and is $O(k)$ faster than BanditPAM in complexity and substantially faster than BanditPAM in wall-clock runtime. First, we demonstrate that BanditPAM has a special structure that allows the reuse of clustering information $\textit{within}$ each iteration. Second, we demonstrate that BanditPAM has additional structure that permits the reuse of information $\textit{across}$ different iterations. These observations inspire our proposed algorithm, BanditPAM++, which returns the same clustering solutions as BanditPAM but often several times faster. For example, on the CIFAR10 dataset, BanditPAM++ returns the same results as BanditPAM but runs over 10$\times$ faster. Finally, we provide a high-performance C++ implementation of BanditPAM++, callable from Python and R, that may be of interest to practitioners at https://github.com/motiwari/BanditPAM. Auxiliary code to reproduce all of our experiments via a one-line script is available at https://github.com/ThrunGroup/BanditPAM_plusplus_experiments.
</details>
<details>
<summary>摘要</summary>
“集群是数据科学中的基本任务，具有广泛的应用。在$k$-medians集群中，集群中心必须是实际数据点，并且可以使用任意距离度量；这些特点使得$k$-medians集群更有可读性，并且可以更好地集 clusters 的特殊对象。随着更高效的$k$-medians算法的发现，$k$-medians集群在最近几年内 Popularity 增长。本文提出了 BanditPAM++，它是一种随机化的 $k$-medians算法，通过两个算法优化，与 BanditPAM 相比， complexity 为 $O(k)$ 和增加了很多的 wall-clock 时间。首先，我们证明 BanditPAM 具有特殊的结构，可以在每个迭代中重用 clustering 信息。其次，我们证明 BanditPAM 具有额外的结构，允许在不同的迭代中重用信息。这些观察点激发我们提出 BanditPAM++，它返回与 BanditPAM 相同的 clustering 解决方案，但通常很多 slower。例如，在 CIFAR10 数据集上，BanditPAM++ 与 BanditPAM 返回相同的结果，但运行速度比 BanditPAM 快了大约 10 倍。最后，我们提供了高性能的 C++ 实现，可以在 Python 和 R 中调用，并可能对实践者有利。详细的实验代码可以在 https://github.com/motiwari/BanditPAM 和 https://github.com/ThrunGroup/BanditPAM_plusplus_experiments 上找到。”
</details></li>
</ul>
<hr>
<h2 id="Automating-the-Correctness-Assessment-of-AI-generated-Code-for-Security-Contexts"><a href="#Automating-the-Correctness-Assessment-of-AI-generated-Code-for-Security-Contexts" class="headerlink" title="Automating the Correctness Assessment of AI-generated Code for Security Contexts"></a>Automating the Correctness Assessment of AI-generated Code for Security Contexts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18834">http://arxiv.org/abs/2310.18834</a></li>
<li>repo_url: None</li>
<li>paper_authors: Domenico Cotroneo, Alessio Foggia, Cristina Improta, Pietro Liguori, Roberto Natella</li>
<li>for: This paper aims to evaluate the correctness of AI-generated code for security purposes using a fully automated method.</li>
<li>methods: The proposed method, named ACCA, uses symbolic execution to assess whether the AI-generated code behaves as a reference implementation.</li>
<li>results: The proposed method outperforms baseline solutions and shows a strong correlation with human evaluation, with an average time of ~0.17s per code snippet, much faster than manual inspection.<details>
<summary>Abstract</summary>
In this paper, we propose a fully automated method, named ACCA, to evaluate the correctness of AI-generated code for security purposes. The method uses symbolic execution to assess whether the AI-generated code behaves as a reference implementation. We use ACCA to assess four state-of-the-art models trained to generate security-oriented assembly code and compare the results of the evaluation with different baseline solutions, including output similarity metrics, widely used in the field, and the well-known ChatGPT, the AI-powered language model developed by OpenAI. Our experiments show that our method outperforms the baseline solutions and assesses the correctness of the AI-generated code similar to the human-based evaluation, which is considered the ground truth for the assessment in the field. Moreover, ACCA has a very strong correlation with human evaluation (Pearson's correlation coefficient r=0.84 on average). Finally, since it is a fully automated solution that does not require any human intervention, the proposed method performs the assessment of every code snippet in ~0.17s on average, which is definitely lower than the average time required by human analysts to manually inspect the code, based on our experience.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种完全自动化的方法，名为ACCA，用于评估人工智能生成的代码的正确性，以便用于安全目的。该方法利用symbolic执行来评估AI生成的代码是否与参考实现一致。我们使用ACCA评估了四种现状最佳的模型，用于生成安全听力的assembly代码，并与不同的基准解决方案进行比较，包括输出相似度指标，在领域内广泛使用的，以及由OpenAI开发的知名的ChatGPT人工智能语言模型。我们的实验表明，我们的方法超越了基准解决方案，并与人类评估类似，被视为领域中的地面真实值。此外，ACCA与人类评估之间存在强相关性（平均Pearson相关系数r=0.84）。最后，由于它是完全自动化的，不需要任何人类参与，我们的方法可以快速地评估每个代码副本，平均需时约0.17秒，明显低于由人工分析员手动检查代码所需的时间，根据我们的经验。
</details></li>
</ul>
<hr>
<h2 id="Responsible-AI-RAI-Games-and-Ensembles"><a href="#Responsible-AI-RAI-Games-and-Ensembles" class="headerlink" title="Responsible AI (RAI) Games and Ensembles"></a>Responsible AI (RAI) Games and Ensembles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18832">http://arxiv.org/abs/2310.18832</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yashgupta-7/rai-games">https://github.com/yashgupta-7/rai-games</a></li>
<li>paper_authors: Yash Gupta, Runtian Zhai, Arun Suggala, Pradeep Ravikumar</li>
<li>for: 这个研究旨在解决人工智能（AI）在社会中的影响，包括公平性、可靠性和安全性等问题。</li>
<li>methods: 这个研究使用了一种普遍的框架，称为责任AI（RAI）游戏，来研究这些问题。两种算法来解决这些游戏：一种是基于在线学习和游戏理论的游戏玩家算法，另一种是基于经典统计文献中的提升和回归算法。</li>
<li>results: 研究证明了这些方法在解决一些RAI问题，特别是在子人口变化时的性能竞争力。<details>
<summary>Abstract</summary>
Several recent works have studied the societal effects of AI; these include issues such as fairness, robustness, and safety. In many of these objectives, a learner seeks to minimize its worst-case loss over a set of predefined distributions (known as uncertainty sets), with usual examples being perturbed versions of the empirical distribution. In other words, aforementioned problems can be written as min-max problems over these uncertainty sets. In this work, we provide a general framework for studying these problems, which we refer to as Responsible AI (RAI) games. We provide two classes of algorithms for solving these games: (a) game-play based algorithms, and (b) greedy stagewise estimation algorithms. The former class is motivated by online learning and game theory, whereas the latter class is motivated by the classical statistical literature on boosting, and regression. We empirically demonstrate the applicability and competitive performance of our techniques for solving several RAI problems, particularly around subpopulation shift.
</details>
<details>
<summary>摘要</summary>
Recent research has focused on the social impact of AI, including issues such as fairness, robustness, and safety. In many cases, the goal is to minimize the worst-case loss over a set of predefined distribution (known as uncertainty sets), such as perturbed versions of the empirical distribution. These problems can be formulated as min-max problems over the uncertainty sets. In this study, we propose a general framework for addressing these issues, which we refer to as Responsible AI (RAI) games. We present two classes of algorithms for solving these games: (a) game-play based algorithms, and (b) greedy stagewise estimation algorithms. The former class is inspired by online learning and game theory, while the latter class is based on the classical statistical literature on boosting and regression. We empirically demonstrate the applicability and competitive performance of our techniques for solving several RAI problems, particularly in the context of subpopulation shift.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. Traditional Chinese is used in Hong Kong, Macau, and Taiwan.
</details></li>
</ul>
<hr>
<h2 id="All-Things-Considered-Detecting-Partisan-Events-from-News-Media-with-Cross-Article-Comparison"><a href="#All-Things-Considered-Detecting-Partisan-Events-from-News-Media-with-Cross-Article-Comparison" class="headerlink" title="All Things Considered: Detecting Partisan Events from News Media with Cross-Article Comparison"></a>All Things Considered: Detecting Partisan Events from News Media with Cross-Article Comparison</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18827">http://arxiv.org/abs/2310.18827</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yujian Liu, Xinliang Frederick Zhang, Kaijian Zou, Ruihong Huang, Nick Beauchamp, Lu Wang</li>
<li>for: 本研究旨在探讨新闻媒体如何影响公众意见，以及媒体如何通过透明或不透明的方式 shape opinion。</li>
<li>methods: 本研究使用了一种基于潜在变量的框架，通过比较相同故事的多篇文章来预测文章的政治倾向。</li>
<li>results: 实验表明，媒体可以通过不公平地选择报道事件来形成公众意见，而且这种偏见存在于主流媒体中，即使媒体具有强的 объекivity 和非政治化准则。<details>
<summary>Abstract</summary>
Public opinion is shaped by the information news media provide, and that information in turn may be shaped by the ideological preferences of media outlets. But while much attention has been devoted to media bias via overt ideological language or topic selection, a more unobtrusive way in which the media shape opinion is via the strategic inclusion or omission of partisan events that may support one side or the other. We develop a latent variable-based framework to predict the ideology of news articles by comparing multiple articles on the same story and identifying partisan events whose inclusion or omission reveals ideology. Our experiments first validate the existence of partisan event selection, and then show that article alignment and cross-document comparison detect partisan events and article ideology better than competitive baselines. Our results reveal the high-level form of media bias, which is present even among mainstream media with strong norms of objectivity and nonpartisanship. Our codebase and dataset are available at https://github.com/launchnlp/ATC.
</details>
<details>
<summary>摘要</summary>
社会舆论是由新闻媒体提供的信息所形成的，而这些信息可能受媒体机构的意识形态偏好所影响。然而，许多注意力集中在媒体偏见的明显表达或话题选择上，而媒体 shape 意见的更加不显式的方式却很少得到关注。我们提出了一种基于隐藏变量的框架，用于预测新闻文章的意识性。我们通过比较同一个故事的多篇文章来确定包含或排除某些政治事件的媒体偏见。我们的实验首先证明了事件选择的存在，然后展示了文章对齐和跨文档比较的能力更好地探测文章意识性和媒体偏见。我们的结果表明，媒体偏见存在于主流媒体中，即使媒体有强大的objectivity和非政治化的准则。我们的代码库和数据集可以在 <https://github.com/launchnlp/ATC> 上获取。
</details></li>
</ul>
<hr>
<h2 id="A-Fuzzy-Time-Series-Based-Model-Using-Particle-Swarm-Optimization-and-Weighted-Rules"><a href="#A-Fuzzy-Time-Series-Based-Model-Using-Particle-Swarm-Optimization-and-Weighted-Rules" class="headerlink" title="A Fuzzy Time Series-Based Model Using Particle Swarm Optimization and Weighted Rules"></a>A Fuzzy Time Series-Based Model Using Particle Swarm Optimization and Weighted Rules</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18825">http://arxiv.org/abs/2310.18825</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Ortiz-Arroyo</li>
<li>for: 提高高阶不确定时间序列模型的精度和可靠性。</li>
<li>methods:  combining particle swarm optimization (PSO) and weighted summation to address the limitations of high-order fuzzy time series models.</li>
<li>results: 比前方法更高精度地模型时间序列。<details>
<summary>Abstract</summary>
During the last decades, a myriad of fuzzy time series models have been proposed in scientific literature. Among the most accurate models found in fuzzy time series, the high-order ones are the most accurate. The research described in this paper tackles three potential limitations associated with the application of high-order fuzzy time series models. To begin with, the adequacy of forecast rules lacks consistency. Secondly, as the model's order increases, data utilization diminishes. Thirdly, the uniformity of forecast rules proves to be highly contingent on the chosen interval partitions. To address these likely drawbacks, we introduce a novel model based on fuzzy time series that amalgamates the principles of particle swarm optimization (PSO) and weighted summation. Our results show that our approach models accurately the time series in comparison with previous methods.
</details>
<details>
<summary>摘要</summary>
在过去几十年中，数字时间序列模型的研究得到了广泛的发展和应用。高阶的含糊时间序列模型在科学文献中被认为是最为准确的。本研究考虑了高阶含糊时间序列模型的三个可能的限制：首先，预测规则的适用稳定性不充分；第二，随着模型的阶数增加，数据利用率逐渐减少；第三，预测规则的均匀性高度取决于选择的时间分割。为解决这些可能的缺点，我们提出了一种基于含糊时间序列的新模型，具有融合了粒子群组合优化（PSO）和Weighted Summary的原则。我们的结果表明，我们的方法可以准确地模型时间序列，与前期方法相比。
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Semi-Supervised-Federated-Learning-How-to-co-train-fully-labeled-and-fully-unlabeled-client-imaging-data"><a href="#Rethinking-Semi-Supervised-Federated-Learning-How-to-co-train-fully-labeled-and-fully-unlabeled-client-imaging-data" class="headerlink" title="Rethinking Semi-Supervised Federated Learning: How to co-train fully-labeled and fully-unlabeled client imaging data"></a>Rethinking Semi-Supervised Federated Learning: How to co-train fully-labeled and fully-unlabeled client imaging data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18815">http://arxiv.org/abs/2310.18815</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pramit Saha, Divyanshu Mishra, J. Alison Noble</li>
<li>for: 本研究旨在解决 semi-supervised federated learning (SSFL) 中 client 之间具有半标注数据的问题，特别是在医疗设置下，合作伙伴（通常是医院）可能拥有图像，但没有注释。</li>
<li>methods: 我们提出了一种新的学习方案，即 Isolated Federated Learning (IsoFed)，以避免简单的平均方法。我们的训练方法包括两个部分：（a）孤立的客户端模型归一化，以及（b）所有客户端的本地自我超vised pre-training。</li>
<li>results: 我们在四种不同的医疗影像数据集上进行了实验，包括 MedMNIST 的医疗影像 benchmark。我们还在不同的实验设置下变换了比例的标注客户端和多样性，以示出我们的方法在不同的情况下的效果。<details>
<summary>Abstract</summary>
The most challenging, yet practical, setting of semi-supervised federated learning (SSFL) is where a few clients have fully labeled data whereas the other clients have fully unlabeled data. This is particularly common in healthcare settings where collaborating partners (typically hospitals) may have images but not annotations. The bottleneck in this setting is the joint training of labeled and unlabeled clients as the objective function for each client varies based on the availability of labels. This paper investigates an alternative way for effective training with labeled and unlabeled clients in a federated setting. We propose a novel learning scheme specifically designed for SSFL which we call Isolated Federated Learning (IsoFed) that circumvents the problem by avoiding simple averaging of supervised and semi-supervised models together. In particular, our training approach consists of two parts - (a) isolated aggregation of labeled and unlabeled client models, and (b) local self-supervised pretraining of isolated global models in all clients. We evaluate our model performance on medical image datasets of four different modalities publicly available within the biomedical image classification benchmark MedMNIST. We further vary the proportion of labeled clients and the degree of heterogeneity to demonstrate the effectiveness of the proposed method under varied experimental settings.
</details>
<details>
<summary>摘要</summary>
最大挑战的、但实际可行的 semi-supervised federated learning（SSFL）设置是，一些客户端有完全标注数据，而另一些客户端有完全无标注数据。这种情况 particullary 在医疗设置中常见，合作伙伴（通常是医院）可能拥有图像，但并没有标注。瓶颈在这种设置下是 joint 训练标注和无标注客户端的目标函数，因为每个客户端的目标函数因标注的可用性而变化。这篇论文investigates an alternative way for effective training with labeled and unlabeled clients in a federated setting. We propose a novel learning scheme specifically designed for SSFL, which we call Isolated Federated Learning (IsoFed), to circumvent this problem by avoiding simple averaging of supervised and semi-supervised models together. In particular, our training approach consists of two parts: (a) isolated aggregation of labeled and unlabeled client models, and (b) local self-supervised pretraining of isolated global models in all clients. We evaluate our model performance on medical image datasets of four different modalities publicly available within the biomedical image classification benchmark MedMNIST. We further vary the proportion of labeled clients and the degree of heterogeneity to demonstrate the effectiveness of the proposed method under varied experimental settings.
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Framework-for-Interpretable-and-Probabilistic-Model-Based-Safe-Reinforcement-Learning"><a href="#Hierarchical-Framework-for-Interpretable-and-Probabilistic-Model-Based-Safe-Reinforcement-Learning" class="headerlink" title="Hierarchical Framework for Interpretable and Probabilistic Model-Based Safe Reinforcement Learning"></a>Hierarchical Framework for Interpretable and Probabilistic Model-Based Safe Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18811">http://arxiv.org/abs/2310.18811</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ammar N. Abbas, Georgios C. Chasparis, John D. Kelleher</li>
<li>for: 这篇论文的目的是提出一种基于深度强化学习的安全关键系统解决方案，以便在安全关键系统中使用深度强化学习，并且提供解释性的执行。</li>
<li>methods: 这篇论文使用了深度强化学习，并与传统决策策略相合作，以提高安全关键系统的可靠性和可控性。它还使用了潜在模型和强化学习的融合，以提高解释性和可靠性。</li>
<li>results: 这篇论文的实验结果显示，BC-SRLA在维护领域中的维护维护过程中表现出色，比传统方法和其他基于RL的基eline更好。<details>
<summary>Abstract</summary>
The difficulty of identifying the physical model of complex systems has led to exploring methods that do not rely on such complex modeling of the systems. Deep reinforcement learning has been the pioneer for solving this problem without the need for relying on the physical model of complex systems by just interacting with it. However, it uses a black-box learning approach that makes it difficult to be applied within real-world and safety-critical systems without providing explanations of the actions derived by the model. Furthermore, an open research question in deep reinforcement learning is how to focus the policy learning of critical decisions within a sparse domain. This paper proposes a novel approach for the use of deep reinforcement learning in safety-critical systems. It combines the advantages of probabilistic modeling and reinforcement learning with the added benefits of interpretability and works in collaboration and synchronization with conventional decision-making strategies. The BC-SRLA is activated in specific situations which are identified autonomously through the fused information of probabilistic model and reinforcement learning, such as abnormal conditions or when the system is near-to-failure. Further, it is initialized with a baseline policy using policy cloning to allow minimum interactions with the environment to address the challenges associated with using RL in safety-critical industries. The effectiveness of the BC-SRLA is demonstrated through a case study in maintenance applied to turbofan engines, where it shows superior performance to the prior art and other baselines.
</details>
<details>
<summary>摘要</summary>
因为识别复杂系统的物理模型具有挑战，因此探索不需要基于这些复杂模型的方法。深度强化学习曾经是解决这个问题的先驱，它不需要基于系统的物理模型来解决问题，只需通过与系统交互来解决问题。然而，它使用黑盒学习方法，这使得其在实际世界和安全关键系统中应用非常困难，而且无法提供行为的解释。此外，深度强化学习中的一个开放研究问题是如何将策略学习集中在稀疏领域中。本文提出了一种基于深度强化学习的新方法，用于安全关键系统中。它结合了概率模型和强化学习的优点，同时增加了可解性。此外，它与传统决策策略协作和同步，在特定情况下自动识别并且通过混合信息来识别，例如异常情况或系统垂直危机。此外，它使用策略做副本来初始化，以最小化与环境的交互，解决了使用强化学习在安全关键行业中的挑战。本文通过一个维护案例研究展示了BC-SRLA的有效性，其在维护领域的表现较优于先前艺术和其他基线。
</details></li>
</ul>
<hr>
<h2 id="OC-NMN-Object-centric-Compositional-Neural-Module-Network-for-Generative-Visual-Analogical-Reasoning"><a href="#OC-NMN-Object-centric-Compositional-Neural-Module-Network-for-Generative-Visual-Analogical-Reasoning" class="headerlink" title="OC-NMN: Object-centric Compositional Neural Module Network for Generative Visual Analogical Reasoning"></a>OC-NMN: Object-centric Compositional Neural Module Network for Generative Visual Analogical Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18807">http://arxiv.org/abs/2310.18807</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rim Assouel, Pau Rodriguez, Perouz Taslakian, David Vazquez, Yoshua Bengio</li>
<li>for: This paper aims to improve the ability of machine learning systems to imagine and compose learned concepts in novel ways, specifically in the context of visual reasoning.</li>
<li>methods: The paper proposes a modular data augmentation framework called Object-centric Compositional Neural Module Network (OC-NMN), which decomposes visual generative reasoning tasks into a series of primitives applied to objects.</li>
<li>results: The paper shows that the proposed modular architectural choices can be used to generate new training tasks that lead to better out-of-distribution generalization, and compares the model to existing and new baselines in a proposed visual reasoning benchmark.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文目标是提高机器学习系统的想象和组合学习能力，特别是在视觉理解中。</li>
<li>methods: 该论文提出了一种模块化数据增强框架，称为Object-centric Compositional Neural Module Network (OC-NMN)，它将视觉生成逻辑任务 decomposes 成一系列对象上的基本操作。</li>
<li>results: 论文显示，提出的模块性建筑设计可以生成新的训练任务，导致更好的 OUT-OF-distribution 通用化。并与现有和新的基准值进行比较，在提posed的视觉理解 bencmark 中。<details>
<summary>Abstract</summary>
A key aspect of human intelligence is the ability to imagine -- composing learned concepts in novel ways -- to make sense of new scenarios. Such capacity is not yet attained for machine learning systems. In this work, in the context of visual reasoning, we show how modularity can be leveraged to derive a compositional data augmentation framework inspired by imagination. Our method, denoted Object-centric Compositional Neural Module Network (OC-NMN), decomposes visual generative reasoning tasks into a series of primitives applied to objects without using a domain-specific language. We show that our modular architectural choices can be used to generate new training tasks that lead to better out-of-distribution generalization. We compare our model to existing and new baselines in proposed visual reasoning benchmark that consists of applying arithmetic operations to MNIST digits.
</details>
<details>
<summary>摘要</summary>
人类智能的一个重要方面是具备想象能力---把已学习的概念组合在新的方式下来---以便理解新的场景。这种能力目前尚未被机器学习系统具备。在这项工作中，我们在视觉逻辑上利用了模块性，以 derive一种基于想象的数据增强框架。我们的方法，称为物体中心的compositional Neural Module Network（OC-NMN），将视觉生成逻辑任务分解成一系列对象上的基本Primitive。我们显示了我们的建筑方式可以生成新的训练任务，导致更好的对外值 generale。我们与现有和新的基准值进行比较，并在我们提出的视觉理解benchmark中进行测试，该benchmark包括对MNIST数字应用数学运算。
</details></li>
</ul>
<hr>
<h2 id="Open-Visual-Knowledge-Extraction-via-Relation-Oriented-Multimodality-Model-Prompting"><a href="#Open-Visual-Knowledge-Extraction-via-Relation-Oriented-Multimodality-Model-Prompting" class="headerlink" title="Open Visual Knowledge Extraction via Relation-Oriented Multimodality Model Prompting"></a>Open Visual Knowledge Extraction via Relation-Oriented Multimodality Model Prompting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18804">http://arxiv.org/abs/2310.18804</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hejie Cui, Xinyu Fang, Zihan Zhang, Ran Xu, Xuan Kan, Xin Liu, Yue Yu, Manling Li, Yangqiu Song, Carl Yang</li>
<li>for: 这篇论文旨在探讨开放视觉知识EXTRACTION的新方法，以提高机器理解世界的能力。</li>
<li>methods: 该方法使用开放关系区域检测器和大型多模态模型，从图像中提取无格式的视觉知识。</li>
<li>results: 实验表明，OpenVik可以生成具有准确性和独特性的开放视觉知识，并在多种视觉理解应用中提供了显著的改进。<details>
<summary>Abstract</summary>
Images contain rich relational knowledge that can help machines understand the world. Existing methods on visual knowledge extraction often rely on the pre-defined format (e.g., sub-verb-obj tuples) or vocabulary (e.g., relation types), restricting the expressiveness of the extracted knowledge. In this work, we take a first exploration to a new paradigm of open visual knowledge extraction. To achieve this, we present OpenVik which consists of an open relational region detector to detect regions potentially containing relational knowledge and a visual knowledge generator that generates format-free knowledge by prompting the large multimodality model with the detected region of interest. We also explore two data enhancement techniques for diversifying the generated format-free visual knowledge. Extensive knowledge quality evaluations highlight the correctness and uniqueness of the extracted open visual knowledge by OpenVik. Moreover, integrating our extracted knowledge across various visual reasoning applications shows consistent improvements, indicating the real-world applicability of OpenVik.
</details>
<details>
<summary>摘要</summary>
图像含有丰富的关系知识，可以帮助机器理解世界。现有的视觉知识EXTRACTION方法 oft rely on先defined format (e.g., sub-verb-obj tuples) or vocabulary (e.g., relation types), restricting the expressiveness of the extracted knowledge。在这项工作中，我们开始了一种新的开放视觉知识EXTRACTION paradigm。为达到这个目标，我们提出了 OpenVik，它包括一个开放关系区域检测器，用于检测可能包含关系知识的区域，以及一个可视知识生成器，通过在检测到区域特点的提示下，生成无格式的知识。我们还探讨了两种数据增强技术，用于让生成的无格式视觉知识更加多样化。广泛的知识质量评估表明OpenVik提取的开放视觉知识具有正确性和独特性。此外，我们在不同的视觉理解应用中集成我们提取的知识，显示了一致的改进， indicating the real-world applicability of OpenVik。
</details></li>
</ul>
<hr>
<h2 id="Sequence-Level-Certainty-Reduces-Hallucination-In-Knowledge-Grounded-Dialogue-Generation"><a href="#Sequence-Level-Certainty-Reduces-Hallucination-In-Knowledge-Grounded-Dialogue-Generation" class="headerlink" title="Sequence-Level Certainty Reduces Hallucination In Knowledge-Grounded Dialogue Generation"></a>Sequence-Level Certainty Reduces Hallucination In Knowledge-Grounded Dialogue Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18794">http://arxiv.org/abs/2310.18794</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yixin Wan, Fanyou Wu, Weijie Xu, Srinivasan H. Sengamedu</li>
<li>for: 本研究的目的是探讨模型幻化现象在自然语言生成（NLG）中的作用，并提出基于确定性的回答排名方法来减少模型幻化。</li>
<li>methods: 本研究使用了序列级确定性的两个方面：概率确定性和含义确定性，并通过对知识推理对话生成（KGDG）任务的实验发现，两者均与模型回答中幻化水平有显著相关性。</li>
<li>results: 研究发现，在模型回答中含义确定性水平较高时，幻化水平较低，而概率确定性水平较高时，幻化水平较高。此外，研究还提供了理论分析和证明，证明含义确定性可以作为概率确定性的一种代替方案，并在黑obox场景中具有可行性。基于这些发现，本研究提出了确定性基本回答排名（CRR）方法，以减少NLG中模型幻化现象。CRR分为两种类型：概率CRR（P-CRR）和含义CRR（S-CRR）。P-CRR使用模型回答整个序列的平均Log probability来排名样本。S-CRR根据模型回答的含义相似度来排名一些模型回答的候选者，并使用含义相似度来估计模型回答的确定性水平。通过对3个KGDG数据集、3种排序方法和4个模型进行了广泛的实验， validate了我们提出的2种CRR方法的效果。<details>
<summary>Abstract</summary>
Model hallucination has been a crucial interest of research in Natural Language Generation (NLG). In this work, we propose sequence-level certainty as a common theme over hallucination in NLG, and explore the correlation between sequence-level certainty and the level of hallucination in model responses. We categorize sequence-level certainty into two aspects: probabilistic certainty and semantic certainty, and reveal through experiments on Knowledge-Grounded Dialogue Generation (KGDG) task that both a higher level of probabilistic certainty and a higher level of semantic certainty in model responses are significantly correlated with a lower level of hallucination. What's more, we provide theoretical proof and analysis to show that semantic certainty is a good estimator of probabilistic certainty, and therefore has the potential as an alternative to probability-based certainty estimation in black-box scenarios. Based on the observation on the relationship between certainty and hallucination, we further propose Certainty-based Response Ranking (CRR), a decoding-time method for mitigating hallucination in NLG. Based on our categorization of sequence-level certainty, we propose 2 types of CRR approach: Probabilistic CRR (P-CRR) and Semantic CRR (S-CRR). P-CRR ranks individually sampled model responses using their arithmetic mean log-probability of the entire sequence. S-CRR approaches certainty estimation from meaning-space, and ranks a number of model response candidates based on their semantic certainty level, which is estimated by the entailment-based Agreement Score (AS). Through extensive experiments across 3 KGDG datasets, 3 decoding methods, and on 4 different models, we validate the effectiveness of our 2 proposed CRR methods to reduce model hallucination.
</details>
<details>
<summary>摘要</summary>
modelo de generación de lenguaje natural (NLG) ha sido un tema crucial de investigación en la comunidad científica. En este trabajo, propusimos la certidumbre de secuencia como un tema común en la generación de lenguaje natural, y exploramos la relación entre la certidumbre de secuencia y el nivel de halucinación en las respuestas del modelo. Distinguiendo la certidumbre de secuencia en dos aspectos: la certidumbre probabilística y la certidumbre semántica, revelamos a través de experimentos en la tarea de generación de diálogo basado en conocimientos (KGDG) que ambos tienen un nivel significativamente correlacionado con un nivel bajo de halucinación. Además, proveímos pruebas teóricas y análisis para demostrar que la certidumbre semántica es un buen estimador de la certidumbre probabilística, y por lo tanto tiene el potencial de servir como una alternativa a la estimación de certidumbre basada en probabilidades en escenarios de "black-box". Basándonos en la observación de la relación entre la certidumbre y la halucinación, propusimos el Metodo de Ranking de Respuestas basado en la Certidumbre (CRR), un método de decodificación en tiempo real para mitigar la halucinación en NLG. Basándonos en nuestra categorización de la certidumbre de secuencia, propusimos dos enfoques de CRR: el enfoque de Certidumbre Probabilística (P-CRR) y el enfoque de Certidumbre Semántica (S-CRR). El enfoque P-CRR clasifica las respuestas individualmente seleccionadas del modelo utilizando su probabilidad aritmética promedio de toda la secuencia. El enfoque S-CRR se basa en la certidumbre semántica, y clasifica un número de candidatos de respuestas del modelo según su nivel de certidumbre semántica, que se estima utilizando el índice de Entendimiento (AS). A través de extensivos experimentos en tres conjuntos de datos de KGDG, tres métodos de decodificación y cuatro modelos diferentes, validamos la eficacia de nuestros dos métodos de CRR para reducir la halucinación del modelo.
</details></li>
</ul>
<hr>
<h2 id="“Do-it-my-way-”-Impact-of-Customizations-on-Trust-perceptions-in-Human-Robot-Collaboration"><a href="#“Do-it-my-way-”-Impact-of-Customizations-on-Trust-perceptions-in-Human-Robot-Collaboration" class="headerlink" title="“Do it my way!”: Impact of Customizations on Trust perceptions in Human-Robot Collaboration"></a>“Do it my way!”: Impact of Customizations on Trust perceptions in Human-Robot Collaboration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18791">http://arxiv.org/abs/2310.18791</a></li>
<li>repo_url: None</li>
<li>paper_authors: Parv Kapoor, Simon Chu, Angela Chen</li>
<li>for: 这个研究旨在探讨个性化助手机器人的影响，以及个性化程度对人类使用者的体验和信任感的影响。</li>
<li>methods: 研究采用了在人类使用者身上进行的内置研究（N&#x3D;17），并对不同水平的自定义可能性进行了比较。</li>
<li>results: 研究发现，增加个性化程度会导致更高的信任和舒适感。这些发现可以帮助设计师设计更信任worthy和个性化的助手机器人。<details>
<summary>Abstract</summary>
Trust has been shown to be a key factor in effective human-robot collaboration. In the context of assistive robotics, the effect of trust factors on human experience is further pronounced. Personalization of assistive robots is an orthogonal factor positively correlated with robot adoption and user perceptions. In this work, we investigate the relationship between these factors through a within-subjects study (N=17). We provide different levels of customization possibilities over baseline autonomous robot behavior and investigate its impact on trust. Our findings indicate that increased levels of customization was associated with higher trust and comfort perceptions. The assistive robot design process can benefit significantly from our insights for designing trustworthy and customized robots.
</details>
<details>
<summary>摘要</summary>
信任被证明为人机合作中关键因素。在帮助型机器人领域，信任因素对人类体验的影响更加明显。个性化机器人设计是一个 orthogonal 因素，与机器人采用和用户对机器人的评价显著相关。本研究通过在subjects（N=17）中进行内部研究，研究自适应机器人行为的不同水平的个性化可能性对信任的影响。我们发现，逐渐提高个性化水平与信任、舒适感的增加有显著相关性。这些发现可以帮助设计信任worthy和个性化的机器人设计过程。
</details></li>
</ul>
<hr>
<h2 id="Laughing-Hyena-Distillery-Extracting-Compact-Recurrences-From-Convolutions"><a href="#Laughing-Hyena-Distillery-Extracting-Compact-Recurrences-From-Convolutions" class="headerlink" title="Laughing Hyena Distillery: Extracting Compact Recurrences From Convolutions"></a>Laughing Hyena Distillery: Extracting Compact Recurrences From Convolutions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18780">http://arxiv.org/abs/2310.18780</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefano Massaroli, Michael Poli, Daniel Y. Fu, Hermann Kumbong, Rom N. Parnichkun, Aman Timalsina, David W. Romero, Quinn McIntyre, Beidi Chen, Atri Rudra, Ce Zhang, Christopher Re, Stefano Ermon, Yoshua Bengio</li>
<li>for: 降低memory footprint和提高throughput during generation</li>
<li>methods: 使用 rational interpolation和model-order reduction techniques，以及Weight-tying filters across channels into heads</li>
<li>results: 实现了10倍于Transformers的throughput和1.5倍于Hyena的throughput，而且无损质量 послеdistillation<details>
<summary>Abstract</summary>
Recent advances in attention-free sequence models rely on convolutions as alternatives to the attention operator at the core of Transformers. In particular, long convolution sequence models have achieved state-of-the-art performance in many domains, but incur a significant cost during auto-regressive inference workloads -- naively requiring a full pass (or caching of activations) over the input sequence for each generated token -- similarly to attention-based models. In this paper, we seek to enable $\mathcal O(1)$ compute and memory cost per token in any pre-trained long convolution architecture to reduce memory footprint and increase throughput during generation. Concretely, our methods consist in extracting low-dimensional linear state-space models from each convolution layer, building upon rational interpolation and model-order reduction techniques. We further introduce architectural improvements to convolution-based layers such as Hyena: by weight-tying the filters across channels into heads, we achieve higher pre-training quality and reduce the number of filters to be distilled. The resulting model achieves 10x higher throughput than Transformers and 1.5x higher than Hyena at 1.3B parameters, without any loss in quality after distillation.
</details>
<details>
<summary>摘要</summary>
最近的进展在无注意力序列模型中使用核函数作为Transformer核心中的注意力运算符的替代方案。具体而言，长核函数序列模型在多个领域中 achieved state-of-the-art performance，但是在自动生成推干负载中具有重要的成本 - 需要遍历输入序列的全部通过或缓存活动的结果。在这篇论文中，我们寻求实现$\mathcal O(1)$的 compute和memory成本每个 токен，以降低快取面积和增加生成速度。具体来说，我们的方法是从每个核函数层提取低维度的线性状态空间模型，建立在理性插值和模型阶层技术之上。我们还引入了对于核函数层的建筑改进，例如Hyena：将核函数跨通道联结成头部，以提高预训品质和降低缩减策略中的缩减策略。实验结果显示，我们的模型可以与Transformer和Hyena相比，在1.3B个参数下实现10倍的生成速度，不会对品质造成损害。
</details></li>
</ul>
<hr>
<h2 id="Improving-Compositional-Generalization-Using-Iterated-Learning-and-Simplicial-Embeddings"><a href="#Improving-Compositional-Generalization-Using-Iterated-Learning-and-Simplicial-Embeddings" class="headerlink" title="Improving Compositional Generalization Using Iterated Learning and Simplicial Embeddings"></a>Improving Compositional Generalization Using Iterated Learning and Simplicial Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18777">http://arxiv.org/abs/2310.18777</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi Ren, Samuel Lavoie, Mikhail Galkin, Danica J. Sutherland, Aaron Courville</li>
<li>for: The paper aims to improve the compositional generalization of deep neural networks, which is the ability to generalize to unseen combinations of latent factors.</li>
<li>methods: The paper proposes using iterated learning on models with simplicial embeddings to improve compositional generalization. This approach is motivated by an analysis of compositionality based on Kolmogorov complexity.</li>
<li>results: The paper demonstrates improvements in compositional generalization over other approaches, using both vision tasks with well-understood latent factors and real molecular graph prediction tasks where the latent structure is unknown.<details>
<summary>Abstract</summary>
Compositional generalization, the ability of an agent to generalize to unseen combinations of latent factors, is easy for humans but hard for deep neural networks. A line of research in cognitive science has hypothesized a process, ``iterated learning,'' to help explain how human language developed this ability; the theory rests on simultaneous pressures towards compressibility (when an ignorant agent learns from an informed one) and expressivity (when it uses the representation for downstream tasks). Inspired by this process, we propose to improve the compositional generalization of deep networks by using iterated learning on models with simplicial embeddings, which can approximately discretize representations. This approach is further motivated by an analysis of compositionality based on Kolmogorov complexity. We show that this combination of changes improves compositional generalization over other approaches, demonstrating these improvements both on vision tasks with well-understood latent factors and on real molecular graph prediction tasks where the latent structure is unknown.
</details>
<details>
<summary>摘要</summary>
人类的 Compositional generalization，即对未经过视图的组合因素进行泛化，容易 для人类，但困难 для深度神经网络。认知科学中的一条研究提出了一个过程，即“迭代学习”，以解释人类语言的发展能力;该理论基于同时应对压缩性（ikor ignorant agent 从 informed one 学习）和表达性（ikor it 使用表示进行下游任务）的同时压力。 inspirited by this process, we propose to improve the compositional generalization of deep networks by using iterated learning on models with simplicial embeddings, which can approximately discretize representations. This approach is further motivated by an analysis of compositionality based on Kolmogorov complexity. We show that this combination of changes improves compositional generalization over other approaches, demonstrating these improvements both on vision tasks with well-understood latent factors and on real molecular graph prediction tasks where the latent structure is unknown.Note: Simplified Chinese is used in mainland China and Singapore, while Traditional Chinese is used in Taiwan, Hong Kong, and Macau. The translation is written in Simplified Chinese.
</details></li>
</ul>
<hr>
<h2 id="Linear-Mode-Connectivity-in-Sparse-Neural-Networks"><a href="#Linear-Mode-Connectivity-in-Sparse-Neural-Networks" class="headerlink" title="Linear Mode Connectivity in Sparse Neural Networks"></a>Linear Mode Connectivity in Sparse Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18769">http://arxiv.org/abs/2310.18769</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luke McDermott, Daniel Cummings</li>
<li>for: 这个论文研究了使用生成的数据进行神经网络减少，并研究了这些减少后的神经网络在真实数据上的训练特性。</li>
<li>methods: 该论文使用了迭代幅度减少（IMP）法，并使用了一种称为“液体减少”的方法来生成数据。</li>
<li>results: 研究发现，使用生成的数据和IMP法可以创建一类稀疏神经网络，这些神经网络在真实数据上训练时更加稳定，并且可以与传统IMP法相比，使用更少的训练点（最多150倍）达到相同的性能。<details>
<summary>Abstract</summary>
With the rise in interest of sparse neural networks, we study how neural network pruning with synthetic data leads to sparse networks with unique training properties. We find that distilled data, a synthetic summarization of the real data, paired with Iterative Magnitude Pruning (IMP) unveils a new class of sparse networks that are more stable to SGD noise on the real data, than either the dense model, or subnetworks found with real data in IMP. That is, synthetically chosen subnetworks often train to the same minima, or exhibit linear mode connectivity. We study this through linear interpolation, loss landscape visualizations, and measuring the diagonal of the hessian. While dataset distillation as a field is still young, we find that these properties lead to synthetic subnetworks matching the performance of traditional IMP with up to 150x less training points in settings where distilled data applies.
</details>
<details>
<summary>摘要</summary>
“因为神经网络束缚的兴趣增长，我们研究了使用 sintetic data 进行神经网络剪除的影响。我们发现，通过对真实数据进行概要汇总，并使用迭代大小剪除（IMP），可以找到一类特有的稀疏网络，它们在真实数据上更加稳定，SGD 噪音的影响下。即使使用真实数据进行 IMP，也不能达到这类网络的性能。我们通过线性 interpolate，损失地图可见化和对偏导数矩阵的评估来研究这一点。虽然数据概要为一个 relativity 新的领域，但我们发现这些特性使得使用 sintetic data 可以达到与传统 IMP 相同的性能，即使是使用 150 倍少的训练点。”
</details></li>
</ul>
<hr>
<h2 id="Reboost-Large-Language-Model-based-Text-to-SQL-Text-to-Python-and-Text-to-Function-–-with-Real-Applications-in-Traffic-Domain"><a href="#Reboost-Large-Language-Model-based-Text-to-SQL-Text-to-Python-and-Text-to-Function-–-with-Real-Applications-in-Traffic-Domain" class="headerlink" title="Reboost Large Language Model-based Text-to-SQL, Text-to-Python, and Text-to-Function – with Real Applications in Traffic Domain"></a>Reboost Large Language Model-based Text-to-SQL, Text-to-Python, and Text-to-Function – with Real Applications in Traffic Domain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18752">http://arxiv.org/abs/2310.18752</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guanghu Sui, Zhishuai Li, Ziyue Li, Sun Yang, Jingqing Ruan, Hangyu Mao, Rui Zhao</li>
<li>for: 提高文本到SQL执行精度</li>
<li>methods: 改进提问方法，包括查询重写和SQL增强</li>
<li>results: 实现了显著提高执行精度，使用较弱的预训练语言模型也达到了21.05%的最高精度Here’s the full translation of the abstract in Simplified Chinese:本文提出了一种更适应和更通用的提问方法，用于提高文本到SQL执行精度。我们发现了对于商业 dataset 的执行精度的显著下降，并且分析了 dataset 的复杂性和问题意图的不同所带来的影响。为了减少信息漏斗，我们将comments、值类型和值示例包含在数据库描述中。我们的实验表明，使用大型自然语言模型（LLMs）可以实现显著的性能提高。相比之下，state-of-the-art 方法在商业 dataset 上的执行精度为21.05%，而我们的方法在同一 dataset 上达到了65.79%。此外，我们还探讨了文本到Python和文本到函数等选项，并对其间的优缺点进行了深入分析，为社区提供了有价值的意见。<details>
<summary>Abstract</summary>
The previous state-of-the-art (SOTA) method achieved a remarkable execution accuracy on the Spider dataset, which is one of the largest and most diverse datasets in the Text-to-SQL domain. However, during our reproduction of the business dataset, we observed a significant drop in performance. We examined the differences in dataset complexity, as well as the clarity of questions' intentions, and assessed how those differences could impact the performance of prompting methods. Subsequently, We develop a more adaptable and more general prompting method, involving mainly query rewriting and SQL boosting, which respectively transform vague information into exact and precise information and enhance the SQL itself by incorporating execution feedback and the query results from the database content. In order to prevent information gaps, we include the comments, value types, and value samples for columns as part of the database description in the prompt. Our experiments with Large Language Models (LLMs) illustrate the significant performance improvement on the business dataset and prove the substantial potential of our method. In terms of execution accuracy on the business dataset, the SOTA method scored 21.05, while our approach scored 65.79. As a result, our approach achieved a notable performance improvement even when using a less capable pre-trained language model. Last but not least, we also explore the Text-to-Python and Text-to-Function options, and we deeply analyze the pros and cons among them, offering valuable insights to the community.
</details>
<details>
<summary>摘要</summary>
previous state-of-the-art (SOTA) 方法在 Spider 数据集上达到了杰出的执行精度，这是文本到 SQL 领域中最大和最多样的数据集之一。然而，在我们重现商业数据集时，我们注意到了显著的性能下降。我们分析了数据集的复杂性以及问题意图的清晰度，并评估了这些差异如何影响提示方法的性能。因此，我们开发了更适应和更通用的提示方法，包括主要的查询重写和 SQL 加强，将混淆信息转化为准确和精确信息，并通过 incorporating 执行反馈和数据库内容的查询结果来增强 SQL 本身。为了避免信息异常，我们将数据库描述中的注释、值类型和值示例包含在提示中。我们的实验表明，使用大型自然语言模型 (LLMs) 可以在商业数据集上实现显著性能提升，并证明了我们的方法的巨大潜力。在商业数据集上的执行精度方面，SOTA 方法得分 21.05，而我们的方法得分 65.79。因此，我们的方法在使用较弱预训练语言模型时 still 实现了显著的性能提升。最后，我们还探索了 Text-to-Python 和 Text-to-Function 选项，并进行了深入分析，提供了价值的发现。
</details></li>
</ul>
<hr>
<h2 id="On-Training-Implicit-Meta-Learning-With-Applications-to-Inductive-Weighing-in-Consistency-Regularization"><a href="#On-Training-Implicit-Meta-Learning-With-Applications-to-Inductive-Weighing-in-Consistency-Regularization" class="headerlink" title="On Training Implicit Meta-Learning With Applications to Inductive Weighing in Consistency Regularization"></a>On Training Implicit Meta-Learning With Applications to Inductive Weighing in Consistency Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18741">http://arxiv.org/abs/2310.18741</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fady Rezk</li>
<li>for: 这个论文的目的是比较不同的缺省方法在隐式微调学习中的计算成本、稳定性、泛化性和估计准确性。</li>
<li>methods: 这个论文使用了多种缺省方法，包括矩阵估计、均值场估计和积分估计等，并对它们进行了系统比较。</li>
<li>results: 研究发现，矩阵估计和均值场估计在缺省学习中具有较高的计算成本和稳定性，而积分估计具有较高的泛化性和估计准确性。此外，研究还提出了一种新的半监督学习算法，可以透过增强具有适应性的域特异特征来增强鲁棒性。该算法的实验结果超过了基eline FixMatch性能。<details>
<summary>Abstract</summary>
Meta-learning that uses implicit gradient have provided an exciting alternative to standard techniques which depend on the trajectory of the inner loop training. Implicit meta-learning (IML), however, require computing $2^{nd}$ order gradients, particularly the Hessian which is impractical to compute for modern deep learning models. Various approximations for the Hessian were proposed but a systematic comparison of their compute cost, stability, generalization of solution found and estimation accuracy were largely overlooked. In this study, we start by conducting a systematic comparative analysis of the various approximation methods and their effect when incorporated into IML training routines. We establish situations where catastrophic forgetting is exhibited in IML and explain their cause in terms of the inability of the approximations to estimate the curvature at convergence points. Sources of IML training instability are demonstrated and remedied. A detailed analysis of the effeciency of various inverse Hessian-vector product approximation methods is also provided. Subsequently, we use the insights gained to propose and evaluate a novel semi-supervised learning algorithm that learns to inductively weigh consistency regularization losses. We show how training a "Confidence Network" to extract domain specific features can learn to up-weigh useful images and down-weigh out-of-distribution samples. Results outperform the baseline FixMatch performance.
</details>
<details>
<summary>摘要</summary>
Meta-学习使用隐式梯度提供了一种有趣的代替标准技术，这些技术取决于内部循环训练的轨迹。然而，隐式 meta-学习（IML）需要计算第二个梯度，特别是希尔比格，这是现代深度学习模型中计算的不实际。Various approximations for the Hessian were proposed, but a systematic comparison of their compute cost, stability, generalization of solution found and estimation accuracy were largely overlooked.在这项研究中，我们开始了一个系统性的比较分析，检验不同的近似方法在IML训练流程中的效果。我们证明了IML训练中出现的 катастрофи忘记现象，并解释了其原因为近似方法无法在 converges 点 estimating 曲线的 curvature。我们还示出了IML训练的不稳定性的来源，并提供了修复方法。另外，我们还提供了一个细节的 inverse Hessian-vector product approximation 方法的效率分析。然后，我们使用获得的理解，提出和评估一种新的半监督学习算法，该算法可以学习 inductively 权重一致减少损失。我们表明了在训练 "信任网络" 来提取域pecific特征时，可以学习到升重用户图像和降低非标范图像。结果超出了基eline FixMatch性能。
</details></li>
</ul>
<hr>
<h2 id="Pre-training-with-Random-Orthogonal-Projection-Image-Modeling"><a href="#Pre-training-with-Random-Orthogonal-Projection-Image-Modeling" class="headerlink" title="Pre-training with Random Orthogonal Projection Image Modeling"></a>Pre-training with Random Orthogonal Projection Image Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18737">http://arxiv.org/abs/2310.18737</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maryam Haghighat, Peyman Moghadam, Shaheer Mohamed, Piotr Koniusz</li>
<li>for: The paper is written for proposing a new self-supervised learning framework called Random Orthogonal Projection Image Modeling (ROPIM) that can be used for visual pre-training without the need for labels.</li>
<li>methods: The paper uses a random orthogonal projection method to randomly mask entire spatial image areas with locally varying masking degrees, which encourages the network to capture and learn structural information about objects and scenes.</li>
<li>results: The paper shows that using random orthogonal projection leads to superior performance compared to crop-based masking, and demonstrates state-of-the-art results on several popular benchmarks.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了介绍一种新的自我超视learning框架，即Random Orthogonal Projection Image Modeling（ROPIM），用于无标签的视觉预训练。</li>
<li>methods: 这篇论文使用随机正交投影方法，随机将整个图像空间掩码，实现了地方性Masking的效果，从而让网络学习对象和场景的结构信息。</li>
<li>results: 这篇论文表明，使用随机正交投影比crop-based masking更高效，并在多个流行的标准测试集上达到了领先的性能。<details>
<summary>Abstract</summary>
Masked Image Modeling (MIM) is a powerful self-supervised strategy for visual pre-training without the use of labels. MIM applies random crops to input images, processes them with an encoder, and then recovers the masked inputs with a decoder, which encourages the network to capture and learn structural information about objects and scenes. The intermediate feature representations obtained from MIM are suitable for fine-tuning on downstream tasks. In this paper, we propose an Image Modeling framework based on random orthogonal projection instead of binary masking as in MIM. Our proposed Random Orthogonal Projection Image Modeling (ROPIM) reduces spatially-wise token information under guaranteed bound on the noise variance and can be considered as masking entire spatial image area under locally varying masking degrees. Since ROPIM uses a random subspace for the projection that realizes the masking step, the readily available complement of the subspace can be used during unmasking to promote recovery of removed information. In this paper, we show that using random orthogonal projection leads to superior performance compared to crop-based masking. We demonstrate state-of-the-art results on several popular benchmarks.
</details>
<details>
<summary>摘要</summary>
自适应学习 ohne 标签的视觉预训练策略：面罩图像模型（MIM）。MIM 使用随机剪辑对输入图像进行处理，然后使用解码器恢复受随机剪辑影响的输入图像，这使得网络学习和捕捉图像中的结构信息。MIM 生成的中间特征表示可以进行下游任务的细化。在这篇论文中，我们提出了基于随机正交投影的图像模型框架（ROPIM）。ROPIM 在空间上减少了Token信息，并且可以保证随机投影的噪声方差的下界。由于 ROPIM 使用随机子空间进行投影，因此可以使用该子空间的可用资源进行解压缩，以便恢复被移除的信息。在这篇论文中，我们证明了使用随机正交投影可以比随机剪辑更高效。我们在多个流行的 benchmark 上达到了状态机器的表现。
</details></li>
</ul>
<hr>
<h2 id="Using-Large-Language-Models-to-Support-Thematic-Analysis-in-Empirical-Legal-Studies"><a href="#Using-Large-Language-Models-to-Support-Thematic-Analysis-in-Empirical-Legal-Studies" class="headerlink" title="Using Large Language Models to Support Thematic Analysis in Empirical Legal Studies"></a>Using Large Language Models to Support Thematic Analysis in Empirical Legal Studies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18729">http://arxiv.org/abs/2310.18729</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jakub Drápal, Hannes Westermann, Jaromir Savelka</li>
<li>for: 本研究旨在探讨如何使用大语言模型（LLM）和法律专家合作进行逻辑分析，以便提高逻辑分析的效率和质量。</li>
<li>methods: 本研究使用了一种新的框架，即将LLM与法律专家合作进行逻辑分析的初始编码（阶段2）、主题搜索（阶段3）和数据分类（阶段4）。</li>
<li>results: 研究发现，使用LLM可以生成合理的初始编码，并且可以根据专家反馈进行改进。此外，模型还能够透过零例学习来将描述事实分类到主题类别中。最后，由LLM自动发现的主题与法律专家所找到的主题之间存在一定的相似性。这些发现可以帮助法律研究人员在启用LLM时作出更 Informed Decisions。<details>
<summary>Abstract</summary>
Thematic analysis and other variants of inductive coding are widely used qualitative analytic methods within empirical legal studies (ELS). We propose a novel framework facilitating effective collaboration of a legal expert with a large language model (LLM) for generating initial codes (phase 2 of thematic analysis), searching for themes (phase 3), and classifying the data in terms of the themes (to kick-start phase 4). We employed the framework for an analysis of a dataset (n=785) of facts descriptions from criminal court opinions regarding thefts. The goal of the analysis was to discover classes of typical thefts. Our results show that the LLM, namely OpenAI's GPT-4, generated reasonable initial codes, and it was capable of improving the quality of the codes based on expert feedback. They also suggest that the model performed well in zero-shot classification of facts descriptions in terms of the themes. Finally, the themes autonomously discovered by the LLM appear to map fairly well to the themes arrived at by legal experts. These findings can be leveraged by legal researchers to guide their decisions in integrating LLMs into their thematic analyses, as well as other inductive coding projects.
</details>
<details>
<summary>摘要</summary>
empirical legal studies (ELS)  widely used qualitative analytic methods, including thematic analysis and its variants. We propose a novel framework for effective collaboration between a legal expert and a large language model (LLM) in thematic analysis, including generating initial codes (phase 2), searching for themes (phase 3), and classifying the data in terms of themes (to kick-start phase 4). We applied the framework to a dataset (n=785) of fact descriptions from criminal court opinions on thefts, aiming to discover typical theft classes. Our results show that OpenAI's GPT-4, the LLM, generated reasonable initial codes and improved code quality based on expert feedback. Additionally, the model performed well in zero-shot classification of fact descriptions in terms of themes. The themes autonomously discovered by the LLM align well with the themes identified by legal experts, providing valuable insights for legal researchers integrating LLMs into their thematic analyses and other inductive coding projects.
</details></li>
</ul>
<hr>
<h2 id="The-Evolution-of-the-Interplay-Between-Input-Distributions-and-Linear-Regions-in-Networks"><a href="#The-Evolution-of-the-Interplay-Between-Input-Distributions-and-Linear-Regions-in-Networks" class="headerlink" title="The Evolution of the Interplay Between Input Distributions and Linear Regions in Networks"></a>The Evolution of the Interplay Between Input Distributions and Linear Regions in Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18725">http://arxiv.org/abs/2310.18725</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuan Qi, Yi Wei</li>
<li>for: 本研究旨在探讨深度神经网络的表达能力，具体来说是通过ReLU activation function来评估神经网络的表达能力。</li>
<li>methods: 本研究使用了 counted number of linear convex regions 来评估神经网络的表达能力。我们也提供了一种基于ReLU activation function的训练过程的分析。</li>
<li>results: 我们的研究发现，对于任意一个一维输入，存在一个最小阈值的神经元数量可以表达它。此外，我们还发现在训练过程中，ReLU网络的决策边界会经历反复细化过程。我们的研究希望能够激发网络优化的研究，并为深度神经网络的探索和分析提供启示。<details>
<summary>Abstract</summary>
It is commonly recognized that the expressiveness of deep neural networks is contingent upon a range of factors, encompassing their depth, width, and other relevant considerations. Currently, the practical performance of the majority of deep neural networks remains uncertain. For ReLU (Rectified Linear Unit) networks with piecewise linear activations, the number of linear convex regions serves as a natural metric to gauge the network's expressivity. In this paper, we count the number of linear convex regions in deep neural networks based on ReLU. In particular, we prove that for any one-dimensional input, there exists a minimum threshold for the number of neurons required to express it. We also empirically observe that for the same network, intricate inputs hinder its capacity to express linear regions. Furthermore, we unveil the iterative refinement process of decision boundaries in ReLU networks during training. We aspire for our research to serve as an inspiration for network optimization endeavors and aids in the exploration and analysis of the behaviors exhibited by deep networks.
</details>
<details>
<summary>摘要</summary>
通常认为深度神经网络的表达能力取决于各种因素，包括它们的深度、宽度和其他相关因素。目前，大多数深度神经网络的实际表现仍然不清楚。为ReLU（矩阵线性单元）网络，数量的凸 convex 区域作为一个自然的度量来衡量网络的表达能力。在这篇论文中，我们计算了深度神经网络中ReLU activation function的凸 convex 区域数量。特别是，我们证明了任何一维输入都存在一个最小阈值的神经元数量，可以表达它。此外，我们还观察到了在同一个网络中，复杂的输入会降低其表达线性区域的能力。此外，我们还揭示了ReLU网络在训练过程中的迭代精细化过程。我们希望通过这项研究，能够激发网络优化的努力，并且对深度网络的行为进行探索和分析。
</details></li>
</ul>
<hr>
<h2 id="WCLD-Curated-Large-Dataset-of-Criminal-Cases-from-Wisconsin-Circuit-Courts"><a href="#WCLD-Curated-Large-Dataset-of-Criminal-Cases-from-Wisconsin-Circuit-Courts" class="headerlink" title="WCLD: Curated Large Dataset of Criminal Cases from Wisconsin Circuit Courts"></a>WCLD: Curated Large Dataset of Criminal Cases from Wisconsin Circuit Courts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18724">http://arxiv.org/abs/2310.18724</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elliott Ash, Naman Goel, Nianyun Li, Claudia Marangon, Peiyao Sun</li>
<li>for: This paper provides a large dataset of criminal cases to support research on machine learning decision-support tools in criminal justice systems, with a focus on fairness and systemic issues.</li>
<li>methods: The dataset is constructed using reliable public data from 1970 to 2020, including information on prior criminal counts, recidivism outcomes, and various other attributes such as neighborhood characteristics, charge severity, and case decisions.</li>
<li>results: The dataset contains a large number of samples from five racial groups and provides researchers with a more comprehensive and rigorous platform for studying algorithmic fairness in the context of criminal justice.<details>
<summary>Abstract</summary>
Machine learning based decision-support tools in criminal justice systems are subjects of intense discussions and academic research. There are important open questions about the utility and fairness of such tools. Academic researchers often rely on a few small datasets that are not sufficient to empirically study various real-world aspects of these questions. In this paper, we contribute WCLD, a curated large dataset of 1.5 million criminal cases from circuit courts in the U.S. state of Wisconsin. We used reliable public data from 1970 to 2020 to curate attributes like prior criminal counts and recidivism outcomes. The dataset contains large number of samples from five racial groups, in addition to information like sex and age (at judgment and first offense). Other attributes in this dataset include neighborhood characteristics obtained from census data, detailed types of offense, charge severity, case decisions, sentence lengths, year of filing etc. We also provide pseudo-identifiers for judge, county and zipcode. The dataset will not only enable researchers to more rigorously study algorithmic fairness in the context of criminal justice, but also relate algorithmic challenges with various systemic issues. We also discuss in detail the process of constructing the dataset and provide a datasheet. The WCLD dataset is available at \url{https://clezdata.github.io/wcld/}.
</details>
<details>
<summary>摘要</summary>
机器学习基于决策支持工具在刑事司法系统中是激烈的讨论和学术研究的主题。有重要的开放问题，例如这些工具的有用性和公平性。学术研究人员 часто依靠一些小的数据集来实际研究各种现实世界方面的问题。在这篇论文中，我们贡献了WCLD，一个 curaated大型数据集，包含150万个刑事案件从美国威斯康星州的环境法院。我们使用可靠的公共数据从1970年到2020年来Curate属性，如前科犯罪记录和重犯率结果。这个数据集包含多个种族组，以及性别和年龄（审判时和首次犯罪时）的信息。其他属性包括从人口普查数据获取的社区特征、细致的犯罪类型、罪名严重程度、审判结果、刑罚长度、提交年份等。我们还提供了判官、郡和邮政编码的 Pseudo-标识符。这个数据集不仅允许研究人员更加严谨地研究刑事司法中的算法公平性，还可以将算法挑战与多种系统问题相关联。我们还在详细介绍了数据集构建过程，并提供了数据表单。WCLD数据集可以在 \url{https://clezdata.github.io/wcld/} 上下载。
</details></li>
</ul>
<hr>
<h2 id="Robust-Offline-Policy-Evaluation-and-Optimization-with-Heavy-Tailed-Rewards"><a href="#Robust-Offline-Policy-Evaluation-and-Optimization-with-Heavy-Tailed-Rewards" class="headerlink" title="Robust Offline Policy Evaluation and Optimization with Heavy-Tailed Rewards"></a>Robust Offline Policy Evaluation and Optimization with Heavy-Tailed Rewards</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18715">http://arxiv.org/abs/2310.18715</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jin Zhu, Runzhe Wan, Zhengling Qi, Shikai Luo, Chengchun Shi</li>
<li>for: 增强线上强化学习（RL）在重 tailed 奖励下的Robustness，这种情况在实际应用中很普遍。</li>
<li>methods: 我们提出了两种算法框架，ROAM和ROOM，用于稳定的 Off-policy Evaluation（OPE）和 Offline Policy Optimization（OPO）。我们的框架通过精心将 median-of-means 方法与线上RL结合，以便直观地估计值函数估计器的uncertainty。这不仅遵循 OPO 的原则，而且 также有效地处理重 tailed 奖励。</li>
<li>results: 我们的两种框架在对 logged 数据集展示 heavy-tailed 奖励分布时表现出色，与现有方法相比，有较高的性能。<details>
<summary>Abstract</summary>
This paper endeavors to augment the robustness of offline reinforcement learning (RL) in scenarios laden with heavy-tailed rewards, a prevalent circumstance in real-world applications. We propose two algorithmic frameworks, ROAM and ROOM, for robust off-policy evaluation (OPE) and offline policy optimization (OPO), respectively. Central to our frameworks is the strategic incorporation of the median-of-means method with offline RL, enabling straightforward uncertainty estimation for the value function estimator. This not only adheres to the principle of pessimism in OPO but also adeptly manages heavy-tailed rewards. Theoretical results and extensive experiments demonstrate that our two frameworks outperform existing methods on the logged dataset exhibits heavy-tailed reward distributions.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="An-Investigation-of-Darwiche-and-Pearl’s-Postulates-for-Iterated-Belief-Update"><a href="#An-Investigation-of-Darwiche-and-Pearl’s-Postulates-for-Iterated-Belief-Update" class="headerlink" title="An Investigation of Darwiche and Pearl’s Postulates for Iterated Belief Update"></a>An Investigation of Darwiche and Pearl’s Postulates for Iterated Belief Update</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18714">http://arxiv.org/abs/2310.18714</a></li>
<li>repo_url: None</li>
<li>paper_authors: Quanlong Guan, Tong Zhu, Liangda Fang, Junming Qiu, Zhao-Rong Lai, Weiqi Luo</li>
<li>For: This paper focuses on belief revision and update, two types of belief change, and how an agent can modify her beliefs in the presence of new information.* Methods: The paper uses the AGM and KM postulates to capture rational belief revision and update, respectively, but notes that these postulates are too permissive and can lead to unreasonable changes in the iteration.* Results: The paper presents a modification of the original KM postulates based on belief states, and migrates several well-known postulates for iterated belief revision to iterated belief update. The paper also provides exact semantic characterizations based on partial preorders for each of the proposed postulates, and analyzes the compatibility between the iterated postulates and the KM postulates for belief update.<details>
<summary>Abstract</summary>
Belief revision and update, two significant types of belief change, both focus on how an agent modify her beliefs in presence of new information. The most striking difference between them is that the former studies the change of beliefs in a static world while the latter concentrates on a dynamically-changing world. The famous AGM and KM postulates were proposed to capture rational belief revision and update, respectively. However, both of them are too permissive to exclude some unreasonable changes in the iteration. In response to this weakness, the DP postulates and its extensions for iterated belief revision were presented. Furthermore, Rodrigues integrated these postulates in belief update. Unfortunately, his approach does not meet the basic requirement of iterated belief update. This paper is intended to solve this problem of Rodrigues's approach. Firstly, we present a modification of the original KM postulates based on belief states. Subsequently, we migrate several well-known postulates for iterated belief revision to iterated belief update. Moreover, we provide the exact semantic characterizations based on partial preorders for each of the proposed postulates. Finally, we analyze the compatibility between the above iterated postulates and the KM postulates for belief update.
</details>
<details>
<summary>摘要</summary>
belief revision和更新两种重要的信念变化都关注于一个代理人在新信息存在下如何修改她的信念。两者最明显的差异在于前者研究在静止世界中的信念变化，而后者专注于动态变化的世界。著名的AGM和KM假设被提出来捕捉合理的信念修改和更新。然而，两者都过于允许一些不合理的修改在迭代中。为了解决这个弱点，DP假设和其扩展被提出来。此外，Rodrigues将这些假设 integrate到信念更新中。然而，他的方法并不满足基本的迭代信念更新要求。这篇论文的目的是解决Rodrigues的方法中的这个问题。首先，我们提出修改了原始KM假设的基于信念状态的修改。然后，我们将许多已知的迭代信念修改假设迁移到迭代信念更新中。此外，我们提供了每个提案的准确的语义特征化，基于partial orden для每个提案。最后，我们分析了以上迭代假设与KM假设之间的兼容性。
</details></li>
</ul>
<hr>
<h2 id="Probing-LLMs-for-Joint-Encoding-of-Linguistic-Categories"><a href="#Probing-LLMs-for-Joint-Encoding-of-Linguistic-Categories" class="headerlink" title="Probing LLMs for Joint Encoding of Linguistic Categories"></a>Probing LLMs for Joint Encoding of Linguistic Categories</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18696">http://arxiv.org/abs/2310.18696</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thesofakillers/infoshare">https://github.com/thesofakillers/infoshare</a></li>
<li>paper_authors: Giulio Starace, Konstantinos Papakostas, Rochelle Choenni, Apostolos Panagiotopoulos, Matteo Rosati, Alina Leidinger, Ekaterina Shutova</li>
<li>for: 这个论文旨在探讨大语言模型（LLM）中不同语言现象之间的编码方式，以及这些编码方式如何交互影响模型的表示。</li>
<li>methods: 作者提出了一种测试框架，用于检查 LLM 中不同语言现象之间的编码方式。他们在 syntax 领域进行了实验，并发现了在同一级别（相关的 parts-of-speech 类）和不同级别（parts-of-speech 类和相关的语法依赖关系）之间存在共同编码的证据。</li>
<li>results: 实验显示，在多语言 LLM 中，同样的 patterns 存在于不同语言中。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) exhibit impressive performance on a range of NLP tasks, due to the general-purpose linguistic knowledge acquired during pretraining. Existing model interpretability research (Tenney et al., 2019) suggests that a linguistic hierarchy emerges in the LLM layers, with lower layers better suited to solving syntactic tasks and higher layers employed for semantic processing. Yet, little is known about how encodings of different linguistic phenomena interact within the models and to what extent processing of linguistically-related categories relies on the same, shared model representations. In this paper, we propose a framework for testing the joint encoding of linguistic categories in LLMs. Focusing on syntax, we find evidence of joint encoding both at the same (related part-of-speech (POS) classes) and different (POS classes and related syntactic dependency relations) levels of linguistic hierarchy. Our cross-lingual experiments show that the same patterns hold across languages in multilingual LLMs.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在多种自然语言处理任务上表现出众，这是因为预训练期间获得的通用语言知识。现有的模型解释研究（Tenney等，2019）表明，LLM层次结构中的下层更适合解决语法任务，而上层则用于 semantics处理。然而，我们对 LLM 中不同语言现象编码的交互并不甚了解，以及这些编码如何在模型中互相协作。在这篇论文中，我们提出了测试 LLM 中语言类别之间的共同编码框架。我们将注重语法，发现在同一级别（相关的部分词类）和不同级别（部分词类和相关的语法关系）之间都有共同编码证据。我们的跨语言实验表明，这些模式在多语言 LLM 中也存在。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Behavior-Extraction-via-Random-Intent-Priors"><a href="#Unsupervised-Behavior-Extraction-via-Random-Intent-Priors" class="headerlink" title="Unsupervised Behavior Extraction via Random Intent Priors"></a>Unsupervised Behavior Extraction via Random Intent Priors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18687">http://arxiv.org/abs/2310.18687</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Hu, Yiqin Yang, Jianing Ye, Ziqing Mai, Chongjie Zhang</li>
<li>for: 提高offline reinforcement learning（RL）算法的效率和实用性，使其能够更好地利用奖励自由数据中的人类行为知识。</li>
<li>methods: 提出了一种无监督的方法UBER，通过不同的假奖分配给不同的代理人来提取多样化的行为集，并将其 reuse 为新任务学习的候选策略。</li>
<li>results: 经验和理论证明表明，使用随机神经网络生成的奖励函数可以提取多样化和有用的行为，一些甚至与专家相似。实验结果表明，UBER可以在多个 benchmark 上学习有效和多样的行为集，超过现有的基elines。<details>
<summary>Abstract</summary>
Reward-free data is abundant and contains rich prior knowledge of human behaviors, but it is not well exploited by offline reinforcement learning (RL) algorithms. In this paper, we propose UBER, an unsupervised approach to extract useful behaviors from offline reward-free datasets via diversified rewards. UBER assigns different pseudo-rewards sampled from a given prior distribution to different agents to extract a diverse set of behaviors, and reuse them as candidate policies to facilitate the learning of new tasks. Perhaps surprisingly, we show that rewards generated from random neural networks are sufficient to extract diverse and useful behaviors, some even close to expert ones. We provide both empirical and theoretical evidence to justify the use of random priors for the reward function. Experiments on multiple benchmarks showcase UBER's ability to learn effective and diverse behavior sets that enhance sample efficiency for online RL, outperforming existing baselines. By reducing reliance on human supervision, UBER broadens the applicability of RL to real-world scenarios with abundant reward-free data.
</details>
<details>
<summary>摘要</summary>
reward-free 数据够丰富，含有人类行为的丰富先验知识，但是现在的Offline reinforcement learning（RL）算法未能充分利用这些数据。在这篇论文中，我们提出了UBER，一种不带supervision的方法，通过多样化的奖励来提取用于新任务学习的有用行为集。我们尝试 assigning different pseudo-奖励，从给定的先验分布中随机生成的奖励，给不同的代理人，以提取多样化的行为集，并将其 reuse 作为新任务学习的候选策略。我们发现，由随机神经网络生成的奖励可以提取出高质量的多样化行为集，其中一些甚至可以与专家级别相比。我们提供了 both empirical 和理论证据，证明使用随机先验来奖励函数是有理由的。我们在多个 bench mark 上进行了实验，证明 UBER 能够学习有效和多样化的行为集，提高在线RL的样本效率，超过现有的基eline。通过减少人类监督，UBER 扩展了RL的应用范围，使其可以在实际情况下应用。
</details></li>
</ul>
<hr>
<h2 id="N-Critics-Self-Refinement-of-Large-Language-Models-with-Ensemble-of-Critics"><a href="#N-Critics-Self-Refinement-of-Large-Language-Models-with-Ensemble-of-Critics" class="headerlink" title="N-Critics: Self-Refinement of Large Language Models with Ensemble of Critics"></a>N-Critics: Self-Refinement of Large Language Models with Ensemble of Critics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18679">http://arxiv.org/abs/2310.18679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sajad Mousavi, Ricardo Luna Gutiérrez, Desik Rengarajan, Vineet Gundecha, Ashwin Ramesh Babu, Avisek Naug, Antonio Guillen, Soumyendu Sarkar</li>
<li>for: 提高 LLM 的可靠性和准确性， Mitigate 偏见和谎言</li>
<li>methods: 使用一个 ensemble of critics 和模型自身的反馈来修正模型输出， drawing inspiration from human self-reflection and input seeking behavior</li>
<li>results:  observe consistent performance improvements in reducing toxicity and correcting factual errors<details>
<summary>Abstract</summary>
We propose a self-correction mechanism for Large Language Models (LLMs) to mitigate issues such as toxicity and fact hallucination. This method involves refining model outputs through an ensemble of critics and the model's own feedback. Drawing inspiration from human behavior, we explore whether LLMs can emulate the self-correction process observed in humans who often engage in self-reflection and seek input from others to refine their understanding of complex topics. Our approach is model-agnostic and can be applied across various domains to enhance trustworthiness by addressing fairness, bias, and robustness concerns. We consistently observe performance improvements in LLMs for reducing toxicity and correcting factual errors.
</details>
<details>
<summary>摘要</summary>
我们提出了一种自修复机制，用于 mitigate Large Language Models（LLMs）中的问题，如恶意和谬误投入。这种方法通过一个ensemble of critics和模型自身的反馈来纠正模型输出。我们从人类行为中获得灵感，探讨 LLMS 是否可以模仿人类自我反思的自修复过程。我们的方法是无关模型的，可以在不同领域中应用，以提高可靠性，解决公平、偏见和Robustness 等问题。我们一致地观察到 LLMS 的性能提高，用于减少恶意和 corrected 错误。
</details></li>
</ul>
<hr>
<h2 id="GalliformeSpectra-A-Hen-Breed-Dataset"><a href="#GalliformeSpectra-A-Hen-Breed-Dataset" class="headerlink" title="GalliformeSpectra: A Hen Breed Dataset"></a>GalliformeSpectra: A Hen Breed Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.19830">http://arxiv.org/abs/2310.19830</a></li>
<li>repo_url: None</li>
<li>paper_authors: Galib Muhammad Shahriar Himel, Md Masudul Islam</li>
<li>for: 这个论文旨在提供一份包含十种不同鸡种的完整数据集，以捕捉每种鸡种的独特特征和特征。</li>
<li>methods: 该论文使用了一种多样化的数据收集方法，收集了1010个原始JPG图像，展示了各种鸡种的身体特征、毛皮模式和特有的特征。这些图像后来被标准化、缩放和转换为PNG格式以保持数据集的一致性。</li>
<li>results: 该数据集提供了一个多样化的资源，可以用于鸡类科学、遗传学和农业研究。这个数据集的潜在价值在于它可以帮助研究人员探索不同鸡种之间的一致性和遗传特征，从而支持鸡类种养、遗传研究和生物技术发展。<details>
<summary>Abstract</summary>
This article presents a comprehensive dataset featuring ten distinct hen breeds, sourced from various regions, capturing the unique characteristics and traits of each breed. The dataset encompasses Bielefeld, Blackorpington, Brahma, Buckeye, Fayoumi, Leghorn, Newhampshire, Plymouthrock, Sussex, and Turken breeds, offering a diverse representation of poultry commonly bred worldwide. A total of 1010 original JPG images were meticulously collected, showcasing the physical attributes, feather patterns, and distinctive features of each hen breed. These images were subsequently standardized, resized, and converted to PNG format for consistency within the dataset. The compilation, although unevenly distributed across the breeds, provides a rich resource, serving as a foundation for research and applications in poultry science, genetics, and agricultural studies. This dataset holds significant potential to contribute to various fields by enabling the exploration and analysis of unique characteristics and genetic traits across different hen breeds, thereby supporting advancements in poultry breeding, farming, and genetic research.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="FinBTech-Blockchain-Based-Video-and-Voice-Authentication-System-for-Enhanced-Security-in-Financial-Transactions-Utilizing-FaceNet512-and-Gaussian-Mixture-Models"><a href="#FinBTech-Blockchain-Based-Video-and-Voice-Authentication-System-for-Enhanced-Security-in-Financial-Transactions-Utilizing-FaceNet512-and-Gaussian-Mixture-Models" class="headerlink" title="FinBTech: Blockchain-Based Video and Voice Authentication System for Enhanced Security in Financial Transactions Utilizing FaceNet512 and Gaussian Mixture Models"></a>FinBTech: Blockchain-Based Video and Voice Authentication System for Enhanced Security in Financial Transactions Utilizing FaceNet512 and Gaussian Mixture Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18668">http://arxiv.org/abs/2310.18668</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prof N. Jeenath Laila, Dr G. Tamilpavai</li>
<li>for: 为了提高金融交易的安全性和可靠性</li>
<li>methods: 使用智能合约、区块链技术、FaceNet512 face recognition和GMM语音认证，实现视频和音频验证</li>
<li>results: 提供了一个无 precedent 的多因素生物 metric 验证系统，提高安全性至新高度<details>
<summary>Abstract</summary>
In the digital age, it is crucial to make sure that financial transactions are as secure and reliable as possible. This abstract offers a ground-breaking method that combines smart contracts, blockchain technology, FaceNet512 for improved face recognition, and Gaussian Mixture Models (GMM) for speech authentication to create a system for video and audio verification that is unmatched. Smart contracts and the immutable ledger of the blockchain are combined to offer a safe and open environment for financial transactions. FaceNet512 and GMM offer multi-factor biometric authentication simultaneously, enhancing security to new heights. By combining cutting-edge technology, this system offers a strong defense against identity theft and illegal access, establishing a new benchmark for safe financial transactions.
</details>
<details>
<summary>摘要</summary>
在数字时代，确保金融交易的安全和可靠性非常重要。这个报道提供了一种创新的方法， combinig智能合同、区块链技术、FaceNet512 для提高人脸识别和混合 Gaussian Mixture Models (GMM)  для语音验证，以创建一个无与伦比的视频和音频验证系统。智能合同和区块链的坚实记录结合，提供了一个安全和开放的金融交易环境。FaceNet512 和 GMM 同时提供多因素生物 metric 验证，提高安全性至新的高度。通过结合前沿技术，这个系统提供了一个强大的防止身份盗用和未经授权访问的防御，设立了新的安全金融交易标准。
</details></li>
</ul>
<hr>
<h2 id="From-Indeterminacy-to-Determinacy-Augmenting-Logical-Reasoning-Capabilities-with-Large-Language-Models"><a href="#From-Indeterminacy-to-Determinacy-Augmenting-Logical-Reasoning-Capabilities-with-Large-Language-Models" class="headerlink" title="From Indeterminacy to Determinacy: Augmenting Logical Reasoning Capabilities with Large Language Models"></a>From Indeterminacy to Determinacy: Augmenting Logical Reasoning Capabilities with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18659">http://arxiv.org/abs/2310.18659</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongda Sun, Weikai Xu, Wei Liu, Jian Luan, Bin Wang, Shuo Shang, Ji-Rong Wen, Rui Yan</li>
<li>for: 提高LLM的逻辑推理能力，以便更好地模仿人类逻辑思维。</li>
<li>methods: 提出了一种新的逻辑推理框架，即DetermLR，该框架将逻辑推理过程定义为一种从不确定前提开始，逐步增加确定前提，使结论变得更加明确的过程。DetermLR包括三个重要组成部分：1）前提识别：将前提分为两类：确定和不确定。这使LLM可以根据特定任务的复杂度选择适当的逻辑结构。2）前提优化和探索：利用量化度量评估每个前提的相关性，以便更好地决定探索哪些前提可能会带来新的发现。3）迭代过程和逻辑记忆：引入逻辑记忆模块，自动记录和提取可用的前提和逻辑路径，以保持历史逻辑细节，从而更好地优化前提优化和逻辑推理过程。</li>
<li>results: 对四个复杂的逻辑推理任务LogiQA、ProofWriter、FOLIO和LogicalDeduction进行了广泛的实验，结果表明，DetermLR与所有基线相比，在逻辑推理任务中表现出色，可以更好地完成逻辑推理任务，同时需要更少的访问状态。<details>
<summary>Abstract</summary>
Recent advances in LLMs have revolutionized the landscape of reasoning tasks. To enhance the capabilities of LLMs to emulate human reasoning, prior works focus on modeling reasoning steps using specific thought structures like chains, trees, or graphs. However, LLM-based reasoning continues to encounter three challenges: 1) Selecting appropriate reasoning structures for various tasks; 2) Exploiting known conditions sufficiently and efficiently to deduce new insights; 3) Considering the impact of historical reasoning experience. To address these challenges, we propose DetermLR, a novel reasoning framework that formulates the reasoning process as a transformational journey from indeterminate premises to determinate ones. This process is marked by the incremental accumulation of determinate premises, making the conclusion progressively closer to clarity. DetermLR includes three essential components: 1) Premise identification: We categorize premises into two distinct types: determinate and indeterminate. This empowers LLMs to customize reasoning structures to match the specific task complexities. 2) Premise prioritization and exploration: We leverage quantitative measurements to assess the relevance of each premise to the target, prioritizing more relevant premises for exploring new insights. 3) Iterative process with reasoning memory: We introduce a reasoning memory module to automate storage and extraction of available premises and reasoning paths, preserving historical reasoning details for more accurate premise prioritization. Comprehensive experimental results show that DetermLR outperforms all baselines on four challenging logical reasoning tasks: LogiQA, ProofWriter, FOLIO, and LogicalDeduction. DetermLR can achieve better reasoning performance while requiring fewer visited states, highlighting its superior efficiency and effectiveness in tackling logical reasoning tasks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Selecting appropriate reasoning structures for various tasks2. Exploiting known conditions sufficiently and efficiently to deduce new insights3. Considering the impact of historical reasoning experience.To address these challenges, we propose DetermLR, a novel reasoning framework that formulates the reasoning process as a transformational journey from indeterminate premises to determinate ones. This process is marked by the incremental accumulation of determinate premises, making the conclusion progressively closer to clarity. DetermLR includes three essential components: 1. Premise identification: We categorize premises into two distinct types: determinate and indeterminate. This empowers LLMs to customize reasoning structures to match the specific task complexities. 2. Premise prioritization and exploration: We leverage quantitative measurements to assess the relevance of each premise to the target, prioritizing more relevant premises for exploring new insights. 3. Iterative process with reasoning memory: We introduce a reasoning memory module to automate storage and extraction of available premises and reasoning paths, preserving historical reasoning details for more accurate premise prioritization.Comprehensive experimental results show that DetermLR outperforms all baselines on four challenging logical reasoning tasks: LogiQA, ProofWriter, FOLIO, and LogicalDeduction. DetermLR can achieve better reasoning performance while requiring fewer visited states, highlighting its superior efficiency and effectiveness in tackling logical reasoning tasks.</details></li>
</ol>
<hr>
<h2 id="EHRXQA-A-Multi-Modal-Question-Answering-Dataset-for-Electronic-Health-Records-with-Chest-X-ray-Images"><a href="#EHRXQA-A-Multi-Modal-Question-Answering-Dataset-for-Electronic-Health-Records-with-Chest-X-ray-Images" class="headerlink" title="EHRXQA: A Multi-Modal Question Answering Dataset for Electronic Health Records with Chest X-ray Images"></a>EHRXQA: A Multi-Modal Question Answering Dataset for Electronic Health Records with Chest X-ray Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18652">http://arxiv.org/abs/2310.18652</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/baeseongsu/ehrxqa">https://github.com/baeseongsu/ehrxqa</a></li>
<li>paper_authors: Seongsu Bae, Daeun Kyung, Jaehee Ryu, Eunbyeol Cho, Gyubok Lee, Sunjun Kweon, Jungwoo Oh, Lei Ji, Eric I-Chao Chang, Tackeun Kim, Edward Choi</li>
<li>For: 这个论文旨在开发一个基于电子医疗记录（EHR）的多模态问答集（EHRXQA），以推动现有EHR问答系统中多模态合理的推理。* Methods: 该论文使用了两个uni-modal资源：1）MIMIC-CXR-VQA数据集，我们新创建的医疗图像问答标准 benchmark，以增强imaging模式在EHR问答中的参与度；2）EHRSQL（MIMIC-IV），一个重新设计的表格基于EHR问答dataset。通过将这两个uni-modal资源集成，我们成功构建了一个多模态EHR问答集。* Results: 该论文提出了一种基于NeuralSQL的策略，其中包括一个外部VQA API，以解决多模态EHR问题中的独特挑战。这项创新的尝试可以提高对多模态EHR源的参与度，我们认为这个dataset可以促进现实世界的医疗应用，如临床决策和研究。<details>
<summary>Abstract</summary>
Electronic Health Records (EHRs), which contain patients' medical histories in various multi-modal formats, often overlook the potential for joint reasoning across imaging and table modalities underexplored in current EHR Question Answering (QA) systems. In this paper, we introduce EHRXQA, a novel multi-modal question answering dataset combining structured EHRs and chest X-ray images. To develop our dataset, we first construct two uni-modal resources: 1) The MIMIC- CXR-VQA dataset, our newly created medical visual question answering (VQA) benchmark, specifically designed to augment the imaging modality in EHR QA, and 2) EHRSQL (MIMIC-IV), a refashioned version of a previously established table-based EHR QA dataset. By integrating these two uni-modal resources, we successfully construct a multi-modal EHR QA dataset that necessitates both uni-modal and cross-modal reasoning. To address the unique challenges of multi-modal questions within EHRs, we propose a NeuralSQL-based strategy equipped with an external VQA API. This pioneering endeavor enhances engagement with multi-modal EHR sources and we believe that our dataset can catalyze advances in real-world medical scenarios such as clinical decision-making and research. EHRXQA is available at https://github.com/baeseongsu/ehrxqa.
</details>
<details>
<summary>摘要</summary>
电子健康记录（EHR），它们包含了患者的医疗历史记录在不同的多模态格式中，经常忽视了现有EHR问答系统中的跨模态合理化潜力。在这篇论文中，我们引入了EHRXQA，一个新的多模态问答数据集，结合了结构化的EHR和胸部X射影像。为了开发我们的数据集，我们首先构建了两个单模态资源：1）我们新创建的医疗图像问答数据集（MIMIC-CXR-VQA），用于增强EHR中的图像模态，并2）EHRSQL（MIMIC-IV），一个重新设计的表格基于EHR问答数据集。通过将这两个单模态资源集成起来，我们成功地构建了一个多模态EHR问答数据集，需要同时进行单模态和跨模态合理化。为了解决EHR中多模态问题中的特殊挑战，我们提出了基于NeuralSQL的策略，并配备了外部VQA API。我们认为这一努力可以提高对多模态EHR源的参与度，并且我们相信EHRXQA数据集可以促进实际医疗场景中的决策和研究。EHRXQA数据集可以在https://github.com/baeseongsu/ehrxqa上下载。
</details></li>
</ul>
<hr>
<h2 id="Sleep-Deprivation-in-the-Forward-Forward-Algorithm"><a href="#Sleep-Deprivation-in-the-Forward-Forward-Algorithm" class="headerlink" title="Sleep Deprivation in the Forward-Forward Algorithm"></a>Sleep Deprivation in the Forward-Forward Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18647">http://arxiv.org/abs/2310.18647</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mirceatlx/ff">https://github.com/mirceatlx/ff</a></li>
<li>paper_authors: Mircea-Tudor Lică, David Dinucu-Jianu</li>
<li>for: 本研究探讨了在睡眠Context中Forward-Forward算法的两个前向通道分离方法的生物学意义。</li>
<li>methods: 本研究使用了Forward-Forward算法进行学习，并通过调整睡眠和醒目阶段之间的差距来调整算法的学习能力。</li>
<li>results: 研究发现，睡眠阶段的差距影响了算法的学习能力，而负数据的存在可以减轻睡眠不足的影响。<details>
<summary>Abstract</summary>
This paper aims to explore the separation of the two forward passes in the Forward-Forward algorithm from a biological perspective in the context of sleep. We show the size of the gap between the sleep and awake phase influences the learning capabilities of the algorithm and highlight the importance of negative data in diminishing the devastating effects of sleep deprivation.
</details>
<details>
<summary>摘要</summary>
Note: "Forward-Forward algorithm" is not a real algorithm, it's a fictional one used for illustration purposes only.
</details></li>
</ul>
<hr>
<h2 id="Predicting-Agricultural-Commodities-Prices-with-Machine-Learning-A-Review-of-Current-Research"><a href="#Predicting-Agricultural-Commodities-Prices-with-Machine-Learning-A-Review-of-Current-Research" class="headerlink" title="Predicting Agricultural Commodities Prices with Machine Learning: A Review of Current Research"></a>Predicting Agricultural Commodities Prices with Machine Learning: A Review of Current Research</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18646">http://arxiv.org/abs/2310.18646</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nhat-Quang Tran, Anna Felipe, Thanh Nguyen Ngoc, Tom Huynh, Quang Tran, Arthur Tang, Thuy Nguyen</li>
<li>For: 这篇论文是关于机器学习算法在农业价格预测中的一种评论。* Methods: 论文详细介绍了各种机器学习算法在农业价格预测中的应用，包括支持向量机器、决策树、彩虹分解等。* Results: 论文认为，机器学习算法可以提高农业价格预测的准确性和实时性，同时可以适应不同的农业市场和环境。但是，论文也指出了这些算法的限制和挑战，例如数据质量和可用性的问题。<details>
<summary>Abstract</summary>
Agricultural price prediction is crucial for farmers, policymakers, and other stakeholders in the agricultural sector. However, it is a challenging task due to the complex and dynamic nature of agricultural markets. Machine learning algorithms have the potential to revolutionize agricultural price prediction by improving accuracy, real-time prediction, customization, and integration. This paper reviews recent research on machine learning algorithms for agricultural price prediction. We discuss the importance of agriculture in developing countries and the problems associated with crop price falls. We then identify the challenges of predicting agricultural prices and highlight how machine learning algorithms can support better prediction. Next, we present a comprehensive analysis of recent research, discussing the strengths and weaknesses of various machine learning techniques. We conclude that machine learning has the potential to revolutionize agricultural price prediction, but further research is essential to address the limitations and challenges associated with this approach.
</details>
<details>
<summary>摘要</summary>
农业价格预测对农民、政策制定者和农业领acker有着重要的意义。然而，由于农业市场的复杂和动态特点，这是一项具有挑战性的任务。机器学习算法有可能为农业价格预测带来革命性的改善，包括准确性、实时预测、定制化和 интеграción。本文 recensreview了最近的研究，探讨了机器学习算法在农业价格预测中的应用。我们讨论了发展国家农业的重要性以及作物价格下跌的问题，然后详细介绍了各种机器学习技术的挑战和局限性。我们 conclude that 机器学习有可能为农业价格预测带来革命性的改善，但进一步的研究是必要的，以解决这种方法的限制和挑战。
</details></li>
</ul>
<hr>
<h2 id="One-shot-Localization-and-Segmentation-of-Medical-Images-with-Foundation-Models"><a href="#One-shot-Localization-and-Segmentation-of-Medical-Images-with-Foundation-Models" class="headerlink" title="One-shot Localization and Segmentation of Medical Images with Foundation Models"></a>One-shot Localization and Segmentation of Medical Images with Foundation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18642">http://arxiv.org/abs/2310.18642</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deepa Anand, Gurunath Reddy M, Vanika Singhal, Dattesh D. Shanbhag, Shriram KS, Uday Patil, Chitresh Bhushan, Kavitha Manickam, Dawei Gui, Rakesh Mullick, Avinash Gopal, Parminder Bhatia, Taha Kass-Hout</li>
<li>for: 本研究使用自然图像预训练的视Transformers（ViT）和稳定扩散（SD）模型来解决医学图像对应问题。</li>
<li>methods: 研究使用多种预训练的ViT（DINO、DINOv2、SAM、CLIP）和SD模型，对医学图像进行解决对应问题。</li>
<li>results: 研究表明，使用自然图像预训练的ViT和SD模型可以在不同的医学图像模式（CT、MR、ultrasound）、多个解剖区域（脑、胸、 Abdomen、Extremities）和多种任务上达到良好的性能。此外，通过与模板图像进行对应，我们使用SAM模型进行单击分割，达到了单击分割的 dice range 62%-90%。我们的单击方法也超过了 reciently proposed few-shot segmentation方法 - UniverSeg（Dice range 47%-80%) 在大多数医学图像模式中的多个semantic segmentation任务中表现出色。<details>
<summary>Abstract</summary>
Recent advances in Vision Transformers (ViT) and Stable Diffusion (SD) models with their ability to capture rich semantic features of the image have been used for image correspondence tasks on natural images. In this paper, we examine the ability of a variety of pre-trained ViT (DINO, DINOv2, SAM, CLIP) and SD models, trained exclusively on natural images, for solving the correspondence problems on medical images. While many works have made a case for in-domain training, we show that the models trained on natural images can offer good performance on medical images across different modalities (CT,MR,Ultrasound) sourced from various manufacturers, over multiple anatomical regions (brain, thorax, abdomen, extremities), and on wide variety of tasks. Further, we leverage the correspondence with respect to a template image to prompt a Segment Anything (SAM) model to arrive at single shot segmentation, achieving dice range of 62%-90% across tasks, using just one image as reference. We also show that our single-shot method outperforms the recently proposed few-shot segmentation method - UniverSeg (Dice range 47%-80%) on most of the semantic segmentation tasks(six out of seven) across medical imaging modalities.
</details>
<details>
<summary>摘要</summary>
近期，人工智能领域内的视觉转换器（ViT）和稳定扩散（SD）模型在自然图像上表现出了捕捉图像 semantics的能力，这些模型在图像匹配任务中表现出色。在这篇论文中，我们研究了不同预训练的 ViT（DINO、DINOv2、SAM、CLIP）和 SD 模型，这些模型均在自然图像上进行封闭式训练，是否能够在医疗图像上解决匹配问题。虽然许多研究认为域内训练是关键，但我们发现这些模型在医疗图像上表现良好，包括不同的modalities（CT、MR、ultrasound），来自不同的制造商，以及多个解剖区域（大脑、胸部、腹部、四肢）。此外，我们利用模板图像的对应关系，使用 SAM 模型进行一步分割，实现了单步分割的 dice 范围为 62%-90%，使用只有一张图像作为参考。此外，我们的单步方法在多种医疗影像模式中的多个semantic segmentation任务中表现出色，超过了最近提出的几个shot segmentation方法（UniverSeg）的 dice 范围（47%-80%）。
</details></li>
</ul>
<hr>
<h2 id="Electrical-Impedance-Tomography-A-Fair-Comparative-Study-on-Deep-Learning-and-Analytic-based-Approaches"><a href="#Electrical-Impedance-Tomography-A-Fair-Comparative-Study-on-Deep-Learning-and-Analytic-based-Approaches" class="headerlink" title="Electrical Impedance Tomography: A Fair Comparative Study on Deep Learning and Analytic-based Approaches"></a>Electrical Impedance Tomography: A Fair Comparative Study on Deep Learning and Analytic-based Approaches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18636">http://arxiv.org/abs/2310.18636</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dericknganyu/eit_dataset_generation">https://github.com/dericknganyu/eit_dataset_generation</a></li>
<li>paper_authors: Derick Nganyu Tanyu, Jianfeng Ning, Andreas Hauptmann, Bangti Jin, Peter Maass</li>
<li>For: This paper focuses on the Electrical Impedance Tomography (EIT) inverse problem, which is the challenge of inferring the internal conductivity distribution of an object from measurements taken on its boundary. The paper explores techniques for solving this problem, particularly the interplay between deep learning-based strategies and classical analytic-based methods.* Methods: The paper examines four state-of-the-art deep learning algorithms for solving the EIT inverse problem, including their representational capabilities and strengths. In addition, two analytic-based methods are dissected for their limitations and strengths. The paper also employs various numerical experiments to evaluate the efficacy of these methods.* Results: The paper provides a nuanced understanding of the methods’ ability to capture essential features and delineate complex conductivity patterns. The incorporation of variable conductivity scenarios allows for exploring the robustness and adaptability of each method. The results demonstrate the potential of deep learning-based methods for solving the EIT inverse problem, particularly in the presence of complex conductivity patterns.<details>
<summary>Abstract</summary>
Electrical Impedance Tomography (EIT) is a powerful imaging technique with diverse applications, e.g., medical diagnosis, industrial monitoring, and environmental studies. The EIT inverse problem is about inferring the internal conductivity distribution of an object from measurements taken on its boundary. It is severely ill-posed, necessitating advanced computational methods for accurate image reconstructions. Recent years have witnessed significant progress, driven by innovations in analytic-based approaches and deep learning. This review explores techniques for solving the EIT inverse problem, focusing on the interplay between contemporary deep learning-based strategies and classical analytic-based methods. Four state-of-the-art deep learning algorithms are rigorously examined, harnessing the representational capabilities of deep neural networks to reconstruct intricate conductivity distributions. In parallel, two analytic-based methods, rooted in mathematical formulations and regularisation techniques, are dissected for their strengths and limitations. These methodologies are evaluated through various numerical experiments, encompassing diverse scenarios that reflect real-world complexities. A suite of performance metrics is employed to assess the efficacy of these methods. These metrics collectively provide a nuanced understanding of the methods' ability to capture essential features and delineate complex conductivity patterns. One novel feature of the study is the incorporation of variable conductivity scenarios, introducing a level of heterogeneity that mimics textured inclusions. This departure from uniform conductivity assumptions mimics realistic scenarios where tissues or materials exhibit spatially varying electrical properties. Exploring how each method responds to such variable conductivity scenarios opens avenues for understanding their robustness and adaptability.
</details>
<details>
<summary>摘要</summary>
电气阻抗成像技术（EIT）是一种 poderosa 的成像技术，广泛应用于医学诊断、工业监测和环境研究等领域。EIT逆问题是关于从物体边缘测量获得内部电导分布的问题，它是非常不稳定的，需要高级计算方法以实现准确的成像重建。过去几年，驱动了由创新的数学基础和深度学习的技术进步，这种技术的研究受到了广泛关注。本文探讨了解决EIT逆问题的方法，特别是将现代深度学习基础与传统的数学基础相结合的方法。本文选择了四种现代深度学习算法进行严格的分析和评估，利用深度神经网络的表达能力来重建复杂的电导分布。同时，本文还介绍了两种传统的数学基础方法，包括基于数学形式和正则化技术的方法，并评估了它们的优缺点。这些方法在多种数字实验中被评估，涵盖了实际中的复杂场景。为评估这些方法的效果，本文采用了多种效果指标，这些指标共同提供了对方法的准确性和复杂电导分布的能力的全面了解。本文的一个新特点是对不同电导性场景进行变量电导分布的研究，这种假设与实际中的细胞或材料表现相符。通过对每种方法的响应来评估它们的Robustness和适应性。
</details></li>
</ul>
<hr>
<h2 id="Setting-the-Trap-Capturing-and-Defeating-Backdoors-in-Pretrained-Language-Models-through-Honeypots"><a href="#Setting-the-Trap-Capturing-and-Defeating-Backdoors-in-Pretrained-Language-Models-through-Honeypots" class="headerlink" title="Setting the Trap: Capturing and Defeating Backdoors in Pretrained Language Models through Honeypots"></a>Setting the Trap: Capturing and Defeating Backdoors in Pretrained Language Models through Honeypots</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18633">http://arxiv.org/abs/2310.18633</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruixiang Tang, Jiayi Yuan, Yiming Li, Zirui Liu, Rui Chen, Xia Hu</li>
<li>for: 防止语言模型中的后门攻击</li>
<li>methods:  integrate a honeypot module into the original PLM, impose penalties on the information acquired by the honeypot module</li>
<li>results: 减少了10%~40%的攻击成功率，比前一代方法更有效和可靠<details>
<summary>Abstract</summary>
In the field of natural language processing, the prevalent approach involves fine-tuning pretrained language models (PLMs) using local samples. Recent research has exposed the susceptibility of PLMs to backdoor attacks, wherein the adversaries can embed malicious prediction behaviors by manipulating a few training samples. In this study, our objective is to develop a backdoor-resistant tuning procedure that yields a backdoor-free model, no matter whether the fine-tuning dataset contains poisoned samples. To this end, we propose and integrate a honeypot module into the original PLM, specifically designed to absorb backdoor information exclusively. Our design is motivated by the observation that lower-layer representations in PLMs carry sufficient backdoor features while carrying minimal information about the original tasks. Consequently, we can impose penalties on the information acquired by the honeypot module to inhibit backdoor creation during the fine-tuning process of the stem network. Comprehensive experiments conducted on benchmark datasets substantiate the effectiveness and robustness of our defensive strategy. Notably, these results indicate a substantial reduction in the attack success rate ranging from 10\% to 40\% when compared to prior state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
在自然语言处理领域，普遍的方法是细化预训练语言模型（PLM）使用本地样本。 recent research has exposed the vulnerability of PLMs to backdoor attacks, where adversaries can embed malicious prediction behaviors by manipulating a few training samples. In this study, our objective is to develop a backdoor-resistant tuning procedure that yields a backdoor-free model, regardless of whether the fine-tuning dataset contains poisoned samples. To this end, we propose and integrate a honeypot module into the original PLM, specifically designed to absorb backdoor information exclusively. Our design is motivated by the observation that lower-layer representations in PLMs carry sufficient backdoor features while carrying minimal information about the original tasks. Therefore, we can impose penalties on the information acquired by the honeypot module to inhibit backdoor creation during the fine-tuning process of the stem network. Comprehensive experiments conducted on benchmark datasets substantiate the effectiveness and robustness of our defensive strategy. Notably, these results indicate a substantial reduction in the attack success rate ranging from 10% to 40% when compared to prior state-of-the-art methods.
</details></li>
</ul>
<hr>
<h2 id="Benchmark-Generation-Framework-with-Customizable-Distortions-for-Image-Classifier-Robustness"><a href="#Benchmark-Generation-Framework-with-Customizable-Distortions-for-Image-Classifier-Robustness" class="headerlink" title="Benchmark Generation Framework with Customizable Distortions for Image Classifier Robustness"></a>Benchmark Generation Framework with Customizable Distortions for Image Classifier Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18626">http://arxiv.org/abs/2310.18626</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soumyendu Sarkar, Ashwin Ramesh Babu, Sajad Mousavi, Zachariah Carmichael, Vineet Gundecha, Sahand Ghorbanpour, Ricardo Luna, Gutierrez Antonio Guillen, Avisek Naug</li>
<li>for: 这个 paper 是为了提供一种生成攻击测试集的框架，以评估图像分类模型的可靠性。</li>
<li>methods: 这个框架使用了一种基于模型学习的强化学习算法，可以根据用户的需求选择合适的扰动种类，并生成多种扰动水平的测试集，以评估不同的图像分类模型的可靠性。</li>
<li>results: 这个框架可以生成高效和可转移的攻击样本，可以让不同的图像分类模型失败，包括 ResNet-50、Inception-V3 和 VGG-16 等模型。这些攻击样本可以在不受束缚的情况下生成，而不需要引入不自然的artifacts或颜色泄漏。<details>
<summary>Abstract</summary>
We present a novel framework for generating adversarial benchmarks to evaluate the robustness of image classification models. Our framework allows users to customize the types of distortions to be optimally applied to images, which helps address the specific distortions relevant to their deployment. The benchmark can generate datasets at various distortion levels to assess the robustness of different image classifiers. Our results show that the adversarial samples generated by our framework with any of the image classification models, like ResNet-50, Inception-V3, and VGG-16, are effective and transferable to other models causing them to fail. These failures happen even when these models are adversarially retrained using state-of-the-art techniques, demonstrating the generalizability of our adversarial samples. We achieve competitive performance in terms of net $L_2$ distortion compared to state-of-the-art benchmark techniques on CIFAR-10 and ImageNet; however, we demonstrate our framework achieves such results with simple distortions like Gaussian noise without introducing unnatural artifacts or color bleeds. This is made possible by a model-based reinforcement learning (RL) agent and a technique that reduces a deep tree search of the image for model sensitivity to perturbations, to a one-level analysis and action. The flexibility of choosing distortions and setting classification probability thresholds for multiple classes makes our framework suitable for algorithmic audits.
</details>
<details>
<summary>摘要</summary>
我团队提出了一种新的框架，用于生成对图像分类模型的Robustness进行评估。我们的框架允许用户自定义图像上应用的最佳噪声类型，以适应其特定的部署环境。这个框架可以生成各种噪声水平的数据集，以评估不同的图像分类器的Robustness。我们的结果显示，我们的框架生成的对图像分类模型的攻击样本，包括ResNet-50、Inception-V3和VGG-16等模型，都是有效的和可传递的。这些攻击样本会让这些模型失败，即使这些模型通过了最先进的防御技术进行适应。我们的框架在CIFAR-10和ImageNet上达到了与state-of-the-art的$L_2$损失相同的竞争性，但是我们的框架可以使用简单的噪声（如 Gaussian 噪声）而不需要引入不自然的artifacts或颜色泄漏。这是由一个基于模型的强化学习（RL） Agent和一种减少图像深度搜索的技术来实现的。我们的框架可以根据用户选择的噪声类型和多个类别的分类概率来进行自定义。这使得我们的框架适用于算法审核。
</details></li>
</ul>
<hr>
<h2 id="Arbitrarily-Scalable-Environment-Generators-via-Neural-Cellular-Automata"><a href="#Arbitrarily-Scalable-Environment-Generators-via-Neural-Cellular-Automata" class="headerlink" title="Arbitrarily Scalable Environment Generators via Neural Cellular Automata"></a>Arbitrarily Scalable Environment Generators via Neural Cellular Automata</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18622">http://arxiv.org/abs/2310.18622</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lunjohnzhang/warehouse_env_gen_nca_public">https://github.com/lunjohnzhang/warehouse_env_gen_nca_public</a></li>
<li>paper_authors: Yulun Zhang, Matthew C. Fontaine, Varun Bhatt, Stefanos Nikolaidis, Jiaoyang Li</li>
<li>for: 提高多机器人系统的吞吐量（improve the throughput of multi-robot systems）</li>
<li>methods: 使用质量多样性（Quality Diversity）算法优化环境生成器（Neural Cellular Automata environment generators）</li>
<li>results: 可以生成无限大的环境，并且维持环境中的准备规划（consistent, regularized patterns），提高多机器人系统的可扩展性和可靠性（improve the scalability and reliability of multi-robot systems）<details>
<summary>Abstract</summary>
We study the problem of generating arbitrarily large environments to improve the throughput of multi-robot systems. Prior work proposes Quality Diversity (QD) algorithms as an effective method for optimizing the environments of automated warehouses. However, these approaches optimize only relatively small environments, falling short when it comes to replicating real-world warehouse sizes. The challenge arises from the exponential increase in the search space as the environment size increases. Additionally, the previous methods have only been tested with up to 350 robots in simulations, while practical warehouses could host thousands of robots. In this paper, instead of optimizing environments, we propose to optimize Neural Cellular Automata (NCA) environment generators via QD algorithms. We train a collection of NCA generators with QD algorithms in small environments and then generate arbitrarily large environments from the generators at test time. We show that NCA environment generators maintain consistent, regularized patterns regardless of environment size, significantly enhancing the scalability of multi-robot systems in two different domains with up to 2,350 robots. Additionally, we demonstrate that our method scales a single-agent reinforcement learning policy to arbitrarily large environments with similar patterns. We include the source code at \url{https://github.com/lunjohnzhang/warehouse_env_gen_nca_public}.
</details>
<details>
<summary>摘要</summary>
我们研究多机器人系统中的环境生成问题，以提高其吞吐量。先前的方法提出了质量多样性（QD）算法来优化自动化仓储的环境，但这些方法仅能优化较小的环境，无法模拟现实世界仓储的规模。这问题的挑战在于搜索空间的对数增长，以及先前的方法仅在350台机器人的 simulations 中进行过测试。在这篇文章中，我们不是直接优化环境，而是透过 QD 算法来优化神经细胞自动机（NCA）环境生成器。我们在小型环境中训练了一个 NCA 环境生成器，然后在测试时使用这个生成器来生成任意大的环境。我们证明了 NCA 环境生成器在不同领域中能够维持一致的、规律的模式，很大地提高了多机器人系统的扩展性，并且还能将单机器人学习策略扩展到任意大的环境中。我们在这篇文章中还提供了源代码，可以在 \url{https://github.com/lunjohnzhang/warehouse_env_gen_nca_public} 中获取。
</details></li>
</ul>
<hr>
<h2 id="Dense-Retrieval-as-Indirect-Supervision-for-Large-space-Decision-Making"><a href="#Dense-Retrieval-as-Indirect-Supervision-for-Large-space-Decision-Making" class="headerlink" title="Dense Retrieval as Indirect Supervision for Large-space Decision Making"></a>Dense Retrieval as Indirect Supervision for Large-space Decision Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18619">http://arxiv.org/abs/2310.18619</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luka-group/ddr">https://github.com/luka-group/ddr</a></li>
<li>paper_authors: Nan Xu, Fei Wang, Mingtao Dong, Muhao Chen</li>
<li>for: 提高大量分类任务的准确率和泛化能力。</li>
<li>methods: 使用 dense retrieval 方法，将大量分类任务 reformulate 为学习 retrieve 任务，并使用 dual-encoder 架构来学习预测。</li>
<li>results: 在多个极端多类分类任务和少量数据情况下，DDR 可以大幅提高预测精度和泛化能力，至少比基eline 27.54%，F1 分数提高 1.17%，并在三个少量意图分类任务中平均提高了1.26%的准确率。<details>
<summary>Abstract</summary>
Many discriminative natural language understanding (NLU) tasks have large label spaces. Learning such a process of large-space decision making is particularly challenging due to the lack of training instances per label and the difficulty of selection among many fine-grained labels. Inspired by dense retrieval methods for passage finding in open-domain QA, we propose a reformulation of large-space discriminative NLU tasks as a learning-to-retrieve task, leading to a novel solution named Dense Decision Retrieval (DDR ). Instead of predicting fine-grained decisions as logits, DDR adopts a dual-encoder architecture that learns to predict by retrieving from a decision thesaurus. This approach not only leverages rich indirect supervision signals from easy-to-consume learning resources for dense retrieval, it also leads to enhanced prediction generalizability with a semantically meaningful representation of the large decision space. When evaluated on tasks with decision spaces ranging from hundreds to hundred-thousand scales, DDR outperforms strong baselines greatly by 27.54% in P@1 on two extreme multi-label classification tasks, 1.17% in F1 score ultra-fine entity typing, and 1.26% in accuracy on three few-shot intent classification tasks on average. Code and resources are available at https://github.com/luka-group/DDR
</details>
<details>
<summary>摘要</summary>
很多推理性自然语言理解（NLU）任务有很大的标签空间。学习这种大空间决策的过程特别是有很多标签的选择和训练实例的缺乏。 inspirited by dense retrieval方法用于在开放领域Question Answering中找到段落，我们提出了对大空间推理性NLU任务的重新表述，导致一种新的解决方案 называ为粘性决策检索（DDR）。而不是预测细化的决策，DDR采用了双核生成器体系，学习通过检索决策词典来预测。这种方法不仅利用了易于采用的学习资源的丰富间接监督信号，还导致了增强的预测泛化性和semantically meaningful的决策空间表示。当评估在标签空间范围从百到千千的任务上，DDR大幅超越了强基eline的表现，平均提高了27.54%的P@1、1.17%的F1分数和1.26%的准确率。代码和资源可以在https://github.com/luka-group/DDR上找到。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Mutual-Information-Analysis-Towards-Multi-view-Clustering-in-The-Wild"><a href="#Hierarchical-Mutual-Information-Analysis-Towards-Multi-view-Clustering-in-The-Wild" class="headerlink" title="Hierarchical Mutual Information Analysis: Towards Multi-view Clustering in The Wild"></a>Hierarchical Mutual Information Analysis: Towards Multi-view Clustering in The Wild</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18614">http://arxiv.org/abs/2310.18614</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiatai Wang, Zhiwei Xu, Xuewen Yang, Xin Wang</li>
<li>for: This paper focuses on addressing the challenges of missing and unaligned data in multi-view clustering, which is a common problem in practical computer vision applications.</li>
<li>methods: The proposed method uses a deep framework that combines data recovery and alignment in a hierarchically consistent way, leveraging dual prediction and contrastive reconstruction to achieve instance-level and class-level alignment.</li>
<li>results: The proposed method significantly outperforms state-of-the-art methods on multi-view clustering even in the cases of view missing and unalignment, as demonstrated by extensive experiments on public datasets.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文针对多视图 clustering 中缺失和不一致的数据问题进行解决，这是实际计算机视觉应用中的常见问题。</li>
<li>methods: 提议的方法使用深度框架，将数据恢复和对齐 fusion 在层次结构上进行一致性验证，通过 dual prediction 和对比重建来实现实例级别和类别级别的对齐。</li>
<li>results: 提议的方法在实际公共数据集上进行了广泛的实验，与现有方法进行比较，得到了显著的性能提升，即使在缺失和不一致的情况下也能够达到显著的效果。<details>
<summary>Abstract</summary>
Multi-view clustering (MVC) can explore common semantics from unsupervised views generated by different sources, and thus has been extensively used in applications of practical computer vision. Due to the spatio-temporal asynchronism, multi-view data often suffer from view missing and are unaligned in real-world applications, which makes it difficult to learn consistent representations. To address the above issues, this work proposes a deep MVC framework where data recovery and alignment are fused in a hierarchically consistent way to maximize the mutual information among different views and ensure the consistency of their latent spaces. More specifically, we first leverage dual prediction to fill in missing views while achieving the instance-level alignment, and then take the contrastive reconstruction to achieve the class-level alignment. To the best of our knowledge, this could be the first successful attempt to handle the missing and unaligned data problem separately with different learning paradigms. Extensive experiments on public datasets demonstrate that our method significantly outperforms state-of-the-art methods on multi-view clustering even in the cases of view missing and unalignment.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Embedding-in-Recommender-Systems-A-Survey"><a href="#Embedding-in-Recommender-Systems-A-Survey" class="headerlink" title="Embedding in Recommender Systems: A Survey"></a>Embedding in Recommender Systems: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18608">http://arxiv.org/abs/2310.18608</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangyu Zhao, Maolin Wang, Xinjian Zhao, Jiansheng Li, Shucheng Zhou, Dawei Yin, Qing Li, Jiliang Tang, Ruocheng Guo</li>
<li>for: 本文提供了一个概述近期 embedding 技术在推荐系统中的研究进展的survey。</li>
<li>methods: 本文覆盖了多种 embedding 方法，包括 collaborative filtering、自监学习和图基于的技术。</li>
<li>results: 本文提出了一些创新的方法来提高推荐系统的性能和计算复杂性，包括 AutoML、哈希技术和量化技术。<details>
<summary>Abstract</summary>
Recommender systems have become an essential component of many online platforms, providing personalized recommendations to users. A crucial aspect is embedding techniques that coverts the high-dimensional discrete features, such as user and item IDs, into low-dimensional continuous vectors and can enhance the recommendation performance. Applying embedding techniques captures complex entity relationships and has spurred substantial research. In this survey, we provide an overview of the recent literature on embedding techniques in recommender systems. This survey covers embedding methods like collaborative filtering, self-supervised learning, and graph-based techniques. Collaborative filtering generates embeddings capturing user-item preferences, excelling in sparse data. Self-supervised methods leverage contrastive or generative learning for various tasks. Graph-based techniques like node2vec exploit complex relationships in network-rich environments. Addressing the scalability challenges inherent to embedding methods, our survey delves into innovative directions within the field of recommendation systems. These directions aim to enhance performance and reduce computational complexity, paving the way for improved recommender systems. Among these innovative approaches, we will introduce Auto Machine Learning (AutoML), hash techniques, and quantization techniques in this survey. We discuss various architectures and techniques and highlight the challenges and future directions in these aspects. This survey aims to provide a comprehensive overview of the state-of-the-art in this rapidly evolving field and serve as a useful resource for researchers and practitioners working in the area of recommender systems.
</details>
<details>
<summary>摘要</summary>
现在许多在线平台上都有推荐系统，为用户提供个性化的推荐。一个重要的方面是嵌入技术，将用户和 Item ID 等高维离散特征转换成低维连续向量，以提高推荐性能。采用嵌入技术可以捕捉复杂的实体关系，并促进了大量研究。在这篇报告中，我们提供了现代推荐系统中嵌入技术的最新Literature综述。这篇报告覆盖了协同练习、自然学习和图像基本技术等嵌入方法。协同练习生成 embeddings，捕捉用户和 Item 的偏好，在缺乏数据时表现出色。自然学习使用对比或生成学习来实现多种任务。图像基本技术如 node2vec 利用网络中的复杂关系。为了解决嵌入方法中的扩展性问题，我们在推荐系统领域内进行了创新的方向，以提高性能并降低计算复杂性，为未来的推荐系统铺平道路。这些创新方向包括自动机器学习（AutoML）、哈希技术和量化技术。我们讨论了不同的架构和技术，并高亮了这些方面中的挑战和未来方向。该报告的目的是为研究人员和实践者提供一份现代化的推荐系统领域的 estado-da-arte 资源，以便他们在这一领域进行更好的研究和实践。
</details></li>
</ul>
<hr>
<h2 id="MILDSum-A-Novel-Benchmark-Dataset-for-Multilingual-Summarization-of-Indian-Legal-Case-Judgments"><a href="#MILDSum-A-Novel-Benchmark-Dataset-for-Multilingual-Summarization-of-Indian-Legal-Case-Judgments" class="headerlink" title="MILDSum: A Novel Benchmark Dataset for Multilingual Summarization of Indian Legal Case Judgments"></a>MILDSum: A Novel Benchmark Dataset for Multilingual Summarization of Indian Legal Case Judgments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18600">http://arxiv.org/abs/2310.18600</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/law-ai/mildsum">https://github.com/law-ai/mildsum</a></li>
<li>paper_authors: Debtanu Datta, Shubham Soni, Rajdeep Mukherjee, Saptarshi Ghosh</li>
<li>for: 本研究旨在提供英文法律文件的跨语言概要，以便在印度的法律系统中提供更加公平的 justice。</li>
<li>methods: 该研究使用了多种多样的概要方法，以评估其在法律领域的性能。</li>
<li>results: 研究发现，跨语言概要在法律领域的应用仍然需要进一步的研究，以提高概要的准确性和可读性。<details>
<summary>Abstract</summary>
Automatic summarization of legal case judgments is a practically important problem that has attracted substantial research efforts in many countries. In the context of the Indian judiciary, there is an additional complexity -- Indian legal case judgments are mostly written in complex English, but a significant portion of India's population lacks command of the English language. Hence, it is crucial to summarize the legal documents in Indian languages to ensure equitable access to justice. While prior research primarily focuses on summarizing legal case judgments in their source languages, this study presents a pioneering effort toward cross-lingual summarization of English legal documents into Hindi, the most frequently spoken Indian language. We construct the first high-quality legal corpus comprising of 3,122 case judgments from prominent Indian courts in English, along with their summaries in both English and Hindi, drafted by legal practitioners. We benchmark the performance of several diverse summarization approaches on our corpus and demonstrate the need for further research in cross-lingual summarization in the legal domain.
</details>
<details>
<summary>摘要</summary>
自动摘要法律案例判决是一个实际重要的问题，在多个国家的研究中都获得了substantial的投入。在印度法院的背景下，有一个额外的复杂性---印度的法律案例判决大多是用复杂的英语写成，但印度大部分人口不会英语。因此，实际需要摘要法律文件的印地语言，以确保公平的法律服务。在先前的研究中，主要对源语言进行摘要，但这项研究则对英文法律文件进行标准化，并将其摘要为印地语言。我们建立了首个高品质的法律档案，包括3,122个案例判决由印度主要法院提供，以及其摘要在英语和印地语言中，由法律专业人员撰写。我们在我们的档案上评估了多种多元摘要方法的表现，并证明了在法律领域中的标准化摘要仍然需要进一步的研究。
</details></li>
</ul>
<hr>
<h2 id="Using-Early-Readouts-to-Mediate-Featural-Bias-in-Distillation"><a href="#Using-Early-Readouts-to-Mediate-Featural-Bias-in-Distillation" class="headerlink" title="Using Early Readouts to Mediate Featural Bias in Distillation"></a>Using Early Readouts to Mediate Featural Bias in Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18590">http://arxiv.org/abs/2310.18590</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rishabh Tiwari, Durga Sivasubramanian, Anmol Mekala, Ganesh Ramakrishnan, Pradeep Shenoy</li>
<li>for: 本研究旨在改进在真实世界的超级vised学习任务中深度网络学习的潜在损害，特别是在托管学习中，学生模型可能比对应教师模型更具有较低的表达能力。</li>
<li>methods: 我们提出了一种新的早期读取机制，通过使用早期网络层的表示来预测标签。我们发现这些早期读outs自动地标识了问题实例或组，具体来说是具有高度信任但 incorrect 预测的情况。</li>
<li>results: 我们显示了这种早期读outs可以自动地为实例层次提供较好的预测信号，可以用于修改分配损害loss的学习过程中。我们在多个benchmark数据集上显示了提高group fairness度量和学生模型的总准确率。此外，我们还提供了次要分析，以帮助理解超级vised学习中特征学习的角色。<details>
<summary>Abstract</summary>
Deep networks tend to learn spurious feature-label correlations in real-world supervised learning tasks. This vulnerability is aggravated in distillation, where a student model may have lesser representational capacity than the corresponding teacher model. Often, knowledge of specific spurious correlations is used to reweight instances & rebalance the learning process. We propose a novel early readout mechanism whereby we attempt to predict the label using representations from earlier network layers. We show that these early readouts automatically identify problem instances or groups in the form of confident, incorrect predictions. Leveraging these signals to modulate the distillation loss on an instance level allows us to substantially improve not only group fairness measures across benchmark datasets, but also overall accuracy of the student model. We also provide secondary analyses that bring insight into the role of feature learning in supervision and distillation.
</details>
<details>
<summary>摘要</summary>
深度网络通常在实际supervised learning任务中学习假的特征-标签相关性。这种漏洞在精神投射中更加加剧，因为学生模型可能比对应的教师模型有更差的表达能力。经常使用特定假相关性的知识来重新权衡实例和重新调整学习过程。我们提出了一种新的早期读取机制，尝试使用早期网络层的表示来预测标签。我们发现这些早期读outs自然地标识问题实例或组，即高信息准确预测。利用这些信号来修改分配损失的实例级别可以大幅提高 benchmark数据集上的组准则性和学生模型的总准确率。我们还提供了次要分析，探讨特征学习在监督和精神投射中的角色。
</details></li>
</ul>
<hr>
<h2 id="Visual-Explanations-via-Iterated-Integrated-Attributions"><a href="#Visual-Explanations-via-Iterated-Integrated-Attributions" class="headerlink" title="Visual Explanations via Iterated Integrated Attributions"></a>Visual Explanations via Iterated Integrated Attributions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18585">http://arxiv.org/abs/2310.18585</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oren Barkan, Yehonatan Elisha, Yuval Asher, Amit Eshel, Noam Koenigstein</li>
<li>for: 这篇论文用于解释视觉模型的预测结果。</li>
<li>methods: 该论文使用迭代 интеGRATED ATTRIBUTES（IIA）方法，通过迭代 интеGRATE 输入图像、模型内部表示和导数，生成准确和专注的解释地图。</li>
<li>results: 论文的实验结果表明，IIA方法可以准确地解释视觉模型的预测结果，并且在不同任务、数据集和网络架构上表现出色，超过了其他当前领先的解释技术。<details>
<summary>Abstract</summary>
We introduce Iterated Integrated Attributions (IIA) - a generic method for explaining the predictions of vision models. IIA employs iterative integration across the input image, the internal representations generated by the model, and their gradients, yielding precise and focused explanation maps. We demonstrate the effectiveness of IIA through comprehensive evaluations across various tasks, datasets, and network architectures. Our results showcase that IIA produces accurate explanation maps, outperforming other state-of-the-art explanation techniques.
</details>
<details>
<summary>摘要</summary>
我们介绍Iterated Integrated Attributions（IIA），一种通用的视觉模型预测解释方法。IIA通过迭代 интеграpection 输入图像、模型内部表示和其导数，生成精细和专注的解释地图。我们通过多种任务、数据集和网络架构的全面评估，证明IIA可以生成准确的解释地图，超越其他当前领域的解释技术。
</details></li>
</ul>
<hr>
<h2 id="Breaking-the-Trilemma-of-Privacy-Utility-Efficiency-via-Controllable-Machine-Unlearning"><a href="#Breaking-the-Trilemma-of-Privacy-Utility-Efficiency-via-Controllable-Machine-Unlearning" class="headerlink" title="Breaking the Trilemma of Privacy, Utility, Efficiency via Controllable Machine Unlearning"></a>Breaking the Trilemma of Privacy, Utility, Efficiency via Controllable Machine Unlearning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18574">http://arxiv.org/abs/2310.18574</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/guangyaodou/conmu">https://github.com/guangyaodou/conmu</a></li>
<li>paper_authors: Zheyuan Liu, Guangyao Dou, Yijun Tian, Chunhui Zhang, Eli Chien, Ziwei Zhu</li>
<li>for: 这篇论文的主要目标是解决机器学习模型中的数据隐私问题，具体来说是通过控制 Privacy-Utility-Efficiency 三方面的质量来实现机器学习模型的卸载。</li>
<li>methods: 这篇论文提出了一种名为 Controllable Machine Unlearning（ConMU）的新框架，该框架包括三个基本模块：重要数据选择模块、进程 Gaussian 机制模块和卸载代理模块。这些模块协同实现了控制 Privacy-Utility-Efficiency 三方面的质量。</li>
<li>results: 对于各种标准数据集的实验表明，ConMU 控制机制具有优于现有卸载方法的灵活性和可控性，并且可以充分考虑不同的实际隐私法规。<details>
<summary>Abstract</summary>
Machine Unlearning (MU) algorithms have become increasingly critical due to the imperative adherence to data privacy regulations. The primary objective of MU is to erase the influence of specific data samples on a given model without the need to retrain it from scratch. Accordingly, existing methods focus on maximizing user privacy protection. However, there are different degrees of privacy regulations for each real-world web-based application. Exploring the full spectrum of trade-offs between privacy, model utility, and runtime efficiency is critical for practical unlearning scenarios. Furthermore, designing the MU algorithm with simple control of the aforementioned trade-off is desirable but challenging due to the inherent complex interaction. To address the challenges, we present Controllable Machine Unlearning (ConMU), a novel framework designed to facilitate the calibration of MU. The ConMU framework contains three integral modules: an important data selection module that reconciles the runtime efficiency and model generalization, a progressive Gaussian mechanism module that balances privacy and model generalization, and an unlearning proxy that controls the trade-offs between privacy and runtime efficiency. Comprehensive experiments on various benchmark datasets have demonstrated the robust adaptability of our control mechanism and its superiority over established unlearning methods. ConMU explores the full spectrum of the Privacy-Utility-Efficiency trade-off and allows practitioners to account for different real-world regulations. Source code available at: https://github.com/guangyaodou/ConMU.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-General-Framework-for-Robust-G-Invariance-in-G-Equivariant-Networks"><a href="#A-General-Framework-for-Robust-G-Invariance-in-G-Equivariant-Networks" class="headerlink" title="A General Framework for Robust G-Invariance in G-Equivariant Networks"></a>A General Framework for Robust G-Invariance in G-Equivariant Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18564">http://arxiv.org/abs/2310.18564</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gtc-invariance/gtc-invariance">https://github.com/gtc-invariance/gtc-invariance</a></li>
<li>paper_authors: Sophia Sanborn, Nina Miolane</li>
<li>For: The paper proposes a method for achieving robust group-invariance in group-equivariant convolutional neural networks (G-CNNs) called the G-triple-correlation (G-TC) layer.* Methods: The G-TC layer leverages the theory of the triple-correlation on groups, which is a unique, lowest-degree polynomial invariant map that is also complete.* Results: The G-TC layer yields measurable improvements in classification accuracy over standard Max G-Pooling in G-CNN architectures, and is resistant to invariance-based adversarial attacks. The method is demonstrated on several groups acting on both $\mathbb{R}^2$ and $\mathbb{R}^3$ on the G-MNIST and G-ModelNet10 datasets.Here is the same information in Simplified Chinese text:* For: 本文提出了一种方法来实现robust group-invariance在群equivariant convolutional neural networks（G-CNNs）中，称为G-triple-correlation（G-TC）层。* Methods: G-TC层利用群中的 triple-correlation理论，这是一个唯一的、最低度的多项式恒等函数，同时也是完整的。* Results: G-TC层在G-CNN架构中提供了较好的分类精度，并且对 invariant-based adversarial attacks具有强大的Robustness。此方法在几个群中对 $\mathbb{R}^2$ 和 $\mathbb{R}^3$ 上的 G-MNIST 和 G-ModelNet10 数据集进行了证明。<details>
<summary>Abstract</summary>
We introduce a general method for achieving robust group-invariance in group-equivariant convolutional neural networks ($G$-CNNs), which we call the $G$-triple-correlation ($G$-TC) layer. The approach leverages the theory of the triple-correlation on groups, which is the unique, lowest-degree polynomial invariant map that is also complete. Many commonly used invariant maps - such as the max - are incomplete: they remove both group and signal structure. A complete invariant, by contrast, removes only the variation due to the actions of the group, while preserving all information about the structure of the signal. The completeness of the triple correlation endows the $G$-TC layer with strong robustness, which can be observed in its resistance to invariance-based adversarial attacks. In addition, we observe that it yields measurable improvements in classification accuracy over standard Max $G$-Pooling in $G$-CNN architectures. We provide a general and efficient implementation of the method for any discretized group, which requires only a table defining the group's product structure. We demonstrate the benefits of this method for $G$-CNNs defined on both commutative and non-commutative groups - $SO(2)$, $O(2)$, $SO(3)$, and $O(3)$ (discretized as the cyclic $C8$, dihedral $D16$, chiral octahedral $O$ and full octahedral $O_h$ groups) - acting on $\mathbb{R}^2$ and $\mathbb{R}^3$ on both $G$-MNIST and $G$-ModelNet10 datasets.
</details>
<details>
<summary>摘要</summary>
我们介绍了一个通用的方法，可以在群equivariant convolutional neural networks（$G$-CNNs）中实现强健的群对称性，我们称之为$G$-三重相关（$G$-TC）层。这种方法利用群论中的三重相関，这是唯一的、最低阶的多项式群对称函数，同时也是完备的。许多常用的对称函数，如最大值，都是不完备的：它们会消除群和信号结构中的一部分。一个完备的对称函数，则会消除群的行动所导致的变化，保留信号的结构信息。三重相关的完备性使得$G$-TC层具有强大的免疫力，可以通过观察它对抗对称基于的攻击而证明。此外，我们发现这种方法可以提高$G$-CNN的分类精度，比标准的最大值$G$-Pooling更好。我们提供了一个通用且有效的实现方法，这需要一个表格定义了群的产生结构。我们在$G$-CNNs中使用了不同的域群，包括$SO(2)$, $O(2)$, $SO(3)$,和$O(3)$（为数为顺序$C8$, $D16$, $O$和$O_h$群），并在$\mathbb{R}^2$和$\mathbb{R}^3$上进行了$G$-MNIST和$G$-ModelNet10数据集上的实验。
</details></li>
</ul>
<hr>
<h2 id="Optimization-Free-Test-Time-Adaptation-for-Cross-Person-Activity-Recognition"><a href="#Optimization-Free-Test-Time-Adaptation-for-Cross-Person-Activity-Recognition" class="headerlink" title="Optimization-Free Test-Time Adaptation for Cross-Person Activity Recognition"></a>Optimization-Free Test-Time Adaptation for Cross-Person Activity Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18562">http://arxiv.org/abs/2310.18562</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Claydon-Wang/OFTTA">https://github.com/Claydon-Wang/OFTTA</a></li>
<li>paper_authors: Shuoyuan Wang, Jindong Wang, HuaJun Xi, Bob Zhang, Lei Zhang, Hongxin Wei</li>
<li>for: 这个论文主要针对的是人体动作识别（HAR）模型在实际应用中的性能降低问题，以及如何通过测试流式进行时间适应（TTA）来解决这个问题。</li>
<li>methods: 这篇论文提出了一种不需要优化的测试时适应（OFTTA）框架，用于抗预测域变化和实时适应。OFTTA使用了快速的测试时批处理（EDTN）来取代批处理（CBN）层，并对分类器进行了距离计算和支持集维护。</li>
<li>results: 对于三个公共的人体动作识别（HAR）数据集和两种不同的TTA设置，实验结果表明，OFTTA可以与现有的TTA方法进行比较，在分类性能和计算效率两个方面均有优异表现。此外，我们还验证了OFTTA在边缘设备上的可行性，表明可能的部署在实际应用中。<details>
<summary>Abstract</summary>
Human Activity Recognition (HAR) models often suffer from performance degradation in real-world applications due to distribution shifts in activity patterns across individuals. Test-Time Adaptation (TTA) is an emerging learning paradigm that aims to utilize the test stream to adjust predictions in real-time inference, which has not been explored in HAR before. However, the high computational cost of optimization-based TTA algorithms makes it intractable to run on resource-constrained edge devices. In this paper, we propose an Optimization-Free Test-Time Adaptation (OFTTA) framework for sensor-based HAR. OFTTA adjusts the feature extractor and linear classifier simultaneously in an optimization-free manner. For the feature extractor, we propose Exponential DecayTest-time Normalization (EDTN) to replace the conventional batch normalization (CBN) layers. EDTN combines CBN and Test-time batch Normalization (TBN) to extract reliable features against domain shifts with TBN's influence decreasing exponentially in deeper layers. For the classifier, we adjust the prediction by computing the distance between the feature and the prototype, which is calculated by a maintained support set. In addition, the update of the support set is based on the pseudo label, which can benefit from reliable features extracted by EDTN. Extensive experiments on three public cross-person HAR datasets and two different TTA settings demonstrate that OFTTA outperforms the state-of-the-art TTA approaches in both classification performance and computational efficiency. Finally, we verify the superiority of our proposed OFTTA on edge devices, indicating possible deployment in real applications. Our code is available at \href{https://github.com/Claydon-Wang/OFTTA}{this https URL}.
</details>
<details>
<summary>摘要</summary>
人体活动识别（HAR）模型经常在实际应用中受到分布偏移的影响，导致性能下降。测试时适应（TTA）是一种新趋势的学习方法，它在实时推断中使用测试流来调整预测，在HAR中尚未得到探索。然而，优化基本的TTA算法的计算成本过高，使其无法在有限的边缘设备上进行实时推断。在这篇论文中，我们提出了一种不需要优化的测试时适应（OFTTA）框架，用于感知器基本HAR。OFTTA同时调整特征提取器和线性分类器。特征提取器方面，我们提出了对域偏移的 exponential decay test-time normalization（EDTN），以取代传统的批量normalization（CBN）层。EDTN将CBN和测试时批量normalization（TBN）相结合，以提取可靠的特征对域偏移。分类器方面，我们通过计算特征和拟标的距离，来更新支持集和pseudo标签。此外，更新支持集的方法基于pseudo标签，可以利用EDTN提取的可靠特征。我们对三个公共跨人HAR数据集和两种不同的TTA设置进行了广泛的实验，结果表明OFTTA在分类性能和计算效率两个方面都超过了当前TTA方法。最后，我们验证了我们提出的OFTTA在边缘设备上的可部署性， indicating possible deployment in real applications.我们的代码可以在\href{https://github.com/Claydon-Wang/OFTTA}{这个https URL}上找到。
</details></li>
</ul>
<hr>
<h2 id="Deep-Intrinsic-Decomposition-with-Adversarial-Learning-for-Hyperspectral-Image-Classification"><a href="#Deep-Intrinsic-Decomposition-with-Adversarial-Learning-for-Hyperspectral-Image-Classification" class="headerlink" title="Deep Intrinsic Decomposition with Adversarial Learning for Hyperspectral Image Classification"></a>Deep Intrinsic Decomposition with Adversarial Learning for Hyperspectral Image Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18549">http://arxiv.org/abs/2310.18549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhiqiang Gong, Xian Zhou, Wen Yao</li>
<li>for: 提高干扰因素影响的高spectral图像分类性能</li>
<li>methods: 利用深度学习的强化学习方法，提取环境因素相关的特征和分类特征，并在激烈学习环境下进行对环境和分类的共同学习</li>
<li>results: 对三个常用的实际数据集进行了实验，并与其他比较方法进行了比较，结果表明提出的方法可以提高高spectral图像分类性能。<details>
<summary>Abstract</summary>
Convolutional neural networks (CNNs) have been demonstrated their powerful ability to extract discriminative features for hyperspectral image classification. However, general deep learning methods for CNNs ignore the influence of complex environmental factor which enlarges the intra-class variance and decreases the inter-class variance. This multiplies the difficulty to extract discriminative features. To overcome this problem, this work develops a novel deep intrinsic decomposition with adversarial learning, namely AdverDecom, for hyperspectral image classification to mitigate the negative impact of environmental factors on classification performance. First, we develop a generative network for hyperspectral image (HyperNet) to extract the environmental-related feature and category-related feature from the image. Then, a discriminative network is constructed to distinguish different environmental categories. Finally, a environmental and category joint learning loss is developed for adversarial learning to make the deep model learn discriminative features. Experiments are conducted over three commonly used real-world datasets and the comparison results show the superiority of the proposed method. The implementation of the proposed method and other compared methods could be accessed at https://github.com/shendu-sw/Adversarial Learning Intrinsic Decomposition for the sake of reproducibility.
</details>
<details>
<summary>摘要</summary>
卷积神经网络（CNN）在多spectral影像分类中表现出了强大的特征提取能力。然而，通用深度学习方法忽略了环境因素的复杂影响，这会增加内类差异和降低对类差异，从而困难提取特征。为解决这个问题，本文提出了一种新的深度内在分解与对抗学习方法，称为AdverDecom，用于多spectral影像分类。首先，我们开发了一个生成网络（HyperNet），用于提取影像中的环境相关特征和类别相关特征。然后，我们构建了一个分类网络，用于分辨不同的环境类别。最后，我们开发了一个环境和类别联合学习损失函数，用于对抗学习，以使深度模型学习特征。我们在三个常用的实际数据集上进行了实验，并比较了我们的方法和其他比较方法的结果，显示了我们的方法的优越性。实现方法和其他比较方法的实现可以通过https://github.com/shendu-sw/Adversarial Learning Intrinsic Decomposition访问，以便重现。
</details></li>
</ul>
<hr>
<h2 id="ReConTab-Regularized-Contrastive-Representation-Learning-for-Tabular-Data"><a href="#ReConTab-Regularized-Contrastive-Representation-Learning-for-Tabular-Data" class="headerlink" title="ReConTab: Regularized Contrastive Representation Learning for Tabular Data"></a>ReConTab: Regularized Contrastive Representation Learning for Tabular Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18541">http://arxiv.org/abs/2310.18541</a></li>
<li>repo_url: None</li>
<li>paper_authors: Suiyao Chen, Jing Wu, Naira Hovakimyan, Handong Yao</li>
<li>for: 本研究旨在提出一种深度自动表示学习框架，以提高tabular数据中的特征工程和选择过程。</li>
<li>methods: 该框架基于同 Raw Features 的非对称 autoencoder，并采用了正则化技术进行 Raw Feature 选择。同时，框架还应用了对比学习来维护最关键的信息。</li>
<li>results: 实验结果表明，该框架可以在各种实际数据集上提供显著的性能提升，并且可以轻松地与传统方法相结合，如 XGBoost 和 Random Forest。<details>
<summary>Abstract</summary>
Representation learning stands as one of the critical machine learning techniques across various domains. Through the acquisition of high-quality features, pre-trained embeddings significantly reduce input space redundancy, benefiting downstream pattern recognition tasks such as classification, regression, or detection. Nonetheless, in the domain of tabular data, feature engineering and selection still heavily rely on manual intervention, leading to time-consuming processes and necessitating domain expertise. In response to this challenge, we introduce ReConTab, a deep automatic representation learning framework with regularized contrastive learning. Agnostic to any type of modeling task, ReConTab constructs an asymmetric autoencoder based on the same raw features from model inputs, producing low-dimensional representative embeddings. Specifically, regularization techniques are applied for raw feature selection. Meanwhile, ReConTab leverages contrastive learning to distill the most pertinent information for downstream tasks. Experiments conducted on extensive real-world datasets substantiate the framework's capacity to yield substantial and robust performance improvements. Furthermore, we empirically demonstrate that pre-trained embeddings can seamlessly integrate as easily adaptable features, enhancing the performance of various traditional methods such as XGBoost and Random Forest.
</details>
<details>
<summary>摘要</summary>
<<SYS>>机器学习中的表示学习技术在不同领域具有重要的地位。通过获得高质量的特征，预训练的嵌入significantly reducent输入空间的重复性，从而为下游的模式识别任务，如分类、回归或检测提供了明显的性能提升。然而，在标量数据领域，功能工程和选择仍然高度依赖于人工干预，导致时间消耗大、需要域专业知识。为解决这个挑战，我们介绍ReConTab，一种深度自动表示学习框架，通过带有正则化的对比学习来实现。不论任务模型的类型，ReConTab使用同 Raw Features 的同构自动encoder来生成低维表示嵌入。特别是，对 Raw Features 进行正则化处理。同时，ReConTab通过对比学习来筛选最关键的信息，以便下游任务。经验表明，ReConTab在广泛的实际数据集上实现了显著和可靠的性能提升。此外，我们也证明了预训练嵌入可以轻松地适应为多种传统方法，如 XGBoost 和 Random Forest 提高性能。<</SYS>>
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/28/cs.AI_2023_10_28/" data-id="cloh7tqcn00697b88ac2t7l4d" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_10_28" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/28/cs.CL_2023_10_28/" class="article-date">
  <time datetime="2023-10-28T11:00:00.000Z" itemprop="datePublished">2023-10-28</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/28/cs.CL_2023_10_28/">cs.CL - 2023-10-28</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Translating-away-Translationese-without-Parallel-Data"><a href="#Translating-away-Translationese-without-Parallel-Data" class="headerlink" title="Translating away Translationese without Parallel Data"></a>Translating away Translationese without Parallel Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18830">http://arxiv.org/abs/2310.18830</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rricha Jalota, Koel Dutta Chowdhury, Cristina España-Bonet, Josef van Genabith</li>
<li>for: 本研究旨在减少翻译语言的影响，以提高跨语言自然语言处理任务的准确性。</li>
<li>methods: 本研究使用了一种新的翻译风格传递方法，利用了自监督学习方法，并结合了原始语言模型损失和 semantics相似性损失。</li>
<li>results: 研究结果表明，本方法能够减少翻译语言的影响，保持内容完整性和目标风格流畅性。<details>
<summary>Abstract</summary>
Translated texts exhibit systematic linguistic differences compared to original texts in the same language, and these differences are referred to as translationese. Translationese has effects on various cross-lingual natural language processing tasks, potentially leading to biased results. In this paper, we explore a novel approach to reduce translationese in translated texts: translation-based style transfer. As there are no parallel human-translated and original data in the same language, we use a self-supervised approach that can learn from comparable (rather than parallel) mono-lingual original and translated data. However, even this self-supervised approach requires some parallel data for validation. We show how we can eliminate the need for parallel validation data by combining the self-supervised loss with an unsupervised loss. This unsupervised loss leverages the original language model loss over the style-transferred output and a semantic similarity loss between the input and style-transferred output. We evaluate our approach in terms of original vs. translationese binary classification in addition to measuring content preservation and target-style fluency. The results show that our approach is able to reduce translationese classifier accuracy to a level of a random classifier after style transfer while adequately preserving the content and fluency in the target original style.
</details>
<details>
<summary>摘要</summary>
文本翻译后会显示系统性的语言差异，这些差异称为翻译语言（translationese）。这些语言差异会影响跨语言自然语言处理任务的结果，可能导致偏向结果。在这篇论文中，我们探索了一种新的方法来减少翻译语言：翻译样式传递。由于没有同语言的人工翻译和原始数据，我们使用了一种自动学习的方法，可以从相似的原始和翻译数据中学习。然而， même 这种自动学习方法需要一些平行数据来验证。我们可以消除平行验证数据的需求 by combining the self-supervised loss with an unsupervised loss。这种无supervised loss 利用了原始语言模型的损失 sobre la output de estilo transferido y una pérdida de similitud semántica entre la entrada y la output de estilo transferido。我们按照原始vs. 翻译语言二分类、内容保持和目标风格流畅来评估我们的方法。结果表明，我们的方法可以在style transfer后减少翻译语言分类器的准确率到随机分类器的水平，同时保持内容和目标风格的流畅。
</details></li>
</ul>
<hr>
<h2 id="Are-NLP-Models-Good-at-Tracing-Thoughts-An-Overview-of-Narrative-Understanding"><a href="#Are-NLP-Models-Good-at-Tracing-Thoughts-An-Overview-of-Narrative-Understanding" class="headerlink" title="Are NLP Models Good at Tracing Thoughts: An Overview of Narrative Understanding"></a>Are NLP Models Good at Tracing Thoughts: An Overview of Narrative Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18783">http://arxiv.org/abs/2310.18783</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lixing Zhu, Runcong Zhao, Lin Gui, Yulan He</li>
<li>for: 本研究旨在探讨narative理解的应用和挑战，以提高大语言模型（LLM）的 narative comprehension 能力。</li>
<li>methods: 本研究使用了 comprehensive survey 方法，对 narrative understanding 任务进行了全面的检查和分类，并详细介绍了关键特征、定义、分类、相关数据集、训练目标和评价指标。</li>
<li>results: 本研究发现，通过扩展 modularized LLM 的能力，可以解决一些新的 narative understanding 任务。此外，通过将 narative understanding 定义为捕捉作者的想象创作灵感的问题，本研究提出了一新的视角，以增强 narative comprehension 能力。<details>
<summary>Abstract</summary>
Narrative understanding involves capturing the author's cognitive processes, providing insights into their knowledge, intentions, beliefs, and desires. Although large language models (LLMs) excel in generating grammatically coherent text, their ability to comprehend the author's thoughts remains uncertain. This limitation hinders the practical applications of narrative understanding. In this paper, we conduct a comprehensive survey of narrative understanding tasks, thoroughly examining their key features, definitions, taxonomy, associated datasets, training objectives, evaluation metrics, and limitations. Furthermore, we explore the potential of expanding the capabilities of modularized LLMs to address novel narrative understanding tasks. By framing narrative understanding as the retrieval of the author's imaginative cues that outline the narrative structure, our study introduces a fresh perspective on enhancing narrative comprehension.
</details>
<details>
<summary>摘要</summary>
narrative understanding 涉及捕捉作者的认知过程，提供作者的知识、意图、信仰、愿望等信息的启示。虽然大语言模型（LLM）在生成 grammatically coherent text 方面表现出色，但它们对作者的思想真实理解仍存在uncertainty。这种限制阻碍了 narraitve understanding 的实际应用。在这篇论文中，我们进行了全面的 narrative understanding 任务调查，详细检查了这些任务的关键特征、定义、分类、相关数据集、训练目标、评价指标以及局限性。此外，我们还探讨了扩展 modularized LLM 的能力，以解决新的 narrative understanding 任务。我们通过将 narrative understanding 定义为捕捉作者的想象力cue 的抽象，从新的角度增强了 narrative comprehension。
</details></li>
</ul>
<hr>
<h2 id="ProMap-Effective-Bilingual-Lexicon-Induction-via-Language-Model-Prompting"><a href="#ProMap-Effective-Bilingual-Lexicon-Induction-via-Language-Model-Prompting" class="headerlink" title="ProMap: Effective Bilingual Lexicon Induction via Language Model Prompting"></a>ProMap: Effective Bilingual Lexicon Induction via Language Model Prompting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18778">http://arxiv.org/abs/2310.18778</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/4mekki4/promap">https://github.com/4mekki4/promap</a></li>
<li>paper_authors: Abdellah El Mekki, Muhammad Abdul-Mageed, ElMoatez Billah Nagoudi, Ismail Berrada, Ahmed Khoumsi</li>
<li>for: 本研究的目的是提出一种基于多语言多方言语言模型的提示方法，以解决基于静态单词表示的单词翻译 task 中的挑战。</li>
<li>methods: 该方法基于提前训练的多语言多方言语言模型，并使用有效的补充提示来改进单词翻译性能。</li>
<li>results: 在评估多种单词翻译方法，包括静态单词表示的方法，ProMap  consistently  achieve 状态的 лучResults ，并且在少数例示enario 下（ fewer than 10 个训练示例）也能够达到良好的性能。<details>
<summary>Abstract</summary>
Bilingual Lexicon Induction (BLI), where words are translated between two languages, is an important NLP task. While noticeable progress on BLI in rich resource languages using static word embeddings has been achieved. The word translation performance can be further improved by incorporating information from contextualized word embeddings. In this paper, we introduce ProMap, a novel approach for BLI that leverages the power of prompting pretrained multilingual and multidialectal language models to address these challenges. To overcome the employment of subword tokens in these models, ProMap relies on an effective padded prompting of language models with a seed dictionary that achieves good performance when used independently. We also demonstrate the effectiveness of ProMap in re-ranking results from other BLI methods such as with aligned static word embeddings. When evaluated on both rich-resource and low-resource languages, ProMap consistently achieves state-of-the-art results. Furthermore, ProMap enables strong performance in few-shot scenarios (even with less than 10 training examples), making it a valuable tool for low-resource language translation. Overall, we believe our method offers both exciting and promising direction for BLI in general and low-resource languages in particular. ProMap code and data are available at \url{https://github.com/4mekki4/promap}.
</details>
<details>
<summary>摘要</summary>
百度 Lexicon 推理 (BLI), 将词语翻译 между两种语言，是 NLP 任务中的一项重要任务。虽然在使用静态词嵌入的情况下，在丰富资源语言中已经取得了可注目的进步，但词语翻译性能可以通过使用语言模型的上下文化词嵌入进一步改进。在这篇论文中，我们介绍了 ProMap，一种新的 BLI 方法，利用预训练的多语言多方言语言模型的力量，解决这些挑战。为了超越使用子词 токен，ProMap 利用有效的补充提示语言模型的方法，并使用种子词典 achieve 好的性能。我们还 demonstarte ProMap 可以在其他 BLI 方法的结果中进行排名，如采用静态词嵌入的方法。当评估在丰富资源语言和低资源语言上时，ProMap  consistently 取得了状态的艺术结果。此外，ProMap 可以在少量示例下进行几极enario （即使使用 less than 10 个训练示例），这使其成为低资源语言翻译中的有价值工具。总之，我们认为我们的方法对 BLI 和低资源语言来说是一种激动人心的和有前途的方向。ProMap 代码和数据可以在 \url{https://github.com/4mekki4/promap} 上找到。
</details></li>
</ul>
<hr>
<h2 id="Crossing-the-Aisle-Unveiling-Partisan-and-Counter-Partisan-Events-in-News-Reporting"><a href="#Crossing-the-Aisle-Unveiling-Partisan-and-Counter-Partisan-Events-in-News-Reporting" class="headerlink" title="Crossing the Aisle: Unveiling Partisan and Counter-Partisan Events in News Reporting"></a>Crossing the Aisle: Unveiling Partisan and Counter-Partisan Events in News Reporting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18768">http://arxiv.org/abs/2310.18768</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaijian Zou, Xinliang Frederick Zhang, Winston Wu, Nick Beauchamp, Lu Wang</li>
<li>for: 这篇论文研究了新闻媒体是如何通过事件包容或排除来影响公众意见的。</li>
<li>methods: 作者首先引入了检测党派和反党派事件的任务，并对这些事件进行了标注。然后，他们使用了高质量的数据集PAC，包含304篇来自不同政治立场的新闻文章，并对其进行了分析。</li>
<li>results: 研究发现，新闻媒体通过事件包容或排除来影响公众意见，并且这种影响可以通过语言模型更好地理解事件在更广泛的上下文中。同时，研究也发现了新闻媒体的选择性报道可能会影响公众意见的方向性。<details>
<summary>Abstract</summary>
News media is expected to uphold unbiased reporting. Yet they may still affect public opinion by selectively including or omitting events that support or contradict their ideological positions. Prior work in NLP has only studied media bias via linguistic style and word usage. In this paper, we study to which degree media balances news reporting and affects consumers through event inclusion or omission. We first introduce the task of detecting both partisan and counter-partisan events: events that support or oppose the author's political ideology. To conduct our study, we annotate a high-quality dataset, PAC, containing 8,511 (counter-)partisan event annotations in 304 news articles from ideologically diverse media outlets. We benchmark PAC to highlight the challenges of this task. Our findings highlight both the ways in which the news subtly shapes opinion and the need for large language models that better understand events within a broader context. Our dataset can be found at https://github.com/launchnlp/Partisan-Event-Dataset.
</details>
<details>
<summary>摘要</summary>
新闻媒体应该保持不倚于任何政治立场的报道，但它们可能仍然影响公众意见通过选择性地包括或排除支持或反对其政治立场的事件。在这篇论文中，我们研究了新闻报道是如何帮助或妨碍公众意见的。我们首先介绍了检测政治立场事件的任务，包括支持和反对作者政治立场的事件。为了进行这项研究，我们在304篇来自不同政治立场的新闻媒体发布的文章中标注了8511个（Counter-)政治立场事件。我们使用PAC数据集进行测试，以高亮这个任务的挑战。我们的发现表明新闻可以在不显着的方式下形成公众意见，同时也表明需要更好地理解事件在更广泛的上下文中。我们的数据集可以在GitHub上找到：https://github.com/launchnlp/Partisan-Event-Dataset。
</details></li>
</ul>
<hr>
<h2 id="TLM-Token-Level-Masking-for-Transformers"><a href="#TLM-Token-Level-Masking-for-Transformers" class="headerlink" title="TLM: Token-Level Masking for Transformers"></a>TLM: Token-Level Masking for Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18738">http://arxiv.org/abs/2310.18738</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Young1993/tlm">https://github.com/Young1993/tlm</a></li>
<li>paper_authors: Yangjun Wu, Kebin Fang, Dongxiang Zhang, Han Wang, Hao Zhang, Gang Chen</li>
<li>for: 本研究旨在提高Transformer模型的鲁棒性和一致性，通过对自注意力连接进行质量控制。</li>
<li>methods: 本研究提出了一种基于Token Level Masking（TLM）的新训练策略，包括两种有效和容易实现的遮盾技术。</li>
<li>results: 实验表明，TLM可以在4种不同的自然语言处理任务上提高性能，比如GLUE、ChineseGLUE、中文语法错误修复和数据到文本生成等，并且可以超越DropHead和注意力遮盾。例如，使用BERT-large模型，TLM在GLUE上提高了0.5点相对于DropHead。此外，TLM在Rotowire上达到了18.93 BLEU的新纪录。<details>
<summary>Abstract</summary>
Structured dropout approaches, such as attention dropout and DropHead, have been investigated to regularize the multi-head attention mechanism in Transformers. In this paper, we propose a new regularization scheme based on token-level rather than structure-level to reduce overfitting. Specifically, we devise a novel Token-Level Masking (TLM) training strategy for Transformers to regularize the connections of self-attention, which consists of two masking techniques that are effective and easy to implement. The underlying idea is to manipulate the connections between tokens in the multi-head attention via masking, where the networks are forced to exploit partial neighbors' information to produce a meaningful representation. The generality and effectiveness of TLM are thoroughly evaluated via extensive experiments on 4 diversified NLP tasks across 18 datasets, including natural language understanding benchmark GLUE, ChineseGLUE, Chinese Grammatical Error Correction, and data-to-text generation. The results indicate that TLM can consistently outperform attention dropout and DropHead, e.g., it increases by 0.5 points relative to DropHead with BERT-large on GLUE. Moreover, TLM can establish a new record on the data-to-text benchmark Rotowire (18.93 BLEU). Our code will be publicly available at https://github.com/Young1993/tlm.
</details>
<details>
<summary>摘要</summary>
“structured dropout方法，如注意力Dropout和DropHead，已经用来规化Transformer中的多头注意力机制。在这篇论文中，我们提出了一新的规化方案，基于Token Level而不是结构 Level，以减少过拟合。 Specifically, we develop a novel Token-Level Masking（TLM）训练策略 дляTransformer，以规化自我注意力的连接，这包括两种遮盾技术，它们是有效且易于实现。 The underlying idea is to manipulate the connections between tokens in the multi-head attention via masking, where the networks are forced to exploit partial neighbors' information to produce a meaningful representation。”“我们透过广泛的实验评估TLM的通用性和效果，包括18个不同的自然语言处理任务和4个测试集。结果显示，TLM可以较DropHead和注意力Dropout表现出色，例如，与BERT-large在GLUE上的结果提高0.5分。此外，TLM可以创下Rotowire（18.93 BLEU）中的新纪录。我们将代码公开在https://github.com/Young1993/tlm。”
</details></li>
</ul>
<hr>
<h2 id="When-Reviewers-Lock-Horn-Finding-Disagreement-in-Scientific-Peer-Reviews"><a href="#When-Reviewers-Lock-Horn-Finding-Disagreement-in-Scientific-Peer-Reviews" class="headerlink" title="When Reviewers Lock Horn: Finding Disagreement in Scientific Peer Reviews"></a>When Reviewers Lock Horn: Finding Disagreement in Scientific Peer Reviews</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18685">http://arxiv.org/abs/2310.18685</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sandeep82945/contradiction-in-peer-review">https://github.com/sandeep82945/contradiction-in-peer-review</a></li>
<li>paper_authors: Sandeep Kumar, Tirthankar Ghosal, Asif Ekbal</li>
<li>for: 本研究旨在Automatically identifying contradictions among reviewers on a given article.</li>
<li>methods: 我们提出了一种基本模型，可以从open review-based ICLR和NeurIPS会议的 around 8.5k paper中检测出对 противоречи的评论。</li>
<li>results: 我们创建了一个包含around 28k review pair中nearly 50k review pair comment的comprehensive review-pair contradiction数据集，并提出了一种基本模型可以自动检测评论中的对 противоречи。<details>
<summary>Abstract</summary>
To this date, the efficacy of the scientific publishing enterprise fundamentally rests on the strength of the peer review process. The journal editor or the conference chair primarily relies on the expert reviewers' assessment, identify points of agreement and disagreement and try to reach a consensus to make a fair and informed decision on whether to accept or reject a paper. However, with the escalating number of submissions requiring review, especially in top-tier Artificial Intelligence (AI) conferences, the editor/chair, among many other works, invests a significant, sometimes stressful effort to mitigate reviewer disagreements. Here in this work, we introduce a novel task of automatically identifying contradictions among reviewers on a given article. To this end, we introduce ContraSciView, a comprehensive review-pair contradiction dataset on around 8.5k papers (with around 28k review pairs containing nearly 50k review pair comments) from the open review-based ICLR and NeurIPS conferences. We further propose a baseline model that detects contradictory statements from the review pairs. To the best of our knowledge, we make the first attempt to identify disagreements among peer reviewers automatically. We make our dataset and code public for further investigations.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ASTormer-An-AST-Structure-aware-Transformer-Decoder-for-Text-to-SQL"><a href="#ASTormer-An-AST-Structure-aware-Transformer-Decoder-for-Text-to-SQL" class="headerlink" title="ASTormer: An AST Structure-aware Transformer Decoder for Text-to-SQL"></a>ASTormer: An AST Structure-aware Transformer Decoder for Text-to-SQL</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18662">http://arxiv.org/abs/2310.18662</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruisheng Cao, Hanchong Zhang, Hongshen Xu, Jieyu Li, Da Ma, Lu Chen, Kai Yu</li>
<li>for: 文章目的是提出一种基于Transformer decoder的文本到SQL转换方法，以生成可执行的SQL程序，并确保输出SQL的有效性。</li>
<li>methods: 该方法使用AST结构具有STRUCTURE-aware Transformer decoder（ASTormer），在decoder中嵌入了结构知识，例如节点类型和位置，并通过绝对和相对位置嵌入来强化结构信息。</li>
<li>results: 对五个文本到SQL benchmark进行了广泛的实验，并证明了ASTormer比基于RNN的竞争对手更有效和高效。<details>
<summary>Abstract</summary>
Text-to-SQL aims to generate an executable SQL program given the user utterance and the corresponding database schema. To ensure the well-formedness of output SQLs, one prominent approach adopts a grammar-based recurrent decoder to produce the equivalent SQL abstract syntax tree (AST). However, previous methods mainly utilize an RNN-series decoder, which 1) is time-consuming and inefficient and 2) introduces very few structure priors. In this work, we propose an AST structure-aware Transformer decoder (ASTormer) to replace traditional RNN cells. The structural knowledge, such as node types and positions in the tree, is seamlessly incorporated into the decoder via both absolute and relative position embeddings. Besides, the proposed framework is compatible with different traversing orders even considering adaptive node selection. Extensive experiments on five text-to-SQL benchmarks demonstrate the effectiveness and efficiency of our structured decoder compared to competitive baselines.
</details>
<details>
<summary>摘要</summary>
文本到SQL的目标是生成基于用户语音和相应的数据库架构的可执行SQL程序。为保证输出SQL的正确性，一种广泛采用的方法是使用 grammar-based 回归decoder生成相应的SQL抽象语法树（AST）。然而，前一代方法主要采用 RNN 序列decoder，这些方法有以下两点缺陷：1）时间consuming 和不效率，2）不提供多少结构偏好。在这项工作中，我们提议一种AST结构意识的Transformer decoder（ASTormer）来取代传统的RNN细胞。在decoder中，结构知识，如树中节点类型和位置，通过绝对和相对位置嵌入被灵活地嵌入。此外，我们提出的框架可以与不同的搜索顺序一起使用，包括自适应节点选择。我们对五个文本到SQLbenchmark进行了广泛的实验，并证明了我们的结构化decoder与其他基准值比较有效和高效。
</details></li>
</ul>
<hr>
<h2 id="Personalised-Distillation-Empowering-Open-Sourced-LLMs-with-Adaptive-Learning-for-Code-Generation"><a href="#Personalised-Distillation-Empowering-Open-Sourced-LLMs-with-Adaptive-Learning-for-Code-Generation" class="headerlink" title="Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation"></a>Personalised Distillation: Empowering Open-Sourced LLMs with Adaptive Learning for Code Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18628">http://arxiv.org/abs/2310.18628</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hailin Chen, Amrita Saha, Steven Hoi, Shafiq Joty</li>
<li>for: 本研究旨在提高小型开源模型的能力，通过将大型关闭源模型（如ChatGPT、GPT-4）的能力储存到小型开源模型中。</li>
<li>methods: 该研究提出了一种个性化储存方法，其中学生模型首先尝试解决任务，然后教师模型提供适应性更新，以便学生模型可以通过自己的错误来进行改进。这种个性化储存方法与传统的预先Feed的方法不同，因为它只有学生模型在进行学习时才会学习，而不是从教师模型那里获得知识。</li>
<li>results: 研究表明，个性化储存方法在代码生成任务中表现出色，可以在只有一 third的数据量下达到传统方法的水平。在HumanEval中，通过使用2.5-3K个性化示例，可以提高CodeGen-mono-16B的表现，从33.6%提高到36.4%，并提高StarCoder的表现，从39.5%提高到45.8%。<details>
<summary>Abstract</summary>
With the rise of powerful closed-sourced LLMs (ChatGPT, GPT-4), there are increasing interests in distilling the capabilies of close-sourced LLMs to smaller open-sourced LLMs. Previous distillation methods usually prompt ChatGPT to generate a set of instructions and answers, for the student model to learn. However, such standard distillation approach neglects the merits and conditions of the student model. Inspired by modern teaching principles, we design a personalised distillation process, in which the student attempts to solve a task first, then the teacher provides an adaptive refinement for the student to improve. Instead of feeding the student with teacher's prior, personalised distillation enables personalised learning for the student model, as it only learns on examples it makes mistakes upon and learns to improve its own solution. On code generation, personalised distillation consistently outperforms standard distillation with only one third of the data. With only 2.5-3K personalised examples that incur a data-collection cost of 4-6$, we boost CodeGen-mono-16B by 7% to achieve 36.4% pass@1 and StarCoder by 12.2% to achieve 45.8% pass@1 on HumanEval.
</details>
<details>
<summary>摘要</summary>
Inspired by modern teaching principles, we designed a personalized distillation process in which the student attempts to solve a task first, and then the teacher provides an adaptive refinement for the student to improve. Instead of feeding the student with the teacher's prior knowledge, personalized distillation enables personalized learning for the student model, as it only learns from examples it makes mistakes on and learns to improve its own solutions.On code generation, personalized distillation consistently outperforms standard distillation with only one-third of the data. With only 2,500 to 3,000 personalized examples that incur a data-collection cost of $4 to $6, we boosted CodeGen-mono-16B by 7% to achieve 36.4% pass@1 and StarCoder by 12.2% to achieve 45.8% pass@1 on HumanEval.
</details></li>
</ul>
<hr>
<h2 id="Anaphor-Assisted-Document-Level-Relation-Extraction"><a href="#Anaphor-Assisted-Document-Level-Relation-Extraction" class="headerlink" title="Anaphor Assisted Document-Level Relation Extraction"></a>Anaphor Assisted Document-Level Relation Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18604">http://arxiv.org/abs/2310.18604</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/burgerburgerburger/aa">https://github.com/burgerburgerburger/aa</a></li>
<li>paper_authors: Chonggang Lu, Richong Zhang, Kai Sun, Jaein Kim, Cunwang Zhang, Yongyi Mao</li>
<li>for:  DocRE document-level relation extraction</li>
<li>methods:  Anaphor-Assisted (AA) framework</li>
<li>results:  new state-of-the-art performance<details>
<summary>Abstract</summary>
Document-level relation extraction (DocRE) involves identifying relations between entities distributed in multiple sentences within a document. Existing methods focus on building a heterogeneous document graph to model the internal structure of an entity and the external interaction between entities. However, there are two drawbacks in existing methods. On one hand, anaphor plays an important role in reasoning to identify relations between entities but is ignored by these methods. On the other hand, these methods achieve cross-sentence entity interactions implicitly by utilizing a document or sentences as intermediate nodes. Such an approach has difficulties in learning fine-grained interactions between entities across different sentences, resulting in sub-optimal performance. To address these issues, we propose an Anaphor-Assisted (AA) framework for DocRE tasks. Experimental results on the widely-used datasets demonstrate that our model achieves a new state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
文档级关系EXTRACTION（DocRE）涉及到在文档中多个句子中Identifying关系 между实体。现有方法是建立不同类型的文档图来模型实体的内部结构和实体之间的外部互动。然而，现有方法存在两点缺陷。一方面，Anaphora在理解关系 identification 中发挥重要作用，但这些方法忽略了它。另一方面，这些方法通过使用文档或句子作为中间节点来实现跨句sentenceEntity interaction，这会增加学习细化实体之间的交互问题，导致性能下降。为了解决这些问题，我们提出了Anaphor-Assisted（AA）框架来Address DocRE任务。实验结果表明，我们的模型在广泛使用的数据集上达到了新的状态的艺术性能。
</details></li>
</ul>
<hr>
<h2 id="Accelerating-LLM-Inference-by-Enabling-Intermediate-Layer-Decoding"><a href="#Accelerating-LLM-Inference-by-Enabling-Intermediate-Layer-Decoding" class="headerlink" title="Accelerating LLM Inference by Enabling Intermediate Layer Decoding"></a>Accelerating LLM Inference by Enabling Intermediate Layer Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18581">http://arxiv.org/abs/2310.18581</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neeraj Varshney, Agneet Chatterjee, Mihir Parmar, Chitta Baral</li>
<li>for: 提高LLMs的执行效率，使其适用于资源受限的实际应用中。</li>
<li>methods: 通过增加中间层的LITE损失，使中间层学习生成文本的能力，而不会影响最终层的生成质量。并通过“动态信任早退”的技术，在token层面实现更高效的推理，保持生成质量。</li>
<li>results: 在Alpaca数据集上进行了广泛的实验，并对四个不同的人工指令测试集进行了总体评估：Vicuna、WizardLM、Koala和Self-Instruct。结果表明，“动态早退”可以实现37.86%的平均成本改进，保持生成质量。进一步的分析结果表明，输出的语义相似性和生成的数量均有改进。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have achieved remarkable performance across a wide variety of natural language tasks; however, their large size makes their inference slow and computationally expensive which poses a practical challenge for resource constrained real-world applications. Focusing on this problem, we propose to instruction tune LLMs in a way that enables intermediate layer decoding for efficiently generating text, but importantly without compromising the quality of the generation. Specifically, we instruction tune LLMs with additional explicit Losses from the InTermediate layErs (LITE) and show that it enables these layers to acquire 'good' generation ability without affecting the generation ability of the final layer. We perform 'dynamic confidence-based early exiting' at token level from the intermediate layers which improves the efficiency of inference while maintaining the generation quality. We conduct comprehensive experiments by instruction tuning LLaMA-2 models on the widely used Alpaca dataset and holistically evaluate on four different human-instruction test sets: Vicuna, WizardLM, Koala, and Self-Instruct. We show that 'dynamic early exiting' achieves consistent and considerable cost improvements (37.86% on average) while maintaining the generation quality of the responses. We further conduct a thorough analysis of the results over several important aspects, such as comparing the semantic similarity of the outputs and dissecting the efficiency improvements by comparing the number of tokens generated in the output. In summary, our work contributes to improving the efficiency of LLM inference while maintaining the generation quality, a crucial step en route to enabling their widespread adoption.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM）在各种自然语言任务上达到了很高的表现水平，但是它们的大小使得其推理慢且计算成本高，这成为了实际应用中的实际挑战。在这个问题上，我们提出了在LLM中 instrucion 优化，以实现中间层解码，以便高效地生成文本，而不会影响最终层的生成质量。我们在LLM中添加了额外的明确损失（LITE），使中间层学习“好”的生成能力，而不会影响最终层的生成能力。我们在中间层进行“动态信息确定早退”，从而提高推理效率，保持生成质量。我们对 LLamA-2 模型进行了广泛的实验，并对四个不同的人工指令测试集进行了总体评估：Vicuna、WizardLM、Koala 和 Self-Instruct。我们发现，“动态早退”可以具有重要的成本改善（37.86% 的平均提高），同时保持生成质量。我们进一步进行了详细的分析结果，包括比较输出的semantic相似性和生成量的比较分析。总之，我们的工作为LLM推理效率的提高，并保持生成质量，是实际应用中的关键一步。
</details></li>
</ul>
<hr>
<h2 id="Identifying-Conspiracy-Theories-News-based-on-Event-Relation-Graph"><a href="#Identifying-Conspiracy-Theories-News-based-on-Event-Relation-Graph" class="headerlink" title="Identifying Conspiracy Theories News based on Event Relation Graph"></a>Identifying Conspiracy Theories News based on Event Relation Graph</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18545">http://arxiv.org/abs/2310.18545</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuanyuanlei-nlp/conspiracy_theories_emnlp_2023">https://github.com/yuanyuanlei-nlp/conspiracy_theories_emnlp_2023</a></li>
<li>paper_authors: Yuanyuan Lei, Ruihong Huang</li>
<li>for: 本研究旨在检测新闻文章中是否存在阴谋理论。</li>
<li>methods: 本文提出了一种基于事件关系图的阴谋理论检测方法，包括开发了一个事件意识语言模型以提高基础语言模型的事件和事件关系知识，以及使用一种多型图注意力网络来 derive 一个图像 embedding。</li>
<li>results: 实验结果表明，基于事件关系图的方法可以提高阴谋理论检测的准确率和受检测率，并且能够在新的媒体源上进行检测。<details>
<summary>Abstract</summary>
Conspiracy theories, as a type of misinformation, are narratives that explains an event or situation in an irrational or malicious manner. While most previous work examined conspiracy theory in social media short texts, limited attention was put on such misinformation in long news documents. In this paper, we aim to identify whether a news article contains conspiracy theories. We observe that a conspiracy story can be made up by mixing uncorrelated events together, or by presenting an unusual distribution of relations between events. Achieving a contextualized understanding of events in a story is essential for detecting conspiracy theories. Thus, we propose to incorporate an event relation graph for each article, in which events are nodes, and four common types of event relations, coreference, temporal, causal, and subevent relations, are considered as edges. Then, we integrate the event relation graph into conspiracy theory identification in two ways: an event-aware language model is developed to augment the basic language model with the knowledge of events and event relations via soft labels; further, a heterogeneous graph attention network is designed to derive a graph embedding based on hard labels. Experiments on a large benchmark dataset show that our approach based on event relation graph improves both precision and recall of conspiracy theory identification, and generalizes well for new unseen media sources.
</details>
<details>
<summary>摘要</summary>
《刺激论题》是一种不合理或恶意的含义，用于解释事件或情况。而大多数前期工作都是通过社交媒体短文来研究刺激论题，却受到了长文报道的限制。在这篇论文中，我们想要判断一篇新闻文章是否包含刺激论题。我们发现，刺激故事可以通过将不相关的事件混合起来，或者通过事件之间的不寻常的关系分布来构成。为了检测刺激论题，我们需要了解事件的上下文知识。因此，我们提议使用事件关系图来识刺刺激论题。每篇文章都有一个事件关系图，其中事件是节点，而四种常见的事件关系，核心引用、时间关系、 causal 关系和 subsequential 关系，被视为边。然后，我们将事件关系图 интеグриinto刺激论题标识中两种方式：首先，我们开发了一个事件意识语言模型，以提高基本语言模型的知识水平，并通过软标签将事件和事件关系传递给模型；其次，我们设计了一个多类Graph注意力网络，以生成基于硬标签的图 embedding。实验表明，我们基于事件关系图的方法可以提高刺激论题标识的精度和准确率，并在新的媒体来源上具有良好的泛化性。
</details></li>
</ul>
<hr>
<h2 id="Discourse-Structures-Guided-Fine-grained-Propaganda-Identification"><a href="#Discourse-Structures-Guided-Fine-grained-Propaganda-Identification" class="headerlink" title="Discourse Structures Guided Fine-grained Propaganda Identification"></a>Discourse Structures Guided Fine-grained Propaganda Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18544">http://arxiv.org/abs/2310.18544</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuanyuanlei-nlp/propaganda_emnlp_2023">https://github.com/yuanyuanlei-nlp/propaganda_emnlp_2023</a></li>
<li>paper_authors: Yuanyuan Lei, Ruihong Huang</li>
<li>for: 本研究旨在识别政治新闻中的宣传内容，以 sentence-level 和 token-level 两级精细度进行识别。</li>
<li>methods: 本研究提出了两种教师模型，一是基于 PDTB 风格的 discourse relations 来识别宣传内容，二是基于本文中的 sentence 和 token 的 discourse structures 来提高宣传内容识别精度。</li>
<li>results: 实验结果表明，通过利用教师预测概率或知识储存框架来汇集 discourse structures 可以显著提高宣传内容识别的精度。<details>
<summary>Abstract</summary>
Propaganda is a form of deceptive narratives that instigate or mislead the public, usually with a political purpose. In this paper, we aim to identify propaganda in political news at two fine-grained levels: sentence-level and token-level. We observe that propaganda content is more likely to be embedded in sentences that attribute causality or assert contrast to nearby sentences, as well as seen in opinionated evaluation, speculation and discussions of future expectation. Hence, we propose to incorporate both local and global discourse structures for propaganda discovery and construct two teacher models for identifying PDTB-style discourse relations between nearby sentences and common discourse roles of sentences in a news article respectively. We further devise two methods to incorporate the two types of discourse structures for propaganda identification by either using teacher predicted probabilities as additional features or soliciting guidance in a knowledge distillation framework. Experiments on the benchmark dataset demonstrate that leveraging guidance from discourse structures can significantly improve both precision and recall of propaganda content identification.
</details>
<details>
<summary>摘要</summary>
宣传是一种欺骗性的叙述，通常有政治目的。在这篇论文中，我们目标是在新闻文本中发现宣传。我们发现宣传内容更容易在归因或者评价附近的句子中出现，以及在评价、推测和未来预测中出现。因此，我们建议使用本地和全局文本结构来发现宣传。我们设计了两种教师模型，一个用于确定邻近句子之间的 PDTB 风格的语言关系，另一个用于确定新闻文本中句子的常见语言角色。此外，我们还提出了两种方法来结合这两种文本结构来发现宣传内容，一种是使用教师预测概率作为额外特征，另一种是在知识填充框架中寻求指导。实验表明，通过使用文本结构的指导，可以大幅提高宣传内容发现的精度和准确性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/28/cs.CL_2023_10_28/" data-id="cloh7tqek00cz7b881p6cff63" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_10_28" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/28/cs.LG_2023_10_28/" class="article-date">
  <time datetime="2023-10-28T10:00:00.000Z" itemprop="datePublished">2023-10-28</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/28/cs.LG_2023_10_28/">cs.LG - 2023-10-28</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="World-Model-Based-Sim2Real-Transfer-for-Visual-Navigation"><a href="#World-Model-Based-Sim2Real-Transfer-for-Visual-Navigation" class="headerlink" title="World Model Based Sim2Real Transfer for Visual Navigation"></a>World Model Based Sim2Real Transfer for Visual Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18847">http://arxiv.org/abs/2310.18847</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chen Liu, Kiran Lekkala, Laurent Itti</li>
<li>For: 本研究目的是开发一个可以从便宜的 simulator 转移到实际世界的 robot  Navigation 系统。* Methods: 本研究使用了一个组合了传统的 World Model  комponents的系统，并将其整合成一个可以在 simulator 上全部训练的 Robust 系统。为了促进转移，我们使用了基于 Bird’s Eye View (BEV) 的中间表示，并将它与 First-Person View (FPV) 的 RGB 图像进行翻译。* Results: 我们使用了 CARLA  simulator 收集的数据进行训练，并显示了模型的效能。最后，我们发布了一个完整的代码库、数据和模型，供大众使用。<details>
<summary>Abstract</summary>
Sim2Real transfer has gained popularity because it helps transfer from inexpensive simulators to real world. This paper presents a novel system that fuses components in a traditional \textit{World Model} into a robust system, trained entirely within a simulator, that \textit{Zero-Shot} transfers to the real world. To facilitate transfer, we use an intermediary representation that are based on \textit{Bird's Eye View (BEV)} images. Thus, our robot learns to navigate in a simulator by first learning to translate from complex \textit{First-Person View (FPV)} based RGB images to BEV representations, then learning to navigate using those representations. Later, when tested in the real world, the robot uses the perception model that translates FPV-based RGB images to embeddings that are used by the downstream policy. The incorporation of state-checking modules using \textit{Anchor images} and \textit{Mixture Density LSTM} not only interpolates uncertain and missing observations but also enhances the robustness of the model when exposed to the real-world environment. We trained the model using data collected using a \textit{Differential drive} robot in the CARLA simulator. Our methodology's effectiveness is shown through the deployment of trained models onto a \textit{Real world Differential drive} robot. Lastly we release a comprehensive codebase, dataset and models for training and deployment that are available to the public.
</details>
<details>
<summary>摘要</summary>
实际转移（Sim2Real）已经受到普遍采用，因为它帮助将来自便宜的模拟器转移到真实世界。这篇论文提出了一个新的系统，将模拟器中的元件融合成一个可靠的系统，由真实世界训练，并且透过运算获得零损转移。为了促进转移，我们使用了中心投影（Bird's Eye View，BEV）图像作为中介表示。因此，我们的机器人在模拟器中学习将复杂的首人视角（First-Person View，FPV）基于RGB图像转换为BEV表示，然后学习使用这些表示进行navigation。当它在真实世界中进行测试时，机器人使用视觉模型将FPV基于RGB图像转换为嵌入，这些嵌入被用于下游策略。另外，我们还使用了状态检查模组使用 anchor image和mixture density LSTM interpolate uncertain和缺失观察，这不仅让模型在真实世界环境中更加稳定，而且也增强了模型的可靠性。我们使用了通过CARLA模拟器收集的数据进行训练。我们的方法的有效性被显示在真实世界中部署训练好的模型。最后，我们发布了一个完整的代码库、数据集和模型，供大众使用。
</details></li>
</ul>
<hr>
<h2 id="A-randomized-algorithm-for-nonconvex-minimization-with-inexact-evaluations-and-complexity-guarantees"><a href="#A-randomized-algorithm-for-nonconvex-minimization-with-inexact-evaluations-and-complexity-guarantees" class="headerlink" title="A randomized algorithm for nonconvex minimization with inexact evaluations and complexity guarantees"></a>A randomized algorithm for nonconvex minimization with inexact evaluations and complexity guarantees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18841">http://arxiv.org/abs/2310.18841</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuyao Li, Stephen J. Wright</li>
<li>for: Minimizing a smooth nonconvex function with inexact oracle access to gradient and Hessian.</li>
<li>methods: Using a novel method that chooses the step direction with equal probability of positive or negative sense, and using relative inexactness measures on gradient and Hessian.</li>
<li>results: Achieving ($\epsilon_{g}, \epsilon_{H}$)-approximate second-order optimality with convergence analysis based on martingale analysis and concentration inequalities.Here’s the full summary in Simplified Chinese:</li>
<li>for: 本文目的是使用不精准渐近 oracle 访问梯度和对角线，来实现 ($ \epsilon_{g}, \epsilon_{H} $)-精度二阶优化。</li>
<li>methods: 我们使用一种新的方法，其中在步长选择时，选择的方向的方向是正负两种有 Equal probability。此外，我们使用梯度和对角线的相对不精准度度量，并松弛了梯度和对角线的第一阶和第二阶误差之间的关联。</li>
<li>results: 我们可以通过 martingale 分析和集中不等式来证明我们的算法可以实现 ($\epsilon_{g}, \epsilon_{H}$)-精度二阶优化，并且可以应用到empirical risk minimization问题中。<details>
<summary>Abstract</summary>
We consider minimization of a smooth nonconvex function with inexact oracle access to gradient and Hessian (but not the function value) to achieve $(\epsilon_{g}, \epsilon_{H})$-approximate second-order optimality. A novel feature of our method is that if an approximate direction of negative curvature is chosen as the step, we choose its sense to be positive or negative with equal probability. We also use relative inexactness measures on gradient and Hessian and relax the coupling between the first- and second-order tolerances $\epsilon_{g}$ and $\epsilon_{H}$. Our convergence analysis includes both an expectation bound based on martingale analysis and a high-probability bound based on concentration inequalities. We apply our algorithm to empirical risk minimization problems and obtain gradient sample complexity.
</details>
<details>
<summary>摘要</summary>
我们考虑使用非конvex函数的最小化，但是只有不准确的梯度和偏微分（而不是函数值）的偏 oracle 访问来实现($\epsilon_{g}, \epsilon_{H}$)-次极性。我们的新特点在于，如果选择一个近似的负曲率方向作为步骤，我们会选择其方向为正或负的概率为50%。我们还使用relative不准确度度量在梯度和偏微分上，并松弛了梯度和偏微分的 Coupling。我们的收敛分析包括基于Martingale分析的预期 bound和基于集中不等式的高概率 bound。我们将我们的算法应用到empirical risk minimization问题，并获得梯度样本复杂度。
</details></li>
</ul>
<hr>
<h2 id="Intrinsic-Gaussian-Vector-Fields-on-Manifolds"><a href="#Intrinsic-Gaussian-Vector-Fields-on-Manifolds" class="headerlink" title="Intrinsic Gaussian Vector Fields on Manifolds"></a>Intrinsic Gaussian Vector Fields on Manifolds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18824">http://arxiv.org/abs/2310.18824</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Robert-Nicoud, Andreas Krause, Viacheslav Borovitskiy</li>
<li>for: 本文主要针对的是模型非欧几何空间上的向量值信号，尤其是在不确定性评估中。</li>
<li>methods: 本文提出了一种新的泊松过程模型，即 HODE-MATÉRN 泊松场，用于模型非欧几何空间上的向量值信号。</li>
<li>results: 本文的实验结果表明，HODE-MATÉRN 泊松场可以在二维球面和高维托里上提供更精细的 inductive bias，并且可以在不同的批处理上进行扩展。<details>
<summary>Abstract</summary>
Various applications ranging from robotics to climate science require modeling signals on non-Euclidean domains, such as the sphere. Gaussian process models on manifolds have recently been proposed for such tasks, in particular when uncertainty quantification is needed. In the manifold setting, vector-valued signals can behave very differently from scalar-valued ones, with much of the progress so far focused on modeling the latter. The former, however, are crucial for many applications, such as modeling wind speeds or force fields of unknown dynamical systems. In this paper, we propose novel Gaussian process models for vector-valued signals on manifolds that are intrinsically defined and account for the geometry of the space in consideration. We provide computational primitives needed to deploy the resulting Hodge-Mat\'ern Gaussian vector fields on the two-dimensional sphere and the hypertori. Further, we highlight two generalization directions: discrete two-dimensional meshes and "ideal" manifolds like hyperspheres, Lie groups, and homogeneous spaces. Finally, we show that our Gaussian vector fields constitute considerably more refined inductive biases than the extrinsic fields proposed before.
</details>
<details>
<summary>摘要</summary>
各种应用，从机器人学到气候科学，需要在非欧几何空间上模型信号，例如球面。在拓扑上， Gaussian process 模型在拓扑上最近得到了提议，特别是当需要uncertainty量化时。在拓扑设置中，向量值信号可能会与scalar值信号有很大差异，而前者在许多应用中非常重要，例如模型风速或未知动力系统的力场。在这篇论文中，我们提出了新的 Gaussian process 模型，用于vector值信号在拓扑上的模型，这些模型具有内在定义的拓扑geometry。我们还提供了在两个维度的球面和杂质上运行这些Hodge-Matérn Gaussian vector fields的计算基础。此外，我们还提出了两个扩展方向：离散二维网格和"理想"拓扑，如高维球面、 Lie group 和同态空间。最后，我们表明了我们的 Gaussian vector fields 比之前提出的外在场更加细致，即更加精细的 inductive bias。
</details></li>
</ul>
<hr>
<h2 id="Successfully-Applying-Lottery-Ticket-Hypothesis-to-Diffusion-Model"><a href="#Successfully-Applying-Lottery-Ticket-Hypothesis-to-Diffusion-Model" class="headerlink" title="Successfully Applying Lottery Ticket Hypothesis to Diffusion Model"></a>Successfully Applying Lottery Ticket Hypothesis to Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18823">http://arxiv.org/abs/2310.18823</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/osier0524/lottery-ticket-to-ddpm">https://github.com/osier0524/lottery-ticket-to-ddpm</a></li>
<li>paper_authors: Chao Jiang, Bo Hui, Bohan Liu, Da Yan</li>
<li>for: 这个论文是为了应用抽签票假设（Lottery Ticket Hypothesis，LTH）到扩散模型而写的。</li>
<li>methods: 这个论文使用了LTH来找到一个扩散模型中的精炼版网络，并通过对这个精炼版网络进行简化来减少计算量。</li>
<li>results: 实验结果表明，这个方法可以找到一个具有更高精度且具有更少计算量的扩散模型。 codes可以在<a target="_blank" rel="noopener" href="https://github.com/osier0524/Lottery-Ticket-to-DDPM%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/osier0524/Lottery-Ticket-to-DDPM中找到。</a><details>
<summary>Abstract</summary>
Despite the success of diffusion models, the training and inference of diffusion models are notoriously expensive due to the long chain of the reverse process. In parallel, the Lottery Ticket Hypothesis (LTH) claims that there exists winning tickets (i.e., aproperly pruned sub-network together with original weight initialization) that can achieve performance competitive to the original dense neural network when trained in isolation. In this work, we for the first time apply LTH to diffusion models. We empirically find subnetworks at sparsity 90%-99% without compromising performance for denoising diffusion probabilistic models on benchmarks (CIFAR-10, CIFAR-100, MNIST). Moreover, existing LTH works identify the subnetworks with a unified sparsity along different layers. We observe that the similarity between two winning tickets of a model varies from block to block. Specifically, the upstream layers from two winning tickets for a model tend to be more similar than the downstream layers. Therefore, we propose to find the winning ticket with varying sparsity along different layers in the model. Experimental results demonstrate that our method can find sparser sub-models that require less memory for storage and reduce the necessary number of FLOPs. Codes are available at https://github.com/osier0524/Lottery-Ticket-to-DDPM.
</details>
<details>
<summary>摘要</summary>
尽管扩散模型取得成功，但它们的训练和推理过程却很昂贵，主要因为扩散过程中的链式结构。同时， Lottery Ticket Hypothesis（LTH）假设存在赢家票（即适当剪辑后的子网络以及原始权重初始化），可以在孤立训练中与普通 dense neural network 具有竞争性的性能。在这个工作中，我们首次应用 LTH 到扩散模型。我们实验发现，在 CIFAR-10、CIFAR-100 和 MNIST 等标准图像预测任务上，可以在 diffusion probabilistic models 中找到 90%-99% 的杂度率下的优秀子网络，而不会影响性能。此外，现有的 LTH 工作通常会找到具有不同层次杂度的子网络。我们发现，两个赢家票之间的相似性从层次上不同。具体来说，模型的上游层从两个赢家票之间更加相似，而下游层则更加不同。因此，我们提议在不同层次上找到具有变化杂度的赢家票。实验结果表明，我们的方法可以找到更加简洁的子网络，减少存储的内存需求和计算所需的 FLOPs。代码可以在 <https://github.com/osier0524/Lottery-Ticket-to-DDPM> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Test-Time-Personalization-for-Federated-Learning"><a href="#Adaptive-Test-Time-Personalization-for-Federated-Learning" class="headerlink" title="Adaptive Test-Time Personalization for Federated Learning"></a>Adaptive Test-Time Personalization for Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18816">http://arxiv.org/abs/2310.18816</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/baowenxuan/atp">https://github.com/baowenxuan/atp</a></li>
<li>paper_authors: Wenxuan Bao, Tianxin Wei, Haohan Wang, Jingrui He</li>
<li>for: 本研究旨在提出一种在测试时进行个性化 Federated Learning (FL) 的方法，以适应不同来源客户端的分布差异。</li>
<li>methods: 我们提出了一种名为 ATP 的自适应学习算法，可以在不含标注数据的情况下，在测试时地方式地适应模型。</li>
<li>results: 我们的 ATP 算法在面对多种分布差异，包括标签差异、图像损害和频率差异等，能够超越现有的 TTA 方法，并且可以在多个数据集和模型架构上实现优秀的表现。<details>
<summary>Abstract</summary>
Personalized federated learning algorithms have shown promising results in adapting models to various distribution shifts. However, most of these methods require labeled data on testing clients for personalization, which is usually unavailable in real-world scenarios. In this paper, we introduce a novel setting called test-time personalized federated learning (TTPFL), where clients locally adapt a global model in an unsupervised way without relying on any labeled data during test-time. While traditional test-time adaptation (TTA) can be used in this scenario, most of them inherently assume training data come from a single domain, while they come from multiple clients (source domains) with different distributions. Overlooking these domain interrelationships can result in suboptimal generalization. Moreover, most TTA algorithms are designed for a specific kind of distribution shift and lack the flexibility to handle multiple kinds of distribution shifts in FL. In this paper, we find that this lack of flexibility partially results from their pre-defining which modules to adapt in the model. To tackle this challenge, we propose a novel algorithm called ATP to adaptively learns the adaptation rates for each module in the model from distribution shifts among source domains. Theoretical analysis proves the strong generalization of ATP. Extensive experiments demonstrate its superiority in handling various distribution shifts including label shift, image corruptions, and domain shift, outperforming existing TTA methods across multiple datasets and model architectures. Our code is available at https://github.com/baowenxuan/ATP .
</details>
<details>
<summary>摘要</summary>
个人化联合学习算法已经在不同分布偏移中适应模型表现出色。然而，大多数这些方法需要测试客户端上有标注数据进行个人化，而在实际场景中这些数据通常不可获得。在这篇论文中，我们介绍了一种新的设定，即测试时个人化联合学习（TTPFL），Client可以在无标注数据的情况下，在本地适应全球模型，而不需要任何标注数据。尽管传统的测试时适应（TTA）可以在这种场景中使用，但大多数它们假设训练数据来自单一领域，而实际上来自多个客户端（源领域）的分布不同。忽略这些领域关系可能会导致低效泛化。此外，大多数TTA算法是为某种特定的分布偏移设计的，缺乏在多种分布偏移中的灵活性。为解决这个挑战，我们提议了一种新的算法，即ATP，可以自动学习模型中每个模块的适应率从分布偏移中。理论分析表明ATP具有强大的泛化性。广泛的实验表明ATP在处理多种分布偏移，包括标签偏移、图像损害和频率偏移，在多个数据集和模型架构上超越了现有的TTA方法，并且其代码可以在https://github.com/baowenxuan/ATP上获取。
</details></li>
</ul>
<hr>
<h2 id="Stability-of-Random-Forests-and-Coverage-of-Random-Forest-Prediction-Intervals"><a href="#Stability-of-Random-Forests-and-Coverage-of-Random-Forest-Prediction-Intervals" class="headerlink" title="Stability of Random Forests and Coverage of Random-Forest Prediction Intervals"></a>Stability of Random Forests and Coverage of Random-Forest Prediction Intervals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18814">http://arxiv.org/abs/2310.18814</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yan Wang, Huaiqing Wu, Dan Nettleton</li>
<li>for: 这个论文主要是为了研究随机森林的稳定性，并且提供了一个稳定性的定义，以及一种基于这个定义的预测 интерVALL的建立方法。</li>
<li>methods: 这个论文使用了随机森林的实际实现，以及一些数理Statistics的工具来研究随机森林的稳定性。</li>
<li>results: 这个论文的结果表明，随机森林在一定条件下具有稳定性，并且可以提供正确的预测点和预测 интерVALL，而且这些预测 interval 的覆盖率可以保证在一定范围内。<details>
<summary>Abstract</summary>
We establish stability of random forests under the mild condition that the squared response ($Y^2$) does not have a heavy tail. In particular, our analysis holds for the practical version of random forests that is implemented in popular packages like \texttt{randomForest} in \texttt{R}. Empirical results show that stability may persist even beyond our assumption and hold for heavy-tailed $Y^2$. Using the stability property, we prove a non-asymptotic lower bound for the coverage probability of prediction intervals constructed from the out-of-bag error of random forests. With another mild condition that is typically satisfied when $Y$ is continuous, we also establish a complementary upper bound, which can be similarly established for the jackknife prediction interval constructed from an arbitrary stable algorithm. We also discuss the asymptotic coverage probability under assumptions weaker than those considered in previous literature. Our work implies that random forests, with its stability property, is an effective machine learning method that can provide not only satisfactory point prediction but also justified interval prediction at almost no extra computational cost.
</details>
<details>
<summary>摘要</summary>
我们证明随机森林的稳定性，具体来说是当响应值($Y^2$) 不具有极大的尾部时。我们的分析适用于实际的随机森林实现，如\texttt{randomForest} 在 \texttt{R} 中的实现。实际结果表明，稳定性可能会 persist 超过我们的假设，并且适用于重 tailed $Y^2$。使用稳定性质量，我们证明了预测间隔 constructed from 随机森林的 out-of-bag 错误的下界。另外，对于 continuous $Y$ 的情况，我们还设立了一个轻量级的条件，并证明了这个下界。我们还讨论了先前文献中考虑的假设下的极限覆盖率。我们的工作 imply 随机森林，具有稳定性质量，是一种有效的机器学习方法，可以不仅提供满意的点预测，还可以提供正确的间预测，而且只需要一些较少的计算成本。
</details></li>
</ul>
<hr>
<h2 id="The-Synergy-of-Speculative-Decoding-and-Batching-in-Serving-Large-Language-Models"><a href="#The-Synergy-of-Speculative-Decoding-and-Batching-in-Serving-Large-Language-Models" class="headerlink" title="The Synergy of Speculative Decoding and Batching in Serving Large Language Models"></a>The Synergy of Speculative Decoding and Batching in Serving Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18813">http://arxiv.org/abs/2310.18813</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qidong Su, Christina Giannoula, Gennady Pekhimenko</li>
<li>for: 这篇论文的目的是研究大语言模型（LLM）的批处理和预测解oding技术，以提高LLM的硬件利用率。</li>
<li>methods: 这篇论文使用了批处理和预测解oding两种技术来提高LLM的硬件利用率。</li>
<li>results: 论文的实验结果表明，适当的预测 lengths 与批处理大小有关，而且提出了一种适应性的预测解oding策略，可以与现有的最佳化策略相比。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) like GPT are state-of-the-art text generation models that provide significant assistance in daily routines. However, LLM execution is inherently sequential, since they only produce one token at a time, thus incurring low hardware utilization on modern GPUs. Batching and speculative decoding are two techniques to improve GPU hardware utilization in LLM inference. To study their synergy, we implement a prototype implementation and perform an extensive characterization analysis on various LLM models and GPU architectures. We observe that the optimal speculation length depends on the batch size used. We analyze the key observation and build a quantitative model to explain it. Based on our analysis, we propose a new adaptive speculative decoding strategy that chooses the optimal speculation length for different batch sizes. Our evaluations show that our proposed method can achieve equal or better performance than the state-of-the-art speculation decoding schemes with fixed speculation length.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）如GPT是现在的文本生成模型，它们在日常 Routine 中提供了重要的帮助。然而，LLM 执行是Sequential 的，它们只生成一个 Token 在一次，从而导致现代 GPU 的硬件利用率低。批处和推测解码是两种技术来提高 LLM 执行的 GPU 硬件利用率。为了研究这两种技术的相互作用，我们实现了一个原型实现，并对不同的 LLM 模型和 GPU 架构进行了广泛的分析。我们发现，使用不同的批处大小时，最佳的推测长度会有所不同。我们分析了这一关键观察结果，并建立了一个量化的模型来解释它。根据我们的分析，我们提出了一种新的自适应推测解码策略，可以根据不同的批处大小选择最佳的推测长度。我们的评估表明，我们的提议方法可以与现有的最佳推测解码方法相当或更好的性能。
</details></li>
</ul>
<hr>
<h2 id="Inverse-distance-weighting-attention"><a href="#Inverse-distance-weighting-attention" class="headerlink" title="Inverse distance weighting attention"></a>Inverse distance weighting attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18805">http://arxiv.org/abs/2310.18805</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/calvinmccarter/idw-attention">https://github.com/calvinmccarter/idw-attention</a></li>
<li>paper_authors: Calvin McCarter</li>
<li>for: 这篇论文研究了取代透彩积 dot-product 注意力的negative-log of Euclidean distance 的效果。</li>
<li>methods: 这种注意力方式简化为 inverse distance weighting interpolation，并在简单的一层隐藏层网络和vanilla cross-entropy loss中进行训练，用于文本分类问题。</li>
<li>results: 研究发现，使用这种注意力方式可以生成一个包含原型的键矩阵和相应的 logits 的解释网络，并可以通过手动构建的特殊情况 прототипы进行低影响的特殊情况处理。<details>
<summary>Abstract</summary>
We report the effects of replacing the scaled dot-product (within softmax) attention with the negative-log of Euclidean distance. This form of attention simplifies to inverse distance weighting interpolation. Used in simple one hidden layer networks and trained with vanilla cross-entropy loss on classification problems, it tends to produce a key matrix containing prototypes and a value matrix with corresponding logits. We also show that the resulting interpretable networks can be augmented with manually-constructed prototypes to perform low-impact handling of special cases.
</details>
<details>
<summary>摘要</summary>
我们报告了在扩展点积（在满意函数中）中使用负欧几丁度的效果。这种注意力的形式简化为对距离权重 interpolating。在简单的一个隐藏层网络中使用，并使用普通的极值损失函数进行训练，它通常会生成一个包含原型的键矩阵和相应的 logits 矩阵。我们还示出了使用手动构造的特殊情况扩展的可行性，以便实现低影响的特殊情况处理。Note: "扩展点积" in Chinese is "扩展点积" (kuòzhè dòngshí), and "负欧几丁度" is "负欧几丁度" (fùōujìtiànduō).
</details></li>
</ul>
<hr>
<h2 id="Weakly-Coupled-Deep-Q-Networks"><a href="#Weakly-Coupled-Deep-Q-Networks" class="headerlink" title="Weakly Coupled Deep Q-Networks"></a>Weakly Coupled Deep Q-Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18803">http://arxiv.org/abs/2310.18803</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ibrahim El Shar, Daniel R. Jiang</li>
<li>for: 增强深度强化学习算法的性能在受约非常小的 Markov决策过程（WCMDP）中。</li>
<li>methods: 使用单一网络训练多个独立的 DQN “子代理”，每个子代理专门处理一个子问题，然后将其解决结果组合成最佳动作值的上界，以引导主 DQN 代理向优化尝试。</li>
<li>results: 在有多达 10 个子问题、3^10 个总动作和连续状态空间的设置下，与 DQN 和相关技术相比，WCDQN 在数值实验中显示更快的收敛速度。<details>
<summary>Abstract</summary>
We propose weakly coupled deep Q-networks (WCDQN), a novel deep reinforcement learning algorithm that enhances performance in a class of structured problems called weakly coupled Markov decision processes (WCMDP). WCMDPs consist of multiple independent subproblems connected by an action space constraint, which is a structural property that frequently emerges in practice. Despite this appealing structure, WCMDPs quickly become intractable as the number of subproblems grows. WCDQN employs a single network to train multiple DQN "subagents", one for each subproblem, and then combine their solutions to establish an upper bound on the optimal action value. This guides the main DQN agent towards optimality. We show that the tabular version, weakly coupled Q-learning (WCQL), converges almost surely to the optimal action value. Numerical experiments show faster convergence compared to DQN and related techniques in settings with as many as 10 subproblems, $3^{10}$ total actions, and a continuous state space.
</details>
<details>
<summary>摘要</summary>
我们提出了弱连结深度Q网络（WCDQN），一种新的深度训练学习算法，它在受限构造问题（WCMDP）中提高表现。WCMDP包含多个独立的子问题，连接在动作空间约束上，这是实际中常见的结构性特征。然而，随着子问题的数量增加，WCMDP很快就会变得无法应对。WCDQN使用单一网络来训练多个DQN“子代”，每个子代针对每个子问题进行训练，然后结合其解决方案以建立最佳动作值的Upper bound。这导引主DQN代向最佳解决方案。我们证明了这个 Tabular 版本，弱连结Q学习（WCQL），会逐渐趋向最佳动作值，并且在包含多达10个子问题、3^{10}个总动作和连续状态空间的numerical实验中比DQN和相关技术更快地趋向最佳解决方案。
</details></li>
</ul>
<hr>
<h2 id="A-Competitive-Algorithm-for-Agnostic-Active-Learning"><a href="#A-Competitive-Algorithm-for-Agnostic-Active-Learning" class="headerlink" title="A Competitive Algorithm for Agnostic Active Learning"></a>A Competitive Algorithm for Agnostic Active Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18786">http://arxiv.org/abs/2310.18786</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eric Price, Yihan Zhou</li>
<li>for: 这种纸是用于研究agnostic active learning的最佳算法，具体来说是用于任何二分类假设集$H$和分布$D_X$ over $X$中的输入。</li>
<li>methods: 我们采用了一种不同于现有的方法的approach，即使用splitting-based方法，以实现在$O(m^* \log |H|)$ queries中达到$O(\eta)$ error的目标。</li>
<li>results: 我们的算法可以与最佳算法匹配，即使在某些输入上有NP困难，我们的算法可以在$O(\log |H|)$ overhead下达到$O(\eta)$ error。<details>
<summary>Abstract</summary>
For some hypothesis classes and input distributions, active agnostic learning needs exponentially fewer samples than passive learning; for other classes and distributions, it offers little to no improvement. The most popular algorithms for agnostic active learning express their performance in terms of a parameter called the disagreement coefficient, but it is known that these algorithms are inefficient on some inputs.   We take a different approach to agnostic active learning, getting an algorithm that is competitive with the optimal algorithm for any binary hypothesis class $H$ and distribution $D_X$ over $X$. In particular, if any algorithm can use $m^*$ queries to get $O(\eta)$ error, then our algorithm uses $O(m^* \log |H|)$ queries to get $O(\eta)$ error. Our algorithm lies in the vein of the splitting-based approach of Dasgupta [2004], which gets a similar result for the realizable ($\eta = 0$) setting.   We also show that it is NP-hard to do better than our algorithm's $O(\log |H|)$ overhead in general.
</details>
<details>
<summary>摘要</summary>
For some hypothesis classes and input distributions, active agnostic learning needs exponentially fewer samples than passive learning; for other classes and distributions, it offers little to no improvement. The most popular algorithms for agnostic active learning express their performance in terms of a parameter called the disagreement coefficient, but it is known that these algorithms are inefficient on some inputs.  We take a different approach to agnostic active learning, getting an algorithm that is competitive with the optimal algorithm for any binary hypothesis class $H$ and distribution $D_X$ over $X$. In particular, if any algorithm can use $m^*$ queries to get $O(\eta)$ error, then our algorithm uses $O(m^* \log |H|)$ queries to get $O(\eta)$ error. Our algorithm is in the same vein as the splitting-based approach of Dasgupta [2004], which gets a similar result for the realizable ($\eta = 0$) setting.   We also prove that it is NP-hard to do better than our algorithm's $O(\log |H|)$ overhead in general.Note: The text has been translated using Simplified Chinese characters.
</details></li>
</ul>
<hr>
<h2 id="High-probability-Convergence-Bounds-for-Nonlinear-Stochastic-Gradient-Descent-Under-Heavy-tailed-Noise"><a href="#High-probability-Convergence-Bounds-for-Nonlinear-Stochastic-Gradient-Descent-Under-Heavy-tailed-Noise" class="headerlink" title="High-probability Convergence Bounds for Nonlinear Stochastic Gradient Descent Under Heavy-tailed Noise"></a>High-probability Convergence Bounds for Nonlinear Stochastic Gradient Descent Under Heavy-tailed Noise</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18784">http://arxiv.org/abs/2310.18784</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aleksandar Armacki, Pranay Sharma, Gauri Joshi, Dragana Bajovic, Dusan Jakovetic, Soummya Kar</li>
<li>for: 本文研究了一种广泛的非线性SGD方法的收敛性。</li>
<li>methods: 本文使用了高probability下的收敛性 bounds，并且可以涵盖大多数现有的非线性SGD方法，如clipping、normalization和quantization。</li>
<li>results: 对具有 lipschitz continuous 的梯度的强转换函数，本文证明了logarithmic的依赖于失败概率，而且可以在heavy-tailed noise下工作。此外，本文的结果比现有的结果更加广泛，可以涵盖更多的非线性SGD方法和不同的噪声分布。<details>
<summary>Abstract</summary>
Several recent works have studied the convergence \textit{in high probability} of stochastic gradient descent (SGD) and its clipped variant. Compared to vanilla SGD, clipped SGD is practically more stable and has the additional theoretical benefit of logarithmic dependence on the failure probability. However, the convergence of other practical nonlinear variants of SGD, e.g., sign SGD, quantized SGD and normalized SGD, that achieve improved communication efficiency or accelerated convergence is much less understood. In this work, we study the convergence bounds \textit{in high probability} of a broad class of nonlinear SGD methods. For strongly convex loss functions with Lipschitz continuous gradients, we prove a logarithmic dependence on the failure probability, even when the noise is heavy-tailed. Strictly more general than the results for clipped SGD, our results hold for any nonlinearity with bounded (component-wise or joint) outputs, such as clipping, normalization, and quantization. Further, existing results with heavy-tailed noise assume bounded $\eta$-th central moments, with $\eta \in (1,2]$. In contrast, our refined analysis works even for $\eta=1$, strictly relaxing the noise moment assumptions in the literature.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Data-driven-Recommendation-Framework-for-Optimal-Walker-Designs"><a href="#A-Data-driven-Recommendation-Framework-for-Optimal-Walker-Designs" class="headerlink" title="A Data-driven Recommendation Framework for Optimal Walker Designs"></a>A Data-driven Recommendation Framework for Optimal Walker Designs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18772">http://arxiv.org/abs/2310.18772</a></li>
<li>repo_url: None</li>
<li>paper_authors: Advaith Narayanan</li>
<li>for: 这篇论文旨在优化医疗步行器，以提高临床恢复和生理治疗下肢体的功能。</li>
<li>methods: 该论文使用自动化机器学习模型和栅Stacked-Ensemble方法，以优化医疗步行器的设计。同时，该论文还提供了大量的 Parametric walker 设计数据，以便训练预测模型。</li>
<li>results: 该论文的结果表明，通过使用自动化机器学习模型和多目标优化算法，可以实现高性能的医疗步行器设计。论文还提供了一些可能的医疗步行器设计，其中一些设计可以减轻重量达30%，同时提高结构稳定性和完整性。<details>
<summary>Abstract</summary>
The rapidly advancing fields of statistical modeling and machine learning have significantly enhanced data-driven design and optimization. This paper focuses on leveraging these design algorithms to optimize a medical walker, an integral part of gait rehabilitation and physiological therapy of the lower extremities. To achieve the desirable qualities of a walker, we train a predictive machine-learning model to identify trade-offs between performance objectives, thus enabling the use of efficient optimization algorithms. To do this, we use an Automated Machine Learning model utilizing a stacked-ensemble approach shown to outperform traditional ML models. However, training a predictive model requires vast amounts of data for accuracy. Due to limited publicly available walker designs, this paper presents a dataset of more than 5,000 parametric walker designs with performance values to assess mass, structural integrity, and stability. These performance values include displacement vectors for the given load case, stress coefficients, mass, and other physical properties. We also introduce a novel method of systematically calculating the stability index of a walker. We use MultiObjective Counterfactuals for Design (MCD), a novel genetic-based optimization algorithm, to explore the diverse 16-dimensional design space and search for high-performing designs based on numerous objectives. This paper presents potential walker designs that demonstrate up to a 30% mass reduction while increasing structural stability and integrity. This work takes a step toward the improved development of assistive mobility devices.
</details>
<details>
<summary>摘要</summary>
“随着统计模型和机器学习的快速进步，数据驱动设计和优化技术已经得到了很大的提高。本文将focus on 使用这些设计算法来优化医疗杆子，它是距离股体重abilitation和物理治疗的重要部分。为了实现杆子的欲望性能，我们将使用预测机器学习模型，以识别表现目标之间的贸易，并启用高效的优化算法。我们使用了自动化机器学习模型，使用堆叠合 ensemble 方法，已经被证明可以超越传统机器学习模型。然而，训练预测模型需要巨量的数据，以确保准确性。由于有限的公开可用的杆子设计，本文提供了超过5,000个 Parametric 杆子设计，并且包含表现值，以评估杆子的质量、结构完整性和稳定性。我们还引入了一新的稳定指数计算方法。我们使用多目标Counterfactuals for Design (MCD) ，一种新的基因型数据分析方法，来探索16个维度的设计空间，寻找高性能的设计。本文显示了可能的杆子设计，证明了可以降低30%的质量，同时增加结构的稳定性和完整性。这个工作为伤健移动设备的改进做出了一步。”
</details></li>
</ul>
<hr>
<h2 id="Rethinking-Semi-Supervised-Imbalanced-Node-Classification-from-Bias-Variance-Decomposition"><a href="#Rethinking-Semi-Supervised-Imbalanced-Node-Classification-from-Bias-Variance-Decomposition" class="headerlink" title="Rethinking Semi-Supervised Imbalanced Node Classification from Bias-Variance Decomposition"></a>Rethinking Semi-Supervised Imbalanced Node Classification from Bias-Variance Decomposition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18765">http://arxiv.org/abs/2310.18765</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yanliang3612/revar">https://github.com/yanliang3612/revar</a></li>
<li>paper_authors: Divin Yan, Gengchen Wei, Chen Yang, Shengzhong Zhang, Zengfeng Huang</li>
<li>for:  Addressing the issue of class imbalance in graph neural networks (GNNs) for learning on graph-structured data.</li>
<li>methods:  Integrates imbalanced node classification and Bias-Variance Decomposition, leverages graph augmentation technique to estimate the variance, and designs a regularization term to alleviate the impact of imbalance.</li>
<li>results:  Outperforms state-of-the-art methods in various imbalanced scenarios, providing a novel theoretical perspective for addressing the problem of imbalanced node classification in GNNs.<details>
<summary>Abstract</summary>
This paper introduces a new approach to address the issue of class imbalance in graph neural networks (GNNs) for learning on graph-structured data. Our approach integrates imbalanced node classification and Bias-Variance Decomposition, establishing a theoretical framework that closely relates data imbalance to model variance. We also leverage graph augmentation technique to estimate the variance, and design a regularization term to alleviate the impact of imbalance. Exhaustive tests are conducted on multiple benchmarks, including naturally imbalanced datasets and public-split class-imbalanced datasets, demonstrating that our approach outperforms state-of-the-art methods in various imbalanced scenarios. This work provides a novel theoretical perspective for addressing the problem of imbalanced node classification in GNNs.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "GNNs" is translated as "图 нейрон网络" (graph neural networks)* "class imbalance" is translated as "类别不均衡" (class imbalance)* "Bias-Variance Decomposition" is translated as "偏差-差异分解" (Bias-Variance Decomposition)* "graph augmentation" is translated as "图补充" (graph augmentation)* "regularization term" is translated as "正则化项" (regularization term)Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and widely used in other countries as well. If you prefer Traditional Chinese, please let me know and I can provide the translation in that form as well.
</details></li>
</ul>
<hr>
<h2 id="Purify-Improving-Diffusion-Purification-with-Advanced-Diffusion-Models-and-Control-of-Randomness"><a href="#Purify-Improving-Diffusion-Purification-with-Advanced-Diffusion-Models-and-Control-of-Randomness" class="headerlink" title="Purify++: Improving Diffusion-Purification with Advanced Diffusion Models and Control of Randomness"></a>Purify++: Improving Diffusion-Purification with Advanced Diffusion Models and Control of Randomness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18762">http://arxiv.org/abs/2310.18762</a></li>
<li>repo_url: None</li>
<li>paper_authors: Boya Zhang, Weijian Luo, Zhihua Zhang</li>
<li>for: 防止神经网络分类器受到攻击的安全性研究</li>
<li>methods:  diffusion purification 方法</li>
<li>results: Purify++ 算法提高了对多种攻击方法的防御能力<details>
<summary>Abstract</summary>
Adversarial attacks can mislead neural network classifiers. The defense against adversarial attacks is important for AI safety. Adversarial purification is a family of approaches that defend adversarial attacks with suitable pre-processing. Diffusion models have been shown to be effective for adversarial purification. Despite their success, many aspects of diffusion purification still remain unexplored. In this paper, we investigate and improve upon three limiting designs of diffusion purification: the use of an improved diffusion model, advanced numerical simulation techniques, and optimal control of randomness. Based on our findings, we propose Purify++, a new diffusion purification algorithm that is now the state-of-the-art purification method against several adversarial attacks. Our work presents a systematic exploration of the limits of diffusion purification methods.
</details>
<details>
<summary>摘要</summary>
Adversarial attacks can mislead neural network classifiers. The defense against adversarial attacks is important for AI safety. Adversarial purification is a family of approaches that defend against adversarial attacks with suitable pre-processing. Diffusion models have been shown to be effective for adversarial purification. Despite their success, many aspects of diffusion purification still remain unexplored. In this paper, we investigate and improve upon three limiting designs of diffusion purification: the use of an improved diffusion model, advanced numerical simulation techniques, and optimal control of randomness. Based on our findings, we propose Purify++, a new diffusion purification algorithm that is now the state-of-the-art purification method against several adversarial attacks. Our work presents a systematic exploration of the limits of diffusion purification methods.Here's the translation in Simplified Chinese characters: adversarial attacks 可以诱导 нейрон网络分类器错误。防止 adversarial attacks 是 AI 安全的重要任务。adversarial purification 是一家 approachedefend against adversarial attacks with suitable pre-processing。diffusion models 已经被证明是有效的 adversarial purification 方法。despite their success, many aspects of diffusion purification still remain unexplored。在这篇 paper中，我们investigate 和改进 diffusion purification 的三个限制设计：使用改进的 diffusion model，进阶的数值 simulations 技术，和优化的随机性控制。基于我们的发现，我们提出 Purify++, 一个新的 diffusion purification 算法，现在是 severaldiffusion purification 方法的州际标准。our work 展示了 diffusion purification 方法的系统性探索。
</details></li>
</ul>
<hr>
<h2 id="Optimization-of-utility-based-shortfall-risk-A-non-asymptotic-viewpoint"><a href="#Optimization-of-utility-based-shortfall-risk-A-non-asymptotic-viewpoint" class="headerlink" title="Optimization of utility-based shortfall risk: A non-asymptotic viewpoint"></a>Optimization of utility-based shortfall risk: A non-asymptotic viewpoint</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18743">http://arxiv.org/abs/2310.18743</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sumedh Gupte, Prashanth L. A., Sanjay P. Bhat</li>
<li>for: 本文研究了金融领域中流量风险的评估和优化问题，具体来说是Utility-based shortfall risk（UBSR）的估计和优化问题。</li>
<li>methods: 本文使用了类型样本平均approximation（SAA）来估计UBSR，并 derive了非尺度性质 bound 的均方差误差。在UBSR优化问题中，本文 derive了UBSR导数的表达式，该表达式是一个期望比率，两个期望都 involve UBSR。使用SAA来 aproximate numerator和denominator中的UBSR，得到一个偏导数估计器。</li>
<li>results: 本文 derive non-尺度性质 bound 表示该偏导数估计器是 asymptotically unbiased。此外，本文还 derive non-尺度性质 bound 表示SG算法的速度减少率。<details>
<summary>Abstract</summary>
We consider the problems of estimation and optimization of utility-based shortfall risk (UBSR), which is a popular risk measure in finance. In the context of UBSR estimation, we derive a non-asymptotic bound on the mean-squared error of the classical sample average approximation (SAA) of UBSR. Next, in the context of UBSR optimization, we derive an expression for the UBSR gradient under a smooth parameterization. This expression is a ratio of expectations, both of which involve the UBSR. We use SAA for the numerator as well as denominator in the UBSR gradient expression to arrive at a biased gradient estimator. We derive non-asymptotic bounds on the estimation error, which show that our gradient estimator is asymptotically unbiased. We incorporate the aforementioned gradient estimator into a stochastic gradient (SG) algorithm for UBSR optimization. Finally, we derive non-asymptotic bounds that quantify the rate of convergence of our SG algorithm for UBSR optimization.
</details>
<details>
<summary>摘要</summary>
我们考虑了金融中流行的价值基础隐没隐危 (UBSR) 的估计和优化问题。在 UBSR 估计上，我们 derivated 一个非对数减少的 bound 为 classical sample average approximation (SAA) 的均方误差。在 UBSR 优化上，我们 derivated 一个表达式，用于 UBSR 的梯度，这个表达式是两个期望的比率，其中一个是 UBSR 的期望值。我们使用 SAA 来计算 numerator 和 denominator 两个部分，从而得到一个偏导数 estimator。我们 derivated 非对数减少的 bounds ，证明了我们的梯度 estimator 是 asymptotically unbiased。最后，我们 incorporated 这个梯度 estimator 到一个随机梯度 (SG) 算法中，并 derivated 非对数减少的 bounds 来评估这个算法的速度传递率。
</details></li>
</ul>
<hr>
<h2 id="Curriculum-Learning-for-Graph-Neural-Networks-Which-Edges-Should-We-Learn-First"><a href="#Curriculum-Learning-for-Graph-Neural-Networks-Which-Edges-Should-We-Learn-First" class="headerlink" title="Curriculum Learning for Graph Neural Networks: Which Edges Should We Learn First"></a>Curriculum Learning for Graph Neural Networks: Which Edges Should We Learn First</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18735">http://arxiv.org/abs/2310.18735</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rollingstonezz/curriculum_learning_for_gnns">https://github.com/rollingstonezz/curriculum_learning_for_gnns</a></li>
<li>paper_authors: Zheng Zhang, Junxiang Wang, Liang Zhao</li>
<li>For: 本文提出了一种新的课程学习策略，用于逐渐将图数据中的边 integrate 到训练中，以提高图 neural network 的泛化能力和Robustness。* Methods: 本文提出了一种基于课程学习的策略，使用了度量学习策略来衡量边的难度，并逐渐将边添加到训练中，以便学习更好的表示。* Results: 经过EXTENSIVE experiments on nine synthetic datasets and nine real-world datasets, 本文 Demonstrated the strength of the proposed method in improving the generalization ability and robustness of learned representations.<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have achieved great success in representing data with dependencies by recursively propagating and aggregating messages along the edges. However, edges in real-world graphs often have varying degrees of difficulty, and some edges may even be noisy to the downstream tasks. Therefore, existing GNNs may lead to suboptimal learned representations because they usually treat every edge in the graph equally. On the other hand, Curriculum Learning (CL), which mimics the human learning principle of learning data samples in a meaningful order, has been shown to be effective in improving the generalization ability and robustness of representation learners by gradually proceeding from easy to more difficult samples during training. Unfortunately, existing CL strategies are designed for independent data samples and cannot trivially generalize to handle data dependencies. To address these issues, we propose a novel CL strategy to gradually incorporate more edges into training according to their difficulty from easy to hard, where the degree of difficulty is measured by how well the edges are expected given the model training status. We demonstrate the strength of our proposed method in improving the generalization ability and robustness of learned representations through extensive experiments on nine synthetic datasets and nine real-world datasets. The code for our proposed method is available at https://github.com/rollingstonezz/Curriculum_learning_for_GNNs.
</details>
<details>
<summary>摘要</summary>
graph neural networks (GNNs) 图神网络已经取得了很大的成功，通过 recursively propagating 和 aggregating 消息来表示具有依赖关系的数据。然而，实际世界中的图 often have varying degrees of difficulty, and some edges may even be noisy to the downstream tasks.因此，现有的 GNN 可能会导致学习的表示不佳，因为它们通常对每个图边进行平等的处理。在另一个面向，curriculum learning (CL)，模仿人类学习的原理，可以在训练过程中逐渐从易到更加复杂的样本中学习，从而提高学习的普适性和鲁棒性。然而，现有的 CL 策略是为独立的数据样本设计的，无法直接扩展到处理数据依赖关系。为解决这些问题，我们提出了一种新的 CL 策略，通过度量图边的难度从易到更加困难地慢慢地包含更多的图边到训练中，其中图边的难度通过模型训练状态来评估。我们通过对九个Synthetic数据集和九个实际世界数据集进行了广泛的实验，证明了我们的提议的方法能够提高学习的普适性和鲁棒性。code  для我们的提议方法可以在 https://github.com/rollingstonezz/Curriculum_learning_for_GNNs 找到。
</details></li>
</ul>
<hr>
<h2 id="Latent-class-analysis-by-regularized-spectral-clustering"><a href="#Latent-class-analysis-by-regularized-spectral-clustering" class="headerlink" title="Latent class analysis by regularized spectral clustering"></a>Latent class analysis by regularized spectral clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18727">http://arxiv.org/abs/2310.18727</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huan Qing</li>
<li>for: 这篇论文的目的是提出两种新的算法来估计 categorical 数据中的潜在类型模型。</li>
<li>methods: 这两种算法都基于一个新定义的规范化拉普拉斯矩阵，计算从响应矩阵中获得的。作者提供了这些算法的理论收敛速率，并证明了它们在某些轻度的条件下稳定地生成了一致的潜在类型分析。</li>
<li>results: 作者通过了广泛的 simulations 实验来证明算法的效率和准确性，并在实际的 categorical 数据上应用了这些算法，获得了有前途的结果。<details>
<summary>Abstract</summary>
The latent class model is a powerful tool for identifying latent classes within populations that share common characteristics for categorical data in social, psychological, and behavioral sciences. In this article, we propose two new algorithms to estimate a latent class model for categorical data. Our algorithms are developed by using a newly defined regularized Laplacian matrix calculated from the response matrix. We provide theoretical convergence rates of our algorithms by considering a sparsity parameter and show that our algorithms stably yield consistent latent class analysis under mild conditions. Additionally, we propose a metric to capture the strength of latent class analysis and several procedures designed based on this metric to infer how many latent classes one should use for real-world categorical data. The efficiency and accuracy of our algorithms are verified by extensive simulated experiments, and we further apply our algorithms to real-world categorical data with promising results.
</details>
<details>
<summary>摘要</summary>
“拉丁类模型是一种强大的工具，用于在人口中找到共同特征的分类数据的社会、心理和行为科学中。在这篇文章中，我们提出了两种新的算法，用于估计拉丁类模型。我们的算法基于响应矩阵中定义的新的规范化拉普拉斯矩阵。我们提供了对我们的算法的理论收敛率，并证明我们的算法在轻度条件下稳定地生成了一致的拉丁类分析。此外，我们还提出了一个用于捕捉拉丁类分析的强度的度量，以及基于这个度量的几种过程，用于在实际中的分类数据中决定拉丁类的数量。我们的算法的效率和准确性通过了广泛的模拟实验，并在实际中应用到了分类数据的成功。”Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="On-the-Accuracy-of-Hotelling-Type-Asymmetric-Tensor-Deflation-A-Random-Tensor-Analysis"><a href="#On-the-Accuracy-of-Hotelling-Type-Asymmetric-Tensor-Deflation-A-Random-Tensor-Analysis" class="headerlink" title="On the Accuracy of Hotelling-Type Asymmetric Tensor Deflation: A Random Tensor Analysis"></a>On the Accuracy of Hotelling-Type Asymmetric Tensor Deflation: A Random Tensor Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18717">http://arxiv.org/abs/2310.18717</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohamed El Amine Seddik, Maxime Guillaud, Alexis Decurninge, José Henrique de Morais Goulart</li>
<li>For: This paper studies the asymptotic behavior of Hotelling-type tensor deflation in the presence of noise, specifically in the regime of large tensor dimensions.* Methods: The paper uses recent advances in random tensor theory to analytically characterize the estimated singular values and the alignment of estimated and true singular vectors at each step of the deflation procedure.* Results: The paper shows that the estimated singular values and the alignments between the estimated and true rank-1 signal components can be used to construct estimators of the signal-to-noise ratios and the alignments between the estimated and true rank-1 signal components.<details>
<summary>Abstract</summary>
This work introduces an asymptotic study of Hotelling-type tensor deflation in the presence of noise, in the regime of large tensor dimensions. Specifically, we consider a low-rank asymmetric tensor model of the form $\sum_{i=1}^r \beta_i{\mathcal{A}_i + {\mathcal{W}$ where $\beta_i\geq 0$ and the ${\mathcal{A}_i$'s are unit-norm rank-one tensors such that $\left| \langle {\mathcal{A}_i, {\mathcal{A}_j \rangle \right| \in [0, 1]$ for $i\neq j$ and ${\mathcal{W}$ is an additive noise term. Assuming that the dominant components are successively estimated from the noisy observation and subsequently subtracted, we leverage recent advances in random tensor theory in the regime of asymptotically large tensor dimensions to analytically characterize the estimated singular values and the alignment of estimated and true singular vectors at each step of the deflation procedure. Furthermore, this result can be used to construct estimators of the signal-to-noise ratios $\beta_i$ and the alignments between the estimated and true rank-1 signal components.
</details>
<details>
<summary>摘要</summary>
The proposed method involves successively estimating the dominant components of the tensor and subtracting them from the noisy observation. By leveraging recent advances in random tensor theory, the paper analytically characterizes the estimated singular values and the alignment of estimated and true singular vectors at each step of the deflation procedure.Furthermore, the results can be used to construct estimators of the signal-to-noise ratios $\beta_i$ and the alignments between the estimated and true rank-1 signal components. This study provides a comprehensive understanding of the behavior of Hotelling-type tensor deflation in the presence of noise and its applications in signal processing and machine learning.In Simplified Chinese, the text can be translated as:这个研究介绍了一种幂等式抑制方法在噪声存在的情况下进行研究，具体来说是在大tensor维度下进行研究。这个模型是一个低维偏 asymmetric tensor的形式，具体来说是 $\sum_{i=1}^r \beta_i{\mathcal{A}_i + {\mathcal{W}$，其中 $\beta_i\geq 0$ 和 $\left| \langle {\mathcal{A}_i, {\mathcal{A}_j \rangle \right| \in [0, 1]$  для $i\neq j$。噪声是一个加itive的。该方法假设在噪声观测下，逐步估计主要组分，并将其从噪声观测中 subtract。通过利用最近的幂等式理论，这篇论文分析了在噪声存在下的逐步估计方法的特性。此外，这些结果还可以用于构建噪声比例和真实维度方向的估计器。这种方法的应用包括信号处理和机器学习等领域。通过这篇论文，我们可以更好地理解幂等式抑制方法在噪声存在下的行为，以及其在实际应用中的可行性和有效性。
</details></li>
</ul>
<hr>
<h2 id="Laplacian-Canonization-A-Minimalist-Approach-to-Sign-and-Basis-Invariant-Spectral-Embedding"><a href="#Laplacian-Canonization-A-Minimalist-Approach-to-Sign-and-Basis-Invariant-Spectral-Embedding" class="headerlink" title="Laplacian Canonization: A Minimalist Approach to Sign and Basis Invariant Spectral Embedding"></a>Laplacian Canonization: A Minimalist Approach to Sign and Basis Invariant Spectral Embedding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18716">http://arxiv.org/abs/2310.18716</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pku-ml/laplaciancanonization">https://github.com/pku-ml/laplaciancanonization</a></li>
<li>paper_authors: Jiangyan Ma, Yifei Wang, Yisen Wang</li>
<li>for: 提高 Graph Transformers 的效果，解决spectral embedding在理论上的缺陷</li>
<li>methods: 直接找到 Laplacian Canonization（LC），一种轻量级的预处理方法，可以应用于任何现有的 GNN</li>
<li>results: MAP 算法可以成功 canonize 超过 90% 的 eigenvectors，并在实验中表现出色，与现有方法相比带来较少的计算开销。<details>
<summary>Abstract</summary>
Spectral embedding is a powerful graph embedding technique that has received a lot of attention recently due to its effectiveness on Graph Transformers. However, from a theoretical perspective, the universal expressive power of spectral embedding comes at the price of losing two important invariance properties of graphs, sign and basis invariance, which also limits its effectiveness on graph data. To remedy this issue, many previous methods developed costly approaches to learn new invariants and suffer from high computation complexity. In this work, we explore a minimal approach that resolves the ambiguity issues by directly finding canonical directions for the eigenvectors, named Laplacian Canonization (LC). As a pure pre-processing method, LC is light-weighted and can be applied to any existing GNNs. We provide a thorough investigation, from theory to algorithm, on this approach, and discover an efficient algorithm named Maximal Axis Projection (MAP) that works for both sign and basis invariance and successfully canonizes more than 90% of all eigenvectors. Experiments on real-world benchmark datasets like ZINC, MOLTOX21, and MOLPCBA show that MAP consistently outperforms existing methods while bringing minimal computation overhead. Code is available at https://github.com/PKU-ML/LaplacianCanonization.
</details>
<details>
<summary>摘要</summary>
干扰 embedding 是一种强大的图 embedding 技术，在图transformer 中得到了很多关注，但从理论角度来看，它的通用表达力来到了两个重要的对称性问题的价格，即标志对称性和基准对称性，这也限制了它在图数据上的效果。为了解决这个问题，许多前一代的方法开发了昂贵的方法来学习新的对称性，并且受到高计算复杂度的困扰。在这种情况下，我们 explore 一种最小的方法，即laplacian canonization (LC)，它可以直接找到图laplacian 的可 canonical 方向。作为一种纯粹的预处理方法，LC 轻量级，可以应用于任何现有的 GNNs。我们提供了一份 thorought 的调查，从理论到算法，对这种方法，并发现了一种高效的算法 named Maximal Axis Projection (MAP)，它可以实现标志对称性和基准对称性，并成功 canonize 超过 90% 的所有 eigenvectors。实验结果表明，MAP 在实际 benchmark 数据上（如 ZINC、MOLTOX21 和 MOLPCBA） consistently 超过现有方法，同时带来最小的计算开销。代码可以在 https://github.com/PKU-ML/LaplacianCanonization 上找到。
</details></li>
</ul>
<hr>
<h2 id="Episodic-Multi-Task-Learning-with-Heterogeneous-Neural-Processes"><a href="#Episodic-Multi-Task-Learning-with-Heterogeneous-Neural-Processes" class="headerlink" title="Episodic Multi-Task Learning with Heterogeneous Neural Processes"></a>Episodic Multi-Task Learning with Heterogeneous Neural Processes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18713">http://arxiv.org/abs/2310.18713</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/autumn9999/hnps">https://github.com/autumn9999/hnps</a></li>
<li>paper_authors: Jiayi Shen, Xiantong Zhen, Qi, Wang, Marcel Worring</li>
<li>for: 本研究旨在解决多任务学习中的数据不足问题，具体来说是在 episodic 训练设置下利用任务之间的不同信息和 episoden 中的元知识，以有效地处理每个任务。</li>
<li>methods: 我们开发了异 heterogeneous Neural Processes (HNPs) 来解决这个问题，它们在层次 Bayes 框架中有效地利用先前经验作为元知识，捕捉任务之间的相互关系，从而 mitigate 数据不足。 transformer 结构的推理模块也是为了快速地进行元知识和任务相关性的推理。</li>
<li>results: 实验结果表明我们的提案的 HNPs 在比较基eline的情况下表现出色，并且对减少数据不足的影响进行了证明。 简化 Studios 中的结果也验证了我们设计的推理模块的有效性。<details>
<summary>Abstract</summary>
This paper focuses on the data-insufficiency problem in multi-task learning within an episodic training setup. Specifically, we explore the potential of heterogeneous information across tasks and meta-knowledge among episodes to effectively tackle each task with limited data. Existing meta-learning methods often fail to take advantage of crucial heterogeneous information in a single episode, while multi-task learning models neglect reusing experience from earlier episodes. To address the problem of insufficient data, we develop Heterogeneous Neural Processes (HNPs) for the episodic multi-task setup. Within the framework of hierarchical Bayes, HNPs effectively capitalize on prior experiences as meta-knowledge and capture task-relatedness among heterogeneous tasks, mitigating data-insufficiency. Meanwhile, transformer-structured inference modules are designed to enable efficient inferences toward meta-knowledge and task-relatedness. In this way, HNPs can learn more powerful functional priors for adapting to novel heterogeneous tasks in each meta-test episode. Experimental results show the superior performance of the proposed HNPs over typical baselines, and ablation studies verify the effectiveness of the designed inference modules.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ALERTA-Net-A-Temporal-Distance-Aware-Recurrent-Networks-for-Stock-Movement-and-Volatility-Prediction"><a href="#ALERTA-Net-A-Temporal-Distance-Aware-Recurrent-Networks-for-Stock-Movement-and-Volatility-Prediction" class="headerlink" title="ALERTA-Net: A Temporal Distance-Aware Recurrent Networks for Stock Movement and Volatility Prediction"></a>ALERTA-Net: A Temporal Distance-Aware Recurrent Networks for Stock Movement and Volatility Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18706">http://arxiv.org/abs/2310.18706</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hao1zhao/alerta-net">https://github.com/hao1zhao/alerta-net</a></li>
<li>paper_authors: Shengkun Wang, YangXiao Bai, Kaiqun Fu, Linhan Wang, Chang-Tien Lu, Taoran Ji</li>
<li>for: 预测股市运动和不稳定性	+ 投资者和 policymakers 都需要准确预测股市，作为经济健康指标</li>
<li>methods:  integrate sentiment analysis, macroeconomic indicators, search engine data, and historical prices within a multi-attention deep learning model	+ 利用社交媒体数据，具有丰富的公众情感信息，以增强股市预测的准确性</li>
<li>results: state-of-the-art performance using a dataset specifically curated for predicting stock market movements and volatility	+ 我们的提议模型在使用自定义的数据集后，实现了股市运动和不稳定性预测的状态oke-of-the-art表现<details>
<summary>Abstract</summary>
For both investors and policymakers, forecasting the stock market is essential as it serves as an indicator of economic well-being. To this end, we harness the power of social media data, a rich source of public sentiment, to enhance the accuracy of stock market predictions. Diverging from conventional methods, we pioneer an approach that integrates sentiment analysis, macroeconomic indicators, search engine data, and historical prices within a multi-attention deep learning model, masterfully decoding the complex patterns inherent in the data. We showcase the state-of-the-art performance of our proposed model using a dataset, specifically curated by us, for predicting stock market movements and volatility.
</details>
<details>
<summary>摘要</summary>
für both investors und policymakers ist die prognose des aktienmarktes essenziell, da er als indicator für die wirtschaftliche well-being dient. um diese herausforderung zu meistern, nutzen wir die kraft von sozialen medien-daten, ein reiches quell von öffentlicher meinung, um die genauigkeit der aktienmarkt-vorhersagen zu verbessern. im Gegensatz zu conventional methods, entwickeln wir eine ansprechung, die sentiment-analyse, makroökonomische indicatoren, suchmaschine-daten und historische preise in einem multi-attention-tiefen lernmodell integriert, das die komplexen muster im data meisterlich decodiert. wir zeigen die state-of-the-art-leistung unseres vorgeschlagenen modells anhand einer datenbasis, die von uns speziell für die vorhersage von aktienmarkt-bewegungen und -volatilität sammeln.
</details></li>
</ul>
<hr>
<h2 id="Explaining-by-Imitating-Understanding-Decisions-by-Interpretable-Policy-Learning"><a href="#Explaining-by-Imitating-Understanding-Decisions-by-Interpretable-Policy-Learning" class="headerlink" title="Explaining by Imitating: Understanding Decisions by Interpretable Policy Learning"></a>Explaining by Imitating: Understanding Decisions by Interpretable Policy Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.19831">http://arxiv.org/abs/2310.19831</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alihanhyk/interpole">https://github.com/alihanhyk/interpole</a></li>
<li>paper_authors: Alihan Hüyük, Daniel Jarrett, Mihaela van der Schaar</li>
<li>for: 这个论文是为了理解人类决策行为的概念模型，以便提高决策过程的透明度和负责任性。</li>
<li>methods: 这个论文提出了一种基于 bayesian 方法的可解释政策学习方法（Interpole），可以同时估计决策者的（可能偏袋）信念更新过程和决策策略。</li>
<li>results: 通过在模拟和真实世界数据上进行实验，论文示出了该方法的可能作为决策过程的调查、评估和理解的潜在价值。<details>
<summary>Abstract</summary>
Understanding human behavior from observed data is critical for transparency and accountability in decision-making. Consider real-world settings such as healthcare, in which modeling a decision-maker's policy is challenging -- with no access to underlying states, no knowledge of environment dynamics, and no allowance for live experimentation. We desire learning a data-driven representation of decision-making behavior that (1) inheres transparency by design, (2) accommodates partial observability, and (3) operates completely offline. To satisfy these key criteria, we propose a novel model-based Bayesian method for interpretable policy learning ("Interpole") that jointly estimates an agent's (possibly biased) belief-update process together with their (possibly suboptimal) belief-action mapping. Through experiments on both simulated and real-world data for the problem of Alzheimer's disease diagnosis, we illustrate the potential of our approach as an investigative device for auditing, quantifying, and understanding human decision-making behavior.
</details>
<details>
<summary>摘要</summary>
理解人类行为从观察数据中是决策过程中的关键，以确保决策过程中的透明度和负责任。在实际场景中，如医疗行业，模型决策者的政策非常困难，因为无法访问基础状态、环境动力学不明确、无法进行实际实验。我们希望通过学习数据驱动的方法学习决策行为，以满足以下三个关键需求：1. 具有透明度设计，以便理解决策过程中的决策因素。2. 可以处理部分可见性，以适应决策过程中的不同情况。3. 完全没有线上运行，以便在决策过程中进行实时调整。为了满足这些需求，我们提出了一种新的模型基于概率方法，即“Interpole”，可以同时估算决策者的（可能偏见的）信念更新过程和（可能不优的）信念行为映射。通过在模拟和实际数据上进行实验，我们证明了我们的方法可以作为决策过程的调查、评估和理解人类决策行为的调查工具。
</details></li>
</ul>
<hr>
<h2 id="Towards-Combinatorial-Generalization-for-Catalysts-A-Kohn-Sham-Charge-Density-Approach"><a href="#Towards-Combinatorial-Generalization-for-Catalysts-A-Kohn-Sham-Charge-Density-Approach" class="headerlink" title="Towards Combinatorial Generalization for Catalysts: A Kohn-Sham Charge-Density Approach"></a>Towards Combinatorial Generalization for Catalysts: A Kohn-Sham Charge-Density Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18702">http://arxiv.org/abs/2310.18702</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ppope/rho-learn">https://github.com/ppope/rho-learn</a></li>
<li>paper_authors: Phillip Pope, David Jacobs</li>
<li>for: 本研究旨在探讨一种基于点wise学习的Kohn-Sham充电密度模型，以实现对新材料的预测和设计。</li>
<li>methods: 本研究使用了点wise学习方法，学习了 bulk catalysts 的充电密度，并在新的材料结构中进行了探索和预测。</li>
<li>results: 研究发现，使用点wise学习方法可以实现对新材料的预测和设计，并且可以在多种元素组合下实现 combinatorial 泛化。测试结果显示，超过 80% 的二元和三元测试样本在使用点wise学习方法下可以更快地达到稳定状态，相比标准基线下降减13%的迭代次数，这可能是独立的兴趣点。<details>
<summary>Abstract</summary>
The Kohn-Sham equations underlie many important applications such as the discovery of new catalysts. Recent machine learning work on catalyst modeling has focused on prediction of the energy, but has so far not yet demonstrated significant out-of-distribution generalization. Here we investigate another approach based on the pointwise learning of the Kohn-Sham charge-density. On a new dataset of bulk catalysts with charge densities, we show density models can generalize to new structures with combinations of elements not seen at train time, a form of combinatorial generalization. We show that over 80% of binary and ternary test cases achieve faster convergence than standard baselines in Density Functional Theory, amounting to an average reduction of 13% in the number of iterations required to reach convergence, which may be of independent interest. Our results suggest that density learning is a viable alternative, trading greater inference costs for a step towards combinatorial generalization, a key property for applications.
</details>
<details>
<summary>摘要</summary>
金ohn-Sham方程在许多重要应用中发挥重要作用，如新 catalyst 的发现。现代机器学习方法在 catalyst 模型化中的 Prediction of energy 方面已经受到了重点研究，但是迄今为止并没有显示出significant out-of-distribution generalization。我们在这里 investigate 一种基于点wise learning of Kohn-Sham charge-density 的方法。使用新的 bulk catalysts with charge densities 数据集，我们显示了 density models 可以generalize 到新的结构，包括元素的组合不同于训练时间，这种 combinatorial generalization。我们表明了超过 80% 的 binary 和 ternary test cases 在 Density Functional Theory 中比标准基elines 更快 converges，平均降低了13%的迭代次数，这可能是独立的 interesseting。我们的结果表明了 density learning 是一种可行的alternative，通过更大的推理成本换取了 combinatorial generalization，一种重要的应用特性。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Algorithms-for-Generalized-Linear-Bandits-with-Heavy-tailed-Rewards"><a href="#Efficient-Algorithms-for-Generalized-Linear-Bandits-with-Heavy-tailed-Rewards" class="headerlink" title="Efficient Algorithms for Generalized Linear Bandits with Heavy-tailed Rewards"></a>Efficient Algorithms for Generalized Linear Bandits with Heavy-tailed Rewards</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18701">http://arxiv.org/abs/2310.18701</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bo Xue, Yimu Wang, Yuanyu Wan, Jinfeng Yi, Lijun Zhang</li>
<li>For:  investigate the problem of generalized linear bandits with heavy-tailed rewards, and propose two novel algorithms based on truncation and mean of medians to address this issue.* Methods:  propose two algorithms, one based on truncation and the other based on mean of medians, to achieve an almost optimal regret bound of $\widetilde{O}(dT^{\frac{1}{1+\epsilon})$ with online learning support and lower computational complexity.* Results:  improve the regret bounds by a logarithmic factor compared to existing algorithms when $\epsilon&#x3D;1$, and confirm the merits of the proposed algorithms through numerical experimental results.<details>
<summary>Abstract</summary>
This paper investigates the problem of generalized linear bandits with heavy-tailed rewards, whose $(1+\epsilon)$-th moment is bounded for some $\epsilon\in (0,1]$. Although there exist methods for generalized linear bandits, most of them focus on bounded or sub-Gaussian rewards and are not well-suited for many real-world scenarios, such as financial markets and web-advertising. To address this issue, we propose two novel algorithms based on truncation and mean of medians. These algorithms achieve an almost optimal regret bound of $\widetilde{O}(dT^{\frac{1}{1+\epsilon})$, where $d$ is the dimension of contextual information and $T$ is the time horizon. Our truncation-based algorithm supports online learning, distinguishing it from existing truncation-based approaches. Additionally, our mean-of-medians-based algorithm requires only $O(\log T)$ rewards and one estimator per epoch, making it more practical. Moreover, our algorithms improve the regret bounds by a logarithmic factor compared to existing algorithms when $\epsilon=1$. Numerical experimental results confirm the merits of our algorithms.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Clairvoyance-A-Pipeline-Toolkit-for-Medical-Time-Series"><a href="#Clairvoyance-A-Pipeline-Toolkit-for-Medical-Time-Series" class="headerlink" title="Clairvoyance: A Pipeline Toolkit for Medical Time Series"></a>Clairvoyance: A Pipeline Toolkit for Medical Time Series</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18688">http://arxiv.org/abs/2310.18688</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vanderschaarlab/clairvoyance">https://github.com/vanderschaarlab/clairvoyance</a></li>
<li>paper_authors: Daniel Jarrett, Jinsung Yoon, Ioana Bica, Zhaozhi Qian, Ari Ercole, Mihaela van der Schaar</li>
<li>for: 这个研究旨在提供一个统一的、端到端的、自动机器学习（AutoML）友好的数据驱动医疗决策支持系统，以便在实际医疗过程中与患者互动，提供适应性强的预测和决策支持。</li>
<li>methods: 这个系统使用了许多Machine Learning（ML）技术，包括数据预processing、缺失数据填充、特征选择、预测和不确定性估计等。</li>
<li>results: 这个系统可以在实际医疗应用中实现高度自动化的数据驱动医疗决策支持，并且可以在不同的医疗设置中进行适应性强的预测和决策支持。<details>
<summary>Abstract</summary>
Time-series learning is the bread and butter of data-driven *clinical decision support*, and the recent explosion in ML research has demonstrated great potential in various healthcare settings. At the same time, medical time-series problems in the wild are challenging due to their highly *composite* nature: They entail design choices and interactions among components that preprocess data, impute missing values, select features, issue predictions, estimate uncertainty, and interpret models. Despite exponential growth in electronic patient data, there is a remarkable gap between the potential and realized utilization of ML for clinical research and decision support. In particular, orchestrating a real-world project lifecycle poses challenges in engineering (i.e. hard to build), evaluation (i.e. hard to assess), and efficiency (i.e. hard to optimize). Designed to address these issues simultaneously, Clairvoyance proposes a unified, end-to-end, autoML-friendly pipeline that serves as a (i) software toolkit, (ii) empirical standard, and (iii) interface for optimization. Our ultimate goal lies in facilitating transparent and reproducible experimentation with complex inference workflows, providing integrated pathways for (1) personalized prediction, (2) treatment-effect estimation, and (3) information acquisition. Through illustrative examples on real-world data in outpatient, general wards, and intensive-care settings, we illustrate the applicability of the pipeline paradigm on core tasks in the healthcare journey. To the best of our knowledge, Clairvoyance is the first to demonstrate viability of a comprehensive and automatable pipeline for clinical time-series ML.
</details>
<details>
<summary>摘要</summary>
时间序列学习是医疗数据驱动的严重症状支持的基础，最近几年的机器学习研究表明了各种医疗设置中的潜力。然而，医疗时间序列问题在实际应用中具有复杂的特性：它们包括数据预处理、缺失值填充、特征选择、预测 issuing、 uncertainty 估计和模型解释等多个组件的交互。尽管电子病人数据的增长呈指数型增长，但是在临床研究和决策支持中实现的潜力与可能性之间还存在巨大的差距。特别是在实际项目生命周期中，工程（即困难于建立）、评估（即困难于评估）和效率（即困难于优化）等问题具有挑战性。为了解决这些问题，Clairvoyance 提出了一个统一、端到端、自动化 ML 友好的管道，作为（i）软件工具包、（ii）实验标准和（iii）优化接口。我们的最终目标是使得医疗时间序列 ML 实际实践中的透明度和可重现性得到改善。通过使用实际数据来 illustrate 管道的应用，我们示例了医疗旅程中的核心任务，如个性化预测、治疗效果估计和信息获取。根据我们所知，Clairvoyance 是首个实现了Complex Inference Workflows 的综合和自动化管道的医疗时间序列 ML 项目。
</details></li>
</ul>
<hr>
<h2 id="DySurv-Dynamic-Deep-Learning-Model-for-Survival-Prediction-in-the-ICU"><a href="#DySurv-Dynamic-Deep-Learning-Model-for-Survival-Prediction-in-the-ICU" class="headerlink" title="DySurv: Dynamic Deep Learning Model for Survival Prediction in the ICU"></a>DySurv: Dynamic Deep Learning Model for Survival Prediction in the ICU</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18681">http://arxiv.org/abs/2310.18681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Munib Mesinovic, Peter Watkinson, Tingting Zhu</li>
<li>for: 这篇论文旨在提出一种基于深度学习的预测生存时间方法，以便在ICU中进行动态死亡风险预测。</li>
<li>methods: 这篇论文使用了一种名为 DySurv 的新型 conditional variational autoencoder-based 方法，使用了病人电子医疗纪录中的静态和时间序列数据来估计死亡风险。</li>
<li>results: 这篇论文的实验结果显示，DySurv 方法可以在标准库中对比其他方法表现出色，并且在实际患者数据库中进行了验证。 survival 估计的内在一致性和不同数据集中的稳定性都支持了这种动态深度学习模型在预测生存时间方法中的可靠性。<details>
<summary>Abstract</summary>
Survival analysis helps approximate underlying distributions of time-to-events which in the case of critical care like in the ICU can be a powerful tool for dynamic mortality risk prediction. Extending beyond the classical Cox model, deep learning techniques have been leveraged over the last years relaxing the many constraints of their counterparts from statistical methods. In this work, we propose a novel conditional variational autoencoder-based method called DySurv which uses a combination of static and time-series measurements from patient electronic health records in estimating risk of death dynamically in the ICU. DySurv has been tested on standard benchmarks where it outperforms most existing methods including other deep learning methods and we evaluate it on a real-world patient database from MIMIC-IV. The predictive capacity of DySurv is consistent and the survival estimates remain disentangled across different datasets supporting the idea that dynamic deep learning models based on conditional variational inference in multi-task cases can be robust models for survival analysis.
</details>
<details>
<summary>摘要</summary>
生存分析可以 aproximate 时间事件的下面分布，在 ICU 中可以是一种强大的动态死亡风险预测工具。在过去几年中，深度学习技术被应用于生存分析，超越了统计方法的多种限制。在这种工作中，我们提出了一种名为 DySurv 的新方法，使用患者电子医疗记录中的静态和时间序列测量来 dynamically 估算 ICU 中死亡风险。DySurv 已经在标准Benchmark上测试，与其他深度学习方法相比，它在大多数情况下表现出色，并在实际患者数据库中进行了评估。survival 预测的可靠性和预测值在不同数据集中保持分离，支持我们的想法，即基于 conditional variational inference 的动态深度学习模型在多任务情况下可以是Robust模型 для survival analysis。
</details></li>
</ul>
<hr>
<h2 id="Energy-Based-Models-for-Anomaly-Detection-A-Manifold-Diffusion-Recovery-Approach"><a href="#Energy-Based-Models-for-Anomaly-Detection-A-Manifold-Diffusion-Recovery-Approach" class="headerlink" title="Energy-Based Models for Anomaly Detection: A Manifold Diffusion Recovery Approach"></a>Energy-Based Models for Anomaly Detection: A Manifold Diffusion Recovery Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18677">http://arxiv.org/abs/2310.18677</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sangwoong Yoon, Young-Uk Jin, Yung-Kyun Noh, Frank C. Park</li>
<li>for: 这篇论文是用于侦测异常（Anomaly Detection）的新方法。</li>
<li>methods: 这篇论文使用的方法是把资料点推广到低维度构造中，然后使用EBM进行侦测。</li>
<li>results: 实验结果显示，这篇论文的方法可以在不同的资料类型和侦测任务中具有优秀的表现。<details>
<summary>Abstract</summary>
We present a new method of training energy-based models (EBMs) for anomaly detection that leverages low-dimensional structures within data. The proposed algorithm, Manifold Projection-Diffusion Recovery (MPDR), first perturbs a data point along a low-dimensional manifold that approximates the training dataset. Then, EBM is trained to maximize the probability of recovering the original data. The training involves the generation of negative samples via MCMC, as in conventional EBM training, but from a different distribution concentrated near the manifold. The resulting near-manifold negative samples are highly informative, reflecting relevant modes of variation in data. An energy function of MPDR effectively learns accurate boundaries of the training data distribution and excels at detecting out-of-distribution samples. Experimental results show that MPDR exhibits strong performance across various anomaly detection tasks involving diverse data types, such as images, vectors, and acoustic signals.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的能量基模型（EBM）训练方法，该方法利用数据中的低维结构。我们的算法，抽象扩散恢复（MPDR），首先将数据点扰动到一个低维抽象 manifold 上，然后通过 MCMC 生成负样本，与 convential EBM 训练中的负样本生成方式类似。但是，MPDR 使用的是一个集中在抽象 manifold 上的分布，从而生成了具有低维结构的负样本。这些近抽象 manifold 上的负样本具有高度信息richness，反映了数据中重要的变换模式。 MPDR 的能量函数可以准确地学习训练数据分布的边界，并且能够准确检测数据集外的异常样本。我们的实验结果显示，MPDR 在多种异常检测任务中表现出色，包括图像、向量和声音信号等数据类型。
</details></li>
</ul>
<hr>
<h2 id="Maximum-Independent-Set-Self-Training-through-Dynamic-Programming"><a href="#Maximum-Independent-Set-Self-Training-through-Dynamic-Programming" class="headerlink" title="Maximum Independent Set: Self-Training through Dynamic Programming"></a>Maximum Independent Set: Self-Training through Dynamic Programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18672">http://arxiv.org/abs/2310.18672</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lorenzo Brusca, Lars C. P. M. Quaedvlieg, Stratis Skoulakis, Grigorios G Chrysos, Volkan Cevher</li>
<li>for: 本文提出了一种基于图神经网络（GNN）的最大独立集（MIS）问题解决方案， drawing inspiration from dynamic programming（DP）。</li>
<li>methods: specifically, the authors propose a DP-like recursive algorithm based on GNNs that first constructs two smaller sub-graphs, predicts the one with the larger MIS, and then uses it in the next recursive call.</li>
<li>results: the authors provide numerical evidence showing the superiority of their method compared to prior methods in multiple synthetic and real-world datasets.<details>
<summary>Abstract</summary>
This work presents a graph neural network (GNN) framework for solving the maximum independent set (MIS) problem, inspired by dynamic programming (DP). Specifically, given a graph, we propose a DP-like recursive algorithm based on GNNs that firstly constructs two smaller sub-graphs, predicts the one with the larger MIS, and then uses it in the next recursive call. To train our algorithm, we require annotated comparisons of different graphs concerning their MIS size. Annotating the comparisons with the output of our algorithm leads to a self-training process that results in more accurate self-annotation of the comparisons and vice versa. We provide numerical evidence showing the superiority of our method vs prior methods in multiple synthetic and real-world datasets.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Causal-discovery-in-a-complex-industrial-system-A-time-series-benchmark"><a href="#Causal-discovery-in-a-complex-industrial-system-A-time-series-benchmark" class="headerlink" title="Causal discovery in a complex industrial system: A time series benchmark"></a>Causal discovery in a complex industrial system: A time series benchmark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18654">http://arxiv.org/abs/2310.18654</a></li>
<li>repo_url: None</li>
<li>paper_authors: Søren Wengel Mogensen, Karin Rathsman, Per Nilsson</li>
<li>for: 这篇论文是用来描述如何从观测数据中推断 causal structure的。</li>
<li>methods: 这篇论文使用了一种时间序列数据的 causal discovery 方法，并对真实的工业系统进行了测试。</li>
<li>results: 论文提供了一个industrial subsystem的 causal graph，并通过专家知识来构建了这个图。这个测试环境可以帮助开发 causal discovery 方法。<details>
<summary>Abstract</summary>
Causal discovery outputs a causal structure, represented by a graph, from observed data. For time series data, there is a variety of methods, however, it is difficult to evaluate these on real data as realistic use cases very rarely come with a known causal graph to which output can be compared. In this paper, we present a dataset from an industrial subsystem at the European Spallation Source along with its causal graph which has been constructed from expert knowledge. This provides a testbed for causal discovery from time series observations of complex systems, and we believe this can help inform the development of causal discovery methodology.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SSL-Framework-for-Causal-Inconsistency-between-Structures-and-Representations"><a href="#SSL-Framework-for-Causal-Inconsistency-between-Structures-and-Representations" class="headerlink" title="SSL Framework for Causal Inconsistency between Structures and Representations"></a>SSL Framework for Causal Inconsistency between Structures and Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18634">http://arxiv.org/abs/2310.18634</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hang Chen, Xinyu Yang, Keqing Du</li>
<li>for: 这篇论文旨在探讨深度学习和 causal discovery 之间的交叉束合，以揭示无法统计数据中的 causal 关系。</li>
<li>methods: 本文提出了一种针对无法统计数据的 intervention 策略和 causal consistency condition (CCC) 的理论发展，并设计了一个自然语言模型 (LLMs) 和一个监督特殊化模型 (SSMs) 的自动学习框架。</li>
<li>results: 该文通过大量实验证明了其方法的有效性，并在三个下游任务中进行了评估。<details>
<summary>Abstract</summary>
The cross-pollination of deep learning and causal discovery has catalyzed a burgeoning field of research seeking to elucidate causal relationships within non-statistical data forms like images, videos, and text. Such data, often being named `indefinite data', exhibit unique challenges-inconsistency between causal structure and representation, which are not common in conventional data forms. To tackle this issue, we theoretically develop intervention strategies suitable for indefinite data and derive causal consistency condition (CCC). Moreover, we design a self-supervised learning (SSL) framework that considers interventions as `views' and CCC as a `philosophy' with two implement examples on Supervised Specialized Models (SSMs) and Large Language Models (LLMs), respectively. To evaluate pure inconsistency manifestations, we have prepared the first high-quality causal dialogue dataset-Causalogue. Evaluations are also performed on three other downstream tasks. Extensive experimentation has substantiated the efficacy of our methodology, illuminating how CCC could potentially play an influential role in various fields.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将深度学习和 causal discovery 融合，激发了一个蓬勃的研究，旨在揭示非统计数据中的 causal 关系。这类数据，常被称为 "未定数据"，具有独特的挑战 -  causal 结构和表示之间的不一致。为解决这个问题，我们提出了适应于未定数据的干预策略和 causal 一致性条件（CCC）的理论发展。此外，我们还设计了一个基于自我监督学习（SSL）框架，在该框架中，干预被视为 "视图"，CCC 被视为 "哲学"，并在 Supervised Specialized Models (SSMs) 和 Large Language Models (LLMs) 中进行了两个实现例子。为了评估纯净的不一致现象，我们准备了首个高质量 causal 对话集 - Causalogue。此外，我们还在三个下游任务上进行了评估。广泛的实验证明了我们的方法的有效性，揭示了 CCC 在不同领域的可能发挥作用。
</details></li>
</ul>
<hr>
<h2 id="Explainable-Modeling-for-Wind-Power-Forecasting-A-Glass-Box-Approach-with-Exceptional-Accuracy"><a href="#Explainable-Modeling-for-Wind-Power-Forecasting-A-Glass-Box-Approach-with-Exceptional-Accuracy" class="headerlink" title="Explainable Modeling for Wind Power Forecasting: A Glass-Box Approach with Exceptional Accuracy"></a>Explainable Modeling for Wind Power Forecasting: A Glass-Box Approach with Exceptional Accuracy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18629">http://arxiv.org/abs/2310.18629</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenlong Liao, Fernando Porté-Agel, Jiannong Fang, Birgitte Bak-Jensen, Guangchun Ruan, Zhe Yang</li>
<li>for: 这篇论文旨在提出一个可读性高的风力预测模型，并且可以实现高精度的风力预测。</li>
<li>methods: 本论文使用了进步的人工智能技术（例如Gradient Boosting），创造了shape函数在预测模型中。这些函数可以将风力输出和输入特征之间的复杂非线性关系实现有效地映射。此外，预测模型还包括互动项，以实现输入特征之间的互动和联合作用。</li>
<li>results: 根据实验结果显示，提案的玻璃箱方法可以实现风力预测的可读性和高精度。对于全球和个别 perspective，这种方法都能够实现高精度的预测。此外，与大多数参考模型相比，玻璃箱方法表现更好，并且和最佳性能的神经网络相比，表现相当。因此，这种玻璃箱方法在可靠的风力预测中具有吸引力。<details>
<summary>Abstract</summary>
Machine learning models (e.g., neural networks) achieve high accuracy in wind power forecasting, but they are usually regarded as black boxes that lack interpretability. To address this issue, the paper proposes a glass-box approach that combines exceptional accuracy with transparency for wind power forecasting. Specifically, advanced artificial intelligence methods (e.g., gradient boosting) are innovatively employed to create shape functions within the forecasting model. These functions effectively map the intricate non-linear relationships between wind power output and input features. Furthermore, the forecasting model is enriched by incorporating interaction terms that adeptly capture interdependencies and synergies among the input features. Simulation results show that the proposed glass-box approach effectively interprets the results of wind power forecasting from both global and instance perspectives. Besides, it outperforms most benchmark models and exhibits comparable performance to the best-performing neural networks. This dual strength of transparency and high accuracy positions the proposed glass-box approach as a compelling choice for reliable wind power forecasting.
</details>
<details>
<summary>摘要</summary>
机器学习模型（如神经网络）可以实现高精度风力预测，但它们通常被视为黑盒模型，缺乏可读性。为解决这个问题，文章提出了一种玻璃盒方法，该方法结合了高精度和可读性来进行风力预测。具体来说，文章使用了进步的人工智能技术（如梯度提升）来创建shape函数在预测模型中。这些函数有效地映射了风力输出和输入特征之间的复杂非线性关系。此外，预测模型还被补充了交互项，以便精准地捕捉输入特征之间的互动和协同作用。 simulation结果显示，提议的玻璃盒方法可以从全局和实例两个角度进行可读性的风力预测，并且在大多数参考模型之上出performances，与最佳性能的神经网络相当。这种两种优点的玻璃盒方法因此成为可靠的风力预测的可靠选择。
</details></li>
</ul>
<hr>
<h2 id="Pessimistic-Off-Policy-Multi-Objective-Optimization"><a href="#Pessimistic-Off-Policy-Multi-Objective-Optimization" class="headerlink" title="Pessimistic Off-Policy Multi-Objective Optimization"></a>Pessimistic Off-Policy Multi-Objective Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18617">http://arxiv.org/abs/2310.18617</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shima Alizadeh, Aniruddha Bhargava, Karthick Gopalswamy, Lalit Jain, Branislav Kveton, Ge Liu</li>
<li>for: 这篇论文主要研究了多目标优化问题中，如何从现有策略收集的数据中提取多目标策略优化。</li>
<li>methods: 该论文提出了一种偏负估 estimator，基于对抗性折衣分数（IPS），用于估算多目标策略价值。这种估计器在理论和实验中都提高了对于naive IPS估计器。</li>
<li>results: 该论文的分析是通用的，可以应用于不同的IPS估计器和优化方法。偏负估 estimator可以通过policy gradient来优化，在所有实验中表现良好。<details>
<summary>Abstract</summary>
Multi-objective optimization is a type of decision making problems where multiple conflicting objectives are optimized. We study offline optimization of multi-objective policies from data collected by an existing policy. We propose a pessimistic estimator for the multi-objective policy values that can be easily plugged into existing formulas for hypervolume computation and optimized. The estimator is based on inverse propensity scores (IPS), and improves upon a naive IPS estimator in both theory and experiments. Our analysis is general, and applies beyond our IPS estimators and methods for optimizing them. The pessimistic estimator can be optimized by policy gradients and performs well in all of our experiments.
</details>
<details>
<summary>摘要</summary>
多目标优化是决策问题的一种，其中有多个矛盾的目标被优化。我们研究基于现有策略所采集的数据进行离线优化的多目标策略。我们提出了一种消极估计器，用于估计多目标策略的价值，这种估计器基于反抗概率分布（IPS），并在理论和实验中都有所改进。我们的分析涵盖了更广泛的领域，并不仅限于我们的IPS估计器和优化方法。这种消极估计器可以通过政策Gradient优化，在所有实验中表现良好。
</details></li>
</ul>
<hr>
<h2 id="Temporally-Disentangled-Representation-Learning-under-Unknown-Nonstationarity"><a href="#Temporally-Disentangled-Representation-Learning-under-Unknown-Nonstationarity" class="headerlink" title="Temporally Disentangled Representation Learning under Unknown Nonstationarity"></a>Temporally Disentangled Representation Learning under Unknown Nonstationarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18615">http://arxiv.org/abs/2310.18615</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiangchensong/nctrl">https://github.com/xiangchensong/nctrl</a></li>
<li>paper_authors: Xiangchen Song, Weiran Yao, Yewen Fan, Xinshuai Dong, Guangyi Chen, Juan Carlos Niebles, Eric Xing, Kun Zhang</li>
<li>for: 研究者们是想解决非站点的时序数据中 causal  represencing 问题，即在不具备辅助变量（如类别标签和&#x2F;或领域标识符）的情况下，可以准确分离 causally 相关的 latent 变量。</li>
<li>methods: 研究者们在这篇论文中提出了一种名为 NCTRL 的原则性估计框架，可以在非站点设置下，基于测量序列数据，重建时延 causal 变量并分离其关系。</li>
<li>results: 实验证明，NCTRL 方法可以可靠地分离时延 causal 变量，并且在不具备辅助变量的情况下，表现出明显的优势，超过了现有的基准值。<details>
<summary>Abstract</summary>
In unsupervised causal representation learning for sequential data with time-delayed latent causal influences, strong identifiability results for the disentanglement of causally-related latent variables have been established in stationary settings by leveraging temporal structure. However, in nonstationary setting, existing work only partially addressed the problem by either utilizing observed auxiliary variables (e.g., class labels and/or domain indexes) as side information or assuming simplified latent causal dynamics. Both constrain the method to a limited range of scenarios. In this study, we further explored the Markov Assumption under time-delayed causally related process in nonstationary setting and showed that under mild conditions, the independent latent components can be recovered from their nonlinear mixture up to a permutation and a component-wise transformation, without the observation of auxiliary variables. We then introduce NCTRL, a principled estimation framework, to reconstruct time-delayed latent causal variables and identify their relations from measured sequential data only. Empirical evaluations demonstrated the reliable identification of time-delayed latent causal influences, with our methodology substantially outperforming existing baselines that fail to exploit the nonstationarity adequately and then, consequently, cannot distinguish distribution shifts.
</details>
<details>
<summary>摘要</summary>
在不监督 causal 表示学习中，对时间延迟的 latent causal 影响进行了强大的可Identifiability 结果，在静止设置下，通过利用时间结构来恰当地识别 causally 相关的 latent 变量。然而，在不稳定设置下，现有的工作只是部分地解决了问题，可以通过利用观测的auxiliary变量（例如类别标签和/或domain标识符）作为副信息，或者假设简单的 latent causal 动力学。两者都限制方法只能在有限的情况下运行。在这项研究中，我们进一步探讨了在时间延迟 causally 相关的 Markov 假设在不稳定设置下，并证明了在某些轻度条件下，独立的 latent 分量可以从其非线性混合中重建，而无需观测 auxilary 变量。然后，我们引入 NCTRL，一种原则性的估计框架，来重建时间延迟的 latent causal 变量，并identify它们之间的关系，从测量的时间序列数据中。实验证明了我们的方法可靠地识别时间延迟的 latent causal 影响，并且substantially 超越了不充分利用不稳定性的现有基准值。
</details></li>
</ul>
<hr>
<h2 id="Efficient-kernel-surrogates-for-neural-network-based-regression"><a href="#Efficient-kernel-surrogates-for-neural-network-based-regression" class="headerlink" title="Efficient kernel surrogates for neural network-based regression"></a>Efficient kernel surrogates for neural network-based regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18612">http://arxiv.org/abs/2310.18612</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saad Qadeer, Andrew Engel, Adam Tsou, Max Vargas, Panos Stinis, Tony Chiang<br>for: 这篇论文的目的是为了解释深度神经网络（DNN）的效果和局限性，并提供一种低成本的估计方法。methods: 这篇论文使用了Randomly initialized DNNs和Conjugate Kernel（CK）来研究DNN的性能。results: 论文表明，CK可以作为NTK的低成本估计方法，并且在某些情况下可以超越NTK的性能。此外，论文还提供了一种改进DNN准确率的简单方法。<details>
<summary>Abstract</summary>
Despite their immense promise in performing a variety of learning tasks, a theoretical understanding of the effectiveness and limitations of Deep Neural Networks (DNNs) has so far eluded practitioners. This is partly due to the inability to determine the closed forms of the learned functions, making it harder to assess their precise dependence on the training data and to study their generalization properties on unseen datasets. Recent work has shown that randomly initialized DNNs in the infinite width limit converge to kernel machines relying on a Neural Tangent Kernel (NTK) with known closed form. These results suggest, and experimental evidence corroborates, that empirical kernel machines can also act as surrogates for finite width DNNs. The high computational cost of assembling the full NTK, however, makes this approach infeasible in practice, motivating the need for low-cost approximations. In the current work, we study the performance of the Conjugate Kernel (CK), an efficient approximation to the NTK that has been observed to yield fairly similar results. For the regression problem of smooth functions and classification using logistic regression, we show that the CK performance is only marginally worse than that of the NTK and, in certain cases, is shown to be superior. In particular, we establish bounds for the relative test losses, verify them with numerical tests, and identify the regularity of the kernel as the key determinant of performance. In addition to providing a theoretical grounding for using CKs instead of NTKs, our framework provides insights into understanding the robustness of the various approximants and suggests a recipe for improving DNN accuracy inexpensively. We present a demonstration of this on the foundation model GPT-2 by comparing its performance on a classification task using a conventional approach and our prescription.
</details>
<details>
<summary>摘要</summary>
尽管深度神经网络（DNN）在许多学习任务上表现出了极大的承诺，但是理论上的效iveness和局限性仍然无法被实践者们完全理解。这是因为不能确定closed form的学习函数，使得训练数据的依赖关系和未经训练数据集的泛化性 harder to assess。近期的研究表明，在无限宽限制下，Randomly initialized DNNs会 converges to kernel machines，这些机器可以通过known closed form的Neural Tangent Kernel（NTK）来描述。这些结果表明，和实验证据支持，empirical kernel machines可以作为finite width DNNs的surrogate。然而，assembling the full NTK的计算成本太高，这使得这种方法在实践中不可行，因此需要低成本的近似。在当前的工作中，我们研究了Conjugate Kernel（CK）的性能，CK是NTK的有效近似。对于抽象函数的回归问题和使用logistic regression进行分类，我们显示CK的性能只是NTK的一个小 margin worse，而且在某些情况下，CKeven outperform NTK。具体来说，我们给出了 bounds for the relative test losses，通过数值测试验证了这些 bound，并发现了核函数的 Regularity是性能的关键因素。此外，我们的框架还提供了使用CK instead of NTK的理论基础，以及如何提高DNN的准确性的recipe。我们在GPT-2基础模型上进行了一个示例，通过对一个分类任务使用我们的方法和传统方法进行比较。
</details></li>
</ul>
<hr>
<h2 id="Where-have-you-been-A-Study-of-Privacy-Risk-for-Point-of-Interest-Recommendation"><a href="#Where-have-you-been-A-Study-of-Privacy-Risk-for-Point-of-Interest-Recommendation" class="headerlink" title="Where have you been? A Study of Privacy Risk for Point-of-Interest Recommendation"></a>Where have you been? A Study of Privacy Risk for Point-of-Interest Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18606">http://arxiv.org/abs/2310.18606</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kunlin Cai, Jinghuai Zhang, Will Shand, Zhiqing Hong, Guang Wang, Desheng Zhang, Jianfeng Chi, Yuan Tian</li>
<li>For: This paper aims to evaluate the privacy risks of mobility data-based machine learning models, specifically point-of-interest recommendation models, by designing a privacy attack suite and conducting experimental evaluations.* Methods: The paper uses a privacy attack suite that includes data extraction and membership inference attacks to evaluate the privacy risks of POI recommendation models. The attacks assume different adversary knowledge and aim to extract different types of sensitive information from mobility data.* Results: The experimental evaluation using two real-world mobility datasets demonstrates that current POI recommendation models are vulnerable to the attacks in the privacy attack suite. The paper also presents unique findings on what types of mobility data are more susceptible to privacy attacks.<details>
<summary>Abstract</summary>
As location-based services (LBS) have grown in popularity, the collection of human mobility data has become increasingly extensive to build machine learning (ML) models offering enhanced convenience to LBS users. However, the convenience comes with the risk of privacy leakage since this type of data might contain sensitive information related to user identities, such as home/work locations. Prior work focuses on protecting mobility data privacy during transmission or prior to release, lacking the privacy risk evaluation of mobility data-based ML models. To better understand and quantify the privacy leakage in mobility data-based ML models, we design a privacy attack suite containing data extraction and membership inference attacks tailored for point-of-interest (POI) recommendation models, one of the most widely used mobility data-based ML models. These attacks in our attack suite assume different adversary knowledge and aim to extract different types of sensitive information from mobility data, providing a holistic privacy risk assessment for POI recommendation models. Our experimental evaluation using two real-world mobility datasets demonstrates that current POI recommendation models are vulnerable to our attacks. We also present unique findings to understand what types of mobility data are more susceptible to privacy attacks. Finally, we evaluate defenses against these attacks and highlight future directions and challenges.
</details>
<details>
<summary>摘要</summary>
为了应对 Location-based Services (LBS) 的普及，人类移动数据的收集已成为建立 Machine Learning (ML) 模型的重要步骤，以提供更高的用户便利。然而，这种便利也会带来隐私泄露的风险，因为这些数据可能包含用户标识信息，如家庭/办公室的位置。先前的工作主要关注于在传输或发布 mobility data 时保护隐私，而忽略了 mobility data 基于 ML 模型的隐私风险评估。为了更好地理解和评估 mobility data 基于 ML 模型的隐私泄露，我们设计了一个隐私攻击集，包括数据EXTRACTION和会员推理攻击，专门为点位服务（POI）推荐模型而设计。这些攻击在我们的攻击集中假设不同的反对手知识，目标是从移动数据中提取不同类型的敏感信息，为 POI 推荐模型的隐私风险进行总体评估。我们使用两个实际的移动数据集进行实验，表明现有 POI 推荐模型对我们的攻击非常感受。我们还发现了不同类型的移动数据是哪些隐私攻击最容易受到的，以及对这些攻击的防御措施和未来方向。
</details></li>
</ul>
<hr>
<h2 id="TorchDEQ-A-Library-for-Deep-Equilibrium-Models"><a href="#TorchDEQ-A-Library-for-Deep-Equilibrium-Models" class="headerlink" title="TorchDEQ: A Library for Deep Equilibrium Models"></a>TorchDEQ: A Library for Deep Equilibrium Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18605">http://arxiv.org/abs/2310.18605</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/locuslab/torchdeq">https://github.com/locuslab/torchdeq</a></li>
<li>paper_authors: Zhengyang Geng, J. Zico Kolter</li>
<li>for: This paper is written to provide a systematic and comprehensive framework for training and applying Deep Equilibrium (DEQ) models, which are a class of implicit models that map inputs to fixed points of neural networks.</li>
<li>methods: The paper presents TorchDEQ, an open-source PyTorch-based library that allows users to define, train, and infer using DEQs over multiple domains with minimal code and best practices.</li>
<li>results: The paper reports that by developing a joint framework that incorporates the best practices across all models, the performance, training stability, and efficiency of DEQs have been substantially improved on ten datasets across all six projects in the “DEQ Zoo”.<details>
<summary>Abstract</summary>
Deep Equilibrium (DEQ) Models, an emerging class of implicit models that maps inputs to fixed points of neural networks, are of growing interest in the deep learning community. However, training and applying DEQ models is currently done in an ad-hoc fashion, with various techniques spread across the literature. In this work, we systematically revisit DEQs and present TorchDEQ, an out-of-the-box PyTorch-based library that allows users to define, train, and infer using DEQs over multiple domains with minimal code and best practices. Using TorchDEQ, we build a ``DEQ Zoo'' that supports six published implicit models across different domains. By developing a joint framework that incorporates the best practices across all models, we have substantially improved the performance, training stability, and efficiency of DEQs on ten datasets across all six projects in the DEQ Zoo. TorchDEQ and DEQ Zoo are released as \href{https://github.com/locuslab/torchdeq}{open source}.
</details>
<details>
<summary>摘要</summary>
深度平衡（DEQ）模型，一种在深度学习社区中升起的新类刚果模型，可以将输入映射到神经网络中的固定点上。然而，在训练和应用DEQ模型时，目前仍然采用各种不同的技术，分散在文献中。在这项工作中，我们系统地回顾DEQs，并提出了一个名为TorchDEQ的基于PyTorch的库，允许用户定义、训练和推理使用DEQs，并在多个领域上进行最小代码和最佳实践。使用TorchDEQ，我们建立了一个名为“DEQ zoo”的 colección，支持了六种已发表的隐式模型，并在不同的领域中进行了六个项目的实验。通过开发一个集成所有模型最佳实践的共同框架，我们在十个数据集上提高了DEQs的性能、训练稳定性和效率。TorchDEQ和DEQ zoo都已经作为开源项目在GitHub上发布。
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-Are-Better-Adversaries-Exploring-Generative-Clean-Label-Backdoor-Attacks-Against-Text-Classifiers"><a href="#Large-Language-Models-Are-Better-Adversaries-Exploring-Generative-Clean-Label-Backdoor-Attacks-Against-Text-Classifiers" class="headerlink" title="Large Language Models Are Better Adversaries: Exploring Generative Clean-Label Backdoor Attacks Against Text Classifiers"></a>Large Language Models Are Better Adversaries: Exploring Generative Clean-Label Backdoor Attacks Against Text Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18603">http://arxiv.org/abs/2310.18603</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wencong You, Zayd Hammoudeh, Daniel Lowd</li>
<li>for: 这 paper 是为了攻击机器学习模型的弱点，使其预测结果被 manipulate 的。</li>
<li>methods: 这 paper 使用了语言模型来自动插入多种风格的触发器到文本中，以达到攻击目标。</li>
<li>results: 论文表明，使用 LLMBkd 攻击方法可以在各种风格下 achieve 高度的攻击成功率，只需要 little effort 和无需模型训练。<details>
<summary>Abstract</summary>
Backdoor attacks manipulate model predictions by inserting innocuous triggers into training and test data. We focus on more realistic and more challenging clean-label attacks where the adversarial training examples are correctly labeled. Our attack, LLMBkd, leverages language models to automatically insert diverse style-based triggers into texts. We also propose a poison selection technique to improve the effectiveness of both LLMBkd as well as existing textual backdoor attacks. Lastly, we describe REACT, a baseline defense to mitigate backdoor attacks via antidote training examples. Our evaluations demonstrate LLMBkd's effectiveness and efficiency, where we consistently achieve high attack success rates across a wide range of styles with little effort and no model training.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将给定文本翻译成简化中文。</SYS>>我们研究了一种新的后门攻击方法，称为LLMBkd。这种攻击方法利用语言模型自动插入文本中的多种风格化触发器。我们还提出了一种毒选择技术，以提高现有的文本后门攻击和LLMBkd的效果。此外，我们还描述了一种基eline防御方法，称为REACT，以 Mitigate backdoor attacks via antidote training examples。我们的评估结果表明，LLMBkd 具有高效率和多样化的触发器，可以轻松地在各种风格下实现高度成功率。
</details></li>
</ul>
<hr>
<h2 id="Online-Decision-Mediation"><a href="#Online-Decision-Mediation" class="headerlink" title="Online Decision Mediation"></a>Online Decision Mediation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18601">http://arxiv.org/abs/2310.18601</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/uvhw/Bitcoin-Foundation">https://github.com/uvhw/Bitcoin-Foundation</a></li>
<li>paper_authors: Daniel Jarrett, Alihan Hüyük, Mihaela van der Schaar</li>
<li>For: The paper aims to serve as an intermediary between expert behavior and human behavior in decision-making, with the goal of striking a balance between purely prescriptive and purely descriptive approaches.* Methods: The paper proposes a solution that trades off immediate loss terms against future improvements in generalization error, and identifies why conventional bandit algorithms may fail.* Results: The paper demonstrates consistent gains over applicable benchmarks on performance measures with respect to the mediator policy, the learned model, and the decision-making system as a whole, through experiments and sensitivities on a variety of datasets.Here’s the simplified Chinese text for the three information points:* For: 这篇论文目标是在决策过程中作为中间人，以寻求 struck a balance between凡是指导的（purely prescriptive）和凡是描述的（purely descriptive）方法。* Methods: 论文提出了一种方法，该方法在评估损失和未来改进的泛化误差之间进行了交易，并解释了 conventional bandit 算法可能失败的原因。* Results: 论文通过对各种数据集的实验和敏感度分析，示出了与相关的参考模型、学习模型和决策系统总体性能的一致性。<details>
<summary>Abstract</summary>
Consider learning a decision support assistant to serve as an intermediary between (oracle) expert behavior and (imperfect) human behavior: At each time, the algorithm observes an action chosen by a fallible agent, and decides whether to *accept* that agent's decision, *intervene* with an alternative, or *request* the expert's opinion. For instance, in clinical diagnosis, fully-autonomous machine behavior is often beyond ethical affordances, thus real-world decision support is often limited to monitoring and forecasting. Instead, such an intermediary would strike a prudent balance between the former (purely prescriptive) and latter (purely descriptive) approaches, while providing an efficient interface between human mistakes and expert feedback. In this work, we first formalize the sequential problem of *online decision mediation* -- that is, of simultaneously learning and evaluating mediator policies from scratch with *abstentive feedback*: In each round, deferring to the oracle obviates the risk of error, but incurs an upfront penalty, and reveals the otherwise hidden expert action as a new training data point. Second, we motivate and propose a solution that seeks to trade off (immediate) loss terms against (future) improvements in generalization error; in doing so, we identify why conventional bandit algorithms may fail. Finally, through experiments and sensitivities on a variety of datasets, we illustrate consistent gains over applicable benchmarks on performance measures with respect to the mediator policy, the learned model, and the decision-making system as a whole.
</details>
<details>
<summary>摘要</summary>
考虑使用决策支持助手作为 oracle 专家行为和人类行为之间的中间人：在每次时刻，算法观察到一个不准确的代理人选择的行动，然后决定是否接受该代理人的决定， intervene with 一个替代方案，或者请求专家的意见。例如，在临床诊断中，完全自主的机器行为经常超出伦理范畴，因此现实世界决策支持通常受限于监测和预测。而这个中间人可以 strike 一个谨慎的平衡 между两者，同时提供一个有效的人类错误和专家反馈之间的交互。在这项工作中，我们首先正式化了在线决策媒介问题的sequential形式：在每个回合中，推迟到oracle会降低风险，但是会付出一个初始的罚款，并将 Otherwise 隐藏的专家行为作为一个新的训练数据点。其次，我们激励和提出一个解决方案，它在同时学习和评估媒介策略时，要求平衡 (immediate) 损失和 (future) 改进泛化误差的问题。在这个过程中，我们发现了 conventional bandit 算法可能失败的原因。最后，通过对多种数据集进行实验和敏感分析，我们证明了我们的方法在表现度量上与相关的benchmark相比具有一致性。
</details></li>
</ul>
<hr>
<h2 id="Fair-Streaming-Principal-Component-Analysis-Statistical-and-Algorithmic-Viewpoint"><a href="#Fair-Streaming-Principal-Component-Analysis-Statistical-and-Algorithmic-Viewpoint" class="headerlink" title="Fair Streaming Principal Component Analysis: Statistical and Algorithmic Viewpoint"></a>Fair Streaming Principal Component Analysis: Statistical and Algorithmic Viewpoint</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18593">http://arxiv.org/abs/2310.18593</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junghyun Lee, Hanseul Cho, Se-Young Yun, Chulhee Yun</li>
<li>for: 这个论文的目标是实现公平的主成分分析（PCA），使得投影后的分布匹配于敏感特征的分布。</li>
<li>methods: 这篇论文使用了一种新的定义called“可能相对公平优化”（PAFO）学习可能性，并在实际应用中提出了一种名为“公平流动PCA”的新设定，以及一种具有内存效率的算法“公平噪声方法”（FNPM）。</li>
<li>results: 这篇论文提供了这种算法的“统计”保证，这是公平PCA文献中的首次。此外，它还验证了这种算法的效果和内存效率在实际数据上。<details>
<summary>Abstract</summary>
Fair Principal Component Analysis (PCA) is a problem setting where we aim to perform PCA while making the resulting representation fair in that the projected distributions, conditional on the sensitive attributes, match one another. However, existing approaches to fair PCA have two main problems: theoretically, there has been no statistical foundation of fair PCA in terms of learnability; practically, limited memory prevents us from using existing approaches, as they explicitly rely on full access to the entire data. On the theoretical side, we rigorously formulate fair PCA using a new notion called \emph{probably approximately fair and optimal} (PAFO) learnability. On the practical side, motivated by recent advances in streaming algorithms for addressing memory limitation, we propose a new setting called \emph{fair streaming PCA} along with a memory-efficient algorithm, fair noisy power method (FNPM). We then provide its {\it statistical} guarantee in terms of PAFO-learnability, which is the first of its kind in fair PCA literature. Lastly, we verify the efficacy and memory efficiency of our algorithm on real-world datasets.
</details>
<details>
<summary>摘要</summary>
“ fair principal component analysis (PCA) 是一个问题设定，我们想要在 PCA 中进行不偏的表现，使得投影的分布，根据敏感特征，相互匹配。然而，现有的公平 PCA 方法有两个主要问题：一是理论上没有公平 PCA 的学习基础; two是实际上限制了我们使用现有方法，因为它们需要完整的数据存储。在理论上，我们严格定义公平 PCA 使用一个新的概念 called “可能接近公平且最佳”(PAFO) 可学习性。在实践上，运用最近的流动数据处理技术，我们提出一个新的设定 called “公平流动 PCA”，以及一个内存有效的算法，叫做公平杂音方法 (FNPM)。我们然后提供这个设定的“ Statistical ”保证，这是公平 PCA 文献中的第一个。最后，我们验证了我们的算法在实际数据上的有效性和内存效率。”
</details></li>
</ul>
<hr>
<h2 id="Inverse-Decision-Modeling-Learning-Interpretable-Representations-of-Behavior"><a href="#Inverse-Decision-Modeling-Learning-Interpretable-Representations-of-Behavior" class="headerlink" title="Inverse Decision Modeling: Learning Interpretable Representations of Behavior"></a>Inverse Decision Modeling: Learning Interpretable Representations of Behavior</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18591">http://arxiv.org/abs/2310.18591</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/danieljarrett/Inverse-Bounded-Rational-Control">https://github.com/danieljarrett/Inverse-Bounded-Rational-Control</a></li>
<li>paper_authors: Daniel Jarrett, Alihan Hüyük, Mihaela van der Schaar</li>
<li>for: 提高决策过程的模型化和改进</li>
<li>methods: 使用参数化表示Sequential Decision Behavior的框架，包括正则化控制行为和资料学习</li>
<li>results: 实现了学习（可读）表示 rationality，自然地捕捉了偏见行为、环境知识不准确和 bounded rationality 的概念<details>
<summary>Abstract</summary>
Decision analysis deals with modeling and enhancing decision processes. A principal challenge in improving behavior is in obtaining a transparent description of existing behavior in the first place. In this paper, we develop an expressive, unifying perspective on inverse decision modeling: a framework for learning parameterized representations of sequential decision behavior. First, we formalize the forward problem (as a normative standard), subsuming common classes of control behavior. Second, we use this to formalize the inverse problem (as a descriptive model), generalizing existing work on imitation/reward learning -- while opening up a much broader class of research problems in behavior representation. Finally, we instantiate this approach with an example (inverse bounded rational control), illustrating how this structure enables learning (interpretable) representations of (bounded) rationality -- while naturally capturing intuitive notions of suboptimal actions, biased beliefs, and imperfect knowledge of environments.
</details>
<details>
<summary>摘要</summary>
First, we define the forward problem, which includes common classes of control behavior. Then, we use this framework to formalize the inverse problem, which generalizes existing work on imitation and reward learning. This approach opens up a broader range of research problems in behavior representation.Finally, we provide an example of inverse bounded rational control, which demonstrates how this structure enables the learning of interpretable representations of rationality while naturally capturing suboptimal actions, biased beliefs, and imperfect knowledge of environments.
</details></li>
</ul>
<hr>
<h2 id="Optimal-Transport-for-Kernel-Gaussian-Mixture-Models"><a href="#Optimal-Transport-for-Kernel-Gaussian-Mixture-Models" class="headerlink" title="Optimal Transport for Kernel Gaussian Mixture Models"></a>Optimal Transport for Kernel Gaussian Mixture Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18586">http://arxiv.org/abs/2310.18586</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jung Hun Oh, Rena Elkin, Anish Kumar Simhal, Jiening Zhu, Joseph O Deasy, Allen Tannenbaum</li>
<li>for: 本研究使用 Wasserstein 距离来衡量两个 Gaussian mixture 的距离，并利用 kernel trick 避免直接将输入数据映射到高维特征空间。</li>
<li>methods: 本研究使用 kernel Gaussian mixture models 来计算两个 Gaussian mixture 的 Wasserstein 距离。</li>
<li>results: 本研究提出了一种基于 RKHS 的 Wasserstein-type metric，可以帮助更好地模型复杂多模 density 的实际数据。<details>
<summary>Abstract</summary>
The Wasserstein distance from optimal mass transport (OMT) is a powerful mathematical tool with numerous applications that provides a natural measure of the distance between two probability distributions. Several methods to incorporate OMT into widely used probabilistic models, such as Gaussian or Gaussian mixture, have been developed to enhance the capability of modeling complex multimodal densities of real datasets. However, very few studies have explored the OMT problems in a reproducing kernel Hilbert space (RKHS), wherein the kernel trick is utilized to avoid the need to explicitly map input data into a high-dimensional feature space. In the current study, we propose a Wasserstein-type metric to compute the distance between two Gaussian mixtures in a RKHS via the kernel trick, i.e., kernel Gaussian mixture models.
</details>
<details>
<summary>摘要</summary>
水斯坦距离（OMT）是一个具有广泛应用的数学工具，它提供了两个概率分布之间的自然距离量。有几种方法可以将 OMT 整合到广泛使用的概率模型中，如 Gaussian 或 Gaussian 混合体，以增强模型处理复杂多模式数据的能力。然而，几乎没有研究探讨 OMT 问题在复复函数希尔贝特空间（RKHS）中，这里利用核函数传递器来避免直接将输入数据映射到高维的特征空间。在 presente 研究中，我们提出了一种 Wasserstein-type 度量来计算两个 Gaussian 混合体之间的距离，即核函数 Gaussian 混合模型。
</details></li>
</ul>
<hr>
<h2 id="Group-Robust-Classification-Without-Any-Group-Information"><a href="#Group-Robust-Classification-Without-Any-Group-Information" class="headerlink" title="Group Robust Classification Without Any Group Information"></a>Group Robust Classification Without Any Group Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18555">http://arxiv.org/abs/2310.18555</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tsirif/ula">https://github.com/tsirif/ula</a></li>
<li>paper_authors: Christos Tsirigotis, Joao Monteiro, Pau Rodriguez, David Vazquez, Aaron Courville</li>
<li>for: 这个研究旨在提高 Empirical Risk Minimization (ERM) 方法的高阶假设精度，并解决训练数据中的假设相互作用所导致的伪 correlations 问题，以便在高风险应用中部署系统。</li>
<li>methods: 这个研究提出了一种 entirely bias-unsupervised 的方法，使用预训练的自我supervised 模型来可靠地提取偏见信息，并与我们的验证标准数据集成logit adjustment 训练损失。</li>
<li>results: 我们的方法可以超过现有方法的性能，并在实际应用中提供了更好的伪相互作用精度，包括在 MPI3D dataset 上进行系统性的普遍化任务中，当混合对应 attribute value  absent 时，现有方法失败。<details>
<summary>Abstract</summary>
Empirical risk minimization (ERM) is sensitive to spurious correlations in the training data, which poses a significant risk when deploying systems trained under this paradigm in high-stake applications. While the existing literature focuses on maximizing group-balanced or worst-group accuracy, estimating these accuracies is hindered by costly bias annotations. This study contends that current bias-unsupervised approaches to group robustness continue to rely on group information to achieve optimal performance. Firstly, these methods implicitly assume that all group combinations are represented during training. To illustrate this, we introduce a systematic generalization task on the MPI3D dataset and discover that current algorithms fail to improve the ERM baseline when combinations of observed attribute values are missing. Secondly, bias labels are still crucial for effective model selection, restricting the practicality of these methods in real-world scenarios. To address these limitations, we propose a revised methodology for training and validating debiased models in an entirely bias-unsupervised manner. We achieve this by employing pretrained self-supervised models to reliably extract bias information, which enables the integration of a logit adjustment training loss with our validation criterion. Our empirical analysis on synthetic and real-world tasks provides evidence that our approach overcomes the identified challenges and consistently enhances robust accuracy, attaining performance which is competitive with or outperforms that of state-of-the-art methods, which, conversely, rely on bias labels for validation.
</details>
<details>
<summary>摘要</summary>
empirical risk minimization (ERM) sensitive to spurious correlations in the training data, posing significant risks when deploying systems trained under this paradigm in high-stakes applications. While the existing literature focuses on maximizing group-balanced or worst-group accuracy, estimating these accuracies is hindered by costly bias annotations. This study contends that current bias-unsupervised approaches to group robustness continue to rely on group information to achieve optimal performance. Firstly, these methods implicitly assume that all group combinations are represented during training. To illustrate this, we introduce a systematic generalization task on the MPI3D dataset and discover that current algorithms fail to improve the ERM baseline when combinations of observed attribute values are missing. Secondly, bias labels are still crucial for effective model selection, restricting the practicality of these methods in real-world scenarios. To address these limitations, we propose a revised methodology for training and validating debiased models in an entirely bias-unsupervised manner. We achieve this by employing pretrained self-supervised models to reliably extract bias information, which enables the integration of a logit adjustment training loss with our validation criterion. Our empirical analysis on synthetic and real-world tasks provides evidence that our approach overcomes the identified challenges and consistently enhances robust accuracy, attaining performance which is competitive with or outperforms that of state-of-the-art methods, which, conversely, rely on bias labels for validation.
</details></li>
</ul>
<hr>
<h2 id="Improved-Regret-Bounds-of-Multinomial-Logistic-Bandits-via-Regret-to-Confidence-Set-Conversion"><a href="#Improved-Regret-Bounds-of-Multinomial-Logistic-Bandits-via-Regret-to-Confidence-Set-Conversion" class="headerlink" title="Improved Regret Bounds of (Multinomial) Logistic Bandits via Regret-to-Confidence-Set Conversion"></a>Improved Regret Bounds of (Multinomial) Logistic Bandits via Regret-to-Confidence-Set Conversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18554">http://arxiv.org/abs/2310.18554</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junghyun Lee, Se-Young Yun, Kwang-Sung Jun</li>
<li>for: 这个论文的目的是提高Logistic Bandit模型中的依赖关系，尤其是在大型数据集 ($S \geq d$) 时。</li>
<li>methods: 这个论文使用了一种新的方法 called “regret-to-confidence set conversion” (R2CS)，用于改进logistic bandit的 regret bound。</li>
<li>results: 通过使用R2CS方法，这个论文得到了一个优化的 regret bound，具有更好的依赖关系于$S$，同时保留计算可行性和其他因素($d$和$T$)的依赖关系。<details>
<summary>Abstract</summary>
Logistic bandit is a ubiquitous framework of modeling users' choices, e.g., click vs. no click for advertisement recommender system. We observe that the prior works overlook or neglect dependencies in $S \geq \lVert \theta_\star \rVert_2$, where $\theta_\star \in \mathbb{R}^d$ is the unknown parameter vector, which is particularly problematic when $S$ is large, e.g., $S \geq d$. In this work, we improve the dependency on $S$ via a novel approach called {\it regret-to-confidence set conversion (R2CS)}, which allows us to construct a convex confidence set based on only the \textit{existence} of an online learning algorithm with a regret guarantee. Using R2CS, we obtain a strict improvement in the regret bound w.r.t. $S$ in logistic bandits while retaining computational feasibility and the dependence on other factors such as $d$ and $T$. We apply our new confidence set to the regret analyses of logistic bandits with a new martingale concentration step that circumvents an additional factor of $S$. We then extend this analysis to multinomial logistic bandits and obtain similar improvements in the regret, showing the efficacy of R2CS. While we applied R2CS to the (multinomial) logistic model, R2CS is a generic approach for developing confidence sets that can be used for various models, which can be of independent interest.
</details>
<details>
<summary>摘要</summary>
“带有搜索问题的游戏”（Logistic Bandit）是一个普遍的框架，用于模型用户选择，例如广告追踪系统中的点击vs无点击。我们发现先前的研究往往忽略或忽略了$S \geq \lVert \theta_\star \rVert_2$中的相互依赖，尤其当$S$较大时（例如$S \geq d$）。在这个工作中，我们通过一种新的方法called“ regret-to-confidence set conversion”（R2CS），将可以建立基于仅存在线上学习算法的 regret guarantee的凸信心集。使用R2CS，我们得到了对$S$的 regret bound的严格改进，同时保持了 Computational Feasibility和其他因素（例如$d$和$T$）的依赖。我们将新的信心集应用到了带有新 martingale concentration step 的 regret分析中，从而缺少一个 $S$ 的额外因素。然后，我们将这些分析扩展到多ategorical logistic bandits，并获得了类似的改进。我们将R2CS应用到（多ategorical） logistic模型，但R2CS是一个更通用的方法，可以用于不同的模型，这可能是独立的兴趣。
</details></li>
</ul>
<hr>
<h2 id="The-Role-of-Reference-Points-in-Machine-Learned-Atomistic-Simulation-Models"><a href="#The-Role-of-Reference-Points-in-Machine-Learned-Atomistic-Simulation-Models" class="headerlink" title="The Role of Reference Points in Machine-Learned Atomistic Simulation Models"></a>The Role of Reference Points in Machine-Learned Atomistic Simulation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18552">http://arxiv.org/abs/2310.18552</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiangyun Lei, Weike Ye, Joseph Montoya, Tim Mueller, Linda Hung, Jens Hummelshoej</li>
<li>for: 本研究提出了一种新的化学环境模型理论（CEMT），用于超越传统的基于原子 Machine Learning Force Field（MLFF）模型，广泛用于化学系统的分子动力学 simulations。</li>
<li>methods: 本研究使用了 Gaussian Multipole（GMP）函数来Feature化不同参考点集，包括finite difference grid-centered和bond-centered模型，以分析不同参考点集的能量预测精度、预测速度和学习效率。</li>
<li>results: 研究发现，使用非原子参考点可以提高力训练的灵活性和适应性，并且可以提高预测精度、预测速度和学习效率。此外，本研究还建立了 CEMT 与 real-space orbital-free finite element Density Functional Theory（FE-DFT）之间的联系，并表明了这种联系可以提高数据效率和稳定性。<details>
<summary>Abstract</summary>
This paper introduces the Chemical Environment Modeling Theory (CEMT), a novel, generalized framework designed to overcome the limitations inherent in traditional atom-centered Machine Learning Force Field (MLFF) models, widely used in atomistic simulations of chemical systems. CEMT demonstrated enhanced flexibility and adaptability by allowing reference points to exist anywhere within the modeled domain and thus, enabling the study of various model architectures. Utilizing Gaussian Multipole (GMP) featurization functions, several models with different reference point sets, including finite difference grid-centered and bond-centered models, were tested to analyze the variance in capabilities intrinsic to models built on distinct reference points. The results underscore the potential of non-atom-centered reference points in force training, revealing variations in prediction accuracy, inference speed and learning efficiency. Finally, a unique connection between CEMT and real-space orbital-free finite element Density Functional Theory (FE-DFT) is established, and the implications include the enhancement of data efficiency and robustness. It allows the leveraging of spatially-resolved energy densities and charge densities from FE-DFT calculations, as well as serving as a pivotal step towards integrating known quantum-mechanical laws into the architecture of ML models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Punica-Multi-Tenant-LoRA-Serving"><a href="#Punica-Multi-Tenant-LoRA-Serving" class="headerlink" title="Punica: Multi-Tenant LoRA Serving"></a>Punica: Multi-Tenant LoRA Serving</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18547">http://arxiv.org/abs/2310.18547</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/punica-ai/punica">https://github.com/punica-ai/punica</a></li>
<li>paper_authors: Lequn Chen, Zihao Ye, Yongji Wu, Danyang Zhuo, Luis Ceze, Arvind Krishnamurthy</li>
<li>for: 这个论文是为了提出一个名为Punica的系统，用于在共享GPU集群中服务多个低阶适应（LoRA）模型。</li>
<li>methods: 这个系统使用了一个新的CUDA核心设计，允许不同LoRA模型的批处理操作在GPU上混合进行，这使得GPU只需要储存一个基础预训练模型，从而大幅提高GPU的内存和计算效率。</li>
<li>results: 根据评估结果，Punica在共享GPU集群中服务多个LoRA模型时，与现有的LLM服务系统相比，可以实现12倍的throughput提高，仅加2毫秒迟延性每个字。Punica的源代码可以在<a target="_blank" rel="noopener" href="https://github.com/punica-ai/punica%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/punica-ai/punica上获取。</a><details>
<summary>Abstract</summary>
Low-rank adaptation (LoRA) has become an important and popular method to adapt pre-trained models to specific domains. We present Punica, a system to serve multiple LoRA models in a shared GPU cluster. Punica contains a new CUDA kernel design that allows batching of GPU operations for different LoRA models. This allows a GPU to hold only a single copy of the underlying pre-trained model when serving multiple, different LoRA models, significantly enhancing GPU efficiency in terms of both memory and computation. Our scheduler consolidates multi-tenant LoRA serving workloads in a shared GPU cluster. With a fixed-sized GPU cluster, our evaluations show that Punica achieves 12x higher throughput in serving multiple LoRA models compared to state-of-the-art LLM serving systems while only adding 2ms latency per token. Punica is open source at https://github.com/punica-ai/punica .
</details>
<details>
<summary>摘要</summary>
低阶尝试（LoRA）已成为特定领域适应模型的重要和受欢迎方法。我们介绍了一个名为“Punica”的系统，用于在共享GPU集群中服务多个LoRA模型。Punica包含一个新的CUDA内核设计，允许不同LoRA模型的GPU操作批处理。这意味着GPU只需要存储一份基于预训练模型的底层模型，可以大幅提高GPU的内存和计算效率。我们的调度器将多家租户的LoRA服务工作负载在共享GPU集群中卷积。与现状的LLM服务系统相比，我们的Punica在服务多个LoRA模型时实现了12倍的throughput，同时只增加2毫秒的延迟每个字。Punica的源代码可以在<https://github.com/punica-ai/punica>上下载。
</details></li>
</ul>
<hr>
<h2 id="End-to-end-Feature-Selection-Approach-for-Learning-Skinny-Trees"><a href="#End-to-end-Feature-Selection-Approach-for-Learning-Skinny-Trees" class="headerlink" title="End-to-end Feature Selection Approach for Learning Skinny Trees"></a>End-to-end Feature Selection Approach for Learning Skinny Trees</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18542">http://arxiv.org/abs/2310.18542</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shibal Ibrahim, Kayhan Behdin, Rahul Mazumder<br>for:这篇论文的目的是提出一种同时进行特征选择和树ensemble学习的工具包，以提高树ensemble模型的性能和可读性。methods:这篇论文使用了一种综合优化方法，包括特征选择和树ensemble学习，并且使用了分组L0-L2正则化来实现特征选择。results:这篇论文在15个 sintetic和实际世界数据集上实现了特征压缩率为1.5倍至620倍，并且在某些情况下可以达到10倍的推理速度提升，而无需失去性能。此外，这篇论文的特征选择方法也超过了许多现有的工具包，例如LightGBM和Random Forests，在特定的特征预算下（25%），Skinny Trees可以提高AUC性能，比LightGBM提高10.2%（最高达37.7%），比Random Forests提高3%（最高达12.5%）。<details>
<summary>Abstract</summary>
Joint feature selection and tree ensemble learning is a challenging task. Popular tree ensemble toolkits e.g., Gradient Boosted Trees and Random Forests support feature selection post-training based on feature importances, which are known to be misleading, and can significantly hurt performance. We propose Skinny Trees: a toolkit for feature selection in tree ensembles, such that feature selection and tree ensemble learning occurs simultaneously. It is based on an end-to-end optimization approach that considers feature selection in differentiable trees with Group $\ell_0 - \ell_2$ regularization. We optimize with a first-order proximal method and present convergence guarantees for a non-convex and non-smooth objective. Interestingly, dense-to-sparse regularization scheduling can lead to more expressive and sparser tree ensembles than vanilla proximal method. On 15 synthetic and real-world datasets, Skinny Trees can achieve $1.5\times$ - $620\times$ feature compression rates, leading up to $10\times$ faster inference over dense trees, without any loss in performance. Skinny Trees lead to superior feature selection than many existing toolkits e.g., in terms of AUC performance for $25\%$ feature budget, Skinny Trees outperforms LightGBM by $10.2\%$ (up to $37.7\%$), and Random Forests by $3\%$ (up to $12.5\%$).
</details>
<details>
<summary>摘要</summary>
共同特征选择和树集合学习是一项具有挑战性的任务。常见的树集合工具包，例如梯度拟合树和随机森林，支持基于特征重要性的特征选择，这些特征选择是已知会导致性能下降的。我们提出了瘦树：一个特征选择在树集合学习中同时进行的工具包。它基于一个端到端优化方法，考虑特征选择在分子树中的分支权重 regularization。我们使用一种第一个贝叶幂方法并提供了对非对称和非均匀目标函数的收敛保证。有趣的是， dense-to-sparse 规则调度可以导致更具表达力和更稀疏的树集合，而不是原始的 proximal 方法。在 15 个 synthetic 和实际世界数据集上，瘦树可以实现 $1.5\times$ - $620\times$ 特征压缩率，导致 $10\times$ 更快的推理速度，而无损性能。瘦树在多个现有工具包中的特征选择表现更佳，例如在 $25\%$ 特征预算下，瘦树可以跟上 LightGBM 的 $10.2\%$ (最高 $37.7\%$)，并跟上 Random Forests 的 $3\%$ (最高 $12.5\%$)。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/28/cs.LG_2023_10_28/" data-id="cloh7tqkf00qy7b8875sd45j7" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_10_28" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/28/eess.IV_2023_10_28/" class="article-date">
  <time datetime="2023-10-28T09:00:00.000Z" itemprop="datePublished">2023-10-28</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/28/eess.IV_2023_10_28/">eess.IV - 2023-10-28</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Tracking-and-fast-imaging-of-a-translational-object-via-Fourier-modulation"><a href="#Tracking-and-fast-imaging-of-a-translational-object-via-Fourier-modulation" class="headerlink" title="Tracking and fast imaging of a translational object via Fourier modulation"></a>Tracking and fast imaging of a translational object via Fourier modulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18732">http://arxiv.org/abs/2310.18732</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shijian Li, Xu-ri Yao, Wei Zhang, Yeliang Wang, Qing Zhao</li>
<li>for: 高速运动物体的追踪和图像化，具有各种应用领域的应用前景。</li>
<li>methods: 运用单ixel图像技术进行进程式捕捉高速运动物体，通过动作补偿以获得更好的图像质量。</li>
<li>results: 方法可以同时具有短的重建时间和高质量图像，并且可以实现对小物体的佳化追踪和边缘检测。<details>
<summary>Abstract</summary>
The tracking and imaging of high-speed moving objects hold significant promise for application in various fields. Single-pixel imaging enables the progressive capture of a fast-moving translational object through motion compensation. However, achieving a balance between a short reconstruction time and a good image quality is challenging. In this study, we present a approach that simultaneously incorporates position encoding and spatial information encoding through the Fourier patterns. The utilization of Fourier patterns with specific spatial frequencies ensures robust and accurate object localization. By exploiting the properties of the Fourier transform, our method achieves a remarkable reduction in time complexity and memory consumption while significantly enhancing image quality. Furthermore, we introduce an optimized sampling strategy specifically tailored for small moving objects, significantly reducing the required dwell time for imaging. The proposed method provides a practical solution for the real-time tracking, imaging and edge detection of translational objects, underscoring its considerable potential for diverse applications.
</details>
<details>
<summary>摘要</summary>
高速移动物体的跟踪和成像具有广泛的应用前景。单像素成像可以逐步捕捉fast-moving translational object，通过运动补偿来实现。但是，实现一个好的图像质量和重建时间短的 equilibrio却是挑战。在这种研究中，我们提出了一种方法，同时 incorporates position encoding和空间信息编码通过干扰Patterns。通过利用干扰transform的特性，我们的方法可以remarkably reduce时间复杂度和内存占用，同时显著提高图像质量。此外，我们还提出了专门为小 objetes introduce an optimized sampling strategy, significantly reducing the required dwell time for imaging.该方法提供了一个实用的解决方案，可以实时跟踪、成像和Edge detection of translational objects，强调其广泛的应用前景。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/28/eess.IV_2023_10_28/" data-id="cloh7tqqb016y7b88h4bdc1d4" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.SP_2023_10_28" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/28/eess.SP_2023_10_28/" class="article-date">
  <time datetime="2023-10-28T08:00:00.000Z" itemprop="datePublished">2023-10-28</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-SP/">eess.SP</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/28/eess.SP_2023_10_28/">eess.SP - 2023-10-28</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Enhancing-Epileptic-Seizure-Detection-with-EEG-Feature-Embeddings"><a href="#Enhancing-Epileptic-Seizure-Detection-with-EEG-Feature-Embeddings" class="headerlink" title="Enhancing Epileptic Seizure Detection with EEG Feature Embeddings"></a>Enhancing Epileptic Seizure Detection with EEG Feature Embeddings</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18767">http://arxiv.org/abs/2310.18767</a></li>
<li>repo_url: None</li>
<li>paper_authors: Arman Zarei, Bingzhao Zhu, Mahsa Shoaran</li>
<li>For: The paper aims to improve the performance of seizure detection systems using EEG signals by learning informative embeddings of the signals.* Methods: The proposed method converts raw EEG signals to appropriate embeddings, which are beneficial for various machine learning models.* Results: The proposed approach achieves significant improvements in sensitivity, specificity, and AUC score across multiple models, with a state-of-the-art classification performance of 100% sensitivity and 99% specificity.Here is the same information in Simplified Chinese text:* For: 这篇论文目的是使用EEG信号提高癫痫检测系统的性能。* Methods: 提议的方法是将原始EEG信号转换为有用的嵌入，这些嵌入对多种机器学习模型都是有利的。* Results: 提议的方法在多个模型上实现了显著提高的敏感性、特异性和AUC分数，并达到了新的顶峰性，即100%的敏感度和99%的特异度。<details>
<summary>Abstract</summary>
Epilepsy is one of the most prevalent brain disorders that disrupts the lives of millions worldwide. For patients with drug-resistant seizures, there exist implantable devices capable of monitoring neural activity, promptly triggering neurostimulation to regulate seizures, or alerting patients of potential episodes. Next-generation seizure detection systems heavily rely on high-accuracy machine learning-based classifiers to detect the seizure onset. Here, we propose to enhance the seizure detection performance by learning informative embeddings of the EEG signal. We empirically demonstrate, for the first time, that converting raw EEG signals to appropriate embeddings can significantly boost the performance of seizure detection algorithms. Importantly, we show that embedding features, which converts the raw EEG into an alternative representation, is beneficial for various machine learning models such as Logistic Regression, Multi-Layer Perceptron, Support Vector Machines, and Gradient Boosted Trees. The experiments were conducted on the CHB-MIT scalp EEG dataset. With the proposed EEG feature embeddings, we achieve significant improvements in sensitivity, specificity, and AUC score across multiple models. By employing this approach alongside an SVM classifier, we were able to attain state-of-the-art classification performance with a sensitivity of 100% and specificity of 99%, setting a new benchmark in the field.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:epsilepsy 是全球范围内最常见的脑部疾病之一，影响了数百万人。为了治疗这些药物抵抗性的癫痫病人，存在可以监测神经活动，迅速诱发神经刺激来调节癫痫的嵌入式设备。未来的癫痫检测系统几乎完全依赖于高精度机器学习模型来检测癫痫开始。在这里，我们提议通过学习有用的嵌入来增强癫痫检测性能。我们实际地示证，对于第一次癫痫检测，将raw EEG信号转换为合适的嵌入可以显著提高癫痫检测算法的性能。此外，我们还证明了嵌入特征可以为不同的机器学习模型，如Logistic Regression、Multi-Layer Perceptron、Support Vector Machines和Gradient Boosted Trees等提供有利。实验在CHB-MIT皮帽EEG数据集上进行。通过我们的EEG特征嵌入，我们在多个模型上实现了显著的改善，包括敏感性、特异性和AUC分数。通过与SVM分类器结合使用，我们实现了当前领域的最佳分类性能，敏感性为100%，特异性为99%。
</details></li>
</ul>
<hr>
<h2 id="Cluster-Based-Cell-Free-Massive-MIMO-Systems-A-Novel-Framework-to-Enhance-Spectral-Efficiency-with-Low-Complexity"><a href="#Cluster-Based-Cell-Free-Massive-MIMO-Systems-A-Novel-Framework-to-Enhance-Spectral-Efficiency-with-Low-Complexity" class="headerlink" title="Cluster-Based Cell-Free Massive MIMO Systems: A Novel Framework to Enhance Spectral Efficiency with Low Complexity"></a>Cluster-Based Cell-Free Massive MIMO Systems: A Novel Framework to Enhance Spectral Efficiency with Low Complexity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18734">http://arxiv.org/abs/2310.18734</a></li>
<li>repo_url: None</li>
<li>paper_authors: Reza Roshanghias, Reza Saadat<br>for: This paper aims to improve the spectral efficiency (SE) of distributed cell-free massive MIMO (CF-mMIMO) systems by proposing a novel cluster-based architecture.methods: The proposed cluster-based structure combines centralized and distributed configurations, with local precoders formed using collectively shared CSI within each cluster. The MMSE precoding technique is used to achieve optimal SE performance.results: The simulation results show that the proposed cluster-based framework achieves a significantly augmented SE compared to the distributed architecture, with the optimal SE attained using four clusters and the MMSE precoding technique. The computational complexity is reduced by over 85%. Additionally, the proposed approach outperforms the centralized structure in terms of SE.Here is the text in Simplified Chinese:for: 本文目的是提高分布式cell-free大MIMO系统的spectral efficiency（SE）。methods: 提议的集群结构 combinest中央化和分布式配置，通过每个集群内CSI的共享来形成本地预编码器。使用MMSE预编码技术来实现优化的SE性能。results: 仪表结果表明，提议的集群结构相比分布式结构，可以获得显著提高的SE性能，最佳SE性能在四个集群和MMSE预编码技术下实现，计算复杂度下降超过85%。此外，提议的方法还超越了中央结构的SE性能。<details>
<summary>Abstract</summary>
The issue of diminished spectral efficiency (SE) of the downlink (DL) transmission in distributed cell-free massive MIMO (CF-mMIMO) systems poses a significant challenge in terms of user equipment (UE) performance when compared to their centralized CF-mMIMO counterparts. The primary root cause of this issue can be attributed to the reduced efficacy of distributed precoders, which are devised using local channel state information (CSI) in distributed systems. This reduced efficacy becomes particularly pronounced in terms of interference mitigation when compared to centralized precoders. To address this issue, this paper proposes a novel architectural framework for CF-mMIMO systems, referred to herein as the "cluster-based structure." Within this innovative structure, a hybrid amalgamation of centralized and distributed configurations is employed, complemented by the introduction of a unique cluster arrangement for the access points (APs) within the network. In this design, the CSI of APs within each cluster is collectively shared within a local processor unit. Consequently, by harnessing this enhanced repository of local channel information, local precoders are formulated, which facilitate more effective interference mitigation with reduced computational complexity compared to the centralized approach. This approach ultimately results in a significantly augmented SE when contrasted with the distributed architecture. The simulation results unequivocally demonstrate that within the cluster-based framework, the optimal SE for the network is attained when utilizing four clusters in conjunction with the MMSE precoding technique, leading to a notable reduction in computational complexity exceeding 85%. Importantly, this approach surpasses the SE performance of the centralized structure.
</details>
<details>
<summary>摘要</summary>
分布式Cell-free巨观MIMO系统（CF-mMIMO）的下行传输（DL） Spectral Efficiency（SE）受到了明显的挑战，用户设备（UE）性能与中央CF-mMIMO对照之下显著下降。主要的根本原因在于分布式预编器的效果减退，这些预编器基于分布式系统中的本地频道状态信息（CSI）设计。在分布式系统中，这种减退的效果特别明显在干扰抑制方面，与中央预编器相比。为解决这一问题，本文提出了一种新的建筑框架，称为“分区结构”。在这种新的架构中， hybrid化中央和分布式配置是使用，并在网络中的APs之间创建了特有的帧排序。在这个设计中，APs在每个分区内的CSI是集中共享在本地处理单元中。通过利用这些增强的本地频道信息，本地预编器是计算更有效的干扰抑制，比中央方法更加简单。这种方法最终导致了分布式系统中的SE显著增加，与分布式架构相比，SE性能得到了显著提高。实验结果表明，在分区结构中，使用四个分区并与MMSE预编器技术相结合，可以获得网络的最佳SE，计算复杂度超过85%。这种方法还超越了中央结构的SE性能。
</details></li>
</ul>
<hr>
<h2 id="Two-stage-space-construction-for-real-time-modeling-of-distributed-parameter-systems-under-sparse-sensing"><a href="#Two-stage-space-construction-for-real-time-modeling-of-distributed-parameter-systems-under-sparse-sensing" class="headerlink" title="Two-stage space construction for real-time modeling of distributed parameter systems under sparse sensing"></a>Two-stage space construction for real-time modeling of distributed parameter systems under sparse sensing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18670">http://arxiv.org/abs/2310.18670</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Wei</li>
<li>for: This paper is written for real-time modeling of distributed parameter systems (DPSs) in cases of limited sensors.</li>
<li>methods: The paper introduces a two-stage spatial construction approach that uses a discrete space-completion method to recuperate spatiotemporal patterns of non-monitored locations, followed by the use of high-dimensional space construction methods to derive continuous spatial basis functions (SBFs). The nonlinear temporal model is identified and adjusted via long short-term memory (LSTM) neural networks.</li>
<li>results: The paper demonstrates the efficacy of the proposed modeling technique under sparse sensing using experimental tests conducted on a pouch-type Li-ion battery. The results show that the use of a cubic B-spline surface is an effective solution for optimizing space construction in the sense of least squares approximation.<details>
<summary>Abstract</summary>
Numerous industrial processes can be defined using distributed parameter systems (DPSs). This study introduces a two-stage spatial construction approach for real-time modeling of DPSs in cases of limited sensors. Initially, a discrete space-completion approach is created to recuperate the spatiotemporal patterns of non-monitored locations under sparse sensing. The high-dimensional space construction method is employed to derive continuous spatial basis functions (SBFs). The identification and adjustment of the nonlinear temporal model are carried out via the long short-term memory (LSTM) neural network. Eventually, the amalgamation of the derived SBFs and temporal model results in a spatially continuous model. The use of a cubic B-spline surface is validated as an effective solution for optimizing space construction in the sense of least squares approximation. Experimental tests conducted on a pouch-type Li-ion battery demonstrate the efficacy of the proposed modeling technique under sparse sensing. This work highlights the promise of sparse sensors in real-time full-space modeling for large-scale battery energy storage systems.
</details>
<details>
<summary>摘要</summary>
许多工业过程可以使用分布参数系统（DPS）进行定义。本研究提出了一种两Stage空间建构方法，用于实时模拟DPS，并且在有限感知的情况下进行模拟。首先，一种精简空间完成方法被创建，以恢复不监测区域的空间时间模式。然后，高维空间建构方法被应用，以 derivate连续空间基函数（SBF）。非线性时间模型的标识和调整由长Short-Term记忆神经网络（LSTM）完成。最后， derivate的 SBFs 和时间模型的结合，得到了一个连续空间模型。实验表明，使用立方BSpline面的方法可以有效地优化空间建构，从 least squares 的角度来看。这种方法在磁力牵引Li-ion电池的实验中得到了证明，并且表明了有限感知的感知器在实时全空间模型化方面的承诺。
</details></li>
</ul>
<hr>
<h2 id="Joint-Localization-and-Communication-Enhancement-in-Uplink-Integrated-Sensing-and-Communications-System-with-Clock-Asynchronism"><a href="#Joint-Localization-and-Communication-Enhancement-in-Uplink-Integrated-Sensing-and-Communications-System-with-Clock-Asynchronism" class="headerlink" title="Joint Localization and Communication Enhancement in Uplink Integrated Sensing and Communications System with Clock Asynchronism"></a>Joint Localization and Communication Enhancement in Uplink Integrated Sensing and Communications System with Clock Asynchronism</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18630">http://arxiv.org/abs/2310.18630</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xu Chen, XinXin He, Zhiyong Feng, Zhiqing Wei, Qixun Zhang, Xin Yuan, Ping Zhang</li>
<li>for: 提高单基站的射频定位和通信可靠性</li>
<li>methods: 利用多信号分类（MUSIC）基于抽象谱（AoA）估计，并在AoA估计中加入信号增强（CSI）估计，以消除额外复杂度。</li>
<li>results: 可以减少时钟偏移（TO）相关的频率变化引起的影响，并且可以实现单基站的射频定位。在实验中，提出的方案可以与最小二乘均方差（MMSE）CSI估计具有相同的比特错误率性能，并且可以提高射频定位的均方差Error（MSE）约8分质量单位。<details>
<summary>Abstract</summary>
In this paper, we propose a joint single-base localization and communication enhancement scheme for the uplink (UL) integrated sensing and communications (ISAC) system with asynchronism, which can achieve accurate single-base localization of user equipment (UE) and significantly improve the communication reliability despite the existence of timing offset (TO) due to the clock asynchronism between UE and base station (BS). Our proposed scheme integrates the CSI enhancement into the multiple signal classification (MUSIC)-based AoA estimation and thus imposes no extra complexity on the ISAC system. We further exploit a MUSIC-based range estimation method and prove that it can suppress the time-varying TO-related phase terms. Exploiting the AoA and range estimation of UE, we can estimate the location of UE. Finally, we propose a joint CSI and data signals-based localization scheme that can coherently exploit the data and the CSI signals to improve the AoA and range estimation, which further enhances the single-base localization of UE. The extensive simulation results show that the enhanced CSI can achieve equivalent bit error rate performance to the minimum mean square error (MMSE) CSI estimator. The proposed joint CSI and data signals-based localization scheme can achieve decimeter-level localization accuracy despite the existing clock asynchronism and improve the localization mean square error (MSE) by about 8 dB compared with the maximum likelihood (ML)-based benchmark method.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种同时进行单基地位置定位和通信增强方案，用于下降链（UL）结合感知通信（ISAC）系统中的异步问题，可以实现精确的单基地位置定位和提高通信可靠性，即使存在时钟偏移（TO）。我们的提议方案将增强因子（CSI）增强纳入多个信号分类（MUSIC）基于投射角（AoA）估计中，从而不增加ISAC系统的复杂性。我们进一步利用MUSIC基于距离估计方法，并证明它可以抑制时间变化的TO相关阶跃项。通过UE的AoA和距离估计，我们可以估计UE的位置。最后，我们提议一种同时使用CSI和数据信号的位置定位方案，可以具有协调利用数据和CSI信号来提高AoA和距离估计的优点，进而提高单基地位置定位精度。实验结果表明，提高CSI可以实现与最小平均方差（MMSE）CSI估计器相同的错误率性能。我们的联合CSI和数据信号基于位置定位方案可以在存在时钟偏移的情况下实现厘米级位置定位精度，并提高位置估计均方差（MSE）约8分贝比对最大likelihood（ML）参考方法。
</details></li>
</ul>
<hr>
<h2 id="A-Generalized-Statistical-Model-for-THz-wireless-Channel-with-Random-Atmospheric-Absorption"><a href="#A-Generalized-Statistical-Model-for-THz-wireless-Channel-with-Random-Atmospheric-Absorption" class="headerlink" title="A Generalized Statistical Model for THz wireless Channel with Random Atmospheric Absorption"></a>A Generalized Statistical Model for THz wireless Channel with Random Atmospheric Absorption</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18616">http://arxiv.org/abs/2310.18616</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pranay Bhardwaj, S. M. Zafaruddin</li>
<li>for: 这个论文是为了研究和模型TERAHERTZ（THz）无线通信频率范围内的信号媒体特性和损害，以及这些损害对连接性和可靠性的影响。</li>
<li>methods: 这篇论文使用了γ分布来描述分子吸收率的Random Path-Loss，以及α-η-κ-μ分布来描述短期干扰。此外，论文还考虑了天线偏倾错误和接收机硬件缺陷。</li>
<li>results: 论文通过fox的H函数来描述信道障碍的共同统计效应，并分析了THz链路的失业概率，以证明提出的通用模型的分析可行性。 computer simulations也用于证明该模型在性能评估中的效果。<details>
<summary>Abstract</summary>
Current statistical channel models for Terahertz (THz) wireless communication primarily concentrate on the sub-THz band, mostly with $\alpha$-$\mu$ and Gaussian mixture fading distributions for short-term fading and deterministic modeling for atmospheric absorption. In this paper, we develop a generalized statistical model for signal propagation at THz frequencies considering random path-loss employing Gamma distribution for the molecular absorption coefficient, short-term fading characterized by the $\alpha$-$\eta$-$\kappa$-$\mu$ distribution, antenna misalignment errors, and transceiver hardware impairments. The proposed model can handle various propagation scenarios, including indoor and outdoor environments, backhaul/fronthaul situations, and complex urban settings. Using Fox's H-functions, we present the probability density function (PDF) and cumulative distribution function (CDF) that capture the combined statistical effects of channel impairments. We analyze the outage probability of a THz link to demonstrate the analytical tractability of the proposed generalized model. We present computer simulations to demonstrate the efficacy of the proposed model for performance assessment with the statistical effect of atmospheric absorption.
</details>
<details>
<summary>摘要</summary>
当前的天 Harrison（THz）无线通信频率模型主要集中在Sub-THz频段，通常使用α-μ和高斯混合折射分布来描述短期折射和大气吸收的 deterministic 模型。在本文中，我们开发了一种通用的天 Harrison（THz）信号卫星传播模型，考虑了随机路径损失，使用γ分布来描述分子吸收系数，短期折射由α-η-κ-μ分布 characterize，天线误差、发射机硬件不良等因素。该模型可以处理不同的传播enario，包括室内和室外环境，后向/前向 Situation，复杂的城市场景。使用Fox的H函数，我们提供了PDF和CDF，这些函数捕捉了天 Harrison（THz）通信频率的共同统计效应。我们分析了THz链接的失业概率，以示analytical tractability of the proposed generalized model。我们通过计算机实验证明了提案的模型在性能评估中的有效性，并且演示了天 Harrison（THz）通信频率的统计效应。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/28/eess.SP_2023_10_28/" data-id="cloh7tqrn01af7b886voncgyt" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_10_27" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/27/cs.SD_2023_10_27/" class="article-date">
  <time datetime="2023-10-27T15:00:00.000Z" itemprop="datePublished">2023-10-27</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/27/cs.SD_2023_10_27/">cs.SD - 2023-10-27</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Enabling-Acoustic-Audience-Feedback-in-Large-Virtual-Events"><a href="#Enabling-Acoustic-Audience-Feedback-in-Large-Virtual-Events" class="headerlink" title="Enabling Acoustic Audience Feedback in Large Virtual Events"></a>Enabling Acoustic Audience Feedback in Large Virtual Events</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18099">http://arxiv.org/abs/2310.18099</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tamay Aykut, Markus Hofbauer, Christopher Kuhn, Eckehard Steinbach, Bernd Girod</li>
<li>for: 提供一个虚拟观众框架，实现虚拟会议中的现场氛围和观众反馈。</li>
<li>methods: 收集本地观众反馈，并将其提交虚拟观众服务器。将组合的虚拟观众反馈资讯传递给所有参加者，并将其转换为单一的音频反馈。</li>
<li>results: 提供一个可以实现现场氛围和观众反馈的虚拟观众框架，实现了虚拟会议中的现场氛围和观众反馈。<details>
<summary>Abstract</summary>
The COVID-19 pandemic shifted many events in our daily lives into the virtual domain. While virtual conference systems provide an alternative to physical meetings, larger events require a muted audience to avoid an accumulation of background noise and distorted audio. However, performing artists strongly rely on the feedback of their audience. We propose a concept for a virtual audience framework which supports all participants with the ambience of a real audience. Audience feedback is collected locally, allowing users to express enthusiasm or discontent by selecting means such as clapping, whistling, booing, and laughter. This feedback is sent as abstract information to a virtual audience server. We broadcast the combined virtual audience feedback information to all participants, which can be synthesized as a single acoustic feedback by the client. The synthesis can be done by turning the collective audience feedback into a prompt that is fed to state-of-the-art models such as AudioGen. This way, each user hears a single acoustic feedback sound of the entire virtual event, without requiring to unmute or risk hearing distorted, unsynchronized feedback.
</details>
<details>
<summary>摘要</summary>
COVID-19 大流行使得许多日常生活活动转移到虚拟领域。虚拟会议系统为物理会议提供了替代方案，但是大型活动需要干杂背景噪音和扭曲的音频避免。但是表演艺术家强调audience反馈的重要性。我们提出了一种虚拟听众框架，该框架支持所有参与者在虚拟环境中感受到真实听众的氛围。听众反馈被本地收集，用户可以通过选择方式如掌声、喊喊、嘘声和笑声表达积极或不满。这些反馈信息被发送到虚拟听众服务器，然后将所有参与者发送的反馈信息组合并 Broadcast。客户端可以将这些反馈信息 sinthez为单一的音频反馈，不需要静音或听到扭曲的反馈。
</details></li>
</ul>
<hr>
<h2 id="TorchAudio-2-1-Advancing-speech-recognition-self-supervised-learning-and-audio-processing-components-for-PyTorch"><a href="#TorchAudio-2-1-Advancing-speech-recognition-self-supervised-learning-and-audio-processing-components-for-PyTorch" class="headerlink" title="TorchAudio 2.1: Advancing speech recognition, self-supervised learning, and audio processing components for PyTorch"></a>TorchAudio 2.1: Advancing speech recognition, self-supervised learning, and audio processing components for PyTorch</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17864">http://arxiv.org/abs/2310.17864</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pytorch/audio">https://github.com/pytorch/audio</a></li>
<li>paper_authors: Jeff Hwang, Moto Hira, Caroline Chen, Xiaohui Zhang, Zhaoheng Ni, Guangzhi Sun, Pingchuan Ma, Ruizhe Huang, Vineel Pratap, Yuekai Zhang, Anurag Kumar, Chin-Yun Yu, Chuang Zhu, Chunxi Liu, Jacob Kahn, Mirco Ravanelli, Peng Sun, Shinji Watanabe, Yangyang Shi, Yumeng Tao, Robin Scheibler, Samuele Cornell, Sean Kim, Stavros Petridis</li>
<li>for: 本文旨在探讨TorchAudio库的开发原则和内容，以及其最新版本（2.1）中包含的关键特性和功能。</li>
<li>methods: 本文使用自动学习预训练管道和高性能CTC解码器、语音识别模型和训练规则、高级媒体输入&#x2F;输出功能和多通道语音提升工具等方法。</li>
<li>results: 本文通过实证研究，证明了一些特性和功能的有效性，并达到了竞争性或者国际先进水平的表现。<details>
<summary>Abstract</summary>
TorchAudio is an open-source audio and speech processing library built for PyTorch. It aims to accelerate the research and development of audio and speech technologies by providing well-designed, easy-to-use, and performant PyTorch components. Its contributors routinely engage with users to understand their needs and fulfill them by developing impactful features. Here, we survey TorchAudio's development principles and contents and highlight key features we include in its latest version (2.1): self-supervised learning pre-trained pipelines and training recipes, high-performance CTC decoders, speech recognition models and training recipes, advanced media I/O capabilities, and tools for performing forced alignment, multi-channel speech enhancement, and reference-less speech assessment. For a selection of these features, through empirical studies, we demonstrate their efficacy and show that they achieve competitive or state-of-the-art performance.
</details>
<details>
<summary>摘要</summary>
torchAudio 是一个开源的音频和语音处理库，建立在 PyTorch 之上，旨在加速音频和语音技术的研究和开发。它的贡献者们routinely与用户交流，了解他们的需求，并通过开发有力量的功能来满足他们。在这篇文章中，我们将survey torchAudio 的开发原则和内容，并强调最新版本（2.1）中包含的关键功能。这些功能包括：自然语言处理预训练管道和训练规程，高性能的 CTC 解码器，语音识别模型和训练规程，高级媒体 I/O 能力，以及用于强制对应、多通道语音增强和无参考语音评估的工具。对这些功能的一些特点，我们通过实验研究证明了它们的有效性，并证明它们在比较或国际级的性能。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/27/cs.SD_2023_10_27/" data-id="cloh7tqmo00x77b88fhwngl0a" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_10_27" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/27/eess.AS_2023_10_27/" class="article-date">
  <time datetime="2023-10-27T14:00:00.000Z" itemprop="datePublished">2023-10-27</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/27/eess.AS_2023_10_27/">eess.AS - 2023-10-27</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Improved-Lossless-Coding-for-Storage-and-Transmission-of-Multichannel-Immersive-Audio"><a href="#Improved-Lossless-Coding-for-Storage-and-Transmission-of-Multichannel-Immersive-Audio" class="headerlink" title="Improved Lossless Coding for Storage and Transmission of Multichannel Immersive Audio"></a>Improved Lossless Coding for Storage and Transmission of Multichannel Immersive Audio</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18461">http://arxiv.org/abs/2310.18461</a></li>
<li>repo_url: None</li>
<li>paper_authors: Toni Hirvonen, Mahmoud Namazi</li>
<li>for: 提高多渠道无损编码的效率，用于听众体验技术</li>
<li>methods: 提议同时编码多个不同渠道的内容，使用过去样本和当前时间样本来预测混合音频，并使用一般线性解法优化模型参数，最后使用rice编码处理剩余信息</li>
<li>results: 相比基eline，提议方法能够提高听众体验技术的压缩率，包括存储和传输Here’s a breakdown of each point:</li>
<li>for: The paper is written for the purpose of improving the efficiency of multichannel lossless coding, which is used in audio compression technology.</li>
<li>methods: The proposed method uses a signal model that predicts the upmix based on both past samples of the upmix and current time samples of the downmix. The model parameters are optimized using a general linear solver, and the prediction residual is Rice coded. Additionally, the use of an SVD projection prior to residual coding is proposed.</li>
<li>results: The proposed method shows improved compression ratios compared to various baselines, including FLAC, for the storage and transmission of immersive audio.<details>
<summary>Abstract</summary>
In this paper, techniques for improving multichannel lossless coding are examined. A method is proposed for the simultaneous coding of two or more different renderings (mixes) of the same content. The signal model uses both past samples of the upmix, and the current time samples of downmix samples to predict the upmix. Model parameters are optimized via a general linear solver, and the prediction residual is Rice coded. Additionally, the use of an SVD projection prior to residual coding is proposed. A comparison is made against various baselines, including FLAC. The proposed methods show improved compression ratios for the storage and transmission of immersive audio.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了多通道无损编码技术的改进方法。我们提议同时编码两个或更多不同的渲染（混合）的同一个内容。信号模型使用过去时间amples的混合和当前时间amples的混合样本来预测混合。模型参数通过一般线性解决器优化，预测差异用Rice编码。此外，我们还提出了SVD проекции前置 residual编码的方法。与不同的基准值进行比较，我们的方法显示在具有幂扩增音频存储和传输中提供了更好的压缩比率。
</details></li>
</ul>
<hr>
<h2 id="MixRep-Hidden-Representation-Mixup-for-Low-Resource-Speech-Recognition"><a href="#MixRep-Hidden-Representation-Mixup-for-Low-Resource-Speech-Recognition" class="headerlink" title="MixRep: Hidden Representation Mixup for Low-Resource Speech Recognition"></a>MixRep: Hidden Representation Mixup for Low-Resource Speech Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18450">http://arxiv.org/abs/2310.18450</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiamin1013/mixrep-espnet">https://github.com/jiamin1013/mixrep-espnet</a></li>
<li>paper_authors: Jiamin Xie, John H. L. Hansen</li>
<li>for: 本研究旨在提出一种简单有效的数据增强策略基于mixup，用于低资源ASR。</li>
<li>methods: 本文提出了 interpolating the feature dimensions of hidden representations in the neural network，可以应用于输入和每层输出的feature。此外，我们还提出了将mixup与时间轴的regulization相结合，并应用到ConformerEncoder上。</li>
<li>results: 实验结果表明，MixRep可以在低资源ASR中提供更高的性能，比其他增强方法更好。与SpecAugment强制比较，MixRep在eval92集和Callhome部分的eval’2000集上减少了相对WRER值6.5%和6.7%。<details>
<summary>Abstract</summary>
In this paper, we present MixRep, a simple and effective data augmentation strategy based on mixup for low-resource ASR. MixRep interpolates the feature dimensions of hidden representations in the neural network that can be applied to both the acoustic feature input and the output of each layer, which generalizes the previous MixSpeech method. Further, we propose to combine the mixup with a regularization along the time axis of the input, which is shown as complementary. We apply MixRep to a Conformer encoder of an E2E LAS architecture trained with a joint CTC loss. We experiment on the WSJ dataset and subsets of the SWB dataset, covering reading and telephony conversational speech. Experimental results show that MixRep consistently outperforms other regularization methods for low-resource ASR. Compared to a strong SpecAugment baseline, MixRep achieves a +6.5\% and a +6.7\% relative WER reduction on the eval92 set and the Callhome part of the eval'2000 set.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种基于mixup的简单有效数据扩大策略，称为MixRep，用于低资源ASR。MixRep interpolates the feature dimensions of hidden representations in the neural network, which can be applied to both the acoustic feature input and the output of each layer, thus generalizing the previous MixSpeech method。另外，我们提议将mixup与时间轴方向的准则相结合，以便增强其效果。我们在一个Conformer编码器上应用MixRep，并使用一个CTC损失函数进行训练。我们在WSJ dataset和SWB dataset的一些子集上进行实验，包括读取和电话交流的语音。实验结果表明，MixRep在低资源ASR中consistently outperform其他准则方法。相比于一个强大的SpecAugment基准，MixRep在eval92集和Callhome部分的eval'2000集上实现了+6.5%和+6.7%的相对WRER降低。
</details></li>
</ul>
<hr>
<h2 id="Relative-Transfer-Function-Vector-Estimation-for-Acoustic-Sensor-Networks-Exploiting-Covariance-Matrix-Structure"><a href="#Relative-Transfer-Function-Vector-Estimation-for-Acoustic-Sensor-Networks-Exploiting-Covariance-Matrix-Structure" class="headerlink" title="Relative Transfer Function Vector Estimation for Acoustic Sensor Networks Exploiting Covariance Matrix Structure"></a>Relative Transfer Function Vector Estimation for Acoustic Sensor Networks Exploiting Covariance Matrix Structure</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18199">http://arxiv.org/abs/2310.18199</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wiebke Middelberg, Henri Gode, Simon Doclo</li>
<li>for: 这篇论文主要针对的是听音环境中多个杂音源的噪声减少问题。</li>
<li>methods: 这篇论文提出了两种Relative Transfer Function（RTF）向量估计方法，其中一种是基于噪声covariance矩阵的whitening方法，另一种是基于噪声矩阵的off-diagonal块选择方法。</li>
<li>results: 在使用这两种方法后，对真实的频谱记录进行了 simulated 环境中的 reverberation 环境中的多个噪声源下的噪声减少测试，结果显示，modified CW方法与CW方法相比，有slightly better的SNR提升表现，而off-diagonal选择方法则超过了偏向RTF向量估计。<details>
<summary>Abstract</summary>
In many multi-microphone algorithms for noise reduction, an estimate of the relative transfer function (RTF) vector of the target speaker is required. The state-of-the-art covariance whitening (CW) method estimates the RTF vector as the principal eigenvector of the whitened noisy covariance matrix, where whitening is performed using an estimate of the noise covariance matrix. In this paper, we consider an acoustic sensor network consisting of multiple microphone nodes. Assuming uncorrelated noise between the nodes but not within the nodes, we propose two RTF vector estimation methods that leverage the block-diagonal structure of the noise covariance matrix. The first method modifies the CW method by considering only the diagonal blocks of the estimated noise covariance matrix. In contrast, the second method only considers the off-diagonal blocks of the noisy covariance matrix, but cannot be solved using a simple eigenvalue decomposition. When applying the estimated RTF vector in a minimum variance distortionless response beamformer, simulation results for real-world recordings in a reverberant environment with multiple noise sources show that the modified CW method performs slightly better than the CW method in terms of SNR improvement, while the off-diagonal selection method outperforms a biased RTF vector estimate obtained as the principal eigenvector of the noisy covariance matrix.
</details>
<details>
<summary>摘要</summary>
多频器算法中的Target speaker的相对传输函数（RTF）向量估计是多频器算法中非常重要的一个步骤。现在的State-of-the-art方法是covariance whitening（CW）方法，它估计RTF向量为白化后的噪声矩阵中的主要特征向量。在这篇论文中，我们考虑了一个包含多个麦克风节点的声学感知网络。假设 node之间的噪声是独立的，但不是内部独立的，我们提出了两种RTF向量估计方法，它们都利用噪声矩阵的块对称结构。第一种方法是修改CW方法，只考虑预估噪声矩阵的对角块。相比之下，第二种方法只考虑噪声矩阵的偏置块，但不可以使用简单的特征值分解来解决。当应用估计RTF向量在无损杂点抗噪声器中时，通过使用实际录制的真实环境中的多个噪声源，我们的simulation结果显示，修改CW方法与CW方法在SNR提高方面的性能略微不同，而偏置选择方法则超过偏置RTF向量估计。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/27/eess.AS_2023_10_27/" data-id="cloh7tqnx010v7b8866vt85xt" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_10_27" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/27/cs.CV_2023_10_27/" class="article-date">
  <time datetime="2023-10-27T13:00:00.000Z" itemprop="datePublished">2023-10-27</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/27/cs.CV_2023_10_27/">cs.CV - 2023-10-27</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Using-convolutional-neural-networks-for-stereological-characterization-of-3D-hetero-aggregates-based-on-synthetic-STEM-data"><a href="#Using-convolutional-neural-networks-for-stereological-characterization-of-3D-hetero-aggregates-based-on-synthetic-STEM-data" class="headerlink" title="Using convolutional neural networks for stereological characterization of 3D hetero-aggregates based on synthetic STEM data"></a>Using convolutional neural networks for stereological characterization of 3D hetero-aggregates based on synthetic STEM data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18523">http://arxiv.org/abs/2310.18523</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lukas Fuchs, Tom Kirstein, Christoph Mahr, Orkun Furat, Valentin Baric, Andreas Rosenauer, Lutz Maedler, Volker Schmidt</li>
<li>for: 这个论文的目的是研究三维结构的异构聚合体，以derive process-structure或structure-property关系。</li>
<li>methods: 这个论文使用机器学习和空间随机模型的方法，通过生成Synthetic Training Data来 overcome 3D imaging技术的问题。</li>
<li>results: 这个论文提出了一种基于机器学习和空间随机模型的方法，可以从2D图像中预测3D结构。此外，论文还进行了错误分析，以评估这种预测方法的准确性。<details>
<summary>Abstract</summary>
The structural characterization of hetero-aggregates in 3D is of great interest, e.g., for deriving process-structure or structure-property relationships. However, since 3D imaging techniques are often difficult to perform as well as time and cost intensive, a characterization of hetero-aggregates based on 2D image data is desirable, but often non-trivial. To overcome the issues of characterizing 3D structures from 2D measurements, a method is presented that relies on machine learning combined with methods of spatial stochastic modeling, where the latter are utilized for the generation of synthetic training data. This kind of training data has the advantage that time-consuming experiments for the synthesis of differently structured materials followed by their 3D imaging can be avoided. More precisely, a parametric stochastic 3D model is presented, from which a wide spectrum of virtual hetero-aggregates can be generated. Additionally, the virtual structures are passed to a physics-based simulation tool in order to generate virtual scanning transmission electron microscopy (STEM) images. The preset parameters of the 3D model together with the simulated STEM images serve as a database for the training of convolutional neural networks, which can be used to determine the parameters of the underlying 3D model and, consequently, to predict 3D structures of hetero-aggregates from 2D STEM images. Furthermore, an error analysis is performed to evaluate the prediction power of the trained neural networks with respect to structural descriptors, e.g. the hetero-coordination number.
</details>
<details>
<summary>摘要</summary>
“三维结构Characterization的研究对于异化体组合物有很大的 интерес，例如 derivation of process-structure or structure-property relationships. However, since 3D imaging techniques are often difficult to perform and time-consuming, a characterization of hetero-aggregates based on 2D image data is desirable but challenging. To overcome the limitations of characterizing 3D structures from 2D measurements, a method is proposed that combines machine learning with spatial stochastic modeling. This approach utilizes synthetic training data generated by the latter method to avoid time-consuming experiments for the synthesis of differently structured materials and their 3D imaging. Specifically, a parametric stochastic 3D model is presented, from which a wide spectrum of virtual hetero-aggregates can be generated. The virtual structures are then passed to a physics-based simulation tool to generate virtual scanning transmission electron microscopy (STEM) images. The pre-set parameters of the 3D model and the simulated STEM images serve as a database for training convolutional neural networks, which can be used to determine the parameters of the underlying 3D model and predict 3D structures of hetero-aggregates from 2D STEM images. Additionally, an error analysis is performed to evaluate the prediction power of the trained neural networks with respect to structural descriptors, such as the hetero-coordination number.”Note that Simplified Chinese is used in this translation, which is a standardized form of Chinese that is easier to read and write than Traditional Chinese. However, if you prefer Traditional Chinese, I can also provide the translation in that format.
</details></li>
</ul>
<hr>
<h2 id="Learning-to-recognize-occluded-and-small-objects-with-partial-inputs"><a href="#Learning-to-recognize-occluded-and-small-objects-with-partial-inputs" class="headerlink" title="Learning to recognize occluded and small objects with partial inputs"></a>Learning to recognize occluded and small objects with partial inputs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18517">http://arxiv.org/abs/2310.18517</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hasibzunair/msl-recognition">https://github.com/hasibzunair/msl-recognition</a></li>
<li>paper_authors: Hasib Zunair, A. Ben Hamza</li>
<li>for: 多个图像中的多个对象识别，特别是当这些对象小时， occlusion 问题更加困难。</li>
<li>methods: 我们提出了Masked Supervised Learning（MSL），一种单stage，无需特定模型的学习方法，通过遮盲分支学习 context-based 表示，并通过标签一致性来模型标签的相互关系。</li>
<li>results: 实验结果表明，MSL 能够与之前的状态图像识别方法竞争，并且可以快速、简单地应用于多个标签图像识别任务。此外，我们还证明了MSL 对随机遮盲的稳定性和非遮盲对象的识别能力。代码和预训练模型可以在 GitHub 上获取。<details>
<summary>Abstract</summary>
Recognizing multiple objects in an image is challenging due to occlusions, and becomes even more so when the objects are small. While promising, existing multi-label image recognition models do not explicitly learn context-based representations, and hence struggle to correctly recognize small and occluded objects. Intuitively, recognizing occluded objects requires knowledge of partial input, and hence context. Motivated by this intuition, we propose Masked Supervised Learning (MSL), a single-stage, model-agnostic learning paradigm for multi-label image recognition. The key idea is to learn context-based representations using a masked branch and to model label co-occurrence using label consistency. Experimental results demonstrate the simplicity, applicability and more importantly the competitive performance of MSL against previous state-of-the-art methods on standard multi-label image recognition benchmarks. In addition, we show that MSL is robust to random masking and demonstrate its effectiveness in recognizing non-masked objects. Code and pretrained models are available on GitHub.
</details>
<details>
<summary>摘要</summary>
Recognizing multiple objects in an image is challenging due to occlusions, and becomes even more so when the objects are small. While existing multi-label image recognition models show promise, they do not explicitly learn context-based representations, and therefore struggle to correctly recognize small and occluded objects. Intuitively, recognizing occluded objects requires knowledge of partial input, and hence context. Motivated by this intuition, we propose Masked Supervised Learning (MSL), a single-stage, model-agnostic learning paradigm for multi-label image recognition. The key idea is to learn context-based representations using a masked branch and to model label co-occurrence using label consistency. Experimental results demonstrate the simplicity, applicability, and more importantly the competitive performance of MSL against previous state-of-the-art methods on standard multi-label image recognition benchmarks. In addition, we show that MSL is robust to random masking and demonstrate its effectiveness in recognizing non-masked objects. Code and pretrained models are available on GitHub.Here's the translation in Traditional Chinese:识别多个图像中的物体是困难的，尤其是当物体小时。现有的多 Label 图像识别模型虽然有推荐，但是它们不会直接学习上下文基于的表现，因此对于小和遮蔽的物体来说，其表现不佳。我们受到这个直觉的动机，提出了几个概念，包括：几个 Label 的共同出现，以及对于部分输入的知识。我们提出了一个单阶段、无法检测的学习方法，即掩盖Supervised Learning (MSL)，以学习上下文基于的表现。我们的关键思想是，通过掩盖分支来学习上下文基于的表现，并且使用标签的共同出现来模型标签的共同性。我们的实验结果显示，MSL 的简单性、应用性和更重要的是，与前一代方法相比，其表现非常竞争。此外，我们还证明了 MSL 在随机掩盖下是稳定的，并且在非掩盖的情况下表现良好。我们的代码和预训模型都可以在 GitHub 上找到。
</details></li>
</ul>
<hr>
<h2 id="GPT-4-Vision-on-Medical-Image-Classification-–-A-Case-Study-on-COVID-19-Dataset"><a href="#GPT-4-Vision-on-Medical-Image-Classification-–-A-Case-Study-on-COVID-19-Dataset" class="headerlink" title="GPT-4 Vision on Medical Image Classification – A Case Study on COVID-19 Dataset"></a>GPT-4 Vision on Medical Image Classification – A Case Study on COVID-19 Dataset</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18498">http://arxiv.org/abs/2310.18498</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruibo Chen, Tianyi Xiong, Yihan Wu, Guodong Liu, Zhengmian Hu, Lichang Chen, Yanshuo Chen, Chenxi Liu, Heng Huang</li>
<li>for: 这份技术报告探讨了 COVID-19 图像分类领域中 GPT-4 Vision (GPT-4V) 的应用，通过培养学习环境中的启发性来提高诊断过程。</li>
<li>methods: 该文使用 GPT-4V 在 COVID-19 图像中进行了启发性学习，以提高图像分类的准确率。</li>
<li>results: 研究发现，通过使用 GPT-4V，图像分类的准确率得到了显著提高，表明了 GPT-4V 在 COVID-19 图像分类中的潜在应用价值。<details>
<summary>Abstract</summary>
This technical report delves into the application of GPT-4 Vision (GPT-4V) in the nuanced realm of COVID-19 image classification, leveraging the transformative potential of in-context learning to enhance diagnostic processes.
</details>
<details>
<summary>摘要</summary>
这份技术报告探讨了 COVID-19 图像分类领域中 GPT-4 Vision（GPT-4V）的应用，利用 context learning 的潜在力量提高诊断过程。Note:* "GPT-4V" is translated as "GPT-4 Vision" (格PT-4视力)* "in-context learning" is translated as " context learning" (上下文学习)* "diagnostic processes" is translated as "诊断过程" (诊断过程)
</details></li>
</ul>
<hr>
<h2 id="Knowledge-based-in-silico-models-and-dataset-for-the-comparative-evaluation-of-mammography-AI-for-a-range-of-breast-characteristics-lesion-conspicuities-and-doses"><a href="#Knowledge-based-in-silico-models-and-dataset-for-the-comparative-evaluation-of-mammography-AI-for-a-range-of-breast-characteristics-lesion-conspicuities-and-doses" class="headerlink" title="Knowledge-based in silico models and dataset for the comparative evaluation of mammography AI for a range of breast characteristics, lesion conspicuities and doses"></a>Knowledge-based in silico models and dataset for the comparative evaluation of mammography AI for a range of breast characteristics, lesion conspicuities and doses</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18494">http://arxiv.org/abs/2310.18494</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/didsr/msynth-release">https://github.com/didsr/msynth-release</a></li>
<li>paper_authors: Elena Sizikova, Niloufar Saharkhiz, Diksha Sharma, Miguel Lago, Berkman Sahiner, Jana G. Delfino, Aldo Badano</li>
<li>for: 评估人工智能（AI）医疗设备的安全性和效能，需要评估AI模型在不同的患者群体中表现。</li>
<li>methods: 我们提出一种基于计算机模拟的评估方法，使用干扰性的数字模型来模拟人体解剖结构，并使用数字复制成像系统来生成真实的synthetic图像集。</li>
<li>results: 我们释放了M-SYNTH数据集，包含四种乳腺纤维质分布的人群，通过Monte Carlo x射线计算模拟不同的暴露水平进行图像捕获。我们发现，随着乳腺纤维质的增加，AI模型的性能逐渐下降，而随着质量的增加，AI模型的性能则逐渐提高。随着暴露水平的减少，AI模型的性能下降，最高的性能出现在较低的暴露水平下。<details>
<summary>Abstract</summary>
To generate evidence regarding the safety and efficacy of artificial intelligence (AI) enabled medical devices, AI models need to be evaluated on a diverse population of patient cases, some of which may not be readily available. We propose an evaluation approach for testing medical imaging AI models that relies on in silico imaging pipelines in which stochastic digital models of human anatomy (in object space) with and without pathology are imaged using a digital replica imaging acquisition system to generate realistic synthetic image datasets. Here, we release M-SYNTH, a dataset of cohorts with four breast fibroglandular density distributions imaged at different exposure levels using Monte Carlo x-ray simulations with the publicly available Virtual Imaging Clinical Trial for Regulatory Evaluation (VICTRE) toolkit. We utilize the synthetic dataset to analyze AI model performance and find that model performance decreases with increasing breast density and increases with higher mass density, as expected. As exposure levels decrease, AI model performance drops with the highest performance achieved at exposure levels lower than the nominal recommended dose for the breast type.
</details>
<details>
<summary>摘要</summary>
<<SYS>>为了生成人工智能（AI）医疗设备的安全性和有效性的证据，我们需要对各种患者群体的病例进行评估。我们提出了一种使用数字医学ipeline进行医学影像AI模型的评估方法，其中使用了卫星模型来生成人工的影像数据集。在这种方法中，我们使用了VICTRE工具包来进行Monte Carlo x射线计算，生成了不同抑制物质分布的胸部病例数据集。我们通过分析这些数据来评估AI模型的性能，发现模型性能随着乳腺细胞分布的增加而下降，而模型在高质量细胞分布下的性能最高。随着曝光水平的下降，AI模型的性能下降，最佳性能在低于标准推荐剂量之下得到。>>>
</details></li>
</ul>
<hr>
<h2 id="Exploring-Shape-Embedding-for-Cloth-Changing-Person-Re-Identification-via-2D-3D-Correspondences"><a href="#Exploring-Shape-Embedding-for-Cloth-Changing-Person-Re-Identification-via-2D-3D-Correspondences" class="headerlink" title="Exploring Shape Embedding for Cloth-Changing Person Re-Identification via 2D-3D Correspondences"></a>Exploring Shape Embedding for Cloth-Changing Person Re-Identification via 2D-3D Correspondences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18438">http://arxiv.org/abs/2310.18438</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yubin Wang, Huimin Yu, Yuming Yan, Shuyi Song, Biyang Liu, Yichong Lu<br>for: 这篇论文旨在解决 cloth-changing ReID 问题，即人脸识别 task 中人物穿着不同服装时的问题。methods: 这篇论文提出了一种新的 shape embedding 方法，即 Continuous Surface Correspondence Learning (CSCL)，它通过Pixel-to-vertex classification来建立人像与3D人体模型之间的连续匹配，从而获取人像与3D模型之间的匹配点。results: 实验表明，CSCL 方法可以remarkably enhance the model’s global understanding of human body shape，并在 cloth-changing ReID 和 cloth-consistent ReID Benchmarks 上达到了出色的效果。<details>
<summary>Abstract</summary>
Cloth-Changing Person Re-Identification (CC-ReID) is a common and realistic problem since fashion constantly changes over time and people's aesthetic preferences are not set in stone. While most existing cloth-changing ReID methods focus on learning cloth-agnostic identity representations from coarse semantic cues (e.g. silhouettes and part segmentation maps), they neglect the continuous shape distributions at the pixel level. In this paper, we propose Continuous Surface Correspondence Learning (CSCL), a new shape embedding paradigm for cloth-changing ReID. CSCL establishes continuous correspondences between a 2D image plane and a canonical 3D body surface via pixel-to-vertex classification, which naturally aligns a person image to the surface of a 3D human model and simultaneously obtains pixel-wise surface embeddings. We further extract fine-grained shape features from the learned surface embeddings and then integrate them with global RGB features via a carefully designed cross-modality fusion module. The shape embedding paradigm based on 2D-3D correspondences remarkably enhances the model's global understanding of human body shape. To promote the study of ReID under clothing change, we construct 3D Dense Persons (DP3D), which is the first large-scale cloth-changing ReID dataset that provides densely annotated 2D-3D correspondences and a precise 3D mesh for each person image, while containing diverse cloth-changing cases over all four seasons. Experiments on both cloth-changing and cloth-consistent ReID benchmarks validate the effectiveness of our method.
</details>
<details>
<summary>摘要</summary>
cloth-changing 人识别 (CC-ReID) 是一个常见并且现实存在的问题，因为时尚不断发展，人们的美学偏好也不是固定的。现有的 cloth-changing ReID 方法多数是通过学习粗略的 semantic cues（例如 silhouette 和 part segmentation map）来学习不同服装下的人脸特征，但是它们忽略了人体图像中精细的形状分布。在这篇文章中，我们提出了 Continuous Surface Correspondence Learning (CSCL)，一种新的形状嵌入方法，用于 cloth-changing ReID。CSCL 通过像素到顶点的分类来建立人体图像与Canonical 3D 人体模型之间的连续对应关系，从而自然地将人体图像与模型之间建立对应关系，同时获得像素级别的表面嵌入。我们还提取了高级别的形状特征从学习的表面嵌入，然后与全球 RGB 特征进行权重相乘。基于 2D-3D 对应关系的形状嵌入方法，可以强化模型对人体形状的全面理解。为了推动 cloth-changing ReID 的研究，我们构建了 3D Dense Persons (DP3D)，这是首个包含了不同的服装变化情况的 cloth-changing ReID 数据集，每个人像图像都有精 densely 注解的 2D-3D 对应关系和精确的 3D 网格。实验表明，我们的方法在 cloth-changing 和 cloth-consistent ReID Benchmark 上具有remarkable的效果。
</details></li>
</ul>
<hr>
<h2 id="Always-Clear-Days-Degradation-Type-and-Severity-Aware-All-In-One-Adverse-Weather-Removal"><a href="#Always-Clear-Days-Degradation-Type-and-Severity-Aware-All-In-One-Adverse-Weather-Removal" class="headerlink" title="Always Clear Days: Degradation Type and Severity Aware All-In-One Adverse Weather Removal"></a>Always Clear Days: Degradation Type and Severity Aware All-In-One Adverse Weather Removal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18293">http://arxiv.org/abs/2310.18293</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu-Wei Chen, Soo-Chang Pei</li>
<li>for: 本研究旨在提出一种综合恢复多种恶势力影像的模型，以解决多种恶势力影像恢复中的两大挑战：第一，发现和处理多元领域的目标分布；第二，设计高效和有效的操作来处理不同类型的降低。</li>
<li>methods: 该模型基于inter&amp;intra-domain适应 literatura，并提出了一种新的Marginal Quality Ranking Loss（MQRL）和一种新的Contrastive Loss（CL）来引导气象情况的提取，以及一些新的技术如多头相关混合（MHCA）和本地-全局适应实例 нормализа（LG-AdaIN）来高效地恢复空间变化的气象降低。</li>
<li>results: 相比于现有的State-of-the-Art方法，该模型可以在不同的气象恢复任务中显著超越对手，并且具有较少的模型参数。此外，该模型还可以 Restore 未seen 领域的多种气象降低图像，并可以调整恢复水平。<details>
<summary>Abstract</summary>
All-in-one adverse weather removal is an emerging topic on image restoration, which aims to restore multiple weather degradation in an unified model, and the challenging are twofold. First, discovering and handling the property of multi-domain in target distribution formed by multiple weather conditions. Second, design efficient and effective operations for different degradation types. To address this problem, most prior works focus on the multi-domain caused by weather type. Inspired by inter\&intra-domain adaptation literature, we observed that not only weather type but also weather severity introduce multi-domain within each weather type domain, which is ignored by previous methods, and further limit their performance. To this end, we proposed a degradation type and severity aware model, called \textbf{UtilityIR}, for blind all-in-one bad weather image restoration. To extract weather information from single image, we proposed a novel Marginal Quality Ranking Loss (MQRL) and utilized Contrastive Loss (CL) to guide weather severity and type extraction, and leverage a bag of novel techniques such as Multi-Head Cross Attention (MHCA) and Local-Global Adaptive Instance Normalization (LG-AdaIN) to efficiently restore spatial varying weather degradation. The proposed method can significantly outperform the SOTA methods subjectively and objectively on different weather restoration tasks with a large margin, and enjoy less model parameters. Proposed method even can restore \textbf{unseen} domain combined multiple degradation images, and modulating restoration level. Implementation code will be available at {https://github.com/fordevoted/UtilityIR}{\textit{this repository}
</details>
<details>
<summary>摘要</summary>
全面天气环境去除是一个现代图像修复领域的热点问题，目标是通过一个统一模型来恢复多种天气下的图像异常情况，问题的两个级别是：首先，发现和处理目标分布中多个域的性质，其次，设计高效和有效的操作方法 для不同的退化类型。以前的大多数工作都是通过多种天气类型来处理多个域的问题，但是我们发现，不同的天气严重性也会在每个天气类型中引入多个域，这一点被以前的方法忽略了，从而限制了其性能。为了解决这个问题，我们提出了一种具有退化类型和严重性意识的模型，称为\textbf{UtilityIR}，用于盲目全面坏天气图像修复。为了从单个图像中提取天气信息，我们提出了一种新的环境质量排名损失函数（MQRL），并使用了对比损失函数（CL）来引导天气严重性和类型的提取，并利用了一系列新的技术，如多头交叉注意力（MHCA）和本地-全局适应实例均衡化（LG-AdaIN），以高效地恢复空间变化的天气退化。我们的方法可以Subjectively和Objectively在不同的天气修复任务上与state-of-the-art方法进行比较，并且具有较少的模型参数。我们的方法甚至可以恢复未经见过的多个退化图像，并可以调整修复水平。我们的实现代码将在[这个仓库](https://github.com/fordevoted/UtilityIR)上提供。
</details></li>
</ul>
<hr>
<h2 id="Heterogeneous-Federated-Learning-with-Group-Aware-Prompt-Tuning"><a href="#Heterogeneous-Federated-Learning-with-Group-Aware-Prompt-Tuning" class="headerlink" title="Heterogeneous Federated Learning with Group-Aware Prompt Tuning"></a>Heterogeneous Federated Learning with Group-Aware Prompt Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18285">http://arxiv.org/abs/2310.18285</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenlong Deng, Christos Thrampoulidis, Xiaoxiao Li</li>
<li>for: 这篇论文探讨了在联合学习（Federated Learning，FL）中使用转换器模型的应用，尤其是在具有多种本地数据的各种客户端上。</li>
<li>methods: 我们采用了预训练的转换器模型，并使用高效的提问调整策略。我们的策略是学习共享提问和组提问，以同时获得通用知识和组特定知识。此外，我们还设置了个性化组提问分配模块，以对每个输入分配个性化的组提问，使全球模型与每个客户端的数据分布相匹配。</li>
<li>results: 我们的方法可以让单个全球模型自动适应不同客户端的本地数据分布，不需要本地微调。与替换方法不同，我们的方法可以准确地跨越客户端之间的差异，从而实现联合学习中的全球和本地模型匹配。我们通过了广泛的实验和减少研究来证明方法的有效性。<details>
<summary>Abstract</summary>
Transformers have achieved remarkable success in various machine-learning tasks, prompting their widespread adoption. In this paper, we explore their application in the context of federated learning (FL), with a particular focus on heterogeneous scenarios where individual clients possess diverse local datasets. To meet the computational and communication demands of FL, we leverage pre-trained Transformers and use an efficient prompt-tuning strategy. Our strategy introduces the concept of learning both shared and group prompts, enabling the acquisition of universal knowledge and group-specific knowledge simultaneously. Additionally, a prompt selection module assigns personalized group prompts to each input, aligning the global model with the data distribution of each client. This approach allows us to train a single global model that can automatically adapt to various local client data distributions without requiring local fine-tuning. In this way, our proposed method effectively bridges the gap between global and personalized local models in Federated Learning and surpasses alternative approaches that lack the capability to adapt to previously unseen clients. The effectiveness of our approach is rigorously validated through extensive experimentation and ablation studies.
</details>
<details>
<summary>摘要</summary>
“对于联邦学习（Federated Learning，FL）的应用，trasnformers已经取得了杰出的成就，它们的广泛应用引起了广泛的关注。在本文中，我们探讨trasnformers在多种不同资料分布的联邦学习中的应用，特别是在客户端拥有多样化的本地数据时。为了解决联邦学习中的计算和通信需求，我们将pre-trained transformers和高效的提示调整策略应用于联邦学习。我们的策略是学习共享和分组提示，允许同时获取通用知识和分组特定知识。此外，提示选择模块将每个输入的个人化分组提示分配给每个客户端，使全球模型与每个客户端的数据分布保持一致。这种方法允许我们训练一个单一的全球模型，无需进行本地微调整，并且自动适应不同客户端的数据分布。因此，我们的提案可以有效地跨越全球和个人化的客户端模型之间的差异，超越缺乏适应不见前的客户端模型。我们的方法的有效性经过了广泛的实验和剥夺研究，以证明其可行性和优势。”
</details></li>
</ul>
<hr>
<h2 id="FOUND-Foot-Optimization-with-Uncertain-Normals-for-Surface-Deformation-Using-Synthetic-Data"><a href="#FOUND-Foot-Optimization-with-Uncertain-Normals-for-Surface-Deformation-Using-Synthetic-Data" class="headerlink" title="FOUND: Foot Optimization with Uncertain Normals for Surface Deformation Using Synthetic Data"></a>FOUND: Foot Optimization with Uncertain Normals for Surface Deformation Using Synthetic Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18279">http://arxiv.org/abs/2310.18279</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oliver Boyne, Gwangbin Bae, James Charles, Roberto Cipolla</li>
<li>for: 这个论文的目的是为了实现几个视图图像中的表面重建 task，并且它特别关注人 Foot 的重建。</li>
<li>methods: 该论文使用了一种 uncertainty-aware 的表面法向量预测器，以及一种优化方案来适应一系列图像。</li>
<li>results: 论文表明其法向量预测器在实际图像上表现出色，而优化方案也在几个视图设置下比 estado del arte 光学测量管道表现更好。<details>
<summary>Abstract</summary>
Surface reconstruction from multi-view images is a challenging task, with solutions often requiring a large number of sampled images with high overlap. We seek to develop a method for few-view reconstruction, for the case of the human foot. To solve this task, we must extract rich geometric cues from RGB images, before carefully fusing them into a final 3D object. Our FOUND approach tackles this, with 4 main contributions: (i) SynFoot, a synthetic dataset of 50,000 photorealistic foot images, paired with ground truth surface normals and keypoints; (ii) an uncertainty-aware surface normal predictor trained on our synthetic dataset; (iii) an optimization scheme for fitting a generative foot model to a series of images; and (iv) a benchmark dataset of calibrated images and high resolution ground truth geometry. We show that our normal predictor outperforms all off-the-shelf equivalents significantly on real images, and our optimization scheme outperforms state-of-the-art photogrammetry pipelines, especially for a few-view setting. We release our synthetic dataset and baseline 3D scans to the research community.
</details>
<details>
<summary>摘要</summary>
表面重建从多视图图像是一项具有挑战性的任务，解决方案通常需要大量的采样图像和高重叠率。我们寻求开发一种几视图重建方法，专门针对人体脚部。为解决这个任务，我们需要从RGB图像中提取丰富的地理学特征，然后精心融合到最终的3D对象中。我们的FOUND方法从以下四个方面做出贡献：(i) SynFoot，一个包含50,000个真实风格的脚部图像，每个图像都有附加的表面法向量和关键点数据；(ii) 基于我们的 sintetic dataset 的不确定性感知表面法向量预测器；(iii) 用于把一系列图像适应到生成的脚部模型中的优化方案；(iv) 一个准备了卡лли布рован的图像和高分辨率的真实地理学几何结构的参考数据集。我们表明我们的normal预测器在真实图像上明显超过了所有准备的等价器，而我们的优化方案在几视图设置下明显超过了当前的摄影探测渠道。我们发布我们的 sintetic dataset 和基线3D扫描数据，以便研究人员进行更多的探索和应用。
</details></li>
</ul>
<hr>
<h2 id="LipSim-A-Provably-Robust-Perceptual-Similarity-Metric"><a href="#LipSim-A-Provably-Robust-Perceptual-Similarity-Metric" class="headerlink" title="LipSim: A Provably Robust Perceptual Similarity Metric"></a>LipSim: A Provably Robust Perceptual Similarity Metric</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18274">http://arxiv.org/abs/2310.18274</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/saraghazanfari/lipsim">https://github.com/saraghazanfari/lipsim</a></li>
<li>paper_authors: Sara Ghazanfari, Alexandre Araujo, Prashanth Krishnamurthy, Farshad Khorrami, Siddharth Garg</li>
<li>for: This paper is written for researchers and practitioners interested in developing and applying perceptual similarity metrics, particularly those concerned with the vulnerability of these metrics to adversarial attacks.</li>
<li>methods: The paper uses an ensemble of ViT-based feature extractors and proposes a framework for training a robust perceptual similarity metric called LipSim, which leverages 1-Lipschitz neural networks as the backbone and provides provable guarantees.</li>
<li>results: The paper demonstrates the vulnerability of state-of-the-art perceptual similarity metrics to adversarial attacks and presents a comprehensive set of experiments showing the performance of LipSim in terms of natural and certified scores, as well as on the image retrieval application.<details>
<summary>Abstract</summary>
Recent years have seen growing interest in developing and applying perceptual similarity metrics. Research has shown the superiority of perceptual metrics over pixel-wise metrics in aligning with human perception and serving as a proxy for the human visual system. On the other hand, as perceptual metrics rely on neural networks, there is a growing concern regarding their resilience, given the established vulnerability of neural networks to adversarial attacks. It is indeed logical to infer that perceptual metrics may inherit both the strengths and shortcomings of neural networks. In this work, we demonstrate the vulnerability of state-of-the-art perceptual similarity metrics based on an ensemble of ViT-based feature extractors to adversarial attacks. We then propose a framework to train a robust perceptual similarity metric called LipSim (Lipschitz Similarity Metric) with provable guarantees. By leveraging 1-Lipschitz neural networks as the backbone, LipSim provides guarded areas around each data point and certificates for all perturbations within an $\ell_2$ ball. Finally, a comprehensive set of experiments shows the performance of LipSim in terms of natural and certified scores and on the image retrieval application. The code is available at https://github.com/SaraGhazanfari/LipSim.
</details>
<details>
<summary>摘要</summary>
近年来，有越来越多的研究者关注开发和应用感知相似度度量。研究表明，感知度量比像素精度更能与人类感知相匹配，并作为人类视觉系统的代理。然而，由于感知度量基于神经网络，因此存在抗击攻击的担忧。这是合理的推理，因为神经网络具有抗击攻击的敏感性。在这种情况下，我们展示了现状顶尖感知相似度度量基于ViT基于特征提取器的集成系统对抗攻击的漏斗性。然后，我们提议一种训练可靠的感知相似度度量的框架，称为LipSim（Lipschitz相似度度量）。通过使用1-Lipschitz神经网络作为核心，LipSim提供了每个数据点的保护区和所有折射在$\ell_2$球体内的证明。最后，我们进行了详细的实验，以评估LipSim在自然和证明得分上的性能，以及图像检索应用中的表现。代码可以在https://github.com/SaraGhazanfari/LipSim中找到。
</details></li>
</ul>
<hr>
<h2 id="PlantPlotGAN-A-Physics-Informed-Generative-Adversarial-Network-for-Plant-Disease-Prediction"><a href="#PlantPlotGAN-A-Physics-Informed-Generative-Adversarial-Network-for-Plant-Disease-Prediction" class="headerlink" title="PlantPlotGAN: A Physics-Informed Generative Adversarial Network for Plant Disease Prediction"></a>PlantPlotGAN: A Physics-Informed Generative Adversarial Network for Plant Disease Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18268">http://arxiv.org/abs/2310.18268</a></li>
<li>repo_url: None</li>
<li>paper_authors: Felipe A. Lopes, Vasit Sagan, Flavio Esposito</li>
<li>for: 园区监测是重要的农业管理和收获健康的关键，尤其是检测植物疾病。</li>
<li>methods: 我们使用无人飞行器（UAV）收集多spectral图像，以帮助园区监测。</li>
<li>results: 我们的 PlantPlotGAN 模型可以生成高品质的合成多spectral图像，并且可以提高检测植物疾病的预测模型精度。<details>
<summary>Abstract</summary>
Monitoring plantations is crucial for crop management and producing healthy harvests. Unmanned Aerial Vehicles (UAVs) have been used to collect multispectral images that aid in this monitoring. However, given the number of hectares to be monitored and the limitations of flight, plant disease signals become visually clear only in the later stages of plant growth and only if the disease has spread throughout a significant portion of the plantation. This limited amount of relevant data hampers the prediction models, as the algorithms struggle to generalize patterns with unbalanced or unrealistic augmented datasets effectively. To address this issue, we propose PlantPlotGAN, a physics-informed generative model capable of creating synthetic multispectral plot images with realistic vegetation indices. These indices served as a proxy for disease detection and were used to evaluate if our model could help increase the accuracy of prediction models. The results demonstrate that the synthetic imagery generated from PlantPlotGAN outperforms state-of-the-art methods regarding the Fr\'echet inception distance. Moreover, prediction models achieve higher accuracy metrics when trained with synthetic and original imagery for earlier plant disease detection compared to the training processes based solely on real imagery.
</details>
<details>
<summary>摘要</summary>
监测植业是cro管理和生产健康卫生的关键。无人驾驶飞行器（UAV）已被用于收集多spectral图像，以帮助监测。然而， giventhe number of hectares to be monitored and the limitations of flight, plant disease signals only become visually clear in the later stages of plant growth, and only if the disease has spread throughout a significant portion of the plantation. This limited amount of relevant data hampers the prediction models, as the algorithms struggle to generalize patterns with unbalanced or unrealistic augmented datasets effectively. To address this issue, we propose PlantPlotGAN, a physics-informed generative model capable of creating synthetic multispectral plot images with realistic vegetation indices. These indices served as a proxy for disease detection and were used to evaluate if our model could help increase the accuracy of prediction models. The results demonstrate that the synthetic imagery generated from PlantPlotGAN outperforms state-of-the-art methods regarding the Fréchet inception distance. Moreover, prediction models achieve higher accuracy metrics when trained with synthetic and original imagery for earlier plant disease detection compared to the training processes based solely on real imagery.Here's the word-for-word translation:监测植业是cro管理和生产健康卫生的关键。无人驾驶飞行器（UAV）已被用于收集多spectral图像，以帮助监测。然而， giventhe number of hectares to be monitored and the limitations of flight, plant disease signals only become visually clear in the later stages of plant growth, and only if the disease has spread throughout a significant portion of the plantation. This limited amount of relevant data hampers the prediction models, as the algorithms struggle to generalize patterns with unbalanced or unrealistic augmented datasets effectively. To address this issue, we propose PlantPlotGAN, a physics-informed generative model capable of creating synthetic multispectral plot images with realistic vegetation indices. These indices served as a proxy for disease detection and were used to evaluate if our model could help increase the accuracy of prediction models. The results demonstrate that the synthetic imagery generated from PlantPlotGAN outperforms state-of-the-art methods regarding the Fréchet inception distance. Moreover, prediction models achieve higher accuracy metrics when trained with synthetic and original imagery for earlier plant disease detection compared to the training processes based solely on real imagery.
</details></li>
</ul>
<hr>
<h2 id="A-Self-Supervised-Approach-to-Land-Cover-Segmentation"><a href="#A-Self-Supervised-Approach-to-Land-Cover-Segmentation" class="headerlink" title="A Self-Supervised Approach to Land Cover Segmentation"></a>A Self-Supervised Approach to Land Cover Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18251">http://arxiv.org/abs/2310.18251</a></li>
<li>repo_url: None</li>
<li>paper_authors: Charles Moore, Dakota Hester</li>
<li>for: 这个论文旨在提供一种自动化高分辨率农业Remote sensing图像分类方法，不需要高质量的地面真实标签。</li>
<li>methods: 该方法使用一个冻结的预训练ViT背景，并在STEGO架构中进行微调。</li>
<li>results: 经过10个微调轮，实现了约52%的准确率在5个样本中，表明了自动化标注高分辨率农业Remote sensing图像的可能性。<details>
<summary>Abstract</summary>
Land use/land cover change (LULC) maps are integral resources in earth science and agricultural research. Due to the nature of such maps, the creation of LULC maps is often constrained by the time and human resources necessary to accurately annotate satellite imagery and remote sensing data. While computer vision models that perform semantic segmentation to create detailed labels from such data are not uncommon, litle research has been done on self-supervised and unsupervised approaches to labelling LULC maps without the use of ground-truth masks. Here, we demonstrate a self-supervised method of land cover segmentation that has no need for high-quality ground truth labels. The proposed deep learning employs a frozen pre-trained ViT backbone transferred from DINO in a STEGO architecture and is fine-tuned using a custom dataset consisting of very high resolution (VHR) sattelite imagery. After only 10 epochs of fine-tuning, an accuracy of roughly 52% was observed across 5 samples, signifying the feasibility of self-supervised models for the automated labelling of VHR LULC maps.
</details>
<details>
<summary>摘要</summary>
Land use/land cover change（LULC）地图是地球科学和农业研究中的重要资源。由于LULC地图的创建通常受到时间和人员资源的限制，因为需要精确地标注卫星图像和远程感知数据。虽然用计算机视觉模型进行semantic segmentation，从数据中生成细节标签并不是无前例的，但是对LULC地图的自动标注而无需高质量地面真实标签的研究不多。本文提出了一种没有需要高质量地面真实标签的自动标注方法。该深度学习模型使用冰结的预训练ViT背bone，并在STEGO架构中进行了精度调整。经过10个精度调整 epoch，模型在5个样本上达到了约52%的准确率，表明自动标注模型可以实施高分辨率LULC地图的自动标注。
</details></li>
</ul>
<hr>
<h2 id="Generative-AI-Model-for-Artistic-Style-Transfer-Using-Convolutional-Neural-Networks"><a href="#Generative-AI-Model-for-Artistic-Style-Transfer-Using-Convolutional-Neural-Networks" class="headerlink" title="Generative AI Model for Artistic Style Transfer Using Convolutional Neural Networks"></a>Generative AI Model for Artistic Style Transfer Using Convolutional Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18237">http://arxiv.org/abs/2310.18237</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonayet Miah, Duc M Cao, Md Abu Sayed, Md. Sabbirul Haque</li>
<li>for: 本文概述了一种基于卷积神经网络（CNN）的图像风格转移技术，用于将一个图像的内容和风格与另一个图像的风格相结合，创造独特的视觉作品。</li>
<li>methods: 本文使用了深度图像表示学习的 CNN 来分离和控制图像的内容和风格，并通过损失计算和优化来实现高质量的风格转移。</li>
<li>results: 本文通过实验结果显示了该方法的效果和多样性，包括不同风格和内容的图像合成。<details>
<summary>Abstract</summary>
Artistic style transfer, a captivating application of generative artificial intelligence, involves fusing the content of one image with the artistic style of another to create unique visual compositions. This paper presents a comprehensive overview of a novel technique for style transfer using Convolutional Neural Networks (CNNs). By leveraging deep image representations learned by CNNs, we demonstrate how to separate and manipulate image content and style, enabling the synthesis of high-quality images that combine content and style in a harmonious manner. We describe the methodology, including content and style representations, loss computation, and optimization, and showcase experimental results highlighting the effectiveness and versatility of the approach across different styles and content
</details>
<details>
<summary>摘要</summary>
美术风格传输，一种吸引人的生成人工智能应用，涉及将一幅图像的内容与另一幅图像的艺术风格相结合，以创造独特的视觉作品。本文提出了一种基于卷积神经网络（CNN）的新方法，用于实现风格传输。通过利用深度图像表示学习出来的CNN，我们示例了如何分离和处理图像内容和风格，以生成高质量的合成图像，其中内容和风格兼得协调。我们介绍了方法的具体实现，包括内容和风格表示、损失计算和优化，并通过实验结果表明该方法在不同的风格和内容上的效果和多样性。
</details></li>
</ul>
<hr>
<h2 id="How-Re-sampling-Helps-for-Long-Tail-Learning"><a href="#How-Re-sampling-Helps-for-Long-Tail-Learning" class="headerlink" title="How Re-sampling Helps for Long-Tail Learning?"></a>How Re-sampling Helps for Long-Tail Learning?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18236">http://arxiv.org/abs/2310.18236</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shijxcs/csa">https://github.com/shijxcs/csa</a></li>
<li>paper_authors: Jiang-Xin Shi, Tong Wei, Yuke Xiang, Yu-Feng Li</li>
<li>for: investigate the effectiveness of re-sampling in modern long-tail learning tasks</li>
<li>methods: experiments on two homogeneous datasets, context shift augmentation module to generate diverse training images for the tail class</li>
<li>results: proposed module can boost generalization and outperform other approaches, including class-balanced re-sampling, decoupled classifier re-training, and data augmentation methods<details>
<summary>Abstract</summary>
Long-tail learning has received significant attention in recent years due to the challenge it poses with extremely imbalanced datasets. In these datasets, only a few classes (known as the head classes) have an adequate number of training samples, while the rest of the classes (known as the tail classes) are infrequent in the training data. Re-sampling is a classical and widely used approach for addressing class imbalance issues. Unfortunately, recent studies claim that re-sampling brings negligible performance improvements in modern long-tail learning tasks. This paper aims to investigate this phenomenon systematically. Our research shows that re-sampling can considerably improve generalization when the training images do not contain semantically irrelevant contexts. In other scenarios, however, it can learn unexpected spurious correlations between irrelevant contexts and target labels. We design experiments on two homogeneous datasets, one containing irrelevant context and the other not, to confirm our findings. To prevent the learning of spurious correlations, we propose a new context shift augmentation module that generates diverse training images for the tail class by maintaining a context bank extracted from the head-class images. Experiments demonstrate that our proposed module can boost the generalization and outperform other approaches, including class-balanced re-sampling, decoupled classifier re-training, and data augmentation methods. The source code is available at https://www.lamda.nju.edu.cn/code_CSA.ashx.
</details>
<details>
<summary>摘要</summary>
“长尾学习在最近几年内得到了广泛关注，因为它面临着极其不均衡的数据集的挑战。在这些数据集中，只有一些类（称为头类）有足够的训练样本，而另外的类（称为尾类）则是训练数据中罕见的。重新采样是经典的和广泛使用的方法来解决类均衡问题。然而，最新的研究表明，重新采样在现代长尾学习任务中并不能提供显著的性能提升。本文旨在系统地探讨这种现象。我们的研究表明，重新采样可以在训练图像不含 semantically irrelevant 上下文时大幅提高泛化。在其他情况下，它可能学习不相关的上下文和目标标签之间的意外相关性。我们设计了两个同质数据集的实验，一个包含 irrelevant context，另一个不包含，以确认我们的发现。为避免学习不相关的上下文，我们提议一种新的上下文shift augmentation模块，该模块可以生成 tail 类的多样化训练图像，保持 head 类图像中的上下文银行。实验表明，我们提议的模块可以提高泛化和其他方法相比，包括类均衡重新采样、解册分类器重新训练和数据扩展方法。代码可以在 <https://www.lamda.nju.edu.cn/code_CSA.ashx> 中获取。”
</details></li>
</ul>
<hr>
<h2 id="Edge-AI-Based-Vein-Detector-for-Efficient-Venipuncture-in-the-Antecubital-Fossa"><a href="#Edge-AI-Based-Vein-Detector-for-Efficient-Venipuncture-in-the-Antecubital-Fossa" class="headerlink" title="Edge AI-Based Vein Detector for Efficient Venipuncture in the Antecubital Fossa"></a>Edge AI-Based Vein Detector for Efficient Venipuncture in the Antecubital Fossa</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18234">http://arxiv.org/abs/2310.18234</a></li>
<li>repo_url: None</li>
<li>paper_authors: Edwin Salcedo, Patricia Peñaloza</li>
<li>for: 这个论文是为了提高 antecubital fossa 中的血管可见性而作的。</li>
<li>methods: 这个论文使用了 Near Infrared (NIR) 成像和深度学习 (DL) 技术来 segmentation 腕静脉。</li>
<li>results: 这个论文提出了一种新的 NIR 成像基于的腕静脉 segmentation 数据集，并提出了一种修改后的 U-Net 架构来特别地在 antecubital fossa 区域中找到血管。此外，这个论文还测试了四种常用的嵌入式微计算机和四种压缩模式，并选择了使用 Raspberry Pi 4B 卡来实现最佳的执行时间和准确性平衡。<details>
<summary>Abstract</summary>
Assessing the condition and visibility of veins is a crucial step before obtaining intravenous access in the antecubital fossa, which is a common procedure to draw blood or administer intravenous therapies (IV therapies). Even though medical practitioners are highly skilled at intravenous cannulation, they usually struggle to perform the procedure in patients with low visible veins due to fluid retention, age, overweight, dark skin tone, or diabetes. Recently, several investigations proposed combining Near Infrared (NIR) imaging and deep learning (DL) techniques for forearm vein segmentation. Although they have demonstrated compelling results, their use has been rather limited owing to the portability and precision requirements to perform venipuncture. In this paper, we aim to contribute to bridging this gap using three strategies. First, we introduce a new NIR-based forearm vein segmentation dataset of 2,016 labelled images collected from 1,008 subjects with low visible veins. Second, we propose a modified U-Net architecture that locates veins specifically in the antecubital fossa region of the examined patient. Finally, a compressed version of the proposed architecture was deployed inside a bespoke, portable vein finder device after testing four common embedded microcomputers and four common quantization modalities. Experimental results showed that the model compressed with Dynamic Range Quantization and deployed on a Raspberry Pi 4B card produced the best execution time and precision balance, with 5.14 FPS and 0.957 of latency and Intersection over Union (IoU), respectively. These results show promising performance inside a resource-restricted low-cost device.
</details>
<details>
<summary>摘要</summary>
医疗人员在 antecubital fossa 区域进行血液或 intravenous therapies (IV therapies) 的时候，需要评估血管的状况和可见度。尽管医疗人员具有高度的血液引导技能，但在有低可见度的血管的患者中，医疗人员通常会面临困难。近些年，一些研究提出了结合 Near Infrared (NIR) 成像和深度学习 (DL) 技术来 segment 胳膊血管的方法。尽管它们已经展示出了吸引人的结果，但它们的使用受到了可移植性和精度的限制，以便在进行 venipuncture 时进行血液引导。在这篇论文中，我们想要帮助bridging这个差距。我们的方法包括三个方面：1. 我们提供了一个新的 NIR-based 胳膊血管 segmentation 数据集，包含了 2,016 个标注的图像，来自 1,008 名患者，其中许多患者有低可见度的血管。2. 我们提出了一种修改后的 U-Net 架构，可以在特定的 antecubital fossa 区域内准确地定位血管。3. 我们在一个特制的、可携带的 vein finder 设备中部署了一个压缩版的提议架构，并测试了四种常见的嵌入式微计算机和四种常见的压缩模式。实验结果表明，使用 Dynamics Range Quantization 压缩并在 Raspberry Pi 4B 卡上部署的模型在执行时间和精度之间达到了良好的平衡，具体来说是 5.14 FPS 和 0.957 的延迟和 Intersection over Union (IoU)，分别是。这些结果表明在有限的资源和低成本设备中，我们的方法可以实现出色的性能。
</details></li>
</ul>
<hr>
<h2 id="TBDLNet-a-network-for-classifying-multidrug-resistant-and-drug-sensitive-tuberculosis"><a href="#TBDLNet-a-network-for-classifying-multidrug-resistant-and-drug-sensitive-tuberculosis" class="headerlink" title="TBDLNet: a network for classifying multidrug-resistant and drug-sensitive tuberculosis"></a>TBDLNet: a network for classifying multidrug-resistant and drug-sensitive tuberculosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18222">http://arxiv.org/abs/2310.18222</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ziquan Zhu, Jing Tao, Shuihua Wang, Xin Zhang, Yudong Zhang</li>
<li>for: 本研究用一种新型深度学习模型TBDLNet来自动识别CT图像，以分类多药 resistant和敏感肺炎。</li>
<li>methods: 该模型采用预训练ResNet50提取特征，并使用三个随机神经网络来避免过拟合问题。 ensemble of three RNNs 是用来提高Robustness的。</li>
<li>results: 该模型在五种批处分划 validation中得到了0.9822的准确率、0.9815的特征率、0.9823的精度、0.9829的敏感率和0.9826的F1-score。TBDLNet适用于分类多药 resistant和敏感肺炎，可以早些地检测多药 resistant肺炎，帮助在时间内调整治疗方案，提高治疗效果。<details>
<summary>Abstract</summary>
This paper proposes applying a novel deep-learning model, TBDLNet, to recognize CT images to classify multidrug-resistant and drug-sensitive tuberculosis automatically. The pre-trained ResNet50 is selected to extract features. Three randomized neural networks are used to alleviate the overfitting problem. The ensemble of three RNNs is applied to boost the robustness via majority voting. The proposed model is evaluated by five-fold cross-validation. Five indexes are selected in this paper, which are accuracy, sensitivity, precision, F1-score, and specificity. The TBDLNet achieves 0.9822 accuracy, 0.9815 specificity, 0.9823 precision, 0.9829 sensitivity, and 0.9826 F1-score, respectively. The TBDLNet is suitable for classifying multidrug-resistant tuberculosis and drug-sensitive tuberculosis. It can detect multidrug-resistant pulmonary tuberculosis as early as possible, which helps to adjust the treatment plan in time and improve the treatment effect.
</details>
<details>
<summary>摘要</summary>
Translation in Simplified Chinese:这篇论文提议使用一种新的深度学习模型TBDLNet，用于自动识别CT图像，并将其分为多药抗药性和敏感肺结核细菌两类。模型使用预训练的ResNet50提取特征，并使用三个随机的神经网络来避免过拟合问题。ensemble三个RNN使用多数投票法来提高鲁棒性。模型使用五fold交叉验证来评估，使用五个指标：准确率、敏感率、精度、F1分数和特征率。TBDLNet在这些指标中得分为0.9822、0.9815、0.9823、0.9829和0.9826，分别。TBDLNet适用于分类多药抗药性和敏感肺结核细菌，可以在时间上早 detection多药抗药性肺结核细菌，帮助在时间上适当地调整治疗方案，提高治疗效果。
</details></li>
</ul>
<hr>
<h2 id="Artifact-Robust-Graph-Based-Learning-in-Digital-Pathology"><a href="#Artifact-Robust-Graph-Based-Learning-in-Digital-Pathology" class="headerlink" title="Artifact-Robust Graph-Based Learning in Digital Pathology"></a>Artifact-Robust Graph-Based Learning in Digital Pathology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18192">http://arxiv.org/abs/2310.18192</a></li>
<li>repo_url: None</li>
<li>paper_authors: Saba Heidari Gheshlaghi, Milan Aryal, Nasim Yahyasoltani, Masoud Ganji<br>for:This paper aims to develop a novel robust learning approach to account for perturbations in whole slide images (WSIs) for prostate cancer diagnosis.methods:The proposed approach uses graph convolutional networks (GCNs) to extract features from the graph representing WSI, followed by a denoiser and a transformer for classification.results:The proposed model shows significant improvement in cancer diagnosis compared to non-robust algorithms, with accuracy and kappa scores improved by the denoiser and the use of GCNs.<details>
<summary>Abstract</summary>
Whole slide images~(WSIs) are digitized images of tissues placed in glass slides using advanced scanners. The digital processing of WSIs is challenging as they are gigapixel images and stored in multi-resolution format. A common challenge with WSIs is that perturbations/artifacts are inevitable during storing the glass slides and digitizing them. These perturbations include motion, which often arises from slide movement during placement, and changes in hue and brightness due to variations in staining chemicals and the quality of digitizing scanners. In this work, a novel robust learning approach to account for these artifacts is presented. Due to the size and resolution of WSIs and to account for neighborhood information, graph-based methods are called for. We use graph convolutional network~(GCN) to extract features from the graph representing WSI. Through a denoiser {and pooling layer}, the effects of perturbations in WSIs are controlled and the output is followed by a transformer for the classification of different grades of prostate cancer. To compare the efficacy of the proposed approach, the model without denoiser is trained and tested with WSIs without any perturbation and then different perturbations are introduced in WSIs and passed through the network with the denoiser. The accuracy and kappa scores of the proposed model with prostate cancer dataset compared with non-robust algorithms show significant improvement in cancer diagnosis.
</details>
<details>
<summary>摘要</summary>
整幕图像（WSIs）是用高级扫描仪将组织胶囊中的组织样本扫描成数字图像。由于WSIs的数字处理具有高分辨率和多resolution format，因此处理WSIs是一项挑战。常见的WSIs问题是在存储玻璃板和扫描时产生的干扰和 artifacts。这些干扰包括摆动、着色和亮度变化，这些变化可能是化学品的质量和扫描仪的不同。在这项工作中，我们提出了一种新的Robust学习方法来处理这些干扰。由于WSIs的大小和分辨率，以及需要考虑 neighboring information，因此我们使用图gram卷积网络（GCN）来提取WSIs中的特征。通过杂化和池化层，我们控制了干扰的影响，然后使用变换器进行不同grade的肾癌诊断。为了比较提议方法的有效性，我们在不含干扰的WSIs上train和测试模型，然后在WSIs中引入不同的干扰，并将其传递 через网络。我们的方法与肾癌数据集的准确率和κ值 Score在非Robust算法的情况下显示了显著的改善。
</details></li>
</ul>
<hr>
<h2 id="Semi-Supervised-Panoptic-Narrative-Grounding"><a href="#Semi-Supervised-Panoptic-Narrative-Grounding" class="headerlink" title="Semi-Supervised Panoptic Narrative Grounding"></a>Semi-Supervised Panoptic Narrative Grounding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18142">http://arxiv.org/abs/2310.18142</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nini0919/sspng">https://github.com/nini0919/sspng</a></li>
<li>paper_authors: Danni Yang, Jiayi Ji, Xiaoshuai Sun, Haowei Wang, Yinan Li, Yiwei Ma, Rongrong Ji</li>
<li>for: 本研究旨在提高叙述幻像检测（PNG）任务的进步，使得它在有限的标注数据下进行训练。</li>
<li>methods: 我们提出了一种新的半有序PNG学习方案（SS-PNG），利用更少的标注图像对和更多的无标注对来实现竞争力的表现。在PNG任务中，每个像素可以属于多个开放的物体，因此现有的多类基于semi-supervised segmentation的框架无法直接应用于这个任务。我们开发了一种专门针对SS-PNG设置的SS-PNG网络（SS-PNG-NW），并进行了严格的 исследование和优化。</li>
<li>results: 我们的SS-PNG-NW+在PNG数据集上进行了广泛的实验，与完全有标注的模型相比，在所有数据比例下达到了相当的表现。特别是，我们的SS-PNG-NW+在只使用30%和50%的标注数据时表现出色，与完全有标注的模型相比，提高了0.8%和1.1%的表现。这表明我们的提出的SS-PNG-NW+在限制标注数据下提高PNG任务的实际性。<details>
<summary>Abstract</summary>
Despite considerable progress, the advancement of Panoptic Narrative Grounding (PNG) remains hindered by costly annotations. In this paper, we introduce a novel Semi-Supervised Panoptic Narrative Grounding (SS-PNG) learning scheme, capitalizing on a smaller set of labeled image-text pairs and a larger set of unlabeled pairs to achieve competitive performance. Unlike visual segmentation tasks, PNG involves one pixel belonging to multiple open-ended nouns. As a result, existing multi-class based semi-supervised segmentation frameworks cannot be directly applied to this task. To address this challenge, we first develop a novel SS-PNG Network (SS-PNG-NW) tailored to the SS-PNG setting. We thoroughly investigate strategies such as Burn-In and data augmentation to determine the optimal generic configuration for the SS-PNG-NW. Additionally, to tackle the issue of imbalanced pseudo-label quality, we propose a Quality-Based Loss Adjustment (QLA) approach to adjust the semi-supervised objective, resulting in an enhanced SS-PNG-NW+. Employing our proposed QLA, we improve BCE Loss and Dice loss at pixel and mask levels, respectively. We conduct extensive experiments on PNG datasets, with our SS-PNG-NW+ demonstrating promising results comparable to fully-supervised models across all data ratios. Remarkably, our SS-PNG-NW+ outperforms fully-supervised models with only 30% and 50% supervision data, exceeding their performance by 0.8% and 1.1% respectively. This highlights the effectiveness of our proposed SS-PNG-NW+ in overcoming the challenges posed by limited annotations and enhancing the applicability of PNG tasks. The source code is available at https://github.com/nini0919/SSPNG.
</details>
<details>
<summary>摘要</summary>
尽管已经做出了很大的进步，但是对于图像文本对应关系（PNG）的进一步发展仍然受到严重的标注成本限制。在这篇论文中，我们介绍了一种新的半超vised Panoptic Narrative Grounding（SS-PNG）学习方案，利用一个更小的标注图像文本对的集合和一个更大的无标注对来实现竞争性的性能。与视觉分割任务不同，PNG中一个像素可以属于多个开放式名称。因此，现有的多类基于 semi-supervised segmentation的框架无法直接应用于这个任务。为解决这个挑战，我们首先开发了一种适应 SS-PNG 的 SS-PNG 网络（SS-PNG-NW）。我们在这种 SS-PNG-NW 中进行了严格的调查和数据增强等策略，以确定最佳的通用配置。此外，为了解决假标注质量偏斜的问题，我们提出了一种 Quality-Based Loss Adjustment（QLA）方法，以调整 semi-supervised 目标函数，从而得到了一种提升的 SS-PNG-NW+。我们在 PNG 数据集上进行了广泛的实验，并证明了我们的 SS-PNG-NW+ 在所有数据比例下具有出色的表现，与完全超vised 模型相当。特别是，我们的 SS-PNG-NW+ 在仅使用 30% 和 50% 的超visisted数据时，超过了完全超vised 模型的性能，提高了其性能的 0.8% 和 1.1% 分别。这种表现说明了我们提出的 SS-PNG-NW+ 对于做到 PNG 任务的应用性能具有很高的效iveness。SS-PNG 网络的源代码可以在 GitHub 上找到：https://github.com/nini0919/SSPNG。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Representation-Learning-for-Diverse-Deformable-Shape-Collections"><a href="#Unsupervised-Representation-Learning-for-Diverse-Deformable-Shape-Collections" class="headerlink" title="Unsupervised Representation Learning for Diverse Deformable Shape Collections"></a>Unsupervised Representation Learning for Diverse Deformable Shape Collections</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18141">http://arxiv.org/abs/2310.18141</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sara Hahner, Souhaib Attaiki, Jochen Garcke, Maks Ovsjanikov</li>
<li>for: 本研究旨在开发一种基于学习的3D表面网格编码和处理方法，用于创建可解释的嵌入空间 для弹性形状集合。</li>
<li>methods: 我们的方法使用spectral pooling技术建立一个通用的隐藏空间，从 tradicional的mesh connectivity和形状类别中解脱出来。</li>
<li>results: 我们的方法可以实现优秀的重建和更加真实和平滑的 interpolations，并且超过基eline方法的性能。<details>
<summary>Abstract</summary>
We introduce a novel learning-based method for encoding and manipulating 3D surface meshes. Our method is specifically designed to create an interpretable embedding space for deformable shape collections. Unlike previous 3D mesh autoencoders that require meshes to be in a 1-to-1 correspondence, our approach is trained on diverse meshes in an unsupervised manner. Central to our method is a spectral pooling technique that establishes a universal latent space, breaking free from traditional constraints of mesh connectivity and shape categories. The entire process consists of two stages. In the first stage, we employ the functional map paradigm to extract point-to-point (p2p) maps between a collection of shapes in an unsupervised manner. These p2p maps are then utilized to construct a common latent space, which ensures straightforward interpretation and independence from mesh connectivity and shape category. Through extensive experiments, we demonstrate that our method achieves excellent reconstructions and produces more realistic and smoother interpolations than baseline approaches.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的学习基于方法用于编码和操作三维表面网格。我们的方法专门设计用于创建可解释的嵌入空间，用于不可归类的形状集合。与过去的3D笼自动编码器不同，我们的方法不需要笼子在1-1对应。我们的方法在无监督的情况下在多种笼子上进行训练。中心于我们的方法是一种spectral pooling技术，该技术建立了一个通用的嵌入空间，脱离了传统的笼子连接和形状类别的限制。整个过程分为两个阶段。在第一阶段，我们使用函数映射方法抽取点对点（p2p）地图 между一个集合的形状。这些p2p地图然后用于构建共同嵌入空间，这使得解释更直观，独立于笼子连接和形状类别。通过广泛的实验，我们证明了我们的方法可以实现出色的重建和更加真实和平滑的 interpolations than 基准方法。
</details></li>
</ul>
<hr>
<h2 id="End-to-end-Video-Gaze-Estimation-via-Capturing-Head-face-eye-Spatial-temporal-Interaction-Context"><a href="#End-to-end-Video-Gaze-Estimation-via-Capturing-Head-face-eye-Spatial-temporal-Interaction-Context" class="headerlink" title="End-to-end Video Gaze Estimation via Capturing Head-face-eye Spatial-temporal Interaction Context"></a>End-to-end Video Gaze Estimation via Capturing Head-face-eye Spatial-temporal Interaction Context</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18131">http://arxiv.org/abs/2310.18131</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zgchen33/mcgaze">https://github.com/zgchen33/mcgaze</a></li>
<li>paper_authors: Yiran Guan, Zhuoguang Chen, Wenzheng Zeng, Zhiguo Cao, Yang Xiao</li>
<li>for: 提出了一种新的方法 Multi-Clue Gaze (MCGaze)，用于通过捕捉头、脸、眼的空间-时间交互context来进行视频跟踪眼动Estimation，这个问题之前没有得到充分关注。</li>
<li>methods: MCGaze方法可以同时解决头、脸、眼的指示位置定位问题，并在一步式的方式下进行优化，从而实现最佳性能。在这个过程中，头、脸、眼的上下文信息互相交换，从而在眼动推断中 simultanously capture global clue from head and face, and local clue from eye.</li>
<li>results: 实验结果表明，MCGaze方法在面临到复杂的 Gaze360 数据集的测试中表现出色，证明了我们的提议的优越性。<details>
<summary>Abstract</summary>
In this letter, we propose a new method, Multi-Clue Gaze (MCGaze), to facilitate video gaze estimation via capturing spatial-temporal interaction context among head, face, and eye in an end-to-end learning way, which has not been well concerned yet. The main advantage of MCGaze is that the tasks of clue localization of head, face, and eye can be solved jointly for gaze estimation in a one-step way, with joint optimization to seek optimal performance. During this, spatial-temporal context exchange happens among the clues on the head, face, and eye. Accordingly, the final gazes obtained by fusing features from various queries can be aware of global clues from heads and faces, and local clues from eyes simultaneously, which essentially leverages performance. Meanwhile, the one-step running way also ensures high running efficiency. Experiments on the challenging Gaze360 dataset verify the superiority of our proposition. The source code will be released at https://github.com/zgchen33/MCGaze.
</details>
<details>
<summary>摘要</summary>
在这封信中，我们提出了一种新的方法，即多 clue gaze（MCGaze），用于通过捕捉头、面和眼的空间-时间交互 context来进行视频眼动估计，这种方法尚未得到了充分关注。MCGaze 的主要优点是可以同时解决头、面和眼的 clue localization 问题，从而实现一步骤的眼动估计，并且在joint optimization中进行优化以求最佳性能。在这个过程中，头、面和眼之间的空间-时间上的Context Exchange 发生，从而使得最终的眼动结果可以同时充分利用全头和面上的全局 clue，以及眼上的本地 clue，这种方法可以提高性能。此外，MCGaze 的一步运行方式也保证了高效率。实验表明，在 Gaze360 数据集上，我们的提议超过了传统方法的性能。源代码将于 https://github.com/zgchen33/MCGaze 上发布。
</details></li>
</ul>
<hr>
<h2 id="Direct-Unsupervised-Denoising"><a href="#Direct-Unsupervised-Denoising" class="headerlink" title="Direct Unsupervised Denoising"></a>Direct Unsupervised Denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18116">http://arxiv.org/abs/2310.18116</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/krulllab/DirectDenoiser">https://github.com/krulllab/DirectDenoiser</a></li>
<li>paper_authors: Benjamin Salmon, Alexander Krull</li>
<li>for: 这个论文是为了提出一种新的干扰除法，以替代传统的监督学习方法。</li>
<li>methods: 这个论文使用了Variational AutoEncoders（VAEs）来实现无监督的干扰除法，而不需要对应的干扰数据。</li>
<li>results: 该方法可以在各种情况下提供高质量的干扰除结果，而且比传统的监督方法更快速，并且可以避免创造大量的样本抽象。<details>
<summary>Abstract</summary>
Traditional supervised denoisers are trained using pairs of noisy input and clean target images. They learn to predict a central tendency of the posterior distribution over possible clean images. When, e.g., trained with the popular quadratic loss function, the network's output will correspond to the minimum mean square error (MMSE) estimate. Unsupervised denoisers based on Variational AutoEncoders (VAEs) have succeeded in achieving state-of-the-art results while requiring only unpaired noisy data as training input. In contrast to the traditional supervised approach, unsupervised denoisers do not directly produce a single prediction, such as the MMSE estimate, but allow us to draw samples from the posterior distribution of clean solutions corresponding to the noisy input. To approximate the MMSE estimate during inference, unsupervised methods have to create and draw a large number of samples - a computationally expensive process - rendering the approach inapplicable in many situations. Here, we present an alternative approach that trains a deterministic network alongside the VAE to directly predict a central tendency. Our method achieves results that surpass the results achieved by the unsupervised method at a fraction of the computational cost.
</details>
<details>
<summary>摘要</summary>
传统的监督式降噪器通常通过对噪声输入和干净目标图像的对照对进行训练，学习预测噪声输入的后逻脑分布中的中位数。例如，使用流行的quadratic loss函数训练网络，网络的输出将对应于最小平均方差估计（MMSE）。不同于传统的监督式方法，无监督降噪器基于Variational AutoEncoders（VAEs）可以在不需要对应的干净数据的情况下实现状态的最佳结果。然而，在推理过程中，无监督降噪器不直接生成唯一的预测结果，而是允许我们从降噪器的 posterior distribution 中随机抽取干净解决方案对应的噪声输入。为了在推理过程中 aproximate MMSE 估计，无监督方法需要创建和抽取大量的样本，这是 computationally expensive 的过程，因此在许多情况下无法应用。在这篇文章中，我们提出了一种alternative方法，该方法通过同时训练 deterministic 网络和 VAE 来直接预测中位数。我们的方法可以在computational cost的一个 fraction 的情况下超越无监督方法的结果。
</details></li>
</ul>
<hr>
<h2 id="Classifier-head-Informed-Feature-Masking-and-Prototype-based-Logit-Smoothing-for-Out-of-Distribution-Detection"><a href="#Classifier-head-Informed-Feature-Masking-and-Prototype-based-Logit-Smoothing-for-Out-of-Distribution-Detection" class="headerlink" title="Classifier-head Informed Feature Masking and Prototype-based Logit Smoothing for Out-of-Distribution Detection"></a>Classifier-head Informed Feature Masking and Prototype-based Logit Smoothing for Out-of-Distribution Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18104">http://arxiv.org/abs/2310.18104</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuohao Sun, Yiqiao Qiu, Zhijun Tan, Weishi Zheng, Ruixuan Wang</li>
<li>for: 这篇研究旨在提出一种有效的后期Out-of-distribution（OOD）检测方法，以解决深度学习模型在实际应用中的错误预测问题。</li>
<li>methods: 本研究使用了一种新的特征遮盾策略和一种新的权重缓和策略，将特征遮盾定义为每个内部分类（ID）的重要特征，并将其他特征遮盾。此外，本研究还使用了一种cosine similarity的类似性计算来自适应温度因子，以缓和神经网络的过度自信预测。</li>
<li>results: 实验结果显示，本研究的方法可以将OOD检测精度提高，并且与现有方法相容。本研究新创出了State-of-the-art的性能。代码将会公开发布。<details>
<summary>Abstract</summary>
Out-of-distribution (OOD) detection is essential when deploying neural networks in the real world. One main challenge is that neural networks often make overconfident predictions on OOD data. In this study, we propose an effective post-hoc OOD detection method based on a new feature masking strategy and a novel logit smoothing strategy. Feature masking determines the important features at the penultimate layer for each in-distribution (ID) class based on the weights of the ID class in the classifier head and masks the rest features. Logit smoothing computes the cosine similarity between the feature vector of the test sample and the prototype of the predicted ID class at the penultimate layer and uses the similarity as an adaptive temperature factor on the logit to alleviate the network's overconfidence prediction for OOD data. With these strategies, we can reduce feature activation of OOD data and enlarge the gap in OOD score between ID and OOD data. Extensive experiments on multiple standard OOD detection benchmarks demonstrate the effectiveness of our method and its compatibility with existing methods, with new state-of-the-art performance achieved from our method. The source code will be released publicly.
</details>
<details>
<summary>摘要</summary>
OUT-OF-DISTRIBUTION (OOD) 检测是在真实世界中部署神经网络的关键。一个主要挑战是神经网络frequently 对OOD数据进行过自信的预测。在这项研究中，我们提出了一种有效的后置OOD检测方法，基于新的特征遮盾策略和一种新的logit平滑策略。特征遮盾在半最后层确定每个ID类型的重要特征，根据ID类型的分类器头的权重，并将其他特征遮盾。logit平滑计算测试样本的特征向量和预测ID类型的prototype在半最后层的cos仿射系数，并使用这个相似性作为适应温度因子来缓解神经网络对OOD数据的过自信预测。通过这些策略，我们可以降低OOD数据的特征活动和扩大ID和OOD数据之间的分布差。我们的方法与现有方法相容，并在多个标准OOD检测 benchmark上实现了新的 state-of-the-art 性能。我们将代码公开发布。
</details></li>
</ul>
<hr>
<h2 id="A-Chebyshev-Confidence-Guided-Source-Free-Domain-Adaptation-Framework-for-Medical-Image-Segmentation"><a href="#A-Chebyshev-Confidence-Guided-Source-Free-Domain-Adaptation-Framework-for-Medical-Image-Segmentation" class="headerlink" title="A Chebyshev Confidence Guided Source-Free Domain Adaptation Framework for Medical Image Segmentation"></a>A Chebyshev Confidence Guided Source-Free Domain Adaptation Framework for Medical Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18087">http://arxiv.org/abs/2310.18087</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiesi Hu, Yanwu Yang, Xutao Guo, Jinghua Wang, Ting Ma<br>for:This paper focuses on addressing the accuracy deterioration issue of pseudo-labels (PLs) in source-free domain adaptation (SFDA) methods, which is a crucial problem in medical imaging scenarios due to privacy concerns.methods:The proposed framework consists of three main components: (1) Chebyshev confidence guided SFDA, (2) confidence-guided denoising methods (direct denoising and prototypical denoising), and (3) a novel teacher-student joint training scheme (TJTS) with a confidence weighting module.results:Extensive experiments in diverse domain scenarios demonstrate the effectiveness of the proposed framework, achieving superior performance compared to state-of-the-art SFDA methods. The proposed approach precisely estimates the reliability of PLs and generates high-quality PLs, leading to improved adaptation performance.<details>
<summary>Abstract</summary>
Source-free domain adaptation (SFDA) aims to adapt models trained on a labeled source domain to an unlabeled target domain without the access to source data. In medical imaging scenarios, the practical significance of SFDA methods has been emphasized due to privacy concerns. Recent State-of-the-art SFDA methods primarily rely on self-training based on pseudo-labels (PLs). Unfortunately, PLs suffer from accuracy deterioration caused by domain shift, and thus limit the effectiveness of the adaptation process. To address this issue, we propose a Chebyshev confidence guided SFDA framework to accurately assess the reliability of PLs and generate self-improving PLs for self-training. The Chebyshev confidence is estimated by calculating probability lower bound of the PL confidence, given the prediction and the corresponding uncertainty. Leveraging the Chebyshev confidence, we introduce two confidence-guided denoising methods: direct denoising and prototypical denoising. Additionally, we propose a novel teacher-student joint training scheme (TJTS) that incorporates a confidence weighting module to improve PLs iteratively. The TJTS, in collaboration with the denoising methods, effectively prevents the propagation of noise and enhances the accuracy of PLs. Extensive experiments in diverse domain scenarios validate the effectiveness of our proposed framework and establish its superiority over state-of-the-art SFDA methods. Our paper contributes to the field of SFDA by providing a novel approach for precisely estimating the reliability of pseudo-labels and a framework for obtaining high-quality PLs, resulting in improved adaptation performance.
</details>
<details>
<summary>摘要</summary>
To address this issue, we propose a Chebyshev confidence guided SFDA framework to accurately assess the reliability of PLs and generate self-improving PLs for self-training. The Chebyshev confidence is estimated by calculating the probability lower bound of the PL confidence, given the prediction and the corresponding uncertainty.Leveraging the Chebyshev confidence, we introduce two confidence-guided denoising methods: direct denoising and prototypical denoising. Additionally, we propose a novel teacher-student joint training scheme (TJTS) that incorporates a confidence weighting module to improve PLs iteratively. The TJTS, in collaboration with the denoising methods, effectively prevents the propagation of noise and enhances the accuracy of PLs.Extensive experiments in diverse domain scenarios validate the effectiveness of our proposed framework and establish its superiority over state-of-the-art SFDA methods. Our paper contributes to the field of SFDA by providing a novel approach for precisely estimating the reliability of pseudo-labels and a framework for obtaining high-quality PLs, resulting in improved adaptation performance.
</details></li>
</ul>
<hr>
<h2 id="Text-Augmented-Spatial-aware-Zero-shot-Referring-Image-Segmentation"><a href="#Text-Augmented-Spatial-aware-Zero-shot-Referring-Image-Segmentation" class="headerlink" title="Text Augmented Spatial-aware Zero-shot Referring Image Segmentation"></a>Text Augmented Spatial-aware Zero-shot Referring Image Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18049">http://arxiv.org/abs/2310.18049</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yucheng Suo, Linchao Zhu, Yi Yang<br>for: 这种研究旨在解决零shot引用图像分割中的挑战，即基于引用表达而不需要训练的实例掩模分割。methods: 该方法基于Text Augmented Spatial-aware（TAS）框架，包括实例掩模提取网络、文本增强视觉对应分数以及空间修正器。results: 对RefCOCO、RefCOCO+和RefCOCOg等多个 dataset进行了广泛的实验，并表明该方法在零shot引用图像分割任务中具有明显的优势，超越了现有的状态计算方法。<details>
<summary>Abstract</summary>
In this paper, we study a challenging task of zero-shot referring image segmentation. This task aims to identify the instance mask that is most related to a referring expression without training on pixel-level annotations. Previous research takes advantage of pre-trained cross-modal models, e.g., CLIP, to align instance-level masks with referring expressions. %Yet, CLIP only considers image-text pair level alignment, which neglects fine-grained image region and complex sentence matching. Yet, CLIP only considers the global-level alignment of image-text pairs, neglecting fine-grained matching between the referring sentence and local image regions. To address this challenge, we introduce a Text Augmented Spatial-aware (TAS) zero-shot referring image segmentation framework that is training-free and robust to various visual encoders. TAS incorporates a mask proposal network for instance-level mask extraction, a text-augmented visual-text matching score for mining the image-text correlation, and a spatial rectifier for mask post-processing. Notably, the text-augmented visual-text matching score leverages a $P$ score and an $N$-score in addition to the typical visual-text matching score. The $P$-score is utilized to close the visual-text domain gap through a surrogate captioning model, where the score is computed between the surrogate model-generated texts and the referring expression. The $N$-score considers the fine-grained alignment of region-text pairs via negative phrase mining, encouraging the masked image to be repelled from the mined distracting phrases. Extensive experiments are conducted on various datasets, including RefCOCO, RefCOCO+, and RefCOCOg. The proposed method clearly outperforms state-of-the-art zero-shot referring image segmentation methods.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了零shot引用图像分割的挑战性任务。这个任务的目标是使用没有Pixel级别注释的情况下，从referring表达中确定最相关的实例Mask。先前的研究利用了预训练的交叉模态模型，如CLIP，来将实例级别的mask与referring表达相Alignment。然而，CLIP只考虑了图像文本对的全局匹配，忽略了图像区域细化和复杂的句子匹配。为解决这个挑战，我们提出了一个Text Augmented Spatial-aware（TAS）零shot引用图像分割框架。TAS包括一个Mask proposal网络 для实例级别的Mask提取，一个文本增强的视觉文本匹配分数 для挖掘图像文本的相关性，以及一个空间正则化器 дляMask后处理。值得注意的是，文本增强的视觉文本匹配分数利用了$P$ score和$N$-score，以及传统的视觉文本匹配分数。$P$-score通过一个surrogate captioning模型来闭合视觉文本域的差距，其中分数是计算surrogate模型生成的文本和引用表达之间的相似度。$N$-score考虑了图像文本对的细化对应，通过负phrase挖掘，使masked图像受到挖掘的负面抑制。我们对RefCOCO、RefCOCO+和RefCOCOg等多个dataset进行了广泛的实验，并证明了我们的方法在零shot引用图像分割任务中具有明显的优势。
</details></li>
</ul>
<hr>
<h2 id="ZeroNVS-Zero-Shot-360-Degree-View-Synthesis-from-a-Single-Real-Image"><a href="#ZeroNVS-Zero-Shot-360-Degree-View-Synthesis-from-a-Single-Real-Image" class="headerlink" title="ZeroNVS: Zero-Shot 360-Degree View Synthesis from a Single Real Image"></a>ZeroNVS: Zero-Shot 360-Degree View Synthesis from a Single Real Image</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17994">http://arxiv.org/abs/2310.17994</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kyle Sargent, Zizhang Li, Tanmay Shah, Charles Herrmann, Hong-Xing Yu, Yunzhi Zhang, Eric Ryan Chan, Dmitry Lagun, Li Fei-Fei, Deqing Sun, Jiajun Wu</li>
<li>for: 这篇论文是设计来 Synthesize single-image novel view for in-the-wild scenes, 对于现有的方法而言，这些方法只适用于单一物体的场景中，这篇论文提出了新的技术来解决受到野外多个物体和复杂背景的挑战。</li>
<li>methods: 这篇论文使用了一个3D-aware散射模型，ZeroNVS，并将其训练在一个混合数据源上，这个数据源包括物体中心、室内和室外场景。为了解决数据混合所引入的问题，例如深度尺度歧义，这篇论文提出了一个新的摄像头参数化和均衡方案。</li>
<li>results: 这篇论文的模型在LPIPS中的 zero-shot 设定中设置了新的州OF-the-art 纪录，甚至超过了特别在DTU上训练的方法。此外，这篇论文还适用了Mip-NeRF 360 dataset作为单一图像新观点合成的新 bencmark，并在这个设定中展现了强大的性能。<details>
<summary>Abstract</summary>
We introduce a 3D-aware diffusion model, ZeroNVS, for single-image novel view synthesis for in-the-wild scenes. While existing methods are designed for single objects with masked backgrounds, we propose new techniques to address challenges introduced by in-the-wild multi-object scenes with complex backgrounds. Specifically, we train a generative prior on a mixture of data sources that capture object-centric, indoor, and outdoor scenes. To address issues from data mixture such as depth-scale ambiguity, we propose a novel camera conditioning parameterization and normalization scheme. Further, we observe that Score Distillation Sampling (SDS) tends to truncate the distribution of complex backgrounds during distillation of 360-degree scenes, and propose "SDS anchoring" to improve the diversity of synthesized novel views. Our model sets a new state-of-the-art result in LPIPS on the DTU dataset in the zero-shot setting, even outperforming methods specifically trained on DTU. We further adapt the challenging Mip-NeRF 360 dataset as a new benchmark for single-image novel view synthesis, and demonstrate strong performance in this setting. Our code and data are at http://kylesargent.github.io/zeronvs/
</details>
<details>
<summary>摘要</summary>
我们介绍了一种3D意识扩散模型，namely ZeroNVS，用于单图新视角合成Scene中的异常场景。而现有方法通常是为单个物体设置masked背景，我们提出了新的技术来解决在野外多对象场景中引入的挑战。具体来说，我们在混合数据源上训练了生成的先验，以捕捉object-centric、indoor和outdoor场景。为了解决数据混合引入的深度尺度歧义，我们提出了一种新的摄像头条件化和正规化方案。此外，我们发现Score Distillation Sampling (SDS)在混合360度场景中进行distillation时，容易对复杂背景进行短结，我们提出了"SDS anchoring"来提高合成的新视角的多样性。我们的模型在LPIPS上DTU数据集上达到了新的州OF-THE-ART记录，甚至超越了特地在DTU上训练的方法。此外，我们采用了Difficult Mip-NeRF 360数据集作为新的benchmark，并在这个设置下达到了出色的性能。我们的代码和数据可以在http://kylesargent.github.io/zeronvs/上找到。
</details></li>
</ul>
<hr>
<h2 id="FaultSeg-Swin-UNETR-Transformer-Based-Self-Supervised-Pretraining-Model-for-Fault-Recognition"><a href="#FaultSeg-Swin-UNETR-Transformer-Based-Self-Supervised-Pretraining-Model-for-Fault-Recognition" class="headerlink" title="FaultSeg Swin-UNETR: Transformer-Based Self-Supervised Pretraining Model for Fault Recognition"></a>FaultSeg Swin-UNETR: Transformer-Based Self-Supervised Pretraining Model for Fault Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17974">http://arxiv.org/abs/2310.17974</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zeren Zhang, Ran Chen, Jinwen Ma</li>
<li>for: 提高震动 fault 识别精度</li>
<li>methods: 自动学习 + Swintransformer + SimMIM 预训练 + 多尺度拟合 + edge detection</li>
<li>results: 在Thebe数据集上实现了领先的性能，OIS和ODS指标中评估为最佳Here’s a brief explanation of each point:1. for: The paper aims to improve the accuracy of seismic fault recognition by introducing a self-supervised learning approach using a large amount of unlabeled seismic data for pretraining.2. methods: The proposed method utilizes the Swin Transformer model as the core network and employs the SimMIM pretraining task to capture unique features related to discontinuities in seismic data. Additionally, the authors refine the structure of the Swin-UNETR model to enable multiscale decoding and fusion for more effective fault detection.3. results: The experimental results on the Thebe dataset demonstrate that the proposed method achieves state-of-the-art performance, as measured by the OIS and ODS metrics.<details>
<summary>Abstract</summary>
This paper introduces an approach to enhance seismic fault recognition through self-supervised pretraining. Seismic fault interpretation holds great significance in the fields of geophysics and geology. However, conventional methods for seismic fault recognition encounter various issues, including dependence on data quality and quantity, as well as susceptibility to interpreter subjectivity. Currently, automated fault recognition methods proposed based on small synthetic datasets experience performance degradation when applied to actual seismic data. To address these challenges, we have introduced the concept of self-supervised learning, utilizing a substantial amount of relatively easily obtainable unlabeled seismic data for pretraining. Specifically, we have employed the Swin Transformer model as the core network and employed the SimMIM pretraining task to capture unique features related to discontinuities in seismic data. During the fine-tuning phase, inspired by edge detection techniques, we have also refined the structure of the Swin-UNETR model, enabling multiscale decoding and fusion for more effective fault detection. Experimental results demonstrate that our proposed method attains state-of-the-art performance on the Thebe dataset, as measured by the OIS and ODS metrics.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Multivessel-Coronary-Artery-Segmentation-and-Stenosis-Localisation-using-Ensemble-Learning"><a href="#Multivessel-Coronary-Artery-Segmentation-and-Stenosis-Localisation-using-Ensemble-Learning" class="headerlink" title="Multivessel Coronary Artery Segmentation and Stenosis Localisation using Ensemble Learning"></a>Multivessel Coronary Artery Segmentation and Stenosis Localisation using Ensemble Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17954">http://arxiv.org/abs/2310.17954</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muhammad Bilal, Dinis Martinho, Reiner Sim, Adnan Qayyum, Hunaid Vohra, Massimo Caputo, Taofeek Akinosho, Sofiat Abioye, Zaheer Khan, Waleed Niaz, Junaid Qadir<br>for: 这个研究旨在提供一个基于机器学习的自动化诊断方案，以帮助cardiologists诊断折叠动脉疾病（CAD）。methods: 该研究使用了一种结合多个基线模型的 ensemble 模型，通过逐渐提高性能的训练策略，包括多个阶段的预training、多血管分割和精度提高等。results: 该研究的结果显示，使用这种方法可以Double the predictive accuracy of the proposed solution，并且通过进一步纠正错误的blob来进行精度提高。最终得到的结果为 coronary artery segmentation 的 mean F1 score 为 37.69%，和 stenosis localization 的 mean F1 score 为 39.41%。<details>
<summary>Abstract</summary>
Coronary angiography analysis is a common clinical task performed by cardiologists to diagnose coronary artery disease (CAD) through an assessment of atherosclerotic plaque's accumulation. This study introduces an end-to-end machine learning solution developed as part of our solution for the MICCAI 2023 Automatic Region-based Coronary Artery Disease diagnostics using x-ray angiography imagEs (ARCADE) challenge, which aims to benchmark solutions for multivessel coronary artery segmentation and potential stenotic lesion localisation from X-ray coronary angiograms. We adopted a robust baseline model training strategy to progressively improve performance, comprising five successive stages of binary class pretraining, multivessel segmentation, fine-tuning using class frequency weighted dataloaders, fine-tuning using F1-based curriculum learning strategy (F1-CLS), and finally multi-target angiogram view classifier-based collective adaptation. Unlike many other medical imaging procedures, this task exhibits a notable degree of interobserver variability. %, making it particularly amenable to automated analysis. Our ensemble model combines the outputs from six baseline models using the weighted ensembling approach, which our analysis shows is found to double the predictive accuracy of the proposed solution. The final prediction was further refined, targeting the correction of misclassified blobs. Our solution achieved a mean F1 score of $37.69\%$ for coronary artery segmentation, and $39.41\%$ for stenosis localisation, positioning our team in the 5th position on both leaderboards. This work demonstrates the potential of automated tools to aid CAD diagnosis, guide interventions, and improve the accuracy of stent injections in clinical settings.
</details>
<details>
<summary>摘要</summary>
coronary angiography 分析是一种常见的临床任务，由医生用于诊断液体动脉疾病（CAD）的评估，包括atherosclerotic plaque的积累。这项研究介绍了一种基于我们的解决方案的自动化解决方案，用于MICCAI 2023 自动区域基础 coronary artery disease 诊断（ARCADE）挑战，以获得多个血管 segmentation 和可能的狭窄 lesion 的位置。我们采用了一种可靠的基线模型训练策略，包括五个顺序的 binary class pretraining、多血管 segmentation、精度调整使用类频率加载器、F1-based curriculum learning strategy（F1-CLS）和最后是多视图 coronary angiogram 类型的集成adaptation。与许多医疗影像过程不同，这个任务具有显著的Interobserver variability，使其更适合自动分析。我们的集成模型将六个基线模型的输出结合使用重量加权ensembleapproach，我们的分析显示可以double predictive accuracy of the proposed solution。最终预测还进行了进一步的纠正，以正确化错误的 blob。我们的解决方案在 coronary artery segmentation 方面 achievement mean F1 score of 37.69%，并在 localisation 方面 achievement mean F1 score of 39.41%，位于领先board 的第五名。这项工作 demonstarted the potential of automated tools to aid CAD diagnosis, guide interventions, and improve the accuracy of stent injections in clinical settings.
</details></li>
</ul>
<hr>
<h2 id="Shape-centered-Representation-Learning-for-Visible-Infrared-Person-Re-identification"><a href="#Shape-centered-Representation-Learning-for-Visible-Infrared-Person-Re-identification" class="headerlink" title="Shape-centered Representation Learning for Visible-Infrared Person Re-identification"></a>Shape-centered Representation Learning for Visible-Infrared Person Re-identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17952">http://arxiv.org/abs/2310.17952</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuang Li, Jiaxu Leng, Ji Gan, Mengjingcheng Mo, Xinbo Gao</li>
<li>for: 这个论文主要目标是提高人各个感知中的人脸识别率，尤其是在可见光和红外光之间的模式转换问题上。</li>
<li>methods: 该论文提出了一种基于形状特征学习的Shape-centered Representation Learning框架（ScRL），包括Shape Feature Propagation（SFP）和Infrared Shape Restitution（ISR）等技术，以提高人脸识别率。</li>
<li>results: 该论文的实验结果表明，ScRL可以在人脸识别任务中实现remarkable的性能，其中 Rank-1（mAP）精度达到76.1%, 71.2%, 92.4%（72.6%, 52.9%, 86.7%）在SYSU-MM01、HITSZ-VCM和RegDB数据集上。<details>
<summary>Abstract</summary>
Current Visible-Infrared Person Re-Identification (VI-ReID) methods prioritize extracting distinguishing appearance features, ignoring the natural resistance of body shape against modality changes. Initially, we gauged the discriminative potential of shapes by a straightforward concatenation of shape and appearance features. However, two unresolved issues persist in the utilization of shape features. One pertains to the dependence on auxiliary models for shape feature extraction in the inference phase, along with the errors in generated infrared shapes due to the intrinsic modality disparity. The other issue involves the inadequately explored correlation between shape and appearance features. To tackle the aforementioned challenges, we propose the Shape-centered Representation Learning framework (ScRL), which focuses on learning shape features and appearance features associated with shapes. Specifically, we devise the Shape Feature Propagation (SFP), facilitating direct extraction of shape features from original images with minimal complexity costs during inference. To restitute inaccuracies in infrared body shapes at the feature level, we present the Infrared Shape Restitution (ISR). Furthermore, to acquire appearance features related to shape, we design the Appearance Feature Enhancement (AFE), which accentuates identity-related features while suppressing identity-unrelated features guided by shape features. Extensive experiments are conducted to validate the effectiveness of the proposed ScRL. Achieving remarkable results, the Rank-1 (mAP) accuracy attains 76.1%, 71.2%, 92.4% (72.6%, 52.9%, 86.7%) on the SYSU-MM01, HITSZ-VCM, RegDB datasets respectively, outperforming existing state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
当前可见红外人重认（VI-ReID）方法强调抽出特征特征，忽视人体形态自然对模态变化的抵抗性。我们首先评估特征的推诉潜力，通过简单 concatenation  shape 和 appearance 特征。但是，在使用 shape 特征时，存在两个不解决的问题。其一是在推理阶段依赖 auxilary 模型来EXTRACT shape 特征，同时因内生模态差而产生的生成红外形态错误。另一个问题是 shape 和 appearance 特征之间的相关性未得到充分探索。为了解决这些挑战，我们提出了 Shape-centered Representation Learning 框架（ScRL），它注重学习 shape 特征和 appearance 特征相关的 shape。具体来说，我们设计了 Shape Feature Propagation （SFP），它可以在原始图像中直接EXTRACT shape 特征，降低推理复杂性。此外，我们还提出了 Infrared Shape Restitution （ISR），用于在特征层修复红外形态错误。此外，我们还设计了 Appearance Feature Enhancement （AFE），它可以强调身份相关的特征，同时避免身份不相关的特征，以shape特征为引导。我们进行了广泛的实验，以验证 ScRL 的效果。得到了惊人的结果，VI-ReID 方法的 Rank-1（mAP）精度达到 76.1%、71.2%、92.4%（72.6%、52.9%、86.7%），在 SYSU-MM01、HITSZ-VCM 和 RegDB 数据集上，分别高于当前状态的前iers。
</details></li>
</ul>
<hr>
<h2 id="Instance-Segmentation-under-Occlusions-via-Location-aware-Copy-Paste-Data-Augmentation"><a href="#Instance-Segmentation-under-Occlusions-via-Location-aware-Copy-Paste-Data-Augmentation" class="headerlink" title="Instance Segmentation under Occlusions via Location-aware Copy-Paste Data Augmentation"></a>Instance Segmentation under Occlusions via Location-aware Copy-Paste Data Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17949">http://arxiv.org/abs/2310.17949</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nguyendinhson-kaist/mmsports23-seg-autoid">https://github.com/nguyendinhson-kaist/mmsports23-seg-autoid</a></li>
<li>paper_authors: Son Nguyen, Mikel Lainsa, Hung Dao, Daeyoung Kim, Giang Nguyen</li>
<li>for: 本研究主要针对计算机视觉中的 occlusion 问题进行解决，具体来说是在 instance segmentation 领域中。</li>
<li>methods: 本研究使用了一种新的数据增强技术，可以生成更多的训练样本，以及一种新的深度学习架构 Hybrid Task Cascade (HTC) 框架，以提高 segmentation 性能。</li>
<li>results: 本研究在 MMSports 2023 DeepSportRadar 比赛中取得了很好的结果，其中 occlusion 得分 (OM) 为 0.533，位于领导者板卡的第一名。<details>
<summary>Abstract</summary>
Occlusion is a long-standing problem in computer vision, particularly in instance segmentation. ACM MMSports 2023 DeepSportRadar has introduced a dataset that focuses on segmenting human subjects within a basketball context and a specialized evaluation metric for occlusion scenarios. Given the modest size of the dataset and the highly deformable nature of the objects to be segmented, this challenge demands the application of robust data augmentation techniques and wisely-chosen deep learning architectures. Our work (ranked 1st in the competition) first proposes a novel data augmentation technique, capable of generating more training samples with wider distribution. Then, we adopt a new architecture - Hybrid Task Cascade (HTC) framework with CBNetV2 as backbone and MaskIoU head to improve segmentation performance. Furthermore, we employ a Stochastic Weight Averaging (SWA) training strategy to improve the model's generalization. As a result, we achieve a remarkable occlusion score (OM) of 0.533 on the challenge dataset, securing the top-1 position on the leaderboard. Source code is available at this https://github.com/nguyendinhson-kaist/MMSports23-Seg-AutoID.
</details>
<details>
<summary>摘要</summary>
干扰是计算机视觉领域的长期问题，特别是在实例分割方面。ACM MMSports 2023 DeepSportRadar  datasets 已经引入了专门用于人体分割的篮球场景，以及特殊的评价指标 для干扰情况。由于数据集的规模较小和需要分割的对象具有高度变形的特点，这个挑战需要应用robust的数据扩展技术和合适的深度学习架构。我们的工作（在比赛中排名第一）首先提出了一种新的数据扩展技术，能够生成更多的训练样本，并且具有更广泛的分布。然后，我们采用了一个新的框架——Hybrid Task Cascade（HTC）框架，其中CBNetV2 作为 backing 和 MaskIoU 头部来提高分割性能。此外，我们还使用了一种Stochastic Weight Averaging（SWA） 训练策略，以提高模型的泛化性。因此，我们在挑战数据集上实现了干扰分数（OM）为 0.533，在 liderboard 上排名第一。源代码可以在以下链接中找到：https://github.com/nguyendinhson-kaist/MMSports23-Seg-AutoID。
</details></li>
</ul>
<hr>
<h2 id="Diversifying-Spatial-Temporal-Perception-for-Video-Domain-Generalization"><a href="#Diversifying-Spatial-Temporal-Perception-for-Video-Domain-Generalization" class="headerlink" title="Diversifying Spatial-Temporal Perception for Video Domain Generalization"></a>Diversifying Spatial-Temporal Perception for Video Domain Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17942">http://arxiv.org/abs/2310.17942</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kunyulin/stdn">https://github.com/kunyulin/stdn</a></li>
<li>paper_authors: Kun-Yu Lin, Jia-Run Du, Yipeng Gao, Jiaming Zhou, Wei-Shi Zheng</li>
<li>for: 学习通用视频分类模型，并在不同目标领域中进行泛化。</li>
<li>methods: 利用多种空间和时间维度的多cue学习，以找到可能的领域不受影响的cue。</li>
<li>results: 在三个不同类型的benchmark上进行了广泛的实验，证明了我们的方法的有效性和多样性。<details>
<summary>Abstract</summary>
Video domain generalization aims to learn generalizable video classification models for unseen target domains by training in a source domain. A critical challenge of video domain generalization is to defend against the heavy reliance on domain-specific cues extracted from the source domain when recognizing target videos. To this end, we propose to perceive diverse spatial-temporal cues in videos, aiming to discover potential domain-invariant cues in addition to domain-specific cues. We contribute a novel model named Spatial-Temporal Diversification Network (STDN), which improves the diversity from both space and time dimensions of video data. First, our STDN proposes to discover various types of spatial cues within individual frames by spatial grouping. Then, our STDN proposes to explicitly model spatial-temporal dependencies between video contents at multiple space-time scales by spatial-temporal relation modeling. Extensive experiments on three benchmarks of different types demonstrate the effectiveness and versatility of our approach.
</details>
<details>
<summary>摘要</summary>
视频领域通用化目标在培养源领域中学习通用的视频分类模型，以便在目标领域中进行推理。一个关键的挑战是防止在目标视频识别中过重依赖源领域特有的特征。为此，我们提议利用视频中的多样化空间-时间特征，找到可能的领域不受影响的特征。我们提出了一种新的模型，即空间-时间多样化网络（STDN），它在视频数据中提高多样化性。首先，我们的 STDN 提出了在个体帧中发现多种空间特征的方法，并进行空间组合。然后，我们的 STDN 利用多个空间-时间尺度的空间-时间关系模型，以模拟视频内容之间的空间-时间相互关系。我们在三个不同类型的 benchmark 上进行了广泛的实验，并证明了我们的方法的有效性和多样性。
</details></li>
</ul>
<hr>
<h2 id="DocStormer-Revitalizing-Multi-Degraded-Colored-Document-Images-to-Pristine-PDF"><a href="#DocStormer-Revitalizing-Multi-Degraded-Colored-Document-Images-to-Pristine-PDF" class="headerlink" title="DocStormer: Revitalizing Multi-Degraded Colored Document Images to Pristine PDF"></a>DocStormer: Revitalizing Multi-Degraded Colored Document Images to Pristine PDF</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17910">http://arxiv.org/abs/2310.17910</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chaowei Liu, Jichun Li, Yihua Teng, Chaoqun Wang, Nuo Xu, Jihao Wu, Dandan Tu</li>
<li>for: 提高多层次陌生文档图像的Restoration至其潜在的PDF版本</li>
<li>methods: 基于”Perceive-then-Restore”模式的 transformer 块，加上 GAN 和优质PDF图像，以减少陌生度和提高视觉质量</li>
<li>results: 实验结果显示， DocStormer 可以有效地恢复多层次陌生文档图像，提供了一个新的 Restoration 方法，可以填补当前学术领域中的一个知识漏洞。<details>
<summary>Abstract</summary>
For capturing colored document images, e.g. posters and magazines, it is common that multiple degradations such as shadows, wrinkles, etc., are simultaneously introduced due to external factors. Restoring multi-degraded colored document images is a great challenge, yet overlooked, as most existing algorithms focus on enhancing color-ignored document images via binarization. Thus, we propose DocStormer, a novel algorithm designed to restore multi-degraded colored documents to their potential pristine PDF. The contributions are: firstly, we propose a "Perceive-then-Restore" paradigm with a reinforced transformer block, which more effectively encodes and utilizes the distribution of degradations. Secondly, we are the first to utilize GAN and pristine PDF magazine images to narrow the distribution gap between the enhanced results and PDF images, in pursuit of less degradation and better visual quality. Thirdly, we propose a non-parametric strategy, PFILI, which enables a smaller training scale and larger testing resolutions with acceptable detail trade-off, while saving memory and inference time. Fourthly, we are the first to propose a novel Multi-Degraded Colored Document image Enhancing dataset, named MD-CDE, for both training and evaluation. Experimental results show that the DocStormer exhibits superior performance, capable of revitalizing multi-degraded colored documents into their potential pristine digital versions, which fills the current academic gap from the perspective of method, data, and task.
</details>
<details>
<summary>摘要</summary>
For capturing 颜色文档图像，如 poster 和杂志， external factors 可能同时引入多种干扰， such as shadows 和折皮等。 Restoring 多干扰的颜色文档图像是一大挑战，尤其是被忽略的，因为大多数现有算法都专注于提高无色文档图像的明暗分割。 Therefore, we propose DocStormer, a novel algorithm designed to restore 多干扰的颜色文档图像 to its potential pristine PDF. The contributions are:Firstly, we propose a "Perceive-then-Restore" paradigm with a reinforced transformer block, which more effectively encodes and utilizes the distribution of degradations.Secondly, we are the first to utilize GAN and pristine PDF magazine images to narrow the distribution gap between the enhanced results and PDF images, in pursuit of less degradation and better visual quality.Thirdly, we propose a non-parametric strategy, PFILI, which enables a smaller training scale and larger testing resolutions with acceptable detail trade-off, while saving memory and inference time.Fourthly, we are the first to propose a novel Multi-Degraded Colored Document image Enhancing dataset, named MD-CDE, for both training and evaluation. Experimental results show that the DocStormer exhibits superior performance, capable of revitalizing 多干扰的颜色文档图像 into its potential pristine digital versions, which fills the current academic gap from the perspective of method, data, and task.
</details></li>
</ul>
<hr>
<h2 id="Impressions-Understanding-Visual-Semiotics-and-Aesthetic-Impact"><a href="#Impressions-Understanding-Visual-Semiotics-and-Aesthetic-Impact" class="headerlink" title="Impressions: Understanding Visual Semiotics and Aesthetic Impact"></a>Impressions: Understanding Visual Semiotics and Aesthetic Impact</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17887">http://arxiv.org/abs/2310.17887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Julia Kruk, Caleb Ziems, Diyi Yang</li>
<li>for:  investigate the semiotics of images and how specific visual features and design choices can elicit specific emotions, thoughts, and beliefs.</li>
<li>methods:  design an annotation task heavily inspired by image analysis techniques in the Visual Arts to collect image-caption pairs and unique annotations exploring impact, pragmatic image description, impressions, and aesthetic design choices.</li>
<li>results:  existing multimodal image captioning and conditional generation models struggle to simulate plausible human responses to images, but this dataset significantly improves their ability to model impressions and aesthetic evaluations of images through fine-tuning and few-shot adaptation.Here is the full translation of the paper’s abstract in Simplified Chinese:</li>
<li>for: 这个研究旨在 investigate the semiotics of images, and how specific visual features and design choices can elicit specific emotions, thoughts, and beliefs.</li>
<li>methods: 这个研究使用了一个 heavily inspired by image analysis techniques in the Visual Arts 的 annotation task，收集了 1,440 个 image-caption pairs 和 4,320 个 unique annotations，探讨 impact, pragmatic image description, impressions, 和 aesthetic design choices.</li>
<li>results: 现有的 multimodal image captioning 和 conditional generation models 对 images 的 simulated human responses 表现不佳，但是这个 dataset 能够 significantly improve 这些模型的 ability to model impressions 和 aesthetic evaluations of images through fine-tuning 和 few-shot adaptation.<details>
<summary>Abstract</summary>
Is aesthetic impact different from beauty? Is visual salience a reflection of its capacity for effective communication? We present Impressions, a novel dataset through which to investigate the semiotics of images, and how specific visual features and design choices can elicit specific emotions, thoughts and beliefs. We posit that the impactfulness of an image extends beyond formal definitions of aesthetics, to its success as a communicative act, where style contributes as much to meaning formation as the subject matter. However, prior image captioning datasets are not designed to empower state-of-the-art architectures to model potential human impressions or interpretations of images. To fill this gap, we design an annotation task heavily inspired by image analysis techniques in the Visual Arts to collect 1,440 image-caption pairs and 4,320 unique annotations exploring impact, pragmatic image description, impressions, and aesthetic design choices. We show that existing multimodal image captioning and conditional generation models struggle to simulate plausible human responses to images. However, this dataset significantly improves their ability to model impressions and aesthetic evaluations of images through fine-tuning and few-shot adaptation.
</details>
<details>
<summary>摘要</summary>
是美学影响与美的区别？视觉吸引力是通信效果的反映吗？我们介绍Impressions，一个新的数据集，用于探讨图像的 semiotics，并如何specific visual features和设计选择可以引发specific emotions, thoughts和beliefs。我们认为图像的吸引力不仅限于传统的美学定义，还包括图像作为通信行为的成功度，style与subject matter共同形成意义。但是，先前的图像描述数据集不适用于激发人类的印象或解释。为了填补这个空白，我们设计了一个基于图像分析技术的image描述任务，收集了1,440个图像-描述对和4,320个特有的批注，探讨影响、实用描述、印象和美学设计选择。我们发现，现有的多modal图像描述和条件生成模型在模拟人类对图像的回应方面表现不佳。但是，这个数据集可以大幅提高这些模型对图像印象和美学评价的能力。
</details></li>
</ul>
<hr>
<h2 id="Reconstructive-Latent-Space-Neural-Radiance-Fields-for-Efficient-3D-Scene-Representations"><a href="#Reconstructive-Latent-Space-Neural-Radiance-Fields-for-Efficient-3D-Scene-Representations" class="headerlink" title="Reconstructive Latent-Space Neural Radiance Fields for Efficient 3D Scene Representations"></a>Reconstructive Latent-Space Neural Radiance Fields for Efficient 3D Scene Representations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17880">http://arxiv.org/abs/2310.17880</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tristan Aumentado-Armstrong, Ashkan Mirzaei, Marcus A. Brubaker, Jonathan Kelly, Alex Levinshtein, Konstantinos G. Derpanis, Igor Gilitschenski</li>
<li>for: 这paper aimed to improve the efficiency of Neural Radiance Fields (NeRFs) for 3D scene representation, while maintaining high image quality.</li>
<li>methods: 该paper使用了一个 autoencoder (AE) 与 NeRF 结合，将 latent features 渲染并用 convolutional decoding 来生成新的视图。</li>
<li>results: 相比标准色域 NeRFs，latent-space NeRF 可以生成更高质量的新视图，并且可以在三倍的渲染速度下得到更好的效果。此外，通过缩小 AE 架构，可以控制效率和图像质量之间的交易，并达到更高的渲染速度。<details>
<summary>Abstract</summary>
Neural Radiance Fields (NeRFs) have proven to be powerful 3D representations, capable of high quality novel view synthesis of complex scenes. While NeRFs have been applied to graphics, vision, and robotics, problems with slow rendering speed and characteristic visual artifacts prevent adoption in many use cases. In this work, we investigate combining an autoencoder (AE) with a NeRF, in which latent features (instead of colours) are rendered and then convolutionally decoded. The resulting latent-space NeRF can produce novel views with higher quality than standard colour-space NeRFs, as the AE can correct certain visual artifacts, while rendering over three times faster. Our work is orthogonal to other techniques for improving NeRF efficiency. Further, we can control the tradeoff between efficiency and image quality by shrinking the AE architecture, achieving over 13 times faster rendering with only a small drop in performance. We hope that our approach can form the basis of an efficient, yet high-fidelity, 3D scene representation for downstream tasks, especially when retaining differentiability is useful, as in many robotics scenarios requiring continual learning.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Siamese-DETR-for-Generic-Multi-Object-Tracking"><a href="#Siamese-DETR-for-Generic-Multi-Object-Tracking" class="headerlink" title="Siamese-DETR for Generic Multi-Object Tracking"></a>Siamese-DETR for Generic Multi-Object Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17875">http://arxiv.org/abs/2310.17875</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiankun Liu, Yichen Li, Yuqi Jiang, Ying Fu<br>for: 本研究的目的是提出一种简单 yet effective的 Generic Multi-Object Tracking (GMOT) 方法，以便在不同场景中检测和跟踪动态对象。methods: 本研究使用了 Siamese-DETR 方法，其中利用了 detection 数据集 (e.g., COCO) 进行训练，并 introduce 了一种动态匹配训练策略以使用提供的筛选器。results: 实验结果显示，Siamese-DETR 在 GMOT-40 数据集上表现出色，至今为止比 EXISTS 的 MOT 方法更高。<details>
<summary>Abstract</summary>
The ability to detect and track the dynamic objects in different scenes is fundamental to real-world applications, e.g., autonomous driving and robot navigation. However, traditional Multi-Object Tracking (MOT) is limited to tracking objects belonging to the pre-defined closed-set categories. Recently, Open-Vocabulary MOT (OVMOT) and Generic MOT (GMOT) are proposed to track interested objects beyond pre-defined categories with the given text prompt and template image. However, the expensive well pre-trained (vision-)language model and fine-grained category annotations are required to train OVMOT models. In this paper, we focus on GMOT and propose a simple but effective method, Siamese-DETR, for GMOT. Only the commonly used detection datasets (e.g., COCO) are required for training. Different from existing GMOT methods, which train a Single Object Tracking (SOT) based detector to detect interested objects and then apply a data association based MOT tracker to get the trajectories, we leverage the inherent object queries in DETR variants. Specifically: 1) The multi-scale object queries are designed based on the given template image, which are effective for detecting different scales of objects with the same category as the template image; 2) A dynamic matching training strategy is introduced to train Siamese-DETR on commonly used detection datasets, which takes full advantage of provided annotations; 3) The online tracking pipeline is simplified through a tracking-by-query manner by incorporating the tracked boxes in previous frame as additional query boxes. The complex data association is replaced with the much simpler Non-Maximum Suppression (NMS). Extensive experimental results show that Siamese-DETR surpasses existing MOT methods on GMOT-40 dataset by a large margin.
</details>
<details>
<summary>摘要</summary>
能力检测和跟踪不同场景中的动态对象是实际应用中的基本要求，例如自动驾驶和机器人导航。然而，传统的多对象跟踪（MOT）仅能跟踪预定的关闭集类型的对象。最近，开放词汇MOT（OVMOT）和通用MOT（GMOT）被提出，以检测与给定模板图像中的对象相关的对象。然而，需要昂贵的高级见语言模型和细化类别标注来训练OVMOT模型。在本文中，我们将关注GMOT，并提出一种简单 yet effective的方法：Siamese-DETR。只需使用常用的检测数据集（例如COCO）进行训练。与现有GMOT方法不同，我们不会训练单个对象检测器来检测兴趣对象，而是利用DETR变体中的内置对象查询。具体来说，我们做了以下三个方法：1）基于给定模板图像的多尺度对象查询，可以有效地检测不同的对象大小与模板图像中的同一类型对象; 2）我们引入了动态匹配训练策略，以利用提供的注释来训练Siamese-DETR; 3）通过将跟踪框架简化为查询方式，并将已跟踪的框架作为额外的查询框架，替代复杂的数据关联。这里的数据关联被替换为非最大Suppression（NMS）。我们的实验结果表明，Siamese-DETR在GMOT-40数据集上大幅超越现有MOT方法。
</details></li>
</ul>
<hr>
<h2 id="SmooSeg-Smoothness-Prior-for-Unsupervised-Semantic-Segmentation"><a href="#SmooSeg-Smoothness-Prior-for-Unsupervised-Semantic-Segmentation" class="headerlink" title="SmooSeg: Smoothness Prior for Unsupervised Semantic Segmentation"></a>SmooSeg: Smoothness Prior for Unsupervised Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17874">http://arxiv.org/abs/2310.17874</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mc-lan/smooseg">https://github.com/mc-lan/smooseg</a></li>
<li>paper_authors: Mengcheng Lan, Xinjiang Wang, Yiping Ke, Jiaxing Xu, Litong Feng, Wayne Zhang</li>
<li>for: 这个论文主要针对不具有人工标注的图像分割 tasks，即将图像分割为Semantic groups而不需要人工标注。</li>
<li>methods: 我们提出了一个 novel 的方法，即 SmooSeg，它利用自我supervised learning 方法来模型对观测到的变化之间的关系，并将这些变化映射到Semantic groups中。我们还引入了一个新的平滑性损失函数，它可以在不同的Semantic groups之间实现平滑的变化，同时保留不同Semantic groups之间的关系。</li>
<li>results: 根据我们的实验结果，SmooSeg 可以对 COCOStuff、Cityscapes 和 Potsdam-3 等三个数据集进行高效的分割，并且与 STEGO 相比，SmooSeg 可以提高 pixel accuracy 的表现。具体来说，在 COCOStuff 数据集上，SmooSeg 可以提高 pixel accuracy 的表现+14.9%，在 Cityscapes 数据集上提高 +13.0%，在 Potsdam-3 数据集上提高 +5.7%。<details>
<summary>Abstract</summary>
Unsupervised semantic segmentation is a challenging task that segments images into semantic groups without manual annotation. Prior works have primarily focused on leveraging prior knowledge of semantic consistency or priori concepts from self-supervised learning methods, which often overlook the coherence property of image segments. In this paper, we demonstrate that the smoothness prior, asserting that close features in a metric space share the same semantics, can significantly simplify segmentation by casting unsupervised semantic segmentation as an energy minimization problem. Under this paradigm, we propose a novel approach called SmooSeg that harnesses self-supervised learning methods to model the closeness relationships among observations as smoothness signals. To effectively discover coherent semantic segments, we introduce a novel smoothness loss that promotes piecewise smoothness within segments while preserving discontinuities across different segments. Additionally, to further enhance segmentation quality, we design an asymmetric teacher-student style predictor that generates smoothly updated pseudo labels, facilitating an optimal fit between observations and labeling outputs. Thanks to the rich supervision cues of the smoothness prior, our SmooSeg significantly outperforms STEGO in terms of pixel accuracy on three datasets: COCOStuff (+14.9%), Cityscapes (+13.0%), and Potsdam-3 (+5.7%).
</details>
<details>
<summary>摘要</summary>
无监督semantic segmentation是一项复杂的任务，它的目标是将图像分割成semantic组without manual annotation. 先前的研究主要依靠自动学习方法来激活先前的semantic consistency或self-supervised learning方法，这些方法经常忽视图像分割的coherence性质. 在这篇论文中，我们表明了smoothness prior，即close features in a metric space share the same semantics，可以大大简化segmentation。 在这个思想下，我们提出了一种新的方法called SmooSeg，它利用self-supervised learning方法来表示observations的closeness关系作为smoothness信号。 为了有效发现coherent semantic segments，我们引入了一种新的smoothness loss，该损失函数激活piecewise smoothness within segments while preserving discontinuities across different segments。 此外，我们还设计了一种异形 teacher-student 预测器，该预测器可以生成smoothly updated pseudo labels，使得observations和labeling输出之间进行优化的适应。 由于smoothness prior提供了丰富的监督信号，我们的SmooSeg在COCOStuff (+14.9%), Cityscapes (+13.0%), and Potsdam-3 (+5.7%)三个数据集上都显著超过STEGO的像素准确率。
</details></li>
</ul>
<hr>
<h2 id="Grid-Jigsaw-Representation-with-CLIP-A-New-Perspective-on-Image-Clustering"><a href="#Grid-Jigsaw-Representation-with-CLIP-A-New-Perspective-on-Image-Clustering" class="headerlink" title="Grid Jigsaw Representation with CLIP: A New Perspective on Image Clustering"></a>Grid Jigsaw Representation with CLIP: A New Perspective on Image Clustering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17869">http://arxiv.org/abs/2310.17869</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijie Song, Zhenzhen Hu, Richang Hong</li>
<li>for: 这种图像归一化学习是计算机视觉领域中的一种不可或缺的基础技术，它可以帮助图像进行有效的分类和识别。</li>
<li>methods: 该文章提出了一种基于缝隙的图像归一化方法，即Grid Jigsaw Representation（GJR），该方法通过模拟人类缝隙图像的方式，来提高模型对图像的特征分解和分类能力。</li>
<li>results: 该文章通过对多个标准 benchmark 数据集进行测试，证明了GJR模块可以帮助图像归一化进行更好的分类和识别，并且在速度和精度两个方面具有优于传统方法的优势。此外，文章还提出了一种基于预训练的Grid Jigsaw Representation（pGJR）方法，该方法可以在快速的 converges 过程中提高图像归一化的效果。<details>
<summary>Abstract</summary>
Unsupervised representation learning for image clustering is essential in computer vision. Although the advancement of visual models has improved image clustering with efficient visual representations, challenges still remain. Firstly, these features often lack the ability to represent the internal structure of images, hindering the accurate clustering of visually similar images. Secondly, the existing features tend to lack finer-grained semantic labels, limiting the ability to capture nuanced differences and similarities between images.   In this paper, we first introduce Jigsaw based strategy method for image clustering called Grid Jigsaw Representation (GJR) with systematic exposition from pixel to feature in discrepancy against human and computer. We emphasize that this algorithm, which mimics human jigsaw puzzle, can effectively improve the model to distinguish the spatial feature between different samples and enhance the clustering ability. GJR modules are appended to a variety of deep convolutional networks and tested with significant improvements on a wide range of benchmark datasets including CIFAR-10, CIFAR-100/20, STL-10, ImageNet-10 and ImageNetDog-15.   On the other hand, convergence efficiency is always an important challenge for unsupervised image clustering. Recently, pretrained representation learning has made great progress and released models can extract mature visual representations. It is obvious that use the pretrained model as feature extractor can speed up the convergence of clustering where our aim is to provide new perspective in image clustering with reasonable resource application and provide new baseline. Further, we innovate pretrain-based Grid Jigsaw Representation (pGJR) with improvement by GJR. The experiment results show the effectiveness on the clustering task with respect to the ACC, NMI and ARI three metrics and super fast convergence speed.
</details>
<details>
<summary>摘要</summary>
自然无监督学习是计算机视觉中不可或缺的一部分。虽然视觉模型的进步使得图像归类得到了有效的视觉表示，但是还存在一些挑战。首先，这些特征通常缺乏表示图像内部结构的能力，使得准确归类类似图像 become more difficult.其次，现有的特征通常缺乏更细grained的Semantic Label，限制了捕捉图像之间细微差异和相似性的能力。在这篇论文中，我们首先介绍了基于Jigsaw策略的图像归类方法，即Grid Jigsaw Representation（GJR），并进行系统性的描述从像素到特征之间的差异。我们强调这种算法，类似于人类的缺失图形，可以有效地提高模型对图像之间的空间特征的分辨率，从而提高归类能力。GJR模块被附加到了多种深度卷积网络中，并在各种benchmark数据集上进行了广泛的测试，包括CIFAR-10、CIFAR-100/20、STL-10、ImageNet-10和ImageNetDog-15。然而，无监督图像归类中的收敛效率总是一个重要的挑战。最近，预训练的表征学习已经取得了很大的进步，释放出了许多高质量的视觉表示。可以看到，使用预训练模型作为特征提取器可以加速归类的收敛速度。我们的目标是提供一种新的视角，以及一种合理的资源应用，以提高图像归类的效果。此外，我们还创新了预训练基于Grid Jigsaw Representation（pGJR），通过改进GJR来提高归类效果。实验结果表明，pGJR在归类任务中对ACC、NMI和ARI三个 metric具有显著的效果，并且具有超快的收敛速度。
</details></li>
</ul>
<hr>
<h2 id="What-You-See-Is-What-You-Detect-Towards-better-Object-Densification-in-3D-detection"><a href="#What-You-See-Is-What-You-Detect-Towards-better-Object-Densification-in-3D-detection" class="headerlink" title="What You See Is What You Detect: Towards better Object Densification in 3D detection"></a>What You See Is What You Detect: Towards better Object Densification in 3D detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17842">http://arxiv.org/abs/2310.17842</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/orbis36/wysiwyd">https://github.com/orbis36/wysiwyd</a></li>
<li>paper_authors: Tianran Liu, Zeping Zhang Morteza Mousa Pasandi, Robert Laganiere</li>
<li>for: The paper is written for improving the accuracy of 3D object detection from Lidar signals, specifically addressing the issue of object completion in 3D perception.</li>
<li>methods: The paper proposes a visible part completion method that requires only a small number of prediction points, which is based on a mesh-deformation-based approach to augment the point set associated with visible foreground objects. The method consists of two parts: an Intra-Frustum Segmentation Transformer (IFST) and a Mesh Depth Completion Network(MDCNet).</li>
<li>results: The paper shows that the proposed method can provide up to 12.2% performance improvements over most of the public baseline models on the KITTI and NuScenes dataset, bringing the state-of-the-art to a new level.Here is the information in Simplified Chinese text:</li>
<li>for: 本文是为了提高三元素探测从激光信号中的准确性，特别是对三元素完成问题的解决。</li>
<li>methods: 本文提出了一种可见部分完成方法，只需要一小部分的预测点，基于 mesh 变形来增强可见前景对象的点集。该方法由两部分组成：内部 Frustum 分割 transformer (IFST) 和 mesh 深度完成网络 (MDCNet)。</li>
<li>results: 本文显示，提出的方法可以在 KITTI 和 NuScenes 数据集上提供最多 12.2% 的性能提升，将状态艺术带到新的水平。<details>
<summary>Abstract</summary>
Recent works have demonstrated the importance of object completion in 3D Perception from Lidar signal. Several methods have been proposed in which modules were used to densify the point clouds produced by laser scanners, leading to better recall and more accurate results. Pursuing in that direction, we present, in this work, a counter-intuitive perspective: the widely-used full-shape completion approach actually leads to a higher error-upper bound especially for far away objects and small objects like pedestrians. Based on this observation, we introduce a visible part completion method that requires only 11.3\% of the prediction points that previous methods generate. To recover the dense representation, we propose a mesh-deformation-based method to augment the point set associated with visible foreground objects. Considering that our approach focuses only on the visible part of the foreground objects to achieve accurate 3D detection, we named our method What You See Is What You Detect (WYSIWYD). Our proposed method is thus a detector-independent model that consists of 2 parts: an Intra-Frustum Segmentation Transformer (IFST) and a Mesh Depth Completion Network(MDCNet) that predicts the foreground depth from mesh deformation. This way, our model does not require the time-consuming full-depth completion task used by most pseudo-lidar-based methods. Our experimental evaluation shows that our approach can provide up to 12.2\% performance improvements over most of the public baseline models on the KITTI and NuScenes dataset bringing the state-of-the-art to a new level. The codes will be available at \textcolor[RGB]{0,0,255}{\url{https://github.com/Orbis36/WYSIWYD}
</details>
<details>
<summary>摘要</summary>
最近的研究表明3D感知从激光信号中的物体完成是非常重要的。许多方法已经被提出，其中包括使用模块来增强激光扫描仪生成的点云，从而提高精度和准确性。在这个方向下，我们在这项工作中提出了一个Counter-Intuitive Perspective：广泛使用的全形完成方法实际上会导致远距离物体和小物体（如人肉）的高错误上界。基于这一观察，我们引入可见部分完成方法，只需11.3%的预测点。为了恢复稠密表示，我们提议一种基于网格扭形的方法，用于补充可见前景物体的点集。由于我们的方法只关注可见前景物体来实现准确3D探测，因此我们将其命名为What You See Is What You Detect（WYSIWYD）。我们的提出的方法包括两部分：Intra-Frustum Segmentation Transformer（IFST）和Mesh Depth Completion Network（MDCNet），它们分别预测前景物体的深度和网格扭形。这样，我们的模型不需要时间consuming的全深度完成任务，与大多数 pseudo-lidar 基于的方法不同。我们的实验评估表明，我们的方法可以在 KITTI 和 NuScenes 数据集上提供Up to 12.2%的性能提升，将状态艺术引入到新的水平。代码将在 \textcolor[RGB]{0,0,255}{\url{https://github.com/Orbis36/WYSIWYD} 上提供。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/27/cs.CV_2023_10_27/" data-id="cloh7tqi900k47b88h8bi1zd2" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_10_27" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/27/cs.AI_2023_10_27/" class="article-date">
  <time datetime="2023-10-27T12:00:00.000Z" itemprop="datePublished">2023-10-27</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/27/cs.AI_2023_10_27/">cs.AI - 2023-10-27</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Multi-Time-Scale-World-Models"><a href="#Multi-Time-Scale-World-Models" class="headerlink" title="Multi Time Scale World Models"></a>Multi Time Scale World Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18534">http://arxiv.org/abs/2310.18534</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/djdprogramming/adfa2">https://github.com/djdprogramming/adfa2</a></li>
<li>paper_authors: Vaisakh Shaj, Saleh Gholam Zadeh, Ozan Demir, Luiz Ricardo Douat, Gerhard Neumann</li>
<li>for: 这 paper 是为了研究智能代理如何使用内部世界模型来预测不同的行为范围和时间尺度上的不同趋势。</li>
<li>methods: 这 paper 使用了一种名为 Multi Time Scale State Space (MTS3) 的概率ormalism，这种ormalism 可以有效地在多个时间尺度上进行高精度的长期预测和不确定性估计。</li>
<li>results: 实验表明，MTS3 方法在许多系统标识 benchmark 上表现出色，包括复杂的模拟和实际世界动力系统。<details>
<summary>Abstract</summary>
Intelligent agents use internal world models to reason and make predictions about different courses of their actions at many scales. Devising learning paradigms and architectures that allow machines to learn world models that operate at multiple levels of temporal abstractions while dealing with complex uncertainty predictions is a major technical hurdle. In this work, we propose a probabilistic formalism to learn multi-time scale world models which we call the Multi Time Scale State Space (MTS3) model. Our model uses a computationally efficient inference scheme on multiple time scales for highly accurate long-horizon predictions and uncertainty estimates over several seconds into the future. Our experiments, which focus on action conditional long horizon future predictions, show that MTS3 outperforms recent methods on several system identification benchmarks including complex simulated and real-world dynamical systems.
</details>
<details>
<summary>摘要</summary>
智能代理用内部世界模型来进行理解和预测不同的行动轨迹，从小规模到大规模，面临艰难的技术挑战。在这种工作中，我们提出了一种概率形式来学习多级时间尺度的世界模型，我们称之为多时间尺度状态空间（MTS3）模型。我们的模型使用多个时间尺度的计算效率优化的推理方案，以实现高精度的长期预测和未来数分秒内的不确定性估计。我们的实验集中关注行动条件长期未来预测，并在复杂的模拟和真实世界动力系统上达到了比较好的效果，超过了最近的方法。
</details></li>
</ul>
<hr>
<h2 id="Sample-based-Explanations-via-Generalized-Representers"><a href="#Sample-based-Explanations-via-Generalized-Representers" class="headerlink" title="Sample based Explanations via Generalized Representers"></a>Sample based Explanations via Generalized Representers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18526">http://arxiv.org/abs/2310.18526</a></li>
<li>repo_url: None</li>
<li>paper_authors: Che-Ping Tsai, Chih-Kuan Yeh, Pradeep Ravikumar</li>
<li>for: 本文提出了一种通用的样本基于解释方法，称为通用代表者（generalized representers），用于测量模型训练样本对测试预测的影响。</li>
<li>methods: 该方法使用两个组件：全局样本重要性和本地样本重要性。全局样本重要性量化训练点对模型的影响，是对测试样本不变的。本地样本重要性使用kernel计算测试点和训练点之间的相似度。文章的一个重要贡献是证明通用代表者是所有样本基于解释方法的自然集合。</li>
<li>results: 文章进行了对两个图像和两个文本分类 datasets 的实验比较，并证明了不同的通用代表者在不同的 dataset 上的性能。<details>
<summary>Abstract</summary>
We propose a general class of sample based explanations of machine learning models, which we term generalized representers. To measure the effect of a training sample on a model's test prediction, generalized representers use two components: a global sample importance that quantifies the importance of the training point to the model and is invariant to test samples, and a local sample importance that measures similarity between the training sample and the test point with a kernel. A key contribution of the paper is to show that generalized representers are the only class of sample based explanations satisfying a natural set of axiomatic properties. We discuss approaches to extract global importances given a kernel, and also natural choices of kernels given modern non-linear models. As we show, many popular existing sample based explanations could be cast as generalized representers with particular choices of kernels and approaches to extract global importances. Additionally, we conduct empirical comparisons of different generalized representers on two image and two text classification datasets.
</details>
<details>
<summary>摘要</summary>
我们提出一种通用的样本基于解释方法，我们称之为通用表示者（generalized representers）。为了测量训练样本对模型测试预测的影响，通用表示者使用两个组件：全局样本重要性和本地样本重要性。全局样本重要性量化训练点对模型的影响，是不变的测试样本，而本地样本重要性则是测试点和训练点之间的相似性，使用核函数。我们的论文的一个重要贡献是证明通用表示者是唯一满足自然的axioms的类型的样本基于解释方法。我们讨论如何从核函数提取全局重要性，以及现代非线性模型中的自然选择核函数。我们还进行了两个图像和两个文本分类 datasets上的实验比较，以证明不同的通用表示者之间的区别。
</details></li>
</ul>
<hr>
<h2 id="3DCoMPaT-An-improved-Large-scale-3D-Vision-Dataset-for-Compositional-Recognition"><a href="#3DCoMPaT-An-improved-Large-scale-3D-Vision-Dataset-for-Compositional-Recognition" class="headerlink" title="3DCoMPaT$^{++}$: An improved Large-scale 3D Vision Dataset for Compositional Recognition"></a>3DCoMPaT$^{++}$: An improved Large-scale 3D Vision Dataset for Compositional Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18511">http://arxiv.org/abs/2310.18511</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Vision-CAIR/3DCoMPaT-v2">https://github.com/Vision-CAIR/3DCoMPaT-v2</a></li>
<li>paper_authors: Habib Slim, Xiang Li, Yuchen Li, Mahmoud Ahmed, Mohamed Ayman, Ujjwal Upadhyay, Ahmed Abdelreheem, Arpit Prajapati, Suhail Pothigara, Peter Wonka, Mohamed Elhoseiny</li>
<li>for: 本研究团队发布了3DCoMPaT$^{++}$,一个包含2D&#x2F;3D多Modal数据集，包括160万个渲染视图和1000万个精细化的3D形状，以及匹配的RGB点云、3D纹理网格、深度地图和分割mask。</li>
<li>methods: 研究人员使用了一种新的任务，即Grounded CoMPaT Recognition (GCR)，以同时识别和地理3D物体的组合材料。此外，研究人员还提出了一种修改后的PointNet$^{++}$模型，用于6D输入的训练。</li>
<li>results: 研究人员在CVPR2023会议上组织了一场数据挑战，展示了赢家方法的使用，并 explore了GCR增强的一些alternative技术。<details>
<summary>Abstract</summary>
In this work, we present 3DCoMPaT$^{++}$, a multimodal 2D/3D dataset with 160 million rendered views of more than 10 million stylized 3D shapes carefully annotated at the part-instance level, alongside matching RGB point clouds, 3D textured meshes, depth maps, and segmentation masks. 3DCoMPaT$^{++}$ covers 41 shape categories, 275 fine-grained part categories, and 293 fine-grained material classes that can be compositionally applied to parts of 3D objects. We render a subset of one million stylized shapes from four equally spaced views as well as four randomized views, leading to a total of 160 million renderings. Parts are segmented at the instance level, with coarse-grained and fine-grained semantic levels. We introduce a new task, called Grounded CoMPaT Recognition (GCR), to collectively recognize and ground compositions of materials on parts of 3D objects. Additionally, we report the outcomes of a data challenge organized at CVPR2023, showcasing the winning method's utilization of a modified PointNet$^{++}$ model trained on 6D inputs, and exploring alternative techniques for GCR enhancement. We hope our work will help ease future research on compositional 3D Vision.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们介绍3DCoMPaT$^{++}$,一个多Modal 2D/3D数据集，包含160万个渲染视图，以及更多的1000万个精细化的3D形状，其中每个形状都有精细化的部件标注，同时还包含匹配的RGB点云、 текстури化的三角形、深度地图和分割mask。3DCoMPaT$^{++}$覆盖了41种形状类，275种精细化部件类，以及293种精细化材料类，这些类可以在3D对象的部件上进行组合应用。我们从四个相等的视图渲染了一个百万个精细化的形状，并且随机选择四个视图，共计160万个渲染。在部件级别进行分割，并设置了粗略和细腻的semantic水平。我们介绍了一个新任务，即Grounded CoMPaT Recognition (GCR)，以同时认识和固定3D对象的部件上的材料组合。此外，我们还报告了CVPR2023年度数据挑战的结果，展示了一种使用修改后的PointNet$^{++}$模型训练于6D输入的赢家方法，以及探讨了GCR增强技术的代替方法。我们希望我们的工作能够为未来的3D视觉研究提供帮助。
</details></li>
</ul>
<hr>
<h2 id="Deep-Reinforcement-Learning-for-Weapons-to-Targets-Assignment-in-a-Hypersonic-strike"><a href="#Deep-Reinforcement-Learning-for-Weapons-to-Targets-Assignment-in-a-Hypersonic-strike" class="headerlink" title="Deep Reinforcement Learning for Weapons to Targets Assignment in a Hypersonic strike"></a>Deep Reinforcement Learning for Weapons to Targets Assignment in a Hypersonic strike</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18509">http://arxiv.org/abs/2310.18509</a></li>
<li>repo_url: None</li>
<li>paper_authors: Brian Gaudet, Kris Drozd, Roberto Furfaro</li>
<li>for: 用深度强化学习优化多辆 hypersonic strike 武器识别策略，以 maximize 每集episode中破坏目标的总价值。</li>
<li>methods: 使用深度强化学习来优化武器识别策略，并与非线性整数编程（NLIP）比较性能。</li>
<li>results: 相比NLIP策略，深度强化学习策略具有优化性和1000倍减少计算时间，可以实现实时决策，满足 autonomous 决策在任务末端。<details>
<summary>Abstract</summary>
We use deep reinforcement learning (RL) to optimize a weapons to target assignment (WTA) policy for multi-vehicle hypersonic strike against multiple targets. The objective is to maximize the total value of destroyed targets in each episode. Each randomly generated episode varies the number and initial conditions of the hypersonic strike weapons (HSW) and targets, the value distribution of the targets, and the probability of a HSW being intercepted. We compare the performance of this WTA policy to that of a benchmark WTA policy derived using non-linear integer programming (NLIP), and find that the RL WTA policy gives near optimal performance with a 1000X speedup in computation time, allowing real time operation that facilitates autonomous decision making in the mission end game.
</details>
<details>
<summary>摘要</summary>
我们使用深度强化学习（RL）优化多辆高速武器对多个目标的分配策略，以最大化每个回合的目标总值。每个随机生成的回合都会变化高速武器和目标的数量和初始状态，目标的价值分布，以及高速武器被 intercept 的概率。我们对这种 WTA 策略与非线性整数编程（NLIP） derive 的参考 WTA 策略进行比较，发现 RL WTA 策略在计算时间上具有1000倍的加速，可以实现实时运行，从而促进任务尾部自动决策。
</details></li>
</ul>
<hr>
<h2 id="How-Well-Do-Feature-Additive-Explainers-Explain-Feature-Additive-Predictors"><a href="#How-Well-Do-Feature-Additive-Explainers-Explain-Feature-Additive-Predictors" class="headerlink" title="How Well Do Feature-Additive Explainers Explain Feature-Additive Predictors?"></a>How Well Do Feature-Additive Explainers Explain Feature-Additive Predictors?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18496">http://arxiv.org/abs/2310.18496</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zachariah Carmichael, Walter J. Scheirer</li>
<li>for: 这篇论文旨在研究可解释AI（XAI）技术，以帮助理解黑盒模型的决策过程。</li>
<li>methods: 该论文使用了多种常用的特征添加式解释器（如LIME、SHAP、SHAPR、MAPLE、PDP），以评估这些解释器在添加式预测器上的效果。</li>
<li>results: 研究发现，这些解释器在处理符号表示、神经网络和总代数模型上都有较差的性能，尤其是当决策过程含有特征交互时。<details>
<summary>Abstract</summary>
Surging interest in deep learning from high-stakes domains has precipitated concern over the inscrutable nature of black box neural networks. Explainable AI (XAI) research has led to an abundance of explanation algorithms for these black boxes. Such post hoc explainers produce human-comprehensible explanations, however, their fidelity with respect to the model is not well understood - explanation evaluation remains one of the most challenging issues in XAI. In this paper, we ask a targeted but important question: can popular feature-additive explainers (e.g., LIME, SHAP, SHAPR, MAPLE, and PDP) explain feature-additive predictors? Herein, we evaluate such explainers on ground truth that is analytically derived from the additive structure of a model. We demonstrate the efficacy of our approach in understanding these explainers applied to symbolic expressions, neural networks, and generalized additive models on thousands of synthetic and several real-world tasks. Our results suggest that all explainers eventually fail to correctly attribute the importance of features, especially when a decision-making process involves feature interactions.
</details>
<details>
<summary>摘要</summary>
高于常规领域的深度学习突破性引起了黑盒神经网络的不可预测性的问题的关注。可解释AI（XAI）研究引发了大量的解释算法 для这些黑盒。然而，这些后期解释器的准确性与模型之间的关系并不很清楚 - 解释评估仍然是XAI中最大的挑战。在这篇论文中，我们提出了一个targeted yet important问题：可能性分解器（例如LIME、SHAP、SHAPR、MAPLE和PDP）能够解释增加性预测器吗？我们在这篇论文中评估这些解释器在符号表示法、神经网络和总加itive模型上的 thousendsof synthetic和several real-world任务中的效果。我们的结果表明，无论是在符号表示法还是在实际任务上，所有的解释器都 eventually fail to correctly attribute the importance of features，特别是当决策过程中涉及到特征之间的互动。
</details></li>
</ul>
<hr>
<h2 id="MOSEL-Inference-Serving-Using-Dynamic-Modality-Selection"><a href="#MOSEL-Inference-Serving-Using-Dynamic-Modality-Selection" class="headerlink" title="MOSEL: Inference Serving Using Dynamic Modality Selection"></a>MOSEL: Inference Serving Using Dynamic Modality Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18481">http://arxiv.org/abs/2310.18481</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bodun Hu, Le Xu, Jeongyoon Moon, Neeraja J. Yadwadkar, Aditya Akella</li>
<li>For: The paper is written for researchers and developers who are working on machine learning models and inference-serving systems, and who are looking for ways to improve the efficiency and accuracy of their models.* Methods: The paper proposes a new approach called modality selection, which involves adaptively choosing the most relevant modalities for an inference task based on user-defined performance and accuracy requirements. The proposed approach is implemented in an automated inference serving system called MOSEL.* Results: The paper reports that MOSEL improves system throughput by 3.6 times with an accuracy guarantee and shortens job completion times by 11 times compared to a baseline approach. The results demonstrate the effectiveness of the modality selection approach and the benefits of using MOSEL for multi-modal machine learning models.<details>
<summary>Abstract</summary>
Rapid advancements over the years have helped machine learning models reach previously hard-to-achieve goals, sometimes even exceeding human capabilities. However, to attain the desired accuracy, the model sizes and in turn their computational requirements have increased drastically. Thus, serving predictions from these models to meet any target latency and cost requirements of applications remains a key challenge, despite recent work in building inference-serving systems as well as algorithmic approaches that dynamically adapt models based on inputs. In this paper, we introduce a form of dynamism, modality selection, where we adaptively choose modalities from inference inputs while maintaining the model quality. We introduce MOSEL, an automated inference serving system for multi-modal ML models that carefully picks input modalities per request based on user-defined performance and accuracy requirements. MOSEL exploits modality configurations extensively, improving system throughput by 3.6$\times$ with an accuracy guarantee and shortening job completion times by 11$\times$.
</details>
<details>
<summary>摘要</summary>
随着时间的推移，机器学习模型在过去的几年内进行了快速的进步，有时甚至超越人类的能力。然而，为了达到所需的准确率，模型的大小和计算需求却有了很大的增长。因此，将预测结果服务到应用程序中，以满足任何目标延迟和成本要求，仍然是一大项目。在这篇论文中，我们引入了一种动态性，即modalities选择，我们在推理输入中动态选择Modalities，保持模型质量。我们介绍了MOSEL，一个自动化推理服务系统，可以智能地选择输入Modalities，根据用户定义的性能和准确率要求。MOSEL利用模式配置的潜在优势，提高系统吞吐量3.6倍，同时保证准确率和完成任务时间的短短化。
</details></li>
</ul>
<hr>
<h2 id="Weighted-Sampled-Split-Learning-WSSL-Balancing-Privacy-Robustness-and-Fairness-in-Distributed-Learning-Environments"><a href="#Weighted-Sampled-Split-Learning-WSSL-Balancing-Privacy-Robustness-and-Fairness-in-Distributed-Learning-Environments" class="headerlink" title="Weighted Sampled Split Learning (WSSL): Balancing Privacy, Robustness, and Fairness in Distributed Learning Environments"></a>Weighted Sampled Split Learning (WSSL): Balancing Privacy, Robustness, and Fairness in Distributed Learning Environments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18479">http://arxiv.org/abs/2310.18479</a></li>
<li>repo_url: None</li>
<li>paper_authors: Manish Osti, Aashray Thakuri, Basheer Qolomany, Aos Mulahuwaish</li>
<li>for: 提高隐私、可靠性和公平性在分布式机器学习系统中</li>
<li>methods: 使用权重采样方法，将学习过程分布到多个客户端，以保护数据隐私和提高模型准确性</li>
<li>results: 1) 提高模型准确性，2) 提高系统可靠性，3) 维护客户端组合的公平性<details>
<summary>Abstract</summary>
This study presents Weighted Sampled Split Learning (WSSL), an innovative framework tailored to bolster privacy, robustness, and fairness in distributed machine learning systems. Unlike traditional approaches, WSSL disperses the learning process among multiple clients, thereby safeguarding data confidentiality. Central to WSSL's efficacy is its utilization of weighted sampling. This approach ensures equitable learning by tactically selecting influential clients based on their contributions. Our evaluation of WSSL spanned various client configurations and employed two distinct datasets: Human Gait Sensor and CIFAR-10. We observed three primary benefits: heightened model accuracy, enhanced robustness, and maintained fairness across diverse client compositions. Notably, our distributed frameworks consistently surpassed centralized counterparts, registering accuracy peaks of 82.63% and 75.51% for the Human Gait Sensor and CIFAR-10 datasets, respectively. These figures contrast with the top accuracies of 81.12% and 58.60% achieved by centralized systems. Collectively, our findings champion WSSL as a potent and scalable successor to conventional centralized learning, marking it as a pivotal stride forward in privacy-focused, resilient, and impartial distributed machine learning.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Causal-disentanglement-of-multimodal-data"><a href="#Causal-disentanglement-of-multimodal-data" class="headerlink" title="Causal disentanglement of multimodal data"></a>Causal disentanglement of multimodal data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18471">http://arxiv.org/abs/2310.18471</a></li>
<li>repo_url: None</li>
<li>paper_authors: Elise Walker, Jonas A. Actor, Carianne Martinez, Nathaniel Trask</li>
<li>for: 本研究旨在探讨 causal representation learning 算法，它可以从数据中找到低维度的表示，并且这些表示具有可解释的 causal 关系。</li>
<li>methods: 本研究使用了多种方法，包括 linear 结构 causal model、 intervenitional 数据和 weak supervision。然而，在 exploratory causal representation learning 中，这些元素和先前信息可能不可用或不合理。因此，我们提出了一种新的 causal representation learning 算法（causalPIMA），它可以使用多模态数据和物理约束来找到重要的 causal 关系。</li>
<li>results: 我们的结果表明，causalPIMA 可以在完全无监督情况下学习一个可解释的 causal 结构，同时也可以找到关键的特征。我们测试了这种算法在一个 synthetic 数据集和一个科学数据集上，结果表明，它可以在完全无监督情况下找到关键的特征和 causal 关系。<details>
<summary>Abstract</summary>
Causal representation learning algorithms discover lower-dimensional representations of data that admit a decipherable interpretation of cause and effect; as achieving such interpretable representations is challenging, many causal learning algorithms utilize elements indicating prior information, such as (linear) structural causal models, interventional data, or weak supervision. Unfortunately, in exploratory causal representation learning, such elements and prior information may not be available or warranted. Alternatively, scientific datasets often have multiple modalities or physics-based constraints, and the use of such scientific, multimodal data has been shown to improve disentanglement in fully unsupervised settings. Consequently, we introduce a causal representation learning algorithm (causalPIMA) that can use multimodal data and known physics to discover important features with causal relationships. Our innovative algorithm utilizes a new differentiable parametrization to learn a directed acyclic graph (DAG) together with a latent space of a variational autoencoder in an end-to-end differentiable framework via a single, tractable evidence lower bound loss function. We place a Gaussian mixture prior on the latent space and identify each of the mixtures with an outcome of the DAG nodes; this novel identification enables feature discovery with causal relationships. Tested against a synthetic and a scientific dataset, our results demonstrate the capability of learning an interpretable causal structure while simultaneously discovering key features in a fully unsupervised setting.
</details>
<details>
<summary>摘要</summary>
causal representation learning algorithms 找到 Lower-dimensional 的表示，这些表示具有可解释的 causal 关系；因为实现这种可解释的表示是困难的，许多 causal learning algorithms 使用元信息，如（线性）结构 causal 模型， intervening 数据或 weak supervision。然而，在 exploratory causal representation learning 中，这些元信息和 prior information 可能不可用或不合适。 alternatively， scientific datasets  часто有多个模式或 physics-based 约束，并使用这些 scientific, multimodal 数据可以提高 disentanglement 在完全无监督的设置中。因此，我们引入了一种 causal representation learning algorithm (causalPIMA)，可以使用 multimodal 数据和known physics 来发现重要的 causal 关系。我们的 innovative algorithm 使用了一种新的 differentiable  parametrization，在一个 end-to-end  differentiable 框架中学习一个 directed acyclic graph (DAG) 和一个 latent space 的 variational autoencoder。我们在这个框架中使用了一个单一的 tractable evidence lower bound 损失函数。我们在 latent space 中分配了 Gaussian mixture prior，并将每个混合物标识为 DAG 节点的结果；这种新的标识使得 feature discovery 具有 causal 关系。我们在一个 sintetic 和一个 scientific dataset 上测试了我们的结果，结果表明我们可以在完全无监督的设置中学习可解释的 causal 结构，同时也可以发现关键的特征。
</details></li>
</ul>
<hr>
<h2 id="Semi-Synthetic-Dataset-Augmentation-for-Application-Specific-Gaze-Estimation"><a href="#Semi-Synthetic-Dataset-Augmentation-for-Application-Specific-Gaze-Estimation" class="headerlink" title="Semi-Synthetic Dataset Augmentation for Application-Specific Gaze Estimation"></a>Semi-Synthetic Dataset Augmentation for Application-Specific Gaze Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18469">http://arxiv.org/abs/2310.18469</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cedric Leblond-Menard, Gabriel Picard-Krashevski, Sofiane Achiche</li>
<li>for: 增强 gaze estimation 数据集，提高模型的通用性</li>
<li>methods: 使用 textured tridimensional mesh 技术，将训练图像从虚拟摄像头中渲染出来</li>
<li>results: 平均降低 gaze estimation 错误角度的比例为 47%<details>
<summary>Abstract</summary>
Although the number of gaze estimation datasets is growing, the application of appearance-based gaze estimation methods is mostly limited to estimating the point of gaze on a screen. This is in part because most datasets are generated in a similar fashion, where the gaze target is on a screen close to camera's origin. In other applications such as assistive robotics or marketing research, the 3D point of gaze might not be close to the camera's origin, meaning models trained on current datasets do not generalize well to these tasks. We therefore suggest generating a textured tridimensional mesh of the face and rendering the training images from a virtual camera at a specific position and orientation related to the application as a mean of augmenting the existing datasets. In our tests, this lead to an average 47% decrease in gaze estimation angular error.
</details>
<details>
<summary>摘要</summary>
In other words, the existing datasets for gaze estimation are mostly generated with the gaze target on a screen close to the camera's origin, which limits the application of appearance-based gaze estimation methods to only estimating the point of gaze on a screen. To address this limitation, we suggest using a textured 3D mesh of the face and rendering the training images from a virtual camera at a specific position and orientation related to the application as a means of augmenting the existing datasets. This leads to an average 47% decrease in gaze estimation angular error.
</details></li>
</ul>
<hr>
<h2 id="LLMSTEP-LLM-proofstep-suggestions-in-Lean"><a href="#LLMSTEP-LLM-proofstep-suggestions-in-Lean" class="headerlink" title="LLMSTEP: LLM proofstep suggestions in Lean"></a>LLMSTEP: LLM proofstep suggestions in Lean</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18457">http://arxiv.org/abs/2310.18457</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wellecks/llmstep">https://github.com/wellecks/llmstep</a></li>
<li>paper_authors: Sean Welleck, Rahul Saha</li>
<li>for: 用于将语言模型集成到lean数据助手中</li>
<li>methods: 使用服务器主机的语言模型生成建议，并在lean中检查和显示给用户</li>
<li>results: 提供了基准语言模型，以及代码 для精度调整和评估，以支持进一步的开发In English, this means:</li>
<li>for: The paper is written to integrate a language model into the Lean proof assistant.</li>
<li>methods: The paper proposes using a server hosting a language model to generate suggestions, which are then checked in Lean and displayed to the user in their development environment.</li>
<li>results: The paper provides a baseline language model, along with code for fine-tuning and evaluation to support further development.<details>
<summary>Abstract</summary>
We present LLMSTEP, a tool for integrating a language model into the Lean proof assistant. LLMSTEP is a Lean 4 tactic that sends a user's proof state to a server hosting a language model. The language model generates suggestions, which are checked in Lean and displayed to a user in their development environment. We provide a baseline language model, along with code for fine-tuning and evaluation to support further development. We provide server implementations that run on CPU, a CUDA GPU, or a Google Colab notebook, as a step towards fast, effective language model suggestions for any user.
</details>
<details>
<summary>摘要</summary>
我们介绍LLMSTEP，一个将语言模型集成到lean推理助手的工具。LLMSTEP是lean 4的一个战略，将用户的证明状态发送到一个主机上的语言模型。语言模型产生建议，并在lean中检查和显示给用户。我们提供了基线语言模型，以及代码 для微调和评估，以支持进一步的开发。我们提供了 CPU、CUDA GPU 和 Google Colab 笔记本上的服务器实现，以便快速、有效地获得任何用户的语言模型建议。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Skip-Orthogonal-List-for-Dynamic-Optimal-Transport-Problem"><a href="#A-Novel-Skip-Orthogonal-List-for-Dynamic-Optimal-Transport-Problem" class="headerlink" title="A Novel Skip Orthogonal List for Dynamic Optimal Transport Problem"></a>A Novel Skip Orthogonal List for Dynamic Optimal Transport Problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18446">http://arxiv.org/abs/2310.18446</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xyxu2033/DynamicOptimalTransport">https://github.com/xyxu2033/DynamicOptimalTransport</a></li>
<li>paper_authors: Xiaoyang Xu, Hu Ding</li>
<li>for:  solves the discrete dynamic optimal transport problem efficiently when the weights or locations of the data points change, with applications in machine learning.</li>
<li>methods:  proposes a novel 2D Skip Orthogonal List and dynamic tree techniques, based on the conventional simplex method, to efficiently complete each pivoting operation within $O(|V|)$ time with high probability.</li>
<li>results:  significantly outperforms existing algorithms in dynamic scenarios, with a few simplex iterations in practice.<details>
<summary>Abstract</summary>
Optimal transportation is a fundamental topic that has attracted a great amount of attention from machine learning community in the past decades. In this paper, we consider an interesting discrete dynamic optimal transport problem: can we efficiently update the optimal transport plan when the weights or the locations of the data points change? This problem is naturally motivated by several applications in machine learning. For example, we often need to compute the optimal transportation cost between two different data sets; if some change happens to a few data points, should we re-compute the high complexity cost function or update the cost by some efficient dynamic data structure? We are aware that several dynamic maximum flow algorithms have been proposed before, however, the research on dynamic minimum cost flow problem is still quite limited, to the best of our knowledge. We propose a novel 2D Skip Orthogonal List together with some dynamic tree techniques. Although our algorithm is based on the conventional simplex method, it can efficiently complete each pivoting operation within $O(|V|)$ time with high probability where $V$ is the set of all supply and demand nodes. Since dynamic modifications typically do not introduce significant changes, our algorithm requires only a few simplex iterations in practice. So our algorithm is more efficient than re-computing the optimal transportation cost that needs at least one traversal over all the $O(|E|) = O(|V|^2)$ variables in general cases. Our experiments demonstrate that our algorithm significantly outperforms existing algorithms in the dynamic scenarios.
</details>
<details>
<summary>摘要</summary>
最优运输是机器学习领域内一个基本问题，在过去几十年内吸引了大量关注。在这篇论文中，我们考虑了一个有趣的离散动态最优运输问题：在数据点的重量或位置发生变化时，是否可以有效地更新最优运输计划？这个问题是机器学习中各种应用场景的自然推动。例如，我们经常需要计算两个不同数据集之间的最优运输成本；如果一些数据点发生变化，是否可以快速地更新高复杂性成本函数，或者使用一些高效的动态数据结构？我们知道有几种动态最大流算法被提出，但是关于动态最小成本流问题的研究还很有限，至于我们所知道的最佳状态。我们提出了一种新的2D跳过列表，并结合了一些动态树技术。尽管我们的算法基于传统的简单кс方法，但它可以在$O(|V|)$时间内高可用性下完成每次轴转操作，其中$V$是所有供应和需求节点的集合。由于动态修改通常不会引入重要的变化，我们的算法只需要几个简单кс迭代即可。因此，我们的算法比重新计算总成本函数，需要至少一次遍历所有$O(|E|) = O(|V|^2)$变量的情况下更高效。我们的实验表明，我们的算法在动态场景下明显超过现有算法。
</details></li>
</ul>
<hr>
<h2 id="Towards-a-fuller-understanding-of-neurons-with-Clustered-Compositional-Explanations"><a href="#Towards-a-fuller-understanding-of-neurons-with-Clustered-Compositional-Explanations" class="headerlink" title="Towards a fuller understanding of neurons with Clustered Compositional Explanations"></a>Towards a fuller understanding of neurons with Clustered Compositional Explanations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18443">http://arxiv.org/abs/2310.18443</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/krlgroup/clustered-compositional-explanations">https://github.com/krlgroup/clustered-compositional-explanations</a></li>
<li>paper_authors: Biagio La Rosa, Leilani H. Gilpin, Roberto Capobianco</li>
<li>for: 本研究旨在提出一种新的 neuron 行为预测方法，即 Clustered Compositional Explanations，以拓宽 neuron 活动谱的spectrum。</li>
<li>methods: 本研究使用 Compositional Explanations 方法，并将其与归一化和一种新的搜索算法结合，以便更好地预测 neuron 的行为。</li>
<li>results: 本研究通过分析不同谱activation的问题和提出了一些 desiderata 质量，以便评估不同算法返回的解释的有效性。<details>
<summary>Abstract</summary>
Compositional Explanations is a method for identifying logical formulas of concepts that approximate the neurons' behavior. However, these explanations are linked to the small spectrum of neuron activations (i.e., the highest ones) used to check the alignment, thus lacking completeness. In this paper, we propose a generalization, called Clustered Compositional Explanations, that combines Compositional Explanations with clustering and a novel search heuristic to approximate a broader spectrum of the neurons' behavior. We define and address the problems connected to the application of these methods to multiple ranges of activations, analyze the insights retrievable by using our algorithm, and propose desiderata qualities that can be used to study the explanations returned by different algorithms.
</details>
<details>
<summary>摘要</summary>
《 compositional explanations 是一种方法，用于identifying logical formulas of concepts that approximate the neurons' behavior。然而，这些解释与小谱activations（即用于检查alignment的最高一些）相关，因此缺乏完整性。在这篇论文中，我们提出了一种扩展，called Clustered Compositional Explanations，它将 Compositional Explanations 与 clustering 和一种新的搜索规则相结合，以approximate a broader spectrum of the neurons' behavior。我们定义并讨论了应用这些方法到多个范围的活动问题，分析了使用我们的算法可以获得的洞察，并提出了对不同算法返回的解释的希望质量。》Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="On-the-Fairness-ROAD-Robust-Optimization-for-Adversarial-Debiasing"><a href="#On-the-Fairness-ROAD-Robust-Optimization-for-Adversarial-Debiasing" class="headerlink" title="On the Fairness ROAD: Robust Optimization for Adversarial Debiasing"></a>On the Fairness ROAD: Robust Optimization for Adversarial Debiasing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18413">http://arxiv.org/abs/2310.18413</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fairmlresearch/road">https://github.com/fairmlresearch/road</a></li>
<li>paper_authors: Vincent Grari, Thibault Laugel, Tatsunori Hashimoto, Sylvain Lamprier, Marcin Detyniecki</li>
<li>for: 本研究旨在解决分布式公平性问题，保证预测结果在不同敏感组中具有地域性均衡。</li>
<li>methods: 我们提出了一种名为ROAD的新方法，基于分布式Robust优化（DRO）框架和公平对抗学习目标，通过一种实例级别的重量策略，优先级给可能存在地方不公平的输入。</li>
<li>results: 实验结果表明，ROAD方法可以在三个标准数据集上实现Pareto优化，即同时保证地域性均衡和全球公平性，并且在分布shift情况下提高公平性泛化性。<details>
<summary>Abstract</summary>
In the field of algorithmic fairness, significant attention has been put on group fairness criteria, such as Demographic Parity and Equalized Odds. Nevertheless, these objectives, measured as global averages, have raised concerns about persistent local disparities between sensitive groups. In this work, we address the problem of local fairness, which ensures that the predictor is unbiased not only in terms of expectations over the whole population, but also within any subregion of the feature space, unknown at training time. To enforce this objective, we introduce ROAD, a novel approach that leverages the Distributionally Robust Optimization (DRO) framework within a fair adversarial learning objective, where an adversary tries to infer the sensitive attribute from the predictions. Using an instance-level re-weighting strategy, ROAD is designed to prioritize inputs that are likely to be locally unfair, i.e. where the adversary faces the least difficulty in reconstructing the sensitive attribute. Numerical experiments demonstrate the effectiveness of our method: it achieves Pareto dominance with respect to local fairness and accuracy for a given global fairness level across three standard datasets, and also enhances fairness generalization under distribution shift.
</details>
<details>
<summary>摘要</summary>
在算法公平领域，大量关注集合公平标准，如人口学性别比和等值机会。然而，这些目标，作为总体平均值，已经引起了地方不均衡的持续问题。在这种情况下，我们解决了地方公平问题，以确保预测器在整个人口中不偏袋，而且在任何未知训练时间的子区域中也是不偏袋。为此，我们提出了ROAD，一种基于分布robust优化（DRO）框架的新方法，具有公平反对抗学习目标，其中一个反对手尝试从预测中推断敏感特征。通过实例级别的重量策略，ROAD可以优先级化可能存在地方不公平的输入，即反对手在推断敏感特征时面临最小的困难。 numerically experiment demontrates the effectiveness of our method：it achieves Pareto dominance with respect to local fairness and accuracy for a given global fairness level across three standard datasets, and also enhances fairness generalization under distribution shift.
</details></li>
</ul>
<hr>
<h2 id="Gen2Sim-Scaling-up-Robot-Learning-in-Simulation-with-Generative-Models"><a href="#Gen2Sim-Scaling-up-Robot-Learning-in-Simulation-with-Generative-Models" class="headerlink" title="Gen2Sim: Scaling up Robot Learning in Simulation with Generative Models"></a>Gen2Sim: Scaling up Robot Learning in Simulation with Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18308">http://arxiv.org/abs/2310.18308</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pushkal Katara, Zhou Xian, Katerina Fragkiadaki</li>
<li>for: 本研究旨在帮助基础学习的机器人抓取 manipulate的技能，以便在多种环境中学习和应用。</li>
<li>methods: 本研究使用大型生成模型来自动生成3D资产、任务描述、任务分解和奖励函数，从而减少人类的参与度。</li>
<li>results: 研究成功地学习了多种长期任务的策略，而非temporally decomposed reward function无法学习这些任务。 Gen2Sim提供了一种可行的方法来扩大和多样化 robot manipulation技能的学习，并且可以通过时间层次分解来探索RL中的行为发现。<details>
<summary>Abstract</summary>
Generalist robot manipulators need to learn a wide variety of manipulation skills across diverse environments. Current robot training pipelines rely on humans to provide kinesthetic demonstrations or to program simulation environments and to code up reward functions for reinforcement learning. Such human involvement is an important bottleneck towards scaling up robot learning across diverse tasks and environments. We propose Generation to Simulation (Gen2Sim), a method for scaling up robot skill learning in simulation by automating generation of 3D assets, task descriptions, task decompositions and reward functions using large pre-trained generative models of language and vision. We generate 3D assets for simulation by lifting open-world 2D object-centric images to 3D using image diffusion models and querying LLMs to determine plausible physics parameters. Given URDF files of generated and human-developed assets, we chain-of-thought prompt LLMs to map these to relevant task descriptions, temporal decompositions, and corresponding python reward functions for reinforcement learning. We show Gen2Sim succeeds in learning policies for diverse long horizon tasks, where reinforcement learning with non temporally decomposed reward functions fails. Gen2Sim provides a viable path for scaling up reinforcement learning for robot manipulators in simulation, both by diversifying and expanding task and environment development, and by facilitating the discovery of reinforcement-learned behaviors through temporal task decomposition in RL. Our work contributes hundreds of simulated assets, tasks and demonstrations, taking a step towards fully autonomous robotic manipulation skill acquisition in simulation.
</details>
<details>
<summary>摘要</summary>
通用 robot manipulator 需要学习多种 manipulate 技能在多种环境中。现有的 robot 训练管道依赖人类提供动能示例或编程 simulation 环境，并编程 reward 函数 для reinforcement learning。这种人类参与度是扩大 robot 学习的重要瓶颈。我们提出 Generation to Simulation（Gen2Sim）方法，用于扩大 robot 技能学习在 simulation 中。我们使用大型预训练的语言和视觉生成模型自动生成 3D 资产、任务描述、任务分解和 reward 函数。我们使用图像扩散模型将开放世界 2D 物体中的图像映射到 3D，并使用 LLMS 确定物理参数。给定 URDF 文件生成和人类开发的资产，我们使用链式思维 Prompt LLMs 将它们映射到相关的任务描述、时间分解和相应的 Python  reward 函数。我们证明 Gen2Sim 可以学习多种长期任务的策略，而 reinforcement learning 无法使用非时间分解的 reward 函数。Gen2Sim 为 robot manipulator 在 simulation 中的学习提供了一条可行的道路，不仅扩大和多样化任务和环境开发，还促进了通过时间分解在 RL 中发现执行 behaviors 的发现。我们的工作提供了数百个模拟资产、任务和示例，为完全自主 robotic manipulation 技能获得做出了一步进展。
</details></li>
</ul>
<hr>
<h2 id="A-Stability-Principle-for-Learning-under-Non-Stationarity"><a href="#A-Stability-Principle-for-Learning-under-Non-Stationarity" class="headerlink" title="A Stability Principle for Learning under Non-Stationarity"></a>A Stability Principle for Learning under Non-Stationarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18304">http://arxiv.org/abs/2310.18304</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chengpiao Huang, Kaizheng Wang</li>
<li>for: 这个研究旨在开发一个适应非站ARY环境的统计学学习框架。</li>
<li>methods: 这个方法利用稳定原则选择每个时间段的回顾窗口，以最大化历史数据的利用，并保持累累合错的总错误在接受随机错误的变化范围内。</li>
<li>results: 论述显示这个方法在不知道非站ARY的情况下也能够适应。 regret bound是最大化对应损失的最小化最大化对应损失，即logarithmic factor。研究中的两个新成果包括一个Function similarity度量和一个分 segmentation技术。<details>
<summary>Abstract</summary>
We develop a versatile framework for statistical learning in non-stationary environments. In each time period, our approach applies a stability principle to select a look-back window that maximizes the utilization of historical data while keeping the cumulative bias within an acceptable range relative to the stochastic error. Our theory showcases the adaptability of this approach to unknown non-stationarity. The regret bound is minimax optimal up to logarithmic factors when the population losses are strongly convex, or Lipschitz only. At the heart of our analysis lie two novel components: a measure of similarity between functions and a segmentation technique for dividing the non-stationary data sequence into quasi-stationary pieces.
</details>
<details>
<summary>摘要</summary>
我们开发了一个灵活的统计学学习框架，适用于不稳定的环境。每个时间间隔，我们的方法会选择一个稳定原则来选择最大化历史数据的利用，同时保持积累偏差在接受范围内的偏差。我们的理论表明这种方法在未知非站ARY情况下具有适应性。我们的 regret bound是最小化的最大化因子，当人口损失是强Converter或Lipschitz时。我们的分析中包括两个新的组成部分：一种函数相似度度量和非站ARY数据序列分割技术。
</details></li>
</ul>
<hr>
<h2 id="Socially-Cognizant-Robotics-for-a-Technology-Enhanced-Society"><a href="#Socially-Cognizant-Robotics-for-a-Technology-Enhanced-Society" class="headerlink" title="Socially Cognizant Robotics for a Technology Enhanced Society"></a>Socially Cognizant Robotics for a Technology Enhanced Society</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18303">http://arxiv.org/abs/2310.18303</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kristin J. Dana, Clinton Andrews, Kostas Bekris, Jacob Feldman, Matthew Stone, Pernille Hemmer, Aaron Mazzeo, Hal Salzman, Jingang Yi</li>
<li>for: 本研究旨在推动人类中心的机器人应用，并关注其影响的问题。</li>
<li>methods: 本研究提出了一种涉猛社会科学方法，将技术和社会科学方法相结合，以便在机器人行为中推动参与者参与和社会评估。</li>
<li>results: 研究发现，通过将人类中心的目标放在首位，可以开拓出许多新的研究视角和问题，以改善机器人与人类之间的交互，并对社会产生的影响。<details>
<summary>Abstract</summary>
Emerging applications of robotics, and concerns about their impact, require the research community to put human-centric objectives front-and-center. To meet this challenge, we advocate an interdisciplinary approach, socially cognizant robotics, which synthesizes technical and social science methods. We argue that this approach follows from the need to empower stakeholder participation (from synchronous human feedback to asynchronous societal assessment) in shaping AI-driven robot behavior at all levels, and leads to a range of novel research perspectives and problems both for improving robots' interactions with individuals and impacts on society. Drawing on these arguments, we develop best practices for socially cognizant robot design that balance traditional technology-based metrics (e.g. efficiency, precision and accuracy) with critically important, albeit challenging to measure, human and society-based metrics.
</details>
<details>
<summary>摘要</summary>
新兴应用场景和对其影响的担忧，需要研究社区将人类中心的目标置于首位。为解决这个挑战，我们支持跨学科的方法，社会认知机器人，它将技术和社会科学方法相结合。我们认为，这种方法来自参与者参与（从同步人类反馈到异步社会评估）在AI驱动机器人行为的形成中发挥作用，并导致了改善机器人与个人交互以及对社会的影响的新研究视角和问题。从这些理由，我们开发了社会认知机器人的最佳实践，权衡传统技术基础的指标（如效率、准确率）与人类和社会基础的指标，这些指标具有挑战性，但对于机器人的设计和应用至关重要。
</details></li>
</ul>
<hr>
<h2 id="Interactive-Motion-Planning-for-Autonomous-Vehicles-with-Joint-Optimization"><a href="#Interactive-Motion-Planning-for-Autonomous-Vehicles-with-Joint-Optimization" class="headerlink" title="Interactive Motion Planning for Autonomous Vehicles with Joint Optimization"></a>Interactive Motion Planning for Autonomous Vehicles with Joint Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18301">http://arxiv.org/abs/2310.18301</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxiao Chen, Sushant Veer, Peter Karkus, Marco Pavone</li>
<li>for:  This paper is written for planning safe motions for autonomous vehicles in highly interactive driving scenarios.</li>
<li>methods:  The paper uses deep-learning-based models for trajectory prediction and joint optimization with model predictive control (MPC) to leverage ego-conditioned prediction.</li>
<li>results:  The proposed Interactive Joint Planning (IJP) method significantly outperforms baselines in closed-loop simulation, demonstrating its effectiveness in providing safe and efficient motions for autonomous vehicles in interactive driving scenarios.Here’s the Chinese translation of the three points:</li>
<li>for: 这篇论文是为了规划自动驾驶车辆在高度互动的驾驶场景中安全的运动计划。</li>
<li>methods: 该论文使用深度学习基于模型来预测轨迹并与模型预测控制（MPC）结合进行联合优化，以利用egos conditioned预测。</li>
<li>results: 提出的互动联合规划（IJP）方法在关闭Loop simulation中显著超越基准值，demonstrating its effectiveness in providing safe and efficient motions for autonomous vehicles in interactive driving scenarios.<details>
<summary>Abstract</summary>
In highly interactive driving scenarios, the actions of one agent greatly influences those of its neighbors. Planning safe motions for autonomous vehicles in such interactive environments, therefore, requires reasoning about the impact of the ego's intended motion plan on nearby agents' behavior. Deep-learning-based models have recently achieved great success in trajectory prediction and many models in the literature allow for ego-conditioned prediction. However, leveraging ego-conditioned prediction remains challenging in downstream planning due to the complex nature of neural networks, limiting the planner structure to simple ones, e.g., sampling-based planner. Despite their ability to generate fine-grained high-quality motion plans, it is difficult for gradient-based planning algorithms, such as model predictive control (MPC), to leverage ego-conditioned prediction due to their iterative nature and need for gradient. We present Interactive Joint Planning (IJP) that bridges MPC with learned prediction models in a computationally scalable manner to provide us the best of both the worlds. In particular, IJP jointly optimizes over the behavior of the ego and the surrounding agents and leverages deep-learned prediction models as prediction priors that the join trajectory optimization tries to stay close to. Furthermore, by leveraging homotopy classes, our joint optimizer searches over diverse motion plans to avoid getting stuck at local minima. Closed-loop simulation result shows that IJP significantly outperforms the baselines that are either without joint optimization or running sampling-based planning.
</details>
<details>
<summary>摘要</summary>
在高度互动的驾驶场景中，一个agent的行为会深刻影响其周围的其他agent。因此，为自动驾驶车辆在这些互动环境中规划安全的动作计划，需要考虑ego的意图动作计划对周围agent的行为的影响。深度学习基于模型在轨迹预测方面刚果取得了很大成功，但是在下游规划中利用egoconditioned预测仍然具有挑战性，因为神经网络的复杂性限制了规划结构的选择，只能选择简单的采样基本预测器。尽管它们可以生成细腻高质量的动作计划，但是使用梯度计算法，如模型预测控制（MPC），利用egoconditioned预测却困难，因为它们的迭代性和需要梯度。我们提出了互动联合规划（IJP），它将MPC与学习预测模型在计算可扩展的方式联系起来，以获得最佳的世界。具体来说，IJP同时优化ego和周围agent的行为，并利用深度学习预测模型作为预测假设，Join trajectory optimization尝试保持近于预测。此外，通过Homotopy类，我们的联合优化器搜索到多种动作计划，以避免陷入地点附近的局部最佳解。关闭环境 simulate结果表明，IJP显著超过了不包含联合优化或运行采样基本预测的基eline。
</details></li>
</ul>
<hr>
<h2 id="Image-Clustering-Conditioned-on-Text-Criteria"><a href="#Image-Clustering-Conditioned-on-Text-Criteria" class="headerlink" title="Image Clustering Conditioned on Text Criteria"></a>Image Clustering Conditioned on Text Criteria</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18297">http://arxiv.org/abs/2310.18297</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sehyunkwon/ictc">https://github.com/sehyunkwon/ictc</a></li>
<li>paper_authors: Sehyun Kwon, Jaeseung Park, Minkyu Kim, Jaewoong Cho, Ernest K. Ryu, Kangwook Lee</li>
<li>for: 图像 clustering based on user-specified text criteria</li>
<li>methods: 利用现代视觉语言模型和大语言模型，实现图像 clustering Conditional on Text Criteria (IC$|$TC)</li>
<li>results: 在不同的基准下，IC$|$TC 可以有效地对图像进行分 clustering，并与基eline 相比显著提高表现。<details>
<summary>Abstract</summary>
Classical clustering methods do not provide users with direct control of the clustering results, and the clustering results may not be consistent with the relevant criterion that a user has in mind. In this work, we present a new methodology for performing image clustering based on user-specified text criteria by leveraging modern vision-language models and large language models. We call our method Image Clustering Conditioned on Text Criteria (IC$|$TC), and it represents a different paradigm of image clustering. IC$|$TC requires a minimal and practical degree of human intervention and grants the user significant control over the clustering results in return. Our experiments show that IC$|$TC can effectively cluster images with various criteria, such as human action, physical location, or the person's mood, while significantly outperforming baselines.
</details>
<details>
<summary>摘要</summary>
传统的帮助方法不提供用户直接控制帮助结果，并且帮助结果可能不符合用户有意思的标准。在这种工作中，我们介绍了一种新的图像帮助方法，基于用户指定的文本标准。我们称之为图像帮助 conditional on 文本标准（IC$|$TC），它代表了一种新的帮助方法 paradigm。IC$|$TC需要最小化和实用的人类干预，并为用户提供了较高的控制权，以换取更好的帮助结果。我们的实验表明，IC$|$TC可以有效地将图像分类到不同的标准，如人类动作、物理位置或人的情绪，而与基准值相比显著性能更高。
</details></li>
</ul>
<hr>
<h2 id="Moments-for-Perceptive-Narration-Analysis-Through-the-Emotional-Attachment-of-Audience-to-Discourse-and-Story"><a href="#Moments-for-Perceptive-Narration-Analysis-Through-the-Emotional-Attachment-of-Audience-to-Discourse-and-Story" class="headerlink" title="Moments for Perceptive Narration Analysis Through the Emotional Attachment of Audience to Discourse and Story"></a>Moments for Perceptive Narration Analysis Through the Emotional Attachment of Audience to Discourse and Story</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18273">http://arxiv.org/abs/2310.18273</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gary Bruins, Ergun Akleman</li>
<li>for: 这篇论文的目的是开发一个可以分析视觉故事的理论框架，从而更好地理解电影、漫画等视觉故事的效果。</li>
<li>methods: 这篇论文引入了一个新的故事元素called “moments”，并提出了一种方法来分解线性故事（如电影）into a set of moments。这些 moments 可以分为两类：Story moments 和 Discourse moments。每种类型的 moment 可以进一步分为三种类型的 universal storytelling moments，这些 moments 可以增强或削弱观众对角色或故事的情感附加。</li>
<li>results: 这篇论文提出了一种方法来目录各种 universal moments 的出现，并使用曲线或颜色带来可视化角色的旅程。此外， authors 还证明了 story moments 和 Discourse moments 都可以转化为一个总趋势参数，这个参数可以在时间轴上Plot 出观众对故事的情感附加情况。<details>
<summary>Abstract</summary>
In this work, our goal is to develop a theoretical framework that can eventually be used for analyzing the effectiveness of visual stories such as feature films to comic books. To develop this theoretical framework, we introduce a new story element called moments. Our conjecture is that any linear story such as the story of a feature film can be decomposed into a set of moments that follow each other. Moments are defined as the perception of the actions, interactions, and expressions of all characters or a single character during a given time period. We categorize the moments into two major types: story moments and discourse moments. Each type of moment can further be classified into three types, which we call universal storytelling moments. We believe these universal moments foster or deteriorate the emotional attachment of the audience to a particular character or the story. We present a methodology to catalog the occurrences of these universal moments as they are found in the story. The cataloged moments can be represented using curves or color strips. Therefore, we can visualize a character's journey through the story as either a 3D curve or a color strip. We also demonstrated that both story and discourse moments can be transformed into one lump-sum attraction parameter. The attraction parameter in time provides a function that can be plotted graphically onto a timeline illustrating changes in the emotional attachment of audience to a character or the story. By inspecting these functions the story analyst can analytically decipher the moments in the story where the attachment is being established, maintained, strengthened, or conversely where it is languishing.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们的目标是开发一个理论框架，以便分析视觉故事，从电影到漫画。为了实现这个目标，我们引入了一个新的故事元素，即“时刻”（moments）。我们的假设是，任何线性故事，例如电影的故事，都可以分解成一系列的时刻，这些时刻继承于一个时间段内的人物或单一人物的行动、互动和表达。我们将时刻分类为两大类：剧情时刻和对话时刻。每种时刻可以进一步分为三种通用故事创作时刻。我们认为这些通用时刻会使观众对特定人物或故事产生情感附加或减少。我们提出了一种方法来目录这些通用时刻的出现，并可以使用曲线或颜色带来表示人物的旅程。我们还证明了，剧情和对话时刻都可以转化为一个累积参数。这个参数在时间上提供了一个函数，可以在时间轴上Plot，并表示观众对人物或故事的情感附加或减少的变化。通过查看这些函数，故事分析人员可以分析故事中情感附加的时刻，以及将其建立、维护、强化或反之。
</details></li>
</ul>
<hr>
<h2 id="Learning-to-Search-Feasible-and-Infeasible-Regions-of-Routing-Problems-with-Flexible-Neural-k-Opt"><a href="#Learning-to-Search-Feasible-and-Infeasible-Regions-of-Routing-Problems-with-Flexible-Neural-k-Opt" class="headerlink" title="Learning to Search Feasible and Infeasible Regions of Routing Problems with Flexible Neural k-Opt"></a>Learning to Search Feasible and Infeasible Regions of Routing Problems with Flexible Neural k-Opt</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18264">http://arxiv.org/abs/2310.18264</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yining043/neuopt">https://github.com/yining043/neuopt</a></li>
<li>paper_authors: Yining Ma, Zhiguang Cao, Yeow Meng Chee</li>
<li>for: 本研究开展了一种基于学习搜索的路径规划算法NeuOpt，用于解决路径规划问题。</li>
<li>methods: NeuOpt使用了一种特定的动作因子化方法和一种自定义的循环双流解码器，以学习具有灵活k-选择的搜索策略。此外，paper还提出了一种引导不可能区域探索（GIRE）方案，以便更好地让搜索算法自主探索可行和不可行的区域。</li>
<li>results: 实验表明，NeuOpt在TSP和CVRP问题上显著超越了现有的面罩-based L2S算法，同时也超越了L2C和L2P算法。此外，paper还提供了一些新的思路来处理VRP约束。<details>
<summary>Abstract</summary>
In this paper, we present Neural k-Opt (NeuOpt), a novel learning-to-search (L2S) solver for routing problems. It learns to perform flexible k-opt exchanges based on a tailored action factorization method and a customized recurrent dual-stream decoder. As a pioneering work to circumvent the pure feasibility masking scheme and enable the autonomous exploration of both feasible and infeasible regions, we then propose the Guided Infeasible Region Exploration (GIRE) scheme, which supplements the NeuOpt policy network with feasibility-related features and leverages reward shaping to steer reinforcement learning more effectively. Additionally, we equip NeuOpt with Dynamic Data Augmentation (D2A) for more diverse searches during inference. Extensive experiments on the Traveling Salesman Problem (TSP) and Capacitated Vehicle Routing Problem (CVRP) demonstrate that our NeuOpt not only significantly outstrips existing (masking-based) L2S solvers, but also showcases superiority over the learning-to-construct (L2C) and learning-to-predict (L2P) solvers. Notably, we offer fresh perspectives on how neural solvers can handle VRP constraints. Our code is available: https://github.com/yining043/NeuOpt.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种名为Neural k-Opt（NeuOpt）的学习到搜索（L2S）算法，用于解决路径问题。它学习如何进行灵活的 k-opt 交换，基于一种适应性的动作因子化方法和一种自定义的循环双流解码器。作为一种突破约束 маскинг 方案的先锋性工作，我们然后提出了指导不可能区域探索（GIRE）方案，该方案在NeuOpt策略网络中添加了可行性相关特征，并通过奖励形成来更有效地驱动学习。此外，我们还为NeuOpt提供了动态数据扩充（D2A）以在推理中进行更多的搜索。我们在旅行商问题（TSP）和容量有限的交通问题（CVRP）进行了广泛的实验，结果表明，我们的NeuOpt不仅明显超越了现有的（masking-based）L2S算法，还超越了学习到构建（L2C）和学习到预测（L2P）算法。另外，我们还提供了一些新的视角，用于描述如何使用神经网络来处理 VRP 约束。我们的代码可以在 GitHub 上找到：https://github.com/yining043/NeuOpt。
</details></li>
</ul>
<hr>
<h2 id="A-Review-of-the-Evidence-for-Existential-Risk-from-AI-via-Misaligned-Power-Seeking"><a href="#A-Review-of-the-Evidence-for-Existential-Risk-from-AI-via-Misaligned-Power-Seeking" class="headerlink" title="A Review of the Evidence for Existential Risk from AI via Misaligned Power-Seeking"></a>A Review of the Evidence for Existential Risk from AI via Misaligned Power-Seeking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18244">http://arxiv.org/abs/2310.18244</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rose Hadshar</li>
<li>for: 该论文探讨了人工智能（AI）可能对人类 pose existential risks 的证据，具体来说是通过偏向和权力寻求。</li>
<li>methods: 该论文对偏向和权力寻求的证据进行了评估，包括实证证据、概念性证据和专家意见。</li>
<li>results: 论文发现，虽然目前没有公开的实证例子表明 AI 系统会发展出偏向和权力寻求，但是理论上的证据和实验证据表明这种风险存在。因此，无法 completly 排除 AI via 偏向和权力寻求对人类 pose existential risks 的可能性。<details>
<summary>Abstract</summary>
Rapid advancements in artificial intelligence (AI) have sparked growing concerns among experts, policymakers, and world leaders regarding the potential for increasingly advanced AI systems to pose existential risks. This paper reviews the evidence for existential risks from AI via misalignment, where AI systems develop goals misaligned with human values, and power-seeking, where misaligned AIs actively seek power. The review examines empirical findings, conceptual arguments and expert opinion relating to specification gaming, goal misgeneralization, and power-seeking. The current state of the evidence is found to be concerning but inconclusive regarding the existence of extreme forms of misaligned power-seeking. Strong empirical evidence of specification gaming combined with strong conceptual evidence for power-seeking make it difficult to dismiss the possibility of existential risk from misaligned power-seeking. On the other hand, to date there are no public empirical examples of misaligned power-seeking in AI systems, and so arguments that future systems will pose an existential risk remain somewhat speculative. Given the current state of the evidence, it is hard to be extremely confident either that misaligned power-seeking poses a large existential risk, or that it poses no existential risk. The fact that we cannot confidently rule out existential risk from AI via misaligned power-seeking is cause for serious concern.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）的快速发展已引发了专家、政策制定者和世界领袖对AI系统可能对人类存在潜在的极大风险的担忧。这篇评论文章检查了AI系统发展不同目标的证据，包括 specification gaming、目标扩展和权力寻求。审查的证据表明，虽然目前没有公共的实证例子，但概念上的证据强，表明AI系统可能会发展出不同于人类价值观的目标。此外，由于目前的证据状况，无法绝对排除AI系统可能对人类存在极大风险的可能性。因此，我们应该对这一点表示严重关注。
</details></li>
</ul>
<hr>
<h2 id="Fine-Tuning-Language-Models-Using-Formal-Methods-Feedback"><a href="#Fine-Tuning-Language-Models-Using-Formal-Methods-Feedback" class="headerlink" title="Fine-Tuning Language Models Using Formal Methods Feedback"></a>Fine-Tuning Language Models Using Formal Methods Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18239">http://arxiv.org/abs/2310.18239</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yunhao Yang, Neel P. Bhatt, Tyler Ingebrand, William Ward, Steven Carr, Zhangyang Wang, Ufuk Topcu</li>
<li>for: 这个论文旨在提高预训练语言模型的应用在自动控制领域，使其能够更好地满足具体任务的需求。</li>
<li>methods: 这篇论文提出了一种完全自动的 fine-tuning 方法，通过自然语言任务描述 guideline 将预训练语言模型转换为具体任务的控制器，并通过世界模型来验证这些控制器的合liance。</li>
<li>results: 论文提供了多个自动驾驶任务的实验结果，表明该方法可以在不同的任务上提高预训练语言模型的性能，从60%提高到90%。<details>
<summary>Abstract</summary>
Although pre-trained language models encode generic knowledge beneficial for planning and control, they may fail to generate appropriate control policies for domain-specific tasks. Existing fine-tuning methods use human feedback to address this limitation, however, sourcing human feedback is labor intensive and costly. We present a fully automated approach to fine-tune pre-trained language models for applications in autonomous systems, bridging the gap between generic knowledge and domain-specific requirements while reducing cost. The method synthesizes automaton-based controllers from pre-trained models guided by natural language task descriptions. These controllers are verifiable against independently provided specifications within a world model, which can be abstract or obtained from a high-fidelity simulator. Controllers with high compliance with the desired specifications receive higher ranks, guiding the iterative fine-tuning process. We provide quantitative evidences, primarily in autonomous driving, to demonstrate the method's effectiveness across multiple tasks. The results indicate an improvement in percentage of specifications satisfied by the controller from 60% to 90%.
</details>
<details>
<summary>摘要</summary>
Our method uses natural language task descriptions to guide the synthesis of automaton-based controllers from pre-trained models. These controllers are verifiable against independently provided specifications within a world model, which can be abstract or obtained from a high-fidelity simulator. Controllers that comply with the desired specifications receive higher ranks, guiding the iterative fine-tuning process.We provide quantitative evidence, primarily in the field of autonomous driving, to demonstrate the effectiveness of our method. The results show an improvement in the percentage of specifications satisfied by the controller, from 60% to 90%.
</details></li>
</ul>
<hr>
<h2 id="Davidsonian-Scene-Graph-Improving-Reliability-in-Fine-grained-Evaluation-for-Text-to-Image-Generation"><a href="#Davidsonian-Scene-Graph-Improving-Reliability-in-Fine-grained-Evaluation-for-Text-to-Image-Generation" class="headerlink" title="Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-to-Image Generation"></a>Davidsonian Scene Graph: Improving Reliability in Fine-grained Evaluation for Text-to-Image Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18235">http://arxiv.org/abs/2310.18235</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jaemin Cho, Yushi Hu, Roopal Garg, Peter Anderson, Ranjay Krishna, Jason Baldridge, Mohit Bansal, Jordi Pont-Tuset, Su Wang<br>for: 这个论文的目的是evaluating text-to-image models的可靠性。methods: 这个论文使用了Question Generation and Answering（QG&#x2F;A）方法，通过使用预训练的基础模型生成提问和答案，然后根据提问生成的答案和图像是否一致来评估图像的可靠性。results: 这个论文通过提出和解决一些可靠性问题（如提问不应该包含幻像、重复或漏掉信息），并使用Davidsonian Scene Graph（DSG）评估框架来提高评估的可靠性。DSG使用图表来组织提问和答案，以确保提问的 semantic coverage 和答案的一致性。经过广泛的实验和人工评估，这个论文证明了DSG可以有效地解决这些问题。<details>
<summary>Abstract</summary>
Evaluating text-to-image models is notoriously difficult. A strong recent approach for assessing text-image faithfulness is based on QG/A (question generation and answering), which uses pre-trained foundational models to automatically generate a set of questions and answers from the prompt, and output images are scored based on whether these answers extracted with a visual question answering model are consistent with the prompt-based answers. This kind of evaluation is naturally dependent on the quality of the underlying QG and QA models. We identify and address several reliability challenges in existing QG/A work: (a) QG questions should respect the prompt (avoiding hallucinations, duplications, and omissions) and (b) VQA answers should be consistent (not asserting that there is no motorcycle in an image while also claiming the motorcycle is blue). We address these issues with Davidsonian Scene Graph (DSG), an empirically grounded evaluation framework inspired by formal semantics. DSG is an automatic, graph-based QG/A that is modularly implemented to be adaptable to any QG/A module. DSG produces atomic and unique questions organized in dependency graphs, which (i) ensure appropriate semantic coverage and (ii) sidestep inconsistent answers. With extensive experimentation and human evaluation on a range of model configurations (LLM, VQA, and T2I), we empirically demonstrate that DSG addresses the challenges noted above. Finally, we present DSG-1k, an open-sourced evaluation benchmark that includes 1,060 prompts, covering a wide range of fine-grained semantic categories with a balanced distribution. We release the DSG-1k prompts and the corresponding DSG questions.
</details>
<details>
<summary>摘要</summary>
评估文本到图像模型是非常困难的。一种强大的最近的方法是基于QG/A（问题生成和回答），它使用预训练的基础模型自动生成了一组问题和答案从提示中，然后根据图像输出的答案是否与提示基础答案一致来评分。这种评估方法自然地受到基础QG和QA模型的质量的影响。我们 indentify和解决了现有QG/A工作中的一些可靠性挑战：（a）QG问题应该遵循提示（避免幻象、重复和漏掉），（b）VQA答案应该一致（不能声称图像中没有摩托车而同时声称摩托车是蓝色）。我们使用戴维森景图（DSG）来解决这些问题，DSG是基于形式 semantics的实际训练的评估框架。DSG自动生成了原子和唯一的问题，组织成依赖图，以确保适当的semantic Coverage并且 circumvent不一致的答案。通过广泛的实验和人工评估，我们证明了DSG可以解决上述挑战。最后，我们提供了DSG-1k，一个开源的评估标准 benchmark，包括1,060个提示，覆盖了各种细化的semantic类别，并且具有良好的分布。我们发布了DSG-1k提示和相应的DSG问题。
</details></li>
</ul>
<hr>
<h2 id="Alignment-and-Outer-Shell-Isotropy-for-Hyperbolic-Graph-Contrastive-Learning"><a href="#Alignment-and-Outer-Shell-Isotropy-for-Hyperbolic-Graph-Contrastive-Learning" class="headerlink" title="Alignment and Outer Shell Isotropy for Hyperbolic Graph Contrastive Learning"></a>Alignment and Outer Shell Isotropy for Hyperbolic Graph Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18209">http://arxiv.org/abs/2310.18209</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifei Zhang, Hao Zhu, Jiahong Liu, Piotr Koniusz, Irwin King</li>
<li>for: 学习高质量自主图表示，以便下游任务的改进。</li>
<li>methods: 提出了一种新的对偶学习框架，包括设计了有效地捕捉层次数据不变信息的对齐度量，以及提出了一种取代均匀度量来避免维度塌降问题。</li>
<li>results: 在不同的гипербо利图表示技术上，通过自动匹配度量和均匀度量来学习高质量图表示，并在supervised和自主学习设置下实现了较高的效果。<details>
<summary>Abstract</summary>
Learning good self-supervised graph representations that are beneficial to downstream tasks is challenging. Among a variety of methods, contrastive learning enjoys competitive performance. The embeddings of contrastive learning are arranged on a hypersphere that enables the Cosine distance measurement in the Euclidean space. However, the underlying structure of many domains such as graphs exhibits highly non-Euclidean latent geometry. To this end, we propose a novel contrastive learning framework to learn high-quality graph embedding. Specifically, we design the alignment metric that effectively captures the hierarchical data-invariant information, as well as we propose a substitute of uniformity metric to prevent the so-called dimensional collapse. We show that in the hyperbolic space one has to address the leaf- and height-level uniformity which are related to properties of trees, whereas in the ambient space of the hyperbolic manifold, these notions translate into imposing an isotropic ring density towards boundaries of Poincar\'e ball. This ring density can be easily imposed by promoting the isotropic feature distribution on the tangent space of manifold. In the experiments, we demonstrate the efficacy of our proposed method across different hyperbolic graph embedding techniques in both supervised and self-supervised learning settings.
</details>
<details>
<summary>摘要</summary>
学习良好的自我超VIewgraph representation是挑战性较高的。contrastive learning方法在这些方法中具有竞争性的表现。contrastive learning的嵌入是在一个径向体上安排的，这使得在欧几何空间中可以使用cosine距离测量。然而，许多领域的下游任务中的数据结构具有非欧几何的隐藏几何结构。为此，我们提出了一种新的对比学习框架，以学习高质量的图像嵌入。具体来说，我们设计了一个对应度度量，可以有效地捕捉层次数据不变信息，同时我们也提出了一种取代均匀度量来避免叫做dimensional collapse。我们发现在拓扑空间中，需要 Addressing leaf-和height-level uniformity，这与树的性质有关。而在拓扑空间中的 ambient space 中，这些概念转化为在Poincaré球的边界上强制实施一个均匀环绕径。这个环绕径可以通过推动拓扑空间的 tangent space 上的均匀特征分布来实现。在实验中，我们证明了我们提出的方法在不同的拓扑空间中的几何图像嵌入技术中具有效果，并在自我超VIewgraph embedding中和supervised learning中进行了证明。
</details></li>
</ul>
<hr>
<h2 id="Is-Scaling-Learned-Optimizers-Worth-It-Evaluating-The-Value-of-VeLO’s-4000-TPU-Months"><a href="#Is-Scaling-Learned-Optimizers-Worth-It-Evaluating-The-Value-of-VeLO’s-4000-TPU-Months" class="headerlink" title="Is Scaling Learned Optimizers Worth It? Evaluating The Value of VeLO’s 4000 TPU Months"></a>Is Scaling Learned Optimizers Worth It? Evaluating The Value of VeLO’s 4000 TPU Months</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18191">http://arxiv.org/abs/2310.18191</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fady Rezk, Antreas Antoniou, Henry Gouk, Timothy Hospedales</li>
<li>for: 本研究是用来训练一个通用的”基础”优化器的最大规模尝试。</li>
<li>methods: 本研究使用了 thousands of 机器学习任务和 over 4000 TPU 月份，以 Produce 一个可以泛化到新问题的优化器，并且不需要 гиперparameters 的调整。</li>
<li>results: 我们发现，与初始声明不符的结论：（1） VeLO 有一个关键的 гиперparameters 需要具体问题的调整，（2） VeLO 并不一定可以在解决质量上超越竞争对手，（3） VeLO 不一定比竞争优化器更快地降低训练损失。这些观察结论质疑 VeLO 的通用性和投资训练它的价值。<details>
<summary>Abstract</summary>
We analyze VeLO (versatile learned optimizer), the largest scale attempt to train a general purpose "foundational" optimizer to date. VeLO was trained on thousands of machine learning tasks using over 4000 TPU months with the goal of producing an optimizer capable of generalizing to new problems while being hyperparameter free, and outperforming industry standards such as Adam. We independently evaluate VeLO on the MLCommons optimizer benchmark suite. We find that, contrary to initial claims: (1) VeLO has a critical hyperparameter that needs problem-specific tuning, (2) VeLO does not necessarily outperform competitors in quality of solution found, and (3) VeLO is not faster than competing optimizers at reducing the training loss. These observations call into question VeLO's generality and the value of the investment in training it.
</details>
<details>
<summary>摘要</summary>
我们分析了VeLO（多功能学习优化器），目前最大规模的尝试是用多种机器学习任务来训练一个通用的“基础”优化器。VeLO在多达4000个TPU月的训练时间和4000个机器学习任务上被训练，以产生一个能够泛化到新问题的优化器，并且不需要任何hyperparameter。我们独立评估了VeLO在MLCommons优化器benchmark集合中的性能。我们发现：1. VeLO有一个关键的hyperparameter需要问题特定的调整。2. VeLO不一定能够超越竞争对手在解决问题的质量上。3. VeLO不一定比竞争对手快速地减少训练损失。这些观察结果质疑了VeLO的通用性和投资训练它的价值。
</details></li>
</ul>
<hr>
<h2 id="Personas-as-a-Way-to-Model-Truthfulness-in-Language-Models"><a href="#Personas-as-a-Way-to-Model-Truthfulness-in-Language-Models" class="headerlink" title="Personas as a Way to Model Truthfulness in Language Models"></a>Personas as a Way to Model Truthfulness in Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18168">http://arxiv.org/abs/2310.18168</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nitish Joshi, Javier Rando, Abulhair Saparov, Najoung Kim, He He</li>
<li>for: This paper explores the ability of large language models to discern truth from falsehood in contradictory data.</li>
<li>methods: The authors hypothesize that language models can cluster truthful text by modeling a truthful persona, which is a group of agents that are likely to produce truthful text and share similar features. They use arithmetics as a synthetic environment to test this hypothesis.</li>
<li>results: The authors find that language models can separate true and false statements, and generalize truthfulness across agents, but only if the agents in the training data share a truthful generative process that enables the creation of a truthful persona. This suggests that models can exploit hierarchical structures in the data to learn abstract concepts like truthfulness.<details>
<summary>Abstract</summary>
Large Language Models are trained on vast amounts of text from the internet, which contains both factual and misleading information about the world. Can language models discern truth from falsehood in this contradicting data? Expanding on the view that LLMs can model different agents producing the corpora, we hypothesize that they can cluster truthful text by modeling a truthful persona: a group of agents that are likely to produce truthful text and share similar features. For example, trustworthy sources like Wikipedia and Science usually use formal writing styles and make consistent claims. By modeling this persona, LLMs can generalize truthfulness beyond the specific contexts in which each agent generated the training text. For example, the model can infer that the agent "Wikipedia" will behave truthfully on topics that were only generated by "Science" because they share a persona. We first show evidence for the persona hypothesis via two observations: (1) we can probe whether a model's answer will be truthful before it is generated; (2) finetuning a model on a set of facts improves its truthfulness on unseen topics. Next, using arithmetics as a synthetic environment, we show that language models can separate true and false statements, and generalize truthfulness across agents; but only if agents in the training data share a truthful generative process that enables the creation of a truthful persona. Overall, our findings suggest that models can exploit hierarchical structures in the data to learn abstract concepts like truthfulness.
</details>
<details>
<summary>摘要</summary>
我们的实验证明了这个人格假设，通过以下两个观察：（1）我们可以在模型生成答案之前检查其是否为真实的；（2）在训练集中对一些事实进行调整，可以提高模型对未见过的主题上的真实性。接下来，我们使用数学为Synthetic环境，证明语言模型可以分辨真实和假的声明，并将真实性扩展到不同的代理人。但是，只有在训练资料中的代理人具有真实生成过程，才能够创建一个真实的人格。总的来说，我们的发现表明了模型可以运用数据的层次结构，学习抽象概念如真实性。
</details></li>
</ul>
<hr>
<h2 id="Improving-Intrinsic-Exploration-by-Creating-Stationary-Objectives"><a href="#Improving-Intrinsic-Exploration-by-Creating-Stationary-Objectives" class="headerlink" title="Improving Intrinsic Exploration by Creating Stationary Objectives"></a>Improving Intrinsic Exploration by Creating Stationary Objectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18144">http://arxiv.org/abs/2310.18144</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roger Creus Castanyer, Joshua Romoff, Glen Berseth</li>
<li>for: 提高 Agent 在探索问题中的性能，特别是在稀缺奖励 Task 和高维 Observation 等难题上。</li>
<li>methods: 利用 Count-based 方法 derivate 探索奖励，并通过 Stationary Objectives For Exploration (SOFE) 框架将原始非站点奖励转化为站点奖励，以便更好地优化 Agent 的目标。</li>
<li>results: 在多种探索问题中，包括稀缺奖励 Task、像素基 Observation、3D 导航和生成的环境等，SOFE 能够提高 Agent 的性能。<details>
<summary>Abstract</summary>
Exploration bonuses in reinforcement learning guide long-horizon exploration by defining custom intrinsic objectives. Count-based methods use the frequency of state visits to derive an exploration bonus. In this paper, we identify that any intrinsic reward function derived from count-based methods is non-stationary and hence induces a difficult objective to optimize for the agent. The key contribution of our work lies in transforming the original non-stationary rewards into stationary rewards through an augmented state representation. For this purpose, we introduce the Stationary Objectives For Exploration (SOFE) framework. SOFE requires identifying sufficient statistics for different exploration bonuses and finding an efficient encoding of these statistics to use as input to a deep network. SOFE is based on proposing state augmentations that expand the state space but hold the promise of simplifying the optimization of the agent's objective. Our experiments show that SOFE improves the agents' performance in challenging exploration problems, including sparse-reward tasks, pixel-based observations, 3D navigation, and procedurally generated environments.
</details>
<details>
<summary>摘要</summary>
文本翻译为简化中文：探索奖励在强化学习中引导长期探索，定义自定义内在目标。计数基本方法使用状态访问频率 derive 探索奖励。我们发现，任何基于计数基本方法 derive 的内在奖励都是非站ARY的，因此难以优化代理人的目标。我们的工作关键在于将原始非站ARY奖励转化为站ARY奖励，通过增强状态表示来实现。为此，我们提出了站ARY目标 для探索 (SOFE) 框架。SOFE需要确定不同探索奖励的 suffiSing statistic 和有效地编码这些统计作为深度网络的输入。SOFE基于提出状态扩展，既可以扩大状态空间，又可以简化代理人的目标优化。我们的实验表明，SOFE在复杂探索问题中提高了代理人的表现，包括罕见奖励任务、像素基本观察、3D导航和生成环境。</SYS>Note: The translation is in Simplified Chinese, which is the standard Chinese writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format instead.
</details></li>
</ul>
<hr>
<h2 id="Ask-more-know-better-Reinforce-Learned-Prompt-Questions-for-Decision-Making-with-Large-Language-Models"><a href="#Ask-more-know-better-Reinforce-Learned-Prompt-Questions-for-Decision-Making-with-Large-Language-Models" class="headerlink" title="Ask more, know better: Reinforce-Learned Prompt Questions for Decision Making with Large Language Models"></a>Ask more, know better: Reinforce-Learned Prompt Questions for Decision Making with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18127">http://arxiv.org/abs/2310.18127</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xue Yan, Yan Song, Xinyu Cui, Filippos Christianos, Haifeng Zhang, David Henry Mguni, Jun Wang</li>
<li>for: This paper aims to develop a fully integrated end-to-end framework for task-solving in real settings using complicated reasoning.</li>
<li>methods: The proposed leader-follower bilevel framework learns to ask relevant questions (prompts) and undertake reasoning to guide the learning of actions to be performed in an environment. The system uses a prompt-generator policy and an action policy to adapt to the CoT process and take decisive, high-performing actions.</li>
<li>results: The empirical data shows that the proposed system outperforms leading methods in agent learning benchmarks such as Overcooked and FourRoom.<details>
<summary>Abstract</summary>
Large language models (LLMs) demonstrate their promise in tackling complicated practical challenges by combining action-based policies with chain of thought (CoT) reasoning. Having high-quality prompts on hand, however, is vital to the framework's effectiveness. Currently, these prompts are handcrafted utilizing extensive human labor, resulting in CoT policies that frequently fail to generalize. Human intervention is also required in order to develop grounding functions that ensure low-level controllers appropriately process CoT reasoning. In this paper, we take the first step towards a fully integrated end-to-end framework for task-solving in real settings employing complicated reasoning. To that purpose, we offer a new leader-follower bilevel framework capable of learning to ask relevant questions (prompts) and subsequently undertaking reasoning to guide the learning of actions to be performed in an environment. A good prompt should make introspective revisions based on historical findings, leading the CoT to consider the anticipated goals. A prompt-generator policy has its own aim in our system, allowing it to adapt to the action policy and automatically root the CoT process towards outputs that lead to decisive, high-performing actions. Meanwhile, the action policy is learning how to use the CoT outputs to take specific actions. Our empirical data reveal that our system outperforms leading methods in agent learning benchmarks such as Overcooked and FourRoom.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在解决实际挑战中展示了其应用潜力，通过结合动作政策和链接思维（CoT）理解。然而，高质量提示是框架的重要 componenet，并且通常需要人工干预以开发基础函数，以确保低层控制器正确处理CoT理解。在这篇论文中，我们将实现完整的终端到终端框架，用于实际设置中的任务解决。为此，我们提出了一个新的领导者-追随者二级框架，能够学习问题（提示）和随后进行理解，以导引行为学习。一个好的提示应该根据历史发现进行 introspective 修订，导引CoT考虑预期目标。在我们的系统中，提示策略有自己的目标，让它适应行为策略，并自动将CoT过程导向出力，以确保高效、决策性的动作。同时，动作策略在使用CoT出力进行特定动作。我们的实验数据显示，我们的系统在代理学习测试 benchmark 中表现出色，比如 Overcooked 和 FourRoom。
</details></li>
</ul>
<hr>
<h2 id="OpinSummEval-Revisiting-Automated-Evaluation-for-Opinion-Summarization"><a href="#OpinSummEval-Revisiting-Automated-Evaluation-for-Opinion-Summarization" class="headerlink" title="OpinSummEval: Revisiting Automated Evaluation for Opinion Summarization"></a>OpinSummEval: Revisiting Automated Evaluation for Opinion Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18122">http://arxiv.org/abs/2310.18122</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/a-chicharito-s/opinsummeval">https://github.com/a-chicharito-s/opinsummeval</a></li>
<li>paper_authors: Yuchen Shen, Xiaojun Wan</li>
<li>for: This paper focuses on the evaluation of opinion summarization models, specifically exploring the correlation between automatic metrics and human ratings.</li>
<li>methods: The paper uses a dataset called OpinSummEval, which includes human judgments and outputs from 14 opinion summarization models. The authors explore the correlation between 24 automatic metrics and human ratings across four dimensions.</li>
<li>results: The authors find that metrics based on neural networks generally outperform non-neural ones, but even the best-performing metrics do not consistently correlate well across all dimensions. This highlights the need for advancements in automated evaluation methods for opinion summarization.<details>
<summary>Abstract</summary>
Opinion summarization sets itself apart from other types of summarization tasks due to its distinctive focus on aspects and sentiments. Although certain automated evaluation methods like ROUGE have gained popularity, we have found them to be unreliable measures for assessing the quality of opinion summaries. In this paper, we present OpinSummEval, a dataset comprising human judgments and outputs from 14 opinion summarization models. We further explore the correlation between 24 automatic metrics and human ratings across four dimensions. Our findings indicate that metrics based on neural networks generally outperform non-neural ones. However, even metrics built on powerful backbones, such as BART and GPT-3/3.5, do not consistently correlate well across all dimensions, highlighting the need for advancements in automated evaluation methods for opinion summarization. The code and data are publicly available at https://github.com/A-Chicharito-S/OpinSummEval/tree/main.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Towards-a-Unified-Conversational-Recommendation-System-Multi-task-Learning-via-Contextualized-Knowledge-Distillation"><a href="#Towards-a-Unified-Conversational-Recommendation-System-Multi-task-Learning-via-Contextualized-Knowledge-Distillation" class="headerlink" title="Towards a Unified Conversational Recommendation System: Multi-task Learning via Contextualized Knowledge Distillation"></a>Towards a Unified Conversational Recommendation System: Multi-task Learning via Contextualized Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18119">http://arxiv.org/abs/2310.18119</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yeongseo Jung, Eunseo Jung, Lei Chen</li>
<li>for: 提高对话式推荐系统（CRS）的个性化推荐和对话能力。</li>
<li>methods: 提出了一种基于Contextualized Knowledge Distillation（ConKD）的多任务学习方法，将对话推荐和对话模块结合到一起，以提高推荐性和对话流畅性。</li>
<li>results: 实验表明，我们的单个模型可以显著提高推荐性，同时保持对话流畅性，并与多任务学习方法相比，实现了相似的多样性表现。<details>
<summary>Abstract</summary>
In Conversational Recommendation System (CRS), an agent is asked to recommend a set of items to users within natural language conversations. To address the need for both conversational capability and personalized recommendations, prior works have utilized separate recommendation and dialogue modules. However, such approach inevitably results in a discrepancy between recommendation results and generated responses. To bridge the gap, we propose a multi-task learning for a unified CRS, where a single model jointly learns both tasks via Contextualized Knowledge Distillation (ConKD). We introduce two versions of ConKD: hard gate and soft gate. The former selectively gates between two task-specific teachers, while the latter integrates knowledge from both teachers. Our gates are computed on-the-fly in a context-specific manner, facilitating flexible integration of relevant knowledge. Extensive experiments demonstrate that our single model significantly improves recommendation performance while enhancing fluency, and achieves comparable results in terms of diversity.
</details>
<details>
<summary>摘要</summary>
在协作推荐系统（CRS）中，一个代理被要求在自然语言交流中推荐一组ITEMS给用户。为了解决个性化推荐和对话能力的需求，先前的工作通常使用了分开的推荐和对话模块。然而，这种方法无法快速bridging these two tasks的差异，导致推荐结果与生成的响应之间存在差异。为了bridge这个差异，我们提出了一种多任务学习的统一CRS，其中一个模型同时学习了两个任务 via Contextualized Knowledge Distillation（ConKD）。我们引入了两种ConKD版本：hard gate和soft gate。前者在两个任务特定的教师之间选择性地阻断，而后者将两个教师的知识集成在一起。我们的门控在上下文具体的计算，使得可以在不同的上下文中灵活地集成相关的知识。我们的实验表明，我们的单一模型可以大幅提高推荐性能，同时提高流畅性，并与多任务学习模型相比，在多样性方面实现相似的结果。
</details></li>
</ul>
<hr>
<h2 id="er-autopilot-1-0-The-Full-Autonomous-Stack-for-Oval-Racing-at-High-Speeds"><a href="#er-autopilot-1-0-The-Full-Autonomous-Stack-for-Oval-Racing-at-High-Speeds" class="headerlink" title="er.autopilot 1.0: The Full Autonomous Stack for Oval Racing at High Speeds"></a>er.autopilot 1.0: The Full Autonomous Stack for Oval Racing at High Speeds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18112">http://arxiv.org/abs/2310.18112</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ayoub Raji, Danilo Caporale, Francesco Gatti, Andrea Giove, Micaela Verucchi, Davide Malatesta, Nicola Musiu, Alessandro Toschi, Silviu Roberto Popitanu, Fabio Bagni, Massimiliano Bosi, Alexander Liniger, Marko Bertogna, Daniele Morra, Francesco Amerotti, Luca Bartoli, Federico Martello, Riccardo Porta</li>
<li>for: 本研究旨在提出一个独立开发的自主车辆软件架构，并在赛车赛道上进行了实验验证。</li>
<li>methods: 本研究使用了独立开发的自主车辆软件，包括了适应障碍物、主动超越和速度控制等模组。</li>
<li>results: 本研究在首两场赛事中获得了第二和第三名的成绩，并提供了各模组的实验结果和所学。<details>
<summary>Abstract</summary>
The Indy Autonomous Challenge (IAC) brought together for the first time in history nine autonomous racing teams competing at unprecedented speed and in head-to-head scenario, using independently developed software on open-wheel racecars. This paper presents the complete software architecture used by team TII EuroRacing (TII-ER), covering all the modules needed to avoid static obstacles, perform active overtakes and reach speeds above 75 m/s (270 km/h). In addition to the most common modules related to perception, planning, and control, we discuss the approaches used for vehicle dynamics modelling, simulation, telemetry, and safety. Overall results and the performance of each module are described, as well as the lessons learned during the first two events of the competition on oval tracks, where the team placed respectively second and third.
</details>
<details>
<summary>摘要</summary>
印第安那自主挑战（IAC）是历史上第一次将九支自主赛车队伍集结在一起，以前所未有的速度和头一头方式竞赛，使用独立开发的软件在开放式赛车上。本文介绍了TII EuroRacing（TII-ER）队伍所使用的完整软件架构，涵盖避免静止障碍物、实施活动超越和速度超过75米/秒（270公里/小时）等模块。此外，我们还讨论了车辆动力学模型、模拟、测验和安全方面的方法。文章结尾还提供了每个模块的性能和成绩，以及在oval赛道上的第一两场比赛中所学到的经验。
</details></li>
</ul>
<hr>
<h2 id="Detrimental-Contexts-in-Open-Domain-Question-Answering"><a href="#Detrimental-Contexts-in-Open-Domain-Question-Answering" class="headerlink" title="Detrimental Contexts in Open-Domain Question Answering"></a>Detrimental Contexts in Open-Domain Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18077">http://arxiv.org/abs/2310.18077</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xfactlab/emnlp2023-damaging-retrieval">https://github.com/xfactlab/emnlp2023-damaging-retrieval</a></li>
<li>paper_authors: Philhoon Oh, James Thorne</li>
<li>for: 本研究旨在探讨抓取大量信息对知识搜索模型的性能影响，并分析抓取大量信息对问答模型的影响。</li>
<li>methods: 本研究使用现有的抓取方法，不需要进一步的训练或数据。研究人员通过对抓取的文章进行筛选，以提高问答模型的性能。</li>
<li>results: 研究人员发现，使用抓取大量信息可以提高问答模型的准确率，但是使用整个文章可以导致模型的性能下降。通过筛选抓取的文章，可以提高模型的性能。<details>
<summary>Abstract</summary>
For knowledge intensive NLP tasks, it has been widely accepted that accessing more information is a contributing factor to improvements in the model's end-to-end performance. However, counter-intuitively, too much context can have a negative impact on the model when evaluated on common question answering (QA) datasets. In this paper, we analyze how passages can have a detrimental effect on retrieve-then-read architectures used in question answering. Our empirical evidence indicates that the current read architecture does not fully leverage the retrieved passages and significantly degrades its performance when using the whole passages compared to utilizing subsets of them. Our findings demonstrate that model accuracy can be improved by 10% on two popular QA datasets by filtering out detrimental passages. Additionally, these outcomes are attained by utilizing existing retrieval methods without further training or data. We further highlight the challenges associated with identifying the detrimental passages. First, even with the correct context, the model can make an incorrect prediction, posing a challenge in determining which passages are most influential. Second, evaluation typically considers lexical matching, which is not robust to variations of correct answers. Despite these limitations, our experimental results underscore the pivotal role of identifying and removing these detrimental passages for the context-efficient retrieve-then-read pipeline. Code and data are available at https://github.com/xfactlab/emnlp2023-damaging-retrieval
</details>
<details>
<summary>摘要</summary>
对知识密集的NLP任务，许多研究表明，更多的信息访问可以提高模型的综合性表现。然而，counter-intuitively，过度的背景信息可能会对模型在常见问答（QA）数据集上的性能产生负面影响。在这篇论文中，我们分析了如何段落可以对问答模型产生负面影响。我们的实验证据表明，当前的读取架构不能充分利用检索到的段落，并且将整个段落作为输入时，模型的性能会明显下降。我们的发现表明，可以通过过滤掉负面影响的段落来提高模型的准确率。此外，我们还高亮了确定负面影响的段落的挑战。首先，即使正确的上下文，模型可能会作出错误预测，困难判断哪些段落最有影响。其次，评估通常是基于字符匹配，这并不是对正确答案的变体具有坚定的鲁棒性。尽管如此，我们的实验结果表明，确定和移除负面影响的段落对Context-efficient检索-然后-读取管线是非常重要的。代码和数据可以在https://github.com/xfactlab/emnlp2023-damaging-retrieval中找到。
</details></li>
</ul>
<hr>
<h2 id="Knowledge-Corpus-Error-in-Question-Answering"><a href="#Knowledge-Corpus-Error-in-Question-Answering" class="headerlink" title="Knowledge Corpus Error in Question Answering"></a>Knowledge Corpus Error in Question Answering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18076">http://arxiv.org/abs/2310.18076</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xfactlab/emnlp2023-knowledge-corpus-error">https://github.com/xfactlab/emnlp2023-knowledge-corpus-error</a></li>
<li>paper_authors: Yejoon Lee, Philhoon Oh, James Thorne</li>
<li>for: This paper explores the effectiveness of generating context passages from large language models (LLMs) in open-domain question answering (QA), and investigates why generated passages may be more effective than retrieved ones.</li>
<li>methods: The paper introduces the concept of knowledge corpus error, which arises when the knowledge corpus used for retrieval is only a subset of the entire string space, and mitigates this shortcoming by generating passages in a larger space using LLMs. The paper also presents an experiment of paraphrasing human-annotated gold context using LLMs to observe knowledge corpus error empirically.</li>
<li>results: The results across three QA benchmarks show an increased performance (10% - 13%) when using paraphrased passage, indicating a signal for the existence of knowledge corpus error.Here is the information in Simplified Chinese text, as requested:</li>
<li>for: 这篇论文研究了开放领域问答（QA）中大语言模型（LLMs）生成上下文段的效果，以及为何生成的段更有效。</li>
<li>methods: 论文提出了知识库错误概念，即知识库用于搜索的字符串空间仅占整个字符串空间的子集，可能排除了更有帮助的段。论文使用大语言模型生成更大的字符串空间，以避免这种缺陷。</li>
<li>results: 结果表明，使用生成的段可以提高表现（10% - 13%），这表明知识库错误的存在。<details>
<summary>Abstract</summary>
Recent works in open-domain question answering (QA) have explored generating context passages from large language models (LLMs), replacing the traditional retrieval step in the QA pipeline. However, it is not well understood why generated passages can be more effective than retrieved ones. This study revisits the conventional formulation of QA and introduces the concept of knowledge corpus error. This error arises when the knowledge corpus used for retrieval is only a subset of the entire string space, potentially excluding more helpful passages that exist outside the corpus. LLMs may mitigate this shortcoming by generating passages in a larger space. We come up with an experiment of paraphrasing human-annotated gold context using LLMs to observe knowledge corpus error empirically. Our results across three QA benchmarks reveal an increased performance (10% - 13%) when using paraphrased passage, indicating a signal for the existence of knowledge corpus error. Our code is available at https://github.com/xfactlab/emnlp2023-knowledge-corpus-error
</details>
<details>
<summary>摘要</summary>
现有研究在开放领域问答（QA）中已经探索了从大语言模型（LLM）中生成上下文段落，取代传统的检索步骤在QA管道中。然而，不是很好地理解为何生成的段落比检索的更有效。本研究重新定义了传统的QA формулировка，并引入了知识库错误的概念。这种错误发生在用于检索的知识库只是字符串空间中的一个子集，可能排除了更有帮助的段落。LLM可能 mitigate这个缺点，因为它们可以生成段落在更大的空间中。我们设计了一个使用LLM来重新译human-annotated金标段落的实验，以观察知识库错误的实际情况。我们的结果在三个QA benchmark上显示，使用重新译段落时性能提高了10%-13%，这表明了知识库错误的存在。我们的代码可以在https://github.com/xfactlab/emnlp2023-knowledge-corpus-error中找到。
</details></li>
</ul>
<hr>
<h2 id="DUMA-a-Dual-Mind-Conversational-Agent-with-Fast-and-Slow-Thinking"><a href="#DUMA-a-Dual-Mind-Conversational-Agent-with-Fast-and-Slow-Thinking" class="headerlink" title="DUMA: a Dual-Mind Conversational Agent with Fast and Slow Thinking"></a>DUMA: a Dual-Mind Conversational Agent with Fast and Slow Thinking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18075">http://arxiv.org/abs/2310.18075</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyu Tian, Liangyu Chen, Na Liu, Yaxuan Liu, Wei Zou, Kaijiang Chen, Ming Cui</li>
<li>for: 这篇论文的目的是提出一个基于 dual-process theory 的 conversational agent 框架，以提高对问题的回答效率和质量。</li>
<li>methods: 这篇论文使用了两个生成型 Large Language Models (LLMs)，一个用于快速思考，另一个用于慢思考。快速思考模型负责外部互动和初步回答生成，根据问题的复杂程度进行评估是否需要启动慢思考模型。当启动时，慢思考模型会主导对话，进行细心的规划、推理和工具使用，以提供一个详细分析的回答。</li>
<li>results: 实验结果显示，我们的方法可以将效率和质量兼顾，与基准相比有很大的改善。<details>
<summary>Abstract</summary>
Inspired by the dual-process theory of human cognition, we introduce DUMA, a novel conversational agent framework that embodies a dual-mind mechanism through the utilization of two generative Large Language Models (LLMs) dedicated to fast and slow thinking respectively. The fast thinking model serves as the primary interface for external interactions and initial response generation, evaluating the necessity for engaging the slow thinking model based on the complexity of the complete response. When invoked, the slow thinking model takes over the conversation, engaging in meticulous planning, reasoning, and tool utilization to provide a well-analyzed response. This dual-mind configuration allows for a seamless transition between intuitive responses and deliberate problem-solving processes based on the situation. We have constructed a conversational agent to handle online inquiries in the real estate industry. The experiment proves that our method balances effectiveness and efficiency, and has a significant improvement compared to the baseline.
</details>
<details>
<summary>摘要</summary>
基于人类认知双进程理论，我们介绍DUMA conversational agent框架，该框架通过两个生成型大语言模型（LLM）来实现 быстро和慢思考的双 Mind 机制。快思模型作为外部交互的主要界面，评估问题的复杂性，并根据需要邀请慢思模型参与对话。当邀请时，慢思模型会承担对话，进行细致的规划、理智和工具使用，以提供优化的回答。这种双 Mind 配置允许在不同情况下协调Intuitive 回答和慎重的问题解决过程。我们在房地产领域的在线问题处理中构建了一个 conversational agent，实验证明我们的方法能够平衡效率和效果，与基准相比有显著改进。
</details></li>
</ul>
<hr>
<h2 id="Moral-Responsibility-for-AI-Systems"><a href="#Moral-Responsibility-for-AI-Systems" class="headerlink" title="Moral Responsibility for AI Systems"></a>Moral Responsibility for AI Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18040">http://arxiv.org/abs/2310.18040</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sander Beckers</li>
<li>for: 本文提出了一个定义AI系统的道德责任的方法，以便在AI系统做出具有道德意义的决策时能够定义道德责任。</li>
<li>methods: 本文使用 causal models 框架定义道德责任的两个条件：行动应该导致结果，并且agent应该意识到可能的道德后果。</li>
<li>results: 本文提出了一种度量道德责任的方法，并与现有的BvH和HK方法进行比较。<details>
<summary>Abstract</summary>
As more and more decisions that have a significant ethical dimension are being outsourced to AI systems, it is important to have a definition of moral responsibility that can be applied to AI systems. Moral responsibility for an outcome of an agent who performs some action is commonly taken to involve both a causal condition and an epistemic condition: the action should cause the outcome, and the agent should have been aware -- in some form or other -- of the possible moral consequences of their action. This paper presents a formal definition of both conditions within the framework of causal models. I compare my approach to the existing approaches of Braham and van Hees (BvH) and of Halpern and Kleiman-Weiner (HK). I then generalize my definition into a degree of responsibility.
</details>
<details>
<summary>摘要</summary>
随着更多的具有道德含义的决策被推到人工智能系统中，有必要为AI系统定义道德责任的定义。道德责任的出来由两个条件组成：行为应该导致结果，并且机器人应该知道（在某种形式下）可能的道德后果。这篇文章提出了一个正式的定义方法，并与布拉姆和海斯（BvH）和哈尔普尔和克莱曼-维纳（HK）的现有方法进行比较。然后，我将定义推广到责任度的一级。Here's the translation in Traditional Chinese:随着更多的具有道德含义的决策被推到人工智能系统中，有必要为AI系统定义道德责任的定义。道德责任的出来由两个条件组成：行为应该导致结果，并且机器人应该知道（在某种形式下）可能的道德后果。这篇文章提出了一个正式的定义方法，并与布拉姆和海斯（BvH）和哈尔普尔和克莱曼-维纳（HK）的现有方法进行比较。然后，我将定义推广到责任度的一级。
</details></li>
</ul>
<hr>
<h2 id="Large-language-models-for-aspect-based-sentiment-analysis"><a href="#Large-language-models-for-aspect-based-sentiment-analysis" class="headerlink" title="Large language models for aspect-based sentiment analysis"></a>Large language models for aspect-based sentiment analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18025">http://arxiv.org/abs/2310.18025</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qagentur/absa_llm">https://github.com/qagentur/absa_llm</a></li>
<li>paper_authors: Paul F. Simmering, Paavo Huoviala</li>
<li>for: The paper is written for assessing the performance of GPT-4 and GPT-3.5 in aspect-based sentiment analysis (ABSA) tasks, and exploring the cost-performance trade-offs of different models.</li>
<li>methods: The paper uses zero-shot, few-shot, and fine-tuned settings to evaluate the performance of GPT-4 and GPT-3.5 on the ABSA task, and compares their performance with InstructABSA [@scaria_instructabsa_2023].</li>
<li>results: The fine-tuned GPT-3.5 achieves a state-of-the-art F1 score of 83.8 on the joint aspect term extraction and polarity classification task, improving upon InstructABSA by 5.7%. However, the fine-tuned model has 1000 times more parameters and thus higher inference cost. The paper also finds that detailed prompts improve performance in zero-shot and few-shot settings but are not necessary for fine-tuned models.<details>
<summary>Abstract</summary>
Large language models (LLMs) offer unprecedented text completion capabilities. As general models, they can fulfill a wide range of roles, including those of more specialized models. We assess the performance of GPT-4 and GPT-3.5 in zero shot, few shot and fine-tuned settings on the aspect-based sentiment analysis (ABSA) task. Fine-tuned GPT-3.5 achieves a state-of-the-art F1 score of 83.8 on the joint aspect term extraction and polarity classification task of the SemEval-2014 Task 4, improving upon InstructABSA [@scaria_instructabsa_2023] by 5.7%. However, this comes at the price of 1000 times more model parameters and thus increased inference cost. We discuss the the cost-performance trade-offs of different models, and analyze the typical errors that they make. Our results also indicate that detailed prompts improve performance in zero-shot and few-shot settings but are not necessary for fine-tuned models. This evidence is relevant for practioners that are faced with the choice of prompt engineering versus fine-tuning when using LLMs for ABSA.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="OffMix-3L-A-Novel-Code-Mixed-Dataset-in-Bangla-English-Hindi-for-Offensive-Language-Identification"><a href="#OffMix-3L-A-Novel-Code-Mixed-Dataset-in-Bangla-English-Hindi-for-Offensive-Language-Identification" class="headerlink" title="OffMix-3L: A Novel Code-Mixed Dataset in Bangla-English-Hindi for Offensive Language Identification"></a>OffMix-3L: A Novel Code-Mixed Dataset in Bangla-English-Hindi for Offensive Language Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18387">http://arxiv.org/abs/2310.18387</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dhiman Goswami, Md Nishat Raihan, Antara Mahmud, Antonios Anstasopoulos, Marcos Zampieri</li>
<li>for: 本研究是为了开发一个新的三语混合语料库，用于识别攻击性语言。</li>
<li>methods: 本研究使用了多种模型进行实验，包括 transformer 基于模型和 GPT 3.5。</li>
<li>results: 研究发现，BanglishBERT 在这个三语混合语料库中表现出色，超过其他 transformer 基于模型的表现。<details>
<summary>Abstract</summary>
Code-mixing is a well-studied linguistic phenomenon when two or more languages are mixed in text or speech. Several works have been conducted on building datasets and performing downstream NLP tasks on code-mixed data. Although it is not uncommon to observe code-mixing of three or more languages, most available datasets in this domain contain code-mixed data from only two languages. In this paper, we introduce OffMix-3L, a novel offensive language identification dataset containing code-mixed data from three different languages. We experiment with several models on this dataset and observe that BanglishBERT outperforms other transformer-based models and GPT-3.5.
</details>
<details>
<summary>摘要</summary>
<SYS>Code-mixing 是一种已经广泛研究的语言现象，在文本或语音中混合两种或更多种语言。许多研究已经建立了 code-mixed 数据集并在这些数据集上进行了下游 NLP 任务。虽然三种语言混合并不是不常见的，但大多数可用的数据集都只包含了两种语言的 code-mixed 数据。在这篇论文中，我们介绍了 OffMix-3L，一个新的三种语言混合语言识别数据集。我们在这个数据集上试用了一些模型，并发现 BanglishBERT 超过了其他转换器基于模型和 GPT-3.5。</SYS>Here's the translation in Traditional Chinese:<SYS>Code-mixing 是一种已经广泛研究的语言现象，在文本或语音中混合两种或更多种语言。许多研究已经建立了 code-mixed 数据集并在这些数据集上进行了下游 NLP 任务。处于三种语言混合的情况下，大多数可用的数据集都只包含了两种语言的 code-mixed 数据。在这篇论文中，我们介绍了 OffMix-3L，一个新的三种语言混合语言识别数据集。我们在这个数据集上尝试了一些模型，并发现 BanglishBERT 超过了其他对应的 transformer 基于模型和 GPT-3.5。</SYS>
</details></li>
</ul>
<hr>
<h2 id="FormalGeo-The-First-Step-Toward-Human-like-IMO-level-Geometric-Automated-Reasoning"><a href="#FormalGeo-The-First-Step-Toward-Human-like-IMO-level-Geometric-Automated-Reasoning" class="headerlink" title="FormalGeo: The First Step Toward Human-like IMO-level Geometric Automated Reasoning"></a>FormalGeo: The First Step Toward Human-like IMO-level Geometric Automated Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18021">http://arxiv.org/abs/2310.18021</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaokai Zhang, Na Zhu, Yiming He, Jia Zou, Qike Huang, Xiaoxiao Jin, Yanjun Guo, Chenyang Mao, Zhe Zhu, Dengfeng Yue, Fangzhen Zhu, Yang Li, Yifan Wang, Yiwen Huang, Runan Wang, Cheng Qin, Zhenbing Zeng, Shaorong Xie, Xiangfeng Luo, Tuo Leng</li>
<li>for: 这个论文的目的是构建一个完整的 formally compatible 平面几何系统，以便将AI自动推理与IMO级别的平面几何挑战联系起来。</li>
<li>methods: 该论文使用了geometry formalization theory（GFT）指导建立了FormalGeo系统，包括88个几何 predicate 和 196个定理。它可以处理、验证和解决IMO级别的平面几何问题。此外，他们还实现了一个基于Python的Formal Geometry Problem Solver（FGPS），可以作为人工智能辅助验证问题解决过程，以及自动问题解决器，使用了forward search、backward search 和 AI-assisted search 等方法。</li>
<li>results: 实现了FormalGeo系统和FGPS实验，证明了GFT的正确性和实用性。使用backward depth-first search方法，解决问题失败率仅2.42%，并可以通过深度学习技术来降低这一值。<details>
<summary>Abstract</summary>
This is the first paper in a series of work we have accomplished over the past three years. In this paper, we have constructed a complete and compatible formal plane geometry system. This will serve as a crucial bridge between IMO-level plane geometry challenges and readable AI automated reasoning. With this formal system in place, we have been able to seamlessly integrate modern AI models with our formal system. Within this formal framework, AI is now capable of providing deductive reasoning solutions to IMO-level plane geometry problems, just like handling other natural languages, and these proofs are readable, traceable, and verifiable. We propose the geometry formalization theory (GFT) to guide the development of the geometry formal system. Based on the GFT, we have established the FormalGeo, which consists of 88 geometric predicates and 196 theorems. It can represent, validate, and solve IMO-level geometry problems. we also have crafted the FGPS (formal geometry problem solver) in Python. It serves as both an interactive assistant for verifying problem-solving processes and an automated problem solver, utilizing various methods such as forward search, backward search and AI-assisted search. We've annotated the FormalGeo7k dataset, containing 6,981 (expand to 186,832 through data augmentation) geometry problems with complete formal language annotations. Implementation of the formal system and experiments on the FormalGeo7k validate the correctness and utility of the GFT. The backward depth-first search method only yields a 2.42% problem-solving failure rate, and we can incorporate deep learning techniques to achieve lower one. The source code of FGPS and FormalGeo7k dataset are available at https://github.com/BitSecret/FormalGeo.
</details>
<details>
<summary>摘要</summary>
这是我们过去三年的一系列工作中的第一篇论文。在这篇论文中，我们构建了一个完整、兼容的正式平面几何系统。这将成为在IMO级平面几何挑战和可读的人工智能自动理解之间的关键桥梁。通过这个正式系统，我们可以将现代人工智能模型与我们的正式系统集成了。在这个正式框架下，人工智能现在可以提供平面几何问题的推理解决方案，就像处理其他自然语言一样，并且这些证明是可读、可追溯和可验证的。我们提出了几何ormal化理论（GFT），以引导正式几何系统的开发。基于GFT，我们建立了FormalGeo，它包含88个几何 predicate 和 196个定理。它可以表示、验证和解决IMO级平面几何问题。我们还制作了FGPS（正式几何问题解决器），它是一个在 Python 中实现的交互式助手和自动问题解决器，可以使用多种方法，如前向搜索、后向搜索和人工智能辅助搜索。我们对 FormaleGeo7k 数据集进行了注释，该数据集包含 6,981 个（通过数据扩充到 186,832）平面几何问题的完整正式语言注释。我们对正式系统的实现和 FormaleGeo7k 数据集的实验 validate 了正确性和实用性。使用回溯深度先搜索法只有2.42%的问题解决失败率，并且可以通过深度学习技术来降低这个数字。FGPS 和 FormaleGeo7k 数据集的源代码可以在 GitHub 上找到。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Enables-Large-Depth-of-Field-Images-for-Sub-Diffraction-Limit-Scanning-Superlens-Microscopy"><a href="#Deep-Learning-Enables-Large-Depth-of-Field-Images-for-Sub-Diffraction-Limit-Scanning-Superlens-Microscopy" class="headerlink" title="Deep Learning Enables Large Depth-of-Field Images for Sub-Diffraction-Limit Scanning Superlens Microscopy"></a>Deep Learning Enables Large Depth-of-Field Images for Sub-Diffraction-Limit Scanning Superlens Microscopy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17997">http://arxiv.org/abs/2310.17997</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui Sun, Hao Luo, Feifei Wang, Qingjiu Chen, Meng Chen, Xiaoduo Wang, Haibo Yu, Guanglie Zhang, Lianqing Liu, Jianping Wang, Dapeng Wu, Wen Jung Li</li>
<li>for: 这个论文的目的是提高扫描电子镜像（SEM）的分辨率和深度场景图像。</li>
<li>methods: 这个论文使用深度学习来建立扫描超分解（OSR）图像和SEM领域图像之间的映射关系，从而将OSR图像转换成SEM类型的大深度场景图像。</li>
<li>results: 比较PSNR和结构相似度指标值表示，深度学习方法在图像到图像翻译中表现出色，与光学超分解图像相比，PSNR提高约0.74dB。这种方法在检测晶圆缺陷、生物样本分析、审查和其他领域都具有广泛的应用前景。<details>
<summary>Abstract</summary>
Scanning electron microscopy (SEM) is indispensable in diverse applications ranging from microelectronics to food processing because it provides large depth-of-field images with a resolution beyond the optical diffraction limit. However, the technology requires coating conductive films on insulator samples and a vacuum environment. We use deep learning to obtain the mapping relationship between optical super-resolution (OSR) images and SEM domain images, which enables the transformation of OSR images into SEM-like large depth-of-field images. Our custom-built scanning superlens microscopy (SSUM) system, which requires neither coating samples by conductive films nor a vacuum environment, is used to acquire the OSR images with features down to ~80 nm. The peak signal-to-noise ratio (PSNR) and structural similarity index measure values indicate that the deep learning method performs excellently in image-to-image translation, with a PSNR improvement of about 0.74 dB over the optical super-resolution images. The proposed method provides a high level of detail in the reconstructed results, indicating that it has broad applicability to chip-level defect detection, biological sample analysis, forensics, and various other fields.
</details>
<details>
<summary>摘要</summary>
扫描电子顾问（SEM）在多种应用中是不可或缺的，包括微电子到食品加工等，因为它可以提供具有大深度场的图像，超过光学折射限制。然而，技术需要将导电薄膜层应用于隔离样品和真空环境。我们使用深度学习来获得扫描超解像（OSR）图像和SEM领域图像之间的映射关系，这使得OSR图像可以转换为大深度场的SEM样式图像。我们自制的扫描超透镜系统（SSUM）不需要将样品层层涂敷导电薄膜，也不需要真空环境，可以获得OSR图像的特征下限为~80nm。PSNR和结构相似性指数值表明，深度学习方法在图像到图像翻译中表现出色，与扫描超解像图像相比，PSNR提高约0.74dB。我们提出的方法可以在各种领域中提供高级别的细节，包括半导体缺陷检测、生物样本分析、法医和多种其他领域。
</details></li>
</ul>
<hr>
<h2 id="Autonomous-3D-Exploration-in-Large-Scale-Environments-with-Dynamic-Obstacles"><a href="#Autonomous-3D-Exploration-in-Large-Scale-Environments-with-Dynamic-Obstacles" class="headerlink" title="Autonomous 3D Exploration in Large-Scale Environments with Dynamic Obstacles"></a>Autonomous 3D Exploration in Large-Scale Environments with Dynamic Obstacles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17977">http://arxiv.org/abs/2310.17977</a></li>
<li>repo_url: None</li>
<li>paper_authors: Emil Wiman, Ludvig Widén, Mattias Tiger, Fredrik Heintz</li>
<li>for: 本研究旨在开探自动系统在动态和不确定的实际环境中的探索能力，以及如何通过包含动态障碍物在计划中来利用动态环境。</li>
<li>methods: 提议的 Dynamic Autonomous Exploration Planner (DAEP) extend AEP，以便考虑动态障碍物，并在各种动态环境中进行了全面评估。</li>
<li>results: DAEP 在动态和大规模环境中表现出优于当前标准方法，并在探索和碰撞避免方面具有更高的效果。<details>
<summary>Abstract</summary>
Exploration in dynamic and uncertain real-world environments is an open problem in robotics and constitutes a foundational capability of autonomous systems operating in most of the real world. While 3D exploration planning has been extensively studied, the environments are assumed static or only reactive collision avoidance is carried out. We propose a novel approach to not only avoid dynamic obstacles but also include them in the plan itself, to exploit the dynamic environment in the agent's favor. The proposed planner, Dynamic Autonomous Exploration Planner (DAEP), extends AEP to explicitly plan with respect to dynamic obstacles. To thoroughly evaluate exploration planners in such settings we propose a new enhanced benchmark suite with several dynamic environments, including large-scale outdoor environments. DAEP outperform state-of-the-art planners in dynamic and large-scale environments. DAEP is shown to be more effective at both exploration and collision avoidance.
</details>
<details>
<summary>摘要</summary>
文本翻译为简化中文：在真实世界中的动态和不确定环境中进行探索是Robotics中的一个开放问题，也是自主系统在大多数真实世界中的基本能力。而3D探索规划已经得到了广泛的研究，但是环境假设为静止的或者只是进行了反射性碰撞避免。我们提出了一种新的方法，不仅避免动态障碍物，而且将其包含在计划中，以利用动态环境来帮助代理人。我们提出的 Dynamic Autonomous Exploration Planner（DAEP）扩展了AEP，以明确地考虑动态障碍物。为了全面评估探索 плаanner在这些设置下的性能，我们提出了一个新的加强版benchmark suite，包括一些大规模的外部环境。DAEP在动态和大规模环境中表现出色，在探索和碰撞避免方面都更有效。</SYS>Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Train-Once-Get-a-Family-State-Adaptive-Balances-for-Offline-to-Online-Reinforcement-Learning"><a href="#Train-Once-Get-a-Family-State-Adaptive-Balances-for-Offline-to-Online-Reinforcement-Learning" class="headerlink" title="Train Once, Get a Family: State-Adaptive Balances for Offline-to-Online Reinforcement Learning"></a>Train Once, Get a Family: State-Adaptive Balances for Offline-to-Online Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17966">http://arxiv.org/abs/2310.17966</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/leaplabthu/famo2o">https://github.com/leaplabthu/famo2o</a></li>
<li>paper_authors: Shenzhi Wang, Qisen Yang, Jiawei Gao, Matthieu Gaetan Lin, Hao Chen, Liwei Wu, Ning Jia, Shiji Song, Gao Huang</li>
<li>for: 这篇论文是关于Offline-to-online reinforcement learning（RL）训练方法的，旨在解决在线环境中融合预先收集的数据集和精度调整的问题。</li>
<li>methods: 该论文提出了一种简单 yet effective的框架，即Family Offline-to-Online RL（FamO2O），可以让现有算法决定不同状态下的改进&#x2F;约束平衡。FamO2O使用一个通用模型训练一个家族政策，并使用一个平衡模型选择适合每个状态的政策。</li>
<li>results: 在许多实验中，FamO2O具有与现有方法相比的 statistically significant 改进，并达到了D4RLbenchmark上的状态空间最佳性能。代码可以在<a target="_blank" rel="noopener" href="https://github.com/LeapLabTHU/FamO2O%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/LeapLabTHU/FamO2O中找到。</a><details>
<summary>Abstract</summary>
Offline-to-online reinforcement learning (RL) is a training paradigm that combines pre-training on a pre-collected dataset with fine-tuning in an online environment. However, the incorporation of online fine-tuning can intensify the well-known distributional shift problem. Existing solutions tackle this problem by imposing a policy constraint on the policy improvement objective in both offline and online learning. They typically advocate a single balance between policy improvement and constraints across diverse data collections. This one-size-fits-all manner may not optimally leverage each collected sample due to the significant variation in data quality across different states. To this end, we introduce Family Offline-to-Online RL (FamO2O), a simple yet effective framework that empowers existing algorithms to determine state-adaptive improvement-constraint balances. FamO2O utilizes a universal model to train a family of policies with different improvement/constraint intensities, and a balance model to select a suitable policy for each state. Theoretically, we prove that state-adaptive balances are necessary for achieving a higher policy performance upper bound. Empirically, extensive experiments show that FamO2O offers a statistically significant improvement over various existing methods, achieving state-of-the-art performance on the D4RL benchmark. Codes are available at https://github.com/LeapLabTHU/FamO2O.
</details>
<details>
<summary>摘要</summary>
偏向在线学习（RL）训练 paradigma combines 预训练在预收集的数据集上与在线环境的精细调整。然而，在线调整可能会加剧分布shift问题。现有的解决方案通过在offline和online学习中加入策略约束来解决该问题。这些方法通常提出一个在多种数据集上保持策略改进目标和约束之间的平衡。然而，这种一大把 fits all的方法可能无法最佳利用每个采集的样本，因为不同的状态下的数据质量有很大的差异。为此，我们介绍了Family Offline-to-Online RL（FamO2O）框架，它可以让现有算法在不同的状态下选择适当的策略改进约束。FamO2O使用一个通用模型来训练一个家族策略，每个策略都有不同的改进约束强度。此外，FamO2O还使用一个平衡模型来选择每个状态下最适合的策略。理论上，我们证明了适应性平衡是实现更高策略性能上限的必要条件。empirically，我们进行了大量的实验，并证明了FamO2O可以在D4RL benchmark上达到状态前方的性能。代码可以在https://github.com/LeapLabTHU/FamO2O上获取。
</details></li>
</ul>
<hr>
<h2 id="Qilin-Med-VL-Towards-Chinese-Large-Vision-Language-Model-for-General-Healthcare"><a href="#Qilin-Med-VL-Towards-Chinese-Large-Vision-Language-Model-for-General-Healthcare" class="headerlink" title="Qilin-Med-VL: Towards Chinese Large Vision-Language Model for General Healthcare"></a>Qilin-Med-VL: Towards Chinese Large Vision-Language Model for General Healthcare</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17956">http://arxiv.org/abs/2310.17956</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/williamliujl/qilin-med-vl">https://github.com/williamliujl/qilin-med-vl</a></li>
<li>paper_authors: Junling Liu, Ziming Wang, Qichen Ye, Dading Chong, Peilin Zhou, Yining Hua<br>for:This paper aims to address the lack of large language models in languages other than English and the ability to interpret multi-modal input, specifically for global healthcare accessibility.methods:The study introduces Qilin-Med-VL, the first Chinese large vision-language model that combines a pre-trained Vision Transformer (ViT) with a foundational language model. The model undergoes a two-stage curriculum training process that includes feature alignment and instruction tuning.results:The model is able to generate medical captions and answer complex medical queries, and the authors release a dataset called ChiMed-VL, which consists of over 1 million image-text pairs to enable detailed and comprehensive interpretation of medical data using various types of images.<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have introduced a new era of proficiency in comprehending complex healthcare and biomedical topics. However, there is a noticeable lack of models in languages other than English and models that can interpret multi-modal input, which is crucial for global healthcare accessibility. In response, this study introduces Qilin-Med-VL, the first Chinese large vision-language model designed to integrate the analysis of textual and visual data. Qilin-Med-VL combines a pre-trained Vision Transformer (ViT) with a foundational LLM. It undergoes a thorough two-stage curriculum training process that includes feature alignment and instruction tuning. This method enhances the model's ability to generate medical captions and answer complex medical queries. We also release ChiMed-VL, a dataset consisting of more than 1M image-text pairs. This dataset has been carefully curated to enable detailed and comprehensive interpretation of medical data using various types of images.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）已经引入了新的时代，能够深刻理解复杂的医疗和生物医学话题。然而， существует一定的语言 besides English和可以处理多modal输入的模型缺失，这对全球医疗访问ibilty是关键。为此，本研究介绍了Qilin-Med-VL，首个用于整合文本和视觉数据的中文大vision-语言模型。Qilin-Med-VL结合预训练的视觉转换器（ViT）和基础的LLM。它通过两个阶段课程训练过程，包括特征对齐和指令调整。这种方法使得模型能够生成医学描述和回答复杂的医学问题。我们还发布了ChiMed-VL数据集，包含more than 1M的图像-文本对。这个数据集经过仔细审核，以便使用不同类型的图像进行详细和全面的医学数据解释。
</details></li>
</ul>
<hr>
<h2 id="Understanding-Parameter-Saliency-via-Extreme-Value-Theory"><a href="#Understanding-Parameter-Saliency-via-Extreme-Value-Theory" class="headerlink" title="Understanding Parameter Saliency via Extreme Value Theory"></a>Understanding Parameter Saliency via Extreme Value Theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17951">http://arxiv.org/abs/2310.17951</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuo Wang, Issei Sato</li>
<li>For: This paper aims to identify and correct misclassifications in deep neural networks, specifically convolutional neural networks (CNNs), by ranking convolution filters based on their potential to cause misidentification.* Methods: The paper uses parameter saliency ranking, which is based on extreme value theory, to identify the filters that are most likely to cause misclassification. The authors also use fine-tuning to correct misidentification.* Results: The paper shows that the proposed method can detect malicious filters and is less biased against the depth of layers in deep neural networks compared to existing methods. The authors also demonstrate the effectiveness of their approach on ImageNet.<details>
<summary>Abstract</summary>
Deep neural networks are being increasingly implemented throughout society in recent years. It is useful to identify which parameters trigger misclassification in diagnosing undesirable model behaviors. The concept of parameter saliency is proposed and used to diagnose convolutional neural networks (CNNs) by ranking convolution filters that may have caused misclassification on the basis of parameter saliency. It is also shown that fine-tuning the top ranking salient filters has efficiently corrected misidentification on ImageNet. However, there is still a knowledge gap in terms of understanding why parameter saliency ranking can find the filters inducing misidentification. In this work, we attempt to bridge the gap by analyzing parameter saliency ranking from a statistical viewpoint, namely, extreme value theory. We first show that the existing work implicitly assumes that the gradient norm computed for each filter follows a normal distribution. Then, we clarify the relationship between parameter saliency and the score based on the peaks-over-threshold (POT) method, which is often used to model extreme values. Finally, we reformulate parameter saliency in terms of the POT method, where this reformulation is regarded as statistical anomaly detection and does not require the implicit assumptions of the existing parameter-saliency formulation. Our experimental results demonstrate that our reformulation can detect malicious filters as well. Furthermore, we show that the existing parameter saliency method exhibits a bias against the depth of layers in deep neural networks. In particular, this bias has the potential to inhibit the discovery of filters that cause misidentification in situations where domain shift occurs. In contrast, parameter saliency based on POT shows less of this bias.
</details>
<details>
<summary>摘要</summary>
深度神经网络在近年中逐渐普及社会。为了诊断模型的不良行为，identifying模型参数的诱导性是非常有用的。在这些年中，我们提出了参数敏感性的概念，并用于诊断卷积神经网络（CNNs）中的参数敏感性排名。我们还证明了精细调整涉及到诊断错误的顶层敏感filter可以高效地修复ImageNet中的误分类。然而，我们还存在一个知识漏洞，即理解参数敏感排名如何找到导致误分类的filter。在这种情况下，我们尝试通过统计视角来填补这个漏洞，即使用极值理论。我们首先显示了现有工作假设每个滤波器的梯度 нор computes follows a normal distribution。然后，我们解释了参数敏感和分数之间的关系，并使用peaks-over-threshold（POT）方法来模型极值。最后，我们重新定义参数敏感，以统计异常检测的形式，不需要现有参数敏感的假设。我们的实验结果表明，我们的重新定义可以检测到危险的滤波器，并且我们发现现有参数敏感方法具有层深度的偏见，可能在领域转换 occurs 时阻碍发现误分类的滤波器。相比之下，基于POT方法的参数敏感方法具有较少的偏见。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-and-Reliable-Feature-Attribution-Method-Double-sided-Remove-and-Reconstruct-DoRaR"><a href="#A-Comprehensive-and-Reliable-Feature-Attribution-Method-Double-sided-Remove-and-Reconstruct-DoRaR" class="headerlink" title="A Comprehensive and Reliable Feature Attribution Method: Double-sided Remove and Reconstruct (DoRaR)"></a>A Comprehensive and Reliable Feature Attribution Method: Double-sided Remove and Reconstruct (DoRaR)</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17945">http://arxiv.org/abs/2310.17945</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dxq21/dorar">https://github.com/dxq21/dorar</a></li>
<li>paper_authors: Dong Qin, George Amariucai, Daji Qiao, Yong Guan, Shen Fu<br>for: 这种研究旨在解决深度神经网络和其他机器学习模型中的内部决策机制不透明性问题，以提高这些黑盒模型在不同领域的应用。methods: 该研究提出了一种基于多种改进方法的 Double-sided Remove and Reconstruct (DoRaR) 特征归因方法，可以有效地减轻艺术ifacts问题和Encoding Prediction in the Explanation (EPITE)问题，并可以帮助训练一个性能更高的特征选择器。results: 该研究通过对 MNIST、CIFAR10 和自己制作的synthetic数据集进行了广泛的测试，表明 DoRaR 特征归因方法可以有效地解释模型决策，并且可以超越其他现有的特征归因方法。<details>
<summary>Abstract</summary>
The limited transparency of the inner decision-making mechanism in deep neural networks (DNN) and other machine learning (ML) models has hindered their application in several domains. In order to tackle this issue, feature attribution methods have been developed to identify the crucial features that heavily influence decisions made by these black box models. However, many feature attribution methods have inherent downsides. For example, one category of feature attribution methods suffers from the artifacts problem, which feeds out-of-distribution masked inputs directly through the classifier that was originally trained on natural data points. Another category of feature attribution method finds explanations by using jointly trained feature selectors and predictors. While avoiding the artifacts problem, this new category suffers from the Encoding Prediction in the Explanation (EPITE) problem, in which the predictor's decisions rely not on the features, but on the masks that selects those features. As a result, the credibility of attribution results is undermined by these downsides. In this research, we introduce the Double-sided Remove and Reconstruct (DoRaR) feature attribution method based on several improvement methods that addresses these issues. By conducting thorough testing on MNIST, CIFAR10 and our own synthetic dataset, we demonstrate that the DoRaR feature attribution method can effectively bypass the above issues and can aid in training a feature selector that outperforms other state-of-the-art feature attribution methods. Our code is available at https://github.com/dxq21/DoRaR.
</details>
<details>
<summary>摘要</summary>
深度神经网络（DNN）和其他机器学习（ML）模型的内部决策机制的不充分透明性，限制了它们在一些领域的应用。为了解决这个问题，feature attrition方法被开发出来，以确定DNN和ML模型决策中的关键特征。然而，许多feature attrition方法存在一些缺点。例如，一类feature attrition方法会产生artefacts问题，即将外部样本掩码直接输入到原始训练的分类器中。另一类feature attrition方法使用共同训练的特征选择器和预测器，可以避免artefacts问题，但是它们会产生Encoding Prediction in the Explanation（EPITE）问题，导致预测结果的可信度受到特征选择器的影响。为了解决这些问题，我们在本研究中提出了Double-sided Remove and Reconstruct（DoRaR）特征attrition方法，基于一些改进方法。通过对MNIST、CIFAR10和我们自己的 sintetic dataset进行了广泛的测试，我们证明了DoRaR特征attrition方法可以有效地 circumvent这些问题，并且可以帮助训练一个性能更高的特征选择器。我们的代码可以在https://github.com/dxq21/DoRaR上下载。
</details></li>
</ul>
<hr>
<h2 id="Unified-Segment-to-Segment-Framework-for-Simultaneous-Sequence-Generation"><a href="#Unified-Segment-to-Segment-Framework-for-Simultaneous-Sequence-Generation" class="headerlink" title="Unified Segment-to-Segment Framework for Simultaneous Sequence Generation"></a>Unified Segment-to-Segment Framework for Simultaneous Sequence Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17940">http://arxiv.org/abs/2310.17940</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shaolei Zhang, Yang Feng</li>
<li>for:  simultaneous sequence generation for real-time scenarios, such as streaming speech recognition, simultaneous machine translation, and simultaneous speech translation</li>
<li>methods:  segment-to-segment framework (Seg2Seg) with adaptive and unified learning for mapping between source and target sequences</li>
<li>results:  state-of-the-art performance and better generality across various tasks, as demonstrated by experiments on multiple simultaneous generation tasks<details>
<summary>Abstract</summary>
Simultaneous sequence generation is a pivotal task for real-time scenarios, such as streaming speech recognition, simultaneous machine translation and simultaneous speech translation, where the target sequence is generated while receiving the source sequence. The crux of achieving high-quality generation with low latency lies in identifying the optimal moments for generating, accomplished by learning a mapping between the source and target sequences. However, existing methods often rely on task-specific heuristics for different sequence types, limiting the model's capacity to adaptively learn the source-target mapping and hindering the exploration of multi-task learning for various simultaneous tasks. In this paper, we propose a unified segment-to-segment framework (Seg2Seg) for simultaneous sequence generation, which learns the mapping in an adaptive and unified manner. During the process of simultaneous generation, the model alternates between waiting for a source segment and generating a target segment, making the segment serve as the natural bridge between the source and target. To accomplish this, Seg2Seg introduces a latent segment as the pivot between source to target and explores all potential source-target mappings via the proposed expectation training, thereby learning the optimal moments for generating. Experiments on multiple simultaneous generation tasks demonstrate that Seg2Seg achieves state-of-the-art performance and exhibits better generality across various tasks.
</details>
<details>
<summary>摘要</summary>
同时序列生成是现实时应用场景中的关键任务，如流媒体语音识别、同时机器翻译和同时语音翻译，其目标序列在接收源序列时生成。实现高质量生成的关键在于确定最佳的生成时机，通过学习源和目标序列之间的映射来实现。然而，现有方法通常采用特定任务的规则来控制生成，限制模型在不同序列类型上适应性地学习源-目标映射，阻碍了不同同时任务的多任务学习。本文提出了一个统一的段到段框架（Seg2Seg），用于同时序列生成。在同时生成过程中，模型会在等待源段和生成目标段之间转换，使得段成为源和目标之间自然的桥梁。为了实现这一点，Seg2Seg引入了一个 latent segment，作为源到目标映射的潜在桥梁，并通过提出的预期训练来探索所有可能的源-目标映射，从而学习最佳的生成时机。实验表明，Seg2Seg在多个同时生成任务上具有状态体系最佳性和更好的普适性。
</details></li>
</ul>
<hr>
<h2 id="Transformers-as-Graph-to-Graph-Models"><a href="#Transformers-as-Graph-to-Graph-Models" class="headerlink" title="Transformers as Graph-to-Graph Models"></a>Transformers as Graph-to-Graph Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17936">http://arxiv.org/abs/2310.17936</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/idiap/g2g-transformer">https://github.com/idiap/g2g-transformer</a></li>
<li>paper_authors: James Henderson, Alireza Mohammadshahi, Andrei C. Coman, Lesly Miculicich</li>
<li>for: 本 paper 的目的是使 Transformers 成为图形模型，并将序列视为特殊情况。</li>
<li>methods: 本 paper 使用图 edges 作为注意力权重，并通过 iterative graph refinement 实现非 autoregressive 图预测。</li>
<li>results: 本 paper 的实验结果表明，这种 architecture 可以达到模elling 多种语言结构的最佳性能，并很好地与预training 中学习的含义语言表示结合。<details>
<summary>Abstract</summary>
We argue that Transformers are essentially graph-to-graph models, with sequences just being a special case. Attention weights are functionally equivalent to graph edges. Our Graph-to-Graph Transformer architecture makes this ability explicit, by inputting graph edges into the attention weight computations and predicting graph edges with attention-like functions, thereby integrating explicit graphs into the latent graphs learned by pretrained Transformers. Adding iterative graph refinement provides a joint embedding of input, output, and latent graphs, allowing non-autoregressive graph prediction to optimise the complete graph without any bespoke pipeline or decoding strategy. Empirical results show that this architecture achieves state-of-the-art accuracies for modelling a variety of linguistic structures, integrating very effectively with the latent linguistic representations learned by pretraining.
</details>
<details>
<summary>摘要</summary>
我们认为Transformer是基本上是图像图模型，序列只是特殊情况。注意权重函数对应于图像边。我们的图像图Transformer架构使得这种能力变得明确，将图像边输入到注意权重计算中，并使用注意函数预测图像边，因此将显式图 integrate到预训练Transformer中学习的潜在图中。添加迭代图精度提供了共同嵌入输入、输出和潜在图，allowing非自适应图预测可以优化完整的图 без any bespoke pipeline or decoding strategy. empirical results show that this architecture achieves state-of-the-art accuracy for modeling a variety of linguistic structures, integrating very effectively with the latent linguistic representations learned by pretraining.Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>
<hr>
<h2 id="Matching-of-Descriptive-Labels-to-Glossary-Descriptions"><a href="#Matching-of-Descriptive-Labels-to-Glossary-Descriptions" class="headerlink" title="Matching of Descriptive Labels to Glossary Descriptions"></a>Matching of Descriptive Labels to Glossary Descriptions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18385">http://arxiv.org/abs/2310.18385</a></li>
<li>repo_url: None</li>
<li>paper_authors: Toshihiro Takahashi, Takaaki Tateishi, Michiaki Tatsubori</li>
<li>for: 这个论文主要是为了解决软件工程中的描述性标签匹配问题，即工程师需要将描述性标签（如商业术语、表列名称）与相关的描述文本相匹配。</li>
<li>methods: 该论文提议使用现有的semantic text similarity测量（STS），并通过扩展 Sentence Retrieval和集成上下文化来增强它。 Sentence Retrieval是一种方法，可以为给定的标签返回与之相关的句子，而集成上下文化则是一种方法，可以计算两个上下文集（例如，两个表中的列名称）之间的相似度。</li>
<li>results: 实验结果表明，提议的方法可以帮助下面STS更正确地匹配描述性标签与描述文本。<details>
<summary>Abstract</summary>
Semantic text similarity plays an important role in software engineering tasks in which engineers are requested to clarify the semantics of descriptive labels (e.g., business terms, table column names) that are often consists of too short or too generic words and appears in their IT systems. We formulate this type of problem as a task of matching descriptive labels to glossary descriptions. We then propose a framework to leverage an existing semantic text similarity measurement (STS) and augment it using semantic label enrichment and set-based collective contextualization where the former is a method to retrieve sentences relevant to a given label and the latter is a method to compute similarity between two contexts each of which is derived from a set of texts (e.g., column names in the same table). We performed an experiment on two datasets derived from publicly available data sources. The result indicated that the proposed methods helped the underlying STS correctly match more descriptive labels with the descriptions.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用简化字符串对文本进行相似度计算，可以帮助软件工程师在IT系统中更好地理解描述性标签（如商业术语、表列名称）的 semantics。我们将这种问题定义为映射描述标签到词典描述的任务。我们then proposed a framework to leveragen existing semantic text similarity measurement (STS) and augment it using semantic label enrichment and set-based collective contextualization。在我们的实验中，我们使用了两个公共数据源中的数据，并得到了结果，表明我们的方法可以帮助STS更正确地匹配描述标签与描述。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Knowing-What-LLMs-DO-NOT-Know-A-Simple-Yet-Effective-Self-Detection-Method"><a href="#Knowing-What-LLMs-DO-NOT-Know-A-Simple-Yet-Effective-Self-Detection-Method" class="headerlink" title="Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method"></a>Knowing What LLMs DO NOT Know: A Simple Yet Effective Self-Detection Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17918">http://arxiv.org/abs/2310.17918</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yukun Zhao, Lingyong Yan, Weiwei Sun, Guoliang Xing, Chong Meng, Shuaiqiang Wang, Zhicong Cheng, Zhaochun Ren, Dawei Yin</li>
<li>for: 检测LLMs生成的非事实答案，提高LLMs的可靠性。</li>
<li>methods: 提出了一种自我检测方法，通过多种文本表达和模型自身的询问来检测LLMs是否生成非事实答案。</li>
<li>results: 经过实验表明，该方法可以有效地检测LLMs生成的非事实答案，并且可以在最新发布的LLMs中进行应用，如Vicuna、ChatGPT和GPT-4等。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have shown great potential in Natural Language Processing (NLP) tasks. However, recent literature reveals that LLMs generate nonfactual responses intermittently, which impedes the LLMs' reliability for further utilization. In this paper, we propose a novel self-detection method to detect which questions that a LLM does not know that are prone to generate nonfactual results. Specifically, we first diversify the textual expressions for a given question and collect the corresponding answers. Then we examine the divergencies between the generated answers to identify the questions that the model may generate falsehoods. All of the above steps can be accomplished by prompting the LLMs themselves without referring to any other external resources. We conduct comprehensive experiments and demonstrate the effectiveness of our method on recently released LLMs, e.g., Vicuna, ChatGPT, and GPT-4.
</details>
<details>
<summary>摘要</summary>
大型自然语言处理模型（LLM）在自然语言处理任务中表现出了很大的潜力。然而，最新的文献表明，LLM occasional generation of nonfactual responses，这限制了LLM的可靠性，使其无法进一步使用。在这篇论文中，我们提出了一种新的自我检测方法，可以检测LLM不熟悉的问题是否会生成非事实答案。 Specifically，我们首先对给定问题的文本表达进行多样化，然后收集相应的答案。然后，我们比较这些生成的答案之间的差异，以确定问题是否会导致模型生成假信息。所有这些步骤都可以通过使用LLM自己的提问，不需要参考任何外部资源。我们对最近发布的LLM，如Vicuna、ChatGPT和GPT-4等进行了广泛的实验，并证明了我们的方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="The-Innovation-to-Occupations-Ontology-Linking-Business-Transformation-Initiatives-to-Occupations-and-Skills"><a href="#The-Innovation-to-Occupations-Ontology-Linking-Business-Transformation-Initiatives-to-Occupations-and-Skills" class="headerlink" title="The Innovation-to-Occupations Ontology: Linking Business Transformation Initiatives to Occupations and Skills"></a>The Innovation-to-Occupations Ontology: Linking Business Transformation Initiatives to Occupations and Skills</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17909">http://arxiv.org/abs/2310.17909</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniela Elia, Fang Chen, Didar Zowghi, Marian-Andrei Rizoiu</li>
<li>for: 这篇论文是为了描述一种新的 ontology 和一种自动填充方法，以链接企业变革 iniciativas 和职业。</li>
<li>methods: 该论文使用了 online job ads 和 Wikipedia 页面的嵌入式提取出来自动填充 ontology。</li>
<li>results: 该研究成功地匹配了各种企业变革 initiaves 和相应的职业，并提供了一种创新的方法来导引企业和教育机构在具体的企业变革 initiaves 中寻找合适的人才。<details>
<summary>Abstract</summary>
The fast adoption of new technologies forces companies to continuously adapt their operations making it harder to predict workforce requirements. Several recent studies have attempted to predict the emergence of new roles and skills in the labour market from online job ads. This paper aims to present a novel ontology linking business transformation initiatives to occupations and an approach to automatically populating it by leveraging embeddings extracted from job ads and Wikipedia pages on business transformation and emerging technologies topics. To our knowledge, no previous research explicitly links business transformation initiatives, like the adoption of new technologies or the entry into new markets, to the roles needed. Our approach successfully matches occupations to transformation initiatives under ten different scenarios, five linked to technology adoption and five related to business. This framework presents an innovative approach to guide enterprises and educational institutions on the workforce requirements for specific business transformation initiatives.
</details>
<details>
<summary>摘要</summary>
新技术的快速采用使公司需要不断适应操作，使预测工作力需求变得更加困难。一些最近的研究尝试通过在线职位招聘广告预测劳动力市场中的新角色和技能的出现。本文提出了一种新的 ontology，将企业转型活动与职业联系起来，并通过利用来自职位招聘和企业转型和新技术主题的Wikipedia页面中提取的嵌入进行自动填充。根据我们所知，没有任何前期研究直接将企业转型活动，如新技术的采用或新市场的入场，与需要的职业联系起来。我们的方法成功地将职业与转型活动相匹配，并在五种技术采用和五种商业转型的场景下进行了十个不同的enario。这种框架将为企业和教育机构提供一种创新的方法，以指导特定的企业转型活动所需的工作力。
</details></li>
</ul>
<hr>
<h2 id="Pitfalls-in-Language-Models-for-Code-Intelligence-A-Taxonomy-and-Survey"><a href="#Pitfalls-in-Language-Models-for-Code-Intelligence-A-Taxonomy-and-Survey" class="headerlink" title="Pitfalls in Language Models for Code Intelligence: A Taxonomy and Survey"></a>Pitfalls in Language Models for Code Intelligence: A Taxonomy and Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17903">http://arxiv.org/abs/2310.17903</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yueyuel/reliablelm4code">https://github.com/yueyuel/reliablelm4code</a></li>
<li>paper_authors: Xinyu She, Yue Liu, Yanjie Zhao, Yiling He, Li Li, Chakkrit Tantithamthavorn, Zhan Qin, Haoyu Wang</li>
<li>for: 本研究旨在探讨语言模型 для代码智能（LM4Code）中存在的各种隐患，以提高其可靠性和实用性。</li>
<li>methods: 我们采用了系统性的研究方法，包括文献综述和分类分析，对67篇来自顶尖学术会议的研究进行了仔细审查。</li>
<li>results: 我们发现了LM4Code研究中存在的4大类隐患，即数据采集和标注、系统设计和学习、性能评估和部署维护。这些隐患可能导致LM4Code系统的不可靠性和实用性问题。<details>
<summary>Abstract</summary>
Modern language models (LMs) have been successfully employed in source code generation and understanding, leading to a significant increase in research focused on learning-based code intelligence, such as automated bug repair, and test case generation. Despite their great potential, language models for code intelligence (LM4Code) are susceptible to potential pitfalls, which hinder realistic performance and further impact their reliability and applicability in real-world deployment. Such challenges drive the need for a comprehensive understanding - not just identifying these issues but delving into their possible implications and existing solutions to build more reliable language models tailored to code intelligence. Based on a well-defined systematic research approach, we conducted an extensive literature review to uncover the pitfalls inherent in LM4Code. Finally, 67 primary studies from top-tier venues have been identified. After carefully examining these studies, we designed a taxonomy of pitfalls in LM4Code research and conducted a systematic study to summarize the issues, implications, current solutions, and challenges of different pitfalls for LM4Code systems. We developed a comprehensive classification scheme that dissects pitfalls across four crucial aspects: data collection and labeling, system design and learning, performance evaluation, and deployment and maintenance. Through this study, we aim to provide a roadmap for researchers and practitioners, facilitating their understanding and utilization of LM4Code in reliable and trustworthy ways.
</details>
<details>
<summary>摘要</summary>
（简化中文）现代语言模型（LM）在源代码生成和理解方面取得了成功，导致学习基于代码智能的研究得到了推动，例如自动修复bug和测试用例生成。尽管LM4Code具有巨大的潜力，但它们也面临着一些潜在的难题，这些难题会影响LM4Code在实际应用中的性能和可靠性。这些挑战需要我们进行全面的理解，不仅是识别这些问题，而且还需要探究它们的可能的影响和现有的解决方案，以建立更可靠的LM4Code系统。我们采用了一种系统atic research approach，进行了广泛的文献综述，并最终确定了67篇来自top-tier venues的研究。经过仔细检查这些研究，我们设计了LM4Code研究中的taxonomy难点，并进行了系统的研究，总结了各种难点的问题、影响、当前的解决方案和挑战。我们开发了一种全面的分类方案，将难点分解成四个重要方面：数据收集和标注、系统设计和学习、性能评估和部署维护。通过这项研究，我们希望为研究者和实践者提供一个路线图，以便他们更好地理解和利用LM4Code，以实现可靠和可信worthy的应用。
</details></li>
</ul>
<hr>
<h2 id="Natural-Language-Interfaces-for-Tabular-Data-Querying-and-Visualization-A-Survey"><a href="#Natural-Language-Interfaces-for-Tabular-Data-Querying-and-Visualization-A-Survey" class="headerlink" title="Natural Language Interfaces for Tabular Data Querying and Visualization: A Survey"></a>Natural Language Interfaces for Tabular Data Querying and Visualization: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17894">http://arxiv.org/abs/2310.17894</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weixu Zhang, Yifei Wang, Yuanfeng Song, Victor Junqiu Wei, Yuxing Tian, Yiyan Qi, Jonathan H. Chan, Raymond Chi-Wing Wong, Haiqin Yang</li>
<li>for: 这篇论文旨在提供一个完整的对话语言处理（NLP）技术在表格数据查询和可见化方面的概述，帮助用户通过自然语言查询来交互 WITH 数据。</li>
<li>methods: 本论文介绍了对话语言处理技术的基本概念和方法，尤其是Semantic Parsing，这是将自然语言转换为SQL查询或数据可见化命令的关键技术。</li>
<li>results: 本论文提供了关于文本-SQL和文本-可见化问题的最新进展，包括数据集、方法、指标和系统设计等方面的报告，并强调了大语言模型（LLM）在这些领域的影响和未来发展的可能性。<details>
<summary>Abstract</summary>
The emergence of natural language processing has revolutionized the way users interact with tabular data, enabling a shift from traditional query languages and manual plotting to more intuitive, language-based interfaces. The rise of large language models (LLMs) such as ChatGPT and its successors has further advanced this field, opening new avenues for natural language processing techniques. This survey presents a comprehensive overview of natural language interfaces for tabular data querying and visualization, which allow users to interact with data using natural language queries. We introduce the fundamental concepts and techniques underlying these interfaces with a particular emphasis on semantic parsing, the key technology facilitating the translation from natural language to SQL queries or data visualization commands. We then delve into the recent advancements in Text-to-SQL and Text-to-Vis problems from the perspectives of datasets, methodologies, metrics, and system designs. This includes a deep dive into the influence of LLMs, highlighting their strengths, limitations, and potential for future improvements. Through this survey, we aim to provide a roadmap for researchers and practitioners interested in developing and applying natural language interfaces for data interaction in the era of large language models.
</details>
<details>
<summary>摘要</summary>
“自然语言处理技术的出现已经改变了用户与数据表格之间的交互方式，从传统的查询语言和手动折衣到更直观的自然语言界面。大型语言模型（LLM）如ChatGPT和其继承者的出现已经进一步推动了这个领域，开启了新的自然语言处理技术的avenues。本缩短所提供的缩短简介了自然语言界面 для数据表格查询和可视化，让用户可以使用自然语言查询来与数据进行交互。我们将介绍这些界面的基本概念和技术，尤其是对于自然语言转换为SQL查询或数据可视化指令的问题，我们将对这些问题进行深入探讨。我们还将详细介绍过去几年在文本转SQL和文本转可视化领域中的进展，包括 dataset、方法、指标和系统设计等方面的发展。这包括对大型语言模型（LLM）的影响，包括它们的优点、局限性和未来改进的潜力。我们 hoped that this survey will provide a roadmap for researchers and practitioners interested in developing and applying natural language interfaces for data interaction in the era of large language models.”Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Can-LLMs-Keep-a-Secret-Testing-Privacy-Implications-of-Language-Models-via-Contextual-Integrity-Theory"><a href="#Can-LLMs-Keep-a-Secret-Testing-Privacy-Implications-of-Language-Models-via-Contextual-Integrity-Theory" class="headerlink" title="Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory"></a>Can LLMs Keep a Secret? Testing Privacy Implications of Language Models via Contextual Integrity Theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17884">http://arxiv.org/abs/2310.17884</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/skywalker023/confAIde">https://github.com/skywalker023/confAIde</a></li>
<li>paper_authors: Niloofar Mireshghallah, Hyunwoo Kim, Xuhui Zhou, Yulia Tsvetkov, Maarten Sap, Reza Shokri, Yejin Choi</li>
<li>for:  This paper highlights the privacy risks associated with the use of large language models (LLMs) in AI assistants, specifically the inference-time privacy risks that arise when LLMs are fed different types of information from multiple sources and are expected to reason about what to share in their outputs.</li>
<li>methods:  The paper proposes ConfAIde, a benchmark designed to identify critical weaknesses in the privacy reasoning capabilities of instruction-tuned LLMs. The authors use this benchmark to evaluate the privacy reasoning abilities of two state-of-the-art LLMs, GPT-4 and ChatGPT.</li>
<li>results:  The authors find that even the most capable models, GPT-4 and ChatGPT, reveal private information in contexts that humans would not, 39% and 57% of the time, respectively. This leakage persists even when the authors employ privacy-inducing prompts or chain-of-thought reasoning. The paper highlights the immediate need to explore novel inference-time privacy-preserving approaches based on reasoning and theory of mind.<details>
<summary>Abstract</summary>
The interactive use of large language models (LLMs) in AI assistants (at work, home, etc.) introduces a new set of inference-time privacy risks: LLMs are fed different types of information from multiple sources in their inputs and are expected to reason about what to share in their outputs, for what purpose and with whom, within a given context. In this work, we draw attention to the highly critical yet overlooked notion of contextual privacy by proposing ConfAIde, a benchmark designed to identify critical weaknesses in the privacy reasoning capabilities of instruction-tuned LLMs. Our experiments show that even the most capable models such as GPT-4 and ChatGPT reveal private information in contexts that humans would not, 39% and 57% of the time, respectively. This leakage persists even when we employ privacy-inducing prompts or chain-of-thought reasoning. Our work underscores the immediate need to explore novel inference-time privacy-preserving approaches, based on reasoning and theory of mind.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLMs）在人工智能助手（在工作、家庭等）的交互使用中引入了一新的推理时隐私风险：LLMs 从多种来源接受不同类型的信息，并被要求在输出中对此进行分享、目的和对象的决定，在给定的上下文中。在这项工作中，我们吸引关注高度敏感但受到忽略的上下文隐私的概念，并提出了 ConfAIde，一个用于评估指导学习模型的隐私推理能力的benchmark。我们的实验显示，even the most capable models such as GPT-4 and ChatGPT reveal private information in contexts that humans would not, 39% and 57% of the time, respectively。这种泄露 persist even when we employ privacy-inducing prompts or chain-of-thought reasoning。我们的工作强调了立即需要探索新的推理时隐私保护方法，基于推理和思维模型。
</details></li>
</ul>
<hr>
<h2 id="ASPIRO-Any-shot-Structured-Parsing-error-Induced-ReprOmpting-for-Consistent-Data-to-Text-Generation"><a href="#ASPIRO-Any-shot-Structured-Parsing-error-Induced-ReprOmpting-for-Consistent-Data-to-Text-Generation" class="headerlink" title="ASPIRO: Any-shot Structured Parsing-error-Induced ReprOmpting for Consistent Data-to-Text Generation"></a>ASPIRO: Any-shot Structured Parsing-error-Induced ReprOmpting for Consistent Data-to-Text Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17877">http://arxiv.org/abs/2310.17877</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vejvarm/aspiro">https://github.com/vejvarm/aspiro</a></li>
<li>paper_authors: Martin Vejvar, Yasutaka Fujimoto</li>
<li>for: 用于构成数据数据预设的短模板句子生成，具有零至几据设置。</li>
<li>methods: 使用大型自然语言模型（LLM）直接生成概念不受限制的模板，而不是依赖 LLM 复制示例物件或手动验证&#x2F;创建模板。 使用 LLM 重新提示和自动架构检查来解决生成问题。</li>
<li>results: 与直接 LLM 输出相比，ASPIRO 平均降低 DART dataset 中生成的括号错误率66%。在 Rel2Text dataset 上，使用最佳 5 据 setup（text-davinci-003）， scored BLEU 50.62、METEOR 45.16、BLEURT 0.82、NUBIA 0.87 和 PARENT 0.8962，与最近的 fine-tuned 预训语言模型竞争。<details>
<summary>Abstract</summary>
We present ASPIRO, an approach for structured data verbalisation into short template sentences in zero to few-shot settings. Unlike previous methods, our approach prompts large language models (LLMs) to directly produce entity-agnostic templates, rather than relying on LLMs to faithfully copy the given example entities, or validating/crafting the templates manually. We incorporate LLM re-prompting, triggered by algorithmic parsing checks, as well as the PARENT metric induced consistency validation to identify and rectify template generation problems in real-time. ASPIRO, compared to direct LLM output, averages 66\% parsing error rate reduction in generated verbalisations of RDF triples on the DART dataset. Our best 5-shot text-davinci-003 setup, scoring BLEU of 50.62, METEOR of 45.16, BLEURT of 0.82, NUBIA of 0.87, and PARENT of 0.8962 on the Rel2Text dataset, competes effectively with recent fine-tuned pre-trained language models.
</details>
<details>
<summary>摘要</summary>
我们介绍ASPIRO方法，用于在零到几极少示例设置下将结构化数据变成简短的模板句子。与前一代方法不同，我们的方法会让大型自然语言模型（LLM）直接生成无关实体的模板，而不是依赖于LLM忠实 копи写给定示例实体，或者手动验证/制定模板。我们利用LLM重新拓展，根据算法解析检查触发，以及由PARENT метрик引起的一致验证，实时rectify模板生成问题。与直接LLM输出相比，ASPIRO方法在DART数据集上的生成架构化描述中的平均解析错误率减少了66%。我们的最佳5枚TEXT-DAVINCI-003设置，在Rel2Text数据集上的BLEU分数为50.62，METEOR分数为45.16，BLEURT分数为0.82，NUBIA分数为0.87，和PARENT分数为0.8962，与最近的微调预训练语言模型竞争得来。
</details></li>
</ul>
<hr>
<h2 id="Ranking-with-Slot-Constraints"><a href="#Ranking-with-Slot-Constraints" class="headerlink" title="Ranking with Slot Constraints"></a>Ranking with Slot Constraints</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17870">http://arxiv.org/abs/2310.17870</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/GarlGuo/ranking_with_slot_constraints">https://github.com/GarlGuo/ranking_with_slot_constraints</a></li>
<li>paper_authors: Wentao Guo, Andrew Wang, Bradon Thymes, Thorsten Joachims</li>
<li>for: ranking with slot constraints, which can be applied to various real-world problems such as college admission and medical trial participant selection.</li>
<li>methods: the proposed algorithm called MatchRank, which aims to maximize the number of filled slots by evaluating candidates in the order of the ranking.</li>
<li>results: MatchRank has a strong approximation guarantee and can provide substantial improvements over a range of synthetic and real-world tasks.Here’s the full summary in Simplified Chinese:</li>
<li>for: ranking with slot constraints, 可以应用到各种实际世界问题，如大学入学和医学试验参与者选择。</li>
<li>methods: 提案的算法叫做MatchRank，它的目标是通过评估候选人来填充槽位。</li>
<li>results: MatchRank具有强的近似保证，并且在多个 sintetic 和实际任务上能提供substantial 的改善。<details>
<summary>Abstract</summary>
We introduce the problem of ranking with slot constraints, which can be used to model a wide range of application problems -- from college admission with limited slots for different majors, to composing a stratified cohort of eligible participants in a medical trial. We show that the conventional Probability Ranking Principle (PRP) can be highly sub-optimal for slot-constrained ranking problems, and we devise a new ranking algorithm, called MatchRank. The goal of MatchRank is to produce rankings that maximize the number of filled slots if candidates are evaluated by a human decision maker in the order of the ranking. In this way, MatchRank generalizes the PRP, and it subsumes the PRP as a special case when there are no slot constraints. Our theoretical analysis shows that MatchRank has a strong approximation guarantee without any independence assumptions between slots or candidates. Furthermore, we show how MatchRank can be implemented efficiently. Beyond the theoretical guarantees, empirical evaluations show that MatchRank can provide substantial improvements over a range of synthetic and real-world tasks.
</details>
<details>
<summary>摘要</summary>
我们介绍了带槽限制的排名问题，这可以用来模型广泛的应用问题---从大学入学限制不同学系的名额，到组织一个适合者的医疗试验参与者实验组。我们表明，传统的概率排名原则（PRP）可以对带槽限制的排名问题高度不理想，而我们提出了一个新的排名算法，called MatchRank。MatchRank的目的是在人工决策者按照排名顺序评估候选者时，生成将满足最多槽位的排名。这样，MatchRank超越了PRP，并将其视为对槽位不存在的特别情况。我们的理论分析显示MatchRank具有强的近似保证，不需要候选者或槽位之间的独立假设。此外，我们显示了如何有效地实现MatchRank。在理论保证之外，实际评估显示MatchRank可以提供广泛的Synthetic和实际任务中的重大改善。
</details></li>
</ul>
<hr>
<h2 id="Reproducibility-in-Multiple-Instance-Learning-A-Case-For-Algorithmic-Unit-Tests"><a href="#Reproducibility-in-Multiple-Instance-Learning-A-Case-For-Algorithmic-Unit-Tests" class="headerlink" title="Reproducibility in Multiple Instance Learning: A Case For Algorithmic Unit Tests"></a>Reproducibility in Multiple Instance Learning: A Case For Algorithmic Unit Tests</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17867">http://arxiv.org/abs/2310.17867</a></li>
<li>repo_url: None</li>
<li>paper_authors: Edward Raff, James Holt<br>for:多元例子学习（MIL）是一个特殊的分类问题，其中输入包含多个实例，每个实例具有一个标签，标签为正则则表示至少有一个正例在输入中，否则为负例。训练这种问题需要将实例级别的信息与袋级别的标签相关联，并且含有一定的 causal 假设和偏见。MIL问题在医疗、网络安全等领域都有广泛的应用。methods:本文研究了五种深度学习的MIL模型，发现这些模型都不尊重标准MIL假设。它们能够学习反相关的实例，即默认为正例，直到看到负例为止，这不应该是正确的MIL模型的行为。我们认为这些模型的改进版本和其他相关工作也会具有同样的问题。results:我们通过一种提议的”算法单元测试”来证明这些模型的问题。我们创建了一些合成数据集，可以由一个尊重MIL假设的模型解决，而这些数据集明显暴露了这些模型学习的问题。五种评估模型各自失败了一个或多个这些测试。这提供了一种模型独立的方法来识别模型假设的违反，我们希望这将对未来的MIL模型开发和评估具有用处。<details>
<summary>Abstract</summary>
Multiple Instance Learning (MIL) is a sub-domain of classification problems with positive and negative labels and a "bag" of inputs, where the label is positive if and only if a positive element is contained within the bag, and otherwise is negative. Training in this context requires associating the bag-wide label to instance-level information, and implicitly contains a causal assumption and asymmetry to the task (i.e., you can't swap the labels without changing the semantics). MIL problems occur in healthcare (one malignant cell indicates cancer), cyber security (one malicious executable makes an infected computer), and many other tasks. In this work, we examine five of the most prominent deep-MIL models and find that none of them respects the standard MIL assumption. They are able to learn anti-correlated instances, i.e., defaulting to "positive" labels until seeing a negative counter-example, which should not be possible for a correct MIL model. We suspect that enhancements and other works derived from these models will share the same issue. In any context in which these models are being used, this creates the potential for learning incorrect models, which creates risk of operational failure. We identify and demonstrate this problem via a proposed "algorithmic unit test", where we create synthetic datasets that can be solved by a MIL respecting model, and which clearly reveal learning that violates MIL assumptions. The five evaluated methods each fail one or more of these tests. This provides a model-agnostic way to identify violations of modeling assumptions, which we hope will be useful for future development and evaluation of MIL models.
</details>
<details>
<summary>摘要</summary>
多例学习（Multiple Instance Learning，MIL）是一个类别问题的子领域，其中包含正例和负例，以及一个“袋”（bag）中的输入，其中正例是指袋中包含正例元素，否则为负例。在这种情况下，训练需要将袋级别标签与实例级别信息相关联，并且含有一定的 causal 假设和不对称性。MIL 问题在医疗（一个有害细胞表示癌症）、计算机安全（一个恶意执行程序使计算机感染）等领域出现。在这种工作中，我们考察了五种最具有影响力的深度MIL模型，并发现其中没有任何一个遵循标准MIL假设。它们可以学习反相关实例，即默认为正例标签，直到看到负例对例，这不应该是正确的MIL模型。我们认为这些模型的改进和其他基于这些模型的工作都会受到同样的问题。在这些模型被使用的任何情况下，这会创造出学习错误的模型，从而导致操作失败的风险。我们通过一种“算法单元测试”来识别和演示这个问题，其中我们创建了一些可以由遵循MIL假设的模型解决的 sintetic 数据集，并显示了这些模型学习的问题。五种评估方法都失败了一个或多个这些测试。这提供了一种模型独立的方式来识别模型假设的违反，我们希望这将对未来的MIL模型发展和评估具有用。
</details></li>
</ul>
<hr>
<h2 id="Function-Space-Bayesian-Pseudocoreset-for-Bayesian-Neural-Networks"><a href="#Function-Space-Bayesian-Pseudocoreset-for-Bayesian-Neural-Networks" class="headerlink" title="Function Space Bayesian Pseudocoreset for Bayesian Neural Networks"></a>Function Space Bayesian Pseudocoreset for Bayesian Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17852">http://arxiv.org/abs/2310.17852</a></li>
<li>repo_url: None</li>
<li>paper_authors: Balhae Kim, Hyungi Lee, Juho Lee</li>
<li>for: 这个论文旨在构建一种 bayesian  Pseudocoreset，用于实现可扩展的 Bayesian 推理。</li>
<li>methods: 该方法在函数空间上构建 variational approximation，并将其与全量数据 posterior 匹配在函数空间上。</li>
<li>results: 该方法可以更好地衡量uncertainty量和Robustness，并且适用于多种模型架构。<details>
<summary>Abstract</summary>
A Bayesian pseudocoreset is a compact synthetic dataset summarizing essential information of a large-scale dataset and thus can be used as a proxy dataset for scalable Bayesian inference. Typically, a Bayesian pseudocoreset is constructed by minimizing a divergence measure between the posterior conditioning on the pseudocoreset and the posterior conditioning on the full dataset. However, evaluating the divergence can be challenging, particularly for the models like deep neural networks having high-dimensional parameters. In this paper, we propose a novel Bayesian pseudocoreset construction method that operates on a function space. Unlike previous methods, which construct and match the coreset and full data posteriors in the space of model parameters (weights), our method constructs variational approximations to the coreset posterior on a function space and matches it to the full data posterior in the function space. By working directly on the function space, our method could bypass several challenges that may arise when working on a weight space, including limited scalability and multi-modality issue. Through various experiments, we demonstrate that the Bayesian pseudocoresets constructed from our method enjoys enhanced uncertainty quantification and better robustness across various model architectures.
</details>
<details>
<summary>摘要</summary>
一个 bayesian pseudocoreset 是一个简化的人工数据集，它捕捉了大规模数据集中的关键信息，因此可以用作可扩展的 bayesian 推理的代理数据集。通常，一个 bayesian pseudocoreset 是通过将 posterior conditioning 中的差异最小化来构建的。然而，对于深度神经网络等高维参数模型来说，评估差异可能具有挑战。在这篇论文中，我们提出了一种新的 bayesian pseudocoreset 构建方法，它在函数空间上进行。不同于之前的方法，我们的方法在模型参数（ weights）空间上构建和匹配 coreset 和全数据 posterior，而不是直接在 weights 空间上做。通过在函数空间上工作，我们的方法可以避免一些在 weights 空间上工作时可能会出现的挑战，包括有限扩展性和多模性问题。通过多个实验，我们示出了 bayesian pseudocoresets 由我们的方法构建的uncertainty quantification和模型 Architecture 的多样性均有所提高。
</details></li>
</ul>
<hr>
<h2 id="Real-time-Animation-Generation-and-Control-on-Rigged-Models-via-Large-Language-Models"><a href="#Real-time-Animation-Generation-and-Control-on-Rigged-Models-via-Large-Language-Models" class="headerlink" title="Real-time Animation Generation and Control on Rigged Models via Large Language Models"></a>Real-time Animation Generation and Control on Rigged Models via Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17838">http://arxiv.org/abs/2310.17838</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Whalefishin/LLM_animation">https://github.com/Whalefishin/LLM_animation</a></li>
<li>paper_authors: Han Huang, Fernanda De La Torre, Cathy Mengying Fang, Andrzej Banburski-Fahey, Judith Amores, Jaron Lanier</li>
<li>for: 这个论文是用于实时动画控制和生成的新方法的介绍，使用自然语言输入控制RIGGED模型。</li>
<li>methods: 论文使用了一个大型语言模型（LLM），将其嵌入在Unity中，以输出结构化文本，并将其解析成多种真实的动画。</li>
<li>results: 论文展示了LLM的潜在性，可以实现动画状态的灵活转换，并通过许多RIGGED模型和动作的质量验证了该方法的稳定性。<details>
<summary>Abstract</summary>
We introduce a novel method for real-time animation control and generation on rigged models using natural language input. First, we embed a large language model (LLM) in Unity to output structured texts that can be parsed into diverse and realistic animations. Second, we illustrate LLM's potential to enable flexible state transition between existing animations. We showcase the robustness of our approach through qualitative results on various rigged models and motions.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种新的实时动画控制和生成技术，使用自然语言输入控制着带有骨架的模型。首先，我们将大型语言模型（LLM）引入Unity中，以输出结构化的文本，并将其解析成多种真实和生动的动画。其次，我们展示了LLM的潜在能力，可以实现动画状态的灵活转换 между已有的动画。我们通过对不同的带有骨架和动作的模型和动画进行质量检测，证明了我们的方法的稳定性和可靠性。
</details></li>
</ul>
<hr>
<h2 id="One-Style-is-All-you-Need-to-Generate-a-Video"><a href="#One-Style-is-All-you-Need-to-Generate-a-Video" class="headerlink" title="One Style is All you Need to Generate a Video"></a>One Style is All you Need to Generate a Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17835">http://arxiv.org/abs/2310.17835</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sandman002/One-Style-is-All-You-Need-to-Generate-a-Video">https://github.com/sandman002/One-Style-is-All-You-Need-to-Generate-a-Video</a></li>
<li>paper_authors: Sandeep Manandhar, Auguste Genovesio</li>
<li>for: 这个论文旨在提出一种基于风格的条件视频生成模型，以及一种新的时间生成器，它基于一组学习的振荡基。</li>
<li>methods: 该方法使用了一种新的时间生成器，基于学习的振荡基，来学习动作的动态表示，这些表示独立于图像内容，可以在不同的演员之间传递。</li>
<li>results: 论文表明，该方法可以对视频质量进行显著提高，并且可以独立地 manipulate 动作和内容，以及进行时间GAN-反转，从一个内容或身份中恢复和传输视频动作。<details>
<summary>Abstract</summary>
In this paper, we propose a style-based conditional video generative model. We introduce a novel temporal generator based on a set of learned sinusoidal bases. Our method learns dynamic representations of various actions that are independent of image content and can be transferred between different actors. Beyond the significant enhancement of video quality compared to prevalent methods, we demonstrate that the disentangled dynamic and content permit their independent manipulation, as well as temporal GAN-inversion to retrieve and transfer a video motion from one content or identity to another without further preprocessing such as landmark points.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种基于风格的条件视频生成模型。我们引入了一种基于学习的振荡基函数，用于学习不同动作的动态表示。我们的方法可以独立地 manipulate 动作表示，并且可以在不同的演员身上传递。除了与常见方法相比带来显著改善的视频质量之外，我们还示出了独立地执行动作和内容的权限，以及时间GAN-反转来重新处理和传输视频动作。Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Ontology-Revision-based-on-Pre-trained-Language-Models"><a href="#Ontology-Revision-based-on-Pre-trained-Language-Models" class="headerlink" title="Ontology Revision based on Pre-trained Language Models"></a>Ontology Revision based on Pre-trained Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18378">http://arxiv.org/abs/2310.18378</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiu Ji, Guilin Qi, Yuxin Ye, Jiaye Li, Site Li, Jianjie Ren, Songtao Lu</li>
<li>for: 本研究旨在提出一种基于预训练模型的 ontology 修订算法，以解决 unsatisfiable 概念的问题。</li>
<li>methods: 本研究使用了 various 的 ontology 修订方法，包括定义 revision 算子和设计排名策略，以及使用 pre-trained 模型来编码 axiom  semantics。</li>
<li>results: 根据实验结果，本研究的算法可以达到了 promising 的性能，而 adapted 修订算法可以大幅提高效率，最多可以Save 96% 的时间。此外，一些 scoring functions 可以帮助修订算法在很多情况下获得更好的结果。<details>
<summary>Abstract</summary>
Ontology revision aims to seamlessly incorporate new information into an existing ontology and plays a crucial role in tasks such as ontology evolution, ontology maintenance, and ontology alignment. Similar to repair single ontologies, resolving logical incoherence in the task of ontology revision is also important and meaningful since incoherence is a main potential factor to cause inconsistency and reasoning with an inconsistent ontology will obtain meaningless answers. To deal with this problem, various ontology revision methods have been proposed to define revision operators and design ranking strategies for axioms in an ontology. However, they rarely consider axiom semantics which provides important information to differentiate axioms. On the other hand, pre-trained models can be utilized to encode axiom semantics, and have been widely applied in many natural language processing tasks and ontology-related ones in recent years. Therefore, in this paper, we define four scoring functions to rank axioms based on a pre-trained model by considering various information from a rebuttal ontology and its corresponding reliable ontology. Based on such a scoring function, we propose an ontology revision algorithm to deal with unsatisfiable concepts at once. If it is hard to resolve all unsatisfiable concepts in a rebuttal ontology together, an adapted revision algorithm is designed to deal with them group by group. We conduct experiments over 19 ontology pairs and compare our algorithms and scoring functions with existing ones. According to the experiments, it shows that our algorithms could achieve promising performance. The adapted revision algorithm could improve the efficiency largely, and at most 96% time could be saved for some ontology pairs. Some of our scoring functions help a revision algorithm obtain better results in many cases, especially for the challenging pairs.
</details>
<details>
<summary>摘要</summary>
ontology revision aims to seamlessly incorporate new information into an existing ontology and plays a crucial role in tasks such as ontology evolution, ontology maintenance, and ontology alignment. similar to repairing single ontologies, resolving logical incoherence in the task of ontology revision is also important and meaningful, as incoherence is a main potential factor that can cause inconsistency, and reasoning with an inconsistent ontology will obtain meaningless answers. to deal with this problem, various ontology revision methods have been proposed to define revision operators and design ranking strategies for axioms in an ontology. however, they rarely consider axiom semantics, which provides important information to differentiate axioms. on the other hand, pre-trained models can be utilized to encode axiom semantics, and have been widely applied in many natural language processing tasks and ontology-related ones in recent years. therefore, in this paper, we define four scoring functions to rank axioms based on a pre-trained model by considering various information from a rebuttal ontology and its corresponding reliable ontology. based on such a scoring function, we propose an ontology revision algorithm to deal with unsatisfiable concepts at once. if it is hard to resolve all unsatisfiable concepts in a rebuttal ontology together, an adapted revision algorithm is designed to deal with them group by group. we conduct experiments over 19 ontology pairs and compare our algorithms and scoring functions with existing ones. according to the experiments, it shows that our algorithms could achieve promising performance. the adapted revision algorithm could improve the efficiency largely, and at most 96% time could be saved for some ontology pairs. some of our scoring functions help a revision algorithm obtain better results in many cases, especially for the challenging pairs.
</details></li>
</ul>
<hr>
<h2 id="Large-scale-Foundation-Models-and-Generative-AI-for-BigData-Neuroscience"><a href="#Large-scale-Foundation-Models-and-Generative-AI-for-BigData-Neuroscience" class="headerlink" title="Large-scale Foundation Models and Generative AI for BigData Neuroscience"></a>Large-scale Foundation Models and Generative AI for BigData Neuroscience</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18377">http://arxiv.org/abs/2310.18377</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ran Wang, Zhe Sage Chen</li>
<li>for: 该论文探讨了基础模型和生成人工智能模型在神经科学中的应用，包括自然语言和语音、 semantics 记忆、神经机器 interfaces（BMIs）和数据扩展。</li>
<li>methods: 该论文使用了自动学习（SSL）和传输学习来描述基础模型和生成 AI 模型的应用。</li>
<li>results: 该论文 argued that this paradigm-shift framework will open new avenues for many neuroscience research directions and discuss the accompanying challenges and opportunities.I hope that helps!<details>
<summary>Abstract</summary>
Recent advances in machine learning have made revolutionary breakthroughs in computer games, image and natural language understanding, and scientific discovery. Foundation models and large-scale language models (LLMs) have recently achieved human-like intelligence thanks to BigData. With the help of self-supervised learning (SSL) and transfer learning, these models may potentially reshape the landscapes of neuroscience research and make a significant impact on the future. Here we present a mini-review on recent advances in foundation models and generative AI models as well as their applications in neuroscience, including natural language and speech, semantic memory, brain-machine interfaces (BMIs), and data augmentation. We argue that this paradigm-shift framework will open new avenues for many neuroscience research directions and discuss the accompanying challenges and opportunities.
</details>
<details>
<summary>摘要</summary>
Recent advances in machine learning have led to significant breakthroughs in computer games, image and natural language understanding, and scientific discovery. The development of foundation models and large-scale language models (LLMs) has achieved human-like intelligence, thanks to the power of BigData. With the help of self-supervised learning (SSL) and transfer learning, these models have the potential to reshape the landscapes of neuroscience research and have a profound impact on the future.In this mini-review, we will explore recent advances in foundation models and generative AI models, as well as their applications in neuroscience. We will discuss the use of these models in natural language and speech, semantic memory, brain-machine interfaces (BMIs), and data augmentation. We argue that this paradigm-shift framework will open new avenues for many neuroscience research directions and discuss the accompanying challenges and opportunities.Foundation Models and Generative AI ModelsFoundation models and generative AI models have been instrumental in achieving human-like intelligence in various fields. These models are trained on large datasets and use self-supervised learning techniques to learn the underlying patterns and relationships in the data. Once trained, these models can be fine-tuned for specific tasks, such as natural language processing, image recognition, and speech recognition.Applications in Neuroscience1. Natural Language and Speech: Foundation models and generative AI models have been used to develop advanced natural language processing systems that can understand and generate human-like language. These systems have numerous applications in neuroscience, such as analyzing large amounts of text data to identify patterns and trends, and generating natural language descriptions of complex scientific concepts.2. Semantic Memory: These models can be used to develop advanced memory systems that can store and retrieve large amounts of information. This has numerous applications in neuroscience, such as developing systems that can remember and recall complex scientific concepts and theories.3. Brain-Machine Interfaces (BMIs): Foundation models and generative AI models can be used to develop advanced BMIs that can read and interpret brain signals. This has numerous applications in neuroscience, such as developing systems that can decode brain signals to control prosthetic limbs and other assistive technologies.4. Data Augmentation: These models can be used to generate large amounts of synthetic data that can be used to augment real-world datasets. This has numerous applications in neuroscience, such as developing systems that can generate synthetic brain imaging data to augment real-world datasets and improve the accuracy of brain imaging techniques.Challenges and OpportunitiesWhile foundation models and generative AI models have the potential to revolutionize neuroscience research, there are several challenges and opportunities that must be addressed. Some of the challenges include:1. Data Quality: The quality of the data used to train these models is crucial. Poor-quality data can lead to biased or inaccurate models.2. Explainability: It is often difficult to understand how these models make decisions, which can be a problem in fields such as neuroscience where transparency and explainability are essential.3. Ethics: The use of these models raises ethical concerns, such as the potential for bias and the impact on employment.4. Training Time: Training these models can be time-consuming and computationally intensive.Despite these challenges, the opportunities presented by foundation models and generative AI models are significant. With the right training data and the appropriate fine-tuning, these models have the potential to revolutionize neuroscience research and lead to significant advances in our understanding of the brain and nervous system.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/27/cs.AI_2023_10_27/" data-id="cloh7tqcn00677b88eeep4r8q" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_10_27" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/10/27/cs.CL_2023_10_27/" class="article-date">
  <time datetime="2023-10-27T11:00:00.000Z" itemprop="datePublished">2023-10-27</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/10/27/cs.CL_2023_10_27/">cs.CL - 2023-10-27</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Evaluating-Cross-Domain-Text-to-SQL-Models-and-Benchmarks"><a href="#Evaluating-Cross-Domain-Text-to-SQL-Models-and-Benchmarks" class="headerlink" title="Evaluating Cross-Domain Text-to-SQL Models and Benchmarks"></a>Evaluating Cross-Domain Text-to-SQL Models and Benchmarks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18538">http://arxiv.org/abs/2310.18538</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammadreza Pourreza, Davood Rafiei</li>
<li>for: 本研究目的是evaluating the performance of text-to-SQL models on several prominent cross-domain benchmarks, and re-evaluating top-performing models to assess their true performance.</li>
<li>methods: 该研究使用了 manual evaluation and equivalent expression rewriting to evaluate the SQL queries and models.</li>
<li>results: 研究发现，due to the multiple interpretations of the provided samples, attaining a perfect performance on these benchmarks is unfeasible.  additionally, the true performance of the models was underestimated, and their relative performance changed after re-evaluation. Most notably, a recent GPT4-based model surpassed the gold standard reference queries in the Spider benchmark in human evaluation, highlighting the importance of interpreting benchmark evaluations cautiously.<details>
<summary>Abstract</summary>
Text-to-SQL benchmarks play a crucial role in evaluating the progress made in the field and the ranking of different models. However, accurately matching a model-generated SQL query to a reference SQL query in a benchmark fails for various reasons, such as underspecified natural language queries, inherent assumptions in both model-generated and reference queries, and the non-deterministic nature of SQL output under certain conditions. In this paper, we conduct an extensive study of several prominent cross-domain text-to-SQL benchmarks and re-evaluate some of the top-performing models within these benchmarks, by both manually evaluating the SQL queries and rewriting them in equivalent expressions. Our evaluation reveals that attaining a perfect performance on these benchmarks is unfeasible due to the multiple interpretations that can be derived from the provided samples. Furthermore, we find that the true performance of the models is underestimated and their relative performance changes after a re-evaluation. Most notably, our evaluation reveals a surprising discovery: a recent GPT4-based model surpasses the gold standard reference queries in the Spider benchmark in our human evaluation. This finding highlights the importance of interpreting benchmark evaluations cautiously, while also acknowledging the critical role of additional independent evaluations in driving advancements in the field.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="On-the-Automatic-Generation-and-Simplification-of-Children’s-Stories"><a href="#On-the-Automatic-Generation-and-Simplification-of-Children’s-Stories" class="headerlink" title="On the Automatic Generation and Simplification of Children’s Stories"></a>On the Automatic Generation and Simplification of Children’s Stories</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18502">http://arxiv.org/abs/2310.18502</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maria Valentini, Jennifer Weber, Jesus Salcido, Téa Wright, Eliana Colunga, Katharina Kann</li>
<li>for: 这个研究的目的是开发一个自动生成儿童教育材料的系统，以提高儿童的学习效果。</li>
<li>methods: 研究者使用了一些流行的大语言模型（LLMs）来生成儿童教育材料，并评估了这些模型的 lexical 和 readability 水平是否适合儿童。</li>
<li>results: 研究者发现，虽然 LLMs 的能力在不断提高，但它们目前还没有能力限制自己的词汇水平适合更年轻的儿童。在第二个实验中，研究者explored the ability of state-of-the-art lexical simplification models to generalize to the domain of children’s stories, and created an efficient pipeline for their automatic generation.<details>
<summary>Abstract</summary>
With recent advances in large language models (LLMs), the concept of automatically generating children's educational materials has become increasingly realistic. Working toward the goal of age-appropriate simplicity in generated educational texts, we first examine the ability of several popular LLMs to generate stories with properly adjusted lexical and readability levels. We find that, in spite of the growing capabilities of LLMs, they do not yet possess the ability to limit their vocabulary to levels appropriate for younger age groups. As a second experiment, we explore the ability of state-of-the-art lexical simplification models to generalize to the domain of children's stories and, thus, create an efficient pipeline for their automatic generation. In order to test these models, we develop a dataset of child-directed lexical simplification instances, with examples taken from the LLM-generated stories in our first experiment. We find that, while the strongest-performing current lexical simplification models do not perform as well on material designed for children due to their reliance on large language models behind the scenes, some models that still achieve fairly strong results on general data can mimic or even improve their performance on children-directed data with proper fine-tuning, which we conduct using our newly created child-directed simplification dataset.
</details>
<details>
<summary>摘要</summary>
As a second experiment, we explore the ability of state-of-the-art lexical simplification models to generalize to the domain of children's stories. We develop a dataset of child-directed lexical simplification instances, using examples from the LLM-generated stories in our first experiment. We find that while the strongest-performing current lexical simplification models do not perform as well on material designed for children, some models that achieve strong results on general data can mimic or even improve their performance on children-directed data with proper fine-tuning.我们使用最新的大语言模型（LLMs），目标是自动生成儿童教育材料。为了实现适合不同年龄层的简化，我们首先评估各种流行的LLMs是否能够自动生成适合不同年龄层的故事。我们发现，虽然LLMs在过去几年内做出了很大的进步，但它们还没有拥有适合儿童年龄层的词汇量。作为第二个实验，我们研究了当前最佳的 lexical simplification 模型是否能够在儿童故事领域得到普遍化。我们开发了一个儿童指向的 lexical simplification 示例集，其中的例子来自我们的第一个实验中的 LLM-生成的故事。我们发现，当前最强的 lexical simplification 模型在面向儿童的数据上表现不如其他数据上，这是因为它们在后台使用大语言模型。但是，一些在普遍数据上表现良好的模型可以通过我们的特制的儿童指向的简化示例集进行细化，从而实现良好的表现。
</details></li>
</ul>
<hr>
<h2 id="Publicly-Detectable-Watermarking-for-Language-Models"><a href="#Publicly-Detectable-Watermarking-for-Language-Models" class="headerlink" title="Publicly Detectable Watermarking for Language Models"></a>Publicly Detectable Watermarking for Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18491">http://arxiv.org/abs/2310.18491</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jaiden Fairoze, Sanjam Garg, Somesh Jha, Saeed Mahloujifar, Mohammad Mahmoody, Mingyuan Wang</li>
<li>for: 本研究旨在构建可证明的语音模型水印方案，以便在公共可读性或可靠性下进行证明。</li>
<li>methods: 本研究使用私钥进行水印，并使用公钥进行水印检测。我们的协议是首个不嵌入生成文本中的统计信号的语音模型水印方案，而是直接使用拒绝抽样来嵌入公共可靠性的 криптографиic signature。我们证明了我们的建构符合强式形式安全保证和私钥水印中的多个欢迎性特性。</li>
<li>results: 我们的水印方案在7B参数范围内进行实验，并证明了我们的正式声明。我们的实验结果表明，我们的水印方案可以保持文本质量，同时符合正式要求。<details>
<summary>Abstract</summary>
We construct the first provable watermarking scheme for language models with public detectability or verifiability: we use a private key for watermarking and a public key for watermark detection. Our protocol is the first watermarking scheme that does not embed a statistical signal in generated text. Rather, we directly embed a publicly-verifiable cryptographic signature using a form of rejection sampling. We show that our construction meets strong formal security guarantees and preserves many desirable properties found in schemes in the private-key watermarking setting. In particular, our watermarking scheme retains distortion-freeness and model agnosticity. We implement our scheme and make empirical measurements over open models in the 7B parameter range. Our experiments suggest that our watermarking scheme meets our formal claims while preserving text quality.
</details>
<details>
<summary>摘要</summary>
我们构建了首个可证明的文本标记 schemes for 语言模型，其中使用私钥进行标记并使用公钥进行标记检测。我们的协议是首个不在生成的文本中嵌入统计信号的 watermarking  schemes，而是直接使用拒绝抽象来嵌入公共可验证的 криптографиic 签名。我们证明了我们的构建符合强制ormal security guarantees 和 preserve many desirable properties found in private-key watermarking setting。特别是，我们的文本标记 schemes  preserved distortion-freeness 和 model agnosticity。我们实现了我们的协议并对 open models 在 7B 参数范围进行了实验。我们的实验表明，我们的文本标记 schemes 符合我们的ormal claims 而 preserve text quality。
</details></li>
</ul>
<hr>
<h2 id="PeTailor-Improving-Large-Language-Model-by-Tailored-Chunk-Scorer-in-Biomedical-Triple-Extraction"><a href="#PeTailor-Improving-Large-Language-Model-by-Tailored-Chunk-Scorer-in-Biomedical-Triple-Extraction" class="headerlink" title="PeTailor: Improving Large Language Model by Tailored Chunk Scorer in Biomedical Triple Extraction"></a>PeTailor: Improving Large Language Model by Tailored Chunk Scorer in Biomedical Triple Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18463">http://arxiv.org/abs/2310.18463</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingchen Li, M. Chen, Huixue Zhou, Rui Zhang</li>
<li>for: 本研究旨在提高自动抽取生物医学实体和其互动的能力，因为现有的专家标注标准数据集的有限性。</li>
<li>methods: 本研究提出了一种基于检索的语言框架（PETAI-LOR），该框架通过修改chunk scorer来适应语言模型（LM）的特定需求。此外，我们还介绍了一个专家标注的生物医学 triple 抽取数据集（GM-CIHT），该数据集涵盖非药治疗和通用生物医学领域。</li>
<li>results: 我们的实验表明，PETAI-LOR在GM-CIHT上实现了状态 искусственный智能的表现。<details>
<summary>Abstract</summary>
The automatic extraction of biomedical entities and their interaction from unstructured data remains a challenging task due to the limited availability of expert-labeled standard datasets. In this paper, we introduce PETAI-LOR, a retrieval-based language framework that is augmented by tailored chunk scorer. Unlike previous retrieval-augmented language models (LM) that retrieve relevant documents by calculating the similarity between the input sentence and the candidate document set, PETAILOR segments the sentence into chunks and retrieves the relevant chunk from our pre-computed chunk-based relational key-value memory. Moreover, in order to comprehend the specific requirements of the LM, PETAI-LOR adapt the tailored chunk scorer to the LM. We also introduce GM-CIHT, an expert annotated biomedical triple extraction dataset with more relation types. This dataset is centered on the non-drug treatment and general biomedical domain. Additionally, we investigate the efficacy of triple extraction models trained on general domains when applied to the biomedical domain. Our experiments reveal that PETAI-LOR achieves state-of-the-art performance on GM-CIHT
</details>
<details>
<summary>摘要</summary>
自动提取生物医学实体和其交互从未结构化数据中 Remains 是一个挑战性的任务，因为专家标注标准数据集的可用性有限。在本文中，我们介绍 PETAI-LOR，一种基于检索的语言框架，该框架通过专门设计的块分词器进行增强。与过去的检索增强语言模型（LM）不同，PETAI-LOR 不是通过计算输入句子和候选文档集之间的相似性来 Retrieval 相关文档，而是通过将句子分成块，然后从我们预计算出的块基于关键值对存储中提取相关块。此外，为了适应特定的LM要求，PETAI-LOR 可以根据LM进行适应tailored块评分器。我们还介绍了GM-CIHT，一个专家标注的生物医学三元EXTRACT数据集，该数据集涵盖非药治疗和普通生物医学领域。此外，我们还调查了将生物医学领域应用于通用领域提取模型的可行性。我们的实验表明，PETAI-LOR 在GM-CIHT上实现了状态机器人的表现。
</details></li>
</ul>
<hr>
<h2 id="Do-Not-Harm-Protected-Groups-in-Debiasing-Language-Representation-Models"><a href="#Do-Not-Harm-Protected-Groups-in-Debiasing-Language-Representation-Models" class="headerlink" title="Do Not Harm Protected Groups in Debiasing Language Representation Models"></a>Do Not Harm Protected Groups in Debiasing Language Representation Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18458">http://arxiv.org/abs/2310.18458</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chloe Qinyu Zhu, Rickard Stureborg, Brandon Fain</li>
<li>for: 这篇论文旨在探讨语言模型中的偏见和不公平对待，以及如何透过干预技术解除偏见。</li>
<li>methods: 本论文使用了四种干预技术，包括word embeddings、 adversarial training、 debiasing word embeddings和 adversarial debiasing。</li>
<li>results: 研究发现，干预技术可以减少偏见，但是这些技术可能会对保护的群体造成不良影响，包括性别、种族和年龄等。<details>
<summary>Abstract</summary>
Language Representation Models (LRMs) trained with real-world data may capture and exacerbate undesired bias and cause unfair treatment of people in various demographic groups. Several techniques have been investigated for applying interventions to LRMs to remove bias in benchmark evaluations on, for example, word embeddings. However, the negative side effects of debiasing interventions are usually not revealed in the downstream tasks. We propose xGAP-DEBIAS, a set of evaluations on assessing the fairness of debiasing. In this work, We examine four debiasing techniques on a real-world text classification task and show that reducing biasing is at the cost of degrading performance for all demographic groups, including those the debiasing techniques aim to protect. We advocate that a debiasing technique should have good downstream performance with the constraint of ensuring no harm to the protected group.
</details>
<details>
<summary>摘要</summary>
语言表示模型（LRM）通过实际数据训练可能捕捉和增强不良偏见，导致各种人口组群体受到不公正待遇。一些技术已经研究了对LRMs进行修正以去除偏见，但这些修正的负面影响通常不会在下游任务中表现出来。我们提出xGAP-DEBIAS，一种评估去偏见的评价方法。在这种工作中，我们研究了一个真实世界文本分类任务中四种去偏见技术，并显示了减少偏见的代价是对所有人口组群体，包括被保护的群体，进行性能下降。我们强调，一种去偏见技术应该在保证不会对保护的群体造成伤害的前提下保持良好的下游性能。
</details></li>
</ul>
<hr>
<h2 id="T5-meets-Tybalt-Author-Attribution-in-Early-Modern-English-Drama-Using-Large-Language-Models"><a href="#T5-meets-Tybalt-Author-Attribution-in-Early-Modern-English-Drama-Using-Large-Language-Models" class="headerlink" title="T5 meets Tybalt: Author Attribution in Early Modern English Drama Using Large Language Models"></a>T5 meets Tybalt: Author Attribution in Early Modern English Drama Using Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18454">http://arxiv.org/abs/2310.18454</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rebecca M. M. Hicke, David Mimno</li>
<li>for: 这个论文探讨了大语言模型在文学领域中的应用，具体来说是用于早期现代英语戏剧作者识别。</li>
<li>methods: 这个论文使用了一个精度调整后的t5-large模型，并对几种基线模型进行比较，包括逻辑回归、支持向量机和归一化delta。</li>
<li>results: 研究发现，这个精度调整后的t5-large模型在小段文本识别作者方面表现出色，并且超过了所有测试基线模型。然而，研究还发现了一些作者在模型的预训练数据中的存在对预测结果产生了困难评估的影响。<details>
<summary>Abstract</summary>
Large language models have shown breakthrough potential in many NLP domains. Here we consider their use for stylometry, specifically authorship identification in Early Modern English drama. We find both promising and concerning results; LLMs are able to accurately predict the author of surprisingly short passages but are also prone to confidently misattribute texts to specific authors. A fine-tuned t5-large model outperforms all tested baselines, including logistic regression, SVM with a linear kernel, and cosine delta, at attributing small passages. However, we see indications that the presence of certain authors in the model's pre-training data affects predictive results in ways that are difficult to assess.
</details>
<details>
<summary>摘要</summary>
大型语言模型在许多自然语言处理领域中显示出了突破性潜力。我们在这里考虑使用这些模型来进行类型推断，具体而言是在 Early Modern English drama 中进行作者识别。我们发现了一些有希望的结果，以及一些担心的结果：大型语言模型能够对短段文本准确地预测作者，但也容易将文本错误归属给特定的作者。我们发现了一些证据表明模型的预设数据中的作者存在影响预测结果的方式，但这些影响难以评估。
</details></li>
</ul>
<hr>
<h2 id="Modeling-Legal-Reasoning-LM-Annotation-at-the-Edge-of-Human-Agreement"><a href="#Modeling-Legal-Reasoning-LM-Annotation-at-the-Edge-of-Human-Agreement" class="headerlink" title="Modeling Legal Reasoning: LM Annotation at the Edge of Human Agreement"></a>Modeling Legal Reasoning: LM Annotation at the Edge of Human Agreement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18440">http://arxiv.org/abs/2310.18440</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rosamond Thalken, Edward H. Stiglitz, David Mimno, Matthew Wilkens</li>
<li>for: 法律逻辑分析的 классификация，即法律哲学分析。</li>
<li>methods: 使用生成语言模型（LMs）进行文档分类任务，并对不同的LM模型进行系统性测试。</li>
<li>results: 发现生成模型在不受 instrucion（i.e. 提示）的情况下表现不佳，但是在对标注过的数据集进行微调后，得到了最佳的结果，并通过应用这些预测来研究历史时期的法律哲学趋势，这与知名的历史质量论相一致，同时还指出了一些可能需要进一步修正的方面。<details>
<summary>Abstract</summary>
Generative language models (LMs) are increasingly used for document class-prediction tasks and promise enormous improvements in cost and efficiency. Existing research often examines simple classification tasks, but the capability of LMs to classify on complex or specialized tasks is less well understood. We consider a highly complex task that is challenging even for humans: the classification of legal reasoning according to jurisprudential philosophy. Using a novel dataset of historical United States Supreme Court opinions annotated by a team of domain experts, we systematically test the performance of a variety of LMs. We find that generative models perform poorly when given instructions (i.e. prompts) equal to the instructions presented to human annotators through our codebook. Our strongest results derive from fine-tuning models on the annotated dataset; the best performing model is an in-domain model, LEGAL-BERT. We apply predictions from this fine-tuned model to study historical trends in jurisprudence, an exercise that both aligns with prominent qualitative historical accounts and points to areas of possible refinement in those accounts. Our findings generally sound a note of caution in the use of generative LMs on complex tasks without fine-tuning and point to the continued relevance of human annotation-intensive classification methods.
</details>
<details>
<summary>摘要</summary>
现代生成语言模型（LMs）在文档分类任务中越来越受到广泛使用，承诺可以大幅提高成本和效率。现有研究通常研究简单的分类任务，但生成模型在复杂或专业化任务上的能力更少被了解。我们考虑了一个非常复杂的任务：用法律哲学来分类法律理解。使用一个新的历史美国最高法院判决 opacity 的注释者队伍编制的数据集，我们系统地测试了多种LMs的性能。我们发现，当给生成模型提供相同的指令（i.e. 提示）时，生成模型表现很差。我们最好的结果来自于在注释过的数据集上练习模型，最佳表现的模型是适应于法律领域的 LEGAL-BERT。我们使用这个练习后的模型进行历史趋势的研究，这与著名的qualitative历史质量相符，并指出了可能的改进点。我们的发现通常表达了对生成LMs在复杂任务中无需练习的使用存在警告，并指出了人工注释Intensive分类方法的持续 relevance。
</details></li>
</ul>
<hr>
<h2 id="Expanding-the-Set-of-Pragmatic-Considerations-in-Conversational-AI"><a href="#Expanding-the-Set-of-Pragmatic-Considerations-in-Conversational-AI" class="headerlink" title="Expanding the Set of Pragmatic Considerations in Conversational AI"></a>Expanding the Set of Pragmatic Considerations in Conversational AI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18435">http://arxiv.org/abs/2310.18435</a></li>
<li>repo_url: None</li>
<li>paper_authors: S. M. Seals, Valerie L. Shalin</li>
<li>for: 这篇论文主要是为了探讨当前对话AI系统的表现有多好，却未能满足用户的需求。</li>
<li>methods: 论文提出了一些实用上的限制，并通过示例表明了这些限制的缺陷。</li>
<li>results: 论文提出了一种类型化的对话AI系统的设计和评估方法，以解决现有系统的实用上的缺陷。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Despite considerable performance improvements, current conversational AI systems often fail to meet user expectations. We discuss several pragmatic limitations of current conversational AI systems. We illustrate pragmatic limitations with examples that are syntactically appropriate, but have clear pragmatic deficiencies. We label our complaints as "Turing Test Triggers" (TTTs) as they indicate where current conversational AI systems fall short compared to human behavior. We develop a taxonomy of pragmatic considerations intended to identify what pragmatic competencies a conversational AI system requires and discuss implications for the design and evaluation of conversational AI systems.
</details>
<details>
<summary>摘要</summary>
尽管现有的对话AI系统已经做出了很大的表现改进，但它们仍然不能满足用户的期望。我们讨论了现有对话AI系统的各种各样的限制。我们使用合适的语法示例来 illustrate these limitations, but these examples have clear pragmatic deficiencies. 我们称这些问题为“图灵测试触发器”（TTTs），因为它们表明现有的对话AI系统与人类行为相比存在着缺陷。我们开发了对话AI系统的pragma考虑的分类，以确定这些系统所需的pragma能力，并讨论了这些分类的影响对对话AI系统的设计和评估。
</details></li>
</ul>
<hr>
<h2 id="SDOH-NLI-a-Dataset-for-Inferring-Social-Determinants-of-Health-from-Clinical-Notes"><a href="#SDOH-NLI-a-Dataset-for-Inferring-Social-Determinants-of-Health-from-Clinical-Notes" class="headerlink" title="SDOH-NLI: a Dataset for Inferring Social Determinants of Health from Clinical Notes"></a>SDOH-NLI: a Dataset for Inferring Social Determinants of Health from Clinical Notes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18431">http://arxiv.org/abs/2310.18431</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adam D. Lelkes, Eric Loreaux, Tal Schuster, Ming-Jun Chen, Alvin Rajkomar</li>
<li>for: This paper aims to provide a new dataset for natural language inference (NLI) tasks to extract social and behavioral determinants of health (SDOH) from clinical notes.</li>
<li>methods: The paper uses a dataset of publicly available clinical notes and formulates SDOH extraction as an NLI task, with binary textual entailment labels obtained from human raters.</li>
<li>results: The authors evaluate both “off-the-shelf” entailment models and models fine-tuned on their data, and find that their dataset appears more challenging than commonly used NLI datasets.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文的目的是提供一个新的自然语言推理（NLI）任务，以提取医疗记录中的社会和行为Determinants of health（SDOH）。</li>
<li>methods: 论文使用了公共可用的医疗记录数据集，将SDOH抽取作为NLI任务，并使用人工评分者提供的二分文本推理标签。</li>
<li>results: 作者评估了一些“卖在架”的推理模型以及特定于其数据集的模型，并发现其数据集与常用的NLI数据集相比更加具有挑战性。<details>
<summary>Abstract</summary>
Social and behavioral determinants of health (SDOH) play a significant role in shaping health outcomes, and extracting these determinants from clinical notes is a first step to help healthcare providers systematically identify opportunities to provide appropriate care and address disparities. Progress on using NLP methods for this task has been hindered by the lack of high-quality publicly available labeled data, largely due to the privacy and regulatory constraints on the use of real patients' information. This paper introduces a new dataset, SDOH-NLI, that is based on publicly available notes and which we release publicly. We formulate SDOH extraction as a natural language inference (NLI) task, and provide binary textual entailment labels obtained from human raters for a cross product of a set of social history snippets as premises and SDOH factors as hypotheses. Our dataset differs from standard NLI benchmarks in that our premises and hypotheses are obtained independently. We evaluate both "off-the-shelf" entailment models as well as models fine-tuned on our data, and highlight the ways in which our dataset appears more challenging than commonly used NLI datasets.
</details>
<details>
<summary>摘要</summary>
社会和行为determinants of health (SDOH) play a significant role in shaping health outcomes, and extracting these determinants from clinical notes is a first step to help healthcare providers systematically identify opportunities to provide appropriate care and address disparities. Progress on using NLP methods for this task has been hindered by the lack of high-quality publicly available labeled data, largely due to the privacy and regulatory constraints on the use of real patients' information. This paper introduces a new dataset, SDOH-NLI, that is based on publicly available notes and which we release publicly. We formulate SDOH extraction as a natural language inference (NLI) task, and provide binary textual entailment labels obtained from human raters for a cross product of a set of social history snippets as premises and SDOH factors as hypotheses. Our dataset differs from standard NLI benchmarks in that our premises and hypotheses are obtained independently. We evaluate both "off-the-shelf" entailment models as well as models fine-tuned on our data, and highlight the ways in which our dataset appears more challenging than commonly used NLI datasets.Here's the translation in Traditional Chinese:社会和行为determinants of health (SDOH) play a significant role in shaping health outcomes, and extracting these determinants from clinical notes is a first step to help healthcare providers systematically identify opportunities to provide appropriate care and address disparities. Progress on using NLP methods for this task has been hindered by the lack of high-quality publicly available labeled data, largely due to the privacy and regulatory constraints on the use of real patients' information. This paper introduces a new dataset, SDOH-NLI, that is based on publicly available notes and which we release publicly. We formulate SDOH extraction as a natural language inference (NLI) task, and provide binary textual entailment labels obtained from human raters for a cross product of a set of social history snippets as premises and SDOH factors as hypotheses. Our dataset differs from standard NLI benchmarks in that our premises and hypotheses are obtained independently. We evaluate both "off-the-shelf" entailment models as well as models fine-tuned on our data, and highlight the ways in which our dataset appears more challenging than commonly used NLI datasets.
</details></li>
</ul>
<hr>
<h2 id="Teacher-Perception-of-Automatically-Extracted-Grammar-Concepts-for-L2-Language-Learning"><a href="#Teacher-Perception-of-Automatically-Extracted-Grammar-Concepts-for-L2-Language-Learning" class="headerlink" title="Teacher Perception of Automatically Extracted Grammar Concepts for L2 Language Learning"></a>Teacher Perception of Automatically Extracted Grammar Concepts for L2 Language Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18417">http://arxiv.org/abs/2310.18417</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aditi Chaudhary, Arun Sampath, Ashwin Sheshadri, Antonios Anastasopoulos, Graham Neubig</li>
<li>for: 这个研究的目的是为了帮助创建语言教学课程，尤其是 для那些没有充分的资源和专业知识的教师。</li>
<li>methods: 这篇论文使用自然语言文库来自动发现和可见化语法描述。它使用文本来回答 morphosyntax 和 semantics 问题，以帮助教师更好地教授印度语言 kannada 和 marathi。</li>
<li>results: 这篇论文的结果表明，使用自然语言文库来自动发现和可见化语法描述可以帮助教师更好地创建语言教学课程，并且这些材料被教育专业人员评估为有用。<details>
<summary>Abstract</summary>
One of the challenges in language teaching is how best to organize rules regarding syntax, semantics, or phonology in a meaningful manner. This not only requires content creators to have pedagogical skills, but also have that language's deep understanding. While comprehensive materials to develop such curricula are available in English and some broadly spoken languages, for many other languages, teachers need to manually create them in response to their students' needs. This is challenging because i) it requires that such experts be accessible and have the necessary resources, and ii) describing all the intricacies of a language is time-consuming and prone to omission. In this work, we aim to facilitate this process by automatically discovering and visualizing grammar descriptions. We extract descriptions from a natural text corpus that answer questions about morphosyntax (learning of word order, agreement, case marking, or word formation) and semantics (learning of vocabulary). We apply this method for teaching two Indian languages, Kannada and Marathi, which, unlike English, do not have well-developed resources for second language learning. To assess the perceived utility of the extracted material, we enlist the help of language educators from schools in North America to perform a manual evaluation, who find the materials have potential to be used for their lesson preparation and learner evaluation.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:一个挑战在语言教学中是如何有效地组织语法、 semantics 或音律规则的方式。这不仅需要内容创作人具备教学技能，还需要对这种语言有深刻的理解。而且，为了开发这些课程资料，英语和一些广泛使用的语言有相关的资源，但对于其他语言，教师需要手动创建响应学生需求的资料。这是因为i) 需要访问这些专家和有必要的资源，ii) 描述语言的细节是时间consuming 和易于缺少。在这个工作中，我们希望通过自动发现和视觉化语法描述来促进这个过程。我们从自然文本 corpus 中提取描述，回答有关 morphosyntax （学习word order、一致、格emarking 或 word formation）和 semantics （学习词汇）的问题。我们对几种印度语言，如 kannada 和 Marathi 进行应用，这些语言与英语不同，没有很好的第二语言学习资源。为了评估提取的材料的实际用途，我们征得北美语言教育专业人士的帮助进行手动评估，他们认为这些材料具有教学和学生评估的潜在用途。
</details></li>
</ul>
<hr>
<h2 id="FP8-LM-Training-FP8-Large-Language-Models"><a href="#FP8-LM-Training-FP8-Large-Language-Models" class="headerlink" title="FP8-LM: Training FP8 Large Language Models"></a>FP8-LM: Training FP8 Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18313">http://arxiv.org/abs/2310.18313</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/azure/ms-amp">https://github.com/azure/ms-amp</a></li>
<li>paper_authors: Houwen Peng, Kan Wu, Yixuan Wei, Guoshuai Zhao, Yuxiang Yang, Ze Liu, Yifan Xiong, Ziyue Yang, Bolin Ni, Jingcheng Hu, Ruihang Li, Miaosen Zhang, Chen Li, Jia Ning, Ruizhe Wang, Zheng Zhang, Shuguang Liu, Joe Chau, Han Hu, Peng Cheng</li>
<li>for: 这个论文探讨FP8低位数据格式在大型自然语言模型（LLM）的高效训练中的应用。</li>
<li>methods: 作者提出了一个新的FP8自动混合精度框架，用于训练LLM模型。这个框架逐渐地使用8位数据格式，包括梯度和优化器状态，以实现混合精度和分布式并行训练。</li>
<li>results: 实验结果显示，在使用GPT-175B模型在H100 GPU平台进行训练时，作者的FP8混合精度训练框架可以实现42%的实际内存使用减少和64%的BF16框架（即Megatron-LM）的运行速度，超过Nvidia Transformer Engine的速度。此外，这种混合精度训练方法可以应用于其他任务，如LLM指令优化和人工回馈学习，从而降低精度训练成本。作者的FP8低精度训练框架已经公开开源于GitHub（<a target="_blank" rel="noopener" href="https://github.com/Azure/MS-AMP">https://github.com/Azure/MS-AMP</a>）。<details>
<summary>Abstract</summary>
In this paper, we explore FP8 low-bit data formats for efficient training of large language models (LLMs). Our key insight is that most variables, such as gradients and optimizer states, in LLM training can employ low-precision data formats without compromising model accuracy and requiring no changes to hyper-parameters. Specifically, we propose a new FP8 automatic mixed-precision framework for training LLMs. This framework offers three levels of FP8 utilization to streamline mixed-precision and distributed parallel training for LLMs. It gradually incorporates 8-bit gradients, optimizer states, and distributed learning in an incremental manner. Experiment results show that, during the training of GPT-175B model on H100 GPU platform, our FP8 mixed-precision training framework not only achieved a remarkable 42% reduction in real memory usage but also ran 64% faster than the widely adopted BF16 framework (i.e., Megatron-LM), surpassing the speed of Nvidia Transformer Engine by 17%. This largely reduces the training costs for large foundation models. Furthermore, our FP8 mixed-precision training methodology is generic. It can be seamlessly applied to other tasks such as LLM instruction tuning and reinforcement learning with human feedback, offering savings in fine-tuning expenses. Our FP8 low-precision training framework is open-sourced at {https://github.com/Azure/MS-AMP}{aka.ms/MS.AMP}.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="An-Approach-to-Automatically-generating-Riddles-aiding-Concept-Attainment"><a href="#An-Approach-to-Automatically-generating-Riddles-aiding-Concept-Attainment" class="headerlink" title="An Approach to Automatically generating Riddles aiding Concept Attainment"></a>An Approach to Automatically generating Riddles aiding Concept Attainment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18290">http://arxiv.org/abs/2310.18290</a></li>
<li>repo_url: None</li>
<li>paper_authors: Niharika Sri Parasa, Chaitali Diwan, Srinath Srinivasa</li>
<li>for: The paper aims to enhance learner engagement in online learning environments by applying the Concept Attainment Model to build conceptual riddles.</li>
<li>methods: The paper uses a combination of natural language processing and the Concept Attainment Model to create factual triples from learning resources, classify them based on their uniqueness to a concept, and generate riddles based on the Concept Attainment Model’s format.</li>
<li>results: The human evaluation of the riddles obtained encouraging results, indicating the effectiveness of the proposed approach in enhancing learner engagement.Here’s the simplified Chinese text for the three information points:</li>
<li>for: 本研究旨在在线学习环境中提高学习者的 engagment，通过应用概念获取模型建立概念游戏。</li>
<li>methods: 本研究使用自然语言处理和概念获取模型将学习资源转换为事实三重，根据概念的唯一性进行分类，并根据概念获取模型的格式生成游戏。</li>
<li>results: 人类评价的结果显示，提案的方法具有吸引学习者的潜力。<details>
<summary>Abstract</summary>
One of the primary challenges in online learning environments, is to retain learner engagement. Several different instructional strategies are proposed both in online and offline environments to enhance learner engagement. The Concept Attainment Model is one such instructional strategy that focuses on learners acquiring a deeper understanding of a concept rather than just its dictionary definition. This is done by searching and listing the properties used to distinguish examples from non-examples of various concepts. Our work attempts to apply the Concept Attainment Model to build conceptual riddles, to deploy over online learning environments. The approach involves creating factual triples from learning resources, classifying them based on their uniqueness to a concept into `Topic Markers' and `Common', followed by generating riddles based on the Concept Attainment Model's format and capturing all possible solutions to those riddles. The results obtained from the human evaluation of riddles prove encouraging.
</details>
<details>
<summary>摘要</summary>
一个主要挑战在在线学习环境中是保持学生的参与度。多种不同的教学策略在在线和OFFLINE环境中被提出，以增强学生的参与度。概念把握模型是一种教学策略，强调学生深入理解概念，而不仅仅是其字面意思。这是通过搜索和列出不同概念的例子和非例子中的特征来实现的。我们尝试将概念把握模型应用于建立概念的谜题，并在在线学习环境中部署。该方法包括从学习资源中提取事实三元组，将其分类为概念的唯一特征和公共特征，然后根据概念把握模型的格式生成谜题，并捕捉所有的解决方案。人工评估结果表明，谜题的效果是有挑战性的。
</details></li>
</ul>
<hr>
<h2 id="MalFake-A-Multimodal-Fake-News-Identification-for-Malayalam-using-Recurrent-Neural-Networks-and-VGG-16"><a href="#MalFake-A-Multimodal-Fake-News-Identification-for-Malayalam-using-Recurrent-Neural-Networks-and-VGG-16" class="headerlink" title="MalFake: A Multimodal Fake News Identification for Malayalam using Recurrent Neural Networks and VGG-16"></a>MalFake: A Multimodal Fake News Identification for Malayalam using Recurrent Neural Networks and VGG-16</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18263">http://arxiv.org/abs/2310.18263</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adhish S. Sujan, Ajitha. V, Aleena Benny, Amiya M. P., V. S. Anoop</li>
<li>for: 这篇研究的目的是为了发展一个能够有效地识别假新闻的模型，尤其是在印度的地方语言中。</li>
<li>methods: 这篇研究使用多modalities的特征提取法和深度学习分类模型来识别假新闻。</li>
<li>results: 这篇研究发现，使用多modalities的特征提取法和深度学习分类模型可以更高度准确地识别假新闻，并且在Malayalam语言中进行了首次实证。<details>
<summary>Abstract</summary>
The amount of news being consumed online has substantially expanded in recent years. Fake news has become increasingly common, especially in regional languages like Malayalam, due to the rapid publication and lack of editorial standards on some online sites. Fake news may have a terrible effect on society, causing people to make bad judgments, lose faith in authorities, and even engage in violent behavior. When we take into the context of India, there are many regional languages, and fake news is spreading in every language. Therefore, providing efficient techniques for identifying false information in regional tongues is crucial. Until now, little to no work has been done in Malayalam, extracting features from multiple modalities to classify fake news. Multimodal approaches are more accurate in detecting fake news, as features from multiple modalities are extracted to build the deep learning classification model. As far as we know, this is the first piece of work in Malayalam that uses multimodal deep learning to tackle false information. Models trained with more than one modality typically outperform models taught with only one modality. Our study in the Malayalam language utilizing multimodal deep learning is a significant step toward more effective misinformation detection and mitigation.
</details>
<details>
<summary>摘要</summary>
在最近几年，网络上新闻的浏览量有所扩大。假新闻在当地语言 like 马拉雅利姆语中变得越来越普遍，尤其是在一些在线站点上不具备编辑标准的情况下。假新闻可能对社会产生坏处，让人们做出错误的判断，失去对权威机构的信任，甚至发生暴力行为。在印度国情下，有很多的地方语言，假新闻在每种语言中广泛传播。因此，为了有效地检测假新闻，在马拉雅利姆语中提供有效的技术是非常重要。直到现在，我们知道的是，在马拉雅利姆语中使用多Modalities 的深度学习模型来检测假新闻是第一次。使用多Modalities 的特征可以提高假新闻检测的准确率，因为从多个模式中提取的特征用于建立深度学习分类模型。我们的研究表明，使用多Modalities 的深度学习模型在马拉雅利姆语中可以有效地检测假新闻。这是一项重要的研究，可以帮助我们更好地检测和解决假新闻。
</details></li>
</ul>
<hr>
<h2 id="Revising-with-a-Backward-Glance-Regressions-and-Skips-during-Reading-as-Cognitive-Signals-for-Revision-Policies-in-Incremental-Processing"><a href="#Revising-with-a-Backward-Glance-Regressions-and-Skips-during-Reading-as-Cognitive-Signals-for-Revision-Policies-in-Incremental-Processing" class="headerlink" title="Revising with a Backward Glance: Regressions and Skips during Reading as Cognitive Signals for Revision Policies in Incremental Processing"></a>Revising with a Backward Glance: Regressions and Skips during Reading as Cognitive Signals for Revision Policies in Incremental Processing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18229">http://arxiv.org/abs/2310.18229</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/briemadu/revreg">https://github.com/briemadu/revreg</a></li>
<li>paper_authors: Brielen Madureira, Pelin Çelikkol, David Schlangen</li>
<li>for: 这个论文旨在研究如何使用人类阅读眼动追踪数据来优化增量处理器的修订策略。</li>
<li>methods: 这个论文使用了人类阅读眼动追踪数据，并使用了普通的混合效应模型来分析人类的阅读习惯。</li>
<li>results: 研究发现，人类阅读眼动追踪数据中的回退和跳过可能serve as useful predictors for revisions in BiLSTMs and Transformer models，并且这些结果适用于多种语言。<details>
<summary>Abstract</summary>
In NLP, incremental processors produce output in instalments, based on incoming prefixes of the linguistic input. Some tokens trigger revisions, causing edits to the output hypothesis, but little is known about why models revise when they revise. A policy that detects the time steps where revisions should happen can improve efficiency. Still, retrieving a suitable signal to train a revision policy is an open problem, since it is not naturally available in datasets. In this work, we investigate the appropriateness of regressions and skips in human reading eye-tracking data as signals to inform revision policies in incremental sequence labelling. Using generalised mixed-effects models, we find that the probability of regressions and skips by humans can potentially serve as useful predictors for revisions in BiLSTMs and Transformer models, with consistent results for various languages.
</details>
<details>
<summary>摘要</summary>
在自然语言处理（NLP）中，逐步处理器生成输出，基于进来的语言输入前缀。一些token触发修订，导致输出假设中的修订，但是不多少是为何模型修订这件事情都不太清楚。一个政策可以提高效率是在哪些时间步骤中进行修订。然而，找到适合训练修订政策的信号仍然是一个开放的问题，因为这些信号不自然地出现在数据集中。在这项工作中，我们 investigate了人类阅读眼动追踪数据中的回退和跳过是否可以作为修订政策的信号。使用通用混合效应模型，我们发现人类的回退和跳过概率可能可以作为BiLSTM和Transformer模型中的修订预测器，具有一致的结果。
</details></li>
</ul>
<hr>
<h2 id="ArcheType-A-Novel-Framework-for-Open-Source-Column-Type-Annotation-using-Large-Language-Models"><a href="#ArcheType-A-Novel-Framework-for-Open-Source-Column-Type-Annotation-using-Large-Language-Models" class="headerlink" title="ArcheType: A Novel Framework for Open-Source Column Type Annotation using Large Language Models"></a>ArcheType: A Novel Framework for Open-Source Column Type Annotation using Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18208">http://arxiv.org/abs/2310.18208</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/penfever/archetype">https://github.com/penfever/archetype</a></li>
<li>paper_authors: Benjamin Feuer, Yurong Liu, Chinmay Hegde, Juliana Freire</li>
<li>for: 本研究旨在解决现有深度学习方法 для semantic column type annotation (CTA) 中的重要缺点，包括类型 fixed 在训练时间、大量训练样本和高 inference 成本。</li>
<li>methods: 本研究使用大语言模型来解决 CTA 问题，并提出了一种简单、实用的方法 ArcheType，包括 context sampling、prompt serialization、model querying 和 label remapping。</li>
<li>results: 本研究在 zero-shot 和 fine-tuned CTA 问题上达到了新的州Of-the-art 性能，包括三个新的领域特定的benchmark，并发布了相关的代码和数据。<details>
<summary>Abstract</summary>
Existing deep-learning approaches to semantic column type annotation (CTA) have important shortcomings: they rely on semantic types which are fixed at training time; require a large number of training samples per type and incur large run-time inference costs; and their performance can degrade when evaluated on novel datasets, even when types remain constant. Large language models have exhibited strong zero-shot classification performance on a wide range of tasks and in this paper we explore their use for CTA. We introduce ArcheType, a simple, practical method for context sampling, prompt serialization, model querying, and label remapping, which enables large language models to solve column type annotation problems in a fully zero-shot manner. We ablate each component of our method separately, and establish that improvements to context sampling and label remapping provide the most consistent gains. ArcheType establishes new state-of-the-art performance on both zero-shot and fine-tuned CTA, including three new domain-specific benchmarks, which we release, along with the code to reproduce our results at https://github.com/penfever/ArcheType.
</details>
<details>
<summary>摘要</summary>
现有的深度学习方法 дляsemantic column type annotation（CTA）具有重要的缺点：它们依赖于固定的semantic type，需要训练样本数量很多，并且在运行时会产生大量的计算成本。此外，它们在新的数据集上表现不佳，即使类型保持不变。大型语言模型在各种任务上表现出了强的零shot分类能力，在这篇论文中，我们探索了它们在CTA中的使用。我们介绍了ArcheType，一种简单、实用的方法，可以使大型语言模型解决column type annotation问题，无需任何训练样本。我们分别离去每个方法的组成部分，并证明了改进context sampling和label remapping可以提供最大的改进。ArcheType在零shot和精心调整的CTA中成功地设置新的状态纪录，包括三个新的域特定的benchmark，我们在https://github.com/penfever/ArcheType中发布了这些benchmark和 reproduce我们的结果的代码。
</details></li>
</ul>
<hr>
<h2 id="INA-An-Integrative-Approach-for-Enhancing-Negotiation-Strategies-with-Reward-Based-Dialogue-System"><a href="#INA-An-Integrative-Approach-for-Enhancing-Negotiation-Strategies-with-Reward-Based-Dialogue-System" class="headerlink" title="INA: An Integrative Approach for Enhancing Negotiation Strategies with Reward-Based Dialogue System"></a>INA: An Integrative Approach for Enhancing Negotiation Strategies with Reward-Based Dialogue System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18207">http://arxiv.org/abs/2310.18207</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zishan-ai/neg">https://github.com/zishan-ai/neg</a></li>
<li>paper_authors: Zishan Ahmad, Suman Saurabh, Vaishakh Sreekanth Menon, Asif Ekbal, Roshni Ramnani, Anutosh Maitra<br>for:* The paper proposes a novel negotiation dialogue agent for online marketplaces, designed to negotiate on price and other factors such as item inclusion&#x2F;exclusion in a bundle deal.methods:* The agent uses a new semi-automated data creation method that combines defining negotiation intents, actions, and intent-action simulation to generate potential dialogue flows.* The agent employs a set of novel rewards tailored for the negotiation task to train the Integrative Negotiation Agent (INA).results:* The proposed approach and reward system significantly enhance the agent’s negotiation capabilities, allowing it to engage in integrative negotiations and dynamically adjust prices and item inclusions&#x2F;exclusions in a bundle deal.<details>
<summary>Abstract</summary>
In this paper, we propose a novel negotiation dialogue agent designed for the online marketplace. Our agent is integrative in nature i.e, it possesses the capability to negotiate on price as well as other factors, such as the addition or removal of items from a deal bundle, thereby offering a more flexible and comprehensive negotiation experience. We create a new dataset called Integrative Negotiation Dataset (IND) to enable this functionality. For this dataset creation, we introduce a new semi-automated data creation method, which combines defining negotiation intents, actions, and intent-action simulation between users and the agent to generate potential dialogue flows. Finally, the prompting of GPT-J, a state-of-the-art language model, is done to generate dialogues for a given intent, with a human-in-the-loop process for post-editing and refining minor errors to ensure high data quality. We employ a set of novel rewards, specifically tailored for the negotiation task to train our Negotiation Agent, termed as the Integrative Negotiation Agent (INA). These rewards incentivize the chatbot to learn effective negotiation strategies that can adapt to various contextual requirements and price proposals. By leveraging the IND, we train our model and conduct experiments to evaluate the effectiveness of our reward-based dialogue system for negotiation. Our results demonstrate that the proposed approach and reward system significantly enhance the agent's negotiation capabilities. The INA successfully engages in integrative negotiations, displaying the ability to dynamically adjust prices and negotiate the inclusion or exclusion of items in a bundle deal
</details>
<details>
<summary>摘要</summary>
本文提出了一种新的谈判对话机器人，适用于在线市场场所。我们的机器人具有整合性，即可以谈判价格以及其他因素，如交易包中的物品添加或删除，从而提供更加灵活和全面的谈判体验。我们创建了一个新的整合谈判数据集（IND），以实现这种功能。为了创建IND，我们提出了一种新的半自动化数据创建方法，该方法结合定义谈判意图、行为和用户和机器人之间的意图动作模拟，以生成潜在的对话流程。最后，我们使用GPT-J，一种现代自然语言处理模型，来提示对话，并进行人类在 Loop 过程中的修改和微调，以确保数据质量高。我们采用一组特定于谈判任务的新奖励，以训练我们的谈判机器人，称为整合谈判机器人（INA）。这些奖励激励机器人学习有效的谈判策略，能够适应不同的情况和价格建议。通过利用IND，我们训练我们的模型，并进行实验来评估我们的奖励基于对话系统的效果。我们的结果表明，我们的方法和奖励系统可以显著提高机器人的谈判能力。INA成功地参与了整合谈判，展现了可以动态调整价格并谈判交易包中的物品 inclusion 或 exclusion 的能力。
</details></li>
</ul>
<hr>
<h2 id="Lost-in-Translation-Found-in-Spans-Identifying-Claims-in-Multilingual-Social-Media"><a href="#Lost-in-Translation-Found-in-Spans-Identifying-Claims-in-Multilingual-Social-Media" class="headerlink" title="Lost in Translation, Found in Spans: Identifying Claims in Multilingual Social Media"></a>Lost in Translation, Found in Spans: Identifying Claims in Multilingual Social Media</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18205">http://arxiv.org/abs/2310.18205</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mbzuai-nlp/x-claim">https://github.com/mbzuai-nlp/x-claim</a></li>
<li>paper_authors: Shubham Mittal, Megha Sundriyal, Preslav Nakov</li>
<li>for: 这篇论文是为了提高社交媒体文本中Checkworthy声明的识别率而写的。</li>
<li>methods: 这篇论文使用了新的数据集X-CLAIM，包含5种印度语言和英语的7000个实际声明，以及现有的encoder-only语言模型和GPT系列的生成大语言模型。</li>
<li>results: 研究发现，使用多种语言进行训练可以超过零扩展传递和翻译数据进行训练的性能，并且小型encoder-only语言模型在低资源语言上表现比GPT系列更好。<details>
<summary>Abstract</summary>
Claim span identification (CSI) is an important step in fact-checking pipelines, aiming to identify text segments that contain a checkworthy claim or assertion in a social media post. Despite its importance to journalists and human fact-checkers, it remains a severely understudied problem, and the scarce research on this topic so far has only focused on English. Here we aim to bridge this gap by creating a novel dataset, X-CLAIM, consisting of 7K real-world claims collected from numerous social media platforms in five Indian languages and English. We report strong baselines with state-of-the-art encoder-only language models (e.g., XLM-R) and we demonstrate the benefits of training on multiple languages over alternative cross-lingual transfer methods such as zero-shot transfer, or training on translated data, from a high-resource language such as English. We evaluate generative large language models from the GPT series using prompting methods on the X-CLAIM dataset and we find that they underperform the smaller encoder-only language models for low-resource languages.
</details>
<details>
<summary>摘要</summary>
“宣称 span 识别（CSI）是 фак-检查管道中的重要步骤，目的是寻找社交媒体文章中可信worthy的声明或asserttion。despite its importance to journalists and human fact-checkers, it remains a severely understudied problem, and the scarce research on this topic so far has only focused on English. Here we aim to bridge this gap by creating a novel dataset, X-CLAIM, consisting of 7K real-world claims collected from numerous social media platforms in five Indian languages and English. We report strong baselines with state-of-the-art encoder-only language models (e.g., XLM-R) and we demonstrate the benefits of training on multiple languages over alternative cross-lingual transfer methods such as zero-shot transfer, or training on translated data, from a high-resource language such as English. We evaluate generative large language models from the GPT series using prompting methods on the X-CLAIM dataset and we find that they underperform the smaller encoder-only language models for low-resource languages.”
</details></li>
</ul>
<hr>
<h2 id="Style-Description-based-Text-to-Speech-with-Conditional-Prosodic-Layer-Normalization-based-Diffusion-GAN"><a href="#Style-Description-based-Text-to-Speech-with-Conditional-Prosodic-Layer-Normalization-based-Diffusion-GAN" class="headerlink" title="Style Description based Text-to-Speech with Conditional Prosodic Layer Normalization based Diffusion GAN"></a>Style Description based Text-to-Speech with Conditional Prosodic Layer Normalization based Diffusion GAN</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18169">http://arxiv.org/abs/2310.18169</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neeraj Kumar, Ankur Narang, Brejesh Lall</li>
<li>for: 该研究旨在提出一种基于Diffusion GAN的方法（Prosodic Diff-TTS），用于基于样式描述和内容文本的输入生成高效的语音样本，仅需4个释除步骤。</li>
<li>methods: 该方法利用了新的条件式词干层normalization技术，将样式嵌入 integrate into多头注意力基本Encoder和Mel spectrogram Decoder结构中，以生成语音。样式嵌入由预训练BERT模型在auxiliary任务上练习，如抑制、速度、情感、性别分类。</li>
<li>results: 该研究在多个多种语音数据集上进行了证明，包括LibriTTS和PromptSpeech数据集，并通过多个量化度量测试生成的准确率和MOS来证明其效果。<details>
<summary>Abstract</summary>
In this paper, we present a Diffusion GAN based approach (Prosodic Diff-TTS) to generate the corresponding high-fidelity speech based on the style description and content text as an input to generate speech samples within only 4 denoising steps. It leverages the novel conditional prosodic layer normalization to incorporate the style embeddings into the multi head attention based phoneme encoder and mel spectrogram decoder based generator architecture to generate the speech. The style embedding is generated by fine tuning the pretrained BERT model on auxiliary tasks such as pitch, speaking speed, emotion,gender classifications. We demonstrate the efficacy of our proposed architecture on multi-speaker LibriTTS and PromptSpeech datasets, using multiple quantitative metrics that measure generated accuracy and MOS.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一种扩散GAN基本方法（叫做Prosodic Diff-TTS），用于根据样式描述和内容文本生成相应的高精度语音，并且只需要4个释除步骤。它利用了新的 conditional prosodic layer normalization来将样式嵌入 incorporated 到多头注意力基本架构中的phoneme encoder和mel spectrogram decoder基本生成器中，以生成语音。样式嵌入由先前热身BERT模型的 fine-tuning 在auxiliary task such as pitch, speaking speed, emotion, gender classifications中进行。我们在多个 speakers的 LibriTTS 和 PromptSpeech 数据集上证明了我们提出的架构的可行性，并使用多个量化度量来评估生成的准确性和MOS。
</details></li>
</ul>
<hr>
<h2 id="MPrompt-Exploring-Multi-level-Prompt-Tuning-for-Machine-Reading-Comprehension"><a href="#MPrompt-Exploring-Multi-level-Prompt-Tuning-for-Machine-Reading-Comprehension" class="headerlink" title="MPrompt: Exploring Multi-level Prompt Tuning for Machine Reading Comprehension"></a>MPrompt: Exploring Multi-level Prompt Tuning for Machine Reading Comprehension</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18167">http://arxiv.org/abs/2310.18167</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guoxin Chen, Yiming Qian, Bowen Wang, Liangzhi Li</li>
<li>for: 这篇论文是为了提出一种轻量级的Prompt tuning方法，以提高预训练语言模型（PLMs）在新 dataset上的表现。</li>
<li>methods: 该方法使用了多级Prompt，包括任务特定、领域特定和上下文特定的Prompt，以提高输入语义理解的精度。另外，该方法还提出了一个独立性约束，以避免域特定Prompt中重复的信息。</li>
<li>results: 在12个不同的benchmark上进行了广泛的实验，并实现了与当前最佳方法的平均提升率为1.94%。<details>
<summary>Abstract</summary>
The large language models have achieved superior performance on various natural language tasks. One major drawback of such approaches is they are resource-intensive in fine-tuning new datasets. Soft-prompt tuning presents a resource-efficient solution to fine-tune the pre-trained language models (PLMs) while keeping their weight frozen. Existing soft prompt methods mainly focus on designing the input-independent prompts that steer the model to fit the domain of the new dataset. Those methods often ignore the fine-grained information about the task and context of the text. In this paper, we propose a multi-level prompt tuning (MPrompt) method for machine reading comprehension. It utilizes prompts at task-specific, domain-specific, and context-specific levels to enhance the comprehension of input semantics at different granularities. We also propose an independence constraint to steer each domain-specific prompt to focus on information within its domain to avoid redundancy. Moreover, we present a prompt generator that incorporates context-related knowledge in the prompt generation to enhance contextual relevancy. We conducted extensive experiments on 12 benchmarks of various QA formats and achieved an average improvement of 1.94\% over the state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型已经在不同的自然语言任务上实现了出色的性能。然而，这些方法具有资源占用很大的缺点，需要较多的训练数据来调整新的数据集。软提示调整方法提供了一种资源有效的解决方案，可以在保持模型权重固定的情况下，对预训练语言模型（PLMs）进行调整。现有的软提示方法主要关注设计独立的输入提示，以使模型适应新数据集的领域。这些方法通常忽略了文本的任务和上下文细节信息。在这篇论文中，我们提出了一种多级提示调整（MPrompt）方法，用于机器阅读理解。它利用提示在任务特定、领域特定和上下文特定三个级别来提高输入 semantics 的理解。我们还提出了一种独立约束，以确保每个领域特定的提示专注于自己的领域内容，以避免重复。此外，我们提出了一种 incorporating 上下文相关知识的提示生成器，以提高上下文相关性。我们在 12 个不同的benchmark上进行了广泛的实验，并实现了与状态 искус法方法的平均提升率为1.94%。
</details></li>
</ul>
<hr>
<h2 id="Elevating-Code-mixed-Text-Handling-through-Auditory-Information-of-Words"><a href="#Elevating-Code-mixed-Text-Handling-through-Auditory-Information-of-Words" class="headerlink" title="Elevating Code-mixed Text Handling through Auditory Information of Words"></a>Elevating Code-mixed Text Handling through Auditory Information of Words</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18155">http://arxiv.org/abs/2310.18155</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mamta, Zishan Ahmad, Asif Ekbal</li>
<li>for:  handles code-mixed textual data with auditory information</li>
<li>methods:  pre-training step based on masked-language-modelling with SOUNDEX representations (SAMLM) and a new input method</li>
<li>results:  improved robustness towards adversarial attacks and better classification results over popular baselines for code-mixed tasksHere is the simplified Chinese version of the three points:</li>
<li>for: 处理混合语言文本数据，使用听音信息</li>
<li>methods: 基于隐藏语言模型的预训练步骤，使用SOUNDEX表示法（SAMLM）和一种新的输入方法</li>
<li>results: 提高了对 adversarial 攻击的Robustness，以及对 code-mixed 任务的基eline 性能<details>
<summary>Abstract</summary>
With the growing popularity of code-mixed data, there is an increasing need for better handling of this type of data, which poses a number of challenges, such as dealing with spelling variations, multiple languages, different scripts, and a lack of resources. Current language models face difficulty in effectively handling code-mixed data as they primarily focus on the semantic representation of words and ignore the auditory phonetic features. This leads to difficulties in handling spelling variations in code-mixed text. In this paper, we propose an effective approach for creating language models for handling code-mixed textual data using auditory information of words from SOUNDEX. Our approach includes a pre-training step based on masked-language-modelling, which includes SOUNDEX representations (SAMLM) and a new method of providing input data to the pre-trained model. Through experimentation on various code-mixed datasets (of different languages) for sentiment, offensive and aggression classification tasks, we establish that our novel language modeling approach (SAMLM) results in improved robustness towards adversarial attacks on code-mixed classification tasks. Additionally, our SAMLM based approach also results in better classification results over the popular baselines for code-mixed tasks. We use the explainability technique, SHAP (SHapley Additive exPlanations) to explain how the auditory features incorporated through SAMLM assist the model to handle the code-mixed text effectively and increase robustness against adversarial attacks \footnote{Source code has been made available on \url{https://github.com/20118/DefenseWithPhonetics}, \url{https://www.iitp.ac.in/~ai-nlp-ml/resources.html\#Phonetics}.
</details>
<details>
<summary>摘要</summary>
随着code-mixed数据的普及，处理这类数据的需求日益增加，但这也存在许多挑战，如处理拼写变化、多语言、不同的字符集和资源不足等。现有语言模型在处理code-mixed文本时存在困难，因为它们主要关注单词的 semantics 表示，忽略了听音特征。这导致了处理拼写变化的困难。在这篇论文中，我们提出了一种有效的方法，使用听音信息来创建适用于处理code-mixed文本数据的语言模型。我们的方法包括在遮盖语言模型的预训练阶段基于MASKED-LANGUAGE-MODELING，以及一种新的输入数据提供方法。通过对不同语言的code-mixed数据集进行 sentiment、攻击和侵略等任务的实验，我们证明了我们的新的语言模型方法（SAMLM）能够更好地鲁棒化对code-mixed文本的攻击。此外，我们的SAMLM基于方法还在code-mixed任务上得到了更好的分类结果，比 популяр的基elines更好。我们使用SHAP（SHapley Additive exPlanations）技术来解释如何通过SAMLM incorporating 听音特征来处理code-mixed文本，从而提高模型对code-mixed文本的鲁棒性和抗击攻击能力。详细的源代码已经在 <https://github.com/20118/DefenseWithPhonetics> 和 <https://www.iitp.ac.in/~ai-nlp-ml/resources.html\#Phonetics> 上发布。
</details></li>
</ul>
<hr>
<h2 id="Disentangled-Representation-Learning-with-Large-Language-Models-for-Text-Attributed-Graphs"><a href="#Disentangled-Representation-Learning-with-Large-Language-Models-for-Text-Attributed-Graphs" class="headerlink" title="Disentangled Representation Learning with Large Language Models for Text-Attributed Graphs"></a>Disentangled Representation Learning with Large Language Models for Text-Attributed Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18152">http://arxiv.org/abs/2310.18152</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yijian Qin, Xin Wang, Ziwei Zhang, Wenwu Zhu<br>for: 这篇论文是为了解决现有的大语言模型（LLM）在文本嵌入图（TAG）中的缺陷，提高LLM的理解和预测能力。methods: 这篇论文提出了一种名为Disentangled Graph-Text Learner（DGTL）模型，通过专门设计的分离图神经网络（GNN）层，使LLM可以更好地捕捉文本嵌入图中的复杂关系。results: 实验证明，提出的DGTL模型可以在文本嵌入图中实现superior或相当于现有基线的性能，并且可以提供自然语言的解释，因此显著提高了模型的可读性。<details>
<summary>Abstract</summary>
Text-attributed graphs (TAGs) are prevalent on the web and research over TAGs such as citation networks, e-commerce networks and social networks has attracted considerable attention in the web community. Recently, large language models (LLMs) have demonstrated exceptional capabilities across a wide range of tasks. However, the existing works focus on harnessing the potential of LLMs solely relying on prompts to convey graph structure information to LLMs, thus suffering from insufficient understanding of the complex structural relationships within TAGs. To address this problem, in this paper we present the Disentangled Graph-Text Learner (DGTL) model, which is able to enhance the reasoning and predicting capabilities of LLMs for TAGs. Our proposed DGTL model incorporates graph structure information through tailored disentangled graph neural network (GNN) layers, enabling LLMs to capture the intricate relationships hidden in text-attributed graphs from multiple structural factors. Furthermore, DGTL operates with frozen pre-trained LLMs, reducing computational costs and allowing much more flexibility in combining with different LLM models. Experimental evaluations demonstrate the effectiveness of the proposed DGTL model on achieving superior or comparable performance over state-of-the-art baselines. Additionally, we also demonstrate that our DGTL model can offer natural language explanations for predictions, thereby significantly enhancing model interpretability.
</details>
<details>
<summary>摘要</summary>
文本归属图（TAG）在网络上非常普遍，研究人员对这些图像（如引用网络、购物网络和社交网络）的研究吸引了广泛的关注。最近，大型自然语言模型（LLM）在各种任务上表现出了非常出色的能力。然而，现有的工作强调仅通过提示来使LLM对图像进行理解，因此忽略了TAG中复杂的结构关系的问题。为解决这个问题，我们在这篇论文中提出了卷积图文学习者（DGTL）模型，可以增强LLM对TAG的理解和预测能力。我们的提议的DGTL模型通过适应的分离卷积神经网络层来捕捉TAG中多种结构因素中的复杂关系，使LLM能够从多个角度理解TAG的结构。此外，DGTL模型可以与预训练的LLM结合使用， thereby reducing computational costs and allowing for much more flexibility in combining with different LLM models。实验评估表明，我们的提议的DGTL模型可以在达到或与当前基eline相当的性能。此外，我们还示出了DGTL模型可以提供自然语言的解释，从而显著提高模型可读性。
</details></li>
</ul>
<hr>
<h2 id="DELPHI-Data-for-Evaluating-LLMs’-Performance-in-Handling-Controversial-Issues"><a href="#DELPHI-Data-for-Evaluating-LLMs’-Performance-in-Handling-Controversial-Issues" class="headerlink" title="DELPHI: Data for Evaluating LLMs’ Performance in Handling Controversial Issues"></a>DELPHI: Data for Evaluating LLMs’ Performance in Handling Controversial Issues</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18130">http://arxiv.org/abs/2310.18130</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zidixiu/delphi">https://github.com/zidixiu/delphi</a></li>
<li>paper_authors: David Q. Sun, Artem Abzaliev, Hadas Kotek, Zidi Xiu, Christopher Klein, Jason D. Williams</li>
<li>For: This paper aims to systematically examine how large language models (LLMs) respond to questions related to ongoing debates and controversial issues.* Methods: The authors propose a novel construction of a controversial questions dataset, expanding upon the publicly released Quora Question Pairs Dataset. They evaluate different LLMs using a subset of this dataset to understand how they handle controversial issues and the stances they adopt.* Results: The research reveals challenges concerning knowledge recency, safety, fairness, and bias in LLMs’ interaction with controversial issues, and contributes to our understanding of how these models handle complex societal debates.Here’s the text in Simplified Chinese:* For: 这篇论文目标是系统地检查大语言模型（LLM）对ongoing debates和争议问题的回答。* Methods: 作者提出了一种基于Quora Question Pairs Dataset的争议问题集的新建构，以评估不同LLM对争议问题的处理和立场。* Results: 研究发现LLM在处理争议问题时存在知识新鲜度、安全、公正性和偏见等挑战，这些挑战对于LLM在处理复杂社会问题的理解具有重要意义。<details>
<summary>Abstract</summary>
Controversy is a reflection of our zeitgeist, and an important aspect to any discourse. The rise of large language models (LLMs) as conversational systems has increased public reliance on these systems for answers to their various questions. Consequently, it is crucial to systematically examine how these models respond to questions that pertaining to ongoing debates. However, few such datasets exist in providing human-annotated labels reflecting the contemporary discussions. To foster research in this area, we propose a novel construction of a controversial questions dataset, expanding upon the publicly released Quora Question Pairs Dataset. This dataset presents challenges concerning knowledge recency, safety, fairness, and bias. We evaluate different LLMs using a subset of this dataset, illuminating how they handle controversial issues and the stances they adopt. This research ultimately contributes to our understanding of LLMs' interaction with controversial issues, paving the way for improvements in their comprehension and handling of complex societal debates.
</details>
<details>
<summary>摘要</summary>
争议是我们时代精神的反映，是任何讨论的重要方面。大语言模型（LLM）作为对话系统的出现，使人们倾向于依赖这些系统以解答他们的各种问题。因此，系统地检查 LLM 如何回答与当前讨论相关的问题是非常重要的。然而，现在还没有多少 datasets 提供了当今社会讨论的人工标注数据。为推动这一领域的研究，我们提出了一种新的争议问题集合，基于已公布的 Quora 问题对 dataset。这个 dataset 存在知识新鲜度、安全性、公平性和偏见等挑战。我们使用一部分这个 dataset 评估不同的 LLM，揭示它们如何处理争议问题，以及它们所采取的立场。这项研究最终会促进我们对 LLM 与复杂社会讨论的理解，为其更好地处理和理解社会争议的能力做出贡献。
</details></li>
</ul>
<hr>
<h2 id="Mind-the-Gap-Automated-Corpus-Creation-for-Enthymeme-Detection-and-Reconstruction-in-Learner-Arguments"><a href="#Mind-the-Gap-Automated-Corpus-Creation-for-Enthymeme-Detection-and-Reconstruction-in-Learner-Arguments" class="headerlink" title="Mind the Gap: Automated Corpus Creation for Enthymeme Detection and Reconstruction in Learner Arguments"></a>Mind the Gap: Automated Corpus Creation for Enthymeme Detection and Reconstruction in Learner Arguments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18098">http://arxiv.org/abs/2310.18098</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/webis-de/emnlp-23">https://github.com/webis-de/emnlp-23</a></li>
<li>paper_authors: Maja Stahl, Nick Düsterhus, Mei-Hua Chen, Henning Wachsmuth</li>
<li>for: 这篇论文主要是为了提高学生写作论据的能力，帮助学生更好地搜寻和重建论据。</li>
<li>methods: 该论文提出了两个新任务来提高学生论据质量：enthymeme detection和enthymeme reconstruction。它们使用自然语言处理技术来自动生成论据实例，并通过人工研究证明了这些实例的质量。</li>
<li>results: 该论文通过实验表明，使用该方法可以生成高质量的论据实例，并且这些实例的自然语言表达与学生原始写作的语言相似。此外，该论文还提出了初步的检测和重建论据的方法，以便进一步研究这些任务的可能性。<details>
<summary>Abstract</summary>
Writing strong arguments can be challenging for learners. It requires to select and arrange multiple argumentative discourse units (ADUs) in a logical and coherent way as well as to decide which ADUs to leave implicit, so called enthymemes. However, when important ADUs are missing, readers might not be able to follow the reasoning or understand the argument's main point. This paper introduces two new tasks for learner arguments: to identify gaps in arguments (enthymeme detection) and to fill such gaps (enthymeme reconstruction). Approaches to both tasks may help learners improve their argument quality. We study how corpora for these tasks can be created automatically by deleting ADUs from an argumentative text that are central to the argument and its quality, while maintaining the text's naturalness. Based on the ICLEv3 corpus of argumentative learner essays, we create 40,089 argument instances for enthymeme detection and reconstruction. Through manual studies, we provide evidence that the proposed corpus creation process leads to the desired quality reduction, and results in arguments that are similarly natural to those written by learners. Finally, first baseline approaches to enthymeme detection and reconstruction demonstrate the corpus' usefulness.
</details>
<details>
<summary>摘要</summary>
写出强大的论据可能对学习者来说是一项挑战。它需要选择并将多个论据性言Unit (ADU) 组织成逻辑和一致的方式，并决定哪些ADU可以被暗示，即欠Entymemes。然而，当重要的ADU缺失时，读者可能无法跟踪思维或理解论据的主要点。这篇论文提出了两个新任务来提高学习者的论据质量：识别论据缺失 (enthymeme检测) 和填充这些缺失 (enthymeme重建).我们研究了如何通过自动创建 corpora来实现这两个任务。基于 ICLEv3  Argumentative learner essays 论文库，我们创建了40,089个论据实例。通过手动研究，我们提供了证据，表明我们的 corpus 创建过程导致了期望的质量降低，并且结果是与学习者写作的论据类似的自然。最后，我们提出了首个基eline Approaches to enthymeme检测和重建，这证明了 corpus 的用用。
</details></li>
</ul>
<hr>
<h2 id="Lost-in-Translation-–-Multilingual-Misinformation-and-its-Evolution"><a href="#Lost-in-Translation-–-Multilingual-Misinformation-and-its-Evolution" class="headerlink" title="Lost in Translation – Multilingual Misinformation and its Evolution"></a>Lost in Translation – Multilingual Misinformation and its Evolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18089">http://arxiv.org/abs/2310.18089</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dorian Quelle, Calvin Cheng, Alexandre Bovet, Scott A. Hale</li>
<li>for: 本研究探讨了在多语言环境中流传的谣言的频率和 dynamics，通过分析了250,000多个不同语言的事实核查。</li>
<li>methods: 该研究使用了事实核查作为谣言传播的代理，并使用多语言句子嵌入来表示事实核查。研究还使用了群erset扩展来分类相似的CLAIM，并分析了不同语言之间CLAIM的连接和短路。</li>
<li>results: 研究发现，虽然大多数谣言CLAIM只被核查一次，但11.7%的CLAIM（相当于21,000多个）被多次核查。研究还发现，33%的重复CLAIM跨语言传播，表明一些谣言可以跨越语言障碍。然而，研究还发现，谣言在同一语言中更容易传播。通过分析不同语言之间CLAIM的连接和短路，研究发现CLAIM逐渐发展和变化，并且在 crossing 语言时更加明显。<details>
<summary>Abstract</summary>
Misinformation and disinformation are growing threats in the digital age, spreading rapidly across languages and borders. This paper investigates the prevalence and dynamics of multilingual misinformation through an analysis of over 250,000 unique fact-checks spanning 95 languages. First, we find that while the majority of misinformation claims are only fact-checked once, 11.7%, corresponding to more than 21,000 claims, are checked multiple times. Using fact-checks as a proxy for the spread of misinformation, we find 33% of repeated claims cross linguistic boundaries, suggesting that some misinformation permeates language barriers. However, spreading patterns exhibit strong homophily, with misinformation more likely to spread within the same language. To study the evolution of claims over time and mutations across languages, we represent fact-checks with multilingual sentence embeddings and cluster semantically similar claims. We analyze the connected components and shortest paths connecting different versions of a claim finding that claims gradually drift over time and undergo greater alteration when traversing languages. Overall, this novel investigation of multilingual misinformation provides key insights. It quantifies redundant fact-checking efforts, establishes that some claims diffuse across languages, measures linguistic homophily, and models the temporal and cross-lingual evolution of claims. The findings advocate for expanded information sharing between fact-checkers globally while underscoring the importance of localized verification.
</details>
<details>
<summary>摘要</summary>
“误信和伪信在数字时代增长为潜在的威胁，迅速在语言和国界之间传播。这篇论文通过分析超过250,000个唯一的事实核查来研究多语言误信的普遍性和动态。我们发现大多数误信声明只被核查一次，但11.7%（相当于 más than 21,000）的声明被重复核查。使用事实核查作为误信传播的代理，我们发现33%的重复声明跨语言传播，这表明一些误信可以跨越语言障碍。然而，误信的传播模式具有强的同语群效应，误信更可能在同一语言中传播。为了研究声明的时间发展和语言过渡的变化，我们使用多语言句子嵌入表示事实核查，并对具有相似含义的声明进行聚类分析。我们分析了声明之间的连接组件和语言之间的短路，发现声明逐渐演化，并在语言之间传播时更容易发生变化。总的来说，这项研究提供了关键的发现，证实了重复核查的重要性，同时也强调了地方化验证的重要性。”
</details></li>
</ul>
<hr>
<h2 id="A-Scalable-Framework-for-Table-of-Contents-Extraction-from-Complex-ESG-Annual-Reports"><a href="#A-Scalable-Framework-for-Table-of-Contents-Extraction-from-Complex-ESG-Annual-Reports" class="headerlink" title="A Scalable Framework for Table of Contents Extraction from Complex ESG Annual Reports"></a>A Scalable Framework for Table of Contents Extraction from Complex ESG Annual Reports</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18073">http://arxiv.org/abs/2310.18073</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyu Wang, Lin Gui, Yulan He</li>
<li>for: 这篇论文主要是关于文档结构化的研究，旨在提出一个新的 dataset，ESGDoc，包含了563家公司的1093份 ESG年报，从2001年到2022年。</li>
<li>methods: 该论文提出了一种新的框架，用于文档结构化，它包括三个步骤：（1）根据文本阅读顺序和字体大小构建初始树；（2）模型每个树节（或文本块），基于它所处的子树上的信息；（3）修改原始树，通过对每个树节进行适当的操作（保留、删除或移动）。</li>
<li>results: 该框架可以更好地处理文档的不同结构和长度，并且比前一代基eline的方法快得多。实验结果表明，我们的方法可以更高效地处理文档，并且可以适应不同的文档长度。<details>
<summary>Abstract</summary>
Table of contents (ToC) extraction centres on structuring documents in a hierarchical manner. In this paper, we propose a new dataset, ESGDoc, comprising 1,093 ESG annual reports from 563 companies spanning from 2001 to 2022. These reports pose significant challenges due to their diverse structures and extensive length. To address these challenges, we propose a new framework for Toc extraction, consisting of three steps: (1) Constructing an initial tree of text blocks based on reading order and font sizes; (2) Modelling each tree node (or text block) independently by considering its contextual information captured in node-centric subtree; (3) Modifying the original tree by taking appropriate action on each tree node (Keep, Delete, or Move). This construction-modelling-modification (CMM) process offers several benefits. It eliminates the need for pairwise modelling of section headings as in previous approaches, making document segmentation practically feasible. By incorporating structured information, each section heading can leverage both local and long-distance context relevant to itself. Experimental results show that our approach outperforms the previous state-of-the-art baseline with a fraction of running time. Our framework proves its scalability by effectively handling documents of any length.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Constructing an initial tree of text blocks based on reading order and font sizes.2. Modeling each tree node (or text block) independently by considering its contextual information captured in a node-centric subtree.3. Modifying the original tree by taking appropriate action on each tree node (Keep, Delete, or Move).This construction-modeling-modification (CMM) process offers several benefits. It eliminates the need for pairwise modeling of section headings as in previous approaches, making document segmentation practically feasible. By incorporating structured information, each section heading can leverage both local and long-distance context relevant to itself. Experimental results show that our approach outperforms the previous state-of-the-art baseline with a fraction of running time. Our framework proves its scalability by effectively handling documents of any length.</details></li>
</ol>
<hr>
<h2 id="Multi-grained-Evidence-Inference-for-Multi-choice-Reading-Comprehension"><a href="#Multi-grained-Evidence-Inference-for-Multi-choice-Reading-Comprehension" class="headerlink" title="Multi-grained Evidence Inference for Multi-choice Reading Comprehension"></a>Multi-grained Evidence Inference for Multi-choice Reading Comprehension</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18070">http://arxiv.org/abs/2310.18070</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yilin Zhao, Hai Zhao, Sufeng Duan</li>
<li>for: 多选机器阅读理解（MRC）是一项具有挑战性的任务，需要机器能够根据提供的选项回答问题。</li>
<li>methods: 我们提出了一种新的通用模型增强方法，名为多重粒度证据推理器（Mugen），用于弥补机器无法直接从给定的繁杂、噪音 passage 中提取准确证据的不足。Mugen 将在不同粒度上提取证据：粗粒度、中粒度和细粒度证据，并将证据与原始 passage 集成，实现了四个多选 MRC benchmark 上显著和一致的性能提升。</li>
<li>results: 我们的方法在四个多选 MRC benchmark 上实现了显著和一致的性能提升。<details>
<summary>Abstract</summary>
Multi-choice Machine Reading Comprehension (MRC) is a major and challenging task for machines to answer questions according to provided options. Answers in multi-choice MRC cannot be directly extracted in the given passages, and essentially require machines capable of reasoning from accurate extracted evidence. However, the critical evidence may be as simple as just one word or phrase, while it is hidden in the given redundant, noisy passage with multiple linguistic hierarchies from phrase, fragment, sentence until the entire passage. We thus propose a novel general-purpose model enhancement which integrates multi-grained evidence comprehensively, named Multi-grained evidence inferencer (Mugen), to make up for the inability. Mugen extracts three different granularities of evidence: coarse-, middle- and fine-grained evidence, and integrates evidence with the original passages, achieving significant and consistent performance improvement on four multi-choice MRC benchmarks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="“Honey-Tell-Me-What’s-Wrong”-Global-Explanation-of-Textual-Discriminative-Models-through-Cooperative-Generation"><a href="#“Honey-Tell-Me-What’s-Wrong”-Global-Explanation-of-Textual-Discriminative-Models-through-Cooperative-Generation" class="headerlink" title="“Honey, Tell Me What’s Wrong”, Global Explanation of Textual Discriminative Models through Cooperative Generation"></a>“Honey, Tell Me What’s Wrong”, Global Explanation of Textual Discriminative Models through Cooperative Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18063">http://arxiv.org/abs/2310.18063</a></li>
<li>repo_url: None</li>
<li>paper_authors: Antoine Chaffin, Julien Delaunay</li>
<li>for: 这篇论文的目的是提出一种全球和模型无关的解释方法，用于文本分类器中。</li>
<li>methods: 这种方法基于合作生成的文本，不需要输入数据集，可以在数据缺失时提供解释。</li>
<li>results: 实验表明，这种方法可以准确地描述分类器对输入空间中的行为，并且在输入数据不具体化时表现更好于使用输入数据的方法。<details>
<summary>Abstract</summary>
The ubiquity of complex machine learning has raised the importance of model-agnostic explanation algorithms. These methods create artificial instances by slightly perturbing real instances, capturing shifts in model decisions. However, such methods rely on initial data and only provide explanations of the decision for these. To tackle these problems, we propose Therapy, the first global and model-agnostic explanation method adapted to text which requires no input dataset. Therapy generates texts following the distribution learned by a classifier through cooperative generation. Because it does not rely on initial samples, it allows to generate explanations even when data is absent (e.g., for confidentiality reasons). Moreover, conversely to existing methods that combine multiple local explanations into a global one, Therapy offers a global overview of the model behavior on the input space. Our experiments show that although using no input data to generate samples, Therapy provides insightful information about features used by the classifier that is competitive with the ones from methods relying on input samples and outperforms them when input samples are not specific to the studied model.
</details>
<details>
<summary>摘要</summary>
“复杂机器学习的普遍使得模型无关解释算法的重要性提高。这些方法通过微量修改真实实例而创造人工实例，捕捉模型决策的变化。然而，这些方法仅依赖于初始数据，只能提供这些数据的决策说明。为解决这些问题，我们提议了疗法（Therapy），是首个全球、模型无关的解释方法，不需要输入数据集。疗法通过与分类器一起生成文本，学习分类器的分布。因为不依赖于初始样本，疗法可以在没有数据时产生解释（例如，保持隐私原则）。此外，不同于现有的方法，将多个本地解释合并成一个全局解释，疗法提供了输入空间上模型行为的全面视图。我们的实验表明，使用没有输入数据生成样本，疗法可以提供有用的特征信息，与使用输入数据生成样本的方法竞争，并在输入数据不是特定于研究模型时表现更好。”
</details></li>
</ul>
<hr>
<h2 id="ViCLEVR-A-Visual-Reasoning-Dataset-and-Hybrid-Multimodal-Fusion-Model-for-Visual-Question-Answering-in-Vietnamese"><a href="#ViCLEVR-A-Visual-Reasoning-Dataset-and-Hybrid-Multimodal-Fusion-Model-for-Visual-Question-Answering-in-Vietnamese" class="headerlink" title="ViCLEVR: A Visual Reasoning Dataset and Hybrid Multimodal Fusion Model for Visual Question Answering in Vietnamese"></a>ViCLEVR: A Visual Reasoning Dataset and Hybrid Multimodal Fusion Model for Visual Question Answering in Vietnamese</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18046">http://arxiv.org/abs/2310.18046</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kvt0012/viclevr">https://github.com/kvt0012/viclevr</a></li>
<li>paper_authors: Khiem Vinh Tran, Hao Phu Phan, Kiet Van Nguyen, Ngan Luu Thuy Nguyen</li>
<li>for: 本研究旨在提高越南语言Visual Question Answering（VQA）系统的性能，并探讨现代视觉理解系统的强点和局限性。</li>
<li>methods: 本研究使用了一个新的多模态混合方法，称为 PhoVIT，该方法可以基于问题来确定图像中的对象。PhoVIT使用了 transformers 来同时进行文本和视觉数据的推理，并在早期模型阶段将两种模式融合。</li>
<li>results: 实验结果显示，我们的提议的模型在四个评价指标中均达到了当前最佳性能。<details>
<summary>Abstract</summary>
In recent years, Visual Question Answering (VQA) has gained significant attention for its diverse applications, including intelligent car assistance, aiding visually impaired individuals, and document image information retrieval using natural language queries. VQA requires effective integration of information from questions and images to generate accurate answers. Neural models for VQA have made remarkable progress on large-scale datasets, with a primary focus on resource-rich languages like English. To address this, we introduce the ViCLEVR dataset, a pioneering collection for evaluating various visual reasoning capabilities in Vietnamese while mitigating biases. The dataset comprises over 26,000 images and 30,000 question-answer pairs (QAs), each question annotated to specify the type of reasoning involved. Leveraging this dataset, we conduct a comprehensive analysis of contemporary visual reasoning systems, offering valuable insights into their strengths and limitations. Furthermore, we present PhoVIT, a comprehensive multimodal fusion that identifies objects in images based on questions. The architecture effectively employs transformers to enable simultaneous reasoning over textual and visual data, merging both modalities at an early model stage. The experimental findings demonstrate that our proposed model achieves state-of-the-art performance across four evaluation metrics. The accompanying code and dataset have been made publicly accessible at \url{https://github.com/kvt0012/ViCLEVR}. This provision seeks to stimulate advancements within the research community, fostering the development of more multimodal fusion algorithms, specifically tailored to address the nuances of low-resource languages, exemplified by Vietnamese.
</details>
<details>
<summary>摘要</summary>
Recently, Visual Question Answering (VQA) has gained significant attention due to its diverse applications, such as intelligent car assistance, aiding visually impaired individuals, and document image information retrieval using natural language queries. VQA requires the effective integration of information from questions and images to generate accurate answers. Neural models for VQA have made remarkable progress on large-scale datasets, with a primary focus on resource-rich languages like English. To address this, we introduce the ViCLEVR dataset, a pioneering collection for evaluating various visual reasoning capabilities in Vietnamese while mitigating biases. The dataset comprises over 26,000 images and 30,000 question-answer pairs (QAs), each question annotated to specify the type of reasoning involved. Leveraging this dataset, we conduct a comprehensive analysis of contemporary visual reasoning systems, offering valuable insights into their strengths and limitations. Furthermore, we present PhoVIT, a comprehensive multimodal fusion that identifies objects in images based on questions. The architecture effectively employs transformers to enable simultaneous reasoning over textual and visual data, merging both modalities at an early model stage. The experimental findings demonstrate that our proposed model achieves state-of-the-art performance across four evaluation metrics. The accompanying code and dataset have been made publicly accessible at [url=https://github.com/kvt0012/ViCLEVR]. This provision seeks to stimulate advancements within the research community, fostering the development of more multimodal fusion algorithms, specifically tailored to address the nuances of low-resource languages, exemplified by Vietnamese.
</details></li>
</ul>
<hr>
<h2 id="On-General-Language-Understanding"><a href="#On-General-Language-Understanding" class="headerlink" title="On General Language Understanding"></a>On General Language Understanding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18038">http://arxiv.org/abs/2310.18038</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Sfedfcv/redesigned-pancake">https://github.com/Sfedfcv/redesigned-pancake</a></li>
<li>paper_authors: David Schlangen</li>
<li>for: 这篇论文的目的是为了探讨人工智能语言处理领域内的语言理解问题，以及现有测量模型质量的方法是否具有足够的有效性。</li>
<li>methods: 这篇论文使用了一种模型，用于描述语言理解是一种多方面的现象，兼包含个人主义和社会过程。</li>
<li>results: 这篇论文的结论是，不同的语言使用场景类型具有不同的特点，而语言理解是一种多方面的现象，需要考虑个人主义和社会过程。此外，选择的理解指标会影响测量模型质量的限制，并且开启了对NLP使用的伦理考虑。<details>
<summary>Abstract</summary>
Natural Language Processing prides itself to be an empirically-minded, if not outright empiricist field, and yet lately it seems to get itself into essentialist debates on issues of meaning and measurement ("Do Large Language Models Understand Language, And If So, How Much?"). This is not by accident: Here, as everywhere, the evidence underspecifies the understanding. As a remedy, this paper sketches the outlines of a model of understanding, which can ground questions of the adequacy of current methods of measurement of model quality. The paper makes three claims: A) That different language use situation types have different characteristics, B) That language understanding is a multifaceted phenomenon, bringing together individualistic and social processes, and C) That the choice of Understanding Indicator marks the limits of benchmarking, and the beginnings of considerations of the ethics of NLP use.
</details>
<details>
<summary>摘要</summary>
自然语言处理（NLP）自认为是一个经验主义的，甚至是直接经验主义的领域，然而最近它似乎涉及到必要的本质主义辩论（"大语言模型是否理解语言，以及如何量度它们？"）。这不是偶合：在这里，就如 everywhere else，证据不够特征化理解。为了解决这问题，这篇论文提出了一个理解模型，以便评估现有测量模型质量的问题。论文提出了三个主张：A）不同的语言使用情况类型有不同的特征；B）语言理解是多方面的现象，既具有个人主义的特征，又具有社会过程的特征；C）选择理解指标标志着测量的限制，也标志着NLP使用的伦理考虑的开始。
</details></li>
</ul>
<hr>
<h2 id="SentMix-3L-A-Bangla-English-Hindi-Code-Mixed-Dataset-for-Sentiment-Analysis"><a href="#SentMix-3L-A-Bangla-English-Hindi-Code-Mixed-Dataset-for-Sentiment-Analysis" class="headerlink" title="SentMix-3L: A Bangla-English-Hindi Code-Mixed Dataset for Sentiment Analysis"></a>SentMix-3L: A Bangla-English-Hindi Code-Mixed Dataset for Sentiment Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18023">http://arxiv.org/abs/2310.18023</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md Nishat Raihan, Dhiman Goswami, Antara Mahmud, Antonios Anstasopoulos, Marcos Zampieri</li>
<li>for: 这篇论文的目的是为了提出一个新的三种语言混合数据集（SentMix-3L），用于 sentiment analysis 的计算模型训练。</li>
<li>methods: 该论文使用了 GPT-3.5 作为预训练模型，并进行了对 SentMix-3L 的全面评估。</li>
<li>results: 研究发现，使用 GPT-3.5 的零shot提问方法可以在 SentMix-3L 上超越所有基于 transformer 的模型。<details>
<summary>Abstract</summary>
Code-mixing is a well-studied linguistic phenomenon when two or more languages are mixed in text or speech. Several datasets have been build with the goal of training computational models for code-mixing. Although it is very common to observe code-mixing with multiple languages, most datasets available contain code-mixed between only two languages. In this paper, we introduce SentMix-3L, a novel dataset for sentiment analysis containing code-mixed data between three languages Bangla, English, and Hindi. We carry out a comprehensive evaluation using SentMix-3L. We show that zero-shot prompting with GPT-3.5 outperforms all transformer-based models on SentMix-3L.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译成简化字符串。<</SYS>>研究人员已经广泛研究了语言混合现象，在文本或语音中混合两种或更多的语言。许多数据集已经建立，用于训练计算机模型。虽然混合多种语言很常见，但大多数可用的数据集只包含两种语言的混合。在这篇论文中，我们介绍了一个新的 sentiment 分析数据集 SentMix-3L，包含三种语言孟加拉语、英语和印地语的混合数据。我们进行了全面的评估，并显示了 GPT-3.5 预训练模型在 SentMix-3L 上的零批训练性能超过所有 transformer 模型。
</details></li>
</ul>
<hr>
<h2 id="NLP-Evaluation-in-trouble-On-the-Need-to-Measure-LLM-Data-Contamination-for-each-Benchmark"><a href="#NLP-Evaluation-in-trouble-On-the-Need-to-Measure-LLM-Data-Contamination-for-each-Benchmark" class="headerlink" title="NLP Evaluation in trouble: On the Need to Measure LLM Data Contamination for each Benchmark"></a>NLP Evaluation in trouble: On the Need to Measure LLM Data Contamination for each Benchmark</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18018">http://arxiv.org/abs/2310.18018</a></li>
<li>repo_url: None</li>
<li>paper_authors: Oscar Sainz, Jon Ander Campos, Iker García-Ferrero, Julen Etxaniz, Oier Lopez de Lacalle, Eneko Agirre</li>
<li>for: 本文 argue that classical NLP task evaluation using annotated benchmarks is facing a serious problem, specifically the worst kind of data contamination.</li>
<li>methods: 本文提出了不同级别的数据污染水平，并呼吁社区共同努力，包括开发自动和半自动检测数据 benchmark 中模型训练时的污染程度的方法，以及建议将污染数据导致的科学结论列入涂抹名单。</li>
<li>results: 本文表明，当一个大自然语言模型（LLM）在测试分割上训练，然后在同一个benchmark上评估时，会导致模型性能的过高估计，从而导致科学结论的错误公布，同时正确的结论被抛弃。这种情况可能导致科学研究的假阳性结论，并且可能对社会造成不良影响。<details>
<summary>Abstract</summary>
In this position paper, we argue that the classical evaluation on Natural Language Processing (NLP) tasks using annotated benchmarks is in trouble. The worst kind of data contamination happens when a Large Language Model (LLM) is trained on the test split of a benchmark, and then evaluated in the same benchmark. The extent of the problem is unknown, as it is not straightforward to measure. Contamination causes an overestimation of the performance of a contaminated model in a target benchmark and associated task with respect to their non-contaminated counterparts. The consequences can be very harmful, with wrong scientific conclusions being published while other correct ones are discarded. This position paper defines different levels of data contamination and argues for a community effort, including the development of automatic and semi-automatic measures to detect when data from a benchmark was exposed to a model, and suggestions for flagging papers with conclusions that are compromised by data contamination.
</details>
<details>
<summary>摘要</summary>
在这份位点论文中，我们Arguments that the traditional evaluation of Natural Language Processing (NLP) tasks using annotated benchmarks is facing a crisis. The most severe data contamination occurs when a Large Language Model (LLM) is trained on the test set of a benchmark and then evaluated in the same benchmark. The extent of the problem is unknown, as it is not easy to measure. Contamination causes an overestimation of the performance of a contaminated model in a target benchmark and associated task compared to their non-contaminated counterparts. The consequences can be very harmful, with wrong scientific conclusions being published while other correct ones are discarded. This position paper defines different levels of data contamination and advocates for a community effort, including the development of automatic and semi-automatic measures to detect when data from a benchmark was exposed to a model, and suggestions for flagging papers with conclusions that are compromised by data contamination.
</details></li>
</ul>
<hr>
<h2 id="Does-Role-Playing-Chatbots-Capture-the-Character-Personalities-Assessing-Personality-Traits-for-Role-Playing-Chatbots"><a href="#Does-Role-Playing-Chatbots-Capture-the-Character-Personalities-Assessing-Personality-Traits-for-Role-Playing-Chatbots" class="headerlink" title="Does Role-Playing Chatbots Capture the Character Personalities? Assessing Personality Traits for Role-Playing Chatbots"></a>Does Role-Playing Chatbots Capture the Character Personalities? Assessing Personality Traits for Role-Playing Chatbots</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17976">http://arxiv.org/abs/2310.17976</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/LC1332/Chat-Haruhi-Suzumiya">https://github.com/LC1332/Chat-Haruhi-Suzumiya</a></li>
<li>paper_authors: Xintao Wang, Quan Tu, Yaying Fei, Ziang Leng, Cheng Li</li>
<li>for: 这篇论文旨在探讨如何使用大规模预训练语言模型来评估角色扮演聊天机器人的人格特质。</li>
<li>methods: 该论文提出了一种开放结束式采访方法，用于评估角色扮演聊天机器人的人格特质，并对32个使用ChatHaruhi库创建的角色扮演聊天机器人进行了评估。</li>
<li>results: 研究结果显示，使用大规模预训练语言模型创建的角色扮演聊天机器人可以准确表现出对应的人格特质，与人类所认可的人格特质的一致率为82.8%。此外，论文还提出了可能的形成聊天机器人人格的策略。因此，这篇论文为Role-playing聊天机器人的研究提供了一个基础性的研究。<details>
<summary>Abstract</summary>
The emergence of large-scale pretrained language models has revolutionized the capabilities of new AI application, especially in the realm of crafting chatbots with distinct personas. Given the "stimulus-response" nature of chatbots, this paper unveils an innovative open-ended interview-style approach for personality assessment on role-playing chatbots, which offers a richer comprehension of their intrinsic personalities. We conduct personality assessments on 32 role-playing chatbots created by the ChatHaruhi library, across both the Big Five and MBTI dimensions, and measure their alignment with human perception. Evaluation results underscore that modern role-playing chatbots based on LLMs can effectively portray personality traits of corresponding characters, with an alignment rate of 82.8% compared with human-perceived personalities. Besides, we also suggest potential strategies for shaping chatbots' personalities. Hence, this paper serves as a cornerstone study for role-playing chatbots that intersects computational linguistics and psychology. Our resources are available at https://github.com/LC1332/Chat-Haruhi-Suzumiya
</details>
<details>
<summary>摘要</summary>
大规模预训语言模型的出现对新的人工智能应用程序带来了革命性的变革，特别是在游戏角色聊天机器人的领域。由于聊天机器人的“刺激-应答”性质，这篇论文推出了一种创新的开端式 интервью式人格测试方法，可以更深入地了解角色聊天机器人的内在人格特质。我们对使用ChatHaruhi库创建的32个角色聊天机器人进行了人格测试，包括Big Five和MBTI维度，并与人类的认知进行比较。结果显示，现代基于LLMs的角色聊天机器人可以有效表达对应的人格特质，与人类认知的人格Alignment率为82.8%。此外，我们还提出了可能的聊天机器人人格模型的形成策略。因此，本论文作为计算语言学和心理学交叉领域的基础研究，可以为角色聊天机器人的开发提供启示。我们的资源可以在https://github.com/LC1332/Chat-Haruhi-Suzumiya 查看。
</details></li>
</ul>
<hr>
<h2 id="Whisper-MCE-Whisper-Model-Finetuned-for-Better-Performance-with-Mixed-Languages"><a href="#Whisper-MCE-Whisper-Model-Finetuned-for-Better-Performance-with-Mixed-Languages" class="headerlink" title="Whisper-MCE: Whisper Model Finetuned for Better Performance with Mixed Languages"></a>Whisper-MCE: Whisper Model Finetuned for Better Performance with Mixed Languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17953">http://arxiv.org/abs/2310.17953</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peng Xie, XingYuan Liu, ZiWei Chen, Kani Chen, Yang Wang</li>
<li>for: 这项研究旨在提高英语自动语音识别（ASR）中的人类水平稳定性和准确率，特别是在小语言和混合语言语音识别方面。</li>
<li>methods: 这项研究使用了自己收集的混合粤语和英语音频数据集（MCE）来训练了自适应的Whisper模型（Whisper-MCE），并提出了一种新的评价机制来评估模型在小语言和混合语言上的效果。</li>
<li>results: 研究表明， compare to基线的Whisper-大型v2模型，Whisper-MCE模型能够更好地捕捉原始音频的内容，实现更高的识别精度，并且具有更快的识别速度，特别是在混合语言任务中表现出色。<details>
<summary>Abstract</summary>
Recently Whisper has approached human-level robustness and accuracy in English automatic speech recognition (ASR), while in minor language and mixed language speech recognition, there remains a compelling need for further improvement. In this work, we present the impressive results of Whisper-MCE, our finetuned Whisper model, which was trained using our self-collected dataset, Mixed Cantonese and English audio dataset (MCE). Meanwhile, considering word error rate (WER) poses challenges when it comes to evaluating its effectiveness in minor language and mixed-language contexts, we present a novel rating mechanism. By comparing our model to the baseline whisper-large-v2 model, we demonstrate its superior ability to accurately capture the content of the original audio, achieve higher recognition accuracy, and exhibit faster recognition speed. Notably, our model outperforms other existing models in the specific task of recognizing mixed language.
</details>
<details>
<summary>摘要</summary>
最近，Whisper 在英语自动语音识别（ASR）中达到了人类水平的Robustness和准确率，而在小语言和杂语言语音识别方面仍然有很大的改进空间。在这项工作中，我们发布了我们自收集的数据集，混合粤语和英语音频数据集（MCE），并使用这些数据集来训练我们的 Whisper 模型，并对其进行了迁移。尽管 word error rate（WER）在小语言和杂语言上存在评估效果的挑战，我们则提出了一种新的评价机制。通过对我们的模型与基eline whisper-large-v2 模型进行比较，我们表明了我们的模型在捕捉原始音频内容的能力更高， recognition 率更高，并且速度更快。值得一提是，我们的模型在杂语言识别任务中表现出色，胜过其他现有的模型。
</details></li>
</ul>
<hr>
<h2 id="SOUL-Towards-Sentiment-and-Opinion-Understanding-of-Language"><a href="#SOUL-Towards-Sentiment-and-Opinion-Understanding-of-Language" class="headerlink" title="SOUL: Towards Sentiment and Opinion Understanding of Language"></a>SOUL: Towards Sentiment and Opinion Understanding of Language</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17924">http://arxiv.org/abs/2310.17924</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/damo-nlp-sg/soul">https://github.com/damo-nlp-sg/soul</a></li>
<li>paper_authors: Yue Deng, Wenxuan Zhang, Sinno Jialin Pan, Lidong Bing</li>
<li>for: 评估语言模型在情感分析领域的能力，探讨语言模型是否能够理解语言中的情感和意见。</li>
<li>methods: 提出了一种新的任务叫做情感和意见理解语言（SOUL），SOUL包括两个子任务：评论理解（RC）和证明生成（JG）。</li>
<li>results: 实验结果表明，SOUL是现有语言模型很难解决的任务，与人类表现相比，语言模型的性能差距可达27%。此外，与人类专家和GPT-4进行评估表明，小语言模型在生成有理根据的证明方面存在限制。这些结果强调了现有语言模型在情感分析领域存在的复杂性，并提出了进一步发展情感分析的需求。<details>
<summary>Abstract</summary>
Sentiment analysis is a well-established natural language processing task, with sentiment polarity classification being one of its most popular and representative tasks. However, despite the success of pre-trained language models in this area, they often fall short of capturing the broader complexities of sentiment analysis. To address this issue, we propose a new task called Sentiment and Opinion Understanding of Language (SOUL). SOUL aims to evaluate sentiment understanding through two subtasks: Review Comprehension (RC) and Justification Generation (JG). RC seeks to validate statements that focus on subjective information based on a review text, while JG requires models to provide explanations for their sentiment predictions. To enable comprehensive evaluation, we annotate a new dataset comprising 15,028 statements from 3,638 reviews. Experimental results indicate that SOUL is a challenging task for both small and large language models, with a performance gap of up to 27% when compared to human performance. Furthermore, evaluations conducted with both human experts and GPT-4 highlight the limitations of the small language model in generating reasoning-based justifications. These findings underscore the challenging nature of the SOUL task for existing models, emphasizing the need for further advancements in sentiment analysis to address its complexities. The new dataset and code are available at https://github.com/DAMO-NLP-SG/SOUL.
</details>
<details>
<summary>摘要</summary>
sentiment分析是一个已经广泛应用的自然语言处理任务，其中情感质量分类是该领域最受欢迎的任务之一。然而，尽管先前训练的语言模型在这个领域取得了成功，但它们经常无法捕捉 sentiment分析的更广泛复杂性。为了解决这个问题，我们提出了一个新的任务，即语言情感理解（SOUL）。SOUL的目的是评估语言情感理解的能力，通过两个子任务：评论理解（RC）和证明生成（JG）。RC检验基于评论文本中主观信息的准确性，而JG要求模型为其情感预测提供解释。为了实现全面的评估，我们注释了一个新的数据集，包含15,028个语句，来自3,638篇评论。实验结果表明，SOUL是现有模型的一个挑战性任务，与人类表现的差距可达27%。此外，通过人类专家和GPT-4的评估，我们发现小语言模型在生成理由基于的证明方面存在限制。这些发现强调现有模型在情感分析的复杂性方面存在困难，需要进一步的进步，以更好地捕捉 sentiment分析的复杂性。新的数据集和代码可以在https://github.com/DAMO-NLP-SG/SOUL上获取。
</details></li>
</ul>
<hr>
<h2 id="3D-Aware-Visual-Question-Answering-about-Parts-Poses-and-Occlusions"><a href="#3D-Aware-Visual-Question-Answering-about-Parts-Poses-and-Occlusions" class="headerlink" title="3D-Aware Visual Question Answering about Parts, Poses and Occlusions"></a>3D-Aware Visual Question Answering about Parts, Poses and Occlusions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17914">http://arxiv.org/abs/2310.17914</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xingruiwang/3d-aware-vqa">https://github.com/xingruiwang/3d-aware-vqa</a></li>
<li>paper_authors: Xingrui Wang, Wufei Ma, Zhuowan Li, Adam Kortylewski, Alan Yuille</li>
<li>for: 推动3D视Question Answering领域的进步，提高VQA模型对3D场景的理解。</li>
<li>methods: 提出了3D-aware VQA任务，并设计了Super-CLEVR-3D数据集，用于挑战VQA模型的 Compositional Reasoning能力。</li>
<li>results: 提出了PO3D-VQA模型，结合概率神经 симвоlic Program Execution 和深度神经网络，实现了3D生成表示和可靠视觉识别。实验结果显示PO3D-VQA模型在3D-aware VQA任务中表现出色，但还有一定的性能差距与2D VQA标准准样本比较， indicating that 3D-aware VQA remains an important open research area。<details>
<summary>Abstract</summary>
Despite rapid progress in Visual question answering (VQA), existing datasets and models mainly focus on testing reasoning in 2D. However, it is important that VQA models also understand the 3D structure of visual scenes, for example to support tasks like navigation or manipulation. This includes an understanding of the 3D object pose, their parts and occlusions. In this work, we introduce the task of 3D-aware VQA, which focuses on challenging questions that require a compositional reasoning over the 3D structure of visual scenes. We address 3D-aware VQA from both the dataset and the model perspective. First, we introduce Super-CLEVR-3D, a compositional reasoning dataset that contains questions about object parts, their 3D poses, and occlusions. Second, we propose PO3D-VQA, a 3D-aware VQA model that marries two powerful ideas: probabilistic neural symbolic program execution for reasoning and deep neural networks with 3D generative representations of objects for robust visual recognition. Our experimental results show our model PO3D-VQA outperforms existing methods significantly, but we still observe a significant performance gap compared to 2D VQA benchmarks, indicating that 3D-aware VQA remains an important open research area.
</details>
<details>
<summary>摘要</summary>
尽管视觉问答（VQA）已经快速进步，现有的数据集和模型主要是测试二维空间中的逻辑能力。然而，VQA模型也需要理解三维视觉场景的结构，如支持导航或操作任务。这包括理解三维物体姿态、部件和遮挡。在这项工作中，我们引入三维逻辑VQA任务，它挑战需要对视觉场景的三维结构进行复杂的推理。我们从数据集和模型两个角度解决3D-aware VQA。首先，我们介绍Super-CLEVR-3D数据集，它包含对物体部件、姿态和遮挡进行复杂的推理的问题。其次，我们提出PO3D-VQA模型，它结合了可靠的神经网络符号表示和深度神经网络的3D生成表示来实现可靠的视觉识别和逻辑推理。我们的实验结果表明，PO3D-VQA模型在3D-aware VQA任务上表现出色，但我们还观察到与2D VQA标准chmark相比，3D-aware VQA任务的性能仍然存在显著的差距，因此3D-aware VQA仍然是一个重要的未解决问题。
</details></li>
</ul>
<hr>
<h2 id="TarGEN-Targeted-Data-Generation-with-Large-Language-Models"><a href="#TarGEN-Targeted-Data-Generation-with-Large-Language-Models" class="headerlink" title="TarGEN: Targeted Data Generation with Large Language Models"></a>TarGEN: Targeted Data Generation with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17876">http://arxiv.org/abs/2310.17876</a></li>
<li>repo_url: None</li>
<li>paper_authors: Himanshu Gupta, Kevin Scaria, Ujjwala Anantheswaran, Shreyas Verma, Mihir Parmar, Saurabh Arjun Sawant, Chitta Baral, Swaroop Mishra</li>
<li>for: 这个论文旨在提供一种基于大语言模型（LLM）的多步指示策略，用于生成高质量的人工数据集。</li>
<li>methods: 该策略基于LLM，并且不需要特定任务实例，因此可以广泛应用于不同任务。另外， authors 还提出了一种自修复技术，以便LLM在数据创建过程中纠正错误标签。</li>
<li>results: 通过在8个SuperGLUE任务上训练不同类型的语言模型，包括编码器-解码器、编码器和解码器等，authors 发现 TarGEN 可以生成高质量的人工数据集，并且与原始数据集相比，模型在 TarGEN 数据集上训练后表现约1-2%点更高。<details>
<summary>Abstract</summary>
The rapid advancement of large language models (LLMs) has sparked interest in data synthesis techniques, aiming to generate diverse and high-quality synthetic datasets. However, these synthetic datasets often suffer from a lack of diversity and added noise. In this paper, we present TarGEN, a multi-step prompting strategy for generating high-quality synthetic datasets utilizing a LLM. An advantage of TarGEN is its seedless nature; it does not require specific task instances, broadening its applicability beyond task replication. We augment TarGEN with a method known as self-correction empowering LLMs to rectify inaccurately labeled instances during dataset creation, ensuring reliable labels. To assess our technique's effectiveness, we emulate 8 tasks from the SuperGLUE benchmark and finetune various language models, including encoder-only, encoder-decoder, and decoder-only models on both synthetic and original training sets. Evaluation on the original test set reveals that models trained on datasets generated by TarGEN perform approximately 1-2% points better than those trained on original datasets (82.84% via syn. vs. 81.12% on og. using Flan-T5). When incorporating instruction tuning, the performance increases to 84.54% on synthetic data vs. 81.49% on original data by Flan-T5. A comprehensive analysis of the synthetic dataset compared to the original dataset reveals that the synthetic dataset demonstrates similar or higher levels of dataset complexity and diversity. Furthermore, the synthetic dataset displays a bias level that aligns closely with the original dataset. Finally, when pre-finetuned on our synthetic SuperGLUE dataset, T5-3B yields impressive results on the OpenLLM leaderboard, surpassing the model trained on the Self-Instruct dataset by 4.14% points. We hope that TarGEN can be helpful for quality data generation and reducing the human efforts to create complex benchmarks.
</details>
<details>
<summary>摘要</summary>
LLMS 的快速进步已经引起了数据生成技术的兴趣，以生成多样化和高质量的synthetic dataset。然而，这些synthetic dataset经常受到缺乏多样性和附加噪音的问题困扰。在本文中，我们提出了 TarGEN，一种多步提示策略，通过 LLMS 来生成高质量的synthetic dataset。 TarGEN 的优点在于它不需要特定任务实例，因此其可以应用于任务复制以外的场景。我们还在 TarGEN 中添加了一种自修复技术，使 LLMS 能够在数据创建过程中纠正错误标签，以确保可靠的标签。为评估我们的技术效果，我们在SuperGLUEbenchmark中模拟了8个任务，并使用不同的语言模型进行训练。我们发现，使用 TarGEN 生成的synthetic dataset，模型在原始测试集上的性能约为1-2%点高于使用原始数据训练的模型（82.84% via syn. vs. 81.12% on og. using Flan-T5）。当将 instrucion tuning  incorporated 时，模型在synthetic数据上的性能提高到84.54% vs. 81.49% on original data by Flan-T5。我们对synthetic dataset和原始 dataset进行了全面的分析，发现synthetic dataset中的多样性和复杂性与原始 dataset相似或更高，并且噪音水平与原始 dataset相似。最后，当 T5-3B 在我们的synthetic SuperGLUE dataset上进行预训练后，在OpenLLM领头占据了4.14%点的优势。我们希望 TarGEN 可以帮助生成高质量的数据，并减少人类创建复杂的benchmark所需的努力。
</details></li>
</ul>
<hr>
<h2 id="From-Values-to-Opinions-Predicting-Human-Behaviors-and-Stances-Using-Value-Injected-Large-Language-Models"><a href="#From-Values-to-Opinions-Predicting-Human-Behaviors-and-Stances-Using-Value-Injected-Large-Language-Models" class="headerlink" title="From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models"></a>From Values to Opinions: Predicting Human Behaviors and Stances Using Value-Injected Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.17857">http://arxiv.org/abs/2310.17857</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dongjunkang/vim">https://github.com/dongjunkang/vim</a></li>
<li>paper_authors: Dongjun Kang, Joonsuk Park, Yohan Jo, JinYeong Bak</li>
<li>for: 预测人们对问题和行为的意见和选择在现实场景中有助于各领域，如政治和市场营销。</li>
<li>methods: 我们提出使用值批入大型自然语言模型（LLM）预测意见和行为，并提出了值批入方法（VIM），包括对话生成和问答方法，通过细化训练将目标价值分布注入到 LLM 中。</li>
<li>results: 我们对四个任务进行了一系列实验，发现使用值批入 LLM substantially 超过基eline，同时也发现使用值批入 LLM 可以更好地预测人们的意见和行为。<details>
<summary>Abstract</summary>
Being able to predict people's opinions on issues and behaviors in realistic scenarios can be helpful in various domains, such as politics and marketing. However, conducting large-scale surveys like the European Social Survey to solicit people's opinions on individual issues can incur prohibitive costs. Leveraging prior research showing influence of core human values on individual decisions and actions, we propose to use value-injected large language models (LLM) to predict opinions and behaviors. To this end, we present Value Injection Method (VIM), a collection of two methods -- argument generation and question answering -- designed to inject targeted value distributions into LLMs via fine-tuning. We then conduct a series of experiments on four tasks to test the effectiveness of VIM and the possibility of using value-injected LLMs to predict opinions and behaviors of people. We find that LLMs value-injected with variations of VIM substantially outperform the baselines. Also, the results suggest that opinions and behaviors can be better predicted using value-injected LLMs than the baseline approaches.
</details>
<details>
<summary>摘要</summary>
可以预测人们对问题和行为的意见在现实场景中是有帮助的，例如在政治和市场营销等领域。然而，进行大规模的民意调查，如欧洲社会调查，以获取人们对个别问题的意见可能会付出昂贵的代价。我们建议使用核心人类价值的影响于个人决策和行为的先前研究，并使用价值插入大语言模型（LLM）来预测意见和行为。为此，我们提出了价值插入方法（VIM），包括两种方法——论点生成和问答——用于在 LL M 中插入目标价值分布。我们then进行了四个任务的 série of experiments 来测试 VIM 的效果和使用价值插入 LL M 来预测人们的意见和行为的可能性。我们发现，使用 VIM 对 LL M 进行 fine-tuning 后，其表现substantially outperform baseline。此外，结果还表明，使用价值插入 LL M 可以更好地预测人们的意见和行为， чем基eline Approaches。
</details></li>
</ul>
<hr>
<h2 id="SQLformer-Deep-Auto-Regressive-Query-Graph-Generation-for-Text-to-SQL-Translation"><a href="#SQLformer-Deep-Auto-Regressive-Query-Graph-Generation-for-Text-to-SQL-Translation" class="headerlink" title="SQLformer: Deep Auto-Regressive Query Graph Generation for Text-to-SQL Translation"></a>SQLformer: Deep Auto-Regressive Query Graph Generation for Text-to-SQL Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2310.18376">http://arxiv.org/abs/2310.18376</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adrián Bazaga, Pietro Liò, Gos Micklem</li>
<li>for: 这个论文旨在解决文本到SQL翻译 зада务中的难题，即将自然语言问题转换成可执行的SQL查询。</li>
<li>methods: 该论文提出了一种名为SQLformer的新的Transformer架构，用于实现文本到SQL翻译任务。该模型预测SQL查询为抽象 syntax tree（AST），并在核心层采用了结构卷积激活。</li>
<li>results: 对于文本到SQL Spider测试集，SQLformer显示出了最新的表现，并且在适应不同数据库和查询任务中具有良好的泛化能力。<details>
<summary>Abstract</summary>
In recent years, there has been growing interest in text-to-SQL translation, which is the task of converting natural language questions into executable SQL queries. This technology is important for its potential to democratize data extraction from databases. However, some of its key hurdles include domain generalisation, which is the ability to adapt to previously unseen databases, and alignment of natural language questions with the corresponding SQL queries. To overcome these challenges, we introduce SQLformer, a novel Transformer architecture specifically crafted to perform text-to-SQL translation tasks. Our model predicts SQL queries as abstract syntax trees (ASTs) in an autoregressive way, incorporating structural inductive bias in the encoder and decoder layers. This bias, guided by database table and column selection, aids the decoder in generating SQL query ASTs represented as graphs in a Breadth-First Search canonical order. Comprehensive experiments illustrate the state-of-the-art performance of SQLformer in the challenging text-to-SQL Spider benchmark. Our implementation is available at https://github.com/AdrianBZG/SQLformer
</details>
<details>
<summary>摘要</summary>
近年来，文本到SQL翻译技术已经受到了越来越多的关注，这是将自然语言问题转换成可执行的SQL查询的任务。这种技术可以帮助普通人从数据库中提取数据。然而，这个技术的一些关键挑战包括领域总结，即将数据库中的数据映射到自然语言中，以及自然语言问题与相应的SQL查询的对应。为了解决这些挑战，我们提出了SQLformer，一种专门为文本到SQL翻译任务设计的Transformer架构。我们的模型预测SQL查询为抽象语法树（AST），并在树和树之间具有指导性的结构卷积。这种卷积引导了数据库表和列的选择，帮助解码器生成SQL查询AST表示为图形，并在深度优先搜索中遍历。我们的实现可以在https://github.com/AdrianBZG/SQLformer上获取。Please note that the translation is in Simplified Chinese, which is one of the two standard forms of Chinese. If you prefer Traditional Chinese, please let me know and I can provide the translation in that form instead.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/10/27/cs.CL_2023_10_27/" data-id="cloh7tqen00d97b88fews8pym" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/3/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="page-number" href="/page/6/">6</a><span class="space">&hellip;</span><a class="page-number" href="/page/84/">84</a><a class="extend next" rel="next" href="/page/5/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">122</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">116</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">56</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">112</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">62</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">8</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
