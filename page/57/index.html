
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/57/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-eess.IV_2023_08_10" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/10/eess.IV_2023_08_10/" class="article-date">
  <time datetime="2023-08-10T09:00:00.000Z" itemprop="datePublished">2023-08-10</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/10/eess.IV_2023_08_10/">eess.IV - 2023-08-10</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Attention-based-3D-CNN-with-Multi-layer-Features-for-Alzheimer’s-Disease-Diagnosis-using-Brain-Images"><a href="#Attention-based-3D-CNN-with-Multi-layer-Features-for-Alzheimer’s-Disease-Diagnosis-using-Brain-Images" class="headerlink" title="Attention-based 3D CNN with Multi-layer Features for Alzheimer’s Disease Diagnosis using Brain Images"></a>Attention-based 3D CNN with Multi-layer Features for Alzheimer’s Disease Diagnosis using Brain Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05655">http://arxiv.org/abs/2308.05655</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanteng Zhang, Qizhi Teng, Xiaohai He, Tong Niu, Lipei Zhang, Yan Liu, Chao Ren</li>
<li>for: 这个研究旨在提高阿尔茨海默病（AD）诊断的准确性，通过结合深度学习和神经网络，从脑图像中提取有用的特征，以便更好地识别阿尔茨海默病。</li>
<li>methods: 本研究使用了一个终端到端的3D CNN框架，基于ResNet，具有多层特征，并通过注意力机制来更好地捕捉脑图像中的微scopic变化。</li>
<li>results: 我们的方法在ADNI数据库上进行了ablation实验，使用了两种数据模式，获得了89.71%和91.18%的AD诊断准确性，并超过了一些现有的方法。<details>
<summary>Abstract</summary>
Structural MRI and PET imaging play an important role in the diagnosis of Alzheimer's disease (AD), showing the morphological changes and glucose metabolism changes in the brain respectively. The manifestations in the brain image of some cognitive impairment patients are relatively inconspicuous, for example, it still has difficulties in achieving accurate diagnosis through sMRI in clinical practice. With the emergence of deep learning, convolutional neural network (CNN) has become a valuable method in AD-aided diagnosis, but some CNN methods cannot effectively learn the features of brain image, making the diagnosis of AD still presents some challenges. In this work, we propose an end-to-end 3D CNN framework for AD diagnosis based on ResNet, which integrates multi-layer features obtained under the effect of the attention mechanism to better capture subtle differences in brain images. The attention maps showed our model can focus on key brain regions related to the disease diagnosis. Our method was verified in ablation experiments with two modality images on 792 subjects from the ADNI database, where AD diagnostic accuracies of 89.71% and 91.18% were achieved based on sMRI and PET respectively, and also outperformed some state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
Magnetic Resonance Imaging (MRI) 和 Positron Emission Tomography (PET) 影像技术在诊断阿尔茨海默病 (AD) 中扮演着重要的角色，显示了脑部的形态变化和葡萄糖代谢变化。但是，在临床实践中，使用深度学习的时候，一些 convolutional neural network (CNN) 方法无法有效地学习脑部影像中的特征，从而使得 AD 的诊断仍然存在一些挑战。在这项工作中，我们提出了基于 ResNet 的终端三维 CNN 框架，该框架可以更好地捕捉脑部影像中的微小差异。我们的注意力地図显示了我们的模型可以更好地关注与疾病诊断相关的关键脑部区域。我们的方法在 ADNI 数据库中进行了ablation实验，使用两种模式的图像进行诊断，并达到了89.71% 和 91.18% 的 AD 诊断精度。此外，我们的方法还超过了一些当前的状态艺术方法。
</details></li>
</ul>
<hr>
<h2 id="SAR-Target-Image-Generation-Method-Using-Azimuth-Controllable-Generative-Adversarial-Network"><a href="#SAR-Target-Image-Generation-Method-Using-Azimuth-Controllable-Generative-Adversarial-Network" class="headerlink" title="SAR Target Image Generation Method Using Azimuth-Controllable Generative Adversarial Network"></a>SAR Target Image Generation Method Using Azimuth-Controllable Generative Adversarial Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05489">http://arxiv.org/abs/2308.05489</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenwei Wang, Jifang Pei, Xiaoyu Liu, Yulin Huang, Deqing Mao, Yin Zhang, Jianyu Yang</li>
<li>for: 提高Synthetic Aperture Radar（SAR）图像的研究进程，适用于SAR图像的开发和应用。</li>
<li>methods: 提出了一种azimuth-controllable生成 adversarial network（GAN），用于生成精确的SAR图像，并可控制图像的Azimuth。该网络主要包括三部分：生成器、推理器和判别器。生成器可以从两个输入SAR图像中提取和融合最佳目标特征，生成SAR图像。而判别器和预测器则可以确定生成的SAR图像的准确性和Azimuth。</li>
<li>results: 通过对多个实验来说，提出的方法可以具有较好的Azimuth控制和SAR图像生成精度。<details>
<summary>Abstract</summary>
Sufficient synthetic aperture radar (SAR) target images are very important for the development of researches. However, available SAR target images are often limited in practice, which hinders the progress of SAR application. In this paper, we propose an azimuth-controllable generative adversarial network to generate precise SAR target images with an intermediate azimuth between two given SAR images' azimuths. This network mainly contains three parts: generator, discriminator, and predictor. Through the proposed specific network structure, the generator can extract and fuse the optimal target features from two input SAR target images to generate SAR target image. Then a similarity discriminator and an azimuth predictor are designed. The similarity discriminator can differentiate the generated SAR target images from the real SAR images to ensure the accuracy of the generated, while the azimuth predictor measures the difference of azimuth between the generated and the desired to ensure the azimuth controllability of the generated. Therefore, the proposed network can generate precise SAR images, and their azimuths can be controlled well by the inputs of the deep network, which can generate the target images in different azimuths to solve the small sample problem to some degree and benefit the researches of SAR images. Extensive experimental results show the superiority of the proposed method in azimuth controllability and accuracy of SAR target image generation.
</details>
<details>
<summary>摘要</summary>
够多的Synthetic Aperture Radar（SAR）目标图像非常重要 для研究发展。然而，实际中可用的SAR目标图像往往受限，这会阻碍SAR应用的进步。在这篇论文中，我们提出了一种 azimuth 可控的生成对抗网络，可以生成具有中间 azimuth 的精准 SAR 目标图像。该网络主要包括三部分：生成器、判别器和预测器。通过我们的具体网络结构，生成器可以从两个输入 SAR 目标图像中提取和融合最佳的目标特征，生成 SAR 目标图像。然后，我们设计了一个相似性判别器和一个 azimuth 预测器。相似性判别器可以判断生成的 SAR 目标图像是否与实际 SAR 图像相似，以确保生成的准确性。而 azimuth 预测器则可以测量生成的 azimuth 与所需的 azimuth 之间的差异，以确保生成的 azimuth 可控性。因此，我们的网络可以生成精准的 SAR 目标图像，并且可以通过输入深度网络的参数控制生成的 azimuth。这有助于解决小样本问题，并为 SAR 图像研究提供一些答案。我们的实验结果表明，我们的方法在 azimuth 可控性和精准性方面具有显著优势。
</details></li>
</ul>
<hr>
<h2 id="Surface-Masked-AutoEncoder-Self-Supervision-for-Cortical-Imaging-Data"><a href="#Surface-Masked-AutoEncoder-Self-Supervision-for-Cortical-Imaging-Data" class="headerlink" title="Surface Masked AutoEncoder: Self-Supervision for Cortical Imaging Data"></a>Surface Masked AutoEncoder: Self-Supervision for Cortical Imaging Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05474">http://arxiv.org/abs/2308.05474</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/metrics-lab/surface-vision-transformers">https://github.com/metrics-lab/surface-vision-transformers</a></li>
<li>paper_authors: Simon Dahan, Mariana da Silva, Daniel Rueckert, Emma C Robinson</li>
<li>for: This paper aims to improve the performance of vision transformer models in cortical surface learning tasks, specifically in the context of cortical imaging where datasets are limited in size.</li>
<li>methods: The proposed method uses Masked AutoEncoder (MAE) self-supervision to pre-train vision transformer models on large datasets, such as the UK Biobank (UKB), and then fine-tunes the models on smaller cortical phenotype regression datasets.</li>
<li>results: The pre-trained models achieve a 26% improvement in performance and an 80% faster convergence compared to models trained from scratch, demonstrating the effectiveness of the proposed method in learning strong representations for cortical surface learning tasks.<details>
<summary>Abstract</summary>
Self-supervision has been widely explored as a means of addressing the lack of inductive biases in vision transformer architectures, which limits generalisation when networks are trained on small datasets. This is crucial in the context of cortical imaging, where phenotypes are complex and heterogeneous, but the available datasets are limited in size. This paper builds upon recent advancements in translating vision transformers to surface meshes and investigates the potential of Masked AutoEncoder (MAE) self-supervision for cortical surface learning. By reconstructing surface data from a masked version of the input, the proposed method effectively models cortical structure to learn strong representations that translate to improved performance in downstream tasks. We evaluate our approach on cortical phenotype regression using the developing Human Connectome Project (dHCP) and demonstrate that pre-training leads to a 26\% improvement in performance, with an 80\% faster convergence, compared to models trained from scratch. Furthermore, we establish that pre-training vision transformer models on large datasets, such as the UK Biobank (UKB), enables the acquisition of robust representations for finetuning in low-data scenarios. Our code and pre-trained models are publicly available at \url{https://github.com/metrics-lab/surface-vision-transformers}.
</details>
<details>
<summary>摘要</summary>
自我超视听已经广泛探索了用于解决视transformer架构中缺乏逻辑假设的问题，这限制了通用化 quando networks是在小数据集上训练的。这篇文章基于latest advancements in translating vision transformers to surface meshes, and investigates the potential of Masked AutoEncoder (MAE) self-supervision for cortical surface learning. By reconstructing surface data from a masked version of the input, the proposed method effectively models cortical structure to learn strong representations that translate to improved performance in downstream tasks. We evaluate our approach on cortical phenotype regression using the developing Human Connectome Project (dHCP) and demonstrate that pre-training leads to a 26% improvement in performance, with an 80% faster convergence, compared to models trained from scratch. Furthermore, we establish that pre-training vision transformer models on large datasets, such as the UK Biobank (UKB), enables the acquisition of robust representations for finetuning in low-data scenarios. Our code and pre-trained models are publicly available at \url{https://github.com/metrics-lab/surface-vision-transformers}.Note: The translation is in Simplified Chinese, which is one of the two standard forms of Chinese writing. The other form is Traditional Chinese.
</details></li>
</ul>
<hr>
<h2 id="Global-in-Local-A-Convolutional-Transformer-for-SAR-ATR-FSL"><a href="#Global-in-Local-A-Convolutional-Transformer-for-SAR-ATR-FSL" class="headerlink" title="Global in Local: A Convolutional Transformer for SAR ATR FSL"></a>Global in Local: A Convolutional Transformer for SAR ATR FSL</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05464">http://arxiv.org/abs/2308.05464</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenwei Wang, Yulin Huang, Xiaoyu Liu, Jifang Pei, Yin Zhang, Jianyu Yang</li>
<li>for: 提高Synthetic Aperture Radar（SAR）自动目标识别（ATR）的几何学学习性能，特别是在有限SAR图像的情况下。</li>
<li>methods: 提出了一种Convolutional Transformer（ConvT）模型，通过建立层次特征表示和捕捉每层的全局依赖关系，解决了SAR图像中的局部特征之间的关系不够紧密的问题。同时，提出了一种新的混合损失函数，可以在几个SAR图像中提取相似和不相似的图像对，以便优化ConvT模型。</li>
<li>results: 在Moving and Stationary Target Acquisition and Recognition（MSTAR）数据集上进行了实验，并达到了 pioneering 的性能，不需要其他SAR目标图像进行训练。<details>
<summary>Abstract</summary>
Convolutional neural networks (CNNs) have dominated the synthetic aperture radar (SAR) automatic target recognition (ATR) for years. However, under the limited SAR images, the width and depth of the CNN-based models are limited, and the widening of the received field for global features in images is hindered, which finally leads to the low performance of recognition. To address these challenges, we propose a Convolutional Transformer (ConvT) for SAR ATR few-shot learning (FSL). The proposed method focuses on constructing a hierarchical feature representation and capturing global dependencies of local features in each layer, named global in local. A novel hybrid loss is proposed to interpret the few SAR images in the forms of recognition labels and contrastive image pairs, construct abundant anchor-positive and anchor-negative image pairs in one batch and provide sufficient loss for the optimization of the ConvT to overcome the few sample effect. An auto augmentation is proposed to enhance and enrich the diversity and amount of the few training samples to explore the hidden feature in a few SAR images and avoid the over-fitting in SAR ATR FSL. Experiments conducted on the Moving and Stationary Target Acquisition and Recognition dataset (MSTAR) have shown the effectiveness of our proposed ConvT for SAR ATR FSL. Different from existing SAR ATR FSL methods employing additional training datasets, our method achieved pioneering performance without other SAR target images in training.
</details>
<details>
<summary>摘要</summary>
convolutional neural networks (CNNs) have dominated the synthetic aperture radar (SAR) automatic target recognition (ATR) for years. However, under the limited SAR images, the width and depth of the CNN-based models are limited, and the widening of the received field for global features in images is hindered, which finally leads to the low performance of recognition. To address these challenges, we propose a Convolutional Transformer (ConvT) for SAR ATR few-shot learning (FSL). The proposed method focuses on constructing a hierarchical feature representation and capturing global dependencies of local features in each layer, named global in local. A novel hybrid loss is proposed to interpret the few SAR images in the forms of recognition labels and contrastive image pairs, construct abundant anchor-positive and anchor-negative image pairs in one batch and provide sufficient loss for the optimization of the ConvT to overcome the few sample effect. An auto augmentation is proposed to enhance and enrich the diversity and amount of the few training samples to explore the hidden feature in a few SAR images and avoid the over-fitting in SAR ATR FSL. Experiments conducted on the Moving and Stationary Target Acquisition and Recognition dataset (MSTAR) have shown the effectiveness of our proposed ConvT for SAR ATR FSL. Different from existing SAR ATR FSL methods employing additional training datasets, our method achieved pioneering performance without other SAR target images in training.Here's the breakdown of the translation:* "convolutional neural networks" is translated as " convolutional neural networks" (同 "convolutional neural networks" in English)* "synthetic aperture radar" is translated as "干扰雷达" (a common translation for "synthetic aperture radar")* "automatic target recognition" is translated as "自动目标识别" (a common translation for "automatic target recognition")* "few-shot learning" is translated as "少量学习" (a common translation for "few-shot learning")* "Convolutional Transformer" is translated as "卷积变换器" (a common translation for "Convolutional Transformer")* "Moving and Stationary Target Acquisition and Recognition dataset" is translated as "移动和静止目标获取和识别数据集" (a common translation for "Moving and Stationary Target Acquisition and Recognition dataset")Note that the translation is in Simplified Chinese, which is the most widely used version of Chinese. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Transforming-Breast-Cancer-Diagnosis-Towards-Real-Time-Ultrasound-to-Mammogram-Conversion-for-Cost-Effective-Diagnosis"><a href="#Transforming-Breast-Cancer-Diagnosis-Towards-Real-Time-Ultrasound-to-Mammogram-Conversion-for-Cost-Effective-Diagnosis" class="headerlink" title="Transforming Breast Cancer Diagnosis: Towards Real-Time Ultrasound to Mammogram Conversion for Cost-Effective Diagnosis"></a>Transforming Breast Cancer Diagnosis: Towards Real-Time Ultrasound to Mammogram Conversion for Cost-Effective Diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05449">http://arxiv.org/abs/2308.05449</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sahar Almahfouz Nasser, Ashutosh Sharma, Anmol Saraf, Amruta Mahendra Parulekar, Purvi Haria, Amit Sethi<br>for: This research aims to provide surgeons with mammogram-like image quality in real-time from noisy US images.methods: The research utilizes the Stride software to numerically solve the forward model and generate ultrasound images from mammography images. Additionally, generative adversarial networks (GANs) are used to tackle the inverse problem of generating mammogram-quality images from ultrasound images.results: The resultant images have considerably more discernible details than the original US images.<details>
<summary>Abstract</summary>
Ultrasound (US) imaging is better suited for intraoperative settings because it is real-time and more portable than other imaging techniques, such as mammography. However, US images are characterized by lower spatial resolution noise-like artifacts. This research aims to address these limitations by providing surgeons with mammogram-like image quality in real-time from noisy US images. Unlike previous approaches for improving US image quality that aim to reduce artifacts by treating them as (speckle noise), we recognize their value as informative wave interference pattern (WIP). To achieve this, we utilize the Stride software to numerically solve the forward model, generating ultrasound images from mammograms images by solving wave-equations. Additionally, we leverage the power of domain adaptation to enhance the realism of the simulated ultrasound images. Then, we utilize generative adversarial networks (GANs) to tackle the inverse problem of generating mammogram-quality images from ultrasound images. The resultant images have considerably more discernible details than the original US images.
</details>
<details>
<summary>摘要</summary>
超声成像（US）在操作间更适合使用，因为它们是实时的，更携带性好于其他成像技术，如胸部X光图像。然而，US图像受到低分辨率噪声杂音的限制。这些研究希望通过为外科医生提供来自噪声US图像的高品质图像，例如胸部X光图像的品质。不同于以往的方法，我们不会将噪声视为干扰，而是认为它们是有用的波形干扰（WIP）。为了实现这一目标，我们利用Stride软件来数学模拟前向模型，将ultrasound图像转换成胸部X光图像，并利用领域适应来增强模拟的超声图像的实际性。然后，我们利用生成对抗网络（GANs）解决超声图像到胸部X光图像的逆问题，得到了胸部X光图像的高品质图像。这些图像的详细程度明显高于原始US图像。
</details></li>
</ul>
<hr>
<h2 id="A-Generalized-Physical-knowledge-guided-Dynamic-Model-for-Underwater-Image-Enhancement"><a href="#A-Generalized-Physical-knowledge-guided-Dynamic-Model-for-Underwater-Image-Enhancement" class="headerlink" title="A Generalized Physical-knowledge-guided Dynamic Model for Underwater Image Enhancement"></a>A Generalized Physical-knowledge-guided Dynamic Model for Underwater Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05447">http://arxiv.org/abs/2308.05447</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pan Mu, Hanning Xu, Zheyuan Liu, Zheng Wang, Sixian Chan, Cong Bai</li>
<li>for: 这个论文是为了提出一种基于物理知识导向的普适水下图像增强方法（GUPDM），以解决水下图像受到散射和吸收的光影响，导致图像颜色扭曲和对比度低下的问题。</li>
<li>methods: 这个方法包括三部分：大气基于动态结构（ADS）、传输基于动态结构（TDS）和优先级基于多尺度结构（PMS）。特别是，为了涵盖复杂的水下场景，这种研究改变了全球大气光和传输，通过形成模型来模拟不同类型的水下图像（如水下图像颜色从黄到蓝）。然后，ADS和TDS使用动态 convolution来自适应地提取水下图像中的准确信息，并生成 Parameters for PMS。</li>
<li>results: 这个方法可以适应不同类型的水下图像，并且可以提高水下图像的对比度和颜色准确性。具体来说，对于不同的水类型，这个方法可以自动选择合适的参数，从而提高图像增强的效果。<details>
<summary>Abstract</summary>
Underwater images often suffer from color distortion and low contrast resulting in various image types, due to the scattering and absorption of light by water. While it is difficult to obtain high-quality paired training samples with a generalized model. To tackle these challenges, we design a Generalized Underwater image enhancement method via a Physical-knowledge-guided Dynamic Model (short for GUPDM), consisting of three parts: Atmosphere-based Dynamic Structure (ADS), Transmission-guided Dynamic Structure (TDS), and Prior-based Multi-scale Structure (PMS). In particular, to cover complex underwater scenes, this study changes the global atmosphere light and the transmission to simulate various underwater image types (e.g., the underwater image color ranging from yellow to blue) through the formation model. We then design ADS and TDS that use dynamic convolutions to adaptively extract prior information from underwater images and generate parameters for PMS. These two modules enable the network to select appropriate parameters for various water types adaptively. Besides, the multi-scale feature extraction module in PMS uses convolution blocks with different kernel sizes and obtains weights for each feature map via channel attention block and fuses them to boost the receptive field of the network. The source code will be available at \href{https://github.com/shiningZZ/GUPDM}{https://github.com/shiningZZ/GUPDM}.
</details>
<details>
<summary>摘要</summary>
水下图像经常受到颜色扭曲和对比度低下，导致各种图像类型，这是由水媒体扩散和吸收光线所致。而获得高质量的通用模型 paired 训练样本很难。为了解决这些挑战，我们设计了一种通用水下图像提升方法，通过物理知识导引动模型（简称 GUPDM），它由三部分组成：大气基础动态结构（ADS）、传输基础动态结构（TDS）和优先级多尺度结构（PMS）。具体来说，为了处理复杂的水下场景，本研究通过形成模型来改变全球大气光和传输，模拟不同的水下图像颜色（例如，水下图像颜色从黄色到蓝色）。然后，我们设计了 ADS 和 TDS，它们使用动态滤波器来自适应地提取水下图像中的优先信息，并生成参数 для PMS。这两个模块使得网络可以在不同的水类型上适应性选择合适的参数。此外，PMS 中的多尺度特征提取模块使用不同的核群尺寸和权重获取器，通过通道注意力块并将其拼接起来，以提高网络的感知范围。源代码将在 \href{https://github.com/shiningZZ/GUPDM}{https://github.com/shiningZZ/GUPDM} 上公开。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Low-light-Light-Field-Images-with-A-Deep-Compensation-Unfolding-Network"><a href="#Enhancing-Low-light-Light-Field-Images-with-A-Deep-Compensation-Unfolding-Network" class="headerlink" title="Enhancing Low-light Light Field Images with A Deep Compensation Unfolding Network"></a>Enhancing Low-light Light Field Images with A Deep Compensation Unfolding Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05404">http://arxiv.org/abs/2308.05404</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lyuxianqiang/lfll-dcu">https://github.com/lyuxianqiang/lfll-dcu</a></li>
<li>paper_authors: Xianqiang Lyu, Junhui Hou</li>
<li>for:  restore low-light light field images</li>
<li>methods: 使用 deep compensation unfolding network (DCUNet) 和 pseudo-explicit feature interaction module</li>
<li>results: 比革命性更好，保留图像的基本 геометрическую结构Here’s a breakdown of each point:1. for: The paper is written for restoring low-light light field images.2. methods: The paper uses a novel and interpretable end-to-end learning framework called the deep compensation unfolding network (DCUNet), which is designed to mimic the optimization process of solving an inverse imaging problem in a data-driven fashion. The framework includes a multi-stage architecture and a content-associated deep compensation module to suppress noise and illumination map estimation errors. Additionally, the paper proposes a pseudo-explicit feature interaction module to comprehensively exploit redundant information in LF images.3. results: The experimental results on both simulated and real datasets demonstrate the superiority of the DCUNet over state-of-the-art methods, both qualitatively and quantitatively. The results also show that DCUNet preserves the essential geometric structure of enhanced LF images much better than other methods.<details>
<summary>Abstract</summary>
This paper presents a novel and interpretable end-to-end learning framework, called the deep compensation unfolding network (DCUNet), for restoring light field (LF) images captured under low-light conditions. DCUNet is designed with a multi-stage architecture that mimics the optimization process of solving an inverse imaging problem in a data-driven fashion. The framework uses the intermediate enhanced result to estimate the illumination map, which is then employed in the unfolding process to produce a new enhanced result. Additionally, DCUNet includes a content-associated deep compensation module at each optimization stage to suppress noise and illumination map estimation errors. To properly mine and leverage the unique characteristics of LF images, this paper proposes a pseudo-explicit feature interaction module that comprehensively exploits redundant information in LF images. The experimental results on both simulated and real datasets demonstrate the superiority of our DCUNet over state-of-the-art methods, both qualitatively and quantitatively. Moreover, DCUNet preserves the essential geometric structure of enhanced LF images much better. The code will be publicly available at https://github.com/lyuxianqiang/LFLL-DCU.
</details>
<details>
<summary>摘要</summary>
To fully utilize the unique characteristics of LF images, this paper proposes a pseudo-explicit feature interaction module that comprehensively exploits redundant information in LF images. The experimental results on both simulated and real datasets demonstrate the superiority of our DCUNet over state-of-the-art methods, both qualitatively and quantitatively. Moreover, DCUNet preserves the essential geometric structure of enhanced LF images much better. The code will be publicly available at https://github.com/lyuxianqiang/LFLL-DCU.中文翻译：本文提出了一种新的、可解释的端到端学习框架，called deep compensation unfolding network (DCUNet)，用于提高低光照的光场图像（LF）。DCUNet 采用了多stage 架构，模拟了解决逆转媒体问题的优化过程。框架使用 intermediate 增强结果来估算照明图像，然后employs 它们在 unfolding 过程中生成新的增强结果。此外，DCUNet 还包括一个内容相关的深度补偿模块，以 suppress 噪声和照明图像估算错误。为了充分利用光场图像的特点，这篇文章提出了一种 Pseudo-explicit feature interaction module，可以全面利用光场图像中的重复信息。实验结果表明，我们的 DCUNet 在实际和模拟数据集上比 state-of-the-art 方法更高效， both qualitatively and quantitatively。此外，DCUNet 更好地保持了增强后 LF 图像的重要几何结构。代码将在 https://github.com/lyuxianqiang/LFLL-DCU 上公开。
</details></li>
</ul>
<hr>
<h2 id="TriDo-Former-A-Triple-Domain-Transformer-for-Direct-PET-Reconstruction-from-Low-Dose-Sinograms"><a href="#TriDo-Former-A-Triple-Domain-Transformer-for-Direct-PET-Reconstruction-from-Low-Dose-Sinograms" class="headerlink" title="TriDo-Former: A Triple-Domain Transformer for Direct PET Reconstruction from Low-Dose Sinograms"></a>TriDo-Former: A Triple-Domain Transformer for Direct PET Reconstruction from Low-Dose Sinograms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05365">http://arxiv.org/abs/2308.05365</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gluucose/TriDoFormer">https://github.com/gluucose/TriDoFormer</a></li>
<li>paper_authors: Jiaqi Cui, Pinxian Zeng, Xinyi Zeng, Peng Wang, Xi Wu, Jiliu Zhou, Yan Wang, Dinggang Shen</li>
<li>For: 提高低剂量Positron发射Tomography（PET）图像质量，以降低辐射暴露。* Methods: 提出一种基于变换器的模型，称为TriDo-Former，可以直接将低剂量PET（LPET）的信号转换为标准剂量PET（SPET）图像。该模型包括两个融合的网络：一个权重提升变换器（SE-Former）用于去噪LPET信号，以及一个空间-спектраль重建变换器（SSR-Former）用于从去噪后的LPET信号中重建SPET图像。* Results: 与现有方法相比，TriDo-Former可以更好地保持图像的细节和边缘，并且能够更好地捕捉全局结构。在临床数据集上进行验证，TriDo-Former表现较好，both qualitatively and quantitatively。<details>
<summary>Abstract</summary>
To obtain high-quality positron emission tomography (PET) images while minimizing radiation exposure, various methods have been proposed for reconstructing standard-dose PET (SPET) images from low-dose PET (LPET) sinograms directly. However, current methods often neglect boundaries during sinogram-to-image reconstruction, resulting in high-frequency distortion in the frequency domain and diminished or fuzzy edges in the reconstructed images. Furthermore, the convolutional architectures, which are commonly used, lack the ability to model long-range non-local interactions, potentially leading to inaccurate representations of global structures. To alleviate these problems, we propose a transformer-based model that unites triple domains of sinogram, image, and frequency for direct PET reconstruction, namely TriDo-Former. Specifically, the TriDo-Former consists of two cascaded networks, i.e., a sinogram enhancement transformer (SE-Former) for denoising the input LPET sinograms and a spatial-spectral reconstruction transformer (SSR-Former) for reconstructing SPET images from the denoised sinograms. Different from the vanilla transformer that splits an image into 2D patches, based specifically on the PET imaging mechanism, our SE-Former divides the sinogram into 1D projection view angles to maintain its inner-structure while denoising, preventing the noise in the sinogram from prorogating into the image domain. Moreover, to mitigate high-frequency distortion and improve reconstruction details, we integrate global frequency parsers (GFPs) into SSR-Former. The GFP serves as a learnable frequency filter that globally adjusts the frequency components in the frequency domain, enforcing the network to restore high-frequency details resembling real SPET images. Validations on a clinical dataset demonstrate that our TriDo-Former outperforms the state-of-the-art methods qualitatively and quantitatively.
</details>
<details>
<summary>摘要</summary>
为了获得高质量的 positron发射tomography（PET）图像，同时尽量降低辐射暴露，various methods have been proposed for reconstructing standard-dose PET（SPET）图像 directly from low-dose PET（LPET）sinograms. However, current methods often neglect boundaries during sinogram-to-image reconstruction, resulting in high-frequency distortion in the frequency domain and diminished or fuzzy edges in the reconstructed images. Furthermore, the convolutional architectures, which are commonly used, lack the ability to model long-range non-local interactions, potentially leading to inaccurate representations of global structures. To alleviate these problems, we propose a transformer-based model that unites triple domains of sinogram, image, and frequency for direct PET reconstruction, namely TriDo-Former. Specifically, the TriDo-Former consists of two cascaded networks, i.e., a sinogram enhancement transformer (SE-Former) for denoising the input LPET sinograms and a spatial-spectral reconstruction transformer (SSR-Former) for reconstructing SPET images from the denoised sinograms. Different from the vanilla transformer that splits an image into 2D patches, based specifically on the PET imaging mechanism, our SE-Former divides the sinogram into 1D projection view angles to maintain its inner-structure while denoising, preventing the noise in the sinogram from propagating into the image domain. Moreover, to mitigate high-frequency distortion and improve reconstruction details, we integrate global frequency parsers (GFPs) into SSR-Former. The GFP serves as a learnable frequency filter that globally adjusts the frequency components in the frequency domain, enforcing the network to restore high-frequency details resembling real SPET images. Validations on a clinical dataset demonstrate that our TriDo-Former outperforms the state-of-the-art methods qualitatively and quantitatively.
</details></li>
</ul>
<hr>
<h2 id="Towards-General-and-Fast-Video-Derain-via-Knowledge-Distillation"><a href="#Towards-General-and-Fast-Video-Derain-via-Knowledge-Distillation" class="headerlink" title="Towards General and Fast Video Derain via Knowledge Distillation"></a>Towards General and Fast Video Derain via Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05346">http://arxiv.org/abs/2308.05346</a></li>
<li>repo_url: None</li>
<li>paper_authors: Defang Cai, Pan Mu, Sixian Chan, Zhanpeng Shao, Cong Bai</li>
<li>for: 本研究旨在提出一种能够处理不同雨梦模式的通用视频雨除网络（名为RRGNet），以优化视频雨除性能。</li>
<li>methods: 我们设计了一个基于帧分组的Encoder-Decoder网络，以利用视频的时间信息。此外，我们还使用了老任务模型来导引当前模型学习新的雨梦模式，以避免忘记现有的知识。</li>
<li>results: 我们的开发的通用方法在运行速度和雨除效果两个方面达到了最佳效果。<details>
<summary>Abstract</summary>
As a common natural weather condition, rain can obscure video frames and thus affect the performance of the visual system, so video derain receives a lot of attention. In natural environments, rain has a wide variety of streak types, which increases the difficulty of the rain removal task. In this paper, we propose a Rain Review-based General video derain Network via knowledge distillation (named RRGNet) that handles different rain streak types with one pre-training weight. Specifically, we design a frame grouping-based encoder-decoder network that makes full use of the temporal information of the video. Further, we use the old task model to guide the current model in learning new rain streak types while avoiding forgetting. To consolidate the network's ability to derain, we design a rain review module to play back data from old tasks for the current model. The experimental results show that our developed general method achieves the best results in terms of running speed and derain effect.
</details>
<details>
<summary>摘要</summary>
为了解决雨水影响视觉系统性能的问题，视频雨除（video derain）已经受到了广泛的关注。自然环境中的雨水有多种斑斓类型，这使得雨除任务变得更加困难。在这篇论文中，我们提出了一种基于知识储存（knowledge distillation）的通用视频雨除网络（RRGNet），可以处理不同的雨斑类型。具体来说，我们设计了一个帧组合网络，使得网络可以充分利用视频的时间信息。此外，我们使用老任务模型来导引当前模型学习新的雨斑类型，以避免忘记。为了巩固网络的雨除能力，我们设计了雨评模块，以便将老任务数据播放给当前模型。实验结果表明，我们开发的通用方法在运行速度和雨除效果两个方面均达到了最佳效果。
</details></li>
</ul>
<hr>
<h2 id="Geometric-Learning-Based-Transformer-Network-for-Estimation-of-Segmentation-Errors"><a href="#Geometric-Learning-Based-Transformer-Network-for-Estimation-of-Segmentation-Errors" class="headerlink" title="Geometric Learning-Based Transformer Network for Estimation of Segmentation Errors"></a>Geometric Learning-Based Transformer Network for Estimation of Segmentation Errors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05068">http://arxiv.org/abs/2308.05068</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sneha Sree C, Mohammad Al Fahim, Keerthi Ram, Mohanasankar Sivaprakasam</li>
<li>for: 这个研究的目的是提供一个用于检查和评估遗传学网络（Graph Neural Network，GNN） segmentation 结果的方法，以帮助医院和临床机构优化遗传学网络的准确性。</li>
<li>methods: 这个方法使用了一个基于 Transformer 架构的 Graph Neural Network（Nodeformer）来量化和分类遗传学网络的批评点误差。它使用了一个对应映射（correspondence mapping）来将遗传学网络的点误差转换为点批评点误差，然后使用 Multi-Layer Perceptron（MLP）来计算和分类点批评点误差。</li>
<li>results: 这个方法在一个高分辨率微型CT数据集上进行了评估，结果显示它可以实现约0.042的平均绝对误差和79.53%的准确率，优于其他 Graph Neural Network（GNN）。此外，这个方法还提出了点批评点预测（vertex-normal prediction）作为自适应任务，以提高网络的总性能。<details>
<summary>Abstract</summary>
Many segmentation networks have been proposed for 3D volumetric segmentation of tumors and organs at risk. Hospitals and clinical institutions seek to accelerate and minimize the efforts of specialists in image segmentation. Still, in case of errors generated by these networks, clinicians would have to manually edit the generated segmentation maps. Given a 3D volume and its putative segmentation map, we propose an approach to identify and measure erroneous regions in the segmentation map. Our method can estimate error at any point or node in a 3D mesh generated from a possibly erroneous volumetric segmentation map, serving as a Quality Assurance tool. We propose a graph neural network-based transformer based on the Nodeformer architecture to measure and classify the segmentation errors at any point. We have evaluated our network on a high-resolution micro-CT dataset of the human inner-ear bony labyrinth structure by simulating erroneous 3D segmentation maps. Our network incorporates a convolutional encoder to compute node-centric features from the input micro-CT data, the Nodeformer to learn the latent graph embeddings, and a Multi-Layer Perceptron (MLP) to compute and classify the node-wise errors. Our network achieves a mean absolute error of ~0.042 over other Graph Neural Networks (GNN) and an accuracy of 79.53% over other GNNs in estimating and classifying the node-wise errors, respectively. We also put forth vertex-normal prediction as a custom pretext task for pre-training the CNN encoder to improve the network's overall performance. Qualitative analysis shows the efficiency of our network in correctly classifying errors and reducing misclassifications.
</details>
<details>
<summary>摘要</summary>
很多分割网络已经被提出用于3D分割肿瘤和潜在受影响的器官。医院和临床机构希望通过加速和减少专家图像分割的努力来加速图像分割过程。然而，在这些网络生成的分割地图中出现错误时，临床医生需要手动修改生成的分割地图。我们提出一种方法，可以在3D矩阵中找到和测量错误的区域。我们的方法可以在3D矩阵中计算错误的误差，并且可以作为图像质量控制工具。我们提出一种基于Transformer架构的图神经网络，可以在3D矩阵中测量和分类分割错误。我们的网络包括一个卷积Encoder来计算输入微CT数据中的节点特征，Nodeformer来学习幂等图像嵌入，以及一个多层感知器（MLP）来计算和分类节点错误。我们的网络在其他图神经网络（GNN）中的mean absolute error为~0.042，并且在分类节点错误的精度为79.53%。我们还提出了预训练CNNEncoder的预测顶点均值作为自定义预处理任务，以提高网络的整体性能。 качеitative分析表明，我们的网络能够正确地分类错误并减少错误分类。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/10/eess.IV_2023_08_10/" data-id="clogyj92s01347cra4ltz67gt" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/09/cs.SD_2023_08_09/" class="article-date">
  <time datetime="2023-08-09T15:00:00.000Z" itemprop="datePublished">2023-08-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/09/cs.SD_2023_08_09/">cs.SD - 2023-08-09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Unsupervised-Out-of-Distribution-Dialect-Detection-with-Mahalanobis-Distance"><a href="#Unsupervised-Out-of-Distribution-Dialect-Detection-with-Mahalanobis-Distance" class="headerlink" title="Unsupervised Out-of-Distribution Dialect Detection with Mahalanobis Distance"></a>Unsupervised Out-of-Distribution Dialect Detection with Mahalanobis Distance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04886">http://arxiv.org/abs/2308.04886</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sourya Dipta Das, Yash Vadi, Abhishek Unnam, Kuldeep Yadav</li>
<li>for: 本研究旨在提高 dialect classification 系统的总性性能，并在实际应用中处理 anomalous inputs。</li>
<li>methods: 我们提出了一种简单 yet effective的无监督 Mahalanobis 距离特征基于方法，用于检测 dialect classification 模型中的 out-of-distribution 样本。</li>
<li>results: 我们的方法在比较其他 state-of-the-art OOD detection 方法时表现出了显著的优势。<details>
<summary>Abstract</summary>
Dialect classification is used in a variety of applications, such as machine translation and speech recognition, to improve the overall performance of the system. In a real-world scenario, a deployed dialect classification model can encounter anomalous inputs that differ from the training data distribution, also called out-of-distribution (OOD) samples. Those OOD samples can lead to unexpected outputs, as dialects of those samples are unseen during model training. Out-of-distribution detection is a new research area that has received little attention in the context of dialect classification. Towards this, we proposed a simple yet effective unsupervised Mahalanobis distance feature-based method to detect out-of-distribution samples. We utilize the latent embeddings from all intermediate layers of a wav2vec 2.0 transformer-based dialect classifier model for multi-task learning. Our proposed approach outperforms other state-of-the-art OOD detection methods significantly.
</details>
<details>
<summary>摘要</summary>
dialect classification 在各种应用中使用，如机器翻译和语音识别，以提高整体系统性能。在实际场景中，部署的 диалект分类模型可能会遇到不同于训练数据分布的输入样本，也称为 OUT-OF-DISTRIBUTION（OOD）样本。这些 OOD 样本可能会导致不期望的输出，因为这些 диалект样本在模型训练时未看到。 OUT-OF-DISTRIBUTION 检测是一个新的研究领域，在 диаLECT 分类领域得到了少量的关注。为了解决这问题，我们提出了一种简单 yet 高效的无监督 Mahalanobis 距离特征基于方法来检测 OOD 样本。我们利用了一个 wav2vec 2.0 基于 transformer 的 диалект分类模型的所有 intermediate 层的矩阵表示。我们的提出方法在与其他现有的 OOD 检测方法比较中表现出色。
</details></li>
</ul>
<hr>
<h2 id="DiVa-An-Iterative-Framework-to-Harvest-More-Diverse-and-Valid-Labels-from-User-Comments-for-Music"><a href="#DiVa-An-Iterative-Framework-to-Harvest-More-Diverse-and-Valid-Labels-from-User-Comments-for-Music" class="headerlink" title="DiVa: An Iterative Framework to Harvest More Diverse and Valid Labels from User Comments for Music"></a>DiVa: An Iterative Framework to Harvest More Diverse and Valid Labels from User Comments for Music</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04805">http://arxiv.org/abs/2308.04805</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jingyaolliu/diva">https://github.com/jingyaolliu/diva</a></li>
<li>paper_authors: Hongru Liang, Jingyao Liu, Yuanxin Xiang, Jiachen Du, Lanjun Zhou, Shushen Pan, Wenqiang Lei</li>
<li>for:  automatic music labeling in an essential but under-explored setting</li>
<li>methods:  uses pre-trained classifiers and a novel joint score function to harvest more diverse and valid labels from user comments</li>
<li>results:  produces more diverse labels missed by the gold labels, superior to state-of-the-art solutions<details>
<summary>Abstract</summary>
Towards sufficient music searching, it is vital to form a complete set of labels for each song. However, current solutions fail to resolve it as they cannot produce diverse enough mappings to make up for the information missed by the gold labels. Based on the observation that such missing information may already be presented in user comments, we propose to study the automated music labeling in an essential but under-explored setting, where the model is required to harvest more diverse and valid labels from the users' comments given limited gold labels. To this end, we design an iterative framework (DiVa) to harvest more $\underline{\text{Di}$verse and $\underline{\text{Va}$lid labels from user comments for music. The framework makes a classifier able to form complete sets of labels for songs via pseudo-labels inferred from pre-trained classifiers and a novel joint score function. The experiment on a densely annotated testing set reveals the superiority of the Diva over state-of-the-art solutions in producing more diverse labels missed by the gold labels. We hope our work can inspire future research on automated music labeling.
</details>
<details>
<summary>摘要</summary>
向 suficient music searching， it is vital to form a complete set of labels for each song。However，current solutions fail to resolve it as they cannot produce diverse enough mappings to make up for the information missed by the gold labels。Based on the observation that such missing information may already be presented in user comments，we propose to study the automated music labeling in an essential but under-explored setting，where the model is required to harvest more diverse and valid labels from the users' comments given limited gold labels。To this end，we design an iterative framework (DiVa) to harvest more $\underline{\text{Di}$verse and $\underline{\text{Va}$lid labels from user comments for music。The framework makes a classifier able to form complete sets of labels for songs via pseudo-labels inferred from pre-trained classifiers and a novel joint score function。The experiment on a densely annotated testing set reveals the superiority of the Diva over state-of-the-art solutions in producing more diverse labels missed by the gold labels。We hope our work can inspire future research on automated music labeling。
</details></li>
</ul>
<hr>
<h2 id="Induction-Network-Audio-Visual-Modality-Gap-Bridging-for-Self-Supervised-Sound-Source-Localization"><a href="#Induction-Network-Audio-Visual-Modality-Gap-Bridging-for-Self-Supervised-Sound-Source-Localization" class="headerlink" title="Induction Network: Audio-Visual Modality Gap-Bridging for Self-Supervised Sound Source Localization"></a>Induction Network: Audio-Visual Modality Gap-Bridging for Self-Supervised Sound Source Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04767">http://arxiv.org/abs/2308.04767</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tahy1/avin">https://github.com/tahy1/avin</a></li>
<li>paper_authors: Tianyu Liu, Peng Zhang, Wei Huang, Yufei Zha, Tao You, Yanning Zhang</li>
<li>for: 本研究旨在解决自主学习音源定位中的modal inconsistency问题，通过对不同modalities的特征进行更好的协调，以提高音源定位的精度和稳定性。</li>
<li>methods: 本研究提出了一种叫做Induction Network的新网络模型，通过分离视觉和声音模式的梯度，使得可以更好地学习视觉特征的描述性模型，并且可以在不同的modalities之间进行更好的协调。此外，还提出了一种适应性的阈值选择策略，以提高模型的Robustness。</li>
<li>results: 在SoundNet-Flickr和VGG-Sound Source等数据集上进行了详细的实验，并证明了与其他state-of-the-art方法相比，本研究的方法在不同的挑战性enario下表现出了superior的性能。<details>
<summary>Abstract</summary>
Self-supervised sound source localization is usually challenged by the modality inconsistency. In recent studies, contrastive learning based strategies have shown promising to establish such a consistent correspondence between audio and sound sources in visual scenarios. Unfortunately, the insufficient attention to the heterogeneity influence in the different modality features still limits this scheme to be further improved, which also becomes the motivation of our work. In this study, an Induction Network is proposed to bridge the modality gap more effectively. By decoupling the gradients of visual and audio modalities, the discriminative visual representations of sound sources can be learned with the designed Induction Vector in a bootstrap manner, which also enables the audio modality to be aligned with the visual modality consistently. In addition to a visual weighted contrastive loss, an adaptive threshold selection strategy is introduced to enhance the robustness of the Induction Network. Substantial experiments conducted on SoundNet-Flickr and VGG-Sound Source datasets have demonstrated a superior performance compared to other state-of-the-art works in different challenging scenarios. The code is available at https://github.com/Tahy1/AVIN
</details>
<details>
<summary>摘要</summary>
自顾supervised音频源localization通常面临 modalities 不一致性挑战。 recent studies have shown that contrastive learning based strategies have promising to establish a consistent correspondence between audio and visual modalities in visual scenarios. However, the insufficient attention to the heterogeneity influence in different modality features still limits this scheme to be further improved, which also becomes the motivation of our work.In this study, an Induction Network is proposed to bridge the modality gap more effectively. By decoupling the gradients of visual and audio modalities, the discriminative visual representations of sound sources can be learned with the designed Induction Vector in a bootstrap manner, which also enables the audio modality to be aligned with the visual modality consistently. In addition, an adaptive threshold selection strategy is introduced to enhance the robustness of the Induction Network.Substantial experiments conducted on SoundNet-Flickr and VGG-Sound Source datasets have demonstrated a superior performance compared to other state-of-the-art works in different challenging scenarios. The code is available at https://github.com/Tahy1/AVIN.Here's the translation in Traditional Chinese:自顾supervised音频源localization通常面临 modalities 不一致性挑战。 recent studies have shown that contrastive learning based strategies have promising to establish a consistent correspondence between audio and visual modalities in visual scenarios. However, the insufficient attention to the heterogeneity influence in different modality features still limits this scheme to be further improved, which also becomes the motivation of our work.In this study, an Induction Network is proposed to bridge the modality gap more effectively. By decoupling the gradients of visual and audio modalities, the discriminative visual representations of sound sources can be learned with the designed Induction Vector in a bootstrap manner, which also enables the audio modality to be aligned with the visual modality consistently. In addition, an adaptive threshold selection strategy is introduced to enhance the robustness of the Induction Network.Substantial experiments conducted on SoundNet-Flickr and VGG-Sound Source datasets have demonstrated a superior performance compared to other state-of-the-art works in different challenging scenarios. The code is available at https://github.com/Tahy1/AVIN.
</details></li>
</ul>
<hr>
<h2 id="Speaker-Recognition-Using-Isomorphic-Graph-Attention-Network-Based-Pooling-on-Self-Supervised-Representation"><a href="#Speaker-Recognition-Using-Isomorphic-Graph-Attention-Network-Based-Pooling-on-Self-Supervised-Representation" class="headerlink" title="Speaker Recognition Using Isomorphic Graph Attention Network Based Pooling on Self-Supervised Representation"></a>Speaker Recognition Using Isomorphic Graph Attention Network Based Pooling on Self-Supervised Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04666">http://arxiv.org/abs/2308.04666</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zirui Ge, Xinzhou Xu, Haiyan Guo, Tingting Wang, Zhen Yang</li>
<li>for: 提高语音识别器的表现，使其能够更好地处理基于语音数据的基础模型。</li>
<li>methods: 使用Isomorphic Graph ATtention network (IsoGAT)来学习语音识别器，并将其与基于自我监督表示的方法结合使用。</li>
<li>results: 在VoxCeleb1&amp;2 dataset上进行了语音识别任务的实验，并比较了提议方法与现有的pooling方法的表现。<details>
<summary>Abstract</summary>
The emergence of self-supervised representation (i.e., wav2vec 2.0) allows speaker-recognition approaches to process spoken signals through foundation models built on speech data. Nevertheless, effective fusion on the representation requires further investigating, due to the inclusion of fixed or sub-optimal temporal pooling strategies. Despite of improved strategies considering graph learning and graph attention factors, non-injective aggregation still exists in the approaches, which may influence the performance for speaker recognition. In this regard, we propose a speaker recognition approach using Isomorphic Graph ATtention network (IsoGAT) on self-supervised representation. The proposed approach contains three modules of representation learning, graph attention, and aggregation, jointly considering learning on the self-supervised representation and the IsoGAT. Then, we perform experiments for speaker recognition tasks on VoxCeleb1\&2 datasets, with the corresponding experimental results demonstrating the recognition performance for the proposed approach, compared with existing pooling approaches on the self-supervised representation.
</details>
<details>
<summary>摘要</summary>
《自我超级 Representation（即 Wav2vec 2.0）的出现允许 speaker recognition 方法通过基于 speech 数据建立的基础模型进行处理 spoken signals。然而，为了实现有效的融合，需要进一步调查，因为包含 fixed 或不优化的 temporal pooling 策略。尽管考虑了基于图学习和图注意因素的改进策略，仍然存在非具有注意力的聚合，这可能影响 speaker recognition 的性能。在这种情况下，我们提出了基于 Isomorphic Graph ATtention network（IsoGAT）的 speaker recognition 方法。该方法包括 three 个模块：表示学习、图注意和聚合，同时考虑了学习 self-supervised representation 和 IsoGAT。然后，我们对 VoxCeleb1&2 数据集进行实验，并得到了对exist pooling approaches on self-supervised representation的比较。》Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. The traditional Chinese writing system is also widely used, especially in Taiwan and Hong Kong.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/09/cs.SD_2023_08_09/" data-id="clogyj90b00t77cra2goqh0qt" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/09/cs.CV_2023_08_09/" class="article-date">
  <time datetime="2023-08-09T13:00:00.000Z" itemprop="datePublished">2023-08-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/09/cs.CV_2023_08_09/">cs.CV - 2023-08-09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Density-Crop-guided-Semi-supervised-Object-Detection-in-Aerial-Images"><a href="#Density-Crop-guided-Semi-supervised-Object-Detection-in-Aerial-Images" class="headerlink" title="Density Crop-guided Semi-supervised Object Detection in Aerial Images"></a>Density Crop-guided Semi-supervised Object Detection in Aerial Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05032">http://arxiv.org/abs/2308.05032</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/akhilpm/dronessod">https://github.com/akhilpm/dronessod</a></li>
<li>paper_authors: Akhil Meethal, Eric Granger, Marco Pedersoli</li>
<li>for: 这篇论文主要应用于如何提高飞行器上的物体探测器训练效率，特别是面临小型物体分布在高分辨率图像上的情况。</li>
<li>methods: 本研究使用了pseudo-labels和弱强同步增强的方法，并将其应用于飞行器上的物体探测器训练。在训练过程中，使用了图像组的丰富度导航，将图像组分为不同的小区域，并将这些小区域用于训练。在测试过程中，使用了这些小区域来增强物体探测器的准确性。</li>
<li>results: 本研究的实验结果显示，使用了density crop-guided semi-supervised detector可以在COCO式AP中提高物体探测器的准确性超过2%。<details>
<summary>Abstract</summary>
One of the important bottlenecks in training modern object detectors is the need for labeled images where bounding box annotations have to be produced for each object present in the image. This bottleneck is further exacerbated in aerial images where the annotators have to label small objects often distributed in clusters on high-resolution images. In recent days, the mean-teacher approach trained with pseudo-labels and weak-strong augmentation consistency is gaining popularity for semi-supervised object detection. However, a direct adaptation of such semi-supervised detectors for aerial images where small clustered objects are often present, might not lead to optimal results. In this paper, we propose a density crop-guided semi-supervised detector that identifies the cluster of small objects during training and also exploits them to improve performance at inference. During training, image crops of clusters identified from labeled and unlabeled images are used to augment the training set, which in turn increases the chance of detecting small objects and creating good pseudo-labels for small objects on the unlabeled images. During inference, the detector is not only able to detect the objects of interest but also regions with a high density of small objects (density crops) so that detections from the input image and detections from image crops are combined, resulting in an overall more accurate object prediction, especially for small objects. Empirical studies on the popular benchmarks of VisDrone and DOTA datasets show the effectiveness of our density crop-guided semi-supervised detector with an average improvement of more than 2\% over the basic mean-teacher method in COCO style AP. Our code is available at: https://github.com/akhilpm/DroneSSOD.
</details>
<details>
<summary>摘要</summary>
一个重要的瓶颈在现代物体探测器的训练中是需要标注的图像，其中每个图像需要生成矩形框注释。这个瓶颈在飞行图像中更加严重，因为注释者需要为高分辨率图像中的小对象进行标注。在最近的日子里，使用pseudo-labels和弱强协同稳定的方法训练的semi-supervised物体探测器在获得优化的结果。然而，直接将这种semi-supervised探测器应用于飞行图像中可能并不会导致最佳的结果。在这篇论文中，我们提出了一种基于密度的剪辑引导的semi-supervised探测器，它在训练时使用标注和无标注图像中的群集来增强训练集，从而提高小对象的检测和生成良好的pseudo-labels。在探测时，探测器不仅可以检测输入图像中的对象，还可以检测密度较高的小对象区域（密度剪辑），从而将输入图像和剪辑图像的检测结果组合起来，实现更加准确的对象预测，特别是小对象。我们的实验结果表明，我们的密度剪辑引导的semi-supervised探测器在COCO风格的AP中超过2%的提升。我们的代码可以在GitHub上找到：https://github.com/akhilpm/DroneSSOD。
</details></li>
</ul>
<hr>
<h2 id="An-End-to-End-Framework-of-Road-User-Detection-Tracking-and-Prediction-from-Monocular-Images"><a href="#An-End-to-End-Framework-of-Road-User-Detection-Tracking-and-Prediction-from-Monocular-Images" class="headerlink" title="An End-to-End Framework of Road User Detection, Tracking, and Prediction from Monocular Images"></a>An End-to-End Framework of Road User Detection, Tracking, and Prediction from Monocular Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05026">http://arxiv.org/abs/2308.05026</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Cheng, Mengmeng liu, Lin Chen</li>
<li>for: 本研究旨在提出一个端到端检测、跟踪和预测框架，帮助自动驾驶车辆实现更高精度的路径预测。</li>
<li>methods: 本研究使用了state-of-the-art online多对象跟踪模型QD-3DT进行感知，并直接基于检测结果训练了路径预测器DCENet++。</li>
<li>results: 广泛的实验表明，ODTP在nuScenes数据集上表现出高级别的端到端路径预测能力，DCENet++通过加强动态地图来预测更为准确的路径，并与其他生成和决定性路径预测模型相比较为稳定。<details>
<summary>Abstract</summary>
Perception that involves multi-object detection and tracking, and trajectory prediction are two major tasks of autonomous driving. However, they are currently mostly studied separately, which results in most trajectory prediction modules being developed based on ground truth trajectories without taking into account that trajectories extracted from the detection and tracking modules in real-world scenarios are noisy. These noisy trajectories can have a significant impact on the performance of the trajectory predictor and can lead to serious prediction errors. In this paper, we build an end-to-end framework for detection, tracking, and trajectory prediction called ODTP (Online Detection, Tracking and Prediction). It adopts the state-of-the-art online multi-object tracking model, QD-3DT, for perception and trains the trajectory predictor, DCENet++, directly based on the detection results without purely relying on ground truth trajectories. We evaluate the performance of ODTP on the widely used nuScenes dataset for autonomous driving. Extensive experiments show that ODPT achieves high performance end-to-end trajectory prediction. DCENet++, with the enhanced dynamic maps, predicts more accurate trajectories than its base model. It is also more robust when compared with other generative and deterministic trajectory prediction models trained on noisy detection results.
</details>
<details>
<summary>摘要</summary>
感知 tasks 中的多对象探测和跟踪，以及预测 trajectory 是自动驾驶技术的两大任务。然而，这两个任务目前大多是分开研究，导致大多数预测 trajectory 模块是基于真实的 trajectory 进行开发，而不是基于实际enario 中的探测和跟踪结果。这些噪音的 trajectory 可能会对预测性能产生重要的影响，导致严重的预测错误。在这篇论文中，我们提出了一个综合框架，称为 ODTP（Online Detection, Tracking and Prediction），用于探测、跟踪和预测。ODTP 采用了当前最佳的在线多对象跟踪模型 QD-3DT，用于感知，并直接基于探测结果进行预测 trajectory 的训练，而不是完全依赖于真实的 trajectory。我们对 nuScenes 数据集进行了广泛的实验，并证明了 ODTP 在综合框架中的高性能端到端预测。DCENet++ 使用了增强的动态地图，预测更加准确的 trajectory，并与其基本模型相比，更加Robust。
</details></li>
</ul>
<hr>
<h2 id="Feature-Modulation-Transformer-Cross-Refinement-of-Global-Representation-via-High-Frequency-Prior-for-Image-Super-Resolution"><a href="#Feature-Modulation-Transformer-Cross-Refinement-of-Global-Representation-via-High-Frequency-Prior-for-Image-Super-Resolution" class="headerlink" title="Feature Modulation Transformer: Cross-Refinement of Global Representation via High-Frequency Prior for Image Super-Resolution"></a>Feature Modulation Transformer: Cross-Refinement of Global Representation via High-Frequency Prior for Image Super-Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05022">http://arxiv.org/abs/2308.05022</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/avc2-uestc/craft-sr">https://github.com/avc2-uestc/craft-sr</a></li>
<li>paper_authors: Ao Li, Le Zhang, Yun Liu, Ce Zhu</li>
<li>For: The paper is written for improving the performance of single image super-resolution (SISR) using transformer-based methods.* Methods: The paper proposes a new method called CRAFT, which integrates the strengths of both convolutional and transformer structures. CRAFT consists of three key components: the high-frequency enhancement residual block (HFERB), the shift rectangle window attention block (SRWAB), and the hybrid fusion block (HFB).* Results: The paper reports that CRAFT outperforms state-of-the-art methods by up to 0.29dB while using fewer parameters, as demonstrated through experiments on multiple datasets.<details>
<summary>Abstract</summary>
Transformer-based methods have exhibited remarkable potential in single image super-resolution (SISR) by effectively extracting long-range dependencies. However, most of the current research in this area has prioritized the design of transformer blocks to capture global information, while overlooking the importance of incorporating high-frequency priors, which we believe could be beneficial. In our study, we conducted a series of experiments and found that transformer structures are more adept at capturing low-frequency information, but have limited capacity in constructing high-frequency representations when compared to their convolutional counterparts. Our proposed solution, the cross-refinement adaptive feature modulation transformer (CRAFT), integrates the strengths of both convolutional and transformer structures. It comprises three key components: the high-frequency enhancement residual block (HFERB) for extracting high-frequency information, the shift rectangle window attention block (SRWAB) for capturing global information, and the hybrid fusion block (HFB) for refining the global representation. Our experiments on multiple datasets demonstrate that CRAFT outperforms state-of-the-art methods by up to 0.29dB while using fewer parameters. The source code will be made available at: https://github.com/AVC2-UESTC/CRAFT-SR.git.
</details>
<details>
<summary>摘要</summary>
“ transformer 基本方法在单图超解（SISR）中表现出了非常出色的潜力，但大多数当前的研究都是强调设计 transformer 块来捕捉全球信息，而忽略了包含高频约束的重要性，我们认为这可能是有利的。在我们的研究中，我们进行了一系列实验，发现 transformer 结构更适合捕捉低频信息，但在高频信息建模方面有限制，与 convolutional 结构相比。我们的提议方案，即 cross-refinement adaptive feature modulation transformer（CRAFT），结合了 convolutional 和 transformer 结构的优点。它包括三个关键组件：高频增强剩余块（HFERB）、移动矩形窗口注意块（SRWAB）和混合融合块（HFB）。我们在多个数据集上进行了实验，结果显示，CRAFT 可以与状态之前的方法相比，在0.29dB 的误差上提高到最高。我们将在 GitHub 上公开源代码：https://github.com/AVC2-UESTC/CRAFT-SR.git。”
</details></li>
</ul>
<hr>
<h2 id="Robust-Object-Modeling-for-Visual-Tracking"><a href="#Robust-Object-Modeling-for-Visual-Tracking" class="headerlink" title="Robust Object Modeling for Visual Tracking"></a>Robust Object Modeling for Visual Tracking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05140">http://arxiv.org/abs/2308.05140</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dawnyc/romtrack">https://github.com/dawnyc/romtrack</a></li>
<li>paper_authors: Yidong Cai, Jie Liu, Jie Tang, Gangshan Wu</li>
<li>for: 提高视觉跟踪的稳定性和性能，尤其是在对象的形态变化和不确定环境下。</li>
<li>methods: 提出了一种同时模型固有模板和协同模板特征的robust对象模型框架（ROMTrack），通过将固有模板特征和搜索区域指导相结合，Suppress干扰性的distractors，提取target对象相关的特征。同时，通过协同模板特征，提取更多的target对象特征，提高整体性能。</li>
<li>results: 实验表明，ROMTrack在多个benchmark上达到了新的状态态-of-the-art水平， indicating that the proposed framework is effective in improving the stability and performance of visual tracking.<details>
<summary>Abstract</summary>
Object modeling has become a core part of recent tracking frameworks. Current popular tackers use Transformer attention to extract the template feature separately or interactively with the search region. However, separate template learning lacks communication between the template and search regions, which brings difficulty in extracting discriminative target-oriented features. On the other hand, interactive template learning produces hybrid template features, which may introduce potential distractors to the template via the cluttered search regions. To enjoy the merits of both methods, we propose a robust object modeling framework for visual tracking (ROMTrack), which simultaneously models the inherent template and the hybrid template features. As a result, harmful distractors can be suppressed by combining the inherent features of target objects with search regions' guidance. Target-related features can also be extracted using the hybrid template, thus resulting in a more robust object modeling framework. To further enhance robustness, we present novel variation tokens to depict the ever-changing appearance of target objects. Variation tokens are adaptable to object deformation and appearance variations, which can boost overall performance with negligible computation. Experiments show that our ROMTrack sets a new state-of-the-art on multiple benchmarks.
</details>
<details>
<summary>摘要</summary>
现代跟踪框架中的对象模型已成为核心。目前流行的跟踪器使用 transformer 注意力来分离模板特征或在搜索区域中交互地学习模板。然而，分离模板学习缺乏模板和搜索区域之间的交流，这会增加提取特定目标 oriented 特征的困难。然而，交互模板学习生成的杂合模板特征可能会通过搜索区域中的噪声引入潜在的干扰器。为了享受到这两种方法的优点，我们提出了一种robust对象模型框架（ROMTrack），它同时模型了内在模板和杂合模板特征。因此，干扰器可以通过将内在特征与搜索区域的指导相结合来被抑制。同时，我们还可以使用杂合模板来提取目标相关的特征，从而得到更加robust的对象模型框架。为了进一步增强可靠性，我们还提出了一种新的变化 токен来描述目标对象的变化。这些变化 токен可以适应物体变形和变化，从而提高总性能。实验表明，我们的 ROMTrack 在多个标准准则上设置了新的状态之冠。
</details></li>
</ul>
<hr>
<h2 id="Do-Diffusion-Models-Suffer-Error-Propagation-Theoretical-Analysis-and-Consistency-Regularization"><a href="#Do-Diffusion-Models-Suffer-Error-Propagation-Theoretical-Analysis-and-Consistency-Regularization" class="headerlink" title="Do Diffusion Models Suffer Error Propagation? Theoretical Analysis and Consistency Regularization"></a>Do Diffusion Models Suffer Error Propagation? Theoretical Analysis and Consistency Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05021">http://arxiv.org/abs/2308.05021</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yangming Li, Zhaozhi Qian, Mihaela van der Schaar</li>
<li>for:  This paper aims to address the error propagation issue in diffusion models, which can cause the cascade structure to magnify distributional mismatches.</li>
<li>methods: The paper proposes a regularization scheme to address error propagation in diffusion models, which is based on a consistency constraint that ensures the forward and backward processes have similar distributions.</li>
<li>results: The paper shows through theoretical analysis and experimental results that the proposed regularization scheme can effectively reduce error propagation in diffusion models, leading to improved performance on multiple image datasets.<details>
<summary>Abstract</summary>
While diffusion models have achieved promising performances in data synthesis, they might suffer error propagation because of their cascade structure, where the distributional mismatch spreads and magnifies through the chain of denoising modules. However, a strict analysis is expected since many sequential models such as Conditional Random Field (CRF) are free from error propagation. In this paper, we empirically and theoretically verify that diffusion models are indeed affected by error propagation and we then propose a regularization to address this problem. Our theoretical analysis reveals that the question can be reduced to whether every denoising module of the diffusion model is fault-tolerant. We derive insightful transition equations, indicating that the module can't recover from input errors and even propagates additional errors to the next module. Our analysis directly leads to a consistency regularization scheme for diffusion models, which explicitly reduces the distribution gap between forward and backward processes. We further introduce a bootstrapping algorithm to reduce the computation cost of the regularizer. Our experimental results on multiple image datasets show that our regularization effectively handles error propagation and significantly improves the performance of vanilla diffusion models.
</details>
<details>
<summary>摘要</summary>
diffusion models 有 achieved promising performances in data synthesis, but they may suffer from error propagation due to their cascade structure, where the distributional mismatch spreads and magnifies through the chain of denoising modules. However, strict analysis is expected since many sequential models such as Conditional Random Field (CRF) are free from error propagation. In this paper, we empirically and theoretically verify that diffusion models are indeed affected by error propagation, and we then propose a regularization to address this problem.我们的理论分析表明， diffusion models 的问题可以简化为每个减腾模组是否有耐错能力。我们 derivate 出几个重要的转换方程，显示每个减腾模组无法从输入错误中恢复，甚至将错误传递到下一个模组。我们的分析直接导向一种一致调整方案，用于降低 diffusion models 中的分布差距。我们还提出了一个快速bootstrapping算法，以减少调整的计算成本。我们的实验结果显示，我们的调整方法可以有效地处理 error propagation，并提高了 vanilla diffusion models 的性能。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Model-Transfer-in-Forest-Mapping-using-Multi-source-Satellite-SAR-and-Optical-Images"><a href="#Deep-Learning-Model-Transfer-in-Forest-Mapping-using-Multi-source-Satellite-SAR-and-Optical-Images" class="headerlink" title="Deep Learning Model Transfer in Forest Mapping using Multi-source Satellite SAR and Optical Images"></a>Deep Learning Model Transfer in Forest Mapping using Multi-source Satellite SAR and Optical Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05005">http://arxiv.org/abs/2308.05005</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shaojia Ge, Oleg Antropov, Tuomas Häme, Ronald E. McRoberts, Jukka Miettinen</li>
<li>for: 这个论文的目的是使用深度学习模型预测森林变量，但是在实际的森林调查中，参考数据通常是plot或stand水平的测量数据，而高质量的代表性数据对深度学习模型的末端训练是罕见的。</li>
<li>methods: 这个研究使用了转移学习，将预训练的深度学习模型转移到目标区域，并使用了plot水平的测量数据进行训练。使用了earlier开发的UNet基于模型（SeUNet）来示例两个不同的落叶阔寒地区，并使用了多源的地球观测数据（ Copernicus Sentinel-1 C-band SAR、Sentinel-2多spectral图像、JAXA ALOS-2 PALSAR-2 SAR组合图像和TanDEM-X бистатиче干扰 ради谱数据）进行预测。</li>
<li>results: 通过转移学习，SeUNet的预测得到了根圆误差（RMSE）为2.70米和R$^2$为0.882，与传统标准方法相比较为准确。 authors expect这种森林特定的深度学习模型转移可以适用于其他森林变量和其他地球观测数据源。<details>
<summary>Abstract</summary>
Deep learning (DL) models are gaining popularity in forest variable prediction using Earth Observation images. However, in practical forest inventories, reference datasets are often represented by plot- or stand-level measurements, while high-quality representative wall-to-wall reference data for end-to-end training of DL models are rarely available. Transfer learning facilitates expansion of the use of deep learning models into areas with sub-optimal training data by allowing pretraining of the model in areas where high-quality teaching data are available. In this study, we perform a "model transfer" (or domain adaptation) of a pretrained DL model into a target area using plot-level measurements and compare performance versus other machine learning models. We use an earlier developed UNet based model (SeUNet) to demonstrate the approach on two distinct taiga sites with varying forest structure and composition. Multisource Earth Observation (EO) data are represented by a combination of Copernicus Sentinel-1 C-band SAR and Sentinel-2 multispectral images, JAXA ALOS-2 PALSAR-2 SAR mosaic and TanDEM-X bistatic interferometric radar data. The training study site is located in Finnish Lapland, while the target site is located in Southern Finland. By leveraging transfer learning, the prediction of SeUNet achieved root mean squared error (RMSE) of 2.70 m and R$^2$ of 0.882, considerably more accurate than traditional benchmark methods. We expect such forest-specific DL model transfer can be suitable also for other forest variables and other EO data sources that are sensitive to forest structure.
</details>
<details>
<summary>摘要</summary>
深度学习（DL）模型在森林变量预测中获得广泛应用，但在实际森林资源评估中，参考数据通常由干扰或树立面级别测量，而高质量代表墙壁到墙壁的参考数据对深度学习模型的端到端训练是罕见。转移学习可以扩展深度学习模型在有限制性训练数据的领域中的应用，通过将预训练模型转移到目标领域使用干扰量级测量。本研究使用了之前开发的UNet基于模型（SeUNet），在两个不同的落叶阔绿林区域中进行了对比研究。使用了欧盟资料遥感-1C频率Synthetic Aperture Radar（SAR）、欧盟资料遥感-2多spectral图像、JAXA ALOS-2 PALSAR-2 SAR覆盖图和TanDEM-X对干扰雷达数据。训练研究地点位于芬兰拉普兰地区，目标地点位于南芬兰。通过利用转移学习，SeUNet模型预测的root mean squared error（RMSE）为2.70米，R$^2$为0.882，远远高于传统标准方法。我们预期这种森林特有的深度学习模型转移可以适用于其他森林变量和其他遥感数据源，这些数据源对森林结构敏感。
</details></li>
</ul>
<hr>
<h2 id="Discrepancy-based-Active-Learning-for-Weakly-Supervised-Bleeding-Segmentation-in-Wireless-Capsule-Endoscopy-Images"><a href="#Discrepancy-based-Active-Learning-for-Weakly-Supervised-Bleeding-Segmentation-in-Wireless-Capsule-Endoscopy-Images" class="headerlink" title="Discrepancy-based Active Learning for Weakly Supervised Bleeding Segmentation in Wireless Capsule Endoscopy Images"></a>Discrepancy-based Active Learning for Weakly Supervised Bleeding Segmentation in Wireless Capsule Endoscopy Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05137">http://arxiv.org/abs/2308.05137</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fan Bai, Xiaohan Xing, Yutian Shen, Han Ma, Max Q. -H. Meng</li>
<li>for: 这篇论文的目的是提出一种新的缺失基本学习（DEAL）方法，以将涉猛投影（CAM）标签与医学图像的真实标签之间的差距填充，并且只需要少量的人工标注。</li>
<li>methods: 这篇论文使用了一种新的缺失基本学习（DEAL）方法，包括一个专门的错误分配模型和一个CAMPUS（CAM、假标签和真实标签选择）标准。这个方法通过将涉猛投影（CAM）标签与模型预测之间的差距用来取代噪音假标签。</li>
<li>results: 根据实验结果，这篇论文的方法比预设的活动学习方法更好，并且只需要10%的训练数据被标注。此外，这篇论文的方法与完全标注的数据集 trains中的性能相似。<details>
<summary>Abstract</summary>
Weakly supervised methods, such as class activation maps (CAM) based, have been applied to achieve bleeding segmentation with low annotation efforts in Wireless Capsule Endoscopy (WCE) images. However, the CAM labels tend to be extremely noisy, and there is an irreparable gap between CAM labels and ground truths for medical images. This paper proposes a new Discrepancy-basEd Active Learning (DEAL) approach to bridge the gap between CAMs and ground truths with a few annotations. Specifically, to liberate labor, we design a novel discrepancy decoder model and a CAMPUS (CAM, Pseudo-label and groUnd-truth Selection) criterion to replace the noisy CAMs with accurate model predictions and a few human labels. The discrepancy decoder model is trained with a unique scheme to generate standard, coarse and fine predictions. And the CAMPUS criterion is proposed to predict the gaps between CAMs and ground truths based on model divergence and CAM divergence. We evaluate our method on the WCE dataset and results show that our method outperforms the state-of-the-art active learning methods and reaches comparable performance to those trained with full annotated datasets with only 10% of the training data labeled.
</details>
<details>
<summary>摘要</summary>
weakly 监督的方法，如基于活化图 (CAM) 的方法，已经应用于具有低注释努力的内膜投射图像 (WCE) 中的分割。然而，CAM 标签往往具有噪声，并且在医疗图像中存在不可覆盖的差距 между CAM 标签和真实值。这篇论文提出了一种新的差异基于活动学习 (DEAL) 方法，以填补 CAM 标签和真实值之间的差距。特别是，为了减少劳动力，我们设计了一种新的差异解码器模型和 CAMPUS (CAM, Pseudo-label and groUnd-truth Selection)  criterion。差异解码器模型通过独特的训练方法生成标准、粗略和细化预测。而 CAMPUS criterion 基于模型分布和 CAM 分布来预测 CAM 与真实值之间的差距。我们在 WCE 数据集上评估了我们的方法，结果显示，我们的方法比 estado-of-the-art 活动学习方法高效，并且只使用 10% 的训练数据标注就达到了与全注释数据集相同的性能。
</details></li>
</ul>
<hr>
<h2 id="IDiff-Face-Synthetic-based-Face-Recognition-through-Fizzy-Identity-Conditioned-Diffusion-Models"><a href="#IDiff-Face-Synthetic-based-Face-Recognition-through-Fizzy-Identity-Conditioned-Diffusion-Models" class="headerlink" title="IDiff-Face: Synthetic-based Face Recognition through Fizzy Identity-Conditioned Diffusion Models"></a>IDiff-Face: Synthetic-based Face Recognition through Fizzy Identity-Conditioned Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04995">http://arxiv.org/abs/2308.04995</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fdbtrs/IDiff-Face">https://github.com/fdbtrs/IDiff-Face</a></li>
<li>paper_authors: Fadi Boutros, Jonas Henry Grebe, Arjan Kuijper, Naser Damer</li>
<li>for: This paper aims to address the issue of limited intra-class diversity and cross-class discrimination in synthetic face datasets, which hinders the performance of face recognition models trained on these datasets.</li>
<li>methods: The proposed approach, IDiff-Face, uses conditional latent diffusion models to generate synthetic identities with realistic identity variations for face recognition training.</li>
<li>results: The proposed approach achieved state-of-the-art performance on the LFW benchmark, with an accuracy of 98.00%, significantly outperforming recent synthetic-based face recognition solutions (95.40%) and bridging the gap to authentic-based face recognition (99.82%).<details>
<summary>Abstract</summary>
The availability of large-scale authentic face databases has been crucial to the significant advances made in face recognition research over the past decade. However, legal and ethical concerns led to the recent retraction of many of these databases by their creators, raising questions about the continuity of future face recognition research without one of its key resources. Synthetic datasets have emerged as a promising alternative to privacy-sensitive authentic data for face recognition development. However, recent synthetic datasets that are used to train face recognition models suffer either from limitations in intra-class diversity or cross-class (identity) discrimination, leading to less optimal accuracies, far away from the accuracies achieved by models trained on authentic data. This paper targets this issue by proposing IDiff-Face, a novel approach based on conditional latent diffusion models for synthetic identity generation with realistic identity variations for face recognition training. Through extensive evaluations, our proposed synthetic-based face recognition approach pushed the limits of state-of-the-art performances, achieving, for example, 98.00% accuracy on the Labeled Faces in the Wild (LFW) benchmark, far ahead from the recent synthetic-based face recognition solutions with 95.40% and bridging the gap to authentic-based face recognition with 99.82% accuracy.
</details>
<details>
<summary>摘要</summary>
大量真实面部数据的可用性对于过去一代面部识别研究的进步做出了重要贡献。然而，法律和伦理问题导致了许多这些数据的撤回，使得未来面部识别研究的继续发展受到了很大的威胁。 synthetic数据 emerged as a promising alternative to privacy-sensitive authentic data for face recognition development. However, recent synthetic datasets used to train face recognition models suffer from limitations in intra-class diversity or cross-class (identity) discrimination, leading to less optimal accuracies, far away from the accuracies achieved by models trained on authentic data. This paper targets this issue by proposing IDiff-Face, a novel approach based on conditional latent diffusion models for synthetic identity generation with realistic identity variations for face recognition training. Through extensive evaluations, our proposed synthetic-based face recognition approach pushed the limits of state-of-the-art performances, achieving, for example, 98.00% accuracy on the Labeled Faces in the Wild (LFW) benchmark, far ahead from the recent synthetic-based face recognition solutions with 95.40% and bridging the gap to authentic-based face recognition with 99.82% accuracy.
</details></li>
</ul>
<hr>
<h2 id="Foreground-Object-Search-by-Distilling-Composite-Image-Feature"><a href="#Foreground-Object-Search-by-Distilling-Composite-Image-Feature" class="headerlink" title="Foreground Object Search by Distilling Composite Image Feature"></a>Foreground Object Search by Distilling Composite Image Feature</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04990">http://arxiv.org/abs/2308.04990</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bcmi/foreground-object-search-dataset-fosd">https://github.com/bcmi/foreground-object-search-dataset-fosd</a></li>
<li>paper_authors: Bo Zhang, Jiacheng Sui, Li Niu</li>
<li>for: 本研究旨在提高前景物搜寻（FOS）的效果，通过塑造复合特征来提高匹配率。</li>
<li>methods: 本方法使用了一个师网络（teacher network）和一个学生网络（student network），其中师网络用于预测复合图像特征，而学生网络则使用了两个Encoder来提取前景特征和背景特征。它们之间的交互输出被要求与师网络预测的复合图像特征匹配。</li>
<li>results: 对于FOS任务，本方法比前一些方法更高效，并且提供了两个新的数据集（S-FOSD和R-FOSD），以便进一步探索FOS领域的可能性。<details>
<summary>Abstract</summary>
Foreground object search (FOS) aims to find compatible foreground objects for a given background image, producing realistic composite image. We observe that competitive retrieval performance could be achieved by using a discriminator to predict the compatibility of composite image, but this approach has unaffordable time cost. To this end, we propose a novel FOS method via distilling composite feature (DiscoFOS). Specifically, the abovementioned discriminator serves as teacher network. The student network employs two encoders to extract foreground feature and background feature. Their interaction output is enforced to match the composite image feature from the teacher network. Additionally, previous works did not release their datasets, so we contribute two datasets for FOS task: S-FOSD dataset with synthetic composite images and R-FOSD dataset with real composite images. Extensive experiments on our two datasets demonstrate the superiority of the proposed method over previous approaches. The dataset and code are available at https://github.com/bcmi/Foreground-Object-Search-Dataset-FOSD.
</details>
<details>
<summary>摘要</summary>
Background object search (FOS) aims to find compatible background objects for a given background image, producing realistic composite image. We observe that competitive retrieval performance could be achieved by using a discriminator to predict the compatibility of composite image, but this approach has unaffordable time cost. To this end, we propose a novel FOS method via distilling composite feature (DiscoFOS). Specifically, the abovementioned discriminator serves as teacher network. The student network employs two encoders to extract foreground feature and background feature. Their interaction output is enforced to match the composite image feature from the teacher network. Additionally, previous works did not release their datasets, so we contribute two datasets for FOS task: S-FOSD dataset with synthetic composite images and R-FOSD dataset with real composite images. Extensive experiments on our two datasets demonstrate the superiority of the proposed method over previous approaches. The dataset and code are available at https://github.com/bcmi/Foreground-Object-Search-Dataset-FOSD.Here's the word-for-word translation of the text into Simplified Chinese:背景物体搜索（FOS）目标是找到与背景图像兼容的背景物体，生成真实的复合图像。我们观察到，通过使用一个推理器预测复合图像的兼容性，可以达到竞争性的检索性能，但这种方法具有不可持续的时间成本。为此，我们提议一种新的FOS方法，通过预测复合特征进行启发（DiscoFOS）。具体来说，所述的推理器服务器作为教师网络。学生网络使用两个编码器提取背景特征和前景特征。它们之间的交互输出被要求与教师网络中的复合图像特征匹配。此外，先前的工作没有公开其数据集，我们为FOS任务贡献了两个数据集：S-FOSD数据集和R-FOSD数据集。我们对这两个数据集进行了广泛的实验，并证明了我们的方法在先前方法之上具有超越性。数据集和代码可以在https://github.com/bcmi/Foreground-Object-Search-Dataset-FOSD上获取。
</details></li>
</ul>
<hr>
<h2 id="Self-supervised-Landmark-Learning-with-Deformation-Reconstruction-and-Cross-subject-Consistency-Objectives"><a href="#Self-supervised-Landmark-Learning-with-Deformation-Reconstruction-and-Cross-subject-Consistency-Objectives" class="headerlink" title="Self-supervised Landmark Learning with Deformation Reconstruction and Cross-subject Consistency Objectives"></a>Self-supervised Landmark Learning with Deformation Reconstruction and Cross-subject Consistency Objectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04987">http://arxiv.org/abs/2308.04987</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chun-Hung Chao, Marc Niethammer</li>
<li>for: 本研究的目的是提出一种自动提取附注点的方法，以优化Statistical Shape Model (SSM)的建模。</li>
<li>methods: 我们提出了一种基于注册模型的自助学习方法，通过考虑注册模型中的特定点来提取附注点。</li>
<li>results: 我们的方法在一种退化股骨arthritis进程预测任务中表现出色，比 EXISTS image-based和点基的方法更高。<details>
<summary>Abstract</summary>
A Point Distribution Model (PDM) is the basis of a Statistical Shape Model (SSM) that relies on a set of landmark points to represent a shape and characterize the shape variation. In this work, we present a self-supervised approach to extract landmark points from a given registration model for the PDMs. Based on the assumption that the landmarks are the points that have the most influence on registration, existing works learn a point-based registration model with a small number of points to estimate the landmark points that influence the deformation the most. However, such approaches assume that the deformation can be captured by point-based registration and quality landmarks can be learned solely with the deformation capturing objective. We argue that data with complicated deformations can not easily be modeled with point-based registration when only a limited number of points is used to extract influential landmark points. Further, landmark consistency is not assured in existing approaches In contrast, we propose to extract landmarks based on a given registration model, which is tailored for the target data, so we can obtain more accurate correspondences. Secondly, to establish the anatomical consistency of the predicted landmarks, we introduce a landmark discovery loss to explicitly encourage the model to predict the landmarks that are anatomically consistent across subjects. We conduct experiments on an osteoarthritis progression prediction task and show our method outperforms existing image-based and point-based approaches.
</details>
<details>
<summary>摘要</summary>
“一个点分布模型（PDM）是基础的 Statistical Shape Model（SSM）的基础，它透过一组点来表示形状和描述形状的变化。在这个工作中，我们提出了一个自动化的方法，以EXTract点来自已知的注册模型中，以便为PDM中的点分布建立更加精确的描述。对于现有的方法，它们假设只需要使用一小数量的点来学习点基于注册模型，并假设这些点可以充分地捕捉变形的特征。但是，我们认为复杂的变形不易被点基于的注册模型所捕捉，尤其是只使用一小数量的点。此外，现有的方法不能保证点的一致性。相反，我们提出了一个基于注册模型的方法，可以更加精确地描述点的分布，并且引入一个关于点的探索损失，以便更好地保证点的一致性。我们对于关节炎进步预测任务进行了实验，结果显示我们的方法可以较前者的图像基于和点基于方法出perform。”
</details></li>
</ul>
<hr>
<h2 id="ACE-HetEM-for-ab-initio-Heterogenous-Cryo-EM-3D-Reconstruction"><a href="#ACE-HetEM-for-ab-initio-Heterogenous-Cryo-EM-3D-Reconstruction" class="headerlink" title="ACE-HetEM for ab initio Heterogenous Cryo-EM 3D Reconstruction"></a>ACE-HetEM for ab initio Heterogenous Cryo-EM 3D Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04956">http://arxiv.org/abs/2308.04956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weijie Chen, Lin Yao, Zeqing Xia, Yuhang Wang</li>
<li>for: 这篇论文的目的是解决潺爆电子镜像实验中的低信号噪声比和不确定的投影角和图像平移问题，以及将2D图像转化为3D结构。</li>
<li>methods: 这篇论文提出了一种基于整合推理的深度学习架构，称为ACE-HetEM，以解决这些问题。该方法通过设计了两个相互关联的训练任务：图像到图像任务和pose到pose任务，来显著强制分离姿态分类和投影估计。</li>
<li>results: 在模拟数据集上，ACE-HetEM的准确率和非整合方法相当，而且它还能生成更高的重建分辨率。此外，ACE-HetEM还可以应用于实验数据集。<details>
<summary>Abstract</summary>
Due to the extremely low signal-to-noise ratio (SNR) and unknown poses (projection angles and image translation) in cryo-EM experiments, reconstructing 3D structures from 2D images is very challenging. On top of these challenges, heterogeneous cryo-EM reconstruction also has an additional requirement: conformation classification. An emerging solution to this problem is called amortized inference, implemented using the autoencoder architecture or its variants. Instead of searching for the correct image-to-pose/conformation mapping for every image in the dataset as in non-amortized methods, amortized inference only needs to train an encoder that maps images to appropriate latent spaces representing poses or conformations. Unfortunately, standard amortized-inference-based methods with entangled latent spaces have difficulty learning the distribution of conformations and poses from cryo-EM images. In this paper, we propose an unsupervised deep learning architecture called "ACE-HetEM" based on amortized inference. To explicitly enforce the disentanglement of conformation classifications and pose estimations, we designed two alternating training tasks in our method: image-to-image task and pose-to-pose task. Results on simulated datasets show that ACE-HetEM has comparable accuracy in pose estimation and produces even better reconstruction resolution than non-amortized methods. Furthermore, we show that ACE-HetEM is also applicable to real experimental datasets.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:由于电子顺传显微实验中的信号噪声比（SNR）和不知的投影角和图像翻译是非常低的，从2D图像中重建3D结构非常困难。此外，病理学实验中的重建还有一个额外要求：确定投影类别和结构。一种趋势的解决方案是受束推断，通过自动编码器架构或其变体来实现。在非束推断方法中，需要为每个图像在数据集中找到正确的图像-投影/结构映射。而我们提出的方法ACE-HetEM使用受束推断，通过两个相互训练任务来强制分离投影类别和结构估计：图像-图像任务和投影-投影任务。实验结果表明，ACE-HetEM在pose估计方面具有相当的准确率，并且在重建分辨率方面还能更好些。此外，我们还证明了ACE-HetEM可以应用于实验数据集。
</details></li>
</ul>
<hr>
<h2 id="Branches-Mutual-Promotion-for-End-to-End-Weakly-Supervised-Semantic-Segmentation"><a href="#Branches-Mutual-Promotion-for-End-to-End-Weakly-Supervised-Semantic-Segmentation" class="headerlink" title="Branches Mutual Promotion for End-to-End Weakly Supervised Semantic Segmentation"></a>Branches Mutual Promotion for End-to-End Weakly Supervised Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04949">http://arxiv.org/abs/2308.04949</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Zhu, Hangzhou He, Xinliang Zhang, Qian Chen, Shuang Zeng, Qiushi Ren, Yanye Lu</li>
<li>for: 提高单stage训练过程中的权重分割模型性能，无需强制关注分类分支。</li>
<li>methods: 将两个分支视为不同的分 segmentation map生成方法，并在两个分支之间建立互动 Mechanism，以便彼此补做。</li>
<li>results: 实验表明，我们的方法在无监督下进行权重分割，比现有的方法高效。<details>
<summary>Abstract</summary>
End-to-end weakly supervised semantic segmentation aims at optimizing a segmentation model in a single-stage training process based on only image annotations. Existing methods adopt an online-trained classification branch to provide pseudo annotations for supervising the segmentation branch. However, this strategy makes the classification branch dominate the whole concurrent training process, hindering these two branches from assisting each other. In our work, we treat these two branches equally by viewing them as diverse ways to generate the segmentation map, and add interactions on both their supervision and operation to achieve mutual promotion. For this purpose, a bidirectional supervision mechanism is elaborated to force the consistency between the outputs of these two branches. Thus, the segmentation branch can also give feedback to the classification branch to enhance the quality of localization seeds. Moreover, our method also designs interaction operations between these two branches to exchange their knowledge to assist each other. Experiments indicate our work outperforms existing end-to-end weakly supervised segmentation methods.
</details>
<details>
<summary>摘要</summary>
End-to-end weakly supervised semantic segmentation aims to optimize a segmentation model in a single-stage training process based on only image annotations. Existing methods use an online-trained classification branch to provide pseudo annotations for supervising the segmentation branch, but this strategy hinders the two branches from assisting each other. In our work, we treat these two branches equally and add interactions on both their supervision and operation to achieve mutual promotion. For this purpose, we elaborate a bidirectional supervision mechanism to enforce consistency between the outputs of the two branches. This allows the segmentation branch to provide feedback to the classification branch to enhance the quality of localization seeds. Moreover, our method also designs interaction operations between the two branches to exchange their knowledge and assist each other. Experimental results show that our work outperforms existing end-to-end weakly supervised segmentation methods.
</details></li>
</ul>
<hr>
<h2 id="SelectNAdapt-Support-Set-Selection-for-Few-Shot-Domain-Adaptation"><a href="#SelectNAdapt-Support-Set-Selection-for-Few-Shot-Domain-Adaptation" class="headerlink" title="SelectNAdapt: Support Set Selection for Few-Shot Domain Adaptation"></a>SelectNAdapt: Support Set Selection for Few-Shot Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04946">http://arxiv.org/abs/2308.04946</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yussef93/selectnadapticcvw">https://github.com/yussef93/selectnadapticcvw</a></li>
<li>paper_authors: Youssef Dawoud, Gustavo Carneiro, Vasileios Belagiannis</li>
<li>for: 这篇论文是为了解决深度神经网络在分布shift时的敏感性问题，特别是将源预训网络适应到目标预训网络中的问题。</li>
<li>methods: 这篇论文提出了一种基于选择支持集的几架shot预训网络适应方法，包括使用自我超vised学习特色特征，然后使用每个类别的聚集方案选择K个表达类别的目标预训网络样本。</li>
<li>results: 这篇论文的实验结果显示，相比于相关方法和标准随机选择方法，SelectNAdapt方法可以更好地适应深度神经网络到目标预训网络中，实现更高的预测性。<details>
<summary>Abstract</summary>
Generalisation of deep neural networks becomes vulnerable when distribution shifts are encountered between train (source) and test (target) domain data. Few-shot domain adaptation mitigates this issue by adapting deep neural networks pre-trained on the source domain to the target domain using a randomly selected and annotated support set from the target domain. This paper argues that randomly selecting the support set can be further improved for effectively adapting the pre-trained source models to the target domain. Alternatively, we propose SelectNAdapt, an algorithm to curate the selection of the target domain samples, which are then annotated and included in the support set. In particular, for the K-shot adaptation problem, we first leverage self-supervision to learn features of the target domain data. Then, we propose a per-class clustering scheme of the learned target domain features and select K representative target samples using a distance-based scoring function. Finally, we bring our selection setup towards a practical ground by relying on pseudo-labels for clustering semantically similar target domain samples. Our experiments show promising results on three few-shot domain adaptation benchmarks for image recognition compared to related approaches and the standard random selection.
</details>
<details>
<summary>摘要</summary>
通用化的深度神经网络在面临源频率和目标频率数据分布shift时变得易受攻击。几拍频率适应缓解这个问题，通过随机选择和标注目标频率领域的支持集来适应源频率上预训练的深度神经网络。这篇论文提出，随机选择支持集可以进一步改进为有效地适应源模型到目标频率领域。作为一种改进方案，我们提出了SelectNAdapt算法，它可以细化目标频率领域样本的选择。具体来说，在K-shot适应问题中，我们首先利用自我超级vision来学习目标频率数据的特征。然后，我们提议一种类别划分方案，将学习的目标频率特征分为K个类别。接着，我们使用一个基于距离评分函数的距离分配K个表示目标频率样本。最后，我们将选择setup带到实际应用中，通过 pseudo-labels来划分semantic相似的目标频率样本。我们的实验结果显示，Compared to related approaches and the standard random selection, our method achieves promising results on three few-shot domain adaptation benchmarks for image recognition.
</details></li>
</ul>
<hr>
<h2 id="JEDI-Joint-Expert-Distillation-in-a-Semi-Supervised-Multi-Dataset-Student-Teacher-Scenario-for-Video-Action-Recognition"><a href="#JEDI-Joint-Expert-Distillation-in-a-Semi-Supervised-Multi-Dataset-Student-Teacher-Scenario-for-Video-Action-Recognition" class="headerlink" title="JEDI: Joint Expert Distillation in a Semi-Supervised Multi-Dataset Student-Teacher Scenario for Video Action Recognition"></a>JEDI: Joint Expert Distillation in a Semi-Supervised Multi-Dataset Student-Teacher Scenario for Video Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04934">http://arxiv.org/abs/2308.04934</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lucian Bicsi, Bogdan Alexe, Radu Tudor Ionescu, Marius Leordeanu</li>
<li>For: 本研究提出了一种多dataset semi-supervised learning方法，即JEDI，以提高个体模型在不同数据集上的性能。* Methods: 该方法使用学习多个专家的知识，每个专家在不同数据集上进行预训练，然后将专家的特征表示 concatenate 成教师模型。 student-teacher semi-supervised learning 方法在joint 和 end-to-end 训练中进行学习，以提高学习效率和泛化能力。* Results: 在四个视频动作识别数据集上验证了该方法，结果表明，同时考虑所有数据集在一个统一的 semi-supervised  Setting 中，可以获得显著的提升，与初始专家相比。<details>
<summary>Abstract</summary>
We propose JEDI, a multi-dataset semi-supervised learning method, which efficiently combines knowledge from multiple experts, learned on different datasets, to train and improve the performance of individual, per dataset, student models. Our approach achieves this by addressing two important problems in current machine learning research: generalization across datasets and limitations of supervised training due to scarcity of labeled data. We start with an arbitrary number of experts, pretrained on their own specific dataset, which form the initial set of student models. The teachers are immediately derived by concatenating the feature representations from the penultimate layers of the students. We then train all models in a student-teacher semi-supervised learning scenario until convergence. In our efficient approach, student-teacher training is carried out jointly and end-to-end, showing that both students and teachers improve their generalization capacity during training. We validate our approach on four video action recognition datasets. By simultaneously considering all datasets within a unified semi-supervised setting, we demonstrate significant improvements over the initial experts.
</details>
<details>
<summary>摘要</summary>
我们提出了JEDI方法，这是一种多集数 semi-supervised learning方法，可以有效地结合多个专家所学习的知识，以提高每个特定集数据的学生模型的性能。我们的方法解决了当前机器学习研究中两个重要问题：跨集数泛化和监督学习因数据缺乏标注数据而受限。我们从初始的任意数量专家开始，每个专家都是在自己特定的集数据上预训练的。我们的教师是通过将学生模型的准备层的特征表示 concatenate 而得到的。然后，我们在学生-教师半监督学习场景下同时训练所有模型，直到收敛。在我们的有效的方法中，学生-教师训练是结合的和端到端的，表明在训练过程中，学生和教师都会提高其泛化能力。我们在四个视频动作识别dataset上验证了我们的方法，并显示了与初始专家相比有显著的改进。通过同时考虑所有集数据，我们的方法实现了跨集数据的泛化。
</details></li>
</ul>
<hr>
<h2 id="GeodesicPSIM-Predicting-the-Quality-of-Static-Mesh-with-Texture-Map-via-Geodesic-Patch-Similarity"><a href="#GeodesicPSIM-Predicting-the-Quality-of-Static-Mesh-with-Texture-Map-via-Geodesic-Patch-Similarity" class="headerlink" title="GeodesicPSIM: Predicting the Quality of Static Mesh with Texture Map via Geodesic Patch Similarity"></a>GeodesicPSIM: Predicting the Quality of Static Mesh with Texture Map via Geodesic Patch Similarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04928">http://arxiv.org/abs/2308.04928</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Qi-Yangsjtu/GeodesicPSIM">https://github.com/Qi-Yangsjtu/GeodesicPSIM</a></li>
<li>paper_authors: Qi Yang, Joel Jung, Xiaozhong Xu, Shan Liu<br>for: GeodesicPSIM is proposed to accurately predict human perception quality for static meshes with texture maps.methods: The paper uses a two-step patch cropping algorithm and a patch texture mapping module to refine the size of 1-hop geodesic patches and build the relationship between mesh geometry and color information. Three types of features are extracted to quantify the distortion.results: GeodesicPSIM provides state-of-the-art performance in comparison with image-based, point-based, and video-based metrics on a newly created and challenging database. The paper also proves the robustness of GeodesicPSIM by introducing different settings of hyperparameters and exhibits the effectiveness of the three proposed features and the patch cropping algorithm through ablation studies.<details>
<summary>Abstract</summary>
Static meshes with texture maps have attracted considerable attention in both industrial manufacturing and academic research, leading to an urgent requirement for effective and robust objective quality evaluation. However, current model-based static mesh quality metrics have obvious limitations: most of them only consider geometry information, while color information is ignored, and they have strict constraints for the meshes' geometrical topology. Other metrics, such as image-based and point-based metrics, are easily influenced by the prepossessing algorithms, e.g., projection and sampling, hampering their ability to perform at their best. In this paper, we propose Geodesic Patch Similarity (GeodesicPSIM), a novel model-based metric to accurately predict human perception quality for static meshes. After selecting a group keypoints, 1-hop geodesic patches are constructed based on both the reference and distorted meshes cleaned by an effective mesh cleaning algorithm. A two-step patch cropping algorithm and a patch texture mapping module refine the size of 1-hop geodesic patches and build the relationship between the mesh geometry and color information, resulting in the generation of 1-hop textured geodesic patches. Three types of features are extracted to quantify the distortion: patch color smoothness, patch discrete mean curvature, and patch pixel color average and variance. To the best of our knowledge, GeodesicPSIM is the first model-based metric especially designed for static meshes with texture maps. GeodesicPSIM provides state-of-the-art performance in comparison with image-based, point-based, and video-based metrics on a newly created and challenging database. We also prove the robustness of GeodesicPSIM by introducing different settings of hyperparameters. Ablation studies also exhibit the effectiveness of three proposed features and the patch cropping algorithm.
</details>
<details>
<summary>摘要</summary>
static mesh 的 texture map 在工业生产和学术研究中吸引了广泛的关注，导致对 static mesh 的效果评估 urgent requirement 的出现。然而，当前的模型基于的 static mesh 质量指标有显著的局限性：大多数它们只考虑 geometry 信息，而忽略 color 信息，并且具有严格的 mesh 的 geometrical topology 约束。其他指标，如图像基于和点基于的指标，容易受到预处理算法的影响，如投影和采样，这会限制它们的表现。在本文中，我们提出了 Geodesic Patch Similarity (GeodesicPSIM)，一种新的模型基于指标，可以准确预测 static mesh 的人类感知质量。选择一组关键点后，使用 cleaned 的 referential 和扭曲的 mesh 构建一个一阶 geodesic patch。一个两步 cropping 算法和一个 patch texture mapping 模块来质量提高一阶 geodesic patch，并将 mesh 的 geometry 和 color 信息建立关系。通过提取三种特征（patch color smoothness、patch discrete mean curvature 和 patch pixel color average和variance），我们可以量化扭曲的程度。在我们知道的情况下，GeodesicPSIM 是第一种特别设计用于 static mesh 的 texture map 的模型基于指标。在一个新创建的和挑战性较高的数据库中，GeodesicPSIM 与图像基于、点基于和视频基于指标进行比较，得到了最新的状态。我们还证明了 GeodesicPSIM 的稳定性，通过不同的设置 hyperparameters 进行证明。另外，我们还进行了ablation study，以证明三种提出的特征和 patch cropping 算法的效果。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Based-Prediction-of-Fractional-Flow-Reserve-along-the-Coronary-Artery"><a href="#Deep-Learning-Based-Prediction-of-Fractional-Flow-Reserve-along-the-Coronary-Artery" class="headerlink" title="Deep Learning-Based Prediction of Fractional Flow Reserve along the Coronary Artery"></a>Deep Learning-Based Prediction of Fractional Flow Reserve along the Coronary Artery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04923">http://arxiv.org/abs/2308.04923</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nils Hampe, Sanne G. M. van Velzen, Jean-Paul Aben, Carlos Collet, Ivana Išgum</li>
<li>for:  This paper aims to develop a deep learning-based method to predict the fractional flow reserve (FFR) along the coronary artery from coronary CT angiography (CCTA) scans, which can help doctors identify functionally significant coronary artery disease (CAD) and determine the best treatment strategy.</li>
<li>methods:  The proposed method uses a combination of a variational autoencoder (VAE) and a convolutional neural network (CNN) to predict the FFR along the artery. The VAE is used to characterize the artery and generate an unsupervised artery encoding, while the CNN uses this encoding and other inputs to predict the FFR. The CNN is supervised by multiple loss functions, including a loss function inspired by the Earth Mover’s Distance (EMD) to predict the correct location of FFR drops and a histogram-based loss to explicitly supervise the slope of the FFR curve.</li>
<li>results:  The proposed method was evaluated using eight-fold cross-validation on a dataset of 110 patients who underwent invasive FFR pullback measurement in 112 arteries. The resulting FFR curves showed good agreement with the reference, allowing the distinction between diffuse and focal CAD distributions in most cases. Quantitative evaluation yielded a mean absolute difference in the area under the FFR pullback curve (AUPC) of 1.7. The method has the potential to provide fast, accurate, and automatic prediction of FFR along the artery from CCTA, which may help doctors make more informed decisions about treatment strategies for CAD patients.<details>
<summary>Abstract</summary>
Functionally significant coronary artery disease (CAD) is caused by plaque buildup in the coronary arteries, potentially leading to narrowing of the arterial lumen, i.e. coronary stenosis, that significantly obstructs blood flow to the myocardium. The current reference for establishing the presence of a functionally significant stenosis is invasive fractional flow reserve (FFR) measurement. To avoid invasive measurements, non-invasive prediction of FFR from coronary CT angiography (CCTA) has emerged. For this, machine learning approaches, characterized by fast inference, are increasingly developed. However, these methods predict a single FFR value per artery i.e. they don't provide information about the stenosis location or treatment strategy. We propose a deep learning-based method to predict the FFR along the artery from CCTA scans. This study includes CCTA images of 110 patients who underwent invasive FFR pullback measurement in 112 arteries. First, a multi planar reconstruction (MPR) of the artery is fed to a variational autoencoder to characterize the artery, i.e. through the lumen area and unsupervised artery encodings. Thereafter, a convolutional neural network (CNN) predicts the FFR along the artery. The CNN is supervised by multiple loss functions, notably a loss function inspired by the Earth Mover's Distance (EMD) to predict the correct location of FFR drops and a histogram-based loss to explicitly supervise the slope of the FFR curve. To train and evaluate our model, eight-fold cross-validation was performed. The resulting FFR curves show good agreement with the reference allowing the distinction between diffuse and focal CAD distributions in most cases. Quantitative evaluation yielded a mean absolute difference in the area under the FFR pullback curve (AUPC) of 1.7. The method may pave the way towards fast, accurate, automatic prediction of FFR along the artery from CCTA.
</details>
<details>
<summary>摘要</summary>
Functionally significant coronary artery disease (CAD) is caused by plaque buildup in the coronary arteries, potentially leading to narrowing of the arterial lumen, i.e. coronary stenosis, that significantly obstructs blood flow to the myocardium. The current reference for establishing the presence of a functionally significant stenosis is invasive fractional flow reserve (FFR) measurement. To avoid invasive measurements, non-invasive prediction of FFR from coronary CT angiography (CCTA) has emerged. For this, machine learning approaches, characterized by fast inference, are increasingly developed. However, these methods predict a single FFR value per artery, i.e. they don't provide information about the stenosis location or treatment strategy. We propose a deep learning-based method to predict the FFR along the artery from CCTA scans.This study includes CCTA images of 110 patients who underwent invasive FFR pullback measurement in 112 arteries. First, a multi planar reconstruction (MPR) of the artery is fed to a variational autoencoder to characterize the artery, i.e. through the lumen area and unsupervised artery encodings. Thereafter, a convolutional neural network (CNN) predicts the FFR along the artery. The CNN is supervised by multiple loss functions, notably a loss function inspired by the Earth Mover's Distance (EMD) to predict the correct location of FFR drops and a histogram-based loss to explicitly supervise the slope of the FFR curve. To train and evaluate our model, eight-fold cross-validation was performed. The resulting FFR curves show good agreement with the reference, allowing the distinction between diffuse and focal CAD distributions in most cases. Quantitative evaluation yielded a mean absolute difference in the area under the FFR pullback curve (AUPC) of 1.7. The method may pave the way towards fast, accurate, automatic prediction of FFR along the artery from CCTA.
</details></li>
</ul>
<hr>
<h2 id="Cross-view-Semantic-Alignment-for-Livestreaming-Product-Recognition"><a href="#Cross-view-Semantic-Alignment-for-Livestreaming-Product-Recognition" class="headerlink" title="Cross-view Semantic Alignment for Livestreaming Product Recognition"></a>Cross-view Semantic Alignment for Livestreaming Product Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04912">http://arxiv.org/abs/2308.04912</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/adxcreative/rice">https://github.com/adxcreative/rice</a></li>
<li>paper_authors: Wenjie Yang, Yiyi Chen, Yan Li, Yanhua Cheng, Xudong Liu, Quan Chen, Han Li</li>
<li>for: 这篇论文旨在提出一个大规模多modal的产品识别数据集（LPR4M），并提出一种基于多视图实例匹配的方法（RICE）来学习产品特征。</li>
<li>methods: 该方法使用了多视图实例匹配学习（MIL）和卷积神经网络，通过实例级别的对比学习和跨视图patch特征传递来学习产品特征。此外，该方法还提出了一种patch特征重建损失来惩罚跨视图patch的semantic不一致。</li>
<li>results: 对于LPR4M数据集，该方法 achieved state-of-the-art performance，并且提供了对多modal数据集的评估和分析，以及对不同视图和数据集的影响的研究。<details>
<summary>Abstract</summary>
Live commerce is the act of selling products online through live streaming. The customer's diverse demands for online products introduce more challenges to Livestreaming Product Recognition. Previous works have primarily focused on fashion clothing data or utilize single-modal input, which does not reflect the real-world scenario where multimodal data from various categories are present. In this paper, we present LPR4M, a large-scale multimodal dataset that covers 34 categories, comprises 3 modalities (image, video, and text), and is 50x larger than the largest publicly available dataset. LPR4M contains diverse videos and noise modality pairs while exhibiting a long-tailed distribution, resembling real-world problems. Moreover, a cRoss-vIew semantiC alignmEnt (RICE) model is proposed to learn discriminative instance features from the image and video views of the products. This is achieved through instance-level contrastive learning and cross-view patch-level feature propagation. A novel Patch Feature Reconstruction loss is proposed to penalize the semantic misalignment between cross-view patches. Extensive experiments demonstrate the effectiveness of RICE and provide insights into the importance of dataset diversity and expressivity. The dataset and code are available at https://github.com/adxcreative/RICE
</details>
<details>
<summary>摘要</summary>
live commerce 是在线销售产品的现象，客户的多样化需求对于在线产品的涵义提出了更多的挑战。现有的研究主要集中在时尚服装数据上，或者使用单模态输入，这并不反映实际情况中的多模态数据从多个类别存在。本文提出了LPR4M，一个大规模多模态数据集，覆盖34个类别，包括图像、视频和文本三种模式，比最大公开数据集50倍大。LPR4M包含多样化的视频和噪音模式对，同时具有长尾分布，类似于实际问题。此外，一种cross-view semantiC alignmEnt（RICE）模型被提出，用于从图像和视频视图中学习抽象实例特征。这是通过实例级别对比学习和跨视图块特征传递来实现的。一种新的patch feature reconstruction loss函数被提出，以惩恶分布在跨视图块上的semantic misalignment。广泛的实验表明RICE的有效性，并提供了数据多样性和表达力的意义。数据和代码可以在https://github.com/adxcreative/RICE上下载。
</details></li>
</ul>
<hr>
<h2 id="StableVQA-A-Deep-No-Reference-Quality-Assessment-Model-for-Video-Stability"><a href="#StableVQA-A-Deep-No-Reference-Quality-Assessment-Model-for-Video-Stability" class="headerlink" title="StableVQA: A Deep No-Reference Quality Assessment Model for Video Stability"></a>StableVQA: A Deep No-Reference Quality Assessment Model for Video Stability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04904">http://arxiv.org/abs/2308.04904</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qmme/stablevqa">https://github.com/qmme/stablevqa</a></li>
<li>paper_authors: Tengchuan Kou, Xiaohong Liu, Wei Sun, Jun Jia, Xiongkuo Min, Guangtao Zhai, Ning Liu</li>
<li>for: 这个论文主要是为了提出一种新的视频稳定评估方法，以及一个大规模的视频稳定数据集，以解决现有的视频质量评估模型无法准确地评估视频稳定性的问题。</li>
<li>methods: 这个论文使用了一种新的视频稳定评估模型，即StableVQA，该模型包括三种特征提取器，即光流、语义和模糊特征提取器，以及一个回归层来预测最终的稳定分数。</li>
<li>results: 实验结果显示，StableVQA模型与主观意见更高度相关，比现有的VQA-S模型和通用VQA模型更高效。<details>
<summary>Abstract</summary>
Video shakiness is an unpleasant distortion of User Generated Content (UGC) videos, which is usually caused by the unstable hold of cameras. In recent years, many video stabilization algorithms have been proposed, yet no specific and accurate metric enables comprehensively evaluating the stability of videos. Indeed, most existing quality assessment models evaluate video quality as a whole without specifically taking the subjective experience of video stability into consideration. Therefore, these models cannot measure the video stability explicitly and precisely when severe shakes are present. In addition, there is no large-scale video database in public that includes various degrees of shaky videos with the corresponding subjective scores available, which hinders the development of Video Quality Assessment for Stability (VQA-S). To this end, we build a new database named StableDB that contains 1,952 diversely-shaky UGC videos, where each video has a Mean Opinion Score (MOS) on the degree of video stability rated by 34 subjects. Moreover, we elaborately design a novel VQA-S model named StableVQA, which consists of three feature extractors to acquire the optical flow, semantic, and blur features respectively, and a regression layer to predict the final stability score. Extensive experiments demonstrate that the StableVQA achieves a higher correlation with subjective opinions than the existing VQA-S models and generic VQA models. The database and codes are available at https://github.com/QMME/StableVQA.
</details>
<details>
<summary>摘要</summary>
文本稳定性是 User Generated Content (UGC) 视频的不愉快变形，通常是由于摄像头不稳定所致。在过去几年，许多视频稳定算法被提出，但没有特定和准确的度量可以全面评估视频稳定性。实际上，大多数现有的质量评估模型将视频质量评估为整体，不特别考虑视频稳定性的主观体验。因此，这些模型无法明确和精确地测量视频稳定性， especial when severe shakes are present。此外，没有一个大规模的公共视频数据库，包含不同程度的抖动视频和相应的主观分数，这阻碍了视频质量评估的发展。为此，我们建立了一个新的数据库名为 StableDB，其包含 1,952 个多样化的 UGC 视频，每个视频具有主观分数（MOS），用于评估视频稳定性。此外，我们还设计了一种新的 VQA-S 模型，名为 StableVQA，它包含三种特征提取器，用于获取光流、 semantics 和抖动特征，以及一个回归层，用于预测最终的稳定性分数。经过广泛的实验，我们发现 StableVQA 与主观意见更高度相关，并且在与既有 VQA-S 模型和通用 VQA 模型进行比较时，也表现出更好的性能。数据库和代码可以在 GitHub 上获取：https://github.com/QMME/StableVQA。
</details></li>
</ul>
<hr>
<h2 id="Histogram-guided-Video-Colorization-Structure-with-Spatial-Temporal-Connection"><a href="#Histogram-guided-Video-Colorization-Structure-with-Spatial-Temporal-Connection" class="headerlink" title="Histogram-guided Video Colorization Structure with Spatial-Temporal Connection"></a>Histogram-guided Video Colorization Structure with Spatial-Temporal Connection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04899">http://arxiv.org/abs/2308.04899</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zheyuan Liu, Pan Mu, Hanning Xu, Cong Bai</li>
<li>for: Video colorization, aiming at obtaining colorful and plausible results from grayish frames.</li>
<li>methods: 使用 Histogram-guided Video Colorization with Spatial-Temporal connection structure (named ST-HVC), 结合 histogram 和流动特征，以及一种组合方案来处理模糊和噪声。</li>
<li>results: 与多种现有图像和视频基于方法进行比较，表现出优秀的数值和质量性表现在两个视频数据集中。<details>
<summary>Abstract</summary>
Video colorization, aiming at obtaining colorful and plausible results from grayish frames, has aroused a lot of interest recently. Nevertheless, how to maintain temporal consistency while keeping the quality of colorized results remains challenging. To tackle the above problems, we present a Histogram-guided Video Colorization with Spatial-Temporal connection structure (named ST-HVC). To fully exploit the chroma and motion information, the joint flow and histogram module is tailored to integrate the histogram and flow features. To manage the blurred and artifact, we design a combination scheme attending to temporal detail and flow feature combination. We further recombine the histogram, flow and sharpness features via a U-shape network. Extensive comparisons are conducted with several state-of-the-art image and video-based methods, demonstrating that the developed method achieves excellent performance both quantitatively and qualitatively in two video datasets.
</details>
<details>
<summary>摘要</summary>
“视频彩色化，目标是从灰度帧中获得鲜艳和合理的结果，在最近几年内引起了很多关注。然而，如何保持时间一致性而保持彩色结果的质量仍然是一大挑战。为解决以上问题，我们提出了基于 histogram 和空间-时间结构的彩色视频处理方法（简称 ST-HVC）。在使用 histogram 和流动特征之前，我们特制了 JOINT FLOW 和 histogram 模块，以便充分利用彩色和运动信息。此外，我们还设计了一种组合方案，以解决杂乱和瑕疵问题。最后，我们通过 U 型网络重新组合 histogram、流动和锐度特征，以实现优秀的性能。我们对多个图像和视频基础方法进行了广泛的比较，并证明了我们提出的方法在两个视频数据集上的出色性 both quantitatively and qualitatively。”Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Transmission-and-Color-guided-Network-for-Underwater-Image-Enhancement"><a href="#Transmission-and-Color-guided-Network-for-Underwater-Image-Enhancement" class="headerlink" title="Transmission and Color-guided Network for Underwater Image Enhancement"></a>Transmission and Color-guided Network for Underwater Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04892">http://arxiv.org/abs/2308.04892</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pan Mu, Jing Fang, Haotian Qian, Cong Bai</li>
<li>for: 提高水下图像质量，解决色偏和对比度低的问题。</li>
<li>methods: 提出了一种基于适应传输和动态色彩导航的网络（ATDCnet），利用物理知识设计了适应传输导向模块（ATM）和动态色彩导航模块（DCM），同时实现了色彩Restoration和对比度增强。</li>
<li>results: 对多个 referential dataset进行了广泛的实验，并达到了当前最佳性能。<details>
<summary>Abstract</summary>
In recent years, with the continuous development of the marine industry, underwater image enhancement has attracted plenty of attention. Unfortunately, the propagation of light in water will be absorbed by water bodies and scattered by suspended particles, resulting in color deviation and low contrast. To solve these two problems, we propose an Adaptive Transmission and Dynamic Color guided network (named ATDCnet) for underwater image enhancement. In particular, to exploit the knowledge of physics, we design an Adaptive Transmission-directed Module (ATM) to better guide the network. To deal with the color deviation problem, we design a Dynamic Color-guided Module (DCM) to post-process the enhanced image color. Further, we design an Encoder-Decoder-based Compensation (EDC) structure with attention and a multi-stage feature fusion mechanism to perform color restoration and contrast enhancement simultaneously. Extensive experiments demonstrate the state-of-the-art performance of the ATDCnet on multiple benchmark datasets.
</details>
<details>
<summary>摘要</summary>
Specifically, we design an Adaptive Transmission-directed Module (ATM) to better guide the network, taking into account the knowledge of physics. To address the color deviation issue, we design a Dynamic Color-guided Module (DCM) to post-process the enhanced image color. Additionally, we propose an Encoder-Decoder-based Compensation (EDC) structure with attention and a multi-stage feature fusion mechanism to perform color restoration and contrast enhancement simultaneously.Extensive experiments show that the ATDCnet achieves state-of-the-art performance on multiple benchmark datasets.
</details></li>
</ul>
<hr>
<h2 id="Deep-Generative-Networks-for-Heterogeneous-Augmentation-of-Cranial-Defects"><a href="#Deep-Generative-Networks-for-Heterogeneous-Augmentation-of-Cranial-Defects" class="headerlink" title="Deep Generative Networks for Heterogeneous Augmentation of Cranial Defects"></a>Deep Generative Networks for Heterogeneous Augmentation of Cranial Defects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04883">http://arxiv.org/abs/2308.04883</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kamil Kwarciak, Marek Wodzinski</li>
<li>For: 本研究旨在提高个性化头部充填设计的自动化程度，通过使用深度学习技术。* Methods: 本研究使用了三种深度生成模型来增强数据集，包括Wasserstein生成对抗网络带梯度约束（WGAN-GP）、WGAN-GP混合变换学习（VAE&#x2F;WGAN-GP）和 introspective变换学习（IntroVAE）。* Results: 通过生成各种不同的缺陷头骨，包括具有相同缺陷的多个头骨，使得自动设计个性化头部充填的过程得到了大幅提高。研究表明，使用生成的头骨数据可以提高缺陷分割的精度，并且可以提供更多的实际案例研究。<details>
<summary>Abstract</summary>
The design of personalized cranial implants is a challenging and tremendous task that has become a hot topic in terms of process automation with the use of deep learning techniques. The main challenge is associated with the high diversity of possible cranial defects. The lack of appropriate data sources negatively influences the data-driven nature of deep learning algorithms. Hence, one of the possible solutions to overcome this problem is to rely on synthetic data. In this work, we propose three volumetric variations of deep generative models to augment the dataset by generating synthetic skulls, i.e. Wasserstein Generative Adversarial Network with Gradient Penalty (WGAN-GP), WGAN-GP hybrid with Variational Autoencoder pretraining (VAE/WGAN-GP) and Introspective Variational Autoencoder (IntroVAE). We show that it is possible to generate dozens of thousands of defective skulls with compatible defects that achieve a trade-off between defect heterogeneity and the realistic shape of the skull. We evaluate obtained synthetic data quantitatively by defect segmentation with the use of V-Net and qualitatively by their latent space exploration. We show that the synthetically generated skulls highly improve the segmentation process compared to using only the original unaugmented data. The generated skulls may improve the automatic design of personalized cranial implants for real medical cases.
</details>
<details>
<summary>摘要</summary>
文本：预制个性化头部刺青设计是一项复杂且具有挑战性的任务，目前在使用深度学习技术时已经成为热点话题。主要挑战在于头部缺陷的多样性。缺乏合适的数据源，使得深度学习算法的数据驱动特性受到负面影响。因此，可以考虑使用合成数据来解决这个问题。在这个工作中，我们提出了三种深度生成模型的几何变换，用于增强数据集，即 Wasserstein生成对抗网络 with Gradient Penalty (WGAN-GP)、WGAN-GP 杂合 hybrid with Variational Autoencoder pretraining (VAE/WGAN-GP) 和 Introspective Variational Autoencoder (IntroVAE)。我们发现可以生成多达数千个具有相同缺陷的人工头部，并且实现了缺陷多样性和真实的头部形状之间的质量衡量。我们通过 V-Net 进行缺陷分割评估，以及latent space探索来评估生成的头部。结果显示，生成的头部能够大幅提高分割过程的精度，相比使用原始未处理数据。这些生成的头部可能会改善实际医疗案例中的个性化头部刺青设计。简化中文：预制个性化头部刺青设计是一项复杂且具有挑战性的任务。主要挑战在于头部缺陷的多样性。缺乏合适的数据源，使得深度学习算法的数据驱动特性受到负面影响。因此，可以考虑使用合成数据来解决这个问题。我们提出了三种深度生成模型，用于增强数据集，包括 Wasserstein生成对抗网络、WGAN-GP 杂合 hybrid 和 Introspective Variational Autoencoder。我们发现可以生成多达数千个具有相同缺陷的人工头部，并且实现了缺陷多样性和真实的头部形状之间的质量衡量。这些生成的头部可能会改善实际医疗案例中的个性化头部刺青设计。
</details></li>
</ul>
<hr>
<h2 id="Learning-multi-domain-feature-relation-for-visible-and-Long-wave-Infrared-image-patch-matching"><a href="#Learning-multi-domain-feature-relation-for-visible-and-Long-wave-Infrared-image-patch-matching" class="headerlink" title="Learning multi-domain feature relation for visible and Long-wave Infrared image patch matching"></a>Learning multi-domain feature relation for visible and Long-wave Infrared image patch matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04880">http://arxiv.org/abs/2308.04880</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiuwei Zhang, Yanping Li, Zhaoshuai Qi, Yi Sun, Yanning Zhang</li>
<li>for: 本研究的目的是提高 Cross-spectral 图像块匹配的性能，特别是在实际应用中。</li>
<li>methods: 本研究使用了一种多元领域特征关系学习网络（MD-FRN），该网络输入了四个分支网络提取的特征，并通过空间相关模块（SCM）和多规 adapted 集成模块（MSAG）来学习空间和缩放领域的特征关系。此外，一种深度域互动机制（DIM）也被应用，以便学习交互式的多元领域特征关系，从而提高对不同模式的应用变化的Robustness。</li>
<li>results: 研究发现，使用 MD-FRN 网络可以提高 Cross-spectral 图像块匹配的性能，特别是在面对不同模式的应用变化时。<details>
<summary>Abstract</summary>
Recently, learning-based algorithms have achieved promising performance on cross-spectral image patch matching, which, however, is still far from satisfactory for practical application. On the one hand, a lack of large-scale dataset with diverse scenes haunts its further improvement for learning-based algorithms, whose performances and generalization rely heavily on the dataset size and diversity. On the other hand, more emphasis has been put on feature relation in the spatial domain whereas the scale dependency between features has often been ignored, leading to performance degeneration especially when encountering significant appearance variations for cross-spectral patches. To address these issues, we publish, to be best of our knowledge, the largest visible and Long-wave Infrared (LWIR) image patch matching dataset, termed VL-CMIM, which contains 1300 pairs of strictly aligned visible and LWIR images and over 2 million patch pairs covering diverse scenes such as asteroid, field, country, build, street and water.In addition, a multi-domain feature relation learning network (MD-FRN) is proposed. Input by the features extracted from a four-branch network, both feature relations in spatial and scale domains are learned via a spatial correlation module (SCM) and multi-scale adaptive aggregation module (MSAG), respectively. To further aggregate the multi-domain relations, a deep domain interactive mechanism (DIM) is applied, where the learnt spatial-relation and scale-relation features are exchanged and further input into MSCRM and SCM. This mechanism allows our model to learn interactive cross-domain feature relations, leading to improved robustness to significant appearance changes due to different modality.
</details>
<details>
<summary>摘要</summary>
近些时间，学习基本的算法在跨спектル图像小块匹配方面实现了可观的表现，但是仍然远远不够满足实际应用需求。一方面，缺乏大规模的多样化场景的数据集，使得further improvement of learning-based algorithms的表现和泛化受到数据集大小和多样化的重要限制。另一方面，更多的注重点放在图像域的特征关系上，而忽略了特征之间的尺度关系，导致特征变化时的表现下降，特别是在遇到明显的特征变化时。为解决这些问题，我们在本文中发布了，以我们所知道的最大的可见和长波infrared（LWIR）图像小块匹配数据集，称为VL-CMIM，该数据集包含1300对精准对齐的可见和LWIR图像，以及超过200万个小块对。此外，我们还提出了一种多域特征关系学习网络（MD-FRN），该网络输入来自四个分支网络提取的特征，并通过空间相关模块（SCM）和多Scale适应汇集模块（MSAG）分别学习图像域和尺度域的特征关系。为了进一步汇集多域关系，我们还应用了深度域互动机制（DIM），该机制使得我们的模型可以学习交互的跨域特征关系，从而提高对不同模态的外观变化的Robustness。
</details></li>
</ul>
<hr>
<h2 id="Tracking-Players-in-a-Badminton-Court-by-Two-Cameras"><a href="#Tracking-Players-in-a-Badminton-Court-by-Two-Cameras" class="headerlink" title="Tracking Players in a Badminton Court by Two Cameras"></a>Tracking Players in a Badminton Court by Two Cameras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04872">http://arxiv.org/abs/2308.04872</a></li>
<li>repo_url: None</li>
<li>paper_authors: Young-Ching Chou, Shen-Ru Zhang, Bo-Wei Chen, Hong-Qi Chen, Cheng-Kuan Lin, Yu-Chee Tseng</li>
<li>for: 这个研究旨在提供一种简单的多对象跟踪（MOT）方法，用于跟踪羽毛球场上的球员。</li>
<li>methods: 该方法利用了两台废料相机，一台位于球场顶部，另一台位于球场侧面。顶部相机用于跟踪球员的轨迹，侧面相机用于分析球员的像素特征。通过计算相邻帧之间的相关性和利用两个相机的信息，实现了球员跟踪。</li>
<li>results: 该方法可以减轻球员 occlusion 和重叠问题，提供了球员轨迹跟踪和多视角分析。系统提供了球员位置和运动姿势的信息，可以作为羽毛球教练或自我训练工具，帮助球员提高游戏策略。<details>
<summary>Abstract</summary>
This study proposes a simple method for multi-object tracking (MOT) of players in a badminton court. We leverage two off-the-shelf cameras, one on the top of the court and the other on the side of the court. The one on the top is to track players' trajectories, while the one on the side is to analyze the pixel features of players. By computing the correlations between adjacent frames and engaging the information of the two cameras, MOT of badminton players is obtained. This two-camera approach addresses the challenge of player occlusion and overlapping in a badminton court, providing player trajectory tracking and multi-angle analysis. The presented system offers insights into the positions and movements of badminton players, thus serving as a coaching or self-training tool for badminton players to improve their gaming strategies.
</details>
<details>
<summary>摘要</summary>
这项研究提出了一种简单的多对目标跟踪（MOT）方法，用于跟踪Badminton场上球员的运动轨迹。我们利用了两台准备的摄像头，一台置于场上，另一台置于场边。前者用于跟踪球员的轨迹，后者用于分析球员的像素特征。通过计算相邻帧之间的相关性和两台摄像头的信息，实现了球员 occlusion 和 overlap 问题的解决，从而实现了多个角度的分析和球员轨迹跟踪。该系统为Badminton球员提供了运动轨迹和多个角度分析的视角，可以作为教练或自我训练工具，帮助球员改进游戏策略。
</details></li>
</ul>
<hr>
<h2 id="InstantAvatar-Efficient-3D-Head-Reconstruction-via-Surface-Rendering"><a href="#InstantAvatar-Efficient-3D-Head-Reconstruction-via-Surface-Rendering" class="headerlink" title="InstantAvatar: Efficient 3D Head Reconstruction via Surface Rendering"></a>InstantAvatar: Efficient 3D Head Reconstruction via Surface Rendering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04868">http://arxiv.org/abs/2308.04868</a></li>
<li>repo_url: None</li>
<li>paper_authors: Antonio Canela, Pol Caselles, Ibrar Malik, Eduard Ramon, Jaime García, Jordi Sánchez-Riera, Gil Triginer, Francesc Moreno-Noguer</li>
<li>for: 快速生成全头Avtaar（full-head avatar）from few images（down to just one）</li>
<li>methods:  combinest voxel-grid neural field representation with surface renderer, and uses a novel statistical model to learn a prior distribution over 3D head signed distance functions.</li>
<li>results: achieves 3D head reconstructions with comparable accuracy as the state-of-the-art, with a 100x speed-up.<details>
<summary>Abstract</summary>
Recent advances in full-head reconstruction have been obtained by optimizing a neural field through differentiable surface or volume rendering to represent a single scene. While these techniques achieve an unprecedented accuracy, they take several minutes, or even hours, due to the expensive optimization process required. In this work, we introduce InstantAvatar, a method that recovers full-head avatars from few images (down to just one) in a few seconds on commodity hardware. In order to speed up the reconstruction process, we propose a system that combines, for the first time, a voxel-grid neural field representation with a surface renderer. Notably, a naive combination of these two techniques leads to unstable optimizations that do not converge to valid solutions. In order to overcome this limitation, we present a novel statistical model that learns a prior distribution over 3D head signed distance functions using a voxel-grid based architecture. The use of this prior model, in combination with other design choices, results into a system that achieves 3D head reconstructions with comparable accuracy as the state-of-the-art with a 100x speed-up.
</details>
<details>
<summary>摘要</summary>
最近的全头重建技术已经取得了很大的进步，通过使用可导表面或体积渲染来优化神经场来表示一个场景。尽管这些技术达到了历史上无前例的精度，但它们需要几分钟或者几个小时的昂贵优化过程。在这项工作中，我们介绍了InstantAvatar方法，可以从几张图像（甚至是一张）中快速地恢复全头模型，仅需几秒钟的时间。为了加速重建过程，我们提议一种结合了神经场格表示和表面渲染的系统。尽管这种组合可能导致不稳定的优化过程，但我们提出了一种新的统计模型，可以学习3D头签名距离函数的 prior 分布。通过这种先进的统计模型，我们可以在其他设计选择的基础上实现一个100倍加速的系统，并且和现状的精度相当。
</details></li>
</ul>
<hr>
<h2 id="Are-Sex-based-Physiological-Differences-the-Cause-of-Gender-Bias-for-Chest-X-ray-Diagnosis"><a href="#Are-Sex-based-Physiological-Differences-the-Cause-of-Gender-Bias-for-Chest-X-ray-Diagnosis" class="headerlink" title="Are Sex-based Physiological Differences the Cause of Gender Bias for Chest X-ray Diagnosis?"></a>Are Sex-based Physiological Differences the Cause of Gender Bias for Chest X-ray Diagnosis?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05129">http://arxiv.org/abs/2308.05129</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nina Weng, Siavash Bigdeli, Eike Petersen, Aasa Feragen</li>
<li>for: 这种研究旨在解释胸部X射线诊断中的性别偏见的原因。</li>
<li>methods: 该研究提出了一种新的采样方法，以解决两个公共数据集中每个病人记录的极度不均衡分布，同时减少标签错误的影响。</li>
<li>results: 研究发现，不是数据集的不均衡导致性别之间的表现差异，而是数据集特有的因素。此外，研究还发现，对于不同疾病和数据集，男女群体之间的表现差异强烈不同。最后，研究发现，对卷积物的影响不是解决表现差异的关键。<details>
<summary>Abstract</summary>
While many studies have assessed the fairness of AI algorithms in the medical field, the causes of differences in prediction performance are often unknown. This lack of knowledge about the causes of bias hampers the efficacy of bias mitigation, as evidenced by the fact that simple dataset balancing still often performs best in reducing performance gaps but is unable to resolve all performance differences. In this work, we investigate the causes of gender bias in machine learning-based chest X-ray diagnosis. In particular, we explore the hypothesis that breast tissue leads to underexposure of the lungs and causes lower model performance. Methodologically, we propose a new sampling method which addresses the highly skewed distribution of recordings per patient in two widely used public datasets, while at the same time reducing the impact of label errors. Our comprehensive analysis of gender differences across diseases, datasets, and gender representations in the training set shows that dataset imbalance is not the sole cause of performance differences. Moreover, relative group performance differs strongly between datasets, indicating important dataset-specific factors influencing male/female group performance. Finally, we investigate the effect of breast tissue more specifically, by cropping out the breasts from recordings, finding that this does not resolve the observed performance gaps. In conclusion, our results indicate that dataset-specific factors, not fundamental physiological differences, are the main drivers of male--female performance gaps in chest X-ray analyses on widely used NIH and CheXpert Dataset.
</details>
<details>
<summary>摘要</summary>
多个研究已经评估了人工智能算法在医疗领域的公平性，但是对差异的预测性能的原因frequently unknown.这种不知道偏见的原因使得偏见缓减措施效果受限，例如简单的数据集平衡仍然能够减少性能差距，但是无法解决所有的差距。在这个工作中，我们调查了机器学习基于骨科X光图诊的性别偏见的原因。特别是，我们研究了肿瘤组织导致肺部不足暴露和降低模型性能的假设。方法上，我们提出了一种新的采样方法， Addressing the highly skewed distribution of recordings per patient in two widely used public datasets, while reducing the impact of label errors.我们对男女之间疾病、数据集和训练集中的性别表示进行了全面的分析，发现数据集偏见不是差异的唯一原因。此外，数据集之间的相对性能差异强烈，表明 dataset-specific factors significantly influencing male/female group performance.最后，我们具体调查了乳腺组织的影响，通过将乳腺从记录中剪除，发现这并不能解决观察到的性能差距。结论是，我们的结果表明，在 widely used NIH and CheXpert Dataset 上， male--female performance gaps in chest X-ray analyses are mainly driven by dataset-specific factors, not fundamental physiological differences.
</details></li>
</ul>
<hr>
<h2 id="View-while-Moving-Efficient-Video-Recognition-in-Long-untrimmed-Videos"><a href="#View-while-Moving-Efficient-Video-Recognition-in-Long-untrimmed-Videos" class="headerlink" title="View while Moving: Efficient Video Recognition in Long-untrimmed Videos"></a>View while Moving: Efficient Video Recognition in Long-untrimmed Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04834">http://arxiv.org/abs/2308.04834</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ye Tian, Mengyu Yang, Lanshan Zhang, Zhizhen Zhang, Yang Liu, Xiaohui Xie, Xirong Que, Wendong Wang</li>
<li>for: 本研究旨在提出一种高效的长视频认知方法，以提高视频识别的效率和准确率。</li>
<li>methods: 本研究使用了人类认知的“视而移”理念，提出了一种新的识别方法，即将粗粒度和细粒度的预览和识别合并到一个整体模型中，从而实现了一次性访问原始帧的目的。</li>
<li>results: 实验结果表明，本方法在长视频和短视频识别任务上均达到了状态革命的性能，同时也提供了新的效率和准确率的贸易OFF。<details>
<summary>Abstract</summary>
Recent adaptive methods for efficient video recognition mostly follow the two-stage paradigm of "preview-then-recognition" and have achieved great success on multiple video benchmarks. However, this two-stage paradigm involves two visits of raw frames from coarse-grained to fine-grained during inference (cannot be parallelized), and the captured spatiotemporal features cannot be reused in the second stage (due to varying granularity), being not friendly to efficiency and computation optimization. To this end, inspired by human cognition, we propose a novel recognition paradigm of "View while Moving" for efficient long-untrimmed video recognition. In contrast to the two-stage paradigm, our paradigm only needs to access the raw frame once. The two phases of coarse-grained sampling and fine-grained recognition are combined into unified spatiotemporal modeling, showing great performance. Moreover, we investigate the properties of semantic units in video and propose a hierarchical mechanism to efficiently capture and reason about the unit-level and video-level temporal semantics in long-untrimmed videos respectively. Extensive experiments on both long-untrimmed and short-trimmed videos demonstrate that our approach outperforms state-of-the-art methods in terms of accuracy as well as efficiency, yielding new efficiency and accuracy trade-offs for video spatiotemporal modeling.
</details>
<details>
<summary>摘要</summary>
现代适应方法 для高效视频识别大多采用两个阶段 paradigm，即"预览然后识别"，在推理过程中两次访问粗粒度和细粒度的原始帧（不能并发），并且在第二阶段 capture的空间时间特征不能重用（因为不同的粒度），不友好于效率和计算优化。为了解决这个问题，我们受人类认知启发，提出了一种新的识别方法——"在移动中查看"，这种方法只需要访问原始帧一次。在两个阶段的粗粒度和细粒度 sampling 和识别结合在一起，实现了非常出色的性能。此外，我们还研究了视频中元素的性质，并提出了一种层次机制来高效地捕捉和理解视频中元素的时间 semantics。广泛的实验表明，我们的方法在精度和效率两个方面都高于当前状态艺术方法，提供了新的精度和效率贸易平衡 для视频空间模型。
</details></li>
</ul>
<hr>
<h2 id="VAST-Vivify-Your-Talking-Avatar-via-Zero-Shot-Expressive-Facial-Style-Transfer"><a href="#VAST-Vivify-Your-Talking-Avatar-via-Zero-Shot-Expressive-Facial-Style-Transfer" class="headerlink" title="VAST: Vivify Your Talking Avatar via Zero-Shot Expressive Facial Style Transfer"></a>VAST: Vivify Your Talking Avatar via Zero-Shot Expressive Facial Style Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04830">http://arxiv.org/abs/2308.04830</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liyang Chen, Zhiyong Wu, Runnan Li, Weihong Bao, Jun Ling, Xu Tan, Sheng Zhao</li>
<li>for: 论文旨在提高现代人工智能讲话人物的生动性和多样性，使其能够从任意视频提示中提取表达性的人脸样式。</li>
<li>methods: 该论文提出了一种不supervised variational style transfer模型（VAST），包括三个关键组件：样式编码器、混合表达解码器和变量式样式增强器。这三个组件共同使得模型能够从视频提示中提取准确的 speech-related 运动和表达性的人脸样式。</li>
<li>results: 实验结果表明，提出的方法能够在零shot情况下，从任意视频提示中提取表达性的人脸样式，并将其转移到个性化的图像渲染器上，以获得更加生动、有authenticity和丰富的讲话人物。<details>
<summary>Abstract</summary>
Current talking face generation methods mainly focus on speech-lip synchronization. However, insufficient investigation on the facial talking style leads to a lifeless and monotonous avatar. Most previous works fail to imitate expressive styles from arbitrary video prompts and ensure the authenticity of the generated video. This paper proposes an unsupervised variational style transfer model (VAST) to vivify the neutral photo-realistic avatars. Our model consists of three key components: a style encoder that extracts facial style representations from the given video prompts; a hybrid facial expression decoder to model accurate speech-related movements; a variational style enhancer that enhances the style space to be highly expressive and meaningful. With our essential designs on facial style learning, our model is able to flexibly capture the expressive facial style from arbitrary video prompts and transfer it onto a personalized image renderer in a zero-shot manner. Experimental results demonstrate the proposed approach contributes to a more vivid talking avatar with higher authenticity and richer expressiveness.
</details>
<details>
<summary>摘要</summary>
当前的话语生成方法主要关注于 speech-lip 同步。然而，对话优化方法的不足导致生成的人工智能人物具有毫不生动的、单一的表情。大多数前一代的工作无法从 произвольный视频提示中捕捉出表情特征，并确保生成的视频的authenticity。本文提出一种无监督的变换式样本传输模型（VAST），以vivify中性真实的人工智能人物。我们的模型包括三个关键组件：一个样式编码器，用于从给定的视频提示中提取表情样式表示;一个混合的表情解码器，用于模型准确的speech-相关的动作;一个变换式样本增强器，用于增强样式空间，使其具有高度表意和意义。通过我们的关键设计，我们的模型能够灵活地从 произвольный视频提示中捕捉表情样式，并将其传输到个性化的图像渲染器中，无需预训练。实验结果表明，我们的方法对生成的人工智能人物具有更高的authenticity和更丰富的表达力。
</details></li>
</ul>
<hr>
<h2 id="MixReorg-Cross-Modal-Mixed-Patch-Reorganization-is-a-Good-Mask-Learner-for-Open-World-Semantic-Segmentation"><a href="#MixReorg-Cross-Modal-Mixed-Patch-Reorganization-is-a-Good-Mask-Learner-for-Open-World-Semantic-Segmentation" class="headerlink" title="MixReorg: Cross-Modal Mixed Patch Reorganization is a Good Mask Learner for Open-World Semantic Segmentation"></a>MixReorg: Cross-Modal Mixed Patch Reorganization is a Good Mask Learner for Open-World Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04829">http://arxiv.org/abs/2308.04829</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaixin Cai, Pengzhen Ren, Yi Zhu, Hang Xu, Jianzhuang Liu, Changlin Li, Guangrun Wang, Xiaodan Liang</li>
<li>for: 提高 semantic segmentation 模型在开放世界enario中的精细对alignment和物体mask预测能力。</li>
<li>methods: 使用 MixReorg 准则，通过混合图像patches并保持patch和文本之间匹配性，提高模型对图像区域的精细Semantic alignment能力。</li>
<li>results: 在多个Zero-shot semantic segmentation benchmark上达到了显著的提高，相比GroupViT， MixReorg 模型在 PASCAL VOC2012、PASCAL Context、MS COCO 和 ADE20K 上的mIoU提高为5.0%、6.2%、2.5% 和 3.4%。<details>
<summary>Abstract</summary>
Recently, semantic segmentation models trained with image-level text supervision have shown promising results in challenging open-world scenarios. However, these models still face difficulties in learning fine-grained semantic alignment at the pixel level and predicting accurate object masks. To address this issue, we propose MixReorg, a novel and straightforward pre-training paradigm for semantic segmentation that enhances a model's ability to reorganize patches mixed across images, exploring both local visual relevance and global semantic coherence. Our approach involves generating fine-grained patch-text pairs data by mixing image patches while preserving the correspondence between patches and text. The model is then trained to minimize the segmentation loss of the mixed images and the two contrastive losses of the original and restored features. With MixReorg as a mask learner, conventional text-supervised semantic segmentation models can achieve highly generalizable pixel-semantic alignment ability, which is crucial for open-world segmentation. After training with large-scale image-text data, MixReorg models can be applied directly to segment visual objects of arbitrary categories, without the need for further fine-tuning. Our proposed framework demonstrates strong performance on popular zero-shot semantic segmentation benchmarks, outperforming GroupViT by significant margins of 5.0%, 6.2%, 2.5%, and 3.4% mIoU on PASCAL VOC2012, PASCAL Context, MS COCO, and ADE20K, respectively.
</details>
<details>
<summary>摘要</summary>
最近，受图像级文本监督训练的 semantic segmentation 模型在开放世界enario中表现出色，但这些模型仍然面临精度的semantic alignment 和准确的 объек mask 预测问题。为解决这个问题，我们提出 MixReorg，一种新的预训练方法 для semantic segmentation，该方法可以提高模型对图像中混合的 patch 的重新组织能力，同时考虑本地视觉相关性和全局semantic coherence。我们的方法是通过混合图像 patch 而生成细化的 patch-text 对，并训练模型将混合图像的 segmentation 损失和原始和恢复特征的两个对照损失降低到最小值。通过 MixReorg 作为 mask learner，传统的文本监督 semantic segmentation 模型可以学习高度普适的像素级semantic alignment能力，这是开放世界 segmentation 中非常重要的。 после训练大规模的图像-文本数据，MixReorg 模型可以直接应用于任意类型的视觉对象分割，无需进一步的微调。我们的提出的框架在流行的零shot semantic segmentation 标准准的 benchmark 上显示出强大的表现，比 GroupViT 高出5.0%, 6.2%, 2.5%, 3.4% mIoU 的提高。
</details></li>
</ul>
<hr>
<h2 id="Seeing-in-Flowing-Adapting-CLIP-for-Action-Recognition-with-Motion-Prompts-Learning"><a href="#Seeing-in-Flowing-Adapting-CLIP-for-Action-Recognition-with-Motion-Prompts-Learning" class="headerlink" title="Seeing in Flowing: Adapting CLIP for Action Recognition with Motion Prompts Learning"></a>Seeing in Flowing: Adapting CLIP for Action Recognition with Motion Prompts Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04828">http://arxiv.org/abs/2308.04828</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiang Wang, Junlong Du, Ke Yan, Shouhong Ding</li>
<li>for: 实现更高效和泛化的动作识别方法</li>
<li>methods: 提出了两流动模型块，一流动模型块用于捕捉视频帧中的动作和空间信息，另一流动模型块用于生成动作aware的提示，并提出了多模态通信块来实现多模态学习</li>
<li>results: 在hmdb-51、ucf-101和kinetics-400 datasets上进行了广泛的实验，其方法在”少shot”和”zero-shot”训练中超越了大多数现有的状态静态方法，并在”closed-set”训练中实现了非常少的可训练参数和额外计算成本。<details>
<summary>Abstract</summary>
The Contrastive Language-Image Pre-training (CLIP) has recently shown remarkable generalization on "zero-shot" training and has applied to many downstream tasks. We explore the adaptation of CLIP to achieve a more efficient and generalized action recognition method. We propose that the key lies in explicitly modeling the motion cues flowing in video frames. To that end, we design a two-stream motion modeling block to capture motion and spatial information at the same time. And then, the obtained motion cues are utilized to drive a dynamic prompts learner to generate motion-aware prompts, which contain much semantic information concerning human actions. In addition, we propose a multimodal communication block to achieve a collaborative learning and further improve the performance. We conduct extensive experiments on HMDB-51, UCF-101, and Kinetics-400 datasets. Our method outperforms most existing state-of-the-art methods by a significant margin on "few-shot" and "zero-shot" training. We also achieve competitive performance on "closed-set" training with extremely few trainable parameters and additional computational costs.
</details>
<details>
<summary>摘要</summary>
CLIP（对照语言图像预训）在最近的应用中显示了很好的普遍化能力，特别是在“零shot”训练中。我们想要探索CLIP的改进，以实现更有效和普遍的动作识别方法。我们认为关键在于Explicitly 模型影像中的动作讯号。为此，我们设计了两条流动模型对应块，以同时捕捉影像中的动作和空间信息。然后，所获得的动作讯号被用来驱动动态提示学习者生成动作感知的提示，这些提示具有人类动作的含义信息。此外，我们提议了多模式通信对应块，以实现多模式学习和进一步提高性能。我们对HMDB-51、UCF-101和Kinetics-400 dataset进行了广泛的实验。我们的方法在“几shot”和“零shot”训练中比大多数现有的方法表现出了明显的超越。我们还在“关闭集”训练中取得了非常有效的性能，仅需要极少的可训练参数和额外的计算成本。
</details></li>
</ul>
<hr>
<h2 id="WaveNeRF-Wavelet-based-Generalizable-Neural-Radiance-Fields"><a href="#WaveNeRF-Wavelet-based-Generalizable-Neural-Radiance-Fields" class="headerlink" title="WaveNeRF: Wavelet-based Generalizable Neural Radiance Fields"></a>WaveNeRF: Wavelet-based Generalizable Neural Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04826">http://arxiv.org/abs/2308.04826</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muyu Xu, Fangneng Zhan, Jiahui Zhang, Yingchen Yu, Xiaoqin Zhang, Christian Theobalt, Ling Shao, Shijian Lu</li>
<li>for: 用于 novel view synthesis via implicit scene representation，但通常受到精度降低的问题。</li>
<li>methods:  integrate Multi-View Stereo (MVS) technique into NeRF，并在新场景中进行一定的微调。</li>
<li>results: 通过将浮点数分解插入到MVS和NeRF中，实现了高质量且通用的Synthesis，无需每个新场景进行微调。<details>
<summary>Abstract</summary>
Neural Radiance Field (NeRF) has shown impressive performance in novel view synthesis via implicit scene representation. However, it usually suffers from poor scalability as requiring densely sampled images for each new scene. Several studies have attempted to mitigate this problem by integrating Multi-View Stereo (MVS) technique into NeRF while they still entail a cumbersome fine-tuning process for new scenes. Notably, the rendering quality will drop severely without this fine-tuning process and the errors mainly appear around the high-frequency features. In the light of this observation, we design WaveNeRF, which integrates wavelet frequency decomposition into MVS and NeRF to achieve generalizable yet high-quality synthesis without any per-scene optimization. To preserve high-frequency information when generating 3D feature volumes, WaveNeRF builds Multi-View Stereo in the Wavelet domain by integrating the discrete wavelet transform into the classical cascade MVS, which disentangles high-frequency information explicitly. With that, disentangled frequency features can be injected into classic NeRF via a novel hybrid neural renderer to yield faithful high-frequency details, and an intuitive frequency-guided sampling strategy can be designed to suppress artifacts around high-frequency regions. Extensive experiments over three widely studied benchmarks show that WaveNeRF achieves superior generalizable radiance field modeling when only given three images as input.
</details>
<details>
<summary>摘要</summary>
neural radiance field (NeRF) 已经展现出优秀的新视图合成能力via做 Implicit scene representation. However, it usually suffers from poor scalability as it requires densely sampled images for each new scene. Several studies have attempted to mitigate this problem by integrating Multi-View Stereo (MVS) technique into NeRF, while they still entail a cumbersome fine-tuning process for new scenes. Notably, the rendering quality will drop severely without this fine-tuning process, and the errors mainly appear around the high-frequency features. In the light of this observation, we design WaveNeRF, which integrates wavelet frequency decomposition into MVS and NeRF to achieve generalizable yet high-quality synthesis without any per-scene optimization. To preserve high-frequency information when generating 3D feature volumes, WaveNeRF builds Multi-View Stereo in the Wavelet domain by integrating the discrete wavelet transform into the classical cascade MVS, which disentangles high-frequency information explicitly. With that, disentangled frequency features can be injected into classic NeRF via a novel hybrid neural renderer to yield faithful high-frequency details, and an intuitive frequency-guided sampling strategy can be designed to suppress artifacts around high-frequency regions. Extensive experiments over three widely studied benchmarks show that WaveNeRF achieves superior generalizable radiance field modeling when only given three images as input.
</details></li>
</ul>
<hr>
<h2 id="HyperCoil-Recon-A-Hypernetwork-based-Adaptive-Coil-Configuration-Task-Switching-Network-for-MRI-Reconstruction"><a href="#HyperCoil-Recon-A-Hypernetwork-based-Adaptive-Coil-Configuration-Task-Switching-Network-for-MRI-Reconstruction" class="headerlink" title="HyperCoil-Recon: A Hypernetwork-based Adaptive Coil Configuration Task Switching Network for MRI Reconstruction"></a>HyperCoil-Recon: A Hypernetwork-based Adaptive Coil Configuration Task Switching Network for MRI Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04821">http://arxiv.org/abs/2308.04821</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sriprabhar/hypercoil-recon">https://github.com/sriprabhar/hypercoil-recon</a></li>
<li>paper_authors: Sriprabha Ramanarayanan, Mohammad Al Fahim, Rahul G. S., Amrit Kumar Jethi, Keerthi Ram, Mohanasankar Sivaprakasam<br>for: HyperCoil-Recon is proposed to address the challenge of training deep learning-based image reconstruction models for multi-coil MRI reconstruction, which requires adapting to diverse coil configurations.methods: The approach uses a hypernetwork-based coil configuration task-switching network, which encodes varying configurations of the number of coils in a multi-tasking perspective. The hypernetworks infer and embed task-specific weights into the reconstruction network, leveraging contextual knowledge of common and varying image features among the various fields-of-view of the coils.results: The approach adapts on the fly to various unseen configurations up to 32 coils when trained on lower numbers (i.e. 7 to 11) of randomly varying coils, and to 120 deviated unseen configurations when trained on 18 configurations in a single model. It matches the performance of coil configuration-specific models and outperforms configuration-invariant models with improvement margins of around 1 dB &#x2F; 0.03 and 0.3 dB &#x2F; 0.02 in PSNR &#x2F; SSIM for knee and brain data.<details>
<summary>Abstract</summary>
Parallel imaging, a fast MRI technique, involves dynamic adjustments based on the configuration i.e. number, positioning, and sensitivity of the coils with respect to the anatomy under study. Conventional deep learning-based image reconstruction models have to be trained or fine-tuned for each configuration, posing a barrier to clinical translation, given the lack of computational resources and machine learning expertise for clinicians to train models at deployment. Joint training on diverse datasets learns a single weight set that might underfit to deviated configurations. We propose, HyperCoil-Recon, a hypernetwork-based coil configuration task-switching network for multi-coil MRI reconstruction that encodes varying configurations of the numbers of coils in a multi-tasking perspective, posing each configuration as a task. The hypernetworks infer and embed task-specific weights into the reconstruction network, 1) effectively utilizing the contextual knowledge of common and varying image features among the various fields-of-view of the coils, and 2) enabling generality to unseen configurations at test time. Experiments reveal that our approach 1) adapts on the fly to various unseen configurations up to 32 coils when trained on lower numbers (i.e. 7 to 11) of randomly varying coils, and to 120 deviated unseen configurations when trained on 18 configurations in a single model, 2) matches the performance of coil configuration-specific models, and 3) outperforms configuration-invariant models with improvement margins of around 1 dB / 0.03 and 0.3 dB / 0.02 in PSNR / SSIM for knee and brain data. Our code is available at https://github.com/sriprabhar/HyperCoil-Recon
</details>
<details>
<summary>摘要</summary>
《平行巡检：一种快速MRI技术》，其中的巡检配置（number，positioning，sensitivity）与研究对象的解剖学相关。传统的深度学习基于图像重建模型需要根据配置进行训练或精度调整，这会对临床应用带来障碍，因为临床医生缺乏计算资源和机器学习专家来在部署时训练模型。我们提议使用卷积网络（hypernetwork）来实现巡检配置任务 switching，其中每个配置视为一个任务。卷积网络在重建网络中插入任务特有的 weights，以利用不同巡检配置中图像特征的共同知识，并在测试时对未经见配置进行普适化。我们的方法可以在不同的巡检配置下进行适应，并且与特定配置模型和配置不变模型相比，能够提高PSNR/SSIM指标约1dB/0.03和0.3dB/0.02。我们的代码可以在https://github.com/sriprabhar/HyperCoil-Recon上找到。
</details></li>
</ul>
<hr>
<h2 id="Joint-Relation-Transformer-for-Multi-Person-Motion-Prediction"><a href="#Joint-Relation-Transformer-for-Multi-Person-Motion-Prediction" class="headerlink" title="Joint-Relation Transformer for Multi-Person Motion Prediction"></a>Joint-Relation Transformer for Multi-Person Motion Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04808">http://arxiv.org/abs/2308.04808</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mediabrain-sjtu/jrtransformer">https://github.com/mediabrain-sjtu/jrtransformer</a></li>
<li>paper_authors: Qingyao Xu, Weibo Mao, Jingze Gong, Chenxin Xu, Siheng Chen, Weidi Xie, Ya Zhang, Yanfeng Wang</li>
<li>for: 提高人体动作预测精度，具体是通过关注人体关节和关系信息来提高人体交互模型化。</li>
<li>methods: 提出了关节关系变换器（Joint-Relation Transformer），利用关系信息来增强交互模型化，并通过关系意识注意力来融合关节信息和关系信息。</li>
<li>results: 实验表明，我们的方法在3DPW-SoMoF&#x2F;RC和CMU-Mpcap&#x2F;MuPoTS-3D数据集上 achieved a 13.4% improvement of 900ms VIM and 17.8%&#x2F;12.0% improvement of 3s MPJPE。<details>
<summary>Abstract</summary>
Multi-person motion prediction is a challenging problem due to the dependency of motion on both individual past movements and interactions with other people. Transformer-based methods have shown promising results on this task, but they miss the explicit relation representation between joints, such as skeleton structure and pairwise distance, which is crucial for accurate interaction modeling. In this paper, we propose the Joint-Relation Transformer, which utilizes relation information to enhance interaction modeling and improve future motion prediction. Our relation information contains the relative distance and the intra-/inter-person physical constraints. To fuse relation and joint information, we design a novel joint-relation fusion layer with relation-aware attention to update both features. Additionally, we supervise the relation information by forecasting future distance. Experiments show that our method achieves a 13.4% improvement of 900ms VIM on 3DPW-SoMoF/RC and 17.8%/12.0% improvement of 3s MPJPE on CMU-Mpcap/MuPoTS-3D dataset.
</details>
<details>
<summary>摘要</summary>
多人运动预测是一个复杂的问题，因为运动的依赖于每个人的过去运动和人们之间的交互。基于Transformer的方法在这个任务上表现出了承诺，但它们缺乏明确的关系表示，如骨架结构和对方之间的距离，这些信息对准确地模拟人体交互是非常重要。在这篇论文中，我们提出了关节关系变换器（Joint-Relation Transformer），它利用关系信息来增强交互模拟，并提高未来运动预测。我们的关系信息包括对方之间的距离和人体内部/外部的物理约束。为了融合关系和关节信息，我们设计了一种新的关节关系融合层，其中包含关注关系的注意力来更新两种特征。此外，我们还对关系信息进行预测未来距离的超vision，以便进一步训练关系信息。实验表明，我们的方法在3DPW-SoMoF/RC和CMU-Mpcap/MuPoTS-3D dataset上的900ms VIM和3s MPJPE上提高了13.4%和17.8%，分别。
</details></li>
</ul>
<hr>
<h2 id="Generalized-Unbiased-Scene-Graph-Generation"><a href="#Generalized-Unbiased-Scene-Graph-Generation" class="headerlink" title="Generalized Unbiased Scene Graph Generation"></a>Generalized Unbiased Scene Graph Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04802">http://arxiv.org/abs/2308.04802</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyu Lyu, Lianli Gao, Junlin Xie, Pengpeng Zeng, Yulu Tian, Jie Shao, Heng Tao Shen</li>
<li>for: 解决 predicate-level 和 concept-level 不均衡问题，提高Scene Graph Generation（SGG）模型的可靠性和 Compositional 能力。</li>
<li>methods: 提出了一种新的研究问题——Generalized Unbiased Scene Graph Generation（G-USGG），并提出了Multi-Concept Learning（MCL）框架，以确保学习过程中具有不同概念的均衡。同时，还引入了Balanced Prototypical Memory（BPM）来实现不同概念的平衡学习。</li>
<li>results: 对 VG-SGG 和 OI-SGG  dataset进行了广泛的实验，证明了我们的模型独立技术在提高 predicate-level 不均衡关系识别和 concept-level compositional 生成能力方面具有极高的效果，并在两个关键方面达到了新的州OF-THE-ART纪录。<details>
<summary>Abstract</summary>
Existing Unbiased Scene Graph Generation (USGG) methods only focus on addressing the predicate-level imbalance that high-frequency classes dominate predictions of rare ones, while overlooking the concept-level imbalance. Actually, even if predicates themselves are balanced, there is still a significant concept-imbalance within them due to the long-tailed distribution of contexts (i.e., subject-object combinations). This concept-level imbalance poses a more pervasive and challenging issue compared to the predicate-level imbalance since subject-object pairs are inherently complex in combinations. Hence, we introduce a novel research problem: Generalized Unbiased Scene Graph Generation (G-USGG), which takes into account both predicate-level and concept-level imbalance. To the end, we propose the Multi-Concept Learning (MCL) framework, which ensures a balanced learning process across rare/ uncommon/ common concepts. MCL first quantifies the concept-level imbalance across predicates in terms of different amounts of concepts, representing as multiple concept-prototypes within the same class. It then effectively learns concept-prototypes by applying the Concept Regularization (CR) technique. Furthermore, to achieve balanced learning over different concepts, we introduce the Balanced Prototypical Memory (BPM), which guides SGG models to generate balanced representations for concept-prototypes. Extensive experiments demonstrate the remarkable efficacy of our model-agnostic strategy in enhancing the performance of benchmark models on both VG-SGG and OI-SGG datasets, leading to new state-of-the-art achievements in two key aspects: predicate-level unbiased relation recognition and concept-level compositional generability.
</details>
<details>
<summary>摘要</summary>
现有的不偏 scene graph生成（USGG）方法只是解决 predicate-level 偏见问题，即高频类占据罕见类预测，而忽略了 concept-level 偏见。实际上，即使 predicate 本身具有平衡，也存在 context 中的 long-tailed 分布，导致 predicate 内部的 concept-level 偏见。这种 concept-level 偏见比 predicate-level 偏见更加广泛和困难，因为 subject-object 组合是复杂的。因此，我们提出了一个新的研究问题： Generalized Unbiased Scene Graph Generation（G-USGG），它考虑了 predicate-level 和 concept-level 偏见。为此，我们提出了 Multi-Concept Learning（MCL）框架，确保学习过程中具有平衡的概念。MCL 首先量化 predicate 中的 concept-level 偏见，并通过 Concept Regularization（CR）技术有效地学习概念权重。此外，为了实现不同概念之间的平衡学习，我们引入了 Balanced Prototypical Memory（BPM），它使得 SGG 模型生成的概念表示具有平衡。经验表明，我们的模型自适应策略可以提高 benchmark 模型在 VG-SGG 和 OI-SGG 数据集上的表现，并创造出新的 state-of-the-art 成绩在两个关键方面： predicate-level 不偏关系认识和 concept-level  композиitional 可 generates。
</details></li>
</ul>
<hr>
<h2 id="High-Level-Features-Parallelization-for-Inference-Cost-Reduction-Through-Selective-Attention"><a href="#High-Level-Features-Parallelization-for-Inference-Cost-Reduction-Through-Selective-Attention" class="headerlink" title="High-Level Features Parallelization for Inference Cost Reduction Through Selective Attention"></a>High-Level Features Parallelization for Inference Cost Reduction Through Selective Attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05128">http://arxiv.org/abs/2308.05128</a></li>
<li>repo_url: None</li>
<li>paper_authors: André Peter Kelm, Lucas Schmidt, Tim Rolff, Christian Wilms, Ehsan Yaghoubi, Simone Frintrop</li>
<li>for: 降低深度学习模型的执行成本，特别是适用于移动设备、工业应用和机器人应用等场景。</li>
<li>methods: 使用平行高级特征来选择性地跳过或选择类型特征，以降低推理成本。该方法基于人脑科学发现， Observation of spatially and contextually separated neural activations in the human brain.</li>
<li>results: 可以保持高性能，但可以减少参数数量、计算复杂度和电力消耗。在一些示例中，可以减少参数数量的75%，并且可以避免重新训练。此外，该方法还具有可以根据增强或抑制高级类型特征来直接影响处理的能力，类似于人脑中的选择性注意力机制。<details>
<summary>Abstract</summary>
In this work, we parallelize high-level features in deep networks to selectively skip or select class-specific features to reduce inference costs. This challenges most deep learning methods due to their limited ability to efficiently and effectively focus on selected class-specific features without retraining. We propose a serial-parallel hybrid architecture with serial generic low-level features and parallel high-level features. This accounts for the fact that many high-level features are class-specific rather than generic, and has connections to recent neuroscientific findings that observe spatially and contextually separated neural activations in the human brain. Our approach provides the unique functionality of cutouts: selecting parts of the network to focus on only relevant subsets of classes without requiring retraining. High performance is maintained, but the cost of inference can be significantly reduced. In some of our examples, up to $75\,\%$ of parameters are skipped and $35\,\%$ fewer GMACs (Giga multiply-accumulate) operations are used as the approach adapts to a change in task complexity. This is important for mobile, industrial, and robotic applications where reducing the number of parameters, the computational complexity, and thus the power consumption can be paramount. Another unique functionality is that it allows processing to be directly influenced by enhancing or inhibiting high-level class-specific features, similar to the mechanism of selective attention in the human brain. This can be relevant for cross-modal applications, the use of semantic prior knowledge, and/or context-aware processing.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们平行化深度网络中的高级特征，以选择性地跳过或选择特定类型的特征，以降低推理成本。这会挑战大多数深度学习方法，因为它们具有限制性能 efficiently和有效地关注选择的特定类型的特征而不需要重新训练。我们提议一种序列-平行混合架构，其包括序列的通用低级特征和平行的高级特征。这是因为许多高级特征是特定的类型而不是通用的，并且与最近的神经科学发现相关，观察人脑中的空间和上下文分离的神经活动。我们的方法提供了独特的功能，即“剪辑”：可以在不需要重新训练的情况下，选择ively关注特定类型的特征。我们的方法可以保持高性能，同时降低推理成本。在一些我们的示例中，可以避免大约75%的参数和35% fewer GMACs（亿乘法积加）操作。这对移动、工业和机器人应用而言非常重要，因为减少参数、计算复杂性和电力消耗是 Paramount。另外，我们的方法还允许处理直接受到高级类型特征的增强或抑制影响，类似于人脑中的选择性注意力机制。这可能对cross-modal应用、使用Semantic prior知识和/或Context-aware处理有 relevance。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Mobile-Privacy-and-Security-A-Face-Skin-Patch-Based-Anti-Spoofing-Approach"><a href="#Enhancing-Mobile-Privacy-and-Security-A-Face-Skin-Patch-Based-Anti-Spoofing-Approach" class="headerlink" title="Enhancing Mobile Privacy and Security: A Face Skin Patch-Based Anti-Spoofing Approach"></a>Enhancing Mobile Privacy and Security: A Face Skin Patch-Based Anti-Spoofing Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04798">http://arxiv.org/abs/2308.04798</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiushi Guo</li>
<li>for: 提高面Recognition系统的安全性，防止假面挡扰。</li>
<li>methods: 基于facial skin patches的方法，使用无隐私信息的图像作为输入，不需要加密或解密。</li>
<li>results: 在多个公共数据集上进行实验，结果表明我们的算法在准确率和速度两个方面具有优势。<details>
<summary>Abstract</summary>
As Facial Recognition System(FRS) is widely applied in areas such as access control and mobile payments due to its convenience and high accuracy. The security of facial recognition is also highly regarded. The Face anti-spoofing system(FAS) for face recognition is an important component used to enhance the security of face recognition systems. Traditional FAS used images containing identity information to detect spoofing traces, however there is a risk of privacy leakage during the transmission and storage of these images. Besides, the encryption and decryption of these privacy-sensitive data takes too long compared to inference time by FAS model. To address the above issues, we propose a face anti-spoofing algorithm based on facial skin patches leveraging pure facial skin patch images as input, which contain no privacy information, no encryption or decryption is needed for these images. We conduct experiments on several public datasets, the results prove that our algorithm has demonstrated superiority in both accuracy and speed.
</details>
<details>
<summary>摘要</summary>
As Facial Recognition System(FRS) 广泛应用于访问控制和移动支付等领域，因为其方便性和高准确率。 Facial recognition 的安全性也备受重视。 Face anti-spoofing system(FAS) 是face recognition 系统中的一个重要组件，用于增强face recognition 系统的安全性。 传统的 FAS 使用包含身份信息的图像检测冒险迹象，但存在隐私泄露的风险在传输和存储这些图像时。 此外，对这些隐私敏感数据的加密和解密也需要很长时间，比推理时间更长。 为解决上述问题，我们提出一种基于 facial skin patches 的面反射验证算法，使用纯度 facial skin patch 图像作为输入，这些图像不含隐私信息，无需加密或解密。 我们在多个公共数据集上进行了实验，结果表明，我们的算法在准确率和速度两个方面具有显著的优势。
</details></li>
</ul>
<hr>
<h2 id="Multi-Scale-Memory-Comparison-for-Zero-Few-Shot-Anomaly-Detection"><a href="#Multi-Scale-Memory-Comparison-for-Zero-Few-Shot-Anomaly-Detection" class="headerlink" title="Multi-Scale Memory Comparison for Zero-&#x2F;Few-Shot Anomaly Detection"></a>Multi-Scale Memory Comparison for Zero-&#x2F;Few-Shot Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04789">http://arxiv.org/abs/2308.04789</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chaoqin Huang, Aofan Jiang, Ya Zhang, Yanfeng Wang</li>
<li>for: 这篇论文主要应用在过程异常检测中，特别是在工业异常检测中。</li>
<li>methods: 本研究提出了一个简单 yet powerful的多尺度记忆比较框架，用于零&#x2F;几shot异常检测。这种方法使用全图像的全球内存储存器，以及对单一物体的个人内存储存器。</li>
<li>results: 本研究在Visual Anomaly and Novelty Detection（VAND）竞赛中的零shot追踪和几shot追踪中获得了4th和2nd名的佳绩。<details>
<summary>Abstract</summary>
Anomaly detection has gained considerable attention due to its broad range of applications, particularly in industrial defect detection. To address the challenges of data collection, researchers have introduced zero-/few-shot anomaly detection techniques that require minimal normal images for each category. However, complex industrial scenarios often involve multiple objects, presenting a significant challenge. In light of this, we propose a straightforward yet powerful multi-scale memory comparison framework for zero-/few-shot anomaly detection. Our approach employs a global memory bank to capture features across the entire image, while an individual memory bank focuses on simplified scenes containing a single object. The efficacy of our method is validated by its remarkable achievement of 4th place in the zero-shot track and 2nd place in the few-shot track of the Visual Anomaly and Novelty Detection (VAND) competition.
</details>
<details>
<summary>摘要</summary>
“异常检测已经受到了广泛关注，特别是在工业缺陷检测方面，因为它们可以应用于各种领域。为了解决数据收集的挑战，研究人员已经提出了零/几个例图 anomaly detection 技术，这些技术需要最小的正常图像。然而，复杂的工业场景经常会包含多个物体，这成为一大挑战。为此，我们提出了一种简单 yet 强大的多级内存比较框架，用于零/几个例图 anomaly detection。我们的方法使用全图内存银行来捕捉图像中的特征，而各个内存银行则专注于单个物体的简化场景。我们的方法的有效性得到了 VAND 比赛中的 zero-shot 轨道和 few-shot 轨道的优秀成绩，排名第四和第二。”Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="PointMBF-A-Multi-scale-Bidirectional-Fusion-Network-for-Unsupervised-RGB-D-Point-Cloud-Registration"><a href="#PointMBF-A-Multi-scale-Bidirectional-Fusion-Network-for-Unsupervised-RGB-D-Point-Cloud-Registration" class="headerlink" title="PointMBF: A Multi-scale Bidirectional Fusion Network for Unsupervised RGB-D Point Cloud Registration"></a>PointMBF: A Multi-scale Bidirectional Fusion Network for Unsupervised RGB-D Point Cloud Registration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04782">http://arxiv.org/abs/2308.04782</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mingzhi Yuan, Kexue Fu, Zhihao Li, Yucong Meng, Manning Wang</li>
<li>for: 本研究旨在提出一种基于学习的点云注册方法，以便更好地利用RGB-D数据，提高注册精度。</li>
<li>methods: 我们提出了一种基于多尺度双向融合的点云注册网络，通过双向融合视觉和 геометрические特征，从多个尺度获取更多的特征，提高对应关系估计的精度。</li>
<li>results: 我们在ScanNet和3DMatch上进行了广泛的实验，结果显示，我们的方法可以达到新的州OF-THE-ART性能水平。<details>
<summary>Abstract</summary>
Point cloud registration is a task to estimate the rigid transformation between two unaligned scans, which plays an important role in many computer vision applications. Previous learning-based works commonly focus on supervised registration, which have limitations in practice. Recently, with the advance of inexpensive RGB-D sensors, several learning-based works utilize RGB-D data to achieve unsupervised registration. However, most of existing unsupervised methods follow a cascaded design or fuse RGB-D data in a unidirectional manner, which do not fully exploit the complementary information in the RGB-D data. To leverage the complementary information more effectively, we propose a network implementing multi-scale bidirectional fusion between RGB images and point clouds generated from depth images. By bidirectionally fusing visual and geometric features in multi-scales, more distinctive deep features for correspondence estimation can be obtained, making our registration more accurate. Extensive experiments on ScanNet and 3DMatch demonstrate that our method achieves new state-of-the-art performance. Code will be released at https://github.com/phdymz/PointMBF
</details>
<details>
<summary>摘要</summary>
点云注册是一个重要的计算机视觉任务，目的是估算两个不同的扫描中的固定变换。在许多计算机视觉应用中，点云注册扮演着关键的角色。先前的学习型工作通常是指监督式注册，它在实际应用中有限制。随着便宜的RGB-D感知器的普及，最近几年有很多学习型工作利用RGB-D数据实现无监督注册。然而，大多数现有的无监督方法采用层次结构或将RGB-D数据在单向方式混合，这并不能充分利用RGB-D数据的补充信息。为了更好地利用RGB-D数据的补充信息，我们提议一种网络实现多尺度粒度的拼接，并将RGB图像和从深度图像生成的点云进行多向拼接。通过多尺度粒度的拼接，可以更好地获得更明确的深度特征，从而提高注册的准确性。我们对ScanNet和3DMatch进行了广泛的实验，结果显示，我们的方法在新的状态艺术性能。代码将在GitHub上发布，请参考https://github.com/phdymz/PointMBF。
</details></li>
</ul>
<hr>
<h2 id="SUnAA-Sparse-Unmixing-using-Archetypal-Analysis"><a href="#SUnAA-Sparse-Unmixing-using-Archetypal-Analysis" class="headerlink" title="SUnAA: Sparse Unmixing using Archetypal Analysis"></a>SUnAA: Sparse Unmixing using Archetypal Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04771">http://arxiv.org/abs/2308.04771</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/behnoodrasti/sunaa">https://github.com/behnoodrasti/sunaa</a></li>
<li>paper_authors: Behnood Rasti, Alexandre Zouaoui, Julien Mairal, Jocelyn Chanussot</li>
<li>for: 这篇论文提出了一种新的稀缺混合技术，使用基本分析（SUnAA）。该技术的目的是将有兴趣的元件混合成为一个稀缺的混合物。</li>
<li>methods: 该技术首先设计了一个基于基本分析的新模型，假设有兴趣的元件是spectral库中提供的元件的几何聚合。然后，提出了一个非对称的最小化问题。与大多数传统稀缺混合方法不同，这里的最小化问题是非对称的。我们使用了活动集算法来逐步最小化优化目标。</li>
<li>results: 对于两个 simulated 数据集，结果表明 SUnAA 的性能比传统和先进的方法更好，具体来说是 signal-to-reconstruction error 下降。此外，SUnAA 还应用于 Cuprite 数据集，并与可用的地质地图进行比较。 Qualitative 评估表明 SUnAA 可以成功估计矿物含量，并在主要矿物的检测方面提供了显著改进。<details>
<summary>Abstract</summary>
This paper introduces a new sparse unmixing technique using archetypal analysis (SUnAA). First, we design a new model based on archetypal analysis. We assume that the endmembers of interest are a convex combination of endmembers provided by a spectral library and that the number of endmembers of interest is known. Then, we propose a minimization problem. Unlike most conventional sparse unmixing methods, here the minimization problem is non-convex. We minimize the optimization objective iteratively using an active set algorithm. Our method is robust to the initialization and only requires the number of endmembers of interest. SUnAA is evaluated using two simulated datasets for which results confirm its better performance over other conventional and advanced techniques in terms of signal-to-reconstruction error. SUnAA is also applied to Cuprite dataset and the results are compared visually with the available geological map provided for this dataset. The qualitative assessment demonstrates the successful estimation of the minerals abundances and significantly improves the detection of dominant minerals compared to the conventional regression-based sparse unmixing methods. The Python implementation of SUnAA can be found at: https://github.com/BehnoodRasti/SUnAA.
</details>
<details>
<summary>摘要</summary>
The performance of SUnAA is evaluated using two simulated datasets, and the results show that it outperforms conventional and advanced techniques in terms of signal-to-reconstruction error. SUnAA is also applied to the Cuprite dataset and the results are compared visually with the available geological map. The qualitative assessment demonstrates the successful estimation of mineral abundances and the improved detection of dominant minerals compared to conventional regression-based sparse unmixing methods.The Python implementation of SUnAA can be found at the following link: <https://github.com/BehnoodRasti/SUnAA>.Translated into Simplified Chinese:这篇论文介绍了一种新的稀疏分解技术，基于体型分析（SUnAA）。该方法假设有兴趣的终端成分是spectral库中的终端成分的 convex combinaison，并且知道终端成分的数量。然后，我们提出了一个非凸优化问题，并使用活动集算法来逐步解决。这种方法对 initialization 非常稳定，只需要终端成分的数量。SUnAA 在两个 simulated 数据集上进行了评估，结果表明它在信号到重建错误方面与其他 conventinal 和高级方法相比，表现更好。此外，SUnAA 还应用于 Cuprite 数据集，并与可用的地质地图进行比较。质量评估表明，SUnAA 成功地估计了矿物质的含量，并在主要矿物质的探测方面提高了可见性。Python 实现的 SUnAA 可以在以下链接中找到：<https://github.com/BehnoodRasti/SUnAA>.
</details></li>
</ul>
<hr>
<h2 id="Objects-do-not-disappear-Video-object-detection-by-single-frame-object-location-anticipation"><a href="#Objects-do-not-disappear-Video-object-detection-by-single-frame-object-location-anticipation" class="headerlink" title="Objects do not disappear: Video object detection by single-frame object location anticipation"></a>Objects do not disappear: Video object detection by single-frame object location anticipation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04770">http://arxiv.org/abs/2308.04770</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/l-kid/video-object-detection-by-location-anticipation">https://github.com/l-kid/video-object-detection-by-location-anticipation</a></li>
<li>paper_authors: Xin Liu, Fatemeh Karimi Nejadasl, Jan C. van Gemert, Olaf Booij, Silvia L. Pintea</li>
<li>for: 提高视频对象检测精度和效率，以及减少注释成本。</li>
<li>methods: 利用视频中对象的连续平滑运动，提高对象检测精度和效率，并减少注释成本。</li>
<li>results: 在四个 dataset 上达到了比state-of-the-art更高的 mean average precision，并且提高了计算效率和注释效率。<details>
<summary>Abstract</summary>
Objects in videos are typically characterized by continuous smooth motion. We exploit continuous smooth motion in three ways. 1) Improved accuracy by using object motion as an additional source of supervision, which we obtain by anticipating object locations from a static keyframe. 2) Improved efficiency by only doing the expensive feature computations on a small subset of all frames. Because neighboring video frames are often redundant, we only compute features for a single static keyframe and predict object locations in subsequent frames. 3) Reduced annotation cost, where we only annotate the keyframe and use smooth pseudo-motion between keyframes. We demonstrate computational efficiency, annotation efficiency, and improved mean average precision compared to the state-of-the-art on four datasets: ImageNet VID, EPIC KITCHENS-55, YouTube-BoundingBoxes, and Waymo Open dataset. Our source code is available at https://github.com/L-KID/Videoobject-detection-by-location-anticipation.
</details>
<details>
<summary>摘要</summary>
视频中的对象通常具有连续的平滑运动。我们利用连续的平滑运动来提高检测精度，并且在三种方面进行利用：1. 使用对象运动作为额外的监督来源，我们通过预测对象位置从静止关键帧中获取。2. 提高效率，只在一小部分帧上进行昂贵的特征计算。因为邻近帧往往是重复的，所以只计算关键帧上的特征，并预测后续帧中对象的位置。3. 降低注释成本，只需注释关键帧，并使用平滑 Pseudo-运动 между关键帧来预测后续帧中对象的位置。我们在四个数据集上进行了比较：ImageNet VID、EPIC KITCHENS-55、YouTube-BoundingBoxes 和 Waymo Open dataset，并demonstrate了计算效率、注释效率以及改进的平均准确率。我们的源代码可以在https://github.com/L-KID/Videoobject-detection-by-location-anticipation上获取。
</details></li>
</ul>
<hr>
<h2 id="FaceSkin-A-Privacy-Preserving-Facial-skin-patch-Dataset-for-multi-Attributes-classification"><a href="#FaceSkin-A-Privacy-Preserving-Facial-skin-patch-Dataset-for-multi-Attributes-classification" class="headerlink" title="FaceSkin: A Privacy Preserving Facial skin patch Dataset for multi Attributes classification"></a>FaceSkin: A Privacy Preserving Facial skin patch Dataset for multi Attributes classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04765">http://arxiv.org/abs/2308.04765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiushi Guo, Shisha Liao</li>
<li>for:  attribute classification, such as age, race, and gender</li>
<li>methods:  utilizes a dataset called FaceSkin, which includes diverse ages and races, as well as synthetic skin-patches from 2D and 3D attack images</li>
<li>results:  effective in attribute classification and has potential for various downstream tasks, such as Face anti-spoofing and Age estimation.<details>
<summary>Abstract</summary>
Human facial skin images contain abundant textural information that can serve as valuable features for attribute classification, such as age, race, and gender. Additionally, facial skin images offer the advantages of easy collection and minimal privacy concerns. However, the availability of well-labeled human skin datasets with a sufficient number of images is limited. To address this issue, we introduce a dataset called FaceSkin, which encompasses a diverse range of ages and races. Furthermore, to broaden the application scenarios, we incorporate synthetic skin-patches obtained from 2D and 3D attack images, including printed paper, replays, and 3D masks. We evaluate the FaceSkin dataset across distinct categories and present experimental results demonstrating its effectiveness in attribute classification, as well as its potential for various downstream tasks, such as Face anti-spoofing and Age estimation.
</details>
<details>
<summary>摘要</summary>
人脸皮肤图像含有丰富的文本特征，可以作为年龄、种族和性别等特征的有价值特征。此外，人脸皮肤图像具有易收集和低隐私问题的优点。然而，有限的人脸皮肤数据集的可用性是一个问题。为解决这个问题，我们介绍了一个名为FaceSkin的数据集，该数据集包含多个年龄和种族的多样化图像。此外，为扩展应用场景，我们添加了由2D和3D攻击图像生成的人工皮肤质感补充。我们在不同类别上评估了FaceSkin数据集，并提供了对attribute分类、Face anti-spoofing和年龄估计等下游任务的实验结果，以及其潜在应用场景。
</details></li>
</ul>
<hr>
<h2 id="SAfER-Layer-Level-Sensitivity-Assessment-for-Efficient-and-Robust-Neural-Network-Inference"><a href="#SAfER-Layer-Level-Sensitivity-Assessment-for-Efficient-and-Robust-Neural-Network-Inference" class="headerlink" title="SAfER: Layer-Level Sensitivity Assessment for Efficient and Robust Neural Network Inference"></a>SAfER: Layer-Level Sensitivity Assessment for Efficient and Robust Neural Network Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04753">http://arxiv.org/abs/2308.04753</a></li>
<li>repo_url: None</li>
<li>paper_authors: Edouard Yvinec, Arnaud Dapogny, Kevin Bailly</li>
<li>for: 这个论文的目的是研究深度神经网络（DNN）的行为和决策的原因。</li>
<li>methods: 这篇论文使用了DNN归因方法，以研究DNN的输入和预测之间的关系。归因方法可以高亮最重要的权重或神经元，从而更有效地选择可以被剪辑的权重。</li>
<li>results: 本论文提出了一种新的方法来评估DNN层的重要性，并创建了一个新的数据集来评估这种方法。研究表明，DNN层的重要性与层之间的相互作用有关，并且可以通过层层的权重融合来评估层的重要性。这些结论可以用于提高DNN的效率（通过剪辑和量化）以及增强DNN的Robustness（例如硬件故障）。<details>
<summary>Abstract</summary>
Deep neural networks (DNNs) demonstrate outstanding performance across most computer vision tasks. Some critical applications, such as autonomous driving or medical imaging, also require investigation into their behavior and the reasons behind the decisions they make. In this vein, DNN attribution consists in studying the relationship between the predictions of a DNN and its inputs. Attribution methods have been adapted to highlight the most relevant weights or neurons in a DNN, allowing to more efficiently select which weights or neurons can be pruned. However, a limitation of these approaches is that weights are typically compared within each layer separately, while some layers might appear as more critical than others. In this work, we propose to investigate DNN layer importance, i.e. to estimate the sensitivity of the accuracy w.r.t. perturbations applied at the layer level. To do so, we propose a novel dataset to evaluate our method as well as future works. We benchmark a number of criteria and draw conclusions regarding how to assess DNN layer importance and, consequently, how to budgetize layers for increased DNN efficiency (with applications for DNN pruning and quantization), as well as robustness to hardware failure (e.g. bit swaps).
</details>
<details>
<summary>摘要</summary>
In this work, we propose to investigate DNN layer importance, i.e., to estimate the sensitivity of the accuracy with respect to perturbations applied at the layer level. To do so, we propose a novel dataset to evaluate our method as well as future works. We benchmark a number of criteria and draw conclusions regarding how to assess DNN layer importance and, consequently, how to budgetize layers for increased DNN efficiency (with applications for DNN pruning and quantization), as well as robustness to hardware failure (e.g., bit swaps).
</details></li>
</ul>
<hr>
<h2 id="TextPainter-Multimodal-Text-Image-Generation-with-Visual-harmony-and-Text-comprehension-for-Poster-Design"><a href="#TextPainter-Multimodal-Text-Image-Generation-with-Visual-harmony-and-Text-comprehension-for-Poster-Design" class="headerlink" title="TextPainter: Multimodal Text Image Generation with Visual-harmony and Text-comprehension for Poster Design"></a>TextPainter: Multimodal Text Image Generation with Visual-harmony and Text-comprehension for Poster Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04733">http://arxiv.org/abs/2308.04733</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifan Gao, Jinpeng Lin, Min Zhou, Chuanbin Liu, Hongtao Xie, Tiezheng Ge, Yuning Jiang</li>
<li>for: This paper is written for researchers and practitioners in the field of text design and multimodal processing, with a focus on generating visually-and-semantically-harmonious text images for posters.</li>
<li>methods: The paper proposes a novel multimodal approach called TextPainter, which leverages contextual visual information and corresponding text semantics to generate text images. The approach takes the global-local background image as a hint of style and guides the text image generation with visual harmony. Additionally, the paper introduces a text comprehension module to achieve both sentence-level and word-level style variations.</li>
<li>results: The paper presents extensive quantitative and qualitative experiments that demonstrate the effectiveness of TextPainter in generating visually-and-semantically-harmonious text images for posters. The results show that TextPainter can generate high-quality text images that are both aesthetically pleasing and semantically consistent with the context.<details>
<summary>Abstract</summary>
Text design is one of the most critical procedures in poster design, as it relies heavily on the creativity and expertise of humans to design text images considering the visual harmony and text-semantic. This study introduces TextPainter, a novel multimodal approach that leverages contextual visual information and corresponding text semantics to generate text images. Specifically, TextPainter takes the global-local background image as a hint of style and guides the text image generation with visual harmony. Furthermore, we leverage the language model and introduce a text comprehension module to achieve both sentence-level and word-level style variations. Besides, we construct the PosterT80K dataset, consisting of about 80K posters annotated with sentence-level bounding boxes and text contents. We hope this dataset will pave the way for further research on multimodal text image generation. Extensive quantitative and qualitative experiments demonstrate that TextPainter can generate visually-and-semantically-harmonious text images for posters.
</details>
<details>
<summary>摘要</summary>
文本设计是海报设计中最重要的过程之一，因为它几乎完全依赖人类的创造力和专业知识来设计文本图像，考虑到视觉和文本 semantics。本研究介绍了 TextPainter，一种新的多Modal方法，利用上下文ual visual information和相应的文本 semantics来生成文本图像。具体来说，TextPainter 利用全局-局部背景图像作为风格的提示，引导文本图像生成，同时还利用语言模型和引入文本理解模块，实现句子级和单词级样式变化。此外，我们构建了 PosterT80K 数据集，包含约80K 海报，每个海报都有 sentence-level  bounding box 和文本内容。我们希望这个数据集能够推动未来的多Modal文本图像生成研究。EXTENSIVE 量化和质量实验表明，TextPainter 可以生成视觉和semantically 和谐的文本图像。
</details></li>
</ul>
<hr>
<h2 id="Self-supervised-Learning-of-Rotation-invariant-3D-Point-Set-Features-using-Transformer-and-its-Self-distillation"><a href="#Self-supervised-Learning-of-Rotation-invariant-3D-Point-Set-Features-using-Transformer-and-its-Self-distillation" class="headerlink" title="Self-supervised Learning of Rotation-invariant 3D Point Set Features using Transformer and its Self-distillation"></a>Self-supervised Learning of Rotation-invariant 3D Point Set Features using Transformer and its Self-distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04725">http://arxiv.org/abs/2308.04725</a></li>
<li>repo_url: None</li>
<li>paper_authors: Takahiko Furuya, Zhoujie Chen, Ryutarou Ohbuchi, Zhenzhong Kuang</li>
<li>for: 本研究提出了一种自然语言处理框架，用于从大量未标注的3D点云数据中学习精准的3D物体特征。</li>
<li>methods: 我们提出了一种自我超vised学习框架，使用多个全球尺度的Token来保持3D物体的空间布局，并使用自我注意机制来细化Token并将其汇聚成一个表示3D点云的旋转不变特征。</li>
<li>results: 我们的算法可以学习精准的3D点云特征，并且比现有的自然语言处理算法更加精准。我们还提出了一种 combining多种数据增强技术来增加训练数据的多样性，以便更好地学习3D点云特征。<details>
<summary>Abstract</summary>
Invariance against rotations of 3D objects is an important property in analyzing 3D point set data. Conventional 3D point set DNNs having rotation invariance typically obtain accurate 3D shape features via supervised learning by using labeled 3D point sets as training samples. However, due to the rapid increase in 3D point set data and the high cost of labeling, a framework to learn rotation-invariant 3D shape features from numerous unlabeled 3D point sets is required. This paper proposes a novel self-supervised learning framework for acquiring accurate and rotation-invariant 3D point set features at object-level. Our proposed lightweight DNN architecture decomposes an input 3D point set into multiple global-scale regions, called tokens, that preserve the spatial layout of partial shapes composing the 3D object. We employ a self-attention mechanism to refine the tokens and aggregate them into an expressive rotation-invariant feature per 3D point set. Our DNN is effectively trained by using pseudo-labels generated by a self-distillation framework. To facilitate the learning of accurate features, we propose to combine multi-crop and cut-mix data augmentation techniques to diversify 3D point sets for training. Through a comprehensive evaluation, we empirically demonstrate that, (1) existing rotation-invariant DNN architectures designed for supervised learning do not necessarily learn accurate 3D shape features under a self-supervised learning scenario, and (2) our proposed algorithm learns rotation-invariant 3D point set features that are more accurate than those learned by existing algorithms. Code will be available at https://github.com/takahikof/RIPT_SDMM
</details>
<details>
<summary>摘要</summary>
“三维点云集数据中的不变性对三维物体的分析是非常重要的属性。传统的三维点云集DNN通常通过监督学习使用标签的三维点云集来获取精确的三维形状特征。但由于三维点云集数据的快速增长和标签成本的高昂，需要一个框架可以从大量未标签的三维点云集中学习精确的三维形状特征。本文提出了一个新的自我监督学习框架，可以从许多未标签的三维点云集中学习精确且不变性的三维形状特征。我们的提案的轻量级DNN架构可以将输入的三维点云集分解为多个全球缩尺的区域，称为“token”，这些区域可以保持三维物体中的空间布局。我们还使用自我注意力机制来精确地调整token，并将其聚合为一个表达三维点云集不变性的特征。我们的DNN可以通过使用自我养分析框架生成的pseudo-labels进行有效地训练。为了让学习精确的特征，我们提议使用多个拼接和切割资料增强技术来让训练集中的3D点云集更加多样化。经过实验验证，我们证明了以下两点：（1）现有的不变性DNN架构，设计来进行监督学习情况下，不一定会学习精确的三维形状特征；（2）我们的提案的算法可以从未标签的三维点云集中学习精确且不变性的三维形状特征，并且比现有的算法更精确。代码将会在https://github.com/takahikof/RIPT_SDMM中公开。”
</details></li>
</ul>
<hr>
<h2 id="Continual-Road-Scene-Semantic-Segmentation-via-Feature-Aligned-Symmetric-Multi-Modal-Network"><a href="#Continual-Road-Scene-Semantic-Segmentation-via-Feature-Aligned-Symmetric-Multi-Modal-Network" class="headerlink" title="Continual Road-Scene Semantic Segmentation via Feature-Aligned Symmetric Multi-Modal Network"></a>Continual Road-Scene Semantic Segmentation via Feature-Aligned Symmetric Multi-Modal Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04702">http://arxiv.org/abs/2308.04702</a></li>
<li>repo_url: None</li>
<li>paper_authors: Francesco Barbato, Elena Camuffo, Simone Milani, Pietro Zanuttigh</li>
<li>for: 这个研究旨在探讨多modal semantic segmentation的紧密结构和Symmetric information-sharing scheme，以实现当一个输入模式缺失时仍能正确显示结果。</li>
<li>methods: 本研究使用紧密结构和Symmetric information-sharing scheme，实现多modal semantic segmentation的稳定性和可靠性。</li>
<li>results: 在SemanticKITTI dataset上进行评估，与 closest competitor 进行比较，得到了良好的结果。 此外，还引入了一个特殊的 continual learning 方案，在 class-incremental continual learning enario中证明了方法的有效性。<details>
<summary>Abstract</summary>
State-of-the-art multimodal semantic segmentation approaches combining LiDAR and color data are usually designed on top of asymmetric information-sharing schemes and assume that both modalities are always available. Regrettably, this strong assumption may not hold in real-world scenarios, where sensors are prone to failure or can face adverse conditions (night-time, rain, fog, etc.) that make the acquired information unreliable. Moreover, these architectures tend to fail in continual learning scenarios. In this work, we re-frame the task of multimodal semantic segmentation by enforcing a tightly-coupled feature representation and a symmetric information-sharing scheme, which allows our approach to work even when one of the input modalities is missing. This makes our model reliable even in safety-critical settings, as is the case of autonomous driving. We evaluate our approach on the SemanticKITTI dataset, comparing it with our closest competitor. We also introduce an ad-hoc continual learning scheme and show results in a class-incremental continual learning scenario that prove the effectiveness of the approach also in this setting.
</details>
<details>
<summary>摘要</summary>
现代多模态Semantic segmentation方法通常基于不均衡信息分享模式和假设所有感知数据都可用。可惜，这强制假设在实际场景中可能不成立，感知器容易出现故障或面临不良天气（夜晚、雨、雾等），导致获取到的信息不可靠。此外，这些架构在连续学习场景下也存在问题。在这项工作中，我们重新定义多模态Semantic segmentation任务，强制实施紧密相关的特征表示和 symmetrical information-sharing模式，使我们的方法能够在一个模式缺失时仍然可靠。这使我们的模型在安全关键的应用场景中可靠，如自动驾驶。我们在SemanticKITTI数据集上评估我们的方法，与 closest competitor进行比较。我们还引入了特殊的连续学习方案，并在类增量连续学习场景中展示结果，证明了我们的方法在这种场景中的有效性。
</details></li>
</ul>
<hr>
<h2 id="GIFD-A-Generative-Gradient-Inversion-Method-with-Feature-Domain-Optimization"><a href="#GIFD-A-Generative-Gradient-Inversion-Method-with-Feature-Domain-Optimization" class="headerlink" title="GIFD: A Generative Gradient Inversion Method with Feature Domain Optimization"></a>GIFD: A Generative Gradient Inversion Method with Feature Domain Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04699">http://arxiv.org/abs/2308.04699</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ffhibnese/gifd">https://github.com/ffhibnese/gifd</a></li>
<li>paper_authors: Hao Fang, Bin Chen, Xuan Wang, Zhi Wang, Shu-Tao Xia</li>
<li>For: This paper proposes a method to protect the privacy of clients in Federated Learning (FL) by defending against gradient inversion attacks.* Methods: The proposed method, called Gradient Inversion over Feature Domains (GIFD), disassembles the Generative Adversarial Network (GAN) model and searches for feature domains in the intermediate layers. It also includes a regularizer to avoid unreal image generation.* Results: The proposed method achieves pixel-level reconstruction and outperforms existing methods. It also demonstrates great generalizability under different defense strategy settings and batch sizes.Here’s the simplified Chinese text:</li>
<li>for: 这篇论文目的是为了在联合学习（Federated Learning，FL）中保护客户端隐私，并对梯度反向攻击进行防御。</li>
<li>methods: 提议的方法是Gradient Inversion over Feature Domains（GIFD），它将GAN模型分解成多个层次结构，并在这些层次结构中搜索特征领域。它还包括一个正则项来避免生成不实际的图像。</li>
<li>results: 提议的方法可以实现像素级重建，并超越现有的方法。它还在不同的防御策略设置和批处大小下展现出了优秀的一致性。<details>
<summary>Abstract</summary>
Federated Learning (FL) has recently emerged as a promising distributed machine learning framework to preserve clients' privacy, by allowing multiple clients to upload the gradients calculated from their local data to a central server. Recent studies find that the exchanged gradients also take the risk of privacy leakage, e.g., an attacker can invert the shared gradients and recover sensitive data against an FL system by leveraging pre-trained generative adversarial networks (GAN) as prior knowledge. However, performing gradient inversion attacks in the latent space of the GAN model limits their expression ability and generalizability. To tackle these challenges, we propose \textbf{G}radient \textbf{I}nversion over \textbf{F}eature \textbf{D}omains (GIFD), which disassembles the GAN model and searches the feature domains of the intermediate layers. Instead of optimizing only over the initial latent code, we progressively change the optimized layer, from the initial latent space to intermediate layers closer to the output images. In addition, we design a regularizer to avoid unreal image generation by adding a small ${l_1}$ ball constraint to the searching range. We also extend GIFD to the out-of-distribution (OOD) setting, which weakens the assumption that the training sets of GANs and FL tasks obey the same data distribution. Extensive experiments demonstrate that our method can achieve pixel-level reconstruction and is superior to the existing methods. Notably, GIFD also shows great generalizability under different defense strategy settings and batch sizes.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 最近 emerge as a promising distributed machine learning framework to preserve clients' privacy, by allowing multiple clients to upload the gradients calculated from their local data to a central server. recent studies find that the exchanged gradients also take the risk of privacy leakage, e.g., an attacker can invert the shared gradients and recover sensitive data against an FL system by leveraging pre-trained generative adversarial networks (GAN) as prior knowledge. however, performing gradient inversion attacks in the latent space of the GAN model limits their expression ability and generalizability. to tackle these challenges, we propose 《G》radient 《I》nversion over 《F》eature 《D》omains (GIFD), which disassembles the GAN model and searches the feature domains of the intermediate layers. instead of optimizing only over the initial latent code, we progressively change the optimized layer, from the initial latent space to intermediate layers closer to the output images. in addition, we design a regularizer to avoid unreal image generation by adding a small ${l_1}$ ball constraint to the searching range. we also extend GIFD to the out-of-distribution (OOD) setting, which weakens the assumption that the training sets of GANs and FL tasks obey the same data distribution. extensive experiments demonstrate that our method can achieve pixel-level reconstruction and is superior to the existing methods. notably, GIFD also shows great generalizability under different defense strategy settings and batch sizes.
</details></li>
</ul>
<hr>
<h2 id="Score-Priors-Guided-Deep-Variational-Inference-for-Unsupervised-Real-World-Single-Image-Denoising"><a href="#Score-Priors-Guided-Deep-Variational-Inference-for-Unsupervised-Real-World-Single-Image-Denoising" class="headerlink" title="Score Priors Guided Deep Variational Inference for Unsupervised Real-World Single Image Denoising"></a>Score Priors Guided Deep Variational Inference for Unsupervised Real-World Single Image Denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04682">http://arxiv.org/abs/2308.04682</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jun Cheng, Tao Liu, Shan Tan</li>
<li>for: 这个论文主要关注的是实际世界单一图像去噪的问题。</li>
<li>methods: 该论文提出了一种基于深度泛化推敲的构思，即ScoreDVI，以解决实际世界单一图像去噪的问题。这种方法利用了易于存取的最小MSE非-$i.i.d$ Gaussian推敲器和泛化推敲样本，从而简化了 posterior 推敲的过程。</li>
<li>results: 该论文的方法比其他单一图像基于的实际世界去噪方法表现更好，并且与 dataset-based 无监督方法相似。<details>
<summary>Abstract</summary>
Real-world single image denoising is crucial and practical in computer vision. Bayesian inversions combined with score priors now have proven effective for single image denoising but are limited to white Gaussian noise. Moreover, applying existing score-based methods for real-world denoising requires not only the explicit train of score priors on the target domain but also the careful design of sampling procedures for posterior inference, which is complicated and impractical. To address these limitations, we propose a score priors-guided deep variational inference, namely ScoreDVI, for practical real-world denoising. By considering the deep variational image posterior with a Gaussian form, score priors are extracted based on easily accessible minimum MSE Non-$i.i.d$ Gaussian denoisers and variational samples, which in turn facilitate optimizing the variational image posterior. Such a procedure adaptively applies cheap score priors to denoising. Additionally, we exploit a Non-$i.i.d$ Gaussian mixture model and variational noise posterior to model the real-world noise. This scheme also enables the pixel-wise fusion of multiple image priors and variational image posteriors. Besides, we develop a noise-aware prior assignment strategy that dynamically adjusts the weight of image priors in the optimization. Our method outperforms other single image-based real-world denoising methods and achieves comparable performance to dataset-based unsupervised methods.
</details>
<details>
<summary>摘要</summary>
By considering the deep variational image posterior with a Gaussian form, score priors are extracted based on easily accessible minimum MSE Non-$i.i.d$ Gaussian denoisers and variational samples, which facilitate optimizing the variational image posterior. This procedure adaptively applies cheap score priors to denoising. Additionally, we exploit a Non-$i.i.d$ Gaussian mixture model and variational noise posterior to model the real-world noise. This scheme enables the pixel-wise fusion of multiple image priors and variational image posteriors.Moreover, we develop a noise-aware prior assignment strategy that dynamically adjusts the weight of image priors in the optimization. Our method outperforms other single image-based real-world denoising methods and achieves comparable performance to dataset-based unsupervised methods.Translation notes:* "Real-world" is translated as "实际世界" (shíjiè shìjì)* "Single image denoising" is translated as "单图干涂除" (dan tú gān bù)* "Bayesian inversions" is translated as " bayesian 逆转" (bài jiàn zhòng)* "Score priors" is translated as "Score 先验" (mù xiān yǐ)* "Non-$i.i.d$ Gaussian denoisers" is translated as "非-$i.i.d$  Gaussian 干涂除器" (fēi-$i.i.d$ Gaussian gān bù zhèng)* "Variational image posterior" is translated as "变分图 posterior" (biàn fēn tú zhèng)* "Pixel-wise fusion" is translated as "像素级融合" (xiàng xiàng jí yù)* "Noise-aware prior assignment" is translated as "针对噪声的先验分配" (jiào duì fāng xiàng zhòng yì)
</details></li>
</ul>
<hr>
<h2 id="A-General-Implicit-Framework-for-Fast-NeRF-Composition-and-Rendering"><a href="#A-General-Implicit-Framework-for-Fast-NeRF-Composition-and-Rendering" class="headerlink" title="A General Implicit Framework for Fast NeRF Composition and Rendering"></a>A General Implicit Framework for Fast NeRF Composition and Rendering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04669">http://arxiv.org/abs/2308.04669</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyu Gao, Ziyi Yang, Yunlu Zhao, Yuxiang Sun, Xiaogang Jin, Changqing Zou</li>
<li>for: 这篇论文主要是为了提高NeRF对象的速度compositing，使其能够在实时中进行多个NeRF对象的组合和预览。</li>
<li>methods: 该方法使用了一种新的表面表示方式 called Neural Depth Fields (NeDF), 它可以快速确定物体之间的空间关系，并且可以使用抽象光源来渲染动态阴影。</li>
<li>results: 该方法可以快速地进行NeRF对象的组合和预览，并且可以在实时中进行多个NeRF对象的组合和预览。此外，该方法还可以作为现有NeRF作品的预览插件使用。<details>
<summary>Abstract</summary>
A variety of Neural Radiance Fields (NeRF) methods have recently achieved remarkable success in high render speed. However, current accelerating methods are specialized and incompatible with various implicit methods, preventing real-time composition over various types of NeRF works. Because NeRF relies on sampling along rays, it is possible to provide general guidance for acceleration. To that end, we propose a general implicit pipeline for composing NeRF objects quickly. Our method enables the casting of dynamic shadows within or between objects using analytical light sources while allowing multiple NeRF objects to be seamlessly placed and rendered together with any arbitrary rigid transformations. Mainly, our work introduces a new surface representation known as Neural Depth Fields (NeDF) that quickly determines the spatial relationship between objects by allowing direct intersection computation between rays and implicit surfaces. It leverages an intersection neural network to query NeRF for acceleration instead of depending on an explicit spatial structure.Our proposed method is the first to enable both the progressive and interactive composition of NeRF objects. Additionally, it also serves as a previewing plugin for a range of existing NeRF works.
</details>
<details>
<summary>摘要</summary>
各种神经辐射场（NeRF）方法在最近几年内取得了显著的成功，但现有的加速方法具有特定的限制，无法与各种隐式方法兼容，因此在实时组合不同类型的 NeRF 作品中存在限制。由于 NeRF 通过抽象线段进行抽象，因此可以提供一般的指导方针 для加速。为了实现这一目标，我们提议一种通用的隐式管道，用于快速组合 NeRF 对象。我们的方法允许在动态阴影中投射analytical 光源，并允许多个 NeRF 对象在任意的旋转变换下进行平铺渲染。主要地，我们的工作引入了一种新的表面表示方式，称为神经深度场（NeDF），它快速确定了物体之间的空间关系，通过直接计算抽象线段与隐式表面之间的交点。它利用了交叉神经网络来查询 NeRF 的加速而不是依赖于显式空间结构。我们的提议方法是首个允许 NeRF 对象进行进度式和交互式组合。此外，它还可以作为许多现有 NeRF 作品的预览插件。
</details></li>
</ul>
<hr>
<h2 id="Classification-of-lung-cancer-subtypes-on-CT-images-with-synthetic-pathological-priors"><a href="#Classification-of-lung-cancer-subtypes-on-CT-images-with-synthetic-pathological-priors" class="headerlink" title="Classification of lung cancer subtypes on CT images with synthetic pathological priors"></a>Classification of lung cancer subtypes on CT images with synthetic pathological priors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04663">http://arxiv.org/abs/2308.04663</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wentao Zhu, Yuan Jin, Gege Ma, Geng Chen, Jan Egger, Shaoting Zhang, Dimitris N. Metaxas</li>
<li>for: 针对肺癌分型的精准诊断，以提高后续治疗和诊断管理的重要性。</li>
<li>methods: 提出了自生成混合特征网络（SGHF-Net），使用深度神经网络 Quantitatively 映射跨模态关系，从 CT 图像中提取与病理图像相关的 “金标准” 信息，并结合 радиологиraphic 特征提取模块（RFEM），实现多Modal 特征拼接框架，以生成更指示性和特定的病理相关特征，最终输出更准确的预测结果。</li>
<li>results: 对于肺癌分型的类型，SGHF-Net 模型比 SOTA 模型具有显著的高精准度，包括准确率（ACC）、曲线面积（AUC）和 F1 分数等指标均有显著提高。<details>
<summary>Abstract</summary>
The accurate diagnosis on pathological subtypes for lung cancer is of significant importance for the follow-up treatments and prognosis managements. In this paper, we propose self-generating hybrid feature network (SGHF-Net) for accurately classifying lung cancer subtypes on computed tomography (CT) images. Inspired by studies stating that cross-scale associations exist in the image patterns between the same case's CT images and its pathological images, we innovatively developed a pathological feature synthetic module (PFSM), which quantitatively maps cross-modality associations through deep neural networks, to derive the "gold standard" information contained in the corresponding pathological images from CT images. Additionally, we designed a radiological feature extraction module (RFEM) to directly acquire CT image information and integrated it with the pathological priors under an effective feature fusion framework, enabling the entire classification model to generate more indicative and specific pathologically related features and eventually output more accurate predictions. The superiority of the proposed model lies in its ability to self-generate hybrid features that contain multi-modality image information based on a single-modality input. To evaluate the effectiveness, adaptability, and generalization ability of our model, we performed extensive experiments on a large-scale multi-center dataset (i.e., 829 cases from three hospitals) to compare our model and a series of state-of-the-art (SOTA) classification models. The experimental results demonstrated the superiority of our model for lung cancer subtypes classification with significant accuracy improvements in terms of accuracy (ACC), area under the curve (AUC), and F1 score.
</details>
<details>
<summary>摘要</summary>
精准诊断lung cancer的临床亚型是诊断和治疗评估中的关键因素。本文提出一种自生成混合特征网络（SGHF-Net），用于精准分类lung cancer亚型的计算机 Tomatoes（CT）影像。研究表明，同一个患者的CT影像和病理图像之间存在跨Modal Association，我们采用Pathological Feature Synthetic Module（PFSM），通过深度神经网络，将CT影像中的病理信息转化为"标准"信息，并与放射学特征提取模块（RFEM）集成，以实现更加指示和特定的病理相关特征，最终输出更高精度的预测结果。我们的模型的优势在于，可以基于单模态输入生成多Modal特征，以提高分类精度。为评估我们的模型的有效性、适应性和普遍性，我们在三家医院的大规模多中心数据集（829例）上进行了广泛的实验，与一系列现有的SOTA分类模型进行比较。实验结果表明，我们的模型在lung cancer亚型分类中表现出了显著的高精度，ACC、AUC和F1分数均达到了SOTA水平。
</details></li>
</ul>
<hr>
<h2 id="Which-Tokens-to-Use-Investigating-Token-Reduction-in-Vision-Transformers"><a href="#Which-Tokens-to-Use-Investigating-Token-Reduction-in-Vision-Transformers" class="headerlink" title="Which Tokens to Use? Investigating Token Reduction in Vision Transformers"></a>Which Tokens to Use? Investigating Token Reduction in Vision Transformers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04657">http://arxiv.org/abs/2308.04657</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/JoakimHaurum/TokenReduction">https://github.com/JoakimHaurum/TokenReduction</a></li>
<li>paper_authors: Joakim Bruslund Haurum, Sergio Escalera, Graham W. Taylor, Thomas B. Moeslund</li>
<li>For: 这 paper 的目的是为了理解不同的token reduction方法在不同的图像分类任务中的减少模式。* Methods: 这 paper 使用了10种不同的token reduction方法，并在四个图像分类dataset上进行了系统比较。* Results: 研究发现，Top-K pruning方法是一个意外的强大基线。通过深入分析不同方法的减少模式，发现减少模式通常不是随机变化的，pruning-based方法的减少模式与固定圆形模式不同，并且在不同的分类任务中减少模式的相似程度是一个中等至强的代理。Here’s the English version of the information for reference:* For: The purpose of this paper is to understand the reduction patterns of different token reduction methods on different image classification tasks.* Methods: The paper uses 10 different token reduction methods and compares them systematically on four image classification datasets.* Results: The study finds that the Top-K pruning method is a surprisingly strong baseline. Through in-depth analysis of the different methods, it is found that the reduction patterns are not consistent when varying the capacity of the backbone model, the reduction patterns of pruning-based methods significantly differ from fixed radial patterns, and the reduction patterns of pruning-based methods are correlated across classification datasets. Finally, it is reported that the similarity of reduction patterns is a moderate-to-strong proxy for model performance. The project page is available at <a target="_blank" rel="noopener" href="https://vap.aau.dk/tokens">https://vap.aau.dk/tokens</a>.<details>
<summary>Abstract</summary>
Since the introduction of the Vision Transformer (ViT), researchers have sought to make ViTs more efficient by removing redundant information in the processed tokens. While different methods have been explored to achieve this goal, we still lack understanding of the resulting reduction patterns and how those patterns differ across token reduction methods and datasets. To close this gap, we set out to understand the reduction patterns of 10 different token reduction methods using four image classification datasets. By systematically comparing these methods on the different classification tasks, we find that the Top-K pruning method is a surprisingly strong baseline. Through in-depth analysis of the different methods, we determine that: the reduction patterns are generally not consistent when varying the capacity of the backbone model, the reduction patterns of pruning-based methods significantly differ from fixed radial patterns, and the reduction patterns of pruning-based methods are correlated across classification datasets. Finally we report that the similarity of reduction patterns is a moderate-to-strong proxy for model performance. Project page at https://vap.aau.dk/tokens.
</details>
<details>
<summary>摘要</summary>
自 introduce Vision Transformer (ViT) 以来，研究人员努力减少 ViT 中处理符号中的重复信息，以提高模型效率。然而，不同的方法在实现这个目标上有所不同，我们仍然缺乏对减少模型的理解和不同减少方法和数据集之间的差异。为了填补这个空白，我们决心了解不同减少方法在四个图像分类任务中的减少模式。我们系统地比较了这些方法，并发现：1. 顶峰权重剪除法是一个意外的强基线。2. 随着后向模型的容量变化，减少模式不一致。3. 剪除基于方法的减少模式与固定圆形减少模式显著不同。4. 剪除基于方法的减少模式在不同的分类任务中呈 corrleation 关系。5. 减少模式之间的相似性是模型性能的中等到强的代表。更多信息请访问我们的项目页面：<https://vap.aau.dk/tokens>。
</details></li>
</ul>
<hr>
<h2 id="Assessing-the-performance-of-deep-learning-based-models-for-prostate-cancer-segmentation-using-uncertainty-scores"><a href="#Assessing-the-performance-of-deep-learning-based-models-for-prostate-cancer-segmentation-using-uncertainty-scores" class="headerlink" title="Assessing the performance of deep learning-based models for prostate cancer segmentation using uncertainty scores"></a>Assessing the performance of deep learning-based models for prostate cancer segmentation using uncertainty scores</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04653">http://arxiv.org/abs/2308.04653</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pablo Cesar Quihui-Rubio, Daniel Flores-Araiza, Gilberto Ochoa-Ruiz, Miguel Gonzalez-Mendoza, Christian Mata</li>
<li>for: 这个研究旨在比较深度学习方法用于脊梁磁共振图像中的不确定性分 segmentation和评估。</li>
<li>methods: 这个研究使用了七种不同的 U-Net 架构，其中包括 Monte Carlo dropout 的扩展。</li>
<li>results: 这个研究发现，使用 Attention R2U-Net 模型可以获得最高的 Mean Intersection over Union (IoU) 和 Dice Similarity Coefficient (DSC) 值，它可以准确地 segmentation所有区域，并且在transition zone和肿瘤边界处具有最低的uncertainty值。<details>
<summary>Abstract</summary>
This study focuses on comparing deep learning methods for the segmentation and quantification of uncertainty in prostate segmentation from MRI images. The aim is to improve the workflow of prostate cancer detection and diagnosis. Seven different U-Net-based architectures, augmented with Monte-Carlo dropout, are evaluated for automatic segmentation of the central zone, peripheral zone, transition zone, and tumor, with uncertainty estimation. The top-performing model in this study is the Attention R2U-Net, achieving a mean Intersection over Union (IoU) of 76.3% and Dice Similarity Coefficient (DSC) of 85% for segmenting all zones. Additionally, Attention R2U-Net exhibits the lowest uncertainty values, particularly in the boundaries of the transition zone and tumor, when compared to the other models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Long-Distance-Gesture-Recognition-using-Dynamic-Neural-Networks"><a href="#Long-Distance-Gesture-Recognition-using-Dynamic-Neural-Networks" class="headerlink" title="Long-Distance Gesture Recognition using Dynamic Neural Networks"></a>Long-Distance Gesture Recognition using Dynamic Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04643">http://arxiv.org/abs/2308.04643</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shubhang Bhatnagar, Sharath Gopal, Narendra Ahuja, Liu Ren</li>
<li>for: 本研究旨在提出一种新的、准确和高效的手势识别方法，可以在更远的距离上识别手势。</li>
<li>methods: 该方法使用动态神经网络选择手势包含的空间区域中的特征进行进一步处理，以提高识别精度和计算效率。</li>
<li>results: 在LD-ConGR长距离数据集上，该方法与前一代方法相比，在识别精度和计算效率两个方面均有显著提高。<details>
<summary>Abstract</summary>
Gestures form an important medium of communication between humans and machines. An overwhelming majority of existing gesture recognition methods are tailored to a scenario where humans and machines are located very close to each other. This short-distance assumption does not hold true for several types of interactions, for example gesture-based interactions with a floor cleaning robot or with a drone. Methods made for short-distance recognition are unable to perform well on long-distance recognition due to gestures occupying only a small portion of the input data. Their performance is especially worse in resource constrained settings where they are not able to effectively focus their limited compute on the gesturing subject. We propose a novel, accurate and efficient method for the recognition of gestures from longer distances. It uses a dynamic neural network to select features from gesture-containing spatial regions of the input sensor data for further processing. This helps the network focus on features important for gesture recognition while discarding background features early on, thus making it more compute efficient compared to other techniques. We demonstrate the performance of our method on the LD-ConGR long-distance dataset where it outperforms previous state-of-the-art methods on recognition accuracy and compute efficiency.
</details>
<details>
<summary>摘要</summary>
人机之间的姿势成为通信的重要媒体。现有的大多数姿势识别方法都是为短距离场景设计的，而这个假设不符合一些交互，如floor cleaning robot或者飞行器的姿势交互。这些短距离的方法在长距离识别中表现不佳，因为姿势只占输入数据中的一小部分。它们在有限的计算资源下表现特别糟糕，无法有效地专注于捕捉姿势表达者。我们提出了一种新的、准确和高效的姿势识别方法，使用动态神经网络选择 gesture-containing 的空间区域输入感知器数据进行进一步处理。这帮助网络在执行姿势识别时选择重要的特征，而不是浪费计算资源于背景特征。我们在 LD-ConGR 长距离数据集上证明了我们的方法的性能，其在识别精度和计算效率两个方面都高于之前的状态 искусственныйints。
</details></li>
</ul>
<hr>
<h2 id="GeoAdapt-Self-Supervised-Test-Time-Adaption-in-LiDAR-Place-Recognition-Using-Geometric-Priors"><a href="#GeoAdapt-Self-Supervised-Test-Time-Adaption-in-LiDAR-Place-Recognition-Using-Geometric-Priors" class="headerlink" title="GeoAdapt: Self-Supervised Test-Time Adaption in LiDAR Place Recognition Using Geometric Priors"></a>GeoAdapt: Self-Supervised Test-Time Adaption in LiDAR Place Recognition Using Geometric Priors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04638">http://arxiv.org/abs/2308.04638</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/csiro-robotics/geoadapt">https://github.com/csiro-robotics/geoadapt</a></li>
<li>paper_authors: Joshua Knights, Stephen Hausler, Sridha Sridharan, Clinton Fookes, Peyman Moghadam</li>
<li>for: 提高 LiDAR 场景认知系统在不同环境下的性能，尤其是在训练和测试数据集中存在域名shift的情况下。</li>
<li>methods: 提出了一种基于深度学习的自动生成 pseudo-标签的方法，通过自我监督学习来提高模型在不同环境下的性能和可靠性。</li>
<li>results: 实验表明，GeoAdapt 可以在中度至严重的域名shift情况下显著提高场景认知性能，并与完全监督的测试时适应方法相比赛得竞争力。<details>
<summary>Abstract</summary>
LiDAR place recognition approaches based on deep learning suffer a significant degradation in performance when there is a shift between the distribution of the training and testing datasets, with re-training often required to achieve top performance. However, obtaining accurate ground truth on new environments can be prohibitively expensive, especially in complex or GPS-deprived environments. To address this issue we propose GeoAdapt, which introduces a novel auxiliary classification head to generate pseudo-labels for re-training on unseen environments in a self-supervised manner. GeoAdapt uses geometric consistency as a prior to improve the robustness of our generated pseudo-labels against domain shift, improving the performance and reliability of our Test-Time Adaptation approach. Comprehensive experiments show that GeoAdapt significantly boosts place recognition performance across moderate to severe domain shifts, and is competitive with fully supervised test-time adaptation approaches. Our code will be available at https://github.com/csiro-robotics/GeoAdapt.
</details>
<details>
<summary>摘要</summary>
“LiDAR位置识别方法基于深度学习受到分布不同的训练和测试数据集之间的偏移会导致性能下降，并且经常需要重新训练以达到最佳性能。然而，在新环境中获取准确的测试数据可以非常昂贵，特别是在复杂或GPS缺乏环境中。为解决这个问题，我们提出了GeoAdapt，它 introduce了一个新的辅助分类头来生成 Pseudo-标签，以便在无监督的自适应方式下重新训练在未看过的环境中。GeoAdapt使用几何一致性作为假设，以提高我们生成的 Pseudo-标签对域转移的可靠性，从而提高了我们的测试时适应方法的性能和可靠性。我们的实验表明，GeoAdapt在中等至严重的域转移情况下能够显著提高位置识别性能，并与完全监督的测试时适应方法竞争。我们的代码将在https://github.com/csiro-robotics/GeoAdapt上公开。”Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Rendering-Humans-from-Object-Occluded-Monocular-Videos"><a href="#Rendering-Humans-from-Object-Occluded-Monocular-Videos" class="headerlink" title="Rendering Humans from Object-Occluded Monocular Videos"></a>Rendering Humans from Object-Occluded Monocular Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04622">http://arxiv.org/abs/2308.04622</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tiangexiang/OccNeRF">https://github.com/tiangexiang/OccNeRF</a></li>
<li>paper_authors: Tiange Xiang, Adam Sun, Jiajun Wu, Ehsan Adeli, Li Fei-Fei</li>
<li>for: 本研究旨在解决三维人体重建和渲染从单目视频中的问题，尤其是在实际场景中，其中可能会有障碍物阻挡相机视野并导致人体部分遮挡。现有方法无法处理这些缺陷，主要是因为标准渲染策略依赖点对点映射，可能导致人体部分的不一致。</li>
<li>methods: 我们提出了一种名为OccNeRF的神经渲染方法，可以更好地渲染人体在受到干扰的场景中。我们直接解决了两个缺陷，一是使用点对点映射的标准渲染策略可能导致人体部分的不一致，二是直接 regression approach 不考虑任何可行性条件（即先验信息） для 渲染下遮挡。为解决这两个缺陷，我们提出了基于表面和可见性先验的渲染方法。</li>
<li>results: 我们验证了我们的方法在both simulated和实际 occlusions 中的超过人体渲染和渲染效果，并证明了我们的方法的优越性。<details>
<summary>Abstract</summary>
3D understanding and rendering of moving humans from monocular videos is a challenging task. Despite recent progress, the task remains difficult in real-world scenarios, where obstacles may block the camera view and cause partial occlusions in the captured videos. Existing methods cannot handle such defects due to two reasons. First, the standard rendering strategy relies on point-point mapping, which could lead to dramatic disparities between the visible and occluded areas of the body. Second, the naive direct regression approach does not consider any feasibility criteria (ie, prior information) for rendering under occlusions. To tackle the above drawbacks, we present OccNeRF, a neural rendering method that achieves better rendering of humans in severely occluded scenes. As direct solutions to the two drawbacks, we propose surface-based rendering by integrating geometry and visibility priors. We validate our method on both simulated and real-world occlusions and demonstrate our method's superiority.
</details>
<details>
<summary>摘要</summary>
三维理解和渲染移动人体从单目视频中是一项具有挑战性的任务。尽管最近有所进步，但在真实世界场景中，障碍物可能会阻挡摄像头视野，导致视频中的部分遮挡。现有方法无法处理这些缺陷，主要因两点：首先，标准渲染策略基于点对点映射，可能导致人体部分遮挡和可见部分之间的差异极大。其次，直接回归方法不考虑任何可行性条件（即先验知识），在遮挡下进行渲染。为解决以上缺陷，我们提出OccNeRF方法，实现在严重遮挡场景中更好的人体渲染。为直接解决两个缺陷，我们提议基于几何和可见约束的表面渲染。我们在模拟和实际遮挡场景中验证了我们的方法，并证明其超越性。
</details></li>
</ul>
<hr>
<h2 id="PSRFlow-Probabilistic-Super-Resolution-with-Flow-Based-Models-for-Scientific-Data"><a href="#PSRFlow-Probabilistic-Super-Resolution-with-Flow-Based-Models-for-Scientific-Data" class="headerlink" title="PSRFlow: Probabilistic Super Resolution with Flow-Based Models for Scientific Data"></a>PSRFlow: Probabilistic Super Resolution with Flow-Based Models for Scientific Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04605">http://arxiv.org/abs/2308.04605</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingyi Shen, Han-Wei Shen</li>
<li>for: 这个论文的目的是提出一种基于正则化流的生成模型，用于科学数据超分辨化，并在超分辨化过程中进行不确定性评估。</li>
<li>methods: 该模型使用正则化流来学习高分辨度数据的Conditional分布，并通过随机抽取各个维度的GaussianLatent空间来实现不确定性评估。</li>
<li>results: 对比其他方法如 interpolate 和 GAN 基本的超分辨化网络，PSRFlow 模型在不确定性评估方面表现出色，并且在不同的数据比例下进行灵活的超分辨化。<details>
<summary>Abstract</summary>
Although many deep-learning-based super-resolution approaches have been proposed in recent years, because no ground truth is available in the inference stage, few can quantify the errors and uncertainties of the super-resolved results. For scientific visualization applications, however, conveying uncertainties of the results to scientists is crucial to avoid generating misleading or incorrect information. In this paper, we propose PSRFlow, a novel normalizing flow-based generative model for scientific data super-resolution that incorporates uncertainty quantification into the super-resolution process. PSRFlow learns the conditional distribution of the high-resolution data based on the low-resolution counterpart. By sampling from a Gaussian latent space that captures the missing information in the high-resolution data, one can generate different plausible super-resolution outputs. The efficient sampling in the Gaussian latent space allows our model to perform uncertainty quantification for the super-resolved results. During model training, we augment the training data with samples across various scales to make the model adaptable to data of different scales, achieving flexible super-resolution for a given input. Our results demonstrate superior performance and robust uncertainty quantification compared with existing methods such as interpolation and GAN-based super-resolution networks.
</details>
<details>
<summary>摘要</summary>
尽管最近几年内提出了许多深度学习基于超分辨率方法，但由于无法在推理阶段获得测试数据，因此只能很难量化和不确定性的超分辨率结果。在科学视觉应用中，却是非常重要的，通过传递结果的不确定性给科学家，以避免生成错误或不准确的信息。在这篇论文中，我们提出了PSRFlow，一种基于Normalizing Flow的生成模型，用于科学数据超分辨率中的不确定性评估。PSRFlow学习了高分辨率数据的Conditional分布，基于低分辨率数据。通过在Gaussian准则空间中采样，可以生成不同的可能的超分辨率输出。我们的模型可以在Gaussian准则空间中高效采样，从而实现对超分辨率结果的不确定性评估。在模型训练时，我们将训练数据扩展到不同的尺度，使模型适应不同的数据尺度，实现数据的灵活超分辨率。我们的结果表明，PSRFlow比既有 interpolate和GAN基于超分辨率网络的方法具有更高的性能和稳定性。
</details></li>
</ul>
<hr>
<h2 id="1st-Place-Solution-for-CVPR2023-BURST-Long-Tail-and-Open-World-Challenges"><a href="#1st-Place-Solution-for-CVPR2023-BURST-Long-Tail-and-Open-World-Challenges" class="headerlink" title="1st Place Solution for CVPR2023 BURST Long Tail and Open World Challenges"></a>1st Place Solution for CVPR2023 BURST Long Tail and Open World Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04598">http://arxiv.org/abs/2308.04598</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaer Huang<br>for:* The paper is written to address the challenge of video instance segmentation (VIS) in long-tailed and open-world scenarios.methods:* The authors use a combination of LVISv0.5 and the COCO dataset with repeat factor sampling to train their model.* They train the detector with segmentation and CEM on the LVISv0.5 + COCO dataset, and then train the instance appearance similarity head on the TAO dataset.results:* The authors achieve 14.9 HOTAall in the BURST test set, ranking 1st in the benchmark.* They also achieve 61.4 OWTAall in the open-world challenges, ranking 1st in the benchmark.<details>
<summary>Abstract</summary>
Currently, Video Instance Segmentation (VIS) aims at segmenting and categorizing objects in videos from a closed set of training categories that contain only a few dozen of categories, lacking the ability to handle diverse objects in real-world videos. As TAO and BURST datasets release, we have the opportunity to research VIS in long-tailed and open-world scenarios. Traditional VIS methods are evaluated on benchmarks limited to a small number of common classes, But practical applications require trackers that go beyond these common classes, detecting and tracking rare and even never-before-seen objects. Inspired by the latest MOT paper for the long tail task (Tracking Every Thing in the Wild, Siyuan Li et), for the BURST long tail challenge, we train our model on a combination of LVISv0.5 and the COCO dataset using repeat factor sampling. First, train the detector with segmentation and CEM on LVISv0.5 + COCO dataset. And then, train the instance appearance similarity head on the TAO dataset. at last, our method (LeTracker) gets 14.9 HOTAall in the BURST test set, ranking 1st in the benchmark. for the open-world challenges, we only use 64 classes (Intersection classes of BURST Train subset and COCO dataset, without LVIS dataset) annotations data training, and testing on BURST test set data and get 61.4 OWTAall, ranking 1st in the benchmark. Our code will be released to facilitate future research.
</details>
<details>
<summary>摘要</summary>
当前，视频实例分割（VIS）目标是将视频中的对象分类和分割，但现有的方法仅能处理固定的训练类别，无法涵盖实际世界中的多样化对象。随着TAO和BURST数据集的发布，我们有机会进行VIS在长尾和开放世界enario中的研究。传统的VIS方法通常被评估在限制于一些常见类别的benchmark上，但实际应用需要满足更多的类别，检测和跟踪 rare和even never-before-seen对象。受latest MOT论文的长尾任务（Tracking Every Thing in the Wild，Siyuan Li et al）的启发，我们在BURST长尾挑战中使用repeat factor sampling训练我们的模型。首先，我们使用LVISv0.5和COCO数据集训练探测器的segmentation和CEM。然后，我们在TAO数据集上训练实例外观相似度头。最后，我们的方法（LeTracker）在BURST测试集上得到14.9 HOTAall，排名第一名。对于开放世界挑战，我们只使用64个类别（BURST训练集和COCO数据集的交集类别，不包括LVIS数据集）的注释数据训练，并在BURST测试集上进行测试，得到61.4 OWTAall，排名第一名。我们的代码将被释出，以便未来的研究。
</details></li>
</ul>
<hr>
<h2 id="LATR-3D-Lane-Detection-from-Monocular-Images-with-Transformer"><a href="#LATR-3D-Lane-Detection-from-Monocular-Images-with-Transformer" class="headerlink" title="LATR: 3D Lane Detection from Monocular Images with Transformer"></a>LATR: 3D Lane Detection from Monocular Images with Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04583">http://arxiv.org/abs/2308.04583</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jmoonr/latr">https://github.com/jmoonr/latr</a></li>
<li>paper_authors: Yueru Luo, Chaoda Zheng, Xu Yan, Tang Kun, Chao Zheng, Shuguang Cui, Zhen Li</li>
<li>for: 本研究旨在解决自动驾驶中3D车道检测问题，具体来说是从单视图图像中检测3D车道。</li>
<li>methods: 本研究使用了3D感知前视图特征，而不是基于转换后的视图表示。 Specifically, LATR使用了跨注意力的查询和键值对来检测3D车道，其中查询基于2D车道感知特征，并采用混合嵌入来增强车道信息。另一方面，3D空间信息通过位坐标嵌入从iteratively更新的3D地面来注入。</li>
<li>results: LATR在synthetic Apollo、realistic OpenLane和ONCE-3DLanes等数据集上表现出优于之前的状态 искусственный方法（例如，OpenLane上的F1分数提高11.4个）。<details>
<summary>Abstract</summary>
3D lane detection from monocular images is a fundamental yet challenging task in autonomous driving. Recent advances primarily rely on structural 3D surrogates (e.g., bird's eye view) built from front-view image features and camera parameters. However, the depth ambiguity in monocular images inevitably causes misalignment between the constructed surrogate feature map and the original image, posing a great challenge for accurate lane detection. To address the above issue, we present a novel LATR model, an end-to-end 3D lane detector that uses 3D-aware front-view features without transformed view representation. Specifically, LATR detects 3D lanes via cross-attention based on query and key-value pairs, constructed using our lane-aware query generator and dynamic 3D ground positional embedding. On the one hand, each query is generated based on 2D lane-aware features and adopts a hybrid embedding to enhance lane information. On the other hand, 3D space information is injected as positional embedding from an iteratively-updated 3D ground plane. LATR outperforms previous state-of-the-art methods on both synthetic Apollo, realistic OpenLane and ONCE-3DLanes by large margins (e.g., 11.4 gain in terms of F1 score on OpenLane). Code will be released at https://github.com/JMoonr/LATR .
</details>
<details>
<summary>摘要</summary>
三维车道检测从单视图图像是自主驾驶中的基本 yet 挑战性任务。当前的进步主要基于结构三维代理（如鸟瞰视图），从前视图图像特征和摄像头参数构建。然而，单视图图像中的深度不确定性无法准确对应原始图像，这对准确车道检测 pose 大问题。为解决上述问题，我们提出了一种新的LATR模型，一个端到端的三维车道检测器，使用三维感知的前视图特征而不需要转换视图表示。具体来说，LATR通过对查询和关键值对进行跨注意力的注意力机制来检测三维车道。一方面，每个查询基于二维车道意识特征，采用混合嵌入以增强车道信息。另一方面，3D空间信息通过循环更新的3D地面嵌入注入到扩展特征中。LATR在 Apollo 和 OpenLane 等实际数据集上的性能明显超过了之前的状态对照方法（例如，OpenLane 上的 F1 分数提高11.4）。代码将在 GitHub 上发布。
</details></li>
</ul>
<hr>
<h2 id="Optimizing-Algorithms-From-Pairwise-User-Preferences"><a href="#Optimizing-Algorithms-From-Pairwise-User-Preferences" class="headerlink" title="Optimizing Algorithms From Pairwise User Preferences"></a>Optimizing Algorithms From Pairwise User Preferences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04571">http://arxiv.org/abs/2308.04571</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/leonidk/pairwise">https://github.com/leonidk/pairwise</a></li>
<li>paper_authors: Leonid Keselman, Katherine Shih, Martial Hebert, Aaron Steinfeld</li>
<li>for: 本研究旨在优化机器人算法参数配置，以便更好地适应人类中心的情境。</li>
<li>methods: 本研究提出了 SortCMA 算法，通过对用户喜好进行排序，以不直接模型奖励函数的方式，高效地和稳定地优化算法参数。</li>
<li>results: 研究中应用 SortCMA 算法成功地优化了无地平 truth 的深度探测仪器和人工社交导航问题，并进行了用户研究以评估社交导航结果。<details>
<summary>Abstract</summary>
Typical black-box optimization approaches in robotics focus on learning from metric scores. However, that is not always possible, as not all developers have ground truth available. Learning appropriate robot behavior in human-centric contexts often requires querying users, who typically cannot provide precise metric scores. Existing approaches leverage human feedback in an attempt to model an implicit reward function; however, this reward may be difficult or impossible to effectively capture. In this work, we introduce SortCMA to optimize algorithm parameter configurations in high dimensions based on pairwise user preferences. SortCMA efficiently and robustly leverages user input to find parameter sets without directly modeling a reward. We apply this method to tuning a commercial depth sensor without ground truth, and to robot social navigation, which involves highly complex preferences over robot behavior. We show that our method succeeds in optimizing for the user's goals and perform a user study to evaluate social navigation results.
</details>
<details>
<summary>摘要</summary>
传统的黑盒优化方法在机器人学中通常是通过学习度量分数来进行。但是，不 все开发者拥有地面 truth，而学习合适的机器人行为在人类中心的上下文中经常需要询问用户，用户通常无法提供精确的度量分数。现有方法利用用户反馈来尝试模型一个隐式奖励函数，但这个奖励可能很难或者无法有效地捕捉。在这项工作中，我们介绍 SortCMA 来优化算法参数配置在高维度基于用户偏好的情况下。SortCMA 能够高效地和稳定地利用用户输入来找到参数集，而不需直接模型一个奖励。我们在没有地面 truth 的情况下使用 SortCMA 来调整一个商业深度探测器，以及机器人社交导航，这些导航包括机器人行为的复杂偏好。我们示示了我们的方法可以在用户的目标下进行优化，并进行了用户研究来评估社交导航结果。
</details></li>
</ul>
<hr>
<h2 id="FocalFormer3D-Focusing-on-Hard-Instance-for-3D-Object-Detection"><a href="#FocalFormer3D-Focusing-on-Hard-Instance-for-3D-Object-Detection" class="headerlink" title="FocalFormer3D : Focusing on Hard Instance for 3D Object Detection"></a>FocalFormer3D : Focusing on Hard Instance for 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04556">http://arxiv.org/abs/2308.04556</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/NVlabs/FocalFormer3D">https://github.com/NVlabs/FocalFormer3D</a></li>
<li>paper_authors: Yilun Chen, Zhiding Yu, Yukang Chen, Shiyi Lan, Animashree Anandkumar, Jiaya Jia, Jose Alvarez</li>
<li>for: 提高3D对象检测中的缺失预测（False Negative）的精度，尤其是在自动驾驶场景中，以免导致危险的情况。</li>
<li>methods: 提出了一种通用的管道方法 Hard Instance Probing (HIP)，可以在多个阶段进行缺失预测的识别和提高模型的预测精度。在3D对象检测方面，我们实现了这个方法为FocalFormer3D，一种简单又高效的检测器，能够高效地检测难对象并提高预测精度。FocalFormer3D使用多个阶段生成查询来找到困难对象，并使用箱级变换器解码器来快速分辨对象和庞大对象候选。</li>
<li>results: 在nuScenes和Waymo datasets上进行实验， validate FocalFormer3D的超越性性能。FocalFormer3D在LiDAR和多模态设置下都具有出色的检测和跟踪性能，其中 nuScenes检测benchmark中的70.5 mAP和73.9 NDS都在1位的LiDAR领导板块上。<details>
<summary>Abstract</summary>
False negatives (FN) in 3D object detection, {\em e.g.}, missing predictions of pedestrians, vehicles, or other obstacles, can lead to potentially dangerous situations in autonomous driving. While being fatal, this issue is understudied in many current 3D detection methods. In this work, we propose Hard Instance Probing (HIP), a general pipeline that identifies \textit{FN} in a multi-stage manner and guides the models to focus on excavating difficult instances. For 3D object detection, we instantiate this method as FocalFormer3D, a simple yet effective detector that excels at excavating difficult objects and improving prediction recall. FocalFormer3D features a multi-stage query generation to discover hard objects and a box-level transformer decoder to efficiently distinguish objects from massive object candidates. Experimental results on the nuScenes and Waymo datasets validate the superior performance of FocalFormer3D. The advantage leads to strong performance on both detection and tracking, in both LiDAR and multi-modal settings. Notably, FocalFormer3D achieves a 70.5 mAP and 73.9 NDS on nuScenes detection benchmark, while the nuScenes tracking benchmark shows 72.1 AMOTA, both ranking 1st place on the nuScenes LiDAR leaderboard. Our code is available at \url{https://github.com/NVlabs/FocalFormer3D}.
</details>
<details>
<summary>摘要</summary>
假阳性（FN）在三维 объек的检测中，例如缺失人行车辆或其他障碍物的预测，可能导致自动驾驶中的危险 Situations. 虽然这是致命的问题，但在许多当前的三维检测方法中却被不 suficiently studied. 在这种工作中，我们提议使用 Hard Instance Probing（HIP），一种总体来说是多个阶段的方法，用于标识假阳性。为三维对象检测，我们实现了 FocalFormer3D，一种简单又高效的检测器，可以帮助模型更好地挖掘困难对象。 FocalFormer3D 的设计包括多个阶段的查询生成，用于找到困难对象，以及一个箱级别的 transformer 解码器，用于高效地分辨对象和大量对象候选者之间。实验结果表明，FocalFormer3D 在 nuScenes 和 Waymo 数据集上表现出色，其优势在于强大的检测和跟踪性能，包括 LiDAR 和多模式设置下的性能。特别是，FocalFormer3D 在 nuScenes 检测benchmark上达到了 70.5 mAP 和 73.9 NDS，在 nuScenes 跟踪benchmark上达到了 72.1 AMOTA，都在 nuScenes LiDAR 领先者板块上排名第一。我们的代码可以在 <https://github.com/NVlabs/FocalFormer3D> 上获取。
</details></li>
</ul>
<hr>
<h2 id="Towards-Automatic-Scoring-of-Spinal-X-ray-for-Ankylosing-Spondylitis"><a href="#Towards-Automatic-Scoring-of-Spinal-X-ray-for-Ankylosing-Spondylitis" class="headerlink" title="Towards Automatic Scoring of Spinal X-ray for Ankylosing Spondylitis"></a>Towards Automatic Scoring of Spinal X-ray for Ankylosing Spondylitis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05123">http://arxiv.org/abs/2308.05123</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanhan Mo, Yao Chen, Aimee Readie, Gregory Ligozio, Thibaud Coroller, Bartłomiej W. Papież</li>
<li>for: 这份研究旨在开发一个自动分配 modified Stoke Ankylosing Spondylitis Spinal Score (mSASSS) 的运算流程，以便对骨架X射像中的脊椎影像进行自动评分。</li>
<li>methods: 这个研究使用了一个2步骤的自动评分管线，称为VertXGradeNet，将骨架X射像中的脊椎影像转换为 modified Stoke Ankylosing Spondylitis Spinal Score (mSASSS) 分数。</li>
<li>results: 研究结果显示，VertXGradeNet 可以对有限量和不均匀的数据进行自动评分，并且在两个试验数据集上实现了0.56和0.51的平衡精度。<details>
<summary>Abstract</summary>
Manually grading structural changes with the modified Stoke Ankylosing Spondylitis Spinal Score (mSASSS) on spinal X-ray imaging is costly and time-consuming due to bone shape complexity and image quality variations. In this study, we address this challenge by prototyping a 2-step auto-grading pipeline, called VertXGradeNet, to automatically predict mSASSS scores for the cervical and lumbar vertebral units (VUs) in X-ray spinal imaging. The VertXGradeNet utilizes VUs generated by our previously developed VU extraction pipeline (VertXNet) as input and predicts mSASSS based on those VUs. VertXGradeNet was evaluated on an in-house dataset of lateral cervical and lumbar X-ray images for axial spondylarthritis patients. Our results show that VertXGradeNet can predict the mSASSS score for each VU when the data is limited in quantity and imbalanced. Overall, it can achieve a balanced accuracy of 0.56 and 0.51 for 4 different mSASSS scores (i.e., a score of 0, 1, 2, 3) on two test datasets. The accuracy of the presented method shows the potential to streamline the spinal radiograph readings and therefore reduce the cost of future clinical trials.
</details>
<details>
<summary>摘要</summary>
人工评估结构变化的成本和时间费用很高，主要是因为骨形态复杂性和图像质量变化。在这项研究中，我们解决这个挑战，推出了一个两步自动评估管线，称为VertXGradeNet，可以自动预测X光影像中肩峰病变综合分数（mSASSS）。VertXGradeNet使用我们先前开发的VU提取管线（VertXNet）生成的VU作为输入，并预测基于这些VU的mSASSS分数。我们的结果表明，VertXGradeNet可以在数量有限、不均衡的数据集上预测每个VU的mSASSS分数。总的来说，它可以在两个测试数据集上实现平均准确率为0.56和0.51，对四个不同的mSASSS分数（即分数为0、1、2、3）进行预测。本方法的准确率表明，可以通过自动化肩峰X光影像读取，提高未来临床试验的效率，降低成本。
</details></li>
</ul>
<hr>
<h2 id="Copy-Number-Variation-Informs-fMRI-based-Prediction-of-Autism-Spectrum-Disorder"><a href="#Copy-Number-Variation-Informs-fMRI-based-Prediction-of-Autism-Spectrum-Disorder" class="headerlink" title="Copy Number Variation Informs fMRI-based Prediction of Autism Spectrum Disorder"></a>Copy Number Variation Informs fMRI-based Prediction of Autism Spectrum Disorder</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05122">http://arxiv.org/abs/2308.05122</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicha C. Dvornek, Catherine Sullivan, James S. Duncan, Abha R. Gupta</li>
<li>for: This paper aims to develop a more integrative model for combining genetic, demographic, and neuroimaging data to better understand the multifactorial etiology of autism spectrum disorder (ASD).</li>
<li>methods: The proposed approach uses an attention-based model that guides attention to neuroimaging features of importance for model prediction based on genetic data derived from copy number variation parameters.</li>
<li>results: The attention-based model combining genetic information, demographic data, and functional magnetic resonance imaging results in superior prediction performance compared to other multimodal approaches, as demonstrated on ASD classification and severity prediction tasks using a sex-balanced dataset of 228 ASD and typically developing subjects.<details>
<summary>Abstract</summary>
The multifactorial etiology of autism spectrum disorder (ASD) suggests that its study would benefit greatly from multimodal approaches that combine data from widely varying platforms, e.g., neuroimaging, genetics, and clinical characterization. Prior neuroimaging-genetic analyses often apply naive feature concatenation approaches in data-driven work or use the findings from one modality to guide posthoc analysis of another, missing the opportunity to analyze the paired multimodal data in a truly unified approach. In this paper, we develop a more integrative model for combining genetic, demographic, and neuroimaging data. Inspired by the influence of genotype on phenotype, we propose using an attention-based approach where the genetic data guides attention to neuroimaging features of importance for model prediction. The genetic data is derived from copy number variation parameters, while the neuroimaging data is from functional magnetic resonance imaging. We evaluate the proposed approach on ASD classification and severity prediction tasks, using a sex-balanced dataset of 228 ASD and typically developing subjects in a 10-fold cross-validation framework. We demonstrate that our attention-based model combining genetic information, demographic data, and functional magnetic resonance imaging results in superior prediction performance compared to other multimodal approaches.
</details>
<details>
<summary>摘要</summary>
Autism spectrum disorder (ASD) 的多因素起源表示，研究它会受到多模态方法的 combinatio。例如，神经成像、遗传学和临床特征的数据可以结合在一起来研究。在过去的神经成像-遗传学分析中，通常采用了简单的特征串接方法或者使用一个模式来导向另一个模式的分析，而忽略了对复合数据进行真正的统一分析。在这篇论文中，我们开发了一种更集成的方法，将遗传学、人口统计学和神经成像数据结合在一起。我们受到遗传型的影响，使用了一种注意力机制，使遗传学数据引导神经成像特征的重要性对模型预测。我们的数据来自于拷贝数变化参数，而神经成像数据来自功能核磁共振成像。我们在ASD分类和严重程度预测任务中使用了10次交叉验证框架，并证明了我们的注意力机制，结合遗传信息、人口统计学和神经成像结果，在多模态方法中实现了更高的预测性能。
</details></li>
</ul>
<hr>
<h2 id="From-Fake-to-Real-FFR-A-two-stage-training-pipeline-for-mitigating-spurious-correlations-with-synthetic-data"><a href="#From-Fake-to-Real-FFR-A-two-stage-training-pipeline-for-mitigating-spurious-correlations-with-synthetic-data" class="headerlink" title="From Fake to Real (FFR): A two-stage training pipeline for mitigating spurious correlations with synthetic data"></a>From Fake to Real (FFR): A two-stage training pipeline for mitigating spurious correlations with synthetic data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04553">http://arxiv.org/abs/2308.04553</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maan Qraitem, Kate Saenko, Bryan A. Plummer</li>
<li>for: 减少图像识别模型学习偏见，特别是因为训练集中某些组（如女性）被下标 Represented 在某些类（如程序员）中。</li>
<li>methods: 使用生成模型生成偏见训练集的 sintetic 数据，以增加训练集中的维度和多样性，从而减少模型学习到的偏见。</li>
<li>results: 提出了一种两阶段管道，首先在偏见synthetic dataset上预训练模型，然后在真实数据上细化。这种管道可以避免训练both real和synthetic数据，从而避免real和synthetic数据之间的偏见。此外，我们的管道还能够学习减轻偏见的特征，从而在第二阶段中减少偏见。此外，我们的管道可以自然地与偏见缓解方法集成，这些方法可以简单地应用于细化阶段。我们的实验证明，我们的管道可以进一步提高偏见缓解方法的性能，在三个大规模数据集上达到状态空间的表现。<details>
<summary>Abstract</summary>
Visual recognition models are prone to learning spurious correlations induced by an imbalanced training set where certain groups (\eg Females) are under-represented in certain classes (\eg Programmers). Generative models offer a promising direction in mitigating this bias by generating synthetic data for the minority samples and thus balancing the training set. However, prior work that uses these approaches overlooks that visual recognition models could often learn to differentiate between real and synthetic images and thus fail to unlearn the bias in the original dataset. In our work, we propose a novel two-stage pipeline to mitigate this issue where 1) we pre-train a model on a balanced synthetic dataset and then 2) fine-tune on the real data. Using this pipeline, we avoid training on both real and synthetic data, thus avoiding the bias between real and synthetic data. Moreover, we learn robust features against the bias in the first step that mitigate the bias in the second step. Moreover, our pipeline naturally integrates with bias mitigation methods; they can be simply applied to the fine-tuning step. As our experiments prove, our pipeline can further improve the performance of bias mitigation methods obtaining state-of-the-art performance on three large-scale datasets.
</details>
<details>
<summary>摘要</summary>
“视觉识别模型容易学习偏见，由于训练集中某些组（如女性）被下标，导致训练集不均衡。生成模型提供了一个有前途的方向，即通过生成少数样本的 sintetic 数据，以增加训练集的均衡性。然而，现有的方法忽略了视觉识别模型可能会学习分辨真实和 sintetic 图像的 diference，从而失去原始数据中的偏见。在我们的工作中，我们提出了一个新的两个阶段管道来解决这个问题：1）我们首先在一个均衡的 sintetic 数据上预训练模型，然后2）在真实数据上细化。使用这个管道，我们可以避免在真实和 sintetic 数据上进行训练，从而避免偏见的问题。此外，我们在第一个阶段学习了对偏见的Robust特征，以 Mitigate 在第二个阶段的偏见。此外，我们的管道自然地与偏见缓解方法集成，这些方法可以简单地应用于细化阶段。根据我们的实验，我们的管道可以进一步提高偏见缓解方法的性能，在三个大规模数据集上达到了状态之作�的表现。”
</details></li>
</ul>
<hr>
<h2 id="Improving-Medical-Image-Classification-in-Noisy-Labels-Using-Only-Self-supervised-Pretraining"><a href="#Improving-Medical-Image-Classification-in-Noisy-Labels-Using-Only-Self-supervised-Pretraining" class="headerlink" title="Improving Medical Image Classification in Noisy Labels Using Only Self-supervised Pretraining"></a>Improving Medical Image Classification in Noisy Labels Using Only Self-supervised Pretraining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04551">http://arxiv.org/abs/2308.04551</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bbrattoli/JigsawPuzzlePytorch">https://github.com/bbrattoli/JigsawPuzzlePytorch</a></li>
<li>paper_authors: Bidur Khanal, Binod Bhattarai, Bishesh Khanal, Cristian A. Linte</li>
<li>for: 这个研究旨在测试自我超vised学习初始化方法可以改善随机标签影像分类性能。</li>
<li>methods: 研究使用了两种自我超vised学习方法：contrastive自我超vised学习和预texte任务基于的自我超vised学习。</li>
<li>results: 研究发现，使用自我超vised学习初始化的模型可以更好地学习随机标签影像，并提高分类性能。<details>
<summary>Abstract</summary>
Noisy labels hurt deep learning-based supervised image classification performance as the models may overfit the noise and learn corrupted feature extractors. For natural image classification training with noisy labeled data, model initialization with contrastive self-supervised pretrained weights has shown to reduce feature corruption and improve classification performance. However, no works have explored: i) how other self-supervised approaches, such as pretext task-based pretraining, impact the learning with noisy label, and ii) any self-supervised pretraining methods alone for medical images in noisy label settings. Medical images often feature smaller datasets and subtle inter class variations, requiring human expertise to ensure correct classification. Thus, it is not clear if the methods improving learning with noisy labels in natural image datasets such as CIFAR would also help with medical images. In this work, we explore contrastive and pretext task-based self-supervised pretraining to initialize the weights of a deep learning classification model for two medical datasets with self-induced noisy labels -- NCT-CRC-HE-100K tissue histological images and COVID-QU-Ex chest X-ray images. Our results show that models initialized with pretrained weights obtained from self-supervised learning can effectively learn better features and improve robustness against noisy labels.
</details>
<details>
<summary>摘要</summary>
噪声标签会对深度学习基于监督图像分类的性能产生负面影响，因为模型可能会适应噪声并学习损坏的特征提取器。在自然图像分类训练中使用噪声标签数据，使用对比自我超vised预训练的初始化方法可以减少特征损坏并提高分类性能。然而，没有任何研究探讨了：i) 其他自我超视任务基本预训练方法对噪声标签学习的影响，ii) 任何自我超视任务基本预训练方法在医学图像上的效果。医学图像通常具有较小的数据集和柔微的间类差异，需要人类专业知识来确保正确的分类。因此，不清楚自然图像数据集CIFAR中的方法会在医学图像上有效。在这项工作中，我们探讨了对比和预 Text Task-based自我超视预训练来初始化深度学习分类模型的两个医学数据集——NCT-CRC-HE-100K组织组织肿瘤图像和COVID-QU-Ex胸部X射图像。我们的结果表明，使用自我超视预训练获得的预 initialize的模型可以更好地学习特征并提高对噪声标签的Robustness。
</details></li>
</ul>
<hr>
<h2 id="Prune-Spatio-temporal-Tokens-by-Semantic-aware-Temporal-Accumulation"><a href="#Prune-Spatio-temporal-Tokens-by-Semantic-aware-Temporal-Accumulation" class="headerlink" title="Prune Spatio-temporal Tokens by Semantic-aware Temporal Accumulation"></a>Prune Spatio-temporal Tokens by Semantic-aware Temporal Accumulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04549">http://arxiv.org/abs/2308.04549</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuangrui Ding, Peisen Zhao, Xiaopeng Zhang, Rui Qian, Hongkai Xiong, Qi Tian</li>
<li>for: 提高视频识别领域中Transformers的速度-准确性贸易 balance。</li>
<li>methods: 提出Semantic-aware Temporal Accumulation score（STA）模块，通过考虑两个关键因素： temporal redundancy和semantic importance，进行token权重调整和减少。</li>
<li>results: 在Kinetics-400和Something-Something V2 datasets上，使用STA模块可以实现约30%的计算减少，而准确率下降幅度只有0.2%。<details>
<summary>Abstract</summary>
Transformers have become the primary backbone of the computer vision community due to their impressive performance. However, the unfriendly computation cost impedes their potential in the video recognition domain. To optimize the speed-accuracy trade-off, we propose Semantic-aware Temporal Accumulation score (STA) to prune spatio-temporal tokens integrally. STA score considers two critical factors: temporal redundancy and semantic importance. The former depicts a specific region based on whether it is a new occurrence or a seen entity by aggregating token-to-token similarity in consecutive frames while the latter evaluates each token based on its contribution to the overall prediction. As a result, tokens with higher scores of STA carry more temporal redundancy as well as lower semantics thus being pruned. Based on the STA score, we are able to progressively prune the tokens without introducing any additional parameters or requiring further re-training. We directly apply the STA module to off-the-shelf ViT and VideoSwin backbones, and the empirical results on Kinetics-400 and Something-Something V2 achieve over 30% computation reduction with a negligible ~0.2% accuracy drop. The code is released at https://github.com/Mark12Ding/STA.
</details>
<details>
<summary>摘要</summary>
孵化器在计算机视觉领域中成为主要脊梁，但它们的计算成本却限制其在视频识别领域的应用。为了优化速率和准确度之间的负荷，我们提议使用 semantic-aware temporal accumulation score（STA）来精炼时空 токен。STA Score考虑了两个关键因素：时间重复和semantic importance。前者描述特定区域是新出现还是已经看到的实体，通过在连续帧中 Token-to-token 相似性的积累来评估；后者根据每个 Token 对总预测的贡献来评估。因此，具有更高 STA 分数的 Token 会有更高的时间重复和更低的semantic importance，因此被折射。基于 STA 分数，我们可以不需要额外参数或重新训练，直接应用 STA 模块到 off-the-shelf ViT 和 VideoSwin 脊梁上。我们在 Kinetics-400 和 Something-Something V2 上进行了实验，实际结果达到了30% 的计算减少，准确率下降约0.2%。代码可以在 GitHub 上找到：https://github.com/Mark12Ding/STA。
</details></li>
</ul>
<hr>
<h2 id="YUDO-YOLO-for-Uniform-Directed-Object-Detection"><a href="#YUDO-YOLO-for-Uniform-Directed-Object-Detection" class="headerlink" title="YUDO: YOLO for Uniform Directed Object Detection"></a>YUDO: YOLO for Uniform Directed Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04542">http://arxiv.org/abs/2308.04542</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/djordjened92/yudo">https://github.com/djordjened92/yudo</a></li>
<li>paper_authors: Đorđe Nedeljković</li>
<li>for: 本文提出了一种高效的对象探测方法，通过预测对象的中心坐标和方向角来实现。由于对象均匀大，该模型不需要预测对象的宽高。</li>
<li>methods: 该方法使用了YoloV7实时对象检测架构，并对其进行了定制。该方法使用了一个非常高效的、小巧的版本，并且只使用了一个无锚头的检测头。</li>
<li>results: 该方法可以准确地检测对象的位置和方向，并且可以快速地进行计算。 authors还引入了扩展的Skew Intersection over Union (SkewIoU)计算方法，用于处理旋转的盒子。<details>
<summary>Abstract</summary>
This paper presents an efficient way of detecting directed objects by predicting their center coordinates and direction angle. Since the objects are of uniform size, the proposed model works without predicting the object's width and height. The dataset used for this problem is presented in Honeybee Segmentation and Tracking Datasets project. One of the contributions of this work is an examination of the ability of the standard real-time object detection architecture like YoloV7 to be customized for position and direction detection. A very efficient, tiny version of the architecture is used in this approach. Moreover, only one of three detection heads without anchors is sufficient for this task. We also introduce the extended Skew Intersection over Union (SkewIoU) calculation for rotated boxes - directed IoU (DirIoU), which includes an absolute angle difference. DirIoU is used both in the matching procedure of target and predicted bounding boxes for mAP calculation, and in the NMS filtering procedure. The code and models are available at https://github.com/djordjened92/yudo.
</details>
<details>
<summary>摘要</summary>
这篇论文提出了一种高效的指向对象探测方法，通过预测对象的中心坐标和方向角来实现。由于对象均匀大小，该模型不需要预测对象的宽高。使用的数据集是Honeybee Segmentation and Tracking Datasets项目中的 dataset。本研究的一个贡献是对标准实时对象检测架构如YoloV7进行定制，以实现位置和方向检测。此外，还引入了扩展的倾斜交叉Union（SkewIoU）计算方法，该方法包括绝对角度差。SkewIoU被用于练习步骤中的匹配过程和NMS筛选步骤。代码和模型可以在https://github.com/djordjened92/yudo中下载。
</details></li>
</ul>
<hr>
<h2 id="Facial-Prior-Based-First-Order-Motion-Model-for-Micro-expression-Generation"><a href="#Facial-Prior-Based-First-Order-Motion-Model-for-Micro-expression-Generation" class="headerlink" title="Facial Prior Based First Order Motion Model for Micro-expression Generation"></a>Facial Prior Based First Order Motion Model for Micro-expression Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04536">http://arxiv.org/abs/2308.04536</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/necolizer/facial-prior-based-fomm">https://github.com/necolizer/facial-prior-based-fomm</a></li>
<li>paper_authors: Yi Zhang, Youjun Zhao, Yuhang Wen, Zixuan Tang, Xinhua Xu, Mengyuan Liu</li>
<li>for: 这篇论文旨在提出一个新的任务：从视频中检测和生成微表情，以应对对于脸部表情识别和探索等领域的应用。</li>
<li>methods: 本文提出了一个新的模型，具有三个模块：首先，我们从视频中提取脸部优先知识特征；其次，我们使用关键点和本地拟合变数估算脸部运动；最后，我们使用表情生成模块将目标脸部驱动生成微表情视频。</li>
<li>results: 本文使用公共的CASME II、SAMM和SMIC datasets进行训练，并使用模型生成新的微表情视频进行评估。模型在Facial Micro-Expression Challenge 2021（MEGC2021）中获得了第一名，并被三位专家认证为Facial Action Coding System认证。<details>
<summary>Abstract</summary>
Spotting facial micro-expression from videos finds various potential applications in fields including clinical diagnosis and interrogation, meanwhile this task is still difficult due to the limited scale of training data. To solve this problem, this paper tries to formulate a new task called micro-expression generation and then presents a strong baseline which combines the first order motion model with facial prior knowledge. Given a target face, we intend to drive the face to generate micro-expression videos according to the motion patterns of source videos. Specifically, our new model involves three modules. First, we extract facial prior features from a region focusing module. Second, we estimate facial motion using key points and local affine transformations with a motion prediction module. Third, expression generation module is used to drive the target face to generate videos. We train our model on public CASME II, SAMM and SMIC datasets and then use the model to generate new micro-expression videos for evaluation. Our model achieves the first place in the Facial Micro-Expression Challenge 2021 (MEGC2021), where our superior performance is verified by three experts with Facial Action Coding System certification. Source code is provided in https://github.com/Necolizer/Facial-Prior-Based-FOMM.
</details>
<details>
<summary>摘要</summary>
发现面部微表情从视频中的应用场景广泛，包括临床诊断和问候，但这个任务仍然具有挑战性，原因是训练数据的限制。为解决这个问题，这篇论文提出了一个新的任务 called micro-expression generation，并提供了一个强大的基线模型，它结合了首要动作模型和面部先验知识。给定一个目标面，我们希望使其生成微表情视频，根据源视频的动作模式。我们的新模型包括三个模块。首先，我们从一个区域专注模块中提取面部先验特征。第二，我们使用关键点和本地拟合变换来估算面部动作，并使用运动预测模块。第三，我们使用表达生成模块来驱动目标面生成视频。我们在公共的 CASME II、SAMM 和 SMIC 数据集上训练了我们的模型，然后使用模型生成新的微表情视频进行评估。我们的模型在 Facial Micro-Expression Challenge 2021 (MEGC2021) 中获得了第一名，并被三位专家（具有 Facial Action Coding System 证书）验证了我们的优秀表现。源代码可以在 https://github.com/Necolizer/Facial-Prior-Based-FOMM 上获取。
</details></li>
</ul>
<hr>
<h2 id="Estimation-of-Human-Condition-at-Disaster-Site-Using-Aerial-Drone-Images"><a href="#Estimation-of-Human-Condition-at-Disaster-Site-Using-Aerial-Drone-Images" class="headerlink" title="Estimation of Human Condition at Disaster Site Using Aerial Drone Images"></a>Estimation of Human Condition at Disaster Site Using Aerial Drone Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04535">http://arxiv.org/abs/2308.04535</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tomoki Arai, Kenji Iwata, Kensho Hara, Yutaka Satoh</li>
<li>for: 这个研究是为了快速理解灾难现场和减少劳动力。</li>
<li>methods: 这个研究使用了人体动作在空中无人机图像中自动估计人员受损状况，并使用3D ResNet分类人类动作特征。</li>
<li>results: 研究结果显示，可以达到超过80%的准确率来分类特征人类动作状况，而其他类似人类动作状况只能达到约50%的准确率。此外，云端VR演示应用程序表明了使用无人机理解灾难现场和估计人员状况的可能性。<details>
<summary>Abstract</summary>
Drones are being used to assess the situation in various disasters. In this study, we investigate a method to automatically estimate the damage status of people based on their actions in aerial drone images in order to understand disaster sites faster and save labor. We constructed a new dataset of aerial images of human actions in a hypothetical disaster that occurred in an urban area, and classified the human damage status using 3D ResNet. The results showed that the status with characteristic human actions could be classified with a recall rate of more than 80%, while other statuses with similar human actions could only be classified with a recall rate of about 50%. In addition, a cloud-based VR presentation application suggested the effectiveness of using drones to understand the disaster site and estimate the human condition.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate english text into simplified chineseDrones are being used to assess the situation in various disasters. In this study, we investigate a method to automatically estimate the damage status of people based on their actions in aerial drone images in order to understand disaster sites faster and save labor. We constructed a new dataset of aerial images of human actions in a hypothetical disaster that occurred in an urban area, and classified the human damage status using 3D ResNet. The results showed that the status with characteristic human actions could be classified with a recall rate of more than 80%, while other statuses with similar human actions could only be classified with a recall rate of about 50%. In addition, a cloud-based VR presentation application suggested the effectiveness of using drones to understand the disaster site and estimate the human condition.中文简体版：<<SYS>>将英文文本翻译成中文简体版用悬浮机评估灾害现场的情况，这项研究探讨了基于悬浮机上空图像的人类行为自动评估人员受损状况的方法，以便更快地理解灾害现场和降低劳动成本。我们创建了一个新的飞行图像人类行为数据集，使用3D ResNet分类人员受损状况，结果显示了特征人类行为状况的分类率高于80%，而其他类似人类行为状况的分类率只有约50%。此外，一个云端VR演示应用程序表明了使用悬浮机理解灾害现场和估算人员状况的效果。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Camouflaged-Object-Segmentation-as-Domain-Adaptation"><a href="#Unsupervised-Camouflaged-Object-Segmentation-as-Domain-Adaptation" class="headerlink" title="Unsupervised Camouflaged Object Segmentation as Domain Adaptation"></a>Unsupervised Camouflaged Object Segmentation as Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04528">http://arxiv.org/abs/2308.04528</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Jun-Pu/UCOS-DA">https://github.com/Jun-Pu/UCOS-DA</a></li>
<li>paper_authors: Yi Zhang, Chengyi Wu</li>
<li>for: 本研究探讨了一新任务，即无监督隐形物 segmentation（UCOS），其中目标对象具有罕见的抽象属性，即隐形。不幸地，现有的无监督模型在适应UCOS时会遇到域之间的差距问题。</li>
<li>methods: 我们在本研究中提出了一种源自无监督领域的适应UCOS任务（UCOS-DA），其中无源标签和目标标签在整个模型训练过程中缺失。我们定义了一个源模型，即基于ImageNet的自我监督视觉变换器。而目标领域包括一个简单的线性层（我们的目标模型）和无标签的隐形对象。我们 THEN设计了一个图像前景背景对比自我挑战性适应预处理管道，以实现Robust UCOS。</li>
<li>results: 我们的基eline模型在UCOS数据集上 achieve superior segmentation性能，与竞争对手无监督模型相比，即使训练集规模只有一半于监督COS counterpart。<details>
<summary>Abstract</summary>
Deep learning for unsupervised image segmentation remains challenging due to the absence of human labels. The common idea is to train a segmentation head, with the supervision of pixel-wise pseudo-labels generated based on the representation of self-supervised backbones. By doing so, the model performance depends much on the distance between the distributions of target datasets and the pre-training dataset (e.g., ImageNet). In this work, we investigate a new task, namely unsupervised camouflaged object segmentation (UCOS), where the target objects own a common rarely-seen attribute, i.e., camouflage. Unsurprisingly, we find that the state-of-the-art unsupervised models struggle in adapting UCOS, due to the domain gap between the properties of generic and camouflaged objects. To this end, we formulate the UCOS as a source-free unsupervised domain adaptation task (UCOS-DA), where both source labels and target labels are absent during the whole model training process. Specifically, we define a source model consisting of self-supervised vision transformers pre-trained on ImageNet. On the other hand, the target domain includes a simple linear layer (i.e., our target model) and unlabeled camouflaged objects. We then design a pipeline for foreground-background-contrastive self-adversarial domain adaptation, to achieve robust UCOS. As a result, our baseline model achieves superior segmentation performance when compared with competing unsupervised models on the UCOS benchmark, with the training set which's scale is only one tenth of the supervised COS counterpart.
</details>
<details>
<summary>摘要</summary>
深度学习无监督图像分割仍然是挑战，因为缺乏人类标签。常见的想法是训练一个分割头，通过自我监督核心的代码生成的 Pseudo-标签来监督。由于模型性能很大程度取决于目标数据集和预训练集（如ImageNet）之间的分布距离，在这个工作中，我们 investigate一个新任务，即无监督隐形对象分割（UCOS）。不 surprisingly，我们发现现有state-of-the-art无监督模型在适应UCOS时受到域 gap的限制，即隐形对象的特性与普通对象的特性之间的域差异。为此，我们将UCOS定义为一个源无监督领域适应任务（UCOS-DA），其中源标签和目标标签都缺失在模型训练过程中。我们定义了一个源模型，即基于ImageNet自我监督vision transformers预训练的模型。然而，目标领域包括一个简单的线性层（即我们的目标模型）和无标签的隐形对象。我们然后设计了一个干扰对比自我适应领域域适应管道，以实现robust UCOS。结果，我们的基线模型在UCOS benchmark上比同类无监督模型表现出色，训练集的规模只是一个十分之一的超vised COS counterpart。
</details></li>
</ul>
<hr>
<h2 id="Large-Scale-Multi-Hypotheses-Cell-Tracking-Using-Ultrametric-Contours-Maps"><a href="#Large-Scale-Multi-Hypotheses-Cell-Tracking-Using-Ultrametric-Contours-Maps" class="headerlink" title="Large-Scale Multi-Hypotheses Cell Tracking Using Ultrametric Contours Maps"></a>Large-Scale Multi-Hypotheses Cell Tracking Using Ultrametric Contours Maps</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04526">http://arxiv.org/abs/2308.04526</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/royerlab/ultrack">https://github.com/royerlab/ultrack</a></li>
<li>paper_authors: Jordão Bragantini, Merlin Lange, Loïc Royer</li>
<li>for: 这篇论文是为了描述一种大规模3D细胞跟踪方法，包括一种选择性分割方法和一种基于最大重叠的分割选择算法。</li>
<li>methods: 该方法使用了一种层次分割假设来计算细胞跟踪和分割，并通过选择不同层次分割来实现细胞跟踪。</li>
<li>results: 该方法在3D图像中实现了状态领先的细胞跟踪结果，并且比使用深度学习方法要快得多。此外，该方法可以支持多种 Cell segmentation 模型，并可以将它们组合成一个 ensemble 来提高跟踪性能。<details>
<summary>Abstract</summary>
In this work, we describe a method for large-scale 3D cell-tracking through a segmentation selection approach. The proposed method is effective at tracking cells across large microscopy datasets on two fronts: (i) It can solve problems containing millions of segmentation instances in terabyte-scale 3D+t datasets; (ii) It achieves competitive results with or without deep learning, which requires 3D annotated data, that is scarce in the fluorescence microscopy field. The proposed method computes cell tracks and segments using a hierarchy of segmentation hypotheses and selects disjoint segments by maximizing the overlap between adjacent frames. We show that this method achieves state-of-the-art results in 3D images from the cell tracking challenge and has a faster integer linear programming formulation. Moreover, our framework is flexible and supports segmentations from off-the-shelf cell segmentation models and can combine them into an ensemble that improves tracking. The code is available https://github.com/royerlab/ultrack.
</details>
<details>
<summary>摘要</summary>
在这个工作中，我们描述了一种大规模3D细胞跟踪方法，通过选择分割选择方法实现。我们提出的方法能够在大规模微型生物图像 dataset 中跟踪细胞，包括：(i) 解决包含数百万个分割实例的 terrabyte 级 3D+t 数据集中的问题;(ii) 在 fluorescence 微型生物图像领域中罕见的3D标注数据不足的情况下，与或 без深度学习模型，达到竞争性的结果。我们的方法计算细胞跟踪和分割使用层次结构的分割假设，并选择不相交的分割。我们展示了该方法在3D图像中的细胞跟踪挑战中达到了状态的前导 результа。此外，我们的框架是灵活的，支持自动生成的细胞分割模型，并可以将其组合成一个 ensemble，以提高跟踪性。代码可以在 https://github.com/royerlab/ultrack 上获取。
</details></li>
</ul>
<hr>
<h2 id="Toward-unlabeled-multi-view-3D-pedestrian-detection-by-generalizable-AI-techniques-and-performance-analysis"><a href="#Toward-unlabeled-multi-view-3D-pedestrian-detection-by-generalizable-AI-techniques-and-performance-analysis" class="headerlink" title="Toward unlabeled multi-view 3D pedestrian detection by generalizable AI: techniques and performance analysis"></a>Toward unlabeled multi-view 3D pedestrian detection by generalizable AI: techniques and performance analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04515">http://arxiv.org/abs/2308.04515</a></li>
<li>repo_url: None</li>
<li>paper_authors: João Paulo Lima, Diego Thomas, Hideaki Uchiyama, Veronica Teichrieb</li>
<li>for: 提高多视图3D人体检测中的泛化能力</li>
<li>methods: 自动标注目标数据和使用无需训练的检测器</li>
<li>results: 使用自动标注方法可以获得更高的泛化性能，比直接使用无需训练的检测器或使用现有的标注源数据训练的检测器更好。<details>
<summary>Abstract</summary>
We unveil how generalizable AI can be used to improve multi-view 3D pedestrian detection in unlabeled target scenes. One way to increase generalization to new scenes is to automatically label target data, which can then be used for training a detector model. In this context, we investigate two approaches for automatically labeling target data: pseudo-labeling using a supervised detector and automatic labeling using an untrained detector (that can be applied out of the box without any training). We adopt a training framework for optimizing detector models using automatic labeling procedures. This framework encompasses different training sets/modes and multi-round automatic labeling strategies. We conduct our analyses on the publicly-available WILDTRACK and MultiviewX datasets. We show that, by using the automatic labeling approach based on an untrained detector, we can obtain superior results than directly using the untrained detector or a detector trained with an existing labeled source dataset. It achieved a MODA about 4% and 1% better than the best existing unlabeled method when using WILDTRACK and MultiviewX as target datasets, respectively.
</details>
<details>
<summary>摘要</summary>
我们揭示了如何使用通用化AI提高多视图3D人体检测在无标目标场景中。一种方法是自动将目标数据标注，然后用于训练检测模型。在这个上下文中，我们研究了两种自动标注目标数据的方法：假标签使用supervised检测器和自动标注使用无学习检测器。我们采用了一个用于优化检测模型的自动标注训练框架。这个框架包括不同的训练集/模式和多轮自动标注策略。我们在公共可用的WILDTRACK和MultiviewX数据集上进行了分析。我们发现，通过使用基于无学习检测器的自动标注方法，可以获得更高的性能，比直接使用无学习检测器或使用现有标注源数据集来训练检测器更好。它在使用WILDTRACK和MultiviewX作为目标数据集时，分别提高了4%和1%。
</details></li>
</ul>
<hr>
<h2 id="When-More-is-Less-Incorporating-Additional-Datasets-Can-Hurt-Performance-By-Introducing-Spurious-Correlations"><a href="#When-More-is-Less-Incorporating-Additional-Datasets-Can-Hurt-Performance-By-Introducing-Spurious-Correlations" class="headerlink" title="When More is Less: Incorporating Additional Datasets Can Hurt Performance By Introducing Spurious Correlations"></a>When More is Less: Incorporating Additional Datasets Can Hurt Performance By Introducing Spurious Correlations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04431">http://arxiv.org/abs/2308.04431</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/basedrhys/ood-generalization">https://github.com/basedrhys/ood-generalization</a></li>
<li>paper_authors: Rhys Compton, Lily Zhang, Aahlad Puli, Rajesh Ranganath</li>
<li>for: 这个研究旨在探讨 whether incorporating more data can always improve machine learning model performance，以及在医学影像数据中存在假相关性的问题。</li>
<li>methods: 这个研究使用了大规模的实验，对四个开源胸部X射线图像集和九个标签进行了组合。</li>
<li>results: 研究发现，在43%的情况下，将两个医院的数据作为训练数据，会使模型在两个医院的数据上具有更差的最坏群体精度。这种结果尽管训练数据更加相似于测试数据，但是由医院特有的图像 artifacts 导致的假相关性的出现。<details>
<summary>Abstract</summary>
In machine learning, incorporating more data is often seen as a reliable strategy for improving model performance; this work challenges that notion by demonstrating that the addition of external datasets in many cases can hurt the resulting model's performance. In a large-scale empirical study across combinations of four different open-source chest x-ray datasets and 9 different labels, we demonstrate that in 43% of settings, a model trained on data from two hospitals has poorer worst group accuracy over both hospitals than a model trained on just a single hospital's data. This surprising result occurs even though the added hospital makes the training distribution more similar to the test distribution. We explain that this phenomenon arises from the spurious correlation that emerges between the disease and hospital, due to hospital-specific image artifacts. We highlight the trade-off one encounters when training on multiple datasets, between the obvious benefit of additional data and insidious cost of the introduced spurious correlation. In some cases, balancing the dataset can remove the spurious correlation and improve performance, but it is not always an effective strategy. We contextualize our results within the literature on spurious correlations to help explain these outcomes. Our experiments underscore the importance of exercising caution when selecting training data for machine learning models, especially in settings where there is a risk of spurious correlations such as with medical imaging. The risks outlined highlight the need for careful data selection and model evaluation in future research and practice.
</details>
<details>
<summary>摘要</summary>
在机器学习中，通常认为更多数据会提高模型性能，但这项工作挑战了这一观点，示出在许多情况下，外部数据集的添加实际上会降低模型性能。我们在四个不同的开源胸部X射线图像集和九个标签之间进行了大规模的实验，发现在43%的情况下，使用两家医院的数据进行训练的模型在两家医院的数据上具有较差的最坏群 accuracy。这种意外的结果尽管训练集在测试集中变得更加相似，但是由医院特有的图像artefact引起的假相关性导致这种现象。我们解释了这种现象的起因，并提出了在多个数据集训练时存在的贸易关系。我们发现在某些情况下，平衡数据可以消除假相关性，提高性能，但并不总是有效的策略。我们将这些结果与文献中的假相关性相关研究进行比较，以帮助解释这些结果。我们的实验警示了在机器学习模型训练时，特别是在医疗影像领域，必须仔细选择训练数据，以避免假相关性的风险。这些风险描述了未来研究和实践中需要进行仔细的数据选择和模型评估。
</details></li>
</ul>
<hr>
<h2 id="A-Deep-Learning-Method-Using-Auto-encoder-and-Generative-Adversarial-Network-for-Anomaly-Detection-on-Ancient-Stone-Stele-Surfaces"><a href="#A-Deep-Learning-Method-Using-Auto-encoder-and-Generative-Adversarial-Network-for-Anomaly-Detection-on-Ancient-Stone-Stele-Surfaces" class="headerlink" title="A Deep-Learning Method Using Auto-encoder and Generative Adversarial Network for Anomaly Detection on Ancient Stone Stele Surfaces"></a>A Deep-Learning Method Using Auto-encoder and Generative Adversarial Network for Anomaly Detection on Ancient Stone Stele Surfaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04426">http://arxiv.org/abs/2308.04426</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yikun Liu, Yuning Wang, Cheng Liu</li>
<li>for: 本研究旨在提供一种深度学习方法，用于自动检测古代石刻上的自然衰老和人工损害。</li>
<li>methods: 该方法使用自动编码器（AE）和生成对抗网络（GAN），不需要大量的异常样本，可以全面检测不可预测的异常。</li>
<li>results: 在使用Longmen洞雕像石刻为案例研究中，提出了一种无监督学习模型，实现了99.74%的重建精度。该方法可以准确地检测七种人工设计的异常，无误告警。<details>
<summary>Abstract</summary>
Accurate detection of natural deterioration and man-made damage on the surfaces of ancient stele in the first instance is essential for their preventive conservation. Existing methods for cultural heritage preservation are not able to achieve this goal perfectly due to the difficulty of balancing accuracy, efficiency, timeliness, and cost. This paper presents a deep-learning method to automatically detect above mentioned emergencies on ancient stone stele in real time, employing autoencoder (AE) and generative adversarial network (GAN). The proposed method overcomes the limitations of existing methods by requiring no extensive anomaly samples while enabling comprehensive detection of unpredictable anomalies. the method includes stages of monitoring, data acquisition, pre-processing, model structuring, and post-processing. Taking the Longmen Grottoes' stone steles as a case study, an unsupervised learning model based on AE and GAN architectures is proposed and validated with a reconstruction accuracy of 99.74\%. The method's evaluation revealed the proficient detection of seven artificially designed anomalies and demonstrated precision and reliability without false alarms. This research provides novel ideas and possibilities for the application of deep learning in the field of cultural heritage.
</details>
<details>
<summary>摘要</summary>
通过检测古代碑刻表面的自然衰败和人工损害，可以采取预防保护措施。现有的文化遗产保护方法不能完全实现这个目标，因为很难平衡准确性、效率、时效性和成本。本文提出了一种基于深度学习的方法，可以在实时中自动检测古代石碑上的紧急情况，使用自适应网络（AE）和生成对抗网络（GAN）。该方法可以减少现有方法的限制，不需要大量的异常样本，同时可以全面检测不可预测的异常。该方法包括监测、数据收集、预处理、模型结构和后处理等阶段。通过使用长门石窟的石碑作为案例研究，我们提出了一种无监督学习模型，并在重建精度为99.74%的基础上验证了其可靠性和精度。测试结果表明该方法可以准确检测七种人工设计的异常情况，而无 FALSE ALARM 问题。这些研究提供了深度学习在文化遗产保护领域的新想法和可能性。
</details></li>
</ul>
<hr>
<h2 id="DiffCR-A-Fast-Conditional-Diffusion-Framework-for-Cloud-Removal-from-Optical-Satellite-Images"><a href="#DiffCR-A-Fast-Conditional-Diffusion-Framework-for-Cloud-Removal-from-Optical-Satellite-Images" class="headerlink" title="DiffCR: A Fast Conditional Diffusion Framework for Cloud Removal from Optical Satellite Images"></a>DiffCR: A Fast Conditional Diffusion Framework for Cloud Removal from Optical Satellite Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04417">http://arxiv.org/abs/2308.04417</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuechao Zou, Kai Li, Junliang Xing, Yu Zhang, Shiying Wang, Lei Jin, Pin Tao</li>
<li>for: 这个论文主要目标是提出一种基于扩散模型的高性能云除法方法，以解决光学卫星图像中云膜的影响。</li>
<li>methods: 该方法基于条件导向扩散模型，并利用深度卷积神经网络进行图像特征提取和云膜模拟。具有独立Encoder来提取条件图像的特征，以保证出处相似的外观信息。同时，我们提出了一种新的时间和条件融合块，以准确模拟条件图像中的出处和目标图像之间的相似性。</li>
<li>results: 我们在两个常用的数据集上进行了广泛的实验评估，并证明了DiffCR在所有指标上均达到了当前最佳性能，其参数和计算复杂度分别为5.1%和5.4%。所有实验结果和代码将在<a target="_blank" rel="noopener" href="https://github.com/XavierJiezou/DiffCR%E4%B8%8A%E5%85%AC%E5%BC%80%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/XavierJiezou/DiffCR上公开发布。</a><details>
<summary>Abstract</summary>
Optical satellite images are a critical data source; however, cloud cover often compromises their quality, hindering image applications and analysis. Consequently, effectively removing clouds from optical satellite images has emerged as a prominent research direction. While recent advancements in cloud removal primarily rely on generative adversarial networks, which may yield suboptimal image quality, diffusion models have demonstrated remarkable success in diverse image-generation tasks, showcasing their potential in addressing this challenge. This paper presents a novel framework called DiffCR, which leverages conditional guided diffusion with deep convolutional networks for high-performance cloud removal for optical satellite imagery. Specifically, we introduce a decoupled encoder for conditional image feature extraction, providing a robust color representation to ensure the close similarity of appearance information between the conditional input and the synthesized output. Moreover, we propose a novel and efficient time and condition fusion block within the cloud removal model to accurately simulate the correspondence between the appearance in the conditional image and the target image at a low computational cost. Extensive experimental evaluations on two commonly used benchmark datasets demonstrate that DiffCR consistently achieves state-of-the-art performance on all metrics, with parameter and computational complexities amounting to only 5.1% and 5.4%, respectively, of those previous best methods. The source code, pre-trained models, and all the experimental results will be publicly available at https://github.com/XavierJiezou/DiffCR upon the paper's acceptance of this work.
</details>
<details>
<summary>摘要</summary>
“Optical 卫星图像是一种重要的数据源；然而，云覆盖通常会降低图像质量，使图像应用和分析变得困难。因此，从云除去技术已成为一个主要的研究方向。而在最近的进展中，大多数研究都基于生成对抗网络，尽管它们可能会导致图像质量下降。Diffusion 模型在多种图像生成任务中表现出色，这表明它们可能会解决这个挑战。本文提出了一个新的框架called DiffCR，它利用 conditional 导向扩散和深度卷积网络来实现高性能的云除去技术。特别是，我们引入了独立的编码器来提取 conditional 图像特征，以确保 conditional 输入和生成输出的外观信息几乎相同。此外，我们还提出了一种新的时间和条件融合块，以准确模拟 conditional 图像中的外观和目标图像之间的对应关系，并且在低计算成本下完成。我们对两种常用的参考数据集进行了广泛的实验评估，结果表明，DiffCR 在所有指标上具有状态之冠的表现，与参数和计算复杂度分别为 5.1% 和 5.4%，与之前最佳方法相比。源代码、预训练模型和所有实验结果将在 https://github.com/XavierJiezou/DiffCR 上公开发布， waits for the paper's acceptance of this work。”
</details></li>
</ul>
<hr>
<h2 id="Digging-into-Depth-Priors-for-Outdoor-Neural-Radiance-Fields"><a href="#Digging-into-Depth-Priors-for-Outdoor-Neural-Radiance-Fields" class="headerlink" title="Digging into Depth Priors for Outdoor Neural Radiance Fields"></a>Digging into Depth Priors for Outdoor Neural Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04413">http://arxiv.org/abs/2308.04413</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/cwchenwang/outdoor-nerf-depth">https://github.com/cwchenwang/outdoor-nerf-depth</a></li>
<li>paper_authors: Chen Wang, Jiadai Sun, Lina Liu, Chenming Wu, Zhelun Shen, Dayan Wu, Yuchao Dai, Liangjun Zhang</li>
<li>for: 本研究旨在探讨在户外NeRF训练中使用深度假设的影响，以解决 radiance fields 中的形态-辐射强度杂化问题。</li>
<li>methods: 本研究使用了两种常见的NeRF方法，并与四种常用的深度假设进行了对比。</li>
<li>results: 实验结果显示了各种深度假设和深度使用方式在户外NeRF训练中的效果，并提供了一些可能有用的实践经验和研究方向。In English, the three key points are:</li>
<li>for: The paper aims to investigate the impact of using depth priors in outdoor NeRF training, to solve the shape-radiance ambiguity problem in radiance fields.</li>
<li>methods: The study uses two commonly used NeRF methods and compares them with four commonly used depth priors.</li>
<li>results: The experimental results show the effects of different depth priors and depth usage strategies in outdoor NeRF training, and provide useful practical experience and research directions.<details>
<summary>Abstract</summary>
Neural Radiance Fields (NeRF) have demonstrated impressive performance in vision and graphics tasks, such as novel view synthesis and immersive reality. However, the shape-radiance ambiguity of radiance fields remains a challenge, especially in the sparse viewpoints setting. Recent work resorts to integrating depth priors into outdoor NeRF training to alleviate the issue. However, the criteria for selecting depth priors and the relative merits of different priors have not been thoroughly investigated. Moreover, the relative merits of selecting different approaches to use the depth priors is also an unexplored problem. In this paper, we provide a comprehensive study and evaluation of employing depth priors to outdoor neural radiance fields, covering common depth sensing technologies and most application ways. Specifically, we conduct extensive experiments with two representative NeRF methods equipped with four commonly-used depth priors and different depth usages on two widely used outdoor datasets. Our experimental results reveal several interesting findings that can potentially benefit practitioners and researchers in training their NeRF models with depth priors. Project Page: https://cwchenwang.github.io/outdoor-nerf-depth
</details>
<details>
<summary>摘要</summary>
神经辐射场（NeRF）在视觉和图形任务中表现出色，如新视角合成和吸引实际。然而，辐射场的形态-辐射权 ambiguity仍然是一大挑战，特别是在稀疏视点设置下。现有研究通过将深度假设 incorporated into outdoor NeRF 训练来解决这个问题。然而，选择depth priors的准则和不同假设的相对优劣还没有进行了全面的研究。此外，使用不同方法选择depth priors的问题也是一个未解决的问题。本文提供了对使用depth priors来outdoor神经辐射场的全面研究和评价，涵盖了常见的深度探测技术和大多数应用方式。特别是，我们进行了两个代表性的NeRF方法和四种常用的深度假设进行了广泛的实验，并在两个广泛使用的户外数据集上进行了extensive experiments。我们的实验结果表明了一些有价值的发现，可能对实践者和研究人员在训练NeRF模型时有所帮助。项目页面：https://cwchenwang.github.io/outdoor-nerf-depth
</details></li>
</ul>
<hr>
<h2 id="V-DETR-DETR-with-Vertex-Relative-Position-Encoding-for-3D-Object-Detection"><a href="#V-DETR-DETR-with-Vertex-Relative-Position-Encoding-for-3D-Object-Detection" class="headerlink" title="V-DETR: DETR with Vertex Relative Position Encoding for 3D Object Detection"></a>V-DETR: DETR with Vertex Relative Position Encoding for 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04409">http://arxiv.org/abs/2308.04409</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yichaoshen-ms/v-detr">https://github.com/yichaoshen-ms/v-detr</a></li>
<li>paper_authors: Yichao Shen, Zigang Geng, Yuhui Yuan, Yutong Lin, Ze Liu, Chunyu Wang, Han Hu, Nanning Zheng, Baining Guo</li>
<li>For: The paper is written for proposing a highly performant 3D object detector for point clouds using the DETR framework.* Methods: The paper introduces a novel 3D Vertex Relative Position Encoding (3DV-RPE) method that computes position encoding for each point based on its relative position to the 3D boxes predicted by the queries in each decoder layer, which helps the model focus on points near the objects and improve object detection accuracy.* Results: The paper achieves significant improvements over the previous 3DETR in $\rm{AP}<em>{25}$&#x2F;$\rm{AP}</em>{50}$ from 65.0%&#x2F;47.0% to 77.8%&#x2F;66.0%, respectively, on the challenging ScanNetV2 benchmark. The method also sets a new record on ScanNetV2 and SUN RGB-D datasets.<details>
<summary>Abstract</summary>
We introduce a highly performant 3D object detector for point clouds using the DETR framework. The prior attempts all end up with suboptimal results because they fail to learn accurate inductive biases from the limited scale of training data. In particular, the queries often attend to points that are far away from the target objects, violating the locality principle in object detection. To address the limitation, we introduce a novel 3D Vertex Relative Position Encoding (3DV-RPE) method which computes position encoding for each point based on its relative position to the 3D boxes predicted by the queries in each decoder layer, thus providing clear information to guide the model to focus on points near the objects, in accordance with the principle of locality. In addition, we systematically improve the pipeline from various aspects such as data normalization based on our understanding of the task. We show exceptional results on the challenging ScanNetV2 benchmark, achieving significant improvements over the previous 3DETR in $\rm{AP}_{25}$/$\rm{AP}_{50}$ from 65.0\%/47.0\% to 77.8\%/66.0\%, respectively. In addition, our method sets a new record on ScanNetV2 and SUN RGB-D datasets.Code will be released at http://github.com/yichaoshen-MS/V-DETR.
</details>
<details>
<summary>摘要</summary>
我们介绍一个高性能的3D物体探测器使用DETR框架。先前的尝试都会得到不佳结果，因为它们无法从训练数据的限制范围中学习正确的归胚。特别是，问题经常对距离目标物体较远的点进行参考，违反了物体探测中的地方性原则。为解决这个限制，我们提出了一个新的3D点 cloud 相对位置编码方法（3DV-RPE），它在每个层的解oder层中计算每个点的位置编码，基于这个点与Predicted 3D Box的相对位置，以提供明确的信息，使模型能够专注于靠近物体的点，遵循物体探测中的地方性原则。此外，我们系统地提高了管线，包括根据我们对任务的认识而进行的数据Normalization。我们在ScanNetV2标准benchmark上获得了出色的结果，从65.0%/47.0%的AP25/AP50提高到77.8%/66.0%，增进了过去3DETR的significant。此外，我们的方法在ScanNetV2和SUN RGB-D数据集上设置了新的纪录。代码将在http://github.com/yichaoshen-MS/V-DETR上发布。
</details></li>
</ul>
<hr>
<h2 id="Person-Re-Identification-without-Identification-via-Event-Anonymization"><a href="#Person-Re-Identification-without-Identification-via-Event-Anonymization" class="headerlink" title="Person Re-Identification without Identification via Event Anonymization"></a>Person Re-Identification without Identification via Event Anonymization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04402">http://arxiv.org/abs/2308.04402</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/IIT-PAVIS/ReId_without_Id">https://github.com/IIT-PAVIS/ReId_without_Id</a></li>
<li>paper_authors: Shafiq Ahmad, Pietro Morerio, Alessio Del Bue</li>
<li>for: 避免人员隐私泄露，对于event-camera视觉应用进行隐私保护。</li>
<li>methods: 提出了一个统一的网络架构，同时实现隐私保护和下游任务（如人ReId）的两重目标。</li>
<li>results: 实现了对于event-camera资料的隐私保护，并在实验中证明了其效果。<details>
<summary>Abstract</summary>
Wide-scale use of visual surveillance in public spaces puts individual privacy at stake while increasing resource consumption (energy, bandwidth, and computation). Neuromorphic vision sensors (event-cameras) have been recently considered a valid solution to the privacy issue because they do not capture detailed RGB visual information of the subjects in the scene. However, recent deep learning architectures have been able to reconstruct images from event cameras with high fidelity, reintroducing a potential threat to privacy for event-based vision applications. In this paper, we aim to anonymize event-streams to protect the identity of human subjects against such image reconstruction attacks. To achieve this, we propose an end-to-end network architecture jointly optimized for the twofold objective of preserving privacy and performing a downstream task such as person ReId. Our network learns to scramble events, enforcing the degradation of images recovered from the privacy attacker. In this work, we also bring to the community the first ever event-based person ReId dataset gathered to evaluate the performance of our approach. We validate our approach with extensive experiments and report results on the synthetic event data simulated from the publicly available SoftBio dataset and our proposed Event-ReId dataset.
</details>
<details>
<summary>摘要</summary>
广泛使用视觉监测在公共空间 puts 个人隐私受到威胁，同时增加资源消耗（能源、带宽、计算）。 neuromorphic vision sensors（事件摄像头）在最近被视为隐私问题的有效解决方案，因为它们不捕捉Scene中主体的详细RGB视觉信息。然而，最近的深度学习架构可以很好地从事件摄像头中重建图像，重新引入隐私问题 для事件视觉应用。在这篇论文中，我们想要匿名事件流以保护人类主体的身份 against 这种图像重建攻击。为了实现这一目标，我们提议了一个综合架构，该架构同时满足隐私保护和下游任务（如人ReId）的两重目标。我们的网络学习混合事件，使得恢复图像的攻击者难以获得有用信息。在这项工作中，我们还为社区提供了首次使用事件基于人ReId数据集进行评估我们的方法的机会。我们通过了详细的实验，并在Synthetic事件数据和我们提出的Event-ReId数据集上进行了评估。
</details></li>
</ul>
<hr>
<h2 id="LEFormer-A-Hybrid-CNN-Transformer-Architecture-for-Accurate-Lake-Extraction-from-Remote-Sensing-Imagery"><a href="#LEFormer-A-Hybrid-CNN-Transformer-Architecture-for-Accurate-Lake-Extraction-from-Remote-Sensing-Imagery" class="headerlink" title="LEFormer: A Hybrid CNN-Transformer Architecture for Accurate Lake Extraction from Remote Sensing Imagery"></a>LEFormer: A Hybrid CNN-Transformer Architecture for Accurate Lake Extraction from Remote Sensing Imagery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04397">http://arxiv.org/abs/2308.04397</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ben Chen, Xuechao Zou, Yu Zhang, Jiayu Li, Kai Li, Pin Tao</li>
<li>For: Accurate lake extraction from remote sensing imagery.* Methods: Hybrid CNN-Transformer architecture (LEFormer) with four main modules: CNN encoder, Transformer encoder, cross-encoder fusion, and lightweight decoder.* Results: Consistently achieves state-of-the-art (SOTA) performance and efficiency on two datasets (Surface Water and Qinghai-Tibet Plateau Lake) with mIoU scores of 90.86% and 97.42%, outperforming existing methods while being 20x more efficient.<details>
<summary>Abstract</summary>
Lake extraction from remote sensing imagery is challenging due to the complex shapes of lakes and the presence of noise. Existing methods suffer from blurred segmentation boundaries and poor foreground modeling. In this paper, we propose a hybrid CNN-Transformer architecture, called LEFormer, for accurate lake extraction. LEFormer contains four main modules: CNN encoder, Transformer encoder, cross-encoder fusion, and lightweight decoder. The CNN encoder recovers local spatial information and improves fine-scale details. Simultaneously, the Transformer encoder captures long-range dependencies between sequences of any length, allowing them to obtain global features and context information better. Finally, a lightweight decoder is employed for mask prediction. We evaluate the performance and efficiency of LEFormer on two datasets, the Surface Water (SW) and the Qinghai-Tibet Plateau Lake (QTPL). Experimental results show that LEFormer consistently achieves state-of-the-art (SOTA) performance and efficiency on these two datasets, outperforming existing methods. Specifically, LEFormer achieves 90.86% and 97.42% mIoU on the SW and QTPL datasets with a parameter count of 3.61M, respectively, while being 20x minor than the previous SOTA method.
</details>
<details>
<summary>摘要</summary>
湖水抽取从遥感影像中是一项复杂的任务，由于湖泊的复杂形态和干扰的存在。现有的方法受到模糊的分割边界和质地模型的限制。在这篇论文中，我们提出了一种混合CNN-Transformer架构，称为LEFormer，用于准确的湖水抽取。LEFormer包括四个主要模块：CNN编码器、Transformer编码器、交叉编码器融合和轻量级解码器。CNN编码器恢复本地空间信息，提高细致细节。同时，Transformer编码器捕捉任意长度序列之间的长距离依赖关系，以获得更好的全球特征和上下文信息。最后，一个轻量级解码器被employmed для推测Mask。我们对LEFormer在两个数据集上进行了性能和效率测试，结果表明LEFormer在这两个数据集上具有SOTA性能和效率，并且在参数计数3.61M的情况下，与之前的SOTA方法相比，LEFormer的参数计数减少了20倍。特别是，LEFormer在SW数据集上达到了90.86%和QTPL数据集上达到了97.42%的mIoU，而且参数计数只有3.61M。
</details></li>
</ul>
<hr>
<h2 id="Data-Augmentation-Based-Unsupervised-Domain-Adaptation-In-Medical-Imaging"><a href="#Data-Augmentation-Based-Unsupervised-Domain-Adaptation-In-Medical-Imaging" class="headerlink" title="Data Augmentation-Based Unsupervised Domain Adaptation In Medical Imaging"></a>Data Augmentation-Based Unsupervised Domain Adaptation In Medical Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04395">http://arxiv.org/abs/2308.04395</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sebastian Nørgaard Llambias, Mads Nielsen, Mostafa Mehdipour Ghazi</li>
<li>for: 这个论文是为了提高医疗成像中的深度学习模型对新扫描的数据统一性，以便更好地应用到临床实践中。</li>
<li>methods: 这个方法使用了MRI特有的增强技术，并进行了广泛的实验，评估了不同数据集、模式、分类任务中的表现。</li>
<li>results: 结果显示，该方法能够实现高精度、广泛适用和对数据集shift具有强大的韧性，在大多数情况下超越了现有的表现。<details>
<summary>Abstract</summary>
Deep learning-based models in medical imaging often struggle to generalize effectively to new scans due to data heterogeneity arising from differences in hardware, acquisition parameters, population, and artifacts. This limitation presents a significant challenge in adopting machine learning models for clinical practice. We propose an unsupervised method for robust domain adaptation in brain MRI segmentation by leveraging MRI-specific augmentation techniques. To evaluate the effectiveness of our method, we conduct extensive experiments across diverse datasets, modalities, and segmentation tasks, comparing against the state-of-the-art methods. The results show that our proposed approach achieves high accuracy, exhibits broad applicability, and showcases remarkable robustness against domain shift in various tasks, surpassing the state-of-the-art performance in the majority of cases.
</details>
<details>
<summary>摘要</summary>
深度学习模型在医疗影像中经常陷于新扫描数据不好适应的问题，这导致模型在实际应用中表现不佳。我们提出了一种无监督的多元领域适应方法，通过利用特定于MRI的扩展技术来强化模型的鲁棒性。为评估我们的方法的有效性，我们在多个数据集、模式和分割任务中进行了广泛的实验，与当前最佳方法进行比较。结果显示，我们的提议方法在多个任务中达到了高精度，具有广泛的应用性和强大的鲁棒性，在大多数情况下超过了当前最佳性能。
</details></li>
</ul>
<hr>
<h2 id="DELFlow-Dense-Efficient-Learning-of-Scene-Flow-for-Large-Scale-Point-Clouds"><a href="#DELFlow-Dense-Efficient-Learning-of-Scene-Flow-for-Large-Scale-Point-Clouds" class="headerlink" title="DELFlow: Dense Efficient Learning of Scene Flow for Large-Scale Point Clouds"></a>DELFlow: Dense Efficient Learning of Scene Flow for Large-Scale Point Clouds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04383">http://arxiv.org/abs/2308.04383</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/IRMVLab/DELFlow">https://github.com/IRMVLab/DELFlow</a></li>
<li>paper_authors: Chensheng Peng, Guangming Wang, Xian Wan Lo, Xinrui Wu, Chenfeng Xu, Masayoshi Tomizuka, Wei Zhan, Hesheng Wang</li>
<li>for: 用于解决点云模式下场景流计算中的缺失问题，提高场景流计算的效率和准确性。</li>
<li>methods: 使用精度补做法将原始点云转换为 dense 格式，并使用新的投影减小信息损失问题。</li>
<li>results: 与优先艺术相比，该方法在 FlyingThings3D 和 KITTI 数据集上实现了更高的效率和准确性。<details>
<summary>Abstract</summary>
Point clouds are naturally sparse, while image pixels are dense. The inconsistency limits feature fusion from both modalities for point-wise scene flow estimation. Previous methods rarely predict scene flow from the entire point clouds of the scene with one-time inference due to the memory inefficiency and heavy overhead from distance calculation and sorting involved in commonly used farthest point sampling, KNN, and ball query algorithms for local feature aggregation. To mitigate these issues in scene flow learning, we regularize raw points to a dense format by storing 3D coordinates in 2D grids. Unlike the sampling operation commonly used in existing works, the dense 2D representation 1) preserves most points in the given scene, 2) brings in a significant boost of efficiency, and 3) eliminates the density gap between points and pixels, allowing us to perform effective feature fusion. We also present a novel warping projection technique to alleviate the information loss problem resulting from the fact that multiple points could be mapped into one grid during projection when computing cost volume. Sufficient experiments demonstrate the efficiency and effectiveness of our method, outperforming the prior-arts on the FlyingThings3D and KITTI dataset.
</details>
<details>
<summary>摘要</summary>
点云自然 sparse，而图像像素 dense。这种不一致性限制了从两个Modalities的特征融合，用于点云流场估计。前一代方法rarely predict scene flow from the entire point clouds of the scene with one-time inference due to memory inefficiency and heavy overhead from distance calculation and sorting involved in commonly used farthest point sampling, KNN, and ball query algorithms for local feature aggregation. To mitigate these issues in scene flow learning, we regularize raw points to a dense format by storing 3D coordinates in 2D grids. Unlike the sampling operation commonly used in existing works, the dense 2D representation 1) preserves most points in the given scene, 2) brings in a significant boost of efficiency, and 3) eliminates the density gap between points and pixels, allowing us to perform effective feature fusion. We also present a novel warping projection technique to alleviate the information loss problem resulting from the fact that multiple points could be mapped into one grid during projection when computing cost volume. Sufficient experiments demonstrate the efficiency and effectiveness of our method, outperforming the prior-arts on the FlyingThings3D and KITTI dataset.Here's a word-for-word translation of the text into Simplified Chinese:点云自然 sparse，而图像像素 dense。这种不一致性限制了从两个Modalities的特征融合，用于点云流场估计。前一代方法rarely predict scene flow from the entire point clouds of the scene with one-time inference due to memory inefficiency and heavy overhead from distance calculation and sorting involved in commonly used farthest point sampling, KNN, and ball query algorithms for local feature aggregation。 To mitigate these issues in scene flow learning, we regularize raw points to a dense format by storing 3D coordinates in 2D grids。 Unlike the sampling operation commonly used in existing works, the dense 2D representation 1) preserves most points in the given scene, 2) brings in a significant boost of efficiency, and 3) eliminates the density gap between points and pixels, allowing us to perform effective feature fusion。 We also present a novel warping projection technique to alleviate the information loss problem resulting from the fact that multiple points could be mapped into one grid during projection when computing cost volume。 Sufficient experiments demonstrate the efficiency and effectiveness of our method, outperforming the prior-arts on the FlyingThings3D and KITTI dataset。
</details></li>
</ul>
<hr>
<h2 id="Your-Negative-May-not-Be-True-Negative-Boosting-Image-Text-Matching-with-False-Negative-Elimination"><a href="#Your-Negative-May-not-Be-True-Negative-Boosting-Image-Text-Matching-with-False-Negative-Elimination" class="headerlink" title="Your Negative May not Be True Negative: Boosting Image-Text Matching with False Negative Elimination"></a>Your Negative May not Be True Negative: Boosting Image-Text Matching with False Negative Elimination</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04380">http://arxiv.org/abs/2308.04380</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luminosityx/fne">https://github.com/luminosityx/fne</a></li>
<li>paper_authors: Haoxuan Li, Yi Bin, Junrong Liao, Yang Yang, Heng Tao Shen</li>
<li>for: 提高图文匹配模型的表现，减少假性负样本的影响</li>
<li>methods: 提出了一种False Negative Elimination（FNE）策略，通过样本选择来避免假性负样本的影响，并通过权重赋值来强制模型对假性负样本进行学习</li>
<li>results: 经过广泛的实验 validate 了我们的提案，在Flickr30K和MS-COCO数据集上达到了比较好的表现，并且在假性负样本的存在下保持了模型的表现稳定性。<details>
<summary>Abstract</summary>
Most existing image-text matching methods adopt triplet loss as the optimization objective, and choosing a proper negative sample for the triplet of <anchor, positive, negative> is important for effectively training the model, e.g., hard negatives make the model learn efficiently and effectively. However, we observe that existing methods mainly employ the most similar samples as hard negatives, which may not be true negatives. In other words, the samples with high similarity but not paired with the anchor may reserve positive semantic associations, and we call them false negatives. Repelling these false negatives in triplet loss would mislead the semantic representation learning and result in inferior retrieval performance. In this paper, we propose a novel False Negative Elimination (FNE) strategy to select negatives via sampling, which could alleviate the problem introduced by false negatives. Specifically, we first construct the distributions of positive and negative samples separately via their similarities with the anchor, based on the features extracted from image and text encoders. Then we calculate the false negative probability of a given sample based on its similarity with the anchor and the above distributions via the Bayes' rule, which is employed as the sampling weight during negative sampling process. Since there may not exist any false negative in a small batch size, we design a memory module with momentum to retain a large negative buffer and implement our negative sampling strategy spanning over the buffer. In addition, to make the model focus on hard negatives, we reassign the sampling weights for the simple negatives with a cut-down strategy. The extensive experiments are conducted on Flickr30K and MS-COCO, and the results demonstrate the superiority of our proposed false negative elimination strategy. The code is available at https://github.com/LuminosityX/FNE.
</details>
<details>
<summary>摘要</summary>
现有的图像文本匹配方法大多采用 triplet loss 作为优化目标，选择正确的负样本 для triplet 中的链接、正例和负例是重要的，以提高模型的训练效率和效果。然而，我们发现现有的方法主要使用最相似的样本作为负样本，这可能不是真正的负例。即，具有高相似度但不是链接的样本可能具有正面 semantic association，我们称之为假负例。对 triplet loss 中的这种假负例的排斥会导致 semantic representation 的学习受到干扰，结果导致对图像文本匹配的 Retrieval 性能下降。在这篇文章中，我们提出了一个 False Negative Elimination (FNE) 策略，用于选择负例via sampling，以解决上述问题。具体来说，我们首先将图像和文本编码器提取出的特征用于分别建立正例和负例的分布，然后计算对链接的 false negative probability 基于它们的相似度和上述分布，并运用 Bayes 规则作为 sampling weight。在小批量大小中可能没有假负例，我们设计了一个内存模组，以维持一个大型的负例缓存，并实现我们的负例抽样策略。此外，为使模型专注于困难的负例，我们将简单的负例重新分配 sampling weight 的策略。实验结果显示，我们提出的 False Negative Elimination 策略在 Flickr30K 和 MS-COCO 上得到了优异的结果。代码可以在 https://github.com/LuminosityX/FNE 上获取。
</details></li>
</ul>
<hr>
<h2 id="Pelta-Shielding-Transformers-to-Mitigate-Evasion-Attacks-in-Federated-Learning"><a href="#Pelta-Shielding-Transformers-to-Mitigate-Evasion-Attacks-in-Federated-Learning" class="headerlink" title="Pelta: Shielding Transformers to Mitigate Evasion Attacks in Federated Learning"></a>Pelta: Shielding Transformers to Mitigate Evasion Attacks in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04373">http://arxiv.org/abs/2308.04373</a></li>
<li>repo_url: None</li>
<li>paper_authors: Simon Queyrut, Yérom-David Bromberg, Valerio Schiavoni</li>
<li>for: 保护 Federated Learning 中的机器学习模型更新，以保持用户数据隐私，并且防止恶意客户端探测模型内部。</li>
<li>methods: Pelta 是一种新的防御机制，利用可信硬件（TEEs）来隐藏部分反Prop链规则，防止攻击者利用这些规则设计恶意样本。</li>
<li>results: Pelta 在一个 state-of-the-art 的集成模型上进行评估，并证明其效iveness  против Self Attention Gradient 攻击。<details>
<summary>Abstract</summary>
The main premise of federated learning is that machine learning model updates are computed locally, in particular to preserve user data privacy, as those never leave the perimeter of their device. This mechanism supposes the general model, once aggregated, to be broadcast to collaborating and non malicious nodes. However, without proper defenses, compromised clients can easily probe the model inside their local memory in search of adversarial examples. For instance, considering image-based applications, adversarial examples consist of imperceptibly perturbed images (to the human eye) misclassified by the local model, which can be later presented to a victim node's counterpart model to replicate the attack. To mitigate such malicious probing, we introduce Pelta, a novel shielding mechanism leveraging trusted hardware. By harnessing the capabilities of Trusted Execution Environments (TEEs), Pelta masks part of the back-propagation chain rule, otherwise typically exploited by attackers for the design of malicious samples. We evaluate Pelta on a state of the art ensemble model and demonstrate its effectiveness against the Self Attention Gradient adversarial Attack.
</details>
<details>
<summary>摘要</summary>
主要假设联邦学习的概念是，机器学习模型的更新是在本地进行，具体是为了维护用户数据隐私，因为这些数据从不会离开用户的设备。这个机制假设整个模型，一旦统计，会被协力且不可靠的节点所传递。但是， Without proper defenses, compromised clients can easily probe the model inside their local memory in search of adversarial examples. For instance, considering image-based applications, adversarial examples consist of imperceptibly perturbed images (to the human eye) misclassified by the local model, which can be later presented to a victim node's counterpart model to replicate the attack. To mitigate such malicious probing, we introduce Pelta, a novel shielding mechanism leveraging trusted hardware. By harnessing the capabilities of Trusted Execution Environments (TEEs), Pelta masks part of the back-propagation chain rule, otherwise typically exploited by attackers for the design of malicious samples. We evaluate Pelta on a state of the art ensemble model and demonstrate its effectiveness against the Self Attention Gradient adversarial Attack.Here's a word-for-word translation of the text into Simplified Chinese:主要假设联邦学习的概念是，机器学习模型的更新是在本地进行，具体是为了保护用户数据隐私，因为这些数据从不会离开用户的设备。这个机制假设整个模型，一旦统计，会被协力且不可靠的节点所传递。但是，无法防止受损客户端可以轻松地在本地内存中探测模型，寻找攻击性的例子。例如，考虑图像基于应用程序，攻击性的例子包括不可见地修改图像（对人类眼可见），使本地模型错误分类，这些修改图像可以在后来被让客户端对方的模型中复制攻击。为了消除这种恶意探测，我们介绍了Pelta，一种新的遮盾机制，利用可信硬件。通过利用可信执行环境（TEEs）的能力，Pelta遮盖一部分的反向传播链规则，通常由攻击者利用来设计恶意样本。我们对一个现代集成模型进行评估，并证明Pelta在自注意Gradient攻击下的效果。
</details></li>
</ul>
<hr>
<h2 id="When-Super-Resolution-Meets-Camouflaged-Object-Detection-A-Comparison-Study"><a href="#When-Super-Resolution-Meets-Camouflaged-Object-Detection-A-Comparison-Study" class="headerlink" title="When Super-Resolution Meets Camouflaged Object Detection: A Comparison Study"></a>When Super-Resolution Meets Camouflaged Object Detection: A Comparison Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04370">http://arxiv.org/abs/2308.04370</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juan Wen, Shupeng Cheng, Peng Xu, Bowen Zhou, Radu Timofte, Weiyan Hou, Luc Van Gool</li>
<li>for: 本研究旨在探讨超解像（SR）和掩蔽物检测（COD）两个领域的共同应用，如低分辨率监测图像可以通过超解像技术进行进一步加工，并且使用COD模型进行掩蔽物检测。</li>
<li>methods: 本研究使用了不同的SR方法在通常使用的COD数据集上进行比较性评估，同时使用SR处理的COD数据集来评估不同的COD模型的Robustness。</li>
<li>results: 本研究通过对SR和COD两个领域的综合评估，探讨了这两个领域之间的关系，发现了一些新的实验现象，并summarized新的研究方向。<details>
<summary>Abstract</summary>
Super Resolution (SR) and Camouflaged Object Detection (COD) are two hot topics in computer vision with various joint applications. For instance, low-resolution surveillance images can be successively processed by super-resolution techniques and camouflaged object detection. However, in previous work, these two areas are always studied in isolation. In this paper, we, for the first time, conduct an integrated comparative evaluation for both. Specifically, we benchmark different super-resolution methods on commonly used COD datasets, and meanwhile, we evaluate the robustness of different COD models by using COD data processed by SR methods. Our goal is to bridge these two domains, discover novel experimental phenomena, summarize new experim.
</details>
<details>
<summary>摘要</summary>
superResolution (SR) 和 camouflagedObjectDetection (COD) 是计算机视觉中两个热门的话题，它们在各种应用场景中可以结合使用。例如，低分辨率的视频监测图像可以被一次接一次地处理superResolution 技术，并且使用 COD 模型进行掩蔽物检测。然而，在过去的研究中，这两个领域一直被研究独立。在这篇论文中，我们首次对这两个领域进行了集成性评估。 Specifically, we 对常用的 COD 数据集进行了不同的 superResolution 方法的比较，而同时，我们也使用 SR 方法处理 COD 数据来评估 COD 模型的可靠性。我们的目标是将这两个领域相连，发现新的实验现象，总结新的经验。
</details></li>
</ul>
<hr>
<h2 id="SSTFormer-Bridging-Spiking-Neural-Network-and-Memory-Support-Transformer-for-Frame-Event-based-Recognition"><a href="#SSTFormer-Bridging-Spiking-Neural-Network-and-Memory-Support-Transformer-for-Frame-Event-based-Recognition" class="headerlink" title="SSTFormer: Bridging Spiking Neural Network and Memory Support Transformer for Frame-Event based Recognition"></a>SSTFormer: Bridging Spiking Neural Network and Memory Support Transformer for Frame-Event based Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04369">http://arxiv.org/abs/2308.04369</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/event-ahu/sstformer">https://github.com/event-ahu/sstformer</a></li>
<li>paper_authors: Xiao Wang, Zongzhen Wu, Yao Rong, Lin Zhu, Bo Jiang, Jin Tang, Yonghong Tian</li>
<li>for: 这个论文的目的是提出一个新的RGB架构对照数据推导架构，用于融合RGB帧和事件流进行模式识别。</li>
<li>methods: 本论文使用了一个新的混合模式识别架构，包括内存支持transformer网络、对原始事件流进行编码、多模式瓶颈融合模组和预测头。</li>
<li>results: 实验结果显示，提出的混合模式识别架构可以实现高性能和能效的模式识别，并且可以处理RGB帧和事件流的融合运算。<details>
<summary>Abstract</summary>
Event camera-based pattern recognition is a newly arising research topic in recent years. Current researchers usually transform the event streams into images, graphs, or voxels, and adopt deep neural networks for event-based classification. Although good performance can be achieved on simple event recognition datasets, however, their results may be still limited due to the following two issues. Firstly, they adopt spatial sparse event streams for recognition only, which may fail to capture the color and detailed texture information well. Secondly, they adopt either Spiking Neural Networks (SNN) for energy-efficient recognition with suboptimal results, or Artificial Neural Networks (ANN) for energy-intensive, high-performance recognition. However, seldom of them consider achieving a balance between these two aspects. In this paper, we formally propose to recognize patterns by fusing RGB frames and event streams simultaneously and propose a new RGB frame-event recognition framework to address the aforementioned issues. The proposed method contains four main modules, i.e., memory support Transformer network for RGB frame encoding, spiking neural network for raw event stream encoding, multi-modal bottleneck fusion module for RGB-Event feature aggregation, and prediction head. Due to the scarce of RGB-Event based classification dataset, we also propose a large-scale PokerEvent dataset which contains 114 classes, and 27102 frame-event pairs recorded using a DVS346 event camera. Extensive experiments on two RGB-Event based classification datasets fully validated the effectiveness of our proposed framework. We hope this work will boost the development of pattern recognition by fusing RGB frames and event streams. Both our dataset and source code of this work will be released at https://github.com/Event-AHU/SSTFormer.
</details>
<details>
<summary>摘要</summary>
event镜头基于模式识别是一个相对较新的研究领域，现有研究者通常将事件流转换为图像、图表或 voxel，并采用深度神经网络进行事件基本类型的识别。尽管在简单的事件识别数据上可以获得良好的性能，但是其结果可能受到以下两个问题的限制。首先，他们仅使用空间稀疏的事件流进行识别，这可能会忽略颜色和细节 тексту层的信息。其次，他们可能采用神经元突发网络（SNN）进行能效识别，或者人工神经网络（ANN）进行能量浪费、高性能识别。然而，很少的人会考虑在这两个方面寻求平衡。在本文中，我们正式提出将RGB帧和事件流同时识别，并提出了一种新的RGB帧-事件识别框架。该框架包括四个主要模块：记忆支持变换网络 дляRGB帧编码、突发神经网络 для raw事件流编码、多模态瓶颈融合模块 дляRGB-Event特征聚合，以及预测头。由于RGB-Event基本类型的识别数据稀缺，我们还提出了一个大规模的PokerEvent数据集，该数据集包含114个类别，27102帧-事件对。我们对两个RGB-Event基本类型的识别数据集进行了广泛的实验，并证明了我们提出的框架的效果。我们希望这种工作能够促进RGB帧和事件流的模式识别的发展。我们的数据集和源代码将在https://github.com/Event-AHU/SSTFormer上发布。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/09/cs.CV_2023_08_09/" data-id="clogyj8xi00fm7cra2l9xf7sa" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/09/cs.AI_2023_08_09/" class="article-date">
  <time datetime="2023-08-09T12:00:00.000Z" itemprop="datePublished">2023-08-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/09/cs.AI_2023_08_09/">cs.AI - 2023-08-09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="MetRoBERTa-Leveraging-Traditional-Customer-Relationship-Management-Data-to-Develop-a-Transit-Topic-Aware-Language-Model"><a href="#MetRoBERTa-Leveraging-Traditional-Customer-Relationship-Management-Data-to-Develop-a-Transit-Topic-Aware-Language-Model" class="headerlink" title="MetRoBERTa: Leveraging Traditional Customer Relationship Management Data to Develop a Transit-Topic-Aware Language Model"></a>MetRoBERTa: Leveraging Traditional Customer Relationship Management Data to Develop a Transit-Topic-Aware Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05012">http://arxiv.org/abs/2308.05012</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Leong, Awad Abdelhalim, Jude Ha, Dianne Patterson, Gabriel L. Pincus, Anthony B. Harris, Michael Eichler, Jinhua Zhao</li>
<li>for: 了解旅客对公共交通服务的反馈，以优化服务质量和满意度。</li>
<li>methods: 利用传统的公共交通客户关系管理（CRM）反馈，开发和部署一种基于语言模型（LLM）的公共交通专题检测系统，以分类开放式文本反馈。</li>
<li>results: 使用半监督学习引擎团队建立了11个广泛的公共交通主题，并使用这些数据来训练和评估一种基于RoBERTa架构的语言模型。该模型在所有评价指标上都超过了经典机器学习方法，提供了90%的主题分类精度。<details>
<summary>Abstract</summary>
Transit riders' feedback provided in ridership surveys, customer relationship management (CRM) channels, and in more recent times, through social media is key for transit agencies to better gauge the efficacy of their services and initiatives. Getting a holistic understanding of riders' experience through the feedback shared in those instruments is often challenging, mostly due to the open-ended, unstructured nature of text feedback. In this paper, we propose leveraging traditional transit CRM feedback to develop and deploy a transit-topic-aware large language model (LLM) capable of classifying open-ended text feedback to relevant transit-specific topics. First, we utilize semi-supervised learning to engineer a training dataset of 11 broad transit topics detected in a corpus of 6 years of customer feedback provided to the Washington Metropolitan Area Transit Authority (WMATA). We then use this dataset to train and thoroughly evaluate a language model based on the RoBERTa architecture. We compare our LLM, MetRoBERTa, to classical machine learning approaches utilizing keyword-based and lexicon representations. Our model outperforms those methods across all evaluation metrics, providing an average topic classification accuracy of 90%. Finally, we provide a value proposition of this work demonstrating how the language model, alongside additional text processing tools, can be applied to add structure to open-ended text sources of feedback like Twitter. The framework and results we present provide a pathway for an automated, generalizable approach for ingesting, visualizing, and reporting transit riders' feedback at scale, enabling agencies to better understand and improve customer experience.
</details>
<details>
<summary>摘要</summary>
公共交通使用者的反馈，从乘客关系管理（CRM）渠道、客户反馈Surveys以及最近的社交媒体，对公共交通机构来说非常重要。通过反馈来了解乘客的体验，可以帮助机构更好地了解自己的服务和活动的效果。然而，由于反馈的开放性和无结构性，通常是困难的获得整体的理解。在这篇文章中，我们提议利用传统的公共交通CRM反馈，开发和部署一个具有公共交通话题意识的大语言模型（LLM），可以将开放式文本反馈分类到相关的公共交通话题。我们首先利用半监督学习，engineer一个训练集，其中包含6年的客户反馈数据，来自华盛顿都会区公共交通管理局（WMATA）。然后，我们使用这个数据集来训练和评估一个基于RoBERTa架构的语言模型。我们与键字基本架构和词汇表表示方法进行比较。我们的模型在所有评价指标上都高于这些方法，提供了90%的话题分类精度。最后，我们提供了这种工作的价值提案，说明如何使用语言模型， alongside其他文本处理工具，对开放式文本反馈 sources like Twitter进行结构化处理，以提高客户体验的理解和改进。我们的框架和结果提供了一种可扩展的自动化方法，可以在大规模的客户反馈数据中快速、自动地进行分类和报告，帮助机构更好地了解和改进客户体验。
</details></li>
</ul>
<hr>
<h2 id="AspectMMKG-A-Multi-modal-Knowledge-Graph-with-Aspect-aware-Entities"><a href="#AspectMMKG-A-Multi-modal-Knowledge-Graph-with-Aspect-aware-Entities" class="headerlink" title="AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities"></a>AspectMMKG: A Multi-modal Knowledge Graph with Aspect-aware Entities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04992">http://arxiv.org/abs/2308.04992</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thezjd/aspectmmkg">https://github.com/thezjd/aspectmmkg</a></li>
<li>paper_authors: Jingdan Zhang, Jiaan Wang, Xiaodan Wang, Zhixu Li, Yanghua Xiao<br>for:这 paper 的目的是构建一个基于多modal数据的实体知识图(MMKG)，以便更全面地理解实体的多个方面。methods:这 paper 使用了一种新的方法，即匹配实体图像与不同的实体方面，以扩展现有的 MMKG。这种方法包括从知识库中收集方面相关的图像，并从知识库中提取方面相关的句子作为查询来 Retrieving a large number of aspect-related images via an online image search engine。results:这 paper constructed a new MMKG called AspectMMKG, which contains 2,380 entities, 18,139 entity aspects, and 645,383 aspect-related images. 这 paper  также提出了一种新的实体方面相关图像检索(AIR)模型，可以更正和扩展 AspectMMKG 中的实体图像。这种模型通过将实体图像、实体方面和相关图像信息integrate into一个模型来学习实体图像与方面相关图像之间的关系。实验结果表明，AIR 模型可以为给定的实体 Retrieves suitable images for different aspects.<details>
<summary>Abstract</summary>
Multi-modal knowledge graphs (MMKGs) combine different modal data (e.g., text and image) for a comprehensive understanding of entities. Despite the recent progress of large-scale MMKGs, existing MMKGs neglect the multi-aspect nature of entities, limiting the ability to comprehend entities from various perspectives. In this paper, we construct AspectMMKG, the first MMKG with aspect-related images by matching images to different entity aspects. Specifically, we collect aspect-related images from a knowledge base, and further extract aspect-related sentences from the knowledge base as queries to retrieve a large number of aspect-related images via an online image search engine. Finally, AspectMMKG contains 2,380 entities, 18,139 entity aspects, and 645,383 aspect-related images. We demonstrate the usability of AspectMMKG in entity aspect linking (EAL) downstream task and show that previous EAL models achieve a new state-of-the-art performance with the help of AspectMMKG. To facilitate the research on aspect-related MMKG, we further propose an aspect-related image retrieval (AIR) model, that aims to correct and expand aspect-related images in AspectMMKG. We train an AIR model to learn the relationship between entity image and entity aspect-related images by incorporating entity image, aspect, and aspect image information. Experimental results indicate that the AIR model could retrieve suitable images for a given entity w.r.t different aspects.
</details>
<details>
<summary>摘要</summary>
多modal知识图（MMKG）结合不同模式数据（例如文本和图像）以实现实体的全面理解。虽然最近大规模的 MMKG 已经取得了进展，但现有 MMKG 忽视实体的多方面性，限制了从不同角度理解实体的能力。在本文中，我们构建了 AspectMMKG，首个基于实体方面的图像的 MMKG。具体来说，我们从知识库中收集了实体方面的图像，并从知识库中提取实体方面相关的句子作为查询来 retrieve 大量实体方面相关的图像 via 在线图像搜索引擎。最后，AspectMMKG 包含 2,380 个实体、18,139 个实体方面、645,383 个实体方面相关的图像。我们示出了 AspectMMKG 在实体方面链接（EAL）下游任务中的可用性，并证明了前一个 EAL 模型在 AspectMMKG 的帮助下实现了新的州OF-THE-ART 性能。为便于研究实体方面相关的 MMKG，我们还提出了一种实体方面相关的图像检索（AIR）模型，该模型 aimed 学习实体图像和实体方面相关图像之间的关系。我们在 AIR 模型中包含实体图像、实体方面和实体方面相关图像信息。实验结果表明，AIR 模型可以为给定实体 Retrieval 相关的图像。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Multilingual-Text-Data-Distillation"><a href="#Exploring-Multilingual-Text-Data-Distillation" class="headerlink" title="Exploring Multilingual Text Data Distillation"></a>Exploring Multilingual Text Data Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04982">http://arxiv.org/abs/2308.04982</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/harshp1802/text-dataset-distillation">https://github.com/harshp1802/text-dataset-distillation</a></li>
<li>paper_authors: Shivam Sahni, Harsh Patel</li>
<li>for: 这篇论文主要用于提出多语言文本分类数据簇范例的数据簇范例，并且运用语言模型学习方法来进行数据簇范例。</li>
<li>methods: 本文提出了多种文本数据簇范例的方法，包括语言模型基于学习方法，以及跨架构对应的数据簇范例。</li>
<li>results: 本文的实验结果显示，这些方法可以实现高度的分类强度，并且具有跨架构对应的数据簇范例能力。此外，本文也 investigate了这些方法对不同语言的公平性。<details>
<summary>Abstract</summary>
With the rise of deep learning, large datasets and complex models have become common, requiring significant computing power. To address this, data distillation has emerged as a technique to quickly train models with lower memory and time requirements. However, data distillation on text-based datasets hasn't been explored much because of the challenges rising due to its discrete nature. Additionally, existing dataset distillation methods often struggle to generalize to new architectures. In the paper, we propose several data distillation techniques for multilingual text classification datasets using language-model-based learning methods. We conduct experiments to analyze their performance in terms of classification strength, and cross-architecture generalization. Furthermore, we investigate the language-specific fairness of the data summaries generated by these methods. Our approach builds upon existing techniques, enhancing cross-architecture generalization in the text data distillation domain.
</details>
<details>
<summary>摘要</summary>
随着深度学习的出现，大量数据和复杂的模型变得普遍，需要大量的计算能力。为解决这问题，数据简化技术得到了广泛应用，但是在文本数据集上，数据简化技术尚未得到了充分的研究，这是因为文本数据的精度性带来了很多挑战。现有的数据简化方法通常难以泛化到新的架构上。在本文中，我们提出了一些基于语言模型学习方法的文本分类数据集简化技术。我们通过实验分析这些技术的分类强度和泛化性。此外，我们还研究了这些方法生成的语言特异性数据概要的公平性。我们的方法基于现有技术，提高了文本数据简化领域的跨架构泛化性。
</details></li>
</ul>
<hr>
<h2 id="Improving-Autonomous-Separation-Assurance-through-Distributed-Reinforcement-Learning-with-Attention-Networks"><a href="#Improving-Autonomous-Separation-Assurance-through-Distributed-Reinforcement-Learning-with-Attention-Networks" class="headerlink" title="Improving Autonomous Separation Assurance through Distributed Reinforcement Learning with Attention Networks"></a>Improving Autonomous Separation Assurance through Distributed Reinforcement Learning with Attention Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04958">http://arxiv.org/abs/2308.04958</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marc W. Brittain, Luis E. Alvarez, Kara Breeden</li>
<li>for: 提供增加自动化运输的高效新交通方式，使用自动驾驶和电动飞机，提供未曾得到服务的市场。</li>
<li>methods: 使用分布式强化学习框架，解决自适应分离能力问题，使用速度和垂直动作实现安全自适应分离。</li>
<li>results: 通过实验研究，表明提议的框架可以在高密度、动态环境中保证安全高效的分离，并且比现有方法具有更高的训练样本通过率。<details>
<summary>Abstract</summary>
Advanced Air Mobility (AAM) introduces a new, efficient mode of transportation with the use of vehicle autonomy and electrified aircraft to provide increasingly autonomous transportation between previously underserved markets. Safe and efficient navigation of low altitude aircraft through highly dense environments requires the integration of a multitude of complex observations, such as surveillance, knowledge of vehicle dynamics, and weather. The processing and reasoning on these observations pose challenges due to the various sources of uncertainty in the information while ensuring cooperation with a variable number of aircraft in the airspace. These challenges coupled with the requirement to make safety-critical decisions in real-time rule out the use of conventional separation assurance techniques. We present a decentralized reinforcement learning framework to provide autonomous self-separation capabilities within AAM corridors with the use of speed and vertical maneuvers. The problem is formulated as a Markov Decision Process and solved by developing a novel extension to the sample-efficient, off-policy soft actor-critic (SAC) algorithm. We introduce the use of attention networks for variable-length observation processing and a distributed computing architecture to achieve high training sample throughput as compared to existing approaches. A comprehensive numerical study shows that the proposed framework can ensure safe and efficient separation of aircraft in high density, dynamic environments with various sources of uncertainty.
</details>
<details>
<summary>摘要</summary>
高级空中流动（AAM）介入了一种新的、高效的交通方式，通过车辆自主和电动飞机提供前所未有的市场。在低空飞行的环境中保持安全和高效的导航需要融合多种复杂的观察，如抽象、车辆动力学和天气情况。这些观察的处理和理解受多种不确定性的影响，同时确保与变量数量的飞机在空间中协作。这些挑战，加上实时做出安全关键决策，排除了传统的分离保障技术的使用。我们提出了一种分布式学习框架，以提供自动化的自分配能力在AAM通道中。问题是表示为马尔可夫决策过程，通过开发一种新的、软 actor-critic（SAC）算法的扩展来解决。我们引入了注意网络来处理变量长度的观察，以及分布式计算架构，以实现高训练样本通过率比现有方法高。一项完整的数学研究表明，我们的框架可以在高密度、动态环境中保持安全和高效的飞机分离能力，并处理多种不确定性。
</details></li>
</ul>
<hr>
<h2 id="Wirelessly-Powered-Federated-Learning-Networks-Joint-Power-Transfer-Data-Sensing-Model-Training-and-Resource-Allocation"><a href="#Wirelessly-Powered-Federated-Learning-Networks-Joint-Power-Transfer-Data-Sensing-Model-Training-and-Resource-Allocation" class="headerlink" title="Wirelessly Powered Federated Learning Networks: Joint Power Transfer, Data Sensing, Model Training, and Resource Allocation"></a>Wirelessly Powered Federated Learning Networks: Joint Power Transfer, Data Sensing, Model Training, and Resource Allocation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04953">http://arxiv.org/abs/2308.04953</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mai Le, Dinh Thai Hoang, Diep N. Nguyen, Won-Joo Hwang, Quoc-Viet Pham</li>
<li>for: 本研究旨在提出一种可持续的联合学习（FL）解决方案，以满足移动设备（MD）的能源限制和数据培养困难。</li>
<li>methods: 该研究提出了一种精简的计算效率算法，通过分解技术来解决联合学习（FL）网络中的资源分配问题，以最小化总完成时间。</li>
<li>results: 研究结果表明，提出的可持续联合学习（S2FL）算法可以减少完成时间，相比其他参考方案，可以减少21.45%。此外，研究还发现在非对抗多access（NOMA）下，可以提高总完成时间8.36%的平均值。<details>
<summary>Abstract</summary>
Federated learning (FL) has found many successes in wireless networks; however, the implementation of FL has been hindered by the energy limitation of mobile devices (MDs) and the availability of training data at MDs. How to integrate wireless power transfer and mobile crowdsensing towards sustainable FL solutions is a research topic entirely missing from the open literature. This work for the first time investigates a resource allocation problem in collaborative sensing-assisted sustainable FL (S2FL) networks with the goal of minimizing the total completion time. We investigate a practical harvesting-sensing-training-transmitting protocol in which energy-limited MDs first harvest energy from RF signals, use it to gain a reward for user participation, sense the training data from the environment, train the local models at MDs, and transmit the model updates to the server. The total completion time minimization problem of jointly optimizing power transfer, transmit power allocation, data sensing, bandwidth allocation, local model training, and data transmission is complicated due to the non-convex objective function, highly non-convex constraints, and strongly coupled variables. We propose a computationally-efficient path-following algorithm to obtain the optimal solution via the decomposition technique. In particular, inner convex approximations are developed for the resource allocation subproblem, and the subproblems are performed alternatively in an iterative fashion. Simulation results are provided to evaluate the effectiveness of the proposed S2FL algorithm in reducing the completion time up to 21.45% in comparison with other benchmark schemes. Further, we investigate an extension of our work from frequency division multiple access (FDMA) to non-orthogonal multiple access (NOMA) and show that NOMA can speed up the total completion time 8.36% on average of the considered FL system.
</details>
<details>
<summary>摘要</summary>
联合学习（FL）在无线网络中获得了许多成功;但是实现FL的实现受到移动设备（MD）的能源限制和训练数据的可用性所妨碍。如何整合无线电力转移和移动协同测量以实现可持续的FL解决方案，这是现有文献中没有研究的领域。本研究首次对联合测量助长的可持续FL网络（S2FL）进行了资源分配问题的研究，以最小化总完成时间。我们提出了一个实用的收数测量训练传输协议，在能源有限的MD上首先从RF信号中获取能量，用以获得用户参与的奖励，从环境中测量训练数据，在MD上训练本地模型，并将模型更新发送到服务器。总完成时间最小化问题是由于目标函数不对应、内部非拘束和变量之间强烈的相互关联，而变得困难。我们提出了一个可靠的 Computational Efficiency 的路径追踪算法，通过分解技术来取得最佳解。具体来说，我们在资源分配子问题上开发了内部凸approximation，并在迭代的方式下进行了资源分配子问题的解决。 simulation 结果显示，对于考虑的FL系统，我们的S2FL算法可以降低总完成时间21.45%。此外，我们将FDMA扩展到NOMA，并显示了NOMA可以将总完成时间提高8.36%的平均值。
</details></li>
</ul>
<hr>
<h2 id="Prototypical-Kernel-Learning-and-Open-set-Foreground-Perception-for-Generalized-Few-shot-Semantic-Segmentation"><a href="#Prototypical-Kernel-Learning-and-Open-set-Foreground-Perception-for-Generalized-Few-shot-Semantic-Segmentation" class="headerlink" title="Prototypical Kernel Learning and Open-set Foreground Perception for Generalized Few-shot Semantic Segmentation"></a>Prototypical Kernel Learning and Open-set Foreground Perception for Generalized Few-shot Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04952">http://arxiv.org/abs/2308.04952</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kai Huang, Feigege Wang, Ye Xi, Yutao Gao</li>
<li>for: 这篇论文是为了扩展 few-shot semantic segmentation (FSS) 的研究，以便在评估时同时 segment unseen classes 和 seen classes。</li>
<li>methods: 该论文提出了一种joint prototypical kernel learning和开放集合前景感知的方法，以解决 representation division 和 embedding prejudice 等问题。具体来说，每个 learnable kernel 负责一个 stuff class，然后 merge 了 prototypical learning 到基类 kernel 的更新中，以保持prototype knowledge aggregation of few-shot novel classes。此外，还采用了一个 class-agnostic 和 open-set foreground detection 模块，以减少 embedding prejudice 并避免 novel targets 被误分类为背景。</li>
<li>results: 在 PASCAL-5i 和 COCO-20i 数据集上进行了广泛的实验，并证明了我们的方法在 previous state-of-the-art 之上表现更好。<details>
<summary>Abstract</summary>
Generalized Few-shot Semantic Segmentation (GFSS) extends Few-shot Semantic Segmentation (FSS) to simultaneously segment unseen classes and seen classes during evaluation. Previous works leverage additional branch or prototypical aggregation to eliminate the constrained setting of FSS. However, representation division and embedding prejudice, which heavily results in poor performance of GFSS, have not been synthetical considered. We address the aforementioned problems by jointing the prototypical kernel learning and open-set foreground perception. Specifically, a group of learnable kernels is proposed to perform segmentation with each kernel in charge of a stuff class. Then, we explore to merge the prototypical learning to the update of base-class kernels, which is consistent with the prototype knowledge aggregation of few-shot novel classes. In addition, a foreground contextual perception module cooperating with conditional bias based inference is adopted to perform class-agnostic as well as open-set foreground detection, thus to mitigate the embedding prejudice and prevent novel targets from being misclassified as background. Moreover, we also adjust our method to the Class Incremental Few-shot Semantic Segmentation (CIFSS) which takes the knowledge of novel classes in a incremental stream. Extensive experiments on PASCAL-5i and COCO-20i datasets demonstrate that our method performs better than previous state-of-the-art.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Variations-on-the-Reinforcement-Learning-performance-of-Blackjack"><a href="#Variations-on-the-Reinforcement-Learning-performance-of-Blackjack" class="headerlink" title="Variations on the Reinforcement Learning performance of Blackjack"></a>Variations on the Reinforcement Learning performance of Blackjack</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07329">http://arxiv.org/abs/2308.07329</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/avishburamdoyal/the-impact-of-deck-size-q-learning-blackjack">https://github.com/avishburamdoyal/the-impact-of-deck-size-q-learning-blackjack</a></li>
<li>paper_authors: Avish Buramdoyal, Tim Gebbie</li>
<li>for: The paper is written to explore the impact of deck size on the convergence of q-learning algorithms in the context of blackjack.</li>
<li>methods: The paper uses a q-learning solution for optimal play in blackjack, and investigates the rate of learning convergence as a function of deck size.</li>
<li>results: The paper shows that a card counter perfectly using the basic strategy and hi-lo system can bring the house to bankruptcy, and that environment variations have a significant impact on this outcome.Here are the three points in Simplified Chinese:</li>
<li>for: 这篇论文是为了研究黑Jackson游戏中q学习算法的 converges 问题而写的。</li>
<li>methods: 这篇论文使用了黑Jackson游戏中的q学习解决方案，并 Investigates 学习速度的变化与扑克牌 deck size 的关系。</li>
<li>results: 这篇论文显示，一个 perfectly 使用基本策略和 hi-lo 系统的 card counter 可以使酒店破产，并且环境变化会对这个结果产生很大的影响。<details>
<summary>Abstract</summary>
Blackjack or "21" is a popular card-based game of chance and skill. The objective of the game is to win by obtaining a hand total higher than the dealer's without exceeding 21. The ideal blackjack strategy will maximize financial return in the long run while avoiding gambler's ruin. The stochastic environment and inherent reward structure of blackjack presents an appealing problem to better understand reinforcement learning agents in the presence of environment variations. Here we consider a q-learning solution for optimal play and investigate the rate of learning convergence of the algorithm as a function of deck size. A blackjack simulator allowing for universal blackjack rules is also implemented to demonstrate the extent to which a card counter perfectly using the basic strategy and hi-lo system can bring the house to bankruptcy and how environment variations impact this outcome. The novelty of our work is to place this conceptual understanding of the impact of deck size in the context of learning agent convergence.
</details>
<details>
<summary>摘要</summary>
黑Jack或"21"是一款流行的 кар牌游戏，旨在通过获得手牌总数高于供应者的手牌总数而赢得比赛，而不超过21。理想的黑Jack策略可以在长期内最大化金钱收益，同时避免投资者的破产。黑Jack的 Stochastic 环境和内在的奖励结构，使得黑Jack 在变化的环境中的研究非常有吸引力。在这里，我们考虑了 q-learning 方法来实现最佳策略，并研究了算法的学习速率是否与扑克牌deck大小相关。我们还实现了一个支持通用黑Jack规则的黑Jack模拟器，以示出一个基本策略和高低系统的卡计数员可以使得供应者铺垮，以及环境变化对这个结果的影响。我们的作品之处在于将这些概念理解与学习代理人快速学习的关系。
</details></li>
</ul>
<hr>
<h2 id="Methods-for-Acquiring-and-Incorporating-Knowledge-into-Stock-Price-Prediction-A-Survey"><a href="#Methods-for-Acquiring-and-Incorporating-Knowledge-into-Stock-Price-Prediction-A-Survey" class="headerlink" title="Methods for Acquiring and Incorporating Knowledge into Stock Price Prediction: A Survey"></a>Methods for Acquiring and Incorporating Knowledge into Stock Price Prediction: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04947">http://arxiv.org/abs/2308.04947</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liping Wang, Jiawei Li, Lifan Zhao, Zhizhuo Kou, Xiaohan Wang, Xinyi Zhu, Hao Wang, Yanyan Shen, Lei Chen</li>
<li>for: This paper aims to provide a systematic and comprehensive overview of methods for incorporating external knowledge into stock price prediction models, including the acquisition of external knowledge from various unstructured data sources and fusion methods for combining external knowledge with historical price features.</li>
<li>methods: The paper covers various methods for acquiring external knowledge, including non-graph-based and graph-based knowledge representations, and explores fusion methods for combining external knowledge with historical price features.</li>
<li>results: The paper includes a compilation of relevant datasets and discusses potential future research directions in this domain.Here’s the same information in Simplified Chinese text:</li>
<li>for: 这篇论文旨在系统地探讨External Knowledge在股票价格预测模型中的应用，包括从多种不结构化数据源获取External Knowledge以及将External Knowledge与历史价格特征进行融合。</li>
<li>methods: 论文涵盖了不同类型的External Knowledge获取方法，包括非图structured和图structured知识表示方法，以及将External Knowledge与历史价格特征进行融合的方法。</li>
<li>results: 论文收录了相关的数据集，并讨论了未来在这个领域的可能的研究方向。<details>
<summary>Abstract</summary>
Predicting stock prices presents a challenging research problem due to the inherent volatility and non-linear nature of the stock market. In recent years, knowledge-enhanced stock price prediction methods have shown groundbreaking results by utilizing external knowledge to understand the stock market. Despite the importance of these methods, there is a scarcity of scholarly works that systematically synthesize previous studies from the perspective of external knowledge types. Specifically, the external knowledge can be modeled in different data structures, which we group into non-graph-based formats and graph-based formats: 1) non-graph-based knowledge captures contextual information and multimedia descriptions specifically associated with an individual stock; 2) graph-based knowledge captures interconnected and interdependent information in the stock market. This survey paper aims to provide a systematic and comprehensive description of methods for acquiring external knowledge from various unstructured data sources and then incorporating it into stock price prediction models. We also explore fusion methods for combining external knowledge with historical price features. Moreover, this paper includes a compilation of relevant datasets and delves into potential future research directions in this domain.
</details>
<details>
<summary>摘要</summary>
预测股票价格是一个复杂的研究问题，因为股票市场本身具有不确定性和非线性。在过去几年，带有知识的股票价格预测方法已经显示出了创新的成果，通过利用外部知识来理解股票市场。尽管这些方法的重要性，但是学术研究中对外部知识类型的系统化synthesis却相对罕见。特别是，外部知识可以通过不同的数据结构来表示，我们将其分为非图形化格式和图形化格式：1）非图形化知识捕捉特定股票的上下文信息和 multimedia描述; 2）图形化知识捕捉股票市场中的相互连接和相互依赖信息。本文旨在提供一个系统性和全面的描述，涵盖从不同的不结构化数据源中获取外部知识，并将其与历史价格特征合并。此外，本文还探讨了外部知识与历史价格特征的融合方法，以及相关数据集和未来研究方向。
</details></li>
</ul>
<hr>
<h2 id="LLMeBench-A-Flexible-Framework-for-Accelerating-LLMs-Benchmarking"><a href="#LLMeBench-A-Flexible-Framework-for-Accelerating-LLMs-Benchmarking" class="headerlink" title="LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking"></a>LLMeBench: A Flexible Framework for Accelerating LLMs Benchmarking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04945">http://arxiv.org/abs/2308.04945</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qcri/llmebench">https://github.com/qcri/llmebench</a></li>
<li>paper_authors: Fahim Dalvi, Maram Hasanain, Sabri Boughorbel, Basel Mousi, Samir Abdaljalil, Nizi Nazar, Ahmed Abdelali, Shammur Absar Chowdhury, Hamdy Mubarak, Ahmed Ali, Majd Hawasly, Nadir Durrani, Firoj Alam</li>
<li>for: 评估大语言模型（LLMs）在不同语言的不同NLP任务中的性能。</li>
<li>methods: 提出了 LLMeBench 框架，可以轻松地自定义为特定任务和数据集，并支持零或几shot学习设定。</li>
<li>results: 在 31 个Unique NLP任务和 53 个公共数据集中进行了约 296K 个实验设定，以评估框架的性能。<details>
<summary>Abstract</summary>
The recent development and success of Large Language Models (LLMs) necessitate an evaluation of their performance across diverse NLP tasks in different languages. Although several frameworks have been developed and made publicly available, their customization capabilities for specific tasks and datasets are often complex for different users. In this study, we introduce the LLMeBench framework. Initially developed to evaluate Arabic NLP tasks using OpenAI's GPT and BLOOM models; it can be seamlessly customized for any NLP task and model, regardless of language. The framework also features zero- and few-shot learning settings. A new custom dataset can be added in less than 10 minutes, and users can use their own model API keys to evaluate the task at hand. The developed framework has been already tested on 31 unique NLP tasks using 53 publicly available datasets within 90 experimental setups, involving approximately 296K data points. We plan to open-source the framework for the community (https://github.com/qcri/LLMeBench/). A video demonstrating the framework is available online (https://youtu.be/FkQn4UjYA0s).
</details>
<details>
<summary>摘要</summary>
The LLMeBench framework is highly customizable and can be easily adapted for any NLP task and model, regardless of language. It also supports zero- and few-shot learning settings, allowing users to evaluate their tasks with minimal data. Adding a new custom dataset to the framework takes less than 10 minutes, and users can use their own model API keys to evaluate the task at hand.We have tested the LLMeBench framework on 31 unique NLP tasks using 53 publicly available datasets within 90 experimental setups, involving approximately 296K data points. The framework is set to be open-sourced for the community, and a video demonstrating its capabilities is available online (https://youtu.be/FkQn4UjYA0s).
</details></li>
</ul>
<hr>
<h2 id="Gaussian-Image-Anomaly-Detection-with-Greedy-Eigencomponent-Selection"><a href="#Gaussian-Image-Anomaly-Detection-with-Greedy-Eigencomponent-Selection" class="headerlink" title="Gaussian Image Anomaly Detection with Greedy Eigencomponent Selection"></a>Gaussian Image Anomaly Detection with Greedy Eigencomponent Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04944">http://arxiv.org/abs/2308.04944</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tetiana Gula, João P C Bertoldo<br>for: 本文旨在提出一种新的维度减少方法，用于图像异常检测（AD），通过使用预训练的卷积神经网络（CNN）和高效率的EfficientNet模型。methods: 本文使用两种类型的树搜索方法，即搜索最佳准则和最佳词汇搜索，以选择最佳的 eigencomponent。同时，我们也进行了三个主要的实验来评估方法的效果，包括测试集的影响、一种异常类型的训练和所有其他类型的评估、以及使用最小数量的图像进行训练和选择。results: 我们的方法在检测精度方面胜过了PCA和NPCA，即使使用 fewer components。这表明，我们的方法可以提供一种有效的维度减少方法，并且可以增强图像异常检测系统的效率和精度。<details>
<summary>Abstract</summary>
Anomaly detection (AD) in images, identifying significant deviations from normality, is a critical issue in computer vision. This paper introduces a novel approach to dimensionality reduction for AD using pre-trained convolutional neural network (CNN) that incorporate EfficientNet models. We investigate the importance of component selection and propose two types of tree search approaches, both employing a greedy strategy, for optimal eigencomponent selection. Our study conducts three main experiments to evaluate the effectiveness of our approach. The first experiment explores the influence of test set performance on component choice, the second experiment examines the performance when we train on one anomaly type and evaluate on all other types, and the third experiment investigates the impact of using a minimum number of images for training and selecting them based on anomaly types. Our approach aims to find the optimal subset of components that deliver the highest performance score, instead of focusing solely on the proportion of variance explained by each component and also understand the components behaviour in different settings. Our results indicate that the proposed method surpasses both Principal Component Analysis (PCA) and Negated Principal Component Analysis (NPCA) in terms of detection accuracy, even when using fewer components. Thus, our approach provides a promising alternative to conventional dimensionality reduction techniques in AD, and holds potential to enhance the efficiency and effectiveness of AD systems.
</details>
<details>
<summary>摘要</summary>
“问题检测（AD）在图像中，找到重要的异常，是计算机视觉中的关键问题。这篇论文介绍了一种新的维度减少方法，使用预训练的卷积神经网络（CNN）和EfficientNet模型。我们研究了选择组件的重要性，并提出了两种树搜索方法，都采用了聪明策略，以便选择最佳的组件。我们的研究进行了三项主要实验，以评估我们的方法的效果。第一项实验研究了测试集的影响因素，第二项实验验证了我们在一种异常类型上训练，然后在所有其他异常类型上进行评估，第三项实验研究了使用最少数量的图像进行训练和选择，并根据异常类型来选择图像。我们的方法旨在找到最佳的组件子集，而不是围绕每个组件的解释度量进行围绕。我们的结果表明，我们的方法在检测精度方面比PCA和NPCA高，即使使用 fewer components。因此，我们的方法提供了一种可靠的替代方法，可以增强AD系统的效率和效果。”
</details></li>
</ul>
<hr>
<h2 id="Semantic-Communications-for-Artificial-Intelligence-Generated-Content-AIGC-Toward-Effective-Content-Creation"><a href="#Semantic-Communications-for-Artificial-Intelligence-Generated-Content-AIGC-Toward-Effective-Content-Creation" class="headerlink" title="Semantic Communications for Artificial Intelligence Generated Content (AIGC) Toward Effective Content Creation"></a>Semantic Communications for Artificial Intelligence Generated Content (AIGC) Toward Effective Content Creation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04942">http://arxiv.org/abs/2308.04942</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guangyuan Liu, Hongyang Du, Dusit Niyato, Jiawen Kang, Zehui Xiong, Dong In Kim, Xuemin, Shen</li>
<li>For: This paper aims to develop a comprehensive conceptual model for integrating Artificial Intelligence Generated Content (AIGC) and Semantic Communication (SemCom), and to propose a novel framework for generating meaningful and effective content using AIGC technology.* Methods: The paper employs a novel framework that uses AIGC technology as an encoder and decoder for semantic information, and jointly optimizes semantic extraction and evaluation metrics tailored to AIGC services. The framework is adaptable to different types of content generated, the required quality, and the semantic information utilized.* Results: The paper presents a case study using a Deep Q Network (DQN) to demonstrate the feasibility of the optimization problem and its convergence characteristics. The study provides useful insights into the effectiveness of the proposed framework for generating meaningful and effective content using AIGC technology.<details>
<summary>Abstract</summary>
Artificial Intelligence Generated Content (AIGC) Services have significant potential in digital content creation. The distinctive abilities of AIGC, such as content generation based on minimal input, hold huge potential, especially when integrating with semantic communication (SemCom). In this paper, a novel comprehensive conceptual model for the integration of AIGC and SemCom is developed. Particularly, a content generation level is introduced on top of the semantic level that provides a clear outline of how AIGC and SemCom interact with each other to produce meaningful and effective content. Moreover, a novel framework that employs AIGC technology is proposed as an encoder and decoder for semantic information, considering the joint optimization of semantic extraction and evaluation metrics tailored to AIGC services. The framework can adapt to different types of content generated, the required quality, and the semantic information utilized. By employing a Deep Q Network (DQN), a case study is presented that provides useful insights into the feasibility of the optimization problem and its convergence characteristics.
</details>
<details>
<summary>摘要</summary>
人工智能生成内容（AIGC）服务具有很大的潜力在数字内容创造中。AIGC的特殊能力，如基于最小输入的内容生成，在整合 semantic communication（SemCom）时表现出巨大的潜力，尤其是在生成有意义和有效的内容方面。在这篇论文中，我们提出了一种新的全面概念模型，用于AIGC和SemCom的整合。具体来说，我们在 semantic 层次上引入了内容生成级别，以便清晰地描述AIGC和SemCom之间的交互方式，并生成有意义和有效的内容。此外，我们提议了一种基于 AIGC 技术的核心架构，用于SemCom 的编解码器，并考虑了对 AIGC 服务的 JOINT 优化。这种框架可以适应不同类型的内容生成、需要的质量和使用的semantic信息。通过使用深度感知网络（DQN），我们在这种优化问题上提供了有用的洞察和其叠合特性。
</details></li>
</ul>
<hr>
<h2 id="An-In-Depth-Analysis-of-Discretization-Methods-for-Communication-Learning-using-Backpropagation-with-Multi-Agent-Reinforcement-Learning"><a href="#An-In-Depth-Analysis-of-Discretization-Methods-for-Communication-Learning-using-Backpropagation-with-Multi-Agent-Reinforcement-Learning" class="headerlink" title="An In-Depth Analysis of Discretization Methods for Communication Learning using Backpropagation with Multi-Agent Reinforcement Learning"></a>An In-Depth Analysis of Discretization Methods for Communication Learning using Backpropagation with Multi-Agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04938">http://arxiv.org/abs/2308.04938</a></li>
<li>repo_url: None</li>
<li>paper_authors: Astrid Vanneste, Simon Vanneste, Kevin Mets, Tom De Schepper, Siegfried Mercelis, Peter Hellinckx</li>
<li>for: 本研究的目的是比较各种常见的精简方法，以及一种新的方法，在多智能 reinforcement learning 中实现有效的通信学习。</li>
<li>methods: 本研究使用了多种常见的精简方法，包括 DIAL、COMA 等方法，以及一种新的方法（ST-DRU）。</li>
<li>results: 研究发现，ST-DRU 方法在不同环境中的表现最佳，其在每个实验中都达到了或超过了其他方法的最佳性能，而且不会在任何环境中失败。<details>
<summary>Abstract</summary>
Communication is crucial in multi-agent reinforcement learning when agents are not able to observe the full state of the environment. The most common approach to allow learned communication between agents is the use of a differentiable communication channel that allows gradients to flow between agents as a form of feedback. However, this is challenging when we want to use discrete messages to reduce the message size, since gradients cannot flow through a discrete communication channel. Previous work proposed methods to deal with this problem. However, these methods are tested in different communication learning architectures and environments, making it hard to compare them. In this paper, we compare several state-of-the-art discretization methods as well as a novel approach. We do this comparison in the context of communication learning using gradients from other agents and perform tests on several environments. In addition, we present COMA-DIAL, a communication learning approach based on DIAL and COMA extended with learning rate scaling and adapted exploration. Using COMA-DIAL allows us to perform experiments on more complex environments. Our results show that the novel ST-DRU method, proposed in this paper, achieves the best results out of all discretization methods across the different environments. It achieves the best or close to the best performance in each of the experiments and is the only method that does not fail on any of the tested environments.
</details>
<details>
<summary>摘要</summary>
<<SYS>>通信是多智能代理学习中关键的一部分，当代理不能观察环境的全部状态时。最常见的解决方案是使用可导通信通道，让代理之间的反馈通过梯度流动。然而，当使用整数消息时，梯度无法流动，这引发了一些问题。先前的研究已经提出了解决方案，但是这些方法在不同的通信学习架构和环境中进行测试，使得比较困难。本文比较了多种当前领先的整数化方法，以及一种新的方法。我们在通信学习中使用其他代理的梯度进行学习，并在多个环境中进行测试。此外，我们还提出了 COMA-DIAL，一种基于 DIAL 和 COMA 的通信学习方法，其中包括学习速率缩放和适应exploration。使用 COMA-DIAL 让我们在更复杂的环境中进行实验。我们的结果表明，本文所提出的新方法 ST-DRU，在不同环境中的所有实验中均达到了最佳result。它在每个实验中达到了最佳或接近最佳性能，并且是唯一不会在任何测试环境中失败的方法。Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Service-Reservation-and-Pricing-for-Green-Metaverses-A-Stackelberg-Game-Approach"><a href="#Service-Reservation-and-Pricing-for-Green-Metaverses-A-Stackelberg-Game-Approach" class="headerlink" title="Service Reservation and Pricing for Green Metaverses: A Stackelberg Game Approach"></a>Service Reservation and Pricing for Green Metaverses: A Stackelberg Game Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04914">http://arxiv.org/abs/2308.04914</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xumin Huang, Yuan Wu, Jiawen Kang, Jiangtian Nie, Weifeng Zhong, Dong In Kim, Shengli Xie</li>
<li>for:  Metaverse服务提供商（MSP）为了实现绿色可持续的Metaverse，通过在协同层次上执行软件组件来减少重复数据传输和处理，从而减少总能 consumption。</li>
<li>methods: 本文使用了一个增强现实（AR）应用程序作为示例，并研究了用户如何向MSP申请卸载服务和MSP如何确定最佳费用标准，以确保用户具有最佳的经济效益。</li>
<li>results:  compared with传统方案，我们的方案可以同时实现能源减少和个人合理性，并且可以满足用户的经济需求。此外，我们还提出了如何通过结合多种新技术实现可持续的绿色Metaverse。<details>
<summary>Abstract</summary>
Metaverse enables users to communicate, collaborate and socialize with each other through their digital avatars. Due to the spatio-temporal characteristics, co-located users are served well by performing their software components in a collaborative manner such that a Metaverse service provider (MSP) eliminates redundant data transmission and processing, ultimately reducing the total energy consumption. The energyefficient service provision is crucial for enabling the green and sustainable Metaverse. In this article, we take an augmented reality (AR) application as an example to achieve this goal. Moreover, we study an economic issue on how the users reserve offloading services from the MSP and how the MSP determines an optimal charging price since each user is rational to decide whether to accept the offloading service by taking into account the monetary cost. A single-leader multi-follower Stackelberg game is formulated between the MSP and users while each user optimizes an offloading probability to minimize the weighted sum of time, energy consumption and monetary cost. Numerical results show that our scheme achieves energy savings and satisfies individual rationality simultaneously compared with the conventional schemes. Finally, we identify and discuss open directions on how several emerging technologies are combined with the sustainable green Metaverse.
</details>
<details>
<summary>摘要</summary>
Metaverse 允许用户通过数字化的人物进行交流、合作和社交交流。由于空间 temporal 特点，用户在同一个地点时，Metaverse 服务提供商 (MSP) 可以减少重复的数据传输和处理，最终减少总能 consumption。这种能源efficient的服务提供是metaverse 的关键，以实现绿色可持续的Metaverse。在这篇文章中，我们使用了一个扩展现实 (AR) 应用程序作为例子，以实现这个目标。此外，我们还研究了用户向 MSP 积分服务的协议和 MSP 如何确定最佳的收费 Price，因为每个用户都是合理的决定是否接受协议，考虑到经济成本。在这个框架中，MSP 是一个领导者，而用户是多个追随者。每个用户都是最小化时间、能源消耗和经济成本的权重和总和。numerical 结果表明，我们的方案可以同时实现能源减少和个人合理性。最后，我们还讨论了一些新兴技术如何与可持续的绿色Metaverse 结合。
</details></li>
</ul>
<hr>
<h2 id="LLaMA-E-Empowering-E-commerce-Authoring-with-Multi-Aspect-Instruction-Following"><a href="#LLaMA-E-Empowering-E-commerce-Authoring-with-Multi-Aspect-Instruction-Following" class="headerlink" title="LLaMA-E: Empowering E-commerce Authoring with Multi-Aspect Instruction Following"></a>LLaMA-E: Empowering E-commerce Authoring with Multi-Aspect Instruction Following</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04913">http://arxiv.org/abs/2308.04913</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaize Shi, Xueyao Sun, Dingxian Wang, Yinlin Fu, Guandong Xu, Qing Li<br>methods: 这篇论文使用了专门的执行 instruction-following 语言模型（LLaMA-E），并将它们训练在多种电商创作任务中，包括广告生成、产品标题修改、产品分类、购买意愿预测和通用问答等。results: 这篇论文的实验结果显示，提案的 LLaMA-E 模型在量和质量评估中均取得了顶尖的结果，并在零执行场景中表现出优势。此外，这篇论文还发现 LLMA-E 模型可以对电商内容创作问题进行优化解决。<details>
<summary>Abstract</summary>
E-commerce authoring involves creating attractive, abundant, and targeted promotional content to drive product sales. The emergence of large language models (LLMs) introduces an innovative paradigm, offering a unified solution to address various authoring tasks within this scenario. However, mainstream LLMs trained on general corpora with common sense knowledge reveal limitations in fitting complex and personalized features unique to e-commerce products and customers. Furthermore, LLMs like GPT-3.5 necessitate remote accessibility, raising concerns about safeguarding voluminous customer privacy data during transmission. This paper proposes the LLaMA-E, the unified and customized instruction-following language models focusing on diverse e-commerce authoring tasks. Specifically, the domain experts create the seed instruction set from the tasks of ads generation, query-enhanced product title rewriting, product classification, purchase intent speculation, and general Q&A. These tasks enable the models to comprehensively understand precise e-commerce authoring knowledge by interleaving features covering typical service aspects of customers, sellers, and platforms. The GPT-3.5 is introduced as a teacher model, which expands the seed instructions to form a training set for the LLaMA-E models with various scales. The experimental results show that the proposed LLaMA-E models achieve state-of-the-art results in quantitative and qualitative evaluations, also exhibiting the advantage in zero-shot scenes. To the best of our knowledge, this study is the first to serve the LLMs to specific e-commerce authoring scenarios.
</details>
<details>
<summary>摘要</summary>
电商作者需创建吸引人、丰富、有目标的推广内容，以促进产品销售。大语言模型（LLM）的出现提供了一种创新的解决方案，可以同时解决多种作者任务。然而，主流的LLM通常由通用文献训练，对电商产品和客户特有的复杂和个性化特征表现出限制。此外，LLM如GPT-3.5需要远程访问，可能会使客户隐私数据泄露。本文提议了LLaMA-E，一种特定于电商作者任务的一体化和个性化语言模型。具体来说，域专家会根据广告生成、产品标题重写、产品分类、购买意愿预测和通用问答等任务，创建种子指令集。这些任务使模型能够全面地理解电商作者的精准知识，覆盖客户、卖家和平台的典型服务方面。GPT-3.5被用作教学模型，将种子指令扩展成训练集，以形成不同规模的LLaMA-E模型。实验结果表明，提议的LLaMA-E模型在量和质量评价中具有国际最佳效果，同时在零容量场景中也表现出优势。到目前为止，这是电商作者scenario中LLM的首次应用。
</details></li>
</ul>
<hr>
<h2 id="SLPT-Selective-Labeling-Meets-Prompt-Tuning-on-Label-Limited-Lesion-Segmentation"><a href="#SLPT-Selective-Labeling-Meets-Prompt-Tuning-on-Label-Limited-Lesion-Segmentation" class="headerlink" title="SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation"></a>SLPT: Selective Labeling Meets Prompt Tuning on Label-Limited Lesion Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04911">http://arxiv.org/abs/2308.04911</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fan Bai, Ke Yan, Xiaoyu Bai, Xinyu Mao, Xiaoli Yin, Jingren Zhou, Yu Shi, Le Lu, Max Q. -H. Meng</li>
<li>for: 这个研究旨在提高医学图像分析中使用深度学习的性能，减少 labels 的成本和增加准确性。</li>
<li>methods: 这个方法使用提前训练的模型，并在限制labels的情况下进行微调。它还使用选择性标签，将最有价的下游标签选择出来，以获得最佳性能。</li>
<li>results: 这个研究在肝癌分 segmentation 中实现了国际级的性能，只需要6%的弹性参数，并且可以在5%的标签数量下 достиieving 94%的全资料性能。<details>
<summary>Abstract</summary>
Medical image analysis using deep learning is often challenged by limited labeled data and high annotation costs. Fine-tuning the entire network in label-limited scenarios can lead to overfitting and suboptimal performance. Recently, prompt tuning has emerged as a more promising technique that introduces a few additional tunable parameters as prompts to a task-agnostic pre-trained model, and updates only these parameters using supervision from limited labeled data while keeping the pre-trained model unchanged. However, previous work has overlooked the importance of selective labeling in downstream tasks, which aims to select the most valuable downstream samples for annotation to achieve the best performance with minimum annotation cost. To address this, we propose a framework that combines selective labeling with prompt tuning (SLPT) to boost performance in limited labels. Specifically, we introduce a feature-aware prompt updater to guide prompt tuning and a TandEm Selective LAbeling (TESLA) strategy. TESLA includes unsupervised diversity selection and supervised selection using prompt-based uncertainty. In addition, we propose a diversified visual prompt tuning strategy to provide multi-prompt-based discrepant predictions for TESLA. We evaluate our method on liver tumor segmentation and achieve state-of-the-art performance, outperforming traditional fine-tuning with only 6% of tunable parameters, also achieving 94% of full-data performance by labeling only 5% of the data.
</details>
<details>
<summary>摘要</summary>
医疗图像分析使用深度学习经常受到有限的标注数据和高标注成本的挑战。 fine-tuning整个网络在标注有限的场景下可能导致逗减和下标性性能。Recently, prompt tuning  emerged as a more promising technique that introduces a few additional tunable parameters as prompts to a task-agnostic pre-trained model, and updates only these parameters using supervision from limited labeled data while keeping the pre-trained model unchanged. However, previous work has overlooked the importance of selective labeling in downstream tasks, which aims to select the most valuable downstream samples for annotation to achieve the best performance with minimum annotation cost. To address this, we propose a framework that combines selective labeling with prompt tuning (SLPT) to boost performance in limited labels. Specifically, we introduce a feature-aware prompt updater to guide prompt tuning and a TandEm Selective LAbeling (TESLA) strategy. TESLA includes unsupervised diversity selection and supervised selection using prompt-based uncertainty. In addition, we propose a diversified visual prompt tuning strategy to provide multi-prompt-based discrepant predictions for TESLA. We evaluate our method on liver tumor segmentation and achieve state-of-the-art performance, outperforming traditional fine-tuning with only 6% of tunable parameters, also achieving 94% of full-data performance by labeling only 5% of the data.
</details></li>
</ul>
<hr>
<h2 id="Adversarial-Deep-Reinforcement-Learning-for-Cyber-Security-in-Software-Defined-Networks"><a href="#Adversarial-Deep-Reinforcement-Learning-for-Cyber-Security-in-Software-Defined-Networks" class="headerlink" title="Adversarial Deep Reinforcement Learning for Cyber Security in Software Defined Networks"></a>Adversarial Deep Reinforcement Learning for Cyber Security in Software Defined Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04909">http://arxiv.org/abs/2308.04909</a></li>
<li>repo_url: None</li>
<li>paper_authors: Luke Borchjes, Clement Nyirenda, Louise Leenen</li>
<li>For: The paper explores the impact of adversarial learning in Deep Reinforcement Learning (DRL) for autonomous security in Software Defined Networks (SDN).* Methods: The paper compares two algorithms, Double Deep Q-Networks (DDQN) and Neural Episodic Control to Deep Q-Network (NEC2DQN or N2D), and evaluates their performance under a white-box setting with a causative attack.* Results: The paper shows that with minute parameter changes, the algorithms are still able to defend the network, and the introduction of the causative attack improves the attacker’s performance.<details>
<summary>Abstract</summary>
This paper focuses on the impact of leveraging autonomous offensive approaches in Deep Reinforcement Learning (DRL) to train more robust agents by exploring the impact of applying adversarial learning to DRL for autonomous security in Software Defined Networks (SDN). Two algorithms, Double Deep Q-Networks (DDQN) and Neural Episodic Control to Deep Q-Network (NEC2DQN or N2D), are compared. NEC2DQN was proposed in 2018 and is a new member of the deep q-network (DQN) family of algorithms. The attacker has full observability of the environment and access to a causative attack that uses state manipulation in an attempt to poison the learning process. The implementation of the attack is done under a white-box setting, in which the attacker has access to the defender's model and experiences. Two games are played; in the first game, DDQN is a defender and N2D is an attacker, and in second game, the roles are reversed. The games are played twice; first, without an active causative attack and secondly, with an active causative attack. For execution, three sets of game results are recorded in which a single set consists of 10 game runs. The before and after results are then compared in order to see if there was actually an improvement or degradation. The results show that with minute parameter changes made to the algorithms, there was growth in the attacker's role, since it is able to win games. Implementation of the adversarial learning by the introduction of the causative attack showed the algorithms are still able to defend the network according to their strengths.
</details>
<details>
<summary>摘要</summary>
Here is the text in Simplified Chinese:这篇论文研究了利用深度强化学习（DRL）中的自主攻击方法来训练更加鲜硬的代理人，并通过对DRL的自主安全性进行抗击学习来强化网络的自主安全性。研究比较了两种算法，Double Deep Q-Networks（DDQN）和Neural Episodic Control to Deep Q-Network（NEC2DQN或N2D），在面临 causative 攻击时的防御能力。攻击者具有环境的全观察权和对 defendere 的模型和经验的访问权。在一个白盒Setting下，攻击者通过 state  manipulate 来尝试毒害学习过程。两个游戏被玩了两次，一次没有活动 causative 攻击，第二次有活动 causative 攻击。每个游戏被玩了十次。前后结果被记录下来，并进行比较，以确定是否有改进或退化。结果显示，通过微调算法的参数，攻击者能够赢得游戏。对于 causative 攻击的引入，算法仍然能够防御网络，根据其优势。
</details></li>
</ul>
<hr>
<h2 id="GraphCC-A-Practical-Graph-Learning-based-Approach-to-Congestion-Control-in-Datacenters"><a href="#GraphCC-A-Practical-Graph-Learning-based-Approach-to-Congestion-Control-in-Datacenters" class="headerlink" title="GraphCC: A Practical Graph Learning-based Approach to Congestion Control in Datacenters"></a>GraphCC: A Practical Graph Learning-based Approach to Congestion Control in Datacenters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04905">http://arxiv.org/abs/2308.04905</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guillermo Bernárdez, José Suárez-Varela, Xiang Shi, Shihan Xiao, Xiangle Cheng, Pere Barlet-Ros, Albert Cabellos-Aparicio</li>
<li>for: 提高数据中心网络（DCN）的流量优化</li>
<li>methods: 使用机器学习（ML）和图神经网络（GNN）实现分布式agent在交换机上协同优化ECN配置</li>
<li>results: 在多种场景下测试和比较GraphCC和ACC两种解决方案，结果显示GraphCC在所有评价场景中表现出色，与ACC比较而言，GraphCC在流程完成时间和缓存占用率方面具有显著的改善($20%$ 的提高和$38.0-85.7%$ 的减少)。<details>
<summary>Abstract</summary>
Congestion Control (CC) plays a fundamental role in optimizing traffic in Data Center Networks (DCN). Currently, DCNs mainly implement two main CC protocols: DCTCP and DCQCN. Both protocols -- and their main variants -- are based on Explicit Congestion Notification (ECN), where intermediate switches mark packets when they detect congestion. The ECN configuration is thus a crucial aspect on the performance of CC protocols. Nowadays, network experts set static ECN parameters carefully selected to optimize the average network performance. However, today's high-speed DCNs experience quick and abrupt changes that severely change the network state (e.g., dynamic traffic workloads, incast events, failures). This leads to under-utilization and sub-optimal performance. This paper presents GraphCC, a novel Machine Learning-based framework for in-network CC optimization. Our distributed solution relies on a novel combination of Multi-agent Reinforcement Learning (MARL) and Graph Neural Networks (GNN), and it is compatible with widely deployed ECN-based CC protocols. GraphCC deploys distributed agents on switches that communicate with their neighbors to cooperate and optimize the global ECN configuration. In our evaluation, we test the performance of GraphCC under a wide variety of scenarios, focusing on the capability of this solution to adapt to new scenarios unseen during training (e.g., new traffic workloads, failures, upgrades). We compare GraphCC with a state-of-the-art MARL-based solution for ECN tuning -- ACC -- and observe that our proposed solution outperforms the state-of-the-art baseline in all of the evaluation scenarios, showing improvements up to $20\%$ in Flow Completion Time as well as significant reductions in buffer occupancy ($38.0-85.7\%$).
</details>
<details>
<summary>摘要</summary>
压力控制（CC）在数据中心网络（DCN）中扮演了基本角色，以优化流量。目前，DCNs主要实施了两种主要的CC协议：DCTCP和DCQCN。这两种协议都基于显式拥堵通知（ECN）， intermediate switches 将包 WHEN 检测拥堵。因此，ECN配置成为了CC协议性能的关键因素。当前，网络专家通过精心选择ECN参数来优化平均网络性能。然而，今天的高速DCNs在快速和突然变化的网络状态下经历了差不多的性能下降。这导致了下Utilization和不佳的性能。本文介绍了一种基于机器学习的GraphCC框架，用于在网络中进行CC优化。我们的分布式解决方案基于多代理循环学习（MARL）和图神经网络（GNN）的新组合，与广泛部署的ECN基于CC协议相容。GraphCC在 switches 上部署分布式代理，与相邻的 switches 进行交互，以便协调和优化全局ECN配置。在我们的评估中，我们测试了GraphCC在多种场景下的性能，特别是它在新的场景下（例如新的流量工作负荷、故障、升级）进行适应性的能力。我们将GraphCC与一种基于MARL的ECN调试解决方案——ACC进行比较，并发现我们的提议方案在所有评估场景中都高于基线，显示改进流程完成时间（$20\%$）以及重要减少缓冲占用（$38.0-85.7\%$）。
</details></li>
</ul>
<hr>
<h2 id="Unleashing-the-Power-of-Extra-Tree-Feature-Selection-and-Random-Forest-Classifier-for-Improved-Survival-Prediction-in-Heart-Failure-Patients"><a href="#Unleashing-the-Power-of-Extra-Tree-Feature-Selection-and-Random-Forest-Classifier-for-Improved-Survival-Prediction-in-Heart-Failure-Patients" class="headerlink" title="Unleashing the Power of Extra-Tree Feature Selection and Random Forest Classifier for Improved Survival Prediction in Heart Failure Patients"></a>Unleashing the Power of Extra-Tree Feature Selection and Random Forest Classifier for Improved Survival Prediction in Heart Failure Patients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05765">http://arxiv.org/abs/2308.05765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md. Simul Hasan Talukder, Rejwan Bin Sulaiman, Mouli Bardhan Paul Angon</li>
<li>for: 预测心衰竭患者生存率，以便早期干预并改善患者结果。</li>
<li>methods: 利用数据处理技术和Extra-Tree（ET）特征选择方法，并与Random Forest（RF）分类器结合，以提高心衰竭患者生存预测精度。</li>
<li>results: 通过ET特征选择算法确定最重要的预测器，并使用网格搜索法进行RF模型的优化，实现了98.33%的准确率，至今为最高的成果。<details>
<summary>Abstract</summary>
Heart failure is a life-threatening condition that affects millions of people worldwide. The ability to accurately predict patient survival can aid in early intervention and improve patient outcomes. In this study, we explore the potential of utilizing data pre-processing techniques and the Extra-Tree (ET) feature selection method in conjunction with the Random Forest (RF) classifier to improve survival prediction in heart failure patients. By leveraging the strengths of ET feature selection, we aim to identify the most significant predictors associated with heart failure survival. Using the public UCL Heart failure (HF) survival dataset, we employ the ET feature selection algorithm to identify the most informative features. These features are then used as input for grid search of RF. Finally, the tuned RF Model was trained and evaluated using different matrices. The approach was achieved 98.33% accuracy that is the highest over the exiting work.
</details>
<details>
<summary>摘要</summary>
心力衰竭是一种生命威胁性的疾病，影响全球数百万人。可以准确预测患者存活的能力可以帮助早期干预，提高患者结果。在这项研究中，我们探讨了使用数据处理技术和EXTRA-TREE（ET）特征选择方法，与Random Forest（RF）分类器结合以提高心力衰竭患者存活预测。通过利用ET特征选择算法的优势，我们希望可以确定心力衰竭存活的最重要预测因素。使用公共的UCL心力衰竭（HF）存活数据集，我们采用ET特征选择算法确定最有用的特征。这些特征然后作为RF模型的输入，进行了网格搜索。最后，通过不同矩阵的训练和评估，我们实现了98.33%的准确率，这是已有工作中最高的成绩。
</details></li>
</ul>
<hr>
<h2 id="Learning-Type-Generalized-Actions-for-Symbolic-Planning"><a href="#Learning-Type-Generalized-Actions-for-Symbolic-Planning" class="headerlink" title="Learning Type-Generalized Actions for Symbolic Planning"></a>Learning Type-Generalized Actions for Symbolic Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04867">http://arxiv.org/abs/2308.04867</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel Tanneberg, Michael Gienger</li>
<li>for: 解决复杂任务，需要长序列的动作和智能代理人的复杂行为。</li>
<li>methods: 使用符号规划技术，使用给定实体层次结构和观察到的类似行为来泛化符号动作。</li>
<li>results: 在模拟的网格式厨房环境中，通过几个观察学习，可以学习和泛化类型总结，解决未经见过的任务组合、新的实体和不预期的环境行为。<details>
<summary>Abstract</summary>
Symbolic planning is a powerful technique to solve complex tasks that require long sequences of actions and can equip an intelligent agent with complex behavior. The downside of this approach is the necessity for suitable symbolic representations describing the state of the environment as well as the actions that can change it. Traditionally such representations are carefully hand-designed by experts for distinct problem domains, which limits their transferability to different problems and environment complexities. In this paper, we propose a novel concept to generalize symbolic actions using a given entity hierarchy and observed similar behavior. In a simulated grid-based kitchen environment, we show that type-generalized actions can be learned from few observations and generalize to novel situations. Incorporating an additional on-the-fly generalization mechanism during planning, unseen task combinations, involving longer sequences, novel entities and unexpected environment behavior, can be solved.
</details>
<details>
<summary>摘要</summary>
symbolic 规划是一种强大的技术，可以解决复杂的任务，需要长串动作，并具备复杂的行为。但是，这种方法的缺点是需要适当的符号表示，描述环境状态以及可以改变它的行动。传统上，这些表示是由专家手动设计，限制了它们在不同问题领域的传输性。在这篇论文中，我们提出了一种新的概念，使用给定的实体层次结构和观察到的相似行为来泛化符号行动。在一个模拟的网格式厨房环境中，我们示出了通过几次观察学习，可以将类型泛化行动应用于新的情况。在规划过程中，附加了一种在线泛化机制，可以解决未看过的任务组合，包括更长的序列，新的实体和意外的环境行为。
</details></li>
</ul>
<hr>
<h2 id="Scalability-of-Message-Encoding-Techniques-for-Continuous-Communication-Learned-with-Multi-Agent-Reinforcement-Learning"><a href="#Scalability-of-Message-Encoding-Techniques-for-Continuous-Communication-Learned-with-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Scalability of Message Encoding Techniques for Continuous Communication Learned with Multi-Agent Reinforcement Learning"></a>Scalability of Message Encoding Techniques for Continuous Communication Learned with Multi-Agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04844">http://arxiv.org/abs/2308.04844</a></li>
<li>repo_url: None</li>
<li>paper_authors: Astrid Vanneste, Thomas Somers, Simon Vanneste, Kevin Mets, Tom De Schepper, Siegfried Mercelis, Peter Hellinckx</li>
<li>for: 本研究旨在 investigating the effect of increasing the amount of information in multi-agent communication messages and the number of agents on the performance of the system.</li>
<li>methods: 本研究使用 multi-agent reinforcement learning 技术，并 comparison of two message encoding methods: mean message encoder 和 attention message encoder.</li>
<li>results:  surprisingly, 我们发现 mean message encoder 在所有情况下表现出色，而 attention message encoder 则表现较差。 进一步分析发现，使用 mean message encoder 的 agent 使用一种组合函数，包括对数和对数函数，来确保重要信息不会在传输过程中丢失。<details>
<summary>Abstract</summary>
Many multi-agent systems require inter-agent communication to properly achieve their goal. By learning the communication protocol alongside the action protocol using multi-agent reinforcement learning techniques, the agents gain the flexibility to determine which information should be shared. However, when the number of agents increases we need to create an encoding of the information contained in these messages. In this paper, we investigate the effect of increasing the amount of information that should be contained in a message and increasing the number of agents. We evaluate these effects on two different message encoding methods, the mean message encoder and the attention message encoder. We perform our experiments on a matrix environment. Surprisingly, our results show that the mean message encoder consistently outperforms the attention message encoder. Therefore, we analyse the communication protocol used by the agents that use the mean message encoder and can conclude that the agents use a combination of an exponential and a logarithmic function in their communication policy to avoid the loss of important information after applying the mean message encoder.
</details>
<details>
<summary>摘要</summary>
多个Agent系统需要间 Agent communication来实现目标。通过使用多 Agent reinforcement learning技术学习交流协议和行为协议，代理人获得了自定义信息共享的灵活性。然而，当代理人数量增加时，我们需要创建消息中信息的编码方式。在这篇论文中，我们研究了增加消息中信息量和代理人数量的效果，并对两种消息编码方法进行评估：mean message encoder和attention message encoder。我们在矩阵环境中进行了实验，结果显示mean message encoder在所有情况下表现出优于attention message encoder。因此，我们分析了使用mean message encoder的交流协议，并确定代理人使用权重函数和幂函数在其交流策略中，以避免信息损失。
</details></li>
</ul>
<hr>
<h2 id="Unlocking-the-Diagnostic-Potential-of-ECG-through-Knowledge-Transfer-from-Cardiac-MRI"><a href="#Unlocking-the-Diagnostic-Potential-of-ECG-through-Knowledge-Transfer-from-Cardiac-MRI" class="headerlink" title="Unlocking the Diagnostic Potential of ECG through Knowledge Transfer from Cardiac MRI"></a>Unlocking the Diagnostic Potential of ECG through Knowledge Transfer from Cardiac MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05764">http://arxiv.org/abs/2308.05764</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oetu/mmcl-ecg-cmr">https://github.com/oetu/mmcl-ecg-cmr</a></li>
<li>paper_authors: Özgün Turgut, Philip Müller, Paul Hager, Suprosanna Shit, Sophie Starck, Martin J. Menten, Eimo Martens, Daniel Rueckert<br>for:本研究的目的是使用自适应对比学习技术，将心脏磁共振成像（CMR）图像中封闭的域特征传递到电cardiogram（ECG）中，以提高心血管疾病诊断的效率和准确性。methods:本研究使用了多模态对比学习和伪数据模型，将CMR图像中的域特征与ECG数据进行对比，以学习ECG中含有的域特征。results:研究结果表明，通过使用自适应对比学习技术，可以从ECG数据中提取出各种心血管疾病的风险和各种心脏现象的信息。此外，研究还发现了ECG中含有CMR图像中封闭的域特征。<details>
<summary>Abstract</summary>
The electrocardiogram (ECG) is a widely available diagnostic tool that allows for a cost-effective and fast assessment of the cardiovascular health. However, more detailed examination with expensive cardiac magnetic resonance (CMR) imaging is often preferred for the diagnosis of cardiovascular diseases. While providing detailed visualization of the cardiac anatomy, CMR imaging is not widely available due to long scan times and high costs. To address this issue, we propose the first self-supervised contrastive approach that transfers domain-specific information from CMR images to ECG embeddings. Our approach combines multimodal contrastive learning with masked data modeling to enable holistic cardiac screening solely from ECG data. In extensive experiments using data from 40,044 UK Biobank subjects, we demonstrate the utility and generalizability of our method. We predict the subject-specific risk of various cardiovascular diseases and determine distinct cardiac phenotypes solely from ECG data. In a qualitative analysis, we demonstrate that our learned ECG embeddings incorporate information from CMR image regions of interest. We make our entire pipeline publicly available, including the source code and pre-trained model weights.
</details>
<details>
<summary>摘要</summary>
电rokardiogram (ECG) 是一种广泛可用的诊断工具，可以快速和效果地评估心血管健康。然而，更详细的检查通常使用昂贵的心血管磁共振 (CMR) 成像，以诊断心血管疾病。虽然可以提供详细的卡ди亚解剖结构，但CMR成像不够普遍使用，因为扫描时间长和成本高。为解决这个问题，我们提出了首个自动supervised contrastiveapproach，可以从CMR图像中传递域特定信息到ECG嵌入。我们的方法结合多modal contrastive学习和masked数据模型，以实现从ECG数据中进行全面的心血管检查。在使用40044名UK Biobank参与者的数据进行广泛的实验中，我们证明了我们的方法的实用性和普遍性。我们预测参与者的具体风险以及不同心血管疾病的各种疾病。在质量分析中，我们示出了我们学习的ECG嵌入包含CMR图像区域兴趣的信息。我们将整个管道公开发布，包括源代码和预训练模型参数。
</details></li>
</ul>
<hr>
<h2 id="On-the-Unexpected-Abilities-of-Large-Language-Models"><a href="#On-the-Unexpected-Abilities-of-Large-Language-Models" class="headerlink" title="On the Unexpected Abilities of Large Language Models"></a>On the Unexpected Abilities of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09720">http://arxiv.org/abs/2308.09720</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefano Nolfi</li>
<li>for: 这篇论文主要是关于大语言模型的研究，具体来说是研究这些模型如何通过 indirect acquisition 方式来获得各种能力。</li>
<li>methods: 这篇论文使用了各种 indirect acquisition 方法，包括 predicting the next words of human-written texts，来研究大语言模型的能力。</li>
<li>results: 研究发现，大语言模型通过 indirect acquisition 方式可以获得各种 интегрирован的能力，包括语言理解和生成能力。此外，这些系统还可以通过自我改进来提高自己的能力。<details>
<summary>Abstract</summary>
Large language models are capable of displaying a wide range of abilities that are not directly connected with the task for which they are trained: predicting the next words of human-written texts. In this article, I discuss the nature of this indirect acquisition process and its relation to other known indirect processes. I argue that an important side effect of such indirect acquisition is the development of integrated abilities. I discuss the extent to which the abilities developed by large language models are predictable. Finally, I briefly discuss the relation between the cognitive skills acquired by these systems and human cognition.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Neuro-Symbolic-RDF-and-Description-Logic-Reasoners-The-State-Of-The-Art-and-Challenges"><a href="#Neuro-Symbolic-RDF-and-Description-Logic-Reasoners-The-State-Of-The-Art-and-Challenges" class="headerlink" title="Neuro-Symbolic RDF and Description Logic Reasoners: The State-Of-The-Art and Challenges"></a>Neuro-Symbolic RDF and Description Logic Reasoners: The State-Of-The-Art and Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04814">http://arxiv.org/abs/2308.04814</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gunjan Singh, Sumit Bhatia, Raghava Mutharaju</li>
<li>for: This paper provides an overview of the existing literature in the field of neuro-symbolic deductive reasoning supported by RDF(S), the description logics EL and ALC, and OWL 2 RL.</li>
<li>methods: The paper discusses various techniques employed in neuro-symbolic deductive reasoning, including neural networks and symbolic systems.</li>
<li>results: The paper provides a comprehensive overview of the existing literature in the field, discussing the tasks addressed and other relevant efforts in this area.<details>
<summary>Abstract</summary>
Ontologies are used in various domains, with RDF and OWL being prominent standards for ontology development. RDF is favored for its simplicity and flexibility, while OWL enables detailed domain knowledge representation. However, as ontologies grow larger and more expressive, reasoning complexity increases, and traditional reasoners struggle to perform efficiently. Despite optimization efforts, scalability remains an issue. Additionally, advancements in automated knowledge base construction have created large and expressive ontologies that are often noisy and inconsistent, posing further challenges for conventional reasoners. To address these challenges, researchers have explored neuro-symbolic approaches that combine neural networks' learning capabilities with symbolic systems' reasoning abilities. In this chapter,we provide an overview of the existing literature in the field of neuro-symbolic deductive reasoning supported by RDF(S), the description logics EL and ALC, and OWL 2 RL, discussing the techniques employed, the tasks they address, and other relevant efforts in this area.
</details>
<details>
<summary>摘要</summary>
ontologies 在不同领域中使用，RDF 和 OWL 是 Ontology 开发的主要标准。RDF 因其简单性和灵活性而受到推崇，而 OWL 允许对域知识进行详细表示。然而，随着 ontologies 的增大和表示力的提高，推理复杂性也随之增加，传统的推理器难以高效执行。尽管进行了优化尝试，但Scalability 仍然是一个问题。此外，自动化知识库建构技术的进步创造了大量和表示力强的 ontologies，这些 ontologies 经常具有噪音和不一致性，对传统的推理器 pose 更大的挑战。为解决这些挑战，研究人员 explore 了 neuralsymbolic 方法，这些方法将 neural networks 的学习能力与 symbolic 系统的推理能力结合起来。在这章中，我们提供了 exist 的文献综述，涵盖使用 RDF(S)、描述逻辑 EL 和 ALC，以及 OWL 2 RL，讨论使用的技术、Addressed 的任务和其他相关的努力。
</details></li>
</ul>
<hr>
<h2 id="A-Fast-and-Optimal-Learning-based-Path-Planning-Method-for-Planetary-Rovers"><a href="#A-Fast-and-Optimal-Learning-based-Path-Planning-Method-for-Planetary-Rovers" class="headerlink" title="A Fast and Optimal Learning-based Path Planning Method for Planetary Rovers"></a>A Fast and Optimal Learning-based Path Planning Method for Planetary Rovers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04792">http://arxiv.org/abs/2308.04792</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiming Ji, Yang Liu, Guanghu Xie, Zongwu Xie, Baoshi Cao</li>
<li>for: 提高 planetary rover 的探索效率，通过学习方法实现快速搜索优化路径。</li>
<li>methods: 利用 numerous pre-annotated optimal path demonstrations 学习 semantic信息，生成概率分布，表示每个像素是优化路径的可能性。</li>
<li>results: 对于 novel maps，可以快速搜索优化路径，并且在同硬件条件下，导航场景生成的优化路径可以大大减少搜索时间。<details>
<summary>Abstract</summary>
Intelligent autonomous path planning is crucial to improve the exploration efficiency of planetary rovers. In this paper, we propose a learning-based method to quickly search for optimal paths in an elevation map, which is called NNPP. The NNPP model learns semantic information about start and goal locations, as well as map representations, from numerous pre-annotated optimal path demonstrations, and produces a probabilistic distribution over each pixel representing the likelihood of it belonging to an optimal path on the map. More specifically, the paper computes the traversal cost for each grid cell from the slope, roughness and elevation difference obtained from the DEM. Subsequently, the start and goal locations are encoded using a Gaussian distribution and different location encoding parameters are analyzed for their effect on model performance. After training, the NNPP model is able to perform path planning on novel maps. Experiments show that the guidance field generated by the NNPP model can significantly reduce the search time for optimal paths under the same hardware conditions, and the advantage of NNPP increases with the scale of the map.
</details>
<details>
<summary>摘要</summary>
智能自主路径规划是探索效率提高 planetary rover 的关键。本文提出一种学习基于的方法，快速搜索地形图上的优化路径，称为 NNPP。 NNPP 模型从 numerous pre-annotated 优化路径示例中学习起始和目标位置的 semantic 信息以及地图表示，并生成地图上每个像素的可能性分布，表示它是优化路径的一部分。更加具体地说，文章计算地形图上每个格子单元的行进成本，基于 DEM 中的坡度、粗糙度和高程差。然后，起始和目标位置被编码为 Gaussian 分布，并对不同的位置编码参数进行分析，以影响模型性能。在训练后，NNPP 模型可以在新地图上进行路径规划。实验表明，NNPP 模型生成的引导场可以在同样的硬件条件下减少搜索优化路径的时间，并且 NNPP 模型在地图规模增加后的优势也随着增加。
</details></li>
</ul>
<hr>
<h2 id="Multi-View-Fusion-and-Distillation-for-Subgrade-Distresses-Detection-based-on-3D-GPR"><a href="#Multi-View-Fusion-and-Distillation-for-Subgrade-Distresses-Detection-based-on-3D-GPR" class="headerlink" title="Multi-View Fusion and Distillation for Subgrade Distresses Detection based on 3D-GPR"></a>Multi-View Fusion and Distillation for Subgrade Distresses Detection based on 3D-GPR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04779">http://arxiv.org/abs/2308.04779</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chunpeng Zhou, Kangjie Ning, Haishuai Wang, Zhi Yu, Sheng Zhou, Jiajun Bu<br>for:This paper focuses on the subgrade distress detection task using 3D ground-penetrating radar (3D-GPR) data, with the goal of enhancing efficiency and accuracy through the use of automatic detection techniques and deep learning.methods:The proposed method leverages multi-view information from 3D-GPR data and constructs a real multi-view image dataset for the detection task. The method also develops a novel framework called GPR-MVFD, which incorporates multi-view distillation and attention-based fusion to extract significant features for subgrade distresses.results:The proposed framework outperforms existing GPR baselines and state-of-the-art methods in multi-view learning, multi-modal learning, and knowledge distillation, as demonstrated through extensive experiments on a new GPR benchmark. The constructed multi-view GPR dataset with expert-annotated labels and the source codes of the proposed framework will be released.<details>
<summary>Abstract</summary>
The application of 3D ground-penetrating radar (3D-GPR) for subgrade distress detection has gained widespread popularity. To enhance the efficiency and accuracy of detection, pioneering studies have attempted to adopt automatic detection techniques, particularly deep learning. However, existing works typically rely on traditional 1D A-scan, 2D B-scan or 3D C-scan data of the GPR, resulting in either insufficient spatial information or high computational complexity. To address these challenges, we introduce a novel methodology for the subgrade distress detection task by leveraging the multi-view information from 3D-GPR data. Moreover, we construct a real multi-view image dataset derived from the original 3D-GPR data for the detection task, which provides richer spatial information compared to A-scan and B-scan data, while reducing computational complexity compared to C-scan data. Subsequently, we develop a novel \textbf{M}ulti-\textbf{V}iew \textbf{V}usion and \textbf{D}istillation framework, \textbf{GPR-MVFD}, specifically designed to optimally utilize the multi-view GPR dataset. This framework ingeniously incorporates multi-view distillation and attention-based fusion to facilitate significant feature extraction for subgrade distresses. In addition, a self-adaptive learning mechanism is adopted to stabilize the model training and prevent performance degeneration in each branch. Extensive experiments conducted on this new GPR benchmark demonstrate the effectiveness and efficiency of our proposed framework. Our framework outperforms not only the existing GPR baselines, but also the state-of-the-art methods in the fields of multi-view learning, multi-modal learning, and knowledge distillation. We will release the constructed multi-view GPR dataset with expert-annotated labels and the source codes of the proposed framework.
</details>
<details>
<summary>摘要</summary>
现在广泛应用的3D地面探测（3D-GPR）技术已经为基层损伤探测带来了广泛的应用。为了提高检测效率和准确性，先锋研究者们已经尝试使用自动检测技术，特别是深度学习。然而，现有的工作通常仅仅基于传统的1D A-scan、2D B-scan或3D C-scan GPR数据，这会导致 either 缺乏空间信息 or 高度计算复杂。为解决这些挑战，我们介绍了一种新的方法oloogy for the subgrade distress detection task by leveraging the multi-view information from 3D-GPR data。此外，我们构建了来自原始3D-GPR数据的真正多视图图像集，这提供了与A-scan和B-scan数据相比更丰富的空间信息，而与C-scan数据相比又更加可靠。然后，我们开发了一种新的Multi-View Fusion and Distillation框架（GPR-MVFD），专门为了优化多视图GPR数据的利用。这个框架杰出地结合了多视图混合和注意力基于的混合，以便实现了显著的特征提取 для基层损伤。此外，我们采用了自适应学习机制，以稳定模型训练和避免每个分支的性能下降。我们在新的GPR benchmark上进行了广泛的实验，并证明了我们提出的方法的有效性和效率。我们的方法不仅超过了现有的GPR基准，还超过了多视图学习、多模态学习和知识混合等领域的状态 искусственный机制。我们将构建的多视图GPR数据集和GPR-MVFD框架的源代码一起发布。
</details></li>
</ul>
<hr>
<h2 id="Multi-modal-Multi-view-Clustering-based-on-Non-negative-Matrix-Factorization"><a href="#Multi-modal-Multi-view-Clustering-based-on-Non-negative-Matrix-Factorization" class="headerlink" title="Multi-modal Multi-view Clustering based on Non-negative Matrix Factorization"></a>Multi-modal Multi-view Clustering based on Non-negative Matrix Factorization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04778">http://arxiv.org/abs/2308.04778</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yasser Khalafaoui, Nistor Grozavu, Basarab Matei, Laurent-Walter Goix</li>
<li>for: 本研究旨在提出一种多模态多观点非正式矩阵因子分解方法，用于挖掘数据集中的多模态结构。</li>
<li>methods: 本研究使用非正式矩阵因子分解方法，通过在数据矩阵中强制非负元素的约束，将数据分解成两个矩阵：一个表示数据分区，另一个表示数据集中各个模态的聚类特征。</li>
<li>results: 实验结果表明，提出的方法在多种数据集上具有优秀的性能，与当前state-of-the-art方法相比，具有更高的准确率和更好的可读性。<details>
<summary>Abstract</summary>
By combining related objects, unsupervised machine learning techniques aim to reveal the underlying patterns in a data set. Non-negative Matrix Factorization (NMF) is a data mining technique that splits data matrices by imposing restrictions on the elements' non-negativity into two matrices: one representing the data partitions and the other to represent the cluster prototypes of the data set. This method has attracted a lot of attention and is used in a wide range of applications, including text mining, clustering, language modeling, music transcription, and neuroscience (gene separation). The interpretation of the generated matrices is made simpler by the absence of negative values. In this article, we propose a study on multi-modal clustering algorithms and present a novel method called multi-modal multi-view non-negative matrix factorization, in which we analyze the collaboration of several local NMF models. The experimental results show the value of the proposed approach, which was evaluated using a variety of data sets, and the obtained results are very promising compared to state of art methods.
</details>
<details>
<summary>摘要</summary>
通过组合相关对象，无监督机器学习技术寻求潜在的数据集下的 patrón。非正式矩阵分解（NMF）是一种数据挖掘技术，通过强制数据矩阵中元素的非负性约束，将数据分解成两个矩阵：一个表示数据分区，另一个表示数据集中聚类prototype。这种方法在各种应用中具有广泛的应用，包括文本挖掘、聚类、语言模型、音乐识别和神经科学（基因分离）。由于缺乏负值，生成的矩阵的解释变得更加简单。在本文中，我们提出了一种多模态聚类算法的研究，并提出了一种新的方法 called 多模态多视图非正式矩阵分解。我们通过分析多个本地NMF模型的协作来进行分析。实验结果显示，提出的方法在多种数据集上具有极高的效果，与现有方法相比，结果很有前途。
</details></li>
</ul>
<hr>
<h2 id="E3-UAV-An-Edge-based-Energy-Efficient-Object-Detection-System-for-Unmanned-Aerial-Vehicles"><a href="#E3-UAV-An-Edge-based-Energy-Efficient-Object-Detection-System-for-Unmanned-Aerial-Vehicles" class="headerlink" title="E3-UAV: An Edge-based Energy-Efficient Object Detection System for Unmanned Aerial Vehicles"></a>E3-UAV: An Edge-based Energy-Efficient Object Detection System for Unmanned Aerial Vehicles</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04774">http://arxiv.org/abs/2308.04774</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiashun Suo, Xingzhou Zhang, Weisong Shi, Wei Zhou</li>
<li>for: 这个研究旨在开发一个能效的无人机基础设施检测系统，以减少无人机在检测任务中的能源消耗。</li>
<li>methods: 这个系统使用了边缘 computing技术，并支援多种无人机设备、边缘设备和检测算法，以实现最佳化的能源消耗。</li>
<li>results: 实验结果显示，这个系统可以在实际应用中对检测任务进行有效的能源消耗优化。<details>
<summary>Abstract</summary>
Motivated by the advances in deep learning techniques, the application of Unmanned Aerial Vehicle (UAV)-based object detection has proliferated across a range of fields, including vehicle counting, fire detection, and city monitoring. While most existing research studies only a subset of the challenges inherent to UAV-based object detection, there are few studies that balance various aspects to design a practical system for energy consumption reduction. In response, we present the E3-UAV, an edge-based energy-efficient object detection system for UAVs. The system is designed to dynamically support various UAV devices, edge devices, and detection algorithms, with the aim of minimizing energy consumption by deciding the most energy-efficient flight parameters (including flight altitude, flight speed, detection algorithm, and sampling rate) required to fulfill the detection requirements of the task. We first present an effective evaluation metric for actual tasks and construct a transparent energy consumption model based on hundreds of actual flight data to formalize the relationship between energy consumption and flight parameters. Then we present a lightweight energy-efficient priority decision algorithm based on a large quantity of actual flight data to assist the system in deciding flight parameters. Finally, we evaluate the performance of the system, and our experimental results demonstrate that it can significantly decrease energy consumption in real-world scenarios. Additionally, we provide four insights that can assist researchers and engineers in their efforts to study UAV-based object detection further.
</details>
<details>
<summary>摘要</summary>
In response, we propose the E3-UAV, an edge-based energy-efficient object detection system for UAVs. The system is designed to dynamically support various UAV devices, edge devices, and detection algorithms, with the aim of minimizing energy consumption by determining the most energy-efficient flight parameters (including flight altitude, flight speed, detection algorithm, and sampling rate) required to fulfill the detection requirements of the task.To evaluate the performance of the system, we first present an effective evaluation metric for actual tasks and construct a transparent energy consumption model based on hundreds of actual flight data to formalize the relationship between energy consumption and flight parameters. Then, we present a lightweight energy-efficient priority decision algorithm based on a large quantity of actual flight data to assist the system in deciding flight parameters.Our experimental results demonstrate that the E3-UAV system can significantly decrease energy consumption in real-world scenarios. Additionally, we provide four insights that can assist researchers and engineers in their efforts to study UAV-based object detection further:1. The choice of detection algorithm has a significant impact on energy consumption, and the most energy-efficient algorithm may not always be the best performer.2. Flight altitude has a greater impact on energy consumption than flight speed, and adjusting flight altitude can lead to significant energy savings.3. Sampling rate has a complex relationship with energy consumption, and the optimal sampling rate depends on the specific task and environment.4. The E3-UAV system can be used for a variety of tasks beyond object detection, such as tracking and monitoring, and can be integrated with other systems to achieve even greater energy savings.In summary, the E3-UAV system represents a significant step forward in the development of energy-efficient UAV-based object detection systems, and our insights provide valuable guidance for future research and development in this area.
</details></li>
</ul>
<hr>
<h2 id="Induction-Network-Audio-Visual-Modality-Gap-Bridging-for-Self-Supervised-Sound-Source-Localization"><a href="#Induction-Network-Audio-Visual-Modality-Gap-Bridging-for-Self-Supervised-Sound-Source-Localization" class="headerlink" title="Induction Network: Audio-Visual Modality Gap-Bridging for Self-Supervised Sound Source Localization"></a>Induction Network: Audio-Visual Modality Gap-Bridging for Self-Supervised Sound Source Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04767">http://arxiv.org/abs/2308.04767</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tahy1/avin">https://github.com/tahy1/avin</a></li>
<li>paper_authors: Tianyu Liu, Peng Zhang, Wei Huang, Yufei Zha, Tao You, Yanning Zhang</li>
<li>for: 本研究旨在解决自主顺序声音源localization中的modal inconsistency问题，通过对听写和视觉特征进行更好的匹配，提高声音源localization的精度和稳定性。</li>
<li>methods: 本研究提出了一种名为Induction Network的新网络模型，通过分离视觉和听写模态的梯度，使得视觉特征更好地学习声音源的描述性特征，同时听写模态也可以与视觉模态一样准确地匹配。此外，本研究还引入了一种适应阈值选择策略，以提高induction网络的Robustness。</li>
<li>results: 实验表明，Compared with其他State-of-the-art工作，本研究的方法在不同的挑战性enario中具有更高的性能和稳定性。特别是在SoundNet-Flickr和VGG-Sound Source数据集上，本研究的方法的声音源localization性能都达到了最高水平。<details>
<summary>Abstract</summary>
Self-supervised sound source localization is usually challenged by the modality inconsistency. In recent studies, contrastive learning based strategies have shown promising to establish such a consistent correspondence between audio and sound sources in visual scenarios. Unfortunately, the insufficient attention to the heterogeneity influence in the different modality features still limits this scheme to be further improved, which also becomes the motivation of our work. In this study, an Induction Network is proposed to bridge the modality gap more effectively. By decoupling the gradients of visual and audio modalities, the discriminative visual representations of sound sources can be learned with the designed Induction Vector in a bootstrap manner, which also enables the audio modality to be aligned with the visual modality consistently. In addition to a visual weighted contrastive loss, an adaptive threshold selection strategy is introduced to enhance the robustness of the Induction Network. Substantial experiments conducted on SoundNet-Flickr and VGG-Sound Source datasets have demonstrated a superior performance compared to other state-of-the-art works in different challenging scenarios. The code is available at https://github.com/Tahy1/AVIN
</details>
<details>
<summary>摘要</summary>
自我超vision的声源localization通常面临modal inconsistency挑战。近年来，基于对比学习的策略在视觉场景中已经展示了promising的表现，可以建立声源和视觉模态之间的一致性。然而，忽视不同模态特征之间的多样性影响仍然限制了这种方案的进一步改进，这也成为了我们的研究动机。在这项研究中，我们提出了一种启发网络，可以更有效地bridging模态差距。通过解coupling视觉和声音模态的梯度，可以学习视觉特征中声源的抽象表示，同时使声音模态与视觉模态保持一致。此外，我们还引入了一种视觉权重对比损失和适应阈值选择策略，以增强启发网络的稳定性。在SoundNet-Flickr和VGG-Sound Source等数据集上进行了大量实验，并证明了与其他状态 искус技术相比，我们的方法在不同的挑战场景中具有优秀的表现。代码可以在https://github.com/Tahy1/AVIN中下载。
</details></li>
</ul>
<hr>
<h2 id="Feature-Matching-Data-Synthesis-for-Non-IID-Federated-Learning"><a href="#Feature-Matching-Data-Synthesis-for-Non-IID-Federated-Learning" class="headerlink" title="Feature Matching Data Synthesis for Non-IID Federated Learning"></a>Feature Matching Data Synthesis for Non-IID Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04761">http://arxiv.org/abs/2308.04761</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijian Li, Yuchang Sun, Jiawei Shao, Yuyi Mao, Jessie Hui Wang, Jun Zhang</li>
<li>for: This paper proposes a novel federated learning (FL) framework with data augmentation to relieve data heterogeneity, which can effectively address the non-independent and identically distributed (non-IID) data challenge in FL.</li>
<li>methods: The proposed framework uses a hard feature matching data synthesis (HFMDS) method to share auxiliary data besides local models, which generates synthetic data by learning the essential class-relevant features of real samples and discarding the redundant features. To further enhance privacy preservation, a hard feature augmentation method is proposed to transfer real features towards the decision boundary, making the synthetic data not only improve the model generalization but also erase the information of real features.</li>
<li>results: The theoretical analysis and simulation results demonstrate that the proposed HFMDS-FL algorithm outperforms the baselines in terms of accuracy, privacy preservation, and computational cost on various benchmark datasets.<details>
<summary>Abstract</summary>
Federated learning (FL) has emerged as a privacy-preserving paradigm that trains neural networks on edge devices without collecting data at a central server. However, FL encounters an inherent challenge in dealing with non-independent and identically distributed (non-IID) data among devices. To address this challenge, this paper proposes a hard feature matching data synthesis (HFMDS) method to share auxiliary data besides local models. Specifically, synthetic data are generated by learning the essential class-relevant features of real samples and discarding the redundant features, which helps to effectively tackle the non-IID issue. For better privacy preservation, we propose a hard feature augmentation method to transfer real features towards the decision boundary, with which the synthetic data not only improve the model generalization but also erase the information of real features. By integrating the proposed HFMDS method with FL, we present a novel FL framework with data augmentation to relieve data heterogeneity. The theoretical analysis highlights the effectiveness of our proposed data synthesis method in solving the non-IID challenge. Simulation results further demonstrate that our proposed HFMDS-FL algorithm outperforms the baselines in terms of accuracy, privacy preservation, and computational cost on various benchmark datasets.
</details>
<details>
<summary>摘要</summary>
federated learning (FL) 已经成为一种保持隐私的 парадиг，通过在边缘设备上训练神经网络而不需要收集数据到中央服务器。然而，FL 遇到了非独立和同样分布 (非 IID) 数据问题。为解决这个挑战，本文提出了一种困难特征匹配数据合成 (HFMDS) 方法，以及在本地模型 aside，共享auxiliary数据。具体来说，我们通过学习实际样本中的重要类相关特征，并丢弃 redundant 特征，可以有效地解决非 IID 问题。为了更好地保持隐私，我们提议一种困难特征增强方法，通过将实际特征转移到决策边界，使得synthetic数据不仅提高模型通用性，还消除实际特征的信息。通过将提档的 HFMDS 方法与 FL 集成，我们提出了一种新的 FL 框架，并在不同的 benchmark 数据集上进行了实验。理论分析表明，我们的提档的数据合成方法能够有效地解决非 IID 问题。实验结果还表明，我们的 HFMDS-FL 算法在准确率、隐私保持和计算成本等方面，与基eline相比，在不同的 benchmark 数据集上表现出色。
</details></li>
</ul>
<hr>
<h2 id="Automated-Driving-Without-Ethics-Meaning-Design-and-Real-World-Implementation"><a href="#Automated-Driving-Without-Ethics-Meaning-Design-and-Real-World-Implementation" class="headerlink" title="Automated Driving Without Ethics: Meaning, Design and Real-World Implementation"></a>Automated Driving Without Ethics: Meaning, Design and Real-World Implementation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04760">http://arxiv.org/abs/2308.04760</a></li>
<li>repo_url: None</li>
<li>paper_authors: Katherine Evans, Nelson de Moura, Raja Chatila, Stéphane Chauvier</li>
<li>for: 这 paper 的目的是提出一种基于预定参数的 AV 决策策略，以便在各种决策场景中满足不同的人道主义观点和公众期望。</li>
<li>methods: 该策略使用了 Ethical Valence Theory，将 AV 决策视为一种缓冲降低报告的过程，并提出多种可能的决策规则，以便在具体的决策场景中选择最适合的行动。</li>
<li>results: 该策略可以帮助评估自动化汽车的决策是否符合社会可接受水平，并且可以满足不同的人道主义观点和公众期望。<details>
<summary>Abstract</summary>
The ethics of automated vehicles (AV) has received a great amount of attention in recent years, specifically in regard to their decisional policies in accident situations in which human harm is a likely consequence. After a discussion about the pertinence and cogency of the term 'artificial moral agent' to describe AVs that would accomplish these sorts of decisions, and starting from the assumption that human harm is unavoidable in some situations, a strategy for AV decision making is proposed using only pre-defined parameters to characterize the risk of possible accidents and also integrating the Ethical Valence Theory, which paints AV decision-making as a type of claim mitigation, into multiple possible decision rules to determine the most suitable action given the specific environment and decision context. The goal of this approach is not to define how moral theory requires vehicles to behave, but rather to provide a computational approach that is flexible enough to accommodate a number of human 'moral positions' concerning what morality demands and what road users may expect, offering an evaluation tool for the social acceptability of an automated vehicle's decision making.
</details>
<details>
<summary>摘要</summary>
自动驾驶车（AV）的伦理问题在最近几年内得到了广泛的关注，尤其是在冲突情况下人类伤害的可能性存在时。 после一些讨论“人造道德代理人”这个术语是否适用于AV，以及从假设存在某些情况下人类伤害是不可避免的前提下，一种基于预先定义的参数来描述可能发生的事故风险，以及纳入伦理价值论中的多种可能的决策规则，以确定在特定环境和决策上最合适的行动。该方法的目的不是定义自动车如何行事，而是提供一种计算方法，能够适应人类“道德位置”的多种要求和公路用户的期望，并提供评估自动车决策的社会可接受性的工具。
</details></li>
</ul>
<hr>
<h2 id="Bird’s-Eye-View-Scene-Graph-for-Vision-Language-Navigation"><a href="#Bird’s-Eye-View-Scene-Graph-for-Vision-Language-Navigation" class="headerlink" title="Bird’s-Eye-View Scene Graph for Vision-Language Navigation"></a>Bird’s-Eye-View Scene Graph for Vision-Language Navigation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04758">http://arxiv.org/abs/2308.04758</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rui Liu, Xiaohan Wang, Wenguan Wang, Yi Yang</li>
<li>for: 这篇论文主要研究的是视觉语言导航（VLN）技术，即让机器人根据人类的指令在3D环境中进行导航。</li>
<li>methods: 该论文提出了一种基于多步BEV表示（BEV Scene Graph，BSG）的方法，用于编码室内环境的场景布局和几何特征。在导航过程中，BSG会建立当前步骤的本地BEV表示，并维护一个基于BEV的全局场景地图，用于存储和组织在线收集的所有本地BEV表示。</li>
<li>results: 与现有方法相比，该方法在REVERIE、R2R和R4R等测试 datasets 上显示出了明显的提升。这表明BEV感知在VLN中具有潜在的应用前景。<details>
<summary>Abstract</summary>
Vision-language navigation (VLN), which entails an agent to navigate 3D environments following human instructions, has shown great advances. However, current agents are built upon panoramic observations, which hinders their ability to perceive 3D scene geometry and easily leads to ambiguous selection of panoramic view. To address these limitations, we present a BEV Scene Graph (BSG), which leverages multi-step BEV representations to encode scene layouts and geometric cues of indoor environment under the supervision of 3D detection. During navigation, BSG builds a local BEV representation at each step and maintains a BEV-based global scene map, which stores and organizes all the online collected local BEV representations according to their topological relations. Based on BSG, the agent predicts a local BEV grid-level decision score and a global graph-level decision score, combined with a sub-view selection score on panoramic views, for more accurate action prediction. Our approach significantly outperforms state-of-the-art methods on REVERIE, R2R, and R4R, showing the potential of BEV perception in VLN.
</details>
<details>
<summary>摘要</summary>
vision-language navigation (VLN) 已经取得了很大的进步，但现有的代理人都是基于投影的观察，这会限制它们对3D场景的理解和 Selection of panoramic view 的能力。为了解决这些局限性，我们提出了 BEV 场景图 (BSG)，它利用多步 BEV 表示来编码室内环境的场景布局和几何信息。在导航过程中，BSG 在每个步骤建立了本地 BEV 表示，并维护了基于 BEV 的全局场景图，该图存储和组织了在线收集的所有本地 BEV 表示，根据它们的 topological relations。基于 BSG，代理人可以预测本地 BEV 格子级别的决策分数和全局图级别的决策分数，同时还可以基于投影视图进行更准确的动作预测。我们的方法在 REVERIE、R2R 和 R4R 上表现出了明显的突破，demonstrating the potential of BEV perception in VLN。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Efficient-Continual-Learning-with-Dynamic-Structure-Development-of-Spiking-Neural-Networks"><a href="#Enhancing-Efficient-Continual-Learning-with-Dynamic-Structure-Development-of-Spiking-Neural-Networks" class="headerlink" title="Enhancing Efficient Continual Learning with Dynamic Structure Development of Spiking Neural Networks"></a>Enhancing Efficient Continual Learning with Dynamic Structure Development of Spiking Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04749">http://arxiv.org/abs/2308.04749</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/braincog-x/brain-cog">https://github.com/braincog-x/brain-cog</a></li>
<li>paper_authors: Bing Han, Feifei Zhao, Yi Zeng, Wenxuan Pan, Guobin Shen</li>
<li>For: The paper proposes a new method for efficient and adaptive continual learning in Spiking Neural Networks (SNNs), inspired by the dynamic structure development of the human brain during child growth and development.* Methods: The proposed method, called Dynamic Structure Development of Spiking Neural Networks (DSD-SNN), dynamically assigns and grows new neurons to new tasks, prunes redundant neurons, and leverages overlapping shared structure to quickly adapt to new tasks while reducing computational overhead.* Results: The proposed model achieves significant improvements in performance, learning speed, and memory capacity compared to existing SNNs-based continual learning methods, and achieves comparable performance with DNNs-based methods.<details>
<summary>Abstract</summary>
Children possess the ability to learn multiple cognitive tasks sequentially, which is a major challenge toward the long-term goal of artificial general intelligence. Existing continual learning frameworks are usually applicable to Deep Neural Networks (DNNs) and lack the exploration on more brain-inspired, energy-efficient Spiking Neural Networks (SNNs). Drawing on continual learning mechanisms during child growth and development, we propose Dynamic Structure Development of Spiking Neural Networks (DSD-SNN) for efficient and adaptive continual learning. When learning a sequence of tasks, the DSD-SNN dynamically assigns and grows new neurons to new tasks and prunes redundant neurons, thereby increasing memory capacity and reducing computational overhead. In addition, the overlapping shared structure helps to quickly leverage all acquired knowledge to new tasks, empowering a single network capable of supporting multiple incremental tasks (without the separate sub-network mask for each task). We validate the effectiveness of the proposed model on multiple class incremental learning and task incremental learning benchmarks. Extensive experiments demonstrated that our model could significantly improve performance, learning speed and memory capacity, and reduce computational overhead. Besides, our DSD-SNN model achieves comparable performance with the DNNs-based methods, and significantly outperforms the state-of-the-art (SOTA) performance for existing SNNs-based continual learning methods.
</details>
<details>
<summary>摘要</summary>
children possess the ability to learn multiple cognitive tasks sequentially, which is a major challenge toward the long-term goal of artificial general intelligence. Existing continual learning frameworks are usually applicable to Deep Neural Networks (DNNs) and lack the exploration on more brain-inspired, energy-efficient Spiking Neural Networks (SNNs). Drawing on continual learning mechanisms during child growth and development, we propose Dynamic Structure Development of Spiking Neural Networks (DSD-SNN) for efficient and adaptive continual learning. When learning a sequence of tasks, the DSD-SNN dynamically assigns and grows new neurons to new tasks and prunes redundant neurons, thereby increasing memory capacity and reducing computational overhead. In addition, the overlapping shared structure helps to quickly leverage all acquired knowledge to new tasks, empowering a single network capable of supporting multiple incremental tasks (without the separate sub-network mask for each task). We validate the effectiveness of the proposed model on multiple class incremental learning and task incremental learning benchmarks. Extensive experiments demonstrated that our model could significantly improve performance, learning speed and memory capacity, and reduce computational overhead. Besides, our DSD-SNN model achieves comparable performance with the DNNs-based methods, and significantly outperforms the state-of-the-art (SOTA) performance for existing SNNs-based continual learning methods.Here's the text in Traditional Chinese:children possess the ability to learn multiple cognitive tasks sequentially, which is a major challenge toward the long-term goal of artificial general intelligence. Existing continual learning frameworks are usually applicable to Deep Neural Networks (DNNs) and lack the exploration on more brain-inspired, energy-efficient Spiking Neural Networks (SNNs). Drawing on continual learning mechanisms during child growth and development, we propose Dynamic Structure Development of Spiking Neural Networks (DSD-SNN) for efficient and adaptive continual learning. When learning a sequence of tasks, the DSD-SNN dynamically assigns and grows new neurons to new tasks and prunes redundant neurons, thereby increasing memory capacity and reducing computational overhead. In addition, the overlapping shared structure helps to quickly leverage all acquired knowledge to new tasks, empowering a single network capable of supporting multiple incremental tasks (without the separate sub-network mask for each task). We validate the effectiveness of the proposed model on multiple class incremental learning and task incremental learning benchmarks. Extensive experiments demonstrated that our model could significantly improve performance, learning speed and memory capacity, and reduce computational overhead. Besides, our DSD-SNN model achieves comparable performance with the DNNs-based methods, and significantly outperforms the state-of-the-art (SOTA) performance for existing SNNs-based continual learning methods.
</details></li>
</ul>
<hr>
<h2 id="Case-Study-Using-AI-Assisted-Code-Generation-In-Mobile-Teams"><a href="#Case-Study-Using-AI-Assisted-Code-Generation-In-Mobile-Teams" class="headerlink" title="Case Study: Using AI-Assisted Code Generation In Mobile Teams"></a>Case Study: Using AI-Assisted Code Generation In Mobile Teams</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04736">http://arxiv.org/abs/2308.04736</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mircea-Serban Vasiliniuc, Adrian Groza</li>
<li>for: 本研究旨在评估人工智能助成编程在实际移动开发团队中的性能，具体是使用适应性的编程语言如kotlin和swift。</li>
<li>methods: 该研究采用了一项大规模的实验研究，参与者共16人，两名技术评审人，从一家软件开发公司的移动部门中挑选参与者，以了解在特定阶段使用LLMs进行代码生成的影响，具体来说是技术培训和技术栈转换。</li>
<li>results: 研究结果表明，使用AI助成编程工具可以提高开发效率和正确率，同时也可以帮助开发者更快地适应新的技术环境。<details>
<summary>Abstract</summary>
The aim of this study is to evaluate the performance of AI-assisted programming in actual mobile development teams that are focused on native mobile languages like Kotlin and Swift. The extensive case study involves 16 participants and 2 technical reviewers, from a software development department designed to understand the impact of using LLMs trained for code generation in specific phases of the team, more specifically, technical onboarding and technical stack switch. The study uses technical problems dedicated to each phase and requests solutions from the participants with and without using AI-Code generators. It measures time, correctness, and technical integration using ReviewerScore, a metric specific to the paper and extracted from actual industry standards, the code reviewers of merge requests. The output is converted and analyzed together with feedback from the participants in an attempt to determine if using AI-assisted programming tools will have an impact on getting developers onboard in a project or helping them with a smooth transition between the two native development environments of mobile development, Android and iOS. The study was performed between May and June 2023 with members of the mobile department of a software development company based in Cluj-Napoca, with Romanian ownership and management.
</details>
<details>
<summary>摘要</summary>
这项研究的目的是评估人工智能助手在实际移动开发团队中的表现，这些团队专注于本地移动语言如kotlin和swift。这项案例研究包括16名参与者和2名技术评审员，来自软件开发部门，旨在了解使用LLMs生成代码在特定阶段的团队中的影响，具体来说是技术培训和技术栈转换。研究使用每个阶段的技术问题，并请参与者在使用AI代码生成器和不使用其之间提交解决方案。研究测量时间、正确性和技术 интеграción使用ReviewerScore指标，该指标来自实际业界标准，代码审查人员对合并请求的反馈。输出被转换和分析，并与参与者反馈结合，以确定使用AI助手编程工具是否会影响开发人员在项目中上手或者在 Android 和 iOS 两个本地开发环境之间的畅转。研究在2023年5月至6月进行，参与者来自罗马尼亚CLuj-Napoca的软件开发公司的移动部门，该公司拥有罗马尼亚所有和管理。
</details></li>
</ul>
<hr>
<h2 id="JEN-1-Text-Guided-Universal-Music-Generation-with-Omnidirectional-Diffusion-Models"><a href="#JEN-1-Text-Guided-Universal-Music-Generation-with-Omnidirectional-Diffusion-Models" class="headerlink" title="JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models"></a>JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04729">http://arxiv.org/abs/2308.04729</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peike Li, Boyu Chen, Yao Yao, Yikai Wang, Allen Wang, Alex Wang</li>
<li>for: 本研究旨在提出一种高精度的文本到音乐生成模型，以解决现有模型的音乐质量和计算效率问题。</li>
<li>methods: 该模型基于扩散过程，并结合了 autoregressive 和 non-autoregressive 训练方法，通过在 Context 学习来实现多种生成任务，包括文本指导音乐生成、音乐填充和续写。</li>
<li>results: 对比先前方法，JEN-1 在文本音乐对齐和音乐质量两个指标上具有显著优势，同时保持计算效率。研究人员提供了在线示例，详细介绍了模型的应用和实现。<details>
<summary>Abstract</summary>
Music generation has attracted growing interest with the advancement of deep generative models. However, generating music conditioned on textual descriptions, known as text-to-music, remains challenging due to the complexity of musical structures and high sampling rate requirements. Despite the task's significance, prevailing generative models exhibit limitations in music quality, computational efficiency, and generalization. This paper introduces JEN-1, a universal high-fidelity model for text-to-music generation. JEN-1 is a diffusion model incorporating both autoregressive and non-autoregressive training. Through in-context learning, JEN-1 performs various generation tasks including text-guided music generation, music inpainting, and continuation. Evaluations demonstrate JEN-1's superior performance over state-of-the-art methods in text-music alignment and music quality while maintaining computational efficiency. Our demos are available at http://futureverse.com/research/jen/demos/jen1
</details>
<details>
<summary>摘要</summary>
音乐生成已经吸引了深入的关注，随着深度生成模型的发展。然而，根据文本描述生成音乐，也称为文本到音乐，仍然是一个挑战，因为音乐结构的复杂性和高抽样率的需求。尽管这个任务的重要性，现有的生成模型却表现出限制，包括音乐质量、计算效率和泛化能力。这篇论文介绍了JEN-1，一种通用的高精度模型 для文本到音乐生成。JEN-1是一种扩散模型，通过同时使用抽样和非抽样训练，实现了在文本指导下生成音乐、音乐填充和续写等多种生成任务。评估结果表明，JEN-1在文本音乐对齐和音乐质量方面表现出了明显的优异性，同时保持计算效率。我们的 demo 可以在 http://futureverse.com/research/jen/demos/jen1 上查看。
</details></li>
</ul>
<hr>
<h2 id="Data-Free-Model-Extraction-Attacks-in-the-Context-of-Object-Detection"><a href="#Data-Free-Model-Extraction-Attacks-in-the-Context-of-Object-Detection" class="headerlink" title="Data-Free Model Extraction Attacks in the Context of Object Detection"></a>Data-Free Model Extraction Attacks in the Context of Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05127">http://arxiv.org/abs/2308.05127</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harshit Shah, Aravindhan G, Pavan Kulkarni, Yuvaraj Govidarajulu, Manojkumar Parmar</li>
<li>for: 本研究旨在攻击机器学习模型中的模型EXTRACTION攻击，通过使用特制的查询语句来盗取目标模型。</li>
<li>methods: 本研究使用了数据自由模型EXTRACTION技术，通过使用生成器类似于生成对抗网络的设置，将查询语句人工地制成，以实现在白盒环境中模拟目标模型。</li>
<li>results: 研究发现，定义损失函数和生成器的设置是EXTRACTION攻击的关键因素，并且使用合理的查询语句可以获得显著的结果。这种对找象检测模型的攻击将支持未来保护这些模型的安全。<details>
<summary>Abstract</summary>
A significant number of machine learning models are vulnerable to model extraction attacks, which focus on stealing the models by using specially curated queries against the target model. This task is well accomplished by using part of the training data or a surrogate dataset to train a new model that mimics a target model in a white-box environment. In pragmatic situations, however, the target models are trained on private datasets that are inaccessible to the adversary. The data-free model extraction technique replaces this problem when it comes to using queries artificially curated by a generator similar to that used in Generative Adversarial Nets. We propose for the first time, to the best of our knowledge, an adversary black box attack extending to a regression problem for predicting bounding box coordinates in object detection. As part of our study, we found that defining a loss function and using a novel generator setup is one of the key aspects in extracting the target model. We find that the proposed model extraction method achieves significant results by using reasonable queries. The discovery of this object detection vulnerability will support future prospects for securing such models.
</details>
<details>
<summary>摘要</summary>
许多机器学习模型容易受到模型EXTRACTION攻击，这种攻击将目标模型通过使用特制的查询来盗取模型。在实际情况下，目标模型通常是使用私有数据进行训练，这些数据不可 accessible于敌方。我们提出了一种数据free模型EXTRACTION技术，使用生成器类似于生成对抗网络来生成训练数据。我们在这种情况下首次，至少知道的情况下，将敌方黑盒攻击扩展到回归问题中，用于预测物体检测中的矩形坐标。在我们的研究中，我们发现了定义损失函数和使用新的生成器设置是EXTRACTION模型的关键方面。我们发现，使用合理的查询，提议的模型EXTRACTION方法可以取得显著的结果。这种发现将对物体检测模型的安全提供支持。
</details></li>
</ul>
<hr>
<h2 id="JiangJun-Mastering-Xiangqi-by-Tackling-Non-Transitivity-in-Two-Player-Zero-Sum-Games"><a href="#JiangJun-Mastering-Xiangqi-by-Tackling-Non-Transitivity-in-Two-Player-Zero-Sum-Games" class="headerlink" title="JiangJun: Mastering Xiangqi by Tackling Non-Transitivity in Two-Player Zero-Sum Games"></a>JiangJun: Mastering Xiangqi by Tackling Non-Transitivity in Two-Player Zero-Sum Games</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04719">http://arxiv.org/abs/2308.04719</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yang Li, Kun Xiong, Yingping Zhang, Jiangcheng Zhu, Stephen Mcaleer, Wei Pan, Jun Wang, Zonghong Dai, Yaodong Yang</li>
<li>for: 这个论文是为了研究完美信息游戏中的非传统性，具体来说是研究中国传统棋盘游戏象棋，与棋盘复杂度相当的棋盘游戏。</li>
<li>methods: 这个论文使用了人类对象棋盘游戏的纪录分析，以及蜕虫 Monte-Carlo Tree Search（MCTS）和策略空间响应器（PSRO）的组合，以估算 Nash 平衡。</li>
<li>results: 这个论文通过对 WeChat 小程序进行实践测试，实现了人类玩家的Master级别冠军，win rate 为 99.41%。这个结果表明了算法的有效性在超越非传统性方面。<details>
<summary>Abstract</summary>
This paper presents an empirical exploration of non-transitivity in perfect-information games, specifically focusing on Xiangqi, a traditional Chinese board game comparable in game-tree complexity to chess and shogi. By analyzing over 10,000 records of human Xiangqi play, we highlight the existence of both transitive and non-transitive elements within the game's strategic structure. To address non-transitivity, we introduce the JiangJun algorithm, an innovative combination of Monte-Carlo Tree Search (MCTS) and Policy Space Response Oracles (PSRO) designed to approximate a Nash equilibrium. We evaluate the algorithm empirically using a WeChat mini program and achieve a Master level with a 99.41\% win rate against human players. The algorithm's effectiveness in overcoming non-transitivity is confirmed by a plethora of metrics, such as relative population performance and visualization results. Our project site is available at \url{https://sites.google.com/view/jiangjun-site/}.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Generative-Perturbation-Analysis-for-Probabilistic-Black-Box-Anomaly-Attribution"><a href="#Generative-Perturbation-Analysis-for-Probabilistic-Black-Box-Anomaly-Attribution" class="headerlink" title="Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution"></a>Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04708">http://arxiv.org/abs/2308.04708</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/idesan/gpa">https://github.com/idesan/gpa</a></li>
<li>paper_authors: Tsuyoshi Idé, Naoki Abe</li>
<li>for: 本文针对黑盒回归Setting中的概率异常归因 Task进行研究，目标是计算每个输入变量的异常归因分布。</li>
<li>methods: 本文提出了一种新的概率异常归因框架，可以计算异常归因分布以及异常归因分布的uncertainty。这种框架基于对异常观察的perturbations进行counter-factual reasoning。</li>
<li>results: 本文提出了一种基于变量 Bayes算法的方法来derive异常归因分布的 distributions。这种方法可以减少异常归因分布的uncertainty。根据作者所知，这是第一个不受异常归因的概率异常归因框架。<details>
<summary>Abstract</summary>
We address the task of probabilistic anomaly attribution in the black-box regression setting, where the goal is to compute the probability distribution of the attribution score of each input variable, given an observed anomaly. The training dataset is assumed to be unavailable. This task differs from the standard XAI (explainable AI) scenario, since we wish to explain the anomalous deviation from a black-box prediction rather than the black-box model itself.   We begin by showing that mainstream model-agnostic explanation methods, such as the Shapley values, are not suitable for this task because of their ``deviation-agnostic property.'' We then propose a novel framework for probabilistic anomaly attribution that allows us to not only compute attribution scores as the predictive mean but also quantify the uncertainty of those scores. This is done by considering a generative process for perturbations that counter-factually bring the observed anomalous observation back to normalcy. We introduce a variational Bayes algorithm for deriving the distributions of per variable attribution scores. To the best of our knowledge, this is the first probabilistic anomaly attribution framework that is free from being deviation-agnostic.
</details>
<details>
<summary>摘要</summary>
我们考虑了黑盒回归Setting中的概率异常归因问题，其目标是计算每个输入变量的归因分布，给出观察到的异常。我们假设训练数据集不可用。这个任务与标准XAI（可解释AI）场景不同，我们想要解释黑盒预测的异常偏差，而不是黑盒模型本身。我们首先表明，主流的模型无关解释方法，如雪佛利值，不适合这个任务，因为它们的“偏差无关性”性。然后，我们提出了一种新的概率异常归因框架，允许我们不仅计算归因分布，还能量度这些分布的不确定性。这是通过考虑一种生成过程来perturbations counter-factually bring the observed anomalous observation back to normalcy来实现的。我们引入了一种变分极 bayes算法来 derive the distributions of per variable attribution scores。到目前为止，这是免受偏差无关性的第一个概率异常归因框架。
</details></li>
</ul>
<hr>
<h2 id="Explainable-AI-in-Orthopedics-Challenges-Opportunities-and-Prospects"><a href="#Explainable-AI-in-Orthopedics-Challenges-Opportunities-and-Prospects" class="headerlink" title="Explainable AI in Orthopedics: Challenges, Opportunities, and Prospects"></a>Explainable AI in Orthopedics: Challenges, Opportunities, and Prospects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04696">http://arxiv.org/abs/2308.04696</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soheyla Amirian, Luke A. Carlson, Matthew F. Gong, Ines Lohse, Kurt R. Weiss, Johannes F. Plate, Ahmad P. Tafti</li>
<li>for: 本研究旨在解决医疗机器学习（AI）在orthopedics中的解释性和可解释性问题，以便临床医生、外科医生和患者能够理解AI模型的各种预测和描述模型的贡献因素。</li>
<li>methods: 本研究采用了多种方法，包括临床实践、数据分析和模型开发，以解决XAI在orthopedics中的挑战。</li>
<li>results: 本研究发现了一些关键的挑战和机遇，包括数据不一致、模型复杂性和解释性要求等，这些挑战需要在AI实践中得到解决，以便在orthopedics中广泛采用XAI。<details>
<summary>Abstract</summary>
While artificial intelligence (AI) has made many successful applications in various domains, its adoption in healthcare lags a little bit behind other high-stakes settings. Several factors contribute to this slower uptake, including regulatory frameworks, patient privacy concerns, and data heterogeneity. However, one significant challenge that impedes the implementation of AI in healthcare, particularly in orthopedics, is the lack of explainability and interpretability around AI models. Addressing the challenge of explainable AI (XAI) in orthopedics requires developing AI models and algorithms that prioritize transparency and interpretability, allowing clinicians, surgeons, and patients to understand the contributing factors behind any AI-powered predictive or descriptive models. The current contribution outlines several key challenges and opportunities that manifest in XAI in orthopedic practice. This work emphasizes the need for interdisciplinary collaborations between AI practitioners, orthopedic specialists, and regulatory entities to establish standards and guidelines for the adoption of XAI in orthopedics.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在不同领域取得了许多成功应用，但在医疗领域的采纳相对落后一些。这些因素包括法规框架、患者隐私问题和数据多样性。然而，在医疗领域中，特别是在骨科方面，缺乏可解释性和解释力是人工智能的实施的一大障碍。解决骨科中的可解释人工智能（XAI）挑战需要开发可透明和可解释的AI模型和算法，让临床医生、外科医生和患者理解任何基于AI的预测或描述性模型的贡献因素。本著作描述了骨科中XAI的一些关键挑战和机遇，并强调需要在AI实践者、骨科专家和法规机构之间建立标准和指南，以便在骨科中广泛采用XAI。
</details></li>
</ul>
<hr>
<h2 id="Finite-Element-Operator-Network-for-Solving-Parametric-PDEs"><a href="#Finite-Element-Operator-Network-for-Solving-Parametric-PDEs" class="headerlink" title="Finite Element Operator Network for Solving Parametric PDEs"></a>Finite Element Operator Network for Solving Parametric PDEs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04690">http://arxiv.org/abs/2308.04690</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jae Yong Lee, Seungchan Ko, Youngjoon Hong</li>
<li>for: 解决 parametric PDEs 的数值方法问题</li>
<li>methods: 提议使用 Finite Element Operator Network (FEONet) 方法，兼用深度学习和传统数值方法，解决 parametric PDEs 问题，不需要输入输出对应的训练数据</li>
<li>results: 在多个 benchmark 问题中，FEONet 方法比现有的状态 искусственный intelligence 方法更高精度、更好的泛化性和计算灵活性，并且可以应用于各种领域中， где PDEs 扮演关键角色。<details>
<summary>Abstract</summary>
Partial differential equations (PDEs) underlie our understanding and prediction of natural phenomena across numerous fields, including physics, engineering, and finance. However, solving parametric PDEs is a complex task that necessitates efficient numerical methods. In this paper, we propose a novel approach for solving parametric PDEs using a Finite Element Operator Network (FEONet). Our proposed method leverages the power of deep learning in conjunction with traditional numerical methods, specifically the finite element method, to solve parametric PDEs in the absence of any paired input-output training data. We demonstrate the effectiveness of our approach on several benchmark problems and show that it outperforms existing state-of-the-art methods in terms of accuracy, generalization, and computational flexibility. Our FEONet framework shows potential for application in various fields where PDEs play a crucial role in modeling complex domains with diverse boundary conditions and singular behavior. Furthermore, we provide theoretical convergence analysis to support our approach, utilizing finite element approximation in numerical analysis.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="web-crawler-strategies-for-web-pages-under-robot-txt-restriction"><a href="#web-crawler-strategies-for-web-pages-under-robot-txt-restriction" class="headerlink" title="web crawler strategies for web pages under robot.txt restriction"></a>web crawler strategies for web pages under robot.txt restriction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04689">http://arxiv.org/abs/2308.04689</a></li>
<li>repo_url: None</li>
<li>paper_authors: Piyush Vyas, Akhilesh Chauhan, Tushar Mandge, Surbhi Hardikar</li>
<li>for: 本研究paper introduce了搜索引擎对 keywords 的工作，以便用户通过搜索获得搜寻结果。</li>
<li>methods: 本研究使用了不同的搜索算法，以提供便捷的搜寻结果给网络浏览者。</li>
<li>results: 本研究回答了一些基本问题，例如网页在搜索引擎中如何获得高排名、搜索引擎如何获得网页的全部内容、网站管理员如何透过 robot.txt 文件对网络爬虫进行限制等等。<details>
<summary>Abstract</summary>
In the present time, all know about World Wide Web and work over the Internet daily. In this paper, we introduce the search engines working for keywords that are entered by users to find something. The search engine uses different search algorithms for convenient results for providing to the net surfer. Net surfers go with the top search results but how did the results of web pages get higher ranks over search engines? how the search engine got that all the web pages in the database? This paper gives the answers to all these kinds of basic questions. Web crawlers working for search engines and robot exclusion protocol rules for web crawlers are also addressed in this research paper. Webmaster uses different restriction facts in robot.txt file to instruct web crawler, some basic formats of robot.txt are also mentioned in this paper.
</details>
<details>
<summary>摘要</summary>
现在，所有人都知道世界延伸网（World Wide Web）以及在互联网上每天进行工作。在这篇论文中，我们介绍了用户输入关键词时搜索引擎所使用的不同搜索算法，以提供便利的搜索结果给网络浏览者。网络浏览者通常会遵循搜索结果的排名，但是如何使得网页在搜索引擎中获得高排名呢？这篇论文会回答这些基本问题。此外，我们还会讨论搜索引擎使用的网络爬虫（web crawler）以及爬虫排除协议（robot exclusion protocol）规则。网站管理员可以使用 robot.txt 文件中的不同限制事实来 instruc爬虫，这篇论文还将介绍一些基本的 robot.txt 格式。
</details></li>
</ul>
<hr>
<h2 id="Rapid-Training-Data-Creation-by-Synthesizing-Medical-Images-for-Classification-and-Localization"><a href="#Rapid-Training-Data-Creation-by-Synthesizing-Medical-Images-for-Classification-and-Localization" class="headerlink" title="Rapid Training Data Creation by Synthesizing Medical Images for Classification and Localization"></a>Rapid Training Data Creation by Synthesizing Medical Images for Classification and Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04687">http://arxiv.org/abs/2308.04687</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhishek Kushwaha, Sarthak Gupta, Anish Bhanushali, Tathagato Rai Dastidar<br>for: 这篇论文的目的是解决医疗影像分析中对于资料标注的问题，以及实现对于医疗影像的训练深度神经网络所需的大量标注资料的产生。methods: 这篇论文使用了一种方法来将真实的数据转换为训练深度神经网络所需的标注资料。这种方法可以帮助解决医疗影像分析中对于资料标注的问题，并且可以实现对于医疗影像的训练深度神经网络所需的大量标注资料的产生。results: 这篇论文的结果显示，使用这种方法可以将医疗影像的训练深度神经网络的对于标注的精度提高 significantly。另外，这种方法可以实现对于医疗影像的训练深度神经网络所需的大量标注资料的产生，并且可以与实际的标注资料相对比较。<details>
<summary>Abstract</summary>
While the use of artificial intelligence (AI) for medical image analysis is gaining wide acceptance, the expertise, time and cost required to generate annotated data in the medical field are significantly high, due to limited availability of both data and expert annotation. Strongly supervised object localization models require data that is exhaustively annotated, meaning all objects of interest in an image are identified. This is difficult to achieve and verify for medical images. We present a method for the transformation of real data to train any Deep Neural Network to solve the above problems. We show the efficacy of this approach on both a weakly supervised localization model and a strongly supervised localization model. For the weakly supervised model, we show that the localization accuracy increases significantly using the generated data. For the strongly supervised model, this approach overcomes the need for exhaustive annotation on real images. In the latter model, we show that the accuracy, when trained with generated images, closely parallels the accuracy when trained with exhaustively annotated real images. The results are demonstrated on images of human urine samples obtained using microscopy.
</details>
<details>
<summary>摘要</summary>
Artificial intelligence (AI) for medical image analysis 受欢迎，但是在医疗领域生成标注数据的专业知识、时间和成本很高，主要是因为医疗数据和专家标注数据的有限性。强制supervised对象定位模型需要完全标注的数据，这是医疗图像中很难以完成和验证。我们提出了一种将实际数据转换为训练任何深度神经网络的方法。我们在弱supervised对象定位模型和强制supervised对象定位模型中应用了这种方法，并证明了其效果。对于弱supervised模型，我们发现使用生成的数据可以显著提高对象定位精度。对于强制supervised模型，这种方法可以解决实际图像中的尝试性标注问题，并且在使用生成的图像进行训练时，对象定位精度与使用实际图像进行训练时的精度几乎相同。我们在人体尿样微scopic图像中进行了实验，并证明了这种方法的有效性。
</details></li>
</ul>
<hr>
<h2 id="Sci-CoT-Leveraging-Large-Language-Models-for-Enhanced-Knowledge-Distillation-in-Small-Models-for-Scientific-QA"><a href="#Sci-CoT-Leveraging-Large-Language-Models-for-Enhanced-Knowledge-Distillation-in-Small-Models-for-Scientific-QA" class="headerlink" title="Sci-CoT: Leveraging Large Language Models for Enhanced Knowledge Distillation in Small Models for Scientific QA"></a>Sci-CoT: Leveraging Large Language Models for Enhanced Knowledge Distillation in Small Models for Scientific QA</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04679">http://arxiv.org/abs/2308.04679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuhan Ma, Haiqi Jiang, Chenyou Fan</li>
<li>for: 这 paper 是 investigate LLMs 的 reasoning 能力，并尝试将其转移到 smaller models 上。</li>
<li>methods: 该 paper 使用 knowledge distillation 方法，分离 rationales 和 answer 的生成过程，以提高 scientific question-answering 任务 的性能。</li>
<li>results: 该 paper 的 80 亿参数模型在 ARC-Easy 数据集下，在 few shot 设定下，超过 BLOOM-176B 的性能。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) have shown outstanding performance across wide range of downstream tasks. This competency is attributed to their substantial parameter size and pre-training on extensive corpus. Moreover, LLMs have exhibited enhanced reasoning capabilities in tackling complex reasoning tasks, owing to the utilization of a method named ``Chain-of-Thought (CoT) prompting''. This method is designed to generate intermediate reasoning steps that guide the inference of the final answer. However, it is essential to highlight that these advanced reasoning abilities appear to emerge in models with a minimum of 10 billion parameters, thereby limiting its efficacy in situations where computational resources are constrained. In this paper, we investigate the possibility of transferring the reasoning capabilities of LLMs to smaller models via knowledge distillation. Specifically, we propose Sci-CoT, a two-stage framework that separates the processes of generating rationales and inferring answers. This method enables a more efficient use of rationales during the answer inference stage, leading to improved performance on scientific question-answering tasks. Utilizing Sci-CoT, our 80-million parameter model is able to exceed the performance of BLOOM-176B in the ARC-Easy dataset under the few shot setting.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Addressing-Racial-Bias-in-Facial-Emotion-Recognition"><a href="#Addressing-Racial-Bias-in-Facial-Emotion-Recognition" class="headerlink" title="Addressing Racial Bias in Facial Emotion Recognition"></a>Addressing Racial Bias in Facial Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04674">http://arxiv.org/abs/2308.04674</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alex Fan, Xingshuo Xiao, Peter Washington</li>
<li>for: 该研究旨在分析深度学习模型在高维输入和主观标签下的公平性问题。</li>
<li>methods: 该研究使用变换训练集的方法来分析种族偏见，并评估模型在不同种族群体中的表现。</li>
<li>results: 研究发现，尽管使用更小的训练集可以改善公平性和性能指标，但在更大的数据集中，种族偏见指标通常保持不变，这表明种族平衡本身不足以实现不同种族群体中的表现均衡。<details>
<summary>Abstract</summary>
Fairness in deep learning models trained with high-dimensional inputs and subjective labels remains a complex and understudied area. Facial emotion recognition, a domain where datasets are often racially imbalanced, can lead to models that yield disparate outcomes across racial groups. This study focuses on analyzing racial bias by sub-sampling training sets with varied racial distributions and assessing test performance across these simulations. Our findings indicate that smaller datasets with posed faces improve on both fairness and performance metrics as the simulations approach racial balance. Notably, the F1-score increases by $27.2\%$ points, and demographic parity increases by $15.7\%$ points on average across the simulations. However, in larger datasets with greater facial variation, fairness metrics generally remain constant, suggesting that racial balance by itself is insufficient to achieve parity in test performance across different racial groups.
</details>
<details>
<summary>摘要</summary>
“深入学习模型对高维输入和主观标签的公平性问题仍然是一个复杂和未得到充分研究的领域。 facial emotion recognition 领域中的数据集经常具有种族不均衡，这可能导致不同种族群体之间的模型性能差异。本研究通过对训练集进行不同种族分布的子批采样，并评估测试性能在这些模拟中的变化。我们发现，使用posed faces的训练集可以提高公平性和性能指标，特别是在模拟中接近种族均衡时。平均而言，使用posed faces的训练集可以提高 F1 分数27.2个百分点，并提高了种族平衡指标15.7个百分点。然而，在大型数据集中，公平指标通常保持不变，这表明，只有寻求种族均衡不能 garantate 测试性能的平衡 across different racial groups。”Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="SSL-Auth-An-Authentication-Framework-by-Fragile-Watermarking-for-Pre-trained-Encoders-in-Self-supervised-Learning"><a href="#SSL-Auth-An-Authentication-Framework-by-Fragile-Watermarking-for-Pre-trained-Encoders-in-Self-supervised-Learning" class="headerlink" title="SSL-Auth: An Authentication Framework by Fragile Watermarking for Pre-trained Encoders in Self-supervised Learning"></a>SSL-Auth: An Authentication Framework by Fragile Watermarking for Pre-trained Encoders in Self-supervised Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04673">http://arxiv.org/abs/2308.04673</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaobei Li, Changchun Yin, Liming Fang, Run Wang, Chenhao Lin</li>
<li>for: 这篇论文的目的是为自动学习（SSL）中的标本处理器提供认证框架，以保护标本处理器的知识产权和在部署时确保标本处理器的可靠性。</li>
<li>methods: 这篇论文使用选择的键amples作为水印信息，并训练一个验证网络来重建水印信息，以验证标本处理器的完整性。</li>
<li>results: 实验结果显示，SSL-Auth可以实现标本处理器的完整性验证，并且可以探测到潜在的黑门和攻击攻击。实验结果显示，SSL-Auth不会对标本处理器的性能造成影响。<details>
<summary>Abstract</summary>
Self-supervised learning (SSL), utilizing unlabeled datasets for training powerful encoders, has achieved significant success recently. These encoders serve as feature extractors for downstream tasks, requiring substantial resources. However, the challenge of protecting the intellectual property of encoder trainers and ensuring the trustworthiness of deployed encoders remains a significant gap in SSL. Moreover, recent researches highlight threats to pre-trained encoders, such as backdoor and adversarial attacks. To address these gaps, we propose SSL-Auth, the first authentication framework designed specifically for pre-trained encoders. In particular, SSL-Auth utilizes selected key samples as watermark information and trains a verification network to reconstruct the watermark information, thereby verifying the integrity of the encoder without compromising model performance. By comparing the reconstruction results of the key samples, malicious alterations can be detected, as modified encoders won't mimic the original reconstruction. Comprehensive evaluations on various encoders and diverse downstream tasks demonstrate the effectiveness and fragility of our proposed SSL-Auth.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Resource-Constrained-Model-Compression-via-Minimax-Optimization-for-Spiking-Neural-Networks"><a href="#Resource-Constrained-Model-Compression-via-Minimax-Optimization-for-Spiking-Neural-Networks" class="headerlink" title="Resource Constrained Model Compression via Minimax Optimization for Spiking Neural Networks"></a>Resource Constrained Model Compression via Minimax Optimization for Spiking Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04672">http://arxiv.org/abs/2308.04672</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chenjallen/resource-constrained-compression-on-snn">https://github.com/chenjallen/resource-constrained-compression-on-snn</a></li>
<li>paper_authors: Jue Chen, Huan Yuan, Jianchao Tan, Bin Chen, Chengru Song, Di Zhang</li>
<li>for:  This paper focuses on compressing Brain-inspired Spiking Neural Networks (SNNs) to improve their deployment on edge devices such as neuromorphic chips.</li>
<li>methods: The proposed method uses an improved end-to-end Minimax optimization method for sparse learning to balance model performance and computation efficiency.</li>
<li>results: The compressed SNN models achieved state-of-the-art (SOTA) performance on various benchmark datasets and architectures.Here’s the same information in Simplified Chinese:</li>
<li>for: 这篇论文主要关注压缩Brain-inspired Spiking Neural Networks (SNNs)，以提高其在边缘设备such as neuromorphic chips上的部署。</li>
<li>methods: 提议的方法使用改进的末端Minimax优化方法来解决稀疏学习问题，以更好地均衡模型性能和计算效率。</li>
<li>results: 压缩后的SNN模型在多个 benchmark数据集和架构上达到了最佳性能（SOTA）。I hope that helps!<details>
<summary>Abstract</summary>
Brain-inspired Spiking Neural Networks (SNNs) have the characteristics of event-driven and high energy-efficient, which are different from traditional Artificial Neural Networks (ANNs) when deployed on edge devices such as neuromorphic chips. Most previous work focuses on SNNs training strategies to improve model performance and brings larger and deeper network architectures. It is difficult to deploy these complex networks on resource-limited edge devices directly. To meet such demand, people compress SNNs very cautiously to balance the performance and the computation efficiency. Existing compression methods either iteratively pruned SNNs using weights norm magnitude or formulated the problem as a sparse learning optimization. We propose an improved end-to-end Minimax optimization method for this sparse learning problem to better balance the model performance and the computation efficiency. We also demonstrate that jointly applying compression and finetuning on SNNs is better than sequentially, especially for extreme compression ratios. The compressed SNN models achieved state-of-the-art (SOTA) performance on various benchmark datasets and architectures. Our code is available at https://github.com/chenjallen/Resource-Constrained-Compression-on-SNN.
</details>
<details>
<summary>摘要</summary>
�建基于大脑的�顿神经网络（SNN）具有事件驱动和高能效的特点，与传统的人工神经网络（ANN）不同，当部署在边缘设备such as neuromorphic chips时。大多数先前的工作将焦点放在SNNs 训练策略以提高模型性能，并带来更大和更深的网络架构。然而，这些复杂的网络直接部署在有限的边缘设备上是困难的。为满足这种需求，人们很注意地压缩SNNs以平衡性能和计算效率。现有的压缩方法包括Iteratively pruning SNNs使用权重norm magnitude或将问题形式为稀疏学习优化问题。我们提出了改进的端到端最小最大优化方法，以更好地平衡模型性能和计算效率。我们还示出，将压缩和训练结合在一起，特别是在极高的压缩比例时，jointly applying compression and finetuning on SNNs 更好than sequentially。压缩后的SNN模型在多个benchmark datasets和架构上达到了state-of-the-art（SOTA）性能。我们的代码可以在https://github.com/chenjallen/Resource-Constrained-Compression-on-SNN上找到。
</details></li>
</ul>
<hr>
<h2 id="A-Hierarchical-Destroy-and-Repair-Approach-for-Solving-Very-Large-Scale-Travelling-Salesman-Problem"><a href="#A-Hierarchical-Destroy-and-Repair-Approach-for-Solving-Very-Large-Scale-Travelling-Salesman-Problem" class="headerlink" title="A Hierarchical Destroy and Repair Approach for Solving Very Large-Scale Travelling Salesman Problem"></a>A Hierarchical Destroy and Repair Approach for Solving Very Large-Scale Travelling Salesman Problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04639">http://arxiv.org/abs/2308.04639</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhang-Hua Fu, Sipeng Sun, Jintong Ren, Tianshu Yu, Haoyu Zhang, Yuanyuan Liu, Lingxiao Huang, Xiang Yan, Pinyan Lu</li>
<li>for: 提出了一种解决大规模的旅行商问题（TSP）的算法，以提高现有算法的计算效率和解决质量。</li>
<li>methods: 提出了一种层次破坏重建（HDR）方法，通过一系列精心设计的破坏重建操作来改进初始解。具有层次搜索框架，可以在一定的等价保证下压缩输入实例，从而提高计算效率。</li>
<li>results: 在 nineteen 个著名的大规模实例上进行了公正的比较，显示 HDR 在计算效率和解决质量两个方面具有竞争力，并在两个大实例上打破了世界纪录。<details>
<summary>Abstract</summary>
For prohibitively large-scale Travelling Salesman Problems (TSPs), existing algorithms face big challenges in terms of both computational efficiency and solution quality. To address this issue, we propose a hierarchical destroy-and-repair (HDR) approach, which attempts to improve an initial solution by applying a series of carefully designed destroy-and-repair operations. A key innovative concept is the hierarchical search framework, which recursively fixes partial edges and compresses the input instance into a small-scale TSP under some equivalence guarantee. This neat search framework is able to deliver highly competitive solutions within a reasonable time. Fair comparisons based on nineteen famous large-scale instances (with 10,000 to 10,000,000 cities) show that HDR is highly competitive against existing state-of-the-art TSP algorithms, in terms of both efficiency and solution quality. Notably, on two large instances with 3,162,278 and 10,000,000 cities, HDR breaks the world records (i.e., best-known results regardless of computation time), which were previously achieved by LKH and its variants, while HDR is completely independent of LKH. Finally, ablation studies are performed to certify the importance and validity of the hierarchical search framework.
</details>
<details>
<summary>摘要</summary>
For 非常大规模的旅行销售人员问题 (TSP), 现有的算法面临着计算效率和解决质量两个大的挑战。为了解决这个问题，我们提议一种层次破坏和重建 (HDR) 方法，它尝试通过一系列特制的破坏和重建操作来提高初始解。一个关键创新的搜索框架是层次搜索框架，它可以在一定的等价保证下将输入实例压缩到小规模的 TSP 中进行搜索。这个搜索框架能够在有限时间内提供高度竞争力的解决方案。基于 nineteen 著名的大规模实例 (10,000 到 10,000,000 个城市) 进行了公正的比较，显示 HDR 在计算效率和解决质量两个方面与现有的状态 искусственный智能 TSP 算法高度竞争。特别是在 3,162,278 和 10,000,000 个城市的两个大实例上，HDR 破坏了世界纪录 (即不管计算时间为何)，这些纪录曾由 LKH 和其变种所获得，而 HDR 与 LKH 完全无关。最后，我们进行了剖面研究，以证明层次搜索框架的重要性和有效性。
</details></li>
</ul>
<hr>
<h2 id="Sparse-Binary-Transformers-for-Multivariate-Time-Series-Modeling"><a href="#Sparse-Binary-Transformers-for-Multivariate-Time-Series-Modeling" class="headerlink" title="Sparse Binary Transformers for Multivariate Time Series Modeling"></a>Sparse Binary Transformers for Multivariate Time Series Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04637">http://arxiv.org/abs/2308.04637</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matt Gorbett, Hossein Shirazi, Indrakshi Ray<br>for:This paper focuses on applying sparse and binary-weighted Transformers to multivariate time series problems, with the goal of achieving accuracy comparable to that of dense floating-point Transformers while reducing computational complexity.methods:The authors use two compression techniques to reduce the number of non-zero operations necessary in the Transformer: 1) applying a fixed mask to the query, key, and value activations, and 2) proposing an attention mask to allow computation only at the current time step.results:The model achieves favorable results across three time series learning tasks: classification, anomaly detection, and single-step forecasting, with up to a 53x reduction in storage size and up to 10.5x reduction in FLOPs compared to the dense floating-point Transformers.<details>
<summary>Abstract</summary>
Compressed Neural Networks have the potential to enable deep learning across new applications and smaller computational environments. However, understanding the range of learning tasks in which such models can succeed is not well studied. In this work, we apply sparse and binary-weighted Transformers to multivariate time series problems, showing that the lightweight models achieve accuracy comparable to that of dense floating-point Transformers of the same structure. Our model achieves favorable results across three time series learning tasks: classification, anomaly detection, and single-step forecasting. Additionally, to reduce the computational complexity of the attention mechanism, we apply two modifications, which show little to no decline in model performance: 1) in the classification task, we apply a fixed mask to the query, key, and value activations, and 2) for forecasting and anomaly detection, which rely on predicting outputs at a single point in time, we propose an attention mask to allow computation only at the current time step. Together, each compression technique and attention modification substantially reduces the number of non-zero operations necessary in the Transformer. We measure the computational savings of our approach over a range of metrics including parameter count, bit size, and floating point operation (FLOPs) count, showing up to a 53x reduction in storage size and up to 10.5x reduction in FLOPs.
</details>
<details>
<summary>摘要</summary>
压缩神经网络（Compressed Neural Networks）具有启动深度学习的潜力，但未有充分研究其在不同任务下的范围。在这个工作中，我们运用稀疑和二进制权重的 transformer 来解决多元时间序问题，获得了与组 dense floating-point transformer 相同结构的精度。我们的模型在三个时间序学习任务中获得了良好的结果：分类、侦测异常和预测。此外，为降低对于注意力机制的计算复杂度，我们提出了两种修改，它们几乎没有影响模型性能：1）在分类任务中，我们对查询、钥匙和值活动中的数据应用固定的面罩，2）在预测和侦测任务中，我们提出了一个注意力面罩，允许只在目前时间步进行计算。组合这些压缩技术和注意力修改，我们可以对 transformer 进行重大的储存空间和计算复杂度的节省。我们使用多个指标来衡量我们的方法对于储存空间、位元数和浮点操作（FLOPs）的节省，获得了最多 53 倍的储存空间节省和最多 10.5 倍的 FLOPs 节省。
</details></li>
</ul>
<hr>
<h2 id="Where’s-the-Liability-in-Harmful-AI-Speech"><a href="#Where’s-the-Liability-in-Harmful-AI-Speech" class="headerlink" title="Where’s the Liability in Harmful AI Speech?"></a>Where’s the Liability in Harmful AI Speech?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04635">http://arxiv.org/abs/2308.04635</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peter Henderson, Tatsunori Hashimoto, Mark Lemley</li>
<li>for: 这篇论文探讨了基于文本的生成AI模型在不同法律责任 régime下的责任风险，以及模型创造者和部署者是否受到法律责任。</li>
<li>methods: 文章使用了三种责任 régime来分析生成AI模型的责任风险，包括诽谤、speech integral to criminal conduct和wrongful death。</li>
<li>results: 文章发现，任何 Section 230 免责分析或下游责任分析都与算法设计细节有紧密的关系，而且在法律责任上存在多个障碍，使得很难确定生成AI模型和关联的党员是否承担生成的言论责任。文章认为，AI应不被总是免责，法院和政策制定者应该仔细考虑技术设计的优化，以便更好地评估这些问题。<details>
<summary>Abstract</summary>
Generative AI, in particular text-based "foundation models" (large models trained on a huge variety of information including the internet), can generate speech that could be problematic under a wide range of liability regimes. Machine learning practitioners regularly "red team" models to identify and mitigate such problematic speech: from "hallucinations" falsely accusing people of serious misconduct to recipes for constructing an atomic bomb. A key question is whether these red-teamed behaviors actually present any liability risk for model creators and deployers under U.S. law, incentivizing investments in safety mechanisms. We examine three liability regimes, tying them to common examples of red-teamed model behaviors: defamation, speech integral to criminal conduct, and wrongful death. We find that any Section 230 immunity analysis or downstream liability analysis is intimately wrapped up in the technical details of algorithm design. And there are many roadblocks to truly finding models (and their associated parties) liable for generated speech. We argue that AI should not be categorically immune from liability in these scenarios and that as courts grapple with the already fine-grained complexities of platform algorithms, the technical details of generative AI loom above with thornier questions. Courts and policymakers should think carefully about what technical design incentives they create as they evaluate these issues.
</details>
<details>
<summary>摘要</summary>
优先级AI，特别是基于文本的“基础模型”（大型模型通过互联网上庞大量信息进行训练），可能会生成有问题的语音。机器学习实践者 regularely “红军”模型以识别和避免这些问题语音，从“幻觉”（误告人员严重不当行为）到杀人炸弹的制作方法。关键问题是这些红色测试行为是否对美国法律而言带来责任风险，并促使投资于安全机制。我们研究了三种责任 régime，与常见的红色测试模型行为相关：诽谤、语音与刑事活动相关、和谋杀。我们发现，任何 Section 230 免责分析或下游责任分析都与算法设计技术细节有紧密的关系。而且有很多障碍物，使得真正找到模型（以及关联的党）因生成的语音而负责。我们认为AI shouldn't be categorically immune from liability in these scenarios，而且法院和政策制定者在评估这些问题时应该仔细考虑技术设计的吸引力。
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Study-of-Sentence-Embedding-Models-for-Assessing-Semantic-Variation"><a href="#A-Comparative-Study-of-Sentence-Embedding-Models-for-Assessing-Semantic-Variation" class="headerlink" title="A Comparative Study of Sentence Embedding Models for Assessing Semantic Variation"></a>A Comparative Study of Sentence Embedding Models for Assessing Semantic Variation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04625">http://arxiv.org/abs/2308.04625</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deven M. Mistry, Ali A. Minai</li>
<li>for: 本研究探讨了长文本中语义变化的pattern，从式学、认知和语言学角度都很有趣。同时，这种分析也有应用于文本分 segmentation、文摘概要和语义新颖性检测等领域。</li>
<li>methods: 本研究使用了多种vector-space方法来实现语句嵌入，并对这些方法的一致性和意义性进行了评估。</li>
<li>results: 研究发现，大多数语句嵌入方法在给定的文档中具有高相关性，但显示出有趣的差异。<details>
<summary>Abstract</summary>
Analyzing the pattern of semantic variation in long real-world texts such as books or transcripts is interesting from the stylistic, cognitive, and linguistic perspectives. It is also useful for applications such as text segmentation, document summarization, and detection of semantic novelty. The recent emergence of several vector-space methods for sentence embedding has made such analysis feasible. However, this raises the issue of how consistent and meaningful the semantic representations produced by various methods are in themselves. In this paper, we compare several recent sentence embedding methods via time-series of semantic similarity between successive sentences and matrices of pairwise sentence similarity for multiple books of literature. In contrast to previous work using target tasks and curated datasets to compare sentence embedding methods, our approach provides an evaluation of the methods 'in the wild'. We find that most of the sentence embedding methods considered do infer highly correlated patterns of semantic similarity in a given document, but show interesting differences.
</details>
<details>
<summary>摘要</summary>
分析长文本中的语义变化 Pattern 是从语言、认知和风格等多个角度来看的非常有趣。同时，这也有很多应用，例如文本分 segmentation、文摘概要和语义新颖性检测。随着 sentence embedding 技术的出现，这种分析变得可能。然而，这也引出了各种方法生成的语义表示是否具有一致性和意义的问题。在这篇文章中，我们对一些最近的 sentence embedding 方法进行了比较，使用时间序列的语义相似性和多本文学作品的对应矩阵来评估这些方法。与之前使用目标任务和精心制作的数据集来评估 sentence embedding 方法不同，我们的方法在实际应用中进行了评估。我们发现大多数考虑的 sentence embedding 方法在给定的文档中具有高度相关的语义相似性模式，但是具有舒适的差异。
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-LLM-powered-Chatbots-Methods-and-Metrics"><a href="#Benchmarking-LLM-powered-Chatbots-Methods-and-Metrics" class="headerlink" title="Benchmarking LLM powered Chatbots: Methods and Metrics"></a>Benchmarking LLM powered Chatbots: Methods and Metrics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04624">http://arxiv.org/abs/2308.04624</a></li>
<li>repo_url: None</li>
<li>paper_authors: Debarag Banerjee, Pooja Singh, Arjun Avadhanam, Saksham Srivastava</li>
<li>for: 评估自动对话机器人（chatbot）的性能，特别是使用生成型人工智能工具（Large Language Models，LLMs）的chatbot。</li>
<li>methods: 提出一种新的终到终（End to End，E2E）benchmark，用于评估chatbot的答案准确性和用用性。</li>
<li>results: 通过对一个示例chatbot进行评估，显示E2E benchmark能够更好地评估chatbot的性能，而且与其他常用的metric相比，E2E benchmark的metric（cosine similarity）表现良好。<details>
<summary>Abstract</summary>
Autonomous conversational agents, i.e. chatbots, are becoming an increasingly common mechanism for enterprises to provide support to customers and partners. In order to rate chatbots, especially ones powered by Generative AI tools like Large Language Models (LLMs) we need to be able to accurately assess their performance. This is where chatbot benchmarking becomes important. In this paper, we propose the use of a novel benchmark that we call the E2E (End to End) benchmark, and show how the E2E benchmark can be used to evaluate accuracy and usefulness of the answers provided by chatbots, especially ones powered by LLMs. We evaluate an example chatbot at different levels of sophistication based on both our E2E benchmark, as well as other available metrics commonly used in the state of art, and observe that the proposed benchmark show better results compared to others. In addition, while some metrics proved to be unpredictable, the metric associated with the E2E benchmark, which uses cosine similarity performed well in evaluating chatbots. The performance of our best models shows that there are several benefits of using the cosine similarity score as a metric in the E2E benchmark.
</details>
<details>
<summary>摘要</summary>
自动化对话代理（即 chatbot）在企业提供客户和伙伴支持的机制中变得越来越普遍。为了评估 chatbot 的性能，特别是基于大型语言模型（LLM）的话语生成器，我们需要能够准确评估它们的表现。这是 где对话机器人评估变得重要。在这篇论文中，我们提议使用一种新的评估标准，称之为端到端（E2E）标准，并证明了该标准可以准确评估对话机器人的答案准确性和用于性。我们对一个示例的对话机器人进行了不同水平的评估，并证明了我们的 E2E 标准与其他常见的状态艺术metric 相比，能够更好地评估对话机器人的性能。此外，我们发现了一些 metrics 的不可预测性，但是与 E2E 标准相关的 cosine 相似性分数metric 表现了良好的评估能力。我们的最佳模型表示，使用 cosine 相似性分数作为metric 在 E2E 标准中有几个优点。
</details></li>
</ul>
<hr>
<h2 id="Accelerating-LLM-Inference-with-Staged-Speculative-Decoding"><a href="#Accelerating-LLM-Inference-with-Staged-Speculative-Decoding" class="headerlink" title="Accelerating LLM Inference with Staged Speculative Decoding"></a>Accelerating LLM Inference with Staged Speculative Decoding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04623">http://arxiv.org/abs/2308.04623</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benjamin Spector, Chris Re</li>
<li>for: 加速大语言模型（LLM）的读取速度，特别是在小批量、设备上的场景下。</li>
<li>methods: 提出了一种新的算法——阶段化推测解码，以优化小批量 inference 的性能。首先，将推测批处理为树状结构，从而降低生成成本和提高每批 tokens 的预期数量。其次，添加了第二个阶段的推测解码。综上所述，对于一个 762M 参数的 GPT-2-L 模型，单批解码延迟时间可以下降至 3.16 倍，同时保持输出质量不变。</li>
<li>results: 对于一个 762M 参数的 GPT-2-L 模型，单批解码延迟时间可以下降至 3.16 倍，同时保持输出质量不变。<details>
<summary>Abstract</summary>
Recent advances with large language models (LLM) illustrate their diverse capabilities. We propose a novel algorithm, staged speculative decoding, to accelerate LLM inference in small-batch, on-device scenarios. We address the low arithmetic intensity of small-batch inference by improving upon previous work in speculative decoding. First, we restructure the speculative batch as a tree, which reduces generation costs and increases the expected tokens per batch. Second, we add a second stage of speculative decoding. Taken together, we reduce single-batch decoding latency by 3.16x with a 762M parameter GPT-2-L model while perfectly preserving output quality.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Model-of-models-–-Part-1"><a href="#Model-of-models-–-Part-1" class="headerlink" title="Model of models – Part 1"></a>Model of models – Part 1</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04600">http://arxiv.org/abs/2308.04600</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shimon Komarovsky</li>
<li>for: 这篇论文提出了一种新的认知模型，作为人工智能代理人的主要组件。这个模型是基于先前的模型，如DENN和AKREM，并包括操作模型（帧&#x2F;类）和愿望。这个模型的核心假设是认知是基于积累知识的操作，并且由适当的愿望导航。此外，这个模型还具有每个智能方面的双重特性，如顶下向和底向学习、总结特化和通用化、以及更多的特性。</li>
<li>methods: 这个模型的主要方法包括基于对照原理的认知演化，从婴儿期到成年期，通过固化原理来描述达到成熟状态。此外，模型还包括一种普适的 AGI 设计方法，以及认知下Constraints or efficiency的方法，如重用和简洁。</li>
<li>results: 这个模型的最终产品是一个动态操作记忆，包含模型和实例。此外，论文还提供了一些示例和初步的进化阶段来达到成熟状态的想法。<details>
<summary>Abstract</summary>
This paper proposes a new cognitive model, acting as the main component of an AGI agent. The model is introduced in its mature intelligence state, and as an extension of previous models, DENN, and especially AKREM, by including operational models (frames/classes) and will. This model's core assumption is that cognition is about operating on accumulated knowledge, with the guidance of an appropriate will. Also, we assume that the actions, part of knowledge, are learning to be aligned with will, during the evolution phase that precedes the mature intelligence state. In addition, this model is mainly based on the duality principle in every known intelligent aspect, such as exhibiting both top-down and bottom-up model learning, generalization verse specialization, and more. Furthermore, a holistic approach is advocated for AGI designing, and cognition under constraints or efficiency is proposed, in the form of reusability and simplicity. Finally, reaching this mature state is described via a cognitive evolution from infancy to adulthood, utilizing a consolidation principle. The final product of this cognitive model is a dynamic operational memory of models and instances. Lastly, some examples and preliminary ideas for the evolution phase to reach the mature state are presented.
</details>
<details>
<summary>摘要</summary>
The model is based on the duality principle in every known intelligent aspect, such as top-down and bottom-up model learning, generalization and specialization, and more. Additionally, the model advocates for a holistic approach to AGI design and cognition under constraints or efficiency, in the form of reusability and simplicity.The model proposes a cognitive evolution from infancy to adulthood, utilizing a consolidation principle to reach the mature state. The final product of the model is a dynamic operational memory of models and instances. Some examples and preliminary ideas for the evolution phase to reach the mature state are also presented.Here is the text in Simplified Chinese:这篇论文提出了一个新的认知模型，作为人工通用智能（AGI）代理人的主要组件。该模型是前一代模型DENN和AKREM的扩展，包括操作模型（框架/类）和愿power。模型的核心假设是认知是通过储存的知识进行操作，并且被适当的愿power引导。模型还假设行为，是知识的一部分，在演化阶段前置于成熟智能状态时，通过学习和对愿power的调整，使行为与愿power相吻合。此外，模型还基于知识的每一个智能方面的 dualism原理，例如展现出顶下向和底上向的模型学习、通用和特殊化、以及更多的方面。模型还提出了一种整体的方法 дляAGI设计和认知，即在约束或效率下进行认知，通过再用性和简洁来实现。最后，模型描述了一种认知演化从婴儿期到成年期，通过固化原理来达到成熟状态。最后，模型还提供了一些初步的演化阶段来达到成熟状态的例子和想法。
</details></li>
</ul>
<hr>
<h2 id="Shepherd-A-Critic-for-Language-Model-Generation"><a href="#Shepherd-A-Critic-for-Language-Model-Generation" class="headerlink" title="Shepherd: A Critic for Language Model Generation"></a>Shepherd: A Critic for Language Model Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04592">http://arxiv.org/abs/2308.04592</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/shepherd">https://github.com/facebookresearch/shepherd</a></li>
<li>paper_authors: Tianlu Wang, Ping Yu, Xiaoqing Ellen Tan, Sean O’Brien, Ramakanth Pasunuru, Jane Dwivedi-Yu, Olga Golovneva, Luke Zettlemoyer, Maryam Fazel-Zarandi, Asli Celikyilmaz</li>
<li>for: 这个论文是为了提出一种基于语言模型的自修复技术，以提高语言模型的输出质量。</li>
<li>methods: 该论文使用了一个特定的语言模型（Shepherd），通过 crítique 答案和提供修复建议来扩展语言模型的能力，并使用高质量的反馈数据集来支持。</li>
<li>results: 根据GPT-4的评价，Shepherd的评价与其他成熔比赛的模型相当或更高（53-87%的胜率），而在人工评价中，Shepherd优于其他模型，并与ChatGPT相对较为均衡。<details>
<summary>Abstract</summary>
As large language models improve, there is increasing interest in techniques that leverage these models' capabilities to refine their own outputs. In this work, we introduce Shepherd, a language model specifically tuned to critique responses and suggest refinements, extending beyond the capabilities of an untuned model to identify diverse errors and provide suggestions to remedy them. At the core of our approach is a high quality feedback dataset, which we curate from community feedback and human annotations. Even though Shepherd is small (7B parameters), its critiques are either equivalent or preferred to those from established models including ChatGPT. Using GPT-4 for evaluation, Shepherd reaches an average win-rate of 53-87% compared to competitive alternatives. In human evaluation, Shepherd strictly outperforms other models and on average closely ties with ChatGPT.
</details>
<details>
<summary>摘要</summary>
large language models 的改进引起了越来越多的关注，这些技术可以利用这些模型的能力来优化其输出。在这项工作中，我们介绍Shepherd，一种特地适应批判回答和提供修正的语言模型，超出了未调节模型的能力，能够识别多种错误并提供修正方案。我们的方法的核心是高质量的反馈数据集，我们从社区反馈和人工标注中筛选出来。尽管Shepherd只有7B个参数，但它的批判比与已有的模型，如ChatGPT相当或更好。使用GPT-4进行评估，Shepherd的平均胜率为53-87%，与竞争对手相比。在人类评估中，Shepherd严格超越了其他模型，平均与ChatGPT相对。
</details></li>
</ul>
<hr>
<h2 id="Temporal-DINO-A-Self-supervised-Video-Strategy-to-Enhance-Action-Prediction"><a href="#Temporal-DINO-A-Self-supervised-Video-Strategy-to-Enhance-Action-Prediction" class="headerlink" title="Temporal DINO: A Self-supervised Video Strategy to Enhance Action Prediction"></a>Temporal DINO: A Self-supervised Video Strategy to Enhance Action Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04589">http://arxiv.org/abs/2308.04589</a></li>
<li>repo_url: None</li>
<li>paper_authors: Izzeddin Teeti, Rongali Sai Bhargav, Vivek Singh, Andrew Bradley, Biplab Banerjee, Fabio Cuzzolin</li>
<li>for: This paper is written for improving the action prediction in computer vision applications such as autonomous driving, activity analysis, and human-computer interaction.</li>
<li>methods: The paper introduces a novel self-supervised video strategy called Temporal-DINO, which uses two models (a “student” and a “teacher”) to learn future context by only observing past frames.</li>
<li>results: The experimental results show that the proposed method achieves significant improvements in prediction performance across different architectures, with an average enhancement of 9.9% Precision Points (PP), and demonstrates efficiency in terms of the pretraining dataset size and the number of epochs required.<details>
<summary>Abstract</summary>
The emerging field of action prediction plays a vital role in various computer vision applications such as autonomous driving, activity analysis and human-computer interaction. Despite significant advancements, accurately predicting future actions remains a challenging problem due to high dimensionality, complex dynamics and uncertainties inherent in video data. Traditional supervised approaches require large amounts of labelled data, which is expensive and time-consuming to obtain. This paper introduces a novel self-supervised video strategy for enhancing action prediction inspired by DINO (self-distillation with no labels). The Temporal-DINO approach employs two models; a 'student' processing past frames; and a 'teacher' processing both past and future frames, enabling a broader temporal context. During training, the teacher guides the student to learn future context by only observing past frames. The strategy is evaluated on ROAD dataset for the action prediction downstream task using 3D-ResNet, Transformer, and LSTM architectures. The experimental results showcase significant improvements in prediction performance across these architectures, with our method achieving an average enhancement of 9.9% Precision Points (PP), highlighting its effectiveness in enhancing the backbones' capabilities of capturing long-term dependencies. Furthermore, our approach demonstrates efficiency regarding the pretraining dataset size and the number of epochs required. This method overcomes limitations present in other approaches, including considering various backbone architectures, addressing multiple prediction horizons, reducing reliance on hand-crafted augmentations, and streamlining the pretraining process into a single stage. These findings highlight the potential of our approach in diverse video-based tasks such as activity recognition, motion planning, and scene understanding.
</details>
<details>
<summary>摘要</summary>
新兴的动作预测领域在计算机视觉应用中扮演着重要角色，包括自主驾驶、活动分析和人机交互。尽管有 significante 进步，但准确预测未来动作仍然是一个挑战，因为视频数据中存在高维度、复杂的动态和内在的不确定性。传统的监督方法需要大量标注数据，这是时间consuming 和成本高的。这篇文章介绍了一种新的无监督视频策略，以提高动作预测， inspirited  by DINO（自我混合无标签）。Temporal-DINO方法使用两个模型：一个“学生”处理过去帧，一个“老师”处理过去和未来帧，这使得学生可以学习未来上下文。在训练过程中，老师指导学生通过只看过去帧来学习未来上下文。这种策略在 ROAD 数据集上进行动作预测下渠道任务中使用 3D-ResNet、Transformer 和 LSTM 架构进行评估。实验结果显示，我们的方法可以在这些架构上提高预测性能，typically 9.9% 精度点（PP），这说明我们的方法可以增强核心的长期依赖能力。此外，我们的方法也具有效率的优势，包括预训练数据集大小和轮数 requirement 的减少。这种方法超越了其他方法的限制，包括考虑多种核心架构、 Addressing 多个预测时间 horizons、减少手动制作的扩展和单一预训练过程。这些发现表明我们的方法在多个视频基于任务中具有潜在的优势，例如活动识别、运动规划和场景理解。
</details></li>
</ul>
<hr>
<h2 id="Developmental-Bootstrapping-From-Simple-Competences-to-Intelligent-Human-Compatible-AIs"><a href="#Developmental-Bootstrapping-From-Simple-Competences-to-Intelligent-Human-Compatible-AIs" class="headerlink" title="Developmental Bootstrapping: From Simple Competences to Intelligent Human-Compatible AIs"></a>Developmental Bootstrapping: From Simple Competences to Intelligent Human-Compatible AIs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04586">http://arxiv.org/abs/2308.04586</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mark Stefik, Robert Price</li>
<li>for: 创建人类compatible的AI（create robust, trustworthy, and human-compatible AIs）</li>
<li>methods: 发展bootstrapping方法（developmental bootstrapping approach）</li>
<li>results: 未达到成年人类水平的能力（have not yet reached adult-level competences）<details>
<summary>Abstract</summary>
Although some AIs surpass human abilities in closed artificial worlds such as board games, in the real world they make strange mistakes and do not notice them. They cannot be instructed easily, fail to use common sense, and lack curiosity. Mainstream approaches for creating AIs include the traditional manually-constructed symbolic AI approach and the generative and deep learning AI approaches including large language models (LLMs). Although it is outside of the mainstream, the developmental bootstrapping approach may have more potential. In developmental bootstrapping, AIs develop competences like human children do. They start with innate competences. They interact with the environment and learn from their interactions. They incrementally extend their innate competences with self-developed competences. They interact and learn from people and establish perceptual, cognitive, and common grounding. They acquire the competences they need through competence bootstrapping. However, developmental robotics has not yet produced AIs with robust adult-level competences. Projects have typically stopped before reaching the Toddler Barrier. This corresponds to human infant development at about two years of age, before infant speech becomes fluent. They also do not bridge the Reading Barrier, where they could skillfully and skeptically draw on the socially developed online information resources that power LLMs. The next competences in human cognitive development involve intrinsic motivation, imitation learning, imagination, coordination, and communication. This position paper lays out the logic, prospects, gaps, and challenges for extending the practice of developmental bootstrapping to create robust, trustworthy, and human-compatible AIs.
</details>
<details>
<summary>摘要</summary>
尽管一些人工智能在封闭的人工世界中超越人类能力，但在真实世界中它们会做奇怪的错误并不会注意到它们。它们不易教育，失去常识，缺乏好奇心。主流的创造人工智能方法包括传统的手动构建符号AI方法和生成和深度学习AI方法，包括大型语言模型（LLM）。虽然它不在主流，但开发启动approach可能具有更大的潜力。在开发启动中，人工智能发展出 Competences 像人类孩子一样。它们从内在的 Competences 开始，与环境互动，从互动学习。它们逐步增强内在 Competences 自己发展出的 Competences。它们与人类交互，学习人类的语言、认知和共同基础。它们通过 Competence 启动获得需要的 Competences。然而，开发机器人学还没有生成成熟的人类水平 Competences。项目通常在达到婴儿障碍（Toddler Barrier）前就停止。这与人类婴儿发展相对应，约两岁时， antes que el habla fluente。它们也不能跨越阅读障碍（Reading Barrier），可以 skillfully 和skeptically draw on the socially developed online information resources that power LLMs。人类认知发展中下一个 Competences 包括内在动机、模仿学习、想象力、协调和communication。这篇position paper 描述了开发启动的逻辑、前景、潜在的差距和挑战，以创建可靠、可信任的人类兼容AI。
</details></li>
</ul>
<hr>
<h2 id="Improving-Performance-in-Continual-Learning-Tasks-using-Bio-Inspired-Architectures"><a href="#Improving-Performance-in-Continual-Learning-Tasks-using-Bio-Inspired-Architectures" class="headerlink" title="Improving Performance in Continual Learning Tasks using Bio-Inspired Architectures"></a>Improving Performance in Continual Learning Tasks using Bio-Inspired Architectures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04539">http://arxiv.org/abs/2308.04539</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sandeep Madireddy, Angel Yanguas-Gil, Prasanna Balaprakash</li>
<li>for: 这篇论文主要针对问题是如何实现不断学习，即无需占用大量存储空间就可以在数据流中不断学习。</li>
<li>methods: 作者提出了一种基于生物学原理的轻量级神经网络架构，该架构包括synaptic plasticity机制和神经调控，可以在在线学习过程中不断学习，而无需使用杂谱缓冲或重播。</li>
<li>results: 作者在Split-MNIST、Split-CIFAR-10和Split-CIFAR-100数据集上实现了在线不断学习的superior性能，并且与其他存储受限的学习方法相比，与STATE-OF-THE-ART的存储充足的重播基于方法相当。此外，作者还将这些设计元素 интеGRATE到其他Backpropagation-based continual learning算法中，提高了它们的准确性。<details>
<summary>Abstract</summary>
The ability to learn continuously from an incoming data stream without catastrophic forgetting is critical to designing intelligent systems. Many approaches to continual learning rely on stochastic gradient descent and its variants that employ global error updates, and hence need to adopt strategies such as memory buffers or replay to circumvent its stability, greed, and short-term memory limitations. To address this limitation, we have developed a biologically inspired lightweight neural network architecture that incorporates synaptic plasticity mechanisms and neuromodulation and hence learns through local error signals to enable online continual learning without stochastic gradient descent.   Our approach leads to superior online continual learning performance on Split-MNIST, Split-CIFAR-10, and Split-CIFAR-100 datasets compared to other memory-constrained learning approaches and matches that of the state-of-the-art memory-intensive replay-based approaches. We further demonstrate the effectiveness of our approach by integrating key design concepts into other backpropagation-based continual learning algorithms, significantly improving their accuracy. Our results provide compelling evidence for the importance of incorporating biological principles into machine learning models and offer insights into how we can leverage them to design more efficient and robust systems for online continual learning.
</details>
<details>
<summary>摘要</summary>
<<SYS>>为设计智能系统，持续学习能力是关键。许多持续学习方法依赖于梯度下降和其变体，这会导致稳定性、贪吃和短期记忆限制。为解决这一限制，我们开发了基于生物学原理的轻量级神经网络架构，包括synaptic plasticity机制和 neuromodulation，从而通过本地错误信号来实现在线持续学习无需梯度下降。我们的方法在Split-MNIST、Split-CIFAR-10和Split-CIFAR-100数据集上表现出色，比其他内存限制的学习方法更好，并与state-of-the-art内存占用重的播放方法匹配。我们还将关键设计元素integrated into other backpropagation-based continual learning algorithms，显著提高了它们的准确性。我们的结果提供了迫使生物学原理integrated into机器学习模型的证据，并提供了如何通过这些原理来设计更高效和可靠的在线持续学习系统。
</details></li>
</ul>
<hr>
<h2 id="Generating-Modern-Persian-Carpet-Map-by-Style-transfer"><a href="#Generating-Modern-Persian-Carpet-Map-by-Style-transfer" class="headerlink" title="Generating Modern Persian Carpet Map by Style-transfer"></a>Generating Modern Persian Carpet Map by Style-transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04529">http://arxiv.org/abs/2308.04529</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dorsa Rahmatian, Monireh Moshavash, Mahdi Eftekhari, Kamran Hoseinkhani</li>
<li>for: 用Deep Neural Networks(DNN)生成现代波斯织革图。</li>
<li>methods: 提议了三种不同的DNN样式转移方法，包括Style-Swap方法、Clip-Styler方法、Gatys方法，以及一些颜色化方法。</li>
<li>results: 生成的织革图易得到了用户评价的满意度，并且比传统方法快速。<details>
<summary>Abstract</summary>
Today, the great performance of Deep Neural Networks(DNN) has been proven in various fields. One of its most attractive applications is to produce artistic designs. A carpet that is known as a piece of art is one of the most important items in a house, which has many enthusiasts all over the world. The first stage of producing a carpet is to prepare its map, which is a difficult, time-consuming, and expensive task. In this research work, our purpose is to use DNN for generating a Modern Persian Carpet Map. To reach this aim, three different DNN style transfer methods are proposed and compared against each other. In the proposed methods, the Style-Swap method is utilized to create the initial carpet map, and in the following, to generate more diverse designs, methods Clip-Styler, Gatys, and Style-Swap are used separately. In addition, some methods are examined and introduced for coloring the produced carpet maps. The designed maps are evaluated via the results of filled questionnaires where the outcomes of user evaluations confirm the popularity of generated carpet maps. Eventually, for the first time, intelligent methods are used in producing carpet maps, and it reduces human intervention. The proposed methods can successfully produce diverse carpet designs, and at a higher speed than traditional ways.
</details>
<details>
<summary>摘要</summary>
In our proposed methods, the Style-Swap method is used to create the initial carpet map, and then, to generate more diverse designs, we use the Clip-Styler, Gatys, and Style-Swap methods separately. Additionally, we explore and introduce some methods for coloring the produced carpet maps. The designed maps are evaluated through filled questionnaires, and the results of user evaluations confirm the popularity of the generated carpet maps.For the first time, intelligent methods are used in producing carpet maps, reducing human intervention. Our proposed methods can successfully produce diverse carpet designs at a higher speed than traditional methods.
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-for-Diverse-Data-Types-Steganalysis-A-Review"><a href="#Deep-Learning-for-Diverse-Data-Types-Steganalysis-A-Review" class="headerlink" title="Deep Learning for Diverse Data Types Steganalysis: A Review"></a>Deep Learning for Diverse Data Types Steganalysis: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04522">http://arxiv.org/abs/2308.04522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hamza Kheddar, Mustapha Hemis, Yassine Himeur, David Megías, Abbes Amira</li>
<li>for: 本研究评论文章旨在提供一个深度学习基于的数字媒体掩盖信息检测方法的系统性评论。</li>
<li>methods: 本文使用的方法包括深度学习、深度跳转学习和深度强化学习等多种方法，以检测数字媒体中隐藏的信息。</li>
<li>results: 本文对多种数字媒体类型进行了检测和分析，并提供了一个系统性的评估 metric 和数据集。同时，文章还提出了未来研究方向和挑战。<details>
<summary>Abstract</summary>
Steganography and steganalysis are two interrelated aspects of the field of information security. Steganography seeks to conceal communications, whereas steganalysis is aimed to either find them or even, if possible, recover the data they contain. Steganography and steganalysis have attracted a great deal of interest, particularly from law enforcement. Steganography is often used by cybercriminals and even terrorists to avoid being captured while in possession of incriminating evidence, even encrypted, since cryptography is prohibited or restricted in many countries. Therefore, knowledge of cutting-edge techniques to uncover concealed information is crucial in exposing illegal acts. Over the last few years, a number of strong and reliable steganography and steganalysis techniques have been introduced in the literature. This review paper provides a comprehensive overview of deep learning-based steganalysis techniques used to detect hidden information within digital media. The paper covers all types of cover in steganalysis, including image, audio, and video, and discusses the most commonly used deep learning techniques. In addition, the paper explores the use of more advanced deep learning techniques, such as deep transfer learning (DTL) and deep reinforcement learning (DRL), to enhance the performance of steganalysis systems. The paper provides a systematic review of recent research in the field, including data sets and evaluation metrics used in recent studies. It also presents a detailed analysis of DTL-based steganalysis approaches and their performance on different data sets. The review concludes with a discussion on the current state of deep learning-based steganalysis, challenges, and future research directions.
</details>
<details>
<summary>摘要</summary>
《隐藏通信和抹除检测：一篇现代信息安全领域的综述》Introduction:信息安全领域中，隐藏通信和抹除检测是两个相关的方面。隐藏通信旨在隐藏通信内容，而抹除检测则是检测和恢复隐藏的内容。由于隐藏通信和抹除检测具有广泛的应用前景，特别是在法律执法方面，因此对于找到隐藏的信息是非常重要的。Background:隐藏通信和抹除检测在过去几年中得到了广泛的关注，特别是在cyber犯罪和恐怖主义领域。隐藏通信可以帮助犯罪分子和恐怖分子避免被捕获，甚至是 encrypted 的情况下。因此，了解最新的隐藏信息检测技术是非常重要的。Methodology:本文将提供一个系统性的综述，涵盖了深度学习基于的隐藏信息检测技术。文章将覆盖所有类型的遮盖，包括图像、音频和视频，并讨论了最常用的深度学习技术。此外，文章还将探讨更高级的深度学习技术，如深度传输学习（DTL）和深度奖励学习（DRL），以提高隐藏信息检测系统的性能。Results:本文结合了最新的研究成果，包括数据集和评估指标。文章还进行了深度传输学习（DTL）基于的隐藏信息检测方法的系统性分析，并对不同数据集进行了详细的性能分析。Discussion:本文结束后，我们将对现代深度学习基于的隐藏信息检测领域进行一个系统性的回顾。我们还将讨论一些挑战和未来的研究方向。Conclusion:深度学习基于的隐藏信息检测技术在信息安全领域具有广泛的应用前景。本文提供了一个系统性的综述，涵盖了深度学习基于的隐藏信息检测技术的最新研究成果。我们希望这篇文章可以为读者提供一个全面的了解，并为未来的研究提供一个指导。
</details></li>
</ul>
<hr>
<h2 id="DisCoCat-for-Donkey-Sentences"><a href="#DisCoCat-for-Donkey-Sentences" class="headerlink" title="DisCoCat for Donkey Sentences"></a>DisCoCat for Donkey Sentences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04519">http://arxiv.org/abs/2308.04519</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lachlan McPheat, Daphne Wang</li>
<li>for: 本文使用分布式compositional模型解释格雷奇的donkey句子。</li>
<li>methods: 本文基于之前的DisCoCat框架，包括扩展以处理谓词、determiners和相对pronouns。文本使用类型逻辑 sintaxisa paraparse donkey句子，并定义了关系和 вектор空间 semantics。</li>
<li>results: 本文提出了一种类型逻辑 sintaxisa paraparse donkey句子，并通过实验证明了其效果。<details>
<summary>Abstract</summary>
We demonstrate how to parse Geach's Donkey sentences in a compositional distributional model of meaning. We build on previous work on the DisCoCat (Distributional Compositional Categorical) framework, including extensions that model discourse, determiners, and relative pronouns. We present a type-logical syntax for parsing donkey sentences, for which we define both relational and vector space semantics.
</details>
<details>
<summary>摘要</summary>
我们展示了如何使用分布式compositional模型来解析格雷奇的驴句。我们基于之前的DisCoCat（分布式compositional categorical）框架，包括扩展以处理话语、determiners和相对副词。我们提出了一种类型逻辑语法来解析驴句，并对其定义了关系和vector空间 semantics。Note: "分布式compositional" (fēnhuì zhīxìng) is a compound word in Chinese, where "分布式" (fēnhuì) means "distributed" and "compositional" is a loanword from English.
</details></li>
</ul>
<hr>
<h2 id="MT-IceNet-–-A-Spatial-and-Multi-Temporal-Deep-Learning-Model-for-Arctic-Sea-Ice-Forecasting"><a href="#MT-IceNet-–-A-Spatial-and-Multi-Temporal-Deep-Learning-Model-for-Arctic-Sea-Ice-Forecasting" class="headerlink" title="MT-IceNet – A Spatial and Multi-Temporal Deep Learning Model for Arctic Sea Ice Forecasting"></a>MT-IceNet – A Spatial and Multi-Temporal Deep Learning Model for Arctic Sea Ice Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04511">http://arxiv.org/abs/2308.04511</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/big-data-lab-umbc/sea-ice-prediction">https://github.com/big-data-lab-umbc/sea-ice-prediction</a></li>
<li>paper_authors: Sahara Ali, Jianwu Wang</li>
<li>for: 本研究旨在提出一种基于深度学习的海冰集中度预测模型（MT-IceNet），以提高海冰预测的准确性和可靠性。</li>
<li>methods: 该模型采用了UNet的Encoder-Decoder架构，并利用了时间和空间的skip连接，以处理多个时间流和空间流的数据。</li>
<li>results: 研究表明，使用NSIDC的卫星评估数据和ERA5的大气和海洋变量，MT-IceNet模型在6个月预测时间点上具有60%的预测误差减少，与现有的模型相比。<details>
<summary>Abstract</summary>
Arctic amplification has altered the climate patterns both regionally and globally, resulting in more frequent and more intense extreme weather events in the past few decades. The essential part of Arctic amplification is the unprecedented sea ice loss as demonstrated by satellite observations. Accurately forecasting Arctic sea ice from sub-seasonal to seasonal scales has been a major research question with fundamental challenges at play. In addition to physics-based Earth system models, researchers have been applying multiple statistical and machine learning models for sea ice forecasting. Looking at the potential of data-driven approaches to study sea ice variations, we propose MT-IceNet - a UNet based spatial and multi-temporal (MT) deep learning model for forecasting Arctic sea ice concentration (SIC). The model uses an encoder-decoder architecture with skip connections and processes multi-temporal input streams to regenerate spatial maps at future timesteps. Using bi-monthly and monthly satellite retrieved sea ice data from NSIDC as well as atmospheric and oceanic variables from ERA5 reanalysis product during 1979-2021, we show that our proposed model provides promising predictive performance for per-pixel SIC forecasting with up to 60% decrease in prediction error for a lead time of 6 months as compared to its state-of-the-art counterparts.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="ChatGPT-for-Arabic-Grammatical-Error-Correction"><a href="#ChatGPT-for-Arabic-Grammatical-Error-Correction" class="headerlink" title="ChatGPT for Arabic Grammatical Error Correction"></a>ChatGPT for Arabic Grammatical Error Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04492">http://arxiv.org/abs/2308.04492</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sang Yun Kwon, Gagan Bhatia, El Moatez Billah Nagoud, Muhammad Abdul-Mageed</li>
<li>for: 本研究探讨了以人工指令为基础的大语言模型（LLM）在非英语语言中文 grammar error correction（GEC）任务中的表现。</li>
<li>methods: 本研究使用了不同的提示方法和（在上下文中）几拟学习来提高 LLM 的性能。</li>
<li>results: GPT-4 在专家提示下 achieve up to $65.49$ F\textsubscript{1} 分数，较前一个基准值高出约 $5$ 分数。 这表明 LLM 在有限的资源情况下可以提供可靠的数据生成方法，并且可以为模型训练提供有用的数据。<details>
<summary>Abstract</summary>
Recently, large language models (LLMs) fine-tuned to follow human instruction have exhibited significant capabilities in various English NLP tasks. However, their performance in grammatical error correction (GEC) tasks, particularly in non-English languages, remains significantly unexplored. In this paper, we delve into abilities of instruction fine-tuned LLMs in Arabic GEC, a task made complex due to Arabic's rich morphology. Our findings suggest that various prompting methods, coupled with (in-context) few-shot learning, demonstrate considerable effectiveness, with GPT-4 achieving up to $65.49$ F\textsubscript{1} score under expert prompting (approximately $5$ points higher than our established baseline). This highlights the potential of LLMs in low-resource settings, offering a viable approach for generating useful synthetic data for model training. Despite these positive results, we find that instruction fine-tuned models, regardless of their size, significantly underperform compared to fully fine-tuned models of significantly smaller sizes. This disparity highlights a substantial room for improvements for LLMs. Inspired by methods from low-resource machine translation, we also develop a method exploiting synthetic data that significantly outperforms previous models on two standard Arabic benchmarks. Our work sets new SoTA for Arabic GEC, with $72.19\%$ and $73.26$ F$_{1}$ on the 2014 and 2015 QALB datasets, respectively.
</details>
<details>
<summary>摘要</summary>
现在，大型语言模型（LLM）经过人类指导的微调表现出了在英语自然语言处理（NLP）任务中的显著能力。然而，它们在非英语语法错误修正（GEC）任务中的表现仍然尚未得到了足够的探索。在这篇论文中，我们探索了微调后的LLM在阿拉伯语GEC任务中的能力。我们发现，使用不同的提示方法和（Context）少量学习可以获得显著的效果，GPT-4在专家提示下达到了$65.49$ F\textsubscript{1} 分数（相对于我们的基准值，大约5个点高）。这显示了LLM在有限的资源情况下的潜在能力，提供了一种可靠的方法来生成有用的合成数据 для模型训练。尽管我们得到了正面的结果，我们发现微调后的模型，无论其大小，都比完全微调的模型（即模型的大小更小）表现下降。这种差异表明了LLM的大型化可能存在一定的限制。 Drawing inspiration from low-resource机器翻译技术，我们还开发了一种利用合成数据的方法，在两个标准的阿拉伯语 benchmark 上获得了显著的提高。我们的工作设置了新的 SoTA  для阿拉伯语 GEC，分别为$72.19\%$ 和 $73.26$ F\textsubscript{1} 在2014 和 2015 QALB 数据集上。
</details></li>
</ul>
<hr>
<h2 id="SILO-Language-Models-Isolating-Legal-Risk-In-a-Nonparametric-Datastore"><a href="#SILO-Language-Models-Isolating-Legal-Risk-In-a-Nonparametric-Datastore" class="headerlink" title="SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore"></a>SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04430">http://arxiv.org/abs/2308.04430</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kernelmachine/silo-lm">https://github.com/kernelmachine/silo-lm</a></li>
<li>paper_authors: Sewon Min, Suchin Gururangan, Eric Wallace, Hannaneh Hajishirzi, Noah A. Smith, Luke Zettlemoyer</li>
<li>for: 本研究旨在构建一种可以在法律上合法地使用的语言模型（LM），以满足现有数据使用法规的要求。</li>
<li>methods: 本研究使用了一种新的方法，即在搜索时使用可Parametric Language Model（OLC）和一个可修改的非参数化数据存储（例如，包含版权书籍或新闻）。这种方法可以在搜索时使用高风险数据，而不需要在训练过程中使用它们。</li>
<li>results: 实验结果显示，使用OLC和非参数化数据存储可以大幅提高语言模型的性能， especialy 在不同领域的搜索中。此外，研究还发现了不同的非参数化方法的效果，以及数据存储大小对性能的影响。这些结果表明，可以构建高质量的语言模型，同时遵守法律法规。<details>
<summary>Abstract</summary>
The legality of training language models (LMs) on copyrighted or otherwise restricted data is under intense debate. However, as we show, model performance significantly degrades if trained only on low-risk text (e.g., out-of-copyright books or government documents), due to its limited size and domain coverage. We present SILO, a new language model that manages this risk-performance tradeoff during inference. SILO is built by (1) training a parametric LM on Open License Corpus (OLC), a new corpus we curate with 228B tokens of public domain and permissively licensed text and (2) augmenting it with a more general and easily modifiable nonparametric datastore (e.g., containing copyrighted books or news) that is only queried during inference. The datastore allows use of high-risk data without training on it, supports sentence-level data attribution, and enables data producers to opt out from the model by removing content from the store. These capabilities can foster compliance with data-use regulations such as the fair use doctrine in the United States and the GDPR in the European Union. Our experiments show that the parametric LM struggles on domains not covered by OLC. However, access to the datastore greatly improves out of domain performance, closing 90% of the performance gap with an LM trained on the Pile, a more diverse corpus with mostly high-risk text. We also analyze which nonparametric approach works best, where the remaining errors lie, and how performance scales with datastore size. Our results suggest that it is possible to build high quality language models while mitigating their legal risk.
</details>
<details>
<summary>摘要</summary>
Currently, the legality of training language models (LMs) on copyrighted or restricted data is under debate. However, as we show, model performance significantly degrades if trained only on low-risk text (e.g., out-of-copyright books or government documents), due to its limited size and domain coverage. We present SILO, a new language model that manages this risk-performance tradeoff during inference. SILO is built by (1) training a parametric LM on Open License Corpus (OLC), a new corpus we curate with 228B tokens of public domain and permissively licensed text, and (2) augmenting it with a more general and easily modifiable nonparametric datastore (e.g., containing copyrighted books or news) that is only queried during inference. The datastore allows use of high-risk data without training on it, supports sentence-level data attribution, and enables data producers to opt out from the model by removing content from the store. These capabilities can foster compliance with data-use regulations such as the fair use doctrine in the United States and the GDPR in the European Union. Our experiments show that the parametric LM struggles on domains not covered by OLC. However, access to the datastore greatly improves out-of-domain performance, closing 90% of the performance gap with an LM trained on the Pile, a more diverse corpus with mostly high-risk text. We also analyze which nonparametric approach works best, where the remaining errors lie, and how performance scales with datastore size. Our results suggest that it is possible to build high-quality language models while mitigating their legal risk.
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-Invariant-Learning-with-Randomized-Linear-Classifiers"><a href="#Probabilistic-Invariant-Learning-with-Randomized-Linear-Classifiers" class="headerlink" title="Probabilistic Invariant Learning with Randomized Linear Classifiers"></a>Probabilistic Invariant Learning with Randomized Linear Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04412">http://arxiv.org/abs/2308.04412</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leonardo Cotta, Gal Yehuda, Assaf Schuster, Chris J. Maddison</li>
<li>for: 本文旨在设计能够保持任务知识的表达力和不变性的模型，而不是耗费过多的计算资源。</li>
<li>methods: 作者提出了一种基于恶的随机化算法的思路，通过接受概率性的通用适应和不变性可以降低计算资源的需求。特别是，作者提出了一类基于随机化的线性模型，称为随机线性分类器（RLCs）。</li>
<li>results: 作者证明了RLCs可以在某些条件下， WITH HIGH PROBABILITY  aproximate any (smooth) function  while preserving invariance to compact group transformations。此外，作者还设计了三种基于RLCs的随机化分类模型，可以在不同的数据上实现概率性和通用适应。最后，作者通过实验表明，这种新的模型在不变任务中可以比 deterministic invariant neural networks 更好地表现。<details>
<summary>Abstract</summary>
Designing models that are both expressive and preserve known invariances of tasks is an increasingly hard problem. Existing solutions tradeoff invariance for computational or memory resources. In this work, we show how to leverage randomness and design models that are both expressive and invariant but use less resources. Inspired by randomized algorithms, our key insight is that accepting probabilistic notions of universal approximation and invariance can reduce our resource requirements. More specifically, we propose a class of binary classification models called Randomized Linear Classifiers (RLCs). We give parameter and sample size conditions in which RLCs can, with high probability, approximate any (smooth) function while preserving invariance to compact group transformations. Leveraging this result, we design three RLCs that are provably probabilistic invariant for classification tasks over sets, graphs, and spherical data. We show how these models can achieve probabilistic invariance and universality using less resources than (deterministic) neural networks and their invariant counterparts. Finally, we empirically demonstrate the benefits of this new class of models on invariant tasks where deterministic invariant neural networks are known to struggle.
</details>
<details>
<summary>摘要</summary>
“设计能够表达性和保持任务知识的模型是一个在不断增长的问题。现有的解决方案都是在计算资源和存储空间方面做出了牺牲。在这种工作中，我们表明了可以通过随机性来解决这个问题。我们的关键发现是，接受随机性的通用近似和不变性可以降低我们的资源需求。更具体地，我们提出了一类基于随机化的线性模型，称为随机线性分类器（RLCs）。我们给出了参数和样本大小的条件，在这些条件下，RLCs可以，高概率地，近似任何（光滑）函数，同时保持 compact 群变换的不变性。基于这个结果，我们设计了三种随机线性模型，它们可以在分类任务中保持随机性和不变性，并且使用较少的资源。最后，我们通过实验证明这种新类型的模型在不变任务中比 deterministic 抽象神经网络更有优势。”
</details></li>
</ul>
<hr>
<h2 id="Fine-Tuning-Games-Bargaining-and-Adaptation-for-General-Purpose-Models"><a href="#Fine-Tuning-Games-Bargaining-and-Adaptation-for-General-Purpose-Models" class="headerlink" title="Fine-Tuning Games: Bargaining and Adaptation for General-Purpose Models"></a>Fine-Tuning Games: Bargaining and Adaptation for General-Purpose Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04399">http://arxiv.org/abs/2308.04399</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benjamin Laufer, Jon Kleinberg, Hoda Heidari</li>
<li>for: 这篇论文旨在描述如何在机器学习（ML）和人工智能（AI）领域内实现精细化过程，即将通用模型（Generalist）带到特定领域中（Domain-specialist）进行适应。</li>
<li>methods: 这篇论文使用了谈判解决方案和游戏均衡来研究firms在这类交互中的策略行为，并提供了一种方法来标识Pareto优化的谈判安排。</li>
<li>results: 论文发现，即使一个公司的成本比另一个公司更高，也可以实现利润分享，并且提供了一些方法来确定合理的谈判安排。<details>
<summary>Abstract</summary>
Major advances in Machine Learning (ML) and Artificial Intelligence (AI) increasingly take the form of developing and releasing general-purpose models. These models are designed to be adapted by other businesses and agencies to perform a particular, domain-specific function. This process has become known as adaptation or fine-tuning. This paper offers a model of the fine-tuning process where a Generalist brings the technological product (here an ML model) to a certain level of performance, and one or more Domain-specialist(s) adapts it for use in a particular domain. Both entities are profit-seeking and incur costs when they invest in the technology, and they must reach a bargaining agreement on how to share the revenue for the technology to reach the market. For a relatively general class of cost and revenue functions, we characterize the conditions under which the fine-tuning game yields a profit-sharing solution. We observe that any potential domain-specialization will either contribute, free-ride, or abstain in their uptake of the technology, and we provide conditions yielding these different strategies. We show how methods based on bargaining solutions and sub-game perfect equilibria provide insights into the strategic behavior of firms in these types of interactions, and we find that profit-sharing can still arise even when one firm has significantly higher costs than another. We also provide methods for identifying Pareto-optimal bargaining arrangements for a general set of utility functions.
</details>
<details>
<summary>摘要</summary>
大量的机器学习（ML）和人工智能（AI）创新都在形式为开发和发布通用模型。这些模型是为其他企业和机构用于特定领域功能而设计的，并且可以通过精度调整来适应不同的领域。这个过程被称为调整或精度调整。这篇论文提出了调整过程中一个通用者和一个或多个领域专家之间的合作模型。这两个实体都是追求利润的，并且投入技术时需要支付成本。为了将技术投入到市场上，他们需要达成协议来分配收益。为一类相对通用的成本和收益函数，我们Characterize了调整游戏中的盈利分享解决方案的条件。我们发现，在采用这种技术时，任何领域专业化都可能会为其投入、免费享用或决不使用技术，并且我们提供了这些不同策略的条件。我们发现，基于谈判解决方案和下游完整平衡的方法可以提供关于企业在这类互动中的策略性行为的深入理解，并且我们发现，盈利分享可以在一个实体有较高成本时仍然出现。此外，我们还提供了一种方法来标识通用集成函数的Pareto优化协议。
</details></li>
</ul>
<hr>
<h2 id="Event-Abstraction-for-Enterprise-Collaboration-Systems-to-Support-Social-Process-Mining"><a href="#Event-Abstraction-for-Enterprise-Collaboration-Systems-to-Support-Social-Process-Mining" class="headerlink" title="Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining"></a>Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04396">http://arxiv.org/abs/2308.04396</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonas Blatt, Patrick Delfmann, Petra Schubert</li>
<li>For: The paper is written for Process Mining (PM) and Enterprise Collaboration Systems (ECS).* Methods: The paper proposes a tailored ECS event abstraction (ECSEA) approach that trains a model by comparing recorded actual user activities with the system-generated low-level traces.* Results: The algorithm produces accurate results.Here’s the information in Simplified Chinese text, as requested:* For: 这篇论文是为了进程挖掘（PM）和企业协作系统（ECS）所写的。* Methods: 论文提出了一种适应ECS事件抽象（ECSEA）方法，通过比较记录的实际用户活动（高级踪迹）与系统生成的低级踪迹（从ECS中提取的）来训练模型。* Results: 算法生成的结果准确。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
One aim of Process Mining (PM) is the discovery of process models from event logs of information systems. PM has been successfully applied to process-oriented enterprise systems but is less suited for communication- and document-oriented Enterprise Collaboration Systems (ECS). ECS event logs are very fine-granular and PM applied to their logs results in spaghetti models. A common solution for this is event abstraction, i.e., converting low-level logs into more abstract high-level logs before running discovery algorithms. ECS logs come with special characteristics that have so far not been fully addressed by existing event abstraction approaches. We aim to close this gap with a tailored ECS event abstraction (ECSEA) approach that trains a model by comparing recorded actual user activities (high-level traces) with the system-generated low-level traces (extracted from the ECS). The model allows us to automatically convert future low-level traces into an abstracted high-level log that can be used for PM. Our evaluation shows that the algorithm produces accurate results. ECSEA is a preprocessing method that is essential for the interpretation of collaborative work activity in ECS, which we call Social Process Mining.
</details>
<details>
<summary>摘要</summary>
一个目标 OF 过程挖掘（PM）是从信息系统事件日志中发现过程模型。PM 已经成功应用于进程 oriented 企业系统，但是它在交流和文档 oriented 企业协作系统（ECS）中 menos 适用。ECS 事件日志具有特殊的特点，PM 应用于其日志会导致蛇形模型。一种常见的解决方案是事件抽象，即将低级别的日志转换为更高级别的日志，以便在发现算法中使用。ECS 日志具有特殊的特点，已经不完全由现有的事件抽象方法解决。我们的目标是通过适应 ECS 事件抽象（ECSEA）方法，训练一个模型，将记录的实际用户活动（高级跟踪）与系统生成的低级别跟踪（从 ECS 提取）进行比较。这个模型可以自动将未来的低级别跟踪转换为抽象的高级别日志，用于 PM。我们的评估表明，该算法生成的结果准确。ECSEA 是一种必需的预处理方法，用于解释 ECS 中的协作工作活动，我们称之为社交过程挖掘。
</details></li>
</ul>
<hr>
<h2 id="Metaheuristic-Algorithms-in-Artificial-Intelligence-with-Applications-to-Bioinformatics-Biostatistics-Ecology-and-the-Manufacturing-Industries"><a href="#Metaheuristic-Algorithms-in-Artificial-Intelligence-with-Applications-to-Bioinformatics-Biostatistics-Ecology-and-the-Manufacturing-Industries" class="headerlink" title="Metaheuristic Algorithms in Artificial Intelligence with Applications to Bioinformatics, Biostatistics, Ecology and, the Manufacturing Industries"></a>Metaheuristic Algorithms in Artificial Intelligence with Applications to Bioinformatics, Biostatistics, Ecology and, the Manufacturing Industries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10875">http://arxiv.org/abs/2308.10875</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/elviscuihan/csoma">https://github.com/elviscuihan/csoma</a></li>
<li>paper_authors: Elvis Han Cui, Zizhao Zhang, Culsome Junwen Chen, Weng Kee Wong</li>
<li>for: 本研究用一种新提出的自然引导算法 Competitive Swarm Optimizer with Mutated Agents (CSO-MA) 应用于各种统计科学中的优化问题，以示其灵活性和与其他算法的比较。</li>
<li>methods: 本研究使用CSO-MA算法，可以处理不同的成本结构或多个用户指定的非线性约束。</li>
<li>results: 本研究在不同的优化问题中应用CSO-MA算法，如找到单个维度泛化趋势模型中参数的最大可能性估计、教育研究中常用的拉希模型参数估计、Markov renewal模型中Cox回归估计和两个分 комpartment模型中缺失值补充等。此外，还应用到生态学问题中选取最佳变量和制造业中用logistic模型与多个交互因素进行车辆燃料实验的设计。<details>
<summary>Abstract</summary>
Nature-inspired metaheuristic algorithms are important components of artificial intelligence, and are increasingly used across disciplines to tackle various types of challenging optimization problems. We apply a newly proposed nature-inspired metaheuristic algorithm called competitive swarm optimizer with mutated agents (CSO-MA) and demonstrate its flexibility and out-performance relative to its competitors in a variety of optimization problems in the statistical sciences. In particular, we show the algorithm is efficient and can incorporate various cost structures or multiple user-specified nonlinear constraints. Our applications include (i) finding maximum likelihood estimates of parameters in a single cell generalized trend model to study pseudotime in bioinformatics, (ii) estimating parameters in a commonly used Rasch model in education research, (iii) finding M-estimates for a Cox regression in a Markov renewal model and (iv) matrix completion to impute missing values in a two compartment model. In addition we discuss applications to (v) select variables optimally in an ecology problem and (vi) design a car refueling experiment for the auto industry using a logistic model with multiple interacting factors.
</details>
<details>
<summary>摘要</summary>
自然 inspirited  мета希顿算法是人工智能中重要的组件，广泛应用于各个领域解决各种复杂的优化问题。我们应用了一种新提出的自然 inspirited  meta希顿算法called 竞争群体优化器with 突变代理（CSO-MA），并证明其灵活性和相比其他竞争者的出色表现在各种优化问题中。具体来说，我们表明该算法可以有效地处理不同的成本结构或多个用户指定的非线性约束。我们的应用包括（i）在生物信息学中使用单个维度泛化趋势模型来找到最大感受度参数的最佳估计，（ii）在教育研究中使用 Rasch 模型来估计参数，（iii）使用 Cox 回归模型来找到 M-估计，（iv）对两个部件模型中的缺失值进行完成，以及（v）在生态学问题中选取最佳变量，（vi）采用 Logistic 模型与多个交互因素来设计汽车燃油实验。
</details></li>
</ul>
<hr>
<h2 id="AdaptEx-A-Self-Service-Contextual-Bandit-Platform"><a href="#AdaptEx-A-Self-Service-Contextual-Bandit-Platform" class="headerlink" title="AdaptEx: A Self-Service Contextual Bandit Platform"></a>AdaptEx: A Self-Service Contextual Bandit Platform</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08650">http://arxiv.org/abs/2308.08650</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Black, Ercument Ilhan, Andrea Marchini, Vilda Markeviciute</li>
<li>for: 这篇论文旨在提出一种自服务上下文链投机平台，以便在Expedia集团 scale上个性化用户体验。</li>
<li>methods: 该平台使用多臂铁人投机算法个性化每位访客的体验，并快速从每次互动中学习。</li>
<li>results: 该平台可以快速提高用户体验，降低传统测试方法相关的成本和时间。它还能够在内容不断变化和连续”冰封”情况下妥协很好地适应。<details>
<summary>Abstract</summary>
This paper presents AdaptEx, a self-service contextual bandit platform widely used at Expedia Group, that leverages multi-armed bandit algorithms to personalize user experiences at scale. AdaptEx considers the unique context of each visitor to select the optimal variants and learns quickly from every interaction they make. It offers a powerful solution to improve user experiences while minimizing the costs and time associated with traditional testing methods. The platform unlocks the ability to iterate towards optimal product solutions quickly, even in ever-changing content and continuous "cold start" situations gracefully.
</details>
<details>
<summary>摘要</summary>
这份论文介绍了Expedia Group广泛使用的自助上下文强制投机平台AdaptEx，该平台利用多臂强制投机算法个性化用户体验，并快速学习每次用户互动。它提供了改善用户体验的强大解决方案，同时减少传统测试方法相关的成本和时间。该平台允许快速迭代到优质产品解决方案，即使在不断变化的内容和连续“冷启动”情况下也能够 gracefully adapt。
</details></li>
</ul>
<hr>
<h2 id="Understanding-the-Effect-of-Counterfactual-Explanations-on-Trust-and-Reliance-on-AI-for-Human-AI-Collaborative-Clinical-Decision-Making"><a href="#Understanding-the-Effect-of-Counterfactual-Explanations-on-Trust-and-Reliance-on-AI-for-Human-AI-Collaborative-Clinical-Decision-Making" class="headerlink" title="Understanding the Effect of Counterfactual Explanations on Trust and Reliance on AI for Human-AI Collaborative Clinical Decision Making"></a>Understanding the Effect of Counterfactual Explanations on Trust and Reliance on AI for Human-AI Collaborative Clinical Decision Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04375">http://arxiv.org/abs/2308.04375</a></li>
<li>repo_url: None</li>
<li>paper_authors: Min Hun Lee, Chong Jun Chew</li>
<li>for: 这个研究旨在帮助人类决策者更好地与人工智能（AI）合作，以提高决策质量。</li>
<li>methods: 这个研究使用了特征解释和对比解释来帮助人类审查AI建议，以减少对AI的过度依赖。</li>
<li>results: 研究发现，当AI建议正确时，both therapists和laypersons可以通过特征解释和对比解释来提高审查性和一致性。然而，当AI建议错误时，对比解释可以帮助both therapists和laypersons减少对错误AI建议的过度依赖。<details>
<summary>Abstract</summary>
Artificial intelligence (AI) is increasingly being considered to assist human decision-making in high-stake domains (e.g. health). However, researchers have discussed an issue that humans can over-rely on wrong suggestions of the AI model instead of achieving human AI complementary performance. In this work, we utilized salient feature explanations along with what-if, counterfactual explanations to make humans review AI suggestions more analytically to reduce overreliance on AI and explored the effect of these explanations on trust and reliance on AI during clinical decision-making. We conducted an experiment with seven therapists and ten laypersons on the task of assessing post-stroke survivors' quality of motion, and analyzed their performance, agreement level on the task, and reliance on AI without and with two types of AI explanations. Our results showed that the AI model with both salient features and counterfactual explanations assisted therapists and laypersons to improve their performance and agreement level on the task when `right' AI outputs are presented. While both therapists and laypersons over-relied on `wrong' AI outputs, counterfactual explanations assisted both therapists and laypersons to reduce their over-reliance on `wrong' AI outputs by 21\% compared to salient feature explanations. Specifically, laypersons had higher performance degrades by 18.0 f1-score with salient feature explanations and 14.0 f1-score with counterfactual explanations than therapists with performance degrades of 8.6 and 2.8 f1-scores respectively. Our work discusses the potential of counterfactual explanations to better estimate the accuracy of an AI model and reduce over-reliance on `wrong' AI outputs and implications for improving human-AI collaborative decision-making.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在高度决策领域（如医疗）中被越来越广泛使用以协助人类决策。然而，研究人员发现，人们可能会过度依赖错误的AI模型建议而不是实现人类AI协同性能。在这种情况下，我们使用了突出性特征解释以及对其他选项的对比解释，以便让人类更加分析地审查AI建议，并且研究这些解释对信任和依赖AI的影响。我们在评估后期生存者质量动作任务上进行了实验，并分析了参与者的表现、同意水平和无AI和两种AI解释情况下的AI依赖度。我们的结果显示，带有突出性特征和对比解释的AI模型可以帮助治疗师和非专业人员提高表现和同意水平。然而，两者都会过度依赖错误的AI输出，并且对比解释可以帮助两者减少对错误AI输出的依赖度，相比突出性特征解释下降21%。特别是，非专业人员在使用突出性特征解释时表现下降18.0 f1-score，而使用对比解释时表现下降14.0 f1-score，与治疗师表现下降8.6和2.8 f1-score相比。我们的研究表明，对比解释可以更好地估计AI模型的准确性，降低对错误AI输出的依赖度，并对人类AI协同决策产生影响。
</details></li>
</ul>
<hr>
<h2 id="Some-Options-for-Instantiation-of-Bipolar-Argument-Graphs-with-Deductive-Arguments"><a href="#Some-Options-for-Instantiation-of-Bipolar-Argument-Graphs-with-Deductive-Arguments" class="headerlink" title="Some Options for Instantiation of Bipolar Argument Graphs with Deductive Arguments"></a>Some Options for Instantiation of Bipolar Argument Graphs with Deductive Arguments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04372">http://arxiv.org/abs/2308.04372</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anthony Hunter</li>
<li>for: 本研究旨在提供一种基于逻辑 Argument 的 Framework，用于实例化二分olar Argument Graph，以更好地理解 Argument 的内部结构和它们之间的交互。</li>
<li>methods: 本研究使用逻辑 Argument 来实例化二分olar Argument Graph，并提出了一些可能的约束，以考虑 Argument 的内部结构和它们之间的关系类型。</li>
<li>results: 本研究的结果可以帮助我们更好地理解二分olar Argument Graph 中的 Argument 和它们之间的交互，并提供一种基于逻辑 Argument 的 Framework 来实现这一目标。<details>
<summary>Abstract</summary>
Argument graphs provide an abstract representation of an argumentative situation. A bipolar argument graph is a directed graph where each node denotes an argument, and each arc denotes the influence of one argument on another. Here we assume that the influence is supporting, attacking, or ambiguous. In a bipolar argument graph, each argument is atomic and so it has no internal structure. Yet to better understand the nature of the individual arguments, and how they interact, it is important to consider their internal structure. To address this need, this paper presents a framework based on the use of logical arguments to instantiate bipolar argument graphs, and a set of possible constraints on instantiating arguments that take into account the internal structure of the arguments, and the types of relationship between arguments.
</details>
<details>
<summary>摘要</summary>
Argument graphs provide an abstract representation of an argumentative situation. A bipolar argument graph is a directed graph where each node denotes an argument, and each arc denotes the influence of one argument on another. Here we assume that the influence is supporting, attacking, or ambiguous. In a bipolar argument graph, each argument is atomic and so it has no internal structure. However, to better understand the nature of the individual arguments and how they interact, it is important to consider their internal structure. To address this need, this paper presents a framework based on the use of logical arguments to instantiate bipolar argument graphs, and a set of possible constraints on instantiating arguments that take into account the internal structure of the arguments and the types of relationships between them.
</details></li>
</ul>
<hr>
<h2 id="Cumulative-Reasoning-with-Large-Language-Models"><a href="#Cumulative-Reasoning-with-Large-Language-Models" class="headerlink" title="Cumulative Reasoning with Large Language Models"></a>Cumulative Reasoning with Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04371">http://arxiv.org/abs/2308.04371</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iiis-ai/cumulative-reasoning">https://github.com/iiis-ai/cumulative-reasoning</a></li>
<li>paper_authors: Yifan Zhang, Jingqin Yang, Yang Yuan, Andrew Chi-Chih Yao</li>
<li>for:  solves complex problems with human-like thought processes</li>
<li>methods:  employs language models in a cumulative and iterative manner, decomposing tasks into smaller components</li>
<li>results:  consistently outperforms existing methods with an improvement up to 9.3%, achieves 98.04% accuracy on the curated FOLIO wiki dataset, and achieves 94% accuracy on the Game of 24 with a 20% enhancement over the previous state-of-the-art method.Here’s the full text in Simplified Chinese:</li>
<li>for:  solves complex problems with human-like thought processes</li>
<li>methods:  employs language models in a cumulative and iterative manner, decomposing tasks into smaller components</li>
<li>results:  consistently outperforms existing methods with an improvement up to 9.3%, achieves 98.04% accuracy on the curated FOLIO wiki dataset, and achieves 94% accuracy on the Game of 24 with a 20% enhancement over the previous state-of-the-art method.<details>
<summary>Abstract</summary>
While language models are powerful and versatile, they often fail to address highly complex problems. This is because solving complex problems requires deliberate thinking, which has been only minimally guided during training. In this paper, we propose a new method called Cumulative Reasoning (CR), which employs language models in a cumulative and iterative manner to emulate human thought processes. By decomposing tasks into smaller components, CR streamlines the problem-solving process, rendering it both more manageable and effective. For logical inference tasks, CR consistently outperforms existing methods with an improvement up to 9.3%, and achieves the astonishing accuracy of 98.04% on the curated FOLIO wiki dataset. In the context of the Game of 24, CR achieves an accuracy of 94%, which signifies a substantial enhancement of 20% over the previous state-of-the-art method (code is available at https://github.com/iiis-ai/cumulative-reasoning).
</details>
<details>
<summary>摘要</summary>
While language models are powerful and versatile, they often fail to address highly complex problems. This is because solving complex problems requires deliberate thinking, which has been only minimally guided during training. In this paper, we propose a new method called Cumulative Reasoning (CR), which employs language models in a cumulative and iterative manner to emulate human thought processes. By decomposing tasks into smaller components, CR streamlines the problem-solving process, rendering it both more manageable and effective. For logical inference tasks, CR consistently outperforms existing methods with an improvement up to 9.3%, and achieves the astonishing accuracy of 98.04% on the curated FOLIO wiki dataset. In the context of the Game of 24, CR achieves an accuracy of 94%, which signifies a substantial enhancement of 20% over the previous state-of-the-art method (code is available at https://github.com/iiis-ai/cumulative-reasoning).Here's the word-for-word translation of the text into Simplified Chinese: whilst language models powerful versatile often fail address highly complex problems . This because solving complex problems requires deliberate thinking , which has been only minimally guided during training . In this paper , we propose new method called Cumulative Reasoning (CR) , which employs language models in cumulative iterative manner emulate human thought processes . By decomposing tasks smaller components , CR streamlines problem-solving process , rendering it both more manageable effective . For logical inference tasks , CR consistently outperforms existing methods with improvement up 9.3% , and achieves astonishing accuracy 98.04% on curated FOLIO wiki dataset . In context of Game of 24 , CR achieves accuracy 94% , which signifies substantial enhancement 20% over previous state-of-the-art method (code available at https://github.com/iiis-ai/cumulative-reasoning) .
</details></li>
</ul>
<hr>
<h2 id="Learning-Unbiased-Image-Segmentation-A-Case-Study-with-Plain-Knee-Radiographs"><a href="#Learning-Unbiased-Image-Segmentation-A-Case-Study-with-Plain-Knee-Radiographs" class="headerlink" title="Learning Unbiased Image Segmentation: A Case Study with Plain Knee Radiographs"></a>Learning Unbiased Image Segmentation: A Case Study with Plain Knee Radiographs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04356">http://arxiv.org/abs/2308.04356</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nickolas Littlefield, Johannes F. Plate, Kurt R. Weiss, Ines Lohse, Avani Chhabra, Ismaeel A. Siddiqui, Zoe Menezes, George Mastorakos, Sakshi Mehul Thakar, Mehrnaz Abedian, Matthew F. Gong, Luke A. Carlson, Hamidreza Moradi, Soheyla Amirian, Ahmad P. Tafti</li>
<li>for: 这个研究的目的是探讨深度学习算法在骨灰质影像分割中存在的可见性偏见，以及如何通过 Mitigation Strategies 来纠正这些偏见。</li>
<li>methods: 这篇研究使用了深度学习算法来进行骨灰质影像分割，并使用了plain radiographs进行训练。</li>
<li>results: 研究发现了gender和racial偏见，并提出了一些 Mitigation Strategies来纠正这些偏见，以确保公平和不偏见的分割结果。<details>
<summary>Abstract</summary>
Automatic segmentation of knee bony anatomy is essential in orthopedics, and it has been around for several years in both pre-operative and post-operative settings. While deep learning algorithms have demonstrated exceptional performance in medical image analysis, the assessment of fairness and potential biases within these models remains limited. This study aims to revisit deep learning-powered knee-bony anatomy segmentation using plain radiographs to uncover visible gender and racial biases. The current contribution offers the potential to advance our understanding of biases, and it provides practical insights for researchers and practitioners in medical imaging. The proposed mitigation strategies mitigate gender and racial biases, ensuring fair and unbiased segmentation results. Furthermore, this work promotes equal access to accurate diagnoses and treatment outcomes for diverse patient populations, fostering equitable and inclusive healthcare provision.
</details>
<details>
<summary>摘要</summary>
自动 segmentation of knee 骨骼结构是orthopedics中的一项基础技术，已经在预操作和后操作设置中存在几年之久。深度学习算法在医疗影像分析中表现出色，但评估公平和可能的偏见在这些模型中仍然有限。本研究旨在通过使用平面X光图像来探索深度学习 powers knee-bony anatomy segmentation中可见的性别和种族偏见。本贡献可能提高我们对偏见的理解，并提供实践的建议 для研究人员和实践者在医疗影像领域。提出的mitigation strategies可以抑制性别和种族偏见，确保公平和不偏见的segmentation结果。此外，这种工作促进了多样化患者人口群的准确诊断和治疗结果，推动了公平和包容的医疗服务。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/09/cs.AI_2023_08_09/" data-id="clogyj8v000277cra95i00xl0" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_08_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/09/cs.CL_2023_08_09/" class="article-date">
  <time datetime="2023-08-09T11:00:00.000Z" itemprop="datePublished">2023-08-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/09/cs.CL_2023_08_09/">cs.CL - 2023-08-09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Performance-Analysis-of-Transformer-Based-Models-BERT-ALBERT-and-RoBERTa-in-Fake-News-Detection"><a href="#Performance-Analysis-of-Transformer-Based-Models-BERT-ALBERT-and-RoBERTa-in-Fake-News-Detection" class="headerlink" title="Performance Analysis of Transformer Based Models (BERT, ALBERT and RoBERTa) in Fake News Detection"></a>Performance Analysis of Transformer Based Models (BERT, ALBERT and RoBERTa) in Fake News Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04950">http://arxiv.org/abs/2308.04950</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shafna81/fakenewsdetection">https://github.com/shafna81/fakenewsdetection</a></li>
<li>paper_authors: Shafna Fitria Nur Azizah, Hasan Dwi Cahyono, Sari Widya Sihwi, Wisnu Widiarto</li>
<li>for: 本研究旨在探讨使用 transformer 模型 для检测假新闻在印度尼西亚语言中的表现。</li>
<li>methods: 本研究使用了 ALBERT 和 RoBERTa 两种改进的 transformer 模型，并对其进行比较，以检测假新闻的性能。</li>
<li>results: 研究发现，使用 ALBERT 模型可以达到 87.6% 的准确率、86.9% 的精度、86.9% F1 分数和 174.5 次&#x2F;秒（epoch）的运行时间，超过了非 transformer 方法的性能。<details>
<summary>Abstract</summary>
Fake news is fake material in a news media format but is not processed properly by news agencies. The fake material can provoke or defame significant entities or individuals or potentially even for the personal interests of the creators, causing problems for society. Distinguishing fake news and real news is challenging due to limited of domain knowledge and time constraints. According to the survey, the top three areas most exposed to hoaxes and misinformation by residents are in Banten, DKI Jakarta and West Java. The model of transformers is referring to an approach in the field of artificial intelligence (AI) in natural language processing utilizing the deep learning architectures. Transformers exercise a powerful attention mechanism to process text in parallel and produce rich and contextual word representations. A previous study indicates a superior performance of a transformer model known as BERT over and above non transformer approach. However, some studies suggest the performance can be improved with the use of improved BERT models known as ALBERT and RoBERTa. However, the modified BERT models are not well explored for detecting fake news in Bahasa Indonesia. In this research, we explore those transformer models and found that ALBERT outperformed other models with 87.6% accuracy, 86.9% precision, 86.9% F1-score, and 174.5 run-time (s/epoch) respectively. Source code available at: https://github.com/Shafna81/fakenewsdetection.git
</details>
<details>
<summary>摘要</summary>
假新闻是指在新闻媒体格式中存在假信息，但是由新闻机构不当处理而导致的假物。假新闻可能会诋毁或攻击重要个体或组织，甚至是为个人利益。分辨假新闻和真实新闻是困难的，因为有限的领域知识和时间限制。据调查，居民最常受到诈骗和不实信息的地区为印度尼西亚巴仁、特区雅加达和西爪哇。 transformers 是一种人工智能（AI）自然语言处理领域的方法，使用深度学习架构。 transformers 使用强大的注意机制来并行处理文本，生成rich和上下文敏感的单词表示。前一项研究表明，BERT 模型在非 transformer 方法之上显示出超越性，但是一些研究表明，使用改进的 BERT 模型，如 ALBERT 和 RoBERTa，可以提高性能。然而，这些改进 BERT 模型在印度尼西亚语言检测假新闻方面尚未得到充分探索。本研究探讨了这些 transformer 模型，发现 ALBERT 模型在准确率、精度、 F1 分数和运行时间等方面均达到了最高水平，具体数据为 87.6%、86.9%、86.9% 和 174.5（s/epoch）。源代码可以在 GitHub 上找到：https://github.com/Shafna81/fakenewsdetection.git。
</details></li>
</ul>
<hr>
<h2 id="Extrapolating-Large-Language-Models-to-Non-English-by-Aligning-Languages"><a href="#Extrapolating-Large-Language-Models-to-Non-English-by-Aligning-Languages" class="headerlink" title="Extrapolating Large Language Models to Non-English by Aligning Languages"></a>Extrapolating Large Language Models to Non-English by Aligning Languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04948">http://arxiv.org/abs/2308.04948</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenhao Zhu, Yunzhe Lv, Qingxiu Dong, Fei Yuan, Jingjing Xu, Shujian Huang, Lingpeng Kong, Jiajun Chen, Lei Li</li>
<li>for: 提高大语言模型（LLM）对非英语语言的能力</li>
<li>methods: 使用语义对齐和指令调整来强化预训练的LLM在非英语语言上</li>
<li>results: x-LLaMA模型在六种非英语语言的跨语言标准 bencmark 上平均高于英语 instrucction-tuned 对手（Alpaca） by 42.50%，并在中文人文任务上达到了8.2%的提升。<details>
<summary>Abstract</summary>
Due to the unbalanced training data distribution, the language ability of large language models (LLMs) is often biased towards English. In this paper, we propose to empower pre-trained LLMs on non-English languages by building semantic alignment across languages. We perform instruction-tuning on LLaMA with both translation task data and cross-lingual general task data to obtain cross-lingual models (x-LLaMA). Experiment results on cross-lingual benchmark XQUAD and MLQA show that x-LLaMA models outperform the English instruction-tuned counterpart (Alpaca) by 42.50% on average on six non-English languages. Further experiments on Chinese benchmark C-Eval show that x-LLaMA achieves significant improvement on Chinese humanities tasks, outperforming Alpaca by 8.2%. We also discover that incorporating non-English text on the target side of translation data is particularly effective for boosting non-English ability. Besides, we find that semantic alignment within LLM can be further strengthened as translation task data scales up and we present the formulation of the underlying scaling law. Evaluation results on translation dataset Flores-101 show that \method outperforms previous LLaMA-based models in all evaluated directions. Code and data will be available at: https://github.com/OwenNJU/x-LLM.
</details>
<details>
<summary>摘要</summary>
由于训练数据的不均衡分布，大型自然语言模型（LLM）的语言能力 часто受到英语的影响。在这篇论文中，我们提出了使用语义对Alignment来强化预训练的LLM在非英语语言上的能力。我们通过对LLaMA进行 instrucion-tuning，使用翻译任务数据和跨语言通用任务数据来获得跨语言模型（x-LLaMA）。实验结果表明，x-LLaMA模型在六种非英语语言的跨语言标准 bencmark XQUAD和MLQA上的表现比英语 instrucion-tuned counterpart（Alpaca）提高42.50%的平均值。进一步的实验表明，x-LLaMA在中文人文任务上 achieve  significan improvement，比Alpaca提高8.2%。我们还发现，在目标语言的翻译数据中包含非英语文本时，特别有效地提高非英语能力。此外，我们发现在翻译任务数据尺度上，LLM的语义对Alignment可以进一步强化。我们还提出了翻译数据集Flores-101上的扩展法则。评估结果表明，我们的方法在所有评估方向上都超过了之前的LLaMA-based模型。代码和数据将在https://github.com/OwenNJU/x-LLM上公开。
</details></li>
</ul>
<hr>
<h2 id="Integrating-large-language-models-and-active-inference-to-understand-eye-movements-in-reading-and-dyslexia"><a href="#Integrating-large-language-models-and-active-inference-to-understand-eye-movements-in-reading-and-dyslexia" class="headerlink" title="Integrating large language models and active inference to understand eye movements in reading and dyslexia"></a>Integrating large language models and active inference to understand eye movements in reading and dyslexia</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04941">http://arxiv.org/abs/2308.04941</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/donnarumma/hai_language">https://github.com/donnarumma/hai_language</a></li>
<li>paper_authors: Francesco Donnarumma, Mirco Frosolone, Giovanni Pezzulo</li>
<li>for:  simulating reading and eye movements using a computational model</li>
<li>methods:  hierarchical active inference, combining strengths of large language models and active inference</li>
<li>results:  proficiency in reading known and unknown words and sentences, exploration of maladaptive inference effects in dyslexia, potential implications for understanding and addressing dyslexia<details>
<summary>Abstract</summary>
We present a novel computational model employing hierarchical active inference to simulate reading and eye movements. The model characterizes linguistic processing as inference over a hierarchical generative model, facilitating predictions and inferences at various levels of granularity, from syllables to sentences.   Our approach combines the strengths of large language models for realistic textual predictions and active inference for guiding eye movements to informative textual information, enabling the testing of predictions. The model exhibits proficiency in reading both known and unknown words and sentences, adhering to the distinction between lexical and nonlexical routes in dual-route theories of reading. Notably, our model permits the exploration of maladaptive inference effects on eye movements during reading, such as in dyslexia. To simulate this condition, we attenuate the contribution of priors during the reading process, leading to incorrect inferences and a more fragmented reading style, characterized by a greater number of shorter saccades. This alignment with empirical findings regarding eye movements in dyslexic individuals highlights the model's potential to aid in understanding the cognitive processes underlying reading and eye movements, as well as how reading deficits associated with dyslexia may emerge from maladaptive predictive processing.   In summary, our model represents a significant advancement in comprehending the intricate cognitive processes involved in reading and eye movements, with potential implications for understanding and addressing dyslexia through the simulation of maladaptive inference. It may offer valuable insights into this condition and contribute to the development of more effective interventions for treatment.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的计算模型，使用层次活动推理来模拟阅读和视力运动。该模型将语言处理视为推理过程中的层次生成模型，从而实现不同级别的预测和推理，从音节到句子。我们的方法结合了大型语言模型的实用性和活动推理的指导力，以便测试预测。模型能够预测已知和未知词和句子，并且遵循 dual-route 理论中的词和非词路径分离。特别是，我们的模型允许探索误差推理对视力运动的影响，如阅读障碍。为了模拟这种情况，我们在阅读过程中减少了假设的影响，导致错误的推理和更多的短暂快速跳跃，这与词 Reading 障碍者的实际观察结果相符。这种对models 的应用可能为理解阅读和视力运动的认知过程提供valuable 信息，以及如何通过模拟误差推理来理解和治疗阅读障碍。
</details></li>
</ul>
<hr>
<h2 id="Unsupervised-Out-of-Distribution-Dialect-Detection-with-Mahalanobis-Distance"><a href="#Unsupervised-Out-of-Distribution-Dialect-Detection-with-Mahalanobis-Distance" class="headerlink" title="Unsupervised Out-of-Distribution Dialect Detection with Mahalanobis Distance"></a>Unsupervised Out-of-Distribution Dialect Detection with Mahalanobis Distance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04886">http://arxiv.org/abs/2308.04886</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sourya Dipta Das, Yash Vadi, Abhishek Unnam, Kuldeep Yadav</li>
<li>for: 本研究旨在提高 dialect classification 系统的总性性能，并应对实际场景中可能出现的异常输入。</li>
<li>methods: 我们提出了一种基于 Mahalanobis 距离的无监督方法，使用 wav2vec 2.0 变换器模型的所有中间层 embedding 进行多任务学习。</li>
<li>results: 我们的方法与其他现有的 OOD 检测方法比较，显著地提高了检测准确率。<details>
<summary>Abstract</summary>
Dialect classification is used in a variety of applications, such as machine translation and speech recognition, to improve the overall performance of the system. In a real-world scenario, a deployed dialect classification model can encounter anomalous inputs that differ from the training data distribution, also called out-of-distribution (OOD) samples. Those OOD samples can lead to unexpected outputs, as dialects of those samples are unseen during model training. Out-of-distribution detection is a new research area that has received little attention in the context of dialect classification. Towards this, we proposed a simple yet effective unsupervised Mahalanobis distance feature-based method to detect out-of-distribution samples. We utilize the latent embeddings from all intermediate layers of a wav2vec 2.0 transformer-based dialect classifier model for multi-task learning. Our proposed approach outperforms other state-of-the-art OOD detection methods significantly.
</details>
<details>
<summary>摘要</summary>
<<SYS>>dialect 分类在多种应用中使用，如机器翻译和语音识别，以提高整体系统性能。在实际场景中，部署的 диалект分类模型可能会遇到不同于训练数据分布的输入，也称为 OUT-OF-DISTRIBUTION（OOD）样本。这些 OOD 样本可能会导致不预期的输出，因为这些 диаLECT 的样本在模型训练时未被考虑。 OUT-OF-DISTRIBUTION 检测是一个新的研究领域，在 диалект分类上尚未受到充分关注。为了解决这个问题，我们提出了一种简单 yet 有效的无监督 Mahalanobis 距离特征基于方法。我们利用了所有 intermediate layer 的 latent 嵌入，来进行多任务学习。我们的提议方法在比较其他现有的 OOD 检测方法时表现出色。
</details></li>
</ul>
<hr>
<h2 id="Information-Theoretic-Characterization-of-Vowel-Harmony-A-Cross-Linguistic-Study-on-Word-Lists"><a href="#Information-Theoretic-Characterization-of-Vowel-Harmony-A-Cross-Linguistic-Study-on-Word-Lists" class="headerlink" title="Information-Theoretic Characterization of Vowel Harmony: A Cross-Linguistic Study on Word Lists"></a>Information-Theoretic Characterization of Vowel Harmony: A Cross-Linguistic Study on Word Lists</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04885">http://arxiv.org/abs/2308.04885</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/uds-lsv/vowel-harmony-from-word-lists">https://github.com/uds-lsv/vowel-harmony-from-word-lists</a></li>
<li>paper_authors: Julius Steuer, Badr Abdullah, Johann-Mattis List, Dietrich Klakow</li>
<li>for: 这项研究的目的是使用数据驱动的计算模型量化口音协调。</li>
<li>methods: 研究人员使用了语音模型（PLMs）来定义一种信息论 metric来衡量口音协调的程度。</li>
<li>results: 研究人员通过使用不含扩Difficult inflection的词形来覆盖更多的语言，并使用word list来训练模型，成功地捕捉了一些语言中的口音协调模式。<details>
<summary>Abstract</summary>
We present a cross-linguistic study that aims to quantify vowel harmony using data-driven computational modeling. Concretely, we define an information-theoretic measure of harmonicity based on the predictability of vowels in a natural language lexicon, which we estimate using phoneme-level language models (PLMs). Prior quantitative studies have relied heavily on inflected word-forms in the analysis of vowel harmony. We instead train our models using cross-linguistically comparable lemma forms with little or no inflection, which enables us to cover more under-studied languages. Training data for our PLMs consists of word lists with a maximum of 1000 entries per language. Despite the fact that the data we employ are substantially smaller than previously used corpora, our experiments demonstrate the neural PLMs capture vowel harmony patterns in a set of languages that exhibit this phenomenon. Our work also demonstrates that word lists are a valuable resource for typological research, and offers new possibilities for future studies on low-resource, under-studied languages.
</details>
<details>
<summary>摘要</summary>
我们发表了一项跨语言研究，旨在使用数据驱动的计算模型量化元音协调。具体来说，我们定义了基于自然语言词典中元音预测性的信息理论度量，并使用语音模型（PLM）来估算。先前的量化研究主要基于语法变化word形式进行分析元音协调。我们 Instead，我们使用跨语言相似的 lemma 形式来训练我们的模型，这使得我们能够更好地涵盖更多的未研究语言。我们的训练数据包括每种语言1000个单词最多的列表。尽管我们使用的数据比之前使用的 corpora 更小，但我们的实验表明我们的神经网络PLMs 能够 Capture 元音协调模式在一组语言中。我们的工作还表明，word lists 是 typological 研究的有价值资源，并且提供了未来研究低资源、未研究语言的新可能性。
</details></li>
</ul>
<hr>
<h2 id="Emotion-Conditioned-Text-Generation-through-Automatic-Prompt-Optimization"><a href="#Emotion-Conditioned-Text-Generation-through-Automatic-Prompt-Optimization" class="headerlink" title="Emotion-Conditioned Text Generation through Automatic Prompt Optimization"></a>Emotion-Conditioned Text Generation through Automatic Prompt Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04857">http://arxiv.org/abs/2308.04857</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yarik Menchaca Resendiz, Roman Klinger</li>
<li>for: 这个论文主要目的是提出一种自动生成受情况条件文本的方法，以便在不需要贵重的精度调整或者培育大型语言模型从头开始的情况下，可以达到竞争性的结果。</li>
<li>methods: 这种方法使用迭代优化程序，通过添加、删除或者替换 tokens，对提供的提示进行优化。为了评估优化后的提示的质量，我们使用一个文本分类器，以确定生成文本中是否满足情况条件。</li>
<li>results: 我们在使用这种方法进行情感条件文本生成 task 时，与手动设计的提示相比，能够达到更高的 macro-average F1 值（0.75），而手动设计的seed prompts 只能达到 macro-average F1 值为 0.22。<details>
<summary>Abstract</summary>
Conditional natural language generation methods often require either expensive fine-tuning or training a large language model from scratch. Both are unlikely to lead to good results without a substantial amount of data and computational resources. Prompt learning without changing the parameters of a large language model presents a promising alternative. It is a cost-effective approach, while still achieving competitive results. While this procedure is now established for zero- and few-shot text classification and structured prediction, it has received limited attention in conditional text generation. We present the first automatic prompt optimization approach for emotion-conditioned text generation with instruction-fine-tuned models. Our method uses an iterative optimization procedure that changes the prompt by adding, removing, or replacing tokens. As objective function, we only require a text classifier that measures the realization of the conditional variable in the generated text. We evaluate the method on emotion-conditioned text generation with a focus on event reports and compare it to manually designed prompts that also act as the seed for the optimization procedure. The optimized prompts achieve 0.75 macro-average F1 to fulfill the emotion condition in contrast to manually designed seed prompts with only 0.22 macro-average F1.
</details>
<details>
<summary>摘要</summary>
常用的自然语言生成方法经常需要 either 昂贵的微调或者从scratch学习大型语言模型。两者都不太可能导致良好的结果，除非有庞大的数据和计算资源。提示学习无需改变大型语言模型的参数，表现出了可持续的潜在。这种方法在零和几个shot文本分类和结构预测方面已经得到了广泛的关注，但在条件文本生成方面却受到了有限的关注。我们提出了首个自动提示优化方法 для情感条件文本生成，使用迭代优化过程，通过添加、删除或替换Token来更新提示。我们的方法只需要一个可测量实现条件变量的文本分类器作为目标函数。我们对情感条件文本生成进行评估，并与手动设计的种子提示进行比较。得到的优化提示达到0.75的macro-average F1，以满足情感条件，而手动设计的种子提示只达到0.22的macro-average F1。
</details></li>
</ul>
<hr>
<h2 id="TSSR-A-Truncated-and-Signed-Square-Root-Activation-Function-for-Neural-Networks"><a href="#TSSR-A-Truncated-and-Signed-Square-Root-Activation-Function-for-Neural-Networks" class="headerlink" title="TSSR: A Truncated and Signed Square Root Activation Function for Neural Networks"></a>TSSR: A Truncated and Signed Square Root Activation Function for Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04832">http://arxiv.org/abs/2308.04832</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanhao Gong</li>
<li>for: 这篇论文主要是为了提出一种新的激活函数called Truncated and Signed Square Root (TSSR)函数。</li>
<li>methods: 这篇论文使用了TSSR函数，该函数具有odd、非线性、卷积和导数 kontinuous和总是正的特点。</li>
<li>results: 试验表明，提议的TSSR函数在比较难以学习的问题上表现更好，比如计算机视觉、自然语言处理和语音识别等领域。<details>
<summary>Abstract</summary>
Activation functions are essential components of neural networks. In this paper, we introduce a new activation function called the Truncated and Signed Square Root (TSSR) function. This function is distinctive because it is odd, nonlinear, monotone and differentiable. Its gradient is continuous and always positive. Thanks to these properties, it has the potential to improve the numerical stability of neural networks. Several experiments confirm that the proposed TSSR has better performance than other stat-of-the-art activation functions. The proposed function has significant implications for the development of neural network models and can be applied to a wide range of applications in fields such as computer vision, natural language processing, and speech recognition.
</details>
<details>
<summary>摘要</summary>
translate into Simplified Chinese:activation functions are crucial components of neural networks. In this paper, we introduce a new activation function called the Truncated and Signed Square Root (TSSR) function. This function is distinctive because it is odd, nonlinear, monotone, and differentiable. Its gradient is continuous and always positive. Thanks to these properties, it has the potential to improve the numerical stability of neural networks. Several experiments confirm that the proposed TSSR has better performance than other state-of-the-art activation functions. The proposed function has significant implications for the development of neural network models and can be applied to a wide range of applications in fields such as computer vision, natural language processing, and speech recognition.Note:* "odd" is translated as "奇数" (qīshū)* "nonlinear" is translated as "非线性" (fēi lǐnéng)* "monotone" is translated as "单调" (dāngdiào)* "differentiable" is translated as "可导数" (kědǎoxiàng)* "continuous" is translated as "连续" (liánxù)* "always positive" is translated as "总是正" (zǒngshì zhèng)
</details></li>
</ul>
<hr>
<h2 id="Evaluating-the-Generation-Capabilities-of-Large-Chinese-Language-Models"><a href="#Evaluating-the-Generation-Capabilities-of-Large-Chinese-Language-Models" class="headerlink" title="Evaluating the Generation Capabilities of Large Chinese Language Models"></a>Evaluating the Generation Capabilities of Large Chinese Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04823">http://arxiv.org/abs/2308.04823</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Felixgithub2017/CG-Eval">https://github.com/Felixgithub2017/CG-Eval</a></li>
<li>paper_authors: Hui Zeng, Jingyuan Xue, Meng Hao, Chen Sun, Bin Ning, Na Zhang</li>
<li>for: 这篇论文是为了评估大型中文语言模型在不同学术领域的生成能力而写的。</li>
<li>methods: 这篇论文使用了多种指标来评估模型的生成质量，包括准确率、相关性、朴素质量等。</li>
<li>results: 论文发现大型中文语言模型在六个领域中的生成能力强度不同，sciences and engineering领域的模型表现最好，而judicial examination领域的模型表现最差。同时，论文还提出了一个可重复性的Gscore指标来评估模型的生成质量。<details>
<summary>Abstract</summary>
This paper presents CG-Eval, the first comprehensive evaluation of the generation capabilities of large Chinese language models across a wide range of academic disciplines. The models' performance was assessed based on their ability to generate accurate and relevant responses to different types of questions in six disciplines, namely, Science and Engineering, Humanities and Social Sciences, Mathematical Calculations, Medical Practitioner Qualification Examination, Judicial Examination, and Certified Public Accountant Examination. This paper also presents Gscore, a composite index derived from the weighted sum of multiple metrics to measure the quality of model's generation against a reference. The test data and test results can be found at http://cgeval.besteasy.com/.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="CLEVA-Chinese-Language-Models-EVAluation-Platform"><a href="#CLEVA-Chinese-Language-Models-EVAluation-Platform" class="headerlink" title="CLEVA: Chinese Language Models EVAluation Platform"></a>CLEVA: Chinese Language Models EVAluation Platform</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04813">http://arxiv.org/abs/2308.04813</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanyang Li, Jianqiao Zhao, Duo Zheng, Zi-Yuan Hu, Zhi Chen, Xiaohui Su, Yongfeng Huang, Shijia Huang, Dahua Lin, Michael R. Lyu, Liwei Wang</li>
<li>for: 评估中文大型自然语言模型（LLM）的能力 has become an increasingly significant issue, and the paper aims to address this issue by presenting a comprehensive platform for evaluating Chinese LLMs.</li>
<li>methods: The platform, called CLEVA, employs a standardized workflow to assess LLMs’ performance across various dimensions, regularly updating a competitive leaderboard. It also curates a significant proportion of new data and develops a sampling strategy to alleviate contamination.</li>
<li>results: Large-scale experiments featuring 23 influential Chinese LLMs have validated CLEVA’s efficacy.Here is the same information in Simplified Chinese text:</li>
<li>for: 评估中文大型自然语言模型（LLM）的能力已成为一个越来越重要的问题，该文章提出了一种全面的评估平台。</li>
<li>methods: 该平台叫做CLEVA，它使用标准化的工作流程评估不同维度的LLM表现，定期更新竞争性的 liderboard。它还curates a significant proportion of new data和开发了一种避免污染的采样策略。</li>
<li>results: 23种Influential Chinese LLMs的大规模实验已经验证了CLEVA的有效性。<details>
<summary>Abstract</summary>
With the continuous emergence of Chinese Large Language Models (LLMs), how to evaluate a model's capabilities has become an increasingly significant issue. The absence of a comprehensive Chinese benchmark that thoroughly assesses a model's performance, the unstandardized and incomparable prompting procedure, and the prevalent risk of contamination pose major challenges in the current evaluation of Chinese LLMs. We present CLEVA, a user-friendly platform crafted to holistically evaluate Chinese LLMs. Our platform employs a standardized workflow to assess LLMs' performance across various dimensions, regularly updating a competitive leaderboard. To alleviate contamination, CLEVA curates a significant proportion of new data and develops a sampling strategy that guarantees a unique subset for each leaderboard round. Empowered by an easy-to-use interface that requires just a few mouse clicks and a model API, users can conduct a thorough evaluation with minimal coding. Large-scale experiments featuring 23 influential Chinese LLMs have validated CLEVA's efficacy.
</details>
<details>
<summary>摘要</summary>
To address these challenges, we present CLEVA, a user-friendly platform that holistically evaluates Chinese LLMs. Our platform employs a standardized workflow to assess LLMs' performance across various dimensions, and regularly updates a competitive leaderboard. To alleviate contamination, CLEVA curates a significant proportion of new data and develops a sampling strategy that guarantees a unique subset for each leaderboard round.CLEVA is easy to use and requires just a few mouse clicks and a model API. Users can conduct a thorough evaluation with minimal coding. Large-scale experiments featuring 23 influential Chinese LLMs have validated CLEVA's efficacy.In simplified Chinese, the text would be:中文大语模型（LLM）的出现使得评估模型能力的问题日益重要。但是现在中文LLM的评估遇到了一些挑战，包括中文benchmark的缺乏，评估程序的标准化和比较不一致，以及污染的问题。为了解决这些挑战，我们提出了CLEVA，一个易用的平台，可以全面评估中文LLM。我们的平台使用标准化的工作流程，评估模型的能力在不同的维度上，并 régulièrement更新竞争性的领先板。为了解决污染的问题，CLEVA获取了大量的新数据，并开发了一个确保每个领先板都有唯一子集的抽样方法。使用CLEVA需要只需要几个点键和模型API，用户可以快速进行充分的评估， minimal coding。大规模的实验表明，CLEVA具有效果。
</details></li>
</ul>
<hr>
<h2 id="A-Bipartite-Graph-is-All-We-Need-for-Enhancing-Emotional-Reasoning-with-Commonsense-Knowledge"><a href="#A-Bipartite-Graph-is-All-We-Need-for-Enhancing-Emotional-Reasoning-with-Commonsense-Knowledge" class="headerlink" title="A Bipartite Graph is All We Need for Enhancing Emotional Reasoning with Commonsense Knowledge"></a>A Bipartite Graph is All We Need for Enhancing Emotional Reasoning with Commonsense Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04811">http://arxiv.org/abs/2308.04811</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/stevekgyang/bhg">https://github.com/stevekgyang/bhg</a></li>
<li>paper_authors: Kailai Yang, Tianlin Zhang, Shaoxiong Ji, Sophia Ananiadou</li>
<li>for: 这种研究旨在提高人工智能系统的情感理解能力，特别是在社交媒体上的舆论挖掘和Empathy对话系统中。</li>
<li>methods: 这种方法使用二分图等维度异质图（BHG）方法，将上下文感知的语音表示和知识表示作为不同类型的节点模型，并提出了两种新的知识聚合节点类型来自动过滤和交互知识。</li>
<li>results: 这种方法在对比之下显著超越了现有的知识混合方法，并且可以直接普适化到不同类型和级别的知识源。<details>
<summary>Abstract</summary>
The context-aware emotional reasoning ability of AI systems, especially in conversations, is of vital importance in applications such as online opinion mining from social media and empathetic dialogue systems. Due to the implicit nature of conveying emotions in many scenarios, commonsense knowledge is widely utilized to enrich utterance semantics and enhance conversation modeling. However, most previous knowledge infusion methods perform empirical knowledge filtering and design highly customized architectures for knowledge interaction with the utterances, which can discard useful knowledge aspects and limit their generalizability to different knowledge sources. Based on these observations, we propose a Bipartite Heterogeneous Graph (BHG) method for enhancing emotional reasoning with commonsense knowledge. In BHG, the extracted context-aware utterance representations and knowledge representations are modeled as heterogeneous nodes. Two more knowledge aggregation node types are proposed to perform automatic knowledge filtering and interaction. BHG-based knowledge infusion can be directly generalized to multi-type and multi-grained knowledge sources. In addition, we propose a Multi-dimensional Heterogeneous Graph Transformer (MHGT) to perform graph reasoning, which can retain unchanged feature spaces and unequal dimensions for heterogeneous node types during inference to prevent unnecessary loss of information. Experiments show that BHG-based methods significantly outperform state-of-the-art knowledge infusion methods and show generalized knowledge infusion ability with higher efficiency. Further analysis proves that previous empirical knowledge filtering methods do not guarantee to provide the most useful knowledge information. Our code is available at: https://github.com/SteveKGYang/BHG.
</details>
<details>
<summary>摘要</summary>
“context-aware情感理解能力”是人工智能系统在对话中的重要特点，尤其在社交媒体上的情感分析和Empathy对话系统中。由于许多情感表达 implicit nature，因此通常使用常识来填充语音 semantics 和对话模型。然而，大多数先前知识混入方法通过 empirical knowledge filtering 和自定义 architectures 来实现知识与语音的交互，这可能会抛弃有用的知识方面和限制其在不同的知识来源上的一致性。基于这些观察，我们提出了一种 Bipartite Heterogeneous Graph (BHG) 方法来增强情感理解。在 BHG 中，提取的上下文化语音表示和知识表示被模型为不同类型的异常节点。我们还提出了两种新的知识聚合节点类型，以自动实现知识过滤和交互。BHG 基于的知识混入方法可以直接普遍应用于不同类型和多维度的知识来源。此外，我们还提出了一种 Multi-dimensional Heterogeneous Graph Transformer (MHGT) 来进行图reasoning，可以保持不变的特征空间和不等维度的异常节点类型 durante inference，以避免不必要的信息损失。实验表明，BHG 基于的方法在情感理解方面表现出色，并且具有更高的一致性和效率。进一步分析表明，先前的 empirical knowledge filtering 方法并不能提供最有用的知识信息。我们的代码可以在 GitHub 上找到：https://github.com/SteveKGYang/BHG。
</details></li>
</ul>
<hr>
<h2 id="ADMUS-A-Progressive-Question-Answering-Framework-Adaptable-to-Multiple-Knowledge-Sources"><a href="#ADMUS-A-Progressive-Question-Answering-Framework-Adaptable-to-Multiple-Knowledge-Sources" class="headerlink" title="ADMUS: A Progressive Question Answering Framework Adaptable to Multiple Knowledge Sources"></a>ADMUS: A Progressive Question Answering Framework Adaptable to Multiple Knowledge Sources</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04800">http://arxiv.org/abs/2308.04800</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yirui Zhan, Yanzeng Li, Minhao Zhang, Lei Zou</li>
<li>for: 提高KBQA系统在实际场景中的应用性，使得KBQA系统能够轻松地适应不同的数据集。</li>
<li>methods: 提出了一种基于深度学习模型的数据独立KBQA系统，通过解耦KBQA系统的架构，使得系统能够轻松地适应不同的数据集，并且支持多语言和多知识基础的混合使用。</li>
<li>results: 在多种不同的数据集上进行了实质性的试验，证明了ADMUS系统的高效性和灵活性。在线示例可以在<a target="_blank" rel="noopener" href="https://answer.gstore.cn/pc/index.html%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://answer.gstore.cn/pc/index.html中找到。</a><details>
<summary>Abstract</summary>
With the introduction of deep learning models, semantic parsingbased knowledge base question answering (KBQA) systems have achieved high performance in handling complex questions. However, most existing approaches primarily focus on enhancing the model's effectiveness on individual benchmark datasets, disregarding the high costs of adapting the system to disparate datasets in real-world scenarios (e.g., multi-tenant platform). Therefore, we present ADMUS, a progressive knowledge base question answering framework designed to accommodate a wide variety of datasets, including multiple languages, diverse backbone knowledge bases, and disparate question answering datasets. To accomplish the purpose, we decouple the architecture of conventional KBQA systems and propose this dataset-independent framework. Our framework supports the seamless integration of new datasets with minimal effort, only requiring creating a dataset-related micro-service at a negligible cost. To enhance the usability of ADUMS, we design a progressive framework consisting of three stages, ranges from executing exact queries, generating approximate queries and retrieving open-domain knowledge referring from large language models. An online demonstration of ADUMS is available at: https://answer.gstore.cn/pc/index.html
</details>
<details>
<summary>摘要</summary>
随着深度学习模型的引入，基于语义解析的知识库问答（KBQA）系统在处理复杂问题的性能得到了显著提高。然而，大多数现有方法主要是强调改进模型在特定 benchmark 数据集上的效果，忽视了在实际场景中适应不同数据集的高成本（例如，多租户平台）。因此，我们提出了 ADMUS，一个适应多种数据集的进步知识库问答框架。为了实现这一目标，我们将 convent ional KBQA 系统的架构划分为多个独立的组件，并且提出了一种不同数据集的独立框架。这些组件可以轻松地与新的数据集集成，只需要创建一个数据集相关的微服务，成本极低。为了提高 ADMUS 的可用性，我们设计了一个进步的框架，包括三个阶段：在执行精确查询、生成approx query和从大语言模型中提取开放领域知识三个阶段。在线示例可以在以下地址找到：https://answer.gstore.cn/pc/index.html。
</details></li>
</ul>
<hr>
<h2 id="Automatically-measuring-speech-fluency-in-people-with-aphasia-first-achievements-using-read-speech-data"><a href="#Automatically-measuring-speech-fluency-in-people-with-aphasia-first-achievements-using-read-speech-data" class="headerlink" title="Automatically measuring speech fluency in people with aphasia: first achievements using read-speech data"></a>Automatically measuring speech fluency in people with aphasia: first achievements using read-speech data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04763">http://arxiv.org/abs/2308.04763</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lionel Fontan, Typhanie Prince, Aleksandra Nowakowska, Halima Sahraoui, Silvia Martinez-Ferreiro</li>
<li>for: This study aims to assess the relevance of a signal processing algorithm for the automatic measurement of speech fluency in people with aphasia (PWA).</li>
<li>methods: The study uses a forward-backward divergence segmentation and a clustering algorithm to compute four automatic predictors of speech fluency, and combines these predictors into multivariate regression models to predict the average SLP ratings of speech fluency.</li>
<li>results: The study finds that the algorithms used can constitute a cost-effective and reliable tool for the assessment of the speech fluency of patients with aphasia in read-aloud tasks, with accurate predictions and high correlation coefficients between the automatic predictions and SLP ratings.<details>
<summary>Abstract</summary>
Background: Speech and language pathologists (SLPs) often relyon judgements of speech fluency for diagnosing or monitoringpatients with aphasia. However, such subjective methods havebeen criticised for their lack of reliability and their clinical cost interms of time. Aims: This study aims at assessing the relevance of a signalprocessingalgorithm, initially developed in the field of language acquisition, for the automatic measurement of speech fluency in people with aphasia (PWA). Methods & Procedures: Twenty-nine PWA and five control participantswere recruited via non-profit organizations and SLP networks. All participants were recorded while reading out loud a set ofsentences taken from the French version of the Boston Diagnostic Aphasia Examination. Three trained SLPs assessed the fluency of each sentence on a five-point qualitative scale. A forward-backward divergence segmentation and a clustering algorithm were used to compute, for each sentence, four automatic predictors of speech fluency: pseudo-syllable rate, speech ratio, rate of silent breaks, and standard deviation of pseudo-syllable length. The four predictors were finally combined into multivariate regression models (a multiplelinear regression - MLR, and two non-linear models) to predict the average SLP ratings of speech fluency, using a leave-one speaker-out validation scheme. Outcomes & Results: All models achieved accurate predictions of speech fluency ratings, with average root-mean-square errors as low as 0.5. The MLR yielded a correlation coefficient of 0.87 with reference ratings at the sentence level, and of 0.93 when aggregating the data for each participant. The inclusion of an additional predictor sensitive to repetitions improved further the predictions with a correlation coefficient of 0.91 at the sentence level, and of 0.96 at the participant level. Conclusions: The algorithms used in this study can constitute a cost-effective and reliable tool for the assessment of the speech fluency of patients with aphasia in read-aloud tasks. Perspectives for the assessment of spontaneous speech are discussed.
</details>
<details>
<summary>摘要</summary>
背景：语言学和语音学师（SLP）经常依靠语言流畅性的评估来诊断或监测患有语言异常的患者。然而，这些主观方法受到了不可靠性的批评，以及严重影响临床成本。目标：本研究目的是评估一种信号处理算法在诊断语言异常患者（PWA）的语言流畅性方面的可靠性。方法与程序：招募了29名PWA和5名控制参与者，来自非营利组织和SLP网络。所有参与者在念出句子时被录音，并且使用法语版本的波士顿语言鉴别检测测试套件中的句子。三名SLP评估每句语言流畅性的五个质量水平。使用前后弧 divergence 分 segmentation 和归一化算法计算每句语言流畅性的四个自动预测器：pseudo-syllable rate、speech ratio、silent breaks 率和pseudo-syllable length 的标准差。这四个预测器最终组合成多变量回归模型（多元回归）和两种非线性模型来预测SLP评估语言流畅性的平均分数，使用了留一个说话者验证方案。结果与结论：所有模型均达到了准确的语言流畅性评估结果，平均根据值为0.5。多元回归模型在句子水平获得了0.87的相关系数，并在每名参与者的数据归一化后获得0.93的相关系数。在添加一个更多的预测器时，预测结果进一步改善，句子水平相关系数提高到0.91，每名参与者的相关系数提高到0.96。结论：这些算法可以成为诊断患有语言异常的患者语言流畅性的可靠和Cost-effective工具。对叙述语言的评估可能性进行了讨论。
</details></li>
</ul>
<hr>
<h2 id="Building-Interpretable-and-Reliable-Open-Information-Retriever-for-New-Domains-Overnight"><a href="#Building-Interpretable-and-Reliable-Open-Information-Retriever-for-New-Domains-Overnight" class="headerlink" title="Building Interpretable and Reliable Open Information Retriever for New Domains Overnight"></a>Building Interpretable and Reliable Open Information Retriever for New Domains Overnight</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04756">http://arxiv.org/abs/2308.04756</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaodong Yu, Ben Zhou, Dan Roth</li>
<li>for: 这篇论文是为了提高信息检索（IR）和知识检索（KR）的性能而写的。</li>
<li>methods: 这篇论文使用了 dense retrieval 模型，通过使用 dense vectors 来表示查询和知识段落，并通过学习字符和Semantic相似性来进行学习。</li>
<li>results: 论文提出了一个信息检索管道，该管道使用 entity&#x2F;event linking 模型和查询分解模型来更加准确地关注查询中不同的信息单元。论文表明，相比单个 dense vectors 和端到端超vision，该管道可以更好地提高 passage coverages 和denotation accuracies，并且更加可读性和可靠性。<details>
<summary>Abstract</summary>
Information retrieval (IR) or knowledge retrieval, is a critical component for many down-stream tasks such as open-domain question answering (QA). It is also very challenging, as it requires succinctness, completeness, and correctness. In recent works, dense retrieval models have achieved state-of-the-art (SOTA) performance on in-domain IR and QA benchmarks by representing queries and knowledge passages with dense vectors and learning the lexical and semantic similarity. However, using single dense vectors and end-to-end supervision are not always optimal because queries may require attention to multiple aspects and event implicit knowledge. In this work, we propose an information retrieval pipeline that uses entity/event linking model and query decomposition model to focus more accurately on different information units of the query. We show that, while being more interpretable and reliable, our proposed pipeline significantly improves passage coverages and denotation accuracies across five IR and QA benchmarks. It will be the go-to system to use for applications that need to perform IR on a new domain without much dedicated effort, because of its superior interpretability and cross-domain performance.
</details>
<details>
<summary>摘要</summary>
信息检索（IR）或知识检索是许多下游任务的关键组件，如开放领域问答（QA）。它具有精炼、完整和正确的要求。在最近的工作中，稠密检索模型已经实现了领域内IR和QA benchmark的状态最佳性（SOTA）性能，通过将查询和知识段表示为稠密矢量，并学习语义和语言相似性。但是，使用单个稠密矢量和端到端超vis�� Nobel是不 siempre最佳，因为查询可能需要对多个方面进行注意力和隐藏知识。在这种情况下，我们提议一个信息检索管道，使用实体/事件关联模型和查询分解模型，以更加准确地关注不同信息单元的查询。我们表明，相比于单一稠密矢量和端到端超vis�� Nobel，我们的提议管道可以更好地提高通过五个IR和QA benchmark的段覆盖率和涵义准确率。这将成为新领域IR应用的标准系统，因为它的超过其他解释和跨领域性能。
</details></li>
</ul>
<hr>
<h2 id="Slot-Induction-via-Pre-trained-Language-Model-Probing-and-Multi-level-Contrastive-Learning"><a href="#Slot-Induction-via-Pre-trained-Language-Model-Probing-and-Multi-level-Contrastive-Learning" class="headerlink" title="Slot Induction via Pre-trained Language Model Probing and Multi-level Contrastive Learning"></a>Slot Induction via Pre-trained Language Model Probing and Multi-level Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04712">http://arxiv.org/abs/2308.04712</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hoang H. Nguyen, Chenwei Zhang, Ye Liu, Philip S. Yu</li>
<li>for: 本研究的目的是提高对话系统中的自然语言理解能力，尤其是任务导向对话（TOD）系统中的意图检测和插槽填充任务。</li>
<li>methods: 本研究使用了无监督语言模型（PLM）探测和对比学习机制，利用无监督语义知识和句子级意图标签信号来进行槽induction任务。</li>
<li>results: 研究结果表明，使用PLM探测和对比学习机制可以有效地实现槽induction任务，并且可以与token级监督模型相似或更高的性能。此外，当扩展到新意图时，我们的SI目标还可以提高插槽填充任务的性能。<details>
<summary>Abstract</summary>
Recent advanced methods in Natural Language Understanding for Task-oriented Dialogue (TOD) Systems (e.g., intent detection and slot filling) require a large amount of annotated data to achieve competitive performance. In reality, token-level annotations (slot labels) are time-consuming and difficult to acquire. In this work, we study the Slot Induction (SI) task whose objective is to induce slot boundaries without explicit knowledge of token-level slot annotations. We propose leveraging Unsupervised Pre-trained Language Model (PLM) Probing and Contrastive Learning mechanism to exploit (1) unsupervised semantic knowledge extracted from PLM, and (2) additional sentence-level intent label signals available from TOD. Our approach is shown to be effective in SI task and capable of bridging the gaps with token-level supervised models on two NLU benchmark datasets. When generalized to emerging intents, our SI objectives also provide enhanced slot label representations, leading to improved performance on the Slot Filling tasks.
</details>
<details>
<summary>摘要</summary>
To address this challenge, we propose leveraging Unsupervised Pre-trained Language Model (PLM) Probing and Contrastive Learning mechanisms to extract unsupervised semantic knowledge from PLM and utilize additional sentence-level intent label signals available from TOD. Our approach is effective in the SI task and can bridge the gap with token-level supervised models on two NLU benchmark datasets.Moreover, our SI objectives also provide enhanced slot label representations, leading to improved performance on Slot Filling tasks. This is particularly useful when dealing with emerging intents, where traditional slot label representations may not be effective. Our approach offers a promising solution for improving the efficiency and accuracy of NLU systems in TOD applications.
</details></li>
</ul>
<hr>
<h2 id="Answering-Unseen-Questions-With-Smaller-Language-Models-Using-Rationale-Generation-and-Dense-Retrieval"><a href="#Answering-Unseen-Questions-With-Smaller-Language-Models-Using-Rationale-Generation-and-Dense-Retrieval" class="headerlink" title="Answering Unseen Questions With Smaller Language Models Using Rationale Generation and Dense Retrieval"></a>Answering Unseen Questions With Smaller Language Models Using Rationale Generation and Dense Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04711">http://arxiv.org/abs/2308.04711</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tim Hartill, Diana Benavides-Prado, Michael Witbrock, Patricia J. Riddle</li>
<li>For: The paper aims to improve the performance of smaller language models on challenging short-answer question-answering tasks by combining rationales generated by a larger language model with longer contexts created from a multi-hop dense retrieval system.* Methods: The paper proposes two methods for combining rationales and contexts: Rationale Ranking (RR) and Reasoning with Retrieval-Augmented Training Data (RATD). RR involves training a model to score both generated rationales and retrieved contexts with respect to relevance and truthfulness, and then combining the scores to derive combined contexts. RATD involves training a smaller reasoning model using retrieval-augmented training datasets to utilize relevant information from longer text sequences.* Results: The paper finds that both methods are effective, but the RATD method is more straightforward to apply and produces the strongest results in unseen settings. The proposed models also generally outperform direct prompts against much larger models in both few-shot chain-of-thought and few-shot answer-only settings.<details>
<summary>Abstract</summary>
When provided with sufficient explanatory context, smaller Language Models have been shown to exhibit strong reasoning ability on challenging short-answer question-answering tasks where the questions are unseen in training. We evaluate two methods for further improvement in this setting. Both methods focus on combining rationales generated by a larger Language Model with longer contexts created from a multi-hop dense retrieval system. The first method ($\textit{RR}$) involves training a Rationale Ranking model to score both generated rationales and retrieved contexts with respect to relevance and truthfulness. We then use the scores to derive combined contexts from both knowledge sources using a number of combinatory strategies. For the second method ($\textit{RATD}$) we train a smaller Reasoning model using retrieval-augmented training datasets such that it becomes proficient at utilising relevant information from longer text sequences that may be only partially evidential and frequently contain many irrelevant sentences. Generally we find that both methods are effective but that the $\textit{RATD}$ method is more straightforward to apply and produces the strongest results in the unseen setting on which we focus. Our single best Reasoning model using only 440 million parameters materially improves upon strong comparable prior baselines for unseen evaluation datasets (StrategyQA 58.9 $\rightarrow$ 61.7 acc., CommonsenseQA 63.6 $\rightarrow$ 72.7 acc., ARC-DA 31.6 $\rightarrow$ 52.1 F1, IIRC 25.5 $\rightarrow$ 27.3 F1) and a version utilising our prior knowledge of each type of question in selecting a context combination strategy does even better. Our proposed models also generally outperform direct prompts against much larger models (BLOOM 175B and StableVicuna 13B) in both few-shot chain-of-thought and few-shot answer-only settings.
</details>
<details>
<summary>摘要</summary>
The first method, called $\textit{RR}$, trains a Rationale Ranking model to score both generated rationales and retrieved contexts based on relevance and truthfulness. We then use the scores to combine the contexts from both knowledge sources using various strategies.The second method, called $\textit{RATD}$, trains a smaller reasoning model using retrieval-augmented training datasets. This allows the model to learn how to utilize relevant information from longer text sequences, even if they contain many irrelevant sentences.We find that both methods are effective, but the $\textit{RATD}$ method is easier to apply and produces the strongest results in unseen settings. Our best reasoning model, using only 440 million parameters, significantly improves upon strong prior baselines (StrategyQA 58.9 $\rightarrow$ 61.7 acc., CommonsenseQA 63.6 $\rightarrow$ 72.7 acc., ARC-DA 31.6 $\rightarrow$ 52.1 F1, IIRC 25.5 $\rightarrow$ 27.3 F1) and even outperforms direct prompts against larger models (BLOOM 175B and StableVicuna 13B) in both few-shot chain-of-thought and few-shot answer-only settings. Our proposed models also generally outperform direct prompts against much larger models in both settings.
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Study-of-Open-Source-Large-Language-Models-GPT-4-and-Claude-2-Multiple-Choice-Test-Taking-in-Nephrology"><a href="#A-Comparative-Study-of-Open-Source-Large-Language-Models-GPT-4-and-Claude-2-Multiple-Choice-Test-Taking-in-Nephrology" class="headerlink" title="A Comparative Study of Open-Source Large Language Models, GPT-4 and Claude 2: Multiple-Choice Test Taking in Nephrology"></a>A Comparative Study of Open-Source Large Language Models, GPT-4 and Claude 2: Multiple-Choice Test Taking in Nephrology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04709">http://arxiv.org/abs/2308.04709</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sean Wu, Michael Koo, Lesley Blum, Andy Black, Liyo Kao, Fabien Scalzo, Ira Kurtz</li>
<li>for: This study investigated the medical knowledge capability of large language models (LLMs) in the context of internal medicine subspecialty multiple-choice test-taking ability.</li>
<li>methods: The study compared the performance of several open-source LLMs (Koala 7B, Falcon 7B, Stable-Vicuna 13B, and Orca Mini 13B) to GPT-4 and Claude 2 on multiple-choice questions in the field of Nephrology.</li>
<li>results: The study found that current widely used open-sourced LLMs have poor zero-shot reasoning ability compared to GPT-4 and Claude 2, with an overall success rate of 17.1% - 25.5% in answering nephSAP multiple-choice questions correctly.<details>
<summary>Abstract</summary>
In recent years, there have been significant breakthroughs in the field of natural language processing, particularly with the development of large language models (LLMs). These LLMs have showcased remarkable capabilities on various benchmarks. In the healthcare field, the exact role LLMs and other future AI models will play remains unclear. There is a potential for these models in the future to be used as part of adaptive physician training, medical co-pilot applications, and digital patient interaction scenarios. The ability of AI models to participate in medical training and patient care will depend in part on their mastery of the knowledge content of specific medical fields. This study investigated the medical knowledge capability of LLMs, specifically in the context of internal medicine subspecialty multiple-choice test-taking ability. We compared the performance of several open-source LLMs (Koala 7B, Falcon 7B, Stable-Vicuna 13B, and Orca Mini 13B), to GPT-4 and Claude 2 on multiple-choice questions in the field of Nephrology. Nephrology was chosen as an example of a particularly conceptually complex subspecialty field within internal medicine. The study was conducted to evaluate the ability of LLM models to provide correct answers to nephSAP (Nephrology Self-Assessment Program) multiple-choice questions. The overall success of open-sourced LLMs in answering the 858 nephSAP multiple-choice questions correctly was 17.1% - 25.5%. In contrast, Claude 2 answered 54.4% of the questions correctly, whereas GPT-4 achieved a score of 73.3%. We show that current widely used open-sourced LLMs do poorly in their ability for zero-shot reasoning when compared to GPT-4 and Claude 2. The findings of this study potentially have significant implications for the future of subspecialty medical training and patient care.
</details>
<details>
<summary>摘要</summary>
近年来，自然语言处理领域有了 significativ breakthrough，特别是大语言模型（LLMs）的发展。这些 LLMs 在不同的标准准则上显示了惊人的能力。在医疗领域，未来 LLMs 和其他未来 AI 模型的具体作用仍然 unclear。这些模型在未来可能用于 adaptive physician training、医疗 copilot 应用和数字patient interaction 场景。AI 模型在医疗教育和患者护理中的参与度取决于它们在特定医学领域的知识内容的掌握程度。本研究 investigated LLMs 在内科亚专业多选题测试能力方面的医学知识能力。我们比较了多个开源 LLMs（Koala 7B、Falcon 7B、Stable-Vicuna 13B 和 Orca Mini 13B）和 GPT-4 和 Claude 2 在尼科логи亚专业多选题中的表现。尼科логи亚专业是内科中的一个特别概念复杂的亚专业领域。本研究的目的是评估 LLM 模型在 nephSAP 多选题中的正确答案能力。全部 open-sourced LLMs 在 858 个 nephSAP 多选题中正确答案的成功率为 17.1% - 25.5%。与此相比， Claude 2 答对了 54.4% 的问题，而 GPT-4 则达到了 73.3%。我们显示了当前广泛使用的 open-sourced LLMs 在零次学习时的能力远低于 GPT-4 和 Claude 2。本研究的结果可能对未来医疗专业培训和患者护理产生重要影响。
</details></li>
</ul>
<hr>
<h2 id="Generating-News-Centric-Crossword-Puzzles-As-A-Constraint-Satisfaction-and-Optimization-Problem"><a href="#Generating-News-Centric-Crossword-Puzzles-As-A-Constraint-Satisfaction-and-Optimization-Problem" class="headerlink" title="Generating News-Centric Crossword Puzzles As A Constraint Satisfaction and Optimization Problem"></a>Generating News-Centric Crossword Puzzles As A Constraint Satisfaction and Optimization Problem</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04688">http://arxiv.org/abs/2308.04688</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaito Majima, Shotaro Ishihara</li>
<li>for: 这个研究旨在创建一个自动生成新闻对应的十字WORD游戏，以增强新闻学习的教育用途。</li>
<li>methods: 这个研究使用了一个问题设定和优化问题的方法，将新闻中的词汇集成十字WORD游戏中，以增加学习效果。</li>
<li>results: 研究发现，即使仅有少量的新闻词汇，仍可以生成新闻对应的十字WORD游戏，并且可以在不同的环境下进行优化。<details>
<summary>Abstract</summary>
Crossword puzzles have traditionally served not only as entertainment but also as an educational tool that can be used to acquire vocabulary and language proficiency. One strategy to enhance the educational purpose is personalization, such as including more words on a particular topic. This paper focuses on the case of encouraging people's interest in news and proposes a framework for automatically generating news-centric crossword puzzles. We designed possible scenarios and built a prototype as a constraint satisfaction and optimization problem, that is, containing as many news-derived words as possible. Our experiments reported the generation probabilities and time required under several conditions. The results showed that news-centric crossword puzzles can be generated even with few news-derived words. We summarize the current issues and future research directions through a qualitative evaluation of the prototype. This is the first proposal that a formulation of a constraint satisfaction and optimization problem can be beneficial as an educational application.
</details>
<details>
<summary>摘要</summary>
十字WORD puzzles 不仅作为娱乐，还可以作为学习工具，帮助学习者提高词汇和语言水平。一种增强教育效果的策略是个性化，例如包含特定主题的词汇。这篇论文关注于鼓励人们对新闻的兴趣，并提出了自动生成新闻中心十字WORD puzzles 的框架。我们设计了可能的情景，建立了一个约束满足优化问题，即包含最多新闻来源的词汇。我们的实验报告了生成概率和时间，并对不同条件进行了评估。结果表明，可以使用少量新闻来源生成新闻中心十字WORD puzzles。我们通过质量评估我们的原型，总结了当前的问题和未来的研究方向。这是首次提出了一种约束满足优化问题可以作为教育应用。
</details></li>
</ul>
<hr>
<h2 id="TBIN-Modeling-Long-Textual-Behavior-Data-for-CTR-Prediction"><a href="#TBIN-Modeling-Long-Textual-Behavior-Data-for-CTR-Prediction" class="headerlink" title="TBIN: Modeling Long Textual Behavior Data for CTR Prediction"></a>TBIN: Modeling Long Textual Behavior Data for CTR Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08483">http://arxiv.org/abs/2308.08483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuwei Chen, Xiang Li, Jian Dong, Jin Zhang, Yongkang Wang, Xingxing Wang</li>
<li>for: 预测点击率 (CTR) 在推荐中发挥关键作用，因此启发自最近崛起的语言模型 (LM) 的工作，通过将用户行为数据组织成文本格式，使用 LM 理解用户在semantic水平上的兴趣。</li>
<li>methods: 本文提出了一种 Textual Behavior-based Interest Chunking Network (TBIN)，该方法结合了有效的本地相关哈希算法和偏移 chunk-based self-attention，以解决上述限制。</li>
<li>results: 实验结果表明，TBIN 可以有效地预测 CTR，并且在实际食物推荐平台上进行了在线实验，得到了较高的预测精度。<details>
<summary>Abstract</summary>
Click-through rate (CTR) prediction plays a pivotal role in the success of recommendations. Inspired by the recent thriving of language models (LMs), a surge of works improve prediction by organizing user behavior data in a \textbf{textual} format and using LMs to understand user interest at a semantic level. While promising, these works have to truncate the textual data to reduce the quadratic computational overhead of self-attention in LMs. However, it has been studied that long user behavior data can significantly benefit CTR prediction. In addition, these works typically condense user diverse interests into a single feature vector, which hinders the expressive capability of the model. In this paper, we propose a \textbf{T}extual \textbf{B}ehavior-based \textbf{I}nterest Chunking \textbf{N}etwork (TBIN), which tackles the above limitations by combining an efficient locality-sensitive hashing algorithm and a shifted chunk-based self-attention. The resulting user diverse interests are dynamically activated, producing user interest representation towards the target item. Finally, the results of both offline and online experiments on real-world food recommendation platform demonstrate the effectiveness of TBIN.
</details>
<details>
<summary>摘要</summary>
点击率（CTR）预测在推荐中扮演重要的角色。鉴于最近崛起的语言模型（LM），一些工作将用户行为数据 format 为文本，并使用 LM 理解用户的 semantic 价值。 Although promising, these works have to truncate the textual data to reduce the quadratic computational overhead of self-attention in LMs. However, it has been studied that long user behavior data can significantly benefit CTR prediction. In addition, these works typically condense user diverse interests into a single feature vector, which hinders the expressive capability of the model.In this paper, we propose a 文本行为基因网络（TBIN）， which tackles the above limitations by combining an efficient locality-sensitive hashing algorithm and a shifted chunk-based self-attention. The resulting user diverse interests are dynamically activated, producing user interest representation towards the target item. Finally, the results of both offline and online experiments on real-world food recommendation platform demonstrate the effectiveness of TBIN.
</details></li>
</ul>
<hr>
<h2 id="Sudowoodo-a-Chinese-Lyric-Imitation-System-with-Source-Lyrics"><a href="#Sudowoodo-a-Chinese-Lyric-Imitation-System-with-Source-Lyrics" class="headerlink" title="Sudowoodo: a Chinese Lyric Imitation System with Source Lyrics"></a>Sudowoodo: a Chinese Lyric Imitation System with Source Lyrics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04665">http://arxiv.org/abs/2308.04665</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongzhu Chang, Rongsheng Zhang, Lin Jiang, Qihang Chen, Le Zhang, Jiashu Pu</li>
<li>for: 这个论文的目的是提出一种基于中文歌词模型的中文歌词模仿系统（Sudowoodo），以便通过模仿已有的歌词来生成新的歌词。</li>
<li>methods: 这个论文使用了一种新的框架，该框架基于中文歌词模型，并使用了一些 keyword-based lyrics 模型来构建一个平行训练集。然后，该论文使用了一种新的 lyrics imitation 模型来训练这个平行训练集。最后，该论文使用了一种 post-processing 模块来筛选和排序生成的歌词，以选择最高质量的歌词。</li>
<li>results: 该论文的实验结果表明，使用该新的框架和模型可以更好地进行中文歌词模仿。此外，该论文还提供了一个 demo 视频，详细介绍了该系统的使用和应用。<details>
<summary>Abstract</summary>
Lyrics generation is a well-known application in natural language generation research, with several previous studies focusing on generating accurate lyrics using precise control such as keywords, rhymes, etc. However, lyrics imitation, which involves writing new lyrics by imitating the style and content of the source lyrics, remains a challenging task due to the lack of a parallel corpus. In this paper, we introduce \textbf{\textit{Sudowoodo}, a Chinese lyrics imitation system that can generate new lyrics based on the text of source lyrics. To address the issue of lacking a parallel training corpus for lyrics imitation, we propose a novel framework to construct a parallel corpus based on a keyword-based lyrics model from source lyrics. Then the pairs \textit{(new lyrics, source lyrics)} are used to train the lyrics imitation model. During the inference process, we utilize a post-processing module to filter and rank the generated lyrics, selecting the highest-quality ones. We incorporated audio information and aligned the lyrics with the audio to form the songs as a bonus. The human evaluation results show that our framework can perform better lyric imitation. Meanwhile, the \textit{Sudowoodo} system and demo video of the system is available at \href{https://Sudowoodo.apps-hp.danlu.netease.com/}{Sudowoodo} and \href{https://youtu.be/u5BBT_j1L5M}{https://youtu.be/u5BBT\_j1L5M}.
</details>
<details>
<summary>摘要</summary>
文章摘要：本文介绍了一种新的中文歌词模仿系统——《嗨嗨》（Sudowoodo），可以基于源歌词文本生成新歌词。由于缺乏平行训练集，歌词模仿 зада务一直是一个挑战。我们提出了一种新的框架，利用关键词基于的歌词模型从源歌词中构建平行训练集。然后，我们使用这些对（新歌词、源歌词）进行训练歌词模仿模型。在推理过程中，我们利用一个后处理模块来筛选和排序生成的歌词，选择最高质量的歌词。此外，我们还 incorporated 音频信息并将歌词与音频进行对应，形成了完整的歌曲。人工评估结果显示，我们的框架可以实现更好的歌词模仿。同时，《嗨嗨》系统和demo视频也可以在 \href{https://Sudowoodo.apps-hp.danlu.netease.com/}{Sudowoodo} 和 \href{https://youtu.be/u5BBT_j1L5M}{https://youtu.be/u5BBT\_j1L5M} 上查看。
</details></li>
</ul>
<hr>
<h2 id="Cross-Lingual-Constituency-Parsing-for-Middle-High-German-A-Delexicalized-Approach"><a href="#Cross-Lingual-Constituency-Parsing-for-Middle-High-German-A-Delexicalized-Approach" class="headerlink" title="Cross-Lingual Constituency Parsing for Middle High German: A Delexicalized Approach"></a>Cross-Lingual Constituency Parsing for Middle High German: A Delexicalized Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04645">http://arxiv.org/abs/2308.04645</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ercong Nie, Helmut Schmid, Hinrich Schütze</li>
<li>for: 本研究旨在建立一个自动 syntax 分析系统 для $\mathbf{M}$iddle $\mathbf{H}$igh $\mathbf{G}$erman $\mathbf{MHG}$，但是 Due to the lack of annotated parse data, 训练一个自动 syntax 分析系统是一个困难的任务。</li>
<li>methods: 我们运用了 cross-lingual transfer 技术，使用 MG parse  dataset 进行训练，并通过 delexicalization 方法将 MG  parse 结果转换为 MHG  parse 结果。</li>
<li>results: 我们的 delexicalized constituency parser 在 MHG 测试集上表现出色，实现了 F1 分数 67.3%，比最佳 zero-shot cross-lingual baseline 高出 28.6% 点。这个鼓舞人心的结果说明了自动 syntax 分析在其他具有相似挑战的古语言中的实际可行性。<details>
<summary>Abstract</summary>
Constituency parsing plays a fundamental role in advancing natural language processing (NLP) tasks. However, training an automatic syntactic analysis system for ancient languages solely relying on annotated parse data is a formidable task due to the inherent challenges in building treebanks for such languages. It demands extensive linguistic expertise, leading to a scarcity of available resources. To overcome this hurdle, cross-lingual transfer techniques which require minimal or even no annotated data for low-resource target languages offer a promising solution. In this study, we focus on building a constituency parser for $\mathbf{M}$iddle $\mathbf{H}$igh $\mathbf{G}$erman $\mathbf{MHG}$ under realistic conditions, where no annotated MHG treebank is available for training. In our approach, we leverage the linguistic continuity and structural similarity between MHG and $\mathbf{M}$odern $\mathbf{G}$erman $\mathbf{MG}$, along with the abundance of MG treebank resources. Specifically, by employing the $\mathit{delexicalization}$ method, we train a constituency parser on MG parse datasets and perform cross-lingual transfer to MHG parsing. Our delexicalized constituency parser demonstrates remarkable performance on the MHG test set, achieving an F1-score of 67.3%. It outperforms the best zero-shot cross-lingual baseline by a margin of 28.6% points. These encouraging results underscore the practicality and potential for automatic syntactic analysis in other ancient languages that face similar challenges as MHG.
</details>
<details>
<summary>摘要</summary>
古代语言处理自然语言处理（NLP）任务的基础角色。然而，为古代语言solely靠注释分析数据自动生成语法分析系统是一项困难的任务，因为这些语言的语法特征往往具有独特的挑战。这需要广泛的语言专业知识，从而导致了资源的缺乏。为了突破这个障碍，跨语言传递技术，即不需要或只需要少量注释数据的低资源目标语言中的技术，提供了一个有前途的解决方案。在这种研究中，我们关注于在实际条件下构建一个中世纪高德语（MHG）的分析器，无需注释MHG语法数据进行训练。我们利用中世纪高德语和现代德语之间的语言相似性和结构相似性，同时利用现代德语语法数据资源的充足。具体来说，我们采用了delexicalization方法，通过在MG语法数据集上训练分析器，并对MHG语法进行跨语言传递。我们的delexicalized分析器在MHG测试集上显示了Remarkable性能，达到了67.3%的F1分数。它超过了零零假设的跨语言基线值28.6个百分点。这些鼓舞人心的结果证明了自动语法分析在其他面临类似挑战的古代语言中的实用性和潜力。
</details></li>
</ul>
<hr>
<h2 id="Single-Sentence-Reader-A-Novel-Approach-for-Addressing-Answer-Position-Bias"><a href="#Single-Sentence-Reader-A-Novel-Approach-for-Addressing-Answer-Position-Bias" class="headerlink" title="Single-Sentence Reader: A Novel Approach for Addressing Answer Position Bias"></a>Single-Sentence Reader: A Novel Approach for Addressing Answer Position Bias</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04566">http://arxiv.org/abs/2308.04566</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sonqt/single-sentence-reader">https://github.com/sonqt/single-sentence-reader</a></li>
<li>paper_authors: Son Quoc Tran, Matt Kretchmar</li>
<li>for: 本研究旨在解决机器阅读理解（MRC）模型借助于偶极性相关性（也称为数据集偏见或笔记痕），从而提高MRC模型的 robustness。</li>
<li>methods: 本研究提出了一种新的单句读者方法，以解决答案位置偏见问题。六种不同的模型被实现，并进行了严格的性能分析。</li>
<li>results: 实验结果表明，提案的单句读者方法可以nearly match conventional training sets上模型的性能，证明其有效性。<details>
<summary>Abstract</summary>
Machine Reading Comprehension (MRC) models tend to take advantage of spurious correlations (also known as dataset bias or annotation artifacts in the research community). Consequently, these models may perform the MRC task without fully comprehending the given context and question, which is undesirable since it may result in low robustness against distribution shift. This paper delves into the concept of answer-position bias, where a significant percentage of training questions have answers located solely in the first sentence of the context. We propose a Single-Sentence Reader as a new approach for addressing answer position bias in MRC. We implement this approach using six different models and thoroughly analyze their performance. Remarkably, our proposed Single-Sentence Readers achieve results that nearly match those of models trained on conventional training sets, proving their effectiveness. Our study also discusses several challenges our Single-Sentence Readers encounter and proposes a potential solution.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Ahead-of-the-Text-Leveraging-Entity-Preposition-for-Financial-Relation-Extraction"><a href="#Ahead-of-the-Text-Leveraging-Entity-Preposition-for-Financial-Relation-Extraction" class="headerlink" title="Ahead of the Text: Leveraging Entity Preposition for Financial Relation Extraction"></a>Ahead of the Text: Leveraging Entity Preposition for Financial Relation Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04534">http://arxiv.org/abs/2308.04534</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefan Pasch, Dimitrios Petridis</li>
<li>for: 这篇论文是为了解决金融实体关系标注任务的，使用了REFind数据集。</li>
<li>methods: 该方法包括将提供的实体插入文本中相应位置，然后使用基于变换器的语言模型roberta-large进行文本分类，最后进行后处理来处理模型生成的不可能预测。</li>
<li>results: 该方法在比赛的公共排名榜上获得了第一名。<details>
<summary>Abstract</summary>
In the context of the ACM KDF-SIGIR 2023 competition, we undertook an entity relation task on a dataset of financial entity relations called REFind. Our top-performing solution involved a multi-step approach. Initially, we inserted the provided entities at their corresponding locations within the text. Subsequently, we fine-tuned the transformer-based language model roberta-large for text classification by utilizing a labeled training set to predict the entity relations. Lastly, we implemented a post-processing phase to identify and handle improbable predictions generated by the model. As a result of our methodology, we achieved the 1st place ranking on the competition's public leaderboard.
</details>
<details>
<summary>摘要</summary>
在ACM KDF-SIGIR 2023比赛的Entity Relation任务中，我们采用了一种多步方法。首先，我们将提供的实体 inserting到文本中相应的位置。然后，我们使用abeled训练集来使transformer基于语言模型roberta-large进行文本分类的精度。最后，我们实施了一个后处理阶段，以便通过模型生成的不可能预测来处理。因此，我们的方法在比赛的公共排名板上获得了第一名。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-Disentanglement-and-Fusion-on-Modality-and-Context-in-Conversational-Multimodal-Emotion-Recognition"><a href="#Revisiting-Disentanglement-and-Fusion-on-Modality-and-Context-in-Conversational-Multimodal-Emotion-Recognition" class="headerlink" title="Revisiting Disentanglement and Fusion on Modality and Context in Conversational Multimodal Emotion Recognition"></a>Revisiting Disentanglement and Fusion on Modality and Context in Conversational Multimodal Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04502">http://arxiv.org/abs/2308.04502</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bobo Li, Hao Fei, Lizi Liao, Yu Zhao, Chong Teng, Tat-Seng Chua, Donghong Ji, Fei Li</li>
<li>for: 本研究targets at further improving the performance of multimodal emotion recognition in conversation (MM-ERC) tasks, by properly modeling the multimodal feature and conversational context.</li>
<li>methods: 该研究提出了一种 dual-level disentanglement mechanism (DDM)和一种 contribution-aware fusion mechanism (CFM)，以及一种 context refusion mechanism (CRM)，用于在feature disentanglement和feature fusion stages中 simultanously modeling the multimodal feature and conversational context.</li>
<li>results: 在两个公共MM-ERC数据集上，该系统实现了新的状态OF-THE-ART性能，并且进行了进一步的分析，表明所提出的方法可以充分利用多 modal和Contextual features，并且具有推广到更广泛的 conversational multimodal任务的潜在潜力。<details>
<summary>Abstract</summary>
It has been a hot research topic to enable machines to understand human emotions in multimodal contexts under dialogue scenarios, which is tasked with multimodal emotion analysis in conversation (MM-ERC). MM-ERC has received consistent attention in recent years, where a diverse range of methods has been proposed for securing better task performance. Most existing works treat MM-ERC as a standard multimodal classification problem and perform multimodal feature disentanglement and fusion for maximizing feature utility. Yet after revisiting the characteristic of MM-ERC, we argue that both the feature multimodality and conversational contextualization should be properly modeled simultaneously during the feature disentanglement and fusion steps. In this work, we target further pushing the task performance by taking full consideration of the above insights. On the one hand, during feature disentanglement, based on the contrastive learning technique, we devise a Dual-level Disentanglement Mechanism (DDM) to decouple the features into both the modality space and utterance space. On the other hand, during the feature fusion stage, we propose a Contribution-aware Fusion Mechanism (CFM) and a Context Refusion Mechanism (CRM) for multimodal and context integration, respectively. They together schedule the proper integrations of multimodal and context features. Specifically, CFM explicitly manages the multimodal feature contributions dynamically, while CRM flexibly coordinates the introduction of dialogue contexts. On two public MM-ERC datasets, our system achieves new state-of-the-art performance consistently. Further analyses demonstrate that all our proposed mechanisms greatly facilitate the MM-ERC task by making full use of the multimodal and context features adaptively. Note that our proposed methods have the great potential to facilitate a broader range of other conversational multimodal tasks.
</details>
<details>
<summary>摘要</summary>
研究团队已经很长时间来关注人工智能机器人理解人类情感的问题，即在对话场景下的多模态情感分析（MM-ERC）。这个问题在过去几年内得到了不间断的关注，而且提出了各种方法来提高任务性能。大多数现有方法都将 MM-ERC 视为标准的多模态分类问题，然后进行多模态特征分离和融合以最大化特征用用。然而，我们在再次检视 MM-ERC 的特点时，发现需要同时模型多模态特征和对话上下文。在这种情况下，我们提出了一种新的方法，以提高任务性能。在特征分离阶段，我们根据对比学习技术提出了双级分离机制（DDM），以分离特征到模态空间和话语空间两个级别。在特征融合阶段，我们提出了参与度感知融合机制（CFM）和上下文融合机制（CRM），用于多模态和上下文集成。CFM 可以动态管理多模态特征的贡献，而 CRM 可以flexibly 协调对话上下文的引入。在两个公共 MM-ERC 数据集上，我们的系统在新的状态均达到了领先的性能。进一步分析表明，我们的所有提出的机制都可以帮助 MM-ERC 任务，使得机器人可以更好地理解人类情感。此外，我们的方法还有潜在的推广性，可以推动更多的对话多模态任务的进步。
</details></li>
</ul>
<hr>
<h2 id="DialogRE-C-An-Extension-of-DialogRE-to-Investigate-How-Much-Coreference-Helps-Relation-Extraction-in-Dialogs"><a href="#DialogRE-C-An-Extension-of-DialogRE-to-Investigate-How-Much-Coreference-Helps-Relation-Extraction-in-Dialogs" class="headerlink" title="DialogRE^C+: An Extension of DialogRE to Investigate How Much Coreference Helps Relation Extraction in Dialogs"></a>DialogRE^C+: An Extension of DialogRE to Investigate How Much Coreference Helps Relation Extraction in Dialogs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04498">http://arxiv.org/abs/2308.04498</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/palm2333/dialogre_coreference">https://github.com/palm2333/dialogre_coreference</a></li>
<li>paper_authors: Yiyun Xiong, Mengwei Dai, Fei Li, Hao Fei, Bobo Li, Shengqiong Wu, Donghong Ji, Chong Teng</li>
<li>For: This paper introduces a new benchmark dataset called DialogRE^C+, which incorporates coreference resolution into the dialogue relation extraction (DRE) task.* Methods: The paper manually annotates a total of 5,068 coreference chains over 36,369 argument mentions based on existing DialogRE data, and develops four coreference-enhanced graph-based DRE models.* Results: The paper evaluates the effect of automatically extracted coreference chains and demonstrates the practicality of the DialogRE^C+ dataset for other domains and tasks.<details>
<summary>Abstract</summary>
Dialogue relation extraction (DRE) that identifies the relations between argument pairs in dialogue text, suffers much from the frequent occurrence of personal pronouns, or entity and speaker coreference. This work introduces a new benchmark dataset DialogRE^C+, introducing coreference resolution into the DRE scenario. With the aid of high-quality coreference knowledge, the reasoning of argument relations is expected to be enhanced. In DialogRE^C+ dataset, we manually annotate total 5,068 coreference chains over 36,369 argument mentions based on the existing DialogRE data, where four different coreference chain types namely speaker chain, person chain, location chain and organization chain are explicitly marked. We further develop 4 coreference-enhanced graph-based DRE models, which learn effective coreference representations for improving the DRE task. We also train a coreference resolution model based on our annotations and evaluate the effect of automatically extracted coreference chains demonstrating the practicality of our dataset and its potential to other domains and tasks.
</details>
<details>
<summary>摘要</summary>
对话关系提取（DRE）在对话文本中识别对话参与者之间的关系，受到个人 pronouns 和实体、发言人核心Reference的频繁出现困扰。这项工作提出了一个新的标准数据集 DialogRE^C+，将核心 Reference resolution 引入 DRE 场景中。通过高质量核心 Reference 知识的帮助，我们预期可以提高对话关系的逻辑推理。在 DialogRE^C+ 数据集中，我们 manually annotated 总共 5,068 个核心 Reference chain  sobre 36,369 个 argue mention，其中包括 speaker chain、person chain、location chain 和 organization chain 四种不同类型的核心 Reference chain。我们还开发了 4 种核心 Reference 增强的图基于 DRE 模型，这些模型学习了有效的核心 Reference 表示，以提高 DRE 任务的性能。此外，我们还训练了基于我们的标注的核心 Reference 解析模型，并评估了自动提取的核心 Reference chain 的实用性， thereby demonstrating the practicality of our dataset and its potential to other domains and tasks.
</details></li>
</ul>
<hr>
<h2 id="A-Bi-directional-Multi-hop-Inference-Model-for-Joint-Dialog-Sentiment-Classification-and-Act-Recognition"><a href="#A-Bi-directional-Multi-hop-Inference-Model-for-Joint-Dialog-Sentiment-Classification-and-Act-Recognition" class="headerlink" title="A Bi-directional Multi-hop Inference Model for Joint Dialog Sentiment Classification and Act Recognition"></a>A Bi-directional Multi-hop Inference Model for Joint Dialog Sentiment Classification and Act Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04424">http://arxiv.org/abs/2308.04424</a></li>
<li>repo_url: None</li>
<li>paper_authors: Li Zheng, Fei Li, Yuyang Chai, Chong Teng, Donghong Ji</li>
<li>for: 这个论文的目的是提出一种新的对话情感分类（DSC）和行为识别（DAR）任务的解决方案，以同时预测每个对话中的情感标签和行为标签。</li>
<li>methods: 该方法利用了一种特征选择网络和双向多跳推理网络，以逐步提取和融合对话中的丰富情感和行为 clue。此外，该方法还使用了对比学习和双向学习来直接模型情感和行为标签之间的相关性。</li>
<li>results: 对两个常用的数据集进行了实验，结果显示，与州立标准比较，该模型在DAR和DSC任务上的性能提高至少2.6%和1.4%。此外，该模型不仅提高了性能，还增强了对这两个任务的解释性。<details>
<summary>Abstract</summary>
The joint task of Dialog Sentiment Classification (DSC) and Act Recognition (DAR) aims to predict the sentiment label and act label for each utterance in a dialog simultaneously. However, current methods encode the dialog context in only one direction, which limits their ability to thoroughly comprehend the context. Moreover, these methods overlook the explicit correlations between sentiment and act labels, which leads to an insufficient ability to capture rich sentiment and act clues and hinders effective and accurate reasoning. To address these issues, we propose a Bi-directional Multi-hop Inference Model (BMIM) that leverages a feature selection network and a bi-directional multi-hop inference network to iteratively extract and integrate rich sentiment and act clues in a bi-directional manner. We also employ contrastive learning and dual learning to explicitly model the correlations of sentiment and act labels. Our experiments on two widely-used datasets show that BMIM outperforms state-of-the-art baselines by at least 2.6% on F1 score in DAR and 1.4% on F1 score in DSC. Additionally, Our proposed model not only improves the performance but also enhances the interpretability of the joint sentiment and act prediction task.
</details>
<details>
<summary>摘要</summary>
joint任务对话情感分类（DSC）和行为识别（DAR）的目标是同时预测每句话的情感标签和行为标签。然而，现有方法只是一个方向地编码对话上下文，这限制了它们对对话上下文的理解能力。另外，这些方法忽略了情感和行为标签之间的直接相关性，这会导致对 sentiment和 act 标签的捕捉不充分，从而降低对这两个任务的准确性和有效性。为了解决这些问题，我们提议一种双向多跳推理模型（BMIM），利用特征选择网络和双向多跳推理网络来顺序提取和融合rich的情感和行为 clue。我们还使用对比学习和双向学习来直接模型情感和行为标签之间的相关性。我们的实验结果表明，BMIM在两个广泛使用的 dataset 上表现至少比状态ixelbaselines 2.6%的F1分数提高，并且我们的提出的模型不仅改善性能，还提高了对这两个任务的合理性。
</details></li>
</ul>
<hr>
<h2 id="Character-level-NMT-and-language-similarity"><a href="#Character-level-NMT-and-language-similarity" class="headerlink" title="Character-level NMT and language similarity"></a>Character-level NMT and language similarity</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04398">http://arxiv.org/abs/2308.04398</a></li>
<li>repo_url: None</li>
<li>paper_authors: Josef Jon, Ondřej Bojar</li>
<li>for: 这个论文是为了研究使用Transformer架构进行字符级别的人工智能翻译，以及不同语言相似度和训练数据大小对翻译的影响。</li>
<li>methods: 这个论文使用了字符级别的Neural Machine Translation（NMT）模型，并使用了Transformer架构。</li>
<li>results: 研究发现，在相似语言之间的翻译benefits于字符级别输入分 segmentation，而在不相似语言之间，字符级别vanilla Transformer-base经常落后于字符级别分 segmentation。研究也证实了之前的发现，可以通过 fine-tuning已经训练过的字符级别模型来逼近这些模型的性能。<details>
<summary>Abstract</summary>
We explore the effectiveness of character-level neural machine translation using Transformer architecture for various levels of language similarity and size of the training dataset on translation between Czech and Croatian, German, Hungarian, Slovak, and Spanish. We evaluate the models using automatic MT metrics and show that translation between similar languages benefits from character-level input segmentation, while for less related languages, character-level vanilla Transformer-base often lags behind subword-level segmentation. We confirm previous findings that it is possible to close the gap by finetuning the already trained subword-level models to character-level.
</details>
<details>
<summary>摘要</summary>
我们研究使用Transformer架构进行字符级别人工智能翻译的效果，在捷克和克罗地亚、德国、匈牙利、斯洛伐克和西班牙之间的翻译中进行了不同语言相似性和训练数据大小的研究。我们使用自动MT指标进行评估，并发现在相似语言之间的翻译中，字符级别输入分 segmentation 带来了好处，而在较不相似的语言中，字符级凯旋Transformer-base 经常落后于字符级别分 segmentation。我们证实了之前的发现，可以通过 fine-tuning 已经训练过的字符级别模型来减变这个差距。
</details></li>
</ul>
<hr>
<h2 id="Learning-Evaluation-Models-from-Large-Language-Models-for-Sequence-Generation"><a href="#Learning-Evaluation-Models-from-Large-Language-Models-for-Sequence-Generation" class="headerlink" title="Learning Evaluation Models from Large Language Models for Sequence Generation"></a>Learning Evaluation Models from Large Language Models for Sequence Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04386">http://arxiv.org/abs/2308.04386</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/djdprogramming/adfa2">https://github.com/djdprogramming/adfa2</a></li>
<li>paper_authors: Chenglong Wang, Hang Zhou, Kaiyan Chang, Tongran Liu, Chunliang Zhang, Quan Du, Tong Xiao, Jingbo Zhu</li>
<li>for: 这篇论文目的是将大语言模型的评估能力转移到较轻量级的语言模型中，以解决大语言模型的 computation challenge。</li>
<li>methods: 这篇论文提出了一个称为ECT的评估能力转移方法，通过将评估模型从LLMs学习到较轻量级的语言模型中，以提高sequence generation模型的评估能力。</li>
<li>results: 实验结果显示，使用ECT学习评估模型后，sequence generation模型的生成结果对于常用的 метри和ChatGPT进行评估都有所提高。<details>
<summary>Abstract</summary>
Large language models achieve state-of-the-art performance on sequence generation evaluation, but typically have a large number of parameters. This is a computational challenge as presented by applying their evaluation capability at scale. To overcome the challenge, in this paper, we propose \textbf{ECT}, an \textbf{e}valuation \textbf{c}apability \textbf{t}ransfer method, to transfer the evaluation capability from LLMs to relatively lightweight language models. Based on the proposed ECT, we learn various evaluation models from ChatGPT, and employ them as reward models to improve sequence generation models via reinforcement learning and reranking approaches. Experimental results on machine translation, text style transfer, and summarization tasks demonstrate the effectiveness of our ECT. Notably, applying the learned evaluation models to sequence generation models results in better generated sequences as evaluated by commonly used metrics and ChatGPT.
</details>
<details>
<summary>摘要</summary>
大型语言模型在序列生成评价评价中表现出色，但它们通常具有较多参数。这是一个计算挑战，因为在应用它们的评价能力的大规模应用中，需要大量的计算资源。为解决这个挑战，在这篇论文中，我们提出了ECT（评价能力传输方法），用于将大型语言模型中的评价能力传输到较轻量级的语言模型中。基于ECT，我们从ChatGPT中学习了多种评价模型，并使其作为激励学习和重新排序的奖励模型。实验结果表明，ECT可以有效地提高序列生成模型的性能，并且应用学习的评价模型可以根据常用的指标和ChatGPT进行评价。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/09/cs.CL_2023_08_09/" data-id="clogyj8w8008t7cra075tg55h" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/09/cs.LG_2023_08_09/" class="article-date">
  <time datetime="2023-08-09T10:00:00.000Z" itemprop="datePublished">2023-08-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/09/cs.LG_2023_08_09/">cs.LG - 2023-08-09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Density-Crop-guided-Semi-supervised-Object-Detection-in-Aerial-Images"><a href="#Density-Crop-guided-Semi-supervised-Object-Detection-in-Aerial-Images" class="headerlink" title="Density Crop-guided Semi-supervised Object Detection in Aerial Images"></a>Density Crop-guided Semi-supervised Object Detection in Aerial Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05032">http://arxiv.org/abs/2308.05032</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/akhilpm/dronessod">https://github.com/akhilpm/dronessod</a></li>
<li>paper_authors: Akhil Meethal, Eric Granger, Marco Pedersoli</li>
<li>for: 这篇论文是针对现代物体检测器的训练问题进行研究，具体是关于如何对高分辨率的天空图像进行物体检测，并且处理小型物体的分布问题。</li>
<li>methods: 这篇论文提出了一种基于密度割载的半指导 semi-supervised 物体检测方法，通过在训练过程中使用内部割载来增强小型物体的检测，并且在测试过程中使用密度割载来结合输入图像和内部割载的检测结果，以提高检测精度。</li>
<li>results: 这篇论文的实验结果显示，与基本的mean-teacher方法相比，密度割载导向的半指导 semi-supervised 物体检测方法可以提高检测精度超过2%，特别是 для小型物体。<details>
<summary>Abstract</summary>
One of the important bottlenecks in training modern object detectors is the need for labeled images where bounding box annotations have to be produced for each object present in the image. This bottleneck is further exacerbated in aerial images where the annotators have to label small objects often distributed in clusters on high-resolution images. In recent days, the mean-teacher approach trained with pseudo-labels and weak-strong augmentation consistency is gaining popularity for semi-supervised object detection. However, a direct adaptation of such semi-supervised detectors for aerial images where small clustered objects are often present, might not lead to optimal results. In this paper, we propose a density crop-guided semi-supervised detector that identifies the cluster of small objects during training and also exploits them to improve performance at inference. During training, image crops of clusters identified from labeled and unlabeled images are used to augment the training set, which in turn increases the chance of detecting small objects and creating good pseudo-labels for small objects on the unlabeled images. During inference, the detector is not only able to detect the objects of interest but also regions with a high density of small objects (density crops) so that detections from the input image and detections from image crops are combined, resulting in an overall more accurate object prediction, especially for small objects. Empirical studies on the popular benchmarks of VisDrone and DOTA datasets show the effectiveness of our density crop-guided semi-supervised detector with an average improvement of more than 2\% over the basic mean-teacher method in COCO style AP. Our code is available at: https://github.com/akhilpm/DroneSSOD.
</details>
<details>
<summary>摘要</summary>
一个重要的瓶颈在现代物体探测器的训练中是需要标注过的图像，其中需要为每个图像中的每个物体生成矩形框注释。这个瓶颈在空中图像中更加突出，因为注释员需要为高分辨率图像中的小对象进行标注。在最近几天，使用pseudo-labels和弱强协同稳定的mean-teacher方法在 semi-supervised 物体探测中得到了广泛的应用。然而，直接适用这种 semi-supervised 探测器于空中图像中，可能并不会导致最佳的结果。在这篇论文中，我们提出了一种基于密度评估的 semi-supervised 探测器，可以在训练时对小对象进行识别，并在探测时利用这些小对象来提高检测的准确性。在训练时，我们使用标注和无标注图像中的群集来增强训练集，从而提高小对象的检测和生成 Pseudo-labels 的可能性。在探测时，探测器不仅能够检测输入图像中的对象，还能够检测高密度的小对象区域（密度评估），从而将输入图像和密度评估中的检测结果组合起来，得到更加准确的对象预测，特别是对小对象。我们的实验结果表明，我们的密度评估基于 semi-supervised 探测器在 COCO 风格的 AP 中超过了基本 mean-teacher 方法的平均提升 más than 2%。我们的代码可以在：https://github.com/akhilpm/DroneSSOD 中找到。
</details></li>
</ul>
<hr>
<h2 id="An-Empirical-Study-on-Using-Large-Language-Models-to-Analyze-Software-Supply-Chain-Security-Failures"><a href="#An-Empirical-Study-on-Using-Large-Language-Models-to-Analyze-Software-Supply-Chain-Security-Failures" class="headerlink" title="An Empirical Study on Using Large Language Models to Analyze Software Supply Chain Security Failures"></a>An Empirical Study on Using Large Language Models to Analyze Software Supply Chain Security Failures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04898">http://arxiv.org/abs/2308.04898</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tanmay Singla, Dharun Anandayuvaraj, Kelechi G. Kalu, Taylor R. Schorlemmer, James C. Davis</li>
<li>for: 本研究旨在使用自然语言处理技术（NLP）和大型语言模型（LLM）来分析历史上的软件供应链安全攻击。</li>
<li>methods: 本研究使用GPT 3.5和Bard两种大型语言模型来自动分析69起软件供应链安全攻击的报告。研究人员 разрабоtaced四个维度来分类这些攻击：类型的攻击、意图、性质和影响。</li>
<li>results: 研究发现，当源文章详细 enough以至于得到人工分析者的一致时，LLMs可以有效地characterize软件供应链攻击。然而，LLMs current不能完全取代人工分析者，未来的工作可以进一步提高LLM的表现在这个领域，并对更广泛的文章和攻击进行研究。<details>
<summary>Abstract</summary>
As we increasingly depend on software systems, the consequences of breaches in the software supply chain become more severe. High-profile cyber attacks like those on SolarWinds and ShadowHammer have resulted in significant financial and data losses, underlining the need for stronger cybersecurity. One way to prevent future breaches is by studying past failures. However, traditional methods of analyzing these failures require manually reading and summarizing reports about them. Automated support could reduce costs and allow analysis of more failures. Natural Language Processing (NLP) techniques such as Large Language Models (LLMs) could be leveraged to assist the analysis of failures. In this study, we assessed the ability of Large Language Models (LLMs) to analyze historical software supply chain breaches. We used LLMs to replicate the manual analysis of 69 software supply chain security failures performed by members of the Cloud Native Computing Foundation (CNCF). We developed prompts for LLMs to categorize these by four dimensions: type of compromise, intent, nature, and impact. GPT 3.5s categorizations had an average accuracy of 68% and Bard had an accuracy of 58% over these dimensions. We report that LLMs effectively characterize software supply chain failures when the source articles are detailed enough for consensus among manual analysts, but cannot yet replace human analysts. Future work can improve LLM performance in this context, and study a broader range of articles and failures.
</details>
<details>
<summary>摘要</summary>
随着我们对软件系统的依赖程度越来越高，软件供应链攻击的后果也变得更加严重。如 solsWinds和ShadowHammer等高 Profile cyber attack 的事件，已经导致了 significannot financial和data losses，这也高亮了更强的cybersecurity的需求。一种方法来防止未来的攻击是通过研究过去的失败来。然而，传统的失败分析方法需要手动阅读和总结报告。自动支持可以降低成本和允许更多的失败分析。自然语言处理（NLP）技术，如大语言模型（LLMs），可以帮助失败分析。在这项研究中，我们评估了LLMs是否可以分析历史软件供应链安全失败。我们使用LLMs来复制人工分析69例软件供应链安全失败，这些失败由Cloud Native Computing Foundation（CNCF）的成员进行了手动分析。我们为LLMs设计了四个维度来分类这些失败：类型攻击、意图、性质和影响。GPT 3.5的分类精度为68%，而Bard的精度为58%。我们发现LLMs可以有效地描述软件供应链失败，但是只有当源文章具有足够细节时，才能达到人工分析者之间的一致。未来的工作可以提高LLM的性能在这种情况下，并研究更广泛的文章和失败。
</details></li>
</ul>
<hr>
<h2 id="Do-Diffusion-Models-Suffer-Error-Propagation-Theoretical-Analysis-and-Consistency-Regularization"><a href="#Do-Diffusion-Models-Suffer-Error-Propagation-Theoretical-Analysis-and-Consistency-Regularization" class="headerlink" title="Do Diffusion Models Suffer Error Propagation? Theoretical Analysis and Consistency Regularization"></a>Do Diffusion Models Suffer Error Propagation? Theoretical Analysis and Consistency Regularization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05021">http://arxiv.org/abs/2308.05021</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yangming Li, Zhaozhi Qian, Mihaela van der Schaar</li>
<li>for: 这个论文的目的是检测扩散模型中的错误卷积问题，并提出一种正则化方法来解决这个问题。</li>
<li>methods: 这个论文使用了empirical和理论分析来证明扩散模型中的错误卷积问题，并提出了一种正则化方法来解决这个问题。</li>
<li>results: 实验结果表明，这种正则化方法可以有效地解决扩散模型中的错误卷积问题，并且可以提高扩散模型的性能。<details>
<summary>Abstract</summary>
While diffusion models have achieved promising performances in data synthesis, they might suffer error propagation because of their cascade structure, where the distributional mismatch spreads and magnifies through the chain of denoising modules. However, a strict analysis is expected since many sequential models such as Conditional Random Field (CRF) are free from error propagation. In this paper, we empirically and theoretically verify that diffusion models are indeed affected by error propagation and we then propose a regularization to address this problem. Our theoretical analysis reveals that the question can be reduced to whether every denoising module of the diffusion model is fault-tolerant. We derive insightful transition equations, indicating that the module can't recover from input errors and even propagates additional errors to the next module. Our analysis directly leads to a consistency regularization scheme for diffusion models, which explicitly reduces the distribution gap between forward and backward processes. We further introduce a bootstrapping algorithm to reduce the computation cost of the regularizer. Our experimental results on multiple image datasets show that our regularization effectively handles error propagation and significantly improves the performance of vanilla diffusion models.
</details>
<details>
<summary>摘要</summary>
Diffusion models 有 achieved promising performance in data synthesis, but they may suffer from error propagation due to their cascade structure, where the distributional mismatch spreads and magnifies through the chain of denoising modules. However, many sequential models such as Conditional Random Field (CRF) are free from error propagation. In this paper, we empirically and theoretically verify that diffusion models are indeed affected by error propagation, and we propose a regularization to address this problem.我们的 teorical analysis shows that the question can be reduced to whether every denoising module of the diffusion model is fault-tolerant. We derive insightful transition equations, indicating that the module cannot recover from input errors and even propagates additional errors to the next module. Our analysis directly leads to a consistency regularization scheme for diffusion models, which explicitly reduces the distribution gap between forward and backward processes.我们还提出了一种 bootstrapping algorithm to reduce the computation cost of the regularizer. Our experimental results on multiple image datasets show that our regularization effectively handles error propagation and significantly improves the performance of vanilla diffusion models.
</details></li>
</ul>
<hr>
<h2 id="When-and-How-Does-Known-Class-Help-Discover-Unknown-Ones-Provable-Understanding-Through-Spectral-Analysis"><a href="#When-and-How-Does-Known-Class-Help-Discover-Unknown-Ones-Provable-Understanding-Through-Spectral-Analysis" class="headerlink" title="When and How Does Known Class Help Discover Unknown Ones? Provable Understanding Through Spectral Analysis"></a>When and How Does Known Class Help Discover Unknown Ones? Provable Understanding Through Spectral Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05017">http://arxiv.org/abs/2308.05017</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/deeplearning-wisc/nscl">https://github.com/deeplearning-wisc/nscl</a></li>
<li>paper_authors: Yiyou Sun, Zhenmei Shi, Yingyu Liang, Yixuan Li</li>
<li>for: 本研究旨在提出一种基于知识的新类发现方法，即使无需标注数据也可以准确地探索新类。</li>
<li>methods: 本研究使用了图论 Representation 和 Spectral Contrastive Loss（NSCL）来解决新类发现问题。图论 Representation 可以将知识集中的类划分为不同的类划分，而 NSCL 可以使得图论 Representation 中的 adjacency matrix  факторизу，从而 derivate 一个可靠的错误 bound 和新类发现的必要和 suffcient 条件。</li>
<li>results: 实验表明，使用 NSCL 可以与多种强基eline 相比竞争，并且在常见的 benchmark 数据集上达到类似或更好的性能，这是一个有趣的实际应用，同时也具有理论保证。<details>
<summary>Abstract</summary>
Novel Class Discovery (NCD) aims at inferring novel classes in an unlabeled set by leveraging prior knowledge from a labeled set with known classes. Despite its importance, there is a lack of theoretical foundations for NCD. This paper bridges the gap by providing an analytical framework to formalize and investigate when and how known classes can help discover novel classes. Tailored to the NCD problem, we introduce a graph-theoretic representation that can be learned by a novel NCD Spectral Contrastive Loss (NSCL). Minimizing this objective is equivalent to factorizing the graph's adjacency matrix, which allows us to derive a provable error bound and provide the sufficient and necessary condition for NCD. Empirically, NSCL can match or outperform several strong baselines on common benchmark datasets, which is appealing for practical usage while enjoying theoretical guarantees.
</details>
<details>
<summary>摘要</summary>
《新类发现（NCD）》的目标是从无标签集中推断出新类，通过利用已知类的先知知识。尽管NCD的理论基础缺乏，这篇论文填补了这一空白，提供了一种分析框架，以便正式地探讨已知类如何帮助发现新类。特地设计 дляNCD问题，我们引入了一种图论的表示方式，可以由NSCL（NCD特征对偶损失）学习。将这个目标函数最小化等价于图的邻接矩阵 факторизация，从而得到了一个可证明的错误 bound 和发现新类的必要和 suficient condition。实验表明，NSCL可以与多种强基eline比肩并列，这是实用上的优点，同时又享有理论保证。
</details></li>
</ul>
<hr>
<h2 id="An-Empirical-Study-of-Bugs-in-Open-Source-Federated-Learning-Framework"><a href="#An-Empirical-Study-of-Bugs-in-Open-Source-Federated-Learning-Framework" class="headerlink" title="An Empirical Study of Bugs in Open-Source Federated Learning Framework"></a>An Empirical Study of Bugs in Open-Source Federated Learning Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05014">http://arxiv.org/abs/2308.05014</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weijie Shao, Yuyang Gao, Fu Song, Sen Chen, Lingling Fan</li>
<li>for: 本研究的目的是 investigate the security issues in federated learning (FL) frameworks.</li>
<li>methods: 本研究使用了manuel collection, classification, and labeling of 1,112 FL framework bugs from 12 open-source FL frameworks on GitHub, and constructed taxonomies of 15 symptoms, 12 root causes, and 20 fix patterns of these bugs.</li>
<li>results: 研究发现了9个发现，包括15种symptoms、12种root causes、20种fix patterns，并对23个逻辑组件和两个主要应用场景进行了分析。<details>
<summary>Abstract</summary>
Federated learning (FL), as a decentralized machine learning solution to the protection of users' private data, has become an important learning paradigm in recent years, especially since the enforcement of stricter laws and regulations in most countries. Therefore, a variety of FL frameworks are released to facilitate the development and application of federated learning. Despite the considerable amount of research on the security and privacy of FL models and systems, the security issues in FL frameworks have not been systematically studied yet. In this paper, we conduct the first empirical study on 1,112 FL framework bugs to investigate their characteristics. These bugs are manually collected, classified, and labeled from 12 open-source FL frameworks on GitHub. In detail, we construct taxonomies of 15 symptoms, 12 root causes, and 20 fix patterns of these bugs and investigate their correlations and distributions on 23 logical components and two main application scenarios. From the results of our study, we present nine findings, discuss their implications, and propound several suggestions to FL framework developers and security researchers on the FL frameworks.
</details>
<details>
<summary>摘要</summary>
federated learning（FL），作为一种保护用户隐私数据的分布式机器学习解决方案，在过去几年中变得非常重要，尤其是在大多数国家实施更加严格的法律和规定后。因此，许多FL框架被发布，以便发展和应用联邦学习。尽管有很多关于FL模型和系统安全性的研究，但FL框架的安全问题尚未得到系统的研究。在这篇论文中，我们进行了第一个对1,112个FL框架漏洞的实证研究，以Investigate其特点。这些漏洞由手动收集、分类和标注的12个开源FL框架在GitHub上的漏洞。在详细的分析中，我们构建了15种表现Symptoms、12种根本原因和20种修复模式的漏洞分类系统，并对23个逻辑组件和两个主要应用场景进行了分析。从我们的研究结果中，我们提出了9个发现，讨论了它们的意义，并对FL框架开发者和安全研究人员提出了一些建议。
</details></li>
</ul>
<hr>
<h2 id="Multi-Class-Deep-SVDD-Anomaly-Detection-Approach-in-Astronomy-with-Distinct-Inlier-Categories"><a href="#Multi-Class-Deep-SVDD-Anomaly-Detection-Approach-in-Astronomy-with-Distinct-Inlier-Categories" class="headerlink" title="Multi-Class Deep SVDD: Anomaly Detection Approach in Astronomy with Distinct Inlier Categories"></a>Multi-Class Deep SVDD: Anomaly Detection Approach in Astronomy with Distinct Inlier Categories</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05011">http://arxiv.org/abs/2308.05011</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mperezcarrasco/AnomalyALeRCE">https://github.com/mperezcarrasco/AnomalyALeRCE</a></li>
<li>paper_authors: Manuel Pérez-Carrasco, Guillermo Cabrera-Vives, Lorena Hernández-García, Francisco Forster, Paula Sánchez-Sáez, Alejandra Muñoz Arancibia, Nicolás Astorga, Franz Bauer, Amelia Bayo, Martina Cádiz-Leyton, Marcio Catelan</li>
<li>for: 这篇论文是用于探索自动化天文数据分析和机器学习技术的应用，以及如何对不同类型的天文数据进行异常探测。</li>
<li>methods: 这篇论文提出了一个叫做 Multi-Class Deep Support Vector Data Description (MCDSVDD) 的新算法，它是 One-Class Deep SVDD 的扩展，可以处理不同类型的内liers category。MCDSVDD 使用神经网络将数据映射到高维球体中，每个高维球体代表一个特定的内liers category。</li>
<li>results: 这篇论文的结果显示 MCDSVDD 能够对天文数据进行有效的异常探测，并且可以利用不同类型的内liers category。<details>
<summary>Abstract</summary>
With the increasing volume of astronomical data generated by modern survey telescopes, automated pipelines and machine learning techniques have become crucial for analyzing and extracting knowledge from these datasets. Anomaly detection, i.e. the task of identifying irregular or unexpected patterns in the data, is a complex challenge in astronomy. In this paper, we propose Multi-Class Deep Support Vector Data Description (MCDSVDD), an extension of the state-of-the-art anomaly detection algorithm One-Class Deep SVDD, specifically designed to handle different inlier categories with distinct data distributions. MCDSVDD uses a neural network to map the data into hyperspheres, where each hypersphere represents a specific inlier category. The distance of each sample from the centers of these hyperspheres determines the anomaly score. We evaluate the effectiveness of MCDSVDD by comparing its performance with several anomaly detection algorithms on a large dataset of astronomical light-curves obtained from the Zwicky Transient Facility. Our results demonstrate the efficacy of MCDSVDD in detecting anomalous sources while leveraging the presence of different inlier categories. The code and the data needed to reproduce our results are publicly available at https://github.com/mperezcarrasco/AnomalyALeRCE.
</details>
<details>
<summary>摘要</summary>
随着现代观测望远镜生成的天文数据量的增加，自动化管道和机器学习技术已成为分析和提取天文数据中的重要工具。异常检测，即在数据中发现不寻常或意外的模式，是天文学中的一项复杂挑战。在这篇论文中，我们提出了多类深度支持向量数据描述（MCDSVDD）算法，这是一种特制来处理不同类准样的异常检测算法。MCDSVDD使用神经网络将数据映射到几个异常分类中的几个圆锥中，每个圆锥表示一种特定的准样类别。每个样本与各个圆锥的中心之间的距离决定了异常分数。我们通过对一些异常检测算法的比较，证明MCDSVDD可以有效地检测异常来源，同时利用不同类准样的存在。codes和需要进行重现的数据可以在https://github.com/mperezcarrasco/AnomalyALeRCE上获取。
</details></li>
</ul>
<hr>
<h2 id="Transferable-Models-for-Bioacoustics-with-Human-Language-Supervision"><a href="#Transferable-Models-for-Bioacoustics-with-Human-Language-Supervision" class="headerlink" title="Transferable Models for Bioacoustics with Human Language Supervision"></a>Transferable Models for Bioacoustics with Human Language Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04978">http://arxiv.org/abs/2308.04978</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/david-rx/biolingual">https://github.com/david-rx/biolingual</a></li>
<li>paper_authors: David Robinson, Adelaide Robinson, Lily Akrapongpisak</li>
<li>for: 本研究的目的是开发一种可扩展、非侵入的方法来跟踪全球生物多样性和人类活动对物种的影响。</li>
<li>methods: 本研究使用了一种新的语音-语言预训练模型，称为BioLingual，以处理生物声学数据。该模型首先将生物声学档案聚合成一个语音-语言数据集，称为AnimalSpeak，包含超过一百万个语音-标注对，其中包含物种、叫声上下文和动物行为信息。然后，通过在这个数据集上训练语音-语言表示之间的连接，该模型可以识别超过一千种动物的叫声，并在零样本下完成生物声学任务。</li>
<li>results: 当finetuned的BioLingual模型在九个任务上达到了新的状态态-of-the-art水平。此外，该模型可以通过自然语言查询来检索动物叫声录音，并且可以在不同的物种和环境下进行可扩展的应用。<details>
<summary>Abstract</summary>
Passive acoustic monitoring offers a scalable, non-invasive method for tracking global biodiversity and anthropogenic impacts on species. Although deep learning has become a vital tool for processing this data, current models are inflexible, typically cover only a handful of species, and are limited by data scarcity. In this work, we propose BioLingual, a new model for bioacoustics based on contrastive language-audio pretraining. We first aggregate bioacoustic archives into a language-audio dataset, called AnimalSpeak, with over a million audio-caption pairs holding information on species, vocalization context, and animal behavior. After training on this dataset to connect language and audio representations, our model can identify over a thousand species' calls across taxa, complete bioacoustic tasks zero-shot, and retrieve animal vocalization recordings from natural text queries. When fine-tuned, BioLingual sets a new state-of-the-art on nine tasks in the Benchmark of Animal Sounds. Given its broad taxa coverage and ability to be flexibly queried in human language, we believe this model opens new paradigms in ecological monitoring and research, including free-text search on the world's acoustic monitoring archives. We open-source our models, dataset, and code.
</details>
<details>
<summary>摘要</summary>
We first aggregate bioacoustic archives into a language-audio dataset, called AnimalSpeak, which contains over one million audio-caption pairs with information on species, vocalization context, and animal behavior. After training on this dataset to connect language and audio representations, our model can identify over a thousand species' calls across taxa, complete bioacoustic tasks zero-shot, and retrieve animal vocalization recordings from natural text queries. When fine-tuned, BioLingual sets a new state-of-the-art on nine tasks in the Benchmark of Animal Sounds.Given its broad taxa coverage and ability to be flexibly queried in human language, we believe that this model opens up new paradigms in ecological monitoring and research, including free-text search on the world's acoustic monitoring archives. We have made our models, dataset, and code open-source, allowing for further research and application of this technology.
</details></li>
</ul>
<hr>
<h2 id="Adversarial-ModSecurity-Countering-Adversarial-SQL-Injections-with-Robust-Machine-Learning"><a href="#Adversarial-ModSecurity-Countering-Adversarial-SQL-Injections-with-Robust-Machine-Learning" class="headerlink" title="Adversarial ModSecurity: Countering Adversarial SQL Injections with Robust Machine Learning"></a>Adversarial ModSecurity: Countering Adversarial SQL Injections with Robust Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04964">http://arxiv.org/abs/2308.04964</a></li>
<li>repo_url: None</li>
<li>paper_authors: Biagio Montaruli, Luca Demetrio, Andrea Valenza, Luca Compagna, Davide Ariu, Luca Piras, Davide Balzarotti, Battista Biggio</li>
<li>for: 本研究旨在提高ModSecurity的攻击检测精度和鲁棒性，以帮助建立更加可靠和安全的Web应用程序防火墙（WAF）。</li>
<li>methods: 本研究使用机器学习模型，名为AdvModSec，来检测针对Web服务的SQL注入攻击（SQLi）。AdvModSec使用ModSecurity的核心规则集（CRS）作为输入特征，并通过训练来检测反对攻击。</li>
<li>results: 实验结果显示，AdvModSec可以提高ModSecurity的检测精度和鲁棒性，具体来说，可以提高检测率21%，并在对抗反对攻击方面提高鲁棒性42%。<details>
<summary>Abstract</summary>
ModSecurity is widely recognized as the standard open-source Web Application Firewall (WAF), maintained by the OWASP Foundation. It detects malicious requests by matching them against the Core Rule Set, identifying well-known attack patterns. Each rule in the CRS is manually assigned a weight, based on the severity of the corresponding attack, and a request is detected as malicious if the sum of the weights of the firing rules exceeds a given threshold. In this work, we show that this simple strategy is largely ineffective for detecting SQL injection (SQLi) attacks, as it tends to block many legitimate requests, while also being vulnerable to adversarial SQLi attacks, i.e., attacks intentionally manipulated to evade detection. To overcome these issues, we design a robust machine learning model, named AdvModSec, which uses the CRS rules as input features, and it is trained to detect adversarial SQLi attacks. Our experiments show that AdvModSec, being trained on the traffic directed towards the protected web services, achieves a better trade-off between detection and false positive rates, improving the detection rate of the vanilla version of ModSecurity with CRS by 21%. Moreover, our approach is able to improve its adversarial robustness against adversarial SQLi attacks by 42%, thereby taking a step forward towards building more robust and trustworthy WAFs.
</details>
<details>
<summary>摘要</summary>
mod_security是通用的开源网络应用程序防火墙（WAF），由OWASP基金会维护。它通过匹配核心规则集来检测攻击性请求，并且每个规则都被手动分配了严重程度，以及检测到的请求是否超过了一定的阈值。在这种简单的策略下，我们发现这个策略在检测SQL注入（SQLi）攻击时效果很差，因为它会拒绝许多合法请求，同时也容易受到攻击者的攻击。为了解决这些问题，我们设计了一个可靠的机器学习模型，名为AdvModSec，它使用核心规则集作为输入特征，并通过训练来检测攻击者Intentional地修改的SQLi攻击。我们的实验表明，AdvModSec在受到保护的网络服务的流量下进行训练后，可以提高检测率，同时也可以降低假阳性率，相比于vanilla版mod_security与核心规则集的检测率提高21%。此外，我们的方法还可以在面对攻击者Intentional地修改SQLi攻击后提高对抗性，提高了24%。这些成果表明我们的方法可以提高WAF的可靠性和信任性。
</details></li>
</ul>
<hr>
<h2 id="CasCIFF-A-Cross-Domain-Information-Fusion-Framework-Tailored-for-Cascade-Prediction-in-Social-Networks"><a href="#CasCIFF-A-Cross-Domain-Information-Fusion-Framework-Tailored-for-Cascade-Prediction-in-Social-Networks" class="headerlink" title="CasCIFF: A Cross-Domain Information Fusion Framework Tailored for Cascade Prediction in Social Networks"></a>CasCIFF: A Cross-Domain Information Fusion Framework Tailored for Cascade Prediction in Social Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04961">http://arxiv.org/abs/2308.04961</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xiaoyuan011/casciff">https://github.com/xiaoyuan011/casciff</a></li>
<li>paper_authors: Hongjun Zhu, Shun Yuan, Xin Liu, Kuo Chen, Chaolong Jia, Ying Qian</li>
<li>for: 本研究旨在提高信息扩散预测的精度，特别是处理用户特征和信息扩散的复杂关系。</li>
<li>methods: 该研究提出了 Cross-Domain Information Fusion Framework (CasCIFF)，这是一种基于多个域的信息融合框架，通过多树邻域信息来提高用户嵌入的Robustness。在插入推荐时，该框架 INTENTIONALLY  integrate 时间戳，以捕捉信息扩散过程中的变化趋势。</li>
<li>results: 研究表明，CasCIFF 可以更好地捕捉用户行为和信息扩散的复杂关系，并且在信息扩散预测任务中表现出了superior的性能。<details>
<summary>Abstract</summary>
Existing approaches for information cascade prediction fall into three main categories: feature-driven methods, point process-based methods, and deep learning-based methods. Among them, deep learning-based methods, characterized by its superior learning and representation capabilities, mitigates the shortcomings inherent of the other methods. However, current deep learning methods still face several persistent challenges. In particular, accurate representation of user attributes remains problematic due to factors such as fake followers and complex network configurations. Previous algorithms that focus on the sequential order of user activations often neglect the rich insights offered by activation timing. Furthermore, these techniques often fail to holistically integrate temporal and structural aspects, thus missing the nuanced propagation trends inherent in information cascades.To address these issues, we propose the Cross-Domain Information Fusion Framework (CasCIFF), which is tailored for information cascade prediction. This framework exploits multi-hop neighborhood information to make user embeddings robust. When embedding cascades, the framework intentionally incorporates timestamps, endowing it with the ability to capture evolving patterns of information diffusion. In particular, the CasCIFF seamlessly integrates the tasks of user classification and cascade prediction into a consolidated framework, thereby allowing the extraction of common features that prove useful for all tasks, a strategy anchored in the principles of multi-task learning.
</details>
<details>
<summary>摘要</summary>
现有的信息冲击预测方法可以分为三个主要类别：基于特征的方法、基于点过程的方法和深度学习基于方法。其中，深度学习基于方法，具有出色的学习和表示能力，可以抵消其他方法的缺点。然而，当前的深度学习方法仍面临多个持续的挑战。特别是，准确地表示用户属性仍然是一个问题，因为因素如假账户和复杂的网络配置。过去的算法通常将用户活动的顺序序列化，而忽略了用户活动的时间序列信息。此外，这些技术通常不能整合时间和结构方面的信息，因此缺乏把握信息冲击的细腻传播趋势。为解决这些问题，我们提出了跨频率信息融合框架（CasCIFF），这是用于信息冲击预测的专门框架。这个框架利用多跳邻居信息来做用户嵌入 Robust。当嵌入冲击时，框架会意识到时间戳，以便捕捉信息传播中的演化趋势。具体来说，CasCIFF通过将用户分类和冲击预测任务融合到一起，从而允许提取共同的特征，这种策略基于多任务学习的原则。
</details></li>
</ul>
<hr>
<h2 id="Representation-Learning-for-Audio-Privacy-Preservation-using-Source-Separation-and-Robust-Adversarial-Learning"><a href="#Representation-Learning-for-Audio-Privacy-Preservation-using-Source-Separation-and-Robust-Adversarial-Learning" class="headerlink" title="Representation Learning for Audio Privacy Preservation using Source Separation and Robust Adversarial Learning"></a>Representation Learning for Audio Privacy Preservation using Source Separation and Robust Adversarial Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04960">http://arxiv.org/abs/2308.04960</a></li>
<li>repo_url: None</li>
<li>paper_authors: Diep Luong, Minh Tran, Shayan Gharib, Konstantinos Drossos, Tuomas Virtanen</li>
<li>for: 隐私保护在智能声学监测系统中一直是一个关键问题， где沟通可以被捕获并与系统运行环境中的目标信号一起记录。在这种研究中，我们提出了将两种常用的隐私保护方法集成到一起：源分离和对抗表示学习。我们的提议的系统学习声音录制的潜在表示，以防止区分沟通和非沟通录制。</li>
<li>methods: 我们的提议方法包括源分离网络对一些隐私敏感数据进行过滤，以及在对抗学习过程中学习隐私保护的表示。</li>
<li>results: 我们的结果表明，在比较不含源分离、不含对抗学习和不含两者的系统之间，我们的提议系统可以显著改善沟通隐私保护，同时保持声学监测任务的好性能。<details>
<summary>Abstract</summary>
Privacy preservation has long been a concern in smart acoustic monitoring systems, where speech can be passively recorded along with a target signal in the system's operating environment. In this study, we propose the integration of two commonly used approaches in privacy preservation: source separation and adversarial representation learning. The proposed system learns the latent representation of audio recordings such that it prevents differentiating between speech and non-speech recordings. Initially, the source separation network filters out some of the privacy-sensitive data, and during the adversarial learning process, the system will learn privacy-preserving representation on the filtered signal. We demonstrate the effectiveness of our proposed method by comparing our method against systems without source separation, without adversarial learning, and without both. Overall, our results suggest that the proposed system can significantly improve speech privacy preservation compared to that of using source separation or adversarial learning solely while maintaining good performance in the acoustic monitoring task.
</details>
<details>
<summary>摘要</summary>
privacy preservation已经是智能听音系统中的长期关注点，其中speech可以通过系统运行环境中的passive recording方式被记录。在这个研究中，我们提议将两种常用的隐私保护方法集成：源分离和对抗表示学习。我们的提议系统将learnlatent表示音频记录，以防止 differentiating between speech和non-speech记录。在源分离网络过滤一部分隐私敏感数据后，在对抗学习过程中，系统会学习隐私保护的表示。我们的实验结果表明，我们的提议方法可以在保持听音任务的好表现的同时，提高speech隐私保护比使用源分离或对抗学习独立的系统。
</details></li>
</ul>
<hr>
<h2 id="Improving-Autonomous-Separation-Assurance-through-Distributed-Reinforcement-Learning-with-Attention-Networks"><a href="#Improving-Autonomous-Separation-Assurance-through-Distributed-Reinforcement-Learning-with-Attention-Networks" class="headerlink" title="Improving Autonomous Separation Assurance through Distributed Reinforcement Learning with Attention Networks"></a>Improving Autonomous Separation Assurance through Distributed Reinforcement Learning with Attention Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04958">http://arxiv.org/abs/2308.04958</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marc W. Brittain, Luis E. Alvarez, Kara Breeden</li>
<li>for: 本研究旨在提出一种基于自适应控制和电动飞机的高效空中交通模式，以提供受欠服务市场的增加自动化交通。</li>
<li>methods: 该研究使用分布式学习框架，并开发了一种新的尺度观察网络和分布式计算架构，以实现高效的自适应分离能力。</li>
<li>results: numerical study表明，提出的方法可以在高强度、动态环境中保证安全有效的飞机分离，并且可以处理多种不确定性的信息。<details>
<summary>Abstract</summary>
Advanced Air Mobility (AAM) introduces a new, efficient mode of transportation with the use of vehicle autonomy and electrified aircraft to provide increasingly autonomous transportation between previously underserved markets. Safe and efficient navigation of low altitude aircraft through highly dense environments requires the integration of a multitude of complex observations, such as surveillance, knowledge of vehicle dynamics, and weather. The processing and reasoning on these observations pose challenges due to the various sources of uncertainty in the information while ensuring cooperation with a variable number of aircraft in the airspace. These challenges coupled with the requirement to make safety-critical decisions in real-time rule out the use of conventional separation assurance techniques. We present a decentralized reinforcement learning framework to provide autonomous self-separation capabilities within AAM corridors with the use of speed and vertical maneuvers. The problem is formulated as a Markov Decision Process and solved by developing a novel extension to the sample-efficient, off-policy soft actor-critic (SAC) algorithm. We introduce the use of attention networks for variable-length observation processing and a distributed computing architecture to achieve high training sample throughput as compared to existing approaches. A comprehensive numerical study shows that the proposed framework can ensure safe and efficient separation of aircraft in high density, dynamic environments with various sources of uncertainty.
</details>
<details>
<summary>摘要</summary>
高级空中 mobilité (AAM) 引入了一种新的、高效的交通方式，通过车辆自主和电动飞机来提供受欢迎的交通 between  formerly underserved markets。  safe and efficient navigation of low altitude aircraft through highly dense environments requires the integration of a multitude of complex observations, such as surveillance, vehicle dynamics knowledge, and weather.  the processing and reasoning on these observations pose challenges due to the various sources of uncertainty in the information while ensuring cooperation with a variable number of aircraft in the airspace. these challenges coupled with the requirement to make safety-critical decisions in real-time rule out the use of conventional separation assurance techniques. we present a decentralized reinforcement learning framework to provide autonomous self-separation capabilities within AAM corridors with the use of speed and vertical maneuvers. the problem is formulated as a Markov decision process and solved by developing a novel extension to the sample-efficient, off-policy soft actor-critic (SAC) algorithm. we introduce the use of attention networks for variable-length observation processing and a distributed computing architecture to achieve high training sample throughput as compared to existing approaches. a comprehensive numerical study shows that the proposed framework can ensure safe and efficient separation of aircraft in high density, dynamic environments with various sources of uncertainty.
</details></li>
</ul>
<hr>
<h2 id="Variations-on-the-Reinforcement-Learning-performance-of-Blackjack"><a href="#Variations-on-the-Reinforcement-Learning-performance-of-Blackjack" class="headerlink" title="Variations on the Reinforcement Learning performance of Blackjack"></a>Variations on the Reinforcement Learning performance of Blackjack</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07329">http://arxiv.org/abs/2308.07329</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/avishburamdoyal/the-impact-of-deck-size-q-learning-blackjack">https://github.com/avishburamdoyal/the-impact-of-deck-size-q-learning-blackjack</a></li>
<li>paper_authors: Avish Buramdoyal, Tim Gebbie</li>
<li>for: 这篇论文旨在研究黑板子游戏中的优化策略，以最大化长期收益而避免投资者落伍。</li>
<li>methods: 该论文使用q学习方法来解决黑板子游戏中的优化问题，并研究学习速率的响应函数和deck size的影响。</li>
<li>results: 研究发现，在黑板子游戏中，使用基础策略和高低系统的card counter可以使房间铺垮，并且牵涉到环境变化的影响。此外，q学习算法在不同deck size下的学习速率也得到了研究。<details>
<summary>Abstract</summary>
Blackjack or "21" is a popular card-based game of chance and skill. The objective of the game is to win by obtaining a hand total higher than the dealer's without exceeding 21. The ideal blackjack strategy will maximize financial return in the long run while avoiding gambler's ruin. The stochastic environment and inherent reward structure of blackjack presents an appealing problem to better understand reinforcement learning agents in the presence of environment variations. Here we consider a q-learning solution for optimal play and investigate the rate of learning convergence of the algorithm as a function of deck size. A blackjack simulator allowing for universal blackjack rules is also implemented to demonstrate the extent to which a card counter perfectly using the basic strategy and hi-lo system can bring the house to bankruptcy and how environment variations impact this outcome. The novelty of our work is to place this conceptual understanding of the impact of deck size in the context of learning agent convergence.
</details>
<details>
<summary>摘要</summary>
黑Jack或"21"是一款受欢迎的 карто牌类游戏，旨在通过获得手牌总数高于卡牌师的手牌总数，而不超过21。理想的黑Jack策略可以在长期内最大化财务回报，同时避免投资者的破产。黑Jack的杂 probabilistic环境和内在的奖励结构，使得黑Jack成为了研究增强学习代理人在环境变化下的理解的一个有appeal的问题。在这里，我们考虑了q学习解决方案，以实现最佳的游戏策略，并研究了算法在卡牌堆大小变化时的学习速率的响应。我们还实现了一个可以实现 universal blackjack规则的黑Jack模拟器，以示出一个基本策略和hi-lo系统的卡计数可以使得临场破产，并如何环境变化影响这种结果。我们的研究的新特点在于将这种概念理解与学习代理人的快速学习速率相联系起来。
</details></li>
</ul>
<hr>
<h2 id="Performance-Analysis-of-Transformer-Based-Models-BERT-ALBERT-and-RoBERTa-in-Fake-News-Detection"><a href="#Performance-Analysis-of-Transformer-Based-Models-BERT-ALBERT-and-RoBERTa-in-Fake-News-Detection" class="headerlink" title="Performance Analysis of Transformer Based Models (BERT, ALBERT and RoBERTa) in Fake News Detection"></a>Performance Analysis of Transformer Based Models (BERT, ALBERT and RoBERTa) in Fake News Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04950">http://arxiv.org/abs/2308.04950</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/shafna81/fakenewsdetection">https://github.com/shafna81/fakenewsdetection</a></li>
<li>paper_authors: Shafna Fitria Nur Azizah, Hasan Dwi Cahyono, Sari Widya Sihwi, Wisnu Widiarto</li>
<li>For: 本研究旨在探讨使用 transformer 模型进行假新闻检测，以提高假新闻检测精度。* Methods: 本研究使用了 ALBERT 模型，并对其进行了改进，以提高假新闻检测精度。* Results: 研究发现，使用 ALBERT 模型可以达到 87.6% 的准确率，86.9% 的精度，86.9% F1-score，以及 174.5 个运行时间（s&#x2F;epoch）。<details>
<summary>Abstract</summary>
Fake news is fake material in a news media format but is not processed properly by news agencies. The fake material can provoke or defame significant entities or individuals or potentially even for the personal interests of the creators, causing problems for society. Distinguishing fake news and real news is challenging due to limited of domain knowledge and time constraints. According to the survey, the top three areas most exposed to hoaxes and misinformation by residents are in Banten, DKI Jakarta and West Java. The model of transformers is referring to an approach in the field of artificial intelligence (AI) in natural language processing utilizing the deep learning architectures. Transformers exercise a powerful attention mechanism to process text in parallel and produce rich and contextual word representations. A previous study indicates a superior performance of a transformer model known as BERT over and above non transformer approach. However, some studies suggest the performance can be improved with the use of improved BERT models known as ALBERT and RoBERTa. However, the modified BERT models are not well explored for detecting fake news in Bahasa Indonesia. In this research, we explore those transformer models and found that ALBERT outperformed other models with 87.6% accuracy, 86.9% precision, 86.9% F1-score, and 174.5 run-time (s/epoch) respectively. Source code available at: https://github.com/Shafna81/fakenewsdetection.git
</details>
<details>
<summary>摘要</summary>
假新闻是指在新闻媒体格式中存在假信息，但是未经正确处理的新闻媒体。假信息可能会挑衅或诋毁重要的实体或个人，甚至为创造者的个人利益而导致社会问题。分辨假新闻和真实新闻是一项挑战，因为有限的领域知识和时间约束。据调查，居民最容易遭受到诈骗和错误信息的地区是万隆、Special Capital Region of Jakarta和西 Java。转换器是一种人工智能（AI）自然语言处理领域的方法，使用深度学习架构。转换器实施了强大的注意力机制，并在平行处理文本，生成富有内在语义的单词表示。以前的研究表明，一种名为BERT的转换器模型在非转换器方法之上表现出优异。然而，一些研究表示，使用改进的BERT模型，如ALBERT和RoBERTa，可以进一步提高性能。然而，这些改进的BERT模型在假新闻检测中的表现还未得到广泛探索。在这项研究中，我们探索了这些转换器模型，并发现ALBERT在87.6%的准确率、86.9%的精度、86.9%的F1分数和174.5个运行时（s/epoch）中表现出优异。源代码可以在GitHub上获取：https://github.com/Shafna81/fakenewsdetection.git。
</details></li>
</ul>
<hr>
<h2 id="Methods-for-Acquiring-and-Incorporating-Knowledge-into-Stock-Price-Prediction-A-Survey"><a href="#Methods-for-Acquiring-and-Incorporating-Knowledge-into-Stock-Price-Prediction-A-Survey" class="headerlink" title="Methods for Acquiring and Incorporating Knowledge into Stock Price Prediction: A Survey"></a>Methods for Acquiring and Incorporating Knowledge into Stock Price Prediction: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04947">http://arxiv.org/abs/2308.04947</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liping Wang, Jiawei Li, Lifan Zhao, Zhizhuo Kou, Xiaohan Wang, Xinyi Zhu, Hao Wang, Yanyan Shen, Lei Chen</li>
<li>For: 本研究目的是对外部知识的整合进行系统性的检讨和总结，以提高股票价格预测的准确性。* Methods: 本研究使用了非图structured和图structured的外部知识，包括文本、多媒体描述和股票市场的关联关系。* Results: 研究提出了一种系统性的方法，可以从不同的未结构化数据源中获取外部知识，并将其与历史价格特征进行融合。此外，研究还总结了一些相关的数据集和未来研究方向。<details>
<summary>Abstract</summary>
Predicting stock prices presents a challenging research problem due to the inherent volatility and non-linear nature of the stock market. In recent years, knowledge-enhanced stock price prediction methods have shown groundbreaking results by utilizing external knowledge to understand the stock market. Despite the importance of these methods, there is a scarcity of scholarly works that systematically synthesize previous studies from the perspective of external knowledge types. Specifically, the external knowledge can be modeled in different data structures, which we group into non-graph-based formats and graph-based formats: 1) non-graph-based knowledge captures contextual information and multimedia descriptions specifically associated with an individual stock; 2) graph-based knowledge captures interconnected and interdependent information in the stock market. This survey paper aims to provide a systematic and comprehensive description of methods for acquiring external knowledge from various unstructured data sources and then incorporating it into stock price prediction models. We also explore fusion methods for combining external knowledge with historical price features. Moreover, this paper includes a compilation of relevant datasets and delves into potential future research directions in this domain.
</details>
<details>
<summary>摘要</summary>
预测股票价格是一个复杂的研究问题，因为股票市场具有自然的波动和非线性。在过去几年，带有知识的股票价格预测方法有着创新的成果，这些方法利用了外部知识来理解股票市场。虽然这些方法的重要性，但是学术研究中几乎没有系统地总结过去的研究，特别是对于不同类型的外部知识的分析。在这篇评论文中，我们将提供一个系统和全面的描述，涵盖从不同的未结构化数据源中获取外部知识，然后将其与历史价格特征结合在一起。此外，我们还会探讨不同类型的融合方法，以及可能的未来研究方向。Here's the translation of the text into Traditional Chinese:预测股票价格是一个复杂的研究问题，因为股票市场具有自然的波动和非线性。在过去几年，带有知识的股票价格预测方法有创新的成果，这些方法利用了外部知识来理解股票市场。处理这些方法的重要性，但是学术研究中几乎没有系统地总结过去的研究，特别是对于不同类型的外部知识的分析。在这篇评论文中，我们将提供一个系统和全面的描述，涵盖从不同的未结构化数据源中获取外部知识，然后将其与历史价格特征结合在一起。此外，我们还会探讨不同类型的融合方法，以及可能的未来研究方向。
</details></li>
</ul>
<hr>
<h2 id="Differentially-Private-Graph-Neural-Network-with-Importance-Grained-Noise-Adaption"><a href="#Differentially-Private-Graph-Neural-Network-with-Importance-Grained-Noise-Adaption" class="headerlink" title="Differentially Private Graph Neural Network with Importance-Grained Noise Adaption"></a>Differentially Private Graph Neural Network with Importance-Grained Noise Adaption</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04943">http://arxiv.org/abs/2308.04943</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxin Qi, Xi Lin, Jun Wu</li>
<li>for: 保护图形数据的隐私，特别是节点数据的隐私，when nodes represent personal and sensitive information。</li>
<li>methods: 提出了一种基于差分隐私的图 neural network (GNN) 算法， named NAP-GNN， which includes topology-based node importance estimation (TNIE) method, adaptive private aggregation method, and private training of graph learning algorithm with adaptive residual connection mode.</li>
<li>results:  theoretically analysis shows that NAP-GNN satisfies privacy guarantees, and empirical experiments over real-world graph datasets show that NAP-GNN achieves a better trade-off between privacy and accuracy.<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) with differential privacy have been proposed to preserve graph privacy when nodes represent personal and sensitive information. However, the existing methods ignore that nodes with different importance may yield diverse privacy demands, which may lead to over-protect some nodes and decrease model utility. In this paper, we study the problem of importance-grained privacy, where nodes contain personal data that need to be kept private but are critical for training a GNN. We propose NAP-GNN, a node-importance-grained privacy-preserving GNN algorithm with privacy guarantees based on adaptive differential privacy to safeguard node information. First, we propose a Topology-based Node Importance Estimation (TNIE) method to infer unknown node importance with neighborhood and centrality awareness. Second, an adaptive private aggregation method is proposed to perturb neighborhood aggregation from node-importance-grain. Third, we propose to privately train a graph learning algorithm on perturbed aggregations in adaptive residual connection mode over multi-layers convolution for node-wise tasks. Theoretically analysis shows that NAP-GNN satisfies privacy guarantees. Empirical experiments over real-world graph datasets show that NAP-GNN achieves a better trade-off between privacy and accuracy.
</details>
<details>
<summary>摘要</summary>
GRAPH NEURAL NETWORKS (GNNs) with differential privacy have been proposed to protect graph privacy when nodes represent personal and sensitive information. However, existing methods ignore that nodes with different importance may have different privacy demands, which may lead to over-protecting some nodes and decreasing model utility. In this paper, we study the problem of importance-grained privacy, where nodes contain personal data that needs to be kept private but are critical for training a GNN. We propose NAP-GNN, a node-importance-grained privacy-preserving GNN algorithm with privacy guarantees based on adaptive differential privacy to safeguard node information. First, we propose a Topology-based Node Importance Estimation (TNIE) method to infer unknown node importance with neighborhood and centrality awareness. Second, an adaptive private aggregation method is proposed to perturb neighborhood aggregation from node-importance-grain. Third, we propose to privately train a graph learning algorithm on perturbed aggregations in adaptive residual connection mode over multi-layers convolution for node-wise tasks. Theoretically analysis shows that NAP-GNN satisfies privacy guarantees. Empirical experiments over real-world graph datasets show that NAP-GNN achieves a better trade-off between privacy and accuracy.
</details></li>
</ul>
<hr>
<h2 id="Analyzing-the-Effect-of-Data-Impurity-on-the-Detection-Performances-of-Mental-Disorders"><a href="#Analyzing-the-Effect-of-Data-Impurity-on-the-Detection-Performances-of-Mental-Disorders" class="headerlink" title="Analyzing the Effect of Data Impurity on the Detection Performances of Mental Disorders"></a>Analyzing the Effect of Data Impurity on the Detection Performances of Mental Disorders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05133">http://arxiv.org/abs/2308.05133</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rohan Kumar Gupta, Rohit Sinha</li>
<li>for: 本研究旨在提高主要用于自动诊断精神疾病的方法的准确性。</li>
<li>methods: 本研究使用了一种新的方法，即从抽象特征空间中提取特定精神疾病的特征，以提高诊断的准确性。</li>
<li>results: 研究发现，通过去除数据杂质，可以显著提高主动神疾病和剂量精神疾病的诊断性能。<details>
<summary>Abstract</summary>
The primary method for identifying mental disorders automatically has traditionally involved using binary classifiers. These classifiers are trained using behavioral data obtained from an interview setup. In this training process, data from individuals with the specific disorder under consideration are categorized as the positive class, while data from all other participants constitute the negative class. In practice, it is widely recognized that certain mental disorders share similar symptoms, causing the collected behavioral data to encompass a variety of attributes associated with multiple disorders. Consequently, attributes linked to the targeted mental disorder might also be present within the negative class. This data impurity may lead to sub-optimal training of the classifier for a mental disorder of interest. In this study, we investigate this hypothesis in the context of major depressive disorder (MDD) and post-traumatic stress disorder detection (PTSD). The results show that upon removal of such data impurity, MDD and PTSD detection performances are significantly improved.
</details>
<details>
<summary>摘要</summary>
主要方法用于自动诊断心理疾病traditionally involve使用二分类器。这些分类器通过使用面试设置收集的行为数据进行训练。在这个训练过程中，患有Specific mental disorder的数据被分类为正样本，而所有其他参与者的数据被分类为负样本。在实践中，一些心理疾病会表现相似的症状，导致收集的行为数据包含多种与多种疾病相关的特征。因此，与targeted mental disorder相关的特征可能会存在在负样本中。这种数据杂质可能会导致分类器的训练不优化。在这项研究中，我们 investigate这个假设在主要抑郁症(MDD)和创后应急压力反应症(PTSD)检测方面。结果显示，在移除数据杂质后，MDD和PTSD检测性能得到了显著改善。
</details></li>
</ul>
<hr>
<h2 id="An-In-Depth-Analysis-of-Discretization-Methods-for-Communication-Learning-using-Backpropagation-with-Multi-Agent-Reinforcement-Learning"><a href="#An-In-Depth-Analysis-of-Discretization-Methods-for-Communication-Learning-using-Backpropagation-with-Multi-Agent-Reinforcement-Learning" class="headerlink" title="An In-Depth Analysis of Discretization Methods for Communication Learning using Backpropagation with Multi-Agent Reinforcement Learning"></a>An In-Depth Analysis of Discretization Methods for Communication Learning using Backpropagation with Multi-Agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04938">http://arxiv.org/abs/2308.04938</a></li>
<li>repo_url: None</li>
<li>paper_authors: Astrid Vanneste, Simon Vanneste, Kevin Mets, Tom De Schepper, Siegfried Mercelis, Peter Hellinckx</li>
<li>for: 这个论文的目的是比较不同的某些方法在多智能人工智能学习中的表现，以及一种基于 DIAL 和 COMA 的通信学习方法的实现。</li>
<li>methods: 这个论文使用的方法包括多种常见的某些方法，以及一种新的方法 named ST-DRU。</li>
<li>results: 论文的结果表明，ST-DRU 方法在不同环境中的表现最佳，它在每个实验中都达到了最佳或非常接近最佳性能，而且是唯一不会在任何环境中失败的方法。<details>
<summary>Abstract</summary>
Communication is crucial in multi-agent reinforcement learning when agents are not able to observe the full state of the environment. The most common approach to allow learned communication between agents is the use of a differentiable communication channel that allows gradients to flow between agents as a form of feedback. However, this is challenging when we want to use discrete messages to reduce the message size, since gradients cannot flow through a discrete communication channel. Previous work proposed methods to deal with this problem. However, these methods are tested in different communication learning architectures and environments, making it hard to compare them. In this paper, we compare several state-of-the-art discretization methods as well as a novel approach. We do this comparison in the context of communication learning using gradients from other agents and perform tests on several environments. In addition, we present COMA-DIAL, a communication learning approach based on DIAL and COMA extended with learning rate scaling and adapted exploration. Using COMA-DIAL allows us to perform experiments on more complex environments. Our results show that the novel ST-DRU method, proposed in this paper, achieves the best results out of all discretization methods across the different environments. It achieves the best or close to the best performance in each of the experiments and is the only method that does not fail on any of the tested environments.
</details>
<details>
<summary>摘要</summary>
互动是多智能算法学习中非常重要的一环，当机器人无法观察环境的全部状态时。通常，使得学习得到的通信频道是使用可微分的通信频道，让条件gradient流过到每个机器人作为回传的形式。但是，当使用类型为码的讯息时，条件gradient无法流过这种通信频道。先前的工作已经提出了解决这个问题的方法，但是这些方法在不同的通信学习架构和环境中进行 tested，使得比较困难。在这篇文章中，我们比较了多个现有的码化方法，以及一个新的方法。我们将这些比较在通信学习中使用其他机器人的条件gradient进行tests，并在多个环境中进行试验。此外，我们还提出了COMA-DIAL，一种基于DIAL和COMA扩展的通信学习方法，并将其与学习速率调整和适应性探索相结合。这使得我们能够在更复杂的环境中进行实验。我们的结果显示，这篇文章中所提出的新方法ST-DRU，在不同的环境中都能够取得最佳或接近最佳的表现。它在每个实验中都能够取得最好或接近最好的结果，并且是唯一不会在任何测试环境中失败的方法。
</details></li>
</ul>
<hr>
<h2 id="JEDI-Joint-Expert-Distillation-in-a-Semi-Supervised-Multi-Dataset-Student-Teacher-Scenario-for-Video-Action-Recognition"><a href="#JEDI-Joint-Expert-Distillation-in-a-Semi-Supervised-Multi-Dataset-Student-Teacher-Scenario-for-Video-Action-Recognition" class="headerlink" title="JEDI: Joint Expert Distillation in a Semi-Supervised Multi-Dataset Student-Teacher Scenario for Video Action Recognition"></a>JEDI: Joint Expert Distillation in a Semi-Supervised Multi-Dataset Student-Teacher Scenario for Video Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04934">http://arxiv.org/abs/2308.04934</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lucian Bicsi, Bogdan Alexe, Radu Tudor Ionescu, Marius Leordeanu</li>
<li>for: 提高机器学习模型的总体性和精度，使其能够在不同数据集上进行更好的推断。</li>
<li>methods: 使用多个数据集的semi-supervised学习方法，通过将多个专家模型（每个专家模型在自己的数据集上进行预训练） concatenate 得到更多的特征表示，并通过学生-教师模式进行同时协同训练，以提高模型的泛化能力和精度。</li>
<li>results: 在四个视频动作识别数据集上进行验证，实验结果表明，在同时考虑所有数据集的semi-supervised学习 Setting下，模型可以获得显著的提升，比起初始专家模型。<details>
<summary>Abstract</summary>
We propose JEDI, a multi-dataset semi-supervised learning method, which efficiently combines knowledge from multiple experts, learned on different datasets, to train and improve the performance of individual, per dataset, student models. Our approach achieves this by addressing two important problems in current machine learning research: generalization across datasets and limitations of supervised training due to scarcity of labeled data. We start with an arbitrary number of experts, pretrained on their own specific dataset, which form the initial set of student models. The teachers are immediately derived by concatenating the feature representations from the penultimate layers of the students. We then train all models in a student-teacher semi-supervised learning scenario until convergence. In our efficient approach, student-teacher training is carried out jointly and end-to-end, showing that both students and teachers improve their generalization capacity during training. We validate our approach on four video action recognition datasets. By simultaneously considering all datasets within a unified semi-supervised setting, we demonstrate significant improvements over the initial experts.
</details>
<details>
<summary>摘要</summary>
我们提出了JEDI方法，这是一种多个数据集半supervised学习方法，它能够有效地将多个专家知识 fusion，来提高每个数据集的学生模型性能。我们的方法解决了当前机器学习研究中的两个重要问题：数据集之间的泛化和监督学习数据的稀缺。我们从arbitrary数量的专家开始，先在自己specific dataset上预训练student模型，然后将专家转化为教师，并通过学生-教师半supervised学习方式进行训练，直到收敛。在我们的高效的方法中，学生-教师训练是joint和端到端的，这表明在训练过程中，学生和教师都会提高其泛化能力。我们在四个视频动作识别数据集上验证了我们的方法，并证明了在同时考虑所有数据集的半supervised Setting下，我们的方法能够实现显著的改进。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Based-Prediction-of-Fractional-Flow-Reserve-along-the-Coronary-Artery"><a href="#Deep-Learning-Based-Prediction-of-Fractional-Flow-Reserve-along-the-Coronary-Artery" class="headerlink" title="Deep Learning-Based Prediction of Fractional Flow Reserve along the Coronary Artery"></a>Deep Learning-Based Prediction of Fractional Flow Reserve along the Coronary Artery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04923">http://arxiv.org/abs/2308.04923</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nils Hampe, Sanne G. M. van Velzen, Jean-Paul Aben, Carlos Collet, Ivana Išgum</li>
<li>For: This paper aims to develop a deep learning-based method for predicting fractional flow reserve (FFR) values along the coronary arteries from coronary computed tomography angiography (CCTA) scans.* Methods: The proposed method uses a variational autoencoder to characterize the artery and a convolutional neural network (CNN) to predict the FFR values. The CNN is supervised by multiple loss functions, including a loss function inspired by the Earth Mover’s Distance (EMD) to predict the correct location of FFR drops and a histogram-based loss to explicitly supervise the slope of the FFR curve.* Results: The resulting FFR curves show good agreement with the reference, allowing the distinction between diffuse and focal coronary artery disease (CAD) distributions in most cases. The mean absolute difference in the area under the FFR pullback curve (AUPC) was 1.7.<details>
<summary>Abstract</summary>
Functionally significant coronary artery disease (CAD) is caused by plaque buildup in the coronary arteries, potentially leading to narrowing of the arterial lumen, i.e. coronary stenosis, that significantly obstructs blood flow to the myocardium. The current reference for establishing the presence of a functionally significant stenosis is invasive fractional flow reserve (FFR) measurement. To avoid invasive measurements, non-invasive prediction of FFR from coronary CT angiography (CCTA) has emerged. For this, machine learning approaches, characterized by fast inference, are increasingly developed. However, these methods predict a single FFR value per artery i.e. they don't provide information about the stenosis location or treatment strategy. We propose a deep learning-based method to predict the FFR along the artery from CCTA scans. This study includes CCTA images of 110 patients who underwent invasive FFR pullback measurement in 112 arteries. First, a multi planar reconstruction (MPR) of the artery is fed to a variational autoencoder to characterize the artery, i.e. through the lumen area and unsupervised artery encodings. Thereafter, a convolutional neural network (CNN) predicts the FFR along the artery. The CNN is supervised by multiple loss functions, notably a loss function inspired by the Earth Mover's Distance (EMD) to predict the correct location of FFR drops and a histogram-based loss to explicitly supervise the slope of the FFR curve. To train and evaluate our model, eight-fold cross-validation was performed. The resulting FFR curves show good agreement with the reference allowing the distinction between diffuse and focal CAD distributions in most cases. Quantitative evaluation yielded a mean absolute difference in the area under the FFR pullback curve (AUPC) of 1.7. The method may pave the way towards fast, accurate, automatic prediction of FFR along the artery from CCTA.
</details>
<details>
<summary>摘要</summary>
《 coronary artery disease （CAD）的功能 significative coronary artery （CA）病变是由 CA 内积累物质堆积，导致 CA 的 luminal 尺寸减小，从而导致 coronary stenosis ，对 myocardium 的血液流减少具有重要作用。目前，确定 CAD 存在功能 significative stenosis 的参照标准是非侵入性 fractional flow reserve （FFR）测量。为了避免非侵入性测量，非侵入性预测 CCTA 图像中的 FFR 已经出现。这些方法具有快速的推理功能，但它们只能预测每条 CA 的单个 FFR 值，无法提供条件尺寸或治疗策略信息。我们提出了基于 deep learning 的方法，可以从 CCTA 图像中预测 CA 的 FFR。这个研究包括 CCTA 图像的 110 例患者，其中每例包含 112 条 CA。首先，MPR 图像被 feed 到 variational autoencoder，以 caracterize the artery，包括 luminal 区域和不supervised artery 编码。然后，使用 convolutional neural network （CNN）预测 CA 的 FFR。CNN 被多个损失函数 supervise，包括一个取自 Earth Mover's Distance （EMD）的损失函数，以正确地预测 FFR 下降的位置，以及一个 histogram-based 损失函数，以直接监督 FFR 曲线的坡度。为了训练和评估我们的模型，我们使用 eight-fold cross-validation 进行了训练和评估。结果显示，我们的 FFR 曲线与参照标准之间有良好的一致性，可以在大多数情况下分辨 diffuse 和 focal CAD 分布。量化评估表明，AUPC 的平均绝对差为 1.7。这种方法可能将为 CCTA 图像中的 FFR 预测带来快速、准确、自动化的方法。
</details></li>
</ul>
<hr>
<h2 id="GraphCC-A-Practical-Graph-Learning-based-Approach-to-Congestion-Control-in-Datacenters"><a href="#GraphCC-A-Practical-Graph-Learning-based-Approach-to-Congestion-Control-in-Datacenters" class="headerlink" title="GraphCC: A Practical Graph Learning-based Approach to Congestion Control in Datacenters"></a>GraphCC: A Practical Graph Learning-based Approach to Congestion Control in Datacenters</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04905">http://arxiv.org/abs/2308.04905</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guillermo Bernárdez, José Suárez-Varela, Xiang Shi, Shihan Xiao, Xiangle Cheng, Pere Barlet-Ros, Albert Cabellos-Aparicio</li>
<li>for: 这个论文是为了优化数据中心网络（DCN）中的堵塞控制（CC）而写的。</li>
<li>methods: 这个论文使用了机器学习（ML）和图神经网络（GNN）来实现分布式的ECN配置优化。它在交换机上部署分布式代理，通过与邻居交换机通信，以协同优化全局ECN配置。</li>
<li>results: 在评估中，GraphCC在不同的场景下表现出色，特别是在新的场景下（例如新的吞吐量工作负荷、故障、升级）下显示出优于状态艺术CC（ACC）的性能，升减流程完成时间（FCRT）和缓冲占用率（BO）。改进率可达20%，并且在不同的评估场景下均显示出优异性能。<details>
<summary>Abstract</summary>
Congestion Control (CC) plays a fundamental role in optimizing traffic in Data Center Networks (DCN). Currently, DCNs mainly implement two main CC protocols: DCTCP and DCQCN. Both protocols -- and their main variants -- are based on Explicit Congestion Notification (ECN), where intermediate switches mark packets when they detect congestion. The ECN configuration is thus a crucial aspect on the performance of CC protocols. Nowadays, network experts set static ECN parameters carefully selected to optimize the average network performance. However, today's high-speed DCNs experience quick and abrupt changes that severely change the network state (e.g., dynamic traffic workloads, incast events, failures). This leads to under-utilization and sub-optimal performance. This paper presents GraphCC, a novel Machine Learning-based framework for in-network CC optimization. Our distributed solution relies on a novel combination of Multi-agent Reinforcement Learning (MARL) and Graph Neural Networks (GNN), and it is compatible with widely deployed ECN-based CC protocols. GraphCC deploys distributed agents on switches that communicate with their neighbors to cooperate and optimize the global ECN configuration. In our evaluation, we test the performance of GraphCC under a wide variety of scenarios, focusing on the capability of this solution to adapt to new scenarios unseen during training (e.g., new traffic workloads, failures, upgrades). We compare GraphCC with a state-of-the-art MARL-based solution for ECN tuning -- ACC -- and observe that our proposed solution outperforms the state-of-the-art baseline in all of the evaluation scenarios, showing improvements up to $20\%$ in Flow Completion Time as well as significant reductions in buffer occupancy ($38.0-85.7\%$).
</details>
<details>
<summary>摘要</summary>
压缩控制（CC）在数据中心网络（DCN）中扮演了基本角色，以优化网络吞吐量。目前，DCN主要实现了两种主要的 CC 协议：DCTCP 和 DCQCN。这两种协议都基于显式压缩通知（ECN）， intermediate switches 将包 WHEN 检测到压缩。因此，ECN 配置成为 CC 协议性能的关键因素。目前，网络专家通过手动设置ECN参数来优化网络性能。然而，今天的高速 DCN 经历了快速和突然变化，导致网络状态发生了剧烈变化（例如，动态流量负荷、广播事件、故障），这会导致网络资源的过度利用和低效性能。本文介绍了 GraphCC，一种基于机器学习的协议优化框架。我们的分布式解决方案基于多代理激励学习（MARL）和图神经网络（GNN），并与广泛部署的 ECN 基于 CC 协议相容。GraphCC 在 switches 上部署分布式代理，与其他 switches 通信以协调优化全局 ECN 配置。在我们的评估中，我们测试了 GraphCC 在多种场景下的性能，重点关注这种解决方案在新场景下（例如，新的流量负荷、故障、升级）未经训练时的可靠性。我们与 state-of-the-art MARL 基于 ECN 调试的解决方案（ACC）进行比较，并发现我们的提议的解决方案在所有评估场景中都高于 state-of-the-art 基线，实现了Flow Completion Time 的改进 ($20\%$) 以及显著减少缓存占用率（$38.0-85.7\%）。
</details></li>
</ul>
<hr>
<h2 id="Towards-true-discovery-of-the-differential-equations"><a href="#Towards-true-discovery-of-the-differential-equations" class="headerlink" title="Towards true discovery of the differential equations"></a>Towards true discovery of the differential equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04901">http://arxiv.org/abs/2308.04901</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/itmo-nss-team/klr2023_paper">https://github.com/itmo-nss-team/klr2023_paper</a></li>
<li>paper_authors: Alexander Hvatov, Roman Titov</li>
<li>for: 该论文旨在发展一种可解释性模型，特别是在自然相关领域。</li>
<li>methods: 该论文使用机器学习技术，特别是差分方程发现。</li>
<li>results: 该论文探讨了独立发现方程的前提和工具，并解决了评估发现的方程是否准确的挑战。<details>
<summary>Abstract</summary>
Differential equation discovery, a machine learning subfield, is used to develop interpretable models, particularly in nature-related applications. By expertly incorporating the general parametric form of the equation of motion and appropriate differential terms, algorithms can autonomously uncover equations from data. This paper explores the prerequisites and tools for independent equation discovery without expert input, eliminating the need for equation form assumptions. We focus on addressing the challenge of assessing the adequacy of discovered equations when the correct equation is unknown, with the aim of providing insights for reliable equation discovery without prior knowledge of the equation form.
</details>
<details>
<summary>摘要</summary>
differential equation发现，机器学习一个Subfield，用于开发可解释的模型，特别在自然相关应用中。通过专业地包含通用参数形式的动态方程和适当的分 diferencial项，算法可以自主发现方程从数据中。本文探讨无需专家输入的独立方程发现的前提和工具，消除方程形式假设的需求。我们专注于解决无法评估发现方程的正确性，当正确的方程未知时，提供可靠的方程发现无需先知方程形式的坚持。Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Unleashing-the-Power-of-Extra-Tree-Feature-Selection-and-Random-Forest-Classifier-for-Improved-Survival-Prediction-in-Heart-Failure-Patients"><a href="#Unleashing-the-Power-of-Extra-Tree-Feature-Selection-and-Random-Forest-Classifier-for-Improved-Survival-Prediction-in-Heart-Failure-Patients" class="headerlink" title="Unleashing the Power of Extra-Tree Feature Selection and Random Forest Classifier for Improved Survival Prediction in Heart Failure Patients"></a>Unleashing the Power of Extra-Tree Feature Selection and Random Forest Classifier for Improved Survival Prediction in Heart Failure Patients</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05765">http://arxiv.org/abs/2308.05765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md. Simul Hasan Talukder, Rejwan Bin Sulaiman, Mouli Bardhan Paul Angon</li>
<li>For: The paper aims to improve survival prediction in heart failure patients by leveraging data pre-processing techniques and the Extra-Tree (ET) feature selection method in conjunction with the Random Forest (RF) classifier.* Methods: The paper uses the public UCL Heart failure (HF) survival dataset and employs the ET feature selection algorithm to identify the most informative features. These features are then used as input for grid search of RF.* Results: The approach achieved 98.33% accuracy, which is the highest over existing work.Here’s the same information in Simplified Chinese text:* For: 这篇论文目标是提高心衰竭患者存活率预测，通过数据处理技术和Extra-Tree（ET）特征选择法和Random Forest（RF）分类器的结合。* Methods: 该论文使用公共的UCL心衰竭存活数据集，并使用ET特征选择算法选择最有用的特征。这些特征然后用于RF搜索。* Results: 方法实现了98.33%的准确率，超过了现有的工作。<details>
<summary>Abstract</summary>
Heart failure is a life-threatening condition that affects millions of people worldwide. The ability to accurately predict patient survival can aid in early intervention and improve patient outcomes. In this study, we explore the potential of utilizing data pre-processing techniques and the Extra-Tree (ET) feature selection method in conjunction with the Random Forest (RF) classifier to improve survival prediction in heart failure patients. By leveraging the strengths of ET feature selection, we aim to identify the most significant predictors associated with heart failure survival. Using the public UCL Heart failure (HF) survival dataset, we employ the ET feature selection algorithm to identify the most informative features. These features are then used as input for grid search of RF. Finally, the tuned RF Model was trained and evaluated using different matrices. The approach was achieved 98.33% accuracy that is the highest over the exiting work.
</details>
<details>
<summary>摘要</summary>
心力衰竭是一种生命威胁性的疾病，影响全球数百万人。可以准确预测患者存活可以提供早期干预，提高患者结果。在这项研究中，我们探讨了使用数据处理技术和Extra-Tree（ET）特征选择方法，与Random Forest（RF）分类器结合，以提高心力衰竭患者存活预测。通过利用ET特征选择算法，我们寻找了心力衰竭存活最重要的预测器。使用公共的UCL心力衰竭存活数据集，我们使用ET特征选择算法确定最有用的特征。这些特征然后用于网格搜索RF模型的调整。最后，我们使用调整后的RF模型进行训练和评估，并使用不同的矩阵进行测试。我们的方法实现了98.33%的准确率，这是目前已知的最高水平。
</details></li>
</ul>
<hr>
<h2 id="Targeted-and-Troublesome-Tracking-and-Advertising-on-Children’s-Websites"><a href="#Targeted-and-Troublesome-Tracking-and-Advertising-on-Children’s-Websites" class="headerlink" title="Targeted and Troublesome: Tracking and Advertising on Children’s Websites"></a>Targeted and Troublesome: Tracking and Advertising on Children’s Websites</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04887">http://arxiv.org/abs/2308.04887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zahra Moti, Asuman Senol, Hamid Bostani, Frederik Zuiderveen Borgesius, Veelasha Moonsamy, Arunesh Mathur, Gunes Acar<br>for:* The paper focuses on the measurement of tracking and targeted advertising on websites directed at children.methods:* The authors use a multilingual classifier based on web page titles and descriptions to identify child-directed websites.* They crawl these websites from five vantage points to measure the prevalence of trackers, fingerprinting scripts, and advertisements.* They develop an ML pipeline to identify improper ads on child-directed websites by processing both images and text extracted from ads.results:* The authors find that around 90% of child-directed websites embed one or more trackers, and about 27% contain targeted advertisements.* They identify improper ads on child-directed websites, including ads for dating, weight loss, and mental health, as well as sex toys and flirting chat services.* The authors conclude that there is a trend of non-compliance with privacy regulations and troubling ad safety practices among many advertisers and child-directed websites.<details>
<summary>Abstract</summary>
On the modern web, trackers and advertisers frequently construct and monetize users' detailed behavioral profiles without consent. Despite various studies on web tracking mechanisms and advertisements, there has been no rigorous study focusing on websites targeted at children. To address this gap, we present a measurement of tracking and (targeted) advertising on websites directed at children. Motivated by lacking a comprehensive list of child-directed (i.e., targeted at children) websites, we first build a multilingual classifier based on web page titles and descriptions. Applying this classifier to over two million pages, we compile a list of two thousand child-directed websites. Crawling these sites from five vantage points, we measure the prevalence of trackers, fingerprinting scripts, and advertisements. Our crawler detects ads displayed on child-directed websites and determines if ad targeting is enabled by scraping ad disclosure pages whenever available. Our results show that around 90% of child-directed websites embed one or more trackers, and about 27% contain targeted advertisements--a practice that should require verifiable parental consent. Next, we identify improper ads on child-directed websites by developing an ML pipeline that processes both images and text extracted from ads. The pipeline allows us to run semantic similarity queries for arbitrary search terms, revealing ads that promote services related to dating, weight loss, and mental health; as well as ads for sex toys and flirting chat services. Some of these ads feature repulsive and sexually explicit imagery. In summary, our findings indicate a trend of non-compliance with privacy regulations and troubling ad safety practices among many advertisers and child-directed websites. To protect children and create a safer online environment, regulators and stakeholders must adopt and enforce more stringent measures.
</details>
<details>
<summary>摘要</summary>
现代网络上，跟踪器和广告商频繁地构建和利用用户的详细行为 profiles 而不经过用户的同意。尽管有各种研究关于网络跟踪机制和广告，但有一个缺乏关于直接向儿童targeted的网站的研究。为了填补这一漏洞，我们提供了一项测量tracking和targeted广告在directed at children的网站上的研究。由于缺乏全面的child-directed（即直接向儿童）网站列表，我们首先创建了一个多语言分类器，基于网页标题和描述来分类。将这些分类器应用于超过两百万页，我们编译了两千个child-directed网站的列表。从五个视点爬取这些站点，我们测量了跟踪器、指纹脚本和广告的存在。我们的爬虫检测在child-directed网站上显示的广告，并判断是否启用了广告targeting，并从可用的广告披露页面中抓取相关信息。我们的结果表明大约90%的child-directed网站 embedding一个或多个跟踪器，而约27%的网站上显示了targeted广告，这些广告应该需要可靠的父母consent。然后，我们使用机器学习管道来识别在child-directed网站上显示的不当广告。这个管道可以处理图像和文本抽取自广告，并允许我们对任意搜索关键词进行 semanticsimilarity 查询，揭示了关于约束、减肥和心理健康的服务，以及性 Toy和情趣交流服务的广告。一些这些广告包含了伤害和性革命的图像。总之，我们的发现表明许多广告商和child-directed网站不遵守隐私法规和儿童在线环境的安全做法。为了保护儿童和创造一个更安全的网络环境，管理者和关注者必须采取和实施更加严格的措施。
</details></li>
</ul>
<hr>
<h2 id="Decorrelating-neurons-using-persistence"><a href="#Decorrelating-neurons-using-persistence" class="headerlink" title="Decorrelating neurons using persistence"></a>Decorrelating neurons using persistence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04870">http://arxiv.org/abs/2308.04870</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rballeba/decorrelatingneuronsusingpersistence">https://github.com/rballeba/decorrelatingneuronsusingpersistence</a></li>
<li>paper_authors: Rubén Ballester, Carles Casacuberta, Sergio Escalera</li>
<li>For: 提高深度学习模型的通用化能力* Methods: 使用 minimum spanning tree 计算 neuron 之间的 correlation dissimilarities，并使用这些误差来减少 neuron 之间的高相关性* Results: 比较 popular 误差函数，并证明了自己的效果，以及在不同的深度学习任务中的可应用性。Here’s the full translation of the paper’s abstract in Simplified Chinese:* For: 本文提出了一种新的方法，用于提高深度学习模型的通用化能力。* Methods: 该方法基于 minimum spanning tree 计算 neuron 之间的 correlation dissimilarities，并使用这些误差来减少 neuron 之间的高相关性。* Results: 比较 popular 误差函数，并证明了自己的效果，以及在不同的深度学习任务中的可应用性。<details>
<summary>Abstract</summary>
We propose a novel way to improve the generalisation capacity of deep learning models by reducing high correlations between neurons. For this, we present two regularisation terms computed from the weights of a minimum spanning tree of the clique whose vertices are the neurons of a given network (or a sample of those), where weights on edges are correlation dissimilarities. We provide an extensive set of experiments to validate the effectiveness of our terms, showing that they outperform popular ones. Also, we demonstrate that naive minimisation of all correlations between neurons obtains lower accuracies than our regularisation terms, suggesting that redundancies play a significant role in artificial neural networks, as evidenced by some studies in neuroscience for real networks. We include a proof of differentiability of our regularisers, thus developing the first effective topological persistence-based regularisation terms that consider the whole set of neurons and that can be applied to a feedforward architecture in any deep learning task such as classification, data generation, or regression.
</details>
<details>
<summary>摘要</summary>
我团队提出了一种新的方法，用于提高深度学习模型的泛化能力，通过减少神经元之间的高相关性。我们提出了两种正则化项，其计算基于某个神经网络（或一个样本）中神经元之间的最小拓扑树，其边的权重是神经元之间的相关性差异。我们提供了广泛的实验，证明了我们的正则化项的有效性，并表明它们超过了popular ones。此外，我们还证明了直接对所有神经元之间的相关性进行最小化，会导致较低的准确率，这表明了人工神经网络中的约束扮演了重要的角色，这与一些 neuroscience 研究中的真实神经网络一致。我们还提供了正则化项的导函数整合，这是首次开发了考虑整个神经元集的 topological persistence 基于的有效正则化项，可以应用于任何深度学习任务，如分类、数据生成或回归。
</details></li>
</ul>
<hr>
<h2 id="Are-Sex-based-Physiological-Differences-the-Cause-of-Gender-Bias-for-Chest-X-ray-Diagnosis"><a href="#Are-Sex-based-Physiological-Differences-the-Cause-of-Gender-Bias-for-Chest-X-ray-Diagnosis" class="headerlink" title="Are Sex-based Physiological Differences the Cause of Gender Bias for Chest X-ray Diagnosis?"></a>Are Sex-based Physiological Differences the Cause of Gender Bias for Chest X-ray Diagnosis?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05129">http://arxiv.org/abs/2308.05129</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nina Weng, Siavash Bigdeli, Eike Petersen, Aasa Feragen</li>
<li>for: 这个研究旨在探讨胸部X射线诊断预测性差异的原因。</li>
<li>methods: 我们提出了一种新的采样方法，以减少数据集中每个患者的记录数量的不均衡分布，同时减少标签错误的影响。</li>
<li>results: 我们的分析发现，数据集特有的因素，而不是基本的生理差异，是胸部X射线预测性差异的主要驱动者。<details>
<summary>Abstract</summary>
While many studies have assessed the fairness of AI algorithms in the medical field, the causes of differences in prediction performance are often unknown. This lack of knowledge about the causes of bias hampers the efficacy of bias mitigation, as evidenced by the fact that simple dataset balancing still often performs best in reducing performance gaps but is unable to resolve all performance differences. In this work, we investigate the causes of gender bias in machine learning-based chest X-ray diagnosis. In particular, we explore the hypothesis that breast tissue leads to underexposure of the lungs and causes lower model performance. Methodologically, we propose a new sampling method which addresses the highly skewed distribution of recordings per patient in two widely used public datasets, while at the same time reducing the impact of label errors. Our comprehensive analysis of gender differences across diseases, datasets, and gender representations in the training set shows that dataset imbalance is not the sole cause of performance differences. Moreover, relative group performance differs strongly between datasets, indicating important dataset-specific factors influencing male/female group performance. Finally, we investigate the effect of breast tissue more specifically, by cropping out the breasts from recordings, finding that this does not resolve the observed performance gaps. In conclusion, our results indicate that dataset-specific factors, not fundamental physiological differences, are the main drivers of male--female performance gaps in chest X-ray analyses on widely used NIH and CheXpert Dataset.
</details>
<details>
<summary>摘要</summary>
虽然许多研究已经评估了人工智能算法在医疗领域的公平性，但对差异的预测性表现的原因 часто不明确。这种不知道偏误的原因使得偏误缓解无法具有最佳效果，如果只是通过简单的数据平衡来减少性能差异。在这项工作中，我们调查了机器学习基于胸部X光图像的性别偏误。我们尝试了一种新的采样方法，以解决两个公共数据集中每个病人记录的极度不均衡的问题，同时减少标签错误的影响。我们对男女之间疾病、数据集和训练集中的性别表现进行了广泛的分析，发现数据集不均衡不是差异的唯一原因。此外，不同数据集中男女组的表现差异很大，这表明数据集特有的因素对男女组的表现产生了重要影响。最后，我们尝试了更 specifically investigate the effect of breast tissue, by cropping out the breasts from the recordings, but found that this did not resolve the observed performance gaps.  conclude, our results indicate that dataset-specific factors, rather than fundamental physiological differences, are the main drivers of male-female performance gaps in chest X-ray analyses on the widely used NIH and CheXpert Dataset.
</details></li>
</ul>
<hr>
<h2 id="Scalability-of-Message-Encoding-Techniques-for-Continuous-Communication-Learned-with-Multi-Agent-Reinforcement-Learning"><a href="#Scalability-of-Message-Encoding-Techniques-for-Continuous-Communication-Learned-with-Multi-Agent-Reinforcement-Learning" class="headerlink" title="Scalability of Message Encoding Techniques for Continuous Communication Learned with Multi-Agent Reinforcement Learning"></a>Scalability of Message Encoding Techniques for Continuous Communication Learned with Multi-Agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04844">http://arxiv.org/abs/2308.04844</a></li>
<li>repo_url: None</li>
<li>paper_authors: Astrid Vanneste, Thomas Somers, Simon Vanneste, Kevin Mets, Tom De Schepper, Siegfried Mercelis, Peter Hellinckx</li>
<li>for: 本研究探讨了多 Agent 系统中 Agent 之间的交流如何影响系统的目标 достиvement。通过学习多 Agent 学习策略， Agent 可以 deterministic 地决定需要交换哪些信息。</li>
<li>methods: 本研究使用了多 Agent 强化学习技术，并 investigate 了不同的信息编码方法（mean message encoder 和 attention message encoder）在不同数量的 Agent 中的影响。</li>
<li>results: 结果表明，在大量 Agent 中，mean message encoder 一直表现出色，superior 于 attention message encoder。研究发现，使用 mean message encoder 的 Agent 采用了一种组合 exponential 和 logarithmic 函数的通信策略，以避免信息损失。<details>
<summary>Abstract</summary>
Many multi-agent systems require inter-agent communication to properly achieve their goal. By learning the communication protocol alongside the action protocol using multi-agent reinforcement learning techniques, the agents gain the flexibility to determine which information should be shared. However, when the number of agents increases we need to create an encoding of the information contained in these messages. In this paper, we investigate the effect of increasing the amount of information that should be contained in a message and increasing the number of agents. We evaluate these effects on two different message encoding methods, the mean message encoder and the attention message encoder. We perform our experiments on a matrix environment. Surprisingly, our results show that the mean message encoder consistently outperforms the attention message encoder. Therefore, we analyse the communication protocol used by the agents that use the mean message encoder and can conclude that the agents use a combination of an exponential and a logarithmic function in their communication policy to avoid the loss of important information after applying the mean message encoder.
</details>
<details>
<summary>摘要</summary>
多个自动机制系统需要间接通信以实现目标。通过同时学习动作协议和通信协议使用多自动学习技术，代理人获得了自定义信息共享的灵活性。然而，当代理人数量增加时，我们需要创建消息中信息的编码。在这篇论文中，我们研究了增加消息中信息量和代理人数量的效果，并对两种消息编码方法进行评估：平均消息编码器和注意消息编码器。我们在矩阵环境中进行实验，结果显示，平均消息编码器一直表现出色，超过注意消息编码器。因此，我们分析了使用平均消息编码器的通信协议中的代理人们使用的函数，并结论这些函数是一种对抗函数和对数函数的组合，以避免在应用平均消息编码器后失去重要信息。
</details></li>
</ul>
<hr>
<h2 id="Unlocking-the-Diagnostic-Potential-of-ECG-through-Knowledge-Transfer-from-Cardiac-MRI"><a href="#Unlocking-the-Diagnostic-Potential-of-ECG-through-Knowledge-Transfer-from-Cardiac-MRI" class="headerlink" title="Unlocking the Diagnostic Potential of ECG through Knowledge Transfer from Cardiac MRI"></a>Unlocking the Diagnostic Potential of ECG through Knowledge Transfer from Cardiac MRI</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05764">http://arxiv.org/abs/2308.05764</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/oetu/mmcl-ecg-cmr">https://github.com/oetu/mmcl-ecg-cmr</a></li>
<li>paper_authors: Özgün Turgut, Philip Müller, Paul Hager, Suprosanna Shit, Sophie Starck, Martin J. Menten, Eimo Martens, Daniel Rueckert</li>
<li>For: 这篇研究旨在提供一种免费和快速的心脏健康评估工具，并将详细的心脏诊断换到更加昂贵的心脏磁共振成像（CMR）成像中。* Methods: 这篇研究提出了第一个自我超vised contrastive方法，将频率域图像与CMR图像的领域专有信息转移到ECG嵌入中。这个方法结合多modal contrastive learning和封页数据模型，实现单个ECG数据的全面心脏检查。* Results: 在对40,044名UK BiobankSubject进行了广泛的实验之后，我们展示了我们的方法的实用性和普遍性。我们预测各个心脏疾病的Subject-specific预后，并从ECG数据中分类出不同的心脏型态。在质感分析中，我们显示了我们学习的ECG嵌入包含了CMR图像区域的信息。我们将整个数据pipeline公开供下载，包括源代码和预读模型的重量。<details>
<summary>Abstract</summary>
The electrocardiogram (ECG) is a widely available diagnostic tool that allows for a cost-effective and fast assessment of the cardiovascular health. However, more detailed examination with expensive cardiac magnetic resonance (CMR) imaging is often preferred for the diagnosis of cardiovascular diseases. While providing detailed visualization of the cardiac anatomy, CMR imaging is not widely available due to long scan times and high costs. To address this issue, we propose the first self-supervised contrastive approach that transfers domain-specific information from CMR images to ECG embeddings. Our approach combines multimodal contrastive learning with masked data modeling to enable holistic cardiac screening solely from ECG data. In extensive experiments using data from 40,044 UK Biobank subjects, we demonstrate the utility and generalizability of our method. We predict the subject-specific risk of various cardiovascular diseases and determine distinct cardiac phenotypes solely from ECG data. In a qualitative analysis, we demonstrate that our learned ECG embeddings incorporate information from CMR image regions of interest. We make our entire pipeline publicly available, including the source code and pre-trained model weights.
</details>
<details>
<summary>摘要</summary>
电导gram (ECG) 是一种广泛可用的诊断工具，可以快速和Cost-effectively评估心血管健康。然而，详细的检查通常使用昂贵的心血管共振成像 (CMR) 图像进行诊断心血管疾病。虽然提供了详细的心血管解剖结构图像，但CMR成像因为长时间扫描和高成本而不太常用。为解决这个问题，我们提出了第一个自动学习对抗方法，将域特定信息从 CMR 图像传递到 ECG 嵌入。我们的方法结合多modal对抗学习和遮盖数据模型，以实现唯一从 ECG 数据进行全面卡ди亚层检查。在使用40044名UK Biobank参与者的数据进行广泛实验中，我们证明了我们的方法的实用性和普适性。我们预测参与者特定的各种心血管疾病的风险，并通过分析发现了具有不同心血管特征的卡ди亚。在质量分析中，我们发现我们学习的 ECG 嵌入包含 CMR 图像区域兴趣的信息。我们将整个管道公开，包括源代码和预训练模型参数。
</details></li>
</ul>
<hr>
<h2 id="Intrinsic-Motivation-via-Surprise-Memory"><a href="#Intrinsic-Motivation-via-Surprise-Memory" class="headerlink" title="Intrinsic Motivation via Surprise Memory"></a>Intrinsic Motivation via Surprise Memory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04836">http://arxiv.org/abs/2308.04836</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/opendilab/DI-engine">https://github.com/opendilab/DI-engine</a></li>
<li>paper_authors: Hung Le, Kien Do, Dung Nguyen, Svetha Venkatesh</li>
<li>for: 这种新的计算模型旨在解决现有的惊喜驱动的探索限制，即使用novelty的惊喜而不是惊喜的 норма来计算奖励。</li>
<li>methods: 我们使用一个记忆网络来存储和重建惊喜，并且使用这个记忆来估计惊喜的新鲜度。</li>
<li>results: 我们的实验表明，将这种记忆网络与不同的惊喜预测器结合使用可以提高探索行为的效率并提高终极性表现，包括雷达、导航和困难的Atari游戏。Is that what you were looking for?<details>
<summary>Abstract</summary>
We present a new computing model for intrinsic rewards in reinforcement learning that addresses the limitations of existing surprise-driven explorations. The reward is the novelty of the surprise rather than the surprise norm. We estimate the surprise novelty as retrieval errors of a memory network wherein the memory stores and reconstructs surprises. Our surprise memory (SM) augments the capability of surprise-based intrinsic motivators, maintaining the agent's interest in exciting exploration while reducing unwanted attraction to unpredictable or noisy observations. Our experiments demonstrate that the SM combined with various surprise predictors exhibits efficient exploring behaviors and significantly boosts the final performance in sparse reward environments, including Noisy-TV, navigation and challenging Atari games.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的计算模型，用于激励学习中的内在奖励，以解决现有的惊喜驱动探索的局限性。我们的奖励是惊喜的新鲜度，而不是惊喜的平均值。我们使用记忆网络来估计惊喜的新鲜度，并称之为惊喜记忆（SM）。我们的SM可以增强惊喜基于内在动机的能力，使机器人保持有趣的探索，同时减少不必要的吸引到不可预测或噪音观察的情况。我们的实验表明，SM结合不同的惊喜预测器可以实现高效的探索行为，并在稀有奖励环境中显著提高最终性能，包括噪音电视、导航和复杂的Atari游戏。
</details></li>
</ul>
<hr>
<h2 id="TSSR-A-Truncated-and-Signed-Square-Root-Activation-Function-for-Neural-Networks"><a href="#TSSR-A-Truncated-and-Signed-Square-Root-Activation-Function-for-Neural-Networks" class="headerlink" title="TSSR: A Truncated and Signed Square Root Activation Function for Neural Networks"></a>TSSR: A Truncated and Signed Square Root Activation Function for Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04832">http://arxiv.org/abs/2308.04832</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanhao Gong</li>
<li>for: 提高神经网络的数值稳定性</li>
<li>methods: 提出了一种新的活化函数called Truncated and Signed Square Root (TSSR)函数</li>
<li>results: TSSR函数在各种应用领域中表现出色，比如计算机视觉、自然语言处理和语音识别等。<details>
<summary>Abstract</summary>
Activation functions are essential components of neural networks. In this paper, we introduce a new activation function called the Truncated and Signed Square Root (TSSR) function. This function is distinctive because it is odd, nonlinear, monotone and differentiable. Its gradient is continuous and always positive. Thanks to these properties, it has the potential to improve the numerical stability of neural networks. Several experiments confirm that the proposed TSSR has better performance than other stat-of-the-art activation functions. The proposed function has significant implications for the development of neural network models and can be applied to a wide range of applications in fields such as computer vision, natural language processing, and speech recognition.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate the following text into Simplified Chinese<</SYS>> activation functions are crucial components of neural networks. In this paper, we introduce a new activation function called the Truncated and Signed Square Root (TSSR) function. This function is unique because it is odd, nonlinear, monotone, and differentiable. Its gradient is continuous and always positive. Thanks to these properties, it has the potential to improve the numerical stability of neural networks. Several experiments confirm that the proposed TSSR has better performance than other state-of-the-art activation functions. The proposed function has significant implications for the development of neural network models and can be applied to a wide range of applications in fields such as computer vision, natural language processing, and speech recognition.Here's the translation:<<SYS>>翻译以下文本为简化字典<</SYS>>激活函数是神经网络中重要的组件。在这篇论文中，我们介绍了一种新的激活函数，即 truncated and signed square root（TSSR）函数。这个函数是独特的，因为它是奇数，非线性，卷积和导数满是 monotone。其导数是连续的，总是正的。由于这些性质，它有可能改善神经网络的数值稳定性。几个实验证明，我们提出的 TSSR 函数在其他现有的激活函数中表现更好。该函数有广泛应用的前景，可以应用于计算机视觉、自然语言处理和语音识别等领域。
</details></li>
</ul>
<hr>
<h2 id="On-the-Unexpected-Abilities-of-Large-Language-Models"><a href="#On-the-Unexpected-Abilities-of-Large-Language-Models" class="headerlink" title="On the Unexpected Abilities of Large Language Models"></a>On the Unexpected Abilities of Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.09720">http://arxiv.org/abs/2308.09720</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stefano Nolfi</li>
<li>for: 这篇论文探讨大语言模型display的多种能力，包括预测人写的下一句文本。</li>
<li>methods: 论文使用了 indirect acquisition process 和其他已知的 indirect processes。</li>
<li>results: 论文 argued that large language models develop integrated abilities as a side effect of indirect acquisition, and discussed the predictability of these abilities. Additionally, the paper briefly discussed the relation between the cognitive skills acquired by these systems and human cognition.<details>
<summary>Abstract</summary>
Large language models are capable of displaying a wide range of abilities that are not directly connected with the task for which they are trained: predicting the next words of human-written texts. In this article, I discuss the nature of this indirect acquisition process and its relation to other known indirect processes. I argue that an important side effect of such indirect acquisition is the development of integrated abilities. I discuss the extent to which the abilities developed by large language models are predictable. Finally, I briefly discuss the relation between the cognitive skills acquired by these systems and human cognition.
</details>
<details>
<summary>摘要</summary>
大型语言模型可以显示广泛的能力，而这些能力与它们所训练的任务没有直接的连接：预测人类写成的文本中的下一句。在这篇文章中，我讨论这种 indirect acquisition 过程的本质和其他已知 indirect process 之间的关系。我认为大型语言模型通过 indirect acquisition 过程中获得的能力具有一定的可预测性。最后，我 briefly discuss 这些系统所获得的认知技能与人类认知之间的关系。
</details></li>
</ul>
<hr>
<h2 id="Bayes-Risk-Consistency-of-Nonparametric-Classification-Rules-for-Spike-Trains-Data"><a href="#Bayes-Risk-Consistency-of-Nonparametric-Classification-Rules-for-Spike-Trains-Data" class="headerlink" title="Bayes Risk Consistency of Nonparametric Classification Rules for Spike Trains Data"></a>Bayes Risk Consistency of Nonparametric Classification Rules for Spike Trains Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04796">http://arxiv.org/abs/2308.04796</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mirosław Pawlak, Mateusz Pabian, Dominik Rzepka</li>
<li>for: 这篇论文针对 Computational neuroscience, imaging, streaming data 和 finance 中的脉冲讯号数据进行应用，采用不同的神经网络和概率模型。</li>
<li>methods: 这篇论文使用了机器学习策略，将脉冲讯号数据分类为二分类问题，并使用非Parametric kernel classifier 来构建模型。</li>
<li>results: 论文提出了一个具有极限性的 Bayes 规则，并证明了这个规则在不断增加的录音时间间隔和训练集大小下的数据采样中的测度。<details>
<summary>Abstract</summary>
Spike trains data find a growing list of applications in computational neuroscience, imaging, streaming data and finance. Machine learning strategies for spike trains are based on various neural network and probabilistic models. The probabilistic approach is relying on parametric or nonparametric specifications of the underlying spike generation model. In this paper we consider the two-class statistical classification problem for a class of spike train data characterized by nonparametrically specified intensity functions. We derive the optimal Bayes rule and next form the plug-in nonparametric kernel classifier. Asymptotical properties of the rules are established including the limit with respect to the increasing recording time interval and the size of a training set. In particular the convergence of the kernel classifier to the Bayes rule is proved. The obtained results are supported by a finite sample simulation studies.
</details>
<details>
<summary>摘要</summary>
射频训练数据在计算神经科学、成像、流动数据和金融等领域发现了广泛的应用。机器学习策略 для射频训练基于各种神经网络和概率模型。 probabilistic 方法取决于射频训练模型的参数或非参数规定。本文考虑一类具有非参数强度函数的射频训练数据的两类统计分类问题。我们 derivation 出最优的 bayes 规则，然后形成插入非参数核函数分类器。我们证明了核函数分类器的极限性，包括记录时间间隔的增长和训练集大小的限制。特别是，我们证明了核函数分类器的极限性和 bayes 规则的同强性。获得的结果得到了finite sample 伪验的支持。
</details></li>
</ul>
<hr>
<h2 id="PETformer-Long-term-Time-Series-Forecasting-via-Placeholder-enhanced-Transformer"><a href="#PETformer-Long-term-Time-Series-Forecasting-via-Placeholder-enhanced-Transformer" class="headerlink" title="PETformer: Long-term Time Series Forecasting via Placeholder-enhanced Transformer"></a>PETformer: Long-term Time Series Forecasting via Placeholder-enhanced Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04791">http://arxiv.org/abs/2308.04791</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shengsheng Lin, Weiwei Lin, Wentai Wu, Songbo Wang, Yongxiang Wang</li>
<li>For: This paper aims to improve the performance of Transformer-based models in long-term time series forecasting (LTSF) tasks by addressing three key issues: temporal continuity, information density, and multi-channel relationships.* Methods: The proposed model, called PETformer, uses three innovative techniques: Placeholder Enhancement Technique (PET), Long Sub-sequence Division (LSD), and Multi-channel Separation and Interaction (MSI) to introduce prior biases suitable for LTSF tasks.* Results: The proposed PETformer model achieves state-of-the-art (SOTA) performance on eight commonly used public datasets for LTSF, outperforming all other models currently available. This demonstrates that Transformer still possesses powerful capabilities in LTSF.Here’s the Chinese version of the information points:* For: 这篇论文目的是提高Transformer基于模型在长期时间序预测（LTSF）任务中的表现，通过解决三个关键问题：时间连续性、信息密度和多通道关系。* Methods: 提议的模型被称为PETformer，使用了三种创新的技术：Placeholder Enhancement Technique（PET）、Long Sub-sequence Division（LSD）和Multi-channel Separation and Interaction（MSI），以引入适合LTSF任务的先验偏好。* Results: PETformer模型在八个常用的公共数据集上达到了状态之最（SOTA）的表现，比其他所有现有的模型都高。这表明Transformer仍然在LTSF中具有强大的能力。<details>
<summary>Abstract</summary>
Recently, Transformer-based models have shown remarkable performance in long-term time series forecasting (LTSF) tasks due to their ability to model long-term dependencies. However, the validity of Transformers for LTSF tasks remains debatable, particularly since recent work has shown that simple linear models can outperform numerous Transformer-based approaches. This suggests that there are limitations to the application of Transformer in LTSF. Therefore, this paper investigates three key issues when applying Transformer to LTSF: temporal continuity, information density, and multi-channel relationships. Accordingly, we propose three innovative solutions, including Placeholder Enhancement Technique (PET), Long Sub-sequence Division (LSD), and Multi-channel Separation and Interaction (MSI), which together form a novel model called PETformer. These three key designs introduce prior biases suitable for LTSF tasks. Extensive experiments have demonstrated that PETformer achieves state-of-the-art (SOTA) performance on eight commonly used public datasets for LTSF, outperforming all other models currently available. This demonstrates that Transformer still possesses powerful capabilities in LTSF.
</details>
<details>
<summary>摘要</summary>
Translation notes:1. "long-term time series forecasting" (LTSF) is translated as "长期时间序列预测" (Chángzhòng Shíjiàn Shílián Yùjian)2. "Transformer-based models" is translated as "基于Transformer的模型" (Jīyuè Transformer de Módeli)3. "simple linear models" is translated as "简单的线性模型" (Jìnduan de Língxíng Módeli)4. "prior biases" is translated as "先前的偏见" (Xiānqián de Péndiǎn)5. "Placeholder Enhancement Technique" is translated as "占位提升技术" (Jǐwèi Tiēshén Jìhuà)6. "Long Sub-sequence Division" is translated as "长 subsequences 分解" (Cháng Subseqences Fēnjiě)7. "Multi-channel Separation and Interaction" is translated as "多通道分离和互动" (Duō Tōngdào Fēnlíng Héhuìdòng)8. "novel model" is translated as "新型模型" (Xīn Xíng Módeli)9. "state-of-the-art" is translated as "现状最佳" (Xiànzhèng Zàiqiào)10. "outperforming" is translated as "超越" (Chāoyù)
</details></li>
</ul>
<hr>
<h2 id="SUnAA-Sparse-Unmixing-using-Archetypal-Analysis"><a href="#SUnAA-Sparse-Unmixing-using-Archetypal-Analysis" class="headerlink" title="SUnAA: Sparse Unmixing using Archetypal Analysis"></a>SUnAA: Sparse Unmixing using Archetypal Analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04771">http://arxiv.org/abs/2308.04771</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/behnoodrasti/sunaa">https://github.com/behnoodrasti/sunaa</a></li>
<li>paper_authors: Behnood Rasti, Alexandre Zouaoui, Julien Mairal, Jocelyn Chanussot</li>
<li>For: 本研究提出了一种基于文化分析的稀疏混合技术（SUnAA），用于解决稀疏混合问题。* Methods: 我们提出了一个基于文化分析的新模型，假设感兴趣的元件是spectral库提供的元件的几何聚合。然后，我们提出了一个非几何优化目标函数，并使用活动集算法进行迭代优化。* Results: 我们使用两个 simulations dataset进行评估，结果表明SUnAA在signal-to-reconstruction error方面表现更好于传统和先进的方法。此外，我们还应用了SUnAA到Cuprite dataset，并与可用的地质图比较。 qualitative assessment表明SUnAA可以成功地估计矿物含量，并在主要矿物的探测中具有显著改善。<details>
<summary>Abstract</summary>
This paper introduces a new sparse unmixing technique using archetypal analysis (SUnAA). First, we design a new model based on archetypal analysis. We assume that the endmembers of interest are a convex combination of endmembers provided by a spectral library and that the number of endmembers of interest is known. Then, we propose a minimization problem. Unlike most conventional sparse unmixing methods, here the minimization problem is non-convex. We minimize the optimization objective iteratively using an active set algorithm. Our method is robust to the initialization and only requires the number of endmembers of interest. SUnAA is evaluated using two simulated datasets for which results confirm its better performance over other conventional and advanced techniques in terms of signal-to-reconstruction error. SUnAA is also applied to Cuprite dataset and the results are compared visually with the available geological map provided for this dataset. The qualitative assessment demonstrates the successful estimation of the minerals abundances and significantly improves the detection of dominant minerals compared to the conventional regression-based sparse unmixing methods. The Python implementation of SUnAA can be found at: https://github.com/BehnoodRasti/SUnAA.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese translation:这篇论文介绍了一种新的稀缺混合技术，基于型态分析（SUnAA）。该方法假设有兴趣的终端成分是spectral库中的终端成分的几何聚合，并且知道终端成分的数量。然后，我们提出了一个非对称的最小化问题。与大多数传统的稀缺混合方法不同，我们在这里使用了活动集算法来解决这个问题。我们的方法对初始化的敏感，只需要终端成分的数量。SUnAA在两个模拟 dataset 上进行评估，结果表明它在信号征化误差方面与其他传统和先进方法相比表现更好。SUnAA还应用于 Cuprite  dataset，并与可用的地质地图进行视觉比较。质量评估表明成功地估计矿物含量，并在主要矿物的检测方面提高了传统回归式稀缺混合方法的性能。Python实现的 SUnAA 可以在：https://github.com/BehnoodRasti/SUnAA 找到。
</details></li>
</ul>
<hr>
<h2 id="Tram-FL-Routing-based-Model-Training-for-Decentralized-Federated-Learning"><a href="#Tram-FL-Routing-based-Model-Training-for-Decentralized-Federated-Learning" class="headerlink" title="Tram-FL: Routing-based Model Training for Decentralized Federated Learning"></a>Tram-FL: Routing-based Model Training for Decentralized Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04762">http://arxiv.org/abs/2308.04762</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/KotaMaejima/Tram-FL">https://github.com/KotaMaejima/Tram-FL</a></li>
<li>paper_authors: Kota Maejima, Takayuki Nishio, Asato Yamazaki, Yuko Hara-Azumi</li>
<li>for: 提高 federated learning 中的精度，解决非独立和相同分布的数据和高频通信导致的模型学习困难。</li>
<li>methods: 提出了一种新的 federated learning 方法，即 Tram-FL，它逐步提高全球模型，通过在节点之间进行模型传输，而不是通过交换和聚合本地模型。还引入了一种动态模型路由算法，以优化路径选择，以提高模型精度。</li>
<li>results: 通过 MNIST、CIFAR-10 和 IMDb 数据集的实验表明，Tram-FL 与提出的路由算法可以在非独立的条件下达到高精度，比基eline高，同时减少通信成本。<details>
<summary>Abstract</summary>
In decentralized federated learning (DFL), substantial traffic from frequent inter-node communication and non-independent and identically distributed (non-IID) data challenges high-accuracy model acquisition. We propose Tram-FL, a novel DFL method, which progressively refines a global model by transferring it sequentially amongst nodes, rather than by exchanging and aggregating local models. We also introduce a dynamic model routing algorithm for optimal route selection, aimed at enhancing model precision with minimal forwarding. Our experiments using MNIST, CIFAR-10, and IMDb datasets demonstrate that Tram-FL with the proposed routing delivers high model accuracy under non-IID conditions, outperforming baselines while reducing communication costs.
</details>
<details>
<summary>摘要</summary>
在分布式联合学习（DFL）中，负担重大的交通和非独立同分布（非IID）数据带来高精度模型获得的挑战。我们提出了Tram-FL方法，它逐步进行全球模型的进一步精度提升，通过将其在节点之间顺序传输，而不是通过交换和聚合本地模型。我们还提出了一种动态模型路由算法，以优化路径选择，以提高模型精度，同时减少前进通信成本。我们通过使用MNIST、CIFAR-10和IMDb数据集进行实验，证明Tram-FL并与提出的路由算法在非IID条件下可以提供高精度模型，而且比基eline优化通信成本。
</details></li>
</ul>
<hr>
<h2 id="Feature-Matching-Data-Synthesis-for-Non-IID-Federated-Learning"><a href="#Feature-Matching-Data-Synthesis-for-Non-IID-Federated-Learning" class="headerlink" title="Feature Matching Data Synthesis for Non-IID Federated Learning"></a>Feature Matching Data Synthesis for Non-IID Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04761">http://arxiv.org/abs/2308.04761</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijian Li, Yuchang Sun, Jiawei Shao, Yuyi Mao, Jessie Hui Wang, Jun Zhang</li>
<li>for: 本研究旨在提出一种基于联合学习的数据同步方法，以解决非独立同分布（非IID）数据问题。</li>
<li>methods: 本文提出了一种困难特征匹配数据生成（HFMDS）方法，通过在本地模型之间共享辅助数据，以及在实际样本中学习重要的类相关特征，来有效地Address非IID问题。此外，我们还提出了一种困难特征增强方法，以将实际特征转移到决策边缘，从而保持隐私。</li>
<li>results: 我们的实验结果表明，将提案的HFMDS方法与联合学习结合使用，可以提高模型泛化性和隐私保护，同时降低计算成本。在多个benchmark数据集上，我们的提案HFMDS-FL算法比基eline表现出较高的准确率和隐私保护，同时计算成本也相对较低。<details>
<summary>Abstract</summary>
Federated learning (FL) has emerged as a privacy-preserving paradigm that trains neural networks on edge devices without collecting data at a central server. However, FL encounters an inherent challenge in dealing with non-independent and identically distributed (non-IID) data among devices. To address this challenge, this paper proposes a hard feature matching data synthesis (HFMDS) method to share auxiliary data besides local models. Specifically, synthetic data are generated by learning the essential class-relevant features of real samples and discarding the redundant features, which helps to effectively tackle the non-IID issue. For better privacy preservation, we propose a hard feature augmentation method to transfer real features towards the decision boundary, with which the synthetic data not only improve the model generalization but also erase the information of real features. By integrating the proposed HFMDS method with FL, we present a novel FL framework with data augmentation to relieve data heterogeneity. The theoretical analysis highlights the effectiveness of our proposed data synthesis method in solving the non-IID challenge. Simulation results further demonstrate that our proposed HFMDS-FL algorithm outperforms the baselines in terms of accuracy, privacy preservation, and computational cost on various benchmark datasets.
</details>
<details>
<summary>摘要</summary>
Federated 学习（FL）已经出现为一种隐私保护的思想，在边缘设备上训练神经网络而无需收集数据到中央服务器。然而，FL 面临着非独立和同分布（非IID）数据的挑战。为解决这个挑战，本文提议一种困难特征匹配数据生成（HFMDS）方法，以及在FL 中使用这种方法来共享辅助数据。具体来说，通过学习真实样本中重要的类相关特征，并丢弃 redundant 特征，可以生成高质量的synthetic数据，以有效地解决非IID 问题。为更好地保持隐私，我们提议一种困难特征扩充方法，将真实特征转移到决策边界，使得synthetic数据不仅提高模型泛化性，还将真实特征信息擦除。通过将提案的 HFMDS 方法与 FL 结合，我们提出了一种新的 FL 框架，并在这个框架中添加了数据扩充。理论分析表明，我们的提议的数据生成方法可以有效解决非IID 问题。实验结果还表明，我们的 HFMDS-FL 算法在各种 benchmark 数据集上比基eline 高于精度、隐私保护和计算成本。
</details></li>
</ul>
<hr>
<h2 id="Collaborative-Learning-From-Distributed-Data-With-Differentially-Private-Synthetic-Twin-Data"><a href="#Collaborative-Learning-From-Distributed-Data-With-Differentially-Private-Synthetic-Twin-Data" class="headerlink" title="Collaborative Learning From Distributed Data With Differentially Private Synthetic Twin Data"></a>Collaborative Learning From Distributed Data With Differentially Private Synthetic Twin Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04755">http://arxiv.org/abs/2308.04755</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dpbayes/collaborative-learning-with-dp-synthetic-twin-data">https://github.com/dpbayes/collaborative-learning-with-dp-synthetic-twin-data</a></li>
<li>paper_authors: Lukas Prediger, Joonas Jälkö, Antti Honkela, Samuel Kaski</li>
<li>for: collaborative learning on sensitive data without violating privacy constraints</li>
<li>methods: 使用具有隐私保证的合成数据分享</li>
<li>results: 与本地数据只使用的情况相比，通过共同学习合成数据集， partiesto obtain more accurate target statistics，尤其是在小型不同类型数据集中; 更多参与者参与学习，则改进的结果越来越大和一致。<details>
<summary>Abstract</summary>
Consider a setting where multiple parties holding sensitive data aim to collaboratively learn population level statistics, but pooling the sensitive data sets is not possible. We propose a framework in which each party shares a differentially private synthetic twin of their data. We study the feasibility of combining such synthetic twin data sets for collaborative learning on real-world health data from the UK Biobank. We discover that parties engaging in the collaborative learning via shared synthetic data obtain more accurate estimates of target statistics compared to using only their local data. This finding extends to the difficult case of small heterogeneous data sets. Furthermore, the more parties participate, the larger and more consistent the improvements become. Finally, we find that data sharing can especially help parties whose data contain underrepresented groups to perform better-adjusted analysis for said groups. Based on our results we conclude that sharing of synthetic twins is a viable method for enabling learning from sensitive data without violating privacy constraints even if individual data sets are small or do not represent the overall population well. The setting of distributed sensitive data is often a bottleneck in biomedical research, which our study shows can be alleviated with privacy-preserving collaborative learning methods.
</details>
<details>
<summary>摘要</summary>
假设多个方持有敏感数据，想要共同学习人口级统计数据，但汇集敏感数据集不可能。我们提出了一个框架，每个方共享一个具有隐私保证的假数据集。我们研究了将这些假数据集合用于共同学习的可能性，并应用于UK Biobank的真实世界医疗数据。我们发现，通过共同学习via共享假数据集，各方可以获得更准确的目标统计数据，包括小型不同类型数据集。此外，参与更多方会导致改进变得更大和更一致。最后，我们发现，共享假数据集可以帮助各方进行更好地调整分析，特别是对于被下代表的群体。根据我们的结果，我们认为共享假数据集是一种可靠的方法，允许保持隐私的方式进行敏感数据的学习，即使个人数据集小或者不代表整个人口。这种分布式敏感数据的设定frequently是生物医学研究中的瓶颈，我们的研究表明，这种瓶颈可以通过隐私保证的共同学习方法来缓解。
</details></li>
</ul>
<hr>
<h2 id="Universal-Fuzzing-via-Large-Language-Models"><a href="#Universal-Fuzzing-via-Large-Language-Models" class="headerlink" title="Universal Fuzzing via Large Language Models"></a>Universal Fuzzing via Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04748">http://arxiv.org/abs/2308.04748</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chunqiu Steven Xia, Matteo Paltenghi, Jia Le Tian, Michael Pradel, Lingming Zhang<br>for: 这篇论文是为了探讨一种基于大语言模型的通用软件测试工具（Fuzz4All），它可以针对多种输入语言和多种语言特性进行测试。methods: 这篇论文使用了大语言模型（LLM）作为输入生成和变换引擎，并提出了一种自动提示技术来创建适合软件测试的LLM提示。另外，它还提出了一种基于LLM的软件测试循环，可以在不同语言和不同特性下进行软件测试。results: 这篇论文的实验结果表明，使用Fuzz4All进行软件测试可以取得更高的覆盖率，而且可以发现76个在广泛使用的系统中的漏洞，其中47个已经确认由开发者们为之前未知的漏洞。<details>
<summary>Abstract</summary>
Fuzzing has achieved tremendous success in discovering bugs and vulnerabilities in various software systems. Systems under test (SUTs) that take in programming or formal language as inputs, e.g., compilers, runtime engines, constraint solvers, and software libraries with accessible APIs, are especially important as they are fundamental building blocks of software development. However, existing fuzzers for such systems often target a specific language, and thus cannot be easily applied to other languages or even other versions of the same language. Moreover, the inputs generated by existing fuzzers are often limited to specific features of the input language, and thus can hardly reveal bugs related to other or new features. This paper presents Fuzz4All, the first fuzzer that is universal in the sense that it can target many different input languages and many different features of these languages. The key idea behind Fuzz4All is to leverage large language models (LLMs) as an input generation and mutation engine, which enables the approach to produce diverse and realistic inputs for any practically relevant language. To realize this potential, we present a novel autoprompting technique, which creates LLM prompts that are wellsuited for fuzzing, and a novel LLM-powered fuzzing loop, which iteratively updates the prompt to create new fuzzing inputs. We evaluate Fuzz4All on nine systems under test that take in six different languages (C, C++, Go, SMT2, Java and Python) as inputs. The evaluation shows, across all six languages, that universal fuzzing achieves higher coverage than existing, language-specific fuzzers. Furthermore, Fuzz4All has identified 76 bugs in widely used systems, such as GCC, Clang, Z3, CVC5, OpenJDK, and the Qiskit quantum computing platform, with 47 bugs already confirmed by developers as previously unknown.
</details>
<details>
<summary>摘要</summary>
各种软件系统中的敏感区域漏洞探测得到了很大的成功，尤其是使用编程或正式语言作为输入的系统（SUT）。这些SUT包括编译器、运行时引擎、约束解决器和可用API的软件库等。然而，现有的敏感区域探测器通常只能针对特定语言，因此无法轻松地应用于其他语言或 même 同一种语言的其他版本。此外，现有的探测器通常仅生成特定语言的输入特性，因此很难暴露新的语言功能中的漏洞。本文介绍了Fuzz4All，首个可以针对多种输入语言和多种语言特性的敏感区域探测器。Fuzz4All的关键思想是利用大语言模型（LLM）作为输入生成和变换引擎，这使得它能够生成多样化和真实的输入 для任何实际有用的语言。为实现这一潜力，我们提出了一种自动提示技术，创建适合探测的 LLM 提示，以及一种基于 LLM 的探测循环，通过更新提示来创造新的探测输入。我们对 nine 种使用 six 种语言（C、C++、Go、SMT2、Java 和 Python）作为输入的系统进行了评估。评估结果显示，在所有 six 种语言中，通用探测 achieve higher coverage than existing, language-specific fuzzers。此外，Fuzz4All 已经发现了76个在广泛使用的系统中的漏洞，其中 47 个已经被开发者确认为之前未知的漏洞。
</details></li>
</ul>
<hr>
<h2 id="Optimizing-a-Transformer-based-network-for-a-deep-learning-seismic-processing-workflow"><a href="#Optimizing-a-Transformer-based-network-for-a-deep-learning-seismic-processing-workflow" class="headerlink" title="Optimizing a Transformer-based network for a deep learning seismic processing workflow"></a>Optimizing a Transformer-based network for a deep learning seismic processing workflow</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04739">http://arxiv.org/abs/2308.04739</a></li>
<li>repo_url: None</li>
<li>paper_authors: Randy Harsuko, Tariq Alkhalifah</li>
<li>for: 这篇论文的目的是提出一种基于Transformer的新型地震处理模型，并通过预训和精细训练策略来适应不同的地震处理任务。</li>
<li>methods: 这篇论文提议对StorSeismic模型进行两个关键修改：使用相对位置编码和低级对焦矩阵，以取代原始的普通自己注意机制和圆振对焦矩阵。</li>
<li>results: 试验结果显示，这些修改可以让StorSeismic模型在处理实际的Marmousi和海上场地数据时表现更快且有竞争力，同时需要训练更少的参数。<details>
<summary>Abstract</summary>
StorSeismic is a recently introduced model based on the Transformer to adapt to various seismic processing tasks through its pretraining and fine-tuning training strategy. In the original implementation, StorSeismic utilized a sinusoidal positional encoding and a conventional self-attention mechanism, both borrowed from the natural language processing (NLP) applications. For seismic processing they admitted good results, but also hinted to limitations in efficiency and expressiveness. We propose modifications to these two key components, by utilizing relative positional encoding and low-rank attention matrices as replacements to the vanilla ones. The proposed changes are tested on processing tasks applied to a realistic Marmousi and offshore field data as a sequential strategy, starting from denoising, direct arrival removal, multiple attenuation, and finally root-mean-squared velocity ($V_{RMS}$) prediction for normal moveout (NMO) correction. We observe faster pretraining and competitive results on the fine-tuning tasks and, additionally, fewer parameters to train compared to the vanilla model.
</details>
<details>
<summary>摘要</summary>
史顿希伯是一种最近引入的模型，基于Transformer来适应不同的地震处理任务。在原始实现中，史��ton希伯使用了抽象位编码和常见的自注意机制，从自然语言处理（NLP）应用中借鉴。对地震处理来说，它们得到了良好的结果，但也表现了效率和表达能力的限制。我们提议对这两个关键组件进行修改，使用相对位置编码和低级别注意矩阵作为替代物。我们对处理任务进行了顺序推进，从噪声除除、直接到达除、多个减弱、最后是根mean-squared velocity（$V_{RMS}$）预测 для正常移动（NMO） corrections。我们发现在先修改任务上快速预训练，并在细化任务上获得了竞争性的结果，同时又需要训练 fewer 参数。
</details></li>
</ul>
<hr>
<h2 id="Going-Deeper-with-Five-point-Stencil-Convolutions-for-Reaction-Diffusion-Equations"><a href="#Going-Deeper-with-Five-point-Stencil-Convolutions-for-Reaction-Diffusion-Equations" class="headerlink" title="Going Deeper with Five-point Stencil Convolutions for Reaction-Diffusion Equations"></a>Going Deeper with Five-point Stencil Convolutions for Reaction-Diffusion Equations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04735">http://arxiv.org/abs/2308.04735</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yongho Kim, Yongho Choi</li>
<li>for:  solves partial differential equations (PDEs) with diverse initial conditions using physics-informed neural networks (PINNs).</li>
<li>methods:  uses five-point stencil convolutional neural networks (FCNNs) with large receptive fields to predict time evolutions, and trains the models using two consecutive snapshots with a time step that satisfies the CFL condition.</li>
<li>results:  demonstrates that the proposed deep FCNNs retain certain accuracies for the heat, Fisher’s, and Allen-Cahn equations, in contrast to finite difference methods (FDMs) that blow up.<details>
<summary>Abstract</summary>
Physics-informed neural networks have been widely applied to partial differential equations with great success because the physics-informed loss essentially requires no observations or discretization. However, it is difficult to optimize model parameters, and these parameters must be trained for each distinct initial condition. To overcome these challenges in second-order reaction-diffusion type equations, a possible way is to use five-point stencil convolutional neural networks (FCNNs). FCNNs are trained using two consecutive snapshots, where the time step corresponds to the step size of the given snapshots. Thus, the time evolution of FCNNs depends on the time step, and the time step must satisfy its CFL condition to avoid blow-up solutions. In this work, we propose deep FCNNs that have large receptive fields to predict time evolutions with a time step larger than the threshold of the CFL condition. To evaluate our models, we consider the heat, Fisher's, and Allen-Cahn equations with diverse initial conditions. We demonstrate that deep FCNNs retain certain accuracies, in contrast to FDMs that blow up.
</details>
<details>
<summary>摘要</summary>
物理学 Informed neural networks 已经广泛应用于部分偏微分方程，取得了很大成功，因为物理学 Informed 损失函数不需要观测或离散。然而，模型参数很难优化，这些参数需要为每个不同的初始条件进行训练。为了解决这些挑战，在第二阶段反应扩散类方程中，可以使用五点矩阵卷积神经网络（FCNN）。FCNN 通过两个连续的快照，其中时间步骤与给出的快照步骤相对应，因此 FCNN 的时间演化取决于时间步骤，并且时间步骤必须满足其 CFL 条件，以避免出现冲击解。在这种工作中，我们提议使用深度 FCNN，其具有大接收场，预测时间演化，时间步骤大于阈值 CFD 条件。为了评估我们的模型，我们考虑了热、施德、艾伦-卡恩方程，并对不同的初始条件进行评估。我们发现深度 FCNN 保留了一定的准确性，与 FDM 不同，后者会冲击。
</details></li>
</ul>
<hr>
<h2 id="JEN-1-Text-Guided-Universal-Music-Generation-with-Omnidirectional-Diffusion-Models"><a href="#JEN-1-Text-Guided-Universal-Music-Generation-with-Omnidirectional-Diffusion-Models" class="headerlink" title="JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models"></a>JEN-1: Text-Guided Universal Music Generation with Omnidirectional Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04729">http://arxiv.org/abs/2308.04729</a></li>
<li>repo_url: None</li>
<li>paper_authors: Peike Li, Boyu Chen, Yao Yao, Yikai Wang, Allen Wang, Alex Wang</li>
<li>for: 本研究旨在提出一种高效、高精度的文本到音乐生成模型（JEN-1），用于解决文本描述下的音乐生成问题。</li>
<li>methods: JEN-1 使用了混合式扩散学习策略，结合了 autoregressive 和 non-autoregressive 训练方法，通过在上下文学习来实现多种生成任务，包括文本指导的音乐生成、音乐填充和续写。</li>
<li>results: 对比prevailing方法，JEN-1 在文本音乐对齐和音乐质量两个指标上具有显著优势，同时保持了计算效率。您可以通过访问 <a target="_blank" rel="noopener" href="http://futureverse.com/research/jen/demos/jen1">http://futureverse.com/research/jen/demos/jen1</a> 来听取我们的示例作品。<details>
<summary>Abstract</summary>
Music generation has attracted growing interest with the advancement of deep generative models. However, generating music conditioned on textual descriptions, known as text-to-music, remains challenging due to the complexity of musical structures and high sampling rate requirements. Despite the task's significance, prevailing generative models exhibit limitations in music quality, computational efficiency, and generalization. This paper introduces JEN-1, a universal high-fidelity model for text-to-music generation. JEN-1 is a diffusion model incorporating both autoregressive and non-autoregressive training. Through in-context learning, JEN-1 performs various generation tasks including text-guided music generation, music inpainting, and continuation. Evaluations demonstrate JEN-1's superior performance over state-of-the-art methods in text-music alignment and music quality while maintaining computational efficiency. Our demos are available at http://futureverse.com/research/jen/demos/jen1
</details>
<details>
<summary>摘要</summary>
音乐生成已经吸引了深入的研究，随着深度生成模型的发展，但是基于文本描述的音乐生成，也就是文本到音乐（text-to-music），仍然是一个挑战。这是因为音乐结构的复杂性和高采样率的要求。虽然这个任务的重要性，现有的生成模型却表现出一些限制，包括音乐质量、计算效率和通用性。这篇论文介绍了JEN-1，一种通用高准确度模型，用于文本到音乐生成。JEN-1是一种扩散模型，通过内容学习来实现文本指导的音乐生成、音乐填充和续写等多种生成任务。评估结果表明，JEN-1在文本音乐对齐和音乐质量方面的表现较为出色，同时保持计算效率。您可以在http://futureverse.com/research/jen/demos/jen1中查看我们的示例。
</details></li>
</ul>
<hr>
<h2 id="Data-Free-Model-Extraction-Attacks-in-the-Context-of-Object-Detection"><a href="#Data-Free-Model-Extraction-Attacks-in-the-Context-of-Object-Detection" class="headerlink" title="Data-Free Model Extraction Attacks in the Context of Object Detection"></a>Data-Free Model Extraction Attacks in the Context of Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05127">http://arxiv.org/abs/2308.05127</a></li>
<li>repo_url: None</li>
<li>paper_authors: Harshit Shah, Aravindhan G, Pavan Kulkarni, Yuvaraj Govidarajulu, Manojkumar Parmar</li>
<li>for: 保护机器学习模型免受模型抽取攻击，攻击者可以使用特制的查询来劫持目标模型。</li>
<li>methods: 使用生成器类似于Generative Adversarial Nets生成人工查询，并定义损失函数和新的生成器设置来实现对目标模型的抽取。</li>
<li>results: 通过使用合理的查询，提出了一种数据free模型抽取方法，并在对象检测预测任务中实现了显著的结果。这种抽取方法将支持未来保护机器学习模型的安全。<details>
<summary>Abstract</summary>
A significant number of machine learning models are vulnerable to model extraction attacks, which focus on stealing the models by using specially curated queries against the target model. This task is well accomplished by using part of the training data or a surrogate dataset to train a new model that mimics a target model in a white-box environment. In pragmatic situations, however, the target models are trained on private datasets that are inaccessible to the adversary. The data-free model extraction technique replaces this problem when it comes to using queries artificially curated by a generator similar to that used in Generative Adversarial Nets. We propose for the first time, to the best of our knowledge, an adversary black box attack extending to a regression problem for predicting bounding box coordinates in object detection. As part of our study, we found that defining a loss function and using a novel generator setup is one of the key aspects in extracting the target model. We find that the proposed model extraction method achieves significant results by using reasonable queries. The discovery of this object detection vulnerability will support future prospects for securing such models.
</details>
<details>
<summary>摘要</summary>
许多机器学习模型容易受到模型提取攻击，这些攻击集中在使用特制的查询来盗取目标模型。这种任务在白盒环境中非常成功，通过使用目标模型的一部分训练数据或代理数据集来训练一个模仿目标模型的新模型。然而，在实际情况下，目标模型通常是使用私有数据进行训练，这些数据对于敌方无法访问。我们提出了第一次，至少知道的恶意黑盒攻击，扩展到回归问题，用于预测对象检测中的 bounding box 坐标。在我们的研究中，我们发现了定义损失函数和使用新的生成器设置是抽取目标模型的关键因素。我们发现，我们提议的模型提取方法可以使用合理的查询来获得显著的结果。这种对象检测攻击发现将支持未来对这些模型的安全。
</details></li>
</ul>
<hr>
<h2 id="Slot-Induction-via-Pre-trained-Language-Model-Probing-and-Multi-level-Contrastive-Learning"><a href="#Slot-Induction-via-Pre-trained-Language-Model-Probing-and-Multi-level-Contrastive-Learning" class="headerlink" title="Slot Induction via Pre-trained Language Model Probing and Multi-level Contrastive Learning"></a>Slot Induction via Pre-trained Language Model Probing and Multi-level Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04712">http://arxiv.org/abs/2308.04712</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hoang H. Nguyen, Chenwei Zhang, Ye Liu, Philip S. Yu</li>
<li>For: The paper is written for task-oriented dialogue (TOD) systems, specifically to improve the performance of natural language understanding (NLU) tasks such as intent detection and slot filling.* Methods: The paper proposes a method called Slot Induction (SI) that uses unsupervised pre-trained language models (PLMs) and contrastive learning to induce slot boundaries without explicit knowledge of token-level slot annotations.* Results: The paper shows that the proposed SI method is effective in the SI task and can bridge the gap with token-level supervised models on two NLU benchmark datasets. Additionally, the paper shows that the SI objectives can provide enhanced slot label representations, leading to improved performance on the Slot Filling tasks.Here is the information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了提高对话系统的自然语言理解性能而写的，具体来说是为了改进意向检测和插槽填充等任务。</li>
<li>methods: 这篇论文提出了一种无监督语言模型（PLM）探索和对比学习的方法，用于不Explicitly knowledge of token-level插槽标签来逻归插槽界限。</li>
<li>results: 论文显示，提出的SI方法在SI任务中效果很好，可以与token级监督模型在两个NLUbenchmark dataset上凑成一个比。此外，论文还显示，SI目标可以提供更好的插槽标签表示，导致插槽填充任务的改进表现。<details>
<summary>Abstract</summary>
Recent advanced methods in Natural Language Understanding for Task-oriented Dialogue (TOD) Systems (e.g., intent detection and slot filling) require a large amount of annotated data to achieve competitive performance. In reality, token-level annotations (slot labels) are time-consuming and difficult to acquire. In this work, we study the Slot Induction (SI) task whose objective is to induce slot boundaries without explicit knowledge of token-level slot annotations. We propose leveraging Unsupervised Pre-trained Language Model (PLM) Probing and Contrastive Learning mechanism to exploit (1) unsupervised semantic knowledge extracted from PLM, and (2) additional sentence-level intent label signals available from TOD. Our approach is shown to be effective in SI task and capable of bridging the gaps with token-level supervised models on two NLU benchmark datasets. When generalized to emerging intents, our SI objectives also provide enhanced slot label representations, leading to improved performance on the Slot Filling tasks.
</details>
<details>
<summary>摘要</summary>
现代技术在任务对话（TOD）系统中的自然语言理解（NLP）方面（例如，意图检测和槽填充）需要大量注解数据来达到竞争性表现。然而，在实际应用中，token级别的注解（槽标签）是时间consuming和困难的获得。在这种工作中，我们研究了槽引入（SI）任务，其目标是无需明确的token级别槽标签来induce槽界限。我们提议利用无监督语言模型（PLM）探测和对比学习机制，以利用PLM中的无监督semantic知识，以及TOD中可获得的句子级意图标签信号。我们的方法在SI任务中显示效果，可以bridge带有token级别监督模型的 gap，在两个NLU benchmark数据集上。此外，当扩展到新意图时，我们的SI目标还能提供加强的槽标签表示，导致在槽填充任务中提高表现。
</details></li>
</ul>
<hr>
<h2 id="Generative-Perturbation-Analysis-for-Probabilistic-Black-Box-Anomaly-Attribution"><a href="#Generative-Perturbation-Analysis-for-Probabilistic-Black-Box-Anomaly-Attribution" class="headerlink" title="Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution"></a>Generative Perturbation Analysis for Probabilistic Black-Box Anomaly Attribution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04708">http://arxiv.org/abs/2308.04708</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/idesan/gpa">https://github.com/idesan/gpa</a></li>
<li>paper_authors: Tsuyoshi Idé, Naoki Abe</li>
<li>for: 这 paper 的目的是解释黑盒回归中的异常分布。</li>
<li>methods: 这 paper 使用了一种新的框架，即Counterfactual Variational Bayes（CVB），来计算输入变量的异常分布。</li>
<li>results: 这 paper 得到了一种不受偏见的异常分布计算方法，并且可以量化异常分布的不确定性。<details>
<summary>Abstract</summary>
We address the task of probabilistic anomaly attribution in the black-box regression setting, where the goal is to compute the probability distribution of the attribution score of each input variable, given an observed anomaly. The training dataset is assumed to be unavailable. This task differs from the standard XAI (explainable AI) scenario, since we wish to explain the anomalous deviation from a black-box prediction rather than the black-box model itself.   We begin by showing that mainstream model-agnostic explanation methods, such as the Shapley values, are not suitable for this task because of their ``deviation-agnostic property.'' We then propose a novel framework for probabilistic anomaly attribution that allows us to not only compute attribution scores as the predictive mean but also quantify the uncertainty of those scores. This is done by considering a generative process for perturbations that counter-factually bring the observed anomalous observation back to normalcy. We introduce a variational Bayes algorithm for deriving the distributions of per variable attribution scores. To the best of our knowledge, this is the first probabilistic anomaly attribution framework that is free from being deviation-agnostic.
</details>
<details>
<summary>摘要</summary>
我团队正在研究黑盒回归Setting中的概率异常归属问题，目标是计算每个输入变量的归属分布，给出观察到的异常。我们假设训练数据集不可用。这个任务与标准XAI（可解释AI）场景不同，我们想要解释黑盒预测的异常偏差而不是黑盒模型本身。我们首先显示了主流的模型无关解释方法，如夏普利值（Shapley value），不适合这个任务，因为它们的偏差无关性。然后，我们提出了一种新的概率异常归属框架，允许我们不仅计算归属分布，还可以评估这些分布的不确定性。这是通过考虑一种对 perturbations 的生成过程来实现的，该过程可以在观察到的异常 observation 的情况下，Counter-factually 带回正常。我们提出了一种变分 Bayes 算法来 derivation 每个变量归属分布的分布。到目前为止，这是免除偏差无关性的第一个概率异常归属框架。
</details></li>
</ul>
<hr>
<h2 id="Pareto-Invariant-Representation-Learning-for-Multimedia-Recommendation"><a href="#Pareto-Invariant-Representation-Learning-for-Multimedia-Recommendation" class="headerlink" title="Pareto Invariant Representation Learning for Multimedia Recommendation"></a>Pareto Invariant Representation Learning for Multimedia Recommendation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04706">http://arxiv.org/abs/2308.04706</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shanshan Huang, Haoxuan Li, Qingsong Li, Chunyuan Zheng, Li Liu</li>
<li>for: 提高多媒体推荐模型的个性化排序和环境适应能力。</li>
<li>methods: 提出了一种基于Pareto优化的多对多目标优化框架，同时学习具有吸引用户注意力的内在因素和其他因素。</li>
<li>results: 在三个公共多媒体推荐数据集上进行比较，研究结果表明PaInvRL模型可以在不同环境下具有优秀的内在和跨环境学习能力。<details>
<summary>Abstract</summary>
Multimedia recommendation involves personalized ranking tasks, where multimedia content is usually represented using a generic encoder. However, these generic representations introduce spurious correlations that fail to reveal users' true preferences. Existing works attempt to alleviate this problem by learning invariant representations, but overlook the balance between independent and identically distributed (IID) and out-of-distribution (OOD) generalization. In this paper, we propose a framework called Pareto Invariant Representation Learning (PaInvRL) to mitigate the impact of spurious correlations from an IID-OOD multi-objective optimization perspective, by learning invariant representations (intrinsic factors that attract user attention) and variant representations (other factors) simultaneously. Specifically, PaInvRL includes three iteratively executed modules: (i) heterogeneous identification module, which identifies the heterogeneous environments to reflect distributional shifts for user-item interactions; (ii) invariant mask generation module, which learns invariant masks based on the Pareto-optimal solutions that minimize the adaptive weighted Invariant Risk Minimization (IRM) and Empirical Risk (ERM) losses; (iii) convert module, which generates both variant representations and item-invariant representations for training a multi-modal recommendation model that mitigates spurious correlations and balances the generalization performance within and cross the environmental distributions. We compare the proposed PaInvRL with state-of-the-art recommendation models on three public multimedia recommendation datasets (Movielens, Tiktok, and Kwai), and the experimental results validate the effectiveness of PaInvRL for both within- and cross-environmental learning.
</details>
<details>
<summary>摘要</summary>
multimedia推荐通常包括个性化排序任务，其中 multimedia 内容通常使用一个通用编码器表示。然而，这些通用表示引入了假 correlate 问题，这些问题使得用户的真实喜好不能正确反映。现有的工作尝试通过学习不变表示来缓解这个问题，但是忽略了IID和OOD总体化的平衡。在这篇论文中，我们提出一个名为Pareto不变表示学习（PaInvRL）的框架，用于减轻IID-OOD多目标优化视角下的假 correlate 问题。具体来说，PaInvRL包括三个相互执行的模块：（i）不同环境标识模块，用于反映用户-项目交互中的分布转移；（ii）不变Mask生成模块，用于基于Pareto优化解决方案Minimize适应权重不变风险（IRM）和实际风险（ERM）损失中的不变Mask；（iii）转换模块，用于生成 variant 表示和项目不变表示，以用于训练一个多Modal推荐模型，以避免假 correlate 和 Balance 在环境分布下的总体化性能。我们对三个公共 multimedia 推荐数据集（Movielens、Tiktok和Kwai）进行比较，并证明PaInvRL在内部和交叉环境中的学习表现效果。
</details></li>
</ul>
<hr>
<h2 id="A-Feature-Set-of-Small-Size-for-the-PDF-Malware-Detection"><a href="#A-Feature-Set-of-Small-Size-for-the-PDF-Malware-Detection" class="headerlink" title="A Feature Set of Small Size for the PDF Malware Detection"></a>A Feature Set of Small Size for the PDF Malware Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04704">http://arxiv.org/abs/2308.04704</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ran Liu, Charles Nicholas</li>
<li>for: 这项研究旨在提出一个小型特征集，以提高PDF malware检测系统的性能。</li>
<li>methods: 该研究使用了六种不同的机器学习模型，并评估了提议的特征集。</li>
<li>results: 研究发现，使用Random Forest模型可以达到99.75%的最高准确率，并且该特征集的12个特征是PDF malware检测领域中最短的之一。<details>
<summary>Abstract</summary>
Machine learning (ML)-based malware detection systems are becoming increasingly important as malware threats increase and get more sophisticated. PDF files are often used as vectors for phishing attacks because they are widely regarded as trustworthy data resources, and are accessible across different platforms. Therefore, researchers have developed many different PDF malware detection methods. Performance in detecting PDF malware is greatly influenced by feature selection. In this research, we propose a small features set that don't require too much domain knowledge of the PDF file. We evaluate proposed features with six different machine learning models. We report the best accuracy of 99.75% when using Random Forest model. Our proposed feature set, which consists of just 12 features, is one of the most conciseness in the field of PDF malware detection. Despite its modest size, we obtain comparable results to state-of-the-art that employ a much larger set of features.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:机器学习（ML）基于的钓鱼攻击检测系统正在日益重要，因为钓鱼威胁不断增长和变得更加复杂。PDF文档经常用于钓鱼攻击，因为它们被广泛认为是可靠的数据资源，可以在不同的平台上访问。因此，研究人员已经开发了许多不同的PDF钓鱼检测方法。检测PDF钓鱼的性能受到特征选择的影响。在本研究中，我们提出了一个小的特征集，不需要过多的领域知识。我们使用六种不同的机器学习模型评估提案的特征。我们发现使用随机森林模型时的最佳准确率为99.75%。我们提出的特征集，包含12个特征，是PDF钓鱼检测领域中最短的一个。尽管它的规模不大，但我们得到了与领先的方法相当的结果。
</details></li>
</ul>
<hr>
<h2 id="An-Analytical-Study-of-Covid-19-Dataset-using-Graph-Based-Clustering-Algorithms"><a href="#An-Analytical-Study-of-Covid-19-Dataset-using-Graph-Based-Clustering-Algorithms" class="headerlink" title="An Analytical Study of Covid-19 Dataset using Graph-Based Clustering Algorithms"></a>An Analytical Study of Covid-19 Dataset using Graph-Based Clustering Algorithms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04697">http://arxiv.org/abs/2308.04697</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mamata Das, P. J. A. Alphonse, Selvakumar K</li>
<li>for: 这项研究是为了研究COVID-19病毒的蛋白质互作网络，以便更好地理解疾病的发展和找到新的治疗方法。</li>
<li>methods: 这项研究使用了三种图库 clustering算法来分析COVID-19数据集中的蛋白质互作网络，以获得更好的分析INTUITION。</li>
<li>results: 研究发现，COVID-19病毒的蛋白质互作网络具有较强的稠密度和连接度，这些特征可能与疾病的发展和恶化有关。<details>
<summary>Abstract</summary>
Corona VIrus Disease abbreviated as COVID-19 is a novel virus which is initially identified in Wuhan of China in December of 2019 and now this deadly disease has spread all over the world. According to World Health Organization (WHO), a total of 3,124,905 people died from 2019 to 2021, April. In this case, many methods, AI base techniques, and machine learning algorithms have been researched and are being used to save people from this pandemic. The SARS-CoV and the 2019-nCoV, SARS-CoV-2 virus invade our bodies, causing some differences in the structure of cell proteins. Protein-protein interaction (PPI) is an essential process in our cells and plays a very important role in the development of medicines and gives ideas about the disease. In this study, we performed clustering on PPI networks generated from 92 genes of the Covi-19 dataset. We have used three graph-based clustering algorithms to give intuition to the analysis of clusters.
</details>
<details>
<summary>摘要</summary>
“科罗纳病毒病”，简称“ COVID-19”，是一种新型病毒，最初在2019年12月在中国武汉地区被发现，现在这种致命病已经在全球蔓延。根据世界卫生组织（WHO）的统计，2019年至2021年4月，总共有3,124,905人死亡。在这个情况下，许多方法、AI基础技术和机器学习算法都在应用以拯救人类。SARS-CoV和2019-nCoV病毒会入侵我们的身体，导致细胞蛋白结构的一些差异。蛋白蛋白互动（PPI）是我们细胞中的一个重要过程，它对于药物的发展和疾病的了解具有非常重要的作用。在这个研究中，我们使用了92个Covi-19数据集中的PPI网络进行对数据的分组。我们使用了三种图形基础的分组算法，以提供分析结果的直觉。
</details></li>
</ul>
<hr>
<h2 id="Explainable-AI-in-Orthopedics-Challenges-Opportunities-and-Prospects"><a href="#Explainable-AI-in-Orthopedics-Challenges-Opportunities-and-Prospects" class="headerlink" title="Explainable AI in Orthopedics: Challenges, Opportunities, and Prospects"></a>Explainable AI in Orthopedics: Challenges, Opportunities, and Prospects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04696">http://arxiv.org/abs/2308.04696</a></li>
<li>repo_url: None</li>
<li>paper_authors: Soheyla Amirian, Luke A. Carlson, Matthew F. Gong, Ines Lohse, Kurt R. Weiss, Johannes F. Plate, Ahmad P. Tafti</li>
<li>for: The paper is written to address the challenge of explainable AI (XAI) in orthopedics and to emphasize the need for interdisciplinary collaborations to establish standards and guidelines for the adoption of XAI in orthopedics.</li>
<li>methods: The paper uses a combination of AI models and algorithms that prioritize transparency and interpretability to address the challenge of XAI in orthopedics.</li>
<li>results: The paper highlights the need for interdisciplinary collaborations between AI practitioners, orthopedic specialists, and regulatory entities to establish standards and guidelines for the adoption of XAI in orthopedics.Here’s the simplified Chinese text for the three key points:</li>
<li>for: 这篇论文是为了解决医学领域中的可解释人工智能（XAI）问题，并且强调需要多元合作来建立XAI在骨科领域的标准和指南。</li>
<li>methods: 这篇论文使用了优先级公布和可解释的人工智能模型和算法来解决XAI在骨科领域的挑战。</li>
<li>results: 这篇论文提出了多元合作的需要，以建立XAI在骨科领域的标准和指南，并且强调了在实施XAI时，需要与医生、外科医生和管理机构之间的合作。<details>
<summary>Abstract</summary>
While artificial intelligence (AI) has made many successful applications in various domains, its adoption in healthcare lags a little bit behind other high-stakes settings. Several factors contribute to this slower uptake, including regulatory frameworks, patient privacy concerns, and data heterogeneity. However, one significant challenge that impedes the implementation of AI in healthcare, particularly in orthopedics, is the lack of explainability and interpretability around AI models. Addressing the challenge of explainable AI (XAI) in orthopedics requires developing AI models and algorithms that prioritize transparency and interpretability, allowing clinicians, surgeons, and patients to understand the contributing factors behind any AI-powered predictive or descriptive models. The current contribution outlines several key challenges and opportunities that manifest in XAI in orthopedic practice. This work emphasizes the need for interdisciplinary collaborations between AI practitioners, orthopedic specialists, and regulatory entities to establish standards and guidelines for the adoption of XAI in orthopedics.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在不同领域已经取得了许多成功应用，但在医疗领域的采纳 slower 了一些。这些因素包括法规框架、患者隐私问题和数据不一致。然而，在医疗领域，特别是在 ortopedics 中，缺乏 Explainable AI（XAI）是实现 AI 的主要挑战。 Addressing the challenge of XAI in orthopedics requires developing AI models and algorithms that prioritize transparency and interpretability, allowing clinicians, surgeons, and patients to understand the contributing factors behind any AI-powered predictive or descriptive models. 现在的贡献将描述 XAI 在 ortopedics 中的一些关键挑战和机遇。这篇文章强调了在 AI 实践者、orthopedic 专家和 regulatory 机构之间的交往合作，以确立 XAI 在 ortopedics 中的标准和指南。
</details></li>
</ul>
<hr>
<h2 id="Finite-Element-Operator-Network-for-Solving-Parametric-PDEs"><a href="#Finite-Element-Operator-Network-for-Solving-Parametric-PDEs" class="headerlink" title="Finite Element Operator Network for Solving Parametric PDEs"></a>Finite Element Operator Network for Solving Parametric PDEs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04690">http://arxiv.org/abs/2308.04690</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jae Yong Lee, Seungchan Ko, Youngjoon Hong</li>
<li>for: 解决Parametric Partial Differential Equations (PDEs)的数值计算问题，即使没有输入输出对应的训练数据。</li>
<li>methods: 提议使用Finite Element Operator Network (FEONet)，结合深度学习和传统的数值方法（特别是finite element方法）解决Parametric PDEs。</li>
<li>results: 对多个 benchmark 问题进行了实验，证明了我们的方法在准确性、泛化能力和计算灵活性等方面表现出色，并且超过了现有的状态艺术方法。<details>
<summary>Abstract</summary>
Partial differential equations (PDEs) underlie our understanding and prediction of natural phenomena across numerous fields, including physics, engineering, and finance. However, solving parametric PDEs is a complex task that necessitates efficient numerical methods. In this paper, we propose a novel approach for solving parametric PDEs using a Finite Element Operator Network (FEONet). Our proposed method leverages the power of deep learning in conjunction with traditional numerical methods, specifically the finite element method, to solve parametric PDEs in the absence of any paired input-output training data. We demonstrate the effectiveness of our approach on several benchmark problems and show that it outperforms existing state-of-the-art methods in terms of accuracy, generalization, and computational flexibility. Our FEONet framework shows potential for application in various fields where PDEs play a crucial role in modeling complex domains with diverse boundary conditions and singular behavior. Furthermore, we provide theoretical convergence analysis to support our approach, utilizing finite element approximation in numerical analysis.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Two-Novel-Approaches-to-Detect-Community-A-Case-Study-of-Omicron-Lineage-Variants-PPI-Network"><a href="#Two-Novel-Approaches-to-Detect-Community-A-Case-Study-of-Omicron-Lineage-Variants-PPI-Network" class="headerlink" title="Two Novel Approaches to Detect Community: A Case Study of Omicron Lineage Variants PPI Network"></a>Two Novel Approaches to Detect Community: A Case Study of Omicron Lineage Variants PPI Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05125">http://arxiv.org/abs/2308.05125</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mamata Das, Selvakumar K., P. J. A. Alphonse</li>
<li>for: 这个研究旨在通过社群分析方法揭示 variant B.1.1.529 (Omicron virus) 中的社群结构，以提高我们对这种病毒的分子水平理解，并且帮助开发新的药物和个性化医疗方法。</li>
<li>methods: 这个研究使用了两种提出的新算法（ABCDE和ALCDE）和四种广泛使用的算法（Girvan-Newman、Louvain、Leiden和Label Propagation）来检测 variant B.1.1.529 网络中的社群结构。</li>
<li>results: 研究发现，使用不同的算法可以检测出 variant B.1.1.529 网络中的社群结构，并且这些社群结构具有独特的特征和性质。<details>
<summary>Abstract</summary>
The capacity to identify and analyze protein-protein interactions, along with their internal modular organization, plays a crucial role in comprehending the intricate mechanisms underlying biological processes at the molecular level. We can learn a lot about the structure and dynamics of these interactions by using network analysis. We can improve our understanding of the biological roots of disease pathogenesis by recognizing network communities. This knowledge, in turn, holds significant potential for driving advancements in drug discovery and facilitating personalized medicine approaches for disease treatment. In this study, we aimed to uncover the communities within the variant B.1.1.529 (Omicron virus) using two proposed novel algorithm (ABCDE and ALCDE) and four widely recognized algorithms: Girvan-Newman, Louvain, Leiden, and Label Propagation algorithm. Each of these algorithms has established prominence in the field and offers unique perspectives on identifying communities within complex networks. We also compare the networks by the global properties, statistic summary, subgraph count, graphlet and validate by the modulaity. By employing these approaches, we sought to gain deeper insights into the structural organization and interconnections present within the Omicron virus network.
</details>
<details>
<summary>摘要</summary>
“蛋白质-蛋白质互动的能力和内部模块化结构在分子层面上关键地影响生物过程的复杂机制。我们可以通过网络分析来学习这些互动的结构和动力学。通过认可网络社区，我们可以更深入地理解疾病生物根据，这将有助于医疗药物发现和疾病治疗中采取人类化方法。在这个研究中，我们使用了两种提出的新算法（ABCDE和ALCDE）和四种已知的算法：Girvan-Newman、Louvain、Leiden和Label Propagation算法。每个这些算法在领域中都有传统的地位，它们可以帮助我们从不同的角度发现疾病网络中的社区。我们还比较了这些网络的全球性、统计摘要、子graph计数、графлет和验证 Modulaity。通过这些方法，我们想要从这些方法中获得更深入的理解疾病网络中的结构和互动。”Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="TBIN-Modeling-Long-Textual-Behavior-Data-for-CTR-Prediction"><a href="#TBIN-Modeling-Long-Textual-Behavior-Data-for-CTR-Prediction" class="headerlink" title="TBIN: Modeling Long Textual Behavior Data for CTR Prediction"></a>TBIN: Modeling Long Textual Behavior Data for CTR Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08483">http://arxiv.org/abs/2308.08483</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuwei Chen, Xiang Li, Jian Dong, Jin Zhang, Yongkang Wang, Xingxing Wang</li>
<li>for: 预测Click-through rate (CTR) 对于推荐有着关键作用，而 latest 语言模型 (LMs) 的繁荣也使得一些工作利用语言模型来理解用户兴趣。</li>
<li>methods: 本文提出了 Textual Behavior-based Interest Chunking Network (TBIN), 它结合了高效的本地性敏感哈希算法和偏移的块基于自注意力，以解决上述限制。</li>
<li>results: 实验结果表明，TBIN 可以更好地预测 CTR，并在实际食品推荐平台上达到了好的效果。<details>
<summary>Abstract</summary>
Click-through rate (CTR) prediction plays a pivotal role in the success of recommendations. Inspired by the recent thriving of language models (LMs), a surge of works improve prediction by organizing user behavior data in a \textbf{textual} format and using LMs to understand user interest at a semantic level. While promising, these works have to truncate the textual data to reduce the quadratic computational overhead of self-attention in LMs. However, it has been studied that long user behavior data can significantly benefit CTR prediction. In addition, these works typically condense user diverse interests into a single feature vector, which hinders the expressive capability of the model. In this paper, we propose a \textbf{T}extual \textbf{B}ehavior-based \textbf{I}nterest Chunking \textbf{N}etwork (TBIN), which tackles the above limitations by combining an efficient locality-sensitive hashing algorithm and a shifted chunk-based self-attention. The resulting user diverse interests are dynamically activated, producing user interest representation towards the target item. Finally, the results of both offline and online experiments on real-world food recommendation platform demonstrate the effectiveness of TBIN.
</details>
<details>
<summary>摘要</summary>
点击率预测（CTR）在推荐中发挥关键作用。鼓使用语言模型（LM）的最近繁荣，一些工作改进预测，将用户行为数据组织成文本格式，并使用LM理解用户兴趣的 semantic 层次。虽然有承诺，但这些工作通常需要压缩文本数据，以降低LM的自注意力计算量的二次性。此外，这些工作通常将用户多样化的兴趣维度化成单一的特征向量，这限制了模型的表达能力。在这篇论文中，我们提出了一种 Textual Behavior-based Interest Chunking Network（TBIN），解决以上限制。TBIN 通过结合本地性敏感哈希算法和偏移 chunk-based self-attention 来实现。这将使用户多样化的兴趣在运行时动态激活，生成用户兴趣表示向 target 项。最后，在实际食品推荐平台上进行了线上和离线实验，证明了 TBIN 的效果。
</details></li>
</ul>
<hr>
<h2 id="A-General-Implicit-Framework-for-Fast-NeRF-Composition-and-Rendering"><a href="#A-General-Implicit-Framework-for-Fast-NeRF-Composition-and-Rendering" class="headerlink" title="A General Implicit Framework for Fast NeRF Composition and Rendering"></a>A General Implicit Framework for Fast NeRF Composition and Rendering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04669">http://arxiv.org/abs/2308.04669</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyu Gao, Ziyi Yang, Yunlu Zhao, Yuxiang Sun, Xiaogang Jin, Changqing Zou</li>
<li>for: This paper aims to provide a general implicit pipeline for composing NeRF objects quickly, enabling the casting of dynamic shadows within or between objects using analytical light sources, and allowing multiple NeRF objects to be seamlessly placed and rendered together with any arbitrary rigid transformations.</li>
<li>methods: The proposed method introduces a new surface representation known as Neural Depth Fields (NeDF), which quickly determines the spatial relationship between objects by allowing direct intersection computation between rays and implicit surfaces. It leverages an intersection neural network to query NeRF for acceleration instead of depending on an explicit spatial structure.</li>
<li>results: The proposed method is the first to enable both the progressive and interactive composition of NeRF objects, and it also serves as a previewing plugin for a range of existing NeRF works.<details>
<summary>Abstract</summary>
A variety of Neural Radiance Fields (NeRF) methods have recently achieved remarkable success in high render speed. However, current accelerating methods are specialized and incompatible with various implicit methods, preventing real-time composition over various types of NeRF works. Because NeRF relies on sampling along rays, it is possible to provide general guidance for acceleration. To that end, we propose a general implicit pipeline for composing NeRF objects quickly. Our method enables the casting of dynamic shadows within or between objects using analytical light sources while allowing multiple NeRF objects to be seamlessly placed and rendered together with any arbitrary rigid transformations. Mainly, our work introduces a new surface representation known as Neural Depth Fields (NeDF) that quickly determines the spatial relationship between objects by allowing direct intersection computation between rays and implicit surfaces. It leverages an intersection neural network to query NeRF for acceleration instead of depending on an explicit spatial structure.Our proposed method is the first to enable both the progressive and interactive composition of NeRF objects. Additionally, it also serves as a previewing plugin for a range of existing NeRF works.
</details>
<details>
<summary>摘要</summary>
各种神经辐射场（NeRF）方法在最近几年内已经实现了高速渲染。然而，当前的加速方法都是特殊化的，与各种隐式方法不兼容，因此无法在不同类型的 NeRF 作品中实现实时组合。因为 NeRF 是基于样本点投射，因此可以提供一般的指导。为了实现这一目标，我们提议一种通用的隐式管道，用于快速组合 NeRF 对象。我们的方法可以在动态阴影下投射 NeRF 对象，并允许多个 NeRF 对象在任意旋转变换下协同渲染。主要是，我们的工作引入了一种新的表面表示方式，即神经深度场（NeDF），它快速确定对象之间的空间关系，并使用神经网络进行交叉计算。这种方法不依赖于Explicit的空间结构，可以快速地计算ray和隐式表面之间的交叉。我们的提议方法是首次实现了 NeRF 对象的逐渐和交互式组合。此外，它还可以作为许多现有 NeRF 作品的预览插件。
</details></li>
</ul>
<hr>
<h2 id="Classification-of-lung-cancer-subtypes-on-CT-images-with-synthetic-pathological-priors"><a href="#Classification-of-lung-cancer-subtypes-on-CT-images-with-synthetic-pathological-priors" class="headerlink" title="Classification of lung cancer subtypes on CT images with synthetic pathological priors"></a>Classification of lung cancer subtypes on CT images with synthetic pathological priors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04663">http://arxiv.org/abs/2308.04663</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wentao Zhu, Yuan Jin, Gege Ma, Geng Chen, Jan Egger, Shaoting Zhang, Dimitris N. Metaxas</li>
<li>for: 这份研究的目的是精确地诊断肺癌的病理型态，以便进行跟踪治疗和预后管理。</li>
<li>methods: 本研究提出了一个自动生成混合特征网络（SGHF-Net），用于从 computed tomography（CT）图像中精确类别肺癌病理型态。研究发现，跨 scales的图像相关性存在在同一个案例的 CT 图像和其相应的病理图像之间，因此开发了一个病理特征合成模组（PFSM），通过深度神经网络来将相应的病理信息从 CT 图像中提取出来。此外，研究还设计了一个 radiological feature extraction module（RFEM），以直接从 CT 图像中提取特征，并与病理先前相结合在一个有效的特征融合框架中，使整个分类模型能够生成更多的指示和特定的病理相关特征，最终获得更高的准确性。</li>
<li>results: 实验结果显示，提案的模型在肺癌病理型态分类任务中具有superiority，与多种state-of-the-art（SOTA）分类模型相比，具有 significiant 的准确性改善，包括精确率（ACC）、抽象曲线（AUC）和 F1 分数。<details>
<summary>Abstract</summary>
The accurate diagnosis on pathological subtypes for lung cancer is of significant importance for the follow-up treatments and prognosis managements. In this paper, we propose self-generating hybrid feature network (SGHF-Net) for accurately classifying lung cancer subtypes on computed tomography (CT) images. Inspired by studies stating that cross-scale associations exist in the image patterns between the same case's CT images and its pathological images, we innovatively developed a pathological feature synthetic module (PFSM), which quantitatively maps cross-modality associations through deep neural networks, to derive the "gold standard" information contained in the corresponding pathological images from CT images. Additionally, we designed a radiological feature extraction module (RFEM) to directly acquire CT image information and integrated it with the pathological priors under an effective feature fusion framework, enabling the entire classification model to generate more indicative and specific pathologically related features and eventually output more accurate predictions. The superiority of the proposed model lies in its ability to self-generate hybrid features that contain multi-modality image information based on a single-modality input. To evaluate the effectiveness, adaptability, and generalization ability of our model, we performed extensive experiments on a large-scale multi-center dataset (i.e., 829 cases from three hospitals) to compare our model and a series of state-of-the-art (SOTA) classification models. The experimental results demonstrated the superiority of our model for lung cancer subtypes classification with significant accuracy improvements in terms of accuracy (ACC), area under the curve (AUC), and F1 score.
</details>
<details>
<summary>摘要</summary>
准确诊断肺癌分型对跟进治疗和预后管理具有重要的重要性。在这篇论文中，我们提议一种自生成混合特征网络（SGHF-Net），用于准确分类肺癌分型的计算机Tomography（CT）图像。受到 Studies表明cross-scale关系存在图像特征之间的同一个患者的CT图像和其 PATHOLOGICAL图像的研究所启发，我们创新地开发了一种 PATHOLOGICAL特征合成模块（PFSM），用于量化跨模态关系，从深度神经网络中获取 PATHOLOGICAL图像中的"金标准"信息。此外，我们设计了一种放射学特征提取模块（RFEM），用于直接获取 CT 图像信息，并将其与 PATHOLOGICAL 先天知识结合在一起，以实现效果的特征融合框架，使整个分类模型能够生成更指示性和特定的 PATHOLOGICAL 相关特征，并最终输出更高精度的预测结果。我们的模型的优势在于它可以基于单一输入模式生成混合特征，包括多Modal 图像信息。为评估我们模型的有效性、适应性和普遍性，我们在大规模多中心数据集（i.e., 829 例from three hospitals）进行了广泛的实验，与一些当前最佳分类模型进行比较。实验结果表明，我们的模型在肺癌分型方面具有显著的准确性改进，包括准确率（ACC）、曲线下的面积（AUC）和 F1 分数。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Bayesian-Optimization-with-Deep-Kernel-Learning-and-Transformer-Pre-trained-on-Multiple-Heterogeneous-Datasets"><a href="#Efficient-Bayesian-Optimization-with-Deep-Kernel-Learning-and-Transformer-Pre-trained-on-Multiple-Heterogeneous-Datasets" class="headerlink" title="Efficient Bayesian Optimization with Deep Kernel Learning and Transformer Pre-trained on Multiple Heterogeneous Datasets"></a>Efficient Bayesian Optimization with Deep Kernel Learning and Transformer Pre-trained on Multiple Heterogeneous Datasets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04660">http://arxiv.org/abs/2308.04660</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenlong Lyu, Shoubo Hu, Jie Chuai, Zhitang Chen</li>
<li>for: 提高黑盒优化问题的解决效率，通过多任务共同 pré-训练surrogate模型。</li>
<li>methods: 使用Transformer基于encoder学习深度特征，定义GPkernel，并提供mix-up初始化策略加速新任务的快速吸引。</li>
<li>results: 在 sintetic和实际benchmark问题上，提出的方法比现有方法更高效。<details>
<summary>Abstract</summary>
Bayesian optimization (BO) is widely adopted in black-box optimization problems and it relies on a surrogate model to approximate the black-box response function. With the increasing number of black-box optimization tasks solved and even more to solve, the ability to learn from multiple prior tasks to jointly pre-train a surrogate model is long-awaited to further boost optimization efficiency. In this paper, we propose a simple approach to pre-train a surrogate, which is a Gaussian process (GP) with a kernel defined on deep features learned from a Transformer-based encoder, using datasets from prior tasks with possibly heterogeneous input spaces. In addition, we provide a simple yet effective mix-up initialization strategy for input tokens corresponding to unseen input variables and therefore accelerate new tasks' convergence. Experiments on both synthetic and real benchmark problems demonstrate the effectiveness of our proposed pre-training and transfer BO strategy over existing methods.
</details>
<details>
<summary>摘要</summary>
bayesian 优化（BO）广泛应用于黑盒优化问题中，它基于一个模拟黑盒响应函数的伪函数来进行优化。随着黑盒优化任务的数量不断增加，并且还有更多的任务需要解决，因此有必要将多个前一个任务的知识共享以提高优化效率。在这篇论文中，我们提出了一种简单的预训练方法，其中使用一个基于Transformer的encoder学习的深度特征来定义GP的kernel，并使用多个先前任务的数据进行预训练。此外，我们还提供了一种简单却有效的混合初始化策略，以便快速加速新任务的启动。实验表明，我们的提议的预训练和传递BO策略在实际和Syntheticbenchmark问题上比既有方法更高效。
</details></li>
</ul>
<hr>
<h2 id="Assessing-the-performance-of-deep-learning-based-models-for-prostate-cancer-segmentation-using-uncertainty-scores"><a href="#Assessing-the-performance-of-deep-learning-based-models-for-prostate-cancer-segmentation-using-uncertainty-scores" class="headerlink" title="Assessing the performance of deep learning-based models for prostate cancer segmentation using uncertainty scores"></a>Assessing the performance of deep learning-based models for prostate cancer segmentation using uncertainty scores</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04653">http://arxiv.org/abs/2308.04653</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pablo Cesar Quihui-Rubio, Daniel Flores-Araiza, Gilberto Ochoa-Ruiz, Miguel Gonzalez-Mendoza, Christian Mata</li>
<li>for: 这项研究旨在比较深度学习方法对MRI图像中肾脏 segmentation和量化不确定性的效果，以提高肾脏癌检测和诊断的工作流程。</li>
<li>methods: 这项研究使用了七种不同的 U-Net 架构，并在这些架构中添加了 Monte-Carlo dropout 等方法进行自动 segmentation 和不确定性估计。</li>
<li>results: 研究发现，Attention R2U-Net 模型在 segmenting 所有区域时达到了平均 Intersection over Union（IoU）76.3%和 Dice Similarity Coefficient（DSC）85%的最高性能，并且在边界区域中，特别是在转换区域和肿瘤边界上，Attention R2U-Net 模型表现出最低的不确定性值。<details>
<summary>Abstract</summary>
This study focuses on comparing deep learning methods for the segmentation and quantification of uncertainty in prostate segmentation from MRI images. The aim is to improve the workflow of prostate cancer detection and diagnosis. Seven different U-Net-based architectures, augmented with Monte-Carlo dropout, are evaluated for automatic segmentation of the central zone, peripheral zone, transition zone, and tumor, with uncertainty estimation. The top-performing model in this study is the Attention R2U-Net, achieving a mean Intersection over Union (IoU) of 76.3% and Dice Similarity Coefficient (DSC) of 85% for segmenting all zones. Additionally, Attention R2U-Net exhibits the lowest uncertainty values, particularly in the boundaries of the transition zone and tumor, when compared to the other models.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Deep-Metric-Learning-for-the-Hemodynamics-Inference-with-Electrocardiogram-Signals"><a href="#Deep-Metric-Learning-for-the-Hemodynamics-Inference-with-Electrocardiogram-Signals" class="headerlink" title="Deep Metric Learning for the Hemodynamics Inference with Electrocardiogram Signals"></a>Deep Metric Learning for the Hemodynamics Inference with Electrocardiogram Signals</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04650">http://arxiv.org/abs/2308.04650</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hyewon Jeong, Collin M. Stultz, Marzyeh Ghassemi</li>
<li>for: 这个研究旨在开发一个可以非侵入性地估计心脏压力的方法，以帮助诊断和治疗心脏病症的患者。</li>
<li>methods: 这个研究使用了深度度量学习（DML）技术，并提出了一个自我监督的DML方法，通过距离基本采矿来提高模型的表现。</li>
<li>results: 研究发现，这个自我监督DML方法可以对于患者 subgroup 进行优化，并且在不同的患者 subgroup 中表现良好。此外，这个方法还可以与现有的标准方法进行比较，以验证其性能。<details>
<summary>Abstract</summary>
Heart failure is a debilitating condition that affects millions of people worldwide and has a significant impact on their quality of life and mortality rates. An objective assessment of cardiac pressures remains an important method for the diagnosis and treatment prognostication for patients with heart failure. Although cardiac catheterization is the gold standard for estimating central hemodynamic pressures, it is an invasive procedure that carries inherent risks, making it a potentially dangerous procedure for some patients. Approaches that leverage non-invasive signals - such as electrocardiogram (ECG) - have the promise to make the routine estimation of cardiac pressures feasible in both inpatient and outpatient settings. Prior models trained to estimate intracardiac pressures (e.g., mean pulmonary capillary wedge pressure (mPCWP)) in a supervised fashion have shown good discriminatory ability but have been limited to the labeled dataset from the heart failure cohort. To address this issue and build a robust representation, we apply deep metric learning (DML) and propose a novel self-supervised DML with distance-based mining that improves the performance of a model with limited labels. We use a dataset that contains over 5.4 million ECGs without concomitant central pressure labels to pre-train a self-supervised DML model which showed improved classification of elevated mPCWP compared to self-supervised contrastive baselines. Additionally, the supervised DML model that is using ECGs with access to 8,172 mPCWP labels demonstrated significantly better performance on the mPCWP regression task compared to the supervised baseline. Moreover, our data suggest that DML yields models that are performant across patient subgroups, even when some patient subgroups are under-represented in the dataset. Our code is available at https://github.com/mandiehyewon/ssldml
</details>
<details>
<summary>摘要</summary>
心力衰竭是一种严重的疾病，影响了全球数百万人的生活质量和死亡率。心脏压力的 объектив评估仍然是诊断和治疗预测的重要方法。尽管心脏插管是心脏压力的标准方法，但它是一种侵入性的程序，带来了内在的风险，因此可能对某些患者而言是危险的。使用非侵入性信号（如电cardiogram）的方法可以使 Routine estimation of cardiac pressures 变得可能。先前的模型，通过监督学习来估计内心脏压力（如mean pulmonary capillary wedge pressure （mPCWP）），在心脏疾病群体中显示了良好的预测能力，但它们受限于标注数据集。为解决这个问题并建立一个坚固的表示，我们应用深度度量学习（DML）并提出一种新的自动化DML，通过距离基本挖掘来提高模型的性能。我们使用了包含超过540万个ECG无相关中央压力标签的数据集来预训一个自动化DML模型，该模型在提高高mPCWP的分类性能方面表现出色，而且与自动化对比基线显著更好。此外，我们使用ECG和8172个mPCWP标签来训练一个监督DML模型，该模型在mPCWP回归任务中表现出色，并且与监督基线显著更好。此外，我们的数据表明，DML模型在不同的患者子组中表现良好，即使某些患者子组在数据集中受到保守。我们的代码可以在https://github.com/mandiehyewon/ssldml 中找到。
</details></li>
</ul>
<hr>
<h2 id="Enhancing-Optimization-Performance-A-Novel-Hybridization-of-Gaussian-Crunching-Search-and-Powell’s-Method-for-Derivative-Free-Optimization"><a href="#Enhancing-Optimization-Performance-A-Novel-Hybridization-of-Gaussian-Crunching-Search-and-Powell’s-Method-for-Derivative-Free-Optimization" class="headerlink" title="Enhancing Optimization Performance: A Novel Hybridization of Gaussian Crunching Search and Powell’s Method for Derivative-Free Optimization"></a>Enhancing Optimization Performance: A Novel Hybridization of Gaussian Crunching Search and Powell’s Method for Derivative-Free Optimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04649">http://arxiv.org/abs/2308.04649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Benny Wong</li>
<li>for: 本研究论文旨在提出一种hybrid化 Gaussian Crunching Search（GCS）和 Powell’s Method的新方法，以提高不具有导数的优化性能。</li>
<li>methods: 本研究使用了GCS和一些传统的不具有导数优化方法的混合，以优化复杂系统中的优化问题。</li>
<li>results: 经过实验，我们发现这种混合方法可以显著提高优化性能，同时保留每种方法的优点。这种混合方法开启了优化复杂系统中的新可能性。<details>
<summary>Abstract</summary>
This research paper presents a novel approach to enhance optimization performance through the hybridization of Gaussian Crunching Search (GCS) and Powell's Method for derivative-free optimization. While GCS has shown promise in overcoming challenges faced by traditional derivative-free optimization methods [1], it may not always excel in finding the local minimum. On the other hand, some traditional methods may have better performance in this regard. However, GCS demonstrates its strength in escaping the trap of local minima and approaching the global minima. Through experimentation, we discovered that by combining GCS with certain traditional derivative-free optimization methods, we can significantly boost performance while retaining the respective advantages of each method. This hybrid approach opens up new possibilities for optimizing complex systems and finding optimal solutions in a range of applications.
</details>
<details>
<summary>摘要</summary>
Note:* "GCS" is translated as " Gaussian Crunching Search" (GCS)* "Powell's Method" is translated as "Powell's Method" ( Powell 方法)* "derivative-free optimization" is translated as "无导数优化" (without derivative optimization)* "local minimum" is translated as "地方最优" (local optimal)* "global minimum" is translated as "全球最优" (global optimal)
</details></li>
</ul>
<hr>
<h2 id="Sparse-Binary-Transformers-for-Multivariate-Time-Series-Modeling"><a href="#Sparse-Binary-Transformers-for-Multivariate-Time-Series-Modeling" class="headerlink" title="Sparse Binary Transformers for Multivariate Time Series Modeling"></a>Sparse Binary Transformers for Multivariate Time Series Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04637">http://arxiv.org/abs/2308.04637</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matt Gorbett, Hossein Shirazi, Indrakshi Ray</li>
<li>for: 应用于多变量时间序列问题的简单深度学习模型</li>
<li>methods: 使用稀疏和二进制权重的 transformer 模型</li>
<li>results: 在三个时间序列学习任务中获得了比较出色的成绩：分类、异常检测和单步预测，同时通过两种修改来减少计算复杂性：1）在分类任务中应用固定mask，2）在预测和异常检测任务中应用时间步骤Attention mask。这些修改和压缩技术可以减少 transformer 模型中非零操作数量，并且对模型性能没有明显的影响。<details>
<summary>Abstract</summary>
Compressed Neural Networks have the potential to enable deep learning across new applications and smaller computational environments. However, understanding the range of learning tasks in which such models can succeed is not well studied. In this work, we apply sparse and binary-weighted Transformers to multivariate time series problems, showing that the lightweight models achieve accuracy comparable to that of dense floating-point Transformers of the same structure. Our model achieves favorable results across three time series learning tasks: classification, anomaly detection, and single-step forecasting. Additionally, to reduce the computational complexity of the attention mechanism, we apply two modifications, which show little to no decline in model performance: 1) in the classification task, we apply a fixed mask to the query, key, and value activations, and 2) for forecasting and anomaly detection, which rely on predicting outputs at a single point in time, we propose an attention mask to allow computation only at the current time step. Together, each compression technique and attention modification substantially reduces the number of non-zero operations necessary in the Transformer. We measure the computational savings of our approach over a range of metrics including parameter count, bit size, and floating point operation (FLOPs) count, showing up to a 53x reduction in storage size and up to 10.5x reduction in FLOPs.
</details>
<details>
<summary>摘要</summary>
压缩神经网络有望推动深度学习应用于新的应用环境和较小的计算环境。然而，了解这些模型在哪些学习任务中能够成功是未有充分研究。在这种工作中，我们使用稀疏和二进制权重的Transformers来解决多变量时间序列问题，并证明这些轻量级模型可以与同结构的浮点数Transformers具有相同的准确率。我们的模型在三个时间序列学习任务中显示出了有利的结果：分类、异常检测和单步预测。此外，为了降低计算复杂性的注意机制，我们应用了两种修改，其中第一种是在分类任务中采用固定掩码来修改查询、关键和值活动，而第二种是在预测和异常检测任务中，因为需要在单个时间步骤上预测输出，我们提议使用注意力掩码，只允许在当前时间步骤上进行计算。总之，我们的方法可以减少Transformer中非零操作数量，并且对参数数、位数和浮点运算（FLOPs）数进行了评估，得出了最多53倍减少存储大小和最多10.5倍减少FLOPs。
</details></li>
</ul>
<hr>
<h2 id="Multiclass-Online-Learnability-under-Bandit-Feedback"><a href="#Multiclass-Online-Learnability-under-Bandit-Feedback" class="headerlink" title="Multiclass Online Learnability under Bandit Feedback"></a>Multiclass Online Learnability under Bandit Feedback</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04620">http://arxiv.org/abs/2308.04620</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ananth Raman, Vinod Raman, Unique Subedi, Ambuj Tewari</li>
<li>for: 研究在线上多类标签分类中的抽象反馈。</li>
<li>methods: extend daniely2013price的结果，显示了统一抽象反馈下的线上多类分类可学习性是必需和充分的。</li>
<li>results: 结果与hanneke2023multiclass的结果相 compliment，显示了在充满信息设定下的线上多类分类可学习性是基于抽象反馈的Littlestone dimension。<details>
<summary>Abstract</summary>
We study online multiclass classification under bandit feedback. We extend the results of (daniely2013price) by showing that the finiteness of the Bandit Littlestone dimension is necessary and sufficient for bandit online multiclass learnability even when the label space is unbounded. Our result complements the recent work by (hanneke2023multiclass) who show that the Littlestone dimension characterizes online multiclass learnability in the full-information setting when the label space is unbounded.
</details>
<details>
<summary>摘要</summary>
我们研究在抽奖式多类分类中的在线学习。我们将(daniely2013price)的结果推广到不确定label空间的情况下，证明在线多类学习的可学习性需要和充分条件是抽奖式Littlestone维度的 фиnisiteness。我们的结果与(hanneke2023multiclass)的最近研究相 complement，其证明在全信息设置下，无限大的label空间下的多类学习可学习性是Littlestone维度的Characterize。
</details></li>
</ul>
<hr>
<h2 id="Improved-Activation-Clipping-for-Universal-Backdoor-Mitigation-and-Test-Time-Detection"><a href="#Improved-Activation-Clipping-for-Universal-Backdoor-Mitigation-and-Test-Time-Detection" class="headerlink" title="Improved Activation Clipping for Universal Backdoor Mitigation and Test-Time Detection"></a>Improved Activation Clipping for Universal Backdoor Mitigation and Test-Time Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04617">http://arxiv.org/abs/2308.04617</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wanghangpsu/mmac">https://github.com/wanghangpsu/mmac</a></li>
<li>paper_authors: Hang Wang, Zhen Xiang, David J. Miller, George Kesidis<br>for: 防止深度神经网络受到后门攻击（Trojan）的攻击，攻击者在训练集中杀入后门触发器，使神经网络在测试时识别攻击者所指定的目标类。methods: 我们提出了一种新的静态策略，通过在小量的净样上学习内层吞吐量的约束，来限制内层吞吐量的范围。这种方法可以更好地防止后门攻击，并且具有强大的鲁棒性。results: 我们的方法在CIFAR-10图像分类任务上显示出了更好的性能，并且对于不同的数据集和攻击方法都具有强大的鲁棒性。此外，我们还提出了一种基于输出差异的测试时检测和修复方法。<details>
<summary>Abstract</summary>
Deep neural networks are vulnerable to backdoor attacks (Trojans), where an attacker poisons the training set with backdoor triggers so that the neural network learns to classify test-time triggers to the attacker's designated target class. Recent work shows that backdoor poisoning induces over-fitting (abnormally large activations) in the attacked model, which motivates a general, post-training clipping method for backdoor mitigation, i.e., with bounds on internal-layer activations learned using a small set of clean samples. We devise a new such approach, choosing the activation bounds to explicitly limit classification margins. This method gives superior performance against peer methods for CIFAR-10 image classification. We also show that this method has strong robustness against adaptive attacks, X2X attacks, and on different datasets. Finally, we demonstrate a method extension for test-time detection and correction based on the output differences between the original and activation-bounded networks. The code of our method is online available.
</details>
<details>
<summary>摘要</summary>
深度神经网络容易受到后门攻击（Trojan），攻击者在训练集中杀断特定目标类的识别器，使神经网络在测试时通过特定目标类来识别测试触发器。最近的研究表明，后门恶意投入会导致模型过度适应（异常大的活化），这种情况下我们提出了一种通用、 после训练剪辑方法来 mitigate 后门攻击，即通过小量的干净样本学习内层活化的约束。我们提出了一种新的方法，选择活化约束来限制分类范围。这种方法在对同类方法进行比较时表现出色，并且具有强大的适应性，可以在X2X攻击、适应攻击和不同的 datasets 上进行验证。最后，我们还示出了一种基于输出差异的测试时检测和修复方法。我们的方法代码在线可用。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-Deep-Learning-and-Data-Preprocessing-Techniques-for-Detection-Prediction-and-Monitoring-of-Stress-and-Stress-related-Mental-Disorders-A-Scoping-Review"><a href="#Machine-Learning-Deep-Learning-and-Data-Preprocessing-Techniques-for-Detection-Prediction-and-Monitoring-of-Stress-and-Stress-related-Mental-Disorders-A-Scoping-Review" class="headerlink" title="Machine Learning, Deep Learning and Data Preprocessing Techniques for Detection, Prediction, and Monitoring of Stress and Stress-related Mental Disorders: A Scoping Review"></a>Machine Learning, Deep Learning and Data Preprocessing Techniques for Detection, Prediction, and Monitoring of Stress and Stress-related Mental Disorders: A Scoping Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04616">http://arxiv.org/abs/2308.04616</a></li>
<li>repo_url: None</li>
<li>paper_authors: Moein Razavi, Samira Ziyadidegan, Reza Jahromi, Saber Kazeminasab, Vahid Janfaza, Ahmadreza Mahmoudzadeh, Elaheh Baharlouei, Farzan Sasangohar</li>
<li>for: 本研究旨在系统评估机器学习（ML）方法在压力检测、预测和分析中的应用。</li>
<li>methods: 该研究使用了严格的探索性评估方法，检查了最新的ML算法、预处理技术和数据类型在压力和压力相关的神经病中的应用。</li>
<li>results: 研究发现，支持向量机器（SVM）、神经网络（NN）和随机森林（RF）模型在所有机器学习算法中具有最高精度和稳定性。此外， Physiological parameters，如心率测量和皮肤响应，是压力预测中最常用的数据类型。<details>
<summary>Abstract</summary>
This comprehensive review systematically evaluates Machine Learning (ML) methodologies employed in the detection, prediction, and analysis of mental stress and its consequent mental disorders (MDs). Utilizing a rigorous scoping review process, the investigation delves into the latest ML algorithms, preprocessing techniques, and data types employed in the context of stress and stress-related MDs. The findings highlight that Support Vector Machine (SVM), Neural Network (NN), and Random Forest (RF) models consistently exhibit superior accuracy and robustness among all machine learning algorithms examined. Furthermore, the review underscores that physiological parameters, such as heart rate measurements and skin response, are prevalently used as stress predictors in ML algorithms. This is attributed to their rich explanatory information concerning stress and stress-related MDs, as well as the relative ease of data acquisition. Additionally, the application of dimensionality reduction techniques, including mappings, feature selection, filtering, and noise reduction, is frequently observed as a crucial step preceding the training of ML algorithms. The synthesis of this review identifies significant research gaps and outlines future directions for the field. These encompass areas such as model interpretability, model personalization, the incorporation of naturalistic settings, and real-time processing capabilities for detection and prediction of stress and stress-related MDs.
</details>
<details>
<summary>摘要</summary>
The findings show that Support Vector Machine (SVM), Neural Network (NN), and Random Forest (RF) models consistently demonstrate superior accuracy and robustness among all ML algorithms examined. Additionally, the review highlights that physiological parameters, such as heart rate measurements and skin response, are commonly used as stress predictors in ML algorithms due to their rich explanatory information and ease of data acquisition.The review also notes that dimensionality reduction techniques, such as mappings, feature selection, filtering, and noise reduction, are frequently applied as a crucial step before training ML algorithms.The synthesis of this review identifies significant research gaps and outlines future directions for the field, including model interpretability, model personalization, the incorporation of naturalistic settings, and real-time processing capabilities for detection and prediction of stress and stress-related MDs.
</details></li>
</ul>
<hr>
<h2 id="Sparse-Array-Design-for-Direction-Finding-using-Deep-Learning"><a href="#Sparse-Array-Design-for-Direction-Finding-using-Deep-Learning" class="headerlink" title="Sparse Array Design for Direction Finding using Deep Learning"></a>Sparse Array Design for Direction Finding using Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04615">http://arxiv.org/abs/2308.04615</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kumar Vijay Mishra, Ahmet M. Elbir, Koichi Ichige</li>
<li>for: 这些研究旨在应用深度学习（DL）技术来设计稀疏数组，以便实现特征工程和预测阶段的低复杂性，以涉及到稀疏数组的 combinatorial search。</li>
<li>methods: 这些研究使用了监督学习和转移学习技术，以及元优化学习算法如模拟热处理，以解决二维稀疏数组设计问题。</li>
<li>results: 这些研究通过数字实验显示了模型基于优化和DL技术的性能，并讨论了对于稀疏数组设计问题的多种实际应用，包括认知雷达、无线通信和 интеGRATED sensing和通信（ISAC）应用。<details>
<summary>Abstract</summary>
In the past few years, deep learning (DL) techniques have been introduced for designing sparse arrays. These methods offer the advantages of feature engineering and low prediction-stage complexity, which is helpful in tackling the combinatorial search inherent to finding a sparse array. In this chapter, we provide a synopsis of several direction finding applications of DL-based sparse arrays. We begin by examining supervised and transfer learning techniques that have applications in selecting sparse arrays for a cognitive radar application. Here, we also discuss the use of meta-heuristic learning algorithms such as simulated annealing for the case of designing two-dimensional sparse arrays. Next, we consider DL-based antenna selection for wireless communications, wherein sparse array problem may also be combined with channel estimation, beamforming, or localization. Finally, we provide an example of deep sparse array technique for integrated sensing and communications (ISAC) application, wherein a trade-off of radar and communications performance makes ISAC sparse array problem very challenging. For each setting, we illustrate the performance of model-based optimization and DL techniques through several numerical experiments. We discuss additional considerations required to ensure robustness of DL-based algorithms against various imperfections in array data.
</details>
<details>
<summary>摘要</summary>
We begin by examining supervised and transfer learning techniques that have applications in selecting sparse arrays for a cognitive radar system. We also discuss the use of meta-heuristic learning algorithms such as simulated annealing for the case of designing two-dimensional sparse arrays.Next, we consider DL-based antenna selection for wireless communications, where the sparse array problem may also be combined with channel estimation, beamforming, or localization. Finally, we provide an example of deep sparse array techniques for integrated sensing and communications (ISAC) applications, where a trade-off between radar and communications performance makes ISAC sparse array problems very challenging.For each setting, we illustrate the performance of model-based optimization and DL techniques through several numerical experiments. We also discuss additional considerations required to ensure the robustness of DL-based algorithms against various imperfections in array data.
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-Driven-Detection-of-Tsunami-Related-Internal-GravityWaves-a-path-towards-open-ocean-natural-hazards-detection"><a href="#Deep-Learning-Driven-Detection-of-Tsunami-Related-Internal-GravityWaves-a-path-towards-open-ocean-natural-hazards-detection" class="headerlink" title="Deep Learning Driven Detection of Tsunami Related Internal GravityWaves: a path towards open-ocean natural hazards detection"></a>Deep Learning Driven Detection of Tsunami Related Internal GravityWaves: a path towards open-ocean natural hazards detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04611">http://arxiv.org/abs/2308.04611</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/vc1492a/tidd">https://github.com/vc1492a/tidd</a></li>
<li>paper_authors: Valentino Constantinou, Michela Ravanelli, Hamlin Liu, Jacob Bortnik</li>
<li>for: 这个论文是为了检测地震引起的内力波在电离层中的影响，以提高早期警报系统的精度。</li>
<li>methods: 这个研究使用了GNSS数据和深度学习技术，并将slant total electron content（sTEC）从VARION算法和计算机视觉中的Gramian Angular Difference Fields（GADF）和卷积神经网络（CNN）组合使用，以实时检测内力波。</li>
<li>results: 研究结果显示，使用这种方法可以在near-real-time中检测到内力波，并在2010年的墨西哥大地震、2011年的东北大地震和2012年的海达岛大地震中达到了91.7%的F1分数。<details>
<summary>Abstract</summary>
Tsunamis can trigger internal gravity waves (IGWs) in the ionosphere, perturbing the Total Electron Content (TEC) - referred to as Traveling Ionospheric Disturbances (TIDs) that are detectable through the Global Navigation Satellite System (GNSS). The GNSS are constellations of satellites providing signals from Earth orbit - Europe's Galileo, the United States' Global Positioning System (GPS), Russia's Global'naya Navigatsionnaya Sputnikovaya Sistema (GLONASS) and China's BeiDou. The real-time detection of TIDs provides an approach for tsunami detection, enhancing early warning systems by providing open-ocean coverage in geographic areas not serviceable by buoy-based warning systems. Large volumes of the GNSS data is leveraged by deep learning, which effectively handles complex non-linear relationships across thousands of data streams. We describe a framework leveraging slant total electron content (sTEC) from the VARION (Variometric Approach for Real-Time Ionosphere Observation) algorithm by Gramian Angular Difference Fields (from Computer Vision) and Convolutional Neural Networks (CNNs) to detect TIDs in near-real-time. Historical data from the 2010 Maule, 2011 Tohoku and the 2012 Haida-Gwaii earthquakes and tsunamis are used in model training, and the later-occurring 2015 Illapel earthquake and tsunami in Chile for out-of-sample model validation. Using the experimental framework described in the paper, we achieved a 91.7% F1 score. Source code is available at: https://github.com/vc1492a/tidd. Our work represents a new frontier in detecting tsunami-driven IGWs in open-ocean, dramatically improving the potential for natural hazards detection for coastal communities.
</details>
<details>
<summary>摘要</summary>
TSUNAMIS可以触发内部重力波（IGW）在电离层，干扰全电子内容（TEC），被称为旅行 ionospheric 干扰（TIDs），可以通过全球导航卫星系统（GNSS）探测。GNSS 包括欧盟的加利列オ（Galileo）、美国的全球定位系统（GPS）、俄罗斯的全球卫星导航系统（GLONASS）和中国的北斗卫星导航系统（BeiDou）。实时探测 TIDs 提供了一种方法，用于早期警报系统，提供了不可达的开 ocean 覆盖。通过深入学习，可以有效处理复杂的非线性关系，并处理数千个数据流。我们描述了一个框架，利用倾斜全电子内容（sTEC）从VARION（Variometric Approach for Real-Time Ionosphere Observation）算法、格里曼angular Difference Fields（from Computer Vision）和卷积神经网络（CNNs）来探测 TIDs 的实时探测。历史数据来自2010年智利地震、2011年日本地震和2012年加拿大海啸，用于模型训练，而2015年智利地震用于模型验证。使用我们所描述的实验框架，我们实现了 91.7% F1 分数。源代码可以在 GitHub 上获取：https://github.com/vc1492a/tidd。我们的工作代表了一种新的前沿，用于探测在开 ocean 中的地震引起的 IGW，这将在沿海社区中提高天然威胁探测的潜在性。
</details></li>
</ul>
<hr>
<h2 id="PSRFlow-Probabilistic-Super-Resolution-with-Flow-Based-Models-for-Scientific-Data"><a href="#PSRFlow-Probabilistic-Super-Resolution-with-Flow-Based-Models-for-Scientific-Data" class="headerlink" title="PSRFlow: Probabilistic Super Resolution with Flow-Based Models for Scientific Data"></a>PSRFlow: Probabilistic Super Resolution with Flow-Based Models for Scientific Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04605">http://arxiv.org/abs/2308.04605</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingyi Shen, Han-Wei Shen</li>
<li>for: 科学数据超分辨化，以避免生成错误或不正确的信息。</li>
<li>methods: 使用normalizing flow-based生成模型PSRFlow，包括uncertainty量化。</li>
<li>results: 与插值和GAN-based超分辨化网络相比，表现出色，并且可以正确地衡量超分辨化结果的不确定性。<details>
<summary>Abstract</summary>
Although many deep-learning-based super-resolution approaches have been proposed in recent years, because no ground truth is available in the inference stage, few can quantify the errors and uncertainties of the super-resolved results. For scientific visualization applications, however, conveying uncertainties of the results to scientists is crucial to avoid generating misleading or incorrect information. In this paper, we propose PSRFlow, a novel normalizing flow-based generative model for scientific data super-resolution that incorporates uncertainty quantification into the super-resolution process. PSRFlow learns the conditional distribution of the high-resolution data based on the low-resolution counterpart. By sampling from a Gaussian latent space that captures the missing information in the high-resolution data, one can generate different plausible super-resolution outputs. The efficient sampling in the Gaussian latent space allows our model to perform uncertainty quantification for the super-resolved results. During model training, we augment the training data with samples across various scales to make the model adaptable to data of different scales, achieving flexible super-resolution for a given input. Our results demonstrate superior performance and robust uncertainty quantification compared with existing methods such as interpolation and GAN-based super-resolution networks.
</details>
<details>
<summary>摘要</summary>
尽管最近几年内有许多基于深度学习的超分辨率方法被提出，但由于无法在推理阶段获得真实的参照值，因此只能很少量化错误和不确定性。在科学视觉应用中，却非常重要将超分辨率结果的不确定性传递给科学家，以避免生成错误或 incorrect 信息。在本文中，我们提出了 PSRFlow，一种基于正规流的生成模型，用于科学数据超分辨率。PSRFlow 学习了高分辨率数据的假设分布，基于低分辨率数据。通过在 Gaussian 隐藏空间中采样，可以生成不同可能的超分辨率输出。在 Gaussian 隐藏空间中高效采样可以实现对超分辨率结果的不确定性评估。在模型训练过程中，我们将训练数据进行了不同尺度的扩展，使模型适应不同的尺度，实现数据的灵活超分辨率。我们的结果表明，与既有方法相比，PSRFlow 具有更高的性能和更精准的不确定性评估。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Decentralized-Federated-Learning"><a href="#A-Survey-on-Decentralized-Federated-Learning" class="headerlink" title="A Survey on Decentralized Federated Learning"></a>A Survey on Decentralized Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04604">http://arxiv.org/abs/2308.04604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Edoardo Gabrielli, Giovanni Pica, Gabriele Tolomei</li>
<li>for: 这篇论文主要是为了探讨分布式学习（Federated Learning，FL）中的分布式客户端服务器架构，以及其中的安全性和可靠性问题。</li>
<li>methods: 这篇论文主要采用文献综述的方法，对现有的分布式FL方法进行了系统的梳理和评估。同时，它还提出了一些未来研究方向，以解决现有的挑战和问题。</li>
<li>results: 这篇论文主要的结果是，现有的分布式FL方法存在一些潜在的安全性和可靠性问题，如中央服务器的单点失败风险和人在中攻击等。同时，它还提出了一些未来研究方向，以解决现有的挑战和问题。<details>
<summary>Abstract</summary>
In recent years, federated learning (FL) has become a very popular paradigm for training distributed, large-scale, and privacy-preserving machine learning (ML) systems. In contrast to standard ML, where data must be collected at the exact location where training is performed, FL takes advantage of the computational capabilities of millions of edge devices to collaboratively train a shared, global model without disclosing their local private data. Specifically, in a typical FL system, the central server acts only as an orchestrator; it iteratively gathers and aggregates all the local models trained by each client on its private data until convergence. Although FL undoubtedly has several benefits over traditional ML (e.g., it protects private data ownership by design), it suffers from several weaknesses. One of the most critical challenges is to overcome the centralized orchestration of the classical FL client-server architecture, which is known to be vulnerable to single-point-of-failure risks and man-in-the-middle attacks, among others. To mitigate such exposure, decentralized FL solutions have emerged where all FL clients cooperate and communicate without a central server. This survey comprehensively summarizes and reviews existing decentralized FL approaches proposed in the literature. Furthermore, it identifies emerging challenges and suggests promising research directions in this under-explored domain.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Deep-Learning-based-Image-Watermarking-A-Brief-Survey"><a href="#Deep-Learning-based-Image-Watermarking-A-Brief-Survey" class="headerlink" title="Deep Learning based Image Watermarking: A Brief Survey"></a>Deep Learning based Image Watermarking: A Brief Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04603">http://arxiv.org/abs/2308.04603</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Zhong, Arjon Das, Fahad Alrasheedi, Abdullah Tanvir</li>
<li>for: 保护图像 against unauthorized use and distribution</li>
<li>methods: 使用深度学习技术，包括Embedder-Extractor Joint Training、Deep Networks as a Feature Transformation和Hybrid schemes</li>
<li>results: 分析了现有的深度学习图像水印技术，并提出了未来研究的可能性。<details>
<summary>Abstract</summary>
The act of secretly embedding and extracting a watermark on a cover image to protect it is known as image watermarking. In recent years, deep learning-based image watermarking techniques have been emerging one after another. To study the state-of-the-art, this survey categorizes cutting-edge deep learning-based image watermarking techniques into Embedder-Extractor Joint Training, Deep Networks as a Feature Transformation, and Hybrid schemes. Research directions in each category are also analyzed and summarized. Additionally, potential future research directions are discussed to envision future studies.
</details>
<details>
<summary>摘要</summary>
“图像水印”是指在封面图像上隐藏并提取水印以保护图像的行为。在最近几年，基于深度学习的图像水印技术逐渐涌现。本笔报告将这些技术分为三类：嵌入器-提取器共同训练、深度网络作为特征转换和混合方案。每个类别的研究方向也进行了分析和总结。此外，未来研究的可能性也被讨论了，以便预测未来的研究方向。
</details></li>
</ul>
<hr>
<h2 id="Quantization-Aware-Factorization-for-Deep-Neural-Network-Compression"><a href="#Quantization-Aware-Factorization-for-Deep-Neural-Network-Compression" class="headerlink" title="Quantization Aware Factorization for Deep Neural Network Compression"></a>Quantization Aware Factorization for Deep Neural Network Compression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04595">http://arxiv.org/abs/2308.04595</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daria Cherniuk, Stanislav Abukhovich, Anh-Huy Phan, Ivan Oseledets, Andrzej Cichocki, Julia Gusak</li>
<li>for: 这个研究旨在开发一个能够同时实现对 neural network 的量化和缩减实现的算法，以提高 deployed 模型的处理能力和能效性。</li>
<li>methods: 本研究使用 Alternating Direction Method of Multipliers (ADMM) for Canonical Polyadic (CP) decomposition with quantized factors, 以实现tensor decomposition的缩减和量化。</li>
<li>results: 试验结果显示， compared to state-of-the-art post-training quantization methods, 本方法可以实现高品质和高效性的平衡，并且具有高的灵活性和可靠性。<details>
<summary>Abstract</summary>
Tensor decomposition of convolutional and fully-connected layers is an effective way to reduce parameters and FLOP in neural networks. Due to memory and power consumption limitations of mobile or embedded devices, the quantization step is usually necessary when pre-trained models are deployed. A conventional post-training quantization approach applied to networks with decomposed weights yields a drop in accuracy. This motivated us to develop an algorithm that finds tensor approximation directly with quantized factors and thus benefit from both compression techniques while keeping the prediction quality of the model. Namely, we propose to use Alternating Direction Method of Multipliers (ADMM) for Canonical Polyadic (CP) decomposition with factors whose elements lie on a specified quantization grid. We compress neural network weights with a devised algorithm and evaluate it's prediction quality and performance. We compare our approach to state-of-the-art post-training quantization methods and demonstrate competitive results and high flexibility in achiving a desirable quality-performance tradeoff.
</details>
<details>
<summary>摘要</summary>
《神经网络参数和计算量减少的tensor分解技术》是一种有效的神经网络减少参数和计算量的方法。由于移动或嵌入式设备的内存和电力限制，通常需要进行量化步骤才能在这些设备上部署预训练模型。然而，通常的后期量化方法在使用分解的 weights 时会导致模型的准确率下降。这种情况 Motivated us 开发一种直接使用量化因子进行tensorapproximation的算法，以便同时利用压缩技术，保持模型预测质量。具体来说，我们提出使用 Alternating Direction Method of Multipliers (ADMM)  для canonical polyadic (CP) 分解，其中因子的元素 lying on a specified quantization grid。我们使用自定义的算法压缩神经网络参数，并评估其预测质量和性能。我们与state-of-the-art post-training quantization方法进行比较，并表现出高的灵活性和满足 desire quality-performance tradeoff。
</details></li>
</ul>
<hr>
<h2 id="ScatterUQ-Interactive-Uncertainty-Visualizations-for-Multiclass-Deep-Learning-Problems"><a href="#ScatterUQ-Interactive-Uncertainty-Visualizations-for-Multiclass-Deep-Learning-Problems" class="headerlink" title="ScatterUQ: Interactive Uncertainty Visualizations for Multiclass Deep Learning Problems"></a>ScatterUQ: Interactive Uncertainty Visualizations for Multiclass Deep Learning Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04588">http://arxiv.org/abs/2308.04588</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mit-ll-responsible-ai/equine-webapp">https://github.com/mit-ll-responsible-ai/equine-webapp</a></li>
<li>paper_authors: Harry Li, Steven Jorgensen, John Holodnak, Allan Wollaber</li>
<li>for: 这个论文是为了解释深度学习模型在多类标签问题中的不确定性，并提供了可靠的分类预测概率和 OUT-OF-Distribution (OOD) 指标，以便机器学习（ML）consumers和工程师可以评估模型对测试示例的预测 confidence。</li>
<li>methods: 这个论文使用了uncertainty-aware深度学习方法，包括距离意识 neural network 和dimensionality reduction技术，以构建可靠的2-D散点图，解释模型对测试示例的预测原因。</li>
<li>results: 这个论文通过一种交互式系统ScatterUQ，可以让用户更好地理解模型在不同不确定性 Settings下的性能，并通过 hover 回调来比较测试示例和训练示例的材料特征，以了解模型uncertainty性能和进行后续操作。<details>
<summary>Abstract</summary>
Recently, uncertainty-aware deep learning methods for multiclass labeling problems have been developed that provide calibrated class prediction probabilities and out-of-distribution (OOD) indicators, letting machine learning (ML) consumers and engineers gauge a model's confidence in its predictions. However, this extra neural network prediction information is challenging to scalably convey visually for arbitrary data sources under multiple uncertainty contexts. To address these challenges, we present ScatterUQ, an interactive system that provides targeted visualizations to allow users to better understand model performance in context-driven uncertainty settings. ScatterUQ leverages recent advances in distance-aware neural networks, together with dimensionality reduction techniques, to construct robust, 2-D scatter plots explaining why a model predicts a test example to be (1) in-distribution and of a particular class, (2) in-distribution but unsure of the class, and (3) out-of-distribution. ML consumers and engineers can visually compare the salient features of test samples with training examples through the use of a ``hover callback'' to understand model uncertainty performance and decide follow up courses of action. We demonstrate the effectiveness of ScatterUQ to explain model uncertainty for a multiclass image classification on a distance-aware neural network trained on Fashion-MNIST and tested on Fashion-MNIST (in distribution) and MNIST digits (out of distribution), as well as a deep learning model for a cyber dataset. We quantitatively evaluate dimensionality reduction techniques to optimize our contextually driven UQ visualizations. Our results indicate that the ScatterUQ system should scale to arbitrary, multiclass datasets. Our code is available at https://github.com/mit-ll-responsible-ai/equine-webapp
</details>
<details>
<summary>摘要</summary>
近期，对多类标签问题的不确定性意识深度学习方法已经发展出来，这些方法可以提供标量预测概率和外部数据（OOD）指示器，让机器学习（ML）用户和工程师可以评估模型对预测的自信心。然而，这些额外神经网络预测信息在多种不确定性Setting下可能困难减少可扩展的可视化显示。为解决这些挑战，我们现在介绍ScatterUQ，一个互动系统，可以提供特定的可视化来让用户更好地理解模型在受限制的不确定性设置下的性能。ScatterUQ利用了最新的距离意识神经网络和维度减少技术，构建了可靠的2D散点图，解释模型对测试示例的预测是（1）在distribution中，（2）在distribution中，但是不确定的类别，以及（3）外部数据。通过使用“悬停回调”，ML用户和工程师可以通过比较测试示例与训练示例的材料特征来理解模型不确定性性能，并根据需要采取后续行动。我们在多类图像分类任务上使用了距离意识神经网络，并在Fashion-MNIST和MNIST数字上进行了测试，以及一个深度学习模型 для一个网络安全任务。我们对维度减少技术进行了量化评估，以便优化我们在不同上下文中的UQ视觉表示。我们的结果表明，ScatterUQ系统可以扩展到任意多类数据集。我们的代码可以在https://github.com/mit-ll-responsible-ai/equine-webapp 上获取。
</details></li>
</ul>
<hr>
<h2 id="Kernel-Single-Proxy-Control-for-Deterministic-Confounding"><a href="#Kernel-Single-Proxy-Control-for-Deterministic-Confounding" class="headerlink" title="Kernel Single Proxy Control for Deterministic Confounding"></a>Kernel Single Proxy Control for Deterministic Confounding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04585">http://arxiv.org/abs/2308.04585</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liyuan Xu, Arthur Gretton</li>
<li>for: 该文章目标是探讨 causal effect estimation 中隐藏 confounder 的问题，并提出了一种基于 proxy 变量的方法。</li>
<li>methods: 该文章使用了两种基于 kernel 的方法：一种是基于 two-stage regression 方法，另一种是基于最大 momentum restriction 方法。</li>
<li>results: 该文章通过实验表明，使用单个 proxy 变量可以成功地估计 causal effect，并且可以在 synthetic dataset 上成功地回归 true causal effect。<details>
<summary>Abstract</summary>
We consider the problem of causal effect estimation with an unobserved confounder, where we observe a proxy variable that is associated with the confounder. Although Proxy Causal Learning (PCL) uses two proxy variables to recover the true causal effect, we show that a single proxy variable is sufficient for causal estimation if the outcome is generated deterministically, generalizing Control Outcome Calibration Approach (COCA). We propose two kernel-based methods for this setting: the first based on the two-stage regression approach, and the second based on a maximum moment restriction approach. We prove that both approaches can consistently estimate the causal effect, and we empirically demonstrate that we can successfully recover the causal effect on a synthetic dataset.
</details>
<details>
<summary>摘要</summary>
我团队考虑了一个 causal effect 估计问题，其中存在一个未观测的假设变量。我们观察了一个代表变量，该变量与假设变量相关。虽然 Proxy Causal Learning（PCL）使用了两个代表变量来恢复真实的 causal effect，但我们显示了一个单个代表变量足够于 causal 估计，如果结果是 deterministic 生成的，则推广 Control Outcome Calibration Approach（COCA）。我们提出了两种基于 kernel 方法来解决这个问题：第一种基于 two-stage 回归方法，第二种基于最大 moments 约束方法。我们证明了这两种方法都可靠地估计 causal effect，并在一个 synthetic 数据集上进行了实验验证。
</details></li>
</ul>
<hr>
<h2 id="RECipe-Does-a-Multi-Modal-Recipe-Knowledge-Graph-Fit-a-Multi-Purpose-Recommendation-System"><a href="#RECipe-Does-a-Multi-Modal-Recipe-Knowledge-Graph-Fit-a-Multi-Purpose-Recommendation-System" class="headerlink" title="RECipe: Does a Multi-Modal Recipe Knowledge Graph Fit a Multi-Purpose Recommendation System?"></a>RECipe: Does a Multi-Modal Recipe Knowledge Graph Fit a Multi-Purpose Recommendation System?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04579">http://arxiv.org/abs/2308.04579</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ali Pesaranghader, Touqir Sajed</li>
<li>for: 本研究旨在提出一个多功能的食谱推荐框架，以解决食谱推荐的问题。</li>
<li>methods: 本研究使用多Modal知识图（MMKG）作为基础，并提出了三个互补性推荐子系统：行为基于推荐、评论基于推荐和图像基于推荐。每个子系统都利用知识图中的实体和关系的嵌入表示进行推荐。</li>
<li>results: 对于两个公开 dataset 上的食谱推荐问题，我们的实验结果表明，KGE 模型与深度神经 Collaborative Filtering（NCF）的性能相似。此外，我们还提出了针对新用户（即冷启动问题）和食谱类别 conditional 推荐的适用方案。最后，我们将 RECipe 应用于多功能推荐设定中。<details>
<summary>Abstract</summary>
Over the past two decades, recommendation systems (RSs) have used machine learning (ML) solutions to recommend items, e.g., movies, books, and restaurants, to clients of a business or an online platform. Recipe recommendation, however, has not yet received much attention compared to those applications. We introduce RECipe as a multi-purpose recipe recommendation framework with a multi-modal knowledge graph (MMKG) backbone. The motivation behind RECipe is to go beyond (deep) neural collaborative filtering (NCF) by recommending recipes to users when they query in natural language or by providing an image. RECipe consists of 3 subsystems: (1) behavior-based recommender, (2) review-based recommender, and (3) image-based recommender. Each subsystem relies on the embedding representations of entities and relations in the graph. We first obtain (pre-trained) embedding representations of textual entities, such as reviews or ingredients, from a fine-tuned model of Microsoft's MPNet. We initialize the weights of the entities with these embeddings to train our knowledge graph embedding (KGE) model. For the visual component, i.e., recipe images, we develop a KGE-Guided variational autoencoder (KG-VAE) to learn the distribution of images and their latent representations. Once KGE and KG-VAE models are fully trained, we use them as a multi-purpose recommendation framework. For benchmarking, we created two knowledge graphs (KGs) from public datasets on Kaggle for recipe recommendation. Our experiments show that the KGE models have comparable performance to the neural solutions. We also present pre-trained NLP embeddings to address important applications such as zero-shot inference for new users (or the cold start problem) and conditional recommendation with respect to recipe categories. We eventually demonstrate the application of RECipe in a multi-purpose recommendation setting.
</details>
<details>
<summary>摘要</summary>
RECipe consists of three subsystems: (1) behavior-based recommender, (2) review-based recommender, and (3) image-based recommender. Each subsystem relies on the embedding representations of entities and relations in the graph. We first obtain (pre-trained) embedding representations of textual entities, such as reviews or ingredients, from a fine-tuned model of Microsoft's MPNet. We initialize the weights of the entities with these embeddings to train our knowledge graph embedding (KGE) model. For the visual component, i.e., recipe images, we develop a KGE-Guided variational autoencoder (KG-VAE) to learn the distribution of images and their latent representations. Once KGE and KG-VAE models are fully trained, we use them as a multi-purpose recommendation framework.For benchmarking, we created two knowledge graphs (KGs) from public datasets on Kaggle for recipe recommendation. Our experiments show that the KGE models have comparable performance to the neural solutions. We also present pre-trained NLP embeddings to address important applications such as zero-shot inference for new users (or the cold start problem) and conditional recommendation with respect to recipe categories. We eventually demonstrate the application of RECipe in a multi-purpose recommendation setting.Translation notes:* "Over the past two decades" is translated as "过去二十年" (guò qù èr shí nián), using the past perfect tense to indicate that the events described in the sentence took place before a specific time in the past.* "recommendation systems" is translated as "推荐系统" (tuī yù xìng zhì), using the pinyin romanization of the Chinese term.* "machine learning" is translated as "机器学习" (jī shì xué xí), using the Chinese term for the field.* "solutions" is translated as "解决方案" (jiě jí fāng àn), using the Chinese term for "solution" or "answer".* "recipe" is translated as "菜谱" (cào bù), using the Chinese term for "recipe".* "users" is translated as "用户" (yòng hù), using the Chinese term for "user".* "queries" is translated as "查询" (chá xún), using the Chinese term for "query".* "natural language" is translated as "自然语言" (zì rán yǔ yán), using the Chinese term for "natural language".* "image" is translated as "图像" (tú xiàng), using the Chinese term for "image".* "entities" is translated as "实体" (shí tǐ), using the Chinese term for "entity".* "relations" is translated as "关系" (guān xì), using the Chinese term for "relation".* "knowledge graph" is translated as "知识图" (zhī shí tú), using the Chinese term for "knowledge graph".* "backbone" is translated as "基础结构" (jī jí jié gòng), using the Chinese term for "backbone" or "basis".* "multi-modal" is translated as "多Modal" (duō mó dāo), using the Chinese term for "multi-modal".* "embedding representations" is translated as "嵌入表示" (fàn shì biǎo xiǎng), using the Chinese term for "embedding representation".* "pre-trained" is translated as "预训练" (zhāng xiǎng xiǎng), using the Chinese term for "pre-trained".* "variational autoencoder" is translated as "变量自适应器" (biàn yù zì shì qǐng), using the Chinese term for "variational autoencoder".* "KGE" is translated as "知识图加 embedding" (zhī shí tú jiā embedding), using the Chinese term for "knowledge graph embedding".* "NLP" is translated as "自然语言处理" (zì rán yǔ yán bù), using the Chinese term for "natural language processing".* "zero-shot" is translated as "零枪指" (zhì zhèng zhǐ), using the Chinese term for "zero-shot".* "cold start" is translated as "冰点问题" (bīng diǎn wèn tí), using the Chinese term for "cold start problem".* "conditional" is translated as "条件" (tiáo jiàn), using the Chinese term for "conditional".* "recipe categories" is translated as "菜谱分类" (cào bù fēn lèi), using the Chinese term for "recipe categories".* "multi-purpose" is translated as "多目的" (duō mù de), using the Chinese term for "multi-purpose".Note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore.
</details></li>
</ul>
<hr>
<h2 id="Copy-Number-Variation-Informs-fMRI-based-Prediction-of-Autism-Spectrum-Disorder"><a href="#Copy-Number-Variation-Informs-fMRI-based-Prediction-of-Autism-Spectrum-Disorder" class="headerlink" title="Copy Number Variation Informs fMRI-based Prediction of Autism Spectrum Disorder"></a>Copy Number Variation Informs fMRI-based Prediction of Autism Spectrum Disorder</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05122">http://arxiv.org/abs/2308.05122</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nicha C. Dvornek, Catherine Sullivan, James S. Duncan, Abha R. Gupta</li>
<li>for: 这个论文旨在探讨多因素性的自闭症 спектル中的多模态方法，以结合不同平台的数据进行研究。</li>
<li>methods: 这个论文提出了一种基于注意力的方法，使用基因数据引导注意力于功能核磁共振成像特征，以提高自闭症分类和严重程度预测性能。</li>
<li>results: 研究人员通过对228例自闭症和正常发育者的数据进行十 fold十字验证，证明了这种注意力基于方法在自闭症分类和严重程度预测任务中的优于其他多模态方法。<details>
<summary>Abstract</summary>
The multifactorial etiology of autism spectrum disorder (ASD) suggests that its study would benefit greatly from multimodal approaches that combine data from widely varying platforms, e.g., neuroimaging, genetics, and clinical characterization. Prior neuroimaging-genetic analyses often apply naive feature concatenation approaches in data-driven work or use the findings from one modality to guide posthoc analysis of another, missing the opportunity to analyze the paired multimodal data in a truly unified approach. In this paper, we develop a more integrative model for combining genetic, demographic, and neuroimaging data. Inspired by the influence of genotype on phenotype, we propose using an attention-based approach where the genetic data guides attention to neuroimaging features of importance for model prediction. The genetic data is derived from copy number variation parameters, while the neuroimaging data is from functional magnetic resonance imaging. We evaluate the proposed approach on ASD classification and severity prediction tasks, using a sex-balanced dataset of 228 ASD and typically developing subjects in a 10-fold cross-validation framework. We demonstrate that our attention-based model combining genetic information, demographic data, and functional magnetic resonance imaging results in superior prediction performance compared to other multimodal approaches.
</details>
<details>
<summary>摘要</summary>
Autism spectrum disorder (ASD) 的多因素起源 suggests that studying it would greatly benefit from 多模态方法， combine 数据 from 各种不同的平台，例如 neuroscience imaging, genetics, and clinical characterization. Previous neuroimaging-genetic analyses often use naive feature concatenation approaches in data-driven work or use the findings from one modality to guide post hoc analysis of another, missing the opportunity to analyze the paired multimodal data in a truly unified approach. In this paper, we develop a more integrative model for combining genetic, demographic, and neuroimaging data. Inspired by the influence of genotype on phenotype, we propose using an attention-based approach where the genetic data guides attention to neuroimaging features of importance for model prediction. The genetic data is derived from copy number variation parameters, while the neuroimaging data is from functional magnetic resonance imaging. We evaluate the proposed approach on ASD classification and severity prediction tasks, using a sex-balanced dataset of 228 ASD and typically developing subjects in a 10-fold cross-validation framework. We demonstrate that our attention-based model combining genetic information, demographic data, and functional magnetic resonance imaging results in superior prediction performance compared to other multimodal approaches.
</details></li>
</ul>
<hr>
<h2 id="From-Fake-to-Real-FFR-A-two-stage-training-pipeline-for-mitigating-spurious-correlations-with-synthetic-data"><a href="#From-Fake-to-Real-FFR-A-two-stage-training-pipeline-for-mitigating-spurious-correlations-with-synthetic-data" class="headerlink" title="From Fake to Real (FFR): A two-stage training pipeline for mitigating spurious correlations with synthetic data"></a>From Fake to Real (FFR): A two-stage training pipeline for mitigating spurious correlations with synthetic data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04553">http://arxiv.org/abs/2308.04553</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maan Qraitem, Kate Saenko, Bryan A. Plummer</li>
<li>for:  mitigate the bias in visual recognition models caused by an imbalanced training set</li>
<li>methods:  pre-train a model on a balanced synthetic dataset, fine-tune on real data, and learn robust features against the bias</li>
<li>results:  improve the performance of bias mitigation methods and achieve state-of-the-art performance on three large-scale datasets<details>
<summary>Abstract</summary>
Visual recognition models are prone to learning spurious correlations induced by an imbalanced training set where certain groups (\eg Females) are under-represented in certain classes (\eg Programmers). Generative models offer a promising direction in mitigating this bias by generating synthetic data for the minority samples and thus balancing the training set. However, prior work that uses these approaches overlooks that visual recognition models could often learn to differentiate between real and synthetic images and thus fail to unlearn the bias in the original dataset. In our work, we propose a novel two-stage pipeline to mitigate this issue where 1) we pre-train a model on a balanced synthetic dataset and then 2) fine-tune on the real data. Using this pipeline, we avoid training on both real and synthetic data, thus avoiding the bias between real and synthetic data. Moreover, we learn robust features against the bias in the first step that mitigate the bias in the second step. Moreover, our pipeline naturally integrates with bias mitigation methods; they can be simply applied to the fine-tuning step. As our experiments prove, our pipeline can further improve the performance of bias mitigation methods obtaining state-of-the-art performance on three large-scale datasets.
</details>
<details>
<summary>摘要</summary>
视觉识别模型容易学习偏袋性词induced by an imbalanced训练集，其中certain groups（例如女性）在certain classes（例如程序员）下是under-represented。生成模型提供了一个promising direction来mitigate这种偏袋性，通过生成Synthetic数据来填充训练集中的缺失。然而，先前的工作 ignores the fact that visual recognition models could learn to differentiate between real and synthetic images, leading to a failure to unlearn the bias in the original dataset.在我们的工作中，我们提出了一个novel two-stage管道来mitigate this issue，包括：1）先在一个平衡的Synthetic dataset上pre-train模型，然后2）在真实数据上 fine-tune。通过这个管道，我们可以避免训练在真实和Synthetic数据上，从而避免偏袋性between real and Synthetic data。此外，我们在第一步学习了强健的特征，以mitigate偏袋性在第二步。此外，我们的管道自然地与偏袋性mitigation方法集成，它们可以简单地应用到精度调整步骤中。根据我们的实验，我们的管道可以进一步提高偏袋性mitigation方法的性能，在三个大规模数据集上达到状态之 искусственный智能的性能。
</details></li>
</ul>
<hr>
<h2 id="Improving-Medical-Image-Classification-in-Noisy-Labels-Using-Only-Self-supervised-Pretraining"><a href="#Improving-Medical-Image-Classification-in-Noisy-Labels-Using-Only-Self-supervised-Pretraining" class="headerlink" title="Improving Medical Image Classification in Noisy Labels Using Only Self-supervised Pretraining"></a>Improving Medical Image Classification in Noisy Labels Using Only Self-supervised Pretraining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04551">http://arxiv.org/abs/2308.04551</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bbrattoli/JigsawPuzzlePytorch">https://github.com/bbrattoli/JigsawPuzzlePytorch</a></li>
<li>paper_authors: Bidur Khanal, Binod Bhattarai, Bishesh Khanal, Cristian A. Linte</li>
<li>for: 这个研究是为了探讨深度学习基于噪音标签的自然图像分类表现如何受损，以及是否可以使用自我主导学习方法来改善分类性能。</li>
<li>methods: 这个研究使用了两种自我主导学习方法：对于自然图像Dataset，使用了对称自我主导学习，并且使用了预设任务基于自我主导学习。</li>
<li>results: 研究发现，使用自我主导学习方法初始化模型的 weights 可以帮助模型更好地学习噪音标签下的图像分类任务，并且可以提高模型对噪音标签的抗衰假性。<details>
<summary>Abstract</summary>
Noisy labels hurt deep learning-based supervised image classification performance as the models may overfit the noise and learn corrupted feature extractors. For natural image classification training with noisy labeled data, model initialization with contrastive self-supervised pretrained weights has shown to reduce feature corruption and improve classification performance. However, no works have explored: i) how other self-supervised approaches, such as pretext task-based pretraining, impact the learning with noisy label, and ii) any self-supervised pretraining methods alone for medical images in noisy label settings. Medical images often feature smaller datasets and subtle inter class variations, requiring human expertise to ensure correct classification. Thus, it is not clear if the methods improving learning with noisy labels in natural image datasets such as CIFAR would also help with medical images. In this work, we explore contrastive and pretext task-based self-supervised pretraining to initialize the weights of a deep learning classification model for two medical datasets with self-induced noisy labels -- NCT-CRC-HE-100K tissue histological images and COVID-QU-Ex chest X-ray images. Our results show that models initialized with pretrained weights obtained from self-supervised learning can effectively learn better features and improve robustness against noisy labels.
</details>
<details>
<summary>摘要</summary>
噪声标签会对深度学习基于监督学习的图像分类性能产生负面影响，因为模型可能会过拟合噪声并学习损坏的特征提取器。在自然图像分类训练中使用噪声标签数据时，使用对比自我超视的初始化模型 weights 可以降低特征损坏和提高分类性能。然而，现有的研究没有探讨：一、其他自我超视任务基于预测任务的预训练对噪声标签下的学习产生影响，二、任何自我超视预训练方法可以独立地为医学图像中的噪声标签下学习提供帮助。医学图像通常具有较小的数据集和极细的间类变化，需要人工专业来确保正确的分类。因此，是否可以在自然图像 dataset 中使用自我超视预训练来提高噪声标签下的学习，是一个未知问题。在这个工作中，我们探讨了对比和预测任务基于自我超视预训练的影响，以 Initialize 深度学习分类模型的 weights 以便在两个医学图像 dataset 上进行自我induced 噪声标签下的学习。我们的结果表明，使用自我超视预训练初始化模型 weights 可以更好地学习特征和提高对噪声标签的Robustness。
</details></li>
</ul>
<hr>
<h2 id="Improving-Performance-in-Continual-Learning-Tasks-using-Bio-Inspired-Architectures"><a href="#Improving-Performance-in-Continual-Learning-Tasks-using-Bio-Inspired-Architectures" class="headerlink" title="Improving Performance in Continual Learning Tasks using Bio-Inspired Architectures"></a>Improving Performance in Continual Learning Tasks using Bio-Inspired Architectures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04539">http://arxiv.org/abs/2308.04539</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sandeep Madireddy, Angel Yanguas-Gil, Prasanna Balaprakash</li>
<li>for: 这篇论文旨在提出一种基于生物学原理的轻量级神经网络架构，以便在不断接收数据流中不间断地学习，而不需要抽象缓存或重播。</li>
<li>methods: 该论文使用了生物学中的 synaptic plasticity 机制和 neuromodulation，通过本地错误信号来进行学习，从而实现了在线不间断学习而不需要 stochastic gradient descent。</li>
<li>results: 该方法在 Split-MNIST、Split-CIFAR-10 和 Split-CIFAR-100 数据集上表现出色，比较memory-constrained learning方法和 memory-intensive replay-based方法更好，并且可以与state-of-the-art memory-intensive replay-based方法匹配。此外， authors 还将关键的设计元素integrated into other backpropagation-based continual learning algorithms，提高了它们的准确性。<details>
<summary>Abstract</summary>
The ability to learn continuously from an incoming data stream without catastrophic forgetting is critical to designing intelligent systems. Many approaches to continual learning rely on stochastic gradient descent and its variants that employ global error updates, and hence need to adopt strategies such as memory buffers or replay to circumvent its stability, greed, and short-term memory limitations. To address this limitation, we have developed a biologically inspired lightweight neural network architecture that incorporates synaptic plasticity mechanisms and neuromodulation and hence learns through local error signals to enable online continual learning without stochastic gradient descent.   Our approach leads to superior online continual learning performance on Split-MNIST, Split-CIFAR-10, and Split-CIFAR-100 datasets compared to other memory-constrained learning approaches and matches that of the state-of-the-art memory-intensive replay-based approaches. We further demonstrate the effectiveness of our approach by integrating key design concepts into other backpropagation-based continual learning algorithms, significantly improving their accuracy. Our results provide compelling evidence for the importance of incorporating biological principles into machine learning models and offer insights into how we can leverage them to design more efficient and robust systems for online continual learning.
</details>
<details>
<summary>摘要</summary>
“持续学习”是设计智能系统的核心能力。许多持续学习方法 rely 于测验函数均值对应和其变形，因此需要运用记忆缓冲或重播来缓解其稳定性、嗜好和短期记忆限制。为解决这个限制，我们已经开发了基于生物学原理的轻量级神经网络架构，具有synaptic plasticity机制和神经调节，因此可以通过本地错误信号进行在线持续学习，不需要数据测验函数均值对应。我们的方法在Split-MNIST、Split-CIFAR-10和Split-CIFAR-100 datasets上实现了较好的在线持续学习性能，比较于其他记忆受限的学习方法和匹配了memory-intensive replay-based方法的性能。我们还证明了我们的方法可以与其他条件反射-based持续学习算法相结合，提高其精度。我们的结果提供了将生物学原理应用到机器学习模型的重要证据，并提供了如何运用这些原理来设计更有效率和可靠的在线持续学习系统。
</details></li>
</ul>
<hr>
<h2 id="Deep-Learning-for-Diverse-Data-Types-Steganalysis-A-Review"><a href="#Deep-Learning-for-Diverse-Data-Types-Steganalysis-A-Review" class="headerlink" title="Deep Learning for Diverse Data Types Steganalysis: A Review"></a>Deep Learning for Diverse Data Types Steganalysis: A Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04522">http://arxiv.org/abs/2308.04522</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hamza Kheddar, Mustapha Hemis, Yassine Himeur, David Megías, Abbes Amira<br>for: 这篇论文主要探讨了深度学习基本的隐藏信息检测技术，以帮助探索黑客或恐怖份子所使用的隐藏通信。methods: 这篇论文主要介绍了各种深度学习技术，包括深度学习探测、深度转移学习和深度强化学习，并评估了它们在不同的数据集上的性能。results: 根据文献的数据显示，深度学习基本的隐藏信息检测技术已经取得了比较高的检测精度和速度。尤其是使用深度转移学习和深度强化学习的方法，能够在不同的类型数据上实现更高的检测性能。<details>
<summary>Abstract</summary>
Steganography and steganalysis are two interrelated aspects of the field of information security. Steganography seeks to conceal communications, whereas steganalysis is aimed to either find them or even, if possible, recover the data they contain. Steganography and steganalysis have attracted a great deal of interest, particularly from law enforcement. Steganography is often used by cybercriminals and even terrorists to avoid being captured while in possession of incriminating evidence, even encrypted, since cryptography is prohibited or restricted in many countries. Therefore, knowledge of cutting-edge techniques to uncover concealed information is crucial in exposing illegal acts. Over the last few years, a number of strong and reliable steganography and steganalysis techniques have been introduced in the literature. This review paper provides a comprehensive overview of deep learning-based steganalysis techniques used to detect hidden information within digital media. The paper covers all types of cover in steganalysis, including image, audio, and video, and discusses the most commonly used deep learning techniques. In addition, the paper explores the use of more advanced deep learning techniques, such as deep transfer learning (DTL) and deep reinforcement learning (DRL), to enhance the performance of steganalysis systems. The paper provides a systematic review of recent research in the field, including data sets and evaluation metrics used in recent studies. It also presents a detailed analysis of DTL-based steganalysis approaches and their performance on different data sets. The review concludes with a discussion on the current state of deep learning-based steganalysis, challenges, and future research directions.
</details>
<details>
<summary>摘要</summary>
信息安全领域中的隐藏通信和找到隐藏通信的技术是两个相关的方面，称为 стеганография和стегана利isis。Steganography是为了隐藏通信，而Steganalysis是为了找到隐藏的通信或者恢复其中的数据。隐藏通信是由Cybercriminal和恐怖分子使用，以避免被抓获时 Possession of incriminating evidence，因为在许多国家， cryptography is prohibited or restricted。因此，了解最新的隐藏信息探测技术是在揭露违法行为中非常重要。过去几年，一些强大和可靠的隐藏信息探测技术在文献中被引入。这篇评论文章提供了深度学习基于的隐藏信息探测技术，用于检测数字媒体中的隐藏信息。文章覆盖了所有类型的遮盖，包括图像、音频和视频，并讨论了最常用的深度学习技术。此外，文章还探讨了使用更高级的深度学习技术，如深度传输学习（DTL）和深度奖励学习（DRL），以提高隐藏信息探测系统的性能。文章提供了现场的评论，包括最新的数据集和评价标准，以及DTL基于的隐藏信息探测方法的性能分析。文章结束于隐藏信息探测领域的当前状况，挑战和未来研究方向。
</details></li>
</ul>
<hr>
<h2 id="Dynamic-Model-Agnostic-Reliability-Evaluation-of-Machine-Learning-Methods-Integrated-in-Instrumentation-Control-Systems"><a href="#Dynamic-Model-Agnostic-Reliability-Evaluation-of-Machine-Learning-Methods-Integrated-in-Instrumentation-Control-Systems" class="headerlink" title="Dynamic Model Agnostic Reliability Evaluation of Machine-Learning Methods Integrated in Instrumentation &amp; Control Systems"></a>Dynamic Model Agnostic Reliability Evaluation of Machine-Learning Methods Integrated in Instrumentation &amp; Control Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05120">http://arxiv.org/abs/2308.05120</a></li>
<li>repo_url: None</li>
<li>paper_authors: Edward Chen, Han Bao, Nam Dinh</li>
<li>for:  This paper aims to improve the trustworthiness of machine learning (ML) predictions in instrumentation and control systems by developing a real-time model-agnostic method to evaluate the relative reliability of ML predictions.</li>
<li>methods:  The proposed method, called Laplacian distributed decay for reliability (LADDR), incorporates out-of-distribution detection on the training dataset to determine the difference between the operational and training datasets, which is used to calculate a prediction’s relative reliability.</li>
<li>results:  The LADDR method is demonstrated on a feedforward neural network-based model used to predict safety significant factors during different loss-of-flow transients, and is shown to be effective in evaluating the relative reliability of ML predictions for conventional interpolation tasks.<details>
<summary>Abstract</summary>
In recent years, the field of data-driven neural network-based machine learning (ML) algorithms has grown significantly and spurred research in its applicability to instrumentation and control systems. While they are promising in operational contexts, the trustworthiness of such algorithms is not adequately assessed. Failures of ML-integrated systems are poorly understood; the lack of comprehensive risk modeling can degrade the trustworthiness of these systems. In recent reports by the National Institute for Standards and Technology, trustworthiness in ML is a critical barrier to adoption and will play a vital role in intelligent systems' safe and accountable operation. Thus, in this work, we demonstrate a real-time model-agnostic method to evaluate the relative reliability of ML predictions by incorporating out-of-distribution detection on the training dataset. It is well documented that ML algorithms excel at interpolation (or near-interpolation) tasks but significantly degrade at extrapolation. This occurs when new samples are "far" from training samples. The method, referred to as the Laplacian distributed decay for reliability (LADDR), determines the difference between the operational and training datasets, which is used to calculate a prediction's relative reliability. LADDR is demonstrated on a feedforward neural network-based model used to predict safety significant factors during different loss-of-flow transients. LADDR is intended as a "data supervisor" and determines the appropriateness of well-trained ML models in the context of operational conditions. Ultimately, LADDR illustrates how training data can be used as evidence to support the trustworthiness of ML predictions when utilized for conventional interpolation tasks.
</details>
<details>
<summary>摘要</summary>
近年来，数据驱动神经网络基于机器学习（ML）算法的Field在实现仪表和控制系统方面得到了广泛的研究和应用。虽然它们在操作上有承诺，但ML算法的可靠性还未得到全面的评估。失败的ML集成系统未能准确地理解;缺乏完善的风险模型可能会降低ML系统的可靠性。国家标准技术研究所的最近报告显示，在智能系统中，可靠性将作为采用ML的关键障碍。因此，在这项工作中，我们提出了一种实时模型不依赖的方法，通过在训练集上进行异常检测来评估ML预测的相对可靠性。ML算法在 interpolate（或近似 interpolate）任务上 excel，但在 extrapolation 任务上会 significatively degrade。这意味着当新样本远离训练样本时，ML算法会表现不佳。我们提出的方法，即Laplacian distributed decay for reliability（LADDR），可以在不同的损失流转中预测安全重要因素的可靠性。LADDR是一种“数据监管”，用于判断训练集和操作集之间的差异，以计算预测的相对可靠性。LADDR是一种模型不依赖的方法，可以在不同的操作条件下评估ML模型的可靠性。最终，LADDR示例了如何在常规 interpolate 任务中使用训练数据作为可靠性的证明。
</details></li>
</ul>
<hr>
<h2 id="MT-IceNet-–-A-Spatial-and-Multi-Temporal-Deep-Learning-Model-for-Arctic-Sea-Ice-Forecasting"><a href="#MT-IceNet-–-A-Spatial-and-Multi-Temporal-Deep-Learning-Model-for-Arctic-Sea-Ice-Forecasting" class="headerlink" title="MT-IceNet – A Spatial and Multi-Temporal Deep Learning Model for Arctic Sea Ice Forecasting"></a>MT-IceNet – A Spatial and Multi-Temporal Deep Learning Model for Arctic Sea Ice Forecasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04511">http://arxiv.org/abs/2308.04511</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/big-data-lab-umbc/sea-ice-prediction">https://github.com/big-data-lab-umbc/sea-ice-prediction</a></li>
<li>paper_authors: Sahara Ali, Jianwu Wang</li>
<li>for: 这 paper 的目的是为了预测北极海冰覆盖率（SIC），以便更好地理解和预测北极气候变化。</li>
<li>methods: 这 paper 使用了一种基于深度学习的方法，称为 MT-IceNet，它使用了一个 UNet 结构，并使用了多个时间流和空间流来预测北极海冰覆盖率。</li>
<li>results: 根据使用 NSIDC 的卫星评估数据和 ERA5 演算结果，这 paper 的结果表明，MT-IceNet 模型可以提供出色的预测性能，比其他现有的方法更加准确，最多可以预测到 6 个月前的情况。<details>
<summary>Abstract</summary>
Arctic amplification has altered the climate patterns both regionally and globally, resulting in more frequent and more intense extreme weather events in the past few decades. The essential part of Arctic amplification is the unprecedented sea ice loss as demonstrated by satellite observations. Accurately forecasting Arctic sea ice from sub-seasonal to seasonal scales has been a major research question with fundamental challenges at play. In addition to physics-based Earth system models, researchers have been applying multiple statistical and machine learning models for sea ice forecasting. Looking at the potential of data-driven approaches to study sea ice variations, we propose MT-IceNet - a UNet based spatial and multi-temporal (MT) deep learning model for forecasting Arctic sea ice concentration (SIC). The model uses an encoder-decoder architecture with skip connections and processes multi-temporal input streams to regenerate spatial maps at future timesteps. Using bi-monthly and monthly satellite retrieved sea ice data from NSIDC as well as atmospheric and oceanic variables from ERA5 reanalysis product during 1979-2021, we show that our proposed model provides promising predictive performance for per-pixel SIC forecasting with up to 60% decrease in prediction error for a lead time of 6 months as compared to its state-of-the-art counterparts.
</details>
<details>
<summary>摘要</summary>
《北极强化效应对 климатиче Patterns 产生了广泛和深刻的影响，从2000年代中期以来，全球和地方的极端天气事件变得更加频繁和严重。北极强化效应的核心是历史上无 precedent的海冰损失，这种观测结果表明了这一点。预测北极海冰的科学研究问题具有基本挑战，包括物理基础模型和统计学机器学习模型。我们提出了MT-IceNet模型，这是一种基于UNet的空间和多时间（MT）深度学习模型，用于预测北极海冰浓度（SIC）。该模型使用编码器-解码器架构，并使用跳接连接来处理多时间输入流，以生成未来时间步的空间地图。使用1979-2021年NSIDC从卫星得到的月度和两个月度海冰数据，以及ERA5分析产品中的大气和海洋变量，我们表明了我们提出的模型在预测每个像素SIC的前6个月的预测误差减少了60%，与现有的模型相比。
</details></li>
</ul>
<hr>
<h2 id="Efficient-option-pricing-with-unary-based-photonic-computing-chip-and-generative-adversarial-learning"><a href="#Efficient-option-pricing-with-unary-based-photonic-computing-chip-and-generative-adversarial-learning" class="headerlink" title="Efficient option pricing with unary-based photonic computing chip and generative adversarial learning"></a>Efficient option pricing with unary-based photonic computing chip and generative adversarial learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04493">http://arxiv.org/abs/2308.04493</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hui Zhang, Lingxiao Wan, Sergi Ramos-Calderer, Yuancheng Zhan, Wai-Keong Mok, Hong Cai, Feng Gao, Xianshu Luo, Guo-Qiang Lo, Leong Chuan Kwek, José Ignacio Latorre, Ai Qun Liu</li>
<li>for: 这个论文是为了提高金融业务效率和质量而设计的。</li>
<li>methods: 这个论文使用光子芯片实现欧洲选择价格的唯一方法，并与量子振荡估算算法相结合，以实现类比于经典 Monte Carlo 方法的二次加速。</li>
<li>results: 这个论文实现了一种光子芯片，可以快速计算欧洲选择价格，并且可以减少经典 Monte Carlo 方法的计算时间。<details>
<summary>Abstract</summary>
In the modern financial industry system, the structure of products has become more and more complex, and the bottleneck constraint of classical computing power has already restricted the development of the financial industry. Here, we present a photonic chip that implements the unary approach to European option pricing, in combination with the quantum amplitude estimation algorithm, to achieve a quadratic speedup compared to classical Monte Carlo methods. The circuit consists of three modules: a module loading the distribution of asset prices, a module computing the expected payoff, and a module performing the quantum amplitude estimation algorithm to introduce speed-ups. In the distribution module, a generative adversarial network is embedded for efficient learning and loading of asset distributions, which precisely capture the market trends. This work is a step forward in the development of specialized photonic processors for applications in finance, with the potential to improve the efficiency and quality of financial services.
</details>
<details>
<summary>摘要</summary>
现代金融系统中，产品结构变得越来越复杂，而 классическое计算能力的瓶颈已经限制了金融业的发展。我们在这里提出了一款光学芯片，实现了一元方法来估算欧洲期权价格，并结合量子振荡估计算法，实现了对类比 Monte Carlo 方法的二次加速。该芯片由三个模块组成：分布模块、预期支付模块和量子振荡估计算法模块。在分布模块中，我们嵌入了生成对抗网络，以高效地学习和加载资产分布，准确捕捉市场趋势。这项工作是金融特殊光学处理器的开发的一个重要步骤，具有改善金融服务效率和质量的潜力。
</details></li>
</ul>
<hr>
<h2 id="When-More-is-Less-Incorporating-Additional-Datasets-Can-Hurt-Performance-By-Introducing-Spurious-Correlations"><a href="#When-More-is-Less-Incorporating-Additional-Datasets-Can-Hurt-Performance-By-Introducing-Spurious-Correlations" class="headerlink" title="When More is Less: Incorporating Additional Datasets Can Hurt Performance By Introducing Spurious Correlations"></a>When More is Less: Incorporating Additional Datasets Can Hurt Performance By Introducing Spurious Correlations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04431">http://arxiv.org/abs/2308.04431</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/basedrhys/ood-generalization">https://github.com/basedrhys/ood-generalization</a></li>
<li>paper_authors: Rhys Compton, Lily Zhang, Aahlad Puli, Rajesh Ranganath</li>
<li>for: 这篇论文旨在探讨机器学习模型如何处理多个数据集的问题，以及这些数据集之间的相互作用。</li>
<li>methods: 作者使用了多个开源的胸部X射线图像数据集，并对它们进行了大规模的实验研究。</li>
<li>results: 研究发现，在43%的情况下，将多个医院的数据集合并训练机器学习模型可能会导致模型的性能下降。这种现象发生在训练数据集与测试数据集之间存在潜在的假相关性的情况下。<details>
<summary>Abstract</summary>
In machine learning, incorporating more data is often seen as a reliable strategy for improving model performance; this work challenges that notion by demonstrating that the addition of external datasets in many cases can hurt the resulting model's performance. In a large-scale empirical study across combinations of four different open-source chest x-ray datasets and 9 different labels, we demonstrate that in 43% of settings, a model trained on data from two hospitals has poorer worst group accuracy over both hospitals than a model trained on just a single hospital's data. This surprising result occurs even though the added hospital makes the training distribution more similar to the test distribution. We explain that this phenomenon arises from the spurious correlation that emerges between the disease and hospital, due to hospital-specific image artifacts. We highlight the trade-off one encounters when training on multiple datasets, between the obvious benefit of additional data and insidious cost of the introduced spurious correlation. In some cases, balancing the dataset can remove the spurious correlation and improve performance, but it is not always an effective strategy. We contextualize our results within the literature on spurious correlations to help explain these outcomes. Our experiments underscore the importance of exercising caution when selecting training data for machine learning models, especially in settings where there is a risk of spurious correlations such as with medical imaging. The risks outlined highlight the need for careful data selection and model evaluation in future research and practice.
</details>
<details>
<summary>摘要</summary>
在机器学习中，通常认为更多数据可以提高模型性能，但这项工作挑战这一观点，表明在许多情况下，外部数据集添加可能会损害模型性能。我们在四个开源胸部X射线图像集和九个标签之间进行了大规模的实验，发现在43%的情况下，使用两家医院的数据进行训练的模型在两家医院的数据上具有较差的最坏群组精度。这种意外的结果，即尽管添加的医院使训练分布更加类似于测试分布，但是模型在两家医院的数据上具有较差的性能。我们解释了这种现象是由于医院特有的图像artifacts产生的假 correlation的影响。我们强调在多个数据集训练时存在的费解之处， между添加更多数据的明显利益和引入的假 correlations的隐性成本。在某些情况下，平衡数据可以消除假 correlations并提高性能，但并非总是有效的策略。我们在文献中归纳了我们的结果，以帮助解释这些结果。我们的实验让人们意识到在机器学习模型训练时，特别是在医疗影像领域，选择数据的价值很大，需要小心评估和选择数据。这些风险提出的需要在未来的研究和实践中进行细心的数据选择和模型评估。
</details></li>
</ul>
<hr>
<h2 id="SILO-Language-Models-Isolating-Legal-Risk-In-a-Nonparametric-Datastore"><a href="#SILO-Language-Models-Isolating-Legal-Risk-In-a-Nonparametric-Datastore" class="headerlink" title="SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore"></a>SILO Language Models: Isolating Legal Risk In a Nonparametric Datastore</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04430">http://arxiv.org/abs/2308.04430</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kernelmachine/silo-lm">https://github.com/kernelmachine/silo-lm</a></li>
<li>paper_authors: Sewon Min, Suchin Gururangan, Eric Wallace, Hannaneh Hajishirzi, Noah A. Smith, Luke Zettlemoyer</li>
<li>for: 本研究旨在探讨训练语言模型（LM）时是否存在版权和限制数据的法律问题，以及如何在搜寻和执行过程中减少这些风险。</li>
<li>methods: 本研究使用了一种新的语言模型（SILO），它通过在搜寻过程中访问一个可更新和修改的非参数数据存储（例如，包含版权书籍或新闻）来减少风险。此外，SILO还使用了一个Parametric LM，用于在Open License Corpus（OLC）上进行训练。</li>
<li>results: 研究发现，使用SILO可以提高语言模型在不同领域的性能，同时减少版权和限制数据的风险。Specifically, SILO的搜寻性能与使用Pile corpus进行训练的LMClosing 90%的性能差。此外，研究还分析了不同的非参数方法的效果，以及数据库大小对性能的影响。<details>
<summary>Abstract</summary>
The legality of training language models (LMs) on copyrighted or otherwise restricted data is under intense debate. However, as we show, model performance significantly degrades if trained only on low-risk text (e.g., out-of-copyright books or government documents), due to its limited size and domain coverage. We present SILO, a new language model that manages this risk-performance tradeoff during inference. SILO is built by (1) training a parametric LM on Open License Corpus (OLC), a new corpus we curate with 228B tokens of public domain and permissively licensed text and (2) augmenting it with a more general and easily modifiable nonparametric datastore (e.g., containing copyrighted books or news) that is only queried during inference. The datastore allows use of high-risk data without training on it, supports sentence-level data attribution, and enables data producers to opt out from the model by removing content from the store. These capabilities can foster compliance with data-use regulations such as the fair use doctrine in the United States and the GDPR in the European Union. Our experiments show that the parametric LM struggles on domains not covered by OLC. However, access to the datastore greatly improves out of domain performance, closing 90% of the performance gap with an LM trained on the Pile, a more diverse corpus with mostly high-risk text. We also analyze which nonparametric approach works best, where the remaining errors lie, and how performance scales with datastore size. Our results suggest that it is possible to build high quality language models while mitigating their legal risk.
</details>
<details>
<summary>摘要</summary>
训练语言模型（LM）在版权或限制数据上的法律合法性正在激烈讨论。然而，我们表明，如果只训练LM在低风险文本（如公共领域或政府文件）上，其性能会显著下降，因为这些文本的数量和覆盖率都很限制。我们提出了SILO，一种新的语言模型，可以在推理时管理这种风险和性能的贸易。SILO由以下两个部分组成：1. 使用 parametric LM 训练 Open License Corpus（OLC），一个我们新建的公共领域和允许授权文本的新词汇库，包含228亿个字符。2. 通过在推理时使用非参数的数据存储（例如包含版权书籍或新闻的数据）来增强模型的性能。这个数据存储支持句子级数据归属，并允许数据生成者在模型中排除自己的内容。我们的实验表明， parametric LM 在不受 OLC 覆盖的领域表现不佳。然而，通过访问数据存储，可以大幅提高 Mod 的 OUT  OF 领域表现，将性能与基于 Pile 的 LM 相凑，这个 Pile 的文本主要是高风险文本。我们还分析了非参数方法的最佳选择、剩下的错误的位置以及数据存储大小的性能满意度。我们的结果表明，可以建立高质量的语言模型，同时避免其法律风险。
</details></li>
</ul>
<hr>
<h2 id="Meta-Learning-Operators-to-Optimality-from-Multi-Task-Non-IID-Data"><a href="#Meta-Learning-Operators-to-Optimality-from-Multi-Task-Non-IID-Data" class="headerlink" title="Meta-Learning Operators to Optimality from Multi-Task Non-IID Data"></a>Meta-Learning Operators to Optimality from Multi-Task Non-IID Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04428">http://arxiv.org/abs/2308.04428</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thomas T. C. K. Zhang, Leonardo F. Toso, James Anderson, Nikolai Matni</li>
<li>for: 这个论文的目的是提出一种基于共同特征提取的机器学习方法，以便在不同来源或任务上学习共同的表示函数，从而降低计算成本和统计泛化。</li>
<li>methods: 这个论文使用的方法包括一种基于替换最小化的对抗学习策略，以及一种基于特征白化的权重更新策略。</li>
<li>results: 这个论文的结果表明，使用这种方法可以在不同来源或任务上学习共同的表示函数，并且可以降低计算成本和统计泛化。此外，这种方法还可以在各种数学模型下进行扩展和应用。<details>
<summary>Abstract</summary>
A powerful concept behind much of the recent progress in machine learning is the extraction of common features across data from heterogeneous sources or tasks. Intuitively, using all of one's data to learn a common representation function benefits both computational effort and statistical generalization by leaving a smaller number of parameters to fine-tune on a given task. Toward theoretically grounding these merits, we propose a general setting of recovering linear operators $M$ from noisy vector measurements $y = Mx + w$, where the covariates $x$ may be both non-i.i.d. and non-isotropic. We demonstrate that existing isotropy-agnostic meta-learning approaches incur biases on the representation update, which causes the scaling of the noise terms to lose favorable dependence on the number of source tasks. This in turn can cause the sample complexity of representation learning to be bottlenecked by the single-task data size. We introduce an adaptation, $\texttt{De-bias & Feature-Whiten}$ ($\texttt{DFW}$), of the popular alternating minimization-descent (AMD) scheme proposed in Collins et al., (2021), and establish linear convergence to the optimal representation with noise level scaling down with the $\textit{total}$ source data size. This leads to generalization bounds on the same order as an oracle empirical risk minimizer. We verify the vital importance of $\texttt{DFW}$ on various numerical simulations. In particular, we show that vanilla alternating-minimization descent fails catastrophically even for iid, but mildly non-isotropic data. Our analysis unifies and generalizes prior work, and provides a flexible framework for a wider range of applications, such as in controls and dynamical systems.
</details>
<details>
<summary>摘要</summary>
一个强大的概念在现代机器学习中是将多元数据中的共同特征提取出来。这将reduces computational effort和statistical generalization的成本，因为仅需要 fine-tune fewer parameters on a given task。在理论上诠释这些优点，我们提出一个统一 Linear operators $M$ 的恢复问题，其中 vector measurements $y = Mx + w$ 中的 covariates $x$ 可能是非 i.i.d. 和非对称的。我们证明了现有的不对称适应学习方法对 representation update 会产生偏见，导致随着任务数量增加而对 noise term 的扩大。这会导致 representation learning 的样本Complexity 被瓶颈在单一任务数据大小上。我们引入了一个适应 $\texttt{De-bias & Feature-Whiten}$ （$\texttt{DFW}$），它是 Collins et al., (2021) 提出的流行的 Alternating Minimization-Descent （AMD）方案的修改。我们证明了 $\texttt{DFW}$ 在 total source data size 下随着阶层降低的情况下，具有线性传播到优化的表现。这导致了一个对 oracle empirical risk minimizer 相似的一个 generalization bound。我们透过各种数据 simulated 的 verify，证明了 $\texttt{DFW}$ 的重要性。具体来说，我们发现了 vanilla Alternating-Minimization Descent 甚至在 iid 的数据上也会 catastrophically fail。我们的分析统一了和扩展了先前的工作，并提供了更多的应用，例如在控制和动力系统等领域。
</details></li>
</ul>
<hr>
<h2 id="A-Deep-Learning-Method-Using-Auto-encoder-and-Generative-Adversarial-Network-for-Anomaly-Detection-on-Ancient-Stone-Stele-Surfaces"><a href="#A-Deep-Learning-Method-Using-Auto-encoder-and-Generative-Adversarial-Network-for-Anomaly-Detection-on-Ancient-Stone-Stele-Surfaces" class="headerlink" title="A Deep-Learning Method Using Auto-encoder and Generative Adversarial Network for Anomaly Detection on Ancient Stone Stele Surfaces"></a>A Deep-Learning Method Using Auto-encoder and Generative Adversarial Network for Anomaly Detection on Ancient Stone Stele Surfaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04426">http://arxiv.org/abs/2308.04426</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yikun Liu, Yuning Wang, Cheng Liu</li>
<li>for: 这个研究是为了检测古代碑石表面上的自然衰老和人工损坏，以便预防文化遗产的保护。</li>
<li>methods: 这篇论文使用深度学习方法来自动检测古代碑石表面上的紧急情况，包括数据获取、预处理、模型设计和后处理等阶段。</li>
<li>results: 这篇论文使用自动encoder（AE）和生成敌方网络（GAN）架构，可以实时检测古代碑石表面上的紧急情况，并且不需要大量的异常样本。在实验中，使用长门洞穴的石碑为案例研究，提出了一个无监督学习模型，并在重建精度99.74%的基础上验证了模型的可靠性和精度。<details>
<summary>Abstract</summary>
Accurate detection of natural deterioration and man-made damage on the surfaces of ancient stele in the first instance is essential for their preventive conservation. Existing methods for cultural heritage preservation are not able to achieve this goal perfectly due to the difficulty of balancing accuracy, efficiency, timeliness, and cost. This paper presents a deep-learning method to automatically detect above mentioned emergencies on ancient stone stele in real time, employing autoencoder (AE) and generative adversarial network (GAN). The proposed method overcomes the limitations of existing methods by requiring no extensive anomaly samples while enabling comprehensive detection of unpredictable anomalies. the method includes stages of monitoring, data acquisition, pre-processing, model structuring, and post-processing. Taking the Longmen Grottoes' stone steles as a case study, an unsupervised learning model based on AE and GAN architectures is proposed and validated with a reconstruction accuracy of 99.74\%. The method's evaluation revealed the proficient detection of seven artificially designed anomalies and demonstrated precision and reliability without false alarms. This research provides novel ideas and possibilities for the application of deep learning in the field of cultural heritage.
</details>
<details>
<summary>摘要</summary>
正确地探测古迹上自然衰老和人为损坏的存在是保护古迹的首要任务。现有的文化遗产保护方法无法完全达到这个目标，因为很难平衡精度、效率、时间和成本。本研究提出了一种基于深度学习的方法，可以自动探测古石碑上的紧急情况，使用自适应神经网络（AE）和生成对抗网络（GAN）。提案的方法可以无需大量的异常样本，同时具有全面探测不可预测的异常的能力。方法包括监控、数据收集、预处理、模型结构和后处理等阶段。以长门石窟的石碑为例，提出了一个无监控学习模型，使用AE和GAN架构，并在重建准确率达99.74%。评估结果显示了对七种人工设计的异常探测的精准性和可靠性，无 FALSE ALARM 的情况。本研究将深度学习应用在文化遗产保护领域提供了新的想法和可能性。
</details></li>
</ul>
<hr>
<h2 id="DiffCR-A-Fast-Conditional-Diffusion-Framework-for-Cloud-Removal-from-Optical-Satellite-Images"><a href="#DiffCR-A-Fast-Conditional-Diffusion-Framework-for-Cloud-Removal-from-Optical-Satellite-Images" class="headerlink" title="DiffCR: A Fast Conditional Diffusion Framework for Cloud Removal from Optical Satellite Images"></a>DiffCR: A Fast Conditional Diffusion Framework for Cloud Removal from Optical Satellite Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04417">http://arxiv.org/abs/2308.04417</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuechao Zou, Kai Li, Junliang Xing, Yu Zhang, Shiying Wang, Lei Jin, Pin Tao</li>
<li>for: 这篇论文的目的是提出一个新的云 removal 框架，以解决Optical satellite images 中的云盖问题，并且提高影像质量。</li>
<li>methods: 本论文使用了条件导向扩散 Models 和深度卷积神经网络，实现高性能的云 removal。特别是，我们提出了一个独立的Encoder，以提取 conditional image 中的特征，并且使用了一个新的时间和条件融合块，以精确地模拟出云的条件影像和目标影像之间的相似性。</li>
<li>results: 实验结果显示，DiffCR 在两个通用的评估数据集上均能够获得最佳性能，并且与前一代方法的参数和computational complexity相比，只需5.1%和5.4%。所有的实验结果和代码将会在<a target="_blank" rel="noopener" href="https://github.com/XavierJiezou/DiffCR">https://github.com/XavierJiezou/DiffCR</a> 上公开。<details>
<summary>Abstract</summary>
Optical satellite images are a critical data source; however, cloud cover often compromises their quality, hindering image applications and analysis. Consequently, effectively removing clouds from optical satellite images has emerged as a prominent research direction. While recent advancements in cloud removal primarily rely on generative adversarial networks, which may yield suboptimal image quality, diffusion models have demonstrated remarkable success in diverse image-generation tasks, showcasing their potential in addressing this challenge. This paper presents a novel framework called DiffCR, which leverages conditional guided diffusion with deep convolutional networks for high-performance cloud removal for optical satellite imagery. Specifically, we introduce a decoupled encoder for conditional image feature extraction, providing a robust color representation to ensure the close similarity of appearance information between the conditional input and the synthesized output. Moreover, we propose a novel and efficient time and condition fusion block within the cloud removal model to accurately simulate the correspondence between the appearance in the conditional image and the target image at a low computational cost. Extensive experimental evaluations on two commonly used benchmark datasets demonstrate that DiffCR consistently achieves state-of-the-art performance on all metrics, with parameter and computational complexities amounting to only 5.1% and 5.4%, respectively, of those previous best methods. The source code, pre-trained models, and all the experimental results will be publicly available at https://github.com/XavierJiezou/DiffCR upon the paper's acceptance of this work.
</details>
<details>
<summary>摘要</summary>
OPTICAL 卫星图像是一种关键的数据源，但是云覆盖往往会降低图像质量，妨碍图像应用和分析。因此，从事cloud removal的研究已经成为一个重要的研究方向。 aunque recent advancements in cloud removal primarily rely on generative adversarial networks, which may yield suboptimal image quality, diffusion models have demonstrated remarkable success in diverse image-generation tasks, showcasing their potential in addressing this challenge. This paper presents a novel framework called DiffCR, which leverages conditional guided diffusion with deep convolutional networks for high-performance cloud removal for optical satellite imagery. Specifically, we introduce a decoupled encoder for conditional image feature extraction, providing a robust color representation to ensure the close similarity of appearance information between the conditional input and the synthesized output. Moreover, we propose a novel and efficient time and condition fusion block within the cloud removal model to accurately simulate the correspondence between the appearance in the conditional image and the target image at a low computational cost. 经验证明，DiffCR在两个常用的 benchmark 数据集上具有最佳性能，与之前最佳方法的参数和计算复杂度分别为5.1%和5.4%。源代码、预训练模型和所有实验结果将在https://github.com/XavierJiezou/DiffCR 上公开发布。
</details></li>
</ul>
<hr>
<h2 id="Vector-Embeddings-by-Sequence-Similarity-and-Context-for-Improved-Compression-Similarity-Search-Clustering-Organization-and-Manipulation-of-cDNA-Libraries"><a href="#Vector-Embeddings-by-Sequence-Similarity-and-Context-for-Improved-Compression-Similarity-Search-Clustering-Organization-and-Manipulation-of-cDNA-Libraries" class="headerlink" title="Vector Embeddings by Sequence Similarity and Context for Improved Compression, Similarity Search, Clustering, Organization, and Manipulation of cDNA Libraries"></a>Vector Embeddings by Sequence Similarity and Context for Improved Compression, Similarity Search, Clustering, Organization, and Manipulation of cDNA Libraries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05118">http://arxiv.org/abs/2308.05118</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daniel H. Um, David A. Knowles, Gail E. Kaiser</li>
<li>for: 这篇论文旨在提出一种新的数字表示方法，用于解决flat string gene format（如FASTA&#x2F;FASTQ5）在研究中的问题。</li>
<li>methods: 该方法基于将序列转换为固定长度的数字表示，并使用这些表示进行更高效的聚类和压缩。</li>
<li>results: 研究发现，通过使用这种数字表示方法，可以更好地聚类序列，并且可以提高压缩率。此外，通过基于 codon triplets 的上下文学习，可以进行更精细的聚类和特征分析。<details>
<summary>Abstract</summary>
This paper demonstrates the utility of organized numerical representations of genes in research involving flat string gene formats (i.e., FASTA/FASTQ5). FASTA/FASTQ files have several current limitations, such as their large file sizes, slow processing speeds for mapping and alignment, and contextual dependencies. These challenges significantly hinder investigations and tasks that involve finding similar sequences. The solution lies in transforming sequences into an alternative representation that facilitates easier clustering into similar groups compared to the raw sequences themselves. By assigning a unique vector embedding to each short sequence, it is possible to more efficiently cluster and improve upon compression performance for the string representations of cDNA libraries. Furthermore, through learning alternative coordinate vector embeddings based on the contexts of codon triplets, we can demonstrate clustering based on amino acid properties. Finally, using this sequence embedding method to encode barcodes and cDNA sequences, we can improve the time complexity of the similarity search by coupling vector embeddings with an algorithm that determines the proximity of vectors in Euclidean space; this allows us to perform sequence similarity searches in a quicker and more modular fashion.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这篇论文展示了用有组织的数字表示方法优化flat string基因格式（即FASTA/FASTQ5）的研究。FASTA/FASTQ文件存在许多现有的限制，例如文件大小、对 mapping 和 aligning 进行slow processing的速度、以及contextual dependencies。这些限制会对investigations和任务 involving finding similar sequences 造成很大的阻碍。解决方案在于将序列转换成一种更好的表示方式，以便更容易将similar sequences clustering。通过赋予每个短序列唯一的vector embedding，可以更高效地 clustering和提高cDNA库的压缩性能。此外，通过基于 codon triplets 的上下文学习alternative coordinate vector embeddings，我们可以示出基于aa properties的 clustering。最后，通过使用这种序列嵌入方法来编码 barcodes 和 cDNA sequences，我们可以通过将vector embeddings coupled with an algorithm that determines the proximity of vectors in Euclidean space 来提高sequence similarity searches的时间复杂度，从而实现更快速和更模块化的搜索方式。
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-Invariant-Learning-with-Randomized-Linear-Classifiers"><a href="#Probabilistic-Invariant-Learning-with-Randomized-Linear-Classifiers" class="headerlink" title="Probabilistic Invariant Learning with Randomized Linear Classifiers"></a>Probabilistic Invariant Learning with Randomized Linear Classifiers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04412">http://arxiv.org/abs/2308.04412</a></li>
<li>repo_url: None</li>
<li>paper_authors: Leonardo Cotta, Gal Yehuda, Assaf Schuster, Chris J. Maddison</li>
<li>for: 这个论文的目的是设计一类能够具有表达力和保持任务不变性的模型，而且具有较少的资源需求。</li>
<li>methods: 这个论文使用了随机化的算法思想，提出了一类基于随机线性模型的分类器（Randomized Linear Classifiers，RLCs），并证明RLCs可以高概率地近似任何（光滑）函数，同时保持 compact group transformations 的不变性。</li>
<li>results: 论文通过实验表明，RLCs可以在不变性任务中超越权重链 neuron 和其不变性版本，具有较少的资源需求。<details>
<summary>Abstract</summary>
Designing models that are both expressive and preserve known invariances of tasks is an increasingly hard problem. Existing solutions tradeoff invariance for computational or memory resources. In this work, we show how to leverage randomness and design models that are both expressive and invariant but use less resources. Inspired by randomized algorithms, our key insight is that accepting probabilistic notions of universal approximation and invariance can reduce our resource requirements. More specifically, we propose a class of binary classification models called Randomized Linear Classifiers (RLCs). We give parameter and sample size conditions in which RLCs can, with high probability, approximate any (smooth) function while preserving invariance to compact group transformations. Leveraging this result, we design three RLCs that are provably probabilistic invariant for classification tasks over sets, graphs, and spherical data. We show how these models can achieve probabilistic invariance and universality using less resources than (deterministic) neural networks and their invariant counterparts. Finally, we empirically demonstrate the benefits of this new class of models on invariant tasks where deterministic invariant neural networks are known to struggle.
</details>
<details>
<summary>摘要</summary>
“设计能够表达性和保持已知 invariants 的模型是一个在不断增长的问题。现有的解决方案都会交换 invariants 和计算或内存资源。在这项工作中，我们表明了如何利用 randomness 和设计能够表达性和 invariants 的模型，同时使用更少的资源。我们的关键发现是接受 probabilistic 的 universality 和 invariants 的想法可以降低我们的资源需求。更 Specifically，我们提出了一类基于 randomized algorithms 的 binary classification 模型，称为 Randomized Linear Classifiers (RLCs)。我们给出了参数和样本大小的条件，在这些条件下，RLCs 可以， WITH HIGH PROBABILITY，近似任何（平滑）函数，同时保持 compact group transformations 的 invariants。基于这个结果，我们设计了三种 RLCs，这些模型可以在 classification tasks 中保证 probabilistic invariants。我们证明了这些模型可以使用更少的资源来实现 universality 和 invariants，比 deterministic 神经网络和其 invariants 的counterparts。最后，我们通过实验证明了这种新的类型模型在 invariant tasks 中的 beneficial effects。”
</details></li>
</ul>
<hr>
<h2 id="XGBD-Explanation-Guided-Graph-Backdoor-Detection"><a href="#XGBD-Explanation-Guided-Graph-Backdoor-Detection" class="headerlink" title="XGBD: Explanation-Guided Graph Backdoor Detection"></a>XGBD: Explanation-Guided Graph Backdoor Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04406">http://arxiv.org/abs/2308.04406</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/guanzihan/gnn_backdoor_detection">https://github.com/guanzihan/gnn_backdoor_detection</a></li>
<li>paper_authors: Zihan Guan, Mengnan Du, Ninghao Liu</li>
<li>For: The paper is written to detect backdoor attacks on graph learning models.* Methods: The paper proposes an explanation-guided backdoor detection method that utilizes topological feature information to distinguish backdoor samples from clean samples.* Results: The proposed method is effective in detecting backdoor attacks on multiple popular datasets and attack methods, and provides explainable results through the use of explanation methods.Here is the same information in Simplified Chinese:* For: 文章目的是探测图学习模型中的后门攻击。* Methods: 文章提出了一种基于 topological 特征信息的解释帮助的后门检测方法。* Results: 提议的方法在多个流行的数据集和攻击方法上显示出了效果，并通过使用解释方法提供了可解释的结果。I hope this helps!<details>
<summary>Abstract</summary>
Backdoor attacks pose a significant security risk to graph learning models. Backdoors can be embedded into the target model by inserting backdoor triggers into the training dataset, causing the model to make incorrect predictions when the trigger is present. To counter backdoor attacks, backdoor detection has been proposed. An emerging detection strategy in the vision and NLP domains is based on an intriguing phenomenon: when training models on a mixture of backdoor and clean samples, the loss on backdoor samples drops significantly faster than on clean samples, allowing backdoor samples to be easily detected by selecting samples with the lowest loss values. However, the ignorance of topological feature information on graph data limits its detection effectiveness when applied directly to the graph domain. To this end, we propose an explanation-guided backdoor detection method to take advantage of the topological information. Specifically, we train a helper model on the graph dataset, feed graph samples into the model, and then adopt explanation methods to attribute model prediction to an important subgraph. We observe that backdoor samples have distinct attribution distribution than clean samples, so the explanatory subgraph could serve as more discriminative features for detecting backdoor samples. Comprehensive experiments on multiple popular datasets and attack methods demonstrate the effectiveness and explainability of our method. Our code is available: https://github.com/GuanZihan/GNN_backdoor_detection.
</details>
<details>
<summary>摘要</summary>
Graph 学习模型面临着重要的安全隐患，即后门攻击。可以通过插入后门触发器到训练集中，使模型在触发器存在时进行错误预测。为了防止后门攻击，后门检测被提议。在视觉和自然语言处理领域，一种emerging检测策略是根据一种奇妙现象：在混合后门和干净样本训练模型时，后门样本的损失值会下降得更快，使得后门样本可以通过选择损失值最低的样本来轻松地检测。然而，在图数据上直接应用这种方法时，它的检测效果受到图数据的topological特征信息的限制。为此，我们提出了一种带有解释的后门检测方法，利用图数据的topological信息。具体来说，我们在图数据集上训练一个助手模型，然后将图样本 feed 到模型中，然后采用解释方法来归因模型预测结果到一个重要的子图。我们发现，后门样本的归因分布与干净样本不同，因此解释子图可以作为更有特征的检测特征。我们的实验表明，我们的方法在多个流行的数据集和攻击方法上具有效果和可解释性。我们的代码可以在 GitHub 上找到：https://github.com/GuanZihan/GNN_backdoor_detection。
</details></li>
</ul>
<hr>
<h2 id="Event-Abstraction-for-Enterprise-Collaboration-Systems-to-Support-Social-Process-Mining"><a href="#Event-Abstraction-for-Enterprise-Collaboration-Systems-to-Support-Social-Process-Mining" class="headerlink" title="Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining"></a>Event Abstraction for Enterprise Collaboration Systems to Support Social Process Mining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04396">http://arxiv.org/abs/2308.04396</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jonas Blatt, Patrick Delfmann, Petra Schubert</li>
<li>for: 这个论文主要针对的是进程挖掘（PM）在信息系统事件日志中发现过程模型的问题，具体来说是对于通信和文档oriented企业协作系统（ECS）的进程模型挖掘。</li>
<li>methods: 这篇论文提出了一种针对ECS事件日志特有的特点的事件抽象方法（ECSEA），该方法通过比较记录的实际用户活动轨迹（高级轨迹）与系统生成的低级事件轨迹（从ECS中提取的）来训练一个模型，从而自动将未来的低级事件轨迹转换为抽象后的高级轨迹，可以用于进程挖掘。</li>
<li>results: 论文的评估结果表明，该算法能够生成准确的结果。ECSEA是一种重要的预处理方法，可以帮助解读ECS中的协作工作活动，我们称之为社会进程挖掘（Social Process Mining）。<details>
<summary>Abstract</summary>
One aim of Process Mining (PM) is the discovery of process models from event logs of information systems. PM has been successfully applied to process-oriented enterprise systems but is less suited for communication- and document-oriented Enterprise Collaboration Systems (ECS). ECS event logs are very fine-granular and PM applied to their logs results in spaghetti models. A common solution for this is event abstraction, i.e., converting low-level logs into more abstract high-level logs before running discovery algorithms. ECS logs come with special characteristics that have so far not been fully addressed by existing event abstraction approaches. We aim to close this gap with a tailored ECS event abstraction (ECSEA) approach that trains a model by comparing recorded actual user activities (high-level traces) with the system-generated low-level traces (extracted from the ECS). The model allows us to automatically convert future low-level traces into an abstracted high-level log that can be used for PM. Our evaluation shows that the algorithm produces accurate results. ECSEA is a preprocessing method that is essential for the interpretation of collaborative work activity in ECS, which we call Social Process Mining.
</details>
<details>
<summary>摘要</summary>
一个目标 OF 进程挖掘（PM）是从信息系统事件日志中发现进程模型。PM 已经成功地应用于进程强调企业系统，但是它对交通和文档强调企业协作系统（ECS）的事件日志 Less 适用。ECS 事件日志具有非常细腻的特点，PM 在其日志上运行发现算法会导致“卡路里模型”。一种常见的解决方案是事件抽象，即将低级别的日志转换为更加抽象的高级别日志，以便于发现算法。ECS 日志具有特殊的特点， existing 事件抽象方法未能充分 Address 这些特点。我们的目标是通过针对实际用户活动记录（高级轨迹）和系统生成的低级别轨迹（从 ECS 提取）进行比较，并 trains 一个模型，以便将未来的低级别轨迹自动转换为抽象的高级别日志，可以用于 PM。我们的评估结果表明，该算法生成的结果准确。ECSEA 是一种适用于 ECS 的预处理方法，它是社交过程挖掘（Social Process Mining）中不可或缺的一部分。
</details></li>
</ul>
<hr>
<h2 id="Data-Augmentation-Based-Unsupervised-Domain-Adaptation-In-Medical-Imaging"><a href="#Data-Augmentation-Based-Unsupervised-Domain-Adaptation-In-Medical-Imaging" class="headerlink" title="Data Augmentation-Based Unsupervised Domain Adaptation In Medical Imaging"></a>Data Augmentation-Based Unsupervised Domain Adaptation In Medical Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04395">http://arxiv.org/abs/2308.04395</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sebastian Nørgaard Llambias, Mads Nielsen, Mostafa Mehdipour Ghazi</li>
<li>for: 这篇研究旨在提出一种不需要标注数据的Domain Adaptation方法，以便在不同的MRI扫描设备和数据集中进行脑部分 segmentation 任务。</li>
<li>methods: 该方法利用了MRI特定的数据生成技术，并通过对数据进行不同的预处理和数据增强来提高模型的泛化能力。</li>
<li>results: 经过广泛的实验和比较，该方法在多种任务和数据集中表现出了高精度和广泛的可用性，同时也能够快速地适应新的扫描设备和数据集。<details>
<summary>Abstract</summary>
Deep learning-based models in medical imaging often struggle to generalize effectively to new scans due to data heterogeneity arising from differences in hardware, acquisition parameters, population, and artifacts. This limitation presents a significant challenge in adopting machine learning models for clinical practice. We propose an unsupervised method for robust domain adaptation in brain MRI segmentation by leveraging MRI-specific augmentation techniques. To evaluate the effectiveness of our method, we conduct extensive experiments across diverse datasets, modalities, and segmentation tasks, comparing against the state-of-the-art methods. The results show that our proposed approach achieves high accuracy, exhibits broad applicability, and showcases remarkable robustness against domain shift in various tasks, surpassing the state-of-the-art performance in the majority of cases.
</details>
<details>
<summary>摘要</summary>
深度学习基本模型在医疗成像领域经常陷入新扫描数据的泛化问题，这是因为数据间的不同，包括硬件、获取参数、人口和artefacts等。这种限制对于实施机器学习模型在临床实践中带来了重要的挑战。我们提议一种无监督的鲁棒领域适应方法，通过利用MRI特有的扩充技术来实现。为评估我们的方法的效果，我们在多个数据集、模式和分割任务中进行了广泛的实验，与当前最佳方法进行比较。结果显示，我们的提议方法在多个任务中具有高精度、广泛适用性和强大的鲁棒性，超越了当前最佳性能的大多数情况。
</details></li>
</ul>
<hr>
<h2 id="Metaheuristic-Algorithms-in-Artificial-Intelligence-with-Applications-to-Bioinformatics-Biostatistics-Ecology-and-the-Manufacturing-Industries"><a href="#Metaheuristic-Algorithms-in-Artificial-Intelligence-with-Applications-to-Bioinformatics-Biostatistics-Ecology-and-the-Manufacturing-Industries" class="headerlink" title="Metaheuristic Algorithms in Artificial Intelligence with Applications to Bioinformatics, Biostatistics, Ecology and, the Manufacturing Industries"></a>Metaheuristic Algorithms in Artificial Intelligence with Applications to Bioinformatics, Biostatistics, Ecology and, the Manufacturing Industries</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10875">http://arxiv.org/abs/2308.10875</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/elviscuihan/csoma">https://github.com/elviscuihan/csoma</a></li>
<li>paper_authors: Elvis Han Cui, Zizhao Zhang, Culsome Junwen Chen, Weng Kee Wong</li>
<li>for:  This paper is written to demonstrate the flexibility and out-performance of a newly proposed nature-inspired metaheuristic algorithm called competitive swarm optimizer with mutated agents (CSO-MA) in various optimization problems in the statistical sciences.</li>
<li>methods:  The paper uses the CSO-MA algorithm to solve a variety of optimization problems, including finding maximum likelihood estimates of parameters, estimating parameters in a Rasch model, finding M-estimates for a Cox regression, and matrix completion to impute missing values.</li>
<li>results:  The paper shows that the CSO-MA algorithm is efficient and can incorporate various cost structures or multiple user-specified nonlinear constraints. The algorithm is applied to a variety of optimization problems, including finding maximum likelihood estimates of parameters in a single cell generalized trend model, estimating parameters in a commonly used Rasch model, finding M-estimates for a Cox regression, and matrix completion to impute missing values.<details>
<summary>Abstract</summary>
Nature-inspired metaheuristic algorithms are important components of artificial intelligence, and are increasingly used across disciplines to tackle various types of challenging optimization problems. We apply a newly proposed nature-inspired metaheuristic algorithm called competitive swarm optimizer with mutated agents (CSO-MA) and demonstrate its flexibility and out-performance relative to its competitors in a variety of optimization problems in the statistical sciences. In particular, we show the algorithm is efficient and can incorporate various cost structures or multiple user-specified nonlinear constraints. Our applications include (i) finding maximum likelihood estimates of parameters in a single cell generalized trend model to study pseudotime in bioinformatics, (ii) estimating parameters in a commonly used Rasch model in education research, (iii) finding M-estimates for a Cox regression in a Markov renewal model and (iv) matrix completion to impute missing values in a two compartment model. In addition we discuss applications to (v) select variables optimally in an ecology problem and (vi) design a car refueling experiment for the auto industry using a logistic model with multiple interacting factors.
</details>
<details>
<summary>摘要</summary>
自然 inspirited metaheuristic algorithms 是人工智能中重要的组件，广泛应用于各个领域解决各种困难的优化问题。我们使用一种新提出的自然 inspirited metaheuristic algorithm called competitive swarm optimizer with mutated agents（CSO-MA），并证明其灵活性和相比其他竞争对手的高性能。在统计科学中，我们应用了这种算法，包括：(i) 在单元维度泛化趋势模型中找到最大化拟合参数的最佳估计值，以研究生物信息学中的pseudotime。(ii) 在教育研究中，使用这种算法来估计Rasch模型中的参数。(iii) 在Markov renewal模型中使用这种算法来找到Cox回归的M-估计值。(iv) 在两个分布中完成缺失值的imatrix completion。此外，我们还讨论了这种算法在生态学问题中选取变量的最佳方法，以及在汽车业中使用Logistic模型来设计一个循环实验。
</details></li>
</ul>
<hr>
<h2 id="AdaptEx-A-Self-Service-Contextual-Bandit-Platform"><a href="#AdaptEx-A-Self-Service-Contextual-Bandit-Platform" class="headerlink" title="AdaptEx: A Self-Service Contextual Bandit Platform"></a>AdaptEx: A Self-Service Contextual Bandit Platform</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08650">http://arxiv.org/abs/2308.08650</a></li>
<li>repo_url: None</li>
<li>paper_authors: William Black, Ercument Ilhan, Andrea Marchini, Vilda Markeviciute</li>
<li>for: 这篇论文是为了介绍一个自助上下文投机平台，即AdaptEx，该平台可以在Expedia Group中广泛应用，以便 personnalize 用户体验。</li>
<li>methods: 该论文使用了多臂投机算法，以适应每个访问者的特定上下文，选择最佳变体，并快速从每次交互中学习。</li>
<li>results: 该平台可以快速提高用户体验，降低传统测试方法相关的成本和时间。它还可以在内容不断变化和连续”冷启”情况下快速迭代到优化产品解决方案。<details>
<summary>Abstract</summary>
This paper presents AdaptEx, a self-service contextual bandit platform widely used at Expedia Group, that leverages multi-armed bandit algorithms to personalize user experiences at scale. AdaptEx considers the unique context of each visitor to select the optimal variants and learns quickly from every interaction they make. It offers a powerful solution to improve user experiences while minimizing the costs and time associated with traditional testing methods. The platform unlocks the ability to iterate towards optimal product solutions quickly, even in ever-changing content and continuous "cold start" situations gracefully.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Understanding-the-Effect-of-Counterfactual-Explanations-on-Trust-and-Reliance-on-AI-for-Human-AI-Collaborative-Clinical-Decision-Making"><a href="#Understanding-the-Effect-of-Counterfactual-Explanations-on-Trust-and-Reliance-on-AI-for-Human-AI-Collaborative-Clinical-Decision-Making" class="headerlink" title="Understanding the Effect of Counterfactual Explanations on Trust and Reliance on AI for Human-AI Collaborative Clinical Decision Making"></a>Understanding the Effect of Counterfactual Explanations on Trust and Reliance on AI for Human-AI Collaborative Clinical Decision Making</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04375">http://arxiv.org/abs/2308.04375</a></li>
<li>repo_url: None</li>
<li>paper_authors: Min Hun Lee, Chong Jun Chew<br>for: 这个论文旨在研究人工智能（AI）在高风险领域（如医疗）的决策支持方面，以及人类对 AI 建议的过度依赖问题。methods: 该论文使用了突出特征解释以及对假解释来让人类更加分析地评估 AI 建议，以降低对 AI 的过度依赖。results: 研究发现，当 AI 模型提供正确的建议时，人类的性能和协调水平都得到了提高。然而，人类对 AI 模型的错误建议仍然存在过度依赖的问题，并且counterfactual解释可以帮助人类减少对错误 AI 建议的过度依赖。Specifically, 非专业人员在使用 counterfactual解释时表现出了更大的改善，而专业人员的性能则更好。<details>
<summary>Abstract</summary>
Artificial intelligence (AI) is increasingly being considered to assist human decision-making in high-stake domains (e.g. health). However, researchers have discussed an issue that humans can over-rely on wrong suggestions of the AI model instead of achieving human AI complementary performance. In this work, we utilized salient feature explanations along with what-if, counterfactual explanations to make humans review AI suggestions more analytically to reduce overreliance on AI and explored the effect of these explanations on trust and reliance on AI during clinical decision-making. We conducted an experiment with seven therapists and ten laypersons on the task of assessing post-stroke survivors' quality of motion, and analyzed their performance, agreement level on the task, and reliance on AI without and with two types of AI explanations. Our results showed that the AI model with both salient features and counterfactual explanations assisted therapists and laypersons to improve their performance and agreement level on the task when `right' AI outputs are presented. While both therapists and laypersons over-relied on `wrong' AI outputs, counterfactual explanations assisted both therapists and laypersons to reduce their over-reliance on `wrong' AI outputs by 21\% compared to salient feature explanations. Specifically, laypersons had higher performance degrades by 18.0 f1-score with salient feature explanations and 14.0 f1-score with counterfactual explanations than therapists with performance degrades of 8.6 and 2.8 f1-scores respectively. Our work discusses the potential of counterfactual explanations to better estimate the accuracy of an AI model and reduce over-reliance on `wrong' AI outputs and implications for improving human-AI collaborative decision-making.
</details>
<details>
<summary>摘要</summary>
人工智能（AI）在高度决策领域（如医疗）中被越来越广泛使用以协助人类决策。然而，研究人员已经提出了一个问题，即人们可能会因为AI模型的错误建议而过分依赖于AI，而不是 дости得人类AI补充性能。在这项工作中，我们使用了突出特征说明以及对比说明来使人们更加分析地评估AI建议，以降低对AI的过分依赖。我们在评估患者质量运动质量任务上进行了实验，并分析了参与者的表现、同意水平和对AI的依赖度。我们的结果表明，含有突出特征和对比说明的AI模型可以帮助治疗师和非专业人员提高表现和同意水平。而且，对比说明可以帮助治疗师和非专业人员减少对“错误”AI输出的过分依赖，相比突出特征说明下降21%。特别是，非专业人员在使用突出特征说明时表现下降18.0 f1-score，而在使用对比说明时表现下降14.0 f1-score，而治疗师则表现下降8.6和2.8 f1-score。我们的研究表明，对比说明可以更好地估计AI模型的准确性，降低对“错误”AI输出的过分依赖，并带来人类AI协同决策的进步。
</details></li>
</ul>
<hr>
<h2 id="Pelta-Shielding-Transformers-to-Mitigate-Evasion-Attacks-in-Federated-Learning"><a href="#Pelta-Shielding-Transformers-to-Mitigate-Evasion-Attacks-in-Federated-Learning" class="headerlink" title="Pelta: Shielding Transformers to Mitigate Evasion Attacks in Federated Learning"></a>Pelta: Shielding Transformers to Mitigate Evasion Attacks in Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04373">http://arxiv.org/abs/2308.04373</a></li>
<li>repo_url: None</li>
<li>paper_authors: Simon Queyrut, Yérom-David Bromberg, Valerio Schiavoni</li>
<li>for: The paper is written to address the issue of privacy preservation in federated learning, specifically the problem of malicious probing attacks on the model updates.</li>
<li>methods: The paper proposes a novel shielding mechanism called Pelta, which leverages Trusted Execution Environments (TEEs) to mask part of the back-propagation chain rule and prevent attackers from exploiting it for the design of malicious samples.</li>
<li>results: The paper demonstrates the effectiveness of Pelta against the Self Attention Gradient adversarial attack on a state-of-the-art ensemble model.Here’s the simplified Chinese version of the three points:</li>
<li>for: 本文是为了解决联合学习中的隐私保护问题，特别是对于攻击者通过模型更新来探测敏感信息。</li>
<li>methods: 本文提出了一种名为Pelta的新防御机制，利用可信执行环境（TEEs）隐藏部分反向传播链规则，防止攻击者通过这些规则设计恶意样本。</li>
<li>results: 本文对一个国际 ensemble 模型进行了评估，并证明Pelta可以有效防止自我注意力梯度攻击。<details>
<summary>Abstract</summary>
The main premise of federated learning is that machine learning model updates are computed locally, in particular to preserve user data privacy, as those never leave the perimeter of their device. This mechanism supposes the general model, once aggregated, to be broadcast to collaborating and non malicious nodes. However, without proper defenses, compromised clients can easily probe the model inside their local memory in search of adversarial examples. For instance, considering image-based applications, adversarial examples consist of imperceptibly perturbed images (to the human eye) misclassified by the local model, which can be later presented to a victim node's counterpart model to replicate the attack. To mitigate such malicious probing, we introduce Pelta, a novel shielding mechanism leveraging trusted hardware. By harnessing the capabilities of Trusted Execution Environments (TEEs), Pelta masks part of the back-propagation chain rule, otherwise typically exploited by attackers for the design of malicious samples. We evaluate Pelta on a state of the art ensemble model and demonstrate its effectiveness against the Self Attention Gradient adversarial Attack.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="SLEM-Machine-Learning-for-Path-Modeling-and-Causal-Inference-with-Super-Learner-Equation-Modeling"><a href="#SLEM-Machine-Learning-for-Path-Modeling-and-Causal-Inference-with-Super-Learner-Equation-Modeling" class="headerlink" title="SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling"></a>SLEM: Machine Learning for Path Modeling and Causal Inference with Super Learner Equation Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04365">http://arxiv.org/abs/2308.04365</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/matthewvowels1/slem">https://github.com/matthewvowels1/slem</a></li>
<li>paper_authors: Matthew J. Vowels</li>
<li>for: 本研究旨在提供一种可靠且不偏的 causal effect 估计方法，以便在 observational 数据上进行预测性的 intervenion 研究。</li>
<li>methods: 本研究使用 Super Learner Equation Modeling（SLEM），一种基于机器学习 Super Learner 集成的路径模型方法，来解决 causal inference 中的函数偏差问题。</li>
<li>results: 对比 SEM 方法，SLEM 在线性模型中表现出了竞争性的表现，并且在非线性关系中表现出了superiority。此外，SLEM 还提供了可靠且不偏的 causal effect 估计方法，可以用于 observational 数据上进行预测性的 intervenion 研究。<details>
<summary>Abstract</summary>
Causal inference is a crucial goal of science, enabling researchers to arrive at meaningful conclusions regarding the predictions of hypothetical interventions using observational data. Path models, Structural Equation Models (SEMs), and, more generally, Directed Acyclic Graphs (DAGs), provide a means to unambiguously specify assumptions regarding the causal structure underlying a phenomenon. Unlike DAGs, which make very few assumptions about the functional and parametric form, SEM assumes linearity. This can result in functional misspecification which prevents researchers from undertaking reliable effect size estimation. In contrast, we propose Super Learner Equation Modeling, a path modeling technique integrating machine learning Super Learner ensembles. We empirically demonstrate its ability to provide consistent and unbiased estimates of causal effects, its competitive performance for linear models when compared with SEM, and highlight its superiority over SEM when dealing with non-linear relationships. We provide open-source code, and a tutorial notebook with example usage, accentuating the easy-to-use nature of the method.
</details>
<details>
<summary>摘要</summary>
科学中的重要目标之一是 causal inference，即使用观察数据来得到干扰干扰的结论。路径模型、结构方程模型（SEM）和、更一般地说，导向无环图（DAG）可以明确地 especify causal structure underlying a phenomenon的假设。不同于 DAG，SEM 假设 linearity，这可能会导致函数假设不正确，从而阻碍研究人员进行可靠的效应大小估计。在这种情况下，我们提出了 Super Learner Equation Modeling，一种路径模型技术， integrate machine learning Super Learner ensembles。我们经验表明它可以提供可靠和不偏的 causal effect estimates，与 SEM 在线性模型中的表现竞争性，并在非线性关系中超过 SEM。我们提供了开源代码和一个教程Notebook，强调这种方法的易用性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/09/cs.LG_2023_08_09/" data-id="clogyj8yu00me7cra1zn7cloi" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_09" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/09/eess.IV_2023_08_09/" class="article-date">
  <time datetime="2023-08-09T09:00:00.000Z" itemprop="datePublished">2023-08-09</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/09/eess.IV_2023_08_09/">eess.IV - 2023-08-09</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="ACE-HetEM-for-ab-initio-Heterogenous-Cryo-EM-3D-Reconstruction"><a href="#ACE-HetEM-for-ab-initio-Heterogenous-Cryo-EM-3D-Reconstruction" class="headerlink" title="ACE-HetEM for ab initio Heterogenous Cryo-EM 3D Reconstruction"></a>ACE-HetEM for ab initio Heterogenous Cryo-EM 3D Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04956">http://arxiv.org/abs/2308.04956</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weijie Chen, Lin Yao, Zeqing Xia, Yuhang Wang<br>for:This paper aims to improve the accuracy of 3D structure reconstruction from cryo-EM images with unknown poses and low signal-to-noise ratio.methods:The proposed method, called ACE-HetEM, uses an unsupervised deep learning architecture based on amortized inference to disentangle conformation classifications and pose estimations.results:ACE-HetEM has comparable accuracy in pose estimation and produces better reconstruction resolution than non-amortized methods on simulated datasets, and is also applicable to real experimental datasets.Here’s the Chinese translation:for:这篇论文目的是提高低信号噪响和未知投影角度的普适电子顺传影像三维结构重建精度。methods:提议的方法是基于杜邦诱导的无监督深度学习架构ACE-HetEM，以分离配置分类和投影估计。results:在模拟数据集上，ACE-HetEM和非杜邦方法相比，pose估计准确率相似，重建分辨率更高，并且可应用于实验室数据集。<details>
<summary>Abstract</summary>
Due to the extremely low signal-to-noise ratio (SNR) and unknown poses (projection angles and image translation) in cryo-EM experiments, reconstructing 3D structures from 2D images is very challenging. On top of these challenges, heterogeneous cryo-EM reconstruction also has an additional requirement: conformation classification. An emerging solution to this problem is called amortized inference, implemented using the autoencoder architecture or its variants. Instead of searching for the correct image-to-pose/conformation mapping for every image in the dataset as in non-amortized methods, amortized inference only needs to train an encoder that maps images to appropriate latent spaces representing poses or conformations. Unfortunately, standard amortized-inference-based methods with entangled latent spaces have difficulty learning the distribution of conformations and poses from cryo-EM images. In this paper, we propose an unsupervised deep learning architecture called "ACE-HetEM" based on amortized inference. To explicitly enforce the disentanglement of conformation classifications and pose estimations, we designed two alternating training tasks in our method: image-to-image task and pose-to-pose task. Results on simulated datasets show that ACE-HetEM has comparable accuracy in pose estimation and produces even better reconstruction resolution than non-amortized methods. Furthermore, we show that ACE-HetEM is also applicable to real experimental datasets.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:由于电镜电子显微镜实验中的信号响应率（SNR）和不确定的投影角度和图像翻译都很低，从2D图像中重建3D结构非常困难。此外，异类电镜电子显微镜重建还有一个额外要求：摘要分类。一种迅速成为解决方案的方法是使用启发器架构或其变体来实现摘要推理。而非摘要方法需要对每个图像在数据集中搜索正确的图像到pose/摘要映射。然而，标准的摘要推理方法附加的缺点是难以从电镜电子显微镜图像中学习摘要分布和投影角度的分布。在这篇论文中，我们提出了一种无监督深度学习架构，称为“ACE-HetEM”，基于摘要推理。为了明确分离摘要分类和投影估计的分布，我们在我们的方法中设计了两个相互轮换的训练任务：图像到图像任务和投影到投影任务。实验结果表明，ACE-HetEM在 simulate 数据集上有相当的准确率和更高的重建分辨率，而且可以应用于实验数据集。
</details></li>
</ul>
<hr>
<h2 id="HSD-PAM-High-Speed-Super-Resolution-Deep-Penetration-Photoacoustic-Microscopy-Imaging-Boosted-by-Dual-Branch-Fusion-Network"><a href="#HSD-PAM-High-Speed-Super-Resolution-Deep-Penetration-Photoacoustic-Microscopy-Imaging-Boosted-by-Dual-Branch-Fusion-Network" class="headerlink" title="HSD-PAM: High Speed Super Resolution Deep Penetration Photoacoustic Microscopy Imaging Boosted by Dual Branch Fusion Network"></a>HSD-PAM: High Speed Super Resolution Deep Penetration Photoacoustic Microscopy Imaging Boosted by Dual Branch Fusion Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04922">http://arxiv.org/abs/2308.04922</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhengyuan Zhang, Haoran Jin, Zesheng Zheng, Wenwen Zhang, Wenhao Lu, Feng Qin, Arunima Sharma, Manojit Pramanik, Yuanjin Zheng</li>
<li>for: 这篇论文旨在提出一种硬件和软件合作的方法，以提高photoacoustic microscopy（PAM）系统的速度、分辨率和深度三个关键参数的矛盾。</li>
<li>methods: 该方法基于数据驱动的算法，包括一个新的双分支合并网络，其中一个高分辨率分支和一个高速分支。</li>
<li>results: 经过广泛的数值和生物体实验 validate，该算法可以提高PAM系统的速度和分辨率，同时保持AR-PAM模式的深度能力。结果显示，对于低分辨率、低采样率AR-PAM图像，可以通过增加采样率和提高分辨率来提高图像质量，从而实现高速、超分辨率、深度采集的PAM系统（HSD-PAM）。<details>
<summary>Abstract</summary>
Photoacoustic microscopy (PAM) is a novel implementation of photoacoustic imaging (PAI) for visualizing the 3D bio-structure, which is realized by raster scanning of the tissue. However, as three involved critical imaging parameters, imaging speed, lateral resolution, and penetration depth have mutual effect to one the other. The improvement of one parameter results in the degradation of other two parameters, which constrains the overall performance of the PAM system. Here, we propose to break these limitations by hardware and software co-design. Starting with low lateral resolution, low sampling rate AR-PAM imaging which possesses the deep penetration capability, we aim to enhance the lateral resolution and up sampling the images, so that high speed, super resolution, and deep penetration for the PAM system (HSD-PAM) can be achieved. Data-driven based algorithm is a promising approach to solve this issue, thereby a dedicated novel dual branch fusion network is proposed, which includes a high resolution branch and a high speed branch. Since the availability of switchable AR-OR-PAM imaging system, the corresponding low resolution, undersample AR-PAM and high resolution, full sampled OR-PAM image pairs are utilized for training the network. Extensive simulation and in vivo experiments have been conducted to validate the trained model, enhancement results have proved the proposed algorithm achieved the best perceptual and quantitative image quality. As a result, the imaging speed is increased 16 times and the imaging lateral resolution is improved 5 times, while the deep penetration merit of AR-PAM modality is still reserved.
</details>
<details>
<summary>摘要</summary>
photoacoustic microscopy (PAM) 是一种新的 photoacoustic imaging (PAI) 技术，用于可见三维生物结构，通过扫描生物组织的方式实现。然而，存在三个关键的图像参数之间的互相关系：图像速度、横向分辨率和吸收深度。提高一个参数会导致其他两个参数受损，这限制了整体 PAM 系统的性能。我们提议通过硬件和软件合作来突破这些限制。从低横向分辨率、低抽象率 AR-PAM 成像开始，我们想要提高横向分辨率和更新图像，以达到高速、超分辨、深入吸收的 PAM 系统（HSD-PAM）。数据驱动基于的算法是一种有希望的方法，因此我们提出了一种专门的双分支融合网络，包括高分辨率分支和高速分支。由于可用的可 switchable AR-OR-PAM 成像系统，对应的低分辨率、下抽象 AR-PAM 和高分辨率、全样本 OR-PAM 图像对在训练网络时使用。我们进行了广泛的 simulations 和生物实验，以验证训练的模型，提升结果表明，提案的算法实现了最佳的感知和量化图像质量。因此，图像速度提高 16 倍，横向分辨率提高 5 倍，而 AR-PAM 模式下的深入吸收特性仍然保留。
</details></li>
</ul>
<hr>
<h2 id="StableVQA-A-Deep-No-Reference-Quality-Assessment-Model-for-Video-Stability"><a href="#StableVQA-A-Deep-No-Reference-Quality-Assessment-Model-for-Video-Stability" class="headerlink" title="StableVQA: A Deep No-Reference Quality Assessment Model for Video Stability"></a>StableVQA: A Deep No-Reference Quality Assessment Model for Video Stability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04904">http://arxiv.org/abs/2308.04904</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qmme/stablevqa">https://github.com/qmme/stablevqa</a></li>
<li>paper_authors: Tengchuan Kou, Xiaohong Liu, Wei Sun, Jun Jia, Xiongkuo Min, Guangtao Zhai, Ning Liu</li>
<li>For: The paper is written for evaluating the stability of User Generated Content (UGC) videos and proposing a novel Video Quality Assessment for Stability (VQA-S) model.* Methods: The paper uses a novel VQA-S model named StableVQA, which consists of three feature extractors to acquire optical flow, semantic, and blur features, and a regression layer to predict the final stability score.* Results: The paper achieves a higher correlation with subjective opinions than existing VQA-S models and generic VQA models, and provides a new database named StableDB that contains 1,952 diversely-shaky UGC videos with subjective scores for video stability.<details>
<summary>Abstract</summary>
Video shakiness is an unpleasant distortion of User Generated Content (UGC) videos, which is usually caused by the unstable hold of cameras. In recent years, many video stabilization algorithms have been proposed, yet no specific and accurate metric enables comprehensively evaluating the stability of videos. Indeed, most existing quality assessment models evaluate video quality as a whole without specifically taking the subjective experience of video stability into consideration. Therefore, these models cannot measure the video stability explicitly and precisely when severe shakes are present. In addition, there is no large-scale video database in public that includes various degrees of shaky videos with the corresponding subjective scores available, which hinders the development of Video Quality Assessment for Stability (VQA-S). To this end, we build a new database named StableDB that contains 1,952 diversely-shaky UGC videos, where each video has a Mean Opinion Score (MOS) on the degree of video stability rated by 34 subjects. Moreover, we elaborately design a novel VQA-S model named StableVQA, which consists of three feature extractors to acquire the optical flow, semantic, and blur features respectively, and a regression layer to predict the final stability score. Extensive experiments demonstrate that the StableVQA achieves a higher correlation with subjective opinions than the existing VQA-S models and generic VQA models. The database and codes are available at https://github.com/QMME/StableVQA.
</details>
<details>
<summary>摘要</summary>
视频不稳定是User Generated Content（UGC）视频中的一种不приятный扭曲，通常是因为摄像机不稳定。在过去的几年中，许多视频稳定算法被提出，但没有专门和准确的度量能够全面评估视频的稳定性。实际上，大多数现有的视频质量评估模型只评估视频质量总体而不是特定地考虑视频稳定的主观体验。因此，这些模型不能明确和精确地测量在严重抖动时的视频稳定性。另外，没有公开的大规模视频数据库，其中包含了不同程度的抖动视频以及对应的主观得分，这阻碍了视频质量评估 для稳定（VQA-S）的发展。为此，我们建立了一个名为StableDB的数据库，其中包含1,952个多样化的UGC视频，每个视频都有由34名评分者评分的视频稳定度的Mean Opinion Score（MOS）。此外，我们还 elaborately 设计了一种名为StableVQA的新型VQA-S模型，它包括三个特征提取器，用于获取光流、 semantics 和模糊特征，以及一个回归层用于预测最终的稳定度分。广泛的实验表明，StableVQA在与主观意见相关性方面高于现有的VQA-S模型和通用VQA模型。数据库和代码可以在https://github.com/QMME/StableVQA 中获取。
</details></li>
</ul>
<hr>
<h2 id="An-automated-pipeline-for-quantitative-T2-fetal-body-MRI-and-segmentation-at-low-field"><a href="#An-automated-pipeline-for-quantitative-T2-fetal-body-MRI-and-segmentation-at-low-field" class="headerlink" title="An automated pipeline for quantitative T2* fetal body MRI and segmentation at low field"></a>An automated pipeline for quantitative T2* fetal body MRI and segmentation at low field</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04903">http://arxiv.org/abs/2308.04903</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kelly Payette, Alena Uus, Jordina Aviles Verdera, Carla Avena Zampieri, Megan Hall, Lisa Story, Maria Deprez, Mary A. Rutherford, Joseph V. Hajnal, Sebastien Ourselin, Raphael Tomi-Tricot, Jana Hutter</li>
<li>for: 这项研究的目的是为了开发一种用于低场强磁共振成像的半自动化管道，以实现快速和详细的量化T2*相关分析。</li>
<li>methods: 这种管道使用了多echo动态序列获取和重建方法，并使用了一个神经网络来自动 segment fetal体3D卷积体。</li>
<li>results: 研究发现，这种管道可以成功地对17-40周的胎儿进行高精度的T2*相关分析，并且具有高度的抗变化和鲁棒性。<details>
<summary>Abstract</summary>
Fetal Magnetic Resonance Imaging at low field strengths is emerging as an exciting direction in perinatal health. Clinical low field (0.55T) scanners are beneficial for fetal imaging due to their reduced susceptibility-induced artefacts, increased T2* values, and wider bore (widening access for the increasingly obese pregnant population). However, the lack of standard automated image processing tools such as segmentation and reconstruction hampers wider clinical use. In this study, we introduce a semi-automatic pipeline using quantitative MRI for the fetal body at low field strength resulting in fast and detailed quantitative T2* relaxometry analysis of all major fetal body organs. Multi-echo dynamic sequences of the fetal body were acquired and reconstructed into a single high-resolution volume using deformable slice-to-volume reconstruction, generating both structural and quantitative T2* 3D volumes. A neural network trained using a semi-supervised approach was created to automatically segment these fetal body 3D volumes into ten different organs (resulting in dice values > 0.74 for 8 out of 10 organs). The T2* values revealed a strong relationship with GA in the lungs, liver, and kidney parenchyma (R^2>0.5). This pipeline was used successfully for a wide range of GAs (17-40 weeks), and is robust to motion artefacts. Low field fetal MRI can be used to perform advanced MRI analysis, and is a viable option for clinical scanning.
</details>
<details>
<summary>摘要</summary>
低场强磁共振成像在妊娠健康领域是一项发展方向。低场（0.55T）扫描仪的优点包括降低受影响的artefacts，提高T2*值和更宽的轴扩（扩大对日益肥胖妊娠人口的访问）。然而，由于缺乏标准自动化图像处理工具，如分割和重建，因此对于临床应用而言，更加受限。本研究中，我们提出了一个半自动化管线，使用量化MRI对妊娠体内部进行快速和详细的T2*相关分析。我们使用多echo动态序列获取和重建妊娠体内部高分辨率三维volume，并使用可变的材料学模型进行slice-to-volume重建。通过使用半超级vised学习方法，我们自动将妊娠体三维volume分割成十个不同的器官（得到了 dice值超过0.74的八个器官）。T2*值与胎儿龄（GA）之间存在强相关性（R^2>0.5）。这种管线在17-40周的多个胎儿龄上成功应用，并具有对运动artefacts的Robust性。低场妊娠MRI可以进行高级MRI分析，是一种可靠的扫描选项。
</details></li>
</ul>
<hr>
<h2 id="Transmission-and-Color-guided-Network-for-Underwater-Image-Enhancement"><a href="#Transmission-and-Color-guided-Network-for-Underwater-Image-Enhancement" class="headerlink" title="Transmission and Color-guided Network for Underwater Image Enhancement"></a>Transmission and Color-guided Network for Underwater Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04892">http://arxiv.org/abs/2308.04892</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pan Mu, Jing Fang, Haotian Qian, Cong Bai</li>
<li>for: 本研究旨在提高水下图像的显示质量，解决光线传播在水中的吸收和散射问题。</li>
<li>methods: 该研究提出了一种基于自适应传输和动态色彩指导网络的水下图像增强方法（名为ATDCnet），包括采用物理知识设计的自适应传输指导模块（ATM）、采用动态色彩指导模块（DCM）进行颜色偏差问题的解决，以及基于编码器-解码器结构和多阶段特征融合机制进行颜色恢复和对比度增强同时处理。</li>
<li>results: EXTENSIVE experiments示出ATDCnet在多个benchmark数据集上达到了当今最佳性能水平。<details>
<summary>Abstract</summary>
In recent years, with the continuous development of the marine industry, underwater image enhancement has attracted plenty of attention. Unfortunately, the propagation of light in water will be absorbed by water bodies and scattered by suspended particles, resulting in color deviation and low contrast. To solve these two problems, we propose an Adaptive Transmission and Dynamic Color guided network (named ATDCnet) for underwater image enhancement. In particular, to exploit the knowledge of physics, we design an Adaptive Transmission-directed Module (ATM) to better guide the network. To deal with the color deviation problem, we design a Dynamic Color-guided Module (DCM) to post-process the enhanced image color. Further, we design an Encoder-Decoder-based Compensation (EDC) structure with attention and a multi-stage feature fusion mechanism to perform color restoration and contrast enhancement simultaneously. Extensive experiments demonstrate the state-of-the-art performance of the ATDCnet on multiple benchmark datasets.
</details>
<details>
<summary>摘要</summary>
Specifically, we design an Adaptive Transmission-directed Module (ATM) to leverage the knowledge of physics and better guide the network. To address the color deviation problem, we design a Dynamic Color-guided Module (DCM) to post-process the enhanced image color. Additionally, we design an Encoder-Decoder-based Compensation (EDC) structure with attention and a multi-stage feature fusion mechanism to simultaneously perform color restoration and contrast enhancement. Extensive experiments show that the ATDCnet achieves state-of-the-art performance on multiple benchmark datasets.
</details></li>
</ul>
<hr>
<h2 id="Deep-Generative-Networks-for-Heterogeneous-Augmentation-of-Cranial-Defects"><a href="#Deep-Generative-Networks-for-Heterogeneous-Augmentation-of-Cranial-Defects" class="headerlink" title="Deep Generative Networks for Heterogeneous Augmentation of Cranial Defects"></a>Deep Generative Networks for Heterogeneous Augmentation of Cranial Defects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04883">http://arxiv.org/abs/2308.04883</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kamil Kwarciak, Marek Wodzinski</li>
<li>for: 这个研究旨在提高人工头盾设计的自动化程度，使用深度学习技术来解决高多标本异常性的挑战。</li>
<li>methods: 本研究使用三种深度生成模型来增强数据集，包括 Wasserstein生成对抗网络受扰条件（WGAN-GP）、WGAN-GP混合方法和 introspective Variational Autoencoder（IntroVAE）。这些模型可以生成万以上的异常头盾，并且可以控制异常的多标本性和头盾的实际形状。</li>
<li>results: 这些生成的异常头盾可以帮助提高人工头盾设计的自动化程度，并且可以增强异常部分的分类效果。研究显示，使用这些生成的异常头盾可以提高头盾设计的精度和效率。<details>
<summary>Abstract</summary>
The design of personalized cranial implants is a challenging and tremendous task that has become a hot topic in terms of process automation with the use of deep learning techniques. The main challenge is associated with the high diversity of possible cranial defects. The lack of appropriate data sources negatively influences the data-driven nature of deep learning algorithms. Hence, one of the possible solutions to overcome this problem is to rely on synthetic data. In this work, we propose three volumetric variations of deep generative models to augment the dataset by generating synthetic skulls, i.e. Wasserstein Generative Adversarial Network with Gradient Penalty (WGAN-GP), WGAN-GP hybrid with Variational Autoencoder pretraining (VAE/WGAN-GP) and Introspective Variational Autoencoder (IntroVAE). We show that it is possible to generate dozens of thousands of defective skulls with compatible defects that achieve a trade-off between defect heterogeneity and the realistic shape of the skull. We evaluate obtained synthetic data quantitatively by defect segmentation with the use of V-Net and qualitatively by their latent space exploration. We show that the synthetically generated skulls highly improve the segmentation process compared to using only the original unaugmented data. The generated skulls may improve the automatic design of personalized cranial implants for real medical cases.
</details>
<details>
<summary>摘要</summary>
个人化骨Implant设计是一个具有挑战性和巨大性的任务，现在透过深度学习技术进行自动化处理而成为热门话题。主要挑战在于骨骼缺陷的多样性。无法获得适当的数据源，对深度学习算法的数据驱动性产生负面影响。因此，我们提出了利用合成数据作为解决方案。在这个研究中，我们提出了三种深度生成模型的卷积量变化，即Wasserstein生成对抗网络受限GP（WGAN-GP）、WGAN-GP混合Variale Autoencoder预训练（VAE/WGAN-GP）和Introspective Variale Autoencoder（IntroVAE）。我们发现可以生成万分之一的缺陷骨骼，并且可以实现缺陷兼具实际骨骼形状的调和。我们使用V-Net进行缺陷分类，并且进行潜在空间探索。我们发现生成的骨骼可以对骨骼缺陷进行优化分类，相比使用仅有原始未处理数据，提高分类效果。这些生成的骨骼可能对实际医疗案例中的个人化骨Implant设计提供帮助。
</details></li>
</ul>
<hr>
<h2 id="HyperCoil-Recon-A-Hypernetwork-based-Adaptive-Coil-Configuration-Task-Switching-Network-for-MRI-Reconstruction"><a href="#HyperCoil-Recon-A-Hypernetwork-based-Adaptive-Coil-Configuration-Task-Switching-Network-for-MRI-Reconstruction" class="headerlink" title="HyperCoil-Recon: A Hypernetwork-based Adaptive Coil Configuration Task Switching Network for MRI Reconstruction"></a>HyperCoil-Recon: A Hypernetwork-based Adaptive Coil Configuration Task Switching Network for MRI Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04821">http://arxiv.org/abs/2308.04821</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sriprabhar/hypercoil-recon">https://github.com/sriprabhar/hypercoil-recon</a></li>
<li>paper_authors: Sriprabha Ramanarayanan, Mohammad Al Fahim, Rahul G. S., Amrit Kumar Jethi, Keerthi Ram, Mohanasankar Sivaprakasam</li>
<li>for: 这个研究是为了提高多极MRI重建的速度和精度，并且解决了训练或微调深度学习模型的问题，以便在临床实施中使用。</li>
<li>methods: 这个研究使用了hypernetwork-based的coil configuration task-switching network，将多个配置的数据集合为一个多任务学习 perspective，将每个配置视为一个任务，并将对应的问题特有的 weights 应用到重建网络中。</li>
<li>results: 这个方法可以在不同的配置下进行灵活的自适应，并且可以与特定的配置进行实时的配置匹配，实现了在试验时对应不同配置的普遍性。实验结果显示，这个方法可以与特定配置进行匹配，并且可以与不同的配置进行自适应，而且与专门设计的配置模型相比，有着1-3dB &#x2F; 0.02-0.03的提升。<details>
<summary>Abstract</summary>
Parallel imaging, a fast MRI technique, involves dynamic adjustments based on the configuration i.e. number, positioning, and sensitivity of the coils with respect to the anatomy under study. Conventional deep learning-based image reconstruction models have to be trained or fine-tuned for each configuration, posing a barrier to clinical translation, given the lack of computational resources and machine learning expertise for clinicians to train models at deployment. Joint training on diverse datasets learns a single weight set that might underfit to deviated configurations. We propose, HyperCoil-Recon, a hypernetwork-based coil configuration task-switching network for multi-coil MRI reconstruction that encodes varying configurations of the numbers of coils in a multi-tasking perspective, posing each configuration as a task. The hypernetworks infer and embed task-specific weights into the reconstruction network, 1) effectively utilizing the contextual knowledge of common and varying image features among the various fields-of-view of the coils, and 2) enabling generality to unseen configurations at test time. Experiments reveal that our approach 1) adapts on the fly to various unseen configurations up to 32 coils when trained on lower numbers (i.e. 7 to 11) of randomly varying coils, and to 120 deviated unseen configurations when trained on 18 configurations in a single model, 2) matches the performance of coil configuration-specific models, and 3) outperforms configuration-invariant models with improvement margins of around 1 dB / 0.03 and 0.3 dB / 0.02 in PSNR / SSIM for knee and brain data. Our code is available at https://github.com/sriprabhar/HyperCoil-Recon
</details>
<details>
<summary>摘要</summary>
“ параллельное изображение， быстрый метод МРИ, involves 动态调整基于配置，即数量、位置和敏感度的磁共振器与研究对象的解剖学相关。 传统的深度学习基于图像重建模型需要训练或微调，这会对临床应用带来障碍，因为临床医生缺乏计算资源和机器学习专业知识来训练模型。 我们提出了 HyperCoil-Recon，一种基于 hypernetwork 的磁共振器配置任务转换网络，用于多个磁共振器的图像重建。 Hypernetworks 将任务特定的 weights 适应到重建网络中，1) 有效地利用磁共振器不同配置下图像特征的共同知识，2) 允许在测试时适应未看过的配置。 实验表明，我们的方法可以1) 在未见过配置下适应到多达 32 个磁共振器，2) 与磁共振器配置特定模型匹配，3) 超过配置不变模型，增幅约为 1 dB / 0.03 和 0.3 dB / 0.02 的 PSNR / SSIM 值。我们的代码可以在 GitHub 上找到。”
</details></li>
</ul>
<hr>
<h2 id="An-Integrated-Visual-Analytics-System-for-Studying-Clinical-Carotid-Artery-Plaques"><a href="#An-Integrated-Visual-Analytics-System-for-Studying-Clinical-Carotid-Artery-Plaques" class="headerlink" title="An Integrated Visual Analytics System for Studying Clinical Carotid Artery Plaques"></a>An Integrated Visual Analytics System for Studying Clinical Carotid Artery Plaques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.06285">http://arxiv.org/abs/2308.06285</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chaoqing Xu, Zhentao Zheng, Yiting Fu, Baofeng Chang, Legao Chen, Minghui Wu, Mingli Song, Jinsong Jiang</li>
<li>for: 这个论文旨在开发一个智能血液动脉疾病诊断系统，帮助血液动脉外科医生全面分析血液动脉疾病的临床生物学和成像指标。</li>
<li>methods: 该系统包括两个主要功能：首先，通过一系列的信息视化方法，显示血液动脉疾病和各种因素之间的相关性，并将患者生物学指标数据集成分析。其次，通过机器学习技术，提高血液动脉疾病组成部分之间的自然相关性的显示，并在医疗图像上显示血液动脉疾病的空间分布。</li>
<li>results: 通过使用医院实际取得的数据进行两个案例研究，结果表明，设计的血液动脉分析系统可以有效地为血液动脉外科医生提供临床诊断和治疗指导。<details>
<summary>Abstract</summary>
Carotid artery plaques can cause arterial vascular diseases such as stroke and myocardial infarction, posing a severe threat to human life. However, the current clinical examination mainly relies on a direct assessment by physicians of patients' clinical indicators and medical images, lacking an integrated visualization tool for analyzing the influencing factors and composition of carotid artery plaques. We have designed an intelligent carotid artery plaque visual analysis system for vascular surgery experts to comprehensively analyze the clinical physiological and imaging indicators of carotid artery diseases. The system mainly includes two functions: First, it displays the correlation between carotid artery plaque and various factors through a series of information visualization methods and integrates the analysis of patient physiological indicator data. Second, it enhances the interface guidance analysis of the inherent correlation between the components of carotid artery plaque through machine learning and displays the spatial distribution of the plaque on medical images. Additionally, we conducted two case studies on carotid artery plaques using real data obtained from a hospital, and the results indicate that our designed carotid analysis system can effectively provide clinical diagnosis and treatment guidance for vascular surgeons.
</details>
<details>
<summary>摘要</summary>
carotid artery plaques can cause arterial vascular diseases such as stroke and myocardial infarction, posing a severe threat to human life. However, the current clinical examination mainly relies on a direct assessment by physicians of patients' clinical indicators and medical images, lacking an integrated visualization tool for analyzing the influencing factors and composition of carotid artery plaques. We have designed an intelligent carotid artery plaque visual analysis system for vascular surgery experts to comprehensively analyze the clinical physiological and imaging indicators of carotid artery diseases. The system mainly includes two functions: First, it displays the correlation between carotid artery plaque and various factors through a series of information visualization methods and integrates the analysis of patient physiological indicator data. Second, it enhances the interface guidance analysis of the inherent correlation between the components of carotid artery plaque through machine learning and displays the spatial distribution of the plaque on medical images. Additionally, we conducted two case studies on carotid artery plaques using real data obtained from a hospital, and the results indicate that our designed carotid analysis system can effectively provide clinical diagnosis and treatment guidance for vascular surgeons.Here's the text in Traditional Chinese:carotid artery plaques can cause arterial vascular diseases such as stroke and myocardial infarction, posing a severe threat to human life. However, the current clinical examination mainly relies on a direct assessment by physicians of patients' clinical indicators and medical images, lacking an integrated visualization tool for analyzing the influencing factors and composition of carotid artery plaques. We have designed an intelligent carotid artery plaque visual analysis system for vascular surgery experts to comprehensively analyze the clinical physiological and imaging indicators of carotid artery diseases. The system mainly includes two functions: First, it displays the correlation between carotid artery plaque and various factors through a series of information visualization methods and integrates the analysis of patient physiological indicator data. Second, it enhances the interface guidance analysis of the inherent correlation between the components of carotid artery plaque through machine learning and displays the spatial distribution of the plaque on medical images. Additionally, we conducted two case studies on carotid artery plaques using real data obtained from a hospital, and the results indicate that our designed carotid analysis system can effectively provide clinical diagnosis and treatment guidance for vascular surgeons.
</details></li>
</ul>
<hr>
<h2 id="Long-Distance-Gesture-Recognition-using-Dynamic-Neural-Networks"><a href="#Long-Distance-Gesture-Recognition-using-Dynamic-Neural-Networks" class="headerlink" title="Long-Distance Gesture Recognition using Dynamic Neural Networks"></a>Long-Distance Gesture Recognition using Dynamic Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04643">http://arxiv.org/abs/2308.04643</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shubhang Bhatnagar, Sharath Gopal, Narendra Ahuja, Liu Ren</li>
<li>For: This paper is written for recognizing gestures from longer distances, specifically for applications such as gesture-based interactions with a floor cleaning robot or a drone.* Methods: The proposed method uses a dynamic neural network to select features from gesture-containing spatial regions of the input sensor data for further processing, which helps the network focus on features important for gesture recognition while discarding background features early on.* Results: The proposed method outperforms previous state-of-the-art methods on recognition accuracy and compute efficiency in the LD-ConGR long-distance dataset.<details>
<summary>Abstract</summary>
Gestures form an important medium of communication between humans and machines. An overwhelming majority of existing gesture recognition methods are tailored to a scenario where humans and machines are located very close to each other. This short-distance assumption does not hold true for several types of interactions, for example gesture-based interactions with a floor cleaning robot or with a drone. Methods made for short-distance recognition are unable to perform well on long-distance recognition due to gestures occupying only a small portion of the input data. Their performance is especially worse in resource constrained settings where they are not able to effectively focus their limited compute on the gesturing subject. We propose a novel, accurate and efficient method for the recognition of gestures from longer distances. It uses a dynamic neural network to select features from gesture-containing spatial regions of the input sensor data for further processing. This helps the network focus on features important for gesture recognition while discarding background features early on, thus making it more compute efficient compared to other techniques. We demonstrate the performance of our method on the LD-ConGR long-distance dataset where it outperforms previous state-of-the-art methods on recognition accuracy and compute efficiency.
</details>
<details>
<summary>摘要</summary>
Gestures 是人工智能与机器之间重要的通信媒体。现有的大多数手势识别方法假设人类和机器在非常近的距离上进行交互，这个短距离假设不符实际的许多交互情况，例如与地板干净机器人或者无人机的交互。由于手势占输入数据中的只占一小部分，因此这些方法在远距离识别中表现不佳。我们提出了一种新的、准确和高效的手势识别方法，它使用动态神经网络选择手势包含的空间区域的输入感知数据进行进一步处理。这有助于网络在执行手势识别时更加有效地启用有限的计算资源，并且能够更高效地识别手势。我们在LD-ConGR长距离数据集上展示了我们的方法的性能，其与前一个状态的方法在识别精度和计算效率上都表现出色。
</details></li>
</ul>
<hr>
<h2 id="1st-Place-Solution-for-CVPR2023-BURST-Long-Tail-and-Open-World-Challenges"><a href="#1st-Place-Solution-for-CVPR2023-BURST-Long-Tail-and-Open-World-Challenges" class="headerlink" title="1st Place Solution for CVPR2023 BURST Long Tail and Open World Challenges"></a>1st Place Solution for CVPR2023 BURST Long Tail and Open World Challenges</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04598">http://arxiv.org/abs/2308.04598</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaer Huang<br>for:* This paper focuses on video instance segmentation (VIS) in long-tailed and open-world scenarios, where traditional VIS methods are limited to a small number of common classes but real-world applications require detection and tracking of rare and never-before-seen objects.methods:* The proposed method, LeTracker, uses a combination of segmentation and CEM on LVISv0.5 + COCO dataset for training the detector, and instance appearance similarity head on TAO dataset.results:* LeTracker achieves 14.9 HOTAall in the BURST test set, ranking 1st in the benchmark, and 61.4 OWTAall in the open-world challenges, ranking 1st in the benchmark.<details>
<summary>Abstract</summary>
Currently, Video Instance Segmentation (VIS) aims at segmenting and categorizing objects in videos from a closed set of training categories that contain only a few dozen of categories, lacking the ability to handle diverse objects in real-world videos. As TAO and BURST datasets release, we have the opportunity to research VIS in long-tailed and open-world scenarios. Traditional VIS methods are evaluated on benchmarks limited to a small number of common classes, But practical applications require trackers that go beyond these common classes, detecting and tracking rare and even never-before-seen objects. Inspired by the latest MOT paper for the long tail task (Tracking Every Thing in the Wild, Siyuan Li et), for the BURST long tail challenge, we train our model on a combination of LVISv0.5 and the COCO dataset using repeat factor sampling. First, train the detector with segmentation and CEM on LVISv0.5 + COCO dataset. And then, train the instance appearance similarity head on the TAO dataset. at last, our method (LeTracker) gets 14.9 HOTAall in the BURST test set, ranking 1st in the benchmark. for the open-world challenges, we only use 64 classes (Intersection classes of BURST Train subset and COCO dataset, without LVIS dataset) annotations data training, and testing on BURST test set data and get 61.4 OWTAall, ranking 1st in the benchmark. Our code will be released to facilitate future research.
</details>
<details>
<summary>摘要</summary>
当前，视频实例分 segmentation（VIS）目标是将视频中的对象分类和分割，但现有的VIS方法只能处理固定的训练类别，缺乏对实际世界视频中的多样化对象的能力。随着TAO和BURST数据集的发布，我们有机会进行VIS在长尾和开放世界场景下的研究。传统的VIS方法通常被评估在限定的一些常见类别上，但实际应用需要超出这些常见类别，检测和跟踪罕见和从未seen的对象。 drawing inspiration from the latest MOT paper on the long tail task（Tracking Every Thing in the Wild，Siyuan Li et al），我们在BURST长尾挑战中使用重复因子抽样训练我们的模型。首先，我们使用LVISv0.5和COCO数据集训练探测器的 segmentation和CEM。然后，我们在TAO数据集上训练实例外观相似头。最后，我们的方法（LeTracker）在BURST测试集上获得14.9 HOTAall，排名第一名。在开放世界挑战中，我们只使用64个类别（BURST训练集和COCO数据集的交集类别，不包括LVIS数据集）的注释数据进行训练，并在BURST测试集上进行测试，得到61.4 OWTAall，排名第一名。我们将代码发布，以便未来的研究。
</details></li>
</ul>
<hr>
<h2 id="Semi-Supervised-Semantic-Segmentation-of-Cell-Nuclei-via-Diffusion-based-Large-Scale-Pre-Training-and-Collaborative-Learning"><a href="#Semi-Supervised-Semantic-Segmentation-of-Cell-Nuclei-via-Diffusion-based-Large-Scale-Pre-Training-and-Collaborative-Learning" class="headerlink" title="Semi-Supervised Semantic Segmentation of Cell Nuclei via Diffusion-based Large-Scale Pre-Training and Collaborative Learning"></a>Semi-Supervised Semantic Segmentation of Cell Nuclei via Diffusion-based Large-Scale Pre-Training and Collaborative Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04578">http://arxiv.org/abs/2308.04578</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhuchen Shao, Sourya Sengupta, Hua Li, Mark A. Anastasio</li>
<li>for: 这篇论文的目的是提出一个新的不监督预训学习框架 для microscopic 图像中细胞核lei的自动化 semantic segmentation, 以便于疾病诊断和组织微环境分析。</li>
<li>methods: 这个框架包括三个主要部分：一、使用一个大规模的无标注数据集进行传播模型的预训; two、使用一个 transformer 型的整合器来将传播模型中的内部特征聚合; three、实现一个协力学习框架，让传播模型和一个监督式分类模型进行共同学习。</li>
<li>results: 在四个公开的数据集上进行了实验，证明了我们的框架可以与竞争性的半监督数据学习方法相比，并且在监督式分类模型的基础上进行了进一步的改进。<details>
<summary>Abstract</summary>
Automated semantic segmentation of cell nuclei in microscopic images is crucial for disease diagnosis and tissue microenvironment analysis. Nonetheless, this task presents challenges due to the complexity and heterogeneity of cells. While supervised deep learning methods are promising, they necessitate large annotated datasets that are time-consuming and error-prone to acquire. Semi-supervised approaches could provide feasible alternatives to this issue. However, the limited annotated data may lead to subpar performance of semi-supervised methods, regardless of the abundance of unlabeled data. In this paper, we introduce a novel unsupervised pre-training-based semi-supervised framework for cell-nuclei segmentation. Our framework is comprised of three main components. Firstly, we pretrain a diffusion model on a large-scale unlabeled dataset. The diffusion model's explicit modeling capability facilitates the learning of semantic feature representation from the unlabeled data. Secondly, we achieve semantic feature aggregation using a transformer-based decoder, where the pretrained diffusion model acts as the feature extractor, enabling us to fully utilize the small amount of labeled data. Finally, we implement a collaborative learning framework between the diffusion-based segmentation model and a supervised segmentation model to further enhance segmentation performance. Experiments were conducted on four publicly available datasets to demonstrate significant improvements compared to competitive semi-supervised segmentation methods and supervised baselines. A series of out-of-distribution tests further confirmed the generality of our framework. Furthermore, thorough ablation experiments and visual analysis confirmed the superiority of our proposed method.
</details>
<details>
<summary>摘要</summary>
自动化的细胞核 segmentation 在微scopic 图像中是致命的 для疾病诊断和组织微environment 分析。然而，这个任务存在复杂性和多样性的细胞问题。 Although supervised deep learning methods are promising, they require large annotated datasets that are time-consuming and error-prone to acquire. Semi-supervised approaches could provide feasible alternatives to this issue. However, the limited annotated data may lead to subpar performance of semi-supervised methods, regardless of the abundance of unlabeled data.In this paper, we introduce a novel unsupervised pre-training-based semi-supervised framework for cell-nuclei segmentation. Our framework consists of three main components. First, we pretrain a diffusion model on a large-scale unlabeled dataset. The diffusion model's explicit modeling capability facilitates the learning of semantic feature representation from the unlabeled data. Second, we achieve semantic feature aggregation using a transformer-based decoder, where the pretrained diffusion model acts as the feature extractor, enabling us to fully utilize the small amount of labeled data. Finally, we implement a collaborative learning framework between the diffusion-based segmentation model and a supervised segmentation model to further enhance segmentation performance. Experiments were conducted on four publicly available datasets to demonstrate significant improvements compared to competitive semi-supervised segmentation methods and supervised baselines. A series of out-of-distribution tests further confirmed the generality of our framework. Furthermore, thorough ablation experiments and visual analysis confirmed the superiority of our proposed method.
</details></li>
</ul>
<hr>
<h2 id="Towards-Automatic-Scoring-of-Spinal-X-ray-for-Ankylosing-Spondylitis"><a href="#Towards-Automatic-Scoring-of-Spinal-X-ray-for-Ankylosing-Spondylitis" class="headerlink" title="Towards Automatic Scoring of Spinal X-ray for Ankylosing Spondylitis"></a>Towards Automatic Scoring of Spinal X-ray for Ankylosing Spondylitis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05123">http://arxiv.org/abs/2308.05123</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanhan Mo, Yao Chen, Aimee Readie, Gregory Ligozio, Thibaud Coroller, Bartłomiej W. Papież</li>
<li>for: 这个研究旨在开发一个自动评分pipeline，以便从骨盘X射线成像中自动预测 modified Stoke Ankylosing Spondylitis Spinal Score (mSASSS) 的分数。</li>
<li>methods: 这个pipeline使用了我们先前开发的 VU 抽出pipeline (VertXNet) 来生成 VU，然后使用这些 VU 作为输入，预测 mSASSS 分数。</li>
<li>results: 我们的结果显示，这个pipeline可以在有限量和不均匀的数据下预测每个 VU 的 mSASSS 分数。总体而言，它可以在两个试验数据集上 achieve 平均准确率为 0.56 和 0.51  для 4 个不同的 mSASSS 分数 (即分数为 0、1、2、3)。<details>
<summary>Abstract</summary>
Manually grading structural changes with the modified Stoke Ankylosing Spondylitis Spinal Score (mSASSS) on spinal X-ray imaging is costly and time-consuming due to bone shape complexity and image quality variations. In this study, we address this challenge by prototyping a 2-step auto-grading pipeline, called VertXGradeNet, to automatically predict mSASSS scores for the cervical and lumbar vertebral units (VUs) in X-ray spinal imaging. The VertXGradeNet utilizes VUs generated by our previously developed VU extraction pipeline (VertXNet) as input and predicts mSASSS based on those VUs. VertXGradeNet was evaluated on an in-house dataset of lateral cervical and lumbar X-ray images for axial spondylarthritis patients. Our results show that VertXGradeNet can predict the mSASSS score for each VU when the data is limited in quantity and imbalanced. Overall, it can achieve a balanced accuracy of 0.56 and 0.51 for 4 different mSASSS scores (i.e., a score of 0, 1, 2, 3) on two test datasets. The accuracy of the presented method shows the potential to streamline the spinal radiograph readings and therefore reduce the cost of future clinical trials.
</details>
<details>
<summary>摘要</summary>
人工评估结构变化使用修改Stoke Ankylosing Spondylitis Spinal Score（mSASSS）在脊椎X射线成像中是成本高和时间耗费大的，这是因为骨形态复杂和成像质量变化。在这项研究中，我们解决这个挑战，推出了一个两步自动评估管道，称为VertXGradeNet，可以自动预测脊椎X射线成像中mSASSS分数。VertXGradeNet使用我们之前开发的VU提取管道（VertXNet）生成的VU作为输入，并根据这些VU预测mSASSS分数。我们在医学实验室内的一个后退性cervical和肠脊椎X射线成像数据集上评估了VertXGradeNet。结果表明，VertXGradeNet可以在数据量有限、不均衡的情况下预测每个VU的mSASSS分数。总的来说，它可以在两个测试数据集上实现平衡性的准确率0.56和0.51，对四个不同的mSASSS分数（即分数为0、1、2、3）进行预测。提出的方法的准确率表明了将来的脊椎X射线成像读取可能会更加流畅，从而降低未来临床试验的成本。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/09/eess.IV_2023_08_09/" data-id="clogyj92q012y7cra18qw1isa" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/08/cs.SD_2023_08_08/" class="article-date">
  <time datetime="2023-08-08T15:00:00.000Z" itemprop="datePublished">2023-08-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/08/cs.SD_2023_08_08/">cs.SD - 2023-08-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Towards-an-AI-to-Win-Ghana’s-National-Science-and-Maths-Quiz"><a href="#Towards-an-AI-to-Win-Ghana’s-National-Science-and-Maths-Quiz" class="headerlink" title="Towards an AI to Win Ghana’s National Science and Maths Quiz"></a>Towards an AI to Win Ghana’s National Science and Maths Quiz</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04333">http://arxiv.org/abs/2308.04333</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nsmq-ai/nsmqai">https://github.com/nsmq-ai/nsmqai</a></li>
<li>paper_authors: George Boateng, Jonathan Abrefah Mensah, Kevin Takyi Yeboah, William Edor, Andrew Kojo Mensah-Onumah, Naafi Dasana Ibrahim, Nana Sam Yeboah</li>
<li>for: The paper is written to explore the possibility of using AI to compete in Ghana’s National Science and Maths Quiz (NSMQ) and to describe the progress made so far in the NSMQ AI project.</li>
<li>methods: The paper uses open-source AI technology to build an AI system that can compete in the NSMQ, with a focus on speech-to-text, text-to-speech, question-answering, and human-computer interaction.</li>
<li>results: The paper describes the progress made thus far in the NSMQ AI project, including the development of an AI system that can compete in the NSMQ and the potential real-world impact of such a system on education in Africa.<details>
<summary>Abstract</summary>
Can an AI win Ghana's National Science and Maths Quiz (NSMQ)? That is the question we seek to answer in the NSMQ AI project, an open-source project that is building AI to compete live in the NSMQ and win. The NSMQ is an annual live science and mathematics competition for senior secondary school students in Ghana in which 3 teams of 2 students compete by answering questions across biology, chemistry, physics, and math in 5 rounds over 5 progressive stages until a winning team is crowned for that year. The NSMQ is an exciting live quiz competition with interesting technical challenges across speech-to-text, text-to-speech, question-answering, and human-computer interaction. In this ongoing work that began in January 2023, we give an overview of the project, describe each of the teams, progress made thus far, and the next steps toward our planned launch and debut of the AI in October for NSMQ 2023. An AI that conquers this grand challenge can have real-world impact on education such as enabling millions of students across Africa to have one-on-one learning support from this AI.
</details>
<details>
<summary>摘要</summary>
可以AI赢得加纳国家科学数学竞赛（NSMQ）呢？这是我们想要回答的问题，我们在NSMQ AI项目中进行开源项目，旨在使AI在NSMQ中赢得比赛。NSMQ是每年举行的live科学数学竞赛，参与者是加纳高中二年级学生，共有3支队伍，每支队伍有2名学生，通过Answering questions across biology, chemistry, physics, and math in 5 rounds over 5 progressive stages until a winning team is crowned for that year。NSMQ是一个有趣的live竞赛，技术挑战包括speech-to-text、text-to-speech、问题回答和人机交互。在这项工作于2023年1月开始的项目中，我们将提供项目概述、团队描述、已经进展和下一步的计划，以便在10月份的NSMQ 2023上发布AI。一旦AI成功解决这个大型挑战，可能会对教育产生实际影响，如提供非洲数百万学生一对一的学习支持。
</details></li>
</ul>
<hr>
<h2 id="Auditory-Attention-Decoding-with-Task-Related-Multi-View-Contrastive-Learning"><a href="#Auditory-Attention-Decoding-with-Task-Related-Multi-View-Contrastive-Learning" class="headerlink" title="Auditory Attention Decoding with Task-Related Multi-View Contrastive Learning"></a>Auditory Attention Decoding with Task-Related Multi-View Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04244">http://arxiv.org/abs/2308.04244</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiaoyu Chen, Changde Du, Qiongyi Zhou, Huiguang He</li>
<li>for: 这 paper 是为了解决 auditory attention 问题，即如何在多个视角下解码听力注意力。</li>
<li>methods: 这 paper 使用了 multi-view VAE 和 task-related multi-view contrastive (TMC) 学习来解码听力注意力。</li>
<li>results: 研究人员通过对 two 个 popular AAD 数据集进行测试，发现了我们的方法的优越性，并与现有的 state-of-the-art 方法进行比较。<details>
<summary>Abstract</summary>
The human brain can easily focus on one speaker and suppress others in scenarios such as a cocktail party. Recently, researchers found that auditory attention can be decoded from the electroencephalogram (EEG) data. However, most existing deep learning methods are difficult to use prior knowledge of different views (that is attended speech and EEG are task-related views) and extract an unsatisfactory representation. Inspired by Broadbent's filter model, we decode auditory attention in a multi-view paradigm and extract the most relevant and important information utilizing the missing view. Specifically, we propose an auditory attention decoding (AAD) method based on multi-view VAE with task-related multi-view contrastive (TMC) learning. Employing TMC learning in multi-view VAE can utilize the missing view to accumulate prior knowledge of different views into the fusion of representation, and extract the approximate task-related representation. We examine our method on two popular AAD datasets, and demonstrate the superiority of our method by comparing it to the state-of-the-art method.
</details>
<details>
<summary>摘要</summary>
人脑可以轻松地关注一个说话者并压抑其他说话者在cocktail party类场景中。现在，研究人员发现了基于电enzephalogram（EEG）数据的听力注意力可以被解码。然而，大多数现有的深度学习方法难以使用不同视图（即注意力和EEG数据是任务相关的视图）的先前知识，并提取不满足的表示。以布鲁门特 filters 模型为 inspirations，我们在多视图 paradigm 中解码听力注意力，并使用缺失的视图来汇集不同视图中的先前知识，并提取任务相关的表示。我们提出了基于多视图VAE的听力注意力解码方法（AAD），并使用任务相关的多视图异构学习（TMC）来学习。通过TMC学习，我们可以在多视图VAE中汇集不同视图中的先前知识，并提取任务相关的表示。我们在两个流行的AAD数据集上进行了实验，并证明了我们的方法的优越性，比较于状态的艺术方法。
</details></li>
</ul>
<hr>
<h2 id="Evil-Operation-Breaking-Speaker-Recognition-with-PaddingBack"><a href="#Evil-Operation-Breaking-Speaker-Recognition-with-PaddingBack" class="headerlink" title="Evil Operation: Breaking Speaker Recognition with PaddingBack"></a>Evil Operation: Breaking Speaker Recognition with PaddingBack</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04179">http://arxiv.org/abs/2308.04179</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhe Ye, Diqun Yan, Li Dong, Kailai Shen</li>
<li>For: The paper aims to propose a novel backdoor attack method that can bypass speaker recognition systems and remain undetectable to human ears.* Methods: The proposed method, called PaddingBack, exploits the widely used speech signal operation of padding to make poisoned samples indistinguishable from clean ones.* Results: The experimental results show that PaddingBack achieves a high attack success rate while maintaining a high rate of benign accuracy, and is able to resist defense methods while maintaining its stealthiness against human perception.Here’s the full text in Simplified Chinese:* For: 本研究提出的目的是提出一种可以绕过说话识别系统的背门附件攻击方法，并且能够避免人类听觉中的异常感。* Methods: 该方法称为PaddingBack，利用了广泛使用的语音信号操作padding，以制作恶意样本与净样本无法分辨。* Results: 实验结果显示，PaddingBack可以达到高度的攻击成功率，同时保持高度的净样本准确率，并且能够抵抗防御方法，同时保持人类听觉中的潜藏性。<details>
<summary>Abstract</summary>
Machine Learning as a Service (MLaaS) has gained popularity due to advancements in machine learning. However, untrusted third-party platforms have raised concerns about AI security, particularly in backdoor attacks. Recent research has shown that speech backdoors can utilize transformations as triggers, similar to image backdoors. However, human ears easily detect these transformations, leading to suspicion. In this paper, we introduce PaddingBack, an inaudible backdoor attack that utilizes malicious operations to make poisoned samples indistinguishable from clean ones. Instead of using external perturbations as triggers, we exploit the widely used speech signal operation, padding, to break speaker recognition systems. Our experimental results demonstrate the effectiveness of the proposed approach, achieving a significantly high attack success rate while maintaining a high rate of benign accuracy. Furthermore, PaddingBack demonstrates the ability to resist defense methods while maintaining its stealthiness against human perception. The results of the stealthiness experiment have been made available at https://nbufabio25.github.io/paddingback/.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="MSAC-Multiple-Speech-Attribute-Control-Method-for-Speech-Emotion-Recognition"><a href="#MSAC-Multiple-Speech-Attribute-Control-Method-for-Speech-Emotion-Recognition" class="headerlink" title="MSAC: Multiple Speech Attribute Control Method for Speech Emotion Recognition"></a>MSAC: Multiple Speech Attribute Control Method for Speech Emotion Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04025">http://arxiv.org/abs/2308.04025</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yu Pan</li>
<li>for: 本研究旨在探讨语音情感识别（SER）方法的可靠性，并研究如何从语音特征分布角度模型语音情感。</li>
<li>methods: 本研究提出了一种基于Convolutional Neural Networks（CNN）的SER模型，采用添加margin软max损失函数以提高类别之间的距离，从而提高分类的准确性。此外，还提出了一种多种语音特征控制方法（MSAC），可以控制语音特征，使模型更加敏感于情感相关特征。</li>
<li>results: 对于单个 corpora 和跨 corpora SER 场景，我们的提议的 SER 工作流程经过了广泛的实验，并 consistently 超过基准值，包括认知、泛化和可靠性性能。单个 corpora SER 场景中，我们的 SER 工作流程达到了72.97%的 WAR 和 71.76%的 UAR 在 IEMOCAP  corpora 上。<details>
<summary>Abstract</summary>
Despite significant progress, speech emotion recognition (SER) remains challenging due to inherent complexity and ambiguity of the emotion attribute, particularly in wild world. Whereas current studies primarily focus on recognition and generalization capabilities, this work pioneers an exploration into the reliability of SER methods and investigates how to model the speech emotion from the aspect of data distribution across various speech attributes. Specifically, we first build a novel CNN-based SER model which adopts additive margin softmax loss to expand the distance between features of different classes, thereby enhancing their discrimination. Second, a novel multiple speech attribute control method MSAC is proposed to explicitly control speech attributes, enabling the model to be less affected by emotion-agnostic attributes and capture more fine-grained emotion-related features. Third, we make a first attempt to test and analyze the reliability of the proposed SER workflow using the out-of-distribution detection method. Extensive experiments on both single and cross-corpus SER scenarios show that our proposed unified SER workflow consistently outperforms the baseline in terms of recognition, generalization, and reliability performance. Besides, in single-corpus SER, the proposed SER workflow achieves superior recognition results with a WAR of 72.97\% and a UAR of 71.76\% on the IEMOCAP corpus.
</details>
<details>
<summary>摘要</summary>
尽管已经取得了 significative 进步，speech emotion recognition（SER）仍然是一项复杂和不确定的任务，尤其在野外环境中。现有研究主要关注recognition和泛化能力，而这项工作则尝试了 SER 方法的可靠性的探索，并 investigate 如何从数据分布角度模型 speech emotion。 Specifically, we first build a novel CNN-based SER model which adopts additive margin softmax loss to expand the distance between features of different classes, thereby enhancing their discrimination. Second, a novel multiple speech attribute control method MSAC is proposed to explicitly control speech attributes, enabling the model to be less affected by emotion-agnostic attributes and capture more fine-grained emotion-related features. Third, we make a first attempt to test and analyze the reliability of the proposed SER workflow using the out-of-distribution detection method. Extensive experiments on both single and cross-corpus SER scenarios show that our proposed unified SER workflow consistently outperforms the baseline in terms of recognition, generalization, and reliability performance. Besides, in single-corpus SER, the proposed SER workflow achieves superior recognition results with a WAR of 72.97% and a UAR of 71.76% on the IEMOCAP corpus.
</details></li>
</ul>
<hr>
<h2 id="Target-Speech-Extraction-with-Conditional-Diffusion-Model"><a href="#Target-Speech-Extraction-with-Conditional-Diffusion-Model" class="headerlink" title="Target Speech Extraction with Conditional Diffusion Model"></a>Target Speech Extraction with Conditional Diffusion Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03987">http://arxiv.org/abs/2308.03987</a></li>
<li>repo_url: None</li>
<li>paper_authors: Naoyuki Kamo, Marc Delcroix, Tomohiro Nakatani</li>
<li>for:  targets speech extraction (TSE) in a mixture of multi-talkers</li>
<li>methods:  uses a conditional diffusion model conditioned on a clue identifying the target speaker, and ensemble inference to reduce potential extraction errors</li>
<li>results:  outperforms a comparable TSE system trained discriminatively in experiments on Libri2mix corpus<details>
<summary>Abstract</summary>
Diffusion model-based speech enhancement has received increased attention since it can generate very natural enhanced signals and generalizes well to unseen conditions. Diffusion models have been explored for several sub-tasks of speech enhancement, such as speech denoising, dereverberation, and source separation. In this paper, we investigate their use for target speech extraction (TSE), which consists of estimating the clean speech signal of a target speaker in a mixture of multi-talkers. TSE is realized by conditioning the extraction process on a clue identifying the target speaker. We show we can realize TSE using a conditional diffusion model conditioned on the clue. Besides, we introduce ensemble inference to reduce potential extraction errors caused by the diffusion process. In experiments on Libri2mix corpus, we show that the proposed diffusion model-based TSE combined with ensemble inference outperforms a comparable TSE system trained discriminatively.
</details>
<details>
<summary>摘要</summary>
听说模型基于扩散模型的speech增强技术在最近几年来得到了更多的关注，因为它可以生成非常自然的增强信号，并且可以在未见过的条件下进行泛化。扩散模型在多个子任务中被探索，如speech噪声除去、泛化声学环境和音源分离。在这篇论文中，我们研究了它们在target speech extraction（TSE）中的使用，TSE是一种估计混合多个说话人的干扰者的清晰speech信号的过程。我们表明可以通过对 clue（指定target speaker）进行条件的扩散模型来实现TSE。此外，我们还引入了集成推理来降低扩散过程中的潜在出错。在Libri2mix数据集上进行了实验，我们发现提出的扩散模型基于TSE，并且集成推理可以与一个相对的TSE系统所得到的性能进行比较。
</details></li>
</ul>
<hr>
<h2 id="Universal-Automatic-Phonetic-Transcription-into-the-International-Phonetic-Alphabet"><a href="#Universal-Automatic-Phonetic-Transcription-into-the-International-Phonetic-Alphabet" class="headerlink" title="Universal Automatic Phonetic Transcription into the International Phonetic Alphabet"></a>Universal Automatic Phonetic Transcription into the International Phonetic Alphabet</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03917">http://arxiv.org/abs/2308.03917</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ctaguchi/multipa">https://github.com/ctaguchi/multipa</a></li>
<li>paper_authors: Chihiro Taguchi, Yusuke Sakai, Parisa Haghani, David Chiang</li>
<li>for: 这个论文旨在提供一种可以转化任何语言的语音到国际音律字母（IPA）的状态对模型。</li>
<li>methods: 该模型基于wav2vec 2.0，并通过 semi-自动地对CommonVoice 11.0中的七种语言的语音进行了训练，以便预测IPA。</li>
<li>results: 我们的模型可以达到与人工标注师相当的质量水平，并且与之前的最佳语音到IPA模型（Wav2Vec2Phoneme）相比，我们的模型在训练数据量相对较少的情况下可以达到类似或更好的结果。<details>
<summary>Abstract</summary>
This paper presents a state-of-the-art model for transcribing speech in any language into the International Phonetic Alphabet (IPA). Transcription of spoken languages into IPA is an essential yet time-consuming process in language documentation, and even partially automating this process has the potential to drastically speed up the documentation of endangered languages. Like the previous best speech-to-IPA model (Wav2Vec2Phoneme), our model is based on wav2vec 2.0 and is fine-tuned to predict IPA from audio input. We use training data from seven languages from CommonVoice 11.0, transcribed into IPA semi-automatically. Although this training dataset is much smaller than Wav2Vec2Phoneme's, its higher quality lets our model achieve comparable or better results. Furthermore, we show that the quality of our universal speech-to-IPA models is close to that of human annotators.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了一种现代模型，用于将任何语言的 spoken language 转录为国际音声字母（IPA）。将语言记录转录为 IPA 是一项重要但是时间占用很大的任务，即使只是部分自动化这个过程，也有很大的潜在速度提升语言记录的批处。与之前的最佳音频-to-IPA 模型（Wav2Vec2Phoneme）一样，我们的模型基于 wav2vec 2.0，并在音频输入上进行了微调，以预测 IPA。我们使用了 CommonVoice 11.0 中的七种语言的训练数据，并将其 semi-automatically 转录为 IPA。虽然我们的训练集规模较小，但它的质量更高，使我们的模型在获得相似或更好的结果。此外，我们还证明了我们的通用音频-to-IPA 模型的质量与人工注释员很相似。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/08/cs.SD_2023_08_08/" data-id="clogyj90a00t17craglj30uk8" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_08_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/08/eess.AS_2023_08_08/" class="article-date">
  <time datetime="2023-08-08T14:00:00.000Z" itemprop="datePublished">2023-08-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/08/eess.AS_2023_08_08/">eess.AS - 2023-08-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Investigating-Speaker-Embedding-Disentanglement-on-Natural-Read-Speech"><a href="#Investigating-Speaker-Embedding-Disentanglement-on-Natural-Read-Speech" class="headerlink" title="Investigating Speaker Embedding Disentanglement on Natural Read Speech"></a>Investigating Speaker Embedding Disentanglement on Natural Read Speech</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04225">http://arxiv.org/abs/2308.04225</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Kuhlmann, Adrian Meise, Fritz Seebauer, Petra Wagner, Reinhold Haeb-Umbach</li>
<li>for: 这个论文的目的是研究语音表示的分解，以提高数据驱动模型的普适性、解释性和公正性。</li>
<li>methods: 该论文使用了标准的分解目标函数来训练语音表示，并对比了这些表示的分解程度。</li>
<li>results: 研究发现，使用标准的分解目标函数可以限制语音表示的分解程度，但可以通过一定程度的改进来提高分解效果。<details>
<summary>Abstract</summary>
Disentanglement is the task of learning representations that identify and separate factors that explain the variation observed in data. Disentangled representations are useful to increase the generalizability, explainability, and fairness of data-driven models. Only little is known about how well such disentanglement works for speech representations. A major challenge when tackling disentanglement for speech representations are the unknown generative factors underlying the speech signal. In this work, we investigate to what degree speech representations encoding speaker identity can be disentangled. To quantify disentanglement, we identify acoustic features that are highly speaker-variant and can serve as proxies for the factors of variation underlying speech. We find that disentanglement of the speaker embedding is limited when trained with standard objectives promoting disentanglement but can be improved over vanilla representation learning to some extent.
</details>
<details>
<summary>摘要</summary>
<SYS><translation_language_model>分化是学习表示法，以分解数据中观察到的变化的因素为目的。分化的表示法有助于提高数据驱动模型的普遍性、解释性和公平性。对于speech表示法，尚不了解分化是否有效。在这种工作中，我们研究了speech表示法中的发音者标识可以被分化的程度。为量分化，我们确定了一些高度发音者特定的音频特征，可以作为变化的因素下的 фактор代表。我们发现，使用标准的分化目标可以有限地分化发音者表示，但可以通过一些程度上的表示学习来提高分化。</translation_language_model></SYS>Here's the translation in Traditional Chinese as well:<SYS><translation_language_model>分化是学习表示法，以分解数据中观察到的变化的因素为目的。分化的表示法有助于提高数据驱动模型的普遍性、解释性和公平性。对于speech表示法，还不了解分化是否有效。在这种工作中，我们研究了speech表示法中的发音者标识可以被分化的程度。为量分化，我们确定了一些高度发音者特定的音频特征，可以作为变化的因素下的 фактор代表。我们发现，使用标准的分化目标可以有限地分化发音者表示，但可以通过一些程度上的表示学习来提高分化。</translation_language_model></SYS>
</details></li>
</ul>
<hr>
<h2 id="EPCFormer-Expression-Prompt-Collaboration-Transformer-for-Universal-Referring-Video-Object-Segmentation"><a href="#EPCFormer-Expression-Prompt-Collaboration-Transformer-for-Universal-Referring-Video-Object-Segmentation" class="headerlink" title="EPCFormer: Expression Prompt Collaboration Transformer for Universal Referring Video Object Segmentation"></a>EPCFormer: Expression Prompt Collaboration Transformer for Universal Referring Video Object Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04162">http://arxiv.org/abs/2308.04162</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lab206/epcformer">https://github.com/lab206/epcformer</a></li>
<li>paper_authors: Jiajun Chen, Jiacheng Lin, Zhiqiang Xiao, Haolong Fu, Ke Nai, Kailun Yang, Zhiyong Li</li>
<li>for: 这 paper 是为了解决 audio-guided video object segmentation (A-VOS) 和 referring video object segmentation (R-VOS) 等两个高度相关的任务。</li>
<li>methods: 这 paper 使用了一种 universal architecture called Expression Prompt Collaboration Transformer (EPCFormer)，并提出了一种 Expression Alignment (EA) 机制和一种 Expression-Visual Attention (EVA) 机制来解决模式表示问题。</li>
<li>results: 实验结果表明，EPCFormer 可以在 A-VOS 和 R-VOS 两个任务上达到州际级Result。此外，EPCFormer 可以快速转移知识 между两个任务，从而提高视频对象 segmentation 的精度。<details>
<summary>Abstract</summary>
Audio-guided Video Object Segmentation (A-VOS) and Referring Video Object Segmentation (R-VOS) are two highly-related tasks, which both aim to segment specific objects from video sequences according to user-provided expression prompts. However, due to the challenges in modeling representations for different modalities, contemporary methods struggle to strike a balance between interaction flexibility and high-precision localization and segmentation. In this paper, we address this problem from two perspectives: the alignment representation of audio and text and the deep interaction among audio, text, and visual features. First, we propose a universal architecture, the Expression Prompt Collaboration Transformer, herein EPCFormer. Next, we propose an Expression Alignment (EA) mechanism for audio and text expressions. By introducing contrastive learning for audio and text expressions, the proposed EPCFormer realizes comprehension of the semantic equivalence between audio and text expressions denoting the same objects. Then, to facilitate deep interactions among audio, text, and video features, we introduce an Expression-Visual Attention (EVA) mechanism. The knowledge of video object segmentation in terms of the expression prompts can seamlessly transfer between the two tasks by deeply exploring complementary cues between text and audio. Experiments on well-recognized benchmarks demonstrate that our universal EPCFormer attains state-of-the-art results on both tasks. The source code of EPCFormer will be made publicly available at https://github.com/lab206/EPCFormer.
</details>
<details>
<summary>摘要</summary>
audio-guided视频对象 segmentation (A-VOS) 和 referring视频对象 segmentation (R-VOS) 是两个非常相关的任务，它们都是根据用户提供的表达提示从视频序列中提取特定对象的。然而，由于不同媒体表示的模型化问题，当前方法很难协调用用户提供的表达提示和高精度的地方化分割。在这篇论文中，我们解决这个问题从两个方面：表达提示的对齐表示和听力和文本特征之间的深度交互。首先，我们提出了一种通用架构，即表达 prompt collaboration transformer（EPCFormer）。然后，我们提出了一种表达对齐（EA）机制，用于对听力和文本表达进行对齐。通过对听力和文本表达进行对比学习，我们的提出的EPCFormer实现了对听力和文本表达的semantic equivalence的认知。然后，为了促进听力、文本和视频特征之间的深度交互，我们引入了表达-视频注意力（EVA）机制。通过深入探索听力、文本和视频特征之间的相互补做，我们的EPCFormer可以很好地传递知识 между两个任务。实验结果表明，我们的通用EPCFormer在两个任务上达到了现有最佳结果。代码将在https://github.com/lab206/EPCFormer上公开。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/08/eess.AS_2023_08_08/" data-id="clogyj91l00yu7crahzv94f6u" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_08" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/08/cs.CV_2023_08_08/" class="article-date">
  <time datetime="2023-08-08T13:00:00.000Z" itemprop="datePublished">2023-08-08</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/08/cs.CV_2023_08_08/">cs.CV - 2023-08-08</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="3D-VisTA-Pre-trained-Transformer-for-3D-Vision-and-Text-Alignment"><a href="#3D-VisTA-Pre-trained-Transformer-for-3D-Vision-and-Text-Alignment" class="headerlink" title="3D-VisTA: Pre-trained Transformer for 3D Vision and Text Alignment"></a>3D-VisTA: Pre-trained Transformer for 3D Vision and Text Alignment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04352">http://arxiv.org/abs/2308.04352</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/3d-vista/3D-VisTA">https://github.com/3d-vista/3D-VisTA</a></li>
<li>paper_authors: Ziyu Zhu, Xiaojian Ma, Yixin Chen, Zhidong Deng, Siyuan Huang, Qing Li</li>
<li>for: 3D vision-language grounding (3D-VL) tasks, such as visual grounding, dense captioning, question answering, and situated reasoning.</li>
<li>methods: Uses a pre-trained Transformer for 3D vision and text alignment, with self-attention layers for single-modal modeling and multi-modal fusion.</li>
<li>results: Achieves state-of-the-art results on various 3D-VL tasks, with superior data efficiency and strong performance even with limited annotations during fine-tuning.Here’s the simplified Chinese text:</li>
<li>for: 3D视力语言固定（3D-VL）任务，如视图固定、密集描述、问答和位置理解。</li>
<li>methods: 使用预训练的 transformer  для 3D视力和文本对齐，通过自我注意层实现单模态模型和多模态融合。</li>
<li>results: 在多种 3D-VL 任务上取得了状态之一的结果，并且在限制缺少标注时的练习 fine-tuning 中表现出色。<details>
<summary>Abstract</summary>
3D vision-language grounding (3D-VL) is an emerging field that aims to connect the 3D physical world with natural language, which is crucial for achieving embodied intelligence. Current 3D-VL models rely heavily on sophisticated modules, auxiliary losses, and optimization tricks, which calls for a simple and unified model. In this paper, we propose 3D-VisTA, a pre-trained Transformer for 3D Vision and Text Alignment that can be easily adapted to various downstream tasks. 3D-VisTA simply utilizes self-attention layers for both single-modal modeling and multi-modal fusion without any sophisticated task-specific design. To further enhance its performance on 3D-VL tasks, we construct ScanScribe, the first large-scale 3D scene-text pairs dataset for 3D-VL pre-training. ScanScribe contains 2,995 RGB-D scans for 1,185 unique indoor scenes originating from ScanNet and 3R-Scan datasets, along with paired 278K scene descriptions generated from existing 3D-VL tasks, templates, and GPT-3. 3D-VisTA is pre-trained on ScanScribe via masked language/object modeling and scene-text matching. It achieves state-of-the-art results on various 3D-VL tasks, ranging from visual grounding and dense captioning to question answering and situated reasoning. Moreover, 3D-VisTA demonstrates superior data efficiency, obtaining strong performance even with limited annotations during downstream task fine-tuning.
</details>
<details>
<summary>摘要</summary>
三维视力语言固定（3D-VL）是一个emerging领域，旨在将三维物理世界与自然语言相连接，这对实体智能是非常重要。现有3D-VL模型都依赖于复杂的模块、辅助损失和优化技巧，这зыва�种简单的和一致的模型。在这篇论文中，我们提出了3D-VisTA，一个预训练的Transformer用于三维视力和文本对齐。3D-VisTA使用自注意层来模型单Modal和多Modal的混合，不需任何任务特定的复杂设计。为了进一步提高3D-VL任务的表现，我们构建了ScanScribe，这是第一个大规模的3D场景文本对 dataset，包括2995个RGB-D扫描和1185个唯一的室内场景，来自ScanNet和3R-Scan dataset，以及278K个场景描述，这些描述来自现有的3D-VL任务、模板和GPT-3。3D-VisTA在ScanScribe上预训练后，可以通过偏挥语言/物体模型和场景文本匹配来进行Masked Language/Object Modeling和Scene-Text Matching。它在多种3D-VL任务上达到了状态前的Result，从visual grounding和精密描述到问题回答和位置理解。此外，3D-VisTA还表现出了优秀的数据效率，能够在下游任务练习时就具有强的表现，即使有限的注释。
</details></li>
</ul>
<hr>
<h2 id="Unifying-Two-Stream-Encoders-with-Transformers-for-Cross-Modal-Retrieval"><a href="#Unifying-Two-Stream-Encoders-with-Transformers-for-Cross-Modal-Retrieval" class="headerlink" title="Unifying Two-Stream Encoders with Transformers for Cross-Modal Retrieval"></a>Unifying Two-Stream Encoders with Transformers for Cross-Modal Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04343">http://arxiv.org/abs/2308.04343</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luminosityx/hat">https://github.com/luminosityx/hat</a></li>
<li>paper_authors: Yi Bin, Haoxuan Li, Yahui Xu, Xing Xu, Yang Yang, Heng Tao Shen</li>
<li>for: 提高跨模态检索的性能，具体来说是提高图像和文本之间的匹配和相关性。</li>
<li>methods: 使用两�reamTransformers作为图像和文本的Encoder，并实现层次对应模块以探索不同层次的多重对应关系。</li>
<li>results: 对两个基准数据集MSCOCO和Flickr30K进行了广泛的实验，并与SOTA基线相比，HAT得到了大量的提升。具体来说，在图像到文本和文本到图像检索两个关键任务上，HAT的Recall@1提高了7.6%和16.7%在MSCOCO上，以及4.4%和11.6%在Flickr30K上。<details>
<summary>Abstract</summary>
Most existing cross-modal retrieval methods employ two-stream encoders with different architectures for images and texts, \textit{e.g.}, CNN for images and RNN/Transformer for texts. Such discrepancy in architectures may induce different semantic distribution spaces and limit the interactions between images and texts, and further result in inferior alignment between images and texts. To fill this research gap, inspired by recent advances of Transformers in vision tasks, we propose to unify the encoder architectures with Transformers for both modalities. Specifically, we design a cross-modal retrieval framework purely based on two-stream Transformers, dubbed \textbf{Hierarchical Alignment Transformers (HAT)}, which consists of an image Transformer, a text Transformer, and a hierarchical alignment module. With such identical architectures, the encoders could produce representations with more similar characteristics for images and texts, and make the interactions and alignments between them much easier. Besides, to leverage the rich semantics, we devise a hierarchical alignment scheme to explore multi-level correspondences of different layers between images and texts. To evaluate the effectiveness of the proposed HAT, we conduct extensive experiments on two benchmark datasets, MSCOCO and Flickr30K. Experimental results demonstrate that HAT outperforms SOTA baselines by a large margin. Specifically, on two key tasks, \textit{i.e.}, image-to-text and text-to-image retrieval, HAT achieves 7.6\% and 16.7\% relative score improvement of Recall@1 on MSCOCO, and 4.4\% and 11.6\% on Flickr30k respectively. The code is available at \url{https://github.com/LuminosityX/HAT}.
</details>
<details>
<summary>摘要</summary>
现有跨Modal Retrieval方法通常采用不同架构的两�ream Encoder，如图像使用CNN，文本使用RNN/Transformer。这种不同的架构可能会导致图像和文本的Semantic分布空间不同，限制图像和文本之间的交互，从而导致图像和文本的Alignment不佳。为了填补这个研究空白，我们提出了一种基于Transformers的跨Modal Retrieval框架，名为层次对齐Transformers（HAT）。这个框架包括图像Transformer、文本Transformer和层次对齐模块。通过使用同一种架构，encoder可以生成更像性的表示，从而使图像和文本之间的交互和对齐变得更加容易。此外，为了利用rich的Semantic，我们设计了一种层次对齐方案，以探索不同层次的对应关系 между图像和文本。为证明HAT的效iveness，我们对MSCOCO和Flickr30K两个benchmark datasets进行了广泛的实验。实验结果表明，HAT在图像-文本和文本-图像检索任务上的表现都超过了State-of-the-Art baseline，具体来说，在MSCOCO上，HAT在图像-文本和文本-图像检索任务上的Recall@1相对于基eline的提高为7.6%和16.7%。在Flickr30K上，HAT的提高为4.4%和11.6%。代码可以在github上找到：https://github.com/LuminosityX/HAT。
</details></li>
</ul>
<hr>
<h2 id="TranSTYLer-Multimodal-Behavioral-Style-Transfer-for-Facial-and-Body-Gestures-Generation"><a href="#TranSTYLer-Multimodal-Behavioral-Style-Transfer-for-Facial-and-Body-Gestures-Generation" class="headerlink" title="TranSTYLer: Multimodal Behavioral Style Transfer for Facial and Body Gestures Generation"></a>TranSTYLer: Multimodal Behavioral Style Transfer for Facial and Body Gestures Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10843">http://arxiv.org/abs/2308.10843</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mireille Fares, Catherine Pelachaud, Nicolas Obin</li>
<li>for: 这篇论文目的是将虚拟代表人物的行为表达风格传递到另一个代表人物中，保留行为的形式，以便在交流中传递意义。</li>
<li>methods: 我们提出了一种基于多模态变换器的模型，称为TranSTYLer，可以将多 modal 的行为合成到源说话者的样式下。我们假设行为表达风格在不同的沟通方式中都有编码，包括文本、语音、身体姿势和脸部表情。我们使用内容和风格分离的方法，以确保传递的风格不会干扰源行为的意义。</li>
<li>results: 我们使用PATS corpus进行训练，并对其进行扩展以包括对话活动和2D脸部特征点。对象和主观评价表明，我们的模型在训练阶段seen和unseen风格时都能够超越状态之前的模型。为了解决可能出现的风格和内容泄露问题，我们提出了一种方法来评估传递的行为和姿势是否成功地采用了target风格，而不会破坏源内容的意义。<details>
<summary>Abstract</summary>
This paper addresses the challenge of transferring the behavior expressivity style of a virtual agent to another one while preserving behaviors shape as they carry communicative meaning. Behavior expressivity style is viewed here as the qualitative properties of behaviors. We propose TranSTYLer, a multimodal transformer based model that synthesizes the multimodal behaviors of a source speaker with the style of a target speaker. We assume that behavior expressivity style is encoded across various modalities of communication, including text, speech, body gestures, and facial expressions. The model employs a style and content disentanglement schema to ensure that the transferred style does not interfere with the meaning conveyed by the source behaviors. Our approach eliminates the need for style labels and allows the generalization to styles that have not been seen during the training phase. We train our model on the PATS corpus, which we extended to include dialog acts and 2D facial landmarks. Objective and subjective evaluations show that our model outperforms state of the art models in style transfer for both seen and unseen styles during training. To tackle the issues of style and content leakage that may arise, we propose a methodology to assess the degree to which behavior and gestures associated with the target style are successfully transferred, while ensuring the preservation of the ones related to the source content.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Domain-Adaptive-Person-Search-via-GAN-based-Scene-Synthesis-for-Cross-scene-Videos"><a href="#Domain-Adaptive-Person-Search-via-GAN-based-Scene-Synthesis-for-Cross-scene-Videos" class="headerlink" title="Domain Adaptive Person Search via GAN-based Scene Synthesis for Cross-scene Videos"></a>Domain Adaptive Person Search via GAN-based Scene Synthesis for Cross-scene Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04322">http://arxiv.org/abs/2308.04322</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/crsm424/da-gss">https://github.com/crsm424/da-gss</a></li>
<li>paper_authors: Huibing Wang, Tianxiang Cui, Mingze Yao, Huijuan Pang, Yushan Du</li>
<li>for: 提高人体搜索任务中的精度和效率，使用生成 adversarial networks (GAN) 生成高质量的人体图像数据。</li>
<li>methods: 基于 Fast R-CNN 模型，采用 Assisted-Identity Query Module (AIDQ) 提供正面图像，并采用 GAN 生成高质量的人体图像数据进行场景合成。采用在线学习策略，同步学习生成的图像和原始图像，以便增强特征学习。</li>
<li>results: 在 CUHK-SYSU 和 PRW 两个人体搜索标准benchmark上进行了广泛的实验，并取得了优秀的性能。并进行了详细的减少性能研究，证明 GAN 生成的数据可以增加数据的多样性和真实性。<details>
<summary>Abstract</summary>
Person search has recently been a challenging task in the computer vision domain, which aims to search specific pedestrians from real cameras.Nevertheless, most surveillance videos comprise only a handful of images of each pedestrian, which often feature identical backgrounds and clothing. Hence, it is difficult to learn more discriminative features for person search in real scenes. To tackle this challenge, we draw on Generative Adversarial Networks (GAN) to synthesize data from surveillance videos. GAN has thrived in computer vision problems because it produces high-quality images efficiently. We merely alter the popular Fast R-CNN model, which is capable of processing videos and yielding accurate detection outcomes. In order to appropriately relieve the pressure brought by the two-stage model, we design an Assisted-Identity Query Module (AIDQ) to provide positive images for the behind part. Besides, the proposed novel GAN-based Scene Synthesis model that can synthesize high-quality cross-id person images for person search tasks. In order to facilitate the feature learning of the GAN-based Scene Synthesis model, we adopt an online learning strategy that collaboratively learns the synthesized images and original images. Extensive experiments on two widely used person search benchmarks, CUHK-SYSU and PRW, have shown that our method has achieved great performance, and the extensive ablation study further justifies our GAN-synthetic data can effectively increase the variability of the datasets and be more realistic.
</details>
<details>
<summary>摘要</summary>
人体搜索是计算机视觉领域中的一个长期挑战，目标是从真实的摄像头中搜索特定的步行人。然而，大多数surveillance视频中只包含每个步行人的几张图像，这些图像通常具有相同的背景和服装。因此，学习更加特异的人体特征变得困难。为解决这个问题，我们引入生成 adversarial networks（GAN）来生成数据集。GAN在计算机视觉问题中取得了成功，因为它可以生成高质量的图像。我们只是修改了popular Fast R-CNN模型，这种模型可以处理视频并提供准确的检测结果。为了正确地减轻两个阶段模型中的压力，我们设计了一个帮助查询模块（AIDQ），以提供后部图像的正面图像。此外，我们还提出了一种新的基于GAN的Scene Synthesis模型，可以生成高质量的跨ID人体图像 для人体搜索任务。为了促进GAN-based Scene Synthesis模型的特征学习，我们采用了在线学习策略，将合作学习生成的图像和原始图像。广泛的实验表明，我们的方法在两个常用的人体搜索标准 benchmarck上表现出色，并且extensive ablation study further justify我们的GAN-synthetic数据可以增加数据集的变化性和更加真实。
</details></li>
</ul>
<hr>
<h2 id="All-pairs-Consistency-Learning-for-Weakly-Supervised-Semantic-Segmentation"><a href="#All-pairs-Consistency-Learning-for-Weakly-Supervised-Semantic-Segmentation" class="headerlink" title="All-pairs Consistency Learning for Weakly Supervised Semantic Segmentation"></a>All-pairs Consistency Learning for Weakly Supervised Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04321">http://arxiv.org/abs/2308.04321</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weixuan Sun, Yanhao Zhang, Zhen Qin, Zheyuan Liu, Lin Cheng, Fanyi Wang, Yiran Zhong, Nick Barnes</li>
<li>for: 提高弱级 semantic segmentation（WSSS）中对象的本地化。</li>
<li>methods: 使用 transformer 基于的常见化regularization，包括 consistency regularization 和 all-pairs consistency regularization（ACR）。</li>
<li>results: 在 PASCAL VOC 和 MS COCO 数据集上实现了更好的类本地化图（67.3% mIoU on PASCAL VOC train），从而提高 WSSS 性能。<details>
<summary>Abstract</summary>
In this work, we propose a new transformer-based regularization to better localize objects for Weakly supervised semantic segmentation (WSSS). In image-level WSSS, Class Activation Map (CAM) is adopted to generate object localization as pseudo segmentation labels. To address the partial activation issue of the CAMs, consistency regularization is employed to maintain activation intensity invariance across various image augmentations. However, such methods ignore pair-wise relations among regions within each CAM, which capture context and should also be invariant across image views. To this end, we propose a new all-pairs consistency regularization (ACR). Given a pair of augmented views, our approach regularizes the activation intensities between a pair of augmented views, while also ensuring that the affinity across regions within each view remains consistent. We adopt vision transformers as the self-attention mechanism naturally embeds pair-wise affinity. This enables us to simply regularize the distance between the attention matrices of augmented image pairs. Additionally, we introduce a novel class-wise localization method that leverages the gradients of the class token. Our method can be seamlessly integrated into existing WSSS methods using transformers without modifying the architectures. We evaluate our method on PASCAL VOC and MS COCO datasets. Our method produces noticeably better class localization maps (67.3% mIoU on PASCAL VOC train), resulting in superior WSSS performances.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了一种基于转换器的新的常规化方法，以改进弱元素概率semantic segmentation（WSSS）中对 объек的本地化。在图像级WSSS中，使用Class Activation Map（CAM）生成对象本地化，但CAM的部分活动问题导致consistency regularization不具备对图像增强的抗锯齿性。我们的方法忽略了每个CAM中的对region之间的关系，这些关系捕捉了上下文信息，并且应该是图像视图不变的。为此，我们提出了一种新的所有对之间一致常规化（ACR）。给定两个扩展视图，我们的方法对扩展视图中的活动强度进行规范，同时确保每个视图中的区域之间的相互关系保持一致。我们采用了转换器作为自我注意力机制，这使得我们可以简单地规范扩展视图之间的距离。此外，我们还提出了一种新的类型本地化方法，该方法利用类token的梯度来优化类本地化。我们的方法可以轻松地与现有的WSSS方法集成，无需修改架构。我们在PASCAL VOC和MS COCO数据集上进行了评估，我们的方法在PASCAL VOC训练集上得到了67.3%的mean Intersection over Union（mIoU），这表明我们的方法可以提供更好的类本地化图像。
</details></li>
</ul>
<hr>
<h2 id="Cloth2Tex-A-Customized-Cloth-Texture-Generation-Pipeline-for-3D-Virtual-Try-On"><a href="#Cloth2Tex-A-Customized-Cloth-Texture-Generation-Pipeline-for-3D-Virtual-Try-On" class="headerlink" title="Cloth2Tex: A Customized Cloth Texture Generation Pipeline for 3D Virtual Try-On"></a>Cloth2Tex: A Customized Cloth Texture Generation Pipeline for 3D Virtual Try-On</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04288">http://arxiv.org/abs/2308.04288</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daiheng Gao, Xu Chen, Xindi Zhang, Qi Wang, Ke Sun, Bang Zhang, Liefeng Bo, Qixing Huang</li>
<li>for: 这篇论文旨在提供一种自然语言处理方法，以便自动生成高质量的3D衣物文字图像，以满足3D虚拟试穿、数字化2D服装到3D服装和布料动画等应用需求。</li>
<li>methods: 该方法基于自我超级vised学习，通过对2D参考图像进行扩散学习，生成高质量的 texture maps，并且可以支持高精度的 texture inpainting。</li>
<li>results: 作者通过质量和量化评估，证明了 Cloth2Tex 可以生成高质量的 texture maps，并且在视觉效果上超过其他方法。<details>
<summary>Abstract</summary>
Fabricating and designing 3D garments has become extremely demanding with the increasing need for synthesizing realistic dressed persons for a variety of applications, e.g. 3D virtual try-on, digitalization of 2D clothes into 3D apparel, and cloth animation. It thus necessitates a simple and straightforward pipeline to obtain high-quality texture from simple input, such as 2D reference images. Since traditional warping-based texture generation methods require a significant number of control points to be manually selected for each type of garment, which can be a time-consuming and tedious process. We propose a novel method, called Cloth2Tex, which eliminates the human burden in this process. Cloth2Tex is a self-supervised method that generates texture maps with reasonable layout and structural consistency. Another key feature of Cloth2Tex is that it can be used to support high-fidelity texture inpainting. This is done by combining Cloth2Tex with a prevailing latent diffusion model. We evaluate our approach both qualitatively and quantitatively and demonstrate that Cloth2Tex can generate high-quality texture maps and achieve the best visual effects in comparison to other methods. Project page: tomguluson92.github.io/projects/cloth2tex/
</details>
<details>
<summary>摘要</summary>
制备和设计3D衣服已经变得极其需求量，因为需要生成真实的穿着人形进行多种应用，如3D虚拟试穿、2D衣服数字化到3D服装和布料动画。因此需要一个简单和直观的管道来获得高质量的纹理，从简单的输入中，如2D参考图像。传统的折叠基于的纹理生成方法需要手动选择大量的控制点，这可以是一个时间consuming和繁琐的过程。我们提议一种新的方法，called Cloth2Tex，它消除了人类的劳动在这个过程中。Cloth2Tex是一种自动学习的方法，可以生成纹理图片，并且具有合理的布局和结构一致性。另外，Cloth2Tex还可以支持高精度的纹理填充。我们通过质量和量化的评估，证明Cloth2Tex可以生成高质量的纹理图片，并且在比较其他方法时，可以 achieve the best visual effects。项目页面：tomguluson92.github.io/projects/cloth2tex/
</details></li>
</ul>
<hr>
<h2 id="Vision-Based-Autonomous-Navigation-for-Unmanned-Surface-Vessel-in-Extreme-Marine-Conditions"><a href="#Vision-Based-Autonomous-Navigation-for-Unmanned-Surface-Vessel-in-Extreme-Marine-Conditions" class="headerlink" title="Vision-Based Autonomous Navigation for Unmanned Surface Vessel in Extreme Marine Conditions"></a>Vision-Based Autonomous Navigation for Unmanned Surface Vessel in Extreme Marine Conditions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04283">http://arxiv.org/abs/2308.04283</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/muhayyuddin/visual-servoing">https://github.com/muhayyuddin/visual-servoing</a></li>
<li>paper_authors: Muhayyuddin Ahmed, Ahsan Baidar Bakht, Taimur Hassan, Waseem Akram, Ahmed Humais, Lakmal Seneviratne, Shaoming He, Defu Lin, Irfan Hussain</li>
<li>for: 本研究旨在提高自主水面船（USV）的视觉 Navigation 性能，特别是在自动检查和跟踪任务中。</li>
<li>methods: 该研究提出了一种基于生成对抗网络（GAN）的自主视觉导航框架，用于在极端海洋环境中跟踪目标对象。该框架包括一个整合的感知管道，通过GAN将噪音除去并高亮目标特征，然后将这些感知特征传递给YOLOv5对象检测器。</li>
<li>results: 对比state-of-the-art净气化方法，该提案在MBZIRC simulate dataset上表现出了明显的优异性能，包括各种指标上的比较优异性能。<details>
<summary>Abstract</summary>
Visual perception is an important component for autonomous navigation of unmanned surface vessels (USV), particularly for the tasks related to autonomous inspection and tracking. These tasks involve vision-based navigation techniques to identify the target for navigation. Reduced visibility under extreme weather conditions in marine environments makes it difficult for vision-based approaches to work properly. To overcome these issues, this paper presents an autonomous vision-based navigation framework for tracking target objects in extreme marine conditions. The proposed framework consists of an integrated perception pipeline that uses a generative adversarial network (GAN) to remove noise and highlight the object features before passing them to the object detector (i.e., YOLOv5). The detected visual features are then used by the USV to track the target. The proposed framework has been thoroughly tested in simulation under extremely reduced visibility due to sandstorms and fog. The results are compared with state-of-the-art de-hazing methods across the benchmarked MBZIRC simulation dataset, on which the proposed scheme has outperformed the existing methods across various metrics.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate text into Simplified ChineseVisual perception is an important component for autonomous navigation of unmanned surface vessels (USV), particularly for the tasks related to autonomous inspection and tracking. These tasks involve vision-based navigation techniques to identify the target for navigation. Reduced visibility under extreme weather conditions in marine environments makes it difficult for vision-based approaches to work properly. To overcome these issues, this paper presents an autonomous vision-based navigation framework for tracking target objects in extreme marine conditions. The proposed framework consists of an integrated perception pipeline that uses a generative adversarial network (GAN) to remove noise and highlight the object features before passing them to the object detector (i.e., YOLOv5). The detected visual features are then used by the USV to track the target. The proposed framework has been thoroughly tested in simulation under extremely reduced visibility due to sandstorms and fog. The results are compared with state-of-the-art de-hazing methods across the benchmarked MBZIRC simulation dataset, on which the proposed scheme has outperformed the existing methods across various metrics.<</SYS>>Here's the translation in Simplified Chinese:视觉认知是自动航行无人水面船（USV）中重要的一部分，尤其是在自动检查和跟踪任务中。这些任务需要基于视觉导航技术来确定目标。 marine 环境中的极端天气条件会使视觉基于的方法难以正常工作。为解决这些问题，本文提出了一个基于视觉的自动导航框架，用于在极端海洋条件下跟踪目标对象。该框架包括一个集成的识别管道，使用生成对抗网络（GAN）来消除噪声并强调对象特征，然后将这些特征传递给对象检测器（YOLOv5）进行检测。检测到的视觉特征然后被用于跟踪目标。本框架在基于 MBZIRC 的 simulate 环境下进行了严格的测试，并与现有的抑霾方法进行了比较。结果表明，提出的方案在各种维度上都有出众的表现。
</details></li>
</ul>
<hr>
<h2 id="SDLFormer-A-Sparse-and-Dense-Locality-enhanced-Transformer-for-Accelerated-MR-Image-Reconstruction"><a href="#SDLFormer-A-Sparse-and-Dense-Locality-enhanced-Transformer-for-Accelerated-MR-Image-Reconstruction" class="headerlink" title="SDLFormer: A Sparse and Dense Locality-enhanced Transformer for Accelerated MR Image Reconstruction"></a>SDLFormer: A Sparse and Dense Locality-enhanced Transformer for Accelerated MR Image Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04262">http://arxiv.org/abs/2308.04262</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rahul-gs-16/sdlformer">https://github.com/rahul-gs-16/sdlformer</a></li>
<li>paper_authors: Rahul G. S., Sriprabha Ramnarayanan, Mohammad Al Fahim, Keerthi Ram, Preejith S. P, Mohanasankar Sivaprakasam</li>
<li>for: 这个论文目的是提出一种基于窗口变换器的加速MRI图像重建方法，以提高MRI图像重建的效率和质量。</li>
<li>methods: 该方法使用窗口变换器网络，并 integrate了扩大注意力机制和卷积Operation来提高图像之间的非本地关系，以及学习低级翻译不变的特征。</li>
<li>results: 对多核磁共振图像加速的实验结果显示，该方法可以与其他重建建筑物相比，提高PSNR和SSIM指标的值。 Code可以在<a target="_blank" rel="noopener" href="https://github.com/rahul-gs-16/sdlformer.git%E4%B8%AD%E6%89%BE%E5%88%B0%E3%80%82">https://github.com/rahul-gs-16/sdlformer.git中找到。</a><details>
<summary>Abstract</summary>
Transformers have emerged as viable alternatives to convolutional neural networks owing to their ability to learn non-local region relationships in the spatial domain. The self-attention mechanism of the transformer enables transformers to capture long-range dependencies in the images, which might be desirable for accelerated MRI image reconstruction as the effect of undersampling is non-local in the image domain. Despite its computational efficiency, the window-based transformers suffer from restricted receptive fields as the dependencies are limited to within the scope of the image windows. We propose a window-based transformer network that integrates dilated attention mechanism and convolution for accelerated MRI image reconstruction. The proposed network consists of dilated and dense neighborhood attention transformers to enhance the distant neighborhood pixel relationship and introduce depth-wise convolutions within the transformer module to learn low-level translation invariant features for accelerated MRI image reconstruction. The proposed model is trained in a self-supervised manner. We perform extensive experiments for multi-coil MRI acceleration for coronal PD, coronal PDFS and axial T2 contrasts with 4x and 5x under-sampling in self-supervised learning based on k-space splitting. We compare our method against other reconstruction architectures and the parallel domain self-supervised learning baseline. Results show that the proposed model exhibits improvement margins of (i) around 1.40 dB in PSNR and around 0.028 in SSIM on average over other architectures (ii) around 1.44 dB in PSNR and around 0.029 in SSIM over parallel domain self-supervised learning. The code is available at https://github.com/rahul-gs-16/sdlformer.git
</details>
<details>
<summary>摘要</summary>
transformers 已经成为了 convolutional neural networks 的可行的替代方案，因为它们可以学习图像空间中的非本地区域关系。transformers 中的自注意机制使得 transformers 可以捕捉图像中的长距离依赖关系，这可能是加速 MRI 图像重建的潜在的优点，因为 MRI 图像下折衔的效果是非本地的。 despite its computational efficiency, window-based transformers suffer from restricted receptive fields as the dependencies are limited to within the scope of the image windows. we propose a window-based transformer network that integrates dilated attention mechanism and convolution for accelerated MRI image reconstruction. the proposed network consists of dilated and dense neighborhood attention transformers to enhance the distant neighborhood pixel relationship and introduce depth-wise convolutions within the transformer module to learn low-level translation invariant features for accelerated MRI image reconstruction. the proposed model is trained in a self-supervised manner. we perform extensive experiments for multi-coil MRI acceleration for coronal PD, coronal PDFS and axial T2 contrasts with 4x and 5x under-sampling in self-supervised learning based on k-space splitting. we compare our method against other reconstruction architectures and the parallel domain self-supervised learning baseline. results show that the proposed model exhibits improvement margins of (i) around 1.40 dB in PSNR and around 0.028 in SSIM on average over other architectures (ii) around 1.44 dB in PSNR and around 0.029 in SSIM over parallel domain self-supervised learning. the code is available at https://github.com/rahul-gs-16/sdlformer.git.
</details></li>
</ul>
<hr>
<h2 id="Blur-aware-metric-depth-estimation-with-multi-focus-plenoptic-cameras"><a href="#Blur-aware-metric-depth-estimation-with-multi-focus-plenoptic-cameras" class="headerlink" title="Blur aware metric depth estimation with multi-focus plenoptic cameras"></a>Blur aware metric depth estimation with multi-focus plenoptic cameras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04252">http://arxiv.org/abs/2308.04252</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/comsee-research/blade">https://github.com/comsee-research/blade</a></li>
<li>paper_authors: Mathieu Labussière, Céline Teulière, Omar Ait-Aider</li>
<li>for: 这个论文的主要目标是提出一种基于raw图像的多重焦距束镜相机的 metric depth estimation算法，以提高不同焦距的匹配和束缚信息的拟合。</li>
<li>methods: 该方法利用了不同焦距的图像捕捉，并通过缓冲信息来提高匹配和束缚信息的拟合。具体来说，该方法首先计算了图像的缓冲信息，然后利用了这些缓冲信息来提高匹配和束缚信息的拟合。</li>
<li>results: 实验结果表明，引入了焦距缓冲信息可以提高depth estimation的准确性和精度。该方法在实验中对实际的3D复杂场景进行了验证，并与3D激光扫描仪获取的实际测量数据进行了比较。<details>
<summary>Abstract</summary>
While a traditional camera only captures one point of view of a scene, a plenoptic or light-field camera, is able to capture spatial and angular information in a single snapshot, enabling depth estimation from a single acquisition. In this paper, we present a new metric depth estimation algorithm using only raw images from a multi-focus plenoptic camera. The proposed approach is especially suited for the multi-focus configuration where several micro-lenses with different focal lengths are used. The main goal of our blur aware depth estimation (BLADE) approach is to improve disparity estimation for defocus stereo images by integrating both correspondence and defocus cues. We thus leverage blur information where it was previously considered a drawback. We explicitly derive an inverse projection model including the defocus blur providing depth estimates up to a scale factor. A method to calibrate the inverse model is then proposed. We thus take into account depth scaling to achieve precise and accurate metric depth estimates. Our results show that introducing defocus cues improves the depth estimation. We demonstrate the effectiveness of our framework and depth scaling calibration on relative depth estimation setups and on real-world 3D complex scenes with ground truth acquired with a 3D lidar scanner.
</details>
<details>
<summary>摘要</summary>
tradicional 摄像机只能捕捉一个场景的一点视角，而 plenoptic 或 light-field 摄像机则能够在单个拍摄中捕捉场景的空间和角度信息，从而实现深度估计从单个获得。在这篇论文中，我们提出了一种基于原始图像的新的深度估计算法，使用多重ocus plenoptic 摄像机获得的Raw图像。我们的方法尤其适用于多重ocus配置，其中多个微镜头具有不同的 фокус距离。我们的方法的主要目标是通过结合匹配和杂谱诱导来提高不同损失的 disparity 估计。我们利用了模糊信息，而前面它被视为一个缺点。我们明确地 derivation 一个逆 проекции模型，包括杂谱模糊，以获得深度估计。然后，我们提出了一种准确做出深度缩放准确的方法。我们的结果表明，将杂谱诱导包含在深度估计中可以提高深度估计的精度。我们在相对深度估计设置和实际世界3D复杂场景中使用了真实的3D激光扫描仪获得的ground truth进行证明。
</details></li>
</ul>
<hr>
<h2 id="AICSD-Adaptive-Inter-Class-Similarity-Distillation-for-Semantic-Segmentation"><a href="#AICSD-Adaptive-Inter-Class-Similarity-Distillation-for-Semantic-Segmentation" class="headerlink" title="AICSD: Adaptive Inter-Class Similarity Distillation for Semantic Segmentation"></a>AICSD: Adaptive Inter-Class Similarity Distillation for Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04243">http://arxiv.org/abs/2308.04243</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/amirmansurian/aicsd">https://github.com/amirmansurian/aicsd</a></li>
<li>paper_authors: Amir M. Mansourian, Rozhan Ahmadi, Shohreh Kasaei</li>
<li>For: The paper aims to improve the accuracy of lightweight student networks for semantic segmentation tasks using knowledge distillation.* Methods: The proposed method, called Inter-Class Similarity Distillation (ICSD), transfers high-order relations from the teacher network to the student network by computing intra-class distributions and inter-class similarity matrices using KL divergence. An Adaptive Loss Weighting (ALW) training strategy is also proposed to gradually reduce the influence of the teacher network towards the end of training.* Results: The proposed method outperforms most existing knowledge distillation methods in terms of mIoU and pixel accuracy on two well-known datasets for semantic segmentation, Cityscapes and Pascal VOC 2012.Here are the three key points in Simplified Chinese text:* 为：本文目的是使用知识传授提高轻量级学生网络在 semantic segmentation 任务中的准确性。* 方法：提议的方法是 Inter-Class Similarity Distillation (ICSD)，它通过计算网络输出中每个类的内部分布来传递教师网络中高阶关系。此外，还使用 Adaptive Loss Weighting (ALW) 训练策略，以逐渐减少教师网络的影响。* 结果：提议的方法在 Cityscapes 和 Pascal VOC 2012 两个常见的 semantic segmentation 数据集上，与大多数现有的知识传授方法相比，在 mIoU 和像素准确性上表现出色。<details>
<summary>Abstract</summary>
In recent years, deep neural networks have achieved remarkable accuracy in computer vision tasks. With inference time being a crucial factor, particularly in dense prediction tasks such as semantic segmentation, knowledge distillation has emerged as a successful technique for improving the accuracy of lightweight student networks. The existing methods often neglect the information in channels and among different classes. To overcome these limitations, this paper proposes a novel method called Inter-Class Similarity Distillation (ICSD) for the purpose of knowledge distillation. The proposed method transfers high-order relations from the teacher network to the student network by independently computing intra-class distributions for each class from network outputs. This is followed by calculating inter-class similarity matrices for distillation using KL divergence between distributions of each pair of classes. To further improve the effectiveness of the proposed method, an Adaptive Loss Weighting (ALW) training strategy is proposed. Unlike existing methods, the ALW strategy gradually reduces the influence of the teacher network towards the end of training process to account for errors in teacher's predictions. Extensive experiments conducted on two well-known datasets for semantic segmentation, Cityscapes and Pascal VOC 2012, validate the effectiveness of the proposed method in terms of mIoU and pixel accuracy. The proposed method outperforms most of existing knowledge distillation methods as demonstrated by both quantitative and qualitative evaluations. Code is available at: https://github.com/AmirMansurian/AICSD
</details>
<details>
<summary>摘要</summary>
Recently, deep neural networks have achieved remarkable accuracy in computer vision tasks. However, with inference time being a crucial factor, particularly in dense prediction tasks such as semantic segmentation, knowledge distillation has emerged as a successful technique for improving the accuracy of lightweight student networks. Existing methods often neglect the information in channels and among different classes. To overcome these limitations, this paper proposes a novel method called Inter-Class Similarity Distillation (ICSD) for the purpose of knowledge distillation.The proposed method transfers high-order relations from the teacher network to the student network by independently computing intra-class distributions for each class from network outputs. This is followed by calculating inter-class similarity matrices for distillation using KL divergence between distributions of each pair of classes. To further improve the effectiveness of the proposed method, an Adaptive Loss Weighting (ALW) training strategy is proposed. Unlike existing methods, the ALW strategy gradually reduces the influence of the teacher network towards the end of training process to account for errors in teacher's predictions.Extensive experiments conducted on two well-known datasets for semantic segmentation, Cityscapes and Pascal VOC 2012, validate the effectiveness of the proposed method in terms of mIoU and pixel accuracy. The proposed method outperforms most of existing knowledge distillation methods as demonstrated by both quantitative and qualitative evaluations. Code is available at: https://github.com/AmirMansurian/AICSD.Here's the translation in Traditional Chinese:过去的几年，深度神经网络在计算机视觉任务中已经取得了很高的准确性。然而，在填充预测任务中，特别是 semantic segmentation 中，推论时间成为一个关键的因素。为了解决这个问题，这篇文章提出了一种名为 Inter-Class Similarity Distillation (ICSD) 的新方法。提案的方法通过获取师网络的高阶关系，将这些关系转移到学生网络中。这是通过获取每个类别的网络输出中的数据，并计算每对类别之间的相似性矩阵来进行知识传递。另外，为了进一步提高方法的效果，这篇文章还提出了一种 Adaptive Loss Weighting (ALW) 训练策略。与现有的方法不同的是，ALW 策略在训练过程中逐渐将师网络的影响降低，以抵销教师预测中的错误。实验结果显示，提案的方法在 Cityscapes 和 Pascal VOC 2012 这两个常用的 semantic segmentation 数据集上具有较高的 mIoU 和像素精度。此外，与现有的知识传递方法比较，提案的方法在量值和质量上都表现较好。代码可以在 https://github.com/AmirMansurian/AICSD 上取得。
</details></li>
</ul>
<hr>
<h2 id="A-Comparative-Study-of-Image-to-Image-Translation-Using-GANs-for-Synthetic-Child-Race-Data"><a href="#A-Comparative-Study-of-Image-to-Image-Translation-Using-GANs-for-Synthetic-Child-Race-Data" class="headerlink" title="A Comparative Study of Image-to-Image Translation Using GANs for Synthetic Child Race Data"></a>A Comparative Study of Image-to-Image Translation Using GANs for Synthetic Child Race Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04232">http://arxiv.org/abs/2308.04232</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wang Yao, Muhammad Ali Farooq, Joseph Lemley, Peter Corcoran</li>
<li>for: 提高face recognition技术的种族多样性</li>
<li>methods: 使用图像-图像转换来调整儿童脸部数据的种族</li>
<li>results: 实验结果表明，使用图像-图像转换方法可以生成各种种族的人工儿童脸部数据样本，提高face recognition技术的种族多样性。<details>
<summary>Abstract</summary>
The lack of ethnic diversity in data has been a limiting factor of face recognition techniques in the literature. This is particularly the case for children where data samples are scarce and presents a challenge when seeking to adapt machine vision algorithms that are trained on adult data to work on children. This work proposes the utilization of image-to-image transformation to synthesize data of different races and thus adjust the ethnicity of children's face data. We consider ethnicity as a style and compare three different Image-to-Image neural network based methods, specifically pix2pix, CycleGAN, and CUT networks to implement Caucasian child data and Asian child data conversion. Experimental validation results on synthetic data demonstrate the feasibility of using image-to-image transformation methods to generate various synthetic child data samples with broader ethnic diversity.
</details>
<details>
<summary>摘要</summary>
“无伦不同的人种数据的缺乏对面 recognition技术的发展带来了限制。尤其是儿童的数据样本罕见，对于适应机器视觉算法trained on adult data来应用于儿童的情况存在挑战。本工作提议利用图像到图像转换来增加不同的人种样本，以适应儿童的脸部数据的不同种族。我们认为人种是一种风格，并评估了三种基于图像到图像神经网络的方法，即 pix2pix、CycleGAN 和 CUT 网络，以实现白人儿童数据和亚洲儿童数据的转换。对于 sintetic data 的实验验证结果表明，使用图像到图像转换方法可以生成各种不同的 sintetic 儿童数据样本，以拓宽人种多样性。”
</details></li>
</ul>
<hr>
<h2 id="Will-your-Doorbell-Camera-still-recognize-you-as-you-grow-old"><a href="#Will-your-Doorbell-Camera-still-recognize-you-as-you-grow-old" class="headerlink" title="Will your Doorbell Camera still recognize you as you grow old"></a>Will your Doorbell Camera still recognize you as you grow old</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04224">http://arxiv.org/abs/2308.04224</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wang Yao, Muhammad Ali Farooq, Joseph Lemley, Peter Corcoran</li>
<li>for: 这个研究探讨了低功耗消费类设备（如门禁摄像头）的Robust验证问题，尤其是针对年龄的影响。</li>
<li>methods: 这个研究使用了两个公共的年龄数据集（AgeDB和Morph-II）作为基线，并使用了一种图形真实的年龄变换方法来增加一组高质量的面部图像，以模拟不同年龄的影响。</li>
<li>results: 实验结果表明，长期年龄影响仍然是现代面部验证方法的主要挑战。<details>
<summary>Abstract</summary>
Robust authentication for low-power consumer devices such as doorbell cameras poses a valuable and unique challenge. This work explores the effect of age and aging on the performance of facial authentication methods. Two public age datasets, AgeDB and Morph-II have been used as baselines in this work. A photo-realistic age transformation method has been employed to augment a set of high-quality facial images with various age effects. Then the effect of these synthetic aging data on the high-performance deep-learning-based face recognition model is quantified by using various metrics including Receiver Operating Characteristic (ROC) curves and match score distributions. Experimental results demonstrate that long-term age effects are still a significant challenge for the state-of-the-art facial authentication method.
</details>
<details>
<summary>摘要</summary>
低功耗消费者设备的坚实验证提供了一个独特和有价值的挑战。这项工作研究了人脸认证方法在不同年龄的影响。使用了公共的年龄数据集AgeDB和Morph-II作为基准，这里使用了一种实际准确的年龄变换方法来增加一组高质量的人脸图像，并对这些图像进行了不同年龄的变换。然后，通过使用深度学习基于的高性能人脸识别模型，量化这些人脸图像在不同年龄的影响。实验结果显示，长期年龄效应仍然是现代人脸认证方法的一大挑战。
</details></li>
</ul>
<hr>
<h2 id="AquaSAM-Underwater-Image-Foreground-Segmentation"><a href="#AquaSAM-Underwater-Image-Foreground-Segmentation" class="headerlink" title="AquaSAM: Underwater Image Foreground Segmentation"></a>AquaSAM: Underwater Image Foreground Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04218">http://arxiv.org/abs/2308.04218</a></li>
<li>repo_url: None</li>
<li>paper_authors: Muduo Xu, Jianhao Su, Yutao Liu</li>
<li>for: 这个论文是为了推广自然图像分割模型（SAM）的成功，将其应用于水下图像分割。</li>
<li>methods: 这篇论文使用自动分类和提取SUIM数据集中的各种标签，然后通过简单的微调方法将SAM模型适应通用水下图像分割。</li>
<li>results: 经过对8种分 segmentation任务（如人体潜水员）的广泛实验，这篇论文表明AquaSAM模型在水下图像分割任务中比默认SAM模型更高效，尤其是在困难任务（如珊瑚礁）中。AquaSAM模型在水下图像分割任务中的平均Dice相似度指数（DSC）提高了7.13%，并在多尺度指标（mIoU）上提高了8.27%。<details>
<summary>Abstract</summary>
The Segment Anything Model (SAM) has revolutionized natural image segmentation, nevertheless, its performance on underwater images is still restricted. This work presents AquaSAM, the first attempt to extend the success of SAM on underwater images with the purpose of creating a versatile method for the segmentation of various underwater targets. To achieve this, we begin by classifying and extracting various labels automatically in SUIM dataset. Subsequently, we develop a straightforward fine-tuning method to adapt SAM to general foreground underwater image segmentation. Through extensive experiments involving eight segmentation tasks like human divers, we demonstrate that AquaSAM outperforms the default SAM model especially at hard tasks like coral reefs. AquaSAM achieves an average Dice Similarity Coefficient (DSC) of 7.13 (%) improvement and an average of 8.27 (%) on mIoU improvement in underwater segmentation tasks.
</details>
<details>
<summary>摘要</summary>
《Segment Anything Model》（SAM）已经革命化自然图像分割，但其在水下图像上的性能仍然受限。这项工作提出了将SAM扩展到水下图像上，以创建一种多样化的水下目标分割方法。为此，我们首先自动找到和分类SUIM数据集中的多种标签。然后，我们开发了一种简单的微调方法，以适应SAM进行普通水下图像分割的适应。经过对八种分割任务，如人体潜水员，的广泛实验，我们表明了 AquaSAM 在水下分割任务中的优异性，尤其是在复杂的珊瑚礁等难题上。AquaSAM 在水下分割任务中的平均 dice相似度系数（DSC）提高了7.13%，和水下分割任务的平均准确率（mIoU）提高了8.27%。
</details></li>
</ul>
<hr>
<h2 id="Robust-retrieval-of-material-chemical-states-in-X-ray-microspectroscopy"><a href="#Robust-retrieval-of-material-chemical-states-in-X-ray-microspectroscopy" class="headerlink" title="Robust retrieval of material chemical states in X-ray microspectroscopy"></a>Robust retrieval of material chemical states in X-ray microspectroscopy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04207">http://arxiv.org/abs/2308.04207</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ting Wang, Xiaotong Wu, Jizhou Li, Chao Wang</li>
<li>for: 研究材料的结构和化学变化，提供高分辨率的结构和光谱信息。</li>
<li>methods: 提出了一种新的数据建模方法和专门的分解框架，可以快速和可靠地检测材料的化学状态，并且可以扩展到多态材料化学。</li>
<li>results: 通过实验结果，证明了该方法的有效性和可靠性，可以在实际应用中快速和准确地检测材料的化学状态，即使在低信号噪声和光谱特征 overlap 的情况下。<details>
<summary>Abstract</summary>
X-ray microspectroscopic techniques are essential for studying morphological and chemical changes in materials, providing high-resolution structural and spectroscopic information. However, its practical data analysis for reliably retrieving the chemical states remains a major obstacle to accelerating the fundamental understanding of materials in many research fields. In this work, we propose a novel data formulation model for X-ray microspectroscopy and develop a dedicated unmixing framework to solve this problem, which is robust to noise and spectral variability. Moreover, this framework is not limited to the analysis of two-state material chemistry, making it an effective alternative to conventional and widely-used methods. In addition, an alternative directional multiplier method with provable convergence is applied to obtain the solution efficiently. Our framework can accurately identify and characterize chemical states in complex and heterogeneous samples, even under challenging conditions such as low signal-to-noise ratios and overlapping spectral features. Extensive experimental results on simulated and real datasets demonstrate its effectiveness and reliability.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Exploring-Transformers-for-Open-world-Instance-Segmentation"><a href="#Exploring-Transformers-for-Open-world-Instance-Segmentation" class="headerlink" title="Exploring Transformers for Open-world Instance Segmentation"></a>Exploring Transformers for Open-world Instance Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04206">http://arxiv.org/abs/2308.04206</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiannan Wu, Yi Jiang, Bin Yan, Huchuan Lu, Zehuan Yuan, Ping Luo</li>
<li>for: 这 paper 的目的是提出一种基于 transformer 的开放世界实例分割方法，以满足现有的实例分割模型在开放世界中的应用。</li>
<li>methods: 这 paper 使用了 transformer 网络，并提出了两个新的技术：首先，attach stop-gradient 操作来防止新类目被抑制为背景，并在 classification 头添加 IoU 头来发现新的物体。其次，提出了一种新的对比学习框架，通过在 object 队列中维护对象的中心点，并动态选择对象和背景的正负样本进行对比学习。</li>
<li>results: 这 paper 的模型在多种开放世界cross-category 和 cross-dataset 推广中取得了state-of-the-art 性能，特别是在 VOC 到 non-VOC 设置下，模型在 ARb100 和 ARm100 上达到了40.0% 和34.9% 的最高记录。在 COCO 到 UVO 推广中，SWORD 模型比前一个最佳的开放世界模型高出5.9% 和8.1% 的 APm 和 ARm100。<details>
<summary>Abstract</summary>
Open-world instance segmentation is a rising task, which aims to segment all objects in the image by learning from a limited number of base-category objects. This task is challenging, as the number of unseen categories could be hundreds of times larger than that of seen categories. Recently, the DETR-like models have been extensively studied in the closed world while stay unexplored in the open world. In this paper, we utilize the Transformer for open-world instance segmentation and present SWORD. Firstly, we introduce to attach the stop-gradient operation before classification head and further add IoU heads for discovering novel objects. We demonstrate that a simple stop-gradient operation not only prevents the novel objects from being suppressed as background, but also allows the network to enjoy the merit of heuristic label assignment. Secondly, we propose a novel contrastive learning framework to enlarge the representations between objects and background. Specifically, we maintain a universal object queue to obtain the object center, and dynamically select positive and negative samples from the object queries for contrastive learning. While the previous works only focus on pursuing average recall and neglect average precision, we show the prominence of SWORD by giving consideration to both criteria. Our models achieve state-of-the-art performance in various open-world cross-category and cross-dataset generalizations. Particularly, in VOC to non-VOC setup, our method sets new state-of-the-art results of 40.0% on ARb100 and 34.9% on ARm100. For COCO to UVO generalization, SWORD significantly outperforms the previous best open-world model by 5.9% on APm and 8.1% on ARm100.
</details>
<details>
<summary>摘要</summary>
open-world实例分割是一项崛起的任务，旨在通过学习有限数量的基本类目对象来分割图像中的所有对象。这个任务非常吃力，因为未知类别的数量可能是已知类别的百倍以上。在过去，DETR-like模型在关闭世界中被广泛研究，而在开放世界中却未得到过 изучение。在这篇论文中，我们使用Transformer进行开放世界实例分割，并提出SWORD。首先，我们在分类头部添加停止梯度操作，并添加IoU头来发现新对象。我们发现简单的停止梯度操作不仅防止新对象被识别为背景，还让网络享受到了识别标签的便利。其次，我们提出了一种新的对比学习框架，以增强对象和背景之间的表示。我们保持一个通用对象队列，以获取对象的中心，并动态选择对象查询中的正确和错误样本进行对比学习。而过去的工作只关注着追求平均回归率，忽略了平均准确率，我们显示SWORD的优势，并在不同的开放世界交叉类和交叉数据集上达到了state-of-the-art表现。尤其是在VOC到非VOC设置下，我们的方法设置了新的state-of-the-art记录，ARb100上的40.0%和ARm100上的34.9%。在COCO到UVO总结上，SWORD明显超过了之前最佳的开放世界模型，APm上提高了5.9%和ARm100上提高了8.1%。
</details></li>
</ul>
<hr>
<h2 id="D3G-Exploring-Gaussian-Prior-for-Temporal-Sentence-Grounding-with-Glance-Annotation"><a href="#D3G-Exploring-Gaussian-Prior-for-Temporal-Sentence-Grounding-with-Glance-Annotation" class="headerlink" title="D3G: Exploring Gaussian Prior for Temporal Sentence Grounding with Glance Annotation"></a>D3G: Exploring Gaussian Prior for Temporal Sentence Grounding with Glance Annotation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04197">http://arxiv.org/abs/2308.04197</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hanjun Li, Xiujun Shu, Sunan He, Ruizhi Qiao, Wei Wen, Taian Guo, Bei Gan, Xing Sun</li>
<li>for: 本研究旨在降低TSG任务中注意力标注成本，保持与完全监督方法相匹配的性能。</li>
<li>methods: 我们提出了一种基于Dynamic Gaussian prior的Grounding框架，包括Semantic Alignment Group Contrastive Learning模块(SA-GCL)和Dynamic Gaussian prior Adjustment模块(DGA)。</li>
<li>results: 我们的D3G方法在三个挑战性 benchmark上进行了广泛的实验，并证明了它的效果性。它与现状的弱监督方法相比，提高了性能的大幅度，并降低了与完全监督方法的性能差距。<details>
<summary>Abstract</summary>
Temporal sentence grounding (TSG) aims to locate a specific moment from an untrimmed video with a given natural language query. Recently, weakly supervised methods still have a large performance gap compared to fully supervised ones, while the latter requires laborious timestamp annotations. In this study, we aim to reduce the annotation cost yet keep competitive performance for TSG task compared to fully supervised ones. To achieve this goal, we investigate a recently proposed glance-supervised temporal sentence grounding task, which requires only single frame annotation (referred to as glance annotation) for each query. Under this setup, we propose a Dynamic Gaussian prior based Grounding framework with Glance annotation (D3G), which consists of a Semantic Alignment Group Contrastive Learning module (SA-GCL) and a Dynamic Gaussian prior Adjustment module (DGA). Specifically, SA-GCL samples reliable positive moments from a 2D temporal map via jointly leveraging Gaussian prior and semantic consistency, which contributes to aligning the positive sentence-moment pairs in the joint embedding space. Moreover, to alleviate the annotation bias resulting from glance annotation and model complex queries consisting of multiple events, we propose the DGA module, which adjusts the distribution dynamically to approximate the ground truth of target moments. Extensive experiments on three challenging benchmarks verify the effectiveness of the proposed D3G. It outperforms the state-of-the-art weakly supervised methods by a large margin and narrows the performance gap compared to fully supervised methods. Code is available at https://github.com/solicucu/D3G.
</details>
<details>
<summary>摘要</summary>
Temporal sentence grounding (TSG) 目标是在没有剪辑的视频中定位一个具体的时刻，与一个自然语言查询符对应。Recently, weakly supervised methods 仍然与完全监督的方法之间存在大量性能差距，而后者需要劳动密集的时间戳注解。在这种研究中，我们想要降低注解成本， yet keep competitive performance for TSG task compared to fully supervised ones。To achieve this goal, we investigate a recently proposed glance-supervised temporal sentence grounding task, which requires only single frame annotation (referred to as glance annotation) for each query。Under this setup, we propose a Dynamic Gaussian prior based Grounding framework with Glance annotation (D3G), which consists of a Semantic Alignment Group Contrastive Learning module (SA-GCL) and a Dynamic Gaussian prior Adjustment module (DGA). Specifically, SA-GCL samples reliable positive moments from a 2D temporal map via jointly leveraging Gaussian prior and semantic consistency, which contributes to aligning the positive sentence-moment pairs in the joint embedding space。Moreover, to alleviate the annotation bias resulting from glance annotation and model complex queries consisting of multiple events, we propose the DGA module, which adjusts the distribution dynamically to approximate the ground truth of target moments。Extensive experiments on three challenging benchmarks verify the effectiveness of the proposed D3G。It outperforms the state-of-the-art weakly supervised methods by a large margin and narrows the performance gap compared to fully supervised methods。代码可以在 https://github.com/solicucu/D3G 中找到。
</details></li>
</ul>
<hr>
<h2 id="Image-Copy-Move-Forgery-Detection-via-Deep-Cross-Scale-PatchMatch"><a href="#Image-Copy-Move-Forgery-Detection-via-Deep-Cross-Scale-PatchMatch" class="headerlink" title="Image Copy-Move Forgery Detection via Deep Cross-Scale PatchMatch"></a>Image Copy-Move Forgery Detection via Deep Cross-Scale PatchMatch</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04188">http://arxiv.org/abs/2308.04188</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yingjie He, Yuanman Li, Changsheng Chen, Xia Li</li>
<li>for: 本研究旨在提高图像 копиrighted forgery detection（CMFD）领域的检测精度和普适性。</li>
<li>methods: 本研究提出了一种新的全级图像CMFD框架， combining conventional and deep learning methods。 Specifically, we design a deep cross-scale patchmatch method tailored for CMFD to localize copy-move regions, and develop a manipulation region location branch for source&#x2F;target separation。</li>
<li>results: 我们的方法在不同的复制和移动内容中显示出了显著更高的普适性和性能， compared to existing approaches。<details>
<summary>Abstract</summary>
The recently developed deep algorithms achieve promising progress in the field of image copy-move forgery detection (CMFD). However, they have limited generalizability in some practical scenarios, where the copy-move objects may not appear in the training images or cloned regions are from the background. To address the above issues, in this work, we propose a novel end-to-end CMFD framework by integrating merits from both conventional and deep methods. Specifically, we design a deep cross-scale patchmatch method tailored for CMFD to localize copy-move regions. In contrast to existing deep models, our scheme aims to seek explicit and reliable point-to-point matching between source and target regions using features extracted from high-resolution scales. Further, we develop a manipulation region location branch for source/target separation. The proposed CMFD framework is completely differentiable and can be trained in an end-to-end manner. Extensive experimental results demonstrate the high generalizability of our method to different copy-move contents, and the proposed scheme achieves significantly better performance than existing approaches.
</details>
<details>
<summary>摘要</summary>
最近发展的深度算法在图像复制移动伪造检测（CMFD）领域具有承诺的进步。然而，这些深度算法在一些实际场景中具有有限的通用性，例如在训练图像中没有复制移动对象或者径复制区域来自背景。为了解决上述问题，在这项工作中，我们提出了一种新的端到端CMFD框架，通过结合传统和深度方法的优点。具体来说，我们设计了一种适合CMFD的深度跨scale patchmatch方法，以便在本地化复制移动区域。与现有的深度模型不同，我们的方案寻求明确和可靠的点对点匹配 между源和目标区域，使用高分辨率层次中提取的特征。此外，我们开发了一个修改区域定位分支，用于源/目标分离。我们提出的CMFD框架是完全可导的，可以在端到端的训练方式下进行培训。广泛的实验结果表明，我们的方法具有不同复制移动内容的高通用性，并且我们提出的方案在现有方法中显著提高了性能。
</details></li>
</ul>
<hr>
<h2 id="How-Generalizable-are-Deepfake-Detectors-An-Empirical-Study"><a href="#How-Generalizable-are-Deepfake-Detectors-An-Empirical-Study" class="headerlink" title="How Generalizable are Deepfake Detectors? An Empirical Study"></a>How Generalizable are Deepfake Detectors? An Empirical Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04177">http://arxiv.org/abs/2308.04177</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/boutiquelee/deepfakeempiricalstudy">https://github.com/boutiquelee/deepfakeempiricalstudy</a></li>
<li>paper_authors: Boquan Li, Jun Sun, Christopher M. Poskitt</li>
<li>for: 这篇论文旨在探讨深伪材料检测方法的普适性，以帮助检测器在不同的 dataset 上保持一步 ahead of 害客。</li>
<li>methods: 本论文使用了六个深伪数据集、五种深伪检测方法和两种模型增强方法进行研究。</li>
<li>results: 研究发现，检测器在零 shot 设定下不能普适化，并且发现检测器学习了特定的合成方法的不良特征，以及检测器EXTRACTING 缺乏特征，导致普适性受限。然而，研究还发现了一些通用的神经元，可能为零 shot 普适性提供了可能的路径。<details>
<summary>Abstract</summary>
Deepfake videos and images are becoming increasingly credible, posing a significant threat given their potential to facilitate fraud or bypass access control systems. This has motivated the development of deepfake detection methods, in which deep learning models are trained to distinguish between real and synthesized footage. Unfortunately, existing detection models struggle to generalize to deepfakes from datasets they were not trained on, but little work has been done to examine why or how this limitation can be addressed. In this paper, we present the first empirical study on the generalizability of deepfake detectors, an essential goal for detectors to stay one step ahead of attackers. Our study utilizes six deepfake datasets, five deepfake detection methods, and two model augmentation approaches, confirming that detectors do not generalize in zero-shot settings. Additionally, we find that detectors are learning unwanted properties specific to synthesis methods and struggling to extract discriminative features, limiting their ability to generalize. Finally, we find that there are neurons universally contributing to detection across seen and unseen datasets, illuminating a possible path forward to zero-shot generalizability.
</details>
<details>
<summary>摘要</summary>
深刻的假动作和图像在增加可信度方面做出了重要贡献，它们的潜在威胁包括诈骗和绕过存取控制系统。这些问题驱使了深入学习检测方法的发展，这些模型通过训练来识别真实和合成的录影。可是，现有的检测模型在不同的数据集上缺乏通用性，但有很少的研究探讨这个限制和如何解决。在这篇论文中，我们提供了深入探讨检测器通用性的首个实践研究，这是检测器要一步拦截到诈骗者的重要目标。我们的研究使用了六个深刻假数据集，五个深刻检测方法和两种模型增强方法，确定了检测器在零点设定下不具通用性。此外，我们发现检测器在合成方法特有的特性上学习不良的特征，导致它们对于新的数据集难以准确检测。最后，我们发现有些神经网络在所有数据集上都具有检测功能，这提供了可能的通用性路径。
</details></li>
</ul>
<hr>
<h2 id="EFaR-2023-Efficient-Face-Recognition-Competition"><a href="#EFaR-2023-Efficient-Face-Recognition-Competition" class="headerlink" title="EFaR 2023: Efficient Face Recognition Competition"></a>EFaR 2023: Efficient Face Recognition Competition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04168">http://arxiv.org/abs/2308.04168</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ahasanpour/EFaR-2023">https://github.com/ahasanpour/EFaR-2023</a></li>
<li>paper_authors: Jan Niklas Kolf, Fadi Boutros, Jurek Elliesen, Markus Theuerkauf, Naser Damer, Mohamad Alansari, Oussama Abdul Hay, Sara Alansari, Sajid Javed, Naoufel Werghi, Klemen Grm, Vitomir Štruc, Fernando Alonso-Fernandez, Kevin Hernandez Diaz, Josef Bigun, Anjith George, Christophe Ecabert, Hatef Otroshi Shahreza, Ketan Kotwal, Sébastien Marcel, Iurii Medvedev, Bo Jin, Diogo Nunes, Ahmad Hassanpour, Pankaj Khatiwada, Aafan Ahmad Toor, Bian Yang</li>
<li>for: 这篇论文主要是为了介绍2023年国际 JOINT会议 on Biometrics (IJCB 2023) 上进行的人脸认可竞赛（EFaR），以及参与竞赛的6个队伍的17个提交。</li>
<li>methods:  submitted solutions 使用了小型、高效的网络架构，以减少计算成本，一些解决方案还应用了模型归一化。</li>
<li>results: 论文评估了提交的解决方案的表现，以及一些基eline的测试数据集上的比较性能。 Here’s the English version of the three key information points:</li>
<li>for: The paper mainly introduces the Efficient Face Recognition Competition (EFaR) held at the 2023 International Joint Conference on Biometrics (IJCB 2023), as well as the 6 teams that participated in the competition with 17 submissions.</li>
<li>methods: The submitted solutions use small, efficient network architectures to reduce computational cost, and some solutions apply model quantization.</li>
<li>results: The paper evaluates the performance of the submitted solutions and compares them to a set of baselines on a diverse set of benchmarks, including bias, cross-quality, and large-scale recognition.<details>
<summary>Abstract</summary>
This paper presents the summary of the Efficient Face Recognition Competition (EFaR) held at the 2023 International Joint Conference on Biometrics (IJCB 2023). The competition received 17 submissions from 6 different teams. To drive further development of efficient face recognition models, the submitted solutions are ranked based on a weighted score of the achieved verification accuracies on a diverse set of benchmarks, as well as the deployability given by the number of floating-point operations and model size. The evaluation of submissions is extended to bias, cross-quality, and large-scale recognition benchmarks. Overall, the paper gives an overview of the achieved performance values of the submitted solutions as well as a diverse set of baselines. The submitted solutions use small, efficient network architectures to reduce the computational cost, some solutions apply model quantization. An outlook on possible techniques that are underrepresented in current solutions is given as well.
</details>
<details>
<summary>摘要</summary>
这篇论文介绍了2023年国际 JOINT Conference on Biometrics（IJCB 2023）上进行的Efficient Face Recognition Competition（EFaR）的结果。比赛接收了6个队伍的17个提交。为了驱动高效人脸识别模型的进一步发展，提交的解决方案按照使用多个benchmark上达到的验证精度的权重分数、以及模型的大小和浮点数据操作数量来进行排名。评测中还包括偏见、交叉评估和大规模识别的benchmark。总的来说，本文给出了提交的解决方案的实际性和多个基准值的概述，以及一些未在当前解决方案中充分表现的可能的技术。
</details></li>
</ul>
<hr>
<h2 id="Under-Display-Camera-Image-Restoration-with-Scattering-Effect"><a href="#Under-Display-Camera-Image-Restoration-with-Scattering-Effect" class="headerlink" title="Under-Display Camera Image Restoration with Scattering Effect"></a>Under-Display Camera Image Restoration with Scattering Effect</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04163">http://arxiv.org/abs/2308.04163</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/namecantbenull/srudc">https://github.com/namecantbenull/srudc</a></li>
<li>paper_authors: Binbin Song, Xiangyu Chen, Shuning Xu, Jiantao Zhou</li>
<li>for:  addresses the under-display camera (UDC) image restoration problem with a specific focus on the scattering effect caused by the display.</li>
<li>methods:  uses a two-branch restoration network, including a scattering branch that uses channel-wise self-attention to estimate the scattering effect parameters, and an image branch that leverages local representation advantages of CNN to recover clear scenes.</li>
<li>results:  demonstrates superior performance over state-of-the-art UDC restoration techniques through extensive experiments on both real-world and synthesized data.Here’s the summary in Traditional Chinese:</li>
<li>for:  addresses the 下层显示器（UDC）的图像修复问题，专注在显示器对图像的散射效应。</li>
<li>methods: 使用了两条分支修复网络，包括散射分支，使用通道别自我注意来估算散射效应的参数，以及图像分支，利用图像网络的地方表现优势来修复清晰的场景。</li>
<li>results: 通过对真实世界和合成数据进行广泛的实验，证明了提案方法与现有的UDC修复技术相比，具有较好的性能。<details>
<summary>Abstract</summary>
The under-display camera (UDC) provides consumers with a full-screen visual experience without any obstruction due to notches or punched holes. However, the semi-transparent nature of the display inevitably introduces the severe degradation into UDC images. In this work, we address the UDC image restoration problem with the specific consideration of the scattering effect caused by the display. We explicitly model the scattering effect by treating the display as a piece of homogeneous scattering medium. With the physical model of the scattering effect, we improve the image formation pipeline for the image synthesis to construct a realistic UDC dataset with ground truths. To suppress the scattering effect for the eventual UDC image recovery, a two-branch restoration network is designed. More specifically, the scattering branch leverages global modeling capabilities of the channel-wise self-attention to estimate parameters of the scattering effect from degraded images. While the image branch exploits the local representation advantage of CNN to recover clear scenes, implicitly guided by the scattering branch. Extensive experiments are conducted on both real-world and synthesized data, demonstrating the superiority of the proposed method over the state-of-the-art UDC restoration techniques. The source code and dataset are available at \url{https://github.com/NamecantbeNULL/SRUDC}.
</details>
<details>
<summary>摘要</summary>
“Under-display camera（UDC）为用户提供了一个无阻碍的全屏视觉体验，但是半透明的显示器无法避免对UDC图像的严重抑制。在这种情况下，我们在UDC图像恢复问题上进行了专门的考虑，并模型了由显示器引起的散射效应。我们通过物理模型来描述散射效应，并对图像形成管线进行了改进，以建立一个真实的UDC数据集。为了减少散射效应的影响，我们设计了两棵树结构，其中一棵是散射分支，利用通道级自注意力来估计散射效应的参数，另一棵是图像分支，利用深度学习来恢复清晰的场景。我们在实际数据上进行了广泛的实验，并证明了我们的方法在UDC图像恢复问题上的优越性。数据集和源代码可以在 GitHub 上获取（https://github.com/NamecantbeNULL/SRUDC）。”
</details></li>
</ul>
<hr>
<h2 id="EPCFormer-Expression-Prompt-Collaboration-Transformer-for-Universal-Referring-Video-Object-Segmentation"><a href="#EPCFormer-Expression-Prompt-Collaboration-Transformer-for-Universal-Referring-Video-Object-Segmentation" class="headerlink" title="EPCFormer: Expression Prompt Collaboration Transformer for Universal Referring Video Object Segmentation"></a>EPCFormer: Expression Prompt Collaboration Transformer for Universal Referring Video Object Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04162">http://arxiv.org/abs/2308.04162</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/lab206/epcformer">https://github.com/lab206/epcformer</a></li>
<li>paper_authors: Jiajun Chen, Jiacheng Lin, Zhiqiang Xiao, Haolong Fu, Ke Nai, Kailun Yang, Zhiyong Li</li>
<li>for: 这个论文主要针对的是Audio-guided Video Object Segmentation (A-VOS)和Referring Video Object Segmentation (R-VOS)两个关联任务，它们都是根据用户提供的表达提示从视频序列中提取特定对象的任务。</li>
<li>methods: 这篇论文提出了两种解决方案，一是对话表达匹配（EA）机制，用于Audio和Text表达之间的匹配，以实现语音和文本表达之间的含义相似性。另一个是表达视觉注意力（EVA）机制，用于深入探究Audio、Text和视频特征之间的互动。</li>
<li>results: 实验结果表明，我们提出的通用EPCFormer模型在两个任务上都达到了状态的艺术Result，并且可以很好地传递知识 между两个任务。<details>
<summary>Abstract</summary>
Audio-guided Video Object Segmentation (A-VOS) and Referring Video Object Segmentation (R-VOS) are two highly-related tasks, which both aim to segment specific objects from video sequences according to user-provided expression prompts. However, due to the challenges in modeling representations for different modalities, contemporary methods struggle to strike a balance between interaction flexibility and high-precision localization and segmentation. In this paper, we address this problem from two perspectives: the alignment representation of audio and text and the deep interaction among audio, text, and visual features. First, we propose a universal architecture, the Expression Prompt Collaboration Transformer, herein EPCFormer. Next, we propose an Expression Alignment (EA) mechanism for audio and text expressions. By introducing contrastive learning for audio and text expressions, the proposed EPCFormer realizes comprehension of the semantic equivalence between audio and text expressions denoting the same objects. Then, to facilitate deep interactions among audio, text, and video features, we introduce an Expression-Visual Attention (EVA) mechanism. The knowledge of video object segmentation in terms of the expression prompts can seamlessly transfer between the two tasks by deeply exploring complementary cues between text and audio. Experiments on well-recognized benchmarks demonstrate that our universal EPCFormer attains state-of-the-art results on both tasks. The source code of EPCFormer will be made publicly available at https://github.com/lab206/EPCFormer.
</details>
<details>
<summary>摘要</summary>
Audio-guided Video Object Segmentation (A-VOS) 和 Referring Video Object Segmentation (R-VOS) 是两个高度相关的任务，它们都是根据用户提供的表达提示来从视频序列中 segment 特定对象。然而，由于不同模式之间的表达模型化困难，当前方法很难以寻求高精度地位和表达提示之间的平衡。在这篇论文中，我们解决这个问题从两个方面：表达提示的对齐表示和深度交互 among audio、文本和视觉特征。首先，我们提出一种通用架构，即表达Prompt Collaboration Transformer（EPCFormer）。然后，我们提出一种表达对齐（EA）机制，用于对 audio 和文本表达进行对齐。通过引入对 audio 和文本表达的对比学习，我们实现了对 audio 和文本表达的Semantic equivalence的认知。然后，为了促进 audio、文本和视觉特征之间的深度交互，我们引入表达-视觉注意力（EVA）机制。通过深入探索 audio、文本和视觉特征之间的 complementary cues，我们实现了从表达提示角度看到的视频对象分割知识的交叉传递。实验结果表明，我们的通用 EPCFormer 在两个任务上达到了状态艺术的Result。源代码将在 GitHub 上公开，详细信息请参考 <https://github.com/lab206/EPCFormer>。
</details></li>
</ul>
<hr>
<h2 id="Towards-Top-Down-Stereoscopic-Image-Quality-Assessment-via-Stereo-Attention"><a href="#Towards-Top-Down-Stereoscopic-Image-Quality-Assessment-via-Stereo-Attention" class="headerlink" title="Towards Top-Down Stereoscopic Image Quality Assessment via Stereo Attention"></a>Towards Top-Down Stereoscopic Image Quality Assessment via Stereo Attention</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04156">http://arxiv.org/abs/2308.04156</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fanning-zhang/satnet">https://github.com/fanning-zhang/satnet</a></li>
<li>paper_authors: Huilin Zhang, Sumei Li, Yongli Chang</li>
<li>for: 这篇论文的目的是提出一种基于顶部下向的图像三维质量评估（SIQA）网络，以更好地评估和改进3D内容的视觉体验。</li>
<li>methods: 该论文提出了一种新的网络方法，即通过层次注意力（Stereo Attention）来实现顶部下向的评估过程。该方法可以从高级二视图信号下到低级单视图信号的进程中进行导引，并在处理管道中进行可调calibration。</li>
<li>results: 实验结果表明，该方法可以更好地模拟人类视觉系统（HVS）的性质，并超越现有的底层方法。<details>
<summary>Abstract</summary>
Stereoscopic image quality assessment (SIQA) plays a crucial role in evaluating and improving the visual experience of 3D content. Existing binocular properties and attention-based methods for SIQA have achieved promising performance. However, these bottom-up approaches are inadequate in exploiting the inherent characteristics of the human visual system (HVS). This paper presents a novel network for SIQA via stereo attention, employing a top-down perspective to guide the quality assessment process. Our proposed method realizes the guidance from high-level binocular signals down to low-level monocular signals, while the binocular and monocular information can be calibrated progressively throughout the processing pipeline. We design a generalized Stereo AttenTion (SAT) block to implement the top-down philosophy in stereo perception. This block utilizes the fusion-generated attention map as a high-level binocular modulator, influencing the representation of two low-level monocular features. Additionally, we introduce an Energy Coefficient (EC) to account for recent findings indicating that binocular responses in the primate primary visual cortex are less than the sum of monocular responses. The adaptive EC can tune the magnitude of binocular response flexibly, thus enhancing the formation of robust binocular features within our framework. To extract the most discriminative quality information from the summation and subtraction of the two branches of monocular features, we utilize a dual-pooling strategy that applies min-pooling and max-pooling operations to the respective branches. Experimental results highlight the superiority of our top-down method in simulating the property of visual perception and advancing the state-of-the-art in the SIQA field. The code of this work is available at https://github.com/Fanning-Zhang/SATNet.
</details>
<details>
<summary>摘要</summary>
三维内容的视觉体验评估（SIQA）具有重要的作用，用于评估和改进三维内容的视觉体验。现有的底层方法和双目性质具有承诺的表现。然而，这些底层方法无法充分利用人视系统（HVS）的内在特性。这篇论文提出了一种新的网络方法 для SIQA，通过双目注意力来导引评估过程。我们的提议方法可以从高级双目信号下降到低级单目信号，同时双目和单目信息可以在处理管道中进行进度性calibration。我们设计了一种通用的双目注意力块（SAT）来实现上述哲学。这个块利用生成的注意力地图作为高级双目模ulator，影响低级单目特征表示。此外，我们引入了能量系数（EC），以应对证明 primate primary visual cortex中的双目响应小于单目响应的现象。可变的EC可以适应性地调整双目响应的 магнитуда，以便在我们的框架中成形Robust的双目特征。为了从两个支路的单目特征之和和差中提取最有价值的质量信息，我们采用了双pooling策略，对两个支路的单目特征进行最小池化和最大池化操作。实验结果表明，我们的底层方法可以准确模拟视觉响应和提高SIQA领域的状态。代码可以在 <https://github.com/Fanning-Zhang/SATNet> 中找到。
</details></li>
</ul>
<hr>
<h2 id="Empowering-Vision-Language-Models-to-Follow-Interleaved-Vision-Language-Instructions"><a href="#Empowering-Vision-Language-Models-to-Follow-Interleaved-Vision-Language-Instructions" class="headerlink" title="Empowering Vision-Language Models to Follow Interleaved Vision-Language Instructions"></a>Empowering Vision-Language Models to Follow Interleaved Vision-Language Instructions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04152">http://arxiv.org/abs/2308.04152</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dcdmllm/cheetah">https://github.com/dcdmllm/cheetah</a></li>
<li>paper_authors: Juncheng Li, Kaihang Pan, Zhiqi Ge, Minghe Gao, Hanwang Zhang, Wei Ji, Wenqiao Zhang, Tat-Seng Chua, Siliang Tang, Yueting Zhuang<br>for: 这个论文旨在�evaluating the instruction following ability of multimodal large language models (MLLMs) on complicated interleaved vision-language instructions, and introducing a generic and lightweight controllable knowledge re-injection module to address the common defect of existing methods.methods: The proposed method utilizes a controllable knowledge re-injection module that leverages the sophisticated reasoning ability of LLMs to conditionally extract instruction-specific visual information and re-inject it into the LLM. The module is learned using an annotation-free cross-attention guided counterfactual image training strategy that collaborates a cascade of foundation models.results: The proposed method achieves state-of-the-art zero-shot performance across all tasks of I4, without high-quality multimodal instruction tuning data. Cheetor also exhibits competitive performance compared with state-of-the-art instruction tuned models on MME benchmark.<details>
<summary>Abstract</summary>
Multimodal Large Language Models (MLLMs) have recently sparked significant interest, which demonstrates emergent capabilities to serve as a general-purpose model for various vision-language tasks. However, existing methods mainly focus on limited types of instructions with a single image as visual context, which hinders the widespread availability of MLLMs. In this paper, we introduce the I4 benchmark to comprehensively evaluate the instruction following ability on complicated interleaved vision-language instructions, which involve intricate image-text sequential context, covering a diverse range of scenarios (e.g., visually-rich webpages/textbooks, lecture slides, embodied dialogue). Systematic evaluation on our I4 benchmark reveals a common defect of existing methods: the Visual Prompt Generator (VPG) trained on image-captioning alignment objective tends to attend to common foreground information for captioning but struggles to extract specific information required by particular tasks. To address this issue, we propose a generic and lightweight controllable knowledge re-injection module, which utilizes the sophisticated reasoning ability of LLMs to control the VPG to conditionally extract instruction-specific visual information and re-inject it into the LLM. Further, we introduce an annotation-free cross-attention guided counterfactual image training strategy to methodically learn the proposed module by collaborating a cascade of foundation models. Enhanced by the proposed module and training strategy, we present Cheetor, a Transformer-based MLLM that can effectively handle a wide variety of interleaved vision-language instructions and achieves state-of-the-art zero-shot performance across all tasks of I4, without high-quality multimodal instruction tuning data. Cheetor also exhibits competitive performance compared with state-of-the-art instruction tuned models on MME benchmark.
</details>
<details>
<summary>摘要</summary>
大量多模态语言模型 (MLLMs) 在最近吸引了广泛的关注，这表明它们在多种视觉语言任务上表现出了总体的多功能性。然而，现有的方法主要集中在有限的类型的指令上，使得 MLMMs 的普及性受限。在这篇论文中，我们介绍了 I4 benchmark，用于全面评估 MLMMs 对于复杂的交叠视觉语言指令的遵循能力。系统性的评估表明，现有的方法存在一种普遍的缺陷：使用图像captioning对应目标训练的视觉提示生成器 (VPG) 往往会强调通用的前景信息，但是忽略特定任务所需的具体信息。为解决这一问题，我们提出了一种通用且轻量级的可控知识重新注入模块，该模块利用 LLMS 的复杂逻辑能力来控制 VPG，将特定任务所需的视觉信息从 LLMS 中提取出来，并重新注入到 LLMS 中。此外，我们提出了一种无需注意标注的横向关注帮助的反向图像培训策略，用于系统地学习该模块。通过该模块和培训策略，我们提出了一种基于转换器的 MLLM ，称为 Cheetor，可以有效地处理各种交叠视觉语言指令，并在 I4 测试benchmark上达到零基eline性能，不需要高质量的多媒体指令调整数据。此外，Cheetor 还与状态当前的指令调整模型在 MME 测试benchmark上表现竞争力。
</details></li>
</ul>
<hr>
<h2 id="Application-for-White-Spot-Syndrome-Virus-WSSV-Monitoring-using-Edge-Machine-Learning"><a href="#Application-for-White-Spot-Syndrome-Virus-WSSV-Monitoring-using-Edge-Machine-Learning" class="headerlink" title="Application for White Spot Syndrome Virus (WSSV) Monitoring using Edge Machine Learning"></a>Application for White Spot Syndrome Virus (WSSV) Monitoring using Edge Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04151">http://arxiv.org/abs/2308.04151</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lorenzo S. Querol, Macario O. Cordel II, Dan Jeric A. Rustia, Mary Nia M. Santos</li>
<li>for: This paper aims to improve disease surveillance in the aquaculture industry, specifically for the White Spot Syndrome Virus (WSSV), by developing a mobile application and training a WSSV recognition model using computer vision techniques.</li>
<li>methods: The authors developed a mobile application to collect and monitor data, and trained two models (MobileNetV3-Small and EfficientNetV2-B0) using an imbalanced dataset to improve WSSV recognition. They also analyzed the saliency heatmaps of both models to understand the features that are most important in making a prediction.</li>
<li>results: The models achieved an F1-Score of 0.72 and 0.99, respectively, and the saliency heatmaps revealed the features that are most important in the images for making a correct prediction. The results demonstrate the effectiveness of using computer vision techniques for WSSV recognition, but also highlight the limitations of using resource-constrained devices and the need for further improvement.<details>
<summary>Abstract</summary>
The aquaculture industry, strongly reliant on shrimp exports, faces challenges due to viral infections like the White Spot Syndrome Virus (WSSV) that severely impact output yields. In this context, computer vision can play a significant role in identifying features not immediately evident to skilled or untrained eyes, potentially reducing the time required to report WSSV infections. In this study, the challenge of limited data for WSSV recognition was addressed. A mobile application dedicated to data collection and monitoring was developed to facilitate the creation of an image dataset to train a WSSV recognition model and improve country-wide disease surveillance. The study also includes a thorough analysis of WSSV recognition to address the challenge of imbalanced learning and on-device inference. The models explored, MobileNetV3-Small and EfficientNetV2-B0, gained an F1-Score of 0.72 and 0.99 respectively. The saliency heatmaps of both models were also observed to uncover the "black-box" nature of these models and to gain insight as to what features in the images are most important in making a prediction. These results highlight the effectiveness and limitations of using models designed for resource-constrained devices and balancing their performance in accurately recognizing WSSV, providing valuable information and direction in the use of computer vision in this domain.
</details>
<details>
<summary>摘要</summary>
鱼养业，强调虾 экспор特别是，面临病毒感染的挑战，如白点综合病毒（WSSV），这会严重影响产量。在这种情况下，计算机视觉可以发挥重要的作用，可以帮助找到不直观或未经训练的目的不可见的特征，从而减少WSSV感染的报告时间。本研究的挑战是有限的数据，用于WSSV识别的模型训练。为解决这个问题，我们开发了一款专门用于数据采集和监测的移动应用程序，以便创建一个用于训练WSSV识别模型的图像数据集。本研究还包括了WSSV识别的全面分析，以解决模型学习的偏袋问题和设备上的推理。我们检查了两种模型，MobileNetV3-Small和EfficientNetV2-B0，它们的F1分数分别为0.72和0.99。我们还研究了这两个模型的精度热图，以了解这些模型在图像中的哪些特征是最重要的，以及它们如何影响模型的预测结果。这些结果显示了使用特定的资源限制的设备上的模型的效果和局限性，以及在精度地识别WSSV的方面的价值信息和指导。
</details></li>
</ul>
<hr>
<h2 id="Class-level-Structural-Relation-Modelling-and-Smoothing-for-Visual-Representation-Learning"><a href="#Class-level-Structural-Relation-Modelling-and-Smoothing-for-Visual-Representation-Learning" class="headerlink" title="Class-level Structural Relation Modelling and Smoothing for Visual Representation Learning"></a>Class-level Structural Relation Modelling and Smoothing for Visual Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04142">http://arxiv.org/abs/2308.04142</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/czt117/csrms">https://github.com/czt117/csrms</a></li>
<li>paper_authors: Zitan Chen, Zhuang Qi, Xiao Cao, Xiangxian Li, Xiangxu Meng, Lei Meng</li>
<li>for: 这篇论文主要targets the problem of visual representation learning, particularly when dealing with classes that have diverse visual patterns.</li>
<li>methods: 这篇论文提出了一个框架，named CSRMS，which includes three modules: Class-level Relation Modelling, Class-aware Graph Sampling, and Relational Graph-Guided Representation Learning. These modules aim to model a relational graph of the entire dataset and perform class-aware smoothing and regularization operations to alleviate the issue of intra-class visual diversity and inter-class similarity.</li>
<li>results: 实验结果显示，CSRMS可以将结构知识模型化到图像表现学中，提高表现学模型的性能。此外，CSRMS可以与现有的最佳表现学模型结合使用，实现表现学模型的性能提升。<details>
<summary>Abstract</summary>
Representation learning for images has been advanced by recent progress in more complex neural models such as the Vision Transformers and new learning theories such as the structural causal models. However, these models mainly rely on the classification loss to implicitly regularize the class-level data distributions, and they may face difficulties when handling classes with diverse visual patterns. We argue that the incorporation of the structural information between data samples may improve this situation. To achieve this goal, this paper presents a framework termed \textbf{C}lass-level Structural Relation Modeling and Smoothing for Visual Representation Learning (CSRMS), which includes the Class-level Relation Modelling, Class-aware Graph Sampling, and Relational Graph-Guided Representation Learning modules to model a relational graph of the entire dataset and perform class-aware smoothing and regularization operations to alleviate the issue of intra-class visual diversity and inter-class similarity. Specifically, the Class-level Relation Modelling module uses a clustering algorithm to learn the data distributions in the feature space and identify three types of class-level sample relations for the training set; Class-aware Graph Sampling module extends typical training batch construction process with three strategies to sample dataset-level sub-graphs; and Relational Graph-Guided Representation Learning module employs a graph convolution network with knowledge-guided smoothing operations to ease the projection from different visual patterns to the same class. Experiments demonstrate the effectiveness of structured knowledge modelling for enhanced representation learning and show that CSRMS can be incorporated with any state-of-the-art visual representation learning models for performance gains. The source codes and demos have been released at https://github.com/czt117/CSRMS.
</details>
<details>
<summary>摘要</summary>
“图像表现学已经由最近的更进步的神经网络模型，如视图变换器和新的学习理论，如结构 causal 模型，所进步。但这些模型主要靠 классификаtion 损失来隐式训练数据分布，可能在处理多标的视觉模式时遇到问题。我们认为将数据样本之间的结构信息纳入模型中可以改善这个情况。为此，这篇论文提出了一个名为 Class-level Structural Relation Modeling and Smoothing for Visual Representation Learning（CSRMS）的框架，包括 Class-level Relation Modelling、Class-aware Graph Sampling 和 Relational Graph-Guided Representation Learning 三个模块。这些模块的目的是建立数据集的关系图，并通过阶段调整和缓和操作来缓和内部分类视觉多样性和相似性。具体来说，Class-level Relation Modelling 模块使用聚类算法学习数据集的分布在特征空间，并识别出三种类别水平的样本关系 для训练集; Class-aware Graph Sampling 模块延伸了传统的训练批次建构过程，使用三种策略来抽样数据集; Relational Graph-Guided Representation Learning 模块运用了图像 convolution 网络和知识导向缓和操作来将不同的视觉模式转换为同一个类别。实验结果显示结构知识模型可以帮助提高图像表现学，并证明 CSRMS 可以与任何现有的图像表现学模型结合使用，以获得性能提升。CSRMS 的源代码和示例已经发布在 GitHub 上（https://github.com/czt117/CSRMS）。”
</details></li>
</ul>
<hr>
<h2 id="Comprehensive-Assessment-of-the-Performance-of-Deep-Learning-Classifiers-Reveals-a-Surprising-Lack-of-Robustness"><a href="#Comprehensive-Assessment-of-the-Performance-of-Deep-Learning-Classifiers-Reveals-a-Surprising-Lack-of-Robustness" class="headerlink" title="Comprehensive Assessment of the Performance of Deep Learning Classifiers Reveals a Surprising Lack of Robustness"></a>Comprehensive Assessment of the Performance of Deep Learning Classifiers Reveals a Surprising Lack of Robustness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04137">http://arxiv.org/abs/2308.04137</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael W. Spratling</li>
<li>for: The paper aims to evaluate the robustness of machine learning models, specifically deep neural networks, and to develop a benchmark for comprehensive evaluation of performance.</li>
<li>methods: The paper proposes using a wide range of different types of data to benchmark performance and using a single metric to produce a consistent evaluation of performance.</li>
<li>results: The paper finds that current deep neural networks are extremely vulnerable to making mistakes on certain types of data, and that they are insecure and unreliable in real-world scenarios where they may encounter data from many different domains.Here’s the Chinese translation of the three points:</li>
<li>for: 这篇论文的目的是评估机器学习模型（尤其是深度神经网络）的可靠性和可靠性评估方法。</li>
<li>methods: 论文提议使用多种不同类型的数据来评估性能，并使用单一指标来生成一致的评估结果。</li>
<li>results: 论文发现现有的深度神经网络在某些类型的数据上很容易出错，并且在实际场景中，它们可能会遇到多种不同的预测任务，因此它们是不可靠的。<details>
<summary>Abstract</summary>
Reliable and robust evaluation methods are a necessary first step towards developing machine learning models that are themselves robust and reliable. Unfortunately, current evaluation protocols typically used to assess classifiers fail to comprehensively evaluate performance as they tend to rely on limited types of test data, and ignore others. For example, using the standard test data fails to evaluate the predictions made by the classifier to samples from classes it was not trained on. On the other hand, testing with data containing samples from unknown classes fails to evaluate how well the classifier can predict the labels for known classes. This article advocates bench-marking performance using a wide range of different types of data and using a single metric that can be applied to all such data types to produce a consistent evaluation of performance. Using such a benchmark it is found that current deep neural networks, including those trained with methods that are believed to produce state-of-the-art robustness, are extremely vulnerable to making mistakes on certain types of data. This means that such models will be unreliable in real-world scenarios where they may encounter data from many different domains, and that they are insecure as they can easily be fooled into making the wrong decisions. It is hoped that these results will motivate the wider adoption of more comprehensive testing methods that will, in turn, lead to the development of more robust machine learning methods in the future.   Code is available at: \url{https://codeberg.org/mwspratling/RobustnessEvaluation}
</details>
<details>
<summary>摘要</summary>
可靠且稳定的评估方法是开发机器学习模型的必要第一步。然而，当前的评估协议通常只使用有限的测试数据来评估类ifiers的性能，而忽略其他类型的测试数据。例如，使用标准测试数据不能评估类ifiers对未知类型数据的预测性能。相反，使用包含未知类型数据的测试数据则不能评估类ifiers对已知类型数据的预测性能。这篇文章提出了使用多种不同类型的数据进行比较性能的方法，并使用一个统一的指标来评估所有数据类型的性能。使用这种标准，发现现有的深度神经网络，包括由其它方法训练的神经网络，在某些数据类型上存在极大的敏感性和容易被骗的问题。这意味着这些模型在实际场景中可能会出现问题，并且它们是不安全的，因为它们可以轻松地被骗到错误决策。希望这些结果能够激励更广泛的测试方法的采用，以便在未来开发更加稳定的机器学习方法。Code可以在以下链接获取：<https://codeberg.org/mwspratling/RobustnessEvaluation>
</details></li>
</ul>
<hr>
<h2 id="OmniDataComposer-A-Unified-Data-Structure-for-Multimodal-Data-Fusion-and-Infinite-Data-Generation"><a href="#OmniDataComposer-A-Unified-Data-Structure-for-Multimodal-Data-Fusion-and-Infinite-Data-Generation" class="headerlink" title="OmniDataComposer: A Unified Data Structure for Multimodal Data Fusion and Infinite Data Generation"></a>OmniDataComposer: A Unified Data Structure for Multimodal Data Fusion and Infinite Data Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04126">http://arxiv.org/abs/2308.04126</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dongyang Yu, Shihao Wang, Yuan Fang, Wangpeng An</li>
<li>for: 这 paper 是为了解决多模态数据融合和无限数据生成问题，以提高人工智能对复杂实际数据的理解和生成能力。</li>
<li>methods: 这 paper 使用了多种操作，包括视频&#x2F;图像描述EXTRACTION、稠密描述EXTRACTION、自动语音识别（ASR）、光学字符识别（OCR）、认知任何模型（RAM）和物体跟踪。</li>
<li>results: 这 paper 的 finale输出将每个视频输入转化成一个详细的时间序列文档，从而使视频变成了详细的故事，使其更易于大语言模型处理。<details>
<summary>Abstract</summary>
This paper presents OmniDataComposer, an innovative approach for multimodal data fusion and unlimited data generation with an intent to refine and uncomplicate interplay among diverse data modalities. Coming to the core breakthrough, it introduces a cohesive data structure proficient in processing and merging multimodal data inputs, which include video, audio, and text.   Our crafted algorithm leverages advancements across multiple operations such as video/image caption extraction, dense caption extraction, Automatic Speech Recognition (ASR), Optical Character Recognition (OCR), Recognize Anything Model(RAM), and object tracking. OmniDataComposer is capable of identifying over 6400 categories of objects, substantially broadening the spectrum of visual information. It amalgamates these diverse modalities, promoting reciprocal enhancement among modalities and facilitating cross-modal data correction. \textbf{The final output metamorphoses each video input into an elaborate sequential document}, virtually transmuting videos into thorough narratives, making them easier to be processed by large language models.   Future prospects include optimizing datasets for each modality to encourage unlimited data generation. This robust base will offer priceless insights to models like ChatGPT, enabling them to create higher quality datasets for video captioning and easing question-answering tasks based on video content. OmniDataComposer inaugurates a new stage in multimodal learning, imparting enormous potential for augmenting AI's understanding and generation of complex, real-world data.
</details>
<details>
<summary>摘要</summary>
The final output transforms each video input into an elaborate sequential document, virtually transmuting videos into thorough narratives that are easier to process by large language models. Future prospects include optimizing datasets for each modality to encourage unlimited data generation, providing priceless insights to models like ChatGPT and enabling them to create higher quality datasets for video captioning. This will ease question-answering tasks based on video content and inaugurate a new stage in multimodal learning, offering enormous potential for augmenting AI's understanding and generation of complex, real-world data.In simplified Chinese, the text would be:这篇论文介绍了 OmniDataComposer，一种创新的多Modal数据融合和无限数据生成方法。核心突破是一种可靠的数据结构，能够高效地处理和融合多Modal数据输入，包括视频、音频和文本。算法利用了多种进步，如视频/图像描述EXTRACTION、稠密描述EXTRACTION、自动语音识别（ASR）、光学字符识别（OCR）、Recognize Anything Model（RAM）和物体跟踪。输出 transformations each video input into an elaborate sequential document， virtually transmuting videos into thorough narratives that are easier to process by large language models。未来的前景包括优化每个模式的数据集，以便无限数据生成。这将为模型如ChatGPT提供无估量的智能，使其创建更高质量的视频描述集和简化基于视频内容的问答任务。OmniDataComposer开启了一个新的多Modal学习阶段，提供了巨大的潜力来增强AI对复杂、实际世界数据的理解和生成。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Color-Recommendation-in-Vector-Graphic-Documents"><a href="#Multimodal-Color-Recommendation-in-Vector-Graphic-Documents" class="headerlink" title="Multimodal Color Recommendation in Vector Graphic Documents"></a>Multimodal Color Recommendation in Vector Graphic Documents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04118">http://arxiv.org/abs/2308.04118</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qianru Qiu, Xueting Wang, Mayu Otani</li>
<li>for: 这个研究旨在提供基于文本 контекст的颜色建议，以帮助设计者选择适合的颜色。</li>
<li>methods: 该模型使用自我注意力网络和 crossed attention网络，以捕捉多个色彩中的关系，并将颜色和文本表示 integrate into one model。</li>
<li>results: 实验结果表明，该方法在准确率、颜色分布和用户体验方面都超过了先前的颜色alette completion方法，同时在全色组生成任务中，其对比 truth palettes 的颜色多样性和相似性也有所提高。<details>
<summary>Abstract</summary>
Color selection plays a critical role in graphic document design and requires sufficient consideration of various contexts. However, recommending appropriate colors which harmonize with the other colors and textual contexts in documents is a challenging task, even for experienced designers. In this study, we propose a multimodal masked color model that integrates both color and textual contexts to provide text-aware color recommendation for graphic documents. Our proposed model comprises self-attention networks to capture the relationships between colors in multiple palettes, and cross-attention networks that incorporate both color and CLIP-based text representations. Our proposed method primarily focuses on color palette completion, which recommends colors based on the given colors and text. Additionally, it is applicable for another color recommendation task, full palette generation, which generates a complete color palette corresponding to the given text. Experimental results demonstrate that our proposed approach surpasses previous color palette completion methods on accuracy, color distribution, and user experience, as well as full palette generation methods concerning color diversity and similarity to the ground truth palettes.
</details>
<details>
<summary>摘要</summary>
颜色选择在图文设计中扮演着关键的角色，需要考虑各种不同的 контекス特。然而，建议合适的颜色，使其融合在其他颜色和文本上下文中，是经验 designer 的挑战。在这个研究中，我们提出了一种多模态假面颜色模型，将多个颜色精灵 integrate 到一起，以提供文本意识 Color 推荐。我们的提议模型包括自我注意力网络，捕捉多个颜色精灵之间的关系，以及 crossed 注意力网络，将颜色和 CLIP 基于的文本表示 incorporate 到一起。我们的提议方法主要关注颜色精灵 completion，根据给定的颜色和文本来推荐颜色。此外，它还适用于另一个颜色推荐任务，全alette generation，生成与给定文本相对应的完整颜色精灵。实验结果表明，我们的提议方法在准确性、颜色分布和用户体验方面，都有所提高，并且在全alette generation 任务中，色彩多样性和真实性与基准 palettes 相比，也有所提高。
</details></li>
</ul>
<hr>
<h2 id="From-Unimodal-to-Multimodal-improving-the-sEMG-Based-Pattern-Recognition-via-deep-generative-models"><a href="#From-Unimodal-to-Multimodal-improving-the-sEMG-Based-Pattern-Recognition-via-deep-generative-models" class="headerlink" title="From Unimodal to Multimodal: improving the sEMG-Based Pattern Recognition via deep generative models"></a>From Unimodal to Multimodal: improving the sEMG-Based Pattern Recognition via deep generative models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04091">http://arxiv.org/abs/2308.04091</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wentao Wei, Linyan Ren</li>
<li>for: 提高手势识别精度</li>
<li>methods: 使用深度生成模型生成虚拟IMU信号，并与真实的EMG信号一起输入多模态Convolutional Neural Network（CNN）模型进行手势识别</li>
<li>results: 对6个数据库进行测试，包括5个公开的数据库和自己收集的数据库，其中28名参与者执行了38种手势，包括EMG和IMU数据，结果表明提议方法比单模态HGR方法（增加2.15%-13.10%）表现更好，这表明通过深度生成模型生成的虚拟IMU信号可以明显提高EMG基于的手势识别精度。<details>
<summary>Abstract</summary>
Multimodal hand gesture recognition (HGR) systems can achieve higher recognition accuracy. However, acquiring multimodal gesture recognition data typically requires users to wear additional sensors, thereby increasing hardware costs. This paper proposes a novel generative approach to improve Surface Electromyography (sEMG)-based HGR accuracy via virtual Inertial Measurement Unit (IMU) signals. Specifically, we trained a deep generative model based on the intrinsic correlation between forearm sEMG signals and forearm IMU signals to generate virtual forearm IMU signals from the input forearm sEMG signals at first. Subsequently, the sEMG signals and virtual IMU signals were fed into a multimodal Convolutional Neural Network (CNN) model for gesture recognition. To evaluate the performance of the proposed approach, we conducted experiments on 6 databases, including 5 publicly available databases and our collected database comprising 28 subjects performing 38 gestures, containing both sEMG and IMU data. The results show that our proposed approach outperforms the sEMG-based unimodal HGR method (with increases of 2.15%-13.10%). It demonstrates that incorporating virtual IMU signals, generated by deep generative models, can significantly enhance the accuracy of sEMG-based HGR. The proposed approach represents a successful attempt to transition from unimodal HGR to multimodal HGR without additional sensor hardware.
</details>
<details>
<summary>摘要</summary>
多模态手势识别（HGR）系统可以提高识别精度。然而，获取多模态手势识别数据通常需要用户穿着额外传感器，从而增加硬件成本。这篇论文提出了一种新的生成方法，用于通过生成虚拟抬肘卫星测量单元（IMU）信号来提高表肘电omyography（sEMG）基于的HGR精度。特别是，我们使用了深度生成模型，根据肘部sEMG信号和肘部IMU信号的内在相关性来生成虚拟肘部IMU信号。然后，sEMG信号和虚拟IMU信号被输入到一个多模态卷积神经网络（CNN）模型中进行手势识别。为评估提案的性能，我们进行了6个数据库的实验，包括5个公共可用的数据库和我们收集的数据库，包含28名参与者进行38种手势，其中包括sEMG和IMU数据。结果表明，我们的提案方法比sEMG基于的单模态HGR方法（增幅1.15%-13.10%）高。这表明，通过深度生成模型生成的虚拟IMU信号可以显著提高sEMG基于的HGR精度。这种方法表明了在不增加额外传感器硬件成本的情况下，从单模态HGR转移到多模态HGR的成功尝试。
</details></li>
</ul>
<hr>
<h2 id="3D-Gaussian-Splatting-for-Real-Time-Radiance-Field-Rendering"><a href="#3D-Gaussian-Splatting-for-Real-Time-Radiance-Field-Rendering" class="headerlink" title="3D Gaussian Splatting for Real-Time Radiance Field Rendering"></a>3D Gaussian Splatting for Real-Time Radiance Field Rendering</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04079">http://arxiv.org/abs/2308.04079</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/graphdeco-inria/gaussian-splatting">https://github.com/graphdeco-inria/gaussian-splatting</a></li>
<li>paper_authors: Bernhard Kerbl, Georgios Kopanas, Thomas Leimkühler, George Drettakis</li>
<li>for: 实现高质量 novel-view 合成，提高 scenes 的完整性和分辨率。</li>
<li>methods: 使用 3D Gaussians 表示 scene，并进行interleaved 优化&#x2F;密度控制，以获得高精度 scene 表示。</li>
<li>results: 实现了 state-of-the-art 的 visual quality 和实时渲染，并且在多个评估 datasets 上达到了领先的Result。<details>
<summary>Abstract</summary>
Radiance Field methods have recently revolutionized novel-view synthesis of scenes captured with multiple photos or videos. However, achieving high visual quality still requires neural networks that are costly to train and render, while recent faster methods inevitably trade off speed for quality. For unbounded and complete scenes (rather than isolated objects) and 1080p resolution rendering, no current method can achieve real-time display rates. We introduce three key elements that allow us to achieve state-of-the-art visual quality while maintaining competitive training times and importantly allow high-quality real-time (>= 30 fps) novel-view synthesis at 1080p resolution. First, starting from sparse points produced during camera calibration, we represent the scene with 3D Gaussians that preserve desirable properties of continuous volumetric radiance fields for scene optimization while avoiding unnecessary computation in empty space; Second, we perform interleaved optimization/density control of the 3D Gaussians, notably optimizing anisotropic covariance to achieve an accurate representation of the scene; Third, we develop a fast visibility-aware rendering algorithm that supports anisotropic splatting and both accelerates training and allows realtime rendering. We demonstrate state-of-the-art visual quality and real-time rendering on several established datasets.
</details>
<details>
<summary>摘要</summary>
“射频场方法”（Radiance Field method）在近期为 novel-view synthesis of captured scenes with multiple photos or videos 进行了革命性的改进。然而，实现高品质仍然需要费时训练和渲染 neural network，而最近的更快的方法则必须牺牲品质来获得速度。对于无限和完整的场景（而不是孤立的物体），以及1080p分辨率的渲染，目前的任何方法都无法在真实时间内进行高品质的novel-view synthesis。我们提出了三个关键的元素，允许我们实现现代化的Visual quality，同时维持竞争性的训练时间和重要的高品质实时（>= 30 fps）novel-view synthesis at 1080p resolution。首先，从摄像机对焦点所生成的稀疏点开始，我们使用3D Gaussians来表示场景，并保留恰当的维度场内散度场的性质，以避免在空间中无需过度计算。第二，我们在3D Gaussians中进行推广/频率控制，特别是对照方差进行最佳化，以确保场景的准确表示。第三，我们开发了一个快速可见性测试的渲染算法，支持标准渲染和实时渲染，并且加速训练和实时渲染。我们在一些已知的测试集上进行了实验，并证明了我们的方法可以实现现代化的Visual quality和高品质的实时渲染。
</details></li>
</ul>
<hr>
<h2 id="Exploiting-Spatial-Temporal-Context-for-Interacting-Hand-Reconstruction-on-Monocular-RGB-Video"><a href="#Exploiting-Spatial-Temporal-Context-for-Interacting-Hand-Reconstruction-on-Monocular-RGB-Video" class="headerlink" title="Exploiting Spatial-Temporal Context for Interacting Hand Reconstruction on Monocular RGB Video"></a>Exploiting Spatial-Temporal Context for Interacting Hand Reconstruction on Monocular RGB Video</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04074">http://arxiv.org/abs/2308.04074</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weichao Zhao, Hezhen Hu, Wengang Zhou, Li li, Houqiang Li</li>
<li>for: 本文旨在提高单摄影像中重构互动手的精度，通过利用空间时间信息来提高互动手的重构效果。</li>
<li>methods: 本文提出了一个新的时间框架，利用时间上下文来补充单摄像头提供的不充分信息，并提出了一个互пенetration检测模块来生成物理合理的互动手。</li>
<li>results: 经验表明，本文提出的方法可以达到新的状态精度水平，在公共测试 benchmark 上实现了最高的表现。<details>
<summary>Abstract</summary>
Reconstructing interacting hands from monocular RGB data is a challenging task, as it involves many interfering factors, e.g. self- and mutual occlusion and similar textures. Previous works only leverage information from a single RGB image without modeling their physically plausible relation, which leads to inferior reconstruction results. In this work, we are dedicated to explicitly exploiting spatial-temporal information to achieve better interacting hand reconstruction. On one hand, we leverage temporal context to complement insufficient information provided by the single frame, and design a novel temporal framework with a temporal constraint for interacting hand motion smoothness. On the other hand, we further propose an interpenetration detection module to produce kinetically plausible interacting hands without physical collisions. Extensive experiments are performed to validate the effectiveness of our proposed framework, which achieves new state-of-the-art performance on public benchmarks.
</details>
<details>
<summary>摘要</summary>
重构互动手 FROM monochrome RGB 数据是一项复杂的任务，因为它们包含许多干扰因素，如自我和相互遮挡，以及类似的 texture。 先前的工作只是利用单个 RGB 图像提供的信息，没有考虑这些物理上的可能的关系，这导致了更差的重建结果。在这项工作中，我们决心显式利用空间-时间信息来实现更好的互动手 reconstruction。一方面，我们利用时间上下文来补充单幅图像中的不足信息，并设计了一个时间框架，以确保互动手动 motion 的平滑性。另一方面，我们进一步提议了一个 penetration 检测模块，以生成物理可能的互动手无碰撞。我们进行了广泛的实验来验证我们的提议的有效性，并实现了公共标准的新高水平性能。
</details></li>
</ul>
<hr>
<h2 id="3D-Scene-Diffusion-Guidance-using-Scene-Graphs"><a href="#3D-Scene-Diffusion-Guidance-using-Scene-Graphs" class="headerlink" title="3D Scene Diffusion Guidance using Scene Graphs"></a>3D Scene Diffusion Guidance using Scene Graphs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04468">http://arxiv.org/abs/2308.04468</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hamnaanaa/3D-Scene-Diffusion-Guidance-using-Scene-Graphs">https://github.com/hamnaanaa/3D-Scene-Diffusion-Guidance-using-Scene-Graphs</a></li>
<li>paper_authors: Mohammad Naanaa, Katharina Schmid, Yinyu Nie</li>
<li>for: 生成高质量3D场景的导航是一项复杂的任务。扩散模型已经显示了可能性，但现有方法直接使用文本嵌入来控制生成，限制了对物体之间复杂的空间关系的吸收。</li>
<li>methods: 我们提议一种使用场景图导航3D场景扩散指导的新方法。我们在杜比纳网络中使用关系图 convolutional块，以利用场景图提供的相对空间信息。</li>
<li>results: 我们的方法可以显著改善场景描述和生成场景之间的对齐。<details>
<summary>Abstract</summary>
Guided synthesis of high-quality 3D scenes is a challenging task. Diffusion models have shown promise in generating diverse data, including 3D scenes. However, current methods rely directly on text embeddings for controlling the generation, limiting the incorporation of complex spatial relationships between objects. We propose a novel approach for 3D scene diffusion guidance using scene graphs. To leverage the relative spatial information the scene graphs provide, we make use of relational graph convolutional blocks within our denoising network. We show that our approach significantly improves the alignment between scene description and generated scene.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将高质量3D场景合成引导为一个挑战性的任务。分散模型已经展示了生成多样数据的潜力，包括3D场景。然而，当前的方法直接基于文本嵌入来控制生成，限制了对物体之间复杂的空间关系的 incorporation。我们提出了一种新的方法，使用场景图导向3D场景扩散指导。为了利用场景图提供的相对空间信息，我们在杂化网络中使用关系图 convolutional块。我们显示，我们的方法可以显著改善场景描述和生成场景之间的对齐。Note: "场景图" (scene graph) refers to a graph that represents the relationships between objects in a scene, and "杂化网络" (denoising network) is a type of neural network that is trained to remove noise from a signal.
</details></li>
</ul>
<hr>
<h2 id="ConDistFL-Conditional-Distillation-for-Federated-Learning-from-Partially-Annotated-Data"><a href="#ConDistFL-Conditional-Distillation-for-Federated-Learning-from-Partially-Annotated-Data" class="headerlink" title="ConDistFL: Conditional Distillation for Federated Learning from Partially Annotated Data"></a>ConDistFL: Conditional Distillation for Federated Learning from Partially Annotated Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04070">http://arxiv.org/abs/2308.04070</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nvidia/nvflare">https://github.com/nvidia/nvflare</a></li>
<li>paper_authors: Pochuan Wang, Chen Shen, Weichung Wang, Masahiro Oda, Chiou-Shann Fuh, Kensaku Mori, Holger R. Roth</li>
<li>for:  simultaneously delineating multiple organs and diseases</li>
<li>methods: federated learning (FL) with knowledge distillation</li>
<li>results: outperforms FedAvg and FedOpt baselines, superior generalizability on external test dataset, can perform well without frequent aggregationHere’s the Simplified Chinese translation of the three points:</li>
<li>for: 同时分割多个器官和疾病</li>
<li>methods: 联邦学习（FL）与知识储存</li>
<li>results: 比 FedAvg 和 FedOpt 基elines有更好的性能，在外部测试集上表现出较高的普适性，可以不经常聚合来达到良好的性能。<details>
<summary>Abstract</summary>
Developing a generalized segmentation model capable of simultaneously delineating multiple organs and diseases is highly desirable. Federated learning (FL) is a key technology enabling the collaborative development of a model without exchanging training data. However, the limited access to fully annotated training data poses a major challenge to training generalizable models. We propose "ConDistFL", a framework to solve this problem by combining FL with knowledge distillation. Local models can extract the knowledge of unlabeled organs and tumors from partially annotated data from the global model with an adequately designed conditional probability representation. We validate our framework on four distinct partially annotated abdominal CT datasets from the MSD and KiTS19 challenges. The experimental results show that the proposed framework significantly outperforms FedAvg and FedOpt baselines. Moreover, the performance on an external test dataset demonstrates superior generalizability compared to models trained on each dataset separately. Our ablation study suggests that ConDistFL can perform well without frequent aggregation, reducing the communication cost of FL. Our implementation will be available at https://github.com/NVIDIA/NVFlare/tree/dev/research/condist-fl.
</details>
<details>
<summary>摘要</summary>
发展一个可以同时分割多个器官和疾病的通用分割模型是非常有优势的。联邦学习（FL）是一种关键技术，它可以帮助建立一个模型，不需要交换训练数据。然而，受到完全标注数据的限制，很难训练通用的模型。我们提出了“ConDistFL”框架，它将FL与知识储存结合以解决这个问题。本地模型可以从全球模型中提取未标注器官和肿瘤的知识，使用适当的条件概率表示。我们在四个不同的部分标注的腹部CT数据集上验证了我们的框架。实验结果表明，我们的框架在FedAvg和FedOpt基准下显著 OUTPERFORMS。此外，对于外部测试集，我们的模型表现更高的普适性，比单独在每个数据集上训练的模型。我们的剖分研究表明，ConDistFL可以在不经常聚合的情况下表现良好，减少联邦学习中的通信成本。我们的实现将在https://github.com/NVIDIA/NVFlare/tree/dev/research/condist-fl上提供。
</details></li>
</ul>
<hr>
<h2 id="Backdoor-Federated-Learning-by-Poisoning-Backdoor-Critical-Layers"><a href="#Backdoor-Federated-Learning-by-Poisoning-Backdoor-Critical-Layers" class="headerlink" title="Backdoor Federated Learning by Poisoning Backdoor-Critical Layers"></a>Backdoor Federated Learning by Poisoning Backdoor-Critical Layers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04466">http://arxiv.org/abs/2308.04466</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haomin Zhuang, Mingxian Yu, Hao Wang, Yang Hua, Jian Li, Xu Yuan</li>
<li>for: 本研究旨在探讨 Federated Learning (FL) 中的后门攻击，以及如何通过识别和适应各种防御策略来实现这种攻击。</li>
<li>methods: 本研究提出了一种基于实际攻击者视角的协调方法，可以帮助攻击者识别和攻击 FL 模型中的极其敏感层（Backdoor-Critical，BC）。此外，本研究还提出了一种基于 BC 层的新型后门攻击方法，可以在不同的防御策略下寻找最佳攻击方式。</li>
<li>results: 经过广泛的实验，研究发现，使用本研究的 BC 层感知后门攻击方法，可以在七种最新的防御策略下成功后门 FL 模型，且比最新的后门攻击方法更高效。<details>
<summary>Abstract</summary>
Federated learning (FL) has been widely deployed to enable machine learning training on sensitive data across distributed devices. However, the decentralized learning paradigm and heterogeneity of FL further extend the attack surface for backdoor attacks. Existing FL attack and defense methodologies typically focus on the whole model. None of them recognizes the existence of backdoor-critical (BC) layers-a small subset of layers that dominate the model vulnerabilities. Attacking the BC layers achieves equivalent effects as attacking the whole model but at a far smaller chance of being detected by state-of-the-art (SOTA) defenses. This paper proposes a general in-situ approach that identifies and verifies BC layers from the perspective of attackers. Based on the identified BC layers, we carefully craft a new backdoor attack methodology that adaptively seeks a fundamental balance between attacking effects and stealthiness under various defense strategies. Extensive experiments show that our BC layer-aware backdoor attacks can successfully backdoor FL under seven SOTA defenses with only 10% malicious clients and outperform the latest backdoor attack methods.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "backdoor-critical" (BC) layers are a small subset of layers in a machine learning model that dominate the model's vulnerabilities.* The proposed approach identifies and verifies BC layers from the perspective of attackers.* The new backdoor attack methodology adaptively seeks a balance between attacking effects and stealthiness under various defense strategies.* The approach can successfully backdoor FL under seven state-of-the-art defenses with only 10% malicious clients and outperform the latest backdoor attack methods.
</details></li>
</ul>
<hr>
<h2 id="An-Empirical-Analysis-of-Range-for-3D-Object-Detection"><a href="#An-Empirical-Analysis-of-Range-for-3D-Object-Detection" class="headerlink" title="An Empirical Analysis of Range for 3D Object Detection"></a>An Empirical Analysis of Range for 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04054">http://arxiv.org/abs/2308.04054</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neehar Peri, Mengtian Li, Benjamin Wilson, Yu-Xiong Wang, James Hays, Deva Ramanan</li>
<li>for: 本文主要研究长距离3D探测，以实现自主驾驶车辆的安全 Navigation。</li>
<li>methods: 本文使用Argoverse 2.0 dataset进行实验分析，探讨长距离3D探测的问题，并发现近距离LiDAR测量是紧密且适合使用小尺寸矩阵，而远距离测量则是疏 dispersed且适合使用大尺寸矩阵。本文还提出了一组为近 vs 远场探测而调整的范围专家，以及一些简单的技术来优化长距离探测的效率和精度。</li>
<li>results: 本文的实验结果显示，使用该范围专家和技术可以提高长距离探测的效率33%，并提高精度3.2% CDS。<details>
<summary>Abstract</summary>
LiDAR-based 3D detection plays a vital role in autonomous navigation. Surprisingly, although autonomous vehicles (AVs) must detect both near-field objects (for collision avoidance) and far-field objects (for longer-term planning), contemporary benchmarks focus only on near-field 3D detection. However, AVs must detect far-field objects for safe navigation. In this paper, we present an empirical analysis of far-field 3D detection using the long-range detection dataset Argoverse 2.0 to better understand the problem, and share the following insight: near-field LiDAR measurements are dense and optimally encoded by small voxels, while far-field measurements are sparse and are better encoded with large voxels. We exploit this observation to build a collection of range experts tuned for near-vs-far field detection, and propose simple techniques to efficiently ensemble models for long-range detection that improve efficiency by 33% and boost accuracy by 3.2% CDS.
</details>
<details>
<summary>摘要</summary>
lidar-based 3D 探测在自动驾驶中扮演着关键性的角色。很奇怪的是，即使自动车辆（AV）需要探测附近 объек（以避免碰撞）和远场 объек（为长期规划），当前的标准准则仅专注于附近 3D 探测。然而，AV 需要探测远场 объек 以确保安全 Navigation。在这篇论文中，我们提供了实验分析远场 3D 探测使用 Argoverse 2.0 长距离探测数据集，以更好地理解问题，并分享以下发现：附近 LiDAR 测量 dense 且最佳地编码为小 voxels，而远场测量则是稀疏的，更适合使用大 voxels 编码。我们利用这一观察，建立了适应于近vs远场探测的范围专家，并提出了简单的技术来有效地ensemble模型以提高长距离探测的效率和准确率。
</details></li>
</ul>
<hr>
<h2 id="Implicit-neural-representations-for-joint-decomposition-and-registration-of-gene-expression-images-in-the-marmoset-brain"><a href="#Implicit-neural-representations-for-joint-decomposition-and-registration-of-gene-expression-images-in-the-marmoset-brain" class="headerlink" title="Implicit neural representations for joint decomposition and registration of gene expression images in the marmoset brain"></a>Implicit neural representations for joint decomposition and registration of gene expression images in the marmoset brain</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04039">http://arxiv.org/abs/2308.04039</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michal Byra, Charissa Poon, Tomomi Shimogori, Henrik Skibbe</li>
<li>for: 本研究旨在提出一种基于隐藏神经表示的图像匹配方法，用于处理两个脑图像之间的匹配问题，其中一个图像包含附加的特征或artefacts，而另一个图像则不包含这些特征。</li>
<li>methods: 本方法使用隐藏网络和图像排除损失来同时进行匹配和图像分解，其中支持图像能够匹配well于模板，而剩余图像则捕捉到各自图像特征的差异。</li>
<li>results: 实验结果表明，本方法可以提供出色的结果，并在其他匹配技术上表现出色。<details>
<summary>Abstract</summary>
We propose a novel image registration method based on implicit neural representations that addresses the challenging problem of registering a pair of brain images with similar anatomical structures, but where one image contains additional features or artifacts that are not present in the other image. To demonstrate its effectiveness, we use 2D microscopy $\textit{in situ}$ hybridization gene expression images of the marmoset brain. Accurately quantifying gene expression requires image registration to a brain template, which is difficult due to the diversity of patterns causing variations in visible anatomical brain structures. Our approach uses implicit networks in combination with an image exclusion loss to jointly perform the registration and decompose the image into a support and residual image. The support image aligns well with the template, while the residual image captures individual image characteristics that diverge from the template. In experiments, our method provided excellent results and outperformed other registration techniques.
</details>
<details>
<summary>摘要</summary>
我们提出了一种基于隐式神经表示的新型图像匹配方法，用于处理一对具有相似解剖结构的脑图像，其中一个图像包含一些不在另一个图像中存在的特征或噪声。为证明其效果，我们使用了2D微显镜天然增强引入蛋白表达图像。正确评估蛋白表达需要图像匹配到脑模板，这是因为脑结构的多样性导致视觉特征的变化。我们的方法使用隐式网络和图像排除损失相结合，同时进行匹配和图像分解。支持图像能够匹配良好到模板，而剩余图像损失中包含各自图像特征。在实验中，我们的方法表现出色，超越了其他匹配技术。
</details></li>
</ul>
<hr>
<h2 id="Synthetic-Augmentation-with-Large-scale-Unconditional-Pre-training"><a href="#Synthetic-Augmentation-with-Large-scale-Unconditional-Pre-training" class="headerlink" title="Synthetic Augmentation with Large-scale Unconditional Pre-training"></a>Synthetic Augmentation with Large-scale Unconditional Pre-training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04020">http://arxiv.org/abs/2308.04020</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/karenyyy/histodiffaug">https://github.com/karenyyy/histodiffaug</a></li>
<li>paper_authors: Jiarong Ye, Haomiao Ni, Peng Jin, Sharon X. Huang, Yuan Xue</li>
<li>for: 提高医疗影像识别系统的训练数据效果，减少专家标注的成本和时间。</li>
<li>methods: 提出了一种名为HistoDiffusion的生成图像增强技术，可以在大量未标注数据集上预训练，然后应用于小规模标注数据集进行增强训练。</li>
<li>results: 通过在三个 histopathology 数据集上预训练，然后在一个 colorectal cancer (CRC) 数据集上测试，得到了训练使用小量标注数据集的增强图像识别率的提高，具体提高6.4%。<details>
<summary>Abstract</summary>
Deep learning based medical image recognition systems often require a substantial amount of training data with expert annotations, which can be expensive and time-consuming to obtain. Recently, synthetic augmentation techniques have been proposed to mitigate the issue by generating realistic images conditioned on class labels. However, the effectiveness of these methods heavily depends on the representation capability of the trained generative model, which cannot be guaranteed without sufficient labeled training data. To further reduce the dependency on annotated data, we propose a synthetic augmentation method called HistoDiffusion, which can be pre-trained on large-scale unlabeled datasets and later applied to a small-scale labeled dataset for augmented training. In particular, we train a latent diffusion model (LDM) on diverse unlabeled datasets to learn common features and generate realistic images without conditional inputs. Then, we fine-tune the model with classifier guidance in latent space on an unseen labeled dataset so that the model can synthesize images of specific categories. Additionally, we adopt a selective mechanism to only add synthetic samples with high confidence of matching to target labels. We evaluate our proposed method by pre-training on three histopathology datasets and testing on a histopathology dataset of colorectal cancer (CRC) excluded from the pre-training datasets. With HistoDiffusion augmentation, the classification accuracy of a backbone classifier is remarkably improved by 6.4% using a small set of the original labels. Our code is available at https://github.com/karenyyy/HistoDiffAug.
</details>
<details>
<summary>摘要</summary>
医学图像识别系统经常需要大量的训练数据，包括专家标注，这可能是时间consuming和成本高的。在最近，人工增强技术被提出，以生成符合类别标签的图像。然而，这些方法的效果受训练的生成模型的表达能力的限制，而这无法保证。为了进一步减少依赖于标注数据，我们提议一种名为HistoDiffusion的人工增强方法。在这种方法中，我们首先在大量无标注数据上训练一个潜在扩散模型（LDM），以学习通用特征并生成真实图像。然后，我们在一个未看过的标注数据集上精度地调整模型，以使其能够生成特定类别的图像。此外，我们采用了一种选择机制，只添加符合目标标签的synthetic样本。我们对三个 Histopathology 数据集进行预训练，并在一个排除在预训练数据集中的大肠癌（CRC）数据集上进行测试。与HistoDiffusion增强后，一个基础类фика器的分类精度显著提高了6.4%，只使用一小部分原始标注。我们的代码可以在 GitHub 上找到：https://github.com/karenyyy/HistoDiffAug。
</details></li>
</ul>
<hr>
<h2 id="Hierarchical-Visual-Primitive-Experts-for-Compositional-Zero-Shot-Learning"><a href="#Hierarchical-Visual-Primitive-Experts-for-Compositional-Zero-Shot-Learning" class="headerlink" title="Hierarchical Visual Primitive Experts for Compositional Zero-Shot Learning"></a>Hierarchical Visual Primitive Experts for Compositional Zero-Shot Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04016">http://arxiv.org/abs/2308.04016</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hanjaekim98/cot">https://github.com/hanjaekim98/cot</a></li>
<li>paper_authors: Hanjae Kim, Jiyoung Lee, Seongheon Park, Kwanghoon Sohn</li>
<li>for: 本研究的目的是提出一种简单可扩展的架构，以解决现有的 zero-shot 组合学习（CZSL）问题，包括考虑对象和特征之间的上下文关系，以及实际世界中的组合数据长尾分布问题。</li>
<li>methods: 本研究提出了一种名为 Composition Transformer（CoT）的简单可扩展架构，该架构包括对象和特征专家，通过可视网络层次结构来生成表示性 embedding。对象专家从底层 final layer 中提取表示性对象 embedding，而特征专家通过一种提出的对象引导注意力模块来生成特征 embedding，以显式地模型上下文关系。</li>
<li>results: 根据多个 benchmark 数据集，包括 MIT-States、C-GQA 和 VAW-CZSL，our method  achieve State-of-the-Art 性能。此外，我们还证明了 CoT 在改善可视特征分辨率和减少模型偏见问题上的效果。代码可以在 <a target="_blank" rel="noopener" href="https://github.com/HanjaeKim98/CoT">https://github.com/HanjaeKim98/CoT</a> 上获取。<details>
<summary>Abstract</summary>
Compositional zero-shot learning (CZSL) aims to recognize unseen compositions with prior knowledge of known primitives (attribute and object). Previous works for CZSL often suffer from grasping the contextuality between attribute and object, as well as the discriminability of visual features, and the long-tailed distribution of real-world compositional data. We propose a simple and scalable framework called Composition Transformer (CoT) to address these issues. CoT employs object and attribute experts in distinctive manners to generate representative embeddings, using the visual network hierarchically. The object expert extracts representative object embeddings from the final layer in a bottom-up manner, while the attribute expert makes attribute embeddings in a top-down manner with a proposed object-guided attention module that models contextuality explicitly. To remedy biased prediction caused by imbalanced data distribution, we develop a simple minority attribute augmentation (MAA) that synthesizes virtual samples by mixing two images and oversampling minority attribute classes. Our method achieves SoTA performance on several benchmarks, including MIT-States, C-GQA, and VAW-CZSL. We also demonstrate the effectiveness of CoT in improving visual discrimination and addressing the model bias from the imbalanced data distribution. The code is available at https://github.com/HanjaeKim98/CoT.
</details>
<details>
<summary>摘要</summary>
compositional zero-shot learning (CZSL)  targets recognizing unseen compositions based on prior knowledge of known primitives (attribute and object). previous works for CZSL often suffer from grasping the contextuality between attribute and object, as well as the discriminability of visual features, and the long-tailed distribution of real-world compositional data. we propose a simple and scalable framework called Composition Transformer (CoT) to address these issues. CoT employs object and attribute experts in distinctive manners to generate representative embeddings, using the visual network hierarchically. the object expert extracts representative object embeddings from the final layer in a bottom-up manner, while the attribute expert makes attribute embeddings in a top-down manner with a proposed object-guided attention module that models contextuality explicitly. to remedy biased prediction caused by imbalanced data distribution, we develop a simple minority attribute augmentation (MAA) that synthesizes virtual samples by mixing two images and oversampling minority attribute classes. our method achieves SoTA performance on several benchmarks, including MIT-States, C-GQA, and VAW-CZSL. we also demonstrate the effectiveness of CoT in improving visual discrimination and addressing the model bias from the imbalanced data distribution. the code is available at https://github.com/HanjaeKim98/CoT.
</details></li>
</ul>
<hr>
<h2 id="Coarse-to-Fine-Learning-Compact-Discriminative-Representation-for-Single-Stage-Image-Retrieval"><a href="#Coarse-to-Fine-Learning-Compact-Discriminative-Representation-for-Single-Stage-Image-Retrieval" class="headerlink" title="Coarse-to-Fine: Learning Compact Discriminative Representation for Single-Stage Image Retrieval"></a>Coarse-to-Fine: Learning Compact Discriminative Representation for Single-Stage Image Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04008">http://arxiv.org/abs/2308.04008</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bassyess/cfcd">https://github.com/bassyess/cfcd</a></li>
<li>paper_authors: Yunquan Zhu, Xinkai Gao, Bo Ke, Ruizhi Qiao, Xing Sun</li>
<li>for: 实现单stage图像检索的高效精度搜索</li>
<li>methods: 提出了一种Coarse-to-Fine框架，学习Compact Discriminative representation（CFCD），只需要图像级别的标签进行训练。具体来说，我们首先设计了一种适应性softmax基于损失函数，在每个mini-batch中动态调整其尺度和边缘，以强化supervision during training和intra-class compactness。其次，我们提出了一种机制，通过硬negative sampling策略选择突出地ocal descriptors，并将其混合到全局表示中，以便在全球范围内优化相互之间的Semantic关系。</li>
<li>results: 经验证明了我们的方法的效果，在Revisited Oxford和Revisited Paris等benchmark上实现了单stage图像检索的state-of-the-art性能。<details>
<summary>Abstract</summary>
Image retrieval targets to find images from a database that are visually similar to the query image. Two-stage methods following retrieve-and-rerank paradigm have achieved excellent performance, but their separate local and global modules are inefficient to real-world applications. To better trade-off retrieval efficiency and accuracy, some approaches fuse global and local feature into a joint representation to perform single-stage image retrieval. However, they are still challenging due to various situations to tackle, $e.g.$, background, occlusion and viewpoint. In this work, we design a Coarse-to-Fine framework to learn Compact Discriminative representation (CFCD) for end-to-end single-stage image retrieval-requiring only image-level labels. Specifically, we first design a novel adaptive softmax-based loss which dynamically tunes its scale and margin within each mini-batch and increases them progressively to strengthen supervision during training and intra-class compactness. Furthermore, we propose a mechanism which attentively selects prominent local descriptors and infuse fine-grained semantic relations into the global representation by a hard negative sampling strategy to optimize inter-class distinctiveness at a global scale. Extensive experimental results have demonstrated the effectiveness of our method, which achieves state-of-the-art single-stage image retrieval performance on benchmarks such as Revisited Oxford and Revisited Paris. Code is available at https://github.com/bassyess/CFCD.
</details>
<details>
<summary>摘要</summary>
<SYS>将给定文本翻译成简化中文。</SYS>图像检索目标是从数据库中检索与查询图像视觉相似的图像。两Stage方法在 retrieve-and-rerank 模式下实现了出色的表现，但它们的分立的本地和全局模块在实际应用中不是非常有效。为了更好地平衡检索效率和准确率，一些方法将全局和本地特征集成为一个共同表示，以实现单stage图像检索。然而，它们仍然面临许多挑战，例如背景、遮挡和视角等。在这项工作中，我们设计了一个粗略到细节的框架，用于学习练习Compact Discriminative representation（CFCD），以实现端到端单stage图像检索，只需要图像级别标签。具体来说，我们首先设计了一种新的适应式软MAX基于损失函数，可以在每个小批中动态调整缩放和边界，以强化supervision during training和内部精度。此外，我们提出了一种机制，可以在硬negative samplingstrategy中选择表现出色的本地特征，并将其注入到全局表示中，以便在全球级别提高对类的分辨率。经验证实结果表明，我们的方法可以实现单stage图像检索的最佳表现，在Revisited Oxford和Revisited Paris等benchmark上达到了状态畅的单stage图像检索性能。代码可以在https://github.com/bassyess/CFCD中找到。
</details></li>
</ul>
<hr>
<h2 id="Few-shot-medical-image-classification-with-simple-shape-and-texture-text-descriptors-using-vision-language-models"><a href="#Few-shot-medical-image-classification-with-simple-shape-and-texture-text-descriptors-using-vision-language-models" class="headerlink" title="Few-shot medical image classification with simple shape and texture text descriptors using vision-language models"></a>Few-shot medical image classification with simple shape and texture text descriptors using vision-language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04005">http://arxiv.org/abs/2308.04005</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michal Byra, Muhammad Febrian Rachmadi, Henrik Skibbe</li>
<li>for: 本研究探讨了视力语言模型（VLMs）和大语言模型在医学图像二进制少量分类中的有用性。</li>
<li>methods: 我们使用GPT-4模型生成医学图像中对象形状和xture特征的文本描述符。然后，这些GPT-4生成的描述符， alongside VLMs pré-训练natural images, 用于分类胸部X射线和乳腺ultrasound图像。</li>
<li>results: 我们的结果表明，使用VLMs和GPT-4生成的描述符进行医学图像二进制少量分类是一种可行的方法。然而，为了准确地分类，需要排除certain descriptor的计算分类分数。此外，我们评估了VLMs对乳腺癌ultrasound图像中形状特征的评价能力。我们进一步调查GPT-4生成的描述符集中的变化程度。我们的工作提供了关于VLMs在医学图像分析中的应用的重要发现。<details>
<summary>Abstract</summary>
In this work, we investigate the usefulness of vision-language models (VLMs) and large language models for binary few-shot classification of medical images. We utilize the GPT-4 model to generate text descriptors that encapsulate the shape and texture characteristics of objects in medical images. Subsequently, these GPT-4 generated descriptors, alongside VLMs pre-trained on natural images, are employed to classify chest X-rays and breast ultrasound images. Our results indicate that few-shot classification of medical images using VLMs and GPT-4 generated descriptors is a viable approach. However, accurate classification requires to exclude certain descriptors from the calculations of the classification scores. Moreover, we assess the ability of VLMs to evaluate shape features in breast mass ultrasound images. We further investigate the degree of variability among the sets of text descriptors produced by GPT-4. Our work provides several important insights about the application of VLMs for medical image analysis.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们调查了视力语言模型（VLM）和大语言模型是否能够实现医学图像二进制几个shot分类。我们使用GPT-4模型生成医学图像中对象的形状和文化特征的文本描述。然后，这些GPT-4生成的描述、 alongside VLMs预训练于自然图像，用于分类胸部X射线和乳腺ultrasound图像。我们的结果表明，使用VLMs和GPT-4生成的描述进行医学图像二进制分类是一种可行的方法。然而，精确地分类需要排除某些描述器从分类得分计算中。此外，我们评估了VLMs对乳腺瘤ultrasound图像中形状特征的评价能力。我们进一步调查GPT-4生成的描述集中的变化程度。我们的研究提供了关于VLMs在医学图像分析方面的重要发现。
</details></li>
</ul>
<hr>
<h2 id="Real-time-Strawberry-Detection-Based-on-Improved-YOLOv5s-Architecture-for-Robotic-Harvesting-in-open-field-environment"><a href="#Real-time-Strawberry-Detection-Based-on-Improved-YOLOv5s-Architecture-for-Robotic-Harvesting-in-open-field-environment" class="headerlink" title="Real-time Strawberry Detection Based on Improved YOLOv5s Architecture for Robotic Harvesting in open-field environment"></a>Real-time Strawberry Detection Based on Improved YOLOv5s Architecture for Robotic Harvesting in open-field environment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03998">http://arxiv.org/abs/2308.03998</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zixuan He, Salik Ram Khana, Xin Zhang, Manoj Karkee, Qin Zhang</li>
<li>For: The paper proposes a custom object detection model based on YOLOv5 for strawberry detection in open-field environments.* Methods: The proposed model modifies the original YOLOv5 architecture by replacing the C3 module with C2f and combining Spatial Pyramid Pooling Fast with Cross Stage Partial Net. The model is trained on a dataset of RGB images of strawberry canopies with three maturity classes.* Results: The proposed model achieves the highest mean average precision of 80.3% among five compared models, with an inference speed of 18ms per image. The model outperforms the latest YOLOv8s in terms of average precision in the immature and mature classes, while being faster and having fewer parameters.<details>
<summary>Abstract</summary>
This study proposed a YOLOv5-based custom object detection model to detect strawberries in an outdoor environment. The original architecture of the YOLOv5s was modified by replacing the C3 module with the C2f module in the backbone network, which provided a better feature gradient flow. Secondly, the Spatial Pyramid Pooling Fast in the final layer of the backbone network of YOLOv5s was combined with Cross Stage Partial Net to improve the generalization ability over the strawberry dataset in this study. The proposed architecture was named YOLOv5s-Straw. The RGB images dataset of the strawberry canopy with three maturity classes (immature, nearly mature, and mature) was collected in open-field environment and augmented through a series of operations including brightness reduction, brightness increase, and noise adding. To verify the superiority of the proposed method for strawberry detection in open-field environment, four competitive detection models (YOLOv3-tiny, YOLOv5s, YOLOv5s-C2f, and YOLOv8s) were trained, and tested under the same computational environment and compared with YOLOv5s-Straw. The results showed that the highest mean average precision of 80.3% was achieved using the proposed architecture whereas the same was achieved with YOLOv3-tiny, YOLOv5s, YOLOv5s-C2f, and YOLOv8s were 73.4%, 77.8%, 79.8%, 79.3%, respectively. Specifically, the average precision of YOLOv5s-Straw was 82.1% in the immature class, 73.5% in the nearly mature class, and 86.6% in the mature class, which were 2.3% and 3.7%, respectively, higher than that of the latest YOLOv8s. The model included 8.6*10^6 network parameters with an inference speed of 18ms per image while the inference speed of YOLOv8s had a slower inference speed of 21.0ms and heavy parameters of 11.1*10^6, which indicates that the proposed model is fast enough for real time strawberry detection and localization for the robotic picking.
</details>
<details>
<summary>摘要</summary>
The dataset used in this study consisted of RGB images of strawberry canopies with three maturity classes (immature, nearly mature, and mature) collected in an open-field environment. The images were augmented using brightness reduction, brightness increase, and noise adding.To evaluate the performance of the proposed model, four competitive detection models (YOLOv3-tiny, YOLOv5s, YOLOv5s-C2f, and YOLOv8s) were trained and tested under the same computational environment. The results showed that the proposed model achieved the highest mean average precision of 80.3%, outperforming the other models by 3.7% to 7.3%. Specifically, the average precision of YOLOv5s-Straw was 82.1% in the immature class, 73.5% in the nearly mature class, and 86.6% in the mature class.The proposed model includes 8.6 million network parameters and has an inference speed of 18ms per image, which is fast enough for real-time strawberry detection and localization for robotic picking. In comparison, YOLOv8s has heavier parameters (11.1 million) and a slower inference speed (21.0ms).Overall, the proposed YOLOv5s-Straw model outperformed other state-of-the-art models for strawberry detection in open-field environments, and is a promising solution for robotic strawberry picking applications.
</details></li>
</ul>
<hr>
<h2 id="PARTNER-Level-up-the-Polar-Representation-for-LiDAR-3D-Object-Detection"><a href="#PARTNER-Level-up-the-Polar-Representation-for-LiDAR-3D-Object-Detection" class="headerlink" title="PARTNER: Level up the Polar Representation for LiDAR 3D Object Detection"></a>PARTNER: Level up the Polar Representation for LiDAR 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03982">http://arxiv.org/abs/2308.03982</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ming Nie, Yujing Xue, Chunwei Wang, Chaoqiang Ye, Hang Xu, Xinge Zhu, Qingqiu Huang, Michael Bi Mi, Xinchao Wang, Li Zhang</li>
<li>for: 提高3D物体探测器的精度和稳定性，特别是在流式探测和不同分辨率下。</li>
<li>methods: 使用极坐标系表示，并引入实例级别的几何信息来改进检测头，以解决非uniform分辨率所导致的特征扭曲问题。</li>
<li>results: 与前一代极坐标系方法相比，实现了3.68%和9.15%的显著提高在 Waymo 和 ONCE 验证集上，并在流式探测和不同分辨率下达到了竞争力的 результаados。<details>
<summary>Abstract</summary>
Recently, polar-based representation has shown promising properties in perceptual tasks. In addition to Cartesian-based approaches, which separate point clouds unevenly, representing point clouds as polar grids has been recognized as an alternative due to (1) its advantage in robust performance under different resolutions and (2) its superiority in streaming-based approaches. However, state-of-the-art polar-based detection methods inevitably suffer from the feature distortion problem because of the non-uniform division of polar representation, resulting in a non-negligible performance gap compared to Cartesian-based approaches. To tackle this issue, we present PARTNER, a novel 3D object detector in the polar coordinate. PARTNER alleviates the dilemma of feature distortion with global representation re-alignment and facilitates the regression by introducing instance-level geometric information into the detection head. Extensive experiments show overwhelming advantages in streaming-based detection and different resolutions. Furthermore, our method outperforms the previous polar-based works with remarkable margins of 3.68% and 9.15% on Waymo and ONCE validation set, thus achieving competitive results over the state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
近些时间，基于极坐标的表示方法在认知任务中展现出了有前途的性能。除了使用坐标系分解的方法，即在不同的分辨率下分别处理点云，基于极坐标网格的表示方法被认为是一个有优势的选择，因为它们在不同的分辨率下具有robust性和流式处理的优势。然而，现状的极坐标基的检测方法无法避免特征扭曲问题，这是因为极坐标网格的非均匀分配引起的。为解决这个问题，我们提出了PARTNER，一种新的3D物体检测器。PARTNER通过重新调整全局表示和添加实例级别的几何信息来缓解特征扭曲问题，并且在检测头中进行了改进，以便更好地进行准确性。我们的方法在流式检测和不同的分辨率上具有了极大的优势，并且在 Waymo和ONCE验证集上比前一代极坐标基的方法有3.68%和9.15%的remarkable margins，从而实现了与当前最佳方法的竞争性。
</details></li>
</ul>
<hr>
<h2 id="PAIF-Perception-Aware-Infrared-Visible-Image-Fusion-for-Attack-Tolerant-Semantic-Segmentation"><a href="#PAIF-Perception-Aware-Infrared-Visible-Image-Fusion-for-Attack-Tolerant-Semantic-Segmentation" class="headerlink" title="PAIF: Perception-Aware Infrared-Visible Image Fusion for Attack-Tolerant Semantic Segmentation"></a>PAIF: Perception-Aware Infrared-Visible Image Fusion for Attack-Tolerant Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03979">http://arxiv.org/abs/2308.03979</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liuzhu-cv/paif">https://github.com/liuzhu-cv/paif</a></li>
<li>paper_authors: Zhu Liu, Jinyuan Liu, Benzhuang Zhang, Long Ma, Xin Fan, Risheng Liu</li>
<li>for: 本研究旨在提高针对抗击的图像融合方法的分割稳定性。</li>
<li>methods: 本研究提出了一种感知响应的融合框架，通过系统性分析不同模式之间的相关性，并提出了一种协调结构来平衡标准准确率和鲁棒性。此外，还提出了一种适应学习策略来提高图像融合的参数鲁棒性，以便在多种抗击干扰下学习有效的特征提取。</li>
<li>results: 实验结果表明，我们的方案可以大幅提高分割稳定性，相比高级竞争者，增加了15.3%的mIOU分割精度。<details>
<summary>Abstract</summary>
Infrared and visible image fusion is a powerful technique that combines complementary information from different modalities for downstream semantic perception tasks. Existing learning-based methods show remarkable performance, but are suffering from the inherent vulnerability of adversarial attacks, causing a significant decrease in accuracy. In this work, a perception-aware fusion framework is proposed to promote segmentation robustness in adversarial scenes. We first conduct systematic analyses about the components of image fusion, investigating the correlation with segmentation robustness under adversarial perturbations. Based on these analyses, we propose a harmonized architecture search with a decomposition-based structure to balance standard accuracy and robustness. We also propose an adaptive learning strategy to improve the parameter robustness of image fusion, which can learn effective feature extraction under diverse adversarial perturbations. Thus, the goals of image fusion (\textit{i.e.,} extracting complementary features from source modalities and defending attack) can be realized from the perspectives of architectural and learning strategies. Extensive experimental results demonstrate that our scheme substantially enhances the robustness, with gains of 15.3% mIOU of segmentation in the adversarial scene, compared with advanced competitors. The source codes are available at https://github.com/LiuZhu-CV/PAIF.
</details>
<details>
<summary>摘要</summary>
infrared和可见图像融合是一种强大的技术，可以将不同modalities的补充信息结合以提高下游semantic perception任务的性能。现有的学习基于方法显示出惊人的表现，但是它们受到内置的敌意攻击的隐藏危险，导致准确性减少。在这种工作中，我们提出了一种感知 aware的融合框架，以提高 segmentation 的 Robustness 在敌意场景中。我们首先进行了系统的分析，探讨了不同modalities的图像融合组件与 segmentation 的相关性。基于这些分析，我们提出了一种协调结构，以平衡标准准确性和 Robustness。我们还提出了一种适应学习策略，以提高图像融合的参数Robustness，使其在多种敌意攻击下学习有效的特征提取。因此，我们的方案可以从architecture和学习策略的角度实现图像融合的两个目标：提取源modalities中的补充特征，并防止攻击。我们的实验结果表明，我们的方案可以大幅提高Robustness，与先进竞争对手相比，增加了15.3%的mIOU segmentation准确率。源代码可以在https://github.com/LiuZhu-CV/PAIF上获取。
</details></li>
</ul>
<hr>
<h2 id="PUG-Photorealistic-and-Semantically-Controllable-Synthetic-Data-for-Representation-Learning"><a href="#PUG-Photorealistic-and-Semantically-Controllable-Synthetic-Data-for-Representation-Learning" class="headerlink" title="PUG: Photorealistic and Semantically Controllable Synthetic Data for Representation Learning"></a>PUG: Photorealistic and Semantically Controllable Synthetic Data for Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03977">http://arxiv.org/abs/2308.03977</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/pug">https://github.com/facebookresearch/pug</a></li>
<li>paper_authors: Florian Bordes, Shashank Shekhar, Mark Ibrahim, Diane Bouchacourt, Pascal Vincent, Ari S. Morcos</li>
<li>for: 这个论文旨在推广使用真实图像数据的问题，提出了一种使用游戏引擎生成高品质的 synthetic 图像数据，以便更好地训练和评估深度神经网络。</li>
<li>methods: 这篇论文使用了 Unreal Engine 游戏引擎，生成了高品质的 synthetic 图像数据，并为 representation learning 研究提供了一种可控、真实的图像环境。</li>
<li>results: 论文通过对多种视觉模型的评估，显示了 PUG 环境和数据集的可用性和有效性，并为研究人员提供了一种更加准确和可靠的评估方式。<details>
<summary>Abstract</summary>
Synthetic image datasets offer unmatched advantages for designing and evaluating deep neural networks: they make it possible to (i) render as many data samples as needed, (ii) precisely control each scene and yield granular ground truth labels (and captions), (iii) precisely control distribution shifts between training and testing to isolate variables of interest for sound experimentation. Despite such promise, the use of synthetic image data is still limited -- and often played down -- mainly due to their lack of realism. Most works therefore rely on datasets of real images, which have often been scraped from public images on the internet, and may have issues with regards to privacy, bias, and copyright, while offering little control over how objects precisely appear. In this work, we present a path to democratize the use of photorealistic synthetic data: we develop a new generation of interactive environments for representation learning research, that offer both controllability and realism. We use the Unreal Engine, a powerful game engine well known in the entertainment industry, to produce PUG (Photorealistic Unreal Graphics) environments and datasets for representation learning. In this paper, we demonstrate the potential of PUG to enable more rigorous evaluations of vision models.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate the following text into Simplified Chinese<</SYS>>人工图像数据集具有无可比的优势，可以为深度神经网络的设计和评估带来很多便利：可以（i）生成无数量的数据样本，（ii）精确控制每个场景和获得细腻的标签和描述，（iii）在训练和测试中控制分布变化，以孤立变量。Despite such promise, the use of synthetic image data is still limited -- and often played down -- mainly due to their lack of realism. Most works therefore rely on datasets of real images, which have often been scraped from public images on the internet, and may have issues with regards to privacy, bias, and copyright, while offering little control over how objects precisely appear. In this work, we present a path to democratize the use of photorealistic synthetic data: we develop a new generation of interactive environments for representation learning research, that offer both controllability and realism. We use the Unreal Engine, a powerful game engine well known in the entertainment industry, to produce PUG (Photorealistic Unreal Graphics) environments and datasets for representation learning. In this paper, we demonstrate the potential of PUG to enable more rigorous evaluations of vision models.Translation:人工图像数据集具有无可比的优势，可以为深度神经网络的设计和评估带来很多便利。可以（i）生成无数量的数据样本，（ii）精确控制每个场景和获得细腻的标签和描述，（iii）在训练和测试中控制分布变化，以孤立变量。尽管如此，使用人工图像数据的使用仍然受到限制——主要是因为它们缺乏实际性。大多数工作因此选择使用实际图像数据，这些数据经常从互联网上抓取，可能存在隐私、偏见和版权问题，而且无法控制对象的具体外观。在这个工作中，我们提出了一种路径，以使用PUG（真实无极图形）环境和数据集来进行表示学习研究。我们使用Unreal Engine游戏引擎，这是娱乐业界非常知名的游戏引擎，生成PUG环境和数据集。在这篇论文中，我们示出了PUG的潜在力量，以允许更加严格的评估视觉模型。
</details></li>
</ul>
<hr>
<h2 id="Prompted-Contrast-with-Masked-Motion-Modeling-Towards-Versatile-3D-Action-Representation-Learning"><a href="#Prompted-Contrast-with-Masked-Motion-Modeling-Towards-Versatile-3D-Action-Representation-Learning" class="headerlink" title="Prompted Contrast with Masked Motion Modeling: Towards Versatile 3D Action Representation Learning"></a>Prompted Contrast with Masked Motion Modeling: Towards Versatile 3D Action Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03975">http://arxiv.org/abs/2308.03975</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiahang Zhang, Lilang Lin, Jiaying Liu</li>
<li>for: 本研究的目的是提出一种新的自动学习方法，用于解决人体动作理解中的骨架关系学习问题，这是一个重要 yet 挑战性的问题。</li>
<li>methods: 本研究使用了Prompted Contrast with Masked Motion Modeling（PCM$^{\rm 3}$）方法，它将对比学习和做牌预测任务相互补充，从而提高了对多个下游任务的泛化能力。</li>
<li>results: 实验结果表明，PCM$^{\rm 3}$ 方法在五个下游任务中的表现都superior于现有的状态之工作，特别是在三个大规模的数据集上。codes<details>
<summary>Abstract</summary>
Self-supervised learning has proved effective for skeleton-based human action understanding, which is an important yet challenging topic. Previous works mainly rely on contrastive learning or masked motion modeling paradigm to model the skeleton relations. However, the sequence-level and joint-level representation learning cannot be effectively and simultaneously handled by these methods. As a result, the learned representations fail to generalize to different downstream tasks. Moreover, combining these two paradigms in a naive manner leaves the synergy between them untapped and can lead to interference in training. To address these problems, we propose Prompted Contrast with Masked Motion Modeling, PCM$^{\rm 3}$, for versatile 3D action representation learning. Our method integrates the contrastive learning and masked prediction tasks in a mutually beneficial manner, which substantially boosts the generalization capacity for various downstream tasks. Specifically, masked prediction provides novel training views for contrastive learning, which in turn guides the masked prediction training with high-level semantic information. Moreover, we propose a dual-prompted multi-task pretraining strategy, which further improves model representations by reducing the interference caused by learning the two different pretext tasks. Extensive experiments on five downstream tasks under three large-scale datasets are conducted, demonstrating the superior generalization capacity of PCM$^{\rm 3}$ compared to the state-of-the-art works. Our project is publicly available at: https://jhang2020.github.io/Projects/PCM3/PCM3.html .
</details>
<details>
<summary>摘要</summary>
自我指导学习已经证明对人体动作理解是有效的，这是一个重要但也是具有挑战性的领域。先前的工作主要采用了对比学习或遮盖动作模型的概念学习方法来模型人体关系。然而，序列水平和联合水平的表示学习无法同时得到有效的处理。这导致学习表示失去泛化到不同的下游任务中。此外，将这两种方法在一种简单的方式结合可能会导致在训练中的干扰。为解决这些问题，我们提出了受提醒的对比学习与遮盖动作模型（PCM$^{\rm 3}$），用于多样化的3D动作表示学习。我们的方法将对比学习和遮盖预测任务融合在一起，从而增强模型的泛化能力 для多种下游任务。具体来说，遮盖预测提供了对比学习训练中的新的训练视图，而对比学习则帮助遮盖预测训练得到高级别semantic信息。此外，我们还提出了双重受提醒多任务预训练策略，可以降低学习两个不同预tex任务时的干扰。我们在三个大规模数据集上进行了五个下游任务的广泛实验，证明PCM$^{\rm 3}$的泛化能力较为先前的工作更高。我们的项目在https://jhang2020.github.io/Projects/PCM3/PCM3.html上公开可用。
</details></li>
</ul>
<hr>
<h2 id="Zero-shot-Skeleton-based-Action-Recognition-via-Mutual-Information-Estimation-and-Maximization"><a href="#Zero-shot-Skeleton-based-Action-Recognition-via-Mutual-Information-Estimation-and-Maximization" class="headerlink" title="Zero-shot Skeleton-based Action Recognition via Mutual Information Estimation and Maximization"></a>Zero-shot Skeleton-based Action Recognition via Mutual Information Estimation and Maximization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03950">http://arxiv.org/abs/2308.03950</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yujieouo/smie">https://github.com/yujieouo/smie</a></li>
<li>paper_authors: Yujie Zhou, Wenwen Qiang, Anyi Rao, Ning Lin, Bing Su, Jiaqi Wang</li>
<li>for: 这个研究目的是为了在训练seen类别的数据上进行zero-shot的动作识别，即识别未见类别的动作。</li>
<li>methods: 我们提出了一新的zero-shot skeleton-based action recognition方法，通过估计和最大化mutual information（MI）。 Specifically, 我们在visual和semantic空间之间实现了分布对齐，并且利用时间信息来增强动作的归一化。</li>
<li>results: 我们在三个大规模的skeleton action dataset上进行了广泛的实验，结果显示了我们的方法的有效性。<details>
<summary>Abstract</summary>
Zero-shot skeleton-based action recognition aims to recognize actions of unseen categories after training on data of seen categories. The key is to build the connection between visual and semantic space from seen to unseen classes. Previous studies have primarily focused on encoding sequences into a singular feature vector, with subsequent mapping the features to an identical anchor point within the embedded space. Their performance is hindered by 1) the ignorance of the global visual/semantic distribution alignment, which results in a limitation to capture the true interdependence between the two spaces. 2) the negligence of temporal information since the frame-wise features with rich action clues are directly pooled into a single feature vector. We propose a new zero-shot skeleton-based action recognition method via mutual information (MI) estimation and maximization. Specifically, 1) we maximize the MI between visual and semantic space for distribution alignment; 2) we leverage the temporal information for estimating the MI by encouraging MI to increase as more frames are observed. Extensive experiments on three large-scale skeleton action datasets confirm the effectiveness of our method. Code: https://github.com/YujieOuO/SMIE.
</details>
<details>
<summary>摘要</summary>
zero-shot骨干基于动作识别targets recognizing unseen categories after training on seen categories. The key is to build a connection between visual and semantic space from seen to unseen classes. Previous studies have primarily focused on encoding sequences into a singular feature vector, with subsequent mapping the features to an identical anchor point within the embedded space. Their performance is hindered by 1) ignorance of the global visual/semantic distribution alignment, which results in a limitation to capture the true interdependence between the two spaces. 2) negligence of temporal information since the frame-wise features with rich action clues are directly pooled into a single feature vector. We propose a new zero-shot skeleton-based action recognition method via mutual information (MI) estimation and maximization. Specifically, 1) we maximize the MI between visual and semantic space for distribution alignment; 2) we leverage the temporal information for estimating the MI by encouraging MI to increase as more frames are observed. Extensive experiments on three large-scale skeleton action datasets confirm the effectiveness of our method. Code: <https://github.com/YujieOuO/SMIE>.Here's the word-for-word translation of the text into Simplified Chinese: zero-shot骨干基于动作识别targetsRecognize unseen categories after training on seen categories. The key is to build a connection between visual and semantic space from seen to unseen classes. Previous studies have primarily focused on encoding sequences into a singular feature vector, with subsequent mapping the features to an identical anchor point within the embedded space. Their performance is hindered by 1) ignorance of the global visual/semantic distribution alignment, which results in a limitation to capture the true interdependence between the two spaces. 2) negligence of temporal information since the frame-wise features with rich action clues are directly pooled into a single feature vector. We propose a new zero-shot skeleton-based action recognition method via mutual information (MI) estimation and maximization. Specifically, 1) we maximize the MI between visual and semantic space for distribution alignment; 2) we leverage the temporal information for estimating the MI by encouraging MI to increase as more frames are observed. Extensive experiments on three large-scale skeleton action datasets confirm the effectiveness of our method. Code: <https://github.com/YujieOuO/SMIE>.
</details></li>
</ul>
<hr>
<h2 id="Deterministic-Neural-Illumination-Mapping-for-Efficient-Auto-White-Balance-Correction"><a href="#Deterministic-Neural-Illumination-Mapping-for-Efficient-Auto-White-Balance-Correction" class="headerlink" title="Deterministic Neural Illumination Mapping for Efficient Auto-White Balance Correction"></a>Deterministic Neural Illumination Mapping for Efficient Auto-White Balance Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03939">http://arxiv.org/abs/2308.03939</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/birdortyedi/denim">https://github.com/birdortyedi/denim</a></li>
<li>paper_authors: Furkan Kınlı, Doğa Yılmaz, Barış Özcan, Furkan Kıraç</li>
<li>for: 提供高速、高质量图像彩度 correction 解决方案</li>
<li>methods: 基于 deterministic color style transfer 的权重映射策略，具有 resolution-agnostic 特点，可整合任何预训练 AWB 网络</li>
<li>results: 实验结果表明，该方法可以实现至少 35 倍快的处理速度，并且与现有方法相当或更高的性能，在高分辨率图像上Here’s the breakdown of each point:1. 为什么：提供高速、高质量图像彩度 correction 解决方案2. 如何：基于 deterministic color style transfer 的权重映射策略，具有 resolution-agnostic 特点，可整合任何预训练 AWB 网络3. 结果：实验结果表明，该方法可以实现至少 35 倍快的处理速度，并且与现有方法相当或更高的性能，在高分辨率图像上<details>
<summary>Abstract</summary>
Auto-white balance (AWB) correction is a critical operation in image signal processors for accurate and consistent color correction across various illumination scenarios. This paper presents a novel and efficient AWB correction method that achieves at least 35 times faster processing with equivalent or superior performance on high-resolution images for the current state-of-the-art methods. Inspired by deterministic color style transfer, our approach introduces deterministic illumination color mapping, leveraging learnable projection matrices for both canonical illumination form and AWB-corrected output. It involves feeding high-resolution images and corresponding latent representations into a mapping module to derive a canonical form, followed by another mapping module that maps the pixel values to those for the corrected version. This strategy is designed as resolution-agnostic and also enables seamless integration of any pre-trained AWB network as the backbone. Experimental results confirm the effectiveness of our approach, revealing significant performance improvements and reduced time complexity compared to state-of-the-art methods. Our method provides an efficient deep learning-based AWB correction solution, promising real-time, high-quality color correction for digital imaging applications. Source code is available at https://github.com/birdortyedi/DeNIM/
</details>
<details>
<summary>摘要</summary>
自动白平衡（AWB）修正是图像信号处理中的关键操作，以确保图像彩色 corrections 在不同照明场景下具有准确性和一致性。本文描述了一种新的和高效的 AWB 修正方法，可以在高分辨率图像上实现至少35倍的处理速度，与现有方法相当或更好的性能。我们的方法基于权值映射矩阵，通过学习映射矩阵来实现权值映射，并将其应用于AWB修正输出。我们的方法包括将高分辨率图像和相应的秘密表示 feed 到映射模块，以 derivation 一个征准形式，然后另一个映射模块将像素值映射到AWB修正后的像素值。这种策略是解决分辨率不依赖的，同时也可以轻松地将任何预训练的AWB网络作为后ION。实验结果表明我们的方法的有效性，表明与现有方法相比，具有显著的性能提升和处理时间减少。我们的方法提供了一种高效的深度学习基于AWB修正解决方案，承诺实时、高质量彩色修正 для数字摄影应用。代码可以在 <https://github.com/birdortyedi/DeNIM/> 上获取。
</details></li>
</ul>
<hr>
<h2 id="TIJO-Trigger-Inversion-with-Joint-Optimization-for-Defending-Multimodal-Backdoored-Models"><a href="#TIJO-Trigger-Inversion-with-Joint-Optimization-for-Defending-Multimodal-Backdoored-Models" class="headerlink" title="TIJO: Trigger Inversion with Joint Optimization for Defending Multimodal Backdoored Models"></a>TIJO: Trigger Inversion with Joint Optimization for Defending Multimodal Backdoored Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03906">http://arxiv.org/abs/2308.03906</a></li>
<li>repo_url: None</li>
<li>paper_authors: Indranil Sur, Karan Sikka, Matthew Walmer, Kaushik Koneripalli, Anirban Roy, Xiao Lin, Ajay Divakaran, Susmit Jha</li>
<li>for: 防止多 modal 模型中的 dual-key 后门攻击</li>
<li>methods: 使用 joint optimization 技术来反向工程 trigger，并在图像和文本模式之间进行协调优化</li>
<li>results: 在 TrojVQA 测试集上，TIJO 方法可以减少 dual-key 后门攻击的攻击效果，并且在单模态后门攻击中也表现出良好的效果<details>
<summary>Abstract</summary>
We present a Multimodal Backdoor Defense technique TIJO (Trigger Inversion using Joint Optimization). Recent work arXiv:2112.07668 has demonstrated successful backdoor attacks on multimodal models for the Visual Question Answering task. Their dual-key backdoor trigger is split across two modalities (image and text), such that the backdoor is activated if and only if the trigger is present in both modalities. We propose TIJO that defends against dual-key attacks through a joint optimization that reverse-engineers the trigger in both the image and text modalities. This joint optimization is challenging in multimodal models due to the disconnected nature of the visual pipeline which consists of an offline feature extractor, whose output is then fused with the text using a fusion module. The key insight enabling the joint optimization in TIJO is that the trigger inversion needs to be carried out in the object detection box feature space as opposed to the pixel space. We demonstrate the effectiveness of our method on the TrojVQA benchmark, where TIJO improves upon the state-of-the-art unimodal methods from an AUC of 0.6 to 0.92 on multimodal dual-key backdoors. Furthermore, our method also improves upon the unimodal baselines on unimodal backdoors. We present ablation studies and qualitative results to provide insights into our algorithm such as the critical importance of overlaying the inverted feature triggers on all visual features during trigger inversion. The prototype implementation of TIJO is available at https://github.com/SRI-CSL/TIJO.
</details>
<details>
<summary>摘要</summary>
我们提出了一种多模态后门防御技术TIJO（Trigger Inversion using Joint Optimization）。在最近的arXiv:2112.07668中，我们已经成功地实现了对多模态模型的后门攻击。这个后门触发器被分解成两个模式（图像和文本），只有在两个模式中都存在触发器时才会启动后门。我们的TIJO技术利用联合优化来防御双钥匙攻击，通过在图像和文本模式中对触发器进行反向工程。这个联合优化在多模态模型中是具有挑战性的，因为视觉管道中的数据都是独立的，包括一个离线特征提取器，其输出然后与文本模式进行融合。我们的关键发现是，在对触发器进行反向工程时，应该在图像特征空间进行，而不是像素空间。我们在TrojVQA benchmark上证明了TIJO的有效性，其在多模态双钥匙后门上从AUC 0.6提高到0.92，并且在单模态后门上也超过了单模态基线。我们还提供了简要的ablation study和Qualitative results，以便更好地理解我们的算法，如果在触发器反向工程中 overlaying 翻译的特征Trigger。TIJO的原型实现可以在https://github.com/SRI-CSL/TIJO中找到。
</details></li>
</ul>
<hr>
<h2 id="Developability-Approximation-for-Neural-Implicits-through-Rank-Minimization"><a href="#Developability-Approximation-for-Neural-Implicits-through-Rank-Minimization" class="headerlink" title="Developability Approximation for Neural Implicits through Rank Minimization"></a>Developability Approximation for Neural Implicits through Rank Minimization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03900">http://arxiv.org/abs/2308.03900</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pratheba Selvaraju</li>
<li>for: 该论文主要用于开发一种可以从二维面上无撕、无扭的三维表面的方法。</li>
<li>methods: 该方法基于神经隐函数，并通过添加一个正则化项来促进zero Gaussian curvature。</li>
<li>results: 实验结果表明，该方法可以准确地重建开发可能的表面，并且可以在受到噪声影响的情况下保持一定的精度。<details>
<summary>Abstract</summary>
Developability refers to the process of creating a surface without any tearing or shearing from a two-dimensional plane. It finds practical applications in the fabrication industry. An essential characteristic of a developable 3D surface is its zero Gaussian curvature, which means that either one or both of the principal curvatures are zero. This paper introduces a method for reconstructing an approximate developable surface from a neural implicit surface. The central idea of our method involves incorporating a regularization term that operates on the second-order derivatives of the neural implicits, effectively promoting zero Gaussian curvature. Implicit surfaces offer the advantage of smoother deformation with infinite resolution, overcoming the high polygonal constraints of state-of-the-art methods using discrete representations. We draw inspiration from the properties of surface curvature and employ rank minimization techniques derived from compressed sensing. Experimental results on both developable and non-developable surfaces, including those affected by noise, validate the generalizability of our method.
</details>
<details>
<summary>摘要</summary>
<<SYS>>将文本翻译为简化字符的中文。<</SYS>>发展可能性指的是将二维面变换为无撕裂、无剪裂的三维表面的过程。它在制造业中有实际应用。一个必要的特征是发展可能性表面的零 Gaussian 几何，这意味着一或两个主要几何都是零。这篇论文介绍了一种使用神经隐式函数来重建精确的发展可能性表面的方法。我们的中心思想是在神经隐式函数的第二阶导数上添加一个正则化项，以实现零 Gaussian 几何。隐式表面具有较平滑的变形和无限分辨率的优势，超越了现有方法使用分割表示的高 polygon 约束。我们启发自表面几何的属性，并使用压缩感知技术来解决矩阵问题。实验结果表明，我们的方法在发展可能性表面和非发展可能性表面，包括受噪声影响的情况下，具有普适性。
</details></li>
</ul>
<hr>
<h2 id="From-Sky-to-the-Ground-A-Large-scale-Benchmark-and-Simple-Baseline-Towards-Real-Rain-Removal"><a href="#From-Sky-to-the-Ground-A-Large-scale-Benchmark-and-Simple-Baseline-Towards-Real-Rain-Removal" class="headerlink" title="From Sky to the Ground: A Large-scale Benchmark and Simple Baseline Towards Real Rain Removal"></a>From Sky to the Ground: A Large-scale Benchmark and Simple Baseline Towards Real Rain Removal</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03867">http://arxiv.org/abs/2308.03867</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yunguo224/lhp-rain">https://github.com/yunguo224/lhp-rain</a></li>
<li>paper_authors: Yun Guo, Xueyao Xiao, Yi Chang, Shumin Deng, Luxin Yan</li>
<li>For: 提高实际雨天图像涂抹（RID）的进步，增加大规模高质量配对训练样本。* Methods: 构建了一个大规模高质量配对雨天图像数据集（LHP-Rain），包括3000个视频序列，100万高分辨率（1920<em>1080）帧对。提出了一种新的稳定低级 tensor 恢复模型，生成更好地分离静背景和动雨。设计了一种简单的 transformer 基于单图雨涂抹基线，同时利用自身关注和跨层关注，具有捕捉特征表示。</em> Results: 对比 existing 方法，提出的 dataset 和 deraining 方法具有显著的优势，在雨天图像涂抹任务中具有更高的性能。<details>
<summary>Abstract</summary>
Learning-based image deraining methods have made great progress. However, the lack of large-scale high-quality paired training samples is the main bottleneck to hamper the real image deraining (RID). To address this dilemma and advance RID, we construct a Large-scale High-quality Paired real rain benchmark (LHP-Rain), including 3000 video sequences with 1 million high-resolution (1920*1080) frame pairs. The advantages of the proposed dataset over the existing ones are three-fold: rain with higher-diversity and larger-scale, image with higher-resolution and higher-quality ground-truth. Specifically, the real rains in LHP-Rain not only contain the classical rain streak/veiling/occlusion in the sky, but also the \textbf{splashing on the ground} overlooked by deraining community. Moreover, we propose a novel robust low-rank tensor recovery model to generate the GT with better separating the static background from the dynamic rain. In addition, we design a simple transformer-based single image deraining baseline, which simultaneously utilize the self-attention and cross-layer attention within the image and rain layer with discriminative feature representation. Extensive experiments verify the superiority of the proposed dataset and deraining method over state-of-the-art.
</details>
<details>
<summary>摘要</summary>
学习基于的图像雨排除方法已经做出了大量的进步。然而，缺乏大规模高质量对应训练样本是阻碍真实图像雨排除（RID）的主要瓶颈。为解决这个困难和提高RID，我们构建了大规模高质量对应雨天 benchmark（LHP-Rain），包括3000个视频序列和100万高分辨率（1920*1080）帧对。LHP-Rain中的雨水比现有的 dataset 更多样化和大规模，图像质量更高，附加的雨水ground truth 更加准确。具体来说，LHP-Rain 中的雨水不仅包括天空中的класси型雨条/遮盲/占据，还包括在地面上的溅射，这一点在雨排除社区中很少被考虑。此外，我们提出了一种新的robust低级张量回归模型，用于生成更加分离静态背景和动态雨水的GT。此外，我们设计了一种简单的 transformer 基于的单图像雨排除基线，同时利用自身关注和跨层关注，在图像和雨层中同时使用特征表示。广泛的实验证明了我们提出的数据集和雨排除方法的优越性。
</details></li>
</ul>
<hr>
<h2 id="DefCor-Net-Physics-Aware-Ultrasound-Deformation-Correction"><a href="#DefCor-Net-Physics-Aware-Ultrasound-Deformation-Correction" class="headerlink" title="DefCor-Net: Physics-Aware Ultrasound Deformation Correction"></a>DefCor-Net: Physics-Aware Ultrasound Deformation Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03865">http://arxiv.org/abs/2308.03865</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/karolinezhy/defcornet">https://github.com/karolinezhy/defcornet</a></li>
<li>paper_authors: Zhongliang Jiang, Yue Zhou, Dongliang Cao, Nassir Navab</li>
<li>for: 这篇论文的目的是对于ultrasound（US）图像取得中的形状扭曲进行修正，以提高诊断的精度和一致性。</li>
<li>methods: 这篇论文提出了一个基于多对多深度学习网络（DefCor-Net）的新型生物学知识感知扭曲修正方法。这个方法通过在粗细对称的特征提取器中进行精确的缩寸推导，以便在当前测量力的基础上线性回归扭曲场。</li>
<li>results: 根据实验结果显示，DefCor-Net可以对于US图像进行高精度的形状修正，从而回复原始的几何结构（Dice Coefficient：从 $14.3\pm20.9$ 提高至 $82.6\pm12.1$，当力量为 $6N$）。<details>
<summary>Abstract</summary>
The recovery of morphologically accurate anatomical images from deformed ones is challenging in ultrasound (US) image acquisition, but crucial to accurate and consistent diagnosis, particularly in the emerging field of computer-assisted diagnosis. This article presents a novel anatomy-aware deformation correction approach based on a coarse-to-fine, multi-scale deep neural network (DefCor-Net). To achieve pixel-wise performance, DefCor-Net incorporates biomedical knowledge by estimating pixel-wise stiffness online using a U-shaped feature extractor. The deformation field is then computed using polynomial regression by integrating the measured force applied by the US probe. Based on real-time estimation of pixel-by-pixel tissue properties, the learning-based approach enables the potential for anatomy-aware deformation correction. To demonstrate the effectiveness of the proposed DefCor-Net, images recorded at multiple locations on forearms and upper arms of six volunteers are used to train and validate DefCor-Net. The results demonstrate that DefCor-Net can significantly improve the accuracy of deformation correction to recover the original geometry (Dice Coefficient: from $14.3\pm20.9$ to $82.6\pm12.1$ when the force is $6N$).
</details>
<details>
<summary>摘要</summary>
“ ultrasound（US）图像获取中，形态准确性的图像恢复是一项挑战，但是对医学诊断的准确性和一致性具有极高的重要性，特别是在计算机助动诊断领域。本文提出了一种基于多尺度深度神经网络（DefCor-Net）的新型形态意识恢复方法。为了实现像素级的表现，DefCor-Net在核心网络中包含生物医学知识，并且在线计算每个像素的刚性。通过把测量US探针所应用的力场 интеグрирова到多元函数回归，DefCor-Net计算出了形态场。基于实时测量每个像素的组织特性，这种学习基于的方法具有潜在的形态意识恢复能力。为证明DefCor-Net的有效性，使用了多个臂和肘的六名志愿者所记录的图像进行训练和验证。结果显示，DefCor-Net可以显著改善对形态恢复的准确性（Dice Coefficient：从14.3±20.9到82.6±12.1，当力场为6N）。”Note: The translation is in Simplified Chinese, which is the standardized form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="High-Throughput-and-Accurate-3D-Scanning-of-Cattle-Using-Time-of-Flight-Sensors-and-Deep-Learning"><a href="#High-Throughput-and-Accurate-3D-Scanning-of-Cattle-Using-Time-of-Flight-Sensors-and-Deep-Learning" class="headerlink" title="High-Throughput and Accurate 3D Scanning of Cattle Using Time-of-Flight Sensors and Deep Learning"></a>High-Throughput and Accurate 3D Scanning of Cattle Using Time-of-Flight Sensors and Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03861">http://arxiv.org/abs/2308.03861</a></li>
<li>repo_url: None</li>
<li>paper_authors: Gbenga Omotara, Seyed Mohamad Ali Tousi, Jared Decker, Derek Brake, Guilherme N. DeSouza</li>
<li>for: 这个论文是为了开发一种高速三维扫描解决方案，用于准确测量牛的形态特征。</li>
<li>methods: 这个系统使用了一个数组深度感知器，包括时间探测（Tof）感知器，每个感知器都由专门的嵌入式设备控制。系统能够生成高质量的3D点云，从而生成高精度的牛形态模型。</li>
<li>results: 根据实验结果，提出的系统能够生成高质量的牛形态模型，并且可以准确测量牛的体积和表面积。<details>
<summary>Abstract</summary>
We introduce a high throughput 3D scanning solution specifically designed to precisely measure cattle phenotypes. This scanner leverages an array of depth sensors, i.e. time-of-flight (Tof) sensors, each governed by dedicated embedded devices. The system excels at generating high-fidelity 3D point clouds, thus facilitating an accurate mesh that faithfully reconstructs the cattle geometry on the fly. In order to evaluate the performance of our system, we have implemented a two-fold validation process. Initially, we test the scanner's competency in determining volume and surface area measurements within a controlled environment featuring known objects. Secondly, we explore the impact and necessity of multi-device synchronization when operating a series of time-of-flight sensors. Based on the experimental results, the proposed system is capable of producing high-quality meshes of untamed cattle for livestock studies.
</details>
<details>
<summary>摘要</summary>
我们介绍了一种高通量3D扫描解决方案，专门为精确测量牛phenotype提供。这个扫描仪使用了一组深度感知器，即时光探测（ToF）感知器，每个感知器由专门的嵌入式设备控制。系统能够生成高品质3D点云，从而实现精确重建牛体均匀的三维模型。为评估我们的系统性能，我们实施了两重验证过程。首先，我们测试了扫描仪在控制台上测量物体体积和表面积的能力。其次，我们探索了在多个时光探测感知器同时运行时的多设备同步的影响和必要性。根据实验结果，我们的系统能够生成高质量牛体三维模型，为畜牧学研究提供有价值的数据。
</details></li>
</ul>
<hr>
<h2 id="3D-Motion-Magnification-Visualizing-Subtle-Motions-with-Time-Varying-Radiance-Fields"><a href="#3D-Motion-Magnification-Visualizing-Subtle-Motions-with-Time-Varying-Radiance-Fields" class="headerlink" title="3D Motion Magnification: Visualizing Subtle Motions with Time Varying Radiance Fields"></a>3D Motion Magnification: Visualizing Subtle Motions with Time Varying Radiance Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03757">http://arxiv.org/abs/2308.03757</a></li>
<li>repo_url: None</li>
<li>paper_authors: Brandon Y. Feng, Hadi Alzayer, Michael Rubinstein, William T. Freeman, Jia-Bin Huang</li>
<li>for: 这个论文旨在帮助我们更好地视觉化某些不可见的运动，尤其是在运动camera中捕捉的场景中。</li>
<li>methods: 该论文提出了一种基于时变辐射场的3D动态扩大方法，可以在运动camera中捕捉的场景中增强微不可见的运动。该方法基于律动原理，通过EXTRACT和增强 embedding点的变化来实现动态扩大。</li>
<li>results: 该论文通过使用不同的场景和摄像头设置进行了研究和验证，并证明了其效果。<details>
<summary>Abstract</summary>
Motion magnification helps us visualize subtle, imperceptible motion. However, prior methods only work for 2D videos captured with a fixed camera. We present a 3D motion magnification method that can magnify subtle motions from scenes captured by a moving camera, while supporting novel view rendering. We represent the scene with time-varying radiance fields and leverage the Eulerian principle for motion magnification to extract and amplify the variation of the embedding of a fixed point over time. We study and validate our proposed principle for 3D motion magnification using both implicit and tri-plane-based radiance fields as our underlying 3D scene representation. We evaluate the effectiveness of our method on both synthetic and real-world scenes captured under various camera setups.
</details>
<details>
<summary>摘要</summary>
运动增大帮助我们可见到微不足的运动。然而，先前的方法只适用于 fix 摄像机拍摄的 2D 视频。我们提出了一种支持新视图渲染的3D 运动增大方法，可以增大 captured by a moving camera 中的微不足运动。我们使用时间变化的辐射场来表示场景，并利用儒利安理则来提取和增强时间上点的变化。我们对使用 implicit 和 tri-plane-based 辐射场作为场景表示方法进行了研究和验证。我们对具有不同摄像机设置的 both synthetic 和实际场景进行了评估。
</details></li>
</ul>
<hr>
<h2 id="FSD-V2-Improving-Fully-Sparse-3D-Object-Detection-with-Virtual-Voxels"><a href="#FSD-V2-Improving-Fully-Sparse-3D-Object-Detection-with-Virtual-Voxels" class="headerlink" title="FSD V2: Improving Fully Sparse 3D Object Detection with Virtual Voxels"></a>FSD V2: Improving Fully Sparse 3D Object Detection with Virtual Voxels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03755">http://arxiv.org/abs/2308.03755</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tusen-ai/sst">https://github.com/tusen-ai/sst</a></li>
<li>paper_authors: Lue Fan, Feng Wang, Naiyan Wang, Zhaoxiang Zhang</li>
<li>for: 这篇论文目的是提出一种简化FSDv1的方法，以提高其普适性和性能。</li>
<li>methods: 这篇论文使用了虚拟voxel的概念，取代了FSDv1中的归一化实例分割。虚拟voxel不仅能解决完全稀缺探测器中的中心特征缺失问题，还使得框架更加简洁和流畅。</li>
<li>results: 这篇论文在三个大规模数据集上进行了实验，包括Waymo开放数据集、Argoverse 2数据集和nuScenes数据集。结果显示FSDv2在长距离场景中表现出色，并在多种场景中具有竞争性的性能。此外，论文还提供了详细的实验分析，以便促进可重复性和进一步研究。<details>
<summary>Abstract</summary>
LiDAR-based fully sparse architecture has garnered increasing attention. FSDv1 stands out as a representative work, achieving impressive efficacy and efficiency, albeit with intricate structures and handcrafted designs. In this paper, we present FSDv2, an evolution that aims to simplify the previous FSDv1 while eliminating the inductive bias introduced by its handcrafted instance-level representation, thus promoting better general applicability. To this end, we introduce the concept of \textbf{virtual voxels}, which takes over the clustering-based instance segmentation in FSDv1. Virtual voxels not only address the notorious issue of the Center Feature Missing problem in fully sparse detectors but also endow the framework with a more elegant and streamlined approach. Consequently, we develop a suite of components to complement the virtual voxel concept, including a virtual voxel encoder, a virtual voxel mixer, and a virtual voxel assignment strategy. Through empirical validation, we demonstrate that the virtual voxel mechanism is functionally similar to the handcrafted clustering in FSDv1 while being more general. We conduct experiments on three large-scale datasets: Waymo Open Dataset, Argoverse 2 dataset, and nuScenes dataset. Our results showcase state-of-the-art performance on all three datasets, highlighting the superiority of FSDv2 in long-range scenarios and its general applicability to achieve competitive performance across diverse scenarios. Moreover, we provide comprehensive experimental analysis to elucidate the workings of FSDv2. To foster reproducibility and further research, we have open-sourced FSDv2 at https://github.com/tusen-ai/SST.
</details>
<details>
<summary>摘要</summary>
“LiDAR-based弹性探测 Architecture 在最近得到了增加的注意。FSDv1 作为代表性的工作，成功地实现了出色的效率和可靠性，但具有复杂的结构和手工设计。在这篇论文中，我们提出 FSDv2，它是 FSDv1 的进化，旨在简化前一代的结构，消除实例级别表示所引入的预设偏见，以提高更好的通用性。为此，我们引入了“虚拟小体”概念，取代 FSDv1 中的弹性分割。虚拟小体不仅解决了完全缺失中心特征问题，还赋予框架更加简洁和流畅的方式。为此，我们开发了一套辅助虚拟小体的组件，包括虚拟小体编码器、虚拟小体混合器和虚拟小体分配策略。通过实验验证，我们证明虚拟小体机制与 FSDv1 中手工 clustering 功能相似，但更加通用。我们在 Waymo Open Dataset、Argoverse 2 dataset 和 nuScenes dataset 上进行了实验，我们的结果显示 FSDv2 在长距离场景中具有状态机器人的性能，并在多种场景中实现了竞争性的表现。此外，我们进行了全面的实验分析，以便更好地解释 FSDv2 的工作原理。为了促进可重复性和进一步研究，我们将 FSDv2 开源在 GitHub 上，请参考 <https://github.com/tusen-ai/SST>。”
</details></li>
</ul>
<hr>
<h2 id="Mask-Frozen-DETR-High-Quality-Instance-Segmentation-with-One-GPU"><a href="#Mask-Frozen-DETR-High-Quality-Instance-Segmentation-with-One-GPU" class="headerlink" title="Mask Frozen-DETR: High Quality Instance Segmentation with One GPU"></a>Mask Frozen-DETR: High Quality Instance Segmentation with One GPU</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03747">http://arxiv.org/abs/2308.03747</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhanhao Liang, Yuhui Yuan</li>
<li>for: 研究如何建立具有最小训练时间和GPU资源的强大实例分割模型，而不是现有的大多数方法尝试通过建立更复杂的框架来提高实例分割模型的准确率，以及这种方法的简单性和通用性。</li>
<li>methods: 我们提出了一种简单的普适框架，称为Mask Frozen-DETR，可以将任何现有的DETR基于对象检测模型转换成强大的实例分割模型。我们的方法仅需训练一个轻量级的mask网络，该网络在固定DETR基于对象检测器的 bounding box 中预测实例mask。</li>
<li>results: 我们的方法在COCO测试数据集上的测试预测中，与状态当前的实例分割方法Mask DINO相比，提高了性能（55.3% vs. 54.7%），并且在训练时间和GPU资源上减少了训练时间的多少（10X）。此外，我们的所有实验都可以使用一个Tesla V100 GPU With 16 GB的内存进行训练，表明了我们提出的框架的显著高效性。<details>
<summary>Abstract</summary>
In this paper, we aim to study how to build a strong instance segmenter with minimal training time and GPUs, as opposed to the majority of current approaches that pursue more accurate instance segmenter by building more advanced frameworks at the cost of longer training time and higher GPU requirements. To achieve this, we introduce a simple and general framework, termed Mask Frozen-DETR, which can convert any existing DETR-based object detection model into a powerful instance segmentation model. Our method only requires training an additional lightweight mask network that predicts instance masks within the bounding boxes given by a frozen DETR-based object detector. Remarkably, our method outperforms the state-of-the-art instance segmentation method Mask DINO in terms of performance on the COCO test-dev split (55.3% vs. 54.7%) while being over 10X times faster to train. Furthermore, all of our experiments can be trained using only one Tesla V100 GPU with 16 GB of memory, demonstrating the significant efficiency of our proposed framework.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们目的是研究如何使用最少的训练时间和GPU来构建一个强大的实例分割器，而不是现有的大多数方法，它们通过建立更高级的框架来提高实例分割器的准确率，但是这会导致训练时间更长和GPU需求更高。为此，我们提出了一个简单和通用的框架，称为Mask Frozen-DETR，它可以将任何现有的DETR基于对象检测模型转化成一个强大的实例分割模型。我们的方法只需训练一个轻量级的面网络，该网络可以在冻结的DETR基于对象检测模型提供的 bounding box 内预测实例面。值得注意的是，我们的方法在 COCO 测试发展集上比 state-of-the-art 实例分割方法 Mask DINO 高出0.6%的性能（55.3% vs. 54.7%），而且训练时间比 Mask DINO 快上10倍。此外，我们所有的实验都可以使用单个 Tesla V100 GPU  WITH 16 GB 内存进行训练，这表明我们提出的方法具有显著的效率。
</details></li>
</ul>
<hr>
<h2 id="AdaptiveSAM-Towards-Efficient-Tuning-of-SAM-for-Surgical-Scene-Segmentation"><a href="#AdaptiveSAM-Towards-Efficient-Tuning-of-SAM-for-Surgical-Scene-Segmentation" class="headerlink" title="AdaptiveSAM: Towards Efficient Tuning of SAM for Surgical Scene Segmentation"></a>AdaptiveSAM: Towards Efficient Tuning of SAM for Surgical Scene Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03726">http://arxiv.org/abs/2308.03726</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jayparanjape/biastuning">https://github.com/jayparanjape/biastuning</a></li>
<li>paper_authors: Jay N. Paranjape, Nithin Gopalakrishnan Nair, Shameema Sikder, S. Swaroop Vedula, Vishal M. Patel<br>for:这篇论文是为了解决人工智能在外科Scene分析中的基本问题，即数据稀缺性问题。methods:这篇论文提出了一种基于Segment-Anything（SAM）模型的适应方法，即AdaptiveSAM，可以快速地适应新的数据集，同时允许文本提示分割。results:实验表明，AdaptiveSAM可以在各种医学影像数据集上出perform better than当前状态的方法，包括手术、超声和X射线等。<details>
<summary>Abstract</summary>
Segmentation is a fundamental problem in surgical scene analysis using artificial intelligence. However, the inherent data scarcity in this domain makes it challenging to adapt traditional segmentation techniques for this task. To tackle this issue, current research employs pretrained models and finetunes them on the given data. Even so, these require training deep networks with millions of parameters every time new data becomes available. A recently published foundation model, Segment-Anything (SAM), generalizes well to a large variety of natural images, hence tackling this challenge to a reasonable extent. However, SAM does not generalize well to the medical domain as is without utilizing a large amount of compute resources for fine-tuning and using task-specific prompts. Moreover, these prompts are in the form of bounding-boxes or foreground/background points that need to be annotated explicitly for every image, making this solution increasingly tedious with higher data size. In this work, we propose AdaptiveSAM - an adaptive modification of SAM that can adjust to new datasets quickly and efficiently, while enabling text-prompted segmentation. For finetuning AdaptiveSAM, we propose an approach called bias-tuning that requires a significantly smaller number of trainable parameters than SAM (less than 2\%). At the same time, AdaptiveSAM requires negligible expert intervention since it uses free-form text as prompt and can segment the object of interest with just the label name as prompt. Our experiments show that AdaptiveSAM outperforms current state-of-the-art methods on various medical imaging datasets including surgery, ultrasound and X-ray. Code is available at https://github.com/JayParanjape/biastuning
</details>
<details>
<summary>摘要</summary>
划分是跨域诊断中的基本问题，但由于医学领域数据的稀缺性，使得传统划分技术难以适应这个任务。为解决这个问题，当前的研究通常使用预训练模型，并对其进行微调。然而，这需要训练深度网络数百万个参数，每次新数据available时需要重新训练。一个最近发表的基础模型Segment-Anything（SAM）能够通用于各种自然图像，因此有所减轻这个问题。然而，SAM在医学领域中不具备泛化能力，需要大量计算资源进行微调，并使用任务特有的提示。这些提示通常是 bounding-boxes 或 foreground/background 点，需要明确标注每个图像，这使得该解决方案难以扩展。在这项工作中，我们提出了 AdaptiveSAM，一种适应型的 SAM 修改。AdaptiveSAM 可以快速地适应新的数据集，而且可以通过自由文本提示进行文本识别。我们还提出了一种偏好调整方法，可以在微调 AdaptiveSAM 时减少参数的数量，至少比 SAM 少于 2%。同时，AdaptiveSAM 需要非常少的专家干预，因为它使用自由文本提示，并且可以通过对象关键词来 segment 目标对象。我们的实验表明，AdaptiveSAM 在各种医学成像数据集上表现出色，包括手术、ultrasound 和 X-ray。代码可以在 https://github.com/JayParanjape/biastuning 上获取。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Temporal-Sentence-Grounding-in-Videos-with-Multi-Teacher-Knowledge-Distillation"><a href="#Efficient-Temporal-Sentence-Grounding-in-Videos-with-Multi-Teacher-Knowledge-Distillation" class="headerlink" title="Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation"></a>Efficient Temporal Sentence Grounding in Videos with Multi-Teacher Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03725">http://arxiv.org/abs/2308.03725</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renjie Liang, Yiming Yang, Hui Lu, Li Li</li>
<li>for: 本研究旨在探讨如何从未处理过的视频中检测自然语言查询中描述的事件时间戳，并提出一种高效的方法。</li>
<li>methods: 该研究提出了一种基于知识储存的高效多教师模型（EMTM），通过将多种不同的网络结构融合到一起，以提高计算效率而不失效果。</li>
<li>results: 实验结果表明，该方法可以在三个常用的TSGV测试集上达到高效性和精度的平衡，而无需使用复杂的架构和损失函数。<details>
<summary>Abstract</summary>
Temporal Sentence Grounding in Videos (TSGV) aims to detect the event timestamps described by the natural language query from untrimmed videos. This paper discusses the challenge of achieving efficient computation in TSGV models while maintaining high performance. Most existing approaches exquisitely design complex architectures to improve accuracy with extra layers and loss, suffering from inefficiency and heaviness. Although some works have noticed that, they only make an issue of feature fusion layers, which can hardly enjoy the highspeed merit in the whole clunky network. To tackle this problem, we propose a novel efficient multi-teacher model (EMTM) based on knowledge distillation to transfer diverse knowledge from both heterogeneous and isomorphic networks. Specifically, We first unify different outputs of the heterogeneous models into one single form. Next, a Knowledge Aggregation Unit (KAU) is built to acquire high-quality integrated soft labels from multiple teachers. After that, the KAU module leverages the multi-scale video and global query information to adaptively determine the weights of different teachers. A Shared Encoder strategy is then proposed to solve the problem that the student shallow layers hardly benefit from teachers, in which an isomorphic teacher is collaboratively trained with the student to align their hidden states. Extensive experimental results on three popular TSGV benchmarks demonstrate that our method is both effective and efficient without bells and whistles.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Automated-Real-Time-Delineation-of-Supraclavicular-Brachial-Plexus-in-Neck-Ultrasonography-Videos-A-Deep-Learning-Approach"><a href="#Automated-Real-Time-Delineation-of-Supraclavicular-Brachial-Plexus-in-Neck-Ultrasonography-Videos-A-Deep-Learning-Approach" class="headerlink" title="Automated Real Time Delineation of Supraclavicular Brachial Plexus in Neck Ultrasonography Videos: A Deep Learning Approach"></a>Automated Real Time Delineation of Supraclavicular Brachial Plexus in Neck Ultrasonography Videos: A Deep Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03717">http://arxiv.org/abs/2308.03717</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhay Tyagi, Abhishek Tyagi, Manpreet Kaur, Jayanthi Sivaswami, Richa Aggarwal, Kapil Dev Soni, Anjan Trikha</li>
<li>for: 这个研究是为了探索使用深度学习模型来进行 neck ultrasound 影像中的副claviicular brachial plexus 的现场分类，以提高医疗执行者对这些影像的识别和分类能力。</li>
<li>methods: 这个研究使用了三种不同的 ultrasound 机器，将227个系统扫描到supraclavicular和interscalene brachial plexus 的不同设定中，共产生了227个唯一的影像视频。这些影像被227名经验丰富的医生评估和标注，并使用了部分自动化的物件追踪和活动曲线算法来标注影像。</li>
<li>results: 研究结果显示，使用深度学习模型可以实现高准确性和可靠性的现场分类，并且可以区别supraclavicular和邻近的interscalene brachial plexus。此外，研究也显示了不同的 ultrasound 机器的影像数据集可以通过精致化和无需精致化的方法来进行数据集的整合和标注。<details>
<summary>Abstract</summary>
Peripheral nerve blocks are crucial to treatment of post-surgical pain and are associated with reduction in perioperative opioid use and hospital stay. Accurate interpretation of sono-anatomy is critical for the success of ultrasound (US) guided peripheral nerve blocks and can be challenging to the new operators. This prospective study enrolled 227 subjects who were systematically scanned for supraclavicular and interscalene brachial plexus in various settings using three different US machines to create a dataset of 227 unique videos. In total, 41,000 video frames were annotated by experienced anaesthesiologists using partial automation with object tracking and active contour algorithms. Four baseline neural network models were trained on the dataset and their performance was evaluated for object detection and segmentation tasks. Generalizability of the best suited model was then tested on the datasets constructed from separate US scanners with and without fine-tuning. The results demonstrate that deep learning models can be leveraged for real time segmentation of supraclavicular brachial plexus in neck ultrasonography videos with high accuracy and reliability. Model was also tested for its ability to differentiate between supraclavicular and adjoining interscalene brachial plexus. The entire dataset has been released publicly for further study by the research community.
</details>
<details>
<summary>摘要</summary>
périphériques nerve blocks sont essentielles pour le traitement de la douleur postopératoire et sont associées à une réduction de l'utilisation de morphiniques periopératoires et de la durée de hospitalisation. L'interprétation accurate de la sono-anatomie est critique pour le succès des blocks nerveuses guidées par ultrason (US) et peut être challengeante pour les nouveaux opérateurs. Cette étude prospective a enrôlé 227 sujets qui ont été systématiquement scannés pour le plexus brachial supraclaviculaire et interscapulin au moyen de trois machines US différentes pour créer un ensemble de 227 vidéos uniques. Au total, 41 000 cadres de vidéo ont été annotés par des anesthésiologistes expérimentés utilisant une partial automation avec des algorithmes de suivi d'objets et de contours actifs. Quatre modèles de réseaux de neurones basiques ont été entraînés sur le dataset et leur performance a été évaluée pour les tâches de détection et de segmentation d'objets. La généralisation du modèle le plus adapté a été testée sur les données constructives de scanners US différents, avec et sans fine-tuning. Les résultats montrent que les modèles d'apprentissage profond peuvent être utilisés pour la segmentation en temps réel du plexus brachial supraclaviculaire dans les vidéos d'ultrasonographie du cou avec une précision et une fiabilité élevées. Le modèle a également été testé pour sa capacité à distinguer entre le plexus brachial supraclaviculaire et l'adjoignant plexus interscapulin. Le tout dataset a été libéré au public pour une étude supplémentaire par la communauté de la recherche.
</details></li>
</ul>
<hr>
<h2 id="Scaling-may-be-all-you-need-for-achieving-human-level-object-recognition-capacity-with-human-like-visual-experience"><a href="#Scaling-may-be-all-you-need-for-achieving-human-level-object-recognition-capacity-with-human-like-visual-experience" class="headerlink" title="Scaling may be all you need for achieving human-level object recognition capacity with human-like visual experience"></a>Scaling may be all you need for achieving human-level object recognition capacity with human-like visual experience</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03712">http://arxiv.org/abs/2308.03712</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/eminorhan/humanlike-vits">https://github.com/eminorhan/humanlike-vits</a></li>
<li>paper_authors: A. Emin Orhan</li>
<li>for: 这种研究是为了检验当今自动学习方法是否可以通过增加数据量和模型大小来达到人类级视觉对象识别能力。</li>
<li>methods: 这种研究使用了掩Masked autoencoders (MAEs)作为自动学习算法，并在增加数据量、模型大小和图像分辨率的情况下进行了涨scale experiment。</li>
<li>results: 研究发现，通过同时增加数据量、模型大小和图像分辨率，可以达到人类级视觉对象识别能力，但需要在模型大小、数据量和图像分辨率的增加中同步进行调整。例如，一个2.5B参数的ViT模型，通过20K小时（2.3年）的人类类视频数据和952x952像素的空间分辨率进行训练，应该可以达到人类级准确率在ImageNet。<details>
<summary>Abstract</summary>
This paper asks whether current self-supervised learning methods, if sufficiently scaled up, would be able to reach human-level visual object recognition capabilities with the same type and amount of visual experience humans learn from. Previous work on this question only considered the scaling of data size. Here, we consider the simultaneous scaling of data size, model size, and image resolution. We perform a scaling experiment with vision transformers up to 633M parameters in size (ViT-H/14) trained with up to 5K hours of human-like video data (long, continuous, mostly egocentric videos) with image resolutions of up to 476x476 pixels. The efficiency of masked autoencoders (MAEs) as a self-supervised learning algorithm makes it possible to run this scaling experiment on an unassuming academic budget. We find that it is feasible to reach human-level object recognition capacity at sub-human scales of model size, data size, and image size, if these factors are scaled up simultaneously. To give a concrete example, we estimate that a 2.5B parameter ViT model trained with 20K hours (2.3 years) of human-like video data with a spatial resolution of 952x952 pixels should be able to reach roughly human-level accuracy on ImageNet. Human-level competence is thus achievable for a fundamental perceptual capability from human-like perceptual experience (human-like in both amount and type) with extremely generic learning algorithms and architectures and without any substantive inductive biases.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Prototype-Learning-for-Out-of-Distribution-Polyp-Segmentation"><a href="#Prototype-Learning-for-Out-of-Distribution-Polyp-Segmentation" class="headerlink" title="Prototype Learning for Out-of-Distribution Polyp Segmentation"></a>Prototype Learning for Out-of-Distribution Polyp Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03709">http://arxiv.org/abs/2308.03709</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikhil Kumar Tomar, Debesh Jha, Ulas Bagci</li>
<li>for: 本研究的目的是创建一个可靠和通用的肿瘤 segmentation 模型，以便在不同中心的数据集上提供可靠的 segmentation 结果。</li>
<li>methods: 我们的模型使用了不同的照明模式，如白光 imaging (WLI)、蓝光 imaging (BLI)、 Linked color imaging (LCI) 和 flexible spectral imaging color enhancement (FICE)，并使用 prototype 来表示每种对象类的特征特征，例如形状、Texture 和颜色。</li>
<li>results: 我们的模型可以在不同中心的数据集上提供高达 $\geq$ 90%的 dice 系数和 $\geq$ 85%的 mIoU 分割精度，并且具有实时处理速度。在对 16 种现状顶尖图像分割架构进行比较时，我们的方法表现出了超越性，这可能将改善临床结果。<details>
<summary>Abstract</summary>
Existing polyp segmentation models from colonoscopy images often fail to provide reliable segmentation results on datasets from different centers, limiting their applicability. Our objective in this study is to create a robust and well-generalized segmentation model named PrototypeLab that can assist in polyp segmentation. To achieve this, we incorporate various lighting modes such as White light imaging (WLI), Blue light imaging (BLI), Linked color imaging (LCI), and Flexible spectral imaging color enhancement (FICE) into our new segmentation model, that learns to create prototypes for each class of object present in the images. These prototypes represent the characteristic features of the objects, such as their shape, texture, color. Our model is designed to perform effectively on out-of-distribution (OOD) datasets from multiple centers. We first generate a coarse mask that is used to learn prototypes for the main object class, which are then employed to generate the final segmentation mask. By using prototypes to represent the main class, our approach handles the variability present in the medical images and generalize well to new data since prototype capture the underlying distribution of the data. PrototypeLab offers a promising solution with a dice coefficient of $\geq$ 90\% and mIoU $\geq$ 85\% with a near real-time processing speed for polyp segmentation. It achieved superior performance on OOD datasets compared to 16 state-of-the-art image segmentation architectures, potentially improving clinical outcomes. Codes are available at https://github.com/xxxxx/PrototypeLab.
</details>
<details>
<summary>摘要</summary>
traditional Chinese version:现有的肿体段化模型从医学护理影像中的分段结果不可靠，限制了它们的实用性。我们的目标是创建一个可靠和普遍适用的分段模型，名为PrototypeLab，可以帮助进行肿体段化。为了实现这一目标，我们在新的分段模型中 integrate了不同的照明方式，如白光成像（WLI）、蓝光成像（BLI）、相关颜色成像（LCI）和可变色spectral成像（FICE）。这些照明方式的整合使我们的新分段模型学习出每个类别对应的原型，这些原型表示对象的形状、 текстура和颜色的特征特征。我们的模型设计能够在多个中心的数据集上表现出色，并且可以快速处理数据。我们首先生成一个粗略的mask，并使用这个mask来学习每个主要类别的原型，然后使用这些原型生成最终的分段mask。通过使用原型来表示主要类别，我们的方法可以处理医学影像中的变化，并且可以很好地适应新数据，因为原型捕捉了数据的下面分布。PrototypeLab提供了一个有 promise的解决方案，其中 dice coefficient ≥ 90%和mIoU ≥ 85%，并且具有近实时处理速度。它在多个中心的数据集上表现出色，并且超过了16种state-of-the-art图像分 segmentation模型，可能改善临床结果。代码可以在https://github.com/xxxxx/PrototypeLab 获取。Here's the translation in Simplified Chinese:现有的肿体段化模型经常无法在不同中心的数据集上提供可靠的分段结果，这限制了它们的实用性。我们的目标是创建一个可靠和普遍适用的分段模型，名为PrototypeLab，可以帮助进行肿体段化。为了实现这一目标，我们在新的分段模型中 integrate了不同的照明方式，如白光成像（WLI）、蓝光成像（BLI）、相关颜色成像（LCI）和可变色spectral成像（FICE）。这些照明方式的整合使我们的新分段模型学习出每个类别对应的原型，这些原型表示对象的形状、 текстуra和颜色的特征特征。我们的模型设计能够在多个中心的数据集上表现出色，并且可以快速处理数据。我们首先生成一个粗略的mask，并使用这个mask来学习每个主要类别的原型，然后使用这些原型生成最终的分段mask。通过使用原型来表示主要类别，我们的方法可以处理医学影像中的变化，并且可以很好地适应新数据，因为原型捕捉了数据的下面分布。PrototypeLab提供了一个有 promise的解决方案，其中 dice coefficient ≥ 90%和mIoU ≥ 85%，并且具有近实时处理速度。它在多个中心的数据集上表现出色，并且超过了16种state-of-the-art图像分 segmentation模型，可能改善临床结果。代码可以在https://github.com/xxxxx/PrototypeLab 获取。
</details></li>
</ul>
<hr>
<h2 id="Video-based-Person-Re-identification-with-Long-Short-Term-Representation-Learning"><a href="#Video-based-Person-Re-identification-with-Long-Short-Term-Representation-Learning" class="headerlink" title="Video-based Person Re-identification with Long Short-Term Representation Learning"></a>Video-based Person Re-identification with Long Short-Term Representation Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03703">http://arxiv.org/abs/2308.03703</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuehu Liu, Pingping Zhang, Huchuan Lu</li>
<li>for: 视频基于人识别（V-ReID）任务是从非重叠摄像机捕捉的 raw 视频中 Retrieval 特定人员，是多媒体和计算机视ión应用的基本任务。然而，由于人员和场景的变化，高性能的实现仍然面临着许多挑战。</li>
<li>methods: 我们注意到人员的长期和短期信息都是重要的robust视频表示。因此，我们提出了一种新的深度学习框架，即 Long Short-Term Representation Learning（LSTRL），以提高 V-ReID 的效果。更具体来说，我们提出了一种 Multi-granularity Appearance Extractor（MAE），可以有效地在多帧中捕捉四种粒度的外观表示。同时，我们提出了一种 Bi-direction Motion Estimator（BME），可以高效地从邻帧中提取回传信息。MAE 和 BME 都可以与现有网络结合使用，以提高特征学习能力。</li>
<li>results: 我们进行了广泛的实验，测试我们的提议在三个常用的标准 benchmar 上。结果显示，我们的方法可以在 V-ReID 中提供更高的性能，超过大多数当前状态的最佳方法。<details>
<summary>Abstract</summary>
Video-based person Re-Identification (V-ReID) aims to retrieve specific persons from raw videos captured by non-overlapped cameras. As a fundamental task, it spreads many multimedia and computer vision applications. However, due to the variations of persons and scenes, there are still many obstacles that must be overcome for high performance. In this work, we notice that both the long-term and short-term information of persons are important for robust video representations. Thus, we propose a novel deep learning framework named Long Short-Term Representation Learning (LSTRL) for effective V-ReID. More specifically, to extract long-term representations, we propose a Multi-granularity Appearance Extractor (MAE), in which four granularity appearances are effectively captured across multiple frames. Meanwhile, to extract short-term representations, we propose a Bi-direction Motion Estimator (BME), in which reciprocal motion information is efficiently extracted from consecutive frames. The MAE and BME are plug-and-play and can be easily inserted into existing networks for efficient feature learning. As a result, they significantly improve the feature representation ability for V-ReID. Extensive experiments on three widely used benchmarks show that our proposed approach can deliver better performances than most state-of-the-arts.
</details>
<details>
<summary>摘要</summary>
视频基于人体重新识别（V-ReID）目标是从非重叠的视频中提取特定人脸。作为基础任务，它广泛应用于多媒体和计算机视觉领域。然而，由于人脸和场景的变化，V-ReID仍然存在许多障碍。在这项工作中，我们注意到人脸的长期和短期信息都是重要的robust视频表示。因此，我们提出了一种新的深度学习框架，即长期短期表示学习（LSTRL），以提高V-ReID的性能。更进一步，我们提出了一种多粒度外观捕获器（MAE），可以有效地在多帧中捕获四个粒度的人脸表达。同时，我们提出了一种双向运动估计器（BME），可以快速提取从一帧到下一帧的对称运动信息。MAE和BME都可以与现有网络结合使用，以提高特征学习的能力。经验表明，我们的提出的方法可以在三个广泛使用的标准测试集上达到比较高的性能。
</details></li>
</ul>
<hr>
<h2 id="Screen-based-3D-Subjective-Experiment-Software"><a href="#Screen-based-3D-Subjective-Experiment-Software" class="headerlink" title="Screen-based 3D Subjective Experiment Software"></a>Screen-based 3D Subjective Experiment Software</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03698">http://arxiv.org/abs/2308.03698</a></li>
<li>repo_url: None</li>
<li>paper_authors: Songlin Fan, Wei Gao</li>
<li>for: 本研究旨在开发一种可靠的3D主观评价平台，以便用户可以自由设计3D主观方法和建立高质量的主观评价数据集，推动3D图形主观评价领域的发展。</li>
<li>methods: 本研究使用了一种能够同时渲染源刺激和受损刺激，并允许刺激响应参与者交互的软件平台，以便准确地描述3D刺激的主观质量差异。</li>
<li>results: 经验分析表明，使用本研究提出的软件平台进行主观测试可以生成合理的3D模型主观质量分数。<details>
<summary>Abstract</summary>
Recently, widespread 3D graphics (e.g., point clouds and meshes) have drawn considerable efforts from academia and industry to assess their perceptual quality by conducting subjective experiments. However, lacking a handy software for 3D subjective experiments complicates the construction of 3D graphics quality assessment datasets, thus hindering the prosperity of relevant fields. In this paper, we develop a powerful platform with which users can flexibly design their 3D subjective methodologies and build high-quality datasets, easing a broad spectrum of 3D graphics subjective quality study. To accurately illustrate the perceptual quality differences of 3D stimuli, our software can simultaneously render the source stimulus and impaired stimulus and allows both stimuli to respond synchronously to viewer interactions. Compared with amateur 3D visualization tool-based or image/video rendering-based schemes, our approach embodies typical 3D applications while minimizing cognitive overload during subjective experiments. We organized a subjective experiment involving 40 participants to verify the validity of the proposed software. Experimental analyses demonstrate that subjective tests on our software can produce reasonable subjective quality scores of 3D models. All resources in this paper can be found at https://openi.pcl.ac.cn/OpenDatasets/3DQA.
</details>
<details>
<summary>摘要</summary>
近些年来，广泛的3D图形（如点云和网格）在学术和industry中吸引了广泛的努力，以评估它们的主观质量通过主观实验。然而，由于缺乏一个方便的3D主观实验软件，建构3D图形质量评估数据集的建构变得更加困难，从而阻碍相关领域的发展。在这篇论文中，我们开发了一个强大的平台，允许用户自由地设计他们的3D主观方法ологи和建立高质量数据集，从而促进3D图形主观质量研究的广泛发展。为准确地 Illustrate3D刺激物的主观质量差异，我们的软件可以同时渲染源刺激和受损刺激，并且允许两个刺激响应同步到观众的交互。与 amateur 3D视觉工具基于的方案或基于图像/视频渲染的方案相比，我们的方法体现出典型的3D应用程序，同时减少主观实验中的认知负担。我们组织了一个主观实验，具有40名参与者，以验证我们提出的软件的有效性。实验分析表明，我们的软件可以生成3D模型的主观质量分数。所有资源可以在https://openi.pcl.ac.cn/OpenDatasets/3DQA找到。
</details></li>
</ul>
<hr>
<h2 id="Learning-Concise-and-Descriptive-Attributes-for-Visual-Recognition"><a href="#Learning-Concise-and-Descriptive-Attributes-for-Visual-Recognition" class="headerlink" title="Learning Concise and Descriptive Attributes for Visual Recognition"></a>Learning Concise and Descriptive Attributes for Visual Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03685">http://arxiv.org/abs/2308.03685</a></li>
<li>repo_url: None</li>
<li>paper_authors: An Yan, Yu Wang, Yiwu Zhong, Chengyu Dong, Zexue He, Yujie Lu, William Wang, Jingbo Shang, Julian McAuley</li>
<li>for: 这研究旨在探讨基础模型的新进展，以及它们如何提高可读性的视觉识别器。</li>
<li>methods: 该研究使用大语言模型（LLM）来生成特征集，然后应用视觉语言模型来分类图像。</li>
<li>results: 研究发现，使用大量的特征集可以达到与图像特征集相当的性能，但是我们在8个 dataset上进一步的调查发现，LLM生成的特征集中有很多噪音。我们提出一种新的学习搜索方法，可以找到更小的 yet 高效的特征集。在 CUB dataset 上，我们的方法可以使用只有 32 个特征集来分类 200 种鸟类，并且达到了使用大量 LLG 生成的特征集（如 10k 个特征集）的性能水平。此外，我们的新方法还具有更高的可读性和交互性，以及能够概括知识的能力。<details>
<summary>Abstract</summary>
Recent advances in foundation models present new opportunities for interpretable visual recognition -- one can first query Large Language Models (LLMs) to obtain a set of attributes that describe each class, then apply vision-language models to classify images via these attributes. Pioneering work shows that querying thousands of attributes can achieve performance competitive with image features. However, our further investigation on 8 datasets reveals that LLM-generated attributes in a large quantity perform almost the same as random words. This surprising finding suggests that significant noise may be present in these attributes. We hypothesize that there exist subsets of attributes that can maintain the classification performance with much smaller sizes, and propose a novel learning-to-search method to discover those concise sets of attributes. As a result, on the CUB dataset, our method achieves performance close to that of massive LLM-generated attributes (e.g., 10k attributes for CUB), yet using only 32 attributes in total to distinguish 200 bird species. Furthermore, our new paradigm demonstrates several additional benefits: higher interpretability and interactivity for humans, and the ability to summarize knowledge for a recognition task.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/08/cs.CV_2023_08_08/" data-id="clogyj8xj00fs7cra5tm51pzn" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/56/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/55/">55</a><a class="page-number" href="/page/56/">56</a><span class="page-number current">57</span><a class="page-number" href="/page/58/">58</a><a class="page-number" href="/page/59/">59</a><span class="space">&hellip;</span><a class="page-number" href="/page/83/">83</a><a class="extend next" rel="next" href="/page/58/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">121</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">115</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">55</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">111</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">61</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
