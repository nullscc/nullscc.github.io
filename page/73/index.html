
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/73/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.SD_2023_08_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/06/cs.SD_2023_08_06/" class="article-date">
  <time datetime="2023-08-06T15:00:00.000Z" itemprop="datePublished">2023-08-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/06/cs.SD_2023_08_06/">cs.SD - 2023-08-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="SoK-Acoustic-Side-Channels"><a href="#SoK-Acoustic-Side-Channels" class="headerlink" title="SoK: Acoustic Side Channels"></a>SoK: Acoustic Side Channels</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03806">http://arxiv.org/abs/2308.03806</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ping Wang, Shishir Nagaraja, Aurélien Bourquard, Haichang Gao, Jeff Yan</li>
<li>for: 本研究准确地分析了音频侧通道，涵盖了全部主要的学术研究领域，讨论了它们的安全意义和防范措施，并确定了未来研究的方向。</li>
<li>methods: 本研究使用了多种方法，包括侧通道分析、反向问题分析和机器学习等，以探讨音频侧通道的安全性和可靠性。</li>
<li>results: 本研究得到了许多有价值的结果，包括发现了一些新的侧通道攻击和防范策略，以及确定了音频侧通道和反向问题之间的深刻联系。<details>
<summary>Abstract</summary>
We provide a state-of-the-art analysis of acoustic side channels, cover all the significant academic research in the area, discuss their security implications and countermeasures, and identify areas for future research. We also make an attempt to bridge side channels and inverse problems, two fields that appear to be completely isolated from each other but have deep connections.
</details>
<details>
<summary>摘要</summary>
我们提供了最新的分析方法，涵盖了全部重要的学术研究领域，讨论了他们的安全影响和防范措施，并确定了未来研究的方向。我们还尝试将侧频渠道和反问题两个领域联系起来，这两个领域之前被视为完全不相关的。
</details></li>
</ul>
<hr>
<h2 id="Characterization-of-cough-sounds-using-statistical-analysis"><a href="#Characterization-of-cough-sounds-using-statistical-analysis" class="headerlink" title="Characterization of cough sounds using statistical analysis"></a>Characterization of cough sounds using statistical analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03019">http://arxiv.org/abs/2308.03019</a></li>
<li>repo_url: None</li>
<li>paper_authors: Naveenkumar Vodnala, Pratap Reddy Lankireddy, Padmasai Yarlagadda</li>
<li>For: The paper aims to characterize cough sounds with voiced content and cough sounds without voiced content, and compare the cough sound characteristics with speech signals.* Methods: The proposed method utilizes spectral roll-off, spectral entropy, spectral flatness, spectral flux, zero crossing rate, spectral centroid, and spectral bandwidth attributes to describe the cough sounds related to the respiratory system, glottal information, and voice model. These attributes are then subjected to statistical analysis using measures of minimum, maximum, mean, median, and standard deviation.* Results: The experimental results show that the mean and frequency distribution of spectral roll-off, spectral centroid, and spectral bandwidth are higher for cough sounds than for speech signals. Spectral flatness levels in cough sounds are found to be around 0.22, while spectral flux varies between 0.3 and 0.6. The zero crossing rate of most frames of cough sounds is between 0.05 and 0.4. These attributes contribute significant information while characterizing cough sounds.Here’s the simplified Chinese text for the three key points:* For: 这个研究的目的是Characterizing cough sounds with voiced content and cough sounds without voiced content, and comparing the cough sound characteristics with speech signals.* Methods: 该方法使用 spectral roll-off, spectral entropy, spectral flatness, spectral flux, zero crossing rate, spectral centroid, and spectral bandwidth attributes to describe the cough sounds related to the respiratory system, glottal information, and voice model. These attributes are then subjected to statistical analysis using measures of minimum, maximum, mean, median, and standard deviation.* Results: 实验结果显示，cough sounds的mean和频谱分布高于speech signals，spectral flatness levels around 0.22，spectral flux between 0.3 and 0.6，zero crossing rate between 0.05 and 0.4. These attributes contribute significant information while characterizing cough sounds.<details>
<summary>Abstract</summary>
Cough is a primary symptom of most respiratory diseases, and changes in cough characteristics provide valuable information for diagnosing respiratory diseases. The characterization of cough sounds still lacks concrete evidence, which makes it difficult to accurately distinguish between different types of coughs and other sounds. The objective of this research work is to characterize cough sounds with voiced content and cough sounds without voiced content. Further, the cough sound characteristics are compared with the characteristics of speech. The proposed method to achieve this goal utilized spectral roll-off, spectral entropy, spectral flatness, spectral flux, zero crossing rate, spectral centroid, and spectral bandwidth attributes which describe the cough sounds related to the respiratory system, glottal information, and voice model. These attributes are then subjected to statistical analysis using the measures of minimum, maximum, mean, median, and standard deviation. The experimental results show that the mean and frequency distribution of spectral roll-off, spectral centroid, and spectral bandwidth are found to be higher for cough sounds than for speech signals. Spectral flatness levels in cough sounds will rise to 0.22, whereas spectral flux varies between 0.3 and 0.6. The Zero Crossing Rate (ZCR) of most frames of cough sounds is between 0.05 and 0.4. These attributes contribute significant information while characterizing cough sounds.
</details>
<details>
<summary>摘要</summary>
<SYS>    <TRANSLATE>        咳是许多呼吸疾病的主要症状之一，Changes in cough characteristics 提供了诊断呼吸疾病的有价值信息。然而，咳 зву的特征化仍然缺乏具体证据，这使得准确地 отличи出咳音和其他声音变得困难。本研究的目的是 caracterize cough sounds with voiced content and cough sounds without voiced content。此外，咳音特征与语音特征进行比较。        提议的方法是利用spectral roll-off, spectral entropy, spectral flatness, spectral flux, zero crossing rate, spectral centroid, and spectral bandwidth attribute来描述咳音。这些特征然后被统计分析，使用最小、最大、平均、中值和标准差度量。实验结果显示，咳音的平均值和频谱分布高于语音信号。咳音中的频谱平坦度达0.22，而频谱流量在0.3和0.6之间变化。咳音中的零极点频率在0.05和0.4之间。这些特征对于 caracterizing cough sounds 提供了重要信息。    </TRANSLATE></SYS>Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you need the translation in Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="DiffDance-Cascaded-Human-Motion-Diffusion-Model-for-Dance-Generation"><a href="#DiffDance-Cascaded-Human-Motion-Diffusion-Model-for-Dance-Generation" class="headerlink" title="DiffDance: Cascaded Human Motion Diffusion Model for Dance Generation"></a>DiffDance: Cascaded Human Motion Diffusion Model for Dance Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02915">http://arxiv.org/abs/2308.02915</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiaosong Qi, Le Zhuo, Aixi Zhang, Yue Liao, Fei Fang, Si Liu, Shuicheng Yan</li>
<li>for: 这 paper 的目的是生成真实的舞蹈序列，以便与输入的音乐进行有效的Alignment。</li>
<li>methods: 这 paper 使用了一种新的层次动态扩散模型，称为DiffDance，来生成高分辨率、长形 dance sequence。该模型包括一个音乐到舞蹈扩散模型和一个序列超分辨率扩散模型。为了将音乐和动作空间联系起来，DiffDance 使用了一个预训练的音频表示学习模型来提取音乐嵌入，并通过对比损失对其嵌入空间进行对齐。</li>
<li>results: 通过对 AIST++  benchmark 数据集进行了广泛的实验，DiffDance 能够生成真实的舞蹈序列，并与输入音乐进行有效的Alignment。这些结果与现有的排序法相当。<details>
<summary>Abstract</summary>
When hearing music, it is natural for people to dance to its rhythm. Automatic dance generation, however, is a challenging task due to the physical constraints of human motion and rhythmic alignment with target music. Conventional autoregressive methods introduce compounding errors during sampling and struggle to capture the long-term structure of dance sequences. To address these limitations, we present a novel cascaded motion diffusion model, DiffDance, designed for high-resolution, long-form dance generation. This model comprises a music-to-dance diffusion model and a sequence super-resolution diffusion model. To bridge the gap between music and motion for conditional generation, DiffDance employs a pretrained audio representation learning model to extract music embeddings and further align its embedding space to motion via contrastive loss. During training our cascaded diffusion model, we also incorporate multiple geometric losses to constrain the model outputs to be physically plausible and add a dynamic loss weight that adaptively changes over diffusion timesteps to facilitate sample diversity. Through comprehensive experiments performed on the benchmark dataset AIST++, we demonstrate that DiffDance is capable of generating realistic dance sequences that align effectively with the input music. These results are comparable to those achieved by state-of-the-art autoregressive methods.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Anonymizing-Speech-Evaluating-and-Designing-Speaker-Anonymization-Techniques"><a href="#Anonymizing-Speech-Evaluating-and-Designing-Speaker-Anonymization-Techniques" class="headerlink" title="Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques"></a>Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04455">http://arxiv.org/abs/2308.04455</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/deep-privacy/SA-toolkit">https://github.com/deep-privacy/SA-toolkit</a></li>
<li>paper_authors: Pierre Champion</li>
<li>for: 本论文旨在解决语音数据隐私问题，提出了一种语音匿名化方法以保护用户的隐私。</li>
<li>methods: 本论文使用的方法包括语音转换、量化变换等，以减少语音数据中的 speaker PPI。</li>
<li>results: 本论文的研究结果显示，量化变换可以减少 speaker PPI 而不影响语音信号的用处。同时，本论文也提出了一种新的攻击方法来逆转匿名化。<details>
<summary>Abstract</summary>
The growing use of voice user interfaces has led to a surge in the collection and storage of speech data. While data collection allows for the development of efficient tools powering most speech services, it also poses serious privacy issues for users as centralized storage makes private personal speech data vulnerable to cyber threats. With the increasing use of voice-based digital assistants like Amazon's Alexa, Google's Home, and Apple's Siri, and with the increasing ease with which personal speech data can be collected, the risk of malicious use of voice-cloning and speaker/gender/pathological/etc. recognition has increased.   This thesis proposes solutions for anonymizing speech and evaluating the degree of the anonymization. In this work, anonymization refers to making personal speech data unlinkable to an identity while maintaining the usefulness (utility) of the speech signal (e.g., access to linguistic content). We start by identifying several challenges that evaluation protocols need to consider to evaluate the degree of privacy protection properly. We clarify how anonymization systems must be configured for evaluation purposes and highlight that many practical deployment configurations do not permit privacy evaluation. Furthermore, we study and examine the most common voice conversion-based anonymization system and identify its weak points before suggesting new methods to overcome some limitations. We isolate all components of the anonymization system to evaluate the degree of speaker PPI associated with each of them. Then, we propose several transformation methods for each component to reduce as much as possible speaker PPI while maintaining utility. We promote anonymization algorithms based on quantization-based transformation as an alternative to the most-used and well-known noise-based approach. Finally, we endeavor a new attack method to invert anonymization.
</details>
<details>
<summary>摘要</summary>
voice用户界面的使用量在增长，导致了对话数据的收集和存储。这种数据收集可以为语音服务的开发提供效率的工具，但也会对用户造成严重的隐私问题，因为中央存储的私人个人对话数据容易受到网络攻击。随着语音基于的数字助手like Amazon的Alexa、Google的Home和Apple的Siri的使用的增加，以及对个人对话数据的收集变得更加容易，隐私抹革和 speaker/性别/疾病等识别的风险也在增加。本论文提出了对话数据的匿名化和评估其匿名化度的解决方案。在这个过程中，匿名化指的是让个人对话数据与身份分离开来，保持语音信号的有用性（如访问语言内容）。我们开始于评估协议中需要考虑的挑战，并且明确匿名化系统的配置方式，并指出了许多实际部署配置不允许隐私评估。此外，我们研究了最常用的语音转换基于匿名化系统，并发现其弱点，然后建议新的方法来解决一些限制。我们分解了匿名化系统的每个组件，并评估它们中 speaker PPI 的度量。然后，我们提议了一些转换方法，以减少 speaker PPI 的度量，同时保持Utility。我们推荐使用量化变换的匿名化算法，而不是最常用的噪音基本方法。最后，我们提出了一种新的攻击方法，用于逆转匿名化。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/06/cs.SD_2023_08_06/" data-id="clp89doj800xki7881u2y9xoy" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/06/cs.CV_2023_08_06/" class="article-date">
  <time datetime="2023-08-06T13:00:00.000Z" itemprop="datePublished">2023-08-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/06/cs.CV_2023_08_06/">cs.CV - 2023-08-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Nest-DGIL-Nesterov-optimized-Deep-Geometric-Incremental-Learning-for-CS-Image-Reconstruction"><a href="#Nest-DGIL-Nesterov-optimized-Deep-Geometric-Incremental-Learning-for-CS-Image-Reconstruction" class="headerlink" title="Nest-DGIL: Nesterov-optimized Deep Geometric Incremental Learning for CS Image Reconstruction"></a>Nest-DGIL: Nesterov-optimized Deep Geometric Incremental Learning for CS Image Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03807">http://arxiv.org/abs/2308.03807</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fanxiaohong/Nest-DGIL">https://github.com/fanxiaohong/Nest-DGIL</a></li>
<li>paper_authors: Xiaohong Fan, Yin Yang, Ke Chen, Yujie Feng, Jianping Zhang</li>
<li>for: This paper proposes a deep geometric incremental learning framework for image reconstruction, which can effectively alleviate artifacts and guarantee the reconstruction of geometric texture details.</li>
<li>methods: The proposed method uses second Nesterov proximal gradient optimization and a cascade geometric incremental learning module to compensate for missing texture information from different geometric spectral decomposition domains.</li>
<li>results: The proposed method demonstrates superior reconstruction performance compared to existing state-of-the-art methods, and can avoid the risk of intermediate reconstruction results falling outside the geometric decomposition domains.Here’s the same information in a more detailed format:</li>
<li>for: This paper aims to develop a deep learning-based method for image reconstruction that can effectively alleviate artifacts and preserve geometric texture details.</li>
<li>methods: The proposed method uses a cascade geometric incremental learning module, which is inspired by the overlap-tile strategy, to compensate for missing texture information from different geometric spectral decomposition domains. The method also employs second Nesterov proximal gradient optimization to improve the convergence speed and ensure the reconstruction of geometric texture details. All parameters in the proposed model are learnable, and an adaptive initialization technique of physical-parameters is used to make the model flexible and ensure smooth convergence.</li>
<li>results: The proposed method is compared with existing state-of-the-art methods, and the results show that it demonstrates superior reconstruction performance. The method can effectively alleviate artifacts and preserve geometric texture details, and can avoid the risk of intermediate reconstruction results falling outside the geometric decomposition domains.I hope this helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
Proximal gradient-based optimization is one of the most common strategies for solving image inverse problems as well as easy to implement. However, these techniques often generate heavy artifacts in image reconstruction. One of the most popular refinement methods is to fine-tune the regularization parameter to alleviate such artifacts, but it may not always be sufficient or applicable due to increased computational costs. In this work, we propose a deep geometric incremental learning framework based on second Nesterov proximal gradient optimization. The proposed end-to-end network not only has the powerful learning ability for high/low frequency image features,but also can theoretically guarantee that geometric texture details will be reconstructed from preliminary linear reconstruction.Furthermore, it can avoid the risk of intermediate reconstruction results falling outside the geometric decomposition domains and achieve fast convergence. Our reconstruction framework is decomposed into four modules including general linear reconstruction, cascade geometric incremental restoration, Nesterov acceleration and post-processing. In the image restoration step,a cascade geometric incremental learning module is designed to compensate for the missing texture information from different geometric spectral decomposition domains. Inspired by overlap-tile strategy, we also develop a post-processing module to remove the block-effect in patch-wise-based natural image reconstruction. All parameters in the proposed model are learnable,an adaptive initialization technique of physical-parameters is also employed to make model flexibility and ensure converging smoothly. We compare the reconstruction performance of the proposed method with existing state-of-the-art methods to demonstrate its superiority. Our source codes are available at https://github.com/fanxiaohong/Nest-DGIL.
</details>
<details>
<summary>摘要</summary>
近似梯度基本优化是解决图像反问题的一种非常常用的策略，但这些技术经常生成严重的artefacts。一种非常流行的改进方法是微调正则化参数，以避免这些artefacts，但这可能不一定是可靠的或可行的，因为它可能会增加计算成本。在这项工作中，我们提出了一种深度凸 геометрическое增量学习框架，基于第二个奈斯特洛夫梯度优化。我们的提案的端到端网络不仅具有高/低频图像特征的强大学习能力，而且可以 theoretically guarantee that geometric texture details will be reconstructed from preliminary linear reconstruction。此外，它可以避免中间重建结果落在几何分解域之外，并 achieve fast convergence。我们的重建框架分为四个模块：通用线性重建、几何增量归一化、奈斯特洛夫加速和后处理。在图像重建步骤中，我们设计了一个几何增量学习模块，用于补做不同几何 spectral decomposition domains 中缺失的文本信息。受 overlap-tile 灵感，我们还开发了一个后处理模块，用于在 patch-wise 基于自然图像重建中消除块效应。所有模型参数都是学习可以，并且我们采用了一种适应性的 физи学参数初始化技术，以确保模型的灵活性和平滑的 converges。我们与现有状态的方法进行比较，以示其超越性。我们的源代码可以在 https://github.com/fanxiaohong/Nest-DGIL 上获取。
</details></li>
</ul>
<hr>
<h2 id="PNN-From-proximal-algorithms-to-robust-unfolded-image-denoising-networks-and-Plug-and-Play-methods"><a href="#PNN-From-proximal-algorithms-to-robust-unfolded-image-denoising-networks-and-Plug-and-Play-methods" class="headerlink" title="PNN: From proximal algorithms to robust unfolded image denoising networks and Plug-and-Play methods"></a>PNN: From proximal algorithms to robust unfolded image denoising networks and Plug-and-Play methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03139">http://arxiv.org/abs/2308.03139</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hoang Trieu Vy Le, Audrey Repetti, Nelly Pustelnik</li>
<li>for: 这篇论文的目的是提出一种基于拟合优化理论的神经网络架构，用于解决频率噪声约束的图像恢复问题。</li>
<li>methods: 这篇论文使用了迭代 proximal 算法，并将其与深度学习策略结合，以提高估计质量。具体来说，这篇论文提出了一种基于 proximal 算法的神经网络架构，称为 proximal neural network (PNN)，可以解决任何基于 proximal 算法的图像恢复任务。</li>
<li>results: 作者们在这篇论文中提出了一种基于 dual-FB 和 primal-dual Chambolle-Pock 算法的 PNN 架构，并证明了这种架构可以在图像恢复任务中实现更好的效果。此外，作者们还提出了一些不同的学习策略，并对其的稳定性（Lipschitz 性）和恢复效果进行了 исследование。最后，作者们证明了这种 PNN 架构在一种镜像减震问题中的稳定性。<details>
<summary>Abstract</summary>
A common approach to solve inverse imaging problems relies on finding a maximum a posteriori (MAP) estimate of the original unknown image, by solving a minimization problem. In thiscontext, iterative proximal algorithms are widely used, enabling to handle non-smooth functions and linear operators. Recently, these algorithms have been paired with deep learning strategies, to further improve the estimate quality. In particular, proximal neural networks (PNNs) have been introduced, obtained by unrolling a proximal algorithm as for finding a MAP estimate, but over a fixed number of iterations, with learned linear operators and parameters. As PNNs are based on optimization theory, they are very flexible, and can be adapted to any image restoration task, as soon as a proximal algorithm can solve it. They further have much lighter architectures than traditional networks. In this article we propose a unified framework to build PNNs for the Gaussian denoising task, based on both the dual-FB and the primal-dual Chambolle-Pock algorithms. We further show that accelerated inertial versions of these algorithms enable skip connections in the associated NN layers. We propose different learning strategies for our PNN framework, and investigate their robustness (Lipschitz property) and denoising efficiency. Finally, we assess the robustness of our PNNs when plugged in a forward-backward algorithm for an image deblurring problem.
</details>
<details>
<summary>摘要</summary>
一般来说，解决反射图像问题的常用方法是找到最大 posteriori (MAP) 估计原始未知图像，解决一个最小化问题。在这种情况下，迭代 proximal 算法广泛使用，以处理非滑动函数和线性运算员。最近，这些算法与深度学习策略相结合，以进一步改善估计质量。特别是， proximal 神经网络 (PNNs) 已经引入，它们是通过固定数量的迭代器来找到 MAP 估计，但是具有学习的线性运算员和参数。由于 PNNs 基于优化理论，它们非常灵活，可以适应任何图像恢复任务，只要可以使用 proximal 算法解决它。此外，它们的架构非常轻量级，比传统神经网络更加轻量级。在这篇文章中，我们提出一个统一的框架来建立 PNNs  для Gaussian 噪声问题，基于 dual-FB 和 primal-dual Chambolle-Pock 算法。我们还证明，使用加速增量版本的这些算法可以在相关的 CNN 层中添加跳过连接。我们提出了不同的学习策略，并investigate 其Robustness 和噪声除去效率。最后，我们评估了我们的 PNNs 在一个前向-后向算法中的稳定性。
</details></li>
</ul>
<hr>
<h2 id="E-CLIP-Towards-Label-efficient-Event-based-Open-world-Understanding-by-CLIP"><a href="#E-CLIP-Towards-Label-efficient-Event-based-Open-world-Understanding-by-CLIP" class="headerlink" title="E-CLIP: Towards Label-efficient Event-based Open-world Understanding by CLIP"></a>E-CLIP: Towards Label-efficient Event-based Open-world Understanding by CLIP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03135">http://arxiv.org/abs/2308.03135</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiazhou Zhou, Xu Zheng, Yuanhuiyi Lyu, Lin Wang</li>
<li>for: 提高 event-based 图像识别 task 的性能</li>
<li>methods: 提出了一个新的框架 E-CLIP，通过在 event 数据上模型缺失的大规模数据集和模式差异，挖掘 CLIP 的潜在能力</li>
<li>results: 在 N-Caltech 数据集上取得了 +3.94% 和 +4.62% 的提升，在细化设定和少量示例设定中都达到了最佳性能<details>
<summary>Abstract</summary>
Contrasting Language-image pertaining (CLIP) has recently shown promising open-world and few-shot performance on 2D image-based recognition tasks. However, the transferred capability of CLIP to the novel event camera data still remains under-explored. In particular, due to the modality gap with the image-text data and the lack of large-scale datasets, achieving this goal is non-trivial and thus requires significant research innovation. In this paper, we propose E-CLIP, a novel and effective framework that unleashes the potential of CLIP for event-based recognition to compensate for the lack of large-scale event-based datasets. Our work addresses two crucial challenges: 1) how to generalize CLIP's visual encoder to event data while fully leveraging events' unique properties, e.g., sparsity and high temporal resolution; 2) how to effectively align the multi-modal embeddings, i.e., image, text, and events. To this end, we first introduce a novel event encoder that subtly models the temporal information from events and meanwhile generates event prompts to promote the modality bridging. We then design a text encoder that generates content prompts and utilizes hybrid text prompts to enhance the E-CLIP's generalization ability across diverse datasets. With the proposed event encoder, text encoder, and original image encoder, a novel Hierarchical Triple Contrastive Alignment (HTCA) module is introduced to jointly optimize the correlation and enable efficient knowledge transfer among the three modalities. We conduct extensive experiments on two recognition benchmarks, and the results demonstrate that our E-CLIP outperforms existing methods by a large margin of +3.94% and +4.62% on the N-Caltech dataset, respectively, in both fine-tuning and few-shot settings. Moreover, our E-CLIP can be flexibly extended to the event retrieval task using both text or image queries, showing plausible performance.
</details>
<details>
<summary>摘要</summary>
另一个挑战是如何将CLIP的视觉编码器应用到事件数据上，并充分利用事件的特有特征，如稀疏性和高时间分辨率。为此，我们首先引入了一种新的事件编码器，它灵活地模拟了事件中的时间信息，同时生成了事件提示，以便模式桥接。然后，我们设计了一个文本编码器，它生成了内容提示，并使用混合文本提示来提高E-CLIP的泛化能力。最后，我们引入了一个新的层次 triple contrastive alignment（HTCA）模块，以同时优化相关性和各模态之间的知识传递。我们在两个认证标准列表上进行了广泛的实验，结果表明，我们的E-CLIP在精度调整和少量调整下比 EXISTS的方法提高了+3.94%和+4.62%的margin。此外，我们的E-CLIP可以灵活地扩展到事件检索任务，使用文本或图像查询，表现可靠。
</details></li>
</ul>
<hr>
<h2 id="NNVISR-Bring-Neural-Network-Video-Interpolation-and-Super-Resolution-into-Video-Processing-Framework"><a href="#NNVISR-Bring-Neural-Network-Video-Interpolation-and-Super-Resolution-into-Video-Processing-Framework" class="headerlink" title="NNVISR: Bring Neural Network Video Interpolation and Super Resolution into Video Processing Framework"></a>NNVISR: Bring Neural Network Video Interpolation and Super Resolution into Video Processing Framework</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03121">http://arxiv.org/abs/2308.03121</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tongyuantongyu/vs-nnvisr">https://github.com/tongyuantongyu/vs-nnvisr</a></li>
<li>paper_authors: Yuan Tong, Mengshun Hu, Zheng Wang</li>
<li>for: 这个论文是为了提供一个基于神经网络的视频提高工具，用于进行各种视频提高任务，包括噪声除除、超分辨、 interpolate 和空间时间超分辨。</li>
<li>methods: 该论文使用的方法是基于神经网络的，可以接受任何能够提高一组帧的神经网络，并处理所有其他网络不依赖的细节 during 视频处理。</li>
<li>results: 该论文的实验结果表明，NNVISR 可以高效地进行视频提高任务，并且可以提供比较高的图像质量。<details>
<summary>Abstract</summary>
We present NNVISR - an open-source filter plugin for the VapourSynth video processing framework, which facilitates the application of neural networks for various kinds of video enhancing tasks, including denoising, super resolution, interpolation, and spatio-temporal super-resolution. NNVISR fills the gap between video enhancement neural networks and video processing pipelines, by accepting any network that enhances a group of frames, and handling all other network agnostic details during video processing. NNVISR is publicly released at https://github.com/tongyuantongyu/vs-NNVISR.
</details>
<details>
<summary>摘要</summary>
我团队现在公开发布一款开源的滤波器插件NNVISR，用于VapourSynth视频处理框架，以应用神经网络进行视频优化任务，包括噪声除除、超分辨率、 interpolate 和空间时间超分辨率。NNVISR将视频优化神经网络与视频处理管道相连接，接受任何可以提高帧组的网络，并处理所有其他网络不关注的细节 durante el procesamiento de video. NNVISR está disponible en <https://github.com/tongyuantongyu/vs-NNVISR>.
</details></li>
</ul>
<hr>
<h2 id="SAAM-Stealthy-Adversarial-Attack-on-Monoculor-Depth-Estimation"><a href="#SAAM-Stealthy-Adversarial-Attack-on-Monoculor-Depth-Estimation" class="headerlink" title="SAAM: Stealthy Adversarial Attack on Monoculor Depth Estimation"></a>SAAM: Stealthy Adversarial Attack on Monoculor Depth Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03108">http://arxiv.org/abs/2308.03108</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amira Guesmi, Muhammad Abdullah Hanif, Bassem Ouni, Muhammad Shafique</li>
<li>for: 本研究探讨了基于深度学习的MDE（多层感知探测）系统在面对抗尾攻击时的漏洞。</li>
<li>methods: 我们提出了一种新的隐蔽式抗尾攻击方法，称为SAAM（隐蔽式抗尾攻击），该方法可以让MDE系统伪造物体的深度估计。我们的实验结果表明，我们设计的隐蔽式抗尾攻击贴图成功地使DNN基于MDE系统产生深度错误。具体来说，我们的设计的隐蔽式抗尾攻击贴图可以在99%的影响区域内达到60%的深度错误。</li>
<li>results: 我们的实验结果表明，我们的SAAM方法可以成功地使MDE系统产生深度错误，并且这些错误具有自然的外观，使其难以被人类识别。我们认为这种威胁对MDE系统在边缘设备上的应用产生了重要的影响，并且希望这种威胁能够引起社区的关注，并促进更多的robust和适应性的防御机制的研究。<details>
<summary>Abstract</summary>
In this paper, we investigate the vulnerability of MDE to adversarial patches. We propose a novel \underline{S}tealthy \underline{A}dversarial \underline{A}ttacks on \underline{M}DE (SAAM) that compromises MDE by either corrupting the estimated distance or causing an object to seamlessly blend into its surroundings. Our experiments, demonstrate that the designed stealthy patch successfully causes a DNN-based MDE to misestimate the depth of objects. In fact, our proposed adversarial patch achieves a significant 60\% depth error with 99\% ratio of the affected region. Importantly, despite its adversarial nature, the patch maintains a naturalistic appearance, making it inconspicuous to human observers. We believe that this work sheds light on the threat of adversarial attacks in the context of MDE on edge devices. We hope it raises awareness within the community about the potential real-life harm of such attacks and encourages further research into developing more robust and adaptive defense mechanisms.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们研究了多光谱探测（MDE）对恶意质patch的抵触性。我们提出了一种新的隐蔽的恶意质patch（SAAM），该patch可以让MDE估算误差或使物体顺滑地融入到它所在的环境中。我们的实验表明，我们设计的隐蔽patch成功地使得基于DNN的MDE估算深度错误。事实上，我们的提案的恶意质patch实现了60%的深度错误率，99%的affected region。重要的是，即使具有恶意目的，patch仍然保持自然的外观，使其对人类观察者难以发现。我们认为，这项工作着光了MDE在边缘设备上的攻击风险，并希望这项研究会引起社区对此类攻击的关注，并促进更多的robust和适应性的防御机制的研究。
</details></li>
</ul>
<hr>
<h2 id="Incorporating-Pre-training-Data-Matters-in-Unsupervised-Domain-Adaptation"><a href="#Incorporating-Pre-training-Data-Matters-in-Unsupervised-Domain-Adaptation" class="headerlink" title="Incorporating Pre-training Data Matters in Unsupervised Domain Adaptation"></a>Incorporating Pre-training Data Matters in Unsupervised Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03097">http://arxiv.org/abs/2308.03097</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yinsong Xu, Aidong Men, Yang Liu, Qingchao Chen</li>
<li>for: 本研究旨在探讨半监督领域适应（UDA）和无源领域适应（SFUDA）方法中的问题，具体来说是研究图像Net、源频谱和目标频谱之间的相互关系，以及在这些频谱上进行 pré-训练后，对目标风险的影响。</li>
<li>methods: 本研究使用了一种名为TriDA的新框架，它在 fine-tuning 过程中保持了预训练集（图像Net）的 semantic 结构，以提高适应性能。</li>
<li>results: 实验结果显示，TriDA 可以在多个 UDA 和 SFUDA 标准测试集上达到当前最佳性能。<details>
<summary>Abstract</summary>
Unsupervised domain adaptation(UDA) and Source-free UDA(SFUDA) methods formulate the problem involving two domains: source and target. They typically employ a standard training approach that begins with models pre-trained on large-scale datasets e.g., ImageNet, while rarely discussing its effect. Recognizing this gap, we investigate the following research questions: (1) What is the correlation among ImageNet, the source, and the target domain? (2) How does pre-training on ImageNet influence the target risk? To answer the first question, we empirically observed an interesting Spontaneous Pulling (SP) Effect in fine-tuning where the discrepancies between any two of the three domains (ImageNet, Source, Target) decrease but at the cost of the impaired semantic structure of the pre-train domain. For the second question, we put forward a theory to explain SP and quantify that the target risk is bound by gradient disparities among the three domains. Our observations reveal a key limitation of existing methods: it hinders the adaptation performance if the semantic cluster structure of the pre-train dataset (i.e.ImageNet) is impaired. To address it, we incorporate ImageNet as the third domain and redefine the UDA/SFUDA as a three-player game. Specifically, inspired by the theory and empirical findings, we present a novel framework termed TriDA which additionally preserves the semantic structure of the pre-train dataset during fine-tuning. Experimental results demonstrate that it achieves state-of-the-art performance across various UDA and SFUDA benchmarks.
</details>
<details>
<summary>摘要</summary>
Unsupervised domain adaptation（UDA）和Source-free UDA（SFUDA）方法通常假设有两个领域：源领域和目标领域。它们通常采用标准训练方法，开始于在大规模数据集上预训练模型，如ImageNet，而rarely探讨其效果。认可这个空隙，我们调查以下研究问题：（1）ImageNet、源领域和目标领域之间有哪些相互关系？（2）预训练在ImageNet上会对目标风险产生何种影响？为回答第一个问题，我们观察了一种有趣的自然抽象（SP）效应在细化中，其中任何两个领域之间的差异都会减少，但是会导致预训练频率的结构受损。为回答第二个问题，我们提出了一种理论来解释SP和量化目标风险受到三个领域的梯度差异的限制。我们的观察表明现有方法的一个重要限制：如果预训练数据集（即ImageNet）的 semantic cluster structure被破坏，那么适应性会受到影响。为解决这个限制，我们将ImageNet作为第三个领域，并重新定义UDA/SFUDA为三个玩家的游戏。具体来说，我们提出了一种新的框架，称为TriDA，它在细化过程中保持预训练数据集的semantic结构。实验结果表明，TriDA可以在多个UDA和SFUDA benchmark上实现状态机器人的性能。
</details></li>
</ul>
<hr>
<h2 id="ECT-Fine-grained-Edge-Detection-with-Learned-Cause-Tokens"><a href="#ECT-Fine-grained-Edge-Detection-with-Learned-Cause-Tokens" class="headerlink" title="ECT: Fine-grained Edge Detection with Learned Cause Tokens"></a>ECT: Fine-grained Edge Detection with Learned Cause Tokens</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03092">http://arxiv.org/abs/2308.03092</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/daniellli/ect">https://github.com/daniellli/ect</a></li>
<li>paper_authors: Shaocong Xu, Xiaoxue Chen, Yuhang Zheng, Guyue Zhou, Yurong Chen, Hongbin Zha, Hao Zhao</li>
<li>for: 本研究强调细化边检测任务，即预测由反射、照明、正常和深度变化引起的特定边。</li>
<li>methods: 我们提出了一种基于转换器的两阶段网络，先预测通用边，然后预测细化边，使用注意机制实现全局响应野。我们还使用可学习的 causal 令和边绑定损失来保证边的一致性。</li>
<li>results: 我们在公共测试集 BSDS-RIND 上以及一些新定义的测试集上进行了评估，并实现了新的状态计算结果。我们的代码、数据和模型都公开在 GitHub 上（ <a target="_blank" rel="noopener" href="https://github.com/Daniellli/ECT.git">https://github.com/Daniellli/ECT.git</a>）。<details>
<summary>Abstract</summary>
In this study, we tackle the challenging fine-grained edge detection task, which refers to predicting specific edges caused by reflectance, illumination, normal, and depth changes, respectively. Prior methods exploit multi-scale convolutional networks, which are limited in three aspects: (1) Convolutions are local operators while identifying the cause of edge formation requires looking at far away pixels. (2) Priors specific to edge cause are fixed in prediction heads. (3) Using separate networks for generic and fine-grained edge detection, and the constraint between them may be violated. To address these three issues, we propose a two-stage transformer-based network sequentially predicting generic edges and fine-grained edges, which has a global receptive field thanks to the attention mechanism. The prior knowledge of edge causes is formulated as four learnable cause tokens in a cause-aware decoder design. Furthermore, to encourage the consistency between generic edges and fine-grained edges, an edge aggregation and alignment loss is exploited. We evaluate our method on the public benchmark BSDS-RIND and several newly derived benchmarks, and achieve new state-of-the-art results. Our code, data, and models are publicly available at https://github.com/Daniellli/ECT.git.
</details>
<details>
<summary>摘要</summary>
在这个研究中，我们面临着细化的边检测任务，即根据反射、照明、 нормаль和深度变化预测特定的边。先前的方法利用多尺度卷积网络，它们受到以下三种限制：（1）卷积是本地操作符，而预测边的原因需要查看远程像素。（2）预测头中的特征预设是固定的。（3）使用分开的网络来预测通用和细化的边，以及这两个网络之间的约束可能会被违反。为了解决这些问题，我们提出了一个两stage的 transformer-based 网络，先预测通用的边，然后预测细化的边，具有全局响应场，因为注意机制。此外，我们还形式化了边的原因为四个学习的 Token，并在 cause-aware 解码器中实现了这些 Token。此外，为了促进通用边和细化边之间的一致性，我们还利用了边聚合和对齐损失。我们在公共的 benchmark BSDS-RIND 上以及一些新 derivation 的 benchmark 上进行了测试，并实现了新的州��archy 记录。我们的代码、数据和模型都公开可用于 <https://github.com/Daniellli/ECT.git>。
</details></li>
</ul>
<hr>
<h2 id="Study-for-Performance-of-MobileNetV1-and-MobileNetV2-Based-on-Breast-Cancer"><a href="#Study-for-Performance-of-MobileNetV1-and-MobileNetV2-Based-on-Breast-Cancer" class="headerlink" title="Study for Performance of MobileNetV1 and MobileNetV2 Based on Breast Cancer"></a>Study for Performance of MobileNetV1 and MobileNetV2 Based on Breast Cancer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03076">http://arxiv.org/abs/2308.03076</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiuqi Yan</li>
<li>for: 这个实验的目的是比较MobileNetV1和MobileNetV2模型在分析乳腺癌图像方面的表现。</li>
<li>methods: 这个实验使用了Kaggle上下载的 histopathological 图像集进行训练，并使用了 MobileNetV1 和 MobileNetV2 模型进行分类。</li>
<li>results: 实验结果显示，在处理这个数据集时，MobileNetV1 模型表现更好，其验证精度和过拟合性也较高。<details>
<summary>Abstract</summary>
Artificial intelligence is constantly evolving and can provide effective help in all aspects of people's lives. The experiment is mainly to study the use of artificial intelligence in the field of medicine. The purpose of this experiment was to compare which of MobileNetV1 and MobileNetV2 models was better at detecting histopathological images of the breast downloaded at Kaggle. When the doctor looks at the pathological image, there may be errors that lead to errors in judgment, and the observation speed is slow. Rational use of artificial intelligence can effectively reduce the error of doctor diagnosis in breast cancer judgment and speed up doctor diagnosis. The dataset was downloaded from Kaggle and then normalized. The basic principle of the experiment is to let the neural network model learn the downloaded data set. Then find the pattern and be able to judge on your own whether breast tissue is cancer. In the dataset, benign tumor pictures and malignant tumor pictures have been classified, of which 198738 are benign tumor pictures and 78, 786 are malignant tumor pictures. After calling MobileNetV1 and MobileNetV2, the dataset is trained separately, the training accuracy and validation accuracy rate are obtained, and the image is drawn. It can be observed that MobileNetV1 has better validation accuracy and overfit during MobileNetV2 training. From the experimental results, it can be seen that in the case of processing this dataset, MobileNetV1 is much better than MobileNetV2.
</details>
<details>
<summary>摘要</summary>
人工智能不断演化，可以提供有效的帮助在人们的生活中。这个实验主要是研究人工智能在医疗领域的应用。实验的目的是比较MobileNetV1和MobileNetV2模型在Kaggle上下载的乳腺病理图像上的性能。当医生查看病理图像时，可能会出现错误，导致诊断错误， Observation speed also slow. 合理使用人工智能可以有效减少医生诊断 breast cancer 的错误率，并加快医生诊断速度。数据集来自Kaggle，然后 норmalized。实验的基本原则是让神经网络模型学习下载的数据集，然后找出模式，以便 judge 是否 breast tissue 是癌变。在数据集中，癌变和非癌变图像已经分类，其中有198738个癌变图像和78786个非癌变图像。在MobileNetV1和MobileNetV2之后，数据集进行了独立的训练，并获得了训练精度和验证精度率，并将图像绘制出来。可以看到，在处理这个数据集时，MobileNetV1比MobileNetV2更好。
</details></li>
</ul>
<hr>
<h2 id="M-3-Net-Multi-view-Encoding-Matching-and-Fusion-for-Few-shot-Fine-grained-Action-Recognition"><a href="#M-3-Net-Multi-view-Encoding-Matching-and-Fusion-for-Few-shot-Fine-grained-Action-Recognition" class="headerlink" title="M$^3$Net: Multi-view Encoding, Matching, and Fusion for Few-shot Fine-grained Action Recognition"></a>M$^3$Net: Multi-view Encoding, Matching, and Fusion for Few-shot Fine-grained Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03063">http://arxiv.org/abs/2308.03063</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Tang, Jun Liu, Shuanglin Yan, Rui Yan, Zechao Li, Jinhui Tang<br>for:* The paper is written for fine-grained action recognition, specifically addressing the challenges of capturing subtle action details and learning from limited data with high intra-class variance and inter-class similarity.methods:* The proposed M$^3$Net framework incorporates multi-view encoding, multi-view matching, and multi-view fusion to facilitate embedding encoding, similarity matching, and decision making across multiple viewpoints.* The framework uses various matching functions to integrate instance-specific, category-specific, and task-specific perspectives, and employs multi-task collaborative learning to enhance embedding generalizability.results:* Experimental results on three challenging benchmarks demonstrate the superiority of M$^3$Net in capturing fine-grained action details and achieving state-of-the-art performance for few-shot fine-grained action recognition.Here’s the information in Simplified Chinese text:for:* 这篇论文是为了解决细化动作识别问题，特别是捕捉细化动作细节和从有限数据中学习的问题。methods:* 提议的 M$^3$Net 框架具有多视图编码、多视图匹配和多视图融合，以便在多个视点上进行嵌入编码、相似匹配和决策。* 该框架使用多种匹配函数集成多种视点，包括实例特定、类别特定和任务特定的视点，以处理多尺度空间时间变化。results:* 实验结果表明，M$^3$Net 能够出色地捕捉细化动作细节并在少量数据下实现状态的最佳性能。<details>
<summary>Abstract</summary>
Due to the scarcity of manually annotated data required for fine-grained video understanding, few-shot fine-grained (FS-FG) action recognition has gained significant attention, with the aim of classifying novel fine-grained action categories with only a few labeled instances. Despite the progress made in FS coarse-grained action recognition, current approaches encounter two challenges when dealing with the fine-grained action categories: the inability to capture subtle action details and the insufficiency of learning from limited data that exhibit high intra-class variance and inter-class similarity. To address these limitations, we propose M$^3$Net, a matching-based framework for FS-FG action recognition, which incorporates \textit{multi-view encoding}, \textit{multi-view matching}, and \textit{multi-view fusion} to facilitate embedding encoding, similarity matching, and decision making across multiple viewpoints. \textit{Multi-view encoding} captures rich contextual details from the intra-frame, intra-video, and intra-episode perspectives, generating customized higher-order embeddings for fine-grained data. \textit{Multi-view matching} integrates various matching functions enabling flexible relation modeling within limited samples to handle multi-scale spatio-temporal variations by leveraging the instance-specific, category-specific, and task-specific perspectives. \textit{Multi-view fusion} consists of matching-predictions fusion and matching-losses fusion over the above views, where the former promotes mutual complementarity and the latter enhances embedding generalizability by employing multi-task collaborative learning. Explainable visualizations and experimental results on three challenging benchmarks demonstrate the superiority of M$^3$Net in capturing fine-grained action details and achieving state-of-the-art performance for FS-FG action recognition.
</details>
<details>
<summary>摘要</summary>
多视图编码 captures rich contextual details from the intra-frame, intra-video, and intra-episode perspectives, generating customized higher-order embeddings for fine-grained data. 多视图匹配 integrates various matching functions enabling flexible relation modeling within limited samples to handle multi-scale spatio-temporal variations by leveraging the instance-specific, category-specific, and task-specific perspectives. 多视图融合 consists of matching-predictions fusion and matching-losses fusion over the above views, where the former promotes mutual complementarity and the latter enhances embedding generalizability by employing multi-task collaborative learning. Explainable visualizations and experimental results on three challenging benchmarks demonstrate the superiority of M$^3$Net in capturing fine-grained action details and achieving state-of-the-art performance for FS-FG action recognition.
</details></li>
</ul>
<hr>
<h2 id="InterTracker-Discovering-and-Tracking-General-Objects-Interacting-with-Hands-in-the-Wild"><a href="#InterTracker-Discovering-and-Tracking-General-Objects-Interacting-with-Hands-in-the-Wild" class="headerlink" title="InterTracker: Discovering and Tracking General Objects Interacting with Hands in the Wild"></a>InterTracker: Discovering and Tracking General Objects Interacting with Hands in the Wild</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03061">http://arxiv.org/abs/2308.03061</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yanyan Shao, Qi Ye, Wenhan Luo, Kaihao Zhang, Jiming Chen</li>
<li>for: 本研究旨在解决人机交互中物体识别的问题，即在受到遮挡、背景噪音和干扰物体的情况下，准确地识别人与物体之间的交互。</li>
<li>methods: 本研究提出了一种基于手套空间时间信息的交互物体跟踪方法，不需要先知道将要跟踪的通用物体，可以在不同的交互场景下准确地识别和跟踪交互物体。</li>
<li>results: 比较实验结果表明，提出的方法在持续交互场景下的表现明显优于现有方法，具体来说，在100DOH数据集上测试和评估的视频水平手套交互数据集上，我们的方法在AP指标下取得了约10%的提升。此外，我们的质量发现也表明，我们的方法可以生成更加连续的交互物体轨迹。<details>
<summary>Abstract</summary>
Understanding human interaction with objects is an important research topic for embodied Artificial Intelligence and identifying the objects that humans are interacting with is a primary problem for interaction understanding. Existing methods rely on frame-based detectors to locate interacting objects. However, this approach is subjected to heavy occlusions, background clutter, and distracting objects. To address the limitations, in this paper, we propose to leverage spatio-temporal information of hand-object interaction to track interactive objects under these challenging cases. Without prior knowledge of the general objects to be tracked like object tracking problems, we first utilize the spatial relation between hands and objects to adaptively discover the interacting objects from the scene. Second, the consistency and continuity of the appearance of objects between successive frames are exploited to track the objects. With this tracking formulation, our method also benefits from training on large-scale general object-tracking datasets. We further curate a video-level hand-object interaction dataset for testing and evaluation from 100DOH. The quantitative results demonstrate that our proposed method outperforms the state-of-the-art methods. Specifically, in scenes with continuous interaction with different objects, we achieve an impressive improvement of about 10% as evaluated using the Average Precision (AP) metric. Our qualitative findings also illustrate that our method can produce more continuous trajectories for interacting objects.
</details>
<details>
<summary>摘要</summary>
人类与物体之间的互动理解是人工智能embodied的重要研究领域，并且确定互动中的物体是primary problem。现有方法通过框架基于的检测器来定位互动中的物体，但这种方法受到压束、背景噪音和干扰物体的影响。为了解决这些限制，在这篇论文中，我们提出了利用手部和物体之间的空间时间信息来跟踪互动中的物体。不需要先知道需要跟踪的通用物体类型，我们首先利用手部和物体之间的空间关系来自适应地发现互动中的物体。其次，我们利用物体之间的相似性和连续性来跟踪物体。这种跟踪方法受益于在大规模的通用物体跟踪数据集上进行训练。我们还制作了基于100DOH的视频级手部物体互动数据集用于测试和评估。量值结果表明，我们提出的方法在不断互动的不同物体场景中表现出色，相比状态艺术方法，我们的方法在AP metric下达到了约10%的提升。我们的质量发现也表明了我们的方法可以生成更加连续的互动物体轨迹。
</details></li>
</ul>
<hr>
<h2 id="TOPIQ-A-Top-down-Approach-from-Semantics-to-Distortions-for-Image-Quality-Assessment"><a href="#TOPIQ-A-Top-down-Approach-from-Semantics-to-Distortions-for-Image-Quality-Assessment" class="headerlink" title="TOPIQ: A Top-down Approach from Semantics to Distortions for Image Quality Assessment"></a>TOPIQ: A Top-down Approach from Semantics to Distortions for Image Quality Assessment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03060">http://arxiv.org/abs/2308.03060</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chaofengc/iqa-pytorch">https://github.com/chaofengc/iqa-pytorch</a></li>
<li>paper_authors: Chaofeng Chen, Jiadi Mo, Jingwen Hou, Haoning Wu, Liang Liao, Wenxiu Sun, Qiong Yan, Weisi Lin</li>
<li>for: 这个论文主要针对图像质量评估（IQA）领域，旨在提高图像质量评估的精度和效率。</li>
<li>methods: 该方法基于人类视觉系统的特点，使用多级尺度特征（global和local特征），并通过提高semantic信息的利用来提高表示能力。具体来说，该方法提出了一种顶部下降的方法（TOPIQ），通过高级semantic信息导引低级特征进行重要区域的强调，从而提高表示能力。</li>
<li>results: 该方法通过设计了一种冗余抽象网络（CFANet），可以用于Full-Reference（FR）和No-Reference（NR）IQA，并且可以与现有的视transformer方法相比，在大多数公共FR和NR标准benchmark上表现更好或竞争性好，同时具有许多更高效的特点。<details>
<summary>Abstract</summary>
Image Quality Assessment (IQA) is a fundamental task in computer vision that has witnessed remarkable progress with deep neural networks. Inspired by the characteristics of the human visual system, existing methods typically use a combination of global and local representations (\ie, multi-scale features) to achieve superior performance. However, most of them adopt simple linear fusion of multi-scale features, and neglect their possibly complex relationship and interaction. In contrast, humans typically first form a global impression to locate important regions and then focus on local details in those regions. We therefore propose a top-down approach that uses high-level semantics to guide the IQA network to focus on semantically important local distortion regions, named as \emph{TOPIQ}. Our approach to IQA involves the design of a heuristic coarse-to-fine network (CFANet) that leverages multi-scale features and progressively propagates multi-level semantic information to low-level representations in a top-down manner. A key component of our approach is the proposed cross-scale attention mechanism, which calculates attention maps for lower level features guided by higher level features. This mechanism emphasizes active semantic regions for low-level distortions, thereby improving performance. CFANet can be used for both Full-Reference (FR) and No-Reference (NR) IQA. We use ResNet50 as its backbone and demonstrate that CFANet achieves better or competitive performance on most public FR and NR benchmarks compared with state-of-the-art methods based on vision transformers, while being much more efficient (with only ${\sim}13\%$ FLOPS of the current best FR method). Codes are released at \url{https://github.com/chaofengc/IQA-PyTorch}.
</details>
<details>
<summary>摘要</summary>
Image质量评估（IQA）是计算机视觉中的基本任务，它在深度神经网络的推动下已经取得了非常出色的进步。人类视觉系统的特点 inspirits  existing methods typically use a combination of global and local representations (\ie, multi-scale features) to achieve superior performance. However, most of them adopt simple linear fusion of multi-scale features, and neglect their possibly complex relationship and interaction. In contrast, humans typically first form a global impression to locate important regions and then focus on local details in those regions. We therefore propose a top-down approach that uses high-level semantics to guide the IQA network to focus on semantically important local distortion regions, named as \emph{TOPIQ}. Our approach to IQA involves the design of a heuristic coarse-to-fine network (CFANet) that leverages multi-scale features and progressively propagates multi-level semantic information to low-level representations in a top-down manner. A key component of our approach is the proposed cross-scale attention mechanism, which calculates attention maps for lower level features guided by higher level features. This mechanism emphasizes active semantic regions for low-level distortions, thereby improving performance. CFANet can be used for both Full-Reference (FR) and No-Reference (NR) IQA. We use ResNet50 as its backbone and demonstrate that CFANet achieves better or competitive performance on most public FR and NR benchmarks compared with state-of-the-art methods based on vision transformers, while being much more efficient (with only $\sim13\%$ FLOPS of the current best FR method). Codes are released at \url{https://github.com/chaofengc/IQA-PyTorch}.
</details></li>
</ul>
<hr>
<h2 id="Multi-scale-Alternated-Attention-Transformer-for-Generalized-Stereo-Matching"><a href="#Multi-scale-Alternated-Attention-Transformer-for-Generalized-Stereo-Matching" class="headerlink" title="Multi-scale Alternated Attention Transformer for Generalized Stereo Matching"></a>Multi-scale Alternated Attention Transformer for Generalized Stereo Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03048">http://arxiv.org/abs/2308.03048</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Miao, Hong Zhao, Tongjia Chen, Wei Huang, Changyan Xiao</li>
<li>for: 提高三视图匹配性能，提供一种新的简单 yet effective的网络结构。</li>
<li>methods: 使用 Alternated Attention U-shaped Transformer (AAUformer) 网络结构，包括窗口自注意力和多尺度 Alternated Attention 几层网络，以提高单视图特征的解释力和匹配精度。</li>
<li>results: 在 Scene Flow 数据集上达到了状态的推出表现，并在 KITTI 2015 数据集上进行了细致的调整，在 synthetic 和 real-world 数据集上进行了跨种植入性比较，表现出色。<details>
<summary>Abstract</summary>
Recent stereo matching networks achieves dramatic performance by introducing epipolar line constraint to limit the matching range of dual-view. However, in complicated real-world scenarios, the feature information based on intra-epipolar line alone is too weak to facilitate stereo matching. In this paper, we present a simple but highly effective network called Alternated Attention U-shaped Transformer (AAUformer) to balance the impact of epipolar line in dual and single view respectively for excellent generalization performance. Compared to other models, our model has several main designs: 1) to better liberate the local semantic features of the single-view at pixel level, we introduce window self-attention to break the limits of intra-row self-attention and completely replace the convolutional network for denser features before cross-matching; 2) the multi-scale alternated attention backbone network was designed to extract invariant features in order to achieves the coarse-to-fine matching process for hard-to-discriminate regions. We performed a series of both comparative studies and ablation studies on several mainstream stereo matching datasets. The results demonstrate that our model achieves state-of-the-art on the Scene Flow dataset, and the fine-tuning performance is competitive on the KITTI 2015 dataset. In addition, for cross generalization experiments on synthetic and real-world datasets, our model outperforms several state-of-the-art works.
</details>
<details>
<summary>摘要</summary>
现代ステレオ匹配ネットワークは、双视点间の匹配范囲を制限するepipolar线制约を导入して、优れた性能を示している。 However, 现実世界の复雑なシーンでは、単视点内の情报に基づいた匹配は弱すぎる。 在这篇论文中，我们は、简单で强大的网络模型 called Alternated Attention U-shaped Transformer (AAUformer) を提出します。 この模型は、双视点および単视点の両方での匹配に対して、均衡的な影响を持つように设计されています。この模型には、以下の主要なデザインが含まれています。1. 単视点の地域的semantic featureをより良く解放するため、ウィンドウ自己注意を导入しました。これにより、梯度网络の制约を完全に超えることができます。2. 多スケールのalternated attentionBackbone Networkを设计しました。これにより、不挥発的な特徴を抽出し、coarse-to-fine匹配プロセスにおいて、难度の高い领域での匹配を可能にします。我们は、several mainstream stereo matching datasetsに対して、比较研究およびablation studyを実施しました。结果は、Scene Flow datasetでstate-of-the-artを记录し、KITTI 2015 datasetでの细化学习性能は、优れた性能を示しています。また、合成および実世界のデータセットでの测定においても、several state-of-the-art worksを越える性能を示しています。
</details></li>
</ul>
<hr>
<h2 id="Prototypes-oriented-Transductive-Few-shot-Learning-with-Conditional-Transport"><a href="#Prototypes-oriented-Transductive-Few-shot-Learning-with-Conditional-Transport" class="headerlink" title="Prototypes-oriented Transductive Few-shot Learning with Conditional Transport"></a>Prototypes-oriented Transductive Few-shot Learning with Conditional Transport</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03047">http://arxiv.org/abs/2308.03047</a></li>
<li>repo_url: None</li>
<li>paper_authors: Long Tian, Jingyi Feng, Wenchao Chen, Xiaoqiang Chai, Liming Wang, Xiyang Liu, Bo Chen</li>
<li>for: 提高异常少量学习（TFSL）模型在异常分布的情况下的性能，即使在类别不均衡的情况下。</li>
<li>methods: 提出一种基于Conditional Transport（CT）的不均衡TFSL模型，称为PUTM，可以全面利用异常query样本的不均衡统计信息，并使用前进和后退导航器作为传输矩阵来偏好每个类别的查询样本分布。</li>
<li>results: 通过实验证明，在四个标准 benchmark上，包括miniImageNet、 tieredImageNet、CUB 和 CIFAR-FS，OUR模型在类别不均衡的情况下表现出优于其他模型。<details>
<summary>Abstract</summary>
Transductive Few-Shot Learning (TFSL) has recently attracted increasing attention since it typically outperforms its inductive peer by leveraging statistics of query samples. However, previous TFSL methods usually encode uniform prior that all the classes within query samples are equally likely, which is biased in imbalanced TFSL and causes severe performance degradation.   Given this pivotal issue, in this work, we propose a novel Conditional Transport (CT) based imbalanced TFSL model called {\textbf P}rototypes-oriented {\textbf U}nbiased {\textbf T}ransfer {\textbf M}odel (PUTM) to fully exploit unbiased statistics of imbalanced query samples, which employs forward and backward navigators as transport matrices to balance the prior of query samples per class between uniform and adaptive data-driven distributions. For efficiently transferring statistics learned by CT, we further derive a closed form solution to refine prototypes based on MAP given the learned navigators. The above two steps of discovering and transferring unbiased statistics follow an iterative manner, formulating our EM-based solver.   Experimental results on four standard benchmarks including miniImageNet, tieredImageNet, CUB, and CIFAR-FS demonstrate superiority of our model in class-imbalanced generalization.
</details>
<details>
<summary>摘要</summary>
传ductive 少样学习 (TFSL) 在最近几年引起了越来越多的关注，因为它通常比其它 inductive 对手优秀，通过训练尝试样本的统计信息来实现。然而，先前的 TFSL 方法通常采用了所有查询样本中类别的均勋统计，这会导致不均衡的 TFSL 表现不佳，特别是在类别异质的情况下。为了解决这一问题，在本工作中，我们提出了一种基于 Conditional Transport (CT) 的不均衡 TFSL 模型，称为 Prototypes-oriented Unbiased Transfer Model (PUTM)。该模型利用前向和后向导航器作为传输矩阵，以均衡查询样本中每个类别的先前统计信息。为了有效地传输 CT 学习的统计信息，我们还 derivates 一个关注 MAP 的闭形解，以修改基于导航器学习的抽象。这两个步骤，jointly 组成我们的 EM-based 解决方案。实验结果表明，我们的模型在 miniImageNet、tieredImageNet、CUB 和 CIFAR-FS 四个标准准标 benchmark 上具有优秀的类别不均衡泛化能力。
</details></li>
</ul>
<hr>
<h2 id="Learning-Fine-Grained-Features-for-Pixel-wise-Video-Correspondences"><a href="#Learning-Fine-Grained-Features-for-Pixel-wise-Video-Correspondences" class="headerlink" title="Learning Fine-Grained Features for Pixel-wise Video Correspondences"></a>Learning Fine-Grained Features for Pixel-wise Video Correspondences</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03040">http://arxiv.org/abs/2308.03040</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/qianduoduolr/fgvc">https://github.com/qianduoduolr/fgvc</a></li>
<li>paper_authors: Rui Li, Shenglong Zhou, Dong Liu</li>
<li>for: 学习 pixel-wise 视频对应关系，提高视频分析效果。</li>
<li>methods: 基于自我超vised学习和 optical flows 的方法，使用 labelled 和 unlabeled 视频进行学习，采用对抗学习 scheme 提高泛化能力。</li>
<li>results: 在多种对应任务上达到了 state-of-the-art 精度和效率。<details>
<summary>Abstract</summary>
Video analysis tasks rely heavily on identifying the pixels from different frames that correspond to the same visual target. To tackle this problem, recent studies have advocated feature learning methods that aim to learn distinctive representations to match the pixels, especially in a self-supervised fashion. Unfortunately, these methods have difficulties for tiny or even single-pixel visual targets. Pixel-wise video correspondences were traditionally related to optical flows, which however lead to deterministic correspondences and lack robustness on real-world videos. We address the problem of learning features for establishing pixel-wise correspondences. Motivated by optical flows as well as the self-supervised feature learning, we propose to use not only labeled synthetic videos but also unlabeled real-world videos for learning fine-grained representations in a holistic framework. We adopt an adversarial learning scheme to enhance the generalization ability of the learned features. Moreover, we design a coarse-to-fine framework to pursue high computational efficiency. Our experimental results on a series of correspondence-based tasks demonstrate that the proposed method outperforms state-of-the-art rivals in both accuracy and efficiency.
</details>
<details>
<summary>摘要</summary>
视频分析任务强调将不同帧中的像素与同一个视觉目标进行对应。为解决这个问题， latest studies have advocated feature learning methods that aim to learn distinctive representations to match the pixels, especially in a self-supervised fashion. However, these methods have difficulties for tiny or even single-pixel visual targets. 传统的像素级视频对应方法与 optic flow 相关，但是这些方法具有决定性对应和在实际视频中缺乏鲁棒性。我们解决了学习建立像素级对应的特征的问题。我们采用了 optical flow 以及自主学习特征学习的思路，并在一个整体框架中学习细腻的表示。我们采用了对抗学习方案来增强学习的通用能力，并设计了一个从粗到细的框架来提高计算效率。我们的实验结果表明，我们的方法在多种对应任务中超过了当前的竞争对手， both in terms of accuracy and efficiency.
</details></li>
</ul>
<hr>
<h2 id="FourLLIE-Boosting-Low-Light-Image-Enhancement-by-Fourier-Frequency-Information"><a href="#FourLLIE-Boosting-Low-Light-Image-Enhancement-by-Fourier-Frequency-Information" class="headerlink" title="FourLLIE: Boosting Low-Light Image Enhancement by Fourier Frequency Information"></a>FourLLIE: Boosting Low-Light Image Enhancement by Fourier Frequency Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03033">http://arxiv.org/abs/2308.03033</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangchx67/fourllie">https://github.com/wangchx67/fourllie</a></li>
<li>paper_authors: Chenxi Wang, Hongjun Wu, Zhi Jin<br>for: This paper focuses on improving the lightness of low-light images using Fourier frequency information.methods: The proposed FourLLIE network uses a two-stage approach, first estimating the amplitude transform map in the Fourier space and then introducing an SNR map to integrate global Fourier frequency and local spatial information.results: The proposed FourLLIE method outperforms existing SOTA LLIE methods on four representative datasets while maintaining good model efficiency.Here’s the text in Simplified Chinese:for: 本文主要针对低光照图像的亮度提升问题，利用傅里叶频率信息。methods: FourLLIE网络采用两stage方法，首先估计傅里叶频率空间中的振荡变换图，然后引入Signal-to-Noise-Ratio（SNR）地图，将全球傅里叶频率和本地空间信息集成。results: FourLLIE方法在四个表示性数据集上比存在状态的方法（SOTA）高，同时保持良好的模型效率。<details>
<summary>Abstract</summary>
Recently, Fourier frequency information has attracted much attention in Low-Light Image Enhancement (LLIE). Some researchers noticed that, in the Fourier space, the lightness degradation mainly exists in the amplitude component and the rest exists in the phase component. By incorporating both the Fourier frequency and the spatial information, these researchers proposed remarkable solutions for LLIE. In this work, we further explore the positive correlation between the magnitude of amplitude and the magnitude of lightness, which can be effectively leveraged to improve the lightness of low-light images in the Fourier space. Moreover, we find that the Fourier transform can extract the global information of the image, and does not introduce massive neural network parameters like Multi-Layer Perceptrons (MLPs) or Transformer. To this end, a two-stage Fourier-based LLIE network (FourLLIE) is proposed. In the first stage, we improve the lightness of low-light images by estimating the amplitude transform map in the Fourier space. In the second stage, we introduce the Signal-to-Noise-Ratio (SNR) map to provide the prior for integrating the global Fourier frequency and the local spatial information, which recovers image details in the spatial space. With this ingenious design, FourLLIE outperforms the existing state-of-the-art (SOTA) LLIE methods on four representative datasets while maintaining good model efficiency.
</details>
<details>
<summary>摘要</summary>
近些时候，弗洛伦幂频信息在低光照图像增强（LLIE）中吸引了非常多的注意力。一些研究人员发现，在弗洛伦空间中，低光照图像的亮度异常主要集中在幂频成分中，剩下的则集中在相位成分中。通过将弗洛伦频率和空间信息结合起来，这些研究人员提出了非常出色的解决方案。在这个工作中，我们进一步探索幂频成分的积分和亮度之间的正相关关系，可以有效地提高低光照图像的亮度在弗洛伦空间中。此外，我们发现弗洛伦变换可以提取图像的全局信息，而不需要大量的神经网络参数，比如多层感知器（MLP）或转移器。为了实现这一目标，我们提出了一种两stage的弗洛伦基于LLIE网络（FourLLIE）。在第一stage中，我们使用幂频变换Map来提高低光照图像的亮度在弗洛伦空间中。在第二stage中，我们引入信噪比特（SNR）Map，以提供优先顺序，将全局弗洛伦频率和本地空间信息集成起来，以恢复图像细节在空间空间中。与既有的SOTA方法相比，FourLLIE在四个代表性的数据集上表现出了出色的性能，同时保持了良好的模型效率。
</details></li>
</ul>
<hr>
<h2 id="Brighten-and-Colorize-A-Decoupled-Network-for-Customized-Low-Light-Image-Enhancement"><a href="#Brighten-and-Colorize-A-Decoupled-Network-for-Customized-Low-Light-Image-Enhancement" class="headerlink" title="Brighten-and-Colorize: A Decoupled Network for Customized Low-Light Image Enhancement"></a>Brighten-and-Colorize: A Decoupled Network for Customized Low-Light Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03029">http://arxiv.org/abs/2308.03029</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenxi Wang, Zhi Jin</li>
<li>for: 提高低光照图像的 perceived 质量 (improve the perceptual quality of low-light images)</li>
<li>methods: 提出一种“炯化和颜色化”网络 (propose a “brighten-and-colorize” network)，将低光照图像进行炯化和颜色化，同时实现具有精度颜色的增强和个性化增强 based on user preferences. (use a “brighten-and-colorize” network to brighten and colorize low-light images, while achieving accurate color and customized enhancement based on user preferences)</li>
<li>results: 实验结果表明，提出的方法可以同时实现 State-Of-The-Art 性能和用户友好的个性化增强。 (experimental results show that the proposed method can achieve both State-Of-The-Art performance and user-friendly customization)<details>
<summary>Abstract</summary>
Low-Light Image Enhancement (LLIE) aims to improve the perceptual quality of an image captured in low-light conditions. Generally, a low-light image can be divided into lightness and chrominance components. Recent advances in this area mainly focus on the refinement of the lightness, while ignoring the role of chrominance. It easily leads to chromatic aberration and, to some extent, limits the diverse applications of chrominance in customized LLIE. In this work, a ``brighten-and-colorize'' network (called BCNet), which introduces image colorization to LLIE, is proposed to address the above issues. BCNet can accomplish LLIE with accurate color and simultaneously enables customized enhancement with varying saturations and color styles based on user preferences. Specifically, BCNet regards LLIE as a multi-task learning problem: brightening and colorization. The brightening sub-task aligns with other conventional LLIE methods to get a well-lit lightness. The colorization sub-task is accomplished by regarding the chrominance of the low-light image as color guidance like the user-guide image colorization. Upon completion of model training, the color guidance (i.e., input low-light chrominance) can be simply manipulated by users to acquire customized results. This customized process is optional and, due to its decoupled nature, does not compromise the structural and detailed information of lightness. Extensive experiments on the commonly used LLIE datasets show that the proposed method achieves both State-Of-The-Art (SOTA) performance and user-friendly customization.
</details>
<details>
<summary>摘要</summary>
低光照图像提升（LLIE）的目标是提高低光照图像的感知质量。通常，低光照图像可以分为亮度和色彩组成部分。现有的研究主要关注亮度的精细调整，而忽略了色彩的角色。这可能会导致彩色偏差和限制了自定义LLIE的多样化应用。在这项工作中，我们提出了一种“炬光化和彩色”网络（BCNet），该网络引入图像彩色化，以解决上述问题。BCNet可以同时完成LLIE和自定义增强，并提供了不同的饱和度和颜色风格的个性化调整，基于用户的偏好。具体来说，BCNet将LLIE视为多任务学习问题：炬光和彩色。炬光子任务与其他传统的LLIE方法一样，以获得良好的亮度。彩色子任务是基于低光照图像的色彩作为颜色指南，与用户指南图像彩色相似。在模型训练完成后，用户可以简单地 manipulate 输入低光照图像的色彩，以获得自定义结果。这个自定义过程是可选的，并且由于其分离的性质，不会对图像的结构和细节信息产生影响。我们对常用的LLIE数据集进行了广泛的实验，结果表明，我们提出的方法同时实现了State-Of-The-Art（SOTA）性能和用户友好的自定义。
</details></li>
</ul>
<hr>
<h2 id="Causal-Disentanglement-Hidden-Markov-Model-for-Fault-Diagnosis"><a href="#Causal-Disentanglement-Hidden-Markov-Model-for-Fault-Diagnosis" class="headerlink" title="Causal Disentanglement Hidden Markov Model for Fault Diagnosis"></a>Causal Disentanglement Hidden Markov Model for Fault Diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03027">http://arxiv.org/abs/2308.03027</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rihao Chang, Yongtao Ma, Weizhi Nie, Jie Nie, An-an Liu</li>
<li>for: 本研究旨在提出一种基于 causal disentanglement hidden markov model (CDHM) 的FAULT DIAGNOSIS方法，以便更好地捕捉 bearing 故障机制的特征，并实现更加精准的FAULT TYPE预测。</li>
<li>methods: 本研究使用了时间序列数据，逐步分离了振荡信号，将 fault-relevant 和 fault-irrelevant 因素分离出来。并使用了 ELBO 优化方法来学习 causal disentanglement markov model。此外，还采用了无监督领域适应技术来传递学习的拟合表示。</li>
<li>results: 在 CWRU 数据集和 IMS 数据集上进行了实验，结果表明，提出的方法能够更好地捕捉 bearing 故障机制的特征，并实现更加精准的FAULT TYPE预测。<details>
<summary>Abstract</summary>
In modern industries, fault diagnosis has been widely applied with the goal of realizing predictive maintenance. The key issue for the fault diagnosis system is to extract representative characteristics of the fault signal and then accurately predict the fault type. In this paper, we propose a Causal Disentanglement Hidden Markov model (CDHM) to learn the causality in the bearing fault mechanism and thus, capture their characteristics to achieve a more robust representation. Specifically, we make full use of the time-series data and progressively disentangle the vibration signal into fault-relevant and fault-irrelevant factors. The ELBO is reformulated to optimize the learning of the causal disentanglement Markov model. Moreover, to expand the scope of the application, we adopt unsupervised domain adaptation to transfer the learned disentangled representations to other working environments. Experiments were conducted on the CWRU dataset and IMS dataset. Relevant results validate the superiority of the proposed method.
</details>
<details>
<summary>摘要</summary>
现代产业中，故障诊断已广泛应用，目标是实现预测维护。故障诊断系统的关键问题是提取异常信号的表征特征，并准确预测故障类型。在这篇论文中，我们提出了 causal disentanglement hidden markov model（CDHM），以学习涟散机制中的 causality，并捕捉其特征，以实现更加稳定的表示。specifically，我们利用时间序列数据，逐渐分离振荡信号，分解为相关和不相关的故障因子。我们 reformulate elbo，以便学习 causal disentanglement markov model。此外，为扩大应用范围，我们采用了无监督领域适应，将学习的分离表示转移到其他工作环境。在CWRU数据集和IMS数据集上进行了实验，获得了相关的结果，证明了我们提出的方法的优越性。
</details></li>
</ul>
<hr>
<h2 id="All-in-one-Multi-degradation-Image-Restoration-Network-via-Hierarchical-Degradation-Representation"><a href="#All-in-one-Multi-degradation-Image-Restoration-Network-via-Hierarchical-Degradation-Representation" class="headerlink" title="All-in-one Multi-degradation Image Restoration Network via Hierarchical Degradation Representation"></a>All-in-one Multi-degradation Image Restoration Network via Hierarchical Degradation Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03021">http://arxiv.org/abs/2308.03021</a></li>
<li>repo_url: None</li>
<li>paper_authors: Cheng Zhang, Yu Zhu, Qingsen Yan, Jinqiu Sun, Yanning Zhang</li>
<li>for:  restore high-quality images from distorted ones, especially on mobile devices</li>
<li>methods:  progressively construct a tree structure through clustering to learn degradation representation, and design a feature transform block (FTB) to align domains and refine features</li>
<li>results:  demonstrate the effectiveness of the method and its advantages over state-of-the-art restoration methods through extensive experiments on multiple distorted datasets<details>
<summary>Abstract</summary>
The aim of image restoration is to recover high-quality images from distorted ones. However, current methods usually focus on a single task (\emph{e.g.}, denoising, deblurring or super-resolution) which cannot address the needs of real-world multi-task processing, especially on mobile devices. Thus, developing an all-in-one method that can restore images from various unknown distortions is a significant challenge. Previous works have employed contrastive learning to learn the degradation representation from observed images, but this often leads to representation drift caused by deficient positive and negative pairs. To address this issue, we propose a novel All-in-one Multi-degradation Image Restoration Network (AMIRNet) that can effectively capture and utilize accurate degradation representation for image restoration. AMIRNet learns a degradation representation for unknown degraded images by progressively constructing a tree structure through clustering, without any prior knowledge of degradation information. This tree-structured representation explicitly reflects the consistency and discrepancy of various distortions, providing a specific clue for image restoration. To further enhance the performance of the image restoration network and overcome domain gaps caused by unknown distortions, we design a feature transform block (FTB) that aligns domains and refines features with the guidance of the degradation representation. We conduct extensive experiments on multiple distorted datasets, demonstrating the effectiveness of our method and its advantages over state-of-the-art restoration methods both qualitatively and quantitatively.
</details>
<details>
<summary>摘要</summary>
目的是 восстановить高质量的图像从扭曲的图像中。然而，当前的方法通常只关注单一任务（例如，去噪、去锐化或超解像），这些方法无法满足实际世界中多任务处理的需求，特别是在移动设备上。因此，开发一个能够从多种不知道的扭曲中恢复图像的通用方法是一项重要的挑战。先前的工作使用了对比学习来学习图像的损害表示，但这经常导致表示漂移问题，由于缺乏正确的正例和负例。为解决这个问题，我们提出了一种新的 All-in-one 多种扭曲图像恢复网络（AMIRNet），它可以有效地捕捉和利用正确的损害表示进行图像恢复。AMIRNet 通过不知道扭曲信息进行批处理，逐渐构建一棵树状结构，无需任何先验知识。这棵树状结构明确地反映了不同的扭曲之间的一致和不一致，为图像恢复提供了特定的线索。为了进一步提高图像恢复网络的性能和过渡域差，我们设计了一种特征变换块（FTB），它可以对频率域进行匹配，并通过损害表示的指导来修正特征。我们在多个扭曲数据集上进行了广泛的实验，证明了我们的方法的效iveness和其与当前状态艺术方法的优势。
</details></li>
</ul>
<hr>
<h2 id="Recurrent-Spike-based-Image-Restoration-under-General-Illumination"><a href="#Recurrent-Spike-based-Image-Restoration-under-General-Illumination" class="headerlink" title="Recurrent Spike-based Image Restoration under General Illumination"></a>Recurrent Spike-based Image Restoration under General Illumination</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03018">http://arxiv.org/abs/2308.03018</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bit-vision/rsir">https://github.com/bit-vision/rsir</a></li>
<li>paper_authors: Lin Zhu, Yunlong Zheng, Mengyue Geng, Lizhi Wang, Hua Huang</li>
<li>for: 该研究旨在开拓基于脉冲（spike）数组的视觉感知领域，提高视觉Task的高速重建和准确率。</li>
<li>methods: 提出了一种基于循环神经网络的脉冲图像修复（RSIR）网络，通过physical-based脉冲噪声模型和适应脉冲转换模块、循环时间特征融合模块和频率基于脉冲噪声消除模块来修复脉冲图像。</li>
<li>results: 通过实验表明，该网络能够在不同的照明条件下修复清晰的图像，并且可以在脉冲数组中 recursive 地处理脉冲信息，以便更好地利用脉冲时间信息。<details>
<summary>Abstract</summary>
Spike camera is a new type of bio-inspired vision sensor that records light intensity in the form of a spike array with high temporal resolution (20,000 Hz). This new paradigm of vision sensor offers significant advantages for many vision tasks such as high speed image reconstruction. However, existing spike-based approaches typically assume that the scenes are with sufficient light intensity, which is usually unavailable in many real-world scenarios such as rainy days or dusk scenes. To unlock more spike-based application scenarios, we propose a Recurrent Spike-based Image Restoration (RSIR) network, which is the first work towards restoring clear images from spike arrays under general illumination. Specifically, to accurately describe the noise distribution under different illuminations, we build a physical-based spike noise model according to the sampling process of the spike camera. Based on the noise model, we design our RSIR network which consists of an adaptive spike transformation module, a recurrent temporal feature fusion module, and a frequency-based spike denoising module. Our RSIR can process the spike array in a recursive manner to ensure that the spike temporal information is well utilized. In the training process, we generate the simulated spike data based on our noise model to train our network. Extensive experiments on real-world datasets with different illuminations demonstrate the effectiveness of the proposed network. The code and dataset are released at https://github.com/BIT-Vision/RSIR.
</details>
<details>
<summary>摘要</summary>
新型生物体鼓启发相机（Spike camera）记录光束强度为数组形式，高度满足视觉任务的高速重建。然而，现有的脉冲基本方法通常假设场景具有足够的光束强度，这通常不符合实际世界的情况，如雨天或晚上场景。为了扩展更多的脉冲基本应用场景，我们提出了一种基于脉冲图像修复（RSIR）网络，这是第一个在普通照明下修复清晰图像的脉冲基本方法。为了准确描述不同照明下的噪声分布，我们构建了基于采样过程的物理基于脉冲噪声模型。根据噪声模型，我们设计了我们的RSIR网络，它包括自适应脉冲转换模块、回归时间特征融合模块和频率基于脉冲噪声清除模块。我们的RSIR可以在恰当的回归方式下处理脉冲数组，以确保脉冲时间信息得到好用。在训练过程中，我们基于我们的噪声模型生成了模拟的脉冲数据来训练我们的网络。实际测试表明，我们的RSIR网络在不同的照明下可以有效地修复清晰图像。我们在 GitHub 上发布了代码和数据集，请参考 <https://github.com/BIT-Vision/RSIR>。
</details></li>
</ul>
<hr>
<h2 id="Early-Detection-and-Localization-of-Pancreatic-Cancer-by-Label-Free-Tumor-Synthesis"><a href="#Early-Detection-and-Localization-of-Pancreatic-Cancer-by-Label-Free-Tumor-Synthesis" class="headerlink" title="Early Detection and Localization of Pancreatic Cancer by Label-Free Tumor Synthesis"></a>Early Detection and Localization of Pancreatic Cancer by Label-Free Tumor Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03008">http://arxiv.org/abs/2308.03008</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mrgiovanni/synthetictumors">https://github.com/mrgiovanni/synthetictumors</a></li>
<li>paper_authors: Bowen Li, Yu-Cheng Chou, Shuwen Sun, Hualin Qiao, Alan Yuille, Zongwei Zhou</li>
<li>for: 提高晚期肠癌患者5年生存率，从8.5%提高到20%。</li>
<li>methods: 使用人工智能（AI）模型来帮助放射学专家早期发现肠癌。</li>
<li>results: 我们的实验表明，通过使用我们的虚拟肿瘤 Synthesis方法，AI模型可以很好地检测晚期肠癌。此外，我们还发现，使用我们的方法可以提高肠癌检测率，特别是小肿瘤的检测率。 Finally,我们证明了我们的方法可以在不同医院的CT扫描数据上提高肠癌检测和地点化的泛化性。<details>
<summary>Abstract</summary>
Early detection and localization of pancreatic cancer can increase the 5-year survival rate for patients from 8.5% to 20%. Artificial intelligence (AI) can potentially assist radiologists in detecting pancreatic tumors at an early stage. Training AI models require a vast number of annotated examples, but the availability of CT scans obtaining early-stage tumors is constrained. This is because early-stage tumors may not cause any symptoms, which can delay detection, and the tumors are relatively small and may be almost invisible to human eyes on CT scans. To address this issue, we develop a tumor synthesis method that can synthesize enormous examples of small pancreatic tumors in the healthy pancreas without the need for manual annotation. Our experiments demonstrate that the overall detection rate of pancreatic tumors, measured by Sensitivity and Specificity, achieved by AI trained on synthetic tumors is comparable to that of real tumors. More importantly, our method shows a much higher detection rate for small tumors. We further investigate the per-voxel segmentation performance of pancreatic tumors if AI is trained on a combination of CT scans with synthetic tumors and CT scans with annotated large tumors at an advanced stage. Finally, we show that synthetic tumors improve AI generalizability in tumor detection and localization when processing CT scans from different hospitals. Overall, our proposed tumor synthesis method has immense potential to improve the early detection of pancreatic cancer, leading to better patient outcomes.
</details>
<details>
<summary>摘要</summary>
早期检测和肿瘤位置确定普罗大肠癌可以提高病人5年存活率从8.5%提高到20%。人工智能（AI）可能能够帮助放射学家在早期检测肿瘤。训练AI模型需要庞大的标注示例，但获得早期肿瘤的CT扫描数据受限。这是因为早期肿瘤可能不会产生任何症状，这可能会延迟检测，而且肿瘤也可能很小，使其在人类眼里几乎不可见。为解决这个问题，我们开发了一种肿瘤合成方法，可以在健康的肠部中合成庞大的小肿瘤示例，无需手动标注。我们的实验表明，由AI训练的总检测率（敏感性和特异性）与实际肿瘤相比，合成肿瘤的检测率相对较高。更重要的是，我们发现合成肿瘤的检测率对小肿瘤是非常高。我们进一步研究了使用合成肿瘤和已知大肿瘤的CT扫描数据训练AI的每个像素分割性能。最后，我们证明合成肿瘤可以提高AI在不同医院的CT扫描数据处理中的普适性。总的来说，我们的肿瘤合成方法具有极大的潜力，可以提高普罗大肠癌的早期检测，从而提高病人的存活率。
</details></li>
</ul>
<hr>
<h2 id="High-Resolution-Vision-Transformers-for-Pixel-Level-Identification-of-Structural-Components-and-Damage"><a href="#High-Resolution-Vision-Transformers-for-Pixel-Level-Identification-of-Structural-Components-and-Damage" class="headerlink" title="High-Resolution Vision Transformers for Pixel-Level Identification of Structural Components and Damage"></a>High-Resolution Vision Transformers for Pixel-Level Identification of Structural Components and Damage</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03006">http://arxiv.org/abs/2308.03006</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kareem Eltouny, Seyedomid Sajedi, Xiao Liang</li>
<li>For: The paper aims to improve the efficiency and accuracy of visual inspection for civil structures, specifically using high-resolution images and deep learning techniques.* Methods: The proposed framework uses a semantic segmentation network based on vision transformers and Laplacian pyramids scaling networks to parse high-resolution visual inspection images. The network is designed to retain both local fine details and global contextual information, while improving computational efficiency.* Results: The proposed framework was evaluated through comprehensive experiments on a dataset of bridge inspection report images, using multiple metrics for pixel-wise materials detection. The results show that the framework can efficiently process high-resolution visual data and accurately detect materials in the images.Here’s the same information in Simplified Chinese:* For: 本研究旨在通过高分辨率图像和深度学习技术进行结构体视觉检查，提高检查效率和准确率。* Methods: 提议的框架使用基于视Transformers的语义分割网络和卷积 pyramids 缩放网络来解析高分辨率视觉检查图像。网络设计保留了细节和全局 semantics 信息，提高计算效率。* Results: 提议的框架通过对桥梁检查报告图像进行广泛的实验，使用多种精度来测试像素粒子材料检测。结果表明，框架可以高效处理高分辨率视觉数据，并准确地检测图像中的材料。<details>
<summary>Abstract</summary>
Visual inspection is predominantly used to evaluate the state of civil structures, but recent developments in unmanned aerial vehicles (UAVs) and artificial intelligence have increased the speed, safety, and reliability of the inspection process. In this study, we develop a semantic segmentation network based on vision transformers and Laplacian pyramids scaling networks for efficiently parsing high-resolution visual inspection images. The massive amounts of collected high-resolution images during inspections can slow down the investigation efforts. And while there have been extensive studies dedicated to the use of deep learning models for damage segmentation, processing high-resolution visual data can pose major computational difficulties. Traditionally, images are either uniformly downsampled or partitioned to cope with computational demands. However, the input is at risk of losing local fine details, such as thin cracks, or global contextual information. Inspired by super-resolution architectures, our vision transformer model learns to resize high-resolution images and masks to retain both the valuable local features and the global semantics without sacrificing computational efficiency. The proposed framework has been evaluated through comprehensive experiments on a dataset of bridge inspection report images using multiple metrics for pixel-wise materials detection.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传感器Visual inspection 主要用于评估公共结构，但最近的无人飞行器（UAV）和人工智能技术的发展已经提高了检查过程的速度、安全性和可靠性。在这项研究中，我们开发了基于视transformer和Laplacian pyramids scaling networks的semantic segmentation网络，用于高效地分解视检图像。采集的大量高分辨率图像可能会拖慢调查的进程。而深度学习模型已经得到了大量的投入，但处理高分辨率视觉数据可能会带来巨大的计算困难。传统上，图像会被uniform downsample或分割，以降低计算开销。然而，输入可能会失去细小的本地缝隙或全局的语义信息。 drawing inspiration from super-resolution architectures，我们的视transformer模型学习了resize高分辨率图像和面积，以保留有价值的本地特征和全局语义信息，不需要牺牲计算效率。我们提出的框架在bridge inspection report图像 dataset上进行了广泛的实验，并使用多种度量器进行像素精度检测。>>Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that form instead.
</details></li>
</ul>
<hr>
<h2 id="MCTformer-Multi-Class-Token-Transformer-for-Weakly-Supervised-Semantic-Segmentation"><a href="#MCTformer-Multi-Class-Token-Transformer-for-Weakly-Supervised-Semantic-Segmentation" class="headerlink" title="MCTformer+: Multi-Class Token Transformer for Weakly Supervised Semantic Segmentation"></a>MCTformer+: Multi-Class Token Transformer for Weakly Supervised Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03005">http://arxiv.org/abs/2308.03005</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xulianuwa/mctformer">https://github.com/xulianuwa/mctformer</a></li>
<li>paper_authors: Lian Xu, Mohammed Bennamoun, Farid Boussaid, Hamid Laga, Wanli Ouyang, Dan Xu</li>
<li>for: 提高弱级Semantic Segmentation（WSSS）的准确性，通过生成准确的类型特征地图作为pseudo标签。</li>
<li>methods: 基于transformer模型，提出一种多类token转换器，通过多类token来实现类型特征的学习和分类。</li>
<li>results: 通过对多个类型token的学习和对patch token的权重调整，实现了高效的类型特征地图生成，并且与Class Activation Mapping（CAM）方法结合使用，在PASCAL VOC 2012和MS COCO 2014数据集上显著提高WSSS性能。<details>
<summary>Abstract</summary>
This paper proposes a novel transformer-based framework that aims to enhance weakly supervised semantic segmentation (WSSS) by generating accurate class-specific object localization maps as pseudo labels. Building upon the observation that the attended regions of the one-class token in the standard vision transformer can contribute to a class-agnostic localization map, we explore the potential of the transformer model to capture class-specific attention for class-discriminative object localization by learning multiple class tokens. We introduce a Multi-Class Token transformer, which incorporates multiple class tokens to enable class-aware interactions with the patch tokens. To achieve this, we devise a class-aware training strategy that establishes a one-to-one correspondence between the output class tokens and the ground-truth class labels. Moreover, a Contrastive-Class-Token (CCT) module is proposed to enhance the learning of discriminative class tokens, enabling the model to better capture the unique characteristics and properties of each class. As a result, class-discriminative object localization maps can be effectively generated by leveraging the class-to-patch attentions associated with different class tokens. To further refine these localization maps, we propose the utilization of patch-level pairwise affinity derived from the patch-to-patch transformer attention. Furthermore, the proposed framework seamlessly complements the Class Activation Mapping (CAM) method, resulting in significantly improved WSSS performance on the PASCAL VOC 2012 and MS COCO 2014 datasets. These results underline the importance of the class token for WSSS.
</details>
<details>
<summary>摘要</summary>
To achieve this, the authors propose a Multi-Class Token transformer that incorporates multiple class tokens, and a class-aware training strategy that establishes a one-to-one correspondence between the output class tokens and the ground-truth class labels. Additionally, a Contrastive-Class-Token (CCT) module is introduced to enhance the learning of discriminative class tokens.The proposed framework also utilizes patch-level pairwise affinity derived from the patch-to-patch transformer attention to refine the localization maps. The authors show that the proposed framework significantly improves WSSS performance on the PASCAL VOC 2012 and MS COCO 2014 datasets, demonstrating the importance of the class token for WSSS.Here is the translation in Simplified Chinese:这篇论文提出了一种基于转换器的新框架，以强化弱监督Semantic Segmentation（WSSS）中的对象局部化映射。这个框架基于对一个类token的注意力来生成准确的类型特有的对象局部化映射。为了实现这一点，作者们提出了多个类token，并使用多类token来实现类 aware的交互。这使得模型能够更好地捕捉类特异的注意力，并生成类型特异的对象局部化映射。此外，作者们还提出了一种强化学习抽象类token的方法，以提高模型对每个类的学习。这种方法基于对类标签和类token之间的对应关系，以确保模型能够正确地学习每个类的特征和属性。此论文还提出了一种使用patch-to-patch transformer注意力来加强对局部化映射的级别。这种方法可以更好地调整局部化映射，以提高WSSS性能。最后，作者们表明，这种框架可以轻松地与Class Activation Mapping（CAM）方法相结合，从而提高WSSS性能。这些结果证明了类token对WSSS的重要性。
</details></li>
</ul>
<hr>
<h2 id="Weakly-supervised-segmentation-of-intracranial-aneurysms-using-a-3D-focal-modulation-UNet"><a href="#Weakly-supervised-segmentation-of-intracranial-aneurysms-using-a-3D-focal-modulation-UNet" class="headerlink" title="Weakly supervised segmentation of intracranial aneurysms using a 3D focal modulation UNet"></a>Weakly supervised segmentation of intracranial aneurysms using a 3D focal modulation UNet</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03001">http://arxiv.org/abs/2308.03001</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amirhossein Rasoulian, Soorena Salari, Yiming Xiao</li>
<li>for: 这个论文的目的是提出一种基于弱监督学习的自动液体动脉精度诊断技术，以便更好地评估和治疗动脉精度疾病。</li>
<li>methods: 这个论文使用了一种新的3D焦点修饰UNet和 conditional random field（CRF）后处理技术来提高UIAs的自动 segmentation。</li>
<li>results: 研究人员通过使用这种新技术实现了UIAs的精度 segmentation，并与现有的3D UNet和Swin-UNETR进行比较，证明了该方法的优越性。<details>
<summary>Abstract</summary>
Accurate identification and quantification of unruptured intracranial aneurysms (UIAs) are essential for the risk assessment and treatment decisions of this cerebrovascular disorder. Current assessment based on 2D manual measures of aneurysms on 3D magnetic resonance angiography (MRA) is sub-optimal and time-consuming. Automatic 3D measures can significantly benefit the clinical workflow and treatment outcomes. However, one major issue in medical image segmentation is the need for large well-annotated data, which can be expensive to obtain. Techniques that mitigate the requirement, such as weakly supervised learning with coarse labels are highly desirable. In this paper, we leverage coarse labels of UIAs from time-of-flight MRAs to obtain refined UIAs segmentation using a novel 3D focal modulation UNet, called FocalSegNet and conditional random field (CRF) postprocessing, with a Dice score of 0.68 and 95% Hausdorff distance of 0.95 mm. We evaluated the performance of the proposed algorithms against the state-of-the-art 3D UNet and Swin-UNETR, and demonstrated the superiority of the proposed FocalSegNet and the benefit of focal modulation for the task.
</details>
<details>
<summary>摘要</summary>
正确识别和量化不ruptured intracranial aneurysms (UIAs) 是脑动脉疾病的风险评估和治疗决策的重要因素。现有的评估方法基于2D手动测量MRA影像的3D磁共振成像是次optimal和时间consuming。自动3D测量可以对临床工作流程和治疗结果产生重要的帮助。然而，医疗影像分类中一个主要的问题是需要大量高质量标注数据，这可能是贵重的。本文利用时间推射MRA中的UIAs粗略标签来实现UIAs精确分类，使用了一个新的3D静止模组UNet（FocalSegNet）和 conditional random field（CRF）后处理，具有0.68的Dice分数和0.95 mm的95% Hausdorff距离。我们评估了提案的算法与现有的3D UNet和Swin-UNETR的比较，并证明了提案的FocalSegNet的优越性和静止模组的重要性。
</details></li>
</ul>
<hr>
<h2 id="StyleEDL-Style-Guided-High-order-Attention-Network-for-Image-Emotion-Distribution-Learning"><a href="#StyleEDL-Style-Guided-High-order-Attention-Network-for-Image-Emotion-Distribution-Learning" class="headerlink" title="StyleEDL: Style-Guided High-order Attention Network for Image Emotion Distribution Learning"></a>StyleEDL: Style-Guided High-order Attention Network for Image Emotion Distribution Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03000">http://arxiv.org/abs/2308.03000</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liuxianyi/styleedl">https://github.com/liuxianyi/styleedl</a></li>
<li>paper_authors: Peiguang Jing, Xianyi Liu, Ji Wang, Yinwei Wei, Liqiang Nie, Yuting Su</li>
<li>for: Image emotion distribution learning</li>
<li>methods: Style-guided high-order attention network, GRAM-based stylistic representations, adversary-constrained high-order attention mechanism, stylistic graph convolutional network</li>
<li>results: Effective emotion distribution learning compared to state-of-the-art methods, demonstrated through extensive experiments on several benchmark datasets.Here is the text in Simplified Chinese:</li>
<li>for: 图像情感分布学习</li>
<li>methods: 风格引导高级注意网络、GRAM基于风格表示、对抗限制高级注意机制、动态生成内容依赖情感表示</li>
<li>results: 比对状态艺法高效的图像情感分布学习，通过多个 benchmark 数据集的广泛实验证明。I hope this helps!<details>
<summary>Abstract</summary>
Emotion distribution learning has gained increasing attention with the tendency to express emotions through images. As for emotion ambiguity arising from humans' subjectivity, substantial previous methods generally focused on learning appropriate representations from the holistic or significant part of images. However, they rarely consider establishing connections with the stylistic information although it can lead to a better understanding of images. In this paper, we propose a style-guided high-order attention network for image emotion distribution learning termed StyleEDL, which interactively learns stylistic-aware representations of images by exploring the hierarchical stylistic information of visual contents. Specifically, we consider exploring the intra- and inter-layer correlations among GRAM-based stylistic representations, and meanwhile exploit an adversary-constrained high-order attention mechanism to capture potential interactions between subtle visual parts. In addition, we introduce a stylistic graph convolutional network to dynamically generate the content-dependent emotion representations to benefit the final emotion distribution learning. Extensive experiments conducted on several benchmark datasets demonstrate the effectiveness of our proposed StyleEDL compared to state-of-the-art methods. The implementation is released at: https://github.com/liuxianyi/StyleEDL.
</details>
<details>
<summary>摘要</summary>
📝Emotion distribution learning has gained increasing attention with the tendency to express emotions through images. However, emotion ambiguity arising from humans' subjectivity has posed a challenge. Previous methods have focused on learning appropriate representations from the holistic or significant part of images, but rarely consider establishing connections with stylistic information. In this paper, we propose a style-guided high-order attention network for image emotion distribution learning termed StyleEDL, which interactively learns stylistic-aware representations of images by exploring the hierarchical stylistic information of visual contents. Specifically, we consider exploring the intra- and inter-layer correlations among GRAM-based stylistic representations, and meanwhile exploit an adversary-constrained high-order attention mechanism to capture potential interactions between subtle visual parts. In addition, we introduce a stylistic graph convolutional network to dynamically generate the content-dependent emotion representations to benefit the final emotion distribution learning. Extensive experiments conducted on several benchmark datasets demonstrate the effectiveness of our proposed StyleEDL compared to state-of-the-art methods. 📈The implementation is released at: <https://github.com/liuxianyi/StyleEDL>.
</details></li>
</ul>
<hr>
<h2 id="Novel-Class-Discovery-for-Long-tailed-Recognition"><a href="#Novel-Class-Discovery-for-Long-tailed-Recognition" class="headerlink" title="Novel Class Discovery for Long-tailed Recognition"></a>Novel Class Discovery for Long-tailed Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02989">http://arxiv.org/abs/2308.02989</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kleinzcy/ncdlr">https://github.com/kleinzcy/ncdlr</a></li>
<li>paper_authors: Zhang Chuyu, Xu Ruijie, He Xuming</li>
<li>for: 本文研究了一种更加实际的新类发现问题，其中新类和已知类的分布呈长尾型。</li>
<li>methods: 本文提出了一种适应自动标注策略，基于类均匀代表。该方法通过解决一个松弛优化运动问题，生成高质量的假标签，有效地减少了类偏见。</li>
<li>results: 对CIFAR100、ImageNet100、Herbarium19和大规模iNaturalist18 dataset进行了广泛的实验，结果表明本方法具有优异性。代码可以在<a target="_blank" rel="noopener" href="https://github.com/kleinzcy/NCDLR%E4%B8%8A%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/kleinzcy/NCDLR上下载。</a><details>
<summary>Abstract</summary>
While the novel class discovery has recently made great progress, existing methods typically focus on improving algorithms on class-balanced benchmarks. However, in real-world recognition tasks, the class distributions of their corresponding datasets are often imbalanced, which leads to serious performance degeneration of those methods. In this paper, we consider a more realistic setting for novel class discovery where the distributions of novel and known classes are long-tailed. One main challenge of this new problem is to discover imbalanced novel classes with the help of long-tailed known classes. To tackle this problem, we propose an adaptive self-labeling strategy based on an equiangular prototype representation of classes. Our method infers high-quality pseudo-labels for the novel classes by solving a relaxed optimal transport problem and effectively mitigates the class biases in learning the known and novel classes. We perform extensive experiments on CIFAR100, ImageNet100, Herbarium19 and large-scale iNaturalist18 datasets, and the results demonstrate the superiority of our method. Our code is available at https://github.com/kleinzcy/NCDLR.
</details>
<details>
<summary>摘要</summary>
新的类发现方法在最近几年内做出了大量的进步，但现有方法通常是通过改进算法来提高类均衡的benchmark上的性能。然而，在实际识别任务中，数据集的类分布通常是不均衡的，这会导致这些方法的性能下降严重。在这篇论文中，我们考虑了更真实的新类发现问题，其中新类和已知类的分布都是长尾分布。我们的主要挑战是通过长尾已知类的帮助，找到不均衡的新类。为解决这个问题，我们提出了一种适应性自标注策略，基于类的等角度表示。我们的方法通过解决一个宽松的优化交通问题，生成高质量的 Pseudo-标签，并有效地消除知类和新类的类偏见。我们在CIFAR100、ImageNet100、Herbarium19和大规模的iNaturalist18 datasets上进行了广泛的实验，结果表明我们的方法具有优越性。我们的代码可以在https://github.com/kleinzcy/NCDLR上获取。
</details></li>
</ul>
<hr>
<h2 id="Introducing-Feature-Attention-Module-on-Convolutional-Neural-Network-for-Diabetic-Retinopathy-Detection"><a href="#Introducing-Feature-Attention-Module-on-Convolutional-Neural-Network-for-Diabetic-Retinopathy-Detection" class="headerlink" title="Introducing Feature Attention Module on Convolutional Neural Network for Diabetic Retinopathy Detection"></a>Introducing Feature Attention Module on Convolutional Neural Network for Diabetic Retinopathy Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02985">http://arxiv.org/abs/2308.02985</a></li>
<li>repo_url: None</li>
<li>paper_authors: Susmita Ghosh, Abhiroop Chatterjee</li>
<li>for: The paper is written for proposing a new methodology for more accurate detection of diabetic retinopathy (DR) using deep learning models.</li>
<li>methods: The proposed method integrates a feature attention module with a pretrained VGG19 convolutional neural network (CNN) to enhance the discriminative power of the CNN. The feature attention module selectively highlights salient features from images and fuses them with the original input, which improves the network’s ability to focus on relevant information.</li>
<li>results: The proposed method achieves an accuracy of 95.70% on the APTOS (Asia Pacific Tele-Ophthalmology Society) DR Dataset, which is higher than the accuracy achieved by other state-of-the-art approaches.<details>
<summary>Abstract</summary>
Diabetic retinopathy (DR) is a leading cause of blindness among diabetic patients. Deep learning models have shown promising results in automating the detection of DR. In the present work, we propose a new methodology that integrates a feature attention module with a pretrained VGG19 convolutional neural network (CNN) for more accurate DR detection. Here, the pretrained net is fine-tuned with the proposed feature attention block. The proposed module aims to leverage the complementary information from various regions of fundus images to enhance the discriminative power of the CNN. The said feature attention module incorporates an attention mechanism which selectively highlights salient features from images and fuses them with the original input. The simultaneous learning of attention weights for the features and thereupon the combination of attention-modulated features within the feature attention block facilitates the network's ability to focus on relevant information while reducing the impact of noisy or irrelevant features. Performance of the proposed method has been evaluated on a widely used dataset for diabetic retinopathy classification e.g., the APTOS (Asia Pacific Tele-Ophthalmology Society) DR Dataset. Results are compared with/without attention module, as well as with other state-of-the-art approaches. Results confirm that the introduction of the fusion module (fusing of feature attention module with CNN) improves the accuracy of DR detection achieving an accuracy of 95.70%.
</details>
<details>
<summary>摘要</summary>
糖尿病 RETINOPATHY (DR) 是糖尿病患者中最主要的失明原因。深度学习模型已经显示了自动DR检测的承诺。在当前工作中，我们提议一种新的方法ológíque，即将特征注意模块与预训练的 VGG19  convolutional neural network (CNN) 集成以提高DR检测的准确度。这里，预训练的网络被细化并与提议的特征注意块结合。该模块的目的是利用不同区域的眼球图像中的补充信息，以提高 CNN 的拟合力。该特征注意模块包括一个注意机制，该机制选择眼球图像中的重要特征，并将其与原始输入进行组合。同时学习注意 весов для特征和组合注意模ulated特征内的特征注意块，使网络能够注重相关信息，降低干扰或无关信息的影响。我们对APTOS（亚太地区电子眼科学会）DR数据集进行了评估，并与和不含注意模块，以及其他当前领先的方法进行比较。结果表明，将特征注意模块与CNN集成（称为特征注意块）可以提高DR检测的准确度，达到95.70%的最高精度。
</details></li>
</ul>
<hr>
<h2 id="Focus-the-Discrepancy-Intra-and-Inter-Correlation-Learning-for-Image-Anomaly-Detection"><a href="#Focus-the-Discrepancy-Intra-and-Inter-Correlation-Learning-for-Image-Anomaly-Detection" class="headerlink" title="Focus the Discrepancy: Intra- and Inter-Correlation Learning for Image Anomaly Detection"></a>Focus the Discrepancy: Intra- and Inter-Correlation Learning for Image Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02983">http://arxiv.org/abs/2308.02983</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xcyao00/fod">https://github.com/xcyao00/fod</a></li>
<li>paper_authors: Xincheng Yao, Ruoqi Li, Zefeng Qian, Yan Luo, Chongyang Zhang</li>
<li>for: 本文提出了一种新的异常检测方法，即 FOcus-the-Discrepancy（FOD），用于同时检测图像中异常点的patch-wise、intra-和inter-异常。</li>
<li>methods: 本文使用了Transformer模型，并对其进行修改，以便更好地捕捉图像中异常点的patch-wise和inter-image correlations。特别是，本文提出了一种新的自我相关映射修改方法，称为Intra-Inter-Correlation（I2Correlation），用于同时建立图像中patch-wise和inter-image的相关性。</li>
<li>results: 本文的实验结果表明，FOD方法可以在三个Unsupervised Real-World AD benchmark上达到非常高的异常检测性能。 Code将会在<a target="_blank" rel="noopener" href="https://github.com/xcyao00/FOD%E4%B8%8A%E6%8F%90%E4%BE%9B%E3%80%82">https://github.com/xcyao00/FOD上提供。</a><details>
<summary>Abstract</summary>
Humans recognize anomalies through two aspects: larger patch-wise representation discrepancies and weaker patch-to-normal-patch correlations. However, the previous AD methods didn't sufficiently combine the two complementary aspects to design AD models. To this end, we find that Transformer can ideally satisfy the two aspects as its great power in the unified modeling of patch-wise representations and patch-to-patch correlations. In this paper, we propose a novel AD framework: FOcus-the-Discrepancy (FOD), which can simultaneously spot the patch-wise, intra- and inter-discrepancies of anomalies. The major characteristic of our method is that we renovate the self-attention maps in transformers to Intra-Inter-Correlation (I2Correlation). The I2Correlation contains a two-branch structure to first explicitly establish intra- and inter-image correlations, and then fuses the features of two-branch to spotlight the abnormal patterns. To learn the intra- and inter-correlations adaptively, we propose the RBF-kernel-based target-correlations as learning targets for self-supervised learning. Besides, we introduce an entropy constraint strategy to solve the mode collapse issue in optimization and further amplify the normal-abnormal distinguishability. Extensive experiments on three unsupervised real-world AD benchmarks show the superior performance of our approach. Code will be available at https://github.com/xcyao00/FOD.
</details>
<details>
<summary>摘要</summary>
人类通过两个方面识别异常：一是较大的补丁层表示差异，二是较弱的补丁与正常补丁之间的相关性。然而，先前的异常检测方法没有足够融合这两个补充性方面来设计异常检测模型。为了解决这问题，我们发现 transformer 可以 идеаль地满足这两个方面，因为它可以强大地统一补丁层表示和补丁之间的相关性。在这篇文章中，我们提出了一种新的异常检测框架：FOcus-the-Discrepancy（FOD），它可以同时检测补丁层、内部和外部异常。我们的方法的主要特点是将 transformer 的自我注意力地图改为 Intra-Inter-Correlation（I2Correlation）。I2Correlation 包括两个分支结构，首先显式建立内部和外部图像相关性，然后将两个分支的特征进行合并，以检测异常模式。为了学习内部和外部相关性适应性地，我们提出了基于 RBF kernel 的目标相关性学习目标，并引入了一种对数分布约束策略，以解决优化过程中的模式覆盖问题。我们的方法在三个未经过超参数的实际异常检测标准benchmark上进行了广泛的实验，并显示了我们的方法的超过其他方法的性能。代码将在 https://github.com/xcyao00/FOD 上提供。
</details></li>
</ul>
<hr>
<h2 id="Beyond-First-Impressions-Integrating-Joint-Multi-modal-Cues-for-Comprehensive-3D-Representation"><a href="#Beyond-First-Impressions-Integrating-Joint-Multi-modal-Cues-for-Comprehensive-3D-Representation" class="headerlink" title="Beyond First Impressions: Integrating Joint Multi-modal Cues for Comprehensive 3D Representation"></a>Beyond First Impressions: Integrating Joint Multi-modal Cues for Comprehensive 3D Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02982">http://arxiv.org/abs/2308.02982</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mr-neko/jm3d">https://github.com/mr-neko/jm3d</a></li>
<li>paper_authors: Haowei Wang, Jiji Tang, Jiayi Ji, Xiaoshuai Sun, Rongsheng Zhang, Yiwei Ma, Minda Zhao, Lincheng Li, zeng zhao, Tangjie Lv, Rongrong Ji</li>
<li>for: 本文提出了一种多视图共同模式匹配方法，以解决现有方法所导致的信息损失和共同匹配问题。</li>
<li>methods: 本文提出了一种新的结构多模态组织器（SMO）和一种联合多模态匹配（JMA）两部分。SMO通过将多视图图像和层次文本纳入一起，提高了视觉和语言模式的表示。JMA通过将语言知识 incorporated into the visual modality，实现了多模态之间的共同匹配。</li>
<li>results: 对于ModelNet40和ScanObjectNN两个数据集，本文的提出的方法JM3D实现了零shot 3D分类的最佳性能。与ULIP相比，JM3D在PointMLP上提高了约4.3%的性能，在PointNet++上提高了最大1.5%的性能。<details>
<summary>Abstract</summary>
In recent years, 3D representation learning has turned to 2D vision-language pre-trained models to overcome data scarcity challenges. However, existing methods simply transfer 2D alignment strategies, aligning 3D representations with single-view 2D images and coarse-grained parent category text. These approaches introduce information degradation and insufficient synergy issues, leading to performance loss. Information degradation arises from overlooking the fact that a 3D representation should be equivalent to a series of multi-view images and more fine-grained subcategory text. Insufficient synergy neglects the idea that a robust 3D representation should align with the joint vision-language space, rather than independently aligning with each modality. In this paper, we propose a multi-view joint modality modeling approach, termed JM3D, to obtain a unified representation for point cloud, text, and image. Specifically, a novel Structured Multimodal Organizer (SMO) is proposed to address the information degradation issue, which introduces contiguous multi-view images and hierarchical text to enrich the representation of vision and language modalities. A Joint Multi-modal Alignment (JMA) is designed to tackle the insufficient synergy problem, which models the joint modality by incorporating language knowledge into the visual modality. Extensive experiments on ModelNet40 and ScanObjectNN demonstrate the effectiveness of our proposed method, JM3D, which achieves state-of-the-art performance in zero-shot 3D classification. JM3D outperforms ULIP by approximately 4.3% on PointMLP and achieves an improvement of up to 6.5% accuracy on PointNet++ in top-1 accuracy for zero-shot 3D classification on ModelNet40. The source code and trained models for all our experiments are publicly available at https://github.com/Mr-Neko/JM3D.
</details>
<details>
<summary>摘要</summary>
在最近的几年中，3D表示学习转向了2D视觉语言预训模型，以解决数据缺乏问题。然而，现有的方法只是将2D对齐策略转移到3D表示上，将3D表示与单视图2D图像和粗粒度的父类别文本进行对齐。这些方法会导致信息损失和不足的共聚问题，从而导致性能下降。信息损失的原因在于忽略了3D表示应该与多视图图像和更细化的子类别文本相对应。不足的共聚问题是由于忽略了视觉语言空间的 JOINT 模型，而不是独立地对每个模式进行对齐。在本文中，我们提出了一种多视图集成模型，称为JM3D，以获得包含点云、文本和图像的统一表示。具体来说，我们提出了一种新的结构化多模式组织器（SMO），以解决信息损失问题，并在视觉和语言模式中引入连续多视图图像和层次文本，以激活表示的多模式。此外，我们还提出了一种联合多模式对齐（JMA），以解决不足的共聚问题，将语言知识integrated到视觉模式中。我们在ModelNet40和ScanObjectNN上进行了广泛的实验，并证明了我们提出的方法JM3D在零shot 3D分类中达到了状态机器人的性能。JM3D在PointMLP和PointNet++上比ULIP高出约4.3%的性能，并在ModelNet40上实现了顶部1个最大值的提高率为6.5%。我们在https://github.com/Mr-Neko/JM3D上提供了所有实验代码和训练模型。
</details></li>
</ul>
<hr>
<h2 id="Robust-estimation-of-exposure-ratios-in-multi-exposure-image-stacks"><a href="#Robust-estimation-of-exposure-ratios-in-multi-exposure-image-stacks" class="headerlink" title="Robust estimation of exposure ratios in multi-exposure image stacks"></a>Robust estimation of exposure ratios in multi-exposure image stacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02968">http://arxiv.org/abs/2308.02968</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gfxdisp/hdrutils">https://github.com/gfxdisp/hdrutils</a></li>
<li>paper_authors: Param Hanji, Rafał K. Mantiuk<br>for:The paper is written for those who need to merge multi-exposure image stacks into a high dynamic range (HDR) image, and want to eliminate banding artifacts caused by inaccurate exposure times.methods:The paper proposes a method to estimate exposure ratios directly from the input images, using an optimization problem to minimize estimation error caused by camera noise. The method uses a linear solver and is robust to pixel misalignment caused by camera or object motion.results:The proposed method eliminates banding artifacts in popular datasets and is essential for applications that require physically accurate reconstructions, such as measuring the modulation transfer function of a display. The code for the method is available.<details>
<summary>Abstract</summary>
Merging multi-exposure image stacks into a high dynamic range (HDR) image requires knowledge of accurate exposure times. When exposure times are inaccurate, for example, when they are extracted from a camera's EXIF metadata, the reconstructed HDR images reveal banding artifacts at smooth gradients. To remedy this, we propose to estimate exposure ratios directly from the input images. We derive the exposure time estimation as an optimization problem, in which pixels are selected from pairs of exposures to minimize estimation error caused by camera noise. When pixel values are represented in the logarithmic domain, the problem can be solved efficiently using a linear solver. We demonstrate that the estimation can be easily made robust to pixel misalignment caused by camera or object motion by collecting pixels from multiple spatial tiles. The proposed automatic exposure estimation and alignment eliminates banding artifacts in popular datasets and is essential for applications that require physically accurate reconstructions, such as measuring the modulation transfer function of a display. The code for the method is available.
</details>
<details>
<summary>摘要</summary>
合并多张曝光图像拼接成高动态范围（HDR）图像需要准确的曝光时间知识。如果曝光时间不准确，例如从相机的EXIF元数据中提取出来的，则重构的HDR图像中会出现扫描 artifacts 在平滑的渐变区域。为解决这问题，我们提议直接从输入图像中估算曝光比率。我们将曝光时间估算作为一个优化问题，在其中选择了对应的曝光图像中的像素，以最小化由相机噪声引起的估算误差。当像素值表示在对数域中时，问题可以通过一个线性解决器效率地解决。我们示出了对摄像头或物体运动引起的像素不对的情况下，可以使用多个空间块收集像素来使估算成为 robust。我们的自动曝光估算和对齐方法可以消除各种流行的数据集中的扫描 artifacts，并是需要物理准确重建的应用，如测量显示器的模板传输函数。我们的代码可以获得。
</details></li>
</ul>
<hr>
<h2 id="Generative-Approach-for-Probabilistic-Human-Mesh-Recovery-using-Diffusion-Models"><a href="#Generative-Approach-for-Probabilistic-Human-Mesh-Recovery-using-Diffusion-Models" class="headerlink" title="Generative Approach for Probabilistic Human Mesh Recovery using Diffusion Models"></a>Generative Approach for Probabilistic Human Mesh Recovery using Diffusion Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02963">http://arxiv.org/abs/2308.02963</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hanbyel0105/diff-hmr">https://github.com/hanbyel0105/diff-hmr</a></li>
<li>paper_authors: Hanbyel Cho, Junmo Kim<br>for: diff-hmr 是一种用于从 2D 图像中重建 3D 人体网格的方法，并且能够处理多个可能性的挑战。methods: diff-hmr 使用了扩散过程来处理从真实参数衍生的模型，并在训练阶段将 SMPL 参数从真实参数扩散到随机分布。results: diff-hmr 可以从同一个输入图像中产生多种不同的结果，因为它可以处理不同的输入噪声。实验结果显示，提案的框架可以有效地模型人体网格重建任务中的潜在多个可能性。<details>
<summary>Abstract</summary>
This work focuses on the problem of reconstructing a 3D human body mesh from a given 2D image. Despite the inherent ambiguity of the task of human mesh recovery, most existing works have adopted a method of regressing a single output. In contrast, we propose a generative approach framework, called "Diffusion-based Human Mesh Recovery (Diff-HMR)" that takes advantage of the denoising diffusion process to account for multiple plausible outcomes. During the training phase, the SMPL parameters are diffused from ground-truth parameters to random distribution, and Diff-HMR learns the reverse process of this diffusion. In the inference phase, the model progressively refines the given random SMPL parameters into the corresponding parameters that align with the input image. Diff-HMR, being a generative approach, is capable of generating diverse results for the same input image as the input noise varies. We conduct validation experiments, and the results demonstrate that the proposed framework effectively models the inherent ambiguity of the task of human mesh recovery in a probabilistic manner. The code is available at https://github.com/hanbyel0105/Diff-HMR
</details>
<details>
<summary>摘要</summary>
这个工作关注于从给定的2D图像中重建3D人体模型的问题。尽管人体模型恢复任务本身具有内在的模糊性，大多数现有的工作都采取了单输出回归的方法。而我们提议的是一种生成方法框架，称为“Diffusion-based Human Mesh Recovery（Diff-HMR）”，它利用杂化扩散过程来考虑多个可能的结果。在训练阶段，SMPL参数从真实参数扩散到随机分布，Diff-HMR学习反向的这种扩散过程。在推理阶段，模型逐渐将给定的随机SMPL参数转化为与输入图像匹配的参数。由于Diff-HMR是一种生成方法，因此它能够根据输入图像的噪声变化生成多种结果。我们进行了验证实验，结果表明，我们提议的框架能够在 probabilistic 的方式模型人体模型恢复任务中的内在模糊性。代码可以在 https://github.com/hanbyel0105/Diff-HMR 上获取。
</details></li>
</ul>
<hr>
<h2 id="DermoSegDiff-A-Boundary-aware-Segmentation-Diffusion-Model-for-Skin-Lesion-Delineation"><a href="#DermoSegDiff-A-Boundary-aware-Segmentation-Diffusion-Model-for-Skin-Lesion-Delineation" class="headerlink" title="DermoSegDiff: A Boundary-aware Segmentation Diffusion Model for Skin Lesion Delineation"></a>DermoSegDiff: A Boundary-aware Segmentation Diffusion Model for Skin Lesion Delineation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02959">http://arxiv.org/abs/2308.02959</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mindflow-institue/dermosegdiff">https://github.com/mindflow-institue/dermosegdiff</a></li>
<li>paper_authors: Afshin Bozorgpour, Yousef Sadegheih, Amirhossein Kazerouni, Reza Azad, Dorit Merhof</li>
<li>for: 静脉皮肤病诊断 Early detection and accurate diagnosis of dermatological conditions.</li>
<li>methods: 使用 Denoising Diffusion Probabilistic Models (DDPMs) 和 U-Net 网络，在学习过程中引入边缘信息，逐渐减少其他区域的重要性。</li>
<li>results: 在多个皮肤分割数据集上实现了比 CNN、transformer 和 diffusion-based 方法更高的效果和泛化能力。<details>
<summary>Abstract</summary>
Skin lesion segmentation plays a critical role in the early detection and accurate diagnosis of dermatological conditions. Denoising Diffusion Probabilistic Models (DDPMs) have recently gained attention for their exceptional image-generation capabilities. Building on these advancements, we propose DermoSegDiff, a novel framework for skin lesion segmentation that incorporates boundary information during the learning process. Our approach introduces a novel loss function that prioritizes the boundaries during training, gradually reducing the significance of other regions. We also introduce a novel U-Net-based denoising network that proficiently integrates noise and semantic information inside the network. Experimental results on multiple skin segmentation datasets demonstrate the superiority of DermoSegDiff over existing CNN, transformer, and diffusion-based approaches, showcasing its effectiveness and generalization in various scenarios. The implementation is publicly accessible on \href{https://github.com/mindflow-institue/dermosegdiff}{GitHub}
</details>
<details>
<summary>摘要</summary>
皮肤梗混杂 Segmentation 在早期检测和精准诊断皮肤疾病中扮演了关键角色。 latest 的 Denoising Diffusion Probabilistic Models (DDPMs) 在图像生成方面吸引了广泛的关注。 基于这些进步，我们提出了 DermoSegDiff，一种新的皮肤梗混杂 Segmentation 框架，在学习过程中加入边界信息。我们的方法引入了一种新的损失函数，在训练过程中优先级化边界，逐渐减少其他区域的重要性。我们还引入了一种基于 U-Net 的净化网络，能够高效地 инте integrate 噪声和semantic信息内网络。多个皮肤分割数据集的实验结果表明 DermoSegDiff 在不同的场景下具有优秀的效果和泛化能力，超越了现有的 CNN、transformer 和扩散基于的方法。实现在 \href{https://github.com/mindflow-institue/dermosegdiff}{GitHub} 上公开 accessible。
</details></li>
</ul>
<hr>
<h2 id="K-band-Self-supervised-MRI-Reconstruction-via-Stochastic-Gradient-Descent-over-K-space-Subsets"><a href="#K-band-Self-supervised-MRI-Reconstruction-via-Stochastic-Gradient-Descent-over-K-space-Subsets" class="headerlink" title="K-band: Self-supervised MRI Reconstruction via Stochastic Gradient Descent over K-space Subsets"></a>K-band: Self-supervised MRI Reconstruction via Stochastic Gradient Descent over K-space Subsets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02958">http://arxiv.org/abs/2308.02958</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mikgroup/k-band">https://github.com/mikgroup/k-band</a></li>
<li>paper_authors: Frederic Wang, Han Qi, Alfredo De Goyeneche, Reinhard Heckel, Michael Lustig, Efrat Shimron</li>
<li>for: 用于使深度学习方法可以使用有限分辨率的k空间数据进行训练。</li>
<li>methods: 引入了一种新的数学框架，称为k带，允许使用有限分辨率的k空间数据进行训练深度学习模型。特别是，我们使用在每次训练迭代中，只使用一小部分的k空间数据来计算梯度的方法。</li>
<li>results: 对于 Raw MRI 数据进行了数值实验，并证明了k带方法可以超过其他基于有限分辨率数据的方法，并与当前最佳方法（SoTA）的性能相当。k带方法因此实现了SoTA性能，而不需要高质量的训练数据。<details>
<summary>Abstract</summary>
Although deep learning (DL) methods are powerful for solving inverse problems, their reliance on high-quality training data is a major hurdle. This is significant in high-dimensional (dynamic/volumetric) magnetic resonance imaging (MRI), where acquisition of high-resolution fully sampled k-space data is impractical. We introduce a novel mathematical framework, dubbed k-band, that enables training DL models using only partial, limited-resolution k-space data. Specifically, we introduce training with stochastic gradient descent (SGD) over k-space subsets. In each training iteration, rather than using the fully sampled k-space for computing gradients, we use only a small k-space portion. This concept is compatible with different sampling strategies; here we demonstrate the method for k-space "bands", which have limited resolution in one dimension and can hence be acquired rapidly. We prove analytically that our method stochastically approximates the gradients computed in a fully-supervised setup, when two simple conditions are met: (i) the limited-resolution axis is chosen randomly-uniformly for every new scan, hence k-space is fully covered across the entire training set, and (ii) the loss function is weighed with a mask, derived here analytically, which facilitates accurate reconstruction of high-resolution details. Numerical experiments with raw MRI data indicate that k-band outperforms two other methods trained on limited-resolution data and performs comparably to state-of-the-art (SoTA) methods trained on high-resolution data. k-band hence obtains SoTA performance, with the advantage of training using only limited-resolution data. This work hence introduces a practical, easy-to-implement, self-supervised training framework, which involves fast acquisition and self-supervised reconstruction and offers theoretical guarantees.
</details>
<details>
<summary>摘要</summary>
although deep learning (DL) 方法是强大的解决反向问题的工具，它们的依赖于高质量训练数据是一个主要的障碍。在高维（动态/体积）磁共振成像（MRI）中，获得高分辨率完全掌握的k空间数据是不实际。我们介绍了一种新的数学框架，称为k空间，允许使用只有部分、有限分辨率k空间数据来训练DL模型。具体来说，我们引入了使用杂次下降（SGD）在k空间subset中训练。在每个训练轮次中，而不是使用完全掌握的k空间来计算导数，我们只使用一小部分k空间。这个概念 compatible with different sampling strategies，我们在这里采用k空间“带”，它们有限制分辨率的一个维度，可以快速获得。我们数学上证明，我们的方法可以随机选择限制分辨率轴，以 Ensure k-space是在整个训练集中完全覆盖。此外，我们还使用一个mask，在这里分析性 derivation，以便准确地重建高分辨率细节。numerical experiments with raw MRI data indicate that k-band outperforms two other methods trained on limited-resolution data and performs comparably to state-of-the-art (SoTA) methods trained on high-resolution data. k-band hence obtains SoTA performance, with the advantage of training using only limited-resolution data. this work hence introduces a practical, easy-to-implement, self-supervised training framework, which involves fast acquisition and self-supervised reconstruction and offers theoretical guarantees.
</details></li>
</ul>
<hr>
<h2 id="Multispectral-Quantitative-Phase-Imaging-Using-a-Diffractive-Optical-Network"><a href="#Multispectral-Quantitative-Phase-Imaging-Using-a-Diffractive-Optical-Network" class="headerlink" title="Multispectral Quantitative Phase Imaging Using a Diffractive Optical Network"></a>Multispectral Quantitative Phase Imaging Using a Diffractive Optical Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02952">http://arxiv.org/abs/2308.02952</a></li>
<li>repo_url: None</li>
<li>paper_authors: Che-Yung Shen, Jingxi Li, Deniz Mengu, Aydogan Ozcan</li>
<li>for: 这种 diffractive processor 可以实现高通量、低功耗的量子phasic 成像，用于生物、材料科学和工程等领域的 transparent 样品的成像。</li>
<li>methods: 使用了 spatially 工程的 diffractive layers，通过 deep learning 优化，将输入对象的phasic 特征编码到输出平面上的INTENSITY variations中，实现多spectral QPI 的同时进行。</li>
<li>results: 通过数字 simulations，我们展示了这种 diffractive multispectral processor 可以同时进行9和16个target spectral band的量子phasic 成像，并且在所有激光通道上保持uniform performance，显示出高质量的 QPI 性能。<details>
<summary>Abstract</summary>
As a label-free imaging technique, quantitative phase imaging (QPI) provides optical path length information of transparent specimens for various applications in biology, materials science, and engineering. Multispectral QPI measures quantitative phase information across multiple spectral bands, permitting the examination of wavelength-specific phase and dispersion characteristics of samples. Here, we present the design of a diffractive processor that can all-optically perform multispectral quantitative phase imaging of transparent phase-only objects in a snapshot. Our design utilizes spatially engineered diffractive layers, optimized through deep learning, to encode the phase profile of the input object at a predetermined set of wavelengths into spatial intensity variations at the output plane, allowing multispectral QPI using a monochrome focal plane array. Through numerical simulations, we demonstrate diffractive multispectral processors to simultaneously perform quantitative phase imaging at 9 and 16 target spectral bands in the visible spectrum. These diffractive multispectral processors maintain uniform performance across all the wavelength channels, revealing a decent QPI performance at each target wavelength. The generalization of these diffractive processor designs is validated through numerical tests on unseen objects, including thin Pap smear images. Due to its all-optical processing capability using passive dielectric diffractive materials, this diffractive multispectral QPI processor offers a compact and power-efficient solution for high-throughput quantitative phase microscopy and spectroscopy. This framework can operate at different parts of the electromagnetic spectrum and be used for a wide range of phase imaging and sensing applications.
</details>
<details>
<summary>摘要</summary>
为了实现标注自由的成像技术，量子阶段成像（QPI）提供了透明样品的光路径信息，用于生物、材料科学和工程各种应用。多spectral QPI测量了透明样品的波长特征，允许样品的波长特征和分散特征的检测。在这里，我们提出了一种可以在一步中完成多spectral量子阶段成像的干涉处理器设计。我们的设计利用了工程干涉层，通过深度学习优化，将输入样品的相位特征编码到预先确定的波长谱中，并通过干涉处理器将其转换为具有空间强度变化的输出平面。这种方法可以通过单色焦点平面数组实现多spectral QPI。我们通过数值 simulations 表明，我们的设计可以同时在9和16个目标频谱中进行多spectral QPI，并且在所有波长通道中保持均衡性，从而实现高质量的QPI性能。我们的总结是，通过深度学习优化的干涉处理器可以在不同的电磁谱спектrum中实现高效的量子阶段成像和感知应用。这种方法可以用于各种透明样品的成像和感知应用，并且可以在不同的波长谱中运行。
</details></li>
</ul>
<hr>
<h2 id="MomentaMorph-Unsupervised-Spatial-Temporal-Registration-with-Momenta-Shooting-and-Correction"><a href="#MomentaMorph-Unsupervised-Spatial-Temporal-Registration-with-Momenta-Shooting-and-Correction" class="headerlink" title="MomentaMorph: Unsupervised Spatial-Temporal Registration with Momenta, Shooting, and Correction"></a>MomentaMorph: Unsupervised Spatial-Temporal Registration with Momenta, Shooting, and Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02949">http://arxiv.org/abs/2308.02949</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhangxing Bian, Shuwen Wei, Yihao Liu, Junyu Chen, Jiachen Zhuo, Fangxu Xing, Jonghye Woo, Aaron Carass, Jerry L. Prince</li>
<li>For: This paper aims to address the challenges of registering magnetic resonance imaging (MRI) data with large motion and repetitive patterns, which can lead to motion estimation errors.* Methods: The proposed method uses a “momenta, shooting, and correction” framework grounded in Lie algebra and Lie group principles. This framework accumulates momenta in the tangent vector space and employs exponential mapping in the diffeomorphic space for rapid approximation towards true optima, circumventing local optima.* Results: The method is demonstrated to be efficient in estimating accurate, dense, and diffeomorphic 2D&#x2F;3D motion fields amidst large motion and repetitive patterns on both a 2D synthetic dataset and a real 3D tMRI dataset.<details>
<summary>Abstract</summary>
Tagged magnetic resonance imaging (tMRI) has been employed for decades to measure the motion of tissue undergoing deformation. However, registration-based motion estimation from tMRI is difficult due to the periodic patterns in these images, particularly when the motion is large. With a larger motion the registration approach gets trapped in a local optima, leading to motion estimation errors. We introduce a novel "momenta, shooting, and correction" framework for Lagrangian motion estimation in the presence of repetitive patterns and large motion. This framework, grounded in Lie algebra and Lie group principles, accumulates momenta in the tangent vector space and employs exponential mapping in the diffeomorphic space for rapid approximation towards true optima, circumventing local optima. A subsequent correction step ensures convergence to true optima. The results on a 2D synthetic dataset and a real 3D tMRI dataset demonstrate our method's efficiency in estimating accurate, dense, and diffeomorphic 2D/3D motion fields amidst large motion and repetitive patterns.
</details>
<details>
<summary>摘要</summary>
测量类型核磁共振成像（tMRI）已经用数十年来量化体内组织运动的变形。然而，从tMRI中使用登录基本的动作估计受到频繁的图样和大动作的限制，导致动作估计出错。我们介绍了一个新的“动量、射线和调整”框架，用于在具有循环图样和大动作的情况下，高精度地估计Lagrangian动作场。这个框架基于李代数和李群原理，在射线空间寄存动量，并使用对称空间的对易映射来快速地对真的极点进行快速趋向，避免本地极点。接着的调整步骤确保了对真的极点的对准。实验结果显示，我们的方法可以高效地在具有大动作和循环图样的2D/3D tMRI数据中估计精度高、密集的动作场。
</details></li>
</ul>
<hr>
<h2 id="Blind-Motion-Deblurring-with-Pixel-Wise-Kernel-Estimation-via-Kernel-Prediction-Networks"><a href="#Blind-Motion-Deblurring-with-Pixel-Wise-Kernel-Estimation-via-Kernel-Prediction-Networks" class="headerlink" title="Blind Motion Deblurring with Pixel-Wise Kernel Estimation via Kernel Prediction Networks"></a>Blind Motion Deblurring with Pixel-Wise Kernel Estimation via Kernel Prediction Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02947">http://arxiv.org/abs/2308.02947</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/guillermocarbajal/j-mkpd">https://github.com/guillermocarbajal/j-mkpd</a></li>
<li>paper_authors: Guillermo Carbajal, Patricia Vitoria, José Lezama, Pablo Musé</li>
<li>for: 提高摄像头拍摄图像的运动模糊除卸。</li>
<li>methods: 使用深度学习方法，首先估计杂质函数，然后使用非盲解减法。</li>
<li>results: 实现了对真实模糊图像的高质量修复，与现有的端到端深度学习方法相当或更好。Here’s the full Chinese text in simplified format:* 为：提高摄像头拍摄图像的运动模糊除卸。* 方法：使用深度学习方法，首先估计杂质函数，然后使用非盲解减法。* 结果：实现了对真实模糊图像的高质量修复，与现有的端到端深度学习方法相当或更好。<details>
<summary>Abstract</summary>
In recent years, the removal of motion blur in photographs has seen impressive progress in the hands of deep learning-based methods, trained to map directly from blurry to sharp images. For this reason, approaches that explicitly use a forward degradation model received significantly less attention. However, a well-defined specification of the blur genesis, as an intermediate step, promotes the generalization and explainability of the method. Towards this goal, we propose a learning-based motion deblurring method based on dense non-uniform motion blur estimation followed by a non-blind deconvolution approach. Specifically, given a blurry image, a first network estimates the dense per-pixel motion blur kernels using a lightweight representation composed of a set of image-adaptive basis motion kernels and the corresponding mixing coefficients. Then, a second network trained jointly with the first one, unrolls a non-blind deconvolution method using the motion kernel field estimated by the first network. The model-driven aspect is further promoted by training the networks on sharp/blurry pairs synthesized according to a convolution-based, non-uniform motion blur degradation model. Qualitative and quantitative evaluation shows that the kernel prediction network produces accurate motion blur estimates, and that the deblurring pipeline leads to restorations of real blurred images that are competitive or superior to those obtained with existing end-to-end deep learning-based methods. Code and trained models are available at https://github.com/GuillermoCarbajal/J-MKPD/.
</details>
<details>
<summary>摘要</summary>
Recent years have seen significant progress in removing motion blur from photographs using deep learning-based methods, which map directly from blurry to sharp images. As a result, methods that explicitly use a forward degradation model have received less attention. However, a well-defined specification of the blur genesis, as an intermediate step, can promote the generalization and explainability of the method. To address this, we propose a learning-based motion deblurring method based on dense non-uniform motion blur estimation followed by a non-blind deconvolution approach.Given a blurry image, the first network estimates the dense per-pixel motion blur kernels using a lightweight representation composed of a set of image-adaptive basis motion kernels and the corresponding mixing coefficients. Then, a second network trained jointly with the first one unrolls a non-blind deconvolution method using the motion kernel field estimated by the first network. The model-driven aspect is further promoted by training the networks on sharp/blurry pairs synthesized according to a convolution-based, non-uniform motion blur degradation model.Qualitative and quantitative evaluation shows that the kernel prediction network produces accurate motion blur estimates, and that the deblurring pipeline leads to restorations of real blurred images that are competitive or superior to those obtained with existing end-to-end deep learning-based methods. Code and trained models are available at <https://github.com/GuillermoCarbajal/J-MKPD/>.
</details></li>
</ul>
<hr>
<h2 id="Automatic-registration-with-continuous-pose-updates-for-marker-less-surgical-navigation-in-spine-surgery"><a href="#Automatic-registration-with-continuous-pose-updates-for-marker-less-surgical-navigation-in-spine-surgery" class="headerlink" title="Automatic registration with continuous pose updates for marker-less surgical navigation in spine surgery"></a>Automatic registration with continuous pose updates for marker-less surgical navigation in spine surgery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02917">http://arxiv.org/abs/2308.02917</a></li>
<li>repo_url: None</li>
<li>paper_authors: Florentin Liebmann, Marco von Atzigen, Dominik Stütz, Julian Wolf, Lukas Zingg, Daniel Suter, Laura Leoty, Hooman Esfandiari, Jess G. Snedeker, Martin R. Oswald, Marc Pollefeys, Mazda Farshad, Philipp Fürnstahl</li>
<li>for: 骨相干 Navigation 系统的开发，以提高 lumbar 脊椎连接手术中的钉 placement 精度。</li>
<li>methods: 使用深度学习神经网络对 lumbar 脊椎进行自动注册，并在实时更新中使用 GPU 加速。</li>
<li>results: 在一个公共数据集上，成功注册率为 96%，注册误差为 2.73 mm，钉轨迹误差为 1.79°，钉入点误差为 2.43 mm。在人体试验中也实现了 100% 的钉准确性和 1.20 mm 的注册精度。<details>
<summary>Abstract</summary>
Established surgical navigation systems for pedicle screw placement have been proven to be accurate, but still reveal limitations in registration or surgical guidance. Registration of preoperative data to the intraoperative anatomy remains a time-consuming, error-prone task that includes exposure to harmful radiation. Surgical guidance through conventional displays has well-known drawbacks, as information cannot be presented in-situ and from the surgeon's perspective. Consequently, radiation-free and more automatic registration methods with subsequent surgeon-centric navigation feedback are desirable. In this work, we present an approach that automatically solves the registration problem for lumbar spinal fusion surgery in a radiation-free manner. A deep neural network was trained to segment the lumbar spine and simultaneously predict its orientation, yielding an initial pose for preoperative models, which then is refined for each vertebra individually and updated in real-time with GPU acceleration while handling surgeon occlusions. An intuitive surgical guidance is provided thanks to the integration into an augmented reality based navigation system. The registration method was verified on a public dataset with a mean of 96\% successful registrations, a target registration error of 2.73 mm, a screw trajectory error of 1.79{\deg} and a screw entry point error of 2.43 mm. Additionally, the whole pipeline was validated in an ex-vivo surgery, yielding a 100\% screw accuracy and a registration accuracy of 1.20 mm. Our results meet clinical demands and emphasize the potential of RGB-D data for fully automatic registration approaches in combination with augmented reality guidance.
</details>
<details>
<summary>摘要</summary>
We trained a deep neural network to segment the lumbar spine and simultaneously predict its orientation, yielding an initial pose for preoperative models, which is then refined for each vertebra individually and updated in real-time with GPU acceleration while handling surgeon occlusions. This approach provides an intuitive surgical guidance through an augmented reality-based navigation system.We verified our registration method on a public dataset with a mean of 96% successful registrations, a target registration error of 2.73 mm, a screw trajectory error of 1.79°, and a screw entry point error of 2.43 mm. Additionally, we validated the whole pipeline in an ex-vivo surgery, yielding a 100% screw accuracy and a registration accuracy of 1.20 mm. Our results meet clinical demands and highlight the potential of RGB-D data for fully automatic registration approaches in combination with augmented reality guidance.
</details></li>
</ul>
<hr>
<h2 id="DiffDance-Cascaded-Human-Motion-Diffusion-Model-for-Dance-Generation"><a href="#DiffDance-Cascaded-Human-Motion-Diffusion-Model-for-Dance-Generation" class="headerlink" title="DiffDance: Cascaded Human Motion Diffusion Model for Dance Generation"></a>DiffDance: Cascaded Human Motion Diffusion Model for Dance Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02915">http://arxiv.org/abs/2308.02915</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiaosong Qi, Le Zhuo, Aixi Zhang, Yue Liao, Fei Fang, Si Liu, Shuicheng Yan</li>
<li>for: 本研究旨在生成高分辨率、长形舞蹈序列，以便与输入音乐进行有效的Alignment。</li>
<li>methods: 该模型采用了一种新的级联动动态模型（DiffDance），其包括一个音乐到舞蹈吸引模型和一个序列超分辨模型。在 conditional 生成过程中，DiffDance 使用了一个预训练的音频表示学习模型来提取音乐嵌入，并通过对比损失来对其嵌入空间与动作进行对齐。</li>
<li>results: 通过对 AIST++ 数据集进行了广泛的实验，我们展示了 DiffDance 能够生成真实的舞蹈序列，并且与输入音乐高效地进行了Alignment。这些结果与当前的 autoregressive 方法相当。<details>
<summary>Abstract</summary>
When hearing music, it is natural for people to dance to its rhythm. Automatic dance generation, however, is a challenging task due to the physical constraints of human motion and rhythmic alignment with target music. Conventional autoregressive methods introduce compounding errors during sampling and struggle to capture the long-term structure of dance sequences. To address these limitations, we present a novel cascaded motion diffusion model, DiffDance, designed for high-resolution, long-form dance generation. This model comprises a music-to-dance diffusion model and a sequence super-resolution diffusion model. To bridge the gap between music and motion for conditional generation, DiffDance employs a pretrained audio representation learning model to extract music embeddings and further align its embedding space to motion via contrastive loss. During training our cascaded diffusion model, we also incorporate multiple geometric losses to constrain the model outputs to be physically plausible and add a dynamic loss weight that adaptively changes over diffusion timesteps to facilitate sample diversity. Through comprehensive experiments performed on the benchmark dataset AIST++, we demonstrate that DiffDance is capable of generating realistic dance sequences that align effectively with the input music. These results are comparable to those achieved by state-of-the-art autoregressive methods.
</details>
<details>
<summary>摘要</summary>
DiffDance consists of a music-to-dance diffusion model and a sequence super-resolution diffusion model. To bridge the gap between music and motion for conditional generation, DiffDance uses a pre-trained audio representation learning model to extract music embeddings and align its embedding space to motion through contrastive loss. During training, we incorporate multiple geometric losses to ensure physically plausible outputs and add a dynamic loss weight that adaptively changes over diffusion timesteps to promote sample diversity.We evaluate DiffDance on the benchmark dataset AIST++ and demonstrate that it can generate realistic dance sequences that effectively align with the input music. Our results are comparable to those achieved by state-of-the-art autoregressive methods.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/06/cs.CV_2023_08_06/" data-id="clp89docm00hji788b5yt2ru2" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/06/cs.AI_2023_08_06/" class="article-date">
  <time datetime="2023-08-06T12:00:00.000Z" itemprop="datePublished">2023-08-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/06/cs.AI_2023_08_06/">cs.AI - 2023-08-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="AI-GOMS-Large-AI-Driven-Global-Ocean-Modeling-System"><a href="#AI-GOMS-Large-AI-Driven-Global-Ocean-Modeling-System" class="headerlink" title="AI-GOMS: Large AI-Driven Global Ocean Modeling System"></a>AI-GOMS: Large AI-Driven Global Ocean Modeling System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03152">http://arxiv.org/abs/2308.03152</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Xiong, Yanfei Xiang, Hao Wu, Shuyi Zhou, Yuze Sun, Muyuan Ma, Xiaomeng Huang</li>
<li>for: 这篇论文旨在提出一种基于人工智能的全球海洋模型系统（AI-GOMS），以提高海洋日干预测的准确性和效率。</li>
<li>methods: 该论文使用了一种基于 Fourier-based Masked Autoencoder 结构的基本海洋变量预测模型，以及一些轻量级细化模型，包括地区下降、浪谱解码和生物化协同模块。</li>
<li>results: 该论文在30天预测期内，对全球海洋基本变量（15层深度）的预测达到了最佳性能，并且在统计指标上表现出色。此外，AI-GOMS还能模拟mesoscale涝团在日本海洋区域的涝团，以及在 тропиical Pacific 海洋区域的海洋层次分布。<details>
<summary>Abstract</summary>
Ocean modeling is a powerful tool for simulating the physical, chemical, and biological processes of the ocean, which is the foundation for marine science research and operational oceanography. Modern numerical ocean modeling mainly consists of governing equations and numerical algorithms. Nonlinear instability, computational expense, low reusability efficiency and high coupling costs have gradually become the main bottlenecks for the further development of numerical ocean modeling. Recently, artificial intelligence-based modeling in scientific computing has shown revolutionary potential for digital twins and scientific simulations, but the bottlenecks of numerical ocean modeling have not been further solved. Here, we present AI-GOMS, a large AI-driven global ocean modeling system, for accurate and efficient global ocean daily prediction. AI-GOMS consists of a backbone model with the Fourier-based Masked Autoencoder structure for basic ocean variable prediction and lightweight fine-tuning models incorporating regional downscaling, wave decoding, and biochemistry coupling modules. AI-GOMS has achieved the best performance in 30 days of prediction for the global ocean basic variables with 15 depth layers at 1/4{\deg} spatial resolution. Beyond the good performance in statistical metrics, AI-GOMS realizes the simulation of mesoscale eddies in the Kuroshio region at 1/12{\deg} spatial resolution and ocean stratification in the tropical Pacific Ocean. AI-GOMS provides a new backbone-downstream paradigm for Earth system modeling, which makes the system transferable, scalable and reusable.
</details>
<details>
<summary>摘要</summary>
海洋模型是一种强大的工具，用于模拟海洋的物理、化学和生物过程，这是海洋科学研究和操作海洋学的基础。现代数值海洋模型主要由管理方程和数值算法组成。不线性不稳定、计算成本高、重用率低和对接成本高逐渐成为数值海洋模型的主要瓶颈。在科学计算中，基于人工智能的模型在近年来表现出革命性的潜力，但是数值海洋模型中的瓶颈问题没有得到解决。我们现在提出了AI-GOMS，一个大型基于人工智能的全球海洋模型系统，用于准确和高效地预测全球海洋的日常变化。AI-GOMS包括一个基本模型，使用带mask的自适应神经网络结构来预测基本海洋变量，以及轻量级的精度适应模型，包括地区下降、波解码和生物化学相互作用模块。AI-GOMS在30天预测全球海洋基本变量中达到了15层深度的1/4度空间分辨率，并实现了库ashiyo区域的微型旋转和海洋层次分布在赤道太平洋海域。AI-GOMS提供了一个新的后台下渠模型，使得系统可以易于传输、扩展和重用。
</details></li>
</ul>
<hr>
<h2 id="“We-care”-Improving-Code-Mixed-Speech-Emotion-Recognition-in-Customer-Care-Conversations"><a href="#“We-care”-Improving-Code-Mixed-Speech-Emotion-Recognition-in-Customer-Care-Conversations" class="headerlink" title="“We care”: Improving Code Mixed Speech Emotion Recognition in Customer-Care Conversations"></a>“We care”: Improving Code Mixed Speech Emotion Recognition in Customer-Care Conversations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03150">http://arxiv.org/abs/2308.03150</a></li>
<li>repo_url: None</li>
<li>paper_authors: N V S Abhishek, Pushpak Bhattacharyya</li>
<li>for: 这个论文的目的是提高对自然语言 conversational AI 中的情绪识别精度。</li>
<li>methods: 该论文使用了自然混合语言的 conversational AI 数据集（NSED），并通过 incorporating word-level VAD value 提高了 SER 任务的精度。</li>
<li>results: 根据该论文的结果，在 NSED 数据集上，通过 incorporating word-level VAD value 可以提高 SER 任务的精度，特别是对于负情绪的识别精度提高了2%。<details>
<summary>Abstract</summary>
Speech Emotion Recognition (SER) is the task of identifying the emotion expressed in a spoken utterance. Emotion recognition is essential in building robust conversational agents in domains such as law, healthcare, education, and customer support. Most of the studies published on SER use datasets created by employing professional actors in a noise-free environment. In natural settings such as a customer care conversation, the audio is often noisy with speakers regularly switching between different languages as they see fit. We have worked in collaboration with a leading unicorn in the Conversational AI sector to develop Natural Speech Emotion Dataset (NSED). NSED is a natural code-mixed speech emotion dataset where each utterance in a conversation is annotated with emotion, sentiment, valence, arousal, and dominance (VAD) values. In this paper, we show that by incorporating word-level VAD value we improve on the task of SER by 2%, for negative emotions, over the baseline value for NSED. High accuracy for negative emotion recognition is essential because customers expressing negative opinions/views need to be pacified with urgency, lest complaints and dissatisfaction snowball and get out of hand. Escalation of negative opinions speedily is crucial for business interests. Our study then can be utilized to develop conversational agents which are more polite and empathetic in such situations.
</details>
<details>
<summary>摘要</summary>
《语音情感识别（SER）是指根据说话人的语音特征来确定他们表达的情感。情感识别是建立Robust conversational agents的关键，特别是在法律、医疗、教育和客户支持等领域。大多数已发表的SER研究使用了由专业演员创建的数据集，这些数据集通常在干净的环境中采集。然而，在自然环境中，如客户服务对话，音频通常具有噪音和Speaker switching between不同的语言的现象。我们与行业领袖的Conversational AI公司合作，开发了自然语音情感数据集（NSED）。NSED是一个自然语音混合语言的情感数据集，每个对话中的每句话都有情感、情感、浓淡、高低（VAD）值的注释。在这篇论文中，我们表明，通过 incorporating 单词级VAD值，可以在NSED数据集上提高SER任务的准确率，对负情感的准确率提高2%。正确识别负情感的精度非常重要，因为客户表达负面意见时需要尽快 pacify，以避免投诉和不满的情况扩散和恶化。这些情况下，我们的研究可以用于开发更加偏袋和同情的对话机器人。》
</details></li>
</ul>
<hr>
<h2 id="Towards-socially-competent-and-culturally-adaptive-artificial-agents-Expressive-order-interactional-disruptions-and-recovery-strategies"><a href="#Towards-socially-competent-and-culturally-adaptive-artificial-agents-Expressive-order-interactional-disruptions-and-recovery-strategies" class="headerlink" title="Towards socially-competent and culturally-adaptive artificial agents Expressive order, interactional disruptions and recovery strategies"></a>Towards socially-competent and culturally-adaptive artificial agents Expressive order, interactional disruptions and recovery strategies</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03146">http://arxiv.org/abs/2308.03146</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chiara Bassetti, Enrico Blanzieri, Stefano Borgo, Sofia Marangon</li>
<li>for: 这个论文的目的是使人工智能代理人在多方交互情况下展现社交技巧和地方社会规范知识。</li>
<li>methods: 这个论文使用了分离表达和功能两个顺序的方法，并提出了一种框架来使人工智能代理人在多方交互情况下成为社交合格的。</li>
<li>results: 这个论文的结果表明，通过分类功能和社交干扰，以及研究人工智能架构是如何利用这些知识的，可以使人工智能代理人在多方交互情况下展现出社交技巧。<details>
<summary>Abstract</summary>
The development of artificial agents for social interaction pushes to enrich robots with social skills and knowledge about (local) social norms. One possibility is to distinguish the expressive and the functional orders during a human-robot interaction. The overarching aim of this work is to set a framework to make the artificial agent socially-competent beyond dyadic interaction-interaction in varying multi-party social situations-and beyond individual-based user personalization, thereby enlarging the current conception of "culturally-adaptive". The core idea is to provide the artificial agent with the capability to handle different kinds of interactional disruptions, and associated recovery strategies, in microsociology. The result is obtained by classifying functional and social disruptions, and by investigating the requirements a robot's architecture should satisfy to exploit such knowledge. The paper also highlights how this level of competence is achieved by focusing on just three dimensions: (i) social capability, (ii) relational role, and (iii) proximity, leaving aside the further complexity of full-fledged human-human interactions. Without going into technical aspects, End-to-end Data-driven Architectures and Modular Architectures are discussed to evaluate the degree to which they can exploit this new set of social and cultural knowledge. Finally, a list of general requirements for such agents is proposed.
</details>
<details>
<summary>摘要</summary>
人工智能代理人的发展推动了赋予机器人社交技能和地方社会规范知识。一种可能是在人机交互中分辨出表达性和功能性的两个顺序。本研究的核心目标是为人工代理人提供社会能力，使其在多方社会情况下能够应对不同类型的交互干扰和相应的恢复策略，从而超越当前的“文化适应”概念。以下是本研究的核心思想：1. 分类功能性和社交性的干扰，并调查机器人体系是如何利用这些知识。2. 只关注三个维度：社会能力、关系角色和距离，忽略人类之间的复杂交互。3. 评估END-TO-END数据驱动体系和模块化体系是否能够利用这些新的社会和文化知识。4. 提出人工代理人的通用要求列表。希望这个翻译能够帮助您！（_ _)
</details></li>
</ul>
<hr>
<h2 id="Embedding-based-Retrieval-with-LLM-for-Effective-Agriculture-Information-Extracting-from-Unstructured-Data"><a href="#Embedding-based-Retrieval-with-LLM-for-Effective-Agriculture-Information-Extracting-from-Unstructured-Data" class="headerlink" title="Embedding-based Retrieval with LLM for Effective Agriculture Information Extracting from Unstructured Data"></a>Embedding-based Retrieval with LLM for Effective Agriculture Information Extracting from Unstructured Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03107">http://arxiv.org/abs/2308.03107</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ruoling Peng, Kang Liu, Po Yang, Zhipeng Yuan, Shunbao Li</li>
<li>for: 本研究旨在提高农业领域病虫识别率，使用域名独立普通话语言模型（LLM）自动提取农业文档中的结构化数据。</li>
<li>methods: 本研究使用文本检索和筛选，使用嵌入空间Retrieval，然后使用LLM问答系统自动提取文档中的实体和属性，并将其转换为结构化数据。</li>
<li>results: 对比现有方法，本研究在标准测试集上保持了更高的准确率，同时具有高效性。<details>
<summary>Abstract</summary>
Pest identification is a crucial aspect of pest control in agriculture. However, most farmers are not capable of accurately identifying pests in the field, and there is a limited number of structured data sources available for rapid querying. In this work, we explored using domain-agnostic general pre-trained large language model(LLM) to extract structured data from agricultural documents with minimal or no human intervention. We propose a methodology that involves text retrieval and filtering using embedding-based retrieval, followed by LLM question-answering to automatically extract entities and attributes from the documents, and transform them into structured data. In comparison to existing methods, our approach achieves consistently better accuracy in the benchmark while maintaining efficiency.
</details>
<details>
<summary>摘要</summary>
害虫识别是农业害虫控制中的关键环节。然而，大多数农民无法在场地上准确地识别害虫，而有限的结构化数据源也不可供快速查询。在这项工作中，我们探讨使用领域独立的大型自然语言模型（LLM）来从农业文档中提取结构化数据，无需或 minimal 人工干预。我们提议一种方法，包括文本检索和筛选使用嵌入空间 retrieval，然后使用 LLM 问答来自动提取文档中的实体和属性，并将其转换为结构化数据。相比现有方法，我们的方法在 benchmark 中具有更高的稳定性和效率。
</details></li>
</ul>
<hr>
<h2 id="Language-based-Photo-Color-Adjustment-for-Graphic-Designs"><a href="#Language-based-Photo-Color-Adjustment-for-Graphic-Designs" class="headerlink" title="Language-based Photo Color Adjustment for Graphic Designs"></a>Language-based Photo Color Adjustment for Graphic Designs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03059">http://arxiv.org/abs/2308.03059</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhenwei Wang, Nanxuan Zhao, Gerhard Hancke, Rynson W. H. Lau</li>
<li>for: 这篇论文的目的是为 graphic design 提供一种语言基于的图像重新色调方法，以便更好地传达图像的信息和增加美感。</li>
<li>methods: 该方法使用了一种语言基于的模型，可以帮助专业人士和新手插画师来重新色调图像。它可以预测图像中的源颜色和目标区域，然后将目标区域重新色调为源颜色。</li>
<li>results: 该方法可以准确地重新色调图像，并且可以根据用户的多重指令来生成多个可能的结果。它还可以保持原始图像的 semantics，以便更好地增加图像的美感。<details>
<summary>Abstract</summary>
Adjusting the photo color to associate with some design elements is an essential way for a graphic design to effectively deliver its message and make it aesthetically pleasing. However, existing tools and previous works face a dilemma between the ease of use and level of expressiveness. To this end, we introduce an interactive language-based approach for photo recoloring, which provides an intuitive system that can assist both experts and novices on graphic design. Given a graphic design containing a photo that needs to be recolored, our model can predict the source colors and the target regions, and then recolor the target regions with the source colors based on the given language-based instruction. The multi-granularity of the instruction allows diverse user intentions. The proposed novel task faces several unique challenges, including: 1) color accuracy for recoloring with exactly the same color from the target design element as specified by the user; 2) multi-granularity instructions for parsing instructions correctly to generate a specific result or multiple plausible ones; and 3) locality for recoloring in semantically meaningful local regions to preserve original image semantics. To address these challenges, we propose a model called LangRecol with two main components: the language-based source color prediction module and the semantic-palette-based photo recoloring module. We also introduce an approach for generating a synthetic graphic design dataset with instructions to enable model training. We evaluate our model via extensive experiments and user studies. We also discuss several practical applications, showing the effectiveness and practicality of our approach. Code and data for this paper are at: https://zhenwwang.github.io/langrecol.
</details>
<details>
<summary>摘要</summary>
adjusting the photo color to match with some design elements is a crucial way for a graphic design to effectively deliver its message and make it visually appealing. However, existing tools and previous works face a dilemma between ease of use and level of expressiveness. To address this challenge, we propose an interactive language-based approach for photo recoloring, which provides an intuitive system that can assist both experts and novices in graphic design. Given a graphic design containing a photo that needs to be recolored, our model can predict the source colors and the target regions, and then recolor the target regions with the source colors based on the given language-based instruction. The multi-granularity of the instruction allows diverse user intentions. The proposed novel task faces several unique challenges, including: 1) color accuracy for recoloring with exactly the same color from the target design element as specified by the user; 2) multi-granularity instructions for parsing instructions correctly to generate a specific result or multiple plausible ones; and 3) locality for recoloring in semantically meaningful local regions to preserve original image semantics. To address these challenges, we propose a model called LangRecol with two main components: the language-based source color prediction module and the semantic-palette-based photo recoloring module. We also introduce an approach for generating a synthetic graphic design dataset with instructions to enable model training. We evaluate our model via extensive experiments and user studies. We also discuss several practical applications, showing the effectiveness and practicality of our approach. Code and data for this paper are available at: <https://zhenwwang.github.io/langrecol>.
</details></li>
</ul>
<hr>
<h2 id="Comparative-Analysis-of-Epileptic-Seizure-Prediction-Exploring-Diverse-Pre-Processing-Techniques-and-Machine-Learning-Models"><a href="#Comparative-Analysis-of-Epileptic-Seizure-Prediction-Exploring-Diverse-Pre-Processing-Techniques-and-Machine-Learning-Models" class="headerlink" title="Comparative Analysis of Epileptic Seizure Prediction: Exploring Diverse Pre-Processing Techniques and Machine Learning Models"></a>Comparative Analysis of Epileptic Seizure Prediction: Exploring Diverse Pre-Processing Techniques and Machine Learning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05176">http://arxiv.org/abs/2308.05176</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md. Simul Hasan Talukder, Rejwan Bin Sulaiman</li>
<li>for: 预测 эпилептических发作</li>
<li>methods: 使用多种机器学习模型进行预测</li>
<li>results: 比较分析五种机器学习模型的性能，结果显示Extra Trees模型在预测 эпилептических发作中表现最佳，其准确率达99.29%，超过了之前的研究成果。<details>
<summary>Abstract</summary>
Epilepsy is a prevalent neurological disorder characterized by recurrent and unpredictable seizures, necessitating accurate prediction for effective management and patient care. Application of machine learning (ML) on electroencephalogram (EEG) recordings, along with its ability to provide valuable insights into brain activity during seizures, is able to make accurate and robust seizure prediction an indispensable component in relevant studies. In this research, we present a comprehensive comparative analysis of five machine learning models - Random Forest (RF), Decision Tree (DT), Extra Trees (ET), Logistic Regression (LR), and Gradient Boosting (GB) - for the prediction of epileptic seizures using EEG data. The dataset underwent meticulous preprocessing, including cleaning, normalization, outlier handling, and oversampling, ensuring data quality and facilitating accurate model training. These preprocessing techniques played a crucial role in enhancing the models' performance. The results of our analysis demonstrate the performance of each model in terms of accuracy. The LR classifier achieved an accuracy of 56.95%, while GB and DT both attained 97.17% accuracy. RT achieved a higher accuracy of 98.99%, while the ET model exhibited the best performance with an accuracy of 99.29%. Our findings reveal that the ET model outperformed not only the other models in the comparative analysis but also surpassed the state-of-the-art results from previous research. The superior performance of the ET model makes it a compelling choice for accurate and robust epileptic seizure prediction using EEG data.
</details>
<details>
<summary>摘要</summary>
эпилепсия是一种常见的神经疾病，表现为不规则的发作，需要准确预测以提供有效的管理和患者照料。通过机器学习（ML）的应用于电энцефалографиagram（EEG）记录，可以提供有价值的脑活动信息 durante发作，因此成为有效的预测组成部分。在这项研究中，我们进行了全面的比较分析，推荐五种机器学习模型：Random Forest（RF）、Decision Tree（DT）、Extra Trees（ET）、Logistic Regression（LR）和Gradient Boosting（GB），用于预测癫痫发作。数据集经过了仔细的处理，包括清洁、 нормализа、异常处理和扩展，以确保数据质量，并促进模型训练。这些处理技术在提高模型性能方面发挥了关键作用。我们的分析结果表明每个模型在准确率方面的表现，LR分类器达到56.95%的准确率，而GB和DT都达到97.17%的准确率。RT达到98.99%的准确率，而ET模型表现出了最好的性能，准确率达99.29%。我们的发现表明，ET模型不仅在本研究中的比较分析中表现出色，还超越了过去研究中的状态体现。ET模型的出色表现使其成为精准和可靠的癫痫发作预测方法。
</details></li>
</ul>
<hr>
<h2 id="Weakly-Supervised-Multi-Task-Representation-Learning-for-Human-Activity-Analysis-Using-Wearables"><a href="#Weakly-Supervised-Multi-Task-Representation-Learning-for-Human-Activity-Analysis-Using-Wearables" class="headerlink" title="Weakly Supervised Multi-Task Representation Learning for Human Activity Analysis Using Wearables"></a>Weakly Supervised Multi-Task Representation Learning for Human Activity Analysis Using Wearables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03805">http://arxiv.org/abs/2308.03805</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taoran Sheng, Manfred Huber</li>
<li>for: 这 paper 的目的是提出一种多任务弱监督 siamese 网络，用于将数据映射到多个表示空间中，以便同时解决多个任务。</li>
<li>methods: 该方法使用了多输出 siamese 网络，其中每个输出都关注一个不同的方面的数据。这使得数据样本的表示向量在多个表示空间中被排序，使得同Semantic meaning的数据在同一个空间中几乎重合。</li>
<li>results: 经过一系列实验表明，该模型可以同时解决多个任务，并且在许多情况下可以超越单任务监督方法的性能。此外，paper 还进一步分析了该框架的architecture和多任务之间的关系，以及将多个任务合并到同一个框架中的可扩展性。<details>
<summary>Abstract</summary>
Sensor data streams from wearable devices and smart environments are widely studied in areas like human activity recognition (HAR), person identification, or health monitoring. However, most of the previous works in activity and sensor stream analysis have been focusing on one aspect of the data, e.g. only recognizing the type of the activity or only identifying the person who performed the activity. We instead propose an approach that uses a weakly supervised multi-output siamese network that learns to map the data into multiple representation spaces, where each representation space focuses on one aspect of the data. The representation vectors of the data samples are positioned in the space such that the data with the same semantic meaning in that aspect are closely located to each other. Therefore, as demonstrated with a set of experiments, the trained model can provide metrics for clustering data based on multiple aspects, allowing it to address multiple tasks simultaneously and even to outperform single task supervised methods in many situations. In addition, further experiments are presented that in more detail analyze the effect of the architecture and of using multiple tasks within this framework, that investigate the scalability of the model to include additional tasks, and that demonstrate the ability of the framework to combine data for which only partial relationship information with respect to the target tasks is available.
</details>
<details>
<summary>摘要</summary>
仪器数据流从智能设备和智能环境中广泛研究，如人动作识别（HAR）、人识别或健康监测。然而，大多数之前的活动和数据流分析工作都是专注一个方面的数据，例如仅仅识别活动的类型或仅仅识别活动的执行者。我们提议一种使用弱监督多输出siamesenet来映射数据到多个表示空间，其中每个表示空间专注一个数据方面。数据样本的表示向量在空间中的位置是根据数据semantic意义相似的，因此训练模型可以为多个任务提供分 clustering  metrics，使其能同时解决多个任务，甚至在许多情况下超越单任务监督方法。此外，我们还进行了进一步的实验，分析了这种架构的影响和多任务内部的效果，以及模型可以扩展到包括更多任务的可扩展性。最后，我们还示出了将多个任务的数据合并起来，只有部分关系信息与目标任务相关的情况下，模型仍然可以提供高效的分类结果。
</details></li>
</ul>
<hr>
<h2 id="Serverless-Federated-AUPRC-Optimization-for-Multi-Party-Collaborative-Imbalanced-Data-Mining"><a href="#Serverless-Federated-AUPRC-Optimization-for-Multi-Party-Collaborative-Imbalanced-Data-Mining" class="headerlink" title="Serverless Federated AUPRC Optimization for Multi-Party Collaborative Imbalanced Data Mining"></a>Serverless Federated AUPRC Optimization for Multi-Party Collaborative Imbalanced Data Mining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03035">http://arxiv.org/abs/2308.03035</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xidongwu/d-auprc">https://github.com/xidongwu/d-auprc</a></li>
<li>paper_authors: Xidong Wu, Zhengmian Hu, Jian Pei, Heng Huang</li>
<li>for: 这篇论文targets the problem of multi-party collaborative training for imbalanced data tasks, with the goal of maximizing the Area Under Precision-Recall Curve (AUPRC).</li>
<li>methods: 该论文提出了一种新的ServerLess biAsed sTochastic gradiEnt (SLATE) algorithm，用于直接优化AUPRC。此外，还提出了一种基于势量衰减技术的ServerLess biAsed sTochastic gradiEnt with Momentum-based variance reduction (SLATE-M) algorithm，用于提高收敛率。</li>
<li>results: 该论文的实验结果表明，SLATE-M算法可以与单机在线方法匹配最佳理论收敛率，并且在多方合作训练中减少了通信成本。<details>
<summary>Abstract</summary>
Multi-party collaborative training, such as distributed learning and federated learning, is used to address the big data challenges. However, traditional multi-party collaborative training algorithms were mainly designed for balanced data mining tasks and are intended to optimize accuracy (\emph{e.g.}, cross-entropy). The data distribution in many real-world applications is skewed and classifiers, which are trained to improve accuracy, perform poorly when applied to imbalanced data tasks since models could be significantly biased toward the primary class. Therefore, the Area Under Precision-Recall Curve (AUPRC) was introduced as an effective metric. Although single-machine AUPRC maximization methods have been designed, multi-party collaborative algorithm has never been studied. The change from the single-machine to the multi-party setting poses critical challenges.   To address the above challenge, we study the serverless multi-party collaborative AUPRC maximization problem since serverless multi-party collaborative training can cut down the communications cost by avoiding the server node bottleneck, and reformulate it as a conditional stochastic optimization problem in a serverless multi-party collaborative learning setting and propose a new ServerLess biAsed sTochastic gradiEnt (SLATE) algorithm to directly optimize the AUPRC. After that, we use the variance reduction technique and propose ServerLess biAsed sTochastic gradiEnt with Momentum-based variance reduction (SLATE-M) algorithm to improve the convergence rate, which matches the best theoretical convergence result reached by the single-machine online method. To the best of our knowledge, this is the first work to solve the multi-party collaborative AUPRC maximization problem.
</details>
<details>
<summary>摘要</summary>
多方合作训练，如分布式学习和联合学习，用于解决大数据挑战。然而，传统的多方合作训练算法主要是为了均衡数据挖掘任务而设计，并且是为了提高准确率（例如，交叉熵）。然而，在实际应用中，数据分布往往偏斜，并且基于主要类别的模型可能会受到偏见。因此，Area Under Precision-Recall Curve（AUPRC）被引入为一个有效的度量。虽然单机AUPRC最大化方法已经被设计，但多方合作算法尚未被研究。在从单机到多机设置中的变化 pose critical challenges。为解决上述挑战，我们研究了无服务器多方合作AUPRC最大化问题，并将其重新定义为无服务器多方合作学习Setting中的conditional stochastic optimization问题。然后，我们提出了一种新的ServerLess biAsed sTochastic gradiEnt（SLATE）算法，以直接优化AUPRC。接着，我们使用了减少偏差的技术，并提出了ServerLess biAsed sTochastic gradiEnt with Momentum-based variance reduction（SLATE-M）算法，以提高收敛率，并与单机在线方法的最佳理论收敛率相匹配。到目前为止，这是首次解决多方合作AUPRC最大化问题的研究。
</details></li>
</ul>
<hr>
<h2 id="Pre-Trained-Large-Language-Models-for-Industrial-Control"><a href="#Pre-Trained-Large-Language-Models-for-Industrial-Control" class="headerlink" title="Pre-Trained Large Language Models for Industrial Control"></a>Pre-Trained Large Language Models for Industrial Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03028">http://arxiv.org/abs/2308.03028</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Song, Chuheng Zhang, Li Zhao, Jiang Bian</li>
<li>For: 这个论文旨在研究使用基础模型GPT-4来控制建筑物的冷暖空调系统（HVAC）。* Methods: 作者使用了GPT-4来控制HVAC系统，并通过提供简短的描述、选择的示例和当前观察来让GPT-4执行操作。* Results: 研究发现，GPT-4可以准确地控制HVAC系统，并且能够在不同的场景下进行一致性的控制。此外，研究还发现了不同的文本背景Context对性能的影响。<details>
<summary>Abstract</summary>
For industrial control, developing high-performance controllers with few samples and low technical debt is appealing. Foundation models, possessing rich prior knowledge obtained from pre-training with Internet-scale corpus, have the potential to be a good controller with proper prompts. In this paper, we take HVAC (Heating, Ventilation, and Air Conditioning) building control as an example to examine the ability of GPT-4 (one of the first-tier foundation models) as the controller. To control HVAC, we wrap the task as a language game by providing text including a short description for the task, several selected demonstrations, and the current observation to GPT-4 on each step and execute the actions responded by GPT-4. We conduct series of experiments to answer the following questions: 1)~How well can GPT-4 control HVAC? 2)~How well can GPT-4 generalize to different scenarios for HVAC control? 3) How different parts of the text context affect the performance? In general, we found GPT-4 achieves the performance comparable to RL methods with few samples and low technical debt, indicating the potential of directly applying foundation models to industrial control tasks.
</details>
<details>
<summary>摘要</summary>
для industrial control, developing high-performance controllers with few samples and low technical debt is appealing. Foundation models, possessing rich prior knowledge obtained from pre-training with Internet-scale corpus, have the potential to be a good controller with proper prompts. In this paper, we take HVAC (Heating, Ventilation, and Air Conditioning) building control as an example to examine the ability of GPT-4 (one of the first-tier foundation models) as the controller. To control HVAC, we wrap the task as a language game by providing text including a short description for the task, several selected demonstrations, and the current observation to GPT-4 on each step and execute the actions responded by GPT-4. We conduct series of experiments to answer the following questions: 1)~How well can GPT-4 control HVAC? 2)~How well can GPT-4 generalize to different scenarios for HVAC control? 3) How different parts of the text context affect the performance? In general, we found GPT-4 achieves the performance comparable to RL methods with few samples and low technical debt, indicating the potential of directly applying foundation models to industrial control tasks.Here's a word-for-word translation of the text into Simplified Chinese:为了 industrial control, 开发高性能控制器只需几个样本和低技术债是吸引人的。基础模型，通过 Internet 规模的预训练获得了丰富的先前知识，有potential为good controller。在这篇论文中，我们选择了 HVAC（卫生、通风、空调）建筑控制作为例子，检查 GPT-4（一个首层基础模型）的控制能力。为了控制 HVAC，我们将任务包装成语言游戏，在每步提供文本描述任务、选择的示例和当前观察，并执行 GPT-4 回答的动作。我们进行了一系列实验，回答以下问题：1）GPT-4 能控制 HVAC 吗？2）GPT-4 能在不同场景下控制 HVAC 吗？3）不同文本上下文部分如何影响性能？总的来说，我们发现 GPT-4 在几个样本和低技术债的情况下可以与RL方法匹配性能，表明可以直接应用基础模型到industrial control任务。
</details></li>
</ul>
<hr>
<h2 id="Towards-Scene-Text-to-Scene-Text-Translation"><a href="#Towards-Scene-Text-to-Scene-Text-Translation" class="headerlink" title="Towards Scene-Text to Scene-Text Translation"></a>Towards Scene-Text to Scene-Text Translation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03024">http://arxiv.org/abs/2308.03024</a></li>
<li>repo_url: None</li>
<li>paper_authors: Onkar Susladkar, Prajwal Gatti, Anand Mishra</li>
<li>for: 这个研究旨在实现“视觉”翻译场景文本从源语言（例如英语）到目标语言（例如中文）。</li>
<li>methods: 我们引入了一种新的决策扩散方法，即VTNet，以Addressing several challenges in visual translation, such as interpolating font to unseen characters and preserving text size and background.</li>
<li>results: 我们通过了广泛的实验和相关方法比较，并且我们的模型超过了之前的状态态-of-the-art结果在传统的场景文本编辑benchmark中。<details>
<summary>Abstract</summary>
In this work, we study the task of ``visually" translating scene text from a source language (e.g., English) to a target language (e.g., Chinese). Visual translation involves not just the recognition and translation of scene text but also the generation of the translated image that preserves visual features of the text, such as font, size, and background. There are several challenges associated with this task, such as interpolating font to unseen characters and preserving text size and the background. To address these, we introduce VTNet, a novel conditional diffusion-based method. To train the VTNet, we create a synthetic cross-lingual dataset of 600K samples of scene text images in six popular languages, including English, Hindi, Tamil, Chinese, Bengali, and German. We evaluate the performance of VTnet through extensive experiments and comparisons to related methods. Our model also surpasses the previous state-of-the-art results on the conventional scene-text editing benchmarks. Further, we present rigorous qualitative studies to understand the strengths and shortcomings of our model. Results show that our approach generalizes well to unseen words and fonts. We firmly believe our work can benefit real-world applications, such as text translation using a phone camera and translating educational materials. Code and data will be made publicly available.
</details>
<details>
<summary>摘要</summary>
在这个研究中，我们研究了将场景文本从源语言（例如英语）翻译到目标语言（例如中文）的任务。视觉翻译不仅包括场景文本的识别和翻译，还包括生成翻译后的图像，保持文本的视觉特征，如字体、大小和背景。这个任务存在许多挑战，如 interpolating 字体到未seen 字符和保持文本大小和背景。为解决这些挑战，我们引入 VTNet，一种新的决策扩散方法。为训练 VTNet，我们创建了600,000个样本的场景文本图像 Synthetic 跨语言数据集，包括英语、捷尔文、泰米尔语、中文、孟加拉语和德语。我们通过广泛的实验和相关方法的比较来评估 VTNet 的性能。我们的模型还超过了之前的状态法则结果在场景文本编辑标准准则上。此外，我们进行了严格的Qualitative 研究，以了解我们的模型的优势和缺陷。结果表明我们的方法可以通过未看过的字符和字体进行泛化。我们认为我们的工作可以实际应用中批用，例如通过手机摄像头进行文本翻译和翻译教学材料。代码和数据将公开发布。
</details></li>
</ul>
<hr>
<h2 id="SAPIEN-Affective-Virtual-Agents-Powered-by-Large-Language-Models"><a href="#SAPIEN-Affective-Virtual-Agents-Powered-by-Large-Language-Models" class="headerlink" title="SAPIEN: Affective Virtual Agents Powered by Large Language Models"></a>SAPIEN: Affective Virtual Agents Powered by Large Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03022">http://arxiv.org/abs/2308.03022</a></li>
<li>repo_url: None</li>
<li>paper_authors: Masum Hasan, Cengiz Ozel, Sammy Potter, Ehsan Hoque</li>
<li>for: 这篇论文描述了一个基于大语言模型的虚拟代表人物平台，可以在13种语言中进行高 fidelioty的对话，并表现出情绪 through facial expressions and voice.</li>
<li>methods: 该平台使用了大语言模型驱动的虚拟代表人物，并允许用户自定义虚拟代表人物的性格、背景和对话前提，以提供丰富、沉浸的互动体验.</li>
<li>results: 该论文介绍了该平台的概述和其应用领域的可能性，从娱乐到心理健康、communication training、语言学习、教育、医疗等领域。此外，论文还考虑了这种真实的虚拟代表人物表现的伦理问题，并考虑了 Ensuring responsible use的挑战。<details>
<summary>Abstract</summary>
In this demo paper, we introduce SAPIEN, a platform for high-fidelity virtual agents driven by large language models that can hold open domain conversations with users in 13 different languages, and display emotions through facial expressions and voice. The platform allows users to customize their virtual agent's personality, background, and conversation premise, thus providing a rich, immersive interaction experience. Furthermore, after the virtual meeting, the user can choose to get the conversation analyzed and receive actionable feedback on their communication skills. This paper illustrates an overview of the platform and discusses the various application domains of this technology, ranging from entertainment to mental health, communication training, language learning, education, healthcare, and beyond. Additionally, we consider the ethical implications of such realistic virtual agent representations and the potential challenges in ensuring responsible use.
</details>
<details>
<summary>摘要</summary>
在这份演示文献中，我们介绍了SAPIEN平台，这是一个可以在13种不同语言上进行高效虚拟代表的大语言模型驱动的平台，可以为用户提供自定义虚拟代表的人格、背景和对话前提，从而提供丰富的 immerse 交互体验。此外，用户可以在虚拟会议后选择获取对话分析，并获得有用的沟通技巧反馈。本文介绍了该平台的概述和其应用领域的多样性，从娱乐到心理健康、沟通培训、语言学习、教育、医疗和更多。此外，我们还考虑了这些真实虚拟代表表现的伦理问题，并讨论了 garantizar 负责任使用的挑战。
</details></li>
</ul>
<hr>
<h2 id="Cal-SFDA-Source-Free-Domain-adaptive-Semantic-Segmentation-with-Differentiable-Expected-Calibration-Error"><a href="#Cal-SFDA-Source-Free-Domain-adaptive-Semantic-Segmentation-with-Differentiable-Expected-Calibration-Error" class="headerlink" title="Cal-SFDA: Source-Free Domain-adaptive Semantic Segmentation with Differentiable Expected Calibration Error"></a>Cal-SFDA: Source-Free Domain-adaptive Semantic Segmentation with Differentiable Expected Calibration Error</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03003">http://arxiv.org/abs/2308.03003</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jo-wang/cal-sfda">https://github.com/jo-wang/cal-sfda</a></li>
<li>paper_authors: Zixin Wang, Yadan Luo, Zhi Chen, Sen Wang, Zi Huang</li>
<li>for: 避免源数据泄露的域适应 semantic segmentation 问题</li>
<li>methods: 自然学习方法 pseudo-label 高信度区域，适应目标数据</li>
<li>results: 比前状态下提高 5.25% of mIoU，并且可以做公平的模型选择<details>
<summary>Abstract</summary>
The prevalence of domain adaptive semantic segmentation has prompted concerns regarding source domain data leakage, where private information from the source domain could inadvertently be exposed in the target domain. To circumvent the requirement for source data, source-free domain adaptation has emerged as a viable solution that leverages self-training methods to pseudo-label high-confidence regions and adapt the model to the target data. However, the confidence scores obtained are often highly biased due to over-confidence and class-imbalance issues, which render both model selection and optimization problematic. In this paper, we propose a novel calibration-guided source-free domain adaptive semantic segmentation (Cal-SFDA) framework. The core idea is to estimate the expected calibration error (ECE) from the segmentation predictions, serving as a strong indicator of the model's generalization capability to the unlabeled target domain. The estimated ECE scores, in turn, assist the model training and fair selection in both source training and target adaptation stages. During model pre-training on the source domain, we ensure the differentiability of the ECE objective by leveraging the LogSumExp trick and using ECE scores to select the best source checkpoints for adaptation. To enable ECE estimation on the target domain without requiring labels, we train a value net for ECE estimation and apply statistic warm-up on its BatchNorm layers for stability. The estimated ECE scores assist in determining the reliability of prediction and enable class-balanced pseudo-labeling by positively guiding the adaptation progress and inhibiting potential error accumulation. Extensive experiments on two widely-used synthetic-to-real transfer tasks show that the proposed approach surpasses previous state-of-the-art by up to 5.25% of mIoU with fair model selection criteria.
</details>
<details>
<summary>摘要</summary>
域际适应 semantic segmentation 的普遍使用引发了来源域数据泄露的问题，即private information从来源域可能不计划地泄露到target域。为了绕过来源数据的需求，source-free domain adaptation  emerged as a viable solution，利用 self-training 方法 Pseudo-label high-confidence regions and adapt the model to the target data。然而，获得的信任分布 часто受到过度自信和分类不均问题的影响，这 rendering both model selection and optimization problematic。在这篇论文中，我们提出了一种新的 calibration-guided source-free domain adaptive semantic segmentation (Cal-SFDA) 框架。核心思想是 estimate the expected calibration error (ECE) from the segmentation predictions, serving as a strong indicator of the model's generalization capability to the unlabeled target domain。Estimated ECE scores, in turn, assist the model training and fair selection in both source training and target adaptation stages。在模型预训练的 source domain 阶段，我们利用 LogSumExp 技巧和 ECE 分数选择最佳的来源检查点进行适应。为了在target domain 上无需标签进行 ECE 估计，我们训练了一个值网来估计 ECE 分数，并在其 BatchNorm 层上应用统计暖身。Estimated ECE scores assist in determining the reliability of prediction and enable class-balanced pseudo-labeling by positively guiding the adaptation progress and inhibiting potential error accumulation。我们在两个Synthetic-to-real transfer task上进行了广泛的实验，结果表明，我们的方法比前一个state-of-the-art 高于5.25%的mIoU，并且满足了公平的模型选择标准。
</details></li>
</ul>
<hr>
<h2 id="Spanish-Pre-trained-BERT-Model-and-Evaluation-Data"><a href="#Spanish-Pre-trained-BERT-Model-and-Evaluation-Data" class="headerlink" title="Spanish Pre-trained BERT Model and Evaluation Data"></a>Spanish Pre-trained BERT Model and Evaluation Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02976">http://arxiv.org/abs/2308.02976</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dccuchile/beto">https://github.com/dccuchile/beto</a></li>
<li>paper_authors: José Cañete, Gabriel Chaperon, Rodrigo Fuentes, Jou-Hui Ho, Hojin Kang, Jorge Pérez</li>
<li>for: 本研究的目的是提供一个基于BERT的西班牙语模型，并且将西班牙语相关任务集成一个单一的库，以便进行模型训练和评估。</li>
<li>methods: 本研究使用BERT预训概念，并将西班牙语数据集用于预训。</li>
<li>results: 经过精致调整后，我们的西班牙语模型在大多数任务中比其他基于BERT的多语言模型优化，甚至在一些任务中创下新的最佳纪录。<details>
<summary>Abstract</summary>
The Spanish language is one of the top 5 spoken languages in the world. Nevertheless, finding resources to train or evaluate Spanish language models is not an easy task. In this paper we help bridge this gap by presenting a BERT-based language model pre-trained exclusively on Spanish data. As a second contribution, we also compiled several tasks specifically for the Spanish language in a single repository much in the spirit of the GLUE benchmark. By fine-tuning our pre-trained Spanish model, we obtain better results compared to other BERT-based models pre-trained on multilingual corpora for most of the tasks, even achieving a new state-of-the-art on some of them. We have publicly released our model, the pre-training data, and the compilation of the Spanish benchmarks.
</details>
<details>
<summary>摘要</summary>
西班牙语是全球前5种最广泛使用的语言之一，然而找到用于训练或评估西班牙语模型的资源并不是一件容易的事情。在这篇论文中，我们帮助填补这一差距，并提供了基于BERT的西班牙语模型，该模型在西班牙语数据上进行了专门预训练。此外，我们还编译了一些特定于西班牙语的任务，并将其集成到了GLUE数据集的同类型的单一存储中。经过我们的西班牙语模型的微调，我们在大多数任务上Obtained better results than other BERT-based models pre-trained on multilingual corpora，甚至在一些任务上创造了新的状态反应。我们已经公开发布了我们的模型、预训练数据和西班牙语benchmark集。
</details></li>
</ul>
<hr>
<h2 id="Understanding-User-Intent-Modeling-for-Conversational-Recommender-Systems-A-Systematic-Literature-Review"><a href="#Understanding-User-Intent-Modeling-for-Conversational-Recommender-Systems-A-Systematic-Literature-Review" class="headerlink" title="Understanding User Intent Modeling for Conversational Recommender Systems: A Systematic Literature Review"></a>Understanding User Intent Modeling for Conversational Recommender Systems: A Systematic Literature Review</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.08496">http://arxiv.org/abs/2308.08496</a></li>
<li>repo_url: None</li>
<li>paper_authors: Siamak Farshidi, Kiyan Rezaee, Sara Mazaheri, Amir Hossein Rahimi, Ali Dadashzadeh, Morteza Ziabakhsh, Sadegh Eskandari, Slinger Jansen</li>
<li>for: 本研究旨在帮助研究者选择适合其系统的用户意图模型，以提高对话推荐系统的个性化响应。</li>
<li>methods: 我们通过系统性的文献综述方法收集了对话推荐系统中通常使用的模型，并基于这些数据开发了一个决策模型。我们还完成了两个案例研究来评估我们提议的决策模型的效果。</li>
<li>results: 我们的研究分析了59种不同的模型和74种通常使用的特征，提供了对用户意图模型的实际应用和评估的深入理解。我们还发现了一些模型组合的潜在优势、趋势、评价标准和常用的训练和评估数据集。<details>
<summary>Abstract</summary>
Context: User intent modeling is a crucial process in Natural Language Processing that aims to identify the underlying purpose behind a user's request, enabling personalized responses. With a vast array of approaches introduced in the literature (over 13,000 papers in the last decade), understanding the related concepts and commonly used models in AI-based systems is essential. Method: We conducted a systematic literature review to gather data on models typically employed in designing conversational recommender systems. From the collected data, we developed a decision model to assist researchers in selecting the most suitable models for their systems. Additionally, we performed two case studies to evaluate the effectiveness of our proposed decision model. Results: Our study analyzed 59 distinct models and identified 74 commonly used features. We provided insights into potential model combinations, trends in model selection, quality concerns, evaluation measures, and frequently used datasets for training and evaluating these models. Contribution: Our study contributes practical insights and a comprehensive understanding of user intent modeling, empowering the development of more effective and personalized conversational recommender systems. With the Conversational Recommender System, researchers can perform a more systematic and efficient assessment of fitting intent modeling frameworks.
</details>
<details>
<summary>摘要</summary>
Context: 用户意图模型化是自然语言处理领域的关键过程，旨在识别用户请求的含义，以提供个性化回答。随着文献中所提出的多种方法的激增（过去一个十年内有超过13,000篇论文），了解相关的概念和在人工智能系统中常用的模型是非常重要。方法：我们进行了系统性的文献综述，以收集用于设计对话推荐系统的模型的数据。从收集到的数据中，我们开发了一个决策模型，以 помо助研究人员选择最适合他们系统的模型。此外，我们进行了两个实验，以评估我们的提议的决策模型的有效性。结果：我们的研究分析了59种不同的模型，并发现了74种通常使用的特征。我们提供了模型组合的可能性、模型选择趋势、质量问题、评价标准和用于训练和评估这些模型的常用数据集。贡献：我们的研究提供了实用的准确和对话推荐系统的全面理解，推动了更有效和个性化的对话推荐系统的开发。通过对话推荐系统，研究人员可以更系统和有效地评估适用的意图模型框架。
</details></li>
</ul>
<hr>
<h2 id="Science-and-engineering-for-what-A-large-scale-analysis-of-students’-projects-in-science-fairs"><a href="#Science-and-engineering-for-what-A-large-scale-analysis-of-students’-projects-in-science-fairs" class="headerlink" title="Science and engineering for what? A large-scale analysis of students’ projects in science fairs"></a>Science and engineering for what? A large-scale analysis of students’ projects in science fairs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02962">http://arxiv.org/abs/2308.02962</a></li>
<li>repo_url: None</li>
<li>paper_authors: Adelmo Eloy, Thomas Palmeira Ferraz, Fellip Silva Alves, Roseli de Deus Lopes</li>
<li>for: The paper is written to analyze the themes and topics that have driven students’ inquiry and design in science fair projects over the past 20 years in Brazil.</li>
<li>methods: The paper uses topic modeling to identify the main topics being explored in the projects, and to examine variations over time, region, and school setting.</li>
<li>results: The analysis found a broad range of topics being explored, with significant variations over time, region, and school setting, and the authors argue that the results and proposed methodology can support further research and inform instruction and resource design for open inquiry experiences in different settings.Here are the three points in Simplified Chinese text:</li>
<li>for: 这个论文是为了分析过去20年在巴西的科学展上学生的探索和设计主题。</li>
<li>methods: 这篇论文使用主题分析来确定学生的探索和设计主题，并分析时间、地区和学校背景的变化。</li>
<li>results: 分析发现了各种主题的探索，时间、地区和学校背景中存在显著的变化，作者认为这些结果和提出的方法可以支持更多的研究，并且用于不同设置的 instrucion 和资源设计。<details>
<summary>Abstract</summary>
Science and Engineering fairs offer K-12 students opportunities to engage with authentic STEM practices. Particularly, students are given the chance to experience authentic and open inquiry processes, by defining which themes, questions and approaches will guide their scientific endeavors. In this study, we analyzed data from over 5,000 projects presented at a nationwide science fair in Brazil over the past 20 years using topic modeling to identify the main topics that have driven students' inquiry and design. Our analysis identified a broad range of topics being explored, with significant variations over time, region, and school setting. We argue those results and proposed methodology can not only support further research in the context of science fairs, but also inform instruction and design of contexts-specific resources to support students in open inquiry experiences in different settings.
</details>
<details>
<summary>摘要</summary>
科学和工程博览会为小学到高中学生提供了实践科学技术的机会。特别是，学生有机会经历真正的开放探索过程，确定他们的科学做业的主题、问题和方法。在这项研究中，我们使用主题分析对 brasil 国内过去 20 年的全国科学博览会上的项目数据进行分析，并确定了学生的探索主题的主要趋势。我们的分析发现了广泛的主题被探索，并且在时间、地区和学校背景中有显著的变化。我们认为这些结果和方法可以不仅支持后续在科学博览会上的研究，还可以 Inform 不同设置中的 instrucion 和资源设计，以支持学生在开放探索经历中。
</details></li>
</ul>
<hr>
<h2 id="Data-Fusion-for-Multi-Task-Learning-of-Building-Extraction-and-Height-Estimation"><a href="#Data-Fusion-for-Multi-Task-Learning-of-Building-Extraction-and-Height-Estimation" class="headerlink" title="Data Fusion for Multi-Task Learning of Building Extraction and Height Estimation"></a>Data Fusion for Multi-Task Learning of Building Extraction and Height Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02960">http://arxiv.org/abs/2308.02960</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/SaadAhmedJamal/IEEE_DFC2023">https://github.com/SaadAhmedJamal/IEEE_DFC2023</a></li>
<li>paper_authors: Saad Ahmed Jamal, Arioluwa Aribisala</li>
<li>for: 这个论文是针对都市重建问题进行的一种多任务学习方法，利用光学和雷达卫星图像进行建筑物提取和高度估算。</li>
<li>methods: 这个论文使用多任务学习方法，将建筑物提取和高度估算作为两个独立的任务进行实现，并在这两个任务之间设置约束。</li>
<li>results: 根据设计实验结果，论文的基准结果在建筑物提取和高度估算方面得到了显著提高。<details>
<summary>Abstract</summary>
In accordance with the urban reconstruction problem proposed by the DFC23 Track 2 Contest, this paper attempts a multitask-learning method of building extraction and height estimation using both optical and radar satellite imagery. Contrary to the initial goal of multitask learning which could potentially give a superior solution by reusing features and forming implicit constraints between multiple tasks, this paper reports the individual implementation of the building extraction and height estimation under constraints. The baseline results for the building extraction and the height estimation significantly increased after designed experiments.
</details>
<details>
<summary>摘要</summary>
根据DFC23 Track 2 Contest提出的城市重建问题，本文提出了一种多任务学习方法，通过光学和雷达卫星图像进行建筑物提取和高度估计。与初始目标的多任务学习不同，本文报告了每个任务的单独实现，而不是 reuse features和形成多任务之间的含义约束。经过设计实验，基准结果显著提高。
</details></li>
</ul>
<hr>
<h2 id="A-criterion-for-Artificial-General-Intelligence-hypothetic-deductive-reasoning-tested-on-ChatGPT"><a href="#A-criterion-for-Artificial-General-Intelligence-hypothetic-deductive-reasoning-tested-on-ChatGPT" class="headerlink" title="A criterion for Artificial General Intelligence: hypothetic-deductive reasoning, tested on ChatGPT"></a>A criterion for Artificial General Intelligence: hypothetic-deductive reasoning, tested on ChatGPT</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02950">http://arxiv.org/abs/2308.02950</a></li>
<li>repo_url: None</li>
<li>paper_authors: Louis Vervoort, Vitaliy Mizyakov, Anastasia Ugleva</li>
<li>for: 这篇论文探讨了一种逻辑能力，即假设推理能力，是否能让AI达到人类智能水平。</li>
<li>methods: 作者提出了一些简单的测试方法来评估AI的假设推理能力，并应用到了ChatGPT上。</li>
<li>results: 研究发现，目前ChatGPT在较复杂的问题上的假设推理能力有限，但如果AI可以在多种情况下表现出这种逻辑能力，那么它就可以被视为人类智能水平。<details>
<summary>Abstract</summary>
We argue that a key reasoning skill that any advanced AI, say GPT-4, should master in order to qualify as 'thinking machine', or AGI, is hypothetic-deductive reasoning. Problem-solving or question-answering can quite generally be construed as involving two steps: hypothesizing that a certain set of hypotheses T applies to the problem or question at hand, and deducing the solution or answer from T - hence the term hypothetic-deductive reasoning. An elementary proxy of hypothetic-deductive reasoning is causal reasoning. We propose simple tests for both types of reasoning, and apply them to ChatGPT. Our study shows that, at present, the chatbot has a limited capacity for either type of reasoning, as soon as the problems considered are somewhat complex. However, we submit that if an AI would be capable of this type of reasoning in a sufficiently wide range of contexts, it would be an AGI.
</details>
<details>
<summary>摘要</summary>
我们认为，任何高级AI，如GPT-4，以“思考机器”或AGI的标准，应具备推理能力。我们认为，这种推理能力应包括假设推理。问题解释或问题回答通常可以分为两步：首先假设一个假设集T适用于问题或问题，然后从T中推理出解释或答案。因此，我们称这种推理为假设推理。我们提出了两种这种推理的简单测验，并将其应用到ChatGPT。我们的研究表明，现在，这个 chatbot 仅有限的能力进行这些类型的推理，只有在问题变得相当复杂时。但我们认为，如果AI能够在充分广泛的上下文中进行这种推理，则它将是一个AGI。
</details></li>
</ul>
<hr>
<h2 id="dPASP-A-Comprehensive-Differentiable-Probabilistic-Answer-Set-Programming-Environment-For-Neurosymbolic-Learning-and-Reasoning"><a href="#dPASP-A-Comprehensive-Differentiable-Probabilistic-Answer-Set-Programming-Environment-For-Neurosymbolic-Learning-and-Reasoning" class="headerlink" title="dPASP: A Comprehensive Differentiable Probabilistic Answer Set Programming Environment For Neurosymbolic Learning and Reasoning"></a>dPASP: A Comprehensive Differentiable Probabilistic Answer Set Programming Environment For Neurosymbolic Learning and Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02944">http://arxiv.org/abs/2308.02944</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renato Lui Geh, Jonas Gonçalves, Igor Cataneo Silveira, Denis Deratani Mauá, Fabio Gagliardi Cozman</li>
<li>for: This paper proposes a new framework called dPASP for differentiable neuro-symbolic reasoning, which allows for the combination of discrete probabilistic models, neural predicates, logic constraints, and interval-valued probabilistic choices.</li>
<li>methods: The paper discusses several semantics for probabilistic logic programs that can express nondeterministic, contradictory, incomplete, and&#x2F;or statistical knowledge, and how gradient-based learning can be performed with neural predicates and probabilistic choices under these semantics.</li>
<li>results: The paper describes an implemented package that supports inference and learning in the language, along with several example programs, and demonstrates that the package allows for end-to-end training of rather sophisticated models and loss functions with minimal user knowledge of deep learning system’s inner workings.<details>
<summary>Abstract</summary>
We present dPASP, a novel declarative probabilistic logic programming framework for differentiable neuro-symbolic reasoning. The framework allows for the specification of discrete probabilistic models with neural predicates, logic constraints and interval-valued probabilistic choices, thus supporting models that combine low-level perception (images, texts, etc), common-sense reasoning, and (vague) statistical knowledge. To support all such features, we discuss the several semantics for probabilistic logic programs that can express nondeterministic, contradictory, incomplete and/or statistical knowledge. We also discuss how gradient-based learning can be performed with neural predicates and probabilistic choices under selected semantics. We then describe an implemented package that supports inference and learning in the language, along with several example programs. The package requires minimal user knowledge of deep learning system's inner workings, while allowing end-to-end training of rather sophisticated models and loss functions.
</details>
<details>
<summary>摘要</summary>
我们介绍了dPASP，一种新的宣告型概率逻辑编程框架，用于不同槽的神经符号逻辑推理。该框架允许指定混合低水平感知（图像、文本等）、通用理智、抽象统计知识的概率模型。为支持这些特性，我们讨论了概率逻辑程序的多种 semantics，包括不确定、矛盾、不完整和统计知识。我们还讨论了如何在选定 semantics 下使用神经 predicate 和概率选择来进行梯度基本学习。然后，我们描述了实现的包，包括推理和学习语言的实现，以及一些示例程序。该包需要最小化用户对深度学习系统内部办公的知识，同时允许执行比较复杂的模型和损失函数的整体训练。
</details></li>
</ul>
<hr>
<h2 id="Dark-Skin-Individuals-Are-at-More-Risk-on-the-Street-Unmasking-Fairness-Issues-of-Autonomous-Driving-Systems"><a href="#Dark-Skin-Individuals-Are-at-More-Risk-on-the-Street-Unmasking-Fairness-Issues-of-Autonomous-Driving-Systems" class="headerlink" title="Dark-Skin Individuals Are at More Risk on the Street: Unmasking Fairness Issues of Autonomous Driving Systems"></a>Dark-Skin Individuals Are at More Risk on the Street: Unmasking Fairness Issues of Autonomous Driving Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02935">http://arxiv.org/abs/2308.02935</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinyue Li, Zhenpeng Chen, Jie M. Zhang, Federica Sarro, Ying Zhang, Xuanzhe Liu<br>for: 本研究检测了自动驾驶系统中人工步行检测器的公平性问题，这是一个尚未得到充分研究的问题。methods: 我们用了8种广泛研究的人工步行检测器进行公平性测试，并对大规模的实际世界数据集进行了大规模的批处理和标注。我们为数据集提供了广泛的标注，包括16,070个性别标签、20,115个年龄标签和3,513个皮肤颜色标签。results: 我们的发现表明，年龄和皮肤颜色存在显著的公平问题。对于成年人和儿童，检测精度差异为19.67%，而对于轻皮和暗皮人，检测精度差异为7.52%。而gender只有1.1%的差异。此外，我们发现在文献中常见的自动驾驶测试场景下，对暗皮人的偏见明显增加。我们将代码、数据和结果公开发布，以便未来关于公平性在自动驾驶领域的研究。<details>
<summary>Abstract</summary>
This paper conducts fairness testing on automated pedestrian detection, a crucial but under-explored issue in autonomous driving systems. We evaluate eight widely-studied pedestrian detectors across demographic groups on large-scale real-world datasets. To enable thorough fairness testing, we provide extensive annotations for the datasets, resulting in 8,311 images with 16,070 gender labels, 20,115 age labels, and 3,513 skin tone labels. Our findings reveal significant fairness issues related to age and skin tone. The detection accuracy for adults is 19.67% higher compared to children, and there is a 7.52% accuracy disparity between light-skin and dark-skin individuals. Gender, however, shows only a 1.1% difference in detection accuracy. Additionally, we investigate common scenarios explored in the literature on autonomous driving testing, and find that the bias towards dark-skin pedestrians increases significantly under scenarios of low contrast and low brightness. We publicly release the code, data, and results to support future research on fairness in autonomous driving.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "crucial" is translated as "重要的" (zhòng yào de), which means "very important" or "crucial"* "under-explored" is translated as "未探索的" (wèi tàn gōu de), which means "under-explored" or "unexplored"* "demographic groups" is translated as "人口群体" (rén kǒu qún tǐ), which means "demographic groups" or "population groups"* "gender" is translated as "性别" (xìng bèi), which means "gender"* "skin tone" is translated as "皮肤色" (pí fù sè), which means "skin tone"* "dark-skin" is translated as "黑皮肤" (hēi pí fù), which means "dark-skin"* "low contrast" is translated as "低对比度" (dī yǎo duì bǐ dù), which means "low contrast"* "low brightness" is translated as "低亮度" (dī liàng dù), which means "low brightness"* "scenarios" is translated as "场景" (chǎng jǐng), which means "scenarios" or "settings"* "bias" is translated as "偏见" (piān jiàn), which means "bias" or "prejudice"
</details></li>
</ul>
<hr>
<h2 id="ConvFormer-Revisiting-Transformer-for-Sequential-User-Modeling"><a href="#ConvFormer-Revisiting-Transformer-for-Sequential-User-Modeling" class="headerlink" title="ConvFormer: Revisiting Transformer for Sequential User Modeling"></a>ConvFormer: Revisiting Transformer for Sequential User Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02925">http://arxiv.org/abs/2308.02925</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hao Wang, Jianxun Lian, Mingqi Wu, Haoxuan Li, Jiajun Fan, Wanyue Xu, Chaozhuo Li, Xing Xie</li>
<li>for: 这篇论文的目的是提高个性化推荐系统中的序列用户模型，以更好地理解用户行为序列。</li>
<li>methods: 该论文使用了改进的Transformer结构，探讨了 item-to-item 机制在序列用户模型中的效果，并从实验分析中提出了三个关键指南。</li>
<li>results: 实验结果表明，该模型在四个公共数据集上实现了state-of-the-art的结果，并证实了提出的三个指南的有用性。<details>
<summary>Abstract</summary>
Sequential user modeling, a critical task in personalized recommender systems, focuses on predicting the next item a user would prefer, requiring a deep understanding of user behavior sequences. Despite the remarkable success of Transformer-based models across various domains, their full potential in comprehending user behavior remains untapped. In this paper, we re-examine Transformer-like architectures aiming to advance state-of-the-art performance. We start by revisiting the core building blocks of Transformer-based methods, analyzing the effectiveness of the item-to-item mechanism within the context of sequential user modeling. After conducting a thorough experimental analysis, we identify three essential criteria for devising efficient sequential user models, which we hope will serve as practical guidelines to inspire and shape future designs. Following this, we introduce ConvFormer, a simple but powerful modification to the Transformer architecture that meets these criteria, yielding state-of-the-art results. Additionally, we present an acceleration technique to minimize the complexity associated with processing extremely long sequences. Experiments on four public datasets showcase ConvFormer's superiority and confirm the validity of our proposed criteria.
</details>
<details>
<summary>摘要</summary>
纵向用户模型化，个人化推荐系统中的关键任务，旨在预测用户下一个 preference 的 item，需要深刻了解用户行为序列。尽管转换器基本模型在不同领域取得了很大成功，但它们在理解用户行为方面的潜在能力还未得到充分利用。本文重新评估转换器类型的架构，以提高个人化推荐系统的性能。我们从转换器基本建构块开始，分析 item-to-item 机制在用户行为序列中的效果。经过广泛的实验分析，我们确定了三个关键标准 для设计高效的纵向用户模型，希望这些标准能够作为实践指南，激发和改进未来的设计。接着，我们介绍 ConvFormer，一种简单 yet 强大的修改，满足这些标准，并实现了状态之最好的结果。此外，我们还提出了加速技术，以降低处理极长序列的复杂性。经过四个公共数据集的实验，ConvFormer 的优势和我们提出的标准的有效性得到了证明。
</details></li>
</ul>
<hr>
<h2 id="Adversarial-Erasing-with-Pruned-Elements-Towards-Better-Graph-Lottery-Ticket"><a href="#Adversarial-Erasing-with-Pruned-Elements-Towards-Better-Graph-Lottery-Ticket" class="headerlink" title="Adversarial Erasing with Pruned Elements: Towards Better Graph Lottery Ticket"></a>Adversarial Erasing with Pruned Elements: Towards Better Graph Lottery Ticket</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02916">http://arxiv.org/abs/2308.02916</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangyuwen0627/ace-glt">https://github.com/wangyuwen0627/ace-glt</a></li>
<li>paper_authors: Yuwen Wang, Shunyu Liu, Kaixuan Chen, Tongtian Zhu, Ji Qiao, Mengjie Shi, Yuanyu Wan, Mingli Song</li>
<li>for: 提高大输入图的深度图神经网络计算成本，并保持原始性能。</li>
<li>methods: 提出了一种新的敌对补做法（ACE），通过在剪枝过程中挖掘价值信息，提高GLT的性能。</li>
<li>results: 实验结果显示，我们的ACE-GLT在多种任务中表现出色，超过了现有方法。<details>
<summary>Abstract</summary>
Graph Lottery Ticket (GLT), a combination of core subgraph and sparse subnetwork, has been proposed to mitigate the computational cost of deep Graph Neural Networks (GNNs) on large input graphs while preserving original performance. However, the winning GLTs in exisiting studies are obtained by applying iterative magnitude-based pruning (IMP) without re-evaluating and re-considering the pruned information, which disregards the dynamic changes in the significance of edges/weights during graph/model structure pruning, and thus limits the appeal of the winning tickets. In this paper, we formulate a conjecture, i.e., existing overlooked valuable information in the pruned graph connections and model parameters which can be re-grouped into GLT to enhance the final performance. Specifically, we propose an adversarial complementary erasing (ACE) framework to explore the valuable information from the pruned components, thereby developing a more powerful GLT, referred to as the ACE-GLT. The main idea is to mine valuable information from pruned edges/weights after each round of IMP, and employ the ACE technique to refine the GLT processing. Finally, experimental results demonstrate that our ACE-GLT outperforms existing methods for searching GLT in diverse tasks. Our code will be made publicly available.
</details>
<details>
<summary>摘要</summary>
Graph Lottery Ticket (GLT), 一种组合核心子图和稀疏子网络的方法，被提出以减少深度图神经网络（GNNs）中输入图的计算成本而保持原始性能。然而，现有的赢家GLT在存在的研究中通常通过不重新评估和重新考虑被剪除的信息来获得赢家票，这会忽略图/模型结构剪除过程中边/权重的动态变化，从而限制赢家票的吸引力。在这篇论文中，我们提出一个 conjecture，即现有的忽略了有价值信息的剪除graph连接和模型参数，可以重新组织成GLT，以提高最终性能。具体来说，我们提出一种对抗补偿抹除（ACE）框架，以探索剪除后的有价值信息，并使用ACE技术来练化GLT处理。最后，我们通过实验结果发现，我们的ACE-GLT在多种任务中超过了现有的搜索GLT方法。我们将代码公开发布。
</details></li>
</ul>
<hr>
<h2 id="Anonymizing-Speech-Evaluating-and-Designing-Speaker-Anonymization-Techniques"><a href="#Anonymizing-Speech-Evaluating-and-Designing-Speaker-Anonymization-Techniques" class="headerlink" title="Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques"></a>Anonymizing Speech: Evaluating and Designing Speaker Anonymization Techniques</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04455">http://arxiv.org/abs/2308.04455</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/deep-privacy/SA-toolkit">https://github.com/deep-privacy/SA-toolkit</a></li>
<li>paper_authors: Pierre Champion</li>
<li>for: 防止语音数据隐私泄露</li>
<li>methods: 使用量化变换提高匿名化精度，并对各组件进行独立评估</li>
<li>results: 提出新的匿名化方法，并对现有系统进行攻击和破解分析<details>
<summary>Abstract</summary>
The growing use of voice user interfaces has led to a surge in the collection and storage of speech data. While data collection allows for the development of efficient tools powering most speech services, it also poses serious privacy issues for users as centralized storage makes private personal speech data vulnerable to cyber threats. With the increasing use of voice-based digital assistants like Amazon's Alexa, Google's Home, and Apple's Siri, and with the increasing ease with which personal speech data can be collected, the risk of malicious use of voice-cloning and speaker/gender/pathological/etc. recognition has increased.   This thesis proposes solutions for anonymizing speech and evaluating the degree of the anonymization. In this work, anonymization refers to making personal speech data unlinkable to an identity while maintaining the usefulness (utility) of the speech signal (e.g., access to linguistic content). We start by identifying several challenges that evaluation protocols need to consider to evaluate the degree of privacy protection properly. We clarify how anonymization systems must be configured for evaluation purposes and highlight that many practical deployment configurations do not permit privacy evaluation. Furthermore, we study and examine the most common voice conversion-based anonymization system and identify its weak points before suggesting new methods to overcome some limitations. We isolate all components of the anonymization system to evaluate the degree of speaker PPI associated with each of them. Then, we propose several transformation methods for each component to reduce as much as possible speaker PPI while maintaining utility. We promote anonymization algorithms based on quantization-based transformation as an alternative to the most-used and well-known noise-based approach. Finally, we endeavor a new attack method to invert anonymization.
</details>
<details>
<summary>摘要</summary>
随着声控交互的使用增加，声音数据的收集和存储也逐渐增加。然而，这也会产生一些隐私问题，因为中央存储的私人声音数据容易受到网络攻击。随着声音基于的数字助手 like Alexa、Home 和 Siri 的使用的加剧，以及声音数据的采集变得更加容易，黑客利用声音恶意识别和 speaker/性别/疾病等识别的风险也在增加。这个论文提出了一些解决隐私问题的方法，包括声音anonimization和评估隐私保护度的方法。在这个工作中，anonimization指的是让个人声音数据与身份分离开来，而不是完全隐藏声音内容。我们开始 by 认识评估协议中需要考虑的一些挑战，并且 clarify 如何配置anonimization系统以便评估。我们还发现了许多实际部署配置不允许隐私评估。此外，我们还研究了最常用的声音转换基于的隐私保护系统的弱点，并提出了一些新的方法来解决一些限制。我们将声音隐私系统中的每个组件分解出来，并评估它们中 speaker PPI 的水平。然后，我们提出了一些变换方法来减少 speaker PPI，同时保持用户体验。我们推荐使用量化变换算法，而不是传统的噪声基本方法。最后，我们提出了一种新的攻击方法，以尝试破坏隐私保护。
</details></li>
</ul>
<hr>
<h2 id="Anomaly-Detection-in-Global-Financial-Markets-with-Graph-Neural-Networks-and-Nonextensive-Entropy"><a href="#Anomaly-Detection-in-Global-Financial-Markets-with-Graph-Neural-Networks-and-Nonextensive-Entropy" class="headerlink" title="Anomaly Detection in Global Financial Markets with Graph Neural Networks and Nonextensive Entropy"></a>Anomaly Detection in Global Financial Markets with Graph Neural Networks and Nonextensive Entropy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02914">http://arxiv.org/abs/2308.02914</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kleyton da Costa</li>
<li>for: 本研究探讨了在全球金融市场中检测异常现象的能力，特别是在多变量系统中。</li>
<li>methods: 本研究使用图神经网络（GNN）来检测异常现象，并考虑了不确定性enarioMeasured by nonextensive entropy。</li>
<li>results: 主要发现结果表明，在危机时期，高度相关的资产结构下降，并且在不同的nonextensive entropy参数下，异常数量 statistically different。<details>
<summary>Abstract</summary>
Anomaly detection is a challenging task, particularly in systems with many variables. Anomalies are outliers that statistically differ from the analyzed data and can arise from rare events, malfunctions, or system misuse. This study investigated the ability to detect anomalies in global financial markets through Graph Neural Networks (GNN) considering an uncertainty scenario measured by a nonextensive entropy. The main findings show that the complex structure of highly correlated assets decreases in a crisis, and the number of anomalies is statistically different for nonextensive entropy parameters considering before, during, and after crisis.
</details>
<details>
<summary>摘要</summary>
<<SYS>>传统的异常检测任务是非常具有挑战性，尤其在系统中存在多个变量时。异常是数据中的异常值，可能由罕见事件、设备故障或系统滥用引起。本研究通过图神经网络（GNN）检测了全球金融市场中的异常现象，并考虑了不确定性enario中的 nonextensive entropy。主要发现结果表明，危机时期的复杂资产结构下降，并且 nonextensive entropy参数中的异常数量在危机前、 durante 和危机后期 Statistically different。Note: "nonextensive entropy" is translated as "不确定性enario" in Simplified Chinese, which is a combination of "不确定" (uncertain) and "scenario" (a hypothetical or imaginary situation).
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/06/cs.AI_2023_08_06/" data-id="clp89do80001ti788fwjj22ea" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_08_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/06/cs.CL_2023_08_06/" class="article-date">
  <time datetime="2023-08-06T11:00:00.000Z" itemprop="datePublished">2023-08-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/06/cs.CL_2023_08_06/">cs.CL - 2023-08-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Food-500-Cap-A-Fine-Grained-Food-Caption-Benchmark-for-Evaluating-Vision-Language-Models"><a href="#Food-500-Cap-A-Fine-Grained-Food-Caption-Benchmark-for-Evaluating-Vision-Language-Models" class="headerlink" title="Food-500 Cap: A Fine-Grained Food Caption Benchmark for Evaluating Vision-Language Models"></a>Food-500 Cap: A Fine-Grained Food Caption Benchmark for Evaluating Vision-Language Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03151">http://arxiv.org/abs/2308.03151</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/aaronma2020/Food500-Cap">https://github.com/aaronma2020/Food500-Cap</a></li>
<li>paper_authors: Zheng Ma, Mianzhi Pan, Wenhan Wu, Kanzhi Cheng, Jianbing Zhang, Shujian Huang, Jiajun Chen</li>
<li>for: 这篇论文旨在探讨 популяр的视觉语言模型（VLM）在特定领域中的能力。</li>
<li>methods: 该论文使用了多种探测方法，包括零 shot 设定下的评估方法，以检测 VLM 的局限性。</li>
<li>results: 实验结果显示，Popular VLM 在食品领域下表现较差，而且对不同地区的食品 Item 的处理能力具有偏见。<details>
<summary>Abstract</summary>
Vision-language models (VLMs) have shown impressive performance in substantial downstream multi-modal tasks. However, only comparing the fine-tuned performance on downstream tasks leads to the poor interpretability of VLMs, which is adverse to their future improvement. Several prior works have identified this issue and used various probing methods under a zero-shot setting to detect VLMs' limitations, but they all examine VLMs using general datasets instead of specialized ones. In practical applications, VLMs are usually applied to specific scenarios, such as e-commerce and news fields, so the generalization of VLMs in specific domains should be given more attention. In this paper, we comprehensively investigate the capabilities of popular VLMs in a specific field, the food domain. To this end, we build a food caption dataset, Food-500 Cap, which contains 24,700 food images with 494 categories. Each image is accompanied by a detailed caption, including fine-grained attributes of food, such as the ingredient, shape, and color. We also provide a culinary culture taxonomy that classifies each food category based on its geographic origin in order to better analyze the performance differences of VLM in different regions. Experiments on our proposed datasets demonstrate that popular VLMs underperform in the food domain compared with their performance in the general domain. Furthermore, our research reveals severe bias in VLMs' ability to handle food items from different geographic regions. We adopt diverse probing methods and evaluate nine VLMs belonging to different architectures to verify the aforementioned observations. We hope that our study will bring researchers' attention to VLM's limitations when applying them to the domain of food or culinary cultures, and spur further investigations to address this issue.
</details>
<details>
<summary>摘要</summary>
视力语模型（VLM）在多Modal任务中表现出色，但只是对下游任务的细致 fine-tuning 可能导致 VLM 的解释性差，这对其未来改进带来障碍。一些先前的研究已经发现这个问题，并使用了不同的探测方法来检测 VLM 的局限性，但这些研究都使用了通用的数据集而不是专门的数据集。在实际应用中，VLM 通常被应用于特定场景，如电商和新闻领域，因此 VLM 在特定领域的泛化性应该得更多的注意。在这篇论文中，我们广泛探讨了流行的 VLM 在食品领域的能力。为此，我们建立了一个食品描述集合，即 Food-500 Cap，该集合包含 24,700 个食品图像，其中每个图像都有 494 个类别。每个图像都有详细的描述，包括食品的成分、形状和颜色。我们还提供了一个culinary culture taxonomy，该税onomy分类每个食品类别基于其地理起源，以便更好地分析 VLM 在不同地区的表现差异。我们对我们提posed的数据集进行实验，发现流行的 VLM 在食品领域的表现落后于其在通用领域的表现。此外，我们的研究发现 VLM 对不同地区的食品项目存在严重的偏见。我们采用了多种探测方法，并评估了九种不同架构的 VLM，以确认以上观察。我们希望通过这种研究，引起研究者对 VLM 在食品或culinary cultures领域的应用中的局限性的注意，并促进进一步的调查以解决这一问题。
</details></li>
</ul>
<hr>
<h2 id="Towards-Multiple-References-Era-–-Addressing-Data-Leakage-and-Limited-Reference-Diversity-in-NLG-Evaluation"><a href="#Towards-Multiple-References-Era-–-Addressing-Data-Leakage-and-Limited-Reference-Diversity-in-NLG-Evaluation" class="headerlink" title="Towards Multiple References Era – Addressing Data Leakage and Limited Reference Diversity in NLG Evaluation"></a>Towards Multiple References Era – Addressing Data Leakage and Limited Reference Diversity in NLG Evaluation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03131">http://arxiv.org/abs/2308.03131</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sefazeng/llm-ref">https://github.com/sefazeng/llm-ref</a></li>
<li>paper_authors: Xianfeng Zeng, Yijin Liu, Fandong Meng, Jie Zhou</li>
<li>for: 提高 matching-based 评估 metric 和人类评估的相关性, 特别是对比 neural-based metric 如 BLEURT.</li>
<li>methods: 使用多个参考文本来增强 matching-based metric 的一致性。</li>
<li>results: 在 WMT Metrics benchmark 中，多参考 F200spBLEU 与单参考 F200spBLEU 之间的准确率提高为 7.2%，并且超过 neural-based BERTscore 的准确率提高为 3.9%。此外，我们发现 LLM 中的数据泄露问题可以通过我们的多参考 metric 减少到一定程度。<details>
<summary>Abstract</summary>
N-gram matching-based evaluation metrics, such as BLEU and chrF, are widely utilized across a range of natural language generation (NLG) tasks. However, recent studies have revealed a weak correlation between these matching-based metrics and human evaluations, especially when compared with neural-based metrics like BLEURT. In this paper, we conjecture that the performance bottleneck in matching-based metrics may be caused by the limited diversity of references. To address this issue, we propose to utilize \textit{multiple references} to enhance the consistency between these metrics and human evaluations. Within the WMT Metrics benchmarks, we observe that the multi-references F200spBLEU surpasses the conventional single-reference one by an accuracy improvement of 7.2\%. Remarkably, it also exceeds the neural-based BERTscore by an accuracy enhancement of 3.9\%. Moreover, we observe that the data leakage issue in large language models (LLMs) can be mitigated to a large extent by our multi-reference metric. We release the code and data at \url{https://github.com/SefaZeng/LLM-Ref}
</details>
<details>
<summary>摘要</summary>
对于自然语言生成（NLG）任务，N-gram匹配基于评估度量，如BLEU和chrF，在广泛应用。然而，最近的研究表明，这些匹配基于度量与人工评估之间的相关性较弱，特别是与神经网络基于度量 like BLEURT 相比。在这篇论文中，我们 conjecture 这种性能瓶颈可能是因为参考文本的多样性有限。为了解决这个问题，我们提议使用多个参考文本来提高这些度量与人工评估之间的一致性。在 WMT Metrics benchmark 中，我们发现使用多个参考文本的 F200spBLEU 的精度提高了7.2%，而且还超过了基于神经网络的 BERTscore 的精度提高3.9%。此外，我们发现大语言模型（LLM）中的数据泄露问题可以通过我们的多个参考文本度量来减轻。我们在 GitHub 上发布了代码和数据，请参考 \url{https://github.com/SefaZeng/LLM-Ref}。
</details></li>
</ul>
<hr>
<h2 id="“Kurosawa”-A-Script-Writer’s-Assistant"><a href="#“Kurosawa”-A-Script-Writer’s-Assistant" class="headerlink" title="“Kurosawa”: A Script Writer’s Assistant"></a>“Kurosawa”: A Script Writer’s Assistant</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03122">http://arxiv.org/abs/2308.03122</a></li>
<li>repo_url: None</li>
<li>paper_authors: Prerak Gandhi, Vishal Pramanik, Pushpak Bhattacharyya</li>
<li>for: 这 paper 的目的是提出一种基于 AI 的剧本创作工具箱，以便自动生成剧本和剧场。</li>
<li>methods: 该工具箱使用 GPT-3 进行微调，并使用 manually annotated 的剧本和剧场数据进行训练。</li>
<li>results: 经过评估后，这些自动生成的剧本和剧场被一家著名的娱乐平台 ErosNow 的编剧人员用于创作。<details>
<summary>Abstract</summary>
Storytelling is the lifeline of the entertainment industry -- movies, TV shows, and stand-up comedies, all need stories. A good and gripping script is the lifeline of storytelling and demands creativity and resource investment. Good scriptwriters are rare to find and often work under severe time pressure. Consequently, entertainment media are actively looking for automation. In this paper, we present an AI-based script-writing workbench called KUROSAWA which addresses the tasks of plot generation and script generation. Plot generation aims to generate a coherent and creative plot (600-800 words) given a prompt (15-40 words). Script generation, on the other hand, generates a scene (200-500 words) in a screenplay format from a brief description (15-40 words). Kurosawa needs data to train. We use a 4-act structure of storytelling to annotate the plot dataset manually. We create a dataset of 1000 manually annotated plots and their corresponding prompts/storylines and a gold-standard dataset of 1000 scenes with four main elements -- scene headings, action lines, dialogues, and character names -- tagged individually. We fine-tune GPT-3 with the above datasets to generate plots and scenes. These plots and scenes are first evaluated and then used by the scriptwriters of a large and famous media platform ErosNow. We release the annotated datasets and the models trained on these datasets as a working benchmark for automatic movie plot and script generation.
</details>
<details>
<summary>摘要</summary>
互联网娱乐业的生命线是故事告诉，电影、电视节目和Stand-up喜剧都需要故事。一个好的和抓人的剧本是故事告诉的生命线，需要创造力和资源投入。好的剧本作家罕见，常工作于严格的时间压力下。因此，娱乐媒体 aktif looking for automation。在这篇论文中，我们介绍了一个基于人工智能的剧本创作工具 called KUROSAWA，它 Addresses the tasks of plot generation and script generation。Plot generation aims to generate a coherent and creative plot (600-800 words) given a prompt (15-40 words). Script generation, on the other hand, generates a scene (200-500 words) in a screenplay format from a brief description (15-40 words). Kurosawa需要数据进行训练。我们使用了4 acts of storytelling structure to annotate the plot dataset manually。我们创建了1000个手动注释的剧本和其相应的提示/故事情节的数据集，以及1000个完整的场景集，每个场景包括四个主要元素：场景标题、行为线、对白和角色名称，并且每个元素都被标记 separately。我们使用这些数据集来精度地调整GPT-3，以生成剧本和场景。这些剧本和场景首先被评估，然后被一家著名的娱乐平台ErosNow的编剧使用。我们发布了注释数据集和基于这些数据集的模型，作为自动电影剧本和剧本生成的工作准则。
</details></li>
</ul>
<hr>
<h2 id="PromptSum-Parameter-Efficient-Controllable-Abstractive-Summarization"><a href="#PromptSum-Parameter-Efficient-Controllable-Abstractive-Summarization" class="headerlink" title="PromptSum: Parameter-Efficient Controllable Abstractive Summarization"></a>PromptSum: Parameter-Efficient Controllable Abstractive Summarization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03117">http://arxiv.org/abs/2308.03117</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mathieu Ravaut, Hailin Chen, Ruochen Zhao, Chengwei Qin, Shafiq Joty, Nancy Chen</li>
<li>for: 提高摘要生成的性能和可控性，同时实现参数效率和数据效率。</li>
<li>methods:  combinig prompt tuning (PT) 技术和多任务目标，以及使用明确的实体提示。</li>
<li>results: 在 популяр的摘要生成benchmark上达到了竞争性ROUGE成绩，同时具有强的可控性，只需要 Parameters的几个数量级下锻炼。<details>
<summary>Abstract</summary>
Prompt tuning (PT), a parameter-efficient technique that only tunes the additional prompt embeddings while keeping the backbone pre-trained language model (PLM) frozen, has shown promising results in language understanding tasks, especially in low-resource scenarios. However, effective prompt design methods suitable for generation tasks such as summarization are still lacking. At the same time, summarization guided through instructions (discrete prompts) can achieve a desirable double objective of high quality and controllability in summary generation. Towards a goal of strong summarization performance under the triple conditions of parameter-efficiency, data-efficiency, and controllability, we introduce PromptSum, a method combining PT with a multi-task objective and discrete entity prompts for abstractive summarization. Our model achieves competitive ROUGE results on popular abstractive summarization benchmarks coupled with a strong level of controllability through entities, all while only tuning several orders of magnitude less parameters.
</details>
<details>
<summary>摘要</summary>
Prompt tuning（PT），一种 parameter-efficient 技术，只是调整额外提示 embedding，保持预训练语言模型（PLM）冻结，已经显示出在语言理解任务中获得了良好的结果，特别是在低资源enario中。然而，适用于生成任务，如摘要的有效提示方法仍然缺乏。而摘要指导 instrucions（discrete prompts）可以实现一个双重目标：高质量和可控性。为了实现强大的摘要性能在三个条件下：参数效率、数据效率和可控性，我们介绍 PromptSum，一种将PT与多任务目标和分类提示拼接在一起的方法。我们的模型在流行的摘要生成benchmark上达到了竞争性ROUGE成绩，同时保持了高水平的可控性，所有这些都只需要调整几个数量级的参数。
</details></li>
</ul>
<hr>
<h2 id="Improving-Domain-Specific-Retrieval-by-NLI-Fine-Tuning"><a href="#Improving-Domain-Specific-Retrieval-by-NLI-Fine-Tuning" class="headerlink" title="Improving Domain-Specific Retrieval by NLI Fine-Tuning"></a>Improving Domain-Specific Retrieval by NLI Fine-Tuning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03103">http://arxiv.org/abs/2308.03103</a></li>
<li>repo_url: None</li>
<li>paper_authors: Roman Dušek, Aleksander Wawer, Christopher Galias, Lidia Wojciechowska</li>
<li>for:  investigate the fine-tuning potential of natural language inference (NLI) data to improve information retrieval and ranking.</li>
<li>methods:  employ both monolingual and multilingual sentence encoders fine-tuned by a supervised method utilizing contrastive loss and NLI data.</li>
<li>results:  NLI fine-tuning increases the performance of the models in both tasks and both languages, with the potential to improve mono- and multilingual models.Here’s the full text in Simplified Chinese:</li>
<li>for: 这篇论文旨在调查自然语言推理（NLI）数据的细化潜力，以提高信息检索和排名。</li>
<li>methods: 我们使用一种监督方法，使用对比损失和NLI数据来细化单语言和多语言句子编码器。</li>
<li>results: NLI细化提高了模型在两种任务和两种语言中的性能，并有可能提高单语言和多语言模型。I hope this helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
The aim of this article is to investigate the fine-tuning potential of natural language inference (NLI) data to improve information retrieval and ranking. We demonstrate this for both English and Polish languages, using data from one of the largest Polish e-commerce sites and selected open-domain datasets. We employ both monolingual and multilingual sentence encoders fine-tuned by a supervised method utilizing contrastive loss and NLI data. Our results point to the fact that NLI fine-tuning increases the performance of the models in both tasks and both languages, with the potential to improve mono- and multilingual models. Finally, we investigate uniformity and alignment of the embeddings to explain the effect of NLI-based fine-tuning for an out-of-domain use-case.
</details>
<details>
<summary>摘要</summary>
本文的目的是调查自然语言推理（NLI）数据的细化 potential，以提高信息检索和排序。我们通过英语和波兰语两种语言进行了实验，使用了一个大型波兰电商网站的数据和一些开放领域的数据集。我们使用了监督方法和对比损失来练化单语言和多语言句子编码器。我们的结果表明，NLI 练化可以提高模型在两种语言中的性能，并且可以改善单语言和多语言模型。最后，我们进行了均匀性和对齐的调查，以解释NLI基于练化的效果在异语言应用场景中。
</details></li>
</ul>
<hr>
<h2 id="LARCH-Large-Language-Model-based-Automatic-Readme-Creation-with-Heuristics"><a href="#LARCH-Large-Language-Model-based-Automatic-Readme-Creation-with-Heuristics" class="headerlink" title="LARCH: Large Language Model-based Automatic Readme Creation with Heuristics"></a>LARCH: Large Language Model-based Automatic Readme Creation with Heuristics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03099">http://arxiv.org/abs/2308.03099</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hitachi-nlp/larch">https://github.com/hitachi-nlp/larch</a></li>
<li>paper_authors: Yuta Koreeda, Terufumi Morishita, Osamu Imaichi, Yasuhiro Sogawa<br>for: This paper aims to demonstrate the ability of large language models (LLMs) to generate coherent and factually correct readmes for software development projects, and to introduce a new tool called LARCH (LLM-based Automatic Readme Creation with Heuristics) that leverages representative code identification with heuristics and weak supervision to achieve this goal.methods: The authors use a dataset of 100 open-source projects to train and evaluate LARCH, and compare its performance with a baseline that does not rely on representative code identification. They use human and automated evaluations to assess the quality of the generated readmes, and show that LARCH outperforms the baseline in the majority of cases.results: The authors report that LARCH is capable of generating coherent and factually correct readmes in the majority of cases, and that it outperforms the baseline in terms of readability, accuracy, and completeness. They also provide a demo video showcasing LARCH’s capabilities, which is available at <a target="_blank" rel="noopener" href="https://youtu.be/ZUKkh5ED-O4">https://youtu.be/ZUKkh5ED-O4</a>.<details>
<summary>Abstract</summary>
Writing a readme is a crucial aspect of software development as it plays a vital role in managing and reusing program code. Though it is a pain point for many developers, automatically creating one remains a challenge even with the recent advancements in large language models (LLMs), because it requires generating an abstract description from thousands of lines of code. In this demo paper, we show that LLMs are capable of generating a coherent and factually correct readmes if we can identify a code fragment that is representative of the repository. Building upon this finding, we developed LARCH (LLM-based Automatic Readme Creation with Heuristics) which leverages representative code identification with heuristics and weak supervision. Through human and automated evaluations, we illustrate that LARCH can generate coherent and factually correct readmes in the majority of cases, outperforming a baseline that does not rely on representative code identification. We have made LARCH open-source and provided a cross-platform Visual Studio Code interface and command-line interface, accessible at https://github.com/hitachi-nlp/larch. A demo video showcasing LARCH's capabilities is available at https://youtu.be/ZUKkh5ED-O4.
</details>
<details>
<summary>摘要</summary>
制作readme文档是软件开发中的一个重要环节，它扮演着管理和重用代码的重要角色。尽管这是许多开发者的痛点，但自动生成readme仍然是一项挑战，尤其是在大语言模型（LLM）的最新进展下。这是因为需要从千行代码中生成抽象的描述。在这个demo paper中，我们显示了LLM可以生成准确和 coherent的readme，只要我们可以确定代码的 Representatives。基于这一发现，我们开发了LARCH（LLM-based Automatic Readme Creation with Heuristics），它利用代码 Representative identification和规则来生成readme。经过人工和自动评估，我们表明LARCH可以在大多数情况下生成准确和 coherent的readme，超过了不含代码 Representative identification的基线。我们将LARCH开源，并提供了跨平台Visual Studio Code接口和命令行接口，可以在https://github.com/hitachi-nlp/larch中下载。一个展示LARCH的功能的 demo 视频可以在https://youtu.be/ZUKkh5ED-O4上找到。
</details></li>
</ul>
<hr>
<h2 id="System-Initiated-Transitions-from-Chit-Chat-to-Task-Oriented-Dialogues-with-Transition-Info-Extractor-and-Transition-Sentence-Generator"><a href="#System-Initiated-Transitions-from-Chit-Chat-to-Task-Oriented-Dialogues-with-Transition-Info-Extractor-and-Transition-Sentence-Generator" class="headerlink" title="System-Initiated Transitions from Chit-Chat to Task-Oriented Dialogues with Transition Info Extractor and Transition Sentence Generator"></a>System-Initiated Transitions from Chit-Chat to Task-Oriented Dialogues with Transition Info Extractor and Transition Sentence Generator</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03098">http://arxiv.org/abs/2308.03098</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ye Liu, Stefan Ultes, Wolfgang Minker, Wolfgang Maier</li>
<li>for:  investigate how a unified dialogue model can take the initiative during the dialogue mode transition from chit-chat to task-oriented in a coherent and cooperative manner.</li>
<li>methods:  built a {transition information extractor} (TIE) and a {transition sentence generator} (TSG) through efficient Adapter tuning and transition prompt learning.</li>
<li>results:  achieved promising performance regarding the proactive transitions and improved the TIE model by utilizing Conditional Random Fields (CRF). The TSG can flexibly generate transition sentences while maintaining the unified capabilities of normal chit-chat and task-oriented response generation.<details>
<summary>Abstract</summary>
In this work, we study dialogue scenarios that start from chit-chat but eventually switch to task-related services, and investigate how a unified dialogue model, which can engage in both chit-chat and task-oriented dialogues, takes the initiative during the dialogue mode transition from chit-chat to task-oriented in a coherent and cooperative manner. We firstly build a {transition info extractor} (TIE) that keeps track of the preceding chit-chat interaction and detects the potential user intention to switch to a task-oriented service. Meanwhile, in the unified model, a {transition sentence generator} (TSG) is extended through efficient Adapter tuning and transition prompt learning. When the TIE successfully finds task-related information from the preceding chit-chat, such as a transition domain, then the TSG is activated automatically in the unified model to initiate this transition by generating a transition sentence under the guidance of transition information extracted by TIE. The experimental results show promising performance regarding the proactive transitions. We achieve an additional large improvement on TIE model by utilizing Conditional Random Fields (CRF). The TSG can flexibly generate transition sentences while maintaining the unified capabilities of normal chit-chat and task-oriented response generation.
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们研究了从小聊天转移到任务相关服务的对话场景，并研究了一个统一对话模型，可以同时参与小聊天和任务准备对话。我们首先建立了一个{"transition信息抽取器"}(TIE)，以跟踪先前的小聊天交互并检测用户可能的任务转换意图。在统一模型中，我们通过高效的Adapter调整和转换提示学习扩展了{转换句生成器}(TSG)。当TIE成功检测到前一个小聊天中的任务相关信息，例如转换领域，那么TSG会自动在统一模型中被启动，通过生成一个转换句来实现转换，并且在TIE提供的转换信息的指导下进行转换句生成。实验结果表明，我们在掌握前一个小聊天中的任务相关信息后，可以通过TSG生成转换句来实现掌握任务的跳转，并且可以保持统一的对话能力。此外，我们还通过使用 Conditional Random Fields (CRF) 来提高TIE模型的性能，并且TSG可以灵活地生成转换句，同时保持统一的对话能力。
</details></li>
</ul>
<hr>
<h2 id="TARJAMAT-Evaluation-of-Bard-and-ChatGPT-on-Machine-Translation-of-Ten-Arabic-Varieties"><a href="#TARJAMAT-Evaluation-of-Bard-and-ChatGPT-on-Machine-Translation-of-Ten-Arabic-Varieties" class="headerlink" title="TARJAMAT: Evaluation of Bard and ChatGPT on Machine Translation of Ten Arabic Varieties"></a>TARJAMAT: Evaluation of Bard and ChatGPT on Machine Translation of Ten Arabic Varieties</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03051">http://arxiv.org/abs/2308.03051</a></li>
<li>repo_url: None</li>
<li>paper_authors: Karima Kadaoui, Samar M. Magdy, Abdul Waheed, Md Tawkat Islam Khondaker, Ahmed Oumar El-Shangiti, El Moatez Billah Nagoudi, Muhammad Abdul-Mageed</li>
<li>For: 这项研究旨在评估Google Bard和OpenAI ChatGPT等大型语言模型在十种阿拉伯语言中的翻译能力。* Methods: 研究使用了这些模型的机器翻译功能，包括古典阿拉伯语、现代标准阿拉伯语和几种方言变体。此外，研究还进行了人类中心的研究，以评估Bard模型在翻译任务中遵循人类指令的能力。* Results: 研究发现，LLMs在某些阿拉伯语言方言上存在困难，特别是缺乏公共数据的语言，如阿尔及利亚和毛里塔尼亚语言。然而，它们在更常见的方言上表现良好，尽管有时与商业系统如Google Translate相比落后。此外，研究还发现Bard模型在翻译任务中遵循人类指令的能力有限。总的来说，研究表明，现有的LLMs仍然缺乏包容性，无法满足不同社区的语言和文化特点。<details>
<summary>Abstract</summary>
Large language models (LLMs) finetuned to follow human instructions have recently emerged as a breakthrough in AI. Models such as Google Bard and OpenAI ChatGPT, for example, are surprisingly powerful tools for question answering, code debugging, and dialogue generation. Despite the purported multilingual proficiency of these models, their linguistic inclusivity remains insufficiently explored. Considering this constraint, we present a thorough assessment of Bard and ChatGPT (encompassing both GPT-3.5 and GPT-4) regarding their machine translation proficiencies across ten varieties of Arabic. Our evaluation covers diverse Arabic varieties such as Classical Arabic, Modern Standard Arabic, and several nuanced dialectal variants. Furthermore, we undertake a human-centric study to scrutinize the efficacy of the most recent model, Bard, in following human instructions during translation tasks. Our exhaustive analysis indicates that LLMs may encounter challenges with certain Arabic dialects, particularly those for which minimal public data exists, such as Algerian and Mauritanian dialects. However, they exhibit satisfactory performance with more prevalent dialects, albeit occasionally trailing behind established commercial systems like Google Translate. Additionally, our analysis reveals a circumscribed capability of Bard in aligning with human instructions in translation contexts. Collectively, our findings underscore that prevailing LLMs remain far from inclusive, with only limited ability to cater for the linguistic and cultural intricacies of diverse communities.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM），如Google Bard和OpenAI ChatGPT，在最近几年内崭新出现，并表现出很强的问答、代码调试和对话生成能力。然而，这些模型的语言多样性仍然未得到足够的探索。因此，我们对Bard和ChatGPT（包括GPT-3.5和GPT-4）在十种阿拉伯语言中的机器翻译能力进行了全面的评估。我们的评估覆盖了古典阿拉伯语、现代标准阿拉伯语以及一些细腻的方言变体。此外，我们还进行了人类中心的研究，以评估Bard在翻译任务中遵循人类指令的能力。我们的详细分析表明，LLMs可能会面临certain阿拉伯语言的挑战，特别是缺乏公共数据的阿尔及杜和 Mauritania的方言。然而，它们在更常见的方言上表现得比较满意，尽管有时会落后于已有的商业系统如Google翻译。此外，我们的分析还发现了Bard在翻译任务中遵循人类指令的能力有限。总之，我们的发现表明，当前的LLMs仍然远离含义，只能够部分地适应不同社区的语言和文化特点。
</details></li>
</ul>
<hr>
<h2 id="3D-EX-A-Unified-Dataset-of-Definitions-and-Dictionary-Examples"><a href="#3D-EX-A-Unified-Dataset-of-Definitions-and-Dictionary-Examples" class="headerlink" title="3D-EX : A Unified Dataset of Definitions and Dictionary Examples"></a>3D-EX : A Unified Dataset of Definitions and Dictionary Examples</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03043">http://arxiv.org/abs/2308.03043</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/f-almeman/3d-ex">https://github.com/f-almeman/3d-ex</a></li>
<li>paper_authors: Fatemah Almeman, Hadi Sheikhi, Luis Espinosa-Anke</li>
<li>for: 这篇论文的目的是为了提供一个中央知识库， combin ing 英语资源，以便在 NLP 任务中使用。</li>
<li>methods: 这篇论文使用了 &lt;term, definition, example&gt;  triplets 来填充 lexical 资源的 gap，并提供了一个统一的评估框架，以避免 memorization。</li>
<li>results: 实验结果表明，这些数据可以在下游 NLP 任务中有效地应用。<details>
<summary>Abstract</summary>
Definitions are a fundamental building block in lexicography, linguistics and computational semantics. In NLP, they have been used for retrofitting word embeddings or augmenting contextual representations in language models. However, lexical resources containing definitions exhibit a wide range of properties, which has implications in the behaviour of models trained and evaluated on them. In this paper, we introduce 3D- EX , a dataset that aims to fill this gap by combining well-known English resources into one centralized knowledge repository in the form of <term, definition, example> triples. 3D- EX is a unified evaluation framework with carefully pre-computed train/validation/test splits to prevent memorization. We report experimental results that suggest that this dataset could be effectively leveraged in downstream NLP tasks. Code and data are available at https://github.com/F-Almeman/3D-EX .
</details>
<details>
<summary>摘要</summary>
<SYS>Translate the given text into Simplified Chinese.</SYS>定义是自然语言处理（NLP）中的基本构件，它们在语义学和计算 semantics 中扮演着重要的角色。在 NLP 中，定义被用于改进词嵌入或增强语言模型的上下文表示。然而，各种语言资源中的定义具有各种特点，这会影响模型在这些资源上训练和评估的行为。本文介绍了3D- EX 数据集，它将英语资源集成到一个中心知识库中，并提供了 <term, definition, example> 三元组。3D- EX 提供了一个统一的评估框架，并且在训练/验证/测试分区中进行了精心预计算，以避免Memorization。我们发现，这个数据集可以在下游 NLP 任务中得到有效地利用。代码和数据可以在 GitHub 上找到：https://github.com/F-Almeman/3D-EX。
</details></li>
</ul>
<hr>
<h2 id="Multi-Source-Pre-Training-for-Cross-Domain-Measurement-Unit-and-Context-Extraction"><a href="#Multi-Source-Pre-Training-for-Cross-Domain-Measurement-Unit-and-Context-Extraction" class="headerlink" title="Multi-Source (Pre-)Training for Cross-Domain Measurement, Unit and Context Extraction"></a>Multi-Source (Pre-)Training for Cross-Domain Measurement, Unit and Context Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02951">http://arxiv.org/abs/2308.02951</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liy140/multidomain-measextract-corpus">https://github.com/liy140/multidomain-measextract-corpus</a></li>
<li>paper_authors: Yueling Li, Sebastian Martschat, Simone Paolo Ponzetto</li>
<li>for: 本研究旨在开发一种跨Domain的自动量测和上下文提取方法，利用预训练语言模型。</li>
<li>methods: 我们构建了多源多Domain的语料库，并在这个语料库上训练了一个端到端提取管道。然后，我们进行多源任务适应性预训练和细化调整，以评估我们的模型在跨Domain的总体化能力。</li>
<li>results: 我们的结果表明，多源训练导致最佳总体结果，而单源训练对各个域的结果具有最佳效果。虽然我们的设置可以提取量值和单位，但需要进一步研究以提高上下文实体的提取。我们将在线上发布使用的跨Domain语料库。<details>
<summary>Abstract</summary>
We present a cross-domain approach for automated measurement and context extraction based on pre-trained language models. We construct a multi-source, multi-domain corpus and train an end-to-end extraction pipeline. We then apply multi-source task-adaptive pre-training and fine-tuning to benchmark the cross-domain generalization capability of our model. Further, we conceptualize and apply a task-specific error analysis and derive insights for future work. Our results suggest that multi-source training leads to the best overall results, while single-source training yields the best results for the respective individual domain. While our setup is successful at extracting quantity values and units, more research is needed to improve the extraction of contextual entities. We make the cross-domain corpus used in this work available online.
</details>
<details>
<summary>摘要</summary>
我们提出了跨领域方法，用于自动测量和上下文提取，基于预训练语言模型。我们构建了多源多领域 corpora，并训练了端到端提取管道。然后，我们实施多源任务适应预训练和精度调整，以评估我们模型的跨领域一致性。此外，我们提出了任务特定错误分析，并从中提取了未来工作的想法。我们的结果表明，多源训练得到了最佳总结果，而单源训练得到了每个固定领域的最佳结果。虽然我们的设置可以提取量值和单位，但更多的研究是需要进一步提高上下文实体的提取。我们在这里发布了用于这项工作的跨领域 corpus。
</details></li>
</ul>
<hr>
<h2 id="Towards-Consistency-Filtering-Free-Unsupervised-Learning-for-Dense-Retrieval"><a href="#Towards-Consistency-Filtering-Free-Unsupervised-Learning-for-Dense-Retrieval" class="headerlink" title="Towards Consistency Filtering-Free Unsupervised Learning for Dense Retrieval"></a>Towards Consistency Filtering-Free Unsupervised Learning for Dense Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02926">http://arxiv.org/abs/2308.02926</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Haoxiang-WasedaU/Towards-Consistency-Filtering-Free-Unsupervised-Learning-for-Dense-Retrieval">https://github.com/Haoxiang-WasedaU/Towards-Consistency-Filtering-Free-Unsupervised-Learning-for-Dense-Retrieval</a></li>
<li>paper_authors: Haoxiang Shi, Sumio Fujita, Tetsuya Sakai</li>
<li>for: 这个研究是为了解决现代神经信息搜寻（IR）中的领域转移问题。</li>
<li>methods: 这个研究使用了不同的方法来取代过去常用的领域专门的手动标注和人工生成的统计数据，以提高rankere的效率和表现。</li>
<li>results: 研究结果显示，使用TextRank基于pseudo relevance feedback的方法可以更好地超越其他方法，而且训练和测试效率都能持续提高。<details>
<summary>Abstract</summary>
Domain transfer is a prevalent challenge in modern neural Information Retrieval (IR). To overcome this problem, previous research has utilized domain-specific manual annotations and synthetic data produced by consistency filtering to finetune a general ranker and produce a domain-specific ranker. However, training such consistency filters are computationally expensive, which significantly reduces the model efficiency. In addition, consistency filtering often struggles to identify retrieval intentions and recognize query and corpus distributions in a target domain. In this study, we evaluate a more efficient solution: replacing the consistency filter with either direct pseudo-labeling, pseudo-relevance feedback, or unsupervised keyword generation methods for achieving consistent filtering-free unsupervised dense retrieval. Our extensive experimental evaluations demonstrate that, on average, TextRank-based pseudo relevance feedback outperforms other methods. Furthermore, we analyzed the training and inference efficiency of the proposed paradigm. The results indicate that filtering-free unsupervised learning can continuously improve training and inference efficiency while maintaining retrieval performance. In some cases, it can even improve performance based on particular datasets.
</details>
<details>
<summary>摘要</summary>
域名转移是现代神经信息检索（IR）中的一大挑战。以前的研究使用了域名特定的手动标注和生成的人工数据来训练一个通用排名器，并生成一个域名特定的排名器。然而，训练这些一致性筛选器是计算机代价高昂，这会明显降低模型效率。另外，一致性筛选器经常难以识别检索意图和查询和文献分布在目标域中。在这种研究中，我们评估了一种更高效的解决方案：取代一致性筛选器，使用直接 pseudo-标注、 pseudo-相关反馈或无监督关键词生成方法来实现一致性自由无监督排名。我们对这些方法进行了广泛的实验评估，结果显示，在平均情况下，基于 TextRank 的 pseudo-相关反馈方法表现较好。此外，我们还分析了我们提议的训练和推理效率。结果表明，无监督无筛选的学习可以不断提高训练和推理效率，同时维持检索性能。在某些情况下，它可以超越基于特定数据集的表现。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/06/cs.CL_2023_08_06/" data-id="clp89doa8009ni788bbjx886j" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_08_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/06/cs.LG_2023_08_06/" class="article-date">
  <time datetime="2023-08-06T10:00:00.000Z" itemprop="datePublished">2023-08-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/06/cs.LG_2023_08_06/">cs.LG - 2023-08-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="AI-GOMS-Large-AI-Driven-Global-Ocean-Modeling-System"><a href="#AI-GOMS-Large-AI-Driven-Global-Ocean-Modeling-System" class="headerlink" title="AI-GOMS: Large AI-Driven Global Ocean Modeling System"></a>AI-GOMS: Large AI-Driven Global Ocean Modeling System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03152">http://arxiv.org/abs/2308.03152</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Xiong, Yanfei Xiang, Hao Wu, Shuyi Zhou, Yuze Sun, Muyuan Ma, Xiaomeng Huang</li>
<li>for: 这个论文的目的是为了提出一种基于人工智能的全球海洋模拟系统，以实现精确和高效的全球海洋日常预测。</li>
<li>methods: 该论文使用了一种基于 Fourier-based Masked Autoencoder 结构的基本海洋变量预测模型，以及一些轻量级的细化预测模型，包括地区下降、涟式解码和生物化 Coupling 模块。</li>
<li>results: 该论文实现了在30天预测期间，全球海洋基本变量的最佳性能，并且可以正确 simulate  mesoscale eddies 在日本热带区域和海洋层次分布在赤道太平洋区域。该系统还实现了对 Earth system 模型的新脊梁下游方式，使其可以易于转移、扩展和重用。<details>
<summary>Abstract</summary>
Ocean modeling is a powerful tool for simulating the physical, chemical, and biological processes of the ocean, which is the foundation for marine science research and operational oceanography. Modern numerical ocean modeling mainly consists of governing equations and numerical algorithms. Nonlinear instability, computational expense, low reusability efficiency and high coupling costs have gradually become the main bottlenecks for the further development of numerical ocean modeling. Recently, artificial intelligence-based modeling in scientific computing has shown revolutionary potential for digital twins and scientific simulations, but the bottlenecks of numerical ocean modeling have not been further solved. Here, we present AI-GOMS, a large AI-driven global ocean modeling system, for accurate and efficient global ocean daily prediction. AI-GOMS consists of a backbone model with the Fourier-based Masked Autoencoder structure for basic ocean variable prediction and lightweight fine-tuning models incorporating regional downscaling, wave decoding, and biochemistry coupling modules. AI-GOMS has achieved the best performance in 30 days of prediction for the global ocean basic variables with 15 depth layers at 1/4{\deg} spatial resolution. Beyond the good performance in statistical metrics, AI-GOMS realizes the simulation of mesoscale eddies in the Kuroshio region at 1/12{\deg} spatial resolution and ocean stratification in the tropical Pacific Ocean. AI-GOMS provides a new backbone-downstream paradigm for Earth system modeling, which makes the system transferable, scalable and reusable.
</details>
<details>
<summary>摘要</summary>
海洋模拟是一种强大的工具，用于模拟海洋物理、化学和生物过程，这是海洋科学研究和操作海洋学的基础。现代数值海洋模拟主要由管理方程和数值算法组成。不线性不稳定、计算成本高、 reuse效率低和对接成本高逐渐成为现代数值海洋模拟的主要瓶颈。近年来，基于人工智能的科学计算方法在数值海洋模拟中表现出革命性的潜力，但现代数值海洋模拟中的瓶颈问题尚未得到解决。在这种情况下，我们提出了AI-GOMS，一个大规模的人工智能驱动的全球海洋模拟系统，用于准确和高效地预测全球海洋日常变化。AI-GOMS包括一个基础模型，其结构基于 Fourier-based Masked Autoencoder，用于预测基本海洋变量。此外，AI-GOMS还包括一些轻量级的精度增强模型，包括地区下降、浪谱解码和生物化学相互作用模块。AI-GOMS在30天预测全球海洋基本变量的15层深度分辨率下达到了最佳性能。除了在统计指标上的良好表现外，AI-GOMS还能够模拟kuroshio区域的宏观瑞度涟潮和热带太平洋海洋的层次分布。AI-GOMS提供了一个新的基础-下游模式，用于地球系统模拟，这使得系统可转移、可扩展和可重用。
</details></li>
</ul>
<hr>
<h2 id="Nest-DGIL-Nesterov-optimized-Deep-Geometric-Incremental-Learning-for-CS-Image-Reconstruction"><a href="#Nest-DGIL-Nesterov-optimized-Deep-Geometric-Incremental-Learning-for-CS-Image-Reconstruction" class="headerlink" title="Nest-DGIL: Nesterov-optimized Deep Geometric Incremental Learning for CS Image Reconstruction"></a>Nest-DGIL: Nesterov-optimized Deep Geometric Incremental Learning for CS Image Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03807">http://arxiv.org/abs/2308.03807</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fanxiaohong/Nest-DGIL">https://github.com/fanxiaohong/Nest-DGIL</a></li>
<li>paper_authors: Xiaohong Fan, Yin Yang, Ke Chen, Yujie Feng, Jianping Zhang</li>
<li>for: 提高图像恢复精度和速度，并减少artefacts。</li>
<li>methods: 基于第二代Nesterov proximal梯度优化的深度凝师增量学习框架。</li>
<li>results: 提出了一种可 theoretically guarantee geometric texture details的恢复方法，并且可以快速 converges。<details>
<summary>Abstract</summary>
Proximal gradient-based optimization is one of the most common strategies for solving image inverse problems as well as easy to implement. However, these techniques often generate heavy artifacts in image reconstruction. One of the most popular refinement methods is to fine-tune the regularization parameter to alleviate such artifacts, but it may not always be sufficient or applicable due to increased computational costs. In this work, we propose a deep geometric incremental learning framework based on second Nesterov proximal gradient optimization. The proposed end-to-end network not only has the powerful learning ability for high/low frequency image features,but also can theoretically guarantee that geometric texture details will be reconstructed from preliminary linear reconstruction.Furthermore, it can avoid the risk of intermediate reconstruction results falling outside the geometric decomposition domains and achieve fast convergence. Our reconstruction framework is decomposed into four modules including general linear reconstruction, cascade geometric incremental restoration, Nesterov acceleration and post-processing. In the image restoration step,a cascade geometric incremental learning module is designed to compensate for the missing texture information from different geometric spectral decomposition domains. Inspired by overlap-tile strategy, we also develop a post-processing module to remove the block-effect in patch-wise-based natural image reconstruction. All parameters in the proposed model are learnable,an adaptive initialization technique of physical-parameters is also employed to make model flexibility and ensure converging smoothly. We compare the reconstruction performance of the proposed method with existing state-of-the-art methods to demonstrate its superiority. Our source codes are available at https://github.com/fanxiaohong/Nest-DGIL.
</details>
<details>
<summary>摘要</summary>
近似 gradient-based 优化是解析图像问题的一种最常见的策略，易于实现。然而，这些技术通常会产生重要的artefacts在图像重建中。一种最受欢迎的修正方法是微调正则化参数，以避免这些artefacts，但这可能并不总是可行或适用，因为它可能会增加计算成本。在这项工作中，我们提出了一种深度几何增量学习框架，基于第二个讷斯特洛夫 proximal gradient 优化。我们的提案的终端网络不仅有强大的学习能力，可以学习高/低频图像特征，而且可以 theoretically 保证，从初步线性重建中恢复几何纹理细节。此外，它可以避免初步重建结果落在几何分解域之外，并快速 converges。我们的重建框架分为四个模块，包括普通的线性重建、几何增量修复、讷斯特洛夫加速和后处理。在图像修复步骤中，我们设计了几何增量修复模块，以补偿不同几何 spectral decomposition 域中缺失的纹理信息。受到 overlap-tile 策略的启发，我们还开发了后处理模块，以除去 patch-wise 基于自然图像重建中的块效应。所有模型参数都是学习的，并且使用 adaptive  initialization 技术，以确保模型的灵活性和平滑的 converging。我们与现有的状态态-of-the-art 方法进行比较，以证明我们的方法的优越性。我们的源代码可以在 https://github.com/fanxiaohong/Nest-DGIL 上获取。
</details></li>
</ul>
<hr>
<h2 id="Self-Directed-Linear-Classification"><a href="#Self-Directed-Linear-Classification" class="headerlink" title="Self-Directed Linear Classification"></a>Self-Directed Linear Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03142">http://arxiv.org/abs/2308.03142</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/neurons">https://github.com/Aryia-Behroziuan/neurons</a></li>
<li>paper_authors: Ilias Diakonikolas, Vasilis Kontonis, Christos Tzamos, Nikos Zarifis</li>
<li>for: 这个论文研究了在线分类中learner预测标签的顺序选择问题，以实现最小化总错误数。</li>
<li>methods: 作者使用了自适应顺序选择方法，并设计了两个主要结果：一是对于uniformly随机从单位球体上取样的$X$数据集，设计了一个高效的自适应学习者，其错误数为$O(d \log \log n)$；二是对于任意$d$-维数据集$X$，设计了一个高效的自适应学习者，可以预测$X$中99%的点标签，错误数与$n$无关。</li>
<li>results: 作者的研究表明，在线分类中，采用自适应顺序选择方法可以实现较低的错误率，比如worst-order和Random-order学习方法的至少$\Omega(d \log n)$错误率。<details>
<summary>Abstract</summary>
In online classification, a learner is presented with a sequence of examples and aims to predict their labels in an online fashion so as to minimize the total number of mistakes. In the self-directed variant, the learner knows in advance the pool of examples and can adaptively choose the order in which predictions are made. Here we study the power of choosing the prediction order and establish the first strong separation between worst-order and random-order learning for the fundamental task of linear classification. Prior to our work, such a separation was known only for very restricted concept classes, e.g., one-dimensional thresholds or axis-aligned rectangles.   We present two main results. If $X$ is a dataset of $n$ points drawn uniformly at random from the $d$-dimensional unit sphere, we design an efficient self-directed learner that makes $O(d \log \log(n))$ mistakes and classifies the entire dataset. If $X$ is an arbitrary $d$-dimensional dataset of size $n$, we design an efficient self-directed learner that predicts the labels of $99\%$ of the points in $X$ with mistake bound independent of $n$. In contrast, under a worst- or random-ordering, the number of mistakes must be at least $\Omega(d \log n)$, even when the points are drawn uniformly from the unit sphere and the learner only needs to predict the labels for $1\%$ of them.
</details>
<details>
<summary>摘要</summary>
在在线分类中，学习者会看到一个序列例子并尝试预测其标签，以最小化总错误数。在自适应变体中，学习者在预测之前知道例子池，并可以动态选择预测的顺序。我们研究预测顺序的选择力，并证明了线性分类的基本任务上最差顺序和随机顺序之间的首次强分离。在我们的工作之前，这种分离只知道对非常限制的概念类型，例如一维阈值或垂直排序的直方体。我们有两个主要结果。如果$X$是一个$d$-维均匀随机选取从单位球体上的$n$个点，我们设计了高效的自适应学习者，其错误数为$O(d \log \log(n))$.如果$X$是一个任意$d$-维数据集大小$n$的点，我们设计了高效的自适应学习者，可以预测$X$中$99\%$的点标签，错误 bound不виси于$n$.相比之下，在最差或随机顺序下，错误数至少为$\Omega(d \log n)$,即使点被均匀选取从单位球体，并且学习者只需要预测$1\%$的点标签。
</details></li>
</ul>
<hr>
<h2 id="Iterative-Magnitude-Pruning-as-a-Renormalisation-Group-A-Study-in-The-Context-of-The-Lottery-Ticket-Hypothesis"><a href="#Iterative-Magnitude-Pruning-as-a-Renormalisation-Group-A-Study-in-The-Context-of-The-Lottery-Ticket-Hypothesis" class="headerlink" title="Iterative Magnitude Pruning as a Renormalisation Group: A Study in The Context of The Lottery Ticket Hypothesis"></a>Iterative Magnitude Pruning as a Renormalisation Group: A Study in The Context of The Lottery Ticket Hypothesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03128">http://arxiv.org/abs/2308.03128</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abu-Al Hassan</li>
<li>for: This paper explores the Lottery Ticket Hypothesis (LTH) in Deep Neural Networks (DNNs), which suggests that smaller, trainable subnetworks within extensive DNNs can achieve performance comparable to the full model.</li>
<li>methods: The paper uses Iterative Magnitude Pruning (IMP) to identify and eliminate minimal weights in DNNs, emulating stepwise learning. The authors also investigate the “universality” of winning tickets and their applicability to other similar problems.</li>
<li>results: The paper bridges the gap between IMP and the Renormalisation Group (RG) theory in physics, providing a more rigorous understanding of IMP and its potential applications in DNNs.<details>
<summary>Abstract</summary>
This thesis delves into the intricate world of Deep Neural Networks (DNNs), focusing on the exciting concept of the Lottery Ticket Hypothesis (LTH). The LTH posits that within extensive DNNs, smaller, trainable subnetworks termed "winning tickets", can achieve performance comparable to the full model. A key process in LTH, Iterative Magnitude Pruning (IMP), incrementally eliminates minimal weights, emulating stepwise learning in DNNs. Once we identify these winning tickets, we further investigate their "universality". In other words, we check if a winning ticket that works well for one specific problem could also work well for other, similar problems. We also bridge the divide between the IMP and the Renormalisation Group (RG) theory in physics, promoting a more rigorous understanding of IMP.
</details>
<details>
<summary>摘要</summary>
这个论文探讨了深度神经网络（DNN）的复杂世界，特别关注了赢家票假设（LTH）。LTH认为，在广泛的DNN中，更小的、可训练的子网络（赢家票）可以达到相同的性能。我们在LTH中使用增量大小减少（IMP）来逐渐减少最小的权重，模拟了DNN中的步骤学习。一旦我们identified这些赢家票，我们进一步调查它们的“通用性”。即我们检查一个赢家票在一个特定问题上能够达到高性能是否也能够在其他相似问题上达到高性能。我们还将IMP与物理学RG理论相连接，以促进IMP的更加准确的理解。
</details></li>
</ul>
<hr>
<h2 id="Learning-Rate-Free-Learning-Dissecting-D-Adaptation-and-Probabilistic-Line-Search"><a href="#Learning-Rate-Free-Learning-Dissecting-D-Adaptation-and-Probabilistic-Line-Search" class="headerlink" title="Learning-Rate-Free Learning: Dissecting D-Adaptation and Probabilistic Line Search"></a>Learning-Rate-Free Learning: Dissecting D-Adaptation and Probabilistic Line Search</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03102">http://arxiv.org/abs/2308.03102</a></li>
<li>repo_url: None</li>
<li>paper_authors: Max McGuinness</li>
<li>for: 本研究探讨了两种最近的学习率优化方法：D-Adaptation（arXiv:2301.07733）和概率线搜（arXiv:1502.02846）。这两种方法强调缓解选择初始学习率的负担，通过距离度量和 Gaussian 过程 posterior 估计，分别实现了。</li>
<li>methods: 本研究使用了 D-Adaptation 方法和概率线搜方法。D-Adaptation 方法基于距离度量，可以在不同的批处理大小下选择最佳学习率。概率线搜方法则使用 Gaussian 过程 posterior 估计来估计学习率的变化范围。</li>
<li>results: 本研究通过对两种方法的比较，发现 D-Adaptation 方法在某些情况下可以提供更高的准确率，而概率线搜方法在其他情况下可以提供更快的收敛速率。此外，本研究还发现了这两种方法在不同的批处理大小下的表现。<details>
<summary>Abstract</summary>
This paper explores two recent methods for learning rate optimisation in stochastic gradient descent: D-Adaptation (arXiv:2301.07733) and probabilistic line search (arXiv:1502.02846). These approaches aim to alleviate the burden of selecting an initial learning rate by incorporating distance metrics and Gaussian process posterior estimates, respectively. In this report, I provide an intuitive overview of both methods, discuss their shared design goals, and devise scope for merging the two algorithms.
</details>
<details>
<summary>摘要</summary>
这份报告探讨了两种最近的学习率优化方法：D-Adaptation（arXiv:2301.07733）和概率线搜索（arXiv:1502.02846）。这两种方法目的是减轻选择初始学习率的负担，通过距离度量和 Gaussian 过程 posterior 估计，分别提供了一种简单的概念概述、讨论这两种方法的共同设计目标，并提出将这两种算法合并的范围。
</details></li>
</ul>
<hr>
<h2 id="Gradient-Coding-through-Iterative-Block-Leverage-Score-Sampling"><a href="#Gradient-Coding-through-Iterative-Block-Leverage-Score-Sampling" class="headerlink" title="Gradient Coding through Iterative Block Leverage Score Sampling"></a>Gradient Coding through Iterative Block Leverage Score Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03096">http://arxiv.org/abs/2308.03096</a></li>
<li>repo_url: None</li>
<li>paper_authors: Neophytos Charalambides, Mert Pilanci, Alfred Hero</li>
<li>for: 这个论文是为了解决分布式计算中的失败问题（即慢进度），通过使用采样技术和编码计算方法来加速线性回归。</li>
<li>methods: 论文使用了一种基于采样的方法，即采样转换后的数据，以获得一个近似的$\ell_2$子空间嵌入。此外，它还使用了一种称为“编码计算”的方法，来加速线性回归。</li>
<li>results: 论文得到了一些有用的结果，包括：1) 采样技术可以在分布式计算中减少计算量，同时保持Solution的质量；2) 编码计算方法可以在分布式计算中加速线性回归，并且可以与采样技术结合使用以获得更好的性能。<details>
<summary>Abstract</summary>
We generalize the leverage score sampling sketch for $\ell_2$-subspace embeddings, to accommodate sampling subsets of the transformed data, so that the sketching approach is appropriate for distributed settings. This is then used to derive an approximate coded computing approach for first-order methods; known as gradient coding, to accelerate linear regression in the presence of failures in distributed computational networks, \textit{i.e.} stragglers. We replicate the data across the distributed network, to attain the approximation guarantees through the induced sampling distribution. The significance and main contribution of this work, is that it unifies randomized numerical linear algebra with approximate coded computing, while attaining an induced $\ell_2$-subspace embedding through uniform sampling. The transition to uniform sampling is done without applying a random projection, as in the case of the subsampled randomized Hadamard transform. Furthermore, by incorporating this technique to coded computing, our scheme is an iterative sketching approach to approximately solving linear regression. We also propose weighting when sketching takes place through sampling with replacement, for further compression.
</details>
<details>
<summary>摘要</summary>
我们扩展了抽象分析过程中的贡献分析方法，以适应分布式设置，使其适合分布式计算环境。这后续用于 derivation of an approximate coded computing approach for first-order methods，known as gradient coding，以加速分布式计算网络中的线性回授。我们将数据复制到分布式网络中，以获得近似保证通过导入的抽象分布。本研究的重要性和主要贡献在于它将随机数学和近似coded computing融合在一起，而且通过导入均匀抽象，以获得$\ell_2$ Sobolev embedding。与传统的随机抽象方法不同的是，我们不需要随机投影，而是通过均匀抽象来实现。此外，我们还提出了在抽象过程中使用权重的思想，以进一步压缩数据。因此，本研究的主要贡献在于提供一种基于随机数学和近似coded computing的迭代快速解方法，用于解决分布式计算环境中的线性回授问题。
</details></li>
</ul>
<hr>
<h2 id="Control-aware-echo-state-networks-Ca-ESN-for-the-suppression-of-extreme-events"><a href="#Control-aware-echo-state-networks-Ca-ESN-for-the-suppression-of-extreme-events" class="headerlink" title="Control-aware echo state networks (Ca-ESN) for the suppression of extreme events"></a>Control-aware echo state networks (Ca-ESN) for the suppression of extreme events</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03095">http://arxiv.org/abs/2308.03095</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alberto Racca, Luca Magri</li>
<li>for: 这篇论文是为了控制无序非线性系统中的极端事件而写的。</li>
<li>methods: 这篇论文使用了控制准确网络（Ca-ESN），让控制策略（如比例-积分-导数控制和模型预测控制）与ESNs融合在一起，以抑制极端事件的发生。</li>
<li>results: 这篇论文在实验中显示了使用Ca-ESN可以将极端事件的发生减少到传统方法的二个阶层，这开启了新的可控非线性系统的可能性。<details>
<summary>Abstract</summary>
Extreme event are sudden large-amplitude changes in the state or observables of chaotic nonlinear systems, which characterize many scientific phenomena. Because of their violent nature, extreme events typically have adverse consequences, which call for methods to prevent the events from happening. In this work, we introduce the control-aware echo state network (Ca-ESN) to seamlessly combine ESNs and control strategies, such as proportional-integral-derivative and model predictive control, to suppress extreme events. The methodology is showcased on a chaotic-turbulent flow, in which we reduce the occurrence of extreme events with respect to traditional methods by two orders of magnitude. This works opens up new possibilities for the efficient control of nonlinear systems with neural networks.
</details>
<details>
<summary>摘要</summary>
非常事件是普遍存在于非线性对称系统中的突然大幅度变化，这些事件 caracterize 许多科学现象。由于它们的暴力性，非常事件通常会带来不良影响，需要控制方法来预防这些事件发生。在这个工作中，我们介绍了控制意识阶层网络（Ca-ESN），它可以联合 ESN 和控制策略，如比例Integral Derivative 控制和模型预测控制，以抑制非常事件。我们在湍流中使用这种方法，可以与传统方法比较，大大降低非常事件的发生频率，具体来说，降低了两个数量级。这个研究开启了非线性系统控制的新可能性。
</details></li>
</ul>
<hr>
<h2 id="Visualization-of-Extremely-Sparse-Contingency-Table-by-Taxicab-Correspondence-Analysis-A-Case-Study-of-Textual-Data"><a href="#Visualization-of-Extremely-Sparse-Contingency-Table-by-Taxicab-Correspondence-Analysis-A-Case-Study-of-Textual-Data" class="headerlink" title="Visualization of Extremely Sparse Contingency Table by Taxicab Correspondence Analysis: A Case Study of Textual Data"></a>Visualization of Extremely Sparse Contingency Table by Taxicab Correspondence Analysis: A Case Study of Textual Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03079">http://arxiv.org/abs/2308.03079</a></li>
<li>repo_url: None</li>
<li>paper_authors: V. Choulakian, J. Allard</li>
<li>for: 这篇论文是用于描述一种Robust Variant of Correspondence Analysis方法，用于可见化EXTREMELY SPARSE ontingency tables。</li>
<li>methods: 这篇论文使用了12+1维度减少方法（t-SNE、UMAP、PHATE等）来Visualize sacred book fragments的文本数据集，该数据集包含590行x8265列。</li>
<li>results: 这篇论文通过使用Robust Variant of Correspondence Analysis方法，可以准确地VisualizeEXTREMELY SPARSE ontingency tables。<details>
<summary>Abstract</summary>
We present an overview of taxicab correspondence analysis, a robust variant of correspondence analysis, for visualization of extremely sparse ontingency tables. In particular we visualize an extremely sparse textual data set of size 590 by 8265 concerning fragments of 8 sacred books recently introduced by Sah and Fokou\'e (2019) and studied quite in detail by (12 + 1) dimension reduction methods (t-SNE, UMAP, PHATE,...) by Ma, Sun and Zou (2022).
</details>
<details>
<summary>摘要</summary>
我们提供了taxicab对应分析的概述，这是对对应分析的一种鲁棒variant，用于可见化极其稀疏的对应表。特别是我们对590行8265列的一个极其稀疏的文本数据集进行可见化，这个数据集是由 Sah和Fokoué（2019）引入的8种圣书的残篇，并由(12+1)维度减少方法（t-SNE、UMAP、PHATE等）进行了详细研究。这个研究是由Ma、Sun和Zou（2022）进行的。
</details></li>
</ul>
<hr>
<h2 id="Study-for-Performance-of-MobileNetV1-and-MobileNetV2-Based-on-Breast-Cancer"><a href="#Study-for-Performance-of-MobileNetV1-and-MobileNetV2-Based-on-Breast-Cancer" class="headerlink" title="Study for Performance of MobileNetV1 and MobileNetV2 Based on Breast Cancer"></a>Study for Performance of MobileNetV1 and MobileNetV2 Based on Breast Cancer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03076">http://arxiv.org/abs/2308.03076</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiuqi Yan</li>
<li>for: 本实验主要目的是研究人工智能在医学领域中的应用，具体来说是比较MobileNetV1和MobileNetV2模型在分类乳腺癌病理图像方面的表现。</li>
<li>methods: 本实验使用了Kaggle上下载的乳腺癌病理图像集进行训练，并对数据集进行 нор化。然后，使用人工智能模型学习下载的数据集，找出图像中的特征并判断乳腺癌是否存在。</li>
<li>results: 实验结果显示，在处理这个数据集时，MobileNetV1表现得更好， validation accuracy和overfit问题在MobileNetV2训练中出现。这表明，在这种情况下，MobileNetV1比MobileNetV2更适合处理乳腺癌病理图像。<details>
<summary>Abstract</summary>
Artificial intelligence is constantly evolving and can provide effective help in all aspects of people's lives. The experiment is mainly to study the use of artificial intelligence in the field of medicine. The purpose of this experiment was to compare which of MobileNetV1 and MobileNetV2 models was better at detecting histopathological images of the breast downloaded at Kaggle. When the doctor looks at the pathological image, there may be errors that lead to errors in judgment, and the observation speed is slow. Rational use of artificial intelligence can effectively reduce the error of doctor diagnosis in breast cancer judgment and speed up doctor diagnosis. The dataset was downloaded from Kaggle and then normalized. The basic principle of the experiment is to let the neural network model learn the downloaded data set. Then find the pattern and be able to judge on your own whether breast tissue is cancer. In the dataset, benign tumor pictures and malignant tumor pictures have been classified, of which 198738 are benign tumor pictures and 78, 786 are malignant tumor pictures. After calling MobileNetV1 and MobileNetV2, the dataset is trained separately, the training accuracy and validation accuracy rate are obtained, and the image is drawn. It can be observed that MobileNetV1 has better validation accuracy and overfit during MobileNetV2 training. From the experimental results, it can be seen that in the case of processing this dataset, MobileNetV1 is much better than MobileNetV2.
</details>
<details>
<summary>摘要</summary>
人工智能不断发展，可以帮助人们在各个方面更有效率。这个实验主要是研究人工智能在医学领域的应用。实验的目的是比较MobileNetV1和MobileNetV2模型在Kaggle上下载的乳腺病理图像中的表现。当医生查看病理图像时，可能存在错误，导致诊断错误和诊断速度慢。合理使用人工智能可以有效减少医生诊断乳腺癌判断中的错误和提高诊断速度。数据集来自Kaggle，然后Normalized。实验的基本原则是让神经网络模型学习下载的数据集，然后找出图像的模式，并能够独立判断乳腺癌。在数据集中，恶性肿瘤图像和癌瘤图像分别被分类，总共有198738个恶性肿瘤图像和78786个癌瘤图像。后来MobileNetV1和MobileNetV2都被调用，数据集被训练 separately，训练精度和验证精度分别获得，并将图像绘制出来。可以看到，在处理这个数据集时，MobileNetV1表现更好。
</details></li>
</ul>
<hr>
<h2 id="Comparative-Analysis-of-Epileptic-Seizure-Prediction-Exploring-Diverse-Pre-Processing-Techniques-and-Machine-Learning-Models"><a href="#Comparative-Analysis-of-Epileptic-Seizure-Prediction-Exploring-Diverse-Pre-Processing-Techniques-and-Machine-Learning-Models" class="headerlink" title="Comparative Analysis of Epileptic Seizure Prediction: Exploring Diverse Pre-Processing Techniques and Machine Learning Models"></a>Comparative Analysis of Epileptic Seizure Prediction: Exploring Diverse Pre-Processing Techniques and Machine Learning Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.05176">http://arxiv.org/abs/2308.05176</a></li>
<li>repo_url: None</li>
<li>paper_authors: Md. Simul Hasan Talukder, Rejwan Bin Sulaiman</li>
<li>for: 预测癫痫症诊断</li>
<li>methods: 使用五种机器学习模型（Random Forest、Decision Tree、Extra Trees、Logistic Regression和Gradient Boosting）对电энцефалографи记录进行预测</li>
<li>results: 研究发现，Extra Trees模型在预测癫痫症中表现最佳，其准确率为99.29%，高于其他模型和先前研究的状态码。<details>
<summary>Abstract</summary>
Epilepsy is a prevalent neurological disorder characterized by recurrent and unpredictable seizures, necessitating accurate prediction for effective management and patient care. Application of machine learning (ML) on electroencephalogram (EEG) recordings, along with its ability to provide valuable insights into brain activity during seizures, is able to make accurate and robust seizure prediction an indispensable component in relevant studies. In this research, we present a comprehensive comparative analysis of five machine learning models - Random Forest (RF), Decision Tree (DT), Extra Trees (ET), Logistic Regression (LR), and Gradient Boosting (GB) - for the prediction of epileptic seizures using EEG data. The dataset underwent meticulous preprocessing, including cleaning, normalization, outlier handling, and oversampling, ensuring data quality and facilitating accurate model training. These preprocessing techniques played a crucial role in enhancing the models' performance. The results of our analysis demonstrate the performance of each model in terms of accuracy. The LR classifier achieved an accuracy of 56.95%, while GB and DT both attained 97.17% accuracy. RT achieved a higher accuracy of 98.99%, while the ET model exhibited the best performance with an accuracy of 99.29%. Our findings reveal that the ET model outperformed not only the other models in the comparative analysis but also surpassed the state-of-the-art results from previous research. The superior performance of the ET model makes it a compelling choice for accurate and robust epileptic seizure prediction using EEG data.
</details>
<details>
<summary>摘要</summary>
“艾滋症是一种常见的神经疾病，具有不可预测的发作和重复的发作，因此需要精准的预测以便有效地管理和照顾病人。在这些研究中，我们展示了五种机器学习模型（Random Forest、Decision Tree、Extra Trees、Logistic Regression和Gradient Boosting）在艾滋症发作预测中的比较分析。这个数据集经过了精益的清洁、调整、异常处理和扩充，以确保数据质量和模型训练的准确性。这些预处理技术在提高模型表现方面扮演了关键的角色。我们的分析结果显示每个模型的精度，LR分类器获得56.95%的精度，而GB和DT均获得97.17%的精度。RT获得98.99%的精度，而ET模型则表现出99.29%的精度。我们的发现表明ET模型不仅在比较分析中表现出色，而且超越了过去研究中的州前成果。ET模型的超越表现使其成为精确和可靠的艾滋症发作预测中的首选。”
</details></li>
</ul>
<hr>
<h2 id="TARJAMAT-Evaluation-of-Bard-and-ChatGPT-on-Machine-Translation-of-Ten-Arabic-Varieties"><a href="#TARJAMAT-Evaluation-of-Bard-and-ChatGPT-on-Machine-Translation-of-Ten-Arabic-Varieties" class="headerlink" title="TARJAMAT: Evaluation of Bard and ChatGPT on Machine Translation of Ten Arabic Varieties"></a>TARJAMAT: Evaluation of Bard and ChatGPT on Machine Translation of Ten Arabic Varieties</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03051">http://arxiv.org/abs/2308.03051</a></li>
<li>repo_url: None</li>
<li>paper_authors: Karima Kadaoui, Samar M. Magdy, Abdul Waheed, Md Tawkat Islam Khondaker, Ahmed Oumar El-Shangiti, El Moatez Billah Nagoudi, Muhammad Abdul-Mageed</li>
<li>for: The paper assesses the machine translation proficiencies of large language models (LLMs) like Google Bard and OpenAI ChatGPT across ten varieties of Arabic, including Classical Arabic and several dialectal variants.</li>
<li>methods: The paper evaluates the performance of LLMs in machine translation tasks, using diverse Arabic varieties and a human-centric study to scrutinize the models’ ability to follow human instructions.</li>
<li>results: The paper finds that LLMs exhibit satisfactory performance with more prevalent Arabic dialects, but encounter challenges with certain dialects, such as Algerian and Mauritanian, which have limited public data. Additionally, the paper reveals that Bard has limited ability to align with human instructions in translation contexts.<details>
<summary>Abstract</summary>
Large language models (LLMs) finetuned to follow human instructions have recently emerged as a breakthrough in AI. Models such as Google Bard and OpenAI ChatGPT, for example, are surprisingly powerful tools for question answering, code debugging, and dialogue generation. Despite the purported multilingual proficiency of these models, their linguistic inclusivity remains insufficiently explored. Considering this constraint, we present a thorough assessment of Bard and ChatGPT (encompassing both GPT-3.5 and GPT-4) regarding their machine translation proficiencies across ten varieties of Arabic. Our evaluation covers diverse Arabic varieties such as Classical Arabic, Modern Standard Arabic, and several nuanced dialectal variants. Furthermore, we undertake a human-centric study to scrutinize the efficacy of the most recent model, Bard, in following human instructions during translation tasks. Our exhaustive analysis indicates that LLMs may encounter challenges with certain Arabic dialects, particularly those for which minimal public data exists, such as Algerian and Mauritanian dialects. However, they exhibit satisfactory performance with more prevalent dialects, albeit occasionally trailing behind established commercial systems like Google Translate. Additionally, our analysis reveals a circumscribed capability of Bard in aligning with human instructions in translation contexts. Collectively, our findings underscore that prevailing LLMs remain far from inclusive, with only limited ability to cater for the linguistic and cultural intricacies of diverse communities.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM），如Google Bard和OpenAI ChatGPT，最近在人工智能领域受到了突破。这些模型在问答、代码调试和对话生成等方面表现出了惊人的能力。然而，这些模型在语言多样性方面的探索仍然不充分。为了解决这个问题，我们对Bard和ChatGPT进行了详细的评估，包括GPT-3.5和GPT-4在内的多种阿拉伯语种。我们的评估覆盖了多种阿拉伯语种，包括古典阿拉伯语、现代标准阿拉伯语以及一些细腻的地方语言变体。此外，我们进行了人类中心的研究，以评估Bard在翻译任务中遵循人类指令的能力。我们的详细分析表明，LLMs可能会在某些阿拉伯语言口语中遇到困难，特别是那些具有少量公共数据的语言，如阿尔及利亚和毛里塔尼亚口语。然而，它们在更常见的口语上表现得更好，尽管 occasionally 落后于商业系统如Google Translate。此外，我们的分析还发现了Bard在翻译任务中遵循人类指令的能力有限。总的来说，我们的发现表明，现有的LLMs仍然远离包容，它们只能部分地适应不同社区的语言和文化特点。
</details></li>
</ul>
<hr>
<h2 id="Weakly-Supervised-Multi-Task-Representation-Learning-for-Human-Activity-Analysis-Using-Wearables"><a href="#Weakly-Supervised-Multi-Task-Representation-Learning-for-Human-Activity-Analysis-Using-Wearables" class="headerlink" title="Weakly Supervised Multi-Task Representation Learning for Human Activity Analysis Using Wearables"></a>Weakly Supervised Multi-Task Representation Learning for Human Activity Analysis Using Wearables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03805">http://arxiv.org/abs/2308.03805</a></li>
<li>repo_url: None</li>
<li>paper_authors: Taoran Sheng, Manfred Huber</li>
<li>for: 这个论文主要针对的是如何使用弱监督多输出siamesenet对着活动和气象数据进行分类和识别。</li>
<li>methods: 该方法使用弱监督多输出siamesenet，该模型可以将数据映射到多个表示空间中，每个表示空间强调一个特定方面的数据。</li>
<li>results: 经过实验 validate，该模型可以同时解决多个任务，并且在许多情况下可以超越单任务监督方法的性能。此外， paper还进一步分析了模型的架构和多任务内部的效果，以及模型的可扩展性。<details>
<summary>Abstract</summary>
Sensor data streams from wearable devices and smart environments are widely studied in areas like human activity recognition (HAR), person identification, or health monitoring. However, most of the previous works in activity and sensor stream analysis have been focusing on one aspect of the data, e.g. only recognizing the type of the activity or only identifying the person who performed the activity. We instead propose an approach that uses a weakly supervised multi-output siamese network that learns to map the data into multiple representation spaces, where each representation space focuses on one aspect of the data. The representation vectors of the data samples are positioned in the space such that the data with the same semantic meaning in that aspect are closely located to each other. Therefore, as demonstrated with a set of experiments, the trained model can provide metrics for clustering data based on multiple aspects, allowing it to address multiple tasks simultaneously and even to outperform single task supervised methods in many situations. In addition, further experiments are presented that in more detail analyze the effect of the architecture and of using multiple tasks within this framework, that investigate the scalability of the model to include additional tasks, and that demonstrate the ability of the framework to combine data for which only partial relationship information with respect to the target tasks is available.
</details>
<details>
<summary>摘要</summary>
感知数据流从智能设备和智能环境中获取，广泛研究在人动作识别（HAR）、人员识别和健康监测等领域。然而，大多数前一些研究在活动和感知流分析中都是专注一个方面的数据，例如只Recognize the type of activity或只是识别执行活动的人。我们提议一种使用弱监督多输出siamesenet，将数据映射到多个表示空间，每个表示空间都关注一个数据方面。数据样本的表示 вектор在空间中位置，使得同Semantic meaning的数据在该方面都很接近。因此，通过实验证明，训练模型可以为多个任务提供分 clustering  metrics，使其能同时解决多个任务，甚至在许多情况下超越单任务超级vised方法。此外，进一步的实验还分析了architecture的影响和多个任务在这种框架中的使用情况，证明模型可以扩展到包括更多任务，并且可以将部分相关信息的数据组合成一起进行分析。
</details></li>
</ul>
<hr>
<h2 id="Machine-learning-methods-for-the-search-for-L-T-brown-dwarfs-in-the-data-of-modern-sky-surveys"><a href="#Machine-learning-methods-for-the-search-for-L-T-brown-dwarfs-in-the-data-of-modern-sky-surveys" class="headerlink" title="Machine learning methods for the search for L&amp;T brown dwarfs in the data of modern sky surveys"></a>Machine learning methods for the search for L&amp;T brown dwarfs in the data of modern sky surveys</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03045">http://arxiv.org/abs/2308.03045</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iamaleksandra/ml-brown-dwarfs">https://github.com/iamaleksandra/ml-brown-dwarfs</a></li>
<li>paper_authors: Aleksandra Avdeeva</li>
<li>for: 这篇论文的目的是为了开发一种基于机器学习方法的方法，用于分类鲸鱼级和橙级恒星的不同类型。</li>
<li>methods: 这篇论文使用了Random Forest Classifier、XGBoost、SVM Classifier和TabNet等机器学习算法，对PanStarrs DR1、2MASS和WISE数据进行分析，以分类鲸鱼级和橙级恒星。</li>
<li>results: 这篇论文的结果表明，使用机器学习方法可以准确地分类鲸鱼级和橙级恒星，并且比传统的决策规则更有效和相关。<details>
<summary>Abstract</summary>
According to various estimates, brown dwarfs (BD) should account for up to 25 percent of all objects in the Galaxy. However, few of them are discovered and well-studied, both individually and as a population. Homogeneous and complete samples of brown dwarfs are needed for these kinds of studies. Due to their weakness, spectral studies of brown dwarfs are rather laborious. For this reason, creating a significant reliable sample of brown dwarfs, confirmed by spectroscopic observations, seems unattainable at the moment. Numerous attempts have been made to search for and create a set of brown dwarfs using their colours as a decision rule applied to a vast amount of survey data. In this work, we use machine learning methods such as Random Forest Classifier, XGBoost, SVM Classifier and TabNet on PanStarrs DR1, 2MASS and WISE data to distinguish L and T brown dwarfs from objects of other spectral and luminosity classes. The explanation of the models is discussed. We also compare our models with classical decision rules, proving their efficiency and relevance.
</details>
<details>
<summary>摘要</summary>
根据不同的估计，棕矮星（BD）应该占到 галаxy中的25%以上的 объект数。然而，它们的发现和研究很少，个体和人口级别都很少。 homogeneous和完整的褐矮星样本是需要的，以便进行这些类型的研究。由于它们的弱点，褐矮星的spectral studies很困难。因此，创建一个可靠的褐矮星样本，通过spectroscopic observations确认，目前看起来不可能。许多人已经尝试过使用颜色作为决策规则，对大量的survey数据进行搜索和建立褐矮星样本。在这种工作中，我们使用机器学习方法，如Random Forest Classifier、XGBoost、SVM Classifier和TabNet，在PanStarrs DR1、2MASS和WISE数据上分类L和T褐矮星和其他 spectral和 luminosity 类型的 объек数。我们还讲述了模型的解释。我们还比较了我们的模型与经典的决策规则，证明它们的高效和 relevance。
</details></li>
</ul>
<hr>
<h2 id="Machine-Learning-for-Infectious-Disease-Risk-Prediction-A-Survey"><a href="#Machine-Learning-for-Infectious-Disease-Risk-Prediction-A-Survey" class="headerlink" title="Machine Learning for Infectious Disease Risk Prediction: A Survey"></a>Machine Learning for Infectious Disease Risk Prediction: A Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03037">http://arxiv.org/abs/2308.03037</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mutong Liu, Yang Liu, Jiming Liu</li>
<li>for: 这篇论文主要是为了探讨机器学习如何在抑制传染疾病方面发挥作用，以帮助更好地预测传染疾病风险。</li>
<li>methods: 这篇论文使用了不同的机器学习模型来预测传染疾病风险，包括统计预测、数据驱动机器学习和epidemiology-inspired机器学习。</li>
<li>results: 论文结果表明，机器学习可以帮助量化疾病传播模式，并准确预测传染疾病风险。但是，在使用机器学习模型时，需要注意输入数据的问题、设计任务目标和评估模型性能等问题。<details>
<summary>Abstract</summary>
Infectious diseases, either emerging or long-lasting, place numerous people at risk and bring heavy public health burdens worldwide. In the process against infectious diseases, predicting the epidemic risk by modeling the disease transmission plays an essential role in assisting with preventing and controlling disease transmission in a more effective way. In this paper, we systematically describe how machine learning can play an essential role in quantitatively characterizing disease transmission patterns and accurately predicting infectious disease risks. First, we introduce the background and motivation of using machine learning for infectious disease risk prediction. Next, we describe the development and components of various machine learning models for infectious disease risk prediction. Specifically, existing models fall into three categories: Statistical prediction, data-driven machine learning, and epidemiology-inspired machine learning. Subsequently, we discuss challenges encountered when dealing with model inputs, designing task-oriented objectives, and conducting performance evaluation. Finally, we conclude with a discussion of open questions and future directions.
</details>
<details>
<summary>摘要</summary>
免疫疾病，无论是新兴的或长期存在的，对全球公共健康带来沉重负担，数百万人受到威胁。在抗击免疫疾病的过程中，预测疾病传播风险的模型化帮助更有效地预测和控制疾病传播。在这篇文章中，我们系统地描述了机器学习如何在免疫疾病风险预测中发挥重要作用。首先，我们介绍了使用机器学习预测免疫疾病风险的背景和动机。然后，我们描述了不同类型的机器学习模型的开发和组成部分。 especifically，现有模型可以分为三类：统计预测、数据驱动机器学习和epidemiology-inspired机器学习。接着，我们讨论了与模型输入、设计任务指向 objective 和性能评估时遇到的挑战。最后，我们 conclude with 未解决的问题和未来方向。
</details></li>
</ul>
<hr>
<h2 id="Serverless-Federated-AUPRC-Optimization-for-Multi-Party-Collaborative-Imbalanced-Data-Mining"><a href="#Serverless-Federated-AUPRC-Optimization-for-Multi-Party-Collaborative-Imbalanced-Data-Mining" class="headerlink" title="Serverless Federated AUPRC Optimization for Multi-Party Collaborative Imbalanced Data Mining"></a>Serverless Federated AUPRC Optimization for Multi-Party Collaborative Imbalanced Data Mining</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03035">http://arxiv.org/abs/2308.03035</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/xidongwu/d-auprc">https://github.com/xidongwu/d-auprc</a></li>
<li>paper_authors: Xidong Wu, Zhengmian Hu, Jian Pei, Heng Huang</li>
<li>for: 这个论文主要针对多方合作训练（分布式学习和联合学习）在巨量数据挑战中提供解决方案。</li>
<li>methods: 本文提出了一种新的服务器less多方合作AUPRC最大化问题，并将其改编为服务器less多方合作学习中的conditional随机优化问题。furthermore, the authors propose a new ServerLess biAsed sTochastic gradiEnt (SLATE) algorithm to directly optimize the AUPRC, and also propose a variance reduction technique called ServerLess biAsed sTochastic gradiEnt with Momentum-based variance reduction (SLATE-M) algorithm to improve the convergence rate.</li>
<li>results: 本文的实验结果表明，SLATE-M算法可以在多方合作学习 Setting中实现更高的AUPRC最大化，并且与单机端Online方法的最优性较高。此外，SLATE-M算法还可以降低了通信成本，提高了计算效率。<details>
<summary>Abstract</summary>
Multi-party collaborative training, such as distributed learning and federated learning, is used to address the big data challenges. However, traditional multi-party collaborative training algorithms were mainly designed for balanced data mining tasks and are intended to optimize accuracy (\emph{e.g.}, cross-entropy). The data distribution in many real-world applications is skewed and classifiers, which are trained to improve accuracy, perform poorly when applied to imbalanced data tasks since models could be significantly biased toward the primary class. Therefore, the Area Under Precision-Recall Curve (AUPRC) was introduced as an effective metric. Although single-machine AUPRC maximization methods have been designed, multi-party collaborative algorithm has never been studied. The change from the single-machine to the multi-party setting poses critical challenges.   To address the above challenge, we study the serverless multi-party collaborative AUPRC maximization problem since serverless multi-party collaborative training can cut down the communications cost by avoiding the server node bottleneck, and reformulate it as a conditional stochastic optimization problem in a serverless multi-party collaborative learning setting and propose a new ServerLess biAsed sTochastic gradiEnt (SLATE) algorithm to directly optimize the AUPRC. After that, we use the variance reduction technique and propose ServerLess biAsed sTochastic gradiEnt with Momentum-based variance reduction (SLATE-M) algorithm to improve the convergence rate, which matches the best theoretical convergence result reached by the single-machine online method. To the best of our knowledge, this is the first work to solve the multi-party collaborative AUPRC maximization problem.
</details>
<details>
<summary>摘要</summary>
多方合作训练，如分布式学习和联邦学习，用于解决大数据挑战。然而，传统的多方合作训练算法主要是为了均衡数据挖掘任务而设计，并且是为了提高准确率（例如，交叉熵）。然而，在多数实际应用中，数据分布是偏斜的，因此用于偏斜数据任务的分类器可能会在应用于不均衡数据任务时表现差。因此， Area Under Precision-Recall Curve（AUPRC）被引入为有效的指标。虽然单机AUPRC最大化方法已经设计，但多方合作算法尚未被研究。在这种多机到多机的转换中，存在关键挑战。为解决以上挑战，我们研究了无服务器多方合作AUPRC最大化问题，因为无服务器多方合作训练可以避免服务器瓶颈，从而减少通信成本。然后，我们将问题重新定义为无服务器多方合作学习中的Conditional Stochastic Optimization问题，并提出了一个新的ServerLess biAsed sTochastic gradiEnt（SLATE）算法，以直接优化AUPRC。之后，我们使用了偏移量降低技术，并提出了ServerLess biAsed sTochastic gradiEnt with Momentum-based variance reduction（SLATE-M）算法，以提高收敛率，与单机在线方法的最佳理论收敛率相匹配。到目前为止，这是首次解决多方合作AUPRC最大化问题的研究。
</details></li>
</ul>
<hr>
<h2 id="Causal-Disentanglement-Hidden-Markov-Model-for-Fault-Diagnosis"><a href="#Causal-Disentanglement-Hidden-Markov-Model-for-Fault-Diagnosis" class="headerlink" title="Causal Disentanglement Hidden Markov Model for Fault Diagnosis"></a>Causal Disentanglement Hidden Markov Model for Fault Diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03027">http://arxiv.org/abs/2308.03027</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rihao Chang, Yongtao Ma, Weizhi Nie, Jie Nie, An-an Liu</li>
<li>for: 这 paper 的目的是提出一种基于 causal disentanglement hidden Markov model (CDHM) 的 fault diagnosis方法，以实现更加准确的维修预测。</li>
<li>methods: 该方法 使用了时间序列数据，逐步分解震动信号为相关 fault 和无关 fault 因素，并使用 ELBO 优化学习 causal disentanglement Markov model。此外，该方法还采用了无监督领域适应，将学习的分解表示转移到其他工作环境中。</li>
<li>results: 实验结果表明，提出的方法能够在 CWRU 数据集和 IMS 数据集上提供更高的预测精度和维修效率，证明了该方法的优势。<details>
<summary>Abstract</summary>
In modern industries, fault diagnosis has been widely applied with the goal of realizing predictive maintenance. The key issue for the fault diagnosis system is to extract representative characteristics of the fault signal and then accurately predict the fault type. In this paper, we propose a Causal Disentanglement Hidden Markov model (CDHM) to learn the causality in the bearing fault mechanism and thus, capture their characteristics to achieve a more robust representation. Specifically, we make full use of the time-series data and progressively disentangle the vibration signal into fault-relevant and fault-irrelevant factors. The ELBO is reformulated to optimize the learning of the causal disentanglement Markov model. Moreover, to expand the scope of the application, we adopt unsupervised domain adaptation to transfer the learned disentangled representations to other working environments. Experiments were conducted on the CWRU dataset and IMS dataset. Relevant results validate the superiority of the proposed method.
</details>
<details>
<summary>摘要</summary>
现代产业中，FAULT诊断已广泛应用，目的是实现预测维护。FAULT诊断系统的关键问题是提取FAULT信号的代表特征，然后准确预测FAULT类型。在这篇论文中，我们提出了 causal Disentanglement Hidden Markov Model（CDHM），用于学习滤波器FAULT机理的 causality，并从而捕捉其特征，以实现更加稳定的表示。specifically，我们利用时间序列数据，逐步分离振荡信号为FAULT相关和FAULT无关的因素。ELBO被重新表述，以便优化学习 causal Disentanglement Markov model。此外，为扩展应用范围，我们采用了无监督领域适应，将学习的分离表示转移到其他工作环境中。在CWRU数据集和IMS数据集上进行了实验，结果证明了我们提出的方法的优越性。
</details></li>
</ul>
<hr>
<h2 id="Early-Detection-and-Localization-of-Pancreatic-Cancer-by-Label-Free-Tumor-Synthesis"><a href="#Early-Detection-and-Localization-of-Pancreatic-Cancer-by-Label-Free-Tumor-Synthesis" class="headerlink" title="Early Detection and Localization of Pancreatic Cancer by Label-Free Tumor Synthesis"></a>Early Detection and Localization of Pancreatic Cancer by Label-Free Tumor Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03008">http://arxiv.org/abs/2308.03008</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mrgiovanni/synthetictumors">https://github.com/mrgiovanni/synthetictumors</a></li>
<li>paper_authors: Bowen Li, Yu-Cheng Chou, Shuwen Sun, Hualin Qiao, Alan Yuille, Zongwei Zhou</li>
<li>for: 早期检测和诊断肝脏癌可以提高病人5年生存率从8.5%提高到20%.</li>
<li>methods: 我们提出了一种使用人工智能（AI）帮助放射科医生早期检测肝脏癌的方法，但是训练AI模型需要大量的标注示例，但现有CT扫描器获得早期癌病变的示例受限。</li>
<li>results: 我们的实验表明，使用我们提出的合成癌病变方法训练AI模型，对肝脏癌的检测率（敏感性和特异性）和每个块分割性能都达到了与实际癌病变示例相当的水平。此外，我们的方法还显示在小癌病变检测方面更高的检测率。<details>
<summary>Abstract</summary>
Early detection and localization of pancreatic cancer can increase the 5-year survival rate for patients from 8.5% to 20%. Artificial intelligence (AI) can potentially assist radiologists in detecting pancreatic tumors at an early stage. Training AI models require a vast number of annotated examples, but the availability of CT scans obtaining early-stage tumors is constrained. This is because early-stage tumors may not cause any symptoms, which can delay detection, and the tumors are relatively small and may be almost invisible to human eyes on CT scans. To address this issue, we develop a tumor synthesis method that can synthesize enormous examples of small pancreatic tumors in the healthy pancreas without the need for manual annotation. Our experiments demonstrate that the overall detection rate of pancreatic tumors, measured by Sensitivity and Specificity, achieved by AI trained on synthetic tumors is comparable to that of real tumors. More importantly, our method shows a much higher detection rate for small tumors. We further investigate the per-voxel segmentation performance of pancreatic tumors if AI is trained on a combination of CT scans with synthetic tumors and CT scans with annotated large tumors at an advanced stage. Finally, we show that synthetic tumors improve AI generalizability in tumor detection and localization when processing CT scans from different hospitals. Overall, our proposed tumor synthesis method has immense potential to improve the early detection of pancreatic cancer, leading to better patient outcomes.
</details>
<details>
<summary>摘要</summary>
早期发现和确定胰腺癌的患者5年生存率可以从8.5%提高到20%.人工智能（AI）可能能够帮助放射学家早期发现胰腺肿瘤。训练AI模型需要巨量的标注示例，但获得早期阶段肿瘤的CT扫描数据受限。这是因为早期阶段的肿瘤可能没有任何症状，这会延迟发现，同时肿瘤也很小，可能对人类眼不可见在CT扫描中。为解决这个问题，我们开发了一种肿瘤合成方法，可以在健康胰腺中合成巨量的小胰腺肿瘤示例，无需人工标注。我们的实验表明，使用合成肿瘤来训练AI的总检测率（敏感度和特异度）和小肿瘤检测率均与实际肿瘤相当。此外，我们还发现，将合成肿瘤与已知大肿瘤的CT扫描数据组合训练AI，可以提高每个voxel的分 segmentation性能。最后，我们证明了合成肿瘤可以提高AI在不同医院CT扫描数据处理中的普适性。总之，我们提出的肿瘤合成方法具有巨大的潜力，可以提高胰腺癌的早期发现，从而提高病人生存率。
</details></li>
</ul>
<hr>
<h2 id="Deep-Polar-Codes"><a href="#Deep-Polar-Codes" class="headerlink" title="Deep Polar Codes"></a>Deep Polar Codes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03004">http://arxiv.org/abs/2308.03004</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/HzFu/MNet_DeepCDR">https://github.com/HzFu/MNet_DeepCDR</a></li>
<li>paper_authors: Geon Choi, Namyoon Lee</li>
<li>for: 这paper是为了提出一种新的预变扭转码，即深度扭转码。</li>
<li>methods: 这paper使用了一种多层扭转变换的深度编码器，以及一种低复杂度的解码算法Successive Cancellation List with Backpropagation Parity Checks (SCL-BPC)。</li>
<li>results:  simulations表明，深度扭转码在不同的编码率下，对块错误率具有较好的性能，并且可以保持低的编码和解码复杂度。此外，这paper还证明了将深度扭转码 concatenate  avec cyclic-redundancy-check codes可以实现finite block length capacity的meta-converse bound within 0.4 dB。<details>
<summary>Abstract</summary>
In this paper, we introduce a novel class of pre-transformed polar codes, termed as deep polar codes. We first present a deep polar encoder that harnesses a series of multi-layered polar transformations with varying sizes. Our approach to encoding enables a low-complexity implementation while significantly enhancing the weight distribution of the code. Moreover, our encoding method offers flexibility in rate-profiling, embracing a wide range of code rates and blocklengths. Next, we put forth a low-complexity decoding algorithm called successive cancellation list with backpropagation parity checks (SCL-BPC). This decoding algorithm leverages the parity check equations in the reverse process of the multi-layered pre-transformed encoding for SCL decoding. Additionally, we present a low-latency decoding algorithm that employs parallel-SCL decoding by treating partially pre-transformed bit patterns as additional frozen bits. Through simulations, we demonstrate that deep polar codes outperform existing pre-transformed polar codes in terms of block error rates across various code rates under short block lengths, while maintaining low encoding and decoding complexity. Furthermore, we show that concatenating deep polar codes with cyclic-redundancy-check codes can achieve the meta-converse bound of the finite block length capacity within 0.4 dB in some instances.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了一种新的预变扩展极码，称为深度极码。我们首先描述了一种深度极码编码器，利用多层极化转换来实现低复杂性实现，同时有效地改善极码的重量分布。此外，我们的编码方法支持范围广适的代码速率和块长度。接下来，我们提出了一种低复杂度解码算法，称为顺序取消列表归并后传递检查（SCL-BPC）。这种解码算法利用了反向的多层预变扩展编码中的严格检查方程，并且可以在低复杂度下实现高效的解码。此外，我们还提出了一种低延迟解码算法，通过并行执行SCL解码来处理部分预变扩展的位 Pattern。通过实验，我们证明了深度极码在不同代码速率下的块错误率较低，同时保持低编码和解码复杂度。此外，我们还显示了将深度极码与循环检查码 concatenate 可以实现finite block length capacity的meta-converse bound within 0.4 dB 的情况。
</details></li>
</ul>
<hr>
<h2 id="Spanish-Pre-trained-BERT-Model-and-Evaluation-Data"><a href="#Spanish-Pre-trained-BERT-Model-and-Evaluation-Data" class="headerlink" title="Spanish Pre-trained BERT Model and Evaluation Data"></a>Spanish Pre-trained BERT Model and Evaluation Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02976">http://arxiv.org/abs/2308.02976</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dccuchile/beto">https://github.com/dccuchile/beto</a></li>
<li>paper_authors: José Cañete, Gabriel Chaperon, Rodrigo Fuentes, Jou-Hui Ho, Hojin Kang, Jorge Pérez</li>
<li>for:  bridging the gap of Spanish language resources for training and evaluating Spanish language models.</li>
<li>methods:  using BERT-based language model pre-trained exclusively on Spanish data, and compiling several tasks specifically for the Spanish language in a single repository.</li>
<li>results:  fine-tuning the pre-trained Spanish model achieves better results compared to other BERT-based models pre-trained on multilingual corpora for most tasks, and achieves a new state-of-the-art on some tasks.Here’s the format you requested:</li>
<li>for: bridging the gap of Spanish language resources</li>
<li>methods: using BERT-based language model pre-trained exclusively on Spanish data, and compiling several tasks specifically for the Spanish language in a single repository</li>
<li>results: fine-tuning the pre-trained Spanish model achieves better results compared to other BERT-based models pre-trained on multilingual corpora for most tasks, and achieves a new state-of-the-art on some tasks.<details>
<summary>Abstract</summary>
The Spanish language is one of the top 5 spoken languages in the world. Nevertheless, finding resources to train or evaluate Spanish language models is not an easy task. In this paper we help bridge this gap by presenting a BERT-based language model pre-trained exclusively on Spanish data. As a second contribution, we also compiled several tasks specifically for the Spanish language in a single repository much in the spirit of the GLUE benchmark. By fine-tuning our pre-trained Spanish model, we obtain better results compared to other BERT-based models pre-trained on multilingual corpora for most of the tasks, even achieving a new state-of-the-art on some of them. We have publicly released our model, the pre-training data, and the compilation of the Spanish benchmarks.
</details>
<details>
<summary>摘要</summary>
西班牙语是全球前5大常用语言之一，但找到用于训练或评估西班牙语模型的资源并不容易。在这篇论文中，我们帮助填补这个差距，提出了基于BERT的西班牙语语言模型，并且在单个存储中集成了许多西班牙语任务。经过练练后的西班牙语模型，在大多数任务上比其他基于多语言Corpus预训练的BERT模型获得更好的结果，甚至达到了一些任务的新状态。我们将公开发布我们的模型、预训练数据和西班牙语benchmark集。
</details></li>
</ul>
<hr>
<h2 id="Generalized-Oversampling-for-Learning-from-Imbalanced-datasets-and-Associated-Theory"><a href="#Generalized-Oversampling-for-Learning-from-Imbalanced-datasets-and-Associated-Theory" class="headerlink" title="Generalized Oversampling for Learning from Imbalanced datasets and Associated Theory"></a>Generalized Oversampling for Learning from Imbalanced datasets and Associated Theory</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02966">http://arxiv.org/abs/2308.02966</a></li>
<li>repo_url: None</li>
<li>paper_authors: Samuel Stocksieker, Denys Pommeret, Arthur Charpentier</li>
<li>for: 这个研究旨在解决受扰数据集的问题，尤其是预测任务中的欠资料问题。</li>
<li>methods: 本研究提出了一个基于核密度估计的数据增强方法，称为GOLIATH算法，可以应用于预测和回归任务。这个方法包括两大家族的人工增加：基于扰动，如 Gaussian Noise，和基于插值，如 SMOTE。它还提供了这些机器学习算法的明确形式和条件密度表达，特别是SMOTE。</li>
<li>results: 本研究评估了GOLIATH算法在受扰数据集中的性能，并与现有的State-of-the-art技术进行比较。结果显示，GOLIATH算法在受扰数据集中具有显著的改善。<details>
<summary>Abstract</summary>
In supervised learning, it is quite frequent to be confronted with real imbalanced datasets. This situation leads to a learning difficulty for standard algorithms. Research and solutions in imbalanced learning have mainly focused on classification tasks. Despite its importance, very few solutions exist for imbalanced regression. In this paper, we propose a data augmentation procedure, the GOLIATH algorithm, based on kernel density estimates which can be used in classification and regression. This general approach encompasses two large families of synthetic oversampling: those based on perturbations, such as Gaussian Noise, and those based on interpolations, such as SMOTE. It also provides an explicit form of these machine learning algorithms and an expression of their conditional densities, in particular for SMOTE. New synthetic data generators are deduced. We apply GOLIATH in imbalanced regression combining such generator procedures with a wild-bootstrap resampling technique for the target values. We evaluate the performance of the GOLIATH algorithm in imbalanced regression situations. We empirically evaluate and compare our approach and demonstrate significant improvement over existing state-of-the-art techniques.
</details>
<details>
<summary>摘要</summary>
在超级vised学习中，很常遇到实际上的不均衡数据集。这种情况会导致标准算法学习困难。研究和解决不均衡学习问题的研究主要集中在分类任务上。尽管它的重要性，实际上很少解决不均衡回归问题的解决方案存在。在这篇论文中，我们提出了一种数据扩充过程，named GOLIATH algorithm，基于kernel density estimates，可以在分类和回归中使用。这种通用的方法包括两大家族的人工增加：基于扰动，如 Gaussian Noise，和基于 interpolations，如 SMOTE。它还提供了这些机器学习算法的明确形式，特别是SMOTE的表达。新的人工数据生成器被推导出来。我们在不均衡回归中结合了这些生成器过程和野生bootstrap抽样技术来针对目标值。我们对GOLIATH算法在不均衡回归情况下的性能进行了实验性评估和比较，并证明了我们的方法在现有状态的技术上具有显著的改善。
</details></li>
</ul>
<hr>
<h2 id="Data-Fusion-for-Multi-Task-Learning-of-Building-Extraction-and-Height-Estimation"><a href="#Data-Fusion-for-Multi-Task-Learning-of-Building-Extraction-and-Height-Estimation" class="headerlink" title="Data Fusion for Multi-Task Learning of Building Extraction and Height Estimation"></a>Data Fusion for Multi-Task Learning of Building Extraction and Height Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02960">http://arxiv.org/abs/2308.02960</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/SaadAhmedJamal/IEEE_DFC2023">https://github.com/SaadAhmedJamal/IEEE_DFC2023</a></li>
<li>paper_authors: Saad Ahmed Jamal, Arioluwa Aribisala</li>
<li>for: 这篇论文是为了解决城市重建问题，使用 optic 和 radar 卫星影像进行多任务学习，实现建筑物抽出和高度估计。</li>
<li>methods: 本论文使用多任务学习方法，将 optic 和 radar 卫星影像融合，实现建筑物抽出和高度估计。</li>
<li>results: 根据设计实验结果，本论文的基准结果显著提高了建筑物抽出和高度估计的精度。<details>
<summary>Abstract</summary>
In accordance with the urban reconstruction problem proposed by the DFC23 Track 2 Contest, this paper attempts a multitask-learning method of building extraction and height estimation using both optical and radar satellite imagery. Contrary to the initial goal of multitask learning which could potentially give a superior solution by reusing features and forming implicit constraints between multiple tasks, this paper reports the individual implementation of the building extraction and height estimation under constraints. The baseline results for the building extraction and the height estimation significantly increased after designed experiments.
</details>
<details>
<summary>摘要</summary>
根据DFC23 Track 2 contest提出的城市重建问题，本文提出了一种多任务学习方法，使用光学和雷达卫星影像进行建筑物提取和高度估计。与初始目标的多任务学习不同，本文对每个任务进行独立实现，并在限制下进行建筑物提取和高度估计。经过设计实验，基准结果显著提高。Note: "多任务学习" in Chinese is "多任务学习" (duō zhòng zhì xué xí), and "光学" and "雷达" are both adjectives, so they are not translated.
</details></li>
</ul>
<hr>
<h2 id="K-band-Self-supervised-MRI-Reconstruction-via-Stochastic-Gradient-Descent-over-K-space-Subsets"><a href="#K-band-Self-supervised-MRI-Reconstruction-via-Stochastic-Gradient-Descent-over-K-space-Subsets" class="headerlink" title="K-band: Self-supervised MRI Reconstruction via Stochastic Gradient Descent over K-space Subsets"></a>K-band: Self-supervised MRI Reconstruction via Stochastic Gradient Descent over K-space Subsets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02958">http://arxiv.org/abs/2308.02958</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mikgroup/k-band">https://github.com/mikgroup/k-band</a></li>
<li>paper_authors: Frederic Wang, Han Qi, Alfredo De Goyeneche, Reinhard Heckel, Michael Lustig, Efrat Shimron</li>
<li>For: This paper aims to develop a novel mathematical framework for training deep learning (DL) models using only partial, limited-resolution k-space data in high-dimensional magnetic resonance imaging (MRI).* Methods: The proposed method, called k-band, uses stochastic gradient descent (SGD) over k-space subsets, where only a small k-space portion is used in each training iteration to compute gradients. The method is compatible with different sampling strategies, and the authors demonstrate its effectiveness using k-space “bands” with limited resolution in one dimension.* Results: The authors prove analytically that their method stochastically approximates the gradients computed in a fully-supervised setup, as long as two conditions are met: (i) the limited-resolution axis is chosen randomly-uniformly for every new scan, and (ii) the loss function is weighed with a mask that facilitates accurate reconstruction of high-resolution details. Numerical experiments with raw MRI data show that k-band outperforms two other methods trained on limited-resolution data and performs comparably to state-of-the-art methods trained on high-resolution data.<details>
<summary>Abstract</summary>
Although deep learning (DL) methods are powerful for solving inverse problems, their reliance on high-quality training data is a major hurdle. This is significant in high-dimensional (dynamic/volumetric) magnetic resonance imaging (MRI), where acquisition of high-resolution fully sampled k-space data is impractical. We introduce a novel mathematical framework, dubbed k-band, that enables training DL models using only partial, limited-resolution k-space data. Specifically, we introduce training with stochastic gradient descent (SGD) over k-space subsets. In each training iteration, rather than using the fully sampled k-space for computing gradients, we use only a small k-space portion. This concept is compatible with different sampling strategies; here we demonstrate the method for k-space "bands", which have limited resolution in one dimension and can hence be acquired rapidly. We prove analytically that our method stochastically approximates the gradients computed in a fully-supervised setup, when two simple conditions are met: (i) the limited-resolution axis is chosen randomly-uniformly for every new scan, hence k-space is fully covered across the entire training set, and (ii) the loss function is weighed with a mask, derived here analytically, which facilitates accurate reconstruction of high-resolution details. Numerical experiments with raw MRI data indicate that k-band outperforms two other methods trained on limited-resolution data and performs comparably to state-of-the-art (SoTA) methods trained on high-resolution data. k-band hence obtains SoTA performance, with the advantage of training using only limited-resolution data. This work hence introduces a practical, easy-to-implement, self-supervised training framework, which involves fast acquisition and self-supervised reconstruction and offers theoretical guarantees.
</details>
<details>
<summary>摘要</summary>
although deep learning (DL) methods are powerful for solving inverse problems, their reliance on high-quality training data is a major hurdle. This is significant in high-dimensional (dynamic/volumetric) magnetic resonance imaging (MRI), where acquiring high-resolution fully sampled k-space data is impractical. We introduce a novel mathematical framework, dubbed k-band, that enables training DL models using only partial, limited-resolution k-space data. Specifically, we introduce training with stochastic gradient descent (SGD) over k-space subsets. In each training iteration, rather than using the fully sampled k-space for computing gradients, we only use a small k-space portion. This concept is compatible with different sampling strategies; here we demonstrate the method for k-space "bands", which have limited resolution in one dimension and can hence be acquired rapidly. We prove analytically that our method stochastically approximates the gradients computed in a fully-supervised setup, when two simple conditions are met: (i) the limited-resolution axis is chosen randomly and uniformly for every new scan, hence k-space is fully covered across the entire training set, and (ii) the loss function is weighed with a mask, derived here analytically, which facilitates accurate reconstruction of high-resolution details. Numerical experiments with raw MRI data indicate that k-band outperforms two other methods trained on limited-resolution data and performs comparably to state-of-the-art (SoTA) methods trained on high-resolution data. k-band hence obtains SoTA performance, with the advantage of training using only limited-resolution data. This work hence introduces a practical, easy-to-implement, self-supervised training framework, which involves fast acquisition and self-supervised reconstruction and offers theoretical guarantees.Here's the translation in Traditional Chinese:虽然深度学习（DL）方法有着解决反射问题的力量，但它们对高品质训练数据的依赖是一个主要的阻碍。这特别是在高维度（动态/体积）磁共振成像（MRI）中，其中高分辨率完整探测空间数据的取得是不实际的。我们提出了一个新的数学框架，名为k-band，可以使用仅有部分、有限分辨率的k-空间数据进行深度学习模型的训练。具体来说，我们引入了使用测出梯度的测出梯度运算，并在每个训练迭代中仅使用k-空间中的一小部分。这个概念可以与不同的采样策略相容，在这里我们示例了使用k-空间"带"，它们在一个维度上有限的分辨率，并可以快速地取得。我们 analytically prove了我们的方法可以随机地近似fully-supervised setup中的梯度，只要两个简单的条件是满足的：（i）在每个新的扫描中，Randomly and uniformly chooses the limited-resolution axis，使得k-space是全面覆盖整个训练集，并（ii）使用一个 analytically derived 的mask，来减轻高分辨率细节的重建。numero Experiments with raw MRI data indicate that k-band outperforms two other methods trained on limited-resolution data and performs comparably to state-of-the-art (SoTA) methods trained on high-resolution data. k-band hence obtains SoTA performance, with the advantage of training using only limited-resolution data. This work hence introduces a practical, easy-to-implement, self-supervised training framework, which involves fast acquisition and self-supervised reconstruction and offers theoretical guarantees.
</details></li>
</ul>
<hr>
<h2 id="An-Empirical-Study-of-AI-based-Smart-Contract-Creation"><a href="#An-Empirical-Study-of-AI-based-Smart-Contract-Creation" class="headerlink" title="An Empirical Study of AI-based Smart Contract Creation"></a>An Empirical Study of AI-based Smart Contract Creation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02955">http://arxiv.org/abs/2308.02955</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rabimba Karanjai, Edward Li, Lei Xu, Weidong Shi</li>
<li>for: 本研究旨在评估大语言模型（LLM）如ChatGPT和Google Palm2在智能合约生成方面的可能性。</li>
<li>methods: 本研究使用了LLMs对智能合约的生成，并评估了生成代码的质量。</li>
<li>results: 研究发现，通过LLMs生成的合约存在安全漏洞，且代码质量和正确性受到输入参数质量的影响。但是，还有一些可能的改进方向。<details>
<summary>Abstract</summary>
The introduction of large language models (LLMs) like ChatGPT and Google Palm2 for smart contract generation seems to be the first well-established instance of an AI pair programmer. LLMs have access to a large number of open-source smart contracts, enabling them to utilize more extensive code in Solidity than other code generation tools. Although the initial and informal assessments of LLMs for smart contract generation are promising, a systematic evaluation is needed to explore the limits and benefits of these models. The main objective of this study is to assess the quality of generated code provided by LLMs for smart contracts. We also aim to evaluate the impact of the quality and variety of input parameters fed to LLMs. To achieve this aim, we created an experimental setup for evaluating the generated code in terms of validity, correctness, and efficiency. Our study finds crucial evidence of security bugs getting introduced in the generated smart contracts as well as the overall quality and correctness of the code getting impacted. However, we also identified the areas where it can be improved. The paper also proposes several potential research directions to improve the process, quality and safety of generated smart contract codes.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLMs）如ChatGPT和Google Palm2的出现在智能合约生成中似乎是首次成功的AI对应程式设计。LLMs有 Access to a large number of open-source smart contracts， allowing them to use more extensive code in Solidity than other code generation tools. Although the initial and informal assessments of LLMs for smart contract generation are promising, a systematic evaluation is needed to explore the limits and benefits of these models. 本研究的主要目的是评估由LLMs生成的智能合约程式码的质量。我们还想评估对LLMs输入参数的影响，以及生成的程式码的安全性和正确性。为了实现这个目标，我们创建了一个实验setup来评估生成的程式码，包括验证、正确性和效率。我们的研究发现，由LLMs生成的智能合约程式码中有许多安全漏洞，并且程式码的全面性和正确性受到影响。但我们也发现了改进这些模型的可能性。本研究的结论提出了多个可能的研究方向，以改善生成的程式码质量、安全性和可靠性。
</details></li>
</ul>
<hr>
<h2 id="dPASP-A-Comprehensive-Differentiable-Probabilistic-Answer-Set-Programming-Environment-For-Neurosymbolic-Learning-and-Reasoning"><a href="#dPASP-A-Comprehensive-Differentiable-Probabilistic-Answer-Set-Programming-Environment-For-Neurosymbolic-Learning-and-Reasoning" class="headerlink" title="dPASP: A Comprehensive Differentiable Probabilistic Answer Set Programming Environment For Neurosymbolic Learning and Reasoning"></a>dPASP: A Comprehensive Differentiable Probabilistic Answer Set Programming Environment For Neurosymbolic Learning and Reasoning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02944">http://arxiv.org/abs/2308.02944</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renato Lui Geh, Jonas Gonçalves, Igor Cataneo Silveira, Denis Deratani Mauá, Fabio Gagliardi Cozman</li>
<li>for: 本文描述了一种新的宣言式概率逻辑编程框架dPASP，用于不同推理和统计知识的结合。</li>
<li>methods: 本文使用了逻辑约束、间值概率选择和神经预测来表示不确定、矛盾、不完整和统计知识。</li>
<li>results: 本文介绍了一种可以执行推理和学习的实现包，包括一些示例程序，并讨论了在不同语义下的梯度下降学习。<details>
<summary>Abstract</summary>
We present dPASP, a novel declarative probabilistic logic programming framework for differentiable neuro-symbolic reasoning. The framework allows for the specification of discrete probabilistic models with neural predicates, logic constraints and interval-valued probabilistic choices, thus supporting models that combine low-level perception (images, texts, etc), common-sense reasoning, and (vague) statistical knowledge. To support all such features, we discuss the several semantics for probabilistic logic programs that can express nondeterministic, contradictory, incomplete and/or statistical knowledge. We also discuss how gradient-based learning can be performed with neural predicates and probabilistic choices under selected semantics. We then describe an implemented package that supports inference and learning in the language, along with several example programs. The package requires minimal user knowledge of deep learning system's inner workings, while allowing end-to-end training of rather sophisticated models and loss functions.
</details>
<details>
<summary>摘要</summary>
我们介绍了dpasp，一种新的声明型概率逻辑编程框架，用于可微分神经符号逻辑推理。这个框架允许用户指定混合低级感知（图像、文本等）、通用理智、混乱统计知识的概率模型。为支持这些特点，我们讨论了几种概率逻辑程序的 semantics，可以表达非束缚、矛盾、不完整和/或统计知识。我们还讨论了如何在选定 semantics 下使用神经 predicate 和概率选择来进行梯度基于学习。然后，我们描述了一个实现的包，包括推理和学习语言中的许多示例程序。这个包需要最少的用户知识 deep learning 系统的内部工作，同时允许用户实现较复杂的模型和损失函数的整体训练。
</details></li>
</ul>
<hr>
<h2 id="Towards-the-Development-of-an-Uncertainty-Quantification-Protocol-for-the-Natural-Gas-Industry"><a href="#Towards-the-Development-of-an-Uncertainty-Quantification-Protocol-for-the-Natural-Gas-Industry" class="headerlink" title="Towards the Development of an Uncertainty Quantification Protocol for the Natural Gas Industry"></a>Towards the Development of an Uncertainty Quantification Protocol for the Natural Gas Industry</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02941">http://arxiv.org/abs/2308.02941</a></li>
<li>repo_url: None</li>
<li>paper_authors: Babajide Kolade</li>
<li>for: 这个论文的目的是为了开发一种用于评估机器学习和机理模型预测结果的不确定性评估协议。</li>
<li>methods: 这个论文使用了机器学习模型和机理模型来进行预测，并使用了不确定性评估协议来评估模型的可靠性。</li>
<li>results: 该论文通过应用不确定性评估协议来评估机器学习和机理模型的预测结果的不确定性，并提供了一些可靠性评估的方法和技术。<details>
<summary>Abstract</summary>
Simulations using machine learning (ML) models and mechanistic models are often run to inform decision-making processes. Uncertainty estimates of simulation results are critical to the decision-making process because simulation results of specific scenarios may have wide, but unspecified, confidence bounds that may impact subsequent analyses and decisions. The objective of this work is to develop a protocol to assess uncertainties in predictions of machine learning and mechanistic simulation models. The protocol will outline an uncertainty quantification workflow that may be used to establish credible bounds of predictability on computed quantities of interest and to assess model sufficiency. The protocol identifies key sources of uncertainties in machine learning and mechanistic modeling, defines applicable methods of uncertainty propagation for these sources, and includes statistically rational estimators for output uncertainties. The work applies the protocol to test cases relevant to the gas distribution industry and presents learnings from its application. The paper concludes with a brief discussion outlining a pathway to the wider adoption of uncertainty quantification within the industry
</details>
<details>
<summary>摘要</summary>
模拟使用机器学习（ML）模型和机理模型经常用于决策过程中，以便更好地了解不同情况下的结果。模拟结果中的uncertainty estimate是决策过程中非常重要的，因为模拟结果的特定情况可能有很宽，但不具体的信任范围，这可能会影响后续分析和决策。本工作的目标是开发一个协议，用于评估机器学习和机理模型预测结果中的不确定性。协议将 outline一个不确定性评估工作流程，可以用来确定计算量表达的可靠范围，并评估模型的充分性。协议将列出机器学习和机理模型中的主要不确定性源泉，并定义这些源泉上适用的不确定性传播方法，并包括输出不确定性的统计合理估计。本工作将应用协议到与天然气分布业有关的测试 случа例，并显示其应用的教训。文章结束于对在业界更广泛采用不确定性评估的道路的简要讨论。
</details></li>
</ul>
<hr>
<h2 id="Towards-Consistency-Filtering-Free-Unsupervised-Learning-for-Dense-Retrieval"><a href="#Towards-Consistency-Filtering-Free-Unsupervised-Learning-for-Dense-Retrieval" class="headerlink" title="Towards Consistency Filtering-Free Unsupervised Learning for Dense Retrieval"></a>Towards Consistency Filtering-Free Unsupervised Learning for Dense Retrieval</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02926">http://arxiv.org/abs/2308.02926</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Haoxiang-WasedaU/Towards-Consistency-Filtering-Free-Unsupervised-Learning-for-Dense-Retrieval">https://github.com/Haoxiang-WasedaU/Towards-Consistency-Filtering-Free-Unsupervised-Learning-for-Dense-Retrieval</a></li>
<li>paper_authors: Haoxiang Shi, Sumio Fujita, Tetsuya Sakai</li>
<li>for:  overcome domain transfer challenge in modern neural Information Retrieval (IR)</li>
<li>methods:  replace consistency filter with direct pseudo-labeling, pseudo-relevance feedback, or unsupervised keyword generation methods</li>
<li>results:  TextRank-based pseudo relevance feedback outperforms other methods, and filtering-free unsupervised learning can continuously improve training and inference efficiency while maintaining retrieval performance.Here’s the full text in Simplified Chinese:</li>
<li>for: 本研究旨在解决现代神经信息检索（IR）中的域转换问题。</li>
<li>methods: 我们提议取代了统计过程的一致性筛选器，使用直接 Pseudo-labeling、Pseudo- relevance feedback 或无监督关键词生成方法。</li>
<li>results: 我们的广泛的实验证明，TextRank-based Pseudo relevance feedback 方法在其他方法之上表现更出色，并且 filtering-free 无监督学习可以不断提高训练和推理效率，同时保持检索性能。<details>
<summary>Abstract</summary>
Domain transfer is a prevalent challenge in modern neural Information Retrieval (IR). To overcome this problem, previous research has utilized domain-specific manual annotations and synthetic data produced by consistency filtering to finetune a general ranker and produce a domain-specific ranker. However, training such consistency filters are computationally expensive, which significantly reduces the model efficiency. In addition, consistency filtering often struggles to identify retrieval intentions and recognize query and corpus distributions in a target domain. In this study, we evaluate a more efficient solution: replacing the consistency filter with either direct pseudo-labeling, pseudo-relevance feedback, or unsupervised keyword generation methods for achieving consistent filtering-free unsupervised dense retrieval. Our extensive experimental evaluations demonstrate that, on average, TextRank-based pseudo relevance feedback outperforms other methods. Furthermore, we analyzed the training and inference efficiency of the proposed paradigm. The results indicate that filtering-free unsupervised learning can continuously improve training and inference efficiency while maintaining retrieval performance. In some cases, it can even improve performance based on particular datasets.
</details>
<details>
<summary>摘要</summary>
域名转移是现代神经信息检索（IR）中的一大挑战。以前的研究使用域名特定的手动标注和生成的域名特定排序器来训练一个通用排序器，以便在目标域名中提高检索性能。然而，训练这些一致性筛选器是计算机Expensive，这会significantly reduces the model efficiency。另外，一致性筛选器经常难以识别检索目的和查询和文献库的分布。在这种研究中，我们评估了一种更有效的解决方案：取代一致性筛选器，使用直接 Pseudo-labeling、pseudo relevance feedback 或无监督关键词生成方法来实现一致性自由无监督检索。我们进行了广泛的实验评估，结果表明，使用 TextRank 基于 Pseudo relevance feedback 的方法在 average 上超过其他方法。此外，我们还分析了提议的训练和执行效率。结果表明，无监督自由学习可以不断提高训练和执行效率，同时保持检索性能。在某些情况下，它甚至可以提高基于特定数据集的性能。
</details></li>
</ul>
<hr>
<h2 id="An-AI-Enabled-Framework-to-Defend-Ingenious-MDT-based-Attacks-on-the-Emerging-Zero-Touch-Cellular-Networks"><a href="#An-AI-Enabled-Framework-to-Defend-Ingenious-MDT-based-Attacks-on-the-Emerging-Zero-Touch-Cellular-Networks" class="headerlink" title="An AI-Enabled Framework to Defend Ingenious MDT-based Attacks on the Emerging Zero Touch Cellular Networks"></a>An AI-Enabled Framework to Defend Ingenious MDT-based Attacks on the Emerging Zero Touch Cellular Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02923">http://arxiv.org/abs/2308.02923</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aneeqa Ijaz, Waseem Raza, Hasan Farooq, Marvin Manalastas, Ali Imran</li>
<li>for:  This paper aims to address the security threats in deeply automated wireless networks and IoT devices, specifically the vulnerability of MDT reports to adversarial attacks.</li>
<li>methods:  The paper proposes a novel Malicious MDT Reports Identification framework (MRIF) using Machine Learning to detect and eliminate malicious MDT reports, and verifies its effectiveness through a use-case.</li>
<li>results:  The paper highlights the detrimental repercussions of adversarial attacks on MDT reports on the performance of common network automation functions, and proposes a countermeasure to defend against such attacks.<details>
<summary>Abstract</summary>
Deep automation provided by self-organizing network (SON) features and their emerging variants such as zero touch automation solutions is a key enabler for increasingly dense wireless networks and pervasive Internet of Things (IoT). To realize their objectives, most automation functionalities rely on the Minimization of Drive Test (MDT) reports. The MDT reports are used to generate inferences about network state and performance, thus dynamically change network parameters accordingly. However, the collection of MDT reports from commodity user devices, particularly low cost IoT devices, make them a vulnerable entry point to launch an adversarial attack on emerging deeply automated wireless networks. This adds a new dimension to the security threats in the IoT and cellular networks. Existing literature on IoT, SON, or zero touch automation does not address this important problem. In this paper, we investigate an impactful, first of its kind adversarial attack that can be launched by exploiting the malicious MDT reports from the compromised user equipment (UE). We highlight the detrimental repercussions of this attack on the performance of common network automation functions. We also propose a novel Malicious MDT Reports Identification framework (MRIF) as a countermeasure to detect and eliminate the malicious MDT reports using Machine Learning and verify it through a use-case. Thus, the defense mechanism can provide the resilience and robustness for zero touch automation SON engines against the adversarial MDT attacks
</details>
<details>
<summary>摘要</summary>
深层自动化由自组织网络（SON）特点和其出现的变种，如零Touch自动化解决方案，是无线网络和互联网物联网（IoT）的关键加速器。为实现这些目标，大多数自动化功能都依赖于推定测试（MDT）报告。MDT报告可以生成对网络状态和性能的推理，因此动态改变网络参数。然而，从低成本IoT设备收集MDT报告，特别是低成本IoT设备，使得它们成为发动对新型深层自动化无线网络的敌意攻击的易受到攻击的入口点。这添加了新的安全隐患到互联网和无线网络中。现有的文献中关于IoT、SON或零Touch自动化没有讨论这个重要问题。在这篇论文中，我们调查了一种新型的攻击，可以通过利用受到恶意MDT报告的用户设备（UE）进行攻击。我们强调了这种攻击对常见网络自动化功能的负面影响。我们还提出了一个新的恶意MDT报告标识框架（MRIF）作为一种对抗手段，通过机器学习来检测和消除恶意MDT报告，并通过用例验证。因此，防御机制可以为零Touch自动化SON引擎提供防御力和坚固性，抵御攻击。
</details></li>
</ul>
<hr>
<h2 id="Structured-Low-Rank-Tensors-for-Generalized-Linear-Models"><a href="#Structured-Low-Rank-Tensors-for-Generalized-Linear-Models" class="headerlink" title="Structured Low-Rank Tensors for Generalized Linear Models"></a>Structured Low-Rank Tensors for Generalized Linear Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02922">http://arxiv.org/abs/2308.02922</a></li>
<li>repo_url: None</li>
<li>paper_authors: Batoul Taki, Anand D. Sarwate, Waheed U. Bajwa</li>
<li>for: 这个论文研究了一种新的低级别矩阵模型（LSR），用于通用线性模型（GLM）问题。</li>
<li>methods: 该论文提出了一种块坐标枢车算法来参数估计LSR结构矩阵GLM问题。</li>
<li>results: 论文 derive了一个最小最大下界，用于评估矩阵GLM问题中参数估计的误差阈值。该下界与矩阵GLM问题的自然度相比，表明sample complexity可能会比vectorized GLMs更低。此外，论文还进行了数值分析，并在 synthetic 数据上进行了三种类型的回归（线性、逻辑和波尔兹）的实验，以及一些医学成像数据上的实验。<details>
<summary>Abstract</summary>
Recent works have shown that imposing tensor structures on the coefficient tensor in regression problems can lead to more reliable parameter estimation and lower sample complexity compared to vector-based methods. This work investigates a new low-rank tensor model, called Low Separation Rank (LSR), in Generalized Linear Model (GLM) problems. The LSR model -- which generalizes the well-known Tucker and CANDECOMP/PARAFAC (CP) models, and is a special case of the Block Tensor Decomposition (BTD) model -- is imposed onto the coefficient tensor in the GLM model. This work proposes a block coordinate descent algorithm for parameter estimation in LSR-structured tensor GLMs. Most importantly, it derives a minimax lower bound on the error threshold on estimating the coefficient tensor in LSR tensor GLM problems. The minimax bound is proportional to the intrinsic degrees of freedom in the LSR tensor GLM problem, suggesting that its sample complexity may be significantly lower than that of vectorized GLMs. This result can also be specialised to lower bound the estimation error in CP and Tucker-structured GLMs. The derived bounds are comparable to tight bounds in the literature for Tucker linear regression, and the tightness of the minimax lower bound is further assessed numerically. Finally, numerical experiments on synthetic datasets demonstrate the efficacy of the proposed LSR tensor model for three regression types (linear, logistic and Poisson). Experiments on a collection of medical imaging datasets demonstrate the usefulness of the LSR model over other tensor models (Tucker and CP) on real, imbalanced data with limited available samples.
</details>
<details>
<summary>摘要</summary>
近期研究表明，在回归问题中强制材料结构 onto 参数矩阵可以导致更可靠的参数估计和较低的样本复杂度，相比 vector-based 方法。这个工作研究了一种新的低级别张量模型，called Low Separation Rank (LSR)，在泛化线性模型 (GLM) 问题中。LSR 模型总结了已知的各种 Tucker 和 CANDECOMP/PARAFAC (CP) 模型，并是特殊情况的块张量分解 (BTD) 模型。这个工作提出了基于块坐标推导法的参数估计算法，并 derivates 一个最小最大下界对 GLM 问题中参数矩阵的估计误差。这个下界与 LSR 张量 GLM 问题中参数矩阵的内在度量相对，表明其样本复杂度可能远低于vectorized GLMs。此外，这个结果还可以特殊化到 CP 和 Tucker 结构 GLM 问题中。经过数学分析和实验 validate，这个下界与文献中已知的精细度下界相当。最后，数值实验表明LSR 张量模型在三种回归类型（线性回归、逻辑回归和波恩回归）中具有出色的效果，并在实际医疗影像数据上进行了比较。
</details></li>
</ul>
<hr>
<h2 id="Spectral-Ranking-Inferences-based-on-General-Multiway-Comparisons"><a href="#Spectral-Ranking-Inferences-based-on-General-Multiway-Comparisons" class="headerlink" title="Spectral Ranking Inferences based on General Multiway Comparisons"></a>Spectral Ranking Inferences based on General Multiway Comparisons</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02918">http://arxiv.org/abs/2308.02918</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jianqing Fan, Zhipeng Lou, Weichen Wang, Mengxin Yu</li>
<li>for: 这 paper 研究 spectral method 在对比Entities的偏好分数的估计和不确定性评估中的性能。</li>
<li>methods: paper 使用 spectral method 在一个非常通用和更真实的设定中，其中比较图包含可能不同大小的高阶约束，并且可能只有一个比较。这种设定在实际应用中非常普遍，因此不需要指定图的随机性和PL&#x2F;BTL模型中的均匀采样假设。</li>
<li>results: paper 发现，在适用 BTL&#x2F;PL 模型时，spectral estimator 和 Maximum Likelihood Estimator (MLE) 之间存在关系。furthermore, paper 提出了一种two-step spectral method，可以达到 MLE 的同等效率。此外，paper 还提出了一个涵盖一 Sample和两 Sample 排名推论的完整框架，可以应用于固定图和随机图设定。这是首次提出了有效的两 Sample rank testing 方法。最后，paper 通过了详细的数学实验和应用于统计期刊和电影排名等。<details>
<summary>Abstract</summary>
This paper studies the performance of the spectral method in the estimation and uncertainty quantification of the unobserved preference scores of compared entities in a very general and more realistic setup in which the comparison graph consists of hyper-edges of possible heterogeneous sizes and the number of comparisons can be as low as one for a given hyper-edge. Such a setting is pervasive in real applications, circumventing the need to specify the graph randomness and the restrictive homogeneous sampling assumption imposed in the commonly-used Bradley-Terry-Luce (BTL) or Plackett-Luce (PL) models. Furthermore, in the scenarios when the BTL or PL models are appropriate, we unravel the relationship between the spectral estimator and the Maximum Likelihood Estimator (MLE). We discover that a two-step spectral method, where we apply the optimal weighting estimated from the equal weighting vanilla spectral method, can achieve the same asymptotic efficiency as the MLE. Given the asymptotic distributions of the estimated preference scores, we also introduce a comprehensive framework to carry out both one-sample and two-sample ranking inferences, applicable to both fixed and random graph settings. It is noteworthy that it is the first time effective two-sample rank testing methods are proposed. Finally, we substantiate our findings via comprehensive numerical simulations and subsequently apply our developed methodologies to perform statistical inferences on statistics journals and movie rankings.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Adversarial-Erasing-with-Pruned-Elements-Towards-Better-Graph-Lottery-Ticket"><a href="#Adversarial-Erasing-with-Pruned-Elements-Towards-Better-Graph-Lottery-Ticket" class="headerlink" title="Adversarial Erasing with Pruned Elements: Towards Better Graph Lottery Ticket"></a>Adversarial Erasing with Pruned Elements: Towards Better Graph Lottery Ticket</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02916">http://arxiv.org/abs/2308.02916</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangyuwen0627/ace-glt">https://github.com/wangyuwen0627/ace-glt</a></li>
<li>paper_authors: Yuwen Wang, Shunyu Liu, Kaixuan Chen, Tongtian Zhu, Ji Qiao, Mengjie Shi, Yuanyu Wan, Mingli Song<br>for:这篇论文旨在提高大输入图形深度学习网络（GNN）的计算成本，而不是降低性能。methods:论文提出了一种组合核心子图和稀疏子网络的方法，即Graph Lottery Ticket（GLT），并使用迭代磁力基于剪枝（IMP）来获得奖券。然而，现有的研究仅将奖券获得者视为终极目标，而忽略了剪枝过程中当前关系的动态变化，这限制了奖券的吸引力。results:实验结果显示，我们的ACE-GLT在多种任务中均超越了现有的搜寻GLT方法。<details>
<summary>Abstract</summary>
Graph Lottery Ticket (GLT), a combination of core subgraph and sparse subnetwork, has been proposed to mitigate the computational cost of deep Graph Neural Networks (GNNs) on large input graphs while preserving original performance. However, the winning GLTs in exisiting studies are obtained by applying iterative magnitude-based pruning (IMP) without re-evaluating and re-considering the pruned information, which disregards the dynamic changes in the significance of edges/weights during graph/model structure pruning, and thus limits the appeal of the winning tickets. In this paper, we formulate a conjecture, i.e., existing overlooked valuable information in the pruned graph connections and model parameters which can be re-grouped into GLT to enhance the final performance. Specifically, we propose an adversarial complementary erasing (ACE) framework to explore the valuable information from the pruned components, thereby developing a more powerful GLT, referred to as the ACE-GLT. The main idea is to mine valuable information from pruned edges/weights after each round of IMP, and employ the ACE technique to refine the GLT processing. Finally, experimental results demonstrate that our ACE-GLT outperforms existing methods for searching GLT in diverse tasks. Our code will be made publicly available.
</details>
<details>
<summary>摘要</summary>
Graph Lottery Ticket（GLT），一种将核心子图和稀疏子网络组合的方法，已被提出来降低深度图神经网络（GNNs）在大输入图上的计算成本，保持原始性能。然而，现有的赢家GLT通常通过不重新评估和重新考虑被剪除的信息来获得，这会忽略图/模型结构剪除中边Edge/权重的动态变化，从而限制赢家票的吸引力。在这篇论文中，我们提出一个假设，即现有的被过look的有价信息在剪除后的图连接和模型参数中，可以重新组织成GLT，以提高最终性能。 Specifically，我们提出一种对抗补做（ACE）框架，以挖掘剪除后的有价信息，并使用ACE技术来练级GLT处理。最后，我们的ACE-GLT在多种任务中的实验结果表明，我们的ACE-GLT比现有的GLT搜索方法更高效。我们的代码将在公共网上公布。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/06/cs.LG_2023_08_06/" data-id="clp89dogh00pci7886dqybfq7" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_08_06" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/06/eess.IV_2023_08_06/" class="article-date">
  <time datetime="2023-08-06T09:00:00.000Z" itemprop="datePublished">2023-08-06</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/06/eess.IV_2023_08_06/">eess.IV - 2023-08-06</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="FourLLIE-Boosting-Low-Light-Image-Enhancement-by-Fourier-Frequency-Information"><a href="#FourLLIE-Boosting-Low-Light-Image-Enhancement-by-Fourier-Frequency-Information" class="headerlink" title="FourLLIE: Boosting Low-Light Image Enhancement by Fourier Frequency Information"></a>FourLLIE: Boosting Low-Light Image Enhancement by Fourier Frequency Information</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03033">http://arxiv.org/abs/2308.03033</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangchx67/fourllie">https://github.com/wangchx67/fourllie</a></li>
<li>paper_authors: Chenxi Wang, Hongjun Wu, Zhi Jin</li>
<li>for: 提高低光照图像的亮度和细节</li>
<li>methods: 利用 fourier 频谱信息和空间信息，提出了一种基于 fourier 频谱的 LLIE 网络（FourLLIE），通过估计 fourier 频谱变换图并在第二个阶段引入 SNR 图来提高图像细节和亮度。</li>
<li>results: FourLLIE 在四个标准测试集上的表现比既有 SOTA 方法更好，同时保持了好的模型效率。<details>
<summary>Abstract</summary>
Recently, Fourier frequency information has attracted much attention in Low-Light Image Enhancement (LLIE). Some researchers noticed that, in the Fourier space, the lightness degradation mainly exists in the amplitude component and the rest exists in the phase component. By incorporating both the Fourier frequency and the spatial information, these researchers proposed remarkable solutions for LLIE. In this work, we further explore the positive correlation between the magnitude of amplitude and the magnitude of lightness, which can be effectively leveraged to improve the lightness of low-light images in the Fourier space. Moreover, we find that the Fourier transform can extract the global information of the image, and does not introduce massive neural network parameters like Multi-Layer Perceptrons (MLPs) or Transformer. To this end, a two-stage Fourier-based LLIE network (FourLLIE) is proposed. In the first stage, we improve the lightness of low-light images by estimating the amplitude transform map in the Fourier space. In the second stage, we introduce the Signal-to-Noise-Ratio (SNR) map to provide the prior for integrating the global Fourier frequency and the local spatial information, which recovers image details in the spatial space. With this ingenious design, FourLLIE outperforms the existing state-of-the-art (SOTA) LLIE methods on four representative datasets while maintaining good model efficiency.
</details>
<details>
<summary>摘要</summary>
近期，傅里叶频率信息在低光照图像提升（LLIE）中受到了很多注意。一些研究人员发现，在傅里叶空间中，亮度减退主要存在于幅度组件中，剩下的存在于相位组件中。通过结合傅里叶频率和空间信息，这些研究人员提出了有优势的解决方案。在这个工作中，我们进一步探索幅度组件的积分和亮度之间的正相关关系，可以有效地提高低光照图像的亮度在傅里叶空间中。此外，我们发现傅里叶变换可以提取图像的全局信息，不需要大量的神经网络参数如多层感知器（MLP）或变换器。为此，我们提出了一个两Stage的傅里叶基于LLIE网络（FourLLIE）。在第一stage中，我们使用傅里叶变换map来提高低光照图像的亮度。在第二stage中，我们引入信号噪比（SNR）地图，以提供亮度提升的优先级，并将全局傅里叶频率和本地空间信息集成起来，以恢复图像的细节。通过这种独特的设计，FourLLIE在四个代表性的数据集上比前一些SOTA LLIE方法表现出色，同时保持了好的模型效率。
</details></li>
</ul>
<hr>
<h2 id="Recurrent-Spike-based-Image-Restoration-under-General-Illumination"><a href="#Recurrent-Spike-based-Image-Restoration-under-General-Illumination" class="headerlink" title="Recurrent Spike-based Image Restoration under General Illumination"></a>Recurrent Spike-based Image Restoration under General Illumination</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03018">http://arxiv.org/abs/2308.03018</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bit-vision/rsir">https://github.com/bit-vision/rsir</a></li>
<li>paper_authors: Lin Zhu, Yunlong Zheng, Mengyue Geng, Lizhi Wang, Hua Huang</li>
<li>for: 这种新型的生物体注视传感器可以记录光Intensity为高速度的锥形数组，具有高时间分辨率（20,000 Hz）。这种新的视觉传感器方式可以提供更多的视觉任务，如高速度图像重建。但是，现有的颗粒基本approaches通常假设场景中有足够的光Intensity，这通常不符合实际世界中的许多场景，如雨天或晚上场景。</li>
<li>methods: 我们提出了一种Recurrent Spike-based Image Restoration（RSIR）网络，这是首个能够从颗粒数组中恢复清晰图像的方法。我们根据采样过程建立了物理基于的颗粒噪声模型，并根据这个噪声模型，我们设计了我们的RSIR网络，该网络包括自适应颗粒变换模块、回归时间特征融合模块和频率基于的颗粒去噪模块。我们的RSIR可以在循环方式处理颗粒数组，以确保颗粒时间信息得到了好用。</li>
<li>results: 我们通过对实际 datasets with different illuminations进行了广泛的实验，证明了我们的方法的有效性。代码和数据集在<a target="_blank" rel="noopener" href="https://github.com/BIT-Vision/RSIR%E4%B8%8A%E5%8F%91%E5%B8%83%E3%80%82">https://github.com/BIT-Vision/RSIR上发布。</a><details>
<summary>Abstract</summary>
Spike camera is a new type of bio-inspired vision sensor that records light intensity in the form of a spike array with high temporal resolution (20,000 Hz). This new paradigm of vision sensor offers significant advantages for many vision tasks such as high speed image reconstruction. However, existing spike-based approaches typically assume that the scenes are with sufficient light intensity, which is usually unavailable in many real-world scenarios such as rainy days or dusk scenes. To unlock more spike-based application scenarios, we propose a Recurrent Spike-based Image Restoration (RSIR) network, which is the first work towards restoring clear images from spike arrays under general illumination. Specifically, to accurately describe the noise distribution under different illuminations, we build a physical-based spike noise model according to the sampling process of the spike camera. Based on the noise model, we design our RSIR network which consists of an adaptive spike transformation module, a recurrent temporal feature fusion module, and a frequency-based spike denoising module. Our RSIR can process the spike array in a recursive manner to ensure that the spike temporal information is well utilized. In the training process, we generate the simulated spike data based on our noise model to train our network. Extensive experiments on real-world datasets with different illuminations demonstrate the effectiveness of the proposed network. The code and dataset are released at https://github.com/BIT-Vision/RSIR.
</details>
<details>
<summary>摘要</summary>
新型的蜂巢相机（Spike camera）是一种基于生物体的视觉传感器，它记录光度的变化形式为高度精度的蜂巢数组（20,000 Hz）。这种新的视觉传感器 paradigma提供了许多视觉任务的高速重建优势，但现有的蜂巢基本方法通常假设场景中有足够的光度，这通常不符合实际情况，如雨天或晚上场景。为了拓展更多的蜂巢应用场景，我们提出了一种基于蜂巢的图像修复网络（RSIR），这是首个在普通照明下修复清晰图像的工作。 Specifically, 我们建立了基于采样过程的物理基于蜂巢噪声模型，以描述不同照明下噪声分布。根据噪声模型，我们设计了我们的 RSIR 网络，该网络包括自适应蜂巢变换模块、回归时间特征融合模块和频率基于蜂巢噪声除净模块。我们的 RSIR 可以 recursive 地处理蜂巢数组，以确保蜂巢时间信息得到好好利用。在训练过程中，我们根据我们的噪声模型生成了模拟的蜂巢数据来训练我们的网络。广泛的实验表明，我们的方法可以在不同的照明下进行高效的图像修复。代码和数据集可以在 <https://github.com/BIT-Vision/RSIR> 上下载。
</details></li>
</ul>
<hr>
<h2 id="High-Resolution-Vision-Transformers-for-Pixel-Level-Identification-of-Structural-Components-and-Damage"><a href="#High-Resolution-Vision-Transformers-for-Pixel-Level-Identification-of-Structural-Components-and-Damage" class="headerlink" title="High-Resolution Vision Transformers for Pixel-Level Identification of Structural Components and Damage"></a>High-Resolution Vision Transformers for Pixel-Level Identification of Structural Components and Damage</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03006">http://arxiv.org/abs/2308.03006</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kareem Eltouny, Seyedomid Sajedi, Xiao Liang</li>
<li>for: 这个研究旨在提高桥梁检查图像的解析和检测效率，使用视transformer和劳拉幂 pyramids scaling网络来高效分割高分辨率视频检查图像。</li>
<li>methods: 该研究提出了一种基于视transformer和劳拉幂 pyramids scaling网络的 semantic segmentation网络，可以高效地处理大量的高分辨率视频检查图像，并保持本地细节和全局 semantics 信息。</li>
<li>results: 经过对bridge inspection report图像的详细实验，该方法能够高效地检测桥梁材料的分布，并且在多种 метриках上达到了比较高的准确率。<details>
<summary>Abstract</summary>
Visual inspection is predominantly used to evaluate the state of civil structures, but recent developments in unmanned aerial vehicles (UAVs) and artificial intelligence have increased the speed, safety, and reliability of the inspection process. In this study, we develop a semantic segmentation network based on vision transformers and Laplacian pyramids scaling networks for efficiently parsing high-resolution visual inspection images. The massive amounts of collected high-resolution images during inspections can slow down the investigation efforts. And while there have been extensive studies dedicated to the use of deep learning models for damage segmentation, processing high-resolution visual data can pose major computational difficulties. Traditionally, images are either uniformly downsampled or partitioned to cope with computational demands. However, the input is at risk of losing local fine details, such as thin cracks, or global contextual information. Inspired by super-resolution architectures, our vision transformer model learns to resize high-resolution images and masks to retain both the valuable local features and the global semantics without sacrificing computational efficiency. The proposed framework has been evaluated through comprehensive experiments on a dataset of bridge inspection report images using multiple metrics for pixel-wise materials detection.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Translate the given text into Simplified Chinese.<</SYS>>视觉检查主要用于评估公共建筑物，但最近的无人飞行器（UAV）和人工智能技术的发展已经提高了检查过程的速度、安全性和可靠性。在这项研究中，我们开发了基于视觉变换器和傅里叶分割网络的Semantic Segmentation网络，用于高效地解析视觉检查图像。收集的大量高分辨率图像可能会拖垮调查工作。虽然有很多关于深度学习模型的损害分割研究，但处理高分辨率视觉数据可以带来很大的计算困难。传统上，图像会被uniform downsample或分割，以降低计算压力，但输入可能会产生Local细腐 crack或全局Contextual信息的产生。受超分辨率架构启发，我们的视觉变换器模型可以resize高分辨率图像和mask来保留有价值的Local特征和全局Semantics信息，不需要牺牲计算效率。我们提出的框架在 bridge 检查报告图像上进行了广泛的实验，使用多种度量来进行像素精度检测。
</details></li>
</ul>
<hr>
<h2 id="Weakly-supervised-segmentation-of-intracranial-aneurysms-using-a-3D-focal-modulation-UNet"><a href="#Weakly-supervised-segmentation-of-intracranial-aneurysms-using-a-3D-focal-modulation-UNet" class="headerlink" title="Weakly supervised segmentation of intracranial aneurysms using a 3D focal modulation UNet"></a>Weakly supervised segmentation of intracranial aneurysms using a 3D focal modulation UNet</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03001">http://arxiv.org/abs/2308.03001</a></li>
<li>repo_url: None</li>
<li>paper_authors: Amirhossein Rasoulian, Soorena Salari, Yiming Xiao</li>
<li>for: 本研究旨在提高脑动脉疾病诊断和治疗决策的准确性和效率，通过自动化三维血管动脉分割来提高UIA诊断和评估。</li>
<li>methods: 本研究使用了弱监督学习和粗糙标签，通过一种基于focal modulation的3D focal modulation UNet和Conditional Random Field（CRF）后处理来实现高精度的UIA分割。</li>
<li>results: 实验结果表明，提出的方法在评估指标Dice分数和 Hausdorff距离上均超过了现有的3D UNet和Swin-UNETR方法，并且显示了 focal modulation 的潜在优势。<details>
<summary>Abstract</summary>
Accurate identification and quantification of unruptured intracranial aneurysms (UIAs) are essential for the risk assessment and treatment decisions of this cerebrovascular disorder. Current assessment based on 2D manual measures of aneurysms on 3D magnetic resonance angiography (MRA) is sub-optimal and time-consuming. Automatic 3D measures can significantly benefit the clinical workflow and treatment outcomes. However, one major issue in medical image segmentation is the need for large well-annotated data, which can be expensive to obtain. Techniques that mitigate the requirement, such as weakly supervised learning with coarse labels are highly desirable. In this paper, we leverage coarse labels of UIAs from time-of-flight MRAs to obtain refined UIAs segmentation using a novel 3D focal modulation UNet, called FocalSegNet and conditional random field (CRF) postprocessing, with a Dice score of 0.68 and 95% Hausdorff distance of 0.95 mm. We evaluated the performance of the proposed algorithms against the state-of-the-art 3D UNet and Swin-UNETR, and demonstrated the superiority of the proposed FocalSegNet and the benefit of focal modulation for the task.
</details>
<details>
<summary>摘要</summary>
精准识别和量化非ruptured intracranial aneurysms (UIAs) 是脑血管疾病风险评估和治疗决策中的关键。现有的评估方法基于2D手动测量在3D磁共振成像(MRA)上的动脉瘤是次优化的和时间consuming。自动3D测量可以帮助优化诊断和治疗结果。然而，医疗图像分割的一个主要问题是需要大量高质量标注数据，这可以是成本高的。我们在这篇论文中利用了时间反射MRAs中的UIAs粗略标注来获得精细的UIAs分割，使用了一种新的3D焦点修饰UNet（FocalSegNet）和条件Random Field（CRF）后处理，得到了0.68的Dice分数和0.95毫米的95% Hausdorff距离。我们对已有的3D UNets和Swin-UNETR进行了比较，并证明了我们提出的FocalSegNet的优越性和焦点修饰的好处。
</details></li>
</ul>
<hr>
<h2 id="DermoSegDiff-A-Boundary-aware-Segmentation-Diffusion-Model-for-Skin-Lesion-Delineation"><a href="#DermoSegDiff-A-Boundary-aware-Segmentation-Diffusion-Model-for-Skin-Lesion-Delineation" class="headerlink" title="DermoSegDiff: A Boundary-aware Segmentation Diffusion Model for Skin Lesion Delineation"></a>DermoSegDiff: A Boundary-aware Segmentation Diffusion Model for Skin Lesion Delineation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02959">http://arxiv.org/abs/2308.02959</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mindflow-institue/dermosegdiff">https://github.com/mindflow-institue/dermosegdiff</a></li>
<li>paper_authors: Afshin Bozorgpour, Yousef Sadegheih, Amirhossein Kazerouni, Reza Azad, Dorit Merhof</li>
<li>for: 静脉皮肤病症诊断早期检测</li>
<li>methods: 使用边缘信息在学习过程中进行增强，并 introduce 一种新的损失函数来优先级化边界信息。</li>
<li>results: 对多个皮肤分割数据集进行实验，表明 DermoSegDiff 比现有 CNN、转换器和扩散模型更高效和普遍。<details>
<summary>Abstract</summary>
Skin lesion segmentation plays a critical role in the early detection and accurate diagnosis of dermatological conditions. Denoising Diffusion Probabilistic Models (DDPMs) have recently gained attention for their exceptional image-generation capabilities. Building on these advancements, we propose DermoSegDiff, a novel framework for skin lesion segmentation that incorporates boundary information during the learning process. Our approach introduces a novel loss function that prioritizes the boundaries during training, gradually reducing the significance of other regions. We also introduce a novel U-Net-based denoising network that proficiently integrates noise and semantic information inside the network. Experimental results on multiple skin segmentation datasets demonstrate the superiority of DermoSegDiff over existing CNN, transformer, and diffusion-based approaches, showcasing its effectiveness and generalization in various scenarios. The implementation is publicly accessible on \href{https://github.com/mindflow-institue/dermosegdiff}{GitHub}
</details>
<details>
<summary>摘要</summary>
皮肤 lesion 分割在早期检测和准确诊断皮肤病理中扮演了关键角色。 reciently， Denoising Diffusion Probabilistic Models (DDPMs) 在图像生成方面受到了广泛关注。 基于这些进步，我们提出了 DermoSegDiff，一种新的皮肤 lesion 分割框架，它在学习过程中引入边界信息。我们的方法引入了一种新的损失函数，在训练过程中优先级是边界区域，逐渐减少其他区域的重要性。我们还引入了一种基于 U-Net 的混合噪声和semantic信息的denoising网络。多个皮肤分割数据集的实验结果表明，DermoSegDiff 在不同场景下比核心 CNN、transformer 和 diffusion 基本上表现出色，展示其效果和泛化能力。实现可以在 \href{https://github.com/mindflow-institue/dermosegdiff}{GitHub} 上获取。
</details></li>
</ul>
<hr>
<h2 id="MomentaMorph-Unsupervised-Spatial-Temporal-Registration-with-Momenta-Shooting-and-Correction"><a href="#MomentaMorph-Unsupervised-Spatial-Temporal-Registration-with-Momenta-Shooting-and-Correction" class="headerlink" title="MomentaMorph: Unsupervised Spatial-Temporal Registration with Momenta, Shooting, and Correction"></a>MomentaMorph: Unsupervised Spatial-Temporal Registration with Momenta, Shooting, and Correction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02949">http://arxiv.org/abs/2308.02949</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhangxing Bian, Shuwen Wei, Yihao Liu, Junyu Chen, Jiachen Zhuo, Fangxu Xing, Jonghye Woo, Aaron Carass, Jerry L. Prince<br>for:这篇论文旨在提出一种新的“劫持、射击、更正”框架，用于在具有复杂模式和大动量的情况下进行劫持动态图像的运动场 estimation。methods:这种框架基于李群和李代数原理，在坐标空间内积累动量，使用抽象映射在坐标空间中快速地逼近真的极小值，并且通过后续的更正步骤确保劫持到真的极小值。results:在一个2D synthetic数据集和一个实际的3D tMRI数据集上，这种方法能够准确地估计2D&#x2F;3D动态图像中的劫持动量场，并且能够适应大动量和复杂模式。<details>
<summary>Abstract</summary>
Tagged magnetic resonance imaging (tMRI) has been employed for decades to measure the motion of tissue undergoing deformation. However, registration-based motion estimation from tMRI is difficult due to the periodic patterns in these images, particularly when the motion is large. With a larger motion the registration approach gets trapped in a local optima, leading to motion estimation errors. We introduce a novel "momenta, shooting, and correction" framework for Lagrangian motion estimation in the presence of repetitive patterns and large motion. This framework, grounded in Lie algebra and Lie group principles, accumulates momenta in the tangent vector space and employs exponential mapping in the diffeomorphic space for rapid approximation towards true optima, circumventing local optima. A subsequent correction step ensures convergence to true optima. The results on a 2D synthetic dataset and a real 3D tMRI dataset demonstrate our method's efficiency in estimating accurate, dense, and diffeomorphic 2D/3D motion fields amidst large motion and repetitive patterns.
</details>
<details>
<summary>摘要</summary>
标记的核磁共振成像（tMRI）已经在数十年内用于测量软组织的运动。然而，基于准确的注册的运动估计从tMRI中很难进行，尤其是当运动较大时。大量运动会让注册方法被困在本地最佳点，导致运动估计错误。我们介绍了一种新的“动量、射击和修正”框架，用于在具有重复模式和大运动的情况下进行拉格朗日运动估计。这个框架基于李代数和李群原理，在 tangent 空间中积累动量，并使用 exponential mapping 在 diffeomorphic 空间中快速地逼近真正的最佳点， circumventing 本地最佳点。后续的修正步骤确保了真正的最佳点准确性。 synthetic 数据集和真实的 3D tMRI 数据集的结果表明，我们的方法可以快速、高精度地估计软组织的 2D/3D 运动场，即使在大运动和重复模式的情况下。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/06/eess.IV_2023_08_06/" data-id="clp89donc018ii788er22egni" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_08_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/05/cs.SD_2023_08_05/" class="article-date">
  <time datetime="2023-08-05T15:00:00.000Z" itemprop="datePublished">2023-08-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/05/cs.SD_2023_08_05/">cs.SD - 2023-08-05</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="ApproBiVT-Lead-ASR-Models-to-Generalize-Better-Using-Approximated-Bias-Variance-Tradeoff-Guided-Early-Stopping-and-Checkpoint-Averaging"><a href="#ApproBiVT-Lead-ASR-Models-to-Generalize-Better-Using-Approximated-Bias-Variance-Tradeoff-Guided-Early-Stopping-and-Checkpoint-Averaging" class="headerlink" title="ApproBiVT: Lead ASR Models to Generalize Better Using Approximated Bias-Variance Tradeoff Guided Early Stopping and Checkpoint Averaging"></a>ApproBiVT: Lead ASR Models to Generalize Better Using Approximated Bias-Variance Tradeoff Guided Early Stopping and Checkpoint Averaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02870">http://arxiv.org/abs/2308.02870</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fangyuan Wang, Ming Hao, Yuhai Shi, Bo Xu</li>
<li>for: This paper aims to improve the conventional recipe for Automatic Speech Recognition (ASR) models by rethinking and updating the early stopping and checkpoint averaging methods from the perspective of the bias-variance tradeoff.</li>
<li>methods: The proposed method, called Approximated Bias-Variance Tradeoff (ApproBiVT), uses the training loss and validation loss as proxies of bias and variance to guide the early stopping and checkpoint averaging.</li>
<li>results: When evaluated on the AISHELL-1 and AISHELL-2 datasets, the proposed recipe provided a CER reduction of 2.5%-3.7% and 3.1%-4.6%, respectively, compared to the conventional recipe.<details>
<summary>Abstract</summary>
The conventional recipe for Automatic Speech Recognition (ASR) models is to 1) train multiple checkpoints on a training set while relying on a validation set to prevent overfitting using early stopping and 2) average several last checkpoints or that of the lowest validation losses to obtain the final model. In this paper, we rethink and update the early stopping and checkpoint averaging from the perspective of the bias-variance tradeoff. Theoretically, the bias and variance represent the fitness and variability of a model and the tradeoff of them determines the overall generalization error. But, it's impractical to evaluate them precisely. As an alternative, we take the training loss and validation loss as proxies of bias and variance and guide the early stopping and checkpoint averaging using their tradeoff, namely an Approximated Bias-Variance Tradeoff (ApproBiVT). When evaluating with advanced ASR models, our recipe provides 2.5%-3.7% and 3.1%-4.6% CER reduction on the AISHELL-1 and AISHELL-2, respectively.
</details>
<details>
<summary>摘要</summary>
传统的自动语音识别（ASR）模型制作流程是：1）在训练集上训练多个Checkpoint，并且使用验证集来防止过拟合，使用早期停止和Checkpoint平均来获得最终模型。在这篇论文中，我们重新思考和更新了早期停止和Checkpoint平均的方法，从偏差-变差质量的角度来考虑。在理论上，偏差和变差代表模型的适应度和多样性，它们之间的质量评价是模型的总泛化误差的关键因素。但是，很难准确地评价它们。因此，我们使用训练损失和验证损失作为偏差和变差的代理，并使用它们之间的质量评价来引导早期停止和Checkpoint平均，即 Approximated Bias-Variance Tradeoff（ApproBiVT）。在使用高级ASR模型进行评估时，我们的制作流程可以提供2.5%-3.7%和3.1%-4.6%的CER减少在AISHELL-1和AISHELL-2上。
</details></li>
</ul>
<hr>
<h2 id="A-Systematic-Exploration-of-Joint-training-for-Singing-Voice-Synthesis"><a href="#A-Systematic-Exploration-of-Joint-training-for-Singing-Voice-Synthesis" class="headerlink" title="A Systematic Exploration of Joint-training for Singing Voice Synthesis"></a>A Systematic Exploration of Joint-training for Singing Voice Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02867">http://arxiv.org/abs/2308.02867</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuning Wu, Yifeng Yu, Jiatong Shi, Tao Qian, Qin Jin</li>
<li>for: 提高Singing Voice Synthesis（SVS）系统的 JOINT-TRAINING 性能</li>
<li>methods: 采用joint-training策略，协同训练Acoustic Model和Vocoder</li>
<li>results: 对多个数据集进行了广泛的实验，并达到了比基eline更稳定的性能，同时提高了整个框架的可解释性。<details>
<summary>Abstract</summary>
There has been a growing interest in using end-to-end acoustic models for singing voice synthesis (SVS). Typically, these models require an additional vocoder to transform the generated acoustic features into the final waveform. However, since the acoustic model and the vocoder are not jointly optimized, a gap can exist between the two models, leading to suboptimal performance. Although a similar problem has been addressed in the TTS systems by joint-training or by replacing acoustic features with a latent representation, adopting corresponding approaches to SVS is not an easy task. How to improve the joint-training of SVS systems has not been well explored. In this paper, we conduct a systematic investigation of how to better perform a joint-training of an acoustic model and a vocoder for SVS. We carry out extensive experiments and demonstrate that our joint-training strategy outperforms baselines, achieving more stable performance across different datasets while also increasing the interpretability of the entire framework.
</details>
<details>
<summary>摘要</summary>
Recently, there has been growing interest in using end-to-end acoustic models for singing voice synthesis (SVS). Typically, these models require an additional vocoder to transform the generated acoustic features into the final waveform. However, since the acoustic model and the vocoder are not jointly optimized, a gap can exist between the two models, leading to suboptimal performance. Although a similar problem has been addressed in TTS systems by joint-training or by replacing acoustic features with a latent representation, adopting corresponding approaches to SVS is not an easy task. How to improve the joint-training of SVS systems has not been well explored. In this paper, we conduct a systematic investigation of how to better perform a joint-training of an acoustic model and a vocoder for SVS. We carry out extensive experiments and demonstrate that our joint-training strategy outperforms baselines, achieving more stable performance across different datasets while also increasing the interpretability of the entire framework.
</details></li>
</ul>
<hr>
<h2 id="Bootstrapping-Contrastive-Learning-Enhanced-Music-Cold-Start-Matching"><a href="#Bootstrapping-Contrastive-Learning-Enhanced-Music-Cold-Start-Matching" class="headerlink" title="Bootstrapping Contrastive Learning Enhanced Music Cold-Start Matching"></a>Bootstrapping Contrastive Learning Enhanced Music Cold-Start Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02844">http://arxiv.org/abs/2308.02844</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xinping Zhao, Ying Zhang, Qiang Xiao, Yuming Ren, Yingchun Yang</li>
<li>for: 这篇论文是为了解决音乐冷启始匹配问题，即在没有相关数据的情况下，根据歌曲内容特征来找到与之相似的歌曲和听众。</li>
<li>methods: 作者们使用了一种名为Bootstrapping Contrastive Learning（BCL）的新的对比学习方法，以增强学习的歌曲表示质量。此外，他们还提出了一种名为Clustering-based Audience Targeting（CAT）的听众定向策略，用于在在线服务中更准确地定位目标听众。</li>
<li>results: 作者们通过对离线数据集和在线系统进行广泛的实验，证明了他们的方法的有效性和高效性。此外，他们还在NetEase Cloud Music上部署了这种方法，影响了数百万用户。<details>
<summary>Abstract</summary>
We study a particular matching task we call Music Cold-Start Matching. In short, given a cold-start song request, we expect to retrieve songs with similar audiences and then fastly push the cold-start song to the audiences of the retrieved songs to warm up it. However, there are hardly any studies done on this task. Therefore, in this paper, we will formalize the problem of Music Cold-Start Matching detailedly and give a scheme. During the offline training, we attempt to learn high-quality song representations based on song content features. But, we find supervision signals typically follow power-law distribution causing skewed representation learning. To address this issue, we propose a novel contrastive learning paradigm named Bootstrapping Contrastive Learning (BCL) to enhance the quality of learned representations by exerting contrastive regularization. During the online serving, to locate the target audiences more accurately, we propose Clustering-based Audience Targeting (CAT) that clusters audience representations to acquire a few cluster centroids and then locate the target audiences by measuring the relevance between the audience representations and the cluster centroids. Extensive experiments on the offline dataset and online system demonstrate the effectiveness and efficiency of our method. Currently, we have deployed it on NetEase Cloud Music, affecting millions of users. Code will be released in the future.
</details>
<details>
<summary>摘要</summary>
我们研究了一个特定的匹配任务，称之为音乐冷启始匹配（Music Cold-Start Matching）。简而言之，给定一个冷启始歌曲请求，我们期望检索到与其相似的听众，然后快速推广冷启始歌曲到检索到的听众中，以便让其热身。然而，现有的研究对此任务的研究非常有限。因此，在这篇论文中，我们将Music Cold-Start Matching问题进行详细化，并提出一种方案。在线上训练时，我们尝试学习高质量的歌曲表示，基于歌曲内容特征。然而，我们发现监督信号通常遵循力量分布，导致表示学习受到扭曲的影响。为解决这个问题，我们提出了一种新的对比学习方法，称之为启动对比学习（Bootstrapping Contrastive Learning，BCL），以提高学习的质量。在线上服务时，我们提出了分组听众定向（Clustering-based Audience Targeting，CAT），将听众表示分组为一些集中点，然后通过测量听众表示和集中点之间的相似度来确定目标听众。我们对历史数据集和在线系统进行了广泛的实验，证明了我们的方法的有效性和效率。目前，我们已经将其部署到NetEase Cloud Music上，影响了数百万名用户。代码将在未来发布。
</details></li>
</ul>
<hr>
<h2 id="Self-Distillation-Network-with-Ensemble-Prototypes-Learning-Robust-Speaker-Representations-without-Supervision"><a href="#Self-Distillation-Network-with-Ensemble-Prototypes-Learning-Robust-Speaker-Representations-without-Supervision" class="headerlink" title="Self-Distillation Network with Ensemble Prototypes: Learning Robust Speaker Representations without Supervision"></a>Self-Distillation Network with Ensemble Prototypes: Learning Robust Speaker Representations without Supervision</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02774">http://arxiv.org/abs/2308.02774</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alibaba-damo-academy/3D-Speaker">https://github.com/alibaba-damo-academy/3D-Speaker</a></li>
<li>paper_authors: Yafeng Chen, Siqi Zheng, Qian Chen</li>
<li>for: 提高无标签 speaker verification 系统的可靠性和稳定性。</li>
<li>methods: 提出了一种自动学习 speaker representation 的 Self-Distillation network with Ensemble Prototypes (SDEP) 框架，无需使用标签数据。</li>
<li>results: 在 VoxCeleb 数据集上进行了详细的实验，并达到了新的 SOTA 水平（ i.e., 等Error rate 1.94%、1.99% 和 3.77%），不使用任何标签数据进行训练。<details>
<summary>Abstract</summary>
Training speaker-discriminative and robust speaker verification systems without speaker labels is still challenging and worthwhile to explore. Previous studies have noted a substantial performance disparity between self-supervised and fully supervised approaches. In this paper, we propose an effective Self-Distillation network with Ensemble Prototypes (SDEP) to facilitate self-supervised speaker representation learning. A range of experiments conducted on the VoxCeleb datasets demonstrate the superiority of the SDEP framework in speaker verification. SDEP achieves a new SOTA on Voxceleb1 speaker verification evaluation benchmark ( i.e., equal error rate 1.94\%, 1.99\%, and 3.77\% for trial Vox1-O, Vox1-E and Vox1-H , respectively), discarding any speaker labels in the training phase. Code will be publicly available at https://github.com/alibaba-damo-academy/3D-Speaker.
</details>
<details>
<summary>摘要</summary>
<SYS>使用无标签的语音训练说话人识别系统仍然是一项挑战，但也是值得探索的。过去的研究表明自我超vised和完全超vised方法之间存在很大的性能差异。在这篇论文中，我们提出了一种有效的自我蒸馏网络与集成观察者（SDEP），以便无标签语音表征学习。对于VoxCeleb数据集进行了一系列实验， demonstarted SDEP框架在说话人识别中的优越性。SDEP在Voxceleb1说话人识别评价标准（即错误率1.94%、1.99%和3.77%）上达到了新的最佳性能，不使用任何说话人标签在训练阶段。代码将在https://github.com/alibaba-damo-academy/3D-Speaker上公开。</SYS>Note that Simplified Chinese is used in the translation, as it is the more widely used standard in mainland China. If you prefer Traditional Chinese, I can provide that as well.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/05/cs.SD_2023_08_05/" data-id="clp89doj400x8i7884872162w" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_08_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/05/cs.CV_2023_08_05/" class="article-date">
  <time datetime="2023-08-05T13:00:00.000Z" itemprop="datePublished">2023-08-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/05/cs.CV_2023_08_05/">cs.CV - 2023-08-05</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Where-and-How-Mitigating-Confusion-in-Neural-Radiance-Fields-from-Sparse-Inputs"><a href="#Where-and-How-Mitigating-Confusion-in-Neural-Radiance-Fields-from-Sparse-Inputs" class="headerlink" title="Where and How: Mitigating Confusion in Neural Radiance Fields from Sparse Inputs"></a>Where and How: Mitigating Confusion in Neural Radiance Fields from Sparse Inputs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02908">http://arxiv.org/abs/2308.02908</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bbbbby-99/wah-nerf">https://github.com/bbbbby-99/wah-nerf</a></li>
<li>paper_authors: Yanqi Bao, Yuxin Li, Jing Huo, Tianyu Ding, Xinyue Liang, Wenbin Li, Yang Gao</li>
<li>for: 这个论文的目的是提高NeRF-S的synthesizing能力，使得它能够更好地生成新的视角。</li>
<li>methods: 这个论文使用了一种新的学习框架，即WaH-NeRF，来解决NeRF-S中的“CONFUSION”问题。这个框架包括一种可变 sampling策略和一种Weight-based Mutual Information Loss，以及一种semi-supervised learning paradigm和一种Pixel-Patch Correspondence Loss。</li>
<li>results: 根据实验结果，WaH-NeRF在NeRF-S Setting下表现出色，超越了之前的方法。<details>
<summary>Abstract</summary>
Neural Radiance Fields from Sparse input} (NeRF-S) have shown great potential in synthesizing novel views with a limited number of observed viewpoints. However, due to the inherent limitations of sparse inputs and the gap between non-adjacent views, rendering results often suffer from over-fitting and foggy surfaces, a phenomenon we refer to as "CONFUSION" during volume rendering. In this paper, we analyze the root cause of this confusion and attribute it to two fundamental questions: "WHERE" and "HOW". To this end, we present a novel learning framework, WaH-NeRF, which effectively mitigates confusion by tackling the following challenges: (i)"WHERE" to Sample? in NeRF-S -- we introduce a Deformable Sampling strategy and a Weight-based Mutual Information Loss to address sample-position confusion arising from the limited number of viewpoints; and (ii) "HOW" to Predict? in NeRF-S -- we propose a Semi-Supervised NeRF learning Paradigm based on pose perturbation and a Pixel-Patch Correspondence Loss to alleviate prediction confusion caused by the disparity between training and testing viewpoints. By integrating our proposed modules and loss functions, WaH-NeRF outperforms previous methods under the NeRF-S setting. Code is available https://github.com/bbbbby-99/WaH-NeRF.
</details>
<details>
<summary>摘要</summary>
neural radiance fields from sparse input (NeRF-S) 有很大的潜力synthesize novel views with a limited number of observed viewpoints. However, due to the inherent limitations of sparse inputs and the gap between non-adjacent views, rendering results often suffer from over-fitting and foggy surfaces, a phenomenon we refer to as "CONFUSION" during volume rendering. In this paper, we analyze the root cause of this confusion and attribute it to two fundamental questions: "WHERE" and "HOW". To this end, we present a novel learning framework, WaH-NeRF, which effectively mitigates confusion by tackling the following challenges: (i)"WHERE" to Sample? in NeRF-S -- we introduce a Deformable Sampling strategy and a Weight-based Mutual Information Loss to address sample-position confusion arising from the limited number of viewpoints; and (ii) "HOW" to Predict? in NeRF-S -- we propose a Semi-Supervised NeRF learning Paradigm based on pose perturbation and a Pixel-Patch Correspondence Loss to alleviate prediction confusion caused by the disparity between training and testing viewpoints. By integrating our proposed modules and loss functions, WaH-NeRF outperforms previous methods under the NeRF-S setting. Code is available at https://github.com/bbbbby-99/WaH-NeRF.
</details></li>
</ul>
<hr>
<h2 id="FAST-Font-Agnostic-Scene-Text-Editing"><a href="#FAST-Font-Agnostic-Scene-Text-Editing" class="headerlink" title="FAST: Font-Agnostic Scene Text Editing"></a>FAST: Font-Agnostic Scene Text Editing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02905">http://arxiv.org/abs/2308.02905</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alloy Das, Prasun Roy, Saumik Bhattacharya, Subhankar Ghosh, Umapada Pal, Michael Blumenstein</li>
<li>for: 提高Scene Text Editing（STE）的研究表现，解决现有文本修改方法的缺点，包括复杂的背景、多种字体风格和文本内容的变化。</li>
<li>methods: 提出了一种新的font-agnostic Scene Text Editing框架，named FAST，可以同时生成文本在任意风格和位置，保持自然和现实的外观，通过组合掩码生成和风格传递来实现。与传统方法不同，该方法不直接修改整个图像像素，而是引入了一种滤波机制，以除掉背景干扰，让网络专注于需要修改的文本区域。此外，还设计了一个文本风格传递模块，以解决文本内容的变化。</li>
<li>results: 对比传统方法，提出的方法在质量和量化两个方面均有显著提高，可以更好地修改图像中的文本。<details>
<summary>Abstract</summary>
Scene Text Editing (STE) is a challenging research problem, and it aims to modify existing texts in an image while preserving the background and the font style of the original text of the image. Due to its various real-life applications, researchers have explored several approaches toward STE in recent years. However, most of the existing STE methods show inferior editing performance because of (1) complex image backgrounds, (2) various font styles, and (3) varying word lengths within the text. To address such inferior editing performance issues, in this paper, we propose a novel font-agnostic scene text editing framework, named FAST, for simultaneously generating text in arbitrary styles and locations while preserving a natural and realistic appearance through combined mask generation and style transfer. The proposed approach differs from the existing methods as they directly modify all image pixels. Instead, the proposed method has introduced a filtering mechanism to remove background distractions, allowing the network to focus solely on the text regions where editing is required. Additionally, a text-style transfer module has been designed to mitigate the challenges posed by varying word lengths. Extensive experiments and ablations have been conducted, and the results demonstrate that the proposed method outperforms the existing methods both qualitatively and quantitatively.
</details>
<details>
<summary>摘要</summary>
场景文本编辑（STE）是一个具有挑战性的研究问题，它目标是修改图像中的文本而不改变图像背景和字体风格。由于它在实际生活中的多种应用，研究人员在过去几年内对STE进行了许多研究。然而，大多数现有的STE方法具有质量不高的编辑性能，主要归结于图像背景的复杂性、字体风格的多样性以及文本中单词的变化。为解决这些问题，在这篇论文中，我们提出了一种新的字体无关场景文本编辑框架，名为FAST，它可以同时生成文本在任意风格和位置上，并保持自然和现实的外观。我们的方法与现有方法不同，它们直接修改所有图像像素。相反，我们的方法引入了一种过滤机制，以除除背景干扰，让网络专注于需要编辑的文本区域。此外，我们还设计了一个文本风格传递模块，以适应文本中单词的变化。我们进行了广泛的实验和缺省分析，结果表明，我们的方法在质量和量上都超越了现有的方法。
</details></li>
</ul>
<hr>
<h2 id="An-Adaptive-Model-Ensemble-Adversarial-Attack-for-Boosting-Adversarial-Transferability"><a href="#An-Adaptive-Model-Ensemble-Adversarial-Attack-for-Boosting-Adversarial-Transferability" class="headerlink" title="An Adaptive Model Ensemble Adversarial Attack for Boosting Adversarial Transferability"></a>An Adaptive Model Ensemble Adversarial Attack for Boosting Adversarial Transferability</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02897">http://arxiv.org/abs/2308.02897</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/CHENBIN99/AdaEA">https://github.com/CHENBIN99/AdaEA</a></li>
<li>paper_authors: Bin Chen, Jia-Li Yin, Shukai Chen, Bo-Hao Chen, Ximeng Liu</li>
<li>for: 本研究的目的是提出一种适应 ensemble 攻击方法，以提高攻击 Transfer-based 黑客攻击的效果。</li>
<li>methods: 本研究使用的方法包括 adaptive ensemble attack (AdaEA) 和额外的 disparity-reduced filter。AdaEA 可以适应控制输出的融合，以capture和amplify adversarial example的内在传递信息。</li>
<li>results: 对于多个数据集，提出的 AdaEA 可以获得显著的提高，并且可以further boost 现有的传递基于攻击。这表明 AdaEA 的效果和多样性。<details>
<summary>Abstract</summary>
While the transferability property of adversarial examples allows the adversary to perform black-box attacks (i.e., the attacker has no knowledge about the target model), the transfer-based adversarial attacks have gained great attention. Previous works mostly study gradient variation or image transformations to amplify the distortion on critical parts of inputs. These methods can work on transferring across models with limited differences, i.e., from CNNs to CNNs, but always fail in transferring across models with wide differences, such as from CNNs to ViTs. Alternatively, model ensemble adversarial attacks are proposed to fuse outputs from surrogate models with diverse architectures to get an ensemble loss, making the generated adversarial example more likely to transfer to other models as it can fool multiple models concurrently. However, existing ensemble attacks simply fuse the outputs of the surrogate models evenly, thus are not efficacious to capture and amplify the intrinsic transfer information of adversarial examples. In this paper, we propose an adaptive ensemble attack, dubbed AdaEA, to adaptively control the fusion of the outputs from each model, via monitoring the discrepancy ratio of their contributions towards the adversarial objective. Furthermore, an extra disparity-reduced filter is introduced to further synchronize the update direction. As a result, we achieve considerable improvement over the existing ensemble attacks on various datasets, and the proposed AdaEA can also boost existing transfer-based attacks, which further demonstrates its efficacy and versatility.
</details>
<details>
<summary>摘要</summary>
而 transferability 性能的敌方例可以进行黑盒攻击（即攻击者没有对目标模型的知识），而转移基于敌方例的攻击吸引了大量关注。先前的工作主要研究了梯度变化或图像变换以增强输入的扰动部分。这些方法可以在有限差异的模型之间传输，例如从CNNs到CNNs，但总是失败在差异较广的模型之间，如从CNNs到ViTs。作为一个替代方案，我们提出了一种ensemble攻击，即将多个模型的输出 fusion 到一起，以获得一个ensemble损失，使得生成的敌方例更可能传输到其他模型，因为它可以同时欺骗多个模型。然而，现有的ensemble攻击简单地将每个模型的输出平均 fusion，因此无法捕捉和增强敌方例的内在传输信息。在这篇论文中，我们提出了一种适应 ensemble 攻击，称为AdaEA，以适应控制每个模型的输出 fusión。我们通过监测敌方例的扰动率来控制输出的权重，并 introduce 了一个降低差异的滤波器，以进一步同步更新方向。因此，我们实现了对多个数据集的现有ensemble攻击的显著改进，并且我们的提案的AdaEA还可以增强现有的传输基于攻击，这再次证明了它的有效性和多样性。
</details></li>
</ul>
<hr>
<h2 id="Cross-modal-Cross-domain-Learning-for-Unsupervised-LiDAR-Semantic-Segmentation"><a href="#Cross-modal-Cross-domain-Learning-for-Unsupervised-LiDAR-Semantic-Segmentation" class="headerlink" title="Cross-modal &amp; Cross-domain Learning for Unsupervised LiDAR Semantic Segmentation"></a>Cross-modal &amp; Cross-domain Learning for Unsupervised LiDAR Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02883">http://arxiv.org/abs/2308.02883</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiyang Chen, Shanshan Zhao, Changxing Ding, Liyao Tang, Chaoyue Wang, Dacheng Tao</li>
<li>for: 这个论文主要针对的问题是如何在只有2D图像和无注意的3D LiDAR数据的情况下实现3D LiDAR semantic segmentation（3DLSS）？</li>
<li>methods: 该论文提出了一种新的3DLSS设定，其中有一个2D数据集（源） WITH semantic annotation，并有一个paired but unannotated 2D图像和3D LiDAR数据（目标）。以实现3DLSS在这种情况下，该论文提出了一种名为 Cross-Modal and Cross-Domain Learning（CoMoDaL）的方法。CoMoDaL的目标是模型1) 不同模式和频谱之间的交叉频谱域distillation，以及2) 目标数据集中不同模式之间的交叉模式引导。</li>
<li>results: 在该论文中，CoMoDaL可以在没有标注的LiDAR数据的情况下实现3DLSS。在几个数据集上进行了实验，并进行了ablations来提供更多的分析。<details>
<summary>Abstract</summary>
In recent years, cross-modal domain adaptation has been studied on the paired 2D image and 3D LiDAR data to ease the labeling costs for 3D LiDAR semantic segmentation (3DLSS) in the target domain. However, in such a setting the paired 2D and 3D data in the source domain are still collected with additional effort. Since the 2D-3D projections can enable the 3D model to learn semantic information from the 2D counterpart, we ask whether we could further remove the need of source 3D data and only rely on the source 2D images. To answer it, this paper studies a new 3DLSS setting where a 2D dataset (source) with semantic annotations and a paired but unannotated 2D image and 3D LiDAR data (target) are available. To achieve 3DLSS in this scenario, we propose Cross-Modal and Cross-Domain Learning (CoMoDaL). Specifically, our CoMoDaL aims at modeling 1) inter-modal cross-domain distillation between the unpaired source 2D image and target 3D LiDAR data, and 2) the intra-domain cross-modal guidance between the target 2D image and 3D LiDAR data pair. In CoMoDaL, we propose to apply several constraints, such as point-to-pixel and prototype-to-pixel alignments, to associate the semantics in different modalities and domains by constructing mixed samples in two modalities. The experimental results on several datasets show that in the proposed setting, the developed CoMoDaL can achieve segmentation without the supervision of labeled LiDAR data. Ablations are also conducted to provide more analysis. Code will be available publicly.
</details>
<details>
<summary>摘要</summary>
近年来，跨Modal频率适应（Cross-Modal Domain Adaptation，CMDA）在paired 2D图像和3D LiDAR数据上进行研究，以减少目标频率上的标注成本 для3D LiDAR semantic segmentation（3DLSS）。然而，在这种设置下，paired 2D和3D数据在源频率上仍然需要额外努力收集。由于2D-3D投影可以帮助3D模型从2D对应的semantic信息，我们问 whether we could further remove the need of source 3D data and only rely on the source 2D images。为了回答这个问题，这篇论文研究了一种新的3DLSS设置，其中一个2D数据集（源）具有semantic标注，以及一个paired但未标注的2D图像和3D LiDAR数据（目标）。为了实现3DLSS在这种enario中，我们提出了 Cross-Modal and Cross-Domain Learning（CoMoDaL）。具体来说，CoMoDaL的目标是模型：1.  между不同模式和频率之间的跨Modal频率适应（inter-modal cross-domain distillation），从未标注的源2D图像和目标3D LiDAR数据中学习semantic信息。2. 目标2D图像和3D LiDAR数据对的内部模式协调（intra-domain cross-modal guidance），从目标2D图像和3D LiDAR数据对中学习semantic信息。在CoMoDaL中，我们提出了一些约束，例如点对像和原型对像的匹配约束，以将不同模式和频率之间的semantic信息相关联。我们通过构建两个模式之间的混合样本来实现这一点。实验结果表明，在我们的设置下，我们提出的CoMoDaL可以在未supervise的LiDAR数据上实现semantic segmentation。我们还进行了一些ablation来提供更多的分析。代码将公开发布。
</details></li>
</ul>
<hr>
<h2 id="Sketch-and-Text-Guided-Diffusion-Model-for-Colored-Point-Cloud-Generation"><a href="#Sketch-and-Text-Guided-Diffusion-Model-for-Colored-Point-Cloud-Generation" class="headerlink" title="Sketch and Text Guided Diffusion Model for Colored Point Cloud Generation"></a>Sketch and Text Guided Diffusion Model for Colored Point Cloud Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02874">http://arxiv.org/abs/2308.02874</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zijie Wu, Yaonan Wang, Mingtao Feng, He Xie, Ajmal Mian</li>
<li>for: 本研究旨在提出一种基于绘图和文本描述的颜色点云生成模型，以解决文本导向图像生成中3D形状的生成困难。</li>
<li>methods: 该模型使用混合激发模型进行颜色点云生成，并通过绘图和文本描述进行联合激发。模型采用级联激发方法，首先激发点坐标和颜色值，然后通过文本描述和绘图来conditioning进行反激发。</li>
<li>results: 实验结果显示，该模型在颜色点云生成任务上表现出色，比之前的状态当中的模型有更好的表现。<details>
<summary>Abstract</summary>
Diffusion probabilistic models have achieved remarkable success in text guided image generation. However, generating 3D shapes is still challenging due to the lack of sufficient data containing 3D models along with their descriptions. Moreover, text based descriptions of 3D shapes are inherently ambiguous and lack details. In this paper, we propose a sketch and text guided probabilistic diffusion model for colored point cloud generation that conditions the denoising process jointly with a hand drawn sketch of the object and its textual description. We incrementally diffuse the point coordinates and color values in a joint diffusion process to reach a Gaussian distribution. Colored point cloud generation thus amounts to learning the reverse diffusion process, conditioned by the sketch and text, to iteratively recover the desired shape and color. Specifically, to learn effective sketch-text embedding, our model adaptively aggregates the joint embedding of text prompt and the sketch based on a capsule attention network. Our model uses staged diffusion to generate the shape and then assign colors to different parts conditioned on the appearance prompt while preserving precise shapes from the first stage. This gives our model the flexibility to extend to multiple tasks, such as appearance re-editing and part segmentation. Experimental results demonstrate that our model outperforms recent state-of-the-art in point cloud generation.
</details>
<details>
<summary>摘要</summary>
Diffusion probabilistic models have achieved remarkable success in text-guided image generation. However, generating 3D shapes is still challenging due to the lack of sufficient data containing 3D models along with their descriptions. Moreover, text-based descriptions of 3D shapes are inherently ambiguous and lack details. In this paper, we propose a sketch and text-guided probabilistic diffusion model for colored point cloud generation that conditions the denoising process jointly with a hand-drawn sketch of the object and its textual description. We incrementally diffuse the point coordinates and color values in a joint diffusion process to reach a Gaussian distribution. Colored point cloud generation thus amounts to learning the reverse diffusion process, conditioned by the sketch and text, to iteratively recover the desired shape and color. Specifically, to learn effective sketch-text embedding, our model adaptively aggregates the joint embedding of text prompt and the sketch based on a capsule attention network. Our model uses staged diffusion to generate the shape and then assigns colors to different parts conditioned on the appearance prompt while preserving precise shapes from the first stage. This gives our model the flexibility to extend to multiple tasks, such as appearance re-editing and part segmentation. Experimental results demonstrate that our model outperforms recent state-of-the-art in point cloud generation.Here's the translation in Traditional Chinese:Diffusion probabilistic models have achieved remarkable success in text-guided image generation. However, generating 3D shapes is still challenging due to the lack of sufficient data containing 3D models along with their descriptions. Moreover, text-based descriptions of 3D shapes are inherently ambiguous and lack details. In this paper, we propose a sketch and text-guided probabilistic diffusion model for colored point cloud generation that conditions the denoising process jointly with a hand-drawn sketch of the object and its textual description. We incrementally diffuse the point coordinates and color values in a joint diffusion process to reach a Gaussian distribution. Colored point cloud generation thus amounts to learning the reverse diffusion process, conditioned by the sketch and text, to iteratively recover the desired shape and color. Specifically, to learn effective sketch-text embedding, our model adaptively aggregates the joint embedding of text prompt and the sketch based on a capsule attention network. Our model uses staged diffusion to generate the shape and then assigns colors to different parts conditioned on the appearance prompt while preserving precise shapes from the first stage. This gives our model the flexibility to extend to multiple tasks, such as appearance re-editing and part segmentation. Experimental results demonstrate that our model outperforms recent state-of-the-art in point cloud generation.
</details></li>
</ul>
<hr>
<h2 id="NP-SemiSeg-When-Neural-Processes-meet-Semi-Supervised-Semantic-Segmentation"><a href="#NP-SemiSeg-When-Neural-Processes-meet-Semi-Supervised-Semantic-Segmentation" class="headerlink" title="NP-SemiSeg: When Neural Processes meet Semi-Supervised Semantic Segmentation"></a>NP-SemiSeg: When Neural Processes meet Semi-Supervised Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02866">http://arxiv.org/abs/2308.02866</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jianf-wang/np-semiseg">https://github.com/jianf-wang/np-semiseg</a></li>
<li>paper_authors: Jianfeng Wang, Daniela Massiceti, Xiaolin Hu, Vladimir Pavlovic, Thomas Lukasiewicz</li>
<li>for: 本研究旨在提高semi-supervised semantic segmentation中的模型精度和可靠性，通过使用神经网络过程（NP）来实现uncertainty量化。</li>
<li>methods: 本研究使用NP来实现semi-supervised semantic segmentation，并在不同的训练设置下进行实验评估。</li>
<li>results: 实验结果表明，NP-SemiSeg模型在PASCAL VOC 2012和Cityscapes公共benchmark上具有效果，并且在不同的训练设置下可以达到比较高的精度和可靠性。<details>
<summary>Abstract</summary>
Semi-supervised semantic segmentation involves assigning pixel-wise labels to unlabeled images at training time. This is useful in a wide range of real-world applications where collecting pixel-wise labels is not feasible in time or cost. Current approaches to semi-supervised semantic segmentation work by predicting pseudo-labels for each pixel from a class-wise probability distribution output by a model. If the predicted probability distribution is incorrect, however, this leads to poor segmentation results, which can have knock-on consequences in safety critical systems, like medical images or self-driving cars. It is, therefore, important to understand what a model does not know, which is mainly achieved by uncertainty quantification. Recently, neural processes (NPs) have been explored in semi-supervised image classification, and they have been a computationally efficient and effective method for uncertainty quantification. In this work, we move one step forward by adapting NPs to semi-supervised semantic segmentation, resulting in a new model called NP-SemiSeg. We experimentally evaluated NP-SemiSeg on the public benchmarks PASCAL VOC 2012 and Cityscapes, with different training settings, and the results verify its effectiveness.
</details>
<details>
<summary>摘要</summary>
<<SYS>> semi-supervised semantic segmentation 涉及到在训练时对无标图像进行像素级标注。这在各种实际应用中非常有用，因为收集像素级标注的时间和成本不符合要求。现有的半监督 semantic segmentation 方法是通过从模型输出的类别概率分布中预测每个像素的 Pseudo-labels，如果预测的概率分布错误，则会导致 segmentation 结果差，这可能会对安全关键系统，如医疗图像或自动驾驶车辆，产生不良影响。因此，了解模型无法捕捉的信息非常重要。在最近的研究中，神经过程（NP）在半监督图像分类中被探索，并被证明是计算效率高并且有效的不确定性评估方法。在这项工作中，我们将NP应用到半监督semantic segmentation，得到了NP-SemiSeg模型。我们对公共 benchmarks PASCAL VOC 2012 和 Cityscapes 进行了不同的训练设置，并得到了 resultado，证明了NP-SemiSeg 的有效性。
</details></li>
</ul>
<hr>
<h2 id="Improving-Generalization-of-Image-Captioning-with-Unsupervised-Prompt-Learning"><a href="#Improving-Generalization-of-Image-Captioning-with-Unsupervised-Prompt-Learning" class="headerlink" title="Improving Generalization of Image Captioning with Unsupervised Prompt Learning"></a>Improving Generalization of Image Captioning with Unsupervised Prompt Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02862">http://arxiv.org/abs/2308.02862</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongchen Wei, Zhenzhong Chen</li>
<li>for: 提高图像描述（GeneIC）的通用性，不需要标注数据。</li>
<li>methods: 使用无监督提问学习方法，利用CLIP模型对目标领域的域pecific提问向量进行优化，从两个方面进行优化：Attribute和Semantic一致性。</li>
<li>results: 通过Attribute和Semantic一致性来约束提问向量，从而学习域pecific的知识，提高图像描述的通用性。<details>
<summary>Abstract</summary>
Pretrained visual-language models have demonstrated impressive zero-shot abilities in image captioning, when accompanied by hand-crafted prompts. Meanwhile, hand-crafted prompts utilize human prior knowledge to guide the model. However, due to the diversity between different domains, such hand-crafted prompt that provide invariant prior knowledge may result in mode collapse for some domains. Some researches attempted to incorporate expert knowledge and instruction datasets, but the results were costly and led to hallucinations. In this paper, we propose an unsupervised prompt learning method to improve Generalization of Image Captioning (GeneIC), which learns a domain-specific prompt vector for the target domain without requiring annotated data. GeneIC aligns visual and language modalities with a pre-trained Contrastive Language-Image Pre-Training (CLIP) model, thus optimizing the domain-specific prompt vector from two aspects: attribute and semantic consistency. Specifically, GeneIC first generates attribute-transferred images with differing attributes, while retaining semantic similarity with original images. Then, GeneIC uses CLIP to measure the similarity between the images and the generated sentences. By exploring the variable and invariant features in the original images and attribute-transferred images, attribute consistency constrains the attribute change direction of both images and sentences to learn domain-specific knowledge. The semantic consistency directly measures the similarity between the generated sentences and images to ensure the accuracy and comprehensiveness of the generated sentences. Consequently, GeneIC only optimizes the prompt vectors, which effectively retains the knowledge in the large model and introduces domain-specific knowledge.
</details>
<details>
<summary>摘要</summary>
《Image Captioning 总结》中，我们提出了一种不需要标注数据的无监督提问学习方法，以提高图文描述（GeneIC）的通用性。我们使用预训练的 Contrastive Language-Image Pre-Training（CLIP）模型，将视觉和语言模式align，从两个方面优化域pecific提问向量：Attribute和Semantic相同性。具体来说，GeneIC首先生成了不同特征的图像，保持了原始图像的Semantic相同性。然后，GeneIC使用CLIP测量图像和生成的句子之间的相似性。通过探索原始图像和特征转移图像中的变量和不变量特征，Attribute相同性确定了特征变化方向的限制。Semantic相同性直接测量生成句子和图像之间的相似性，以确保生成句子的准确性和全面性。因此，GeneIC只优化提问向量，Effectively retains the knowledge in the large model and introduces domain-specific knowledge。
</details></li>
</ul>
<hr>
<h2 id="Generative-Adversarial-Networks-for-Stain-Normalisation-in-Histopathology"><a href="#Generative-Adversarial-Networks-for-Stain-Normalisation-in-Histopathology" class="headerlink" title="Generative Adversarial Networks for Stain Normalisation in Histopathology"></a>Generative Adversarial Networks for Stain Normalisation in Histopathology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02851">http://arxiv.org/abs/2308.02851</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jack Breen, Kieran Zucker, Katie Allen, Nishant Ravikumar, Nicolas M. Orsi</li>
<li>for: 研究人员希望通过人工智能技术提高诊断的准确性和效率，但是受到数位病理学像的视觉差异问题导致模型对未见到的数据偏预测不好。</li>
<li>methods: 当研究人员使用生成对抗网络（GAN）来实现染色调整时，通常会比非生成方法表现更好，但是需要更高的计算资源。不过，不同的GAN和非GAN方法在不同的情况下和根据不同的表现指标都会出perform differently。</li>
<li>results: 目前研究人员正在寻找一种能够有效地和有效率地标准化病理学像的方法，以使AI模型更加普遍和可靠。<details>
<summary>Abstract</summary>
The rapid growth of digital pathology in recent years has provided an ideal opportunity for the development of artificial intelligence-based tools to improve the accuracy and efficiency of clinical diagnoses. One of the significant roadblocks to current research is the high level of visual variability across digital pathology images, causing models to generalise poorly to unseen data. Stain normalisation aims to standardise the visual profile of digital pathology images without changing the structural content of the images. In this chapter, we explore different techniques which have been used for stain normalisation in digital pathology, with a focus on approaches which utilise generative adversarial networks (GANs). Typically, GAN-based methods outperform non-generative approaches but at the cost of much greater computational requirements. However, it is not clear which method is best for stain normalisation in general, with different GAN and non-GAN approaches outperforming each other in different scenarios and according to different performance metrics. This is an ongoing field of study as researchers aim to identify a method which efficiently and effectively normalises pathology images to make AI models more robust and generalisable.
</details>
<details>
<summary>摘要</summary>
随着数字病理学的快速发展，现在提供了一个 идеal 的机会，以便通过人工智能技术来提高临床诊断的准确性和效率。然而，一个 significante 的障碍是数字病理图像之间的视觉变化很高，使模型很难泛化到未看到的数据。图像标准化的目的是为了标准化数字病理图像的视觉oprofile，而不是改变图像的结构内容。在这个章节中，我们探讨了不同的技术，以便在数字病理中实现图像标准化，特别是使用生成对抗网络（GAN）。通常，GAN基本技术在性能上表现更好，但是需要许多更高的计算需求。然而，不清楚哪种方法是最佳的标准化方法，因为不同的 GAN 和非 GAN 方法在不同的情况下和按照不同的表现指标而出performancedifferently。这是一个持续的研究领域，研究人员希望能够找到一种能够有效地和高效地标准化病理图像的方法，以便使 AI 模型更加Robust 和泛化。
</details></li>
</ul>
<hr>
<h2 id="Flashlight-Search-Medial-Axis-A-Pixel-Free-Pore-Network-Extraction-Algorithm"><a href="#Flashlight-Search-Medial-Axis-A-Pixel-Free-Pore-Network-Extraction-Algorithm" class="headerlink" title="Flashlight Search Medial Axis: A Pixel-Free Pore-Network Extraction Algorithm"></a>Flashlight Search Medial Axis: A Pixel-Free Pore-Network Extraction Algorithm</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.10990">http://arxiv.org/abs/2308.10990</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jie Liu, Tao Zhang, Shuyu Sun</li>
<li>for: 本研究使用 Flashlight Search Medial Axis（FSMA）算法来提取porous media中的细胞网络，以提高流体流动研究的准确性。</li>
<li>methods: 该算法基于笔画空间，在二维或三维空间中使用搜索域来寻找细胞网络。它采用维度减少的思想，只需要在搜索域中选择一些点，而不是计算整个空间中的每个点。这使得计算复杂性得到了显著减少，从而实现了大规模的细胞网络提取。</li>
<li>results: 研究表明，FSMA算法在不同的两维和三维porous media中都表现良好，无论细胞网络的topological结构如何或缺口和喉孔中心的位置如何。此外，该算法还可以处理关闭和开放边界的情况。最重要的是，FSMA算法可以搜索死绕的细胞，这在多相流动研究中具有重要意义。<details>
<summary>Abstract</summary>
Pore-network models (PNMs) have become an important tool in the study of fluid flow in porous media over the last few decades, and the accuracy of their results highly depends on the extraction of pore networks. Traditional methods of pore-network extraction are based on pixels and require images with high quality. Here, a pixel-free method called the flashlight search medial axis (FSMA) algorithm is proposed for pore-network extraction in a continuous space. The search domain in a two-dimensional space is a line, whereas a surface domain is searched in a three-dimensional scenario. Thus, the FSMA algorithm follows the dimensionality reduction idea; the medial axis can be identified using only a few points instead of calculating every point in the void space. In this way, computational complexity of this method is greatly reduced compared to that of traditional pixel-based extraction methods, thus enabling large-scale pore-network extraction. Based on cases featuring two- and three-dimensional porous media, the FSMA algorithm performs well regardless of the topological structure of the pore network or the positions of the pore and throat centers. This algorithm can also be used to examine both closed- and open-boundary cases. Finally, the FSMA algorithm can search dead-end pores, which is of great significance in the study of multiphase flow in porous media.
</details>
<details>
<summary>摘要</summary>
PORE-NETWORK MODELS (PNMs) 在过去几十年内已成为观察 fluid 流动在孔隙媒体中的重要工具，其精度准确性强度取决于绘制孔隙网络的方法。传统的方法基于像素，需要高质量的图像。在这篇文章中，我们提出了一种不基于像素的方法，即 flashlight search medial axis (FSMA) 算法，用于在连续空间中提取孔隙网络。在两维空间中，搜索域是一条线，而在三维情况下，搜索域是一个表面。因此，FSMA 算法遵循维度减少的想法，通过仅使用几个点来识别中心轴，而不是计算整个空心空间中的每个点。这种方法的计算复杂度与传统基于像素的提取方法相比，减少了很多，因此可以实现大规模的孔隙网络提取。基于二维和三维孔隙媒体的实验，FSMA 算法在不同的 topological 结构和孔隙中心位置下表现良好。此外，这种算法还可以用于考虑关闭和开放边界的情况。最后，FSMA 算法可以搜索死绕孔，这对多相流动在孔隙媒体中的研究具有重要性。
</details></li>
</ul>
<hr>
<h2 id="Landmark-Detection-using-Transformer-Toward-Robot-assisted-Nasal-Airway-Intubation"><a href="#Landmark-Detection-using-Transformer-Toward-Robot-assisted-Nasal-Airway-Intubation" class="headerlink" title="Landmark Detection using Transformer Toward Robot-assisted Nasal Airway Intubation"></a>Landmark Detection using Transformer Toward Robot-assisted Nasal Airway Intubation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02845">http://arxiv.org/abs/2308.02845</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/conorlth/airway_intubation_landmarks_detection">https://github.com/conorlth/airway_intubation_landmarks_detection</a></li>
<li>paper_authors: Tianhang Liu, Hechen Li, Long Bai, Yanan Wu, An Wang, Mobarakol Islam, Hongliang Ren</li>
<li>for: 这篇研究旨在提出一个基于 transformer 的 landmark 检测解决方案，用于 robot-assisted 气管 intubation 中更高精度地位检测关键目标和器官。</li>
<li>methods: 本研究使用了 deformable DeTR 和 semantic-aligned-matching 模组，实现了更高精度的 landmark 检测。</li>
<li>results: 实验结果显示，我们的解决方案在检测精度方面具有竞争力，并且可以帮助提高 robot-assisted 气管 intubation 的精度和效率。<details>
<summary>Abstract</summary>
Robot-assisted airway intubation application needs high accuracy in locating targets and organs. Two vital landmarks, nostrils and glottis, can be detected during the intubation to accommodate the stages of nasal intubation. Automated landmark detection can provide accurate localization and quantitative evaluation. The Detection Transformer (DeTR) leads object detectors to a new paradigm with long-range dependence. However, current DeTR requires long iterations to converge, and does not perform well in detecting small objects. This paper proposes a transformer-based landmark detection solution with deformable DeTR and the semantic-aligned-matching module for detecting landmarks in robot-assisted intubation. The semantics aligner can effectively align the semantics of object queries and image features in the same embedding space using the most discriminative features. To evaluate the performance of our solution, we utilize a publicly accessible glottis dataset and automatically annotate a nostril detection dataset. The experimental results demonstrate our competitive performance in detection accuracy. Our code is publicly accessible.
</details>
<details>
<summary>摘要</summary>
robot-assisted 气管 Intubation 应用需要高精度在目标和器官位置进行定位。两个重要的标志物，鼻孔和聊肉，可以在气管 Intubation 中被探测出来，以便进行不同的气管 Intubation 阶段。自动化标志物检测可以提供准确的定位和评估。 transformer （DeTR） 引导 object 检测器进入新的 paradigm 中，但现有的 DeTR 需要长时间迭代才能平衡，并不适合检测小型 объек。这篇论文提出了基于 transformer 的标志物检测解决方案，其中包括可变 DeTR 和 semantic-aligned-matching 模块。semantic aligner 可以很好地对 object 查询和图像特征在同一个 embedding 空间进行Semantic 对齐。为了评估我们的解决方案的性能，我们利用了公共可访问的 glottis 数据集，并自动注意nostril 检测数据集。实验结果表明我们的竞争性表现。我们的代码公开 accessible。
</details></li>
</ul>
<hr>
<h2 id="Learning-Unified-Decompositional-and-Compositional-NeRF-for-Editable-Novel-View-Synthesis"><a href="#Learning-Unified-Decompositional-and-Compositional-NeRF-for-Editable-Novel-View-Synthesis" class="headerlink" title="Learning Unified Decompositional and Compositional NeRF for Editable Novel View Synthesis"></a>Learning Unified Decompositional and Compositional NeRF for Editable Novel View Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02840">http://arxiv.org/abs/2308.02840</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuxin Wang, Wayne Wu, Dan Xu</li>
<li>for: 本文targets joint scene novel view synthesis and editing based on implicit neural scene representations, with a unified Neural Radiance Field (NeRF) framework to effectively perform scene decomposition and composition.</li>
<li>methods: 该方法使用两个阶段NeRF框架，首先学习一个全局辐射场为指导点抽象，然后在第二个细化阶段使用一个新的一颗对象辐射场regulatory模块和 pseudo监督via填充来处理不确定背景区域。</li>
<li>results: 该方法可以有效地进行Scene decomposition和Composition，并且在novel-view synthesis和 editing任务上表现出色，超越了state-of-the-art方法。<details>
<summary>Abstract</summary>
Implicit neural representations have shown powerful capacity in modeling real-world 3D scenes, offering superior performance in novel view synthesis. In this paper, we target a more challenging scenario, i.e., joint scene novel view synthesis and editing based on implicit neural scene representations. State-of-the-art methods in this direction typically consider building separate networks for these two tasks (i.e., view synthesis and editing). Thus, the modeling of interactions and correlations between these two tasks is very limited, which, however, is critical for learning high-quality scene representations. To tackle this problem, in this paper, we propose a unified Neural Radiance Field (NeRF) framework to effectively perform joint scene decomposition and composition for modeling real-world scenes. The decomposition aims at learning disentangled 3D representations of different objects and the background, allowing for scene editing, while scene composition models an entire scene representation for novel view synthesis. Specifically, with a two-stage NeRF framework, we learn a coarse stage for predicting a global radiance field as guidance for point sampling, and in the second fine-grained stage, we perform scene decomposition by a novel one-hot object radiance field regularization module and a pseudo supervision via inpainting to handle ambiguous background regions occluded by objects. The decomposed object-level radiance fields are further composed by using activations from the decomposition module. Extensive quantitative and qualitative results show the effectiveness of our method for scene decomposition and composition, outperforming state-of-the-art methods for both novel-view synthesis and editing tasks.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate into Simplified Chinese实现了卷积神经表示法的有力的场景模型，对实际世界场景的synthesys提供了更高的性能。在这篇论文中，我们面临更加困难的场景，即对卷积神经场景表示的同时synthesys和编辑。现有的方法通常是建立不同的网络来解决这两个任务（即synthesys和编辑），因此模型这两个任务之间的交互和相互关系很有限，这在学习高质量场景表示方面是关键。为了解决这个问题，在这篇论文中，我们提出了一个统一的神经频谱场景（NeRF）框架，以有效地进行场景的分解和组合，以模型现实世界场景。分解目标在学习独立的3D对象和背景的分解，以便场景编辑，而场景组合模型整个场景的表示，用于新视角synthesys。具体来说，我们采用了两个阶段的NeRF框架，在第一阶段，我们学习一个全局的频谱场景，作为点抽象的指导，在第二阶段，我们使用一种新的一键对象频谱场景 régularization模块，以及一种 Pseudo supervision via inpainting来处理隐藏在对象后面的背景区域。分解出的对象级频谱场景被进一步组合使用活动从分解模块。广泛的量化和质量测试结果表明，我们的方法在场景分解和组合方面具有优秀的效果，在新视角synthesys和编辑任务中都高于状态艺术方法。
</details></li>
</ul>
<hr>
<h2 id="A-Comprehensive-Analysis-of-Real-World-Image-Captioning-and-Scene-Identification"><a href="#A-Comprehensive-Analysis-of-Real-World-Image-Captioning-and-Scene-Identification" class="headerlink" title="A Comprehensive Analysis of Real-World Image Captioning and Scene Identification"></a>A Comprehensive Analysis of Real-World Image Captioning and Scene Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02833">http://arxiv.org/abs/2308.02833</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sai Suprabhanu Nallapaneni, Subrahmanyam Konakanchi</li>
<li>for: 本研究旨在evaluating the performance of various image captioning models in real-world environments, where images are often poor in quality and there are numerous points of attention.</li>
<li>methods: 本研究使用了不同的编码机制、语言解码器和训练方法，并使用了MIT Indoor scenes dataset中的800多个图像和65多个场景类来训练和测试模型。</li>
<li>results: 研究发现，使用IC3方法生成更细致的描述可以提高图像描述的准确率和完整性。<details>
<summary>Abstract</summary>
Image captioning is a computer vision task that involves generating natural language descriptions for images. This method has numerous applications in various domains, including image retrieval systems, medicine, and various industries. However, while there has been significant research in image captioning, most studies have focused on high quality images or controlled environments, without exploring the challenges of real-world image captioning. Real-world image captioning involves complex and dynamic environments with numerous points of attention, with images which are often very poor in quality, making it a challenging task, even for humans. This paper evaluates the performance of various models that are built on top of different encoding mechanisms, language decoders and training procedures using a newly created real-world dataset that consists of over 800+ images of over 65 different scene classes, built using MIT Indoor scenes dataset. This dataset is captioned using the IC3 approach that generates more descriptive captions by summarizing the details that are covered by standard image captioning models from unique view-points of the image.
</details>
<details>
<summary>摘要</summary>
Image captioning 是一种计算机视觉任务，它涉及生成图像的自然语言描述。这种方法在各个领域有广泛的应用，如图像检索系统、医学和各种产业。然而，许多研究都集中在高质量图像或控制环境下进行了研究，而忽略了实际世界中的挑战。实际世界中的图像描述 task 面临着复杂和动态的环境，以及众多的关注点，图像的质量也往往很差，这使得这个任务变得非常困难，连人类也有困难。这篇论文评估了基于不同编码机制、语言解码器和训练方法的多种模型的性能，使用了MIT室内场景 dataset 创建的超过 800 张图像、65 个不同场景类的新 dataset。这个 dataset 使用 IC3 方法进行描述，该方法通过从不同视角把握图像的细节来生成更加描述性的描述。
</details></li>
</ul>
<hr>
<h2 id="SwinGar-Spectrum-Inspired-Neural-Dynamic-Deformation-for-Free-Swinging-Garments"><a href="#SwinGar-Spectrum-Inspired-Neural-Dynamic-Deformation-for-Free-Swinging-Garments" class="headerlink" title="SwinGar: Spectrum-Inspired Neural Dynamic Deformation for Free-Swinging Garments"></a>SwinGar: Spectrum-Inspired Neural Dynamic Deformation for Free-Swinging Garments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02827">http://arxiv.org/abs/2308.02827</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tianxing Li, Rui Shi, Qing Zhu, Takashi Kanai</li>
<li>for: 本研究提出了一种基于spectrum学习的新方法，用于生成具有动态效果和个性化细节的服装弯曲。现有的服装动画方法受限于static行为或特定的网络模型，这限制了它们在实际场景中的应用。本方法可以解决这些限制，并提供一个统一的框架，以预测不同服装的动态行为，并且能够生成多种自然和实际的弯曲。</li>
<li>methods: 我们首先观察到，supervised learning中的问题是偏好低频，导致弯曲变得过于平滑。为解决这个问题，我们引入了一种频谱控制策略，从spectrum的角度来增强弯曲的生成。此外，为使网络能够高度普适和有效地学习不同服装的弯曲，我们提出了spectral描述符，以实现全局形状信息的总体描述。基于以上策略，我们开发了一种频谱控制的动态服装弯曲估算器，并将其与长短时间记忆（LSTM）结合使用。该估算器能够自动输出不同服装类型的连续弯曲，无论服装的网格结构或 vertex 数。</li>
<li>results: 我们的实验结果表明，我们的方法在多种自由摆服装上具有remarkable的效果，并且超越了现有的方法。<details>
<summary>Abstract</summary>
Our work presents a novel spectrum-inspired learning-based approach for generating clothing deformations with dynamic effects and personalized details. Existing methods in the field of clothing animation are limited to either static behavior or specific network models for individual garments, which hinders their applicability in real-world scenarios where diverse animated garments are required. Our proposed method overcomes these limitations by providing a unified framework that predicts dynamic behavior for different garments with arbitrary topology and looseness, resulting in versatile and realistic deformations. First, we observe that the problem of bias towards low frequency always hampers supervised learning and leads to overly smooth deformations. To address this issue, we introduce a frequency-control strategy from a spectral perspective that enhances the generation of high-frequency details of the deformation. In addition, to make the network highly generalizable and able to learn various clothing deformations effectively, we propose a spectral descriptor to achieve a generalized description of the global shape information. Building on the above strategies, we develop a dynamic clothing deformation estimator that integrates frequency-controllable attention mechanisms with long short-term memory. The estimator takes as input expressive features from garments and human bodies, allowing it to automatically output continuous deformations for diverse clothing types, independent of mesh topology or vertex count. Finally, we present a neural collision handling method to further enhance the realism of garments. Our experimental results demonstrate the effectiveness of our approach on a variety of free-swinging garments and its superiority over state-of-the-art methods.
</details>
<details>
<summary>摘要</summary>
我们的工作提出了一种新的spectrum-inspired学习基于方法，用于生成动态效果和个性化细节的服装扭曲。现有的服装动画方法在场景中有限， either static behavior or specific network models for individual garments，这限制了它们在实际应用中的可用性。我们的提议方法继承了这些限制，提供了一个统一框架，预测不同服装的动态行为，包括任意的服装结构和松弛度，从而实现了多样化和现实的扭曲。首先，我们发现了低频偏见问题，常常妨碍超级vised学习，导致扭曲过于平滑。为解决这个问题，我们引入了spectral perspective的频率控制策略，提高生成扭曲的高频细节。此外，为使网络具有高度普适性和能够有效地学习多种服装扭曲，我们提议了spectral描述器，实现了全局形状信息的总体描述。基于以上策略，我们开发了一个频率可控的注意力机制，并将其与长短期记忆相结合。该机制能够自动输出不同服装类型的连续扭曲，无论服装的结构或 vertex 数。最后，我们提出了一种神经网络碰撞处理方法，以进一步提高服装的现实性。我们的实验结果表明，我们的方法在多种自由挥移服装上得到了效果，并且与现状方法相比，具有更高的实用性。
</details></li>
</ul>
<hr>
<h2 id="Deep-Image-Harmonization-in-Dual-Color-Spaces"><a href="#Deep-Image-Harmonization-in-Dual-Color-Spaces" class="headerlink" title="Deep Image Harmonization in Dual Color Spaces"></a>Deep Image Harmonization in Dual Color Spaces</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02813">http://arxiv.org/abs/2308.02813</a></li>
<li>repo_url: None</li>
<li>paper_authors: Linfeng Tan, Jiangtong Li, Li Niu, Liqing Zhang</li>
<li>for:  This paper focuses on addressing the issue of image inconsistency in image composition, specifically in the context of foreground and background.</li>
<li>methods:  The proposed method utilizes dual color spaces, specifically $RGB$ and $Lab$, to decorrelate the color and illumination features in the image. The method consists of a $RGB$ harmonization backbone, an $Lab$ encoding module, and an $Lab$ control module.</li>
<li>results:  The proposed method alleviates the workload in the harmonization process and provides disentangled color and illumination statistics, leading to improved image harmonization results.<details>
<summary>Abstract</summary>
Image harmonization is an essential step in image composition that adjusts the appearance of composite foreground to address the inconsistency between foreground and background. Existing methods primarily operate in correlated $RGB$ color space, leading to entangled features and limited representation ability. In contrast, decorrelated color space (e.g., $Lab$) has decorrelated channels that provide disentangled color and illumination statistics. In this paper, we explore image harmonization in dual color spaces, which supplements entangled $RGB$ features with disentangled $L$, $a$, $b$ features to alleviate the workload in harmonization process. The network comprises a $RGB$ harmonization backbone, an $Lab$ encoding module, and an $Lab$ control module. The backbone is a U-Net network translating composite image to harmonized image. Three encoders in $Lab$ encoding module extract three control codes independently from $L$, $a$, $b$ channels, which are used to manipulate the decoder features in harmonization backbone via $Lab$ control module. Our code and model are available at \href{https://github.com/bcmi/DucoNet-Image-Harmonization}{https://github.com/bcmi/DucoNet-Image-Harmonization}.
</details>
<details>
<summary>摘要</summary>
Image harmonization 是一个重要的图像组合步骤，它调整了 composite foreground 的外观，以解决背景和前景的不一致。现有的方法主要在相关的 $RGB$ 色彩空间中进行操作，导致特征被束缚在一起，表达能力有限。与此相反，decorrelated color space （例如 $Lab$）具有分离的通道，提供了分离的色度和照明统计。在这篇论文中，我们探讨了图像协调在双色空间中，该空间补充了束缚 $RGB$ 特征的 $L$, $a$, $b$ 特征，以减轻协调过程中的工作负担。网络包括 $RGB$ 协调背bone， $Lab$ 编码模块，和 $Lab$ 控制模块。背bone 是一个 U-Net 网络，将 composite image 翻译成协调后的图像。 $Lab$ 编码模块 中的三个encoder 独立地从 $L$, $a$, $b$ 通道提取三个控制代码，这些代码用于在协调背bone 中 manipulate Decoder 特征。我们的代码和模型可以在 \href{https://github.com/bcmi/DucoNet-Image-Harmonization}{https://github.com/bcmi/DucoNet-Image-Harmonization} 上获取。
</details></li>
</ul>
<hr>
<h2 id="Thin-On-Sensor-Nanophotonic-Array-Cameras"><a href="#Thin-On-Sensor-Nanophotonic-Array-Cameras" class="headerlink" title="Thin On-Sensor Nanophotonic Array Cameras"></a>Thin On-Sensor Nanophotonic Array Cameras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02797">http://arxiv.org/abs/2308.02797</a></li>
<li>repo_url: None</li>
<li>paper_authors: Praneeth Chakravarthula, Jipeng Sun, Xiao Li, Chenyang Lei, Gene Chou, Mario Bijelic, Johannes Froesch, Arka Majumdar, Felix Heide</li>
<li>for: The paper is written for exploring an alternative to traditional compound optics in commodity camera systems, using flat nanophotonic computational cameras that employ an array of skewed lenslets and a learned reconstruction approach.</li>
<li>methods: The paper proposes a differentiable optimization method that continuously samples over the visible spectrum and factorizes the optical modulation for different incident fields into individual lenses. The authors also use a generative diffusion model for probabilistic reconstruction.</li>
<li>results: The paper demonstrates the ability to recover images from diverse scenes in broadband with a single nanophotonic layer, using both simulation and an experimental prototype. The proposed flat camera design is capable of achieving high-quality image reconstruction with a flat and thin metasurface.<details>
<summary>Abstract</summary>
Today's commodity camera systems rely on compound optics to map light originating from the scene to positions on the sensor where it gets recorded as an image. To record images without optical aberrations, i.e., deviations from Gauss' linear model of optics, typical lens systems introduce increasingly complex stacks of optical elements which are responsible for the height of existing commodity cameras. In this work, we investigate flat nanophotonic computational cameras as an alternative that employs an array of skewed lenslets and a learned reconstruction approach. The optical array is embedded on a metasurface that, at 700~nm height, is flat and sits on the sensor cover glass at 2.5~mm focal distance from the sensor. To tackle the highly chromatic response of a metasurface and design the array over the entire sensor, we propose a differentiable optimization method that continuously samples over the visible spectrum and factorizes the optical modulation for different incident fields into individual lenses. We reconstruct a megapixel image from our flat imager with a learned probabilistic reconstruction method that employs a generative diffusion model to sample an implicit prior. To tackle scene-dependent aberrations in broadband, we propose a method for acquiring paired captured training data in varying illumination conditions. We assess the proposed flat camera design in simulation and with an experimental prototype, validating that the method is capable of recovering images from diverse scenes in broadband with a single nanophotonic layer.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:今天的商用相机系统依靠复合光学来将场景中的光映射到感光器上的位置，并以图像的形式记录下来。为了不受光学偏差的影响，常见的镜系统会引入越来越复杂的光学元件，这些元件负责现有的商用相机的高度。在这个工作中，我们研究了使用平板光学计算相机，该设计包括一个倾斜的透镜阵列和一种学习重建方法。该光学阵列被嵌入在700nm的高度上的金属表面上，并位于感光器保护玻璃上的2.5mm距离上。为了解决金属表面的高度吸收和设计阵列，我们提出了一种可 diferenciable 优化方法，该方法可以不断样本在可见光谱中，并将不同的入射场分解成各个透镜。我们使用一种学习涂抹模型来重建一个兆像，并使用一种生成扩散模型来采样一个隐藏的先验。为了解决场景相依的偏差，我们提出了一种获得包含变化照明条件的对应训练数据的方法。我们在实验和模拟中验证了我们的平板相机设计，并证明了该方法可以从多种场景中恢复宽频图像，只需一个单一的 nanophotonic 层。
</details></li>
</ul>
<hr>
<h2 id="Unfolding-Once-is-Enough-A-Deployment-Friendly-Transformer-Unit-for-Super-Resolution"><a href="#Unfolding-Once-is-Enough-A-Deployment-Friendly-Transformer-Unit-for-Super-Resolution" class="headerlink" title="Unfolding Once is Enough: A Deployment-Friendly Transformer Unit for Super-Resolution"></a>Unfolding Once is Enough: A Deployment-Friendly Transformer Unit for Super-Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02794">http://arxiv.org/abs/2308.02794</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yongliuy/ditn">https://github.com/yongliuy/ditn</a></li>
<li>paper_authors: Yong Liu, Hang Dong, Boyang Liang, Songwei Liu, Qingji Dong, Kai Chen, Fangmin Chen, Lean Fu, Fei Wang</li>
<li>for: 这个论文主要是为了提出一个可部署的内部单元Transformer网络（DITN），用于单一图像超解析（SISR）任务。</li>
<li>methods: 这个论文使用了一个内部单元Transformer层（ITL）和一个空间意识层（SAL）来有效地重建本地结构信息和探索距离依赖，以提高SISR任务的性能。</li>
<li>results: 这个论文的模型可以在训练和部署平台上实现高效的性能，并且提供了一些实验证明这个模型的可行性和高效性。<details>
<summary>Abstract</summary>
Recent years have witnessed a few attempts of vision transformers for single image super-resolution (SISR). Since the high resolution of intermediate features in SISR models increases memory and computational requirements, efficient SISR transformers are more favored. Based on some popular transformer backbone, many methods have explored reasonable schemes to reduce the computational complexity of the self-attention module while achieving impressive performance. However, these methods only focus on the performance on the training platform (e.g., Pytorch/Tensorflow) without further optimization for the deployment platform (e.g., TensorRT). Therefore, they inevitably contain some redundant operators, posing challenges for subsequent deployment in real-world applications. In this paper, we propose a deployment-friendly transformer unit, namely UFONE (i.e., UnFolding ONce is Enough), to alleviate these problems. In each UFONE, we introduce an Inner-patch Transformer Layer (ITL) to efficiently reconstruct the local structural information from patches and a Spatial-Aware Layer (SAL) to exploit the long-range dependencies between patches. Based on UFONE, we propose a Deployment-friendly Inner-patch Transformer Network (DITN) for the SISR task, which can achieve favorable performance with low latency and memory usage on both training and deployment platforms. Furthermore, to further boost the deployment efficiency of the proposed DITN on TensorRT, we also provide an efficient substitution for layer normalization and propose a fusion optimization strategy for specific operators. Extensive experiments show that our models can achieve competitive results in terms of qualitative and quantitative performance with high deployment efficiency. Code is available at \url{https://github.com/yongliuy/DITN}.
</details>
<details>
<summary>摘要</summary>
近年来，Single Image Super-Resolution（SISR）领域内有一些视力 трансформа器的尝试。由于高级别特征的存储和计算需求增加，efficient SISR transformer更受欢迎。基于一些流行的transformer backbone，许多方法已经探索了合理的减少自注意模块的计算复杂度的方法，以达到出色的表现。然而，这些方法只关注在训练平台（如PyTorch/TensorFlow）上的表现，没有进一步优化 для部署平台（如TensorRT）。因此，它们绝对包含一些冗余的运算符，对实际应用中的部署带来挑战。在这篇论文中，我们提出了一种部署友好的transformer单元，称为UFONE（即UnFolding ONce is Enough），以解决这些问题。在每个UFONE中，我们引入了 Inner-patch Transformer Layer（ITL），以有效地重构局部结构信息，并在每个patch之间引入Spatial-Aware Layer（SAL），以利用远程依赖关系。基于UFONE，我们提出了一种部署友好的Inner-patch Transformer Network（DITN），用于SISR任务，可以在训练和部署平台上达到低延迟和内存使用率的良好性能。此外，为了进一步提高提档端的部署效率，我们还提供了一种高效的层normalization替换方法和一种特定运算符的融合优化策略。广泛的实验表明，我们的模型可以在qualitative和quantitative方面具有竞争性的性能，同时具有高部署效率。代码可以在\url{https://github.com/yongliuy/DITN}上获取。
</details></li>
</ul>
<hr>
<h2 id="Few-shot-Class-Incremental-Semantic-Segmentation-via-Pseudo-Labeling-and-Knowledge-Distillation"><a href="#Few-shot-Class-Incremental-Semantic-Segmentation-via-Pseudo-Labeling-and-Knowledge-Distillation" class="headerlink" title="Few-shot Class-Incremental Semantic Segmentation via Pseudo-Labeling and Knowledge Distillation"></a>Few-shot Class-Incremental Semantic Segmentation via Pseudo-Labeling and Knowledge Distillation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02790">http://arxiv.org/abs/2308.02790</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chasonjiang/fscilss">https://github.com/chasonjiang/fscilss</a></li>
<li>paper_authors: Chengjia Jiang, Tao Wang, Sien Li, Jinyang Wang, Shirui Wang, Antonios Antoniou<br>for:The paper addresses the problem of learning new classes for semantic segmentation models from few examples, which is challenging due to limited novel data and avoiding catastrophic forgetting.methods:The proposed approach uses a pseudo-labeling strategy to augment few-shot training annotations, transferring knowledge from labeled images to unlabeled images with a coarse-to-fine approach. This includes matching labeled images to their nearest neighbors in the unlabeled image set at the scene level, and obtaining pseudo-labels within this neighborhood using classifiers learned on the few-shot annotations. Knowledge distillation is also used on both labeled and unlabeled data to retain knowledge on existing classes.results:The proposed approach is validated on the Cityscapes and KITTI datasets in the self-driving domain, with extensive experiments showing its efficacy in learning new classes from few examples while retaining knowledge on existing classes.<details>
<summary>Abstract</summary>
We address the problem of learning new classes for semantic segmentation models from few examples, which is challenging because of the following two reasons. Firstly, it is difficult to learn from limited novel data to capture the underlying class distribution. Secondly, it is challenging to retain knowledge for existing classes and to avoid catastrophic forgetting. For learning from limited data, we propose a pseudo-labeling strategy to augment the few-shot training annotations in order to learn novel classes more effectively. Given only one or a few images labeled with the novel classes and a much larger set of unlabeled images, we transfer the knowledge from labeled images to unlabeled images with a coarse-to-fine pseudo-labeling approach in two steps. Specifically, we first match each labeled image to its nearest neighbors in the unlabeled image set at the scene level, in order to obtain images with a similar scene layout. This is followed by obtaining pseudo-labels within this neighborhood by applying classifiers learned on the few-shot annotations. In addition, we use knowledge distillation on both labeled and unlabeled data to retain knowledge on existing classes. We integrate the above steps into a single convolutional neural network with a unified learning objective. Extensive experiments on the Cityscapes and KITTI datasets validate the efficacy of the proposed approach in the self-driving domain. Code is available from https://github.com/ChasonJiang/FSCILSS.
</details>
<details>
<summary>摘要</summary>
我们面临的问题是从几个示例学习新的类型，这是因为以下两个原因困难：首先，从有限的新数据中学习到基于类型分布的下面是困难的；其次，保持现有类型的知识，而不是忘记旧类型。为了学习几个示例，我们提议使用假标注策略来增强几个示例的训练签名，以便更好地学习新类型。我们给每个标注的图像找到与其相似的场景图像，然后在这个场景图像集中获取pseudo-标签，并在这个邻居集中应用经过几个示例签名学习的分类器。此外，我们还使用知识继承来保持现有类型的知识。我们将上述步骤 integrate into a single convolutional neural network with a unified learning objective。我们在Cityscapes和KITTI数据集上进行了广泛的实验，并证明了我们的方法在自动驾驶领域的有效性。代码可以从https://github.com/ChasonJiang/FSCILSS中下载。
</details></li>
</ul>
<hr>
<h2 id="A-Voting-Stacking-Ensemble-of-Inception-Networks-for-Cervical-Cytology-Classification"><a href="#A-Voting-Stacking-Ensemble-of-Inception-Networks-for-Cervical-Cytology-Classification" class="headerlink" title="A Voting-Stacking Ensemble of Inception Networks for Cervical Cytology Classification"></a>A Voting-Stacking Ensemble of Inception Networks for Cervical Cytology Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02781">http://arxiv.org/abs/2308.02781</a></li>
<li>repo_url: None</li>
<li>paper_authors: Linyi Qian, Qian Huang, Yulin Chen, Junzhou Chen<br>for: 这个研究旨在提高乳腺癌早期检测和诊断精度，以减少女性健康威胁。methods: 本研究使用了三个Inception网络作为基础学习者，并通过投票组合集成了他们的输出。遗传学习者在投票组合集成模型中的错误样本上进行了进一步的训练，并使用了多层 Stacking 组合架构以提高性能。results: 研究在 SIPakMed、Herlev 和 Mendeley 数据集上进行了评估，实现了准确率100%、100% 和 100% 分别。评估结果超越了目前州先的方法，显示出本方法在实际应用中具有优秀的潜力，可以帮助病理学家早期检测乳腺癌。<details>
<summary>Abstract</summary>
Cervical cancer is one of the most severe diseases threatening women's health. Early detection and diagnosis can significantly reduce cancer risk, in which cervical cytology classification is indispensable. Researchers have recently designed many networks for automated cervical cancer diagnosis, but the limited accuracy and bulky size of these individual models cannot meet practical application needs. To address this issue, we propose a Voting-Stacking ensemble strategy, which employs three Inception networks as base learners and integrates their outputs through a voting ensemble. The samples misclassified by the ensemble model generate a new training set on which a linear classification model is trained as the meta-learner and performs the final predictions. In addition, a multi-level Stacking ensemble framework is designed to improve performance further. The method is evaluated on the SIPakMed, Herlev, and Mendeley datasets, achieving accuracies of 100%, 100%, and 100%, respectively. The experimental results outperform the current state-of-the-art (SOTA) methods, demonstrating its potential for reducing screening workload and helping pathologists detect cervical cancer.
</details>
<details>
<summary>摘要</summary>
cervical cancer 是女性健康中最严重的一种疾病。早期检测和诊断可以显著降低 cancer 的风险，在这个过程中，预防细胞学分类是不可或缺的。研究人员最近设计了许多自动诊断 cervical cancer 的网络，但这些个体模型的准确率和大小均不能满足实际应用需求。为解决这个问题，我们提出了一种投票汇聚策略，该策略使用三个 Inception 网络作为基础学习器，并将其输出集成到投票 ensemble。样本被模型错分类后生成一个新的训练集，并在这个集合上训练一个线性分类模型，并进行最终预测。此外，我们还设计了多级汇聚框架，以进一步提高性能。我们在 SIPakMed、Herlev 和 Mendeley 数据集上进行了实验，实现了100%、100% 和 100% 的准确率，分别。实验结果超出当前状态艺术（SOTA）方法的性能，demonstrating its potential for reducing screening workload and helping pathologists detect cervical cancer.
</details></li>
</ul>
<hr>
<h2 id="Dual-Degradation-Inspired-Deep-Unfolding-Network-for-Low-Light-Image-Enhancement"><a href="#Dual-Degradation-Inspired-Deep-Unfolding-Network-for-Low-Light-Image-Enhancement" class="headerlink" title="Dual Degradation-Inspired Deep Unfolding Network for Low-Light Image Enhancement"></a>Dual Degradation-Inspired Deep Unfolding Network for Low-Light Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02776">http://arxiv.org/abs/2308.02776</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huake Wang, Xingsong Hou, Xiaoyang Yan<br>for: This paper proposes a novel deep learning network called DASUNet for low-light image enhancement, which explicitly simulates the deterioration mechanism of low-light images and learns two distinct image priors via considering degradation specificity between luminance and chrominance spaces.methods: The proposed DASUNet uses a dual degradation model (DDM) to simulate the deterioration mechanism of low-light images, and an alternating optimization solution to solve the proposed DDM. Additionally, the network uses a prior modeling module (PMM) to enhance the representation capability of dual degradation priors, and a space aggregation module (SAM) to boost the interaction of two degradation models.results: Extensive experiments on multiple popular low-light image datasets validate the effectiveness of DASUNet compared to canonical state-of-the-art low-light image enhancement methods.<details>
<summary>Abstract</summary>
Although low-light image enhancement has achieved great stride based on deep enhancement models, most of them mainly stress on enhancement performance via an elaborated black-box network and rarely explore the physical significance of enhancement models. Towards this issue, we propose a Dual degrAdation-inSpired deep Unfolding network, termed DASUNet, for low-light image enhancement. Specifically, we construct a dual degradation model (DDM) to explicitly simulate the deterioration mechanism of low-light images. It learns two distinct image priors via considering degradation specificity between luminance and chrominance spaces. To make the proposed scheme tractable, we design an alternating optimization solution to solve the proposed DDM. Further, the designed solution is unfolded into a specified deep network, imitating the iteration updating rules, to form DASUNet. Local and long-range information are obtained by prior modeling module (PMM), inheriting the advantages of convolution and Transformer, to enhance the representation capability of dual degradation priors. Additionally, a space aggregation module (SAM) is presented to boost the interaction of two degradation models. Extensive experiments on multiple popular low-light image datasets validate the effectiveness of DASUNet compared to canonical state-of-the-art low-light image enhancement methods. Our source code and pretrained model will be publicly available.
</details>
<details>
<summary>摘要</summary>
although low-light image enhancement has made great strides based on deep enhancement models, most of them focus on improving performance through complex black-box networks and rarely explore the physical significance of enhancement models. To address this issue, we propose a Dual degradation-inspired deep Unfolding network, termed DASUNet, for low-light image enhancement. Specifically, we construct a dual degradation model (DDM) to explicitly simulate the deterioration mechanism of low-light images. It learns two distinct image priors by considering the degradation specificity between luminance and chrominance spaces. To make the proposed scheme tractable, we design an alternating optimization solution to solve the proposed DDM. Further, the designed solution is unfolded into a specified deep network, imitating the iteration updating rules, to form DASUNet. Local and long-range information are obtained by prior modeling module (PMM), inheriting the advantages of convolution and Transformer, to enhance the representation capability of dual degradation priors. Additionally, a space aggregation module (SAM) is presented to boost the interaction of two degradation models. Extensive experiments on multiple popular low-light image datasets validate the effectiveness of DASUNet compared to canonical state-of-the-art low-light image enhancement methods. Our source code and pretrained model will be publicly available.Note: The translation is in Simplified Chinese, which is one of the two standard Chinese scripts used in mainland China and Singapore. The other script is Traditional Chinese, which is used in Taiwan, Hong Kong, and other countries.
</details></li>
</ul>
<hr>
<h2 id="One-stage-Low-resolution-Text-Recognition-with-High-resolution-Knowledge-Transfer"><a href="#One-stage-Low-resolution-Text-Recognition-with-High-resolution-Knowledge-Transfer" class="headerlink" title="One-stage Low-resolution Text Recognition with High-resolution Knowledge Transfer"></a>One-stage Low-resolution Text Recognition with High-resolution Knowledge Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02770">http://arxiv.org/abs/2308.02770</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/csguoh/kd-ltr">https://github.com/csguoh/kd-ltr</a></li>
<li>paper_authors: Hang Guo, Tao Dai, Mingyan Zhu, Guanghao Meng, Bin Chen, Zhi Wang, Shu-Tao Xia</li>
<li>for: 提高低分辨率文本识别精度和效率，适用于实际应用场景。</li>
<li>methods: 基于知识传递的一Stage框架，包括视觉吸引损失、semantic contrastive loss和软幂损失等多种损失函数，以提高模型的学习效果和稳定性。</li>
<li>results: 对多种低分辨率文本数据进行了广泛的实验，表明提出的方法可以效果地提高低分辨率文本识别精度和效率，并且比 tradicional two-stage 框架更加高效和稳定。<details>
<summary>Abstract</summary>
Recognizing characters from low-resolution (LR) text images poses a significant challenge due to the information deficiency as well as the noise and blur in low-quality images. Current solutions for low-resolution text recognition (LTR) typically rely on a two-stage pipeline that involves super-resolution as the first stage followed by the second-stage recognition. Although this pipeline is straightforward and intuitive, it has to use an additional super-resolution network, which causes inefficiencies during training and testing. Moreover, the recognition accuracy of the second stage heavily depends on the reconstruction quality of the first stage, causing ineffectiveness. In this work, we attempt to address these challenges from a novel perspective: adapting the recognizer to low-resolution inputs by transferring the knowledge from the high-resolution. Guided by this idea, we propose an efficient and effective knowledge distillation framework to achieve multi-level knowledge transfer. Specifically, the visual focus loss is proposed to extract the character position knowledge with resolution gap reduction and character region focus, the semantic contrastive loss is employed to exploit the contextual semantic knowledge with contrastive learning, and the soft logits loss facilitates both local word-level and global sequence-level learning from the soft teacher label. Extensive experiments show that the proposed one-stage pipeline significantly outperforms super-resolution based two-stage frameworks in terms of effectiveness and efficiency, accompanied by favorable robustness. Code is available at https://github.com/csguoh/KD-LTR.
</details>
<details>
<summary>摘要</summary>
Current solutions for low-resolution text recognition (LTR) typically rely on a two-stage pipeline that involves super-resolution as the first stage followed by the second-stage recognition. However, this pipeline is not efficient and effective due to the additional super-resolution network and the heavy dependence of the second stage on the reconstruction quality of the first stage. In this work, we propose a novel approach to address these challenges by adapting the recognizer to low-resolution inputs through knowledge transfer from high-resolution inputs. Specifically, we use a knowledge distillation framework that includes visual focus loss, semantic contrastive loss, and soft logits loss to extract character position knowledge, exploit contextual semantic knowledge, and facilitate both local word-level and global sequence-level learning. Extensive experiments show that our one-stage pipeline outperforms super-resolution based two-stage frameworks in terms of effectiveness and efficiency, with favorable robustness. Code is available at https://github.com/csguoh/KD-LTR.Here's the Chinese text with Traditional Chinese characters:现有的低分辨率文本识别（LTR）解决方案通常是以二阶段管道为基础，首先使用超解析，然后进行第二阶段识别。然而，这个管道并不是非常有效和高效，因为需要额外的超解析网络，并且第二阶段识别的精度仅仅取决于第一阶段的重建质量。在这个工作中，我们尝试通过将知识传递到低分辨率输入中来解决这些挑战。我们提出了一个高效和有效的知识传递框架，包括视觉钩损传学、semantic contrastive learning和软顶掌握损传学。实验结果显示，我们的一阶段管道明显超过了基于超解析的二阶段管道，在效率和稳定性方面具有优势。代码可以在https://github.com/csguoh/KD-LTR中找到。
</details></li>
</ul>
<hr>
<h2 id="DeDrift-Robust-Similarity-Search-under-Content-Drift"><a href="#DeDrift-Robust-Similarity-Search-under-Content-Drift" class="headerlink" title="DeDrift: Robust Similarity Search under Content Drift"></a>DeDrift: Robust Similarity Search under Content Drift</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02752">http://arxiv.org/abs/2308.02752</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dmitry Baranchuk, Matthijs Douze, Yash Upadhyay, I. Zeki Yalniz</li>
<li>for: 这个研究旨在探讨媒体分享网站上内容的统计分布随着时间的变化，以及这种变化对大规模相似搜寻工具的影响。</li>
<li>methods: 这篇研究使用 nearest neighbor search in embedding space 来 investigate the impact of content drift on large-scale similarity search tools, and introduces a method called DeDrift to continuously adapt the indexing structures on-the-fly.</li>
<li>results: DeDrift 可以几乎完全消除因查询和数据库内容迁移而导致的搜寻精度下降，并且比全 indexes reconstruction 更快速，可以达到 100 倍的速度提升。<details>
<summary>Abstract</summary>
The statistical distribution of content uploaded and searched on media sharing sites changes over time due to seasonal, sociological and technical factors. We investigate the impact of this "content drift" for large-scale similarity search tools, based on nearest neighbor search in embedding space. Unless a costly index reconstruction is performed frequently, content drift degrades the search accuracy and efficiency. The degradation is especially severe since, in general, both the query and database distributions change.   We introduce and analyze real-world image and video datasets for which temporal information is available over a long time period. Based on the learnings, we devise DeDrift, a method that updates embedding quantizers to continuously adapt large-scale indexing structures on-the-fly. DeDrift almost eliminates the accuracy degradation due to the query and database content drift while being up to 100x faster than a full index reconstruction.
</details>
<details>
<summary>摘要</summary>
随着时间的推移，媒体分享网站上上传和搜索的内容分布也发生变化，这些变化受到季节性、社会性和技术因素的影响。我们研究这些内容漂移（content drift）对大规模相似搜索工具的影响，基于最近邻居搜索空间中的嵌入式搜索。如果不定期更新索引，内容漂移会导致搜索精度和效率下降，特别是查询和数据库分布都发生变化。我们使用实际世界的图像和视频数据集，其中具有长时间的时间信息，以便学习内容漂移的影响。根据这些学习，我们提出了DeDrift方法，它可以在运行中continuously更新大规模索引结构，以适应内容漂移。DeDrift可以减少查询和数据库内容漂移导致的精度下降，同时比全Index重建更快，可以达到100倍的提升。
</details></li>
</ul>
<hr>
<h2 id="Discrimination-of-Radiologists-Utilizing-Eye-Tracking-Technology-and-Machine-Learning-A-Case-Study"><a href="#Discrimination-of-Radiologists-Utilizing-Eye-Tracking-Technology-and-Machine-Learning-A-Case-Study" class="headerlink" title="Discrimination of Radiologists Utilizing Eye-Tracking Technology and Machine Learning: A Case Study"></a>Discrimination of Radiologists Utilizing Eye-Tracking Technology and Machine Learning: A Case Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02748">http://arxiv.org/abs/2308.02748</a></li>
<li>repo_url: None</li>
<li>paper_authors: Stanford Martinez, Carolina Ramirez-Tamayo, Syed Hasib Akhter Faruqui, Kal L. Clark, Adel Alaeddini, Nicholas Czarnek, Aarushi Aggarwal, Sahra Emamzadeh, Jeffrey R. Mock, Edward J. Golob</li>
<li>for: 鉴别医生经验水平</li>
<li>methods: 使用个性化高维度视搜策略和精度编码方法</li>
<li>results: 比较现有方法表现出色，可以帮助鉴别医生的经验水平和需要进一步培训<details>
<summary>Abstract</summary>
Perception-related errors comprise most diagnostic mistakes in radiology. To mitigate this problem, radiologists employ personalized and high-dimensional visual search strategies, otherwise known as search patterns. Qualitative descriptions of these search patterns, which involve the physician verbalizing or annotating the order he/she analyzes the image, can be unreliable due to discrepancies in what is reported versus the actual visual patterns. This discrepancy can interfere with quality improvement interventions and negatively impact patient care. This study presents a novel discretized feature encoding based on spatiotemporal binning of fixation data for efficient geometric alignment and temporal ordering of eye movement when reading chest X-rays. The encoded features of the eye-fixation data are employed by machine learning classifiers to discriminate between faculty and trainee radiologists. We include a clinical trial case study utilizing the Area Under the Curve (AUC), Accuracy, F1, Sensitivity, and Specificity metrics for class separability to evaluate the discriminability between the two subjects in regard to their level of experience. We then compare the classification performance to state-of-the-art methodologies. A repeatability experiment using a separate dataset, experimental protocol, and eye tracker was also performed using eight subjects to evaluate the robustness of the proposed approach. The numerical results from both experiments demonstrate that classifiers employing the proposed feature encoding methods outperform the current state-of-the-art in differentiating between radiologists in terms of experience level. This signifies the potential impact of the proposed method for identifying radiologists' level of expertise and those who would benefit from additional training.
</details>
<details>
<summary>摘要</summary>
诊断错误主要由视觉相关错误引起，以避免这个问题，辐射医生使用个性化高维度视觉搜索策略，即搜索模式。但是，这些搜索模式的 качеitative描述可能不准确，因为医生所报告的与实际视觉模式之间存在差异。这种差异可能会对质量改进 intervención和患者护理产生负面影响。本研究提出了一种新的Feature编码方法，基于维度分割和时间排序的眼动数据，以实现高效的几何对齐和时间排序。这些编码的特征被用于机器学习分类器，以分别抑制faculty和学生医生的诊断能力。我们在使用AUC、准确率、F1、感知率和特征率等度量进行评估分类表达的临床试验中，与现有方法进行比较。此外，我们还进行了使用不同数据集、实验室和眼动仪的重复试验，以评估提案的稳定性。 numerically的结果表明，使用提案的特征编码方法的分类器，在分别抑制faculty和学生医生的诊断能力方面表现出色，而且比现有方法更高效。这表明提案的方法可能对于诊断能力水平的识别和需要进行更多训练的医生进行了深刻的影响。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Part-Informed-Visual-Language-Learning-for-Person-Re-Identification"><a href="#Exploring-Part-Informed-Visual-Language-Learning-for-Person-Re-Identification" class="headerlink" title="Exploring Part-Informed Visual-Language Learning for Person Re-Identification"></a>Exploring Part-Informed Visual-Language Learning for Person Re-Identification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02738">http://arxiv.org/abs/2308.02738</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yin Lin, Cong Liu, Yehansen Chen, Jinshui Hu, Bing Yin, Baocai Yin, Zengfu Wang<br>for:* 本研究旨在提高基于视觉语言学习的人识别（ReID）任务中的细腻特征。methods:* 该方法提出使用部分指导语言监督来增强细腻视觉特征。* 该方法包括人体分割指南尝试策略和层次融合方式来确保在部分特征semantic consistency。results:* 该方法在四个常用的ReID benchmark上 achieve substantial improvements，特别是在MSMT17数据集上report 90.3% Rank-1和76.5% mAP。<details>
<summary>Abstract</summary>
Recently, visual-language learning has shown great potential in enhancing visual-based person re-identification (ReID). Existing visual-language learning-based ReID methods often focus on whole-body scale image-text feature alignment, while neglecting supervisions on fine-grained part features. This choice simplifies the learning process but cannot guarantee within-part feature semantic consistency thus hindering the final performance. Therefore, we propose to enhance fine-grained visual features with part-informed language supervision for ReID tasks. The proposed method, named Part-Informed Visual-language Learning ($\pi$-VL), suggests that (i) a human parsing-guided prompt tuning strategy and (ii) a hierarchical fusion-based visual-language alignment paradigm play essential roles in ensuring within-part feature semantic consistency. Specifically, we combine both identity labels and parsing maps to constitute pixel-level text prompts and fuse multi-stage visual features with a light-weight auxiliary head to perform fine-grained image-text alignment. As a plug-and-play and inference-free solution, our $\pi$-VL achieves substantial improvements over previous state-of-the-arts on four common-used ReID benchmarks, especially reporting 90.3% Rank-1 and 76.5% mAP for the most challenging MSMT17 database without bells and whistles.
</details>
<details>
<summary>摘要</summary>
最近，视觉语言学习已经显示出增强视觉基于人识别（ReID）的潜在能力。现有的视觉语言学习基于ReID方法通常会关注全身图像特征对齐，而忽略细节特征的监督。这种选择可以简化学习过程，但无法保证内部特征 semantics的一致性，从而降低最终性能。因此，我们提出了在ReID任务中增强细节视觉特征的方法，即Part-Informed Visual-language Learning（$\pi$-VL）。我们的方法包括以下两个关键组成部分：1. 人体分割指导的提问调整策略。2. 层次融合基于视觉语言对齐方法。具体来说，我们将标签和分割地图组合成像素级文本提示，并将多stage视觉特征与轻量级辅助头进行集成，以实现细节图像-文本对齐。我们的$\pi$-VL方法可以作为插件和推理自由解决方案，在四个常用的ReID benchmark上实现了显著的提高，特别是在MSMT17数据集上Report 90.3% Rank-1和76.5% mAP的最高得分。
</details></li>
</ul>
<hr>
<h2 id="EndoDepthL-Lightweight-Endoscopic-Monocular-Depth-Estimation-with-CNN-Transformer"><a href="#EndoDepthL-Lightweight-Endoscopic-Monocular-Depth-Estimation-with-CNN-Transformer" class="headerlink" title="EndoDepthL: Lightweight Endoscopic Monocular Depth Estimation with CNN-Transformer"></a>EndoDepthL: Lightweight Endoscopic Monocular Depth Estimation with CNN-Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02716">http://arxiv.org/abs/2308.02716</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yangke Li</li>
<li>for: 提高endoscopic imaging中深度估计的准确率和效果，特别是实时推理和光泽反射的影响。</li>
<li>methods: 提出一种轻量级解决方案，名为EndoDepthL，它将Convolutional Neural Networks (CNN)和Transformers结合使用，预测多尺度深度地图。我们的方法包括优化网络架构、扩展多尺度扩展 convolution 和多通道注意机制。我们还引入了一个统计信息边界面面 mask，以降低光泽反射区域的影响。</li>
<li>results: 我们对假象深度估计在endoscopic imaging中的性能进行了全面评估，并与现有基eline解决方案进行了比较。结果表明，EndoDepthL  Ensures depth estimation accuracy with a lightweight structure。<details>
<summary>Abstract</summary>
In this study, we address the key challenges concerning the accuracy and effectiveness of depth estimation for endoscopic imaging, with a particular emphasis on real-time inference and the impact of light reflections. We propose a novel lightweight solution named EndoDepthL that integrates Convolutional Neural Networks (CNN) and Transformers to predict multi-scale depth maps. Our approach includes optimizing the network architecture, incorporating multi-scale dilated convolution, and a multi-channel attention mechanism. We also introduce a statistical confidence boundary mask to minimize the impact of reflective areas. To better evaluate the performance of monocular depth estimation in endoscopic imaging, we propose a novel complexity evaluation metric that considers network parameter size, floating-point operations, and inference frames per second. We comprehensively evaluate our proposed method and compare it with existing baseline solutions. The results demonstrate that EndoDepthL ensures depth estimation accuracy with a lightweight structure.
</details>
<details>
<summary>摘要</summary>
在本研究中，我们解决了投射精度和效果的关键挑战，尤其是实时推理和光折射的影响。我们提出了一种新的轻量级解决方案，名为EndoDepthL，它将Convolutional Neural Networks（CNN）和Transformers结合以预测多尺度深度地图。我们的方法包括优化网络架构、使用多尺度扩展 convolution 和多通道注意机制。我们还引入了一个统计信息边界面面来最小化反射区域的影响。为更好地评估单摄深度估计在内窥影像中的性能，我们提出了一个新的复杂度评估指标，考虑网络参数大小、浮点运算和推理帧数。我们对我们的提议方法进行了全面评估，并与现有的基线解决方案进行比较。结果显示，EndoDepthL  Ensures depth estimation accuracy with a lightweight structure。
</details></li>
</ul>
<hr>
<h2 id="Exploring-the-Effect-of-Sparse-Recovery-on-the-Quality-of-Image-Superresolution"><a href="#Exploring-the-Effect-of-Sparse-Recovery-on-the-Quality-of-Image-Superresolution" class="headerlink" title="Exploring the Effect of Sparse Recovery on the Quality of Image Superresolution"></a>Exploring the Effect of Sparse Recovery on the Quality of Image Superresolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02714">http://arxiv.org/abs/2308.02714</a></li>
<li>repo_url: None</li>
<li>paper_authors: Antonio Castro</li>
<li>for: 这个论文的目的是研究用字典学习来进行图像超分解。</li>
<li>methods: 这个论文使用了一对关联的字典来学习图像块的高分和低分对应关系，使得对于低分输入图像，可以使用高分字典来恢复对应的高分图像块。</li>
<li>results: 这个论文的实验结果表明，使用不同的简单恢复算法可以影响图像恢复的质量。<details>
<summary>Abstract</summary>
Dictionary learning can be used for image superresolution by learning a pair of coupled dictionaries of image patches from high-resolution and low-resolution image pairs such that the corresponding pairs share the same sparse vector when represented by the coupled dictionaries. These dictionaries then can be used to to reconstruct the corresponding high-resolution patches from low-resolution input images based on sparse recovery. The idea is to recover the shared sparse vector using the low-resolution dictionary and then multiply it by the high-resolution dictionary to recover the corresponding high-resolution image patch. In this work, we study the effect of the sparse recovery algorithm that we use on the quality of the reconstructed images. We offer empirical experiments to search for the best sparse recovery algorithm that can be used for this purpose.
</details>
<details>
<summary>摘要</summary>
<<SYS>>对于图像超分解，词典学习可以用来学习一对对应的高分辨率和低分辨率图像对的词典，使得这对对应的词典元素共享同一个简约 вектор。这些词典然后可以用来从低分辨率输入图像中重建对应的高分辨率图像片段，基于简约恢复。我们的想法是通过低分辨率词典来恢复共享的简约 вектор，然后将其乘以高分辨率词典来恢复对应的高分辨率图像片段。在这个工作中，我们研究了使用不同的简约恢复算法对图像质量的影响，并通过实验搜索最佳的简约恢复算法。Note: Simplified Chinese is also known as "Mandarin" Chinese, and it is the official language of China. It is written using the same characters as Traditional Chinese, but with simpler stroke orders and fewer characters.
</details></li>
</ul>
<hr>
<h2 id="EDI-ESKF-based-Disjoint-Initialization-for-Visual-Inertial-SLAM-Systems"><a href="#EDI-ESKF-based-Disjoint-Initialization-for-Visual-Inertial-SLAM-Systems" class="headerlink" title="EDI: ESKF-based Disjoint Initialization for Visual-Inertial SLAM Systems"></a>EDI: ESKF-based Disjoint Initialization for Visual-Inertial SLAM Systems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02670">http://arxiv.org/abs/2308.02670</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weihan Wang, Jiani Li, Yuhang Ming, Philippos Mordohai</li>
<li>for: 这篇论文的目的是提出一种快速、精准、可靠的视像运动初始化方法（EDI），以解决现有的视像运动初始化方法存在的问题。</li>
<li>methods: 这篇论文使用的方法包括误差状态库检测器（ESKF）来估计陀螺偏差和纯单眼SLAM中的旋转估计的误差，以及一个关键几何方法来估计初速度、尺度、重力和加速度偏差。</li>
<li>results: 根据评估数据，这篇论文的EDI方法在几个挑战性环境中（包括人工散射误差）可以在几秒钟内实现精准的视像运动初始化，并且超过了其他状态艺术的视像运动初始化方法。<details>
<summary>Abstract</summary>
Visual-inertial initialization can be classified into joint and disjoint approaches. Joint approaches tackle both the visual and the inertial parameters together by aligning observations from feature-bearing points based on IMU integration then use a closed-form solution with visual and acceleration observations to find initial velocity and gravity. In contrast, disjoint approaches independently solve the Structure from Motion (SFM) problem and determine inertial parameters from up-to-scale camera poses obtained from pure monocular SLAM. However, previous disjoint methods have limitations, like assuming negligible acceleration bias impact or accurate rotation estimation by pure monocular SLAM. To address these issues, we propose EDI, a novel approach for fast, accurate, and robust visual-inertial initialization. Our method incorporates an Error-state Kalman Filter (ESKF) to estimate gyroscope bias and correct rotation estimates from monocular SLAM, overcoming dependence on pure monocular SLAM for rotation estimation. To estimate the scale factor without prior information, we offer a closed-form solution for initial velocity, scale, gravity, and acceleration bias estimation. To address gravity and acceleration bias coupling, we introduce weights in the linear least-squares equations, ensuring acceleration bias observability and handling outliers. Extensive evaluation on the EuRoC dataset shows that our method achieves an average scale error of 5.8% in less than 3 seconds, outperforming other state-of-the-art disjoint visual-inertial initialization approaches, even in challenging environments and with artificial noise corruption.
</details>
<details>
<summary>摘要</summary>
“视听初始化可以分为联合和分割两种方法。联合方法同时处理视听参数，通过IMU综合 integrating 视觉特征点的观察结果，并使用关闭式解决方案来计算初速度和重力。相比之下，分割方法独立解决 Структура从 Move（SFM）问题，并从纯粹的一频单摄像头SLAM中获取各种相机位置。然而，以往的分割方法有一些限制，如假设加速度偏移的影响为零或纯粹的一频单摄像头SLAM中的旋转估计准确。为解决这些问题，我们提出了一种新的方法——EDI，它是一种快速、准确和Robust的视听初始化方法。我们的方法通过Error-state Kalman Filter（ESKF）来估算陀螺偏移和纯粹的一频单摄像头SLAM中的旋转估计，从而超越了依赖于纯粹的一频单摄像头SLAM中的旋转估计。为估计初速度、比例因子、重力和加速度偏移的问题，我们提供了一个关闭式解决方案。为处理重力和加速度偏移之间的相互作用，我们引入了权重，确保加速度偏移的观察可见性和承受扰动。我们的方法在EuRoC数据集上进行了广泛的评估，结果显示，我们的方法在 less than 3 秒内，覆盖率Error 5.8%，超越了其他当前最佳的分割视听初始化方法，即使在复杂的环境下和人工噪声损害。”
</details></li>
</ul>
<hr>
<h2 id="ReCLIP-Refine-Contrastive-Language-Image-Pre-Training-with-Source-Free-Domain-Adaptation"><a href="#ReCLIP-Refine-Contrastive-Language-Image-Pre-Training-with-Source-Free-Domain-Adaptation" class="headerlink" title="ReCLIP: Refine Contrastive Language Image Pre-Training with Source Free Domain Adaptation"></a>ReCLIP: Refine Contrastive Language Image Pre-Training with Source Free Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03793">http://arxiv.org/abs/2308.03793</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xuefeng Hu, Ke Zhang, Lu Xia, Albert Chen, Jiajia Luo, Yuyin Sun, Ken Wang, Nan Qiao, Xiao Zeng, Min Sun, Cheng-Hao Kuo, Ram Nevatia</li>
<li>for: 提高 CLIP 模型在下游领域中的表现，即使没有源数据或目标标签数据。</li>
<li>methods: 提出了一种源自无关领域适应方法，通过学习投影空间来减轻视文混合的嵌入推断，然后通过跨Modal自我训练来更新视觉编码器和文本编码器，并且不断更新标签以减少领域差异和混合错误。</li>
<li>results: 实验结果显示，ReCLIP 可以将 CLIP 模型的平均错误率从 30.17% 降低至 25.06% 在 22 个图像分类benchmark上。<details>
<summary>Abstract</summary>
Large-scale Pre-Training Vision-Language Model such as CLIP has demonstrated outstanding performance in zero-shot classification, e.g. achieving 76.3% top-1 accuracy on ImageNet without seeing any example, which leads to potential benefits to many tasks that have no labeled data. However, while applying CLIP to a downstream target domain, the presence of visual and text domain gaps and cross-modality misalignment can greatly impact the model performance. To address such challenges, we propose ReCLIP, the first source-free domain adaptation method for vision-language models, which does not require any source data or target labeled data. ReCLIP first learns a projection space to mitigate the misaligned visual-text embeddings and learns pseudo labels, and then deploys cross-modality self-training with the pseudo labels, to update visual and text encoders, refine labels and reduce domain gaps and misalignments iteratively. With extensive experiments, we demonstrate ReCLIP reduces the average error rate of CLIP from 30.17% to 25.06% on 22 image classification benchmarks.
</details>
<details>
<summary>摘要</summary>
大规模预训练视语模型如CLIP已经表现出色的零例推断能力，例如在ImageNet上达到76.3%的顶部一准确率无需见过任何示例，这可能会带来许多无标示数据的任务中的优势。然而，在应用CLIP到下游目标领域时，视语频域差和交叉Modal不一致可能会对模型表现产生很大的影响。为了解决这些挑战，我们提出了ReCLIP，首个无源频段适应方法，不需要源数据或目标标记数据。ReCLIP首先学习一个抑制覆盖视语嵌入的投影空间，然后通过交叉模式自动训练，使视和文批处程序更新、精细标签和减少频段差异和不一致。经过广泛的实验，我们示出ReCLIP可以将CLIP的平均错误率从30.17%降低到25.06%。
</details></li>
</ul>
<hr>
<h2 id="Convolutions-Die-Hard-Open-Vocabulary-Segmentation-with-Single-Frozen-Convolutional-CLIP"><a href="#Convolutions-Die-Hard-Open-Vocabulary-Segmentation-with-Single-Frozen-Convolutional-CLIP" class="headerlink" title="Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen Convolutional CLIP"></a>Convolutions Die Hard: Open-Vocabulary Segmentation with Single Frozen Convolutional CLIP</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02487">http://arxiv.org/abs/2308.02487</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bytedance/fc-clip">https://github.com/bytedance/fc-clip</a></li>
<li>paper_authors: Qihang Yu, Ju He, Xueqing Deng, Xiaohui Shen, Liang-Chieh Chen</li>
<li>for: 本研究的目的是提出一种单stage的多Modal模型，以解决开放词汇分割的挑战。</li>
<li>methods: 该模型使用了共享冻结Convolutional CLIP backbone，并利用图像和文本特征在共享embedding空间中进行桥接，从而 Addressing the challenge of open-vocabulary segmentation.</li>
<li>results: 研究显示，FC-CLIP在Zero-shot manner测试时，在ADE20K、Mapillary Vistas和Cityscapes等 datasets上达到了26.8 PQ、16.8 AP、34.1 mIoU、18.2 PQ、27.9 mIoU、44.0 PQ、26.8 AP、56.2 mIoU的最高表现，与之前的艺术品相比，提高了4.2 PQ、2.4 AP、4.2 mIoU、4.0 PQ、20.1 PQ的表现。同时，FC-CLIP的训练和测试时间相比之前的艺术品快7.5倍和6.6倍，使用参数数量相对减少5.9倍。<details>
<summary>Abstract</summary>
Open-vocabulary segmentation is a challenging task requiring segmenting and recognizing objects from an open set of categories. One way to address this challenge is to leverage multi-modal models, such as CLIP, to provide image and text features in a shared embedding space, which bridges the gap between closed-vocabulary and open-vocabulary recognition. Hence, existing methods often adopt a two-stage framework to tackle the problem, where the inputs first go through a mask generator and then through the CLIP model along with the predicted masks. This process involves extracting features from images multiple times, which can be ineffective and inefficient. By contrast, we propose to build everything into a single-stage framework using a shared Frozen Convolutional CLIP backbone, which not only significantly simplifies the current two-stage pipeline, but also remarkably yields a better accuracy-cost trade-off. The proposed FC-CLIP, benefits from the following observations: the frozen CLIP backbone maintains the ability of open-vocabulary classification and can also serve as a strong mask generator, and the convolutional CLIP generalizes well to a larger input resolution than the one used during contrastive image-text pretraining. When training on COCO panoptic data only and testing in a zero-shot manner, FC-CLIP achieve 26.8 PQ, 16.8 AP, and 34.1 mIoU on ADE20K, 18.2 PQ, 27.9 mIoU on Mapillary Vistas, 44.0 PQ, 26.8 AP, 56.2 mIoU on Cityscapes, outperforming the prior art by +4.2 PQ, +2.4 AP, +4.2 mIoU on ADE20K, +4.0 PQ on Mapillary Vistas and +20.1 PQ on Cityscapes, respectively. Additionally, the training and testing time of FC-CLIP is 7.5x and 6.6x significantly faster than the same prior art, while using 5.9x fewer parameters. FC-CLIP also sets a new state-of-the-art performance across various open-vocabulary semantic segmentation datasets. Code at https://github.com/bytedance/fc-clip
</details>
<details>
<summary>摘要</summary>
开放词汇 segmentation 是一项具有挑战性的任务，需要将图像和文本分割和识别到开放集的类别中。一种 Addressing this challenge is to leverage multi-modal models, such as CLIP, to provide image and text features in a shared embedding space, which bridges the gap between closed-vocabulary and open-vocabulary recognition. Existing methods often adopt a two-stage framework to tackle the problem, where the inputs first go through a mask generator and then through the CLIP model along with the predicted masks. This process involves extracting features from images multiple times, which can be ineffective and inefficient.By contrast, we propose a single-stage framework using a shared Frozen Convolutional CLIP backbone, which not only significantly simplifies the current two-stage pipeline, but also remarkably yields a better accuracy-cost trade-off. The proposed FC-CLIP benefits from the following observations: the frozen CLIP backbone maintains the ability of open-vocabulary classification and can also serve as a strong mask generator, and the convolutional CLIP generalizes well to a larger input resolution than the one used during contrastive image-text pretraining.When training on COCO panoptic data only and testing in a zero-shot manner, FC-CLIP achieves 26.8 PQ, 16.8 AP, and 34.1 mIoU on ADE20K, 18.2 PQ, 27.9 mIoU on Mapillary Vistas, 44.0 PQ, 26.8 AP, 56.2 mIoU on Cityscapes, outperforming the prior art by +4.2 PQ, +2.4 AP, +4.2 mIoU on ADE20K, +4.0 PQ on Mapillary Vistas, and +20.1 PQ on Cityscapes, respectively. Additionally, the training and testing time of FC-CLIP is 7.5x and 6.6x significantly faster than the same prior art, while using 5.9x fewer parameters. FC-CLIP also sets a new state-of-the-art performance across various open-vocabulary semantic segmentation datasets.Code: <https://github.com/bytedance/fc-clip>
</details></li>
</ul>
<hr>
<h2 id="Uncertainty-Estimation-and-Propagation-in-Accelerated-MRI-Reconstruction"><a href="#Uncertainty-Estimation-and-Propagation-in-Accelerated-MRI-Reconstruction" class="headerlink" title="Uncertainty Estimation and Propagation in Accelerated MRI Reconstruction"></a>Uncertainty Estimation and Propagation in Accelerated MRI Reconstruction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02631">http://arxiv.org/abs/2308.02631</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/paulkogni/mr-recon-uq">https://github.com/paulkogni/mr-recon-uq</a></li>
<li>paper_authors: Paul Fischer, Thomas Küstner, Christian F. Baumgartner</li>
<li>for: 这个论文是关于MR成像技术基于深度学习的重建方法，尤其在高速下进行重建时得到了无 precedent的重建质量。</li>
<li>methods: 该论文提出了一种基于conditional hierarchical variational autoencoders的概率重建技术（PHiRec），以提高MR成像重建的质量和不确定性评估。</li>
<li>results: 研究人员发现，PHiRec可以生成高质量的重建结果，同时也可以更好地评估MR成像重建过程中的不确定性，并且可以传播这些不确定性到下游分割任务中。<details>
<summary>Abstract</summary>
MRI reconstruction techniques based on deep learning have led to unprecedented reconstruction quality especially in highly accelerated settings. However, deep learning techniques are also known to fail unexpectedly and hallucinate structures. This is particularly problematic if reconstructions are directly used for downstream tasks such as real-time treatment guidance or automated extraction of clinical paramters (e.g. via segmentation). Well-calibrated uncertainty quantification will be a key ingredient for safe use of this technology in clinical practice. In this paper we propose a novel probabilistic reconstruction technique (PHiRec) building on the idea of conditional hierarchical variational autoencoders. We demonstrate that our proposed method produces high-quality reconstructions as well as uncertainty quantification that is substantially better calibrated than several strong baselines. We furthermore demonstrate how uncertainties arising in the MR econstruction can be propagated to a downstream segmentation task, and show that PHiRec also allows well-calibrated estimation of segmentation uncertainties that originated in the MR reconstruction process.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/05/cs.CV_2023_08_05/" data-id="clp89docm00hli788anwm13y6" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_08_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/05/cs.AI_2023_08_05/" class="article-date">
  <time datetime="2023-08-05T12:00:00.000Z" itemprop="datePublished">2023-08-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/05/cs.AI_2023_08_05/">cs.AI - 2023-08-05</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Edge-of-stability-echo-state-networks"><a href="#Edge-of-stability-echo-state-networks" class="headerlink" title="Edge of stability echo state networks"></a>Edge of stability echo state networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02902">http://arxiv.org/abs/2308.02902</a></li>
<li>repo_url: None</li>
<li>paper_authors: Andrea Ceni, Claudio Gallicchio</li>
<li>for: 这个论文提出了一种新的储量计算（Reservoir Computing，RC）架构，叫做Edge of Stability Echo State Network（ES$^2$N）。</li>
<li>methods: 这个模型基于定义储量层为非线性储量（如标准ESN中的储量）和一个线性储量，实现了正交变换。作者提供了详细的数学分析，证明了引入模型的整个征 specie的Jacobian可以在一个可控的圆形范围内，并利用这个特性以示出ES$^2$N的前向动力学在设计的边缘混乱 régime内进行演化。</li>
<li>results: 实验分析表明，引入的储量模型可以达到理论最大的短期记忆容量。同时，相比标准ESN，ES$^2$N具有更好的记忆和非线性质量的融合，以及在推理非线性模型方面的显著改善。<details>
<summary>Abstract</summary>
In this paper, we propose a new Reservoir Computing (RC) architecture, called the Edge of Stability Echo State Network (ES$^2$N). The introduced ES$^2$N model is based on defining the reservoir layer as a convex combination of a nonlinear reservoir (as in the standard ESN), and a linear reservoir that implements an orthogonal transformation. We provide a thorough mathematical analysis of the introduced model, proving that the whole eigenspectrum of the Jacobian of the ES2N map can be contained in an annular neighbourhood of a complex circle of controllable radius, and exploit this property to demonstrate that the ES$^2$N's forward dynamics evolves close to the edge-of-chaos regime by design. Remarkably, our experimental analysis shows that the newly introduced reservoir model is able to reach the theoretical maximum short-term memory capacity. At the same time, in comparison to standard ESN, ES$^2$N is shown to offer a favorable trade-off between memory and nonlinearity, as well as a significant improvement of performance in autoregressive nonlinear modeling.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们提出了一新的储存 computing（RC）架构，称为Edge of Stability Echo State Network（ES$^2$N）。我们引入的ES$^2$N模型基于定义储存层为非线性储存（如标准ESN）和线性储存实现正交变换的权重组合。我们提供了ES$^2$N模型的完整数学分析，证明整个储存映射的雅可比矩阵的所有特征值可以包含在一个可控制的圆形范围内，并利用这个性质来证明ES$^2$N的前向动力学在设计上靠近边缘混乱 режи。在实验中，我们发现新引入的储存模型可以达到理论最大短期记忆容量。同时，相比标准ESN，ES$^2$N具有更好的记忆和非线性质量之间的交换，以及在推理非线性模型方面的显著改善。
</details></li>
</ul>
<hr>
<h2 id="Textual-Data-Mining-for-Financial-Fraud-Detection-A-Deep-Learning-Approach"><a href="#Textual-Data-Mining-for-Financial-Fraud-Detection-A-Deep-Learning-Approach" class="headerlink" title="Textual Data Mining for Financial Fraud Detection: A Deep Learning Approach"></a>Textual Data Mining for Financial Fraud Detection: A Deep Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03800">http://arxiv.org/abs/2308.03800</a></li>
<li>repo_url: None</li>
<li>paper_authors: Qiuru Li</li>
<li>for: 这个研究用了深度学习方法来进行自然语言处理（NLP）Binary分类任务，检测金融诈骗文本。</li>
<li>methods: 研究者首先从香港证券交易所（HKEX）新闻中搜索了违规公司的 regulatory announcements 和 enforcement bulletins，并将其 MD&amp;A 报告 sentences 标签和时间排序。研究者使用了多种神经网络模型，包括多层感知器（Multilayer Perceptrons）with Embedding layers、vanilla Recurrent Neural Network（RNN）、Long-Short Term Memory（LSTM）和 Gated Recurrent Unit（GRU）进行文本分类任务。</li>
<li>results: 研究者的结果表明，使用这些多种神经网络模型可以准确地检测金融诈骗。这些结果对金融诈骗检测有重要的意义，并为业界实践人员、 regulators 和研究人员提供了有价值的意见，帮助他们开发更加有力的诈骗检测方法。<details>
<summary>Abstract</summary>
In this report, I present a deep learning approach to conduct a natural language processing (hereafter NLP) binary classification task for analyzing financial-fraud texts. First, I searched for regulatory announcements and enforcement bulletins from HKEX news to define fraudulent companies and to extract their MD&A reports before I organized the sentences from the reports with labels and reporting time. My methodology involved different kinds of neural network models, including Multilayer Perceptrons with Embedding layers, vanilla Recurrent Neural Network (RNN), Long-Short Term Memory (LSTM), and Gated Recurrent Unit (GRU) for the text classification task. By utilizing this diverse set of models, I aim to perform a comprehensive comparison of their accuracy in detecting financial fraud. My results bring significant implications for financial fraud detection as this work contributes to the growing body of research at the intersection of deep learning, NLP, and finance, providing valuable insights for industry practitioners, regulators, and researchers in the pursuit of more robust and effective fraud detection methodologies.
</details>
<details>
<summary>摘要</summary>
在这份报告中，我使用深度学习方法进行自然语言处理（以下简称NLP）的二分类任务，以分析金融诈骗文本。首先，我从香港证券交易所新闻中搜索了规范公告和执行公告，以定义诈骗公司并从其财务报告中提取MD&A报告。然后，我将报告中的句子按照标签和报告时间进行排序。我的方法包括多层感知器（Multilayer Perceptrons）、普通的循环神经网络（vanilla RNN）、长短期记忆神经网络（LSTM）和闭合循环神经网络（GRU）等多种神经网络模型，用于文本分类任务。通过使用这些多种模型，我想要进行全面的比较，以确定这些模型在检测金融诈骗方面的准确率。我的结果对金融诈骗检测有着重要的意义，这项工作将贡献到深度学习、NLP和金融之间的交叉领域的研究中，为业内专业人士、监管机构和研究人员提供价值的发现。
</details></li>
</ul>
<hr>
<h2 id="Meta-learning-in-healthcare-A-survey"><a href="#Meta-learning-in-healthcare-A-survey" class="headerlink" title="Meta-learning in healthcare: A survey"></a>Meta-learning in healthcare: A survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02877">http://arxiv.org/abs/2308.02877</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alireza Rafiei, Ronald Moore, Sina Jahromi, Farshid Hajati, Rishikesan Kamaleswaran<br>for:这篇论文旨在探讨基于知识和体验的meta-learning在医疗领域的应用，以提供对健康领域中critical挑战的解决方案。methods:这篇论文使用了多种meta-learning方法，包括多&#x2F;单任务学习和多&#x2F;几少射学习，并将这些方法应用到医疗领域中。results:这篇论文总结了过去几年在医疗领域中的meta-learning研究，包括各种应用和挑战，以及未来的挑战和展望。<details>
<summary>Abstract</summary>
As a subset of machine learning, meta-learning, or learning to learn, aims at improving the model's capabilities by employing prior knowledge and experience. A meta-learning paradigm can appropriately tackle the conventional challenges of traditional learning approaches, such as insufficient number of samples, domain shifts, and generalization. These unique characteristics position meta-learning as a suitable choice for developing influential solutions in various healthcare contexts, where the available data is often insufficient, and the data collection methodologies are different. This survey discusses meta-learning broad applications in the healthcare domain to provide insight into how and where it can address critical healthcare challenges. We first describe the theoretical foundations and pivotal methods of meta-learning. We then divide the employed meta-learning approaches in the healthcare domain into two main categories of multi/single-task learning and many/few-shot learning and survey the studies. Finally, we highlight the current challenges in meta-learning research, discuss the potential solutions and provide future perspectives on meta-learning in healthcare.
</details>
<details>
<summary>摘要</summary>
为了提高模型的能力，机器学习的一个子集——元学习（learning to learn），利用先前的知识和经验来提高模型的性能。元学习的思想可以有效地解决传统学习方法面临的挑战，如数据缺乏、频率不均等。这些特点使得元学习成为在医疗领域开发有力的解决方案的适用场景。本文首先介绍元学习的理论基础和关键方法，然后将医疗领域中emploied元学习方法分为多/单任务学习和多/少射学习两个主要类别，并survey相关研究。最后，我们提出了当前元学习研究中的挑战，并讨论了 potential解决方案，以及未来元学习在医疗领域的前景。
</details></li>
</ul>
<hr>
<h2 id="Semi-supervised-Learning-for-Segmentation-of-Bleeding-Regions-in-Video-Capsule-Endoscopy"><a href="#Semi-supervised-Learning-for-Segmentation-of-Bleeding-Regions-in-Video-Capsule-Endoscopy" class="headerlink" title="Semi-supervised Learning for Segmentation of Bleeding Regions in Video Capsule Endoscopy"></a>Semi-supervised Learning for Segmentation of Bleeding Regions in Video Capsule Endoscopy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02869">http://arxiv.org/abs/2308.02869</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hechen Li, Yanan Wu, Long Bai, An Wang, Tong Chen, Hongliang Ren</li>
<li>for: 用于诊断不同类型的肠胃内部疾病，包括不明确出血。</li>
<li>methods: 采用 semi-supervised learning 方法，使用 <code>Mean Teacher</code> 方法构建学生 U-Net 模型和老师模型，并在训练过程中交互更新参数。</li>
<li>results: 实验结果表明，使用 SSL 方法可以减少模型训练所需的注释量，无需妥协准确性。<details>
<summary>Abstract</summary>
In the realm of modern diagnostic technology, video capsule endoscopy (VCE) is a standout for its high efficacy and non-invasive nature in diagnosing various gastrointestinal (GI) conditions, including obscure bleeding. Importantly, for the successful diagnosis and treatment of these conditions, accurate recognition of bleeding regions in VCE images is crucial. While deep learning-based methods have emerged as powerful tools for the automated analysis of VCE images, they often demand large training datasets with comprehensive annotations. Acquiring these labeled datasets tends to be time-consuming, costly, and requires significant domain expertise. To mitigate this issue, we have embraced a semi-supervised learning (SSL) approach for the bleeding regions segmentation within VCE. By adopting the `Mean Teacher' method, we construct a student U-Net equipped with an scSE attention block, alongside a teacher model of the same architecture. These models' parameters are alternately updated throughout the training process. We use the Kvasir-Capsule dataset for our experiments, which encompasses various GI bleeding conditions. Notably, we develop the segmentation annotations for this dataset ourselves. The findings from our experiments endorse the efficacy of the SSL-based segmentation strategy, demonstrating its capacity to reduce reliance on large volumes of annotations for model training, without compromising on the accuracy of identification.
</details>
<details>
<summary>摘要</summary>
现代诊断技术中，视频幂 capsule endoscopy (VCE) 是一种非侵入性和高效的诊断多种消化道（GI）疾病的技术，包括不明确出血。在成功诊断和治疗这些疾病的过程中，准确地识别出血液区域在 VCE 图像中是关键。深度学习基本方法已经在 VCE 图像的自动分析中展示出了强大的能力，但它们通常需要大量的训练数据集，并且需要具有很大的域专业知识来获取这些标注数据集。为了解决这个问题，我们采用了一种半监督学习（SSL）方法来进行出血区域的分割。我们采用的是“Mean Teacher”方法，通过将一个学生 U-Net 和一个教师模型相互更新参数，以实现学习。我们使用 Kvasir-Capsule 数据集进行实验，该数据集包括多种 GI 出血病变。它们的分割标注我们自己制作了。实验结果证明了 SSL 基于的分割策略的效果，表明它可以降低对大量标注的依赖，不会影响识别的精度。
</details></li>
</ul>
<hr>
<h2 id="Replace-Scoring-with-Arrangement-A-Contextual-Set-to-Arrangement-Framework-for-Learning-to-Rank"><a href="#Replace-Scoring-with-Arrangement-A-Contextual-Set-to-Arrangement-Framework-for-Learning-to-Rank" class="headerlink" title="Replace Scoring with Arrangement: A Contextual Set-to-Arrangement Framework for Learning-to-Rank"></a>Replace Scoring with Arrangement: A Contextual Set-to-Arrangement Framework for Learning-to-Rank</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02860">http://arxiv.org/abs/2308.02860</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Jinjiarui/STARank">https://github.com/Jinjiarui/STARank</a></li>
<li>paper_authors: Jiarui Jin, Xianyu Chen, Weinan Zhang, Mengyue Yang, Yang Wang, Yali Du, Yong Yu, Jun Wang</li>
<li>for: 这个研究目的是为了提出一个能够将候选项目集转换为排序结果的新框架，即Set-To-Arrangement Ranking（STARank）。</li>
<li>methods: STARank使用了Plackett-Luce模组来安排候选项目，并且使用了内部一致性性来 derivate一个 computationally efficient list-wise loss。</li>
<li>results: 实验结果显示，STARank在2个学习排名 benchmark dataset和3个top-N实际推荐dataset上表现出色，较前方的9个方法更好。此外，STARank还能够在对候选项目之间的上下文依赖性下提供更好的性能。<details>
<summary>Abstract</summary>
Learning-to-rank is a core technique in the top-N recommendation task, where an ideal ranker would be a mapping from an item set to an arrangement (a.k.a. permutation). Most existing solutions fall in the paradigm of probabilistic ranking principle (PRP), i.e., first score each item in the candidate set and then perform a sort operation to generate the top ranking list. However, these approaches neglect the contextual dependence among candidate items during individual scoring, and the sort operation is non-differentiable. To bypass the above issues, we propose Set-To-Arrangement Ranking (STARank), a new framework directly generates the permutations of the candidate items without the need for individually scoring and sort operations; and is end-to-end differentiable. As a result, STARank can operate when only the ground-truth permutations are accessible without requiring access to the ground-truth relevance scores for items. For this purpose, STARank first reads the candidate items in the context of the user browsing history, whose representations are fed into a Plackett-Luce module to arrange the given items into a list. To effectively utilize the given ground-truth permutations for supervising STARank, we leverage the internal consistency property of Plackett-Luce models to derive a computationally efficient list-wise loss. Experimental comparisons against 9 the state-of-the-art methods on 2 learning-to-rank benchmark datasets and 3 top-N real-world recommendation datasets demonstrate the superiority of STARank in terms of conventional ranking metrics. Notice that these ranking metrics do not consider the effects of the contextual dependence among the items in the list, we design a new family of simulation-based ranking metrics, where existing metrics can be regarded as special cases. STARank can consistently achieve better performance in terms of PBM and UBM simulation-based metrics.
</details>
<details>
<summary>摘要</summary>
学习排名是推荐任务的核心技术，其理想rankerd是一个将元素集映射到排序（即排序）的函数。现有的方法大多采用概率排名原则（PRP），即先对候选集中的每个元素分配排名并then执行排序操作来生成top排名列表。然而，这些方法忽略了候选项之间的上下文依赖关系，并且排序操作是不可导的。为了缺省这些问题，我们提出了Set-To-Arrangement Ranking（STARank），一种新的框架，可以直接生成候选项的排序列表，而不需要对每个元素进行分配排名和排序操作。此外，STARank还是端到端可导的。因此，STARank可以在只有真实排名available的情况下运行，而不需要访问真实的相关性分数。为了使用给定的真实排名来监督STARank，我们利用了Plackett-Luce模型的内部一致性性来 derivate一种 computationally efficient的列表性损失。我们在2个学习排名 benchmark dataset和3个top-N实际推荐dataset上进行了对9种状态对方法的实验比较，结果表明STARank在传统排名度量上表现出色。请注意，这些排名度量不考虑候选项列表中的上下文依赖关系，我们设计了一新的基于simulation的排名度量家族，其中现有的度量可以看作特殊情况。STARank可以在PBM和UBM simulation-based度量上提供更好的性能。
</details></li>
</ul>
<hr>
<h2 id="feather-–-a-Python-SDK-to-share-and-deploy-models"><a href="#feather-–-a-Python-SDK-to-share-and-deploy-models" class="headerlink" title="feather – a Python SDK to share and deploy models"></a>feather – a Python SDK to share and deploy models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02838">http://arxiv.org/abs/2308.02838</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nihir Vedd, Paul Riga</li>
<li>for: 本研究旨在提供一个简单的工具，帮助模型开发者在20行代码以下构建可重用的用户界面。</li>
<li>methods: 本研究使用Python SDK，让开发者指定可交互的视觉组件（如文件上传组件）。服务器则提供了1) 访问和使用模型的视觉界面的URL; 2) 对模型进行自动评估的API端点。</li>
<li>results: 本研究提出了feather的动机和值 proposition，并提供了完整的技术和实现细节。例如，SDK可支持多步骤模型，并可以自动对储存数据集进行评估。但是请注意，feather是一个休眠项目，我们已经开源了代码用于研究purposes。<details>
<summary>Abstract</summary>
At its core, feather was a tool that allowed model developers to build shareable user interfaces for their models in under 20 lines of code. Using the Python SDK, developers specified visual components that users would interact with. (e.g. a FileUpload component to allow users to upload a file). Our service then provided 1) a URL that allowed others to access and use the model visually via a user interface; 2) an API endpoint to allow programmatic requests to a model. In this paper, we discuss feather's motivations and the value we intended to offer AI researchers and developers. For example, the SDK can support multi-step models and can be extended to run automatic evaluation against held out datasets. We additionally provide comprehensive technical and implementation details.   N.B. feather is presently a dormant project. We have open sourced our code for research purposes: https://github.com/feather-ai/
</details>
<details>
<summary>摘要</summary>
文本核心是一个工具，允许模型开发者在20行代码以下建立可共享用户界面 для他们的模型。使用Python SDK，开发者指定了用户会交互的视觉组件（例如文件上传组件）。我们的服务然后提供了以下两个功能：1）一个URL，允许他人通过用户界面访问和使用模型；2）一个API端点，允许程序请求模型的请求。在这篇论文中，我们讨论了feather的动机和我们对AI研究者和开发者的意图价值。例如，SDK可以支持多步骤模型，并可以扩展以自动对储存数据进行评估。我们还提供了完整的技术和实现细节。注意：feather目前是一个休眠项目，我们已经开源了我们的代码 для研究用途：https://github.com/feather-ai/。
</details></li>
</ul>
<hr>
<h2 id="Physics-Based-Task-Generation-through-Causal-Sequence-of-Physical-Interactions"><a href="#Physics-Based-Task-Generation-through-Causal-Sequence-of-Physical-Interactions" class="headerlink" title="Physics-Based Task Generation through Causal Sequence of Physical Interactions"></a>Physics-Based Task Generation through Causal Sequence of Physical Interactions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02835">http://arxiv.org/abs/2308.02835</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chathura Gamage, Vimukthini Pinto, Matthew Stephenson, Jochen Renz</li>
<li>for: 本研究的目的是提供一种系统的方法来生成基于物理学的任务，以便更好地评估人工智能系统在真实世界中的物理理解能力。</li>
<li>methods: 本研究使用了定义物理场景的 causal 序列方法，并提出了一种基于这些定义的物理环境生成任务的方法。</li>
<li>results: 研究人员使用了游戏 Angry Birds 来示例性评估生成的任务，并通过多种指标（包括物理稳定性、可用性和不可用性）评估了这些任务的质量。<details>
<summary>Abstract</summary>
Performing tasks in a physical environment is a crucial yet challenging problem for AI systems operating in the real world. Physics simulation-based tasks are often employed to facilitate research that addresses this challenge. In this paper, first, we present a systematic approach for defining a physical scenario using a causal sequence of physical interactions between objects. Then, we propose a methodology for generating tasks in a physics-simulating environment using these defined scenarios as inputs. Our approach enables a better understanding of the granular mechanics required for solving physics-based tasks, thereby facilitating accurate evaluation of AI systems' physical reasoning capabilities. We demonstrate our proposed task generation methodology using the physics-based puzzle game Angry Birds and evaluate the generated tasks using a range of metrics, including physical stability, solvability using intended physical interactions, and accidental solvability using unintended solutions. We believe that the tasks generated using our proposed methodology can facilitate a nuanced evaluation of physical reasoning agents, thus paving the way for the development of agents for more sophisticated real-world applications.
</details>
<details>
<summary>摘要</summary>
在物理环境中完成任务是人工智能系统在真实世界中的一个关键和挑战。基于物理模拟的任务经常用于解决这一问题。在这篇论文中，我们首先提出一种系统的方法来定义物理场景，使用物理相互作用的 causal 序列来描述物理交互。然后，我们提出一种使用这些定义的场景来生成在物理模拟环境中的任务的方法。我们的方法可以帮助更好地理解物理任务的细致机理，从而帮助评估人工智能系统在物理上的理解能力。我们使用Physics-based puzzle game Angry Birds进行示例，并使用一系列指标来评估生成的任务，包括物理稳定性、可以通过意图的物理交互解决、以及意外地解决使用非意图的解决方案。我们认为生成的任务可以帮助评估物理理解代理人的能力，因此为更复杂的真实世界应用开创道路。
</details></li>
</ul>
<hr>
<h2 id="Multi-Agent-Verification-and-Control-with-Probabilistic-Model-Checking"><a href="#Multi-Agent-Verification-and-Control-with-Probabilistic-Model-Checking" class="headerlink" title="Multi-Agent Verification and Control with Probabilistic Model Checking"></a>Multi-Agent Verification and Control with Probabilistic Model Checking</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02829">http://arxiv.org/abs/2308.02829</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Parker</li>
<li>for: 这篇论文是关于形式自动推理，它是用于软件或硬件系统的形式逻辑推理的技术。</li>
<li>methods: 这篇论文使用了多种方法，包括逻辑、自动机、图论、优化、数值方法和控制。</li>
<li>results: 这篇论文总结了一些在多代理情况下的推理进展，以及这些进展的应用。它还提出了在多代理情况下推理的挑战。<details>
<summary>Abstract</summary>
Probabilistic model checking is a technique for formal automated reasoning about software or hardware systems that operate in the context of uncertainty or stochasticity. It builds upon ideas and techniques from a diverse range of fields, from logic, automata and graph theory, to optimisation, numerical methods and control. In recent years, probabilistic model checking has also been extended to integrate ideas from game theory, notably using models such as stochastic games and solution concepts such as equilibria, to formally verify the interaction of multiple rational agents with distinct objectives. This provides a means to reason flexibly about agents acting in either an adversarial or a collaborative fashion, and opens up opportunities to tackle new problems within, for example, artificial intelligence, robotics and autonomous systems. In this paper, we summarise some of the advances in this area, and highlight applications for which they have already been used. We discuss how the strengths of probabilistic model checking apply, or have the potential to apply, to the multi-agent setting and outline some of the key challenges required to make further progress in this field.
</details>
<details>
<summary>摘要</summary>
probabistic model checking 是一种技术，用于正式自动推理软件或硬件系统在不确定性或随机性的情况下的行为。它借鉴了多种领域的想法和技巧，包括逻辑、自动机和图论，以及优化、数值方法和控制。在最近几年，probabistic model checking 还被扩展到与游戏理论相结合，使用模型如随机游戏和解迪rium such as equilibria，以正式验证多个有目的智能代理人之间的互动。这提供了一种可以灵活地关于代理人在对抗或合作的方式下行为的方式，并开阔了人工智能、 роботех和自动化系统等领域的应用可能性。在这篇文章中，我们将summarize一些在这个领域的进展，并高亮应用于哪些领域。我们讨论probabistic model checking 在多代理人设置下的优势，以及需要在这个领域进行进一步进展的关键挑战。
</details></li>
</ul>
<hr>
<h2 id="A-Symbolic-Character-Aware-Model-for-Solving-Geometry-Problems"><a href="#A-Symbolic-Character-Aware-Model-for-Solving-Geometry-Problems" class="headerlink" title="A Symbolic Character-Aware Model for Solving Geometry Problems"></a>A Symbolic Character-Aware Model for Solving Geometry Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02823">http://arxiv.org/abs/2308.02823</a></li>
<li>repo_url: None</li>
<li>paper_authors: Maizhen Ning, Qiu-Feng Wang, Kaizhu Huang, Xiaowei Huang</li>
<li>for: 解决几何问题，提高几何理解和计算能力</li>
<li>methods: 使用符号字符对象认知模型，结合文本和图像modal reasoning框架，并在图像Encoder中使用自动学习方法进行自我超vised学习</li>
<li>results: 在GeoQA和Geometry3K两个标准数据集上实现了新的州OF-the-art问题解决率和解决步骤的改进，具体来说是从60.0%提高到64.1%，并且在Geometry3K数据集上将问题平均解决步骤从6.9下降到6.0。<details>
<summary>Abstract</summary>
AI has made significant progress in solving math problems, but geometry problems remain challenging due to their reliance on both text and diagrams. In the text description, symbolic characters such as "$\triangle$ABC" often serve as a bridge to connect the corresponding diagram. However, by simply tokenizing symbolic characters into individual letters (e.g., 'A', 'B' and 'C'), existing works fail to study them explicitly and thus lose the semantic relationship with the diagram. In this paper, we develop a symbolic character-aware model to fully explore the role of these characters in both text and diagram understanding and optimize the model under a multi-modal reasoning framework. In the text encoder, we propose merging individual symbolic characters to form one semantic unit along with geometric information from the corresponding diagram. For the diagram encoder, we pre-train it under a multi-label classification framework with the symbolic characters as labels. In addition, we enhance the geometry diagram understanding ability via a self-supervised learning method under the masked image modeling auxiliary task. By integrating the proposed model into a general encoder-decoder pipeline for solving geometry problems, we demonstrate its superiority on two benchmark datasets, including GeoQA and Geometry3K, with extensive experiments. Specifically, on GeoQA, the question-solving accuracy is increased from 60.0\% to 64.1\%, achieving a new state-of-the-art accuracy; on Geometry3K, we reduce the question average solving steps from 6.9 down to 6.0 with marginally higher solving accuracy.
</details>
<details>
<summary>摘要</summary>
AI已经做出了重要的进步在解决数学问题上，但 geometry问题仍然是挑战的，因为它们需要同文本和图表之间建立连接。在文本描述中，符号Character such as "$\triangle$ABC"  часто作为连接图表和文本之间的桥梁。然而，现有的工作往往会将符号Character tokenized into individual letters（例如，'A', 'B' 和 'C'），从而失去了图表和文本之间的semantic关系。在这篇论文中，我们开发了一种符号Character-aware的模型，以全面探讨符号Character在文本和图表理解中的角色，并在多模态推理框架下优化模型。在文本Encoder中，我们提议将个别的符号Character合并成一个semantic单元，并与图表中的 геометри信息相结合。对于图表Encoder，我们在多Label分类框架下预训练它，使其能够学习符号Character的semantic信息。此外，我们通过自动学习方法在masked image modeling auxiliary task中增强图表理解能力。通过将我们的模型集成到一个通用的encoder-decoder架构中，我们在GeoQA和Geometry3K两个标准测试集上进行了广泛的实验，并证明了我们的模型在这些测试集上的超越性。具体来说，在GeoQA上，问题解决率从60.0%提高到64.1%，创造了新的state-of-the-art纪录;在Geometry3K上，我们将问题的平均解决步骤从6.9降低到6.0，并保持了marginally高的解决率。
</details></li>
</ul>
<hr>
<h2 id="The-changing-rule-of-human-bone-density-with-aging-based-on-a-novel-definition-and-mensuration-of-bone-density-with-computed-tomography"><a href="#The-changing-rule-of-human-bone-density-with-aging-based-on-a-novel-definition-and-mensuration-of-bone-density-with-computed-tomography" class="headerlink" title="The changing rule of human bone density with aging based on a novel definition and mensuration of bone density with computed tomography"></a>The changing rule of human bone density with aging based on a novel definition and mensuration of bone density with computed tomography</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02815">http://arxiv.org/abs/2308.02815</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/thu-cvlab/jmedsegv2">https://github.com/thu-cvlab/jmedsegv2</a></li>
<li>paper_authors: Linmi Tao, Ruiyang Liu, Yuanbiao Wang, Yuezhi Zhou, Li Huo, Guilan Hu, Xiangsong Zhang, Zuo-Xiang He</li>
<li>for: 这个研究旨在提供一种新的方法来评估年龄相关的骨密度变化，以便个性化评估骨健康风险。</li>
<li>methods: 研究人员提出了一种基于精心分割计算机断层成像（CT）图像的统计模型，以及一种基于CT值的骨密度评估方法。</li>
<li>results: 研究发现，骨密度随着年龄增长而下降，这种下降Rate在女性和男性之间有所差异，女性在39-80岁之间的年龄段下降的速度约为1.6倍于男性。这些结果证明了骨密度不同岁龄段的变化是线性的，从而为骨健康研究和临床诊断提供了新的视角。<details>
<summary>Abstract</summary>
Osteoporosis and fragility fractures have emerged as major public health concerns in an aging population. However, measuring age-related changes in bone density using dual-energy X-ray absorptiometry has limited personalized risk assessment due to susceptibility to interference from various factors. In this study, we propose an innovative statistical model of bone pixel distribution in fine-segmented computed tomography (CT) images, along with a novel approach to measuring bone density based on CT values of bone pixels. Our findings indicate that bone density exhibits a linear decline with age during adulthood between the ages of 39 and 80, with the rate of decline being approximately 1.6 times faster in women than in men. This contradicts the widely accepted notion that bone density starts declining in women at menopause and in men at around 50 years of age. The linearity of age-related changes provides further insights into the dynamics of the aging human body. Consequently, our findings suggest that the definition of osteoporosis by the World Health Organization should be revised to the standard deviation of age-based bone density. Furthermore, these results open up new avenues for research in bone health care and clinical investigation of osteoporosis.
</details>
<details>
<summary>摘要</summary>
骨质疾病和脆骨损伤已经成为老龄人口的主要公共健康问题。然而，使用双能X射线吸收率测量年龄相关的骨密度受到了各种因素的干扰， limiting personalized risk assessment. 在本研究中，我们提出了一个创新的骨像分布统计模型，以及一种基于Computed Tomography（CT）值的骨密度衡量方法。我们的发现显示，骨密度随着年龄的增长会 linear decline，女性与男性的增长率相对约1.6倍，这与通过Menopause和50岁的男性开始衰老骨骼的观念不符。这 Linearity of age-related changes provides further insights into the dynamics of the aging human body. Therefore, our findings suggest that the definition of osteoporosis by the World Health Organization should be revised to the standard deviation of age-based bone density. Furthermore, these results open up new avenues for research in bone health care and clinical investigation of osteoporosis.
</details></li>
</ul>
<hr>
<h2 id="Artificial-Intelligence-for-Molecular-Communication"><a href="#Artificial-Intelligence-for-Molecular-Communication" class="headerlink" title="Artificial Intelligence for Molecular Communication"></a>Artificial Intelligence for Molecular Communication</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02812">http://arxiv.org/abs/2308.02812</a></li>
<li>repo_url: None</li>
<li>paper_authors: Max Bartunik, Jens Kirchner, Oliver Keszocze</li>
<li>for: 这个研究是为了探讨分子通信技术，尤其是在医疗设备中使用这种技术实现数据传输。</li>
<li>methods: 这个研究使用了人工神经网络来解读受到干扰的讯号。</li>
<li>results: 这个研究发现，使用人工神经网络可以实现可靠地识别受到干扰的讯号。<details>
<summary>Abstract</summary>
Molecular communication is a novel approach for data transmission between miniaturized devices, especially in contexts where electrical signals are to be avoided. The communication is based on sending molecules (or other particles) at nano scale through channel instead sending electrons over a wire. Molecular communication devices have a large potential in medical applications as they offer an alternative to antenna-based transmission systems that may not be applicable due to size, temperature, or radiation constraints. The communication is achieved by transforming a digital signal into concentrations of molecules. These molecules are then detected at the other end of the communication channel and transformed back into a digital signal. Accurately modeling the transmission channel is often not possible which may be due to a lack of data or time-varying parameters of the channel (e. g., the movements of a person wearing a medical device). This makes demodulation of the signal very difficult. Many approaches for demodulation have been discussed with one particular approach having tremendous success: artificial neural networks. These networks imitate the decision process in the human brain and are capable of reliably classifying noisy input data. Training such a network relies on a large set of training data. As molecular communication as a technology is still in its early development phase, this data is not always readily available. We discuss neural network-based demodulation approaches relying on synthetic data based on theoretical channel models as well as works using actual measurements produced by a prototype test bed. In this work, we give a general overview over the field molecular communication, discuss the challenges in the demodulations process of transmitted signals, and present approaches to these challenges that are based on artificial neural networks.
</details>
<details>
<summary>摘要</summary>
молекуляр通信是一种新的方法 для数据传输 между微型设备，特别在电子信号被避免的情况下。通信基于发送分子（或其他粒子）在nanoscale通道上进行传输，而不是在电缆上发送电子信号。分子通信设备在医疗应用中有很大的潜力，因为它们可以提供一种antenna-based传输系统的替代方案，这些系统可能因为尺寸、温度或辐射限制而无法适用。通信是将数字信号转换成分子的浓度。这些分子然后在通信频道的另一端被探测，并转换回数字信号。因为模拟传输频道的模型很难，因此分子通信的许多挑战在于模拟频道的困难。许多适用于模拟频道的方法已经被讨论，其中一种方法具有惊人的成功：人工神经网络。这些网络模仿人脑中的决策过程，可以可靠地分类噪音输入数据。训练这种网络需要大量的训练数据。由于分子通信技术还处于早期发展阶段，这些数据不总是可用。我们讨论基于理论频道模型生成的 sintetic数据，以及使用实际测量生成的数据来训练人工神经网络。在这篇文章中，我们提供了分子通信领域的总体介绍，讨论了传输信号的各种挑战，以及基于人工神经网络的解决方案。
</details></li>
</ul>
<hr>
<h2 id="A-generative-model-for-surrogates-of-spatial-temporal-wildfire-nowcasting"><a href="#A-generative-model-for-surrogates-of-spatial-temporal-wildfire-nowcasting" class="headerlink" title="A generative model for surrogates of spatial-temporal wildfire nowcasting"></a>A generative model for surrogates of spatial-temporal wildfire nowcasting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02810">http://arxiv.org/abs/2308.02810</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sibo Cheng, Yike Guo, Rossella Arcucci</li>
<li>for:  This paper aims to provide a generative model for real-time wildfire nowcasting, using a three-dimensional Vector-Quantized Variational Autoencoders to generate spatial-temporal sequences of unseen wildfire burned areas in a given ecoregion.</li>
<li>methods:  The proposed method uses a generative model based on a three-dimensional Vector-Quantized Variational Autoencoders to generate coherent and structured fire scenarios, taking into account the impact from geophysical variables such as vegetation and slope.</li>
<li>results:  The generated data are used to train a surrogate model for predicting wildfire dissemination, which has been tested on both simulation data and the real Chimney fire event, showing promising results.<details>
<summary>Abstract</summary>
Recent increase in wildfires worldwide has led to the need for real-time fire nowcasting. Physics-driven models, such as cellular automata and computational fluid dynamics can provide high-fidelity fire spread simulations but they are computationally expensive and time-consuming. Much effort has been put into developing machine learning models for fire prediction. However, these models are often region-specific and require a substantial quantity of simulation data for training purpose. This results in a significant amount of computational effort for different ecoregions. In this work, a generative model is proposed using a three-dimensional Vector-Quantized Variational Autoencoders to generate spatial-temporal sequences of unseen wildfire burned areas in a given ecoregion. The model is tested in the ecoregion of a recent massive wildfire event in California, known as the Chimney fire. Numerical results show that the model succeed in generating coherent and structured fire scenarios, taking into account the impact from geophysical variables, such as vegetation and slope. Generated data are also used to train a surrogate model for predicting wildfire dissemination, which has been tested on both simulation data and the real Chimney fire event.
</details>
<details>
<summary>摘要</summary>
全球各地的野火增加，带来了实时火灾预测的需求。物理驱动的模型，如细胞自动机和计算流体力学，可以提供高精度的火灾传播模拟，但是它们 computationally expensive 和 time-consuming。大量的努力已经投入到了机器学习模型的开发中，以预测野火。然而，这些模型通常是地域特定的，需要大量的 simulate 数据来训练目的。这导致了不同的生态区域需要巨量的计算力。在这篇文章中，一种基于三维 вектор量化自适应器的生成模型被提议，用于生成未经见过的野火烧毁区域的三维空间时间序列。模型在加利福尼亚州的一个latest massive wildfire事件中进行了测试，称为Chimney fire。数据测试结果表明，模型成功地生成了具有相互关系的和结构的野火场景，考虑了地理物理变量，如 vegetation 和 slope。生成的数据还用于训练一个用于预测野火传播的代理模型，该模型在实际Chimney fire事件上进行了测试，以及在 simulate 数据上进行了测试。
</details></li>
</ul>
<hr>
<h2 id="MiAMix-Enhancing-Image-Classification-through-a-Multi-stage-Augmented-Mixed-Sample-Data-Augmentation-Method"><a href="#MiAMix-Enhancing-Image-Classification-through-a-Multi-stage-Augmented-Mixed-Sample-Data-Augmentation-Method" class="headerlink" title="MiAMix: Enhancing Image Classification through a Multi-stage Augmented Mixed Sample Data Augmentation Method"></a>MiAMix: Enhancing Image Classification through a Multi-stage Augmented Mixed Sample Data Augmentation Method</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02804">http://arxiv.org/abs/2308.02804</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wen Liang, Youzhi Liang, Jianguo Jia<br>for: 这篇论文的目的是提出一种名为 MiAMix 的多阶段混合调整方法，以提高深度学习模型的性能和泛化能力。methods: 这篇论文使用了多种多标的混合方法，包括 Image Augmentation 和 Mixup 架构，并且随机选择混合几何调整方法以提高混合效果。results: 根据四个图像标准benchmark的评估结果，MiAMix 可以提高模型的性能，并且不需要额外的计算负载。相比之下，与现有的混合样本数据增强方法进行比较，MiAMix 表现更好。<details>
<summary>Abstract</summary>
Despite substantial progress in the field of deep learning, overfitting persists as a critical challenge, and data augmentation has emerged as a particularly promising approach due to its capacity to enhance model generalization in various computer vision tasks. While various strategies have been proposed, Mixed Sample Data Augmentation (MSDA) has shown great potential for enhancing model performance and generalization. We introduce a novel mixup method called MiAMix, which stands for Multi-stage Augmented Mixup. MiAMix integrates image augmentation into the mixup framework, utilizes multiple diversified mixing methods concurrently, and improves the mixing method by randomly selecting mixing mask augmentation methods. Recent methods utilize saliency information and the MiAMix is designed for computational efficiency as well, reducing additional overhead and offering easy integration into existing training pipelines. We comprehensively evaluate MiaMix using four image benchmarks and pitting it against current state-of-the-art mixed sample data augmentation techniques to demonstrate that MIAMix improves performance without heavy computational overhead.
</details>
<details>
<summary>摘要</summary>
尽管深度学习领域已取得了显著进步，但过拟合仍然是一个重要挑战，而数据扩充因其能够提高模型通用性而成为一个非常有前途的方法。虽然有很多策略被提出，但混合样本数据扩充（MSDA）表现出了很大的潜力，可以提高模型性能和通用性。我们介绍了一种新的混合方法，称为 Multi-stage Augmented Mixup（MiAMix），它将图像扩充integrated into mixup框架，同时使用多种多样化的混合方法，并通过随机选择混合maske augmentation方法来提高混合方法。现有的方法使用了注意力信息，而MiAMix也是为计算效率而设计，减少了额外的负担和提供了易于集成到现有训练管道的便利性。我们对MiaMix进行了四个图像标准曲线的完整评估，并与当前状态的混合样本数据扩充技术进行比较，以示MiAMix可以提高性能而不带重量级计算过程。
</details></li>
</ul>
<hr>
<h2 id="Crowdsourcing-Fraud-Detection-over-Heterogeneous-Temporal-MMMA-Graph"><a href="#Crowdsourcing-Fraud-Detection-over-Heterogeneous-Temporal-MMMA-Graph" class="headerlink" title="Crowdsourcing Fraud Detection over Heterogeneous Temporal MMMA Graph"></a>Crowdsourcing Fraud Detection over Heterogeneous Temporal MMMA Graph</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02793">http://arxiv.org/abs/2308.02793</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zequan Xu, Qihang Sun, Shaofeng Hu, Jieming Shi, Hui Li</li>
<li>for: 本研究旨在探讨使用多用途消息应用程序（MMMA）的Click farm业务带来的cybercriminal们如何实施拥堵财务损失的 Crowdsourcing fraud。</li>
<li>methods: 本研究提出了一种新的对比多视角学习方法（CMT），用于在非常不同的时间图（HTG）上探测 Crowdsourcing fraud。CMT可以 capture HTG的不同性和动态性，并生成高质量的表示，以便在自动学习的方式下进行批量检测。</li>
<li>results: 在一个industry-size HTG上应用CMT后，可以具有显著的性能提升，与其他方法相比。此外，CMT还在一个大规模的公共金融HTG上进行了实验，并取得了显著的结果，表明CMT可以应用于其他图像异常检测任务中。<details>
<summary>Abstract</summary>
The rise of the click farm business using Multi-purpose Messaging Mobile Apps (MMMAs) tempts cybercriminals to perpetrate crowdsourcing frauds that cause financial losses to click farm workers. In this paper, we propose a novel contrastive multi-view learning method named CMT for crowdsourcing fraud detection over the heterogeneous temporal graph (HTG) of MMMA. CMT captures both heterogeneity and dynamics of HTG and generates high-quality representations for crowdsourcing fraud detection in a self-supervised manner. We deploy CMT to detect crowdsourcing frauds on an industry-size HTG of a representative MMMA WeChat and it significantly outperforms other methods. CMT also shows promising results for fraud detection on a large-scale public financial HTG, indicating that it can be applied in other graph anomaly detection tasks.
</details>
<details>
<summary>摘要</summary>
随着多功能通信手机应用程序（MMMA）的兴起， click farm业务的营运者被黑客利用以进行卫星投票诈骗， causing financial losses to click farm workers. 在这篇论文中，我们提议一种新的对比多视图学习方法（CMT），用于在异质时间图（HTG）上探测卫星投票诈骗。 CMT 能够 Capture HTG 中的异质和动态特征，并生成高质量的 Representation 以自主supervised 方式探测卫星投票诈骗。 我们在一个industry-size HTG 上部署 CMT，并显著超越其他方法。 CMT 还在一个大规模的公共金融 HTG 上显示出了扫描投票诈骗的扩展性， indicating that it can be applied to other graph anomaly detection tasks.
</details></li>
</ul>
<hr>
<h2 id="Solving-Logistic-Oriented-Bin-Packing-Problems-Through-a-Hybrid-Quantum-Classical-Approach"><a href="#Solving-Logistic-Oriented-Bin-Packing-Problems-Through-a-Hybrid-Quantum-Classical-Approach" class="headerlink" title="Solving Logistic-Oriented Bin Packing Problems Through a Hybrid Quantum-Classical Approach"></a>Solving Logistic-Oriented Bin Packing Problems Through a Hybrid Quantum-Classical Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02787">http://arxiv.org/abs/2308.02787</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sebastián V. Romero, Eneko Osaba, Esther Villar-Rodriguez, Antón Asla</li>
<li>for: 解决现实世界中的箱包问题（Bin Packing Problem），即将物品归类到箱中，以降低存储成本或改善货物分配。</li>
<li>methods: 使用作者之前发表的量子-классической框架（Q4RealBPP），解决现实世界中的箱包问题实际问题。</li>
<li>results: 在本文中，作者采用了多种特点，如箱不同类型、一维、二维和三维实例的解决方案，以及物品与箱的关联要求和交付优先级等，并测试了这些特点和Q4RealBPP的应用能力。<details>
<summary>Abstract</summary>
The Bin Packing Problem is a classic problem with wide industrial applicability. In fact, the efficient packing of items into bins is one of the toughest challenges in many logistic corporations and is a critical issue for reducing storage costs or improving vehicle space allocation. In this work, we resort to our previously published quantum-classical framework known as Q4RealBPP, and elaborate on the solving of real-world oriented instances of the Bin Packing Problem. With this purpose, this paper gravitates on the following characteristics: i) the existence of heterogeneous bins, ii) the extension of the framework to solve not only three-dimensional, but also one- and two-dimensional instances of the problem, iii) requirements for item-bin associations, and iv) delivery priorities. All these features have been tested in this paper, as well as the ability of Q4RealBPP to solve real-world oriented instances.
</details>
<details>
<summary>摘要</summary>
文本：The Bin Packing Problem is a classic problem with wide industrial applicability. In fact, the efficient packing of items into bins is one of the toughest challenges in many logistic corporations and is a critical issue for reducing storage costs or improving vehicle space allocation. In this work, we resort to our previously published quantum-classical framework known as Q4RealBPP, and elaborate on the solving of real-world oriented instances of the Bin Packing Problem. With this purpose, this paper gravitates on the following characteristics: i) the existence of heterogeneous bins, ii) the extension of the framework to solve not only three-dimensional, but also one- and two-dimensional instances of the problem, iii) requirements for item-bin associations, and iv) delivery priorities. All these features have been tested in this paper, as well as the ability of Q4RealBPP to solve real-world oriented instances.中文翻译： bin packing 问题是一个广泛的工业应用问题。实际上，fficiently packing items into bins 是许多物流公司面临的最大挑战，是降低存储成本或改善车辆空间分配的关键问题。在这种情况下，我们 resort 到我们之前发表的量子-классической框架，称为 Q4RealBPP，并详细介绍了解决实际应用场景的问题。为此，本文强调以下特征：i) 存在异ogeneous bins，ii) 扩展框架以解决不仅三维，而且一维和二维实例的问题，iii) 物品-桶关联要求，以及 iv) 交付优先级。所有这些特征都在本文中进行了测试，以及 Q4RealBPP 的应用实际应用场景。
</details></li>
</ul>
<hr>
<h2 id="Semi-supervised-Contrastive-Regression-for-Estimation-of-Eye-Gaze"><a href="#Semi-supervised-Contrastive-Regression-for-Estimation-of-Eye-Gaze" class="headerlink" title="Semi-supervised Contrastive Regression for Estimation of Eye Gaze"></a>Semi-supervised Contrastive Regression for Estimation of Eye Gaze</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02784">http://arxiv.org/abs/2308.02784</a></li>
<li>repo_url: None</li>
<li>paper_authors: Somsukla Maiti, Akshansh Gupta</li>
<li>for: 这篇研究旨在开发一个半超vised的对比学习框架，以便估测人们的视线方向。</li>
<li>methods: 这篇研究使用的方法是对比学习框架，并提出了一个新的对比损失函数，以提高对比学习的精度和效率。</li>
<li>results: 这篇研究发现，这个对比学习框架可以从小访实验数据中获得一个具有普遍适用性的解决方案，并与许多现有的对比学习技术相比，表现更好。<details>
<summary>Abstract</summary>
With the escalated demand of human-machine interfaces for intelligent systems, development of gaze controlled system have become a necessity. Gaze, being the non-intrusive form of human interaction, is one of the best suited approach. Appearance based deep learning models are the most widely used for gaze estimation. But the performance of these models is entirely influenced by the size of labeled gaze dataset and in effect affects generalization in performance. This paper aims to develop a semi-supervised contrastive learning framework for estimation of gaze direction. With a small labeled gaze dataset, the framework is able to find a generalized solution even for unseen face images. In this paper, we have proposed a new contrastive loss paradigm that maximizes the similarity agreement between similar images and at the same time reduces the redundancy in embedding representations. Our contrastive regression framework shows good performance in comparison to several state of the art contrastive learning techniques used for gaze estimation.
</details>
<details>
<summary>摘要</summary>
随着人机交互系统中智能系统的需求增加，考虑到人机交互的非侵入性，考虑到人机交互的非侵入性， gaze controlled system 的开发已成为必要。 gaze 是一种非侵入性的人机交互方式，是最适合的方式之一。 使用 deep learning 模型来进行 gaze 估计是最常见的方法，但这些模型的性能完全受到 Labelled gaze dataset 的大小的限制，从而影响其性能的总体化。本文提出了一种 semi-supervised contrastive learning 框架，可以使用小量 Labelled gaze dataset 来估计 gaze 方向。该框架能够在未看过的面孔图像上找到一个通用的解决方案。我们提出了一种新的对比损失函数，可以最大化相似图像之间的相似性，同时减少对 embedding 表示的重复性。我们的对比回归框架在许多 state-of-the-art 对比学习技术用于 gaze 估计方面显示了良好的性能。
</details></li>
</ul>
<hr>
<h2 id="Surrogate-Empowered-Sim2Real-Transfer-of-Deep-Reinforcement-Learning-for-ORC-Superheat-Control"><a href="#Surrogate-Empowered-Sim2Real-Transfer-of-Deep-Reinforcement-Learning-for-ORC-Superheat-Control" class="headerlink" title="Surrogate Empowered Sim2Real Transfer of Deep Reinforcement Learning for ORC Superheat Control"></a>Surrogate Empowered Sim2Real Transfer of Deep Reinforcement Learning for ORC Superheat Control</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02765">http://arxiv.org/abs/2308.02765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Runze Lin, Yangyang Luo, Xialai Wu, Junghui Chen, Biao Huang, Lei Xie, Hongye Su</li>
<li>for: 提高智能制造过程工业中ORC系统的控制性能和用户使用Friendliness。</li>
<li>methods: 使用深度强化学习（DRL）控制方法，通过实验结果显示了DRL控制方法在多种运行条件下的一致性和可靠性。</li>
<li>results: 实验结果表明，提出的Sim2Real传输学习控制方法可以快速提高DRL在ORC控制问题中的训练速度，并解决多种运行条件下DRL代理人的一致性问题。<details>
<summary>Abstract</summary>
The Organic Rankine Cycle (ORC) is widely used in industrial waste heat recovery due to its simple structure and easy maintenance. However, in the context of smart manufacturing in the process industry, traditional model-based optimization control methods are unable to adapt to the varying operating conditions of the ORC system or sudden changes in operating modes. Deep reinforcement learning (DRL) has significant advantages in situations with uncertainty as it directly achieves control objectives by interacting with the environment without requiring an explicit model of the controlled plant. Nevertheless, direct application of DRL to physical ORC systems presents unacceptable safety risks, and its generalization performance under model-plant mismatch is insufficient to support ORC control requirements. Therefore, this paper proposes a Sim2Real transfer learning-based DRL control method for ORC superheat control, which aims to provide a new simple, feasible, and user-friendly solution for energy system optimization control. Experimental results show that the proposed method greatly improves the training speed of DRL in ORC control problems and solves the generalization performance issue of the agent under multiple operating conditions through Sim2Real transfer.
</details>
<details>
<summary>摘要</summary>
“对于工业废热回收中的组合式润滑循环（ORC）系统，由于其简单的结构和维护容易，因此在制程工业中广泛应用。但在智能制造中，传统的模型基于优化控制方法无法适应ORC系统的变化操作条件或突然变化的操作模式。深度强化学习（DRL）在不确定情况下有优势，因为它直接实现控制目标无需明确控制plant的模型。但是，将DRL直接应用到物理ORC系统中会带来不可接受的安全隐患，并且其通用性在多个操作条件下的表现不足以满足ORC控制需求。因此，本文提出了一种基于Sim2Real传播学习的DRL控制方法，以提供一个新的简单、可行、用户友好的能源系统优化控制解决方案。实验结果显示，提案的方法可以对ORC超载控制问题进行快速培训DRL，并且透过Sim2Real传播解决代理人在多个操作条件下的一致性问题。”
</details></li>
</ul>
<hr>
<h2 id="NeRFs-The-Search-for-the-Best-3D-Representation"><a href="#NeRFs-The-Search-for-the-Best-3D-Representation" class="headerlink" title="NeRFs: The Search for the Best 3D Representation"></a>NeRFs: The Search for the Best 3D Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02751">http://arxiv.org/abs/2308.02751</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ravi Ramamoorthi</li>
<li>for: The paper is written for those interested in 3D representation and view synthesis, particularly in the context of Neural Radiance Fields (NeRFs) and their applications in computer graphics and vision.</li>
<li>methods: The paper uses a review of the NeRF representation and its applications, as well as a historical perspective on the development of 3D representation for view synthesis and related problems.</li>
<li>results: The paper provides insights into the current state of NeRF representations and their applications, as well as new developments and future directions in 3D representation.Here is the same information in Simplified Chinese text:</li>
<li>for: 这篇论文是为了那些关注3D表示和视图合成的人们，尤其是在神经采样场景下的Neural Radiance Fields（NeRFs）和其应用于计算机图形和视觉领域。</li>
<li>methods: 这篇论文使用了NeRF表示的评论和应用，以及视图合成和相关问题的历史发展。</li>
<li>results: 这篇论文提供了NeRF表示的当前状况和应用，以及新的发展和未来方向。<details>
<summary>Abstract</summary>
Neural Radiance Fields or NeRFs have become the representation of choice for problems in view synthesis or image-based rendering, as well as in many other applications across computer graphics and vision, and beyond. At their core, NeRFs describe a new representation of 3D scenes or 3D geometry. Instead of meshes, disparity maps, multiplane images or even voxel grids, they represent the scene as a continuous volume, with volumetric parameters like view-dependent radiance and volume density obtained by querying a neural network. The NeRF representation has now been widely used, with thousands of papers extending or building on it every year, multiple authors and websites providing overviews and surveys, and numerous industrial applications and startup companies. In this article, we briefly review the NeRF representation, and describe the three decades-long quest to find the best 3D representation for view synthesis and related problems, culminating in the NeRF papers. We then describe new developments in terms of NeRF representations and make some observations and insights regarding the future of 3D representations.
</details>
<details>
<summary>摘要</summary>
neural radiance fields (NeRFs) 已成为视图合成或基于图像渲染等问题的表示方法选择，以及计算机视觉领域中许多其他应用程序的首选表示方法。 NeRFs 描述了一种新的三维场景或三维几何表示方法，而不是传统的网格、投影图、多平面图像或粒子网格。 NeRF 表示方法通过访问神经网络来获取视依赖的光度和体积密度，并且表示场景为一个连续体，而不是分割的几何体。在这篇文章中，我们将简要介绍 NeRF 表示方法，并描述了三十年来寻找最佳视图合成和相关问题的解决方案，即 NeRF 论文。然后，我们将介绍 NeRF 表示方法的新发展，以及一些关于未来三维表示方法的观察和发现。
</details></li>
</ul>
<hr>
<h2 id="Nonlinear-Controller-Design-for-a-Quadrotor-with-Inverted-Pendulum"><a href="#Nonlinear-Controller-Design-for-a-Quadrotor-with-Inverted-Pendulum" class="headerlink" title="Nonlinear Controller Design for a Quadrotor with Inverted Pendulum"></a>Nonlinear Controller Design for a Quadrotor with Inverted Pendulum</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02741">http://arxiv.org/abs/2308.02741</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xichen Shi, Yashwanth Kumar Nakka</li>
<li>for: 研究了四轴直径自适应控制系统的非线性动力学系统，并实现了轨迹跟踪和稳定控制。</li>
<li>methods: 使用了反馈线性化和控制Λ恒定函数（CLF）的方法，并利用了二次Programming（QP）来解决控制问题。</li>
<li>results: 实现了四轴直径自适应控制系统的轨迹跟踪和稳定控制，并在四轴直径自适应控制系统和圆柱吊车组合情况下实现了轨迹跟踪。<details>
<summary>Abstract</summary>
The quadrotor is a $6$ degrees-of-freedom (DoF) system with underactuation. Adding a spherical pendulum on top of a quadrotor further complicates the task of achieving any output tracking while stabilizing the rest. In this report, we present different types of controllers for the nonlinear dynamical system of quadrotor and pendulum combination, utilizing feedback-linearization and control Lyapunov function with quadratic programming (CLF-QP) approaches. We demonstrated trajectory tracking for quadrotor-only case as well as quadrotor-pendulum-combined case.
</details>
<details>
<summary>摘要</summary>
四旋翼机是6度自由度（DoF）系统，受不足动作控制的影响。在这种情况下，加装球形悬挂在四旋翼机之上，使得控制任务变得更加复杂。本报告介绍了不同类型的控制器，用于非线性动力学系统的四旋翼机和悬挂组合，包括反馈线性化和控制 Lyapunov 函数（CLF）的方法。我们也展示了四旋翼机只有情况和四旋翼机与悬挂相结合的轨迹跟踪情况。
</details></li>
</ul>
<hr>
<h2 id="Assessing-the-impact-of-emergency-department-short-stay-units-using-length-of-stay-prediction-and-discrete-event-simulation"><a href="#Assessing-the-impact-of-emergency-department-short-stay-units-using-length-of-stay-prediction-and-discrete-event-simulation" class="headerlink" title="Assessing the impact of emergency department short stay units using length-of-stay prediction and discrete event simulation"></a>Assessing the impact of emergency department short stay units using length-of-stay prediction and discrete event simulation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02730">http://arxiv.org/abs/2308.02730</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mucahit Cevik, Can Kavaklioglu, Fahad Razak, Amol Verma, Ayse Basar</li>
<li>for: 预测住院日期可以帮助医疗决策和资源分配。本研究旨在建立一个决策支持系统，以预测急诊部内科病人的住院日期。</li>
<li>methods: 我们进行了探索数据分析和特征选择方法，以确定预测住院日期最佳的特征。我们还开发了一个离散事件模拟模型，以评估预测模型在实际场景中的表现。</li>
<li>results: 我们的结果表明，建议的表现是一般可接受的，并不需要特征选择。此外，结果表明可以使用患者入院特征、实验室测试结果、Radiology、生命体征和临床记录来预测住院日期，并且预测效果可以达到0.69的AUC值（分类短期和长期住院患者）。<details>
<summary>Abstract</summary>
Accurately predicting hospital length-of-stay at the time a patient is admitted to hospital may help guide clinical decision making and resource allocation. In this study we aim to build a decision support system that predicts hospital length-of-stay for patients admitted to general internal medicine from the emergency department. We conduct an exploratory data analysis and employ feature selection methods to identify the attributes that result in the best predictive performance. We also develop a discrete-event simulation model to assess the performances of the prediction models in a practical setting. Our results show that the recommendation performances of the proposed approaches are generally acceptable and do not benefit from the feature selection. Further, the results indicate that hospital length-of-stay could be predicted with reasonable accuracy (e.g., AUC value for classifying short and long stay patients is 0.69) using patient admission demographics, laboratory test results, diagnostic imaging, vital signs and clinical documentation.
</details>
<details>
<summary>摘要</summary>
可以准确预测入院病人的医院length-of-stay（LoS）可以帮助医疗决策和资源分配。在这个研究中，我们想要建立一个决策支持系统，用于预测急诊医学科病人的医院LoS。我们进行了探索性数据分析，并使用特征选择方法来确定最佳预测性能的属性。我们还开发了一个离散事件模拟模型，以评估预测模型在实际场景中的表现。我们的结果表明，提议的方法的表现是一般可接受的，并且不受特征选择的影响。此外，结果表明，可以使用病人入院的人数、实验室测试结果、 radiológica图像、生命体征和临床记录来预测医院LoS，并且预测的准确率（例如，AUC值用于分类短长停病人是0.69）。
</details></li>
</ul>
<hr>
<h2 id="Towards-Improving-Harmonic-Sensitivity-and-Prediction-Stability-for-Singing-Melody-Extraction"><a href="#Towards-Improving-Harmonic-Sensitivity-and-Prediction-Stability-for-Singing-Melody-Extraction" class="headerlink" title="Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction"></a>Towards Improving Harmonic Sensitivity and Prediction Stability for Singing Melody Extraction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02723">http://arxiv.org/abs/2308.02723</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/smoothken/kknet">https://github.com/smoothken/kknet</a></li>
<li>paper_authors: Keren Shao, Ke Chen, Taylor Berg-Kirkpatrick, Shlomo Dubnov</li>
<li>for: 提高歌唱 мелодии提取模型的性能</li>
<li>methods: 输入特征修改和训练目标修改，基于两个假设：一是声音spectrogram中的harmonic衰减速度较快，二是短暂的 vocals和非 vocals段落很罕见。</li>
<li>results: 对多种模型，包括MSNet、FTANet和新引入的PianoNet，进行了修改，并通过实验证明了提议的修改对歌唱 мелодии提取有 empirical 效果。<details>
<summary>Abstract</summary>
In deep learning research, many melody extraction models rely on redesigning neural network architectures to improve performance. In this paper, we propose an input feature modification and a training objective modification based on two assumptions. First, harmonics in the spectrograms of audio data decay rapidly along the frequency axis. To enhance the model's sensitivity on the trailing harmonics, we modify the Combined Frequency and Periodicity (CFP) representation using discrete z-transform. Second, the vocal and non-vocal segments with extremely short duration are uncommon. To ensure a more stable melody contour, we design a differentiable loss function that prevents the model from predicting such segments. We apply these modifications to several models, including MSNet, FTANet, and a newly introduced model, PianoNet, modified from a piano transcription network. Our experimental results demonstrate that the proposed modifications are empirically effective for singing melody extraction.
</details>
<details>
<summary>摘要</summary>
在深度学习研究中，许多旋律提取模型采用重新设计神经网络架构以提高性能。在这篇论文中，我们提出了输入特征修改和训练目标修改，基于两个假设。首先， audio数据spectrogram中的谱harmonics快速衰减 along the frequency axis。为了增强模型对后续谱harmonics的敏感性，我们使用discrete z-transform修改Combined Frequency and Periodicity (CFP)表示。其次， vocals和非 vocals的极短时间段是非常罕见的。为了确保更稳定的旋律轮廓，我们设计了可导的损失函数，防止模型预测这些时间段。我们应用这些修改于several models，包括MSNet、FTANet和一种新引入的模型，PianoNet，该模型来自钢琴谱写网络。我们的实验结果表明，提出的修改是empirically effective дляSinging melody extraction。
</details></li>
</ul>
<hr>
<h2 id="Solving-Witness-type-Triangle-Puzzles-Faster-with-an-Automatically-Learned-Human-Explainable-Predicate"><a href="#Solving-Witness-type-Triangle-Puzzles-Faster-with-an-Automatically-Learned-Human-Explainable-Predicate" class="headerlink" title="Solving Witness-type Triangle Puzzles Faster with an Automatically Learned Human-Explainable Predicate"></a>Solving Witness-type Triangle Puzzles Faster with an Automatically Learned Human-Explainable Predicate</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02666">http://arxiv.org/abs/2308.02666</a></li>
<li>repo_url: None</li>
<li>paper_authors: Justin Stevens, Vadim Bulitko, David Thue</li>
<li>for: 用于帮助玩家解决游戏《证人》中的谜题，以及帮助谜题设计者生成更好的谜题。</li>
<li>methods: 使用人工智能谜题解决器自动解决谜题，并学习一个可解释的预测方法来判断partial path是否可以转化为解决方案。</li>
<li>results: 使用这种预测方法可以加速搜索，平均提高搜索速度六倍，而且可以在固定搜索时间预算下解决更大的谜题。<details>
<summary>Abstract</summary>
Automatically solving puzzle instances in the game The Witness can guide players toward solutions and help puzzle designers generate better puzzles. In the latter case such an Artificial Intelligence puzzle solver can inform a human puzzle designer and procedural puzzle generator to produce better instances. The puzzles, however, are combinatorially difficult and search-based solvers can require large amounts of time and memory. We accelerate such search by automatically learning a human-explainable predicate that predicts whether a partial path to a Witness-type puzzle is not completable to a solution path. We prove a key property of the learned predicate which allows us to use it for pruning successor states in search thereby accelerating search by an average of six times while maintaining completeness of the underlying search. Conversely given a fixed search time budget per puzzle our predicate-accelerated search can solve more puzzle instances of larger sizes than the baseline search.
</details>
<details>
<summary>摘要</summary>
自动解决游戏《证人》中的PUZZLE实例可以帮助玩家找到解决方案，同时也可以帮助游戏设计者生成更好的PUZZLE。在后一种情况下，人工智能PUZZLE解决器可以告诉人类PUZZLE设计者和生成器制造更好的实例。然而，这些PUZZLE具有复杂的组合性，搜索基于的解决方法可能需要大量的时间和内存。我们使用自动学习的人类可读 predicate来预测partial path是否可能不能完成到解决方案。我们证明了该 predicate 的一个关键性质，这使得我们可以在搜索中使用它进行减少继承状态，从而加速搜索，而且平均加速 six 倍，保持搜索的完整性。相反，给定一个固定的搜索时间预算，我们的 predicate-加速搜索可以解决更大的PUZZLE实例，比基eline搜索更多。
</details></li>
</ul>
<hr>
<h2 id="Let’s-Give-a-Voice-to-Conversational-Agents-in-Virtual-Reality"><a href="#Let’s-Give-a-Voice-to-Conversational-Agents-in-Virtual-Reality" class="headerlink" title="Let’s Give a Voice to Conversational Agents in Virtual Reality"></a>Let’s Give a Voice to Conversational Agents in Virtual Reality</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02665">http://arxiv.org/abs/2308.02665</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sislab-unitn/Let-s-Give-a-Voice-to-Conversational-Agents-in-VR">https://github.com/sislab-unitn/Let-s-Give-a-Voice-to-Conversational-Agents-in-VR</a></li>
<li>paper_authors: Michele Yin, Gabriel Roccabruna, Abhinav Azad, Giuseppe Riccardi</li>
<li>for: 这个论文的目标是提高虚拟现实中对话体验的互动性，并使用多模态和 immerse 交互来增强对话体验。</li>
<li>methods: 这个论文提出了一种开源架构，用于简化在虚拟环境中开发对话体验的过程，并允许插入不同领域的对话体验和自定义或云端的语音识别和语音合成模型，以使对话变得语音基于。</li>
<li>results: 作者在 Unity 中创建了两个对话 прототип，一个是非 immerse 显示，另一个是 VR 头sets，并在数字健康领域中进行了测试和评估。<details>
<summary>Abstract</summary>
The dialogue experience with conversational agents can be greatly enhanced with multimodal and immersive interactions in virtual reality. In this work, we present an open-source architecture with the goal of simplifying the development of conversational agents operating in virtual environments. The architecture offers the possibility of plugging in conversational agents of different domains and adding custom or cloud-based Speech-To-Text and Text-To-Speech models to make the interaction voice-based. Using this architecture, we present two conversational prototypes operating in the digital health domain developed in Unity for both non-immersive displays and VR headsets.
</details>
<details>
<summary>摘要</summary>
对话体验可以通过多模态和 immerse 交互在虚拟现实中进行增强。在这项工作中，我们提出了一个开源架构，以便简化在虚拟环境中运行 conversational agent 的开发。该架构允许插入不同领域的 conversational agent，并可以添加自定义或云端的 Speech-To-Text 和 Text-To-Speech 模型，以使交互voice基于。使用这个架构，我们向大家展示了在 Unity 中为非 immerse 显示和 VR 头戴设备开发的两个对话原型，其中一个是在医疗领域中进行了开发。
</details></li>
</ul>
<hr>
<h2 id="MM-Vet-Evaluating-Large-Multimodal-Models-for-Integrated-Capabilities"><a href="#MM-Vet-Evaluating-Large-Multimodal-Models-for-Integrated-Capabilities" class="headerlink" title="MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities"></a>MM-Vet: Evaluating Large Multimodal Models for Integrated Capabilities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02490">http://arxiv.org/abs/2308.02490</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuweihao/mm-vet">https://github.com/yuweihao/mm-vet</a></li>
<li>paper_authors: Weihao Yu, Zhengyuan Yang, Linjie Li, Jianfeng Wang, Kevin Lin, Zicheng Liu, Xinchao Wang, Lijuan Wang</li>
<li>For: The paper proposes an evaluation benchmark called MM-Vet to evaluate large multimodal models (LMMs) on complicated multimodal tasks.* Methods: The paper uses six core vision-language (VL) capabilities to define the tasks and evaluates the 16 integrations of interest derived from the capability combination. The paper also proposes an LLM-based evaluator for open-ended outputs to evaluate the models across different question types and answer styles.* Results: The paper evaluates representative LMMs on MM-Vet and provides insights into the capabilities of different LMM system paradigms and models.Here is the simplified Chinese version of the three key points:* For: 文章提出了一个名为 MM-Vet 的评估准则，用于评估大型多Modal模型（LMMs）在复杂多Modal任务上的表现。* 方法: 文章使用 six core 视力语言（VL）能力定义任务，并评估了这些能力的16种组合。文章还提出了基于 LLM 的评估器，用于评估不同类型的问题和答案风格。* 结果: 文章对 representative LMMs 进行了 MM-Vet 的评估，并提供了不同系统 paradigm 和模型的能力的详细分析。<details>
<summary>Abstract</summary>
We propose MM-Vet, an evaluation benchmark that examines large multimodal models (LMMs) on complicated multimodal tasks. Recent LMMs have shown various intriguing abilities, such as solving math problems written on the blackboard, reasoning about events and celebrities in news images, and explaining visual jokes. Rapid model advancements pose challenges to evaluation benchmark development. Problems include: (1) How to systematically structure and evaluate the complicated multimodal tasks; (2) How to design evaluation metrics that work well across question and answer types; and (3) How to give model insights beyond a simple performance ranking. To this end, we present MM-Vet, designed based on the insight that the intriguing ability to solve complicated tasks is often achieved by a generalist model being able to integrate different core vision-language (VL) capabilities. MM-Vet defines 6 core VL capabilities and examines the 16 integrations of interest derived from the capability combination. For evaluation metrics, we propose an LLM-based evaluator for open-ended outputs. The evaluator enables the evaluation across different question types and answer styles, resulting in a unified scoring metric. We evaluate representative LMMs on MM-Vet, providing insights into the capabilities of different LMM system paradigms and models. Code and data are available at https://github.com/yuweihao/MM-Vet.
</details>
<details>
<summary>摘要</summary>
我们提出了MM-Vet，一个评估标准用于测试大型多modal模型（LMM）在复杂多modal任务上的能力。最近的LMM模型已经展示了各种奇妙的能力，如解决written on the blackboard的数学问题，理解新闻图片中的事件和名人，以及解释视觉笑话。由于模型的快速进步，评估标准的开发受到挑战。问题包括：（1）如何系统地结构化和评估复杂多modal任务；（2）如何设计评估指标，能够适应不同的问题类型和答案风格；以及（3）如何为模型提供更深刻的理解，不仅是简单的性能排名。为此，我们提出了MM-Vet，基于多modal视语（VL）能力的核心能力的设计。MM-Vet定义了6个核心VL能力，并评估16种 интерес的核心能力组合。 для评估指标，我们提议一种基于LLM的评估器，可以评估不同的问题类型和答案风格，从而获得统一的评估指标。我们对代表性的LMM模型进行了MM-Vet的评估，从而获得了不同模型系统和模型 paradigm的能力的具体情况。代码和数据可以在https://github.com/yuweihao/MM-Vet中获取。
</details></li>
</ul>
<hr>
<h2 id="Generation-of-Realistic-Synthetic-Raw-Radar-Data-for-Automated-Driving-Applications-using-Generative-Adversarial-Networks"><a href="#Generation-of-Realistic-Synthetic-Raw-Radar-Data-for-Automated-Driving-Applications-using-Generative-Adversarial-Networks" class="headerlink" title="Generation of Realistic Synthetic Raw Radar Data for Automated Driving Applications using Generative Adversarial Networks"></a>Generation of Realistic Synthetic Raw Radar Data for Automated Driving Applications using Generative Adversarial Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02632">http://arxiv.org/abs/2308.02632</a></li>
<li>repo_url: None</li>
<li>paper_authors: Eduardo C. Fidelis, Fabio Reway, Herick Y. S. Ribeiro, Pietro L. Campos, Werner Huber, Christian Icking, Lester A. Faria, Torsten Schön</li>
<li>for: 这个研究的目的是为了发展一个更快速的双普朗恩几何激光（FMCW）实验方法，并且可以生成实验数据。</li>
<li>methods: 这个方法使用了生成对抗网络（GAN）来生成激光数据，并且可以同时生成16个激光脉冲。</li>
<li>results: 这个方法可以实现激光数据的生成，并且可以实现与实际数据之间的对比，并且可以提高处理激光数据的算法的可能性。<details>
<summary>Abstract</summary>
The main approaches for simulating FMCW radar are based on ray tracing, which is usually computationally intensive and do not account for background noise. This work proposes a faster method for FMCW radar simulation capable of generating synthetic raw radar data using generative adversarial networks (GAN). The code and pre-trained weights are open-source and available on GitHub. This method generates 16 simultaneous chirps, which allows the generated data to be used for the further development of algorithms for processing radar data (filtering and clustering). This can increase the potential for data augmentation, e.g., by generating data in non-existent or safety-critical scenarios that are not reproducible in real life. In this work, the GAN was trained with radar measurements of a motorcycle and used to generate synthetic raw radar data of a motorcycle traveling in a straight line. For generating this data, the distance of the motorcycle and Gaussian noise are used as input to the neural network. The synthetic generated radar chirps were evaluated using the Frechet Inception Distance (FID). Then, the Range-Azimuth (RA) map is calculated twice: first, based on synthetic data using this GAN and, second, based on real data. Based on these RA maps, an algorithm with adaptive threshold and edge detection is used for object detection. The results have shown that the data is realistic in terms of coherent radar reflections of the motorcycle and background noise based on the comparison of chirps, the RA maps and the object detection results. Thus, the proposed method in this work has shown to minimize the simulation-to-reality gap for the generation of radar data.
</details>
<details>
<summary>摘要</summary>
主要方法 для模拟雷达是基于射线跟踪，通常是计算机处理昂贵并不考虑背景噪声。这项工作提出了一种更快的雷达数据生成方法，使用生成对抗网络（GAN）来生成合成雷达数据。代码和预训练 веса公开源代码在GitHub上可用。这种方法生成了16个同时的雷达射击，使得生成的数据可以用于雷达数据处理算法的进一步开发（滤波和归一化）。这可以增加数据增强的潜在性，例如生成不可能或安全关键的场景中的数据，以便在实际生活中不可能重现。在这项工作中，GAN被训练使用雷达测量数据，并用来生成雷达数据。输入到神经网络的距离和高斯噪声来生成雷达射击。生成的雷达射击被评估使用彩色卷积扩散（FID）。然后，基于生成的数据和实际数据，计算雷达-方向（RA）图。RA图被计算两次：首先，基于生成数据使用这个GAN；其次，基于实际数据。基于这些RA图，使用适应阈值和边检测算法进行对象检测。结果表明，生成的数据具有准确的干扰雷达反射和背景噪声，根据射击、RA图和对象检测结果进行比较。因此，提出的方法在本工作中减少了模拟到现实差距。
</details></li>
</ul>
<hr>
<h2 id="Nonprehensile-Planar-Manipulation-through-Reinforcement-Learning-with-Multimodal-Categorical-Exploration"><a href="#Nonprehensile-Planar-Manipulation-through-Reinforcement-Learning-with-Multimodal-Categorical-Exploration" class="headerlink" title="Nonprehensile Planar Manipulation through Reinforcement Learning with Multimodal Categorical Exploration"></a>Nonprehensile Planar Manipulation through Reinforcement Learning with Multimodal Categorical Exploration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02459">http://arxiv.org/abs/2308.02459</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juan Del Aguila Ferrandis, João Moura, Sethu Vijayakumar</li>
<li>for: 这个论文目的是开发一种可以实现灵活非握持操作的 робот控制器，例如拧pushing an object on a table。</li>
<li>methods: 这篇论文使用了人工智能学习（RL）框架，并通过多态探索方法来让控制器更加灵活和精准。</li>
<li>results: 论文表明，使用多态探索方法可以让RL控制器在不同的初始和目标物体位置和方向下进行灵活的操作，并且对于外部干扰和观测噪声 Display textshowed improved accuracy and smooth trajectories compared to previous RL literature.  Furthermore, the learned policies were shown to be transferable to physical robot hardware.<details>
<summary>Abstract</summary>
Developing robot controllers capable of achieving dexterous nonprehensile manipulation, such as pushing an object on a table, is challenging. The underactuated and hybrid-dynamics nature of the problem, further complicated by the uncertainty resulting from the frictional interactions, requires sophisticated control behaviors. Reinforcement Learning (RL) is a powerful framework for developing such robot controllers. However, previous RL literature addressing the nonprehensile pushing task achieves low accuracy, non-smooth trajectories, and only simple motions, i.e. without rotation of the manipulated object. We conjecture that previously used unimodal exploration strategies fail to capture the inherent hybrid-dynamics of the task, arising from the different possible contact interaction modes between the robot and the object, such as sticking, sliding, and separation. In this work, we propose a multimodal exploration approach through categorical distributions, which enables us to train planar pushing RL policies for arbitrary starting and target object poses, i.e. positions and orientations, and with improved accuracy. We show that the learned policies are robust to external disturbances and observation noise, and scale to tasks with multiple pushers. Furthermore, we validate the transferability of the learned policies, trained entirely in simulation, to a physical robot hardware using the KUKA iiwa robot arm. See our supplemental video: https://youtu.be/vTdva1mgrk4.
</details>
<details>
<summary>摘要</summary>
开发能够完成无握持的机械人控制器，例如将物体推push到表面上，是一项复杂的任务。由于机械人的下降和混合动力学性质，以及与物体之间的摩擦交互的不确定性，需要开发出复杂的控制方法。学习回归（RL）是一种强大的框架 для开发这类机械人控制器。然而，先前RL文献中的非握持推动任务往往具有低精度、不稳定的轨迹和简单的运动，即不包括机械人 manipulate对象的旋转。我们 conjecture that previous unimodal exploration strategies fail to capture the inherent hybrid dynamics of the task, arising from the different possible contact interaction modes between the robot and the object, such as sticking, sliding, and separation.在这种情况下，我们提出了多模态探索方法，通过分类分布来实现。这使得我们可以训练平面推动RL策略，对于任意起始和目标对象位姿和orientation，并且具有改善的精度。我们示出了学习的策略对于外部干扰和观测噪声具有鲁棒性和扩展性，并且可以扩展到多个推动器。此外，我们验证了学习的策略，完全在 simulate 环境中训练的，可以转移到物理机械人硬件上，使用KUKA iiwa robot臂。请参考我们的补充视频：https://youtu.be/vTdva1mgrk4。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Temporal-Knowledge-Graph-Completion-Taxonomy-Progress-and-Prospects"><a href="#A-Survey-on-Temporal-Knowledge-Graph-Completion-Taxonomy-Progress-and-Prospects" class="headerlink" title="A Survey on Temporal Knowledge Graph Completion: Taxonomy, Progress, and Prospects"></a>A Survey on Temporal Knowledge Graph Completion: Taxonomy, Progress, and Prospects</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02457">http://arxiv.org/abs/2308.02457</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jiapuwang/awesome-tkgc">https://github.com/jiapuwang/awesome-tkgc</a></li>
<li>paper_authors: Jiapu Wang, Boyue Wang, Meikang Qiu, Shirui Pan, Bo Xiong, Heng Liu, Linhao Luo, Tengfei Liu, Yongli Hu, Baocai Yin, Wen Gao</li>
<li>for: 本研究提出了一个完整的知识图谱（TKG）完成任务，以解决知识图谱中存在 incomplete 的问题。</li>
<li>methods: 本研究对 TKGC 方法进行了全面的回顾和分析，包括 Background、Interpolation 和 Extrapolation 三部分。</li>
<li>results: 本研究对 TKGC 方法进行了详细的介绍和分类，并提出了未来研究方向。<details>
<summary>Abstract</summary>
Temporal characteristics are prominently evident in a substantial volume of knowledge, which underscores the pivotal role of Temporal Knowledge Graphs (TKGs) in both academia and industry. However, TKGs often suffer from incompleteness for three main reasons: the continuous emergence of new knowledge, the weakness of the algorithm for extracting structured information from unstructured data, and the lack of information in the source dataset. Thus, the task of Temporal Knowledge Graph Completion (TKGC) has attracted increasing attention, aiming to predict missing items based on the available information. In this paper, we provide a comprehensive review of TKGC methods and their details. Specifically, this paper mainly consists of three components, namely, 1)Background, which covers the preliminaries of TKGC methods, loss functions required for training, as well as the dataset and evaluation protocol; 2)Interpolation, that estimates and predicts the missing elements or set of elements through the relevant available information. It further categorizes related TKGC methods based on how to process temporal information; 3)Extrapolation, which typically focuses on continuous TKGs and predicts future events, and then classifies all extrapolation methods based on the algorithms they utilize. We further pinpoint the challenges and discuss future research directions of TKGC.
</details>
<details>
<summary>摘要</summary>
temporal characteristics are prominently evident in a substantial volume of knowledge, which underscores the pivotal role of Temporal Knowledge Graphs (TKGs) in both academia and industry. However, TKGs often suffer from incompleteness due to three main reasons: the continuous emergence of new knowledge, the weakness of the algorithm for extracting structured information from unstructured data, and the lack of information in the source dataset. Therefore, the task of Temporal Knowledge Graph Completion (TKGC) has attracted increasing attention, aiming to predict missing items based on the available information. In this paper, we provide a comprehensive review of TKGC methods and their details. Specifically, this paper mainly consists of three components, namely, 1)Background, which covers the preliminaries of TKGC methods, loss functions required for training, as well as the dataset and evaluation protocol; 2)Interpolation, that estimates and predicts the missing elements or set of elements through the relevant available information. It further categorizes related TKGC methods based on how to process temporal information; 3)Extrapolation, which typically focuses on continuous TKGs and predicts future events, and then classifies all extrapolation methods based on the algorithms they utilize. We further pinpoint the challenges and discuss future research directions of TKGC.Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="From-Military-to-Healthcare-Adopting-and-Expanding-Ethical-Principles-for-Generative-Artificial-Intelligence"><a href="#From-Military-to-Healthcare-Adopting-and-Expanding-Ethical-Principles-for-Generative-Artificial-Intelligence" class="headerlink" title="From Military to Healthcare: Adopting and Expanding Ethical Principles for Generative Artificial Intelligence"></a>From Military to Healthcare: Adopting and Expanding Ethical Principles for Generative Artificial Intelligence</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02448">http://arxiv.org/abs/2308.02448</a></li>
<li>repo_url: None</li>
<li>paper_authors: David Oniani, Jordan Hilsman, Yifan Peng, COL, Ronald K. Poropatich, COL Jeremy C. Pamplin, LTC Gary L. Legault, Yanshan Wang</li>
<li>For: The paper is written to propose ethical principles for the use of generative AI in healthcare, with the goal of addressing ethical dilemmas and challenges posed by the technology.* Methods: The paper uses a framework called GREAT PLEA to outline the ethical principles for generative AI in healthcare, which includes governance, reliability, equity, accountability, traceability, privacy, lawfulness, empathy, and autonomy.* Results: The paper aims to provide a proactive approach to addressing the ethical challenges of generative AI in healthcare, with the goal of ensuring the technology is used in a responsible and ethical manner.<details>
<summary>Abstract</summary>
In 2020, the U.S. Department of Defense officially disclosed a set of ethical principles to guide the use of Artificial Intelligence (AI) technologies on future battlefields. Despite stark differences, there are core similarities between the military and medical service. Warriors on battlefields often face life-altering circumstances that require quick decision-making. Medical providers experience similar challenges in a rapidly changing healthcare environment, such as in the emergency department or during surgery treating a life-threatening condition. Generative AI, an emerging technology designed to efficiently generate valuable information, holds great promise. As computing power becomes more accessible and the abundance of health data, such as electronic health records, electrocardiograms, and medical images, increases, it is inevitable that healthcare will be revolutionized by this technology. Recently, generative AI has captivated the research community, leading to debates about its application in healthcare, mainly due to concerns about transparency and related issues. Meanwhile, concerns about the potential exacerbation of health disparities due to modeling biases have raised notable ethical concerns regarding the use of this technology in healthcare. However, the ethical principles for generative AI in healthcare have been understudied, and decision-makers often fail to consider the significance of generative AI. In this paper, we propose GREAT PLEA ethical principles, encompassing governance, reliability, equity, accountability, traceability, privacy, lawfulness, empathy, and autonomy, for generative AI in healthcare. We aim to proactively address the ethical dilemmas and challenges posed by the integration of generative AI in healthcare.
</details>
<details>
<summary>摘要</summary>
在2020年，美国国防部官方公布了一组伦理原则，用于导引人工智能技术在未来战场上的使用。尽管Military和医疗服务之间存在显著的不同，但在面临生命改变的情况下，战士和医疗提供者都需要快速做出决策。生成AI，一种以计算机功能为基础的技术，可以高效生成有价值信息。随着计算机技术的进步和医疗数据的增加，医疗将被生成AI技术改革。Recently, generative AI has captivated the research community, leading to debates about its application in healthcare, mainly due to concerns about transparency and related issues. Meanwhile, concerns about the potential exacerbation of health disparities due to modeling biases have raised notable ethical concerns regarding the use of this technology in healthcare. However, the ethical principles for generative AI in healthcare have been understudied, and decision-makers often fail to consider the significance of generative AI. In this paper, we propose GREAT PLEA ethical principles, encompassing governance, reliability, equity, accountability, traceability, privacy, lawfulness, empathy, and autonomy, for generative AI in healthcare. We aim to proactively address the ethical dilemmas and challenges posed by the integration of generative AI in healthcare.
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/05/cs.AI_2023_08_05/" data-id="clp89do81001vi788a321gaky" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CL_2023_08_05" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/08/05/cs.CL_2023_08_05/" class="article-date">
  <time datetime="2023-08-05T11:00:00.000Z" itemprop="datePublished">2023-08-05</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CL/">cs.CL</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/08/05/cs.CL_2023_08_05/">cs.CL - 2023-08-05</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="LaDA-Latent-Dialogue-Action-For-Zero-shot-Cross-lingual-Neural-Network-Language-Modeling"><a href="#LaDA-Latent-Dialogue-Action-For-Zero-shot-Cross-lingual-Neural-Network-Language-Modeling" class="headerlink" title="LaDA: Latent Dialogue Action For Zero-shot Cross-lingual Neural Network Language Modeling"></a>LaDA: Latent Dialogue Action For Zero-shot Cross-lingual Neural Network Language Modeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02903">http://arxiv.org/abs/2308.02903</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhanyu Ma, Jian Ye, Shuang Cheng</li>
<li>for: 提高跨语言对话理解系统的表现（cross-lingual spoken language understanding）</li>
<li>methods: 使用隐藏对话动作层（LaDA）优化解码策略，提高处理距离语言的复杂多语言意图和槽值的能力</li>
<li>results: 在公共数据集上达到了领域内最佳的result，包括零shot和几shot适应情况<details>
<summary>Abstract</summary>
Cross-lingual adaptation has proven effective in spoken language understanding (SLU) systems with limited resources. Existing methods are frequently unsatisfactory for intent detection and slot filling, particularly for distant languages that differ significantly from the source language in scripts, morphology, and syntax. Latent Dialogue Action (LaDA) layer is proposed to optimize decoding strategy in order to address the aforementioned issues. The model consists of an additional layer of latent dialogue action. It enables our model to improve a system's capability of handling conversations with complex multilingual intent and slot values of distant languages. To the best of our knowledge, this is the first exhaustive investigation of the use of latent variables for optimizing cross-lingual SLU policy during the decode stage. LaDA obtains state-of-the-art results on public datasets for both zero-shot and few-shot adaptation.
</details>
<details>
<summary>摘要</summary>
cross-lingual adaptation 已经证明对于听说语言理解（SLU）系统来说是有效的。现有的方法frequently不满足意向检测和槽填充，特别是对于远程语言而言，这些语言在字母、形态和语法方面存在显著的差异。为了解决这些问题，我们提出了 latent dialogue action（LaDA）层。这层允许我们的模型在decode阶段进行优化，以提高系统处理多语言意向和槽值的能力。据我们所知，这是首次对于在decode阶段使用隐藏变量进行cross-lingual SLU策略优化的实验。LaDA在公共数据集上获得了状态之arte Results for both zero-shot and few-shot adaptation。
</details></li>
</ul>
<hr>
<h2 id="ApproBiVT-Lead-ASR-Models-to-Generalize-Better-Using-Approximated-Bias-Variance-Tradeoff-Guided-Early-Stopping-and-Checkpoint-Averaging"><a href="#ApproBiVT-Lead-ASR-Models-to-Generalize-Better-Using-Approximated-Bias-Variance-Tradeoff-Guided-Early-Stopping-and-Checkpoint-Averaging" class="headerlink" title="ApproBiVT: Lead ASR Models to Generalize Better Using Approximated Bias-Variance Tradeoff Guided Early Stopping and Checkpoint Averaging"></a>ApproBiVT: Lead ASR Models to Generalize Better Using Approximated Bias-Variance Tradeoff Guided Early Stopping and Checkpoint Averaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02870">http://arxiv.org/abs/2308.02870</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fangyuan Wang, Ming Hao, Yuhai Shi, Bo Xu</li>
<li>for: 提高自动语音识别（ASR）模型的性能</li>
<li>methods: 基于偏差-差异质量评估的早停止和模型权重平均</li>
<li>results: 在使用高级ASR模型时，提供2.5%-3.7%和3.1%-4.6% CER降准的改进Here’s the breakdown of each point:</li>
<li>for: The paper aims to improve the performance of ASR models.</li>
<li>methods: The authors rethink and update the early stopping and checkpoint averaging methods based on the bias-variance tradeoff, using training loss and validation loss as proxies for bias and variance.</li>
<li>results: The proposed method provides a 2.5%-3.7% and 3.1%-4.6% CER reduction on the AISHELL-1 and AISHELL-2 datasets, respectively, when evaluated with advanced ASR models.<details>
<summary>Abstract</summary>
The conventional recipe for Automatic Speech Recognition (ASR) models is to 1) train multiple checkpoints on a training set while relying on a validation set to prevent overfitting using early stopping and 2) average several last checkpoints or that of the lowest validation losses to obtain the final model. In this paper, we rethink and update the early stopping and checkpoint averaging from the perspective of the bias-variance tradeoff. Theoretically, the bias and variance represent the fitness and variability of a model and the tradeoff of them determines the overall generalization error. But, it's impractical to evaluate them precisely. As an alternative, we take the training loss and validation loss as proxies of bias and variance and guide the early stopping and checkpoint averaging using their tradeoff, namely an Approximated Bias-Variance Tradeoff (ApproBiVT). When evaluating with advanced ASR models, our recipe provides 2.5%-3.7% and 3.1%-4.6% CER reduction on the AISHELL-1 and AISHELL-2, respectively.
</details>
<details>
<summary>摘要</summary>
传统的自动语音识别（ASR）模型的制作方式是：1）在训练集上训练多个检查点，使用验证集来避免过拟合，并2）将多个最后的检查点或验证loss的平均值作为最终模型。在这篇论文中，我们重新思考了早期停止和检查点平均值的方法，从偏差-方差质量的角度进行了更新。在理论上，偏差和方差表示模型的适应度和多样性，它们之间的质量评估会决定模型的总化适应错误。但是，不可能准确地评估它们。作为替代方案，我们使用训练损失和验证损失作为偏差和方差的代理，并通过它们之间的质量评估来引导早期停止和检查点平均值，即 Approximated Bias-Variance Tradeoff（ApproBiVT）。当评估高级ASR模型时，我们的方法可以提供2.5%-3.7%和3.1%-4.6%的CER降减在AISHELL-1和AISHELL-2上。
</details></li>
</ul>
<hr>
<h2 id="EduChat-A-Large-Scale-Language-Model-based-Chatbot-System-for-Intelligent-Education"><a href="#EduChat-A-Large-Scale-Language-Model-based-Chatbot-System-for-Intelligent-Education" class="headerlink" title="EduChat: A Large-Scale Language Model-based Chatbot System for Intelligent Education"></a>EduChat: A Large-Scale Language Model-based Chatbot System for Intelligent Education</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02773">http://arxiv.org/abs/2308.02773</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/icalk-nlp/educhat">https://github.com/icalk-nlp/educhat</a></li>
<li>paper_authors: Yuhao Dan, Zhikai Lei, Yiyang Gu, Yong Li, Jianghao Yin, Jiaju Lin, Linhao Ye, Zhiyan Tie, Yougen Zhou, Yilei Wang, Aimin Zhou, Ze Zhou, Qin Chen, Jie Zhou, Liang He, Xipeng Qiu</li>
<li>for: 支持个性化、公正、慈善的智能教育，服务教师、学生和家长。</li>
<li>methods: 利用心理学和教育理论，提高教育功能，如开放问答、议论评估、索西里亚教学和情感支持，并通过预训练教育词汇和细化系统指令来学习域特定知识。</li>
<li>results: 已经在线上作为开源项目提供，其代码、数据和模型参数在平台（如GitHub和Hugging Face）上公开，同时准备了其功能示例（<a target="_blank" rel="noopener" href="https://vimeo.com/851004454%EF%BC%89%EF%BC%8C%E6%97%A8%E5%9C%A8%E6%8E%A8%E5%8A%A8LLM%E7%9A%84%E6%95%99%E8%82%B2%E5%BA%94%E7%94%A8%E7%A0%94%E7%A9%B6%E5%92%8C%E5%BA%94%E7%94%A8%E3%80%82">https://vimeo.com/851004454），旨在推动LLM的教育应用研究和应用。</a><details>
<summary>Abstract</summary>
EduChat (https://www.educhat.top/) is a large-scale language model (LLM)-based chatbot system in the education domain. Its goal is to support personalized, fair, and compassionate intelligent education, serving teachers, students, and parents. Guided by theories from psychology and education, it further strengthens educational functions such as open question answering, essay assessment, Socratic teaching, and emotional support based on the existing basic LLMs. Particularly, we learn domain-specific knowledge by pre-training on the educational corpus and stimulate various skills with tool use by fine-tuning on designed system prompts and instructions. Currently, EduChat is available online as an open-source project, with its code, data, and model parameters available on platforms (e.g., GitHub https://github.com/icalk-nlp/EduChat, Hugging Face https://huggingface.co/ecnu-icalk ). We also prepare a demonstration of its capabilities online (https://vimeo.com/851004454). This initiative aims to promote research and applications of LLMs for intelligent education.
</details>
<details>
<summary>摘要</summary>
eduChat（https://www.educhat.top/）是一个基于大规模语言模型（LLM）的教育领域聊天机器人系统。其目标是支持个性化、公正、慈善的智能教育，为教师、学生和家长提供支持。受心理学和教育理论引导，它进一步增强了教育功能，如开放问答、作文评价、索洛尼教学和情感支持，基于现有的基础 LLM。特别是，我们通过预训练教育词汇库来学习域语言知识，并通过细化系统提示和指导来刺激多种技能。目前，eduChat已经在线上开放，可以免费下载和使用（如GitHub https://github.com/icalk-nlp/EduChat、Hugging Face https://huggingface.co/ecnu-icalk）。我们还准备了其功能示例视频（https://vimeo.com/851004454）。这一 iniciative 的目标是推动 LLM 的应用和研究在智能教育领域。
</details></li>
</ul>
<hr>
<h2 id="Meta-Tsallis-Entropy-Minimization-A-New-Self-Training-Approach-for-Domain-Adaptation-on-Text-Classification"><a href="#Meta-Tsallis-Entropy-Minimization-A-New-Self-Training-Approach-for-Domain-Adaptation-on-Text-Classification" class="headerlink" title="Meta-Tsallis-Entropy Minimization: A New Self-Training Approach for Domain Adaptation on Text Classification"></a>Meta-Tsallis-Entropy Minimization: A New Self-Training Approach for Domain Adaptation on Text Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02746">http://arxiv.org/abs/2308.02746</a></li>
<li>repo_url: None</li>
<li>paper_authors: Menglong Lu, Zhen Huang, Zhiliang Tian, Yunxiang Zhao, Xuanyu Fei, Dongsheng Li</li>
<li>for: 这篇论文的目的是提出一种基于自我训练的预测模型适应领域转换方法，以扩展自然语言处理中的文本分类任务。</li>
<li>methods: 这篇论文使用了一种名为Meta-Tsallis Entropy Minimization（MTEM）的meta-学习算法，将预测模型适应到目标领域。此外，还提出了一种简化Second-order derivation的减少计算成本的技术，以及一种热点抽样机制来快速生成 pseudo labels。</li>
<li>results: 实验结果显示，MTEM 可以提高 BERT 预测模型的适应性，平均提高了4%的benchmark数据集上的适应性。<details>
<summary>Abstract</summary>
Text classification is a fundamental task for natural language processing, and adapting text classification models across domains has broad applications. Self-training generates pseudo-examples from the model's predictions and iteratively trains on the pseudo-examples, i.e., minimizes the loss on the source domain and the Gibbs entropy on the target domain. However, Gibbs entropy is sensitive to prediction errors, and thus, self-training tends to fail when the domain shift is large. In this paper, we propose Meta-Tsallis Entropy minimization (MTEM), which applies a meta-learning algorithm to optimize the instance adaptive Tsallis entropy on the target domain. To reduce the computation cost of MTEM, we propose an approximation technique to approximate the Second-order derivation involved in the meta-learning. To efficiently generate pseudo labels, we propose an annealing sampling mechanism for exploring the model's prediction probability. Theoretically, we prove the convergence of the meta-learning algorithm in MTEM and analyze the effectiveness of MTEM in achieving domain adaptation. Experimentally, MTEM improves the adaptation performance of BERT with an average of 4 percent on the benchmark dataset.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="How-Good-Are-SOTA-Fake-News-Detectors"><a href="#How-Good-Are-SOTA-Fake-News-Detectors" class="headerlink" title="How Good Are SOTA Fake News Detectors"></a>How Good Are SOTA Fake News Detectors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02727">http://arxiv.org/abs/2308.02727</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/miceland2/fake_news_detection">https://github.com/miceland2/fake_news_detection</a></li>
<li>paper_authors: Matthew Iceland</li>
<li>for: 本研究旨在评估机器学习模型在假新闻检测中的可靠性，以防止假信息在广泛传播前被检测出来。</li>
<li>methods: 本研究使用了多种传统和深度学习模型，包括Support Vector Machines（SVM）、Random Forest（RF）、Long Short-Term Memory（LSTM）和Transformer等，以评估这些模型在不同任务上的表现。</li>
<li>results: 研究发现，传统模型在数据外部分布上的泛化性比较好，而深度学习模型在特定任务上的表现可能更好，但最佳的模型可能取决于具体的任务。<details>
<summary>Abstract</summary>
Automatic fake news detection with machine learning can prevent the dissemination of false statements before they gain many views. Several datasets labeling statements as legitimate or false have been created since the 2016 United States presidential election for the prospect of training machine learning models. We evaluate the robustness of both traditional and deep state-of-the-art models to gauge how well they may perform in the real world. We find that traditional models tend to generalize better to data outside the distribution it was trained on compared to more recently-developed large language models, though the best model to use may depend on the specific task at hand.
</details>
<details>
<summary>摘要</summary>
自动化假新闻检测使用机器学习可以防止假陈述在得到许多观看之前传播。自2016年美国总统选举以来，已经创建了多个标注声明为真实或假的数据集，用于训练机器学习模型。我们评估了传统和深度状态对的模型Robustness，以评估它们在真实世界中的表现。我们发现传统模型在不同的数据分布外的总体性能比较好，但最佳模型可能取决于具体的任务。Note: "Simplified Chinese" is a romanization of Chinese that uses simpler characters and grammar to facilitate learning and communication. It is not a formal standard, but rather a common informal writing system used in online communication and education.Translation notes:* "Automatic fake news detection" is translated as "自动化假新闻检测" (zìhuì zhìyì xiǎngxìn)* "with machine learning" is translated as "使用机器学习" (shǐyòu jīshù xuéxí)* "can prevent the dissemination of false statements" is translated as "可以防止假陈述的传播" (kěyǐ fángzhì zhēnshuō de chuánxì)* "before they gain many views" is translated as "前于它们得到许多观看" (qián yú tāmen dékuò yīduō guānkàn)* "Several datasets labeling statements as legitimate or false have been created" is translated as "已经创建了多个标注声明为真实或假的数据集" (yǐjīng chéngchǎi le duō gè tiǎnzi xiǎngxìn zhī shí yǔ bìng shí)* "since the 2016 United States presidential election" is translated as "自2016年美国总统选举以来" (zì 2016 nián míguó zǒngtǒng jiǎngdǎo zhīlì)* "for the prospect of training machine learning models" is translated as "用于训练机器学习模型" (yǐng yú xùnxíng jīshù xuéxí módel)* "We evaluate the robustness of both traditional and deep state-of-the-art models" is translated as "我们评估了传统和深度状态对的模型Robustness" (wǒmen píngyì le zhòngyì yǔ shēngrán zhìyì de módel Robustness)* "to gauge how well they may perform in the real world" is translated as "以评估它们在真实世界中的表现" (yǐ píngyì tāmen zhè yì shì jièshí zhìyì de biǎo xiǎng)* "We find that traditional models tend to generalize better to data outside the distribution it was trained on" is translated as "我们发现传统模型在不同的数据分布外的总体性能比较好" (wǒmen fāxìn zhòngyì módel zài bùdàng de xiǎngxì yì shì zhìyì de zǒngtǐ xìngkě)* "though the best model to use may depend on the specific task at hand" is translated as "尽管最佳模型可能取决于具体的任务" (juéyàng zuìjì módel kěnéng qùjué yú gè tâi zhì)
</details></li>
</ul>
<hr>
<h2 id="Forget-Demonstrations-Focus-on-Learning-from-Textual-Instructions"><a href="#Forget-Demonstrations-Focus-on-Learning-from-Textual-Instructions" class="headerlink" title="Forget Demonstrations, Focus on Learning from Textual Instructions"></a>Forget Demonstrations, Focus on Learning from Textual Instructions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.03795">http://arxiv.org/abs/2308.03795</a></li>
<li>repo_url: None</li>
<li>paper_authors: Renze Lou, Wenpeng Yin</li>
<li>for:  Zero-shot cross-task generalization in demonstration-free learning from textual instructions.</li>
<li>methods:  automatically find critical sentences in the definition, and a ranking objective to force the model to generate gold outputs with higher probabilities when those critical parts are highlighted.</li>
<li>results:  state-of-the-art performance on a challenging benchmark.<details>
<summary>Abstract</summary>
This work studies a challenging yet more realistic setting for zero-shot cross-task generalization: demonstration-free learning from textual instructions, presuming the existence of a paragraph-style task definition while no demonstrations exist. To better learn the task supervision from the definition, we propose two strategies: first, to automatically find out the critical sentences in the definition; second, a ranking objective to force the model to generate the gold outputs with higher probabilities when those critical parts are highlighted in the definition. The joint efforts of the two strategies yield state-of-the-art performance on the challenging benchmark. Our code will be released in the final version of the paper.
</details>
<details>
<summary>摘要</summary></li>
</ul>
<ol>
<li>Automatically identifying crucial sentences in the definition.2. A ranking objective to encourage the model to generate the correct outputs with higher probabilities when the critical parts are highlighted in the definition.The combination of these two strategies achieves state-of-the-art performance on a challenging benchmark. Our code will be released with the final version of the paper.</details></li>
</ol>
<hr>
<h2 id="Adapting-the-NICT-JLE-Corpus-for-Disfluency-Detection-Models"><a href="#Adapting-the-NICT-JLE-Corpus-for-Disfluency-Detection-Models" class="headerlink" title="Adapting the NICT-JLE Corpus for Disfluency Detection Models"></a>Adapting the NICT-JLE Corpus for Disfluency Detection Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02482">http://arxiv.org/abs/2308.02482</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lucy Skidmore, Roger K. Moore</li>
<li>for: 本研究的目的是提供一个标准化的训练和评估模型的数据集，用于检测学习者语言表达中的干扰。</li>
<li>methods: 本研究使用了NICT-JLE corpus，并对其进行了适应化，以便用于干扰检测模型的训练和评估。</li>
<li>results: 本研究提供了一个标准化的训练、保留和测试集，可供未来的干扰检测研究使用。I hope that helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
The detection of disfluencies such as hesitations, repetitions and false starts commonly found in speech is a widely studied area of research. With a standardised process for evaluation using the Switchboard Corpus, model performance can be easily compared across approaches. This is not the case for disfluency detection research on learner speech, however, where such datasets have restricted access policies, making comparison and subsequent development of improved models more challenging. To address this issue, this paper describes the adaptation of the NICT-JLE corpus, containing approximately 300 hours of English learners' oral proficiency tests, to a format that is suitable for disfluency detection model training and evaluation. Points of difference between the NICT-JLE and Switchboard corpora are explored, followed by a detailed overview of adaptations to the tag set and meta-features of the NICT-JLE corpus. The result of this work provides a standardised train, heldout and test set for use in future research on disfluency detection for learner speech.
</details>
<details>
<summary>摘要</summary>
研究干扰现象如停顿、重复和开始错误的检测在语音中是广泛的研究领域。使用标准化的评估过程和 Switchboard  Corporare，模型的性能可以方便地比较。但是对于学习者语音干扰检测研究，这些数据集却有限制的访问政策，使得对比和后续模型的改进更加困难。为解决这问题，这篇论文描述了将 NICT-JLE  corpora（约为 300 小时的英语学习者口语考试）改进为适于干扰检测模型训练和评估的格式。本文首先探讨了 NICT-JLE 和 Switchboard  corpora 之间的差异，然后详细介绍了 NICT-JLE  corpora 的标签集和 ме타特征的修改。结果是提供了一个标准化的训练集、保留集和测试集，用于未来learner speech 干扰检测研究。
</details></li>
</ul>
<hr>
<h2 id="Towards-Generalist-Foundation-Model-for-Radiology"><a href="#Towards-Generalist-Foundation-Model-for-Radiology" class="headerlink" title="Towards Generalist Foundation Model for Radiology"></a>Towards Generalist Foundation Model for Radiology</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02463">http://arxiv.org/abs/2308.02463</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chaoyi-wu/radfm">https://github.com/chaoyi-wu/radfm</a></li>
<li>paper_authors: Chaoyi Wu, Xiaoman Zhang, Ya Zhang, Yanfeng Wang, Weidi Xie</li>
<li>for: 这项研究的目的是开发Radiology Foundation Model（RadFM）。</li>
<li>methods: 我们在数据、模型设计和评估方面进行了全面的考虑，并提出了一种架构，可以将文本输入与2D或3D医学扫描图像相互融合，并在多种医学任务上生成响应。模型首先在MedMD大规模医学多modal数据集上进行了预训练，然后在RadMD（医学清洗版MedMD）上进行了域专域精度训练。</li>
<li>results: 我们的实验结果表明，RadFM在处理多种医学问题时表现出色，比既有的多Modal基础模型更高。代码、数据和模型检查点都将公开发布，以便更多人继续研究和开发这一领域。<details>
<summary>Abstract</summary>
In this study, we aim to initiate the development of Radiology Foundation Model, termed as RadFM.We consider the construction of foundational models from the perspectives of data, model design, and evaluation thoroughly. Our contribution can be concluded as follows: (i), we construct a large-scale Medical Multi-modal Dataset, MedMD, consisting of 16M 2D and 3D medical scans. To the best of our knowledge, this is the first multi-modal dataset containing 3D medical scans. (ii), We propose an architecture that enables visually conditioned generative pre-training, allowing for the integration of text input interleaved with 2D or 3D medical scans to generate response for diverse radiologic tasks. The model was initially pre-trained on MedMD and subsequently domain-specific fine-tuned on RadMD, a radiologic cleaned version of MedMD, containing 3M radiologic visual-language pairs. (iii), we propose a new evaluation benchmark that comprises five tasks, aiming to comprehensively assess the capability of foundation models in handling practical clinical problems. Our experimental results confirm that RadFM significantly outperforms existing multi-modal foundation models. The codes, data, and model checkpoint will all be made publicly available to promote further research and development in the field.
</details>
<details>
<summary>摘要</summary>
在本研究中，我们目标是开发Radiology Foundation Model（RadFM）。我们对foundational model的构建进行了全面的考虑，包括数据、模型设计和评估方面。我们的贡献可以结合以下三点：(i) 我们构建了一个大规模的医疗多modal数据集（MedMD），包含1600万个2D和3D医疗扫描图像。到目前为止，这是第一个包含3D医疗扫描图像的多modal数据集。(ii) 我们提出了一种拥有可视条件生成的架构，允许将文本输入与2D或3D医疗扫描图像相互融合，以生成多种医疗任务的回应。该模型首先在MedMD上进行了 pré-training，然后在RadMD上进行了域pecific的精度调整，RadMD包含300万个医疗视语对。(iii) 我们提出了一个新的评估指标，包括五个任务，旨在全面评估基础模型在解决实际临床问题时的能力。我们的实验结果表明，RadFM在多modal基础模型中表现出色，在不同的医疗任务上具有优异的表现。我们将代码、数据和模型检查点一起公开，以便进一步的研究和发展。
</details></li>
</ul>
<hr>
<h2 id="Legal-Summarisation-through-LLMs-The-PRODIGIT-Project"><a href="#Legal-Summarisation-through-LLMs-The-PRODIGIT-Project" class="headerlink" title="Legal Summarisation through LLMs: The PRODIGIT Project"></a>Legal Summarisation through LLMs: The PRODIGIT Project</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04416">http://arxiv.org/abs/2308.04416</a></li>
<li>repo_url: None</li>
<li>paper_authors: Thiago Dal Pont, Federico Galli, Andrea Loreggia, Giuseppe Pisano, Riccardo Rovatti, Giovanni Sartor</li>
<li>for: 本研究旨在支持税务法官和律师通过数字技术，特点是使用人工智能（AI）。</li>
<li>methods: 本研究使用了不同的工具和方法来进行抽取和概要生成，包括语言模型（LLMs）和GPT4。</li>
<li>results: 根据专业税务法官和律师的评价，研究所得到的结果得到了满意的评价。在此基础之上，正在建立一个protoype应用程序，将在公共领域中公布。<details>
<summary>Abstract</summary>
We present some initial results of a large-scale Italian project called PRODIGIT which aims to support tax judges and lawyers through digital technology, focusing on AI. We have focused on generation of summaries of judicial decisions and on the extraction of related information, such as the identification of legal issues and decision-making criteria, and the specification of keywords. To this end, we have deployed and evaluated different tools and approaches to extractive and abstractive summarisation. We have applied LLMs, and particularly on GPT4, which has enabled us to obtain results that proved satisfactory, according to an evaluation by expert tax judges and lawyers. On this basis, a prototype application is being built which will be made publicly available.
</details>
<details>
<summary>摘要</summary>
我们现在宣布一些初步结果的大规模意大利项目，名为PRODIGIT，旨在通过数字技术支持税务法官和律师，重点是人工智能。我们对判决摘要生成和相关信息提取进行了重点尝试，包括法律问题识别和决策标准的特定，以及关键词的指定。为此，我们已经部署和评估了不同的工具和方法，包括自然语言处理技术和GPT4。经专业税务法官和律师评估，我们的结果得到了满意的评价。基于这个基础，我们正在建立一个原型应用程序，计划将其公开发布。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/08/05/cs.CL_2023_08_05/" data-id="clp89doa9009ri7887sn1dw5j" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/72/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/71/">71</a><a class="page-number" href="/page/72/">72</a><span class="page-number current">73</span><a class="page-number" href="/page/74/">74</a><a class="page-number" href="/page/75/">75</a><span class="space">&hellip;</span><a class="page-number" href="/page/97/">97</a><a class="extend next" rel="next" href="/page/74/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">141</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">128</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">66</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">127</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-SP/">eess.SP</a><span class="category-list-count">81</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/11/">November 2023</a><span class="archive-list-count">140</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">231</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">212</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">175</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">208</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
