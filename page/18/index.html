
<!DOCTYPE html>
<html>
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
  
  <title>Fun Paper</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="Fun Paper">
<meta property="og:url" content="https://nullscc.github.io/page/18/index.html">
<meta property="og:site_name" content="Fun Paper">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="nullscc">
<meta name="twitter:card" content="summary">
  
  
  
<link rel="stylesheet" href="/css/style.css">

  
    <link href="//fonts.useso.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <!--[if lt IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7/html5shiv.min.js"></script><![endif]-->
  
  

<meta name="generator" content="Hexo 6.3.0"></head>

<body>
<div id="container">
  <div id="wrap">
    <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <nav id="upper-nav" class="inner">
      <a id="main-nav-toggle" class="nav-icon"></a>
      <div class="sub-nav">
        
        
          <a id="nav-github" class="nav-icon" target="_blank" rel="noopener" href="https://github.com/nullscc"></a>
        
      </div>
    </nav>
    <div id="header-title">
      
        <h1 id="blog-title-wrap">
          <a href="/" id="blog-title">Fun Paper</a>
        </h1>
      
    </div>
    <div id="contenedor">
      <ul class="cube">
        <li class="cara">Paper</li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
        <li class="cara"></li>
      </ul>
    </div>
    <nav id="main-nav">
      
        <a class="main-nav-link" href="/">Home</a>
      
        <a class="main-nav-link" href="/archives">Archives</a>
      
    </nav>
  </div>
</header>

    <div class="outer">
      <section id="main">
  
    <article id="post-cs.CV_2023_07_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/16/cs.CV_2023_07_16/" class="article-date">
  <time datetime="2023-07-15T16:00:00.000Z" itemprop="datePublished">2023-07-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/16/cs.CV_2023_07_16/">cs.CV - 2023-07-16 21:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Diffusion-to-Confusion-Naturalistic-Adversarial-Patch-Generation-Based-on-Diffusion-Model-for-Object-Detector"><a href="#Diffusion-to-Confusion-Naturalistic-Adversarial-Patch-Generation-Based-on-Diffusion-Model-for-Object-Detector" class="headerlink" title="Diffusion to Confusion: Naturalistic Adversarial Patch Generation Based on Diffusion Model for Object Detector"></a>Diffusion to Confusion: Naturalistic Adversarial Patch Generation Based on Diffusion Model for Object Detector</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08076">http://arxiv.org/abs/2307.08076</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shuo-Yen Lin, Ernie Chu, Che-Hsien Lin, Jun-Cheng Chen, Jia-Ching Wang</li>
<li>For: The paper aims to address the issue of poor-quality physical adversarial patches for protecting personal privacy from malicious monitoring using object detectors.* Methods: The proposed method uses diffusion models (DM) to generate naturalistic adversarial patches that are high-quality and stable, without suffering from mode collapse problems.* Results: The proposed approach achieves better-quality and more naturalistic adversarial patches than other state-of-the-art patch generation methods, with acceptable attack performance and various generation trade-offs under different conditions.Here are the three points in Simplified Chinese text:* For: 本文目标是解决对象检测器的恶意监测中的个人隐私泄露问题，通过生成高质量的物理攻击质 patches。* Methods: 提议方法基于扩散模型（DM），通过采样预训练于自然图像的DM模型，可以稳定地生成高质量和自然的物理攻击质 patches。* Results: 对比其他状态公共的攻击质 patch生成方法，提议方法可以实现更好的攻击性和质量，同时提供不同条件下的生成质量负担。<details>
<summary>Abstract</summary>
Many physical adversarial patch generation methods are widely proposed to protect personal privacy from malicious monitoring using object detectors. However, they usually fail to generate satisfactory patch images in terms of both stealthiness and attack performance without making huge efforts on careful hyperparameter tuning. To address this issue, we propose a novel naturalistic adversarial patch generation method based on the diffusion models (DM). Through sampling the optimal image from the DM model pretrained upon natural images, it allows us to stably craft high-quality and naturalistic physical adversarial patches to humans without suffering from serious mode collapse problems as other deep generative models. To the best of our knowledge, we are the first to propose DM-based naturalistic adversarial patch generation for object detectors. With extensive quantitative, qualitative, and subjective experiments, the results demonstrate the effectiveness of the proposed approach to generate better-quality and more naturalistic adversarial patches while achieving acceptable attack performance than other state-of-the-art patch generation methods. We also show various generation trade-offs under different conditions.
</details>
<details>
<summary>摘要</summary>
多种物理抗击方法已经广泛提出来保护个人隐私免受恶势力监测器的攻击。然而，这些方法通常无法生成满意的质量的抗击图像，而且需要大量的优化参数调整，以达到良好的攻击性和隐蔽性。为解决这个问题，我们提出了一种新的自然化抗击方法，基于扩散模型（DM）。通过从DM模型预训练于自然图像中采样最佳图像，我们可以稳定地生成高质量和自然化的物理抗击图像，而不会受到深度生成模型的严重混合问题的影响。我们认为我们是第一个提出DM模型基于的自然化抗击图像生成方法。通过了广泛的量化、质量和主观实验，我们的方法可以生成更高质量和更自然化的抗击图像，同时保持可接受的攻击性。我们还展示了不同条件下的生成质量的交易。
</details></li>
</ul>
<hr>
<h2 id="Dense-Multitask-Learning-to-Reconfigure-Comics"><a href="#Dense-Multitask-Learning-to-Reconfigure-Comics" class="headerlink" title="Dense Multitask Learning to Reconfigure Comics"></a>Dense Multitask Learning to Reconfigure Comics</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08071">http://arxiv.org/abs/2307.08071</a></li>
<li>repo_url: None</li>
<li>paper_authors: Deblina Bhattacharjee, Sabine Süsstrunk, Mathieu Salzmann</li>
<li>for: 这paper的目的是开发一种多任务学习（MTL）模型，以实现漫画幕anel的精度预测，以便将漫画从一个发布频道传输到另一个。</li>
<li>methods: 我们使用了一种常见的策略，即无监督图像到图像翻译，以利用大量的真实世界约束。我们还利用了这些翻译结果，开发了一种基于视力变换器底层和域转移注意模块的多任务方法。</li>
<li>results: 我们的MTL方法可以成功地标识漫画幕anel中的Semantic单元以及嵌入的3D notion。这是一个非常具有挑战性的问题，因为漫画包含了不同的艺术风格、插图、布局和 объек scale，这些因素取决于作者的创作过程。<details>
<summary>Abstract</summary>
In this paper, we develop a MultiTask Learning (MTL) model to achieve dense predictions for comics panels to, in turn, facilitate the transfer of comics from one publication channel to another by assisting authors in the task of reconfiguring their narratives. Our MTL method can successfully identify the semantic units as well as the embedded notion of 3D in comic panels. This is a significantly challenging problem because comics comprise disparate artistic styles, illustrations, layouts, and object scales that depend on the authors creative process. Typically, dense image-based prediction techniques require a large corpus of data. Finding an automated solution for dense prediction in the comics domain, therefore, becomes more difficult with the lack of ground-truth dense annotations for the comics images. To address these challenges, we develop the following solutions: 1) we leverage a commonly-used strategy known as unsupervised image-to-image translation, which allows us to utilize a large corpus of real-world annotations; 2) we utilize the results of the translations to develop our multitasking approach that is based on a vision transformer backbone and a domain transferable attention module; 3) we study the feasibility of integrating our MTL dense-prediction method with an existing retargeting method, thereby reconfiguring comics.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们开发了一种多任务学习（MTL）模型，以实现漫画panel的密集预测，以便将漫画从一个发布渠道传输到另一个渠道，并 помочь作者重新配置他们的故事。我们的MTL方法可以成功地标识漫画中的语义单元以及嵌入的3D notion。这是一个非常具有挑战性的问题，因为漫画包含了不同的艺术风格、插图、布局和对象比例，这些因素取决于作者的创作过程。通常，密集图像基于预测技术需要很大的数据库。因此，在漫画领域找到自动化密集预测的解决方案变得更加困难，因为漫画图像的密集批注缺乏。为 Addressing these challenges, we develop the following solutions:1. 我们利用一种通常使用的策略，即无监督图像到图像翻译，以使用大量的实际世界约束。2. 我们利用翻译结果来开发我们的多任务方法，该方法基于视Transformer底层和域传递注意模块。3. 我们研究将我们的MTL密集预测方法与现有的重定向方法集成，以重新配置漫画。
</details></li>
</ul>
<hr>
<h2 id="MaGNAS-A-Mapping-Aware-Graph-Neural-Architecture-Search-Framework-for-Heterogeneous-MPSoC-Deployment"><a href="#MaGNAS-A-Mapping-Aware-Graph-Neural-Architecture-Search-Framework-for-Heterogeneous-MPSoC-Deployment" class="headerlink" title="MaGNAS: A Mapping-Aware Graph Neural Architecture Search Framework for Heterogeneous MPSoC Deployment"></a>MaGNAS: A Mapping-Aware Graph Neural Architecture Search Framework for Heterogeneous MPSoC Deployment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08065">http://arxiv.org/abs/2307.08065</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohanad Odema, Halima Bouzidi, Hamza Ouarnoughi, Smail Niar, Mohammad Abdullah Al Faruque</li>
<li>For: The paper is written for vision-based applications that require efficient processing on heterogeneous MPSoC platforms.* Methods: The paper proposes a novel unified design-mapping approach for efficient processing of vision GNN workloads on heterogeneous MPSoC platforms, including a mapping-aware Graph Neural Architecture Search (MaGNAS) framework.* Results: The proposed MaGNAS framework achieves 1.57x latency speedup and is 3.38x more energy-efficient for several vision datasets executed on the Xavier MPSoC platform compared to the GPU-only deployment, while sustaining an average 0.11% accuracy reduction from the baseline.Here’s the simplified Chinese text for the three information points:* For: 这篇论文是为视觉应用程序设计的，需要高效地运行在多核心处理器系统（MPSoC）上。* Methods: 论文提出了一种新的统一设计映射方法，用于高效地处理视觉Graph Neural Networks（GNN）任务在多核心MPSoC平台上。* Results: 提出的MaGNAS框架在Xavier MPSoC上实现了1.57倍的延迟速度提升和3.38倍的能效率提升，而且与基线相比减少了0.11%的准确率。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) are becoming increasingly popular for vision-based applications due to their intrinsic capacity in modeling structural and contextual relations between various parts of an image frame. On another front, the rising popularity of deep vision-based applications at the edge has been facilitated by the recent advancements in heterogeneous multi-processor Systems on Chips (MPSoCs) that enable inference under real-time, stringent execution requirements. By extension, GNNs employed for vision-based applications must adhere to the same execution requirements. Yet contrary to typical deep neural networks, the irregular flow of graph learning operations poses a challenge to running GNNs on such heterogeneous MPSoC platforms. In this paper, we propose a novel unified design-mapping approach for efficient processing of vision GNN workloads on heterogeneous MPSoC platforms. Particularly, we develop MaGNAS, a mapping-aware Graph Neural Architecture Search framework. MaGNAS proposes a GNN architectural design space coupled with prospective mapping options on a heterogeneous SoC to identify model architectures that maximize on-device resource efficiency. To achieve this, MaGNAS employs a two-tier evolutionary search to identify optimal GNNs and mapping pairings that yield the best performance trade-offs. Through designing a supernet derived from the recent Vision GNN (ViG) architecture, we conducted experiments on four (04) state-of-the-art vision datasets using both (i) a real hardware SoC platform (NVIDIA Xavier AGX) and (ii) a performance/cost model simulator for DNN accelerators. Our experimental results demonstrate that MaGNAS is able to provide 1.57x latency speedup and is 3.38x more energy-efficient for several vision datasets executed on the Xavier MPSoC vs. the GPU-only deployment while sustaining an average 0.11% accuracy reduction from the baseline.
</details>
<details>
<summary>摘要</summary>
图 neural network (GNN) 在视觉应用中变得越来越受欢迎，这是因为它们内置了图结构和上下文关系 между图像帧中不同部分的能力。同时，由于近期增加的深度视觉应用在边缘进行执行，因此GNN也必须遵循同样的执行要求。然而，与 Typical deep neural networks不同，图学习操作的不规则流动使得在多核心处理器系统（MPSoC）平台上运行GNN变得更加挑战。在这篇论文中，我们提出了一种新的统一设计映射方法，以便高效地处理视觉GNN工作负荷在多核心处理器平台上。具体来说，我们开发了 MaGNAS，一个具有映射意识的图 neural architecture search框架。MaGNAS提出了一个图 neural 架构设计空间，并与多核心 SoC 上的可能的映射选择相结合，以便确定最佳的GNN模型，以最大化设备资源利用。为达到这一目标，MaGNAS使用了两层演化搜索，以确定最佳的GNN和映射对。通过基于最近的视觉 GNN（ViG）架构的超网，我们进行了在四个（04） state-of-the-art 视觉 dataset 上的实验，使用了 both (i) 真实硬件 SoC 平台（NVIDIA Xavier AGX）和 (ii) 性能/成本模型适用于 DNN 加速器的表现/成本模拟器。我们的实验结果表明，MaGNAS 能够提供 1.57 倍的延迟速度提升和 3.38 倍的能效性提升，而在 Xavier MPSoC 上执行多个视觉dataset 时与 GPU-only 部署相比，保持了平均 0.11% 的准确性下降。
</details></li>
</ul>
<hr>
<h2 id="LafitE-Latent-Diffusion-Model-with-Feature-Editing-for-Unsupervised-Multi-class-Anomaly-Detection"><a href="#LafitE-Latent-Diffusion-Model-with-Feature-Editing-for-Unsupervised-Multi-class-Anomaly-Detection" class="headerlink" title="LafitE: Latent Diffusion Model with Feature Editing for Unsupervised Multi-class Anomaly Detection"></a>LafitE: Latent Diffusion Model with Feature Editing for Unsupervised Multi-class Anomaly Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08059">http://arxiv.org/abs/2307.08059</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haonan Yin, Guanlong Jiao, Qianhui Wu, Borje F. Karlsson, Biqing Huang, Chin Yew Lin</li>
<li>for: 本研究旨在为flexible manufacturing systems提供一种不需要监督的多类异常检测方法，能够在只有正常数据可用时检测到对象属于多个类型的异常。</li>
<li>methods: 本研究使用生成器基于方法，包括潜在扩散模型 для重建，以解决泛化难点’’问题，以及特征编辑策略来进一步缓解’’标识短ircuit’’问题。</li>
<li>results: 对MVTec-AD和MPDD数据集进行了广泛的实验，显示提出的LafitE方法在average AUROC指标上与现有方法相比，具有显著的优势。同时，通过我们提出的pseudo验证集来选择适合实际测试集的超参数。<details>
<summary>Abstract</summary>
In the context of flexible manufacturing systems that are required to produce different types and quantities of products with minimal reconfiguration, this paper addresses the problem of unsupervised multi-class anomaly detection: develop a unified model to detect anomalies from objects belonging to multiple classes when only normal data is accessible. We first explore the generative-based approach and investigate latent diffusion models for reconstruction to mitigate the notorious ``identity shortcut'' issue in auto-encoder based methods. We then introduce a feature editing strategy that modifies the input feature space of the diffusion model to further alleviate ``identity shortcuts'' and meanwhile improve the reconstruction quality of normal regions, leading to fewer false positive predictions. Moreover, we are the first who pose the problem of hyperparameter selection in unsupervised anomaly detection, and propose a solution of synthesizing anomaly data for a pseudo validation set to address this problem. Extensive experiments on benchmark datasets MVTec-AD and MPDD show that the proposed LafitE, \ie, Latent Diffusion Model with Feature Editing, outperforms state-of-art methods by a significant margin in terms of average AUROC. The hyperparamters selected via our pseudo validation set are well-matched to the real test set.
</details>
<details>
<summary>摘要</summary>
在需要生产不同类型和量的产品时，这篇论文解决了无监督多类异常检测的问题：开发一个综合模型，可以从多个类型的对象中检测异常。我们首先探讨了生成器基本的方法，并调查了抽象扩散模型来解决拥有短circuit''问题，这是抽象扩散模型基于方法的一个常见问题。然后，我们引入了特征编辑策略，将输入特征空间中的特征进行修改，以更好地降低异常点的检测难度，同时提高正常区域的重建质量，从而减少假阳性预测。此外，我们是第一个提出了无监督异常检测中参数选择的问题，并提出了一种使用生成异常数据来 Pseudo 验证集来解决这个问题。我们的LafitE（即潜在扩散模型与特征编辑）在 MPDD 和 MVTec-AD 测试集上进行了广泛的实验，结果表明，它在 average AUROC 方面与状态机器人在前方的方法相比，具有显著的优势。而我们选择的参数via Pseudo 验证集和实际测试集之间的匹配性也很高。
</details></li>
</ul>
<hr>
<h2 id="TransNuSeg-A-Lightweight-Multi-Task-Transformer-for-Nuclei-Segmentation"><a href="#TransNuSeg-A-Lightweight-Multi-Task-Transformer-for-Nuclei-Segmentation" class="headerlink" title="TransNuSeg: A Lightweight Multi-Task Transformer for Nuclei Segmentation"></a>TransNuSeg: A Lightweight Multi-Task Transformer for Nuclei Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08051">http://arxiv.org/abs/2307.08051</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhenqi-he/transnuseg">https://github.com/zhenqi-he/transnuseg</a></li>
<li>paper_authors: Zhenqi He, Mathias Unberath, Jing Ke, Yiqing Shen<br>for:这篇论文的目的是提出一种基于Transformer的自动核体分割方法，以提高核体分割的准确性和效率。methods:这篇论文使用了一种新的多任务学习策略，将核体分割任务分解成三个子任务：核体实例分割、核体边沿分割和分割边缘集成。此外，它还使用了一种新的自适应共享机制，以便在不同分支之间共享自适应 heads。results:这篇论文的实验结果表明，使用这种方法可以在两个不同的数据集上，与CA2.5-Net等其他状态对抗方法相比，提高核体分割的精度。此外，这种方法还可以降低模型的参数量，从而提高计算效率。<details>
<summary>Abstract</summary>
Nuclei appear small in size, yet, in real clinical practice, the global spatial information and correlation of the color or brightness contrast between nuclei and background, have been considered a crucial component for accurate nuclei segmentation. However, the field of automatic nuclei segmentation is dominated by Convolutional Neural Networks (CNNs), meanwhile, the potential of the recently prevalent Transformers has not been fully explored, which is powerful in capturing local-global correlations. To this end, we make the first attempt at a pure Transformer framework for nuclei segmentation, called TransNuSeg. Different from prior work, we decouple the challenging nuclei segmentation task into an intrinsic multi-task learning task, where a tri-decoder structure is employed for nuclei instance, nuclei edge, and clustered edge segmentation respectively. To eliminate the divergent predictions from different branches in previous work, a novel self distillation loss is introduced to explicitly impose consistency regulation between branches. Moreover, to formulate the high correlation between branches and also reduce the number of parameters, an efficient attention sharing scheme is proposed by partially sharing the self-attention heads amongst the tri-decoders. Finally, a token MLP bottleneck replaces the over-parameterized Transformer bottleneck for a further reduction in model complexity. Experiments on two datasets of different modalities, including MoNuSeg have shown that our methods can outperform state-of-the-art counterparts such as CA2.5-Net by 2-3% Dice with 30% fewer parameters. In conclusion, TransNuSeg confirms the strength of Transformer in the context of nuclei segmentation, which thus can serve as an efficient solution for real clinical practice. Code is available at https://github.com/zhenqi-he/transnuseg.
</details>
<details>
<summary>摘要</summary>
核体在实际临床应用中显示为小型，但是在实际临床实践中，全局空间信息和背景颜色或亮度差异的 corrélation，被视为精确的核体分割的关键组成部分。然而，自动核体分割领域被 CNN 所主导，而 transformer 的潜在力量尚未得到完全利用，这是拥有地方-全局 corrélation 的强大能力。为此，我们首次提出了一个纯 transformer 框架 для核体分割，称为 TransNuSeg。与先前的工作不同，我们将核体分割任务分解为内生多任务学习任务，其中使用 tri-decoder 结构进行核体实例、核体边和分割的聚合edge 分割。为了消除不同分支的不同预测，我们引入了一种新的自我抽象损失，以直接强制不同分支之间的一致性规则。此外，我们还提出了一种高效的注意力共享方案，通过共享部分自动注意力头来降低模型参数数量。最后，我们将各自MLP 瓶颈替换为更加简单的 токен MLP 瓶颈，以进一步降低模型复杂性。在两个不同模式的数据集上进行了实验，包括 MoNuSeg，我们的方法可以与状态态-of-the-art 对手 CA2.5-Net 相比，提高 Dice 指标2-3%，同时减少参数数量30%。结论：TransNuSeg 证明了 transformer 在核体分割领域的力量，可以作为实际临床应用的高效解决方案。代码可以在 <https://github.com/zhenqi-he/transnuseg> 上获取。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-SLCA-UNet-Architecture-for-Automatic-MRI-Brain-Tumor-Segmentation"><a href="#A-Novel-SLCA-UNet-Architecture-for-Automatic-MRI-Brain-Tumor-Segmentation" class="headerlink" title="A Novel SLCA-UNet Architecture for Automatic MRI Brain Tumor Segmentation"></a>A Novel SLCA-UNet Architecture for Automatic MRI Brain Tumor Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08048">http://arxiv.org/abs/2307.08048</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tejashwini P S, Thriveni J, Venugopal K R<br>for: 这个论文主要针对的是如何通过深度学习来自动化脑肿图像分类和识别。methods: 该论文提出了一种基于UNet架构的修改方法，即SLCA UNet方法，该方法包括循环感知层、Channel Attention层和堆叠卷积层等模块，能够有效地捕捉脑肿图像中的细节和概念信息。results: 该论文在使用BraTS数据集进行测试时，实现了良好的性能，其中Dice指标、敏感度、特异度和 Hausdorff95指标分别为0.845、0.845、0.999和8.1。<details>
<summary>Abstract</summary>
Brain tumor is deliberated as one of the severe health complications which lead to decrease in life expectancy of the individuals and is also considered as a prominent cause of mortality worldwide. Therefore, timely detection and prediction of brain tumors can be helpful to prevent death rates due to brain tumors. Biomedical image analysis is a widely known solution to diagnose brain tumor. Although MRI is the current standard method for imaging tumors, its clinical usefulness is constrained by the requirement of manual segmentation which is time-consuming. Deep learning-based approaches have emerged as a promising solution to develop automated biomedical image exploration tools and the UNet architecture is commonly used for segmentation. However, the traditional UNet has limitations in terms of complexity, training, accuracy, and contextual information processing. As a result, the modified UNet architecture, which incorporates residual dense blocks, layered attention, and channel attention modules, in addition to stacked convolution, can effectively capture both coarse and fine feature information. The proposed SLCA UNet approach achieves good performance on the freely accessible Brain Tumor Segmentation (BraTS) dataset, with an average performance of 0.845, 0.845, 0.999, and 8.1 in terms of Dice, Sensitivity, Specificity, and Hausdorff95 for BraTS 2020 dataset, respectively.
</details>
<details>
<summary>摘要</summary>
脑肿是一种严重的健康问题，可能导致个体寿命减少，并被视为全球致死原因之一。因此，在时间上掌握和预测脑肿的技术是非常重要的。生物医学影像分析是一种广泛应用的解决方案，用于诊断脑肿。虽然MRI是当前标准的肿体影像方法，但其临床实用性受到手动分 segmentation 的限制，这是时间consuming 的。基于深度学习的方法在诊断方面出现了一种可能的解决方案，其中 UNet 架构是最常用的。然而，传统的 UNet 有许多局限性，包括复杂度、训练、准确率和上下文信息处理等方面。因此，基于 SLCA UNet 架构，通过添加径 residual dense blocks、层 attention 和通道 attention 模块，可以更好地捕捉肿体中粗细特征信息。提出的 SLCA UNet 方法在可以获得 BraTS 2020 数据集的自由访问Brain Tumor Segmentation（BraTS）数据集上的良好性能，其中的平均性能为0.845、0.845、0.999和8.1。
</details></li>
</ul>
<hr>
<h2 id="Planting-a-SEED-of-Vision-in-Large-Language-Model"><a href="#Planting-a-SEED-of-Vision-in-Large-Language-Model" class="headerlink" title="Planting a SEED of Vision in Large Language Model"></a>Planting a SEED of Vision in Large Language Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08041">http://arxiv.org/abs/2307.08041</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ailab-cvc/seed">https://github.com/ailab-cvc/seed</a></li>
<li>paper_authors: Yuying Ge, Yixiao Ge, Ziyun Zeng, Xintao Wang, Ying Shan</li>
<li>for: 这个论文是为了提供一种能让语言模型同时看图和画图的图像tokenizer。</li>
<li>methods: 这个论文使用了一种新的图像tokenizer architecture，它使用了一个1D causal dependency来生成图像token，并且通过在tokenizer训练阶段进行优化来使图像token capture高级别 semantics。</li>
<li>results: 通过使用这种新的图像tokenizer，LLM可以通过简单的LoRA tuning来实现图像-文本和文本-图像生成。这个论文在5.7天内使用64个V100 GPU和500万个公共可用的图像-文本对对其进行训练。<details>
<summary>Abstract</summary>
We present SEED, an elaborate image tokenizer that empowers Large Language Models (LLMs) with the emergent ability to SEE and Draw at the same time. Research on image tokenizers has previously reached an impasse, as frameworks employing quantized visual tokens have lost prominence due to subpar performance and convergence in multimodal comprehension (compared to BLIP-2, etc.) or generation (compared to Stable Diffusion, etc.). Despite the limitations, we remain confident in its natural capacity to unify visual and textual representations, facilitating scalable multimodal training with LLM's original recipe. In this study, we identify two crucial principles for the architecture and training of SEED that effectively ease subsequent alignment with LLMs. (1) Image tokens should be independent of 2D physical patch positions and instead be produced with a 1D causal dependency, exhibiting intrinsic interdependence that aligns with the left-to-right autoregressive prediction mechanism in LLMs. (2) Image tokens should capture high-level semantics consistent with the degree of semantic abstraction in words, and be optimized for both discriminativeness and reconstruction during the tokenizer training phase. As a result, the off-the-shelf LLM is able to perform both image-to-text and text-to-image generation by incorporating our SEED through efficient LoRA tuning. Comprehensive multimodal pretraining and instruction tuning, which may yield improved results, are reserved for future investigation. This version of SEED was trained in 5.7 days using only 64 V100 GPUs and 5M publicly available image-text pairs. Our preliminary study emphasizes the great potential of discrete visual tokens in versatile multimodal LLMs and the importance of proper image tokenizers in broader research.
</details>
<details>
<summary>摘要</summary>
我们介绍SEED，一个复杂的图像tokenizer，允许大型语言模型（LLM）同时“看”和“绘”。过去的研究图像tokenizer已经到了僵对，因为使用量化的视觉token导致了与BLIP-2等模型的比较不利，以及生成模型的比较不利（比如Stable Diffusion等）。尽管有限制，我们仍然信任它的自然能力，将vision和textual表现结合起来，实现标准多模式训练， LLM 的原始配方。在这个研究中，我们确定了两个重要的建筑和训练SEED的原则，以确保其与LLM的配合。1. 图像token应该与2D物理 patch 位置无关，而是通过1D causal dependency 生成，这样的自然依赖性与 LLM 的左往右预测机制相关。2. 图像token应该捕捉高度抽象的 semantics，与 слова的Semantic abstraction 相关，并在 tokenizer 训练阶段进行优化。因此，通过我们的SEED，标准 LLM 可以进行图像-文本和文本-图像生成，只需要通过LoRA调整。未来的多模式预训和指令调整可能会带来更好的结果。我们在5.7天内使用64个V100 GPU和500万个公开可用的图像-文本对给SEED进行训练。我们的初步研究显示，可以使用精确的图像tokenizer来实现多模式LLM的实用性和多元性。
</details></li>
</ul>
<hr>
<h2 id="Multi-Object-Discovery-by-Low-Dimensional-Object-Motion"><a href="#Multi-Object-Discovery-by-Low-Dimensional-Object-Motion" class="headerlink" title="Multi-Object Discovery by Low-Dimensional Object Motion"></a>Multi-Object Discovery by Low-Dimensional Object Motion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08027">http://arxiv.org/abs/2307.08027</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sadrasafa/multi-object-segmentation">https://github.com/sadrasafa/multi-object-segmentation</a></li>
<li>paper_authors: Sadra Safadoust, Fatma Güney</li>
<li>for: 该研究旨在提高单图像中的动态 reconstruction，即使无法获取下一帧图像。</li>
<li>methods: 该研究使用了像素级几何和物体运动来解除单图像中的流动ambiguity。</li>
<li>results: 该研究在 sintetic和实际 datasets上达到了state-of-the-art的多物体分 segmentation结果，并且对预测深度图表现了可靠的性能。<details>
<summary>Abstract</summary>
Recent work in unsupervised multi-object segmentation shows impressive results by predicting motion from a single image despite the inherent ambiguity in predicting motion without the next image. On the other hand, the set of possible motions for an image can be constrained to a low-dimensional space by considering the scene structure and moving objects in it. We propose to model pixel-wise geometry and object motion to remove ambiguity in reconstructing flow from a single image. Specifically, we divide the image into coherently moving regions and use depth to construct flow bases that best explain the observed flow in each region. We achieve state-of-the-art results in unsupervised multi-object segmentation on synthetic and real-world datasets by modeling the scene structure and object motion. Our evaluation of the predicted depth maps shows reliable performance in monocular depth estimation.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Analysing-Gender-Bias-in-Text-to-Image-Models-using-Object-Detection"><a href="#Analysing-Gender-Bias-in-Text-to-Image-Models-using-Object-Detection" class="headerlink" title="Analysing Gender Bias in Text-to-Image Models using Object Detection"></a>Analysing Gender Bias in Text-to-Image Models using Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08025">http://arxiv.org/abs/2307.08025</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/harveymannering/text-to-image-bias">https://github.com/harveymannering/text-to-image-bias</a></li>
<li>paper_authors: Harvey Mannering</li>
<li>for: 该研究目的是测试文本到图像模型中的偏见。</li>
<li>methods: 该研究使用了对应的提示，例如“一个男人&#x2F;女人持有一个物品”，以检查某些物品是否与certain gender相关。</li>
<li>results: 分析结果显示， masculine prompts 更 frequently generate了如锦标、剑、车、棒棒球和自行车等物品，而 feminine prompts 更 frequently generate了如手提包、雨伞、碗、瓶子和杯子等物品。<details>
<summary>Abstract</summary>
This work presents a novel strategy to measure bias in text-to-image models. Using paired prompts that specify gender and vaguely reference an object (e.g. "a man/woman holding an item") we can examine whether certain objects are associated with a certain gender. In analysing results from Stable Diffusion, we observed that male prompts generated objects such as ties, knives, trucks, baseball bats, and bicycles more frequently. On the other hand, female prompts were more likely to generate objects such as handbags, umbrellas, bowls, bottles, and cups. We hope that the method outlined here will be a useful tool for examining bias in text-to-image models.
</details>
<details>
<summary>摘要</summary>
Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Boosting-3-DoF-Ground-to-Satellite-Camera-Localization-Accuracy-via-Geometry-Guided-Cross-View-Transformer"><a href="#Boosting-3-DoF-Ground-to-Satellite-Camera-Localization-Accuracy-via-Geometry-Guided-Cross-View-Transformer" class="headerlink" title="Boosting 3-DoF Ground-to-Satellite Camera Localization Accuracy via Geometry-Guided Cross-View Transformer"></a>Boosting 3-DoF Ground-to-Satellite Camera Localization Accuracy via Geometry-Guided Cross-View Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08015">http://arxiv.org/abs/2307.08015</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yujiao Shi, Fei Wu, Akhil Perincherry, Ankit Vora, Hongdong Li</li>
<li>for: 提高Camera pose estimation的精度，尤其是在具有有限样本密度的卫星图像库中。</li>
<li>methods: 我们提出了一种方法，通过估算地面图像和卫星图像之间的相对旋转和翻译来提高地面摄像机的位置和方向估计的准确性。我们的方法包括：(1) 使用geometry-guided cross-view transformer来将地面视图转换为飞行视图；(2) 使用神经网络pose optimizer来估计卫星图像和地面图像之间的相对旋转；(3) 使用uncertainty-guided spatial correlation来生成可能性图中的车辆位置。</li>
<li>results: 我们的方法在cross-view KITTI dataset上实验表明，与state-of-the-art方法相比，具有显著的改进。特别是，限制车辆 lateral pose 在1m内的概率从35.54%提高到76.44%，限制车辆 orientation 在1°内的概率从19.64%提高到99.10%。<details>
<summary>Abstract</summary>
Image retrieval-based cross-view localization methods often lead to very coarse camera pose estimation, due to the limited sampling density of the database satellite images. In this paper, we propose a method to increase the accuracy of a ground camera's location and orientation by estimating the relative rotation and translation between the ground-level image and its matched/retrieved satellite image. Our approach designs a geometry-guided cross-view transformer that combines the benefits of conventional geometry and learnable cross-view transformers to map the ground-view observations to an overhead view. Given the synthesized overhead view and observed satellite feature maps, we construct a neural pose optimizer with strong global information embedding ability to estimate the relative rotation between them. After aligning their rotations, we develop an uncertainty-guided spatial correlation to generate a probability map of the vehicle locations, from which the relative translation can be determined. Experimental results demonstrate that our method significantly outperforms the state-of-the-art. Notably, the likelihood of restricting the vehicle lateral pose to be within 1m of its Ground Truth (GT) value on the cross-view KITTI dataset has been improved from $35.54\%$ to $76.44\%$, and the likelihood of restricting the vehicle orientation to be within $1^{\circ}$ of its GT value has been improved from $19.64\%$ to $99.10\%$.
</details>
<details>
<summary>摘要</summary>
Image Retrieval-based Cross-view Localization Methods Often Lead to Very Coarse Camera Pose Estimation, Due to the Limited Sampling Density of the Database Satellite Images. In This Paper, We Propose a Method to Increase the Accuracy of a Ground Camera's Location and Orientation by Estimating the Relative Rotation and Translation Between the Ground-level Image and Its Matched/retrieved Satellite Image. Our Approach Designs a Geometry-guided Cross-view Transformer That Combines the Benefits of Conventional Geometry and Learnable Cross-view Transformers to Map the Ground-view Observations to an Overhead View. Given the Synthesized Overhead View and Observed Satellite Feature Maps, We Construct a Neural Pose Optimizer with Strong Global Information Embedding Ability to Estimate the Relative Rotation Between Them. After Aligning Their Rotations, We Develop an Uncertainty-guided Spatial Correlation to Generate a Probability Map of the Vehicle Locations, from Which the Relative Translation Can Be Determined. Experimental Results Demonstrate That Our Method Significantly Outperforms the State-of-the-art. Notably, the Likelihood of Restricting the Vehicle Lateral Pose to Be Within 1m of Its Ground Truth (GT) Value on the Cross-view KITTI Dataset Has Been Improved from $35.54\%$ to $76.44\%$, and the Likelihood of Restricting the Vehicle Orientation to Be Within $1^{\circ}$ of Its GT Value Has Been Improved from $19.64\%$ to $99.10\%$.
</details></li>
</ul>
<hr>
<h2 id="Revisiting-Implicit-Models-Sparsity-Trade-offs-Capability-in-Weight-tied-Model-for-Vision-Tasks"><a href="#Revisiting-Implicit-Models-Sparsity-Trade-offs-Capability-in-Weight-tied-Model-for-Vision-Tasks" class="headerlink" title="Revisiting Implicit Models: Sparsity Trade-offs Capability in Weight-tied Model for Vision Tasks"></a>Revisiting Implicit Models: Sparsity Trade-offs Capability in Weight-tied Model for Vision Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08013">http://arxiv.org/abs/2307.08013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haobo Song, Soumajit Majumder, Tao Lin</li>
<li>for: This paper aims to revisit the line of implicit models, specifically weight-tied models, and evaluate their effectiveness, stability, and efficiency on vision tasks.</li>
<li>methods: The paper uses weight-tied models as the basis for its study, and proposes the use of distinct sparse masks to improve the model capacity.</li>
<li>results: The paper finds that weight-tied models are more effective, stable, and efficient on vision tasks compared to DEQ variants, and provides design guidelines for practitioners regarding the selection of depth, width, and sparsity.<details>
<summary>Abstract</summary>
Implicit models such as Deep Equilibrium Models (DEQs) have garnered significant attention in the community for their ability to train infinite layer models with elegant solution-finding procedures and constant memory footprint. However, despite several attempts, these methods are heavily constrained by model inefficiency and optimization instability. Furthermore, fair benchmarking across relevant methods for vision tasks is missing. In this work, we revisit the line of implicit models and trace them back to the original weight-tied models. Surprisingly, we observe that weight-tied models are more effective, stable, as well as efficient on vision tasks, compared to the DEQ variants. Through the lens of these simple-yet-clean weight-tied models, we further study the fundamental limits in the model capacity of such models and propose the use of distinct sparse masks to improve the model capacity. Finally, for practitioners, we offer design guidelines regarding the depth, width, and sparsity selection for weight-tied models, and demonstrate the generalizability of our insights to other learning paradigms.
</details>
<details>
<summary>摘要</summary>
匿型模型（如深度均衡模型）在社区中受到了广泛关注，因为它们可以训练无穷层模型，并且有着简洁的解决方案和常量内存占用。然而，虽然有几次尝试，但这些方法受到了模型不充分利用和优化不稳定的限制。此外，相关的视觉任务中的公平比较缺失。在这种情况下，我们回到了权重相关模型的起源，并发现了权重相关模型在视觉任务上的效果更高，稳定性更好，并且更高效。通过这些简单 yet clean的权重相关模型，我们进一步研究了这些模型的基本限制，并提出了使用特定的稀疏面积来提高模型容量的方法。最后，我们向实践者提供了深度、宽度和稀疏性选择的设计指南，并证明了我们的理解在其他学习模式上的普适性。
</details></li>
</ul>
<hr>
<h2 id="Householder-Projector-for-Unsupervised-Latent-Semantics-Discovery"><a href="#Householder-Projector-for-Unsupervised-Latent-Semantics-Discovery" class="headerlink" title="Householder Projector for Unsupervised Latent Semantics Discovery"></a>Householder Projector for Unsupervised Latent Semantics Discovery</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08012">http://arxiv.org/abs/2307.08012</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/kingjamessong/householdergan">https://github.com/kingjamessong/householdergan</a></li>
<li>paper_authors: Yue Song, Jichao Zhang, Nicu Sebe, Wei Wang</li>
<li>for: 这个论文主要是为了探索 generator adversarial networks (GANs) 的内在结构，以便更好地理解和控制图像生成过程。</li>
<li>methods: 作者提出了一种基于 Householder 变换的低级别正交矩阵表示方法（Householder Projector），用于参数化 projection matrix，从而实现对 latent code 的 traverse 以便发现更加精细的 semantic attributes。</li>
<li>results: 作者在 StyleGAN2&#x2F;StyleGAN3 模型中集成了 Householder Projector，并在多个 benchmark 上评估了模型的表现。结果显示，只需要在原始训练步骤的 1% 上进行微调，Householder Projector 可以帮助 StyleGANs 发现更加精细和准确的 semantic attributes，而不需要牺牲图像的准确性。<details>
<summary>Abstract</summary>
Generative Adversarial Networks (GANs), especially the recent style-based generators (StyleGANs), have versatile semantics in the structured latent space. Latent semantics discovery methods emerge to move around the latent code such that only one factor varies during the traversal. Recently, an unsupervised method proposed a promising direction to directly use the eigenvectors of the projection matrix that maps latent codes to features as the interpretable directions. However, one overlooked fact is that the projection matrix is non-orthogonal and the number of eigenvectors is too large. The non-orthogonality would entangle semantic attributes in the top few eigenvectors, and the large dimensionality might result in meaningless variations among the directions even if the matrix is orthogonal. To avoid these issues, we propose Householder Projector, a flexible and general low-rank orthogonal matrix representation based on Householder transformations, to parameterize the projection matrix. The orthogonality guarantees that the eigenvectors correspond to disentangled interpretable semantics, while the low-rank property encourages that each identified direction has meaningful variations. We integrate our projector into pre-trained StyleGAN2/StyleGAN3 and evaluate the models on several benchmarks. Within only $1\%$ of the original training steps for fine-tuning, our projector helps StyleGANs to discover more disentangled and precise semantic attributes without sacrificing image fidelity.
</details>
<details>
<summary>摘要</summary>
“生成问题网络”（GANs），特别是最近的样式基因生成器（StyleGANs），在结构化的底层空间中有多元 semantics。内在semantics发现方法产生了可以在底层代码中移动的方法，以便只有一个因素在旅游中变化。最近，一种无监督的方法提出了一个可能的方向， directly使用对应码到特征的投影矩阵的特征向量作为可解释的方向。然而，一个被遗忘的事实是，投影矩阵不对称，数量过多的特征向量会导致意义的变化，即使投影矩阵是对称的。为了解决这些问题，我们提出了“Householder Projector”，一种通用且统一的低维度对称矩阵表示，基于Householder变换。对称性 garantuees that the feature vectors correspond to disentangled interpretable semantics, while the low-rank property encourages that each identified direction has meaningful variations. We integrate our projector into pre-trained StyleGAN2/StyleGAN3 and evaluate the models on several benchmarks. Within only 1% of the original training steps for fine-tuning, our projector helps StyleGANs to discover more disentangled and precise semantic attributes without sacrificing image fidelity.
</details></li>
</ul>
<hr>
<h2 id="LUCYD-A-Feature-Driven-Richardson-Lucy-Deconvolution-Network"><a href="#LUCYD-A-Feature-Driven-Richardson-Lucy-Deconvolution-Network" class="headerlink" title="LUCYD: A Feature-Driven Richardson-Lucy Deconvolution Network"></a>LUCYD: A Feature-Driven Richardson-Lucy Deconvolution Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07998">http://arxiv.org/abs/2307.07998</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ctom2/lucyd-deconvolution">https://github.com/ctom2/lucyd-deconvolution</a></li>
<li>paper_authors: Tomáš Chobola, Gesine Müller, Veit Dausmann, Anton Theileis, Jan Taucher, Jan Huisken, Tingying Peng</li>
<li>for: 提高微scopic图像质量和可读性</li>
<li>methods: 结合Richardson-Lucy抽象方程和深度学习网络特征，提出了LUCYD方法，以增强图像质量并降低计算成本。</li>
<li>results: LUCYD方法在synthetic和实际微scopic图像中表现出色，超过了现有方法的性能，并能够处理不同的微scopic模式和捕捉条件。<details>
<summary>Abstract</summary>
The process of acquiring microscopic images in life sciences often results in image degradation and corruption, characterised by the presence of noise and blur, which poses significant challenges in accurately analysing and interpreting the obtained data. This paper proposes LUCYD, a novel method for the restoration of volumetric microscopy images that combines the Richardson-Lucy deconvolution formula and the fusion of deep features obtained by a fully convolutional network. By integrating the image formation process into a feature-driven restoration model, the proposed approach aims to enhance the quality of the restored images whilst reducing computational costs and maintaining a high degree of interpretability. Our results demonstrate that LUCYD outperforms the state-of-the-art methods in both synthetic and real microscopy images, achieving superior performance in terms of image quality and generalisability. We show that the model can handle various microscopy modalities and different imaging conditions by evaluating it on two different microscopy datasets, including volumetric widefield and light-sheet microscopy. Our experiments indicate that LUCYD can significantly improve resolution, contrast, and overall quality of microscopy images. Therefore, it can be a valuable tool for microscopy image restoration and can facilitate further research in various microscopy applications. We made the source code for the model accessible under https://github.com/ctom2/lucyd-deconvolution.
</details>
<details>
<summary>摘要</summary>
生物科学中获取微scopic图像过程经常会导致图像异常和损害，表现为噪声和模糊，这会对数据分析和解释带来重大挑战。这篇论文提出了LUCYD方法，该方法combines Richardson-Lucy整形方程和基于完全 convolutional neural network 的深度特征融合，以提高图像 restore 的质量，降低计算成本，保持高度可解释性。我们的结果表明，LUCYD方法在对比state-of-the-art方法时表现出色，在 sintetic 和实际 microscopy 图像中都达到了更高的图像质量和普适性。我们的实验表明，LUCYD方法可以处理不同的 microscopy 模式和拍摄条件，并且可以在两个不同的 microscopy 数据集上进行评估，包括volumetric widefield 和 light-sheet microscopy。我们的实验结果表明，LUCYD方法可以大幅提高微scopic图像的分辨率、对比度和总质量。因此，它可以成为微scopic图像 Restoration 的有价值工具，并且可以推动各种 microscopy 应用的进一步研究。我们将模型的源代码公开于 GitHub 上，可以通过 <https://github.com/ctom2/lucyd-deconvolution> 访问。
</details></li>
</ul>
<hr>
<h2 id="Enforcing-Topological-Interaction-between-Implicit-Surfaces-via-Uniform-Sampling"><a href="#Enforcing-Topological-Interaction-between-Implicit-Surfaces-via-Uniform-Sampling" class="headerlink" title="Enforcing Topological Interaction between Implicit Surfaces via Uniform Sampling"></a>Enforcing Topological Interaction between Implicit Surfaces via Uniform Sampling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08716">http://arxiv.org/abs/2307.08716</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hieu Le, Nicolas Talabot, Jiancheng Yang, Pascal Fua</li>
<li>for: 本文旨在提出一种新的方法，用于精确地模型3D物体表面，以保证它们之间的topological交互。</li>
<li>methods: 该方法基于随机点的统计方法，通过选择一组点作为参照点，来修正3D物体表面。</li>
<li>results: 实验表明，该方法可以准确地重建人体心脏，保证组件之间的topological连接。此外，该方法还可以用来模拟手与任意物体之间的各种交互方式。<details>
<summary>Abstract</summary>
Objects interact with each other in various ways, including containment, contact, or maintaining fixed distances. Ensuring these topological interactions is crucial for accurate modeling in many scenarios. In this paper, we propose a novel method to refine 3D object representations, ensuring that their surfaces adhere to a topological prior. Our key observation is that the object interaction can be observed via a stochastic approximation method: the statistic of signed distances between a large number of random points to the object surfaces reflect the interaction between them. Thus, the object interaction can be indirectly manipulated by using choosing a set of points as anchors to refine the object surfaces. In particular, we show that our method can be used to enforce two objects to have a specific contact ratio while having no surface intersection. The conducted experiments show that our proposed method enables accurate 3D reconstruction of human hearts, ensuring proper topological connectivity between components. Further, we show that our proposed method can be used to simulate various ways a hand can interact with an arbitrary object.
</details>
<details>
<summary>摘要</summary>
objects 与其他物体之间存在多种互动方式，包括含容、触摸或维持固定距离。保证这些拓扑互动是对很多场景中模型的精确预测非常重要。在这篇论文中，我们提出了一种新的方法来精细调整3D物体表示，使其表面遵循拓扑优先。我们的关键观察是物体互动可以通过一种随机点方法的统计来观察：对一大量Random点的积分可以反映物体之间的互动。因此，我们可以通过选择一组点作为安全来修改物体表面，以间接地控制物体互动。具体来说，我们表明了我们的方法可以用来保证两个物体之间有specific contact比例，而不会出现表面交叉。实验结果表明，我们的提议方法可以准确地重建人类心脏，并保证组件之间的拓扑连接性。此外，我们还表明了我们的方法可以用来模拟手部与任意物体之间的各种互动方式。
</details></li>
</ul>
<hr>
<h2 id="Integrating-Human-Parsing-and-Pose-Network-for-Human-Action-Recognition"><a href="#Integrating-Human-Parsing-and-Pose-Network-for-Human-Action-Recognition" class="headerlink" title="Integrating Human Parsing and Pose Network for Human Action Recognition"></a>Integrating Human Parsing and Pose Network for Human Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07977">http://arxiv.org/abs/2307.07977</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/liujf69/ipp-net-parsing">https://github.com/liujf69/ipp-net-parsing</a></li>
<li>paper_authors: Runwei Ding, Yuhang Wen, Jinfu Liu, Nan Dai, Fanyang Meng, Mengyuan Liu</li>
<li>for: 本研究旨在提高人体动作识别的精度，使用人体解剖特征图和人体分剖特征图作为输入模式。</li>
<li>methods: 本研究提出了一种Integrating Human Parsing and Pose Network（IPP-Net），利用人体解剖特征图和人体分剖特征图进行双路结合，以提高人体动作识别的精度。人体pose分支使用图型卷积网络来模型pose特征，而人体分剖分支使用人体探测和分剖器来提取多帧人体部分特征，然后使用卷积嵌入学习来学习人体分剖特征。</li>
<li>results: 对于NTU RGB+D和NTU RGB+D 120测试集，IPP-Net的实验结果表明，IPP-Net可以在人体动作识别任务中获得更高的准确率，比如exist的方法更高。代码可以在<a target="_blank" rel="noopener" href="https://github.com/liujf69/IPP-Net-Parsing%E4%B8%8A%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/liujf69/IPP-Net-Parsing上获取。</a><details>
<summary>Abstract</summary>
Human skeletons and RGB sequences are both widely-adopted input modalities for human action recognition. However, skeletons lack appearance features and color data suffer large amount of irrelevant depiction. To address this, we introduce human parsing feature map as a novel modality, since it can selectively retain spatiotemporal features of the body parts, while filtering out noises regarding outfits, backgrounds, etc. We propose an Integrating Human Parsing and Pose Network (IPP-Net) for action recognition, which is the first to leverage both skeletons and human parsing feature maps in dual-branch approach. The human pose branch feeds compact skeletal representations of different modalities in graph convolutional network to model pose features. In human parsing branch, multi-frame body-part parsing features are extracted with human detector and parser, which is later learnt using a convolutional backbone. A late ensemble of two branches is adopted to get final predictions, considering both robust keypoints and rich semantic body-part features. Extensive experiments on NTU RGB+D and NTU RGB+D 120 benchmarks consistently verify the effectiveness of the proposed IPP-Net, which outperforms the existing action recognition methods. Our code is publicly available at https://github.com/liujf69/IPP-Net-Parsing .
</details>
<details>
<summary>摘要</summary>
人体骨架和RGB序列都是人类动作识别中广泛使用的输入模式。然而，骨架缺乏外表特征，RGB数据受到大量不相关的描述所受损害。为了解决这个问题，我们引入人体解析特征图作为一种新的输入模式，因为它可以选择性地保留身体部位的空间特征，并过滤背景和服装等不相关的噪音。我们提议一种 integrate human parsing and pose network（IPP-Net），它是第一个同时利用骨架和人体解析特征图进行双树结构的方法。人体姿势分支将不同模式的短暂骨架表示feed到图像卷积网络中，以模型姿势特征。人体解析分支使用人体检测和解析器来提取多帧身体部位解析特征，并使用卷积核心学习。最后，我们采用了两支分支的晚期ensemble来得到最终预测结果，考虑到了稳定的关键点和丰富的语义身体部位特征。我们的代码可以在https://github.com/liujf69/IPP-Net-Parsing上找到。extensive experiments on NTU RGB+D and NTU RGB+D 120 benchmarks consistently verify the effectiveness of the proposed IPP-Net, which outperforms the existing action recognition methods.
</details></li>
</ul>
<hr>
<h2 id="HRHD-HK-A-benchmark-dataset-of-high-rise-and-high-density-urban-scenes-for-3D-semantic-segmentation-of-photogrammetric-point-clouds"><a href="#HRHD-HK-A-benchmark-dataset-of-high-rise-and-high-density-urban-scenes-for-3D-semantic-segmentation-of-photogrammetric-point-clouds" class="headerlink" title="HRHD-HK: A benchmark dataset of high-rise and high-density urban scenes for 3D semantic segmentation of photogrammetric point clouds"></a>HRHD-HK: A benchmark dataset of high-rise and high-density urban scenes for 3D semantic segmentation of photogrammetric point clouds</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07976">http://arxiv.org/abs/2307.07976</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/luzaijiaoxial/hrhd-hk">https://github.com/luzaijiaoxial/hrhd-hk</a></li>
<li>paper_authors: Maosu Li, Yijie Wu, Anthony G. O. Yeh, Fan Xue</li>
<li>for: 这篇论文旨在评估现有的3Dsemantic segmentation方法，以及它们在多样化的城市场景中的性能。</li>
<li>methods: 这篇论文使用了8种流行的semantic segmentation方法，并对其进行了全面的评估。</li>
<li>results: 实验结果表明，现有的3D semantic segmentation方法在处理高层、高密度城市区域时仍有很大的改进空间，特别是对于城市 объек的小体积物体。<details>
<summary>Abstract</summary>
Many existing 3D semantic segmentation methods, deep learning in computer vision notably, claimed to achieve desired results on urban point clouds, in which the city objects are too many and diverse for people to judge qualitatively. Thus, it is significant to assess these methods quantitatively in diversified real-world urban scenes, encompassing high-rise, low-rise, high-density, and low-density urban areas. However, existing public benchmark datasets primarily represent low-rise scenes from European cities and cannot assess the methods comprehensively. This paper presents a benchmark dataset of high-rise urban point clouds, namely High-Rise, High-Density urban scenes of Hong Kong (HRHD-HK), which has been vacant for a long time. HRHD-HK arranged in 150 tiles contains 273 million colorful photogrammetric 3D points from diverse urban settings. The semantic labels of HRHD-HK include building, vegetation, road, waterbody, facility, terrain, and vehicle. To the best of our knowledge, HRHD-HK is the first photogrammetric dataset that focuses on HRHD urban areas. This paper also comprehensively evaluates eight popular semantic segmentation methods on the HRHD-HK dataset. Experimental results confirmed plenty of room for enhancing the current 3D semantic segmentation of point clouds, especially for city objects with small volumes. Our dataset is publicly available at: https://github.com/LuZaiJiaoXiaL/HRHD-HK.
</details>
<details>
<summary>摘要</summary>
许多现有的3Dsemantic segmentation方法，特别是深度学习在计算机视觉领域，宣称达到了所需的结果在城市点云中，其中城市 объекts 太多和多样，使人无法评估其质量。因此，需要对这些方法进行量化的评估，以适应多样化的城市场景。然而，现有的公共benchmark数据集主要表示欧洲城市的低层建筑，无法全面评估这些方法。本文提出了一个高层、高密度城市点云数据集，即高层高密度城市区域的香港（HRHD-HK）数据集，该数据集已经空缺了很长时间。HRHD-HK包括150个块，每个块包含273万个颜色化光学3D点云，来自不同的城市环境。 semantic label 包括建筑、植被、路面、水域、设施、地形和车辆。根据我们所知，HRHD-HK是首个专注于高层高密度城市区域的光学数据集。本文还进行了8种流行的semantic segmentation方法的全面评估。实验结果表明，目前的3Dsemantic segmentation技术在城市点云中仍有很多的提升空间，特别是对城市对象的小体积。我们的数据集可以在：https://github.com/LuZaiJiaoXiaL/HRHD-HK中下载。
</details></li>
</ul>
<hr>
<h2 id="Towards-Viewpoint-Invariant-Visual-Recognition-via-Adversarial-Training"><a href="#Towards-Viewpoint-Invariant-Visual-Recognition-via-Adversarial-Training" class="headerlink" title="Towards Viewpoint-Invariant Visual Recognition via Adversarial Training"></a>Towards Viewpoint-Invariant Visual Recognition via Adversarial Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.10235">http://arxiv.org/abs/2307.10235</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shouwei Ruan, Yinpeng Dong, Hang Su, Jianteng Peng, Ning Chen, Xingxing Wei</li>
<li>for: 提高图像分类器的视角不变性，使其能够在不同的视角下仍然准确地预测图像。</li>
<li>methods: 提出了一种基于对抗训练的方法，称为视点不变 adversarial training（VIAT），通过将视点变换视为攻击， формули了一个最小化损失函数，以实现视点不变的图像分类器。</li>
<li>results: 经验表明，VIAT 可以有效地提高多种图像分类器的视角不变性，并且可以通过将对抗视点分布传递给不同的图像，提高对象的泛化性能。<details>
<summary>Abstract</summary>
Visual recognition models are not invariant to viewpoint changes in the 3D world, as different viewing directions can dramatically affect the predictions given the same object. Although many efforts have been devoted to making neural networks invariant to 2D image translations and rotations, viewpoint invariance is rarely investigated. As most models process images in the perspective view, it is challenging to impose invariance to 3D viewpoint changes based only on 2D inputs. Motivated by the success of adversarial training in promoting model robustness, we propose Viewpoint-Invariant Adversarial Training (VIAT) to improve viewpoint robustness of common image classifiers. By regarding viewpoint transformation as an attack, VIAT is formulated as a minimax optimization problem, where the inner maximization characterizes diverse adversarial viewpoints by learning a Gaussian mixture distribution based on a new attack GMVFool, while the outer minimization trains a viewpoint-invariant classifier by minimizing the expected loss over the worst-case adversarial viewpoint distributions. To further improve the generalization performance, a distribution sharing strategy is introduced leveraging the transferability of adversarial viewpoints across objects. Experiments validate the effectiveness of VIAT in improving the viewpoint robustness of various image classifiers based on the diversity of adversarial viewpoints generated by GMVFool.
</details>
<details>
<summary>摘要</summary>
“视觉识别模型不具备对3D世界视角变化的不变性，因为不同的观察方向可能会对同一物体的预测产生很大的影响。虽然许多努力已经投入到了使用神经网络对2D图像的翻译和旋转进行不变性处理，但视点不变性 rarely investigated。因为大多数模型在 perspective view 中处理图像，因此基于2D输入 alone 提高3D视角不变性的问题是挑战。鼓动了对模型 robustness 的成功，我们提出了 Viewpoint-Invariant Adversarial Training（VIAT），以提高常见图像分类器的视角不变性。VIAT 是一种 minimax 优化问题，其中内部最大化部分表示多样化的敌方攻击视点，通过学习一个基于新的攻击 GMVFool 的 Gaussian mixture distribution，而外部最小化部分则是在最坏情况下的敌方视点分布上进行视点不变性的训练。为了进一步提高通用性表现，我们还提出了基于对敌方视点的传输性的分布分享策略。实验证明，VIAT 可以提高多种图像分类器的视角不变性，基于 GMVFool 生成的多样化敌方视点。”
</details></li>
</ul>
<hr>
<h2 id="Dual-level-Interaction-for-Domain-Adaptive-Semantic-Segmentation"><a href="#Dual-level-Interaction-for-Domain-Adaptive-Semantic-Segmentation" class="headerlink" title="Dual-level Interaction for Domain Adaptive Semantic Segmentation"></a>Dual-level Interaction for Domain Adaptive Semantic Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07972">http://arxiv.org/abs/2307.07972</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rainjamesy/dida">https://github.com/rainjamesy/dida</a></li>
<li>paper_authors: Dongyu Yao, Boheng Li</li>
<li>for: 这篇论文主要针对域 adaptation 上的 semantic segmentation 问题，提出了一种基于 dual-level interaction 的方法（DIDA），以增强模型的鲁棒性和精度。</li>
<li>methods: 该方法在 semantic segmentation 中使用了域 adaptation 技术，并在不同的域上进行了 augmented 视图的交互，以便增强模型的鲁棒性和精度。此外，该方法还使用了一种动态更新策略来保持一个有用的实例银行，以便更好地捕捉实例的特征。</li>
<li>results: 根据实验结果，该方法在 confusing 和 long-tailed 类上表现出了明显的优势，特别是在 semantic segmentation 中。与现有方法相比，该方法可以增强模型的精度和鲁棒性，并且可以更好地处理域 adaptation 问题。<details>
<summary>Abstract</summary>
Self-training approach recently secures its position in domain adaptive semantic segmentation, where a model is trained with target domain pseudo-labels. Current advances have mitigated noisy pseudo-labels resulting from the domain gap. However, they still struggle with erroneous pseudo-labels near the boundaries of the semantic classifier. In this paper, we tackle this issue by proposing a dual-level interaction for domain adaptation (DIDA) in semantic segmentation. Explicitly, we encourage the different augmented views of the same pixel to have not only similar class prediction (semantic-level) but also akin similarity relationship with respect to other pixels (instance-level). As it's impossible to keep features of all pixel instances for a dataset, we, therefore, maintain a labeled instance bank with dynamic updating strategies to selectively store the informative features of instances. Further, DIDA performs cross-level interaction with scattering and gathering techniques to regenerate more reliable pseudo-labels. Our method outperforms the state-of-the-art by a notable margin, especially on confusing and long-tailed classes. Code is available at \href{https://github.com/RainJamesY/DIDA}
</details>
<details>
<summary>摘要</summary>
自适应方法最近在域 adapted semantic segmentation 中脱颖而出，其中一个模型通过目标域 Pseudo-标签 进行训练。现有技术已经消除了域之间的噪声 Pseudo-标签，但仍然在边缘类划分器中遇到了错误 Pseudo-标签。在这篇论文中，我们解决了这个问题，我们提议一种双级互动 для域适应（DIDA）在semantic segmentation中。具体来说，我们要求不同的扩展视图（augmented views）中的同一个像素有不仅相似的类预测（semantic-level），还有类似的相似性关系与其他像素（instance-level）。由于不可能保持一个 dataset 中所有像素的特征，我们因此保持一个标注的实例银行，并使用动态更新策略来选择ively存储实例中的有用特征。此外，DIDA通过散布和聚集技术来进行交互，以重新生成更可靠的 Pseudo-标签。我们的方法与当前状态的较好，尤其是在混淆和长尾类上。代码可以在 \href{https://github.com/RainJamesY/DIDA} 上找到。
</details></li>
</ul>
<hr>
<h2 id="EmoSet-A-Large-scale-Visual-Emotion-Dataset-with-Rich-Attributes"><a href="#EmoSet-A-Large-scale-Visual-Emotion-Dataset-with-Rich-Attributes" class="headerlink" title="EmoSet: A Large-scale Visual Emotion Dataset with Rich Attributes"></a>EmoSet: A Large-scale Visual Emotion Dataset with Rich Attributes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07961">http://arxiv.org/abs/2307.07961</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingyuan Yang, Qirui Huang, Tingting Ding, Dani Lischinski, Daniel Cohen-Or, Hui Huang<br>for:This paper aims to introduce a large-scale visual emotion dataset (EmoSet) with rich annotations to support research in visual emotion analysis and understanding.methods:The dataset is constructed by collecting images from social networks and artistic sources, and is annotated with 118,102 images and 14 emotion attributes, including brightness, colorfulness, scene type, object class, facial expression, and human action.results:EmoSet is five times larger than the largest existing dataset and is well balanced between different emotion categories, providing a valuable resource for researchers in the field of affective computing.<details>
<summary>Abstract</summary>
Visual Emotion Analysis (VEA) aims at predicting people's emotional responses to visual stimuli. This is a promising, yet challenging, task in affective computing, which has drawn increasing attention in recent years. Most of the existing work in this area focuses on feature design, while little attention has been paid to dataset construction. In this work, we introduce EmoSet, the first large-scale visual emotion dataset annotated with rich attributes, which is superior to existing datasets in four aspects: scale, annotation richness, diversity, and data balance. EmoSet comprises 3.3 million images in total, with 118,102 of these images carefully labeled by human annotators, making it five times larger than the largest existing dataset. EmoSet includes images from social networks, as well as artistic images, and it is well balanced between different emotion categories. Motivated by psychological studies, in addition to emotion category, each image is also annotated with a set of describable emotion attributes: brightness, colorfulness, scene type, object class, facial expression, and human action, which can help understand visual emotions in a precise and interpretable way. The relevance of these emotion attributes is validated by analyzing the correlations between them and visual emotion, as well as by designing an attribute module to help visual emotion recognition. We believe EmoSet will bring some key insights and encourage further research in visual emotion analysis and understanding. Project page: https://vcc.tech/EmoSet.
</details>
<details>
<summary>摘要</summary>
Visual Emotion Analysis (VEA) 目标是预测人们对视觉刺激的情感反应。这是一项有前途的、具有挑战性的任务，在情感计算领域内，在最近几年内受到了越来越多的关注。大多数现有的工作在这个领域都是特征设计方向，而忽略了数据建构。在这项工作中，我们介绍了Emoset，第一个大规模的视觉情感数据集，其中包含330万个图像，其中118,102个图像被人类标注员仔细标注，比现有最大的数据集大五倍。Emoset包含社交媒体图像以及艺术图像，并且具有良好的各种情感类别的均衡。受精神学研究 inspirited，每个图像还被标注了一组可见的情感特征：明亮度、颜色彩强、场景类型、物体类型、表情和人类动作，这些特征可以帮助理解视觉情感的精确和可读性。这些情感特征的相关性被证明通过对它们与视觉情感之间的相关性分析，以及设计了一个特征模块来帮助视觉情感认知。我们认为Emoset将带来一些关键的发现，并促进视觉情感分析和理解的进一步研究。项目页面：https://vcc.tech/EmoSet。
</details></li>
</ul>
<hr>
<h2 id="Accurate-3D-Prediction-of-Missing-Teeth-in-Diverse-Patterns-for-Precise-Dental-Implant-Planning"><a href="#Accurate-3D-Prediction-of-Missing-Teeth-in-Diverse-Patterns-for-Precise-Dental-Implant-Planning" class="headerlink" title="Accurate 3D Prediction of Missing Teeth in Diverse Patterns for Precise Dental Implant Planning"></a>Accurate 3D Prediction of Missing Teeth in Diverse Patterns for Precise Dental Implant Planning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07953">http://arxiv.org/abs/2307.07953</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Ma, Peng Xue, Yuning Gu, Yue Zhao, Min Zhu, Zhongxiang Ding, Dinggang Shen</li>
<li>For: 这个研究旨在提供一种准确预测缺失牙齿的框架，以便为牙齿嵌入式计划提供更好的规划和置入。* Methods: 该研究使用了一种基于CBCT图像的数据集来估算牙齿模型之间的点对点匹配关系，并将每种牙齿类型的位置和形状信息编码到牙齿词典中。然后，使用 sparse 表示法来学习缺失牙齿的邻近牙齿的位置和形状信息，并将这些信息应用到缺失牙齿的词典中来生成准确的预测结果。* Results: 研究结果表明，该提出的框架可以准确预测缺失牙齿的位置和形状，其预测误差为1.04mm和1.33mm分别对于单个缺失牙齿和14个缺失牙齿的预测。这表明该框架可以准确预测缺失牙齿在不同的模式下。<details>
<summary>Abstract</summary>
In recent years, the demand for dental implants has surged, driven by their high success rates and esthetic advantages. However, accurate prediction of missing teeth for precise digital implant planning remains a challenge due to the intricate nature of dental structures and the variability in tooth loss patterns. This study presents a novel framework for accurate prediction of missing teeth in different patterns, facilitating digital implant planning. The proposed framework begins by estimating point-to-point correspondence among a dataset of dental mesh models reconstructed from CBCT images of healthy subjects. Subsequently, tooth dictionaries are constructed for each tooth type, encoding their position and shape information based on the established point-to-point correspondence. To predict missing teeth in a given dental mesh model, sparse coefficients are learned by sparsely representing adjacent teeth of the missing teeth using the corresponding tooth dictionaries. These coefficients are then applied to the dictionaries of the missing teeth to generate accurate predictions of their positions and shapes. The evaluation results on real subjects shows that our proposed framework achieves an average prediction error of 1.04mm for predictions of single missing tooth and an average prediction error of 1.33mm for the prediction of 14 missing teeth, which demonstrates its capability of accurately predicting missing teeth in various patterns. By accurately predicting missing teeth, dental professionals can improve the planning and placement of dental implants, leading to better esthetic and functional outcomes for patients undergoing dental implant procedures.
</details>
<details>
<summary>摘要</summary>
Recently, the demand for dental implants has increased significantly due to their high success rates and aesthetic advantages. However, accurately predicting missing teeth for precise digital implant planning remains a challenge due to the complexity of dental structures and the variability of tooth loss patterns. This study proposes a novel framework for accurately predicting missing teeth in different patterns, facilitating digital implant planning.The proposed framework begins by estimating point-to-point correspondence among a dataset of dental mesh models reconstructed from CBCT images of healthy subjects. Next, tooth dictionaries are constructed for each tooth type, encoding their position and shape information based on the established point-to-point correspondence. To predict missing teeth in a given dental mesh model, sparse coefficients are learned by sparsely representing adjacent teeth of the missing teeth using the corresponding tooth dictionaries. These coefficients are then applied to the dictionaries of the missing teeth to generate accurate predictions of their positions and shapes.The evaluation results on real subjects show that our proposed framework achieves an average prediction error of 1.04mm for predictions of single missing teeth and an average prediction error of 1.33mm for the prediction of 14 missing teeth, which demonstrates its ability to accurately predict missing teeth in various patterns. By accurately predicting missing teeth, dental professionals can improve the planning and placement of dental implants, leading to better esthetic and functional outcomes for patients undergoing dental implant procedures.
</details></li>
</ul>
<hr>
<h2 id="Accelerating-Distributed-ML-Training-via-Selective-Synchronization"><a href="#Accelerating-Distributed-ML-Training-via-Selective-Synchronization" class="headerlink" title="Accelerating Distributed ML Training via Selective Synchronization"></a>Accelerating Distributed ML Training via Selective Synchronization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07950">http://arxiv.org/abs/2307.07950</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sahil Tyagi, Martin Swany</li>
<li>for: 这篇论文的目的是提出一种实用、低开销的深度神经网络（DNNs）训练方法，以提高分布式训练中的效率。</li>
<li>methods: 这篇论文使用的方法包括：	+ 精确地决定在每步的统计聚合是否有必要，以避免高交互成本的统计聚合所带来的过度负担。	+ 在不同的训练案例中，适当地调整统计聚合的频率，以便在训练时间中实现最佳的对照。	+ 提出了多种优化方法，以提高在半同步训练中的融合。</li>
<li>results: 这篇论文的结果显示，使用\texttt{SelSync}方法可以实现与BSP训练相同或更好的精度，而且可以降低训练时间，对应的缩减比例为14倍。<details>
<summary>Abstract</summary>
In distributed training, deep neural networks (DNNs) are launched over multiple workers concurrently and aggregate their local updates on each step in bulk-synchronous parallel (BSP) training. However, BSP does not linearly scale-out due to high communication cost of aggregation. To mitigate this overhead, alternatives like Federated Averaging (FedAvg) and Stale-Synchronous Parallel (SSP) either reduce synchronization frequency or eliminate it altogether, usually at the cost of lower final accuracy. In this paper, we present \texttt{SelSync}, a practical, low-overhead method for DNN training that dynamically chooses to incur or avoid communication at each step either by calling the aggregation op or applying local updates based on their significance. We propose various optimizations as part of \texttt{SelSync} to improve convergence in the context of \textit{semi-synchronous} training. Our system converges to the same or better accuracy than BSP while reducing training time by up to 14$\times$.
</details>
<details>
<summary>摘要</summary>
在分布式训练中，深度神经网络（DNN）被多个工作者同时启动，并在每次步骤中在大规模同步（BSP）训练中进行集中更新。然而，BSP不会线性扩展，因为聚合成本过高。为了缓解这个开销，有些alternatives如联邦平均（FedAvg）和停顿同步并行（SSP）可以减少同步频率，或者完全消除同步，通常是在牺牲最终准确性的代价。在这篇论文中，我们提出了\texttt{SelSync}，一种实用、低开销的DNN训练方法，可以在每次步骤中动态决定是否进行聚合或者应用本地更新，根据它们的重要性。我们还提出了多种优化，以提高在半同步训练中的整合。我们的系统可以与BSP相比，提高训练效率，同时保持最终准确性。
</details></li>
</ul>
<hr>
<h2 id="Language-Conditioned-Traffic-Generation"><a href="#Language-Conditioned-Traffic-Generation" class="headerlink" title="Language Conditioned Traffic Generation"></a>Language Conditioned Traffic Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07947">http://arxiv.org/abs/2307.07947</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Shuhan Tan, Boris Ivanovic, Xinshuo Weng, Marco Pavone, Philipp Kraehenbuehl</li>
<li>for: 这篇论文主要用于解决现代自动驾驶开发中的模拟问题，即创建真实、可扩展、具有吸引力的交通场景。</li>
<li>methods: 该论文使用语言作为交通场景生成的超visory工具， combines a large language model with a transformer-based decoder architecture，从数据集中选择可能的地图位置，并生成初始的交通分布和车辆的动态。</li>
<li>results:  compared to prior work，LCTGen模型在无条件和条件交通场景生成中显示出了更高的实际性和准确性。<details>
<summary>Abstract</summary>
Simulation forms the backbone of modern self-driving development. Simulators help develop, test, and improve driving systems without putting humans, vehicles, or their environment at risk. However, simulators face a major challenge: They rely on realistic, scalable, yet interesting content. While recent advances in rendering and scene reconstruction make great strides in creating static scene assets, modeling their layout, dynamics, and behaviors remains challenging. In this work, we turn to language as a source of supervision for dynamic traffic scene generation. Our model, LCTGen, combines a large language model with a transformer-based decoder architecture that selects likely map locations from a dataset of maps, and produces an initial traffic distribution, as well as the dynamics of each vehicle. LCTGen outperforms prior work in both unconditional and conditional traffic scene generation in terms of realism and fidelity. Code and video will be available at https://ariostgx.github.io/lctgen.
</details>
<details>
<summary>摘要</summary>
现代自动驾驶发展的核心是模拟。模拟器帮助开发、测试和改进驾驶系统，而不会对人类、车辆或环境造成危险。然而，模拟器遇到一个主要挑战：它们需要真实、可扩展、又有趣的内容。而最近的渲染和场景重建技术已经做出了很大的进步，但是模拟场景的布局、动态和行为仍然是一个挑战。在这项工作中，我们寻求语言作为模拟场景生成的超级视图。我们的模型LCTGen结合了一个大型语言模型和一个基于转换器的解码器架构，从数据集中选择可能的地图位置，并生成初始的交通分布以及每辆车辆的动力学。LCTGen在无条件和条件交通场景生成方面比前一代的工作更高效和更真实。代码和视频将在https://ariostgx.github.io/lctgen上提供。
</details></li>
</ul>
<hr>
<h2 id="Surface-Geometry-Processing-An-Efficient-Normal-based-Detail-Representation"><a href="#Surface-Geometry-Processing-An-Efficient-Normal-based-Detail-Representation" class="headerlink" title="Surface Geometry Processing: An Efficient Normal-based Detail Representation"></a>Surface Geometry Processing: An Efficient Normal-based Detail Representation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07945">http://arxiv.org/abs/2307.07945</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wuyuan Xie, Miaohui Wang, Di Lin, Boxin Shi, Jianmin Jiang</li>
<li>for: 本文提出了一种高效的Surface detail处理框架，用于解决高分辨率3D视觉应用中的传统方法具有较大的内存和计算时间成本。</li>
<li>methods: 本文提出了一种基于2D正常域的新的Surface detail处理方法，通过抽取新的正常特征表示来表示微geometry结构。文中both theoretically和empirically阐述了该表示的三个重要性能属性：细节分离、细节传输和细节幂等。</li>
<li>results: 对比现有状态的艺技，我们证明并示出了提议的正常基于表示的效果和多样性。在最新的benchmark dataset上，我们实现了理论分析和实验结果，证明了我们的正常基于表示的效果和多样性。在相同输入Surface vertices上，我们的方法只需6.5%的内存成本和14.0%的运行时间，相比现有竞争算法。<details>
<summary>Abstract</summary>
With the rapid development of high-resolution 3D vision applications, the traditional way of manipulating surface detail requires considerable memory and computing time. To address these problems, we introduce an efficient surface detail processing framework in 2D normal domain, which extracts new normal feature representations as the carrier of micro geometry structures that are illustrated both theoretically and empirically in this article. Compared with the existing state of the arts, we verify and demonstrate that the proposed normal-based representation has three important properties, including detail separability, detail transferability and detail idempotence. Finally, three new schemes are further designed for geometric surface detail processing applications, including geometric texture synthesis, geometry detail transfer, and 3D surface super-resolution. Theoretical analysis and experimental results on the latest benchmark dataset verify the effectiveness and versatility of our normal-based representation, which accepts 30 times of the input surface vertices but at the same time only takes 6.5% memory cost and 14.0% running time in comparison with existing competing algorithms.
</details>
<details>
<summary>摘要</summary>
Traditional high-resolution 3D vision applications 的面精度处理方式很快发展，但这些方法需要大量的内存和计算时间。为解决这些问题，我们介绍了一种高效的面精度处理框架，该框架在2D正常域中提取了新的正常特征表示，这些表示包括微geometry结构的示例，我们在这篇文章中对其进行了理论和实验 validate。与现有的状态艺术相比，我们的正常基于表示具有三个重要特性，包括细节分离、细节传输和细节幂等。最后，我们针对几种几种 геометри�结构细节处理应用程序设计了三种新方案，包括几何�xture生成、细节传输和3D surface超分辨率。我们的正常基于表示在对最新的benchmark数据进行了理论分析和实验验证，其可以接受30倍的输入面Vertex，但同时只需6.5%的内存成本和14.0%的计算时间，与现有的竞争算法相比。
</details></li>
</ul>
<hr>
<h2 id="CVSformer-Cross-View-Synthesis-Transformer-for-Semantic-Scene-Completion"><a href="#CVSformer-Cross-View-Synthesis-Transformer-for-Semantic-Scene-Completion" class="headerlink" title="CVSformer: Cross-View Synthesis Transformer for Semantic Scene Completion"></a>CVSformer: Cross-View Synthesis Transformer for Semantic Scene Completion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07938">http://arxiv.org/abs/2307.07938</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haotian Dong, Enhui Ma, Lubo Wang, Miaohui Wang, Wuyuan Xie, Qing Guo, Ping Li, Lingyu Liang, Kairui Yang, Di Lin<br>for:CVSformer is proposed to improve semantic scene completion by learning cross-view object relationships.methods:CVSformer consists of Multi-View Feature Synthesis and Cross-View Transformer to learn cross-view object relationships.results:CVSformer achieves state-of-the-art results on public datasets.<details>
<summary>Abstract</summary>
Semantic scene completion (SSC) requires an accurate understanding of the geometric and semantic relationships between the objects in the 3D scene for reasoning the occluded objects. The popular SSC methods voxelize the 3D objects, allowing the deep 3D convolutional network (3D CNN) to learn the object relationships from the complex scenes. However, the current networks lack the controllable kernels to model the object relationship across multiple views, where appropriate views provide the relevant information for suggesting the existence of the occluded objects. In this paper, we propose Cross-View Synthesis Transformer (CVSformer), which consists of Multi-View Feature Synthesis and Cross-View Transformer for learning cross-view object relationships. In the multi-view feature synthesis, we use a set of 3D convolutional kernels rotated differently to compute the multi-view features for each voxel. In the cross-view transformer, we employ the cross-view fusion to comprehensively learn the cross-view relationships, which form useful information for enhancing the features of individual views. We use the enhanced features to predict the geometric occupancies and semantic labels of all voxels. We evaluate CVSformer on public datasets, where CVSformer yields state-of-the-art results.
</details>
<details>
<summary>摘要</summary>
In this paper, we propose Cross-View Synthesis Transformer (CVSformer), which consists of Multi-View Feature Synthesis and Cross-View Transformer for learning cross-view object relationships. In Multi-View Feature Synthesis, we use a set of 3D convolutional kernels rotated differently to compute multi-view features for each voxel. In Cross-View Transformer, we employ cross-view fusion to comprehensively learn cross-view relationships, which form useful information for enhancing the features of individual views. We use the enhanced features to predict the geometric occupancies and semantic labels of all voxels.We evaluate CVSformer on public datasets, where CVSformer yields state-of-the-art results.
</details></li>
</ul>
<hr>
<h2 id="S2R-ViT-for-Multi-Agent-Cooperative-Perception-Bridging-the-Gap-from-Simulation-to-Reality"><a href="#S2R-ViT-for-Multi-Agent-Cooperative-Perception-Bridging-the-Gap-from-Simulation-to-Reality" class="headerlink" title="S2R-ViT for Multi-Agent Cooperative Perception: Bridging the Gap from Simulation to Reality"></a>S2R-ViT for Multi-Agent Cooperative Perception: Bridging the Gap from Simulation to Reality</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07935">http://arxiv.org/abs/2307.07935</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jinlong Li, Runsheng Xu, Xinyu Liu, Baolu Li, Qin Zou, Jiaqi Ma, Hongkai Yu</li>
<li>for: 本研究旨在解决现有多智能体协同感知算法在实际世界中表现不佳的问题，即在实际数据上下文中，由于 simulate 数据和实际数据之间的域差异，导致模型在实际世界中的感知性能下降。</li>
<li>methods: 本研究提出了一种首次在多智能体协同感知中实现了 sim2real 转移学习框架，通过一种新的视力变换器（ViT），并考虑了实施差（Implementation Gap）和特征差（Feature Gap）两种域差。为了有效地 relief 实施差，我们提出了一种不确定性感知器，并通过在egosensor和inter-sensor之间进行特征适应而减少特征差。</li>
<li>results: 我们在公共多智能体协同感知数据集OPV2V和V2V4Real上进行了广泛的实验，结果表明，提出的S2R-ViT可以有效地跨越实际和模拟之间的域差，并在点云基于3D物体检测方面表现出色，至于其他方法。<details>
<summary>Abstract</summary>
Due to the lack of real multi-agent data and time-consuming of labeling, existing multi-agent cooperative perception algorithms usually select the simulated sensor data for training and validating. However, the perception performance is degraded when these simulation-trained models are deployed to the real world, due to the significant domain gap between the simulated and real data. In this paper, we propose the first Simulation-to-Reality transfer learning framework for multi-agent cooperative perception using a novel Vision Transformer, named as S2R-ViT, which considers both the Implementation Gap and Feature Gap between simulated and real data. We investigate the effects of these two types of domain gaps and propose a novel uncertainty-aware vision transformer to effectively relief the Implementation Gap and an agent-based feature adaptation module with inter-agent and ego-agent discriminators to reduce the Feature Gap. Our intensive experiments on the public multi-agent cooperative perception datasets OPV2V and V2V4Real demonstrate that the proposed S2R-ViT can effectively bridge the gap from simulation to reality and outperform other methods significantly for point cloud-based 3D object detection.
</details>
<details>
<summary>摘要</summary>
Translation notes:* "multi-agent" is translated as "多智能" (duō zhìnéng)* "cooperative perception" is translated as "合作感知" (hézuò gǎnperce)* "simulation-trained models" is translated as "模拟训练模型" (móxī xùxíng módelì)* "real world" is translated as "实际世界" (shíjiè shìjiè)* "domain gap" is translated as "领域差距" (lánxìng jìnjù)* "Implementation Gap" is translated as "实现差距" (shíxiàn jìnjù)* "Feature Gap" is translated as "特征差距" (tèxí jìnjù)* "uncertainty-aware vision transformer" is translated as "不确定性意识感知变换器" (bù qièdìngxìng yìshì gǎnperce bianhuàng)* "agent-based feature adaptation module" is translated as "智能 Agent 基于特征修改模块" (zhìnéng agent jīyú yìxìng xiūgòu módèl)Note: The translation is based on Simplified Chinese, which is used in mainland China. If you need Traditional Chinese translation, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Contrastive-Multi-Task-Dense-Prediction"><a href="#Contrastive-Multi-Task-Dense-Prediction" class="headerlink" title="Contrastive Multi-Task Dense Prediction"></a>Contrastive Multi-Task Dense Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07934">http://arxiv.org/abs/2307.07934</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/USTCPCS/CVPR2018_attention">https://github.com/USTCPCS/CVPR2018_attention</a></li>
<li>paper_authors: Siwei Yang, Hanrong Ye, Dan Xu</li>
<li>for: This paper addresses the problem of multi-task dense prediction, aiming to achieve simultaneous learning and inference on multiple dense prediction tasks in a single framework.</li>
<li>methods: The paper introduces feature-wise contrastive consistency to model cross-task interactions, which effectively boosts representation learning for different sub-tasks without extra expensive distillation modules.</li>
<li>results: The proposed multi-task contrastive learning approach achieves superior performance on two challenging datasets (NYUD-v2 and Pascal-Context), establishing new state-of-the-art results for dense predictions.<details>
<summary>Abstract</summary>
This paper targets the problem of multi-task dense prediction which aims to achieve simultaneous learning and inference on a bunch of multiple dense prediction tasks in a single framework. A core objective in design is how to effectively model cross-task interactions to achieve a comprehensive improvement on different tasks based on their inherent complementarity and consistency. Existing works typically design extra expensive distillation modules to perform explicit interaction computations among different task-specific features in both training and inference, bringing difficulty in adaptation for different task sets, and reducing efficiency due to clearly increased size of multi-task models. In contrast, we introduce feature-wise contrastive consistency into modeling the cross-task interactions for multi-task dense prediction. We propose a novel multi-task contrastive regularization method based on the consistency to effectively boost the representation learning of the different sub-tasks, which can also be easily generalized to different multi-task dense prediction frameworks, and costs no additional computation in the inference. Extensive experiments on two challenging datasets (i.e. NYUD-v2 and Pascal-Context) clearly demonstrate the superiority of the proposed multi-task contrastive learning approach for dense predictions, establishing new state-of-the-art performances.
</details>
<details>
<summary>摘要</summary>
In contrast, we introduce feature-wise contrastive consistency to model cross-task interactions for multi-task dense prediction. We propose a novel multi-task contrastive regularization method based on consistency to effectively boost representation learning of different sub-tasks, which can be easily generalized to different multi-task dense prediction frameworks and does not require additional computation in inference. Extensive experiments on two challenging datasets (NYUD-v2 and Pascal-Context) demonstrate the superiority of the proposed multi-task contrastive learning approach for dense predictions, establishing new state-of-the-art performances.
</details></li>
</ul>
<hr>
<h2 id="Holistic-Prototype-Attention-Network-for-Few-Shot-VOS"><a href="#Holistic-Prototype-Attention-Network-for-Few-Shot-VOS" class="headerlink" title="Holistic Prototype Attention Network for Few-Shot VOS"></a>Holistic Prototype Attention Network for Few-Shot VOS</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07933">http://arxiv.org/abs/2307.07933</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/nust-machine-intelligence-laboratory/hpan">https://github.com/nust-machine-intelligence-laboratory/hpan</a></li>
<li>paper_authors: Yin Tang, Tao Chen, Xiruo Jiang, Yazhou Yao, Guo-Sen Xie, Heng-Tao Shen</li>
<li>for: 提高ew-shot video对象分割（FSVOS）中的动态对象分割精度，通过小量支持图像进行权重学习。</li>
<li>methods: 我们提出了一种整体prototype注意网络（HPAN），它包括 prototype graph注意模块（PGAM）和对称prototype注意模块（BPAM），通过将有用知识传递到未经见类别上来提高分割性能。</li>
<li>results: 我们在YouTube-FSVOS上进行了广泛的实验，并证明了我们提出的HPAN方法的有效性和优越性。<details>
<summary>Abstract</summary>
Few-shot video object segmentation (FSVOS) aims to segment dynamic objects of unseen classes by resorting to a small set of support images that contain pixel-level object annotations. Existing methods have demonstrated that the domain agent-based attention mechanism is effective in FSVOS by learning the correlation between support images and query frames. However, the agent frame contains redundant pixel information and background noise, resulting in inferior segmentation performance. Moreover, existing methods tend to ignore inter-frame correlations in query videos. To alleviate the above dilemma, we propose a holistic prototype attention network (HPAN) for advancing FSVOS. Specifically, HPAN introduces a prototype graph attention module (PGAM) and a bidirectional prototype attention module (BPAM), transferring informative knowledge from seen to unseen classes. PGAM generates local prototypes from all foreground features and then utilizes their internal correlations to enhance the representation of the holistic prototypes. BPAM exploits the holistic information from support images and video frames by fusing co-attention and self-attention to achieve support-query semantic consistency and inner-frame temporal consistency. Extensive experiments on YouTube-FSVOS have been provided to demonstrate the effectiveness and superiority of our proposed HPAN method.
</details>
<details>
<summary>摘要</summary>
“几帧影像物类分割（FSVOS）目的是将无法见的类别中的动态物类分割，通过一小集支持影像，其中包含像素级别物类标注。现有方法已经证明，对FSVOS使用域间代理机制可以将支持影像和询问帧之间建立相互关联。然而，代理帧中含有重复的像素信息和背景噪音，导致分割性能不佳。此外，现有方法往往忽略了询问影像之间的相互关联。为解决以上问题，我们提出了整体原型注意网络（HPAN），以提高FSVOS的性能。具体来说，HPAN包括一个原型图像注意模组（PGAM）和一个双向原型注意模组（BPAM），将有用的知识传递自见到未见的类别。PGAM从所有前景特征中生成本地区prototype，然后利用这些内部相关性来强化整体prototype的表现。BPAM利用支持影像和询问影像之间的共同关联和自我关联，实现支持询问semantic一致和内部时间一致。我们在YouTube-FSVOS上进行了广泛的实验，以证明我们提出的HPAN方法的有效性和superiority。”
</details></li>
</ul>
<hr>
<h2 id="DocTr-Document-Transformer-for-Structured-Information-Extraction-in-Documents"><a href="#DocTr-Document-Transformer-for-Structured-Information-Extraction-in-Documents" class="headerlink" title="DocTr: Document Transformer for Structured Information Extraction in Documents"></a>DocTr: Document Transformer for Structured Information Extraction in Documents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07929">http://arxiv.org/abs/2307.07929</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haofu Liao, Aruni RoyChowdhury, Weijian Li, Ankan Bansal, Yuting Zhang, Zhuowen Tu, Ravi Kumar Satzoda, R. Manmatha, Vijay Mahadevan</li>
<li>for: 提出了一种新的结构化信息抽取（SIE）方法，用于从视觉 ric 文档中提取结构化信息。</li>
<li>methods: 使用了 anchor-based 对象检测器的想法，将实体表示为 anchor word 和 bounding box，并表示实体关联为 anchor word 的关联。</li>
<li>results: 评估在三个 SIE  benchmark 上，提出的方法显示效果很好，并且在语言上进行 предваритель训练 后，能够学习实体检测。<details>
<summary>Abstract</summary>
We present a new formulation for structured information extraction (SIE) from visually rich documents. It aims to address the limitations of existing IOB tagging or graph-based formulations, which are either overly reliant on the correct ordering of input text or struggle with decoding a complex graph. Instead, motivated by anchor-based object detectors in vision, we represent an entity as an anchor word and a bounding box, and represent entity linking as the association between anchor words. This is more robust to text ordering, and maintains a compact graph for entity linking. The formulation motivates us to introduce 1) a DOCument TRansformer (DocTr) that aims at detecting and associating entity bounding boxes in visually rich documents, and 2) a simple pre-training strategy that helps learn entity detection in the context of language. Evaluations on three SIE benchmarks show the effectiveness of the proposed formulation, and the overall approach outperforms existing solutions.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的结构信息提取（SIE）方式，用于从视觉丰富文档中提取结构信息。该方式希望解决现有的IOB标注或图像基于的形ulation的限制，这些限制是 Either too reliant on the correct ordering of input text or struggle with decoding a complex graph. 而是，我们将实体表示为一个锚字和一个矩形框，并将实体连接视为锚字之间的关系。这种方式更加鲁棒地对text的顺序，并保持了compact的图像 для实体连接。这种方式的提出使我们引入了以下两个方法：1. DOCument TRansformer (DocTr)，用于在视觉丰富文档中检测和关联实体矩形框。2. 一种简单的预训练策略，用于在语言上学习实体检测。我们对三个SIE benchmark进行了评估，结果显示了提posed方式的效果，并且总的approach exceeds existing solutions。
</details></li>
</ul>
<hr>
<h2 id="Reinforced-Disentanglement-for-Face-Swapping-without-Skip-Connection"><a href="#Reinforced-Disentanglement-for-Face-Swapping-without-Skip-Connection" class="headerlink" title="Reinforced Disentanglement for Face Swapping without Skip Connection"></a>Reinforced Disentanglement for Face Swapping without Skip Connection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07928">http://arxiv.org/abs/2307.07928</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/alaist/RD-FS">https://github.com/alaist/RD-FS</a></li>
<li>paper_authors: Xiaohang Ren, Xingyu Chen, Pengfei Yao, Heung-Yeung Shum, Baoyuan Wang</li>
<li>for: 解决SOTA face swap模型中的人脸特征泄露和非人脸特征失去Problem</li>
<li>methods: 引入新的face swap框架’WSC-swap’, eliminating skip connections and using two target encoders to respectively capture pixel-level non-facial region attributes and semantic non-identity attributes in the face region. Plus, employing both identity removal loss via adversarial training and non-identity preservation loss via prior 3DMM models.</li>
<li>results: 对FaceForensics++和CelebA-HQ进行了广泛的实验，比较表现出色，包括一个新的指标 для测试人脸一致性，这个指标之前完全被忽略了。<details>
<summary>Abstract</summary>
The SOTA face swap models still suffer the problem of either target identity (i.e., shape) being leaked or the target non-identity attributes (i.e., background, hair) failing to be fully preserved in the final results. We show that this insufficient disentanglement is caused by two flawed designs that were commonly adopted in prior models: (1) counting on only one compressed encoder to represent both the semantic-level non-identity facial attributes(i.e., pose) and the pixel-level non-facial region details, which is contradictory to satisfy at the same time; (2) highly relying on long skip-connections between the encoder and the final generator, leaking a certain amount of target face identity into the result. To fix them, we introduce a new face swap framework called 'WSC-swap' that gets rid of skip connections and uses two target encoders to respectively capture the pixel-level non-facial region attributes and the semantic non-identity attributes in the face region. To further reinforce the disentanglement learning for the target encoder, we employ both identity removal loss via adversarial training (i.e., GAN) and the non-identity preservation loss via prior 3DMM models like [11]. Extensive experiments on both FaceForensics++ and CelebA-HQ show that our results significantly outperform previous works on a rich set of metrics, including one novel metric for measuring identity consistency that was completely neglected before.
</details>
<details>
<summary>摘要</summary>
现状的SOTA面 swap模型仍然受到两种问题的困扰：一是目标人脸特征（即形状）泄露，二是目标非人脸特征（如背景和 волосы）在最终结果中未能完全保留。我们显示出这种不足的分离是由两种不当的设计引起的：（1）通过单一压缩编码器来表示面部非人脸特征（即姿势）和像素级非人脸地方特征，这是不可能同时满足的；（2）高度依赖长跳转连接来传递编码器到最终生成器，这会带来一定程度的目标人脸标识泄露。为了解决这些问题，我们提出了一个新的面 swap框架 called 'WSC-swap'，它 eliminates skip connections and uses two target encoders to respectively capture the pixel-level non-facial region attributes and the semantic non-identity attributes in the face region. 为了进一步加强目标编码器的分离学习，我们采用了both identity removal loss via adversarial training（i.e., GAN）和非人脸保持损失 via prior 3DMM models like [11]. Our extensive experiments on both FaceForensics++ and CelebA-HQ show that our results significantly outperform previous works on a rich set of metrics, including one novel metric for measuring identity consistency that was completely neglected before.
</details></li>
</ul>
<hr>
<h2 id="RayMVSNet-Learning-Ray-based-1D-Implicit-Fields-for-Accurate-Multi-View-Stereo"><a href="#RayMVSNet-Learning-Ray-based-1D-Implicit-Fields-for-Accurate-Multi-View-Stereo" class="headerlink" title="RayMVSNet++: Learning Ray-based 1D Implicit Fields for Accurate Multi-View Stereo"></a>RayMVSNet++: Learning Ray-based 1D Implicit Fields for Accurate Multi-View Stereo</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.10233">http://arxiv.org/abs/2307.10233</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yifei Shi, Junhua Xi, Dewen Hu, Zhiping Cai, Kai Xu</li>
<li>for: 这个论文的目的是提出一种基于学习的多视图静止（MVS）方法，以提高多视图静止的精度和效率。</li>
<li>methods: 这个方法使用了直接优化每个摄像头光束上的深度值，模拟激光激光仪的距离测量。具体来说，它使用了序列预测方法，通过转换器特征来学习Sequential Modeling，实际上是多视图静止中的epipolar线搜索。</li>
<li>results: 这个方法在DTU和Tanks &amp; Temples数据集上达到了所有前一代学习基于方法的总重建得分0.33mm和F-score59.48%。它能够在复杂的景象中提供高质量的深度估计和点云重建。此外，提出了RayMVSNet++以增强每个光束的上下文特征聚合，通过设计了一个注意力阀unit来选择在本地折射镜附近的相关的邻居光束。RayMVSNet++在ScanNet数据集上达到了状态艺术性能。<details>
<summary>Abstract</summary>
Learning-based multi-view stereo (MVS) has by far centered around 3D convolution on cost volumes. Due to the high computation and memory consumption of 3D CNN, the resolution of output depth is often considerably limited. Different from most existing works dedicated to adaptive refinement of cost volumes, we opt to directly optimize the depth value along each camera ray, mimicking the range finding of a laser scanner. This reduces the MVS problem to ray-based depth optimization which is much more light-weight than full cost volume optimization. In particular, we propose RayMVSNet which learns sequential prediction of a 1D implicit field along each camera ray with the zero-crossing point indicating scene depth. This sequential modeling, conducted based on transformer features, essentially learns the epipolar line search in traditional multi-view stereo. We devise a multi-task learning for better optimization convergence and depth accuracy. We found the monotonicity property of the SDFs along each ray greatly benefits the depth estimation. Our method ranks top on both the DTU and the Tanks & Temples datasets over all previous learning-based methods, achieving an overall reconstruction score of 0.33mm on DTU and an F-score of 59.48% on Tanks & Temples. It is able to produce high-quality depth estimation and point cloud reconstruction in challenging scenarios such as objects/scenes with non-textured surface, severe occlusion, and highly varying depth range. Further, we propose RayMVSNet++ to enhance contextual feature aggregation for each ray through designing an attentional gating unit to select semantically relevant neighboring rays within the local frustum around that ray. RayMVSNet++ achieves state-of-the-art performance on the ScanNet dataset. In particular, it attains an AbsRel of 0.058m and produces accurate results on the two subsets of textureless regions and large depth variation.
</details>
<details>
<summary>摘要</summary>
学习基于多视图涂抹（MVS）的方法主要集中在3D convolution中的成本量和存储占用。由于3D CNN的计算和存储占用非常高，输出深度的分辨率经常受到限制。与大多数现有的成本量优化方法不同，我们直接优化摄像头方向上的深度值，模拟激光雷达扫描器的范围找寻。这将MVS问题降低到折线基于深度优化，与全成本量优化相比许多轻量级。特别是，我们提出了RayMVSNet，它通过学习每个摄像头方向上的1D隐函数来预测折线上的深度值，并在扫描器范围内查找零交叉点。这种顺序模型化，基于变换器特征，实际上学习了传统多视图涂抹中的epipolar线搜索。我们设计了多任务学习来改进优化的吞吐量和深度准确率。我们发现折线上SDF的 monotonicity 性帮助深度估计。我们的方法在DTU和Tanks & Temples数据集上至今为止的所有学习基于方法中排名第一，实现了总重建分数为0.33mm（DTU）和59.48%（Tanks & Temples）。它能够在物体/场景中的非杂表面、严重遮挡和高度变化的深度范围中生成高质量的深度估计和点云重建。此外，我们提出了RayMVSNet++，它通过设计了注意力闭合单元来选择当地frustum中的相互 relevante的折线，从而增强每个折线的上下文特征汇集。RayMVSNet++在ScanNet数据集上达到了状态的最佳性能，其中包括Textureless Regions和大深度变化两个子集。
</details></li>
</ul>
<hr>
<h2 id="On-the-Robustness-of-Split-Learning-against-Adversarial-Attacks"><a href="#On-the-Robustness-of-Split-Learning-against-Adversarial-Attacks" class="headerlink" title="On the Robustness of Split Learning against Adversarial Attacks"></a>On the Robustness of Split Learning against Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07916">http://arxiv.org/abs/2307.07916</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fmy266/SplitADV">https://github.com/fmy266/SplitADV</a></li>
<li>paper_authors: Mingyuan Fan, Cen Chen, Chengyu Wang, Wenmeng Zhou, Jun Huang</li>
<li>for: 证明分学可以增强模型安全性，尤其是在敏感数据不能直接分享的情况下。</li>
<li>methods: 通过分享部分模型和计算结果，而不是直接分享敏感数据和模型细节，来实现模型训练和共享。</li>
<li>results: 研究发现，对于敏感数据，分学可以减少对模型的攻击，但是在中间层级上的攻击仍然存在，并且可以通过新的攻击方法（SPADV）来证明这一点。<details>
<summary>Abstract</summary>
Split learning enables collaborative deep learning model training while preserving data privacy and model security by avoiding direct sharing of raw data and model details (i.e., sever and clients only hold partial sub-networks and exchange intermediate computations). However, existing research has mainly focused on examining its reliability for privacy protection, with little investigation into model security. Specifically, by exploring full models, attackers can launch adversarial attacks, and split learning can mitigate this severe threat by only disclosing part of models to untrusted servers.This paper aims to evaluate the robustness of split learning against adversarial attacks, particularly in the most challenging setting where untrusted servers only have access to the intermediate layers of the model.Existing adversarial attacks mostly focus on the centralized setting instead of the collaborative setting, thus, to better evaluate the robustness of split learning, we develop a tailored attack called SPADV, which comprises two stages: 1) shadow model training that addresses the issue of lacking part of the model and 2) local adversarial attack that produces adversarial examples to evaluate.The first stage only requires a few unlabeled non-IID data, and, in the second stage, SPADV perturbs the intermediate output of natural samples to craft the adversarial ones. The overall cost of the proposed attack process is relatively low, yet the empirical attack effectiveness is significantly high, demonstrating the surprising vulnerability of split learning to adversarial attacks.
</details>
<details>
<summary>摘要</summary>
分学习可以实现合作深度学习模型训练，同时保护数据隐私和模型安全，因为服务器和客户端只保持部分子网和交换中间计算。然而，现有研究主要关注隐私保护的可靠性，很少研究模型安全。Specifically, by exploring全模型，攻击者可以发起对抗性攻击，并且分学习可以 Mitigate this severe threat by only disclosing部分模型 to untrusted servers。本文的目的是评估分学习对抗性攻击的Robustness，特别是在最具挑战性的设定下，即无法信任服务器仅有访问模型中间层。现有的对抗性攻击主要集中在中央设定中，而不是合作设定，因此，为更好地评估分学习的Robustness，我们开发了一种适应攻击，称为SPADV。SPADV包括两个阶段：1）阴影模型训练，解决了因为缺少部分模型而产生的问题，2）本地对抗性攻击，生成对抗性样本来评估。在第一阶段，只需几个非相关的非ID数据，而在第二阶段，SPADV在自然样本中 Output的中间部分进行了预处理，以生成对抗性样本。整个攻击过程的总成本相对较低， yet the empirical attack effectiveness is significantly high，表明了分学习对抗性攻击的Surprising vulnerability。
</details></li>
</ul>
<hr>
<h2 id="Predicting-mechanical-properties-of-Carbon-Nanotube-CNT-images-Using-Multi-Layer-Synthetic-Finite-Element-Model-Simulations"><a href="#Predicting-mechanical-properties-of-Carbon-Nanotube-CNT-images-Using-Multi-Layer-Synthetic-Finite-Element-Model-Simulations" class="headerlink" title="Predicting mechanical properties of Carbon Nanotube (CNT) images Using Multi-Layer Synthetic Finite Element Model Simulations"></a>Predicting mechanical properties of Carbon Nanotube (CNT) images Using Multi-Layer Synthetic Finite Element Model Simulations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07912">http://arxiv.org/abs/2307.07912</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaveh Safavigerdini, Koundinya Nouduri, Ramakrishna Surya, Andrew Reinhard, Zach Quinlan, Filiz Bunyak, Matthew R. Maschmann, Kannappan Palaniappan</li>
<li>For: The paper is written for predicting mechanical properties of vertically-oriented carbon nanotube (CNT) forest images using a deep learning model for artificial intelligence (AI)-based materials discovery.* Methods: The paper uses an innovative data augmentation technique that involves the use of multi-layer synthetic (MLS) or quasi-2.5D images, which are generated by blending 2D synthetic images. The paper also uses a physics-based model to estimate mechanical properties such as stiffness and buckling load for the MLS images. The proposed deep learning architecture, CNTNeXt, builds upon the previous CNTNet neural network, using a ResNeXt feature representation followed by random forest regression estimator.* Results: The paper expects the proposed machine learning approach to outperform single synthetic image-based learning when it comes to predicting mechanical properties of real scanning electron microscopy images. This has the potential to accelerate understanding and control of CNT forest self-assembly for diverse applications.Here are the three points in Simplified Chinese text:* For: 这篇论文是为了预测垂直方向碳纳米管（CNT）森林图像的机械性能使用深度学习模型进行人工智能（AI）基于材料发现。* Methods: 论文使用了一种创新的数据增强技术，利用多层合成（MLS）或 quasi-2.5D 图像，这些图像是通过拼接2D synthetic图像来生成。 MLs 图像更像真实的扫描电子显微镜（SEM）图像，但不需要进行expensive的3D simulations或实验。机械性能如强度和折倒荷重等被使用物理基本模型来估算。* Results: 论文预计该提出的机器学习方法会在真实SEM图像上预测机械性能时比单个synthetic图像基本学习更高效。这有可能加速CNT森林自组装的理解和控制，以推动多种应用。<details>
<summary>Abstract</summary>
We present a pipeline for predicting mechanical properties of vertically-oriented carbon nanotube (CNT) forest images using a deep learning model for artificial intelligence (AI)-based materials discovery. Our approach incorporates an innovative data augmentation technique that involves the use of multi-layer synthetic (MLS) or quasi-2.5D images which are generated by blending 2D synthetic images. The MLS images more closely resemble 3D synthetic and real scanning electron microscopy (SEM) images of CNTs but without the computational cost of performing expensive 3D simulations or experiments. Mechanical properties such as stiffness and buckling load for the MLS images are estimated using a physics-based model. The proposed deep learning architecture, CNTNeXt, builds upon our previous CNTNet neural network, using a ResNeXt feature representation followed by random forest regression estimator. Our machine learning approach for predicting CNT physical properties by utilizing a blended set of synthetic images is expected to outperform single synthetic image-based learning when it comes to predicting mechanical properties of real scanning electron microscopy images. This has the potential to accelerate understanding and control of CNT forest self-assembly for diverse applications.
</details>
<details>
<summary>摘要</summary>
我们提出了一个管道，用于预测纵向碳纳米管（CNT）森林图像中的机械性能，使用深度学习模型，以实现人工智能（AI）基于材料发现。我们的方法包括一种创新的数据增强技术，使用多层合成（MLS）或 quasi-2.5D 图像，这些图像由混合2D 合成图像来生成。MLS 图像更加closely resemble 3D 合成和实验室扫描电子镜像（SEM）图像，但没有 computationally expensive 3D  simulations 或实验的成本。机械性能，如刚性和塌笔荷，对 MLS 图像进行估算，使用物理基础模型。我们提出的深度学习架构，CNTNeXt，基于我们之前的 CNTNet 神经网络，使用 ResNeXt 特征表示，然后使用随机森林回归估计器。我们的机器学习方法，通过使用混合的合成图像来预测 CNT 物理性能，对于实验室扫描电子镜像图像的机械性能预测，具有更高的性能，相比单个合成图像基于学习。这有助于加速理解和控制 CNT 森林自组装的应用。
</details></li>
</ul>
<hr>
<h2 id="Multitemporal-SAR-images-change-detection-and-visualization-using-RABASAR-and-simplified-GLR"><a href="#Multitemporal-SAR-images-change-detection-and-visualization-using-RABASAR-and-simplified-GLR" class="headerlink" title="Multitemporal SAR images change detection and visualization using RABASAR and simplified GLR"></a>Multitemporal SAR images change detection and visualization using RABASAR and simplified GLR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07892">http://arxiv.org/abs/2307.07892</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weiying Zhao, Charles-Alban Deledalle, Loïc Denis, Henri Maître, Jean-Marie Nicolas, Florence Tupin</li>
<li>for: 本研究旨在检测不同类型的地表变化，以便对地面监测进行更好的准备。</li>
<li>methods: 本研究提出了一种简化了通量比（SGLR）方法，假设同时间像素具有相同的等效数目（ENL）。此外，还开发了一种改进的光谱划分法以确定变化类型。</li>
<li>results: 研究人员通过处理模拟和SAR图像，并与传统方法进行比较，证明了提案方法的效果性。特别是，数值实验表明，该方法可以有效地检测农田地区变化、建筑地区变化、港区变化和洪涝变化。<details>
<summary>Abstract</summary>
Understanding the state of changed areas requires that precise information be given about the changes. Thus, detecting different kinds of changes is important for land surface monitoring. SAR sensors are ideal to fulfil this task, because of their all-time and all-weather capabilities, with good accuracy of the acquisition geometry and without effects of atmospheric constituents for amplitude data. In this study, we propose a simplified generalized likelihood ratio ($S_{GLR}$) method assuming that corresponding temporal pixels have the same equivalent number of looks (ENL). Thanks to the denoised data provided by a ratio-based multitemporal SAR image denoising method (RABASAR), we successfully applied this similarity test approach to compute the change areas. A new change magnitude index method and an improved spectral clustering-based change classification method are also developed. In addition, we apply the simplified generalized likelihood ratio to detect the maximum change magnitude time, and the change starting and ending times. Then, we propose to use an adaptation of the REACTIV method to visualize the detection results vividly. The effectiveness of the proposed methods is demonstrated through the processing of simulated and SAR images, and the comparison with classical techniques. In particular, numerical experiments proved that the developed method has good performances in detecting farmland area changes, building area changes, harbour area changes and flooding area changes.
</details>
<details>
<summary>摘要</summary>
理解改变区域的状态需要提供精确的改变信息。因此，检测不同类型的改变是重要的 для地面监测。SAR探测器是理想的选择，因为它们在任何时间和天气条件下都有good accuracy的获取geometry和无 atmospheric constituents的影响。在这项研究中，我们提出了一种简化了通用类比比率（SGLR）方法，假设同一时间的批量像素具有相同的等效数量looks（ENL）。经过了 ratio-based multitemporal SAR图像减噪方法（RABASAR）提供的净化数据，我们成功地应用了这种相似测试方法来计算改变区域。此外，我们还开发了一种改进的光谱分类法来分类改变，以及一种最大变化强度时间、改变开始和结束时间的检测方法。最后，我们使用了一种基于REACTIV方法的修改来可见化检测结果。我们通过处理 simulated和SAR图像，以及与传统技术进行比较，证明了我们提出的方法的有效性。具体来说，数值实验表明，我们的方法在检测农田改变、建筑改变、港口改变和洪涝改变方面具有良好的表现。
</details></li>
</ul>
<hr>
<h2 id="Why-Does-Little-Robustness-Help-Understanding-Adversarial-Transferability-From-Surrogate-Training"><a href="#Why-Does-Little-Robustness-Help-Understanding-Adversarial-Transferability-From-Surrogate-Training" class="headerlink" title="Why Does Little Robustness Help? Understanding Adversarial Transferability From Surrogate Training"></a>Why Does Little Robustness Help? Understanding Adversarial Transferability From Surrogate Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07873">http://arxiv.org/abs/2307.07873</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yechao Zhang, Shengshan Hu, Leo Yu Zhang, Junyu Shi, Minghui Li, Xiaogeng Liu, Wei Wan, Hai Jin</li>
<li>for: 本研究的目的是解释对深度神经网络（DNNs）的抗击例（Adversarial Examples，AE）的传播性。</li>
<li>methods: 本研究使用了一系列的理论和实验分析，以了解在对DNNs进行对抗性训练时，模型的平滑性和梯度相似性之间的负相关性。</li>
<li>results: 研究发现，在对DNNs进行对抗性训练时，数据分布shift和梯度相似性之间存在负相关性。此外，研究还发现，通过控制数据分布shift和梯度regularization，可以构建更好的代理模型，以提高对抗性训练的传播性。<details>
<summary>Abstract</summary>
Adversarial examples (AEs) for DNNs have been shown to be transferable: AEs that successfully fool white-box surrogate models can also deceive other black-box models with different architectures. Although a bunch of empirical studies have provided guidance on generating highly transferable AEs, many of these findings lack explanations and even lead to inconsistent advice. In this paper, we take a further step towards understanding adversarial transferability, with a particular focus on surrogate aspects. Starting from the intriguing little robustness phenomenon, where models adversarially trained with mildly perturbed adversarial samples can serve as better surrogates, we attribute it to a trade-off between two predominant factors: model smoothness and gradient similarity. Our investigations focus on their joint effects, rather than their separate correlations with transferability. Through a series of theoretical and empirical analyses, we conjecture that the data distribution shift in adversarial training explains the degradation of gradient similarity. Building on these insights, we explore the impacts of data augmentation and gradient regularization on transferability and identify that the trade-off generally exists in the various training mechanisms, thus building a comprehensive blueprint for the regulation mechanism behind transferability. Finally, we provide a general route for constructing better surrogates to boost transferability which optimizes both model smoothness and gradient similarity simultaneously, e.g., the combination of input gradient regularization and sharpness-aware minimization (SAM), validated by extensive experiments. In summary, we call for attention to the united impacts of these two factors for launching effective transfer attacks, rather than optimizing one while ignoring the other, and emphasize the crucial role of manipulating surrogate models.
</details>
<details>
<summary>摘要</summary>
adversarial examples (AEs) for DNNs have been shown to be transferable: AEs that successfully fool white-box surrogate models can also deceive other black-box models with different architectures. Although a bunch of empirical studies have provided guidance on generating highly transferable AEs, many of these findings lack explanations and even lead to inconsistent advice. In this paper, we take a further step towards understanding adversarial transferability, with a particular focus on surrogate aspects. Starting from the intriguing little robustness phenomenon, where models adversarially trained with mildly perturbed adversarial samples can serve as better surrogates, we attribute it to a trade-off between two predominant factors: model smoothness and gradient similarity. Our investigations focus on their joint effects, rather than their separate correlations with transferability. Through a series of theoretical and empirical analyses, we conjecture that the data distribution shift in adversarial training explains the degradation of gradient similarity. Building on these insights, we explore the impacts of data augmentation and gradient regularization on transferability and identify that the trade-off generally exists in the various training mechanisms, thus building a comprehensive blueprint for the regulation mechanism behind transferability. Finally, we provide a general route for constructing better surrogates to boost transferability which optimizes both model smoothness and gradient similarity simultaneously, e.g., the combination of input gradient regularization and sharpness-aware minimization (SAM), validated by extensive experiments. In summary, we call for attention to the united impacts of these two factors for launching effective transfer attacks, rather than optimizing one while ignoring the other, and emphasize the crucial role of manipulating surrogate models.
</details></li>
</ul>
<hr>
<h2 id="Unified-Adversarial-Patch-for-Cross-modal-Attacks-in-the-Physical-World"><a href="#Unified-Adversarial-Patch-for-Cross-modal-Attacks-in-the-Physical-World" class="headerlink" title="Unified Adversarial Patch for Cross-modal Attacks in the Physical World"></a>Unified Adversarial Patch for Cross-modal Attacks in the Physical World</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07859">http://arxiv.org/abs/2307.07859</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xingxing Wei, Yao Huang, Yitong Sun, Jie Yu<br>for:  This paper aims to demonstrate the potential risks of physical adversarial attacks on object detectors that use both visible and infrared sensors.methods:  The authors propose a unified adversarial patch that can fool both visible and infrared object detectors simultaneously, using a single patch. They design a novel boundary-limited shape optimization method to achieve compact and smooth shapes, and propose a score-aware iterative evaluation to balance the fooling degree between the two sensors.results:  The authors achieve an Attack Success Rate (ASR) of 73.33% and 69.17% against one-stage and two-stage object detectors, respectively. They also verify the effective attacks in the physical world under various settings, such as different angles, distances, postures, and scenes.<details>
<summary>Abstract</summary>
Recently, physical adversarial attacks have been presented to evade DNNs-based object detectors. To ensure the security, many scenarios are simultaneously deployed with visible sensors and infrared sensors, leading to the failures of these single-modal physical attacks. To show the potential risks under such scenes, we propose a unified adversarial patch to perform cross-modal physical attacks, i.e., fooling visible and infrared object detectors at the same time via a single patch. Considering different imaging mechanisms of visible and infrared sensors, our work focuses on modeling the shapes of adversarial patches, which can be captured in different modalities when they change. To this end, we design a novel boundary-limited shape optimization to achieve the compact and smooth shapes, and thus they can be easily implemented in the physical world. In addition, to balance the fooling degree between visible detector and infrared detector during the optimization process, we propose a score-aware iterative evaluation, which can guide the adversarial patch to iteratively reduce the predicted scores of the multi-modal sensors. We finally test our method against the one-stage detector: YOLOv3 and the two-stage detector: Faster RCNN. Results show that our unified patch achieves an Attack Success Rate (ASR) of 73.33% and 69.17%, respectively. More importantly, we verify the effective attacks in the physical world when visible and infrared sensors shoot the objects under various settings like different angles, distances, postures, and scenes.
</details>
<details>
<summary>摘要</summary>
最近，物理攻击被提出以逃脱基于DNN的物体检测器。为确保安全，许多场景同时使用可见感知器和红外感知器，导致单模态物理攻击失败。为了表明这些场景下的风险，我们提议一种横跨模态物理攻击，即通过单个贴图 Fooled 可见和红外检测器。considering 不同的感知机制，我们的工作专注于模型适应器形状的设计，这些形状可以在不同的感知器下被捕捉。为此，我们设计了一种 novel 边界限定的形状优化方法，以实现紧凑和平滑的形状，这些形状可以轻松地在物理世界中实现。此外，为保证可见检测器和红外检测器在优化过程中的攻击度差异，我们提议一种分数感知迭代评估，可以导引攻击贴图在迭代过程中逐渐减少多模检测器的预测分数。最后，我们对 YOLOv3 和 Faster RCNN 进行测试，结果显示我们的横跨模态贴图可以在不同的角度、距离、姿态和场景下实现73.33% 和 69.17% 的攻击成功率。更重要的是，我们在物理世界中验证了这些攻击的有效性，当可见和红外感知器在不同的设置下拍摄对象时。
</details></li>
</ul>
<hr>
<h2 id="Neural-Video-Recovery-for-Cloud-Gaming"><a href="#Neural-Video-Recovery-for-Cloud-Gaming" class="headerlink" title="Neural Video Recovery for Cloud Gaming"></a>Neural Video Recovery for Cloud Gaming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07847">http://arxiv.org/abs/2307.07847</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/neurons">https://github.com/Aryia-Behroziuan/neurons</a></li>
<li>paper_authors: Zhaoyuan He, Yifan Yang, Shuozhe Li, Diyuan Dai, Lili Qiu</li>
<li>for: 提高云游戏的视频恢复精度和效率</li>
<li>methods: 使用游戏状态提高视频恢复精度，使用部分解码视频快速恢复失去的视频帧</li>
<li>results: 在iPhone 12和笔记机实现中，证明了使用游戏状态提高视频恢复精度，并且实现了高效的视频恢复Here is the translation in Simplified Chinese:</li>
<li>for: 提高云游戏的视频恢复精度和效率</li>
<li>methods: 使用游戏状态提高视频恢复精度，使用部分解码视频快速恢复失去的视频帧</li>
<li>results: 在iPhone 12和笔记机实现中，证明了使用游戏状态提高视频恢复精度，并且实现了高效的视频恢复<details>
<summary>Abstract</summary>
Cloud gaming is a multi-billion dollar industry. A client in cloud gaming sends its movement to the game server on the Internet, which renders and transmits the resulting video back. In order to provide a good gaming experience, a latency below 80 ms is required. This means that video rendering, encoding, transmission, decoding, and display have to finish within that time frame, which is especially challenging to achieve due to server overload, network congestion, and losses. In this paper, we propose a new method for recovering lost or corrupted video frames in cloud gaming. Unlike traditional video frame recovery, our approach uses game states to significantly enhance recovery accuracy and utilizes partially decoded frames to recover lost portions. We develop a holistic system that consists of (i) efficiently extracting game states, (ii) modifying H.264 video decoder to generate a mask to indicate which portions of video frames need recovery, and (iii) designing a novel neural network to recover either complete or partial video frames. Our approach is extensively evaluated using iPhone 12 and laptop implementations, and we demonstrate the utility of game states in the game video recovery and the effectiveness of our overall design.
</details>
<details>
<summary>摘要</summary>
云台游戏是一个多百亿美元的业态。客户端在云台游戏中将其运动发送到游戏服务器上，服务器在互联网上渲染和传输结果，并将视频传输回客户端。为提供良好的游戏体验，云台游戏中的延迟必须低于80ms。这意味着视频渲染、编码、传输、解码和显示必须在这个时间段内完成，这是特别困难的因为服务器过载、网络压力和损失。在这篇论文中，我们提出了一种新的视频帧恢复方法，与传统视频帧恢复方法不同，我们的方法使用游戏状态进行明显提高恢复精度，并使用部分解码的帧来恢复丢失的部分。我们设计了一个整体系统，包括(i)高效地提取游戏状态，(ii)修改H.264视频解码器生成一个抑制器，用于指示需要恢复的视频帧部分，以及(iii)设计一种新的神经网络来恢复完整或部分的视频帧。我们的方法在iPhone 12和笔记机实现中进行了广泛的评估，并证明游戏状态在游戏视频恢复中的重要性以及我们的总体设计的有效性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/16/cs.CV_2023_07_16/" data-id="clly4xtcx003xvl8841ee3gqf" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_07_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/16/cs.LG_2023_07_16/" class="article-date">
  <time datetime="2023-07-15T16:00:00.000Z" itemprop="datePublished">2023-07-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/16/cs.LG_2023_07_16/">cs.LG - 2023-07-16 18:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Dataset-Distillation-Meets-Provable-Subset-Selection"><a href="#Dataset-Distillation-Meets-Provable-Subset-Selection" class="headerlink" title="Dataset Distillation Meets Provable Subset Selection"></a>Dataset Distillation Meets Provable Subset Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08086">http://arxiv.org/abs/2307.08086</a></li>
<li>repo_url: None</li>
<li>paper_authors: Murad Tukan, Alaa Maalouf, Margarita Osadchy</li>
<li>for: 提高 dataset distillation 的效果，减少数据量和计算成本。</li>
<li>methods: 使用 sampling-based 方法初始化 distilled set，并在训练过程中使用 importance 定义来选择数据集。</li>
<li>results: 实验结果表明，我们的方法可以启用 exiting dataset distillation 技术，并提高其性能。<details>
<summary>Abstract</summary>
Deep learning has grown tremendously over recent years, yielding state-of-the-art results in various fields. However, training such models requires huge amounts of data, increasing the computational time and cost. To address this, dataset distillation was proposed to compress a large training dataset into a smaller synthetic one that retains its performance -- this is usually done by (1) uniformly initializing a synthetic set and (2) iteratively updating/learning this set according to a predefined loss by uniformly sampling instances from the full data. In this paper, we improve both phases of dataset distillation: (1) we present a provable, sampling-based approach for initializing the distilled set by identifying important and removing redundant points in the data, and (2) we further merge the idea of data subset selection with dataset distillation, by training the distilled set on ``important'' sampled points during the training procedure instead of randomly sampling the next batch. To do so, we define the notion of importance based on the relative contribution of instances with respect to two different loss functions, i.e., one for the initialization phase (a kernel fitting function for kernel ridge regression and $K$-means based loss function for any other distillation method), and the relative cross-entropy loss (or any other predefined loss) function for the training phase. Finally, we provide experimental results showing how our method can latch on to existing dataset distillation techniques and improve their performance.
</details>
<details>
<summary>摘要</summary>
深度学习在最近几年内发展 extremely rapidly，在不同领域取得了状态的艺术 Results。然而，训练这些模型需要巨量数据和计算资源，这导致了训练时间和成本的增加。为解决这个问题，人们提出了数据集缩写，将大量的训练数据缩写成一个更小的合成数据集，保持其性能。在这篇论文中，我们改进了两个数据集缩写阶段：1. 我们提出了一种可证明的抽样方法，通过重要性分析和减少数据中的重复项来初始化缩写集。2. 我们进一步将数据subset选择纳入数据集缩写，在训练过程中使用“重要”的抽样点训练缩写集而不是随机抽样下一个批。我们定义了“重要”的概念，根据数据点对两个不同的损失函数（一个是 kernel ridge regression 和 $K$-means 基于损失函数，另一个是距离损失函数）的相对贡献来确定。最后，我们提供了实验结果，证明我们的方法可以与现有的数据集缩写技术相结合，提高其性能。
</details></li>
</ul>
<hr>
<h2 id="POMDP-inference-and-robust-solution-via-deep-reinforcement-learning-An-application-to-railway-optimal-maintenance"><a href="#POMDP-inference-and-robust-solution-via-deep-reinforcement-learning-An-application-to-railway-optimal-maintenance" class="headerlink" title="POMDP inference and robust solution via deep reinforcement learning: An application to railway optimal maintenance"></a>POMDP inference and robust solution via deep reinforcement learning: An application to railway optimal maintenance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08082">http://arxiv.org/abs/2307.08082</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/giarcieri/robust-optimal-maintenance-planning-through-reinforcement-learning-and-rllib">https://github.com/giarcieri/robust-optimal-maintenance-planning-through-reinforcement-learning-and-rllib</a></li>
<li>paper_authors: Giacomo Arcieri, Cyprien Hoelzl, Oliver Schwery, Daniel Straub, Konstantinos G. Papakonstantinou, Eleni Chatzi</li>
<li>for: 这项研究的目的是提出一种 combining framework for inference and robust solution of POMDPs via deep RL, 用于解决复杂的顺序决策问题在不确定环境中。</li>
<li>methods: 该framework包括使用Markov Chain Monte Carlo sampling来 JOINTLYINFER transition和observation模型参数，然后使用深度学习技术解决POMDP问题，并通过域随机化将参数 Distributions incorporated into the solution。</li>
<li>results: 该研究 comparing the use of transformers和long short-term memory networks，以及model-based&#x2F;model-free hybrid approach，并应用于实际世界的轨道资产维护规划问题。<details>
<summary>Abstract</summary>
Partially Observable Markov Decision Processes (POMDPs) can model complex sequential decision-making problems under stochastic and uncertain environments. A main reason hindering their broad adoption in real-world applications is the lack of availability of a suitable POMDP model or a simulator thereof. Available solution algorithms, such as Reinforcement Learning (RL), require the knowledge of the transition dynamics and the observation generating process, which are often unknown and non-trivial to infer. In this work, we propose a combined framework for inference and robust solution of POMDPs via deep RL. First, all transition and observation model parameters are jointly inferred via Markov Chain Monte Carlo sampling of a hidden Markov model, which is conditioned on actions, in order to recover full posterior distributions from the available data. The POMDP with uncertain parameters is then solved via deep RL techniques with the parameter distributions incorporated into the solution via domain randomization, in order to develop solutions that are robust to model uncertainty. As a further contribution, we compare the use of transformers and long short-term memory networks, which constitute model-free RL solutions, with a model-based/model-free hybrid approach. We apply these methods to the real-world problem of optimal maintenance planning for railway assets.
</details>
<details>
<summary>摘要</summary>
In this work, we propose a combined framework for inferring and solving POMDPs via deep RL. First, all transition and observation model parameters are jointly inferred via Markov Chain Monte Carlo (MCMC) sampling of a hidden Markov model (HMM), conditioned on actions, to recover full posterior distributions from the available data. The POMDP with uncertain parameters is then solved via deep RL techniques, with the parameter distributions incorporated into the solution via domain randomization, to develop solutions that are robust to model uncertainty.As a further contribution, we compare the use of transformers and long short-term memory (LSTM) networks, which constitute model-free RL solutions, with a model-based/model-free hybrid approach. We apply these methods to the real-world problem of optimal maintenance planning for railway assets.
</details></li>
</ul>
<hr>
<h2 id="Flexible-and-efficient-spatial-extremes-emulation-via-variational-autoencoders"><a href="#Flexible-and-efficient-spatial-extremes-emulation-via-variational-autoencoders" class="headerlink" title="Flexible and efficient spatial extremes emulation via variational autoencoders"></a>Flexible and efficient spatial extremes emulation via variational autoencoders</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08079">http://arxiv.org/abs/2307.08079</a></li>
<li>repo_url: None</li>
<li>paper_authors: Likun Zhang, Xiaoyu Ma, Christopher K. Wikle, Raphaël Huser</li>
<li>for: 用于模elling Complex 的 spatial extremes 性质</li>
<li>methods: 使用 encoding-decoding 结构的 variational autoencoder (extVAE)</li>
<li>results: 可以更快和更高精度地 simulate  spatial extremes 模型输出，并且可以更好地 capture  tail 部分的性质<details>
<summary>Abstract</summary>
Many real-world processes have complex tail dependence structures that cannot be characterized using classical Gaussian processes. More flexible spatial extremes models such as Gaussian scale mixtures and single-station conditioning models exhibit appealing extremal dependence properties but are often exceedingly prohibitive to fit and simulate from. In this paper, we develop a new spatial extremes model that has flexible and non-stationary dependence properties, and we integrate it in the encoding-decoding structure of a variational autoencoder (extVAE). The extVAE can be used as a spatio-temporal emulator that characterizes the distribution of potential mechanistic model output states and produces outputs that have the same properties as the inputs, especially in the tail. Through extensive simulation studies, we show that our extVAE is vastly more time-efficient than traditional Bayesian inference while also outperforming many spatial extremes models with a stationary dependence structure. To further demonstrate the computational power of the extVAE, we analyze a high-resolution satellite-derived dataset of sea surface temperature in the Red Sea, which includes daily measurements at 16703 grid cells.
</details>
<details>
<summary>摘要</summary>
很多现实世界的过程都具有复杂的尾部依赖结构，不能使用传统的 Gaussian 过程来描述。更灵活的 spatial extremes 模型，如 Gaussian scale mixtures 和 single-station conditioning models，具有吸引人的极端依赖性质，但是常常非常困难 fitted 和 simulate from。在这篇论文中，我们开发了一种新的 spatial extremes 模型，具有灵活和非站ary 的依赖性质。我们将其集成到 encoding-decoding 结构中，并将其用作一种 spatio-temporal emulator，可以Characterizes the distribution of potential mechanistic model output states and produces outputs that have the same properties as the inputs, especially in the tail.通过广泛的 simulations 研究，我们表明我们的 extVAE 在时间效率方面远胜传统的 Bayesian inference，同时也能够超越许多 stationary 的 spatial extremes 模型。为了进一步展示 extVAE 的计算能力，我们分析了一个高分辨率的卫星Derived 数据集，包括每天 measurement 的 16703 个网格单元的 sea surface temperature 在红海。
</details></li>
</ul>
<hr>
<h2 id="MaGNAS-A-Mapping-Aware-Graph-Neural-Architecture-Search-Framework-for-Heterogeneous-MPSoC-Deployment"><a href="#MaGNAS-A-Mapping-Aware-Graph-Neural-Architecture-Search-Framework-for-Heterogeneous-MPSoC-Deployment" class="headerlink" title="MaGNAS: A Mapping-Aware Graph Neural Architecture Search Framework for Heterogeneous MPSoC Deployment"></a>MaGNAS: A Mapping-Aware Graph Neural Architecture Search Framework for Heterogeneous MPSoC Deployment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08065">http://arxiv.org/abs/2307.08065</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohanad Odema, Halima Bouzidi, Hamza Ouarnoughi, Smail Niar, Mohammad Abdullah Al Faruque</li>
<li>for: 这 paper 是为了提高图像推理 tasks 的性能和能效性而设计的。</li>
<li>methods: 该 paper 使用了一种叫做 MaGNAS 的图 neural architecture search 框架，该框架可以在多处理器系统上（SoC）上进行图 neural network 的设计和映射。</li>
<li>results:  experiments 表明，使用 MaGNAS 可以在 NVIDIA Xavier AGX 平台上提高图像推理 tasks 的性能和能效性，比基eline 的 GPU-only 部署提高 1.57 倍的延迟速度和 3.38 倍的能效率，同时保持平均的准确率下降 0.11%。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) are becoming increasingly popular for vision-based applications due to their intrinsic capacity in modeling structural and contextual relations between various parts of an image frame. On another front, the rising popularity of deep vision-based applications at the edge has been facilitated by the recent advancements in heterogeneous multi-processor Systems on Chips (MPSoCs) that enable inference under real-time, stringent execution requirements. By extension, GNNs employed for vision-based applications must adhere to the same execution requirements. Yet contrary to typical deep neural networks, the irregular flow of graph learning operations poses a challenge to running GNNs on such heterogeneous MPSoC platforms. In this paper, we propose a novel unified design-mapping approach for efficient processing of vision GNN workloads on heterogeneous MPSoC platforms. Particularly, we develop MaGNAS, a mapping-aware Graph Neural Architecture Search framework. MaGNAS proposes a GNN architectural design space coupled with prospective mapping options on a heterogeneous SoC to identify model architectures that maximize on-device resource efficiency. To achieve this, MaGNAS employs a two-tier evolutionary search to identify optimal GNNs and mapping pairings that yield the best performance trade-offs. Through designing a supernet derived from the recent Vision GNN (ViG) architecture, we conducted experiments on four (04) state-of-the-art vision datasets using both (i) a real hardware SoC platform (NVIDIA Xavier AGX) and (ii) a performance/cost model simulator for DNN accelerators. Our experimental results demonstrate that MaGNAS is able to provide 1.57x latency speedup and is 3.38x more energy-efficient for several vision datasets executed on the Xavier MPSoC vs. the GPU-only deployment while sustaining an average 0.11% accuracy reduction from the baseline.
</details>
<details>
<summary>摘要</summary>
图 neural network (GNN) 在视觉应用中日益受欢迎，因为它们可以自然地模型图像帧中不同部分之间的结构和上下文关系。另一方面，由于近期的深度视觉应用在边缘得到了广泛的应用，因此GNN在这些应用中必须遵循同样的执行要求。然而，与普通的深度神经网络不同，图学习操作的不规则流动对于运行GNN在多核心系统中带来了挑战。在这篇论文中，我们提出了一种统一的设计映射方法，用于有效地处理视觉GNN工作负荷在多核心系统上。特别是，我们开发了MaGNAS，一个具有Mapping-Aware Graph Neural Architecture Search（MaGNAS）框架。MaGNAS将GNN建立的建筑设计空间与多核心SoC上的可能的映射选项相结合，以便标识最佳的设备资源利用率。为了实现这一点，MaGNAS采用了两层演化搜索，以确定最佳的GNN和映射对的性能交互。通过基于最近的Vision GNN（ViG）架构设计了一个超网，我们在四个state-of-the-art视觉数据集上进行了实验。我们的实验结果表明，MaGNAS能够提供1.57倍的延迟速度提升和3.38倍的能量效率提升，而在NVIDIA Xavier AGX多核心系统上执行视觉数据集时与GPU-only部署相比，保持了0.11%的准确率下降。
</details></li>
</ul>
<hr>
<h2 id="Fast-Quantum-Algorithm-for-Attention-Computation"><a href="#Fast-Quantum-Algorithm-for-Attention-Computation" class="headerlink" title="Fast Quantum Algorithm for Attention Computation"></a>Fast Quantum Algorithm for Attention Computation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08045">http://arxiv.org/abs/2307.08045</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yeqi Gao, Zhao Song, Xin Yang, Ruizhe Zhang</li>
<li>for: 大型自然语言处理（NLP）模型（LLMs）的性能表现出色，它们通过高级深度学习技术得到了广泛应用。</li>
<li>methods: 本研究使用Grover搜寻算法来高效 Compute sparse attention computation matrix。</li>
<li>results: 我们的量子算法可以取得 polynomial 的速度提升，并且 attention matrix 具有Extra low-rank 结构，可以帮助获得更快的 LLM 训练算法。<details>
<summary>Abstract</summary>
Large language models (LLMs) have demonstrated exceptional performance across a wide range of tasks. These models, powered by advanced deep learning techniques, have revolutionized the field of natural language processing (NLP) and have achieved remarkable results in various language-related tasks.   LLMs have excelled in tasks such as machine translation, sentiment analysis, question answering, text generation, text classification, language modeling, and more. They have proven to be highly effective in capturing complex linguistic patterns, understanding context, and generating coherent and contextually relevant text. The attention scheme plays a crucial role in the architecture of large language models (LLMs). It is a fundamental component that enables the model to capture and utilize contextual information during language processing tasks effectively. Making the attention scheme computation faster is one of the central questions to speed up the LLMs computation. It is well-known that quantum machine has certain computational advantages compared to the classical machine. However, it is currently unknown whether quantum computing can aid in LLM.   In this work, we focus on utilizing Grover's Search algorithm to compute a sparse attention computation matrix efficiently. We achieve a polynomial quantum speed-up over the classical method. Moreover, the attention matrix outputted by our quantum algorithm exhibits an extra low-rank structure that will be useful in obtaining a faster training algorithm for LLMs. Additionally, we present a detailed analysis of the algorithm's error analysis and time complexity within the context of computing the attention matrix.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）在各种语言处理任务中表现出色，应用先进的深度学习技术。这些模型在机器翻译、情感分析、问答、文本生成、文本分类、语言模型等任务中均有卓越表现。它们能够吸收复杂的语言模式，理解上下文，并生成具有上下文相关性的文本。模型中的注意力结构是重要的基本 ком成分，它在语言处理任务中实现了效果。目前，尚未知道Quantum computing是否可以应用于LLM。在这个工作中，我们专注于使用Grover搜寻算法计算稀疏注意力computation матриrice，以取得高效的量子速度优化。我们获得了对级数方法的多项式优化，并且注意力矩阵的出力显示了额外的低维结构，这将会帮助获得更快的LLM训练算法。此外，我们还提供了计算注意力矩阵的错误分析和时间复杂度分析。
</details></li>
</ul>
<hr>
<h2 id="Towards-Flexible-Time-to-event-Modeling-Optimizing-Neural-Networks-via-Rank-Regression"><a href="#Towards-Flexible-Time-to-event-Modeling-Optimizing-Neural-Networks-via-Rank-Regression" class="headerlink" title="Towards Flexible Time-to-event Modeling: Optimizing Neural Networks via Rank Regression"></a>Towards Flexible Time-to-event Modeling: Optimizing Neural Networks via Rank Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08044">http://arxiv.org/abs/2307.08044</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/teboozas/dart_ecai23">https://github.com/teboozas/dart_ecai23</a></li>
<li>paper_authors: Hyunjun Lee, Junhyun Lee, Taehwa Choi, Jaewoo Kang, Sangbum Choi</li>
<li>for: 预测时间事件发生的时间点 (predicting the time of occurrence of an event)</li>
<li>methods: 使用深度学习模型，基于Gehan的排名统计 (using a deep learning model based on Gehan’s rank statistic)</li>
<li>results: 在多个 benchmark 数据集上实现了显著的提升，无需额外参数或复杂的模型架构 (achieved significant improvements on multiple benchmark datasets without additional hyperparameters or complex model architectures)<details>
<summary>Abstract</summary>
Time-to-event analysis, also known as survival analysis, aims to predict the time of occurrence of an event, given a set of features. One of the major challenges in this area is dealing with censored data, which can make learning algorithms more complex. Traditional methods such as Cox's proportional hazards model and the accelerated failure time (AFT) model have been popular in this field, but they often require assumptions such as proportional hazards and linearity. In particular, the AFT models often require pre-specified parametric distributional assumptions. To improve predictive performance and alleviate strict assumptions, there have been many deep learning approaches for hazard-based models in recent years. However, representation learning for AFT has not been widely explored in the neural network literature, despite its simplicity and interpretability in comparison to hazard-focused methods. In this work, we introduce the Deep AFT Rank-regression model for Time-to-event prediction (DART). This model uses an objective function based on Gehan's rank statistic, which is efficient and reliable for representation learning. On top of eliminating the requirement to establish a baseline event time distribution, DART retains the advantages of directly predicting event time in standard AFT models. The proposed method is a semiparametric approach to AFT modeling that does not impose any distributional assumptions on the survival time distribution. This also eliminates the need for additional hyperparameters or complex model architectures, unlike existing neural network-based AFT models. Through quantitative analysis on various benchmark datasets, we have shown that DART has significant potential for modeling high-throughput censored time-to-event data.
</details>
<details>
<summary>摘要</summary>
时间到事分析（也称为存存分析）的目标是预测事件发生的时间， givens 一组特征。 这个领域的一个主要挑战是处理 censored 数据，可以使学习算法更加复杂。传统方法 such as Cox 的对数加速破碎模型和加速失败时间（AFT）模型在这个领域非常受欢迎，但它们经常需要假设，例如对比例的危险和线性。特别是 AF 模型经常需要预先指定的参数分布假设。为了提高预测性能和缓解严格假设，在过去的几年中有很多深度学习方法在预测 hazard-based 模型中得到应用。然而， representation learning 在神经网络文献中对 AFT 模型的应用还很少，尽管它在比较简单和可读性方面比 hazard-focused 方法更有优势。在这项工作中，我们介绍了 Deep AFT Rank-regression 模型（DART），这个模型使用基于 Gehan 排名统计的目标函数，这是一种高效的 representation learning 方法。在 eliminating the requirement to establish a baseline event time distribution 的同时，DART 保留了标准 AFT 模型中的优点，直接预测事件时间。我们的提案的方法是一种 semi-parametric AFT 模型，不需要任何参数分布假设，这也消除了需要额外的 гипер Parameters 或复杂的模型架构，与现有的神经网络基于 AFT 模型不同。通过对各种 benchmark 数据进行量化分析，我们表明了 DART 在高通过率 censored time-to-event 数据模型中具有显著的潜力。
</details></li>
</ul>
<hr>
<h2 id="Bivariate-DeepKriging-for-Large-scale-Spatial-Interpolation-of-Wind-Fields"><a href="#Bivariate-DeepKriging-for-Large-scale-Spatial-Interpolation-of-Wind-Fields" class="headerlink" title="Bivariate DeepKriging for Large-scale Spatial Interpolation of Wind Fields"></a>Bivariate DeepKriging for Large-scale Spatial Interpolation of Wind Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08038">http://arxiv.org/abs/2307.08038</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pratik Nag, Ying Sun, Brian J Reich</li>
<li>for: 这篇论文旨在提供一种高精度风场数据的大规模插值或降阶方法，用于气象、海洋学和气候研究等领域。</li>
<li>methods: 本文提出了一种称为“深度拟合”的方法，它是一个具有空间对预的深度神经网络，具有空间对预的嵌入层，用于预测二维空间资料。</li>
<li>results: 比较traditional cokriging预测器，深度拟合方法的预测性能更高，且可以快速 Compute，实现高效的数据预测。在中东地区506,771个位置上应用了深度拟合方法，结果表明其预测性能佳，且大大减少了计算时间。<details>
<summary>Abstract</summary>
High spatial resolution wind data are essential for a wide range of applications in climate, oceanographic and meteorological studies. Large-scale spatial interpolation or downscaling of bivariate wind fields having velocity in two dimensions is a challenging task because wind data tend to be non-Gaussian with high spatial variability and heterogeneity. In spatial statistics, cokriging is commonly used for predicting bivariate spatial fields. However, the cokriging predictor is not optimal except for Gaussian processes. Additionally, cokriging is computationally prohibitive for large datasets. In this paper, we propose a method, called bivariate DeepKriging, which is a spatially dependent deep neural network (DNN) with an embedding layer constructed by spatial radial basis functions for bivariate spatial data prediction. We then develop a distribution-free uncertainty quantification method based on bootstrap and ensemble DNN. Our proposed approach outperforms the traditional cokriging predictor with commonly used covariance functions, such as the linear model of co-regionalization and flexible bivariate Mat\'ern covariance. We demonstrate the computational efficiency and scalability of the proposed DNN model, with computations that are, on average, 20 times faster than those of conventional techniques. We apply the bivariate DeepKriging method to the wind data over the Middle East region at 506,771 locations. The prediction performance of the proposed method is superior over the cokriging predictors and dramatically reduces computation time.
</details>
<details>
<summary>摘要</summary>
高空间分辨率风数据是气候、海洋学和气象研究中的重要工具。大规模的风场 interpolación或下采样是一项复杂的任务，因为风数据往往非 Gaussian 分布，具有高空间变化和不均匀性。在空间统计中，cokriging 是广泛使用的方法，但predictor 不是优化的，除非使用 Gaussian 过程。此外，cokriging 对大量数据来说是计算昂贵的。在这篇论文中，我们提出了一种方法，即双向 DeepKriging，它是一种具有空间依赖性的双向深度神经网络（DNN），其中 embedding 层由空间径向基函数构建。我们然后开发了一种不含分布的不确定性评估方法，基于 bootstrap 和集成 DNN。我们的提出的方法在传统的 cokriging 预测器中超越了常用的 covariance 函数，如线性模型协调和灵活的双向 Matér  covariance。我们 demonstate 了我们的 DNN 模型的计算效率和可扩展性，计算时间比传统技术平均快20倍。我们应用了双向 DeepKriging 方法于中东地区的风数据，包括506,771个位置。我们的预测性能较传统的 cokriging 预测器更高，计算时间减少了90%。
</details></li>
</ul>
<hr>
<h2 id="Magnetic-Field-Based-Reward-Shaping-for-Goal-Conditioned-Reinforcement-Learning"><a href="#Magnetic-Field-Based-Reward-Shaping-for-Goal-Conditioned-Reinforcement-Learning" class="headerlink" title="Magnetic Field-Based Reward Shaping for Goal-Conditioned Reinforcement Learning"></a>Magnetic Field-Based Reward Shaping for Goal-Conditioned Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08033">http://arxiv.org/abs/2307.08033</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongyu Ding, Yuanze Tang, Qing Wu, Bo Wang, Chunlin Chen, Zhi Wang</li>
<li>for: 提高目标填充RL任务中样本效率，即使面临动态环境和奖励稀缺。</li>
<li>methods: 基于磁场的奖励定制（MFRS）方法，通过将目标和障碍物视为常见磁铁，根据磁场强度的非线性和不规则分布来设置奖励函数。</li>
<li>results: 在 simulate 和实际 робо控任务中，MFRS 比相关现有方法更高效，可以有效提高RL算法在目标填充任务中的样本效率，并且可以适应不同的目标和障碍物动态。<details>
<summary>Abstract</summary>
Goal-conditioned reinforcement learning (RL) is an interesting extension of the traditional RL framework, where the dynamic environment and reward sparsity can cause conventional learning algorithms to fail. Reward shaping is a practical approach to improving sample efficiency by embedding human domain knowledge into the learning process. Existing reward shaping methods for goal-conditioned RL are typically built on distance metrics with a linear and isotropic distribution, which may fail to provide sufficient information about the ever-changing environment with high complexity. This paper proposes a novel magnetic field-based reward shaping (MFRS) method for goal-conditioned RL tasks with dynamic target and obstacles. Inspired by the physical properties of magnets, we consider the target and obstacles as permanent magnets and establish the reward function according to the intensity values of the magnetic field generated by these magnets. The nonlinear and anisotropic distribution of the magnetic field intensity can provide more accessible and conducive information about the optimization landscape, thus introducing a more sophisticated magnetic reward compared to the distance-based setting. Further, we transform our magnetic reward to the form of potential-based reward shaping by learning a secondary potential function concurrently to ensure the optimal policy invariance of our method. Experiments results in both simulated and real-world robotic manipulation tasks demonstrate that MFRS outperforms relevant existing methods and effectively improves the sample efficiency of RL algorithms in goal-conditioned tasks with various dynamics of the target and obstacles.
</details>
<details>
<summary>摘要</summary>
traditional reinforcement learning（RL）框架中的目标条件RL是一种有趣的扩展，因为动态环境和奖励稀缺可能使得传统的学习算法失效。奖励形成是一种实用的方法来提高样本效率，其中将人类领域知识 embed 到学习过程中。现有的奖励形成方法 для goal-conditioned RL 通常基于距离度量，这可能无法提供动态环境中的高复杂性所需的充分信息。这篇论文提出了一种基于磁场的奖励形成（MFRS）方法，用于goal-conditioned RL 任务中的动态目标和障碍物。我们根据物体的物理性质，将目标和障碍物视为永久磁铁，并根据这些磁铁生成的磁场强度设置奖励函数。非线性和不均匀的磁场强度分布可以提供更多的可访问和渠道化信息关于优化地图，因此引入一种更加复杂的磁奖。此外，我们将我们的磁奖转换为 potential-based 奖励形成，通过同时学习次要潜在函数来确保我们的方法的优化策略不变性。实验结果表明，MFRS在模拟和实际 робоック抓取任务中表现出色，超越了相关的现有方法，并有效地提高了RL算法在目标条件下的样本效率。
</details></li>
</ul>
<hr>
<h2 id="Noise-aware-Speech-Enhancement-using-Diffusion-Probabilistic-Model"><a href="#Noise-aware-Speech-Enhancement-using-Diffusion-Probabilistic-Model" class="headerlink" title="Noise-aware Speech Enhancement using Diffusion Probabilistic Model"></a>Noise-aware Speech Enhancement using Diffusion Probabilistic Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08029">http://arxiv.org/abs/2307.08029</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yuchen005/nase">https://github.com/yuchen005/nase</a></li>
<li>paper_authors: Yuchen Hu, Chen Chen, Ruizhe Li, Qiushi Zhu, Eng Siong Chng</li>
<li>for: 提高扩散模型下的生成散音增强（SE）性能，尤其是对于未经测试的噪声。</li>
<li>methods: 提出一种基于噪声特征的散音增强（NASE）方法，通过EXTRACTING噪声特征来导引反推进程。同时，提出一种多任务学习方案，以 JOINTLY 优化 SE 和 NC 任务，以提高噪声特征的提取精度。</li>
<li>results: 实验证明，NASE 可以与多种主流扩散 SE 模型结合使用，并在 VoiceBank-DEMAND 数据集上显示出显著提高，特别是对于未经测试的噪声。<details>
<summary>Abstract</summary>
With recent advances of diffusion model, generative speech enhancement (SE) has attracted a surge of research interest due to its great potential for unseen testing noises. However, existing efforts mainly focus on inherent properties of clean speech for inference, underexploiting the varying noise information in real-world conditions. In this paper, we propose a noise-aware speech enhancement (NASE) approach that extracts noise-specific information to guide the reverse process in diffusion model. Specifically, we design a noise classification (NC) model to produce acoustic embedding as a noise conditioner for guiding the reverse denoising process. Meanwhile, a multi-task learning scheme is devised to jointly optimize SE and NC tasks, in order to enhance the noise specificity of extracted noise conditioner. Our proposed NASE is shown to be a plug-and-play module that can be generalized to any diffusion SE models. Experiment evidence on VoiceBank-DEMAND dataset shows that NASE achieves significant improvement over multiple mainstream diffusion SE models, especially on unseen testing noises.
</details>
<details>
<summary>摘要</summary>
Recent advances in diffusion models have led to a surge of research interest in generative speech enhancement (SE) due to its great potential for unseen testing noises. However, existing efforts primarily focus on the inherent properties of clean speech for inference, neglecting the varying noise information in real-world conditions. In this paper, we propose a noise-aware speech enhancement (NASE) approach that extracts noise-specific information to guide the reverse process in the diffusion model. Specifically, we design a noise classification (NC) model to produce an acoustic embedding as a noise conditioner for guiding the reverse denoising process. Moreover, we devise a multi-task learning scheme to jointly optimize the SE and NC tasks, enhancing the noise specificity of the extracted noise conditioner. Our proposed NASE is shown to be a plug-and-play module that can be generalized to any diffusion SE models. Experimental evidence on the VoiceBank-DEMAND dataset demonstrates that NASE achieves significant improvement over multiple mainstream diffusion SE models, especially on unseen testing noises.
</details></li>
</ul>
<hr>
<h2 id="Revisiting-Implicit-Models-Sparsity-Trade-offs-Capability-in-Weight-tied-Model-for-Vision-Tasks"><a href="#Revisiting-Implicit-Models-Sparsity-Trade-offs-Capability-in-Weight-tied-Model-for-Vision-Tasks" class="headerlink" title="Revisiting Implicit Models: Sparsity Trade-offs Capability in Weight-tied Model for Vision Tasks"></a>Revisiting Implicit Models: Sparsity Trade-offs Capability in Weight-tied Model for Vision Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08013">http://arxiv.org/abs/2307.08013</a></li>
<li>repo_url: None</li>
<li>paper_authors: Haobo Song, Soumajit Majumder, Tao Lin</li>
<li>for: 该文章旨在探讨隐式模型（DEQs）在视觉任务上的表现，以及其相对于其他方法的比较。</li>
<li>methods: 该文章使用Weight-tied模型，并对其进行了深入研究，以及提出了使用特异 sparse masks 来提高模型容量。</li>
<li>results: 研究发现，Weight-tied模型在视觉任务上比DEQ variants更有效稳定，并且可以更好地 generalized to other learning paradigms。<details>
<summary>Abstract</summary>
Implicit models such as Deep Equilibrium Models (DEQs) have garnered significant attention in the community for their ability to train infinite layer models with elegant solution-finding procedures and constant memory footprint. However, despite several attempts, these methods are heavily constrained by model inefficiency and optimization instability. Furthermore, fair benchmarking across relevant methods for vision tasks is missing. In this work, we revisit the line of implicit models and trace them back to the original weight-tied models. Surprisingly, we observe that weight-tied models are more effective, stable, as well as efficient on vision tasks, compared to the DEQ variants. Through the lens of these simple-yet-clean weight-tied models, we further study the fundamental limits in the model capacity of such models and propose the use of distinct sparse masks to improve the model capacity. Finally, for practitioners, we offer design guidelines regarding the depth, width, and sparsity selection for weight-tied models, and demonstrate the generalizability of our insights to other learning paradigms.
</details>
<details>
<summary>摘要</summary>
匿名模型（DEQs）在社区中受到了广泛关注，因为它们可以训练无穷层模型，并且拥有简洁的解决方案和常量内存占用。然而，虽然有几次尝试，但这些方法受到了模型不充分利用和优化不稳定的限制。此外，对于视觉任务的比较是缺失的。在这项工作中，我们回顾了匿名模型的线索，并发现Weight-tied模型在视觉任务上更有效率、稳定、并且更高效。通过这些简单而干净的Weight-tied模型，我们进一步研究了这些模型的基本限制，并提出了使用特定的稀疏mask来提高模型容量。最后，我们对于实践者提供了depth、宽和稀疏选择的设计指南，并证明了我们的理解在其他学习方法上也是可行。
</details></li>
</ul>
<hr>
<h2 id="For-One-Shot-Decoding-Self-supervised-Deep-Learning-Based-Polar-Decoder"><a href="#For-One-Shot-Decoding-Self-supervised-Deep-Learning-Based-Polar-Decoder" class="headerlink" title="For One-Shot Decoding: Self-supervised Deep Learning-Based Polar Decoder"></a>For One-Shot Decoding: Self-supervised Deep Learning-Based Polar Decoder</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08004">http://arxiv.org/abs/2307.08004</a></li>
<li>repo_url: None</li>
<li>paper_authors: Huiying Song, Yihao Luo, Yuma Fukuzawa</li>
<li>for: 实现一种基于深度学习的排序码解码方案，具有一次解码功能。</li>
<li>methods: 透过自动化学习并利用生成矩阵来训练神经网络，将神经网络训练为bounded distance解码器。</li>
<li>results: Computer simulations show that the proposed scheme can achieve similar performance to the maximum a posteriori (MAP) decoder for very short packets, and the proposed neural network decoder (NND) has better generalization ability than the conventional one.<details>
<summary>Abstract</summary>
We propose a self-supervised deep learning-based decoding scheme that enables one-shot decoding of polar codes. In the proposed scheme, rather than using the information bit vectors as labels for training the neural network (NN) through supervised learning as the conventional scheme did, the NN is trained to function as a bounded distance decoder by leveraging the generator matrix of polar codes through self-supervised learning. This approach eliminates the reliance on predefined labels, empowering the potential to train directly on the actual data within communication systems and thereby enhancing the applicability. Furthermore, computer simulations demonstrate that (i) the bit error rate (BER) and block error rate (BLER) performances of the proposed scheme can approach those of the maximum a posteriori (MAP) decoder for very short packets and (ii) the proposed NN decoder (NND) exhibits much superior generalization ability compared to the conventional one.
</details>
<details>
<summary>摘要</summary>
我们提出一种自动超vised深度学习的解码方案，可以实现一击解码楔形码。在我们的方案中，而不是通过指定标签来用深度学习训练神经网络（NN），就是通过楔形码生成矩阵自我超vised学习训练NN。这种方法消除了靠定标签的依赖，使得可以直接在通信系统中训练NN，从而提高可用性。此外，计算机实验表明，（i）提案的方案可以在很短的包长度下达到MAP解码器的比Error rate和块Error rate性能，（ii）提案的NN解码器（NND）在对比传统方法的情况下显示出了很好的泛化能力。
</details></li>
</ul>
<hr>
<h2 id="Joint-Microseismic-Event-Detection-and-Location-with-a-Detection-Transformer"><a href="#Joint-Microseismic-Event-Detection-and-Location-with-a-Detection-Transformer" class="headerlink" title="Joint Microseismic Event Detection and Location with a Detection Transformer"></a>Joint Microseismic Event Detection and Location with a Detection Transformer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.09207">http://arxiv.org/abs/2307.09207</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuanyuan Yang, Claire Birnie, Tariq Alkhalifah</li>
<li>for: 这个研究旨在提出一个能够同时探测和定位微地震事件的方法，以实现实时微地震监控。</li>
<li>methods: 本研究使用了卷积神经网和Encoder-Decoder Transformer，并应用了一个基于集合的匈牙利损失函数，以直接处理录取到的波形资料。</li>
<li>results: 实验结果显示，提案的方法能够正确地探测和定位微地震事件，并且在实际应用中能够获得高效和可靠的结果。<details>
<summary>Abstract</summary>
Microseismic event detection and location are two primary components in microseismic monitoring, which offers us invaluable insights into the subsurface during reservoir stimulation and evolution. Conventional approaches for event detection and location often suffer from manual intervention and/or heavy computation, while current machine learning-assisted approaches typically address detection and location separately; such limitations hinder the potential for real-time microseismic monitoring. We propose an approach to unify event detection and source location into a single framework by adapting a Convolutional Neural Network backbone and an encoder-decoder Transformer with a set-based Hungarian loss, which is applied directly to recorded waveforms. The proposed network is trained on synthetic data simulating multiple microseismic events corresponding to random source locations in the area of suspected microseismic activities. A synthetic test on a 2D profile of the SEAM Time Lapse model illustrates the capability of the proposed method in detecting the events properly and locating them in the subsurface accurately; while, a field test using the Arkoma Basin data further proves its practicability, efficiency, and its potential in paving the way for real-time monitoring of microseismic events.
</details>
<details>
<summary>摘要</summary>
微型地震事件检测和定位是微型地震监测的两个关键组成部分，它为我们提供了无价的地层下预测和演化的准确信息。传统的方法通常受到人工干预和/或重量计算的限制，而当前的机器学习帮助的方法通常分别处理检测和定位，这些限制了实时微型地震监测的可能性。我们提出了一种将事件检测和源位置嵌入到同一个框架中的方法，通过采用卷积神经网络背景和encoder-decoder转换器，并使用集合基于hungarian损失函数进行训练。该网络在记录波形上直接应用。我们对多个微型地震事件的同时发生进行了synthetic数据生成，并在2DProfile上进行了一个synthetic测试，这些测试结果表明了我们的方法可以正确地检测事件并准确地定位其位置在地层下。此外，我们还对Arkoma Basin数据进行了一个实际测试，这些测试结果表明了我们的方法的实用性、效率和实时监测微型地震事件的潜在性。
</details></li>
</ul>
<hr>
<h2 id="LUCYD-A-Feature-Driven-Richardson-Lucy-Deconvolution-Network"><a href="#LUCYD-A-Feature-Driven-Richardson-Lucy-Deconvolution-Network" class="headerlink" title="LUCYD: A Feature-Driven Richardson-Lucy Deconvolution Network"></a>LUCYD: A Feature-Driven Richardson-Lucy Deconvolution Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07998">http://arxiv.org/abs/2307.07998</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ctom2/lucyd-deconvolution">https://github.com/ctom2/lucyd-deconvolution</a></li>
<li>paper_authors: Tomáš Chobola, Gesine Müller, Veit Dausmann, Anton Theileis, Jan Taucher, Jan Huisken, Tingying Peng</li>
<li>for: 提高微scopic图像质量和可读性</li>
<li>methods: 结合Richardson-Lucy方程和深度学习特征，提出了一种基于特征驱动的图像恢复模型</li>
<li>results: 对于synthetic和实际微scopic图像，LUCYD方法表现出色，提高图像质量和一致性，并且可以处理不同的微scopic模式和捕捉条件。<details>
<summary>Abstract</summary>
The process of acquiring microscopic images in life sciences often results in image degradation and corruption, characterised by the presence of noise and blur, which poses significant challenges in accurately analysing and interpreting the obtained data. This paper proposes LUCYD, a novel method for the restoration of volumetric microscopy images that combines the Richardson-Lucy deconvolution formula and the fusion of deep features obtained by a fully convolutional network. By integrating the image formation process into a feature-driven restoration model, the proposed approach aims to enhance the quality of the restored images whilst reducing computational costs and maintaining a high degree of interpretability. Our results demonstrate that LUCYD outperforms the state-of-the-art methods in both synthetic and real microscopy images, achieving superior performance in terms of image quality and generalisability. We show that the model can handle various microscopy modalities and different imaging conditions by evaluating it on two different microscopy datasets, including volumetric widefield and light-sheet microscopy. Our experiments indicate that LUCYD can significantly improve resolution, contrast, and overall quality of microscopy images. Therefore, it can be a valuable tool for microscopy image restoration and can facilitate further research in various microscopy applications. We made the source code for the model accessible under https://github.com/ctom2/lucyd-deconvolution.
</details>
<details>
<summary>摘要</summary>
生物科学中获取微型图像的过程经常会导致图像异常和损害，表现为图像噪声和模糊，这会对数据分析和解释提出 significiant 挑战。这篇论文提出了一种名为LUCYD的新方法，用于修复Volume Microscopy 图像。该方法结合了Richardson-Lucy 减 convolution 方程和基于深度学习的卷积网络来提高图像的品质。通过将图像形成过程包含在一个特征驱动的修复模型中，该方法希望提高修复后图像的质量，同时降低计算成本并保持高度可读性。我们的结果表明，LUCYD 在 synthetic 和实际 Microscopy 图像中都超过了现有方法的性能，在图像质量和泛化性方面表现出色。我们通过评估其在不同 Microscopy 模式和拍摄条件下的表现，发现LUCYD 可以处理不同的 Microscopy 模式和拍摄条件。我们的实验表明，LUCYD 可以显著提高 Microscopy 图像的分辨率、对比度和整体质量。因此，它可以成为 Microscopy 图像修复的有价值工具，并促进了不同 Microscopy 应用的进一步研究。我们将模型的源代码公开在 <https://github.com/ctom2/lucyd-deconvolution> 上。
</details></li>
</ul>
<hr>
<h2 id="MargCTGAN-A-“Marginally’’-Better-CTGAN-for-the-Low-Sample-Regime"><a href="#MargCTGAN-A-“Marginally’’-Better-CTGAN-for-the-Low-Sample-Regime" class="headerlink" title="MargCTGAN: A “Marginally’’ Better CTGAN for the Low Sample Regime"></a>MargCTGAN: A “Marginally’’ Better CTGAN for the Low Sample Regime</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07997">http://arxiv.org/abs/2307.07997</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/tejuafonja/margctgan">https://github.com/tejuafonja/margctgan</a></li>
<li>paper_authors: Tejumade Afonja, Dingfan Chen, Mario Fritz</li>
<li>for: This paper is written for evaluating the effectiveness of synthetic tabular data generation methods, specifically in low sample scenarios, and addressing the oversight of neglecting statistical properties in current evaluation methods.</li>
<li>methods: The paper uses three state-of-the-art synthetic tabular data generators, including CTGAN, and evaluates their performance based on marginal distribution, column-pair correlation, joint distribution, and downstream task utility. The proposed MargCTGAN model adds feature matching of de-correlated marginals to improve the statistical properties and downstream utility of the synthetic data.</li>
<li>results: The paper shows that CTGAN underperforms in low sample settings in terms of utility, but the proposed MargCTGAN model consistently improves downstream utility as well as statistical properties of the synthetic data.<details>
<summary>Abstract</summary>
The potential of realistic and useful synthetic data is significant. However, current evaluation methods for synthetic tabular data generation predominantly focus on downstream task usefulness, often neglecting the importance of statistical properties. This oversight becomes particularly prominent in low sample scenarios, accompanied by a swift deterioration of these statistical measures. In this paper, we address this issue by conducting an evaluation of three state-of-the-art synthetic tabular data generators based on their marginal distribution, column-pair correlation, joint distribution and downstream task utility performance across high to low sample regimes. The popular CTGAN model shows strong utility, but underperforms in low sample settings in terms of utility. To overcome this limitation, we propose MargCTGAN that adds feature matching of de-correlated marginals, which results in a consistent improvement in downstream utility as well as statistical properties of the synthetic data.
</details>
<details>
<summary>摘要</summary>
现实生成的数据的潜在价值很大。然而，目前的生成synthetic tabular数据的评估方法主要关注下游任务的有用性，经常忽略了统计性质的重要性。这种欠缺特别在低样本情况下显著，同时这些统计度量快速下降。在这篇论文中，我们解决这个问题，通过评估三种现状最佳的synthetic tabular数据生成器的边缘分布、列对协同分布、共同分布和下游任务有用性的表现，从高样本到低样本的场景中进行评估。CTGAN模型在下游任务上表现良好，但在低样本情况下表现不佳，其 Utility 下降。为了解决这个限制，我们提议MargCTGAN，它通过匹配特征的分布，使得下游任务的有用性和统计性质都得到了改进。
</details></li>
</ul>
<hr>
<h2 id="CoNAN-Conditional-Neural-Aggregation-Network-For-Unconstrained-Face-Feature-Fusion"><a href="#CoNAN-Conditional-Neural-Aggregation-Network-For-Unconstrained-Face-Feature-Fusion" class="headerlink" title="CoNAN: Conditional Neural Aggregation Network For Unconstrained Face Feature Fusion"></a>CoNAN: Conditional Neural Aggregation Network For Unconstrained Face Feature Fusion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.10237">http://arxiv.org/abs/2307.10237</a></li>
<li>repo_url: None</li>
<li>paper_authors: Bhavin Jawade, Deen Dayal Mohan, Dennis Fedorishin, Srirangaraj Setlur, Venu Govindaraju</li>
<li>for: 长距离、低分辨率、不同视角、照明、姿势和 atmospheric conditions 下的面部识别，提高face recognition的精度和可靠性。</li>
<li>methods: 基于面部特征的分布信息来Conditioning，通过学习一个context vector来对特征进行权重调整，以提高face recognition的精度和可靠性。</li>
<li>results: 在BTS和DroneSURF等长距离未控制的面部识别数据集上达到了state-of-the-art的结果，证明了我们的方法的优势。<details>
<summary>Abstract</summary>
Face recognition from image sets acquired under unregulated and uncontrolled settings, such as at large distances, low resolutions, varying viewpoints, illumination, pose, and atmospheric conditions, is challenging. Face feature aggregation, which involves aggregating a set of N feature representations present in a template into a single global representation, plays a pivotal role in such recognition systems. Existing works in traditional face feature aggregation either utilize metadata or high-dimensional intermediate feature representations to estimate feature quality for aggregation. However, generating high-quality metadata or style information is not feasible for extremely low-resolution faces captured in long-range and high altitude settings. To overcome these limitations, we propose a feature distribution conditioning approach called CoNAN for template aggregation. Specifically, our method aims to learn a context vector conditioned over the distribution information of the incoming feature set, which is utilized to weigh the features based on their estimated informativeness. The proposed method produces state-of-the-art results on long-range unconstrained face recognition datasets such as BTS, and DroneSURF, validating the advantages of such an aggregation strategy.
</details>
<details>
<summary>摘要</summary>
面部识别从图像集中获取在无法控制的设置下进行，如在远距离、低分辨率、不同视点、照明、姿势和大气条件下，是有挑战的。在这些识别系统中，面部特征聚合起important role，即将一个模板中的多个特征表示聚合到一个全局表示中。现有的传统面部特征聚合方法可以通过metadata或高维度中间特征表示来估计特征质量进行聚合。然而，在EXTREMELY LOW-RESOLUTION的脸部图像中，生成高质量的metadata或样式信息是不可能的。为了突破这些限制，我们提出了一种特征分布条件的方法called CoNAN для模板聚合。具体来说，我们的方法是学习一个conditioned over the distribution information of the incoming feature set，用于对特征进行权重调整基于估计的有用性。我们的方法在long-range和高高度设置下的无结构化脸部识别数据集，如BTS和DroneSURF， producessate-of-the-art结果，证明了such an aggregation strategy的优势。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-of-Techniques-for-Optimizing-Transformer-Inference"><a href="#A-Survey-of-Techniques-for-Optimizing-Transformer-Inference" class="headerlink" title="A Survey of Techniques for Optimizing Transformer Inference"></a>A Survey of Techniques for Optimizing Transformer Inference</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07982">http://arxiv.org/abs/2307.07982</a></li>
<li>repo_url: None</li>
<li>paper_authors: Krishna Teja Chitty-Venkata, Sparsh Mittal, Murali Emani, Venkatram Vishwanath, Arun K. Somani</li>
<li>for: 本文旨在把transformer网络的推理阶段优化技术综述一下，以便为研究人员和学生提供一个全面的参考。</li>
<li>methods: 本文总结了多种优化技术，包括知识传承、剪枝、量化、神经网络搜索和特征硬件设计等，以提高transformer网络的推理效率。</li>
<li>results: 本文对多种模型和技术进行了评估，并展示了它们的数据量和精度之间的质量评估。同时，本文还预测了未来这一领域的发展趋势。<details>
<summary>Abstract</summary>
Recent years have seen a phenomenal rise in performance and applications of transformer neural networks. The family of transformer networks, including Bidirectional Encoder Representations from Transformer (BERT), Generative Pretrained Transformer (GPT) and Vision Transformer (ViT), have shown their effectiveness across Natural Language Processing (NLP) and Computer Vision (CV) domains. Transformer-based networks such as ChatGPT have impacted the lives of common men. However, the quest for high predictive performance has led to an exponential increase in transformers' memory and compute footprint. Researchers have proposed techniques to optimize transformer inference at all levels of abstraction. This paper presents a comprehensive survey of techniques for optimizing the inference phase of transformer networks. We survey techniques such as knowledge distillation, pruning, quantization, neural architecture search and lightweight network design at the algorithmic level. We further review hardware-level optimization techniques and the design of novel hardware accelerators for transformers. We summarize the quantitative results on the number of parameters/FLOPs and accuracy of several models/techniques to showcase the tradeoff exercised by them. We also outline future directions in this rapidly evolving field of research. We believe that this survey will educate both novice and seasoned researchers and also spark a plethora of research efforts in this field.
</details>
<details>
<summary>摘要</summary>
近年来，变换神经网络家族，包括矢量代码表（BERT）、生成预训练变换网络（GPT）和视觉转换网络（ViT），在自然语言处理（NLP）和计算机视觉（CV）领域中表现出色。变换网络如ChatGPT对公众生活产生了深远的影响。然而，为了 достичь高预测性能，变换网络的内存和计算核心覆盖面积呈极值增长趋势。研究人员提出了优化变换推理阶段的多种技术。本文对优化变换网络推理阶段的技术进行了全面的检视，包括知识储存、剪辑、量化、神经网络搜索和轻量级网络设计等算法级别的技术。此外，我们还评估硬件级别的优化技术和专门为变换网络设计的新硬件加速器。我们对多种模型和技术的参数/计算量和准确率进行了评量分析，并对这些技术的许多特点进行了详细的描述。我们还预测未来这一领域的发展趋势。我们相信，这篇评论将为初学者和季读者都提供深刻的了解，并且将激发这一领域的大量研究。
</details></li>
</ul>
<hr>
<h2 id="Byzantine-Robust-Distributed-Online-Learning-Taming-Adversarial-Participants-in-An-Adversarial-Environment"><a href="#Byzantine-Robust-Distributed-Online-Learning-Taming-Adversarial-Participants-in-An-Adversarial-Environment" class="headerlink" title="Byzantine-Robust Distributed Online Learning: Taming Adversarial Participants in An Adversarial Environment"></a>Byzantine-Robust Distributed Online Learning: Taming Adversarial Participants in An Adversarial Environment</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07980">http://arxiv.org/abs/2307.07980</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wanger521/ogd">https://github.com/wanger521/ogd</a></li>
<li>paper_authors: Xingrong Dong, Zhaoxian Wu, Qing Ling, Zhi Tian</li>
<li>for: 这个论文研究了分布式在线学习下的拜尼袭击问题。</li>
<li>methods: 该论文使用了一种robust aggregation rule，并提出了一种Byzantine-robust分布式在线摘要算法来实现sublinear的权衡误差 bound。</li>
<li>results: 该论文证明了，即使使用State-of-the-art robust aggregation rule，分布式在线学习仍然只能实现线性的拜尼袭击 regret bound，这是不可避免的。但是，当环境不完全是敌对的，即honest participant的损失是独立同分布的时，我们可以实现sublinear的随机误差 bound。<details>
<summary>Abstract</summary>
This paper studies distributed online learning under Byzantine attacks. The performance of an online learning algorithm is often characterized by (adversarial) regret, which evaluates the quality of one-step-ahead decision-making when an environment provides adversarial losses, and a sublinear bound is preferred. But we prove that, even with a class of state-of-the-art robust aggregation rules, in an adversarial environment and in the presence of Byzantine participants, distributed online gradient descent can only achieve a linear adversarial regret bound, which is tight. This is the inevitable consequence of Byzantine attacks, even though we can control the constant of the linear adversarial regret to a reasonable level. Interestingly, when the environment is not fully adversarial so that the losses of the honest participants are i.i.d. (independent and identically distributed), we show that sublinear stochastic regret, in contrast to the aforementioned adversarial regret, is possible. We develop a Byzantine-robust distributed online momentum algorithm to attain such a sublinear stochastic regret bound. Extensive numerical experiments corroborate our theoretical analysis.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Finite-element-inspired-networks-Learning-physically-plausible-deformable-object-dynamics-from-partial-observations"><a href="#Finite-element-inspired-networks-Learning-physically-plausible-deformable-object-dynamics-from-partial-observations" class="headerlink" title="Finite element inspired networks: Learning physically-plausible deformable object dynamics from partial observations"></a>Finite element inspired networks: Learning physically-plausible deformable object dynamics from partial observations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07975">http://arxiv.org/abs/2307.07975</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shamil Mamedov, A. René Geist, Jan Swevers, Sebastian Trimpe</li>
<li>For: The paper aims to develop a human-interpretable and data-efficient model for simulating the dynamics of deformable linear objects (DLOs).* Methods: The authors draw inspiration from the rigid finite element method (R-FEM) and model a DLO as a serial chain of rigid bodies whose internal state is unrolled through time by a dynamics network. They train the dynamics network jointly with a physics-informed encoder to ensure that the state representation is physically meaningful.* Results: The authors demonstrate the effectiveness of their approach in a robot experiment, showing that the “Finite element inspired network” (FEN) forms a capable DLO dynamics model that yields physically interpretable predictions from partial observations.Here’s the information in Simplified Chinese text:</li>
<li>for: 该文章目标是开发一种可以快速预测并具有人类可读性的材料线性对象动力学模型。</li>
<li>methods: 作者们引入了刚体Finite element方法（R-FEM），将材料线性对象模型为一串连接的刚体体 whose internal state通过时间的推进。他们将动力学网络与物理学习编码器同时训练，以确保状态表示具有物理意义。</li>
<li>results: 作者们在Robot实验中展示了他们的方法的效果，显示了”Finite element inspired network”（FEN）可以快速预测材料线性对象动力学行为，并且从部分观察数据中获得物理意义的预测结果。<details>
<summary>Abstract</summary>
The accurate simulation of deformable linear object (DLO) dynamics is challenging if the task at hand requires a human-interpretable and data-efficient model that also yields fast predictions. To arrive at such model, we draw inspiration from the rigid finite element method (R-FEM) and model a DLO as a serial chain of rigid bodies whose internal state is unrolled through time by a dynamics network. As this state is not observed directly, the dynamics network is trained jointly with a physics-informed encoder mapping observed motion variables to the body chain's state. To encourage that the state acquires a physically meaningful representation, we leverage the forward kinematics (FK) of the underlying R-FEM model as a decoder. We demonstrate in a robot experiment that this architecture - being termed "Finite element inspired network" - forms an easy to handle, yet capable DLO dynamics model yielding physically interpretable predictions from partial observations.   The project code is available at: \url{https://tinyurl.com/fei-networks}
</details>
<details>
<summary>摘要</summary>
对于不可归纳的线性物体（DLO）动力学的准确模拟是一项挑战，特别是当需要一个人类可读的和数据效率的模型，同时还需要快速预测。为了实现这种模型，我们从可变finite element方法（R-FEM）中继承灵感，将DLO表示为一串连续的刚体体 whose internal state是通过时间的卷积来实现的。由于这个状态不直接可见，因此我们将动力网络与物理学整体编码器一起训练，以将观察到的动作变量映射到body链的状态上。为了使状态具有物理意义，我们利用了下行骨干（FK）的前向几何学模型作为解码器。我们在Robot实验中展示了这种架构，称之为"finite element inspired network"，可以提供容易处理、具有物理解释能力的DLO动力学模型，从部分观察数据中提取物理意义的预测结果。Code project可以在以下链接中找到：https://tinyurl.com/fei-networks
</details></li>
</ul>
<hr>
<h2 id="Heteroscedastic-Causal-Structure-Learning"><a href="#Heteroscedastic-Causal-Structure-Learning" class="headerlink" title="Heteroscedastic Causal Structure Learning"></a>Heteroscedastic Causal Structure Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07973">http://arxiv.org/abs/2307.07973</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/baosws/host">https://github.com/baosws/host</a></li>
<li>paper_authors: Bao Duong, Thin Nguyen</li>
<li>for: 学习导向的不同树（DAGs），即从观察数据中找到 causal 关系的编码问题。</li>
<li>methods: 我们提出了一种基于 Gaussian 噪声的不同树学习算法，即 HOST（Heteroscedastic causal STructure learning）算法，它可以在 polynomial 时间复杂度下解决 causal 结构学习问题。</li>
<li>results: 我们通过广泛的实验评估表明，HOST 算法在 causal 顺序学习和结构学习问题中与状态之前的方法竞争。<details>
<summary>Abstract</summary>
Heretofore, learning the directed acyclic graphs (DAGs) that encode the cause-effect relationships embedded in observational data is a computationally challenging problem. A recent trend of studies has shown that it is possible to recover the DAGs with polynomial time complexity under the equal variances assumption. However, this prohibits the heteroscedasticity of the noise, which allows for more flexible modeling capabilities, but at the same time is substantially more challenging to handle. In this study, we tackle the heteroscedastic causal structure learning problem under Gaussian noises. By exploiting the normality of the causal mechanisms, we can recover a valid causal ordering, which can uniquely identify the causal DAG using a series of conditional independence tests. The result is HOST (Heteroscedastic causal STructure learning), a simple yet effective causal structure learning algorithm that scales polynomially in both sample size and dimensionality. In addition, via extensive empirical evaluations on a wide range of both controlled and real datasets, we show that the proposed HOST method is competitive with state-of-the-art approaches in both the causal order learning and structure learning problems.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Enhancing-Energy-Efficiency-and-Reliability-in-Autonomous-Systems-Estimation-using-Neuromorphic-Approach"><a href="#Enhancing-Energy-Efficiency-and-Reliability-in-Autonomous-Systems-Estimation-using-Neuromorphic-Approach" class="headerlink" title="Enhancing Energy Efficiency and Reliability in Autonomous Systems Estimation using Neuromorphic Approach"></a>Enhancing Energy Efficiency and Reliability in Autonomous Systems Estimation using Neuromorphic Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07963">http://arxiv.org/abs/2307.07963</a></li>
<li>repo_url: None</li>
<li>paper_authors: Reza Ahmadvand, Sarah Safura Sharif, Yaser Mike Banad</li>
<li>for: 这篇论文的目的是提出一个基于脉冲编程理论和脉冲神经网络（SNN）的估计框架，以便实现低Size、Weight、Power（SWaP）电脑的能效性和可靠性。</li>
<li>methods: 本研究使用了SNN-基于的卡尔曼约瑟（KF）和修改后的滑块创新续推（MSIF），并且设计了系统模型对应的网络重量矩阵，以消除学习需求。</li>
<li>results: 比较了提案的策略和其算法对应的KF和MSIF，使用了 Monte Carlo 实验，并评估了SNN-MSIF的稳定性，包括在模型不确定性和神经元损失的情况下。结果显示了提案的方法的可行性和SNN-MSIF的精度和稳定性的超越性。此外，脉冲图从网络中观察到的脉冲图亮点，表明了提案的方法实现了约97%的脉冲减少。<details>
<summary>Abstract</summary>
Energy efficiency and reliability have long been crucial factors for ensuring cost-effective and safe missions in autonomous systems computers. With the rapid evolution of industries such as space robotics and advanced air mobility, the demand for these low size, weight, and power (SWaP) computers has grown significantly. This study focuses on introducing an estimation framework based on spike coding theories and spiking neural networks (SNN), leveraging the efficiency and scalability of neuromorphic computers. Therefore, we propose an SNN-based Kalman filter (KF), a fundamental and widely adopted optimal strategy for well-defined linear systems. Furthermore, based on the modified sliding innovation filter (MSIF) we present a robust strategy called SNN-MSIF. Notably, the weight matrices of the networks are designed according to the system model, eliminating the need for learning. To evaluate the effectiveness of the proposed strategies, we compare them to their algorithmic counterparts, namely the KF and the MSIF, using Monte Carlo simulations. Additionally, we assess the robustness of SNN-MSIF by comparing it to SNN-KF in the presence of modeling uncertainties and neuron loss. Our results demonstrate the applicability of the proposed methods and highlight the superior performance of SNN-MSIF in terms of accuracy and robustness. Furthermore, the spiking pattern observed from the networks serves as evidence of the energy efficiency achieved by the proposed methods, as they exhibited an impressive reduction of approximately 97 percent in emitted spikes compared to possible spikes.
</details>
<details>
<summary>摘要</summary>
“能效率和可靠性在自动系统计算机中已经是长期关键因素，以确保成本效果和安全的任务。随着空间 робо技术和高级空中交通等行业的快速发展，小型、轻量、低功耗（SWaP）计算机的需求增长了 significatively。本研究提出了基于射频编码理论和射频神经网络（SNN）的估算框架，利用神经计算机的效率和可扩展性。因此，我们提出了基于SNN的卡尔曼畸（KF），是一种广泛采用的优质策略，适用于定义良好的线性系统。此外，基于修改的滑动创新畸（MSIF），我们提出了一种可靠的策略，称为SNN-MSIF。各种网络权重矩阵按照系统模型设计，无需学习。通过对提出的策略与算法策略进行比较，我们评估了提案的有效性。此外，我们还对SNN-MSIF的可靠性进行了评估，并在模型不确定性和神经丢失的情况下与SNN-KF进行比较。结果表明提案的方法的可行性和SNN-MSIF的精度和可靠性的提高。此外，由网络产生的射频模式表明了提案的能效率实现，它们在可能发生的射频中减少了约97%。”
</details></li>
</ul>
<hr>
<h2 id="Automated-Polynomial-Filter-Learning-for-Graph-Neural-Networks"><a href="#Automated-Polynomial-Filter-Learning-for-Graph-Neural-Networks" class="headerlink" title="Automated Polynomial Filter Learning for Graph Neural Networks"></a>Automated Polynomial Filter Learning for Graph Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07956">http://arxiv.org/abs/2307.07956</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/neurons">https://github.com/Aryia-Behroziuan/neurons</a></li>
<li>paper_authors: Wendi Yu, Zhichao Hou, Xiaorui Liu</li>
<li>For: This paper is written for researchers and practitioners in the field of graph neural networks (GNNs) and related areas, as it explores the potential and limitations of polynomial graph filter learning approaches and proposes a novel automated polynomial graph filter learning framework called Auto-Polynomial.* Methods: The paper uses polynomial graph filters as guiding principles in the design of GNNs, and proposes a novel automated learning framework called Auto-Polynomial that efficiently learns better filters capable of adapting to various complex graph signals.* Results: The paper demonstrates significant and consistent performance improvements on both homophilic and heterophilic graphs across multiple learning settings considering various labeling ratios, which unleashes the potential of polynomial filter learning.<details>
<summary>Abstract</summary>
Polynomial graph filters have been widely used as guiding principles in the design of Graph Neural Networks (GNNs). Recently, the adaptive learning of the polynomial graph filters has demonstrated promising performance for modeling graph signals on both homophilic and heterophilic graphs, owning to their flexibility and expressiveness. In this work, we conduct a novel preliminary study to explore the potential and limitations of polynomial graph filter learning approaches, revealing a severe overfitting issue. To improve the effectiveness of polynomial graph filters, we propose Auto-Polynomial, a novel and general automated polynomial graph filter learning framework that efficiently learns better filters capable of adapting to various complex graph signals. Comprehensive experiments and ablation studies demonstrate significant and consistent performance improvements on both homophilic and heterophilic graphs across multiple learning settings considering various labeling ratios, which unleashes the potential of polynomial filter learning.
</details>
<details>
<summary>摘要</summary>
偏微分 графические фильтры已经广泛应用于图神经网络（GNNs）的设计中。最近，可变学习偏微分 графические фильтры的应用已经展示了在模型图信号上的出色表现，感谢它们的灵活性和表达能力。在这项工作中，我们进行了一项新的初步研究，探索偏微分 графические филь特的潜在和局限性，发现了严重的欠拟合问题。为了改善偏微分 графические filters的效果，我们提出了 Auto-Polynomial，一种新的、通用的自动偏微分 графические filters 学习框架，可以高效地学习更好的 filters，能够适应不同的复杂图信号。经过完善的实验和割除研究，我们发现了在不同的学习设定下，包括不同的标签比例，在Homophilic和Heterophilic图上，Auto-Polynomial 可以在多种情况下提供显著和稳定的性能改进。
</details></li>
</ul>
<hr>
<h2 id="SentimentGPT-Exploiting-GPT-for-Advanced-Sentiment-Analysis-and-its-Departure-from-Current-Machine-Learning"><a href="#SentimentGPT-Exploiting-GPT-for-Advanced-Sentiment-Analysis-and-its-Departure-from-Current-Machine-Learning" class="headerlink" title="SentimentGPT: Exploiting GPT for Advanced Sentiment Analysis and its Departure from Current Machine Learning"></a>SentimentGPT: Exploiting GPT for Advanced Sentiment Analysis and its Departure from Current Machine Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.10234">http://arxiv.org/abs/2307.10234</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kiana Kheiri, Hamid Karimi</li>
<li>for: 这个研究探讨了基于Transformer生成器（GPT）的多种方法在 sentiment analysis 中的表现，具体是使用 SemEval 2017 数据集进行 Task 4 的分析。</li>
<li>methods: 这个研究使用了三种主要策略：1）使用高级 GPT-3.5 Turbo 进行提示工程，2）精度调整 GPT 模型，3）一种创新的嵌入分类方法。</li>
<li>results: 研究结果表明，GPT 方法在 predictive performance 方面表现出了明显的优势，相比之前的 state-of-the-art 模型，GPT 模型的 F1 分数提高了 более 22%。此外，研究还探讨了 sentiment analysis 任务中的常见挑战，如理解上下文和检测蔑词。研究表明，GPT 模型在处理这些复杂性方面具有强大的能力。<details>
<summary>Abstract</summary>
This study presents a thorough examination of various Generative Pretrained Transformer (GPT) methodologies in sentiment analysis, specifically in the context of Task 4 on the SemEval 2017 dataset. Three primary strategies are employed: 1) prompt engineering using the advanced GPT-3.5 Turbo, 2) fine-tuning GPT models, and 3) an inventive approach to embedding classification. The research yields detailed comparative insights among these strategies and individual GPT models, revealing their unique strengths and potential limitations. Additionally, the study compares these GPT-based methodologies with other current, high-performing models previously used with the same dataset. The results illustrate the significant superiority of the GPT approaches in terms of predictive performance, more than 22\% in F1-score compared to the state-of-the-art. Further, the paper sheds light on common challenges in sentiment analysis tasks, such as understanding context and detecting sarcasm. It underscores the enhanced capabilities of the GPT models to effectively handle these complexities. Taken together, these findings highlight the promising potential of GPT models in sentiment analysis, setting the stage for future research in this field. The code can be found at https://github.com/DSAatUSU/SentimentGPT
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Accelerating-Distributed-ML-Training-via-Selective-Synchronization"><a href="#Accelerating-Distributed-ML-Training-via-Selective-Synchronization" class="headerlink" title="Accelerating Distributed ML Training via Selective Synchronization"></a>Accelerating Distributed ML Training via Selective Synchronization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07950">http://arxiv.org/abs/2307.07950</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sahil Tyagi, Martin Swany</li>
<li>for: 这篇论文主要旨在提出一种实用、低开销的深度神经网络（DNN）训练方法，以提高分布式训练中的效率。</li>
<li>methods: 本文使用了一种名为\texttt{SelSync}的实际方法，它在每步决定是否进行交互，以提高训练效率。此外，\texttt{SelSync}还提出了一些优化策略来提高在半同步训练中的整合。</li>
<li>results: 根据实验结果，\texttt{SelSync}可以与传统的分布式训练方法（如BSP）具有相同或更好的准确性，同时减少训练时间，最多减少14倍。<details>
<summary>Abstract</summary>
In distributed training, deep neural networks (DNNs) are launched over multiple workers concurrently and aggregate their local updates on each step in bulk-synchronous parallel (BSP) training. However, BSP does not linearly scale-out due to high communication cost of aggregation. To mitigate this overhead, alternatives like Federated Averaging (FedAvg) and Stale-Synchronous Parallel (SSP) either reduce synchronization frequency or eliminate it altogether, usually at the cost of lower final accuracy. In this paper, we present \texttt{SelSync}, a practical, low-overhead method for DNN training that dynamically chooses to incur or avoid communication at each step either by calling the aggregation op or applying local updates based on their significance. We propose various optimizations as part of \texttt{SelSync} to improve convergence in the context of \textit{semi-synchronous} training. Our system converges to the same or better accuracy than BSP while reducing training time by up to 14$\times$.
</details>
<details>
<summary>摘要</summary>
在分布式训练中，深度神经网络（DNNs）会在多个工作者同时进行并将本地更新集中发送到每个步骤上进行大规模同步并发训练（BSP）。然而，BSP不会线性扩展，因为协调成本过高。为了减少这些开销， alternativas como Federated Averaging（FedAvg）和Stale-Synchronous Parallel（SSP）可以减少同步频率或完全消除同步，通常是在牺牲最终准确性的代价。在这篇论文中，我们提出了\texttt{SelSync}，一种实用、低开销的DNN训练方法，可以在每个步骤之间动态选择是否进行通信。我们还提出了多种优化，以提高在半同步训练的 конверGENCE。我们的系统可以与BSP相比，提高训练时间的效率，最多可以减少训练时间的14倍。
</details></li>
</ul>
<hr>
<h2 id="Revisiting-Domain-Adaptive-3D-Object-Detection-by-Reliable-Diverse-and-Class-balanced-Pseudo-Labeling"><a href="#Revisiting-Domain-Adaptive-3D-Object-Detection-by-Reliable-Diverse-and-Class-balanced-Pseudo-Labeling" class="headerlink" title="Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-balanced Pseudo-Labeling"></a>Revisiting Domain-Adaptive 3D Object Detection by Reliable, Diverse and Class-balanced Pseudo-Labeling</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07944">http://arxiv.org/abs/2307.07944</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhuoxiao-chen/redb-da-3ddet">https://github.com/zhuoxiao-chen/redb-da-3ddet</a></li>
<li>paper_authors: Zhuoxiao Chen, Yadan Luo, Zheng Wang, Mahsa Baktashmotlagh, Zi Huang</li>
<li>for: 本文targets at domain-adaptive 3D object detection, specifically addressing the challenge of low-quality pseudo labels and class imbalance in multi-class training settings.</li>
<li>methods: 本文提出了一种基于pseudo labeling的域 adapted 3D object detection方法，包括ReDB框架、cross-domain examination（CDE）和overlapped boxes counting（OBC）等技术。</li>
<li>results: 实验结果表明， compared to existing 3D domain adaptation methods, our proposed ReDB approach significantly improves 3D object detection performance, with a 23.15% mAP improvement on the nuScenes $\rightarrow$ KITTI task.<details>
<summary>Abstract</summary>
Unsupervised domain adaptation (DA) with the aid of pseudo labeling techniques has emerged as a crucial approach for domain-adaptive 3D object detection. While effective, existing DA methods suffer from a substantial drop in performance when applied to a multi-class training setting, due to the co-existence of low-quality pseudo labels and class imbalance issues. In this paper, we address this challenge by proposing a novel ReDB framework tailored for learning to detect all classes at once. Our approach produces Reliable, Diverse, and class-Balanced pseudo 3D boxes to iteratively guide the self-training on a distributionally different target domain. To alleviate disruptions caused by the environmental discrepancy (e.g., beam numbers), the proposed cross-domain examination (CDE) assesses the correctness of pseudo labels by copy-pasting target instances into a source environment and measuring the prediction consistency. To reduce computational overhead and mitigate the object shift (e.g., scales and point densities), we design an overlapped boxes counting (OBC) metric that allows to uniformly downsample pseudo-labeled objects across different geometric characteristics. To confront the issue of inter-class imbalance, we progressively augment the target point clouds with a class-balanced set of pseudo-labeled target instances and source objects, which boosts recognition accuracies on both frequently appearing and rare classes. Experimental results on three benchmark datasets using both voxel-based (i.e., SECOND) and point-based 3D detectors (i.e., PointRCNN) demonstrate that our proposed ReDB approach outperforms existing 3D domain adaptation methods by a large margin, improving 23.15% mAP on the nuScenes $\rightarrow$ KITTI task. The code is available at https://github.com/zhuoxiao-chen/ReDB-DA-3Ddet.
</details>
<details>
<summary>摘要</summary>
“对于多类别训练设定下的隐式领域适应（DA）， Pseudo 标签技术已经成为一种重要的方法。然而，现有的 DA 方法在多类别训练设定下会受到较大的性能下降，这是因为 Pseudo 标签质量低下和分布不均匀问题。在这篇文章中，我们提出了一个名为 ReDB 的框架，用于同时探索所有类别。我们的方法可以生成可靠、多样和分布均匀的 Pseudo 3D 标签，并在不同的目标领域中将其适应自我训练。为了解决环境差异所导致的干扰（例如：批量数量），我们提出了跨领域评估（CDE），用于评估 Pseudo 标签的正确性，并在目标环境中复制目标实体。为了减少计算负载和补偿物体移动（例如：数量和点密度），我们设计了重 overlap 的盒子（OBC）度量，允许对不同的几何特征进行均匀抽样。为了解决类别不均匀问题，我们逐渐将目标点云补充了一些具有分布均匀的 Pseudo 标签目标实体和原始点云，这样可以提高识别率，包括常见的类别和罕见的类别。实验结果显示，我们的 ReDB 方法在三个 benchmark 数据集上比较早的 3D 领域适应方法提高了 23.15% mAP，对于 nuScenes ← KITTI 任务来说，这表明我们的方法可以更好地适应不同的领域。代码可以在 https://github.com/zhuoxiao-chen/ReDB-DA-3Ddet 上找到。”
</details></li>
</ul>
<hr>
<h2 id="KECOR-Kernel-Coding-Rate-Maximization-for-Active-3D-Object-Detection"><a href="#KECOR-Kernel-Coding-Rate-Maximization-for-Active-3D-Object-Detection" class="headerlink" title="KECOR: Kernel Coding Rate Maximization for Active 3D Object Detection"></a>KECOR: Kernel Coding Rate Maximization for Active 3D Object Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07942">http://arxiv.org/abs/2307.07942</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Luoyadan/KECOR-active-3Ddet">https://github.com/Luoyadan/KECOR-active-3Ddet</a></li>
<li>paper_authors: Yadan Luo, Zhuoxiao Chen, Zhen Fang, Zheng Zhang, Zi Huang, Mahsa Baktashmotlagh</li>
<li>for: 提高自动驾驶中LiDAR检测器的可靠性，使用活动学习方法来减少标注量。</li>
<li>methods: 使用信息论来选择最有用的点云获取标注，并通过搜索算法选择最有用的点云。</li>
<li>results: 比起现有方法，提高了监督学习性能的同时减少了约44%的标注成本和26%的计算时间。<details>
<summary>Abstract</summary>
Achieving a reliable LiDAR-based object detector in autonomous driving is paramount, but its success hinges on obtaining large amounts of precise 3D annotations. Active learning (AL) seeks to mitigate the annotation burden through algorithms that use fewer labels and can attain performance comparable to fully supervised learning. Although AL has shown promise, current approaches prioritize the selection of unlabeled point clouds with high uncertainty and/or diversity, leading to the selection of more instances for labeling and reduced computational efficiency. In this paper, we resort to a novel kernel coding rate maximization (KECOR) strategy which aims to identify the most informative point clouds to acquire labels through the lens of information theory. Greedy search is applied to seek desired point clouds that can maximize the minimal number of bits required to encode the latent features. To determine the uniqueness and informativeness of the selected samples from the model perspective, we construct a proxy network of the 3D detector head and compute the outer product of Jacobians from all proxy layers to form the empirical neural tangent kernel (NTK) matrix. To accommodate both one-stage (i.e., SECOND) and two-stage detectors (i.e., PVRCNN), we further incorporate the classification entropy maximization and well trade-off between detection performance and the total number of bounding boxes selected for annotation. Extensive experiments conducted on two 3D benchmarks and a 2D detection dataset evidence the superiority and versatility of the proposed approach. Our results show that approximately 44% box-level annotation costs and 26% computational time are reduced compared to the state-of-the-art AL method, without compromising detection performance.
</details>
<details>
<summary>摘要</summary>
需要一个可靠的LiDAR基于对象检测器在自动驾驶中，但其成功取决于获得大量精度3D注释。活动学习（AL）希望减轻注释压力通过使用 fewer labels 和可以达到完全监督学习的性能。 although AL has shown promise, current approaches prioritize the selection of unlabeled point clouds with high uncertainty and/or diversity, leading to the selection of more instances for labeling and reduced computational efficiency.在这篇论文中，我们采用了一种新的幂 coding rate maximization（KECOR）策略，该策略目的是通过信息理论来标识最有用的点云来获得标注。 我们使用批处理来寻找想要标注的点云，以便最大化最小数量的比特位数据编码 latent 特征。为了确定选择的样本唯一性和有用性，我们构建了一个3D检测头的卫星网络，并计算所有卫星层的外积Jacobian的 outer product，以形成empirical neural tangent kernel（NTK）矩阵。为了适应一stage（i.e., SECOND）和two-stage检测器（i.e., PVRCNN），我们进一步包括分类 entropy maximization 和检测性能和总绘制盒数之间的平衡。我们在两个3D benchmark和一个2D检测数据集上进行了广泛的实验，结果显示了我们的方法的优越性和多样性。我们发现，相比于状态 искусственный智能方法，我们的方法可以降低盒级注释成本约44%，并且不会影响检测性能。
</details></li>
</ul>
<hr>
<h2 id="Optimal-Compression-of-Unit-Norm-Vectors-in-the-High-Distortion-Regime"><a href="#Optimal-Compression-of-Unit-Norm-Vectors-in-the-High-Distortion-Regime" class="headerlink" title="Optimal Compression of Unit Norm Vectors in the High Distortion Regime"></a>Optimal Compression of Unit Norm Vectors in the High Distortion Regime</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07941">http://arxiv.org/abs/2307.07941</a></li>
<li>repo_url: None</li>
<li>paper_authors: Heng Zhu, Avishek Ghosh, Arya Mazumdar</li>
<li>for: 这篇论文探讨了将单位 нор 向量压缩成最少位元数，以确保可以在接受到的水平上实现重建的可接受程度。</li>
<li>methods: 本研究将Rate-Distortion&#x2F;covering code文献中的问题探讨，但专注于”高 Distortion”  regime。研究在最坏情况下进行，无任何对vector的假设，但允许使用随机压缩 Maps。</li>
<li>results: 研究发现，简单的压缩方案几乎是最佳的。结果包括部分新的结果和已知结果，但是在这篇论文中汇集了所有结果 для 完整性。<details>
<summary>Abstract</summary>
Motivated by the need for communication-efficient distributed learning, we investigate the method for compressing a unit norm vector into the minimum number of bits, while still allowing for some acceptable level of distortion in recovery. This problem has been explored in the rate-distortion/covering code literature, but our focus is exclusively on the "high-distortion" regime. We approach this problem in a worst-case scenario, without any prior information on the vector, but allowing for the use of randomized compression maps. Our study considers both biased and unbiased compression methods and determines the optimal compression rates. It turns out that simple compression schemes are nearly optimal in this scenario. While the results are a mix of new and known, they are compiled in this paper for completeness.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Motivated by the need for communication-efficient distributed learning, we investigate the method for compressing a unit norm vector into the minimum number of bits, while still allowing for some acceptable level of distortion in recovery. This problem has been explored in the rate-distortion/covering code literature, but our focus is exclusively on the 'high-distortion' regime. We approach this problem in a worst-case scenario, without any prior information on the vector, but allowing for the use of randomized compression maps. Our study considers both biased and unbiased compression methods and determines the optimal compression rates. It turns out that simple compression schemes are nearly optimal in this scenario. While the results are a mix of new and known, they are compiled in this paper for completeness." into Simplified Chinese.翻译文本：<<SYS>>驱动通信效率的分布式学习需求，我们调查了最小化单元 нор 向量 bit 数量的压缩方法，同时仍允许接受一定的损害率。这个问题在 rate-distortion/covering code 文献中已经被研究过，但我们专注于 "高损害"  régime。我们在最坏情况下进行研究，不具备向量的任何先前信息，但允许使用随机压缩映射。我们的研究包括偏向和无偏向压缩方法，并确定了最优压缩率。结果显示，简单的压缩方案几乎是最优的。虽然结果包含一些新知识和已知的成果，但它们在这篇文章中被编辑成完整。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-Truncated-Norm-Regularization-Method-for-Multi-channel-Color-Image-Denoising"><a href="#A-Novel-Truncated-Norm-Regularization-Method-for-Multi-channel-Color-Image-Denoising" class="headerlink" title="A Novel Truncated Norm Regularization Method for Multi-channel Color Image Denoising"></a>A Novel Truncated Norm Regularization Method for Multi-channel Color Image Denoising</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07932">http://arxiv.org/abs/2307.07932</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wangzhi82/DtNFM">https://github.com/wangzhi82/DtNFM</a></li>
<li>paper_authors: Yiwen Shan, Dong Hu, Haoming Ding, Chunming Yang, Zhi Wang</li>
<li>for: 这篇研究旨在提出一种基于双重权重核心幂方法的彩色图像干扰除法，以解决现实世界中彩色图像干扰除中存在跨通道差异和空间变化的问题。</li>
<li>methods: 该方法使用了双重权重核心幂方法（DtNFM），通过利用干扰图像中的非本地自相似性，将相似的结构聚集起来，并将每个组建立一个DtNFM模型来估算其干扰版本。最终的干扰除图像由多个估算结果 concatenate 得到。</li>
<li>results: 该方法在 synthetic 和实际噪声数据集上进行了广泛的实验，并证明了它在现实世界中彩色图像干扰除中表现出优于许多状态之前的方法。<details>
<summary>Abstract</summary>
Due to the high flexibility and remarkable performance, low-rank approximation methods has been widely studied for color image denoising. However, those methods mostly ignore either the cross-channel difference or the spatial variation of noise, which limits their capacity in real world color image denoising. To overcome those drawbacks, this paper is proposed to denoise color images with a double-weighted truncated nuclear norm minus truncated Frobenius norm minimization (DtNFM) method. Through exploiting the nonlocal self-similarity of the noisy image, the similar structures are gathered and a series of similar patch matrices are constructed. For each group, the DtNFM model is conducted for estimating its denoised version. The denoised image would be obtained by concatenating all the denoised patch matrices. The proposed DtNFM model has two merits. First, it models and utilizes both the cross-channel difference and the spatial variation of noise. This provides sufficient flexibility for handling the complex distribution of noise in real world images. Second, the proposed DtNFM model provides a close approximation to the underlying clean matrix since it can treat different rank components flexibly. To solve the problem resulted from DtNFM model, an accurate and effective algorithm is proposed by exploiting the framework of the alternating direction method of multipliers (ADMM). The generated subproblems are discussed in detail. And their global optima can be easily obtained in closed-form. Rigorous mathematical derivation proves that the solution sequences generated by the algorithm converge to a single critical point. Extensive experiments on synthetic and real noise datasets demonstrate that the proposed method outperforms many state-of-the-art color image denoising methods.
</details>
<details>
<summary>摘要</summary>
due to the high flexibility and remarkable performance, low-rank approximation methods have been widely studied for color image denoising. however, those methods mostly ignore either the cross-channel difference or the spatial variation of noise, which limits their capacity in real-world color image denoising. to overcome these drawbacks, this paper proposes a double-weighted truncated nuclear norm minus truncated frobenius norm minimization (DtNFM) method for denoising color images. by exploiting the nonlocal self-similarity of the noisy image, similar structures are gathered and a series of similar patch matrices are constructed. for each group, the DtNFM model is conducted to estimate its denoised version. the denoised image is obtained by concatenating all the denoised patch matrices. the proposed DtNFM model has two merits. first, it models and utilizes both the cross-channel difference and the spatial variation of noise, providing sufficient flexibility for handling the complex distribution of noise in real-world images. second, the proposed DtNFM model provides a close approximation to the underlying clean matrix, treating different rank components flexibly. to solve the problem resulted from the DtNFM model, an accurate and effective algorithm is proposed by exploiting the framework of the alternating direction method of multipliers (ADMM). the generated subproblems are discussed in detail, and their global optima can be easily obtained in closed form. rigorous mathematical derivation proves that the solution sequences generated by the algorithm converge to a single critical point. extensive experiments on synthetic and real noise datasets demonstrate that the proposed method outperforms many state-of-the-art color image denoising methods.
</details></li>
</ul>
<hr>
<h2 id="On-the-Robustness-of-Split-Learning-against-Adversarial-Attacks"><a href="#On-the-Robustness-of-Split-Learning-against-Adversarial-Attacks" class="headerlink" title="On the Robustness of Split Learning against Adversarial Attacks"></a>On the Robustness of Split Learning against Adversarial Attacks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07916">http://arxiv.org/abs/2307.07916</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fmy266/SplitADV">https://github.com/fmy266/SplitADV</a></li>
<li>paper_authors: Mingyuan Fan, Cen Chen, Chengyu Wang, Wenmeng Zhou, Jun Huang</li>
<li>for: 评估分布式学习中对 adversarial 攻击的Robustness,特别是在无法访问全模型的情况下。</li>
<li>methods: 开发了一种特定于分布式学习的攻击方法，称为 SPADV，它包括两个阶段：1）阴影模型训练，解决模型缺失部分的问题，2）本地 adversarial 攻击，生成 adversarial 例子来评估。</li>
<li>results: SPADV 需要only a few unlabeled non-IID data，并且可以在第二阶段通过对 naturalsamples中的Intermediate output进行拟合来生成 adversarial examples，这表明了分布式学习对 adversarial 攻击的Robustness surprisingly vulnerable。<details>
<summary>Abstract</summary>
Split learning enables collaborative deep learning model training while preserving data privacy and model security by avoiding direct sharing of raw data and model details (i.e., sever and clients only hold partial sub-networks and exchange intermediate computations). However, existing research has mainly focused on examining its reliability for privacy protection, with little investigation into model security. Specifically, by exploring full models, attackers can launch adversarial attacks, and split learning can mitigate this severe threat by only disclosing part of models to untrusted servers.This paper aims to evaluate the robustness of split learning against adversarial attacks, particularly in the most challenging setting where untrusted servers only have access to the intermediate layers of the model.Existing adversarial attacks mostly focus on the centralized setting instead of the collaborative setting, thus, to better evaluate the robustness of split learning, we develop a tailored attack called SPADV, which comprises two stages: 1) shadow model training that addresses the issue of lacking part of the model and 2) local adversarial attack that produces adversarial examples to evaluate.The first stage only requires a few unlabeled non-IID data, and, in the second stage, SPADV perturbs the intermediate output of natural samples to craft the adversarial ones. The overall cost of the proposed attack process is relatively low, yet the empirical attack effectiveness is significantly high, demonstrating the surprising vulnerability of split learning to adversarial attacks.
</details>
<details>
<summary>摘要</summary>
分学促进了分布式深度学习模型的共同训练，同时保护数据隐私和模型安全，因为服务器和客户端只持有部分子网和交换中间计算。然而，现有研究主要集中在隐私保护的可靠性上，很少探讨模型安全性。具体来说，通过探索全模型，攻击者可以发起对抗性攻击，而分学促可以通过仅披露部分模型来减轻这种严重的威胁。这篇论文的目的是评估分学促的可抗性 against 对抗性攻击，特别是在最具挑战性的设定下，即不可信服务器仅有访问模型中间层。现有的对抗性攻击主要集中在中央设定下，而不是合作设定，因此，为更好地评估分学促的可抗性，我们开发了一种特定的攻击方法，称为 SPADV。 SPADV 包括两个阶段：1）遮盾模型培训，解决因缺少部分模型而产生的问题，2）本地对抗性攻击，生成对抗性示例来评估。第一阶段只需要一些非相关的非独特数据，而第二阶段，SPADV 对于自然示例的间接输出进行了扰动，以生成对抗性示例。整个攻击过程的总成本较低，但实际攻击效果却非常高，表明了分学促对于对抗性攻击的意外脆弱性。
</details></li>
</ul>
<hr>
<h2 id="Exploiting-FPGA-Capabilities-for-Accelerated-Biomedical-Computing"><a href="#Exploiting-FPGA-Capabilities-for-Accelerated-Biomedical-Computing" class="headerlink" title="Exploiting FPGA Capabilities for Accelerated Biomedical Computing"></a>Exploiting FPGA Capabilities for Accelerated Biomedical Computing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07914">http://arxiv.org/abs/2307.07914</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kayode Inadagbo, Baran Arig, Nisanur Alici, Murat Isik</li>
<li>for: 这个研究旨在通过使用 Field Programmable Gate Arrays (FPGAs) 提高心电信号分析，并提出了多种高级神经网络架构，包括卷积神经网络 (CNN)、循环神经网络 (RNN)、长期短TERM Memory网络 (LSTMs) 和深度信念网络 (DBNs)。</li>
<li>methods: 我们使用 MIT-BIH 心电性股库进行训练和验证，并在模型中引入 Gaussian 噪声以提高算法的Robustness。我们还使用 EarlyStopping 回调和 Dropout 层来避免过拟合。此外，我们还开发了一个自定义的 Tensor Compute Unit (TCU) 加速器，用于 PYNQ Z1 板。</li>
<li>results: 我们计算了各种性能指标，如延迟和通过put，以获得实际的应用级别高性能的FPGA在生物医学计算中的潜在性。这种研究最终提供了优化神经网络性能在 FPGAs 上的指南，为不同应用场景提供参考。<details>
<summary>Abstract</summary>
This study presents advanced neural network architectures including Convolutional Neural Networks (CNN), Recurrent Neural Networks (RNN), Long Short-Term Memory Networks (LSTMs), and Deep Belief Networks (DBNs) for enhanced ECG signal analysis using Field Programmable Gate Arrays (FPGAs). We utilize the MIT-BIH Arrhythmia Database for training and validation, introducing Gaussian noise to improve algorithm robustness. The implemented models feature various layers for distinct processing and classification tasks and techniques like EarlyStopping callback and Dropout layer are used to mitigate overfitting. Our work also explores the development of a custom Tensor Compute Unit (TCU) accelerator for the PYNQ Z1 board, offering comprehensive steps for FPGA-based machine learning, including setting up the Tensil toolchain in Docker, selecting architecture, configuring PS-PL, and compiling and executing models. Performance metrics such as latency and throughput are calculated for practical insights, demonstrating the potential of FPGAs in high-performance biomedical computing. The study ultimately offers a guide for optimizing neural network performance on FPGAs for various applications.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:这个研究提出了使用场程可编程阵列（FPGAs）进行高性能生物医学计算的先进神经网络架构，包括卷积神经网络（CNN）、循环神经网络（RNN）、长期短Memory神经网络（LSTM）和深度信仰神经网络（DBNs）。我们使用MIT-BIH心跳频数据库进行训练和验证，并在神经网络中引入 Gaussian 噪声以提高算法的稳定性。实现的模型包括不同层次的处理和分类任务，并使用 EarlyStopping 回调函数和 Dropout 层来避免过拟合。我们的工作还探讨了基于 PYNQ Z1 板的自定义 Tensor Compute Unit (TCU) 加速器的开发，并提供了完整的 FPGA-based 机器学习实现方法，包括在 Docker 中设置 Tensil 工具链、选择架构、配置 PS-PL 和编译并执行模型。实验中计算的性能指标包括延迟和吞吐量，以提供实用的指导，展示 FPGAs 在高性能生物医学计算中的潜力。研究最终提供了优化神经网络性能在 FPGAs 上的指南，用于多种应用。
</details></li>
</ul>
<hr>
<h2 id="Predicting-mechanical-properties-of-Carbon-Nanotube-CNT-images-Using-Multi-Layer-Synthetic-Finite-Element-Model-Simulations"><a href="#Predicting-mechanical-properties-of-Carbon-Nanotube-CNT-images-Using-Multi-Layer-Synthetic-Finite-Element-Model-Simulations" class="headerlink" title="Predicting mechanical properties of Carbon Nanotube (CNT) images Using Multi-Layer Synthetic Finite Element Model Simulations"></a>Predicting mechanical properties of Carbon Nanotube (CNT) images Using Multi-Layer Synthetic Finite Element Model Simulations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07912">http://arxiv.org/abs/2307.07912</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kaveh Safavigerdini, Koundinya Nouduri, Ramakrishna Surya, Andrew Reinhard, Zach Quinlan, Filiz Bunyak, Matthew R. Maschmann, Kannappan Palaniappan</li>
<li>for: 预测碳纳米管（CNT）林集成体的机械性能</li>
<li>methods: 使用深度学习模型和人工智能（AI）基 materials发现</li>
<li>results: 提出一种使用多层合成图像（MLS）或 quasi-2.5D 图像进行数据增强的管道，可以更好地预测 CNT 林集成体的机械性能。<details>
<summary>Abstract</summary>
We present a pipeline for predicting mechanical properties of vertically-oriented carbon nanotube (CNT) forest images using a deep learning model for artificial intelligence (AI)-based materials discovery. Our approach incorporates an innovative data augmentation technique that involves the use of multi-layer synthetic (MLS) or quasi-2.5D images which are generated by blending 2D synthetic images. The MLS images more closely resemble 3D synthetic and real scanning electron microscopy (SEM) images of CNTs but without the computational cost of performing expensive 3D simulations or experiments. Mechanical properties such as stiffness and buckling load for the MLS images are estimated using a physics-based model. The proposed deep learning architecture, CNTNeXt, builds upon our previous CNTNet neural network, using a ResNeXt feature representation followed by random forest regression estimator. Our machine learning approach for predicting CNT physical properties by utilizing a blended set of synthetic images is expected to outperform single synthetic image-based learning when it comes to predicting mechanical properties of real scanning electron microscopy images. This has the potential to accelerate understanding and control of CNT forest self-assembly for diverse applications.
</details>
<details>
<summary>摘要</summary>
我们提出了一个气候预测碳纳米管（CNT）林图像的机械性能预测管道，使用深度学习模型来实现人工智能（AI）基于材料发现。我们的方法包括一种创新的数据增强技术，使用多层合成（MLS）或 quasi-2.5D 图像，这些图像由拼接2D 合成图像而成。MLS 图像更接近3D 合成和实验室扫描电子显微镜（SEM）图像，但没有 computationally Expensive 3D 模拟或实验的成本。机械性能如刚性和填充荷 для MLS 图像通过物理基础模型进行估算。我们的提议的深度学习架构，CNTNeXt，基于我们之前的 CNTNet 神经网络，使用 ResNeXt 特征表示 followed by random forest 回归估计器。我们的机器学习方法，通过使用拼接 synthetic 图像来预测 CNT 物理性能，预计能够超越单独使用 synthetic 图像来预测实际 SEM 图像中的机械性能，从而加速了 CNT 林自组装的理解和控制，并且具有广泛的应用前景。
</details></li>
</ul>
<hr>
<h2 id="MESOB-Balancing-Equilibria-Social-Optimality"><a href="#MESOB-Balancing-Equilibria-Social-Optimality" class="headerlink" title="MESOB: Balancing Equilibria &amp; Social Optimality"></a>MESOB: Balancing Equilibria &amp; Social Optimality</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07911">http://arxiv.org/abs/2307.07911</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xin Guo, Lihong Li, Sareh Nabi, Rabih Salhab, Junzi Zhang</li>
<li>for: This paper aims to provide a novel optimization method for multi-level and multi-agent games with anonymous agents and complex interplay between competition and cooperation.</li>
<li>methods: The proposed method is called MESOB-OMO, which combines a mean-field approximation with an occupation measure optimization method to solve a bi-objective optimization problem.</li>
<li>results: The proposed method is effective in balancing the interests of different parties and handling the competitive nature of bidders, and outperforms baseline methods that only consider either the competitive or cooperative aspects.Here is the text in Simplified Chinese:</li>
<li>for: 这篇论文目标是提供一种新的优化方法，用于处理多层多代理人的游戏，具有大量匿名代理人和复杂的竞争与合作关系。</li>
<li>methods: 提议的方法是MESOB-OMO，它将mean-field approximation与占用度优化方法相结合，解决bi-objective优化问题。</li>
<li>results: MESOB-OMO方法能够均衡不同党之利益，抑制竞争性代理人的行为，并与基准方法相比显示出优异性。<details>
<summary>Abstract</summary>
Motivated by bid recommendation in online ad auctions, this paper considers a general class of multi-level and multi-agent games, with two major characteristics: one is a large number of anonymous agents, and the other is the intricate interplay between competition and cooperation. To model such complex systems, we propose a novel and tractable bi-objective optimization formulation with mean-field approximation, called MESOB (Mean-field Equilibria & Social Optimality Balancing), as well as an associated occupation measure optimization (OMO) method called MESOB-OMO to solve it. MESOB-OMO enables obtaining approximately Pareto efficient solutions in terms of the dual objectives of competition and cooperation in MESOB, and in particular allows for Nash equilibrium selection and social equalization in an asymptotic manner. We apply MESOB-OMO to bid recommendation in a simulated pay-per-click ad auction. Experiments demonstrate its efficacy in balancing the interests of different parties and in handling the competitive nature of bidders, as well as its advantages over baselines that only consider either the competitive or the cooperative aspects.
</details>
<details>
<summary>摘要</summary>
<<SYS>>使用在在线广告拍卖中的拍卖推荐为动机，这篇论文考虑了一个总体来说是多层次和多代理人的游戏，具有两个主要特征：一是一大量的匿名代理人，二是竞争和合作之间的复杂互动。为了模型这些复杂系统，我们提出了一种新的和可行的双目标优化方法，称为MESOB（Mean-field Equilibria & Social Optimality Balancing），以及与之相关的占用度优化方法MESOB-OMO（MESOB-Occupation Measure Optimization）来解决它。MESOB-OMO可以在MESOB中获得约等价的竞争和合作两个目标的解，并且可以在极限情况下实现纳什均衡选择和社会平等。我们在模拟的一个基于拍卖的点播广告拍卖中应用MESOB-OMO。实验表明，它可以均衡不同党的利益，同时处理竞争性的拍卖者，以及与基准值（只考虑竞争或合作方面）相比，具有优势。
</details></li>
</ul>
<hr>
<h2 id="Seeing-is-not-Believing-Robust-Reinforcement-Learning-against-Spurious-Correlation"><a href="#Seeing-is-not-Believing-Robust-Reinforcement-Learning-against-Spurious-Correlation" class="headerlink" title="Seeing is not Believing: Robust Reinforcement Learning against Spurious Correlation"></a>Seeing is not Believing: Robust Reinforcement Learning against Spurious Correlation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07907">http://arxiv.org/abs/2307.07907</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenhao Ding, Laixi Shi, Yuejie Chi, Ding Zhao</li>
<li>for:  Handle spurious correlation in reinforcement learning to improve the robustness of real-world tasks.</li>
<li>methods:  Propose a new framework called Robust State-Confounded Markov Decision Processes (RSC-MDPs) and design an empirical algorithm to learn the robust optimal policy.</li>
<li>results:  Outperform all baselines in eight realistic self-driving and manipulation tasks.<details>
<summary>Abstract</summary>
Robustness has been extensively studied in reinforcement learning (RL) to handle various forms of uncertainty such as random perturbations, rare events, and malicious attacks. In this work, we consider one critical type of robustness against spurious correlation, where different portions of the state do not have causality but have correlations induced by unobserved confounders. These spurious correlations are ubiquitous in real-world tasks, for instance, a self-driving car usually observes heavy traffic in the daytime and light traffic at night due to unobservable human activity. A model that learns such useless or even harmful correlation could catastrophically fail when the confounder in the test case deviates from the training one. Although motivated, enabling robustness against spurious correlation poses significant challenges since the uncertainty set, shaped by the unobserved confounder and sequential structure of RL, is difficult to characterize and identify. Existing robust algorithms that assume simple and unstructured uncertainty sets are therefore inadequate to address this challenge. To solve this issue, we propose Robust State-Confounded Markov Decision Processes (RSC-MDPs) and theoretically demonstrate its superiority in breaking spurious correlations compared with other robust RL counterparts. We also design an empirical algorithm to learn the robust optimal policy for RSC-MDPs, which outperforms all baselines in eight realistic self-driving and manipulation tasks.
</details>
<details>
<summary>摘要</summary>
robustness 在强化学习（RL）中已经广泛研究，以处理不同形式的不确定性，如随机干扰、罕见事件和恶意攻击。在这项工作中，我们考虑了一种关键的一种强度对假设相关性，即不同的状态部分没有 causality，但由不见的干扰因素引起的相关性。这种假设相关性在实际任务中很普遍，例如一个自驾车通常在白天会观察到压力很大的交通，而在夜晚则是非常少的交通，这是由于不可见的人类活动引起的。如果模型学习这种无用或甚至有害的相关性，那么在测试案例中，当干扰因素与训练案例不同时，模型可能会catastrophically fail。虽然有动机，但使模型具有假设相关性的鲁棒性具有 significante challenges，因为不确定集，由不见的干扰因素和RL的顺序结构塑造，很难characterize和识别。现有的鲁棒算法假设简单的和无结构的不确定集，因此无法解决这一问题。为解决这个问题，我们提出了Robust State-Confounded Markov Decision Processes（RSC-MDPs），并 theoretically demonstrab其在破坏假设相关性方面的优越性。我们还设计了一种实际算法，用于学习RSC-MDPs中的鲁棒优胜策略，并在八个实际自驾和操作任务中超过所有基elines。
</details></li>
</ul>
<hr>
<h2 id="Anomaly-Detection-in-Automated-Fibre-Placement-Learning-with-Data-Limitations"><a href="#Anomaly-Detection-in-Automated-Fibre-Placement-Learning-with-Data-Limitations" class="headerlink" title="Anomaly Detection in Automated Fibre Placement: Learning with Data Limitations"></a>Anomaly Detection in Automated Fibre Placement: Learning with Data Limitations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07893">http://arxiv.org/abs/2307.07893</a></li>
<li>repo_url: None</li>
<li>paper_authors: Assef Ghamisi, Todd Charter, Li Ji, Maxime Rivard, Gil Lund, Homayoun Najjaran</li>
<li>for: Automated Fibre Placement (AFP) 自动纤维放置系统中的缺陷检测</li>
<li>methods: 无监督深度学习和经典计算机视觉算法</li>
<li>results: 可以减少训练图像数量，同时检测到各种表面问题，并且可以准确地标识缺陷位置<details>
<summary>Abstract</summary>
Conventional defect detection systems in Automated Fibre Placement (AFP) typically rely on end-to-end supervised learning, necessitating a substantial number of labelled defective samples for effective training. However, the scarcity of such labelled data poses a challenge. To overcome this limitation, we present a comprehensive framework for defect detection and localization in Automated Fibre Placement. Our approach combines unsupervised deep learning and classical computer vision algorithms, eliminating the need for labelled data or manufacturing defect samples. It efficiently detects various surface issues while requiring fewer images of composite parts for training. Our framework employs an innovative sample extraction method leveraging AFP's inherent symmetry to expand the dataset. By inputting a depth map of the fibre layup surface, we extract local samples aligned with each composite strip (tow). These samples are processed through an autoencoder, trained on normal samples for precise reconstructions, highlighting anomalies through reconstruction errors. Aggregated values form an anomaly map for insightful visualization. The framework employs blob detection on this map to locate manufacturing defects. The experimental findings reveal that despite training the autoencoder with a limited number of images, our proposed method exhibits satisfactory detection accuracy and accurately identifies defect locations. Our framework demonstrates comparable performance to existing methods, while also offering the advantage of detecting all types of anomalies without relying on an extensive labelled dataset of defects.
</details>
<details>
<summary>摘要</summary>
Our framework employs an innovative sample extraction method that leverages AFP's inherent symmetry to expand the dataset. By inputting a depth map of the fibre layup surface, we extract local samples aligned with each composite strip (tow). These samples are processed through an autoencoder, trained on normal samples for precise reconstructions, highlighting anomalies through reconstruction errors. Aggregated values form an anomaly map for insightful visualization. The framework employs blob detection on this map to locate manufacturing defects.Experimental findings show that our proposed method exhibits satisfactory detection accuracy and accurately identifies defect locations, despite training the autoencoder with a limited number of images. Our framework demonstrates comparable performance to existing methods, while also offering the advantage of detecting all types of anomalies without relying on an extensive labelled dataset of defects.
</details></li>
</ul>
<hr>
<h2 id="Multitemporal-SAR-images-change-detection-and-visualization-using-RABASAR-and-simplified-GLR"><a href="#Multitemporal-SAR-images-change-detection-and-visualization-using-RABASAR-and-simplified-GLR" class="headerlink" title="Multitemporal SAR images change detection and visualization using RABASAR and simplified GLR"></a>Multitemporal SAR images change detection and visualization using RABASAR and simplified GLR</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07892">http://arxiv.org/abs/2307.07892</a></li>
<li>repo_url: None</li>
<li>paper_authors: Weiying Zhao, Charles-Alban Deledalle, Loïc Denis, Henri Maître, Jean-Marie Nicolas, Florence Tupin</li>
<li>for: 这个论文主要是为了检测土地表面的变化，尤其是不同类型的变化，如农田、建筑、港口和洪涝等。</li>
<li>methods: 本论文提出了一种简化的总体可能比率（SGLR）方法，假设同时间像素具有相同的等效数量看（ENL）。此外，本论文还提出了一种改进的光谱划分法和一种改进的变化类别法。</li>
<li>results: 本论文通过处理模拟和Synthetic Aperture Radar（SAR）图像，证明了提出的方法的效果，特别是在检测农田、建筑、港口和洪涝等区域变化方面。<details>
<summary>Abstract</summary>
Understanding the state of changed areas requires that precise information be given about the changes. Thus, detecting different kinds of changes is important for land surface monitoring. SAR sensors are ideal to fulfil this task, because of their all-time and all-weather capabilities, with good accuracy of the acquisition geometry and without effects of atmospheric constituents for amplitude data. In this study, we propose a simplified generalized likelihood ratio ($S_{GLR}$) method assuming that corresponding temporal pixels have the same equivalent number of looks (ENL). Thanks to the denoised data provided by a ratio-based multitemporal SAR image denoising method (RABASAR), we successfully applied this similarity test approach to compute the change areas. A new change magnitude index method and an improved spectral clustering-based change classification method are also developed. In addition, we apply the simplified generalized likelihood ratio to detect the maximum change magnitude time, and the change starting and ending times. Then, we propose to use an adaptation of the REACTIV method to visualize the detection results vividly. The effectiveness of the proposed methods is demonstrated through the processing of simulated and SAR images, and the comparison with classical techniques. In particular, numerical experiments proved that the developed method has good performances in detecting farmland area changes, building area changes, harbour area changes and flooding area changes.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate the following text into Simplified Chinese<</SYS>>理解改变区域的状况需要提供精确的改变信息。因此，检测不同类型的改变是重要的 для土地表面监测。SAR感知器非常适合完成这项任务，因为它们在任何时间和任何天气情况下都有良好的探测geometry的准确性，而无需 atmospheric constituents的影响。在这项研究中，我们提出了一种简化的通用概率比例（SGLR）方法，假设相应的时间像素有同等的等效数量 Looks（ENL）。由于降噪数据提供了由比例基于多 temporal SAR图像降噪方法（RABASAR），我们成功地应用了这种相似性测试方法来计算改变区域。此外，我们还开发了一种改进的spectral clustering-based改变类型分类方法和一种最大改变幅度时间检测方法。然后，我们使用简化的SGLR方法检测改变的开始和结束时间。最后，我们提出了使用adapted REACTIV方法来Visual化检测结果的方法。实验证明了我们提出的方法的效果，包括对农地改变、建筑改变、港口改变和洪涝改变等方面的检测。
</details></li>
</ul>
<hr>
<h2 id="Investigation-of-compressor-cascade-flow-based-on-physics-informed-neural-networks"><a href="#Investigation-of-compressor-cascade-flow-based-on-physics-informed-neural-networks" class="headerlink" title="Investigation of compressor cascade flow based on physics-informed neural networks"></a>Investigation of compressor cascade flow based on physics-informed neural networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.04501">http://arxiv.org/abs/2308.04501</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhihui Li, Francesco Montomoli, Sanjiv Sharma</li>
<li>for: 这项研究使用新兴的物理告知神经网络（PINNs）方法，为首次预测压缩机风场。</li>
<li>methods: 这种方法基于两维问题，包括液体力学方程在前向和反向问题中。</li>
<li>results: PINNs能够高精度地预测压缩机风场，并且在无部分边界条件的情况下，PINNs显示出了与传统CFD方法相比的明显优势。<details>
<summary>Abstract</summary>
In this study, we utilize the emerging Physics Informed Neural Networks (PINNs) approach for the first time to predict the flow field of a compressor cascade. The approach is demonstrated on a two-dimensional problem, incorporating Navier-Stokes equations in both the forward and inverse problems. In the forward problem, PINNs effectively predict the flow field of the compressor. The key advantage over Deep Neural Networks (DNNs) is that the PINNs model incorporates a physical relationship between the relevant quantities, resulting in more precise predictions. PINNs show obvious advantages over the traditional CFD approaches when dealing with inverse problems in the absence of partial boundary conditions. PINNs successfully reconstruct the flow field of the compressor cascade solely based on partial velocity vectors and wall pressure information. This research provides compelling evidence that PINNs offer turbomachinery designers a promising alternative to the current dominant CFD methods, delivering higher accuracy compared to DNNs.
</details>
<details>
<summary>摘要</summary>
在本研究中，我们首次利用emerging Physics Informed Neural Networks（PINNs）方法预测压缩机螺旋叶流场。该方法在二维问题上进行了示例，并包括了 Navier-Stokes 方程在前向和反向问题中。在前向问题中，PINNs有效地预测了压缩机的流场。与深度神经网络（DNNs）相比，PINNs 模型具有物理关系的相互关系，从而实现了更加精确的预测。在 inverse 问题中，PINNs 显示出了与传统 CFD 方法相比的明显优势，可以在缺少部分边界条件时成功重建压缩机螺旋叶流场。这项研究提供了证明 PINNs 对液压机设计师提供了一个可靠的代替方法，比 DNNs 更高精度。
</details></li>
</ul>
<hr>
<h2 id="Handwritten-and-Printed-Text-Segmentation-A-Signature-Case-Study"><a href="#Handwritten-and-Printed-Text-Segmentation-A-Signature-Case-Study" class="headerlink" title="Handwritten and Printed Text Segmentation: A Signature Case Study"></a>Handwritten and Printed Text Segmentation: A Signature Case Study</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07887">http://arxiv.org/abs/2307.07887</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sina Gholamian, Ali Vahdat</li>
<li>for: 提高手写和印刷文本分类精度</li>
<li>methods: 引入新的数据集SignaTR6K和模型架构</li>
<li>results: 比对先前工作提高17.9%和7.3%的IOU分数<details>
<summary>Abstract</summary>
While analyzing scanned documents, handwritten text can overlap with printed text. This overlap causes difficulties during the optical character recognition (OCR) and digitization process of documents, and subsequently, hurts downstream NLP tasks. Prior research either focuses solely on the binary classification of handwritten text or performs a three-class segmentation of the document, i.e., recognition of handwritten, printed, and background pixels. This approach results in the assignment of overlapping handwritten and printed pixels to only one of the classes, and thus, they are not accounted for in the other class. Thus, in this research, we develop novel approaches to address the challenges of handwritten and printed text segmentation. Our objective is to recover text from different classes in their entirety, especially enhancing the segmentation performance on overlapping sections. To support this task, we introduce a new dataset, SignaTR6K, collected from real legal documents, as well as a new model architecture for the handwritten and printed text segmentation task. Our best configuration outperforms prior work on two different datasets by 17.9% and 7.3% on IoU scores. The SignaTR6K dataset is accessible for download via the following link: https://forms.office.com/r/2a5RDg7cAY.
</details>
<details>
<summary>摘要</summary>
While analyzing scanned documents, handwritten text can overlap with printed text. This overlap causes difficulties during the optical character recognition (OCR) and digitization process of documents, and subsequently, hurts downstream NLP tasks. Prior research either focuses solely on the binary classification of handwritten text or performs a three-class segmentation of the document, i.e., recognition of handwritten, printed, and background pixels. This approach results in the assignment of overlapping handwritten and printed pixels to only one of the classes, and thus, they are not accounted for in the other class. Therefore, in this research, we develop novel approaches to address the challenges of handwritten and printed text segmentation. Our objective is to recover text from different classes in their entirety, especially enhancing the segmentation performance on overlapping sections. To support this task, we introduce a new dataset, SignaTR6K, collected from real legal documents, as well as a new model architecture for the handwritten and printed text segmentation task. Our best configuration outperforms prior work on two different datasets by 17.9% and 7.3% on IoU scores. The SignaTR6K dataset is accessible for download via the following link: https://forms.office.com/r/2a5RDg7cAY.
</details></li>
</ul>
<hr>
<h2 id="Intuitionistic-Fuzzy-Broad-Learning-System-Enhancing-Robustness-Against-Noise-and-Outliers"><a href="#Intuitionistic-Fuzzy-Broad-Learning-System-Enhancing-Robustness-Against-Noise-and-Outliers" class="headerlink" title="Intuitionistic Fuzzy Broad Learning System: Enhancing Robustness Against Noise and Outliers"></a>Intuitionistic Fuzzy Broad Learning System: Enhancing Robustness Against Noise and Outliers</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08713">http://arxiv.org/abs/2307.08713</a></li>
<li>repo_url: None</li>
<li>paper_authors: M. Sajid, A. K. Malik, M. Tanveer<br>for: 提高 Broad Learning System (BLS) 的稳定性和有效性，应对实际数据集中噪声和异常值的问题。methods: 提出了两种改进 BLS 模型：含隐式含度的 F-BLS 模型和基于直觉含数理论的 IF-BLS 模型。两种模型都使用距离函数来评估训练点的成员度，但是 F-BLS 模型只考虑训练点与类中心的距离，而 IF-BLS 模型则考虑训练点的含度和非含度。results: 对于 44 个 UCI 数据集和 ADNI 数据集，提出的 F-BLS 和 IF-BLS 模型都显示出优于基eline 模型的总体化能力和鲁棒性。具有噪声的 UCI 数据集上，提出的方法也能够保持比较高的总体化能力和鲁棒性。<details>
<summary>Abstract</summary>
In the realm of data classification, broad learning system (BLS) has proven to be a potent tool that utilizes a layer-by-layer feed-forward neural network. It consists of feature learning and enhancement segments, working together to extract intricate features from input data. The traditional BLS treats all samples as equally significant, which makes it less robust and less effective for real-world datasets with noises and outliers. To address this issue, we propose the fuzzy BLS (F-BLS) model, which assigns a fuzzy membership value to each training point to reduce the influence of noises and outliers. In assigning the membership value, the F-BLS model solely considers the distance from samples to the class center in the original feature space without incorporating the extent of non-belongingness to a class. We further propose a novel BLS based on intuitionistic fuzzy theory (IF-BLS). The proposed IF-BLS utilizes intuitionistic fuzzy numbers based on fuzzy membership and non-membership values to assign scores to training points in the high-dimensional feature space by using a kernel function. We evaluate the performance of proposed F-BLS and IF-BLS models on 44 UCI benchmark datasets across diverse domains. Furthermore, Gaussian noise is added to some UCI datasets to assess the robustness of the proposed F-BLS and IF-BLS models. Experimental results demonstrate superior generalization performance of the proposed F-BLS and IF-BLS models compared to baseline models, both with and without Gaussian noise. Additionally, we implement the proposed F-BLS and IF-BLS models on the Alzheimers Disease Neuroimaging Initiative (ADNI) dataset, and promising results showcase the models effectiveness in real-world applications. The proposed methods offer a promising solution to enhance the BLS frameworks ability to handle noise and outliers.
</details>
<details>
<summary>摘要</summary>
在数据分类领域，广泛学习系统（BLS）已经证明是一种强大的工具，使用层次 feed-forward 神经网络。它包括特征学习和提升段，共同提取输入数据中细腻的特征。传统的 BLS 对所有样本都视为一样重要，这使得它在真实世界的数据集中 less robust 和 less effective。为解决这个问题，我们提出了模糊 BLS（F-BLS）模型，它将对each training point 分配模糊会员价值，以降低噪声和异常值的影响。在分配会员价值时，F-BLS 模型只考虑样本与类中心的距离在原始特征空间中，不考虑类外的非属性程度。我们还提出了基于INTUITIONISTIC FUZZY理论（IF-BLS）的新模型。该模型使用INTUITIONISTIC FUZZY数字，基于模糊会员价值和非会员价值来对训练点进行分配分数。我们对44个 UCI benchmark 数据集进行了评估，并在一些 UCI 数据集上添加了高斯噪声，以评估我们提出的 F-BLS 和 IF-BLS 模型的Robustness。实验结果表明我们的提出的 F-BLS 和 IF-BLS 模型在对比基eline模型时表现出优化的总体化能力，同时在噪声和异常值存在的情况下也有优异的表现。此外，我们在ADNI 数据集上实现了我们的 F-BLS 和 IF-BLS 模型，并得到了有 promise 的结果，这表明我们的方法在真实世界应用中具有潜在的价值。我们的方法可以增强 BLS 框架对噪声和异常值的处理能力。
</details></li>
</ul>
<hr>
<h2 id="Gradient-free-training-of-neural-ODEs-for-system-identification-and-control-using-ensemble-Kalman-inversion"><a href="#Gradient-free-training-of-neural-ODEs-for-system-identification-and-control-using-ensemble-Kalman-inversion" class="headerlink" title="Gradient-free training of neural ODEs for system identification and control using ensemble Kalman inversion"></a>Gradient-free training of neural ODEs for system identification and control using ensemble Kalman inversion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07882">http://arxiv.org/abs/2307.07882</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://gitlab.com/computationalscience/eki-neural-ode">https://gitlab.com/computationalscience/eki-neural-ode</a></li>
<li>paper_authors: Lucas Böttcher</li>
<li>for:  solves inverse problems within a Bayesian framework for system identification and optimal control tasks</li>
<li>methods:  Ensemble Kalman inversion (EKI), a sequential Monte Carlo method that is gradient-free and only requires forward passes to evaluate artificial neural networks</li>
<li>results:  EKI is an efficient method for training neural ODEs, with competitive runtime and solution quality compared to commonly used gradient-based optimizers.<details>
<summary>Abstract</summary>
Ensemble Kalman inversion (EKI) is a sequential Monte Carlo method used to solve inverse problems within a Bayesian framework. Unlike backpropagation, EKI is a gradient-free optimization method that only necessitates the evaluation of artificial neural networks in forward passes. In this study, we examine the effectiveness of EKI in training neural ordinary differential equations (neural ODEs) for system identification and control tasks. To apply EKI to optimal control problems, we formulate inverse problems that incorporate a Tikhonov-type regularization term. Our numerical results demonstrate that EKI is an efficient method for training neural ODEs in system identification and optimal control problems, with runtime and quality of solutions that are competitive with commonly used gradient-based optimizers.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Graph-Embedded-Intuitionistic-Fuzzy-RVFL-for-Class-Imbalance-Learning"><a href="#Graph-Embedded-Intuitionistic-Fuzzy-RVFL-for-Class-Imbalance-Learning" class="headerlink" title="Graph Embedded Intuitionistic Fuzzy RVFL for Class Imbalance Learning"></a>Graph Embedded Intuitionistic Fuzzy RVFL for Class Imbalance Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07881">http://arxiv.org/abs/2307.07881</a></li>
<li>repo_url: None</li>
<li>paper_authors: M. A. Ganaie, M. Sajid, A. K. Malik, M. Tanveer</li>
<li>for: 该论文目的是解决机器学习领域中的类异常学习问题，即处理含有少量样本的训练集时，模型往往受到类别偏好的影响，导致少量类型的样本被排除。</li>
<li>methods: 该论文提出了一种基于图像函数链（RVFL）网络的新型分类模型，称为图像函数链 intuitionistic 瑞利（GE-IFRVFL）模型。该模型利用图像函数来提取数据集中的含义丰富信息，并使用 Intuitionistic 瑞利集来处理数据中的不确定性和不准确性。</li>
<li>results: 该论文在多个 benchmark 不均衡数据集上进行了实验，结果表明，与传统 RVFL 网络相比，GE-IFRVFL 模型在处理不均衡数据集时表现出了明显的优势。此外，该论文还应用了该模型在 ADNI 数据集上，并取得了良好的结果，证明该模型在实际应用中也具有出色的表现。<details>
<summary>Abstract</summary>
The domain of machine learning is confronted with a crucial research area known as class imbalance learning, which presents considerable hurdles in the precise classification of minority classes. This issue can result in biased models where the majority class takes precedence in the training process, leading to the underrepresentation of the minority class. The random vector functional link (RVFL) network is a widely-used and effective learning model for classification due to its speed and efficiency. However, it suffers from low accuracy when dealing with imbalanced datasets. To overcome this limitation, we propose a novel graph embedded intuitionistic fuzzy RVFL for class imbalance learning (GE-IFRVFL-CIL) model incorporating a weighting mechanism to handle imbalanced datasets. The proposed GE-IFRVFL-CIL model has a plethora of benefits, such as $(i)$ it leverages graph embedding to extract semantically rich information from the dataset, $(ii)$ it uses intuitionistic fuzzy sets to handle uncertainty and imprecision in the data, $(iii)$ and the most important, it tackles class imbalance learning. The amalgamation of a weighting scheme, graph embedding, and intuitionistic fuzzy sets leads to the superior performance of the proposed model on various benchmark imbalanced datasets, including UCI and KEEL. Furthermore, we implement the proposed GE-IFRVFL-CIL on the ADNI dataset and achieved promising results, demonstrating the model's effectiveness in real-world applications. The proposed method provides a promising solution for handling class imbalance in machine learning and has the potential to be applied to other classification problems.
</details>
<details>
<summary>摘要</summary>
machine learning 领域面临一个重要的研究领域，即类别不均衡学习（Class Imbalance Learning，简称 CIL），这种情况可能导致模型偏向主要类别，从而导致少数类别的下 represencing。Random vector functional link（RVFL）网络是一种广泛使用和高效的学习模型，但它在不均衡数据集上表现不佳。为了解决这个限制，我们提出了一种基于图embeded intuitionistic fuzzy RVFL（GE-IFRVFL-CIL）模型，该模型具有以下优点：$(i)$ 利用图embeded提取数据集中具有含义的信息；$(ii)$ 使用intuitionistic fuzzy sets处理数据中的不确定和不准确性；$(iii)$ 特别是，解决类别不均衡学习问题。通过将权重机制、图embeded和intuitionistic fuzzy sets结合在一起，我们的模型在多个benchmark不均衡数据集上表现出色，包括UCI和KEEL。此外，我们在ADNI数据集上实现了该模型，并获得了可观的结果，证明了模型在实际应用中的效果。本方法为处理机器学习中的类别不均衡提供了一个有 Promise的解决方案，并可以应用于其他分类问题。
</details></li>
</ul>
<hr>
<h2 id="Why-Does-Little-Robustness-Help-Understanding-Adversarial-Transferability-From-Surrogate-Training"><a href="#Why-Does-Little-Robustness-Help-Understanding-Adversarial-Transferability-From-Surrogate-Training" class="headerlink" title="Why Does Little Robustness Help? Understanding Adversarial Transferability From Surrogate Training"></a>Why Does Little Robustness Help? Understanding Adversarial Transferability From Surrogate Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07873">http://arxiv.org/abs/2307.07873</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yechao Zhang, Shengshan Hu, Leo Yu Zhang, Junyu Shi, Minghui Li, Xiaogeng Liu, Wei Wan, Hai Jin</li>
<li>for: 本研究旨在更深入地理解对 Deep Neural Networks (DNNs) 的抗击例软件的可迁移性，尤其是在代理模型方面。</li>
<li>methods: 本研究使用了一系列的理论和实验分析，探讨了两个主要因素——模型平滑性和梯度相似性——如何影响对 DNNs 的抗击例软件的可迁移性。</li>
<li>results: 研究发现，在对 DNNs 进行 adversarial 训练时，模型平滑性和梯度相似性之间存在负相关关系，而这两个因素又与对 DNNs 的抗击例软件的可迁移性有着普遍的影响。通过调整数据增强和梯度正则化，可以同时提高模型平滑性和梯度相似性，从而提高对 DNNs 的抗击例软件的可迁移性。<details>
<summary>Abstract</summary>
Adversarial examples (AEs) for DNNs have been shown to be transferable: AEs that successfully fool white-box surrogate models can also deceive other black-box models with different architectures. Although a bunch of empirical studies have provided guidance on generating highly transferable AEs, many of these findings lack explanations and even lead to inconsistent advice. In this paper, we take a further step towards understanding adversarial transferability, with a particular focus on surrogate aspects. Starting from the intriguing little robustness phenomenon, where models adversarially trained with mildly perturbed adversarial samples can serve as better surrogates, we attribute it to a trade-off between two predominant factors: model smoothness and gradient similarity. Our investigations focus on their joint effects, rather than their separate correlations with transferability. Through a series of theoretical and empirical analyses, we conjecture that the data distribution shift in adversarial training explains the degradation of gradient similarity. Building on these insights, we explore the impacts of data augmentation and gradient regularization on transferability and identify that the trade-off generally exists in the various training mechanisms, thus building a comprehensive blueprint for the regulation mechanism behind transferability. Finally, we provide a general route for constructing better surrogates to boost transferability which optimizes both model smoothness and gradient similarity simultaneously, e.g., the combination of input gradient regularization and sharpness-aware minimization (SAM), validated by extensive experiments. In summary, we call for attention to the united impacts of these two factors for launching effective transfer attacks, rather than optimizing one while ignoring the other, and emphasize the crucial role of manipulating surrogate models.
</details>
<details>
<summary>摘要</summary>
深度学习模型（DNN）的敌对示例（AE）已经被证明可以传播：AE 可以在不同的模型结构下骗别的黑盒模型。虽然一些实验研究提供了生成高度传播的AE的指导，但是大多数这些发现缺乏解释，甚至导致不一致的建议。在这篇文章中，我们带领读者一步进一步地了解对抗传播性，特别是在代理方面。我们从小的Robustness现象出发，其中模型在弱相对抗样本上进行了适应性训练后，可以作为更好的代理模型。我们归因这一现象于两个主要因素的贡献：模型的平滑性和梯度相似性。我们的分析将注重这两个因素之间的共同效应，而不是它们与传播性之间的相互关系。通过一系列理论和实验分析，我们提出了数据分布shift在对抗训练中的影响，以及如何通过数据增强和梯度规则来调节传播性。最后，我们提出了一种通用的制定机制，可以同时优化模型的平滑性和梯度相似性，并通过广泛的实验证明其效果。因此，我们呼吁关注这两个因素的共同影响，而不是仅仅优化一个而忽略另一个，并强调在制定代理模型时的重要性。
</details></li>
</ul>
<hr>
<h2 id="Does-Double-Descent-Occur-in-Self-Supervised-Learning"><a href="#Does-Double-Descent-Occur-in-Self-Supervised-Learning" class="headerlink" title="Does Double Descent Occur in Self-Supervised Learning?"></a>Does Double Descent Occur in Self-Supervised Learning?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07872">http://arxiv.org/abs/2307.07872</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yonatangideoni/double_descent_tiny_paper">https://github.com/yonatangideoni/double_descent_tiny_paper</a></li>
<li>paper_authors: Alisia Lupidi, Yonatan Gideoni, Dulhan Jayalath</li>
<li>for:  investigate the existence of double descent in self-supervised models</li>
<li>methods: use standard and linear autoencoders, two previously unstudied settings</li>
<li>results: the test loss either has a classical U-shape or monotonically decreases, without exhibiting a double-descent curve.<details>
<summary>Abstract</summary>
Most investigations into double descent have focused on supervised models while the few works studying self-supervised settings find a surprising lack of the phenomenon. These results imply that double descent may not exist in self-supervised models. We show this empirically using a standard and linear autoencoder, two previously unstudied settings. The test loss is found to have either a classical U-shape or to monotonically decrease instead of exhibiting a double-descent curve. We hope that further work on this will help elucidate the theoretical underpinnings of this phenomenon.
</details>
<details>
<summary>摘要</summary>
大多数调查双峰现象都集中在指导学习模型上，而自适应学习设置中的研究却有很少。这些结果表明双峰现象可能不存在于自适应模型中。我们通过标准和线性自动编码器两种未研究过的设置来证实这一点。测试损失的曲线可以分为两种：一种是经典的U型曲线，另一种是 monotonically decrease 而不是展现双峰曲线。我们希望未来的研究能够深入探讨这一现象的理论基础。
</details></li>
</ul>
<hr>
<h2 id="The-SocialAI-School-Insights-from-Developmental-Psychology-Towards-Artificial-Socio-Cultural-Agents"><a href="#The-SocialAI-School-Insights-from-Developmental-Psychology-Towards-Artificial-Socio-Cultural-Agents" class="headerlink" title="The SocialAI School: Insights from Developmental Psychology Towards Artificial Socio-Cultural Agents"></a>The SocialAI School: Insights from Developmental Psychology Towards Artificial Socio-Cultural Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07871">http://arxiv.org/abs/2307.07871</a></li>
<li>repo_url: None</li>
<li>paper_authors: Grgur Kovač, Rémy Portelas, Peter Ford Dominey, Pierre-Yves Oudeyer</li>
<li>for: 这个论文主要是为了探讨人工智能在社会交互 Setting中的发展，以及如何通过发展心理学来帮助AI研究社会智能。</li>
<li>methods: 这篇论文使用了Michael Tomasello和Jerome Bruner等发展心理学家的理论，并提出了一个可 parameterized 的社交AI学校，用于帮助研究者进行相关的实验和研究。</li>
<li>results: 这篇论文的结果表明，通过使用社交AI学校，可以让RL代理和大语言模型在社交交互 Setting中展现出更高的社会智能能力。同时，这篇论文也提供了一个简单的入门点，以帮助AI研究者更好地理解和应用发展心理学。<details>
<summary>Abstract</summary>
Developmental psychologists have long-established the importance of socio-cognitive abilities in human intelligence. These abilities enable us to enter, participate and benefit from human culture. AI research on social interactive agents mostly concerns the emergence of culture in a multi-agent setting (often without a strong grounding in developmental psychology). We argue that AI research should be informed by psychology and study socio-cognitive abilities enabling to enter a culture too. We discuss the theories of Michael Tomasello and Jerome Bruner to introduce some of their concepts to AI and outline key concepts and socio-cognitive abilities. We present The SocialAI school - a tool including a customizable parameterized uite of procedurally generated environments, which simplifies conducting experiments regarding those concepts. We show examples of such experiments with RL agents and Large Language Models. The main motivation of this work is to engage the AI community around the problem of social intelligence informed by developmental psychology, and to provide a tool to simplify first steps in this direction. Refer to the project website for code and additional information: https://sites.google.com/view/socialai-school.
</details>
<details>
<summary>摘要</summary>
We draw on the theories of Michael Tomasello and Jerome Bruner to introduce some of their concepts in AI and outline key socio-cognitive abilities. We present the SocialAI school, a tool that includes a customizable parameterized suite of procedurally generated environments, which simplifies conducting experiments regarding these concepts. We demonstrate examples of such experiments with reinforcement learning (RL) agents and large language models.Our main motivation is to engage the AI community in the problem of social intelligence informed by developmental psychology and provide a tool to simplify initial steps in this direction. For more information and access to the project's code, please refer to the project website at <https://sites.google.com/view/socialai-school>.
</details></li>
</ul>
<hr>
<h2 id="Large-Language-Models-as-Superpositions-of-Cultural-Perspectives"><a href="#Large-Language-Models-as-Superpositions-of-Cultural-Perspectives" class="headerlink" title="Large Language Models as Superpositions of Cultural Perspectives"></a>Large Language Models as Superpositions of Cultural Perspectives</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07870">http://arxiv.org/abs/2307.07870</a></li>
<li>repo_url: None</li>
<li>paper_authors: Grgur Kovač, Masataka Sawayama, Rémy Portelas, Cédric Colas, Peter Ford Dominey, Pierre-Yves Oudeyer</li>
<li>for: 这 paper 主要研究了大型自然语言模型 (LLMs) 是如何被识别为具有人性或价值观的问题。</li>
<li>methods: 作者使用了问卷调查 (PVQ, VSM, IPIP) 来研究 LLMS 在不同情境下表达的价值和人性特质是如何变化的。他们还通过质量实验来示例 LLMS 在不同情境下表达的价值是如何改变的。</li>
<li>results: 研究发现 LLMS 在不同情境下表达的价值和人性特质是 Context-dependent 的，并且可以通过不同的方法来控制这些表达。同时，作者还发现了不同模型的 drivability 和可控性。<details>
<summary>Abstract</summary>
Large Language Models (LLMs) are often misleadingly recognized as having a personality or a set of values. We argue that an LLM can be seen as a superposition of perspectives with different values and personality traits. LLMs exhibit context-dependent values and personality traits that change based on the induced perspective (as opposed to humans, who tend to have more coherent values and personality traits across contexts). We introduce the concept of perspective controllability, which refers to a model's affordance to adopt various perspectives with differing values and personality traits. In our experiments, we use questionnaires from psychology (PVQ, VSM, IPIP) to study how exhibited values and personality traits change based on different perspectives. Through qualitative experiments, we show that LLMs express different values when those are (implicitly or explicitly) implied in the prompt, and that LLMs express different values even when those are not obviously implied (demonstrating their context-dependent nature). We then conduct quantitative experiments to study the controllability of different models (GPT-4, GPT-3.5, OpenAssistant, StableVicuna, StableLM), the effectiveness of various methods for inducing perspectives, and the smoothness of the models' drivability. We conclude by examining the broader implications of our work and outline a variety of associated scientific questions. The project website is available at https://sites.google.com/view/llm-superpositions .
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM）经常被误认为具有人格或一组价值观。我们认为，LLM可以看作是一个积加的视角，具有不同的价值观和人格特质。LLM在不同的上下文中展现出不同的价值观和人格特质，而人类在不同上下文中的价值观和人格特质往往更加一致。我们提出了“视角可控性”概念，即模型可以采取不同的视角，以便采取不同的价值观和人格特质。我们通过心理测试（PVQ、VSM、IPIP）研究了LLM在不同上下文中表达的价值观和人格特质是如何变化的。我们还通过质量实验表明，LLM在不同的提示下表达不同的价值观，而且这些价值观不一定是明确地表达出来的（ demonstrate 其上下文相依性）。我们然后进行了量化实验，研究不同模型（GPT-4、GPT-3.5、OpenAssistant、StableVicuna、StableLM）的可控性，不同方法的影响和模型的顺略性。我们最后结论，我们的工作有很多相关科学问题，并提出了一些新的科学问题。相关研究网站地址为 <https://sites.google.com/view/llm-superpositions>。
</details></li>
</ul>
<hr>
<h2 id="Custom-DNN-using-Reward-Modulated-Inverted-STDP-Learning-for-Temporal-Pattern-Recognition"><a href="#Custom-DNN-using-Reward-Modulated-Inverted-STDP-Learning-for-Temporal-Pattern-Recognition" class="headerlink" title="Custom DNN using Reward Modulated Inverted STDP Learning for Temporal Pattern Recognition"></a>Custom DNN using Reward Modulated Inverted STDP Learning for Temporal Pattern Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07869">http://arxiv.org/abs/2307.07869</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vijay Shankaran Vivekanand, Rajkumar Kubendran</li>
<li>for: 本研究旨在提出一种高效的时间峰检测算法，用于各种领域，如异常检测、关键词检测和神经科学。</li>
<li>methods: 该算法结合奖金补偿行为、HEBBbian和反HEBBbian基于学习方法，可以在动态数据集上高效地识别时间峰模式。</li>
<li>results: 对于一个复杂的语音数据集，该算法的表现比 estado-of-the-art 更高， indicating that the algorithm can effectively recognize temporal spike patterns in real-world data.<details>
<summary>Abstract</summary>
Temporal spike recognition plays a crucial role in various domains, including anomaly detection, keyword spotting and neuroscience. This paper presents a novel algorithm for efficient temporal spike pattern recognition on sparse event series data. The algorithm leverages a combination of reward-modulatory behavior, Hebbian and anti-Hebbian based learning methods to identify patterns in dynamic datasets with short intervals of training. The algorithm begins with a preprocessing step, where the input data is rationalized and translated to a feature-rich yet sparse spike time series data. Next, a linear feed forward spiking neural network processes this data to identify a trained pattern. Finally, the next layer performs a weighted check to ensure the correct pattern has been detected.To evaluate the performance of the proposed algorithm, it was trained on a complex dataset containing spoken digits with spike information and its output compared to state-of-the-art.
</details>
<details>
<summary>摘要</summary>
<<SYS>>Temporal spike recognition plays a crucial role in various domains, including anomaly detection, keyword spotting, and neuroscience. This paper presents a novel algorithm for efficient temporal spike pattern recognition on sparse event series data. The algorithm leverages a combination of reward-modulatory behavior, Hebbian, and anti-Hebbian based learning methods to identify patterns in dynamic datasets with short intervals of training. The algorithm begins with a preprocessing step, where the input data is rationalized and translated to a feature-rich yet sparse spike time series data. Next, a linear feed forward spiking neural network processes this data to identify a trained pattern. Finally, the next layer performs a weighted check to ensure the correct pattern has been detected. To evaluate the performance of the proposed algorithm, it was trained on a complex dataset containing spoken digits with spike information and its output compared to state-of-the-art.中文简体版： Temporal spike recognition在各种领域都扮演着关键角色，包括异常检测、关键词检测和神经科学。本文提出了一种高效的时间脉冲模式识别算法，用于处理缺省事件序列数据。该算法结合奖励调节行为、希伯纳和反希伯纳基本学习方法，在短期培训下 indentify动态数据中的模式。该算法的前期处理步骤将输入数据理解化和转换为具有丰富特征 yet sparse spike时间序列数据。接着，一个线性径向冲击神经网络处理这些数据，以标识已经训练的模式。最后，下一层 performs一个权重检查，以确保正确的模式已经被检测到。为评估提出的算法性能，它被训练在一个包含 spoken digits 的复杂数据集上，并与当前领先的输出进行比较。
</details></li>
</ul>
<hr>
<h2 id="Contrasting-the-efficiency-of-stock-price-prediction-models-using-various-types-of-LSTM-models-aided-with-sentiment-analysis"><a href="#Contrasting-the-efficiency-of-stock-price-prediction-models-using-various-types-of-LSTM-models-aided-with-sentiment-analysis" class="headerlink" title="Contrasting the efficiency of stock price prediction models using various types of LSTM models aided with sentiment analysis"></a>Contrasting the efficiency of stock price prediction models using various types of LSTM models aided with sentiment analysis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07868">http://arxiv.org/abs/2307.07868</a></li>
<li>repo_url: None</li>
<li>paper_authors: Varun Sangwan, Vishesh Kumar Singh, Bibin Christopher V</li>
<li>for: 该研究目标是找到使用公司预测和行业表现来正确预测股票价格，包括短期和长期目标。</li>
<li>methods: 该研究使用公司预测和行业表现来建立模型，以便预测股票价格。</li>
<li>results: 该研究得到的结果可以帮助投资者更好地理解公司的股票价格，并且可以用于长期和短期投资决策。I hope this helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Our research aims to find the best model that uses companies projections and sector performances and how the given company fares accordingly to correctly predict equity share prices for both short and long term goals.
</details>
<details>
<summary>摘要</summary>
我们的研究目标是找到最佳的模型，该使用公司预测和行业表现来正确预测股票价格，包括短期和长期目标。
</details></li>
</ul>
<hr>
<h2 id="Benchmarking-the-Effectiveness-of-Classification-Algorithms-and-SVM-Kernels-for-Dry-Beans"><a href="#Benchmarking-the-Effectiveness-of-Classification-Algorithms-and-SVM-Kernels-for-Dry-Beans" class="headerlink" title="Benchmarking the Effectiveness of Classification Algorithms and SVM Kernels for Dry Beans"></a>Benchmarking the Effectiveness of Classification Algorithms and SVM Kernels for Dry Beans</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07863">http://arxiv.org/abs/2307.07863</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anant Mehta, Prajit Sengupta, Divisha Garg, Harpreet Singh, Yosi Shacham Diamand</li>
<li>for: 增强作物产量，植物育种者和农业研究人员可以通过识别感兴趣特征、疾病抵抗力和营养含量来提高作物产量。</li>
<li>methods: 本研究使用了不同的支持向量机(SVM)分类算法，包括直线、多项式和径向基函数(RBF)，以及其他流行的分类算法进行比较和分析。为了降低维度，使用了主成分分析(PCA)进行预处理。</li>
<li>results: 研究发现，使用径向基函数(RBF) SVM 算法可以达到最高的准确率（93.34%）、精度（92.61%）、回归率（92.35%）和 F1 分数（91.40%）。此外，研究还提供了有用的视觉化和实验分析，为识别不同 SVM 算法在复杂和非线性结构的数据集中的重要性提供了有价值的指导。<details>
<summary>Abstract</summary>
Plant breeders and agricultural researchers can increase crop productivity by identifying desirable features, disease resistance, and nutritional content by analysing the Dry Bean dataset. This study analyses and compares different Support Vector Machine (SVM) classification algorithms, namely linear, polynomial, and radial basis function (RBF), along with other popular classification algorithms. The analysis is performed on the Dry Bean Dataset, with PCA (Principal Component Analysis) conducted as a preprocessing step for dimensionality reduction. The primary evaluation metric used is accuracy, and the RBF SVM kernel algorithm achieves the highest Accuracy of 93.34%, Precision of 92.61%, Recall of 92.35% and F1 Score as 91.40%. Along with adept visualization and empirical analysis, this study offers valuable guidance by emphasizing the importance of considering different SVM algorithms for complex and non-linear structured datasets.
</details>
<details>
<summary>摘要</summary>
植物育种者和农业研究人员可以通过识别有利特征、疾病抵抗力和营养含量来提高作物产量。这个研究分析和比较不同的支持向量机器学习（SVM）分类算法，包括直线、多项式和径向基函数（RBF），以及其他流行的分类算法。研究使用了干豇数据集，先进行了主成分分析（PCA）作为维度减少步骤。主要评价指标是准确率，RBF SVM 算法实现了最高的准确率为 93.34%、精度为 92.61%、回归率为 92.35% 和 F1 分数为 91.40%。此外，研究还提供了丰富的视觉化和实证分析，为复杂和非线性结构数据中的SVM算法选择提供了有价值的指导。
</details></li>
</ul>
<hr>
<h2 id="Automated-Knowledge-Modeling-for-Cancer-Clinical-Practice-Guidelines"><a href="#Automated-Knowledge-Modeling-for-Cancer-Clinical-Practice-Guidelines" class="headerlink" title="Automated Knowledge Modeling for Cancer Clinical Practice Guidelines"></a>Automated Knowledge Modeling for Cancer Clinical Practice Guidelines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.10231">http://arxiv.org/abs/2307.10231</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pralaypati Ta, Bhumika Gupta, Arihant Jain, Sneha Sree C, Arunima Sarkar, Keerthi Ram, Mohanasankar Sivaprakasam<br>for:This paper aims to develop an automated method for extracting knowledge from National Comprehensive Cancer Network (NCCN) Clinical Practice Guidelines (CPGs) in Oncology and generating a structured model containing the retrieved knowledge.methods:The proposed method uses natural language processing (NLP) techniques to extract knowledge from NCCN CPGs, and employs a knowledge model to represent the extracted knowledge in a structured format. The method also includes three enrichment strategies to enhance the model: Cancer staging information, UMLS Metathesaurus &amp; NCIt concepts, and Node classification.results:The proposed method was tested using two versions of NCCN Non-Small Cell Lung Cancer (NSCLC) CPG, and achieved a high accuracy of 0.81 in Node classification using a Support Vector Machine (SVM) model with 10-fold cross-validation.<details>
<summary>Abstract</summary>
Clinical Practice Guidelines (CPGs) for cancer diseases evolve rapidly due to new evidence generated by active research. Currently, CPGs are primarily published in a document format that is ill-suited for managing this developing knowledge. A knowledge model of the guidelines document suitable for programmatic interaction is required. This work proposes an automated method for extraction of knowledge from National Comprehensive Cancer Network (NCCN) CPGs in Oncology and generating a structured model containing the retrieved knowledge. The proposed method was tested using two versions of NCCN Non-Small Cell Lung Cancer (NSCLC) CPG to demonstrate the effectiveness in faithful extraction and modeling of knowledge. Three enrichment strategies using Cancer staging information, Unified Medical Language System (UMLS) Metathesaurus & National Cancer Institute thesaurus (NCIt) concepts, and Node classification are also presented to enhance the model towards enabling programmatic traversal and querying of cancer care guidelines. The Node classification was performed using a Support Vector Machine (SVM) model, achieving a classification accuracy of 0.81 with 10-fold cross-validation.
</details>
<details>
<summary>摘要</summary>
临床实践指南 (CPGs) for cancer diseases 在新证据的激发下不断发展。目前，CPGs 主要以文档格式发布，这种格式不适合管理这些发展中的知识。这项工作提出了一种自动提取 CPGS 文档中的知识并生成一个结构化模型的方法。该方法在使用两个版本的 National Comprehensive Cancer Network (NCCN) Non-Small Cell Lung Cancer (NSCLC) CPG 进行测试，并证明了 faithful 提取和模型知识的效果。此外，文章还提出了三种润色策略，使得模型具有可programmatic traversal和querying cancer care guidelines的能力。这三种润色策略分别是使用 Cancer 分期信息、Unified Medical Language System (UMLS) Metathesaurus & National Cancer Institute thesaurus (NCIt) 概念以及节点分类。Node 分类使用 Support Vector Machine (SVM) 模型，在10-fold cross-validation中达到了0.81的分类精度。
</details></li>
</ul>
<hr>
<h2 id="Variational-Inference-with-Gaussian-Score-Matching"><a href="#Variational-Inference-with-Gaussian-Score-Matching" class="headerlink" title="Variational Inference with Gaussian Score Matching"></a>Variational Inference with Gaussian Score Matching</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07849">http://arxiv.org/abs/2307.07849</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/modichirag/gsm-vi">https://github.com/modichirag/gsm-vi</a></li>
<li>paper_authors: Chirag Modi, Charles Margossian, Yuling Yao, Robert Gower, David Blei, Lawrence Saul</li>
<li>For: The paper is written for researchers and practitioners interested in Bayesian inference and variational inference.* Methods: The paper proposes a new approach to variational inference called score matching variational inference (GSM-VI), which is based on the principle of score matching and can be applied to a wide class of models. The algorithm iteratively adjusts the variational estimate to match the scores at a newly sampled value of the latent variables.* Results: The paper compares GSM-VI to black box variational inference (BBVI) and studies how GSM-VI behaves as a function of the problem dimensionality, the condition number of the target covariance matrix, and the degree of mismatch between the approximating and exact posterior distribution. The results show that GSM-VI is faster than BBVI and requires fewer gradient evaluations to obtain a comparable quality of approximation.<details>
<summary>Abstract</summary>
Variational inference (VI) is a method to approximate the computationally intractable posterior distributions that arise in Bayesian statistics. Typically, VI fits a simple parametric distribution to the target posterior by minimizing an appropriate objective such as the evidence lower bound (ELBO). In this work, we present a new approach to VI based on the principle of score matching, that if two distributions are equal then their score functions (i.e., gradients of the log density) are equal at every point on their support. With this, we develop score matching VI, an iterative algorithm that seeks to match the scores between the variational approximation and the exact posterior. At each iteration, score matching VI solves an inner optimization, one that minimally adjusts the current variational estimate to match the scores at a newly sampled value of the latent variables. We show that when the variational family is a Gaussian, this inner optimization enjoys a closed form solution, which we call Gaussian score matching VI (GSM-VI). GSM-VI is also a ``black box'' variational algorithm in that it only requires a differentiable joint distribution, and as such it can be applied to a wide class of models. We compare GSM-VI to black box variational inference (BBVI), which has similar requirements but instead optimizes the ELBO. We study how GSM-VI behaves as a function of the problem dimensionality, the condition number of the target covariance matrix (when the target is Gaussian), and the degree of mismatch between the approximating and exact posterior distribution. We also study GSM-VI on a collection of real-world Bayesian inference problems from the posteriorDB database of datasets and models. In all of our studies we find that GSM-VI is faster than BBVI, but without sacrificing accuracy. It requires 10-100x fewer gradient evaluations to obtain a comparable quality of approximation.
</details>
<details>
<summary>摘要</summary>
“统计学中的统计推理（Variational Inference，VI）是一种方法估计computationally intractable的 posterior distribution。通常，VI使用一个简单的 parametric distribution 来替代目标 posterior，并且使用一个适当的目标函数，例如证据下界（Evidence Lower Bound，ELBO）来对其进行最佳化。在这个研究中，我们提出了一种基于得分匹配原理的新方法，即得分匹配VI（Score Matching VI，SM-VI）。这个方法的基本思想是，如果两个分布相同，则它们的得分函数（即分布的LOG值的导数）在它们的支持集上也是相同的。我们透过对SM-VI进行迭代运算，将得分匹配到目标 posterior 中的分布。在每个迭代中，SM-VI解决一个内部优化问题，将当前的渠道估计匹配到目标 posterior 中的分布。当渠道家族为 Gaussian 时，内部优化问题具有关注形式的解，我们称之为 Gaussian Score Matching VI（GSM-VI）。GSM-VI 也是一个“黑盒子”渠道推理方法，它只需要一个可微的共同分布，并且可以应用到广泛的模型中。我们与黑盒子推理（BBVI）进行比较，BBVI 的要求相同，但是它将 ELBO 优化而不是得分匹配。我们研究了 GSM-VI 的行为，包括问题的维度、目标均值矩阵的条件数（当目标为 Gaussian 时）和渠道估计和实际 posterior 的匹配程度。我们还对一些真实世界的 Bayesian 推理问题进行了研究，包括 posteriorDB 数据库中的数据和模型。在所有的研究中，我们发现 GSM-VI 比 BBVI 快速，并且无需牺牲精度。GSM-VI 需要 10-100 倍 fewer gradient evaluations 以取得相同质量的渠道估计。”
</details></li>
</ul>
<hr>
<h2 id="Neural-Video-Recovery-for-Cloud-Gaming"><a href="#Neural-Video-Recovery-for-Cloud-Gaming" class="headerlink" title="Neural Video Recovery for Cloud Gaming"></a>Neural Video Recovery for Cloud Gaming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07847">http://arxiv.org/abs/2307.07847</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/neurons">https://github.com/Aryia-Behroziuan/neurons</a></li>
<li>paper_authors: Zhaoyuan He, Yifan Yang, Shuozhe Li, Diyuan Dai, Lili Qiu</li>
<li>for: 提高云游戏的视频恢复率和质量，以提供更好的游戏体验。</li>
<li>methods: 使用游戏状态进行视频恢复，并使用部分解码的帧来恢复丢失的视频部分。开发了一个整体系统，包括提取游戏状态、修改H.264视频解码器生成恢复帧的掩码，以及设计一种新的神经网络来恢复完整或部分的视频帧。</li>
<li>results: 通过iPhone 12和笔记机实现，证明了游戏状态在视频恢复中的重要性，以及我们的总体设计的有效性。<details>
<summary>Abstract</summary>
Cloud gaming is a multi-billion dollar industry. A client in cloud gaming sends its movement to the game server on the Internet, which renders and transmits the resulting video back. In order to provide a good gaming experience, a latency below 80 ms is required. This means that video rendering, encoding, transmission, decoding, and display have to finish within that time frame, which is especially challenging to achieve due to server overload, network congestion, and losses. In this paper, we propose a new method for recovering lost or corrupted video frames in cloud gaming. Unlike traditional video frame recovery, our approach uses game states to significantly enhance recovery accuracy and utilizes partially decoded frames to recover lost portions. We develop a holistic system that consists of (i) efficiently extracting game states, (ii) modifying H.264 video decoder to generate a mask to indicate which portions of video frames need recovery, and (iii) designing a novel neural network to recover either complete or partial video frames. Our approach is extensively evaluated using iPhone 12 and laptop implementations, and we demonstrate the utility of game states in the game video recovery and the effectiveness of our overall design.
</details>
<details>
<summary>摘要</summary>
云游戏是一个多亿美元的industry。一个客户端在云游戏中将其运动发送到游戏服务器上的互联网上，服务器将其渲染并将结果视频回传。为了提供良好的游戏体验，云游戏需要的延迟时间在80ms左右。这意味着视频渲染、编码、传输、解码和显示都需要在这个时间段内完成，这是特别是由服务器过载、网络拥堵和 losses 而具有挑战性。在这篇论文中，我们提出了一种新的视频帧恢复方法，与传统的视频帧恢复方法不同的是，我们的方法使用游戏状态以显著提高恢复精度，并使用部分解码的帧来恢复丢失的部分。我们开发了一个整体系统，包括（i）高效地提取游戏状态，（ii）修改H.264视频解码器生成一个面积指示需要恢复的视频帧部分，以及（iii）设计一种新的神经网络来恢复完整或部分的视频帧。我们的方法在iPhone 12和笔记机实现中进行了广泛的测试，并证明了游戏状态在游戏视频恢复中的重要性和我们的整体设计的有效性。
</details></li>
</ul>
<hr>
<h2 id="Transformers-are-Universal-Predictors"><a href="#Transformers-are-Universal-Predictors" class="headerlink" title="Transformers are Universal Predictors"></a>Transformers are Universal Predictors</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07843">http://arxiv.org/abs/2307.07843</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/danderfer/Comp_Sci_Sem_2">https://github.com/danderfer/Comp_Sci_Sem_2</a></li>
<li>paper_authors: Sourya Basu, Moulik Choraria, Lav R. Varshney</li>
<li>for: 这篇论文是研究Transformer架构的语言模型限制和其在信息论中的通用预测性的。</li>
<li>methods: 论文使用了信息论的方法来分析Transformer架构的性能，并在非对称数据 regime中分析不同组件的作用，特别是在数据效率训练中。</li>
<li>results: 实验表明，Transformer架构在 sintetic 和实际数据上具有良好的性能，且可以在数据效率训练中获得优秀的结果。<details>
<summary>Abstract</summary>
We find limits to the Transformer architecture for language modeling and show it has a universal prediction property in an information-theoretic sense. We further analyze performance in non-asymptotic data regimes to understand the role of various components of the Transformer architecture, especially in the context of data-efficient training. We validate our theoretical analysis with experiments on both synthetic and real datasets.
</details>
<details>
<summary>摘要</summary>
我们发现 transformer 架构在语言模型预测中存在限制，并证明它有一种普遍预测性质在信息理论上。我们进一步分析不同组件的转换器架构在非对称数据 régime 中的表现，尤其是在数据效果训练中。我们 validate our 理论分析通过实验测试 synthetic 和实际数据集。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="RegExplainer-Generating-Explanations-for-Graph-Neural-Networks-in-Regression-Task"><a href="#RegExplainer-Generating-Explanations-for-Graph-Neural-Networks-in-Regression-Task" class="headerlink" title="RegExplainer: Generating Explanations for Graph Neural Networks in Regression Task"></a>RegExplainer: Generating Explanations for Graph Neural Networks in Regression Task</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07840">http://arxiv.org/abs/2307.07840</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiaxing Zhang, Zhuomin Chen, Hao Mei, Dongsheng Luo, Hua Wei</li>
<li>for: 这 paper 的目的是解释图像 regression 模型（XAIG-R）的含义，以便更好地理解图像学习任务中的推理过程。</li>
<li>methods: 这 paper 使用了信息瓶颈理论基于的一个新目标函数，以及一种新的混合框架，可以支持不同的 GNN 模型在一种模型无关的方式上。此外，它还提出了一种对比学习策略来解决 regression 任务中的连续顺序标签问题。</li>
<li>results: 这 paper 通过三个 benchmark 数据集和一个实际数据集进行了广泛的实验，证明了该方法的有效性在解释 GNN 模型在 regression 任务中。<details>
<summary>Abstract</summary>
Graph regression is a fundamental task and has received increasing attention in a wide range of graph learning tasks. However, the inference process is often not interpretable. Most existing explanation techniques are limited to understanding GNN behaviors in classification tasks. In this work, we seek an explanation to interpret the graph regression models (XAIG-R). We show that existing methods overlook the distribution shifting and continuously ordered decision boundary, which hinders them away from being applied in the regression tasks. To address these challenges, we propose a novel objective based on the information bottleneck theory and introduce a new mix-up framework, which could support various GNNs in a model-agnostic manner. We further present a contrastive learning strategy to tackle the continuously ordered labels in regression task. To empirically verify the effectiveness of the proposed method, we introduce three benchmark datasets and a real-life dataset for evaluation. Extensive experiments show the effectiveness of the proposed method in interpreting GNN models in regression tasks.
</details>
<details>
<summary>摘要</summary>
GRaph regression是一个基本任务，在各种图学习任务中受到了越来越多的关注。然而，推断过程经常不可解释。大多数现有的解释技术仅适用于理解 GNN 的类型任务。在这项工作中，我们寻求一种可解释的方法，用于解释图 regression 模型（XAIG-R）。我们发现现有方法忽略了分布Shift和连续顺序决策边界，这会阻碍它们在回归任务中应用。为解决这些挑战，我们提出了一个基于信息瓶颈理论的新目标函数，并提出了一种新的混合框架，可以支持多种 GNN 在一种模型无关的方式上。此外，我们还提出了一种对比学习策略，用于处理连续顺序标签在回归任务中。为证明提出的方法的有效性，我们引入了三个标准数据集和一个真实数据集进行评估。广泛的实验表明，我们的方法可以有效地解释 GNN 模型在回归任务中。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/16/cs.LG_2023_07_16/" data-id="clly4xtdb0057vl887pm9hncr" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_07_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/16/cs.SD_2023_07_16/" class="article-date">
  <time datetime="2023-07-15T16:00:00.000Z" itemprop="datePublished">2023-07-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/16/cs.SD_2023_07_16/">cs.SD - 2023-07-16 123:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="NoiseBandNet-Controllable-Time-Varying-Neural-Synthesis-of-Sound-Effects-Using-Filterbanks"><a href="#NoiseBandNet-Controllable-Time-Varying-Neural-Synthesis-of-Sound-Effects-Using-Filterbanks" class="headerlink" title="NoiseBandNet: Controllable Time-Varying Neural Synthesis of Sound Effects Using Filterbanks"></a>NoiseBandNet: Controllable Time-Varying Neural Synthesis of Sound Effects Using Filterbanks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08007">http://arxiv.org/abs/2307.08007</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/adrianbarahona/noisebandnet">https://github.com/adrianbarahona/noisebandnet</a></li>
<li>paper_authors: Adrián Barahona-Ríos, Tom Collins</li>
<li>for: 本研究旨在提出一种可控制的神经音频合成方法，以便生成具有时间和频率分辨率的各种听起来不同的声音效果。</li>
<li>methods: 该方法使用滤波器链来过滤白噪，从而实现声音效果的生成和控制。</li>
<li>results: 对于十种声音效果的测试，NoiseBandNet得分高于四种变体的DDSP滤波器synthesizer，在九个评价类别中得分更高，表明NoiseBandNet可以生成具有时间和频率分辨率的各种听起来不同的声音效果。<details>
<summary>Abstract</summary>
Controllable neural audio synthesis of sound effects is a challenging task due to the potential scarcity and spectro-temporal variance of the data. Differentiable digital signal processing (DDSP) synthesisers have been successfully employed to model and control musical and harmonic signals using relatively limited data and computational resources. Here we propose NoiseBandNet, an architecture capable of synthesising and controlling sound effects by filtering white noise through a filterbank, thus going further than previous systems that make assumptions about the harmonic nature of sounds. We evaluate our approach via a series of experiments, modelling footsteps, thunderstorm, pottery, knocking, and metal sound effects. Comparing NoiseBandNet audio reconstruction capabilities to four variants of the DDSP-filtered noise synthesiser, NoiseBandNet scores higher in nine out of ten evaluation categories, establishing a flexible DDSP method for generating time-varying, inharmonic sound effects of arbitrary length with both good time and frequency resolution. Finally, we introduce some potential creative uses of NoiseBandNet, by generating variations, performing loudness transfer, and by training it on user-defined control curves.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate into Simplified Chinese� controllable neural audio synthesis of sound effects is a challenging task due to the potential scarcity and spectro-temporal variance of the data. Differentiable digital signal processing (DDSP) synthesisers have been successfully employed to model and control musical and harmonic signals using relatively limited data and computational resources. Here we propose NoiseBandNet, an architecture capable of synthesising and controlling sound effects by filtering white noise through a filterbank, thus going further than previous systems that make assumptions about the harmonic nature of sounds. We evaluate our approach via a series of experiments, modelling footsteps, thunderstorm, pottery, knocking, and metal sound effects. Comparing NoiseBandNet audio reconstruction capabilities to four variants of the DDSP-filtered noise synthesiser, NoiseBandNet scores higher in nine out of ten evaluation categories, establishing a flexible DDSP method for generating time-varying, inharmonic sound effects of arbitrary length with both good time and frequency resolution. Finally, we introduce some potential creative uses of NoiseBandNet, by generating variations, performing loudness transfer, and by training it on user-defined control curves.Translation:控制可能的神经音频合成声效是一个挑战性的任务，因为声效数据的可能性和spectro-temporal variance很大。 diferenciable digital signal processing（DDSP）Synthesisers have been successfully employed to model and control musical and harmonic signals using relatively limited data and computational resources. 我们提议NoiseBandNet，一种可以通过filterbank filtering white noise来实现和控制声效的架构。这超过了之前的系统，它们假设声效的和谐性。我们通过一系列实验，模拟了踏步、雨天、陶艺、打击和金属声效。 Comparing NoiseBandNet的声音重建能力与四种DDSP滤波器处理的噪声合成器，NoiseBandNet在十个评价类别中得分高于其他四个， Establishing a flexible DDSP method for generating time-varying, inharmonic sound effects of arbitrary length with both good time and frequency resolution。最后，我们介绍了一些可能的创造性使用NoiseBandNet，如生成变化、卷积传递和用户定义的控制曲线。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/16/cs.SD_2023_07_16/" data-id="clly4xtec008ivl88e1kg3ewn" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_07_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/16/eess.AS_2023_07_16/" class="article-date">
  <time datetime="2023-07-15T16:00:00.000Z" itemprop="datePublished">2023-07-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/16/eess.AS_2023_07_16/">eess.AS - 2023-07-16 22:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Model-Adaptation-for-ASR-in-low-resource-Indian-Languages"><a href="#Model-Adaptation-for-ASR-in-low-resource-Indian-Languages" class="headerlink" title="Model Adaptation for ASR in low-resource Indian Languages"></a>Model Adaptation for ASR in low-resource Indian Languages</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07948">http://arxiv.org/abs/2307.07948</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhayjeet Singh, Arjun Singh Mehta, Ashish Khuraishi K S, Deekshitha G, Gauri Date, Jai Nanavati, Jesuraja Bandekar, Karnalius Basumatary, Karthika P, Sandhya Badiger, Sathvik Udupa, Saurabh Kumar, Savitha, Prasanta Kumar Ghosh, Prashanthi V, Priyanka Pai, Raoul Nanavati, Rohan Saxena, Sai Praneeth Reddy Mora, Srinivasa Raghavan</li>
<li>for: The paper aims to improve automatic speech recognition (ASR) performance for low-resource languages, specifically Indian languages like Bengali and Bhojpuri.</li>
<li>methods: The paper uses self-supervised learning (SSL) based acoustic models like wav2vec2 and large-scale multi-lingual training like Whisper, and explores the use of adaptation and fine-tuning techniques to overcome the low-resource nature of the data.</li>
<li>results: The paper aims to understand the importance of each modality (acoustics and text) in building a reliable ASR system for low-resource languages, and to explore the applicability of these approaches to various languages spoken around the world.<details>
<summary>Abstract</summary>
Automatic speech recognition (ASR) performance has improved drastically in recent years, mainly enabled by self-supervised learning (SSL) based acoustic models such as wav2vec2 and large-scale multi-lingual training like Whisper. A huge challenge still exists for low-resource languages where the availability of both audio and text is limited. This is further complicated by the presence of multiple dialects like in Indian languages. However, many Indian languages can be grouped into the same families and share the same script and grammatical structure. This is where a lot of adaptation and fine-tuning techniques can be applied to overcome the low-resource nature of the data by utilising well-resourced similar languages.   In such scenarios, it is important to understand the extent to which each modality, like acoustics and text, is important in building a reliable ASR. It could be the case that an abundance of acoustic data in a language reduces the need for large text-only corpora. Or, due to the availability of various pretrained acoustic models, the vice-versa could also be true. In this proposed special session, we encourage the community to explore these ideas with the data in two low-resource Indian languages of Bengali and Bhojpuri. These approaches are not limited to Indian languages, the solutions are potentially applicable to various languages spoken around the world.
</details>
<details>
<summary>摘要</summary>
自动语音识别（ASR）性能在最近几年内有了惊人的提升，主要归功于基于自我超级学习（SSL）的声音模型，如wave2vec2以及大规模多语言训练如Whisper。然而，低资源语言仍然存在巨大的挑战，主要是因为语音和文本数据的可用性受限。这更加复杂，因为印度语言有多种方言。然而，许多印度语言可以分组，并且共享同一个字母和 grammatical structure。这使得可以应用大量的适应和精度调整技术来缓解低资源数据的问题，使用已有的资源更加有利。在这个特别会议中，我们邀请社区探讨以下想法：使用声音和文本Modalities 之间的关系来构建可靠的 ASR。可能是，一个语言有充足的声音数据，可以减少文本 corpora 的需求。或者，由于各种预训练声音模型的可用性，可以相反的情况。我们鼓励社区在孟买利语和帕雷语两种低资源印度语言中进行研究。这些方法不仅适用于印度语言，而且可能适用于世界各地的语言。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/16/eess.AS_2023_07_16/" data-id="clly4xtf400bevl8801xw2jyw" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.IV_2023_07_16" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/16/eess.IV_2023_07_16/" class="article-date">
  <time datetime="2023-07-15T16:00:00.000Z" itemprop="datePublished">2023-07-16</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-IV/">eess.IV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/16/eess.IV_2023_07_16/">eess.IV - 2023-07-16 17:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="TransNuSeg-A-Lightweight-Multi-Task-Transformer-for-Nuclei-Segmentation"><a href="#TransNuSeg-A-Lightweight-Multi-Task-Transformer-for-Nuclei-Segmentation" class="headerlink" title="TransNuSeg: A Lightweight Multi-Task Transformer for Nuclei Segmentation"></a>TransNuSeg: A Lightweight Multi-Task Transformer for Nuclei Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08051">http://arxiv.org/abs/2307.08051</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/zhenqi-he/transnuseg">https://github.com/zhenqi-he/transnuseg</a></li>
<li>paper_authors: Zhenqi He, Mathias Unberath, Jing Ke, Yiqing Shen</li>
<li>for: 这篇论文是为了提出一种基于Transformer的 nuclei segmentation方法，以解决现有的自动 nuclei segmentation方法具有较高的参数数量和训练时间。</li>
<li>methods: 这篇论文使用了一种叫做TransNuSeg的pure Transformer框架，其中包括了一个tri-decoder结构，用于同时进行nuclei实例、nuclei边缘和分布式边缘分割。此外， authors还提出了一种新的自适应loss函数，以确保不同分支的预测结果之间的一致性。</li>
<li>results: 实验表明，TransNuSeg方法可以在两个不同的数据集上，与state-of-the-art counterparts such as CA2.5-Net比较，提高了2-3%的Dice指标，同时减少了30%的参数数量。这表明，Transformer在nuclei segmentation领域中具有强大的能力，可以作为实际临床应用中的有效解决方案。<details>
<summary>Abstract</summary>
Nuclei appear small in size, yet, in real clinical practice, the global spatial information and correlation of the color or brightness contrast between nuclei and background, have been considered a crucial component for accurate nuclei segmentation. However, the field of automatic nuclei segmentation is dominated by Convolutional Neural Networks (CNNs), meanwhile, the potential of the recently prevalent Transformers has not been fully explored, which is powerful in capturing local-global correlations. To this end, we make the first attempt at a pure Transformer framework for nuclei segmentation, called TransNuSeg. Different from prior work, we decouple the challenging nuclei segmentation task into an intrinsic multi-task learning task, where a tri-decoder structure is employed for nuclei instance, nuclei edge, and clustered edge segmentation respectively. To eliminate the divergent predictions from different branches in previous work, a novel self distillation loss is introduced to explicitly impose consistency regulation between branches. Moreover, to formulate the high correlation between branches and also reduce the number of parameters, an efficient attention sharing scheme is proposed by partially sharing the self-attention heads amongst the tri-decoders. Finally, a token MLP bottleneck replaces the over-parameterized Transformer bottleneck for a further reduction in model complexity. Experiments on two datasets of different modalities, including MoNuSeg have shown that our methods can outperform state-of-the-art counterparts such as CA2.5-Net by 2-3% Dice with 30% fewer parameters. In conclusion, TransNuSeg confirms the strength of Transformer in the context of nuclei segmentation, which thus can serve as an efficient solution for real clinical practice. Code is available at https://github.com/zhenqi-he/transnuseg.
</details>
<details>
<summary>摘要</summary>
nuclei 看起来很小，但在实际临床实践中，全球空间信息和背景和核或亮度对比的色彩或亮度对比，被视为精度核 segmentation 的关键组成部分。然而，核心 automatic segmentation 领域被 Convolutional Neural Networks (CNNs) 所主导，而 transformer 的潜力尚未得到充分探索，这是强大地捕捉当地-全球对应关系的。为此，我们提出了首个纯 transformer 框架，称为 TransNuSeg。与先前的工作不同，我们将挑战性的核 segmentation 任务分解成内在多任务学习任务，其中使用 tri-decoder 结构进行核实例、核边和集群边 segmentation 等。为了消除先前工作中分支的不一致预测，我们引入了一种新的自我抽象损失函数，以显式地强制分支之间的一致性规则。此外，我们还提出了一种高效的注意力共享方案，通过在 tri-decoders 中共享自注意力头来降低模型参数数量。最后，我们将 токен MLP 瓶颈取代了过参数化的 transformer 瓶颈，以进一步降低模型复杂性。在两个不同的模式数据上进行了实验，包括 MoNuSeg，我们的方法可以与 state-of-the-art 对手 CA2.5-Net 相比，提高 Dice 指标2-3%，并且减少参数数量30%。结论：TransNuSeg 证明了 transformer 在核 segmentation 上的力量，这些可以作为实际临床实践中的高效解决方案。代码可以在 <https://github.com/zhenqi-he/transnuseg> 上获取。
</details></li>
</ul>
<hr>
<h2 id="A-Novel-SLCA-UNet-Architecture-for-Automatic-MRI-Brain-Tumor-Segmentation"><a href="#A-Novel-SLCA-UNet-Architecture-for-Automatic-MRI-Brain-Tumor-Segmentation" class="headerlink" title="A Novel SLCA-UNet Architecture for Automatic MRI Brain Tumor Segmentation"></a>A Novel SLCA-UNet Architecture for Automatic MRI Brain Tumor Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08048">http://arxiv.org/abs/2307.08048</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tejashwini P S, Thriveni J, Venugopal K R</li>
<li>for: 预测和检测脑肿瘤，以降低因脑肿瘤而导致的死亡率。</li>
<li>methods: 使用深度学习方法，特别是UNet架构，自动化生物医学影像探索工具。</li>
<li>results: 提出了一种修改后的UNet架构，可以有效地捕捉脑肿瘤影像中的粗细特征信息，并在Brain Tumor Segmentation（BraTS）数据集上达到了良好的性能，具体表现为0.845、0.845、0.999和8.1等指标。<details>
<summary>Abstract</summary>
Brain tumor is deliberated as one of the severe health complications which lead to decrease in life expectancy of the individuals and is also considered as a prominent cause of mortality worldwide. Therefore, timely detection and prediction of brain tumors can be helpful to prevent death rates due to brain tumors. Biomedical image analysis is a widely known solution to diagnose brain tumor. Although MRI is the current standard method for imaging tumors, its clinical usefulness is constrained by the requirement of manual segmentation which is time-consuming. Deep learning-based approaches have emerged as a promising solution to develop automated biomedical image exploration tools and the UNet architecture is commonly used for segmentation. However, the traditional UNet has limitations in terms of complexity, training, accuracy, and contextual information processing. As a result, the modified UNet architecture, which incorporates residual dense blocks, layered attention, and channel attention modules, in addition to stacked convolution, can effectively capture both coarse and fine feature information. The proposed SLCA UNet approach achieves good performance on the freely accessible Brain Tumor Segmentation (BraTS) dataset, with an average performance of 0.845, 0.845, 0.999, and 8.1 in terms of Dice, Sensitivity, Specificity, and Hausdorff95 for BraTS 2020 dataset, respectively.
</details>
<details>
<summary>摘要</summary>
脑肿是一种严重的健康问题，可能导致个体寿命下降，并被认为是全球致死率的一大原因。因此，在时间上掌握和预测脑肿的诊断是非常重要的。生物医学图像分析是一种广泛应用的解决方案，但现有的MRI技术受到手动 segmentation 的限制，这是耗时consuming。深度学习基本单元（Deep Learning-based Approaches）已经出现为开发自动生物医学图像探索工具的有力的解决方案之一。然而，传统的 UNet  Architecture 受到复杂性、训练、准确率和上下文信息处理等限制。为此，我们提出了修改后的 UNet 架构，包括循环堆叠、层次注意力和渠道注意力模块，可以有效地捕捉粗细特征信息。我们的 SLCA UNet 方法在公共可用的 Brain Tumor Segmentation（BraTS）数据集上达到了良好的性能，其中 BraTS 2020 数据集的平均性能为 0.845、0.845、0.999 和 8.1 分别在 Dice、敏感性、特异性和 Hausdorff95 方面。
</details></li>
</ul>
<hr>
<h2 id="SHAMSUL-Simultaneous-Heatmap-Analysis-to-investigate-Medical-Significance-Utilizing-Local-interpretability-methods"><a href="#SHAMSUL-Simultaneous-Heatmap-Analysis-to-investigate-Medical-Significance-Utilizing-Local-interpretability-methods" class="headerlink" title="SHAMSUL: Simultaneous Heatmap-Analysis to investigate Medical Significance Utilizing Local interpretability methods"></a>SHAMSUL: Simultaneous Heatmap-Analysis to investigate Medical Significance Utilizing Local interpretability methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08003">http://arxiv.org/abs/2307.08003</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anondo1969/shamsul">https://github.com/anondo1969/shamsul</a></li>
<li>paper_authors: Mahbub Ul Alam, Jaakko Hollmén, Jón Rúnar Baldvinsson, Rahim Rahmani</li>
<li>For: This paper aims to improve the interpretability of deep neural networks in the medical and healthcare domain by applying and comparing four well-established interpretability methods (LIME, SHAP, Grad-CAM, and LRP) to a chest radiography dataset.* Methods: The paper uses transfer learning and a multi-label-multi-class chest radiography dataset to interpret predictions pertaining to specific pathology classes. The authors evaluate the performance of the four interpretability methods through quantitative and qualitative investigations, and compare the results against human expert annotation.* Results: The paper finds that Grad-CAM demonstrates the most favorable performance in quantitative evaluation, while the LIME heatmap segmentation visualization exhibits the highest level of medical significance. The research highlights the strengths and limitations of the four interpretability methods and suggests that a multimodal-based approach could offer additional insights for enhancing interpretability in the medical domain.Here is the same information in Simplified Chinese text:* For: 本研究旨在提高深度神经网络在医疗领域的解释性，通过应用和比较四种已知的解释方法（LIME、SHAP、Grad-CAM、LRP）来解释特定疾病类型的预测结果。* Methods: 本研究使用了传输学习和多类多标签的胸部X射线数据集来解释特定疾病类型的预测结果。作者们通过量化和质量调查来评估四种解释方法的性能，并与人工专家标注进行比较。* Results: 研究发现，Grad-CAM在量化评估中表现最佳，而 LIME 热图分割视觉化显示最高的医学意义。研究揭示了四种解释方法的优缺点，并建议在医疗领域使用多Modal 基于的方法可以提供更多的解释。<details>
<summary>Abstract</summary>
The interpretability of deep neural networks has become a subject of great interest within the medical and healthcare domain. This attention stems from concerns regarding transparency, legal and ethical considerations, and the medical significance of predictions generated by these deep neural networks in clinical decision support systems. To address this matter, our study delves into the application of four well-established interpretability methods: Local Interpretable Model-agnostic Explanations (LIME), Shapley Additive exPlanations (SHAP), Gradient-weighted Class Activation Mapping (Grad-CAM), and Layer-wise Relevance Propagation (LRP). Leveraging the approach of transfer learning with a multi-label-multi-class chest radiography dataset, we aim to interpret predictions pertaining to specific pathology classes. Our analysis encompasses both single-label and multi-label predictions, providing a comprehensive and unbiased assessment through quantitative and qualitative investigations, which are compared against human expert annotation. Notably, Grad-CAM demonstrates the most favorable performance in quantitative evaluation, while the LIME heatmap segmentation visualization exhibits the highest level of medical significance. Our research highlights the strengths and limitations of these interpretability methods and suggests that a multimodal-based approach, incorporating diverse sources of information beyond chest radiography images, could offer additional insights for enhancing interpretability in the medical domain.
</details>
<details>
<summary>摘要</summary>
《深度神经网络可读性的研究在医疗领域引发了广泛的关注，主要是由于透明度、法律和伦理考虑以及在临床决策支持系统中神经网络预测的医学意义。为解决这个问题，我们的研究探讨了四种已有的可读性方法：本地可读性模型自定义解释（LIME）、Shapley添加itive exPlanations（SHAP）、梯度权重分类活动映射（Grad-CAM）和层次 relevance propagation（LRP）。通过将这些方法应用于一个多标签多类胸部X射像数据集，我们想要解释具体疾病类型的预测结果。我们的分析包括单标签和多标签预测，并通过量化和质量调查对比人工专家标注进行了全面和无偏评估。结果显示，Grad-CAM在量化评估中表现最佳，而LIME热图分 segmentation 可读性方法显示最高水平的医学意义。我们的研究描述了这些可读性方法的优缺点，并表明在医疗领域可能需要结合多种信息源以获得更多的解释。》
</details></li>
</ul>
<hr>
<h2 id="MoTIF-Learning-Motion-Trajectories-with-Local-Implicit-Neural-Functions-for-Continuous-Space-Time-Video-Super-Resolution"><a href="#MoTIF-Learning-Motion-Trajectories-with-Local-Implicit-Neural-Functions-for-Continuous-Space-Time-Video-Super-Resolution" class="headerlink" title="MoTIF: Learning Motion Trajectories with Local Implicit Neural Functions for Continuous Space-Time Video Super-Resolution"></a>MoTIF: Learning Motion Trajectories with Local Implicit Neural Functions for Continuous Space-Time Video Super-Resolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07988">http://arxiv.org/abs/2307.07988</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sichun233746/motif">https://github.com/sichun233746/motif</a></li>
<li>paper_authors: Yi-Hsin Chen, Si-Cun Chen, Yi-Hsin Chen, Yen-Yu Lin, Wen-Hsiao Peng</li>
<li>for: 这篇论文的目的是提出一种能够在任意扩大比例下提高视频的空间时间超分辨率（C-STVSR）技术。</li>
<li>methods: 该技术使用了一种空间时间本地隐藏函数，可以学习输入视频帧之间的前进动态信息。该函数有着学习前进动态信息的特点，而不是学习一个混合动态信息的混合函数。为了使得动态信息 interpolate 更加容易，该技术使用了从输入视频中提取的稀疏样本前进动态信息作为上下文输入。</li>
<li>results: 该技术在C-STVSR领域实现了状态机器的性能记录，并提供了一个可用的源代码MoTIF。<details>
<summary>Abstract</summary>
This work addresses continuous space-time video super-resolution (C-STVSR) that aims to up-scale an input video both spatially and temporally by any scaling factors. One key challenge of C-STVSR is to propagate information temporally among the input video frames. To this end, we introduce a space-time local implicit neural function. It has the striking feature of learning forward motion for a continuum of pixels. We motivate the use of forward motion from the perspective of learning individual motion trajectories, as opposed to learning a mixture of motion trajectories with backward motion. To ease motion interpolation, we encode sparsely sampled forward motion extracted from the input video as the contextual input. Along with a reliability-aware splatting and decoding scheme, our framework, termed MoTIF, achieves the state-of-the-art performance on C-STVSR. The source code of MoTIF is available at https://github.com/sichun233746/MoTIF.
</details>
<details>
<summary>摘要</summary>
这个工作Addresses continuous space-time video super-resolution (C-STVSR)，它的目标是通过任何缩放因子将输入视频 both spatially and temporally up-scale。一个关键挑战是在输入视频帧之间传递信息。为此，我们引入了一个空间时本地隐藏神经函数。它有突出的特点是学习输入视频帧中的前进运动。我们从输入视频的动作轨迹学习的角度出发，而不是学习混合动作轨迹中的后向运动。为了简化运动插值，我们将输入视频中稀疏样本的前进运动编码为上下文输入。与一种可靠性感知扩散和解码方案相结合，我们的框架，称之为MoTIF，实现了C-STVSR领域的状态级性能。MoTIF的源代码可以在https://github.com/sichun233746/MoTIF上获取。
</details></li>
</ul>
<hr>
<h2 id="Panoramic-Voltage-Sensitive-Optical-Mapping-of-Contracting-Hearts-using-Cooperative-Multi-View-Motion-Tracking-with-12-to-24-Cameras"><a href="#Panoramic-Voltage-Sensitive-Optical-Mapping-of-Contracting-Hearts-using-Cooperative-Multi-View-Motion-Tracking-with-12-to-24-Cameras" class="headerlink" title="Panoramic Voltage-Sensitive Optical Mapping of Contracting Hearts using Cooperative Multi-View Motion Tracking with 12 to 24 Cameras"></a>Panoramic Voltage-Sensitive Optical Mapping of Contracting Hearts using Cooperative Multi-View Motion Tracking with 12 to 24 Cameras</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07943">http://arxiv.org/abs/2307.07943</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shrey Chowdhary, Jan Lebert, Shai Dickman, Jan Christoph</li>
<li>for: 这研究用于图像心脏的活动电位波，以高空间和时间分辨率观察心脏表面的变形。</li>
<li>methods: 这种多摄像头光学映射技术使用24个高速低成本摄像头，可以在整个扭形的心脏表面上图像活动电位波。</li>
<li>results: 研究发现可以使用12个摄像头获得0.5-1.0兆Pixel的合并分辨率，并使用计算机视觉技术进行三维协同多视图动态重建和高分辨率电子敏感测量。通过这种设置，研究者在兔心中测量到了不同心律rhythm中的活动电位波，包括正常律 rhythm、脉冲心律和心肺综合症。这种设置定义了现有技术的新状态，可以用于研究心脏的电机动力学 dynamics during health和疾病。<details>
<summary>Abstract</summary>
Action potential waves triggering the heart's contractions can be imaged at high spatial and temporal resolutions across the heart surface using voltage-sensitive optical mapping. However, for over three decades, optical mapping has been performed with contraction-inhibited hearts. While it was recently demonstrated that action potential waves can be imaged on parts of the three-dimensional deforming ventricular surface using multi-camera optical mapping, panoramic measurements of action potential waves across the entire beating heart surface remained elusive. Here, we introduce a high-resolution multi-camera optical mapping system consisting of up to 24 high-speed, low-cost cameras with which it is possible to image action potential waves at high resolutions on the entire, strongly deforming ventricular surface of the heart. We imaged isolated hearts inside a custom-designed soccerball-shaped imaging chamber, which facilitates imaging and even illumination with excitation light from all sides in a panoramic fashion. We found that it is possible to image the entire ventricular surface using 12 cameras with 0.5-1.0 megapixels combined resolution. The 12 calibrated cameras generate 1.5 gigabytes of video data per second at imaging speeds of 500 fps, which we process using various computer vision techniques, including three-dimensional cooperative multi-view motion tracking, to generate three-dimensional dynamic reconstructions of the deforming heart surface with corresponding high-resolution voltage-sensitive optical measurements. With our setup, we measured action potential waves at unprecedented resolutions on the contracting three-dimensional surface of rabbit hearts during sinus rhythm, paced rhythm as well as ventricular fibrillation. Our imaging setup defines a new state-of-the-art in the field and can be used to study the heart's electromechanical dynamics during health and disease.
</details>
<details>
<summary>摘要</summary>
心脏的刺激波可以通过电容性光Mapping在心脏表面上获得高空间和时间分辨率的刺激波图像。然而，在过去三十年内，光Mapping都是使用干扰心脏的方法进行的。而现在，我们已经成功地在三维凹陷心脏表面上获得刺激波图像，但这些图像仅限于部分心脏表面。在本文中，我们介绍了一种高分辨率多camera光Mapping系统，该系统由24个高速、低成本摄像头组成，可以在整个弯曲的心脏表面上获得刺激波图像。我们使用自定义的足球形封装室进行心脏封装，以便从所有方向进行扫描和照明。我们发现，使用12个0.5-1.0 megapixels摄像头可以获得整个心脏表面的图像。这12个可 kalibrated摄像头每秒钟生成1.5 gigabytes的视频数据，我们使用了多种计算机视觉技术，包括三维合作多视图运动跟踪，来生成三维动态重建三维凹陷心脏表面的高分辨率电容性光测量。通过我们的设置，我们在各种心脏rhythm中测量了刺激波的历史最高分辨率图像。我们的捕捉设置定义了心脏研究领域的新状态符。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/16/eess.IV_2023_07_16/" data-id="clly4xtfp00dfvl881qxjcikj" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.AI_2023_07_15" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/15/cs.AI_2023_07_15/" class="article-date">
  <time datetime="2023-07-14T16:00:00.000Z" itemprop="datePublished">2023-07-15</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-AI/">cs.AI</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/15/cs.AI_2023_07_15/">cs.AI - 2023-07-15 20:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="MixupExplainer-Generalizing-Explanations-for-Graph-Neural-Networks-with-Data-Augmentation"><a href="#MixupExplainer-Generalizing-Explanations-for-Graph-Neural-Networks-with-Data-Augmentation" class="headerlink" title="MixupExplainer: Generalizing Explanations for Graph Neural Networks with Data Augmentation"></a>MixupExplainer: Generalizing Explanations for Graph Neural Networks with Data Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07832">http://arxiv.org/abs/2307.07832</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jz48/mixupexplainer">https://github.com/jz48/mixupexplainer</a></li>
<li>paper_authors: Jiaxing Zhang, Dongsheng Luo, Hua Wei</li>
<li>for: 本文旨在探讨Graph Neural Networks（GNN）的预测结果是否可解释，并提出一种基于Graph Information Bottleneck（GIB）的mixup方法来解决分布Shift问题。</li>
<li>methods: 本文提出了一种基于GIB的mixup方法，称为MixupExplainer，其具有理论保证，能够解决分布Shift问题。</li>
<li>results: 经过广泛的实验 validate MixupExplainer方法的效果，并提供了分布Shift问题的解决方案。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have received increasing attention due to their ability to learn from graph-structured data. However, their predictions are often not interpretable. Post-hoc instance-level explanation methods have been proposed to understand GNN predictions. These methods seek to discover substructures that explain the prediction behavior of a trained GNN. In this paper, we shed light on the existence of the distribution shifting issue in existing methods, which affects explanation quality, particularly in applications on real-life datasets with tight decision boundaries. To address this issue, we introduce a generalized Graph Information Bottleneck (GIB) form that includes a label-independent graph variable, which is equivalent to the vanilla GIB. Driven by the generalized GIB, we propose a graph mixup method, MixupExplainer, with a theoretical guarantee to resolve the distribution shifting issue. We conduct extensive experiments on both synthetic and real-world datasets to validate the effectiveness of our proposed mixup approach over existing approaches. We also provide a detailed analysis of how our proposed approach alleviates the distribution shifting issue.
</details>
<details>
<summary>摘要</summary>
图 нейрон网络（GNN）因其能够学习图结构数据而受到了越来越多的关注。然而，它们的预测结果通常不可解释。后续的实例级别解释方法已经被提出来了解 GNN 预测结果。这些方法寻找可以解释训练过的 GNN 预测行为的子结构。在这篇文章中，我们指出了现有方法中的分布转移问题，这会影响解释质量，特别是在实际数据集上面临着紧张的决策边界。为解决这个问题，我们引入一种通用的图信息瓶颈（GIB）形式，该形式包括一个独立于标签的图变量，与普通的 GIB 相同。驱动于通用 GIB，我们提出了一种图混合方法，叫做 MixupExplainer，具有解决分布转移问题的理论保证。我们在 synthetic 和实际数据集上进行了广泛的实验，证明了我们的提议的混合方法比现有方法更有效。我们还提供了对我们的提议方法如何缓解分布转移问题的详细分析。
</details></li>
</ul>
<hr>
<h2 id="text-EFO-k-CQA-Towards-Knowledge-Graph-Complex-Query-Answering-beyond-Set-Operation"><a href="#text-EFO-k-CQA-Towards-Knowledge-Graph-Complex-Query-Answering-beyond-Set-Operation" class="headerlink" title="$\text{EFO}_{k}$-CQA: Towards Knowledge Graph Complex Query Answering beyond Set Operation"></a>$\text{EFO}_{k}$-CQA: Towards Knowledge Graph Complex Query Answering beyond Set Operation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13701">http://arxiv.org/abs/2307.13701</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hkust-knowcomp/efok-cqa">https://github.com/hkust-knowcomp/efok-cqa</a></li>
<li>paper_authors: Hang Yin, Zihao Wang, Weizhi Fei, Yangqiu Song</li>
<li>for: 提供了一个框架，用于 Answering Existential First-order Queries with multiple variables（EFO），并评估这些方法在这个框架下的性能。</li>
<li>methods: 使用了学习基本的方法来掌握不完整的知识，以应对开放世界假设下的查询。</li>
<li>results: 建立了一个具有741种查询的数据集（EFO-CQA），并通过实验证明了这些查询的难度对于查询方法的影响。<details>
<summary>Abstract</summary>
To answer complex queries on knowledge graphs, logical reasoning over incomplete knowledge is required due to the open-world assumption. Learning-based methods are essential because they are capable of generalizing over unobserved knowledge. Therefore, an appropriate dataset is fundamental to both obtaining and evaluating such methods under this paradigm. In this paper, we propose a comprehensive framework for data generation, model training, and method evaluation that covers the combinatorial space of Existential First-order Queries with multiple variables ($\text{EFO}_{k}$). The combinatorial query space in our framework significantly extends those defined by set operations in the existing literature. Additionally, we construct a dataset, $\text{EFO}_{k}$-CQA, with 741 types of query for empirical evaluation, and our benchmark results provide new insights into how query hardness affects the results. Furthermore, we demonstrate that the existing dataset construction process is systematically biased that hinders the appropriate development of query-answering methods, highlighting the importance of our work. Our code and data are provided in~\url{https://github.com/HKUST-KnowComp/EFOK-CQA}.
</details>
<details>
<summary>摘要</summary>
“为了回答知识图中的复杂查询，因为开放世界假设，需要逻辑推理 sobre 未完整的知识。学习型方法是必要的，因为它们可以泛化到未观察到的知识。因此，一个合适的数据集是知识检索方法的基础和评估的重要组成部分。在这篇论文中，我们提出了一个完整的框架，包括数据生成、模型训练和方法评估，对多变量Existential First-order Queries（EFO）的 combinatorial 查询空间进行覆盖。我们的框架中的查询空间比现有文献中的set操作定义的更加广泛。此外，我们还构建了741种类型的查询集，并对其进行实验评估。我们的研究结果提供了新的思路，描述了查询难度如何影响结果。此外，我们还发现了现有数据集构建过程存在系统性的偏见，这阻碍了合适的查询回答方法的发展，高亮了我们的工作的重要性。我们的代码和数据可以在https://github.com/HKUST-KnowComp/EFOK-CQA中获取。”Note: The translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you prefer Traditional Chinese, please let me know and I can provide the translation in that form instead.
</details></li>
</ul>
<hr>
<h2 id="Improving-Trace-Link-Recommendation-by-Using-Non-Isotropic-Distances-and-Combinations"><a href="#Improving-Trace-Link-Recommendation-by-Using-Non-Isotropic-Distances-and-Combinations" class="headerlink" title="Improving Trace Link Recommendation by Using Non-Isotropic Distances and Combinations"></a>Improving Trace Link Recommendation by Using Non-Isotropic Distances and Combinations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07781">http://arxiv.org/abs/2307.07781</a></li>
<li>repo_url: None</li>
<li>paper_authors: Christof Tinnes</li>
<li>for: 本研究旨在提高软件开发、维护和运维中 Trace 链的效率，尤其是通过自动计算Trace链来减少人工干预。</li>
<li>methods: 本研究使用了自然语言处理工具来自动计算Trace链，并通过 geometric viewpoint on semantic similarity 来提高 Trace 链的准确率。</li>
<li>results: 研究在四个开源项目和两个企业项目上进行了实验，结果表明， geometric viewpoint on semantic similarity 可以帮助提高 Trace 链的准确率，并且这些发现可以用于其他信息检索问题。<details>
<summary>Abstract</summary>
The existence of trace links between artifacts of the software development life cycle can improve the efficiency of many activities during software development, maintenance and operations. Unfortunately, the creation and maintenance of trace links is time-consuming and error-prone. Research efforts have been spent to automatically compute trace links and lately gained momentum, e.g., due to the availability of powerful tools in the area of natural language processing. In this paper, we report on some observations that we made during studying non-linear similarity measures for computing trace links. We argue, that taking a geometric viewpoint on semantic similarity can be helpful for future traceability research. We evaluated our observations on a dataset of four open source projects and two industrial projects. We furthermore point out that our findings are more general and can build the basis for other information retrieval problems as well.
</details>
<details>
<summary>摘要</summary>
软件开发生命周期中的trace链可以提高软件开发、维护和运维的效率。然而，创建和维护trace链却是时间consuming和容易出错的。研究者们已经投入大量时间和精力来自动计算trace链，最近又得到了新的动力，例如自然语言处理领域的强大工具的出现。本文报告了我们在非线性相似度测量中所作出的观察，我们认为从 geometric 视角来看 semantic 相似度可以对未来的traceability研究提供帮助。我们对四个开源项目和两个industrial项目进行了评估，并指出我们的发现不仅限于traceability问题，还可以应用于其他信息检索问题。
</details></li>
</ul>
<hr>
<h2 id="Explaining-and-visualizing-black-box-models-through-counterfactual-paths"><a href="#Explaining-and-visualizing-black-box-models-through-counterfactual-paths" class="headerlink" title="Explaining and visualizing black-box models through counterfactual paths"></a>Explaining and visualizing black-box models through counterfactual paths</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07764">http://arxiv.org/abs/2307.07764</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pievos101/cpath">https://github.com/pievos101/cpath</a></li>
<li>paper_authors: Bastian Pfeifer, Mateusz Krzyzinski, Hubert Baniecki, Anna Saranti, Andreas Holzinger, Przemyslaw Biecek</li>
<li>for: 该论文旨在提出一种基于 conditional permutation 的 Explainable AI（XAI）方法，使黑盒模型变得透明和可解释。</li>
<li>methods: 该方法使用 conditional permutation 生成的 counterfactual paths，测量特征的重要性通过Sequential permutations of features 的影响对模型预测变化。</li>
<li>results: 实验表明，该方法可以准确地解释和视觉化黑盒模型，并在 synthetic 和医疗数据上得到了实际应用。<details>
<summary>Abstract</summary>
Explainable AI (XAI) is an increasingly important area of machine learning research, which aims to make black-box models transparent and interpretable. In this paper, we propose a novel approach to XAI that uses the so-called counterfactual paths generated by conditional permutations of features. The algorithm measures feature importance by identifying sequential permutations of features that most influence changes in model predictions. It is particularly suitable for generating explanations based on counterfactual paths in knowledge graphs incorporating domain knowledge. Counterfactual paths introduce an additional graph dimension to current XAI methods in both explaining and visualizing black-box models. Experiments with synthetic and medical data demonstrate the practical applicability of our approach.
</details>
<details>
<summary>摘要</summary>
<<SYS>>用于机器学习研究的可解释AI（XAI）是一个日益重要的领域，旨在让黑盒模型变得透明和可解释。在这篇论文中，我们提出了一种新的XAI方法，使用叫做条件 permutation的feature counterfactual paths来衡量特征重要性。这个算法可以基于知识图 incorporating domain knowledge中的counterfactual paths来生成解释。counterfactual paths增加了现有XAI方法的一个新的维度，可以对黑盒模型的解释和可视化进行更好的支持。实验结果显示了我们的方法在synthetic和医疗数据上的实际可行性。Translation notes:* "可解释AI" (XAI) is translated as "可解释AI" (XAI), which is the standard term used in Simplified Chinese.* "黑盒模型" (black-box model) is translated as "黑盒模型" (black-box model), which is the standard term used in Simplified Chinese.* "counterfactual paths" is translated as "counterfactual paths" (counterfactual paths), which is the standard term used in Simplified Chinese.* "knowledge graph" is translated as "知识图" (knowledge graph), which is the standard term used in Simplified Chinese.* "domain knowledge" is translated as "领域知识" (domain knowledge), which is the standard term used in Simplified Chinese.I hope this helps! Let me know if you have any further questions.
</details></li>
</ul>
<hr>
<h2 id="Bidirectionally-Deformable-Motion-Modulation-For-Video-based-Human-Pose-Transfer"><a href="#Bidirectionally-Deformable-Motion-Modulation-For-Video-based-Human-Pose-Transfer" class="headerlink" title="Bidirectionally Deformable Motion Modulation For Video-based Human Pose Transfer"></a>Bidirectionally Deformable Motion Modulation For Video-based Human Pose Transfer</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07754">http://arxiv.org/abs/2307.07754</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/rocketappslab/bdmm">https://github.com/rocketappslab/bdmm</a></li>
<li>paper_authors: Wing-Yin Yu, Lai-Man Po, Ray C. C. Cheung, Yuzhi Zhao, Yu Xue, Kun Li</li>
<li>For: 动作人体图像做pose转换，即将原始图像动作转换为目标人体pose中的动作。* Methods: 提出了一种新的弹性动作修饰（DMM）方法，通过几何核OFFSET和自适应重量调整来同时实现特征对Alignment和样式传递。* Results: 与现有方法相比，提出的方法可以更好地处理衣物上的复杂结构和不连续的姿势，并且可以更好地保持图像的稳定性和视觉连续性。<details>
<summary>Abstract</summary>
Video-based human pose transfer is a video-to-video generation task that animates a plain source human image based on a series of target human poses. Considering the difficulties in transferring highly structural patterns on the garments and discontinuous poses, existing methods often generate unsatisfactory results such as distorted textures and flickering artifacts. To address these issues, we propose a novel Deformable Motion Modulation (DMM) that utilizes geometric kernel offset with adaptive weight modulation to simultaneously perform feature alignment and style transfer. Different from normal style modulation used in style transfer, the proposed modulation mechanism adaptively reconstructs smoothed frames from style codes according to the object shape through an irregular receptive field of view. To enhance the spatio-temporal consistency, we leverage bidirectional propagation to extract the hidden motion information from a warped image sequence generated by noisy poses. The proposed feature propagation significantly enhances the motion prediction ability by forward and backward propagation. Both quantitative and qualitative experimental results demonstrate superiority over the state-of-the-arts in terms of image fidelity and visual continuity. The source code is publicly available at github.com/rocketappslab/bdmm.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate text into Simplified ChineseVideo-based human pose transfer是一种视频到视频生成任务，把平板的源人像图像基于一系列目标人 pose 动作。由于衣物上的结构很复杂，以及各种异常的姿势，现有方法通常会生成不满意的结果，如扭曲的 тексту涂抹和闪烁 artifacts。为解决这些问题，我们提出了一种新的减少动作模ulation（DMM）技术，利用几何kernel偏移以及适应加权修正来同时进行特征对齐和样式传递。与普通的样式修饰用于样式传递不同，我们的修饰机制可以根据对象形状自适应重建缓和frames从样式代码中。为了提高空间-时间一致性，我们利用双向传播来提取隐藏的运动信息从扭曲的图像序列，并且通过前向和后向传播来增强运动预测能力。实验结果表明，我们的特征传播方法可以明显提高图像准确性和视觉连续性，而且在量化和质量两个方面都超过了现有技术。源代码可以在github.com/rocketappslab/bdmm 中获取。Note: The translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Learning-Expressive-Priors-for-Generalization-and-Uncertainty-Estimation-in-Neural-Networks"><a href="#Learning-Expressive-Priors-for-Generalization-and-Uncertainty-Estimation-in-Neural-Networks" class="headerlink" title="Learning Expressive Priors for Generalization and Uncertainty Estimation in Neural Networks"></a>Learning Expressive Priors for Generalization and Uncertainty Estimation in Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07753">http://arxiv.org/abs/2307.07753</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dlr-rm/bpnn">https://github.com/dlr-rm/bpnn</a></li>
<li>paper_authors: Dominik Schnaus, Jongseok Lee, Daniel Cremers, Rudolph Triebel</li>
<li>for: 提高深度神经网络的通用化和不确定性估计</li>
<li>methods: 利用可扩展的结构 posteriors 作为帮助神经网络通用化和不确定性估计的快速学习方法，并提供可靠的泛化证明</li>
<li>results: 实验表明，该方法可以有效地提高神经网络的不确定性估计和通用化性，并且在不断学习框架中实现了良好的性能<details>
<summary>Abstract</summary>
In this work, we propose a novel prior learning method for advancing generalization and uncertainty estimation in deep neural networks. The key idea is to exploit scalable and structured posteriors of neural networks as informative priors with generalization guarantees. Our learned priors provide expressive probabilistic representations at large scale, like Bayesian counterparts of pre-trained models on ImageNet, and further produce non-vacuous generalization bounds. We also extend this idea to a continual learning framework, where the favorable properties of our priors are desirable. Major enablers are our technical contributions: (1) the sums-of-Kronecker-product computations, and (2) the derivations and optimizations of tractable objectives that lead to improved generalization bounds. Empirically, we exhaustively show the effectiveness of this method for uncertainty estimation and generalization.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了一种新的先学习方法，用于提高深度神经网络的通用化和不确定性估计。关键思想是利用可扩展和结构化的神经网络 posterior 作为有效的先学习模型，具有通用化保证。我们学习的先学习模型可以在大规模上提供表达性的概率表示，类似于 bayesian 对 ImageNet 预训练模型的counterpart，并且生成非虚无效的通用化误差 bound。我们还将这个想法扩展到 continual learning 框架中，其中我们的先学习模型具有恰当的特性。主要实现方法包括：(1)  kronecker 乘积计算，以及对这些计算的Derivation和优化，以实现改进的通用化误差 bound。我们在实验中证明了这种方法的有效性，用于 uncertainty estimation 和通用化。
</details></li>
</ul>
<hr>
<h2 id="Combining-model-predictive-control-and-predictive-reinforcement-learning-for-stable-quadrupedal-robot-locomotion"><a href="#Combining-model-predictive-control-and-predictive-reinforcement-learning-for-stable-quadrupedal-robot-locomotion" class="headerlink" title="Combining model-predictive control and predictive reinforcement learning for stable quadrupedal robot locomotion"></a>Combining model-predictive control and predictive reinforcement learning for stable quadrupedal robot locomotion</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07752">http://arxiv.org/abs/2307.07752</a></li>
<li>repo_url: None</li>
<li>paper_authors: Vyacheslav Kovalev, Anna Shkromada, Henni Ouerdane, Pavel Osinenko</li>
<li>For: 这篇论文旨在研究如何通过模型预测和预测学习控制器来获得四肢机器人稳定的步行。* Methods: 本文使用了模型预测控制（MPC）和预测学习（RL）两种控制方法来解决四肢机器人稳定步行问题。MPC是一种已知的控制方法，但是它不使用线上学习，只有一些适应型的变化。RL则是一种基于体验的学习方法，但是在高复杂的机器人中可能不太适用。本文的混合方法结合了MPC和RL，使用了成本滚动算法和一个对应的Q函数预测器，以缓解MPC的计算复杂性。* Results: 本文的实验结果显示，使用了混合控制的四肢机器人可以在短时间内获得稳定的步行，而nominal MP控制器则在较长时间内失败。此外，本文的控制器不需要前期训练，可以进行现场操作。结果显示，混合MPC和RL的控制方法可以实现四肢机器人稳定步行的平衡。<details>
<summary>Abstract</summary>
Stable gait generation is a crucial problem for legged robot locomotion as this impacts other critical performance factors such as, e.g. mobility over an uneven terrain and power consumption. Gait generation stability results from the efficient control of the interaction between the legged robot's body and the environment where it moves. Here, we study how this can be achieved by a combination of model-predictive and predictive reinforcement learning controllers. Model-predictive control (MPC) is a well-established method that does not utilize any online learning (except for some adaptive variations) as it provides a convenient interface for state constraints management. Reinforcement learning (RL), in contrast, relies on adaptation based on pure experience. In its bare-bone variants, RL is not always suitable for robots due to their high complexity and expensive simulation/experimentation. In this work, we combine both control methods to address the quadrupedal robot stable gate generation problem. The hybrid approach that we develop and apply uses a cost roll-out algorithm with a tail cost in the form of a Q-function modeled by a neural network; this allows to alleviate the computational complexity, which grows exponentially with the prediction horizon in a purely MPC approach. We demonstrate that our RL gait controller achieves stable locomotion at short horizons, where a nominal MP controller fails. Further, our controller is capable of live operation, meaning that it does not require previous training. Our results suggest that the hybridization of MPC with RL, as presented here, is beneficial to achieve a good balance between online control capabilities and computational complexity.
</details>
<details>
<summary>摘要</summary>
稳定步态生成是四肢机器人行走中的关键问题，这会影响其他重要性能因素，如覆盖不平地形和功率消耗。稳定步态生成的稳定性来自四肢机器人身体和运动环境之间的有效控制。在这里，我们研究如何通过组合模型预测和预测学习控制器来实现稳定步态生成。模型预测控制（MPC）是一种已知的方法，不使用线上学习（除了一些适应变化），它提供了一个方便的状态约束管理界面。学习控制（RL），相比之下，基于经验学习，不适用于机器人，因为它们的复杂性和临界实验/仿真成本高。在这个工作中，我们将这两种控制方法结合使用，以解决四肢机器人稳定步态生成问题。我们开发的混合方法使用一个成本滚动算法，其中的尾成本是一个模拟网络模型的Q函数；这使得计算复杂性减少，在完全MPC方法中计算复杂性呈指数增长的情况下。我们的RL步态控制器可以在短预测时间内实现稳定行走，而一个准确MP控制器则无法实现。此外，我们的控制器可以进行实时操作，不需要先期训练。我们的结果表明，在MPC和RL之间的混合，如我们所提出的，可以实现一个良好的平衡，以提高在线控制能力和计算复杂性。
</details></li>
</ul>
<hr>
<h2 id="SINC-Self-Supervised-In-Context-Learning-for-Vision-Language-Tasks"><a href="#SINC-Self-Supervised-In-Context-Learning-for-Vision-Language-Tasks" class="headerlink" title="SINC: Self-Supervised In-Context Learning for Vision-Language Tasks"></a>SINC: Self-Supervised In-Context Learning for Vision-Language Tasks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07742">http://arxiv.org/abs/2307.07742</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yi-Syuan Chen, Yun-Zhu Song, Cheng Yu Yeo, Bei Liu, Jianlong Fu, Hong-Han Shuai<br>for: 这个论文的目的是探讨如何实现无 gradient 学习的情况下，大型 transformer 模型在视觉语言领域中进行增Context 学习。methods: 这个论文使用的方法是引入视觉信息到大型语言模型中，以便在输入上进行增Context 预测。results: 实验结果表明，SINC 方法在多种视觉语言任务下，在几个shot Setting 下表现出色，而且可以在实时进行增Context 预测。此外，SINC 方法的设计也帮助我们了解视觉语言领域中增Context 学习的好处，以及这种学习方式在不同任务中的发展。<details>
<summary>Abstract</summary>
Large Pre-trained Transformers exhibit an intriguing capacity for in-context learning. Without gradient updates, these models can rapidly construct new predictors from demonstrations presented in the inputs. Recent works promote this ability in the vision-language domain by incorporating visual information into large language models that can already make in-context predictions. However, these methods could inherit issues in the language domain, such as template sensitivity and hallucination. Also, the scale of these language models raises a significant demand for computations, making learning and operating these models resource-intensive. To this end, we raise a question: ``How can we enable in-context learning without relying on the intrinsic in-context ability of large language models?". To answer it, we propose a succinct and general framework, Self-supervised IN-Context learning (SINC), that introduces a meta-model to learn on self-supervised prompts consisting of tailored demonstrations. The learned models can be transferred to downstream tasks for making in-context predictions on-the-fly. Extensive experiments show that SINC outperforms gradient-based methods in various vision-language tasks under few-shot settings. Furthermore, the designs of SINC help us investigate the benefits of in-context learning across different tasks, and the analysis further reveals the essential components for the emergence of in-context learning in the vision-language domain.
</details>
<details>
<summary>摘要</summary>
大型预训Transformer显示了有趣的 Context Learning能力。无需梯度更新，这些模型可快速从输入中提取示例构建新预测器。最近的工作在视觉语言领域把视觉信息 integrate到可以在输入中进行预测的大语言模型中，以提高Context Learning能力。然而，这些方法可能会继承语言领域的问题，如模板敏感和幻觉。此外，这些语言模型的大规模需要巨量的计算资源，使学习和运行这些模型成为资源占用。因此，我们提出了问题：“如何启用Context Learning无需大语言模型的内在能力？”为回答这个问题，我们提出了一种简洁且通用的框架，Self-supervised IN-Context learning（SINC）。SINC引入了一个元模型，用于在自我超visuelle示例上学习。学习后，这些模型可以被转移到下游任务中进行实时预测。广泛的实验显示，SINC在视觉语言任务下的几个shot设定下表现出色，超过了梯度更新方法。此外，SINC的设计帮助我们调查在不同任务中Context Learning的好处，并且分析还揭示了视觉语言领域Context Learning的发展的关键组成部分。
</details></li>
</ul>
<hr>
<h2 id="Intuitive-Access-to-Smartphone-Settings-Using-Relevance-Model-Trained-by-Contrastive-Learning"><a href="#Intuitive-Access-to-Smartphone-Settings-Using-Relevance-Model-Trained-by-Contrastive-Learning" class="headerlink" title="Intuitive Access to Smartphone Settings Using Relevance Model Trained by Contrastive Learning"></a>Intuitive Access to Smartphone Settings Using Relevance Model Trained by Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.09177">http://arxiv.org/abs/2307.09177</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joonyoung Kim, Kangwook Lee, Haebin Shin, Hurnjoo Lee, Sechun Kang, Byunguk Choi, Dong Shin, Joohyung Lee<br>for: 该论文 targets 智能手机中的功能搜索问题，即用户难以找到功能的问题。methods: 该论文提出了一种新的搜索系统，使用了对比学习来训练一个拥有Contextual relevance的相关性模型，以及应用了知识填充来压缩模型，使其在设备上运行高效。results: 测试结果显示，该系统在 contextual sentence 查询和 usual keyword-based 查询中表现出色，超过了现有的搜索基准。<details>
<summary>Abstract</summary>
The more new features that are being added to smartphones, the harder it becomes for users to find them. This is because the feature names are usually short, and there are just too many to remember. In such a case, the users may want to ask contextual queries that describe the features they are looking for, but the standard term frequency-based search cannot process them. This paper presents a novel retrieval system for mobile features that accepts intuitive and contextual search queries. We trained a relevance model via contrastive learning from a pre-trained language model to perceive the contextual relevance between query embeddings and indexed mobile features. Also, to make it run efficiently on-device using minimal resources, we applied knowledge distillation to compress the model without degrading much performance. To verify the feasibility of our method, we collected test queries and conducted comparative experiments with the currently deployed search baselines. The results show that our system outperforms the others on contextual sentence queries and even on usual keyword-based queries.
</details>
<details>
<summary>摘要</summary>
随着智能手机中新增功能的数量的增加，用户找到这些功能越来越Difficult.这是因为功能名称通常很短，而且有太多了，用户可能会想要提问 Contextual queries 描述所需的功能，但标准的 terme frequency-based search 系统无法处理这些查询。本文介绍了一种新的手机功能检索系统，该系统可以接受用户提出的Intuitive和Contextual search queries。我们通过对预先训练的语言模型进行对比学习来训练一个 relevance 模型，以便在查询embeddings中感知Contextual relevance。此外，为了在设备上运行效率高并使用 minimal resources，我们应用了知识填充技术来压缩模型。为了证明我们的方法的可行性，我们收集了测试查询并进行了相对 эксперименты。结果表明，我们的系统在Contextual sentence queries 和一般键 palab 查询中都高于其他基elines。
</details></li>
</ul>
<hr>
<h2 id="Safe-Formulas-in-the-General-Theory-of-Stable-Models"><a href="#Safe-Formulas-in-the-General-Theory-of-Stable-Models" class="headerlink" title="Safe Formulas in the General Theory of Stable Models"></a>Safe Formulas in the General Theory of Stable Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.09166">http://arxiv.org/abs/2307.09166</a></li>
<li>repo_url: None</li>
<li>paper_authors: Joohyung Lee, Vladimir Lifschitz, Ravi Palla</li>
<li>for: 本研究探讨了安全首项公式的概念，它们可以视为答案集解释器的设计中的一个重要组成部分。</li>
<li>methods: 本研究使用了安全句子的概念，并证明任何安全句子都等价于其归grounding的结果 – 即将所有量词替换为多重 conjunctions 和 disjunctions 后得到的变量自由句子。</li>
<li>results: 根据本研究结果，安全句子和其归grounding结果具有相同的稳定模型，而稳定模型的描述可以用一种简单的语法形式来表示。<details>
<summary>Abstract</summary>
Safe first-order formulas generalize the concept of a safe rule, which plays an important role in the design of answer set solvers. We show that any safe sentence is equivalent, in a certain sense, to the result of its grounding -- to the variable-free sentence obtained from it by replacing all quantifiers with multiple conjunctions and disjunctions. It follows that a safe sentence and the result of its grounding have the same stable models, and that the stable models of a safe sentence can be characterized by a formula of a simple syntactic form.
</details>
<details>
<summary>摘要</summary>
安全的首项式式表示安全规则的概念，这种概念在答案集解决器的设计中发挥着重要作用。我们证明任何安全句子都等价于其归根结构 -- 将它中的全量化器替换为多个并 conjunctions 和 disjunctions 后得到的变量自由句子。因此，安全句子和它的归根结构具有相同的稳定模型，并且安全句子的稳定模型可以通过一个简单的语法结构来描述。
</details></li>
</ul>
<hr>
<h2 id="Measuring-Perceived-Trust-in-XAI-Assisted-Decision-Making-by-Eliciting-a-Mental-Model"><a href="#Measuring-Perceived-Trust-in-XAI-Assisted-Decision-Making-by-Eliciting-a-Mental-Model" class="headerlink" title="Measuring Perceived Trust in XAI-Assisted Decision-Making by Eliciting a Mental Model"></a>Measuring Perceived Trust in XAI-Assisted Decision-Making by Eliciting a Mental Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.11765">http://arxiv.org/abs/2307.11765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohsen Abbaspour Onari, Isel Grau, Marco S. Nobile, Yingqian Zhang</li>
<li>for: 本研究用了一种新的方法来测量用户对可解释人工智能（XAI）模型的信任感。</li>
<li>methods: 这种方法利用了可解释机器学习（ML）模型来分类可能患有 COVID-19 的病人为正或负。然后，医疗专家（ME）根据他们的知识和 XAI 模型的预测和解释进行诊断决策任务。</li>
<li>results: 研究发现，对于每个 ME，可以获得一个量化的信任值，以确定他们对 XAI 模型的信任程度。这些量化值可以判断 ME 是否对 XAI 模型有信任或不信任。此外，研究还发现，MEs 的心理主观性会影响他们对 XAI 模型的信任程度。<details>
<summary>Abstract</summary>
This empirical study proposes a novel methodology to measure users' perceived trust in an Explainable Artificial Intelligence (XAI) model. To do so, users' mental models are elicited using Fuzzy Cognitive Maps (FCMs). First, we exploit an interpretable Machine Learning (ML) model to classify suspected COVID-19 patients into positive or negative cases. Then, Medical Experts' (MEs) conduct a diagnostic decision-making task based on their knowledge and then prediction and interpretations provided by the XAI model. In order to evaluate the impact of interpretations on perceived trust, explanation satisfaction attributes are rated by MEs through a survey. Then, they are considered as FCM's concepts to determine their influences on each other and, ultimately, on the perceived trust. Moreover, to consider MEs' mental subjectivity, fuzzy linguistic variables are used to determine the strength of influences. After reaching the steady state of FCMs, a quantified value is obtained to measure the perceived trust of each ME. The results show that the quantified values can determine whether MEs trust or distrust the XAI model. We analyze this behavior by comparing the quantified values with MEs' performance in completing diagnostic tasks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Elementary-Sets-for-Logic-Programs"><a href="#Elementary-Sets-for-Logic-Programs" class="headerlink" title="Elementary Sets for Logic Programs"></a>Elementary Sets for Logic Programs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.09168">http://arxiv.org/abs/2307.09168</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Martin Gebser, Joohyung Lee, Yuliya Lierler</li>
<li>for: 本文研究了非逻辑程序的答案集和 Clark 完善的模型之间的关系。</li>
<li>methods: 本文使用了林和赵的定理，以及 Gebser 和 Schaub 的 restrict loop 方法。</li>
<li>results: 本文提出了一种更加简单和普适的 elementary set 概念，并证明了其与非逻辑程序相关的最大不充足 elementary set 是非逻辑程序的所有非空不充足集之最小集。此外，本文还提供了一种图理学方法来Characterize elementary sets for nondisjunctive programs。在 contrast to nondisjunctive programs, 本文显示了对于分配程序，确定 elementary set 是 coNP-complete。<details>
<summary>Abstract</summary>
By introducing the concepts of a loop and a loop formula, Lin and Zhao showed that the answer sets of a nondisjunctive logic program are exactly the models of its Clark's completion that satisfy the loop formulas of all loops. Recently, Gebser and Schaub showed that the Lin-Zhao theorem remains correct even if we restrict loop formulas to a special class of loops called ``elementary loops.'' In this paper, we simplify and generalize the notion of an elementary loop, and clarify its role. We propose the notion of an elementary set, which is almost equivalent to the notion of an elementary loop for nondisjunctive programs, but is simpler, and, unlike elementary loops, can be extended to disjunctive programs without producing unintuitive results. We show that the maximal unfounded elementary sets for the ``relevant'' part of a program are exactly the minimal sets among the nonempty unfounded sets. We also present a graph-theoretic characterization of elementary sets for nondisjunctive programs, which is simpler than the one proposed in (Gebser & Schaub 2005). Unlike the case of nondisjunctive programs, we show that the problem of deciding an elementary set is coNP-complete for disjunctive programs.
</details>
<details>
<summary>摘要</summary>
林和赵通过引入循环和循环公式，表明答案集合的非逻辑程序是完全 Clark 完成的模型，满足所有循环公式的循环。最近，格卜和瑞布 показа了林-赵定理仍然正确，只要限制循环公式为特殊类循环 called “元素循环”。在这篇文章中，我们简化和推广元素循环的概念，并解释其作用。我们提出了元素集的概念，它与元素循环对非逻辑程序几乎等价，但更简单，而且与元素循环不同的是可以扩展到分支程序无需生成不自然的结果。我们证明了最大不定元素集的“相关”部分的程序是非空不定集中的最小集。我们还提出了非逻辑程序的元素集的图学特征化，这比 Gebser 和 Schaub （2005）提出的特征化更简单。不同于非逻辑程序，我们证明了决定元素集的问题是 coNP-完全的 для分支程序。
</details></li>
</ul>
<hr>
<h2 id="Abstracting-Concept-Changing-Rules-for-Solving-Raven’s-Progressive-Matrix-Problems"><a href="#Abstracting-Concept-Changing-Rules-for-Solving-Raven’s-Progressive-Matrix-Problems" class="headerlink" title="Abstracting Concept-Changing Rules for Solving Raven’s Progressive Matrix Problems"></a>Abstracting Concept-Changing Rules for Solving Raven’s Progressive Matrix Problems</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07734">http://arxiv.org/abs/2307.07734</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/fudanvi/generative-abstract-reasoning">https://github.com/fudanvi/generative-abstract-reasoning</a></li>
<li>paper_authors: Fan Shi, Bin Li, Xiangyang Xue</li>
<li>for: 这种研究旨在提高机器智能的抽象能力，以便在新环境中发现底层规则。</li>
<li>methods: 这种方法使用了Raven’s Progressive Matrix（RPM）测试，并使用深度隐藏变量模型来抽象概念改变规则。</li>
<li>results: 这种方法可以自动抽象全局规则，并且在无外部监督下达到了同级或更高的准确率。<details>
<summary>Abstract</summary>
The abstract visual reasoning ability in human intelligence benefits discovering underlying rules in the novel environment. Raven's Progressive Matrix (RPM) is a classic test to realize such ability in machine intelligence by selecting from candidates. Recent studies suggest that solving RPM in an answer-generation way boosts a more in-depth understanding of rules. However, existing generative solvers cannot discover the global concept-changing rules without auxiliary supervision (e.g., rule annotations and distractors in candidate sets). To this end, we propose a deep latent variable model for Concept-changing Rule ABstraction (CRAB) by learning interpretable concepts and parsing concept-changing rules in the latent space. With the iterative learning process, CRAB can automatically abstract global rules shared on the dataset on each concept and form the learnable prior knowledge of global rules. CRAB outperforms the baselines trained without auxiliary supervision in the arbitrary-position answer generation task and achieves comparable and even higher accuracy than the compared models trained with auxiliary supervision. Finally, we conduct experiments to illustrate the interpretability of CRAB in concept learning, answer selection, and global rule abstraction.
</details>
<details>
<summary>摘要</summary>
人类智能中的抽象视觉理解能力可以帮助发现新环境中的底层规则。Raven's Progressive Matrix (RPM) 是一种经典的测试，用于评测机器智能中的这种能力。Recent studies 表明，通过answer-generation的方式解决RPM可以提高对规则的更深入的理解。然而，现有的生成解决方案无法自动发现全局概念变化的规则，需要 auxiliary supervision（例如，规则注释和distractors在候选集中）。为此，我们提出了一种深入学习的秘密变量模型，即Concept-changing Rule ABstraction (CRAB)，可以学习可读的概念和解析概念变化规则在隐藏空间中。通过迭代学习过程，CRAB可以自动抽象数据集中的全局规则，并将这些规则形成可学习的先验知识。CRAB在无auxiliary supervision的arbitrary-position answer generation任务中表现出色，并与包括auxiliary supervision的比较模型相比，达到了相同或更高的准确率。最后，我们进行了实验，以示CRAB在概念学习、答案选择和全局规则抽象方面的解释性。
</details></li>
</ul>
<hr>
<h2 id="Causal-Laws-and-Multi-Valued-Fluents"><a href="#Causal-Laws-and-Multi-Valued-Fluents" class="headerlink" title="Causal Laws and Multi-Valued Fluents"></a>Causal Laws and Multi-Valued Fluents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.10227">http://arxiv.org/abs/2307.10227</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Aryia-Behroziuan/References">https://github.com/Aryia-Behroziuan/References</a></li>
<li>paper_authors: Enrico Giunchiglia, Joohyung Lee, Vladimir Lifschitz, Hudson Turner</li>
<li>for: 本研究继续 investigate 非 monotonic  formalism 表示行为属性的工作，特别是 отлича между “真” 和 “被引起”，如 McCain 和 Turner 提出的 causal logic 和 Giunchiglia 和 Lifschitz 提出的 action language C。</li>
<li>methods: 本文使用 extension 方法，使得 language C+ 可以表示非空集值。此外，本文还描述了 actions 的 attribute 的描述，这对 elaboration tolerance 非常重要。</li>
<li>results: 本文显示了 causal theories 中 multi-valued constants 的 eliminating，并将 C+ 与 Pednault 提出的 action language ADL 进行比较。<details>
<summary>Abstract</summary>
This paper continues the line of work on representing properties of actions in nonmonotonic formalisms that stresses the distinction between being "true" and being "caused", as in the system of causal logic introduced by McCain and Turner and in the action language C proposed by Giunchiglia and Lifschitz. The only fluents directly representable in language C+ are truth-valued fluents, which is often inconvenient. We show that both causal logic and language C can be extended to allow values from arbitrary nonempty sets. Our extension of language C, called C+, also makes it possible to describe actions in terms of their attributes, which is important from the perspective of elaboration tolerance. We describe an embedding of C+ in causal theories with multi-valued constants, relate C+ to Pednault's action language ADL, and show how multi-valued constants can be eliminated in favor of Boolean constants.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="On-Loop-Formulas-with-Variables"><a href="#On-Loop-Formulas-with-Variables" class="headerlink" title="On Loop Formulas with Variables"></a>On Loop Formulas with Variables</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.10226">http://arxiv.org/abs/2307.10226</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/SOYJUN/FTP-implement-based-on-UDP">https://github.com/SOYJUN/FTP-implement-based-on-UDP</a></li>
<li>paper_authors: Joohyung Lee, Yunsong Meng</li>
<li>for: 这个论文是为了推广 Ferraris et al. 的稳定模型定义，不再基于固定点，可应用于任意首选论 sentences 的 syntax。</li>
<li>methods: 这篇论文使用 Chen, Lin, Wang, Zhang 的 loop formulas with variables，并将其推广到分支计划和任意首选论 sentences。它还扩展了逻辑计划的语法，允许显式Quantifier，并定义其 semantics 为 Ferraris et al. 的稳定模型语言的一个 subclass。</li>
<li>results: 这篇论文显示了这种扩展的逻辑计划可以在稳定模型 semantics 下进行非 monotonic reasoning，而且在不假设唯一名称和Domain closure 的情况下仍然能够处理非 Herbrand 稳定模型。此外，它还显示了一些语法条件，使得查询答案可以通过 first-order 逻辑推理来实现，从而可以使用 first-order 证明器进行非 Herbrand 稳定模型的推理。<details>
<summary>Abstract</summary>
Recently Ferraris, Lee and Lifschitz proposed a new definition of stable models that does not refer to grounding, which applies to the syntax of arbitrary first-order sentences. We show its relation to the idea of loop formulas with variables by Chen, Lin, Wang and Zhang, and generalize their loop formulas to disjunctive programs and to arbitrary first-order sentences. We also extend the syntax of logic programs to allow explicit quantifiers, and define its semantics as a subclass of the new language of stable models by Ferraris et al. Such programs inherit from the general language the ability to handle nonmonotonic reasoning under the stable model semantics even in the absence of the unique name and the domain closure assumptions, while yielding more succinct loop formulas than the general language due to the restricted syntax. We also show certain syntactic conditions under which query answering for an extended program can be reduced to entailment checking in first-order logic, providing a way to apply first-order theorem provers to reasoning about non-Herbrand stable models.
</details>
<details>
<summary>摘要</summary>
最近，菲律数、李和里夫斯提出了一个新的定义方式，不受地面影响，可以应用于任意首项关系文法中的语法。我们展示了这个定义与陈等人的循环式关系式的联系，并将其扩展到分类程式和任意首项关系文法中。我们还将逻辑程式的 syntax 扩展为允许显式量词，并定义其 semantics 为一个基于新的稳定模型语言的子集。这些程式继承了稳定模型语言中的非对称逻辑推理能力，但是具有更短的循环式关系式，因为其 restrictive syntax。我们还展示了一些语法条件，使得问题回答可以与首项关系逻辑推理相同，并且可以运用首项关系逻辑推理器进行非HERBRAND稳定模型的推理。
</details></li>
</ul>
<hr>
<h2 id="First-Order-Stable-Model-Semantics-with-Intensional-Functions"><a href="#First-Order-Stable-Model-Semantics-with-Intensional-Functions" class="headerlink" title="First-Order Stable Model Semantics with Intensional Functions"></a>First-Order Stable Model Semantics with Intensional Functions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.10225">http://arxiv.org/abs/2307.10225</a></li>
<li>repo_url: None</li>
<li>paper_authors: Michael Bartholomew, Joohyung Lee</li>
<li>for: 该论文旨在扩展answer set programming（ASP）中的函数支持，以便在ASP中执行first-order reasoning。</li>
<li>methods: 该论文使用了 Ferraris、Lee、Lifschitz的first-order stable model semantics，并将函数与前置定义的 predicate 一样地处理。</li>
<li>results: 该论文显示了多种已知的ASP性质可以自然地扩展到该形式中，并与其他相关的方法进行比较。此外，该论文还基于这种扩展定义了Answer Set Programming Modulo Theories（ASPMT），可以在含有实数的领域中进行有效的first-orderreasoning。<details>
<summary>Abstract</summary>
In classical logic, nonBoolean fluents, such as the location of an object, can be naturally described by functions. However, this is not the case in answer set programs, where the values of functions are pre-defined, and nonmonotonicity of the semantics is related to minimizing the extents of predicates but has nothing to do with functions. We extend the first-order stable model semantics by Ferraris, Lee, and Lifschitz to allow intensional functions -- functions that are specified by a logic program just like predicates are specified. We show that many known properties of the stable model semantics are naturally extended to this formalism and compare it with other related approaches to incorporating intensional functions. Furthermore, we use this extension as a basis for defining Answer Set Programming Modulo Theories (ASPMT), analogous to the way that Satisfiability Modulo Theories (SMT) is defined, allowing for SMT-like effective first-order reasoning in the context of ASP. Using SMT solving techniques involving functions, ASPMT can be applied to domains containing real numbers and alleviates the grounding problem. We show that other approaches to integrating ASP and CSP/SMT can be related to special cases of ASPMT in which functions are limited to non-intensional ones.
</details>
<details>
<summary>摘要</summary>
在经典逻辑中，非布尔流变量，如物体的位置，可以自然地被函数描述。然而，在答案集程序中，函数的值是预先定义的，并且非 monotonicity 的 semantics 与函数没有直接关系。我们将 Ferraris、Lee 和 Lifschitz 的第一阶stable model semantics 扩展以允许内在函数 -- 函数被逻辑程序所定义，与 predicates 一样。我们表明了许多已知的 stable model semantics 的属性被自然地扩展到这种 формалиズмом，并与其他相关的方法进行比较。此外，我们使用这种扩展为基础，定义了 Answer Set Programming Modulo Theories（ASPMT），类似于 Satisfiability Modulo Theories（SMT）的定义，允许在 ASP 中进行有效的第一阶逻辑推理。使用 SMT 解决方法 involving functions，ASPMT 可以应用于含有实数的Domain中，并alleviate the grounding problem。我们还证明了其他将 ASP 和 CSP/SMT 集成的方法可以被看作 ASPMT 中函数的特殊情况。
</details></li>
</ul>
<hr>
<h2 id="RL-ViGen-A-Reinforcement-Learning-Benchmark-for-Visual-Generalization"><a href="#RL-ViGen-A-Reinforcement-Learning-Benchmark-for-Visual-Generalization" class="headerlink" title="RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization"></a>RL-ViGen: A Reinforcement Learning Benchmark for Visual Generalization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.10224">http://arxiv.org/abs/2307.10224</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gemcollector/rl-vigen">https://github.com/gemcollector/rl-vigen</a></li>
<li>paper_authors: Zhecheng Yuan, Sizhe Yang, Pu Hua, Can Chang, Kaizhe Hu, Xiaolong Wang, Huazhe Xu<br>for:* 这篇论文旨在解决视觉学习中的扩展性问题，即RL Agent在不同任务和扩展类别下的扩展性能力的评估。methods:* 本论文提出了RL-ViGen，一个新的视觉学习评价 benchmark，其包含了多种任务和扩展类别，以便更好地评估RL Agent的扩展性能力。results:* 实验结果表明，现有的视觉RL算法中没有一个 universally 适用于所有任务，RL-ViGen 可以作为一个 catalyst，促进未来创造出适用于实际场景的通用视觉RL Agent。<details>
<summary>Abstract</summary>
Visual Reinforcement Learning (Visual RL), coupled with high-dimensional observations, has consistently confronted the long-standing challenge of out-of-distribution generalization. Despite the focus on algorithms aimed at resolving visual generalization problems, we argue that the devil is in the existing benchmarks as they are restricted to isolated tasks and generalization categories, undermining a comprehensive evaluation of agents' visual generalization capabilities. To bridge this gap, we introduce RL-ViGen: a novel Reinforcement Learning Benchmark for Visual Generalization, which contains diverse tasks and a wide spectrum of generalization types, thereby facilitating the derivation of more reliable conclusions. Furthermore, RL-ViGen incorporates the latest generalization visual RL algorithms into a unified framework, under which the experiment results indicate that no single existing algorithm has prevailed universally across tasks. Our aspiration is that RL-ViGen will serve as a catalyst in this area, and lay a foundation for the future creation of universal visual generalization RL agents suitable for real-world scenarios. Access to our code and implemented algorithms is provided at https://gemcollector.github.io/RL-ViGen/.
</details>
<details>
<summary>摘要</summary>
visual reinforcement learning (Visual RL)  coupled with high-dimensional observations, has consistently confronted the long-standing challenge of out-of-distribution generalization. Despite the focus on algorithms aimed at resolving visual generalization problems, we argue that the devil is in the existing benchmarks as they are restricted to isolated tasks and generalization categories, undermining a comprehensive evaluation of agents' visual generalization capabilities. To bridge this gap, we introduce RL-ViGen: a novel Reinforcement Learning Benchmark for Visual Generalization, which contains diverse tasks and a wide spectrum of generalization types, thereby facilitating the derivation of more reliable conclusions. Furthermore, RL-ViGen incorporates the latest generalization visual RL algorithms into a unified framework, under which the experiment results indicate that no single existing algorithm has prevailed universally across tasks. Our aspiration is that RL-ViGen will serve as a catalyst in this area, and lay a foundation for the future creation of universal visual generalization RL agents suitable for real-world scenarios. Access to our code and implemented algorithms is provided at https://gemcollector.github.io/RL-ViGen/.Here's the word-for-word translation of the text into Simplified Chinese:视觉强化学习（Visual RL），结合高维度观察，一直面临着 OUT-OF-distribution 泛化挑战。尽管关注在解决视觉泛化问题上的算法，但我们认为存在的 benchmarks 是隔离任务和泛化类别的，这会妨碍对代理人的视觉泛化能力进行全面评估。为了bridging这个差距，我们介绍 RL-ViGen：一个新的强化学习 benchmark  для视觉泛化，包含多种任务和广泛的泛化类型，从而促进更可靠的结论。此外， RL-ViGen 还将 latest visual RL 泛化算法集成到一个统一的框架中，实验结果表明，无论任务，任何一个现有算法都没有在所有任务上 universal 适用。我们希望 RL-ViGen 能成为这一领域的 catalyst，并为实际场景中的 universal 视觉泛化 RL 代理人提供基础。可以在https://gemcollector.github.io/RL-ViGen/ 获取我们的代码和实现算法。
</details></li>
</ul>
<hr>
<h2 id="NeurASP-Embracing-Neural-Networks-into-Answer-Set-Programming"><a href="#NeurASP-Embracing-Neural-Networks-into-Answer-Set-Programming" class="headerlink" title="NeurASP: Embracing Neural Networks into Answer Set Programming"></a>NeurASP: Embracing Neural Networks into Answer Set Programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07700">http://arxiv.org/abs/2307.07700</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhun Yang, Adam Ishay, Joohyung Lee</li>
<li>for: 用于结合符号计算和低水平计算的简单扩展</li>
<li>methods: 使用神经网络输出作为答案集计算中的概率分布</li>
<li>results: 可以使用预训练神经网络进行符号计算，并通过应用符号逻辑来改善神经网络的感知结果，同时可以通过训练ASP规则来使神经网络更好地学习。<details>
<summary>Abstract</summary>
We present NeurASP, a simple extension of answer set programs by embracing neural networks. By treating the neural network output as the probability distribution over atomic facts in answer set programs, NeurASP provides a simple and effective way to integrate sub-symbolic and symbolic computation. We demonstrate how NeurASP can make use of a pre-trained neural network in symbolic computation and how it can improve the neural network's perception result by applying symbolic reasoning in answer set programming. Also, NeurASP can be used to train a neural network better by training with ASP rules so that a neural network not only learns from implicit correlations from the data but also from the explicit complex semantic constraints expressed by the rules.
</details>
<details>
<summary>摘要</summary>
我团队今天宣布了一个简单的扩展项目，即NeurASP，它通过将神经网络输出视为答案集程序中的概率分布来实现。通过将子符号计算和符号计算结合起来，NeurASP提供了一个简单有效的方式来整合子符号计算和符号计算。我们展示了如何使用预训练神经网络进行符号计算，以及如何通过应用答案集程序的 символиック逻辑来改进神经网络的识别结果。此外，NeurASP还可以用来训练神经网络，使其不仅从数据中学习隐式相关性，还从答案集程序中表达的复杂 semantic constraints中学习明确的符号逻辑。
</details></li>
</ul>
<hr>
<h2 id="Leveraging-Large-Language-Models-to-Generate-Answer-Set-Programs"><a href="#Leveraging-Large-Language-Models-to-Generate-Answer-Set-Programs" class="headerlink" title="Leveraging Large Language Models to Generate Answer Set Programs"></a>Leveraging Large Language Models to Generate Answer Set Programs</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07699">http://arxiv.org/abs/2307.07699</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/azreasoners/gpt-asp-rules">https://github.com/azreasoners/gpt-asp-rules</a></li>
<li>paper_authors: Adam Ishay, Zhun Yang, Joohyung Lee</li>
<li>for: 该论文旨在探讨大型自然语言处理模型（LLM）如何帮助创建答案集程序（Answer Set Program），以便解决复杂的逻辑问题。</li>
<li>methods: 该论文提出了一种 neuromorphic 方法，即使用 LLM 将自然语言描述转换为答案集程序。该方法首先使用 LLM 转换自然语言描述为一系列的句子，然后使用答案集程序语言来描述问题。</li>
<li>results: 研究发现，只需要几个受Context learning示例，LLM 就可以生成相对复杂的答案集程序。大多数错误都是相对简单的，可以由人类轻松 corrrect。因此，LLM 可以有效地帮助创建答案集程序。<details>
<summary>Abstract</summary>
Large language models (LLMs), such as GPT-3 and GPT-4, have demonstrated exceptional performance in various natural language processing tasks and have shown the ability to solve certain reasoning problems. However, their reasoning capabilities are limited and relatively shallow, despite the application of various prompting techniques. In contrast, formal logic is adept at handling complex reasoning, but translating natural language descriptions into formal logic is a challenging task that non-experts struggle with. This paper proposes a neuro-symbolic method that combines the strengths of large language models and answer set programming. Specifically, we employ an LLM to transform natural language descriptions of logic puzzles into answer set programs. We carefully design prompts for an LLM to convert natural language descriptions into answer set programs in a step by step manner. Surprisingly, with just a few in-context learning examples, LLMs can generate reasonably complex answer set programs. The majority of errors made are relatively simple and can be easily corrected by humans, thus enabling LLMs to effectively assist in the creation of answer set programs.
</details>
<details>
<summary>摘要</summary>
大型语言模型（LLM），如GPT-3和GPT-4，在不同的自然语言处理任务中表现出色，并且能够解决一些推理问题。然而，它们的推理能力相对较浅，即使使用了不同的推问技巧。相比之下，正式逻辑能够处理复杂的推理，但将自然语言描述转换为正式逻辑是一个困难的任务，非专家通常难以进行。这篇论文提议了一个神经符号方法，将大型语言模型和答案集计算结合在一起。具体来说，我们使用一个LLM将自然语言描述逻辑题目转换为答案集程式。我们严格设计了对LLM的推问示例，以步骤地方式将自然语言描述转换为答案集程式。 surprisingly，仅需几个内容学习示例，LLM可以生成相对复杂的答案集程式。大多数错误都是相对简单的，可以轻松地由人类更正，因此LLM可以有效地协助创建答案集程式。
</details></li>
</ul>
<hr>
<h2 id="The-Growth-of-E-Bike-Use-A-Machine-Learning-Approach"><a href="#The-Growth-of-E-Bike-Use-A-Machine-Learning-Approach" class="headerlink" title="The Growth of E-Bike Use: A Machine Learning Approach"></a>The Growth of E-Bike Use: A Machine Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02034">http://arxiv.org/abs/2308.02034</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aditya Gupta, Samarth Chitgopekar, Alexander Kim, Joseph Jiang, Megan Wang, Christopher Grattoni</li>
<li>for: 这项研究是为了帮助政策制定者更好地理解电动自行车（e-bike）的发展和影响。</li>
<li>methods: 这项研究使用了ARIMA模型和一种监管式机器学习算法来预测电动自行车销售量的增长。此外，研究还使用了Random Forest回归模型来分析电动自行车销售增长的因素。</li>
<li>results: 研究发现，电动自行车在美国的使用带来了15,737.82公斤的二氧化碳排放减少和716,630.727千卡路里的热量燃烧。此外，研究还发现了电动自行车销售增长的主要影响因素，包括可 dispose的人均收入和受欢迎程度。<details>
<summary>Abstract</summary>
We present our work on electric bicycles (e-bikes) and their implications for policymakers in the United States. E-bikes have gained significant popularity as a fast and eco-friendly transportation option. As we strive for a sustainable energy plan, understanding the growth and impact of e-bikes is crucial for policymakers. Our mathematical modeling offers insights into the value of e-bikes and their role in the future. Using an ARIMA model, a supervised machine-learning algorithm, we predicted the growth of e-bike sales in the U.S. Our model, trained on historical sales data from January 2006 to December 2022, projected sales of 1.3 million units in 2025 and 2.113 million units in 2028. To assess the factors contributing to e-bike usage, we employed a Random Forest regression model. The most significant factors influencing e-bike sales growth were disposable personal income and popularity. Furthermore, we examined the environmental and health impacts of e-bikes. Through Monte Carlo simulations, we estimated the reduction in carbon emissions due to e-bike use and the calories burned through e-biking. Our findings revealed that e-bike usage in the U.S. resulted in a reduction of 15,737.82 kilograms of CO2 emissions in 2022. Additionally, e-bike users burned approximately 716,630.727 kilocalories through their activities in the same year. Our research provides valuable insights for policymakers, emphasizing the potential of e-bikes as a sustainable transportation solution. By understanding the growth factors and quantifying the environmental and health benefits, policymakers can make informed decisions about integrating e-bikes into future energy and transportation strategies.
</details>
<details>
<summary>摘要</summary>
我们在美国的电动自行车（e-bike）方面进行了研究，并对政策制定者提供了有价值的信息。电动自行车在快速和环保的交通方式上受到了广泛的欢迎，因此理解电动自行车的增长和影响对于政策制定者是非常重要的。我们使用ARIMA模型和一种监管的机器学习算法来预测美国电动自行车销售的增长。我们的模型，基于2006年1月至2022年12月的历史销售数据，预测到2025年的销售量将达130万台，而到2028年将达2113万台。为了了解电动自行车使用的因素，我们使用Random Forest回归模型。我们发现，个人废弃收入和流行度是电动自行车销售增长的最重要因素。此外，我们还对电动自行车的环境和健康影响进行了分析。通过蒙特卡罗 simulate，我们计算了因电动自行车使用而减少的二氧化碳排放量和通过电动自行车活动烧取的卡路里。我们的发现表明，在2022年，美国的电动自行车使用已经减少了15737.82公斤的二氧化碳排放量，同时电动自行车用户通过其活动烧取了约716630.727公斤的卡路里。我们的研究为政策制定者提供了有价值的信息，证明了电动自行车的可持续性，并且可以作为未来能源和交通战略的一部分。通过理解电动自行车增长的因素和量化电动自行车对环境和健康的影响，政策制定者可以做出有知识的决策。
</details></li>
</ul>
<hr>
<h2 id="Coupling-Large-Language-Models-with-Logic-Programming-for-Robust-and-General-Reasoning-from-Text"><a href="#Coupling-Large-Language-Models-with-Logic-Programming-for-Robust-and-General-Reasoning-from-Text" class="headerlink" title="Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text"></a>Coupling Large Language Models with Logic Programming for Robust and General Reasoning from Text</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07696">http://arxiv.org/abs/2307.07696</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/azreasoners/llm-asp">https://github.com/azreasoners/llm-asp</a></li>
<li>paper_authors: Zhun Yang, Adam Ishay, Joohyung Lee</li>
<li>for: 这个论文主要目标是提高大语言模型（LLM）的逻辑能力，使其能够与专门为逻辑语言理解问题训练的模型竞争。</li>
<li>methods: 该论文使用了一种基于 ASP（answer set programming）的逻辑知识表示形式，将自然语言句子转换为逻辑形式，并将这些逻辑形式作为 LLM 的输入。这种方法可以在不需要重新训练的情况下，让 LLM 适应不同的问题。</li>
<li>results: 该论文实验表明，这种方法可以在多个 NLP 评估 benchmark 上实现state-of-the-art 性能，包括 bAbI、StepGame、CLUTRR 和 gSCAN。此外，这种方法还可以成功解决了一些 LLM 无法解决的机器人规划任务。<details>
<summary>Abstract</summary>
While large language models (LLMs), such as GPT-3, appear to be robust and general, their reasoning ability is not at a level to compete with the best models trained for specific natural language reasoning problems. In this study, we observe that a large language model can serve as a highly effective few-shot semantic parser. It can convert natural language sentences into a logical form that serves as input for answer set programs, a logic-based declarative knowledge representation formalism. The combination results in a robust and general system that can handle multiple question-answering tasks without requiring retraining for each new task. It only needs a few examples to guide the LLM's adaptation to a specific task, along with reusable ASP knowledge modules that can be applied to multiple tasks. We demonstrate that this method achieves state-of-the-art performance on several NLP benchmarks, including bAbI, StepGame, CLUTRR, and gSCAN. Additionally, it successfully tackles robot planning tasks that an LLM alone fails to solve.
</details>
<details>
<summary>摘要</summary>
大型自然语言模型（LLM），如GPT-3，看起来具有坚固的基础和通用性，但它们的理解能力并没有与专门设计的自然语言理解问题模型相比。在这个研究中，我们发现了一种使用大型自然语言模型来实现几次例示semantic parser的方法。它可以将自然语言句子转换成逻辑形式，该逻辑形式可以作为答案集程序的输入，这种逻辑基于的知识表示形式。这种组合系统可以处理多个问题回答任务，无需为每个新任务进行重新训练。它只需要几个示例来导引LLM的适应特定任务，以及可重用的ASP知识模块，可以应用于多个任务。我们 demonstated 这种方法在多个 NLP 标准准测试上达到了现状最佳性能，包括 bAbI、StepGame、CLUTRR 和 gSCAN。此外，它还成功解决了一些 LLM 无法解决的机器人规划任务。
</details></li>
</ul>
<hr>
<h2 id="A-Survey-on-Change-Detection-Techniques-in-Document-Images"><a href="#A-Survey-on-Change-Detection-Techniques-in-Document-Images" class="headerlink" title="A Survey on Change Detection Techniques in Document Images"></a>A Survey on Change Detection Techniques in Document Images</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07691">http://arxiv.org/abs/2307.07691</a></li>
<li>repo_url: None</li>
<li>paper_authors: Abhinandan Kumar Pun, Mohammed Javed, David S. Doermann</li>
<li>for: 本文主要针对文档图像中的变化检测问题，其应用于医学、Remote Sensing 等领域。</li>
<li>methods: 本文对文档图像中的变化检测方法进行了报告和分析，包括内容基于的方法和结构基于的方法。</li>
<li>results: 本文对文档图像中的变化检测方法进行了总结和评价，并报告了现有的数据集和评价指标，以及现有方法的缺点和挑战。<details>
<summary>Abstract</summary>
The problem of change detection in images finds application in different domains like diagnosis of diseases in the medical field, detecting growth patterns of cities through remote sensing, and finding changes in legal documents and contracts. However, this paper presents a survey on core techniques and rules to detect changes in different versions of a document image. Our discussions on change detection focus on two categories -- content-based and layout-based. The content-based techniques intelligently extract and analyze the image contents (text or non-text) to show the possible differences, whereas the layout-based techniques use structural information to predict document changes. We also summarize the existing datasets and evaluation metrics used in change detection experiments. The shortcomings and challenges the existing methods face are reported, along with some pointers for future research work.
</details>
<details>
<summary>摘要</summary>
该问题在不同领域都有应用，如医疗领域的疾病诊断、通过远程感知获取城市增长趋势，以及法律文档和合同中的变化检测。然而，本文主要介绍了文档版本之间的变化检测技术和规则。我们的讨论关注内容基于和布局基于的两个类别。内容基于的技术通过智能EXTRACT和分析图像内容（文本或非文本）来显示可能的差异，而布局基于的技术使用结构信息预测文档变化。我们还总结了已有的数据集和评价标准，并报告现有方法的缺陷和挑战，以及未来研究的指向。
</details></li>
</ul>
<hr>
<h2 id="Creating-a-Dataset-for-High-Performance-Computing-Code-Translation-A-Bridge-Between-HPC-Fortran-and-C"><a href="#Creating-a-Dataset-for-High-Performance-Computing-Code-Translation-A-Bridge-Between-HPC-Fortran-and-C" class="headerlink" title="Creating a Dataset for High-Performance Computing Code Translation: A Bridge Between HPC Fortran and C++"></a>Creating a Dataset for High-Performance Computing Code Translation: A Bridge Between HPC Fortran and C++</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07686">http://arxiv.org/abs/2307.07686</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bin123apple/fortran-cpp-hpc-code-translation-dataset">https://github.com/bin123apple/fortran-cpp-hpc-code-translation-dataset</a></li>
<li>paper_authors: Bin Lei, Caiwen Ding, Le Chen, Pei-Hung Lin, Chunhua Liao</li>
<li>for: 这个论文是为了提供一个用于训练机器学习模型翻译OpenMP Fortran和C++代码的新数据集而写的。</li>
<li>methods: 该论文使用了一种精心制定的代码相似性测试来初步准备数据集，以确保其可靠性和可应用性。然后，通过量化（CodeBLEU）和质量（人员评估）方法评估数据集的效果。</li>
<li>results: 研究表明，使用该数据集可以大幅提高大规模语言模型的翻译能力，具体提高$\times 5.1$（无前期编程知识）和$\times 9.9$（有些编程familiarity）。这种数据集的出现有助于提高高性计算代码翻译的领域进步。数据集可以在<a target="_blank" rel="noopener" href="https://github.com/bin123apple/Fortran-CPP-HPC-code-translation-dataset%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/bin123apple/Fortran-CPP-HPC-code-translation-dataset中下载。</a><details>
<summary>Abstract</summary>
In this study, we present a novel dataset for training machine learning models translating between OpenMP Fortran and C++ code. To ensure reliability and applicability, the dataset is initially refined using a meticulous code similarity test. The effectiveness of our dataset is assessed using both quantitative (CodeBLEU) and qualitative (human evaluation) methods. We demonstrate how this dataset can significantly improve the translation capabilities of large-scale language models, with improvements of $\mathbf{\times 5.1}$ for models with no prior coding knowledge and $\mathbf{\times 9.9}$ for models with some coding familiarity. Our work highlights the potential of this dataset to advance the field of code translation for high-performance computing. The dataset is available at https://github.com/bin123apple/Fortran-CPP-HPC-code-translation-dataset
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们提供了一个新的代码集合用于训练机器学习模型翻译OpenMP Fortran和C++代码。为确保可靠性和可应用性，我们首先使用仔细的代码相似性测试进行初步约束。我们使用代码BLEU和人类评估方法进行评估效果，并证明这些数据可以帮助大规模语言模型提高翻译能力，其中模型没有编程知识时提高$\times 5.1$，而具有一定编程经验时提高$\times 9.9$。我们的工作表明这个数据集可以推动高性能计算领域代码翻译的发展。这个数据集可以在https://github.com/bin123apple/Fortran-CPP-HPC-code-translation-dataset中下载。
</details></li>
</ul>
<hr>
<h2 id="Bound-by-the-Bounty-Collaboratively-Shaping-Evaluation-Processes-for-Queer-AI-Harms"><a href="#Bound-by-the-Bounty-Collaboratively-Shaping-Evaluation-Processes-for-Queer-AI-Harms" class="headerlink" title="Bound by the Bounty: Collaboratively Shaping Evaluation Processes for Queer AI Harms"></a>Bound by the Bounty: Collaboratively Shaping Evaluation Processes for Queer AI Harms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.10223">http://arxiv.org/abs/2307.10223</a></li>
<li>repo_url: None</li>
<li>paper_authors: Organizers of QueerInAI, Nathan Dennler, Anaelia Ovalle, Ashwin Singh, Luca Soldaini, Arjun Subramonian, Huy Tu, William Agnew, Avijit Ghosh, Kyra Yee, Irene Font Peradejordi, Zeerak Talat, Mayra Russo, Jess de Jesus de Pinho Pinhal</li>
<li>for: This paper aims to understand the perspectives of queer communities on bias evaluation benchmarks and dataset and model documentation for AI systems, and to redesign these processes from queer perspectives.</li>
<li>methods: The paper uses a participatory workshop to gather feedback from queer communities on bias bounties and to critique and redesign these processes.</li>
<li>results: The paper finds that queer communities have concerns about the ownership, incentives, and efficacy of bias bounties, and advocates for community ownership of bounties and the use of participatory processes (e.g., co-creation) to complement bias bounties.<details>
<summary>Abstract</summary>
Bias evaluation benchmarks and dataset and model documentation have emerged as central processes for assessing the biases and harms of artificial intelligence (AI) systems. However, these auditing processes have been criticized for their failure to integrate the knowledge of marginalized communities and consider the power dynamics between auditors and the communities. Consequently, modes of bias evaluation have been proposed that engage impacted communities in identifying and assessing the harms of AI systems (e.g., bias bounties). Even so, asking what marginalized communities want from such auditing processes has been neglected. In this paper, we ask queer communities for their positions on, and desires from, auditing processes. To this end, we organized a participatory workshop to critique and redesign bias bounties from queer perspectives. We found that when given space, the scope of feedback from workshop participants goes far beyond what bias bounties afford, with participants questioning the ownership, incentives, and efficacy of bounties. We conclude by advocating for community ownership of bounties and complementing bounties with participatory processes (e.g., co-creation).
</details>
<details>
<summary>摘要</summary>
人工智能（AI）系统的偏见和伤害评估过程和数据集已成为评估AI系统偏见和伤害的中心过程。然而，这些审核过程受到了社会弱势群体知识不包括和审核人员与社区力量不均衡的批评。因此，一些偏见评估模式被提出，通过与受影响社区合作来识别和评估AI系统的伤害（例如，偏见报酬）。然而，寻求社会弱势群体想要从审核过程中获得的问题仍然被忽略。在这篇论文中，我们问到了LGBTQ+社区对审核过程的看法和期望。为此，我们组织了参与式工作坊，批判和重新设计偏见报酬从Queer perspective。我们发现，当给予参与者空间时，参与者的反馈范围超出了偏见报酬的范围，参与者质疑报酬的所有权、动机和有效性。我们 conclude by advocating for community ownership of bounties and complementing bounties with participatory processes (e.g., co-creation).
</details></li>
</ul>
<hr>
<h2 id="Efficient-Adversarial-Attacks-on-Online-Multi-agent-Reinforcement-Learning"><a href="#Efficient-Adversarial-Attacks-on-Online-Multi-agent-Reinforcement-Learning" class="headerlink" title="Efficient Adversarial Attacks on Online Multi-agent Reinforcement Learning"></a>Efficient Adversarial Attacks on Online Multi-agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07670">http://arxiv.org/abs/2307.07670</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guanlin Liu, Lifeng Lai</li>
<li>For: 本研究探讨了多智能体强化学习（MARL）模型面临恶意攻击的影响。* Methods: 我们 investigate the impact of adversarial attacks on MARL models, including action poisoning and reward poisoning attacks, as well as a mixed attack strategy that combines both.* Results: 我们发现，混合攻击策略可以高效地攻击 MARL 模型，即使攻击者没有对环境和代理人算法的任何先前信息。<details>
<summary>Abstract</summary>
Due to the broad range of applications of multi-agent reinforcement learning (MARL), understanding the effects of adversarial attacks against MARL model is essential for the safe applications of this model. Motivated by this, we investigate the impact of adversarial attacks on MARL. In the considered setup, there is an exogenous attacker who is able to modify the rewards before the agents receive them or manipulate the actions before the environment receives them. The attacker aims to guide each agent into a target policy or maximize the cumulative rewards under some specific reward function chosen by the attacker, while minimizing the amount of manipulation on feedback and action. We first show the limitations of the action poisoning only attacks and the reward poisoning only attacks. We then introduce a mixed attack strategy with both the action poisoning and the reward poisoning. We show that the mixed attack strategy can efficiently attack MARL agents even if the attacker has no prior information about the underlying environment and the agents' algorithms.
</details>
<details>
<summary>摘要</summary>
We first show the limitations of action poisoning only attacks and reward poisoning only attacks. We then introduce a mixed attack strategy that combines both action poisoning and reward poisoning. We demonstrate that the mixed attack strategy can effectively attack MARL agents even if the attacker has no prior knowledge of the underlying environment and the agents' algorithms.
</details></li>
</ul>
<hr>
<h2 id="Efficient-Action-Robust-Reinforcement-Learning-with-Probabilistic-Policy-Execution-Uncertainty"><a href="#Efficient-Action-Robust-Reinforcement-Learning-with-Probabilistic-Policy-Execution-Uncertainty" class="headerlink" title="Efficient Action Robust Reinforcement Learning with Probabilistic Policy Execution Uncertainty"></a>Efficient Action Robust Reinforcement Learning with Probabilistic Policy Execution Uncertainty</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07666">http://arxiv.org/abs/2307.07666</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guanlin Liu, Zhihan Zhou, Han Liu, Lifeng Lai</li>
<li>for: 这 paper 的目的是提出一种可靠的 reinforcement learning 算法，可以在行动不确定性的情况下优化最坏情况性能。</li>
<li>methods: 这 paper 使用了 probablistic policy execution uncertainty，并提出了 action robust Bellman optimality equation 来解决这类 MDP 中的优化问题。</li>
<li>results: 该 paper 的 Action Robust Reinforcement Learning with Certificates (ARRLC) 算法可以 дости到 minimax 优化的 regret 和样本复杂度，并且在实验中证明了其在行动偏移情况下的稳定性和更快的 converges 速度。<details>
<summary>Abstract</summary>
Robust reinforcement learning (RL) aims to find a policy that optimizes the worst-case performance in the face of uncertainties. In this paper, we focus on action robust RL with the probabilistic policy execution uncertainty, in which, instead of always carrying out the action specified by the policy, the agent will take the action specified by the policy with probability $1-\rho$ and an alternative adversarial action with probability $\rho$. We establish the existence of an optimal policy on the action robust MDPs with probabilistic policy execution uncertainty and provide the action robust Bellman optimality equation for its solution. Furthermore, we develop Action Robust Reinforcement Learning with Certificates (ARRLC) algorithm that achieves minimax optimal regret and sample complexity. Furthermore, we conduct numerical experiments to validate our approach's robustness, demonstrating that ARRLC outperforms non-robust RL algorithms and converges faster than the robust TD algorithm in the presence of action perturbations.
</details>
<details>
<summary>摘要</summary>
中文简体版Robust reinforcement learning（RL）目的是找到面对不确定性时的最佳策略。在这篇论文中，我们关注行动稳健RL，即在执行策略时存在可能性的情况下，agent将按照策略指定的行动执行的可能性为$1-\rho$，而剩下的可能性为$\rho$。我们证明了action robust Markov decision process（MDP）中的优化策略的存在，并提供了action robust Bellman优化方程的解。此外，我们开发了Action Robust Reinforcement Learning with Certificates（ARRLC）算法，实现了最小最大 regret和样本复杂度的优化。此外，我们进行了数值实验，证明了ARRLC在行动偏移下的 robustness，并证明它在存在行动偏移时比非稳健RL算法和robust TD算法更快 converges。Traditional Chinese versionRobust reinforcement learning（RL）的目的是找到面对不确定性时的最佳策略。在这篇论文中，我们关注行动稳健RL，即在执行策略时存在可能性的情况下，agent将按照策略指定的行动执行的可能性为$1-\rho$，而剩下的可能性为$\rho$。我们证明了action robust Markov decision process（MDP）中的优化策略的存在，并提供了action robust Bellman优化方程的解。此外，我们开发了Action Robust Reinforcement Learning with Certificates（ARRLC）算法，实现了最小最大 regret和样本复杂度的优化。此外，我们进行了数值实验，证明了ARRLC在行动偏移下的 robustness，并证明它在存在行动偏移时比非稳健RL算法和robust TD算法更快 converges。
</details></li>
</ul>
<hr>
<h2 id="MPDIoU-A-Loss-for-Efficient-and-Accurate-Bounding-Box-Regression"><a href="#MPDIoU-A-Loss-for-Efficient-and-Accurate-Bounding-Box-Regression" class="headerlink" title="MPDIoU: A Loss for Efficient and Accurate Bounding Box Regression"></a>MPDIoU: A Loss for Efficient and Accurate Bounding Box Regression</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07662">http://arxiv.org/abs/2307.07662</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ma Siliang, Xu Yong</li>
<li>for: 本研究旨在解决现有 bounding box regression loss function 无法优化 predicted box 和 groundtruth box 尺寸相同但是宽高值不同的问题。</li>
<li>methods: 本研究提出了一种基于 minimum point distance 的 bounding box similarity comparison metric MPDIoU，包括了现有 loss functions 中考虑的所有相关因素，如 overlap 或 non-overlapping 面积、中心点距离、宽高差异，而简化计算过程。基于 MPDIoU 的 bounding box regression loss function 被称为 LMPDIoU。</li>
<li>results: 实验结果表明，基于 MPDIoU 的 loss function 在 state-of-the-art instance segmentation 和 object detection 模型（例如 YOLACT 和 YOLOv7）上，对 PASCAL VOC、MS COCO 和 IIIT5k 进行训练后，与现有 loss functions 相比，具有更高的精度和效果。<details>
<summary>Abstract</summary>
Bounding box regression (BBR) has been widely used in object detection and instance segmentation, which is an important step in object localization. However, most of the existing loss functions for bounding box regression cannot be optimized when the predicted box has the same aspect ratio as the groundtruth box, but the width and height values are exactly different. In order to tackle the issues mentioned above, we fully explore the geometric features of horizontal rectangle and propose a novel bounding box similarity comparison metric MPDIoU based on minimum point distance, which contains all of the relevant factors considered in the existing loss functions, namely overlapping or non-overlapping area, central points distance, and deviation of width and height, while simplifying the calculation process. On this basis, we propose a bounding box regression loss function based on MPDIoU, called LMPDIoU . Experimental results show that the MPDIoU loss function is applied to state-of-the-art instance segmentation (e.g., YOLACT) and object detection (e.g., YOLOv7) model trained on PASCAL VOC, MS COCO, and IIIT5k outperforms existing loss functions.
</details>
<details>
<summary>摘要</summary>
bounding box regression (BBR) 广泛应用于物体检测和实例分割，是物体Localization的重要步骤。然而，现有的 bounding box regression 损失函数无法优化预测框与实际框的尺寸值不同，但宽高比相同的情况。为解决以上问题，我们彻底探讨直方框的几何特征，并提出一种基于最小点距离的 bounding box 相似比较度量 MPDIoU，该度量包含现有损失函数中考虑的所有因素，包括重叠或非重叠区域、中心点距离、宽高差异，而简化计算过程。基于 MPDIoU 度量，我们提出了一种基于 MPDIoU 的 bounding box regression 损失函数 LMPDIoU。实验结果表明，MPDIoU 损失函数在 state-of-the-art 实例分割（如 YOLACT）和物体检测（如 YOLOv7）模型在 PASCAL VOC、MS COCO 和 IIIT5k 上训练后，与现有损失函数相比，具有更高的性能。
</details></li>
</ul>
<hr>
<h2 id="SALC-Skeleton-Assisted-Learning-Based-Clustering-for-Time-Varying-Indoor-Localization"><a href="#SALC-Skeleton-Assisted-Learning-Based-Clustering-for-Time-Varying-Indoor-Localization" class="headerlink" title="SALC: Skeleton-Assisted Learning-Based Clustering for Time-Varying Indoor Localization"></a>SALC: Skeleton-Assisted Learning-Based Clustering for Time-Varying Indoor Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07650">http://arxiv.org/abs/2307.07650</a></li>
<li>repo_url: None</li>
<li>paper_authors: An-Hung Hsiao, Li-Hsiang Shen, Chen-Yi Chang, Chun-Jie Chiu, Kai-Ten Feng<br>for: 本研究旨在提高室内地位系统的精度和可靠性，透过对室内 WiFi 接点点 (AP) 的接收信号强度 (RSS) 进行建立 fingerprinting 数据库。methods: 本研究提出了一个基于 skeleton-assisted learning-based clustering (SALC) 系统，包括 RSS-oriented map-assisted clustering (ROMAC)、cluster-based online database establishment (CODE) 和 cluster-scaled location estimation (CsLE)。SALC 系统结合了骨架基于最短路 (SSP) 的相似性和时间变化的 RSS 测量 across reference points (RPs)。results:  simulation 和实验结果表明，提出的 SALC 系统可以有效地重建 fingerprint 数据库，提高地位估计精度，比较出色于现有Literature中的其他方法。<details>
<summary>Abstract</summary>
Wireless indoor localization has attracted significant amount of attention in recent years. Using received signal strength (RSS) obtained from WiFi access points (APs) for establishing fingerprinting database is a widely utilized method in indoor localization. However, the time-variant problem for indoor positioning systems is not well-investigated in existing literature. Compared to conventional static fingerprinting, the dynamicallyreconstructed database can adapt to a highly-changing environment, which achieves sustainability of localization accuracy. To deal with the time-varying issue, we propose a skeleton-assisted learning-based clustering localization (SALC) system, including RSS-oriented map-assisted clustering (ROMAC), cluster-based online database establishment (CODE), and cluster-scaled location estimation (CsLE). The SALC scheme jointly considers similarities from the skeleton-based shortest path (SSP) and the time-varying RSS measurements across the reference points (RPs). ROMAC clusters RPs into different feature sets and therefore selects suitable monitor points (MPs) for enhancing location estimation. Moreover, the CODE algorithm aims for establishing adaptive fingerprint database to alleviate the timevarying problem. Finally, CsLE is adopted to acquire the target position by leveraging the benefits of clustering information and estimated signal variations in order to rescale the weights fromweighted k-nearest neighbors (WkNN) method. Both simulation and experimental results demonstrate that the proposed SALC system can effectively reconstruct the fingerprint database with an enhanced location estimation accuracy, which outperforms the other existing schemes in the open literature.
</details>
<details>
<summary>摘要</summary>
无线内部位置已引起过去几年的广泛关注。使用WiFi接入点（AP）接收信号强度（RSS）建立指本库是内部位置系统中广泛使用的方法。然而，现有文献中对内部位置系统的时间变化问题并未得到充分研究。与传统静止指本相比，动态重建库可以适应高度变化的环境，实现位置准确性的持续稳定。为解决时间变化问题，我们提出了骨架帮助学习基本的集成位置系统（SALC），包括RSS方向的地图帮助集成（ROMAC）、集成在线数据库建立（CODE）和集群扩大位置估计（CsLE）。SALC方案同时考虑骨架基于最短路（SSP）的相似性和时间变化的RSS测量值。ROMAC将RP集成到不同的特征集中，选择合适的监测点（MP）以提高位置估计。此外，CODE算法旨在建立适应时间变化的指本库，以解决时间变化问题。最后，CsLE方法通过利用集群信息和估计信号变化来重新调整WkNN方法中的权重，以获得更高的位置估计精度。实验和 simulations结果表明，提出的SALC系统可以有效地重建指本库，并提高位置估计精度，超过现有文献中的其他方案。
</details></li>
</ul>
<hr>
<h2 id="Othering-and-low-prestige-framing-of-immigrant-cuisines-in-US-restaurant-reviews-and-large-language-models"><a href="#Othering-and-low-prestige-framing-of-immigrant-cuisines-in-US-restaurant-reviews-and-large-language-models" class="headerlink" title="Othering and low prestige framing of immigrant cuisines in US restaurant reviews and large language models"></a>Othering and low prestige framing of immigrant cuisines in US restaurant reviews and large language models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07645">http://arxiv.org/abs/2307.07645</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yiweiluo/immigrant-food-framing">https://github.com/yiweiluo/immigrant-food-framing</a></li>
<li>paper_authors: Yiwei Luo, Kristina Gligorić, Dan Jurafsky</li>
<li>for: This paper aims to understand implicit attitudes toward food and how they can perpetuate social prejudice, specifically in the context of immigrant cuisines.</li>
<li>methods: The authors use linguistic analyses of over 2.1 million English language Yelp reviews of restaurants in 14 US states to evaluate social theories about attitudes toward immigrant cuisine. They control for factors such as restaurant price and neighborhood racial diversity.</li>
<li>results: The authors find that immigrant cuisines are more likely to be framed in objectifying and othering terms of authenticity, exoticism, and prototypicality, and that non-Western immigrant cuisines receive more othering than European cuisines. Additionally, they find that non-Western immigrant cuisines are framed less positively and as lower status, being evaluated in terms of affordability and hygiene. Finally, they show that reviews generated by large language models (LLMs) reproduce many of the same framing tendencies.<details>
<summary>Abstract</summary>
Identifying and understanding implicit attitudes toward food can help efforts to mitigate social prejudice due to food's pervasive role as a marker of cultural and ethnic identity. Stereotypes about food are a form of microaggression that contribute to harmful public discourse that may in turn perpetuate prejudice toward ethnic groups and negatively impact economic outcomes for restaurants. Through careful linguistic analyses, we evaluate social theories about attitudes toward immigrant cuisine in a large-scale study of framing differences in 2.1M English language Yelp reviews of restaurants in 14 US states. Controlling for factors such as restaurant price and neighborhood racial diversity, we find that immigrant cuisines are more likely to be framed in objectifying and othering terms of authenticity (e.g., authentic, traditional), exoticism (e.g., exotic, different), and prototypicality (e.g., typical, usual), but that non-Western immigrant cuisines (e.g., Indian, Mexican) receive more othering than European cuisines (e.g., French, Italian). We further find that non-Western immigrant cuisines are framed less positively and as lower status, being evaluated in terms of affordability and hygiene. Finally, we show that reviews generated by large language models (LLMs) reproduce many of the same framing tendencies. Our results empirically corroborate social theories of taste and gastronomic stereotyping, and reveal linguistic processes by which such attitudes are reified.
</details>
<details>
<summary>摘要</summary>
认识和理解食物的隐式态度可以帮助减少基于食物的文化和民族身份 marker 的社会偏见。食物的刻板印象是一种微侵略，它们可能在社会公共讨论中产生有害的影响，从而导致对少数民族的偏见和不良经济效益。通过精心的语言分析，我们在大规模的英语 Yelp 评论数据集中评估社会理论对移民菜系的态度。控制因素包括餐厅价格和邻里种族多样性，我们发现移民菜系更有可能被归类为真实、传统、特色、外国、不同、常见等词汇，但非西方移民菜系（如印度、墨西哥）被其他化比欧洲菜系（如法国、意大利）更多。此外，我们发现非西方移民菜系在评价中受到负面评价，被评价为便宜和卫生。最后，我们发现由大语言模型（LLMs）生成的评论也存在类似的归类倾向。我们的结果经验证了社会理论的味蕾和文化刻板印象，并揭示了语言过程如何固化这些态度。
</details></li>
</ul>
<hr>
<h2 id="It-is-currently-hodgepodge’’-Examining-AI-ML-Practitioners’-Challenges-during-Co-production-of-Responsible-AI-Values"><a href="#It-is-currently-hodgepodge’’-Examining-AI-ML-Practitioners’-Challenges-during-Co-production-of-Responsible-AI-Values" class="headerlink" title="&#96;It is currently hodgepodge’’: Examining AI&#x2F;ML Practitioners’ Challenges during Co-production of Responsible AI Values"></a>&#96;It is currently hodgepodge’’: Examining AI&#x2F;ML Practitioners’ Challenges during Co-production of Responsible AI Values</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.10221">http://arxiv.org/abs/2307.10221</a></li>
<li>repo_url: None</li>
<li>paper_authors: Rama Adithya Varanasi, Nitesh Goyal</li>
<li>for: 本研究旨在探讨AI&#x2F;ML实践者在实施责任AI（RAI）价值观时遇到的挑战，以及这些挑战如何影响实践者的工作。</li>
<li>methods: 本研究采用了采访方法，问问23名参与者，来自10家组织，他们在实施AI&#x2F;ML产品时如何保持RAI价值观。</li>
<li>results: 研究发现，实施RAI价值观会由于组织结构和价值观念的冲突而带来挑战，这些挑战会影响实践者的工作。研究还发现了多种解决这些挑战的策略，包括在组织结构和价值观念方面进行调整。<details>
<summary>Abstract</summary>
Recently, the AI/ML research community has indicated an urgent need to establish Responsible AI (RAI) values and practices as part of the AI/ML lifecycle. Several organizations and communities are responding to this call by sharing RAI guidelines. However, there are gaps in awareness, deliberation, and execution of such practices for multi-disciplinary ML practitioners. This work contributes to the discussion by unpacking co-production challenges faced by practitioners as they align their RAI values. We interviewed 23 individuals, across 10 organizations, tasked to ship AI/ML based products while upholding RAI norms and found that both top-down and bottom-up institutional structures create burden for different roles preventing them from upholding RAI values, a challenge that is further exacerbated when executing conflicted values. We share multiple value levers used as strategies by the practitioners to resolve their challenges. We end our paper with recommendations for inclusive and equitable RAI value-practices, creating supportive organizational structures and opportunities to further aid practitioners.
</details>
<details>
<summary>摘要</summary>
We interviewed 23 individuals from 10 organizations that are tasked with shipping AI/ML-based products while upholding RAI norms. We found that both top-down and bottom-up institutional structures create burdens for different roles, preventing them from upholding RAI values. This challenge is further exacerbated when executing conflicting values.To address these challenges, we share multiple value levers used by practitioners as strategies to resolve their challenges. These include:1. Inclusive and equitable value-practices: Practitioners must prioritize inclusive and equitable value-practices that take into account the needs and perspectives of diverse stakeholders.2. Supportive organizational structures: Organizations must create supportive structures and opportunities to further aid practitioners in upholding RAI values.3. Ongoing education and training: Practitioners must receive ongoing education and training on RAI values and practices to ensure they are equipped to handle the challenges they face.We end our paper with recommendations for inclusive and equitable RAI value-practices, creating supportive organizational structures, and providing ongoing education and training to practitioners. By addressing these challenges, we can ensure that RAI values are upheld in the development and deployment of AI/ML-based products.
</details></li>
</ul>
<hr>
<h2 id="Exploring-Link-Prediction-over-Hyper-Relational-Temporal-Knowledge-Graphs-Enhanced-with-Time-Invariant-Relational-Knowledge"><a href="#Exploring-Link-Prediction-over-Hyper-Relational-Temporal-Knowledge-Graphs-Enhanced-with-Time-Invariant-Relational-Knowledge" class="headerlink" title="Exploring Link Prediction over Hyper-Relational Temporal Knowledge Graphs Enhanced with Time-Invariant Relational Knowledge"></a>Exploring Link Prediction over Hyper-Relational Temporal Knowledge Graphs Enhanced with Time-Invariant Relational Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.10219">http://arxiv.org/abs/2307.10219</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zifeng Ding, Jingcheng Wu, Jingpei Wu, Yan Xia, Volker Tresp</li>
<li>for: This paper focuses on filling the gap between temporal knowledge graph (TKG) reasoning and hyper-relational knowledge graph (HKG) reasoning, by developing a new benchmark dataset and a reasoning model that can efficiently handle both temporal and qualifier information.</li>
<li>methods: The proposed reasoning model leverages both temporal and time-invariant relational knowledge from the Wikidata knowledge base to improve the performance of HTKG reasoning.</li>
<li>results: The experimental results show that the proposed model outperforms previous related methods on HTKG link prediction, and can be further enhanced by jointly leveraging both temporal and time-invariant relational knowledge.Here’s the simplified Chinese text version of the three information points:</li>
<li>for: 这篇论文主要是填补知识图论理和超 relate 知识图论理之间的空白，通过开发新的benchmark数据集和一种能够有效处理时间和资格信息的reasoning模型。</li>
<li>methods: 提出的reasoning模型利用知识图中的时间不变的关系知识和Wikidata知识库中的时间不变关系知识来提高HTKG论理的性能。</li>
<li>results: 实验结果表明，提出的模型在HTKG链接预测 task上表现出色，并且可以通过共同利用时间不变和资格信息来进一步提高性能。<details>
<summary>Abstract</summary>
Stemming from traditional knowledge graphs (KGs), hyper-relational KGs (HKGs) provide additional key-value pairs (i.e., qualifiers) for each KG fact that help to better restrict the fact validity. In recent years, there has been an increasing interest in studying graph reasoning over HKGs. In the meantime, due to the ever-evolving nature of world knowledge, extensive parallel works have been focusing on reasoning over temporal KGs (TKGs), where each TKG fact can be viewed as a KG fact coupled with a timestamp (or time period) specifying its time validity. The existing HKG reasoning approaches do not consider temporal information because it is not explicitly specified in previous benchmark datasets. Besides, all the previous TKG reasoning methods only lay emphasis on temporal reasoning and have no way to learn from qualifiers. To this end, we aim to fill the gap between TKG reasoning and HKG reasoning. We develop two new benchmark hyper-relational TKG (HTKG) datasets, i.e., Wiki-hy and YAGO-hy, and propose a HTKG reasoning model that efficiently models both temporal facts and qualifiers. We further exploit additional time-invariant relational knowledge from the Wikidata knowledge base and study its effectiveness in HTKG reasoning. Time-invariant relational knowledge serves as the knowledge that remains unchanged in time (e.g., Sasha Obama is the child of Barack Obama), and it has never been fully explored in previous TKG reasoning benchmarks and approaches. Experimental results show that our model substantially outperforms previous related methods on HTKG link prediction and can be enhanced by jointly leveraging both temporal and time-invariant relational knowledge.
</details>
<details>
<summary>摘要</summary>
traditional知识 graphs（KGs）的扩展，hyper-relational知识 graphs（HKGs）提供每个KG事实的额外关键值对（i.e., 资格），以更好地限定事实的有效性。近年来，研究graph reasoning over HKGs的兴趣在增长。同时，由于世界知识的不断演进，大量并发的工作在研究temporal知识 graphs（TKGs）上进行reasoning，每个TKG事实可以视为KG事实加上时间戳（或时间段），指定其时间有效性。现有的HKGreasoning方法不考虑时间信息，因为之前的benchmark dataset不Explicitly specified。此外，所有前一些TKGreasoning方法只是强调时间reasoning，没有考虑学习资格。为此，我们希望填补HKGreasoning和TKGreasoning之间的空白。我们开发了两个新的benchmark hyper-relational TKG（HTKG）数据集，即Wiki-hy和YAGO-hy，并提出了一种HTKGreasoning模型，可以效率地模型时间事实和资格。此外，我们还利用Wikidata知识库中的静止关系知识，并研究其在HTKGreasoning中的效果。静止关系知识是指不变于时间的知识（例如，萨沙·奥巴马是巴拉克·奥巴马的孩子），在前一些TKGreasoningbenchmark和方法中从未得到过全面的探索。实验结果表明，我们的模型在HTKGlink prediction中具有明显的优势，并可以通过结合时间和静止关系知识来进一步提高性能。
</details></li>
</ul>
<hr>
<h2 id="Dissenting-Explanations-Leveraging-Disagreement-to-Reduce-Model-Overreliance"><a href="#Dissenting-Explanations-Leveraging-Disagreement-to-Reduce-Model-Overreliance" class="headerlink" title="Dissenting Explanations: Leveraging Disagreement to Reduce Model Overreliance"></a>Dissenting Explanations: Leveraging Disagreement to Reduce Model Overreliance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07636">http://arxiv.org/abs/2307.07636</a></li>
<li>repo_url: None</li>
<li>paper_authors: Omer Reingold, Judy Hanwen Shen, Aditi Talati</li>
<li>for: 该文章的目的是提出了一种新的解释方法，即“分裂解释”，以帮助人们从解释中获得更多的启示，而不仅仅是依靠模型的预测。</li>
<li>methods: 该文章提出了一种基于多模型的分裂解释方法，包括全局和本地的方法。这些方法可以在模型之间的不同预测时提供不同的解释，以便帮助人们更好地理解模型的决策过程。</li>
<li>results: 经过一个小样本研究，authors发现，通过提供分裂解释，可以减少人们对模型预测的过重依赖，同时不会降低总准确率。这表明，分裂解释可以帮助人们更好地理解模型的决策过程，并减少模型预测的不确定性。<details>
<summary>Abstract</summary>
While explainability is a desirable characteristic of increasingly complex black-box models, modern explanation methods have been shown to be inconsistent and contradictory. The semantics of explanations is not always fully understood - to what extent do explanations "explain" a decision and to what extent do they merely advocate for a decision? Can we help humans gain insights from explanations accompanying correct predictions and not over-rely on incorrect predictions advocated for by explanations? With this perspective in mind, we introduce the notion of dissenting explanations: conflicting predictions with accompanying explanations. We first explore the advantage of dissenting explanations in the setting of model multiplicity, where multiple models with similar performance may have different predictions. In such cases, providing dissenting explanations could be done by invoking the explanations of disagreeing models. Through a pilot study, we demonstrate that dissenting explanations reduce overreliance on model predictions, without reducing overall accuracy. Motivated by the utility of dissenting explanations we present both global and local methods for their generation.
</details>
<details>
<summary>摘要</summary>
“ explainnability 是复杂黑盒模型的一个欲具备的特点，但现代解释方法有时会被视为不一致和矛盾。解释的 semantics 不 sempre fully understood - 解释是否真的解释了一个决策，或者仅仅是支持一个决策？我们可以帮助人们从解释中获得启发，而不是仅仅依赖错误的预测和解释？以此角度，我们引入了不同的解释： conflicting predictions with accompanying explanations。在模型多样性的设定中，多个模型具有相似的表现可能会有不同的预测。在这种情况下，提供不同的解释可以通过邀请不同的模型的解释。我们通过一个小试验示出，提供不同的解释可以对抗预测的过度依赖，而不减少整体准确性。驱动了不同解释的 utility，我们提出了全球和本地的生成方法。”Note that Simplified Chinese is used in mainland China, while Traditional Chinese is used in Taiwan and Hong Kong.
</details></li>
</ul>
<hr>
<h2 id="Value-based-Fast-and-Slow-AI-Nudging"><a href="#Value-based-Fast-and-Slow-AI-Nudging" class="headerlink" title="Value-based Fast and Slow AI Nudging"></a>Value-based Fast and Slow AI Nudging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07628">http://arxiv.org/abs/2307.07628</a></li>
<li>repo_url: None</li>
<li>paper_authors: Marianna B. Ganapini, Francesco Fabiano, Lior Horesh, Andrea Loreggia, Nicholas Mattei, Keerthiram Murugesan, Vishal Pallagani, Francesca Rossi, Biplav Srivastava, Brent Venable<br>for: 这项研究旨在开发一个基于人工智能和人类协作的决策框架，该框架通过提供决策建议来引导人类做出决策。methods: 该研究使用了三种决策激励模式，这些模式根据决策建议是在什么时候提供给人类，以便激励人类快速思考、慢速思考或自reflective思考。results: 研究人员通过使用不同的价值来决定何时和如何使用各种决策激励模式，以实现更好的决策效果。例如，在做出决策时，可以考虑decision quality、speed、human upskilling和learning、human agency和隐私等价值。<details>
<summary>Abstract</summary>
Nudging is a behavioral strategy aimed at influencing people's thoughts and actions. Nudging techniques can be found in many situations in our daily lives, and these nudging techniques can targeted at human fast and unconscious thinking, e.g., by using images to generate fear or the more careful and effortful slow thinking, e.g., by releasing information that makes us reflect on our choices. In this paper, we propose and discuss a value-based AI-human collaborative framework where AI systems nudge humans by proposing decision recommendations. Three different nudging modalities, based on when recommendations are presented to the human, are intended to stimulate human fast thinking, slow thinking, or meta-cognition. Values that are relevant to a specific decision scenario are used to decide when and how to use each of these nudging modalities. Examples of values are decision quality, speed, human upskilling and learning, human agency, and privacy. Several values can be present at the same time, and their priorities can vary over time. The framework treats values as parameters to be instantiated in a specific decision environment.
</details>
<details>
<summary>摘要</summary>
推动（nudging）是一种行为战略，旨在影响人们的思想和行为。推动技巧可以在我们日常生活中找到很多的应用，这些推动技巧可以 targets 人们的快速和不自觉的思维，例如使用图像引发恐惧或更加细致和努力的慢思考。在这篇论文中，我们提出了一种基于人工智能和人类合作的价值基于推动框架。这个框架中的三种推动模式，基于建议给人时的 WHEN 和 HOW，用于刺激人们的快速思维、慢思考或者元认知。在具体的决策场景中，根据相关的价值来决定使用哪种推动模式。例如，决策质量、快速响应、人类技能和学习、人类自主权和隐私等价值。在这个框架中，价值被视为实例化在特定决策环境中的参数。
</details></li>
</ul>
<hr>
<h2 id="Interactive-Spatiotemporal-Token-Attention-Network-for-Skeleton-based-General-Interactive-Action-Recognition"><a href="#Interactive-Spatiotemporal-Token-Attention-Network-for-Skeleton-based-General-Interactive-Action-Recognition" class="headerlink" title="Interactive Spatiotemporal Token Attention Network for Skeleton-based General Interactive Action Recognition"></a>Interactive Spatiotemporal Token Attention Network for Skeleton-based General Interactive Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07469">http://arxiv.org/abs/2307.07469</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/Necolizer/ISTA-Net">https://github.com/Necolizer/ISTA-Net</a></li>
<li>paper_authors: Yuhang Wen, Zixuan Tang, Yunsheng Pang, Beichen Ding, Mengyuan Liu</li>
<li>for: 本研究旨在提高人机交互行为识别的精度和效率，以便更好地实现人机合作。</li>
<li>methods: 本文提出了一种Interactive Spatiotemporal Token Attention Network（ISTA-Net），该网络同时模型了空间、时间和交互关系。具体来说，ISTA-Net使用了Tokenizer将Interactive Spatiotemporal Tokens（IST）分割成多个多样化实体的动作。通过扩展实体维度，IST提供了更好的交互表示。为了同时学习三个维度，ISTA-Net使用了多头自注意блоック和3D卷积来捕捉间Token的相关性。</li>
<li>results: EXTensive experiments on four datasets show that ISTA-Net outperforms state-of-the-art methods in recognizing interactive actions, demonstrating the effectiveness of the proposed approach.<details>
<summary>Abstract</summary>
Recognizing interactive action plays an important role in human-robot interaction and collaboration. Previous methods use late fusion and co-attention mechanism to capture interactive relations, which have limited learning capability or inefficiency to adapt to more interacting entities. With assumption that priors of each entity are already known, they also lack evaluations on a more general setting addressing the diversity of subjects. To address these problems, we propose an Interactive Spatiotemporal Token Attention Network (ISTA-Net), which simultaneously model spatial, temporal, and interactive relations. Specifically, our network contains a tokenizer to partition Interactive Spatiotemporal Tokens (ISTs), which is a unified way to represent motions of multiple diverse entities. By extending the entity dimension, ISTs provide better interactive representations. To jointly learn along three dimensions in ISTs, multi-head self-attention blocks integrated with 3D convolutions are designed to capture inter-token correlations. When modeling correlations, a strict entity ordering is usually irrelevant for recognizing interactive actions. To this end, Entity Rearrangement is proposed to eliminate the orderliness in ISTs for interchangeable entities. Extensive experiments on four datasets verify the effectiveness of ISTA-Net by outperforming state-of-the-art methods. Our code is publicly available at https://github.com/Necolizer/ISTA-Net
</details>
<details>
<summary>摘要</summary>
Recognizing interactive action plays an important role in human-robot interaction and collaboration. Previous methods use late fusion and co-attention mechanism to capture interactive relations, which have limited learning capability or inefficiency to adapt to more interacting entities. With assumption that priors of each entity are already known, they also lack evaluations on a more general setting addressing the diversity of subjects. To address these problems, we propose an Interactive Spatiotemporal Token Attention Network (ISTA-Net), which simultaneously models spatial, temporal, and interactive relations. Specifically, our network contains a tokenizer to partition Interactive Spatiotemporal Tokens (ISTs), which is a unified way to represent motions of multiple diverse entities. By extending the entity dimension, ISTs provide better interactive representations. To jointly learn along three dimensions in ISTs, multi-head self-attention blocks integrated with 3D convolutions are designed to capture inter-token correlations. When modeling correlations, a strict entity ordering is usually irrelevant for recognizing interactive actions. To this end, Entity Rearrangement is proposed to eliminate the orderliness in ISTs for interchangeable entities. Extensive experiments on four datasets verify the effectiveness of ISTA-Net by outperforming state-of-the-art methods. Our code is publicly available at https://github.com/Necolizer/ISTA-Net.Here's the text with some notes on the translation:* "Recognizing interactive action" is translated as "认识人机交互行为" (règng shí yǔ jì xìng zhì xíng)* "Interactive Spatiotemporal Token Attention Network" is translated as "交互空时token注意网络" (jiāo xì kōng shí zhōng zhì wǎng wǎn)* "Interactive Spatiotemporal Tokens" is translated as "交互空时token" (jiāo xì kōng shí zhōng zhì)* "Entity Rearrangement" is translated as "实体重新排序" (shí tǐ zhòng xīn pinyīn)Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Structured-Pruning-of-Neural-Networks-for-Constraints-Learning"><a href="#Structured-Pruning-of-Neural-Networks-for-Constraints-Learning" class="headerlink" title="Structured Pruning of Neural Networks for Constraints Learning"></a>Structured Pruning of Neural Networks for Constraints Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07457">http://arxiv.org/abs/2307.07457</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matteo Cacciola, Antonio Frangioni, Andrea Lodi<br>for: 这篇论文主要关注在机器学习（ML）模型与运筐学（OR）工具的集成方面，具体来说是使用混合整数编程（MIP）表述ML模型输出的问题。methods: 本论文使用了束缚（pruning）技术来缩减人工神经网络（ANNs）中的参数数量，从而提高MIP表述的效率。results:  experiments 表明，使用束缚技术可以在ML模型的解决过程中提供显著的加速，而无需妥协解决质量。<details>
<summary>Abstract</summary>
In recent years, the integration of Machine Learning (ML) models with Operation Research (OR) tools has gained popularity across diverse applications, including cancer treatment, algorithmic configuration, and chemical process optimization. In this domain, the combination of ML and OR often relies on representing the ML model output using Mixed Integer Programming (MIP) formulations. Numerous studies in the literature have developed such formulations for many ML predictors, with a particular emphasis on Artificial Neural Networks (ANNs) due to their significant interest in many applications. However, ANNs frequently contain a large number of parameters, resulting in MIP formulations that are impractical to solve, thereby impeding scalability. In fact, the ML community has already introduced several techniques to reduce the parameter count of ANNs without compromising their performance, since the substantial size of modern ANNs presents challenges for ML applications as it significantly impacts computational efforts during training and necessitates significant memory resources for storage. In this paper, we showcase the effectiveness of pruning, one of these techniques, when applied to ANNs prior to their integration into MIPs. By pruning the ANN, we achieve significant improvements in the speed of the solution process. We discuss why pruning is more suitable in this context compared to other ML compression techniques, and we identify the most appropriate pruning strategies. To highlight the potential of this approach, we conduct experiments using feed-forward neural networks with multiple layers to construct adversarial examples. Our results demonstrate that pruning offers remarkable reductions in solution times without hindering the quality of the final decision, enabling the resolution of previously unsolvable instances.
</details>
<details>
<summary>摘要</summary>
近年来，机器学习（ML）模型与运筐学（OR）工具的集成在多种应用中得到了广泛的推广，包括肿瘤治疗、算法配置和化学过程优化。在这个领域，ML和OR的结合常常通过表示ML模型输出的混合整数编程（MIP）形式来实现。文献中有许多研究发展了这种形式，尤其是人工神经网络（ANNs），因为它们在许多应用中具有广泛的 интерес。然而，ANNs经常具有较大的参数数量，导致MIP形式成为实际不可解决的，从而阻碍了扩展性。事实上，ML社区已经开发了许多技术来减少ANNs中参数的数量，以避免降低性能。在这篇论文中，我们展示了对ANNs进行剪裁后，在MIP中的速度解决过程中的显著改善。我们解释了为什么剪裁在这种上下文中比其他ML压缩技术更适合，并确定了最佳剪裁策略。为了强调这种方法的潜力，我们在多层扩散神经网络中构建了反对例。我们的结果表明，剪裁可以在解决之前不可解决的实例中提供了很大的改善，而不会影响最终决策的质量。
</details></li>
</ul>
<hr>
<h2 id="Can-Large-Language-Models-Empower-Molecular-Property-Prediction"><a href="#Can-Large-Language-Models-Empower-Molecular-Property-Prediction" class="headerlink" title="Can Large Language Models Empower Molecular Property Prediction?"></a>Can Large Language Models Empower Molecular Property Prediction?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07443">http://arxiv.org/abs/2307.07443</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chnq/llm4mol">https://github.com/chnq/llm4mol</a></li>
<li>paper_authors: Chen Qian, Huayi Tang, Zhirui Yang, Hong Liang, Yong Liu</li>
<li>for: 这篇论文旨在探讨大语言模型（LLM）在分子性质预测中的应用。</li>
<li>methods: 作者采用了两个视角：零&#x2F;几 shot分子分类和使用 LL.M 生成的新解释作为分子表示。</li>
<li>results: 实验结果表明，文本解释作为分子表示在多个 benchmark 数据集上具有优势，并证明 LL.M 在分子性质预测任务中具有潜在的潜力。<details>
<summary>Abstract</summary>
Molecular property prediction has gained significant attention due to its transformative potential in multiple scientific disciplines. Conventionally, a molecule graph can be represented either as a graph-structured data or a SMILES text. Recently, the rapid development of Large Language Models (LLMs) has revolutionized the field of NLP. Although it is natural to utilize LLMs to assist in understanding molecules represented by SMILES, the exploration of how LLMs will impact molecular property prediction is still in its early stage. In this work, we advance towards this objective through two perspectives: zero/few-shot molecular classification, and using the new explanations generated by LLMs as representations of molecules. To be specific, we first prompt LLMs to do in-context molecular classification and evaluate their performance. After that, we employ LLMs to generate semantically enriched explanations for the original SMILES and then leverage that to fine-tune a small-scale LM model for multiple downstream tasks. The experimental results highlight the superiority of text explanations as molecular representations across multiple benchmark datasets, and confirm the immense potential of LLMs in molecular property prediction tasks. Codes are available at \url{https://github.com/ChnQ/LLM4Mol}.
</details>
<details>
<summary>摘要</summary>
摩尔电子性预测已经受到了广泛关注，因为它在多种科学领域的变革性很大。传统上，摩尔图可以被表示为图structured data或SMILES文本。在最近的几年中，大型自然语言模型（LLMs）的快速发展对涉及到NLP领域的研究带来了革命性的变革。虽然可以使用LLMs来帮助理解表示by SMILES的分子，但是研究如何使用LLMs进行分子性预测的阶段仍处于初期阶段。在这项工作中，我们通过两个视角进行推进：零/几个shot分子分类，和使用LLMs生成的新的解释来代表分子。具体来说，我们首先让LLMs在上下文中进行分子分类，并评估其性能。然后，我们使用LLMs生成Semantically enriched explanations for the original SMILES，并使用该解释来精化一个小规模LM模型以进行多个下游任务。实验结果表明，文本解释作为分子表示的 superiority across multiple benchmark datasets，并证明了LLMs在分子性预测任务中的巨大潜力。代码可以在 \url{https://github.com/ChnQ/LLM4Mol} 上获取。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/15/cs.AI_2023_07_15/" data-id="clly4xtbe000tvl881dg4emuy" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.CV_2023_07_15" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/15/cs.CV_2023_07_15/" class="article-date">
  <time datetime="2023-07-14T16:00:00.000Z" itemprop="datePublished">2023-07-15</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-CV/">cs.CV</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/15/cs.CV_2023_07_15/">cs.CV - 2023-07-15 21:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="HQG-Net-Unpaired-Medical-Image-Enhancement-with-High-Quality-Guidance"><a href="#HQG-Net-Unpaired-Medical-Image-Enhancement-with-High-Quality-Guidance" class="headerlink" title="HQG-Net: Unpaired Medical Image Enhancement with High-Quality Guidance"></a>HQG-Net: Unpaired Medical Image Enhancement with High-Quality Guidance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07829">http://arxiv.org/abs/2307.07829</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chunming He, Kai Li, Guoxia Xu, Jiangpeng Yan, Longxiang Tang, Yulun Zhang, Xiu Li, Yaowei Wang</li>
<li>for: 提高医疗影像质量（UMIE），使低质量医疗影像变成高质量医疗影像，不需要使用对应的高质量影像进行训练。</li>
<li>methods: 提出了一种新的UMIE方法，利用变量ormalization模块直接在低质量影像增强过程中编码高质量灵感，并通过对抗学习和内容响应损失来导航增强过程。</li>
<li>results: 对三个医疗影像 dataset进行了实验，并证明了该方法可以在增强质量和下游任务性能之间取得平衡，并且在许多情况下超越了现有的方法。<details>
<summary>Abstract</summary>
Unpaired Medical Image Enhancement (UMIE) aims to transform a low-quality (LQ) medical image into a high-quality (HQ) one without relying on paired images for training. While most existing approaches are based on Pix2Pix/CycleGAN and are effective to some extent, they fail to explicitly use HQ information to guide the enhancement process, which can lead to undesired artifacts and structural distortions. In this paper, we propose a novel UMIE approach that avoids the above limitation of existing methods by directly encoding HQ cues into the LQ enhancement process in a variational fashion and thus model the UMIE task under the joint distribution between the LQ and HQ domains. Specifically, we extract features from an HQ image and explicitly insert the features, which are expected to encode HQ cues, into the enhancement network to guide the LQ enhancement with the variational normalization module. We train the enhancement network adversarially with a discriminator to ensure the generated HQ image falls into the HQ domain. We further propose a content-aware loss to guide the enhancement process with wavelet-based pixel-level and multi-encoder-based feature-level constraints. Additionally, as a key motivation for performing image enhancement is to make the enhanced images serve better for downstream tasks, we propose a bi-level learning scheme to optimize the UMIE task and downstream tasks cooperatively, helping generate HQ images both visually appealing and favorable for downstream tasks. Experiments on three medical datasets, including two newly collected datasets, verify that the proposed method outperforms existing techniques in terms of both enhancement quality and downstream task performance. We will make the code and the newly collected datasets publicly available for community study.
</details>
<details>
<summary>摘要</summary>
<<SYS>>医学图像提高（UMIE）的目标是将低质量（LQ）医学图像转换成高质量（HQ）图像，不需要使用对应的图像进行训练。现有的方法多数基于Pix2Pix/CycleGAN，尽管有一定的效果，但是它们不会直接使用HQ信息来导引提高过程，这可能会导致不必要的artefacts和结构性错误。在这篇论文中，我们提出了一种新的UMIE方法，避免了现有方法的这一限制，通过直接在LQ提高过程中编码HQ信息，并在变量化正则模块中进行变量化正则化。具体来说，我们从HQ图像中提取特征，并直接插入提高网络中，以便使LQ图像提高以HQ图像的特征为导引。我们通过对提高网络进行对抗训练，使得生成的HQ图像在HQ领域中。我们还提出了一种内容相关损失，以便通过波лет特-基于的像素级和多编码器-基于的特征级约束，指导提高过程。此外，作为提高图像的主要动机是为了使图像更好地服务于下游任务，我们提出了一种叠加学习方案，以便在UMIE任务和下游任务之间协同优化，使得生成的HQ图像同时具备视觉吸引力和下游任务的有利性。实验结果表明，提出的方法在三个医学 dataset 上表现出色，超过了现有技术。我们将代码和新收集的 dataset 公开发布，为社区的研究提供便利。
</details></li>
</ul>
<hr>
<h2 id="TinyTracker-Ultra-Fast-and-Ultra-Low-Power-Edge-Vision-In-Sensor-for-Gaze-Estimation"><a href="#TinyTracker-Ultra-Fast-and-Ultra-Low-Power-Edge-Vision-In-Sensor-for-Gaze-Estimation" class="headerlink" title="TinyTracker: Ultra-Fast and Ultra-Low-Power Edge Vision In-Sensor for Gaze Estimation"></a>TinyTracker: Ultra-Fast and Ultra-Low-Power Edge Vision In-Sensor for Gaze Estimation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07813">http://arxiv.org/abs/2307.07813</a></li>
<li>repo_url: None</li>
<li>paper_authors: Pietro Bonazzi, Thomas Ruegg, Sizhen Bian, Yawei Li, Michele Magno</li>
<li>for: 这个论文的目的是提出一种高效低功耗的边缘视觉应用，以解决边缘设备的计算负担问题。</li>
<li>methods: 该论文使用了一种新的“AI在传感器”视觉平台，SONY的IMX500，实现了ultra-fast和ultra-low-power的边缘视觉应用。</li>
<li>results: 研究表明，IMX500比Google Coral Dev Micro和SONY Spresense更快（19ms vs 34.4ms）和更高效（4.9mJ VS 34.2mJ），并且可以实现2D gaze estimation的高精度预测（最大差错0.16cm）。<details>
<summary>Abstract</summary>
Intelligent edge vision tasks encounter the critical challenge of ensuring power and latency efficiency due to the typically heavy computational load they impose on edge platforms.This work leverages one of the first "AI in sensor" vision platforms, IMX500 by Sony, to achieve ultra-fast and ultra-low-power end-to-end edge vision applications. We evaluate the IMX500 and compare it to other edge platforms, such as the Google Coral Dev Micro and Sony Spresense, by exploring gaze estimation as a case study. We propose TinyTracker, a highly efficient, fully quantized model for 2D gaze estimation designed to maximize the performance of the edge vision systems considered in this study. TinyTracker achieves a 41x size reduction (600Kb) compared to iTracker [1] without significant loss in gaze estimation accuracy (maximum of 0.16 cm when fully quantized). TinyTracker's deployment on the Sony IMX500 vision sensor results in end-to-end latency of around 19ms. The camera takes around 17.9ms to read, process and transmit the pixels to the accelerator. The inference time of the network is 0.86ms with an additional 0.24 ms for retrieving the results from the sensor. The overall energy consumption of the end-to-end system is 4.9 mJ, including 0.06 mJ for inference. The end-to-end study shows that IMX500 is 1.7x faster than CoralMicro (19ms vs 34.4ms) and 7x more power efficient (4.9mJ VS 34.2mJ)
</details>
<details>
<summary>摘要</summary>
智能边缘视觉任务面临 crítical 挑战，因为它们通常占用边缘平台的重要计算负担。这项工作利用了首个“AI在传感器”视觉平台IMX500（由索尼制造），实现ultra-fast和ultra-low-power的边缘视觉应用。我们对IMX500进行了比较，并使用了其他边缘平台，如Google Coral Dev Micro和索尼Spresense，通过察看计算作为研究案例。我们提出了TinyTracker，一种高效、全数字化模型，用于实现2D gaze estimation。TinyTracker在IMX500视觉传感器上部署后，实现了约19ms的终端延迟时间。摄像头需要17.9ms来读取、处理和传输像素到加速器。网络执行时间为0.86ms，加上从传感器中获取结果的时间（0.24ms）。总的来说，边缘系统的能 consumption 为4.9 mJ，其中计算部分占用0.06 mJ。对照研究显示，IMX500比CoralMicro（19ms VS 34.4ms）更快，并且在能 efficiency 方面更高（4.9mJ VS 34.2mJ）。
</details></li>
</ul>
<hr>
<h2 id="Multiscale-Memory-Comparator-Transformer-for-Few-Shot-Video-Segmentation"><a href="#Multiscale-Memory-Comparator-Transformer-for-Few-Shot-Video-Segmentation" class="headerlink" title="Multiscale Memory Comparator Transformer for Few-Shot Video Segmentation"></a>Multiscale Memory Comparator Transformer for Few-Shot Video Segmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07812">http://arxiv.org/abs/2307.07812</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/msiam/mmc-multiscalememory">https://github.com/msiam/mmc-multiscalememory</a></li>
<li>paper_authors: Mennatullah Siam, Rezaul Karim, He Zhao, Richard Wildes</li>
<li>for: 这篇论文主要针对几个支持图像中的特定新类，使用少量标注图像进行分类。</li>
<li>methods: 该方法使用一种名为多尺度记忆比较器（MMC），它将信息在不同尺度级别内共享，以增强分类精度。</li>
<li>results: 该方法在几个实验中均超过了基eline，并达到了状态之arte。代码可以在<a target="_blank" rel="noopener" href="https://github.com/MSiam/MMC-MultiscaleMemory%E4%B8%AD%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/MSiam/MMC-MultiscaleMemory中下载。</a><details>
<summary>Abstract</summary>
Few-shot video segmentation is the task of delineating a specific novel class in a query video using few labelled support images. Typical approaches compare support and query features while limiting comparisons to a single feature layer and thereby ignore potentially valuable information. We present a meta-learned Multiscale Memory Comparator (MMC) for few-shot video segmentation that combines information across scales within a transformer decoder. Typical multiscale transformer decoders for segmentation tasks learn a compressed representation, their queries, through information exchange across scales. Unlike previous work, we instead preserve the detailed feature maps during across scale information exchange via a multiscale memory transformer decoding to reduce confusion between the background and novel class. Integral to the approach, we investigate multiple forms of information exchange across scales in different tasks and provide insights with empirical evidence on which to use in each task. The overall comparisons among query and support features benefit from both rich semantics and precise localization. We demonstrate our approach primarily on few-shot video object segmentation and an adapted version on the fully supervised counterpart. In all cases, our approach outperforms the baseline and yields state-of-the-art performance. Our code is publicly available at https://github.com/MSiam/MMC-MultiscaleMemory.
</details>
<details>
<summary>摘要</summary>
几个批量视频分割是指将特定的新类型在查询视频中分割使用几个标注图像。通常的方法是比较支持和查询特征，并限制比较到单个特征层，因此可能会忽略有价值信息。我们提出了基于模型学习的多尺度内存比较器（MMC），用于几个批量视频分割，它将在变换器解码器中结合多尺度信息。通常的多尺度变换器解码器用于分割任务会学习压缩表示，其查询通过不同尺度之间的信息交换来学习压缩表示。与之前的工作不同，我们在交换过程中保留细节特征图，以避免背景和新类型之间的混淆。我们的方法包括多种不同任务中的信息交换方式，并提供了实验证据，以帮助选择合适的信息交换方式。通过比较查询和支持特征，我们的方法可以获得丰富的 semantics 和精确的地方化。我们在几个几个批量视频对象分割和修改后的完全监督版本中展示了我们的方法，在所有情况下，我们的方法都超越基准，并实现了状态的最佳性。我们的代码可以在 GitHub 上获取：https://github.com/MSiam/MMC-MultiscaleMemory。
</details></li>
</ul>
<hr>
<h2 id="MUVF-YOLOX-A-Multi-modal-Ultrasound-Video-Fusion-Network-for-Renal-Tumor-Diagnosis"><a href="#MUVF-YOLOX-A-Multi-modal-Ultrasound-Video-Fusion-Network-for-Renal-Tumor-Diagnosis" class="headerlink" title="MUVF-YOLOX: A Multi-modal Ultrasound Video Fusion Network for Renal Tumor Diagnosis"></a>MUVF-YOLOX: A Multi-modal Ultrasound Video Fusion Network for Renal Tumor Diagnosis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07807">http://arxiv.org/abs/2307.07807</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jeunyuli/muaf">https://github.com/jeunyuli/muaf</a></li>
<li>paper_authors: Junyu Li, Han Huang, Dong Ni, Wufeng Xue, Dongmei Zhu, Jun Cheng</li>
<li>for: 这个研究的目的是为了早期识别肾脏癌，以提高病人存活率。</li>
<li>methods: 这个研究使用了融合B模式和CEUS模式射频影像的多modal聚合网络，以实现多modal特征融合和影像分类。</li>
<li>results: 实验结果显示，提案的框架比单模式模型和竞争方法更高的准确性。此外，我们的OTA模组在多帧射频影像中实现了更高的分类精度。<details>
<summary>Abstract</summary>
Early diagnosis of renal cancer can greatly improve the survival rate of patients. Contrast-enhanced ultrasound (CEUS) is a cost-effective and non-invasive imaging technique and has become more and more frequently used for renal tumor diagnosis. However, the classification of benign and malignant renal tumors can still be very challenging due to the highly heterogeneous appearance of cancer and imaging artifacts. Our aim is to detect and classify renal tumors by integrating B-mode and CEUS-mode ultrasound videos. To this end, we propose a novel multi-modal ultrasound video fusion network that can effectively perform multi-modal feature fusion and video classification for renal tumor diagnosis. The attention-based multi-modal fusion module uses cross-attention and self-attention to extract modality-invariant features and modality-specific features in parallel. In addition, we design an object-level temporal aggregation (OTA) module that can automatically filter low-quality features and efficiently integrate temporal information from multiple frames to improve the accuracy of tumor diagnosis. Experimental results on a multicenter dataset show that the proposed framework outperforms the single-modal models and the competing methods. Furthermore, our OTA module achieves higher classification accuracy than the frame-level predictions. Our code is available at \url{https://github.com/JeunyuLi/MUAF}.
</details>
<details>
<summary>摘要</summary>
早期诊断肾癌可以大幅提高患者存活率。扩增噪声超声（CEUS）是一种Cost-effective和非侵入性的成像技术，在肾肿瘤诊断中越来越常用。然而，肾肿瘤的分类仍然是非常困难的，主要是因为肿瘤的外观非常异常，以及成像 artifacts。我们的目标是通过融合B模式和CEUS模式超声视频来检测和分类肾肿瘤。为此，我们提出了一种新的多模态超声视频融合网络，可以有效地执行多模态特征融合和视频分类。我们的注意力基于多模态融合模块使用交叉注意力和自注意力来提取模式不变特征和模式特定特征。此外，我们设计了一个物体级别时间聚合（OTA）模块，可以自动筛选低质量特征并高效地集成多帧中的时间信息，以提高肾肿瘤诊断的准确性。实验结果表明，我们提出的框架在多中心数据集上表现出优于单模态模型和竞争方法。此外，我们的 OTA 模块在帧级预测中实现了更高的分类精度。我们的代码可以在 \url{https://github.com/JeunyuLi/MUAF} 上获取。
</details></li>
</ul>
<hr>
<h2 id="Joint-Adversarial-and-Collaborative-Learning-for-Self-Supervised-Action-Recognition"><a href="#Joint-Adversarial-and-Collaborative-Learning-for-Self-Supervised-Action-Recognition" class="headerlink" title="Joint Adversarial and Collaborative Learning for Self-Supervised Action Recognition"></a>Joint Adversarial and Collaborative Learning for Self-Supervised Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07791">http://arxiv.org/abs/2307.07791</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/levigty/acl">https://github.com/levigty/acl</a></li>
<li>paper_authors: Tianyu Guo, Mengyuan Liu, Hong Liu, Wenhao Li, Jingwen Guo, Tao Wang, Yidi Li</li>
<li>for: 本研究的目的是使用对比学习方法，包括MoCo和SimCLR，来解决自然语言处理中的自我supervised动作识别任务。</li>
<li>methods: 本研究使用多个数据流（joint、运动和骨）进行ensemble学习，同时如何在单个流中构建一个特异性的特征空间并有效地将多个流的信息汇聚到一起仍然是一个开放的问题。</li>
<li>results: 我们首先应用一种新的对比学习方法called BYOL来学习从骨架数据，并将其формализова为一个简单 yet effective的基线方法 для自我supervised骨架动作识别。此外，我们还提出了一种联合对抗学习（ACL）框架，其结合了cross-model对抗学习（CMAL）和cross-stream合作学习（CSCL）。<details>
<summary>Abstract</summary>
Considering the instance-level discriminative ability, contrastive learning methods, including MoCo and SimCLR, have been adapted from the original image representation learning task to solve the self-supervised skeleton-based action recognition task. These methods usually use multiple data streams (i.e., joint, motion, and bone) for ensemble learning, meanwhile, how to construct a discriminative feature space within a single stream and effectively aggregate the information from multiple streams remains an open problem. To this end, we first apply a new contrastive learning method called BYOL to learn from skeleton data and formulate SkeletonBYOL as a simple yet effective baseline for self-supervised skeleton-based action recognition. Inspired by SkeletonBYOL, we further present a joint Adversarial and Collaborative Learning (ACL) framework, which combines Cross-Model Adversarial Learning (CMAL) and Cross-Stream Collaborative Learning (CSCL). Specifically, CMAL learns single-stream representation by cross-model adversarial loss to obtain more discriminative features. To aggregate and interact with multi-stream information, CSCL is designed by generating similarity pseudo label of ensemble learning as supervision and guiding feature generation for individual streams. Exhaustive experiments on three datasets verify the complementary properties between CMAL and CSCL and also verify that our method can perform favorably against state-of-the-art methods using various evaluation protocols. Our code and models are publicly available at \url{https://github.com/Levigty/ACL}.
</details>
<details>
<summary>摘要</summary>
基于实例水平的异同能力，包括MoCo和SimCLR等对比学习方法，已经从原始图像表示学习任务中适应到解决自动识别动作任务。这些方法通常使用多个数据流（即联合、运动和骨）进行ensemble学习，而在单个流中构建准确的特征空间并有效地聚合多个流的信息仍然是一个开放的问题。为此，我们首先应用一种新的对比学习方法called BYOL来学习从骨架数据，并将SkeletonBYOL作为一个简单又有效的基线 для自主学习骨架动作识别。受SkeletonBYOL的启发，我们进一步提出了一种联合对抗学习（ACL）框架，该框架将对抗学习（CMAL）和流处理学习（CSCL）相结合。具体来说，CMAL通过跨模型对抗损失来获得更准确的特征，而CSCL通过生成流处理学习中的similarity pseudo标签来引导特征生成和流处理学习。我们对三个数据集进行了详细的实验，并证明了ACL的共轭性和对比学习方法的优势。我们的代码和模型在\url{https://github.com/Levigty/ACL}上公开。
</details></li>
</ul>
<hr>
<h2 id="Adaptive-Nonlinear-Latent-Transformation-for-Conditional-Face-Editing"><a href="#Adaptive-Nonlinear-Latent-Transformation-for-Conditional-Face-Editing" class="headerlink" title="Adaptive Nonlinear Latent Transformation for Conditional Face Editing"></a>Adaptive Nonlinear Latent Transformation for Conditional Face Editing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07790">http://arxiv.org/abs/2307.07790</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hzzone/adatrans">https://github.com/hzzone/adatrans</a></li>
<li>paper_authors: Zhizhong Huang, Siteng Ma, Junping Zhang, Hongming Shan</li>
<li>for: 本文提出了一种新的适应非线性潜在转换方法（AdaTrans），用于不混合的条件脸部编辑。</li>
<li>methods: 本方法将编辑过程分解为多个细节步骤，每个步骤的方向和大小受到面部特征和潜在码的控制。这种非线性转换路径可以操作面部到目标特征Attributes，保持其他特征不变。此外，本文还提出了一种独立学习策略，基于mutual information框架，以消除特征之间的混合。</li>
<li>results: 对于多种面部特征，AdaTrans能够实现可控的脸部编辑，具有分离、灵活性和高质量的优点。与现有方法相比，AdaTrans在面部特征之间的混合、年龄差距和少量标注数据下表现出较好的性能。代码可以从<a target="_blank" rel="noopener" href="https://github.com/Hzzone/AdaTrans%E8%8E%B7%E5%8F%96%E3%80%82">https://github.com/Hzzone/AdaTrans获取。</a><details>
<summary>Abstract</summary>
Recent works for face editing usually manipulate the latent space of StyleGAN via the linear semantic directions. However, they usually suffer from the entanglement of facial attributes, need to tune the optimal editing strength, and are limited to binary attributes with strong supervision signals. This paper proposes a novel adaptive nonlinear latent transformation for disentangled and conditional face editing, termed AdaTrans. Specifically, our AdaTrans divides the manipulation process into several finer steps; i.e., the direction and size at each step are conditioned on both the facial attributes and the latent codes. In this way, AdaTrans describes an adaptive nonlinear transformation trajectory to manipulate the faces into target attributes while keeping other attributes unchanged. Then, AdaTrans leverages a predefined density model to constrain the learned trajectory in the distribution of latent codes by maximizing the likelihood of transformed latent code. Moreover, we also propose a disentangled learning strategy under a mutual information framework to eliminate the entanglement among attributes, which can further relax the need for labeled data. Consequently, AdaTrans enables a controllable face editing with the advantages of disentanglement, flexibility with non-binary attributes, and high fidelity. Extensive experimental results on various facial attributes demonstrate the qualitative and quantitative effectiveness of the proposed AdaTrans over existing state-of-the-art methods, especially in the most challenging scenarios with a large age gap and few labeled examples. The source code is available at https://github.com/Hzzone/AdaTrans.
</details>
<details>
<summary>摘要</summary>
最近的面部编辑方法通常通过 StyleGAN 的归一化空间进行 manipulate。然而，这些方法通常受到面部特征的杂化的限制，需要调整最佳编辑强度，并且只能处理二分类特征。这篇论文提出了一种新的适应非线性层次变换方法，称为 AdaTrans。具体来说，我们的 AdaTrans 将掌控过程分解成多个更细的步骤，即在每个步骤中的方向和大小受到面部特征和归一化码的Conditioning。这样，AdaTrans 可以描述一个适应非线性变换轨迹，以控制面部变换为目标特征，保持其他特征不变。然后，AdaTrans 利用一个预定义的概率模型来约束学习的轨迹在归一化码的分布中，通过最大化变换后的归一化码的概率来提升。此外，我们还提出了一种不依赖标注数据的分解学习策略，基于mutual information框架，以消除特征之间的杂化，从而更好地适应具有不同特征的面部编辑。因此，AdaTrans 可以提供可控的面部编辑，具有分解、非二分类特征和高精度的优势。我们的实验结果表明，AdaTrans 在不同的面部特征下表现出较好的效果，特别是在面部年龄差较大和标注数据少的情况下。代码可以在 <https://github.com/Hzzone/AdaTrans> 上获取。
</details></li>
</ul>
<hr>
<h2 id="SoccerKDNet-A-Knowledge-Distillation-Framework-for-Action-Recognition-in-Soccer-Videos"><a href="#SoccerKDNet-A-Knowledge-Distillation-Framework-for-Action-Recognition-in-Soccer-Videos" class="headerlink" title="SoccerKDNet: A Knowledge Distillation Framework for Action Recognition in Soccer Videos"></a>SoccerKDNet: A Knowledge Distillation Framework for Action Recognition in Soccer Videos</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07768">http://arxiv.org/abs/2307.07768</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sarosij Bose, Saikat Sarkar, Amlan Chakrabarti</li>
<li>For: The paper is written for classifying player actions in soccer videos, which is a challenging problem in sports analytics.* Methods: The paper proposes a novel end-to-end knowledge distillation based transfer learning network pre-trained on the Kinetics400 dataset, and introduces a unique loss parameterization.* Results: The paper obtains 67.20% validation accuracy on a new dataset named SoccerDB1, which consists of 448 videos and 4 diverse classes of players playing soccer. The model also generalizes well to new datasets.Here is the same information in Simplified Chinese text:* For: 这篇论文是为了解决足球视频中玩家行为的分类问题，这是体育分析中的一个挑战。* Methods: 论文提出了一种新的端到端知识储备基于转移学习网络，并引入了一个唯一的损失参数化。* Results: 论文在新的足球DB1数据集上获得了67.20%的验证精度，该数据集包括448个视频和4种多样化的玩家类别。模型也能够轻松地适应新的数据集。<details>
<summary>Abstract</summary>
Classifying player actions from soccer videos is a challenging problem, which has become increasingly important in sports analytics over the years. Most state-of-the-art methods employ highly complex offline networks, which makes it difficult to deploy such models in resource constrained scenarios. Here, in this paper we propose a novel end-to-end knowledge distillation based transfer learning network pre-trained on the Kinetics400 dataset and then perform extensive analysis on the learned framework by introducing a unique loss parameterization. We also introduce a new dataset named SoccerDB1 containing 448 videos and consisting of 4 diverse classes each of players playing soccer. Furthermore, we introduce an unique loss parameter that help us linearly weigh the extent to which the predictions of each network are utilized. Finally, we also perform a thorough performance study using various changed hyperparameters. We also benchmark the first classification results on the new SoccerDB1 dataset obtaining 67.20% validation accuracy. Apart from outperforming prior arts significantly, our model also generalizes to new datasets easily. The dataset has been made publicly available at: https://bit.ly/soccerdb1
</details>
<details>
<summary>摘要</summary>
“足球视频中玩家行为分类是一个复杂的问题，在体育分析领域已经越来越重要。大多数当前最佳方法使用高度复杂的离线网络，这使得在资源受限的情况下难以部署这些模型。在这篇论文中，我们提出了一种新的终端到终端知识储备基于转移学习网络，并进行了广泛的分析。我们还介绍了一个新的损失参数化方法，以及一个名为足球DB1的新数据集，该数据集包含448个视频和4种多样化的玩家在足球比赛中的行为。此外，我们还引入了一个唯一的损失参数，以便将每个网络的预测值 linearly 权重。最后，我们还进行了详细的性能研究，并对不同的变量参数进行了测试。我们的模型在新的足球DB1数据集上获得了67.20%的验证精度，并且能够轻松地在新的数据集上进行扩展。数据集可以在以下链接获取：https://bit.ly/soccerdb1。”
</details></li>
</ul>
<hr>
<h2 id="Tightly-Coupled-LiDAR-Visual-SLAM-Based-on-Geometric-Features-for-Mobile-Agents"><a href="#Tightly-Coupled-LiDAR-Visual-SLAM-Based-on-Geometric-Features-for-Mobile-Agents" class="headerlink" title="Tightly-Coupled LiDAR-Visual SLAM Based on Geometric Features for Mobile Agents"></a>Tightly-Coupled LiDAR-Visual SLAM Based on Geometric Features for Mobile Agents</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07763">http://arxiv.org/abs/2307.07763</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ke Cao, Ruiping Liu, Ze Wang, Kunyu Peng, Jiaming Zhang, Junwei Zheng, Zhifeng Teng, Kailun Yang, Rainer Stiefelhagen</li>
<li>for: 提供自动化导航和任务执行在复杂和未知环境中，以便移动机器人可以更好地操作。</li>
<li>methods: 利用LiDAR-视觉Simultaneous Localization and Mapping（SLAM）技术，包括两个子系统（LiDAR和单目视觉SLAM）和一个融合框架。融合框架将深度和 semantic的多Modal 几何特征相关，以便补充视觉线尺标和添加方向优化。</li>
<li>results: 在M2DGR公共数据集上进行评估，与当前状态的多模式方法相比，我们的系统实现了更高精度和更加稳定的姿态估计。<details>
<summary>Abstract</summary>
The mobile robot relies on SLAM (Simultaneous Localization and Mapping) to provide autonomous navigation and task execution in complex and unknown environments. However, it is hard to develop a dedicated algorithm for mobile robots due to dynamic and challenging situations, such as poor lighting conditions and motion blur. To tackle this issue, we propose a tightly-coupled LiDAR-visual SLAM based on geometric features, which includes two sub-systems (LiDAR and monocular visual SLAM) and a fusion framework. The fusion framework associates the depth and semantics of the multi-modal geometric features to complement the visual line landmarks and to add direction optimization in Bundle Adjustment (BA). This further constrains visual odometry. On the other hand, the entire line segment detected by the visual subsystem overcomes the limitation of the LiDAR subsystem, which can only perform the local calculation for geometric features. It adjusts the direction of linear feature points and filters out outliers, leading to a higher accurate odometry system. Finally, we employ a module to detect the subsystem's operation, providing the LiDAR subsystem's output as a complementary trajectory to our system while visual subsystem tracking fails. The evaluation results on the public dataset M2DGR, gathered from ground robots across various indoor and outdoor scenarios, show that our system achieves more accurate and robust pose estimation compared to current state-of-the-art multi-modal methods.
</details>
<details>
<summary>摘要</summary>
Mobile robot 依靠 SLAM (同时地理定位和地图生成) 实现自主导航和任务执行在复杂和未知环境中。但是开发专门的移动 robot 算法具有困难的动态和挑战性情况，如低光照条件和运动模糊。为解决这个问题，我们提议一种紧密相关的 LiDAR-视觉 SLAM，其包括两个子系统（LiDAR 和单目视觉 SLAM）以及一个融合框架。融合框架将depth 和视觉特征相关，以补偿视线标记的缺失，并在Bundle Adjustment 中添加方向优化。这使得视觉遥感更加精准。另一方面，视觉子系统检测到的整条线段超越了 LiDAR 子系统的局部计算能力，可以调整方向和过滤异常值，从而实现更高精度的遥感系统。最后，我们采用一个模块来检测子系统的运作，提供 LiDAR 子系统的补偿轨迹，而视觉子系统跟踪失败时。根据公共数据集 M2DGR，从各种室内和室外场景中收集的数据，我们的系统实现了与当前状态艺术多模式方法相比更高精度和更加稳定的姿态估计。
</details></li>
</ul>
<hr>
<h2 id="Open-Scene-Understanding-Grounded-Situation-Recognition-Meets-Segment-Anything-for-Helping-People-with-Visual-Impairments"><a href="#Open-Scene-Understanding-Grounded-Situation-Recognition-Meets-Segment-Anything-for-Helping-People-with-Visual-Impairments" class="headerlink" title="Open Scene Understanding: Grounded Situation Recognition Meets Segment Anything for Helping People with Visual Impairments"></a>Open Scene Understanding: Grounded Situation Recognition Meets Segment Anything for Helping People with Visual Impairments</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07757">http://arxiv.org/abs/2307.07757</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ruipingl/opensu">https://github.com/ruipingl/opensu</a></li>
<li>paper_authors: Ruiping Liu, Jiaming Zhang, Kunyu Peng, Junwei Zheng, Ke Cao, Yufan Chen, Kailun Yang, Rainer Stiefelhagen</li>
<li>for: 帮助人们 WITH 视觉障碍（PVI）更加独立地移动，通过增强场景理解和提供有用信息。</li>
<li>methods: 基于 Grounded Situation Recognition（GSR）技术，采用高效的 Segment Anything Model（SAM）和固定纯transformer背景结构，并将所有激活函数换为GELU，以提高GSR性能。</li>
<li>results: 在 SWiG 数据集上达到了领先的表现，并通过在辅助技术数据集和应用示例中的场景测试和应用示例，证明了 OpenSU 系统的可行性和有用性。<details>
<summary>Abstract</summary>
Grounded Situation Recognition (GSR) is capable of recognizing and interpreting visual scenes in a contextually intuitive way, yielding salient activities (verbs) and the involved entities (roles) depicted in images. In this work, we focus on the application of GSR in assisting people with visual impairments (PVI). However, precise localization information of detected objects is often required to navigate their surroundings confidently and make informed decisions. For the first time, we propose an Open Scene Understanding (OpenSU) system that aims to generate pixel-wise dense segmentation masks of involved entities instead of bounding boxes. Specifically, we build our OpenSU system on top of GSR by additionally adopting an efficient Segment Anything Model (SAM). Furthermore, to enhance the feature extraction and interaction between the encoder-decoder structure, we construct our OpenSU system using a solid pure transformer backbone to improve the performance of GSR. In order to accelerate the convergence, we replace all the activation functions within the GSR decoders with GELU, thereby reducing the training duration. In quantitative analysis, our model achieves state-of-the-art performance on the SWiG dataset. Moreover, through field testing on dedicated assistive technology datasets and application demonstrations, the proposed OpenSU system can be used to enhance scene understanding and facilitate the independent mobility of people with visual impairments. Our code will be available at https://github.com/RuipingL/OpenSU.
</details>
<details>
<summary>摘要</summary>
“固定Scene理解（GSR）能够识别和解释视觉场景，将其转换为有意义的活动（动词）和参与的实体（角色）。在这个工作中，我们专注于将GSR应用于视障人士（PVI）。然而，精确的地方化信息是需要帮助PVI人士自信地穿梭环境和做出了知情的决策。为了解决这个问题，我们提出了一个开放场景理解（OpenSU）系统，旨在生成像素粒度密集的参与实体分割图案。具体来说，我们将OpenSU系统建立在GSR之上，还 adopting一个高效的填充模型（SAM）。此外，为了增强协变和协变之间的交互，我们使用一个坚固的纯transformer背景架构来提高GSR的表现。为了加速训练，我们将所有的启动函数在GSR解oder中替换为GELU，从而减少训练时间。在量值分析中，我们的模型在SWiG dataset上 achieve state-of-the-art表现。此外，通过特定助理技术dataset和应用示例的野试，我们的OpenSU系统可以增强场景理解和推动视障人士的独立 mobilility。我们的代码将在https://github.com/RuipingL/OpenSU 上available。”
</details></li>
</ul>
<hr>
<h2 id="Fast-Adaptation-with-Bradley-Terry-Preference-Models-in-Text-To-Image-Classification-and-Generation"><a href="#Fast-Adaptation-with-Bradley-Terry-Preference-Models-in-Text-To-Image-Classification-and-Generation" class="headerlink" title="Fast Adaptation with Bradley-Terry Preference Models in Text-To-Image Classification and Generation"></a>Fast Adaptation with Bradley-Terry Preference Models in Text-To-Image Classification and Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07929">http://arxiv.org/abs/2308.07929</a></li>
<li>repo_url: None</li>
<li>paper_authors: Victor Gallego</li>
<li>for: 这个研究是为了适应大型多modal模型（如CLIP和Stable Diffusion） towards sets of particular human preferences，使得用户能够 personnalize 这些模型 для特定任务或偏好。</li>
<li>methods: 我们使用 Bradley-Terry 偏好模型开发了一种快速适应方法，可以快速调整原始模型，只需要几个示例和Minimal computing resources。</li>
<li>results: 我们透过不同的多modal text and image understanding领域的实验，证明了这个框架的能力，包括偏好预测为赏金模型、生成任务等。<details>
<summary>Abstract</summary>
Recently, large multimodal models, such as CLIP and Stable Diffusion have experimented tremendous successes in both foundations and applications. However, as these models increase in parameter size and computational requirements, it becomes more challenging for users to personalize them for specific tasks or preferences. In this work, we address the problem of adapting the previous models towards sets of particular human preferences, aligning the retrieved or generated images with the preferences of the user. We leverage the Bradley-Terry preference model to develop a fast adaptation method that efficiently fine-tunes the original model, with few examples and with minimal computing resources. Extensive evidence of the capabilities of this framework is provided through experiments in different domains related to multimodal text and image understanding, including preference prediction as a reward model, and generation tasks.
</details>
<details>
<summary>摘要</summary>
Note:* "multimodal models" is translated as "多modal模型" (duō modal módel)* "CLIP" is translated as "CLIP" (C-L-I-P)* "Stable Diffusion" is translated as "稳定扩散" (jìng dìng kuò chuān)* "Bradley-Terry preference model" is translated as "布拉德利-特里尔喜好模型" (Bù lā dé lǐ-tè lì xǐ huān módel)* "fine-tunes" is translated as "细调" (xì diào)* "extensive evidence" is translated as "广泛的证据" (guǎng fāng de jiàn jí)
</details></li>
</ul>
<hr>
<h2 id="Prawn-Morphometrics-and-Weight-Estimation-from-Images-using-Deep-Learning-for-Landmark-Localization"><a href="#Prawn-Morphometrics-and-Weight-Estimation-from-Images-using-Deep-Learning-for-Landmark-Localization" class="headerlink" title="Prawn Morphometrics and Weight Estimation from Images using Deep Learning for Landmark Localization"></a>Prawn Morphometrics and Weight Estimation from Images using Deep Learning for Landmark Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07732">http://arxiv.org/abs/2307.07732</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alzayat Saleh, Md Mehedi Hasan, Herman W Raadsma, Mehar S Khatkar, Dean R Jerry, Mostafa Rahimi Azghadi</li>
<li>for: 这个研究是为了开发一个可靠且高精度的数位图像识别技术，以便在水产业中快速和准确地取得鱼类的形态数据，包括体重和 morphometric 分析。</li>
<li>methods: 这个研究使用了一种新的深度学习（DL）方法，包括两个主要 ком成分：一个特征提取模组，使用克罗内克积分操作 effficiently 结合低级和高级特征；以及一个点位标定模组，使用这些特征来预测虾子身体中的关键 morphological 点（点标）的坐标。</li>
<li>results: 我们的实验结果显示，这个新的DL方法在精度、可靠性和效率方面都比以前的DL方法表现更好，并且在8164幅虾子图像 dataset 上进行评估。我们也使用了原始特征来Derive five important prawn traits，并使用PCA方法来找出这些点标之间的距离，发现这些距离和鱼类的体长和宽度有高度的相关性。<details>
<summary>Abstract</summary>
Accurate weight estimation and morphometric analyses are useful in aquaculture for optimizing feeding, predicting harvest yields, identifying desirable traits for selective breeding, grading processes, and monitoring the health status of production animals. However, the collection of phenotypic data through traditional manual approaches at industrial scales and in real-time is time-consuming, labour-intensive, and prone to errors. Digital imaging of individuals and subsequent training of prediction models using Deep Learning (DL) has the potential to rapidly and accurately acquire phenotypic data from aquaculture species. In this study, we applied a novel DL approach to automate weight estimation and morphometric analysis using the black tiger prawn (Penaeus monodon) as a model crustacean. The DL approach comprises two main components: a feature extraction module that efficiently combines low-level and high-level features using the Kronecker product operation; followed by a landmark localization module that then uses these features to predict the coordinates of key morphological points (landmarks) on the prawn body. Once these landmarks were extracted, weight was estimated using a weight regression module based on the extracted landmarks using a fully connected network. For morphometric analyses, we utilized the detected landmarks to derive five important prawn traits. Principal Component Analysis (PCA) was also used to identify landmark-derived distances, which were found to be highly correlated with shape features such as body length, and width. We evaluated our approach on a large dataset of 8164 images of the Black tiger prawn (Penaeus monodon) collected from Australian farms. Our experimental results demonstrate that the novel DL approach outperforms existing DL methods in terms of accuracy, robustness, and efficiency.
</details>
<details>
<summary>摘要</summary>
Accurate weight estimation和形态分析在水产业中是非常有用的，可以优化饲料、预测捕捞量、确定适应性 trait、分级处理和监测生产动物的健康状况。但是，通过传统的手动方法收集生物数据在工业规模和实时是时间consuming、劳动密集和容易出错。数字图像技术可以快速和准确地获取生物数据。在这种研究中，我们采用了一种新的深度学习（DL）方法来自动化生物量和形态分析。这种DL方法包括两个主要组成部分：一个特征提取模块，使用Kronecker乘法高效地结合低级和高级特征；然后是一个地标定位模块，使用这些特征预测虾蟹身体上关键的形态特征（地标）的坐标。一旦获得了这些地标，我们使用基于这些地标的普通连接网络来估算虾蟹的重量。为了形态分析，我们利用检测到的地标来计算五个重要的虾蟹特征。我们还使用主成分分析（PCA）来确定由地标得到的距离，这些距离与身体长度和宽度之间存在高度相关性。我们对澳大利亚营养虾蟹（Penaeus monodon）的大量数据集进行了实验，结果表明，我们的DL方法在准确性、可靠性和效率方面都高于现有的DL方法。
</details></li>
</ul>
<hr>
<h2 id="Improving-NeRF-with-Height-Data-for-Utilization-of-GIS-Data"><a href="#Improving-NeRF-with-Height-Data-for-Utilization-of-GIS-Data" class="headerlink" title="Improving NeRF with Height Data for Utilization of GIS Data"></a>Improving NeRF with Height Data for Utilization of GIS Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07729">http://arxiv.org/abs/2307.07729</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hinata Aoki, Takao Yamanaka</li>
<li>for: 使用 Geographic Information System (GIS) 获取的高程数据，应用 Neural Radiance Fields (NeRF) 技术来重建大规模Scene。</li>
<li>methods: 将场景空间分成多个 объек和背景，使用高程数据来表示它们，并采用自适应采样方法。</li>
<li>results: 通过这种方法，可以提高图像渲染的准确性，同时减少训练速度。<details>
<summary>Abstract</summary>
Neural Radiance Fields (NeRF) has been applied to various tasks related to representations of 3D scenes. Most studies based on NeRF have focused on a small object, while a few studies have tried to reconstruct large-scale scenes although these methods tend to require large computational cost. For the application of NeRF to large-scale scenes, a method based on NeRF is proposed in this paper to effectively use height data which can be obtained from GIS (Geographic Information System). For this purpose, the scene space was divided into multiple objects and a background using the height data to represent them with separate neural networks. In addition, an adaptive sampling method is also proposed by using the height data. As a result, the accuracy of image rendering was improved with faster training speed.
</details>
<details>
<summary>摘要</summary>
<<SYS>>translate "Neural Radiance Fields (NeRF) has been applied to various tasks related to representations of 3D scenes. Most studies based on NeRF have focused on a small object, while a few studies have tried to reconstruct large-scale scenes although these methods tend to require large computational cost. For the application of NeRF to large-scale scenes, a method based on NeRF is proposed in this paper to effectively use height data which can be obtained from GIS (Geographic Information System). For this purpose, the scene space was divided into multiple objects and a background using the height data to represent them with separate neural networks. In addition, an adaptive sampling method is also proposed by using the height data. As a result, the accuracy of image rendering was improved with faster training speed." into Simplified Chinese.哦！下面是文本翻译成简化字的中文：NeRF（神经辐射场）已经应用于多种3D场景表示任务中。大多数NeRF研究都集中在小对象上，只有一些研究尝试了大规模场景重建，但这些方法通常需要大量计算成本。为了应用NeRF到大规模场景，这篇论文提出了一种基于NeRF的方法，使用GIS（地理信息系统）获取的高程数据来有效地使用它们。为此，场景空间被分解成多个对象和背景，使用高程数据来表示它们的不同神经网络。此外，还提出了一种适应采样方法。因此，图像渲染精度得到了改善，同时训练速度也得到了加速。
</details></li>
</ul>
<hr>
<h2 id="Improving-Translation-Invariance-in-Convolutional-Neural-Networks-with-Peripheral-Prediction-Padding"><a href="#Improving-Translation-Invariance-in-Convolutional-Neural-Networks-with-Peripheral-Prediction-Padding" class="headerlink" title="Improving Translation Invariance in Convolutional Neural Networks with Peripheral Prediction Padding"></a>Improving Translation Invariance in Convolutional Neural Networks with Peripheral Prediction Padding</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07725">http://arxiv.org/abs/2307.07725</a></li>
<li>repo_url: None</li>
<li>paper_authors: Kensuke Mukai, Takao Yamanaka</li>
<li>for: 这个论文是为了提出一种新的填充方法，以便在卷积神经网络中进行端到端训练。</li>
<li>methods: 该方法使用一种新的填充方法，即 Peripheral Prediction Padding (PP-Pad) 方法，可以根据每个任务而不同地训练填充值。</li>
<li>results: 经过测试，该方法在 semantic segmentation 任务中实现了更高的准确率和翻译不变性，比既前一些方法更好。I hope this helps! Let me know if you have any other questions.<details>
<summary>Abstract</summary>
Zero padding is often used in convolutional neural networks to prevent the feature map size from decreasing with each layer. However, recent studies have shown that zero padding promotes encoding of absolute positional information, which may adversely affect the performance of some tasks. In this work, a novel padding method called Peripheral Prediction Padding (PP-Pad) method is proposed, which enables end-to-end training of padding values suitable for each task instead of zero padding. Moreover, novel metrics to quantitatively evaluate the translation invariance of the model are presented. By evaluating with these metrics, it was confirmed that the proposed method achieved higher accuracy and translation invariance than the previous methods in a semantic segmentation task.
</details>
<details>
<summary>摘要</summary>
很多时候，卷积神经网络中使用零填充来防止特征图的大小随层数量递减。然而，最近的研究表明，零填充可能会导致编码绝对位置信息，这可能会影响一些任务的性能。在这种情况下，一种新的填充方法called Peripheral Prediction Padding（PP-Pad）方法被提出，该方法可以在每个任务中自动训练适合的填充值。此外，一些用于评估模型的翻译不变性的新指标也被提出。通过使用这些指标评估，确认了提议方法在 semantic segmentation 任务中实现了更高的准确率和翻译不变性，与之前的方法相比。
</details></li>
</ul>
<hr>
<h2 id="Spatial-Spectral-Hyperspectral-Classification-based-on-Learnable-3D-Group-Convolution"><a href="#Spatial-Spectral-Hyperspectral-Classification-based-on-Learnable-3D-Group-Convolution" class="headerlink" title="Spatial-Spectral Hyperspectral Classification based on Learnable 3D Group Convolution"></a>Spatial-Spectral Hyperspectral Classification based on Learnable 3D Group Convolution</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07720">http://arxiv.org/abs/2307.07720</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guandong Li, Mengxia Ye<br>for:This paper proposes a learnable group convolution network (LGCNet) to improve the performance of deep neural networks in hyperspectral image classification.methods:The LGCNet module uses a dynamic learning method for the input channels and convolution kernel grouping, which allows for flexible grouping structures and improved representation ability.results:The LGCNet achieves better inference speed and accuracy than mainstream hyperspectral image classification methods on three datasets (Indian Pines, Pavia University, and KSC).<details>
<summary>Abstract</summary>
Deep neural networks have faced many problems in hyperspectral image classification, including the ineffective utilization of spectral-spatial joint information and the problems of gradient vanishing and overfitting that arise with increasing depth. In order to accelerate the deployment of models on edge devices with strict latency requirements and limited computing power, this paper proposes a learnable group convolution network (LGCNet) based on an improved 3D-DenseNet model and a lightweight model design. The LGCNet module improves the shortcomings of group convolution by introducing a dynamic learning method for the input channels and convolution kernel grouping, enabling flexible grouping structures and generating better representation ability. Through the overall loss and gradient of the backpropagation network, the 3D group convolution is dynamically determined and updated in an end-to-end manner. The learnable number of channels and corresponding grouping can capture different complementary visual features of input images, allowing the CNN to learn richer feature representations. When extracting high-dimensional and redundant hyperspectral data, the 3D convolution kernels also contain a large amount of redundant information. The LGC module allows the 3D-DenseNet to choose channel information with more semantic features, and is very efficient, making it suitable for embedding in any deep neural network for acceleration and efficiency improvements. LGC enables the 3D-CNN to achieve sufficient feature extraction while also meeting speed and computing requirements. Furthermore, LGCNet has achieved progress in inference speed and accuracy, and outperforms mainstream hyperspectral image classification methods on the Indian Pines, Pavia University, and KSC datasets.
</details>
<details>
<summary>摘要</summary>
深度神经网络在多spectral图像分类中遇到了许多问题，包括不好地利用spectral-spatial共同信息和深度增加导致梯度消失和过拟合问题。为了加速部署模型在边缘设备上，这篇文章提出了一种可学习的群集卷积网络（LGCNet），基于改进的3D-DenseNet模型和轻量级模型设计。LGCNet模块将group卷积缺点改进，通过动态学习输入通道和卷积核组合，实现更flexible的grouping结构，并且能够更好地表示能力。通过整体损失和反向传播网络的梯度，3D group卷积在端到端方式进行动态确定和更新。学习可变通道和相应的grouping可以捕捉不同的辐射特征图像的可读性信息，使CNN学习更加丰富的特征表示。在提取高维和重复的多spectral数据时，3D卷积核也包含了大量的重复信息。LGC模块使得3D-DenseNet可以选择更多semantic的通道信息，非常高效，适用于任何深度神经网络的加速和效率提高。LGCNet在推理速度和准确率方面进步，并在印度棕榈、帕维亚大学和科学中心 datasets 上超越主流多spectral图像分类方法。
</details></li>
</ul>
<hr>
<h2 id="ExposureDiffusion-Learning-to-Expose-for-Low-light-Image-Enhancement"><a href="#ExposureDiffusion-Learning-to-Expose-for-Low-light-Image-Enhancement" class="headerlink" title="ExposureDiffusion: Learning to Expose for Low-light Image Enhancement"></a>ExposureDiffusion: Learning to Expose for Low-light Image Enhancement</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07710">http://arxiv.org/abs/2307.07710</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/wyf0912/ExposureDiffusion">https://github.com/wyf0912/ExposureDiffusion</a></li>
<li>paper_authors: Yufei Wang, Yi Yu, Wenhan Yang, Lanqing Guo, Lap-Pui Chau, Alex C. Kot, Bihan Wen</li>
<li>for: 提高图像亮度和准确率</li>
<li>methods: 结合扩散模型和物理基础模型，实现图像亮度提高和准确率提高</li>
<li>results: 实现了图像亮度提高和准确率提高，并且比传统扩散模型具有更好的一致性和更快的推理速度<details>
<summary>Abstract</summary>
Previous raw image-based low-light image enhancement methods predominantly relied on feed-forward neural networks to learn deterministic mappings from low-light to normally-exposed images. However, they failed to capture critical distribution information, leading to visually undesirable results. This work addresses the issue by seamlessly integrating a diffusion model with a physics-based exposure model. Different from a vanilla diffusion model that has to perform Gaussian denoising, with the injected physics-based exposure model, our restoration process can directly start from a noisy image instead of pure noise. As such, our method obtains significantly improved performance and reduced inference time compared with vanilla diffusion models. To make full use of the advantages of different intermediate steps, we further propose an adaptive residual layer that effectively screens out the side-effect in the iterative refinement when the intermediate results have been already well-exposed. The proposed framework can work with both real-paired datasets, SOTA noise models, and different backbone networks. Note that, the proposed framework is compatible with real-paired datasets, real/synthetic noise models, and different backbone networks. We evaluate the proposed method on various public benchmarks, achieving promising results with consistent improvements using different exposure models and backbones. Besides, the proposed method achieves better generalization capacity for unseen amplifying ratios and better performance than a larger feedforward neural model when few parameters are adopted.
</details>
<details>
<summary>摘要</summary>
previous raw image-based low-light image enhancement methods mostly relied on feed-forward neural networks to learn deterministic mappings from low-light to normally-exposed images, but they failed to capture critical distribution information, leading to visually undesirable results. this work addresses the issue by seamlessly integrating a diffusion model with a physics-based exposure model. different from a vanilla diffusion model that has to perform Gaussian denoising, with the injected physics-based exposure model, our restoration process can directly start from a noisy image instead of pure noise. as such, our method obtains significantly improved performance and reduced inference time compared with vanilla diffusion models. to make full use of the advantages of different intermediate steps, we further propose an adaptive residual layer that effectively screens out the side-effect in the iterative refinement when the intermediate results have been already well-exposed. the proposed framework can work with both real-paired datasets, SOTA noise models, and different backbone networks. note that, the proposed framework is compatible with real-paired datasets, real/synthetic noise models, and different backbone networks. we evaluate the proposed method on various public benchmarks, achieving promising results with consistent improvements using different exposure models and backbones. besides, the proposed method achieves better generalization capacity for unseen amplifying ratios and better performance than a larger feedforward neural model when few parameters are adopted.Here's the translation in Traditional Chinese:previous raw image-based low-light image enhancement methods mostly relied on feed-forward neural networks to learn deterministic mappings from low-light to normally-exposed images, but they failed to capture critical distribution information, leading to visually undesirable results. this work addresses the issue by seamlessly integrating a diffusion model with a physics-based exposure model. different from a vanilla diffusion model that has to perform Gaussian denoising, with the injected physics-based exposure model, our restoration process can directly start from a noisy image instead of pure noise. as such, our method obtains significantly improved performance and reduced inference time compared with vanilla diffusion models. to make full use of the advantages of different intermediate steps, we further propose an adaptive residual layer that effectively screens out the side-effect in the iterative refinement when the intermediate results have been already well-exposed. the proposed framework can work with both real-paired datasets, SOTA noise models, and different backbone networks. note that, the proposed framework is compatible with real-paired datasets, real/synthetic noise models, and different backbone networks. we evaluate the proposed method on various public benchmarks, achieving promising results with consistent improvements using different exposure models and backbones. besides, the proposed method achieves better generalization capacity for unseen amplifying ratios and better performance than a larger feedforward neural model when few parameters are adopted.
</details></li>
</ul>
<hr>
<h2 id="PSGformer-Enhancing-3D-Point-Cloud-Instance-Segmentation-via-Precise-Semantic-Guidance"><a href="#PSGformer-Enhancing-3D-Point-Cloud-Instance-Segmentation-via-Precise-Semantic-Guidance" class="headerlink" title="PSGformer: Enhancing 3D Point Cloud Instance Segmentation via Precise Semantic Guidance"></a>PSGformer: Enhancing 3D Point Cloud Instance Segmentation via Precise Semantic Guidance</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07708">http://arxiv.org/abs/2307.07708</a></li>
<li>repo_url: None</li>
<li>paper_authors: Lei Pan, Wuyang Luan, Yuan Zheng, Qiang Fu, Junhui Li</li>
<li>for: 提高3D实例分割的性能，解决现有的3D semantic segmentation模型导致的限制。</li>
<li>methods: 提出了一种新的3D实例分割网络PSGformer，包括两个关键进步：首先，我们提出了一种多级semantic aggregation module，通过对前景点 filtering和多半径聚合来有效地捕捉场景特征。其次，PSGformer引入了并行特征融合transformer模块，通过独立处理超点特征和聚合特征来实现更全面的特征表示。</li>
<li>results: 在ScanNetv2 dataset上进行了广泛的实验，并证明PSGformer可以在Scannetv2隐藏测试集上提高3D实例分割的性能，比对比的状态体系方法高2.2%。<details>
<summary>Abstract</summary>
Most existing 3D instance segmentation methods are derived from 3D semantic segmentation models. However, these indirect approaches suffer from certain limitations. They fail to fully leverage global and local semantic information for accurate prediction, which hampers the overall performance of the 3D instance segmentation framework. To address these issues, this paper presents PSGformer, a novel 3D instance segmentation network. PSGformer incorporates two key advancements to enhance the performance of 3D instance segmentation. Firstly, we propose a Multi-Level Semantic Aggregation Module, which effectively captures scene features by employing foreground point filtering and multi-radius aggregation. This module enables the acquisition of more detailed semantic information from global and local perspectives. Secondly, PSGformer introduces a Parallel Feature Fusion Transformer Module that independently processes super-point features and aggregated features using transformers. The model achieves a more comprehensive feature representation by the features which connect global and local features. We conducted extensive experiments on the ScanNetv2 dataset. Notably, PSGformer exceeds compared state-of-the-art methods by 2.2% on ScanNetv2 hidden test set in terms of mAP. Our code and models will be publicly released.
</details>
<details>
<summary>摘要</summary>
现有的大多数3D实例分割方法都是基于3Dsemantic分割模型的派生方法。然而，这些间接方法受到一定的限制。它们不能充分利用全局和局部semantic信息，导致3D实例分割框架的总性表现下降。为了解决这些问题，本文提出了PSGformer，一种新的3D实例分割网络。PSGformer包括两项关键进步，以提高3D实例分割的表现。首先，我们提出了一个多级semantic汇集模块，该模块通过对前景点滤波和多半径汇集来有效地捕捉场景特征。这使得更详细的semantic信息从全局和局部角度得到了捕捉。其次，PSGformer引入了并行特征融合 transformer模块，该模块使用transformer独立处理超点特征和汇集特征，以实现更全面的特征表示。我们在ScanNetv2 dataset上进行了广泛的实验。值得注意的是，PSGformer在ScanNetv2隐藏测试集上比相对state-of-the-art方法高出2.2%的mAP。我们将代码和模型公开发布。
</details></li>
</ul>
<hr>
<h2 id="Neural-Deformable-Models-for-3D-Bi-Ventricular-Heart-Shape-Reconstruction-and-Modeling-from-2D-Sparse-Cardiac-Magnetic-Resonance-Imaging"><a href="#Neural-Deformable-Models-for-3D-Bi-Ventricular-Heart-Shape-Reconstruction-and-Modeling-from-2D-Sparse-Cardiac-Magnetic-Resonance-Imaging" class="headerlink" title="Neural Deformable Models for 3D Bi-Ventricular Heart Shape Reconstruction and Modeling from 2D Sparse Cardiac Magnetic Resonance Imaging"></a>Neural Deformable Models for 3D Bi-Ventricular Heart Shape Reconstruction and Modeling from 2D Sparse Cardiac Magnetic Resonance Imaging</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07693">http://arxiv.org/abs/2307.07693</a></li>
<li>repo_url: None</li>
<li>paper_authors: Meng Ye, Dong Yang, Mikael Kanski, Leon Axel, Dimitris Metaxas</li>
<li>for: 重建和模型三维心脏bi-射影形状从二维精 sparsecardiac magnetic resonance(CMR)成像数据</li>
<li>methods: 使用混合型抽象超quadrics模型，通过 globally和 locally抽象来模型bi-射影形状</li>
<li>results: 比 conventiomal方法高效、可以自动生成高质量三角形网格、学习 dense对应关系以进行准确心脏形态 региSTRATION<details>
<summary>Abstract</summary>
We propose a novel neural deformable model (NDM) targeting at the reconstruction and modeling of 3D bi-ventricular shape of the heart from 2D sparse cardiac magnetic resonance (CMR) imaging data. We model the bi-ventricular shape using blended deformable superquadrics, which are parameterized by a set of geometric parameter functions and are capable of deforming globally and locally. While global geometric parameter functions and deformations capture gross shape features from visual data, local deformations, parameterized as neural diffeomorphic point flows, can be learned to recover the detailed heart shape.Different from iterative optimization methods used in conventional deformable model formulations, NDMs can be trained to learn such geometric parameter functions, global and local deformations from a shape distribution manifold. Our NDM can learn to densify a sparse cardiac point cloud with arbitrary scales and generate high-quality triangular meshes automatically. It also enables the implicit learning of dense correspondences among different heart shape instances for accurate cardiac shape registration. Furthermore, the parameters of NDM are intuitive, and can be used by a physician without sophisticated post-processing. Experimental results on a large CMR dataset demonstrate the improved performance of NDM over conventional methods.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的神经流形模型（NDM），用于从2D稀疏卡路里影像数据中重建和模型3D双腔形心的形状。我们使用混合的流形超quadrics来模型双腔形，这些超quadrics是由一组 геометрических参数函数parameter化的，可以在全球和地方水平上进行扭曲。而全球的 геометрические参数函数和扭曲可以从视觉数据中提取大规模的形状特征，而地方的扭曲，则是通过神经Diffusion点流来学习，以回归心形的细节。与传统的可变模型形式ulation中的迭代优化方法不同，NDM可以通过形态分布拟合来学习 geometric parameter functions和全球和地方的扭曲。我们的NDM可以从稀疏卡路里点云中填充任意尺度的点云，并自动生成高质量的三角形网格。此外，NDM还可以自动学习 dense correspondences among different heart shape instances，以实现准确的心形注册。此外，NDM的参数是直观的，可以由医生 без高级后处理使用。实验结果表明，NDM在大量CMR数据集上表现得更好于传统方法。
</details></li>
</ul>
<hr>
<h2 id="DRM-IR-Task-Adaptive-Deep-Unfolding-Network-for-All-In-One-Image-Restoration"><a href="#DRM-IR-Task-Adaptive-Deep-Unfolding-Network-for-All-In-One-Image-Restoration" class="headerlink" title="DRM-IR: Task-Adaptive Deep Unfolding Network for All-In-One Image Restoration"></a>DRM-IR: Task-Adaptive Deep Unfolding Network for All-In-One Image Restoration</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07688">http://arxiv.org/abs/2307.07688</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/YuanshuoCheng/DRM-IR">https://github.com/YuanshuoCheng/DRM-IR</a></li>
<li>paper_authors: Yuanshuo Cheng, Mingwen Shao, Yecong Wan, Chao Wang, Wangmeng Zuo</li>
<li>for: 这篇论文是为了提出一种高效的全能性图像修复方法（DRM-IR），以提高图像修复性能。</li>
<li>methods: 该方法包括任务适应质量模型和模型基于图像修复两个子任务，它们是通过参考图像对进行最大 posteriori推断的。</li>
<li>results: 对多个标准数据集进行了广泛的实验，显示DRM-IR可以达到当今最佳的全能性图像修复性能。<details>
<summary>Abstract</summary>
Existing All-In-One image restoration (IR) methods usually lack flexible modeling on various types of degradation, thus impeding the restoration performance. To achieve All-In-One IR with higher task dexterity, this work proposes an efficient Dynamic Reference Modeling paradigm (DRM-IR), which consists of task-adaptive degradation modeling and model-based image restoring. Specifically, these two subtasks are formalized as a pair of entangled reference-based maximum a posteriori (MAP) inferences, which are optimized synchronously in an unfolding-based manner. With the two cascaded subtasks, DRM-IR first dynamically models the task-specific degradation based on a reference image pair and further restores the image with the collected degradation statistics. Besides, to bridge the semantic gap between the reference and target degraded images, we further devise a Degradation Prior Transmitter (DPT) that restrains the instance-specific feature differences. DRM-IR explicitly provides superior flexibility for All-in-One IR while being interpretable. Extensive experiments on multiple benchmark datasets show that our DRM-IR achieves state-of-the-art in All-In-One IR.
</details>
<details>
<summary>摘要</summary>
现有的全包式图像恢复（IR）方法通常缺乏不同类型的退化模型的灵活定制，因此影响了恢复性能。为了实现更高的任务技巧性，本工作提出了高效的动态参照模型 paradigma（DRM-IR），它包括任务适应性的退化模型和基于模型的图像恢复。具体来说，这两个子任务被形式化为一对推理最大 posteriori（MAP）推理，它们在一种层次结构上进行同步优化。通过两个层次的子任务，DRM-IR首先在参照图像对中动态地模型任务特定的退化，然后使用采集的退化统计来恢复图像。此外，为了跨越参照图像和目标退化图像之间的Semantic gap，我们还提出了退化先天传输器（DPT），它限制了特定的特征差异。DRM-IR显式地提供了更高灵活性和可解释性，并在多个 benchmark 数据集上进行了广泛的实验，证明了我们的 DRM-IR 在全包式IR 中实现了state-of-the-art。
</details></li>
</ul>
<hr>
<h2 id="Semantic-Contrastive-Bootstrapping-for-Single-positive-Multi-label-Recognition"><a href="#Semantic-Contrastive-Bootstrapping-for-Single-positive-Multi-label-Recognition" class="headerlink" title="Semantic Contrastive Bootstrapping for Single-positive Multi-label Recognition"></a>Semantic Contrastive Bootstrapping for Single-positive Multi-label Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07680">http://arxiv.org/abs/2307.07680</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/iCVTEAM/Scob">https://github.com/iCVTEAM/Scob</a></li>
<li>paper_authors: Cheng Chen, Yifan Zhao, Jia Li</li>
<li>for: 这篇论文主要用于提出一种学习多个标签图像识别方法，以便利用部分标注数据进行训练，并且可以提高图像识别性能和减少标注工作量。</li>
<li>methods: 该方法使用semantic contrastive bootstrapping（Scob）方法，通过引入类活动作为semantic guidance来慢慢恢复交对关系，然后提出一种循环semantic masked transformer来提取图像级别的iconic对象表示，并在多个标签分类任务上进行contrastive学习。</li>
<li>results: 经过extensive的实验表明，提出的共同学习框架可以在四个公共多个标签图像识别benchmark上大幅超越现有的模型，并且可以减少可能由错误semantic guidance引起的干扰。<details>
<summary>Abstract</summary>
Learning multi-label image recognition with incomplete annotation is gaining popularity due to its superior performance and significant labor savings when compared to training with fully labeled datasets. Existing literature mainly focuses on label completion and co-occurrence learning while facing difficulties with the most common single-positive label manner. To tackle this problem, we present a semantic contrastive bootstrapping (Scob) approach to gradually recover the cross-object relationships by introducing class activation as semantic guidance. With this learning guidance, we then propose a recurrent semantic masked transformer to extract iconic object-level representations and delve into the contrastive learning problems on multi-label classification tasks. We further propose a bootstrapping framework in an Expectation-Maximization fashion that iteratively optimizes the network parameters and refines semantic guidance to alleviate possible disturbance caused by wrong semantic guidance. Extensive experimental results demonstrate that the proposed joint learning framework surpasses the state-of-the-art models by a large margin on four public multi-label image recognition benchmarks. Codes can be found at https://github.com/iCVTEAM/Scob.
</details>
<details>
<summary>摘要</summary>
学习多标签图像识别 WITH incomplete annotation 在当前研究中得到了广泛的关注，因为它在训练完全标注数据集时表现出的高性能和重要的劳动力成本减少。现有文献主要关注于标签完成和共occurrence学习，而面临着最常见的单个正样式问题。为解决这个问题，我们提出了semantic contrastive bootstrapping（Scob）方法，通过引入类活动作为semantic guidance来慢慢地恢复交对关系。然后，我们提议一种循环semantic masked transformer来提取图像级别的iconic对象表示，并探索多标签分类任务中的contrastive learning问题。我们还提出了一个Expectation-Maximization的框架，iteratively optimize网络参数和refine semantic guidance，以避免可能由错误的semantic guidance引起的干扰。实验结果表明，我们提出的 JOINT learning框架在四个公共多标签图像识别benchmark上超过了当前状态的模型，并且可以在https://github.com/iCVTEAM/Scob找到代码。
</details></li>
</ul>
<hr>
<h2 id="Both-Spatial-and-Frequency-Cues-Contribute-to-High-Fidelity-Image-Inpainting"><a href="#Both-Spatial-and-Frequency-Cues-Contribute-to-High-Fidelity-Image-Inpainting" class="headerlink" title="Both Spatial and Frequency Cues Contribute to High-Fidelity Image Inpainting"></a>Both Spatial and Frequency Cues Contribute to High-Fidelity Image Inpainting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07678">http://arxiv.org/abs/2307.07678</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ze Lu, Yalei Lv, Wenqi Wang, Pengfei Xiong</li>
<li>for:  Image inpainting with deep generative approaches.</li>
<li>methods:  Proposed Frequency-Spatial Complementary Network (FSCN) with extra Frequency Branch and Frequency Loss, and Frequency-Spatial Cross-Attention Block (FSCAB) to fuse multi-domain features.</li>
<li>results:  Superior inpainting results with fewer parameters and less computation cost, outperforming previous state-of-the-art approaches.<details>
<summary>Abstract</summary>
Deep generative approaches have obtained great success in image inpainting recently. However, most generative inpainting networks suffer from either over-smooth results or aliasing artifacts. The former lacks high-frequency details, while the latter lacks semantic structure. To address this issue, we propose an effective Frequency-Spatial Complementary Network (FSCN) by exploiting rich semantic information in both spatial and frequency domains. Specifically, we introduce an extra Frequency Branch and Frequency Loss on the spatial-based network to impose direct supervision on the frequency information, and propose a Frequency-Spatial Cross-Attention Block (FSCAB) to fuse multi-domain features and combine the corresponding characteristics. With our FSCAB, the inpainting network is capable of capturing frequency information and preserving visual consistency simultaneously. Extensive quantitative and qualitative experiments demonstrate that our inpainting network can effectively achieve superior results, outperforming previous state-of-the-art approaches with significantly fewer parameters and less computation cost. The code will be released soon.
</details>
<details>
<summary>摘要</summary>
深度生成方法在图像填充方面最近几年取得了很大的成功。然而，大多数生成填充网络都会面临高频环境的过滤问题，导致结果过滤而失去高频环境的细节，或者保留了semantic结构，但是图像中的细节失真。为了解决这个问题，我们提出了一种有效的频率空间补充网络（FSCN），通过利用图像空间和频率频谱中的丰富semantic信息来解决。特别是，我们在网络中添加了额外的频率分支和频率损失，以直接监督频率信息，并提出了频率空间协同块（FSCAB）来融合多个频谱特征并组合相应的特征。通过我们的FSCAB，填充网络可以同时捕捉频率信息和保持视觉一致性。广泛的量化和质量测试表明，我们的填充网络可以达到更高的效果，比前一代方法有更少的参数和计算成本。代码将很快地发布。
</details></li>
</ul>
<hr>
<h2 id="Learning-from-Pseudo-labeled-Segmentation-for-Multi-Class-Object-Counting"><a href="#Learning-from-Pseudo-labeled-Segmentation-for-Multi-Class-Object-Counting" class="headerlink" title="Learning from Pseudo-labeled Segmentation for Multi-Class Object Counting"></a>Learning from Pseudo-labeled Segmentation for Multi-Class Object Counting</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07677">http://arxiv.org/abs/2307.07677</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jingyi Xu, Hieu Le, Dimitris Samaras</li>
<li>for: 本研究的目的是为了解决现有的物件计数模型在多类图像中对象计数 task 中的挑战，即尝试使用只有一些示例来计数图像中的多个物件类型。</li>
<li>methods: 我们提议使用示例基本的分割模型来地方化对象区域，然后使用这些分割模型来计数图像中的物件。我们使用只有盒子示例和点注释来获取pseudo segmentation masks，并训练这些分割模型。</li>
<li>results: 我们在两个新的多类数据集和一个真实图像集上评估了不同方法的性能，并显示了我们的提议方法在这些数据集上显著超过了之前的物件计数方法。<details>
<summary>Abstract</summary>
Class-agnostic counting (CAC) has numerous potential applications across various domains. The goal is to count objects of an arbitrary category during testing, based on only a few annotated exemplars. In this paper, we point out that the task of counting objects of interest when there are multiple object classes in the image (namely, multi-class object counting) is particularly challenging for current object counting models. They often greedily count every object regardless of the exemplars. To address this issue, we propose localizing the area containing the objects of interest via an exemplar-based segmentation model before counting them. The key challenge here is the lack of segmentation supervision to train this model. To this end, we propose a method to obtain pseudo segmentation masks using only box exemplars and dot annotations. We show that the segmentation model trained on these pseudo-labeled masks can effectively localize objects of interest for an arbitrary multi-class image based on the exemplars. To evaluate the performance of different methods on multi-class counting, we introduce two new benchmarks, a synthetic multi-class dataset and a new test set of real images in which objects from multiple classes are present. Our proposed method shows a significant advantage over the previous CAC methods on these two benchmarks.
</details>
<details>
<summary>摘要</summary>
“类agnostic counting（CAC）具有广泛的应用前景，可以在不同领域中应用。目标是在测试过程中，基于只有一些标注的示例来计数对象。在本文中，我们指出，当图像中存在多个对象类时（即多类对象计数），现有的对象计数模型很难准确地计数对象。他们通常会吃掉所有对象，不论是否符合示例。为解决这个问题，我们提议先使用示例基于分割模型将对象区域围括出来，然后计数围括区域中的对象。关键问题在于，如何训练这个分割模型。为此，我们提议使用只有盒子示例和点标注来生成pseudo分割面积。我们发现，这种分割模型可以基于示例来有效地围括对象区域，并且可以在任意多类图像中计数对象。为评估不同方法的性能，我们创建了两个新的标准 bencmarks：一个是Synthetic多类数据集，另一个是一个新的实际图像测试集，其中对象来自多个类。我们的提议方法在这两个标准 bencmarks上表现出了明显的优势。”
</details></li>
</ul>
<hr>
<h2 id="INVE-Interactive-Neural-Video-Editing"><a href="#INVE-Interactive-Neural-Video-Editing" class="headerlink" title="INVE: Interactive Neural Video Editing"></a>INVE: Interactive Neural Video Editing</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07663">http://arxiv.org/abs/2307.07663</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jiahui Huang, Leonid Sigal, Kwang Moo Yi, Oliver Wang, Joon-Young Lee</li>
<li>for: 这个论文是为了提供一种实时视频编辑解决方案，帮助视频编辑过程中的 sparse frame 编辑propagation到整个视频clip。</li>
<li>methods: 该方法基于 recent work on Layered Neural Atlas (LNA)，但是LNA受到两大缺点：（1）方法太慢 для实时编辑，（2）不支持一些编辑用case，如直接帧编辑和固定Texture tracking。我们采用高效的网络架构，以及 hash-grids 编码，以提高处理速度。此外，我们学习 bi-directional 函数 между image-atlas 和引入 vectorized editing，这些都使得我们的 INVE 可以支持更多的编辑。</li>
<li>results: 相比 LNA，我们的 INVE 可以减少学习和推理时间，并且支持更多的视频编辑操作。我们通过对 INVE 和 LNA 进行了全面的量化和质量分析，并展示了 INVE 的优越性和改进的性能。 для视频结果，请参考 <a target="_blank" rel="noopener" href="https://gabriel-huang.github.io/inve/">https://gabriel-huang.github.io/inve/</a>。<details>
<summary>Abstract</summary>
We present Interactive Neural Video Editing (INVE), a real-time video editing solution, which can assist the video editing process by consistently propagating sparse frame edits to the entire video clip. Our method is inspired by the recent work on Layered Neural Atlas (LNA). LNA, however, suffers from two major drawbacks: (1) the method is too slow for interactive editing, and (2) it offers insufficient support for some editing use cases, including direct frame editing and rigid texture tracking. To address these challenges we leverage and adopt highly efficient network architectures, powered by hash-grids encoding, to substantially improve processing speed. In addition, we learn bi-directional functions between image-atlas and introduce vectorized editing, which collectively enables a much greater variety of edits in both the atlas and the frames directly. Compared to LNA, our INVE reduces the learning and inference time by a factor of 5, and supports various video editing operations that LNA cannot. We showcase the superiority of INVE over LNA in interactive video editing through a comprehensive quantitative and qualitative analysis, highlighting its numerous advantages and improved performance. For video results, please see https://gabriel-huang.github.io/inve/
</details>
<details>
<summary>摘要</summary>
我们介绍Interactive Neural Video Editing（INVE），一个实时影像修剪解决方案，可以帮助影像修剪过程中的叠加短缺几帧至整个影像片。我们的方法受到latest Layered Neural Atlas（LNA）的启发，但LNA有两个主要缺点：（1）方法太慢 для互动编辑，（2）它无法支持一些编辑用 caso，包括直接几帧编辑和固定的 Texture Tracking。为了解决这些挑战，我们采用高效的网络架构，并利用 Hash-Grids 编码，以提高处理速度。此外，我们学习了两向函数 между Image-Atlas和引入 вектор化编辑，这样可以实现更多的编辑在 both the atlas and the frames directly。与LNA相比，INVE可以reduces the learning and inference time by a factor of 5, and supports various video editing operations that LNA cannot。我们通过对INVE和LNA的Quantitative and qualitative analysis，强调其许多优点和改进的表现。如果您想看到影像效果，请参考 <https://gabriel-huang.github.io/inve/>。
</details></li>
</ul>
<hr>
<h2 id="RFLA-A-Stealthy-Reflected-Light-Adversarial-Attack-in-the-Physical-World"><a href="#RFLA-A-Stealthy-Reflected-Light-Adversarial-Attack-in-the-Physical-World" class="headerlink" title="RFLA: A Stealthy Reflected Light Adversarial Attack in the Physical World"></a>RFLA: A Stealthy Reflected Light Adversarial Attack in the Physical World</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07653">http://arxiv.org/abs/2307.07653</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/winterwindwang/rfla">https://github.com/winterwindwang/rfla</a></li>
<li>paper_authors: Donghua Wang, Wen Yao, Tingsong Jiang, Chao Li, Xiaoqian Chen</li>
<li>for: 本研究旨在攻击深度神经网络(DNNs)的物理攻击方法。</li>
<li>methods: 本文提出了一种新的反射光攻击(RFLA)方法，通过在镜前放置透明彩虹的彩色透明膜和纸剪形成不同颜色的几何图形来实现。</li>
<li>results: 实验结果表明，提出的方法在不同的数据集和模型上达到了99%以上的成功率，并在不同的物理环境中进行了验证。<details>
<summary>Abstract</summary>
Physical adversarial attacks against deep neural networks (DNNs) have recently gained increasing attention. The current mainstream physical attacks use printed adversarial patches or camouflage to alter the appearance of the target object. However, these approaches generate conspicuous adversarial patterns that show poor stealthiness. Another physical deployable attack is the optical attack, featuring stealthiness while exhibiting weakly in the daytime with sunlight. In this paper, we propose a novel Reflected Light Attack (RFLA), featuring effective and stealthy in both the digital and physical world, which is implemented by placing the color transparent plastic sheet and a paper cut of a specific shape in front of the mirror to create different colored geometries on the target object. To achieve these goals, we devise a general framework based on the circle to model the reflected light on the target object. Specifically, we optimize a circle (composed of a coordinate and radius) to carry various geometrical shapes determined by the optimized angle. The fill color of the geometry shape and its corresponding transparency are also optimized. We extensively evaluate the effectiveness of RFLA on different datasets and models. Experiment results suggest that the proposed method achieves over 99% success rate on different datasets and models in the digital world. Additionally, we verify the effectiveness of the proposed method in different physical environments by using sunlight or a flashlight.
</details>
<details>
<summary>摘要</summary>
Recently, physical adversarial attacks against deep neural networks (DNNs) have gained increasing attention. Current mainstream physical attacks use printed adversarial patches or camouflage to alter the appearance of the target object, but these approaches generate conspicuous adversarial patterns that show poor stealthiness. Another physical deployable attack is the optical attack, which is stealthy during the daytime with sunlight. In this paper, we propose a novel Reflected Light Attack (RFLA), which is effective and stealthy in both the digital and physical worlds. This attack is implemented by placing a color transparent plastic sheet and a paper cut of a specific shape in front of a mirror to create different colored geometries on the target object. To achieve these goals, we develop a general framework based on the circle to model the reflected light on the target object. Specifically, we optimize a circle (composed of a coordinate and radius) to carry various geometrical shapes determined by the optimized angle. The fill color of the geometry shape and its corresponding transparency are also optimized. We extensively evaluate the effectiveness of RFLA on different datasets and models. Experiment results suggest that the proposed method achieves over 99% success rate on different datasets and models in the digital world. Additionally, we verify the effectiveness of the proposed method in different physical environments by using sunlight or a flashlight.
</details></li>
</ul>
<hr>
<h2 id="ACF-Net-An-Attention-enhanced-Co-interactive-Fusion-Network-for-Automated-Structural-Condition-Assessment-in-Visual-Inspection"><a href="#ACF-Net-An-Attention-enhanced-Co-interactive-Fusion-Network-for-Automated-Structural-Condition-Assessment-in-Visual-Inspection" class="headerlink" title="ACF-Net: An Attention-enhanced Co-interactive Fusion Network for Automated Structural Condition Assessment in Visual Inspection"></a>ACF-Net: An Attention-enhanced Co-interactive Fusion Network for Automated Structural Condition Assessment in Visual Inspection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07643">http://arxiv.org/abs/2307.07643</a></li>
<li>repo_url: None</li>
<li>paper_authors: Chenyu Zhang, Zhaozheng Yin, Ruwen Qin<br>for: 这篇论文旨在提出一种自动化桥梁Visual化检查的方法，以提高公共工程设施的监测效率。methods: 该方法基于Attention-enhanced Co-interactive Fusion Network (ACF-Net)，可同时分析结构元素和表面缺陷，并使用两个任务特定的学习子网计算任务特定特征。results: 实验结果表明，提出的ACF-Net方法在新的Steel Bridge Condition Inspection Visual (SBCIV)测试集上达到了92.11% mIoU для元素分析和87.16% mIoU для腐蚀分割，超越当前状态的方法。<details>
<summary>Abstract</summary>
Efficiently monitoring the condition of civil infrastructures necessitates automating the structural condition assessment in visual inspection. This paper proposes an Attention-enhanced Co-interactive Fusion Network (ACF-Net) for automatic structural condition assessment in visual bridge inspection. The ACF-Net can simultaneously parse structural elements and segment surface defects on the elements in inspection images. It integrates two task-specific relearning subnets to extract task-specific features from an overall feature embedding and a co-interactive feature fusion module to capture the spatial correlation and facilitate information sharing between tasks. Experimental results demonstrate that the proposed ACF-Net outperforms the current state-of-the-art approaches, achieving promising performance with 92.11% mIoU for element parsing and 87.16% mIoU for corrosion segmentation on the new benchmark dataset Steel Bridge Condition Inspection Visual (SBCIV) testing set. An ablation study reveals the strengths of ACF-Net, and a case study showcases its capability to automate structural condition assessment. The code will be open-source after acceptance.
</details>
<details>
<summary>摘要</summary>
efficiently monitoring civil infrastructure condition requires automating structural condition assessment in visual inspection. this paper proposes an attention-enhanced co-interactive fusion network (ACF-Net) for automatic structural condition assessment in visual bridge inspection. the ACF-Net can simultaneously parse structural elements and segment surface defects on the elements in inspection images. it integrates two task-specific relearning subnets to extract task-specific features from an overall feature embedding and a co-interactive feature fusion module to capture the spatial correlation and facilitate information sharing between tasks. experimental results demonstrate that the proposed ACF-Net outperforms the current state-of-the-art approaches, achieving promising performance with 92.11% mIoU for element parsing and 87.16% mIoU for corrosion segmentation on the new benchmark dataset steel bridge condition inspection visual (SBCIV) testing set. an ablation study reveals the strengths of ACF-Net, and a case study showcases its capability to automate structural condition assessment. the code will be open-source after acceptance.Here's the text with traditional Chinese characters:efficiently monitoring civil infrastructure condition requires automating structural condition assessment in visual inspection. this paper proposes an attention-enhanced co-interactive fusion network (ACF-Net) for automatic structural condition assessment in visual bridge inspection. the ACF-Net can simultaneously parse structural elements and segment surface defects on the elements in inspection images. it integrates two task-specific relearning subnets to extract task-specific features from an overall feature embedding and a co-interactive feature fusion module to capture the spatial correlation and facilitate information sharing between tasks. experimental results demonstrate that the proposed ACF-Net outperforms the current state-of-the-art approaches, achieving promising performance with 92.11% mIoU for element parsing and 87.16% mIoU for corrosion segmentation on the new benchmark dataset steel bridge condition inspection visual (SBCIV) testing set. an ablation study reveals the strengths of ACF-Net, and a case study showcases its capability to automate structural condition assessment. the code will be open-source after acceptance.
</details></li>
</ul>
<hr>
<h2 id="CoTracker-It-is-Better-to-Track-Together"><a href="#CoTracker-It-is-Better-to-Track-Together" class="headerlink" title="CoTracker: It is Better to Track Together"></a>CoTracker: It is Better to Track Together</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07635">http://arxiv.org/abs/2307.07635</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/facebookresearch/co-tracker">https://github.com/facebookresearch/co-tracker</a></li>
<li>paper_authors: Nikita Karaev, Ignacio Rocco, Benjamin Graham, Natalia Neverova, Andrea Vedaldi, Christian Rupprecht</li>
<li>for: 这个论文的目的是提出一种能够同时跟踪多个视频帧中多个点的抽象方法，以提高视频动作预测的性能。</li>
<li>methods: 这个方法使用了transformer网络，特制的注意层，iteratively更新多个轨迹的估计。</li>
<li>results: 这个方法在大多数测试 benchmark 中超越了当前state-of-the-art方法，并且可以同时跟踪一些点，还可以在视频帧中添加新的点进行跟踪。<details>
<summary>Abstract</summary>
Methods for video motion prediction either estimate jointly the instantaneous motion of all points in a given video frame using optical flow or independently track the motion of individual points throughout the video. The latter is true even for powerful deep-learning methods that can track points through occlusions. Tracking points individually ignores the strong correlation that can exist between the points, for instance, because they belong to the same physical object, potentially harming performance. In this paper, we thus propose CoTracker, an architecture that jointly tracks multiple points throughout an entire video. This architecture combines several ideas from the optical flow and tracking literature in a new, flexible and powerful design. It is based on a transformer network that models the correlation of different points in time via specialised attention layers. The transformer iteratively updates an estimate of several trajectories. It can be applied in a sliding-window manner to very long videos, for which we engineer an unrolled training loop. It can track from one to several points jointly and supports adding new points to track at any time. The result is a flexible and powerful tracking algorithm that outperforms state-of-the-art methods in almost all benchmarks.
</details>
<details>
<summary>摘要</summary>
视频动态预测方法可以同时估计视频帧中所有点的快照动态，或者独立地跟踪视频中每个点的动态。前者是true，即使使用深度学习方法，可以在遮挡中跟踪点。但是，单独跟踪点可能忽略视频中点之间的强相关性，例如因为它们属于同一物理对象，从而影响性能。为此，我们在这篇论文中提出了CoTracker，一种架构，可以在整个视频中同时跟踪多个点。这种架构结合了光流和跟踪领域的一些想法，并实现了一种flexible和强大的设计。它基于特殊注意层，以模型不同时间点之间的点相关性。特殊注意层在循环更新多个轨迹的估计，可以在很长的视频中使用滑块训练方法。它可以同时跟踪1到多个点，并且支持在任何时间添加新的点。结果是一种灵活和强大的跟踪算法，比state-of-the-art方法在大多数测试 benchMarks 上出perform。
</details></li>
</ul>
<hr>
<h2 id="Generalizable-Embeddings-with-Cross-batch-Metric-Learning"><a href="#Generalizable-Embeddings-with-Cross-batch-Metric-Learning" class="headerlink" title="Generalizable Embeddings with Cross-batch Metric Learning"></a>Generalizable Embeddings with Cross-batch Metric Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07620">http://arxiv.org/abs/2307.07620</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yetigurbuz/xml-dml">https://github.com/yetigurbuz/xml-dml</a></li>
<li>paper_authors: Yeti Z. Gurbuz, A. Aydin Alatan</li>
<li>for: 本文探讨了深度度量学中的全球平均pooling（GAP）组件，以及其在学习泛化表示的效果。</li>
<li>methods: 作者将GAP视为一种将各个特征向量作为独立的 semantic entity 进行组合的方式，并通过一种可 convex combination of learnable prototypes来表示GAP。然后，作者通过一种 recursive 过程来适应一个批处理的样本，并在每一轮中使用不同的批处理来正则化学习。</li>
<li>results: 作者在4个流行的DML benchmark上验证了他们的方法，并发现其可以提高DML模型的泛化能力。<details>
<summary>Abstract</summary>
Global average pooling (GAP) is a popular component in deep metric learning (DML) for aggregating features. Its effectiveness is often attributed to treating each feature vector as a distinct semantic entity and GAP as a combination of them. Albeit substantiated, such an explanation's algorithmic implications to learn generalizable entities to represent unseen classes, a crucial DML goal, remain unclear. To address this, we formulate GAP as a convex combination of learnable prototypes. We then show that the prototype learning can be expressed as a recursive process fitting a linear predictor to a batch of samples. Building on that perspective, we consider two batches of disjoint classes at each iteration and regularize the learning by expressing the samples of a batch with the prototypes that are fitted to the other batch. We validate our approach on 4 popular DML benchmarks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Gastrointestinal-Disease-Classification-through-Explainable-and-Cost-Sensitive-Deep-Neural-Networks-with-Supervised-Contrastive-Learning"><a href="#Gastrointestinal-Disease-Classification-through-Explainable-and-Cost-Sensitive-Deep-Neural-Networks-with-Supervised-Contrastive-Learning" class="headerlink" title="Gastrointestinal Disease Classification through Explainable and Cost-Sensitive Deep Neural Networks with Supervised Contrastive Learning"></a>Gastrointestinal Disease Classification through Explainable and Cost-Sensitive Deep Neural Networks with Supervised Contrastive Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07603">http://arxiv.org/abs/2307.07603</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dibya404/gastrointestinal-disease-classification-through-explainable-and-cost-sensitive-dnn-with-scl">https://github.com/dibya404/gastrointestinal-disease-classification-through-explainable-and-cost-sensitive-dnn-with-scl</a></li>
<li>paper_authors: Dibya Nath, G. M. Shahariar</li>
<li>for: 这篇论文是为了开发一种基于深度卷积神经网络和可读性学习的肠胃疾病分类方法。</li>
<li>methods: 该方法利用了Cost-sensitive预训练的深度卷积神经网络架构，并采用了监督式对照学习来学习疾病相关的特征。此外，该方法还包括了Gradient-based的可读性技术，以提高模型的解释性。</li>
<li>results: 经过广泛的实验和比较，该方法能够实现高精度的肠胃疾病分类，同时具有Robustness和解释性。<details>
<summary>Abstract</summary>
Gastrointestinal diseases pose significant healthcare chall-enges as they manifest in diverse ways and can lead to potential complications. Ensuring precise and timely classification of these diseases is pivotal in guiding treatment choices and enhancing patient outcomes. This paper introduces a novel approach on classifying gastrointestinal diseases by leveraging cost-sensitive pre-trained deep convolutional neural network (CNN) architectures with supervised contrastive learning. Our approach enables the network to learn representations that capture vital disease-related features, while also considering the relationships of similarity between samples. To tackle the challenges posed by imbalanced datasets and the cost-sensitive nature of misclassification errors in healthcare, we incorporate cost-sensitive learning. By assigning distinct costs to misclassifications based on the disease class, we prioritize accurate classification of critical conditions. Furthermore, we enhance the interpretability of our model by integrating gradient-based techniques from explainable artificial intelligence (AI). This inclusion provides valuable insights into the decision-making process of the network, aiding in understanding the features that contribute to disease classification. To assess the effectiveness of our proposed approach, we perform extensive experiments on a comprehensive gastrointestinal disease dataset, such as the Hyper-Kvasir dataset. Through thorough comparisons with existing works, we demonstrate the strong classification accuracy, robustness and interpretability of our model. We have made the implementation of our proposed approach publicly available at https://github.com/dibya404/Gastrointestinal-Disease-Classification-through-Explainable-and-Cost-Sensitive-DNN-with-SCL
</details>
<details>
<summary>摘要</summary>
Gastrointestinal diseases pose significant healthcare challenges as they manifest in diverse ways and can lead to potential complications. Ensuring precise and timely classification of these diseases is crucial in guiding treatment choices and enhancing patient outcomes. This paper introduces a novel approach to classifying gastrointestinal diseases by leveraging cost-sensitive pre-trained deep convolutional neural network (CNN) architectures with supervised contrastive learning. Our approach enables the network to learn representations that capture vital disease-related features, while also considering the relationships of similarity between samples. To tackle the challenges posed by imbalanced datasets and the cost-sensitive nature of misclassification errors in healthcare, we incorporate cost-sensitive learning. By assigning distinct costs to misclassifications based on the disease class, we prioritize accurate classification of critical conditions. Furthermore, we enhance the interpretability of our model by integrating gradient-based techniques from explainable artificial intelligence (AI). This inclusion provides valuable insights into the decision-making process of the network, aiding in understanding the features that contribute to disease classification. To assess the effectiveness of our proposed approach, we perform extensive experiments on a comprehensive gastrointestinal disease dataset, such as the Hyper-Kvasir dataset. Through thorough comparisons with existing works, we demonstrate the strong classification accuracy, robustness, and interpretability of our model. We have made the implementation of our proposed approach publicly available at https://github.com/dibya404/Gastrointestinal-Disease-Classification-through-Explainable-and-Cost-Sensitive-DNN-with-SCL.
</details></li>
</ul>
<hr>
<h2 id="NIFTY-Neural-Object-Interaction-Fields-for-Guided-Human-Motion-Synthesis"><a href="#NIFTY-Neural-Object-Interaction-Fields-for-Guided-Human-Motion-Synthesis" class="headerlink" title="NIFTY: Neural Object Interaction Fields for Guided Human Motion Synthesis"></a>NIFTY: Neural Object Interaction Fields for Guided Human Motion Synthesis</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07511">http://arxiv.org/abs/2307.07511</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nilesh Kulkarni, Davis Rempe, Kyle Genova, Abhijit Kundu, Justin Johnson, David Fouhey, Leonidas Guibas</li>
<li>for: 这个论文 targets the problem of generating realistic 3D human motions interacting with objects in a scene.</li>
<li>methods: 该论文提出了一个名为Neural Interaction Fields for Trajectory sYnthesis（NIFTY）的框架，它使用了神经网络生成交互场，以及基于物体的物理约束来驱动人物动作的扩散过程，以生成更加真实和可信的人物动作。</li>
<li>results: 该论文通过使用自动生成的 sintetic数据和NIFTY框架，实现了更加真实和可信的人物动作Synthesize，包括坐下和抬起几种对象的动作。这些动作质量和成功完成率都高于其他方法。<details>
<summary>Abstract</summary>
We address the problem of generating realistic 3D motions of humans interacting with objects in a scene. Our key idea is to create a neural interaction field attached to a specific object, which outputs the distance to the valid interaction manifold given a human pose as input. This interaction field guides the sampling of an object-conditioned human motion diffusion model, so as to encourage plausible contacts and affordance semantics. To support interactions with scarcely available data, we propose an automated synthetic data pipeline. For this, we seed a pre-trained motion model, which has priors for the basics of human movement, with interaction-specific anchor poses extracted from limited motion capture data. Using our guided diffusion model trained on generated synthetic data, we synthesize realistic motions for sitting and lifting with several objects, outperforming alternative approaches in terms of motion quality and successful action completion. We call our framework NIFTY: Neural Interaction Fields for Trajectory sYnthesis.
</details>
<details>
<summary>摘要</summary>
我们Addressing the problem of generating realistic 3D human motions interacting with objects in a scene. Our key idea is to create a neural interaction field attached to a specific object, which outputs the distance to the valid interaction manifold given a human pose as input. This interaction field guides the sampling of an object-conditioned human motion diffusion model, so as to encourage plausible contacts and affordance semantics. To support interactions with scarce data, we propose an automated synthetic data pipeline. For this, we seed a pre-trained motion model with interaction-specific anchor poses extracted from limited motion capture data. Using our guided diffusion model trained on generated synthetic data, we synthesize realistic motions for sitting and lifting with several objects, outperforming alternative approaches in terms of motion quality and successful action completion. We call our framework NIFTY: Neural Interaction Fields for Trajectory sYnthesis.Here's the translation breakdown:* 我们 (wǒmen) - we* Addressing ( Addressing) - addressing* the problem (the problem) - the problem* of generating (of generating) - of generating* realistic 3D human motions (realistic 3D human motions) - realistic 3D human motions* interacting (interacting) - interacting* with objects (with objects) - with objects* in a scene (in a scene) - in a scene* Our key idea (Our key idea) - Our key idea* is to create (is to create) - is to create* a neural interaction field (a neural interaction field) - a neural interaction field* attached to (attached to) - attached to* a specific object (a specific object) - a specific object* which outputs (which outputs) - which outputs* the distance (the distance) - the distance* to the valid interaction manifold (to the valid interaction manifold) - to the valid interaction manifold* given (given) - given* a human pose (a human pose) - a human pose* as input (as input) - as input* This interaction field (This interaction field) - This interaction field* guides (guides) - guides* the sampling (the sampling) - the sampling* of an object-conditioned (object-conditioned) - object-conditioned* human motion diffusion model (human motion diffusion model) - human motion diffusion model* so as to encourage (so as to encourage) - so as to encourage* plausible contacts (plausible contacts) - plausible contacts* and affordance semantics (and affordance semantics) - and affordance semantics* To support interactions (To support interactions) - To support interactions* with scarce data (with scarce data) - with scarce data* we propose (we propose) - we propose* an automated synthetic data pipeline (an automated synthetic data pipeline) - an automated synthetic data pipeline* For this (For this) - For this* we seed (we seed) - we seed* a pre-trained motion model (a pre-trained motion model) - a pre-trained motion model* with interaction-specific (with interaction-specific) - with interaction-specific* anchor poses (anchor poses) - anchor poses* extracted from (extracted from) - extracted from* limited motion capture data (limited motion capture data) - limited motion capture data* Using our guided diffusion model (Using our guided diffusion model) - Using our guided diffusion model* trained on generated (trained on generated) - trained on generated* synthetic data (synthetic data) - synthetic data* we synthesize (we synthesize) - we synthesize* realistic motions (realistic motions) - realistic motions* for sitting (for sitting) - for sitting* and lifting (and lifting) - and lifting* with several objects (with several objects) - with several objects* outperforming (outperforming) - outperforming* alternative approaches (alternative approaches) - alternative approaches* in terms of motion quality (in terms of motion quality) - in terms of motion quality* and successful action completion (and successful action completion) - and successful action completion* We call our framework (We call our framework) - We call our framework* NIFTY (NIFTY) - NIFTY* Neural Interaction Fields for Trajectory sYnthesis (Neural Interaction Fields for Trajectory sYnthesis) - Neural Interaction Fields for Trajectory sYnthesis
</details></li>
</ul>
<hr>
<h2 id="Brain-Tumor-Detection-using-Convolutional-Neural-Networks-with-Skip-Connections"><a href="#Brain-Tumor-Detection-using-Convolutional-Neural-Networks-with-Skip-Connections" class="headerlink" title="Brain Tumor Detection using Convolutional Neural Networks with Skip Connections"></a>Brain Tumor Detection using Convolutional Neural Networks with Skip Connections</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07503">http://arxiv.org/abs/2307.07503</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aupam Hamran, Marzieh Vaeztourshizi, Amirhossein Esmaili, Massoud Pedram</li>
<li>for: 用CNN分类脑肿为benign和malignant两类</li>
<li>methods: 使用MRI技术，采用不同的CNN体系结构，并应用扩展和深化网络，以及添加跳过连接等优化技术以提高网络的准确率</li>
<li>results: 结果表明，一些优化技术可以judiciously用于超越基eline CNN模型Note: “judiciously” is a bit of a tricky word to translate, but I’ve translated it as “可以judiciously用于” (can be used judiciously) to convey the idea that the optimization techniques can be selectively applied to achieve better results.<details>
<summary>Abstract</summary>
In this paper, we present different architectures of Convolutional Neural Networks (CNN) to analyze and classify the brain tumors into benign and malignant types using the Magnetic Resonance Imaging (MRI) technique. Different CNN architecture optimization techniques such as widening and deepening of the network and adding skip connections are applied to improve the accuracy of the network. Results show that a subset of these techniques can judiciously be used to outperform a baseline CNN model used for the same purpose.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了不同类型的卷积神经网络（CNN），用于通过磁共振成像（MRI）技术分类脑肿为非恶性和恶性两类。不同的CNN建立优化技术，如宽化和深化网络以及添加跳过连接，用于提高网络的准确性。结果表明，一些这些技术可以有效地用于超越基eline CNN模型，用于同一目的。Here's a word-for-word translation of the text using Traditional Chinese characters:在这篇论文中，我们介绍了不同类型的卷积神经网络（CNN），用于通过磁共振成像（MRI）技术分类脑肿为非恶性和恶性两类。不同的CNN建立优化技术，如宽化和深化网络以及添加跳过连接，用于提高网络的准确性。结果表明，一些这些技术可以有效地用于超越基eline CNN模型，用于同一目的。
</details></li>
</ul>
<hr>
<h2 id="TALL-Thumbnail-Layout-for-Deepfake-Video-Detection"><a href="#TALL-Thumbnail-Layout-for-Deepfake-Video-Detection" class="headerlink" title="TALL: Thumbnail Layout for Deepfake Video Detection"></a>TALL: Thumbnail Layout for Deepfake Video Detection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07494">http://arxiv.org/abs/2307.07494</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yuting Xu, Jian Liang, Gengyun Jia, Ziming Yang, Yanhao Zhang, Ran He</li>
<li>for: 这篇论文主要应用于侦测深增伪影片（deepfake video detection）。</li>
<li>methods: 本篇论文提出了一个简单 yet effective的策略，即幕照片（Thumbnail Layout，TALL），它可以将影片幕拍成一个预先定义的布局，以保留空间和时间相依性。TALL 是无需更改现有代码的简单方法，只需要在每幕中对继承幕拍进行干扰，然后将其转换为子图排序为预先定义的布局。</li>
<li>results: 实验结果显示，TALL 和 SOTA TALL-Swin 在标准测试集和跨测试集上均有出色的表现，TALL 的 AUC 为 90.79%，而 TALL-Swin 的 AUC 为 93.43%。<details>
<summary>Abstract</summary>
The growing threats of deepfakes to society and cybersecurity have raised enormous public concerns, and increasing efforts have been devoted to this critical topic of deepfake video detection. Existing video methods achieve good performance but are computationally intensive. This paper introduces a simple yet effective strategy named Thumbnail Layout (TALL), which transforms a video clip into a pre-defined layout to realize the preservation of spatial and temporal dependencies. Specifically, consecutive frames are masked in a fixed position in each frame to improve generalization, then resized to sub-images and rearranged into a pre-defined layout as the thumbnail. TALL is model-agnostic and extremely simple by only modifying a few lines of code. Inspired by the success of vision transformers, we incorporate TALL into Swin Transformer, forming an efficient and effective method TALL-Swin. Extensive experiments on intra-dataset and cross-dataset validate the validity and superiority of TALL and SOTA TALL-Swin. TALL-Swin achieves 90.79$\%$ AUC on the challenging cross-dataset task, FaceForensics++ $\to$ Celeb-DF. The code is available at https://github.com/rainy-xu/TALL4Deepfake.
</details>
<details>
<summary>摘要</summary>
“深圳技术”的威胁对社会和网络安全引起了巨大的公众关注，而寻找深圳视频的检测方法也在不断地努力。现有的视频方法可以达到好的性能，但是 computationally intensive。这篇文章介绍了一种简单 yet effective的策略，即 Thumbnail Layout（TALL），它将视频剪辑转换为预定的布局，以保持空间和时间相互依赖关系。 Specifically, consecutive frames 是在固定位置上填充，然后resize 为子图并重新排序成预定的布局作为缩略图。TALL 是无关模型的，只需要修改一些代码。通过 incorporate TALL 到 Swin Transformer 中，我们得到了高效和有效的方法 TALL-Swin。广泛的实验表明 TALL 和 SOTA TALL-Swin 的有效性和优势。 TALL-Swin 在艰辛的 cross-dataset 任务 FaceForensics++ $\to$ Celeb-DF 上达到了 90.79% AUC。代码可以在 GitHub 上找到：https://github.com/rainy-xu/TALL4Deepfake。
</details></li>
</ul>
<hr>
<h2 id="PseudoCal-A-Source-Free-Approach-to-Unsupervised-Uncertainty-Calibration-in-Domain-Adaptation"><a href="#PseudoCal-A-Source-Free-Approach-to-Unsupervised-Uncertainty-Calibration-in-Domain-Adaptation" class="headerlink" title="PseudoCal: A Source-Free Approach to Unsupervised Uncertainty Calibration in Domain Adaptation"></a>PseudoCal: A Source-Free Approach to Unsupervised Uncertainty Calibration in Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07489">http://arxiv.org/abs/2307.07489</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dapeng Hu, Jian Liang, Xinchao Wang, Chuan-Sheng Foo</li>
<li>for: 提高目标频率下模型的准确性</li>
<li>methods: 使用 PseudoCal 方法，依据无标目标数据进行准确性调整</li>
<li>results: 相比现有方法， PseudoCal 方法显示出了更低的准确性错误<details>
<summary>Abstract</summary>
Unsupervised domain adaptation (UDA) has witnessed remarkable advancements in improving the accuracy of models for unlabeled target domains. However, the calibration of predictive uncertainty in the target domain, a crucial aspect of the safe deployment of UDA models, has received limited attention. The conventional in-domain calibration method, \textit{temperature scaling} (TempScal), encounters challenges due to domain distribution shifts and the absence of labeled target domain data. Recent approaches have employed importance-weighting techniques to estimate the target-optimal temperature based on re-weighted labeled source data. Nonetheless, these methods require source data and suffer from unreliable density estimates under severe domain shifts, rendering them unsuitable for source-free UDA settings. To overcome these limitations, we propose PseudoCal, a source-free calibration method that exclusively relies on unlabeled target data. Unlike previous approaches that treat UDA calibration as a \textit{covariate shift} problem, we consider it as an unsupervised calibration problem specific to the target domain. Motivated by the factorization of the negative log-likelihood (NLL) objective in TempScal, we generate a labeled pseudo-target set that captures the structure of the real target. By doing so, we transform the unsupervised calibration problem into a supervised one, enabling us to effectively address it using widely-used in-domain methods like TempScal. Finally, we thoroughly evaluate the calibration performance of PseudoCal by conducting extensive experiments on 10 UDA methods, considering both traditional UDA settings and recent source-free UDA scenarios. The experimental results consistently demonstrate the superior performance of PseudoCal, exhibiting significantly reduced calibration error compared to existing calibration methods.
</details>
<details>
<summary>摘要</summary>
Unsupervised domain adaptation (UDA) 在提高目标领域模型的准确性方面做出了非常出色的进步。然而，目标领域模型的预测uncertainty的准确性调整，作为模型安全部署的关键方面，受到了有限的关注。传统的域内准确度调整方法（TemperatureScaling， TempScal）在域分布转移和目标领域数据缺失问题上遇到了挑战。 latest approaches use importance-weighting techniques to estimate the target-optimal temperature based on re-weighted labeled source data. 然而，这些方法需要源数据，并且在严重的域转移情况下，density estimates 不可靠，从而无法适用于源自由 UDA 设置。为了解决这些限制，我们提出了 PseudoCal，一种源自由的准确性调整方法，不依赖于源数据。与前方法不同，我们将 UDA 准确性调整视为目标域specific的无监督准确性调整问题。 Motivated by the factorization of the negative log-likelihood (NLL) objective in TempScal, we generate a labeled pseudo-target set that captures the structure of the real target. By doing so, we transform the unsupervised calibration problem into a supervised one, enabling us to effectively address it using widely-used in-domain methods like TempScal。我们进行了广泛的实验，评估 PseudoCal 的准确性调整性能，包括传统 UDA 设置以及最近的源自由 UDA 场景。实验结果 consistently demonstrate the superior performance of PseudoCal， exhibiting significantly reduced calibration error compared to existing calibration methods。
</details></li>
</ul>
<hr>
<h2 id="DreamTeacher-Pretraining-Image-Backbones-with-Deep-Generative-Models"><a href="#DreamTeacher-Pretraining-Image-Backbones-with-Deep-Generative-Models" class="headerlink" title="DreamTeacher: Pretraining Image Backbones with Deep Generative Models"></a>DreamTeacher: Pretraining Image Backbones with Deep Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07487">http://arxiv.org/abs/2307.07487</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daiqing Li, Huan Ling, Amlan Kar, David Acuna, Seung Wook Kim, Karsten Kreis, Antonio Torralba, Sanja Fidler</li>
<li>for: 本研究提出了一种自我超vised特征表示学习框架 DreamTeacher，利用生成网络进行预训练下游图像卷积体。</li>
<li>methods: 我们提出了两种知识精炼方法：1）将生成模型学习的生成特征精炼到目标图像卷积体上，作为代替大量标注数据集such as ImageNet的预训练方法；2）将生成网络中的标签精炼到目标卷积体的幂点上。</li>
<li>results: 我们进行了多种生成模型、密集预测 benchmarks 和多种预训练方法的实验研究，发现我们的 DreamTeacher 对现有的自我超vised表示学习方法进行了显著超越。 不supervised ImageNet 预训练通过 DreamTeacher  leads to significant improvements over ImageNet classification pre-training on downstream datasets, showcasing generative models and diffusion generative models specifically, as a promising approach to representation learning on large, diverse datasets without requiring manual annotation.<details>
<summary>Abstract</summary>
In this work, we introduce a self-supervised feature representation learning framework DreamTeacher that utilizes generative networks for pre-training downstream image backbones. We propose to distill knowledge from a trained generative model into standard image backbones that have been well engineered for specific perception tasks. We investigate two types of knowledge distillation: 1) distilling learned generative features onto target image backbones as an alternative to pretraining these backbones on large labeled datasets such as ImageNet, and 2) distilling labels obtained from generative networks with task heads onto logits of target backbones. We perform extensive analyses on multiple generative models, dense prediction benchmarks, and several pre-training regimes. We empirically find that our DreamTeacher significantly outperforms existing self-supervised representation learning approaches across the board. Unsupervised ImageNet pre-training with DreamTeacher leads to significant improvements over ImageNet classification pre-training on downstream datasets, showcasing generative models, and diffusion generative models specifically, as a promising approach to representation learning on large, diverse datasets without requiring manual annotation.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们介绍了一个自我超vised特征表示学习框架 DreamTeacher，该框架利用生成网络进行预训练下游图像脊梁。我们提议通过将已经训练过的生成模型中的知识注入到标准图像脊梁上来，以代替使用大量标注数据集如ImageNet进行预训练。我们 investigate了两种知识注入方法：1）将生成模型中学习的特征注入到目标图像脊梁上作为替代预训练方法，2）将生成网络中的标签注入到目标脊梁的幂点上。我们进行了多种生成模型、精度预测 bencmarks 和多种预训练方式的实验研究。我们发现，我们的 DreamTeacher 在所有自我超vised表示学习方法中显著超越了其他方法。不需要人工标注，使用 DreamTeacher 进行无监督ImageNet预训练可以在下游数据集上获得显著改进，并且在多个生成模型和扩散生成模型中都有显著的改进。
</details></li>
</ul>
<hr>
<h2 id="Multimodal-Distillation-for-Egocentric-Action-Recognition"><a href="#Multimodal-Distillation-for-Egocentric-Action-Recognition" class="headerlink" title="Multimodal Distillation for Egocentric Action Recognition"></a>Multimodal Distillation for Egocentric Action Recognition</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07483">http://arxiv.org/abs/2307.07483</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/gorjanradevski/multimodal-distillation">https://github.com/gorjanradevski/multimodal-distillation</a></li>
<li>paper_authors: Gorjan Radevski, Dusan Grujicic, Marie-Francine Moens, Matthew Blaschko, Tinne Tuytelaars</li>
<li>for: 本研究目的是为了模型手部物体互动，以提高 egocentric 视频理解性能。</li>
<li>methods: 该paper使用了 CNNs 和 Vision Transformers 等标准模型，并采用了多modal 输入模块，以提高模型性能。然而，这些多modal 模块增加了模型的复杂度，使其不适合实际应用。本研究目标是保留多modal 模型的性能，但只使用 RGB 帧作为输入。</li>
<li>results: 研究发现，使用 multimodal 教师进行教学，可以使学生模型更加准确和更加靠谱。此外，本研究还提出了一种原则正的多modal 知识塑造框架，以解决多modal 知识塑造中出现的问题。最后，研究发现了计算复杂度的减少，并证明了我们的方法可以保持高性能，同时减少输入视图的数量。<details>
<summary>Abstract</summary>
The focal point of egocentric video understanding is modelling hand-object interactions. Standard models, e.g. CNNs or Vision Transformers, which receive RGB frames as input perform well. However, their performance improves further by employing additional input modalities that provide complementary cues, such as object detections, optical flow, audio, etc. The added complexity of the modality-specific modules, on the other hand, makes these models impractical for deployment. The goal of this work is to retain the performance of such a multimodal approach, while using only the RGB frames as input at inference time. We demonstrate that for egocentric action recognition on the Epic-Kitchens and the Something-Something datasets, students which are taught by multimodal teachers tend to be more accurate and better calibrated than architecturally equivalent models trained on ground truth labels in a unimodal or multimodal fashion. We further adopt a principled multimodal knowledge distillation framework, allowing us to deal with issues which occur when applying multimodal knowledge distillation in a naive manner. Lastly, we demonstrate the achieved reduction in computational complexity, and show that our approach maintains higher performance with the reduction of the number of input views. We release our code at https://github.com/gorjanradevski/multimodal-distillation.
</details>
<details>
<summary>摘要</summary>
主要焦点是模型手object交互的 egocentric视频理解。标准模型，如CNNs或视Transformers，使用RGB帧作为输入表现良好。然而，通过添加补充的模式特征信息，如物体检测、流动、音频等，其性能可以进一步提高。然而，这些模式特征模块的附加复杂性使得这些模型在部署时不实用。我们的目标是保留多模式approach的性能，使用只RGB帧作为输入进行推理。我们示出在Epic-Kitchens和Something-Something数据集上进行 egocentric动作识别 tasks，使用多模式教师进行教育的学生比architectureEquivalent模型在单模式或多模式教学情况下更准确和更好地规范。我们进一步采用了一种原则正的多模式知识储存框架，以解决在naive manner中应用多模式知识储存时出现的问题。最后，我们表明实现的计算复杂度减少，并示出我们的方法可以在输入视图数量减少的情况下保持更高的性能。我们在https://github.com/gorjanradevski/multimodal-distillation上发布了代码。
</details></li>
</ul>
<hr>
<h2 id="Dual-Query-Multiple-Instance-Learning-for-Dynamic-Meta-Embedding-based-Tumor-Classification"><a href="#Dual-Query-Multiple-Instance-Learning-for-Dynamic-Meta-Embedding-based-Tumor-Classification" class="headerlink" title="Dual-Query Multiple Instance Learning for Dynamic Meta-Embedding based Tumor Classification"></a>Dual-Query Multiple Instance Learning for Dynamic Meta-Embedding based Tumor Classification</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07482">http://arxiv.org/abs/2307.07482</a></li>
<li>repo_url: None</li>
<li>paper_authors: Simon Holdenried-Krafft, Peter Somers, Ivonne A. Montes-Majarro, Diana Silimon, Cristina Tarín, Falko Fend, Hendrik P. A. Lensch</li>
<li>for: 这个论文主要针对的是肿瘤诊断和治疗规划中的整幕影像评估，以高Definition Magnification进行细胞分析。</li>
<li>methods: 该论文提出了一种基于嵌入模型的多例学习（MIL）管道，包括嵌入模型和聚合步骤。在嵌入模型方面，我们explore了使用最新的自我超vised预训练模型来提高MIL的普适性。在聚合步骤方面，我们提出了一种新的MIL架构，可以将MIL-注意力与相关自注意力结合使用。</li>
<li>results: 我们在三个 histopathological 数据集上进行了实验，并证明了我们的方法可以与当前状态艺技相比提高至多10%的性能。<details>
<summary>Abstract</summary>
Whole slide image (WSI) assessment is a challenging and crucial step in cancer diagnosis and treatment planning. WSIs require high magnifications to facilitate sub-cellular analysis. Precise annotations for patch- or even pixel-level classifications in the context of gigapixel WSIs are tedious to acquire and require domain experts. Coarse-grained labels, on the other hand, are easily accessible, which makes WSI classification an ideal use case for multiple instance learning (MIL). In our work, we propose a novel embedding-based Dual-Query MIL pipeline (DQ-MIL). We contribute to both the embedding and aggregation steps. Since all-purpose visual feature representations are not yet available, embedding models are currently limited in terms of generalizability. With our work, we explore the potential of dynamic meta-embedding based on cutting-edge self-supervised pre-trained models in the context of MIL. Moreover, we propose a new MIL architecture capable of combining MIL-attention with correlated self-attention. The Dual-Query Perceiver design of our approach allows us to leverage the concept of self-distillation and to combine the advantages of a small model in the context of a low data regime with the rich feature representation of a larger model. We demonstrate the superior performance of our approach on three histopathological datasets, where we show improvement of up to 10% over state-of-the-art approaches.
</details>
<details>
<summary>摘要</summary>
整幕图像（WSI）评估是癌症诊断和治疗规划中的关键步骤。WSI需要高放大以便进行细胞分析。精确的标注对patch-或甚至像素级分类在 context of gigapixel WSIs 是繁琐的和需要域专家。相比之下，粗粒标注更加容易获得，这使得WSI分类成为多例学习（MIL）的理想应用场景。在我们的工作中，我们提出了一种新的嵌入基于的双Query MIL管道（DQ-MIL）。我们对嵌入和聚合步骤做出了贡献。由于目前的视觉特征表示Model 没有通用的ALL-PURPOSE，嵌入模型因此受限于通用性。我们通过在MILCONTEXT中使用 cutting-edge self-supervised pre-trained model 的动态元 embedding来探索这一点。此外，我们还提出了一种新的MIL架构，可以结合MIL注意力和相关自注意力。我们的approach 使用 Dual-Query Perceiver 的设计，可以利用自馈采集和小模型在低数据情况下的优势，同时保留大模型的丰富特征表示。我们在三个 histopathological 数据集上进行了实验，并证明了我们的方法在 state-of-the-art 方法之上提高了10%。
</details></li>
</ul>
<hr>
<h2 id="Atlas-Based-Interpretable-Age-Prediction"><a href="#Atlas-Based-Interpretable-Age-Prediction" class="headerlink" title="Atlas-Based Interpretable Age Prediction"></a>Atlas-Based Interpretable Age Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07439">http://arxiv.org/abs/2307.07439</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sophie Starck, Yadunandan Vivekanand Kini, Jessica Johanna Maria Ritter, Rickmer Braren, Daniel Rueckert, Tamara Mueller</li>
<li>for: 这个研究旨在提高医疗评估和研究中的年龄预测精度，以检测疾病和异常年龄变化。</li>
<li>methods: 这种研究使用整体图像进行整个身体的研究，并使用Grad-CAM解释方法确定身体部位对年龄预测的影响。</li>
<li>results: 研究发现了三个关键的身体部位，即脊梁、自生肌肉和心脏区域，这三个部位对年龄预测具有最高的重要性。<details>
<summary>Abstract</summary>
Age prediction is an important part of medical assessments and research. It can aid in detecting diseases as well as abnormal ageing by highlighting the discrepancy between chronological and biological age. To gain a comprehensive understanding of age-related changes observed in various body parts, we investigate them on a larger scale by using whole-body images. We utilise the Grad-CAM interpretability method to determine the body areas most predictive of a person's age. We expand our analysis beyond individual subjects by employing registration techniques to generate population-wide interpretability maps. Furthermore, we set state-of-the-art whole-body age prediction with a model that achieves a mean absolute error of 2.76 years. Our findings reveal three primary areas of interest: the spine, the autochthonous back muscles, and the cardiac region, which exhibits the highest importance.
</details>
<details>
<summary>摘要</summary>
生长预测是医学评估和研究中非常重要的一部分。它可以帮助检测疾病以及异常年龄，并且可以预测人体各部位的年龄变化。为了更全面地了解各部位年龄变化，我们使用整体图像进行研究。我们使用Grad-CAM可读性方法来确定人体各部位年龄预测最有价值的部位。此外，我们还使用注册技术来生成人类总体可读性图。此外，我们设置了全面的整体年龄预测模型，实现了年龄差值的平均绝对误差为2.76年。我们的发现显示了三个主要的关注方向：脊梁、自生肌肉和心脏区域，这三个方向具有最高的重要性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/15/cs.CV_2023_07_15/" data-id="clly4xtc6003ivl88b633gwlz" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.LG_2023_07_15" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/15/cs.LG_2023_07_15/" class="article-date">
  <time datetime="2023-07-14T16:00:00.000Z" itemprop="datePublished">2023-07-15</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-LG/">cs.LG</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/15/cs.LG_2023_07_15/">cs.LG - 2023-07-15 18:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="MixupExplainer-Generalizing-Explanations-for-Graph-Neural-Networks-with-Data-Augmentation"><a href="#MixupExplainer-Generalizing-Explanations-for-Graph-Neural-Networks-with-Data-Augmentation" class="headerlink" title="MixupExplainer: Generalizing Explanations for Graph Neural Networks with Data Augmentation"></a>MixupExplainer: Generalizing Explanations for Graph Neural Networks with Data Augmentation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07832">http://arxiv.org/abs/2307.07832</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/jz48/mixupexplainer">https://github.com/jz48/mixupexplainer</a></li>
<li>paper_authors: Jiaxing Zhang, Dongsheng Luo, Hua Wei</li>
<li>for: This paper aims to address the issue of distribution shifting in post-hoc instance-level explanation methods for Graph Neural Networks (GNNs), which can lead to poor explanation quality in real-world applications with tight decision boundaries.</li>
<li>methods: The proposed approach is based on a generalized Graph Information Bottleneck (GIB) form that includes a label-independent graph variable, which is equivalent to the vanilla GIB. The approach also uses a graph mixup method called MixupExplainer, which has a theoretical guarantee to resolve the distribution shifting issue.</li>
<li>results: The proposed MixupExplainer approach is validated through extensive experiments on both synthetic and real-world datasets, and is shown to be effective in addressing the distribution shifting issue and improving explanation quality. Additionally, the paper provides a detailed analysis of how the proposed approach alleviates the distribution shifting issue.Here is the result in Simplified Chinese text:</li>
<li>for: 这篇论文的目的是解决图神经网络（GNNs）的后期实例级解释方法中的分布shift问题，以提高实际应用中的决策边界。</li>
<li>methods: 该方法基于一种泛化的图信息瓶颈（GIB）形式，该形式包括一个独立于标签的图变量，与普通的GIB相等。该方法还使用一种图mixup方法called MixupExplainer，该方法具有解决分布shift问题的理论保证。</li>
<li>results: 该方法通过对 sintetic和实际数据集进行了广泛的实验 validate，并证明了其能够有效地解决分布shift问题，提高解释质量。此外，论文还提供了对该方法如何缓解分布shift问题的详细分析。<details>
<summary>Abstract</summary>
Graph Neural Networks (GNNs) have received increasing attention due to their ability to learn from graph-structured data. However, their predictions are often not interpretable. Post-hoc instance-level explanation methods have been proposed to understand GNN predictions. These methods seek to discover substructures that explain the prediction behavior of a trained GNN. In this paper, we shed light on the existence of the distribution shifting issue in existing methods, which affects explanation quality, particularly in applications on real-life datasets with tight decision boundaries. To address this issue, we introduce a generalized Graph Information Bottleneck (GIB) form that includes a label-independent graph variable, which is equivalent to the vanilla GIB. Driven by the generalized GIB, we propose a graph mixup method, MixupExplainer, with a theoretical guarantee to resolve the distribution shifting issue. We conduct extensive experiments on both synthetic and real-world datasets to validate the effectiveness of our proposed mixup approach over existing approaches. We also provide a detailed analysis of how our proposed approach alleviates the distribution shifting issue.
</details>
<details>
<summary>摘要</summary>
graph neural networks (GNNs) 已经收到了越来越多的关注，因为它们可以从图结构数据中学习。然而，它们的预测通常不是可解释的。post-hoc实例级解释方法已经被提出，以解释训练好的 GNN 的预测行为。在这篇论文中，我们探讨了现有方法中的分布转移问题，该问题影响解释质量，特别是在实际数据集上 with tight decision boundaries 上。为解决这个问题，我们引入一种通用的图信息瓶颈（GIB）形式，该形式包括一个独立于标签的图变量，与普通的 GIB 相等。驱动于通用 GIB，我们提议一种图mixup方法，MixupExplainer，具有解决分布转移问题的理论保证。我们在 both synthetic 和实际数据集上进行了广泛的实验，以验证我们的提议的混合方法的效iveness。我们还提供了详细的分析，解释我们的提议如何缓解分布转移问题。
</details></li>
</ul>
<hr>
<h2 id="Minimal-Random-Code-Learning-with-Mean-KL-Parameterization"><a href="#Minimal-Random-Code-Learning-with-Mean-KL-Parameterization" class="headerlink" title="Minimal Random Code Learning with Mean-KL Parameterization"></a>Minimal Random Code Learning with Mean-KL Parameterization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07816">http://arxiv.org/abs/2307.07816</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jihao Andreas Lin, Gergely Flamich, José Miguel Hernández-Lobato</li>
<li>for: 这个论文研究了两种基于Minimal Random Code Learning（MIRACLE）的变分 Bayesian neural networks的质量行为和稳定性。</li>
<li>methods: 论文使用了一种强大的、conditionally Gaussian变分approximation来 aproximate the weight posterior $Q_{\mathbf{w}}$，并使用relative entropy coding来压缩一个weight sample从 posterior中使用 Gaussian coding distribution $P_{\mathbf{w}}$。</li>
<li>results: 作者们发现，使用 Mean-KL 参数化可以更快 converges 并保持预测性能，并且 Mean-KL 导致了更有意义的变分分布和压缩weight sample，这些sample更易受到截彩处理。<details>
<summary>Abstract</summary>
This paper studies the qualitative behavior and robustness of two variants of Minimal Random Code Learning (MIRACLE) used to compress variational Bayesian neural networks. MIRACLE implements a powerful, conditionally Gaussian variational approximation for the weight posterior $Q_{\mathbf{w}}$ and uses relative entropy coding to compress a weight sample from the posterior using a Gaussian coding distribution $P_{\mathbf{w}}$. To achieve the desired compression rate, $D_{\mathrm{KL}}[Q_{\mathbf{w}} \Vert P_{\mathbf{w}}]$ must be constrained, which requires a computationally expensive annealing procedure under the conventional mean-variance (Mean-Var) parameterization for $Q_{\mathbf{w}}$. Instead, we parameterize $Q_{\mathbf{w}}$ by its mean and KL divergence from $P_{\mathbf{w}}$ to constrain the compression cost to the desired value by construction. We demonstrate that variational training with Mean-KL parameterization converges twice as fast and maintains predictive performance after compression. Furthermore, we show that Mean-KL leads to more meaningful variational distributions with heavier tails and compressed weight samples which are more robust to pruning.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Machine-Learning-Meets-Mental-Training-–-A-Proof-of-Concept-Applied-to-Memory-Sports"><a href="#Machine-Learning-Meets-Mental-Training-–-A-Proof-of-Concept-Applied-to-Memory-Sports" class="headerlink" title="Machine Learning Meets Mental Training – A Proof of Concept Applied to Memory Sports"></a>Machine Learning Meets Mental Training – A Proof of Concept Applied to Memory Sports</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.08712">http://arxiv.org/abs/2307.08712</a></li>
<li>repo_url: None</li>
<li>paper_authors: Emanuele Regnani</li>
<li>for: 这个研究旨在结合机器学习和记忆运动两个领域，以实现一种实用的机器学习应用于记忆运动的实践。</li>
<li>methods: 该研究使用了机器学习算法，包括支持向量机和归一化树，来分析记忆运动中的数据。</li>
<li>results: 研究发现，通过使用机器学习算法，可以提高记忆运动的效果和精度，并且可以预测记忆运动的成绩。<details>
<summary>Abstract</summary>
This work aims to combine these two fields together by presenting a practical implementation of machine learning to the particular form of mental training that is the art of memory, taken in its competitive version called "Memory Sports". Such a fusion, on the one hand, strives to raise awareness about both realms, while on the other it seeks to encourage research in this mixed field as a way to, ultimately, drive forward the development of this seemingly underestimated sport.
</details>
<details>
<summary>摘要</summary>
(Simplified Chinese)这项工作 aimsto combine these two fields together by presenting a practical implementation of machine learning to the particular form of mental training that is the art of memory, taken in its competitive version called "Memory Sports". Such a fusion, on the one hand, strives to raise awareness about both realms, while on the other it seeks to encourage research in this mixed field as a way to, ultimately, drive forward the development of this seemingly underestimated sport.Note: The word " Memory Sports" is not a direct translation of "Memory Sports" in Chinese, but it is a commonly used term in the field to refer to competitive memory training.
</details></li>
</ul>
<hr>
<h2 id="Graph-Automorphism-Group-Equivariant-Neural-Networks"><a href="#Graph-Automorphism-Group-Equivariant-Neural-Networks" class="headerlink" title="Graph Automorphism Group Equivariant Neural Networks"></a>Graph Automorphism Group Equivariant Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07810">http://arxiv.org/abs/2307.07810</a></li>
<li>repo_url: None</li>
<li>paper_authors: Edward Pearce-Crump</li>
<li>for: 这种研究的目的是对任意有 $n$ 个顶点的图 $G$ 和其自动同态群 $\textrm{Aut}(G)$ 进行全面的 caracterization，即确定所有可能的 $\textrm{Aut}(G)$-equivariant neural network 的层次结构，其层次空间是 $\mathbb{R}^{n}$ 的 tensor power。</li>
<li>methods: 这种研究使用了learnable、线性、$\textrm{Aut}(G)$-equivariant层函数的 span set 来 characterize 所有可能的层次结构。</li>
<li>results: 研究发现，对于任意的图 $G$ 和 $\textrm{Aut}(G)$,存在一个 span set of matrices 表示所有可能的 learnable、线性、$\textrm{Aut}(G)$-equivariant层函数，并且这些层函数可以在标准基底上表示 $\mathbb{R}^{n}$ 中的所有 tensor power。<details>
<summary>Abstract</summary>
For any graph $G$ having $n$ vertices and its automorphism group $\textrm{Aut}(G)$, we provide a full characterisation of all of the possible $\textrm{Aut}(G)$-equivariant neural networks whose layers are some tensor power of $\mathbb{R}^{n}$. In particular, we find a spanning set of matrices for the learnable, linear, $\textrm{Aut}(G)$-equivariant layer functions between such tensor power spaces in the standard basis of $\mathbb{R}^{n}$.
</details>
<details>
<summary>摘要</summary>
Simplified Chinese:For any graph $G$ with $n$ vertices, we provide a full characterization of all possible $\textrm{Aut}(G)$-equivariant neural networks whose layers are some tensor power of $\mathbb{R}^{n}$. Specifically, we find a spanning set of matrices for the learnable, linear, $\textrm{Aut}(G)$-equivariant layer functions between such tensor power spaces in the standard basis of $\mathbb{R}^{n}$.Note: "tensor power" is not a standard term in Simplified Chinese, so I used the phrase "some tensor power" to convey the same meaning.
</details></li>
</ul>
<hr>
<h2 id="text-EFO-k-CQA-Towards-Knowledge-Graph-Complex-Query-Answering-beyond-Set-Operation"><a href="#text-EFO-k-CQA-Towards-Knowledge-Graph-Complex-Query-Answering-beyond-Set-Operation" class="headerlink" title="$\text{EFO}_{k}$-CQA: Towards Knowledge Graph Complex Query Answering beyond Set Operation"></a>$\text{EFO}_{k}$-CQA: Towards Knowledge Graph Complex Query Answering beyond Set Operation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.13701">http://arxiv.org/abs/2307.13701</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hkust-knowcomp/efok-cqa">https://github.com/hkust-knowcomp/efok-cqa</a></li>
<li>paper_authors: Hang Yin, Zihao Wang, Weizhi Fei, Yangqiu Song</li>
<li>for: 本研究的目的是提供一个涵盖多变量existential first-order queries（EFO）的完整框架，并评估这些方法在这个框架下的性能。</li>
<li>methods: 本研究使用了一些学习基本的方法，以扩展现有的知识 гра图学习方法，并将其应用到EFO queries中。</li>
<li>results: 本研究提出了一个名为 $\text{EFO}_{k}$-CQA的新数据集，并通过实验评估了这些方法在不同的查询难度下的性能。results also show that the existing dataset construction process is biased, highlighting the importance of the proposed framework.<details>
<summary>Abstract</summary>
To answer complex queries on knowledge graphs, logical reasoning over incomplete knowledge is required due to the open-world assumption. Learning-based methods are essential because they are capable of generalizing over unobserved knowledge. Therefore, an appropriate dataset is fundamental to both obtaining and evaluating such methods under this paradigm. In this paper, we propose a comprehensive framework for data generation, model training, and method evaluation that covers the combinatorial space of Existential First-order Queries with multiple variables ($\text{EFO}_{k}$). The combinatorial query space in our framework significantly extends those defined by set operations in the existing literature. Additionally, we construct a dataset, $\text{EFO}_{k}$-CQA, with 741 types of query for empirical evaluation, and our benchmark results provide new insights into how query hardness affects the results. Furthermore, we demonstrate that the existing dataset construction process is systematically biased that hinders the appropriate development of query-answering methods, highlighting the importance of our work. Our code and data are provided in~\url{https://github.com/HKUST-KnowComp/EFOK-CQA}.
</details>
<details>
<summary>摘要</summary>
“为回答知识图中复杂的查询，因为开放世界假设，需要逻辑推理 sobre 不完全的知识。学习基于方法是必要的，因为它们可以对未观察到的知识进行泛化。因此，一个适当的数据集是知识推理方法的基础，以及评估这些方法的基础。在这篇论文中，我们提出了一个完整的框架，包括数据生成、模型训练和方法评估，覆盖了多变量($\text{EFO}_{k}$)的组合空间。我们的框架中的组合查询空间significantly extends those defined by set operations in the existing literature。此外，我们构建了741种类型的查询集，并提供了empirical evaluation，我们的研究结果提供了新的视角，描述了查询困难度对结果的影响。此外，我们还发现了现有数据集构建过程存在系统性的偏见，这阻碍了适当的查询答案方法的发展，强调了我们的工作的重要性。我们的代码和数据可以在\url{https://github.com/HKUST-KnowComp/EFOK-CQA}中找到。”
</details></li>
</ul>
<hr>
<h2 id="The-Interpolating-Information-Criterion-for-Overparameterized-Models"><a href="#The-Interpolating-Information-Criterion-for-Overparameterized-Models" class="headerlink" title="The Interpolating Information Criterion for Overparameterized Models"></a>The Interpolating Information Criterion for Overparameterized Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07785">http://arxiv.org/abs/2307.07785</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liam Hodgkinson, Chris van der Heide, Robert Salomone, Fred Roosta, Michael W. Mahoney</li>
<li>for:  interpolating estimators with overparameterized models</li>
<li>methods:  using classical information criteria, Bayesian duality, and prior misspecification</li>
<li>results:  a new information criterion called Interpolating Information Criterion (IIC) that accounts for prior misspecification, geometric and spectral properties of the model, and is numerically consistent with known empirical and theoretical behavior in the overparameterized setting<details>
<summary>Abstract</summary>
The problem of model selection is considered for the setting of interpolating estimators, where the number of model parameters exceeds the size of the dataset. Classical information criteria typically consider the large-data limit, penalizing model size. However, these criteria are not appropriate in modern settings where overparameterized models tend to perform well. For any overparameterized model, we show that there exists a dual underparameterized model that possesses the same marginal likelihood, thus establishing a form of Bayesian duality. This enables more classical methods to be used in the overparameterized setting, revealing the Interpolating Information Criterion, a measure of model quality that naturally incorporates the choice of prior into the model selection. Our new information criterion accounts for prior misspecification, geometric and spectral properties of the model, and is numerically consistent with known empirical and theoretical behavior in this regime.
</details>
<details>
<summary>摘要</summary>
“模型选择问题在 interpolating estimators 的设置下被考虑，其中模型参数的数量超出数据集的大小。经典信息critérium通常在大数据 limit 下考虑模型大小，但这些 критериion 不适用于现代设置， где过参数化模型往往表现良好。我们证明，任何过参数化模型都存在一个对应的 dual underparameterized model，这两个模型具有同样的边缘分布，从而建立了一种 Bayesian duality。这使得更 classical methods 可以在过参数化 Setting 中使用，揭示了 interpolating information criterion，一种评价模型质量的指标，这个指标自然地包括先验选择的选择。我们的新信息 критериion 考虑了先验错误、模型的几何和спектраль性质，与已知的 empirical 和理论行为相一致。”
</details></li>
</ul>
<hr>
<h2 id="CatBoost-Versus-XGBoost-and-LightGBM-Developing-Enhanced-Predictive-Models-for-Zero-Inflated-Insurance-Claim-Data"><a href="#CatBoost-Versus-XGBoost-and-LightGBM-Developing-Enhanced-Predictive-Models-for-Zero-Inflated-Insurance-Claim-Data" class="headerlink" title="CatBoost Versus XGBoost and LightGBM: Developing Enhanced Predictive Models for Zero-Inflated Insurance Claim Data"></a>CatBoost Versus XGBoost and LightGBM: Developing Enhanced Predictive Models for Zero-Inflated Insurance Claim Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07771">http://arxiv.org/abs/2307.07771</a></li>
<li>repo_url: None</li>
<li>paper_authors: Banghee So</li>
<li>for: 这 paper 是为了构建投保laim predictive模型而写的，面临着高度右偏度分布的正确laims 和过多的 zeros 的挑战。</li>
<li>methods: 这 paper 使用了 zero-inflated 模型，将 traditional count model 和 binary model 结合起来，更有效地处理投保laim 数据。</li>
<li>results: 经过对两个不同的数据集的分析和比较， CatBoost 库在建立汽车投保laim frequency 模型方面表现最佳，并且发现 zero-inflated Poisson 树模型在不同数据特点下的假设对于relation between inflation probability and distribution mean 的变化会影响其性能。 I hope this helps! Let me know if you have any further questions.<details>
<summary>Abstract</summary>
In the property and casualty insurance industry, some challenges are presented in constructing claim predictive models due to a highly right-skewed distribution of positive claims with excess zeros. Traditional models, such as Poisson or negative binomial Generalized Linear Models(GLMs), frequently struggle with inflated zeros. In response to this, researchers in actuarial science have employed ``zero-inflated" models that merge a traditional count model and a binary model to address these datasets more effectively. This paper uses boosting algorithms to process insurance claim data, including zero-inflated telematics data, in order to construct claim frequency models. We evaluated and compared three popular gradient boosting libraries - XGBoost, LightGBM, and CatBoost - with the aim of identifying the most suitable library for training insurance claim data and fitting actuarial frequency models. Through a rigorous analysis of two distinct datasets, we demonstrated that CatBoost is superior in developing auto claim frequency models based on predictive performance. We also found that Zero-inflated Poisson boosted tree models, with variations in their assumptions about the relationship between inflation probability and distribution mean, outperformed others depending on data characteristics. Furthermore, by using a specific CatBoost tool, we explored the effects and interactions of different risk features on the frequency model when using telematics data.
</details>
<details>
<summary>摘要</summary>
在财产和责任保险业务中，建立投保模型时会遇到一些挑战，主要是因为投保金额呈右skewed分布，具有过多的零值。传统模型，如波尔tz或非正态泛化模型（GLM），经常遇到膨胀零值问题。为了解决这个问题， actuarial science 研究人员使用了“zero-inflated”模型，这种模型结合了传统的计数模型和二分模型，可以更有效地处理这些数据。本文使用了扩大算法来处理投保laim data，包括零Inflated telematics data，以建立投保频率模型。我们对三种popular gradient boosting库（XGBoost、LightGBM、CatBoost）进行了评估和比较，以确定最适合训练投保laim数据和适应保险频率模型的库。经过对两个不同的数据集的严格分析，我们发现CatBoost在开发汽车投保频率模型方面表现出色，并且对数据特点进行了深入的探索和分析。此外，我们还使用了CatBoost工具来探索不同风险特征对频率模型的影响，并对telematics数据进行了深入的分析。
</details></li>
</ul>
<hr>
<h2 id="randomHAR-Improving-Ensemble-Deep-Learners-for-Human-Activity-Recognition-with-Sensor-Selection-and-Reinforcement-Learning"><a href="#randomHAR-Improving-Ensemble-Deep-Learners-for-Human-Activity-Recognition-with-Sensor-Selection-and-Reinforcement-Learning" class="headerlink" title="randomHAR: Improving Ensemble Deep Learners for Human Activity Recognition with Sensor Selection and Reinforcement Learning"></a>randomHAR: Improving Ensemble Deep Learners for Human Activity Recognition with Sensor Selection and Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07770">http://arxiv.org/abs/2307.07770</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yiran Huang, Yexu Zhou, Till Riedel, Likun Fang, Michael Beigl</li>
<li>for: 提高人体动作识别（HAR）领域中的表现，并且超越其他需要手动工程Feature的建筑。</li>
<li>methods: 使用随机选择数据集中的感知器数据来训练多个深度学习模型，并使用强化学习算法来选择最佳的模型 subsets 用于运行预测。</li>
<li>results: 对六个HAR数据集进行比较，结果表明提议的方法可以超越当前状态的各种方法，包括ensembleLSTM。<details>
<summary>Abstract</summary>
Deep learning has proven to be an effective approach in the field of Human activity recognition (HAR), outperforming other architectures that require manual feature engineering. Despite recent advancements, challenges inherent to HAR data, such as noisy data, intra-class variability and inter-class similarity, remain. To address these challenges, we propose an ensemble method, called randomHAR. The general idea behind randomHAR is training a series of deep learning models with the same architecture on randomly selected sensor data from the given dataset. Besides, an agent is trained with the reinforcement learning algorithm to identify the optimal subset of the trained models that are utilized for runtime prediction. In contrast to existing work, this approach optimizes the ensemble process rather than the architecture of the constituent models. To assess the performance of the approach, we compare it against two HAR algorithms, including the current state of the art, on six HAR benchmark datasets. The result of the experiment demonstrates that the proposed approach outperforms the state-of-the-art method, ensembleLSTM.
</details>
<details>
<summary>摘要</summary>
深度学习在人动识别（HAR）领域已经证明是一种有效的方法，超过了需要人工特征工程的其他架构。 DESPITE recent advancements, HAR数据中的挑战，如噪音数据、内类变化和间类相似性，仍然存在。 To address these challenges, we propose an ensemble method, called randomHAR. The general idea behind randomHAR is to train a series of deep learning models with the same architecture on randomly selected sensor data from the given dataset. Besides, an agent is trained with the reinforcement learning algorithm to identify the optimal subset of the trained models that are utilized for runtime prediction. In contrast to existing work, this approach optimizes the ensemble process rather than the architecture of the constituent models. To assess the performance of the approach, we compare it against two HAR algorithms, including the current state of the art, on six HAR benchmark datasets. The result of the experiment demonstrates that the proposed approach outperforms the state-of-the-art method, ensembleLSTM.Note that the translation is in Simplified Chinese, which is the standard writing system used in mainland China. If you prefer Traditional Chinese, please let me know and I can provide the translation in that format as well.
</details></li>
</ul>
<hr>
<h2 id="Variational-Monte-Carlo-on-a-Budget-–-Fine-tuning-pre-trained-Neural-Wavefunctions"><a href="#Variational-Monte-Carlo-on-a-Budget-–-Fine-tuning-pre-trained-Neural-Wavefunctions" class="headerlink" title="Variational Monte Carlo on a Budget – Fine-tuning pre-trained Neural Wavefunctions"></a>Variational Monte Carlo on a Budget – Fine-tuning pre-trained Neural Wavefunctions</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.09337">http://arxiv.org/abs/2307.09337</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/mdsunivie/deeperwin">https://github.com/mdsunivie/deeperwin</a></li>
<li>paper_authors: Michael Scherbela, Leon Gerard, Philipp Grohs</li>
<li>for: 这 paper 的目的是提出一种基于深度学习的变量 Monte Carlo（DL-VMC）方法，以提高计算量化化学中的精度。</li>
<li>methods: 这 paper 使用了自我超vised wavefunction optimization 来预训练 DL-VMC 模型，并在新的分子实例上应用这个模型来获得更高的精度。</li>
<li>results:  compared to established methods such as CCSD(T)-2Z, 这 paper 的方法可以获得更高的精度和更好的相对能量。 In addition, the method can be applied to a wide variety of test systems and shows good scalability.<details>
<summary>Abstract</summary>
Obtaining accurate solutions to the Schr\"odinger equation is the key challenge in computational quantum chemistry. Deep-learning-based Variational Monte Carlo (DL-VMC) has recently outperformed conventional approaches in terms of accuracy, but only at large computational cost. Whereas in many domains models are trained once and subsequently applied for inference, accurate DL-VMC so far requires a full optimization for every new problem instance, consuming thousands of GPUhs even for small molecules. We instead propose a DL-VMC model which has been pre-trained using self-supervised wavefunction optimization on a large and chemically diverse set of molecules. Applying this model to new molecules without any optimization, yields wavefunctions and absolute energies that outperform established methods such as CCSD(T)-2Z. To obtain accurate relative energies, only few fine-tuning steps of this base model are required. We accomplish this with a fully end-to-end machine-learned model, consisting of an improved geometry embedding architecture and an existing SE(3)-equivariant model to represent molecular orbitals. Combining this architecture with continuous sampling of geometries, we improve zero-shot accuracy by two orders of magnitude compared to the state of the art. We extensively evaluate the accuracy, scalability and limitations of our base model on a wide variety of test systems.
</details>
<details>
<summary>摘要</summary>
computational quantum chemistry中的主要挑战是获取准确的Schrödinger方程解。深度学习基于变量 Monte Carlo（DL-VMC）在过去几年内已经超越了传统方法，但是它们的计算成本很大。在许多领域中，模型会被训练一次并用于推理，而DL-VMC则需要每个新问题都进行全局优化，消耗了千个GPUhs甚至对于小分子来说。我们提议一种已经预训练过的DL-VMC模型，使用自动优化的自我适应波函数优化算法来训练。对于新的分子，只需要几个精度调整步骤，就可以获得比CCSD(T)-2Z更高的精度。为了获取准确的相对能量，我们使用一个完整的端到端机器学习模型，包括改进的几何嵌入体系和现有的SE(3)-可变模型来表示分子轨道函数。将这种体系与连续样本的几何描述相结合，我们提高了零shot精度至少两个数量级比前state of the art。我们对各种测试系统进行了广泛的评估，包括准确度、可扩展性和限制。
</details></li>
</ul>
<hr>
<h2 id="Real-time-Traffic-Classification-for-5G-NSA-Encrypted-Data-Flows-With-Physical-Channel-Records"><a href="#Real-time-Traffic-Classification-for-5G-NSA-Encrypted-Data-Flows-With-Physical-Channel-Records" class="headerlink" title="Real-time Traffic Classification for 5G NSA Encrypted Data Flows With Physical Channel Records"></a>Real-time Traffic Classification for 5G NSA Encrypted Data Flows With Physical Channel Records</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07756">http://arxiv.org/abs/2307.07756</a></li>
<li>repo_url: None</li>
<li>paper_authors: Xiao Fei, Philippe Martins, Jialiang Lu</li>
<li>for: 5G-NR mobile network traffic classification for QoS management and dynamic resource allocation</li>
<li>methods: real-time encrypted traffic classification using physical channel records and decision-tree-based gradient boosting algorithms</li>
<li>results: 95% accuracy with state-of-the-art response time of 10ms using Light Gradient Boosting Machine (LGBM)<details>
<summary>Abstract</summary>
The classification of fifth-generation New-Radio (5G-NR) mobile network traffic is an emerging topic in the field of telecommunications. It can be utilized for quality of service (QoS) management and dynamic resource allocation. However, traditional approaches such as Deep Packet Inspection (DPI) can not be directly applied to encrypted data flows. Therefore, new real-time encrypted traffic classification algorithms need to be investigated to handle dynamic transmission. In this study, we examine the real-time encrypted 5G Non-Standalone (NSA) application-level traffic classification using physical channel records. Due to the vastness of their features, decision-tree-based gradient boosting algorithms are a viable approach for classification. We generate a noise-limited 5G NSA trace dataset with traffic from multiple applications. We develop a new pipeline to convert sequences of physical channel records into numerical vectors. A set of machine learning models are tested, and we propose our solution based on Light Gradient Boosting Machine (LGBM) due to its advantages in fast parallel training and low computational burden in practical scenarios. Our experiments demonstrate that our algorithm can achieve 95% accuracy on the classification task with a state-of-the-art response time as quick as 10ms.
</details>
<details>
<summary>摘要</summary>
fifth-generation New-Radio (5G-NR) 移动网络流量的分类是当前 телеcommunications 领域的一个热点话题。它可以用于质量服务（QoS）管理和动态资源分配。然而，传统的方法，如深度包检查（DPI），无法直接应用于加密数据流。因此，新的实时加密交通分类算法需要被研究以处理动态传输。在本研究中，我们研究了实时加密5G非标准应用级别（NSA）的应用级别流量分类，使用物理通道记录。由于它们的特征很多，决策树基本的泵浦搅拌算法是一种可行的方法。我们生成了5G NSA的噪声限定数据集，包括多个应用程序的流量。我们开发了一个新的管道，将物理通道记录序列转换为数字矢量。一系列机器学习模型被测试，我们提议使用光 Gradient Boosting Machine（LGBM），因为它在实际应用中具有快速并行训练和低计算负担的优点。我们的实验表明，我们的算法可以在分类任务上达到95%的准确率，并且响应时间只需10ms。
</details></li>
</ul>
<hr>
<h2 id="Learning-Expressive-Priors-for-Generalization-and-Uncertainty-Estimation-in-Neural-Networks"><a href="#Learning-Expressive-Priors-for-Generalization-and-Uncertainty-Estimation-in-Neural-Networks" class="headerlink" title="Learning Expressive Priors for Generalization and Uncertainty Estimation in Neural Networks"></a>Learning Expressive Priors for Generalization and Uncertainty Estimation in Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07753">http://arxiv.org/abs/2307.07753</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dlr-rm/bpnn">https://github.com/dlr-rm/bpnn</a></li>
<li>paper_authors: Dominik Schnaus, Jongseok Lee, Daniel Cremers, Rudolph Triebel</li>
<li>for: 本文提出了一种新的先学习方法，用于提高深度神经网络的通用化和不确定性估计。</li>
<li>methods: 本文使用了可扩展的结构化 posterior 方法，以获得具有普遍保证的通用化表达。我们的学习的先验提供了具有表达能力的概率表示，类似于 Bayesian 对 ImageNet 预训练模型的Counterparts，并且生成了非虚无的泛化 bound。</li>
<li>results: 我们通过实验证明了这种方法的效果，包括不确定性估计和通用化。<details>
<summary>Abstract</summary>
In this work, we propose a novel prior learning method for advancing generalization and uncertainty estimation in deep neural networks. The key idea is to exploit scalable and structured posteriors of neural networks as informative priors with generalization guarantees. Our learned priors provide expressive probabilistic representations at large scale, like Bayesian counterparts of pre-trained models on ImageNet, and further produce non-vacuous generalization bounds. We also extend this idea to a continual learning framework, where the favorable properties of our priors are desirable. Major enablers are our technical contributions: (1) the sums-of-Kronecker-product computations, and (2) the derivations and optimizations of tractable objectives that lead to improved generalization bounds. Empirically, we exhaustively show the effectiveness of this method for uncertainty estimation and generalization.
</details>
<details>
<summary>摘要</summary>
在这项工作中，我们提出了一种新的先学习方法，用于提高深度神经网络的泛化和不确定性估计。关键思想是利用可扩展和结构化的神经网络 posterior 作为有用的先学习模型，具有泛化保证。我们学习的先学习模型可以在大规模上表达可信度，类似于 Bayesian 对 ImageNet 预训练模型的Counterpart，并且生成非虚无效的泛化误差 bound。我们还将这个想法应用于连续学习框架，其中我们的先学习模型具有恰当的性质。主要推动因素是我们的技术贡献：（1） Kronecker 乘积计算，以及（2）对可迭代目标函数的 derivation 和优化，导致改进的泛化误差 bound。在实验中，我们详细展示了这种方法的效果，包括不确定性估计和泛化。
</details></li>
</ul>
<hr>
<h2 id="Probabilistic-Black-Box-Checking-via-Active-MDP-Learning"><a href="#Probabilistic-Black-Box-Checking-via-Active-MDP-Learning" class="headerlink" title="Probabilistic Black-Box Checking via Active MDP Learning"></a>Probabilistic Black-Box Checking via Active MDP Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07930">http://arxiv.org/abs/2308.07930</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junya Shijubo, Masaki Waga, Kohei Suenaga</li>
<li>for: 测试黑盒系统的概率性行为</li>
<li>methods: 使用活动Markov决策过程学习、概率模型检查和统计假设测试</li>
<li>results: ProbBBC比现有方法更高效，特别是对具有有限观察的系统。<details>
<summary>Abstract</summary>
We introduce a novel methodology for testing stochastic black-box systems, frequently encountered in embedded systems. Our approach enhances the established black-box checking (BBC) technique to address stochastic behavior. Traditional BBC primarily involves iteratively identifying an input that breaches the system's specifications by executing the following three phases: the learning phase to construct an automaton approximating the black box's behavior, the synthesis phase to identify a candidate counterexample from the learned automaton, and the validation phase to validate the obtained candidate counterexample and the learned automaton against the original black-box system. Our method, ProbBBC, refines the conventional BBC approach by (1) employing an active Markov Decision Process (MDP) learning method during the learning phase, (2) incorporating probabilistic model checking in the synthesis phase, and (3) applying statistical hypothesis testing in the validation phase. ProbBBC uniquely integrates these techniques rather than merely substituting each method in the traditional BBC; for instance, the statistical hypothesis testing and the MDP learning procedure exchange information regarding the black-box system's observation with one another. The experiment results suggest that ProbBBC outperforms an existing method, especially for systems with limited observation.
</details>
<details>
<summary>摘要</summary>
我们介绍一种新的黑盒系统测试方法，这种方法可以更好地捕捉黑盒系统中的随机行为。我们的方法基于传统的黑盒检查（BBC）技术，但它具有以下三个特点：1. 在学习阶段使用活动马尔可夫遇处理（MDP）学习方法，以更好地模拟黑盒系统的行为。2. 在合成阶段使用概率模型检查，以更好地找到黑盒系统的错误。3. 在验证阶段使用统计假设检测，以验证获得的候选反例和学习的黑盒系统是否符合原始黑盒系统。我们的方法不同于传统的 BBC 方法，不仅是将每种方法简单地替换成另一种。例如，统计假设检测和 MDP 学习过程之间会互相交换黑盒系统的观察信息。我们的实验结果表明，ProbBBC 比现有的方法更高效，特别是针对具有有限观察的系统。
</details></li>
</ul>
<hr>
<h2 id="On-the-Utility-Gain-of-Iterative-Bayesian-Update-for-Locally-Differentially-Private-Mechanisms"><a href="#On-the-Utility-Gain-of-Iterative-Bayesian-Update-for-Locally-Differentially-Private-Mechanisms" class="headerlink" title="On the Utility Gain of Iterative Bayesian Update for Locally Differentially Private Mechanisms"></a>On the Utility Gain of Iterative Bayesian Update for Locally Differentially Private Mechanisms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07744">http://arxiv.org/abs/2307.07744</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/hharcolezi/multi-freq-ldpy">https://github.com/hharcolezi/multi-freq-ldpy</a></li>
<li>paper_authors: Héber H. Arcolezi, Selene Cerna, Catuscia Palamidessi</li>
<li>for: 本研究 investigate了使用 Iterative Bayesian Update (IBU) 提高 private discrete distribution 估计中的实用性，使用受到 Locally Differentially Private (LDP) 机制的数据干扰。</li>
<li>methods: 我们比较了 IBU 和 Matrix Inversion (MI) 两种估计技术的性能，对七种LDP机制进行了一次数据收集和多次数据收集的比较（如 RAPPOR）。我们还在不同的实用环境下（包括 synthetic 数据和实际数据）进行了参数调整（包括 utility 度量、用户数 n、领域大小 k 和隐私参数 {\epsilon}）。</li>
<li>results: 我们的结果表明，IBU 可以在不同的场景下提高 LDP 机制的实用性，而不需要额外的隐私成本。例如，在高隐私 режи（即 {\epsilon} 小）下，IBU 可以提供更好的实用性比 MI。我们的研究为实践者提供了使用 IBU 和现有 LDP 机制进行更准确和隐私保护的数据分析的指导。此外，我们将 IBU 实现到了 state-of-the-art multi-freq-ldpy Python 包（<a target="_blank" rel="noopener" href="https://pypi.org/project/multi-freq-ldpy/%EF%BC%89%E4%B8%AD%EF%BC%8C%E5%B9%B6%E5%B0%86%E6%89%80%E6%9C%89%E6%88%91%E4%BB%AC%E7%94%A8%E4%BA%8E%E5%AE%9E%E9%AA%8C%E7%9A%84%E4%BB%A3%E7%A0%81%E5%BC%80%E6%BA%90%E4%BA%86%E4%B8%BA">https://pypi.org/project/multi-freq-ldpy/）中，并将所有我们用于实验的代码开源了为</a> tutorials。<details>
<summary>Abstract</summary>
This paper investigates the utility gain of using Iterative Bayesian Update (IBU) for private discrete distribution estimation using data obfuscated with Locally Differentially Private (LDP) mechanisms. We compare the performance of IBU to Matrix Inversion (MI), a standard estimation technique, for seven LDP mechanisms designed for one-time data collection and for other seven LDP mechanisms designed for multiple data collections (e.g., RAPPOR). To broaden the scope of our study, we also varied the utility metric, the number of users n, the domain size k, and the privacy parameter {\epsilon}, using both synthetic and real-world data. Our results suggest that IBU can be a useful post-processing tool for improving the utility of LDP mechanisms in different scenarios without any additional privacy cost. For instance, our experiments show that IBU can provide better utility than MI, especially in high privacy regimes (i.e., when {\epsilon} is small). Our paper provides insights for practitioners to use IBU in conjunction with existing LDP mechanisms for more accurate and privacy-preserving data analysis. Finally, we implemented IBU for all fourteen LDP mechanisms into the state-of-the-art multi-freq-ldpy Python package (https://pypi.org/project/multi-freq-ldpy/) and open-sourced all our code used for the experiments as tutorials.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Knowledge-Graph-Enhanced-Intelligent-Tutoring-System-Based-on-Exercise-Representativeness-and-Informativeness"><a href="#Knowledge-Graph-Enhanced-Intelligent-Tutoring-System-Based-on-Exercise-Representativeness-and-Informativeness" class="headerlink" title="Knowledge Graph Enhanced Intelligent Tutoring System Based on Exercise Representativeness and Informativeness"></a>Knowledge Graph Enhanced Intelligent Tutoring System Based on Exercise Representativeness and Informativeness</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.15076">http://arxiv.org/abs/2307.15076</a></li>
<li>repo_url: None</li>
<li>paper_authors: Linqing Li, Zhifeng Wang</li>
<li>for: 提高学生的性能，适应不同学生的学习需求</li>
<li>methods: 基于知识图建立一个权重计算模型，考虑了知识图中的多种关系，并使用了新型的神经网络诊断模型</li>
<li>results: 对两个公共教育数据集进行了广泛的实验，结果表明，该 framwork 可以更好地推荐适合学生的练习题，提高学生的性能<details>
<summary>Abstract</summary>
Presently, knowledge graph-based recommendation algorithms have garnered considerable attention among researchers. However, these algorithms solely consider knowledge graphs with single relationships and do not effectively model exercise-rich features, such as exercise representativeness and informativeness. Consequently, this paper proposes a framework, namely the Knowledge-Graph-Exercise Representativeness and Informativeness Framework, to address these two issues. The framework consists of four intricate components and a novel cognitive diagnosis model called the Neural Attentive cognitive diagnosis model. These components encompass the informativeness component, exercise representation component, knowledge importance component, and exercise representativeness component. The informativeness component evaluates the informational value of each question and identifies the candidate question set that exhibits the highest exercise informativeness. Furthermore, the skill embeddings are employed as input for the knowledge importance component. This component transforms a one-dimensional knowledge graph into a multi-dimensional one through four class relations and calculates skill importance weights based on novelty and popularity. Subsequently, the exercise representativeness component incorporates exercise weight knowledge coverage to select questions from the candidate question set for the tested question set. Lastly, the cognitive diagnosis model leverages exercise representation and skill importance weights to predict student performance on the test set and estimate their knowledge state. To evaluate the effectiveness of our selection strategy, extensive experiments were conducted on two publicly available educational datasets. The experimental results demonstrate that our framework can recommend appropriate exercises to students, leading to improved student performance.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:当前，基于知识图的推荐算法已经吸引了研究人员的广泛关注。然而，这些算法只考虑单 relate 知识图，并不能有效地模型运动rich feature，如运动 representativeness 和 informativeness。因此，本文提出了一个框架，即知识图运动 representativeness 和 informativeness 框架，以解决这两个问题。该框架包括四个复杂的组件和一个新的认知诊断模型called Neural Attentive cognitive diagnosis model。这些组件包括 informativeness 组件、运动表现组件、知识重要性组件和运动 representativeness 组件。informativeness 组件评估每个问题的信息价值，并将候选问题集定为展示最高运动 informativeness。此外，技能嵌入被用作知识重要性组件的输入。这个组件通过四种类关系将一维知识图转换为多维知识图，并计算技能重要性 weights 基于新鲜度和流行度。然后，运动 representativeness 组件将运动权重知识覆盖纳入选择候选问题集的 tested question set。最后，认知诊断模型通过运动表现和技能重要性 weights 预测学生在测试集上的表现和知识状态。为评估我们的选择策略的效果，我们在两个公共可用的教育数据集上进行了广泛的实验。实验结果表明，我们的框架可以为学生推荐适合的运动，从而提高学生的表现。
</details></li>
</ul>
<hr>
<h2 id="Promotion-Inhibition-Effects-in-Networks-A-Model-with-Negative-Probabilities"><a href="#Promotion-Inhibition-Effects-in-Networks-A-Model-with-Negative-Probabilities" class="headerlink" title="Promotion&#x2F;Inhibition Effects in Networks: A Model with Negative Probabilities"></a>Promotion&#x2F;Inhibition Effects in Networks: A Model with Negative Probabilities</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07738">http://arxiv.org/abs/2307.07738</a></li>
<li>repo_url: None</li>
<li>paper_authors: Anqi Dong, Tryphon T. Georgiou, Allen Tannenbaum</li>
<li>for: 本研究旨在解决基因网络中Edge-weight的 inverse problem，即根据签入式互连矩阵和表达水平确定Edge-weight。</li>
<li>methods: 本研究采用了P。Dirac和R。Feynman提出的“负概率”框架，并设立了可能性形式来获得Edge-weight的值。 solve this problem, the proposed optimization problem can be solved via a generalization of the well-known Sinkhorn algorithm.</li>
<li>results: 本研究得到了一种基于“负概率”框架的方法，可以在基因网络中确定Edge-weight，并且这种方法可以通过一种扩展的Sinkhorn算法来解决。<details>
<summary>Abstract</summary>
Biological networks often encapsulate promotion/inhibition as signed edge-weights of a graph. Nodes may correspond to genes assigned expression levels (mass) of respective proteins. The promotion/inhibition nature of co-expression between nodes is encoded in the sign of the corresponding entry of a sign-indefinite adjacency matrix, though the strength of such co-expression (i.e., the precise value of edge weights) cannot typically be directly measured. Herein we address the inverse problem to determine network edge-weights based on a sign-indefinite adjacency and expression levels at the nodes. While our motivation originates in gene networks, the framework applies to networks where promotion/inhibition dictates a stationary mass distribution at the nodes. In order to identify suitable edge-weights we adopt a framework of ``negative probabilities,'' advocated by P.\ Dirac and R.\ Feynman, and we set up a likelihood formalism to obtain values for the sought edge-weights. The proposed optimization problem can be solved via a generalization of the well-known Sinkhorn algorithm; in our setting the Sinkhorn-type ``diagonal scalings'' are multiplicative or inverse-multiplicative, depending on the sign of the respective entries in the adjacency matrix, with value computed as the positive root of a quadratic polynomial.
</details>
<details>
<summary>摘要</summary>
To identify suitable edge weights, we adopt a framework of "negative probabilities" advocated by P. Dirac and R. Feynman. We set up a likelihood formalism to obtain values for the sought edge weights. The proposed optimization problem can be solved using a generalization of the well-known Sinkhorn algorithm; in our setting, the Sinkhorn-type "diagonal scalings" are multiplicative or inverse-multiplicative, depending on the sign of the respective entries in the adjacency matrix, with values computed as the positive root of a quadratic polynomial.
</details></li>
</ul>
<hr>
<h2 id="Measuring-Perceived-Trust-in-XAI-Assisted-Decision-Making-by-Eliciting-a-Mental-Model"><a href="#Measuring-Perceived-Trust-in-XAI-Assisted-Decision-Making-by-Eliciting-a-Mental-Model" class="headerlink" title="Measuring Perceived Trust in XAI-Assisted Decision-Making by Eliciting a Mental Model"></a>Measuring Perceived Trust in XAI-Assisted Decision-Making by Eliciting a Mental Model</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.11765">http://arxiv.org/abs/2307.11765</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohsen Abbaspour Onari, Isel Grau, Marco S. Nobile, Yingqian Zhang</li>
<li>for: This paper aims to measure users’ perceived trust in an Explainable Artificial Intelligence (XAI) model by eliciting their mental models using Fuzzy Cognitive Maps (FCMs).</li>
<li>methods: The paper uses an interpretable Machine Learning (ML) model to classify suspected COVID-19 patients and then evaluates the impact of interpretations on perceived trust through a survey of Medical Experts’ (MEs) explanation satisfaction attributes. Fuzzy linguistic variables are used to determine the strength of influences in MEs’ mental subjectivity.</li>
<li>results: The paper obtains quantified values to measure the perceived trust of each ME and analyzes the behavior of MEs in completing diagnostic tasks based on the quantified values. The results show that the quantified values can determine whether MEs trust or distrust the XAI model.<details>
<summary>Abstract</summary>
This empirical study proposes a novel methodology to measure users' perceived trust in an Explainable Artificial Intelligence (XAI) model. To do so, users' mental models are elicited using Fuzzy Cognitive Maps (FCMs). First, we exploit an interpretable Machine Learning (ML) model to classify suspected COVID-19 patients into positive or negative cases. Then, Medical Experts' (MEs) conduct a diagnostic decision-making task based on their knowledge and then prediction and interpretations provided by the XAI model. In order to evaluate the impact of interpretations on perceived trust, explanation satisfaction attributes are rated by MEs through a survey. Then, they are considered as FCM's concepts to determine their influences on each other and, ultimately, on the perceived trust. Moreover, to consider MEs' mental subjectivity, fuzzy linguistic variables are used to determine the strength of influences. After reaching the steady state of FCMs, a quantified value is obtained to measure the perceived trust of each ME. The results show that the quantified values can determine whether MEs trust or distrust the XAI model. We analyze this behavior by comparing the quantified values with MEs' performance in completing diagnostic tasks.
</details>
<details>
<summary>摘要</summary>
Translation Notes:* "empirical study" is translated as "实验研究" (shí yàn yán jí)* "perceived trust" is translated as "感知的信任" (gǎn zhī de xìn ràng)* "Fuzzy Cognitive Maps" is translated as "模糊认知地图" (mó huang gòu zhī dì tú)* "Medical Experts" is translated as "医学专家" (yī xué zhù jià)* "diagnostic decision-making task" is translated as "诊断决策任务" (shòu yán jì suī zhèng yì)* "explanation satisfaction attributes" is translated as "解释满意属性" (jiě jie cháng zhì fù xìng)* "fuzzy linguistic variables" is translated as "模糊语言变量" (mó huang yǔ yán biàn zhì)* "quantified value" is translated as "量化值" (liàng zhì yù)* "perceived trust of each ME" is translated as "每位ME的感知信任" (mēi zhì ME de gǎn zhī xìn ràng)
</details></li>
</ul>
<hr>
<h2 id="Fast-Adaptation-with-Bradley-Terry-Preference-Models-in-Text-To-Image-Classification-and-Generation"><a href="#Fast-Adaptation-with-Bradley-Terry-Preference-Models-in-Text-To-Image-Classification-and-Generation" class="headerlink" title="Fast Adaptation with Bradley-Terry Preference Models in Text-To-Image Classification and Generation"></a>Fast Adaptation with Bradley-Terry Preference Models in Text-To-Image Classification and Generation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.07929">http://arxiv.org/abs/2308.07929</a></li>
<li>repo_url: None</li>
<li>paper_authors: Victor Gallego</li>
<li>for: 这篇论文的目的是如何将大型多modal模型（如CLIP和Stable Diffusion）进行特定任务或偏好的个性化。</li>
<li>methods: 本研究使用布莱德利-泰勒喜好模型（Bradley-Terry preference model）开发了一种快速适应方法，将原始模型迅速微调，只需少量的示例和计算资源。</li>
<li>results: 实验结果显示了这个框架在不同的多modal文本和图像理解领域中的能力，包括喜好预测和生成任务。<details>
<summary>Abstract</summary>
Recently, large multimodal models, such as CLIP and Stable Diffusion have experimented tremendous successes in both foundations and applications. However, as these models increase in parameter size and computational requirements, it becomes more challenging for users to personalize them for specific tasks or preferences. In this work, we address the problem of adapting the previous models towards sets of particular human preferences, aligning the retrieved or generated images with the preferences of the user. We leverage the Bradley-Terry preference model to develop a fast adaptation method that efficiently fine-tunes the original model, with few examples and with minimal computing resources. Extensive evidence of the capabilities of this framework is provided through experiments in different domains related to multimodal text and image understanding, including preference prediction as a reward model, and generation tasks.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="A-Nearly-Linear-Time-Algorithm-for-Structured-Support-Vector-Machines"><a href="#A-Nearly-Linear-Time-Algorithm-for-Structured-Support-Vector-Machines" class="headerlink" title="A Nearly-Linear Time Algorithm for Structured Support Vector Machines"></a>A Nearly-Linear Time Algorithm for Structured Support Vector Machines</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07735">http://arxiv.org/abs/2307.07735</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/ljinstat/Structured_Data_Random_Features_for_Large-Scale_Kernel_Machines">https://github.com/ljinstat/Structured_Data_Random_Features_for_Large-Scale_Kernel_Machines</a></li>
<li>paper_authors: Yuzhou Gu, Zhao Song, Lichen Zhang</li>
<li>for:  quadratic programming with low-rank factorization or low-treewidth, and a small number of linear constraints</li>
<li>methods:  nearly-linear time algorithm</li>
<li>results:  nearly-linear time algorithms for low-treewidth or low-rank SVMs<details>
<summary>Abstract</summary>
Quadratic programming is a fundamental problem in the field of convex optimization. Many practical tasks can be formulated as quadratic programming, for example, the support vector machine (SVM). Linear SVM is one of the most popular tools over the last three decades in machine learning before deep learning method dominating.   In general, a quadratic program has input size $\Theta(n^2)$ (where $n$ is the number of variables), thus takes $\Omega(n^2)$ time to solve. Nevertheless, quadratic programs coming from SVMs has input size $O(n)$, allowing the possibility of designing nearly-linear time algorithms. Two important classes of SVMs are programs admitting low-rank kernel factorizations and low-treewidth programs. Low-treewidth convex optimization has gained increasing interest in the past few years (e.g.~linear programming [Dong, Lee and Ye 2021] and semidefinite programming [Gu and Song 2022]). Therefore, an important open question is whether there exist nearly-linear time algorithms for quadratic programs with these nice structures.   In this work, we provide the first nearly-linear time algorithm for solving quadratic programming with low-rank factorization or low-treewidth, and a small number of linear constraints. Our results imply nearly-linear time algorithms for low-treewidth or low-rank SVMs.
</details>
<details>
<summary>摘要</summary>
quadratic programming 是 convex optimization 领域中的基本问题。许多实际任务可以被формализова为quadratic programming，例如支持向量机器（SVM）。线性SVM 是过去三十年最受欢迎的机器学习工具之一，直到深度学习方法成为主流。  在一般情况下，quadratic program 的输入大小为 $\Theta(n^2)$（where $n$ 是变数的数量），因此需要 $\Omega(n^2)$ 时间来解决。然而，从 SVM 中获得的quadratic program 的输入大小为 $O(n)$，这使得可能设计近似线性时间的算法。两个重要的 SVM 类别是允许低矩阵kernel factorization 和低树几何 programme。低树几何 convex optimization 在过去几年内（例如线性程度 [Dong, Lee 和 Ye 2021] 和对偶定理程度 [Gu 和 Song 2022]）获得了增加的关注。因此，一个重要的开问是是否存在近似线性时间的算法 для quadratic program  WITH low-rank factorization 或 low-treewidth。在这个工作中，我们提供了第一个 near-linear time algorithm for solving quadratic programming with low-rank factorization or low-treewidth, 和一小数量的线性几何。我们的结果意味着 near-linear time algorithms for low-treewidth 或 low-rank SVMs.
</details></li>
</ul>
<hr>
<h2 id="Towards-Optimal-Neural-Networks-the-Role-of-Sample-Splitting-in-Hyperparameter-Selection"><a href="#Towards-Optimal-Neural-Networks-the-Role-of-Sample-Splitting-in-Hyperparameter-Selection" class="headerlink" title="Towards Optimal Neural Networks: the Role of Sample Splitting in Hyperparameter Selection"></a>Towards Optimal Neural Networks: the Role of Sample Splitting in Hyperparameter Selection</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07726">http://arxiv.org/abs/2307.07726</a></li>
<li>repo_url: None</li>
<li>paper_authors: Shijin Gong, Xinyu Zhang</li>
<li>for: 理解神经网络模型的效iveness</li>
<li>methods: 通过sample splitting的实践来找到优化hyperparameters的方法</li>
<li>results: 实验结果证明了这种方法可以使神经网络模型的预测风险下降到最低Translation:</li>
<li>for: Understanding the effectiveness of neural network models</li>
<li>methods: By practicing sample splitting to optimize hyperparameters</li>
<li>results: Experimental results prove that this method can minimize the prediction risk of neural network models<details>
<summary>Abstract</summary>
When artificial neural networks have demonstrated exceptional practical success in a variety of domains, investigations into their theoretical characteristics, such as their approximation power, statistical properties, and generalization performance, have made significant strides. In this paper, we construct a novel theory for understanding the effectiveness of neural networks by discovering the mystery underlying a common practice during neural network model construction: sample splitting. Our theory demonstrates that, the optimal hyperparameters derived from sample splitting can enable a neural network model that asymptotically minimizes the prediction risk. We conduct extensive experiments across different application scenarios and network architectures, and the results manifest our theory's effectiveness.
</details>
<details>
<summary>摘要</summary></li>
</ul>
</details>


<hr>
<h2 id="Visual-Analytics-For-Machine-Learning-A-Data-Perspective-Survey"><a href="#Visual-Analytics-For-Machine-Learning-A-Data-Perspective-Survey" class="headerlink" title="Visual Analytics For Machine Learning: A Data Perspective Survey"></a>Visual Analytics For Machine Learning: A Data Perspective Survey</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07712">http://arxiv.org/abs/2307.07712</a></li>
<li>repo_url: None</li>
<li>paper_authors: Junpeng Wang, Shixia Liu, Wei Zhang</li>
<li>for: 本文是一份系统性的回顾，探讨过去十年内关于机器学习（ML）模型的可视化（VIS）研究。</li>
<li>methods: 本文分类了常见的机器学习模型处理的数据类型为五种，解释每种类型的特点，并提及对其学习适应的机器学习模型。</li>
<li>results: 对143篇评估的论文进行分析，发现这些论文在不同的ML管道阶段和数据类型上进行了六种任务，并对未来研究方向做出预测。<details>
<summary>Abstract</summary>
The past decade has witnessed a plethora of works that leverage the power of visualization (VIS) to interpret machine learning (ML) models. The corresponding research topic, VIS4ML, keeps growing at a fast pace. To better organize the enormous works and shed light on the developing trend of VIS4ML, we provide a systematic review of these works through this survey. Since data quality greatly impacts the performance of ML models, our survey focuses specifically on summarizing VIS4ML works from the data perspective. First, we categorize the common data handled by ML models into five types, explain the unique features of each type, and highlight the corresponding ML models that are good at learning from them. Second, from the large number of VIS4ML works, we tease out six tasks that operate on these types of data (i.e., data-centric tasks) at different stages of the ML pipeline to understand, diagnose, and refine ML models. Lastly, by studying the distribution of 143 surveyed papers across the five data types, six data-centric tasks, and their intersections, we analyze the prospective research directions and envision future research trends.
</details>
<details>
<summary>摘要</summary>
过去一个 décennie  hath witnessed a plethora of works that leveraged the power of visualization (VIS) to interpret machine learning (ML) models. The corresponding research topic, VIS4ML, hath been growing at a fast pace. To better organize the enormous works and shed light on the developing trend of VIS4ML, we provide a systematic review of these works through this survey. Since data quality greatly impacts the performance of ML models, our survey focuses specifically on summarizing VIS4ML works from the data perspective. First, we categorize the common data handled by ML models into five types, explain the unique features of each type, and highlight the corresponding ML models that are good at learning from them. Second, from the large number of VIS4ML works, we tease out six tasks that operate on these types of data (i.e., data-centric tasks) at different stages of the ML pipeline to understand, diagnose, and refine ML models. Lastly, by studying the distribution of 143 surveyed papers across the five data types, six data-centric tasks, and their intersections, we analyze the prospective research directions and envision future research trends.
</details></li>
</ul>
<hr>
<h2 id="Identification-of-Stochasticity-by-Matrix-decomposition-Applied-on-Black-Hole-Data"><a href="#Identification-of-Stochasticity-by-Matrix-decomposition-Applied-on-Black-Hole-Data" class="headerlink" title="Identification of Stochasticity by Matrix-decomposition: Applied on Black Hole Data"></a>Identification of Stochasticity by Matrix-decomposition: Applied on Black Hole Data</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07703">http://arxiv.org/abs/2307.07703</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sunilvengalil/ts_analysis_pca_eig">https://github.com/sunilvengalil/ts_analysis_pca_eig</a></li>
<li>paper_authors: Sai Pradeep Chakka, Sunil Kumar Vengalil, Neelam Sinha</li>
<li>for: 本研究旨在提出一种两路矩阵分解法，用于分类时间序列数据。</li>
<li>methods: 该算法使用了两种不同的技术：单值分解（SVD）和主成分分析（PCA）。</li>
<li>results: 对synthetic数据进行了分析，并在实验中使用了SVM进行分类。结果显示，在12个时间类中，SVD-label和PCA-label之间存在高度的一致性。<details>
<summary>Abstract</summary>
Timeseries classification as stochastic (noise-like) or non-stochastic (structured), helps understand the underlying dynamics, in several domains. Here we propose a two-legged matrix decomposition-based algorithm utilizing two complementary techniques for classification. In Singular Value Decomposition (SVD) based analysis leg, we perform topological analysis (Betti numbers) on singular vectors containing temporal information, leading to SVD-label. Parallely, temporal-ordering agnostic Principal Component Analysis (PCA) is performed, and the proposed PCA-derived features are computed. These features, extracted from synthetic timeseries of the two labels, are observed to map the timeseries to a linearly separable feature space. Support Vector Machine (SVM) is used to produce PCA-label. The proposed methods have been applied to synthetic data, comprising 41 realisations of white-noise, pink-noise (stochastic), Logistic-map at growth-rate 4 and Lorentz-system (non-stochastic), as proof-of-concept. Proposed algorithm is applied on astronomical data: 12 temporal-classes of timeseries of black hole GRS 1915+105, obtained from RXTE satellite with average length 25000. For a given timeseries, if SVD-label and PCA-label concur, then the label is retained; else deemed "Uncertain". Comparison of obtained results with those in literature are presented. It's found that out of 12 temporal classes of GRS 1915+105, concurrence between SVD-label and PCA-label is obtained on 11 of them.
</details>
<details>
<summary>摘要</summary>
时间序列分类为随机（噪声如的）或非随机（结构化），可以帮助我们理解时间序列的下面动力学。我们提出了一种基于两个脚本的矩阵分解算法，利用两种 complementary 技术进行分类。在 Singular Value Decomposition（SVD）基础分析脚本中，我们进行了 topological 分析（Betti 数）于时间信号中的特征向量，从而获得 SVD-标签。同时，无关于时间顺序的 Principal Component Analysis（PCA）被应用，并计算了提案的 PCA-derived 特征。这些特征从 synthetic 时间序列中提取出来，并在线性分离特征空间中映射时间序列。使用 Support Vector Machine（SVM）生成 PCA-标签。我们对 synthetic 数据进行了证明，包括41个实现 white-noise、pink-noise（随机）、Logistic-map 增长率4和 Lorentz-system（非随机）。我们还应用了这种方法于天文数据：RXTE 卫星上的 12 个 temporal 类时间序列，每个时间序列的平均长度为 25000。对于每个时间序列，如果 SVD-标签和 PCA-标签协调，则保留标签；否则被称为 "Uncertain"。我们对得到的结果与文献中的结果进行了比较，发现 GRS 1915+105 黑洞的 11 个 temporal 类时间序列中，SVD-标签和 PCA-标签协调。
</details></li>
</ul>
<hr>
<h2 id="NeurASP-Embracing-Neural-Networks-into-Answer-Set-Programming"><a href="#NeurASP-Embracing-Neural-Networks-into-Answer-Set-Programming" class="headerlink" title="NeurASP: Embracing Neural Networks into Answer Set Programming"></a>NeurASP: Embracing Neural Networks into Answer Set Programming</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07700">http://arxiv.org/abs/2307.07700</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zhun Yang, Adam Ishay, Joohyung Lee</li>
<li>for: 该论文是为了推动Answer Set Programming（ASP）和神经网络之间的 integración，提供了一种简单扩展的Answer Set Programming（NeurASP）。</li>
<li>methods: 该论文使用神经网络输出作为Answer Set Programming中的概率分布，从而实现了sub-symbolic和symbolic计算的集成。它还展示了如何使用预训练神经网络在符号计算中使用ASP规则，以及如何使用ASP规则来训练神经网络。</li>
<li>results: NeurASP可以使用预训练神经网络来改善神经网络的识别结果，并且可以使用ASP规则来帮助神经网络学习从数据中的隐式相关性和Explicit complex semantic constraints。<details>
<summary>Abstract</summary>
We present NeurASP, a simple extension of answer set programs by embracing neural networks. By treating the neural network output as the probability distribution over atomic facts in answer set programs, NeurASP provides a simple and effective way to integrate sub-symbolic and symbolic computation. We demonstrate how NeurASP can make use of a pre-trained neural network in symbolic computation and how it can improve the neural network's perception result by applying symbolic reasoning in answer set programming. Also, NeurASP can be used to train a neural network better by training with ASP rules so that a neural network not only learns from implicit correlations from the data but also from the explicit complex semantic constraints expressed by the rules.
</details>
<details>
<summary>摘要</summary>
我们介绍NeurASP，一个简单扩展Answer Set Programs（ASP）的方法，通过将神经网络输出视为Answer Set Programs中的原子事实的概率分布。NeurASP提供了一个简单而有效的方式将子符号 computations和符号 computations融合。我们显示了NeurASP如何使用预训练的神经网络在符号计算中使用，以及如何运用符号推理来改善神经网络的认知结果。此外，NeurASP还可以用来训练神经网络，使其不仅从数据中学习隐含的相互关联，而且还从ASP规则中获得明确的复杂 semantic constraint。
</details></li>
</ul>
<hr>
<h2 id="The-Growth-of-E-Bike-Use-A-Machine-Learning-Approach"><a href="#The-Growth-of-E-Bike-Use-A-Machine-Learning-Approach" class="headerlink" title="The Growth of E-Bike Use: A Machine Learning Approach"></a>The Growth of E-Bike Use: A Machine Learning Approach</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.02034">http://arxiv.org/abs/2308.02034</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aditya Gupta, Samarth Chitgopekar, Alexander Kim, Joseph Jiang, Megan Wang, Christopher Grattoni<br>for: 这个研究的目的是为美国政策制定者提供关于电动自行车（e-bike）的信息，以便他们能够更好地了解电动自行车的增长和影响，并在制定可持续能源计划时做出更 Informed decisions。methods: 这个研究使用了ARIMA模型和一种监管机器学习算法来预测电动自行车销售量的增长。此外，研究还使用Random Forest回归模型来分析电动自行车销售增长的因素。results: 研究发现，电动自行车在美国的销售量将在2025年和2028年分别达到130万和2113万个单位。此外，研究还发现，电动自行车的使用会减少碳排放和提高体能消耗。在2022年，电动自行车的使用已经减少了15737.82吨碳排放和716630.727千卡ло里。<details>
<summary>Abstract</summary>
We present our work on electric bicycles (e-bikes) and their implications for policymakers in the United States. E-bikes have gained significant popularity as a fast and eco-friendly transportation option. As we strive for a sustainable energy plan, understanding the growth and impact of e-bikes is crucial for policymakers. Our mathematical modeling offers insights into the value of e-bikes and their role in the future. Using an ARIMA model, a supervised machine-learning algorithm, we predicted the growth of e-bike sales in the U.S. Our model, trained on historical sales data from January 2006 to December 2022, projected sales of 1.3 million units in 2025 and 2.113 million units in 2028. To assess the factors contributing to e-bike usage, we employed a Random Forest regression model. The most significant factors influencing e-bike sales growth were disposable personal income and popularity. Furthermore, we examined the environmental and health impacts of e-bikes. Through Monte Carlo simulations, we estimated the reduction in carbon emissions due to e-bike use and the calories burned through e-biking. Our findings revealed that e-bike usage in the U.S. resulted in a reduction of 15,737.82 kilograms of CO2 emissions in 2022. Additionally, e-bike users burned approximately 716,630.727 kilocalories through their activities in the same year. Our research provides valuable insights for policymakers, emphasizing the potential of e-bikes as a sustainable transportation solution. By understanding the growth factors and quantifying the environmental and health benefits, policymakers can make informed decisions about integrating e-bikes into future energy and transportation strategies.
</details>
<details>
<summary>摘要</summary>
我们对电动自行车（e-bike）的研究和其对政策 makers 在美国的影响进行了报告。电动自行车在快速和环保交通方面受到了广泛的欢迎，随着我们努力实现可持续能源规划，理解电动自行车的增长和影响非常重要。我们使用 ARIMA 模型和一种监管机器学习算法来预测电动自行车销售在美国的增长。我们的模型，基于2006年1月至2022年12月的历史销售数据，预测在2025年销售130万部电动自行车，在2028年销售2113万部。为了评估电动自行车使用的因素，我们使用Random Forest回归模型。最主要影响电动自行车销售增长的因素是可 dispose 个人收入和流行度。此外，我们还研究了电动自行车对环境和健康的影响。通过蒙地卡罗模拟，我们估算了电动自行车使用在美国的碳排放减少和热量燃烧。我们的发现表明，在2022年，电动自行车在美国的使用已经减少了15737.82公斤的碳排放，同时电动自行车用户通过其活动燃烧了约716630.727公利 kalories。我们的研究为政策 makers 提供了有价值的见解，强调电动自行车作为可持续交通解决方案的潜在价值。通过理解电动自行车增长因素和评估环境和健康的影响，政策 makers 可以做出 Informed 的决策，将电动自行车纳入未来能源和交通战略中。
</details></li>
</ul>
<hr>
<h2 id="Reducing-operator-complexity-in-Algebraic-Multigrid-with-Machine-Learning-Approaches"><a href="#Reducing-operator-complexity-in-Algebraic-Multigrid-with-Machine-Learning-Approaches" class="headerlink" title="Reducing operator complexity in Algebraic Multigrid with Machine Learning Approaches"></a>Reducing operator complexity in Algebraic Multigrid with Machine Learning Approaches</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07695">http://arxiv.org/abs/2307.07695</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ru Huang, Kai Chang, Huan He, Ruipeng Li, Yuanzhe Xi</li>
<li>for:  solves parametric partial differential equation (PDE) problems with increasing operator complexity.</li>
<li>methods:  utilizes neural networks (NNs) combined with smooth test vectors from multigrid eigenvalue problems.</li>
<li>results:  reduces the complexity of coarse-grid operators while maintaining overall AMG convergence.Here’s the simplified Chinese text:</li>
<li>for: 用于解决参数部分 diferencial equation (PDE) 问题中增加运算 complexity.</li>
<li>methods: 利用神经网络 (NNs) 与多普逊值问题中的畅通测试向量结合.</li>
<li>results: 降低粗网操作符的复杂性，保持总的 AMG  converges.<details>
<summary>Abstract</summary>
We propose a data-driven and machine-learning-based approach to compute non-Galerkin coarse-grid operators in algebraic multigrid (AMG) methods, addressing the well-known issue of increasing operator complexity. Guided by the AMG theory on spectrally equivalent coarse-grid operators, we have developed novel ML algorithms that utilize neural networks (NNs) combined with smooth test vectors from multigrid eigenvalue problems. The proposed method demonstrates promise in reducing the complexity of coarse-grid operators while maintaining overall AMG convergence for solving parametric partial differential equation (PDE) problems. Numerical experiments on anisotropic rotated Laplacian and linear elasticity problems are provided to showcase the performance and compare with existing methods for computing non-Galerkin coarse-grid operators.
</details>
<details>
<summary>摘要</summary>
我们提出了一种基于数据驱动和机器学习的方法，用于在数学多普逊（AMG）方法中计算非加尔erkin粗积算子，解决了常见的算子复杂性问题。我们根据AMG理论中的特征相似粗积算子，开发了一种新的机器学习算法，利用神经网络（NN）和多普逊域值问题中的平滑测试向量。我们的方法可以减少粗积算子的复杂性，同时保持AMG方法的总体收敛性，用于解决参数化partial differential equation（PDE）问题。我们在不同的旋转卷积 Laplacian 和线性塑性问题上进行了数值实验，以示出我们的方法的性能和与现有方法相比。
</details></li>
</ul>
<hr>
<h2 id="Creating-a-Dataset-for-High-Performance-Computing-Code-Translation-A-Bridge-Between-HPC-Fortran-and-C"><a href="#Creating-a-Dataset-for-High-Performance-Computing-Code-Translation-A-Bridge-Between-HPC-Fortran-and-C" class="headerlink" title="Creating a Dataset for High-Performance Computing Code Translation: A Bridge Between HPC Fortran and C++"></a>Creating a Dataset for High-Performance Computing Code Translation: A Bridge Between HPC Fortran and C++</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07686">http://arxiv.org/abs/2307.07686</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/bin123apple/fortran-cpp-hpc-code-translation-dataset">https://github.com/bin123apple/fortran-cpp-hpc-code-translation-dataset</a></li>
<li>paper_authors: Bin Lei, Caiwen Ding, Le Chen, Pei-Hung Lin, Chunhua Liao</li>
<li>for: 本研究准备了一个新的机器学习模型训练集，用于翻译OpenMP Fortran和C++代码。</li>
<li>methods: 为确保可靠性和实用性，该集 initially refined 使用仔细的代码相似性测试。</li>
<li>results: 我们使用量化(CodeBLEU)和质量(人类评估)方法评估该集的有效性，并发现该集可以提高大规模语言模型的翻译能力，比如无编程知识下的提升为$\mathbf{\times 5.1}$，有编程知识下的提升为$\mathbf{\times 9.9}$。这种dataset的存在可能推动高性能计算领域中的代码翻译技术的发展。该集可以在<a target="_blank" rel="noopener" href="https://github.com/bin123apple/Fortran-CPP-HPC-code-translation-dataset%E4%B8%8A%E4%B8%8B%E8%BD%BD%E3%80%82">https://github.com/bin123apple/Fortran-CPP-HPC-code-translation-dataset上下载。</a><details>
<summary>Abstract</summary>
In this study, we present a novel dataset for training machine learning models translating between OpenMP Fortran and C++ code. To ensure reliability and applicability, the dataset is initially refined using a meticulous code similarity test. The effectiveness of our dataset is assessed using both quantitative (CodeBLEU) and qualitative (human evaluation) methods. We demonstrate how this dataset can significantly improve the translation capabilities of large-scale language models, with improvements of $\mathbf{\times 5.1}$ for models with no prior coding knowledge and $\mathbf{\times 9.9}$ for models with some coding familiarity. Our work highlights the potential of this dataset to advance the field of code translation for high-performance computing. The dataset is available at https://github.com/bin123apple/Fortran-CPP-HPC-code-translation-dataset
</details>
<details>
<summary>摘要</summary>
在这项研究中，我们提供了一个新的数据集用于训练机器学习模型在OpenMP Fortran和C++代码之间翻译。为确保可靠性和实用性，我们首先使用精细的代码相似性测试进行初步纤细。我们使用代码BLEU和人类评估方法进行评估数据集的效果，并证明了该数据集可以大幅提高大规模语言模型的翻译能力，具体是$\times 5.1$ для没有编程知识的模型和$\times 9.9$ для具有一定编程经验的模型。我们的工作展示了该数据集在高性能计算领域的代码翻译技术的前进。数据集可以在https://github.com/bin123apple/Fortran-CPP-HPC-code-translation-dataset中下载。
</details></li>
</ul>
<hr>
<h2 id="Learning-Subjective-Time-Series-Data-via-Utopia-Label-Distribution-Approximation"><a href="#Learning-Subjective-Time-Series-Data-via-Utopia-Label-Distribution-Approximation" class="headerlink" title="Learning Subjective Time-Series Data via Utopia Label Distribution Approximation"></a>Learning Subjective Time-Series Data via Utopia Label Distribution Approximation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07682">http://arxiv.org/abs/2307.07682</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wenxin Xu, Hexin Jiang, Xuefeng Liang, Ying Zhou, Yin Zhao, Jie Zhang<br>for:STR tasks (Subjective time-series regression)methods:ULDA (Utopia Label Distribution Approximation)TNS (Time-slice Normal Sampling)CWL (Convolutional Weighted Loss)results:lifts the state-of-the-art performance on two STR tasks and three benchmark datasets.<details>
<summary>Abstract</summary>
Subjective time-series regression (STR) tasks have gained increasing attention recently. However, most existing methods overlook the label distribution bias in STR data, which results in biased models. Emerging studies on imbalanced regression tasks, such as age estimation and depth estimation, hypothesize that the prior label distribution of the dataset is uniform. However, we observe that the label distributions of training and test sets in STR tasks are likely to be neither uniform nor identical. This distinct feature calls for new approaches that estimate more reasonable distributions to train a fair model. In this work, we propose Utopia Label Distribution Approximation (ULDA) for time-series data, which makes the training label distribution closer to real-world but unknown (utopia) label distribution. This would enhance the model's fairness. Specifically, ULDA first convolves the training label distribution by a Gaussian kernel. After convolution, the required sample quantity at each regression label may change. We further devise the Time-slice Normal Sampling (TNS) to generate new samples when the required sample quantity is greater than the initial sample quantity, and the Convolutional Weighted Loss (CWL) to lower the sample weight when the required sample quantity is less than the initial quantity. These two modules not only assist the model training on the approximated utopia label distribution, but also maintain the sample continuity in temporal context space. To the best of our knowledge, ULDA is the first method to address the label distribution bias in time-series data. Extensive experiments demonstrate that ULDA lifts the state-of-the-art performance on two STR tasks and three benchmark datasets.
</details>
<details>
<summary>摘要</summary>
受到媒体关注的主观时序回归（STR）任务在最近几年来得到了越来越多的关注。然而，大多数现有方法忽略了STR数据中标签分布偏见，导致模型偏向。新诞听学者认为STR任务中的标签分布是均匀的，但我们发现STR任务中的训练和测试集标签分布很可能不均匀，也不是完全相同的。这种特殊特点需要新的方法来训练公正的模型。在这种情况下，我们提出了UTopia标签分布近似（ULDA）方法，用于在时序数据上训练公正的模型。ULDA方法首先将训练标签分布通过 Gaussian 核函数进行混合。在混合后，每个回归标签的样本数量可能会改变。我们还提出了时间扁平分布（TNS）和卷积权重损失（CWL）两个模块，用于生成新的样本和更正模型的训练。这两个模块不仅帮助模型在训练中使用更加公正的标签分布，还保持了样本在时间上的连续性。到目前为止，ULDA方法是首个强调STR任务中标签分布偏见的方法。我们对 STR 任务中的三个标准数据集进行了广泛的实验，结果表明ULDA方法可以超越当前的状态势。
</details></li>
</ul>
<hr>
<h2 id="Data-centric-Operational-Design-Domain-Characterization-for-Machine-Learning-based-Aeronautical-Products"><a href="#Data-centric-Operational-Design-Domain-Characterization-for-Machine-Learning-based-Aeronautical-Products" class="headerlink" title="Data-centric Operational Design Domain Characterization for Machine Learning-based Aeronautical Products"></a>Data-centric Operational Design Domain Characterization for Machine Learning-based Aeronautical Products</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07681">http://arxiv.org/abs/2307.07681</a></li>
<li>repo_url: None</li>
<li>paper_authors: Fateh Kaakai, Shridhar “Shreeder” Adibhatla, Ganesh Pai, Emmanuelle Escorihuela</li>
<li>for: 这个论文是为了提供一种初次准确地定义机器学习（ML）基于飞行器产品的操作设计域（ODD）的方法。</li>
<li>methods: 该方法是基于数据而不是场景而定义ODD，并提出了将定义ODD的参数维度和 ML 应用可能遇到的数据类型进行明确表述，以及这些数据类型对 ML 模型和系统层次结构的影响。</li>
<li>results: 该论文指出，通过这种方法可以确定 ML 模型的需求，以及系统层次结构中 ML 模型和高级系统的可能的影响，以及可能需要进行学习保障过程和系统体系设计考虑。 例如，通过使用飞行器飞行范围来说明这些概念。<details>
<summary>Abstract</summary>
We give a first rigorous characterization of Operational Design Domains (ODDs) for Machine Learning (ML)-based aeronautical products. Unlike in other application sectors (such as self-driving road vehicles) where ODD development is scenario-based, our approach is data-centric: we propose the dimensions along which the parameters that define an ODD can be explicitly captured, together with a categorization of the data that ML-based applications can encounter in operation, whilst identifying their system-level relevance and impact. Specifically, we discuss how those data categories are useful to determine: the requirements necessary to drive the design of ML Models (MLMs); the potential effects on MLMs and higher levels of the system hierarchy; the learning assurance processes that may be needed, and system architectural considerations. We illustrate the underlying concepts with an example of an aircraft flight envelope.
</details>
<details>
<summary>摘要</summary>
我们给出了机器学习（ML）基于航空产品的操作设计领域（ODD）的首次正式定义。与其他应用领域（如自动驾驶道路车辆）的ODD开发不同，我们的方法是数据中心：我们提议定义ODD参数的维度，并将ML基于应用中可能遇到的数据分类，以及这些数据的系统水平重要性和影响。specifically， we discuss how these data categories can be used to determine: the requirements needed to drive the design of ML models（MLMs）; the potential effects on MLMs and higher levels of the system hierarchy; the learning assurance processes that may be needed, and system architectural considerations. We illustrate the underlying concepts with an example of an aircraft flight envelope.Note: Please note that the translation is in Simplified Chinese, which is the standard form of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Sequence-Based-Nanobody-Antigen-Binding-Prediction"><a href="#Sequence-Based-Nanobody-Antigen-Binding-Prediction" class="headerlink" title="Sequence-Based Nanobody-Antigen Binding Prediction"></a>Sequence-Based Nanobody-Antigen Binding Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2308.01920">http://arxiv.org/abs/2308.01920</a></li>
<li>repo_url: None</li>
<li>paper_authors: Usama Sardar, Sarwan Ali, Muhammad Sohaib Ayub, Muhammad Shoaib, Khurram Bashir, Imdad Ullah Khan, Murray Patterson<br>for: This paper aims to develop a machine-learning method to predict the binding of nanobodies (Nb) to antigens based solely on sequence data.methods: The authors curated a comprehensive dataset of Nb-Antigen binding and nonbinding data and devised an embedding method based on gapped k-mers to predict binding based only on sequences of Nb and Antigen.results: The approach achieved up to 90% accuracy in binding prediction and was significantly more efficient compared to the widely-used computational docking technique.<details>
<summary>Abstract</summary>
Nanobodies (Nb) are monomeric heavy-chain fragments derived from heavy-chain only antibodies naturally found in Camelids and Sharks. Their considerably small size (~3-4 nm; 13 kDa) and favorable biophysical properties make them attractive targets for recombinant production. Furthermore, their unique ability to bind selectively to specific antigens, such as toxins, chemicals, bacteria, and viruses, makes them powerful tools in cell biology, structural biology, medical diagnostics, and future therapeutic agents in treating cancer and other serious illnesses. However, a critical challenge in nanobodies production is the unavailability of nanobodies for a majority of antigens. Although some computational methods have been proposed to screen potential nanobodies for given target antigens, their practical application is highly restricted due to their reliance on 3D structures. Moreover, predicting nanobodyantigen interactions (binding) is a time-consuming and labor-intensive task. This study aims to develop a machine-learning method to predict Nanobody-Antigen binding solely based on the sequence data. We curated a comprehensive dataset of Nanobody-Antigen binding and nonbinding data and devised an embedding method based on gapped k-mers to predict binding based only on sequences of nanobody and antigen. Our approach achieves up to 90% accuracy in binding prediction and is significantly more efficient compared to the widely-used computational docking technique.
</details>
<details>
<summary>摘要</summary>
纳诺体（Nb）是含有重链只的轻链抗体的自然存在的哺乳动物和鲨鱼中的蛋白质。它们的非常小的大小（约3-4奈米，13 kDa）和有利的生物物理性质使其成为了重点生产的目标。此外，它们可以特异性地绑定到特定抗原，如毒素、化学物质、细菌和病毒，使其成为了细胞生物、结构生物、医学诊断和未来的疾病治疗的有力工具。然而，纳诺体生产中的主要挑战是缺乏纳诺体对大多数抗原的可用性。虽然一些计算方法已经被提出来屏选纳诺体对给定抗原的可能性，但它们的实际应用受到了三维结构的限制，而且预测纳诺体-抗原交互（绑定）是一项时间consuming和劳动密集的任务。本研究旨在开发一种基于序列数据的机器学习方法，以预测纳诺体-抗原绑定。我们收集了一个完整的纳诺体-抗原绑定和非绑定数据集，并采用基于异常词的嵌入方法来预测绑定基于纳诺体和抗原的序列数据。我们的方法可以达到90%的准确率，与广泛使用的计算协同技术相比，效率明显高于。
</details></li>
</ul>
<hr>
<h2 id="Sharp-Convergence-Rates-for-Matching-Pursuit"><a href="#Sharp-Convergence-Rates-for-Matching-Pursuit" class="headerlink" title="Sharp Convergence Rates for Matching Pursuit"></a>Sharp Convergence Rates for Matching Pursuit</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07679">http://arxiv.org/abs/2307.07679</a></li>
<li>repo_url: None</li>
<li>paper_authors: Jason M. Klusowski, Jonathan W. Siegel</li>
<li>for: 本文研究了matching pursuit的基本限制，即用一个 слова库中的元素组成一个稀疏的线性组合来近似目标函数。当目标函数在字典的变化空间中时，过去几十年有很多卓越的工作获得了上下限 bounds on error of matching pursuit，但它们并不匹配。本文的主要贡献是将这个差异关系closed和获得了准确的衰减率特征。</li>
<li>methods: 本文使用了一个最差情况的字典来构建，该字典显示出了现有最佳上限 bound cannot be significantly improved。结果是，与其他greedy algorithm variants不同，matching pursuit的 converges rate是非优的并由一个certain non-linear equation的解决决定。这使得我们可以结论出任何Amount of shrinkage improve matching pursuit in the worst case.</li>
<li>results: 本文的结果是，任何Amount of shrinkage improve matching pursuit in the worst case。这意味着，无论如何选择 слова库，matching pursuit都会在最差情况下出现衰减。这与之前的研究不同，因为它们通常认为matching pursuit在某些情况下是optimal的。<details>
<summary>Abstract</summary>
We study the fundamental limits of matching pursuit, or the pure greedy algorithm, for approximating a target function by a sparse linear combination of elements from a dictionary. When the target function is contained in the variation space corresponding to the dictionary, many impressive works over the past few decades have obtained upper and lower bounds on the error of matching pursuit, but they do not match. The main contribution of this paper is to close this gap and obtain a sharp characterization of the decay rate of matching pursuit. Specifically, we construct a worst case dictionary which shows that the existing best upper bound cannot be significantly improved. It turns out that, unlike other greedy algorithm variants, the converge rate is suboptimal and is determined by the solution to a certain non-linear equation. This enables us to conclude that any amount of shrinkage improves matching pursuit in the worst case.
</details>
<details>
<summary>摘要</summary>
我们研究基本限制的匹配追求（也称为纯格列批处理），用一个简单的线性组合来近似目标函数。当目标函数在字典的变换空间中存在时，过去几十年有很多出色的成果，得到了误差的上下限，但是它们不匹配。本文的主要贡献是关于匹配追求的衰减率的锐化特征化。我们构建了最坏情况的字典，显示现有的最佳上限不能得到显著改进。结果表明，与其他格列算法变体不同，匹配追求的 converges率是不优的，并且取决于一个非线性方程的解。这使得我们能够 conclued 任何Amount of shrinkage 都会提高匹配追求的性能在最坏情况下。
</details></li>
</ul>
<hr>
<h2 id="On-the-Robustness-of-Epoch-Greedy-in-Multi-Agent-Contextual-Bandit-Mechanisms"><a href="#On-the-Robustness-of-Epoch-Greedy-in-Multi-Agent-Contextual-Bandit-Mechanisms" class="headerlink" title="On the Robustness of Epoch-Greedy in Multi-Agent Contextual Bandit Mechanisms"></a>On the Robustness of Epoch-Greedy in Multi-Agent Contextual Bandit Mechanisms</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07675">http://arxiv.org/abs/2307.07675</a></li>
<li>repo_url: None</li>
<li>paper_authors: Yinglun Xu, Bhuvesh Kumar, Jacob Abernethy</li>
<li>for: 这篇论文主要关注在多重投机机制中的学习问题，特别是面临三大挑战：吸引真实投标行为、使用用户个性化、以及抵御 manipulate click 模式。</li>
<li>methods: 这篇论文使用了多种方法来解决这些挑战，包括 truthful multi-armed bandit mechanisms、contextual bandit algorithms 和 bandits with adversarial corruptions。</li>
<li>results: 研究发现，可以通过扩展 $\epsilon$-greedy 算法来处理这些挑战，并且这种扩展具有对 adversarial data corruption attacks 的 innate robustness，并且性能会随损害的Amount decay linearly。<details>
<summary>Abstract</summary>
Efficient learning in multi-armed bandit mechanisms such as pay-per-click (PPC) auctions typically involves three challenges: 1) inducing truthful bidding behavior (incentives), 2) using personalization in the users (context), and 3) circumventing manipulations in click patterns (corruptions). Each of these challenges has been studied orthogonally in the literature; incentives have been addressed by a line of work on truthful multi-armed bandit mechanisms, context has been extensively tackled by contextual bandit algorithms, while corruptions have been discussed via a recent line of work on bandits with adversarial corruptions. Since these challenges co-exist, it is important to understand the robustness of each of these approaches in addressing the other challenges, provide algorithms that can handle all simultaneously, and highlight inherent limitations in this combination. In this work, we show that the most prominent contextual bandit algorithm, $\epsilon$-greedy can be extended to handle the challenges introduced by strategic arms in the contextual multi-arm bandit mechanism setting. We further show that $\epsilon$-greedy is inherently robust to adversarial data corruption attacks and achieves performance that degrades linearly with the amount of corruption.
</details>
<details>
<summary>摘要</summary>
efficient learning in multi-armed bandit mechanisms such as pay-per-click (PPC) auctions typically involves three challenges: 1) inducing truthful bidding behavior (incentives), 2) using personalization in the users (context), and 3) circumventing manipulations in click patterns (corruptions). each of these challenges has been studied orthogonally in the literature; incentives have been addressed by a line of work on truthful multi-armed bandit mechanisms, context has been extensively tackled by contextual bandit algorithms, while corruptions have been discussed via a recent line of work on bandits with adversarial corruptions. since these challenges co-exist, it is important to understand the robustness of each of these approaches in addressing the other challenges, provide algorithms that can handle all simultaneously, and highlight inherent limitations in this combination. in this work, we show that the most prominent contextual bandit algorithm, $\epsilon$-greedy can be extended to handle the challenges introduced by strategic arms in the contextual multi-arm bandit mechanism setting. we further show that $\epsilon$-greedy is inherently robust to adversarial data corruption attacks and achieves performance that degrades linearly with the amount of corruption.
</details></li>
</ul>
<hr>
<h2 id="An-Empirical-Study-of-the-Effectiveness-of-Using-a-Replay-Buffer-on-Mode-Discovery-in-GFlowNets"><a href="#An-Empirical-Study-of-the-Effectiveness-of-Using-a-Replay-Buffer-on-Mode-Discovery-in-GFlowNets" class="headerlink" title="An Empirical Study of the Effectiveness of Using a Replay Buffer on Mode Discovery in GFlowNets"></a>An Empirical Study of the Effectiveness of Using a Replay Buffer on Mode Discovery in GFlowNets</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07674">http://arxiv.org/abs/2307.07674</a></li>
<li>repo_url: None</li>
<li>paper_authors: Nikhil Vemgal, Elaine Lau, Doina Precup</li>
<li>for: 本文研究了如何使用储存缓存（replay buffer）来加速GFlowNets模式发现。</li>
<li>methods: 本文employs empirical studies to explore various replay buffer sampling techniques and evaluates their impact on the speed of mode discovery and the quality of the discovered modes.</li>
<li>results: 实验结果表明，在Hypergrid即地域和分子合成环境中，使用储存缓存可以significantly improve模式发现速度和模式质量。<details>
<summary>Abstract</summary>
Reinforcement Learning (RL) algorithms aim to learn an optimal policy by iteratively sampling actions to learn how to maximize the total expected return, $R(x)$. GFlowNets are a special class of algorithms designed to generate diverse candidates, $x$, from a discrete set, by learning a policy that approximates the proportional sampling of $R(x)$. GFlowNets exhibit improved mode discovery compared to conventional RL algorithms, which is very useful for applications such as drug discovery and combinatorial search. However, since GFlowNets are a relatively recent class of algorithms, many techniques which are useful in RL have not yet been associated with them. In this paper, we study the utilization of a replay buffer for GFlowNets. We explore empirically various replay buffer sampling techniques and assess the impact on the speed of mode discovery and the quality of the modes discovered. Our experimental results in the Hypergrid toy domain and a molecule synthesis environment demonstrate significant improvements in mode discovery when training with a replay buffer, compared to training only with trajectories generated on-policy.
</details>
<details>
<summary>摘要</summary>
强化学习（RL）算法的目标是通过反复样本动作来学习最佳策略，以 maximize the total expected return, $R(x)$. GFlowNets 是一种特殊的算法，用于生成自 discrete 集合中的多个候选者，$x$, 通过学习一个策略，来近似 proportional sampling of $R(x)$. GFlowNets 在模式发现方面表现出了改善，这对于应用如药物发现和 combinatorial search 非常有用。然而，由于 GFlowNets 是一种相对较新的算法，许多RL中的技巧还没有与其相关。在这篇论文中，我们研究了 GFlowNets 中使用 replay buffer 的利用。我们通过 empirical 方式研究了不同的 replay buffer 采样技术的影响，以及它们对速度模式发现和模式质量的影响。我们的实验结果在 Hypergrid 玩家领域和一个分子合成环境中表明，在训练中使用 replay buffer 可以比训练只使用在政策上的 trajectories 更快地发现模式，并且模式质量也更高。
</details></li>
</ul>
<hr>
<h2 id="Efficient-Adversarial-Attacks-on-Online-Multi-agent-Reinforcement-Learning"><a href="#Efficient-Adversarial-Attacks-on-Online-Multi-agent-Reinforcement-Learning" class="headerlink" title="Efficient Adversarial Attacks on Online Multi-agent Reinforcement Learning"></a>Efficient Adversarial Attacks on Online Multi-agent Reinforcement Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07670">http://arxiv.org/abs/2307.07670</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guanlin Liu, Lifeng Lai</li>
<li>for:  investigate the impact of adversarial attacks on MARL</li>
<li>methods:  action poisoning, reward poisoning, mixed attack strategy</li>
<li>results:  efficient attack on MARL agents even with no prior information about the environment and agents’ algorithms<details>
<summary>Abstract</summary>
Due to the broad range of applications of multi-agent reinforcement learning (MARL), understanding the effects of adversarial attacks against MARL model is essential for the safe applications of this model. Motivated by this, we investigate the impact of adversarial attacks on MARL. In the considered setup, there is an exogenous attacker who is able to modify the rewards before the agents receive them or manipulate the actions before the environment receives them. The attacker aims to guide each agent into a target policy or maximize the cumulative rewards under some specific reward function chosen by the attacker, while minimizing the amount of manipulation on feedback and action. We first show the limitations of the action poisoning only attacks and the reward poisoning only attacks. We then introduce a mixed attack strategy with both the action poisoning and the reward poisoning. We show that the mixed attack strategy can efficiently attack MARL agents even if the attacker has no prior information about the underlying environment and the agents' algorithms.
</details>
<details>
<summary>摘要</summary>
We first show the limitations of action poisoning only attacks and reward poisoning only attacks. We then introduce a mixed attack strategy that combines both action poisoning and reward poisoning. We demonstrate that the mixed attack strategy can efficiently attack MARL agents even if the attacker has no prior knowledge of the underlying environment and the agents' algorithms.
</details></li>
</ul>
<hr>
<h2 id="Efficient-Action-Robust-Reinforcement-Learning-with-Probabilistic-Policy-Execution-Uncertainty"><a href="#Efficient-Action-Robust-Reinforcement-Learning-with-Probabilistic-Policy-Execution-Uncertainty" class="headerlink" title="Efficient Action Robust Reinforcement Learning with Probabilistic Policy Execution Uncertainty"></a>Efficient Action Robust Reinforcement Learning with Probabilistic Policy Execution Uncertainty</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07666">http://arxiv.org/abs/2307.07666</a></li>
<li>repo_url: None</li>
<li>paper_authors: Guanlin Liu, Zhihan Zhou, Han Liu, Lifeng Lai</li>
<li>for: 本研究目的是找到面对不确定性时的最佳策略，以优化最差情况性能。</li>
<li>methods: 本研究使用了可靠性执行不确定性，即策略中指定的动作会被执行的概率是1-ρ，而冲击动作会被执行的概率是ρ。我们提出了动作稳健MDP的优化方法，并开发了Action Robust Reinforcement Learning with Certificates（ARRLC）算法，可以实现最小最大偏差和样本复杂度。</li>
<li>results: 我们通过数值实验 validate了我们的方法的稳健性，并证明了ARRLC在动作冲击下比非稳健RL算法表现更好，并且 faster than robust TD算法在存在动作冲击时 converge。<details>
<summary>Abstract</summary>
Robust reinforcement learning (RL) aims to find a policy that optimizes the worst-case performance in the face of uncertainties. In this paper, we focus on action robust RL with the probabilistic policy execution uncertainty, in which, instead of always carrying out the action specified by the policy, the agent will take the action specified by the policy with probability $1-\rho$ and an alternative adversarial action with probability $\rho$. We establish the existence of an optimal policy on the action robust MDPs with probabilistic policy execution uncertainty and provide the action robust Bellman optimality equation for its solution. Furthermore, we develop Action Robust Reinforcement Learning with Certificates (ARRLC) algorithm that achieves minimax optimal regret and sample complexity. Furthermore, we conduct numerical experiments to validate our approach's robustness, demonstrating that ARRLC outperforms non-robust RL algorithms and converges faster than the robust TD algorithm in the presence of action perturbations.
</details>
<details>
<summary>摘要</summary>
Robust reinforcement learning (RL) aims to find a policy that optimizes the worst-case performance in the face of uncertainties. In this paper, we focus on action robust RL with probabilistic policy execution uncertainty, in which, instead of always carrying out the action specified by the policy, the agent will take the action specified by the policy with probability $1-\rho$ and an alternative adversarial action with probability $\rho$. We establish the existence of an optimal policy on the action robust MDPs with probabilistic policy execution uncertainty and provide the action robust Bellman optimality equation for its solution. Furthermore, we develop Action Robust Reinforcement Learning with Certificates (ARRLC) algorithm that achieves minimax optimal regret and sample complexity. Furthermore, we conduct numerical experiments to validate our approach's robustness, demonstrating that ARRLC outperforms non-robust RL algorithms and converges faster than the robust TD algorithm in the presence of action perturbations.Here's the translation in Simplified Chinese:robust reinforcement learning (RL) 目标是找到面临不确定性时的政策优化策略，在这篇论文中，我们关注action robust RL中的抽象uncertainty， Specifically, instead of always carrying out the action specified by the policy, the agent will take the action specified by the policy with probability $1-\rho$ and an alternative adversarial action with probability $\rho$. We prove the existence of an optimal policy on the action robust MDPs with probabilistic policy execution uncertainty and provide the action robust Bellman optimality equation for its solution. In addition, we develop Action Robust Reinforcement Learning with Certificates (ARRLC) algorithm that achieves minimax optimal regret and sample complexity. Finally, we conduct numerical experiments to validate our approach's robustness, demonstrating that ARRLC outperforms non-robust RL algorithms and converges faster than the robust TD algorithm in the presence of action perturbations.
</details></li>
</ul>
<hr>
<h2 id="Machine-learning-for-option-pricing-an-empirical-investigation-of-network-architectures"><a href="#Machine-learning-for-option-pricing-an-empirical-investigation-of-network-architectures" class="headerlink" title="Machine learning for option pricing: an empirical investigation of network architectures"></a>Machine learning for option pricing: an empirical investigation of network architectures</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07657">http://arxiv.org/abs/2307.07657</a></li>
<li>repo_url: None</li>
<li>paper_authors: Laurens Van Mieghem, Antonis Papapantoleon, Jonas Papazoglou-Hennig</li>
<li>for: 学习选取OPTION价格或附加价值，给出相应的输入数据（模型参数）和输出数据（选取价格或附加价值）。</li>
<li>methods: 使用激活函数网络架构，包括普通的推进网络和图像分类方法中的通用高速公路网络，以及最新的机器学习方法 дляPDEs。</li>
<li>results: 通过实验发现，对选取价格问题，使用通用高速公路网络架构可以得到最佳性能，其中误差和训练时间都是最佳。而在计算附加价值时，经过必要的转换后，DGM架构的变体可以获得最佳性能。<details>
<summary>Abstract</summary>
We consider the supervised learning problem of learning the price of an option or the implied volatility given appropriate input data (model parameters) and corresponding output data (option prices or implied volatilities). The majority of articles in this literature considers a (plain) feed forward neural network architecture in order to connect the neurons used for learning the function mapping inputs to outputs. In this article, motivated by methods in image classification and recent advances in machine learning methods for PDEs, we investigate empirically whether and how the choice of network architecture affects the accuracy and training time of a machine learning algorithm. We find that for option pricing problems, where we focus on the Black--Scholes and the Heston model, the generalized highway network architecture outperforms all other variants, when considering the mean squared error and the training time as criteria. Moreover, for the computation of the implied volatility, after a necessary transformation, a variant of the DGM architecture outperforms all other variants, when considering again the mean squared error and the training time as criteria.
</details>
<details>
<summary>摘要</summary>
我们考虑了超级vised学习问题，即通过适当的输入数据（模型参数）和对应的输出数据（选项价格或预测volatility）来学习函数映射。大多数文章在这个文献中使用（普通）径向神经网络架构来连接学习神经元。在这篇文章中，我们受到图像分类方法和最近的机器学习方法 дляPDE的影响，我们在option价格问题上进行了实验，以评估不同网络架构对精度和训练时间的影响。我们发现，对黑-谢尔斯和哈斯顿模型的option价格问题，通用高速公路网络架构在评估 Mean Squared Error 和训练时间作为标准对比下，其表现比其他所有变体更好。此外，对计算预测volatility问题，经过必要的变换，一种DGM架构的变体在评估 Mean Squared Error 和训练时间作为标准对比下，表现比其他所有变体更好。
</details></li>
</ul>
<hr>
<h2 id="DIGEST-Fast-and-Communication-Efficient-Decentralized-Learning-with-Local-Updates"><a href="#DIGEST-Fast-and-Communication-Efficient-Decentralized-Learning-with-Local-Updates" class="headerlink" title="DIGEST: Fast and Communication Efficient Decentralized Learning with Local Updates"></a>DIGEST: Fast and Communication Efficient Decentralized Learning with Local Updates</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07652">http://arxiv.org/abs/2307.07652</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/anonymous404404/digestcode">https://github.com/anonymous404404/digestcode</a></li>
<li>paper_authors: Peyman Gholami, Hulya Seferoglu</li>
<li>for: 这个论文主要针对的是异构分布数据的归一化学习问题，并提出了一种异步分布式学习机制DIGEST，以提高通信效率和速度。</li>
<li>methods: 该论文基于Gossip算法和随机漫步算法的想法，并且关注了Stochastic Gradient Descent（SGD）算法。DIGEST机制是一种异步分布式算法，基于本地SGD算法，可以提高通信效率和速度。</li>
<li>results: 论文通过分析单流和多流DIGEST机制的渐进性和通信开销，证明了两者都可以 approached到优化解决方案。在ilogistic回归和深度神经网络ResNet20上进行了实验，结果表明，多流DIGEST在iid设定下的渐进性比基eline更好，而在非iid设定下则超越基eline。<details>
<summary>Abstract</summary>
Two widely considered decentralized learning algorithms are Gossip and random walk-based learning. Gossip algorithms (both synchronous and asynchronous versions) suffer from high communication cost, while random-walk based learning experiences increased convergence time. In this paper, we design a fast and communication-efficient asynchronous decentralized learning mechanism DIGEST by taking advantage of both Gossip and random-walk ideas, and focusing on stochastic gradient descent (SGD). DIGEST is an asynchronous decentralized algorithm building on local-SGD algorithms, which are originally designed for communication efficient centralized learning. We design both single-stream and multi-stream DIGEST, where the communication overhead may increase when the number of streams increases, and there is a convergence and communication overhead trade-off which can be leveraged. We analyze the convergence of single- and multi-stream DIGEST, and prove that both algorithms approach to the optimal solution asymptotically for both iid and non-iid data distributions. We evaluate the performance of single- and multi-stream DIGEST for logistic regression and a deep neural network ResNet20. The simulation results confirm that multi-stream DIGEST has nice convergence properties; i.e., its convergence time is better than or comparable to the baselines in iid setting, and outperforms the baselines in non-iid setting.
</details>
<details>
<summary>摘要</summary>
“两种广泛被考虑的分布式学习算法是聊天和随机游走学习。聊天算法（同步和异步版本）具有高通信成本，而随机游走学习则具有增长的收敛时间。在这篇论文中，我们设计了一种快速和通信效率高的异步分布式学习机制DIGEST，通过融合聊天和随机游走的想法，专注于随机梯度下降（SGD）。DIGEST是一种异步分布式算法，基于本地SGD算法，原本设计用于通信效率高的中央化学习。我们设计了单流和多流DIGEST，其通信开销随着流数增加，并且存在一种收敛和通信开销贸易，可以利用。我们分析了单流和多流DIGEST的收敛，并证明它们在iid和非iid数据分布下都能够向优化解决方案 asymptotically。我们对单流和多流DIGEST进行了逻辑回归和深度神经网络ResNet20的性能评估。实验结果表明，多流DIGEST具有良好的收敛性质，即其收敛时间在iid设定下比基eline更快，并在非iid设定下超过基eline。”
</details></li>
</ul>
<hr>
<h2 id="SALC-Skeleton-Assisted-Learning-Based-Clustering-for-Time-Varying-Indoor-Localization"><a href="#SALC-Skeleton-Assisted-Learning-Based-Clustering-for-Time-Varying-Indoor-Localization" class="headerlink" title="SALC: Skeleton-Assisted Learning-Based Clustering for Time-Varying Indoor Localization"></a>SALC: Skeleton-Assisted Learning-Based Clustering for Time-Varying Indoor Localization</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07650">http://arxiv.org/abs/2307.07650</a></li>
<li>repo_url: None</li>
<li>paper_authors: An-Hung Hsiao, Li-Hsiang Shen, Chen-Yi Chang, Chun-Jie Chiu, Kai-Ten Feng</li>
<li>For: The paper is written for establishing a sustainable and accurate indoor localization system that can adapt to highly-changing environments.* Methods: The paper proposes a skeleton-assisted learning-based clustering localization (SALC) system that jointly considers similarities from the skeleton-based shortest path (SSP) and time-varying RSS measurements across reference points (RPs). The system includes RSS-oriented map-assisted clustering (ROMAC), cluster-based online database establishment (CODE), and cluster-scaled location estimation (CsLE).* Results: The proposed SALC system can effectively reconstruct the fingerprint database with an enhanced location estimation accuracy, outperforming other existing schemes in the open literature. Both simulation and experimental results demonstrate the effectiveness of the proposed system.<details>
<summary>Abstract</summary>
Wireless indoor localization has attracted significant amount of attention in recent years. Using received signal strength (RSS) obtained from WiFi access points (APs) for establishing fingerprinting database is a widely utilized method in indoor localization. However, the time-variant problem for indoor positioning systems is not well-investigated in existing literature. Compared to conventional static fingerprinting, the dynamicallyreconstructed database can adapt to a highly-changing environment, which achieves sustainability of localization accuracy. To deal with the time-varying issue, we propose a skeleton-assisted learning-based clustering localization (SALC) system, including RSS-oriented map-assisted clustering (ROMAC), cluster-based online database establishment (CODE), and cluster-scaled location estimation (CsLE). The SALC scheme jointly considers similarities from the skeleton-based shortest path (SSP) and the time-varying RSS measurements across the reference points (RPs). ROMAC clusters RPs into different feature sets and therefore selects suitable monitor points (MPs) for enhancing location estimation. Moreover, the CODE algorithm aims for establishing adaptive fingerprint database to alleviate the timevarying problem. Finally, CsLE is adopted to acquire the target position by leveraging the benefits of clustering information and estimated signal variations in order to rescale the weights fromweighted k-nearest neighbors (WkNN) method. Both simulation and experimental results demonstrate that the proposed SALC system can effectively reconstruct the fingerprint database with an enhanced location estimation accuracy, which outperforms the other existing schemes in the open literature.
</details>
<details>
<summary>摘要</summary>
sans serif;">无线内部位置系统在过去几年内吸引了广泛的关注。使用WiFi接入点（AP）获得的接收信号强度（RSS）来建立指本库是内部位置系统中广泛使用的方法。然而，现有文献中对indoor位置系统中的时间变化问题的研究不够。相比于传统的静止指本，动态重建库可以适应高度变化的环境，实现地位测定精度的持续性。为解决时间变化问题，我们提议一种骨架协助学习基于扩展的分布式位置估计系统（SALC），包括RSS导向的地图帮助分组（ROMAC）、群集基本在线数据建立（CODE）和群集缩放位置估计（CsLE）。SALC方案同时考虑骨架基于最短路（SSP）的相似性和时间变化的RSS测量值 across reference points（RPs）。ROMAC将RPs分为不同的特征集并因此选择了改进地位估计的适用点（MPs）。此外，CODE算法目的是建立适应时间变化的指本库，以解决时间变化问题。最后，CsLE方法使用分组信息和估计信号变化来重新衡量weighted k-nearest neighbors（WkNN）方法中的权重，以实现更高的地位估计精度。在实验和 simulations中，我们发现，提议的SALC系统可以更好地重建指本库，并在开 literature中的其他方案中表现出更高的地位估计精度。
</details></li>
</ul>
<hr>
<h2 id="DistTGL-Distributed-Memory-Based-Temporal-Graph-Neural-Network-Training"><a href="#DistTGL-Distributed-Memory-Based-Temporal-Graph-Neural-Network-Training" class="headerlink" title="DistTGL: Distributed Memory-Based Temporal Graph Neural Network Training"></a>DistTGL: Distributed Memory-Based Temporal Graph Neural Network Training</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07649">http://arxiv.org/abs/2307.07649</a></li>
<li>repo_url: None</li>
<li>paper_authors: Hongkuan Zhou, Da Zheng, Xiang Song, George Karypis, Viktor Prasanna</li>
<li>for: 这个论文主要用于提出一种可Scalable的 distributed GPU clusters 上进行 memory-based Temporal Graph Neural Networks 的训练方法，以提高训练效率和精度。</li>
<li>methods: 该论文提出了三个改进方法：1) 提高 TGNN 模型，2) 开发了一种新的训练算法，3) 优化系统。</li>
<li>results: 在实验中，DistTGL 实现了近线性的速度增长，相比单机方法，准确率提高 14.5%，训练 durchput 提高 10.17倍。<details>
<summary>Abstract</summary>
Memory-based Temporal Graph Neural Networks are powerful tools in dynamic graph representation learning and have demonstrated superior performance in many real-world applications. However, their node memory favors smaller batch sizes to capture more dependencies in graph events and needs to be maintained synchronously across all trainers. As a result, existing frameworks suffer from accuracy loss when scaling to multiple GPUs. Evenworse, the tremendous overhead to synchronize the node memory make it impractical to be deployed to distributed GPU clusters. In this work, we propose DistTGL -- an efficient and scalable solution to train memory-based TGNNs on distributed GPU clusters. DistTGL has three improvements over existing solutions: an enhanced TGNN model, a novel training algorithm, and an optimized system. In experiments, DistTGL achieves near-linear convergence speedup, outperforming state-of-the-art single-machine method by 14.5% in accuracy and 10.17x in training throughput.
</details>
<details>
<summary>摘要</summary>
<<SYS>> translate "Memory-based Temporal Graph Neural Networks are powerful tools in dynamic graph representation learning and have demonstrated superior performance in many real-world applications. However, their node memory favors smaller batch sizes to capture more dependencies in graph events and needs to be maintained synchronously across all trainers. As a result, existing frameworks suffer from accuracy loss when scaling to multiple GPUs. Even worse, the tremendous overhead to synchronize the node memory make it impractical to be deployed to distributed GPU clusters. In this work, we propose DistTGL -- an efficient and scalable solution to train memory-based TGNNs on distributed GPU clusters. DistTGL has three improvements over existing solutions: an enhanced TGNN model, a novel training algorithm, and an optimized system. In experiments, DistTGL achieves near-linear convergence speedup, outperforming state-of-the-art single-machine method by 14.5% in accuracy and 10.17x in training throughput." into Simplified Chinese.<<SYS>>室内Memery-based Temporal Graph Neural Networks是动态图表示学习中的 poderful工具，在多个实际应用中表现出了superior的性能。然而，它们的节点记忆偏好 smaller batch size以捕捉更多的图事件依赖关系，并需要在所有训练器上同步保持。因此，现有的框架会导致精度损失when scaling to multiple GPUs。worse, synchronizing the node memory leads to significant overhead, making it impractical to deploy to distributed GPU clusters.在这种情况下，我们提出了DistTGL——一种高效可扩展的解决方案，用于在分布式GPU集群上训练 memory-based TGNNs。DistTGL有三个改进：一种改进的TGNN模型，一种新的训练算法，以及一种优化的系统。在实验中，DistTGL实现了近线性的速度增长，相比单机方法的14.5%的精度提升和10.17x的训练吞吐量。
</details></li>
</ul>
<hr>
<h2 id="Exploring-Link-Prediction-over-Hyper-Relational-Temporal-Knowledge-Graphs-Enhanced-with-Time-Invariant-Relational-Knowledge"><a href="#Exploring-Link-Prediction-over-Hyper-Relational-Temporal-Knowledge-Graphs-Enhanced-with-Time-Invariant-Relational-Knowledge" class="headerlink" title="Exploring Link Prediction over Hyper-Relational Temporal Knowledge Graphs Enhanced with Time-Invariant Relational Knowledge"></a>Exploring Link Prediction over Hyper-Relational Temporal Knowledge Graphs Enhanced with Time-Invariant Relational Knowledge</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.10219">http://arxiv.org/abs/2307.10219</a></li>
<li>repo_url: None</li>
<li>paper_authors: Zifeng Ding, Jingcheng Wu, Jingpei Wu, Yan Xia, Volker Tresp</li>
<li>for: 这篇论文主要针对的是hyper-relational知识 graphs（HKGs）和temporal知识 graphs（TKGs）的理解和推理。</li>
<li>methods: 作者提出了两个新的benchmark datasets（Wiki-hy和YAGO-hy）和一种HTKG理解模型，该模型可以有效地处理时间信息和资料信息。</li>
<li>results: 实验结果表明，作者的模型在HTKG连接预测任务上显著超过了之前相关方法，并且可以通过同时利用时间不变的关系知识和时间信息来进一步提高表现。<details>
<summary>Abstract</summary>
Stemming from traditional knowledge graphs (KGs), hyper-relational KGs (HKGs) provide additional key-value pairs (i.e., qualifiers) for each KG fact that help to better restrict the fact validity. In recent years, there has been an increasing interest in studying graph reasoning over HKGs. In the meantime, due to the ever-evolving nature of world knowledge, extensive parallel works have been focusing on reasoning over temporal KGs (TKGs), where each TKG fact can be viewed as a KG fact coupled with a timestamp (or time period) specifying its time validity. The existing HKG reasoning approaches do not consider temporal information because it is not explicitly specified in previous benchmark datasets. Besides, all the previous TKG reasoning methods only lay emphasis on temporal reasoning and have no way to learn from qualifiers. To this end, we aim to fill the gap between TKG reasoning and HKG reasoning. We develop two new benchmark hyper-relational TKG (HTKG) datasets, i.e., Wiki-hy and YAGO-hy, and propose a HTKG reasoning model that efficiently models both temporal facts and qualifiers. We further exploit additional time-invariant relational knowledge from the Wikidata knowledge base and study its effectiveness in HTKG reasoning. Time-invariant relational knowledge serves as the knowledge that remains unchanged in time (e.g., Sasha Obama is the child of Barack Obama), and it has never been fully explored in previous TKG reasoning benchmarks and approaches. Experimental results show that our model substantially outperforms previous related methods on HTKG link prediction and can be enhanced by jointly leveraging both temporal and time-invariant relational knowledge.
</details>
<details>
<summary>摘要</summary>
traditional知识 graphs (KGs)的核心思想，hyper-relational知识 graphs (HKGs)提供每个KG事实的额外键值对（即资格），以更好地限定事实的有效性。近年来，研究图像理解在HKGs上有增加的兴趣。同时，由于世界知识的演化性，广泛的平行工作在图像理解过程中强调时间因素。现有的HKG理解方法不考虑时间信息，而且所有以前的TKG理解方法只是强调时间理解，没有考虑资格。为了填补这一空白，我们的目标是将HKG理解和TKG理解联系起来。我们开发了两个新的Benchmark hyper-relational TKG（HTKG）数据集，即Wiki-hy和YAGO-hy，并提出了一种HTKG理解模型，该模型能够有效地处理时间因素和资格。此外，我们还利用Wikidata知识库中的时间不变的关系知识，并研究其在HTKG理解中的效果。时间不变的关系知识是指不会随着时间的变化（例如萨沙·奥巴马是巴拉克·奥巴马的孩子），这种知识从未在过去的TKG理解benchmark和方法中被完全探索。实验结果表明，我们的模型在HTKG链接预测任务上显著超越了相关方法，并且可以通过同时利用时间因素和时间不变的关系知识来进一步提高性能。
</details></li>
</ul>
<hr>
<h2 id="Towards-Model-Size-Agnostic-Compute-Free-Memorization-based-Inference-of-Deep-Learning"><a href="#Towards-Model-Size-Agnostic-Compute-Free-Memorization-based-Inference-of-Deep-Learning" class="headerlink" title="Towards Model-Size Agnostic, Compute-Free, Memorization-based Inference of Deep Learning"></a>Towards Model-Size Agnostic, Compute-Free, Memorization-based Inference of Deep Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07631">http://arxiv.org/abs/2307.07631</a></li>
<li>repo_url: None</li>
<li>paper_authors: Davide Giacomini, Maeesha Binte Hashem, Jeremiah Suarez, Swarup Bhunia, Amit Ranjan Trivedi</li>
<li>for: 提高资源受限设备上深度神经网络模型的部署</li>
<li>methods: 使用记忆搜索（MBI），具有计算免卷和只需查找的特点，通过缓存中存储键值对来实现计算免卷的推理</li>
<li>results: 相比较现有的计算在内存（CIM）方法，MBI在MNIST字符识别任务上提高了能效率，相对于多层感知（MLP）-CIM和ResNet20-CIM方法，MBI的能效率提高了大约2.7倍和83倍Here’s the full translation of the abstract in Simplified Chinese:随着深度神经网络的快速发展，它们在各种任务上的表现得到了大幅提高，如图像和语音识别等。然而，随着模型的复杂度增加，计算成本和参数数量也随之增加，使得在资源受限设备上部署这些模型变得更加困难。本文提出了一种新的记忆搜索（MBI）方法，它具有计算免卷和只需查找的特点。通过缓存中存储键值对来实现计算免卷的推理。我们利用了隐藏向量来组合多个扫描结果，以实现问题的总分类输出。通过bayesian优化和归一化，减少了必要的查找数量，提高了准确率。此外，我们还提出了内存计算电路来快速查找输入查询匹配的关键vector。相比较现有的计算在内存（CIM）方法，MBI在MNIST字符识别任务上提高了能效率，相对于多层感知（MLP）-CIM和ResNet20-CIM方法，MBI的能效率提高了大约2.7倍和83倍。<details>
<summary>Abstract</summary>
The rapid advancement of deep neural networks has significantly improved various tasks, such as image and speech recognition. However, as the complexity of these models increases, so does the computational cost and the number of parameters, making it difficult to deploy them on resource-constrained devices. This paper proposes a novel memorization-based inference (MBI) that is compute free and only requires lookups. Specifically, our work capitalizes on the inference mechanism of the recurrent attention model (RAM), where only a small window of input domain (glimpse) is processed in a one time step, and the outputs from multiple glimpses are combined through a hidden vector to determine the overall classification output of the problem. By leveraging the low-dimensionality of glimpse, our inference procedure stores key value pairs comprising of glimpse location, patch vector, etc. in a table. The computations are obviated during inference by utilizing the table to read out key-value pairs and performing compute-free inference by memorization. By exploiting Bayesian optimization and clustering, the necessary lookups are reduced, and accuracy is improved. We also present in-memory computing circuits to quickly look up the matching key vector to an input query. Compared to competitive compute-in-memory (CIM) approaches, MBI improves energy efficiency by almost 2.7 times than multilayer perceptions (MLP)-CIM and by almost 83 times than ResNet20-CIM for MNIST character recognition.
</details>
<details>
<summary>摘要</summary>
深度神经网络的快速进步大大提高了各种任务，如图像和语音识别。然而，随着模型的复杂度增加，计算成本和参数数量也在增加，使得在有限资源的设备上部署变得困难。这篇论文提出了一种新的记忆化推理（MBI），它是计算免的，只需要lookups。我们的工作利用回卷注意力模型（RAM）的推理机制，只处理一次步骤中的小窗口输入领域（印象），并将多个印象的输出组合到一个隐藏向量中，以确定问题的总分类输出。我们利用印象的低维度，将推理过程中的关键值对存储在一个表中。在推理过程中，通过利用表来读取关键值对和计算免的推理。通过对搜索和分区进行优化，减少了必要的lookups，提高了准确率。我们还提出了内存计算电路，快速查找输入查询对应的匹配键向量。与与计算在内存（CIM）方法相比，MBI提高了能效率，相对于多层感知（MLP）-CIM的2.7倍，相对于ResNet20-CIM的83倍。
</details></li>
</ul>
<hr>
<h2 id="Generalizable-Embeddings-with-Cross-batch-Metric-Learning"><a href="#Generalizable-Embeddings-with-Cross-batch-Metric-Learning" class="headerlink" title="Generalizable Embeddings with Cross-batch Metric Learning"></a>Generalizable Embeddings with Cross-batch Metric Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07620">http://arxiv.org/abs/2307.07620</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/yetigurbuz/xml-dml">https://github.com/yetigurbuz/xml-dml</a></li>
<li>paper_authors: Yeti Z. Gurbuz, A. Aydin Alatan</li>
<li>for: 本文研究了深度度量学中的全球平均池化（GAP）组件，以及如何使其更好地捕捉Semantic Entity。</li>
<li>methods: 本文使用了学习可迁移的原型来表示GAP，并表明了这种方法可以在不同的批处理中进行可靠的学习。</li>
<li>results: 本文在4个深度度量学benchmark上验证了这种方法的效果，并达到了比较好的结果。In English, this means:</li>
<li>for: The paper studies the Global Average Pooling (GAP) component in deep metric learning (DML) and how it can better capture Semantic Entity.</li>
<li>methods: The paper uses learnable prototypes to represent GAP, and shows that this method can be reliably learned across different batches.</li>
<li>results: The paper verifies the effectiveness of this method on four popular DML benchmarks, achieving good results.<details>
<summary>Abstract</summary>
Global average pooling (GAP) is a popular component in deep metric learning (DML) for aggregating features. Its effectiveness is often attributed to treating each feature vector as a distinct semantic entity and GAP as a combination of them. Albeit substantiated, such an explanation's algorithmic implications to learn generalizable entities to represent unseen classes, a crucial DML goal, remain unclear. To address this, we formulate GAP as a convex combination of learnable prototypes. We then show that the prototype learning can be expressed as a recursive process fitting a linear predictor to a batch of samples. Building on that perspective, we consider two batches of disjoint classes at each iteration and regularize the learning by expressing the samples of a batch with the prototypes that are fitted to the other batch. We validate our approach on 4 popular DML benchmarks.
</details>
<details>
<summary>摘要</summary>
全球平均池化（GAP）是深度度量学（DML）中常用的一个组件，用于Feature集合。其效果通常被归结到对每个特征向量视为不同的semantic实体，并将GAP视为它们的组合。虽然这种解释得到了证明，但是它的算法逻辑来学习可 generalized Entities来表示未经看过的类，深度度量学的重要目标，仍然不清楚。为此，我们将GAP表示为可学习的原型的吞合权重的 convex combination。我们然后证明了这种原型学习可以表示为一个递归过程，对一个批处理样本适应一个线性预测器。从这个角度出发，我们考虑了两个不同的批处理，并在每个迭代阶段对学习进行正则化，使用这些批处理中的样本表示另一个批处理中的原型。我们验证了我们的方法在4个深度度量学标准测试集上。
</details></li>
</ul>
<hr>
<h2 id="Efficiently-Factorizing-Boolean-Matrices-using-Proximal-Gradient-Descent"><a href="#Efficiently-Factorizing-Boolean-Matrices-using-Proximal-Gradient-Descent" class="headerlink" title="Efficiently Factorizing Boolean Matrices using Proximal Gradient Descent"></a>Efficiently Factorizing Boolean Matrices using Proximal Gradient Descent</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07615">http://arxiv.org/abs/2307.07615</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/sdall/elbmf-python">https://github.com/sdall/elbmf-python</a></li>
<li>paper_authors: Sebastian Dalleiger, Jilles Vreeken</li>
<li>for:  addresses the interpretability problem of NMF on Boolean data</li>
<li>methods:  uses Boolean algebra to decompose the input into low-rank Boolean factor matrices, with a novel elastic-binary regularizer and proximal gradient algorithm</li>
<li>results:  demonstrates good performance in practice, with quick convergence, precise recovery of ground truth, and exact estimation of simulated rank; improves upon the state of the art in recall, loss, and runtime, and provides easily interpretable and semantically meaningful results on real-world data.Here’s the full text in Simplified Chinese:</li>
<li>for: addresses the interpretability problem of NMF on Boolean data</li>
<li>methods: 使用Boolean代数划分输入为低级Boolean分解矩阵，这些矩阵具有高可解释性和实际上非常有用，但是需要解决NP困难的 combinatorial优化问题; 我们提议使用一种新的灵活二进制正则化，从而 derivate一种 proximal 梯度算法</li>
<li>results: 通过广泛的实验表明，我们的方法在实际中工作良好：在 sintetic 数据上，它快速收敛，准确地回归真实值，并且正确地估算预设的rank; 在实际数据上，它超越了现有的状态，在回归、损失和运行时间上均有所提高，并且一个医疗领域的案例研究表明，我们的结果易于理解和具有Semantically Meaningful。<details>
<summary>Abstract</summary>
Addressing the interpretability problem of NMF on Boolean data, Boolean Matrix Factorization (BMF) uses Boolean algebra to decompose the input into low-rank Boolean factor matrices. These matrices are highly interpretable and very useful in practice, but they come at the high computational cost of solving an NP-hard combinatorial optimization problem. To reduce the computational burden, we propose to relax BMF continuously using a novel elastic-binary regularizer, from which we derive a proximal gradient algorithm. Through an extensive set of experiments, we demonstrate that our method works well in practice: On synthetic data, we show that it converges quickly, recovers the ground truth precisely, and estimates the simulated rank exactly. On real-world data, we improve upon the state of the art in recall, loss, and runtime, and a case study from the medical domain confirms that our results are easily interpretable and semantically meaningful.
</details>
<details>
<summary>摘要</summary>
Translated into Simplified Chinese:Addressing the interpretability problem of NMF on Boolean data, Boolean Matrix Factorization (BMF) uses Boolean algebra to decompose the input into low-rank Boolean factor matrices. These matrices are highly interpretable and very useful in practice, but they come at the high computational cost of solving an NP-hard combinatorial optimization problem. To reduce the computational burden, we propose to relax BMF continuously using a novel elastic-binary regularizer, from which we derive a proximal gradient algorithm. Through an extensive set of experiments, we demonstrate that our method works well in practice: On synthetic data, we show that it converges quickly, recovers the ground truth precisely, and estimates the simulated rank exactly. On real-world data, we improve upon the state of the art in recall, loss, and runtime, and a case study from the medical domain confirms that our results are easily interpretable and semantically meaningful.Note: Please note that the translation is in Simplified Chinese, which is one of the two standard versions of Chinese used in mainland China and Singapore. If you need Traditional Chinese, please let me know.
</details></li>
</ul>
<hr>
<h2 id="Towards-Generalizable-Detection-of-Urgency-of-Discussion-Forum-Posts"><a href="#Towards-Generalizable-Detection-of-Urgency-of-Discussion-Forum-Posts" class="headerlink" title="Towards Generalizable Detection of Urgency of Discussion Forum Posts"></a>Towards Generalizable Detection of Urgency of Discussion Forum Posts</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07614">http://arxiv.org/abs/2307.07614</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/pcla-code/forum-posts-urgency">https://github.com/pcla-code/forum-posts-urgency</a></li>
<li>paper_authors: Valdemar Švábenský, Ryan S. Baker, Andrés Zambrano, Yishan Zou, Stefan Slater</li>
<li>for: 提高在线课程教学质量，帮助 instruктор更好地支持学生学习</li>
<li>methods: 使用predictive模型自动判断讨论区帖子的优先级，以便 instructor 更有效地响应学生问题</li>
<li>results: 使用支持向量回归算法和Universal Sentence Encoder嵌入式，实现了对讨论区帖子的优先级预测，可以帮助 instructor 更好地利用时间，提高学生学习质量<details>
<summary>Abstract</summary>
Students who take an online course, such as a MOOC, use the course's discussion forum to ask questions or reach out to instructors when encountering an issue. However, reading and responding to students' questions is difficult to scale because of the time needed to consider each message. As a result, critical issues may be left unresolved, and students may lose the motivation to continue in the course. To help address this problem, we build predictive models that automatically determine the urgency of each forum post, so that these posts can be brought to instructors' attention. This paper goes beyond previous work by predicting not just a binary decision cut-off but a post's level of urgency on a 7-point scale. First, we train and cross-validate several models on an original data set of 3,503 posts from MOOCs at University of Pennsylvania. Second, to determine the generalizability of our models, we test their performance on a separate, previously published data set of 29,604 posts from MOOCs at Stanford University. While the previous work on post urgency used only one data set, we evaluated the prediction across different data sets and courses. The best-performing model was a support vector regressor trained on the Universal Sentence Encoder embeddings of the posts, achieving an RMSE of 1.1 on the training set and 1.4 on the test set. Understanding the urgency of forum posts enables instructors to focus their time more effectively and, as a result, better support student learning.
</details>
<details>
<summary>摘要</summary>
在线学习者，如MOOC课程的学生，通常会使用课程的讨论 форуم来提问或与教师联系，当遇到问题时。然而，为了考虑每条消息，评估每个消息的时间成本很高，因此可能会有重要的问题被忽略。为了解决这个问题，我们构建了预测模型，以自动确定讨论 форум的优先级，以便将这些消息引导给教师的注意。这篇论文超过了之前的工作，不仅预测了一个二分类决策阈值，而且预测了每条消息的优先级水平，从1到7的7个级别。首先，我们训练和十分之检验了多种模型，使用大学 Pennsylvania的MOOC课程的原始数据集3,503条消息。其次，为了证明我们的模型的一致性，我们测试了它们的性能在另一个，已经发表的数据集29,604条消息中。而之前的帖子优先级预测工作只使用了一个数据集，我们在不同的数据集和课程之间评估预测。最佳性能的模型是使用Universe Sentence Encoder嵌入的支持向量回归模型，在训练集上的RMSE为1.1，测试集上的RMSE为1.4。了解讨论 форум中的帖子优先级，可以帮助教师更有效地利用时间，从而更好地支持学生学习。
</details></li>
</ul>
<hr>
<h2 id="First-order-Methods-for-Affinely-Constrained-Composite-Non-convex-Non-smooth-Problems-Lower-Complexity-Bound-and-Near-optimal-Methods"><a href="#First-order-Methods-for-Affinely-Constrained-Composite-Non-convex-Non-smooth-Problems-Lower-Complexity-Bound-and-Near-optimal-Methods" class="headerlink" title="First-order Methods for Affinely Constrained Composite Non-convex Non-smooth Problems: Lower Complexity Bound and Near-optimal Methods"></a>First-order Methods for Affinely Constrained Composite Non-convex Non-smooth Problems: Lower Complexity Bound and Near-optimal Methods</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07605">http://arxiv.org/abs/2307.07605</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Liu, Qihang Lin, Yangyang Xu</li>
<li>for: 这个论文主要针对 composite non-convex non-smooth 优化问题，具有线性和&#x2F;或非线性函数约束。</li>
<li>methods: 本论文使用 first-order method (FOM) 来解决上述问题，并提供了lower complexity bound的确定。</li>
<li>results: 本论文首次为 composite non-convex non-smooth 优化问题提供了lower complexity bound，并采用了一种名为减小距离梯度（IPG）方法来实现这个目标。该方法具有 oracle complexity 与 lower bound 几乎相同的性质。<details>
<summary>Abstract</summary>
Many recent studies on first-order methods (FOMs) focus on \emph{composite non-convex non-smooth} optimization with linear and/or nonlinear function constraints. Upper (or worst-case) complexity bounds have been established for these methods. However, little can be claimed about their optimality as no lower bound is known, except for a few special \emph{smooth non-convex} cases. In this paper, we make the first attempt to establish lower complexity bounds of FOMs for solving a class of composite non-convex non-smooth optimization with linear constraints. Assuming two different first-order oracles, we establish lower complexity bounds of FOMs to produce a (near) $\epsilon$-stationary point of a problem (and its reformulation) in the considered problem class, for any given tolerance $\epsilon>0$. In addition, we present an inexact proximal gradient (IPG) method by using the more relaxed one of the two assumed first-order oracles. The oracle complexity of the proposed IPG, to find a (near) $\epsilon$-stationary point of the considered problem and its reformulation, matches our established lower bounds up to a logarithmic factor. Therefore, our lower complexity bounds and the proposed IPG method are almost non-improvable.
</details>
<details>
<summary>摘要</summary>
很多最近的研究对于首项方法（FOMs）强调 composite non-convex non-smooth 优化问题，包括线性和/或非线性函数约束。然而，对于这些方法的优化性没有很多研究，只有一些特殊的平滑非几何优化问题例外。在这篇论文中，我们首次尝试确定 FOMs 对于解决 composite non-convex non-smooth 优化问题的类型的下界复杂度。我们假设两种不同的首项或acles，并确定 FOMs 的下界复杂度，以便在任何给定的 tolerance ε > 0 下，生成 (near) ε-站点。此外，我们还提出了一种不准确的 proximal Gradient（IPG）方法，使用更松的一个首项或acles。我们的 IPG 方法的 oracle 复杂度与我们确定的下界复杂度几乎相同，只有一个对数性logarithmic factor。因此，我们的下界复杂度和提出的 IPG 方法在优化性方面几乎不可改进。
</details></li>
</ul>
<hr>
<h2 id="Smooth-Lower-Bounds-for-Differentially-Private-Algorithms-via-Padding-and-Permuting-Fingerprinting-Codes"><a href="#Smooth-Lower-Bounds-for-Differentially-Private-Algorithms-via-Padding-and-Permuting-Fingerprinting-Codes" class="headerlink" title="Smooth Lower Bounds for Differentially Private Algorithms via Padding-and-Permuting Fingerprinting Codes"></a>Smooth Lower Bounds for Differentially Private Algorithms via Padding-and-Permuting Fingerprinting Codes</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07604">http://arxiv.org/abs/2307.07604</a></li>
<li>repo_url: None</li>
<li>paper_authors: Naty Peter, Eliad Tsfadia, Jonathan Ullman</li>
<li>for: 这个论文是为了提供一种简单的方法来生成硬例子，以便为 differentially private（DP）算法的下界建立更加精细的lower bound。</li>
<li>methods: 这个论文使用了一种called “padding-and-permuting”的转换来生成硬例子，并使用了一个新的指纹代码构造方法来提供更加精细的下界。</li>
<li>results: 这个论文提供了新的下界在不同的设置下，包括DP averaging、approximate k-means clustering和DP subspace estimation等。这些下界是基于一种新的指纹lemmata，它比之前的指纹lemmata更加强大，并且可以直接从lemmata来证明下界。<details>
<summary>Abstract</summary>
Fingerprinting arguments, first introduced by Bun, Ullman, and Vadhan (STOC 2014), are the most widely used method for establishing lower bounds on the sample complexity or error of approximately differentially private (DP) algorithms. Still, there are many problems in differential privacy for which we don't know suitable lower bounds, and even for problems that we do, the lower bounds are not smooth, and usually become vacuous when the error is larger than some threshold.   In this work, we present a simple method to generate hard instances by applying a padding-and-permuting transformation to a fingerprinting code. We illustrate the applicability of this method by providing new lower bounds in various settings:   1. A tight lower bound for DP averaging in the low-accuracy regime, which in particular implies a new lower bound for the private 1-cluster problem introduced by Nissim, Stemmer, and Vadhan (PODS 2016).   2. A lower bound on the additive error of DP algorithms for approximate k-means clustering, as a function of the multiplicative error, which is tight for a constant multiplication error.   3. A lower bound for estimating the top singular vector of a matrix under DP in low-accuracy regimes, which is a special case of DP subspace estimation studied by Singhal and Steinke (NeurIPS 2021).   Our main technique is to apply a padding-and-permuting transformation to a fingerprinting code. However, rather than proving our results using a black-box access to an existing fingerprinting code (e.g., Tardos' code), we develop a new fingerprinting lemma that is stronger than those of Dwork et al. (FOCS 2015) and Bun et al. (SODA 2017), and prove our lower bounds directly from the lemma. Our lemma, in particular, gives a simpler fingerprinting code construction with optimal rate (up to polylogarithmic factors) that is of independent interest.
</details>
<details>
<summary>摘要</summary>
“指纹Argument”，最早由布恩、奥尔曼和 вадан（STOC 2014）引入，是最广泛使用的方法来确定下界或错误率的约 differentially private（DP）算法的下界。然而，有很多 differential privacy 问题，我们还没有知道合适的下界，而且甚至对已知的问题，下界不是平滑的，通常在误差大于某个阈值时变得无效。在这项工作中，我们提出了一种简单的方法，通过对指纹编码进行补充和排序转换来生成困难实例。我们通过以下几个方面证明了这种方法的应用性：1. 对DP抽象平均在低精度 régime中的下界，具体是对Nissim、Stemmer和 вадан（PODS 2016）所引入的私人1-集问题的新下界。2. DP算法对 Approximate k-means 集群化的添加性误差下界，其中multiplicative error是常数多项式的。3. DP算法对矩阵 top singular vector 的估计在低精度 régime中的下界，这是特殊的DP subspace estimation问题，与Singhal和Steinke（NeurIPS 2021）的研究相关。我们的主要技巧是对指纹编码进行补充和排序转换。而不是通过黑盒访问现有的指纹编码（例如Tardos的代码）来证明我们的结果（例如Dwork等人（FOCS 2015）和布恩等人（SODA 2017）的结果），我们开发了一个新的指纹 lemmatheorem，该lemmatheorem是Dwork等人（FOCS 2015）和布恩等人（SODA 2017）的lemmatheorem更强，并直接从lemmatheorem prove我们的下界。具体来说，我们的lemmatheorem提供了一种更简单的指纹编码建构，具有最佳率（即polylogarithmic factor），这是独立有价值的。
</details></li>
</ul>
<hr>
<h2 id="Training-Discrete-Energy-Based-Models-with-Energy-Discrepancy"><a href="#Training-Discrete-Energy-Based-Models-with-Energy-Discrepancy" class="headerlink" title="Training Discrete Energy-Based Models with Energy Discrepancy"></a>Training Discrete Energy-Based Models with Energy Discrepancy</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07595">http://arxiv.org/abs/2307.07595</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tobias Schröder, Zijing Ou, Yingzhen Li, Andrew B. Duncan</li>
<li>for: 本研究旨在提出一种新的对照损失函数，以便在离散空间上训练能量基模型（EBM）。</li>
<li>methods: 本研究使用了能量差（ED），一种新的对照损失函数，只需评估能量函数在数据点和其扰动版本之间的差异，无需采用MCMC样本抽取策略。</li>
<li>results: 研究人员通过对三种扰动过程（bernoulli噪声、杜特推论变换和邻域结构）的性能进行比较，并在离散链模型、二进制 sintetic 数据和离散图像数据集上进行了实验，证明了ED的效果。<details>
<summary>Abstract</summary>
Training energy-based models (EBMs) on discrete spaces is challenging because sampling over such spaces can be difficult. We propose to train discrete EBMs with energy discrepancy (ED), a novel type of contrastive loss functional which only requires the evaluation of the energy function at data points and their perturbed counter parts, thus not relying on sampling strategies like Markov chain Monte Carlo (MCMC). Energy discrepancy offers theoretical guarantees for a broad class of perturbation processes of which we investigate three types: perturbations based on Bernoulli noise, based on deterministic transforms, and based on neighbourhood structures. We demonstrate their relative performance on lattice Ising models, binary synthetic data, and discrete image data sets.
</details>
<details>
<summary>摘要</summary>
培训能量基于模型（EBM）在极性空间上是具有挑战性的，因为抽样这些空间可能困难。我们提议使用能量差（ED），一种新的对比损失函数，只需评估能量函数在数据点和其扰动版本之间，因此不需要采用样本策略如Markov链 Monte Carlo（MCMC）。能量差提供了对广泛类型扰动过程的理论保证，我们investigate三种类型的扰动过程：基于 Bernoulli 噪声、基于 deterministic transforms 和基于 neighbor structure。我们在邻居 Ising 模型、二进制 synthetic 数据和极性图像数据集上证明了它们的相对性能。
</details></li>
</ul>
<hr>
<h2 id="A-Quantitative-Approach-to-Predicting-Representational-Learning-and-Performance-in-Neural-Networks"><a href="#A-Quantitative-Approach-to-Predicting-Representational-Learning-and-Performance-in-Neural-Networks" class="headerlink" title="A Quantitative Approach to Predicting Representational Learning and Performance in Neural Networks"></a>A Quantitative Approach to Predicting Representational Learning and Performance in Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07575">http://arxiv.org/abs/2307.07575</a></li>
<li>repo_url: None</li>
<li>paper_authors: Ryan Pyle, Sebastian Musslick, Jonathan D. Cohen, Ankit B. Patel</li>
<li>for: 本研究旨在探讨神经网络（生物和人工）如何学习表示和处理输入信息，以解决任务。不同类型的表示可能适用于不同类型的任务，因此理解和设计有用的网络需要了解学习的表示。</li>
<li>methods: 本研究提出了一种新的 Pseudo-kernel 基于工具，用于分析和预测神经网络学习的表示。该工具基于网络的初始条件和训练课程，并且可以预测表示学习对顺序单任务和并行多任务性能的影响。</li>
<li>results: 研究人员使用了一个简单的测试案例，然后使用该工具对一个关于表示学习对顺序单任务和并行多任务性能的问题进行预测。结果显示，该工具可以预测表示学习的规模初始化和训练课程对下游同时多任务性能的影响。<details>
<summary>Abstract</summary>
A key property of neural networks (both biological and artificial) is how they learn to represent and manipulate input information in order to solve a task. Different types of representations may be suited to different types of tasks, making identifying and understanding learned representations a critical part of understanding and designing useful networks. In this paper, we introduce a new pseudo-kernel based tool for analyzing and predicting learned representations, based only on the initial conditions of the network and the training curriculum. We validate the method on a simple test case, before demonstrating its use on a question about the effects of representational learning on sequential single versus concurrent multitask performance. We show that our method can be used to predict the effects of the scale of weight initialization and training curriculum on representational learning and downstream concurrent multitasking performance.
</details>
<details>
<summary>摘要</summary>
neuronal networks（生物和人工的）的一个关键性能是如何学习表示和处理输入信息以解决任务。不同类型的表示可能适用于不同类型的任务，因此识别和理解学习的表示是设计有用网络的关键部分。在这篇论文中，我们介绍了一种新的 Pseudo-kernel 基于工具 для分析和预测学习的表示，只基于网络的初始条件和训练课程。我们验证了这种方法在一个简单的测试场景中，然后示cases the use of this method to predict the effects of representational learning on sequential single versus concurrent multitask performance. We show that our method can be used to predict the effects of the scale of weight initialization and training curriculum on representational learning and downstream concurrent multitasking performance.Here's the translation in Traditional Chinese: neuronal networks（生物和人工的）的一个关键性能是如何学习表示和处理输入信息以解决任务。不同的类型的表示可能适用于不同的任务，因此识别和理解学习的表示是设计有用网络的关键部分。在这篇论文中，我们介绍了一种新的 Pseudo-kernel 基于工具 для分析和预测学习的表示，只基于网络的初始条件和训练课程。我们验证了这种方法在一个简单的测试场景中，然后示cases the use of this method to predict the effects of representational learning on sequential single versus concurrent multitask performance. We show that our method can be used to predict the effects of the scale of weight initialization and training curriculum on representational learning and downstream concurrent multitasking performance.
</details></li>
</ul>
<hr>
<h2 id="Harpa-High-Rate-Phase-Association-with-Travel-Time-Neural-Fields"><a href="#Harpa-High-Rate-Phase-Association-with-Travel-Time-Neural-Fields" class="headerlink" title="Harpa: High-Rate Phase Association with Travel Time Neural Fields"></a>Harpa: High-Rate Phase Association with Travel Time Neural Fields</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07572">http://arxiv.org/abs/2307.07572</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/dadacheng/phase_association">https://github.com/dadacheng/phase_association</a></li>
<li>paper_authors: Cheng Shi, Maarten V. de Hoop, Ivan Dokmanić</li>
<li>for: 这个论文是为了处理小型、高频地震事件所写的，以获取地震动力学特性的信息。</li>
<li>methods: 这个论文使用了深度神经场来建立波速和相关时间的生成模型，并解决了空间-时间源local化和波速恢复问题。</li>
<li>results: 这个论文表明可以在高速度下进行相关性分组，并且可以 efficiently处理不确定的波速。 numercial experiments表明，\harpa可以 efficiently associates high-rate seismicity clouds over complex, unknown wave speeds and graciously handles noisy and missing picks.<details>
<summary>Abstract</summary>
Phase association groups seismic wave arrivals according to their originating earthquakes. It is a fundamental task in a seismic data processing pipeline, but challenging to perform for smaller, high-rate seismic events which carry fundamental information about earthquake dynamics, especially with a commonly assumed inaccurate wave speed model. As a consequence, most association methods focus on larger events that occur at a lower rate and are thus easier to associate, even though microseismicity provides a valuable description of the elastic medium properties in the subsurface. In this paper, we show that association is possible at rates much higher than previously reported even when the wave speed is unknown. We propose Harpa, a high-rate seismic phase association method which leverages deep neural fields to build generative models of wave speeds and associated travel times, and first solves a joint spatio--temporal source localization and wave speed recovery problem, followed by association. We obviate the need for associated phases by interpreting arrival time data as probability measures and using an optimal transport loss to enforce data fidelity. The joint recovery problem is known to admit a unique solution under certain conditions but due to the non-convexity of the corresponding loss a simple gradient scheme converges to poor local minima. We show that this is effectively mitigated by stochastic gradient Langevin dynamics (SGLD). Numerical experiments show that \harpa~efficiently associates high-rate seismicity clouds over complex, unknown wave speeds and graciously handles noisy and missing picks.
</details>
<details>
<summary>摘要</summary>
phasic association groups seismic wave arrivals based on their originating earthquakes. It is a fundamental task in a seismic data processing pipeline, but challenging to perform for smaller, high-rate seismic events which carry fundamental information about earthquake dynamics, especially with a commonly assumed inaccurate wave speed model. As a consequence, most association methods focus on larger events that occur at a lower rate and are thus easier to associate, even though microseismicity provides a valuable description of the elastic medium properties in the subsurface. In this paper, we show that association is possible at rates much higher than previously reported even when the wave speed is unknown. We propose Harpa, a high-rate seismic phase association method which leverages deep neural fields to build generative models of wave speeds and associated travel times, and first solves a joint spatio--temporal source localization and wave speed recovery problem, followed by association. We obviate the need for associated phases by interpreting arrival time data as probability measures and using an optimal transport loss to enforce data fidelity. The joint recovery problem is known to admit a unique solution under certain conditions but due to the non-convexity of the corresponding loss a simple gradient scheme converges to poor local minima. We show that this is effectively mitigated by stochastic gradient Langevin dynamics (SGLD). Numerical experiments show that \harpa~efficiently associates high-rate seismicity clouds over complex, unknown wave speeds and graciously handles noisy and missing picks.
</details></li>
</ul>
<hr>
<h2 id="Variational-Prediction"><a href="#Variational-Prediction" class="headerlink" title="Variational Prediction"></a>Variational Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07568">http://arxiv.org/abs/2307.07568</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/piyushpathak03/Recommendation-systems">https://github.com/piyushpathak03/Recommendation-systems</a></li>
<li>paper_authors: Alexander A. Alemi, Ben Poole</li>
<li>for: 这个论文是为了探讨 bayesian inference 的优势以及其计算成本问题。</li>
<li>methods: 这篇论文使用了一种名为 Variational Prediction 的技术，即直接学习一种 variational approximation 来 aproximate posterior predictive distribution。</li>
<li>results: 这篇论文通过使用 Variational Prediction 技术，可以提供良好的预测分布，而无需在测试时进行 marginalization 成本。<details>
<summary>Abstract</summary>
Bayesian inference offers benefits over maximum likelihood, but it also comes with computational costs. Computing the posterior is typically intractable, as is marginalizing that posterior to form the posterior predictive distribution. In this paper, we present variational prediction, a technique for directly learning a variational approximation to the posterior predictive distribution using a variational bound. This approach can provide good predictive distributions without test time marginalization costs. We demonstrate Variational Prediction on an illustrative toy example.
</details>
<details>
<summary>摘要</summary>
Note:* "Bayesian inference"  bayesian inference (悖论推理)* "maximum likelihood"  maximum likelihood (最大可能性)* "posterior"  posterior (后期)* "posterior predictive distribution"  posterior predictive distribution (后期预测分布)* "variational bound"  variational bound (可能性范围)* "variational prediction"  variational prediction (可能性预测)
</details></li>
</ul>
<hr>
<h2 id="Reconstruction-of-3-Axis-Seismocardiogram-from-Right-to-left-and-Head-to-foot-Components-Using-A-Long-Short-Term-Memory-Network"><a href="#Reconstruction-of-3-Axis-Seismocardiogram-from-Right-to-left-and-Head-to-foot-Components-Using-A-Long-Short-Term-Memory-Network" class="headerlink" title="Reconstruction of 3-Axis Seismocardiogram from Right-to-left and Head-to-foot Components Using A Long Short-Term Memory Network"></a>Reconstruction of 3-Axis Seismocardiogram from Right-to-left and Head-to-foot Components Using A Long Short-Term Memory Network</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07566">http://arxiv.org/abs/2307.07566</a></li>
<li>repo_url: None</li>
<li>paper_authors: Mohammad Muntasir Rahman, Amirtahà Taebi</li>
<li>for: 这个研究旨在开发一个深度学习模型，用于预测心脏电压信号（SCG）的dorsoventral方向。</li>
<li>methods: 使用了15名健康成人的数据集来训练和验证模型，使用了三轴加速计 recording SCG信号，并使用了电cardiogram R波 Segmentation，将信号下推、 нормаLIZATION、中心化。</li>
<li>results: 研究获得了一个LSTM网络，可以将一个心脏周期中的100个时间步骤的SCG信号转换为dorsoventral方向的SCG信号，mean square error为0.09。这项研究显示了深度学习模型可以将 dual-axis加速计读取的数据转换为三轴SCG信号。<details>
<summary>Abstract</summary>
This pilot study aims to develop a deep learning model for predicting seismocardiogram (SCG) signals in the dorsoventral direction from the SCG signals in the right-to-left and head-to-foot directions ($\textrm{SCG}_x$ and $\textrm{SCG}_y$). The dataset used for the training and validation of the model was obtained from 15 healthy adult subjects. The SCG signals were recorded using tri-axial accelerometers placed on the chest of each subject. The signals were then segmented using electrocardiogram R waves, and the segments were downsampled, normalized, and centered around zero. The resulting dataset was used to train and validate a long short-term memory (LSTM) network with two layers and a dropout layer to prevent overfitting. The network took as input 100-time steps of $\textrm{SCG}_x$ and $\textrm{SCG}_y$, representing one cardiac cycle, and outputted a vector that mapped to the target variable being predicted. The results showed that the LSTM model had a mean square error of 0.09 between the predicted and actual SCG segments in the dorsoventral direction. The study demonstrates the potential of deep learning models for reconstructing 3-axis SCG signals using the data obtained from dual-axis accelerometers.
</details>
<details>
<summary>摘要</summary>
Here's the translation in Simplified Chinese:这项试验旨在开发一个深度学习模型，用于预测心电幂量信号（SCG）的dorsoventral方向。试验使用15名健康成人的SCG信号，通过三轴加速度计记录在胸部。信号被电cardiogram R波分割，下amples， норmalize和减少中心在零点。结果显示，使用LSTM网络（两层）和dropout层预防过拟合。网络输入100个时间步长的$SCG_x$和$SCG_y$，表示一个心脏频率征，输出一个向量，将目标变量映射到。结果显示LSTM模型与实际SCG段的平均方差为0.09。这项研究表明，深度学习模型可以使用双轴加速度计记录的数据来重建3轴SCG信号。
</details></li>
</ul>
<hr>
<h2 id="Expressive-Monotonic-Neural-Networks"><a href="#Expressive-Monotonic-Neural-Networks" class="headerlink" title="Expressive Monotonic Neural Networks"></a>Expressive Monotonic Neural Networks</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07512">http://arxiv.org/abs/2307.07512</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/niklasnolte/hlt_2track">https://github.com/niklasnolte/hlt_2track</a></li>
<li>paper_authors: Ouail Kitouni, Niklas Nolte, Michael Williams</li>
<li>for: 这个论文的目的是建立一种能够确保神经网络输出具有约束依赖性的权重建立方法，以便在各种应用场景中提高神经网络的可解释性和公平性。</li>
<li>methods: 该论文提出了一种基于权重约束的神经网络架构，通过单个差分连接来实现精确的依赖性。该方法直接控制神经网络的李普希茨常数，从而提供了额外的稳定性 benefit。</li>
<li>results: 该论文通过训练多种应用场景中的强大、稳定、可解释的探测器，达到了与当前状态艺术法的竞争性性能。<details>
<summary>Abstract</summary>
The monotonic dependence of the outputs of a neural network on some of its inputs is a crucial inductive bias in many scenarios where domain knowledge dictates such behavior. This is especially important for interpretability and fairness considerations. In a broader context, scenarios in which monotonicity is important can be found in finance, medicine, physics, and other disciplines. It is thus desirable to build neural network architectures that implement this inductive bias provably. In this work, we propose a weight-constrained architecture with a single residual connection to achieve exact monotonic dependence in any subset of the inputs. The weight constraint scheme directly controls the Lipschitz constant of the neural network and thus provides the additional benefit of robustness. Compared to currently existing techniques used for monotonicity, our method is simpler in implementation and in theory foundations, has negligible computational overhead, is guaranteed to produce monotonic dependence, and is highly expressive. We show how the algorithm is used to train powerful, robust, and interpretable discriminators that achieve competitive performance compared to current state-of-the-art methods across various benchmarks, from social applications to the classification of the decays of subatomic particles produced at the CERN Large Hadron Collider.
</details>
<details>
<summary>摘要</summary>
很多情况下，神经网络的输出对某些输入的 monotonic dependence 是一种重要的推导假设。这种假设在解释性和公平性方面具有重要意义。在更广泛的上下文中， monotonicity 在金融、医学、物理和其他领域都具有重要的意义。因此，建立能够实现这种假设的神经网络架构是非常感兴趣的。在这种情况下，我们提出了一种带有单个差异连接的权重约束架构，可以实现任意输入子集的精确 monotonic dependence。这种约束方案直接控制神经网络的 Lipschitz 常数，从而提供了额外的robustness  benefit。与现有的 monotonicity 实现技术相比，我们的方法更简单，更有理论基础，计算开销几乎可以忽略不计，可以保证 monotonic dependence，并且具有很高的表达能力。我们显示了如何使用这种算法来训练高效、Robust、可解释的分类器，在社会应用和辐射子粒子在 CERN 大弹性粒子加速器中的分类方面达到了竞争性的性能。
</details></li>
</ul>
<hr>
<h2 id="MGit-A-Model-Versioning-and-Management-System"><a href="#MGit-A-Model-Versioning-and-Management-System" class="headerlink" title="MGit: A Model Versioning and Management System"></a>MGit: A Model Versioning and Management System</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07507">http://arxiv.org/abs/2307.07507</a></li>
<li>repo_url: None</li>
<li>paper_authors: Wei Hao, Daniel Mendoza, Rafael da Silva, Deepak Narayanan, Amar Phanishaye</li>
<li>for: 这篇论文是关于机器学习（ML）中模型 derivation的管理系统，帮助用户更好地存储、测试、更新和合作模型Derivative。</li>
<li>methods: 该系统使用线aje graph来记录模型之间的 provinance和版本信息，并实现了高效存储模型参数的优化和相关的测试、更新和合作功能。</li>
<li>results: 该系统可以减少线aje graph的存储占用量，并自动将下游模型更新对应的上游模型的更新。<details>
<summary>Abstract</summary>
Models derived from other models are extremely common in machine learning (ML) today. For example, transfer learning is used to create task-specific models from "pre-trained" models through finetuning. This has led to an ecosystem where models are related to each other, sharing structure and often even parameter values. However, it is hard to manage these model derivatives: the storage overhead of storing all derived models quickly becomes onerous, prompting users to get rid of intermediate models that might be useful for further analysis. Additionally, undesired behaviors in models are hard to track down (e.g., is a bug inherited from an upstream model?). In this paper, we propose a model versioning and management system called MGit that makes it easier to store, test, update, and collaborate on model derivatives. MGit introduces a lineage graph that records provenance and versioning information between models, optimizations to efficiently store model parameters, as well as abstractions over this lineage graph that facilitate relevant testing, updating and collaboration functionality. MGit is able to reduce the lineage graph's storage footprint by up to 7x and automatically update downstream models in response to updates to upstream models.
</details>
<details>
<summary>摘要</summary>
现在机器学习（ML）中，基于其他模型 derivated 的模型非常常见。例如，通过 fine-tuning 来创建任务特定模型从 "预训练" 模型。这导致了一个模型之间相互关联，共享结构，甚至参数值的生态系统。然而，管理这些模型Derivative 很困难：存储所有 derivated 模型的存储开销很快就变得压力很大，让用户放弃 intermediate 模型，可能用于进一步分析。此外，模型中的不良行为困难跟踪（例如，一个 bug 是从上游模型继承吗？）。在这篇论文中，我们提出一个名为 MGit 的模型版本管理系统，使得更加容易存储、测试、更新和合作模型Derivative。MGit 引入了模型家族图，记录模型的 происхождение和版本信息，并且提供了 Parameters 的优化，以及基于这个家族图的抽象，使得更加方便地进行相关的测试、更新和合作功能。MGit 能够将模型家族图的存储占用量减少至最多 7 倍，并自动将下游模型更新响应上游模型的更新。
</details></li>
</ul>
<hr>
<h2 id="Brain-Tumor-Detection-using-Convolutional-Neural-Networks-with-Skip-Connections"><a href="#Brain-Tumor-Detection-using-Convolutional-Neural-Networks-with-Skip-Connections" class="headerlink" title="Brain Tumor Detection using Convolutional Neural Networks with Skip Connections"></a>Brain Tumor Detection using Convolutional Neural Networks with Skip Connections</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07503">http://arxiv.org/abs/2307.07503</a></li>
<li>repo_url: None</li>
<li>paper_authors: Aupam Hamran, Marzieh Vaeztourshizi, Amirhossein Esmaili, Massoud Pedram</li>
<li>for: 用CNN分类脑肿为良性和恶性类型</li>
<li>methods: 使用MRI技术，采用不同的CNN建立方案进行分类</li>
<li>results: 结果显示，一些优化技术可以致使CNN模型在这个目标上表现出色<details>
<summary>Abstract</summary>
In this paper, we present different architectures of Convolutional Neural Networks (CNN) to analyze and classify the brain tumors into benign and malignant types using the Magnetic Resonance Imaging (MRI) technique. Different CNN architecture optimization techniques such as widening and deepening of the network and adding skip connections are applied to improve the accuracy of the network. Results show that a subset of these techniques can judiciously be used to outperform a baseline CNN model used for the same purpose.
</details>
<details>
<summary>摘要</summary>
在这篇论文中，我们介绍了不同类型的卷积神经网络（CNN）来分类大脑肿瘤为良性和有害两类使用Magnetic Resonance Imaging（MRI）技术。不同的CNN结构优化技术 such as 宽化和深化网络以及添加跳过连接被应用以提高网络的准确率。结果显示，一个子集这些技术可以有效地使用以超越基eline CNN模型。Here's the word-for-word translation:在这篇论文中，我们介绍了不同类型的卷积神经网络（CNN）来分类大脑肿瘤为良性和有害两类使用Magnetic Resonance Imaging（MRI）技术。不同的CNN结构优化技术such as 宽化和深化网络以及添加跳过连接被应用以提高网络的准确率。结果显示，一个子集这些技术可以有效地使用以超越基eline CNN模型。
</details></li>
</ul>
<hr>
<h2 id="Reinforcement-Learning-for-Photonic-Component-Design"><a href="#Reinforcement-Learning-for-Photonic-Component-Design" class="headerlink" title="Reinforcement Learning for Photonic Component Design"></a>Reinforcement Learning for Photonic Component Design</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.11075">http://arxiv.org/abs/2307.11075</a></li>
<li>repo_url: None</li>
<li>paper_authors: Donald Witt, Jeff Young, Lukas Chrostowski</li>
<li>for: 本研究旨在开发一种含有异常处理的fab-in-the-loop算法，用于设计尺度在220nm的尺度较小的光子学组件。</li>
<li>methods: 该算法利用了异常处理机制，以抵消尺度较小的光子学组件 fabrication process中的异常。</li>
<li>results: 该算法可以提高插入损耗从8.8dB降至3.24dB，并且可以生成具有150nm宽扩展带width的设计，其最低点loss不超过10.2dB。<details>
<summary>Abstract</summary>
We present a new fab-in-the-loop reinforcement learning algorithm for the design of nano-photonic components that accounts for the imperfections present in nanofabrication processes. As a demonstration of the potential of this technique, we apply it to the design of photonic crystal grating couplers (PhCGC) fabricated on a 220nm silicon on insulator (SOI) single etch platform. This fab-in-the-loop algorithm improves the insertion loss from 8.8 dB to 3.24 dB. The widest bandwidth designs produced using our fab-in-the-loop algorithm are able to cover a 150nm bandwidth with less than 10.2 dB of loss at their lowest point.
</details>
<details>
<summary>摘要</summary>
我们提出了一种新的 fab-in-the-loop 束缚学习算法，用于 nanophotonic 组件的设计，考虑到 nanofabrication 过程中存在的不确定性。作为这种技术的演示，我们应用它于 SOI 单刻平台上的 photonic crystal grating couplers (PhCGC) 的设计。这种 fab-in-the-loop 算法改善了插入损耗从 8.8 dB 降低至 3.24 dB。我们使用这种算法生成的设计可以覆盖 150nm 的频谱宽度，且损耗在最低点下不超过 10.2 dB。
</details></li>
</ul>
<hr>
<h2 id="PseudoCal-A-Source-Free-Approach-to-Unsupervised-Uncertainty-Calibration-in-Domain-Adaptation"><a href="#PseudoCal-A-Source-Free-Approach-to-Unsupervised-Uncertainty-Calibration-in-Domain-Adaptation" class="headerlink" title="PseudoCal: A Source-Free Approach to Unsupervised Uncertainty Calibration in Domain Adaptation"></a>PseudoCal: A Source-Free Approach to Unsupervised Uncertainty Calibration in Domain Adaptation</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07489">http://arxiv.org/abs/2307.07489</a></li>
<li>repo_url: None</li>
<li>paper_authors: Dapeng Hu, Jian Liang, Xinchao Wang, Chuan-Sheng Foo<br>for:This paper focuses on improving the calibration of predictive uncertainty in unsupervised domain adaptation (UDA) models, specifically in source-free UDA settings.methods:The proposed method, PseudoCal, relies exclusively on unlabeled target data to calibrate UDA models. It transforms the unsupervised calibration problem into a supervised one by generating a labeled pseudo-target set that captures the structure of the real target.results:Extensive experiments on 10 UDA methods show that PseudoCal consistently exhibits significantly reduced calibration error compared to existing calibration methods, both in traditional UDA settings and recent source-free UDA scenarios.<details>
<summary>Abstract</summary>
Unsupervised domain adaptation (UDA) has witnessed remarkable advancements in improving the accuracy of models for unlabeled target domains. However, the calibration of predictive uncertainty in the target domain, a crucial aspect of the safe deployment of UDA models, has received limited attention. The conventional in-domain calibration method, \textit{temperature scaling} (TempScal), encounters challenges due to domain distribution shifts and the absence of labeled target domain data. Recent approaches have employed importance-weighting techniques to estimate the target-optimal temperature based on re-weighted labeled source data. Nonetheless, these methods require source data and suffer from unreliable density estimates under severe domain shifts, rendering them unsuitable for source-free UDA settings. To overcome these limitations, we propose PseudoCal, a source-free calibration method that exclusively relies on unlabeled target data. Unlike previous approaches that treat UDA calibration as a \textit{covariate shift} problem, we consider it as an unsupervised calibration problem specific to the target domain. Motivated by the factorization of the negative log-likelihood (NLL) objective in TempScal, we generate a labeled pseudo-target set that captures the structure of the real target. By doing so, we transform the unsupervised calibration problem into a supervised one, enabling us to effectively address it using widely-used in-domain methods like TempScal. Finally, we thoroughly evaluate the calibration performance of PseudoCal by conducting extensive experiments on 10 UDA methods, considering both traditional UDA settings and recent source-free UDA scenarios. The experimental results consistently demonstrate the superior performance of PseudoCal, exhibiting significantly reduced calibration error compared to existing calibration methods.
</details>
<details>
<summary>摘要</summary>
Unsupervised domain adaptation (UDA) 技术在目标频道中的准确性方面做出了很多突出的进步，但是目标频道中的预测 uncertainty 的准确性却受到了有限的关注。传统的域内准则（TempScal）方法在域 Distribution 的转移和目标频道没有标注数据的情况下遇到了挑战。现有的方法使用重要性评估技术来估算目标频道优化的温度，但是这些方法需要源数据，而且在严重的域转移情况下，概率估计不可靠，因此不适用于源自由 UDA 设置。为了解决这些局限性，我们提出了 PseudoCal，一种源自由的准则调整方法，不需要源数据。与前期方法不同，我们将 UDA 准则调整视为目标频道特有的无监督准则调整问题，而不是 covariate shift 问题。受 TempScal 的负逻辑 log-likelihood（NLL） objective 的因子化启发，我们生成了一个 Pseudo-target 集，这个集合捕捉了真实target 的结构。通过这种方式，我们将无监督准则调整问题转化为监督的一个，可以使用现有的域内方法，如 TempScal，进行有效地处理。最后，我们进行了广泛的实验，评估了 10 种 UDA 方法，包括传统的 UDA 设置以及 recent source-free UDA 情况。实验结果表明，PseudoCal 的准则调整性能明显高于现有的准则调整方法，显示它在 calibration error 方面具有显著的优势。
</details></li>
</ul>
<hr>
<h2 id="DreamTeacher-Pretraining-Image-Backbones-with-Deep-Generative-Models"><a href="#DreamTeacher-Pretraining-Image-Backbones-with-Deep-Generative-Models" class="headerlink" title="DreamTeacher: Pretraining Image Backbones with Deep Generative Models"></a>DreamTeacher: Pretraining Image Backbones with Deep Generative Models</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07487">http://arxiv.org/abs/2307.07487</a></li>
<li>repo_url: None</li>
<li>paper_authors: Daiqing Li, Huan Ling, Amlan Kar, David Acuna, Seung Wook Kim, Karsten Kreis, Antonio Torralba, Sanja Fidler</li>
<li>for: 本研究旨在提出一种自然语言处理框架，即梦教师，该框架利用生成网络进行预训练下游图像背景。</li>
<li>methods: 我们提出了两种知识填充方法：1）将生成网络学习的生成特征填充到目标图像背景上，作为对ImageNet大型标注数据集的预训练；2）将生成网络获得的标签填充到目标背景上的Logits上。</li>
<li>results: 我们进行了多种生成模型、精密预测benchmark和预训练策略的实验研究，并观察到我们的梦教师在所有自我超越现有自然语言处理方法。不需要手动标注，使用梦教师进行无监督图像预训练，可以获得显著改善。<details>
<summary>Abstract</summary>
In this work, we introduce a self-supervised feature representation learning framework DreamTeacher that utilizes generative networks for pre-training downstream image backbones. We propose to distill knowledge from a trained generative model into standard image backbones that have been well engineered for specific perception tasks. We investigate two types of knowledge distillation: 1) distilling learned generative features onto target image backbones as an alternative to pretraining these backbones on large labeled datasets such as ImageNet, and 2) distilling labels obtained from generative networks with task heads onto logits of target backbones. We perform extensive analyses on multiple generative models, dense prediction benchmarks, and several pre-training regimes. We empirically find that our DreamTeacher significantly outperforms existing self-supervised representation learning approaches across the board. Unsupervised ImageNet pre-training with DreamTeacher leads to significant improvements over ImageNet classification pre-training on downstream datasets, showcasing generative models, and diffusion generative models specifically, as a promising approach to representation learning on large, diverse datasets without requiring manual annotation.
</details>
<details>
<summary>摘要</summary>
“在这个研究中，我们介绍了一个自我超vised特征表示学习框架DreamTeacher，该框架利用生成网络进行预训练下游图像脑筋。我们提议通过将生成模型已经学习的特征知识融入到标准图像脑筋中来，而不是使用大量标注数据集如ImageNet进行预训练。我们研究了两种知识融入方法：1）将生成模型学习的特征知识直接融入目标图像脑筋中，2）将生成网络中的标签融入到目标脑筋的响应值中。我们对多种生成模型、粘密预测benchmark和预训练策略进行了广泛的分析。我们发现，我们的DreamTeacher在所有自我超vised表示学习方法之上表现出优异的成绩。不需要手动标注，使用DreamTeacher进行无监督ImageNet预训练可以在下游数据集上获得显著改进，特别是使用扩散生成模型。”
</details></li>
</ul>
<hr>
<h2 id="Population-Expansion-for-Training-Language-Models-with-Private-Federated-Learning"><a href="#Population-Expansion-for-Training-Language-Models-with-Private-Federated-Learning" class="headerlink" title="Population Expansion for Training Language Models with Private Federated Learning"></a>Population Expansion for Training Language Models with Private Federated Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07477">http://arxiv.org/abs/2307.07477</a></li>
<li>repo_url: None</li>
<li>paper_authors: Tatsuki Koga, Congzheng Song, Martin Pelikan, Mona Chitnis</li>
<li>for: 这个研究旨在提高 federated learning（FL） combined with differential privacy（DP）的机器学习（ML）训练效率和形式化隐私保证，尤其是在小型人口的情况下。</li>
<li>methods: 这个研究使用了域适应技术来扩展人口，以加快训练和提高最终模型质量。</li>
<li>results: 研究表明，使用这些技术可以提高模型的使用価价（ Utility），在实际的语言模型化数据集上提高13%到30%。<details>
<summary>Abstract</summary>
Federated learning (FL) combined with differential privacy (DP) offers machine learning (ML) training with distributed devices and with a formal privacy guarantee. With a large population of devices, FL with DP produces a performant model in a timely manner. However, for applications with a smaller population, not only does the model utility degrade as the DP noise is inversely proportional to population, but also the training latency increases since waiting for enough clients to become available from a smaller pool is slower. In this work, we thus propose expanding the population based on domain adaptation techniques to speed up the training and improves the final model quality when training with small populations. We empirically demonstrate that our techniques can improve the utility by 13% to 30% on real-world language modeling datasets.
</details>
<details>
<summary>摘要</summary>
联合 federated learning (FL) 和差异隐私 (DP) 可以为分布式设备进行机器学习 (ML) 训练，并且提供正式的隐私保证。通过大量的设备人口，FL 与 DP 可以生成高性能的模型，但是在小规模应用中，模型的Utility 会逐渐下降，而且训练时间会增加，因为等待足够的客户端可用于训练的池子中 slower。为了解决这个问题，我们提议通过领域适应技术扩大人口，以加速训练和提高最终模型质量。我们经验表明，我们的技术可以提高实际语言模型集成的Utility 13% 到 30%。
</details></li>
</ul>
<hr>
<h2 id="Structured-Pruning-of-Neural-Networks-for-Constraints-Learning"><a href="#Structured-Pruning-of-Neural-Networks-for-Constraints-Learning" class="headerlink" title="Structured Pruning of Neural Networks for Constraints Learning"></a>Structured Pruning of Neural Networks for Constraints Learning</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07457">http://arxiv.org/abs/2307.07457</a></li>
<li>repo_url: None</li>
<li>paper_authors: Matteo Cacciola, Antonio Frangioni, Andrea Lodi</li>
<li>for: 这篇论文主要探讨了Machine Learning（ML）模型与Operation Research（OR）工具的组合，尤其是在肝癌治疗、算法配置和化学处理优化等领域。</li>
<li>methods: 本研究使用了删除（pruning）技术来将人工神经网络（ANNs）裁短，以提高Mixed Integer Programming（MIP）表达的解决速度。</li>
<li>results: 实验结果显示，删除可以对多层 feed-forward neural networks 建立反例，并且可以实现很大的解决速度提高，而不会对最终决策的质量产生影响。<details>
<summary>Abstract</summary>
In recent years, the integration of Machine Learning (ML) models with Operation Research (OR) tools has gained popularity across diverse applications, including cancer treatment, algorithmic configuration, and chemical process optimization. In this domain, the combination of ML and OR often relies on representing the ML model output using Mixed Integer Programming (MIP) formulations. Numerous studies in the literature have developed such formulations for many ML predictors, with a particular emphasis on Artificial Neural Networks (ANNs) due to their significant interest in many applications. However, ANNs frequently contain a large number of parameters, resulting in MIP formulations that are impractical to solve, thereby impeding scalability. In fact, the ML community has already introduced several techniques to reduce the parameter count of ANNs without compromising their performance, since the substantial size of modern ANNs presents challenges for ML applications as it significantly impacts computational efforts during training and necessitates significant memory resources for storage. In this paper, we showcase the effectiveness of pruning, one of these techniques, when applied to ANNs prior to their integration into MIPs. By pruning the ANN, we achieve significant improvements in the speed of the solution process. We discuss why pruning is more suitable in this context compared to other ML compression techniques, and we identify the most appropriate pruning strategies. To highlight the potential of this approach, we conduct experiments using feed-forward neural networks with multiple layers to construct adversarial examples. Our results demonstrate that pruning offers remarkable reductions in solution times without hindering the quality of the final decision, enabling the resolution of previously unsolvable instances.
</details>
<details>
<summary>摘要</summary>
近年来，机器学习（ML）模型与运筹学（OR）工具的集成在多种应用中得到了普遍的推广，包括肿瘤治疗、算法配置和化学过程优化。在这个领域，ML和OR的结合经常通过使用混合整数编程（MIP）表述来实现。文献中有很多研究对多种ML预测器进行了MIP表述，特别是人工神经网络（ANNs），因为它们在许多应用中具有极高的 интерес。然而，ANNs经常具有很多参数，导致MIP表述变得不实现，从而降低了扩展性。事实上，ML社区已经开发出了许多技术来减少ANNs中参数的数量，以避免降低性能。在这篇论文中，我们展示了采用剪枝（pruning）这一技术可以在ANNs之前进行剪枝，从而实现显著提高解决速度的效果。我们解释了为什么剪枝在这个上下文中比其他ML压缩技术更适用，并标识了最佳剪枝策略。为了强调这种方法的潜力，我们通过使用多层感知网络构建了反对抗例。我们的结果表明，剪枝可以很有效地减少解决时间，而无需妨碍最终决策的质量，从而解决了之前不可解决的实例。
</details></li>
</ul>
<hr>
<h2 id="Generative-adversarial-networks-for-data-scarce-spectral-applications"><a href="#Generative-adversarial-networks-for-data-scarce-spectral-applications" class="headerlink" title="Generative adversarial networks for data-scarce spectral applications"></a>Generative adversarial networks for data-scarce spectral applications</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07454">http://arxiv.org/abs/2307.07454</a></li>
<li>repo_url: None</li>
<li>paper_authors: Juan José García-Esteban, Juan Carlos Cuevas, Jorge Bravo-Abad</li>
<li>for: 本研究应用生成数学智慧（GANs）在科学领域中，解决不同科学 context 中的数据短缺问题。</li>
<li>methods: 本研究使用了 Wasserstein GANs (WGANs) 和条件 WGANs (CWGANs)，并与单元 feed-forward neural network (FFNN) 进行联合使用，以增强模型的性能。</li>
<li>results: 研究发现，使用 CWGAN 进行数据增强，可以提高 FFNN 的表现，特别是在有限数据情况下。此外，CWGAN 可以作为低数据情况下的代理模型，表现较好。<details>
<summary>Abstract</summary>
Generative adversarial networks (GANs) are one of the most robust and versatile techniques in the field of generative artificial intelligence. In this work, we report on an application of GANs in the domain of synthetic spectral data generation, offering a solution to the scarcity of data found in various scientific contexts. We demonstrate the proposed approach by applying it to an illustrative problem within the realm of near-field radiative heat transfer involving a multilayered hyperbolic metamaterial. We find that a successful generation of spectral data requires two modifications to conventional GANs: (i) the introduction of Wasserstein GANs (WGANs) to avoid mode collapse, and, (ii) the conditioning of WGANs to obtain accurate labels for the generated data. We show that a simple feed-forward neural network (FFNN), when augmented with data generated by a CWGAN, enhances significantly its performance under conditions of limited data availability, demonstrating the intrinsic value of CWGAN data augmentation beyond simply providing larger datasets. In addition, we show that CWGANs can act as a surrogate model with improved performance in the low-data regime with respect to simple FFNNs. Overall, this work highlights the potential of generative machine learning algorithms in scientific applications beyond image generation and optimization.
</details>
<details>
<summary>摘要</summary>
生成对抗网络（GAN）是生成人工智能领域最为稳健和多样化的技术之一。在这项工作中，我们报告了GAN在spectral数据生成领域的应用，提供了数据缺乏问题的解决方案。我们通过在多层赫普力元件中的近场辐射热传输问题中应用提议方法来示例。我们发现，成功生成spectral数据需要两个修改：（i）引入Wasserstein GANs（WGANs）以避免模式塌溃，以及（ii）使WGANs Conditioned以获取准确的标签 для生成数据。我们表明，在有限数据情况下，一个简单的Feed-Forward Neural Network（FFNN），当其被补充了由CWGAN生成的数据后，显著提高了其性能。此外，我们还示出了CWGAN可以作为低数据情况下的代理模型，其性能比简单的FFNN更高。总的来说，这项工作强调了生成机器学习算法在科学应用之外的潜在价值。
</details></li>
</ul>
<hr>
<h2 id="Differentially-Private-Clustering-in-Data-Streams"><a href="#Differentially-Private-Clustering-in-Data-Streams" class="headerlink" title="Differentially Private Clustering in Data Streams"></a>Differentially Private Clustering in Data Streams</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07449">http://arxiv.org/abs/2307.07449</a></li>
<li>repo_url: None</li>
<li>paper_authors: Alessandro Epasto, Tamalika Mukherjee, Peilin Zhong</li>
<li>for: 这个论文关注的问题是如何在流处理中实现隐私保护的分 clustering算法，以满足现实世界中数据隐私的要求。</li>
<li>methods: 这个论文提出了一种基于流处理的差分隐私 clustering算法，使用了流处理模型来处理大规模的数据流。该算法只需一个通过数据流的一次扫描，并且可以在流处理中实现分 clustering。</li>
<li>results: 该论文提出了一种可以实现$(1+\gamma)$-倍增加的差分隐私 clustering算法，使用了流处理模型和差分隐私技术。该算法的空间复杂度为$poly(k,d,\log(T))$,并且可以保证对于任意的$\gamma&gt;0$，扩展系数是$(1+\gamma)$，增加系数是$poly(k,d,\log(T))$.<details>
<summary>Abstract</summary>
The streaming model is an abstraction of computing over massive data streams, which is a popular way of dealing with large-scale modern data analysis. In this model, there is a stream of data points, one after the other. A streaming algorithm is only allowed one pass over the data stream, and the goal is to perform some analysis during the stream while using as small space as possible.   Clustering problems (such as $k$-means and $k$-median) are fundamental unsupervised machine learning primitives, and streaming clustering algorithms have been extensively studied in the past. However, since data privacy becomes a central concern in many real-world applications, non-private clustering algorithms are not applicable in many scenarios.   In this work, we provide the first differentially private streaming algorithms for $k$-means and $k$-median clustering of $d$-dimensional Euclidean data points over a stream with length at most $T$ using $poly(k,d,\log(T))$ space to achieve a {\it constant} multiplicative error and a $poly(k,d,\log(T))$ additive error. In particular, we present a differentially private streaming clustering framework which only requires an offline DP coreset algorithm as a blackbox. By plugging in existing DP coreset results via Ghazi, Kumar, Manurangsi 2020 and Kaplan, Stemmer 2018, we achieve (1) a $(1+\gamma)$-multiplicative approximation with $\tilde{O}_\gamma(poly(k,d,\log(T)))$ space for any $\gamma>0$, and the additive error is $poly(k,d,\log(T))$ or (2) an $O(1)$-multiplicative approximation with $\tilde{O}(k \cdot poly(d,\log(T)))$ space and $poly(k,d,\log(T))$ additive error.   In addition, our algorithmic framework is also differentially private under the continual release setting, i.e., the union of outputs of our algorithms at every timestamp is always differentially private.
</details>
<details>
<summary>摘要</summary>
“流处理模型是大规模数据流处理的抽象，是现代数据分析中受欢迎的方法。在这个模型中，有一串数据点，一个接一个地进行处理。流处理算法只有一次可以访问数据流，目标是在流中进行分析，使用最小的空间。归类问题（如$k$-means和$k$- median）是现代无监督机器学习的基本 primitives，流处理归类算法已经得到了广泛的研究。然而，由于数据隐私问题的关注，非私有的归类算法不适用于许多场景。在这种情况下，我们提供了首个具有常量多元因子错误和$poly(k,d,\log(T))$空间的扩展隐私流处理归类算法。特别是，我们提供了一个具有隐私性的流处理归类框架，只需要一个私有DP核心算法作为黑盒。通过插入现有的DP核心结果，我们实现了以下两个目标：1. $(1+\gamma)$-多元因子近似， $\tilde{O}_\gamma(poly(k,d,\log(T)))$ 空间，对于任何 $\gamma>0$。错误是 $poly(k,d,\log(T))$。2. $O(1)$-多元因子近似， $\tilde{O}(k \cdot poly(d,\log(T)))$ 空间，错误是 $poly(k,d,\log(T))$。此外，我们的算法框架还是隐私的，即将流处理算法的输出集合在每个时间戳都是隐私的。”
</details></li>
</ul>
<hr>
<h2 id="Can-Large-Language-Models-Empower-Molecular-Property-Prediction"><a href="#Can-Large-Language-Models-Empower-Molecular-Property-Prediction" class="headerlink" title="Can Large Language Models Empower Molecular Property Prediction?"></a>Can Large Language Models Empower Molecular Property Prediction?</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07443">http://arxiv.org/abs/2307.07443</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/chnq/llm4mol">https://github.com/chnq/llm4mol</a></li>
<li>paper_authors: Chen Qian, Huayi Tang, Zhirui Yang, Hong Liang, Yong Liu</li>
<li>for: 本研究旨在利用大型自然语言模型（LLM）提高分子物理性能预测。</li>
<li>methods: 本研究采用两个视角：零&#x2F;几次分子类型化和使用LLM生成的新解释作为分子表示。</li>
<li>results: 实验结果表明，使用文本解释作为分子表示可以在多个benchmark数据集上实现优越性，并证明LLM在分子物理性能预测任务中具有极大的潜力。<details>
<summary>Abstract</summary>
Molecular property prediction has gained significant attention due to its transformative potential in multiple scientific disciplines. Conventionally, a molecule graph can be represented either as a graph-structured data or a SMILES text. Recently, the rapid development of Large Language Models (LLMs) has revolutionized the field of NLP. Although it is natural to utilize LLMs to assist in understanding molecules represented by SMILES, the exploration of how LLMs will impact molecular property prediction is still in its early stage. In this work, we advance towards this objective through two perspectives: zero/few-shot molecular classification, and using the new explanations generated by LLMs as representations of molecules. To be specific, we first prompt LLMs to do in-context molecular classification and evaluate their performance. After that, we employ LLMs to generate semantically enriched explanations for the original SMILES and then leverage that to fine-tune a small-scale LM model for multiple downstream tasks. The experimental results highlight the superiority of text explanations as molecular representations across multiple benchmark datasets, and confirm the immense potential of LLMs in molecular property prediction tasks. Codes are available at \url{https://github.com/ChnQ/LLM4Mol}.
</details>
<details>
<summary>摘要</summary>
молекулярная свойство предсказание 已经吸引了广泛关注，因为它在多种科学领域中可能产生很大的转变。通常，分子图可以表示为图structured data或SMILES文本。在最近几年，大型自然语言模型（LLMs）的快速发展已经革命化了自然语言处理（NLP）领域。虽然可以使用LLMs来帮助理解表示分子的SMILES，但是研究如何使用LLMs进行分子性质预测的阶段还处于早期。在这种工作中，我们通过两个视角提前这个目标：零/几个分子类别和使用LLMs生成的新解释来代表分子。具体来说，我们首先请求LLMs在上下文中进行分子分类，并评估其表现。然后，我们使用LLMs生成semantically Rich explanation for the original SMILES，并使用这些解释来精细调整一个小规模LM模型 для多个下游任务。实验结果表明文本解释作为分子表示的超越多个benchmark dataset，并证明LLMs在分子性质预测任务中的极大潜力。代码可以在 \url{https://github.com/ChnQ/LLM4Mol} 中找到。
</details></li>
</ul>
<hr>
<h2 id="Atlas-Based-Interpretable-Age-Prediction"><a href="#Atlas-Based-Interpretable-Age-Prediction" class="headerlink" title="Atlas-Based Interpretable Age Prediction"></a>Atlas-Based Interpretable Age Prediction</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07439">http://arxiv.org/abs/2307.07439</a></li>
<li>repo_url: None</li>
<li>paper_authors: Sophie Starck, Yadunandan Vivekanand Kini, Jessica Johanna Maria Ritter, Rickmer Braren, Daniel Rueckert, Tamara Mueller</li>
<li>for: 该研究旨在提高医学评估和研究中的年龄预测精度，以检测疾病和异常年龄衰老。</li>
<li>methods: 该研究使用整体身体图像进行研究，并使用Grad-CAM解释方法确定人体不同部位对年龄预测的影响。通过注册技术生成人口范围内的解释地图，以扩展分析范围。</li>
<li>results: 研究发现三个主要预测年龄关键部位：脊梁、自生背肌和心脏区，其中心脏区的重要性最高。该模型在整体身体图像上实现了state-of-the-art的年龄预测精度，年龄差异平均值为2.76年。<details>
<summary>Abstract</summary>
Age prediction is an important part of medical assessments and research. It can aid in detecting diseases as well as abnormal ageing by highlighting the discrepancy between chronological and biological age. To gain a comprehensive understanding of age-related changes observed in various body parts, we investigate them on a larger scale by using whole-body images. We utilise the Grad-CAM interpretability method to determine the body areas most predictive of a person's age. We expand our analysis beyond individual subjects by employing registration techniques to generate population-wide interpretability maps. Furthermore, we set state-of-the-art whole-body age prediction with a model that achieves a mean absolute error of 2.76 years. Our findings reveal three primary areas of interest: the spine, the autochthonous back muscles, and the cardiac region, which exhibits the highest importance.
</details>
<details>
<summary>摘要</summary>
预测年龄是医学评估和研究中的一个重要部分。它可以帮助检测疾病以及异常年龄的趋势，并且通过显示生物年龄与 cronological age 之间的差异来提供有价值的信息。为了更全面地了解不同部位的年龄相关变化，我们使用整体图像进行研究。我们使用 Grad-CAM 可读性方法来确定人体各部位最有predictive value的地方。此外，我们还使用注册技术来生成全 популяцион的可读性地图，以扩展我们的分析范围。此外，我们实现了全身年龄预测的state-of-the-art模型，其 сред平均绝对误差为2.76年。我们的发现表明了三个主要领域：脊梁、自生肌肉和心脏区域，这三个领域具有最高的重要性。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/15/cs.LG_2023_07_15/" data-id="clly4xtd9004zvl88d6w6cy73" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-cs.SD_2023_07_15" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/15/cs.SD_2023_07_15/" class="article-date">
  <time datetime="2023-07-14T16:00:00.000Z" itemprop="datePublished">2023-07-15</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/cs-SD/">cs.SD</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/15/cs.SD_2023_07_15/">cs.SD - 2023-07-15 123:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Single-and-Multi-Speaker-Cloned-Voice-Detection-From-Perceptual-to-Learned-Features"><a href="#Single-and-Multi-Speaker-Cloned-Voice-Detection-From-Perceptual-to-Learned-Features" class="headerlink" title="Single and Multi-Speaker Cloned Voice Detection: From Perceptual to Learned Features"></a>Single and Multi-Speaker Cloned Voice Detection: From Perceptual to Learned Features</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07683">http://arxiv.org/abs/2307.07683</a></li>
<li>repo_url: <a target="_blank" rel="noopener" href="https://github.com/audio-df-ucb/clonedvoicedetection">https://github.com/audio-df-ucb/clonedvoicedetection</a></li>
<li>paper_authors: Sarah Barrington, Romit Barua, Gautham Koorma, Hany Farid</li>
<li>for: 本研究旨在 diferenciating real and cloned voices, particularly in the context of synthetic-voice cloning technologies.</li>
<li>methods: 本研究使用三种不同的方法来分辨真实的voice和假的voice，包括基于低维度感知特征的方法、基于普通频谱特征的方法以及基于端到端学习的方法。</li>
<li>results: 研究显示这三种方法可以准确地分辨真实的voice和假的voice，特别是当使用多个音频示例时。learned features consistently yield an equal error rate between $0%$ and $4%$, and are reasonably robust to adversarial laundering.<details>
<summary>Abstract</summary>
Synthetic-voice cloning technologies have seen significant advances in recent years, giving rise to a range of potential harms. From small- and large-scale financial fraud to disinformation campaigns, the need for reliable methods to differentiate real and synthesized voices is imperative. We describe three techniques for differentiating a real from a cloned voice designed to impersonate a specific person. These three approaches differ in their feature extraction stage with low-dimensional perceptual features offering high interpretability but lower accuracy, to generic spectral features, and end-to-end learned features offering less interpretability but higher accuracy. We show the efficacy of these approaches when trained on a single speaker's voice and when trained on multiple voices. The learned features consistently yield an equal error rate between $0\%$ and $4\%$, and are reasonably robust to adversarial laundering.
</details>
<details>
<summary>摘要</summary>
人工声音克隆技术在最近几年内得到了显著的进步，导致了一系列的可能性问题。从小规模到大规模的金融诈骗到假信息攻击，有必要的可靠方法来分辨真实的声音和假声音。我们描述了三种方法来分辨真实的声音和假声音，这三种方法在特征提取阶段有不同的特征。低维度感知特征提供了高度可解释性，但精度较低，而通用频谱特征和终端学习特征则提供了更高的精度，但是解释性较低。我们展示了这些方法在单个 speaker的声音和多个声音上的效果，并证明了这些方法在不同的场景下的可靠性。学习得到的特征在0%到4%的等错误率之间具有恒定的性，并在恶意洗涤下保持了一定的Robustness。
</details></li>
</ul>
<hr>
<h2 id="Towards-spoken-dialect-identification-of-Irish"><a href="#Towards-spoken-dialect-identification-of-Irish" class="headerlink" title="Towards spoken dialect identification of Irish"></a>Towards spoken dialect identification of Irish</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07436">http://arxiv.org/abs/2307.07436</a></li>
<li>repo_url: None</li>
<li>paper_authors: Liam Lonergan, Mengjie Qian, Neasa Ní Chiaráin, Christer Gobl, Ailbhe Ní Chasaide</li>
<li>for: 本研究旨在开发一个用于识别爱尔兰语言方言的语音识别系统，以便在识别爱尔兰语言时提供更加准确的结果。</li>
<li>methods: 本研究使用了两种音频分类模型：XLS-R和ECAPA-TDNN，以及一个基于预训练的爱尔兰语言BERT模型来进行文本分类。ECAPA-TDNN模型在整体上表现最佳，具有73%的准确率，而将其与文本模型进行融合可以提高准确率至76%。</li>
<li>results: 研究发现，最精准地识别爱尔兰语言的方言是 Ulster 方言，具有94%的准确率。然而，模型在识别康нахacht和慕尼黑方言时存在困难，这表明可能需要采用更加细化的方法来准确地分辨这些方言。<details>
<summary>Abstract</summary>
The Irish language is rich in its diversity of dialects and accents. This compounds the difficulty of creating a speech recognition system for the low-resource language, as such a system must contend with a high degree of variability with limited corpora. A recent study investigating dialect bias in Irish ASR found that balanced training corpora gave rise to unequal dialect performance, with performance for the Ulster dialect being consistently worse than for the Connacht or Munster dialects. Motivated by this, the present experiments investigate spoken dialect identification of Irish, with a view to incorporating such a system into the speech recognition pipeline. Two acoustic classification models are tested, XLS-R and ECAPA-TDNN, in conjunction with a text-based classifier using a pretrained Irish-language BERT model. The ECAPA-TDNN, particularly a model pretrained for language identification on the VoxLingua107 dataset, performed best overall, with an accuracy of 73%. This was further improved to 76% by fusing the model's outputs with the text-based model. The Ulster dialect was most accurately identified, with an accuracy of 94%, however the model struggled to disambiguate between the Connacht and Munster dialects, suggesting a more nuanced approach may be necessary to robustly distinguish between the dialects of Irish.
</details>
<details>
<summary>摘要</summary>
爱尔兰语言具有多样性的方言和口音，这使得为低资源语言创建语音识别系统的问题更加复杂，因为系统需要处理巨量的变化和有限的数据集。一项最近的研究发现，在爱尔兰ASR中的方言偏见会导致不均匀的方言表现，其中 Ulster 方言的表现一直比 Connacht 和 Munster 方言差。为了解决这个问题，当前的实验探索了爱尔兰口音的识别，以便将其 integrate 到语音识别管道中。两种音频分类模型，XLS-R 和 ECAPA-TDNN，以及一个基于 Irish-language BERT 模型的文本分类器被测试。ECAPA-TDNN 模型，特别是在 VoxLingua107 数据集上进行语言预训练，表现最佳，准确率为 73%。通过将模型的输出与文本分类器进行拟合，准确率可以提高到 76%。 Ulster 方言的识别率最高，为 94%，但模型在 Connacht 和 Munster 方言之间的异化方面存在困难，这表明可能需要采取更加细化的方法，以具有更加精准地分识爱尔兰方言。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/15/cs.SD_2023_07_15/" data-id="clly4xteb008cvl886qik32p1" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
    <article id="post-eess.AS_2023_07_15" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <h3 href="/2023/07/15/eess.AS_2023_07_15/" class="article-date">
  <time datetime="2023-07-14T16:00:00.000Z" itemprop="datePublished">2023-07-15</time>
</h3>
    
  <div class="article-category">
    <a class="article-category-link" href="/categories/eess-AS/">eess.AS</a>
  </div>

  </div>
  <div class="article-inner">
  <div class="curve-down">
  <div class="fill-content">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2023/07/15/eess.AS_2023_07_15/">eess.AS - 2023-07-15 22:00:00</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        
        <h2 id="Audio-Visual-Speech-Enhancement-Using-Self-supervised-Learning-to-Improve-Speech-Intelligibility-in-Cochlear-Implant-Simulations"><a href="#Audio-Visual-Speech-Enhancement-Using-Self-supervised-Learning-to-Improve-Speech-Intelligibility-in-Cochlear-Implant-Simulations" class="headerlink" title="Audio-Visual Speech Enhancement Using Self-supervised Learning to Improve Speech Intelligibility in Cochlear Implant Simulations"></a>Audio-Visual Speech Enhancement Using Self-supervised Learning to Improve Speech Intelligibility in Cochlear Implant Simulations</h2><ul>
<li>paper_url: <a target="_blank" rel="noopener" href="http://arxiv.org/abs/2307.07748">http://arxiv.org/abs/2307.07748</a></li>
<li>repo_url: None</li>
<li>paper_authors: Richard Lee Lai, Jen-Cheng Hou, Mandar Gogate, Kia Dashtipour, Amir Hussain, Yu Tsao</li>
<li>for: 帮助听力障碍者更好地理解对话，特别是在噪声环境中。</li>
<li>methods: 提出了一种基于深度学习的自动识别技术，combines 视频和声音信号，并使用Transformer-based SSL AV-HuBERT模型提取特征，然后使用 BLSTM-based SE 模型进行加工。</li>
<li>results: 实验结果显示，提出的方法可以成功地超越限制性的数据问题，并且在不同的噪声环境中都能够提高对话理解性。具体来说，PESQ 值从 1.43 提高到 1.67，STOI 值从 0.70 提高到 0.74。此外，还进行了对 CI 用户的评估，结果表明，在人工对话中遇到的动态噪声中，SSL-AVSE 表现出了明显的改善。NCM 值提高了 26.5% 到 87.2% 相比于噪声基线。<details>
<summary>Abstract</summary>
Individuals with hearing impairments face challenges in their ability to comprehend speech, particularly in noisy environments. The aim of this study is to explore the effectiveness of audio-visual speech enhancement (AVSE) in enhancing the intelligibility of vocoded speech in cochlear implant (CI) simulations. Notably, the study focuses on a challenged scenario where there is limited availability of training data for the AVSE task. To address this problem, we propose a novel deep neural network framework termed Self-Supervised Learning-based AVSE (SSL-AVSE). The proposed SSL-AVSE combines visual cues, such as lip and mouth movements, from the target speakers with corresponding audio signals. The contextually combined audio and visual data are then fed into a Transformer-based SSL AV-HuBERT model to extract features, which are further processed using a BLSTM-based SE model. The results demonstrate several key findings. Firstly, SSL-AVSE successfully overcomes the issue of limited data by leveraging the AV-HuBERT model. Secondly, by fine-tuning the AV-HuBERT model parameters for the target SE task, significant performance improvements are achieved. Specifically, there is a notable enhancement in PESQ (Perceptual Evaluation of Speech Quality) from 1.43 to 1.67 and in STOI (Short-Time Objective Intelligibility) from 0.70 to 0.74. Furthermore, the performance of the SSL-AVSE was evaluated using CI vocoded speech to assess the intelligibility for CI users. Comparative experimental outcomes reveal that in the presence of dynamic noises encountered during human conversations, SSL-AVSE exhibits a substantial improvement. The NCM (Normal Correlation Matrix) values indicate an increase of 26.5% to 87.2% compared to the noisy baseline.
</details>
<details>
<summary>摘要</summary>
听力障碍者面临听说能力下降的挑战，特别是在噪声环境中。本研究的目的是探讨audio-visualspeech增强（AVSE）在cochlear implant（CI）模拟中的有效性。值得注意的是，这个研究强调了一个困难的enario，即有限的培训数据 дляAVSE任务。为解决这个问题，我们提出了一种新的深度神经网络框架，称为Self-Supervised Learning-based AVSE（SSL-AVSE）。SSL-AVSE通过将目标speaker的lip和mouth运动视频信号与相应的音频信号结合，并将这些上下文混合的数据feed into一个Transformer-based SSL AV-HuBERT模型来提取特征。然后，通过一个BLSTM-based SE模型进行进一步处理。实验结果显示了以下几点：首先，SSL-AVSE成功地超越了有限的数据问题，利用了AV-HuBERT模型。其次，通过对AV-HuBERT模型参数的微调，在目标SE任务中实现了显著性能提升。具体来说，PESQ（Perceptual Evaluation of Speech Quality）从1.43提高到1.67，STOI（Short-Time Objective Intelligibility）从0.70提高到0.74。此外，SSL-AVSE的性能还被评估了使用CI vocoded speech来评估智能度对CI用户的智能度。对比实验结果表明，在人类对话中遇到的动态噪声中，SSL-AVSE表现出了显著提升。NCM（Normal Correlation Matrix）值表明，在噪声基eline比较之下，SSL-AVSE的提升为26.5%-87.2%。
</details></li>
</ul>

      
    </div>
    <footer class="article-footer">
      <div class="article-footer-content">
        
        <a data-url="https://nullscc.github.io/2023/07/15/eess.AS_2023_07_15/" data-id="clly4xtf300bcvl88di3u58nm" class="article-share-link">Share</a>
        
      </div>
    </footer>
  </div>
  </div>
  </div>
  
</article>



  
  
    <nav id="page-nav">
      <a class="extend prev" rel="prev" href="/page/17/">&amp;laquo; Prev</a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/16/">16</a><a class="page-number" href="/page/17/">17</a><span class="page-number current">18</span><a class="page-number" href="/page/19/">19</a><a class="page-number" href="/page/20/">20</a><span class="space">&hellip;</span><a class="page-number" href="/page/28/">28</a><a class="extend next" rel="next" href="/page/19/">Next &amp;raquo;</a>
    </nav>
  
</section>
      
      <aside id="sidebar">
  
    <div class="widget-wrap">
  <h3 class="widget-title">Calendar</h3>
  <div id="calendar"></div>
</div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Categories</h3>
    <div class="widget">
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/cs-AI/">cs.AI</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CL/">cs.CL</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-CV/">cs.CV</a><span class="category-list-count">26</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-LG/">cs.LG</a><span class="category-list-count">59</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/cs-SD/">cs.SD</a><span class="category-list-count">55</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-AS/">eess.AS</a><span class="category-list-count">29</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/eess-IV/">eess.IV</a><span class="category-list-count">56</span></li></ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">108</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a><span class="archive-list-count">169</span></li></ul>
    </div>
  </div>

  
</aside>
      
    </div>
    <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2023 nullscc<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
      .
      Theme by <a href="https://github.com/sun11/hexo-theme-paperbox" target="_blank">Paperbox</a>
    </div>
  </div>
</footer>
  </div>
  <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>

  

<!-- totop start -->
<div id="totop">
	<a title="To Top"></a>
</div>
<!-- totop end -->

<!-- swiftype search start -->

<!-- swiftype search end -->



<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

<script src="//cdnjs.cloudflare.com/ajax/libs/lrsjng.jquery-qrcode/0.12.0/jquery.qrcode.min.js"></script>


  
<link rel="stylesheet" href="/fancybox/jquery.fancybox.css">

  
<script src="/fancybox/jquery.fancybox.pack.js"></script>



<!-- add calendar widget -->

  <script src="/js/calendar.js"></script>
  <script src="/js/languages.js"></script>
  <script type="text/javascript">
    $(function() {
    
      $('#calendar').aCalendar('en', $.extend('{"months":["January","February","March","April","May","June","July","August","September","October","November","December"],"dayOfWeekShort":["S","M","T","W","T","F","S"],"dayOfWeek":["Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"]}', {single:'true', root:'calendar/'}));
    
    });
  </script>



<script src="/js/script.js"></script>


</div>
</body>
</html>
